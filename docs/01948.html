<html>
<head>
<title>Breast cancer detection with SVC and KNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于SVC和KNN的乳腺癌检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-project-1-breast-cancer-detection-with-svc-and-knn-2238ced776fc?source=collection_archive---------7-----------------------#2019-11-23">https://medium.com/analytics-vidhya/machine-learning-project-1-breast-cancer-detection-with-svc-and-knn-2238ced776fc?source=collection_archive---------7-----------------------#2019-11-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ca9f88b1eeebbdd5f0277727c848b043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gZ-OXw9M40Mx6dRK"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://unsplash.com/@michael_schiffer_design?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">迈克尔·希弗</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="32b4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个机器学习项目是关于预测肿瘤的类型——恶性还是良性。数据集来自UIC机器学习数据库。这里可以下载<a class="ae iu" href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data" rel="noopener ugc nofollow" target="_blank"/>。下载的数据集是。数据文件。文件扩展名可以更改为。csv文件。这些列被命名为“id”、“团块厚度”、“细胞大小的均匀性”、“细胞形状的均匀性”、“边缘粘附”、“单个上皮细胞大小”、“裸核”、“空白染色质”、“正常核仁”、“有丝分裂”和“类别”</p><p id="8a3d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">导入必要的包。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="23cb" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import sklearn<br/>from sklearn import preprocessing<br/>from sklearn.svm import SVC<br/>from sklearn import model_selection<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.metrics import classification_report,accuracy_score<br/>from pandas.plotting import scatter_matrix<br/>import seaborn as sns</strong></span></pre><h1 id="92fe" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">数据加载</strong></h1><p id="bd1d" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">数据集被加载到数据帧“df”中。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="1a31" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">df = pd.read_csv(‘Breast cancer.csv’) </strong>#<strong class="jy hj"><em class="lk"> </em></strong>The data set ‘Breast cancer.csv’ is loaded into ‘df’ dataframe.</span><span id="21c0" class="kc kd hi jy b fi ll kf l kg kh"><strong class="jy hj">df.head()<em class="lk"> </em></strong># Displays the first five rows of ‘df’.</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/87c92674f44df34bc8b4157b13885c02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8wYWtVt92OJGPj-E6Zq6Tg.png"/></div></div></figure><p id="6bfe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">“id”、“团块厚度”、“细胞大小的均匀性”、“细胞形状的均匀性”、“边缘粘附”、“单个上皮细胞大小”、“裸核”、“空白染色质”、“正常核仁”、“有丝分裂”是用于预测输出“类别”的变量。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="25ec" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">df.shape</strong></span></pre><p id="94d8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据帧的形状为(699，11)，表明有699个训练案例。</p><h1 id="c4a4" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">数据预处理</h1><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="5730" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">df.drop(‘id’,axis = 1,inplace = True) </strong># 'axis = 1' denotes column and 'inplace = True' denotes changes are saved in 'df'.</span></pre><p id="9529" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">“id”列被删除，因为它不影响输出“class”。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="e27f" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">df.shape</strong></span></pre><p id="dc49" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，数据帧的形状为(699，10)</p><p id="8022" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">检查缺失值</strong></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="8d28" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">col_names = ['clump thickness’,’uniformity of cell size’,’uniformity of cell shape’,’marginal adhesion’,’single epithelial cell size’,’bare nuclei’,’bland chromatin’,’normal nucleoli’,’mitosis’,’class’]</strong> # ‘col_names’ is a list of column names in‘Breast cancer.csv’</span><span id="cc98" class="kc kd hi jy b fi ll kf l kg kh"># Prints count of each column<br/><strong class="jy hj">for x in col_names: <br/> print(df[x].count())</strong></span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/297c2a0b948756ec7c39be26165241ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wy-dDlNEGgKETCq9RpfWZg.png"/></div></div></figure><p id="6f48" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每列的计数是699，这表明没有丢失值。</p><p id="f5a3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了仔细检查，我们绘制了一张热图。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="9e20" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">sns.heatmap(df.isnull())<br/></strong># df.isnull() is True (value =1)if null value and False (value = 0) otherwise.</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/5fdc3138a2a89329eb91540bb84b4a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*mFzGpdbCD6_aSRqHVG9qRg.png"/></div></figure><p id="1fe7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该值始终为0。热图还显示没有缺失值。</p><p id="07bc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">检查分类变量</strong></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="27d1" class="kc kd hi jy b fi ke kf l kg kh"># Prints total number of unique elements in each column<br/><strong class="jy hj">for x in col_names: <br/> print(df[x].nunique())</strong></span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/f36eab04c0bda7d4f24e7cc3991f587f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M42J3QE6xtVxCj9JqitH3Q.png"/></div></div></figure><p id="f189" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所有的变量都是分类变量。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="ba7b" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">df.drop(‘bare nuclei’,axis = 1,inplace = True)</strong></span></pre><p id="4325" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于格式问题，删除了“裸核”一栏。</p><p id="81da" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">了解数据</strong></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="1077" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">df.describe()</strong></span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/3e9716e2ca757d22e77ea90d515a54d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XJGRYjl0wwsjyEJF-RYktA.png"/></div></div></figure><p id="7d1c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出变量“class”是离散的，有两个值:- 2(良性)和4(恶性)。“类别”的平均值更接近2，表明良性病例更多。所有输入变量的最小值和最大值分别为1和10。</p><blockquote class="lr ls lt"><p id="a980" class="iv iw lk ix b iy iz ja jb jc jd je jf lu jh ji jj lv jl jm jn lw jp jq jr js hb bi translated">注意:-因为没有缺失值，并且所有分类变量都有数值，所以数据预处理是容易和舒适的。</p></blockquote><h1 id="86f6" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">数据可视化</h1><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="1816" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">df.hist(figsize = (10,8))<br/>plt.show()</strong></span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/6e0bf7c7a3be1d115897415631a68773.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*fmSJjGmhE8fO26VL8SeoOg.png"/></div></figure><p id="0068" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">“团块厚度”在某种程度上是均匀分布的。所有其他变量都向右倾斜。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="08e9" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">plt.figure(figsize = (10,10))<br/>sns.pairplot(df)</strong></span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/8964dec26952b639fd09c0514c8ae364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y1Qyntcg5hAbYsi0JMdFLw.png"/></div></div></figure><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/5686ec50ba44969f19c6063c5d45784b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oXz6KI6_jKHzE400TkGEHw.png"/></div></div></figure><p id="f21f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">“泡孔尺寸的均匀性”似乎与“泡孔形状的均匀性”有很强的线性关系。最后一行“类”是针对每个输入变量绘制的，这表明绘制决策边界将是困难的。(决策边界是一个超曲面，它将基础向量空间划分为两个集合，每个集合对应一个类)。</p><h1 id="c8b5" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">模特培训</h1><p id="25fb" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">数据集已经过预处理，可以进行训练了。在两种模型之间进行比较:- SVC(支持向量分类器)和KNN(K-最近邻)。</p><p id="592f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">SVC和KNN的比较</strong></p><p id="d84e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">基于交叉验证分数进行比较。给定的训练集被分成2个集:“训练集”和“测试集”。使用“训练集”的一部分来训练该模型。交叉验证分数是根据“Train_set”的其他部分中已训练模型的性能计算的。</p><p id="1967" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有各种各样的交叉验证技术，我们将在后面讨论。这里使用了K重交叉验证技术。</p><p id="b286" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">训练集被分成“训练集”和“测试集”。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="c51b" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">X = df.drop(‘class’,1)</strong> # X is input<br/><strong class="jy hj">y = df[‘class’]</strong> # y is output<br/><strong class="jy hj">X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=0.2)</strong> # Spitting into 'Train_set' and 'Test_set'.</span></pre><p id="db8a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">计算两个模型的交叉验证分数。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="d74c" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">validation_type = model_selection.KFold(n_splits = 10)</strong> # K-Fold cross validation technique is used.<br/><strong class="jy hj">cross_validation_result1 = model_selection.cross_val_score(SVC(),X_train,y_train,cv = validation_type,scoring = ‘accuracy’) </strong># Cross validation score of SVC model.<br/><strong class="jy hj">cross_validation_result2 = model_selection.cross_val_score(KNeighborsClassifier(n_neighbors = 5),X_train,y_train,cv = validation_type,scoring = ‘accuracy’) </strong># Cross validation score of KNN model.<br/><strong class="jy hj">print(cross_validation_result1.mean(),cross_validation_result2.mean())</strong></span></pre><p id="7104" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">SVC模型的交叉验证分数= 0.9605</p><p id="22f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">KNN模型的交叉验证得分= 0.9534</p><p id="2b2e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">SVC模型在给定数据集上的性能预期优于KNN模型。让我们通过使用“训练集”训练模型并使用“测试集”计算“准确度分数”和“分类报告”来验证这一点。</p><p id="9e71" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">SVC模型性能</strong></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="571a" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">a = SVC().fit(X_train,y_train) </strong># Fitting the model.<strong class="jy hj"><br/>predictions = a.predict(X_test) </strong># Test set is predicted.<strong class="jy hj"><br/>print(accuracy_score(y_test,predictions)) </strong># Accuracy score is calculated.<strong class="jy hj"><br/>print(classification_report(y_test,predictions)) </strong># Classification report is generated.</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/e823a2aaf12f99489852bb0b33ea1bde.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*mqhKMcFWb1GAD79OHhG3HA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">准确度分数和分类报告</figcaption></figure><p id="6dad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">KNN车型的性能</strong></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="5f94" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">b = KNeighborsClassifier(n_neighbors = 5).fit(X_train,y_train)</strong> # Fitting the model.<br/><strong class="jy hj">predictions = b.predict(X_test)</strong> # Test set is predicted.<br/><strong class="jy hj">print(accuracy_score(y_test,predictions))</strong> # Accuracy score is calculated.<br/><strong class="jy hj">print(classification_report(y_test,predictions))</strong> # Classification report is generated.</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/393b391113f6d50c2e63b541b1094640.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*6Hiy3rc5lh0Bxq0gFHKAWw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">准确度分数和分类报告</figcaption></figure><p id="5e49" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">SVC模型的准确度得分= 0.964</p><p id="9ce2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">KNN模型的准确度得分= 0.957</p><p id="8708" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如预期的那样，对于给定的数据集，SVC模型的精度和F1值优于KNN模型。</p><p id="b2a3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">使用训练模型进行预测</strong></p><p id="dd0f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">训练的SVC模型用于预测特定的情况:-'团块厚度' = 1，'细胞大小的均匀性' = 2，'细胞形状的均匀性' = 2，'边缘粘附' = 5，'单个上皮细胞大小' = 3，'空白染色质' = 6，'正常核仁' = 4，'有丝分裂' = 8。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="a7c3" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">prediction = a.predict(np.array([[1,2,2,5,3,6,4,8]]))<br/>print(prediction)</strong></span></pre><p id="f2d8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">“类”的预测值是4，这表明它是恶性肿瘤。</p><p id="3df3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">快乐阅读！</p></div></div>    
</body>
</html>