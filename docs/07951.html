<html>
<head>
<title>NLP The Tools, Techniques and Application</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP工具、技术和应用</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/nlp-the-tools-techniques-and-application-baadb0ce42ad?source=collection_archive---------29-----------------------#2020-07-12">https://medium.com/analytics-vidhya/nlp-the-tools-techniques-and-application-baadb0ce42ad?source=collection_archive---------29-----------------------#2020-07-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/2774bab079480482e51b50ec061a919f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*BbRKMfB7ysbgERSrLhzNUA.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">自然语言处理</figcaption></figure><p id="921a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">恭喜你！！你赢得了25000美元。点击此链接兑换您的货币$$$。你有没有注意到你的收件箱里再也看不到这样的邮件了。这类电子邮件被称为“垃圾邮件”。而你看不到这类邮件背后的现象，是因为NLP(自然语言处理)。</p><p id="5c30" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，自然语言处理是人工智能中的一个子集，它处理分析，并使用文本和语音组件提供智能解决方案。由于NLP deals使用了AI(深度学习、机器学习和一些数据科学)。重要的商品是数据/信息。并且在训练或使用数据之前，必须对其进行清理。原始数据称为原始数据，将原始数据转换/清洗成有用数据的过程称为处理。处理文本数据被称为文本处理。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es jo"><img src="../Images/b5068c75693a38cce9bbfa431640f580.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bGXycOmg_UiYCdUuU4GXwQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">关系集</figcaption></figure><h2 id="31f3" class="jx jy hi bd jz ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">文本处理、工具和技术</h2><p id="7cb2" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">有各种方法和程序来处理文本。中的NLTK库提供了预处理数据所需的所有方法。各种文本预处理方法有</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es kx"><img src="../Images/58123a8e324196885f2012f48d231514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*rsWKtPMawArG5U_kUQfonQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">文本处理</figcaption></figure><ol class=""><li id="1e48" class="ky kz hi is b it iu ix iy jb la jf lb jj lc jn ld le lf lg bi translated"><strong class="is hj">去除噪声</strong>:噪声是整个数据文档中存在的不需要的信息，它们可能是图像、一些数字、特殊符号，甚至是html标签，如&lt; div &gt;、&lt; img &gt;、&lt; h1 &gt;等等。这些标签并没有为程序员提供任何有用的信息，而是充当了chunk的角色。所以我们可以使用正则表达式(在python正则表达式库中被称为re)来消除这些噪声</li></ol><pre class="jp jq jr js fd lh li lj lk aw ll bi"><span id="0b80" class="jx jy hi li b fi lm ln l lo lp">import re<br/>text="&lt;h1&gt; Hello this is how Regular Expressions work in python and we can remove the noise using re module &lt;/h1&gt;"<br/>new_text= re.sub(r'&lt;.?h1&gt;','',text)</span><span id="5074" class="jx jy hi li b fi lq ln l lo lp"> #this replaces the h1 and /h1 tag with empty space </span></pre><p id="5a8d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.<strong class="is hj">分词</strong>:将文档信息转换成句子或单词(将文本拆分成单词)的过程。nltk为我们提供了两种类型的分词器:单词分词器和句子分词器<br/> a) <strong class="is hj">单词分词器</strong>:将文本拆分成单词</p><pre class="jp jq jr js fd lh li lj lk aw ll bi"><span id="95ce" class="jx jy hi li b fi lm ln l lo lp">from nltk.tokenize import word_tokenize<br/>text= "This text is to be Tokenized"<br/>tokenized=word_tokenize(text)<br/>print(tokenized)</span><span id="be99" class="jx jy hi li b fi lq ln l lo lp"># ["This", "text","is","to", "be", "Tokenized"]</span></pre><p id="2819" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">b) <strong class="is hj">句子标记化</strong>:句子标记化是将文本拆分成句子的过程。</p><pre class="jp jq jr js fd lh li lj lk aw ll bi"><span id="280b" class="jx jy hi li b fi lm ln l lo lp">from nltk.tokenize import sent_tokenize<br/>text="hi this is a sentence. this is another sentence"<br/>tokenized= sent_tokenized(text)<br/>print(tokenized)</span><span id="0ab6" class="jx jy hi li b fi lq ln l lo lp">#["hi this is a sentence", "this is another sentence"]</span></pre><p id="4112" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这两种标记化方法的使用取决于应用。在使用NLP构建应用程序时，标记化是一个重要的过程</p><p id="c0b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.词汇化是一把解剖刀，将单词分解到它们的词根形式。例如，NLTK的精明的lemmatizer知道“am”和“are”与“be”相关。</p><pre class="jp jq jr js fd lh li lj lk aw ll bi"><span id="668b" class="jx jy hi li b fi lm ln l lo lp">from nltk.stem import WordNetLemmatizer <br/>lemmatizer = WordNetLemmatizer()<br/>tokenized = ["NBC", "was", "founded", "in", "1926"] <br/>lemmatized = [lemmatizer.lemmatize(token) for token in tokenized]    print(lemmatized)<br/> # ["NBC", "wa", "founded", "in", "1926"]</span></pre><p id="abd6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在标记化文本之后，接着进行词汇化，以使用词汇化器将标记化的单词转换成它们的词根形式。这个过程被广泛用于建立聊天机器人。</p><p id="69c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.<strong class="is hj">词干化</strong>:就是去掉单词的前缀和后缀的过程。因为后缀没有给所需的数据增加任何意义，所以我们最好删除它们。雨变成了雨，光变成了光</p><pre class="jp jq jr js fd lh li lj lk aw ll bi"><span id="2d13" class="jx jy hi li b fi lm ln l lo lp">from nltk.stem import PorterStemmer<br/>stemmer = PorterStemmer()<br/>tokenized = ['NBC', 'was', 'founded', 'in', '1926', '.', 'This', 'makes', 'NBC', 'the', 'oldest', 'major', 'broadcast', 'network', '.']  <br/>stemmed = [stemmer.stem(token) for token in tokenized]  print(stemmed) <br/># ['nbc', 'wa', 'found', 'in', '1926', '.', 'thi', 'make', 'nbc', 'the', 'oldest', 'major', 'broadcast', 'network', '.']</span></pre><p id="f243" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">词干分析是搜索引擎用来提高用户输入和网站点击匹配度的常用方法。</p><p id="8eb6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.<strong class="is hj">停用词去除</strong>:停用词是我们在预处理过程中，在不关心句子结构的情况下去除的词。停用词的例子有“and”、“an”、“the”。幸运的是，nltk库提供了一个删除不需要的单词的功能</p><pre class="jp jq jr js fd lh li lj lk aw ll bi"><span id="1cac" class="jx jy hi li b fi lm ln l lo lp">from nltk.corpus import stopwords<br/>stop_words = set(stopwords.words('english'))<br/>nbc_statement = "NBC was founded in 1926 making it the oldest major broadcast network in the USA" <br/>word_tokens = word_tokenize(nbc_statement)  <br/># tokenize nbc_statement  <br/>statement_no_stop = [word for word in word_tokens if word not in stop_words]  print(statement_no_stop)<br/># ['NBC', 'founded', '1926', 'making', 'oldest', 'major', 'broadcast', 'network', 'USA']</span></pre><p id="f69e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">文本处理是使用自然语言处理构建应用程序的第一步。需要遵循各种流程，例如</p><ul class=""><li id="7d1c" class="ky kz hi is b it iu ix iy jb la jf lb jj lc jn lr le lf lg bi translated">词性标注</li><li id="01d7" class="ky kz hi is b it ls ix lt jb lu jf lv jj lw jn lr le lf lg bi translated">解析文本。</li><li id="445e" class="ky kz hi is b it ls ix lt jb lu jf lv jj lw jn lr le lf lg bi translated">将单词转换为矢量(Word2Vec)</li><li id="a364" class="ky kz hi is b it ls ix lt jb lu jf lv jj lw jn lr le lf lg bi translated">找出文本之间的相似之处。</li><li id="1d0d" class="ky kz hi is b it ls ix lt jb lu jf lv jj lw jn lr le lf lg bi translated">主题建模。</li></ul><h1 id="a034" class="lx jy hi bd jz ly lz ma kd mb mc md kh me mf mg kk mh mi mj kn mk ml mm kq mn bi translated">应用程序</h1><p id="37d8" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">被称为自然语言处理的人工智能子集被用于构建许多产品，例如</p><ul class=""><li id="4e93" class="ky kz hi is b it iu ix iy jb la jf lb jj lc jn lr le lf lg bi translated">聊天机器人</li><li id="c715" class="ky kz hi is b it ls ix lt jb lu jf lv jj lw jn lr le lf lg bi translated">垃圾邮件分类器</li><li id="bcb5" class="ky kz hi is b it ls ix lt jb lu jf lv jj lw jn lr le lf lg bi translated">情感分析(正面或负面反馈)</li><li id="bb96" class="ky kz hi is b it ls ix lt jb lu jf lv jj lw jn lr le lf lg bi translated">剽窃检查器</li><li id="0f84" class="ky kz hi is b it ls ix lt jb lu jf lv jj lw jn lr le lf lg bi translated">还有更多</li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es mo"><img src="../Images/7f6b12810807f28e5431ee6162ae5fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2C2OjE6POLC_O_aJiC2llw.png"/></div></div></figure><p id="4a3b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，奖励检验情绪分析程序，并检查反馈是积极的还是消极的。</p><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mp mq l"/></div></figure></div></div>    
</body>
</html>