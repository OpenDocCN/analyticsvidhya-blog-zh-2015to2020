<html>
<head>
<title>Introduction to 2 Dimensional LSTM Autoencoder</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">二维LSTM自动编码器简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-2-dimensional-lstm-autoencoder-47c238fd827f?source=collection_archive---------7-----------------------#2020-10-16">https://medium.com/analytics-vidhya/introduction-to-2-dimensional-lstm-autoencoder-47c238fd827f?source=collection_archive---------7-----------------------#2020-10-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6558" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我早期知识库的延续，在那里我使用1D·LSTM进行自动编码器和异常检测，可以在这里找到<a class="ae jd" href="https://github.com/adnanmushtaq1996/lstm-autoencoder" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/665ad2f814e509349cfa8851f0425d8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*wKE69-fX180Q_gkzYzGbwg.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">自动编码器结构</figcaption></figure><p id="fb2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我将话题扩展到2D数据的LSTM自动编码器。创建一个单独的职位，因为LSTM往往会变得很棘手，当谈到投入。</p><blockquote class="jq jr js"><p id="87bb" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">@ <a class="ae jd" href="https://towardsdatascience.com/@timurbikmukhametov?source=post_page-----133dad96cd00--------------------------------" rel="noopener" target="_blank">铁木尔·比克穆哈梅托夫</a> <a class="ae jd" href="https://towardsdatascience.com/how-to-reshape-data-and-do-regression-for-time-series-using-lstm-133dad96cd00" rel="noopener" target="_blank">这里</a>可以找到一个解释输入和输出的惊人博客。</p></blockquote><p id="f122" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看一些代码来理解2D LSTM自动编码器。</p><p id="5573" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们将使用我为测试创建的简单数据，同样的数据可以在GitHub <a class="ae jd" href="https://github.com/adnanmushtaq1996/2D-LSTM-AUTOENCODER" rel="noopener ugc nofollow" target="_blank">的源代码中找到。</a></p><p id="fd76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们开始吧！！</p><p id="6e00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">导入依赖关系</strong></p><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="78c3" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">import</strong> <strong class="jy hj">pandas</strong> <strong class="jy hj">as</strong> <strong class="jy hj">pd</strong><br/><strong class="jy hj">import</strong> <strong class="jy hj">numpy</strong> <strong class="jy hj">as</strong> <strong class="jy hj">np</strong><br/><br/><strong class="jy hj">from</strong> <strong class="jy hj">tensorflow</strong> <strong class="jy hj">import</strong> keras<br/><strong class="jy hj">from</strong> <strong class="jy hj">tensorflow.python.keras.layers</strong> <strong class="jy hj">import</strong> Input, Dense,RepeatVector, TimeDistributed, Dense, Dropout, LSTM<br/><strong class="jy hj">from</strong> <strong class="jy hj">tensorflow.python.keras.models</strong> <strong class="jy hj">import</strong> Sequential<br/><br/><strong class="jy hj">import</strong> <strong class="jy hj">matplotlib.pyplot</strong> <strong class="jy hj">as</strong> <strong class="jy hj">plt</strong><br/>%matplotlib inline<br/><br/><strong class="jy hj">import</strong> <strong class="jy hj">sklearn</strong><br/><strong class="jy hj">from</strong> <strong class="jy hj">sklearn.preprocessing</strong> <strong class="jy hj">import</strong> StandardScaler<br/><strong class="jy hj">from</strong> <strong class="jy hj">sklearn.model_selection</strong> <strong class="jy hj">import</strong> train_test_split</span></pre><p id="9c0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">读取数据</strong></p><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="fff1" class="kc kd hi jy b fi ke kf l kg kh">df = pd.read_csv('../Data/Sample.csv', parse_dates=['Time Stamp'], index_col='Time Stamp')<br/>df.head(n=5)  </span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ki"><img src="../Images/6657d4514b966d135372ec864e5de182.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*PYDL2f3el9G0ynbdF3MBuw.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">用于测试的数据集</figcaption></figure><h2 id="017a" class="kc kd hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">为LSTM输入创建数据(一系列数据，即在此创建一系列具有时间步长和元素数量的数据)</h2><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="d718" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">def</strong> create_dataset(X, y, time_steps=1):<br/>    Xs, ys = [], []<br/>    <strong class="jy hj">for</strong> i <strong class="jy hj">in</strong> range(len(X) - time_steps):<br/>        v = X.iloc[i:(i + time_steps)].values<br/>        Xs.append(v)        <br/>        ys.append(y.iloc[i + time_steps])<br/>    <strong class="jy hj">return</strong> np.array(Xs), np.array(ys)</span><span id="7948" class="kc kd hi jy b fi lc kf l kg kh"><em class="jt"># Timesteps will define how many Elements we have</em><br/>TIME_STEPS = 5<br/><br/>X_train, y_train = create_dataset(df, df, TIME_STEPS)<br/><br/><br/>print(X_train.shape)</span></pre><p id="02bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">X_train的形状是(20，5，2)，每个输入块具有5个样本，每个样本具有2个特征。</p><blockquote class="jq jr js"><p id="0baa" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">如果你理解了这一步，那么剩下的就容易多了。</p></blockquote><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="7b22" class="kc kd hi jy b fi ke kf l kg kh"><em class="jt">#Size of Input Data  is n_samples * timesteps * n_features</em></span></pre><h2 id="0fb4" class="kc kd hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">创建LSTM自动编码器模型</h2><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="69ff" class="kc kd hi jy b fi ke kf l kg kh">model = Sequential()<br/>model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))<br/>model.add(Dropout(rate=0.2))<br/>model.add(RepeatVector(X_train.shape[1]))<br/>model.add(LSTM(128, return_sequences=<strong class="jy hj">True</strong>))<br/>model.add(Dropout(rate=0.2))<br/>model.add(TimeDistributed(Dense(X_train.shape[2])))<br/>model.compile(optimizer='adam', loss='mae')<br/>model.summary()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ld"><img src="../Images/edddeaaeaf206aa7e488261cb30edcf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*E2yJ9ph1TWLXsXAwYQ6Rbg.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">模型摘要</figcaption></figure><p id="1d0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">训练模型</strong></p><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="956a" class="kc kd hi jy b fi ke kf l kg kh">history = model.fit(X_train, X_train, epochs=200, batch_size=32, validation_split=0.1)</span></pre><p id="63b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">可视化培训</strong></p><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="654f" class="kc kd hi jy b fi ke kf l kg kh">plt.plot(history.history['loss'], label='Training loss') plt.plot(history.history['val_loss'], label='Validation loss') plt.legend();</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es le"><img src="../Images/d93ca6fea4c848297485275a10e06863.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*BKH2f1JuAHgXxzAj2lredw.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">培训损失图</figcaption></figure><p id="5064" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">测试模型</strong></p><p id="12b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，最重要的阶段来了，测试我们有多接近用我们的模型重建输入，这个模型很难用数据训练。</p><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="2ebe" class="kc kd hi jy b fi ke kf l kg kh"><em class="jt">#Create a new test data close to what model has seen and check the MSE</em><br/>test1 = np.array([[ 1, 0.7],<br/>                [2, 0.86],<br/>                [2.9, 0.85],<br/>                [4.1, 0.64],<br/>                [5,0.89]])<br/><br/>test = np.reshape(test1,newshape=(-1,5,2))<br/>y = model.predict(test)<br/>y = y.reshape(5,2)<br/>print(" THE MSE IS  : " ,sklearn.metrics.mean_squared_error(test1, y))<br/>print("The Recreated Output is : ",y)</span></pre><p id="4d68" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们检查MSE和我们的模型重新创建了什么。</p><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="0650" class="kc kd hi jy b fi ke kf l kg kh">THE MSE IS  :  0.09770384336959057<br/>The Recreated Output is :  [[1.1208125  0.33779058]<br/> [2.170816   0.5113479 ]<br/> [3.0839798  0.5797549 ]<br/> [3.819326   0.5880815 ]<br/> [4.376938   0.5675875 ]]</span></pre><h2 id="81ee" class="kc kd hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">在这里，模型能够以低误差重建输入</h2><h2 id="4899" class="kc kd hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">现在让我们用测试数据来检查一下，模型不是用这些数据来训练的。</h2><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="98b1" class="kc kd hi jy b fi ke kf l kg kh"><em class="jt">#Create a new test data close to what model has NOT seen and check the MSE</em><br/>test2 = np.array([[ 1, 0.74],<br/>                  [6, 0.60],<br/>                  [7, 0.96],<br/>                  [8, 0.42],<br/>                  [5,0.85]])<br/><br/>test = np.reshape(test2,newshape=(-1,5,2))<br/>y = model.predict(test)<br/>y = y.reshape(5,2)<br/>print(" THE MSE IS  : " ,sklearn.metrics.mean_squared_error(test2, y))<br/>print("The Recreated Output is : ",y)</span></pre><p id="b50b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们检查MSE和我们的模型重新创建了什么。</p><pre class="jf jg jh ji fd jx jy jz ka aw kb bi"><span id="2ca9" class="kc kd hi jy b fi ke kf l kg kh">THE MSE IS  :  2.5207483415118306<br/>The Recreated Output is :  [[1.6618627  0.4883529 ]<br/> [3.1379414  0.71685326]<br/> [4.2798247  0.7910608 ]<br/> [5.0690384  0.79329824]<br/> [5.580368   0.7696756 ]]</span></pre><h2 id="91d0" class="kc kd hi bd kj kk kl km kn ko kp kq kr iq ks kt ku iu kv kw kx iy ky kz la lb bi translated">在这里，模型无法重新创建输入，因为它没有在这些数据上进行训练，也无法提取其特征。</h2><p id="b03d" class="pw-post-body-paragraph if ig hi ih b ii lf ik il im lg io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">我们已经学会了如何制作二维LSTM自动编码器。我在以前的博客中列出了许多应用程序，例如:</p><ol class=""><li id="f86b" class="lk ll hi ih b ii ij im in iq lm iu ln iy lo jc lp lq lr ls bi translated">噪音的消除</li><li id="9078" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated">特征提取(仅使用编码器部分)</li><li id="d7c7" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated">异常检测</li></ol><p id="ccc6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Github库:<a class="ae jd" href="https://github.com/adnanmushtaq1996/2D-LSTM-AUTOENCODER" rel="noopener ugc nofollow" target="_blank">https://github.com/adnanmushtaq1996/2D-LSTM-AUTOENCODER</a></p><p id="d5be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望你喜欢阅读:)</p></div></div>    
</body>
</html>