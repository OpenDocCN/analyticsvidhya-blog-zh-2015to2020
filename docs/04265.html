<html>
<head>
<title>Detecting custom objects on video stream with Tensorflow and OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用Tensorflow和OpenCV检测视频流中的自定义对象</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/detecting-custom-objects-on-video-stream-with-tensorflow-and-opencv-34406bd0ec9?source=collection_archive---------6-----------------------#2020-03-12">https://medium.com/analytics-vidhya/detecting-custom-objects-on-video-stream-with-tensorflow-and-opencv-34406bd0ec9?source=collection_archive---------6-----------------------#2020-03-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/bd4d772588c5d329f43008b99d8bea49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*nExdZPWnJKohoF_uF1wqNg.png"/></div></figure><p id="ae3b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本系列的第一篇文章中，我在一台Windows 10机器上安装了Tensorflow Object Detection API，并对静态图像进行了测试。在<a class="ae jk" rel="noopener" href="/@daniel.schwalm/real-time-object-detection-with-tensorflow-object-detection-api-and-opencv-9c9430a18fdf">的下一篇文章</a>中，我向你展示了如何使用网络摄像头检测视频流中的基本对象。<br/>在这篇文章中，我将向你展示如何在视频流中检测你自己的自定义对象。</p><h1 id="6f99" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">先决条件</h1><p id="ed31" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">为了正确地遵循本教程，我建议阅读我以前的两篇文章，因为在本教程中，我将假设您已经设置了Tensorflow对象检测API，并使用网络摄像机视频流通过内置模型运行。</p><h1 id="e561" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">定义自定义对象</h1><p id="a2a2" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">任何预训练模型的限制，如我们在上一篇文章中使用的<em class="ko">SSD _ mobilenet _ v1 _ coco _ 2017 _ 11 _ 17</em>模型，都只能检测那些对其进行训练的图像类。<em class="ko">SSD _ mobilenet _ v1 _ coco _ 2017 _ 11 _ 17</em>模型在<strong class="io hj"> 80个不同的对象类</strong>上进行训练，包括火车、人或者不同种类的水果。如果你想检测别的东西，你必须创建你自己的模型，并在你自己的物体上训练它。幸运的是，我们不必从头开始创建我们的模型，我们可以使用Tensorflow轻松地进行迁移学习，我将很快向您展示如何操作。</p><p id="6774" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我的最终目标是为我的花园建造一个鸟类探测器。我花园里最常来的游客是喜鹊和斑鸠。它们是不同种类的鸟，但从物体探测的角度来看，它们有些相似。它们有头、翅膀和尾巴，区分它们不像比较橘子和火车。因此，在我的实验中，我想选择两个有些相似但能被人类区分的物体。我选择了卡通系列《粉红猪小妹》中我女儿最喜欢的两个角色——粉红猪小妹和乔治。我女儿两个玩具都有，所以我可以在客厅里玩。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es kp"><img src="../Images/7a3db2ec97892b7bd87395136f91d788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Bgf89yRp9EpgzHgGuCH7A.jpeg"/></div></div></figure><h1 id="6e12" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">拍摄图像</h1><p id="6124" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">创建我们自己的模型的第一步是以不同对象的图像的形式获得训练数据。我在公寓的不同地点拍了大约30张乔治和30张粉红猪小妹的照片。我还拍了大约30张照片，在同一张照片中可以看到他们两个。</p><blockquote class="ky kz la"><p id="02fa" class="im in ko io b ip iq ir is it iu iv iw lb iy iz ja lc jc jd je ld jg jh ji jj hb bi translated">小贴士#1 :你拍的照片越多越好，但是一开始你不应该在这上面花太多时间。总共大约100幅图像对于第一轮训练应该足够了。确保你在不同的地点拍照，你的物体应该从不同的角度拍摄，有不同的背景。</p></blockquote><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es le"><img src="../Images/aa0bdfa28b4b16d5675ef0dd2715f7db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qo5QFuarNeGRBysLq5uEyA.png"/></div></div></figure><p id="5071" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">拍摄图像后，将它们分成训练图像和测试图像。创建一个<em class="ko">训练</em>和一个<em class="ko">测试</em>文件夹，将80%的图像放入<em class="ko">训练</em>文件夹，同时将20%的图像放入<em class="ko">测试</em>文件夹。请确保将图像分为训练集和测试集，以便根据图像在整个图像集中的分布正确地表示图像。</p><h1 id="63da" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">标记图像</h1><p id="0e61" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">为了训练模型，我们必须在每张图像上标记出我们的对象的位置。我用了一个叫做<a class="ae jk" href="https://tzutalin.github.io/labelImg/" rel="noopener ugc nofollow" target="_blank"> LabelImg </a>的工具来给图片加标签。下载最新版本，并通过在对象周围创建边界框来开始标记。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es lf"><img src="../Images/05d501b6e4158fa860da6bb52d0de241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g_UnAorRrwxtmiNqTgbJUA.png"/></div></div></figure><h1 id="3cf3" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">准备培训数据</h1><p id="4cd0" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">给你的图片贴上标签后，你会有一个各自的。每个图像的xml文件。<br/>这个。xml格式不适合直接在Tensorflow中训练我们的模型，我们必须将。xml文件转换成。csv格式，然后将。csv文件转换为TFRecords。<br/>我创建了一个小脚本来完成以上所有工作，你可以在我的<a class="ae jk" href="https://github.com/dschwalm/deeplearning/blob/master/tensorflow/object_detection/scripts/configure_training.py" rel="noopener ugc nofollow" target="_blank"> github资源库</a>中找到它。<br/>你可以这样称呼它:</p><pre class="kq kr ks kt fd lg lh li lj aw lk bi"><span id="77c6" class="ll jm hi lh b fi lm ln l lo lp">python configure_training.py -imageRoot e:/python/labelimg/peppazsoli -labelMap "peppa:1,george:2" -labelMapOutputFile e:/python/tensorflow/models/research/object_detection/training\labelmap.pbtxt</span></pre><p id="c6c3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">它将:</p><ul class=""><li id="0c6f" class="lq lr hi io b ip iq it iu ix ls jb lt jf lu jj lv lw lx ly bi translated">转换。xml文件转换成。csv文件</li><li id="709f" class="lq lr hi io b ip lz it ma ix mb jb mc jf md jj lv lw lx ly bi translated">转换。csv文件转换为TFRecords</li><li id="3647" class="lq lr hi io b ip lz it ma ix mb jb mc jf md jj lv lw lx ly bi translated">为训练生成标签映射文件</li></ul><h1 id="8bea" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">配置我们的预训练模型</h1><p id="ff13" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">这次我们将使用与<a class="ae jk" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank"> Tensorflow模型zoo </a>不同的模型，即<em class="ko">faster _ rcnn _ inception _ v2 _ coco _ 2018 _ 01 _ 28</em>模型。<br/>下载并提取<em class="ko"> object_detection </em>文件夹中的模型。</p><p id="0cab" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在物体检测文件夹中创建一个<em class="ko">训练</em>文件夹。在这里，我们将收集培训所需的所有文件。<br/>从<em class="ko"> sample </em>文件夹复制<em class="ko">faster _ rcnn _ inception _ v2 _ pets . config</em>文件到<em class="ko"> training </em>文件夹。打开文件，提供类的数量为2，如下所示。还要根据您的路径修改需要文件路径的行:</p><pre class="kq kr ks kt fd lg lh li lj aw lk bi"><span id="65b6" class="ll jm hi lh b fi lm ln l lo lp">…<br/>num_classes: 2<br/>…<br/>fine_tune_checkpoint: "e:/python/tensorflow/models/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt"<br/>…<br/>train_input_reader: {<br/>  tf_record_input_reader {<br/>    input_path: "e:/python/labelimg/peppazsoli/train.record"<br/>  }<br/>  label_map_path: "e:/python/tensorflow/models/research/object_detection/training/labelmap.pbtxt"<br/>}<br/>…<br/>eval_input_reader: {<br/>  tf_record_input_reader {<br/>    input_path: "e:/python/labelimg/peppazsoli/test.record"<br/>  }<br/>  label_map_path: "e:/python/tensorflow/models/research/object_detection/training/labelmap.pbtxt"<br/>  shuffle: false<br/>  num_readers: 1<br/>}</span></pre><h1 id="207f" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">进行培训</h1><p id="2b3b" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">最后，我们可以开始训练我们的模型。<br/>将<em class="ko">object _ detection/legacy/train . py</em>复制到<em class="ko"> object_detection </em>文件夹本身，并在该文件夹中用下面的命令调用它:</p><pre class="kq kr ks kt fd lg lh li lj aw lk bi"><span id="81bd" class="ll jm hi lh b fi lm ln l lo lp">python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config</span></pre><p id="43cd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">培训应该开始，根据您系统的性能，可能需要一段时间，直到损失达到可接受的水平。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es me"><img src="../Images/6f598755a4432ec1fef8b04a765fd74f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*plCGw9lq3ZOV8OT0VUAdTg.png"/></div></div></figure><p id="24a1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">您可以通过打开一个新的命令提示符并在<em class="ko"> object_detection </em>文件夹<em class="ko">中发出以下命令来使用TensorBoard跟踪丢失</em></p><pre class="kq kr ks kt fd lg lh li lj aw lk bi"><span id="7f86" class="ll jm hi lh b fi lm ln l lo lp">tensorboard --logdir=training</span></pre><p id="c85f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，TensorBoard应该可以从您的浏览器访问到<a class="ae jk" href="http://localhost:6006/" rel="noopener ugc nofollow" target="_blank"> http://localhost:6006/ </a>。</p><p id="1e4b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">您也可以在图表上看到损失在减少:</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mf"><img src="../Images/b7c0fd77641157e8d1715132c0204315.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ZhjEjGq3qMxMK-02VD5bg.png"/></div></div></figure><blockquote class="ky kz la"><p id="c2a2" class="im in ko io b ip iq ir is it iu iv iw lb iy iz ja lc jc jd je ld jg jh ji jj hb bi translated"><strong class="io hj">提示#2 </strong>:我执行我的模型，直到损失达到0.01左右，这在我的GPU上花了大约1.5个小时。一般来说，你应该运行模型，直到损失明显减少。</p></blockquote><p id="8210" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">按Ctrl + C按钮停止训练。</p><h1 id="b040" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">执行对象检测</h1><p id="7d6d" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">作为培训的结果，在您的<em class="ko">培训</em>文件夹中创建了几个文件。搜索<em class="ko"> model.ckpt-xxxx </em>文件的最高索引，并记下最高编号。我的情况是6246。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/44efb77b3652638c0f351f7c52c8704c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*1B5WHydhVBAKjc7sFby-sA.png"/></div></figure><p id="2bd5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了运行模型，我们需要导出训练期间生成的推理图。您可以通过调用<em class="ko"> object_detection </em>文件夹中的以下命令来实现:</p><pre class="kq kr ks kt fd lg lh li lj aw lk bi"><span id="25ad" class="ll jm hi lh b fi lm ln l lo lp">python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_pets.config --trained_checkpoint_prefix training/model.ckpt-6246 --output_directory inference_graph</span></pre><p id="e40b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，推理图将被导出到名为<em class="ko">freezed _ inference _ graph . Pb</em>的文件中的<em class="ko">推理图</em>文件夹中。我们将使用这个文件来运行我们在github资源库中找到的<a class="ae jk" href="https://github.com/dschwalm/deeplearning/blob/master/tensorflow/object_detection/webcam_detection_custom.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>中的模型。</p><figure class="kq kr ks kt fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h1 id="8deb" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">估价</h1><p id="08f5" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">根据上面的视频，你可以看到这个模型远非完美。主要问题是:</p><ul class=""><li id="0ff9" class="lq lr hi io b ip iq it iu ix ls jb lt jf lu jj lv lw lx ly bi translated">该模型经常混淆Peppa和乔治。这很自然，因为它们非常相似，尤其是从某些角度来看。为了解决这个问题，我们需要这两个人更多的训练图像。</li><li id="49cf" class="lq lr hi io b ip lz it ma ix mb jb mc jf md jj lv lw lx ly bi translated">该模型将其他对象分类为Peppa或George，例如人、灯泡或狗。我认为，除了训练图像数量少之外，主要原因是这些图像的背景不够多样。为了解决这个问题，我们需要更多的训练图像来判断混淆的物体是否也存在。</li></ul><p id="b1ff" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">感谢您关注这一系列。作为下一步，我将尝试使用IP摄像头来探测物体。</p></div></div>    
</body>
</html>