<html>
<head>
<title>How to increase accuracy of CNN models in 2020 ?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在2020年提高CNN模型的准确性？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-increase-accuracy-of-cnn-models-d1b96edfe64e?source=collection_archive---------3-----------------------#2020-08-01">https://medium.com/analytics-vidhya/how-to-increase-accuracy-of-cnn-models-d1b96edfe64e?source=collection_archive---------3-----------------------#2020-08-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4dd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将分享一些技巧和诀窍，通过它们我们可以提高深度学习中CNN模型的准确性。</p><p id="3cf5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以通过以下方法做到这一点</p><ol class=""><li id="1da0" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">使用预训练模型</strong> →首先，我们必须使用预训练模型权重，因为它们在识别大量图像时是通用的。因此，学习到的它们的权重将有助于对我们将在数据集中分类的少数几个类进行分类。为此，我们只需要<strong class="ih hj">改变我们将使用的预训练模型的最终层</strong>，并冻结除最终层之外的所有层的权重。</li></ol><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jm"><img src="../Images/5e446b97c009dece978cbf82a48b99a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z5yNzuqFyrNRZF2SKylovA.png"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">显示预训练模型的<strong class="bd kc">精度与模型中使用的<strong class="bd kc">参数数量</strong>的图表</strong></figcaption></figure><p id="2d62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，从上图中我们可以看到，与其他模型相比，EfficientNet模型表现最佳，因为与其他模型相比，EfficientNet的参数数量较少。我们可以在<strong class="ih hj"> pytorch </strong>中使用高效网络作为→</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="1b10" class="ki kj hi ke b fi kk kl l km kn">!pip install efficientnet_pytorch</span></pre><p id="749f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="ae0f" class="ki kj hi ke b fi kk kl l km kn">from efficientnet_pytorch import EfficientNet<br/>model = EfficientNet.from_pretrained('efficientnet-b0')</span></pre><p id="f9c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，根据我们的要求对最后一层进行修改。</p><p id="c4b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">使用数据扩充方法进行推广</strong> →我们可以在内核中使用以下数据扩充方法来提高模型的准确性。</p><h2 id="d7e1" class="ki kj hi bd kc ko kp kq kr ks kt ku kv iq kw kx ky iu kz la lb iy lc ld le lf bi translated"># <strong class="ak">混淆</strong> →</h2><p id="53a3" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">在MixUp中，我们在将两个原始图像输入到我们的模型(可能在同一个类中，也可能不在同一个类中)之前混合它们，并对它们进行线性组合:根据张量。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ll"><img src="../Images/8e8ea7cb5c87abcd70cda4415762f48a.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/0*KaJMXcYSwYO9VuRx.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">混乱的图示</figcaption></figure><p id="0ebf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了在pytorch中实现混合，我们可以使用:</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="e0d3" class="ki kj hi ke b fi kk kl l km kn">!pip install torchtoolbox<br/>from torchtoolbox.tools import mixup_data, mixup_criterion</span></pre><p id="aa20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后在<strong class="ih hj"> train </strong>类中我们可以添加这行代码</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="1915" class="ki kj hi ke b fi kk kl l km kn">alpha = 0.2<br/>for i, (inputs, labels) in enumerate(train_data):<br/>    if <!-- -->torch.cuda.is_available():<br/>        <!-- -->inputs= inputs.cuda()<br/>        labels = labels.cuda()<br/><br/>    inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha)<br/>    optimizer.zero_grad()<br/>    outputs = model(data)<br/>    loss = mixup_criterion(<strong class="ke hj">Loss</strong>, outputs, labels_a, labels_b, lam)<br/><br/>    loss.backward()<br/>    optimizer.update()</span></pre><p id="d114" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中，<code class="du lm ln lo ke b"><strong class="ih hj">Loss = torch.nn.CrossEntroyLoss()</strong></code></p><h2 id="21e7" class="ki kj hi bd kc ko kp kq kr ks kt ku kv iq kw kx ky iu kz la lb iy lc ld le lf bi translated"># <strong class="ak">断流器</strong> →</h2><p id="50bf" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">在裁剪中，我们从训练数据中的各种图像类别中移除随机正方形块。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lp"><img src="../Images/a740445cc6f92bebfb2fc656ceb79458.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*BX6vWN9eEOkMLYdsproBNQ.png"/></div></figure><p id="0a4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了在pytorch中实现CutOut，我们可以使用:</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="26a5" class="ki kj hi ke b fi kk kl l km kn">!pip install torchtoolbox<br/>from torchtoolbox.transform import Cutout<br/>import <!-- -->albumentations</span></pre><p id="4f78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在图像变换中，我们可以用它来→</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="aa87" class="ki kj hi ke b fi kk kl l km kn">transforms = albumentations.Compose([<br/> albumentations.Resize(img_height , img_width, always_apply = True) ,<strong class="ke hj">Cutout()</strong>,<br/> albumentations.Normalize(mean , std , always_apply = True),<br/> albumentations.ShiftScaleRotate(shift_limit = 0.0625,<br/> scale_limit = 0.1 ,<br/> rotate_limit = 5,<br/> p = 0.9)</span></pre><h2 id="c58e" class="ki kj hi bd kc ko kp kq kr ks kt ku kv iq kw kx ky iu kz la lb iy lc ld le lf bi translated"># <strong class="ak"> CutMix </strong> →</h2><p id="fff1" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">在剪切混合中，我们从一个类中取出一片图像，粘贴到另一个类的图像上。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lq"><img src="../Images/f5bcf3a336e4f5b533618976fda63755.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*1_rcINOjjPTpVTxY-tGKSQ.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">芒果图像上的苹果剪辑图像实例</figcaption></figure><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="c064" class="ki kj hi ke b fi kk kl l km kn"># in Pytorch<br/>$ pip install git+https://github.com/ildoonet/cutmix</span></pre><p id="63e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，对于训练图像数据集类的对象，我们必须在pytorch数据加载器中加载数据集之前执行此操作</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="bb25" class="ki kj hi ke b fi kk kl l km kn">cutMix_train_dataset = CutMix(train_dataset, num_class=100, beta=1.0, prob=0.5, num_mix=2)</span></pre><p id="0d89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用的损失是</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="d05c" class="ki kj hi ke b fi kk kl l km kn">Loss = CutMixCrossEntropyLoss(True)</span></pre><h2 id="b9f2" class="ki kj hi bd kc ko kp kq kr ks kt ku kv iq kw kx ky iu kz la lb iy lc ld le lf bi translated">#F <strong class="ak">混合</strong> →</h2><p id="c14e" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">FMix是Mix、CutMix等的变体。Fmix采用从傅立叶空间采样的掩码来混合训练样本。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es lr"><img src="../Images/32aad93f5db26da03653e18c9f0b5058.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WGFH9zLbloLX0ZmVREMcng.jpeg"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">fmix示例</figcaption></figure><p id="5367" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在pytorch中，我们可以像这样实现fmix</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="214b" class="ki kj hi ke b fi kk kl l km kn">from os.path import exists</span><span id="1088" class="ki kj hi ke b fi ls kl l km kn">if not exists(‘fmix.zip’):</span><span id="eb00" class="ki kj hi ke b fi ls kl l km kn"> !wget -O fmix.zip <a class="ae lt" href="https://github.com/ecs-vlc/fmix/archive/master.zip" rel="noopener ugc nofollow" target="_blank">https://github.com/ecs-vlc/fmix/archive/master.zip</a><br/> !unzip -qq fmix.zip<br/> !mv FMix-master/* ./<br/> !rm -r FMix-master</span></pre><p id="6f1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，<strong class="ih hj">用pytorch dataloaders </strong>创建一批数据，并在上述gitHub repo的fmix.py文件中应用<code class="du lm ln lo ke b">sample_and_apply</code>函数。此外，在训练这些新图像和新标签时，我们使用损失函数作为:</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="badc" class="ki kj hi ke b fi kk kl l km kn">alpha, decay_power = 1.0, 3.0<br/><br/>for epoch in range(epochs):<br/>    for batch, labels in training_dataloader:<br/>        batch, perm, lambda = sample_and_apply(batch, alpha,       decay_power, (img_height, img_width))<br/>        out = my_model(batch)<br/>        loss = torch.nn.CrossEntroyLoss(out, labels) * lambda + torch.nn.CrossEntroyLoss(out, target[perm]) * (1 - lambda)</span></pre><p id="f7ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">仅在<strong class="ih hj">训练阶段</strong>。</p><p id="f207" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3 </strong>。<strong class="ih hj">使用随机加权平均</strong> →这是一个简单的过程，在没有额外成本的情况下，在深度学习中提高了随机梯度下降(SGD)的泛化能力，可以作为<strong class="ih hj"> PyTorch </strong>中任何其他优化器的替代。<strong class="ih hj"> SWA </strong>使用修改的学习率计划对SGD遍历的权重进行平均。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es lu"><img src="../Images/d00d51686c309847e745e31e4b4089e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HSiMJG5K0BtcqpOZ.png"/></div></div></figure><p id="2e25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在pytorch中，我们可以像这样实现<strong class="ih hj"> SWA </strong></p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="dcb0" class="ki kj hi ke b fi kk kl l km kn">!pip install torchcontrib</span></pre><p id="d312" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后导入它</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="f07b" class="ki kj hi ke b fi kk kl l km kn">from torchcontrib.optim import SWA</span></pre><p id="f529" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我们可以像这样用SWA包装我们的优化器</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="dbce" class="ki kj hi ke b fi kk kl l km kn"><strong class="ke hj">our_optimizer</strong> = torch.optim.Adam(model.parameters(), lr=1e-4)<br/>optimizer = SWA(<strong class="ke hj">our_optimizer</strong>, swa_start=5, swa_freq=5, swa_lr=0.05)</span></pre><p id="aee2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，在训练循环的最后加上这个。</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="8544" class="ki kj hi ke b fi kk kl l km kn">optimizer.swap_swa_sgd()</span></pre><p id="24e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将我们模型的权重设置为它们的<strong class="ih hj"> SWA </strong>平均值。</p><p id="0a35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.<strong class="ih hj">使用早期停止</strong> →这是一种正则化形式，用于避免在训练数据集上过度拟合。提前停止会跟踪验证损失，如果损失连续几个时期停止下降，则训练也会停止。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lv"><img src="../Images/654872039b8eaa753da66a7a79e4bd04.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/0*6QOWTwt-dZH78qkU.png"/></div></figure><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="bf79" class="ki kj hi ke b fi kk kl l km kn">!pip install pytorchtools   #first install pytorchtools</span></pre><p id="8004" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，导入<strong class="ih hj">提前停止</strong></p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="c34d" class="ki kj hi ke b fi kk kl l km kn">from pytorchtools import EarlyStopping</span></pre><p id="1af6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">之后，在训练和验证循环开始之前初始化early_stopping对象，如下所示</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="2de6" class="ki kj hi ke b fi kk kl l km kn"><strong class="ke hj">early_stopping</strong> = EarlyStopping(patience=patience, verbose=<strong class="ke hj">True</strong>)<br/>    <br/>for epoch in range(n_epochs):<br/>  ..............</span></pre><p id="3a4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，在得到训练和验证损失后，借助<code class="du lm ln lo ke b"><strong class="ih hj">early_stopping</strong></code> <strong class="ih hj"> </strong>对象将早停检查点放在那里。</p><pre class="jn jo jp jq fd kd ke kf kg aw kh bi"><span id="d072" class="ki kj hi ke b fi kk kl l km kn"><em class="lw"># early_stopping needs the validation loss to check if it has decresed and if it has, it will make a checkpoint of the current model</em></span><span id="62f4" class="ki kj hi ke b fi ls kl l km kn">early_stopping(valid_loss, model)<br/>if early_stopping.early_stop:<br/>   print("Early stopping")<br/>   break</span></pre><p id="2390" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是我们在分类问题中可以使用的一些技巧和窍门。如果你有任何问题、意见或担忧，请在评论中告诉我。感谢阅读，并在此之前享受学习。</p><h2 id="43bb" class="ki kj hi bd kc ko kp kq kr ks kt ku kv iq kw kx ky iu kz la lb iy lc ld le lf bi translated">GitHub回购信用:→</h2><p id="68f3" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated"><strong class="ih hj">预训练模型→</strong>https://github.com/Cadene/pretrained-models.pytorch T21</p><p id="c9bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">效率网模型→</strong>T25】https://github.com/lukemelas/EfficientNet-PyTorch</p><p id="8ecd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">混淆、断流</strong>→<a class="ae lt" href="https://github.com/PistonY/torch-toolbox" rel="noopener ugc nofollow" target="_blank">https://github.com/PistonY/torch-toolbox</a></p><p id="ac66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">剪切混合</strong>→<a class="ae lt" href="https://github.com/ildoonet/cutmix" rel="noopener ugc nofollow" target="_blank">https://github.com/ildoonet/cutmix</a></p><p id="e3a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">Fmix</strong>→<a class="ae lt" href="https://github.com/ecs-vlc/FMix" rel="noopener ugc nofollow" target="_blank">https://github.com/ecs-vlc/FMix</a></p><p id="72e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">随机加权平均</strong>→<a class="ae lt" href="https://github.com/pytorch/contrib" rel="noopener ugc nofollow" target="_blank">https://github.com/pytorch/contrib</a></p><p id="28f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">提前停车</strong>→【https://github.com/Bjarten/early-stopping-pytorch T2】</p></div></div>    
</body>
</html>