<html>
<head>
<title>Building a Text Classifier with Spacy 3.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Spacy 3.0 构建文本分类器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-text-classifier-with-spacy-3-0-dd16e9979a?source=collection_archive---------1-----------------------#2020-11-15">https://medium.com/analytics-vidhya/building-a-text-classifier-with-spacy-3-0-dd16e9979a?source=collection_archive---------1-----------------------#2020-11-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0cf3237de1c2264f3c5e830fb7d77194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTV0nki9dn47P6L93UKIcQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">马库斯·温克勒在<a class="ae iu" href="https://unsplash.com/s/photos/review?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="d290" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://explosion.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="jt">爆款 AI </em> </a>刚刚为他们的自然语言处理工具包<a class="ae iu" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> <em class="jt"> SpaCy </em> </a>发布了全新的夜间版本。多年来，我一直是这个包的忠实粉丝，因为它允许快速开发，并且易于用来创建可以处理自然书写文本的应用程序。</p><p id="5c90" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">过去有太多优秀的文章展示了 SpaCy 的 2.0+版本的 API。他们的 API 最近的变化也影响了大多数教程，现在新发布的<a class="ae iu" href="https://nightly.spacy.io/" rel="noopener ugc nofollow" target="_blank"> Spacy V3 </a>打破了这些教程。我喜欢这些变化，并想展示用很少几行代码训练一个文本分类器是多么简单。</p><p id="def3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第一步，我们需要安装一些软件包:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="a357" class="kd ke hi jz b fi kf kg l kh ki">pip install spacy-nightly<br/>pip install ml-datasets<br/>python -m spacy download en_core_web_md</span></pre><p id="a657" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://github.com/explosion/ml-datasets" rel="noopener ugc nofollow" target="_blank"> <em class="jt"> Ml-Datasets </em> </a>是一个来自<em class="jt"> Explosion AI </em>的数据集管理库，它也提供了一种简单的方法来加载数据。我们将使用这个库获取数据来训练我们的分类器。</p><div class="kj kk ez fb kl km"><a href="https://github.com/explosion/ml-datasets" rel="noopener  ugc nofollow" target="_blank"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hj fi z dy kr ea eb ks ed ef hh bi translated">爆炸/ml-数据集</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">用于测试和示例脚本的各种机器学习数据集的加载器。thinc.extra.datasets 前情提要</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">github.com</p></div></div><div class="kv l"><div class="kw l kx ky kz kv la io km"/></div></div></a></div><h1 id="3198" class="lb ke hi bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">让我们建立一个分类器</h1><p id="826e" class="pw-post-body-paragraph iv iw hi ix b iy ly ja jb jc lz je jf jg ma ji jj jk mb jm jn jo mc jq jr js hb bi translated">完整代码也可以在 GitHub 资源库中找到:</p><div class="kj kk ez fb kl km"><a href="https://github.com/p-sodmann/Spacy3Textcat" rel="noopener  ugc nofollow" target="_blank"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hj fi z dy kr ea eb ks ed ef hh bi translated">p-sodmann/Spacy3Textcat</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">SpacyV3 文本分类器教程 GitHub 是超过 5000 万开发者的家园，他们一起工作来托管和审查…</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">github.com</p></div></div><div class="kv l"><div class="md l kx ky kz kv la io km"/></div></div></a></div><p id="ccd5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们需要首先设置好一切:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="aeb0" class="kd ke hi jz b fi kf kg l kh ki">import spacy</span><span id="1095" class="kd ke hi jz b fi me kg l kh ki"># tqdm is a great progress bar for python<br/># tqdm.auto automatically selects a text based progress <br/># for the console <br/># and html based output in jupyter notebooks<br/>from tqdm.auto import tqdm</span><span id="097c" class="kd ke hi jz b fi me kg l kh ki"># DocBin is spacys new way to store Docs in a <br/># binary format for training later<br/>from spacy.tokens import DocBin</span><span id="bdf0" class="kd ke hi jz b fi me kg l kh ki"># We want to classify movie reviews as positive or negative<br/># <a class="ae iu" href="http://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener ugc nofollow" target="_blank">http://ai.stanford.edu/~amaas/data/sentiment/</a><br/>from ml_datasets import imdb</span><span id="1fe7" class="kd ke hi jz b fi me kg l kh ki"># load movie reviews as a tuple (text, label)<br/>train_data, valid_data = imdb()</span><span id="c43a" class="kd ke hi jz b fi me kg l kh ki"># load a medium sized english language model in spacy<br/>nlp = spacy.load(“en_core_web_md”)</span></pre><p id="351e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们需要将文本和标签转换成整洁的空间文档对象。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="1700" class="kd ke hi jz b fi kf kg l kh ki">def make_docs(data):<br/>    """<br/>    this will take a list of texts and labels <br/>    and transform them in spacy documents<br/>    <br/>    data: list(tuple(text, label))<br/>    <br/>    returns: List(spacy.Doc.doc)<br/>    """<br/>    <br/>    docs = []<br/>    # nlp.pipe([texts]) is way faster than running <br/>    # nlp(text) for each text<br/>    # as_tuples allows us to pass in a tuple, <br/>    # the first one is treated as text<br/>    # the second one will get returned as it is.<br/>    <br/>    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):<br/>        <br/>        # we need to set the (text)cat(egory) for each document<br/>        doc.cats["positive"] = label<br/>        <br/>        # put them into a nice list<br/>        docs.append(doc)<br/>    <br/>    return docs</span></pre><p id="b8be" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们只需要转换我们的数据，并将其作为二进制文件存储在光盘上。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="bab5" class="kd ke hi jz b fi kf kg l kh ki"># we are so far only interested in the first 5000 reviews<br/># this will keep the training time short.<br/># In practice take as much data as you can get.<br/># you can always reduce it to make the script even faster.<br/>num_texts = 5000</span><span id="ce39" class="kd ke hi jz b fi me kg l kh ki"># first we need to transform all the training data<br/>train_docs = make_docs(train_data[:num_texts])<br/># then we save it in a binary file to disc<br/>doc_bin = DocBin(docs=train_docs)<br/>doc_bin.to_disk("./data/train.spacy")</span><span id="a7c6" class="kd ke hi jz b fi me kg l kh ki"># repeat for validation data<br/>valid_docs = make_docs(valid_data[:num_texts])<br/>doc_bin = DocBin(docs=valid_docs)<br/>doc_bin.to_disk("./data/valid.spacy")</span></pre><p id="4b62" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们需要创建一个配置文件，告诉 SpaCy 应该从我们的数据中学到什么。<br/> <em class="jt">爆炸 AI </em>创建了一个快速制作基础配置文件的工具:<a class="ae iu" href="https://nightly.spacy.io/usage/training#quickstart" rel="noopener ugc nofollow" target="_blank">https://nightly.spacy.io/usage/training</a></p><p id="6caf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我们的例子中，我们将在 components 下选择“Textcat”，在硬件中选择 CPU 优先，以及“Optimize-for”:效率。通常<em class="jt"> SpaCy </em>会为每个参数提供相同的默认值。对于您的问题来说，它们不是最佳参数，但对于大多数数据来说，它们会工作得很好。<br/>我们需要改变训练和验证数据的路径:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="22a1" class="kd ke hi jz b fi kf kg l kh ki">[paths]<br/>train = "data/train.spacy"<br/>dev = "data/valid.spacy"</span></pre><p id="fbed" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一步，我们需要将基本配置转变为完整配置。Spacy 将自动使用默认参数填充所有缺失值:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="7dd8" class="kd ke hi jz b fi kf kg l kh ki">python -m spacy init fill-config ./base_config.cfg ./config.cfg</span></pre><p id="cd62" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，我们可以在 CLI 中启动培训:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="e8ae" class="kd ke hi jz b fi kf kg l kh ki">python -m spacy train config.cfg --output ./output</span></pre><p id="a564" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于每个训练步骤，它将产生一个输出及其损失和准确性。损失告诉我们分类器的错误有多大，分数告诉我们二元分类正确的频率。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="c913" class="kd ke hi jz b fi kf kg l kh ki">E #    LOSS TOK2VEC LOSS TEXTCAT CATS_SCORE SCORE<br/>— — — — — — — — — — — — — — — — — — — — — — — — — <br/>0 0    0.00         0.25         48.82      0.49<br/>2 5600 0.00         1.91         92.54      0.93</span></pre><h1 id="7871" class="lb ke hi bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">根据我们自己的输入运行分类器</h1><p id="2f68" class="pw-post-body-paragraph iv iw hi ix b iy ly ja jb jc lz je jf jg ma ji jj jk mb jm jn jo mc jq jr js hb bi translated">训练好的模型保存在“输出”文件夹中。脚本完成后，我们可以加载“输出/模型-最佳”模型，并检查新输入的预测:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="6697" class="kd ke hi jz b fi kf kg l kh ki">import spacy</span><span id="71b9" class="kd ke hi jz b fi me kg l kh ki"># load thebest model from training<br/>nlp = spacy.load("output/model-best")</span><span id="7671" class="kd ke hi jz b fi me kg l kh ki">text = ""<br/>print("type : ‘quit’ to exit")</span><span id="c2b3" class="kd ke hi jz b fi me kg l kh ki"># predict the sentiment until someone writes quit<br/>while text != "quit":<br/>    text = input("Please enter example input: ")<br/>    doc = nlp(text)<br/>    if doc.cats['positive'] &gt;.5:<br/>        print(f"the sentiment is positive")<br/>    else:<br/>        print(f"the sentiment is negative")</span></pre><h1 id="9f4b" class="lb ke hi bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">进一步的改进</h1><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/04ed49e710b366475c5b08db87adde6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DjtkfzPSTfr9eesbxVWY2g.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@centelm?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">克莱门特·法利泽</a>在<a class="ae iu" href="https://unsplash.com/s/photos/further?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="957b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们没有为这个文本分类器使用任何预先训练的向量，我们可能不会得到评论“有多好”的可表示分数。我们将得到一个二元答案:文本输入的情绪是否大于 0.5，它被认为是积极的。</p><p id="5c60" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们输入的文本与我们训练分类器所依据的数据不同，输出可能没有意义:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="b764" class="kd ke hi jz b fi kf kg l kh ki">Please enter example input: i hate mondays<br/>the sentiment is positive</span></pre><h2 id="61a8" class="kd ke hi bd lc mg mh mi lg mj mk ml lk jg mm mn lo jk mo mp ls jo mq mr lw ms bi translated">改进分类器的步骤如下:</h2><p id="ed77" class="pw-post-body-paragraph iv iw hi ix b iy ly ja jb jc lz je jf jg ma ji jj jk mb jm jn jo mc jq jr js hb bi translated"><strong class="ix hj"> 1。在更多的数据上训练:</strong> <br/>我们只用了 5000 个文本，这只是整个语料库的五分之一。我们可以很容易地改变我们的脚本，以获得更多的例子。我们甚至可以尝试从不同的资源获取数据，或者自己给网站打分。</p><p id="3923" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 2。训练更多的步骤:</strong> <br/>目前，我们的脚本要么在 1600 个训练步骤后停止，而没有在验证数据上找到更好的“解决方案”，要么在总共 20000 个步骤后停止。在我们的情况下，一个步骤是向前传递，进行预测，向后传递，校正神经网络，因此预测和标签之间的误差(损失)变得更小。我们可以增加值[耐心、最大步数和最大次数]，看看优化器是否能在稍后的训练中为我们的网络找到更好的权重。</p><p id="3e3a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 2。使用预先训练的单词向量。</strong> <br/>默认情况下，SpaCy 中的训练使用的是 Tok2Vec 层。它使用单词的长度等特征来动态生成向量。优点是它可以处理以前看不见的单词，并用数字表示出来。缺点是它的嵌入不代表它的意义。<br/>预先训练的单词向量是从大量文本中导出的每个单词的数字表示，并试图将单词的意思嵌入到高维空间中。这有助于将语义相似的单词组合在一起。</p><p id="6514" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 3。使用变压器模型。</strong><br/>Transformer 是一种“较新”的架构，它将单词的上下文包含到它的嵌入中。SpaCy V3 现在支持像<a class="ae iu" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> <em class="jt"> Bert </em> </a> <em class="jt"> </em>这样的模型，这有助于进一步提升性能。</p><p id="5d3f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 4。检测输入中的异常值。我们在电影评论上训练我们的网络。这并不意味着模型可以告诉你一个烹饪食谱是好是坏。我们可能希望检查是否应该对输入数据进行预测，或者返回数据与定型相差太大而无法进行有意义的预测。Vincent D. Warmerdam 就此事做了一些很棒的演讲，比如“<a class="ae iu" href="https://www.youtube.com/watch?v=Z8MEFI7ZJlA&amp;ab_channel=PyData" rel="noopener ugc nofollow" target="_blank">如何约束人为的愚蠢</a>”。</strong></p><p id="c2dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我也期待着即将到来的 Ines 和 Sofie 的视频，这将为 SpaCy V3 的使用带来更多的见解。</p><figure class="ju jv jw jx fd ij"><div class="bz dy l di"><div class="mt mu l"/></div></figure></div></div>    
</body>
</html>