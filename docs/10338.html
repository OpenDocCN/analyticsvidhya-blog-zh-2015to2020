<html>
<head>
<title>ML06: Intro to Multi-class Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML06:多类分类介绍</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ml06-intro-to-multi-class-classification-e61eb7492ffd?source=collection_archive---------18-----------------------#2020-10-14">https://medium.com/analytics-vidhya/ml06-intro-to-multi-class-classification-e61eb7492ffd?source=collection_archive---------18-----------------------#2020-10-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9f5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是机器学习系列背后的<a class="ae jd" href="https://malhotravaibhav.medium.com/maths-behind-machine-learning-15e8ad8267c" rel="noopener">数学的延续。</a></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/35e3b4e9507319b6c744a8b3b79dd605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-GB7wyRyuFfpSZ_4y4DnNA.png"/></div></div></figure><p id="38ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上一篇文章中，我们看到了最大间隔原则是如何优雅地解决二元分类任务的。</p><blockquote class="jq jr js"><p id="854e" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">B <!-- -->但是对于多类来说，最大利润的概念更难表述。所以问题是，我们怎样才能把2类公式重新用于k类。</p></blockquote><p id="11cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> One-vs-Rest (OvR): </strong>对于每一个类k，训练一个SVM，该是分类k (one)对非k(Rest)的专家，这意味着我们必须为每一个类k创建一个二元分类器，该分类器是将该类(k)从所有其他类中分离出来的专家。</p><p id="0ad2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">一对一(OvO): </strong>对于每一对类(k，k’)，训练一个擅长对k与k’进行分类的SVM。</p><p id="e30b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">无论是哪种情况，都可以通过组合单个二元预测来进行多类预测。</p><h1 id="7947" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">一对多</h1><p id="6867" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">让我们以一个3类分类器为例，对于OvR，我们需要3个SVM，每个SVM都是将一个类从另两个类中分离出来的专家。让我们看一个直观的例子如下:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es la"><img src="../Images/c5ccc642c37634e5aeb1888e78506469.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYJTPZSbe2IAGQzSV0zDhw.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">线性核的OvR SVM</figcaption></figure><p id="0af1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以有3个支持向量机，一个用于蓝色，一个用于橙色，一个用于绿色。每个SVM都接受二进制数据的训练，这意味着它的任务是将自己的类与所有其他类分开。下面的热图显示了单个SVM的热图。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lf"><img src="../Images/73ac0c49df269ff9a7029cd8cc5b7f2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q2qI6Xg3RnFkISGkeN4nHA.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">培训OvR热图</figcaption></figure></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><h1 id="3e86" class="jx jy hi bd jz ka ln kc kd ke lo kg kh ki lp kk kl km lq ko kp kq lr ks kt ku bi translated">一对一</h1><p id="f275" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">对于上面的同一个例子，让我们看看OvO是如何工作的。对于这个3个类的例子，我们不是为每个类训练一个SVM，而是为每对类训练一个SVM。因此，在训练SVM时，它只关注这一对职业，而忽略了其他职业。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ls"><img src="../Images/e1e040b68b1742fd2218b3e02670be66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zLpvdr28evjxvdUKYM8zvA.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">线性核卵</figcaption></figure><p id="1c31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于上面的例子，我们训练一个SVM来分离蓝色和绿色，一个分离蓝色和橙色，一个分离橙色和绿色。下面的热图显示了培训过程，我们可以看到，在为一对学员进行培训时，它完全忽略了其他班级。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es la"><img src="../Images/cac1168d8160b978e15f72e0c5097c14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3AGsRTF0Bp5e2onnikxj9Q.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">OvO培训热图</figcaption></figure><p id="24d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了对点x进行预测，我们选择具有最高票数的类k。</p><blockquote class="jq jr js"><p id="1705" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">这两种方法都有一个问题，那就是训练起来可能会非常慢。</p><p id="7926" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">OvR:训练k个支持向量机，每个都在完整的数据集上。</p><p id="98dd" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated"><strong class="ih hj"> OvO:训练k个支持向量机，但每个支持向量机只训练数据集的一部分。</strong></p></blockquote></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><h1 id="daec" class="jx jy hi bd jz ka ln kc kd ke lo kg kh ki lp kk kl km lq ko kp kq lr ks kt ku bi translated">多类分类的逻辑回归。</h1><p id="0342" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">理解逻辑回归是很重要的，如果你需要一点修改，请参考这篇文章。</p><p id="c774" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们也可以将OvR和OvO的概念用于逻辑回归，但是结果表明LR具有自然的多类最大似然公式。</p><h2 id="2ffe" class="lt jy hi bd jz lu lv lw kd lx ly lz kh iq ma mb kl iu mc md kp iy me mf kt mg bi translated">来自多输出线性回归的多输出逻辑回归</h2><p id="748e" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">我们可以训练一个线性回归模型来生成一个k维向量作为多输出数据集的输出，如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mh"><img src="../Images/e8eb791b12bd9b296d48637ac308fc90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x2xn4623Ksw_Q0e2-AAlng.png"/></div></div></figure><p id="5041" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，如果我们将元素式sigmoid捕捉到输出上，并独立预测每个标签的输出，我们将收到如下多标签输出:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mi"><img src="../Images/51193710bd771e550b2b3a58bc63c71c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*YxWHFDE0EqGr9N-bzZibgA.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">实际和预测标签的示例</figcaption></figure><p id="4d20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于分类，属于每个类别的实际概率不能独立预测。它们的总和必须是1。</p><p id="d6ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">理想情况下，我们需要预测所有类的联合概率。谢天谢地，我们有Softmax功能来拯救我们。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mj"><img src="../Images/01bd758a5565cca772cbc0f5d52d01e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*1F9vj6CYO7_FWnl1keoK0A.png"/></div></figure><p id="456a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">直觉</strong>:放大向量a中的最大值，然后归一化，保证应用softmax后所有值之和等于1。因此，我们实现了我们的多类分类器。</p><p id="7f0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们用我们在SVM看到的同一个例子来看看它的实际应用:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mk"><img src="../Images/38b5449f628aeeccf574218810641690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rm9Ekk3fspyHInhXkui3NA.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">三类多分类的Logistic回归</figcaption></figure></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><h1 id="5efb" class="jx jy hi bd jz ka ln kc kd ke lo kg kh ki lp kk kl km lq ko kp kq lr ks kt ku bi translated">奖金部分:</h1><h2 id="8e96" class="lt jy hi bd jz lu lv lw kd lx ly lz kh iq ma mb kl iu mc md kp iy me mf kt mg bi translated">多类与多标签分类与标记</h2><blockquote class="jq jr js"><p id="e1c6" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">多类:给定<em class="hi"> x </em>预测K个类中的一个唯一类(一个“类标签”)。</p><p id="e04a" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">多标签:给定<em class="hi"> x </em>，预测应该关联到x的K个标签的子集</p><p id="cf55" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">标签:通常是图像的多标签分类。</p></blockquote></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="4caa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有许多多类分类器可用，如<strong class="ih hj"> k-NN </strong>、<strong class="ih hj">朴素贝叶斯分类器</strong>，我将在后面讨论。</p><p id="6818" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望这篇文章为你提供了多类分类的直觉。它们对于处理现实世界的问题很重要，并且有广泛的应用。希望你喜欢学习它！</p><p id="5332" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有关问题/反馈，您可以通过我的<a class="ae jd" href="https://www.linkedin.com/in/vm3/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或我的<a class="ae jd" href="https://malhotravaibhav.com/" rel="noopener ugc nofollow" target="_blank">网站</a>联系我。</p><p id="b042" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快乐学习！</p></div></div>    
</body>
</html>