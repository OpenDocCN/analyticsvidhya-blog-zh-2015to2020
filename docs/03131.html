<html>
<head>
<title>TensorFlow Object Detection API Tutorial — Wind Turbine Detection using Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow对象检测API教程—使用Google Colab进行风力涡轮机检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorflow-object-detection-api-tutorial-wind-turbine-detection-using-google-colab-e8e2e120e54e?source=collection_archive---------10-----------------------#2020-01-17">https://medium.com/analytics-vidhya/tensorflow-object-detection-api-tutorial-wind-turbine-detection-using-google-colab-e8e2e120e54e?source=collection_archive---------10-----------------------#2020-01-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8f79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">使用TensorFlow对象检测API从航空或卫星图像中检测风力涡轮机</em></p><h1 id="a5ab" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated"><strong class="ak">概述</strong></h1><p id="6e2d" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">本教程描述了一个Jupyter笔记本和支持文件，使用<a class="ae kh" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow对象检测API </a>来训练风力涡轮机对象检测器。这款笔记本运行在<a class="ae kh" href="https://colab.research.google.com/notebooks/welcome.ipynb" rel="noopener ugc nofollow" target="_blank">谷歌联合实验室</a>中，该实验室提供了一个免费的虚拟机，预装了TensorFlow并可以访问GPU。这简化了开始使用TensorFlow进行有趣的事情(如对象检测)所需的设置过程。将Google Colab与开源TensorFlow对象检测API相结合，提供了训练自定义对象检测模型所需的所有工具。</p><p id="600c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本教程中，描述了从航空图像中检测风力涡轮机的过程。使用<a class="ae kh" href="https://earthexplorer.usgs.gov/" rel="noopener ugc nofollow" target="_blank"> USGS EarthExplorer </a>从公开可用的<a class="ae kh" href="https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/" rel="noopener ugc nofollow" target="_blank">国家农业图像计划(NAIP)数据库</a>获得航空图像。总共收集了488幅图像，其中至少包含一个完整的风力涡轮机，并将其分成<a class="ae kh" href="https://github.com/lbborkowski/wind-turbine-detector/tree/master/images/train" rel="noopener ugc nofollow" target="_blank">系列</a>(约80%)、<a class="ae kh" href="https://github.com/lbborkowski/wind-turbine-detector/tree/master/images/test" rel="noopener ugc nofollow" target="_blank">测试</a>(约16%)和<a class="ae kh" href="https://github.com/lbborkowski/wind-turbine-detector/tree/master/images/valid" rel="noopener ugc nofollow" target="_blank">验证</a>(约4%)组。</p><p id="f65b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从训练到推理的完整流程包含在GitHub <a class="ae kh" href="https://github.com/lbborkowski/wind-turbine-detector" rel="noopener ugc nofollow" target="_blank"> repo </a>中的Jupyter笔记本中，对流程中的每一步都有详细的解释。对于那些有兴趣训练自己的自定义对象检测模型的人来说，这可以作为一个教程。该过程分为三个步骤:1 .<strong class="ih hj">训练</strong>，2。<strong class="ih hj">验证</strong>和3。<strong class="ih hj">风力发电机检测和定位</strong>。</p><p id="2aa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图显示了一幅典型的航空或卫星输入图像，以及几幅对每台风力涡轮机进行了正确检测和分类的输出图像。如您所见，TensorFlow对象检测API提供了先进的预训练卷积神经网络(CNN)模型，可以自动对大范围内的结构或对象进行定位和分类。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ki"><img src="../Images/f5acbb16bb05a649e597ccc44225bb63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EGYsmlpiiZgKohM1qtvLaw.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">从1米分辨率的航空图像中探测风力涡轮机。从 <a class="ae kh" href="https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/" rel="noopener ugc nofollow" target="_blank"> <em class="ky">国家农业影像计划(NAIP)数据库</em> </a> <em class="ky">获得的原始航拍影像。</em></figcaption></figure></div><div class="ab cl kz la gp lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="hb hc hd he hf"><h1 id="0d8e" class="je jf hi bd jg jh lg jj jk jl lh jn jo jp li jr js jt lj jv jw jx lk jz ka kb bi translated">培养</h1><p id="a26b" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">在从NAIP数据库的原始5978 x 7648像素航空图像中截取的标记的300 x 300像素图像上执行训练。选择300 x 300的图像大小是为了避免过度使用内存，因为基于TensorFlow对象检测SSD的模型会将所有输入图像重新缩放到该大小。此外，通过该操作提高了对象尺寸与图像尺寸的比率。每张图片包含至少一个风力涡轮机，使用<a class="ae kh" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">标签</a>进行标记。在LabelImg中注释图像会创建一个对应于每个图像的XML文件。这些XML文件必须先转换为CSV，然后再转换为TFRecords。可以在<a class="ae kh" href="https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9" rel="noopener" target="_blank">这里</a>或者<a class="ae kh" href="https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到示例代码(在其他地方)。</p><p id="b495" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面显示了一些带标签的图像。总共有392幅图像用于训练，80幅用于测试。该培训集包括不同容量、制造商和设计的风力涡轮机。</p><div class="kj kk kl km fd ab cb"><figure class="ll kn lm ln lo lp lq paragraph-image"><img src="../Images/40885f712727a21b2ec99b994b3f54a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*X6Z9D30Bh-g51_Kghd3CNw.png"/></figure><figure class="ll kn lr ln lo lp lq paragraph-image"><img src="../Images/63831db6f5216537305015679d2c892d.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*p-gxO87CcyuzOrjYG9dHFg.png"/></figure><figure class="ll kn lm ln lo lp lq paragraph-image"><img src="../Images/6cb1661abd3b0f9a7a0812a697630b07.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*sGamBN30gcydg9x_h2OIvg.png"/></figure></div><div class="ab cb"><figure class="ll kn lr ln lo lp lq paragraph-image"><img src="../Images/1c2d6044a1409ac321252c39919c006a.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*vgPyOZjYL7Q6dWdpF4PrGA.png"/></figure><figure class="ll kn lm ln lo lp lq paragraph-image"><img src="../Images/5e8ca25f78a56682710da7d093978d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*FhyoH8FjwCwH9D5aXkQitQ.png"/></figure><figure class="ll kn lm ln lo lp lq paragraph-image"><img src="../Images/76cd983fcb2f2fa3ade535a442e7816d.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*X27HU-h19mHiEX8jIlZYsw.png"/><figcaption class="ku kv et er es kw kx bd b be z dx ls di lt lu translated">风力涡轮机检测器的标记训练图像样本</figcaption></figure></div><p id="99ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">来自<a class="ae kh" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow对象检测模型Zoo </a>的预训练CNN模型被用作起点。选择ssd_inception_v2_coco模型是基于其准确性和效率的平衡。关于如何安装和配置TensorFlow对象检测API的详细信息，包括依赖关系，可以在<a class="ae kh" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="452b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用来自<a class="ae kh" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow对象检测API repo </a>的经修改的<a class="ae kh" href="https://github.com/lbborkowski/wind-turbine-detector/blob/master/model_main.py" rel="noopener ugc nofollow" target="_blank"> model_main.py </a>文件来训练风力涡轮机检测器模型，该文件包括在导入语句之后的“TF . logging . set _ verbosity(TF . logging . info)”，以每100步输出损失。在修改后的模型配置文件<a class="ae kh" href="https://github.com/lbborkowski/wind-turbine-detector/blob/master/training/ssd_inception_v2_coco_WTDetector.config" rel="noopener ugc nofollow" target="_blank">SSD _ inception _ v2 _ coco _ wt detector . config</a>中，对示例ssd_inception_v2_coco.config文件进行了以下更改/添加:</p><ul class=""><li id="5b60" class="lv lw hi ih b ii ij im in iq lx iu ly iy lz jc ma mb mc md bi translated">数量_类别:1</li><li id="7bbc" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">批量大小:12</li><li id="a431" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">fine _ tune _ check point:" pre-trained-model/model . ckpt "</li><li id="76c6" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">train _ input _ reader:{ TF _ record _ input _ reader { input _ path:" annotations/train . record " } label _ map _ path:" annotations/label _ map . Pb txt " }</li><li id="2871" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">eval _ input _ reader:{ TF _ record _ input _ reader { input _ path:" annotations/test . record " } label _ map _ path:" annotations/label _ map . Pb txt " shuffle:false num _ readers:1 }</li></ul><p id="f774" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">修改后的配置文件中规定了额外的数据/图像增强。将垂直翻转和90度旋转与默认的水平翻转相结合，训练数据可以扩展到包含所有可能的风力涡轮机方位。由于风力涡轮机可以面向任何方向，这些操作有助于概化模型。</p><ul class=""><li id="d9cc" class="lv lw hi ih b ii ij im in iq lx iu ly iy lz jc ma mb mc md bi translated">data _ augment _ options { random _ vertical _ flip { } }</li><li id="8c52" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">data _ augmentation _ options { random _ rotation 90 { } }</li></ul></div><div class="ab cl kz la gp lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="hb hc hd he hf"><h1 id="eed6" class="je jf hi bd jg jh lg jj jk jl lh jn jo jp li jr js jt lj jv jw jx lk jz ka kb bi translated">确认</h1><p id="3968" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">为了验证模型，一组未标记的验证图像与训练集和测试集分开保存。总共16幅图像用于验证。由于在训练期间执行的随机图像增强，验证结果可能在训练运行之间有所不同。然而，我发现，在默认的训练参数下，验证图像集中的17个风力涡轮机中至少有15个被检测到的概率很高。我甚至经历了100%的准确性(所有风力涡轮机都被正确检测到)，但是由于训练中的随机性，每个训练的模型可能会提供略有不同的结果。验证步骤的一些结果如下所示。</p><div class="kj kk kl km fd ab cb"><figure class="ll kn mj ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/334e81a0a75a45781ccd3af94a83761a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*yUrHM6VNNF49cuEQLM9zuA.png"/></div></figure><figure class="ll kn mj ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/a7d7fe92d71bfc336d1e1dc27ac80f4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Pd1dd_Nadnq_4K0ja8bYfA.png"/></div></figure><figure class="ll kn mj ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/ec2b967270fae8b1a17357240a799a12.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*y0JNMJF4YlAJ2qVuz2wlsg.png"/></div></figure></div><div class="ab cb"><figure class="ll kn mj ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/27e2651a03414edcad7d5889b4fe3fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*rPDifcJsAkRF9wm_IGZm3w.png"/></div></figure><figure class="ll kn mj ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/4426a857265ecd721c99bee4cb8d1ce1.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*O0EUeXU9ccAja7l_gPYR_A.png"/></div></figure><figure class="ll kn mj ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/7fd38e412881f4477cbd037b0078ce0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0mjd8k8pl74593She1jBCQ.png"/></div><figcaption class="ku kv et er es kw kx bd b be z dx ls di lt lu translated">经过培训的风力涡轮机检测器的验证结果</figcaption></figure></div></div><div class="ab cl kz la gp lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="hb hc hd he hf"><h1 id="3d4b" class="je jf hi bd jg jh lg jj jk jl lh jn jo jp li jr js jt lj jv jw jx lk jz ka kb bi translated">风力涡轮机检测和定位</h1><p id="5e7d" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">最后，经过训练的模型被应用于覆盖大约4英里乘4英里区域的完整NAIP图像。为了在这个大区域上执行检测，使用滑动窗口方法来分析5978×7648像素原始图像上的300×300像素图像。一旦执行了该分析，就在每个检测到的风力涡轮机的原始NAIP图像上绘制标记。此外，输出每台风机的经纬度以供验证。下面是两张NAIP图像，所有检测到的风力涡轮机都用红色标记表示。此外，包含风力涡轮机纬度和经度坐标子集的表格如下所示。该模型的检测精度很高，但是存在非风力涡轮机对象(例如房屋、谷仓或道路)被检测并分类为风力涡轮机的情况。</p><div class="kj kk kl km fd ab cb"><figure class="ll kn mk ln lo lp lq paragraph-image"><img src="../Images/55e1c2982ea732fac4046cb2438737e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*XZf2Lhe_jhP0CBsW6MkGsg.png"/></figure><figure class="ll kn ml ln lo lp lq paragraph-image"><img src="../Images/fa20323a11fe0c6bf2c96f7f35b7bd97.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*S5ZtZVYH-IBgqFBbomfbsQ.png"/><figcaption class="ku kv et er es kw kx bd b be z dx mm di mn lu translated">使用应用于4 x 4英里航空图像的训练模型检测到的风力涡轮机位置(用红色标记表示)</figcaption></figure></div><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es mo"><img src="../Images/dac6ce1ea05bdb35706c85e36fef0568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*_Mm7MEd-gvWE-A5kCnZ9SQ.png"/></div><figcaption class="ku kv et er es kw kx bd b be z dx translated"><em class="ky">检测到的风力涡轮机样本集的位置</em></figcaption></figure></div><div class="ab cl kz la gp lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="hb hc hd he hf"><h1 id="fb17" class="je jf hi bd jg jh lg jj jk jl lh jn jo jp li jr js jt lj jv jw jx lk jz ka kb bi translated">摘要</h1><p id="b60a" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">经训练的风力涡轮机检测模型显示具有大约90%的准确度(在验证集中检测到17个风力涡轮机中的至少15个)。通过使用更大的图像集(训练+测试)以及使用更准确的预训练模型，可能会实现更高的准确性。在<a class="ae kh" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow物体探测模型动物园</a>可以找到替代模型，包括那些具有更高地图的模型。在这篇<a class="ae kh" href="https://arxiv.org/pdf/1611.10012.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中可以找到各种对象检测模型架构(例如，更快的RCNN、SSD、R-FCN)的速度、精度和内存之间的权衡细节，这可以作为确定哪种架构最适合您的应用的良好起点。</p><p id="0eaa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本教程和随附的Jupyter笔记本中介绍的综合管道包括训练、验证和推理，可以应用于许多其他应用，包括从航空或卫星图像中检测各种对象。</p><p id="97d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">启动Jupyter笔记本，点击</em> <a class="ae kh" href="https://colab.research.google.com/github/lbborkowski/wind-turbine-detector/blob/master/WindTurbineDetector_200529.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="jd">此处</em> </a> <em class="jd">，开始在Google Colab中检测风力涡轮机。</em></p></div></div>    
</body>
</html>