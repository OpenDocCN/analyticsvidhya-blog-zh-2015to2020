<html>
<head>
<title>Configure Hadoop and start cluster services using Ansible Playbook !!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Ansible Playbook 配置 Hadoop 并启动集群服务！！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/configure-hadoop-and-start-cluster-services-using-ansible-playbook-fb0708488c50?source=collection_archive---------16-----------------------#2020-12-27">https://medium.com/analytics-vidhya/configure-hadoop-and-start-cluster-services-using-ansible-playbook-fb0708488c50?source=collection_archive---------16-----------------------#2020-12-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1b508f53d03964107eb0519984fff073.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GLjbQ3SfYO792G0oThm_2g.png"/></div></div></figure><p id="5427" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们需要创建一个清单文件，ansible 可以在其中知道这些是目标节点的 IP。<br/>库存文件意味着它包含带有认证的目标节点的 IP。其中我们给出了主节点和从节点的 IP…</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jo"><img src="../Images/f9c9a7da54e161076f5fd65c4fa58b11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QdT_FgC1wfmhT0IQ8Ydj3A.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">存货文件</figcaption></figure><p id="9a6d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">主配置</strong></p><p id="62ee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 1 </strong> &gt;首先，我们将软件转移到目标节点，然后我们将安装…</p><p id="d3b5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在安装之前，我们首先检查是否安装了软件，因为 Ansible 中没有用于设置或安装 Hadoop 软件的模块(由于使用了额外的关键字，即强制 Hadoop 和我们正在使用的模块，即<strong class="is hj">命令</strong>不支持 ansible 的等幂运算<strong class="is hj"> …。</strong></p><pre class="jp jq jr js fd jx jy jz ka aw kb bi"><span id="cbb6" class="kc kd hi jy b fi ke kf l kg kh">- hosts: master<br/>  <br/>  vars_prompt:<br/>  <br/>  - name: fold_name_hadoop_master<br/>    private: no<br/>    prompt: "Enter the Name for your master Folder ?"</span><span id="0439" class="kc kd hi jy b fi ki kf l kg kh">- name: port_num_for_hdfs<br/>    private: no<br/>    prompt: "Give the Port Num for the Master Service ?"</span><span id="1218" class="kc kd hi jy b fi ki kf l kg kh">tasks:<br/> <br/>  - name: "Transfering the SOftware Hadoop !!"<br/>    copy: <br/>     dest: "/root/hadoop-1.2.1-1.x86_64.rpm"<br/>     src: hadoop-1.2.1-1.x86_64.rpm<br/>  <br/>  - name: "Transfering the Software Java !!"<br/>    copy:<br/>     dest: "/root/jdk-8u171-linux-x64.rpm"<br/>     src: jdk-8u171-linux-x64.rpm</span><span id="dd44" class="kc kd hi jy b fi ki kf l kg kh">- name: "Checking that Hadoop is INstalled or NOt !!"<br/>    command: "rpm -q hadoop"<br/>    register: hadoop<br/>    ignore_errors: yes</span><span id="8bc1" class="kc kd hi jy b fi ki kf l kg kh">- name: "CHecking the Java is Installed or Not !!"<br/>    command: "java -version"<br/>    register: java<br/>    ignore_errors: yes</span><span id="e1db" class="kc kd hi jy b fi ki kf l kg kh">- name: "Installing the JAVA !!"<br/>    command: "rpm -ivh jdk-8u171-linux-x64.rpm"<br/>    ignore_errors: yes<br/>    when: java.rc != 0</span><span id="8e75" class="kc kd hi jy b fi ki kf l kg kh">- name: "Imstalling the Hadoop !!"<br/>    command: "rpm -ivh hadoop-1.2.1-1.x86_64.rpm --force"<br/>    ignore_errors: yes<br/>    when: hadoop.rc != 0</span></pre><p id="01ec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们需要为主节点创建一个文件夹，以便从节点可以通过它共享存储，并将一些元数据保存到其中<strong class="is hj">和</strong>我们需要配置配置文件，如下所示:</p><p id="c70b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">→ hdfs-site.xml</p><p id="d281" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">→核心网站. xml</p><pre class="jp jq jr js fd jx jy jz ka aw kb bi"><span id="a603" class="kc kd hi jy b fi ke kf l kg kh">- name: "Configuring the Conf file hdfs-site.xml  !!"<br/>    blockinfile:<br/>      path: "/etc/hadoop/hdfs-site.xml"<br/>      insertafter: "&lt;configuration&gt;"<br/>      block: |<br/>            &lt;property&gt;<br/>            &lt;name&gt;dfs.name.dir&lt;/name&gt;<br/>            &lt;value&gt; {{fold_name_hadoop_master}}&lt;/value&gt;<br/>            &lt;/property&gt;<br/>  <br/>  - name: "Configuring the Conf file core-site.xml  !!"<br/>    blockinfile:<br/>      path: "/etc/hadoop/core-site.xml"<br/>      insertafter: "&lt;configuration&gt;"<br/>      block: |<br/>            &lt;property&gt;<br/>            &lt;name&gt;fs.default.name&lt;/name&gt;<br/>            &lt;value&gt; hdfs://0.0.0.0:{{port_num_for_hdfs}} &lt;/value&gt;<br/>            &lt;/property&gt;</span><span id="7d1c" class="kc kd hi jy b fi ki kf l kg kh">- name: "Creating the DIr in the Master NOde !!"<br/>    file:<br/>     state: directory<br/>     path: "//{{fold_name_hadoop_master}}"</span></pre><p id="e7be" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后我们需要第一次格式化那个文件夹，然后我们将根据用户给定的端口运行服务…</p><pre class="jp jq jr js fd jx jy jz ka aw kb bi"><span id="0e49" class="kc kd hi jy b fi ke kf l kg kh">- name: "Formating that Directory !!"<br/>    shell: "echo Y | hadoop namenode -format"</span><span id="f7e5" class="kc kd hi jy b fi ki kf l kg kh">- name: "Starting the Service !!"<br/>    command: "hadoop-daemon.sh start namenode"</span></pre><p id="4181" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过同样的步骤，我们也可以配置从节点…只有一件事我们需要使用我们的大脑捕捉主节点的 IP 在飞行的事实变量的帮助下…</p><blockquote class="kj kk kl"><p id="8bc2" class="iq ir km is b it iu iv iw ix iy iz ja kn jc jd je ko jg jh ji kp jk jl jm jn hb bi translated">{{groups['slave'][0]}}</p></blockquote><p id="450d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此配置😎….</p><p id="7760" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感谢您阅读本博客…</p></div></div>    
</body>
</html>