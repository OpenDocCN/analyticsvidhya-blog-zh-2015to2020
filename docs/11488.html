<html>
<head>
<title>Language modelling to person modelling?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">语言造型到人物造型？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/language-modelling-to-person-modelling-ca0a1835ab76?source=collection_archive---------14-----------------------#2020-12-05">https://medium.com/analytics-vidhya/language-modelling-to-person-modelling-ca0a1835ab76?source=collection_archive---------14-----------------------#2020-12-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="efda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着疫情肆虐我们的生活，我们努力定义我们的“新正常”的健康生活。受限的社交聚会和与爱人的会面让我们中的一些人渴望同伴来分享我们的想法，发泄或只是活在当下。</p><p id="0c44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鉴于人工智能正在转变为无所不在的力量，解决我们周围的许多问题，这能否被用来给我们一些归属感？</p><blockquote class="jd je jf"><p id="7ff3" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">“在我看来，对我们的大脑来说，最有成效、最自然的锻炼是对话。”——米歇尔·德·蒙田。</p></blockquote><p id="ab63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">带着这个想法，我开始创造一个智能机器人，它能够像人一样对我做出反应。简而言之，贾维斯对我的钢铁侠。</p></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><p id="9884" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，我从这里描述的传统语言<a class="ae jr" href="https://www.coursera.org/learn/nlp-sequence-models" rel="noopener ugc nofollow" target="_blank">开始</a>。你想知道我正在模仿的人是谁？随着最近结束的美国总统辩论，当然是唐纳德·特朗普，乔·拜登，甚至更好，一个组合的人格！</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es js"><img src="../Images/0d14a681d862f8d872c4b3d8418aac6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*edmYUgAga0BW0TG9s_yZQw.jpeg"/></div></div></figure></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><h1 id="a52f" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">首先，让我们感受一下我们的数据集</h1><p id="94d6" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">在通过删除停用词、标点符号和标记来清理文本之后，让我们来看看两位说话者使用的最常见的五个二元模型。</p><pre class="jt ju jv jw fd lh li lj lk aw ll bi"><span id="8a69" class="lm kf hi li b fi ln lo l lp lq"><strong class="li hj">DONALD TRUMP</strong><br/>[(('take', 'look'), 19), (('let', 'tell'), 15), <strong class="li hj">(('new', 'york'),</strong> 14), (('individual', 'mandate'), 13), (('million', 'people'), 12)]</span><span id="1f39" class="lm kf hi li b fi lr lo l lp lq">--------------------------------------------------------------------</span><span id="9782" class="lm kf hi li b fi lr lo l lp lq"><strong class="li hj">JOE BIDEN</strong><br/>[(('make', 'sure'), 37), (('united', 'states'), 23), <strong class="li hj">(('number', 'one'), 23), (('number', 'two'), 17)</strong>, (('one', 'number'), 15)</span></pre><p id="3eab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然我们确实听到了特朗普在纽约的许多言论，但拜登列举观点的风格也很明显。</p><p id="7623" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止一切顺利！</p><h1 id="5647" class="ke kf hi bd kg kh ls kj kk kl lt kn ko kp lu kr ks kt lv kv kw kx lw kz la lb bi translated">惨败的模式。</h1><p id="efb6" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">我开始设计我的个人模型，试图教会它在给定一系列单词的情况下预测下一个单词。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es lx"><img src="../Images/f9ca1ca70a42483d7b82b80e06305b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*hJDIwl4rsVnoa-lZEKkYnw.png"/></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">语言建模的 LSTM 模型</figcaption></figure><p id="d3bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一些大胆的决定。</p><p id="2e4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">用于单词嵌入的 word 2 vec</strong></p><p id="5bbb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我认为使用<a class="ae jr" href="https://code.google.com/archive/p/word2vec/" rel="noopener ugc nofollow" target="_blank">预训练的 Google word2vec </a>进行单词嵌入是明智的，这样模型就可以推断出像<code class="du mc md me li b">citizens</code>和<code class="du mc md me li b">people</code>、<code class="du mc md me li b">country</code>和<code class="du mc md me li b">nation</code>是同义词这样的想法。然而，很多常用词如<code class="du mc md me li b">how</code>、<code class="du mc md me li b">and</code>、<code class="du mc md me li b">are</code>等并没有在模型中表现出来。这可能是因为在训练原始模型时删除了停用词。我使用一个随机向量来表示它，因为停用词在我们的总统文本生成问题中也是必要的。</p><p id="15ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">最大序列长度</strong></p><p id="d9b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">两位演讲者使用的平均句子长度分别为 10.67 和 14.02。然而，我决定把这个限制在 10，因为这个模型的目标是让<strong class="ih hj">合理的句子</strong>不一定长。</p><p id="1478" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">损失余弦相似度</strong></p><p id="0bb8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于<code class="du mc md me li b">citizens</code>和<code class="du mc md me li b">people</code>是同义词的同样原因，我认为用一个代替另一个来惩罚模型是不公平的。由于这些单词的向量表示具有很高的相似性，余弦相似性似乎是损失函数的合理选择。</p></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><p id="1443" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于航向破坏了它，该模型没有表现良好——无论是在精度方面(约 50%)还是在预测方面。这可能是由于相对于输入数据，模型的词汇集很大(即 Word2vec 预处理模型的词汇集)。只是一个猜测！</p></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><h1 id="cabe" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">有点效果的模型。</h1><p id="7aae" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">所以，我决定选择另一种建筑<a class="ae jr" href="https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/" rel="noopener ugc nofollow" target="_blank"/>来试图纠正我的错误，同时交叉手指和脚趾。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es lx"><img src="../Images/ebbd286f611133e54549561c529b26d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*ASzHU1zomJPAUirN3fmGZg.png"/></div></figure><p id="61c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在使用较小的序列长度 4，并且消除了 word2vec 的情况下，这个模型似乎表现得更好。蓝色的文本是模型的输入(出现在文本中的片段)。的输出以橙色突出显示(如果它存在于文本中)，以绿色突出显示(如果它不存在)。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es mf"><img src="../Images/dad2b3a8345ed91567065fe63ce6b697.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C4Ysx-FoOZnJu-B94GAFvQ.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">抽样输出</figcaption></figure><p id="3aef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然产量还不是很可观，但它确实了解到了<code class="du mc md me li b">white</code>之后通常是<code class="du mc md me li b">house</code>、<code class="du mc md me li b">tax</code>之后是<code class="du mc md me li b">cuts</code>、<code class="du mc md me li b">law</code>之后是<code class="du mc md me li b">enforcement</code>等等……</p><p id="7cf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这确实是冰山一角。该模型需要在更大的数据集上进行训练和评估，但那是以后的事了。在那之前，在一个平行的世界里快乐的编码！</p><p id="217c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集和代码—<a class="ae jr" href="https://www.kaggle.com/wasp12/debate-language-model" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/wasp12/debate-language-model</a></p></div></div>    
</body>
</html>