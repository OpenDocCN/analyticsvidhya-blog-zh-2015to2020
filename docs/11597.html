<html>
<head>
<title>Image Captioning with Attention: Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关注图像字幕:第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-captioning-with-attention-part-2-f3616d5cf8d1?source=collection_archive---------6-----------------------#2020-12-10">https://medium.com/analytics-vidhya/image-captioning-with-attention-part-2-f3616d5cf8d1?source=collection_archive---------6-----------------------#2020-12-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="09f0" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">图像字幕项目的第二部分包括模型训练和字幕采样的过程</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/c9758474d277a51c6090f4efe6b28d59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h6HnoEfOfEh7SEZdpcn02w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">视觉注意力</figcaption></figure><h1 id="35b6" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">模特培训</h1><p id="5b9d" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">在本文的第一部分<a class="ae lb" href="https://makarovartyom-ma.medium.com/image-captioning-with-attention-part-1-e8a5f783f6d3" rel="noopener">中，我们已经介绍了图像字幕编码器-解码器模型的整体架构。</a></p><p id="d748" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">现在我们来详细讨论一下训练过程。您可以通过 GitHub <a class="ae lb" href="https://github.com/MakarovArtyom/Image-Captioning-with-Attention/blob/master/2_Training.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a>找到培训笔记本。</p><h2 id="765e" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">超参数</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lv lw l"/></div></figure><ul class=""><li id="0477" class="lx ly hi kh b ki lc kl ld ko lz ks ma kw mb la mc md me mf bi translated">请注意，较小的<code class="du mg mh mi mj b">batch_size</code>会导致更强的<em class="mk">正则化</em> <em class="mk">效果</em>，并且更容易在内存中容纳一批。我选择了一个等于<code class="du mg mh mi mj b">64</code>的批量。</li><li id="6d1c" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated"><code class="du mg mh mi mj b">vocab_threshold</code> -一个单词在作为词汇表的一部分之前必须出现在标题中的总次数。门槛越高，我们对创造词汇的限制就越严格。</li><li id="f631" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated">基于实验，历元数被设置为<code class="du mg mh mi mj b">14</code>。在实践中，只要训练和验证错误持续下降，我们就持续训练。</li></ul><h2 id="48ae" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">变形金刚(电影名)</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">数据转换</figcaption></figure><ul class=""><li id="2f6f" class="lx ly hi kh b ki lc kl ld ko lz ks ma kw mb la mc md me mf bi translated">首先，我们调整原始图像的大小，执行<code class="du mg mh mi mj b">transforms.Rezize(256)</code>并随机裁剪得到一个 224x224 的图像样本- <code class="du mg mh mi mj b">transforms.RandomCrop(224)</code>。</li><li id="c96d" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated">随后，我们水平翻转样本<code class="du mg mh mi mj b">transforms.RandomHorizontalFlip()</code>，转换成张量<code class="du mg mh mi mj b">transform.ToTensor()</code>并归一化。</li><li id="cb18" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated">注意，在给定<code class="du mg mh mi mj b">0.485</code>的<em class="mk">均值</em>和<code class="du mg mh mi mj b">0.229</code>的<em class="mk">标准差</em>的情况下，归一化应用于图像样本- <code class="du mg mh mi mj b">transform.Normalize((0.485, 0.485, 0.485), (0.229, 0.229, 0.229))</code>的所有通道(深度=3)。</li></ul><h2 id="6b1b" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">训练循环</h2><p id="4b2c" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">为了在单个历元上完成训练，我们定义接收以下参数的函数:</p><ul class=""><li id="caba" class="lx ly hi kh b ki lc kl ld ko lz ks ma kw mb la mc md me mf bi translated"><em class="mk">历元</em> —当前历元的编号。</li><li id="6b67" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated"><em class="mk">编码器</em> —型号的编码器，设置为评估模式<code class="du mg mh mi mj b">eval()</code>。</li><li id="f5d1" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated"><em class="mk">解码器</em> —模特的解码器，我们的目标是训练。</li><li id="00e5" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated"><em class="mk">优化器</em> —模型的优化器(在我们的例子中是 Adam)。亚当是训练的常见选择，它具有阿达格拉德和 RMSProp ⁶.的特性</li><li id="a83c" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated"><em class="mk">准则</em> —优化的损失函数。我们使用由 softmax 函数产生的交叉熵损失<code class="du mg mh mi mj b">CrossEntropyLoss()</code>，它包括应用于概率的负对数似然<code class="du mg mh mi mj b">NLLLoss()</code>的影响。</li><li id="b05f" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated"><em class="mk">次数</em> —总次数。我们使用<code class="du mg mh mi mj b">14</code>纪元来训练模型。</li><li id="8bf7" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated"><em class="mk">数据加载器</em> —指定的数据加载器(用于训练、验证或测试)。</li><li id="39d7" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated"><em class="mk"> write_file </em> —写入培训日志的文件。我们将统计数据存储在两个独立的<code class="du mg mh mi mj b">txt</code>文件中。</li><li id="e7bd" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated"><em class="mk"> save_every - </em>保存每个训练时段后的结果。</li></ul><p id="ecdc" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">注意，我们在<code class="du mg mh mi mj b">captions_train</code>变量中存储了我们在<em class="mk">上训练的没有第一个字</em>的字幕，在<code class="du mg mh mi mj b">captions_target</code>变量中存储了没有最后一个字的目标字幕<em class="mk">。</em></p><p id="3fc6" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">训练循环的完整代码如下所示。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">培训功能</figcaption></figure><h2 id="4e41" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">验证循环</h2><p id="ad4b" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">验证函数遵循与训练函数相同的逻辑，除了我们为模型的假设计算的蓝色分数。</p><p id="75a1" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">在每个验证步骤中:</p><ul class=""><li id="8250" class="lx ly hi kh b ki lc kl ld ko lz ks ma kw mb la mc md me mf bi translated">我们将模型生成的输出索引<code class="du mg mh mi mj b">terms_idx</code>传递给<code class="du mg mh mi mj b">get_hypothesis()</code>函数，并获得图像批次的假设列表<code class="du mg mh mi mj b">hyp_list</code>。</li><li id="0d93" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated">接下来，我们相应地用<code class="du mg mh mi mj b">hyp_list</code>和<code class="du mg mh mi mj b">caps_processed</code>填充<code class="du mg mh mi mj b">hypothesis</code>和<code class="du mg mh mi mj b">references</code>列表。第一个列表存储了我们在一个时期内得到的所有假设。第二个列表包含所有处理过的目标标题<code class="du mg mh mi mj b">caps_processed</code>，使用<code class="du mg mh mi mj b">get_batch_caps()</code>函数返回。</li><li id="f4e9" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated">使用<a class="ae lb" href="https://www.nltk.org/_modules/nltk/translate/bleu_score.html" rel="noopener ugc nofollow" target="_blank"> NLTK 包</a>中的<code class="du mg mh mi mj b">corpus_bleu()</code>函数计算 BLEU 分数。</li></ul><h2 id="5788" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">BLEU 得分简单来说</h2><p id="7f3b" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">BLEU 评分是一个标准的度量，广泛用于 NLP 和 CV 领域，用于评估机器生成的翻译或字幕相对于人的翻译或字幕。BLEU 算法的细节可以在吴恩达的<a class="ae lb" href="https://www.aclweb.org/anthology/P02-1040/" rel="noopener ugc nofollow" target="_blank">原论文</a>和这个著名的<a class="ae lb" href="https://www.youtube.com/watch?v=DejHQYAGb7Q" rel="noopener ugc nofollow" target="_blank">深度学习课程</a>中找到。</p><p id="f589" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">根据 NLTK 实现，我还提供了公式和支持性示例来演示单幅图像的 BLEU 分数计算。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/e661c4707e099eaf6ab58919e7655fe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T74kiikYyzgmaKkKiXGgKQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">BLEU 分数计算</figcaption></figure><p id="407a" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">BP——“简洁惩罚”。如果候选的长度与任何翻译长度相同，我们将其设置为<strong class="kh hj"> 1.0 </strong>。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mr"><img src="../Images/aceabc7ded0c3b6d428a7bf11dc49d9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*DNkHwsWOoPzYIEBeXQdEbg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">罚款计算简洁</figcaption></figure><p id="fd54" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">让我们来看看基于 1、2、3 和 4 克精度的批量单个图像<em class="mk">的 BLEU 分数估计。</em></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">n-gram BLEU 分数计算</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ms"><img src="../Images/9d04ccb619b3dc01a2dffe8c6712c44b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3qMF_U2ONl6jt4fFo6Ui3w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图 1:“Unigram 修改的精度”</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mt"><img src="../Images/e36b4227de185a087bd5d99ec7b03506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oreft9V6wiTtFHc8a3Jldw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图 2:“2 克精度”</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mu"><img src="../Images/e64f96db095ae6f723d214fc8ca5d451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EvwSiZPIjSeSSpUw7PcjMQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图 3:“3 克精度”</figcaption></figure><p id="a76a" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">注意，如果削波计数等于 0，<code class="du mg mh mi mj b">epsilon</code>用于调整精度，加上它的命名者(默认<code class="du mg mh mi mj b">epsilon</code> = 0.1)。这种方法可以通过添加<code class="du mg mh mi mj b">smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method1</code>作为<code class="du mg mh mi mj b">corpus_bleu()</code>的参数来实现。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mv"><img src="../Images/0dccc86988e2676f6b32ee301cd2e29c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sjHJb9pKl5hnTQgbTPZWZw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图 4:“4 克精度”</figcaption></figure><p id="4c1c" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">在验证循环中，我们在每次迭代中对整批图像应用<code class="du mg mh mi mj b">corpus_bleu</code>。在这种情况下，计算整个时期的 BLEU 分数。</p><p id="1374" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">在这种情况下，修改后的精度𝑝由单个削波计数总和(分子)和单个 n 元文法计数(分母)的比率<strong class="kh hj">表示。</strong></p><p id="bdb9" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">现在，我们可以如下定义验证循环。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">验证循环</figcaption></figure><p id="a108" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">尽管 BLEU 算法的使用有缺点(一些警告在⁷的博客中列出)，但它在评估模型的性能时仍然表现良好。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mw"><img src="../Images/61f7423cece4559d25f034d3c5259182.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*09oQbZnKqTK-Fr1H__0XIg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图 5:“BLEU 评分评估”</figcaption></figure><h2 id="7481" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">培训结果</h2><ul class=""><li id="9481" class="lx ly hi kh b ki kj kl km ko mx ks my kw mz la mc md me mf bi translated">在 14 个时期的整个训练过程中，训练和验证损失以及<em class="mk">困惑</em>(损失的指数尺度)保持下降。</li><li id="2cbd" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated">注意在训练的第一个和第五个时期之间的训练和验证损失之间的差距:与训练损失相比更低的验证损失可以通过应用于隐藏状态的丢失层来解释<code class="du mg mh mi mj b">h</code>。我们激活 dropout 以在训练期间引入噪声，并在验证期间停用它。</li></ul><div class="iy iz ja jb fd ab cb"><figure class="na jc nb nc nd ne nf paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/4796fd780143fc26c9f4da085b9a9e74.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*GhJU93WvdkcjQUKwNjQyJg.png"/></div></figure><figure class="na jc ng nc nd ne nf paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/721354a4f304992a056d89afbec5f68c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*FimlvcaY3QgHvsDKRPDFUw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx nh di ni nj translated">图 6:“培训/验证日志”</figcaption></figure></div><h1 id="9782" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">推理</h1><p id="bc9e" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">采用了两种解码方法来从产生的标记中生成字幕:</p><ul class=""><li id="7636" class="lx ly hi kh b ki lc kl ld ko lz ks ma kw mb la mc md me mf bi translated">贪婪的搜索。</li><li id="0b1d" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la mc md me mf bi translated">光束搜索。</li></ul><h2 id="2a78" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">贪婪搜索</h2><p id="4354" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">贪婪搜索方法假设在每个后续解码步骤中采用<em class="mk"> argmax </em>或<em class="mk">最可能单词</em>。我们从特殊标记<code class="du mg mh mi mj b">&lt;START&gt;</code>开始，使用顶部的单词作为输入，继续生成一个序列。</p><p id="51a6" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">例如，停止标准可以是生成的句子中的最大单词数(在我们的例子中是<code class="du mg mh mi mj b">max_sentence=20</code>)或到达<code class="du mg mh mi mj b">&lt;END&gt;</code>标记。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/07f596f7943abc30b07282942787fb5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jhkqwkokPwSTKfobYWoaUQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图 7:“贪婪解码”</figcaption></figure><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">解码器类下的贪婪解码方法</figcaption></figure><h2 id="28e3" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">波束搜索</h2><p id="4117" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">为了更灵活地选择假设，可以采用波束搜索的思想——与上面描述的贪婪搜索不同，我们跟踪<strong class="kh hj"> k </strong> <em class="mk"> </em>最有可能的假设，将表征的<em class="mk">个体分数</em>相加，并计算假设的<em class="mk">累积分数</em>(图表上的分数-1、分数-2、分数-3)。</p><p id="8dec" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">我们继续搜索，直到达到最大令牌数或生成了<code class="du mg mh mi mj b">n</code>个完整的假设。由于较长的假设具有较低的累积分数，因此需要通过长度对其进行<em class="mk">归一化。</em></p><p id="d45d" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">我强烈推荐<a class="ae lb" href="http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture08-nmt.pdf" rel="noopener ugc nofollow" target="_blank"> CS224N NLP 讲座</a>了解更多关于 seq-2-seq 模型的解码方法和波束搜索，特别是⁵.</p><p id="658a" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">另外，在<a class="ae lb" href="https://github.com/MakarovArtyom/Image-Captioning-with-Attention/blob/master/beam_search.py" rel="noopener ugc nofollow" target="_blank">项目的资源库</a>下检查我的 beam search 实现。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nl"><img src="../Images/50baacb93497d1a0e8f17e2a2d5cc984.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NUj5VbGYD5xv3OamBnxFsw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图 8:“k = 2 的波束搜索。可视化改编自<a class="ae lb" href="http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture08-nmt.pdf" rel="noopener ugc nofollow" target="_blank"> CS224N/Ling284 </a></figcaption></figure><p id="38c6" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">下面，您可以找到由贪婪搜索生成的模型预测的一些示例(目前波束搜索脚本需要一些变通方法和额外的评估):</p><div class="iy iz ja jb fd ab cb"><figure class="na jc nm nc nd ne nf paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/041172300aac50c94b9beb0b974015a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*Q5sNV7XrdYZAvBVY3EizdA.png"/></div></figure><figure class="na jc nn nc nd ne nf paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/e31e101e303bd0fc9411d98358afeb2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*iCbwolmbos7uTo_JEv6ySg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx no di np nj translated">贪婪搜索解码模型预测</figcaption></figure></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nq"><img src="../Images/d3330757965fc175111e22872b529988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pmy-FB97sfmtm7W4NSFqHw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">注意力可视化</figcaption></figure><h2 id="ec26" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">进一步的改进</h2><ol class=""><li id="5c17" class="lx ly hi kh b ki kj kl km ko mx ks my kw mz la nr md me mf bi translated">首先，<em class="mk">增加数据集的大小</em>并向数据添加更多的方差可以获得更好的性能，因为模型将能够学习更多的细微差别。</li><li id="6ca8" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la nr md me mf bi translated"><em class="mk">门控上下文</em>的用法<a class="ae lb" href="https://arxiv.org/abs/1502.03044" rel="noopener ugc nofollow" target="_blank"> <em class="mk"> Show，Attend and Tell</em></a><em class="mk"/>论文第 4.2.1 节描述的方法建议将 sigmoid 应用于线性激活的解码器的最后隐藏状态，并将其用作上下文向量的门(将 gate 乘以注意上下文)。这提高了注意力模型强调图像中的对象的能力。</li><li id="1fb1" class="lx ly hi kh b ki ml kl mm ko mn ks mo kw mp la nr md me mf bi translated"><em class="mk">修改模型的架构</em> —较大的模型需要足够多的数据来学习其参数。然而，即使使用更简单的 seq-2seq 无注意模型，您也可以获得不错的结果。尝试其他类型的注意力也是一种选择，例如，使用<a class="ae lb" href="https://arxiv.org/abs/1508.04025" rel="noopener ugc nofollow" target="_blank"> Luong <em class="mk">乘法注意力</em> </a> <em class="mk"> </em>或<a class="ae lb" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank"> <em class="mk">自我注意力与变压器的机制</em> </a> <em class="mk"> ⁴.</em></li></ol></div><div class="ab cl ns nt gp nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="hb hc hd he hf"><h1 id="4039" class="jn jo hi bd jp jq nz js jt ju oa jw jx io ob ip jz ir oc is kb iu od iv kd ke bi translated">参考:</h1><p id="0a93" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">[1]基肖尔·帕皮涅尼，萨利姆·鲁科斯，托德·沃德，魏-朱婧。(2002 年 7 月)。<em class="mk"> Bleu:一种自动评估机器翻译的方法</em>。</p><p id="b859" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">[2]开尔文·徐、吉米·巴雷、瑞安·基罗斯、赵京贤、亚伦·库维尔、鲁斯兰·萨拉胡季诺夫、理查德·泽梅尔、约舒阿·本吉奥。(2016 年 4 月 19 日)。<em class="mk">展示、出席、讲述:视觉注意的神经图像字幕生成。</em></p><p id="0ae6" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">[3] Minh-Thang Luong，Hieu Pham，Christopher D. Manning。(2015 年 8 月 17 日)。<em class="mk">基于注意力的神经机器翻译的有效方法</em>。</p><p id="8d72" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">[4]阿希什·瓦斯瓦尼、诺姆·沙泽尔、尼基·帕尔马、雅各布·乌兹科雷特、利翁·琼斯、艾丹·戈麦斯、卢卡兹·凯泽、伊利亚·波洛苏欣。(2017 年 6 月 12 日<em class="mk">)。你所需要的只是关注</em>。</p><p id="33cb" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">[5]斯坦福。(2020 年冬)。<a class="ae lb" href="http://web.stanford.edu/class/cs224n/" rel="noopener ugc nofollow" target="_blank"> CS224n:深度学习的自然语言处理</a>。</p><p id="2350" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">[6]杰森·布朗利。(2017 年 7 月 3 日)。<a class="ae lb" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">温和介绍深度学习的 Adam 优化算法</a>。</p><p id="0ccf" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">[7]毛蕾。(2019 年 11 月 17 日)。<a class="ae lb" href="https://leimao.github.io/blog/BLEU-Score/" rel="noopener ugc nofollow" target="_blank">双语评价替角(BLEU) </a>。</p></div></div>    
</body>
</html>