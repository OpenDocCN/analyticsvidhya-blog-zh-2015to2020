<html>
<head>
<title>Machine Learning : K-Nearest Neighbors (Theory Explained)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习:K-最近邻(理论解释)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learing-k-nearest-neighbors-theory-explained-3dfe2fdcdc5d?source=collection_archive---------13-----------------------#2020-09-09">https://medium.com/analytics-vidhya/machine-learing-k-nearest-neighbors-theory-explained-3dfe2fdcdc5d?source=collection_archive---------13-----------------------#2020-09-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/eb8d4e62eae2d56ad0952d67fb2a33cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mgaz7wbrx64wrecEZns-ZA.jpeg"/></div></div></figure><h1 id="6328" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是K-最近邻？</h1><p id="0f06" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">KNN是一种受监督的机器学习算法，可用于回归和分类问题。稍后将解释为什么使用KNN而不是其他算法</p><h1 id="b34c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">K近邻是如何工作的？(分类问题)</h1><p id="2566" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">对我们来说，毫无疑问，机器学习算法需要数据来进行训练。KNN也不例外。<br/>为了解释KNN是如何工作的，我们来看一个例子:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es km"><img src="../Images/b0d9c1796763baad3a09332e238170e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtGYKqP9jnHJf3EORjJ-Cg.png"/></div></div></figure><p id="d895" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">让我们考虑这样一个问题，给定一个人的身高和体重，我们必须对这个人是否适合参军进行分类(抱歉，找不到更好的例子)，并假设图1.1代表了许多人的数据。其中，红色代表健康，蓝色代表不健康。</p><p id="22dd" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">因此，假设一个新的人必须接受这个测试，才能被归类到这些类别之一(健康/不健康)。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/8810ae76c2e18a3ad40b0b96ee726a89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cv2iLcBwCNrHFGHQkk6h1w.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">图1.2</figcaption></figure><p id="b012" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">现在，设新人的身高为H，体重为w，图1.2中的<br/>和<strong class="jq hj">红星</strong>代表这个新人。因此，星星的坐标将是(H，W)</p><p id="54a4" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">在KNN，我们必须手动选择变量名k的值，这将在后面显示。</p><p id="a70d" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">在这种情况下，让我们尝试k=3和k=6: <br/>如果K = 3，我们将在我们的训练集上找到与我们的<strong class="jq hj">红星(新人)最近的3个现有数据点。</strong></p><p id="a1a4" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><strong class="jq hj">如何找到距离新数据点最近的3个点？</strong></p><ol class=""><li id="249b" class="lb lc hi jq b jr kr jv ks jz ld kd le kh lf kl lg lh li lj bi translated">找到<strong class="jq hj">新数据点(H，W) </strong>和训练集中所有其他数据点之间的欧几里德距离，并将它们放入一个数组中</li></ol><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/94f7ba84e26c4eb881ed7824e1173710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*J7ynq1kc67DYlB4U602GgA.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">两个坐标之间的欧几里德距离公式</figcaption></figure><p id="e1c8" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">2.按升序对数组进行排序<br/> 3。获取数组的前3个元素(<em class="ll">因为k=3 </em>)</p><p id="6c3a" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><strong class="jq hj">如何给新人分类？</strong></p><p id="12f5" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">现在我们得到了最接近<strong class="jq hj">红星(新人)坐标的3个数据点，</strong>剩下要做的就是找到这3个数据点所属的类。<br/>如果其中两个属于适合类，另一个属于不适合类，那么我们把新人(红星)归类为适合。如果不是这样，我们就把新人归类为不适合。</p><p id="490c" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><em class="ll">这就是KNN的工作方式。我们实际上是根据相邻数据的主要类别(欧几里德距离)对数据进行分类，因此命名为K最近邻。</em></p><h1 id="ecd6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">K近邻是如何工作的？(回归问题)</h1><p id="6251" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">回归和分类的所有步骤都是一样的，直到得到数组<strong class="jq hj">(如上图)</strong>的<br/>‘K’个元素</p><p id="a267" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">在找到最接近新数据点的K个元素之后。我们取列表中“K”个元素的因变量Y的平均值，该值被指定为新数据点的Y值。</p><p id="af46" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><strong class="jq hj"> <em class="ll">注意:与分类不同，回归输出是回归的连续值，因此我们取数组前“k”个元素的平均值，并将该值指定为新数据的预测值。</em>T3】</strong></p><h1 id="52e2" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">为什么K值很重要？</h1><p id="d0ce" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">K会影响我们模型的准确性，而从中对新数据进行分类的最近邻的数量非常重要<br/>K值非常小会导致过度拟合，K值非常小会导致欠拟合。因此，选择正确的K值非常重要</p><h1 id="029b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">K值如何选择？</strong></h1><p id="4c5f" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">没有完美的方法来选择k的值。但是，它在很大程度上取决于数据集。</p><p id="5967" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">但是，仍然有一些评估指标使事情变得更容易。<br/>使用测试集和损失函数。<br/>因此，损失函数是告诉我们预测值偏离实际值多少的一种度量</p><p id="0b4d" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">对于回归问题，我们可以使用<strong class="jq hj">均方误差损失</strong>，对于分类问题，我们可以根据分类类型使用<strong class="jq hj">二元交叉熵或分类交叉熵损失</strong>。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/0f79e681b8bfb787a2905d3819222388.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*TCE9Kui4fbyZl5u3ARRBJw.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">均方误差</figcaption></figure><p id="7381" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">解释这些损失函数超出了这篇博文的范围。但是，基本要点是，我们可以使用不同的K值，并使用每个值的损失函数来计算损失。<br/>我们最终选择损失最低的K值。</p><h1 id="7ba5" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论</h1><p id="1156" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">因此，KNN是一个简单而有效的算法，因为它非常依赖于其相邻值的坐标，这就是它的工作原理。</p><p id="4302" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><strong class="jq hj">感谢阅读</strong></p></div></div>    
</body>
</html>