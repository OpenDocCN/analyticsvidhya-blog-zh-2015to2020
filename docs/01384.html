<html>
<head>
<title>Object Detection with OpenCV-Python using YOLOv3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用YOLOv3的OpenCV-Python的对象检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/object-detection-with-opencv-python-using-yolov3-481f02c6aa35?source=collection_archive---------1-----------------------#2019-10-19">https://medium.com/analytics-vidhya/object-detection-with-opencv-python-using-yolov3-481f02c6aa35?source=collection_archive---------1-----------------------#2019-10-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es im"><img src="../Images/40196e2fbd52e76a2f120f3878629c7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XEhPJ9UrOqOqoHWS_g8dCw.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">使用YOLOv3算法检测汽车、摩托车和人</figcaption></figure><p id="6c1c" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">大家好。</p><p id="1dd0" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi ka translated">目标检测正在成为计算机视觉中一个引人入胜的应用和研究领域。由于更快的计算能力和先进的算法，我们正在通过使用图像和视频让计算机像人类一样理解。</p><p id="75ca" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在本文中，我们将看到如何使用OpenCV和Python，通过应用最流行的YOLO(你只看一次)算法来检测静态图片中的对象。</p><p id="4c82" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我假设:</p><p id="d87a" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">你对Python有一定的了解，熟悉IDE — Jupyter notebook。你已经了解了卷积神经网络(CNN)的工作原理<em class="kj">(我推荐吴恩达教授在CNN上的课程</em> <a class="ae kk" href="https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning" rel="noopener ugc nofollow" target="_blank"> <em class="kj"> Coursera </em> </a> <em class="kj">进行学习)</em></p><p id="e50a" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">几个澄清:</p><p id="6b3e" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">OpenCV是计算机视觉库/框架，我们将使用它来支持我们的YOLOv3算法。OpenCV内置了对暗网架构的支持。</p><p id="bb08" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">暗网架构是用于分类80个不同类别的预训练模型。我们现在的目标是，我们将在OpenCV中使用Darknet(YOLOv3)来使用Python语言对对象进行分类。</p><p id="5214" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们开始吧。</p><p id="4bc1" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">YOLO是一个物体检测算法<em class="kj">(查看论文出来吧2015 </em> <a class="ae kk" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="kj">这里</em> </a> <em class="kj">)。</em>最新的YOLOv3比基本的YOLO和YOLOv2更强大，比R-CNN等以前的算法更快，也更准确。核心原因是各层的卷积实现，这意味着与需要多次扫描的其他算法相比，它只扫描图像(或帧)一次来进行预测。(卷积的幂。耶！)</p><p id="c9a6" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">设置:</p><p id="daf0" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们需要3个主要文件</p><ol class=""><li id="beea" class="kl km hi je b jf jg jj jk jn kn jr ko jv kp jz kq kr ks kt bi translated">yolo.cfg(从此处<a class="ae kk" href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg" rel="noopener ugc nofollow" target="_blank">下载</a> ) —配置文件</li><li id="55b7" class="kl km hi je b jf ku jj kv jn kw jr kx jv ky jz kq kr ks kt bi translated">yolo.weights(从<a class="ae kk" href="https://pjreddie.com/media/files/yolov3.weights" rel="noopener ugc nofollow" target="_blank">这里</a>下载)——预训练的重量</li><li id="4fc5" class="kl km hi je b jf ku jj kv jn kw jr kx jv ky jz kq kr ks kt bi translated">coco.names(从<a class="ae kk" href="https://github.com/pjreddie/darknet/blob/master/data/coco.names" rel="noopener ugc nofollow" target="_blank">这里下载</a> )- 80个班级名字</li></ol><p id="9acc" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">让我们开始编码:</p><p id="120d" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这里我用的是Jupyter笔记本。</p><p id="110d" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">第一步是导入cv2和numpy库。然后我们通过传递权重和cfg文件使用<strong class="je hj"> cv2.dnn.readNet </strong>加载yolo v3算法。然后，我们将使用coco.names文件加载数组中的所有类名。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es kz"><img src="../Images/8b9a15f9ce7ffecc181a4317356e4d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*95IdjV8Voa7JFJz23w2Z7w.png"/></div></div></figure><p id="8faf" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">接下来我们将定义输出层，因为我们将在那里使用<strong class="je hj">net . getunconnectedoutlayers</strong>和<strong class="je hj"> net.getLayerNames. </strong>来定义要检测的对象</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es la"><img src="../Images/1545a5d643f22f7ffbe4516acd897905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Bu2Gs4s2DLbn6xEiThuaA.png"/></div></div></figure><p id="b4c6" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">接下来让我们加载一个图像。我们将把图像的高度和宽度缩小到40%和30%。并将所有这些值保存在原始图像的<strong class="je hj">高度、宽度、通道</strong>变量中。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es lb"><img src="../Images/139cb9e34f002d18226a21d52e2fc48c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cti0ZTTHnhHjcpLxpDv70g.png"/></div></div></figure><p id="0356" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">要查看图像，请使用下面的代码，但要记住将下面的代码放在文件的末尾。任何代码总是在下面三行的上面。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es lc"><img src="../Images/30d0a8851091785c76c3135bd6642653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TA1VhfzHuPMTPK11yS0EhQ.png"/></div></div></figure><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ld"><img src="../Images/b9cfbcdb31a87a759f6da10f792067e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HaI85Efp4GTrLQv-_Bg_ug.jpeg"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">原象</figcaption></figure><p id="7c9b" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这是我们的原始图像，我们希望从中检测尽可能多的对象。但是我们不能把这个图像直接交给算法。所以我们需要从这个图像做一些转换。这被称为斑点转换，基本上是从图像中提取特征。</p><p id="7580" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们将通过使用<strong class="je hj"> cv2.dnn.blobFromImage </strong>并传递几个变量来检测blob中的对象:<strong class="je hj"> img </strong>是文件名，比例因子为0.00392，要在blob中使用的图像大小为(416，416)，从层中减去平均值为(0，0，0)，设置<strong class="je hj"> True </strong>标志意味着我们将使用红色反转蓝色，因为OpenCV使用BGR，但我们在图像中有通道为RGB。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es le"><img src="../Images/1ed9c28ba7d2091095181a165759be22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x9_JRWePDOJmHkKwfy1WqA.png"/></div></div></figure><p id="bc7a" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">现在让我们通过使用下面的代码来看看3个不同的blobs是什么样子的。我们没有观察到太多的差异，但这是我们将输入到YOLO算法。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es lf"><img src="../Images/0b3f86bbf427f383ade90a3343f46cc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wCqueHge25fUvrvS9xP9_Q.png"/></div></div></figure><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es lg"><img src="../Images/0c787673d64d6b64aac4332006563e29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QthbBNmMveip7Z7WIicg1w.png"/></div></div></figure><p id="a9e6" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们现在使用<strong class="je hj"> net.setInput(blob) </strong>将这个blob传递给网络，然后将它转发给<strong class="je hj"> outputlayers。</strong>此处所有对象都已被检测到，并且<strong class="je hj"> outs </strong>包含我们需要指示提取对象位置的所有信息，如顶部、左侧、右侧、底部位置、类别名称。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es lh"><img src="../Images/65df2a500d92f36a2671873e2d4abe91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3JUx6S0FPT7_W_8FjBklFA.png"/></div></div></figure><p id="b86c" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">现在让我们通过在屏幕上显示信息来评估<strong class="je hj">输出</strong>。主要我们将试图预测置信度，意思是当算法预测某个对象时，它有多有把握。为此，我们将循环通过<strong class="je hj">出局，</strong>首先获得每个<strong class="je hj">出局</strong>的所有<strong class="je hj">分数</strong>。然后获取其中得分最高的<strong class="je hj"> class_id </strong>，然后通过传递<strong class="je hj"> class_id </strong>将<strong class="je hj">置信度</strong>赋给<strong class="je hj">得分</strong>的值。</p><p id="1eea" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">现在，我们将置信度阈值指定为0.5。任何高于0.5的值都意味着检测到物体。设<strong class="je hj">中心x，中心y，w </strong>为宽度，<strong class="je hj"> h </strong>为被检测物体的高度。这里我们将我们先前保存的原始图像的<strong class="je hj">高度、宽度</strong>变量。我们还将在物体的中心画一个厚度为2的圆，只是为了证明物体已经被检测到。</p><p id="9cf3" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">进一步让我们通过使用<strong class="je hj"> center_x，center_y，w，h </strong>在被检测对象周围绘制矩形。并附加一些信息到像<strong class="je hj">类，信心。</strong></p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es lb"><img src="../Images/f5c17b8a47e80a86862052955e4ba2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a-R0AwKEq07INdVxy-fYAQ.png"/></div></div></figure><p id="39b0" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">运行上面的代码会产生以下输出。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es li"><img src="../Images/dc0e0472c05cf80a043dfc7d70daa8c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NbSOSVH8hgXp5wAipvDG7g.png"/></div></div></figure><p id="cf47" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">可能会有这样的情况，同一个对象可能会被多次检测到，如下所示。(在我上面的测试图像中，没有检测到多个对象，所以我使用下面的不同图像来显示该场景)。您可以看到笔记本电脑和显示器各检测到两个框。我们想消除这种情况。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es lj"><img src="../Images/3a9bd4159ba7f4e7ddd11a3c4bfb8162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t3b5Ez0bRXU-xg9OZbm32g.png"/></div></div></figure><p id="82c6" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">为了消除这种情况，我们将使用非最大抑制(NMS)功能。这将通过使用某个阈值(任何具有小于0.6的值的框将被移除)来消除框，并且它确定仅保留所有框中最好的。并且<strong class="je hj">索引</strong>变量将跟踪这种被检测到的独特物体。因此不会多次检测到相同的对象。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es lk"><img src="../Images/c82a3f2d96f84d413802aa30465e0d94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BL7CKlQRMoXITTrRb5tiDw.png"/></div></div></figure><p id="aabb" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">现在使用下面的循环遍历所有找到的<strong class="je hj">框</strong>，如果框出现在<strong class="je hj">索引</strong>中，那么只画一个矩形，给它上色，在上面放上类名文本。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ll"><img src="../Images/3f160d6e1c86c00ee7ae460861d343b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ta7fJ8noWpLWeN7ha2d1FQ.png"/></div></div></figure><p id="68ed" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">最终输出将类似于这样。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es li"><img src="../Images/39842d0e23a674447e3318abe5a0f8e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Njh0-rrNxqhu_p6ccZj5oQ.png"/></div></div></figure><p id="eae1" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">因此，我们从测试图像中检测出汽车、人和摩托车。</p><p id="2d71" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">哇哦。我想这很难接受。</p><p id="6837" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">但我希望这将有助于实现yolov3算法。我试图让初学者的心态可以理解。如果您有任何问题或意见，请告诉我。</p><p id="96f8" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">回旋石！</p><p id="f16f" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">快乐学习！</p><p id="35f0" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">谢了。</p><p id="d958" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">【你可以在<a class="ae kk" href="https://github.com/darshanadakane/yolov3_objectdetection" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到完整的代码。喜欢就明星。谢谢]</p><p id="6878" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><em class="kj">(在下一篇文章中，我将展示如何使用网络摄像头和YOLOv3算法实时检测物体)</em></p></div></div>    
</body>
</html>