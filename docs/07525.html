<html>
<head>
<title>Basic Web Scraping</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基本网页抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/basic-web-scraping-d6bb44118304?source=collection_archive---------27-----------------------#2020-06-28">https://medium.com/analytics-vidhya/basic-web-scraping-d6bb44118304?source=collection_archive---------27-----------------------#2020-06-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="1fef" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">只知道基本原理就能让你去任何地方。</h2></div><p id="04c1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">网络搜集为处理你最感兴趣的数据提供了如此多的机会，而且比你想象的要容易。一个人对他们正在处理的数据的兴趣可以决定一个项目的成败，这对于他们的学习动机有很大的影响。这个简单的工具可以帮助你获取真正有助于你学习的数据。</p><p id="984f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">读完这篇文章后，你应该能够将基本的网络抓取付诸实践，这将让你获得80%的数据。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="6f25" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你不知道什么是网络抓取，那都是在名义上。你编写一个程序，<em class="ka">从网站上抓取</em>数据，从中你可以提取某些信息，形成你自己的数据集。</p><p id="0c0a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">web抓取有两个常见的标准python包，being Requests和BeautifulSoup。当然，还有许多其他的软件包，但是这两个是我将重点关注的，因为它们非常流行并且简单易用。</p><p id="5625" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Requests允许您简单地通过HTTP请求从任何网页获取信息。BeautifulSoup允许您从请求中提取想要的信息。</p><p id="0fed" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我将简要介绍一下基本知识，然后通过搜集Genius上流行的十大歌曲的歌词，向您展示一个我如何学会使用它们的例子。</p><h1 id="9d15" class="kb kc hi bd kd ke kf kg kh ki kj kk kl io km ip kn ir ko is kp iu kq iv kr ks bi translated">基本概述</h1><h2 id="f739" class="kt kc hi bd kd ku kv kw kh kx ky kz kl jg la lb kn jk lc ld kp jo le lf kr lg bi translated">要求</h2><p id="7e60" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">下面是分别为pip和conda安装请求的命令。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="eaa5" class="kt kc hi lr b fi lv lw l lx ly">pip install requests</span><span id="02b2" class="kt kc hi lr b fi lz lw l lx ly">conda install -c anaconda requests</span></pre><p id="7c6d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面这简单的两行已经可以让你开始抓取网页了。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="062c" class="kt kc hi lr b fi lv lw l lx ly">import requests</span><span id="08ef" class="kt kc hi lr b fi lz lw l lx ly">page = requests.get(url)</span></pre><p id="7e27" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第二行将HTTP请求的结果返回到您的URL，然后您可以从中提取信息。</p><h2 id="7238" class="kt kc hi bd kd ku kv kw kh kx ky kz kl jg la lb kn jk lc ld kp jo le lf kr lg bi translated">美丽的声音</h2><p id="0092" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">要安装BeautifulSoup，下面分别是pip和conda的命令。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="b6da" class="kt kc hi lr b fi lv lw l lx ly">pip install beautifulsoup4</span><span id="9097" class="kt kc hi lr b fi lz lw l lx ly">conda install -c anaconda beautifulsoup4</span></pre><p id="ed72" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过这些行，您可以访问您想要从网站上获取的特定信息。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="3889" class="kt kc hi lr b fi lv lw l lx ly">from bs4 import BeautifulSoup</span><span id="e71a" class="kt kc hi lr b fi lz lw l lx ly">soup = BeautifulSoup(page.content, 'html.parser')</span><span id="91b5" class="kt kc hi lr b fi lz lw l lx ly">soup.find_all(tag)</span><span id="e9a6" class="kt kc hi lr b fi lz lw l lx ly">tag_element.get(property)<br/>tag_element.text</span></pre><p id="0efd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">HTTP请求包含各种信息，但是我们使用内容(对应于HTML)来创建一个漂亮的组对象。我们还传入了一个解析器，因为BeautifulSoup对象表示一个经过解析的HTML文档。这个BeautifulSoup对象具有某些方法和属性，可以让我们轻松地提取信息。</p><p id="7395" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">find_all方法返回指定标签的元素列表。还有其他可选参数，比如class，它允许我们进一步指定希望它返回哪些元素。这些元素有我们可以从中获取信息的方法和属性。</p><p id="1414" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这只是为了对代码的样子有一个大致的了解，所以如果还没有完全理解，也不要担心。在本文后面的实际操作中使用它们将会把我们放下的难题拼凑起来。</p><h2 id="f6d8" class="kt kc hi bd kd ku kv kw kh kx ky kz kl jg la lb kn jk lc ld kp jo le lf kr lg bi translated">基本网页抓取过程</h2><ol class=""><li id="ed36" class="ma mb hi iz b ja lh jd li jg mc jk md jo me js mf mg mh mi bi translated">找到您想要提取的数据。</li><li id="d46c" class="ma mb hi iz b ja mj jd mk jg ml jk mm jo mn js mf mg mh mi bi translated">使用网站的URL发出HTTP请求。</li><li id="5345" class="ma mb hi iz b ja mj jd mk jg ml jk mm jo mn js mf mg mh mi bi translated">将其HTML提取到一个BeautifulSoup对象中。</li><li id="94b4" class="ma mb hi iz b ja mj jd mk jg ml jk mm jo mn js mf mg mh mi bi translated">在HTML中筛选，找到包含所需信息的元素。</li><li id="14c7" class="ma mb hi iz b ja mj jd mk jg ml jk mm jo mn js mf mg mh mi bi translated">从这些元素中提取信息。</li><li id="7580" class="ma mb hi iz b ja mj jd mk jg ml jk mm jo mn js mf mg mh mi bi translated">将数据存储在数据集中。</li></ol><h1 id="0cb1" class="kb kc hi bd kd ke kf kg kh ki kj kk kl io km ip kn ir ko is kp iu kq iv kr ks bi translated">示例:从Genius中提取歌词</h1><p id="cb84" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">就在一两年前，当我刚开始接触数据科学项目和文章时，我一直认为分析歌曲的歌词太酷了。然而，与此同时，它感觉完全遥不可及，我对人们如何着手获取数据感到困惑。现在才知道其实挺简单的。在这个例子中，我们将从Genius上流行的前十首歌曲中抓取歌词。</p><p id="004d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从导入我们最喜欢的包开始。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="38fc" class="kt kc hi lr b fi lv lw l lx ly">import requests<br/>from bs4 import BeautifulSoup</span></pre><p id="2ea1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后让我们实际上找到保存这十首歌曲的页面的URL。</p><figure class="lm ln lo lp fd mp er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mo"><img src="../Images/44919b35d39792be9645d2a9a5fffe19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o5PI3z8A48MI2k858F1R2w.png"/></div></div><figcaption class="mw mx et er es my mz bd b be z dx translated">genius.com截图</figcaption></figure><p id="f55a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">经过大约2秒钟的滚动，我发现他们实际上只是在主页上，所以网址是"https://genius.com/"。</p><p id="3a6d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们把它放到我们的函数中来获取网页的HTTP请求信息。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="be21" class="kt kc hi lr b fi lv lw l lx ly">home_page = requests.get(‘https://genius.com/')</span></pre><p id="ff21" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们可以开始打开页面，通过将HTML分解成一个BeautifulSoup对象来获取这些歌曲歌词的链接。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="d732" class="kt kc hi lr b fi lv lw l lx ly">home_html = BeautifulSoup(home_page.content, ‘html.parser’)</span></pre><p id="2779" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们有了一个BeautifulSoup对象，我们可以用find_all方法访问它的元素。在我们这样做之前，我们实际上必须查看页面的HTML以找到要挑选的正确元素。</p><p id="be23" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你既可以按ctrl+shift+i，也可以点击谷歌Chrome右上角的三个点→更多工具→开发者工具，它应该会在边上打开网页的源代码。你需要对文本进行一些筛选，但至少在Chrome中，浏览器会通过在页面上突出显示HTML的每个元素在页面上对应的内容来帮助指导你。打开几个div后，我发现我的链接在哪里。</p><figure class="lm ln lo lp fd mp er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es na"><img src="../Images/caa46a59a13d5f18c07eff6b7fe2d2ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LGVD7AZVGc4c-7b2wUNiFQ.png"/></div></div><figcaption class="mw mx et er es my mz bd b be z dx translated">genius.com及其源代码的截图。这显示了在示例中找到链接的样子。</figcaption></figure><p id="5b7d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Genius在这里有一些奇怪的div，但是我们仍然可以看出这个元素对应于第一行。这里我们可以看到链接，更重要的是，我们可以看到保存我们信息的元素的类型——以及它的类。我们可以利用这些信息来挑选出所有这些元素。</p><p id="4511" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">链接在' a '标记中，它的类是' PageGriddesktop-a6v 82 w-0 ChartItemdesktop _ _ Row-sc-3 bmioe-0 qsIlk '。我确保检查了接下来的几个元素，看看我们实际上要检索的不仅仅是这一个链接，而是这种类型的所有链接，然后我把它扔进了我的函数。这个类可能看起来有点复杂，但对我们的目的来说这无关紧要，因为我们只需要用它来区分我们想要的“a”元素和页面上的其余“a”元素。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="3110" class="kt kc hi lr b fi lv lw l lx ly">links = home_html.find_all(‘a’, class_=’PageGriddesktop-a6v82w-0 ChartItemdesktop__Row-sc-3bmioe-0 qsIlk’)</span></pre><p id="dc94" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们有了链接，我们可以试着从其中一个页面获取歌词，最后，对其余的页面重复同样的过程。</p><p id="74b8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们通过访问存储链接的“href”属性从“a”元素获取链接。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="73d1" class="kt kc hi lr b fi lv lw l lx ly">url = links[0].get(‘href’)</span></pre><p id="aa71" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">附注:到目前为止，我们几乎已经完成了网页抓取的全面运行；我们用我们的程序从一个网站上检索了信息。然而，我喜欢这个例子，因为我们再次运行它，但以稍微不同的方式，并希望通过重复这个过程获得完整的理解。</p><p id="ae4f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们可以从该页面中找到信息，并将其转换为一个漂亮的Soup对象。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="928b" class="kt kc hi lr b fi lv lw l lx ly">lyrics_page = requests.get(url)<br/>lyrics_html = BeautifulSoup(lyrics_page.content, ‘html.parser’)</span></pre><p id="a57b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后我们仔细检查这个页面的HTML，发现歌词在一个“div”元素中，这个元素有一个更方便命名的类“lyrics”。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="edfe" class="kt kc hi lr b fi lv lw l lx ly">lyrics_div = lyrics_html.find_all(‘div’, class_=’lyrics’)</span></pre><p id="6ada" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这实际上是这个类唯一的div，我们可以像这样获取歌词并将其拆分到各自的行中。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="5c1a" class="kt kc hi lr b fi lv lw l lx ly">lyrics = lyrics_div[0].text<br/>lines = lyrics.split(‘\n’)</span></pre><p id="3bdf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们可以循环每个链接的前几行代码，得到这个。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="38f8" class="kt kc hi lr b fi lv lw l lx ly">song_lyrics = {}</span><span id="833a" class="kt kc hi lr b fi lz lw l lx ly">for i in range(len(links)):<br/>    url = links[i].get(‘href’)</span><span id="67fc" class="kt kc hi lr b fi lz lw l lx ly">    lyrics_page = requests.get(url)<br/>    lyrics_html = BeautifulSoup(lyrics_page.content, ‘html.parser’)</span><span id="604c" class="kt kc hi lr b fi lz lw l lx ly">    # get song lyrics<br/>    lyrics_div = lyrics_html.find_all(‘div’, class_=’lyrics’)<br/>    lyrics = lyrics_div[0].text<br/>    lines = lyrics.split(‘\n’)</span><span id="f567" class="kt kc hi lr b fi lz lw l lx ly">    # get song title<br/>    title_elements = lyrics_html.find_all(‘h1’, class_=’header_with_cover_art-primary_info-title’)<br/>    title = title_elements[0].text</span><span id="dcd2" class="kt kc hi lr b fi lz lw l lx ly">    song_lyrics[title] = lines</span></pre><p id="521c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这样，我们将每首歌的歌词列表存储在了一个字典中。我们可以通过显示每首歌曲及其前几行来检查我们的结果。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="8f65" class="kt kc hi lr b fi lv lw l lx ly">for song in song_lyrics:<br/>    print (song, song_lyrics[song][:4])</span></pre><figure class="lm ln lo lp fd mp er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es nb"><img src="../Images/fd2c2535d7fdded8899b6dccb4b44d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cgXBzkV7TLB24o2biNwlvQ.png"/></div></div><figcaption class="mw mx et er es my mz bd b be z dx translated">从Genius排行榜上刮下来的十首歌的前几行</figcaption></figure><p id="ee4a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽管在进一步使用它之前，显然还有一些清理工作要做，但这表明我们做了所有我们想做的事情。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="5e2f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我希望您能够将数据科学工作流程的更多部分掌握在自己手中。你不必再仅仅依赖Kaggle和手工制作的数据集，你可以处理你在网上找到的几乎任何有趣的数据。到目前为止，它对我自己的旅程产生了很大的影响，我希望它对你也有影响。</p></div></div>    
</body>
</html>