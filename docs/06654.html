<html>
<head>
<title>How to Handle Missing Values?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何处理缺失值？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-handle-missing-values-byaryan-cb76b9dbaae2?source=collection_archive---------8-----------------------#2020-05-29">https://medium.com/analytics-vidhya/how-to-handle-missing-values-byaryan-cb76b9dbaae2?source=collection_archive---------8-----------------------#2020-05-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5845" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kickstarter实践指南。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/188e54a69d2943052f459671005b40e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aTwZq7ceSHClNuAconBNig.jpeg"/></div></div></figure><p id="51a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<a class="ae jp" href="https://blog.usejournal.com/intro-to-machine-learning-part2-byaryan-4dd7f20f4a19?source=friends_link&amp;sk=aec114377221595b9b0f46612441a49d" rel="noopener ugc nofollow" target="_blank">之前的</a>文章中，我承诺讨论如何处理缺失的价值观！</p><p id="aa39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我们将讨论不同的策略来应对缺失的价值观。您将学习在任何给定或大部分数据集上比较这些方法的有效性。</p><h1 id="5ebf" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">介绍</h1><p id="6d4d" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">根据维基百科，“在统计学中，<strong class="ih hj">缺失数据</strong>，或者<strong class="ih hj">缺失值</strong>，发生在没有数据值存储在观察变量中的时候。缺失数据是一种常见现象，会对从数据中得出的结论产生重大影响。”</p><p id="d1aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于各种原因，许多现实世界的数据集包含缺失值，通常编码为<strong class="ih hj">空格</strong>、<strong class="ih hj"> NaNs </strong>或其他<strong class="ih hj">占位符</strong>。</p><p id="e14d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据可以通过多种方式合并缺失值。例如在住房数据中:</p><ul class=""><li id="0700" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">一个一居室的房子不会包括第二个卧室有多大的答案。</li><li id="147b" class="kt ku hi ih b ii ld im le iq lf iu lg iy lh jc ky kz la lb bi translated">房主可能不想分享他们的收入。</li></ul><p id="1864" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Python库将缺失的数字表示为<strong class="ih hj"> nan </strong>，这是“<strong class="ih hj">不是数字</strong>”的缩写。然而，包含<strong class="ih hj"> nan </strong>值的数据集与<strong class="ih hj"> Sklearn </strong>估计器不一致，后者假设数组中的所有值都是数字，并且都有意义，因此可以对它们应用数学运算。</p><p id="0cb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用包含缺失值的数据集的一个基本策略是丢弃包含缺失值的整行和/或整列。然而，这是以丢失可能很重要(即使不完整)的有价值的数据为代价的。一个更好的策略是填充缺失值，即从没有缺失的数据部分估计它们。</p><p id="7456" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以使用以下命令找出哪些单元格缺少值，以及每列中缺少值的百分比:</p><pre class="je jf jg jh fd li lj lk ll aw lm bi"><span id="ee3a" class="ln jr hi lj b fi lo lp l lq lr">def missingcheck(data):<br/> total = data.isnull().sum().sort_values(ascending=False)<br/> percent_1 = data.isnull().sum()/data.isnull().count()*100<br/> percent_2 = (np.round(percent_1, 1)).sort_values(ascending=False)<br/> missing_data = pd.concat([total, percent_2], axis=1, keys=[‘Total’, ‘%’])<br/> return missing_data</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ls"><img src="../Images/e25f3bfd5fdfa961dd2d0a95f5090c4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M67FfB72xed6LKWUVbmK0w.png"/></div></div></figure><p id="89d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所有这些代码都存在于Github库<a class="ae jp" href="https://github.com/aryanc55/MLIn10Minutes" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">mlin 10 minutes</strong></a>！</p><h2 id="51d4" class="ln jr hi bd js lt lu lv jw lw lx ly ka iq lz ma ke iu mb mc ki iy md me km mf bi translated">此外，分离数字属性和分类属性</h2><p id="5574" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">因为会影响我们对于缺失值处理会遵循的策略！您可以分别处理缺失的值，然后将它们连接在一起！但是为了使这篇文章简洁易懂，我将只继续讨论数值。</p><h1 id="18d6" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">函数来评估每种方法的准确性</h1><p id="0f5a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我们定义了一个函数<em class="lc"> score_dataset() </em>来比较处理缺失值的不同方法。该函数报告随机森林模型的<a class="ae jp" href="https://en.wikipedia.org/wiki/Mean_absolute_error" rel="noopener ugc nofollow" target="_blank">平均绝对误差</a> (MAE)。</p><pre class="je jf jg jh fd li lj lk ll aw lm bi"><span id="15ac" class="ln jr hi lj b fi lo lp l lq lr">from sklearn.ensemble import RandomForestRegressor<br/>from sklearn.metrics import mean_absolute_error</span><span id="5e4a" class="ln jr hi lj b fi mg lp l lq lr"># Function for comparing different approaches<br/>def score_dataset(X_train, X_valid, y_train, y_valid):<br/> RFr = RandomForestRegressor(n_estimators=150, random_state=42)<br/> RFr.fit(X_train, y_train)<br/> preds = RFr.predict(X_valid)<br/> return mean_absolute_error(y_valid, preds)</span></pre><h1 id="6929" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">1)一种简单的方法:删除缺少值的列</h1><p id="9260" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">最基本的选择是删除缺少值的列。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mh"><img src="../Images/ea647e8fc244acb152ec32e0b9f4df80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sQfI7FiG7ZIo3Axm.png"/></div></div><figcaption class="mi mj et er es mk ml bd b be z dx translated">来源:Kaggle</figcaption></figure><p id="caa4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">除非删除的列中的大多数值都丢失了，否则模型将无法访问大量(也许有用！)信息用这种方法。作为一个极端的例子，考虑一个有20，000行的数据集，其中一个重要的列只缺少一个条目。这种方法会删除整个列！</p><pre class="je jf jg jh fd li lj lk ll aw lm bi"><span id="6a25" class="ln jr hi lj b fi lo lp l lq lr">#get names of columns with missing values<br/>cols_with_missing = [col for col in X_train.columns<br/> if X_train[col].isnull().any()]<br/># drop columns in training and validation data<br/>reduced_X_train = X_train.drop(cols_with_missing, axis=1)<br/>reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mm"><img src="../Images/21d6ac83ce6c717bb5e50bfe632fec35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jdlK4WZHkJl8RgtmNEIMpg.png"/></div></div></figure><h1 id="852c" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">2)更好的选择:单变量插补</h1><p id="e5c2" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><strong class="ih hj">插补</strong>用某个数字填充缺失值。例如，我们可以沿着每个<strong class="ih hj">列</strong>填入<strong class="ih hj">平均值</strong>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mh"><img src="../Images/267025b7bc9aa27723699a0da164824d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ju-M3Mmu-wLeclm_.png"/></div></div><figcaption class="mi mj et er es mk ml bd b be z dx translated">来源:Kaggle</figcaption></figure><p id="8549" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在大多数情况下，估算值不会完全正确，但它通常会比完全删除列得到更好的模型。</p><p id="f022" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<a class="ae jp" href="https://scikit-learn.org/stable/modules/impute.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>中给出的一种插补算法是<strong class="ih hj">单变量</strong>，</p><p id="5088" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">"<em class="lc">仅使用第I个特征维度中的非缺失值来估算该特征维度中的值"</em>(例如，估算。简单输入器)。</p><p id="9d64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">sklearn包中的<strong class="ih hj">simple imputr</strong>提供了输入缺失值的基本策略。缺失值可以使用提供的<strong class="ih hj">常量值</strong>进行估算，或者使用缺失值所在的每一列的<strong class="ih hj">统计数据</strong>(平均值、中值或最频繁值)。</p><p id="ff89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的代码片段演示了如何替换丢失的值:</p><pre class="je jf jg jh fd li lj lk ll aw lm bi"><span id="1a20" class="ln jr hi lj b fi lo lp l lq lr">from sklearn.impute import SimpleImputer<br/># imputation<br/>simple_imputer = SimpleImputer()</span><span id="7658" class="ln jr hi lj b fi mg lp l lq lr">imputed_X_train= pd.DataFrame(simple_imputer.fit_transform(X_train))</span><span id="62df" class="ln jr hi lj b fi mg lp l lq lr">imputed_X_valid = pd.DataFrame(simple_imputer.transform(X_valid))</span><span id="c59e" class="ln jr hi lj b fi mg lp l lq lr"># imputation removed column names; put them back<br/>imputed_X_train.columns = X_train.columns<br/>imputed_X_valid.columns = X_valid.columns</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mn"><img src="../Images/23cad2c3628730eeab9ef5a7f7ecc21d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_eiVZLZvA_DkhY4qdEmRyA.png"/></div></div></figure><p id="351e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">记住，我告诉过你，我们对于数字和分类属性的策略是不同的。观察你自己，如果列有分类数据，如“高”、“中”、“低”，就不能使用平均值。</p><p id="5edd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当使用<em class="lc">‘most _ frequency’</em>或<em class="lc">‘constant’</em>策略时，SimpleImputer类还支持表示为字符串值或<em class="lc">pandas categories</em>的分类数据。</p><h1 id="9f12" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">3)另一种选择:多元插补</h1><p id="98ab" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">正如在<em class="lc"> Sklearn </em>文档中所定义的，“多变量估算器，从所有其他特征中估算每个特征。<em class="lc">一种输入缺失值的策略，通过以循环方式将具有缺失值的每个特征建模为其他特征的函数</em>。</p><p id="fdac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种更先进的方法在<strong class="ih hj">迭代估算器</strong>类中实现，该类将每个具有缺失值的特征建模为其他特征的函数，并使用该估算值进行估算。它以循环迭代的方式实现:在每一步，一个特征列被指定为输出<strong class="ih hj"> <em class="lc"> y </em> </strong>，其他特征列被视为输入<strong class="ih hj"> <em class="lc"> X </em> </strong>。已知<strong class="ih hj"> <em class="lc"> y </em> </strong>的<em class="lc"> (X，y) </em> 上拟合一个<strong class="ih hj">回归量</strong>。然后用回归器<strong class="ih hj">预测</strong>yT31<strong class="ih hj">的<strong class="ih hj">缺失</strong>值。对每个特征进行迭代，然后对<em class="lc"> max_iteration </em>插补轮次进行重复。返回最后一轮插补的结果。</strong></p><p id="4fef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是代码片段:</p><pre class="je jf jg jh fd li lj lk ll aw lm bi"><span id="6fae" class="ln jr hi lj b fi lo lp l lq lr">br_imputer = IterativeImputer(BayesianRidge()) <br/>imputed_X_train = pd.DataFrame(br_imputer.fit_transform(X_train))</span><span id="911c" class="ln jr hi lj b fi mg lp l lq lr">imputed_X_valid = pd.DataFrame(br_imputer.transform(X_valid))</span><span id="0a44" class="ln jr hi lj b fi mg lp l lq lr"># imputation removed column names; put them back<br/>imputed_X_train.columns = X_train.columns<br/>imputed_X_valid.columns = X_valid.columns</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mm"><img src="../Images/a92e4807acf49b45b8075a8d74c91b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F2i-CKA67J08AB6xmxfY2g.png"/></div></div></figure><p id="8eb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以在迭代估算器中使用的一些估算器:</p><ul class=""><li id="1b14" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated"><code class="du mo mp mq lj b"><a class="ae jp" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">BayesianRidge</strong></a></code>:正则化线性回归</li><li id="d4fa" class="kt ku hi ih b ii ld im le iq lf iu lg iy lh jc ky kz la lb bi translated"><code class="du mo mp mq lj b"><a class="ae jp" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">DecisionTreeRegressor</strong></a></code>:非线性回归</li><li id="56f1" class="kt ku hi ih b ii ld im le iq lf iu lg iy lh jc ky kz la lb bi translated"><code class="du mo mp mq lj b"><a class="ae jp" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">ExtraTreesRegressor</strong></a></code>:类似于R中的missForest</li><li id="aa44" class="kt ku hi ih b ii ld im le iq lf iu lg iy lh jc ky kz la lb bi translated"><code class="du mo mp mq lj b"><a class="ae jp" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">KNeighborsRegressor</strong></a></code>:与其他KNN插补方法相当</li></ul><p id="ba5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<strong class="ih hj"> R数据科学生态系统中有很多成熟的插补包:Amelia、mi、mice、missForest </strong>等。</p><p id="91a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">顺序插补算法可以有很多种变化，都可以在<strong class="ih hj">中绕过<code class="du mo mp mq lj b"><a class="ae jp" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">IterativeImputer</strong></a></code>不同的回归元</strong>来实现，用于预测缺失的特征值。</p><p id="6231" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在流行的missForest方法的情况下，这个回归量是一个随机森林。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mr"><img src="../Images/3a32d01d6690e2978e406e9957aa9cc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ULFqs9HqJjcvV1rg.png"/></div></div><figcaption class="mi mj et er es mk ml bd b be z dx translated">加州房屋数据集上各种插补策略的比较。来源:Scikit-learn</figcaption></figure><h1 id="fa8b" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">4)最近邻插补</h1><p id="3923" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><em class="lc"> k最近邻算法</em>可用于输入缺失数据，方法是找到具有缺失数据的观测值的<em class="lc"> k最近邻</em>，然后基于邻中的非缺失值输入它们。</p><p id="d1ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对此有几种可能的策略。可以使用<strong class="ih hj"> 1NN </strong>，其中我们搜索<em class="lc">最相似的邻居</em>，然后使用它的值来替换丢失的数据。</p><p id="3002" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">或者，我们可以使用<strong class="ih hj"> kNN </strong>和<em class="lc"> k个邻居</em>并计算邻居的<strong class="ih hj">平均值</strong>，或<strong class="ih hj">加权平均值</strong>、<em class="lc">，其中到邻居的距离被用作权重</em>，因此邻居越近，在计算平均值时其权重越大。使用最常用的加权平均技术。</p><p id="4de6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> KNNimputer </strong>类使用<strong class="ih hj"> k最近邻</strong>方法提供填充缺失值的插补。它使用支持缺失值的欧几里德距离度量。它被称为<em class="lc"> nan_euclidean_distance </em>，用于查找最近的邻居。</p><p id="c417" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lc">注</em> </strong>根据官方文档:“<code class="du mo mp mq lj b"><a class="ae jp" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="lc">sklearn.neighbors.KNeighborsRegressor</em></strong></a></code> <em class="lc">与KNN插补不同，后者是通过使用一种考虑缺失值的距离度量从缺失值的样本中学习，而不是对其进行插补。</em></p><p id="81b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是一段代码:</p><pre class="je jf jg jh fd li lj lk ll aw lm bi"><span id="c8a9" class="ln jr hi lj b fi lo lp l lq lr">knn_imputer = KNNImputer(n_neighbors=2, weights=”uniform”)</span><span id="b0e3" class="ln jr hi lj b fi mg lp l lq lr">imputed_X_train = pd.DataFrame(knn_imputer.fit_transform(X_train))</span><span id="98d4" class="ln jr hi lj b fi mg lp l lq lr">imputed_X_valid = pd.DataFrame(knn_imputer.transform(X_valid))</span><span id="cc05" class="ln jr hi lj b fi mg lp l lq lr"># imputation removed column names; put them back<br/>imputed_X_train.columns = X_train.columns<br/>imputed_X_valid.columns = X_valid.columns</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ms"><img src="../Images/0786c2d29a402c7f18602844b420e6af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RAQOYP1e-bbzSrnlyhcNzg.png"/></div></div></figure><h1 id="60e5" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">5)无法估算</h1><p id="b830" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">插补是一种广为接受的方法，通常效果很好。但是，估算值可能会排列在其实际值(未收集在数据集中)的下方或上方。或者缺失的行值可能在其他方面有所不同。在这种情况下，通过考虑最初缺少哪些值，您的模型会表现得更好。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mh"><img src="../Images/c2786ddb95c690236310eaee95435b91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jZVbGy3P66r6srO-.png"/></div></div></figure><p id="456d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种方法中，和以前一样，我们估算缺失值。然后，对于原始数据集中缺少条目的每一列，我们添加一个新列来标记估算条目的位置。</p><pre class="je jf jg jh fd li lj lk ll aw lm bi"><span id="ffe6" class="ln jr hi lj b fi lo lp l lq lr">imputed_X_train_plus = X_train.copy()<br/>imputed_X_test_plus = X_valid.copy()</span><span id="c29c" class="ln jr hi lj b fi mg lp l lq lr">cols_with_missing = (col for col in X_train.columns <br/> if X_train[col].isnull().any())<br/>for col in cols_with_missing:<br/> imputed_X_train_plus[col + ‘_was_missing’] = imputed_X_train_plus[col].isnull()<br/> imputed_X_test_plus[col + ‘_was_missing’] = imputed_X_test_plus[col].isnull()<br/>#see what happend to the dataset<br/>imputed_X_train_plus.head()</span><span id="2a7a" class="ln jr hi lj b fi mg lp l lq lr"># And now we Imputation<br/>my_imputer = SimpleImputer()<br/>imputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)<br/>imputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mt"><img src="../Images/808b9db7f61dab40545e5c321487fd2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MG_eZtG0anigR5r1zJSt6Q.png"/></div></div></figure><p id="b54b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在某些情况下，这将有意义地改善结果。其他情况下，一点帮助都没有。</p><h1 id="97b9" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">6)不能是缺失值！</h1><p id="8c1b" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">等等，什么？</p><p id="6f31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">是的，你认为丢失的值可能并不是丢失的值。这可能是由于NA(不可用)编码混乱或我们对它的解释有误。例如:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mu"><img src="../Images/9f049e56583362cab08e6589b41595ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*RWL6pDxGULfNZuGOW5ZJzw.png"/></div></figure><p id="0717" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> PoolQC </strong>:数据描述说<strong class="ih hj"> NA </strong>的意思是“<strong class="ih hj">无池</strong>”。这是有道理的，考虑到巨大的失踪价值比率(+99%)，而且大多数房子一般都没有游泳池。</p><p id="37ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样的道理也适用于<strong class="ih hj">栅栏</strong>和<strong class="ih hj">杂项</strong>，因为这些房屋可能没有任何栅栏或杂项特征。</p><h1 id="7edf" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">那有什么条件呢？</h1><p id="7374" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><em class="lc">数据科学的人认为这是对研究者的批判“风格”如何处理的问题。即使有人想做野蛮的均值/中值/众数替换或者删除它们，也没有“一般”的对错。没事的。</em></p><p id="43d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人们可以比较MAE来选择最好的结果。可以进行多次插补，并且应对每个变异结果进行分析。例如，在均值、中值或众数之外应该选择什么。在迭代估算中，应该使用什么样的估计量，甚至在KNNimputer中，k的值应该是多少？</p><p id="fbd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个人的估算方法是"<strong class="ih hj"> <em class="lc">不伤害</em> </strong>"让你的算法学会，这就是简单估算策略的全部。但是，每种情况都是不同的，所以你必须尝试不同的方法，如果你有足够的数据，通过测试集和验证集来验证它们。</p><p id="70c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所有这些都依赖于<em class="lc">数据集和问题的领域</em>。仅仅是你的<em class="lc">直觉</em>会引导你选择<em class="lc">最适合的方法</em>！</p><p id="d4ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你喜欢这篇文章，那就按下按钮吧。对更多的帖子感兴趣吗？确保按照这个系列<a class="ae jp" href="https://github.com/aryanc55/MLIn10Minutes" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">mlin 10分钟</strong> </a>。</p><p id="04ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">欢迎留言提问！你也可以<a class="ae jp" href="https://www.instagram.com/bdcoe/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> DM </strong> </a>你的疑惑。</p><h1 id="93a3" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">确认:</h1><ul class=""><li id="14e0" class="kt ku hi ih b ii ko im kp iq mv iu mw iy mx jc ky kz la lb bi translated"><a class="ae jp" href="https://en.wikipedia.org/wiki/Missing_data" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Missing_data</a></li><li id="043f" class="kt ku hi ih b ii ld im le iq lf iu lg iy lh jc ky kz la lb bi translated"><a class="ae jp" href="https://leandeep.com/datalab-kaggle/handling-missing-values.html" rel="noopener ugc nofollow" target="_blank">https://lean deep . com/data lab-ka ggle/handling-missing-values . html</a></li><li id="0ef5" class="kt ku hi ih b ii ld im le iq lf iu lg iy lh jc ky kz la lb bi translated"><a class="ae jp" href="https://scikit-learn.org/stable/modules/impute.html" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/modules/impute.html</a></li><li id="9d59" class="kt ku hi ih b ii ld im le iq lf iu lg iy lh jc ky kz la lb bi translated"><a class="ae jp" href="https://stats.stackexchange.com/questions/327074/k-nearest-neighbor-imputation-explanation" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/327074/k-最近邻-插补-解释</a></li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="ab fe cl my"><img src="../Images/f6ae63a547653638887058049ac934ec.png" data-original-src="https://miro.medium.com/v2/format:webp/1*QdGP-3h_5MF2tCYz3w3VWQ.png"/></div></figure></div></div>    
</body>
</html>