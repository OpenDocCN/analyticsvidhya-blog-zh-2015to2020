<html>
<head>
<title>Maximum Likelihood Estimation -Conceptual understanding using an example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最大似然估计-用一个例子理解概念</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/maximum-likelihood-estimation-conceptual-understanding-using-an-example-28367a464486?source=collection_archive---------8-----------------------#2020-01-13">https://medium.com/analytics-vidhya/maximum-likelihood-estimation-conceptual-understanding-using-an-example-28367a464486?source=collection_archive---------8-----------------------#2020-01-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5721" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最大似然估计是机器学习的核心概念之一。许多其他机器学习算法/技术都是基于使用MLE得出的结果。因此，总是建议对概念有一个正确的理解，并在我们的口袋里有一个方便的例子。</p><blockquote class="jd je jf"><p id="5f39" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">这个故事传达了MLE背后的意图，也为我们提供了一个简单的例子，我们可以随身携带以备将来使用。</p></blockquote><p id="33bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人们试图尽最大可能减少数学的使用。但建议读者对微分和概率有基本的了解。</p><p id="e5af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将从一个例子开始，并使用最大似然估计(MLE)来获得所需的解决方案。借助例子，我们将理解最大似然估计的概念。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jk"><img src="../Images/0457042b5d5071533946c5f38394e110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6QteyaaJ0XlyuTvGkRIorg.png"/></div></div></figure><h2 id="fdde" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">例子</h2><p id="b38a" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">一枚不公平的硬币被掷5次。5次投掷的结果如下:HHTTH。得到人头的概率有多大？</p><p id="5e10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解:<br/> p(人头)=(我们得到人头的次数)/(总抛数)<br/> p(人头)= #人头/#抛数<br/> p(人头)= 3/5 = 0.6</p><p id="0ec8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗯，解决方案很简单。然而，此时出现了另一个问题:</p><blockquote class="kw"><p id="341d" class="kx ky hi bd kz la lb lc ld le lf jc dx translated">为什么p(head)= # Heads/# toss？？？？</p></blockquote><p id="a69a" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">让我们看看最大似然估计能否帮助我们回答上述问题。</p><blockquote class="kw"><p id="4df8" class="kx ky hi bd kz la lb lc ld le lf jc dx translated">在我们移动之前:</p><p id="d65a" class="kx ky hi bd kz la lb lc ld le lf jc dx translated">1)让我们假设p(头)=θ，p(尾)= 1-θ</p><p id="a8e9" class="kx ky hi bd kz la lb lc ld le lf jc dx translated">2)让我们称我们的观察数据集为‘D’。D = HHTTH。</p></blockquote><h1 id="06b2" class="ll jx hi bd jy lm ln lo kc lp lq lr kg ls lt lu kj lv lw lx km ly lz ma kp mb bi translated"><strong class="ak">最大似然估计</strong>θ的值，即p(头)</h1><p id="ce2b" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">所以，根据我们的假设，我们知道得到人头的概率是θ。</p><blockquote class="jd je jf"><p id="f45e" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">我们的最终目标是找到θ的值，这样θ的值可以帮助我们声称，如果我们投掷硬币5次，我们将得到类似于数据集d中的观察结果。</p></blockquote><blockquote class="kw"><p id="e23a" class="kx ky hi bd kz la mc md me mf mg jc dx translated"><em class="mh">重复上述几行，我们需要为硬币找到(估计)一个θ，这样，在重复5次投掷硬币的相同实验时，得到D作为最终结果的机会(</em> <strong class="ak"> <em class="mh">可能性</em> </strong> <em class="mh">)是</em> <strong class="ak"> <em class="mh">最大化</em> </strong> <em class="mh">。</em></p></blockquote><h2 id="a0dc" class="jw jx hi bd jy jz mi kb kc kd mj kf kg iq mk ki kj iu ml kl km iy mm ko kp kq bi translated">我们如何找到一个θ，它增加了得到D作为最终结果的机会？</h2><ol class=""><li id="4e77" class="mn mo hi ih b ii kr im ks iq mp iu mq iy mr jc ms mt mu mv bi translated">首先，我们试着想出一个函数，它给出我们得到D的概率作为最终结果。这被称为<strong class="ih hj">似然函数</strong>。</li><li id="da39" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">然后，我们取似然函数的对数，得到<strong class="ih hj">对数似然函数</strong>。(完成这一步是出于后面陈述的数学原因。它不是最大似然的真实概念的一部分。)</li><li id="244e" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">最后<strong class="ih hj">，</strong>我们<strong class="ih hj">最大化</strong>这个对数似然函数来最大化得到d的概率。</li></ol><h2 id="f8f3" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated"><strong class="ak"> 1)寻找似然函数:</strong></h2><p id="85f1" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">考虑到我们已经知道p(head)是θ，获得数据集D作为最终结果的<strong class="ih hj">可能性</strong>是获得与数据集D中存在的头部和尾部相同序列(或数量)的<strong class="ih hj">概率</strong></p><p id="802b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，<br/> <strong class="ih hj">可能性</strong> = p(得到与D中相同的首尾序列)</p><p id="b6c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">既然D = HHTTH，<br/> <strong class="ih hj">可能性</strong> = p(头)。p(头)。p(尾巴)。p(尾巴)。p(头)</p><p id="2b7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">设nh= #Heads =头数<br/>设nt = #Tails =尾数</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es nb"><img src="../Images/a6bca729c596e60415708530fb36a59a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PQYRr1YxqGpx4U8kRPWVkQ.png"/></div></div></figure><p id="c9ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们得到的似然函数L(θ)为:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es nb"><img src="../Images/5126f311f9dd5fdf3b88339490b125e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XWj7QjyBrwgxsyIgZENMqA.png"/></div></div><figcaption class="nc nd et er es ne nf bd b be z dx translated">似然函数</figcaption></figure><h2 id="6fc2" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">2)寻找对数似然函数:</h2><p id="dc71" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><strong class="ih hj">我们为什么要拿走日志？<br/> </strong>似然函数L(θ)将θ提升到#heads的幂次，将(1-θ)提升到#tails的幂次。由于θ&lt;1，巨大的#heads或#tails值可能会导致我们的似然函数采用非常小的浮点值。为了防止这种情况，我们采用了似然函数的对数。这就是众所周知的对数似然函数。</p><p id="fe01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">拿走日志还有另一个原因。据观察，与微分似然函数相比，微分对数似然函数更容易。这一点在故事的结尾会变得更加明显。)</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es nb"><img src="../Images/30fcc20d369749b80f27973c8685dbb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jd0ngXemvjdbzOUy1jlc8g.png"/></div></div></figure><p id="c496" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，对数似然函数l(θ)为:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es nb"><img src="../Images/a6a446adb38ebaaa724e3cc4d6d514dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*poLMAOpQaPLCP85WaldscA.png"/></div></div><figcaption class="nc nd et er es ne nf bd b be z dx translated">对数似然函数</figcaption></figure><h2 id="37f9" class="jw jx hi bd jy jz ka kb kc kd ke kf kg iq kh ki kj iu kk kl km iy kn ko kp kq bi translated">3)最大化对数似然估计θ</h2><p id="1898" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我们希望找到一个可以最大化的似然函数。然而，我们将似然函数改为对数似然函数。现在我们正朝着最大化对数似然的目标前进。</p><p id="80da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">对数似然最大化和似然最大化是一样的吗？<br/> </strong>原来是的！！<br/>由于‘log’是一个递增函数，最大化对数似然函数的θ值也将最大化似然函数。</p><p id="bbda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们如何最大化对数似然函数l(θ)？<br/> 对数似然最大化是指，找到一个θ值，使得对数似然函数值l(θ)最大化。</p><p id="74b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个简单的最大化问题，我们已经得到一个等式l(θ),我们需要找到一个使等式最大化的θ值。</p><p id="3ccc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以对l(θ)w . r . tθ求导，使其等于0。这有助于我们求出θ的值。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es nb"><img src="../Images/e820aa2aedc4d52bdabdd90f6fb81627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*msoIKwzHkd_Cmf-0C7WMAw.png"/></div></div></figure><blockquote class="kw"><p id="cf26" class="kx ky hi bd kz la mc md me mf mg jc dx translated">因此，使用最大似然估计，我们估计了p(head)即θ的值，并发现它是#Heads / #Tosses。这有助于我们回答“为什么p(head)= # Heads/# toss？”。</p></blockquote><h1 id="baa9" class="ll jx hi bd jy lm ln lo kc lp lq lr kg ls lt lu kj lv lw lx km ly lz ma kp mb bi translated">结论:</h1><p id="a711" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">最大似然法用于估计参数值(在我们的例子中是p(head))。</p><ol class=""><li id="4c9c" class="mn mo hi ih b ii ij im in iq ng iu nh iy ni jc ms mt mu mv bi translated">我们假设我们知道参数的值，并将该值称为θ</li><li id="caca" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">利用θ，我们找到了似然函数。</li><li id="fe48" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">为了数学上的方便，我们取似然函数的对数。</li><li id="a887" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">我们最大化对数似然函数来获得θ的值。</li></ol></div></div>    
</body>
</html>