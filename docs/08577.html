<html>
<head>
<title>Boosting Apache Spark Application by Running Multiple Parallel Jobs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过运行多个并行作业提升Apache Spark应用程序</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/boosting-apache-spark-application-by-running-multiple-parallel-jobs-25d13ee7d2a6?source=collection_archive---------0-----------------------#2020-08-04">https://medium.com/analytics-vidhya/boosting-apache-spark-application-by-running-multiple-parallel-jobs-25d13ee7d2a6?source=collection_archive---------0-----------------------#2020-08-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/cce9697a494226171fb19f66f07b11df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*net6rfSvjji0PAMfbxaRMA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">安东尼·拉奥在<a class="ae iu" href="https://unsplash.com/s/photos/fire-booster?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="e55c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated"><span class="l ju jv jw bm jx jy jz ka kb di"> T </span>从这篇文章的标题中，您可能会想到一个问题，Apache Spark已经并行执行数据处理了，它有什么新功能吗？如果是这样的话，请允许我给出一个关于spark job的想法——它是一个并行计算，一旦在应用程序中调用spark操作，就会创建一个并行计算。除此之外，一个众所周知的事实是，默认情况下，Apache Spark在每个执行器之间运行多个任务来实现并行性，然而，在作业级别却不是这样。换句话说，一旦一个spark动作被调用，一个spark作业就出现了，它由一个或多个阶段组成，并且这些阶段被进一步分解成多个任务，这些任务由执行者并行处理。因此，Spark一次并行运行多个任务，而不是多个作业。</p><p id="a5a5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">警告:这并不意味着spark不能运行并发作业。</strong></p><p id="02ff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过这篇文章，我们将探索如何通过一次运行多个作业(spark动作)来提高默认spark应用程序的性能。我还会分享一些spark UI片段，这些片段表明<strong class="ix hj">对于相同的工作量，Spark应用程序并发作业所用的时间只有默认Spark应用程序的四分之一。</strong></p><p id="e668" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kc">注意:在本文中，我可能用“工作”一词来表示“火花行动”</em></p><p id="28f6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">根据我的个人经验，我观察到一些提取应用程序包含这样的动作或作业，它们彼此之间没有任何关系，它们是完全独立的Dag。</p><p id="76a8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">用一个简单的例子来说明:</p><ul class=""><li id="087d" class="kd ke hi ix b iy iz jc jd jg kf jk kg jo kh js ki kj kk kl bi translated">我们想要查询3个不同的表并保存它们的CSV输出。(由于每个查询只涉及一个操作，即“保存”,这意味着在spark UI中会产生3个作业。)</li></ul><p id="9be9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了实现上述声明，我们有以下选择。</p><ul class=""><li id="5493" class="kd ke hi ix b iy iz jc jd jg kf jk kg jo kh js ki kj kk kl bi translated">每个查询有不同的Spark会话——非常低效和昂贵的想法。</li><li id="6277" class="kd ke hi ix b iy km jc kn jg ko jk kp jo kq js ki kj kk kl bi translated">相同的spark会话，并在循环中执行查询，即Spark应用程序的默认特性。</li><li id="29f4" class="kd ke hi ix b iy km jc kn jg ko jk kp jo kq js ki kj kk kl bi translated">相同的Spark会话并并行运行查询——与其他两个相比非常高效。让我们继续吧。</li></ul><p id="d8e7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过使用单个spark会话运行并发作业，不仅可以最大限度地提高资源利用率，还可以大幅减少应用时间和成本。此外，如果我们有足够的资源，并且这些作业之间没有任何联系，那么在一个循环中或作为不同的spark应用程序执行它们是没有意义的。</p><p id="106f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们已经了解了我们的目标是什么和为什么，是时候看看我们如何实现它了。</p></div><div class="ab cl kr ks gp kt" role="separator"><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw"/></div><div class="hb hc hd he hf"><p id="f92b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了实现作业级的并发，我们可以利用Scala并发特性，称为<a class="ae iu" href="https://docs.scala-lang.org/overviews/core/futures.html" rel="noopener ugc nofollow" target="_blank"><em class="kc"/></a>。它的ExecutionContext负责异步执行计算。</p><p id="fc2c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在下面的代码中，我们有三个查询和一个名为“<em class="kc"> executeAndSave </em>”的函数。我们将这个函数的调用封装在一个Future块中，并调用名为“Await.result”的Future函数来等待所有查询的结果。这样，我们将能够并行运行多个“保存”作业，并且不要忘记最后关闭<strong class="ix hj"> ExecutionContext </strong>。</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="1f1e" class="lh li hi ld b fi lj lk l ll lm">import scala.concurrent.<strong class="ld hj">ExecutionContext</strong>.Implicits.global<br/>import scala.concurrent.duration.{Duration,MINUTES}<br/>import scala.concurrent.{Await, Future}</span><span id="fab8" class="lh li hi ld b fi ln lk l ll lm"><br/>val pathPrefix="/lake/mutlithreading/"<br/>val queries=Seq("SELECT * FROM ABC|output1","SELECT * FROM    PQR|output2","SELECT * FROM XYZ|output3")<br/><strong class="ld hj">val futureArray: Array[Future[Unit]] = new Array[Future[Unit]](3)</strong><br/>var i=0</span><span id="82e3" class="lh li hi ld b fi ln lk l ll lm">queries.foreach(queryAndPath =&gt; {<br/>          val query=queryAndPath.split("\\|")(0)<br/>          val dataPath=pathPrefix+queryAndPath.split("\\|")(1).trim<br/>          <strong class="ld hj">futureArray(i) = Future {<br/>                executeAndSave(query,dataPath)<br/>            }</strong><br/>              i = i + 1<br/>      })</span><span id="38db" class="lh li hi ld b fi ln lk l ll lm"><strong class="ld hj">futureArray.map(s =&gt; Await.result(s, Duration(15, MINUTES)))</strong><br/>  <br/>def executeAndSave(query:String,dataPath:String)(implicit context: Context):Unit = {<br/>  println(s"$query starts")<br/>  context.spark.sql(query).write.mode("overwrite").parquet(dataPath)<br/>  println(s"$query completes")<br/>    }</span></pre><blockquote class="lo lp lq"><p id="f051" class="iv iw kc ix b iy iz ja jb jc jd je jf lr jh ji jj ls jl jm jn lt jp jq jr js hb bi translated">除了上述解决方案，<a class="lu lv ge" href="https://medium.com/u/86ac004e37f9?source=post_page-----25d13ee7d2a6--------------------------------" rel="noopener" target="_blank"> <strong class="ix hj"> Pavel Filatov </strong> </a>在评论中建议，可以通过使用提供隐式并行的<a class="ae iu" href="https://docs.scala-lang.org/overviews/parallel-collections/overview.html" rel="noopener ugc nofollow" target="_blank">并行集合</a>来使其更加简单。我还认为，这是一种更简单的方法，我们不需要控制底层的并行化细节。下面请看他的<a class="ae iu" href="https://gist.github.com/pavel-filatov/aaea22e304bfdb509866f13034df0d80" rel="noopener ugc nofollow" target="_blank">s解决方案</a>。</p></blockquote><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lw lx l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://gist.github.com/pavel-filatov/aaea22e304bfdb509866f13034df0d80" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/Pavel-filatov/aaea 22e 304 bfdb 509866 f 13034 df0 d 80</a></figcaption></figure><h2 id="4b30" class="lh li hi bd ly lz ma mb mc md me mf mg jg mh mi mj jk mk ml mm jo mn mo mp mq bi translated"><strong class="ak">默认spark应用与并发spark应用之间的持续时间分析</strong></h2><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mr"><img src="../Images/3f2e232d3a6936ac1cd7dc0cf15e21bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c2F184u0bFJply8WJLjmRw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">连续作业的Spark UI</figcaption></figure><p id="46f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的代码片段中，我们可以看到默认的spark应用程序用了17秒，而下图所示的带有并发作业的spark应用程序只用了4秒就完成了同样多的工作。还可以看到，所有三个作业的提交时间是相同的。也可以从事件时间表中确认作业相互重叠的位置。由于<strong class="ix hj">任务Id 3 </strong>花费了4秒，这在其他两个任务中是最长的，因此我们认为这是该任务的总时间。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mr"><img src="../Images/3a1dad7a467f1093ab70dae6a4f45e50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ei9GsWQ918y7gyXKAMsvIg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">并发作业的Spark UI</figcaption></figure><p id="ab66" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在大多数情况下，在spark应用程序中运行并发作业会带来积极的结果并提升性能，<strong class="ix hj">然而，可能会出现单独Scala Futures无法帮助</strong>的情况，这是因为有时一个作业会消耗所有资源，而其他作业必须等到它们获得一部分资源后才能执行。在这种情况下，我们需要配置Spark的公平调度，这将确保资源分配给所有触发的作业。我在这里讨论过这个主题——“<a class="ae iu" href="https://towardsdatascience.com/apache-spark-sharing-fairly-between-concurrent-jobs-d1caba6e77c2" rel="noopener" target="_blank">Apache Spark:在一个应用程序中的并发作业之间公平地共享</a></p><p id="fe44" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">希望，这篇帖子对你有所帮助。</p><p id="8982" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请在评论中分享你的想法和建议。</p></div></div>    
</body>
</html>