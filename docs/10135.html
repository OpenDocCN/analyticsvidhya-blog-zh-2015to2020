<html>
<head>
<title>Classifying Text Reviews of Amazon Products Using Naive Bayes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用朴素贝叶斯对亚马逊产品的文本评论进行分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classifying-text-reviews-of-amazon-products-using-naive-bayes-4a21c6fabaff?source=collection_archive---------12-----------------------#2020-10-06">https://medium.com/analytics-vidhya/classifying-text-reviews-of-amazon-products-using-naive-bayes-4a21c6fabaff?source=collection_archive---------12-----------------------#2020-10-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/80deef6bfc1351a79fca6fed8b83a9d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A1MmJ3y9WhLQlpFN0we3Og.jpeg"/></div></div></figure><p id="9909" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如之前<a class="ae jo" rel="noopener" href="/analytics-vidhya/the-naivety-of-naive-bayes-72c2a1738f80">提到的</a>，在文本分类方面，朴素贝叶斯是一种优秀的机器学习算法。对文本数据进行分类通常包括大量文本挖掘形式的预处理，然后才适合于构建模型。文本挖掘是将原始的、非结构化的文本数据转换成有意义的、结构化的形式以提取有价值的见解的过程。这里，我们将构建一个简单的朴素贝叶斯模型，该模型将获取亚马逊产品的文本评论，并将它们分类为“正面”或“负面”。</p><h2 id="6f78" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">最初的步骤</h2><p id="44da" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">这里使用的亚马逊精品评论<a class="ae jo" href="https://www.kaggle.com/snap/amazon-fine-food-reviews" rel="noopener ugc nofollow" target="_blank">数据集</a>取自Kaggle。原始完整数据集包含35172行10个特征，其中我们只需要代表产品<em class="kp">得分</em>，评论<em class="kp">摘要</em>和完整评论<em class="kp">文本</em>的特征。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/a23711957660dc495a5b5b43c85b22c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uTRSjVDY6_0q37goDSnN-w.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图一。包含必要要素的亚马逊数据集的子集。</figcaption></figure><p id="31cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将首先从<em class="kp">得分</em>特性构建<em class="kp">响应</em>变量，将<em class="kp">得分</em> &gt; 3的行标记为“正”，其他的标记为“负”。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/66656dea6d62f29eda3591b59421f741.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M7-MfOFhGsFPvInhohMrIQ.jpeg"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图二。不同审核分数(上图)和不同回答(下图)的柱状图。</figcaption></figure><p id="954d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的目标是构建一个模型，该模型可以接收多行文本数据，并将相应的<em class="kp">响应</em>分类为“肯定”或“否定”。文本数据可以是评审<em class="kp">摘要</em>或评审<em class="kp">文本</em>。对于一个简单有效的模型，我们将考虑评审<em class="kp">总结</em>。</p><h2 id="e45e" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated"><strong class="ak">语料库创建和清理</strong></h2><p id="9e9d" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">在我们到达模型构建阶段之前，原始文本数据必须经过几个步骤才能获得有用的形式。我们首先从评审摘要创建一个语料库，它只是一个摘要文本文件的集合。我们将语料库中的所有字母转换为小写，然后开始清理过程，去除不必要的数字、标点符号和不必要的单词(称为停用词，包括频繁使用的单词，如“I”、“or”、“and”、“the”等)，只取单词的词根(如表示“go”、“goes”、“going”的单个单词)，最后删除所有不必要的空格。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es la"><img src="../Images/93cd9f741315d4893f9a1c9cc635fd99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*-nwnrd4J0vE-ThtKum9jQg.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图三。语料库的创建和清理。</figcaption></figure><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lb"><img src="../Images/04adbed51ad5ce5ba16905d50721cbc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B8ryBUKKCw_Df5_GzXXw1Q.jpeg"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图4。清洗过程之前(左)和之后(右)的语料库中的文本。</figcaption></figure><p id="3633" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">清理完语料库后，文本文件只剩下那些单词，与我们去掉的单词相反，它们可能对分类有用。</p><h2 id="765e" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated"><strong class="ak">文档术语矩阵</strong></h2><p id="eeb1" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">现在有了干净的语料库，我们将形成一个文档术语矩阵(DTM)。DTM是一个矩阵，其中每行对应于语料库中的一个文本文件，列由语料库中找到的所有术语组成，每个(<em class="kp"> i </em>，<em class="kp"> j </em>)条目是第<em class="kp"> j </em>个术语在第<em class="kp"> i </em>个文本文件中出现的频率。DTM经常类似于稀疏矩阵，即具有很少数量的非零值的矩阵。因此，我们通常通过移除一些稀疏项来获取DTM的子集。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/7c7909c24d14c79288cd41738f3791e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4H6M8FWcR8WvUF4yGrREwQ.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图五。通过移除稀疏项来获取DTM的子集。</figcaption></figure><p id="d8bb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里，我们将稀疏度设置为0.99965，这意味着我们将删除至少99.965%的单元格为零的项。设置稀疏值没有特定的规则；不同的级别导致不同数量的术语，因此准确度值也不同。</p><h2 id="660f" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">可视化和词云</h2><p id="5b1a" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">我们可以制作柱状图，显示不同单词在文本文件中出现的频率。这里，我们首先根据文本文件的<em class="kp">响应</em>类型对其进行了分区，并为每个分区制作了上述柱状图。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/797897fa5c6ba0c2274044efd8d56ade.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RmzyY0xKPbparAUyZePQ3w.jpeg"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图六。柱状图显示单词在正面(顶部)和负面(底部)回答中出现的频率。</figcaption></figure><p id="d138" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，当我们处理文本文件时，我们可以利用一种叫做文字云的东西来实现可视化。单词云是一种将DTM中出现的单词显示为云的图像，其中每个单词的大小表示其频率。所以，上面的柱状图可以用下面的单词云的形式来表示。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/43fccc4affba97faf0350cddff12c23b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z6JAq0bqVeU22JOrhAqzIQ.jpeg"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图7。正面(左)和负面(右)回答中出现的单词的单词云。</figcaption></figure><h2 id="04c0" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated"><em class="le">朴素贝叶斯的工作</em></h2><p id="4863" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">让我们大致看看朴素贝叶斯在文本分类中是如何工作的。假设我们的语料库中有一个评论说“伟大的产品”，我们想对它的<em class="kp">响应</em>进行分类。朴素贝叶斯首先计算“肯定”和“否定”回答的概率。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/e38b999be4b39d0206fad67d7dd3660c.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*wPI5YNGS43Q2ISFv_2aKYQ.png"/></div></figure><p id="d051" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，它计算在“正面”和“负面”评论中获得“伟大”一词的概率。“产品”这个词也是如此。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/387b519ee4b89cd66890cb8a8902615d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*tUBn-bD9KFiL-rkKWvlvhw.png"/></div></figure><p id="645f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">到目前为止所做的计算可以用频率表的形式来概括。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/e5d33519686f45eca8ce408690c75004.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*9QF0YHnUlCwFi0q5gi7e7g.png"/></div></figure><p id="0839" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，朴素贝叶斯分类器计算分数，帮助指示评论是“正面”还是“负面”。对于“阳性”标签，分数计算如下。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es li"><img src="../Images/10de2e6a706a58a9202dd9a4b0243fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*JNBjuMp8DPL8DDleZN_Wtw.png"/></div></figure><p id="a72c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样，对于“负面”标签。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/92f0cbca3d611298ccd3ee47c4ce8295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*ybQc-3IeGHgXeU9cJco2_Q.png"/></div></figure><p id="0829" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这两个分数分别与评论为“正面”或“负面”的概率成比例，因为评论说的是“伟大的产品”。因为“正面”标签的分数较大，所以朴素贝叶斯将评论分类为“正面”。</p><h2 id="5c63" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated"><em class="le">拟合H2O朴素贝叶斯模型</em></h2><p id="8fe7" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">因为当所有的独立变量都是分类变量时，朴素贝叶斯工作得最好，所以我们将把每一项的频率转换成一个因子变量，如果频率大于0，则用标签“是”，如果频率等于0，则用标签“否”。然后，我们按照8:2的比例将数据分为训练数据集和测试数据集。使用简单的<em class="kp"> prop.table() </em>函数，我们可以检查两个数据集中<em class="kp">响应</em>标签的分布是否相等，并且还可以获得基线精度。由于在两个数据集中，大约77%的数据的<em class="kp">响应</em>为“正”，所以即使我们将所有数据标记为“正”，我们也肯定会得到77%的准确度(基线)。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/256ce677153fe140e71156a3fe3275ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*Ky8MC3BtAVBkNR7OUYSzBA.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图8。获得基线精度。</figcaption></figure><p id="86ed" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们继续从训练数据制作H2O朴素贝叶斯模型。为了考虑训练数据中存在但测试数据中可能缺失的任何项，我们将超参数<em class="kp">拉普拉斯</em>的值设为1。这确保了我们不会从测试数据中得到任何项的概率为0，而该概率在训练数据中不存在。所述模型给我们的结果具有几乎83%的准确度，这优于基线。</p><h2 id="9860" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">模型改进:N-Gram标记器</h2><p id="b96e" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">到目前为止，在确定<em class="kp">响应</em>类型<em class="kp">时，我们只考虑了文本文件中出现的单个单词。</em>在图6所示的两个柱状图中，我们可以看到许多单词同时出现在阳性和阴性反应中。因此，仅仅通过查看单个单词很难清楚地解释单词-响应关联。</p><p id="680c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">记号化是将文本分割成记号列表的过程，记号可以是任何东西:单个字符、单词甚至句子。n-gram记号赋予器所做的是将每个文本文件分割成包含n个连续单词的序列。相邻单词为它们与相应的<em class="kp">响应</em>类型的关联提供了更多的含义，因此可能会导致更好的结果。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/44c58b70b456c10d1ca85659cbe87157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*MHORyWMLb7w19bhKIWblnQ.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图九。使用2克记号赋予器创建DTM。</figcaption></figure><p id="35f3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">就像前面提到的图6一样，我们可以根据它们的<em class="kp">响应</em>类型制作柱状图，显示文本文件中出现的不同两个单词组合的频率。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/3120d060115d984338f26573f5087cd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xcwLrdDEUMXkPGkAo0f7Cg.jpeg"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图10。柱状图显示了正面(顶部)和负面(底部)回答中出现的两个单词组合的频率。</figcaption></figure><p id="62c7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们可以像以前一样遵循同样的步骤；唯一的区别是，我们现在考虑文本文件中出现的连续单词的两个单词组合，而不是单个单词，以便预测<em class="kp">响应</em>标签。</p><p id="b728" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">完整的代码可在<a class="ae jo" href="https://github.com/gauravalley/Amazon-Review-Classification" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p></div></div>    
</body>
</html>