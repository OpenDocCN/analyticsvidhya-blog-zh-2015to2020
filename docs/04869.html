<html>
<head>
<title>Paper Analysis 1 : Single Image Super Resolution Using IDN Network[CVPR 2018]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文分析1:使用IDN网络的单幅图像超分辨率[CVPR 2018]</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/paper-analysis-1-fast-and-accurate-single-image-super-resolution-using-idn-network-cvpr-2018-8db365d48fa2?source=collection_archive---------17-----------------------#2020-04-03">https://medium.com/analytics-vidhya/paper-analysis-1-fast-and-accurate-single-image-super-resolution-using-idn-network-cvpr-2018-8db365d48fa2?source=collection_archive---------17-----------------------#2020-04-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="94d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">原文:</em><a class="ae je" href="https://arxiv.org/pdf/1803.09454.pdf" rel="noopener ugc nofollow" target="_blank"><em class="jd"/></a></p><h1 id="6f1e" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">简介:</strong></h1><p id="c2b4" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">已经提出了大量的单幅图像超分辨率方法，主要是插值方法、重建方法以及示例方法。插值方法具有高的重建效率，因为它们使用CNN模型，但是这些方法也具有一些缺点</p><ol class=""><li id="c665" class="ki kj hi ih b ii ij im in iq kk iu kl iy km jc kn ko kp kq bi translated">它们具有很高的计算复杂度和很高的内存消耗。</li><li id="2136" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">从卷积层出来的特征图被不加区别地直接传递到顺序网络，即每个特征图被赋予相同的权重。通俗地说，没有给出足够信息的特征地图也被赋予与给出图像的高价值特征的特征地图相同的重要性。(<a class="ae je" href="https://arxiv.org/pdf/1709.01507.pdf" rel="noopener ugc nofollow" target="_blank">更多信息请参考挤压和激励网络研究论文</a>)</li></ol><p id="b4be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了防止这些缺点，提出了IDN(信息提取网络),因为与插值方法相比，它使用较少数量的滤波器来提供更快的性能。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kw"><img src="../Images/380c764b531cda770cebaa2414125639.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YrmwjScsSQSbtF3fNWcZew.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">图1:信息提取网络架构</figcaption></figure><p id="27b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，这种方法有一个<strong class="ih hj">特征提取</strong>块，其中使用一系列卷积层从低分辨率(<strong class="ih hj"> LR </strong>)图像中提取特征，随后是堆叠的多个<strong class="ih hj">提取</strong>块以提取残留信息，随后是<strong class="ih hj">重构</strong>块以获得高分辨率(<strong class="ih hj"> HR </strong>)残留图像。</p><p id="487e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了获得HR图像，我们对残差图像和上采样的LR图像进行元素相加操作(使用双三次插值)。</p><p id="5c50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">蒸馏装置由两个网络组成:</p><ol class=""><li id="7126" class="ki kj hi ih b ii ij im in iq kk iu kl iy km jc kn ko kp kq bi translated"><strong class="ih hj"> <em class="jd">增强网络</em> </strong></li><li id="07a9" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated"><strong class="ih hj"> <em class="jd">压缩网络</em> </strong></li></ol><h1 id="319c" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">网络结构:</strong></h1><ol class=""><li id="3893" class="ki kj hi ih b ii kd im ke iq lm iu ln iy lo jc kn ko kp kq bi translated"><strong class="ih hj"> <em class="jd">特征提取</em> </strong>:通过将图像经过一系列卷积层来提取特征。</li></ol><p id="bb3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以数学上可以表示为:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lp"><img src="../Images/c47a1b1ecfd7600ffb5dfade6fa18f06.png" data-original-src="https://miro.medium.com/v2/resize:fit:172/format:webp/1*c6nF-WI9xikFnL5MhNFJ1A.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式1:输入图像的特征提取</figcaption></figure><p id="731b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> x </strong>:输入图像到特征提取块</p><p id="fdb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> f </strong>:特征提取</p><p id="ab11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> B₀ </strong>:提取特征</p><p id="9977" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj"> <em class="jd">提取块</em> </strong>:这个块是架构的核心，在这里特征提取后的特征图被增强，然后被提取以给出残留信息。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lq"><img src="../Images/535088e6b92cbf0bd50d107bd58c82f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*6YwyHhb2n23vaX4MYAWMHA.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式2:蒸馏块</figcaption></figure><p id="d51c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Fₖ </strong>:第k个蒸馏块功能</p><p id="f1c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Bₖ₋₁ </strong>:第k蒸馏块输入</p><p id="6027" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Bₖ </strong>:第k蒸馏块产量</p><p id="6b3d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该区块由两个网络组成:</p><p id="9949" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">增强网络</strong>:增强单元由2个卷积网络组成，每个网络为3层模块。特征地图分为两部分，一部分表示短路径特征，另一部分表示长路径特征(参见下图)。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lr"><img src="../Images/ebf86f1c71ba192fe5db800954188162.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/1*7uSmJ_PwkpFDWZLGDJ1jEg.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">图2:增强网络</figcaption></figure><p id="5f96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">长路径特征基本上是增强的短路径特征。然后将两个特征图组合在一起，以获得更丰富和有效的信息。因此，增强单元是为了提高网络的表示能力，而压缩网络是为了从增强单元的输出中滤除不想要的信息。</p><p id="e0e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">长路径特征是输入图像的增强特征，但是当图像通过六个卷积层时，有可能遗漏任何重要的信息，因此长路径特征和短路径特征的连接是必要的，因为短路径特征包含部分保留的信息，这些信息将填补任何重要的遗漏特征的空白。</p><p id="05cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">增强单元的输入通过一个卷积网络，其后是一个泄漏的ReLU(或LReLU)。由于有6层，第I层的特征映射维数可以表示为Dᵢ (i = 1，…。,6).</p><p id="1e4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第三卷积层的输出通过激活函数，并被分成两部分。</p><p id="364a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经提到，特征提取后输入到蒸馏块作为Bₖ₋₁.</p><p id="5945" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们可以将第三卷积层之后的输出表示为:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es ls"><img src="../Images/92d5577cf47627340395156905ddc0eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:238/format:webp/1*MjMAb2fagTDkE6188U5Hkg.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式3:短路径的输出</figcaption></figure><p id="c046" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中Pk1:第k个增强单元中第一个卷积网络(短路径)的输出</p><p id="9e18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Ca </strong>:链式卷积层</p><p id="13a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在短路径之后，Pk1的D3/s维度和第一卷积layer(Bₖ₋₁的输入)被连接</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lt"><img src="../Images/7c1b5d56576401b4a94f49818df3d358.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*O9OSjggfckf8eSadGZGafw.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式4:分割Pk1并连接</figcaption></figure><p id="8141" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Rk </strong>:切片后输出</p><p id="7021" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> C </strong>:串联</p><p id="5065" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于长路径:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lu"><img src="../Images/2eb989db679272777eaec0d660561f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*RURtwCjb_9evak-1aYlZ4A.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式5:长路径的输出</figcaption></figure><p id="a96f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Cb </strong>:卷积运算</p><p id="333e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Pk2 </strong>:长路径通过第二卷积网络后的输出</p><p id="debb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以<strong class="ih hj"> Pk </strong> = Pk2 + Rk</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lv"><img src="../Images/6a0e70ee0010588dc7a5dd6347369346.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*fYN0cX9q5-iCm5xOAYBHcw.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式6:组合级联要素和长路径要素</figcaption></figure><p id="eaca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">压缩单元</strong>:它是一个1x1卷积层，用于降维和提取相关信息。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lq"><img src="../Images/b566e97040c46a170814c93a0099fe95.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*WApZ0Q5iHLfxUt4Ex70J9g.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式7:压缩单位</figcaption></figure><p id="27d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.<strong class="ih hj"> <em class="jd">重构块</em> </strong>:它是卷积层的一系列转置(参考图1)。</p><p id="4b22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，该架构的总体等式可以写成:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lw"><img src="../Images/239a8e0ad02d61d2558d9dcc6cfb01a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*Fv2nVRBZ0R-0VPjXMUx27Q.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式8:模型的总输出</figcaption></figure><p id="26cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> U </strong>:原始图像的双三次插值</p><p id="55ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> R </strong>:重建块</p><h1 id="3d27" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">损失函数:</strong></h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lx"><img src="../Images/6890dec4e3e9b6d4bca1678ee2478b27.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*zkthJMsZGU6ZHulgHQlcPA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式9 : MSE损失</figcaption></figure><p id="5e9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">早期的超分辨率模型通常存在MSE损失，实验结果并不理想。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es ly"><img src="../Images/5a2bae625974787ec876e8d498197860.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*dq_k_vI5VkIPRtVf0xUVjA.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">等式10 : MAE损失</figcaption></figure><p id="e2a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个模型中，我们使用两个损失函数。可以看出，MSE损失可以提高具有MAE损失的训练网络的性能。因此，该模型用MAE损失训练，然后用MSE损失微调。</p><h1 id="cc40" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">实验及结果:</strong></h1><p id="6269" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">使用的数据集是<strong class="ih hj">伯克利分割数据集</strong></p><p id="7d17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果是这样的</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lz"><img src="../Images/4c1bc595bd071bf4b5130bbd28aaa7d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*SRxG-eEoIB9ClfO52ny5qw.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">结果1:剩余图像及其数据分布</figcaption></figure><p id="087f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">增强单元的特征图可以通过绘图来观察。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es ma"><img src="../Images/5d6f0a263d0aea388e095fe335770ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*CCRyOWXUC1olc4DdSpWoKg.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">结果2:平均特征图的可视化</figcaption></figure><p id="ba3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，让我们来看看这个模型与其他模型相比表现如何。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mb"><img src="../Images/9fe1050b45014f3db9bfbb47f384a7b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UHK6XO2u0F2dzhm-yyhhfg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">结果3:IDN与其他方法的比较</figcaption></figure><h1 id="aaaa" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">结论:</strong></h1><p id="60e7" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">因此，在信息提取网络的帮助下成功地实现了单幅图像的超分辨率，其中增强单元增强有用的特征，压缩单元滤除不需要的特征，最后重建图像。</p><h1 id="ae9e" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">参考资料:</h1><ol class=""><li id="2aca" class="ki kj hi ih b ii kd im ke iq lm iu ln iy lo jc kn ko kp kq bi translated"><a class="ae je" href="https://arxiv.org/pdf/1803.09454.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1803.09454.pdf</a></li><li id="7bd3" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated"><a class="ae je" href="https://ieeexplore.ieee.org/document/8913994/" rel="noopener ugc nofollow" target="_blank">https://ieeexplore.ieee.org/document/8913994/</a></li><li id="3c7b" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated"><a class="ae je" href="https://github.com/jangsoopark/IDN-TensorFlow" rel="noopener ugc nofollow" target="_blank">https://github.com/jangsoopark/IDN-TensorFlow</a></li><li id="af03" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated"><a class="ae je" href="https://github.com/Zheng222/IDN-Caffe" rel="noopener ugc nofollow" target="_blank">https://github.com/Zheng222/IDN-Caffe</a></li></ol></div></div>    
</body>
</html>