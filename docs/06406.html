<html>
<head>
<title>Easy Web Scraping(5 lines of code) on dynamic website(CSR) with python and selenium in 2020</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2020年使用python和selenium在动态网站(CSR)上轻松抓取网页(5行代码)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/easy-web-scraping-5-lines-of-code-on-dynamic-website-csr-with-python-and-selenium-in-2020-44523c475b5?source=collection_archive---------10-----------------------#2020-05-21">https://medium.com/analytics-vidhya/easy-web-scraping-5-lines-of-code-on-dynamic-website-csr-with-python-and-selenium-in-2020-44523c475b5?source=collection_archive---------10-----------------------#2020-05-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/586aeec0bcec9b91619b9a7b4905eb74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WgXQ9o3ai3q0IrJt8Ku0Fw.jpeg"/></div></div></figure><h1 id="b2f9" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">简介</strong></h1><p id="97a9" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在有很多方法可以抓取网页，不管是用Javascript(我认为是最简单的)还是其他编程语言。在本文中，我将关注Python，因为你知道这是数据科学的时代，数据科学家热爱Python，我最近也迷上了数据分析师领域。</p><p id="2917" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">有3个流行的库可以使用Python进行Web抓取，它们是Selenium、Beautiful Soup和Scrapy(它们是如何不同的，你可以观看这个<a class="ae kr" href="https://www.youtube.com/watch?v=zucvHSQsKHA" rel="noopener ugc nofollow" target="_blank"> youtube视频</a>)。这个内容我将向你展示如何与硒和美丽的汤，这是直观的，易于实施。</p><h1 id="a7cd" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">先决条件</h1><ul class=""><li id="8f2e" class="ks kt hi jq b jr js jv jw jz ku kd kv kh kw kl kx ky kz la bi translated">安装硒和美丽的汤包</li></ul><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="ff5b" class="lk ir hi lg b fi ll lm l ln lo">pip install selenium<br/>pip install BeautifulSoup4</span></pre><ul class=""><li id="19c5" class="ks kt hi jq b jr km jv kn jz lp kd lq kh lr kl kx ky kz la bi translated">任何文本编辑器，但我会推荐木星笔记本或谷歌colab，因为它更容易调试</li><li id="db80" class="ks kt hi jq b jr ls jv lt jz lu kd lv kh lw kl kx ky kz la bi translated">Selenium web驱动程序。这是另一件重要的事情，因为selenium需要一个web驱动程序来创建一个允许selenium控制的新网页。本教程我将使用Chrome驱动程序。你可以在这里下载Chrome驱动程序<a class="ae kr" href="http://chromedriver.chromium.org/downloads" rel="noopener ugc nofollow" target="_blank"/>。* *在下载chrome驱动程序之前，请检查您的google chrome版本是否与您的Chrome版本兼容。</li></ul><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/8b54a2ef0d69640bb76e822e250fcee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*yr7BwrACUM7InCV71m4G4w.png"/></div></figure><h1 id="e80b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">我们开始吧</h1><p id="f7ad" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我就刮一下整个<a class="ae kr" href="https://reverb.com/marketplace/electric-guitars?make=suhr&amp;page=1" rel="noopener ugc nofollow" target="_blank">混响吉他搜索页面</a>源码作为例子。</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="0321" class="lk ir hi lg b fi ll lm l ln lo">from bs4 import BeautifulSoup<br/>from selenium import webdriver<br/>import time</span><span id="923a" class="lk ir hi lg b fi ly lm l ln lo">driver = webdriver.Chrome('directory/to/web_driver')<br/>driver.get("<a class="ae kr" href="https://reverb.com/marketplace/electric-guitars?make=fender&amp;page=100" rel="noopener ugc nofollow" target="_blank">https://reverb.com/marketplace/electric-guitars?make=fender&amp;page=</a>1")<br/>time.sleep(3)<br/>html_source = driver.page_source<br/>soup = BeautifulSoup(html_source,'lxml')</span></pre><p id="fa99" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">正如你所看到的只有5行代码，我们有一个完整的HTML页面来源于一个特定的URL。我将从上面的代码中一行一行地解释。</p><ol class=""><li id="6a1c" class="ks kt hi jq b jr km jv kn jz lp kd lq kh lr kl lz ky kz la bi translated">执行web驱动程序(下载的那个)并存储到驱动程序变量</li></ol><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="30d4" class="lk ir hi lg b fi ll lm l ln lo">driver = webdriver.Chrome('directory/to/web_driver')</span></pre><p id="41b7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">2.告诉web驱动程序打开URL</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="b3be" class="lk ir hi lg b fi ll lm l ln lo">driver.get("<a class="ae kr" href="https://reverb.com/marketplace/electric-guitars?make=fender&amp;page=100" rel="noopener ugc nofollow" target="_blank">https://reverb.com/marketplace/electric-guitars?make=fender&amp;page=</a>1")</span></pre><p id="896a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">3.这一行非常重要，我们需要设置睡眠时间，等待网页完全加载，因为这是一个动态网站或一些客户端渲染(CSR)调用。你可以在这里阅读更多关于CSR和其他类型<a class="ae kr" href="https://www.toptal.com/front-end/client-side-vs-server-side-pre-rendering" rel="noopener ugc nofollow" target="_blank">的内容。</a></p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="983f" class="lk ir hi lg b fi ll lm l ln lo">time.sleep(3)</span></pre><p id="9153" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">4.获取页面源</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="bf85" class="lk ir hi lg b fi ll lm l ln lo">html_source = driver.page_source</span></pre><p id="071d" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">5.调用Beautiful Soup并解析HTML源代码。你可以从漂亮的Soup文档<a class="ae kr" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">中找到解析器选项。</a></p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="a9b9" class="lk ir hi lg b fi ll lm l ln lo">soup = BeautifulSoup(html_source,'lxml')</span></pre><p id="ab28" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">所以是的，差不多就是这样。如何以一种非常简单的方式进行网页抓取？</p><h1 id="62d4" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">奖金</h1><p id="cd53" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">如果你想知道所有吉他产品的名称和价格。基本上，在我们抓取了页面源之后，这意味着我们拥有了特定页面上的所有信息。我们可以用美丽的汤来获取那些特殊的信息。</p><p id="6696" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这个概念很简单。搜索存储产品名称或您想知道的任何内容的标签、类别或id。(我们将使用这些标签、类或id作为美汤的参数)。你可以使用谷歌浏览器中的检查元素功能，通过在mac中按下cmd+opt+i来找出标签、类或id。</p><h2 id="8f4e" class="lk ir hi bd is ma mb mc iw md me mf ja jz mg mh je kd mi mj ji kh mk ml jm mm bi translated">产品名称</h2><p id="2a7b" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">对于产品名，我检查了HTML源代码后，发现产品名在‘H4’标签和‘grid-card _ _ title’类中</p><p id="bbcb" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我已经在soup变量中存储了HTML源代码，所以我可以调用函数“find_all ”,并传递两个参数第一个是标记名和类名，以查找产品名。</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="2bc8" class="lk ir hi lg b fi ll lm l ln lo">all_product_name = soup.find_all('h4', class_='grid-card__title')</span></pre><p id="6e5c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">下面是结果，你可以看到我们有所有特定的h4标签和类grid-card__title。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/5e3fcdc74fb0d62ea4192fe13ec30b6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IF-oV6LpEQx_Zy3tYnqTzw.png"/></div></div></figure><p id="a8f5" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">那么，如果我们只想要那些标签中的文本呢？？就用。文本函数并循环遍历该列表。</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="804a" class="lk ir hi lg b fi ll lm l ln lo">[i.text for i in all_product_name]</span></pre><p id="8cef" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">嘭！我们得到了我们想要的。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/183faa0aeced9c914d1bc8dab9b58b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z3ZLZchivH4OA8D864WI3g.png"/></div></div></figure><h1 id="5b6a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论</h1><p id="10f6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">刮页来源<br/> -安装硒<br/> -安装美汤<br/> -下载web驱动</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="9103" class="lk ir hi lg b fi ll lm l ln lo">from bs4 import BeautifulSoup<br/>from selenium import webdriver<br/>import time<br/>URL = "www.whateverwebpage.com"</span><span id="9d12" class="lk ir hi lg b fi ly lm l ln lo">driver = webdriver.Chrome('directory/to/web_driver')<br/>driver.get(URL)<br/>time.sleep(3)<br/>html_source = driver.page_source<br/>soup = BeautifulSoup(html_source,'lxml')</span></pre><p id="2701" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">用美人汤刮后获得具体信息。了解更多<a class="ae kr" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#" rel="noopener ugc nofollow" target="_blank">美汤</a>。</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="be82" class="lk ir hi lg b fi ll lm l ln lo">#soup.find(tag_name,class or id)<br/>all_product_name = soup.find_all('h4', class_='grid-card__title')<br/>#return text inside tag <br/>[i.text for i in all_product_name]</span></pre><p id="fe85" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这就是在动态网站上抓取网页的基础，只需要5行代码。:)</p></div></div>    
</body>
</html>