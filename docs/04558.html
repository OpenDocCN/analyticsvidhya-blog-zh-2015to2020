<html>
<head>
<title>Concepts Extraction: How I learned to stop worrying and love multilingual data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">概念提取:我如何学会不再担心并热爱多语言数据</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/concepts-extraction-how-i-learn-to-stop-worrying-and-love-multilingual-data-b342ce13c52e?source=collection_archive---------11-----------------------#2020-03-24">https://medium.com/analytics-vidhya/concepts-extraction-how-i-learn-to-stop-worrying-and-love-multilingual-data-b342ce13c52e?source=collection_archive---------11-----------------------#2020-03-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/61a5ca63440b1ea75ed4b26a8f0f57cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rh9sG2Gq873UPu8yCht9SA.png"/></div></div></figure><div class=""/><div class=""><h2 id="feff" class="pw-subtitle-paragraph iq hs ht bd b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh dx translated">如何让不同语言的文本数据变得可以理解</h2></div><p id="6c9f" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">作为人类，我们喜欢在日常生活中使用文本。作为人类，我们喜欢和计算机一起工作。但问题是计算机不喜欢和文本打交道。当处理大量的文本数据时，我们需要自动处理它们。这就是NLP的用武之地！</p><p id="dd70" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">概念抽取是自然语言处理的一个领域，其重点是找出文本的语义。例如，你可以知道提到的人、地点、物体等等..它被用来更好地理解我们正在处理的数据。大多数工具只关注一小部分语言，尤其是英语。这就是为什么我们要使用中立的新闻API。Neutral News是一家专注于许多不同语言的NLP任务的公司。</p><p id="bc85" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><em class="ke">免责声明:这篇博客是由中立新闻的联合创始人写的，只是让你知道:)</em></p><p id="2429" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在这篇博客中，我将展示我们如何使用<a class="ae kf" href="https://neutralnews.fr/" rel="noopener ugc nofollow" target="_blank">中性新闻Api </a>从8种不同语言的文章集中突出主题。</p><p id="ae77" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这个API需要订阅才能使用，但幸运的是，我们提供300个请求的免费试用。这个教程就用它吧！你可以在这里注册<a class="ae kf" href="https://neutralnews.fr/accounts/register" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="ae08" class="kg kh ht bd ki kj kk kl km kn ko kp kq iz kr ja ks jc kt jd ku jf kv jg kw kx bi translated">让我们开始吧！</h1><p id="13f2" class="pw-post-body-paragraph ji jj ht jk b jl ky iu jn jo kz ix jq jr la jt ju jv lb jx jy jz lc kb kc kd hb bi translated">我们假设您已经安装了python3。你可以在这里找到我将要使用的语料库<a class="ae kf" href="https://drive.google.com/open?id=1QAKzfq4B37_EM1mtpPPmwRj0J1pdH1G7" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="3dff" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">让我们首先创建一个简单的函数来加载文章:</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="46b6" class="lm kh ht li b fi ln lo l lp lq">import json</span><span id="dbec" class="lm kh ht li b fi lr lo l lp lq">def get_data(path):<br/>    return json.load(open(path, 'r'))</span><span id="48f6" class="lm kh ht li b fi lr lo l lp lq">data = get_data('articles.json')</span></pre><h1 id="f524" class="kg kh ht bd ki kj kk kl km kn ko kp kq iz kr ja ks jc kt jd ku jf kv jg kw kx bi translated">API的第一步</h1><p id="5ded" class="pw-post-body-paragraph ji jj ht jk b jl ky iu jn jo kz ix jq jr la jt ju jv lb jx jy jz lc kb kc kd hb bi translated">中立新闻提供了一个Python客户端来简化API的使用。这很简单，让我们先安装它。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="6241" class="lm kh ht li b fi ln lo l lp lq">pip3 install PyNeutralNews</span></pre><p id="b60c" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">现在让我们创建客户机对象，它将使我们能够调用API(您将需要用您的免费试用凭证来替换凭证):</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="79ed" class="lm kh ht li b fi ln lo l lp lq">from PyNeutralNews import Client</span><span id="c059" class="lm kh ht li b fi lr lo l lp lq">client = Client("&lt;email&gt;", "&lt;password&gt;")</span></pre><p id="7b69" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">我们将使用下面的函数get_concepts从文本中获取提取的概念以及相关的权重。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="9848" class="lm kh ht li b fi ln lo l lp lq">from collections import Counter</span><span id="b9ab" class="lm kh ht li b fi lr lo l lp lq">def get_concepts(text, lang=None):</span><span id="2809" class="lm kh ht li b fi lr lo l lp lq">   res = client.nlp.semantic_analysis(text, lang, concepts_properties=["titles.en", "titles.auto"])</span><span id="12ed" class="lm kh ht li b fi lr lo l lp lq">   concepts = Counter()</span><span id="648f" class="lm kh ht li b fi lr lo l lp lq">   for concept in res.concepts:</span><span id="6c8a" class="lm kh ht li b fi lr lo l lp lq">        titles = concept.properties["titles"]</span><span id="bd80" class="lm kh ht li b fi lr lo l lp lq">        title = titles.get("en") or titles[res.lang]</span><span id="fc91" class="lm kh ht li b fi lr lo l lp lq">        concepts[title] += concept.weight</span><span id="d05c" class="lm kh ht li b fi lr lo l lp lq">    return concepts</span></pre><p id="7b9b" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在这里，我们可以看到我们有一个以概念名为关键字、以其权重为值的字典。权重对应于文本中概念的语义值。高权重意味着概念在文本中具有重要意义。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="aec4" class="lm kh ht li b fi ln lo l lp lq">&gt;&gt; get_concepts(data['ko'][0], 'ko')<br/>Counter({'United States': 0.16974641714195385,<br/>         'President (government title)': 0.11700783103451891,<br/>         'Justice Party (South Korea)': 0.11516047368626284,<br/>         'Facebook': 0.0977350464727538,<br/>         'Diplomacy': 0.09208318129951651,<br/>         'Washington, D.C.': 0.09057665492040855,<br/>         'Mass media': 0.07374152731976248,<br/>         'German reunification': 0.06379742089362807,<br/>         'Literature': 0.06115040296658773,<br/>         'Ambassador': 0.06047045207677463,<br/>         'Human': 0.058530592187832624})</span></pre><p id="03ad" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">有用！很好，现在让我们创建一个函数，它将存储语料库中的每个概念及其出现次数和累积权重。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="fd45" class="lm kh ht li b fi ln lo l lp lq">def get_all_concepts(corpus):<br/>    concepts = {}<br/>    for lang, data in corpus.items():<br/>        print('get concepts from', lang)<br/>        for i, article in enumerate(data):<br/>            if (i + 1) % 10 == 0:<br/>                print(i, '/', len(data))<br/>                break<br/>            res = get_concepts(article, lang)<br/>            for concept, weight in res.items():<br/>                if concept not in concepts:<br/>                    concepts[concept] = (0, 0)<br/>                c, w = concepts[concept]<br/>                concepts[concept] = (c + 1, w + weight)<br/>    return concepts</span><span id="ba59" class="lm kh ht li b fi lr lo l lp lq">concepts = get_all_concepts(data)</span></pre><p id="32fb" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">我们将首先根据出现的频率画出最常见的概念。</p><pre class="ld le lf lg fd lh li lj lk aw ll bi"><span id="c0b2" class="lm kh ht li b fi ln lo l lp lq">import matplotlib.pyplot as plt<br/>import numpy as np</span><span id="7147" class="lm kh ht li b fi lr lo l lp lq">concepts_occ = {k: v[0] for k, v in sorted(concepts.items(), key=lambda item: item[1][0])[::-1]}</span><span id="5abb" class="lm kh ht li b fi lr lo l lp lq">def plot_concepts(concepts, limit=10):<br/>    <br/>    fig, ax = plt.subplots(figsize=(20, 10))<br/>    ax.bar(np.arange(limit), height=list(concepts.values())[:limit], tick_label=list(concepts.keys())[:limit])</span><span id="16f7" class="lm kh ht li b fi lr lo l lp lq">plot_concepts(concepts_occ)</span></pre><figure class="ld le lf lg fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ls"><img src="../Images/e769ae14f8d7931f7e195d858dbd683a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gvvM1kPa6tZY6RhpzS56Tg.png"/></div></div></figure><p id="1fca" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">不错！我们现在开始对语料库中的主要主题有了一个很好的想法。但是我们仍然有一些词对我们没有真正的帮助。让我们看看是否可以通过考虑权重来摆脱它们，进行更精确的语义分析。</p><figure class="ld le lf lg fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lt"><img src="../Images/22afcea2b1a4e935d577f1bd1c03a65c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AvEFK8-9yWRWNsfoDTHA2Q.png"/></div></div></figure><p id="818d" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">现在，我们对文章语料库中的主要主题有了更好的概述。任务完成！😃</p><figure class="ld le lf lg fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lu"><img src="../Images/6aaf75acd5cc165aa873319bf90763a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*olsloRJjihhWDEkTM3Ao_Q.png"/></div></div></figure><h1 id="c05f" class="kg kh ht bd ki kj kk kl km kn ko kp kq iz kr ja ks jc kt jd ku jf kv jg kw kx bi translated">下一步是什么？</h1><p id="a84c" class="pw-post-body-paragraph ji jj ht jk b jl ky iu jn jo kz ix jq jr la jt ju jv lb jx jy jz lc kb kc kd hb bi translated">现在我们有了我们的主题，我们可以做更多的事情！例如，我们可以对我们的新数据进行聚类，以找到不同语言的相关文章。</p></div></div>    
</body>
</html>