<html>
<head>
<title>Movie Recommendations System(Spark, SQL with Python)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">电影推荐系统(Spark，SQL和Python)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/movie-recommendations-system-spark-sql-with-python-4ad29f238ab?source=collection_archive---------7-----------------------#2020-05-21">https://medium.com/analytics-vidhya/movie-recommendations-system-spark-sql-with-python-4ad29f238ab?source=collection_archive---------7-----------------------#2020-05-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="b138" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用Spark在AWS上的集群管理器，从100万个评级中创建了“相似电影推荐”模型。执行SQL命令，SQL风格的函数，并通过MLLib改进电影推荐模型。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/0aec24c987a157139d2c7ab7d73c6f14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l9dIvOVH5KhpK1LFvgoClA.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片来源:互联网</figcaption></figure><p id="3c77" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">由于近年来电影业技术的进步，越来越多的人在舒适的沙发上欣赏他们最喜欢的电影。因此，看到网飞、Hulu、Disney+等不同电影流媒体服务之间争夺霸主地位的大战就不足为奇了。跨越新闻头条(亚历山大，2020)。尽管有不同的营销策略和原创内容，但所有这些网站都有一个共同点:“电影推荐系统”。</p><p id="1bc2" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">通过两种方法向观众推荐电影:协同过滤或基于内容的过滤。基于内容的过滤基于你观看历史的基因做出了他们的预测，如果你喜欢《老友记》或《疯狂动物城》，那么你会在你的推荐列表中看到《Shazam》，这是纯粹的“喜剧”。另一方面，协同过滤系统是基于相似用户的历史来进行预测的。电影流媒体服务同时使用两者以获得最佳效果。(基尔日纳，2018年)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kj"><img src="../Images/5d81fc574f41e7876c5d49481a03b0dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X9T91TjJeE2hN0op5uUsyg.png"/></div></div></figure><p id="11ea" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这个项目中，我们将探索使用Python中的Spark代码为《星球大战》(1997)电影获得电影推荐的协同过滤方法。这些推荐是由那些在观看《星球大战》(1997)的同时评论了其他电影的人的观看历史产生的。如果他们对《星球大战》(1997)的评价很高，他们很可能也会对其他类似的电影有同样的想法。该项目使用三个独立的数据集:</p><ol class=""><li id="62b3" class="kk kl hi jp b jq jr jt ju jw km ka kn ke ko ki kp kq kr ks bi translated"><strong class="jp hj"> u.ITEM </strong>文件包含:“电影ID”、“电影名称”</li><li id="dc0c" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated"><strong class="jp hj"> u.DATA </strong>文件包含:100，000个电影评级的“用户ID”、“电影ID”、“电影操作”、“时间戳”。数据集来自1998年</li><li id="b504" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated"><strong class="jp hj">“收视率”</strong>文件包含类似于<strong class="jp hj"> u.DATA </strong>文件的功能，但适用于100万电影收视率。数据集来自2003年</li></ol></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="1164" class="lf lg hi bd lh li lj lk ll lm ln lo lp io lq ip lr ir ls is lt iu lu iv lv lw bi translated"><strong class="ak"> I/探索性数据分析(EDA) </strong></h1><p id="338f" class="pw-post-body-paragraph jn jo hi jp b jq lx ij js jt ly im jv jw lz jy jz ka ma kc kd ke mb kg kh ki hb bi translated">首先，我们将引入的Pyspark包运行到Anaconda环境中。每次运行程序时，我们都需要在“本地”设置正确的上下文和一些配置。然后我创建了弹性分布式数据集(RDD)，这是分布在集群中许多机器上的数据元素的分布式集合，通常在Java或Scala编程中更常见。之后，我们指定使用lambda的“map”函数将数据解析为不同的值，并通过countByValue()函数根据值对所有评论进行计数。因此，我们会将每个评论分数分类为一个关键，而具有类似分数的评论数量在RDD的价值。下面的结果告诉我们，观众在评分时通常是慷慨的，大多数电影的评分在2到4之间，其中4是评论数量最多的。只有大约2000部电影被评为最佳或经典电影，这需要真正的努力。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mc"><img src="../Images/14ef470c938c5c43a75e42d9e29e4e08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*RxLqO4ZHWx5ZiSyjKZU0Kg.png"/></div></figure><p id="2b53" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来，我们将使用map()函数和lambda方法创建“movies”变量，只提取一个“MovieID”列表作为键，并将每一行的值赋为“1 ”,以便我们稍后可以将它们加在一起。然后，我们通过reduceByKey()函数将共享同一个“MovieID”键的所有行加起来，计算一部电影被评论的次数。之后，我们交换了键和值之间的位置，以便“出现次数”成为键，而“MovieID”成为值。通过sortByKey()，我们发现“50”是最受欢迎的电影，有584条评论。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es md"><img src="../Images/533f767dcd9f8e337aa2152250dd10ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*uJh93BtjkFx1w3rmStlZ0Q.png"/></div></figure><p id="c869" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">为了检查它是什么电影，我们建立了一个字典来匹配“电影ID”和“电影名称”。后来我们终于发现，一直以来都是《星球大战(1997)》</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es me"><img src="../Images/5e11d7239834b292bd6f03f721b48705.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*OPpPZSFaR4D8DsTG4Dli_g.png"/></div></figure></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="eebc" class="lf lg hi bd lh li lj lk ll lm ln lo lp io lq ip lr ir ls is lt iu lu iv lv lw bi translated"><strong class="ak"> II/电影推荐和潜在模型优化方法</strong></h1><p id="f475" class="pw-post-body-paragraph jn jo hi jp b jq lx ij js jt ly im jv jw lz jy jz ka ma kc kd ke mb kg kh ki hb bi translated">为了重新创建电影推荐系统，我们必须遵循三个步骤。首先，我们<strong class="jp hj"> </strong>找到由同一个人观看的每一对电影。然后，我们在观看了这两部电影的所有用户中测量他们的评分的相似性。最后，我们先按电影排序，然后按相似度排序</p><p id="231b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">通过代码的方法:</strong></p><ol class=""><li id="9c22" class="kk kl hi jp b jq jr jt ju jw km ka kn ke ko ki kp kq kr ks bi translated">将输入分级映射到(用户ID，(电影ID，分级))</li><li id="92e7" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">查找评级为同一用户的每一对电影</li></ol><blockquote class="mf mg mh"><p id="4486" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">这可以通过“自加入”操作来完成</p><p id="6ebf" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">此时，我们有(userID，((电影ID1，评级1)，(电影ID2，评级2)))</p></blockquote><p id="1788" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">3.过滤掉重复的对</p><p id="02b3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">4.让电影配对成为关键</p><blockquote class="mf mg mh"><p id="0840" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">映射到((movieID1，movieID2)，(rating1，rating2) /// movieID: keys，rating: values</p></blockquote><p id="1471" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">5.groupByKey()来获取为每个电影对找到的每个评级对</p><p id="57a8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">6.计算电影对中每个电影的评分之间的相似性</p><p id="8d19" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">7.排序、保存和显示结果</p><p id="e99b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">值得注意的是，我们使用的模型实现了“共面度量”。我们还将最低共同评价人或最低分数的阈值设置为0.95，将发生阈值设置为50。与其他项目不同，这不能用Jupyter笔记本上的脚本来完成，而是用Anaconda提示符来完成。在开始菜单的Anaconda提示符下运行命令‘spark-submit Movies-similarities . py 50’。确保将文件保存在中。py而不是。ipynb格式，并在正确的驱动器上运行您的代码，以便它可以顺利运行。完成后，我们有以下最终建议:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/ed6ee6d8d36308666648ecd79d064e69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*na2c877rHE0YGB7X-lxfkw.png"/></div></div></figure><p id="2f27" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">“分数”表明你的预测有多准确，“强度”象征着看过《星球大战》(1977)的类似用户的数量。在这份报告中,“得分”更可信，这就是为什么我们在推荐《绝地归来》之前推荐《帝国反击战》,尽管后者实力较低。然而，我们需要确保适度的“实力”门槛，因为我们有一些不相关的推荐，如《海底两万里》(20，000 leafs of the Sea)、《近距离》(Close Shave)和《超级无敌掌门狗》(Wallace &amp; Gromit)，只有不到100篇类似的评论。</p><p id="4609" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">有五种方法可以改进结果，即未来的研究者改进模型</strong>:</p><blockquote class="mf mg mh"><p id="3dc4" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">丢弃所有像“1”这样的坏评级，只保留好的推荐</p><p id="a60e" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">尝试不同的相似性度量，而不是“同侧度量”，如皮尔逊相关系数、贾卡系数、条件概率</p><p id="5dac" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">发明一种新的相似性度量标准，将共同评价者的数量考虑在内</p><p id="a297" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">通过使用类型数据集将“内容过滤方法”与“协作过滤”相结合，以逼真地模拟电影推荐系统</p><p id="b667" class="jn jo mi jp b jq jr ij js jt ju im jv mj jx jy jz mk kb kc kd ml kf kg kh ki hb bi translated">调整我们上面设置的阈值</p></blockquote><p id="d42f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这种情况下，我们将查看前3项建议旁边的，系统将建议我们修改阈值的其他3项建议是什么。我们忽略前三部电影的原因是因为它们的“得分”都在300分以上，如果我们包括它们，我们的比较就没有用了。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mn"><img src="../Images/ef59ad1eb6ccff6d27c042f07a584e51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*ynn0jB0xgrm4xTMebSS-KQ.png"/></div></figure><p id="ff0c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">从上表可以清楚地看出，最后一个阈值分数组合是最好的，因为它包括了所有在类型方面与《星球大战1977》相似的经典作品:冒险、动作和科幻</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="ddc8" class="lf lg hi bd lh li lj lk ll lm ln lo lp io lq ip lr ir ls is lt iu lu iv lv lw bi translated"><strong class="ak"> III/云集群上的电影推荐(亚马逊网络服务-EC2) </strong></h1><p id="9c4f" class="pw-post-body-paragraph jn jo hi jp b jq lx ij js jt ly im jv jw lz jy jz ka ma kc kd ke mb kg kh ki hb bi translated">在这一部分中，我们使用AWS中的EC2在云集群上运行Spark，从而获得了一百万个电影评级，而不仅仅是100.000个。</p><h2 id="6958" class="mo lg hi bd lh mp mq mr ll ms mt mu lp jw mv mw lr ka mx my lt ke mz na lv nb bi translated"><strong class="ak">a)AWS Elastic MapReduce和PartitionBy()简介</strong></h2><p id="91ee" class="pw-post-body-paragraph jn jo hi jp b jq lx ij js jt ly im jv jw lz jy jz ka ma kc kd ke mb kg kh ki hb bi translated"><strong class="jp hj"> AWS弹性MapReduce: </strong></p><ol class=""><li id="6c4c" class="kk kl hi jp b jq jr jt ju jw km ka kn ke ko ki kp kq kr ks bi translated">在您自己的集群上租用时间的非常快速和简单的方法</li><li id="4d38" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">在Hadoop的Yarn集群管理器上为您设置默认的spark配置</li><li id="6911" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">Spark还有一个内置的独立集群管理器和脚本来建立自己的基于EC2的集群(Barr，2009)</li><li id="4dcf" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">EMR上的Spark并不贵，但也不便宜</li><li id="ea46" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">确保首先在数据的一个子集上本地运行</li></ol><p id="f682" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> PartitionBy(): </strong>是RDD上的一个方法，你可以用它来说“嘿，我要运行一些大型操作，但是我没有足够的计算机资源来实际上把它分成许多不同的执行器，许多不同的运行”这基本上告诉我我想把这个作业分成多少部分。确定多少分区是足够的非常重要</p><ol class=""><li id="4792" class="kk kl hi jp b jq jr jt ju jw km ka kn ke ko ki kp kq kr ks bi translated">太少，我们将无法充分利用您的群集</li><li id="18a8" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">太多会导致混排数据的开销太大</li><li id="1e27" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">至少要有与可用内存中的内核或执行器一样多的分区</li><li id="353c" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">对于大型操作，在10台计算机上使用partition by(100)通常是一个合理的起点</li></ol><h2 id="0628" class="mo lg hi bd lh mp mq mr ll ms mt mu lp jw mv mw lr ka mx my lt ke mz na lv nb bi translated"><strong class="ak"> b)流程和审核:</strong></h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nc"><img src="../Images/c7d65169440d9f1f33b4098f5c564bdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H-Q1R777SQSgOIvyuqlKqw.png"/></div></div></figure><ol class=""><li id="dac4" class="kk kl hi jp b jq jr jt ju jw km ka kn ke ko ki kp kq kr ks bi translated">我们将使用<strong class="jp hj">‘u . DATA’</strong>文件，但对于100万电影收视率。我们从s3n加载数据，而不是Amazon simple stories服务上的普通日志。数据集存储在云系统本身，而不是我们保存在计算机上的实际文件。(Sundog-Spark)。SparkConf是空的，而不是后面有东西，因为我要在命令行上传递它。利用EMR elastic Map Reduce上的一些预聚集的东西，这些东西会自动告诉Spark在Hadoop线程上运行</li></ol><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/8b3071ca0c0787dcaf4c7216353d1bef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gTCjpVOzt3VAm_bcuWvwZg.png"/></div></div></figure><p id="4a12" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">2.重复我们在第二部分中创建的代码。</p><p id="c05a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">3.打开AWS，通过在驱动程序中使用一个空的默认SparkConf来指定每个执行器的<strong class="jp hj">内存——这样，我们将使用默认的EMR设置，以及您从主节点传递到spark-submit的任何命令行选项。在这个项目中，默认的executor内存预算512MB不足以处理一百万个电影评级。因此，我们必须做的是:</strong></p><blockquote class="ne"><p id="be21" class="nf ng hi bd nh ni nj nk nl nm nn ki dx translated">spark-submit-executor-memory 1g电影-相似点-1M.py 260</p></blockquote><p id="e27b" class="pw-post-body-paragraph jn jo hi jp b jq no ij js jt np im jv jw nq jy jz ka nr kc kd ke ns kg kh ki hb bi translated">(从我们集群的主节点。executor-memory 1g用于指定u将为每个executor放置1gb，以便顺利运行一切)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nt"><img src="../Images/571b4a02a3154973b7884a03fd7fa1aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jTfR2UOODjTwaWhJ5X7b2g.png"/></div></div></figure><p id="aa49" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">4.在联机集群上运行数据集。为了做到这一点，我们必须经历许多小步骤。我们将脚本和数据放在EMR可以轻松访问的地方。接下来，使用AWS控制台为Spark启动EMR集群，<strong class="jp hj">其中，AWS在那一刻开始计费。</strong>然后，获取主节点的外部DNS名称，并使用“Hadoop”用户帐户和您的私钥文件登录。复制你的驱动程序和任何需要的文件。最后，运行spark-submit并观察输出。</p><blockquote class="ne"><p id="f50f" class="nf ng hi bd nh ni nj nk nl nm nn ki dx translated"><strong class="ak"> <em class="nu">但是一定要记得在完成后终止集群</em> </strong></p></blockquote><figure class="nw nx ny nz oa jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nv"><img src="../Images/028d2ef871e2b1ac74fd681b32393e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s1T1A5ecZe_cBFhjwbCkww.jpeg"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ob"><img src="../Images/6e1c376af04d6eda50e7a55f00e90255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2uORqiE_teDfZLVgqbRf2w.png"/></div></div></figure><p id="4e93" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">就像我们之前的《星球大战:第五集》是最相似的电影。但在那之后，《三十郎(1962)》和《无声无息，深入运行》分别以0.9877和0.9791的“分数”排名第二和第五。然而，当我们看“实力”时，只有60人评价“星球大战4”，也评价“三十郎(1962)”，只有145人评价“无声无息，深入运行”。这些都是很低的值。由于我们正在处理100万个结果，因此最好将“强度”阈值提高一点，以显示更正确的结果，如“夺宝奇兵”或“星球大战:第六集”。后来，我们将发生阈值从50固定为1000，以便它可以产生更准确的值</p><p id="0ccd" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">请记住，我们稍后可能会遇到一些问题。其中之一是当我们有遗嘱执行人未能发出心跳。因此，当您对每个执行器要求太多，并且需要更多执行器时，您可以修改partitionBy()，通过使用更小的分区来减少每个执行器的工作量。另一个问题是管理依赖关系，因为你的执行器有时可能不属于你的驱动脚本。我们既可以使用广播变量来共享RDD之外的数据，也可以使用一些没有预装在EMR上的Python包。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="53b6" class="lf lg hi bd lh li lj lk ll lm ln lo lp io lq ip lr ir ls is lt iu lu iv lv lw bi translated"><strong class="ak">使用Spark的机器学习库(MLlib)的IV/电影推荐系统</strong></h1><h2 id="ff17" class="mo lg hi bd lh mp mq mr ll ms mt mu lp jw mv mw lr ka mx my lt ke mz na lv nb bi translated"><strong class="ak"> a) MLlib能力</strong></h2><ol class=""><li id="a525" class="kk kl hi jp b jq lx jt ly jw oc ka od ke oe ki kp kq kr ks bi translated"><strong class="jp hj">特征提取</strong>:对搜索有用的词频/逆文档频率</li><li id="affd" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated"><strong class="jp hj">基本统计</strong>:卡方检验、皮尔逊或斯皮尔曼相关、最小值、最大值、平均值、方差</li><li id="2c6c" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated"><strong class="jp hj"> ML模型</strong>:线性回归、逻辑回归、SVM、朴素贝叶斯、决策树、K均值聚类(McDonald，2019)</li><li id="3518" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">分析的主成分，奇异值分解</li><li id="c75b" class="kk kl hi jp b jq kt jt ku jw kv ka kw ke kx ki kp kq kr ks bi translated">使用交替最小二乘法的建议</li></ol><p id="0a6d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">MLlib数据有三种类型:矢量(密集或稀疏)，标记点，评级</p><h2 id="b2f8" class="mo lg hi bd lh mp mq mr ll ms mt mu lp jw mv mw lr ka mx my lt ke mz na lv nb bi translated"><strong class="ak"> b)流程和评审:</strong></h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es of"><img src="../Images/2041ced0267b1aa9e3ff1d1a678535a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*0xCSaYwDaFW0HJ3n8IV-Ug.png"/></div></figure><p id="0e3d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们首先向<strong class="jp hj"> u. Data </strong>添加了3个以上的假评论来测试我们的模型，创建了配置和检查点。然后，我们加载数据并训练模型</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es og"><img src="../Images/ee4b4d9a0328156c1ad14e604ccdf73d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*Tmf6kl5inrNW3FxfT00L2g.png"/></div></figure><p id="d283" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">每次运行代码时，它都会产生与之前不同的结果。不幸的是，所有numIterations = 20的电影推荐都与《星球大战帝国反击战》不相似。在numIterations = 6的情况下，该模型推荐的《美国水牛城》(American Buffalo)或《哈莱姆(Harlem，1993)》甚至与《星球大战》(Star War)电影相去甚远。这些都是粗略的结果，我们可以进一步改进模型。如果模型对所选参数非常敏感，我们可以将数据分为“训练”和“测试”组，以评估参数的各种排列。创建一个嵌套循环(黑盒),尝试你能想到的所有组合。但是这是相当不可靠的，因为你可以过度拟合结果。如果我们在不同的人使用它的地方或者从不同的时间框架改变他们的UI，这种方法的预测并不总是有效的。因此，在分析大数据时，我们需要始终保持警惕和怀疑，即使我们的模型。在这种情况下，normal Spark实际上提供了比MLLib更准确的结果。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="fdfb" class="lf lg hi bd lh li lj lk ll lm ln lo lp io lq ip lr ir ls is lt iu lu iv lv lw bi translated"><strong class="ak">用SparkSQL和DataFrames简化代码</strong></h1><p id="7aa4" class="pw-post-body-paragraph jn jo hi jp b jq lx ij js jt ly im jv jw lz jy jz ka ma kc kd ke mb kg kh ki hb bi translated">在这个项目的这一部分，我们将看到SparksSQL如何帮助我们简化与RDD相比的数据帧代码。Dataframe属于数据集伞，DataFrame是一个表或类似二维数组的结构，其中每列包含一个变量的值，每行包含每列的一组值。(Geeksforgeeks，2019)由于与RDD相比具有距离优势，它被认为是Spark的未来。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es oh"><img src="../Images/b700bb39815dee89adbcc73f43f5fb9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*02UwsePTHCbTekvJDJ3h2Q.png"/></div></figure><p id="375b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">与之前的大块代码不同，当我们对SQL使用DataFrame而不是RDD格式时，代码更加充分。所有的动作都可以呈现在一行代码中，如下所示。我们可以同时根据ID对数据进行分组，然后对它们进行计数，然后按照电影评论的数量进行升序排序。与《星球大战(1997)》是最受欢迎的电影相比，我们以更快的速度实现了相同的EDA分析。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es oi"><img src="../Images/e05f88589685da4467a67430129705a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*UBD64j7Hb_-kbq4lv4UyMg.png"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es oj"><img src="../Images/fd0ae4eeb8595068ec5b623874dbf71c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*uf-xsX3SnNBSiGag5N0vnQ.png"/></div></figure><h1 id="a850" class="lf lg hi bd lh li ok lk ll lm ol lo lp io om ip lr ir on is lt iu oo iv lv lw bi translated"><strong class="ak">六/结论</strong></h1><p id="552f" class="pw-post-body-paragraph jn jo hi jp b jq lx ij js jt ly im jv jw lz jy jz ka ma kc kd ke mb kg kh ki hb bi translated">这个项目是一个很好的机会，让我们了解Spark是如何根据协作过滤方法在中构建有效的电影推荐系统的。这也证明了机器学习并不总是关于使用最先进的技术，而是我们实际上对问题的理解程度。通过简单的Spark代码战胜复杂的MLlib，可以明显看出</p><p id="60f8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">Github</strong>:<a class="ae op" href="https://github.com/Lukastuong123/Python-Projects/tree/master/Project-%20Movie%20Recommendations%20(Spark%2C%20SQL%20with%20Python)" rel="noopener ugc nofollow" target="_blank">https://Github . com/lukastuong 123/Python-Projects/tree/master/Project-% 20 movie % 20建议% 20(Spark % 2C % 20 SQL % 20 with % 20 Python)</a></p><p id="bf3c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">参考&amp;来源:</strong></p><p id="7b10" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">极客forgeeks。(2019).</strong> Python |熊猫DataFrame。从https://www.geeksforgeeks.org/python-pandas-dataframe/<a class="ae op" href="https://www.geeksforgeeks.org/python-pandas-dataframe/" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="e37c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">亚历山大，J. (2020) </strong>。流媒体战争终于开始了，但这更多的是一场礼貌的争吵，而不是全面战争。检索自<a class="ae op" href="https://www.theverge.com/2020/2/6/21126156/streaming-wars-disney-plus-netflix-wall-street-subscribers-hbo-max-peacock" rel="noopener ugc nofollow" target="_blank">https://www . the verge . com/2020/2/6/21126156/streaming-wars-Disney-plus-网飞-wall-street-subscribers-HBO-max-peacock</a></p><p id="0252" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">麦克唐纳，C. (2019)。</strong>阿帕奇Spark机器学习教程| MapR。检索自<a class="ae op" href="https://mapr.com/blog/apache-spark-machine-learning-tutorial/" rel="noopener ugc nofollow" target="_blank">https://mapr . com/blog/Apache-spark-machine-learning-tutorial/</a></p><p id="8db4" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">巴尔，J. (2009年4月2日)。宣布亚马逊弹性MapReduce。检索自<a class="ae op" href="https://aws.amazon.com/blogs/aws/announcing-amazon-elastic-mapreduce/" rel="noopener ugc nofollow" target="_blank">https://AWS . Amazon . com/blogs/AWS/announcing-Amazon-elastic-MapReduce/</a></p><p id="3875" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> Kirzhner，E. (2018)。</strong>机器学习。协同过滤与基于内容的过滤的解释。检索自<a class="ae op" href="https://codeburst.io/explanation-of-recommender-systems-in-information-retrieval-13077e1d916c" rel="noopener" target="_blank">https://code burst . io/explain-of-recommender-systems-in-information-retrieval-13077 E1 d 916 c</a></p><p id="2b9b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">电影评论数据集【https://grouplens.org/datasets/movielens/】:<a class="ae op" href="https://grouplens.org/datasets/movielens/" rel="noopener ugc nofollow" target="_blank"/></strong></p><p id="63f0" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">灵感来源:凯恩，F. (2020)。</strong>用Apache Spark和Python驯服大数据——动手吧！[幻灯片]。检索自<a class="ae op" href="https://www.udemy.com/course/taming-big-data-with-apache-spark-hands-on/" rel="noopener ugc nofollow" target="_blank">https://www . udemy . com/course/taming-big-data-with-Apache-spark-hands-on/</a></p></div></div>    
</body>
</html>