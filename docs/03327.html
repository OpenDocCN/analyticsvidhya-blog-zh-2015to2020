<html>
<head>
<title>Using MaskRCNN to predict tropical fruits in custom dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用MaskRCNN预测自定义数据集中的热带水果</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/using-maskrcnn-to-predict-tropical-fruits-in-custom-dataset-4f079d05fbe1?source=collection_archive---------9-----------------------#2020-01-26">https://medium.com/analytics-vidhya/using-maskrcnn-to-predict-tropical-fruits-in-custom-dataset-4f079d05fbe1?source=collection_archive---------9-----------------------#2020-01-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ba3eabfec607a10680e702322bd60e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rSrWtqTj_F4e1yjSKSrfKg.jpeg"/></div></div></figure><p id="26fe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在自定义数据集上使用Mask_RCNN预测水果的应用程序，这是一个如何为自定义数据集创建对象检测应用程序的简单教程，作为一个示例，我们在这种情况下只使用热带水果的数据集(橙子和菠萝)。</p><p id="5c94" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">github中的源代码:<a class="ae jo" href="https://github.com/bernardcaldas/object-detection-custom-maskrcnn" rel="noopener ugc nofollow" target="_blank">https://github . com/bernardcaldas/object-detection-custom-maskrcnn</a></p><h1 id="8d1b" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">计算机视觉</h1><p id="2a86" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">近年来，我们可以在生活中看到很多应用，包括自动驾驶汽车、面部检测应用、教育、军事、金融等。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/60a6e3976822acc01e378103ff707ee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*ix87wCMBqwbBX-SLhN5MSA.gif"/></div></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/279b619626672908a4793a963caaec24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*rwSLV6prludthrPmC6BJvw.gif"/></div></div></figure><h1 id="85ba" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">实例分割</h1><p id="83b2" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">实例分割识别对象、检测和描绘图像中出现的每个感兴趣的不同对象是一项任务。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/f72c095b91ab09e0c061d71cc642d38c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ri3dfxm6NQ_zi7LJW8inyw.png"/></div></div></figure><p id="091e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">跟随Waleed Abdulla的帖子，解释R-CNN是一种最常用的图像分割和检测对象的算法。</p><div class="kz la ez fb lb lc"><a href="https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46" rel="noopener  ugc nofollow" target="_blank"><div class="ld ab dw"><div class="le ab lf cl cj lg"><h2 class="bd hj fi z dy lh ea eb li ed ef hh bi translated">色彩的飞溅:使用掩膜R-CNN和张量流的实例分割</h2><div class="lj l"><h3 class="bd b fi z dy lh ea eb li ed ef dx translated">通过构建彩色飞溅滤镜来解释</h3></div><div class="lk l"><p class="bd b fp z dy lh ea eb li ed ef dx translated">engineering.matterport.com</p></div></div><div class="ll l"><div class="lm l ln lo lp ll lq io lc"/></div></div></a></div><h1 id="3810" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">为自定义数据集创建对象分段</h1><p id="def1" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">对于这个任务，这是一个非常好的工具，可以从名为<a class="ae jo" href="https://github.com/EscVM/OIDv4_ToolKit" rel="noopener ugc nofollow" target="_blank"> OIDv4_ToolKit </a>的google images下载图像，在克隆了repo并安装了所需的包之后，我们可以通过下面的命令行下载图像。</p><pre class="kt ku kv kw fd lr ls lt lu aw lv bi"><span id="0ca2" class="lw jq hi ls b fi lx ly l lz ma">python3 main.py downloader --classes Pineapple Orange --type_csv validation</span></pre><h1 id="e345" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">1.注释图像</h1><p id="1bc4" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">使用工具VIA，我们可以注释数据集中的图像，如下图所示</p><p id="7af1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">VIA工具链接:<a class="ae jo" href="https://www.robots.ox.ac.uk/~vgg/software/via/via-1.0.6.html" rel="noopener ugc nofollow" target="_blank">https://www . robots . ox . AC . uk/~ vgg/software/VIA/VIA-1 . 0 . 6 . html</a></p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/04134a9b87471c5d7345651518414797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yp5pFIGpamSqLBSP6CnTsg.png"/></div></div></figure><p id="f82a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注释完所有图像后，我们需要生成一个json文件，其中包含项目中使用的所有坐标，作为标准的“via_region_data.json”。</p><h1 id="6803" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">2.设置环境</h1><p id="2a12" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">让我们从matterport mask rcnn克隆repo并安装所需的软件包</p><div class="kz la ez fb lb lc"><a href="https://github.com/matterport/Mask_RCNN" rel="noopener  ugc nofollow" target="_blank"><div class="ld ab dw"><div class="le ab lf cl cj lg"><h2 class="bd hj fi z dy lh ea eb li ed ef hh bi translated">matterport/Mask_RCNN</h2><div class="lj l"><h3 class="bd b fi z dy lh ea eb li ed ef dx translated">这是Mask R-CNN在Python 3、Keras和TensorFlow上的实现。该模型生成边界框和…</h3></div><div class="lk l"><p class="bd b fp z dy lh ea eb li ed ef dx translated">github.com</p></div></div><div class="ll l"><div class="mc l ln lo lp ll lq io lc"/></div></div></a></div><ul class=""><li id="ef69" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated">安装依赖项</li></ul><pre class="kt ku kv kw fd lr ls lt lu aw lv bi"><span id="3083" class="lw jq hi ls b fi lx ly l lz ma">pip3 install -r requirements.txt</span></pre><ul class=""><li id="d20a" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated">从存储库根目录运行安装程序</li></ul><pre class="kt ku kv kw fd lr ls lt lu aw lv bi"><span id="58d8" class="lw jq hi ls b fi lx ly l lz ma">python3 setup.py install</span></pre><p id="e48d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从目录“samples/balloon”中复制一份，并使用您的项目名称重命名，在本例中为“samples/tropical”</p><p id="67a1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在此结构中创建一个“train”和“val”文件夹，并移动之前用json文件注释的文件，请考虑在您的结构中拆分80%的train和20%的validations文件。</p><p id="c98a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结构项目</p><p id="5698" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">-热带<br/> | <br/> | <br/> ballonn.py</p><ul class=""><li id="3c77" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated">火车文件夹<br/>|<br/>file1.png<br/>file2.png<br/>。<br/>。<br/>via _ region _ data . JSON<br/>|<br/>|<br/>-val文件夹<br/>|<br/>file1.png<br/>file2.png<br/>。<br/>。<br/> via_region_data.json</li></ul><h1 id="2605" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">3.设置代码</h1><p id="11dc" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">让我们在“samples/tropica/balloon . py”中设置代码，首先从自定义数据集中重命名该文件，在本例中为“samples/tropica/fruits.py”。</p><p id="bbeb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在现在的fruits.py文件中，让我们做一些如下的改变。</p><p id="210e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#气球配置到水果配置</p><p id="85c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#气球数据集到水果数据集</p><figure class="kt ku kv kw fd ij"><div class="bz dy l di"><div class="mm mn l"/></div></figure></div><div class="ab cl mo mp gp mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="hb hc hd he hf"><h1 id="805e" class="jp jq hi bd jr js mv ju jv jw mw jy jz ka mx kc kd ke my kg kh ki mz kk kl km bi translated">4.使用迁移学习训练模型</h1><p id="fc9c" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">使用下面的代码之一，我们将使用COCO模型或imagenet的权重来训练模型。</p><figure class="kt ku kv kw fd ij"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="cf21" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本次培训的重量将保存在每个时期的日志文件夹中，我们可以使用tensorboard查看我们模型的结果和指标，请键入:</p><p id="2b8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"># tensor board—logdir = path/to/logs</p><p id="c7f8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本地端口6006上运行时，结果将与此类似</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/9719d648033a5c3b9feca8090ed5ed0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ao3d-U42XIP5VGFBhPwJA.png"/></div></div></figure><p id="0223" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们有了模型训练lets run，文件夹中名为inspect_balloon_model.ipynb的笔记本，并配置以查看结果；</p><p id="d31e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">函数来预测单个文件；</p><figure class="kt ku kv kw fd ij"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="3e4a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果；</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/4d057077dbaf2c420aaadfc53430344e.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*PeSM4u_-DQhZIy-zwJt8TQ.jpeg"/></div><figcaption class="nc nd et er es ne nf bd b be z dx translated">原始文件</figcaption></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ng"><img src="../Images/978116116d804abe458ff06c71d3516a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5CG7_OmGFvwShgwVRRp4wA.png"/></div></div><figcaption class="nc nd et er es ne nf bd b be z dx translated">预测图像</figcaption></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a408629d999fadccb691f73728a3b353.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kme0j0F_GqMiQAQNKT0Xtw.jpeg"/></div></div><figcaption class="nc nd et er es ne nf bd b be z dx translated">原始文件</figcaption></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nh"><img src="../Images/f068ed97e17818addb229efc30546185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J0T4gKnAdgSKRkybTvYI0g.png"/></div></div><figcaption class="nc nd et er es ne nf bd b be z dx translated">预测图像</figcaption></figure></div><div class="ab cl mo mp gp mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="hb hc hd he hf"><h1 id="2447" class="jp jq hi bd jr js mv ju jv jw mw jy jz ka mx kc kd ke my kg kh ki mz kk kl km bi translated">结果</h1><p id="f3f7" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">该模型需要一些改进来修复，该模型仅用76幅图像进行训练，也许我们可以设置更多的时期和更多的图像来获得良好的结果，并使用tensorboard来查看训练损失和验证损失</p><p id="a3b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“mrcnn/config.py”我们可以设置一些设置来改进我们的模型。</p><pre class="kt ku kv kw fd lr ls lt lu aw lv bi"><span id="a269" class="lw jq hi ls b fi lx ly l lz ma">class Config(object):<br/>    """Base configuration class. For custom configurations, create a<br/>    sub-class that inherits from this one and override properties<br/>    that need to be changed.<br/>    """<br/>    # Name the configurations. For example, 'COCO', 'Experiment 3', ...etc.<br/>    # Useful if your code needs to do things differently depending on which<br/>    # experiment is running.<br/>    NAME = None  # Override in sub-classes</span><span id="d33d" class="lw jq hi ls b fi ni ly l lz ma"># NUMBER OF GPUs to use. When using only a CPU, this needs to be set to 1.<br/>    GPU_COUNT = 1</span><span id="eee0" class="lw jq hi ls b fi ni ly l lz ma"># Number of images to train with on each GPU. A 12GB GPU can typically<br/>    # handle 2 images of 1024x1024px.<br/>    # Adjust based on your GPU memory and image sizes. Use the highest<br/>    # number that your GPU can handle for best performance.<br/>    IMAGES_PER_GPU = 2</span><span id="4984" class="lw jq hi ls b fi ni ly l lz ma"># Number of training steps per epoch<br/>    # This doesn't need to match the size of the training set. Tensorboard<br/>    # updates are saved at the end of each epoch, so setting this to a<br/>    # smaller number means getting more frequent TensorBoard updates.<br/>    # Validation stats are also calculated at each epoch end and they<br/>    # might take a while, so don't set this too small to avoid spending<br/>    # a lot of time on validation stats.<br/>    STEPS_PER_EPOCH = 1000</span><span id="6a16" class="lw jq hi ls b fi ni ly l lz ma"># Number of validation steps to run at the end of every training epoch.<br/>    # A bigger number improves accuracy of validation stats, but slows<br/>    # down the training.<br/>    VALIDATION_STEPS = 50</span><span id="20ac" class="lw jq hi ls b fi ni ly l lz ma"># Backbone network architecture<br/>    # Supported values are: resnet50, resnet101.<br/>    # You can also provide a callable that should have the signature<br/>    # of model.resnet_graph. If you do so, you need to supply a callable<br/>    # to COMPUTE_BACKBONE_SHAPE as well<br/>    BACKBONE = "resnet101"</span><span id="ec12" class="lw jq hi ls b fi ni ly l lz ma"># Only useful if you supply a callable to BACKBONE. Should compute<br/>    # the shape of each layer of the FPN Pyramid.<br/>    # See model.compute_backbone_shapes<br/>    COMPUTE_BACKBONE_SHAPE = None</span><span id="4068" class="lw jq hi ls b fi ni ly l lz ma"># The strides of each layer of the FPN Pyramid. These values<br/>    # are based on a Resnet101 backbone.<br/>    BACKBONE_STRIDES = [4, 8, 16, 32, 64]</span><span id="36b2" class="lw jq hi ls b fi ni ly l lz ma"># Size of the fully-connected layers in the classification graph<br/>    FPN_CLASSIF_FC_LAYERS_SIZE = 1024</span><span id="883b" class="lw jq hi ls b fi ni ly l lz ma"># Size of the top-down layers used to build the feature pyramid<br/>    TOP_DOWN_PYRAMID_SIZE = 256</span><span id="3ddb" class="lw jq hi ls b fi ni ly l lz ma"># Number of classification classes (including background)<br/>    NUM_CLASSES = 1  # Override in sub-classes</span><span id="41b9" class="lw jq hi ls b fi ni ly l lz ma"># Length of square anchor side in pixels<br/>    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)</span><span id="cc2f" class="lw jq hi ls b fi ni ly l lz ma"># Ratios of anchors at each cell (width/height)<br/>    # A value of 1 represents a square anchor, and 0.5 is a wide anchor<br/>    RPN_ANCHOR_RATIOS = [0.5, 1, 2]</span><span id="5365" class="lw jq hi ls b fi ni ly l lz ma"># Anchor stride<br/>    # If 1 then anchors are created for each cell in the backbone feature map.<br/>    # If 2, then anchors are created for every other cell, and so on.<br/>    RPN_ANCHOR_STRIDE = 1</span><span id="c21a" class="lw jq hi ls b fi ni ly l lz ma"># Non-max suppression threshold to filter RPN proposals.<br/>    # You can increase this during training to generate more propsals.<br/>    RPN_NMS_THRESHOLD = 0.7</span><span id="5036" class="lw jq hi ls b fi ni ly l lz ma"># How many anchors per image to use for RPN training<br/>    RPN_TRAIN_ANCHORS_PER_IMAGE = 256</span></pre><h1 id="1472" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论</h1><p id="0c3f" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">在这篇文章中，我只是展示了如何使用这个repo来检测自定义数据集中的一些对象，请随意使用这个工具，如果你想说点什么，请跟我联系。</p><p id="30ee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">贝尔纳多·阿卡尔达斯</p><p id="d570" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">推特；【https://twitter.com/bernardocalda10 T2】号</p><p id="942c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Github项目</p><p id="6d14" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://github.com/bernardcaldas/object-detection-custom-maskrcnn/tree/master/tropical" rel="noopener ugc nofollow" target="_blank">https://github . com/bernardcaldas/object-detection-custom-maskrcnn/tree/master/tropical</a></p></div></div>    
</body>
</html>