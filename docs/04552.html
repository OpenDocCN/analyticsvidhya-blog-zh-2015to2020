<html>
<head>
<title>How to stop touching your face? Hands and face detection with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何停止摸脸？使用Python进行手部和面部检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-stop-touching-your-face-hands-and-face-detection-with-python-60ecb0d28d69?source=collection_archive---------4-----------------------#2020-03-24">https://medium.com/analytics-vidhya/how-to-stop-touching-your-face-hands-and-face-detection-with-python-60ecb0d28d69?source=collection_archive---------4-----------------------#2020-03-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii"><div class="bz dy l di"><div class="ij ik l"/></div><figcaption class="il im et er es in io bd b be z dx translated">当双手靠近面部时，会发出警报声</figcaption></figure><h1 id="76aa" class="ip iq hi bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">介绍</h1><p id="47d2" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我通常会写一些关于<a class="ae kl" rel="noopener" href="/analytics-vidhya/growth-hacker-guide-to-business-intelligence-2eb9f77c559c?source=friends_link&amp;sk=62020c248ca686a0db913018d9f3687d">业务发展</a>、<a class="ae kl" rel="noopener" href="/analytics-vidhya/introduction-to-growth-hacking-how-to-expand-your-contacts-database-virtually-infinitely-9845b03234e2?source=friends_link&amp;sk=cc076a0bfc2b8ce0ab40becb385dc006">营销和成长黑客</a>的文章。这个帖子不一样。嗯，我们的生活也变得非常不同…</p><blockquote class="km"><p id="2425" class="kn ko hi bd kp kq kr ks kt ku kv kk dx translated">目的是说明一种(非常)简单的方法来利用人工智能和机器学习来检测手和脸。我将使用已经存在的模型和库，所以不需要培训。</p></blockquote><p id="c8e1" class="pw-post-body-paragraph jn jo hi jp b jq kw js jt ju kx jw jx jy ky ka kb kc kz ke kf kg la ki kj kk hb bi translated">我最终使用的用于人脸检测的库(<a class="ae kl" href="https://github.com/arunponnusamy/cvlib" rel="noopener ugc nofollow" target="_blank"> <em class="lb"> cvlib </em> </a>)也可以检测<a class="ae kl" href="http://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> 80个上下文</a>中的常见对象。因此它对其他应用程序也很有用。</p><p id="dc76" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated"><strong class="jp hj">完整代码在这里:</strong><a class="ae kl" href="https://github.com/borismay/dont_touch_your_face" rel="noopener ugc nofollow" target="_blank"><strong class="jp hj">https://github.com/borismay/dont_touch_your_face</strong></a></p><p id="3b74" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">如果你还记得，有一个非常流行的帖子:<a class="ae kl" rel="noopener" href="/@ageitgey/snagging-parking-spaces-with-mask-r-cnn-and-python-955f2231c400">用Mask R-CNN和Python抢停车位</a>，我用了几乎相同的方法。</p><p id="8e91" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">它在我配有i7 CPU的笔记本电脑上运行，没有GPU，正如你所见，它非常接近实时。因此，人们可以将它移植到其他平台，或者在家里使用它来培养健康和拯救生命的习惯:-)</p><p id="f278" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">你会惊讶于自己摸脸的次数！</p><p id="9ef6" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">所以，保持安全和健康，让我们看看它是如何工作的。</p><h1 id="9cf4" class="ip iq hi bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">寻找正确的分类器</h1><p id="352f" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">对于人脸检测，我测试了几个现有的库。</p><p id="2471" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">可以参考<em class="lb"> detectors.py </em>实现所有被测试的检测器。还有一个用于微调检测参数的Streamlit UI。Github库里什么都有。</p><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es lh"><img src="../Images/63c8103a50bc3d0e672c5cfb12e91c88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dPnhwqu-zh4cF6kaGYOJTA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">简化用户界面，微调各种检测参数</figcaption></figure><p id="1667" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">判决如下:</p><ol class=""><li id="6aef" class="ls lt hi jp b jq lc ju ld jy lu kc lv kg lw kk lx ly lz ma bi translated"><em class="lb"> cv2。cascade classifier</em>——这是一个嵌入式分类器，附带了<a class="ae kl" href="https://pypi.org/project/opencv-python/" rel="noopener ugc nofollow" target="_blank"> Open-CV库</a>。有多个参数可以配置，在文档中没有很好地解释。幸运的是，有一个<a class="ae kl" href="https://stackoverflow.com/questions/20801015/recommended-values-for-opencv-detectmultiscale-parameters" rel="noopener ugc nofollow" target="_blank"> StackOverflow post </a>可以带你通过。整体性能不够。只有当你直视镜头时才有效</li><li id="5502" class="ls lt hi jp b jq mb ju mc jy md kc me kg mf kk lx ly lz ma bi translated"><a class="ae kl" href="https://pypi.org/project/face-recognition/" rel="noopener ugc nofollow" target="_blank"><em class="lb">face _ recognition</em></a>—构建在dlib之上的一个包。有两种检测模式:<em class="lb">【hog】</em>和<em class="lb">【CNN】</em>。它用<em class="lb">‘CNN’</em>提供了合理的结果，然而在我简单的硬件上它非常耗时</li><li id="4e6e" class="ls lt hi jp b jq mb ju mc jy md kc me kg mf kk lx ly lz ma bi translated"><strong class="jp hj">获胜者是…</strong><a class="ae kl" href="https://github.com/arunponnusamy/cvlib" rel="noopener ugc nofollow" target="_blank"><strong class="jp hj"><em class="lb">cvlib</em></strong></a><em class="lb"/>——下面，<em class="lb"> cvlib </em>正在使用一个类似AlexNet的模型，该模型是在Gil Levi和Tal Hassner的<a class="ae kl" href="https://talhassner.github.io/home/publication/2015_CVPR" rel="noopener ugc nofollow" target="_blank"> CVPR 2015 </a>论文的<a class="ae kl" href="https://talhassner.github.io/home/projects/Adience/Adience-data.html#agegender" rel="noopener ugc nofollow" target="_blank"> Adience数据集</a>上训练的。它产生了非常稳健的结果和快速的性能。除了人脸检测，它可以用一行代码检测上下文中的80个<a class="ae kl" href="https://github.com/arunponnusamy/object-detection-opencv/blob/master/yolov3.txt" rel="noopener ugc nofollow" target="_blank">常见物体</a>。对于对象检测，它使用在<a class="ae kl" href="http://cocodataset.org/" rel="noopener ugc nofollow" target="_blank"> COCO数据集</a>上训练的<a class="ae kl" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank"> YOLOv3 </a>模型</li></ol><p id="45bc" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">找到一个可靠的手部检测库有点困难。我用的是<a class="mg mh ge" href="https://medium.com/u/304fe0310a13?source=post_page-----60ecb0d28d69--------------------------------" rel="noopener" target="_blank"> Victor Dibia的</a>作品，在本帖中描述:<a class="ae kl" rel="noopener" href="/@victor.dibia/how-to-build-a-real-time-hand-detector-using-neural-networks-ssd-on-tensorflow-d6bac0e4b2ce">如何在Tensorflow </a> (2017)，GitHub repository，<a class="ae kl" href="https://github.com/victordibia/handtracking" rel="noopener ugc nofollow" target="_blank">https://github.com/victordibia/handtracking</a>上使用神经网络(SSD)构建实时手部探测器。</p><h1 id="2ecd" class="ip iq hi bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">把所有的放在一起</h1><p id="42ef" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">流程如下:</p><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mi"><img src="../Images/1a26df9dda3a40f3bc62ff88d39d7495.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*bl57yzErhFq8QZuF1T6rbg.png"/></div></figure><ol class=""><li id="3636" class="ls lt hi jp b jq lc ju ld jy lu kc lv kg lw kk lx ly lz ma bi translated">配置网络摄像机并初始化其参数</li><li id="065f" class="ls lt hi jp b jq mb ju mc jy md kc me kg mf kk lx ly lz ma bi translated">初始化探测器</li><li id="df69" class="ls lt hi jp b jq mb ju mc jy md kc me kg mf kk lx ly lz ma bi translated">无限循环:<br/>读取图像<br/>检测面部和手部<br/>如果他们靠得很近，警告用户</li></ol><h2 id="8d39" class="mj iq hi bd ir mk ml mm iv mn mo mp iz jy mq mr jd kc ms mt jh kg mu mv jl mw bi translated">网络摄像头</h2><p id="f369" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">创建网络摄像机对象，并配置图像大小:</p><pre class="li lj lk ll fd mx my mz na aw nb bi"><span id="a176" class="mj iq hi my b fi nc nd l ne nf">cap = cv2.VideoCapture(0)<br/>cap.set(3, 1280/2)<br/>cap.set(4, 1024/2)</span></pre><p id="6b16" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">网络摄像头的参数描述可以在<a class="ae kl" href="https://stackoverflow.com/questions/11420748/setting-camera-parameters-in-opencv-python" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="6c4e" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">捕捉视频帧也非常简单:</p><pre class="li lj lk ll fd mx my mz na aw nb bi"><span id="19c2" class="mj iq hi my b fi nc nd l ne nf">ret, frame = cap.read()</span></pre><p id="1279" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">然而，来自照相机的图像是BGR格式的。为了将它提供给分类器，您需要将其转换为RGB:</p><pre class="li lj lk ll fd mx my mz na aw nb bi"><span id="e736" class="mj iq hi my b fi nc nd l ne nf">rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)</span></pre><h2 id="676e" class="mj iq hi bd ir mk ml mm iv mn mo mp iz jy mq mr jd kc ms mt jh kg mu mv jl mw bi translated">面部和手部检测</h2><p id="cbdb" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我定义了一个基类，为我将使用的所有检测器提供一个类似的接口:</p><pre class="li lj lk ll fd mx my mz na aw nb bi"><span id="a864" class="mj iq hi my b fi nc nd l ne nf">class Detector:<br/>    detector_params = {}<br/>    detector = None<br/><br/>    def __init__(self):<br/>        pass<br/><br/>    def set_detector_params(self, params):<br/>        self.detector_params = params<br/><br/>    def detect(self):<br/>        pass</span></pre><p id="0291" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">每个检测器将从这个类继承并实现它的方法，包括构造函数。使得在创建检测器对象之后，它将具有相同的接口。</p><p id="eda2" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">例如，这是FaceDetector的实现，以及它在代码中的调用方式:</p><pre class="li lj lk ll fd mx my mz na aw nb bi"><span id="31f4" class="mj iq hi my b fi nc nd l ne nf">class CVLibDetector(Detector):<br/>    def __init__(self):<br/>        self.detector = cv<br/><br/>    def detect(self, rgb_image):<br/>        # returns an array of (top, right, bottom, left)<br/>        objects, confidences = self.detector.detect_face(rgb_image)<br/>        # change to an array of (x, y, w, h)<br/>        return [(top, left, bottom - top, right - left) for (top, right, bottom, left) in objects]</span><span id="3f62" class="mj iq hi my b fi ng nd l ne nf">FaceDetector = CVLibDetector()<br/>face = FaceDetector.detect(rgb)</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es nh"><img src="../Images/c7999c3951f88e541e530763befcb2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JkkdIRGzjJPW4_ee-qutxg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">人脸检测结果</figcaption></figure><p id="5759" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">正如我提到的，我使用了<a class="ae kl" rel="noopener" href="/@victor.dibia/how-to-build-a-real-time-hand-detector-using-neural-networks-ssd-on-tensorflow-d6bac0e4b2ce">如何在Tensorflow </a> (2017)、GitHub repository、<a class="ae kl" href="https://github.com/victordibia/handtracking" rel="noopener ugc nofollow" target="_blank">https://github.com/victordibia/handtracking</a>上使用神经网络(SSD)构建实时手部检测器作为起点。我需要更新几行代码，让它在没有GPU的情况下与TensorFlow 2.0一起工作。</p><h2 id="c91b" class="mj iq hi bd ir mk ml mm iv mn mo mp iz jy mq mr jd kc ms mt jh kg mu mv jl mw bi translated">检测面部触摸</h2><p id="8ef3" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">因为这是2D图像，所以没有简单的方法来模拟手和脸的三维位置。</p><p id="d8e2" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">我假设如果检测到的手和脸的边界框相交，它将被声明为触摸事件。</p><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es ni"><img src="../Images/7deb9305672d3a99492193936db15d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*IMpNTxK3KaDYF3jhrmq35g.png"/></div></figure><p id="b8b7" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">为了实现检测，我使用了<a class="ae kl" href="https://github.com/Toblerity/Shapely" rel="noopener ugc nofollow" target="_blank"> shapely </a>库。这是一个非常有用的几何计算库，我经常用它进行地理空间分析。</p><p id="75c4" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">每个检测到的对象由以下参数表示:</p><pre class="li lj lk ll fd mx my mz na aw nb bi"><span id="1625" class="mj iq hi my b fi nc nd l ne nf">x, y, w, h = obj</span></pre><p id="78ad" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">我将把每个检测到的对象变成一个多边形，然后计算手的多边形和脸的多边形之间的交集:</p><pre class="li lj lk ll fd mx my mz na aw nb bi"><span id="bb12" class="mj iq hi my b fi nc nd l ne nf">def obj_to_poly(obj):<br/>    x, y, w, h = obj<br/>    return Polygon([(x, y), (x+w, y), (x+w, y+h), (x, y+h)])</span><span id="40cb" class="mj iq hi my b fi ng nd l ne nf">def objects_touch(face, hands):<br/>    if face and hands:<br/>        face_poly = obj_to_poly(face[0])<br/>        for hand in hands:<br/>            hand_poly = obj_to_poly(hand)<br/>            if face_poly.intersects(hand_poly):<br/>                return True<br/>    return False</span></pre><p id="5ae3" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">如果这些对象相交，该函数将返回True。</p><p id="11fd" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">就是这样。</p></div><div class="ab cl nj nk gp nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="hb hc hd he hf"><p id="8b9d" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">我在周末花了几个小时把它们放在一起，目的是展示用python使用机器学习和人工智能是多么容易。有许多已经可用的经过训练的库，使我们能够以最小的努力构建强大的应用程序。</p><p id="303a" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">还有一件事。也许这个原型也可以用来增加我们触摸面部的自我意识。下载它，运行30分钟，你就会看到结果。</p><p id="ad43" class="pw-post-body-paragraph jn jo hi jp b jq lc js jt ju ld jw jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated"><strong class="jp hj">呆在家里，把手从脸上拿开。</strong></p></div></div>    
</body>
</html>