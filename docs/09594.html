<html>
<head>
<title>Assumptions of Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归的假设</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/assumptions-of-linear-regression-61ce2d4915e0?source=collection_archive---------11-----------------------#2020-09-12">https://medium.com/analytics-vidhya/assumptions-of-linear-regression-61ce2d4915e0?source=collection_archive---------11-----------------------#2020-09-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1683" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归需要满足一些假设，否则线性模型给出的输出是不可信的。这是面试中很常见的问题。</p><p id="ff71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">简单线性回归:</strong>当数据只有1个独立特征时，则称之为简单线性回归。</p><p id="e20b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">多元线性回归:</strong>当数据有1个以上的独立特征时，称为多元线性回归。</p><p id="187d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将借助简单线性回归来理解线性回归的假设。</p><h2 id="be5d" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">1.X和y变量之间存在线性关系。</h2><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es jy"><img src="../Images/4c549e76200dd84aec5fb36d88f063c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-0bNMypdElfSflS5ONShQ.png"/></div></div></figure><p id="470f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种假设认为独立和从属特征具有线性关系。为了检验这个假设，我们可以使用散点图，散点图应该看起来像上面的左图。</p><h2 id="28e6" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">2.误差项呈正态分布。</h2><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es kk"><img src="../Images/7acdc96cd97ff7b44ba19565633113f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tu3JJ9ixztsuVhQXz-aJbw.png"/></div></div></figure><p id="2203" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个假设认为误差项是正态分布的。这里预测误差减去实际目标。要检查这一假设，请根据数据拟合模型并进行预测。现在计算误差，并画出这个误差的分布(直方图)，这个分布应该看起来像正态分布。</p><p id="8eec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.<strong class="ih hj">误差项相互独立</strong></p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es kl"><img src="../Images/f7dc7c8db85e1fc2870e6fdf63baf3b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*uMeVYAs0bysvFV1TaSB6MQ.png"/></div></figure><p id="a2da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了检验这个假设，在目标变量和误差项之间画一个散点图。散点图不应显示明显的模式。</p><h2 id="a026" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">4.同方差:误差项具有恒定的方差。</h2><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es km"><img src="../Images/660bf2384f4d4d2d8bf67eb58a39f9d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xQUEgj-0bStajMssALCvkA.png"/></div></div></figure><p id="8e12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要检查这一点，在独立特征和目标特征之间绘制一个散点图，然后在同一轴上，在独立特征和预测之间绘制一个散点图。您应该会得到一个类似上面左图的图形。</p><h2 id="46d0" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated"><strong class="ak"> 5。最小多重共线性:</strong></h2><p id="a278" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">多重共线性意味着1个要素与其他要素相关，我们希望最小化多重共线性。很明显，这个问题出现在多个线性回归中，因为它包含不止一个特征。为了检验这一假设，使用VIF(方差膨胀系数)</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es ks"><img src="../Images/1d8e95860f817aa6fa37f50ff6d5a832.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*_yCXAtTSvLZ06l0Qj-Ngrg.png"/></div></figure><p id="67ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">VIF值越高，多重共线性越高。在大多数情况下，VIF值不应大于10。</p><p id="f23b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kt">感谢您的宝贵时间！</em>T13】</strong></p><p id="0b8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ku" href="https://link.medium.com/LU8C6wAsM9" rel="noopener"> <strong class="ih hj"> <em class="kt">想了解完整的线性回归概念？</em> </strong> </a></p></div></div>    
</body>
</html>