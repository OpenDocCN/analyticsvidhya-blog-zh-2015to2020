# é¢å‘åˆå­¦è€…çš„ Python é€»è¾‘å›å½’å®ç”¨æŒ‡å—

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/a-practical-guide-to-logistic-regression-in-python-for-beginners-f04cf6b63d33?source=collection_archive---------2----------------------->

é€»è¾‘å›å½’çš„æ ¹æºå¯ä»¥è¿½æº¯åˆ° 19 ä¸–çºªï¼Œå½“æ—¶æ¯”åˆ©æ—¶æ•°å­¦å®¶[](https://en.wikipedia.org/wiki/Pierre_FranÃ§ois_Verhulst)**åœ¨ä¸ºäººå£å¢é•¿å»ºæ¨¡çš„ä¸€ç³»åˆ—ä¸‰ç¯‡è®ºæ–‡ä¸­æå‡ºäº†*é€»è¾‘å‡½æ•°/é€»è¾‘å¢é•¿*ã€‚åæ¥åœ¨ 1883 å¹´ï¼Œå¨å»‰Â·å¥¥æ–¯ç‰¹ç“¦å°”å¾·[](https://en.wikipedia.org/wiki/Wilhelm_Ostwald)****å°†å®ƒåº”ç”¨äºåŒ–å­¦ä¸­çš„è‡ªåŠ¨å‚¬åŒ–æ¨¡å‹ã€‚å¤§çº¦ 200 å¹´åï¼Œé€»è¾‘å›å½’ç°åœ¨æ˜¯å„ä¸ªé¢†åŸŸä¸­ä½¿ç”¨æœ€å¹¿æ³›çš„ç»Ÿè®¡æ¨¡å‹ä¹‹ä¸€ï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ ã€ç»æµå­¦ã€åŒ»å­¦ç­‰ã€‚******

# ********1.0ã€‚å¤©å•Šã€‚ä¸€äº›æ•°å­¦å®šä¹‰ğŸ˜********

******ç®€è€Œè¨€ä¹‹ï¼Œé€»è¾‘å›å½’æ¨¡å‹ä½¿ç”¨é€»è¾‘å‡½æ•°:******

******![](img/0e0b5d6fa9ed32bf0b88f4c057c81fc0.png)******

******å°†çº¿æ€§æ–¹ç¨‹çš„è¾“å‡ºå‹ç¼©åˆ° 0 åˆ° 1 ä¹‹é—´ã€‚é€»è¾‘æ›²çº¿æ˜¯ä¸€ç§å¸¸è§çš„ S å½¢æ›²çº¿ï¼Œå¦‚ä¸‹æ‰€ç¤º:******

******![](img/69e99b38b69abfc0191c051223cd318c.png)******

******æ¥æº: [hvidberrrg](https://hvidberrrg.github.io/deep_learning/activation_functions/sigmoid_function_and_derivative.html)******

# ******2.0.é‡è¦å‡è®¾ğŸ§******

******åœ¨ä½¿ç”¨é€»è¾‘å›å½’å»ºæ¨¡ä¹‹å‰ï¼Œæœ‰ 4 ä¸ªä¸»è¦å‡è®¾éœ€è¦è€ƒè™‘ã€‚è¿™äº›æ˜¯:******

1.  ********å› å˜é‡/å“åº”å˜é‡/ç›®æ ‡å˜é‡å¿…é¡»æ˜¯äºŒå…ƒæˆ–äºŒåˆ†å˜é‡**:ä¸€ä¸ªæ•°æ®ç‚¹å¿…é¡»åªé€‚åˆä¸¤ä¸ªç±»åˆ«ä¸­çš„ä¸€ä¸ªã€‚ä¾‹å¦‚ï¼Œé¢„æµ‹ä¸€ä¸ªäººæ˜¯å¦æœ‰è‚¿ç˜¤â€”â€”æ˜¯(1)ï¼Œå¦(0)ã€‚******
2.  ******ç¼ºä¹å¤šé‡å…±çº¿æ€§**:ç‹¬ç«‹/é¢„æµ‹å˜é‡ä¹‹é—´å¿…é¡»å¾ˆå°‘æˆ–æ²¡æœ‰å…±çº¿æ€§ï¼Œè¿™æ„å‘³ç€å®ƒä»¬åº”è¯¥ç›¸äº’ç‹¬ç«‹ã€‚æ–¹å·®è†¨èƒ€å› å­(VIF)æ˜¯å¯ç”¨äºæ£€æŸ¥å¤šé‡å…±çº¿æ€§çš„ç®€å•æµ‹è¯•ä¹‹ä¸€ã€‚å¦‚æœä¸€ä¸ªå› å­çš„ VIF åˆ†æ•°é«˜äº 5ï¼Œæœ€å¥½æ˜¯åˆ é™¤ä¸€ä¸ªç›¸å…³çš„ç‹¬ç«‹å˜é‡ä»¥å‡å°‘å†—ä½™ã€‚****
3.  ****å¤§æ ·æœ¬é‡:å’Œä»»ä½•ç»Ÿè®¡æ¨¡å‹ä¸€æ ·ï¼Œè¿‡å»çš„æ•°æ®æ˜¯ç¨³å¥æ¨¡å‹çš„å…³é”®ã€‚åŒæ ·ï¼Œæ ·æœ¬é‡è¶Šå¤§ï¼Œé€»è¾‘å›å½’åˆ†æçš„ç»“æœè¶Šå¥½ï¼Œè¶Šå¯é ã€‚****
4.  ******å¯¹æ•°ä¼˜åŠ¿å…³ç³»**:è‡ªå˜é‡å¿…é¡»ä¸å¯¹æ•°ä¼˜åŠ¿å‘ˆçº¿æ€§ç›¸å…³ã€‚****

# ******3.0ã€‚Python ä»£ç åˆ†æ­¥æŒ‡å—ğŸ¤“******

****æœ¬èŠ‚ä½œä¸ºé€»è¾‘å›å½’[é“¶è¡Œè¥é”€](https://archive.ics.uci.edu/ml/datasets/bank+marketing)æ•°æ®é›†å®æ–½çš„å®Œæ•´æŒ‡å—/æ•™ç¨‹ã€‚è¿™ä¸ªæœºå™¨å­¦ä¹ ä»»åŠ¡çš„ç›®æ ‡æ˜¯é¢„æµ‹å®¢æˆ·æ˜¯å¦ä¼šè®¢é˜…å®šæœŸå­˜æ¬¾ã€‚æœ¬æ–‡ä½¿ç”¨çš„æ•°æ®é›†å’Œä»£ç å¯ä»¥åœ¨è¿™ä¸ª [GitHub èµ„æºåº“](https://github.com/akbarhusnoo/Logistic-Regression-Portuguese-Bank-Marketing)ä¸­æ‰¾åˆ°ã€‚****

## ****I .å¯¼å…¥åº“****

```
**import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels
import sklearn**
```

## ****äºŒã€‚äº†è§£æ•°æ®é›†****

```
**#access dataset from GitHub link
url_link = '[https://raw.githubusercontent.com/akbarhusnoo/Logistic-Regression-Portuguese-Bank-Marketing/main/Portuguese%20Bank%20Marketing%20Dataset.csv'](https://raw.githubusercontent.com/akbarhusnoo/Logistic-Regression-Portuguese-Bank-Marketing/main/Portuguese%20Bank%20Marketing%20Dataset.csv')#read file
df_bank = pd.read_csv(url_link)#display top 5 rows
display(df_bank.head())#display number of rows and columns
print('\nShape of dataset = ', df_bank.shape)#display list of attributes present in dataset
print('\nList of Attributes:\n ', list(df_bank.columns))**
```

****![](img/fdd6041b386c3ef8a659777db8fcb8c2.png)****

****äº§å‡º 3(äºŒ)â€”â€”æŒ‰ä½œè€…åˆ†ç±»çš„å›¾åƒ****

****è¿™ä¸ªæ•°æ®é›†ç”± 21 ä¸ªå±æ€§/åˆ—å’Œ 41188 æ¡è®°å½•/è¡Œç»„æˆã€‚å¹´é¾„ã€å·¥ä½œç­‰å˜é‡ã€‚æ˜¯ç‰¹æ€§åˆ—è¡¨ï¼Œè€Œå˜é‡æ˜¯ y â€”å®¢æˆ·æ˜¯å¦å·²é¢„è®¢å®šæœŸå­˜æ¬¾ï¼Ÿæ˜¯ç›®æ ‡å˜é‡ï¼Œ1 è¡¨ç¤ºâ€œæ˜¯â€ï¼Œ0 è¡¨ç¤ºâ€œå¦â€ã€‚****

## ****ä¸‰ã€‚ç›®æ ‡å˜é‡å¯ä»¥ç”¨äºé€»è¾‘å›å½’å—ï¼Ÿ****

****æ˜¯çš„ã€‚è¿™æ˜¯å› ä¸ºç›®æ ‡å˜é‡æ˜¯**äºŒå…ƒ/äºŒå…ƒ**ã€‚****

## ****å››ã€‚æ£€æŸ¥ç¼ºå°‘çš„å€¼****

****æœ‰å‡ ç§æ–¹æ³•å¯ä»¥å¤„ç†æ•°æ®é›†ä¸­ç¼ºå¤±å€¼é€ æˆçš„éº»çƒ¦ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”±äºæ ·æœ¬é‡è¶³å¤Ÿå¤§ï¼Œå¦‚æœå­˜åœ¨ç¼ºå¤±å€¼ï¼Œå¯ä»¥ä¸¢å¼ƒè¿™äº›å€¼ã€‚****

```
**#check if there are missing values in dataset
print(df_bank.isnull().values.any())**
```

****![](img/c419cd88b15d6900b368d5b0e52228f9.png)****

****äº§å‡º 3ãˆ£â€”â€”æŒ‰ä½œè€…åˆ†ç±»çš„å›¾åƒ****

****åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæ•°æ®é›†ä¸åŒ…å«ä»»ä½•ç¼ºå¤±å€¼ã€‚****

## ******äº”ã€æ•°æ®æ¢ç´¢******

```
**#visualise the target variable
sns.countplot(x ='y', data = df_bank)
plt.show()**
```

****![](img/2e15b1181af92777c61a935364d22831.png)****

****è¾“å‡º 3(V) â€”æŒ‰ä½œè€…åˆ†ç±»çš„å›¾åƒ****

****0 çº§å’Œ 1 çº§æä¸å¹³è¡¡ã€‚å› æ­¤ï¼Œå¯¹äºè¿™ä¸ªåœºæ™¯ï¼Œå‡†ç¡®æ€§ä¸æ˜¯ä¸€ä¸ªå¥½çš„æ€§èƒ½è¯„ä¼°æŒ‡æ ‡ã€‚****

## ******å…­ã€‚ç¼–ç åˆ†ç±»å˜é‡******

****ä½¿ç”¨[æ ‡ç­¾ç¼–ç å™¨](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)å¯¹æ•°æ®é›†ä¸­å‡ºç°çš„åˆ†ç±»å˜é‡è¿›è¡Œç¼–ç ã€‚****

```
**#label encoding for all categorical variables in dataset
from sklearn.preprocessing import LabelEncoderlabel_encoder = LabelEncoder()
df_bank['job'] = label_encoder.fit_transform(df_bank['job'])
df_bank['marital'] = label_encoder.fit_transform(df_bank['marital'])
df_bank['education'] = label_encoder.fit_transform(df_bank['education'])
df_bank['default'] = label_encoder.fit_transform(df_bank['default'])
df_bank['housing'] = label_encoder.fit_transform(df_bank['housing'])
df_bank['loan'] = label_encoder.fit_transform(df_bank['loan'])
df_bank['contact'] = label_encoder.fit_transform(df_bank['contact'])
df_bank['month'] = label_encoder.fit_transform(df_bank['month'])
df_bank['day_of_week'] = label_encoder.fit_transform(df_bank['day_of_week'])
df_bank['poutcome'] = label_encoder.fit_transform(df_bank['poutcome'])**
```

## ****ä¸ƒã€‚ç‰¹å¾å·¥ç¨‹****

******A .ä»æ•´ä¸ªæ•°æ®é›†åˆ†å‰²ç‰¹å¾é›†******

```
**#segment dataset into features set
X = df_bank.loc[:, list(df_bank.columns)[0:20]]**
```

******B .æ£€æŸ¥å¤šé‡å…±çº¿æ€§******

****ä¸ºäº†æ£€æŸ¥è‡ªå˜é‡ä¸­çš„å¤šé‡å…±çº¿æ€§ï¼Œä½¿ç”¨äº† [*æ–¹å·®è†¨èƒ€å› å­(VIF)*](https://en.wikipedia.org/wiki/Variance_inflation_factor) æŠ€æœ¯ã€‚VIF å¾—åˆ†ä¸º> 10 çš„å˜é‡æ„å‘³ç€å®ƒä»¬éå¸¸å¼ºç›¸å…³ã€‚å› æ­¤ï¼Œå®ƒä»¬åœ¨é€»è¾‘å›å½’æ¨¡å‹ä¸­è¢«ä¸¢å¼ƒå’Œæ’é™¤ã€‚****

```
**#calculate Variance Inflation Factor
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif_scores = pd.DataFrame() 
vif_scores["Attribute"] = X.columns 

# calculating VIF for each feature 
vif_scores["VIF Scores"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))] 

display(vif_scores)**
```

****![](img/f6ff2cb80e42be9d90eef50b9dd86a0a.png)****

****äº§å‡º 3(ä¸ƒã€‚B) â€”ä½œè€…æä¾›çš„å›¾ç‰‡****

## ****å…«ã€‚å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒå’Œæµ‹è¯•****

****å»ºè®®å°†æ•°æ®åˆ†æˆ 70-30 ä»½ï¼Œå…¶ä¸­è®­ç»ƒæ•°æ®é›†å  70%ï¼Œæµ‹è¯•æ•°æ®é›†å  30%ã€‚****

```
**#segment dataset into significant features and target
X = df_bank.loc[:, ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'previous']]
y = df_bank['y']#split dataset into training and testing features and targets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3)**
```

## ****ä¹ã€‚ç”¨é€»è¾‘å›å½’æ¨¡å‹æ‹Ÿåˆæ•°æ®****

****è®­ç»ƒæ•°æ®è¢«é¦ˆé€åˆ°é€»è¾‘å›å½’æ¨¡å‹ï¼Œç”¨äºè®­ç»ƒåè€…ã€‚****

```
**#fit logistic regression model to data
from sklearn.linear_model import LogisticRegressionlogistic_regression_model = LogisticRegression()
logistic_regression_model.fit(X_train, y_train)**
```

****![](img/c191a6a593788e07c5ddbf6b65e8c388.png)****

****äº§å‡º 3(IX)â€”â€”æŒ‰ä½œè€…åˆ†ç±»çš„å›¾åƒ****

## ******åã€è¯„ä»· Logistic å›å½’æ¨¡å‹******

****ç„¶åå°†æµ‹è¯•ç‰¹å¾è¾“å…¥åˆ°é€»è¾‘å›å½’æ¨¡å‹ä¸­ã€‚ç„¶åï¼Œæ€§èƒ½æŒ‡æ ‡å’Œæ··æ·†çŸ©é˜µè®¡ç®—å¦‚ä¸‹:****

```
**#evaluate model using test data
y_predicted = logistic_regression_model.predict(X_test)
display(y_predicted)#compute confusion matrix
from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_test, y_predicted)
print('\nThe Confusion Matrix is as follows:\n', confusion_matrix)#compute performance metrices
from sklearn.metrics import precision_score
from sklearn.metrics import roc_auc_score
print('\nArea Under the Receiver Operating Characteristic Curve:', roc_auc_score(y_test, y_predicted))
print('\nPrecision:', precision_score(y_test, y_predicted))**
```

****![](img/2e6157a6d2d8d4049e7d2db9f607f493.png)****

****äº§å‡º 3(IX)â€”â€”æŒ‰ä½œè€…åˆ†ç±»çš„å›¾åƒ****

****å› æ­¤ï¼Œæ¨¡å‹æ­£ç¡®é¢„æµ‹äº† **11111** (10767+344)æ•°æ®**ï¼Œé”™è¯¯é¢„æµ‹äº† **1246** (194+1052)æ•°æ®ã€‚******

# ****4.0.å‚è€ƒ****

****[1]ç»Ÿè®¡è§£å†³æ–¹æ¡ˆã€‚(2013).*ä»€ä¹ˆæ˜¯é€»è¾‘å›å½’ï¼Ÿâ€”ç»Ÿè®¡è§£å†³æ–¹æ¡ˆ*ã€‚[åœ¨çº¿]è¯·è®¿é—®:[https://www . statistics solutions . com/what-is-logistic-regression/ã€‚](https://www.statisticssolutions.com/what-is-logistic-regression/.)****

****[2]æ°æ£®Â·å¸ƒæœ—åˆ©(2016)ã€‚*ç”¨äºæœºå™¨å­¦ä¹ çš„é€»è¾‘å›å½’*ã€‚[åœ¨çº¿]æœºå™¨å­¦ä¹ æŒæ¡ã€‚å¯ä»ä»¥ä¸‹ç½‘å€è·å¾—:[https://machine learning mastery . com/logistic-regression-for-machine-learning/ã€‚](https://machinelearningmastery.com/logistic-regression-for-machine-learning/.)****

****[3]ç½—æ°å°”-è¨æ‹‰æ‰ï¼ŒJ. (2017)ã€‚*ä½¿ç”¨ Python è¿›è¡Œæ•°æ®ç§‘å­¦å’Œåˆ†æ*ã€‚ä½›ç½—é‡Œè¾¾å·åšå¡æ‹‰é¡¿:Crc å‡ºç‰ˆç¤¾ï¼Œæ³°å‹’&å¼—æœ—è¥¿æ–¯é›†å›¢ã€‚****

****â€Œ[4]Millerï¼ŒT.W. (2015)ã€‚*è¥é”€æ•°æ®ç§‘å­¦:ä½¿ç”¨ R å’Œ Python çš„é¢„æµ‹åˆ†æå»ºæ¨¡æŠ€æœ¯*ã€‚ä¸Šé©¬éæ²³:é‡‘èæ—¶æŠ¥/Prentice Hallã€‚****