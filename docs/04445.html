<html>
<head>
<title>Intro to Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/intro-to-linear-regression-eadc111a4596?source=collection_archive---------21-----------------------#2020-03-19">https://medium.com/analytics-vidhya/intro-to-linear-regression-eadc111a4596?source=collection_archive---------21-----------------------#2020-03-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1d54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归是所有预测模型的始祖。两个世纪过去了，它的魅力在很大程度上被它的后代所掩盖，但它的相关性并没有减少——或者说用处没有减少。那么什么是线性回归呢？</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/29dea554493e7e67fd310a5b7668703f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j-QeN4EobLWTG0TuBMxpow.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">首先，它看起来有点像这样</figcaption></figure><p id="56c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归通过用线性方程拟合数据来模拟变量之间的关系。这种熟悉的可视化是通过散点图绘制的“最佳拟合线”。该线是“最佳拟合”的，因为它尽可能地接近散点图中的所有点，同时仍然符合线性方程(形式为y = a + bx)。</p><p id="540c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有许多不同类型的线性回归，它们在如何定义“尽可能接近散点中的所有点”上有很大的不同，但原始和最重要的形式是<strong class="ih hj">普通最小二乘法(OLS) </strong>。</p><p id="c82d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">OLS通过找到最小化均方误差(MSE)的线性方程来计算直线。MSE正是tin上显示的内容:对于每个点，到最佳拟合线的垂直距离就是误差(或“残差”)，MSE的计算方法是取这些误差中的每一个，对它们求平方，然后求平均值。当你找到能给出最低MSE的线性方程时，你就有了线性回归。幸运的是，这个过程很容易自动化，很少需要手动完成。</p><p id="a6b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，线性回归确实需要对数据进行某些假设。可以用手助记线+I来记住这些假设:</p><ul class=""><li id="b0d3" class="jt ju hi ih b ii ij im in iq jv iu jw iy jx jc jy jz ka kb bi translated">线性:数据需要看起来像一条线，或者即使是最佳拟合的线也不会拟合得很好。</li><li id="f2ad" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">误差的独立性:误差(点与线的垂直距离)不能有任何明确的趋势或彼此之间的关系。</li><li id="832c" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">误差的正态性:误差应服从正态分布；也就是说，他们不应该有这样或那样的偏见。</li><li id="68da" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">方差相等:误差在图中应该有大致相同的方差。如果它们随着你的前进而一致变大，你就有问题了。</li><li id="c2ba" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">预测因子的独立性:这一条只适用于多元线性回归(使用多个变量作为预测因子的回归)，因此+I .它只是意味着用作预测因子的变量不能彼此相关。这个假设几乎总是至少有一点被违反(事实上，真空中不存在任何东西)，但它越成立越好。</li></ul><p id="093c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然您仍然可以在不满足假设的情况下进行线性回归，但这通常是一个非常糟糕的想法。要知道为什么，看看这四个情节，著名的安斯科姆四重奏:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kh"><img src="../Images/170ead477a6b528446dd0e42a047766b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Tmg47fvhRHYUO7qSQtBqQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">休斯顿，我们有麻烦了</figcaption></figure><p id="ed25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里的问题应该很清楚。尽管四个数据集具有几乎相同的汇总统计数据，并返回相同的最佳拟合线，但该线只是第一个数据集的合理近似。其他三个违反了各种线假设(这里没有+I，因为它只是一个简单的线性回归)，线性回归返回的结果是误导性的——比没有更糟。</p><p id="983c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">仅仅因为回归工作并不意味着它给你任何有用的东西！然而，请记住LINE+I假设，线性回归非常有效。它存在了两百年是有原因的，尽管它可能不像神经网络那样耀眼，但我们将它弃之不顾是非常不妥的。有时候，越简单越好。</p></div></div>    
</body>
</html>