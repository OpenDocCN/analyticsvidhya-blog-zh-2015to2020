<html>
<head>
<title>Kinship Classification Using VGGFace</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用VGGFace进行亲属分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/kinship-classification-using-vggface-a7c76f81288?source=collection_archive---------5-----------------------#2019-09-03">https://medium.com/analytics-vidhya/kinship-classification-using-vggface-a7c76f81288?source=collection_archive---------5-----------------------#2019-09-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9998" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将构建一个模型，仅根据两个人的面部图像来确定他们是否有血缘关系。这个挑战来自kaggle竞赛东北微笑实验室——在野外识别人脸<a class="ae jd" href="https://www.kaggle.com/c/recognizing-faces-in-the-wild" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/recognizing-faces-in-the-wild</a></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/62f3fb00057c8beb1432abb9bb00e62b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*44KkdXd9NT2eSyNyCQpd1Q.png"/></div></div></figure><p id="135a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们使用从预训练模型VGGFace获得的特征。我们同时经过两张脸，得到他们有亲属关系的概率。获得两个图像特征，然后将它们组合以传递到密集层。下面是网络的架构。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jq"><img src="../Images/f7eade333bb7b5c27eb6e404028bf645.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YlebEHj-gZG4-aomOE9rIg.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">(模型架构)</figcaption></figure><p id="22d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些功能的组合方式参考了kaggle笔记本。</p><h1 id="54e7" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak"> VGGFace </strong></h1><p id="de6d" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">牛津大学的视觉几何小组(VGG)开发了一个深度卷积神经网络模型，并在非常大的人脸数据集上进行人脸识别任务的训练。在基准人脸识别数据集上对它们进行了评估，证明了该模型在从人脸生成广义特征方面是有效的。</p><p id="b53e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有VGGFace的Keras实现。点击https://github.com/rcmalli/keras-vggface<a class="ae jd" href="https://github.com/rcmalli/keras-vggface" rel="noopener ugc nofollow" target="_blank">的链接</a>，了解如何安装以及如何使用不同的型号。对于这个任务，我们将使用VGGFace的“ResNet50”模型。</p><h1 id="0421" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">数据</strong></h1><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ky"><img src="../Images/f740da3f8f4d2e4d6858be7aa9308d37.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*wAQHf8CNoa4JWktPi65xpA.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kz"><img src="../Images/79292648656fbf1371f8cfc25d747e12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ML9AnobA1Rl5qEEP0X0cHw.png"/></div></div></figure><p id="ce18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有培训、测试目录和关系csv文件。关系csv文件由具有亲属关系的一对人组成。train文件夹包含不同系列的目录。每个家庭目录都有属于该家庭的每个人的子目录。测试目录只有人的图像。我们必须核实提交文件中的亲属关系。</p><h1 id="d4f4" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">代码</strong></h1><p id="2d8b" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">首先安装Keras-vgg face模型(参考上面的链接)</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es la"><img src="../Images/1cc2d01d411e7dbd0692b38d6be94b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*5R4mWyp4M2v3kEhhKGaZxw.png"/></div></figure><p id="556c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我们导入所需的库</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lb"><img src="../Images/d62aa09a25eb330493c95d3fd0921ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ySxJj6fOHCgnNCEgknTNQ.png"/></div></div></figure><p id="2932" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面这段代码获得了不同的人和他们的图像的路径。它构建了一个字典，其中键是persons(格式为F002/MID1 ),值是属于那个人的图像列表。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lc"><img src="../Images/1b46bbc00b914ad950ee272ea3c18b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7t6YCoGmdhKaDOGRXKa9g.png"/></div></div></figure><p id="0f3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们读取关系文件，并以元组列表的形式生成关系。根据选择的验证系列，这些关系分为训练集和验证集。“img2arr”函数获取图像的路径，并以(224，224，3)的形式返回相应的数组。Keras VGGFace实现提供了一个方法“preprocess_input ”,它按照VGGFace输入的形状输出图像。VGGFace模型接受形状(224，224，3)的输入。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ld"><img src="../Images/dce6ae2190ad5d86752423f37f986e21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zWR18iZPrhht5Sb5yvQDQ.png"/></div></div></figure><p id="230c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面这段代码是一个python生成器，它与fit_generator方法一起使用，以指定的批处理大小生成图像。</p><p id="c8a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有有亲属关系的夫妇的数据。但是为了训练模型，我们还应该提供没有亲属关系的夫妇的数据。这个逻辑也包含在定义的python生成器中。该批中的一半将具有有亲属关系的图像对(比如类1 ),而剩余的一半将具有没有亲属关系的图像对(比如类0)</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es le"><img src="../Images/f0e322e68ee9deca9752fde8610c1070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BVpIil9eknc5ClZ3VS2D7Q.png"/></div></div></figure><p id="8264" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的代码是为了建立一个模型。该模型是按照上面所示的体系结构构建的。我们利用函数式API进行建模。这两个图像被传递到VGGFace模型中。我们移除了VGGFace的顶层，这样我们得到的输出就是人脸嵌入。然后，我们使用这些特征的不同组合(x1 -x2)、(x1-x2)、(x1*x2)。这些被连接并通过relu激活传递到密集层，然后传递到softmax层。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lf"><img src="../Images/d86e7c952ca87ce9a182bfc902d1a334.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*0vHnGA6Gd9YLMAHs_FzDeg.png"/></div></figure><p id="117d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用二进制交叉熵损失进行最小化和Adam优化。</p><p id="acdb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练时使用回调<em class="lg">模型检查点</em>和<em class="lg"> ReduceLROnPlateau </em>。只有当验证精度与前一个历元相比有所提高时，模型检查点才会在每个历元后保存模型。当验证精度在相当长的时期内没有提高时，ReduceLROnPlateau将降低学习率。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lh"><img src="../Images/88e43b24c26fa858173e13d93c3367ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iuReE0xg1ANsCsKrev9Wkg.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es li"><img src="../Images/6c073dd1d00d502a84a1f69c6f348985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hzvIEcSQCMTXT0bwPb3gBA.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lj"><img src="../Images/c05396e560bda942bc8f97ab2d447703.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aSd0crZNs3cVNRqbRne_sw.png"/></div></div></figure><p id="8fa3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们读取生成示例提交csv文件中给出的图像对，以进行测试，如上面的代码所示。</p><p id="509d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了做出更好的预测，我们可以为不同的验证集训练模型，然后取所有模型预测的平均值。</p><p id="321a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GitHub链接:</p><p id="9e58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://github.com/bhargavasatyamani/kaggle-competitions/blob/master/Recognizing%20faces%20in%20th%20wild.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/bhargavasatyamani/ka ggle-competitions/blob/master/recogniting % 20 faces % 20 in % 20 th % 20 wild . ipynb</a></p></div></div>    
</body>
</html>