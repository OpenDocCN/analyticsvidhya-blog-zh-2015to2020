<html>
<head>
<title>Bagging v Boosting : Pulsar Star feat. The H2O Package</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Bagging v助推:脉冲星恒星壮举。H2O一揽子计划</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/bagging-v-boosting-the-h2o-package-e288b09ade7e?source=collection_archive---------37-----------------------#2020-03-30">https://medium.com/analytics-vidhya/bagging-v-boosting-the-h2o-package-e288b09ade7e?source=collection_archive---------37-----------------------#2020-03-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/1c2f0748df8c2c9d2708db9332e94f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*I2djqyl0xWK8WMrnEmb30A.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来源:谷歌</figcaption></figure><p id="e57b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们深入研究装袋和增压的复杂性之前，我们需要质疑这种复杂过程的必要性。<a class="ae jo" rel="noopener" href="/analytics-vidhya/a-comparison-of-some-basic-ml-algorithms-by-using-red-wine-quality-data-8318bd6e19e1">在前面的</a>中，我们已经看到了决策树算法是如何工作的，以及它是如何容易被解释的。那我们为什么不解决这个问题呢？如果决策树运行良好，为什么还要做额外的工作呢？</p><p id="473a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">偏差-方差权衡</strong></p><p id="1f0b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">而决策树算法简单、高度直观且非常容易解释；事实上，它经常容易被过度拟合，使其无法成为理想的算法。所谓过拟合模型，我们指的是完全符合或预测训练集，但对任何其他数据集都不能这样做的模型。这种特性，即不同数据集拟合的差异，称为方差。因此，决策树模型无法预测除了它接受训练的数据集之外的任何其他数据集，因此它显示出很高的方差。此外，由于它正确地预测了训练集，我们可以说它具有较低的偏差。就偏差而言，我们指的是预测模型值和潜在真实值之间的差异。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es jp"><img src="../Images/54bc71961094b069954cef6c205e9e25.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*yI_3sLiQir-Y2K6aBF-V8Q.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来源:谷歌</figcaption></figure><p id="ff11" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">机器学习的主要方面是使用一种算法来建立一个模型，平衡适量的偏差和方差，最好是低偏差和低方差。这种模型将能够准确地预测训练集，并且对于任何其他数据集也表现良好，给出一致的良好预测。虽然偏向性较低，但决策树模型通常具有较高的方差。虽然有许多方法可以减少方差:限制叶子的数量，限制节点层次的数量，修剪等等；将它们与Bagging和Boosting的概念结合起来是获得相对更准确结果的更好方法。</p><p id="67ff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">装袋</strong></p><p id="b591" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">降低决策树模型的高方差的一种方法是获取它们的集合，其中每个树都是通过从训练集中引导数据集来构建的。通过引导，我们意味着通过从允许重复的训练集中随机选择样本来创建新的数据集，直到两个数据集具有相同的大小。一个新的样本通过在每棵树上运行来分类，并给它一个获得多数投票的类别。这种基于从引导数据集创建的模型集合对结果进行平均的过程称为Bagging(B-Bootstrapped，Agg- Aggregate)。</p><p id="f32e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">方差的减少是中心极限定理的直接结果</p><blockquote class="ju jv jw"><p id="c0c2" class="iq ir jx is b it iu iv iw ix iy iz ja jy jc jd je jz jg jh ji ka jk jl jm jn hb bi translated">“对于一系列'<strong class="is hj"> n </strong> <em class="hi"> ' </em>独立同分布的随机变量，均值为'<strong class="is hj"> mu </strong>'，方差为'<strong class="is hj"> sigma-squared </strong>'，在一定的一般条件下，它们的和将服从正态分布，均值为'<strong class="is hj"> n*mu </strong>'，方差为'<strong class="is hj">n * sigma-squared</strong>'<em class="hi">'</em>为'<strong class="is hj"> n </strong> ' <strong class="is hj"> </strong>趋于'【T18</p></blockquote><p id="2ffe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将意味着它们的平均值将具有平均值'<em class="jx">μ'</em>和方差'<em class="jx">σ-平方/n' </em>。因此，通过对一组决策树的结果进行平均，我们得到了一个显著降低的方差。</p><p id="7bea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">自举和聚集是我们之前在随机森林中见过的事情。随机森林是Bagging的一个特例，除了引导和聚集，我们还有一个附加条件，即在每次分裂时，只使用一个随机变量子集。有时，我们可能会在变量中有一个很强的预测器。因此，这个变量最终几乎总是成为每棵树的根。因此，这些树最终变得高度相关。通过在每次分裂时获取随机变量的子集，我们确保这种情况不会发生，因此我们在森林中获得了不同的决策树集合。应该注意的是，森林中的树木没有被修剪，因此它们中的每一个都具有较低的偏差。结果，通过使用随机森林，我们得到了一个低偏差和低方差的模型。</p><p id="05d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">增压</strong></p><p id="2fe8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Boosting是一种方法，在这种方法中，我们创建了一系列弱学习者——通常具有高偏差和低方差，以便每个后续学习者都强调纠正其前任所犯的错误，从而降低模型整体的偏差。与Bagging不同，在Bagging中，树可以以任何随机顺序构建，Boosting要求学习器按顺序进行，因为每个学习器都是通过考虑前一个学习器的错误而得到的。梯度推进机器(GBM)是推进算法的一个例子。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kb"><img src="../Images/5467305d1d2c6a4c3f44689a9f1c358a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*04P78hwaLA0pgF1i_0Jlww.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来源:谷歌</figcaption></figure><p id="31a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它通过使用损失函数<strong class="is hj"> </strong> <em class="jx"> L(y，F(x))从结果的初始猜测<em class="jx"> Fo(x) </em> <strong class="is hj"> </strong>开始；</em>然后考虑<em class="jx"> m = </em> 1，使用损失函数的梯度从数据集中的样本计算伪残差。然后，基于这些残差继续构建决策树(弱学习器)<em class="jx">h1(x)</em><strong class="is hj"><em class="jx"/></strong>，并且再次通过使用损失函数来计算每个终端节点的输出值“<em class="jx">γ-1”</em>。应该注意的是，与它们以前的用途不同，这里构建树是为了获得残差的值。现在，为了避免过度拟合，树的输出值通常乘以正则化参数，称为学习率，以获得缩放的结果。学习率是一个缩小每棵树对最终预测的贡献的因素。对初始猜测<em class="jx">F0(x)</em>和树的缩放结果求和，以获得每个样本的新预测<em class="jx"> F1(x) </em>。此后，使用这些新的预测<em class="jx"> F1(x) </em>和初始猜测<em class="jx"> Fo(x)再次计算新的残差；</em>然后增加<em class="jx"> m = 2 </em>，在这些新的残差上建立一个新的树<em class="jx"> h2(x) </em>以获得输出值'<em class="jx"> gamma-2' </em>，该输出值再次由学习率缩放。初始猜测<em class="jx"> Fo(x) </em>、第一树的缩放结果和第二树的缩放结果都被求和，以获得每个样本的新预测<em class="jx"> F2(x) </em>。以这种方式，新的树被不断地添加到序列中，直到<em class="jx"> m=预定义的M </em>或<em class="jx"> </em>当<em class="jx"> </em>额外的树未能改善结果。</p><p id="b1f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">应该注意的是，在每一步，残差变得比它们先前的值小。而且，每次预测都比前一次好。即使结果证明它们比以前更差，我们继续构建后续树的事实也确保了以后会有所改善。这是GBM的主要方面，<em class="jx">即。</em></p><blockquote class="ju jv jw"><p id="f57e" class="iq ir jx is b it iu iv iw ix iy iz ja jy jc jd je jz jg jh ji ka jk jl jm jn hb bi translated">朝着正确的方向迈出许多小步，以获得更好、更准确的结果。</p></blockquote><p id="353c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">H2O套餐</strong></p><p id="fb48" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">H2O是一个开源平台，使用内存压缩来处理大量数据。除了用于GBM和随机森林的函数，R中的H2O包也有用于其他ML算法的函数，比如朴素贝叶斯、SVM等等。由于它使用并行处理，计算是严格执行的，使它比其他软件包快得多。请注意，H2O要求更新并正确安装Java JRE。</p><p id="8616" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里，我们将使用来自Kaggle数据集库中包含脉冲星候选星的<a class="ae jo" href="https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star" rel="noopener ugc nofollow" target="_blank">数据集。</a></p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kg"><img src="../Images/71cb102a6a1e09b2bb098a2609933bf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4qi1sfJ4V0BC3tzrk_I_tg.png"/></div></div></figure><p id="7960" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">像异常值处理这样的数据清理在之前作为<a class="ae jo" rel="noopener" href="/analytics-vidhya/a-comparison-of-some-basic-ml-algorithms-by-using-red-wine-quality-data-8318bd6e19e1">完成。在这之后，我们通过柱状图检查目标类的分布。我们还绘制了预测变量的相关矩阵和预测变量相对于目标类的分布图。然后，我们以8:2的比例将数据分为训练和测试。最后但非常重要的一步是检查训练和测试数据集中目标类的分布，确保它们几乎相同。</a></p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kg"><img src="../Images/aff14879d96f412a8630831faf5105fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fRv1k3P-AQqCz4t6RNVpng.png"/></div></div></figure><p id="2134" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们通过使用<em class="jx">库()</em>函数调用H2O包。我们将使用<em class="jx"> h2o.init()、</em>以及<em class="jx"> </em>初始化h2o，为H2O分配大约50%的RAM大小(<em class="jx"> max_mem_size </em>)，并设置合适的并行进程数量(通过设置<em class="jx"> nthreads = -1，</em>该数量将自动决定)。<em class="jx"> h20.removeAll() </em>在H2O集群已经在运行的情况下清除石板。然后，我们使用<em class="jx"> as.h2o() </em>将我们的训练和测试数据集作为对象分配给H2O集群。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kh"><img src="../Images/1efb24dc87d42822b951db6c6e9b97f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iP3Pvg6G5WA6YnDZwnMYYQ.png"/></div></div></figure><p id="fc71" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jx">装袋</em> </strong>:我们首先使用<em class="jx"> h2o.randomForest() </em>函数制作一个简单的随机森林模型。我们检查模型的不同度量和重要变量，然后用这个模型做初步预测。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es ki"><img src="../Images/5a6dd85fe0daafe160b4004c9185c402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1kp1ZoO_37d-HULnn7sOUA.png"/></div></div></figure><p id="414f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们将建立另一个模型，但这次我们将调整以下超参数-</p><p id="e15c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jx">(一)</em> </strong> <em class="jx"> ntrees: </em>森林中的树木数量；<strong class="is hj"><em class="jx">【b】</em></strong><em class="jx">mtries:</em>每次分割时使用的随机变量的个数；<strong class="is hj"><em class="jx">【c】</em></strong><em class="jx">stopping _ rounds</em>，<em class="jx"> stopping_metric，stopping_tolerance: </em>如果连续得分事件的'<em class="jx"> stopping_metric' </em>没有提高(<em class="jx">stopping _ tolerance '</em>* 100)%，则停止生成新树；<strong class="is hj"><em class="jx">(d)</em></strong><em class="jx">balance _ classes:True</em>对于不平衡的数据，这里就是这种情况；<strong class="is hj"><em class="jx">(e)</em></strong><em class="jx">n folds:<em class="jx">k</em>的</em>值用于<em class="jx"> k- </em>的交叉折叠验证；<strong class="is hj"><em class="jx">(f)</em></strong><em class="jx">score _ each _ iteration:True</em>如果我们想要针对每棵树的训练和验证进行预测。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kj"><img src="../Images/312cb7409bfb918f264b228f74d474f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QVBZZZLULWNmrEt8UkQM4g.png"/></div></div></figure><p id="b142" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们看到超参数的调整带来了更好的召回和AUC值，尽管准确度和精确度有所下降。但是，由于Recall和AUC相对来说比其他的更重要，新模型确实在给定恒星是否是脉冲星的分类上做得更好。</p><p id="d910" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jx">助推</em> </strong>:和之前一样，我们先用<em class="jx"> h2o.gbm() </em>函数做一个简单的GBM模型。我们检查模型的不同度量和重要变量，然后用这个模型做初步预测。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kk"><img src="../Images/a336b53fc604f2a1157832a5656b497a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qURCj-79bgqVXhzo0F1fjg.png"/></div></div></figure><p id="83ba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样，我们将构建另一个模型，但这次我们将调整以下超参数-</p><p id="c53f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jx">(一)</em> </strong> <em class="jx"> ntrees: </em>森林中的树木数量；<strong class="is hj"><em class="jx">(b)</em></strong><em class="jx">max _ depth:</em>每棵树的最大深度；<strong class="is hj"><em class="jx">(c)</em></strong><em class="jx">learn _ rate:</em>以学习率来缩放从每棵树获得的输出值<em class="jx">；</em><strong class="is hj"><em class="jx">(d)</em></strong><em class="jx">sample _ rate:</em>每棵树的行采样率<em class="jx">；</em><strong class="is hj"><em class="jx">(e)</em></strong><em class="jx">col _ sample _ rate:</em>每棵树的列采样率<em class="jx">；</em><strong class="is hj"><em class="jx">【f】</em></strong><em class="jx">stopping _ rounds</em>，<em class="jx"> stopping_metric，stopping_tolerance: </em>如果连续得分事件的'<em class="jx"> stopping_metric' </em>'没有提高(<em class="jx">stopping _ tolerance '</em>* 100)%，则停止生成新树；<strong class="is hj"><em class="jx">(g)</em></strong><em class="jx">balance _ classes:True</em>对于不平衡的数据，这里就是这种情况；<strong class="is hj"><em class="jx">(h)</em></strong><em class="jx">n folds:<em class="jx">k的</em>值为<em class="jx"> k- </em>折叠交叉验证；<strong class="is hj"> <em class="jx">(一)</em></strong><em class="jx">score _ tree _ iteration:</em>模型在每一个<em class="jx"> 'score_tree_interval' </em>树后进行评分。</em></p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kl"><img src="../Images/09c20bd0c604c64a953af0a1e7c9c517.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nK2tWSVwiEncdo2U7s2Q4g.png"/></div></div></figure><p id="b1b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们看到，通过调整超参数，准确性、召回率和AUC的值都有所增加，尽管精确度显示出小幅下降。此外，如果我们将修改的随机森林模型与修改的GBM模型进行比较，我们会发现后者在所有四个指标上都具有更好的值。因此，在这种情况下，Boosting在预测一个给定的恒星是否是脉冲星方面做得更好。</p><p id="dcb7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">值得注意的是，尽管装袋和提升提供了比决策树更好的结果，但它们更难解释。此外，这两种方法都包含大量的超参数，因此调整它们以获得合适的模型所需的运行时间可能会非常长。因此，打包和提升是计算上非常昂贵的方法。</p><p id="164e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">完整代码可在<a class="ae jo" href="https://github.com/gauravalley/Pulsar-Star-Prediction" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p></div></div>    
</body>
</html>