<html>
<head>
<title>Review: Spatial Pyramid Pooling[1406.4729]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">审查:空间金字塔池[1406.4729]</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/review-spatial-pyramid-pooling-1406-4729-bfc142988dd2?source=collection_archive---------3-----------------------#2020-04-19">https://medium.com/analytics-vidhya/review-spatial-pyramid-pooling-1406-4729-bfc142988dd2?source=collection_archive---------3-----------------------#2020-04-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="21dd" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">向CNN传递可变大小的输入</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/b84291720732a98a69e09a3b4c0eaa2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2yrYj7SrUffyOAXpGaoUw.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">演职员表:<a class="ae jn" href="https://en.wikipedia.org/wiki/Object_detection" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Object_detection</a></figcaption></figure><p id="3df3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我已经计划阅读主要的物体探测论文(虽然我已经粗略地阅读了它们中的大部分，但我会详细地阅读它们，好到足以写一篇关于它们的博客)。这些论文与基于深度学习的对象检测相关。随时给建议或询问疑惑会尽我所能帮助大家。我将在下面写下每篇论文的arxiv代码，并在下面给出博客(我写的时候会不断更新)和他们论文的链接。任何从这个领域开始的人都可以跳过许多这样的论文。当我读完所有的论文后，我还会写下它们的优先级/重要性(根据理解主题的必要性)。<br/>我写这篇博客是考虑到和我相似并且仍在学习的读者。万一我犯了任何错误(我将通过从各种来源(包括博客、代码和视频)深入理解论文来尽量减少错误)，任何人都可以随意地在博客上强调它或添加评论。我已经提到了我将在博客结尾涉及的论文列表。</p><p id="fe73" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们开始吧:)</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><p id="e957" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">CNN用于从图像中提取特征，然后是用于分类的全连接层。由于卷积运算是以滑动窗口方式应用的，所以它可以接受不同大小的输入，从而产生不同大小的输出。因为CNN之后是可以接受固定大小输入的全连接层。这使得CNN不能接受不同大小的输入。因此，图像在被送入CNN之前，首先被重塑成某种特定的维度。这产生了另一个问题，即图像扭曲和分辨率降低。空间金字塔池可以解决这个问题。</p><h2 id="14d1" class="kr ks hi bd kt ku kv kw kx ky kz la lb jx lc ld le kb lf lg lh kf li lj lk ll bi translated">空间金字塔池</h2><p id="81a1" class="pw-post-body-paragraph jo jp hi jq b jr lm ij jt ju ln im jw jx lo jz ka kb lp kd ke kf lq kh ki kj hb bi translated">在空间金字塔合并之前，提取的要素地图通常被展平(完全连接的图层接受作为1d矢量的输入)或合并，以滑动窗口方式应用，从而提供不同大小的输出。</p><p id="2534" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">空间金字塔池在局部空间箱中维护空间信息。箱柜的数量和大小是固定的。在每个空间仓中，汇集每个滤波器的响应。在下图所示的示例中，完成了三级池。在论文中，作者到处使用最大池。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lr"><img src="../Images/87c173f1d01d3fc10700af953d6cee07.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*qkWGONIVKO1xyJZD6urYag.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">空间金字塔池(鸣谢:<a class="ae jn" href="https://arxiv.org/pdf/1406.4729.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></figcaption></figure><p id="1aa1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">输出特征图有256个过滤器，大小任意(取决于输入大小)。</p><ol class=""><li id="2684" class="ls lt hi jq b jr js ju jv jx lu kb lv kf lw kj lx ly lz ma bi translated">在第一个池层(图中的灰色层)中，输出只有一个容器，覆盖了一个完整的图像。这类似于全局池操作。这个池的输出是256-d。</li><li id="44ce" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated">在第二次汇集中，特征图被汇集成具有4个箱，从而给出大小为4*256的输出。</li><li id="bed9" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated">在第三个池中，特征图被池化以具有16个箱，从而给出大小为16*256的输出。</li></ol><p id="3d3d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">所有池层的输出被展平和连接，以给出固定维度的输出，而不考虑输入大小。</p><h2 id="bb0f" class="kr ks hi bd kt ku kv kw kx ky kz la lb jx lc ld le kb lf lg lh kf li lj lk ll bi translated">多尺寸训练</h2><p id="e377" class="pw-post-body-paragraph jo jp hi jq b jr lm ij jt ju ln im jw jx lo jz ka kb lp kd ke kf lq kh ki kj hb bi translated">由于现在我们的CNN能够使用不同大小的输入，作者为多种输入大小训练了网络(他们选择224*224和180*180)。多尺寸训练的主要原因是模拟不同的输入尺寸。这种方法效果很好，显示出比单一尺寸训练更好的效果。</p><p id="2f55" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这篇论文还有其他的实验和训练策略，出于简洁和篇幅的原因，我将跳过这些，这篇博客的目的是讲述这些技术，而不是在每篇论文中进行的实验。</p><h2 id="29e1" class="kr ks hi bd kt ku kv kw kx ky kz la lb jx lc ld le kb lf lg lh kf li lj lk ll bi translated">用于对象检测的SPPNet</h2><p id="467a" class="pw-post-body-paragraph jo jp hi jq b jr lm ij jt ju ln im jw jx lo jz ka kb lp kd ke kf lq kh ki kj hb bi translated">使用空间金字塔池的对象检测是建立在RCNN架构之上的，我希望你们知道这一点。在RCNN中，生成2000个区域提议，然后2000个裁剪的图像通过CNN。在SPPNet中，每个图像只提取一次特征图。对每个候选者应用空间金字塔池来生成固定大小的表示。由于CNN是最耗时的部分，与RCNN相比，SPPNet非常快。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mg"><img src="../Images/50cd7e583aeb89d5b82f7ef2c31c916a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*bNjKGNQnF7c9Br8_YkegRw.png"/></div></figure><p id="4adb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于每个提议，完全连接的层被执行2000次，以生成最终预测。</p><p id="e77a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">和平…</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="fb40" class="mh ks hi bd kt mi mj mk kx ml mm mn lb io mo ip le ir mp is lh iu mq iv lk mr bi translated">论文列表:</h1><ol class=""><li id="cead" class="ls lt hi jq b jr lm ju ln jx ms kb mt kf mu kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1312.6229.pdf" rel="noopener ugc nofollow" target="_blank"> OverFeat:使用卷积网络的综合识别、定位和检测</a>。[ <a class="ae jn" href="https://towardsdatascience.com/overfeat-review-1312-6229-4fd925f3739f" rel="noopener" target="_blank">链接到博客</a></li><li id="2cb1" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank">丰富的特征层次，用于精确的对象检测和语义分割(RCNN)。</a> [ <a class="ae jn" rel="noopener" href="/@sanchittanwar75/rcnn-review-1311-2524-898c3148789a">链接到博客</a></li><li id="f69d" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1406.4729.pdf" rel="noopener ugc nofollow" target="_blank">用于视觉识别的深度卷积网络中的空间金字塔池(SPPNet)。</a> ←你完成了这篇博客。</li><li id="69a1" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank">快速R-CNN </a>【链接到博客】</li><li id="a82b" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">更快的R-CNN:利用区域提议网络实现实时目标检测。</a>【博客链接】</li><li id="414b" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">你只看一次:统一的，实时的物体检测。</a>【博客链接】</li><li id="8b68" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1512.02325.pdf" rel="noopener ugc nofollow" target="_blank"> SSD:单次多盒探测器</a>。[博客链接]</li><li id="903f" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated">R-FCN:通过基于区域的完全卷积网络的目标检测。【博客链接】</li><li id="db07" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1612.03144.pdf" rel="noopener ugc nofollow" target="_blank">用于目标检测的特征金字塔网络。</a>【博客链接】</li><li id="d26a" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1701.06659.pdf" rel="noopener ugc nofollow" target="_blank"> DSSD:解卷积单粒子探测器</a>。[博客链接]</li><li id="b760" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1708.02002.pdf" rel="noopener ugc nofollow" target="_blank">密集物体检测的焦点丢失(视网膜网)。</a>【博客链接】</li><li id="9eed" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1804.02767.pdf" rel="noopener ugc nofollow" target="_blank"> YOLOv3:增量改进</a>。[博客链接]</li><li id="ee60" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1805.09300v3.pdf" rel="noopener ugc nofollow" target="_blank">狙击手:高效多尺度训练</a>。[博客链接]</li><li id="ef7f" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1904.04514.pdf" rel="noopener ugc nofollow" target="_blank">用于标记像素和区域的高分辨率表示。</a>【博客链接】</li><li id="900c" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1904.01355v5.pdf" rel="noopener ugc nofollow" target="_blank"> FCOS:全卷积一级目标检测</a>。[博客链接]</li><li id="c8f6" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1904.07850.pdf" rel="noopener ugc nofollow" target="_blank">物体为点</a>。[博客链接]</li><li id="a15e" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated">CornerNet-Lite:高效的基于关键点的对象检测。【博客链接】</li><li id="43a0" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated">用于物体检测的关键点三元组。[博客链接]</li><li id="76dd" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated"><a class="ae jn" href="https://arxiv.org/pdf/1909.00700.pdf" rel="noopener ugc nofollow" target="_blank">用于实时对象检测的训练时间友好网络。</a>【博客链接】</li><li id="82e1" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated">CBNet:一种用于目标检测的新型复合主干网络体系结构。【博客链接】</li><li id="2929" class="ls lt hi jq b jr mb ju mc jx md kb me kf mf kj lx ly lz ma bi translated">EfficientDet:可扩展且高效的对象检测。[博客链接]</li></ol><p id="62bd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">和平…</p></div></div>    
</body>
</html>