<html>
<head>
<title>Aptos Blindness Challenge — Part 1 (Baseline — EfficientNet)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Aptos失明挑战—第1部分(基线—效率网)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/aptos-blindness-challenge-part-1-baseline-efficientnet-c7a256daa6e5?source=collection_archive---------15-----------------------#2020-07-17">https://medium.com/analytics-vidhya/aptos-blindness-challenge-part-1-baseline-efficientnet-c7a256daa6e5?source=collection_archive---------15-----------------------#2020-07-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b1ecdd6040f68c0520b2454a16168a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mdX2a0yxcGJun7ntUlbBnA.jpeg"/></div></div></figure><p id="5ab0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Kaggle在2019年9月举办了<a class="ae jo" href="https://www.kaggle.com/c/aptos2019-blindness-detection" rel="noopener ugc nofollow" target="_blank"> Aptos失明挑战赛</a>。虽然我参加聚会已经很晚了，但我想我还是要试试。该比赛是关于从印度各医院拍摄的瞳孔图像中检测糖尿病视网膜病变。实现可以在我的GitHub(【https://github.com/preeyonuj/Aptos-Blindess-Challenge】)上找到。</p><p id="99fa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我将分多个部分发布我的实现。第一部分需要在默认图像上实现一个基本的EfficientNet(没有图像预处理)。本文将分为3个主要部分:</p><ol class=""><li id="1feb" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">数据探索</li><li id="0bff" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">系统模型化</li><li id="b88c" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">测试集上的推断</li><li id="56c5" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">改进的余地</li></ol><h1 id="344f" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据探索</h1><p id="8ad7" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated"><strong class="is hj">什么是糖尿病视网膜病变？</strong></p><p id="fccc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">糖尿病视网膜病变是一种影响眼睛的糖尿病并发症。它是由眼睛后部(视网膜)感光组织的血管受损引起的。这种情况可能发生在任何1型或二型糖尿病患者身上。患糖尿病的时间越长，血糖控制得越差，患这种眼部并发症的可能性就越大。</p><p id="180e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">从瞳孔图像中检测糖尿病视网膜病变</strong></p><p id="5724" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从技术上讲，医学来源声称糖尿病视网膜病变有2个阶段。</p><ol class=""><li id="e185" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">早期糖尿病视网膜病变:这一阶段有一个更常见的名字，非增殖性糖尿病视网膜病变(NPDR)——新血管不再生长(增殖)。当你患有NPDR时，你视网膜中的血管壁会变弱。微小的凸起(微动脉瘤)从较小血管的血管壁突出，有时会将液体和血液泄漏到视网膜中。较大的视网膜血管也会开始扩张，直径变得不规则。随着更多的血管堵塞，NPDR可以从轻度发展到重度。</li><li id="8af3" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">晚期糖尿病性视网膜病变:糖尿病性视网膜病变可以发展为这种更严重的类型，称为增生性糖尿病性视网膜病变。在这种类型中，受损的血管会关闭，导致视网膜中新的异常血管的生长，并会泄漏到充满眼睛中心(玻璃体)的透明胶状物质中。</li></ol><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/21af113c265eea5c1b0a088f2ff91b9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*jH0FhCvv3KhItiOy3we6bA.png"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">温和的NDPR</figcaption></figure><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/6e769aaac0e38db1b1cb3b23676bce36.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*OrWKW5BkClKPGi25N17W6w.png"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">温和的NDPR</figcaption></figure><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/ef990adf2d9478ccbd689e9d7eefdafe.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*KcbZSZpDOnWmGGl3aF5Z0w.png"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">重度NDPR</figcaption></figure><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/eca0887c38aca722301c199fd5a617bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R9fqPNDcySU64XU1gMHEGg.png"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">增生性DR</figcaption></figure><p id="87d3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">探索数据集</strong></p><p id="e9f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">临床医生对每张图像的糖尿病性视网膜病变的严重程度进行了评级，等级为0到4:</p><p id="a18c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">0 —无灾难恢复</p><p id="ed5c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1 —轻度DR</p><p id="50c8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2 —中度灾难恢复</p><p id="976a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3 —严重灾难恢复</p><p id="bb1a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4 —增生性DR</p><p id="159c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">据说数据集在类之间会有一定量的污染。图像可能包含伪像、失焦、曝光不足或曝光过度。这些图像是在很长一段时间内使用各种相机从多个诊所收集的，这将引入进一步的变化。</p><p id="6232" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于这个数据集是从Kaggle竞赛中获取的，因此提供的测试集没有标签来验证结果，因此我将训练集划分为train-test。这样，我们可以在更精细的层次上分析结果。图像的名称以及它们的诊断也与数据集一起提供。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/882533c87ccf79430a4d385fe231e063.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*pKO42N81pEWx7yULVRbOlg.png"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">不同类别之间的数据分布(全部数据)</figcaption></figure><p id="344a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">据观察，0类(无DR)有大量数据。3级(重度DR)的数据量最少。</p><p id="1903" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里是一个小的数据示例，以便熟悉数据集。这些图像实际上非常大，需要缩小。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/59fd61e69f6d250bdf4eac572a3c6ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A8N7HXcT5NPscdvfw2uMqw.png"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">不同班级的样本</figcaption></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="91ff" class="kd ke hi bd kf kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la bi translated"><strong class="ak">建模</strong></h1><p id="f125" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在本节中，我们将在PyTorch中准备一个基本的高效Net B0模型。我们将按原样使用这些图像(未经预处理)。这可以被认为是一个基线，我们将在这个过程中进行多次修改，并希望在每次迭代后改进结果。</p><p id="a0e0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">什么是高效网？</strong></p><p id="3118" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">EfficientNet是一种理念，而不是单一的架构。作者在这种方法中试图利用的是复合缩放的力量。众所周知，更高的缩放比例导致更好的精度，通常有三种缩放比例:<br/> 1 .深度:缩放网络深度是许多卷积网络最常用的方式。直觉是，更深的卷积网络可以捕捉更丰富和更复杂的特征，并在新任务上进行很好的概括。<br/> 2。宽度:更宽的网络往往能够捕捉更细粒度的特征，也更容易训练。<br/> 3。分辨率:对于更高分辨率的输入图像，卷积网络可以捕获更精细的模式。从早期网络的224x224开始，现代网络倾向于使用299x299或331x331以获得更好的准确性。最近，GPipe实现了480x480分辨率的一流ImageNet精度。</p><p id="c1ca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了追求更高的准确性和效率，在扩展过程中平衡网络宽度、深度和分辨率的所有维度至关重要。因此，他们提出了一种新的缩放方式，用一个系数来控制三维空间。他们对这些维度的完美系数进行网格搜索，并将系数应用于这些维度。然后，这些系数被用于扩大基线移动网络，称为EfficientNet-B0。在这里，我已经开始与高效-B1，这是一个比基础模型高一个档次。</p><p id="b9c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">实现</strong></p><p id="bd19" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将使用PyTorch实现一个EfficientNet-B1。首先，我们将导入一些库。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="5f19" class="mk ke hi mg b fi ml mm l mn mo"><strong class="mg hj">import</strong> <strong class="mg hj">warnings</strong><br/>warnings.filterwarnings('ignore')<br/><br/><strong class="mg hj">import</strong> <strong class="mg hj">numpy</strong> <strong class="mg hj">as</strong> <strong class="mg hj">np</strong><br/><strong class="mg hj">import</strong> <strong class="mg hj">pandas</strong> <strong class="mg hj">as</strong> <strong class="mg hj">pd</strong><br/><strong class="mg hj">import</strong> <strong class="mg hj">matplotlib.pyplot</strong> <strong class="mg hj">as</strong> <strong class="mg hj">plt</strong><br/><strong class="mg hj">import</strong> <strong class="mg hj">cv2</strong><br/><strong class="mg hj">import</strong> <strong class="mg hj">random</strong><br/><strong class="mg hj">import</strong> <strong class="mg hj">os</strong><br/><br/><strong class="mg hj">from</strong> <strong class="mg hj">torch.utils.data</strong> <strong class="mg hj">import</strong> WeightedRandomSampler<br/><strong class="mg hj">from</strong> <strong class="mg hj">torchvision</strong> <strong class="mg hj">import</strong> datasets, transforms<br/><strong class="mg hj">import</strong> <strong class="mg hj">torch</strong><br/><strong class="mg hj">import</strong> <strong class="mg hj">torch.optim</strong> <strong class="mg hj">as</strong> <strong class="mg hj">optim</strong><br/><strong class="mg hj">import</strong> <strong class="mg hj">torch.nn.functional</strong> <strong class="mg hj">as</strong> <strong class="mg hj">F</strong><br/><strong class="mg hj">import</strong> <strong class="mg hj">torch.nn</strong> <strong class="mg hj">as</strong> <strong class="mg hj">nn</strong><br/><strong class="mg hj">from</strong> <strong class="mg hj">efficientnet_pytorch</strong> <strong class="mg hj">import</strong> EfficientNet<br/><strong class="mg hj">from</strong> <strong class="mg hj">torch.optim.lr_scheduler</strong> <strong class="mg hj">import</strong> StepLR</span><span id="2653" class="mk ke hi mg b fi mp mm l mn mo"><strong class="mg hj">from</strong> <strong class="mg hj">sklearn.metrics</strong> <strong class="mg hj">import</strong> accuracy_score<br/><strong class="mg hj">from</strong> <strong class="mg hj">sklearn.metrics</strong> <strong class="mg hj">import</strong> confusion_matrix<br/><strong class="mg hj">from</strong> <strong class="mg hj">sklearn.metrics</strong> <strong class="mg hj">import</strong> cohen_kappa_score</span></pre><p id="92e7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">虽然，我没有在这段代码中植入任何东西，但是我还是喜欢包含这段代码。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="1ac4" class="mk ke hi mg b fi ml mm l mn mo"><strong class="mg hj">def</strong> seed_everything(seed):<br/>    random.seed(seed)<br/>    os.environ['PYTHONHASHSEED'] = str(seed)<br/>    np.random.seed(seed)<br/>    torch.manual_seed(seed)<br/>    torch.cuda.manual_seed(seed)<br/>    torch.backends.cudnn.deterministic = <strong class="mg hj">True</strong><br/><br/>SEED = 42<br/>seed_everything(SEED)</span></pre><p id="1be7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们将定义一个为我们训练模型的函数。我输入以下变量:</p><ul class=""><li id="7739" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn mq jv jw jx bi translated">log_interval:在每个log_interval之后打印训练统计数据</li><li id="a9b5" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn mq jv jw jx bi translated">型号:PyTorch型号</li><li id="c752" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn mq jv jw jx bi translated">设备:定义在其上分配张量的设备的对象。不是CPU就是GPU。</li><li id="0dc8" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn mq jv jw jx bi translated">train_loader:训练数据集上的Python iterable</li><li id="28de" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn mq jv jw jx bi translated">优化器:训练时使用的优化器</li><li id="896f" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn mq jv jw jx bi translated">历元:训练的历元数</li></ul><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="be26" class="mk ke hi mg b fi ml mm l mn mo"><strong class="mg hj">def</strong> train(log_interval, model, device, train_loader, optimizer, epoch):<br/>    model.train()<br/>    <strong class="mg hj">for</strong> batch_idx, (data, target) <strong class="mg hj">in</strong> enumerate(train_loader):<br/>        data, target = data.to(device), target.to(device)<br/>        optimizer.zero_grad()<br/>        output = model(data)<br/>        output = nn.LogSoftmax(dim=1)(output)<em class="mr">       </em><br/>        loss = F.nll_loss(output, target)<br/>        loss.backward()<br/>        optimizer.step()<br/>        <strong class="mg hj">if</strong> batch_idx % log_interval == 0:<br/>            print('Train Epoch: <strong class="mg hj">{}</strong> [<strong class="mg hj">{}</strong>/<strong class="mg hj">{}</strong> (<strong class="mg hj">{:.0f}</strong>%)]<strong class="mg hj">\t</strong>Loss:<strong class="mg hj">{:.6f}</strong>'.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader),loss.item()))</span></pre><p id="398d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，我们将定义一个测试函数，以检查在每个时期之后，经过训练的模型如何在验证集上执行。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="8356" class="mk ke hi mg b fi ml mm l mn mo"><strong class="mg hj">def</strong> test(model, device, test_loader):<br/>    model.eval()<br/>    test_loss = 0<br/>    correct = 0<br/>    <strong class="mg hj">with</strong> torch.no_grad():<br/>        <strong class="mg hj">for</strong> data, target <strong class="mg hj">in</strong> test_loader:<br/>            data, target = data.to(device), target.to(device)<br/>            output = model(data)<br/>            output = nn.LogSoftmax(dim=1)(output)<br/>            test_loss += F.nll_loss(output, target, reduction='sum').item()<br/>            pred = output.argmax(dim=1, keepdim=<strong class="mg hj">True</strong>)  <br/>            correct += pred.eq(target.view_as(pred)).sum().item()<br/><br/>    test_loss /= len(test_loader.dataset)<br/><br/>    print('<strong class="mg hj">\n</strong>Test set: Average loss: <strong class="mg hj">{:.4f}</strong>, Accuracy: <strong class="mg hj">{}</strong>/<strong class="mg hj">{}</strong> (<strong class="mg hj">{:.0f}</strong>%)<strong class="mg hj">\n</strong>'.format(<br/>        test_loss, correct, len(test_loader.dataset),<br/>        100. * correct / len(test_loader.dataset)))</span></pre><p id="16c8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，定义训练的参数。上面我已经说了大部分。其余的是:</p><ul class=""><li id="2b8e" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn mq jv jw jx bi translated">lr:初始学习率</li><li id="e5c4" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn mq jv jw jx bi translated">γ:学习率衰减的乘法因子</li><li id="5a37" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn mq jv jw jx bi translated">类的数量:类的数量(对于这个问题陈述，是5)</li></ul><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="540c" class="mk ke hi mg b fi ml mm l mn mo">batch_size = 30<br/>epochs = 50<br/>log_interval = 10<br/>save_model = <strong class="mg hj">True</strong><br/>lr = 0.01<br/>gamma = 0.7<br/>no_of_classes = 5</span></pre><p id="2daf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于类别不平衡，我们将使用加权样本来提供跨类别的平等感。这里的“train.csv”包含每个图像的路径及其标签。该CSV提供每个类别中的样本总数。权重是根据每个类别中的样本数量计算的。但是权重需要在WeightedRandomSampler函数中分配给每个样本。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="f850" class="mk ke hi mg b fi ml mm l mn mo">class_info  = pd.read_csv("./data/train/separated/train.csv")<br/>class_count = class_info['labels'].value_counts().values.tolist()<br/>target_list = class_info['labels'].values.tolist()<br/><br/>target_list = torch.tensor(target_list)<br/>target_list = target_list[torch.randperm(len(target_list))]<br/><br/>class_weights = 1./torch.tensor(class_count, dtype=torch.float)<br/>class_weights_all = class_weights[target_list]<br/>weighted_sampler = WeightedRandomSampler(<br/>    weights=class_weights_all,<br/>    num_samples=len(class_weights_all),<br/>    replacement=<strong class="mg hj">True</strong><br/>)</span></pre><p id="60c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们定义存储数据的路径。数据以特定的方式存储。“train”文件夹包含5个文件夹，每个文件夹代表一个类。这5个文件夹的名称对应于我们分配的标签名称。我们还检查GPU是否可用，如果可用，我们用它定义“设备”变量。“kwargs”只是定义了用于训练和验证的投料批量。“kwargs”可以有多个其他参数。<br/>“transform”变量依赖于PyTorch，并在将训练图像输入模型之前存储要对其进行的图像转换。<br/>最后,‘Train _ loader’是训练集上的可迭代的，而‘val _ loader’是验证集上的可迭代的。这些用于将数据输入模型进行训练或验证。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="150a" class="mk ke hi mg b fi ml mm l mn mo">traindir = "./data/train/separated/train"<br/>valdir = "./data/train/separated/val"<br/><br/>use_cuda = torch.cuda.is_available()<br/>device = torch.device("cuda" <strong class="mg hj">if</strong> use_cuda <strong class="mg hj">else</strong> "cpu")<br/><br/>kwargs = {'batch_size': batch_size}</span><span id="a577" class="mk ke hi mg b fi mp mm l mn mo">transform=transforms.Compose([<br/>    transforms.Resize([224, 224]),<br/>    transforms.ToTensor()])</span><span id="0683" class="mk ke hi mg b fi mp mm l mn mo">dataset1 = datasets.ImageFolder(traindir,transform=transform)<br/>dataset2 = datasets.ImageFolder(valdir,transform=transform)<br/><br/>train_loader = torch.utils.data.DataLoader(dataset1, sampler=weighted_sampler, **kwargs)<br/>val_loader = torch.utils.data.DataLoader(dataset2, **kwargs)</span></pre><p id="620e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们定义效率网络模型。我安装了一个库，它允许我调用一个简单的函数来加载EfficientNet模型。我们还在模型的末尾定义了全连接层，以将预先构建的模型的输出转换为5维向量，该向量表示我们的问题陈述中的5个类。<br/>然后，我们将模型加载到所用的设备上。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="4480" class="mk ke hi mg b fi ml mm l mn mo">model = EfficientNet.from_name('efficientnet-b1')<br/><strong class="mg hj">for</strong> param <strong class="mg hj">in</strong> model.parameters():<br/>    param.requires_grad = <strong class="mg hj">True</strong><br/><br/>num_ftrs = model._fc.in_features<br/>model._fc = nn.Linear(num_ftrs, no_of_classes)<br/>model = model.to(device)</span></pre><p id="fe1c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">作为标准，我决定使用交叉熵损失。它将Softmax和NLL损耗合并为一个函数。当有多个类需要考虑时，这是一个有用的标准。对每个迷你批次的观测值进行平均。我已经决定使用Adam optimizer，因为它们通常表现很好。可以理解的是，不同的优化器可能会有更好的性能，但我还没有研究它。<br/> StepLR是在每个“步长”时期后修改学习率的函数。这里的“步长”设置为1。“gamma”设置为0.7，这基本上意味着在每个时期后将0.7乘以学习率，从而在此过程中降低学习率。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="2b00" class="mk ke hi mg b fi ml mm l mn mo">criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))<br/>optimizer = optim.Adam(model.parameters(), lr=lr)<br/>scheduler = StepLR(optimizer, step_size=1, gamma=gamma)</span></pre><p id="596c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一个主循环，其中我们调用训练函数来训练模型，调用测试函数来测试验证集上的模型，并调用调度程序来在一定数量的时期后改变学习。最后，一旦训练完成，我们使用torch.save保存模型。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="6253" class="mk ke hi mg b fi ml mm l mn mo"><strong class="mg hj">for</strong> epoch <strong class="mg hj">in</strong> range(1, epochs + 1):<br/>    train(log_interval, model, device, train_loader, optimizer, epoch)<br/>    test(model, device, test_loader)<br/>    scheduler.step()<br/><br/><strong class="mg hj">if</strong> save_model:<br/>    torch.save(model.state_dict(), "aptos_blindness_effnet_b1_weighted.pt")</span><span id="d9a1" class="mk ke hi mg b fi mp mm l mn mo">############# OUTPUT #############<br/>After 50 epochs, the results were:<br/>Test set: Average loss: 0.7208, Accuracy: 528/733 (72%)</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="680c" class="kd ke hi bd kf kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la bi translated"><strong class="ak">测试集上的推理</strong></h1><p id="d4ed" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">推理代码片段只是上面定义的测试函数的修改版本。要加载一个保存的模型，这个模型必须已经在某个变量中定义了(这里是“模型”)。我们只需要将state_dict上传到那个变量上，瞧，我们的模型就可以进行推理了。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="5d41" class="mk ke hi mg b fi ml mm l mn mo">model_path = "aptos_blindness_effnet_b1_weighted.pt"<br/>use_cuda = torch.cuda.is_available()<br/>device = torch.device("cuda" <strong class="mg hj">if</strong> use_cuda <strong class="mg hj">else</strong> "cpu")<br/>model = EfficientNet.from_name('efficientnet-b1').to(device)<br/>model.load_state_dict(torch.load(model_path))</span></pre><p id="573e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们用测试数据集的路径来定义“testdir”变量。我们也在测试集上保持相同的转换，因为我刚刚裁剪了图像，并在函数中对其进行了归一化。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="1daf" class="mk ke hi mg b fi ml mm l mn mo">testdir = "./data/train/separated/test"</span><span id="ca7f" class="mk ke hi mg b fi mp mm l mn mo">transform=transforms.Compose([<br/>    transforms.Resize([224, 224]),<br/>    transforms.ToTensor(),<br/>    transforms.Normalize((0.1307,), (0.3081,))<br/>    ])</span><span id="a440" class="mk ke hi mg b fi mp mm l mn mo">dataset1 = datasets.ImageFolder(testdir, transform=transform)<br/>test_loader = torch.utils.data.DataLoader(dataset1)<br/><br/>model.eval()<br/>test_loss = 0<br/><br/>true_labels = []<br/>preds = []<br/><br/><strong class="mg hj">with</strong> torch.no_grad():<br/>    correct = 0<br/>    total = 0<br/>    <strong class="mg hj">for</strong> images, labels <strong class="mg hj">in</strong> test_loader:<br/>        images = images.to(device)<br/>        labels = labels.to(device)<br/>        true_labels.append(labels)<br/>        output = model(images)<br/>        output = nn.LogSoftmax(dim=1)(output)<br/>        test_loss += F.nll_loss(output, labels, reduction='sum').item()<br/>        pred = output.argmax(dim=1, keepdim=<strong class="mg hj">True</strong>)<br/>        preds.append(pred)<br/>        correct += pred.eq(labels.view_as(pred)).sum().item()<br/>        <br/>        total += labels.size(0)<br/><br/>    print('Test Accuracy of the model on the test images: <strong class="mg hj">{}</strong> %'.format(100 * correct / total))</span></pre><p id="d21e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">测试结果并不是很好。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ms"><img src="../Images/ab91be3696be86016462f8bea68fed92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3tmVA0ss9gKg7HB7LbT_ug.png"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">测试集的混淆矩阵</figcaption></figure><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="a1fe" class="mk ke hi mg b fi ml mm l mn mo">Overall Accuracy : 0.71869 <br/>Kappa Score : 0.54697</span></pre><p id="d2e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">很明显，该模型未能根据数据进行适当的训练。该模型偏向于类别2，即它预测大多数测试样本为类别2。3类和4类几乎没有正确的预测。准确率在71%左右，但看起来它是由主导类的正确预测推动的。从流行的观点来看，如果类的比例实际上类似于真实世界的场景，那么“重要”类被正确分类可能是个好消息。但这也是一种直觉，在这个特殊的问题中，如果一个人患有增殖性DR(4级),这是严重的，可以导致失明，但被诊断为中度DR(2级),这将是一个严重的疏忽。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="ce78" class="kd ke hi bd kf kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la bi translated"><strong class="ak">改进空间</strong></h1><p id="5f3c" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">现在，我们已经成功地在我们的数据集上实现了一个EfficientNet-B1。但是结果并没有那么好。当然，我们可以关注很多方面来提高我们的成绩。以下是这些要点的列表(我可能会漏掉一些要点，但都是我自己想出来的):</p><ol class=""><li id="149d" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">图像增强:在我上面提供的例子中，我们可以看到类之间的差异并不明显。差异非常小，模型很有可能(很有可能)无法捕捉到这些差异。例如，特定的图像变换——调整图像的亮度、伽玛或色彩映射，可能有助于突出差异。另一种基于图像的解决方案可以是数据增强，使用SMOTE或一些高级神经架构，如GANs或VAEs。</li><li id="1b25" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">修改模型参数:模型中有多个可编辑的参数。首先是模型本身。EfficientNet有多种变体，更复杂的版本有更大的架构足迹，所以这一切都取决于你的GPU。第二，有像学习率、学习率衰减的伽马、模型的标准、使用的优化器、学习率衰减的特定方法等参数。这些参数在模型的成功中起着巨大的作用，我非常确定微调它们会改善我的结果。</li></ol></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><p id="53f8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以，我想在这里结束我的文章。这只是我未来工作的一个基线，我将分部分发布，解释我所做的改变。这就像一次问题陈述之旅，随着我们的前进，发现它的各个方面。请继续关注第二部分。感谢您的阅读！</p><p id="7f5b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">GitHub链接:<a class="ae jo" href="https://github.com/preeyonuj/Aptos-Blindess-Challenge" rel="noopener ugc nofollow" target="_blank">https://github.com/preeyonuj/Aptos-Blindess-Challenge</a></p><p id="652b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">领英:【www.linkedin.com/in/pb1807 T2】</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><p id="7eb8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是我提到的信息来源的链接:</p><ol class=""><li id="9f1b" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">卡格尔比赛:【https://www.kaggle.com/c/aptos2019-blindness-detection T4】</li><li id="0f42" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">糖尿病视网膜病变相关信息:<a class="ae jo" href="https://www.mayoclinic.org/diseases-conditions/diabetic-retinopathy/symptoms-causes/syc-20371611" rel="noopener ugc nofollow" target="_blank">https://www . mayo clinic . org/diseases-conditions/Diabetic-Retinopathy/symptoms-causes/syc-2037 16 11</a></li><li id="488c" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">EfficientNet PyTorch库:<a class="ae jo" href="https://pypi.org/project/efficientnet-pytorch/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/efficientnet-pytorch/</a></li><li id="4339" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">使用Pixlr在线编辑器编辑的图像</li></ol></div></div>    
</body>
</html>