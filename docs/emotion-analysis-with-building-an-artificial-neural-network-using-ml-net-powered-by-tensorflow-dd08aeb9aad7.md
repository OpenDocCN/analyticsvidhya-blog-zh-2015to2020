# åŸºäºå¼ é‡æµ ML.NET æ„å»ºäººå·¥ç¥ç»ç½‘ç»œçš„æƒ…æ„Ÿåˆ†æ

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/emotion-analysis-with-building-an-artificial-neural-network-using-ml-net-powered-by-tensorflow-dd08aeb9aad7?source=collection_archive---------4----------------------->

æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½æ˜¯ä¿¡æ¯æŠ€æœ¯çš„æ–°äº®ç‚¹ã€‚å¾®è½¯ä½œä¸ºå…¶æœ€å¤§çš„å¸‚åœºä»½é¢ä¹‹ä¸€ï¼Œç»ˆäºåœ¨ 2018 å¹´ 5 æœˆå®£å¸ƒæ´åŠ© ML.NETã€‚Net å¼€å‘äººå‘˜æ¥å®ç°ä»–ä»¬çš„ç›®æ ‡ã€‚ä½†æ˜¯ä¸ Pythonã€Javaã€LISP ç­‰å…¶ä»–æŠ€æœ¯ç›¸æ¯”ï¼Œå®ƒè¿˜æ˜¯ç›¸å½“æ–°çš„ã€‚å°±å¼€æºé¡¹ç›®ã€åº“æˆ–ç¬¬ä¸‰æ–¹å·¥å…·è€Œè¨€ï¼Œè¿˜æ²¡æœ‰è¶³å¤Ÿçš„èµ„æºã€‚è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ã€‚Net èµ¶ä¸Šå…¶ä»–å¤§çš„æŠ€æœ¯å…¬å¸æ¥å‘å±•å®ƒçš„ç¤¾åŒº

å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸å¿…ç­‰åˆ°è¿™ç§æƒ…å†µå‘ç”Ÿï¼Œæ„Ÿè°¢å¾®è½¯çš„å·¥ç¨‹å¸ˆï¼Œä»–ä»¬ä½¿ ML.NET è·å¾—äº†è‡ªé€‚åº”çš„å¼€å‘ä½“éªŒï¼Œå¹¶åœ¨ä¸ NimbusML ä¸€èµ·ä½¿ç”¨æ—¶æ”¯æŒ [Python](https://en.wikipedia.org/wiki/Python_(programming_language)) æ¨¡å‹ã€‚
æˆ‘ä»¬éƒ½åº”è¯¥æ„Ÿè°¢å¾®è½¯çš„æƒŠäººå·¥ä½œï¼

![](img/9ca4f23c9296275e5e6e4332f1c8351d.png)

æœ‰äº›äººæ›´å–œæ¬¢çœ‹è€Œä¸æ˜¯è¯»ï¼Œä¹Ÿåˆ¶ä½œä¸€ä¸ªè§†é¢‘æ¥æ¼”ç¤ºè¿™ç§ä¸œè¥¿åœ¨è¡ŒåŠ¨ä¸­å¾€å¾€æ˜¯æœ‰æ„ä¹‰çš„ï¼Œæ­£å› ä¸ºå¦‚æ­¤ï¼Œä¸‹é¢çš„è§†é¢‘çš„å­˜åœ¨ã€‚

åœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç°æœ‰çš„é¢„è®­ç»ƒ Tensorflow æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç”±å…·æœ‰æ•°åƒå¹…å›¾åƒçš„ç¥ç»ç½‘ç»œæ„å»ºï¼Œå¹¶é©»ç•™åœ¨è°·æ­Œçš„ä¸€ä¸ªæœåŠ¡å™¨ä¸­ï¼Œå¹¶åˆ©ç”¨[**æ·±åº¦å­¦ä¹ **](https://en.wikipedia.org/wiki/Deep_learning) æ¥æ„å»ºæˆ‘ä»¬è‡ªå·±çš„ç¥ç»ç½‘ç»œï¼Œä»¥æé«˜æˆ‘ä»¬çš„å‡†ç¡®æ€§å¹¶åŠ å¿«è®­ç»ƒè¿‡ç¨‹ã€‚æˆ‘å°†åˆ›å»ºä¸€ä¸ª. Net æ ¸å¿ƒæ§åˆ¶å°åº”ç”¨ç¨‹åºæ¥å®ç°è¿™ä¸€ç‚¹ï¼Œå½“æ–‡ç« ç»“æŸæ—¶ï¼Œæˆ‘ä»¬å°†æœ‰ä¸€ä¸ªè·¨å¹³å°çš„å¯æ‰§è¡Œåº”ç”¨ç¨‹åºã€‚

![](img/c2a254f10c6db95dc7aa58dcef6158cd.png)

ä¸Šå›¾å±•ç¤ºäº† ML.NET åº”ç”¨ç¨‹åºçš„æ‹“æ‰‘ç»“æ„

è®©æˆ‘è¯´ï¼Œè¿™ç¯‡æ–‡ç« å—åˆ°äº†å¾®è½¯å®˜æ–¹æ–‡æ¡£çš„å¼ºçƒˆå¯å‘ã€‚è¯´å¾—å¤Ÿå¤šäº†ï¼Œè®©æˆ‘ä»¬å¼€å§‹è¡ŒåŠ¨å§ã€‚

æˆ‘å·²ç»æ›´æ”¹äº†è¾“å…¥æ•°æ®é›†å¹¶åŒ…å«äº†å¸®åŠ©å™¨æ–¹æ³•ï¼Œ
æœ€åï¼Œä¸ºäº†å‡†ç¡®èµ·è§ï¼Œé€šè¿‡é‡æ–°æ ¼å¼åŒ–å’Œç°åº¦åŒ–æ¯ä¸ªå›¾åƒæ¥æ ‡å‡†åŒ–æ¨¡å‹ï¼Œä¸‹é¢æ˜¯ä¸€äº›ä¾‹å­ï¼›

![](img/fc1448066b8d2c3be7b75aa114266152.png)![](img/ad9557f304462f228c8a54bf1bd693b2.png)

è¿™ç§ç¼–è¾‘æ˜¯å¦‚æ­¤ç®€å•ï¼Œç”±äºã€‚Net æ ¸å¿ƒçš„å›¾åƒå¤„ç†åº“ã€‚ç»˜å›¾å‘½åç©ºé—´ï¼Œæˆ‘ä»¬æ‰€åšçš„åªæ˜¯é¦–å…ˆè°ƒæ•´å›¾åƒå¤§å°ä¸º 48x48ï¼Œç„¶åè½¬æ¢ä¸ºç°åº¦ã€‚ä¸‹é¢è¿™äº›ä»£ç ä¼˜é›…åœ°æ»¡è¶³äº†æˆ‘ä»¬çš„éœ€æ±‚ï¼›

```
public static Bitmap TranformToGrayscale(Bitmap original)
        {
            //create a blank bitmap the same size as original
            Bitmap newBitmap = new Bitmap(original.Width, original.Height);//get a graphics object from the new image
            using (Graphics g = Graphics.FromImage(newBitmap))
            {
                //create the grayscale ColorMatrix
                System.Drawing.Imaging.ColorMatrix colorMatrix = new System.Drawing.Imaging.ColorMatrix(
                   new float[][]
                   {
             new float[] {.3f, .3f, .3f, 0, 0},
             new float[] {.59f, .59f, .59f, 0, 0},
             new float[] {.11f, .11f, .11f, 0, 0},
             new float[] {0, 0, 0, 1, 0},
             new float[] {0, 0, 0, 0, 1}
                   });//create some image attributes
                using (ImageAttributes attributes = new ImageAttributes())
                {
                    //set the color matrix attribute
                    attributes.SetColorMatrix(colorMatrix);//draw the original image on the new image
                    //using the grayscale color matrix
                    g.DrawImage(original, new System.Drawing.Rectangle(0, 0, original.Width, original.Height),
                                0, 0, original.Width, original.Height, GraphicsUnit.Pixel, attributes);
                }
            }
            return newBitmap;
        }public static Bitmap ResizeImage(System.Drawing.Image image, int width, int height)
        {
            var destRect = new System.Drawing.Rectangle(0, 0, width, height);
            var destImage = new Bitmap(width, height);destImage.SetResolution(image.HorizontalResolution, image.VerticalResolution);using (var graphics = Graphics.FromImage(destImage))
            {
                graphics.CompositingMode = CompositingMode.SourceCopy;
                graphics.CompositingQuality = CompositingQuality.HighQuality;
                graphics.InterpolationMode = InterpolationMode.HighQualityBicubic;
                graphics.SmoothingMode = SmoothingMode.HighQuality;
                graphics.PixelOffsetMode = PixelOffsetMode.HighQuality;using (var wrapMode = new ImageAttributes())
                {
                    wrapMode.SetWrapMode(WrapMode.TileFlipXY);
                    graphics.DrawImage(image, destRect, 0, 0, image.Width, image.Height, GraphicsUnit.Pixel, wrapMode);
                }
            }return destImage;
        }To improve the accuracy of our model we standardize images as greyscaled and 48x48 length no matter the size of the original image
```

è¿™å¯ä»¥æ¶ˆé™¤æ•°æ®ä¸­çš„å™ªå£°ï¼ŒåŠ å¿«è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶æ›´å¿«åœ°æ‰§è¡Œé¢„æµ‹ã€‚

æˆ‘ä»¬å°†éµå¾ªä»¥ä¸‹æ­¥éª¤æ¥å®ç°å®ƒ:

# 1.å»ºç«‹æ¨¡å‹

æ„å»ºæ¨¡å‹åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤:

*   ä»åˆå§‹æ•°æ®è§†å›¾çš„æ–‡ä»¶å¤¹ä¸­åŠ è½½å›¾åƒè·¯å¾„å’Œç›¸å…³æ ‡ç­¾
*   æ ¹æ®ä½¿ç”¨çš„ TensorFlow é¢„è®­ç»ƒæ¨¡å‹(å¦‚ InceptionV3)çš„éœ€è¦è¿›è¡Œå˜æ¢æ—¶ï¼Œå°†å›¾åƒåŠ è½½åˆ°å†…å­˜ä¸­ã€‚(æ ¹æ®æ‰€ä½¿ç”¨çš„æ·±åº¦ç¥ç»ç½‘ç»œçš„è¦æ±‚ï¼Œè°ƒæ•´åƒç´ å€¼çš„å¤§å°å¹¶ä½¿å…¶æ­£å¸¸åŒ–)
*   å›¾åƒ*ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹çš„ç‰¹å¾åŒ–*
*   åŸºäº LbfgsMaximumEntropy çš„å›¾åƒåˆ†ç±»

ä¸æ˜¯:ä½ å¯ä»¥è®¿é—®é¢„å…ˆè®­ç»ƒå¥½çš„ Tensorflow æ¨¡å‹çš„æ•°æ®åº“[è¿™é‡Œ](https://www.tensorflow.org/resources/models-datasets)

åœ¨ç±»ç±»å‹ä¸­å®šä¹‰æ•°æ®çš„æ¨¡å¼ï¼Œå¹¶åœ¨ä½¿ç”¨ TextLoader åŠ è½½æ•°æ®æ—¶å¼•ç”¨è¯¥ç±»å‹ã€‚è¿™é‡Œçš„ç±»ç±»å‹æ˜¯ ImageNetDataã€‚

```
public class ImageData
    {
        [LoadColumn(0)]
        public string ImagePath; [LoadColumn(1)]
        public string Label;
    }
```

é€šè¿‡ LoadImagesFromDirectory()ä½¿ç”¨å®ç”¨æ–¹æ³•å°†æ‰€æœ‰è®­ç»ƒå’Œæµ‹è¯•å›¾åƒåˆ†åˆ«åŠ è½½åˆ°æ•°æ®è§†å›¾ä¸­:

```
IEnumerable<ImageData> allImages = LoadImagesFromDirectory(folder: imagesDownloadFolderPath, useFolderNameasLabel: true);IEnumerable<ImageData> testImages = LoadImagesFromDirectory(folder: testimagesDownloadFolderPath);
```

åœ¨å°†æ•°æ®é›†æ‹†åˆ†ä¸ºä¸¤ä¸ªæ•°æ®é›†(è®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†)ä¹‹å‰ï¼Œå¯¹å›¾åƒè¿›è¡Œæ··æ´—ï¼Œä»¥ä¾¿é€šè¿‡æ ‡æ³¨åˆ†ç±»æ›´å¥½åœ°å¹³è¡¡æ•°æ®é›†ã€‚

```
ConsoleHelper.ConsoleWriteHeader("Read model");
Console.WriteLine($"Model location: {inputTensorFlowModelFilePath}");
Console.WriteLine($"Training file: {dataLocation}");// 1\. Load images information (filenames and labels) in IDataView//Load the initial single full Image-Set
IDataView fullImagesDataset = mlContext.Data.LoadFromEnumerable(imageSet);
IDataView trainDataView = mlContext.Data.ShuffleRows(fullImagesDataset);
IDataView testDataView = mlContext.Data.LoadFromEnumerable(testSet);
```

ä»¥ä¸‹æ­¥éª¤å®šä¹‰äº†åŸ¹è®­ç®¡é“ã€‚é€šå¸¸ï¼Œåœ¨å¤„ç†æ·±åº¦ç¥ç»ç½‘ç»œæ—¶ï¼Œæ‚¨å¿…é¡»ä½¿å›¾åƒé€‚åº”ç½‘ç»œé¢„æœŸçš„æ ¼å¼ã€‚è¿™å°±æ˜¯å›¾åƒè¢«è°ƒæ•´å¤§å°ç„¶åå˜æ¢çš„åŸå› ã€‚

```
// 2\. Load images in-memory while applying image transformations 
// Input and output column names have to coincide with the input and output tensor names of the TensorFlow model
// You can check out those tensor names by opening the Tensorflow .pb model with a visual tool like Netron: [https://github.com/lutzroeder/netron](https://github.com/lutzroeder/netron)
// TF .pb model --> input node --> INPUTS --> input --> id: "input" 
// TF .pb model --> Softmax node --> INPUTS --> logits --> id: "softmax2_pre_activation" (Inceptionv1) or "InceptionV3/Predictions/Reshape" (Inception v3)var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: LabelAsKey, inputColumnName: "Label")
                .Append(mlContext.Transforms.LoadImages(outputColumnName: "image_object", imageFolder: imagesFolder, inputColumnName: nameof(DataModels.ImageData.ImagePath)))
                .Append(mlContext.Transforms.ResizeImages(outputColumnName: "image_object_resized", 
                                                            imageWidth: ImageSettingsForTFModel.imageWidth, imageHeight: ImageSettingsForTFModel.imageHeight, 
                                                            inputColumnName: "image_object"))
                .Append(mlContext.Transforms.ExtractPixels(outputColumnName:"input", inputColumnName:"image_object_resized", 
                                                            interleavePixelColors:ImageSettingsForTFModel.channelsLast, 
                                                            offsetImage:ImageSettingsForTFModel.mean, 
                                                            scaleImage:ImageSettingsForTFModel.scale))  //for Inception v3 needs scaleImage: set to 1/255f. Not needed for InceptionV1\. 
                .Append(mlContext.Model.LoadTensorFlowModel(inputTensorFlowModelFilePath).
                        ScoreTensorFlowModel(outputColumnNames: new[] { "InceptionV3/Predictions/Reshape" }, 
                                            inputColumnNames: new[] { "input" }, 
                                            addBatchDimensionInput: false));  // (For Inception v1 --> addBatchDimensionInput: true)  (For Inception v3 --> addBatchDimensionInput: false)
```

æœ€åï¼Œæ·»åŠ  ML.NET åˆ†çº§åŸ¹è®­å¸ˆ(LbfgsMaximumEntropy)ä»¥æœ€ç»ˆç¡®å®šåŸ¹è®­æ¸ é“:

```
// Set the training algorithm and convert back the key to the categorical values (original labels)                            
var trainer = mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(labelColumnName: LabelAsKey, featureColumnName: "InceptionV3/Predictions/Reshape");  //"softmax2_pre_activation" for Inception v1
var trainingPipeline = dataProcessPipeline.Append(trainer)
                                            .Append(mlContext.Transforms.Conversion.MapKeyToValue(PredictedLabelValue, "PredictedLabel"));
```

# 2.ç«è½¦æ¨¡å‹

ä¸ºäº†å¼€å§‹åŸ¹è®­ï¼Œåœ¨å·²å»ºç®¡é“ä¸Šæ‰§è¡Œ`Fit`:

```
ITransformer model = trainingPipeline.Fit(trainingDataView);
```

# 3.è¯„ä¼°æ¨¡å‹

è®­ç»ƒç»“æŸåï¼Œæˆ‘ä»¬ä½¿ç”¨è®­ç»ƒæ•°æ®å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚`Evaluate`å‡½æ•°éœ€è¦ä¸€ä¸ª`IDataView`ä½œä¸ºå‚æ•°ï¼Œå®ƒåŒ…å«ä½¿ç”¨æµ‹è¯•æ•°æ®é›†åˆ†å‰²çš„æ‰€æœ‰é¢„æµ‹ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†`Transform`åº”ç”¨äºæ¨¡å‹ï¼Œç„¶åå–`AsDynamic`å€¼ã€‚

```
// Make bulk predictions and calculate quality metrics
ConsoleWriteHeader("Create Predictions and Evaluate the model quality");
IDataView predictionsDataView = model.Transform(testDataView);

// Show the performance metrics for the multi-class classification            
var classificationContext = mlContext.MulticlassClassification;
var metrics = classificationContext.Evaluate(predictionsDataView, labelColumnName: LabelAsKey, predictedLabelColumnName: "PredictedLabel");
ConsoleHelper.PrintMultiClassClassificationMetrics(trainer.ToString(), metrics);
```

æœ€åï¼Œæˆ‘ä»¬ä¿å­˜æ¨¡å‹:

```
mlContext.Model.Save(model, predictionsDataView.Schema, outputMlNetModelFilePath);
```

## è¿è¡Œåº”ç”¨ç¨‹åºæ¥è®­ç»ƒæ¨¡å‹

ä¸ºäº†è®­ç»ƒæ‚¨çš„æ¨¡å‹ï¼Œæ‚¨åº”è¯¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œ:

1.  åœ¨ Visual Studio ä¸­å°†`ImageClassification.Train`è®¾ç½®ä¸ºå¯åŠ¨é¡¹ç›®
2.  åœ¨ Visual Studio ä¸­æŒ‰ F5ã€‚è®­ç»ƒè¿‡ç¨‹å°†å¼€å§‹ï¼Œå¹¶ä¼šèŠ±è´¹æˆ–å¤šæˆ–å°‘çš„æ—¶é—´ï¼Œè¿™å–å†³äºæ‚¨è®­ç»ƒçš„å›¾åƒæ•°é‡ã€‚
3.  è®­ç»ƒè¿‡ç¨‹å®Œæˆåï¼Œä¸ºäº†ä½¿ç”¨æ–°çš„è®­ç»ƒæ¨¡å‹æ›´æ–°æ¶ˆè´¹åº”ç”¨ç¨‹åºï¼Œæ‚¨å¿…é¡»å¤åˆ¶/ç²˜è´´ç”Ÿæˆçš„ ML.NET æ¨¡å‹æ–‡ä»¶(assets/inputs/image classifier . zip)å¹¶å°†å…¶ç²˜è´´åˆ°æ¶ˆè´¹åº”ç”¨ç¨‹åºé¡¹ç›®(assets/inputs/MLNETModel)ä¸­ï¼Œè¯¥é¡¹ç›®æ¨¡æ‹Ÿä»…è¿è¡Œæ¨¡å‹è¿›è¡Œé¢„æµ‹çš„æœ€ç»ˆç”¨æˆ·åº”ç”¨ç¨‹åºã€‚

# 4.æ¨¡å‹æ¶ˆè€—ä»£ç 

é¦–å…ˆï¼Œæ‚¨éœ€è¦åŠ è½½åœ¨æ¨¡å‹è®­ç»ƒæœŸé—´åˆ›å»ºçš„æ¨¡å‹

```
ITransformer loadedModel = mlContext.Model.Load(modelLocation,out var modelInputSchema);
```

ç„¶åï¼Œåˆ›å»ºä¸€ä¸ªé¢„æµ‹å™¨å¼•æ“ï¼Œå¹¶è¿›è¡Œç¤ºä¾‹é¢„æµ‹:

```
var predictionEngine = mlContext.Model.CreatePredictionEngine<ImageData, ImagePrediction>(loadedModel);IEnumerable<ImageData> imagesToPredict = LoadImagesFromDirectory(imagesFolder, true);//Predict the first image in the folder
//
ImageData imageToPredict = new ImageData
{
    ImagePath = imagesToPredict.First().ImagePath
};var prediction = predictionEngine.Predict(imageToPredict);Console.WriteLine("");
Console.WriteLine($"ImageFile : [{Path.GetFileName(imageToPredict.ImagePath)}], " +
                    $"Scores : [{string.Join(",", prediction.Score)}], " +
                    $"Predicted Label : {prediction.PredictedLabelValue}");
```

é¢„æµ‹å¼•æ“æ¥æ”¶ç±»å‹ä¸º`ImageData`çš„å¯¹è±¡ä½œä¸ºå‚æ•°(åŒ…å«ä¸¤ä¸ªå±æ€§:`ImagePath`å’Œ`Label`)ã€‚ç„¶åè¿”å›ä¸€ä¸ªç±»å‹ä¸º`ImagePrediction`çš„å¯¹è±¡ï¼Œå®ƒä¿å­˜äº†`PredictedLabel`å’Œ`Score` ( *æ¦‚ç‡*å€¼åœ¨ 0 å’Œ 1 ä¹‹é—´)å±æ€§ã€‚

è®©æˆ‘ä»¬è¿è¡Œåº”ç”¨ç¨‹åºå¹¶æ£€æŸ¥æˆ‘ä»¬çš„æ¨¡å‹æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œå¯¹äºè¿™æ¬¡æ‰§è¡Œï¼Œæˆ‘ä¸ä¼šé‡æ–°æ ¼å¼åŒ–æµ‹è¯•å›¾åƒï¼Œå°†å®ƒä»¬æŒ‰å…¶åŸå§‹å½¢çŠ¶æ¨é€åˆ°è®­ç»ƒç®¡é“ï¼Œä¹‹åæˆ‘å°†é‡æ–°å¼€å§‹æ‰§è¡Œã€‚

è¿™ä¸¤ç§ç»“æœéƒ½å‡ºç°åœ¨ä¸‹é¢çš„å›¾ç‰‡ä¸­ï¼›

![](img/478e659a8724bd8c14c522cfa6ad9879.png)

ç»“æœ:1 ä¸ªæ­£ç¡®ï¼Œ3 ä¸ªé”™è¯¯

æ­£å¦‚ä½ åœ¨ä¸Šé¢çœ‹åˆ°çš„ï¼Œè¿™å¹¶ä¸åƒé¢„æœŸçš„é‚£æ ·å¥½ï¼Œæˆ‘å’Œå®å®è¿˜å¥½ï¼Œä½†å¸•å…‹å…ˆç”Ÿåœ¨è¿™é‡Œæ„Ÿè§‰ä¸åˆ°å¹³é™(èœ˜è››ä¾ ç”µå½±ä¸­çš„åœºæ™¯ï¼Œå½“ä»–çš„çˆ¶äº²å‘ç”Ÿè½¦ç¥¸ï¼Œæ­»åœ¨ä»–é¢å‰ï¼Œæ˜¯çš„ï¼Œåº”è¯¥æ˜¯æ‚²ä¼¤çš„ï¼ğŸ¤¬)

æ›´ç³Ÿç³•çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ç½‘ç»œè®¤ä¸ºæ‹œç™»åœ¨è¿™é‡Œæ„Ÿåˆ°æ‚²ä¼¤â€¦æˆ‘è®¤ä¸ºè¿™ä¸åº”è¯¥æ˜¯ä½ èµ¢å¾—é€‰ä¸¾å¹¶æˆä¸ºç¾å›½æ€»ç»Ÿæ—¶çš„æ„Ÿå—ã€‚

> æ‰€ä»¥å¾ˆæ˜æ˜¾æˆ‘ä»¬çš„æ¨¡å‹æœ‰é—®é¢˜ï¼Œæˆ‘åœ¨äº’è”ç½‘ä¸Šæœç´¢äººå·¥ç¥ç»ç½‘ç»œçš„åŸç†å’Œå»ºç«‹è®­ç»ƒæ¨¡å‹çš„æœ€ä½³å®è·µï¼Œæœ€ç»ˆå¾—å‡ºäº†æ ‡å‡†åŒ–æ‰€æœ‰å›¾åƒçš„æƒ³æ³•ã€‚æˆ‘å·²ç»åœ¨ä¸Šé¢æåˆ°äº†å®ƒæ˜¯å¦‚ä½•åšåˆ°çš„ï¼Œåœ¨æ–‡ç« çš„æœ€åè¿˜æœ‰ä¸€ä¸ªé“¾æ¥å¯ä»¥ä¸‹è½½å®Œæ•´çš„æºä»£ç 

è®©æˆ‘ä»¬é‡æ–°å¯åŠ¨åº”ç”¨ç¨‹åºï¼Œè¿™ä¸€æ¬¡å›¾åƒå°†åœ¨é¢„æµ‹ä¹‹å‰ç»è¿‡è°ƒæ•´å¤§å°å’Œç°åº¦çš„å¤„ç†

![](img/569af45f3b60b2b700e6bb78f93f4b26.png)

ç»“æœ:3 ä¸ªæ­£ç¡®ï¼Œ1 ä¸ªé”™è¯¯

æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œ[å›¾åƒé™å™ª](https://www.ijsr.net/archive/v6i3/25031706.pdf)å¦‚ä½•æé«˜å‡†ç¡®æ€§å’Œé¢„æµ‹ä»¥åŠæ€§èƒ½(å®ƒçš„è¿è¡Œé€Ÿåº¦å‡ ä¹å¿«äº† 4 å€ï¼)çš„é‡è¦æ€§ã€‚

æˆ‘ä¸æƒ³å†çœ‹åˆ°è¿™ç¯‡æ–‡ç« äº†ï¼Œæˆ‘ä»¬æ­£å¤„åœ¨ä¸€ä¸ªç»“æŸçš„å¥½æ—¶æœºã€‚
æ‚¨å¯ä»¥ä¸‹è½½å®Œæ•´çš„[æºä»£ç ](https://github.com/y3n3rrr/EmotionAnalysisWithMLNET)å¹¶å°è¯•ä½¿ç”¨æ‚¨è‡ªå·±çš„å®šåˆ¶å›¾åƒï¼Œå®ƒå‡ ä¹å¯ä»¥å‘å¸ƒç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œä½†å¦‚æœæ‚¨å¸Œæœ›æ›´å‡†ç¡®åœ°è¿›è¡Œæ›´å¥½çš„é¢„æµ‹ï¼Œæˆ‘å¼ºçƒˆå»ºè®®æ‚¨ä½¿ç”¨è®­ç»ƒæœ‰ç´ çš„æ¨¡å‹

è¿™æ˜¯æˆ‘æ­£åœ¨æ€è€ƒçš„é—®é¢˜ï¼Œæˆ‘æƒ³ç”¨æˆ‘æœ€è¿‘æ‰¾åˆ°çš„è®­ç»ƒé›†å†™ä¸€ç¯‡æ–°æ–‡ç« ã€‚æ¥è‡ª Kaggle çš„è¿™ä¸ªæ ·æœ¬åŒ…å«æ•°ä»¥åƒè®¡çš„å›¾åƒï¼Œå¯ä»¥ç”¨æ¥è®­ç»ƒç¥ç»ç½‘ç»œã€‚è¿™ç¯‡ä¸é”™çš„[æ–‡ç« ](/@jsflo.dev/training-a-tensorflow-model-to-recognize-emotions-a20c3bcd6468)ä¹Ÿæ¶µç›–äº†å®ƒã€‚æ‚¨å¯ä»¥è·Ÿè¿›åŸºäº python çš„å·¥ä½œï¼Œæˆ–è€…ç­‰æˆ‘æ¥å¤„ç†ï¼Œåœ¨å†…éƒ¨é‡æ–°åˆ›å»ºå®ƒã€‚Net æ ¸å¿ƒçš„æ–¹æ³•ã€‚ç½‘

å½“ç„¶ï¼Œæˆ‘å¯¹ä½ çš„æƒ³æ³•æŒå¼€æ”¾æ€åº¦ï¼Œæˆ‘å¾ˆä¹æ„çŸ¥é“ä½ å¸Œæœ›æˆ‘ä¸ºä¸€ç¯‡æ–°æ–‡ç« é€‰æ‹©ä»€ä¹ˆä¸»é¢˜ï¼Œåªè¦å®ƒæ˜¯ä¸€ä¸ªæ¸¸ä¹åœºã€‚ç½‘ç»œæ ¸å¿ƒå’Œååº”âš›ï¸.ä½ å¯ä»¥åœ¨ä¸‹é¢çš„ç‰ˆå—å‘è¡¨è¯„è®ºï¼Œæˆ–è€…åœ¨ [LinkedIn](https://www.linkedin.com/in/mehmet-yener-yilmaz-833a07101/) æˆ– [Twitter](https://twitter.com/myeneryilmaz) ä¸Šå‘é€æ¶ˆæ¯

æœªå®Œå¾…ç»­â€¦

å›è§ï¼Œ
ç©†ç½•é»˜å¾·Â·è€¶çº³å°”Â·è€¶å°”é©¬å…¹