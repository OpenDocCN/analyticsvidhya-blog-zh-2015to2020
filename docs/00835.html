<html>
<head>
<title>Featurization of Text data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本数据的特征</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/featurization-of-text-data-bow-tf-idf-avgw2v-tfidf-weighted-w2v-7a6c62e8b097?source=collection_archive---------2-----------------------#2019-09-12">https://medium.com/analytics-vidhya/featurization-of-text-data-bow-tf-idf-avgw2v-tfidf-weighted-w2v-7a6c62e8b097?source=collection_archive---------2-----------------------#2019-09-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="7e7f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">BOW，TF-IDF，Word2Vec，TF-IDF加权Word2Vec</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/0d56fe0350865b40b60e1305202ca295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*82xn8MZ6dy113Q58.jpg"/></div></div></figure><h2 id="5073" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">1 —一袋单词</h2><p id="25fc" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp ju kq kr ks jy kt ku kv kc kw kx ky kz hb bi translated">它首先构建一个包含文本中所有单词的字典。它由文本中所有独特的单词组成。它将word表示为一个稀疏矩阵。</p><p id="d207" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">对于每个文档(行)，查找唯一的单词，其中每个单词是一个不同的维度。每个单元格由单词在相应行中出现的次数组成。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl lf"><img src="../Images/0575a25d2017a558788faa2857c9e745.png" data-original-src="https://miro.medium.com/v2/format:webp/1*zEtu8XiNKW3G8lYwq6Jnjw.png"/></div></figure><p id="b770" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated"><em class="lg"> d </em>将非常大，其中大部分单元格的值为零。这就是形成稀疏矩阵的原因。</p><p id="f238" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">如果两个向量非常相似，那么它们会非常接近。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lh"><img src="../Images/d1b822e15b1a6f71102e73c81f48a0a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/0*LqdgA7TeL54Avz-0.png"/></div></figure><p id="a10f" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">所以两个向量之间的长度是d=|(Term1-Term2)|范数等于d的平方根。</p><p id="61fb" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">代码:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es li"><img src="../Images/ac9881246466bdd020d4dca532dbbbc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*wMQ1VdPy52Y8IFm7svMpbw.png"/></div></figure><p id="4b50" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated"><strong class="kj hj">缺点:</strong></p><p id="6f19" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">BOW不考虑语义。《出埃及记》美味和可口有着相同的含义，但弓认为是分开的。</p><h2 id="57f3" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">二元、三元和多元</h2><p id="bb17" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp ju kq kr ks jy kt ku kv kc kw kx ky kz hb bi translated"><a class="ae lj" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . feature _ extraction . text . count vectorizer . html</a></p><p id="0b9c" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">在构建n元语法之前，应该避免删除像“not”这样的停用词。它将单词表示为密集向量。</p><p id="ff91" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated"><strong class="kj hj">ngram _ range</strong>:<em class="lg">tuple(min _ n，max_n) </em></p><p id="1ac4" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">要提取的不同n元文法的n值范围的下限和上限。使min_n &lt;= n &lt;= max_n will be used.</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lk"><img src="../Images/6516be663c195f42392bdc63eafcd1ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n1Ho1geaBa3Cb2iPfMVE5w.png"/></div></div></figure><h1 id="0a94" class="ll jk hi bd jl lm ln lo jp lp lq lr jt io ls ip jx ir lt is kb iu lu iv kf lv bi translated">TF-IDF (term frequency-inverse document frequency)</h1><p id="ce6a" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp ju kq kr ks jy kt ku kv kc kw kx ky kz hb bi translated">TF- the number of times the word <em class="lg"> t </em>出现在文档<em class="lg"> d </em>中的所有n值除以文档<em class="lg"> d </em>中的总字数。换句话说，就是在文档d中找到一个单词的概率。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/bb2fb7dd262de9028cdd022ca2ecb708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YRNgo9_aHlRWhMJm.png"/></div></div></figure><p id="bf44" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">如果一个单词出现在更多的文档中，则IDF减少。单元值是TF * IDF的乘积。文档中的生僻词更重要，如果某个词在文档/评论中出现频率较高，则更重要。</p><p id="0a98" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">代码:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lw"><img src="../Images/c822120d85cdec6823368a8d677fec7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xmfmo__VSsS4bUJY1oEdHA.png"/></div></div></figure><p id="af22" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">tf-idf矢量化的密集输出。<a class="ae lj" href="https://stackoverflow.com/questions/48429367/appending-2-dimensional-list-dense-output-of-tfidf-result-into-pandas-datafram" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/48429367/appending-2-dimensional-list-dense-output-of-tfi df-result-into-pandas-data fram</a></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/af1c1d806910d25f196c23e5a31d1220.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*T5LlZVI2SHZ1PZ3F.png"/></div></div></figure><p id="4579" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated"><strong class="kj hj">缺点::</strong></p><p id="59e8" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">仍然不理解单词的意思。</p><h1 id="f123" class="ll jk hi bd jl lm ln lo jp lp lq lr jt io ls ip jx ir lt is kb iu lu iv kf lv bi translated">word 2矢量</h1><p id="6dd3" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp ju kq kr ks jy kt ku kv kc kw kx ky kz hb bi translated">Word2vec基本上以这样的方式将单词放置在特征空间中，即它们的位置由其含义决定，即具有相似含义的单词被聚集在一起，并且两个单词之间的距离也具有相同的含义。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ly"><img src="../Images/bdd2fcee1a3085be2beaaf01814a67e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*zogogzOm7yTN9GGY437iBQ.png"/></div></figure><p id="7563" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated"><strong class="kj hj">余弦相似度</strong></p><p id="6885" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">让我们首先了解什么是余弦相似度，因为word2vec使用余弦相似度来找出最相似的单词。余弦相似性不仅可以判断两个向量之间的相似性，还可以检验向量的正交性。余弦相似度由公式表示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lz"><img src="../Images/6def7803232b60af9b6682672d198990.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/0*_dD1BUAJUHuLtNdF"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/8e687baafc8844af058cbf6c100398ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZuVKcxV741sfQ-ig.png"/></div></div></figure><p id="3ecc" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">如果角度接近于零，那么我们可以说向量彼此非常相似，如果θ为90度，那么我们可以说向量彼此正交(正交向量彼此不相关)，如果θ为180度，那么我们可以说两个向量彼此相反。</p><p id="57c3" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">#<a class="ae lj" href="http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XXpERSgza01" rel="noopener ugc nofollow" target="_blank">http://ka vita-gan esan . com/gensim-word 2 vec-tutorial-starter-code/# . xxpersgza 01</a></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mb"><img src="../Images/4fa91415c2bff08b2e5967d292600db8.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*cZZ8DyKwLHTVntR0s6PoBw.png"/></div></figure><p id="c180" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated"><strong class="kj hj"> <em class="lg">案例1:想训练自己的W2V </em> </strong></p><p id="c461" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">#<a class="ae lj" href="http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.W17SRFAzZPY" rel="noopener ugc nofollow" target="_blank">http://ka vita-gan esan . com/gensim-word 2 vec-tutorial-starter-code/# . w17 srfazzpy</a><br/>你可以对这个整个单元格进行注释，也可以根据需要更改这些变量。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mc"><img src="../Images/be949806d7a3cbd0eeb9f5741ef16580.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*ib6iq0jiI3DQxiGaQOwMww.png"/></div></figure><p id="2526" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated"><strong class="kj hj"> <em class="lg"> Case2::想在google news上训练Google w2v train</em></strong></p><p id="912d" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">#在这个项目中，我们使用google的预训练模型<br/> #它的3.3G文件，一旦你将它加载到你的内存中<br/> #它占用大约9Gb，所以请只在你有&gt; 12G的ram <br/>时才执行这个步骤#我们将提供一个pickle文件，它包含一个dict，<br/> #它包含我们所有的courpus单词作为键，model[word]作为值<br/> #要使用这个代码片段，请下载" GoogleNews-vectors-negative 300 . bin</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es md"><img src="../Images/8fc39523a2cf5fa156935426c0351af4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vpoeTowhG5mzRKVz12tT5g.png"/></div></div></figure><p id="ac1e" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">要检查单词出现的次数:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es me"><img src="../Images/9780f65114b8ca50f92f19f07cbb1d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*LzTwEcDdljC0ygp3vpouTg.png"/></div></figure><h2 id="fd0a" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">平均单词2矢量</h2><p id="96ba" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp ju kq kr ks jy kt ku kv kc kw kx ky kz hb bi translated">我们需要给出大型文本语料库，其中每个单词都有一个向量。它试图从原始文本中自动学习向量之间的关系。向量的维数越大，它的信息量就越大。</p><p id="d6ad" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">属性:</p><ol class=""><li id="fd6e" class="mf mg hi kj b kk la kn lb ju mh jy mi kc mj kz mk ml mm mn bi translated">如果字w1和w2相似，则向量v1和v2会更接近。</li><li id="0652" class="mf mg hi kj b kk mo kn mp ju mq jy mr kc ms kz mk ml mm mn bi translated">自动学习单词/矢量之间的关系。</li></ol><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mt"><img src="../Images/f59a3b5044c6c457b1f25dd2ef8e3efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/0*FxX1Saf81DAjduXr.png"/></div></figure><p id="1c0f" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">我们正在观察男女关系图，我们观察到男人和女人之间的距离与国王(男人)和王后(女人)之间的距离相同，不仅性别不同，而且如果我们观察同性，我们观察到王后和女人之间的距离与国王和男人之间的距离相同(国王和男人，王后和女人代表同性比较，因此它们必须是相等的距离)</p><p id="b19e" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated"><strong class="kj hj">如何把每个文档转换成矢量？</strong></p><p id="12e9" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">假设在一个文档(行)中有w1，w2，…wn单词。以便转换成矢量。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mu"><img src="../Images/75748c08e7bc95387a7cd2ff09a8dc65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/0*MA9bjMQf9XVhiXQl"/></div></figure><p id="821f" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">每个单词都有一个向量，我们将平均word2vec转换为除以文档中的单词数。</p><p id="59dc" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">代码:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/9fe076c7ab717a0450233d110f731a1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*waE4nyL2XAXWdjubMVzv1g.png"/></div></figure><h1 id="364e" class="ll jk hi bd jl lm ln lo jp lp lq lr jt io ls ip jx ir lt is kb iu lu iv kf lv bi translated">TFIDF加权Word2Vec</h1><p id="1195" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp ju kq kr ks jy kt ku kv kc kw kx ky kz hb bi translated">在这个方法中，我们首先计算每个单词的tfidf值。然后按照与上一节相同的方法，将tfidf值乘以相应的字，然后将总和除以tfidf值总和。</p><p id="070b" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">代码:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mw"><img src="../Images/593135e699ebd46da32f8187e2e38a10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*U0UbRbATxMWXMsVk6mvCYw.png"/></div></figure><p id="6167" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated"># TF-IDF加权Word2Vec</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mx"><img src="../Images/9e5e1551b2551f2414efdcb17c0b2df5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IpZbXD7aSXTtEmqlEihLvg.png"/></div></figure><p id="60d5" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi">=======================================</p><p id="ef07" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi translated">在给定链接的<a class="ae lj" href="https://github.com/ranasingh-gkp/Applied_AI_O/blob/master/Assignments_AFR_2018/Amazon_Fine_Food_Reviews_Analysis.ipynb" rel="noopener ugc nofollow" target="_blank">Amazon _ Fine _ Food _ Reviews _ analysis . ipynb</a>笔记本中找到代码。<a class="ae lj" href="https://github.com/ranasingh-gkp/Applied_AI_O/tree/master/Assignments_AFR_2018" rel="noopener ugc nofollow" target="_blank">https://github . com/Rana Singh-gkp/Applied _ AI _ O/tree/master/Assignments _ AFR _ 2018</a></p><p id="4431" class="pw-post-body-paragraph kh ki hi kj b kk la ij km kn lb im kp ju lc kr ks jy ld ku kv kc le kx ky kz hb bi">=====================================</p><h2 id="9311" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">参考:</h2><ol class=""><li id="8c23" class="mf mg hi kj b kk kl kn ko ju my jy mz kc na kz mk ml mm mn bi translated">谷歌图片</li><li id="0dd7" class="mf mg hi kj b kk mo kn mp ju mq jy mr kc ms kz mk ml mm mn bi translated">应用人工智能</li><li id="e04d" class="mf mg hi kj b kk mo kn mp ju mq jy mr kc ms kz mk ml mm mn bi translated">Kaggle.com/amazon食品评论</li></ol></div></div>    
</body>
</html>