<html>
<head>
<title>NSFW Classifier to Curb out Censored Content.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NSFW分类器遏制审查内容。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/nsfw-classifier-to-curb-out-censored-content-d8e88dac165c?source=collection_archive---------5-----------------------#2019-10-20">https://medium.com/analytics-vidhya/nsfw-classifier-to-curb-out-censored-content-d8e88dac165c?source=collection_archive---------5-----------------------#2019-10-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ef91184d077ff901ef9b2f686f2a908b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1rMWZQEXWsTR-bGY"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://unsplash.com/@mr_williams_photography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">迈卡·威廉姆斯</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="75d4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">为了让网络对儿童更安全，许多社交媒体，如Tumblr、脸书、Instagram，都在限制NSFW内容，打造一个更安全的社区。</strong></p><p id="97cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最近，印度政府禁止避孕套广告，因为它们对儿童来说是下流的。于是我产生了一个疑问，这些广告真的不雅吗？让我们利用深度学习的力量找到答案。所以让我们通过使用<strong class="ix hj"> NSFW分类器来找出广告的本质。</strong></p><h1 id="450e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">建立模型的步骤:</strong></h1><ol class=""><li id="749b" class="kr ks hi ix b iy kt jc ku jg kv jk kw jo kx js ky kz la lb bi translated">检索数据</li><li id="ad14" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">预处理数据</li><li id="34b2" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">训练深度学习模型</li><li id="c08e" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">使用OpenCV测试广告</li><li id="70db" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">改进模型以发现图像中的细节</li></ol><h1 id="88cd" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">1.获取数据:</h1><p id="77a6" class="pw-post-body-paragraph iv iw hi ix b iy kt ja jb jc ku je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">获取数据是最重要的一步。但是30%的互联网内容是色情的，所以我们有足够的数据。我们在reddit和9gag上也有很多不安全的内容。所以我们只需要提取图像来训练我们的模型。我在Github上发现了Alex Kim制作的这个很棒的回购。我用它下载了三种图像数据:色情、中性和性感。</p><h1 id="ac98" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">2.预处理数据:</h1><p id="ef01" class="pw-post-body-paragraph iv iw hi ix b iy kt ja jb jc ku je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">由于我们从脚本中下载的数据将被分类到3个不同的文件夹中，它们有各自的图像，所以我们不需要分别标记它们。我们将使用Keras ImageDataGenerator的强大功能来生成更多的数据。稍后我们可以使用flowfromdirectory()函数来处理训练。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="0962" class="lt ju hi lp b fi lu lv l lw lx"># File : NSFW.ipynb<br/>train_data_generation <strong class="lp hj">= </strong>ImageDataGenerator(rescale<strong class="lp hj">=</strong>1.<strong class="lp hj">/</strong>255, rotation_range<strong class="lp hj">=</strong>30, width_shift_range<strong class="lp hj">=</strong>0.2, height_shift_range<strong class="lp hj">=</strong>0.2, shear_range<strong class="lp hj">=</strong>0.2, zoom_range<strong class="lp hj">=</strong>0.2, channel_shift_range<strong class="lp hj">=</strong>20, horizontal_flip<strong class="lp hj">=True</strong>)</span></pre><h1 id="cd20" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">3.训练深度学习模型:</h1><p id="b5ea" class="pw-post-body-paragraph iv iw hi ix b iy kt ja jb jc ku je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">我们将在Keras中使用迁移学习，并为此使用MobileNetV2。因为它有很少的参数，非常适合应用程序。然后我在最后一层尝试了不同的架构，我在密集层使用了256个单位和128个单位，但是他们开始过度适应。然后，最后我想出了一个32个单位的单一密集层，批量标准化，辍学，并获得了93.5%的测试数据的准确性。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="5e81" class="lt ju hi lp b fi lu lv l lw lx"># File : NSFW.ipynb<br/>conv_m <strong class="lp hj">= </strong>MobileNetV2(weights<strong class="lp hj">=</strong>'imagenet', include_top<strong class="lp hj">=False</strong>, input_shape<strong class="lp hj">=</strong>(size, size, 3)) <br/>conv_m.trainable <strong class="lp hj">= False<br/></strong>model.add(conv_m) model.add(AveragePooling2D(pool_size<strong class="lp hj">=</strong>(7, 7))) model.add(Flatten())<br/>model.add(Dense(32, activation <strong class="lp hj">= </strong>'relu')) model.add(BatchNormalization()) model.add(Dropout(0.5))<br/>model.add(Dense(3, activation<strong class="lp hj">=</strong>'softmax'))</span></pre><p id="9755" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我使用了ModelCheckpoint和ReduceLROnPlateau回调，然后使用了带有动量的SGD分类器。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="65fa" class="lt ju hi lp b fi lu lv l lw lx">model.compile( loss<strong class="lp hj">=</strong>'categorical_crossentropy', optimizer<strong class="lp hj">=</strong>SGD(lr <strong class="lp hj">= </strong>0.1, momentum <strong class="lp hj">= </strong>0.9), metrics<strong class="lp hj">=</strong>['accuracy'])</span></pre><p id="2fcf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我以10的步长对它进行了100次训练，因为我没有任何GPU，所以我花了大约7-8个小时来训练25GB大小的模型。我在GCP上用60 GB内存运行它。你可以从我的Github获得训练过的模型，见文章末尾。</p><p id="b7be" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">我们模型的输出:</strong></p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="8ef2" class="lt ju hi lp b fi lu lv l lw lx">from PIL import Image<br/>import numpy as np<br/>from skimage import transform<br/>def load(filename):<br/>    np_image = Image.open(filename)<br/>    np_image = np.array(np_image).astype('float32')/255<br/>    np_image = transform.resize(np_image, (224, 224, 3))<br/>    np_image = np.expand_dims(np_image, axis=0)<br/>    img=mpimg.imread(filename)<br/>    plt.imshow(img)<br/>    return np_image</span><span id="c3bf" class="lt ju hi lp b fi ly lv l lw lx">image = load("selena.jpg")<br/>ans = model.predict(image)<br/>maping = {0 : "Neutral", 1 : "Porn", 2 : "Sexy"}<br/>new_ans = np.argmax(ans[0])</span><span id="0a12" class="lt ju hi lp b fi ly lv l lw lx">print(maping[new_ans], np.round(ans,2))<br/>print("With {} probability".format(ans[0][new_ans]))</span></pre><p id="a6ad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输入:</p><figure class="lk ll lm ln fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/c638c512cb93e77ce84af4d8326c5eca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VS1SuN9aRey0qOqerAJVNA.jpeg"/></div></div></figure><p id="cf6f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:<br/>性感[[0.01 0。0.99]] <br/>以0.98的概率</p><p id="df11" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">在iPhone上部署模型。</strong></p><p id="f12c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，我们需要iOS兼容形式的模型。因此，我们将使用python库coremltools。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="4572" class="lt ju hi lp b fi lu lv l lw lx">import coremltools<br/>model.author <strong class="lp hj">= </strong>"Lakshay Chhabra"<br/>model.short_description <strong class="lp hj">= </strong>"NSFW Image Classifier"<br/>output_labels <strong class="lp hj">= </strong>['Neutral', 'Porn', 'Sexy']</span><span id="9a13" class="lt ju hi lp b fi ly lv l lw lx">ios = coremltools.converters.keras.convert(model, input_names=['image'], output_names = ['output'],                       class_labels = output_labels, image_input_names = 'image', image_scale=1/255.0)</span><span id="953b" class="lt ju hi lp b fi ly lv l lw lx">ios.save('NSFW.mlmodel')</span></pre><p id="7cec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的模型保存下来了，让我们将它加载到swift应用程序中。<br/> <strong class="ix hj">第一步:<br/> </strong>设计app的前端，我们为它使用了故事板。我们选择了带有模糊效果的图像视图，因为图像将是NSFW，所以我们将它们隐藏在模糊层下。</p><p id="e41e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第二步:<br/> </strong>我们根据自己的需要调整了图像的大小。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="dff6" class="lt ju hi lp b fi lu lv l lw lx">func resizeImage(image: UIImage) -&gt; UIImage {                        var newSize: CGSize <br/>newSize = CGSize(width: 224, height: 224)<br/>let rect = CGRect(x: 0, y: 0, width: 224, height: 224)                UIGraphicsBeginImageContextWithOptions(newSize, false, 1.0)     image.draw(in: rect)        <br/>let newImage = UIGraphicsGetImageFromCurrentImageContext()        UIGraphicsEndImageContext()               <br/>return newImage!   <br/> }</span></pre><p id="a62d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第三步:<br/> </strong>所以现在我们将使用我们训练好的模型来预测结果，让我们看看来自<a class="ae iu" href="https://github.com/lakshaychhabra/NSFW-ios-ML/blob/master/NSFW%20Detect/ViewController.swift" rel="noopener ugc nofollow" target="_blank">文件</a>的一小段代码。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="66f1" class="lt ju hi lp b fi lu lv l lw lx">let request = VNCoreMLRequest(model: model) { (request, error) in            print(request.results!)<br/>guard let classification = request.results?.first as? VNClassificationObservation<br/>else{ <br/>fatalError("cant find the image")<br/>}<br/>DispatchQueue.main.async {<br/>let confidenceRate = (classification.confidence) * 100                self.output_label.text = "\(confidenceRate)% it's \(String(describing: classification.identifier))"<br/>self.k = self.dict[classification.identifier]!                if(self.k == 0){<br/>self.warning.text = "Safe Image"<br/>}<br/>else if(self.k == 1){<br/>self.warning.text = "NSFW Image"<br/>}else{ <br/>self.warning.text = "Not For Kids Image"<br/>}                           <br/>}</span></pre><p id="9c2e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">让我们看看输出:</strong></p><figure class="lk ll lm ln fd ij"><div class="bz dy l di"><div class="ma mb l"/></div></figure><h1 id="33b4" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">4.使用OpenCV测试广告:</h1><p id="348b" class="pw-post-body-paragraph iv iw hi ix b iy kt ja jb jc ku je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">对于测试视频来说，openCV是一个很棒的包。视频只是图像序列，所以我们可以对每个图像进行分类，如果任何图像不安全，我们可以将视频列为不安全。我们将使用openCV加载视频，不要忘记这一步，因为它非常重要。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="34e8" class="lt ju hi lp b fi lu lv l lw lx"># File : NSFW Video Detector<br/># We are dividing image by 255.0 as keeping image pixels in range of # 0-1 as it is easier to train. As we used 0-1 range in training so # we need our input as same as we provided while training #classifier.</span><span id="8068" class="lt ju hi lp b fi ly lv l lw lx">vs = cv2.VideoCapture(input_vid)<br/>writer = None<br/>(W, H) = (None, None)<br/> <br/># loop over frames from the video file stream<br/>while True:<br/>    # read the next frame from the file<br/>    (grabbed, frame) = vs.read()<br/> <br/>    # if the frame was not grabbed, then we have reached the end<br/>    # of the stream<br/>    if not grabbed:<br/>        break<br/> <br/>    # if the frame dimensions are empty, grab them<br/>    if W is None or H is None:<br/>        (H, W) = frame.shape[:2]<br/>    <br/>    output = frame.copy()<br/>    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)<br/>    frame = frame/255.0<br/>    frame = cv2.resize(frame, (224, 224)).astype("float32")<br/>    <br/>#     frame -= mean<br/>    <br/>    # make predictions on the frame and then update the predictions<br/>    # queue<br/>    preds = model.predict(np.expand_dims(frame, axis=0))[0]<br/>    print(preds)<br/>    Q.append(preds)</span><span id="7694" class="lt ju hi lp b fi ly lv l lw lx"># perform prediction averaging over the current history of<br/>    # previous predictions</span><span id="b3b9" class="lt ju hi lp b fi ly lv l lw lx">results = np.array(Q).mean(axis=0)<br/>    i = np.argmax(preds)<br/>    label = labels[i]<br/>    # draw the activity on the output frame<br/>    text = "activity: {}:".format(label)<br/>    cv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5)</span><span id="03a3" class="lt ju hi lp b fi ly lv l lw lx"># check if the video writer is None<br/>    if writer is None:<br/>        # initialize our video writer<br/>        fourcc = cv2.VideoWriter_fourcc(*"MJPG")<br/>        writer = cv2.VideoWriter(output_vid, fourcc, 30, (W, H), True)</span><span id="fa7b" class="lt ju hi lp b fi ly lv l lw lx"># write the output frame to disk<br/>    writer.write(output)</span><span id="e56b" class="lt ju hi lp b fi ly lv l lw lx"># show the output image<br/>    cv2.imshow("Output", output)<br/>    key = cv2.waitKey(1) &amp; 0xFF</span><span id="0d24" class="lt ju hi lp b fi ly lv l lw lx"># if the `q` key was pressed, break from the loop<br/>    if key == ord("q"):<br/>        break<br/>        <br/># release the file pointers<br/>print("[INFO] cleaning up...")<br/># writer.release()<br/>vs.release()</span></pre><p id="9504" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当运行避孕套广告时，上述代码的输出是:</p><figure class="lk ll lm ln fd ij"><div class="bz dy l di"><div class="mc mb l"/></div></figure><p id="b6f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一些场景被列为性感和色情，所以我想政府是对的😜。</p><h1 id="e8eb" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">5.改进模型以发现图像中的细节:</h1><p id="282c" class="pw-post-body-paragraph iv iw hi ix b iy kt ja jb jc ku je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">如果我们要分类的图像很大，而图像中只有很小一部分是NSFW内容，该怎么办？为了解决这个问题，我使用了滑动窗口技术来遍历图像中的小帧，并逐行对它们进行分类。当我把这张图片作为一个整体输入分类器时，它把它识别为色情图片。但是可能存在NSFW含量非常少情况。所以我们来试试吧。</p><p id="cdc3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">PS。我在处理图像后输入了审查，所以对读者来说是安全的。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="0f34" class="lt ju hi lp b fi lu lv l lw lx">def check(unsave = 0):<br/>    image = cv2.imread("final.png")<br/>    (winW, winH) = (224, 224)<br/>    maping = {0 : "Neutral", 1 : "Porn", 2 : "Sexy"}<br/>    writer = None<br/>    for resized in pyramid(image, scale=5):<br/>        # loop over the sliding window for each layer of the pyramid<br/>        for (x, y, window) in sliding_window(resized, stepSize=48, windowSize=(winW, winH)):<br/>            # if the window does not meet our desired window size, ignore it</span><span id="ca90" class="lt ju hi lp b fi ly lv l lw lx">if window.shape[0] != winH or window.shape[1] != winW:<br/>                continue</span><span id="5c42" class="lt ju hi lp b fi ly lv l lw lx"># THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A<br/>            # MACHINE LEARNING CLASSIFIER TO CLASSIFY THE CONTENTS OF THE<br/>            # WINDOW<br/>            output = resized.copy()<br/>            frame = cv2.cvtColor(window, cv2.COLOR_BGR2RGB)<br/>            frame = frame/255.0<br/>            preds = model.predict(np.expand_dims(frame, axis=0))[0]<br/>            i = np.argmax(preds)<br/>            label = maping[i]<br/>            print(preds, label)<br/>            <br/>            if unsave:<br/>                if i == 1:<br/>                    return "Porn Found"<br/>                <br/>            if not unsave:<br/>                clone = resized.copy()<br/>                image = cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)<br/>                cv2.putText(image, label, (x, y+50), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0, 255, 0), 5)</span><span id="4515" class="lt ju hi lp b fi ly lv l lw lx">cv2.imshow("Window", clone)<br/>                cv2.waitKey(1)<br/>                time.sleep(0.09)</span><span id="2437" class="lt ju hi lp b fi ly lv l lw lx">if writer is None:<br/>                # initialize our video writer<br/>                    fourcc = cv2.VideoWriter_fourcc(*"MJPG")<br/>                    writer = cv2.VideoWriter("1.avi", fourcc, 8, (1080, 720), True)</span><span id="167c" class="lt ju hi lp b fi ly lv l lw lx"># write the output frame to disk<br/>                writer.write(clone)<br/>    return "Save to View"</span><span id="216e" class="lt ju hi lp b fi ly lv l lw lx"># Frame by Frame ipynb<br/># Just added a very small change</span><span id="37f0" class="lt ju hi lp b fi ly lv l lw lx"><strong class="lp hj">def </strong>isUnsave(): <br/>    ans <strong class="lp hj">= </strong>check(1)<br/>    print(ans)<br/># This check function is similar to what we made during Video <br/># Detection but sliding window concept is added. </span></pre><figure class="lk ll lm ln fd ij"><div class="bz dy l di"><div class="md mb l"/></div></figure><h1 id="e374" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">未来工作:</h1><ol class=""><li id="b66c" class="kr ks hi ix b iy kt jc ku jg kv jk kw jo kx js ky kz la lb bi translated">该分类器未能识别男性生殖器，因为它没有在男性生殖器上进行训练。因此，从未来的角度来看，我们可以在更多的数据上训练我们的模型。</li><li id="d271" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">这个分类器无法识别漫画、动漫和非常。因此，我们可以在reddit上废弃更多数据，并进一步训练它。</li></ol><h1 id="0aeb" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">总结:</h1><p id="90f9" class="pw-post-body-paragraph iv iw hi ix b iy kt ja jb jc ku je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">构建这个模型是一种很棒的体验，在各种图像上测试它更有趣。该模型在日常生活图像上效果很好，精确度可以进一步提高。对于失败案例，我们可以在动漫和更多色情资料上训练模型。</p><h1 id="42a1" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">资源:</h1><ol class=""><li id="e3ac" class="kr ks hi ix b iy kt jc ku jg kv jk kw jo kx js ky kz la lb bi translated">我的NSFW分类器的Github库:<a class="ae iu" href="https://github.com/lakshaychhabra/NSFW-Detection-DL" rel="noopener ugc nofollow" target="_blank">https://github.com/lakshaychhabra/NSFW-Detection-DL</a></li><li id="d2e7" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">iOS应用的Github库:<a class="ae iu" href="https://github.com/lakshaychhabra/NSFW-ios-ML" rel="noopener ugc nofollow" target="_blank">https://github.com/lakshaychhabra/NSFW-ios-ML</a></li><li id="f4f7" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">我的作品集:<a class="ae iu" href="https://lakshaychhabra.github.io" rel="noopener ugc nofollow" target="_blank">lakshaychabra . github . io</a></li></ol><h1 id="3c60" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">参考资料:</h1><p id="c479" class="pw-post-body-paragraph iv iw hi ix b iy kt ja jb jc ku je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">特别感谢数据科学社区在网络上提供的精彩内容。</p><ol class=""><li id="6b64" class="kr ks hi ix b iy iz jc jd jg me jk mf jo mg js ky kz la lb bi translated">数据集:<a class="ae iu" href="https://github.com/alex000kim/nsfw_data_scraper" rel="noopener ugc nofollow" target="_blank">https://github.com/alex000kim/nsfw_data_scraper</a></li><li id="f7fc" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">博客参考:<a class="ae iu" href="https://www.freecodecamp.org/news/how-to-set-up-nsfw-content-detection-with-machine-learning-229a9725829c/" rel="noopener ugc nofollow" target="_blank">https://www . freecodecamp . org/news/how-to-set-up-nsfw-content-detection-with-machine-learning-229 a 9725829 c/</a></li><li id="9e6a" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">OpenCV参考:<a class="ae iu" href="https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/2019/07/15/video-classification-with-keras-and-deep-learning/</a>，<a class="ae iu" href="https://www.pyimagesearch.com/2015/03/23/sliding-windows-for-object-detection-with-python-and-opencv/" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/2015/03/23/sliding-windows-for-object-detection-with-python-and-OpenCV/</a></li><li id="703e" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">关于Ban的新闻:<a class="ae iu" href="https://www.thehindu.com/news/national/govt-bans-condom-ads-from-6-am-to-10-pm-because-they-are-indecent/article21461765.ece" rel="noopener ugc nofollow" target="_blank">https://www . the Hindu . com/news/national/govt-bans-避孕套-广告-从早上6点到晚上10点-因为他们是不雅的/article21461765.ece </a></li></ol></div></div>    
</body>
</html>