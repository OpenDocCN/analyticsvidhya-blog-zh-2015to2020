<html>
<head>
<title>Generating quirky things with Recurrent Neural Nets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用递归神经网络生成奇怪的东西</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/generating-quirky-things-with-recurrent-neural-nets-4c0c8749cdf0?source=collection_archive---------25-----------------------#2020-06-16">https://medium.com/analytics-vidhya/generating-quirky-things-with-recurrent-neural-nets-4c0c8749cdf0?source=collection_archive---------25-----------------------#2020-06-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5e05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度学习具有独特的能力，在应用研究领域有很多空间可以探索。一种用于理解时序数据中的说谎结构和语义的灵活类型的神经网络被称为递归神经网络。它所具有的显著特征包括一个反馈回路，该回路包含来自前一层的输出，用作下一层的输入，从而有助于传播顺序信息。递归神经网络(RNNs)在理解各种文本数据方面是通用的，并且已经被证明可以从时间序列中学习，这在以前的应用研究中是例外的。为了一个有趣的周末实验，我尝试从训练过的RNN中生成数据，在本文中，我将讨论RNN和我学到的东西。</p><h1 id="afcd" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">为什么是递归神经网络？</h1><p id="1a61" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">递归神经网络是为了理解顺序或时间序列数据而专门构建的神经网络。为了理解给网络的输入数据，神经元之间有信息流。rnn在理解文本数据、语音类信息、金融建模和工业物联网方面显示出无与伦比的成果。</p><p id="de4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RNNs的一个主要缺点是不能考虑前一段时间的信息。这很重要，因为在序列数据中，模式和关系是长期的，而不是短期的。这个缺点被称为消失梯度问题。为了克服这个缺点，构建了RNNs的增强版本，称为<strong class="ih hj">长短期记忆(LSTM)网络</strong>。LSTMs在神经元结构内部有额外的门，以合并最近的神经元输出，并在内存中携带旧的神经元输出。因此，我们将在本文中使用LSTMs来执行我们的实验。</p><h1 id="fa84" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">实验</h1><p id="3e01" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">1.如前所述，rnn在从文本数据中学习方面非常出色。对于我们的第一种实验，莎士比亚的作品[1]用于生成类似的文本。40个字符的句子用于预测下一个字符，并依次考虑生成的输出。输入和输出如下所示。该模型很好地学习了十四行诗的结构。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/b82d9e24cdaa41a1bbae177ca5331da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PjLNohkOweydx3KVKO1GHA.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">使用LSTM的莎士比亚文本生成的输出</figcaption></figure><p id="6b57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.从文本生成中获得灵感，我们尝试使用LSTM模型产生不寻常的东西，并分析计算机程序如何学习。我们首先尝试让神经网络学习如何用Python编码。为此，使用了来自python语言官方Github的Python文件。大约有5000行Python代码，一个简单浅显的LSTM模型被训练学习。<br/>下面展示的是一张GIF图，展示了代码打字速度比人快得多，但却没有什么意义。LSTM模型还很好地学习了python语言的语义，以及一些常见的东西，如def、class和self。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kw"><img src="../Images/fe4f55c2d8a70ea694cdc6988c04be84.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*gGXgWfAK2gD-yMoDaIpMvQ.gif"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">实验中生成的Python代码一瞥</figcaption></figure><p id="c160" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成的代码片段如下所示。</p><pre class="kh ki kj kk fd kx ky kz la aw lb bi"><span id="a7f4" class="lc je hi ky b fi ld le l lf lg">import os<br/>import sys<br/>import time<br/>def ese_type_rith(self, pasametern): # a d e gefar()<br/>        parg ivtraneedersoad<br/>    xovarimstifon_types_vernore:<br/>        def ___names___one'</span><span id="bd61" class="lc je hi ky b fi lh le l lf lg">def tet__bseted__paktanse_= belaces:<br/>        areis = notels<br/>            # th  suiplebate as nvters anc angedueprod:<br/>        alst<br/>    def __are_ty_eser(self) -&gt; noter<br/>    n'tedefattrod orgeederestrer(strfla[tt]):<br/>        tinestainl(_type:<br/>        id = 1wistrrpine[[st, ].gt, "typit .asrusectraes senfor()<br/>    def __ont': 'tiot_replt', 'self._typenasem_, flocamnt', foowdifins). 'conte  ithod in gonericgs.ancamstuplereatt</span><span id="7c9f" class="lc je hi ky b fi lh le l lf lg">class int(self):<br/>        def __ent__(self, als())):<br/>            "                'tert inttrawastdy<br/>    def __ =b[th, mamb, %ry)<br/>        self.assertisinnttacha(), typing.typing.mathing, typing.ppoytecthon)<br/>    # freprpowt nverection a " n generic[tape.duperfreprar typencoresu):<br/>    def uler(pamp'tacters': [typing.lmaldb', [antiant])<br/>        self.asserttisisstance(unio)<br/>        esvera: proo'for):<br/>        {fargg_valo('or, 'gonerac'), 'lowalset, l[str]], vullecit]])<br/>    def costen(self) -</span><span id="b1f5" class="lc je hi ky b fi lh le l lf lg">with self.assertraises(tyteerror):<br/>            idstruples(ppy'nynetupingalenefrodt': 'gonora.terd', ' cont]<br/>    def __sent_typevar(on_type_nore, mpse):<br/>    ")<br/>    __sult_fool_gen_taclo= teupleyes(alkareiand), pashon ', ()<br/>        if iss.abyergetror("<br/>    walss<br/>        rabe_ganametrest_ches _isnclash(self):<br/>        self.asserttsinsiclast(dobj, typing.dumppr(typy,<br/>if nt_ainamater s(be)<br/>        # o#vars calssartiand, variont": ...__quar(meterval_n', *args))r, pvarisns<br/>   ("__nated__farsungee_varg__'and setpr = inmot ay inerant = ontolne<br/>                        retued user["" "<br/>    __splt__tytin_typenvar([eptsedta, trableckpronaniong):<br/>        = {pramed(', 'nyping)</span><span id="e2f9" class="lc je hi ky b fi lh le l lf lg">def test seribonan, self):<br/>        witiss abclassiame(patypenytype,"rfloamed)<br/>        if nomedtepeise = ypewr[t0, nt.__note_ty__hargs__,<br/>   ' __nite___= u]</span><span id="2956" class="lc je hi ky b fi lh le l lf lg">pdev__args_tepl(gstrabc[tepliames)<br/>    def te_ne(no__, flob =insecastnang</span><span id="5eb8" class="lc je hi ky b fi lh le l lf lg">( a'serg, iflobals)],<br/>                 colencorato # abale struplo <br/>    xdef nmpichast fono  undithabecimptypargs tre a sub. or :<br/>    <br/>    typing cramptrethed conce tho kefarlable domedwault als ak: clistable:<br/>    def umaterarsy_verle:<br/>            gefrorg = ' f (prggenest_coulle_cove(supletore[usror, sulf,):</span><span id="82f1" class="lc je hi ky b fi lh le l lf lg">def cest_col__astr__(self):<br/>        n = seluniot dve, in =sumplamederintcanthorunor = 'x counerdof pa thefcl.a_gechings# bage frewth in%promec, mpasysenctept notatxs, aytr.<br/>   momed = typing.motynibisestr,<br/>                             def.__dect_als__(suefrope_dent:<br/>    pass</span><span id="a772" class="lc je hi ky b fi lh le l lf lg">def _made_pancher(sulf):<br/>    if tyse appor = f qunerim_roremston)<br/>        thep(self.dempam_hoxnmew_trupe__siplt(self),</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es li"><img src="../Images/ba82ca892e684011f315e9903dd1b127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uRmGDU3nCtEnv0i1iIlxag.jpeg"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">兰博基尼Aventador(感谢我的相机)</figcaption></figure><p id="57ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.作为一名兰博基尼车迷，我想出了这个主意，训练LSTM模特学习和产生兰博基尼Aventador的加速声。在我看来，44k频率(每秒的数据值)左右的音频信号是神经网络时间序列数据的一个很好的来源。这激发了足够的信心来使用22秒的加速声音来训练LSTM模型。从LSTM顺序产生的输出学习与兰博基尼汽车排气有关的独特特征(爆裂声和爆裂声)。输出的wav文件由背景噪声(白噪声)组成，为了得到清晰的输出，消除了背景噪声。下面附上输出的一个小片段。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="lj lk l"/></div></figure><h1 id="60b0" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">讨论</h1><p id="c3d6" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">从上述实验中，我们可以得出结论，LSTM模型在从序列数据中学习方面非常出色，并且可以生成多种数据风格。在训练过程中，损失值呈指数下降，实验的相应图表如下所示。这灌输了一个动机，以实验更多的LSTM变化和对自然语言处理应用研究。</p><div class="kh ki kj kk fd ab cb"><figure class="ll kl lm ln lo lp lq paragraph-image"><img src="../Images/c23f3c681a824d595c2e1d853b8521e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*zikqmWhbFeKYiAjuhXREeg.png"/></figure><figure class="ll kl lm ln lo lp lq paragraph-image"><img src="../Images/452a97394e74fd8cb01b8c6e7254d4b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*xp4ApPvrumv9KIZSE-zrUQ.png"/><figcaption class="ks kt et er es ku kv bd b be z dx lr di ls lt translated">代码生成和文本生成实验的训练损失值图。</figcaption></figure></div><p id="2408" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本实验使用的代码、输入文件和输出文件可以在<a class="ae lu" href="https://github.com/sakshambassi/nlp" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="2ee5" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">参考</h1><p id="84ac" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">1莎士比亚作品，麻省理工开放式课程；<a class="ae lu" href="https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt" rel="noopener ugc nofollow" target="_blank">https://OCW . MIT . edu/ans 7870/6/6.006/s08/lecture notes/files/t8 . Shakespeare . txt</a></p><p id="b921" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2 Franç ois Chollet，深度学习与Python代码示例，<a class="ae lu" href="https://github.com/fchollet/deep-learning-with-python-notebooks" rel="noopener ugc nofollow" target="_blank">https://github . com/fchollet/Deep-Learning-with-Python-notebooks</a></p><h1 id="5c83" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">承认</h1><p id="d36c" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我要感谢我的朋友阿塔瓦·戈米卡尔(Atharva Gomekar)帮助我培训LSTM进行音频生成，并感谢沙维·托马尔(Sharvi Tomar)分享她的RNNs知识。</p></div></div>    
</body>
</html>