# Hadoop 是在消亡还是在重新发明…

> 原文：<https://medium.com/analytics-vidhya/is-hadoop-dying-or-re-inventing-3e4f144752d4?source=collection_archive---------14----------------------->

![](img/610223335f5e0860499b2bc170347e04.png)

术语 Hadoop 和 bigdata 经常与 BigData 互换使用，BigData 通常意味着使用 Hadoop 来高效地处理大量数据。随着最近事态的转变和新技术的出现，特别是 Kubernetes，有无数的帖子指出 Hadoop 的消亡以及一项技术如何像它成名一样迅速地消失。我不禁想知道，如果在 Hadoop 上运行的一些商业模式不能成功，为什么 Hadoop 会受到如此多的负面宣传。

作为一项技术，Hadoop 远不止看上去那么简单！如果你认为 Hadoop 只是 HDFS(Hadoop 分布式文件系统)上的 MapReduce 和 YARN(又一个资源谈判者)，那么肯定它可能有有限的寿命。但是，如果您将 Hadoop 视为一个允许多种技术在分布式架构中相互交流的生态系统，那么观点就会转变为一种设计理念，而不仅仅是它的一种实现。

这是我们第一次可以利用多种商用硬件来处理数 TB/数 Pb 的数据，并在其上使用多种开源解决方案，如 Hive/Oozie/Spark 等，以完美的协调满足各种需求。每个项目都做了不同的事情；Hive 提供了类似 sql 的查询接口，Oziee 简化了您的 ETL 工作负载，Spark 提升了您的 map-reduce 工作负载。所有这些服务都巧妙地与 HDFS 和纱线结合在一起。你可以不严格地把它们看作来自 Kubernetes 世界的单个容器；这些是整个生态系统的基石。一大堆项目在它的背上启动，像 Storm、Zeppelin、Flume、Drill 等都参与了大 Hadoop 生态系统。像 Hortonworks/Cloudera 这样的公司在使各种不同的技术在一个公共生态系统中一起运行方面做了一些令人惊叹的工作，将大数据之旅推向了一个全新的水平。

当我们开始我们的大数据之旅时，我发现 MapReduce 极其笨重，难以编写。一个简单的字数统计问题(Hello World of BigData)需要相当多的代码才能让它工作。我们从未真正费心去学习 MapReduce 编程，但我们肯定理解它背后的设计思想。另一方面，Spark 凭借简单的 api 赢得了市场。我现在可以用几行代码写字数了。我们直接采用 Spark 作为编写 MapReduce 程序的主要方法。对我来说，spark 并不标志着 Hadoop 的终结，它标志着从基于文件的 map reduce 到内存 Spark 处理的演变。速度快了几个数量级。它与 Hive 无缝协作，从 HDFS 获取我的数据，并可以使用 YARN 在存储我的数据的机器上运行我的容器，从而大大减少了数据传输时间。

使用 HDFS 存储 TB 级结构化或非结构化数据的能力极大地推动了我们的本地数据工作。这里最大的竞争是以非常低的成本提供云存储。然而，计算数据存储位置(数据位置)的能力是云模型必须放弃的优势；云提供商通过区分计算和存储低估了这一概念。此外，来自银行业的您总是想要一些数据，而这些数据是您天生就喜欢放在本地机器上的。没有比这更好的本地存储卷的方式了，冗余和恢复与各种开源技术(如 HDFS)一起工作，并且能够像普通的 Linux 文件系统一样与之交互。

当然，HDFS 也有其缺点，冗余增加了所需的空间。对于 HDFS，我们需要存储三倍(默认)的数据大小，以实现冗余并容忍两台机器故障。云将给你不断增加的 9 的可靠性，而不需要支付额外的冗余。但是，在 Hadoop 3 中，我们现在有了擦除代码，可以将您的存储容量显著提高 150–200%。即使在这些改进之后，看起来 HDFS 可能会输给廉价的云存储，但是从 Hadoop 生态系统的角度来看，它淘汰了 HDFS，插入了 S3/Azure，而其他一切都保持不变，这就是它的设计之美。

人们经常抱怨设置 Hadoop 很困难，这也是他们输给提供托管服务的云提供商的一个原因。作为一名工程师，我觉得理解 Hadoop 架构的工作方式是一次性的努力。如果你使用 Cloudera 或 Hortonworks 发行版，这就更容易了。开始的确很有挑战性，但是学习 C++/Java 和编写我的第一个交易系统也是如此。它给了我一个很好的想法，让我知道有不同人参与的分布式系统是如何作为一个整体工作的。对于托管服务，由于抽象，总是有机会错过一些更好的调整细节，并且它们总是需要一些时间来赶上最新版本，我们一年前就迁移到了 Hadoop 3！

随着 Kubernetes 提供跨机器编排容器的能力，它解决了 Hadoop 的最大缺点，即管理和调度部分！如果 Hadoop 上的 namenode 失效，您将失去整个集群，因此 Hadoop 采用了具有两个 NameNode 的 HA 模式。第一个 namenode 一死，第二个就会接手。但是如果第二个倒下了，你又会陷入困境。Kubernetes 不会遇到这样的问题，因为它会在检测到故障时自动在另一台机器上启动服务。因此，Kubernetes 可以成为推出 namenode 的自然选择，它可以增强 Hadoop namenode 的可用性。Kubernetes 调度也有可能接管 YARN 调度，但它仍然必须改进其调度机制，并实现一些数据局部性的智能，以胜过 YARN。YARN 已经针对 hadoop map 降低工作负载进行了高度优化，但是没有什么可以阻止我们在 kubernetes 或不同的调度程序上使用 YARN。

我不认为更新的技术是 Hadoop 的死亡之钉，而是一种解决 Hadoop 缺点的服务，并将其发展为更可靠和可持续的服务。Kubernetes 做不到 Hive/Spark/HDFS 或整个 Hadoop 生态系统所做的。但 HDFS/Hive/Spark 肯定可以在 Kubernetes 上作为容器运行，将 Hadoop 生态系统重新发明到一个新时代。对于那些不想处理内部成本的人来说，AWS EMR 和 Azure HDInsight 是 Hadoop 如何在云中工作的完美例子。Cloudera 已经推出了一系列产品，将 Hadoop 从内部带到云环境。Hadoop 设计已经让它们模块化的独立组件通过定义良好的 API 相互通信，允许您在云中或作为容器即插即用。大数据生态系统将继续发展，Hadoop 核心组件将以一种或另一种形式存在，并随着环境的发展而改变其形象。

# 高拉夫·沙阿出版

*最初发表于*[*【https://www.linkedin.com】*](https://www.linkedin.com/pulse/hadoop-dying-re-inventing-gaurav-shah)*。*