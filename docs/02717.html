<html>
<head>
<title>NLP of Bible Chapters and Books — Similarity and Clustering with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">圣经章节和书籍的自然语言处理——与Python的相似性和聚类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/nlp-of-bible-chapters-and-books-similarity-and-clustering-with-python-69c9073251e?source=collection_archive---------6-----------------------#2019-12-30">https://medium.com/analytics-vidhya/nlp-of-bible-chapters-and-books-similarity-and-clustering-with-python-69c9073251e?source=collection_archive---------6-----------------------#2019-12-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f0b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">圣经是我最喜欢的书之一。除了宗教，这里的目的是试图更好地理解圣经写作的背景，以及一系列的划分(章节，新约/旧约，福音书)在NLP方面是否有意义。</p><h1 id="2df7" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">网络抓取和预处理——网络圣经</h1><p id="827e" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">数据来自网络圣经门户，这是一个由一群学者做的新的免费翻译，附带了他们做的许多笔记。我真的很喜欢阅读这个版本，所以我选择它来进行分析。</p><p id="65cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于框架，在Python上使用了Selenium。该代码和该工作中的主要问题将在未来的新故事中发布。在这里，我们只加载数据。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="a265" class="kp je hi kl b fi kq kr l ks kt">df = pd.read_csv(<strong class="kl hj">'data\\Original\\netBible.csv'</strong>, index_col=0)</span></pre><p id="0260" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些数据是按章节组织的。为了分析书籍，这些章节被连接起来。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="25ce" class="kp je hi kl b fi kq kr l ks kt">df.book = [r.replace(<strong class="kl hj">'netText_'</strong>, <strong class="kl hj">''</strong>) <strong class="kl hj">for </strong>r <strong class="kl hj">in </strong>df.book]<br/>df[<strong class="kl hj">'chapter'</strong>] = [r.split(<strong class="kl hj">'_'</strong>)[1] <strong class="kl hj">for </strong>r <strong class="kl hj">in </strong>df.book]<br/>df[<strong class="kl hj">'book'</strong>] = [r.split(<strong class="kl hj">'_'</strong>)[0] <strong class="kl hj">if </strong>len(r.split(<strong class="kl hj">'_'</strong>)) == 2 <strong class="kl hj">else </strong>r.split(<strong class="kl hj">'_'</strong>)[0] + <strong class="kl hj">'_' </strong>+ r.split(<strong class="kl hj">'_'</strong>)[1] <strong class="kl hj">for </strong>r <strong class="kl hj">in </strong>df.book]</span></pre><p id="81c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还创建了一个特性来识别旧约还是新约。由于这些行的顺序与圣经中的顺序相同，我们只选择了《新约》的第一本书，并将其他行标在下面。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="a51a" class="kp je hi kl b fi kq kr l ks kt">df[<strong class="kl hj">'testament'</strong>] = 0<br/>firstMat = df.loc[df[<strong class="kl hj">'book'</strong>] == <strong class="kl hj">'Matthew'</strong>, :].index[0]<br/>df.loc[firstMat:, <strong class="kl hj">'testament'</strong>] = 1</span></pre><p id="330a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们替换了新的行字符(' \n ')，并删除了停用词。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="8557" class="kp je hi kl b fi kq kr l ks kt">df.text = [re.sub(<strong class="kl hj">r'\d+'</strong>, <strong class="kl hj">''</strong>, r.replace(<strong class="kl hj">'\n'</strong>, <strong class="kl hj">' '</strong>)) <strong class="kl hj">for </strong>r <strong class="kl hj">in </strong>df.text]<br/><strong class="kl hj">for </strong>t <strong class="kl hj">in </strong>stopwords.words(<strong class="kl hj">'english'</strong>):<br/>    df.text = [s.replace(<strong class="kl hj">' ' </strong>+ t + <strong class="kl hj">' '</strong>, <strong class="kl hj">' '</strong>) <strong class="kl hj">for </strong>s <strong class="kl hj">in </strong>df.text]</span></pre><h1 id="323d" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">矢量化—转换数字文本</h1><p id="36c2" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">这里使用的矢量化方法是术语频率—逆文档频率(TF-IDF)。这种矢量化方法提取文本中每个术语的频率，并将所有文档中每个术语频率的倒数相加。具体来说，我们使用了sklearn包。用于创建矢量器的代码如下。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="cb50" class="kp je hi kl b fi kq kr l ks kt">vec = TfidfVectorizer()<br/>vecRes = vec.fit_transform(df.text).toarray()</span></pre><h1 id="e8c6" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">类似</h1><p id="b71f" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">在将文本转换成数字(向量)后，我们想计算出所有的书彼此有多少相似之处。为此，我们对TF-IDF提供的数据使用了余弦相似度。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="8beb" class="kp je hi kl b fi kq kr l ks kt"><em class="ku"># Similarity of Chapters<br/></em>vec = TfidfVectorizer()<br/>vecRes = vec.fit_transform(df.text).toarray()<br/>simRes = cosine_similarity(vecRes)<br/><em class="ku">## Testaments<br/></em>vecResOT = vec.fit_transform(df[df.testament==0].text).toarray()<br/>vecResNT = vec.fit_transform(df[df.testament==1].text).toarray()<br/>simResOT = cosine_similarity(vecResOT)<br/>simResNT = cosine_similarity(vecResNT)<br/><br/><br/><em class="ku"># Similarity of Books<br/></em>vec = TfidfVectorizer()<br/>df[<strong class="kl hj">'_'</strong>] = <strong class="kl hj">' '<br/></strong>vecRes_books = vec.fit_transform(df.groupby(<strong class="kl hj">'book'</strong>)[[<strong class="kl hj">'text'</strong>, <strong class="kl hj">'_'</strong>]].agg(<strong class="kl hj">'sum'</strong>).text).toarray()<br/>simRes_books = cosine_similarity(vecRes_books)<br/><em class="ku">## Testaments<br/></em>vecRes_booksOT = vec.fit_transform(df[df.testament==0].groupby(<strong class="kl hj">'book'</strong>)[[<strong class="kl hj">'text'</strong>, <strong class="kl hj">'_'</strong>]].agg(<strong class="kl hj">'sum'</strong>).text).toarray()<br/>vecRes_booksNT = vec.fit_transform(df[df.testament==1].groupby(<strong class="kl hj">'book'</strong>)[[<strong class="kl hj">'text'</strong>, <strong class="kl hj">'_'</strong>]].agg(<strong class="kl hj">'sum'</strong>).text).toarray()<br/>simRes_booksOT = cosine_similarity(vecRes_booksOT)<br/>simRes_booksNT = cosine_similarity(vecRes_booksNT)</span></pre><p id="d290" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果表明，对于章节，平均相似度在0.68%左右，最大相似度为97.24%。对于书籍，平均值为0.27%，最大值为91.31%。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="6a64" class="kp je hi kl b fi kq kr l ks kt">chaptersSim = pd.melt(pd.DataFrame(simRes)).value.drop_duplicates()<br/>booksSim = pd.melt(pd.DataFrame(simRes_books)).value.drop_duplicates()<br/><br/>fig, ax = plt.subplots(nrows=1, ncols=2)<br/><br/>chaptersSim.hist(ax=ax[0])<br/>ax[0].set_title(<strong class="kl hj">'Chapters'</strong>)<br/>booksSim.hist(ax=ax[1])<br/>ax[1].set_title(<strong class="kl hj">'Books'</strong>)<br/>plt.show()</span></pre><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es kv"><img src="../Images/c0b98ccc81384b57f47cc5993d1a9f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*pRP6Ab86BSv_LM_RPssrXg.png"/></div></figure><p id="eae5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">遗嘱分析表明，这些群体可能不会影响相似性的结果，但是，更多的测试将在这个主题中完成，并在未来的新故事中发表。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="d79d" class="kp je hi kl b fi kq kr l ks kt">chaptersSimOT = pd.melt(pd.DataFrame(simResOT)).value.drop_duplicates()<br/>booksSimOT = pd.melt(pd.DataFrame(simRes_booksOT)).value.drop_duplicates()<br/>chaptersSimNT = pd.melt(pd.DataFrame(simResNT)).value.drop_duplicates()<br/>booksSimNT = pd.melt(pd.DataFrame(simRes_booksNT)).value.drop_duplicates()<br/><br/>fig, ax = plt.subplots(nrows=2, ncols=2)<br/><br/>chaptersSimOT.hist(ax=ax[0, 0])<br/>ax[0,0].set_title(<strong class="kl hj">'Chapters - Old Testament'</strong>)<br/>chaptersSimNT.hist(ax=ax[1, 0])<br/>ax[1,0].set_title(<strong class="kl hj">'Chapters - New Testament'</strong>)<br/>booksSimOT.hist(ax=ax[0,1])<br/>ax[0,1].set_title(<strong class="kl hj">'Books - Old Testament'</strong>)<br/>booksSimNT.hist(ax=ax[1,1])<br/>ax[1,1].set_title(<strong class="kl hj">'Books - New Testament'</strong>)<br/>plt.show()</span></pre><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es kv"><img src="../Images/60421bcdae99bcbdd8dc3071f6b4a94f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*KZgCQsZ6sasseoatmMBOtw.png"/></div></figure><p id="1c3d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些结果表明，尽管所有这些书都属于同一组，但它们可能不太相似。</p><h1 id="f19d" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">使聚集</h1><p id="383b" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">对于聚类任务，使用主成分分析(PCA)来降低维度。这种技术使得减少特征的总数成为可能。在这种情况下，数据集减少到2个要素。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="4bee" class="kp je hi kl b fi kq kr l ks kt">dr = PCA(n_components=2)<br/>pcaDF = pd.DataFrame(dr.fit_transform(vecRes))<br/>pcaDF_books = pd.DataFrame(dr.fit_transform(vecRes_books))</span></pre><p id="24c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在那之后，每一章/书只有两个数字特征，这使得在散点图中绘制结果成为可能。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="c220" class="kp je hi kl b fi kq kr l ks kt">fig, ax = plt.subplots(nrows=2, ncols=1)<br/>fig.set_size_inches(14, 12)<br/><br/><em class="ku"># Chapters<br/></em>ax[0].scatter(pcaDF.loc[df.testament == 0, :].iloc[:, 0], pcaDF.loc[df.testament == 0, :].iloc[:, 1], label=<strong class="kl hj">'Old'</strong>)<br/>ax[0].scatter(pcaDF.loc[df.testament == 1, :].iloc[:, 0], pcaDF.loc[df.testament == 1, :].iloc[:, 1], label=<strong class="kl hj">'New'</strong>)<br/>ax[0].set_title(<strong class="kl hj">'Chapters PCA'</strong>)<br/>ax[0].legend()<br/><br/><em class="ku"># Books<br/></em>ax[1].scatter(pcaDF_books.loc[testament.testament == 0, 0], pcaDF_books.loc[testament.testament == 0, 1], label=<strong class="kl hj">'Old'</strong>)<br/>ax[1].scatter(pcaDF_books.loc[testament.testament == 1, 0], ax[1].set_title(<strong class="kl hj">'Books PCA'</strong>)<br/>ax[1].legend()<br/>plt.show()</span></pre><figure class="kg kh ki kj fd kw er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es kz"><img src="../Images/895dcbaa9ebf56d39696174d657cc0a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WvSfBCYwJOlFPJCbUb_yIQ.png"/></div></div></figure><p id="362e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过分析该图，可以注意到形成了三个主要群体。我们将需要单独绘制图书图，并带有名称，这样我们可以更好地理解结果。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="460f" class="kp je hi kl b fi kq kr l ks kt"># Create object with book names<br/>testament = df.groupby(<strong class="kl hj">'book'</strong>)[[<strong class="kl hj">'testament'</strong>]].agg(<strong class="kl hj">'mean'</strong>)<br/>testament.index = range(0,66)<br/>bookNames = df.groupby(<strong class="kl hj">'book'</strong>).agg(<strong class="kl hj">'sum'</strong>).index</span><span id="e2f4" class="kp je hi kl b fi le kr l ks kt"># Plot<br/>fig = plt.figure()<br/>fig.set_size_inches(14, 8)<br/><br/>pcaDF_books = pd.DataFrame(dr.fit_transform(vecRes_books))<br/>plt.scatter(pcaDF_books.loc[testament.testament == 0, 0], pcaDF_books.loc[testament.testament == 0, 1], label=<strong class="kl hj">'Old'</strong>)<br/>plt.scatter(pcaDF_books.loc[testament.testament == 1, 0], pcaDF_books.loc[testament.testament == 1, 1], label=<strong class="kl hj">'New'</strong>)<br/># Labels moved down<br/>lbBelow = [<strong class="kl hj">'Luke'</strong>, <strong class="kl hj">'Judges'</strong>, <strong class="kl hj">'Daniel'</strong>, <strong class="kl hj">'2_Kings'</strong>, <strong class="kl hj">'Haggai'</strong>, <strong class="kl hj">'Amos'</strong>, <strong class="kl hj">'1_Thessalonians'</strong>, <strong class="kl hj">'Colossians'</strong>, <strong class="kl hj">'2_Peter'</strong>, <strong class="kl hj">'Exodus'</strong>, <strong class="kl hj">'Joel'</strong>, <strong class="kl hj">'Zephaniah'</strong>, <strong class="kl hj">'Habakkuk'</strong>]</span><span id="2596" class="kp je hi kl b fi le kr l ks kt"># Labels moved down and left<br/>lbBelowL = [<strong class="kl hj">'Lamentations'</strong>, <strong class="kl hj">'1_Peter'</strong>, <strong class="kl hj">'2_Timothy'</strong>]</span><span id="c38f" class="kp je hi kl b fi le kr l ks kt"># Labels moved left<br/>lbLeft = [<strong class="kl hj">'1_Chronicles'</strong>, <strong class="kl hj">'1_Corinthians'</strong>, <strong class="kl hj">'2_Corinthians'</strong>]</span><span id="6c20" class="kp je hi kl b fi le kr l ks kt"><strong class="kl hj">for </strong>p <strong class="kl hj">in </strong>pcaDF_books.index:<br/>    print(bookNames[p])<br/>    <strong class="kl hj">if </strong>bookNames[p] <strong class="kl hj">in </strong>lbBelow:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(0, -18),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))<br/>    <strong class="kl hj">elif </strong>bookNames[p] <strong class="kl hj">in </strong>lbBelowL:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(-30, -18),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))<br/>    <strong class="kl hj">elif </strong>bookNames[p] <strong class="kl hj">in </strong>lbLeft:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(-15, 10),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))<br/>    <strong class="kl hj">elif </strong>bookNames[p] == <strong class="kl hj">'2_Thessalonians'</strong>:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(-30, -36),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))<br/>    <strong class="kl hj">elif </strong>bookNames[p] == <strong class="kl hj">'Deuteronomy'</strong>:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(50, 10),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))pcaDF_books.loc[p, 1]), xytext=(0, 10), textcoords=<strong class="kl hj">'offset points'</strong>)<br/>plt.title(<strong class="kl hj">'Books PCA'</strong>)<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kg kh ki kj fd kw er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es kz"><img src="../Images/cf01349d08df009cadacd866d9844926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-deP0ubRgIDpv3nIQiR1ng.png"/></div></div></figure><p id="4ac9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以看出福音书彼此非常接近，表明这些书可能与所有其他圣经不同。有趣的是，使徒行传是福音书最接近的一点。</p><p id="676b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们使用k-means算法从这些数据点创建组。因为我们可以清楚地识别3个组，所以我们将n_clusters设置为3。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="2566" class="kp je hi kl b fi kq kr l ks kt"># Train model<br/>kmeans = KMeans(n_clusters=3).fit(vecRes)</span><span id="a4ca" class="kp je hi kl b fi le kr l ks kt"># Plot results<br/>fig = plt.figure()<br/>fig.set_size_inches(14, 8)<br/><br/>plt.scatter(pcaDF_books.loc[kmeans_books.labels_ == 0, 0], pcaDF_books.loc[kmeans_books.labels_ == 0, 1], label=<strong class="kl hj">'Group 1'</strong>)<br/>plt.scatter(pcaDF_books.loc[kmeans_books.labels_ == 1, 0], pcaDF_books.loc[kmeans_books.labels_ == 1, 1], label=<strong class="kl hj">'Group 2'</strong>)<br/>plt.scatter(pcaDF_books.loc[kmeans_books.labels_ == 2, 0], pcaDF_books.loc[kmeans_books.labels_ == 2, 1], label=<strong class="kl hj">'Group 3'</strong>)</span><span id="f820" class="kp je hi kl b fi le kr l ks kt"># Labels moved down<br/>lbBelow = [<strong class="kl hj">'Luke'</strong>, <strong class="kl hj">'Judges'</strong>, <strong class="kl hj">'Daniel'</strong>, <strong class="kl hj">'2_Kings'</strong>, <strong class="kl hj">'Haggai'</strong>, <strong class="kl hj">'Amos'</strong>, <strong class="kl hj">'1_Thessalonians'</strong>, <strong class="kl hj">'Colossians'</strong>, <strong class="kl hj">'2_Peter'</strong>, <strong class="kl hj">'Exodus'</strong>, <strong class="kl hj">'Joel'</strong>, <strong class="kl hj">'Zephaniah'</strong>, <strong class="kl hj">'Habakkuk'</strong>]</span><span id="bc9a" class="kp je hi kl b fi le kr l ks kt"># Labels moved down and left<br/>lbBelowL = [<strong class="kl hj">'Lamentations'</strong>, <strong class="kl hj">'1_Peter'</strong>, <strong class="kl hj">'2_Timothy'</strong>]</span><span id="389f" class="kp je hi kl b fi le kr l ks kt"># Labels moved left<br/>lbLeft = [<strong class="kl hj">'1_Chronicles'</strong>, <strong class="kl hj">'1_Corinthians'</strong>, <strong class="kl hj">'2_Corinthians'</strong>]</span><span id="4e42" class="kp je hi kl b fi le kr l ks kt"><strong class="kl hj">for </strong>p <strong class="kl hj">in </strong>pcaDF_books.index:<br/>    print(bookNames[p])<br/>    <strong class="kl hj">if </strong>bookNames[p] <strong class="kl hj">in </strong>lbBelow:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(0, -18),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))<br/>    <strong class="kl hj">elif </strong>bookNames[p] <strong class="kl hj">in </strong>lbBelowL:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(-30, -18),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))<br/>    <strong class="kl hj">elif </strong>bookNames[p] <strong class="kl hj">in </strong>lbLeft:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(-15, 10),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))<br/>    <strong class="kl hj">elif </strong>bookNames[p] == <strong class="kl hj">'2_Thessalonians'</strong>:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(-30, -36),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))<br/>    <strong class="kl hj">elif </strong>bookNames[p] == <strong class="kl hj">'Deuteronomy'</strong>:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(50, 10),<br/>                     textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))<br/>    <strong class="kl hj">else</strong>:<br/>        plt.annotate(bookNames[p], (pcaDF_books.loc[p, 0], pcaDF_books.loc[p, 1]), xytext=(0, 10), textcoords=<strong class="kl hj">'offset points'</strong>, arrowprops = dict(arrowstyle = <strong class="kl hj">'-&gt;'</strong>, connectionstyle = <strong class="kl hj">'arc3,rad=0'</strong>))pcaDF_books.loc[p, 1]), xytext=(0, 10), textcoords=<strong class="kl hj">'offset points'</strong>)<br/>plt.title(<strong class="kl hj">'Books K-Means'</strong>)<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kg kh ki kj fd kw er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es kz"><img src="../Images/ed66cc045d2994cadf9723007a4b32fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8dE05DpqLJM_jq2jMprLw.png"/></div></div></figure><p id="a08d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由K-Means模型创建的组与福音组中的使徒行传和埃斯特的新/旧/福音划分非常相似。传道书，最初是旧约全书，是“新约全书”中的一本书，而启示录则相反。</p><h1 id="d3a7" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">结论</h1><p id="0e96" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">如果你想开始学习面向NLP的Python，这篇文章中的代码可能会对你有所帮助。然而，如果你想开始阅读圣经，从一大组(旧约、新约或福音书)开始，然后从你开始的地方转到其他相近的点可能会很有趣。我会建议你先读福音书，但这取决于你自己！</p><p id="2b69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好好读书/编码！</p></div></div>    
</body>
</html>