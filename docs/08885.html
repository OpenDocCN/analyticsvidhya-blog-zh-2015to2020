<html>
<head>
<title>Model optimization techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型优化技术</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/model-optimization-techniques-79a3a96b6427?source=collection_archive---------15-----------------------#2020-08-17">https://medium.com/analytics-vidhya/model-optimization-techniques-79a3a96b6427?source=collection_archive---------15-----------------------#2020-08-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0a89e2904d9efa86a6fe971eca3f20a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cozITwlOo6tzXSWrSxv_Cg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Tensorflow 2.3已经发布了，请到他们的网站上看看</figcaption></figure><p id="3cc8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi js translated">训练结束后，当我看着我的模特尺寸时，我总是因为它显示的数字而感到沮丧。但是没有更多的担忧，因为机器学习世界在过去十年里已经有了巨大的发展。在本文中，我将向您介绍使用TensorFlow进行模型优化的方法。</p><p id="fe82" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> Tensorflow </strong>是谷歌创建的开源深度学习框架，它应该在每个机器学习研究人员和有志者的列表中。可以说，在这十年里，每一个新模型都是基于Tensorflow或Pytorch。最初，市场上还有其他参与者，如<strong class="iw hj"> MXNet、Caffe </strong>等，但现在与Tensorflow和Pytorch相比，它们的份额非常少。随着权重聚类被添加到已经存在的剪枝和量化中，有三种主要的方法可以在不减少度量的情况下减少他们的模型的大小。</p><p id="11ac" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">修剪:</strong></p><p id="56ed" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">修剪实质上是取消神经网络的一些权重。所以这里发生的是在训练过程中，一些神经元没有被训练完，只有重要的神经元被训练。当无效神经元不再参与推理时，情况也是如此。修剪有助于显著压缩模型，即它可以减少高达6倍的大小，并且指标损失0.1%。以下是在以常规方式编译和训练模型后，如何在Keras模型中实现修剪的方法。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="2c6b" class="kk kl hi kg b fi km kn l ko kp">import tensorflow_model_optimization as tfmot</span><span id="a213" class="kk kl hi kg b fi kq kn l ko kp">prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude</span><span id="bb2d" class="kk kl hi kg b fi kq kn l ko kp"># Compute end step to finish pruning after 2 epochs.<br/>batch_size = 128<br/>epochs = 2<br/>validation_split = 0.1 # 10% of training set will be used for validation set. </span><span id="99a2" class="kk kl hi kg b fi kq kn l ko kp">num_images = train_images.shape[0] * (1 - validation_split)<br/>end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs</span><span id="570c" class="kk kl hi kg b fi kq kn l ko kp"># Define model for pruning.<br/>pruning_params = {<br/>      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,<br/>                                                               final_sparsity=0.80,<br/>                                                               begin_step=0,<br/>                                                               end_step=end_step)<br/>}</span><span id="76d6" class="kk kl hi kg b fi kq kn l ko kp">model_for_pruning = prune_low_magnitude(model, **pruning_params)</span><span id="d57b" class="kk kl hi kg b fi kq kn l ko kp"># `prune_low_magnitude` requires a recompile.<br/>model_for_pruning.compile(optimizer='adam',<br/>              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),<br/>              metrics=['accuracy'])</span><span id="ed0f" class="kk kl hi kg b fi kq kn l ko kp">model_for_pruning.summary()</span></pre><p id="dcce" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">量化:</strong></p><p id="5cfc" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在这种方法中，我们不会取消任何神经元，但我们会将模型权重从浮点数转换为整数。实践中主要有两种量化方法。一个是量化感知训练，另一个是后量化。量化感知训练包括在训练期间将权重转换为整数，而后量化是在保存模型时将权重转换为整数。下面是在Keras模型中实现这两种方法的方法</p><ul class=""><li id="204f" class="kr ks hi iw b ix iy jb jc jf kt jj ku jn kv jr kw kx ky kz bi translated"><strong class="iw hj">量化感知训练</strong></li></ul><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="bb39" class="kk kl hi kg b fi km kn l ko kp">import tensorflow_model_optimization as tfmot<br/><br/>quantize_model = tfmot.quantization.keras.quantize_model<br/><br/># q_aware stands for for quantization aware.<br/>q_aware_model = quantize_model(model)<br/><br/># `quantize_model` requires a recompile.<br/>q_aware_model.compile(optimizer='adam',<br/>              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),<br/>              metrics=['accuracy'])<br/><br/>q_aware_model.summary()</span></pre><ul class=""><li id="062e" class="kr ks hi iw b ix iy jb jc jf kt jj ku jn kv jr kw kx ky kz bi translated"><strong class="iw hj">后量化</strong></li></ul><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="aa49" class="kk kl hi kg b fi km kn l ko kp">import tensorflow as tf<br/>converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)<br/>converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]<br/>tflite_quant_model = converter.convert()</span></pre><p id="db7c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">权重聚类</strong></p><p id="d40d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这是我更感兴趣的方法，因为它的实现方式。将单个层中的权重聚类成<strong class="iw hj"> <em class="la"> N </em> </strong>个聚类，并找到它们各自的质心值。这些权重随后被质心值取代，这将极大地有助于模型压缩。与以前的方法相比，获得的度量更好。模型度量和大小取决于N值，如果它太低，我们将得到高度压缩的模型，但度量将非常差，反之亦然。下面是它在Keras模型中的实现方式</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="1929" class="kk kl hi kg b fi km kn l ko kp">``import tensorflow_model_optimization as tfmot<br/><br/>cluster_weights = tfmot.clustering.keras.cluster_weights<br/>CentroidInitialization = tfmot.clustering.keras.CentroidInitialization<br/><br/>clustering_params = {<br/>  'number_of_clusters': 16,<br/>  'cluster_centroids_init': CentroidInitialization.LINEAR<br/>}<br/><br/># Cluster a whole model<br/>clustered_model = cluster_weights(model, **clustering_params)<br/><br/># Use smaller learning rate for fine-tuning clustered model<br/>opt = tf.keras.optimizers.Adam(learning_rate=1e-5)<br/><br/>clustered_model.compile(<br/>  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),<br/>  optimizer=opt,<br/>  metrics=['accuracy'])<br/><br/>clustered_model.summary()</span></pre><p id="930f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以这是我第一次尝试从我所涉足的领域解释一些东西。我希望你觉得这是有用的。谢谢你阅读它。您的评论比以往任何时候都受欢迎，我感谢您的时间和努力</p><p id="7610" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">请继续关注我的账户，我会经常发布新的文章</p></div></div>    
</body>
</html>