<html>
<head>
<title>PySpark Syntax—5 Quick Tips</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PySpark 语法—5 个快速提示</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/pyspark-xp-syntax-f57a9e6a500f?source=collection_archive---------8-----------------------#2020-12-03">https://medium.com/analytics-vidhya/pyspark-xp-syntax-f57a9e6a500f?source=collection_archive---------8-----------------------#2020-12-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b12946d9ae4a5f55053111f518d32e96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tP-dw4Oj_42BYbkdtYbjMA.png"/></div></div></figure><p id="cfce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一系列帖子中的第一个帖子，<strong class="is hj"> <em class="jo"> PySpark XP </em> </strong>，每个帖子由 5 个提示组成。<strong class="is hj"> XP </strong>代表<strong class="is hj">经验值</strong>，因为这些提示与我在 PySpark 的经历中了解到的事情有关。每篇文章都将提供我使用 PySpark 的不同方面的技巧。</p><p id="9def" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第一个帖子是关于<strong class="is hj">语法</strong>。对于 PySpark 初学者来说，这将是很有价值的一课。更有经验的开发人员也可以从中学习(查看<strong class="is hj">提示#2 </strong>)。</p><p id="5ec6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">查看本帖的 Jupyter 笔记本点击<a class="ae jp" href="https://github.com/danflomin/medium/blob/main/Tips/Part%201%20-%20Syntax/Medium%20-%20Tips%20-%20Syntax.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">此处</strong> </a>。</p><h2 id="b380" class="jq jr hi bd js jt ju jv jw jx jy jz ka jb kb kc kd jf ke kf kg jj kh ki kj kk bi translated">提示 1 —列对象</h2><p id="cdef" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kn jd je jf ko jh ji jj kp jl jm jn hb bi translated">列本身就是对象。人们可以将一列放入一个列表或另一个集合中，或者对对象本身应用函数。这将列的概念与其父数据框架分离开来。</p><p id="0c71" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里有一个例子。</p><p id="abfb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们有一个包含两列整数的数据帧。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/79fd2f343de50f5c776bd38392b7c029.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*JGeSiiVLNgH2VU1PjkL8oA.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 1</figcaption></figure><p id="f57e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多，常用列整体来进行<code class="du kz la lb lc b">select</code>或<code class="du kz la lb lc b">withColumn</code>操作。像这样—</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/049643623f7da2bb61290846b3459086.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*0nLEG_2bC5Kgtuj5h_TIlw.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 2</figcaption></figure><p id="1af2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是列也可以在<code class="du kz la lb lc b">select</code>或<code class="du kz la lb lc b">withColumn</code>操作之外相乘。</p><p id="eeff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">看下面— </strong></p><p id="ec2c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先我们导入 Spark 的函数。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es le"><img src="../Images/01392898b9361599e3fb6800b31a9b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*8aOaIwwcthQ5tu_EKVaT3w.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 3</figcaption></figure><p id="482f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们把<code class="du kz la lb lc b">df</code>的列放在一个列表中。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/355b9587074175687c0f0afb3b328e32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*y6jG11lw56G6elSnmvntlw.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 4</figcaption></figure><p id="f8d1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">魔力来了。我们将每列乘以 2，并将相乘后的列“返回”到数据帧。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/8cc050bc8343a10dbaafd46c63643168.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*SeW4DY8ToSID1XSKbmNipQ.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 5</figcaption></figure><h2 id="bc99" class="jq jr hi bd js jt ju jv jw jx jy jz ka jb kb kc kd jf ke kf kg jj kh ki kj kk bi translated">提示#2 —选择与使用列</h2><p id="411c" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kn jd je jf ko jh ji jj kp jl jm jn hb bi translated">在我的第一篇和最后一篇文章中(点击<a class="ae jp" rel="noopener" href="/p/e273ede0ca13"> <strong class="is hj">此处</strong> </a>查看)，我讨论了关于 Spark join 优化，以及如何使用<code class="du kz la lb lc b">withColumn</code>而不是<code class="du kz la lb lc b">join</code>进行优化。</p><p id="04fa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一位读者让我注意到这样一个事实，即一次又一次地连续使用<code class="du kz la lb lc b">withColumn</code>，应该比对所有需要的新列使用 1 个<code class="du kz la lb lc b">select</code>要慢(仅针对驱动程序)。</p><p id="3a74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这相当于图 3，但是使用了两次<code class="du kz la lb lc b">withColumn</code>而不是一个<code class="du kz la lb lc b">select</code>子句。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/ae13b4958a34c49bd708090ca95281c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ORwkwScuw8zHQU003761g.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 6</figcaption></figure><p id="7fed" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其原因是 dataframe 对象是不可变的，因此在每个<code class="du kz la lb lc b">withColumn</code>之后，返回一个新的 dataframe 对象。新数据帧的构建需要时间 Spark 的内部实现消耗了这些时间。</p><p id="a162" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于这种现象更彻底的解释，请查看底部的参考资料部分。</p><h2 id="9837" class="jq jr hi bd js jt ju jv jw jx jy jz ka jb kb kc kd jf ke kf kg jj kh ki kj kk bi translated">技巧 3 —混叠</h2><p id="ba5b" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kn jd je jf ko jh ji jj kp jl jm jn hb bi translated">最常见的情况是当你想分组然后求和时。最简单的语法留给我们一个奇怪命名的列(就像<strong class="is hj">技巧 1 </strong>)。以后使用这个专栏名称可能会令人沮丧，但不会影响交易。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es li"><img src="../Images/a181ea3265e7f6ba48f771a35c7c76d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*QJqeswfbrs1WfkiWz53dIQ.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 7</figcaption></figure><p id="45f1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">绕过这个问题的方法如下—</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/abeaa8c6e661817e1b253ee405c7f126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*LBWtS3WCR3ZpwdWscJ1ldQ.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 8</figcaption></figure><h2 id="6282" class="jq jr hi bd js jt ju jv jw jx jy jz ka jb kb kc kd jf ke kf kg jj kh ki kj kk bi translated">提示 4—选择表达式</h2><p id="0d73" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kn jd je jf ko jh ji jj kp jl jm jn hb bi translated">在 PySpark 代码中使用来自<code class="du kz la lb lc b">pyspark.sql.functions</code>的函数是很常见的。导入所需的函数可能有点麻烦，而且没有人希望总是导入函数(尤其是在 Jupyter 笔记本中)。</p><p id="3300" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假设我们想要对我们的 2 列应用<strong class="is hj"> sin </strong>函数。我们可以做下面的事情，当然是用别名(；</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/d2f5ba91d8a30b2eb018684c69d62dbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*wyJbL97vL0VdHGMi8MLc6A.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 9</figcaption></figure><p id="891e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另一种方法是给数据帧一个名称，然后使用 SQL 语法查询数据帧，如下例所示。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/0f2d391d3b897a015b88808b10d8cccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*Tdi0sv0WdW2Qq0lLOdNyrg.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 10</figcaption></figure><p id="6c00" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是，我更喜欢另一种选择。<code class="du kz la lb lc b">selectExpr</code>能够在数据帧上使用 SQL 语法进行选择，使用字符串，无需命名数据帧或导入所需函数。</p><p id="ae8e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请看下文，了解如何做到这一点。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/e8fae2574f4295f1232ce3333b165988.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*IVICSvTSl5MlTW4AJCWEAA.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 11</figcaption></figure><p id="2b53" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">而且…我们甚至可以在<code class="du kz la lb lc b">selectExpr</code>子句中为我们的列起别名！</p><h2 id="56ba" class="jq jr hi bd js jt ju jv jw jx jy jz ka jb kb kc kd jf ke kf kg jj kh ki kj kk bi translated">技巧 5 —行对象</h2><p id="b7f8" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kn jd je jf ko jh ji jj kp jl jm jn hb bi translated">一个数据帧在某种程度上是一个<strong class="is hj">行</strong>的集合。我们说的是类<code class="du kz la lb lc b">pyspark.sql.Row</code>。</p><p id="3dd1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当你<code class="du kz la lb lc b">collect</code>一个数据帧时，你最终会得到一个列表，其中每个元素都是一个<code class="du kz la lb lc b">Row</code>。你遇到<code class="du kz la lb lc b">Row</code>对象的另一个地方是当你把数据帧转换成 RDD 时。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/a5ae5f0615d3d1d2ccac2bb96ea1ab36.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*G7MqpWWwYNIjSIouvM8utA.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 12</figcaption></figure><p id="18ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们抓住一排—</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/5d35c805dcfe970a85ef9066a110e38a.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*mk03NmWt5zpiHHKbH1TYZw.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 13</figcaption></figure><p id="092f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">可以通过几种方式访问行的值。这里有两个:</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/62ec020bf527d759dbec636ccdc57251.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*WNHjeGv7q83vSw3M7CFjJg.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">图 14</figcaption></figure><h1 id="2e3e" class="lq jr hi bd js lr ls lt jw lu lv lw ka lx ly lz kd ma mb mc kg md me mf kj mg bi translated">结论</h1><p id="68bc" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kn jd je jf ko jh ji jj kp jl jm jn hb bi translated">感谢阅读我关于 PySpark 语法的 5 个技巧。</p><h2 id="5f0a" class="jq jr hi bd js jt ju jv jw jx jy jz ka jb kb kc kd jf ke kf kg jj kh ki kj kk bi translated">系列文章</h2><p id="6607" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kn jd je jf ko jh ji jj kp jl jm jn hb bi translated">(2) <a class="ae jp" href="https://flomin-dan.medium.com/pyspark-planning-a-guide-for-1st-timers-e9a79a4706aa" rel="noopener"> PySpark 规划——首次创业指南</a></p><h2 id="06e4" class="jq jr hi bd js jt ju jv jw jx jy jz ka jb kb kc kd jf ke kf kg jj kh ki kj kk bi translated">参考</h2><p id="0c12" class="pw-post-body-paragraph iq ir hi is b it kl iv iw ix km iz ja jb kn jd je jf ko jh ji jj kp jl jm jn hb bi translated"><a class="ae jp" rel="noopener" href="/@manuzhang/the-hidden-cost-of-spark-withcolumn-8ffea517c015">提示# 3</a>——“火花<em class="jo">与</em>列的隐性成本”。</p></div></div>    
</body>
</html>