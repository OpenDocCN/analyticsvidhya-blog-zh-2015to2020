<html>
<head>
<title>Object detection with YOLO</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO物体检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/object-detection-with-yolo-aa2dfab21d56?source=collection_archive---------3-----------------------#2020-08-03">https://medium.com/analytics-vidhya/object-detection-with-yolo-aa2dfab21d56?source=collection_archive---------3-----------------------#2020-08-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="937c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的帖子显示了如何基于YOLO架构训练对象检测模型(下面参考资料中关于该主题的研究文章的链接)，在Google Colab中获取地图和平均损失统计数据，并使用自定义Python脚本测试训练的模型。</p><h1 id="90eb" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">储存库准备</h1><p id="787a" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><strong class="ih hj"> 1。</strong>克隆存储库(DarkNet框架):</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="26f3" class="kp je hi kl b fi kq kr l ks kt">!git clone <a class="ae ku" href="https://github.com/AlexeyAB/darknet.git" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexeyAB/darknet.git</a></span></pre><p id="7799" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong> bash命令以感叹号开始</p><blockquote class="kv kw kx"><p id="759a" class="if ig ky ih b ii ij ik il im in io ip kz ir is it la iv iw ix lb iz ja jb jc hb bi translated">感叹号用于执行来自底层操作系统的命令。<br/> <strong class="ih hj">来源</strong>-<a class="ae ku" href="https://towardsdatascience.com/an-effective-way-of-managing-files-on-google-colab-ac37f792690b?gi=7e7ac2742a2d" rel="noopener" target="_blank">https://towards data science . com/an-effective-way-of-managing-files-on-Google-cola b-ac37f 792690 b？gi=7e7ac2742a2d </a></p></blockquote><p id="ddfc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。</strong>创建文件夹构建-发布:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="37e4" class="kp je hi kl b fi kq kr l ks kt">cd /content/drive/My\ Drive/darknet/<br/>!mkdir build-release<br/>cd /content/drive/My\ Drive/darknet/build-release/</span></pre><p id="7bdf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong> <em class="ky">可选地</em>，在编译之前，用户可能会在终端中注释掉生成打印输出的源代码中的行，因为默认情况下，训练过程生成的输出过于冗余，即使为了显示打印输出，也会额外加载操作内存。)，在某个时候造成冻结甚至突然终止(笔者经历过几次)。以下摘录仅包含两次迭代的输出:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="29a7" class="kp je hi kl b fi kq kr l ks kt"><strong class="kl hj">truncated</strong><br/>7: 679.634888, 679.691040 avg loss, 0.000000 rate, 0.385118 seconds, 224 images, 419.996108 hours left<br/>Loaded: 2.210867 seconds - performance bottleneck on CPU or Disk HDD/SSD<br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.605842, GIOU: 0.574251), Class: 0.500359, Obj: 0.501755, No Obj: 0.500504, .5R: 1.000000, .75R: 0.000000, count: 5, class_loss = 271.598236, iou_loss = 0.801147, total_loss = 272.399384 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500954, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.291870, iou_loss = 0.000000, total_loss = 1087.291870 <br/> total_bbox = 248, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.614312, GIOU: 0.605125), Class: 0.500208, Obj: 0.501565, No Obj: 0.500505, .5R: 0.750000, .75R: 0.000000, count: 4, class_loss = 271.537018, iou_loss = 0.536957, total_loss = 272.073975 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500934, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.293945, iou_loss = 0.000000, total_loss = 1087.293945 <br/> total_bbox = 252, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.640582, GIOU: 0.634447), Class: 0.499148, Obj: 0.500193, No Obj: 0.500503, .5R: 0.600000, .75R: 0.200000, count: 5, class_loss = 271.477295, iou_loss = 0.716827, total_loss = 272.194122 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500943, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.298706, iou_loss = 0.000000, total_loss = 1087.298706 <br/> total_bbox = 257, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.578494, GIOU: 0.560010), Class: 0.500962, Obj: 0.502538, No Obj: 0.500505, .5R: 0.800000, .75R: 0.000000, count: 5, class_loss = 271.405792, iou_loss = 0.654083, total_loss = 272.059875 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500935, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.299683, iou_loss = 0.000000, total_loss = 1087.299683 <br/> total_bbox = 262, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.635607, GIOU: 0.608577), Class: 0.500960, Obj: 0.502537, No Obj: 0.500506, .5R: 0.750000, .75R: 0.250000, count: 4, class_loss = 271.092285, iou_loss = 0.535187, total_loss = 271.627472 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500919, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.300903, iou_loss = 0.000000, total_loss = 1087.300903 <br/> total_bbox = 266, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.571984, GIOU: 0.536152), Class: 0.500218, Obj: 0.501519, No Obj: 0.500505, .5R: 0.500000, .75R: 0.000000, count: 4, class_loss = 271.347656, iou_loss = 0.689331, total_loss = 272.036987 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500935, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.295410, iou_loss = 0.000000, total_loss = 1087.295410 <br/> total_bbox = 270, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.674173, GIOU: 0.652403), Class: 0.500960, Obj: 0.502531, No Obj: 0.500503, .5R: 1.000000, .75R: 0.250000, count: 4, class_loss = 271.155334, iou_loss = 0.497925, total_loss = 271.653259 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500935, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.292358, iou_loss = 0.000000, total_loss = 1087.292358 <br/> total_bbox = 274, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.639989, GIOU: 0.600127), Class: 0.500965, Obj: 0.502533, No Obj: 0.500506, .5R: 0.750000, .75R: 0.500000, count: 4, class_loss = 270.776886, iou_loss = 0.559204, total_loss = 271.336090 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500933, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.296143, iou_loss = 0.000000, total_loss = 1087.296143 <br/> total_bbox = 278, rewritten_bbox = 0.000000 % <br/><br/> 8: 679.609314, 679.682861 avg loss, 0.000000 rate, 0.393729 seconds, 256 images, 418.879547 hours left<br/>Loaded: 1.570684 seconds - performance bottleneck on CPU or Disk HDD/SSD<br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.471209, GIOU: 0.434264), Class: 0.500210, Obj: 0.501556, No Obj: 0.500503, .5R: 0.500000, .75R: 0.000000, count: 4, class_loss = 271.537018, iou_loss = 0.976410, total_loss = 272.513428 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500933, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.296387, iou_loss = 0.000000, total_loss = 1087.296387 <br/> total_bbox = 282, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.616591, GIOU: 0.601557), Class: 0.500208, Obj: 0.501559, No Obj: 0.500503, .5R: 1.000000, .75R: 0.250000, count: 4, class_loss = 271.410980, iou_loss = 0.328857, total_loss = 271.739838 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500925, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.294678, iou_loss = 0.000000, total_loss = 1087.294678 <br/> total_bbox = 286, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.560825, GIOU: 0.559239), Class: 0.499954, Obj: 0.501222, No Obj: 0.500504, .5R: 0.833333, .75R: 0.000000, count: 6, class_loss = 271.661560, iou_loss = 0.975983, total_loss = 272.637543 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500941, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.299683, iou_loss = 0.000000, total_loss = 1087.299683 <br/> total_bbox = 292, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.594659, GIOU: 0.592429), Class: 0.499454, Obj: 0.500582, No Obj: 0.500505, .5R: 0.750000, .75R: 0.250000, count: 4, class_loss = 271.161102, iou_loss = 0.735657, total_loss = 271.896759 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500947, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.291870, iou_loss = 0.000000, total_loss = 1087.291870 <br/> total_bbox = 296, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.546971, GIOU: 0.527006), Class: 0.500188, Obj: 0.501606, No Obj: 0.500506, .5R: 0.500000, .75R: 0.000000, count: 4, class_loss = 271.537018, iou_loss = 0.620148, total_loss = 272.157166 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500932, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.293457, iou_loss = 0.000000, total_loss = 1087.293457 <br/> total_bbox = 300, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.703408, GIOU: 0.697468), Class: 0.500990, Obj: 0.502102, No Obj: 0.500505, .5R: 1.000000, .75R: 0.200000, count: 5, class_loss = 271.091461, iou_loss = 0.492645, total_loss = 271.584106 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.326191, GIOU: 0.083068), Class: 0.502488, Obj: 0.502020, No Obj: 0.500926, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.353516, iou_loss = 0.583740, total_loss = 1087.937256 <br/> total_bbox = 306, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.652279, GIOU: 0.637695), Class: 0.500962, Obj: 0.502520, No Obj: 0.500505, .5R: 0.750000, .75R: 0.250000, count: 4, class_loss = 270.902740, iou_loss = 0.349670, total_loss = 271.252411 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500928, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.301758, iou_loss = 0.000000, total_loss = 1087.301758 <br/> total_bbox = 310, rewritten_bbox = 0.000000 % <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 16 Avg (IOU: 0.673402, GIOU: 0.651781), Class: 0.500969, Obj: 0.502514, No Obj: 0.500506, .5R: 0.750000, .75R: 0.500000, count: 4, class_loss = 271.029327, iou_loss = 0.494690, total_loss = 271.524017 <br/>v3 (mse loss, Normalizer: (iou: 0.75, cls: 1.00) Region 23 Avg (IOU: 0.000000, GIOU: 0.000000), Class: 0.000000, Obj: 0.000000, No Obj: 0.500919, .5R: 0.000000, .75R: 0.000000, count: 1, class_loss = 1087.297485, iou_loss = 0.000000, total_loss = 1087.297485 <br/> total_bbox = 314, rewritten_bbox = 0.000000 % <br/><strong class="kl hj">truncated</strong></span></pre><p id="de94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每次迭代的长度取决于细分的数量(仅影响内存利用率——细分越少，内存的工作负载越高，因为它必须同时处理更多的图像)和convnet (DarkNet19、DarkNet53、DenseNet、ResNet等。)</p><p id="4a2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">打开darknet/src/region_layer.c并注释掉以下行:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="dd92" class="kp je hi kl b fi kq kr l ks kt">printf(“Region Avg IOU: %f, Class: %f, Obj: %f, No Obj: %f, Avg Recall: %f, count: %d\n”, avg_iou/count, avg_cat/class_count, avg_obj/count, avg_anyobj/(l.w*l.h*l.n*l.batch), recall/count, count);</span></pre><p id="dfab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">打开darknet/src/yolo_layer.c并注释掉下面一行:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="b565" class="kp je hi kl b fi kq kr l ks kt">fprintf(stderr, “v3 (%s loss, Normalizer: (iou: %.2f, cls: %.2f) Region %d Avg (IOU: %f, GIOU: %f), Class: %f, Obj: %f, No Obj: %f, .5R: %f, .75R: %f, count: %d, class_loss = %f, iou_loss = %f, total_loss = %f \n”,<br/> (l.iou_loss == MSE ? “mse” : (l.iou_loss == GIOU ? “giou” : “iou”)), l.iou_normalizer, l.cls_normalizer, state.index, tot_iou / count, tot_giou / count, avg_cat / class_count, avg_obj / count, avg_anyobj / (l.w*l.h*l.n*l.batch), recall / count, recall75 / count, count,<br/> classification_loss, iou_loss, loss);</span></pre><p id="b603" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在某些情况下，最终使用的是区域层而不是yolo(例如。，对于DenseNet)因此应该注释掉两个文件中的行。</p><p id="3137" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。</strong>编译储存库:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="c53f" class="kp je hi kl b fi kq kr l ks kt">!cmake ..<br/>!make<br/>!make install</span></pre><p id="9366" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意#1: </strong>如果用户想改变源代码，他必须重新编译。<br/> <strong class="ih hj">注#2: <br/> </strong>为暗网每次新建会话更改权限:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="e19b" class="kp je hi kl b fi kq kr l ks kt">!chmod -R 777 darknet</span></pre><p id="8eea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">否则，使用darknet的每个命令将提供:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="3de9" class="kp je hi kl b fi kq kr l ks kt">/bin/bash: ./darknet: Permission denied</span></pre><h1 id="12c1" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">数据准备</h1><p id="a3c1" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><strong class="ih hj">注:</strong>数据准备必须在Colab中完成</p><p id="e38d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1。</strong>获取图像</p><p id="7768" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。</strong>为图像加标签克隆LabelImg并打开它:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="ac6b" class="kp je hi kl b fi kq kr l ks kt">git clone <a class="ae ku" href="https://github.com/tzutalin/labelImg.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tzutalin/labelImg.git</a><br/>cd labelImg</span></pre><p id="94bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。</strong>安装所需的软件包(适用于Linux):</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="6f52" class="kp je hi kl b fi kq kr l ks kt">sudo apt install pyqt5-dev-tools<br/>sudo pip3 install -r requirements/requirements-linux-python3.txt<br/>make qt5py3</span></pre><p id="412f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注:</strong>对于其他操作系统，请遵循<a class="ae ku" href="https://github.com/" rel="noopener ugc nofollow" target="_blank">https://github.com/</a>T35】Tzu talin/labelImg上的安装指南</p><p id="e152" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。</strong>运行标签:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="2a80" class="kp je hi kl b fi kq kr l ks kt">python3 labelImg.py</span></pre><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lc"><img src="../Images/0cfe284ec0034627d7b21007e1724535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*79tFaA_fmIUpDiu66g3-pQ.png"/></div></div></figure><p id="8e8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 5。</strong>选择PASCAL VOC标注格式:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lc"><img src="../Images/7e740fa8f9a348c02239fde31213a2f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qvm5H5FljGHkwi8xsDTVkQ.png"/></div></div></figure><p id="a8de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong>最好选择PASCAL VOC格式，因为它包含更多的信息，可以在以后使用Tensorflow使用标记的图像，并且可以随时使用Python-script(在下面的模型配置中讨论)转换为YOLO格式，而不是相反——格式包含相对于图像宽度和高度的浮点值<strong class="ih hj">,它可以等于0到1，因此，不可能从相对值恢复绝对值。</strong></p><p id="c37c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 6。</strong>标签图像:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lc"><img src="../Images/858b48c0604f0cc75e12fab3ce79592e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f3Lny_-c6mOfvQBhFWEuoA.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">选择创建/n复选框</figcaption></figure><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lc"><img src="../Images/2cf681bf3682a3cedf452153bb18a6b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Al98gdT38J0jHNo0ijq68w.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">突出显示对象，并为其指定名称</figcaption></figure><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lc"><img src="../Images/a51b9462791915afea85dcfc7efff1ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CsbwWdaqZIxt3sgUTURorg.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">对象现在已被标记</figcaption></figure><p id="1927" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 7。</strong>图像和XML标签文件:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lo"><img src="../Images/a8559ec095d2e96e2e5472e0d3200aa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tL8vcgpWbf9kXEKERB3K2g.png"/></div></div></figure><p id="386b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在继续下一步之前，最好先熟悉几个脚本，这对准备数据和测试最终模型可能是有用的。代码基于使用OpenCV的<a class="ae ku" href="https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/" rel="noopener ugc nofollow" target="_blank"> YOLO对象检测</a>，<a class="ae ku" href="https://www.pyimagesearch.com/2020/02/10/opencv-dnn-with-nvidia-gpus-1549-faster-yolo-ssd-and-mask-r-cnn/" rel="noopener ugc nofollow" target="_blank">OpenCV‘dnn’使用NVIDIA GPU:1549%更快的YOLO、SSD和Mask R-CNN </a>，<a class="ae ku" href="https://www.pyimagesearch.com/2017/02/06/faster-video-file-fps-with-cv2-videocapture-and-opencv/" rel="noopener ugc nofollow" target="_blank">使用cv2更快的视频文件FPS。Adrian Rosebrock的视频捕获和OpenCV </a>。<br/> <strong class="ih hj">注:</strong>以下软件将进一步完善。</p><p id="2f2d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">8。首先克隆存储库:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="c050" class="kp je hi kl b fi kq kr l ks kt">git clone <a class="ae ku" href="https://ElencheZetetique@bitbucket.org/ElencheZetetique/rtod.git" rel="noopener ugc nofollow" target="_blank">https://ElencheZetetique@bitbucket.org/ElencheZetetique/rtod.git</a></span></pre><p id="62ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">脚本prepare.py包含几个功能，如灰度缩放，调整大小，给图像指定唯一的名称，PASCAL VOC标签修改和转换为YOLO格式。</p><p id="37f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">9。转换为YOLO格式:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="052a" class="kp je hi kl b fi kq kr l ks kt">python3 prepare.py -s /path/to/Documents/Dataset/ -yf 25 -cpy /path/to/</span></pre><p id="b0a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里</p><ul class=""><li id="c963" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">标志<code class="du ly lz ma kl b">-s/--src</code>指向源文件夹(在这种情况下是数据集文件夹)；</li><li id="221b" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc lu lv lw lx bi translated">标志<code class="du ly lz ma kl b">-yf/--yolo_format</code>转换为YOLO并取5到35之间的整数，以便将数据集分成训练和验证子集；</li><li id="a68e" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc lu lv lw lx bi translated">标志<code class="du ly lz ma kl b">-cpy/--change_path_yolo</code>在train.txt，valid.txt中的图像名称前设置路径</li></ul><p id="e858" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用标志<code class="du ly lz ma kl b">-h/--help</code>获取更多详细信息</p><p id="9245" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">命令的结果:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mg"><img src="../Images/c169b5bd2165efe6ff840711b051fbbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QyXHTYq5Ivb6Z6O75CccHA.png"/></div></div></figure><ul class=""><li id="d155" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">每个图像现在都有额外的YOLO格式的txt文件:</li></ul><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mh"><img src="../Images/f40aa40607ff780a7f82ecc9c60e8dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A8--t4wfj0WdKajhdcn2ug.png"/></div></div></figure><p id="cc5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO标签文件有以下内容:</p><p id="599e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du ly lz ma kl b">0 0.571111 0.445141 0.764444 0.495298</code></p><blockquote class="kv kw kx"><p id="9b7e" class="if ig ky ih b ii ij ik il im in io ip kz ir is it la iv iw ix lb iz ja jb jc hb bi translated"><code class="du ly lz ma kl b">&lt;object-class&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;<br/></code>其中:<br/> <code class="du ly lz ma kl b">-&lt;object-class&gt;</code> -整数对象编号从<code class="du ly lz ma kl b">0</code>到<code class="du ly lz ma kl b">(classes-1)<br/>&lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code> -浮点值<strong class="ih hj">相对于图像的宽度和高度</strong>，可以等于从<code class="du ly lz ma kl b">(0.0 to 1.0]<br/></code>例如:<code class="du ly lz ma kl b">&lt;x&gt; = &lt;absolute_x&gt; / &lt;image_width&gt;</code>或<code class="du ly lz ma kl b">&lt;height&gt; = &lt;absolute_height&gt; / &lt;image_height&gt;<br/></code> atention: <code class="du ly lz ma kl b">&lt;x_center&gt; &lt;y_center&gt;</code> -是矩形的中心(不是左上角)<br/><strong class="ih hj">Source</strong>—<a class="ae ku" href="https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects" rel="noopener ugc nofollow" target="_blank">https://github . com/AlexeyAB/darknet # how-to-train-to-detect-your-custom</a></p></blockquote><ul class=""><li id="b41f" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">cfg文件夹:</li></ul><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mi"><img src="../Images/686a109cbd7e488727cd0c60ccf6e8b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AXBQubXt-DBt4l1ZYEGI6Q.png"/></div></div></figure><p id="7d90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">cfg文件夹包含:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div class="er es mj"><img src="../Images/7b1b5ef4981de1822fd3cdd5248423a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*vFNKSfgMPJ95_5SUeXt6oQ.png"/></div></figure><ul class=""><li id="acb6" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">文件夹cfg中的obj.data文件，包含以下内容:</li></ul><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="fccd" class="kp je hi kl b fi kq kr l ks kt">classes=num_of_classes<br/>train=/path/to/train.txt<br/>valid=/path/to/valid.txt<br/>names=/path/to/obj.names<br/>backup=/path/to/backup</span></pre><p id="f904" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更改/path/to/backup to /mydrive，这是一个到路径的链接，所有权重(经过一定次数迭代后的训练模型)将在训练期间保存到该路径，例如。：</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="3be1" class="kp je hi kl b fi kq kr l ks kt">!ln -s “/content/drive/My Drive/YOLO/backup” /mydrive</span></pre><p id="be01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注#1: </strong>链接用于避免因文件夹名My Drive不可修改而导致的错误。<br/></p><ul class=""><li id="a93d" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">obj.names文件，其中包含模型应接受训练的所有对象的列表。例如，如果使用所有COCO对象在数据集上训练模型:</li></ul><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="b075" class="kp je hi kl b fi kq kr l ks kt">person<br/>bicycle<br/>car<br/>motorbike<br/>aeroplane<br/>bus<br/>train<br/>truck<br/>boat<br/>traffic light<br/>fire hydrant<br/>stop sign<br/>parking meter<br/>bench<br/>bird<br/>cat<br/>dog<br/>horse<br/>sheep<br/>cow<br/>elephant<br/>bear<br/>zebra<br/>giraffe<br/>backpack<br/>umbrella<br/>handbag<br/>tie<br/>suitcase<br/>frisbee<br/>skis<br/>snowboard<br/>sports ball<br/>kite<br/>baseball bat<br/>baseball glove<br/>skateboard<br/>surfboard<br/>tennis racket<br/>bottle<br/>wine glass<br/>cup<br/>fork<br/>knife<br/>spoon<br/>bowl<br/>banana<br/>apple<br/>sandwich<br/>orange<br/>broccoli<br/>carrot<br/>hot dog<br/>pizza<br/>donut<br/>cake<br/>chair<br/>sofa<br/>pottedplant<br/>bed<br/>diningtable<br/>toilet<br/>tvmonitor<br/>laptop<br/>mouse<br/>remote<br/>keyboard<br/>cell phone<br/>microwave<br/>oven<br/>toaster<br/>sink<br/>refrigerator<br/>book<br/>clock<br/>vase<br/>scissors<br/>teddy bear<br/>hair drier<br/>toothbrush</span></pre><blockquote class="kv kw kx"><p id="4c09" class="if ig ky ih b ii ij ik il im in io ip kz ir is it la iv iw ix lb iz ja jb jc hb bi translated">下载自【https://github.com/AlexeyAB/darknet】<br/><strong class="ih hj">来源</strong>—<a class="ae ku" href="https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/coco.names" rel="noopener ugc nofollow" target="_blank">https://camo . githubusercontent . com/d 60 fdba 6 c 007 a5df 888747 C2 c 03664 c 91c 12 C1 e/68747470733 a2f 6873746 F2 E6 f 72672 f 776562742 f 79642 f 766 C2 f 61672 f 7</a></p></blockquote><ul class=""><li id="5722" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">train.txt和valid.txt</li></ul><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mk"><img src="../Images/0fe31f3eb3fe244e3bb7c5ffef1ed231.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S1jXASIvjlrItma9r6ErcA.png"/></div></div></figure><p id="1587" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">文件的内容:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ml"><img src="../Images/cf8519169045711284032c5e2b0a6686.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FfLWp9OS7a9fxQ1lXoFUGg.png"/></div></div></figure><p id="43d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">10。得到*。来自<a class="ae ku" href="https://github.com/AlexeyAB/darknet/tree/master/cfg" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexeyAB/darknet/tree/master/cfg</a>的cfg并修改它:</p><blockquote class="kv kw kx"><p id="3ccc" class="if ig ky ih b ii ij ik il im in io ip kz ir is it la iv iw ix lb iz ja jb jc hb bi translated">在每个<code class="du ly lz ma kl b"><em class="hi">[yolo]</em></code>层之前的3个<code class="du ly lz ma kl b"><em class="hi">[convolutional]</em></code>中，将<code class="du ly lz ma kl b"><em class="hi">filters=255</em></code>更改为filters=(classes + 5)x3，请记住，它只需是每个<code class="du ly lz ma kl b"><em class="hi">[yolo]</em></code>层之前的最后一个<code class="du ly lz ma kl b"><em class="hi">[convolutional]</em></code>。<br/> <strong class="ih hj">来源</strong>-<a class="ae ku" href="https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects" rel="noopener ugc nofollow" target="_blank">https://github . com/AlexeyAB/darknet # how-to-train-detect-your-custom-objects</a>(项目#1)</p></blockquote><p id="a9e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注:</strong> *。cfg必须对应于预训练的权重，否则执行失败。兼容性列表显示在<a class="ae ku" href="https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects" rel="noopener ugc nofollow" target="_blank">https://github . com/AlexeyAB/darknet # how-to-train-detect-your-custom-objects</a>(项目#7)中</p><h1 id="8202" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">培养</h1><p id="f511" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><strong class="ih hj"> 1。</strong>现在可以开始训练了:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="de08" class="kp je hi kl b fi kq kr l ks kt">!./darknet detector train /content/sample_data/obj.data /content/sample_data/yolov3-tiny.cfg /content/drive/My\ Drive/pretrained/darknet19_448.conv.23 -dont_show</span></pre><p id="b53d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意#1: </strong>仔细检查所有文件的路径，否则执行失败(尤其是train.txt和valid.txt中指定的图像路径)。<strong class="ih hj"> <br/>注#2: </strong>在Colab中必须使用flag -dont_show，否则执行一开始就被终止。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="242b" class="kp je hi kl b fi kq kr l ks kt"><strong class="kl hj">truncated</strong><br/>If error occurs - run training with flag: -dont_show <br/>Unable to init server: Could not connect: Connection refused<br/><br/>(chart_yolov3-tiny.png:2780): Gtk-<strong class="kl hj">WARNING</strong> **: 20:15:19.955: cannot open display:</span></pre><blockquote class="kv kw kx"><p id="1869" class="if ig ky ih b ii ij ik il im in io ip kz ir is it la iv iw ix lb iz ja jb jc hb bi translated">(要禁用丢失窗口，请使用<code class="du ly lz ma kl b">darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137 -dont_show</code>，如果您在没有监控的计算机上训练，例如云亚马逊EC2) <br/> <strong class="ih hj">来源</strong>-<a class="ae ku" href="https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects" rel="noopener ugc nofollow" target="_blank">https://github . com/AlexeyAB/darknet #如何训练以检测您的定制对象</a>(项目#8)</p></blockquote><figure class="kg kh ki kj fd ld er es paragraph-image"><div class="er es mm"><img src="../Images/6ee3ac79b6edc2f46b6e7b29b2f9747c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*00xFrYQO5gR2dRwotHdVig.jpeg"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">Loss-window(下载自<a class="ae ku" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexeyAB/darknet</a><strong class="bd jf">来源</strong>-<a class="ae ku" href="https://camo.githubusercontent.com/d60dfdba6c007a5df888747c2c03664c91c12c1e/68747470733a2f2f6873746f2e6f72672f776562742f79642f766c2f61672f7964766c616775746f66327a636e6a6f64737467726f656e3861632e6a706567" rel="noopener ugc nofollow" target="_blank">https://camo . githubusercontent . com/d 60 fdba 6 c 007 a5df 888747 C2 c 03664 c 91 c 12 C1 e/68747470733 a2 F2 f 6873746 F2 E6 f 72672 f 776562742 f 79642 f 766 C2 f 616721</a></figcaption></figure><p id="adee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了保存可能用于进一步分析(在分析输出中解释)的输出(训练过程),可以将输出重定向到文本文件:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="d0d5" class="kp je hi kl b fi kq kr l ks kt">!./darknet detector train /content/sample_data/obj.data /content/sample_data/yolov3-tiny.cfg /content/drive/My\ Drive/pretrained/darknet19_448.conv.23 -dont_show &gt; /content/drive/My\ Drive/backup/training_output.txt</span></pre><p id="50fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。</strong>在为/mydrive指定的备份文件夹中查找结果</p><p id="cc77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们可以将训练好的模型与obj.names和*一起使用。cfg(详见测试)。</p><h1 id="3541" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">测试</h1><p id="d2e3" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">现在是测试训练好的模型的时候了。下载您喜欢用于对象检测的权重文件，将其保存在主机上，并与obj.names和*放在一个文件夹中。用于为当前模型定型的cfg文件。</p><p id="ec23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1。</strong>运行视频捕捉命令:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="ddaf" class="kp je hi kl b fi kq kr l ks kt">python3 test.py -d /path/to/Model -vc 0 -sf</span></pre><p id="78d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里</p><ul class=""><li id="878f" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">标志<code class="du ly lz ma kl b">-vc/--video_cap</code> —处理来自摄像机的视频。设置相机编号。(在这种情况下，它是“0”)</li><li id="4ad1" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc lu lv lw lx bi translated">标志<code class="du ly lz ma kl b">-d/--darknet</code> —暗网(基于)目录的路径(必须包含*。cfg，*。名称(要检测的对象列表)，*。重量—每个仅一次)</li><li id="5a98" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc lu lv lw lx bi translated">标志<code class="du ly lz ma kl b">-sf/--save_frame</code>—如果为真，则保存检测到对象的帧</li></ul><p id="3f3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">详情请致电<code class="du ly lz ma kl b">-h/--help</code></p><p id="3d90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用户可以在文件夹结果中找到带有检测到的对象的帧:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div class="er es mn"><img src="../Images/763b3f38a13e617ab95f14e9dc5b620a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*n7XTexUPzSH7uz04UkGR3A.png"/></div></figure><p id="ac5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">并找到结果。每个所谓的会话都有一个时间戳，对应于运行命令的时间:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div class="er es mo"><img src="../Images/9bbca70c484ba894e4967bf1902cd863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*E3m3MGYzMsUbVZzk28KXnQ.png"/></div></figure><p id="f841" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">检测示例:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div class="er es mp"><img src="../Images/54334dc831b64d1163595b769cf40756.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*5XFNHgPZm8ThgiXlsL-s3g.jpeg"/></div></figure><p id="2518" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。</strong>对于推理图像，将图像放入一个文件夹并运行:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="71a6" class="kp je hi kl b fi kq kr l ks kt">python3 test.py -d /path/to/Model -is /path/to/folder/with/images</span></pre><p id="6a10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里</p><ul class=""><li id="d6a0" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">标志<code class="du ly lz ma kl b">-is/--image_src</code> —带有图像的文件夹</li></ul><p id="6ba6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">进度显示在终端中:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mq"><img src="../Images/2fda63da04ced29d128f5603096ceda1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BK3uZy_IkU7H5JlNZdFGVw.png"/></div></div></figure><p id="48fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行结束后，所有处理过的图像都在结果文件夹中。</p><p id="997e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">检测到物体的图像示例:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mr"><img src="../Images/39713ad86fdcbc3fd2cce737439668cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vdq7_uUYFhpntHJRq-s_Fg.jpeg"/></div></div></figure><p id="e343" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。</strong>对于视频:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="2425" class="kp je hi kl b fi kq kr l ks kt">python3 test.py -d /path/to/Model -vs /path/to/folder/with/images</span></pre><p id="62b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里</p><ul class=""><li id="54e5" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">标志<code class="du ly lz ma kl b">-vs/--video_src</code>—视频路径</li></ul><p id="c6db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">进度显示在终端中:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ms"><img src="../Images/0587fbb5637c3a0f2c47e25125f01db5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZUzC7Et8qSknNkjQcQcolw.png"/></div></div></figure><p id="fd09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ku" href="https://drive.google.com/file/d/1wZXzJ1tBvraVaQEGEeYUskLIB2qxHazi/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">检测到物体的视频示例</a></p><p id="77a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行结束后，可以在结果文件夹中找到处理过的视频。</p><h1 id="7207" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">分析输出</h1><p id="7bcb" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><strong class="ih hj"> 1。</strong>地图</p><p id="b07f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你对地图特征不熟悉，可以阅读参考文献中相应的文章。<br/>为了获得所有权重的mAP，运行以下bash脚本(<a class="ae ku" href="https://drive.google.com/file/d/1mKZt3j1SwwNvFRtZDvXoqRsslQlHmRPM/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">下载脚本</a>):</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="3b6e" class="kp je hi kl b fi kq kr l ks kt">!bash /content/drive/My\ Drive/for_mAP/get_mAP.sh</span></pre><p id="bae1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内容:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="6016" class="kp je hi kl b fi kq kr l ks kt">#!/usr/bin/bash<br/>cd /content/drive/My\ Drive/darknet/build-release</span><span id="e2e7" class="kp je hi kl b fi mt kr l ks kt">for i in {1000..LAST_WEIGHT..1000}<br/>    do<br/>        ./darknet detector map /content/sample_data/obj.data /content/drive/My\ Drive/for_mAP/yolov3.cfg /content/drive/My\ Drive/for_mAP/yolov3_$i.weights -points 0 &gt;&gt; /content/drive/My\ Drive/for_mAP/output$i.txt<br/>        ./darknet detector map /content/sample_data/obj.data /content/drive/My\ Drive/for_mAP/yolov3.cfg /content/drive/My\ Drive/for_mAP/yolov3_$i.weights -iou_thresh 0.75 -points 0 &gt;&gt; /content/drive/My\ Drive/for_mAP/output$i.txt<br/>        ./darknet detector map /content/sample_data/obj.data /content/drive/My\ Drive/for_mAP/yolov3.cfg /content/drive/My\ Drive/for_mAP/yolov3_$i.weights -points 11 &gt;&gt; /content/drive/My\ Drive/for_mAP/output$i.txt<br/>        ./darknet detector map /content/sample_data/obj.data /content/drive/My\ Drive/for_mAP/yolov3.cfg /content/drive/My\ Drive/for_mAP/yolov3_$i.weights -iou_thresh 0.75 -points 11 &gt;&gt; /content/drive/My\ Drive/for_mAP/output$i.txt<br/>        ./darknet detector map /content/sample_data/obj.data /content/drive/My\ Drive/for_mAP/yolov3.cfg /content/drive/My\ Drive/for_mAP/yolov3_$i.weights -points 101 &gt;&gt; /content/drive/My\ Drive/for_mAP/output$i.txt<br/>        ./darknet detector map /content/sample_data/obj.data /content/drive/My\ Drive/for_mAP/yolov3.cfg /content/drive/My\ Drive/for_mAP/yolov3_$i.weights -iou_thresh 0.75 -points 101 &gt;&gt; /content/drive/My\ Drive/for_mAP/output$i.txt<br/>    done</span></pre><p id="083a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里</p><ul class=""><li id="c630" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">在最后保存的重量中输入LAST_WEIGHT而不是LAST _ WEIGHT</li></ul><p id="412c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据PASCAL VOC 2007(-点11)、PASCAL VOC 2012(-点0)和MS COCO(-点101)标准，脚本获取0.5 IoU(默认情况下无标志)和0.75 IoU (-iou_thresh 0.75)的mAP。</p><p id="2a45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该脚本提供了:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mu"><img src="../Images/632453bb42af9d761dbf9e86216557dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DwApYzymGoQsMce9QEugRQ.png"/></div></div></figure><p id="f933" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个文件包含以下信息:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="d0e2" class="kp je hi kl b fi kq kr l ks kt">net.optimized_memory = 0 <br/>mini_batch = 1, batch = 16, time_steps = 1, train = 0</span><span id="ab9a" class="kp je hi kl b fi mt kr l ks kt">seen 64, trained: 64 K-images (1 Kilo-batches_64)</span><span id="a63d" class="kp je hi kl b fi mt kr l ks kt">calculation mAP (mean average precision)...</span><span id="fbff" class="kp je hi kl b fi mt kr l ks kt">detections_count = 136, unique_truth_count = 109  <br/> rank = 0 of ranks = 136 <br/> rank = 100 of ranks = 136 <br/>class_id = 0, name = Nutria, ap = 91.94%     (TP = 99, FP = 4)</span><span id="0677" class="kp je hi kl b fi mt kr l ks kt">for conf_thresh = 0.25, precision = 0.96, recall = 0.91, F1-score = 0.93 <br/> for conf_thresh = 0.25, TP = 99, FP = 4, FN = 10, average IoU = 75.43 %</span><span id="2a35" class="kp je hi kl b fi mt kr l ks kt">IoU threshold = 50 %, used Area-Under-Curve for each unique Recall <br/> mean average precision (mAP@0.50) = 0.919386, or 91.94 %</span><span id="d416" class="kp je hi kl b fi mt kr l ks kt">Set -points flag:<br/> `-points 101` for MS COCO <br/> `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) <br/> `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset<br/>net.optimized_memory = 0 <br/>mini_batch = 1, batch = 16, time_steps = 1, train = 0</span><span id="f698" class="kp je hi kl b fi mt kr l ks kt">seen 64, trained: 64 K-images (1 Kilo-batches_64)</span><span id="8fa6" class="kp je hi kl b fi mt kr l ks kt">calculation mAP (mean average precision)...</span><span id="cd38" class="kp je hi kl b fi mt kr l ks kt">detections_count = 136, unique_truth_count = 109  <br/> rank = 0 of ranks = 136 <br/> rank = 100 of ranks = 136 <br/>class_id = 0, name = Nutria, ap = 49.81%     (TP = 67, FP = 36)</span><span id="8ad2" class="kp je hi kl b fi mt kr l ks kt">for conf_thresh = 0.25, precision = 0.65, recall = 0.61, F1-score = 0.63 <br/> for conf_thresh = 0.25, TP = 67, FP = 36, FN = 42, average IoU = 54.34 %</span><span id="0e9d" class="kp je hi kl b fi mt kr l ks kt">IoU threshold = 75 %, used Area-Under-Curve for each unique Recall <br/> mean average precision (mAP@0.75) = 0.498097, or 49.81 %</span><span id="e25c" class="kp je hi kl b fi mt kr l ks kt">Set -points flag:<br/> `-points 101` for MS COCO <br/> `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) <br/> `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset<br/>net.optimized_memory = 0 <br/>mini_batch = 1, batch = 16, time_steps = 1, train = 0</span><span id="4000" class="kp je hi kl b fi mt kr l ks kt">seen 64, trained: 64 K-images (1 Kilo-batches_64)</span><span id="09c8" class="kp je hi kl b fi mt kr l ks kt">calculation mAP (mean average precision)...</span><span id="b066" class="kp je hi kl b fi mt kr l ks kt">detections_count = 136, unique_truth_count = 109  <br/> rank = 0 of ranks = 136 <br/> rank = 100 of ranks = 136 <br/>class_id = 0, name = Nutria, ap = 90.26%     (TP = 99, FP = 4)</span><span id="da9c" class="kp je hi kl b fi mt kr l ks kt">for conf_thresh = 0.25, precision = 0.96, recall = 0.91, F1-score = 0.93 <br/> for conf_thresh = 0.25, TP = 99, FP = 4, FN = 10, average IoU = 75.43 %</span><span id="ee9d" class="kp je hi kl b fi mt kr l ks kt">IoU threshold = 50 %, used 11 Recall-points <br/> mean average precision (mAP@0.50) = 0.902615, or 90.26 %</span><span id="67fb" class="kp je hi kl b fi mt kr l ks kt">Set -points flag:<br/> `-points 101` for MS COCO <br/> `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) <br/> `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset<br/>net.optimized_memory = 0 <br/>mini_batch = 1, batch = 16, time_steps = 1, train = 0</span><span id="b402" class="kp je hi kl b fi mt kr l ks kt">seen 64, trained: 64 K-images (1 Kilo-batches_64)</span><span id="a003" class="kp je hi kl b fi mt kr l ks kt">calculation mAP (mean average precision)...</span><span id="a696" class="kp je hi kl b fi mt kr l ks kt">detections_count = 136, unique_truth_count = 109  <br/> rank = 0 of ranks = 136 <br/> rank = 100 of ranks = 136 <br/>class_id = 0, name = Nutria, ap = 49.67%     (TP = 67, FP = 36)</span><span id="8590" class="kp je hi kl b fi mt kr l ks kt">for conf_thresh = 0.25, precision = 0.65, recall = 0.61, F1-score = 0.63 <br/> for conf_thresh = 0.25, TP = 67, FP = 36, FN = 42, average IoU = 54.34 %</span><span id="e590" class="kp je hi kl b fi mt kr l ks kt">IoU threshold = 75 %, used 11 Recall-points <br/> mean average precision (mAP@0.75) = 0.496749, or 49.67 %</span><span id="8778" class="kp je hi kl b fi mt kr l ks kt">Set -points flag:<br/> `-points 101` for MS COCO <br/> `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) <br/> `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset<br/>net.optimized_memory = 0 <br/>mini_batch = 1, batch = 16, time_steps = 1, train = 0</span><span id="501c" class="kp je hi kl b fi mt kr l ks kt">seen 64, trained: 64 K-images (1 Kilo-batches_64)</span><span id="9753" class="kp je hi kl b fi mt kr l ks kt">calculation mAP (mean average precision)...</span><span id="50f7" class="kp je hi kl b fi mt kr l ks kt">detections_count = 136, unique_truth_count = 109  <br/> rank = 0 of ranks = 136 <br/> rank = 100 of ranks = 136 <br/>class_id = 0, name = Nutria, ap = 92.34%     (TP = 99, FP = 4)</span><span id="e893" class="kp je hi kl b fi mt kr l ks kt">for conf_thresh = 0.25, precision = 0.96, recall = 0.91, F1-score = 0.93 <br/> for conf_thresh = 0.25, TP = 99, FP = 4, FN = 10, average IoU = 75.43 %</span><span id="0dec" class="kp je hi kl b fi mt kr l ks kt">IoU threshold = 50 %, used 101 Recall-points <br/> mean average precision (mAP@0.50) = 0.923423, or 92.34 %</span><span id="5f93" class="kp je hi kl b fi mt kr l ks kt">Set -points flag:<br/> `-points 101` for MS COCO <br/> `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) <br/> `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset<br/>net.optimized_memory = 0 <br/>mini_batch = 1, batch = 16, time_steps = 1, train = 0</span><span id="9a5d" class="kp je hi kl b fi mt kr l ks kt">seen 64, trained: 64 K-images (1 Kilo-batches_64)</span><span id="58f7" class="kp je hi kl b fi mt kr l ks kt">calculation mAP (mean average precision)...</span><span id="ac97" class="kp je hi kl b fi mt kr l ks kt">detections_count = 136, unique_truth_count = 109  <br/> rank = 0 of ranks = 136 <br/> rank = 100 of ranks = 136 <br/>class_id = 0, name = Nutria, ap = 49.90%     (TP = 67, FP = 36)</span><span id="9eef" class="kp je hi kl b fi mt kr l ks kt">for conf_thresh = 0.25, precision = 0.65, recall = 0.61, F1-score = 0.63 <br/> for conf_thresh = 0.25, TP = 67, FP = 36, FN = 42, average IoU = 54.34 %</span><span id="1ba3" class="kp je hi kl b fi mt kr l ks kt">IoU threshold = 75 %, used 101 Recall-points <br/> mean average precision (mAP@0.75) = 0.498992, or 49.90 %</span><span id="0934" class="kp je hi kl b fi mt kr l ks kt">Set -points flag:<br/> `-points 101` for MS COCO <br/> `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) <br/> `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset</span></pre><p id="ac1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将所有文件保存到主机上的磁盘，放在一个文件夹中，并使用Python脚本运行命令:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="a7bb" class="kp je hi kl b fi kq kr l ks kt">python3 prepare.py -msy -s /path/to/folder_with_mAP_files -d /path/to/output/folder</span></pre><p id="fed5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里</p><ul class=""><li id="01f8" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">flag <code class="du ly lz ma kl b">-msy/--mAP_stat_yolo</code>从给定文件夹中获取YOLO的地图统计数据，并将其保存在Excel文件中。</li></ul><p id="ef95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div class="er es mv"><img src="../Images/9822bd59d8a451b0d21ae203bd5f55d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*eNgJJ3U4wL_sqSpArhl0gw.png"/></div></figure><p id="661f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。</strong>平均损耗<br/>为了获得平均损耗动态，它在训练期间如何变化，是下降还是上升，在主机上保存txt-file training_output.txt并运行以下命令:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="49b4" class="kp je hi kl b fi kq kr l ks kt">python3 prepare.py -s /path/to/folder/with/output/file -tsy training_output.txt -d /path/to/output/folder</span></pre><p id="a0fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里</p><ul class=""><li id="9dfc" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">flag <code class="du ly lz ma kl b">-tsy/--train_stat_yolo</code>从给定的文件夹中获取YOLO的训练统计数据，并将其保存在Excel中。</li></ul><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mw"><img src="../Images/3d25eff50f1f9b3213240be9bf471b6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bIP0oolezgyxNV20ZsJajA.png"/></div></div></figure><p id="b81d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。</strong>有了给定的信息，现在可以通过绘制图表(使用内置的Excel或OpenDocument功能)来查看哪个权重文件更适合使用。</p><p id="e837" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于平均损失:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lc"><img src="../Images/69e952372ad157fc2349aa373a303778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VCd0NIMlKxQtU84C53fSWQ.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">不同批量的型号</figcaption></figure><p id="8de8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于地图:</p><figure class="kg kh ki kj fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lc"><img src="../Images/f48756f893ede76da33558d945bc1840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ppu2_xsUuiyFSfBp9CrXew.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">不同的地图评估使用相同的模型</figcaption></figure><h1 id="7148" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">下载链接</h1><ul class=""><li id="0b1d" class="lp lq hi ih b ii kb im kc iq mx iu my iy mz jc lu lv lw lx bi translated"><a class="ae ku" href="https://drive.google.com/file/d/1mKZt3j1SwwNvFRtZDvXoqRsslQlHmRPM/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">获取地图脚本</a></li><li id="a987" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc lu lv lw lx bi translated"><a class="ae ku" href="https://drive.google.com/drive/folders/1A8Irwnwd0zWqKNfdzP3VrMApSG5PM-yJ?usp=sharing" rel="noopener ugc nofollow" target="_blank">训练模型(一个类/对象——动物海狸鼠)</a></li><li id="1f23" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc lu lv lw lx bi translated"><a class="ae ku" href="https://drive.google.com/drive/folders/1UPiVm6nLWJx88waFsVBqgLyFpZim8g9g?usp=sharing" rel="noopener ugc nofollow" target="_blank">数据集(1000和1500幅图像，一个类别/对象——动物海狸鼠)</a></li><li id="7ab5" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc lu lv lw lx bi translated"><a class="ae ku" href="https://drive.google.com/drive/folders/1UBZ0hBx_XVRsj2xjbKAKZNlzBtIBaiDx?usp=sharing" rel="noopener ugc nofollow" target="_blank">预训练的convnets(在更大的数据集上训练，如ImageNet、COCO) </a></li><li id="ea23" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc lu lv lw lx bi translated"><a class="ae ku" href="https://colab.research.google.com/drive/1_p_iJlwMro7qvDIs80BTOGW37U0YSX1i?usp=sharing" rel="noopener ugc nofollow" target="_blank">YOLO剧本</a></li></ul><h1 id="33c1" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">参考</h1><ol class=""><li id="b6d5" class="lp lq hi ih b ii kb im kc iq mx iu my iy mz jc na lv lw lx bi translated"><a class="ae ku" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">你只看一次:统一的、实时的物体检测</a></li><li id="cd0a" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated">更好、更快、更强</li><li id="8ce1" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated">约洛夫3:一个渐进的改进</li><li id="4af1" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://arxiv.org/pdf/2004.10934.pdf" rel="noopener ugc nofollow" target="_blank"> YOLOv4:物体检测的最佳速度和精度</a></li><li id="34bf" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank">Darknet:C语言中的开源神经网络</a></li><li id="3f71" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank">GitHub上的DarkNet框架(原版)</a></li><li id="241b" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">GitHub上的DarkNet框架(由AlexeyAB派生)</a></li><li id="856e" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://towardsdatascience.com/an-effective-way-of-managing-files-on-google-colab-ac37f792690b?gi=7e7ac2742a2d" rel="noopener" target="_blank">在Google Colab上管理文件的有效方法</a></li><li id="c5d1" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" rel="noopener" href="/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173">目标检测图(平均精度)</a></li><li id="8715" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://makarandtapaswi.wordpress.com/2012/07/02/intuition-behind-average-precision-and-map/" rel="noopener ugc nofollow" target="_blank">直觉背后的平均精度和地图</a></li><li id="f784" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://stackoverflow.com/questions/46094282/why-we-use-map-score-for-evaluate-object-detectors-in-deep-learning" rel="noopener ugc nofollow" target="_blank">为什么我们使用mAp评分来评估深度学习中的对象检测器？</a></li><li id="9fa3" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://towardsdatascience.com/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models-1ea4f67a9dbd?gi=e72771773d3f" rel="noopener" target="_blank">测量目标检测模型—地图—什么是平均精度？</a></li><li id="2382" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" rel="noopener" href="/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d">我们从单次拍摄物体探测器(SSD、YOLOv3)、FPN &amp;焦损失(RetinaNet)中学到了什么？</a></li><li id="383f" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/" rel="noopener ugc nofollow" target="_blank">用OpenCV进行YOLO物体检测</a></li><li id="2034" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://www.pyimagesearch.com/2020/02/10/opencv-dnn-with-nvidia-gpus-1549-faster-yolo-ssd-and-mask-r-cnn/" rel="noopener ugc nofollow" target="_blank">采用NVIDIA GPUs的OpenCV‘dnn ’: YOLO、SSD和Mask R-CNN的速度提高了1549%</a></li><li id="7499" class="lp lq hi ih b ii mb im mc iq md iu me iy mf jc na lv lw lx bi translated"><a class="ae ku" href="https://www.pyimagesearch.com/2017/02/06/faster-video-file-fps-with-cv2-videocapture-and-opencv/" rel="noopener ugc nofollow" target="_blank">使用cv2加快视频文件FPS。视频捕捉和OpenCV </a></li></ol></div></div>    
</body>
</html>