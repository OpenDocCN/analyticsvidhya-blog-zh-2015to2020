<html>
<head>
<title>NLP Techniques with Shakespeare’s Plays</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">莎士比亚戏剧中的自然语言处理技术</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/nlp-techniques-with-shakespeares-plays-d8843ba26a4f?source=collection_archive---------7-----------------------#2020-06-25">https://medium.com/analytics-vidhya/nlp-techniques-with-shakespeares-plays-d8843ba26a4f?source=collection_archive---------7-----------------------#2020-06-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/a4303cf96ff6a49ec508949db3f88f1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1L7zORHMlYdjtfTi7OmbOQ.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">照片由<a class="ae hv" href="https://unsplash.com/@voodoojava?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">马特·里奇</a>在<a class="ae hv" rel="noopener ugc nofollow" target="_blank" href="/s/photos/shakespeare?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"> Unsplash </a>上拍摄</figcaption></figure><div class=""/><div class=""><h2 id="6dea" class="pw-subtitle-paragraph iv hx hy bd b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm dx translated">用Bard清理和分类文本</h2></div><p id="56b8" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">考虑到今天生成的大量文本数据，自然语言处理是数据科学最有趣的方面之一，同时也可能是最挑剔的方面之一。文本数据可能很难处理，因为语言/方言、标点符号、时间段等等而变得复杂。然而，它是一个非常常用的工具——谁在工作中不会遇到自动完成或拼写检查呢？在我的项目中，我想探索如何使用NLP技术来处理文本分类，特别是作者识别。</p><p id="2d6b" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我在这里概述的项目探索了文学中最有趣的问题之一，即莎士比亚戏剧的作者。大多数学者拒绝对他的作者身份提出任何挑战，尽管有一小部分人坚持认为他不具备皇家宫廷的知识，不了解欧洲大陆的地理，也没有接受过写剧本的教育，并提出这些剧本可能是由另一位伊丽莎白时代的剧作家如克里斯托夫·马洛，甚至是弗朗西斯·培根爵士写的。我的目标是创建一个分类模型来区分他的戏剧，并探索可视化这些文本的方法。</p><h1 id="575f" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">数据</h1><figure class="lc ld le lf fd hk er es paragraph-image"><div class="er es lb"><img src="../Images/619fea3a31dfa6f965dbb8da4acef4b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*t4YiuDjsdQyLhdFGKwGwmg.png"/></div></figure><p id="e232" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我的整个数据集包括39部莎士比亚戏剧(这包括两位贵族亲戚和爱德华三世的部分作品)和50部非莎士比亚戏剧。该图表还会让你更好地了解每一类戏剧的长度，包括去除停用词后的字数，以及每一类对语料库的贡献(大致相同，尽管有几个更长的非莎士比亚戏剧)。所有这些都是以。来自古腾堡计划的txt文件。莎士比亚以外的戏剧都是由英国文艺复兴时期的其他剧作家写的，如本·琼生、托马斯·米德尔顿、约翰·弗莱彻和弗朗西斯·博蒙特，他们都在同一时期工作，即16世纪末至17世纪初。在英国文艺复兴时期上演的戏剧很少出版，所以莎士比亚同时代的戏剧更是少之又少。这个数据有一些局限性。首先，我们的莎士比亚戏剧全集的样本量意味着我只有39个数据点用于我们的目标类。此外，非莎士比亚戏剧也遭受自己的作者问题，其中一些已经在莎士比亚的名字下出版，并被列在古登堡计划下。最后，相对缺乏对非莎士比亚戏剧的编辑和拼写修改，一些单词在不同的戏剧中可能会有不同的拼写。</p><p id="5148" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在进行数据清理之前，我随机地将数据分成训练/测试文件夹，在训练集中产生71个文本，在测试集中产生18个文本(20%)。我这里并不是在处理一个显著的类别不平衡——我们的目标包括我们数据的43%。</p><h1 id="74e1" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">清理数据</h1><p id="7f3c" class="pw-post-body-paragraph jn jo hy jp b jq lg iz js jt lh jc jv jw li jy jz ka lj kc kd ke lk kg kh ki hb bi translated">下面是一个上传的. txt片段的例子。在许多情况下，在我想要删除的文本前后都有大量注释——一些编辑笔记、描述该作品及其出版历史的文章、透露各版本不同拼写和行差异的脚注，以及古腾堡计划插入的描述发行限制的法律语言。每部剧都有这种不同格式的笔记，所以我编辑了文本，从剧中人开始，在许多(但不是所有)文本包含的古腾堡计划**结尾* *行之前结束。为了绝对确保我删除了任何中间或结尾的音符，我传递了用于删除的单词(例如莎士比亚'，'古腾堡'，'电子')剥离任何挥之不去的不需要的线。</p><pre class="lc ld le lf fd ll lm ln lo aw lp bi"><span id="e1cc" class="lq kk hy lm b fi lr ls l lt lu"> 'That I neither feel how she should be loved, nor know how she\n',<br/> 'should be worthy, is the opinion that fire cannot melt out of me: I will\n',<br/> 'die in it at the stake.\n',</span></pre><p id="ca81" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来，我删除了停用词和标点符号，包括由Bryan Bumgardner提供的伊丽莎白时代的停用词，在这里可以找到。然后，我将句子分割开来，使用词性标注器，以便将每个单词词条化。然后，对每个词汇化的游戏进行符号化，以创建用于分类模型的数据的TF-IDF表示。TF-IDF(term frequency-inverse document frequency)是语料库中所有单词的常用矢量化表示，通过描述一个单词在单个文本中的频率以及包含该单词的文档数量，来显示该单词对语料库有多重要/稀有。这种变换的结果形状是一个71×41，361的矩阵。我还通过创建数据的二元模型表示来减小这些向量的大小(例如，“but，soft”，“soft，what”，“what，light”，“light，from”)；我还使用了一个使用scikit-learn的截断SVD的降维TF-IDF，它对文本的矩阵表示进行线性降维，可以有效地处理稀疏矩阵。得到的简化矩阵保留了80%的解释方差。</p><h1 id="d402" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">探索性数据分析</h1><p id="de76" class="pw-post-body-paragraph jn jo hy jp b jq lg iz js jt lh jc jv jw li jy jz ka lj kc kd ke lk kg kh ki hb bi translated">虽然除了课文本身，我没有其他的特点，但是有很多方法可以探索我们课堂上的差异。很可能莎士比亚最常用的词十有八九与他的同龄人非常不同。您可以在下面看到，在我们的两个类中，用于训练数据的20个最常见的标记是完全不同的，重叠部分比我预期的还要少。或许基于此，人们可以推断莎士比亚比他的同龄人写了更多的历史剧(或者至少是涉及宫廷的戏剧)。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div class="er es lv"><img src="../Images/3cf279d4635ae6763b8cc81687470589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*G0a8_MN9fM59pXYnyGIYiA.png"/></div></figure><p id="a18d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">虽然我在完整的TF-IDF中使用了41，361个“特征”,但我使用了t-分布式随机邻居嵌入(t-SNE)来在二维空间中可视化这一高维数据，并查看我们的类如何彼此相关地分布，如下所示。我们的班级代表的领域之间似乎有一些重叠，但这为我的分类能力带来了希望。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div class="er es lw"><img src="../Images/861b533a0f37a8f59e2ef47d833f9c42.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*k9a3vUaqVRHotYsMzcSWww.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">t-SNE用于训练数据的一元模型</figcaption></figure><p id="7055" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">使用t-SNE的另一种方法是创建一个Word2Vec模型，这是一个双层神经网络，可以为语料库中的每个单词生成一个矩阵，并根据单词共现的可能性生成相似性。我使用了一个非常宽的<strong class="jp hz">窗口</strong>20(与每个单词的距离)来确定共现，并为每个单词创建了一个向量，大小为<strong class="jp hz">100，用于每个类的可视化，以及一个200个单词的<strong class="jp hz"> min_count </strong>(出现次数少于200次的单词被忽略)。我们可以在下面看到使用我们训练集中的所有文本得到的可视化结果，并使用这些向量根据我们的文本提取最相似的单词。例如，与爱情最相似的5个词是“心”、“我的”、“思想”、“公平”和“欲望”。</strong></p><figure class="lc ld le lf fd hk er es paragraph-image"><div class="er es lx"><img src="../Images/2e8857be578d279732aea25b8822a4ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*ru-3-8l3L2Oy2RwtlkoB_g.png"/></div></figure><p id="b478" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">虽然看到T-SNE可视化如何表达我们数据中的相似性很有趣，但重要的是要注意，作为一种降维算法，不同的运行会根据我们的Word2Vec模型中设置的困惑和其他超参数产生不同的结果，因此我们可以继续探索这些图形如何最好地表达这种规模的数据。进一步阅读t-SNE和绘图类</p><h1 id="87f2" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">分类模型</h1><p id="f545" class="pw-post-body-paragraph jn jo hy jp b jq lg iz js jt lh jc jv jw li jy jz ka lj kc kd ke lk kg kh ki hb bi translated">我使用了前面提到的三个TF-IDF表示来构建下面的模型，以及使用手套重量的单词嵌入数据集。GloVe(单词表示的全局向量)是斯坦福大学建立的NLP方法，包含预先训练的权重，以便生成我们语料库的数据表示。我使用网格搜索来调整随机森林和XGBoost的超参数，并使用管道将手套嵌入传递给XGBoost和RNN。</p><ul class=""><li id="1720" class="ly lz hy jp b jq jr jt ju jw ma ka mb ke mc ki md me mf mg bi translated">随机森林</li><li id="dc86" class="ly lz hy jp b jq mh jt mi jw mj ka mk ke ml ki md me mf mg bi translated">朴素贝叶斯(多项式和补码)</li><li id="6570" class="ly lz hy jp b jq mh jt mi jw mj ka mk ke ml ki md me mf mg bi translated">支持向量机(具有线性核)</li><li id="73b6" class="ly lz hy jp b jq mh jt mi jw mj ka mk ke ml ki md me mf mg bi translated">XGBoost</li><li id="ab33" class="ly lz hy jp b jq mh jt mi jw mj ka mk ke ml ki md me mf mg bi translated">LSTM递归神经网络</li></ul><p id="a24f" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">最成功的模型是使用我们的unigrams的完整TF-IDF表示的XGBoost，以及使用预训练手套权重的递归神经网络，这两个模型在我们的测试和训练数据上都实现了100%的准确性，随后是使用完整TF-IDF的随机森林和网格搜索，这实现了94%的准确性，并且在我们的目标类上实现了94%的F1分数。基于单词嵌入的XGBoost，最初担心手套重量不适合我的数据，但使用RNN证明了这一点。您可以在下面看到这些模型的结果，尽管许多其他模型要么由于表现不佳而被放弃，类似于具有降维TF-IDF的随机森林，它在我的许多模型中表现不佳，以及RNN，它被反复调整以确保它不会过度适应我的训练/验证数据。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mm"><img src="../Images/1fefa5ee06820312f289162da5491405.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M2g9NpEfYXa4yJw2TJP2kw.png"/></div></div></figure><h1 id="1525" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">主题建模</h1><p id="63fd" class="pw-post-body-paragraph jn jo hy jp b jq lg iz js jt lh jc jv jw li jy jz ka lj kc kd ke lk kg kh ki hb bi translated">最后但同样重要的是，我使用Gensim的潜在Dirichlet关联工具来探索执行无监督学习的可能性——在这种情况下，主题建模。下面是一个例子，它使用Gensim的pyLDAvis将两个类中的所有文本结合在一起，为LDA模型提供了一个交互式仪表板。这个主题将“国王”作为这个主题最重要的符号，这并不奇怪，因为它也从许多政治/历史剧(爱德华三世，李尔王，亨利二世)中引入了角色名称。在右边，我们还可以调整λ/relevance，允许我们调整术语在每个主题中出现的概率和lift之间的权衡，lift是术语在主题中出现的次数与它在语料库中其他地方出现的次数的比率。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mn"><img src="../Images/22a99cf26384f0a64319f9eed67dd6e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K8kkbe8InEC7xa1GQy2buA.png"/></div></div></figure><p id="c923" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">值得注意的是，随着主题数量在3到30之间的变化，我的连贯分数从未达到0.36以上，所以尽管这些主题在将某些角色联系在一起方面很有趣，但这些都不是高质量的可解释主题，甚至与我们的7个主题也有一些重叠。</p><h1 id="2d46" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">结论</h1><p id="10a8" class="pw-post-body-paragraph jn jo hy jp b jq lg iz js jt lh jc jv jw li jy jz ka lj kc kd ke lk kg kh ki hb bi translated">这些文本为探索文本清理、可视化、分类建模和主题建模的NLP技术提供了一种令人兴奋的方式。作者归属只是处理文本数据的一种方式，这些技术适用于一切，从标记假新闻/垃圾邮件，识别整个文学作品的写作风格相似性，或捕捉抄袭。即使使用较小的语料库，这一过程的转换和产生的数据集使用不是一个而是两个模型在我们的数据上产生100%的准确性。展望未来，有许多方法可以扩展这个项目——例如，随着新文本继续添加到古腾堡计划，扩展我们的非目标类，或者甚至可以为莎士比亚爱好者创建一个推荐系统来找到新的阅读材料。</p><p id="a4e2" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这个项目的完整代码可以从Github 上的<a class="ae hv" href="https://github.com/Kaguilar1222/Module5_NLP" rel="noopener ugc nofollow" target="_blank">获得。</a></p><h1 id="b59c" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">其他来源:</h1><p id="c2f4" class="pw-post-body-paragraph jn jo hy jp b jq lg iz js jt lh jc jv jw li jy jz ka lj kc kd ke lk kg kh ki hb bi translated">赛义德、沙欣和马可·斯普雷特。“全文还是摘要？使用潜在的狄利克雷分配检查主题连贯性分数。2017年IEEE数据科学与高级分析国际会议(DSAA)，2017，doi:10.1109/dsaa.2017.61</p><p id="79eb" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">"用Python和Gensim进行主题建模."<em class="mo">机器学习加</em>，2020年4月16日，<a class="ae hv" href="http://www.machinelearningplus.com/nlp/topic-modeling-gensim-python." rel="noopener ugc nofollow" target="_blank">www . Machine Learning Plus . com/NLP/topic-modeling-gensim-python。</a></p></div></div>    
</body>
</html>