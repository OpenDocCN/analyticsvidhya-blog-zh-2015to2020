<html>
<head>
<title>Understanding SimCLR — A Simple Framework for Contrastive Learning of Visual Representations with Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解sim clr——用代码对比学习视觉表示的简单框架</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-simclr-a-simple-framework-for-contrastive-learning-of-visual-representations-d544a9003f3c?source=collection_archive---------2-----------------------#2020-04-04">https://medium.com/analytics-vidhya/understanding-simclr-a-simple-framework-for-contrastive-learning-of-visual-representations-d544a9003f3c?source=collection_archive---------2-----------------------#2020-04-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b13e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">他的论文[1]为视觉表征的对比学习提出了一个简单的框架(作者称之为<strong class="ih hj"> SimCLR </strong>)。这些视觉表示是向量，线性分类器可以在这些向量上被训练来解决像图像分类这样的问题。我们知道，我们可以通过在ImageNet等标记数据集上训练ResNet等深度学习模型来学习这些视觉表示。但是标记和注释数据是一个耗时的过程，需要大量的劳动，所以我们希望尽可能地避免它。<a class="ae jm" href="https://paperswithcode.com/task/self-supervised-image-classification" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">自我监督学习</strong> </a>是一种通过发现和利用不同输入特征之间的相关性来自动标记训练数据的学习技术。在没有人类监督的情况下，我们如何学习这些视觉表征？对比学习是本文提出的答案。让我们借助一个例子来看看它是什么。</p><h1 id="c88a" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">对比学习</h1><p id="38fa" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">对比学习法，通过<strong class="ih hj">对比正面对与负面对</strong>来学习表征。我们通过一个例子来了解一下这些正负对是什么。</p><p id="ab06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们有下面一批25张图片。这些是来自5个类别的图像，即飞机、汽车、狗、大象和猫，但请注意，这些标签不会用于训练整个模型。然而，在学习算法时，我们将使用这些标签进行可视化。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kq"><img src="../Images/d1c4d3ea5f9bab00221953c34c32091f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zhhEyNSH6vf23kIQDuzLsQ.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">来自该<a class="ae jm" href="https://github.com/thunderInfy/imagenet-5-categories" rel="noopener ugc nofollow" target="_blank">数据集</a>的一批25幅示例图像</figcaption></figure><p id="641e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这25张图片的尺寸都是224 x 224。我们应用两个数据增强操作的组合，第一个是<strong class="ih hj">随机裁剪并将</strong>调整到224 x 224，第二个是<strong class="ih hj">颜色失真</strong>，每个图像两次，以获得两个新图像。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lg"><img src="../Images/b811ab74195a8d1d7df0f6db4f8faaa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FJIe08DzfhKjVk5adGnVSA.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">从左到右:原始图像，通过在原始图像上应用两次随机裁剪、调整大小和颜色变形的组合而获得的两个图像。</figcaption></figure><p id="66a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在PyTorch中应用这些数据扩充的代码如下。</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="bc9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们对我们的25个图像中的每一个应用这种数据增强的组合，以获得50个增强的图像。之后我们会处理这50张增强图像。在这些图像中，<strong class="ih hj">我们将正对定义为从同一幅原始图像</strong>中得到的那些图像对。所以，有25个正对。通常，对于一批N幅图像，我们将得到2N幅增强图像。从这2N幅图像中给定一个特定的正对(I，j)，我们认为<strong class="ih hj">另外2(N-1)幅图像是I和j的负例。</strong></p><p id="70a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，现在我们知道了什么是积极和消极配对，让我们看看作者是如何利用这些来学习视觉表征的。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es lj"><img src="../Images/b4fe1eb1bedcbe3b8a694f61d25a008f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*SWN5j9iFBFmDDDSLCwAaHg.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated">来源:[1]</figcaption></figure><p id="9848" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，到目前为止，我们已经有了这些增强图像。我们在神经网络中输入每个正对(如上图所示的f和g的组合)，我们得到矢量z_i和z_j。我们<strong class="ih hj">最大化这些矢量之间的一致性</strong>。我们希望同一幅图像的不同外观有相似的表现。</p><p id="14d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些向量之间的一致性通过最小化这些向量之间的对比损失(<strong class="ih hj">归一化温度标度交叉熵损失</strong>或<strong class="ih hj"> NT-Xent </strong>来最大化。我们来详细了解一下这个损失。</p><h1 id="787f" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">归一化温度标度交叉熵损失</h1><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="lk li l"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated">gif来自giphy.com</figcaption></figure><p id="de9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让sim表示余弦相似度函数，如下所示。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es ll"><img src="../Images/dbbe034873b45cc73d372ea69ebce281.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*qkJxrSmjMVkKbAkoKIshQQ.jpeg"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">余弦相似性</figcaption></figure><p id="ddf0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，正对实例(I，j)的NT-Xent损耗定义为</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lm"><img src="../Images/75d60494e153278d781ecb3deced8658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ru0RB4hM-UB6_hSuMBzPlg.jpeg"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">正示例对(I，j)的NT-Xent损失函数</figcaption></figure><p id="2d70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过使用对数函数的性质和一些代数操作来简化上述损失函数形式，我们得到了稍微更容易理解的形式。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es ln"><img src="../Images/96bade01d80932e8aaab92ea66ad1a3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r4IugZoKm1lvXiLpyEy5IQ.jpeg"/></div></div></figure><p id="4ceb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到，通过最小化正示例对(I，j)的NT-Xent损失，我们不仅<strong class="ih hj">使向量z_i更类似于z_j </strong>，而且<strong class="ih hj">使其不同于所有其他向量。</strong></p><p id="8d5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，损耗是不对称的，即l_{i，j}！= l_{j，i}，因为分子中的和是不同的。因此，为了计算最终损失，我们计算所有正对(分别取(I，j)和(j，I ))的损失，然后取平均值。</p><p id="97ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以把τ看作一个温度超参数，它使损失函数形式更易于表达。它的各种价值可以尝试，作者也这样做了。</p><p id="15c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是PyTorch中这个损失函数的代码。</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="99a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">理解上面的代码(如果你读完代码后理解了代码，请随意略读解释):</p><p id="4836" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的代码中，a和b是每个都包含N个增强图像表示的向量，并且在I从1到N的意义上保持顺序，a[i]和b[i]一起是正对。我们看到，在损失函数中，我们需要向量对之间的相似性。我们知道两个向量之间的相似性是它们各自单位向量之间的点积。所以我们在a和b中找到每一行的单位向量，并将结果存储在a_cap和b_cap中。请注意，我们需要从2N个示例中选择的所有对之间的相似性。因此，我们首先连接a_cap和b_cap以获得2N个示例的单个向量a_cap_b_cap。现在最关键的部分是理解<strong class="ih hj">a _ cap _ b _ cap与a_cap_b_cap_transpose的矩阵乘积给出了相似性矩阵</strong>，其第I，j项表示表示I和表示j之间的相似性，其中I和j都从1变化到2N。我希望代码的其余部分从中间变量的名称中可以看得很清楚。</p><p id="d750" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑从两个不同的汽车图像中获得的以下四个正对。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kq"><img src="../Images/06a6c2ebf42501d45cd3c5c8afba9023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2F2NIfgt9SplAF6U1IvRnA.png"/></div></div></figure><p id="798f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过最大化正对表示之间的一致性，我们本质上正在做的是<strong class="ih hj">我们正在制作汽车和汽车部件的表示(因为随机裁剪)，不太强调颜色(因为颜色抖动)，彼此靠近。这导致汽车整体表示之间的相似性增加。</strong></p><h1 id="b5ee" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结果</h1><p id="24b4" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">我们在我们的<a class="ae jm" href="https://github.com/thunderInfy/imagenet-5-categories" rel="noopener ugc nofollow" target="_blank">数据集</a>上使用NT-Xent损失函数训练一个resnet。它包含1250幅用于训练的图像(每类250幅)和250幅用于测试的图像(每类50幅)。</p><p id="9740" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">resnet的代码如下。我们使用resnet18模型，并用一些其他完全连接的层替换顶层。</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="lh li l"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated">Resnet 18，最后一层用非线性分类器代替</figcaption></figure><p id="fddd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练上面的resnet时，我们得到了下面的NT-Xent丢失与历元数的关系图。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es lo"><img src="../Images/d28ff9cab3afd80cdf59c5119b9295ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*0X6c2P8a4tsR5avUMyOH4g.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated">训练损失与时期数的关系图</figcaption></figure><p id="d16d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们从我们的训练数据中随机选择10%的例子，我们将揭示这些例子的标签，以便在我们学习的表示之上训练线性分类器。可以这样想:假设你第一次看到<a class="ae jm" href="https://en.wikipedia.org/wiki/Devanagari_numerals" rel="noopener ugc nofollow" target="_blank">梵文数字</a>，你不知道哪个数字代表哪个数字。你仍然可以在这组数字中辨认出十组。所以，为了识别梵文数字，你只需要知道哪个簇对应哪个数字。因此，需要更少的标记，因为数字的某种聚类表示已经在你的脑海中了。</p><p id="759a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们为我们的测试(250个图像)可视化最后一层向量(在我们的例子中是25维的),并使用t-SNE来训练(仅10% — 125个图像)。在下面的散点图中，我们使用标签，使属于同一类别的图像具有相同的颜色。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lp"><img src="../Images/a5dd7c897d2d88871b3d87ad7cca925c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HZ99kyKcVszGb7144AAyww.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">最后一层向量的t-SNE可视化</figcaption></figure><p id="4532" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是倒数第二层向量(在我们的例子中是50维)的t-SNE可视化。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lq"><img src="../Images/ead7713aa12c9ce1b451f9f4315c109e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0gFPwT6cEplNuRzmKBX4uw.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">倒数第二层向量的t-SNE可视化</figcaption></figure><p id="1172" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在上面的图像中看到一些星团，这是一个很好的迹象。</p><p id="6322" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">获得上述SNE霸王龙图像的代码如下。</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="3489" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在在从倒数第二层(50维)获得的表示上训练线性分类器。线性分类器的代码如下。</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="79c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们获得了下面的训练和测试精度图&amp;交叉熵损失与历元数的关系。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lr"><img src="../Images/79a7ae7681b6220ef54d3582083eb72c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JiC8JkTNzViMM93GaM59mg.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">在10%标记的训练数据上训练线性分类器时获得的准确度和损失对时期数的图</figcaption></figure><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es ls"><img src="../Images/417d75c1cf03c7fdb9eb60af556b689f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NX-rdRfeFzvHZmYYOBqjkg.png"/></div></div></figure><h2 id="e838" class="lt jo hi bd jp lu lv lw jt lx ly lz jx iq ma mb kb iu mc md kf iy me mf kj mg bi translated">与监督分类器的比较</h2><p id="890d" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">为了理解获得的结果有多好，我们将它们与从监督分类器(Resnet-18模型)获得的结果进行比较。表1显示了比较结果。监督分类器的精度和损失图如下。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es mh"><img src="../Images/ed2e12d9c550ea8319564e1c933afff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MY2Y6vkJJsoPmEQSBI_AfQ.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">精度和损失与历元数的关系图</figcaption></figure><p id="6d7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大约在180个历元时，精确度突然增加，这时我们关闭了数据扩充，之后模型开始过度拟合。我们存储了具有最佳测试准确性的模型。</p><p id="0703" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到监督和非监督分类器之间有14%的精度差距。我们使用256的批量和Resnet-18模型。<strong class="ih hj">如果我们使用更大的批量和更大更宽的模型，这14%的差距可以进一步缩小，因为与监督方法相比，SimCLR从这些方法中获益更多</strong>。但这需要更强的计算能力(<strong class="ih hj">动量对比和来自SimCLR (MoCo-V2)的想法可以帮助我们做到这一点——我写了一篇关于它的博文</strong> <a class="ae jm" rel="noopener" href="/analytics-vidhya/simclr-with-less-computational-constraints-moco-v2-in-pytorch-3d8f3a8f8bf2"> <strong class="ih hj">这里</strong> </a>)。</p><p id="c8f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文的代码在<a class="ae jm" href="https://github.com/thunderInfy/simclr" rel="noopener ugc nofollow" target="_blank"> this GitHub repo </a>中。</p><h1 id="e7d3" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">参考</h1><p id="c083" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">[1] <a class="ae jm" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank">陈婷、西蒙·科恩布鲁斯、穆罕默德·诺鲁齐和杰弗里·e·辛顿。视觉表征对比学习的简单框架。arXiv预印本arXiv:2002.05709，2020</a>；[ <a class="ae jm" href="http://cse.iitkgp.ac.in/~arastogi/papers/simclr.pdf" rel="noopener ugc nofollow" target="_blank">由我突出显示</a></p></div><div class="ab cl mi mj gp mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="hb hc hd he hf"><p id="1e1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">更新:</strong></p><ul class=""><li id="7144" class="mp mq hi ih b ii ij im in iq mr iu ms iy mt jc mu mv mw mx bi translated"><a class="ae jm" rel="noopener" href="/@aditya.rastogi/the-projection-head-in-simclr-b73cfc447854?source=friends_link&amp;sk=46b5fbfc3240224a417fe3edfddf1fa5">与选择正确的投影头</a>相关的更新导致resnet-18 SimCLR(含10%标签)模型在测试集上的<strong class="ih hj">精度提高了65.2% </strong>。</li><li id="a71e" class="mp mq hi ih b ii my im mz iq na iu nb iy nc jc mu mv mw mx bi translated">我使用Google Colab来运行这个SimCLR代码。<a class="ae jm" href="https://colab.research.google.com/drive/1YaLNsuaVeimgi-d473wk96wCD0BGecPd" rel="noopener ugc nofollow" target="_blank">这是Colab的笔记本链接。</a></li></ul><p id="07b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您花时间阅读本文。</p></div></div>    
</body>
</html>