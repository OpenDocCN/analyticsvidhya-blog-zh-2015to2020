<html>
<head>
<title>Spark Performance Tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火花性能调谐</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spark-performance-tuning-77c911117d9?source=collection_archive---------11-----------------------#2020-03-14">https://medium.com/analytics-vidhya/spark-performance-tuning-77c911117d9?source=collection_archive---------11-----------------------#2020-03-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c2f909252f3dc30421de2f9976d6d5c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AkHATU__jquKdgsj6HXsWg.jpeg"/></div></div></figure><p id="665b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Apache Spark是一个统一的分析引擎，已经被各行各业的企业迅速采用。</p><p id="491b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在内存中处理数据的能力比使用MapReduce处理数据快10倍。但是，如果spark作业没有得到适当的调整，可能会导致作业失败。</p><p id="e48c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们进入spark调优之前，让我们回顾一下它的架构。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es jo"><img src="../Images/afde587281ce3d826aa7b549a74dc53b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*EzZs4uEuO30lV51KV07_RA.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">火花建筑</figcaption></figure><p id="5249" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark有一个驱动程序和许多worker节点，这些节点有执行程序来运行任务。输入数据被分成多个分区，每个分区充当一个由执行器执行的任务。</p><p id="f5f3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于大多数Spark计算的内存性质，Spark程序可能会受到集群中任何资源的限制:CPU、网络带宽或内存。</p><p id="0c7e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">优化火花作业有多种技术:</p><ul class=""><li id="befc" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf bi translated">内存调整/垃圾收集调整</li><li id="1995" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">数据序列化</li><li id="dc87" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">集群配置</li><li id="9996" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">并行度</li><li id="4030" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">广播</li><li id="4324" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">静态数据</li><li id="e025" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">数据局部性</li></ul><h1 id="9d10" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">记忆问题</h1><p id="3969" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">在优化内存问题时，有三个考虑因素:</p><ul class=""><li id="25b4" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf bi translated">对象使用的内存量</li><li id="48a6" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">访问这些对象的成本</li><li id="01e9" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">垃圾收集的开销</li></ul><p id="68ed" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">默认情况下，java对象访问速度很快，但是它们很容易比原始数据多消耗2-5倍的空间。</p><p id="e737" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每个不同的Java对象都有一个“对象头”，大约16个字节，包含诸如指向其类的指针之类的信息。对于一个只有很少数据的对象(比如一个Int字段)，这可能比数据大。</p><p id="9506" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Java字符串在原始字符串数据上有大约40字节的开销(因为它们将字符串数据存储在一个字符数组中并保存额外的数据，如长度)，并且由于string内部使用UTF-16编码，每个字符存储为两个字节。因此，一个10个字符的字符串可以轻松地消耗60个字节。</p><p id="204d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">常见的集合类(如HashMap和LinkedList)使用链接数据结构，其中每个条目都有一个“包装器”对象(如Map。条目)。这个对象不仅有一个头，还有指向列表中下一个对象的指针(通常每个指针有8个字节)。</p><h2 id="2eac" class="lo km hi bd kn lp lq lr kr ls lt lu kv jb lv lw kz jf lx ly ld jj lz ma lh mb bi translated">内存管理概述</h2><ul class=""><li id="0586" class="jx jy hi is b it lj ix lk jb mc jf md jj me jn kc kd ke kf bi translated">Spark中的内存使用主要分为两类:<strong class="is hj">执行和存储。</strong>用于计算的执行内存，如洗牌、连接、聚合、排序。存储内存用于缓存。</li><li id="b2b6" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">在Spark中，执行共享一个统一的区域(M)。当不使用执行内存时，存储可以获取所有可用内存，反之亦然</li><li id="3e1d" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">执行内存可以驱逐存储内存</li><li id="f427" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">在(M)内存中有一个子区域(R ),其中执行内存不能驱逐存储内存</li><li id="85d0" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">存储内存无法收回执行内存</li><li id="c691" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated"><strong class="is hj"><em class="mf">spark . memory . fraction</em></strong><em class="mf"/>将大小(M)表示为JVM堆的分数(默认为0.6)</li><li id="0290" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated"><strong class="is hj"><em class="mf">spark . memory . storage fraction</em></strong><em class="mf"/>将大小(R)表示为M的一部分(默认值为0.5)是M内的存储空间，其中缓存的块不会被执行驱逐</li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/bcea557814c077bbc19286a63772aa0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*9YVILgK87f8KHbnAGplRNg.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">火花存储器管理</figcaption></figure><ul class=""><li id="c471" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf bi translated">如果在你的项目中使用的缓存很少，考虑减少<strong class="is hj">spark . memory . storage fraction</strong>的值</li></ul><h1 id="3d28" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">调整数据结构</h1><p id="f04d" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">减少内存消耗的方法是避免增加开销的Java特性，比如基于指针的数据结构和包装对象。</p><ul class=""><li id="7a29" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf bi translated">设计您的数据结构，以优先选择原始时间，而不是像HashMap这样的集合类</li><li id="335c" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">考虑对键使用数字id而不是字符串</li><li id="b7ae" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">如果你的RAM少于32GB，设置JVM标志<em class="mf">–xx:+UseCompressedOops</em>使指针为四字节而不是八字节。你可以在<em class="mf"> spark-env.sh </em>中添加这些选项</li><li id="8aa4" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">当对象仍然太大时，减少内存存储的一个更简单的方法是以<strong class="is hj">序列化形式</strong>存储它们，比如MEMORY_ONLY_SER</li><li id="0bd0" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">以序列化形式存储对象的唯一缺点是访问时间较慢，因为要反序列化每个对象</li></ul><h1 id="d457" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">数据序列化</h1><p id="6f46" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">序列化在任何分布式应用程序的性能中扮演着重要的角色。将对象序列化的速度较慢或消耗大量字节的格式将大大降低计算速度</p><p id="ddf4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark提供了两个序列化库:</p><ul class=""><li id="dbcc" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf bi translated"><strong class="is hj"> Java序列化</strong>:默认情况下，Spark使用Java的ObjetOutputStream框架序列化对象，可以与您创建的实现<a class="ae mh" href="http://docs.oracle.com/javase/6/docs/api/java/io/Serializable.html" rel="noopener ugc nofollow" target="_blank"> java.io.Serializable </a>的任何类一起工作。您还可以通过扩展<a class="ae mh" href="http://docs.oracle.com/javase/6/docs/api/java/io/Externalizable.html" rel="noopener ugc nofollow" target="_blank"> java.io.Externalizable </a>来更紧密地控制序列化的性能。Java序列化很灵活，但通常很慢，并且会导致许多类的大型序列化格式</li><li id="2461" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated"><strong class="is hj"> Kryo序列化:</strong> Spark还可以使用Kryo库(版本2)更快地序列化对象。Kryo比Java序列化要快得多，也紧凑得多(通常是Java序列化的10倍)，但是它并不支持所有的可序列化类型，并且需要你提前<em class="mf">注册</em>你将在程序中使用的类以获得最佳性能。</li><li id="b289" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">您可以通过使用Spark Conf初始化作业并调用<em class="mf"> conf.set("spark.serializer "，" org . Apache . Spark . serializer . kryoserializer ")</em>来切换到Kryo</li><li id="73d1" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">它配置序列化程序，该序列化程序不仅用于在工作节点之间传送数据，还用于将rdd序列化到磁盘</li><li id="75fd" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">用Kryo注册你自己的类，使用<em class="mf"> registerKryoClasses </em>方法</li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/4f0e02eb0977b462c8b8029362bf2721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KKUxkvDfckQvoKTZh81C4g.png"/></div></div></figure><h1 id="3b3b" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">垃圾收集调整</h1><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/eea8e324b55b0bff66b77fe60a881fed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lX5o8Ea24UB2OeudlvvE3A.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">碎片帐集</figcaption></figure><ul class=""><li id="9963" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf bi translated">如果在任务完成之前多次调用全垃圾收集，这意味着没有足够的内存来执行任务</li><li id="7782" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">如果有两个次要GC和两个次要GC，分配更多的Eden内存会有所帮助。如果Eden内存的大小是E，那么我们可以将年轻一代的大小设置为–Xmn =(4/3 * E)</li><li id="c54e" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">如果OldGen快满了，通过降低<em class="mf"> spark.memory.fraction. </em>来减少用于缓存的内存量。此外，考虑减小年轻一代的大小</li><li id="2a27" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">如果我们的任务是从HDFS读取数据，任务使用的内存量可以通过HDFS块的大小来估计。通常，解压缩块的大小通常是块大小的2到3倍。因此，对于3或4个任务的工作空间，以及128MB的HDFS块大小，我们可以估计Eden空间为(3*4*128 MB)</li></ul><h1 id="3d60" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">并行度</h1><ul class=""><li id="0dd9" class="jx jy hi is b it lj ix lk jb mc jf md jj me jn kc kd ke kf bi translated">除非我们将分区设置得足够高，否则集群不会得到充分利用</li><li id="d0b3" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">我们可以将分区号作为第二个参数传递，或者在配置属性<em class="mf">spark . default . parallelism</em>中设置</li><li id="24ee" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">建议在我们的集群中，每个CPU使用2–3个任务</li></ul><h1 id="e707" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">集群配置</h1><p id="782f" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated"><strong class="is hj">调度:</strong>我们可以将<em class="mf"> spark.scheduler.mode </em>设置为<em class="mf"> FAIR </em>以允许多个用户更好地共享资源。设置<em class="mf">–max-executer-core</em>，指定我们的应用需要的最大执行器内核数。这确保了我们的应用程序不会占用集群中的所有资源</p><p id="3a76" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">Dynamin Allocation:</strong>Spark提供了一种机制，可以根据工作负载动态调整应用程序占用的资源。这意味着我们的应用程序可以将不再使用的资源交还给集群，并在以后需要时再次请求它们。当有多个应用程序共享集群时，这很有用。</p><h1 id="0558" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">广播大变量</h1><ul class=""><li id="111a" class="jx jy hi is b it lj ix lk jb mc jf md jj me jn kc kd ke kf bi translated">广播变量允许程序员在每台机器上缓存一个只读变量，而不是随任务一起发送一个副本</li><li id="3c2f" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">为了有效地向每个节点提供大量的输入数据集</li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/e75aac8335d48e9cd0316f693c1276b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*ZnB2n9PgCuzCjyCPDfg6hA.png"/></div></figure><h1 id="ffb9" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">静态数据</h1><ul class=""><li id="c49e" class="jx jy hi is b it lj ix lk jb mc jf md jj me jn kc kd ke kf bi translated">确保我们存储的数据能够有效读取是绝对必要的</li><li id="6d16" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">这涉及到选择我们的存储系统，选择数据格式</li></ul><h2 id="f4a9" class="lo km hi bd kn lp lq lr kr ls lt lu kv jb lv lw kz jf lx ly ld jj lz ma lh mb bi translated">基于文件的长期数据存储</h2><ul class=""><li id="ab09" class="jx jy hi is b it lj ix lk jb mc jf md jj me jn kc kd ke kf bi translated">有不同类型的文件格式，如CSV、Apache Parquet</li><li id="6def" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">尽管CSV结构良好，但解析起来非常慢</li><li id="2d2d" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">我们可以选择拼花地板作为更有效的文件格式</li><li id="67fb" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">Parquet使用面向列的存储方式将数据存储在二进制文件中</li><li id="b0bb" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">可以跳过查询中不需要的数据</li></ul><h2 id="d1e8" class="lo km hi bd kn lp lq lr kr ls lt lu kv jb lv lw kz jf lx ly ld jj lz ma lh mb bi translated">可拆分文件类型和压缩</h2><ul class=""><li id="6358" class="jx jy hi is b it lj ix lk jb mc jf md jj me jn kc kd ke kf bi translated">文件格式应该是可溢出的，这样不同的任务可以并行读取文件的不同部分</li><li id="f16d" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">可分割性来自压缩格式</li><li id="d822" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">像ZIP和TAR这样的压缩格式是不可分割的</li><li id="0638" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">文件格式如GZIP，BZIP2是可拆分的</li></ul><h2 id="80d9" class="lo km hi bd kn lp lq lr kr ls lt lu kv jb lv lw kz jf lx ly ld jj lz ma lh mb bi translated">表分区</h2><ul class=""><li id="3f5a" class="jx jy hi is b it lj ix lk jb mc jf md jj me jn kc kd ke kf bi translated">表分区是指根据键将文件存储在不同的目录中</li><li id="9a0d" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">划分我们的数据允许spark根据密钥跳过不相关的文件</li></ul><h2 id="d055" class="lo km hi bd kn lp lq lr kr ls lt lu kv jb lv lw kz jf lx ly ld jj lz ma lh mb bi translated">桶装</h2><ul class=""><li id="2214" class="jx jy hi is b it lj ix lk jb mc jf md jj me jn kc kd ke kf bi translated">当某些分区中的数据不对称时，我们可以使用分桶</li><li id="fd49" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">如果在读取后频繁地对列执行连接，则存储数据可以提高性能和稳定性</li></ul><h2 id="fff0" class="lo km hi bd kn lp lq lr kr ls lt lu kv jb lv lw kz jf lx ly ld jj lz ma lh mb bi translated">文件的数量</h2><ul class=""><li id="ab23" class="jx jy hi is b it lj ix lk jb mc jf md jj me jn kc kd ke kf bi translated">避免大量小文件</li><li id="c56b" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">当从块大小为128MB的HDFS读取数据时，30个5MB的文件每个将请求30个块，即使相同的数据可以放在2个块中(总共150 MB)</li><li id="cc45" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">大量的小文件会增加网络和调度开销</li></ul><h1 id="fbee" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">数据局部性</h1><p id="9905" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">如果数据和对其进行操作的代码在一起，那么计算往往会更快。由于大小的原因，将序列化代码从一个地方运送到另一个地方比将一大块数据运送到另一个地方要快</p><p id="9eff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据局部性有几个级别:</p><ul class=""><li id="fae9" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf bi translated">PROCESS_LOCAL数据与运行代码在同一个JVM中</li><li id="47cd" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">NODE_LOCAL数据在同一节点中</li><li id="8158" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">RACK_LOCAL数据位于服务器的同一机架上</li><li id="e5f5" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">任何数据都在网络的其他地方，而不是在同一个机架上</li></ul></div></div>    
</body>
</html>