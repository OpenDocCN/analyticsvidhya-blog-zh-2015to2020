<html>
<head>
<title>Math behind Artificial Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工神经网络背后的数学</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/math-behind-artificial-neural-networks-42f260fc1b25?source=collection_archive---------9-----------------------#2020-07-20">https://medium.com/analytics-vidhya/math-behind-artificial-neural-networks-42f260fc1b25?source=collection_archive---------9-----------------------#2020-07-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7384" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">近来，人工神经网络在许多应用中被认为是有用的，如预测、分类、识别、翻译等等。当前的例子是一个简单的人工神经网络在给定输入数的情况下预测输出的应用。</p><p id="4325" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将考虑一个机器的例子，它接收输入A、B、C并产生一个输出。该示例包括用一组数据(训练数据)训练人工神经网络，以及用一组不同的数据(测试数据)测试该网络，该组数据以前没有被馈送过。在这种情况下，数据是从具有不同实验设置的实验中收集的。例如，给定输入设置A=1，B=1，C=1，产生输出=1，必须使用不同的实验设置进行多次运行才能获得数据。采集的<em class="jd"> </em>数据必须分为两组——训练集(用于训练神经网络，测试集——用于测试训练好的神经网络的性能)，训练与测试数据的比率一般为80:20。</p><p id="8f1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人工神经网络类似于人的神经网络，由处理信息的相互连接的神经元组成。人工神经网络的体系结构如下图所示，分为三层:输入层，通过它输入信息；隐藏层，连接处理信息的输入层和输出层；输出层，传递输出。</p><p id="87d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是输入A、B、C和标有“目标”的输出的样本数据集。我只显示了10行数据，一般来说，需要更多的数据集来训练网络。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/ff52e4c33a728f2872c9c0f844991237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pvv6wpSAhHMO8-Q5kb4qxw.png"/></div></div></figure><p id="8acb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于当前示例，不需要对输入进行归一化，但是当输入具有不同的尺度时，必须对输入进行归一化。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jq"><img src="../Images/72d19c57c26e884e43cfd02d6a651255.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*erIHcQKnq1SLQRWxJa7ubw.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jr"><img src="../Images/841eccab2edbd868c47b54ecb3e70e6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CveD7c0Tk8fZPu2F1QyCYw.png"/></div></div></figure><p id="5f05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面显示了一个简单的前馈反向传播人工神经网络，具有一个输入、隐藏和输出层。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es js"><img src="../Images/e6f679c40a1b978b3a3ae62544a44c37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pQqfO4vNHcRwRDbtiEoHLA.png"/></div></div></figure><p id="6b5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了更好地理解，让我们考虑只输入上表中第一行的一个输入集，A=1，B=1，C=1，输出目标=1。一旦选择了架构，就必须初始化连接不同层的突触的权重。我们可以随机初始化权重，或者选择较小的值开始。这里，我将所有连接的权重初始化为0.1，使下面的讨论中的数学变得简单。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jt"><img src="../Images/a03b695404175c7fe1c19fb603c7b1f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jjyM1dpwK03IdGNdthrN7Q.png"/></div></div></figure><p id="1d09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">正向传递和反向传播</strong></p><p id="8470" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练包括两个步骤:前向传递:输入通过网络进入输出层，产生输出。反向传播:误差反向传播到调整权重的网络中。</p><p id="c181" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">向前传球:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ju"><img src="../Images/7549c736897efd2a4ea8f911ac361075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U93NDQGu8aEouX62ovm4UA.png"/></div></div></figure><p id="bc8e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是一个简单的神经元，它有两个功能</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jv"><img src="../Images/f791c5d4bb77c43c513f19a9c6dad7dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*PqyellKMf_fTkAORT-6nlw.png"/></div></figure><p id="5296" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.每个节点上具有各自权重的输入值的总和。</p><p id="513b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.使用激活函数F(X)激活输入信号。很少有像sigmoid、ReLu、tanh等这样的激活函数。实际上，当前示例在两层中的节点处使用sigmoid激活函数。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jw"><img src="../Images/ad7c2137c2316bbaf4f26bed43eafe95.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*zF6ZxYJnZQidTZ6PBoXyBA.png"/></div></figure><p id="5572" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们只考虑隐藏节点1的计算，H1在上面的ANN图中，隐藏层1的值= (1 * 0.1) + (1 * 0.1) + (1 * 0.1) = 0.3</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jx"><img src="../Images/c3e129fda459478f4376f7ec7569fa3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/1*NRM3q7A5MVUpnkya6Oktyg.png"/></div></figure><p id="8133" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应用sigmoid激活函数= sigmoid(0.3)= 1/(exp(0.3)+1)= 0.57</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jy"><img src="../Images/ce82aa99403e92b366b74f38b8262e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*aqGEi-O0xKEi3iD1jB_LBw.png"/></div></figure><p id="418e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在每个隐藏节点进行类似的计算，并将值传递到输出层。输出层中节点值，</p><p id="5bd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出节点的值=(0.57 * 0.1)+(0.57 * 0.1)+(0.57 * 0.1)+(0.57 * 0.1)= 0.228</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jz"><img src="../Images/73a3911465b16f0ccddf47cb83aadef4.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*xTJ42TJAYmGvAfJBIIPqAQ.png"/></div></figure><p id="188f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应用sigmoid激活函数= sigmoid(2.28)= 1/(exp(2.28)+1)= 0.56</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ka"><img src="../Images/6d3dc72e57855af70e8fe6841f4a4ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*WFu1_60m_Np9VsIMP23WDA.png"/></div></figure><p id="6178" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">反向传播:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kb"><img src="../Images/1167e396b8d4356889dad22468cb9884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mQDskJlNtNSn8Y5t_qH6qw.png"/></div></div></figure><p id="e413" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">误差是网络预测值(输出)与原始值(目标)之间的差值，误差值为误差= 0.5 *(1–0.56)= 0.0968。此处的误差值仅针对一个数据点进行计算。误差通常在所有数据点上计算一次，甚至成批计算。</p><p id="f282" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出节点的误差传播:</p><p id="b464" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">仅与一个权重相关的误差变化如下所示，该权重是连接隐藏层中的节点H1与输出层的权重。</p><p id="bf4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">等式左侧的项下面是连接隐藏输出层的权重必须更新的变化，以最小化误差，从而使输出值与目标值匹配。通过应用链式法则，我们得到:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kc"><img src="../Images/e5434ceededfca9e5e2b9c9e033f187f.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*kEBfAVKxko0jejj5Z5uItA.png"/></div></figure><p id="ff0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">拆分并计算上式中的每一项:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kd"><img src="../Images/9205184235e40d520dfb354b36532771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d0LTJtsKNeXcM7ynTwWc5w.png"/></div></div></figure><p id="9f82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将所有项1、2、3分组以获得误差信息</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ke"><img src="../Images/ccf71b268744421feefe6c85d60778e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*dmODZ8HsyElC9BYP-bXD7A.png"/></div></figure><p id="928e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出节点处的权重必须更新的误差信息是</p><p id="b424" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">= -(1–0.56) * 0.246 * 0.57 = -0.0617</p><p id="493c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">隐藏节点处误差信息的类似计算:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kf"><img src="../Images/ba7b3c584445da133e0fbd5b7bc14bee.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*n9Y45dK3ImuBEP3Fu3D5Tg.png"/></div></figure><p id="e140" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">拆分并计算上式中的每一项:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kg"><img src="../Images/936849cf68fcb0cb235a9ee226779a1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tTGoglq9L10gC2nb48C2JQ.png"/></div></div></figure><p id="b0e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对上述所有项进行分组，得到隐含层的误差信息，</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kh"><img src="../Images/99d901e5e49e407cc0bf07b9a97aadb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*rslOSZrfA8sb3nDwS7GwYg.png"/></div></figure><p id="4d2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">误差项=-(1–0.56)* 0.246 * 0.1 * 0.245 * 1 =-0.00265</p><p id="9b4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">权值通过隐藏层和输出层中每个节点的误差信息进行更新</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ki"><img src="../Images/0d3598dc007f5c3a4e20e8140df56940.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*U8yLqmvBd5DZT7XGpmBnbw.png"/></div></figure><p id="5551" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一次迭代后更新的权重，连接输入隐藏层的权重</p><p id="f376" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">= 0.1-(-0.00265 )</p><p id="21df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更新了连接隐藏输出层的权重，</p><p id="9f89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">= 0.1-(-0.00617)</p><p id="bafd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">利用新更新的权重，前馈传递和反向传播迭代，直到权重稳定在特定值，以最小化使输出值匹配目标值的误差。该算法对数据表中的所有行进行迭代，最后人工神经网络以特定的权重稳定下来，为预测做好准备。训练后的最后一步是将输入数据输入到经过训练的神经网络中，以获得预测结果。</p><p id="583f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文提供了对人工神经网络的基本理解，然而还有许多概念需要探索，如偏差、学习速率、激活函数、动量因子、使神经网络健壮和有效的结构..</p><p id="ae3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请报告任何错误。感谢您的阅读。</p></div></div>    
</body>
</html>