<html>
<head>
<title>GANimation — Facial Animation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">动画——面部动画</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ganimation-facial-animation-109439fa93ec?source=collection_archive---------12-----------------------#2020-09-03">https://medium.com/analytics-vidhya/ganimation-facial-animation-109439fa93ec?source=collection_archive---------12-----------------------#2020-09-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="29d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Ganimation是一篇有趣的论文，发表于2018年，作者通过控制定义人类表情的面部运动，成功地改变了面部表情。</p><p id="2247" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看报纸上的图片，它们展示了一些例子。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/f625fac7f5d7cd8e17b9a2fd84295a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fwQ9UIUZl79Nwx9bZQZSNQ.png"/></div></div></figure><p id="fb07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">什么是动作单元？</strong></p><p id="81e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">埃克曼和弗里森开发了面部动作编码系统(FACS)来描述面部表情。它将面部表情分解为肌肉运动的各个部分，称为动作单元(AUs)。例如，恐惧是由以下因素引起的——内提眉(AU1)、外提眉(AU2)、降眉(AU4)、上提眼睑(AU5)、收紧眼睑(AU7)、伸展嘴唇(AU20)和下巴下垂(AU26)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jp"><img src="../Images/74cf7ed806693c54a44e817f7a480781.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/1*8ZVD33Qkrut_fspupIlXiw.gif"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">图片Courtsey:<a class="ae ju" href="https://inc.ucsd.edu/mplab/grants/project1/research/face-detection.html" rel="noopener ugc nofollow" target="_blank">https://Inc . ucsd . edu/mplab/grants/project 1/research/face-detection . html</a></figcaption></figure><p id="69a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">生成动作单元</strong></p><p id="2d22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以使用像OpenFace Toolkit这样的项目来生成面部动作单元。OpenFace接收人脸图像并生成动作单元向量。它使用MTCNN(多任务卷积神经网络)来裁剪人脸，这是人脸检测中的SOTA和线性核SVM来回归AU强度估计。</p><p id="535a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Tadas Baltrusaitis非常慷慨地开源了OpenFace Toolkit实现，并提供了一个方便的docker来为每张脸生成动作单元。</p><p id="4ae6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为人脸生成的样本AU看起来像这样-</p><p id="4de7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jv">【0.3，0.19，0。, 0.02, 0., 1.73, 0.56, 0.96, 0., 0., 0.03, 0., 0.63, 0., 0.75, 2.11, 0.] </em></p><p id="9c27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">值为0表示不存在该AU，而正数表示激活的程度。</p><p id="f22b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">组织方法</strong></p><p id="6c6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Ganimation是一个合成面部动画的模型，它涉及到控制这些动作单元。它是一个GAN架构，其中模型以一维向量为条件，指示每个动作单元的存在/不存在和大小。重要的是，训练过程只需要输入图像及其动作单元向量。</p><p id="14db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">给定具有动作单元y(r)的输入图像Iy(r)，想法是学习映射M，将其转换为具有动作单元y(g)的输出图像Iy(g)。</p><p id="284a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">发电机有两个部件。G1-将图像Iy(r)变换为Iy(g ), G2将图像从Iy(g)变换回Iy(r )_预测。对于鉴别器，有D_I和D_y，D _ I评估图像的照片真实性，D _ y评估从生成的图像Iy(g)预测的动作单元y(g)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jw"><img src="../Images/2adb37a62910bb2310ad72171d7addf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gsTPRIC38_zfv52gWfCczw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">图片提供:组织信息纸</figcaption></figure><p id="a5ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练是在{ Iy(r)，y(r)，y(g) }的三元组上进行的，其中目标动作单元向量y(g)是随机生成的。这使得数据的生成非常简单。给定一组人脸图像，所有需要做的就是得到一个紧密的人脸裁剪并生成它的动作单元。</p><p id="5636" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">发电机</strong></p><p id="3043" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I(o):尺寸为H×W×3的输入图像，具有动作单元y(o) <br/> y(o):输入/原始表达式的动作单元编码(大小为N的一维向量)<br/> y(f):输出/期望表达式的动作单元编码(大小为N的一维向量)<br/> I(f):以y(f)为条件的输出图像</p><p id="34c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图像向量与动作单元y(o)连接，得到H x W x (3 + N)的输出。其中，大小为N的y(o)被表示为类似于H×W×N向量的扩展版本。</p><p id="02e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成器回归并生成两个输出。一个注意力遮罩A (H x W)和一个RGB颜色变换(H x W x 3)。</p><p id="b2e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意屏蔽A决定了C中的每个像素对输出图像I(f)的贡献。</p><p id="b810" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I(f) = (1- A)。C +临时国际组织</p><p id="2ea8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果Aij为1，那么我们可以看到，当Aij为0时，I(0)的对应像素被直接复制到输出图像vs，此时颜色变换被用于在输出图像中生成该像素。</p><p id="f240" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成器架构改编自论文“使用循环一致对抗网络的不成对图像到图像的翻译”，该论文使用两个生成器方法，并稍作修改。</p><p id="177c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该网络包含三个卷积、几个残差块、两个步长为1/2的分数步长卷积以及一个将特征映射到RGB的卷积。它对128 × 128图像使用6个块，对256 × 256和更高分辨率的训练图像使用9个<br/>块。它还使用实例规范化，而不是批处理规范化。</p><p id="ee0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">鉴别器</strong></p><p id="8ee3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鉴别器组件有两个组件— D_I和D_y</p><p id="9b4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">D_I类似于贴片GAN。这只会对图像碎片尺度的结构造成不利影响。它试图分类一个N×N的小块是真的还是假的。这是在图像上卷积运行的，对响应求平均值以获得最终输出。</p><p id="325e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">D_y是估计AU激活的回归头。</p><p id="234d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">损失函数</strong></p><p id="7ab6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看损失函数。这是4次失败的组合。</p><p id="7556" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.图像不利损失—这是基于WGAN-GP使用推土机距离的标准GAN损失。最初的GAN具有Jenson-Shannon发散损失函数，但是这不是连续的并且可以饱和。相反，WGAN-GP使用Wasserstein损失，它并不真正输出介于0和1之间的数字。</p><p id="2eb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批评家损失函数:D(x) — D(G(x)) <br/>发电机损失函数:D(G(x))</p><p id="8192" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中D(x)是真实图像的评价分数，D(G(x))是虚假图像的鉴别分数。<br/>鉴别器试图通过最大化差异来最大化临界损失函数。发电机试图最大化发电机损耗函数。实际损失是通过反转符号来实现的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jx"><img src="../Images/561515ab8c8a89c7fa52f88755ca00a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6W2cmMR2yBFqqC7d_Rwnag.png"/></div></div></figure><p id="1f5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.注意力丢失——这是两种正规化的混合。第一种是全变差正则化，它更多的是像素到像素的平滑。第二种是L2正则化，以防止注意力权重饱和。如果注意力权重在上面的注意力等式中饱和，我们可以看到输出图像将开始镜像输入，并且生成器将没有效果。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jy"><img src="../Images/74bf3e3826a3f347c97da1c99fc81230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ZwfmHNEbYf3OKQvaiWaCw.png"/></div></div></figure><p id="8175" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.条件表达式丢失-这是操作单元丢失。对于一个给定的动作单元y(f ),我们期望生成器产生一个改变了表达式的图像。因此，该损失的一个分量测量生成图像上的回归损失与实际AU向量y(f)之间的损失。另一个分量是原始图像上的预测AU和AU向量y(o)之间的回归损失</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jz"><img src="../Images/f708f4b10806fb5c914037c45b42ba9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SHuAmPSb1zi7f_gM_Gaieg.png"/></div></div></figure><p id="0390" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.身份丢失——我们有两个生成器，一个将图像I(o)转换为I(f)。另一个将I(f)变换为I(o)predicted。这意味着可以将这种损失作为信息损失来测量，也称为周期一致性损失。所以这是我(o)和我(o)_预测之间的损失。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ka"><img src="../Images/32168d7535167c681ad2160211fb2b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZnG36DhhwUkJjqvWKy4tow.png"/></div></div></figure><p id="6e26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终损失函数是所有4次损失的组合。</p><p id="5878" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损失=图像对抗性损失+ λy *条件表达式损失+ λa *(生成器1的注意损失+生成器2的注意损失)+ λidt *同一性损失</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kb"><img src="../Images/05c6ada714dbd71c70d2ae40b226c22d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*naBSINam6StvTMAWAHEejQ.png"/></div></div></figure><p id="ec9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损耗最终被定义为一个典型的GAN极小极大问题。最小值和最大值是发电机损耗的最小化和鉴别器损耗的最大化。鉴别器寻求将正确标签分配给原始样本以及来自生成器的样本的概率最大化。</p><p id="c43c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最大化log D(x) + log(1-D(G(z))) <br/>其中x为实际样本，G(z)为生成样本。</p><p id="0920" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">评估定制图像上的组织</strong></p><p id="7778" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了在自定义图像集上对其进行评估，筛选一组目标人脸图像，测试图像并生成动作单元。需要对所有人脸图像进行近距离裁剪。我用的是MTCNN。使用测试图像、测试图像的动作单元和从定制图像集中的样本中提取的动作单元，获得具有改变的表达式的最终输出。</p><p id="4601" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我在我的一张粗暴的照片上试着生成改变的表情:)模型获取测试图像并改变它以复制目标图像的表情。这里，每行的第一个图像是提供的测试图像，该行的最后一个图像是目标图像。当目标动作单位的大小逐渐变化时，可以看到表达的变化。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kc"><img src="../Images/0077a0891c077fb2d84643659222bdfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eqdrFvAhGSu67WgEna014g.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kc"><img src="../Images/1cfa2ffdd655cc99641eb7dd11bfea59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AdHXO3R8aYd8OuwsMMLpZA.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kc"><img src="../Images/dac6d5ab6921e098d3f693c244753917.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f8kkKFbEDlxoowG9A1UXAw.jpeg"/></div></div></figure><p id="5bfa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望你喜欢这篇文章！请在评论中告诉我</p><p id="42f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">推荐人:</strong></p><p id="b754" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.组织动画:来自单一图像的解剖学意义上的面部动画——阿尔伯特·普马罗拉、安东尼奥·阿古多、阿莱克斯·m·马丁内斯、阿尔贝托·桑菲利乌、弗朗切斯克·莫雷诺-诺古尔<br/><a class="ae ju" href="https://arxiv.org/pdf/1807.09251.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1807.09251.pdf</a></p><p id="f6c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<a class="ae ju" href="https://www.paulekman.com/facial-action-coding-system/" rel="noopener ugc nofollow" target="_blank">https://www.paulekman.com/facial-action-coding-system/</a></p><p id="b80a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.生成对抗网络——https://arxiv.org/pdf/1406.2661.pdf<a class="ae ju" href="https://arxiv.org/pdf/1406.2661.pdf" rel="noopener ugc nofollow" target="_blank">T3</a></p><p id="08fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.瓦瑟斯坦·甘—阿约夫斯基，m .，钦塔拉，s .，博图，l .<br/>T5，</p><p id="d330" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.瓦瑟斯坦·甘斯的改进训练—<a class="ae ju" href="https://arxiv.org/pdf/1704.00028.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1704.00028.pdf</a></p><p id="5ca4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.OpenFace 2.0:面部行为分析工具包<br/><a class="ae ju" href="http://multicomp.cs.cmu.edu/wp-content/uploads/2018/11/OpenFace.pdf" rel="noopener ugc nofollow" target="_blank">http://multicomp . cs . CMU . edu/WP-content/uploads/2018/11/open face . pdf</a><br/><a class="ae ju" href="https://github.com/TadasBaltrusaitis/OpenFace" rel="noopener ugc nofollow" target="_blank">https://github.com/TadasBaltrusaitis/OpenFace</a></p><p id="d1b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.使用循环一致对抗网络的不成对图像到图像翻译<br/><a class="ae ju" href="https://arxiv.org/abs/1703.10593" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1703.10593</a></p><p id="56ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">8.J .实时风格转换和超分辨率的感知损失——约翰逊、阿拉希和飞飞。<br/><a class="ae ju" href="https://arxiv.org/pdf/1603.08155.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1603.08155.pdf</a></p><p id="4191" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">9.基于条件对抗网络的图像到图像翻译—伊索拉，p，朱，J.Y，周，t，埃夫罗斯，</p><p id="3ad8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">10.<a class="ae ju" href="https://github.com/albertpumarola/GANimation" rel="noopener ugc nofollow" target="_blank">https://github.com/albertpumarola/GANimation</a></p><p id="856d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">11.<a class="ae ju" href="https://github.com/donydchen/ganimation_replicate" rel="noopener ugc nofollow" target="_blank">https://github.com/donydchen/ganimation_replicate</a></p></div></div>    
</body>
</html>