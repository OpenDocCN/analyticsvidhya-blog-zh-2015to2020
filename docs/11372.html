<html>
<head>
<title>Classification and detection of Covid-19 in chest radiographs using Deep Learning and IBM Visual Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习和 IBM 视觉识别对胸片中的新冠肺炎进行分类和检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classification-and-detection-of-covid-19-in-chest-radiographs-using-deep-learning-and-ibm-visual-28782777bb4?source=collection_archive---------37-----------------------#2020-11-30">https://medium.com/analytics-vidhya/classification-and-detection-of-covid-19-in-chest-radiographs-using-deep-learning-and-ibm-visual-28782777bb4?source=collection_archive---------37-----------------------#2020-11-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f113daa564648aa429be1c8eb1efebe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NxUI79XHQM_4sf612xrOqw.png"/></div></div></figure><p id="8346" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2020 年中期，我们一直在经历一场疫情，起因是新冠肺炎，这种病毒 2019 年底起源于中国，2020 年初到达欧美。到目前为止，截至 11 月中旬，全球已有 5490 多万人感染了这种病毒，约 130 万人死亡。面对这种疫情，不同的医疗和技术解决方案正在开发中。今天，通过技术我们可以创造不同的工具来帮助我们对抗这种病毒，比如机器人。同样，由于人工智能有助于执行人类日常做的不同任务，如视觉，可以开发算法通过 X 射线诊断新冠肺炎，就像医生一样。这就是我详述以下工作的原因。</p><h1 id="090a" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">方法论</strong></h1><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es km"><img src="../Images/c2d903c7617156cf844b4ae43801b117.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W30chXAsKhRzAnYJEvQ7Ow.png"/></div></div></figure><p id="60f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该方法包括 5 个步骤:收集、预处理、建模、检测和评估</p><h1 id="03ad" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">数据收集</strong></h1><p id="0fad" class="pw-post-body-paragraph iq ir hi is b it kr iv iw ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn hb bi translated">这些图像来自 Kaggle，包含以下分布:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/49704f40f9c6c1021f1a622d60feae90.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*bEwCL7bYdw1oxr_gR2FCXA.png"/></div></figure><p id="3437" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些图像是关于新冠肺炎、正常人和肺炎的，因为冠状病毒引起的大多数损伤与肺炎病例中发现的损伤非常相似。总共有 2583 个图像:冠状病毒的 577 个图像，正常的 1004 个图像和肺炎的 1002 个图像。</p><h1 id="9473" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">图像预处理</h1><p id="3f82" class="pw-post-body-paragraph iq ir hi is b it kr iv iw ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn hb bi translated">胸部射线照片或通常称为 x 射线图像用于获得人体内部结构的图像，并且具有各种类型:CT 扫描(计算机断层摄影)、乳房 x 线照相术、血管造影术、荧光透视法等。<br/>这些类型的图像是医疗领域中最广泛使用的诊断工具，使我们能够看到从骨折到肺部病变的各种情况。另一方面，这些类型的图像有两个缺点:图像的<strong class="is hj"> <em class="kx">低对比度</em> </strong>和可能破坏图像的<strong class="is hj"> <em class="kx">加性噪声</em> </strong>。<br/>有几种过滤器可以去除图像中的噪声，其中一种是高斯过滤器，它允许您稳定图像中的变化。为了提高对比度，可以使用对比度自适应直方图均衡化(CLAHE)技术，该技术允许在噪声消除过程之后增加射线照片中的对比度，以便提高性能。这就是为什么这些图像必须经过预处理阶段。需要注意的是<strong class="is hj"> <em class="kx">为了处理这种类型的图像</em> </strong>，必须首先去除<strong class="is hj"> <em class="kx">噪声</em> </strong>(应用高斯滤波器)<strong class="is hj"> <em class="kx">然后提高对比度</em> </strong> (CLAHE)，如果提高了对比度而之前没有去除噪声，会导致信息(图像的特征)的丢失，从而降低图像的质量，进而降低分类的性能。</p><p id="c71e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，导入库:</p><ol class=""><li id="0bab" class="ky kz hi is b it iu ix iy jb la jf lb jj lc jn ld le lf lg bi translated">操作系统:允许文件管理</li><li id="dc67" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">BytesIO:允许将数据保存在内存的缓冲区中</li><li id="cccd" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">Zipfile:允许提取 zipp 中的压缩图像</li><li id="8fa8" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">Ibm_boto3:允许将 zip 文件从 IBM Cloud Object Storage 导入到路径:<strong class="is hj"> / home / wuser </strong></li></ol><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/adb348261921d58ca58a98053c9035ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dS6uquMs5y3X8NT3J4jGWQ.png"/></div></div></figure><p id="b0c5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其次，包含 3 个文件夹(正常、Covid19、肺炎)的 zip 文件必须上传到<strong class="is hj">对象存储器</strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/251c76323bb82346fd1dbb3ae310ceb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H4LG9eBSQDulMDUpdYgiaw.png"/></div></div></figure><p id="6773" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后使用<strong class="is hj"> <em class="kx"> StreamingBody 对象</em> </strong>将其插入到代码中</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/3bee6054886ec6d93d4ca1233d5046c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ayfOSrLYdtSFxxHgTcrfQg.png"/></div></div></figure><p id="90e1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用 zipfile 库提取图像，并将类保存在名为 classes_required 的数组中。</p><p id="9ca0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，图像将保存在以下路径:<strong class="is hj"> / home / wsuser / work/ </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/c02c2e1bae183a66a851da25819e5ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ooAEIJMWowQ4PBdb28t6hg.png"/></div></div></figure><p id="ebbf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用两个 for 循环，图像将被迭代并存储在一个名为 images 的数组中。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/8daff6b40d882c066a77275193cb0399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wi0JcG_zUbmYqIA5brFKMA.png"/></div></div></figure><p id="fcb3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，创建一个 CLAHE 类型的对象，它将帮助我们提高图像的对比度(对比度增强)，并通过另一个 for 循环迭代图像，其过程如下:</p><ol class=""><li id="8102" class="ky kz hi is b it iu ix iy jb la jf lb jj lc jn ld le lf lg bi translated">转换为灰度(cv.cvtColor (img，cv。颜色-RGB 2 灰色)</li><li id="5510" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">应用高斯滤波器(cv。GaussianBlur (gray，(5，5)，0))，它有一个 5×5 的内核</li><li id="1cf6" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">最后，应用 CLAHE 函数来提高图像的对比度。</li></ol><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/3a82eacdc51699519e4e52430d3c3400.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*eCdT9bC9u55jGgP4H8fu2w.png"/></div></figure><h1 id="98e8" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">建模</strong></h1><p id="fd01" class="pw-post-body-paragraph iq ir hi is b it kr iv iw ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn hb bi translated">深度学习架构用于图像的特征提取和分类。在这种情况下，使用了视觉几何组 19 (VGG19)，它由 19 层组成(16 个卷积层、3 个全连接层、5 个 MaxPool 层和 1 个 SoftMax 层)。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/e6d6b01f03d0affc570988703a610239.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-R_uOamt9mOROyE7bD0Hcg.png"/></div></div></figure><p id="8032" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，保存图像</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/7b76520a21232cf4057352e7266b9069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Va2dqPqqLc4mmSQKdcWScQ.png"/></div></div></figure><p id="f4cf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先导入以下库:</p><ol class=""><li id="63c5" class="ky kz hi is b it iu ix iy jb la jf lb jj lc jn ld le lf lg bi translated">ImageDataGenerator(做数据扩充)。</li><li id="5ead" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">VGG19(深度学习架构)。</li><li id="c6bc" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">AveragePooling2D，Input，Dense，Flatten，Dropout，Model 对模型进行调优，使其适应三类分类。</li><li id="d9a5" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">SGD 作为优化器。</li><li id="072e" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">to _ categorical(使标签适应三类 numpy 格式)。</li><li id="46cf" class="ky kz hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">train_test_split 对数据进行分区。</li></ol><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/12dd2df8bc58e9df487a306fdb475954.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z9M6irmi40AQ15u89JwUNQ.png"/></div></div></figure><p id="ff6a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因为我们将数据存储在一个数组(nv_image)中，并且按顺序，我们通过一个 for 循环来保存标签。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/b43dfb02bc971d57d1b02fd69165564a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WwBrY-wHvu3vnzF95Etbfw.png"/></div></div></figure><p id="fa63" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，将图像的大小调整为 224 x 224，并将图像的大小除以 255。此外，通过 for 循环和 to _ categorical()函数对标签进行一次性编码。数据分区是 75/25。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/d089958ce3706ecaab7281b7d556e8c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nes_GOTz0r2znci5KqPSDw.png"/></div></div></figure><p id="2a8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用 ImageDataGenerator 函数，通过旋转 15 度来执行数据扩充。然后加载 VGG19 架构，用“imagenet”权重进行迁移学习。需要注意的是，架构进行了修改，增加了一个 GlobalAveragePooling 层，这是一个 514 个神经元的全连接层，压降为 0.5。因为有 3 个类，所以使用 softmax 函数。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/bfb57d974d9c7454f92724932b6969ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YSeIWw50_fvC5g4-acDjXw.png"/></div></div></figure><p id="0525" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">学习率= 0.001，100 次，批次大小为 64</p><p id="59e4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">冠状病毒检测</strong></p><p id="3423" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对象检测是计算机视觉的一项任务，涉及检测图像或视频中的对象。在这种情况下，使用 IBM 云服务视觉识别检测到指示冠状病毒存在的病变。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/92c2fceff9910b972c6e7dfde8abdd69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TDsjpBh3kg2kl4mfRvjROA.png"/></div></div></figure><p id="e787" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">值得注意的是，标记过程是由一名具有 15 年以上经验的放射科医师完成的，他曾在秘鲁的多家医院和私人诊所工作过。正如我们在视觉识别中看到的，我们加载图像并选择 Add object 按钮，在病变所在的位置绘制一个正方形。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/aef01418afd19f9b3930d33dee047cc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*phV-_W9KeJwbALxoh524bw.png"/></div></div></figure><p id="05ab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">标记图像后，按下列车模型按钮。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/8ada99299c10306a95eae324b8b3402b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hcaJzLp9e9TbyFKLzEChtw.png"/></div></div></figure><p id="8467" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">模型训练完成后，提取 apikey 和 url。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/ef4445ad13db0cbfea4f719c32b99c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S7izG1329AHj7dqtsTQyzw.png"/></div></div></figure><p id="e7a8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">提取 apikey 和 url 后，我们继续在 IBM Watson 笔记本中实现视觉识别模型。为此，需要导入 libm_boto3、Config 和 ClientError 库(以便能够访问 IBM Cloud 对象存储)</p><p id="a20d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了测试模型，您必须上传一个包含新图像的 zip 文件(testing2.zip ),并导入您的凭证和 ICOS SDK (IBM Cloud Object Storage)。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/0ea04bada36c5824c3ffeccad3e0a0e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KC9-pHOKV8_L64RXnU-1Zg.png"/></div></div></figure><p id="b159" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用 ls 命令，可以看到 zip 文件已经在路径中。出于这个原因，zipfile 被导入，zip 中的图像被提取出来。有了这个库，你就可以获得 zip 文件中图片的名称。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/30b0bd327cfe174250da66ebcc6e55fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jJ6bSWz--XGZp9bA9sy1mQ.png"/></div></div></figure><p id="260b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，用 url 和 apikey 实例化虚拟识别模型</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/c262956e4eb53bea64dec00b28f86ddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V6vWa2AExM8d8sb5Kqs2dQ.png"/></div></div></figure><p id="482f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了执行检测，使用了一个 for 循环，该循环遍历图像并取出用视觉识别模型预测的边界框的坐标。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/1e38cd40ad08ca59211751805d9be242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AvEQJwBK61RGpsuizigL0A.png"/></div></div></figure><p id="3e6e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，使用另一个 for 循环，在图像和它所属的类中绘制边界框。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/f7efc7d11f72e6c6c8fc8f7e0d1ef5df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1LnS7W2fmyme-X-RQC_O2g.png"/></div></div></figure><h1 id="4b4b" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">评估</strong></h1><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/9d1aacf031e0e8ca3d2953ea32bd778e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4XE6zqHMhlu9hRr07_ri4Q.png"/></div></div></figure><p id="ae9d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">VGG19 在四项指标(准确度、召回率、精确度和 f1 得分)中取得了好成绩。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/a6a64080898ec531c911e653bc52536a.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*ZCD6WlIYYmc6gmqFOcV9kA.png"/></div></figure><p id="319f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在混淆矩阵中，我们可以看到该模型对少数图像进行了错误分类。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/a887d66b0997b515d076cf77fcfcc063.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xHuq-0EPDEf0ddMlIaKC_w.png"/></div></div></figure><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/2bafe312abd82c7e2949b9f90bcb6b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*5zn8iacpjV4nV5DhLa0IVQ.png"/></div></figure><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/54f8d1f385b9692f8ff8eb40427578af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K9g_KEVbi-LKMfP9AdPAQQ.png"/></div></div></figure><p id="eee1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，我们在图表中看到，准确性和损失表明该模型相对较好地概括了数据分布。然而，这可以通过拥有更多图像来改善，从而显著减少损失。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/4d1095ff87f1d9a0f247ab28848c28fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UVpT7wkiNI3IWt7aNHdVtw.png"/></div></div></figure><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/a2ef7a843baa645c1497d83b3b8a988a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dlAyHRql_V_l9ARxGUersg.png"/></div></div></figure></div></div>    
</body>
</html>