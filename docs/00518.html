<html>
<head>
<title>How to Get Started with NLP — 6 Unique Methods to Perform Tokenization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何开始使用NLP-6执行令牌化的独特方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-get-started-with-nlp-6-unique-methods-to-perform-tokenization-b6a98d23daae?source=collection_archive---------2-----------------------#2019-07-18">https://medium.com/analytics-vidhya/how-to-get-started-with-nlp-6-unique-methods-to-perform-tokenization-b6a98d23daae?source=collection_archive---------2-----------------------#2019-07-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="839c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">概观</h1><ul class=""><li id="816f" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">想开始学习自然语言处理(NLP)吗？这是完美的第一步</li><li id="2a16" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">了解如何执行标记化，这是为构建NLP模型准备数据的一个关键方面</li><li id="680f" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">我们提出了6种不同的方法来对文本数据进行标记化</li></ul><h1 id="8a3b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="6c12" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">你是否对互联网上大量的文本数据着迷？您是否正在寻找处理这些文本数据的方法，但不确定从哪里开始？毕竟，机器识别数字，而不是我们语言中的字母。在机器学习中，这可能是一个棘手的问题。</p><p id="f295" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">那么我们如何操作和清理这些文本数据来构建模型呢？答案就在<a class="ae ku" href="https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp?utm_source=blog&amp;utm_medium=how-get-started-nlp-6-unique-ways-perform-tokenization" rel="noopener ugc nofollow" target="_blank">自然语言处理(NLP) </a>的奇妙世界里。</p><p id="d0d4" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">解决NLP问题是一个多阶段的过程。在我们考虑进入建模阶段之前，我们需要首先清理非结构化的文本数据。清理数据包括几个关键步骤:</p><ul class=""><li id="c4c5" class="jd je hi jf b jg kp ji kq jk kv jm kw jo kx jq jr js jt ju bi translated">单词标记化</li><li id="18de" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">预测每个单词的词性</li><li id="2141" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">文本词汇化</li><li id="fc80" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">识别和删除停用词，等等。</li></ul><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ky"><img src="../Images/1c3c98896b935160f1254de12f456bf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jt4_5T-u7LRmjHa1.jpg"/></div></div></figure><p id="e794" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">在本文中，我们将讨论第一步——标记化。我们将首先了解什么是记号化，以及为什么在NLP中需要记号化。然后，我们将看看在Python中执行标记化的六种独特方式。</p><p id="5597" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">这篇文章没有先决条件。任何对NLP或数据科学感兴趣的人都可以参与进来。如果您正在寻找学习NLP的端到端资源，您应该查看我们的综合课程:</p><ul class=""><li id="cd1e" class="jd je hi jf b jg kp ji kq jk kv jm kw jo kx jq jr js jt ju bi translated"><a class="ae ku" href="https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp?utm_source=blog&amp;utm_medium=how-get-started-nlp-6-unique-ways-perform-tokenization" rel="noopener ugc nofollow" target="_blank">使用Python的自然语言处理</a></li></ul><h1 id="8d10" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">目录</h1><ul class=""><li id="3a99" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">什么是NLP中的标记化？</li><li id="b3f9" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">为什么需要标记化？</li><li id="836c" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">在Python中执行标记化的不同方法</li><li id="651a" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">使用Python split()函数进行标记化</li><li id="a2d7" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">使用正则表达式的标记化</li><li id="9a69" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">使用NLTK的标记化</li><li id="be2c" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">使用空间的标记化</li><li id="4797" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">使用Keras的标记化</li><li id="a1e9" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">使用Gensim进行标记化</li></ul><h1 id="cf56" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">什么是NLP中的标记化？</h1><p id="ad42" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">在处理文本数据时，标记化是最常见的任务之一。但是术语“标记化”实际上是什么意思呢？</p><blockquote class="lk ll lm"><p id="c80f" class="ka kb ln jf b jg kp kc kd ji kq ke kf lo kr kh ki lp ks kk kl lq kt kn ko jq hb bi translated"><em class="hi">标记化本质上是将短语、句子、段落或整个文本文档分割成更小的单元，例如单个单词或术语。这些更小的单元中的每一个都被称为令牌。</em></p></blockquote><p id="d9fb" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">查看下图，了解这一定义:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lr"><img src="../Images/027b7c7faa6d8732fe854344339562cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bp-SR-3SGRWSdS34.png"/></div></div></figure><p id="df2a" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">标记可以是单词、数字或标点符号。在标记化中，通过定位单词边界来创建更小的单元。等等——什么是单词边界？</p><p id="3fb2" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">这是一个单词的结束点和下一个单词的开始点。这些标记被认为是词干化和词汇化的第一步(文本预处理的下一个阶段，我们将在下一篇文章中讨论)。</p><h1 id="fb39" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">为什么NLP中需要标记化？</h1><p id="bbac" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">我想让你想想这里的英语。当你阅读这一部分的时候，选择你能想到的任何一句话，并牢记在心。这将有助于您以更简单的方式理解标记化的重要性。</p><p id="b9bb" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">在处理一种自然语言之前，我们需要确定分词是处理NLP(文本数据)的最基本步骤。<em class="ln">构成一串字符的单词</em>。这就是为什么<strong class="jf hj">这很重要，因为通过分析文本中出现的单词，可以很容易地解释文本的意思。</strong></p><p id="4a4c" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">我们举个例子。考虑下面的字符串:</p><p id="c343" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">你认为在我们对这个字符串执行标记化之后会发生什么？我们得到['This '，' is '，' a '，cat']。</p><p id="d2d8" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">这样做有许多用途。我们可以使用这种标记化的形式来:</p><ul class=""><li id="9fbd" class="jd je hi jf b jg kp ji kq jk kv jm kw jo kx jq jr js jt ju bi translated">统计课文中的单词数</li><li id="6c54" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">计算单词的频率，也就是某个特定单词出现的次数</li></ul><p id="3e5b" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">诸如此类。我们可以提取更多的信息，我们将在以后的文章中详细讨论。现在，是时候深入到本文的核心了——在NLP中执行标记化的不同方法。</p><h1 id="7539" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">在Python中执行标记化的方法</h1><p id="5129" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">我们将看到六种可以对文本数据执行标记化的独特方法。我已经为每个方法提供了Python代码，因此您可以在自己的机器上跟随。</p><h1 id="0dd8" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">1.使用Python的split()函数进行标记化</h1><p id="7602" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">让我们从<strong class="jf hj"> split() </strong>方法开始，因为它是最基本的一种。在用指定的分隔符断开给定的字符串后，它返回一个字符串列表。默认情况下，split()在每个空格处断开一个字符串。我们可以把分隔符改成任何东西。我们去看看。</p><p id="f96f" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">分词</strong></p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="b96a" class="lz ig hi lv b fi ma mb l mc md">Output : ['Founded', 'in', '2002,', 'SpaceX's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi-planet', 'species', 'by', 'building', 'a', 'self-sustaining', 'city', 'on', 'Mars.', 'In', '2008,', 'SpaceX's', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid-fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth.']</span></pre><p id="29a2" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">句子标记化</strong></p><p id="7a5c" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">这类似于单词标记化。这里，我们在分析中研究句子的结构。一个句子通常以句号(。)，所以我们可以用“.”作为分隔符来断开字符串:</p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="d6c4" class="lz ig hi lv b fi ma mb l mc md">Output : ['Founded in 2002, SpaceX's mission is to enable humans to become a spacefaring civilization and a multi-planet \nspecies by building a self-sustaining city on Mars', 'In 2008, SpaceX's Falcon 1 became the first privately developed \nliquid-fuel launch vehicle to orbit the Earth.']</span></pre><p id="2747" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">使用Python的<em class="ln"> split() </em>方法的一个主要缺点是我们一次只能使用一个分隔符。还有一点需要注意的是——在单词标记化中，<em class="ln"> split() </em>并没有将标点符号作为单独的标记来考虑。</p><h1 id="160f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">2.使用正则表达式(RegEx)的标记化</h1><p id="a8d6" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">首先，让我们了解一下什么是正则表达式。它基本上是一个特殊的字符序列，帮助您使用该序列作为模式来匹配或查找其他字符串或字符串集。</p><p id="e028" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">我们可以使用Python中的<strong class="jf hj"> re </strong>库来处理正则表达式。这个库预装了Python安装包。</p><p id="486b" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">现在，让我们记住正则表达式，执行单词标记化和句子标记化。</p><p id="2ddb" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">词语标记化</strong></p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="ed40" class="lz ig hi lv b fi ma mb l mc md">Output : ['Founded', 'in', '2002', 'SpaceX', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 'Mars', 'In', '2008', 'SpaceX', 's', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth']</span></pre><p id="af50" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">“<code class="du me mf mg lv b">\w</code>”代表“任何单词字符”，通常指字母数字(字母、数字)和下划线(_)。“+”表示任何次数。<strong class="jf hj">所以<em class="ln"> [\w']+ </em>表示代码应该找到所有的字母数字字符，直到遇到任何其他字符。</strong></p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mh"><img src="../Images/3868979a7ec3c40df31015a147822f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F7WugaK82b6mcL08.png"/></div></div></figure><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="6915" class="lz ig hi lv b fi ma mb l mc md">Output : ['Founded in 2002, SpaceX's mission is to enable humans to become a spacefaring civilization and a multi-planet \nspecies by building a self-sustaining city on Mars.', 'In 2008, SpaceX's Falcon 1 became the first privately developed \nliquid-fuel launch vehicle to orbit the Earth.']</span></pre><p id="8ae5" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">这里，我们比<em class="ln"> split() </em>方法有优势，因为我们可以同时传递多个分隔符。在上面的代码中，<strong class="jf hj">我们使用了<em class="ln"> re.compile() </em>函数，其中我们传递了[。？！].这意味着只要遇到这些字符，句子就会被拆分。</strong></p><p id="d8ae" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">有兴趣阅读更多关于RegEx的内容吗？以下资源将帮助您开始学习NLP中的正则表达式:</p><ul class=""><li id="75f1" class="jd je hi jf b jg kp ji kq jk kv jm kw jo kx jq jr js jt ju bi translated"><a class="ae ku" href="https://www.analyticsvidhya.com/blog/2015/06/regular-expression-python/" rel="noopener ugc nofollow" target="_blank">Python正则表达式初学者教程</a></li><li id="fe6b" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated"><a class="ae ku" href="https://www.analyticsvidhya.com/blog/2017/03/extracting-information-from-reports-using-regular-expressons-library-in-python/" rel="noopener ugc nofollow" target="_blank">使用Python中的正则表达式库从报告中提取信息</a></li></ul><h1 id="a158" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.使用NLTK的标记化</h1><p id="8665" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">现在，这是一个库，你越是处理文本数据，你就会越欣赏它。NLTK是Natural Language ToolKit的缩写，是用Python编写的用于符号和统计自然语言处理的库。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mi"><img src="../Images/aba96db67ccc66b5f2db6f43dd05504c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jJcvYO8HKF1X8GTC.png"/></div></div></figure><p id="4707" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">您可以使用下面的代码安装NLTK:</p><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="45ab" class="lz ig hi lv b fi ma mb l mc md">pip install --user -U nltk</span></pre><p id="f3da" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">NLTK包含一个名为<em class="ln"> tokenize() </em>的模块，它进一步分为两个子类别:</p><ul class=""><li id="5f3a" class="jd je hi jf b jg kp ji kq jk kv jm kw jo kx jq jr js jt ju bi translated"><strong class="jf hj"> Word tokenize: </strong>我们使用word_tokenize()方法将一个句子分割成记号或单词</li><li id="ed45" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated"><strong class="jf hj">句子标记化:</strong>我们使用sent_tokenize()方法将文档或段落分割成句子</li></ul><p id="9008" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">让我们一个一个地看看这两个。</p><p id="54f9" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">词语标记化</strong></p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="c3e2" class="lz ig hi lv b fi ma mb l mc md">Output: ['Founded', 'in', '2002', ',', 'SpaceX', ''', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi-planet', 'species', 'by', 'building', 'a', 'self-sustaining', 'city', 'on', 'Mars', '.', 'In', '2008', ',', 'SpaceX', ''', 's', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid-fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth', '.']</span></pre><p id="fa6c" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">句子标记化</strong></p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="0e1a" class="lz ig hi lv b fi ma mb l mc md">Output: ['Founded in 2002, SpaceX's mission is to enable humans to become a spacefaring civilization and a multi-planet \nspecies by building a self-sustaining city on Mars.', 'In 2008, SpaceX's Falcon 1 became the first privately developed \nliquid-fuel launch vehicle to orbit the Earth.']</span></pre><h1 id="4da9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.使用空间库进行标记化</h1><p id="1748" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">我喜欢空间图书馆。我不记得上一次在做NLP项目的时候不用它是什么时候了。它就是这么有用。</p><p id="3cc6" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">spaCy是高级<a class="ae ku" href="https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp?utm_source=blog&amp;utm_medium=how-get-started-nlp-6-unique-ways-perform-tokenization" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj">自然语言处理</strong> (NLP) </a>的<strong class="jf hj">开源库</strong>。它支持超过49种语言，并提供最先进的计算速度。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mj"><img src="../Images/65f2d61dcdb5cbb3fb420f2bf2e140cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zsd2a2wKljjvVz1o.jpg"/></div></div></figure><p id="2968" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">要在Linux中安装Spacy:</p><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="ed38" class="lz ig hi lv b fi ma mb l mc md">pip install -U spacy <br/>python -m spacy download en</span></pre><p id="ed55" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">要在其他操作系统上安装，请通过<a class="ae ku" href="https://spacy.io/usage" rel="noopener ugc nofollow" target="_blank">这个链接</a>。</p><p id="9ed0" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">因此，让我们看看如何利用spaCy的强大功能来执行标记化。我们将使用支持英语的spacy.lang.en。</p><p id="7a13" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">词语标记化</strong></p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="a4ca" class="lz ig hi lv b fi ma mb l mc md">Output : ['Founded', 'in', '2002', ',', 'SpaceX', ''s', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', '-', 'planet', '\n', 'species', 'by', 'building', 'a', 'self', '-', 'sustaining', 'city', 'on', 'Mars', '.', 'In', '2008', ',', 'SpaceX', ''s', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', '\n', 'liquid', '-', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth', '.']</span></pre><p id="f6e2" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">句子标记化</strong></p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="2060" class="lz ig hi lv b fi ma mb l mc md">Output : ['Founded in 2002, SpaceX's mission is to enable humans to become a spacefaring civilization and a multi-planet \nspecies by building a self-sustaining city on Mars.', 'In 2008, SpaceX's Falcon 1 became the first privately developed \nliquid-fuel launch vehicle to orbit the Earth.']</span></pre><p id="66b2" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">在执行NLP任务时，spaCy比其他库要快得多(是的，甚至是NLTK)。我鼓励你听下面的DataHack广播播客，了解spaCy是如何创建的背后的故事以及你可以在哪里使用它:</p><ul class=""><li id="f8e1" class="jd je hi jf b jg kp ji kq jk kv jm kw jo kx jq jr js jt ju bi translated">数据黑客电台#23:伊内斯·蒙塔尼和马修·霍尼巴尔spaCy背后的大脑</li></ul><p id="6f44" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">这里有一个深入的教程让你开始使用spaCy:</p><ul class=""><li id="e2c0" class="jd je hi jf b jg kp ji kq jk kv jm kw jo kx jq jr js jt ju bi translated"><a class="ae ku" href="https://www.analyticsvidhya.com/blog/2017/04/natural-language-processing-made-easy-using-spacy-%E2%80%8Bin-python/?utm_source=blog&amp;utm_medium=how-get-started-nlp-6-unique-ways-perform-tokenization" rel="noopener ugc nofollow" target="_blank">自然语言处理变得简单——使用SpaCy(在Python中)</a></li></ul><h1 id="b64a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">5.使用Keras的标记化</h1><p id="2275" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">喀拉斯！目前业界最热门的深度学习框架之一。它是一个用于Python的开源神经网络库。Keras超级好用，也可以在TensorFlow上面运行。</p><p id="7f62" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">在NLP上下文中，我们可以使用Keras来清理我们通常收集的非结构化文本数据。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mj"><img src="../Images/46f61d05e7f74d5c546def19248d51fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jYV6-wXoB5zpDa9m.png"/></div></div></figure><p id="49fe" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">您可以只使用一行代码在您的机器上安装Keras:</p><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="2601" class="lz ig hi lv b fi ma mb l mc md">pip install Keras</span></pre><p id="14cb" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">让我们开始吧。为了使用Keras执行单词标记化，我们使用来自<em class="ln">Keras . preprocessing . text</em>类的<em class="ln"> text_to_word_sequence </em>方法。</p><p id="c1fe" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">让我们看看Keras的行动。</p><p id="c0b5" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">单词标记化</strong></p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="a824" class="lz ig hi lv b fi ma mb l mc md">Output : ['founded', 'in', '2002', 'spacex's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 'mars', 'in', '2008', 'spacex's', 'falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'earth']</span></pre><p id="6455" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">Keras在标记字母之前降低了所有字母的大小写。你可以想象，这为我们节省了很多时间！</p><h1 id="ccc9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">6.使用Gensim进行标记化</h1><p id="0913" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">我们将在这里介绍的最后一种标记化方法是使用Gensim库。<strong class="jf hj">它是一个用于无监督主题建模和自然语言处理的开源库</strong>，旨在从给定文档中自动提取语义主题。</p><p id="cf1c" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">以下是安装Gensim的方法:</p><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="4aba" class="lz ig hi lv b fi ma mb l mc md">pip install gensim</span></pre><p id="de54" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">我们可以使用<em class="ln"> gensim.utils </em>类导入<em class="ln"> tokenize </em>方法来执行单词标记化。</p><p id="bdc8" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">词语标记化</strong></p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="03cb" class="lz ig hi lv b fi ma mb l mc md">Outpur : ['Founded', 'in', 'SpaceX', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 'Mars', 'In', 'SpaceX', 's', 'Falcon', 'became', 'the', 'first', 'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth']</span></pre><p id="aacb" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">句子标记化</strong></p><p id="0174" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">为了执行句子标记化，我们使用来自<em class="ln">gensim . summerization . text tcleaner</em>类的<em class="ln"> split_sentences </em>方法:</p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="ls lt l"/></div></figure><pre class="kz la lb lc fd lu lv lw lx aw ly bi"><span id="183d" class="lz ig hi lv b fi ma mb l mc md">Output : ['Founded in 2002, SpaceX's mission is to enable humans to become a spacefaring civilization and a multi-planet ', 'species by building a self-sustaining city on Mars.', 'In 2008, SpaceX's Falcon 1 became the first privately developed ', 'liquid-fuel launch vehicle to orbit the Earth.']</span></pre><p id="e0e7" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">你可能已经注意到Gensim对标点符号非常严格。每当遇到标点符号时，它就会拆分。在句子分割中，Gensim在遇到“\n”时标记文本，而其他库忽略它。</p><h1 id="d4a1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结束注释</h1><p id="7612" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">标记化是整个NLP流程中的一个关键步骤。我们不能不首先清理文本就直接进入模型构建部分。</p><p id="767c" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">在本文中，我们看到了给定文本的六种不同的标记化方法(单词和句子)。还有其他方法，但这些方法足以让你开始这个话题。</p><p id="4c26" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">我将在以后的文章中介绍其他文本清理步骤，如删除停用词、词性标注和识别命名实体。在那之前，继续学习！</p><p id="81ca" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">你也可以在分析Vidhya的Android应用上阅读这篇文章</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mk"><img src="../Images/6349c83d7803217dc7e6d269b6e8e905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/0*AnB5JSffmUlhq-Vj.png"/></div></div></figure><p id="55b8" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">相关文章</p></div><div class="ab cl ml mm gp mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hb hc hd he hf"><p id="9655" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><em class="ln">原载于2019年7月18日</em><a class="ae ku" href="https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/" rel="noopener ugc nofollow" target="_blank"><em class="ln">【https://www.analyticsvidhya.com】</em></a><em class="ln">。</em></p></div></div>    
</body>
</html>