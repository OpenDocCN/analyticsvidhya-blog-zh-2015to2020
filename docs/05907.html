<html>
<head>
<title>Dog Breed Classifier — Power of Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">犬种分类器——神经网络的力量</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/dog-breed-classifier-power-of-neural-networks-a277f4ad91be?source=collection_archive---------16-----------------------#2020-05-05">https://medium.com/analytics-vidhya/dog-breed-classifier-power-of-neural-networks-a277f4ad91be?source=collection_archive---------16-----------------------#2020-05-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="00c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不仅把狗，而且把人的形象也归类为狗的品种，这是多么有趣啊！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/d515effc404b7752392c88f103e7d560.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQVbkZK-AwzpwACOvAi5rQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">人工神经网络<a class="ae jt" href="https://commons.wikimedia.org/wiki/File:Single-layer_feedforward_artificial_neural_network.png" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="4af8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi ju translated"><span class="l jv jw jx bm jy jz ka kb kc di">令人难以置信的是，上面显示的边和节点创造了一套强大的算法，能够漂亮地识别模式。这些都是在人脑的基础上建立的，人脑可以通过一种机器感知分类来解释感官数据。它拍摄图像、声音、文本、时间序列等。所有真实世界的数据，并将其转换为数字向量以识别模式。</span></p><p id="3797" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我们将更多地关注<strong class="ih hj">卷积神经网络</strong> (ConvNets或CNN)，它是<strong class="ih hj">深度神经网络</strong>的一个类别，已被证明在分析视觉图像尤其是图像识别和分类领域非常有效。为了进一步理解这一点，我们将通过一个卷积神经网络来处理现实世界中用户提供的图像。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kd"><img src="../Images/6e3a6c67ee2ace215fbeaaef7debfba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kum6fk7tzPjW5Qm41nUGSg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://unsplash.com/photos/yihlaRCCvd4" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="f36b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">给定一张狗的图像，该算法将识别潜在的狗品种。如果提供一个人的形象，代码将识别相似的狗品种。</p><p id="b6bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">听起来很有趣不是吗？让我们潜入更深的地方…</p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><p id="93af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个非常简单的7步流程<strong class="ih hj"/>,不同于在幕后运行的复杂的神经网络流程:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kl"><img src="../Images/07acbc1d1bbb25a082fa4ef314a43166.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*7o4Ud_KtLZEOsumWTbURtA.gif"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">卷积神经网络<a class="ae jt" href="https://commons.wikimedia.org/wiki/File:Convolutional_Neural_Network.gif" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="1205" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="km">第一步:</em> </strong> <em class="km">导入数据集<br/> </em> <strong class="ih hj"> <em class="km">第二步</em> </strong> <em class="km">:检测人类<br/> </em> <strong class="ih hj"> <em class="km">第三步:</em> </strong> <em class="km">检测狗<br/> </em> <strong class="ih hj"> <em class="km">第四步:</em> </strong> <em class="km">创建CNN对狗的品种进行分类<br/> </em> <strong class="ih hj"> <em class="km">第五步:) <br/> </em> <strong class="ih hj"> <em class="km">第六步:</em> </strong> <em class="km">写一个算法绑定上面的步骤<br/> </em> <strong class="ih hj"> <em class="km">第七步:</em> </strong> <em class="km">测试算法</em></strong></p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h1 id="79b0" class="kn ko hi bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated"><strong class="ak">第一步:</strong>导入数据集</h1><p id="8d02" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">我们从从<a class="ae jt" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip" rel="noopener ugc nofollow" target="_blank"> Udacity </a>导入所需的库和数据集开始。数据集有<strong class="ih hj">~ 8500张狗的图片，横跨133个狗品种</strong>。导入后，我们将数据分为训练、验证和测试数据集，分布分别为80%、10%和10%，并存储每个数据集的特性和目标。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="737b" class="lv ko hi lr b fi lw lx l ly lz">from sklearn.datasets import load_files       <br/>from keras.utils import np_utils<br/>import numpy as np<br/>from glob import glob</span><span id="5588" class="lv ko hi lr b fi ma lx l ly lz"># define function to load train, test, and validation datasets<br/>def load_dataset(path):<br/>    data = load_files(path)<br/>    dog_files = np.array(data['filenames'])<br/>    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)<br/>    return dog_files, dog_targets</span><span id="1d89" class="lv ko hi lr b fi ma lx l ly lz"># load train, test, and validation datasets<br/>train_files, train_targets = load_dataset('../../../data/dog_images/train')<br/>valid_files, valid_targets = load_dataset('../../../data/dog_images/valid')<br/>test_files, test_targets = load_dataset('../../../data/dog_images/test')</span><span id="576f" class="lv ko hi lr b fi ma lx l ly lz"># load list of dog names<br/>dog_names = [item[20:-1] for item in sorted(glob("../../../data/dog_images/train/*/"))]</span></pre><h1 id="12bf" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">第二步:探测人类</h1><p id="86ae" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">在这一步，我们将编写一个函数来检测图像是否有人脸。为了能够设计这个函数，我们首先从<a class="ae jt" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip" rel="noopener ugc nofollow" target="_blank"> Udacity </a>导入一个人类图像数据集。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="b6f1" class="lv ko hi lr b fi lw lx l ly lz">import random<br/>random.seed(8675309)</span><span id="ed3f" class="lv ko hi lr b fi ma lx l ly lz"># load filenames in shuffled human dataset<br/>human_files = np.array(glob("../../../data/lfw/*/*"))<br/>random.shuffle(human_files)</span><span id="5633" class="lv ko hi lr b fi ma lx l ly lz"># print statistics about the dataset<br/>print('There are %d total human images.' % len(human_files))</span></pre><p id="847f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，为了检测人脸，我们使用OpenCV的<a class="ae jt" href="https://docs.opencv.org/trunk/db/d28/tutorial_cascade_classifier.html" rel="noopener ugc nofollow" target="_blank"> Haar基于特征的级联分类器</a>的实现。OpenCV提供了许多预先训练的人脸检测器，作为XML文件存储在<a class="ae jt" href="https://github.com/opencv/opencv/tree/master/data/haarcascades" rel="noopener ugc nofollow" target="_blank"> Github </a>上，我们下载了其中一个检测器。正如我们在下面看到的，在检测到人脸之前，算法还需要一些额外的图像转换步骤。下面的<code class="du mg mh mi lr b">face_detector</code>函数将图像路径作为参数，如果检测到人脸，则返回<code class="du mg mh mi lr b">True</code>，否则返回<code class="du mg mh mi lr b">False</code>。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="1312" class="lv ko hi lr b fi lw lx l ly lz">import cv2                <br/>import matplotlib.pyplot as plt                        <br/>%matplotlib inline</span><span id="e624" class="lv ko hi lr b fi ma lx l ly lz"># extract pre-trained face detector<br/>face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')</span><span id="e98b" class="lv ko hi lr b fi ma lx l ly lz"># returns "True" if face is detected in image stored at img_path<br/>def face_detector(img_path):<br/>    img = cv2.imread(img_path)<br/>    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br/>    faces = face_cascade.detectMultiScale(gray)<br/>    return len(faces) &gt; 0</span></pre><p id="b955" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们从之前下载的人和狗的数据中抽取100个图像样本，并通过函数运行它们。我们的模型能够在<strong class="ih hj"> 100% </strong>的人图像和<strong class="ih hj"> 11% </strong>的狗图像中检测出人脸。很好，但这足够了吗？</p><h1 id="163b" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">第三步:探测狗</h1><p id="f9c3" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">在这一步中，我们使用一个预先训练好的<a class="ae jt" href="http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006" rel="noopener ugc nofollow" target="_blank"> ResNet-50 </a>模型来检测图像中的狗。我们首先下载ResNet-50模型以及已经在<a class="ae jt" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>上训练过的权重，这是一个非常大的流行数据集，用于图像分类和其他视觉任务。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="7c7b" class="lv ko hi lr b fi lw lx l ly lz">from keras.applications.resnet50 import ResNet50</span><span id="b95b" class="lv ko hi lr b fi ma lx l ly lz"># define ResNet50 model<br/>ResNet50_model = ResNet50(weights='imagenet')</span></pre><p id="b407" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑到真实世界的图像可能有多混乱，通常需要在输入模型之前进行一些预处理。下面的<code class="du mg mh mi lr b">path_to_tensor</code>函数首先将所有图像的大小调整为224×224像素的正方形<em class="km">(关键步骤之一)</em>。接下来，图像被转换成4D数组<em class="km">(又名4D张量)</em>，因为Keras CNN在这里使用TensorFlow作为后端。<em class="km">张量是矩阵到N维空间的推广</em>。<em class="km">更多详情请看这篇伟大的</em> <a class="ae jt" href="https://www.kdnuggets.com/2018/05/wtf-tensor.html" rel="noopener ugc nofollow" target="_blank"> <em class="km">帖子</em> </a> <em class="km"> by </em> <a class="mj mk ge" href="https://medium.com/u/a0bc63d95eb0?source=post_page-----a277f4ad91be--------------------------------" rel="noopener" target="_blank"> <em class="km">马修梅奥</em> </a> <em class="km">。</em></p><p id="2050" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入形状:<strong class="ih hj"> (nb_samples，rows，columns，channels) </strong>其中，<br/> <code class="du mg mh mi lr b">nb_samples</code>为图像(或样本)总数，<br/> <code class="du mg mh mi lr b">rows</code>，<code class="du mg mh mi lr b">columns</code>，<code class="du mg mh mi lr b">channels</code>分别对应每幅图像的高度，长度，深度。我们的4D张量是(1，224，224，3)。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="f137" class="lv ko hi lr b fi lw lx l ly lz">from keras.preprocessing import image                  <br/>from tqdm import tqdm</span><span id="d624" class="lv ko hi lr b fi ma lx l ly lz">def path_to_tensor(img_path):<br/>    # loads RGB image as PIL.Image.Image type<br/>    img = image.load_img(img_path, target_size=(224, 224))<br/>    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)<br/>    x = image.img_to_array(img)<br/>    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor<br/>    return np.expand_dims(x, axis=0)</span><span id="dab1" class="lv ko hi lr b fi ma lx l ly lz">def paths_to_tensor(img_paths):<br/>    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]<br/>    return np.vstack(list_of_tensors)</span></pre><p id="a8a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在模型可用于预测之前，需要一些额外的预处理步骤，如将RGB图像转换为BGR，通过从每个图像的每个像素中减去平均像素来归一化模型等。这都由<code class="du mg mh mi lr b">preprocess_input</code>功能负责。要了解更多信息，请点击查看代码<a class="ae jt" href="https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="e90d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们的图像已经格式化了，我们准备把它提供给ResNet-50并进行预测。下面的<code class="du mg mh mi lr b">predict</code>函数返回图像属于特定ImageNet类别的预测概率。为了将返回的整数映射到模型的预测对象类，请使用这个<a class="ae jt" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank">字典</a>。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="c8a0" class="lv ko hi lr b fi lw lx l ly lz">from keras.applications.resnet50 import preprocess_input, decode_predictions</span><span id="c22f" class="lv ko hi lr b fi ma lx l ly lz">def ResNet50_predict_labels(img_path):<br/>    # returns prediction vector for image located at img_path<br/>    img = preprocess_input(path_to_tensor(img_path))<br/>    return np.argmax(ResNet50_model.predict(img))</span></pre><p id="4144" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">字典中所有的狗类别都对应于151-268键。因此，要检测一张狗脸，我们需要检查下面的<code class="du mg mh mi lr b">ResNet50_predict_labels</code>函数是否返回一个介于151和268(含)之间的值。如果检测到狗脸，该函数返回<code class="du mg mh mi lr b">True</code>，否则返回<code class="du mg mh mi lr b">False</code>。</p><p id="4432" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似于步骤2，我们通过这个函数运行100个图像的样本。我们的模型能够在狗图像的<strong class="ih hj"> 100% </strong>和人图像的<strong class="ih hj"> 0% </strong>中检测到狗脸。</p><h1 id="9b39" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">第四步:创建一个CNN来分类狗的品种</h1><p id="d518" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">既然我们能够在图像中检测出人和狗的脸，我们的下一个目标是对狗的品种进行分类。我们创建了一个CNN模型来帮助这些分类预测。在我们开始建立模型之前，我们通过将每个图像中的每个像素除以255来重新缩放图像。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="f949" class="lv ko hi lr b fi lw lx l ly lz"># pre-process the data for Keras<br/>train_tensors = paths_to_tensor(train_files).astype('float32')/255<br/>valid_tensors = paths_to_tensor(valid_files).astype('float32')/255<br/>test_tensors = paths_to_tensor(test_files).astype('float32')/255</span></pre><p id="a9ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是来自我们分类模型的<strong class="ih hj"> CNN架构</strong>。CNN的设计目标通常是使输入阵列比其长度或宽度更深。在下面使用的3个<strong class="ih hj">卷积层</strong>中，我增加了过滤器的数量，以增加特征的堆叠，从而增加其深度。每个卷积层之后是一个<strong class="ih hj">最大池层</strong>，以减少图像的空间维度。然后，我们将矩阵展平成一个向量，然后将它送入一个完全连接的<strong class="ih hj">密集层</strong>，因为这些不接受多维数组。该层使用softmax激活函数来获得每个类别的分类概率，以及133个输出节点，在我们的训练数据中，每个狗类别1个。<em class="km">要详细了解每个参数，以及这些参数是如何计算的，请参见本</em> <a class="ae jt" href="https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d" rel="noopener" target="_blank"> <em class="km">帖子</em></a><em class="km">by</em><a class="mj mk ge" href="https://medium.com/u/4ed456ddae20?source=post_page-----a277f4ad91be--------------------------------" rel="noopener" target="_blank"><em class="km">Rakshith Vasudev</em></a><em class="km">。</em></p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="6e0c" class="lv ko hi lr b fi lw lx l ly lz">from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D<br/>from keras.layers import Dropout, Flatten, Dense<br/>from keras.models import Sequential</span><span id="8507" class="lv ko hi lr b fi ma lx l ly lz"># Define your architecture.</span><span id="5ae8" class="lv ko hi lr b fi ma lx l ly lz">model = Sequential()<br/># Convolutional layers and maxpooling layers, note: all images are 224*224 pixel<br/>model.add(Conv2D(filters=16, kernel_size=2, strides=1, padding='same',activation='relu', input_shape=[224,224,3]))<br/>model.add(MaxPooling2D(pool_size=2, strides=1, padding='same'))</span><span id="5ed8" class="lv ko hi lr b fi ma lx l ly lz">model.add(Conv2D(filters=32, kernel_size=2, strides=2, padding='same',activation='relu'))<br/>model.add(MaxPooling2D(pool_size=2, strides=1, padding='same'))</span><span id="696e" class="lv ko hi lr b fi ma lx l ly lz">model.add(Conv2D(filters=64, kernel_size=2, strides=2, padding='same',activation='relu'))<br/>model.add(MaxPooling2D(pool_size=2, strides=1, padding='same'))<br/>#model.add(GlobalAveragePooling2D())</span><span id="c9bf" class="lv ko hi lr b fi ma lx l ly lz"># Flatten the array into a vector and feed to a dense layer<br/>model.add(Flatten())<br/>model.add(Dense(133, activation='softmax'))</span><span id="5179" class="lv ko hi lr b fi ma lx l ly lz">model.summary()</span></pre><p id="ca5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们<strong class="ih hj">编译</strong>，而<strong class="ih hj">训练</strong>我们的模型。ModelCheckpoint用于保存获得最佳验证损失的模型。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="d160" class="lv ko hi lr b fi lw lx l ly lz">from keras.callbacks import ModelCheckpoint</span><span id="1f28" class="lv ko hi lr b fi ma lx l ly lz">model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])</span><span id="3a4c" class="lv ko hi lr b fi ma lx l ly lz">checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', <br/>                               verbose=1, save_best_only=True)</span><span id="a59a" class="lv ko hi lr b fi ma lx l ly lz">model.fit(train_tensors, train_targets, <br/>          validation_data=(valid_tensors, valid_targets),<br/>          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)</span></pre><p id="2b43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们的模型被训练，我们加载之前保存的权重，并使用它在我们的<strong class="ih hj">测试</strong>数据上运行模型，以评估我们的模型的准确性。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="52ab" class="lv ko hi lr b fi lw lx l ly lz">model.load_weights('saved_models/weights.best.from_scratch.hdf5')</span><span id="c2ce" class="lv ko hi lr b fi ma lx l ly lz"># get index of predicted dog breed for each image in test set<br/>dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]</span><span id="8bc9" class="lv ko hi lr b fi ma lx l ly lz"># report test accuracy<br/>test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)<br/>print('Test accuracy: %.4f%%' % test_accuracy)</span></pre><p id="244c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个模型工作正常，并且会给出<strong class="ih hj"> ~7% </strong>的精度。你一定在想，这么多才能得到这么低的精度？请记住，这是没有任何参数微调和数据增强。这是接下来的步骤将有助于提高准确性的地方。</p><h1 id="2457" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">第五步:使用预先构建的Keras CNN模型，并修改这些模型来对狗的品种进行分类(使用迁移学习)</h1><p id="34cc" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">Keras中有一些突破性的预建CNN架构，可以通过迁移学习来使用。VGG16、VGG19、ResNet50、Xception、InceptionV3。这些模型有助于在不牺牲准确性的情况下减少训练时间。这里使用了预先训练的VGG-16模型，并将其输入到我们的模型中。我们只添加了一个全局平均池层<em class="km">(减少维度)</em>和一个具有softmax激活函数的全连接层<em class="km">(为每个狗类别获得一个节点)</em>。</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="619e" class="lv ko hi lr b fi lw lx l ly lz">bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')<br/>train_VGG16 = bottleneck_features['train']<br/>valid_VGG16 = bottleneck_features['valid']<br/>test_VGG16 = bottleneck_features['test']</span><span id="fe1e" class="lv ko hi lr b fi ma lx l ly lz"># CNN architecture using Transfer Learning<br/>VGG16_model = Sequential()<br/>VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))<br/>VGG16_model.add(Dense(133, activation='softmax'))</span><span id="e276" class="lv ko hi lr b fi ma lx l ly lz">VGG16_model.summary()</span></pre><p id="c04c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们通过这个新训练的模型和预先计算的特征运行我们的测试数据时，我们的准确性在更短的时间内增加到了<strong class="ih hj"> ~45% </strong>，这是一个显著的改进。这是因为现在网络中只有2层正在处理。使用ResNet50模型，准确率进一步跃升至<strong class="ih hj"> ~82% </strong>，这是我最终在代码中使用的。</p><h1 id="9dc2" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">第六步:写一个算法来绑定上面的步骤</h1><p id="648d" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">这是我们把所有不同的部分放在一起的步骤。我们编写了一个简单的算法，它接受一个图像路径，并首先确定它是否包含人脸、狗脸，或者两者都不包含。然后，</p><ul class=""><li id="6ea3" class="ml mm hi ih b ii ij im in iq mn iu mo iy mp jc mq mr ms mt bi translated">如果在图像中检测到一只<strong class="ih hj">狗</strong>，返回预测的品种。</li><li id="5949" class="ml mm hi ih b ii mu im mv iq mw iu mx iy my jc mq mr ms mt bi translated">如果在图像中检测到一个<strong class="ih hj">人</strong>，返回相似的狗品种。</li><li id="448e" class="ml mm hi ih b ii mu im mv iq mw iu mx iy my jc mq mr ms mt bi translated">如果在图像中没有检测到<strong class="ih hj">或</strong>，则提供指示错误的输出。</li></ul><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="d1c1" class="lv ko hi lr b fi lw lx l ly lz">def display_detect_image(img_path):<br/>    detect_breed(img_path)<br/>    # load color (BGR) image<br/>    img = cv2.imread(img_path)<br/>    # convert BGR image to RGB for plotting<br/>    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)<br/>    # display the image<br/>    plt.imshow(cv_rgb)<br/>    return plt.show()</span><span id="91a6" class="lv ko hi lr b fi ma lx l ly lz">def detect_breed(img_path):<br/>    # check if image is human face<br/>    if face_detector(img_path) == True:<br/>        return print("Hello human! Your face resembles a: ",Resnet50_predict_breed(img_path).str.split(".")[-1])<br/>    # check if image is dog face<br/>    elif dog_detector(img_path) == True:<br/>        return print("Hello dog! Your predicted breed is: ",Resnet50_predict_breed(img_path).str.split(".")[-1])<br/>    # else print an error message<br/>    else:<br/>        return print("Oops! This is neither a human nor a dog")</span></pre><h1 id="9894" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">步骤7:测试我们的算法</h1><p id="866e" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">在这一部分，我们将看到我们算法的强大之处，并尝试一下！我随机提供了一些狗和人的图像，瞧！算法预测品种。现在，如果你喜欢街上或公园里的一只狗，你想知道它的品种，不需要问主人，只需点击一张图片，并通过模型运行它😄</p><p id="7c6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="km">要访问完整的代码，请点击</em>  <em class="km">查看我的GitHub的链接。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mz"><img src="../Images/d1f36ee2c34e4d8def33e91070c650e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uu65_iBJ7sPczlkiBs5sWg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es na"><img src="../Images/350754a206c14e66e7f449ffb7fe528c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sVoq5OyitvYmtnvFTI21Ng.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nb"><img src="../Images/58b1bec9a259e5be388b3a6abca1d524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qUCZjX50j-GWM2PeYSbeoQ.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nc"><img src="../Images/db17803e4d71baed59bf7d3d8a939fd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OWAdy4lSjLQGjp0sB-aZmg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nd"><img src="../Images/46faeafc5eb40cbc2da5e4cf29c7e1b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kff4SG9NJ7Pt0mTJ9j_WkA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ne"><img src="../Images/71c2ee7ca01a48b8dac5bd096b6db5df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z_RSKP2l5DZqhwZkufiFCQ.png"/></div></div></figure><blockquote class="nf ng nh"><p id="f06f" class="if ig km ih b ii ij ik il im in io ip ni ir is it nj iv iw ix nk iz ja jb jc hb bi translated"><strong class="ih hj">参考文献:</strong></p><p id="581b" class="if ig km ih b ii ij ik il im in io ip ni ir is it nj iv iw ix nk iz ja jb jc hb bi translated"><a class="ae jt" href="https://pathmind.com/wiki/neural-network" rel="noopener ugc nofollow" target="_blank">https://pathmind.com/wiki/neural-network</a></p><p id="07c6" class="if ig km ih b ii ij ik il im in io ip ni ir is it nj iv iw ix nk iz ja jb jc hb bi translated"><a class="ae jt" href="https://analyticsindiamag.com/tensorflow-vs-keras-which-one-should-you-choose/" rel="noopener ugc nofollow" target="_blank">https://analyticsindiamag . com/tensor flow-vs-keras-你应该选择哪一个/ </a></p></blockquote></div></div>    
</body>
</html>