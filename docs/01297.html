<html>
<head>
<title>Hyperparameter Tuning and Evaluation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超参数调谐和评估</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hyperparameter-tuning-and-evaluating-3df8032da76c?source=collection_archive---------11-----------------------#2019-10-13">https://medium.com/analytics-vidhya/hyperparameter-tuning-and-evaluating-3df8032da76c?source=collection_archive---------11-----------------------#2019-10-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="cd3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">网格搜索调整、k倍评估和基于树的模型的特征重要性</em></p><p id="b1e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了改进机器学习模型或简单地创建好的模型，一个人需要理解的关键概念之一是<strong class="ih hj">超参数</strong>。机器学习模型可能有大量的参数，其中许多参数对于机器从输入数据中实际学习和正确归纳非常关键。</p><p id="25c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些参数中的一些在训练过程中不断更新，通过使用技术-如<a class="ae je" href="https://en.wikipedia.org/wiki/Gradient_descent" rel="noopener ugc nofollow" target="_blank">梯度下降</a>。另一方面，其他参数在训练期间保持固定，因为它们是训练本身的定义。这些固定的参数就是我们所说的<strong class="ih hj">超参数</strong>。</p><p id="f64f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如前所述，超参数定义了模型的训练过程。例如，在处理集合方法时，他们会告诉模型:使用多少个虚拟估计量，停止标准是什么，树的最大可能深度，单叶的最小数据点数量，等等。对于一个模型来说，这些都是非常相关的特征，并且根据问题的不同，可能是获得一个具有随机精度的模型和一个最先进的模型之间的差异。</p><p id="d0cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鉴于此，为了找到解决机器学习问题的最佳模型，我们需要找到正确的超参数，由于我们无法在训练期间更新这些参数，为了找到它们，我们将一次又一次地训练模型。再一次。</p><h2 id="b9d0" class="jf jg hi bd jh ji jj jk jl jm jn jo jp iq jq jr js iu jt ju jv iy jw jx jy jz bi translated">网格搜索</h2><p id="9020" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq kc is it iu kd iw ix iy ke ja jb jc hb bi translated">最简单也可能是最著名的超参数调整方法是<strong class="ih hj">网格搜索</strong>。在网格搜索中，用户必须定义一个<strong class="ih hj">超参数空间</strong>，即一个数值范围或列表，用于每个所需参数的训练。网格搜索方法将为这些参数的每个可能组合训练一个模型<strong class="ih hj">，并将返回每个单一训练组合的结果。</strong></p><p id="9fb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Scikit-Learn中，可以通过将模型和数据输入sk Learn . model _ selection . gridsearchcv来使用网格搜索。</p><h2 id="d35b" class="jf jg hi bd jh ji jj jk jl jm jn jo jp iq jq jr js iu jt ju jv iy jw jx jy jz bi translated">k倍和分层</h2><p id="f32f" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq kc is it iu kd iw ix iy ke ja jb jc hb bi translated">当训练一堆不同的模型时，确保模型之间的比较是公平的也是非常重要的。在机器学习中发现的两个常见问题是不平衡的训练数据和。</p><p id="b369" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了解决这种不平衡，有一种叫做<strong class="ih hj">分层</strong>的东西，通常是用户在创建模型时设置的。分层基本上是将输入数据分成训练和测试，同时保持其平衡的行为。</p><p id="2078" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，如果您要拆分一个包含50个人样本的数据集，其中40人是男性，10人是女性，那么有很小的可能性(考虑到20%的测试数据)您的培训将只考虑男性，并且您的测试将只针对女性数据。根据数据集的内容，这可能会对结果产生巨大影响。对该数据集进行分层将通过确保男性和女性在训练和测试数据中得到平等的表示来解决这个问题。</p><p id="5c40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是即使我们在某些方面取得了平衡，我们怎么能确定我们的数据分割的当前配置没有不切实际地很好地工作呢？有时，只是碰巧，我们的训练数据和测试数据可能匹配得太好，或者太差，如果应用于未来收集的数据，最终给出的分数就不会相同。这个问题通常通过使用<strong class="ih hj"> K型折叠</strong>来解决。</p><p id="1913" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将数据分割成K倍意味着数据被分割成相同大小的<strong class="ih hj"> <em class="jd"> K </em> </strong>随机分割，对于每个分割，将在所有其他分割的组合上训练一个模型，然后在该分割上测试它。在<strong class="ih hj"> K </strong>测试之后，用户可以从每个测试中取平均值，并将其用作所选模型的更真实的结果。</p><p id="7c18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">组合分层和K-Folds也是机器学习中非常常见的方法，实际上是前面提到的GridSearchCV函数的<em class="jd">默认</em>配置。</p><h2 id="6d2b" class="jf jg hi bd jh ji jj jk jl jm jn jo jp iq jq jr js iu jt ju jv iy jw jx jy jz bi translated">反对过度拟合的随机性</h2><p id="f2ef" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq kc is it iu kd iw ix iy ke ja jb jc hb bi translated">随机性是一个很好的例子，说明单个参数如何对模型产生巨大影响。在处理<a class="ae je" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" rel="noopener ugc nofollow" target="_blank">决策树分类器</a>时，是否随机拆分数据的选择取决于用户。实际上，在构建决策树的<a class="ae je" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html" rel="noopener ugc nofollow" target="_blank"> bagging分类器</a>时，这种简单的参数选择可能会将bagging分类器变成<a class="ae je" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">随机森林分类器</a>。</p><p id="fd90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种添加到数据分割中的随机性使得bagging分类器能够找到数据上的模式，这些模式在只进行最佳分割时难以识别。这在试图避免过度拟合时非常有用。当基于树的算法只寻找最佳分割选择时，它们会很快过度拟合，因为一些关键的数据特征可能不会被探索。通过随机分割，可以测试许多可能性，然后由算法相应地测量/加权。这意味着更多的元素将被</p><p id="93e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以使用scikit-learn来测试这一点。</p><pre class="kf kg kh ki fd kj kk kl km aw kn bi"><span id="5bf7" class="jf jg hi kk b fi ko kp l kq kr"><strong class="kk hj"># import the necessary stuff</strong><br/>from sklearn.datasets import fetch_20newsgroups_vectorized<br/>from sklearn.ensemble import BaggingClassifier<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.model_selection import cross_val_score</span><span id="c7cb" class="jf jg hi kk b fi ks kp l kq kr"><strong class="kk hj"># load our dataset</strong><br/>data = fetch_20newsgroups_vectorized()</span><span id="c41e" class="jf jg hi kk b fi ks kp l kq kr"><strong class="kk hj"># set non-random classifier</strong><br/>not_random_bagging_clf = BaggingClassifier(DecisionTreeClassifier(splitter=<strong class="kk hj"><em class="jd">'best'</em></strong>, max_depth=2), n_estimators=500, max_features=0.33, oob_score=True)</span><span id="fdbb" class="jf jg hi kk b fi ks kp l kq kr"><strong class="kk hj"># set random classifier</strong><br/>random_bagging_clf = BaggingClassifier(DecisionTreeClassifier(splitter=<strong class="kk hj"><em class="jd">'random'</em></strong>, max_depth=2), n_estimators=500, max_features=0.33, oob_score=True)</span><span id="f66a" class="jf jg hi kk b fi ks kp l kq kr"><strong class="kk hj"># score each</strong><br/>oob_score_nr = cross_val_score(not_random_bagging_clf, data.data, data.target, cv=5).mean()<br/>oob_score_r = cross_val_score(random_bagging_clf, data.data, data.target, cv=5).mean()</span></pre><p id="e70c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">非随机分类器的5重交叉验证结果:</p><pre class="kf kg kh ki fd kj kk kl km aw kn bi"><span id="a663" class="jf jg hi kk b fi ko kp l kq kr">OOB Score: 0.3808</span></pre><p id="85a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于随机分类器:</p><pre class="kf kg kh ki fd kj kk kl km aw kn bi"><span id="8a88" class="jf jg hi kk b fi ko kp l kq kr">OOB Score: 0.5017</span></pre><p id="53b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们能够通过简单地改变<strong class="ih hj">分离器</strong>参数来成功地增加我们的OOB分数。</p><h2 id="4b94" class="jf jg hi bd jh ji jj jk jl jm jn jo jp iq jq jr js iu jt ju jv iy jw jx jy jz bi translated">权衡:理解</h2><p id="3718" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq kc is it iu kd iw ix iy ke ja jb jc hb bi translated">但是没有什么是完美的\_(ಠ_ಠ)_/，随机森林中的随机性所带来的改进让我们失去了基于树的方法的综合方面。而在常规树方法中，我们可以理解某个拆分决策是基于一组特定的规则做出的，当模型中发生随机性时，它会产生影响，使一些拆分决策<strong class="ih hj">不可预测</strong>(因为它是<strong class="ih hj">随机的</strong>！)</p><h2 id="7694" class="jf jg hi bd jh ji jj jk jl jm jn jo jp iq jq jr js iu jt ju jv iy jw jx jy jz bi translated">特征重要性</h2><p id="c4f1" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq kc is it iu kd iw ix iy ke ja jb jc hb bi translated">但是随机森林的另一个有趣之处是由算法生成的<strong class="ih hj">特征重要性</strong>“报告”。尽管重要性分数最初不是一个超参数，但它可以用于像<strong class="ih hj">特征选择</strong>这样的事情，并且可以作为调整过程的一部分插入到模型的管道中。</p><p id="8883" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据科学家可能希望在网格搜索器模型中测试不同的特征维度大小，以检查所有的特征是否实际相关。如果不同维度的模型具有相同的结果，您可能希望保留更简单的模型(维度更少)，因为它可能</p><p id="4980" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">特性重要性并不是一个非常客观的术语，就像不同的人对什么使某件事情变得重要会有不同的看法一样，有许多不同的方式来衡量特性的重要性。著名的梯度增强框架<a class="ae je" href="https://en.wikipedia.org/wiki/XGBoost" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>单独提供了3种不同类型的特征重要性度量:“权重”、“增益”和“覆盖”。下面是它们与我们的示例数据集中的随机森林(RFs)的比较:</p><figure class="kf kg kh ki fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es kt"><img src="../Images/a548c3a4b1482ce3542b5eaf3fe83bce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sgSi0Eswcz_oEuCUJaN5bA.png"/></div></div></figure><p id="9c24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里的特征没有名称，通过索引来识别。有<strong class="ih hj"> 130107 </strong>不同的特性，您可以看到，尽管每次测量仅显示20个元素，但前20个结果之间有一些“交集”。例如:</p><ul class=""><li id="9fb2" class="lb lc hi ih b ii ij im in iq ld iu le iy lf jc lg lh li lj bi translated"><em class="jd">特征33301 </em>是RFs中的<strong class="ih hj">第1</strong>和<em class="jd">中的<strong class="ih hj">第5</strong>重量</em>；</li><li id="3df8" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated"><em class="jd">特征58487 </em>在<em class="jd">盖</em>和<em class="jd">增益中均为<strong class="ih hj">第一</strong>；</em></li><li id="3017" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated"><em class="jd">特性104409 </em>在<strong class="ih hj">RFs和<em class="jd"> gain </em>中都是前10 </strong></li></ul><p id="b549" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">体重</em>和<em class="jd">增益</em>共有6个元素在它们的前20名中，<em class="jd">封面</em>和<em class="jd">增益</em>也共有6个，<em class="jd">体重</em>和<em class="jd">封面</em>一个都没有。《随机森林》前20名共有12个元素<em class="jd">权重</em>，4个<em class="jd">增益</em>，没有一个<em class="jd">覆盖</em>。这可能会让我们认为重要性的RF测量更接近于<em class="jd">、</em>，但事实并非如此，因为<a class="ae je" href="https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27" rel="noopener" target="_blank">对<em class="jd">、</em>、</a>、<em class="jd">、</em>增益的定义更接近于我们的bagging模型如何测量重要性。</p><p id="58d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个重要的(！)练习理解特性重要性是主观的，在您的模型中尝试不同的重要性度量是一个好主意。这不仅将您使用的特性数量转化为一个<em class="jd">超参数</em>，还转化为度量标准。</p><p id="6211" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您的来访，祝您在构建机器学习管道的过程中好运！:)</p></div></div>    
</body>
</html>