<html>
<head>
<title>Classifying asteroids using ML: A beginner’s tale (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用最大似然法分类小行星:初学者的故事(第二部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classifying-asteroids-using-ml-a-beginners-tale-part-2-1e379f7a781d?source=collection_archive---------29-----------------------#2020-07-13">https://medium.com/analytics-vidhya/classifying-asteroids-using-ml-a-beginners-tale-part-2-1e379f7a781d?source=collection_archive---------29-----------------------#2020-07-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/6052c8c5dad1afa3451f18fccd081eec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*clBdvl-wsylDXZDD9kUwmw.jpeg"/></div></div></figure><p id="1857" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">嗨！这是使用ML第1部分分类小行星的后续文章。在第一篇文章中，我介绍了一些非常基本的东西，如导入库、上传文件、执行标签编码、重采样以及出于与目标变量无关的原因而丢弃要素。如果你不知道如何做到这一切，我建议你访问以前的文章<a class="ae jo" rel="noopener" href="/@tarushipathak/classifying-asteroids-using-ml-a-beginners-tale-part-1-f4385458f13"> <strong class="is hj">这里</strong> </a>。</p><p id="db48" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇文章中，我将涵盖以下内容:</p><ul class=""><li id="7f72" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">相关热图</li><li id="2da3" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">标准化变量</li><li id="ce3a" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">实现最大似然算法</li></ul><p id="4305" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那我们开始吧！</p><h1 id="d827" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">相关热图</h1><p id="8a6a" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在删除列(这里的原因不是它们对目标变量的贡献)并进行其他必要的分析之后，我们前进到关联热图。相关热图通过颜色告诉我们变量之间的相关性有多强。用于计算相关性的公式是皮尔逊相关系数。大于零的值具有正相关性，这意味着两个变量的变化方向相同。负相关意味着它们会向相反的方向变化。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/e716c134205464bd6a7fc19d7943ad83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZUqgikTwgGgSpCQ_9V1vJg.png"/></div></div></figure><p id="0924" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">相关性热图通常用于删除与目标变量不相关的特征。解释相关性热图时的一个新手错误是丢弃显示负相关性的变量。负相关并不意味着完全没有关系。从上面的关联图中，你可以看到关联被赋予了颜色。相关性越强，颜色就越亮。</p><p id="336c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，我，有时，发现很难阅读，尤其是当它有这么多的变量。所以我倾向于用另一种我觉得更直观的方式来描绘这种相关性。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/559aaade9a7d1567e92d2d687109019b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tM-KzpQ35T6n6aHX84n-_A.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">与响应变量的相关性</figcaption></figure><p id="66a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面的图片中，您可以清楚地看到哪个特征与目标变量的相关性较弱。所以，我们会放弃Dist小姐。(千米)，木星组织和不变量，纪元密切度，半长轴，倾角，Asc节点，经度近日点，Arg轨道，周期近日点，时间，平均异常和平均运动。</p><p id="ab24" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，您将看到数据分析和ML的美妙之处。你对这50个变量一无所知，无论你放弃什么变量，都只是因为它们对目标变量没有贡献。如果你有天文学领域的知识，特别是关于小行星的知识，也许，去掉这些变量会太明显，但是，你没有，你仍然得出同样的结论。这就是数据分析的美妙之处。</p><h1 id="108b" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">归一化变量</strong></h1><p id="f2b1" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">如果特征变量的值太大，那么它们最终会对目标变量贡献更多，即使它们不相关。这就是为什么在对它们实现算法之前，我们必须对它们进行规范化。用于执行此操作的库称为标准缩放器。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/a3f3ea3e54b36ad9cb0134ec760572f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*MBwfYRllQG4Br_nRwoCcJQ.png"/></div></figure><p id="1033" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您只需分离特征和目标变量，从sklearn.preprocessing导入标准Scaler，并将其用于特征变量。</p><p id="bcf6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们的数据可以进行预测了。</p><h1 id="b46f" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">实现机器学习模型</h1><p id="070d" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">由于sklearn库，这实际上是最容易的部分之一。我们将使用逻辑回归，因为它是高度用于二元分类的模型之一。首先，我们使用train_test_split函数将数据集分为训练集和测试集。</p><p id="11dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这之后，我们简单地实现逻辑回归。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/7619e8adff8a3edf8965faf79bae9391.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*Q6g3yrrPeD2UKtfTi_9wNw.png"/></div></figure><p id="78a6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“拟合”方法可以拟合定型集上的模型，而“预测”方法可以帮助您对测试数据进行预测。然后将预测值与原始值进行比较，以返回精确度。分类报告是一个sklearn指标，它返回F1分数、精确度和召回率以及准确度。他们告诉你你的<strong class="is hj">分类</strong>模型有多好。</p><h1 id="8214" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">祝贺成功分类小行星！</strong></h1><p id="1381" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">希望你学到了一些东西！如果你愿意，留下一些评论和掌声吧！</p></div></div>    
</body>
</html>