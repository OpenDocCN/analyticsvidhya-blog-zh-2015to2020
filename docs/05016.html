<html>
<head>
<title>My First Image Classifying Model: Fashion_MNIST</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我的第一个图像分类模型:时尚_MNIST</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/my-first-image-classifying-model-fashion-mnist-89c85f4aa4e1?source=collection_archive---------4-----------------------#2020-04-08">https://medium.com/analytics-vidhya/my-first-image-classifying-model-fashion-mnist-89c85f4aa4e1?source=collection_archive---------4-----------------------#2020-04-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="b678" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="fc3f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">想象一下:你忙完一天的工作回到家。你的家人很高兴看到你回家。但是你放松的计划似乎变成了一场真正的灾难。你正在做晚饭，突然，你的孩子向你走来，说他们需要明天拍照时穿的衬衫。你开始恐慌，因为你的妻子/丈夫感觉不舒服，你不能同时做两件事。在那一刻，你希望你能有一个设备，可以为你做到这一点；一个既能帮你洗衣服，又能叠衣服的设备！</p><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="kg kh l"/></div></figure><p id="d7ef" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">你猜怎么着我同意川普的观点…仅此一次。无论如何，让我给你看一些我正在研究的很酷的东西:一个可以对不同类型的衣服进行分类的神经网络！</p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><h1 id="3e55" class="if ig hi bd ih ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc bi translated">编码:背景知识</h1><p id="0c69" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">所以，你可能会说，“好吧，这听起来很酷。但是它是如何工作的呢？”这就是我在这篇文章中的目的；快速浏览一下我做了什么。</p><p id="dba7" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">我用来导入服装图片的库被称为时尚MNIST数据集。这个数据集包含28 * 28px的服装灰度图像。该库包含10种类型的服装:</p><ul class=""><li id="20fe" class="kz la hi jf b jg ki jk kj jo lb js lc jw ld ka le lf lg lh bi translated">t恤/上衣</li><li id="d718" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">裤子</li><li id="376b" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">套衫</li><li id="988b" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">连衣裙</li><li id="c0e9" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">外套</li><li id="916a" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">凉鞋</li><li id="6970" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">衬衫</li><li id="6339" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">运动鞋</li><li id="a323" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">包</li><li id="c1d0" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">踝靴</li></ul><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/c37e6aa82b616ba3fbc7e2979288ac31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ymrqRtMnRIy4IM4IexLr9g.png"/></div></div></figure><p id="ecd2" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">因此，给定一个输入图像，这些将是我们可能的输出。总的来说，时尚MNIST数据集包含70，000张图像，这对我们来说无疑是足够的。在70，000幅图像中，我们将使用其中的60，000幅来训练神经网络，另外10，000幅用于测试神经网络。另外，请记住，每个图像都是28px x 28px的图像，这意味着有784个像素。因此，这项工作只是将784个像素作为输入，然后输出图像代表的10种不同服装中的一种。</p><p id="f845" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">让我们快速看一下我们的神经网络是什么样子的:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/42b15eddddad475f7281c42898b49cb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S6t_smvyXvXnDAO7UkL4MA.png"/></div></div></figure><p id="804f" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">这里发生的情况是，神经网络不能处理二维图像(28 x 28图像)，只能处理一维图像(数组)。所以，我们在这里要做的是把图像压缩成一个一维数组，用长度乘以高度。这就是784的由来(28 x 28)。这就是所谓的扁平化方法。因此，在这种情况下，我们的输入层是784个神经元。我们的隐藏层，在这种情况下，将是128个神经元，然后从那里，显示10个输出，这是可能的服装类型，如上所示。</p><p id="9a2a" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">为此，我们必须使用一个称为ReLU(校正线性单位)的函数:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lu"><img src="../Images/c937f949d3cc9c6098cde3c09bca23c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aRwE57JwcGRY2vYcSzjPIg.png"/></div></div></figure><p id="6439" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">ReLU(也称为校正线性单位)是一个数学函数，我们可以用它来显示我们的概率值。我的意思是我们得到10个输出值，而不是1个。所以，这样想:当我们得到最后10个输出时，我们得到的是概率而不是陈述。总和将是1，显示每个类别的概率值。雷鲁就是这么做的。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lv"><img src="../Images/4ef96c8fd805f096081a94fbc3c1e7ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kFVgBH7e5ZIJ38Ewd6jXQg.png"/></div></div></figure><p id="c0cf" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">我们还将在最后使用softmax函数来帮助显示概率。</p><h1 id="b7a6" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">让我们开始编码吧！</h1><p id="0ab4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我会在文章的最后放一个链接，这样你就可以看到所有的代码和所有的导入以及所有的这些和那些。所以，我要跳过所有的预处理，把重点放在神经网络上。</p><pre class="kb kc kd ke fd lw lx ly lz aw ma bi"><span id="a91b" class="mb ig hi lx b fi mc md l me mf">mnist_model = tf.keras.Sequential([</span><span id="06e7" class="mb ig hi lx b fi mg md l me mf">tf.keras.layers.Flatten(input_shape=(28, 28, 1)),</span><span id="f9c2" class="mb ig hi lx b fi mg md l me mf">tf.keras.layers.Dense(128, activation=tf.nn.relu),</span><span id="c302" class="mb ig hi lx b fi mg md l me mf">tf.keras.layers.Dense(10, activation=tf.nn.softmax)</span><span id="3791" class="mb ig hi lx b fi mg md l me mf">])</span></pre><p id="f890" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">如你所见，我们正在使用TensorFlow库来构建我们的神经网络。让我们更深入地了解一下我们正在做的事情:</p><ul class=""><li id="80ad" class="kz la hi jf b jg ki jk kj jo lb js lc jw ld ka le lf lg lh bi translated"><strong class="jf hj"> input </strong> <code class="du mh mi mj lx b">tf.keras.layers.Flatten</code> -该层将一个二维数组(矩阵)转换成一个784 (28 x 28)的一维数组。把这一层想象成把图像从一个正方形排成一条长线。这一层什么都不学；它只是重塑了数据。</li><li id="1906" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated"><strong class="jf hj">【隐藏】</strong><code class="du mh mi mj lx b">tf.keras.layers.Dense</code>——126个神经元的密集连接层。每个神经元(也称为节点)接收来自前一层所有784个节点的输入，根据将在训练期间学习的隐藏参数对该输入进行加权，并向下一层输出单个值。</li><li id="ae78" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated"><strong class="jf hj">输出</strong> <code class="du mh mi mj lx b">tf.keras.layers.Dense</code>这是一个10节点的softmax层，每个节点代表一类服装。与前一层一样，每个节点从它之前的层中的128个节点获取输入，根据学习到的参数对该输入进行加权，然后以[0，1]的形式输出一个值，该值当然表示图像属于该类的概率。所有10个节点的和是1。</li></ul><p id="7fd4" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">在我们完成模型之前，我们需要编译它:</p><pre class="kb kc kd ke fd lw lx ly lz aw ma bi"><span id="557d" class="mb ig hi lx b fi mc md l me mf">mnist_model.compile(optimizer=’adam’,</span><span id="c1c4" class="mb ig hi lx b fi mg md l me mf">loss=’sparse_categorical_crossentropy’,</span><span id="9a12" class="mb ig hi lx b fi mg md l me mf">metrics=[‘accuracy’])</span></pre><ul class=""><li id="38a4" class="kz la hi jf b jg ki jk kj jo lb js lc jw ld ka le lf lg lh bi translated">损失函数-一种算法，用于测量模型输出与期望输出的差距。训练的目标是这个措施的损失。</li><li id="09ea" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">优化器-用于调整模型内部参数以最小化损失的算法。</li><li id="a526" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">指标——用于监控培训和测试步骤。以下示例使用准确度，即正确分类的图像比例:</li></ul><p id="3f5e" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated"><strong class="jf hj">训练模型</strong></p><p id="2597" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">我们所做的是为训练数据集定义迭代行为:</p><ul class=""><li id="73ba" class="kz la hi jf b jg ki jk kj jo lb js lc jw ld ka le lf lg lh bi translated">通过指定<code class="du mh mi mj lx b">dataset.repeat()</code>永远重复(下面描述的<code class="du mh mi mj lx b">epochs</code>参数限制我们执行训练的时间)。</li><li id="13e3" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated"><code class="du mh mi mj lx b">dataset.shuffle(60000)</code>使顺序随机化，所以我们的模型不能从例子的顺序中学习任何东西。</li><li id="7331" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">并且<code class="du mh mi mj lx b">dataset.batch(32)</code>告诉<code class="du mh mi mj lx b">model.fit</code>在更新模型变量时使用32个图像和标签的批次。</li></ul><p id="262c" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">通过调用<code class="du mh mi mj lx b">model.fit</code>方法进行训练:</p><ul class=""><li id="94e7" class="kz la hi jf b jg ki jk kj jo lb js lc jw ld ka le lf lg lh bi translated">使用<code class="du mh mi mj lx b">train_dataset</code>将训练数据输入模型</li><li id="f017" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">模型学习将图像和标签联系起来。</li><li id="d588" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated"><code class="du mh mi mj lx b">epochs=5</code>参数将训练限制为训练数据集的5次完整迭代，因此总共5 * 60000 = 300000个示例。</li></ul><pre class="kb kc kd ke fd lw lx ly lz aw ma bi"><span id="2237" class="mb ig hi lx b fi mc md l me mf">BATCH_SIZE = 32</span><span id="909a" class="mb ig hi lx b fi mg md l me mf">train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)</span><span id="3de6" class="mb ig hi lx b fi mg md l me mf">test_dataset = test_dataset.batch(BATCH_SIZE)</span><span id="9944" class="mb ig hi lx b fi mg md l me mf">mnist_model.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE)</span></pre><p id="2751" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">现在，瞧！我们的模特正在接受训练！</p><pre class="kb kc kd ke fd lw lx ly lz aw ma bi"><span id="4a8a" class="mb ig hi lx b fi mc md l me mf">Epoch 1/5<br/>1875/1875 [==============================] - 36s 19ms/step - loss: 0.4963 - accuracy: 0.8266<br/>Epoch 2/5<br/>1875/1875 [==============================] - 33s 18ms/step - loss: 0.3761 - accuracy: 0.8655<br/>Epoch 3/5<br/>1875/1875 [==============================] - 34s 18ms/step - loss: 0.3340 - accuracy: 0.8784<br/>Epoch 4/5<br/>1875/1875 [==============================] - 33s 18ms/step - loss: 0.3083 - accuracy: 0.8865<br/>Epoch 5/5<br/>1875/1875 [==============================] - 29s 15ms/step - loss: 0.2935 - accuracy: 0.8919</span><span id="bbe4" class="mb ig hi lx b fi mg md l me mf">&lt;tensorflow.python.keras.callbacks.History at 0x7fee73b267b8&gt;</span></pre><p id="fdcd" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">如您所见，损失和准确性指标显示得很清楚。在运行第5个时期后，我们可以看到，我们的模型准确率为89%,而我们的损失约为29%。</p><p id="f3cc" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated"><strong class="jf hj">评估我们的模型</strong></p><p id="47c2" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">现在让我们比较模型在我们的测试数据集上的表现。我们可以使用测试数据集中的所有示例来评估模型的准确性。</p><pre class="kb kc kd ke fd lw lx ly lz aw ma bi"><span id="ea2b" class="mb ig hi lx b fi mc md l me mf">test_loss, test_accuracy = mnist_model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))</span><span id="b056" class="mb ig hi lx b fi mg md l me mf">313/313 [==============================] - 3s 11ms/step - loss: 0.3563 - accuracy: 0.8754</span></pre><p id="4dd6" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">查看我们的数据，测试数据集的准确性与训练数据集相似(87%和89%)。这完全在意料之中，因为模型是在<code class="du mh mi mj lx b">train_dataset</code>上训练的。当模型看到它以前没有见过的图像时(在这种情况下，<code class="du mh mi mj lx b">test_dataset</code>)，我们可以预期精度会下降几个百分点。</p><p id="e686" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">为了结束这一切，让我们现在把一切都计划出来！</p><pre class="kb kc kd ke fd lw lx ly lz aw ma bi"><span id="8568" class="mb ig hi lx b fi mc md l me mf">def plot_image(i, predictions_array, true_labels, images):</span><span id="79ee" class="mb ig hi lx b fi mg md l me mf">predictions_array, true_labels, img = predictions_array[i], <br/>    true_labels[i], images[i]<br/>    plt.grid(False)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.imshow(img[...,0], cmap=plt.cm.binary) <br/>    predicted_label = np.argmax(predictions_array)    <br/>    if predicted_label == true_labels:<br/>        color = 'blue' <br/>    else:<br/>        color = 'red'</span><span id="a85f" class="mb ig hi lx b fi mg md l me mf">plt.xlabel("{} {:2.0f}{})".format(class_names[predicted_label],<br/>    100*np.max(predictions_array), class_names[true_labels]),   <br/>    color=color)</span><span id="2145" class="mb ig hi lx b fi mg md l me mf">def plotting_probabilities(i, predictions_array, true_labels):</span><span id="9313" class="mb ig hi lx b fi mg md l me mf">predictions_array, true_labels = predictions_array[i],     <br/>    true_labels[i]<br/>    plt.grid(False)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    thisplot = plt.bar(range(10), predictions_array,  <br/>    color="#777777") <br/>    plt.ylim([0,1])<br/>    predicted_label = np.argmax(predictions_array)<br/>    thisplot[predicted_label].set_color('red')<br/>    thisplot[true_labels].set_color('blue')</span><span id="1600" class="mb ig hi lx b fi mg md l me mf">#Plot the first 25images, their predicted label, and the true label</span><span id="3570" class="mb ig hi lx b fi mg md l me mf">num_rows = 5<br/>num_cols = 3<br/>num_images = num_rows*num_cols</span><span id="1e07" class="mb ig hi lx b fi mg md l me mf">plt.figure(figsize=(2*2*num_cols, 2*num_rows))</span><span id="ccd5" class="mb ig hi lx b fi mg md l me mf">for i in range(num_images):<br/>    plt.subplot(num_rows, 2*num_cols, 2*i+1)<br/>    plot_image(i, predictions, test_labels, test_images) <br/>    plt.subplot(num_rows, 2*num_cols, 2*i+2)<br/>    plotting_probabilities(i, predictions, test_labels)</span></pre><p id="2718" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">这是我们的输出:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mk"><img src="../Images/911ad85f8e784265f8dc062abc3f56bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*anodRqtZ02bsdyIFq1IT4g.png"/></div></div></figure><p id="2987" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">但是等等…这还没有结束。如果你梦想中的洗衣机出错了怎么办？如果你所有衣服中有10%分类错误会怎样？如果我告诉你，你的机器有可能以95%以上的准确率对你的衣服进行分类，你会怎么想？欢迎来到卷积和最大池的世界。</p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><h1 id="4b50" class="if ig hi bd ih ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc bi translated">卷积神经网络——卷积</h1><p id="a024" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">卷积神经网络本质上是一种比常规深度神经网络更精确的神经网络。该算法的两个主要概念是卷积和最大池。假设我们有这样一幅灰度图像:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ml"><img src="../Images/86790eddc9d1f8336e9aa1e464c136c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZIq2eTNAPwaLUvyE0LLimQ.png"/></div></div></figure><p id="9a49" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">为简单起见，我们假设图像高6像素，宽6像素。计算机会将图像解释为二维像素阵列。因为图像是灰度的，所以每个像素的值在0到255之间(0代表黑色，255代表白色)。假设这些是像素值:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/e8a17e0e2b6cbc3d8f0a373a9ace2bd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cpxc-5vr0eolT24CUuxqxw.png"/></div></div></figure><p id="2154" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">像素值将被归一化为0和1之间的值。卷积层的概念实质上是创建另一个层网格，称为内核或过滤器。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mm"><img src="../Images/81956f0dbf30a8dce3c332c7d10fd3f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LQFzj_BgJwSVSNCxMjVNfQ.png"/></div></div></figure><p id="9964" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">从那里，我们可以扫描整个图像的内核。图像大小为6 x 6，内核大小为3 x 3。卷积层将内核应用于输入图像的区域。假设我们要对像素值25执行内核卷积。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mn"><img src="../Images/e0003755621e748081df0eef526f92f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CrIhCEEeHrN2OrzL9fDnjQ.png"/></div></div></figure><p id="9f80" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">应用卷积的第一步应该是将内核集中在我们想要的像素上。在这种情况下，我们使用25。我们现在要做的是查看以绿色像素为中心的3x 3网格中的像素值。所以，我们要做的是把每个对应的图像和内核值相乘，然后求和。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/c1aa967f75dc3d674c23cb1237df5479.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o2OBEgZbeXAn9PMmTL8JRw.png"/></div></div></figure><p id="551e" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">现在，我们将对图像的所有其他像素做同样的处理。但是边缘的像素呢？当你像这里看到的那样把内核放在那个像素的中心时，正方形的一些部分会脱离网格。我们该怎么办？</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es mo"><img src="../Images/bb7b8ab39737cbc0fb3464a7758d710a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*awXrZKqHx0-3a1ZUQxklog.png"/></div></figure><ul class=""><li id="f997" class="kz la hi jf b jg ki jk kj jo lb js lc jw ld ka le lf lg lh bi translated">完全忽略该像素，就好像它根本不存在一样。这是通常的做法，但是缺点是你会丢失关于图像的信息，因为复杂的图像会比原始图像小得多。</li><li id="9b62" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">一个更常见的选择是执行一种称为零填充的方法。我们要做的是在原始图像周围放置0，然后求和。我们将在整个图像周围添加零填充。</li></ul><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/89e3c154253494be9aa49ae99f6b405d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pTxh3Li78NljVSHxcyuSbA.png"/></div></div></figure><h1 id="0657" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">最大池化</h1><p id="dc41" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Maxpooling本质上是通过汇总区域来减小输入图像的大小。为了执行maxpooling，我们需要选择两件事情:一个网格，这将是池的大小，和一个步幅。对于下面的例子，我们将使用如下所示的2 x 2 px网格:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/43124beb3036f0efa441389223fa9dcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tyjqqLuxc3fTZVhNSK05Fw.png"/></div></div></figure><p id="c0c3" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">我们在这里做的是查看我们的2 x 2 px网格，选择最大值，然后将其放入我们的3 x 3网格。maxpooling中使用的一个参数是步幅。这实质上决定了窗口在图像上滑动的像素数。在这个例子中，我们使用的步幅是2。结果将是一个比原始图像小的新图像。</p><h1 id="a886" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">快速回顾</h1><ul class=""><li id="8a33" class="kz la hi jf b jg jh jk jl jo mp js mq jw mr ka le lf lg lh bi translated">卷积是对图像应用滤镜(“内核”)的过程。</li><li id="2530" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">最大池是通过缩减像素采样减小图像大小的过程。</li><li id="dba3" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">CNN的:卷积神经网络。这是一个至少有一个卷积层的网络。典型的CNN还包括其他类型的层，例如池层和密集层。</li><li id="122f" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">内核/过滤器:比输入小的矩阵，用于将输入转换成块</li><li id="daa4" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">填充:在输入图像周围添加一定值的像素，通常为0</li><li id="637b" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">Stride:内核(滤镜)在图像上滑动的像素数。</li><li id="6a0d" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">缩减像素采样:缩小图像大小的行为</li></ul><h1 id="1521" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">把这个编码出来！</h1><p id="a4ec" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">因此，让我们也直接进入神经网络，因为这是与之前模型的唯一不同之处:</p><pre class="kb kc kd ke fd lw lx ly lz aw ma bi"><span id="ec8f" class="mb ig hi lx b fi mc md l me mf">cnn_model = tf.keras.Sequential([</span><span id="79ec" class="mb ig hi lx b fi mg md l me mf">tf.keras.layers.Conv2D(32, (3,3), padding='same',     <br/>    activation=tf.nn.relu, input_shape=(28, 28, 1)),<br/>    tf.keras.layers.MaxPooling2D((2, 2), strides=2),  <br/>    <br/>    tf.keras.layers.Conv2D(64, (3,3), padding='same', <br/>    activation=tf.nn.relu, input_shape=(28, 28, 1)),<br/>    tf.keras.layers.MaxPooling2D((2, 2), strides=2),</span><span id="7e06" class="mb ig hi lx b fi mg md l me mf">tf.keras.layers.Flatten(),<br/>    tf.keras.layers.Dense(128, activation=tf.nn.relu),<br/>    tf.keras.layers.Dense(10, activation=tf.nn.softmax)</span><span id="ffb5" class="mb ig hi lx b fi mg md l me mf">])</span></pre><p id="1e05" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">网络层包括:</p><ul class=""><li id="e2db" class="kz la hi jf b jg ki jk kj jo lb js lc jw ld ka le lf lg lh bi translated">卷积:<em class="ms"> tf.keras.layers.Conv2D和max pool 2d</em>—网络从两对Conv/MaxPool开始。第一层是应用于输入图像的Conv2D滤镜(3，3)，通过使用填充保留原始图像大小，并创建32个输出(卷积)图像(因此该层创建32个与输入大小相同的卷积图像)。</li><li id="27a2" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">maxpooling:<em class="ms">TF . keras . layers . maxpooling 2d—</em>之后，<em class="ms"> </em>使用步长为2的MaxPooling2D (2，2)减小32个卷积输出的大小。下一个Conv2D也有一个(3，3)内核，接受32个图像作为输入，并创建64个输出，这些输出的大小再次被MaxPooling2D层减小。</li><li id="8cf2" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">输出<em class="ms"> tf.keras.layers.Dense </em> —一个128个神经元，后面是一个10节点的softmax层。每个节点代表一类服装。与前一层一样，最后一层从它之前的层中的128个节点获取输入，并输出范围[0，1]中的值，表示图像属于该类的概率。所有10个节点值的总和为1。</li></ul><p id="609e" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">我们对模型的编译与上一个相同:</p><pre class="kb kc kd ke fd lw lx ly lz aw ma bi"><span id="fae3" class="mb ig hi lx b fi mc md l me mf">cnn_model.compile(optimizer='adam',<br/>                  loss='sparse_categorical_crossentropy',<br/>                  metrics=['accuracy'])</span></pre><p id="1768" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated"><strong class="jf hj">训练模特</strong></p><p id="21df" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">训练模型也与之前的模型非常相似，但唯一的区别是我们有10个时期，而不是5个:</p><pre class="kb kc kd ke fd lw lx ly lz aw ma bi"><span id="ba16" class="mb ig hi lx b fi mc md l me mf">BATCH_SIZE = 32</span><span id="04ef" class="mb ig hi lx b fi mg md l me mf">train_dataset = train_dataset.cache().repeat()<br/>.shuffle(num_train_examples).batch(BATCH_SIZE)</span><span id="e9ba" class="mb ig hi lx b fi mg md l me mf">test_dataset = test_dataset.cache().batch(BATCH_SIZE)</span><span id="35a4" class="mb ig hi lx b fi mg md l me mf">cnn_model.fit(train_dataset, epochs=10, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))</span><span id="5c7d" class="mb ig hi lx b fi mg md l me mf">Epoch 1/10<br/>1875/1875 [==============================] - 10s 5ms/step - loss: 0.4011 - accuracy: 0.8546<br/>Epoch 2/10<br/>1875/1875 [==============================] - 10s 5ms/step - loss: 0.2646 - accuracy: 0.9039<br/>Epoch 3/10<br/>1875/1875 [==============================] - 11s 6ms/step - loss: 0.2198 - accuracy: 0.9196<br/>Epoch 4/10<br/>1875/1875 [==============================] - 10s 5ms/step - loss: 0.1890 - accuracy: 0.9298<br/>Epoch 5/10<br/>1875/1875 [==============================] - 10s 6ms/step - loss: 0.1576 - accuracy: 0.9413<br/>Epoch 6/10<br/>1875/1875 [==============================] - 11s 6ms/step - loss: 0.1367 - accuracy: 0.9481<br/>Epoch 7/10<br/>1875/1875 [==============================] - 10s 5ms/step - loss: 0.1156 - accuracy: 0.9572<br/>Epoch 8/10<br/>1875/1875 [==============================] - 10s 5ms/step - loss: 0.0991 - accuracy: 0.9630<br/>Epoch 9/10<br/>1875/1875 [==============================] - 10s 5ms/step - loss: 0.0835 - accuracy: 0.9688<br/>Epoch 10/10<br/>1875/1875 [==============================] - 10s 5ms/step - loss: 0.0696 - accuracy: 0.9745</span><span id="a452" class="mb ig hi lx b fi mg md l me mf">&lt;tensorflow.python.keras.callbacks.History at 0x7fee6d4d3080&gt;</span></pre><p id="d67a" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">你可以注意到我们最终的准确率是97%！</p><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="mt kh l"/></div></figure><p id="a26c" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">现在，让我们计划一下:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mu"><img src="../Images/1542b3cd22f8611b135dc02924114b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*45UZkMTgt2pOeNhi4i10OQ.png"/></div></div></figure><p id="0e39" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">正如你所看到的，使用卷积和最大池的概念，你再也不会头疼了，因为下一次，你会有一个方便的漂亮洗衣机，它在97%的时间里工作(我们不谈论那3%…)。</p><p id="2a11" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">好吧，我答应我会显示代码，所以在这里！这是一个谷歌协作实验室，所以你必须登录你的谷歌账户。<a class="ae mv" href="https://colab.research.google.com/drive/14jlNhRXlrBslqGVIWpnV08iA0DLxS8EI" rel="noopener ugc nofollow" target="_blank">点击此文。</a></p><p id="c7fd" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">阅读本文的收获:</p><ul class=""><li id="6c8a" class="kz la hi jf b jg ki jk kj jo lb js lc jw ld ka le lf lg lh bi translated">ReLU和Softmax函数是帮助显示概率的两种不同类型的函数</li><li id="4314" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">CNN的:卷积神经网络是至少有一个卷积层的网络。</li><li id="9e4f" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">卷积是对图像应用滤镜(“内核”)的过程。</li><li id="42ec" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">最大池是通过缩减像素采样减小图像大小的过程。</li><li id="e4b3" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">内核/过滤器:比输入小的矩阵，用于将输入转换成块。用于盘旋。</li><li id="2587" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">零填充:在图像两端添加0个像素来帮助执行卷积</li></ul><p id="cc14" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">这是我的<a class="ae mv" href="https://subscribepage.com/srianumakonda" rel="noopener ugc nofollow" target="_blank">时事通讯</a>、<a class="ae mv" href="https://www.linkedin.com/in/srianumakonda/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>和<a class="ae mv" href="mailto:sri.anumakonda06@gmail.com" rel="noopener ugc nofollow" target="_blank">电子邮件</a>如果你想联系我。</p><p id="c97d" class="pw-post-body-paragraph jd je hi jf b jg ki ji jj jk kj jm jn jo kk jq jr js kl ju jv jw km jy jz ka hb bi translated">对我来说就是这样，享受你的一天！</p></div></div>    
</body>
</html>