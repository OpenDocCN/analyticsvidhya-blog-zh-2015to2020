# 优化算法

> 原文：<https://medium.com/analytics-vidhya/optimization-algorithms-feb9dcb57116?source=collection_archive---------2----------------------->

在这篇文章中，我将简要解释我将要解释的每种优化算法的优缺点。感谢斯坦福频道给我机会对所有这些有趣的概念有更好的直觉，这样我就能与你们分享了。

首先，我想我们应该谈谈梯度下降。这里的过程是，我们在大约 1m 的方向上有一些值，这些值是输入值，比如说图像的像素乘以权重矩阵，我们试图在你的损失显著减少的方向上前进，如这里所示

![](img/66592f4e629babeda9f879dbaf54a1ec.png)

就这么简单，计算所有方向的梯度(梯度只是导数，即斜率，但考虑几个变量),正如我所说的，我们有大约 1m 的维度，然后找到最大的斜率，然后取其负方向，这样最后你就可以下山了，这就是你的目标。

![](img/cf4d520072426665a1471011982db67f.png)

> 这里的演示显示了如何计算梯度向量，您将不得不取所有重量在任何方向都没有运动的状态下的总和，并将其从 W+h 中减去，其中 h 是我们在某个方向上所做的改变，在这种情况下，我们通过学习率= 0.0001(我们的步长有多大)取向 0.34 的方向，结果形式是仅在一个方向上的梯度！！是的，你必须计算所有方向

这可能是梯度下降的一个问题，所以你必须运行所有的数据，使下山一步！！**恭喜—** 对于梯度下降，你现在已经熟悉了它的工作原理。

解决方案？！

**随机梯度下降**

> 在 SGD 中的情况是，我们将只取一小批数据，可能是 64，128，并近似为向任何方向更新的数据的总和，而不是遍历所有数据，这些数据肯定会很大。

![](img/88af933a350a3f11593c2b2b62cd5d31.png)

问题 1

> 如果你认为，只要你是水平移动，你的损失将更新缓慢，因为你的目标是尽可能快地去中心的笑脸，但同时，如果垂直，你的损失将快速更新，所以当选择 SGD 作为我们的优化算法时，这可能是一个问题

![](img/7075e51a12e35aa28284ba6941bc4f34.png)

或者，如果它达到一个局部最小值或一个鞍点，斜率接近于零，所以我们的损失不会更新，所以它卡住了！！可能是个问题。

另一个问题是，你不认为当 SGD 逼近数据的总和以便以比梯度下降更快的方式更新时，它应该向权重引入一些噪声吗？

## 带动量的 SGD

把速度引入方程，让我们看看。

![](img/c36e49ba5f8636b1ab5b2dc6c9d5b833.png)

所以它不再依赖于梯度，它现在依赖于一个新的参数，称为速度，速度实际上是模型通过的先前梯度的总和，所以总和永远不会等于零，它会比正常的 SGD 更新得更快

![](img/4ae5dd52f7737931980b54cd51c6be9c.png)

这实际上解决了固定在局部最大值的问题，但实际上我们还有另一个问题，正如我之前所说的，模型倾向于根据方向移动得更快或更慢(在问题 1 的图中解释过),那么你认为对此有什么解决方案

# 阿达格拉德

![](img/70c144ae56d5f06e70d4b12e37a5303b.png)

问题 1 的解决方案

这张照片告诉我们什么？看着 x，把它当作你的步长，我们将向导数除以梯度的平方的负方向移动，让我们想想，如果这个值很大，在垂直方向上，x 的值会很小，所以步长会很小，而如果梯度平方的值很小，让我们考虑圆曲线处的水平方向，那么 x 的值足够大，可以更快地更新，很简单，你已经解决了不同方向上不同更新率的问题。

> 我们已经完成了所有的科学，另外两个算法只是我们之前讨论过的一些算法的混合

# RMSprop

![](img/d08265c60e431787736b77d7d77eafd0.png)

刚刚添加了衰减率项，以确保 grad_square 在任何情况下都不会为零

# 圣经》和《古兰经》传统中）亚当（人类第一人的名字

![](img/ac799f7efa443bbc6112a36592c084d5.png)

Adam 只是通过计算动量来混合动量和 AdaGrad，以实现更新速度，并除以平方梯度来解决不同方向上不同更新的问题，但请稍等一下，第一次迭代中会发生什么我们认为 first_moment 和 second_moment 的值将非常接近于零，因此我们将添加一个偏差项来解决这个问题。

![](img/5e00e884511244e03c850e0ac8aaefd6.png)

解决了！！

我们已经到了本教程的结尾，如果你喜欢，请投票支持，我将会发布很多关于机器学习和深度学习的概念和项目的教程

# 谢谢