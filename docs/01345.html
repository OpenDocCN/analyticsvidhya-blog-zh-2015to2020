<html>
<head>
<title>Auto Image Caption Generator for Visually Impaired People</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为视障人士提供的自动图像字幕生成器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/automated-image-caption-generator-for-visually-impaired-people-7279c42cb638?source=collection_archive---------7-----------------------#2019-10-16">https://medium.com/analytics-vidhya/automated-image-caption-generator-for-visually-impaired-people-7279c42cb638?source=collection_archive---------7-----------------------#2019-10-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="82c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">能够使用正确形成的英语句子自动描述图像的内容是一项具有挑战性的任务，但它可以帮助视障人士更好地了解他们的周围环境，从而产生巨大的影响。</p><p id="3dbd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，这些图像可以用来生成字幕，这些字幕可以大声地读给视障人士听，这样他们就可以更好地了解周围发生的事情。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/00ba35af468df6b798aa71d9029e8bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*CWXpXbgqjCk4dzghlWxvfA.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">盲人面临的挑战</figcaption></figure><h1 id="06ef" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">解决问题的技术途径</strong></h1><p id="d388" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们实现了一个深度递归架构，可以自动生成图像的简短描述。我们的模型使用在ImageNet上预先训练的CNN来获取图像特征。然后，我们将这些特征输入到一个普通的RNN或LSTM网络中(图2 ),用有效的英语生成图像的描述。</p><h1 id="57bd" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">基于CNN的图像特征提取器</strong></h1><p id="d91e" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">对于特征提取，我们使用CNN。CNN已经被广泛用于和研究图像任务，并且是当前用于对象识别和检测的最先进的方法。具体而言，对于所有输入图像，我们从VGG-16网络的fc7层提取特征，该网络在ImageNet上预先训练，该网络非常适合于对象检测。我们获得了一个4096维的图像特征向量，由于计算限制，我们使用主成分分析(PCA)将其减少到512维的图像特征向量。在第一次迭代中，我们将这些特性加入到RNN或LSTM的第一层中。</p><h1 id="d14b" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">基于RNN的句子生成器</strong></h1><p id="a688" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们首先用普通的rnn进行实验，因为它们已经被证明是处理序列数据的强大模型[25，26]。通过将输入序列映射到一系列隐藏状态，以及通过给定的等式将隐藏状态映射到输出，标准RNNs可以学习复杂的时间动态。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ks"><img src="../Images/21c33bd3a3d4f9c1eae1c51a3a7f6b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*WzqzRpa9sKkgbEc28WJ1rA.png"/></div></figure><p id="be46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中f是元素式非线性，ht 2 RN是具有N个隐藏单元的隐藏状态，yt是时间t的输出，在我们的实现中，我们使用双曲正切作为元素式非线性。对于长度为T输入序列x1；x2；:::;xT，以上更新按h1(设h0 = 0)，y1，h2，y2，… hT，yT顺序计算。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es kt"><img src="../Images/58ab528522a68526f0e6cc46b739023c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*19Qg1layYRKvasaYkwDQKQ.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图2:图像检索系统和语言生成管道。</figcaption></figure><h1 id="2d43" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">基于LSTM的句子生成器</strong></h1><p id="6b88" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">虽然rnn已经被证明在文本生成和语音识别等任务上是成功的[25，26]，但训练它们学习长期动力学是困难的。这个问题可能是由于梯度通过递归网络的许多层向下传播所导致的消失和爆炸梯度问题。LSTM网络(图3)提供了一个解决方案，它结合了存储单元，允许网络学习何时忘记以前的隐藏状态，以及何时在获得新信息时更新隐藏状态。</p><h1 id="4108" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">培养</h1><p id="30c5" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们训练LSTM模型以基于当前单词(xt)和前一上下文(ht􀀀1).)正确预测下一个单词(yt)我们这样做:我们设置h0 = 0，x1为起始向量，期望的标签y1为序列中的第一个单词。然后，我们将x2设置为与网络生成的第一个单词相对应的单词向量。基于这个第一单词向量和先前的上下文，网络然后预测第二单词，等等。使用Mikolov等人描述的word2vec嵌入模型来生成单词向量。阿尔[1]。在最后一步中，xT表示最后一个字，yT被设置为结束标记。</p><h1 id="9c2f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">测试</h1><p id="7b35" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">为了预测句子，我们获得图像特征bv，设置h0 = 0，设置x1为起始向量，并计算第一个单词y1上的分布。因此，我们从分布中挑选argmax，将其嵌入向量设置为x2，并重复该过程，直到生成结束令牌。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ky"><img src="../Images/1426826f671dc0a48c8227cea17a25c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*drjHfNUi5XTP7sxvImRgEA.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图3: LSTM单元及其门</figcaption></figure><h1 id="4fe9" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">最佳化</h1><p id="6a43" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们使用随机梯度下降(SGD)和25个图像句子对的小批量，动量为0.95。我们交叉验证了学习率和权重衰减。我们使用Adam获得了最好的结果，Adam是一种有效的随机优化方法，它只需要一阶梯度，并根据梯度的一阶和二阶矩的估计值计算不同参数的个体自适应学习率。Adam的主要优点是参数更新的幅度对于梯度的重新标度是不变的，它的步长近似地由步长超参数限定，并且它自动执行一种形式的步长退火。</p><h1 id="023b" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">资料组</h1><p id="9626" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在本练习中，我们将使用2014版的Microsoft COCO数据集，该数据集已成为图像字幕的标准测试平台。该数据集由80，000张训练图像和40，000张验证图像组成，每张图像都由亚马逊机械土耳其公司的工作人员编写的5个标题进行了注释。在图4中可以看到四个带有标题的示例图像。我们将所有句子转换成小写，并丢弃非字母数字字符。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kz"><img src="../Images/8d11e494fabcf87ee16f5e2cb4c8138f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*K7kIno89eH-McAkmZ4ylLw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图4:来自微软COCO标题数据集的示例图像和标题。</figcaption></figure><h1 id="dea1" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">定性结果</strong></h1><p id="0d5e" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们的模型用有效的英语生成图像的合理描述(图6和7)。从图5中的示例背景可以看出，该模型发现了可解释的视觉语义对应，即使对于相对较小的对象，例如图7中的电话。生成的描述足够准确，对有视觉障碍的人很有帮助。总的来说，我们发现在训练数据中可以找到相对大部分的生成句子(60%)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es la"><img src="../Images/c2863d284a9ae04df31cb76a8459c7c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*A7tZoEijbAN2MSsISwDh3w.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图5:对Microsoft COCO 2014数据集的1，000张测试图像的完整图像预测评估</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es lb"><img src="../Images/50692b743f4e0d521ca5c93a4dc3a237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*efQq9GxikIfEA-jNtw8moA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图6:使用RNN结构生成的示例图像描述。</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es lc"><img src="../Images/94b9d38364f114e247ddf91237e209a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AQZD2WlTk_HP5EO3aDHJfA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图7:使用LSTM结构生成的示例图像描述。</figcaption></figure><h1 id="138a" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">结论</strong></h1><p id="a415" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们创建了一个深度学习模型，它可以自动生成图像标题，目的是帮助视障人士更好地了解他们的周围环境。</p><h1 id="1d0b" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">参考</h1><p id="5a71" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><a class="ae ld" href="https://cs224d.stanford.edu/reports/mcelamri.pdf" rel="noopener ugc nofollow" target="_blank"><em class="le">https://cs224d.stanford.edu报道麦克拉姆里</em>T3】</a></p><p id="7d65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ld" href="https://www.semanticscholar.org/paper/Automated-Neural-Image-Caption-Generator-for-People-Elamri-Planque/cc61cd90529fede6e1bfb14042d021bc2a076e99" rel="noopener ugc nofollow" target="_blank">https://www . semantic scholar . org/paper/Automated-Neural-Image-Caption-Generator-for-People-El amri-Planque/cc 61 CD 90529 fede 6 E1 bfb 14042d 021 BC 2a 076 e 99</a></p><p id="a0fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ld" href="https://www.livestrong.com/article/241936-challenges-that-blind-people-face/" rel="noopener ugc nofollow" target="_blank"><em class="le">https://www . livestrong . com/article/241936-挑战盲人脸</em> </a></p><p id="efed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[1]米科洛夫、托马斯、伊利亚·苏茨基弗、程凯、格雷戈·s·科拉多和杰夫·迪恩。"单词和短语的分布式表示及其组合性."神经信息处理系统进展26:3111–3119(2013)。网络。2016年4月29日</p></div></div>    
</body>
</html>