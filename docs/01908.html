<html>
<head>
<title>HyperParameter Tuning — Hyperopt Bayesian Optimization for (Xgboost and Neural network)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超参数调整——超点贝叶斯优化(Xgboost和神经网络)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hyperparameter-tuning-hyperopt-bayesian-optimization-for-xgboost-and-neural-network-8aedf278a1c9?source=collection_archive---------0-----------------------#2019-11-21">https://medium.com/analytics-vidhya/hyperparameter-tuning-hyperopt-bayesian-optimization-for-xgboost-and-neural-network-8aedf278a1c9?source=collection_archive---------0-----------------------#2019-11-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/64700a5ad720575cebbb98dbb453f9ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yN1tDtgs5sxi0A32Ef2Mfg.jpeg"/></div></div></figure><p id="b4e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">超参数:</strong>这些是确定算法学习过程的某些值/权重。</p><p id="07e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">机器学习模型的某些参数:</strong>学习速率、alpha、最大深度、col-samples、权重、gamma等。</p><p id="f916" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">深度学习模型的某些参数</strong>:单元(单元数)、层(层数)、辍学率、核正则化子、激活函数等。</p><p id="252e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">超参数优化</strong>是为机器学习/深度学习算法选择最优或最佳参数。通常，我们最终用各种可能的参数范围手动调整或训练模型，直到获得最佳拟合模型。超参数调整有助于确定最佳调整参数并返回最佳拟合模型，这是构建ML/DL模型时要遵循的最佳实践。</p><p id="1cef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本节中，我们讨论一种最精确和最成功的超参数方法，即<strong class="is hj">超视。</strong></p><p id="3d0d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">优化无非是找到一个最小的成本函数，这决定了一个模型在训练集和测试集的整体性能更好。</p><p id="e4cd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一个功能强大python库，可以搜索超参数值空间。它实现了三个函数来最小化成本函数，</p><ol class=""><li id="1459" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">随机搜索</li><li id="3908" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">树Parzen估计量</li><li id="8f07" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">适应性TPE</li></ol><p id="786c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">导入所需包:</strong></p><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="8baf" class="kl km hi kh b fi kn ko l kp kq">import hyperopt<br/>from hyperopt import fmin, tpe, hp, STATUS_OK, Trials</span></pre><p id="c910" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">远视功能:</p><ul class=""><li id="b166" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn kr ju jv jw bi translated"><code class="du ks kt ku kh b">hp.choice(label, options)</code> —返回选项之一，应为列表或元组。</li><li id="2e3f" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kr ju jv jw bi translated"><code class="du ks kt ku kh b">hp.randint(label, upper)</code> —返回范围[0，上限]之间的随机整数。</li><li id="e728" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kr ju jv jw bi translated"><code class="du ks kt ku kh b">hp.uniform(label, low, high)</code> —统一返回一个介于<code class="du ks kt ku kh b">low</code>和<code class="du ks kt ku kh b">high</code>之间的值。</li><li id="7979" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kr ju jv jw bi translated"><code class="du ks kt ku kh b">hp.quniform(label, low, high, q)</code> —返回值round(uniform(low，high) / q) * q，即舍入小数值并返回整数</li><li id="e51a" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kr ju jv jw bi translated"><code class="du ks kt ku kh b">hp.normal(label, mean, std)</code> —返回具有平均值和标准差σ的正态分布的实数值。</li></ul><p id="d190" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">机器学习算法hyperopt-XGBOOST中涉及的步骤:</strong></p><p id="3b5a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤1: </strong>初始化空间或一个所需的值范围:</p><figure class="kc kd ke kf fd ij"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="3f15" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第二步:</strong>定义目标函数:</p><figure class="kc kd ke kf fd ij"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="9268" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第三步:</strong>运行远视功能:</p><figure class="kc kd ke kf fd ij"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="9ae8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里，“最佳”为您提供最适合模型的最佳参数和更好的损失函数值。<strong class="is hj"> trials </strong>，它是一个包含或存储所有统计和诊断信息的对象，如超参数、模型已训练的每组参数的损失函数。<strong class="is hj"> fmin </strong>，它是一个最小化损失函数的优化函数，接受4个输入。使用的算法是'<strong class="is hj"> tpe.suggest </strong>，其他可以使用的算法是'<strong class="is hj"> tpe.rand.suggest </strong>。</p><blockquote class="kx ky kz"><p id="0e32" class="iq ir la is b it iu iv iw ix iy iz ja lb jc jd je lc jg jh ji ld jk jl jm jn hb bi translated"><strong class="is hj">*使用使用hyperopt获得的最佳参数重新训练模型算法，并根据测试集对其进行评估，或将其用于预测* </strong></p></blockquote></div><div class="ab cl le lf gp lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="hb hc hd he hf"><p id="59fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">深度学习算法/神经网络的hyperopt中涉及的步骤:</strong></p><p id="c2c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤1: </strong>初始化空间或一个要求的数值范围:</p><figure class="kc kd ke kf fd ij"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="819f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第二步:</strong>定义目标函数:</p><figure class="kc kd ke kf fd ij"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="1a0e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第三步:</strong>运行远视功能:</p><figure class="kc kd ke kf fd ij"><div class="bz dy l di"><div class="kv kw l"/></div></figure><blockquote class="kx ky kz"><p id="4aee" class="iq ir la is b it iu iv iw ix iy iz ja lb jc jd je lc jg jh ji ld jk jl jm jn hb bi translated"><strong class="is hj">*使用使用hyperopt获得的最佳参数重新训练模型算法，并根据测试集对其进行评估，或将其用于预测* </strong></p></blockquote><h1 id="98ae" class="ll km hi bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated"><strong class="ak">结论:</strong></h1><p id="c770" class="pw-post-body-paragraph iq ir hi is b it mi iv iw ix mj iz ja jb mk jd je jf ml jh ji jj mm jl jm jn hb bi translated">我们已经讨论了如何使用sklearn python库“hyperopt ”,这是数据科学领域中广泛首选的库。超参数调整是建立学习算法模型的重要步骤，需要仔细检查。另一个用于神经网络超参数调整的不同python库是<strong class="is hj">‘hyperas’。关于这篇文章的任何问题，欢迎在下面评论。</strong></p></div></div>    
</body>
</html>