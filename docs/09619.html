<html>
<head>
<title>Why is Model Evaluation a crucial step in Machine Learning? — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么模型评估是机器学习中至关重要的一步？—第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/why-is-model-evaluation-a-crucial-step-in-machine-learning-part-1-eeb4882e7c8a?source=collection_archive---------17-----------------------#2020-09-13">https://medium.com/analytics-vidhya/why-is-model-evaluation-a-crucial-step-in-machine-learning-part-1-eeb4882e7c8a?source=collection_archive---------17-----------------------#2020-09-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/848982730eb571e7528925b435400d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*enQj526M0aYE7xQZPNGa7A.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由昆泰·德威迪拍摄</figcaption></figure><p id="59a6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">任何研究人员或数据科学家的核心目标一直是推导出一个对潜在问题领域来说“T0”完美的模型。在深入研究数据本身的复杂计算之前，应该首先准备看起来最适合这一目的的工具。首先，机器学习实践者总是在模型的“<em class="js">参数和超参数</em>周围涂鸦，以获得尽可能高的<strong class="iw hj">泛化精度</strong>。让我们继续，看看如何以最佳方式掌握这些工具。</p><blockquote class="jt ju jv"><p id="6d47" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">将模型拟合到训练数据集是不同的事情；让它成为一个“好的预测器”是另一回事。这一步是必须要做的，因为我们的模型的泛化行为依赖于它。反正没人想要死记硬背的模型！</p></blockquote><p id="be22" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> <em class="js">注</em> </strong> <em class="js">:我曾经尝试总结过一篇</em> <strong class="iw hj"> <em class="js"> Sabastian Raschka 的研究文章，《机器学习中的</em> </strong> <a class="ae jz" href="https://arxiv.org/abs/1811.12808" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hj"> <em class="js">模型评估、模型选择、算法选择</em> </strong> </a> <strong class="iw hj"> <em class="js">》。尽管这篇文章有点冗长，但我确实发现它信息量大得惊人。我很感谢作者在他的作品中非常详细。</em></strong></p><p id="d5a1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">本文由三个部分组成，以保持每个部分的长度略短，并提供模块化学习:</p><ul class=""><li id="43d7" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated"><strong class="iw hj"> <em class="js">第一部分:</em> </strong>一些基本概念和术语。</li><li id="ca16" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated"><a class="ae jz" rel="noopener" href="/@kountaydwivedi/different-model-evaluation-methodologies-part-2-679fcb064c55"> <strong class="iw hj"> <em class="js">第二部分:</em> </strong>模型评估的不同方法。</a></li><li id="ee86" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated"><a class="ae jz" rel="noopener" href="/@kountaydwivedi/model-selection-techniques-part-3-d5ebb6ea4c77"> <strong class="iw hj"> <em class="js">第三部分:</em> </strong>不同的模式选择方法。</a></li></ul></div><div class="ab cl ko kp gp kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="hb hc hd he hf"><blockquote class="kv"><p id="bfe5" class="kw kx hi bd ky kz la lb lc ld le jr dx translated">你将会学到什么</p></blockquote><ul class=""><li id="9e4c" class="ka kb hi iw b ix lf jb lg jf lh jj li jn lj jr kf kg kh ki bi translated">模型评估的不同方法及其比较。</li><li id="d445" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">如何从<em class="js">假设空间</em>中选择最佳模型(基本上每个模型对应<em class="js">假设空间</em>中的一个特定假设)。</li><li id="3b50" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">选择一个最佳算法，最适合手头的问题。</li></ul><blockquote class="kv"><p id="e977" class="kw kx hi bd ky kz lk ll lm ln lo jr dx translated">为什么我们需要做这些事情？</p></blockquote><ul class=""><li id="c99e" class="ka kb hi iw b ix lf jb lg jf lh jj li jn lj jr kf kg kh ki bi translated">我们希望<strong class="iw hj">评估我们的模型在不可预见的数据示例上的预测性能</strong>(泛化精度)。</li><li id="d816" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">我们还想尽可能地提高我们模型的性能。</li><li id="1d95" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">最后，在机器学习的几个算法中，我们想要挑选一个计算上最优的<strong class="iw hj">来解决我们的问题。</strong></li></ul></div><div class="ab cl ko kp gp kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="hb hc hd he hf"><blockquote class="kv"><p id="044a" class="kw kx hi bd ky kz la lb lc ld le jr dx translated">术语意识</p></blockquote><blockquote class="jt ju jv"><p id="e072" class="iu iv js iw b ix lf iz ja jb lg jd je jw lp jh ji jx lq jl jm jy lr jp jq jr hb bi translated"><strong class="iw hj">监督学习和分类方法</strong></p></blockquote><ul class=""><li id="689b" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">监督学习是机器学习范式之一，其中数据集示例的<strong class="iw hj">基础事实是我们先验已知的</strong>。</li><li id="bfb4" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">分类是一项机器学习任务，其中我们的模型负责处理分类数据。也就是说，我们的模型应该以识别特定数据示例属于哪个类为目标。</li></ul><p id="b626" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> <em class="js">注意:</em> </strong> <em class="js">在本文中，我们将只研究监督学习方法和分类任务。</em></p><blockquote class="jt ju jv"><p id="7c35" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj">假设、目标函数和模型</strong></p></blockquote><ul class=""><li id="cd8d" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">在预测模型中，我们通常热衷于学习或逼近特定未知函数。这实际上是我们想要建模的<strong class="iw hj">目标函数(<em class="js"> f(y) </em>)。我们不知道真正的功能(否则就不需要数据科学家了！！)</strong></li><li id="ac8a" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated"><strong class="iw hj">我们希望尽可能接近目标函数的函数就是假设。由于我们不知道目标函数的真实性质，因此我们只能希望我们的假设尽可能地接近它。</strong></li><li id="726d" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated"><strong class="iw hj">模型只是假设</strong>的一种表现形式。当我们概念化我们的功能时，它是一个假设；当我们显化它(物化它)，它就变成了一个模型。</li></ul><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/36f0a9e307195fc966ed9bd1b0c5119e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O4OC-mCJK6GuQAwKA1w4TQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图 1:ML 算法如何从<strong class="bd lx"> <em class="ly">假设空间</em> </strong> <em class="ly">中选择最佳假设(最终模型)</em></figcaption></figure><blockquote class="jt ju jv"><p id="621f" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj">参数和超参数</strong></p></blockquote><ul class=""><li id="0bae" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">了解上述术语之间的区别对我们来说很重要。当设计一个机器学习模型时，有许多因素对产生我们模型的最佳泛化精度起着至关重要的作用。</li><li id="ea58" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">一个<strong class="iw hj">模型参数</strong>，是我们的模型实际学习的变量。我们的模型进行预测时会用到这些。实际上，模型只需要学习这些参数。因此，当模型被完全训练时，它们被自动确定。<br/>模型参数示例:<br/> * <strong class="iw hj"> <em class="js">神经网络中某一层的权重</em></strong><br/>*<strong class="iw hj"><em class="js">分类或回归模型中的系数</em></strong><em class="js"/><br/>*<strong class="iw hj"><em class="js">支持向量</em> </strong> <em class="js"> </em></li><li id="5dd5" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">另一方面，<strong class="iw hj">超参数</strong>是类似元模型参数的变量。他们实际上控制算法的行为，以便获得模型的参数。本质上，我们可以说，“我们调整超参数以获得最佳的模型参数”。这些需要由实验者来决定，而不是由算法来决定。它们被明确地输入到程序中，并进行微调以获得最佳结果。<br/>超参数的例子:<br/> *模型损失函数中的<em class="js"> L-2 </em> <strong class="iw hj"> <em class="js">正则化</em>项</strong>。<br/> *学习率<strong class="iw hj"><em class="js">(</em><em class="js">)</em></strong><em class="js"/>一个模型的数量<br/>*<strong class="iw hj"><em class="js"/></strong><em class="js">【迭代次数】</em></li></ul><blockquote class="jt ju jv"><p id="3074" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj">分层与简单随机抽样</strong></p></blockquote><ul class=""><li id="81db" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">如果我们想研究一个群体，那么我们应该意识到这样一个事实，即它有自己的统计数据(均值、方差、偏差等)。).群体中可能有一个或多个子类。例如:猫科动物有许多子类，如老虎、猞猁、美洲狮等。</li><li id="e0bb" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">为了研究一个群体，我们收集一些样本(样本越多，研究越好)。</li><li id="b77d" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">现在，我们正在收集的这个样本，<strong class="iw hj">如果它在本质上只是随机的，那么我们可能最终得到的数据并不代表在真实的潜在总体中发现的子类的比率。也就是说，假设猫科动物的比例是老虎:猞猁:美洲狮= 25:25:50。因此，所收集的样本也应该具有尽可能接近于此的比率，这在简单随机抽样的情况下可能不会发生。</strong></li><li id="91a0" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">因此，我们使用<strong class="iw hj">分层随机抽样的概念，它以随机方式进行抽样，但保持样本中真实总体子类的原始比率不变。</strong></li></ul><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/b1693800292ad9cdbb74f28b0532cef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RiOoZEYHrKg2Gv1VdthZFg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图 2:说明了不同的 b/w 分层抽样和简单随机抽样。我们可以看到，在分层抽样中，总人口的比率是如何保持不变的。(Kountay Dwivedi 摄)</figcaption></figure><blockquote class="jt ju jv"><p id="574b" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj">过拟合和欠拟合</strong></p></blockquote><ul class=""><li id="f10d" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">我们知道，如果我们的模型能够很好地概括实时示例(看不见的数据点)，那么它将是“<strong class="iw hj">好的</strong>”。但是我们如何衡量这个<strong class="iw hj">泛化精度</strong>？</li><li id="c304" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">为此，我们首先将现有数据集分成两个子集——<strong class="iw hj">训练集和测试集。</strong></li><li id="99f6" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">我们首先训练我们的模型，并使用训练集学习参数。此后，我们使用测试集测试模型的预测准确性。</li><li id="4a8b" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">当<strong class="iw hj">无法捕捉到潜在数据样本的基本趋势和细节时，一个模型在本质上是<strong class="iw hj">欠拟合</strong>。</strong>相反，如果<strong class="iw hj">捕捉到数据样本中的噪声和基本细节，模型在本质上就是<strong class="iw hj">过度拟合</strong>。</strong></li><li id="3989" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">欠适和过适的概念，虽然看起来很简单，但实际上很难理解。让我们看看下面的图表:</li></ul><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/5ab9c2784643d10f3dc7d7e526b96d1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X2noosdY8iBcO8sTGin51w.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图 3:显示模型欠拟合、过拟合和良好区域的图表。(Kountay Dwivedi 摄)</figcaption></figure><ul class=""><li id="8e98" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated"><em class="js">图— 3 </em>显示的是<em class="js">能力</em>(一个模型可以处理多复杂的功能)和模型的<em class="js">错误率</em>之间的关系图。</li><li id="843f" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated"><strong class="iw hj">区域 1 —欠拟合区域:</strong>我们可以看到，训练误差以及泛化误差率很高。原因是<em class="js">模型的简单性(图— 4) </em>。一个模型，如果设计得非常简单，将无法捕捉样本的本质，从而无法很好地拟合数据。</li><li id="8197" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated"><strong class="iw hj">3 区——过度拟合区:</strong>在这里，情况完全相反。由于其<em class="js">的复杂性质</em>，该模型甚至捕捉到样本的细微细节(即噪声)，因此，尽管它导致训练误差下降，因为它已经对此进行了大量练习，但泛化误差也在上升。</li><li id="e4a1" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated"><strong class="iw hj">区域 2 —“好”区域:</strong>我们希望我们的模型学习样本的<strong class="iw hj">本质属性</strong>，而不是噪声(比如错误注释的数据项，或者离群值)。因此，区域 2 是模型的首选复杂度。</li></ul><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/846d95f5acb5cfb4f6bf73ccebbce846.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jikmc3pncVp_bZGBTfxxug.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图—4:<strong class="bd lx">高偏差</strong>模型(左)与<strong class="bd lx">高变量</strong>模型(右)的对比图(Kountay Dwivedi 拍摄)</figcaption></figure><blockquote class="jt ju jv"><p id="52b7" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj">偏差和方差</strong></p></blockquote><ul class=""><li id="94fa" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">与过拟合和欠拟合的概念非常相关，具有<strong class="iw hj">高偏差</strong>的模型最终落入<strong class="iw hj">欠拟合区，</strong>而具有<strong class="iw hj">高方差</strong>的<strong class="iw hj">T37】模型落入<strong class="iw hj">过拟合区。</strong></strong></li><li id="536a" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">假设我们的模型预测结果为<em class="js"> y_hat </em>，真实标签为<em class="js"> y </em>，那么偏差将为<strong class="iw hj">预测结果和真实标签的期望值之差 b/w。</strong></li></ul><figure class="lt lu lv lw fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/97fd53b91f5974229fdc66838fb1844b.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*j4kDJvAidDANYKHCfkodKQ.png"/></div></figure><ul class=""><li id="11a5" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">此外，方差将是<strong class="iw hj">y _ hat<em class="js">的平方的期望值</em>和 y _ hat<em class="js">的平方的期望值之间的差。</em>T53】</strong></li></ul><figure class="lt lu lv lw fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/397d947acf776733f8fdfb29350b2ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*juDgcgmLxrXghbtv_TOwVw.png"/></div></figure><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/1b839f2e69a8ed7c8fc743a9ca56fbb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gllh6EXhZ8SsuPlhUZjvbQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图 5:偏差和方差的图示(照片由 Kountay Dwivedi 拍摄)</figcaption></figure><blockquote class="jt ju jv"><p id="26bf" class="iu iv js iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj">0–1 损失和预测精度</strong></p></blockquote><ul class=""><li id="65d9" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">有许多损失函数可供使用。为了简单起见，实际上使用了<strong class="iw hj"><em class="js">0–1 损失函数</em> </strong>。让我们假设我们必须做一个分类问题，其中样本由两个类组成(例如，一个学生的成绩——他是通过还是失败)。在这种情况下，0–1 损失实际上定义为:</li></ul><figure class="lt lu lv lw fd ij er es paragraph-image"><div class="er es me"><img src="../Images/2b6829299dff7024af5be895704e0628.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*ucpkiGm3Cu4FyiUx0Romjw.png"/></div></figure><ul class=""><li id="b6b3" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">上式中，<strong class="iw hj"> <em class="js"> y_i_hat </em> </strong>是我们模型给出的预测值，<strong class="iw hj"> <em class="js"> y_i </em> </strong>是属于样本的<strong class="iw hj"><em class="js">I-</em></strong>th<strong class="iw hj"><em class="js"/></strong>数据示例的真值。</li><li id="b03f" class="ka kb hi iw b ix kj jb kk jf kl jj km jn kn jr kf kg kh ki bi translated">有了这个概念，我们计算预测误差<strong class="iw hj"> <em class="js"> ERR </em> </strong>作为整个数据集上<em class="js">0–1 损失</em>的<strong class="iw hj">期望值，有<em class="js"> n </em>个例子。</strong></li></ul><figure class="lt lu lv lw fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/d6e76169bdad42d7df391f639f260c78.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*77FOew6-cf31LM1A3q8eag.png"/></div></figure><ul class=""><li id="5703" class="ka kb hi iw b ix iy jb jc jf kc jj kd jn ke jr kf kg kh ki bi translated">由此可见，<strong class="iw hj"><em class="js">【ACC】</em></strong>的预测精度为:</li></ul><figure class="lt lu lv lw fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/7a7af7f09e6686de1efdeecae12b4d42.png" data-original-src="https://miro.medium.com/v2/resize:fit:352/format:webp/1*7ZAMM3Z0x77Ce3YtClkBVA.png"/></div></figure></div><div class="ab cl ko kp gp kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="hb hc hd he hf"><blockquote class="kv"><p id="c42c" class="kw kx hi bd ky kz la lb lc ld le jr dx translated">接下来—第 2 部分</p></blockquote><p id="1a38" class="pw-post-body-paragraph iu iv hi iw b ix lf iz ja jb lg jd je jf lp jh ji jj lq jl jm jn lr jp jq jr hb bi translated">在学习了理解模型评估和选择背后的思想和直觉所需的基本术语和概念之后，我们现在继续学习<a class="ae jz" rel="noopener" href="/@kountaydwivedi/different-model-evaluation-methodologies-part-2-679fcb064c55"> <strong class="iw hj"> <em class="js">第 2 部分——不同的模型评估方法</em> </strong>。</a>敬请关注，快乐学习。<br/> :-}</p></div></div>    
</body>
</html>