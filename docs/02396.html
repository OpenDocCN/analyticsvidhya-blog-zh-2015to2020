<html>
<head>
<title>TensorFlow Basics to Mastery Series Part-1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow基础到精通系列第1部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorflow-basics-to-mastery-series-part-1-bea59468f937?source=collection_archive---------19-----------------------#2019-12-14">https://medium.com/analytics-vidhya/tensorflow-basics-to-mastery-series-part-1-bea59468f937?source=collection_archive---------19-----------------------#2019-12-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="0ec7" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">本系列将掌握您使用google的TensorFlow框架构建神经网络的技巧</p></blockquote><p id="67c2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">深度学习(DL)所能做的所有令人惊叹的工作都是在相当长的一段时间内创造所有它能创造的空气，让人们疯狂。让我们停止谈论所有愚蠢的令人瞠目结舌的场景，我们做的每一个DL突破性新闻滚动。是时候用这块蛋糕弄脏我们的手，体验它的味道，让它在卡片上物有所值了</p><p id="f0ef" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">让我们首先列出一些流行的深度学习工具/框架</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jk"><img src="../Images/c0953d3fa4f4c1229710a768a4399bfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0sLQHeVYg_jktouAk46LKg.png"/></div></div></figure><p id="8feb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">研究人员通过在一些DL框架上构建一些高级包装器来构建神经网络，即使对其细微差别的了解很少，也使我们的生活变得简单</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jw"><img src="../Images/e212a2a467ecf1a92ec0faf8feee6402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*-F7qjApL8_NxLKxoKXNGTQ.png"/></div></figure><p id="edae" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这个系列将在TensorFlow上从基础一直到精通水平。手指交叉，期待一些令人兴奋的学习，没有任何进一步的行动，让我们开始这个新的范例。</p><h2 id="9f16" class="jx jy hi bd jz ka kb kc kd ke kf kg kh jh ki kj kk ji kl km kn jj ko kp kq kr bi translated">快速回到编程历史(传统编程与机器学习编程):</h2><p id="2c83" class="pw-post-body-paragraph ii ij hi il b im ks io ip iq kt is it jh ku iw ix ji kv ja jb jj kw je jf jg hb bi translated"><strong class="il hj">传统编程</strong>是指我们试图通过编纂关于数据的规则(已知:规则和数据，未知:输出答案)来解决问题并获得未知结果</p><p id="b46d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">机器学习</strong>是我们让系统通过输入数据和答案(已知:输出答案和数据，未知:规则)来找出规则</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es kx"><img src="../Images/f60848e6c6950a6a71f081a744c2975d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cek-U9ZfBJhRIpn4POCNKA.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">上图展示了传统编程和机器学习的对比</figcaption></figure><p id="0210" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在让我们来看看传统编程的优缺点</p><p id="10f4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">优点——为每一个独特的场景建立基于观察的手工规则</p><p id="232c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">缺点——当你不得不为每一个可能的场景制定规则时，这变得非常困难和混乱(在解决任何现实世界的问题时通常会有很多规则)</p><p id="01a1" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">相反，我们使用<strong class="il hj">机器学习</strong>方法，教给机器每一种可能的场景，让它用数据和相应的标签找出所有可能的规则。</p><p id="4f4d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"> <em class="ik">快速走进机器学习的基础知识..</em>T9】</strong></p><p id="4777" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">机器学习学习和理解数据中的模式，并试图在没有任何显式编码的情况下提出规则。这是这个全新范例中最激动人心的部分。</p><p id="eccb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">一旦从提供的数据中学习了<strong class="il hj">假设函数</strong>(规则)。例如:如果y = 5x + 10是学习到的假设函数，那么我们必须评估假设函数有多好，它转换了模型的优良因子。在此基础上，我们可以决定是坚持相同的假设函数，还是对其进行调整，以减少之前公式化的假设函数所造成的误差。</p><p id="ce58" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">损失函数</strong>帮助我们评估假设函数的拟合优度。这个损失函数是在我们从数据中得到的实际输出<em class="ik"> Y </em>和我们的假设函数产生的<em class="ik"> Yhat </em>之间测量的。一些损失函数是</p><p id="fc8c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">—均方误差(MSE)</p><p id="98fd" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">—均方根误差(RMSE)</p><p id="f7ee" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">—平均绝对误差(MAE)</p><p id="5bc0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">—平均绝对百分比误差(MAPE)</p><p id="e3d3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">利用上述方法之一(根据我们试图解决的问题类型适当选择)来计算公式化假设函数的损失/误差。一旦我们计算出损失/误差，我们就需要想办法减少它。这是在一个叫做<strong class="il hj">梯度下降</strong>的功能的帮助下完成的。同样，有各种利用梯度下降来减少误差的方法，我们将在本系列中讨论这些方法。</p><p id="26f5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">T9】机器学习&amp;深度学习:T11】</strong></p><p id="c299" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">深度学习是机器学习的一个子集。在深度学习中，我们试图复制人类大脑与神经元合作的方式。因此我们建立的模型称为<strong class="il hj"> <em class="ik">神经网络</em> </strong> <em class="ik">。</em></p><p id="9c28" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">区别传统机器学习模型和深度学习模型的一个主要因素是特征选择。在经典的机器学习方法中，我们选择要训练的特征，假设函数为我们挑选的每个特征制定重要性。但是在深度学习神经网络方法的情况下，没有特征选择层，并且整个数据被消耗。这使得它们有了一个昵称<em class="ik">黑匣子。</em></p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lc"><img src="../Images/2182efbc593b613d4e43caead0bc8b3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aNhodqXi_uuWMr6D_8NLQQ.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">该图显示了所谓的神经网络黑盒中的组件，如层、神经元和权重(箭头)</figcaption></figure><p id="2914" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在让我们快速看看神经网络的基本单元，从基本的Keras实现开始</p><p id="9950" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">—神经元:输入/计算值的占位符</p><p id="d557" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">—层:特定层级中的一组神经元</p><p id="47d0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">—权重:定义神经元在预测中帮助接近实际数据的重要性</p><p id="d089" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">—损失:实际数据输出和模型/网络输出之间的差异</p><p id="e090" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">—优化器:减少损失/错误的方法或功能</p><h2 id="8ec4" class="jx jy hi bd jz ka kb kc kd ke kf kg kh jh ki kj kk ji kl km kn jj ko kp kq kr bi translated">“Keras”——tensor flow的高级API</h2><p id="2db0" class="pw-post-body-paragraph ii ij hi il b im ks io ip iq kt is it jh ku iw ix ji kv ja jb jj kw je jf jg hb bi translated">如前所述，Keras是一个高级包装器或API，以TensorFlow/Theano/CNTK作为其粒度级别来构建神经网络</p><blockquote class="if ig ih"><p id="9065" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">神经网络只不过是按逻辑排列的一组功能，它可以学习嵌入数据中的模式。</p></blockquote><p id="e2ab" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">安装TensorFlow，然后安装其API Keras</p><figure class="jl jm jn jo fd jp"><div class="bz dy l di"><div class="ld le l"/></div></figure><p id="3f87" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">在Keras中，机器学习模型中发生的所有数学运算都可以作为函数(由研究人员编写的优化代码)使用。</p><p id="c1a4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">让我们使用TensorFlow和Keras API构建一个简单的模型</p><figure class="jl jm jn jo fd jp"><div class="bz dy l di"><div class="ld le l"/></div></figure><p id="0bd4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">x和y分别是输入和输出标签。如果我们通过观察x和y之间的关系做一个简单的数学运算</p><p id="f856" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"><em class="ik">y = 3x+1</em>T3】</strong></p><p id="2a27" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在，我们将尝试将生物大脑中发生的数学运算复制到人工神经网络中。首先让我们铺设网络结构</p><figure class="jl jm jn jo fd jp"><div class="bz dy l di"><div class="ld le l"/></div></figure><ol class=""><li id="6099" class="lf lg hi il b im in iq ir jh lh ji li jj lj jg lk ll lm ln bi translated">首先导入TensorFlow和Numpy库。</li></ol><p id="dcf6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">2.Keras <strong class="il hj">顺序</strong>调用被定义为一个接一个地创建神经网络层。</p><p id="2189" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">3.接下来，我们定义<strong class="il hj">密集</strong>层，它成为我们的第一个只有一个神经元的层，因为我们每个数据点的输入长度是1。</p><p id="35fa" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">4.我们定义<strong class="il hj">损失函数</strong>为MSE</p><p id="9caf" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">5.“随机梯度下降”<strong class="il hj">优化器</strong>被初始化以减少损失</p><p id="b2ef" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在，我们的架构(层、损失函数、优化器等)都设置好了，可以根据我们的数据(x &amp; y)进行训练</p><p id="9059" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">6.Model.fit方法调用将开始为我们的模型训练300个时期</p><p id="6362" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在让我们看看我们的网络从我们的数据中学到了多少</p><figure class="jl jm jn jo fd jp"><div class="bz dy l di"><div class="ld le l"/></div></figure><p id="bc05" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">尝试预测一个新的数据点，比如说5应该产生16(即3*5 +1)。</p><p id="2ddc" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">该模型输出15.98，非常接近16。就是这样！！我们已经尝试并复制了人类系统外神经元的生物行为:)</p><p id="0288" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">我们将很快在本系列的第2部分再见，在那之前继续努力吧！！！！</p></div></div>    
</body>
</html>