<html>
<head>
<title>How to deploy your Neural Network Model using Ktrain</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Ktrain部署您的神经网络模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-deploy-your-neural-network-model-using-ktrain-ae255b134c77?source=collection_archive---------2-----------------------#2020-01-06">https://medium.com/analytics-vidhya/how-to-deploy-your-neural-network-model-using-ktrain-ae255b134c77?source=collection_archive---------2-----------------------#2020-01-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/50b2207a6119c1f789d44c53c3d9d738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YhNutblqDt7l1B06"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Mauro Sbicego 在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="96d8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">注意:</strong>我假设你知道如何在ktrain中训练模型，但有一个基本的笔记本也显示了如何使用ktrain，我已经在下面的库版本中运行了该笔记本。<strong class="ix hj"> <em class="jt">你会在文章末尾找到文章源代码和参考资料。</em>T9】</strong></p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="ecce" class="kd ke hi jz b fi kf kg l kh ki">ktrain==0.26.4<br/>tensorflow==2.5.0</span></pre></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><p id="03b7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">本文更新于2021年7月9日。</strong></p></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><p id="9207" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我在<a class="ae iu" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> google colab </a>中训练我的深度学习模型，做情感分析的时候。我发现了一篇有趣的文章<a class="ae iu" rel="noopener" href="/@asmaiya/explainable-ai-in-practice-2e5ae2d16dc7"> <strong class="ix hj"> <em class="jt">可解释的人工智能实践</em> </strong> </a>，当我读到它时，我对它的酷感到震惊。我们如何在四行中训练我们的深度学习模型，各种方法用于文本分类，如<a class="ae iu" href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html" rel="noopener ugc nofollow" target="_blank"> BERT </a>，这是一个最先进的类模型，fasttext和其他许多技术都包含在<a class="ae iu" href="https://github.com/amaiya/ktrain" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> ktrain </strong> </a>中。ktrain是Keras训练神经网络的轻量级包装器，它给了我非常令人惊讶的结果，也可以根据需要定制。所以，我们来做部署吧。</p><p id="b3bc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第一步</strong>:你必须使用<strong class="ix hj"> learner </strong>变量训练你的模型，比如<strong class="ix hj"> learner.autofit() </strong>和<strong class="ix hj"> preproc </strong>用于预处理文本。所以，你要做的就是调用ktrain中的<strong class="ix hj">get _ predict or</strong>函数，使用<strong class="ix hj"> save </strong>函数保存模型。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="b17f" class="kd ke hi jz b fi kf kg l kh ki">predictor = ktrain.get_predictor(learner.model, preproc)<br/>predictor.save('spam_text_message')<br/>print('MODEL SAVED')</span></pre><p id="87b9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第二步:</strong>现在，我有了一个名为<strong class="ix hj"> spam_text_message </strong>的文件夹，里面有两个文件<strong class="ix hj"> tf_model.h5 </strong>和<strong class="ix hj"> tf_model.preproc. </strong>现在，我们可以加载模型进行预测了。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="906c" class="kd ke hi jz b fi kf kg l kh ki">import pickle<br/>from tensorflow.keras.models import load_model</span><span id="592b" class="kd ke hi jz b fi kq kg l kh ki"># loading preprocess and model file<br/>features = pickle.load(open('spam_text_message/tf_model.preproc',<br/>                            'rb'))<br/>new_model = load_model('spam_text_message/tf_model.h5')<br/>labels = ['ham', 'spam']</span></pre><p id="e562" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从上面的代码中，我们已经在features变量中加载了<strong class="ix hj"> tf_model.preproc </strong>文件，在new_model变量中加载了<strong class="ix hj"> tf_model.h5 </strong>，并且<strong class="ix hj">标签列</strong> names被<strong class="ix hj"> one-hot </strong>编码。</p><p id="2314" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第三步:现在，让我们做预测，但在此之前，我们必须预处理文本。所以，我们将使用<strong class="ix hj">特性的</strong>变量。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="3d5a" class="kd ke hi jz b fi kf kg l kh ki">text = 'hey i am spam'<br/>preproc_text = features.preprocess([text])</span></pre><p id="d8ab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我已经在<strong class="ix hj">特性</strong>变量中调用了<strong class="ix hj">预处理</strong>函数，并将预处理文本保存在<strong class="ix hj"> preproc_text </strong>变量中。</p><p id="784e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第四步:现在，我们可以做预测了。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="fa7b" class="kd ke hi jz b fi kf kg l kh ki">result = new_model.predict(preproc_text)</span><span id="c869" class="kd ke hi jz b fi kq kg l kh ki"># OUTPUT =&gt;array([[9.9999797e-01, 2.0015173e-06]], dtype=float32)</span></pre><p id="f1c4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">完成预测后，我们将得到<strong class="ix hj">n数组。</strong>因此，我们将把数组转换成我们的标签，如果你愿意，你可以使用数组值作为分数。</p><p id="9d98" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤5: </strong>我有一个一次性编码的标签列表。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="2a5c" class="kd ke hi jz b fi kf kg l kh ki">label = labels[result[0].argmax(axis=0)]<br/>score = ('{:.2f}'.format(round(np.max(result[0]), 2)*100))<br/>print('LABEL :', label, 'SCORE :', score)</span><span id="6230" class="kd ke hi jz b fi kq kg l kh ki"># OUTPUT =&gt; LABEL : ham SCORE : 100.00</span></pre><p id="d1ce" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果您有任何疑问和建议，请随时提出，我会尽快解决。</p><p id="8539" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谢谢，祝您愉快。</p><p id="1f85" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">参考资料:</strong>关于<em class="jt"> ktrain、</em>的更多信息，请参见<em class="jt"> ktrain、</em>  上的<a class="ae iu" href="https://github.com/amaiya/ktrain" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">教程笔记本。</strong></a></p><p id="6a76" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">源代码:</strong><a class="ae iu" href="https://github.com/ianuragbhatt/datascience-jupyter-notebooks/blob/master/ktrain/ktrain_deployment_text_classification.ipynb" rel="noopener ugc nofollow" target="_blank">kt rain-deployment-text-class ification . ipynb</a></p></div></div>    
</body>
</html>