<html>
<head>
<title>Clustering Geo-location : DBSCAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">聚类地理位置:DBSCAN</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/clustering-geo-location-dbscan-cadb33b0442e?source=collection_archive---------0-----------------------#2020-07-21">https://medium.com/analytics-vidhya/clustering-geo-location-dbscan-cadb33b0442e?source=collection_archive---------0-----------------------#2020-07-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/8e9e37bfc0526e1203a0f76c6fcf3a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pa-TivkbQ_DJzy8cTXRjWA.png"/></div></div></figure><div class=""/><h1 id="6507" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">聚类</strong></h1><p id="3638" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi km translated"><span class="l kn ko kp bm kq kr ks kt ku di"> C </span> <strong class="jq hu">聚类是大型数据库中知识发现的主要数据挖掘方法之一。它是根据相似性对大型数据集进行分组的过程。聚类分析是许多工程和科学应用领域的主要工具，包括数据分割、</strong> <a class="ae kv" href="https://g.co/kgs/6XeZQx" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hu">连续属性的离散化</strong> </a> <strong class="jq hu">、数据简化、离群点检测、噪声过滤、模式识别和图像处理</strong></p><h1 id="96bd" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> DBSCAN ( <em class="kw">带噪声的应用程序的基于密度的空间聚类</em> ) </strong></h1><p id="8405" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><strong class="jq hu"> DBSCAN <em class="kx">(含噪声应用的基于密度的空间聚类)是一种重要的空间聚类技术，在众多应用中被广泛采用。DBSCAN是一种用于机器学习的聚类方法，用于将高密度的聚类与低密度的聚类分开。鉴于DBSCAN是一种基于密度的聚类算法，它在寻找数据中具有高密度观测值的区域，而不是观测值不太密集的区域方面做得很好。</em>T19】</strong></p><p id="cbd1" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu">目录</strong></p><p id="0181" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu"> 1: <em class="kx">探索性数据分析</em> </strong></p><p id="d380" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu"> 2: <em class="kx">可视化地理数据</em> </strong></p><p id="2b77" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu"> 3:聚类强度/性能指标</strong></p><p id="c10e" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu"> 4: <em class="kx"> K均值聚类</em> </strong></p><p id="9018" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu">5:<em class="kx">DBS can</em>T39】</strong></p><p id="2283" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu">6:<em class="kx">hdb scan</em>T43】</strong></p><p id="a72a" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu"> 7: <em class="kx">处理异常值</em> </strong></p><blockquote class="ld le lf"><p id="39be" class="jo jp kx jq b jr ky jt ju jv kz jx jy lg la kb kc lh lb kf kg li lc kj kk kl hb bi translated"><strong class="jq hu">“我们有出租车停靠点位置，并且想要定义这些出租车的关键集群，在那里我们可以为在该区域运营的所有出租车建立服务站”。</strong></p></blockquote><h1 id="ede7" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">先决条件</strong></h1><p id="5a87" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们必须安装笔记本中没有内置的外部库。</p><ol class=""><li id="f76a" class="lj lk ht jq b jr ky jv kz jz ll kd lm kh ln kl lo lp lq lr bi translated"><strong class="jq hu"> HDBSCAN </strong></li></ol><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="901d" class="mb ir ht lx b fi mc md l me mf"><strong class="lx hu">#installing HDBSCAN <br/>!pip install hdbscan</strong></span></pre><p id="29e5" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu"> 2。叶子</strong></p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="efc6" class="mb ir ht lx b fi mc md l me mf"><strong class="lx hu">!pip install folium</strong></span></pre><p id="d881" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu"> 3。正则表达式</strong></p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="6eac" class="mb ir ht lx b fi mc md l me mf"><strong class="lx hu">!pip install re</strong></span></pre><h1 id="a438" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">让我们开始编码</strong></h1><p id="c14b" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><strong class="jq hu"> <em class="kx">导入库</em> </strong></p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="130c" class="mb ir ht lx b fi mc md l me mf"><strong class="lx hu">import matplotlib<br/>%matplotlib inline<br/>%config InlineBackend.figure_format = 'svg'<br/>import matplotlib.pyplot as plt<br/>plt.style.use('ggplot')</strong></span><span id="5b91" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">import pandas as pd<br/>import numpy as np<br/>import seaborn as sns<br/>from tqdm import tqdm</strong></span><span id="e1a1" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">from sklearn.cluster import KMeans, DBSCAN<br/>from sklearn.metrics import silhouette_score<br/>from sklearn.datasets import make_blobs<br/>from sklearn.neighbors import KNeighborsClassifier</strong></span><span id="9d7a" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">from ipywidgets import interactive</strong></span><span id="03e2" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">from collections import defaultdict</strong></span><span id="50bb" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">import hdbscan<br/>import folium<br/>import re</strong></span><span id="e2bc" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">cols = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4',<br/>        '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', <br/>        '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', <br/>        '#000075', '#808080']*10</strong></span><span id="33e1" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">sns.set(style="white")<br/></strong></span></pre><h1 id="f22b" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">探索性数据分析</h1><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="3e7d" class="mb ir ht lx b fi mc md l me mf">df = pd.read_csv('taxi_data.csv')<br/>df.head()</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es mh"><img src="../Images/e59e1696a8c414188aae10db57f43571.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*z7ixMd7a9EJBLYim-Uyv2A.png"/></div></figure><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="79c9" class="mb ir ht lx b fi mc md l me mf">df.duplicated(subset=['LON', 'LAT']).values.any()<br/><strong class="lx hu">output:TRUE</strong></span><span id="e53c" class="mb ir ht lx b fi mg md l me mf">df.isna().values.any()<br/><strong class="lx hu">output:TRUE</strong></span></pre><p id="9c0e" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu">删除NaN &amp;重复行</strong></p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="010e" class="mb ir ht lx b fi mc md l me mf">print(f'Before dropping NaNs and dupes\t:\tdf.shape = {df.shape}')<br/>df.dropna(inplace=True)<br/>df.drop_duplicates(subset=['LON', 'LAT'], keep='first', inplace=True)<br/>print(f'After dropping NaNs and dupes\t:\tdf.shape = {df.shape}')</span><span id="706e" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">output</strong><br/><strong class="lx hu">Before dropping NaNs and dupes	:	df.shape = (838, 3)<br/>After dropping NaNs and dupes	:	df.shape = (823, 3)</strong></span></pre><p id="9128" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu">散点图可视化</strong></p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="4e33" class="mb ir ht lx b fi mc md l me mf">X = np.array(df[[‘LON’, ‘LAT’]], dtype=’float64')<br/>plt.scatter(X[:,0], X[:,1], alpha=0.2, s=50)</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es mi"><img src="../Images/ef53ce2e01c23a40c447d3b5ebe1ce5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*V0-qNZtCtxFw7CHk7K575w.png"/></div></figure><h1 id="1f90" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">可视化地理数据</h1><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="518b" class="mb ir ht lx b fi mc md l me mf">m = folium.Map(location=[df.LAT.mean(), df.LON.mean()], zoom_start=9, <br/>               tiles='OpenStreet Map')</span><span id="d57a" class="mb ir ht lx b fi mg md l me mf">for _, row in df.iterrows():<br/>    folium.CircleMarker(<br/>        location=[row.LAT, row.LON],<br/>        radius=5,<br/>        popup=re.sub(r'[^a-zA-Z ]+', '', row.NAME),<br/>        color='#1787FE',<br/>        fill=True,<br/>        fill_colour='#1787FE'<br/>    ).add_to(m)</span><span id="7867" class="mb ir ht lx b fi mg md l me mf"><br/>m</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mj"><img src="../Images/c98e11acc76f42ab8fd5a97034bd7500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MXHRREbEoRU-9lRFIn389Q.png"/></div></div></figure><h1 id="33e2" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">聚类强度/性能指标</h1><p id="a35f" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><strong class="jq hu">绩效指标</strong>用于衡量企业的<strong class="jq hu">行为、活动和绩效。这应该是在一个范围内测量所需数据的数据形式，允许形成支持总体业务目标实现的基础。</strong></p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="89c9" class="mb ir ht lx b fi mc md l me mf">X_blobs, _ = make_blobs(n_samples=1000, centers=10, n_features=2, <br/>                        cluster_std=0.5, random_state=4)</span><span id="7b9a" class="mb ir ht lx b fi mg md l me mf">plt.scatter(X_blobs[:,0], X_blobs[:,1], alpha=0.2)</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es mk"><img src="../Images/5c7af5480600b0f82c9594e62f74ce5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*reL00PellCfZZZLbRjMm8Q.png"/></div></figure><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="bd1e" class="mb ir ht lx b fi mc md l me mf">class_predictions = np.load('sample_clusters.npy')</span><span id="0d0f" class="mb ir ht lx b fi mg md l me mf">unique_clusters = np.unique(class_predictions)<br/>for unique_cluster in unique_clusters:<br/>    X = X_blobs[class_predictions==unique_cluster]<br/>    plt.scatter(X[:,0], X[:,1], alpha=0.2, c=cols[unique_cluster])</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es ml"><img src="../Images/49c0d4e2ace940467f4c4dc9e765c30f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*YZPDgcG5gw8TBfbnLd-4vg.png"/></div></figure><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="f589" class="mb ir ht lx b fi mc md l me mf">silhouette_score(X_blobs, class_predictions)<br/><strong class="lx hu">output:0.6657220862867241</strong></span></pre></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><pre class="lw lx ly lz aw ma bi"><span id="3105" class="mb ir ht lx b fi mt mu mv mw mx md l me mf">class_predictions = np.load('sample_clusters_improved.npy')<br/>unique_clusters = np.unique(class_predictions)<br/>for unique_cluster in unique_clusters:<br/>    X = X_blobs[class_predictions==unique_cluster]<br/>    plt.scatter(X[:,0], X[:,1], alpha=0.2, c=cols[unique_cluster])</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es my"><img src="../Images/e8c028c371c75df026e1b874364b31a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*0i-tttG9UV9bnIlz5eqWog.png"/></div></figure><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="da46" class="mb ir ht lx b fi mc md l me mf">silhouette_score(X_blobs, class_predictions)<br/><strong class="lx hu">output:0.7473587799908298</strong></span></pre><h1 id="ef63" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">k均值聚类</h1><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="824d" class="mb ir ht lx b fi mc md l me mf">X_blobs, _ = make_blobs(n_samples=1000, centers=50, <br/>                        n_features=2, cluster_std=1, random_state=4)<br/>data = defaultdict(dict)<br/>for x in range(1,21):<br/>    model = KMeans(n_clusters=3, random_state=17, <br/>                   max_iter=x, n_init=1).fit(X_blobs)<br/>    <br/>    data[x]['class_predictions'] = model.predict(X_blobs)<br/>    data[x]['centroids'] = model.cluster_centers_<br/>    data[x]['unique_classes'] = np.unique(class_predictions)</span><span id="58fa" class="mb ir ht lx b fi mg md l me mf">def f(x):<br/>    class_predictions = data[x]['class_predictions']<br/>    centroids = data[x]['centroids']<br/>    unique_classes = data[x]['unique_classes']</span><span id="a42c" class="mb ir ht lx b fi mg md l me mf">for unique_class in unique_classes:<br/>            plt.scatter(X_blobs[class_predictions==unique_class][:,0], <br/>                        X_blobs[class_predictions==unique_class][:,1], <br/>                        alpha=0.3, c=cols[unique_class])<br/>    plt.scatter(centroids[:,0], centroids[:,1], s=200, c='#000000', marker='v')<br/>    plt.ylim([-15,15]); plt.xlim([-15,15])<br/>    plt.title('How K-Means Clusters')</span><span id="8694" class="mb ir ht lx b fi mg md l me mf">interactive_plot = interactive(f, x=(1, 20))<br/>output = interactive_plot.children[-1]<br/>output.layout.height = '350px'<br/>interactive_plot</span><span id="233b" class="mb ir ht lx b fi mg md l me mf">X = np.array(df[['LON', 'LAT']], dtype='float64')<br/>k = 70<br/>model = KMeans(n_clusters=k, random_state=17).fit(X)<br/>class_predictions = model.predict(X)<br/>df[f'CLUSTER_kmeans{k}'] = class_predictions</span><span id="3248" class="mb ir ht lx b fi mg md l me mf">df.head()</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es mz"><img src="../Images/86d04e982e1f0f3b601b7905477e8eea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*h_DWB92_-YM8uzLmmFc1vg.png"/></div></figure><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="c9e9" class="mb ir ht lx b fi mc md l me mf">def create_map(df, cluster_column):<br/>    m = folium.Map(location=[df.LAT.mean(), df.LON.mean()], zoom_start=9, tiles='OpenStreet Map')</span><span id="d98f" class="mb ir ht lx b fi mg md l me mf">for _, row in df.iterrows():</span><span id="362b" class="mb ir ht lx b fi mg md l me mf">if row[cluster_column] == -1:<br/>            cluster_colour = '#000000'<br/>        else:<br/>            cluster_colour = cols[row[cluster_column]]</span><span id="0169" class="mb ir ht lx b fi mg md l me mf">folium.CircleMarker(<br/>            location= [row['LAT'], row['LON']],<br/>            radius=5,<br/>            popup= row[cluster_column],<br/>            color=cluster_colour,<br/>            fill=True,<br/>            fill_color=cluster_colour<br/>        ).add_to(m)<br/>        <br/>    return m</span><span id="533e" class="mb ir ht lx b fi mg md l me mf">m = create_map(df, 'CLUSTER_kmeans70')<br/>print(f'K={k}')<br/>print(f'Silhouette Score: {silhouette_score(X, class_predictions)}')</span><span id="c543" class="mb ir ht lx b fi mg md l me mf">m.save('kmeans_70.html')</span><span id="5abb" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">OUTPUT:<br/>K=99<br/>Silhouette Score: 0.6971082963940812</strong></span><span id="a4ba" class="mb ir ht lx b fi mg md l me mf">m</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es na"><img src="../Images/e775b3c1319fdd02e0201ed0509726b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NrpfSI3o5qLpwvpgR2dFlg.png"/></div></div></figure><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="5538" class="mb ir ht lx b fi mc md l me mf">best_silhouette, best_k = -1, 0</span><span id="c8f1" class="mb ir ht lx b fi mg md l me mf">for k in tqdm(range(2, 100)):<br/>    model = KMeans(n_clusters=k, random_state=1).fit(X)<br/>    class_predictions = model.predict(X)<br/>    <br/>    curr_silhouette = silhouette_score(X, class_predictions)<br/>    if curr_silhouette &gt; best_silhouette:<br/>        best_k = k<br/>        best_silhouette = curr_silhouette<br/>        <br/>print(f'K={best_k}')<br/>print(f'Silhouette Score: {best_silhouette}')</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nb"><img src="../Images/74bc2db83931b5ced604a068c6755d27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hBKolsovxpywl5rI7t27oA.png"/></div></div></figure><h1 id="7163" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">基于密度的噪声应用空间聚类</h1><p id="cac9" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">基于密度的含噪声应用空间聚类</p><p id="83d6" class="pw-post-body-paragraph jo jp ht jq b jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl hb bi translated"><strong class="jq hu">用于索引某些值的代码</strong></p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="e7ad" class="mb ir ht lx b fi mc md l me mf">dummy = np.array([-1, -1, -1, 2, 3, 4, 5, -1])</span><span id="6810" class="mb ir ht lx b fi mg md l me mf">new = np.array([(counter+2)*x if x==-1 else x for counter, x in enumerate(dummy)])</span><span id="6c91" class="mb ir ht lx b fi mg md l me mf">model = DBSCAN(eps=0.01, min_samples=5).fit(X)<br/>class_predictions = model.labels_</span><span id="df4c" class="mb ir ht lx b fi mg md l me mf">df['CLUSTERS_DBSCAN'] = class_predictions</span><span id="cbd2" class="mb ir ht lx b fi mg md l me mf">m = create_map(df, 'CLUSTERS_DBSCAN')</span><span id="a1fc" class="mb ir ht lx b fi mg md l me mf">print(f'Number of clusters found: {len(np.unique(class_predictions))}')<br/>print(f'Number of outliers found: {len(class_predictions[class_predictions==-1])}')</span><span id="019e" class="mb ir ht lx b fi mg md l me mf">print(f'Silhouette ignoring outliers: {silhouette_score(X[class_predictions!=-1], class_predictions[class_predictions!=-1])}')</span><span id="609d" class="mb ir ht lx b fi mg md l me mf">no_outliers = 0<br/>no_outliers = np.array([(counter+2)*x if x==-1 else x for counter, x in enumerate(class_predictions)])<br/>print(f'Silhouette outliers as singletons: {silhouette_score(X, no_outliers)}')</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es nc"><img src="../Images/2e3adca289e06709fddc87b27bbff968.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*q48JW8rBLKdMZyQDadA3ug.png"/></div></figure><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="9456" class="mb ir ht lx b fi mc md l me mf">m</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nd"><img src="../Images/51c82a4f74c0b1f212d78f1f6c370adf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9fDywac3gX69wPYWw2c5qw.png"/></div></div></figure></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="b38f" class="mb ir ht lx b fi mc md l me mf">hdbscan.HDBSCAN?</span></pre><h1 id="8248" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">处理异常值</h1><p id="52e6" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">一个<strong class="jq hu">离群值</strong>是一个明显偏离其余对象的对象。它们可能是由测量或执行错误引起的。异常数据的分析被称为异常分析或异常挖掘。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="b05e" class="mb ir ht lx b fi mc md l me mf">classifier = KNeighborsClassifier(n_neighbors=1)</span><span id="56ae" class="mb ir ht lx b fi mg md l me mf">df_train = df[df.CLUSTER_HDBSCAN!=-1]<br/>df_predict = df[df.CLUSTER_HDBSCAN==-1]</span><span id="e57c" class="mb ir ht lx b fi mg md l me mf">X_train = np.array(df_train[['LON', 'LAT']], dtype='float64')<br/>y_train = np.array(df_train['CLUSTER_HDBSCAN'])</span><span id="dedb" class="mb ir ht lx b fi mg md l me mf">X_predict = np.array(df_predict[['LON', 'LAT']], dtype='float64')</span><span id="d257" class="mb ir ht lx b fi mg md l me mf">classifier.fit(X_train, y_train)</span><span id="8af1" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu"><br/>KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',<br/>                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,<br/>                     weights='uniform')</strong></span><span id="3d59" class="mb ir ht lx b fi mg md l me mf">predictions = classifier.predict(X_predict)<br/>df['CLUSTER_hybrid'] = df['CLUSTER_HDBSCAN']<br/>df.loc[df.CLUSTER_HDBSCAN==-1, 'CLUSTER_hybrid'] = predictions<br/>m = create_map(df, 'CLUSTER_hybrid')<br/>m</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nd"><img src="../Images/66a1d5bf5c8f63279e8061903c59af85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hEJ4dXAU1T0Ji1V0cPSJEQ.png"/></div></div></figure><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="1877" class="mb ir ht lx b fi mc md l me mf">class_predictions = df.CLUSTER_hybrid<br/>print(f'Number of clusters found: {len(np.unique(class_predictions))}')<br/>print(f'Silhouette: {silhouette_score(X, class_predictions)}')</span><span id="e11e" class="mb ir ht lx b fi mg md l me mf">m.save('hybrid.html')</span><span id="12c2" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">OUTPUT<br/>Number of clusters found: 66<br/>Silhouette: 0.5849126494706486</strong></span><span id="77eb" class="mb ir ht lx b fi mg md l me mf"><br/>df['CLUSTER_hybrid'].value_counts().plot.hist(bins=70, alpha=0.4, <br/>                                              label='Hybrid')<br/>df['CLUSTER_kmeans70'].value_counts().plot.hist(bins=70, alpha=0.4,<br/>                                               label='K-Means (70)')<br/>plt.legend()<br/>plt.title('Comparing Hybrid and K-Means Approaches')<br/>plt.xlabel('Cluster Sizes')</span><span id="474c" class="mb ir ht lx b fi mg md l me mf"><strong class="lx hu">OUTPUT<br/>Text(0.5, 0, 'Cluster Sizes')</strong></span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ne"><img src="../Images/5232f6183bc4a5df63673c1b10cb205d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8qSKaPD3wKjDTTdDzqSaZg.png"/></div></div></figure><blockquote class="ld le lf"><p id="5f53" class="jo jp kx jq b jr ky jt ju jv kz jx jy lg la kb kc lh lb kf kg li lc kj kk kl hb bi translated"><strong class="jq hu">如果你想自己运行代码，可以通过google colab链接:</strong></p></blockquote><div class="hh hi ez fb hj nf"><a href="https://colab.research.google.com/drive/1MMzPZDuVUkuU_JDvqpflyMcSw7H3iwoy?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hu fi z dy nk ea eb nl ed ef hs bi translated">谷歌联合实验室</h2><div class="nm l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">colab.research.google.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns hp nf"/></div></div></a></div></div></div>    
</body>
</html>