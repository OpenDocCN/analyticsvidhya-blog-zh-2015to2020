<html>
<head>
<title>Customer Transaction Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">客户交易预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/customer-transaction-prediction-31c28beba1ea?source=collection_archive---------3-----------------------#2019-12-12">https://medium.com/analytics-vidhya/customer-transaction-prediction-31c28beba1ea?source=collection_archive---------3-----------------------#2019-12-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4cda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如题，这个博客是关于一个名为桑坦德客户交易的kaggle竞赛。对于任何一家以金融为基础的公司来说，最重要的事情是了解客户将来是否会使用他们的服务。桑坦德银行(Santander)也给出了同样的情况，该银行要求我们解决一个挑战，以预测客户未来是否会进行交易。我将告诉你如何解决这个挑战，以及我做了哪些功能工程来获得90%的AUC结果并排名前4%。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/f5022a3484419e0a47b5eea3b7aac538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4vg0lW_YVZluXxzdGMfCIQ.png"/></div></div></figure><h1 id="5f48" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">问题陈述</strong></h1><p id="0c34" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">这个kaggle挑战的问题陈述是预测客户是否会进行未来的交易，而不管交易的金额。这里的限制是我们应该给出基于概率的预测。</p><h1 id="e028" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">机器学习问题陈述</strong></h1><p id="5693" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">到目前为止，我们已经看到了问题和问题的限制，但所有这些都与业务角度有关。为了使用机器学习来解决这个挑战，我们必须将其转化为机器学习问题陈述，伙计们，这个东西不仅仅限于这个特定的问题陈述，还包括所有其他挑战。在解决任何现实世界的问题之前，我们首先要将其转化为机器学习问题。对于这个问题，我们的ML问题陈述将是这样的:“<strong class="ih hj">这是一个经典的二元分类机器学习问题，其中我们必须预测客户是否会进行未来交易，评估指标是AUC。</strong></p><h1 id="80b1" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">数据集</strong></h1><p id="bf3a" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">数据集是匿名的，因此我们无法知道哪个要素是什么。该数据集中总共有200个要素，以及ID_code和目标列。目标列包含0和1值，其中0表示客户不会进行交易，1表示客户会进行交易。<br/>您可以从以下链接下载数据集:</p><p id="91a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ks" href="https://www.kaggle.com/c/santander-customer-transaction-prediction/overview/evaluation" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/Santander-customer-transaction-prediction/</a></p><h1 id="92d5" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">导入库</strong></h1><p id="22cf" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">到目前为止，你已经完全了解了问题陈述及其约束条件，所以现在让我们从编码部分开始。首先，我们从导入所有必需的库开始。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="d192" class="ky jq hi ku b fi kz la l lb lc">import pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import roc_curve, auc,roc_auc_score<br/>from sklearn.model_selection import StratifiedKFold<br/>from sklearn.model_selection import RandomizedSearchCV<br/>import lightgbm as lgb<br/>import timeit<br/>import time</span></pre><h1 id="61c4" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">探索性数据分析</strong></h1><p id="ca4c" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们已经完成了库的加载，让我们从探索性数据分析(EDA)开始。伙计们，EDA是解决任何机器学习问题的最重要的一步，它可以帮助你更深入地了解数据集，并帮助你派生出新的功能，以便更好地学习你的模型。我们首先通过加载数据来启动EDA。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="c980" class="ky jq hi ku b fi kz la l lb lc">data = pd.read_csv(‘train.csv’)#train data<br/>data_test = pd.read_csv(‘test.csv’)#test data</span><span id="b87c" class="ky jq hi ku b fi ld la l lb lc">data.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es le"><img src="../Images/e2b25318932a4f9275a44c558a856ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9NDUObygma8EwtZXMo9xvQ.png"/></div></div></figure><p id="9c8a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">加载训练和测试数据后，我重新安排了一些列，将目标列放在最后，并将数据保存到新的CSV文件名data_train.csv中。</p><p id="dd5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">检查数据集的平衡</strong></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="86fc" class="ky jq hi ku b fi kz la l lb lc">data_train[‘target’].value_counts()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lf"><img src="../Images/ff72ab2f4c540755fdcd19c6b2b6c165.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IF5Kb4MbVt7hymLIrIPY-Q.png"/></div></div></figure><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="3d5d" class="ky jq hi ku b fi kz la l lb lc">ax = sns.countplot(‘target’,data=data_train)<br/>print(“percentage of data belongs to 0 :”, data_train[‘target’].value_counts()[0]*100/200000,”%”)<br/>print(“percentage of data belongs to 1 :”, data_train[‘target’].value_counts()[1]*100/200000,”%”)<br/>ax.plot()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lg"><img src="../Images/e3ae7fee4834657ffe41549d19a1aeae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sUBgzYwAMh_XfVXxhdJhVw.png"/></div></div></figure><p id="461d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，大约90%的数据属于0类，只有10%属于1类，因此我们可以得出结论，该数据是一个不平衡的数据</p><p id="2f74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">检查空值</strong></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="4679" class="ky jq hi ku b fi kz la l lb lc">data_train.isnull().sum()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lg"><img src="../Images/3153041c11051b8c935d3e6d5a730004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*25Xsm0MMlcoc-FSyQJVqOQ.png"/></div></div></figure><p id="c9e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对我们来说，一件好事是，如我们所见，任何特征都没有空值，因此不需要对缺失值进行插补。<br/>现在让我们检查所有特征在目标值0和1上的分布情况，为此我编写了下面的函数，因为我们有200个特征，所以我们将分布分为两部分，第一部分我取了100个特征，第二部分取了其余的100个特征。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="225d" class="ky jq hi ku b fi kz la l lb lc">def feature_distribution(data_1,data_2,target_0,target_1,features_list):<br/># Here we are setting the style of the plot and grid in it<br/>sns.set_style(‘whitegrid’)<br/>plt.figure() # Here we are initializing the plt figure object<br/># Here we are creating the subplot and initialzing it size and row col size<br/>fig, ax = plt.subplots(10,10,figsize=(18,22))<br/>for plot_count, feature in enumerate(features_list):<br/>#plotting the plots here for every plot feature<br/>plt.subplot(10,10,plot_count+1)<br/>#plotting the pdf plot for every feature towards the target value<br/>sns.distplot(data_1[feature], hist=False,label=target_0)<br/>sns.distplot(data_2[feature], hist=False,label=target_1)<br/>plt.xlabel(feature, fontsize=9)# Here we are setting the x axis label<br/>locs, labels = plt.xticks()<br/># Here we are setting the ticks for x and y axis<br/>plt.tick_params(axis=’x’, which=’major’, labelsize=6, pad=-6)<br/>plt.tick_params(axis=’y’, which=’major’, labelsize=6)<br/>plt.show();<br/>## Dstribution for the first 100 features<br/>target_0_data = data.loc[data_train[‘target’] == 0]<br/>target_1_data = data.loc[data_train[‘target’] == 1]<br/>features = data.columns.values[1:101]<br/>feature_distribution(target_0_data, target_1_data, ‘0’, ‘1’, features)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lh"><img src="../Images/82bf92f73f530c7e10711390b5bef54f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ezIYU0af3T9gsLsOUVof9g.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">目标类前100个特征的样本分布</figcaption></figure><p id="b27f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，我们对其余的100个特征进行了分析，得出了以下结论:<br/> 1) <em class="lm">通过观察每个特征相对于目标值的分布，我发现大多数特征对于目标值具有不同的分布<br/>。<br/> 2)我们也可以说有一些特征不是完全而是有一点非常接近正态分布。</em> <br/> 3) <em class="lm">因此我可以说对数据做了某种处理。</em></p><p id="b852" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">让我们检查数据的平均值和标准差的分布<br/> </strong>就像我们对特征所做的那样让我们检查数据的平均值和标准差的分布。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="ce0a" class="ky jq hi ku b fi kz la l lb lc">plt.figure(figsize=(16,6))<br/>sns.set_style(‘whitegrid’)<br/>features = data_train.columns.values[1:202]<br/>plt.title(“Distribution of mean values per row in the data”)<br/>plt.xlabel(‘mean value’)<br/>plt.ylabel(‘pdf value’)<br/>sns.distplot(data_train[features].mean(axis=1),color=”green”, kde=True,bins=120)<br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ln"><img src="../Images/4e8594125247506c57f5db8d19c44c36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KSpa4dsD4-7gbhqh1JMLxg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">数据中每行平均值的分布</figcaption></figure><p id="af92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在查看数据的行值的均值图之后，进行以下观察:<br/> 1) <em class="lm">上图显示了每个特征的均值沿行的分布，并且似乎遵循高斯类型。<br/> 2)该图看起来有点像高斯分布，平均值为6.7342。<br/> 3)从上图中，我们可以说大约有80%的特征的平均值在6.5和7.0之间</em></p><p id="3ed0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，我们绘制了数据中每列平均值的分布，得到了下图。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/87bd82ed36295f21471d1ad53106c500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tb8UeS2wiZHbXAiZTosoyw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">数据中每列平均值的分布</figcaption></figure><p id="5e1d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在查看数据<br/> 1) <em class="lm">的col值的均值图后，做出以下观察。上图是每个特征的列方式的均值分布。<br/> 2)列向均值分布不是高斯分布。</em> <br/> 3) <em class="lm">大多数列的平均值在-10到20之间。</em></p><p id="4452" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，我沿着数据的行和列绘制了标准偏差的分布，并分别得到了下面的图和观察值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ln"><img src="../Images/fc0f3a8f7c84511a3e43f10d40649283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jhqRjtdjHTbqjur1sJ8qFQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">数据中每行标准值的分布</figcaption></figure><p id="40b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观察结果如下:<br/> 1) <em class="lm">我们可以看到，沿着行的每个特征的标准偏差分布也类似于不完全遵循<br/>而是根据曲线形状的高斯分布。<br/> 2)大约60%的特征的标准偏差在9.3-10之间。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/40e3ee3de3980bd4979a63ff03bc63d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ze9E9nHYgv0y3bbR-BwBFA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">数据中每列的标准值分布</figcaption></figure><p id="29c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观察结果<br/> 1) <em class="lm">如图表所示，我们可以说沿着列的标准偏差和特征的分布来自一些其他分布。<br/> 2)有大量特征的偏差在0 &amp; 6的范围内。<br/> 3)最小标准差0，最大21左右什么的。</em></p><p id="18e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">平均值数据集的分布，按目标值分组。<br/> </strong>这里我又做了一次上面的EDA，但是做了一些改动，我用目标值对平均值进行了分组。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ln"><img src="../Images/876cf3974bb78e699bb2576fbb92484b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*otv5qi88hFqFqyViXWYjeQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">按目标值分组的数据集中每行平均值的分布</figcaption></figure><p id="0f01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观察:<br/> 1) <em class="lm">上图显示了每个特征朝向目标的平均分布。每个类别的每个特征的分布看起来有点相似。因此，这些特征将很好地识别目标类别。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/ddfd0161326d17e2e28fab7e07e8d17b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PRgeSYstIhBz8gRBe01aCw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">按目标值分组的数据集中每列平均值的分布</figcaption></figure><p id="f179" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观察:<br/> 1) <em class="lm">看上面的图，两者的分布非常相似。所有的特征都可以帮助我们识别目标类。<br/> 3)大多数特征意味着位于-10到20的范围内。</em></p><p id="aee4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">行和列数据中最小值和最大值的双向分布</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/028d4051fe5fc738c8316a27dea4676e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vRACR_GzrovBNgHtwJwsdQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">数据中每行最小值的分布</figcaption></figure><p id="9f38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观察如下:<br/> 1) <em class="lm">上图显示了各特征的min值分布。这个图看起来偏向右边。<br/> 3)最小值在-40到-20范围内的大多数特征。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/bd37ea64d4125b7b6beab073c7d52164.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u01N__ry7xPW-Y58LJCRxw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">数据中每列最小值的分布</figcaption></figure><p id="f2e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观察:<br/> 1) <em class="lm">上图是每个特性的列式最小值分布。<br/> 2)我们观察到了较低的值，即-80，因为长队列位于较低的一侧。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/2188f1b78057cb466a69a7723a39fb37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E9OmB2H2Q-SN6WcJcpaK-w.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">数据中每行最大值的分布</figcaption></figure><p id="708e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观测值:<br/> 1) <em class="lm">以上分布是每个特征最大值的行方向分布。我们可以在右边观察到最大值70，因为长尾在图的右边。因为长尾在右边，所以图形向左倾斜。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/f4602293a4c78886568bd07be7002258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ugwwnrwas7VbMlSLGdGbaQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">数据中最大值的分布</figcaption></figure><p id="c818" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观察:<br/> 1) <em class="lm">以上分布是每个特征最大值的col wise分布。<br/> 2)我们可以观察到最大值80，因为图的长尾在右边。</em></p><p id="5175" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">现在让我们检查特征之间的相关性<br/> </strong>到目前为止，我所有的EDA都是基于图形分布，所以现在既然数据包含数字特征，就应该检查特征之间的相关性。所以让我们开始吧。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="a367" class="ky jq hi ku b fi kz la l lb lc">features = data_train.columns.values[1:200] # Here we are getting all th features<br/># And here we are calculating the correlation of every featre ad sorting it in ascending order<br/>cor_data = data_train[features].corr().abs().unstack().sort_values(kind=”quicksort”).reset_index() <br/>cor_data = cor_data[cor_data[‘level_0’] != cor_data[‘level_1’]]</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lp"><img src="../Images/91f16eccdf8b92a83119f78094bcb528.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*ztiZNoJHN_RYD-enkRG2RA.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">最高相关数据</figcaption></figure><h1 id="7aef" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">训练一个没有任何特征工程的模型</strong></h1><p id="779e" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我已经结束了我的EDA，但是你们可以做更多的工作来发现更多关于数据的有趣信息。知道你的模型的基线是什么的一个方法应该是你可以在原始数据上训练任何模型，而不需要做任何特征工程。在博客的这一部分，我也在做同样的事情。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="cc0e" class="ky jq hi ku b fi kz la l lb lc">start = timeit.default_timer()<br/># %%time<br/>lgb_model = lgb.LGBMClassifier(boosting_type= ‘gbdt’, objective=’binary’,feature_fraction=0.05,<br/> class_weight=’balanced’,num_leaves=8,n_estimators=2000,max_depth=5,<br/> learning_rate=0.05,metric=’auc’,bagging_fraction=0.4, n_jobs=-1)<br/>lgb_model.fit(X_train, y_train)</span><span id="2fdc" class="ky jq hi ku b fi ld la l lb lc">predict_y_train = batch_predict(lgb_model, X_train)<br/>predict_y_cv = batch_predict(lgb_model, X_cv)</span><span id="57e8" class="ky jq hi ku b fi ld la l lb lc">train_fpr, train_tpr, tr_thresholds = roc_curve(y_train, predict_y_train)<br/>test_fpr, test_tpr, te_thresholds = roc_curve(y_cv, predict_y_cv)<br/>plt.plot(train_fpr, train_tpr, label=”train AUC =”+str(auc(train_fpr, train_tpr)))<br/>plt.plot(test_fpr, test_tpr, label=”test AUC =”+str(auc(test_fpr, test_tpr)))<br/>plt.legend()<br/># plt.xlabel(“K: hyperparameter”)<br/>plt.ylabel(“AUC”)<br/>plt.title(“ERROR PLOTS”)<br/>plt.grid()<br/>plt.show()<br/>stop = timeit.default_timer()<br/>print(‘Time in mins: ‘,(stop — start)/60)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/40d976ffdfafdb5b26c5abd90290ba9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*DAzh6yXU03BDB4375zcsbw.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">田的AUC图及其检验</figcaption></figure><p id="97b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观察结果<br/>测试AUC达到89.52%，无需任何特征工程，我的目标是使用一些有趣的特征工程来进一步提高AUC。</p><h1 id="a662" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">特色工程</strong></h1><p id="65a1" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">从EDA中我们可以看到，均值、标准差、最小值、最大值、总和、偏斜度、峰度、中值可以作为一个很好的特征</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="1573" class="ky jq hi ku b fi kz la l lb lc">%time<br/># <a class="ae ks" href="https://www.youtube.com/watch?v=LEWpRlaEJO8" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=LEWpRlaEJO8</a><br/>idx = features = data.columns.values[2:202]<br/>for dataFrame in [data_test, data_train]:<br/> dataFrame[‘sum’] = dataFrame[idx].sum(axis=1) <br/> dataFrame[‘min’] = dataFrame[idx].min(axis=1)<br/> dataFrame[‘max’] = dataFrame[idx].max(axis=1)<br/> dataFrame[‘mean’] = dataFrame[idx].mean(axis=1)<br/> dataFrame[‘std’] = dataFrame[idx].std(axis=1)<br/> dataFrame[‘skew’] = dataFrame[idx].skew(axis=1)<br/> dataFrame[‘kurt’] = dataFrame[idx].kurtosis(axis=1)<br/> dataFrame[‘med’] = dataFrame[idx].median(axis=1)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lr"><img src="../Images/6abc5c30698bc4a80a275e60a3baf88d.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*fzRldMy3trCVRv4qwufKFQ.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">特征工程特征</figcaption></figure><p id="544f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个更有趣的特性可能是每个特性的值的舍入。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="1816" class="ky jq hi ku b fi kz la l lb lc">%%time<br/># <a class="ae ks" href="https://www.geeksforgeeks.org/numpy-round_-python/" rel="noopener ugc nofollow" target="_blank">https://www.geeksforgeeks.org/numpy-round_-python/</a><br/>features_value = [col for col in data_train.columns if col not in [‘ID_code’,’target’]]<br/># In this we ar rounding of the value of each columns and creating a new freature of the same <br/>for feature in features_value:<br/> data_train[‘round_2’+ feature] = np.round(data_train[feature],2)<br/> data_test[‘round_2’+ feature] = np.round(data_test[feature],2)<br/> data_train[‘round_1’+ feature] = np.round(data_train[feature],1) <br/> data_test[‘round_1’+ feature] = np.round(data_test[feature],1)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ls"><img src="../Images/9271689e9861bcf2dbdf8608a72eb51d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IjVBnUUo1-Nb5n86hJ7htA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">一些圆形特征</figcaption></figure><p id="9811" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在完成功能工程后，我们设法将功能增加到626个。</p><h1 id="eb8e" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">最终模型培训</strong></h1><p id="f045" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">一旦创建了新功能，就到了训练模型的时候了，看看AUC的值是多少，我是否设法将其增加了89.52%以上。</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="3ca0" class="ky jq hi ku b fi kz la l lb lc">parameter = {<br/> ‘bagging_freq’: 5,<br/> ‘bagging_fraction’: 0.4,<br/> ‘boost_from_average’:’false’,<br/> ‘boost’: ‘gbdt’,<br/> ‘feature_fraction’: 0.05,<br/> ‘learning_rate’: 0.01,<br/> ‘max_depth’: -1, <br/> ‘metric’:’auc’,<br/> ‘min_data_in_leaf’: 80,<br/> ‘min_sum_hessian_in_leaf’: 10.0,<br/> ‘num_leaves’: 13,<br/> ‘num_threads’: 8,<br/> ‘tree_learner’: ‘serial’,<br/> ‘objective’: ‘binary’, <br/> ‘verbosity’: 1<br/>}<br/># <a class="ae ks" href="https://www.kaggle.com/adrianlievano/light-gbm-with-stratified-kfold" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/adrianlievano/light-gbm-with-stratified-kfold</a><br/># Getting all the features name except the ID_code , target <br/>features = [col for col in data_train_final_.columns if col not in [‘ID_code’, ‘target’]]<br/># Inititalizing the K-Fold object<br/>K_folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000) <br/># this creates the empty numpy array of length of x in which we store the prediction of every validation data<br/>val_pred = np.zeros(len(x))<br/># In this we keep the predicted output of the test data <br/>predictions_test = np.zeros(len(data_test_final_))<br/>#In this loop we are doing the training and prediction for each folds and we are getting the train and valid data <br/># using the trn_idx and val_idx <br/>for n_fold, (trn_idx, val_idx) in enumerate(K_folds.split(x.values, y.values)):<br/> print(“Fold {}”.format(n_fold))<br/> # Getting the train and validation data from the x data<br/> train_data = lgb.Dataset(x.iloc[trn_idx][features], label=y.iloc[trn_idx]) <br/> valid_data = lgb.Dataset(x.iloc[val_idx][features], label=y.iloc[val_idx])<br/> # Here we are training lightgbm model on train and valid dataset<br/> num_round = 1000000<br/> classifier = lgb.train(parameter, train_data, num_round, <br/> valid_sets = [train_data, valid_data],<br/> verbose_eval=1000, early_stopping_rounds = 3000)<br/> # Here we are doing the prediction on the valid data <br/> val_pred[val_idx] = classifier.predict(x.iloc[val_idx][features], num_iteration=classifier.best_iteration)<br/> # And here we are doing the prediction on the test data<br/> predictions_test += classifier.predict(data_test_final_[features], <br/> num_iteration=classifier.best_iteration) / K_folds.n_splits<br/>print(“CV score: {:&lt;8.5f}”.format(roc_auc_score(y, val_pred)))</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lg"><img src="../Images/78df8058797d952b3b1f6065f748b471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EMO-kVpJ-B234rOkLgn7Qw.png"/></div></div></figure><p id="c24b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如你所见，AUC分数达到了90%,因此是时候在kaggle上提交并检查分数了。</p><p id="6e39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">创建提交CSV </strong></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="f1d4" class="ky jq hi ku b fi kz la l lb lc">sub_df = pd.DataFrame({“ID_code”:data_test[“ID_code”].values})<br/>sub_df[“target”] = predictions<br/>sub_df.to_csv(“submission.csv”, index=False)</span></pre><h1 id="8849" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">结果的</strong></h1><p id="cec0" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">创建提交文件后，在kaggle上测试它的时间，看看结果。所以祈祷吧。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lt"><img src="../Images/4b48e23ec9050f8afe36d66f12aaa04d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XoAgnAHCyTqXViHfTvmrFA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">kaggle提交的结果</figcaption></figure><p id="8ad3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如你所看到的，我设法在kaggle测试数据上获得了0.90041的AUC。正如我们所知，在机器学习领域，没有完美的解决方案，每个模型都有改进的空间，我的解决方案还可以进一步改进。</p><h1 id="2b98" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">改进范围</strong></h1><p id="a139" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">您可以通过加入一些其他功能工程来进一步改进该解决方案，其中之一是频率编码，并通过删除合成测试数据，这要感谢YaG320在其内核中分享的这项令人敬畏的技术<a class="ae ks" href="https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/YAG 320/list-of-fake-samples-and-public-private-lb-split</a>。您还可以执行数据扩充，并将AUC提高高达92%。</p><h1 id="ec9f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">参考文献</strong></h1><p id="ba1f" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><a class="ae ks" href="https://www.kaggle.com/c/santander-customer-transaction-prediction/overview/evaluation" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/Santander-customer-transaction-prediction/overview/evaluation</a><br/><a class="ae ks" href="https://www.youtube.com/watch?v=LEWpRlaEJO8" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=LEWpRlaEJO8</a><br/><a class="ae ks" href="https://www.kaggle.com/yag320/list-of-fake-samples-and-public-private-lb-split" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/YAG 320/list-of-fake-samples-and-public-private-lb-split</a></p><p id="8f45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">你可以在LinkedIn上联系我</strong><br/><a class="ae ks" href="https://www.linkedin.com/in/vashistnarayan-singh/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/vashistnarayan-singh/</a></p></div></div>    
</body>
</html>