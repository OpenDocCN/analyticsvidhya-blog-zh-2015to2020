<html>
<head>
<title>Build a Decision Tree in Minutes using Weka (No Coding Required!)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Weka在几分钟内建立一个决策树(不需要编码！)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/build-a-decision-tree-in-minutes-using-weka-no-coding-required-d884e72e0c16?source=collection_archive---------16-----------------------#2020-03-10">https://medium.com/analytics-vidhya/build-a-decision-tree-in-minutes-using-weka-no-coding-required-d884e72e0c16?source=collection_archive---------16-----------------------#2020-03-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><ul class=""><li id="7798" class="if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw bi translated">了解如何使用Weka构建决策树模型</li><li id="4986" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">本教程非常适合机器学习和决策树的新手，以及那些对编码不熟悉的人</li></ul><h1 id="96c6" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">介绍</h1><blockquote class="ka"><p id="8fb4" class="kb kc hi bd kd ke kf kg kh ki kj is dx translated">障碍越大，克服它就越光荣</p><p id="a19c" class="kb kc hi bd kd ke kf kg kh ki kj is dx translated"><em class="kk">——莫里哀</em></p></blockquote><p id="4627" class="pw-post-body-paragraph kl km hi ih b ii kn ko kp ik kq kr ks im kt ku kv io kw kx ky iq kz la lb is hb bi translated">对于来自非技术背景的人来说，机器学习可能会令人生畏。所有的机器学习工作似乎都需要对Python(或R)有健康的理解。</p><p id="b9cc" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">那么非程序员如何获得编码经验呢？这不是小菜一碟！</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lf"><img src="../Images/efc484d42a996fba7225f0fcd0639a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DiXwlDtHM6QuohN8.jpg"/></div></div></figure><p id="8f43" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">这里有一个好消息——有<a class="ae lr" href="https://www.analyticsvidhya.com/blog/2018/05/19-data-science-tools-for-people-dont-understand-coding/?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank">大量的工具让我们无需编码就能执行机器学习任务。您可以在一个漂亮的图形界面中轻松地从头开始构建像决策树这样的算法。那不是梦吗？这些工具，如Weka，主要帮助我们处理两件事:</a></p><ul class=""><li id="ebeb" class="if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw bi translated">快速建立一个机器学习模型，比如决策树，并了解算法的执行情况。稍后可以对其进行修改和构建</li><li id="4664" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">这是向客户/你的领导团队展示你在做什么的理想方式</li></ul><p id="cbe5" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">本文将向您展示在没有任何编程知识的情况下，如何在Weka中使用决策树解决分类和回归问题！</p><p id="0eac" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated"><em class="ls">但是如果你热衷于接触编程和机器学习，我建议你参加以下精心策划的课程:</em></p><h1 id="2209" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">目录</h1><ul class=""><li id="25a8" class="if ig hi ih b ii lt ik lu im lv io lw iq lx is it iu iv iw bi translated">机器学习中的分类与回归</li><li id="165a" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">理解决策树</li><li id="4eaf" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">探索Weka中的数据集</li><li id="9fd1" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">Weka中决策树的分类</li><li id="8a68" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">Weka中的决策树参数</li><li id="3ac3" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">在Weka中可视化决策树</li><li id="4fc4" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">在Weka中使用决策树进行回归</li></ul><h1 id="6b75" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">机器学习中的分类与回归</h1><p id="f720" class="pw-post-body-paragraph kl km hi ih b ii lt ko kp ik lu kr ks im ly ku kv io lz kx ky iq ma la lb is hb bi translated">我先快速总结一下在<a class="ae lr" href="https://courses.analyticsvidhya.com/courses/applied-machine-learning-beginner-to-professional" rel="noopener ugc nofollow" target="_blank">机器学习</a>的背景下什么是分类和回归。在深入研究决策树之前，了解这些概念非常重要。</p><p id="322b" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">一个<strong class="ih hj">分类</strong> <strong class="ih hj">问题</strong>是关于教你的机器学习模型如何将一个数据值归类到多个类中的一个。它通过学习每一类的特征来做到这一点。例如，为了预测图像是猫还是狗，模型根据训练数据学习狗和猫的特征。</p><p id="9c08" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">一个<strong class="ih hj">回归</strong> <strong class="ih hj">问题</strong>是关于教你的机器学习模型如何预测一个连续量的未来值。它通过学习过去受不同变量影响的数量模式来做到这一点。例如，试图预测公司未来股价的模型就是一个回归问题。</p><p id="7bfc" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">你可以在我们的<a class="ae lr" href="http://datahack.analyticsvidhya.com/?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank"> DataHack平台</a>上找到大量的这两个问题。</p><p id="c3da" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">现在，让我们学习一种解决这两个问题的算法——决策树！</p><h1 id="2ce0" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">理解决策树</h1><p id="beaf" class="pw-post-body-paragraph kl km hi ih b ii lt ko kp ik lu kr ks im ly ku kv io lz kx ky iq ma la lb is hb bi translated"><strong class="ih hj">决策树</strong>也被称为<strong class="ih hj">分类和回归树(CART) </strong>它们通过学习导致决策的if/else问题的答案来工作。这些问题形成了树状结构，因而得名。</p><p id="105a" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">例如，假设我们想预测一个人是否会点餐。为此，我们可以设想以下决策树:</p><figure class="lg lh li lj fd lk er es paragraph-image"><div class="er es mb"><img src="../Images/a197d871848aba3dda4ef079e1743839.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/0*9DouDOQmf81F_Z_Y.png"/></div></figure><p id="eb24" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">树中的每个节点代表一个从数据集中存在的要素派生的问题。基于这些问题对数据集进行分割，直到达到树的最大深度。最后一个节点不提问，但表示该值属于哪个类。</p><blockquote class="ka"><p id="2a3e" class="kb kc hi bd kd ke kf kg kh ki kj is dx translated">决策树中最顶端的节点称为<strong class="ak">根节点</strong></p><p id="6b2d" class="kb kc hi bd kd ke kf kg kh ki kj is dx translated"><em class="kk">最底层的节点称为</em> <strong class="ak"> <em class="kk">叶节点</em> </strong></p><p id="1054" class="kb kc hi bd kd ke kf kg kh ki kj is dx translated">被分成子节点的节点被称为<strong class="ak"> <em class="kk">父节点。</em> </strong>子节点称为<strong class="ak"> <em class="kk">子节点</em> </strong></p></blockquote><p id="3cc9" class="pw-post-body-paragraph kl km hi ih b ii kn ko kp ik kq kr ks im kt ku kv io kw kx ky iq kz la lb is hb bi translated">如果您想详细了解决策树，我建议您浏览以下资源:</p><ul class=""><li id="21bd" class="if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw bi translated"><a class="ae lr" href="https://courses.analyticsvidhya.com/courses/getting-started-with-decision-trees?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank">决策树入门(免费课程)</a></li><li id="f711" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated"><a class="ae lr" href="https://www.analyticsvidhya.com/blog/2016/04/tree-based-algorithms-complete-tutorial-scratch-in-python/?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank">基于树的算法:从头开始的完整教程</a></li></ul><h1 id="2b37" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">什么是Weka？为什么要用Weka进行机器学习？</h1><blockquote class="ka"><p id="e043" class="kb kc hi bd kd ke kf kg kh ki kj is dx translated"><strong class="ak"><em class="kk">“Weka</em></strong><em class="kk">是一款免费开源软件，内置了一系列机器学习算法，您可以通过图形用户界面访问！”</em></p></blockquote><p id="ad35" class="pw-post-body-paragraph kl km hi ih b ii kn ko kp ik kq kr ks im kt ku kv io kw kx ky iq kz la lb is hb bi translated"><strong class="ih hj"> WEKA </strong>代表<strong class="ih hj">怀卡托知识分析环境</strong>，由新西兰怀卡托大学开发。</p><p id="cc2f" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">Weka有多个内置函数，用于实现从线性回归到神经网络的广泛的机器学习算法。这使您只需点击一个按钮，就可以在数据集上部署最复杂的算法！不仅如此，Weka对访问Python和R的一些最常见的机器学习库算法给予了支持！</p><p id="21cd" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">使用Weka，您可以对数据进行预处理、分类、聚类，甚至可视化数据！这可以在不同格式的数据文件上实现，比如ARFF、CSV、C4.5和JSON。Weka甚至允许您向数据集添加过滤器，通过过滤器您可以规范化数据、标准化数据、在名义值和数值之间交换特性等等！</p><p id="7b67" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">我可以继续讲述Weka的神奇之处，但是就本文的范围而言，让我们通过创建一个决策树来尝试探索Weka。现在开始从他们的官方网站下载Weka吧！</p><figure class="lg lh li lj fd lk er es paragraph-image"><div class="er es mc"><img src="../Images/6c938bfe74550b397909f220b9b9ff39.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/0*qzZz6w368xCVyWUv.png"/></div></figure><h1 id="60e8" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">探索Weka中的数据集</h1><p id="1b1b" class="pw-post-body-paragraph kl km hi ih b ii lt ko kp ik lu kr ks im ly ku kv io lz kx ky iq ma la lb is hb bi translated">我将从<a class="ae lr" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)" rel="noopener ugc nofollow" target="_blank"> UCI机器学习库</a>获取乳腺癌数据集。我建议你在前进之前阅读一下这个问题。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div class="er es md"><img src="../Images/24a847e1080822f5a7083a70252205fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/0*ES4gdcScXErcY8p2.png"/></div></figure><p id="4ea1" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">让我们首先在Weka中加载数据集。为此，请遵循以下步骤:</p><ol class=""><li id="4d91" class="if ig hi ih b ii ij ik il im in io ip iq ir is me iu iv iw bi translated">打开Weka GUI</li><li id="fddb" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is me iu iv iw bi translated">选择<strong class="ih hj">【探索者】</strong>选项。</li><li id="6bf9" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is me iu iv iw bi translated">选择<strong class="ih hj">“打开文件”</strong>并选择您的数据集。</li></ol><p id="e259" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">您的Weka窗口现在应该如下所示:</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mf"><img src="../Images/9000eaacaa17a86fda9577b304dc2450.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Qirb3NrPhaAHWne3.png"/></div></div></figure><p id="d974" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">您可以在左侧查看数据集中的所有要素。Weka会自动为您的要素创建地块，您在浏览要素时会注意到这一点。</p><p id="a410" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">如果您点击<strong class="ih hj">“全部可视化”</strong>按钮，您甚至可以一起查看所有图。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mf"><img src="../Images/6ba634acc57971b7928a5f2390eb2e20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*V3JxvZrbsAtRzvO0.png"/></div></div></figure><p id="b7b5" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">现在让我们训练我们的分类模型！</p><h1 id="599e" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">Weka中决策树的分类</h1><p id="df9e" class="pw-post-body-paragraph kl km hi ih b ii lt ko kp ik lu kr ks im ly ku kv io lz kx ky iq ma la lb is hb bi translated">在Weka中实现决策树非常简单。只需完成以下步骤:</p><ol class=""><li id="723c" class="if ig hi ih b ii ij ik il im in io ip iq ir is me iu iv iw bi translated">点击顶部的<strong class="ih hj">“分类”</strong>标签</li><li id="4434" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is me iu iv iw bi translated">点击<strong class="ih hj">“选择”</strong>按钮</li><li id="b211" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is me iu iv iw bi translated">从下拉列表中选择<strong class="ih hj">“trees”</strong>，这将打开所有的树算法</li><li id="6bec" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is me iu iv iw bi translated">最后，选择<strong class="ih hj">决策树</strong></li></ol><blockquote class="ka"><p id="bc17" class="kb kc hi bd kd ke mg mh mi mj mk is dx translated"><strong class="ak"> <em class="kk">“约简误差剪枝树(RepTree) </em> </strong> <em class="kk">是一个快速决策树学习器，它使用</em> <strong class="ak"> <em class="kk">信息增益</em> </strong> <em class="kk">作为分裂准则来构建决策/回归树，并使用约简误差剪枝算法进行剪枝。”</em></p></blockquote><p id="8925" class="pw-post-body-paragraph kl km hi ih b ii kn ko kp ik kq kr ks im kt ku kv io kw kx ky iq kz la lb is hb bi translated">你可以在这篇<a class="ae lr" href="https://www.researchgate.net/publication/294086112_A_Reduced_Error_Pruning_Technique_for_Improving_Accuracy_of_Decision_Tree_Learning" rel="noopener ugc nofollow" target="_blank">研究论文</a>中了解减少错误修剪技术。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ml"><img src="../Images/9bfa6472137cebf1666598cd9fa56ecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dpJlTz63c0ove2Uo.png"/></div></div></figure><blockquote class="ka"><p id="07bf" class="kb kc hi bd kd ke mg mh mi mj mk is dx translated">“决策树根据所有可用变量拆分节点，然后选择导致最相似子节点的拆分。”</p><p id="c4fb" class="kb kc hi bd kd ke kf kg kh ki kj is dx translated"><a class="ae lr" href="https://www.analyticsvidhya.com/blog/2016/04/tree-based-algorithms-complete-tutorial-scratch-in-python/#three?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank">信息增益</a>用于计算样本在分割时的同质性。</p></blockquote><p id="1f0d" class="pw-post-body-paragraph kl km hi ih b ii kn ko kp ik kq kr ks im kt ku kv io kw kx ky iq kz la lb is hb bi translated">您可以从<strong class="ih hj">“开始”</strong>按钮正上方的下拉菜单中选择您的目标功能。如果不这样做，WEKA会自动选择最后一个特征作为目标。</p><p id="5a91" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated"><strong class="ih hj"> "Percentage split" </strong>指定您希望保留多少数据用于训练分类器。其余的数据在测试阶段用于计算模型的准确性。</p><p id="7ab6" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated"><strong class="ih hj">“交叉验证折叠”</strong>指定您希望分类器迭代训练数据的次数。但是请记住，每次训练数据都是从总数据中随机选择的。然而，训练数据的大小将保持与<strong class="ih hj">“百分比分割”</strong>指定的相同。</p><blockquote class="ka"><p id="30f0" class="kb kc hi bd kd ke kf kg kh ki kj is dx translated"><em class="kk">您使用的交叉验证折叠数越多，您的模型就越好。这使得模型在随机选择的数据上训练，这使得它更健壮。</em></p></blockquote><p id="38ad" class="pw-post-body-paragraph kl km hi ih b ii kn ko kp ik kq kr ks im kt ku kv io kw kx ky iq kz la lb is hb bi translated">最后，按下<strong class="ih hj">“开始”</strong>按钮，分级机就可以大显身手了！</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mf"><img src="../Images/529ca40593d5c4526eb4d9c75cb4583d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HkXSnAIAPsKq9jfU.png"/></div></div></figure><p id="b033" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">我们的分类器获得了92.4%的准确率。Weka甚至为您打印了<strong class="ih hj">混淆矩阵</strong>，其中给出了不同的指标。你可以在这里详细学习关于混淆矩阵和其他指标的<a class="ae lr" href="https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="8676" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">Weka中的决策树参数</h1><p id="39a1" class="pw-post-body-paragraph kl km hi ih b ii lt ko kp ik lu kr ks im ly ku kv io lz kx ky iq ma la lb is hb bi translated">决策树有很多参数。我们可以调整这些来提高我们模型的整体性能。这就是决策树的工作知识真正发挥重要作用的地方。</p><p id="a667" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">您可以通过点击顶部的决策树算法来访问这些参数:</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mf"><img src="../Images/187c8a8e3444facbed42f3113f7c817e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*z8zka3-rsfJFGSam.png"/></div></div></figure><p id="5351" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">先简单说一下主要参数:</p><ul class=""><li id="fb88" class="if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw bi translated"><strong class="ih hj"><em class="ls">max depth</em></strong><em class="ls"/>——它决定了你的决策树的最大深度。默认情况下，它是-1，这意味着算法将自动控制深度。但是您可以手动调整该值以获得最佳的数据结果</li><li id="5e05" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated"><strong class="ih hj"><em class="ls"/></strong>-剪枝是指在不包含太多信息的叶子节点上自动削减。这使得决策树简单且易于解释</li><li id="5096" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated"><strong class="ih hj"> <em class="ls"> numFolds </em> </strong> -指定数量的折叠数据将用于修剪决策树。其余的将用于发展规则</li><li id="a6e6" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated"><strong class="ih hj"> <em class="ls"> minNum </em> </strong> —每个叶的最小实例数。如果没有提到，树将继续分裂，直到所有的叶节点只有一个相关的类</li></ul><p id="ca94" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">您始终可以尝试这些参数的不同值，以获得数据集的最佳精度。</p><h1 id="3851" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">在Weka中可视化您的决策树</h1><p id="b94f" class="pw-post-body-paragraph kl km hi ih b ii lt ko kp ik lu kr ks im ly ku kv io lz kx ky iq ma la lb is hb bi translated">Weka甚至允许您轻松地可视化基于数据集构建的决策树:</p><ol class=""><li id="98ac" class="if ig hi ih b ii ij ik il im in io ip iq ir is me iu iv iw bi translated">转到<strong class="ih hj">“结果列表”</strong>部分，右键单击您训练好的算法</li><li id="eae6" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is me iu iv iw bi translated">选择<strong class="ih hj">“可视化树”</strong>选项</li></ol><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mf"><img src="../Images/e8e9a4d69d335dcd2517ba8fd8a2f085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xAthIuugxK66Zsdb.png"/></div></div></figure><p id="2b60" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">您的决策树将如下所示:</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mf"><img src="../Images/e2a1a2d1310df750a0ce226050d62e3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ljv7i_73rWfocdS1.png"/></div></div></figure><p id="452b" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">解释这些价值观可能有点吓人，但是一旦你掌握了窍门，它实际上是非常容易的。</p><p id="4eb4" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">连接结点的线上的值表示基于父结点要素中的值的分割标准</p><p id="b970" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">在叶节点中:</p><ul class=""><li id="1252" class="if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw bi translated">括号前的值表示分类值</li><li id="8dd2" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">第一个括号中的第一个值是该叶中训练集的实例总数。第二个值是该叶中错误分类的实例数量</li><li id="d664" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated">第二个括号中的第一个值是该叶中修剪集的实例总数。第二个值是该叶中错误分类的实例数量</li></ul><h1 id="609a" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">在Weka中使用决策树进行回归</h1><p id="5d25" class="pw-post-body-paragraph kl km hi ih b ii lt ko kp ik lu kr ks im ly ku kv io lz kx ky iq ma la lb is hb bi translated">就像我之前说的，决策树是如此的多才多艺，它们可以处理分类问题，也可以处理回归问题。为此，我将使用来自<a class="ae lr" href="https://datahack.analyticsvidhya.com/contest/all/?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank"> Analytics Vidhya的DataHack平台</a>的“<a class="ae lr" href="https://datahack.analyticsvidhya.com/contest/enigma-codefest-machine-learning-1/?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank">预测upvots</a>的数量”问题。</p><p id="6bb8" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">在这里，我们需要预测一个用户在问答平台上提出的一个问题的评分。</p><p id="4f3c" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">像往常一样，我们将从加载数据文件开始。但是这一次，对于数据集中的每个用户，数据还包含一个<em class="ls">“ID”</em>列。这在预测中没有用。因此，我们将通过选择列名下面的<strong class="ih hj">“Remove”</strong>选项来删除该列:</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mf"><img src="../Images/fe731f10a2d19fc880cb412a9da9c20b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*D9qyI8bVOzkc9--r.png"/></div></div></figure><p id="c130" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">我们可以对数据集进行预测，就像我们对乳腺癌问题进行预测一样。<strong class="ih hj"> RepTree </strong>会自动检测回归问题:</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mf"><img src="../Images/18f4943d9671385cefa58f0b28010370.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fBhWCDXHNkbX7wQD.png"/></div></div></figure><p id="0d70" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">黑客马拉松中提供的评估标准是RMSE分数。我们可以看到，在没有任何特征工程的情况下，该模型具有非常差的RMSE。这就是你要介入的地方——继续，实验并提升最终模型！</p><h1 id="86ce" class="jc jd hi bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">结束注释</h1><p id="8897" class="pw-post-body-paragraph kl km hi ih b ii lt ko kp ik lu kr ks im ly ku kv io lz kx ky iq ma la lb is hb bi translated">就这样，你不用做任何编程就创建了一个决策树模型！这将对你掌握机器学习模型的工作大有帮助。</p><p id="a3c1" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">如果你想学习和探索机器学习的编程部分，我强烈建议你浏览一下<a class="ae lr" href="https://courses.analyticsvidhya.com/collections/?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank"> Analytics Vidhya </a>网站上这些精心策划的课程:</p><ul class=""><li id="2849" class="if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw bi translated"><a class="ae lr" href="https://courses.analyticsvidhya.com/courses/introduction-to-data-science?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank">面向数据科学的Python</a></li><li id="ad6f" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated"><a class="ae lr" href="https://courses.analyticsvidhya.com/courses/a-comprehensive-learning-path-to-become-a-data-scientist-in-2020?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank">2020年成为数据科学家的全面学习途径</a></li><li id="429f" class="if ig hi ih b ii ix ik iy im iz io ja iq jb is it iu iv iw bi translated"><a class="ae lr" href="https://courses.analyticsvidhya.com/courses/getting-started-with-decision-trees?utm_source=blog&amp;utm_medium=decision-tree-weka-no-coding" rel="noopener ugc nofollow" target="_blank">决策树入门</a></li></ul><p id="cbc9" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated">你也可以在分析Vidhya的Android应用上阅读这篇文章</p></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><p id="c9d2" class="pw-post-body-paragraph kl km hi ih b ii ij ko kp ik il kr ks im lc ku kv io ld kx ky iq le la lb is hb bi translated"><em class="ls">原载于2020年3月10日https://www.analyticsvidhya.com</em><a class="ae lr" href="https://www.analyticsvidhya.com/blog/2020/03/decision-tree-weka-no-coding/" rel="noopener ugc nofollow" target="_blank"><em class="ls"/></a><em class="ls">。</em></p></div></div>    
</body>
</html>