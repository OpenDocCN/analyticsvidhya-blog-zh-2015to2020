<html>
<head>
<title>Natural Language Processing (NLP): Practical Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理(NLP):实用介绍</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/natural-language-processing-nlp-practical-introduction-1fe3ad96e360?source=collection_archive---------21-----------------------#2020-03-26">https://medium.com/analytics-vidhya/natural-language-processing-nlp-practical-introduction-1fe3ad96e360?source=collection_archive---------21-----------------------#2020-03-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8544aef1650a3eb77561d02c8417db30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T00ipRjCPSfBD_1E"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">帕特里克·托马索在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="7e2d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们产生的数据比以往任何时候都多。其中很大一部分是文本。推文、评论、评论、搜索、查询，一切都在文本中，因为这是我们交流的方式，这是我们的语言。</p><blockquote class="jt ju jv"><p id="870a" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">电脑就知道0和1，多教教吧</p></blockquote></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h2 id="12be" class="kh ki hi bd kj kk kl km kn ko kp kq kr jg ks kt ku jk kv kw kx jo ky kz la lb bi translated">先决条件:</h2><ol class=""><li id="5686" class="lc ld hi ix b iy le jc lf jg lg jk lh jo li js lj lk ll lm bi translated">Python基础</li><li id="9363" class="lc ld hi ix b iy ln jc lo jg lp jk lq jo lr js lj lk ll lm bi translated">NLP概念，如标记化、停用词、词干和矢量化</li><li id="fbde" class="lc ld hi ix b iy ln jc lo jg lp jk lq jo lr js lj lk ll lm bi translated">Word2Vec基础</li></ol></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><blockquote class="jt ju jv"><p id="0173" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated"><strong class="ix hj">注意:这个故事没有深入NLP的理论，而是展示了如何开始使用python(实用方法)</strong></p></blockquote></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><p id="61d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">考虑数据集:</strong> <a class="ae iu" href="https://www.kaggle.com/rmisra/news-category-dataset" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">新闻类别</strong> </a></p><h2 id="5e69" class="kh ki hi bd kj kk kl km kn ko kp kq kr jg ks kt ku jk kv kw kx jo ky kz la lb bi translated">步骤0:导入</h2><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="3f73" class="kh ki hi lx b fi mb mc l md me">#Importing the required libraries<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from nltk.stem import PorterStemmer <br/>from nltk.tokenize import word_tokenize<br/>import nltk<br/>from nltk.corpus import stopwords<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from nltk.corpus import stopwords<br/>stop = stopwords.words('english')<br/>from sklearn.metrics.pairwise import cosine_similarity</span></pre></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h2 id="31cc" class="kh ki hi bd kj kk kl km kn ko kp kq kr jg ks kt ku jk kv kw kx jo ky kz la lb bi translated">第一步:探索</h2><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/913429bead1322d277063c99b7d3999d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jdWKGESRar7FQ8s2KJnJmw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">显示数据集的前五行</figcaption></figure><p id="928e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它有5个栏目:类别、标题、作者、链接、简短描述和日期。<br/>我们可以看到数据是按日期降序排列的，也就是说最新的新闻最先出现。查看short_description，我们可以说它可能会也可能不会给出关于标题的细节。</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/2d4fb913467ae9deb5bf06596aad36e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8zLnCd3v_uNzofpvPE_QhQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">缺失数据</figcaption></figure><p id="dcfe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在查看更多行时，我们可以看到有丢失的值。</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/4f1dabc0b3ea302e231fc81bd4fc4e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*3XN3IPxJCkEuf6kms0XWyw.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">df.info()</figcaption></figure><p id="a5b3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们看到所有的值都是非空对象，但这不是真的，因为有丢失的值。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="1714" class="kh ki hi lx b fi mb mc l md me">print('--------Column Category----------')</span><span id="54a9" class="kh ki hi lx b fi mi mc l md me">#Checking if the column value contains an empty string as empty string is considered as a non-null value.<br/>print(len(df[(df['category']=='')]))</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/cec14576be8414fc60cfb0906dcf1c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*0z0D5ZujPfDGghczm-V_wg.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">缺失值总数</figcaption></figure><p id="28b7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">标题列有6个空值，这些行必须从数据集中删除，因为如果标题为空，我们就无法知道文章的内容。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="1652" class="kh ki hi lx b fi mb mc l md me">len(df['headline'].unique())</span></pre><p id="f4d9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">总共有199344个唯一标题，但总行数是200853，这意味着存在重复条目，必须删除这些条目，并且必须只保留一个值。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="4136" class="kh ki hi lx b fi mb mc l md me">#Deleting rows where headlines are null<br/>df.drop(df[df['headline'] == ''].index, inplace = True)</span><span id="05b5" class="kh ki hi lx b fi mi mc l md me">#Deleting duplicate rows<br/>df.drop_duplicates(subset ='headline', <br/>                     keep = 'first', inplace = True)</span></pre></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h2 id="18db" class="kh ki hi bd kj kk kl km kn ko kp kq kr jg ks kt ku jk kv kw kx jo ky kz la lb bi translated">步骤2:预处理</h2><p id="3313" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg mk ji jj jk ml jm jn jo mm jq jr js hb bi translated">现在，我们已经探索了数据，并进行了一些清理，下一步是预处理。<br/>从这里开始，我们将只考虑“标题”列。</p><p id="c7d2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jw">预处理阶段:</em> </strong></p><ol class=""><li id="c95e" class="lc ld hi ix b iy iz jc jd jg mn jk mo jo mp js lj lk ll lm bi translated">标记化</li><li id="eb70" class="lc ld hi ix b iy ln jc lo jg lp jk lq jo lr js lj lk ll lm bi translated">停用词移除</li><li id="5460" class="lc ld hi ix b iy ln jc lo jg lp jk lq jo lr js lj lk ll lm bi translated">删除标点符号</li><li id="1cbd" class="lc ld hi ix b iy ln jc lo jg lp jk lq jo lr js lj lk ll lm bi translated">堵塞物</li><li id="d37a" class="lc ld hi ix b iy ln jc lo jg lp jk lq jo lr js lj lk ll lm bi translated">…向量化…</li></ol><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="558b" class="kh ki hi lx b fi mb mc l md me">#Tokenization<br/>df['headline_tokens'] = df['headline'].apply(word_tokenize)</span><span id="6fe3" class="kh ki hi lx b fi mi mc l md me">#All words to lowercase<br/>df['headline_tokens'] = df['headline_tokens'].apply(lambda sentence:      [words.lower() for words in sentence])</span><span id="1a06" class="kh ki hi lx b fi mi mc l md me">#Removal of stop words<br/> df["stopped"] = df['headline_tokens'].apply(lambda sentence: [words for words in sentence if words not in stop])</span><span id="aa5a" class="kh ki hi lx b fi mi mc l md me">#Only storing alphabetic characters<br/>df["alpha"] = df['stopped'].apply(lambda sentence: [words for words in sentence if words.isalpha()])</span><span id="5e2b" class="kh ki hi lx b fi mi mc l md me">#Stemming<br/>df["stem"] = df["alpha"].apply(lambda sentence: [ps.stem(word) for word in sentence])</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/677be6319fbe0eae29453d23697759fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Oxpdc9Y7wV4csQoT76n9w.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">预处理的逐步结果</figcaption></figure><p id="1d45" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在矢量化(将标题转换成矢量格式)之前，我们还需要做两件事。</p><blockquote class="jt ju jv"><p id="5313" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">词干提取后，可能会有一些标题只包含停用词，这样的标题将变得无效，因此我们需要删除它们。</p><p id="53d5" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">移除许多行后，我们需要重置索引，这非常重要。<br/>如果没有这样做，则使用索引值和。iloc返回不同的行。</p></blockquote><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="f2b8" class="kh ki hi lx b fi mb mc l md me">#Dropping the rows which have no value in 'stem' <br/>df = df.dropna(subset=['stem'])</span><span id="8971" class="kh ki hi lx b fi mi mc l md me">#Resetting index<br/>df.reset_index(inplace = True, drop = True)</span></pre><p id="628c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">矢量化:</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="c40e" class="kh ki hi lx b fi mb mc l md me">#Initializing TFIDF<br/>tfidf = TfidfVectorizer()</span><span id="aa89" class="kh ki hi lx b fi mi mc l md me">#Transforming the dataframe into TFIDF<br/>X_t = tfidf.fit_transform(df['stem'])</span></pre><p id="110c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们终于把数据帧转换成了矢量格式。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><blockquote class="jt ju jv"><p id="2298" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">让我们看看计算机是否能理解这篇课文</p></blockquote><h2 id="d433" class="kh ki hi bd kj kk kl km kn ko kp kq kr jg ks kt ku jk kv kw kx jo ky kz la lb bi translated">第三步:寻找相似的文章</h2><p id="7fe1" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg mk ji jj jk ml jm jn jo mm jq jr js hb bi translated">我们将向计算机提供一个新的标题，看看它是否能从数据集中返回类似的文章。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="d47d" class="kh ki hi lx b fi mb mc l md me">#A new headline which is not in the dataset<br/>headline = {'headline': 'Trump elected as the president of the United States again'}</span><span id="e245" class="kh ki hi lx b fi mi mc l md me">#Storing it into the dataframe<br/>new_test = pd.DataFrame(headline,index=[0])</span></pre><p id="de80" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们必须对这个数据帧进行预处理，使其具有相同的格式。</p><blockquote class="jt ju jv"><p id="cecf" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">只有变更处于矢量化阶段。这里我们只变换数据，不拟合。</p></blockquote><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="543b" class="kh ki hi lx b fi mb mc l md me">#Using cosine_similarity to find similar articles<br/>cosine_list = []<br/>cosine_list = list(map(lambda x:                    <br/>cosine_similarity(df_test_vectorized,x)[0][0], X_t))</span><span id="cb99" class="kh ki hi lx b fi mi mc l md me">#Converting list of cosine scores in numpy array<br/>cosine_np = np.array(cosine_list).flatten()</span><span id="f6b8" class="kh ki hi lx b fi mi mc l md me">#Getting the index list after sorting by scores<br/>index_list = np.argsort(cosine_np)</span><span id="3628" class="kh ki hi lx b fi mi mc l md me">#Getting the index of articles with highest similarity <br/>fetched_index = index_list[-2:-7:-1]</span><span id="2079" class="kh ki hi lx b fi mi mc l md me">#Building the dataframe<br/>fetched_dataframe= pd.DataFrame({'Category':df.iloc[fetched_index]['category'].values,<br/>                                'Headline':df.iloc[fetched_index]['headline'].values,<br/>                                'Date':df.iloc[fetched_index]['date'].values})</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/e2987e054d7b5f1041c482b51c8a52f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*LYDnioMM6_kMUQtQRz6f8Q.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">类似文章</figcaption></figure><p id="1958" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到结果是基于内容的，这意味着大多数相似的文章将与查询标题中的单词相同。</p><p id="a075" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了改善结果，我们可以使用gensim Word2Vec模型。这个模型可以用来寻找相似的单词而不是句子。<br/>但是可以建立一个平均的word2vec模型来找到相似的句子。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h2 id="26e0" class="kh ki hi bd kj kk kl km kn ko kp kq kr jg ks kt ku jk kv kw kx jo ky kz la lb bi translated">Word2Vec</h2><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="a0e6" class="kh ki hi lx b fi mb mc l md me">#Initializing the model<br/>model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)</span><span id="1d5c" class="kh ki hi lx b fi mi mc l md me">#Calculating avg word2vec for both dataframe and new article<br/>avgW2V = []<br/>for i in df['headline']:<br/>        word_vec = np.zeros(300,dtype="float32")<br/>        for word in i.split():<br/>            if word in model.vocab:<br/>                word_vec = np.add(word_vec,model[word])<br/>        word_vec = np.divide(word_vec,len(i.split()))<br/>        avgW2V.append(word_vec)</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/07f603c6aa81fc6b48240fbe8cf8d13c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*Q5rhvvnbiA7o6YExWXzS-g.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用Word2Vec的类似文章</figcaption></figure><p id="6e9e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到，我们得到的是多样化的文章，而不是基于内容的相似性。</p><p id="65f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们考虑另一个TF-IDF和Word2Vec模型如何给出不同结果的例子。</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mt"><img src="../Images/28cbe4a53cbed7ad8ed388dcf46ed972.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*YUVv8XX72iuT3DJNXGDWpA.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">余弦相似度</figcaption></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mu"><img src="../Images/4cb4e4cde289a9bdc532f486c8ffa587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*KTg3nIGCRpSFIXQAyBQ58g.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">平均Word2Vec(余弦相似度)</figcaption></figure><p id="7679" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到Word2Vec型号比TF-IDF好多少。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h2 id="a8fd" class="kh ki hi bd kj kk kl km kn ko kp kq kr jg ks kt ku jk kv kw kx jo ky kz la lb bi translated">接下来呢！：</h2><ol class=""><li id="3176" class="lc ld hi ix b iy le jc lf jg lg jk lh jo li js lj lk ll lm bi translated">可以不用TF-IDF，用词袋(BOW)。</li><li id="2b37" class="lc ld hi ix b iy ln jc lo jg lp jk lq jo lr js lj lk ll lm bi translated">还有n元模型等其他模型。</li><li id="0134" class="lc ld hi ix b iy ln jc lo jg lp jk lq jo lr js lj lk ll lm bi translated">还有skip-gram和cbow模型。</li><li id="adba" class="lc ld hi ix b iy ln jc lo jg lp jk lq jo lr js lj lk ll lm bi translated">不同的相似性度量。</li></ol><p id="ef00" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可以尝试这些模型，看看哪一个给出更好的结果。</p></div></div>    
</body>
</html>