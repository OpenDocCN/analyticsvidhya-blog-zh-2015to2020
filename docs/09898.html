<html>
<head>
<title>CUDA — GPU Device Architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CUDA——GPU 设备架构</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cuda-compute-unified-device-architecture-part-3-f52476576d6d?source=collection_archive---------5-----------------------#2020-09-25">https://medium.com/analytics-vidhya/cuda-compute-unified-device-architecture-part-3-f52476576d6d?source=collection_archive---------5-----------------------#2020-09-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/4bf7c08c48c027e31f8e59745f119d94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YOUlwnPheTcz2n8VfbwFRA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">英伟达图灵架构</figcaption></figure><p id="5916" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在这篇文章中，我们将讨论 NVIDIA GPU 的基本架构，以及如何优化并行编程的可用资源。这篇文章是续集的第三部分。之前帖子的链接是<a class="ae js" rel="noopener" href="/analytics-vidhya/cuda-compute-unified-device-architecture-part-1-8f9ff3179440">第一部分</a>和<a class="ae js" rel="noopener" href="/analytics-vidhya/cuda-compute-unified-device-architecture-part-2-f3841c25375e">第二部分</a>。</p><p id="76b8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我用的是英伟达 GeForce GTX 1650 GPU，属于英伟达图灵架构。所以，在这篇文章中分享的大部分细节都属于图灵架构，但是我会试着概括这些概念。</p><p id="b1bf" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">GPU 中的计算核心被分组为一个单元，称为流式多处理器(简称 SM)。在 GTX 1650 中，有 14 个 SMs，每个都有 64 个 CUDA 核心(FP 32 核心)和 64 个 INT 核心。每个 SM 都有自己的 warp 调度程序、调度程序、寄存器、共享内存和 L1 缓存。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jt"><img src="../Images/6c2d719f889059d11f7dde90b83ca7b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*pc2tmoo267C163-ct-LnMw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">流式多处理器</figcaption></figure><p id="c228" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">GPU 的指令架构是<strong class="iw hj">单指令多线程(SIMT) </strong>。线程在一个名为 warp 的集合中执行。Warp 是 GPU 中的基本执行单位。<strong class="iw hj">一般来说，经纱(经纱尺寸)中的纱线数量为 32 根。</strong>即使要处理一个线程，warp 调度程序也会启动 32 个线程的 warp，其中 1 个线程将成为活动线程。因此，我们应该确保 warp 中的所有线程都是活动的，以便更好地利用 GPU 资源。</p><p id="4d63" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">根据经纱的准备情况，它被分为三类:</p><ol class=""><li id="c476" class="jy jz hi iw b ix iy jb jc jf ka jj kb jn kc jr kd ke kf kg bi translated">选定的扭曲-活动执行的扭曲</li><li id="c170" class="jy jz hi iw b ix kh jb ki jf kj jj kk jn kl jr kd ke kf kg bi translated">合格 warp — warp 准备好执行，其所有参数都可用，但正在等待执行</li><li id="4b55" class="jy jz hi iw b ix kh jb ki jf kj jj kk jn kl jr kd ke kf kg bi translated">停滞翘曲-翘曲未准备好执行</li></ol><h1 id="c299" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">分级存储器体系</h1><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/44fe748e359b927d963362818f1327c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*lDCrinjudh1j_ZqzlBVoIw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">Pic 礼貌研究门户</figcaption></figure><p id="1751" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">寄存器</strong> —寄存器为 32 位，一个线程最多可分配 255 个寄存器。每个 SM 总共有 64 kB 的寄存器文件可用。</p><p id="913c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">共享内存</strong> —共享内存分配给线程块，每个 SM 有 64 kB 的共享内存。</p><p id="8a34" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">与全局存储器传输延迟相比，寄存器和共享存储器具有非常小的存储器传输延迟。因此，我们应该充分利用可用的寄存器和共享内存来隐藏延迟。</p><h1 id="4e41" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">潜伏隐藏</h1><p id="572e" class="pw-post-body-paragraph iu iv hi iw b ix ll iz ja jb lm jd je jf ln jh ji jj lo jl jm jn lp jp jq jr hb bi translated">有两种类型的延迟—计算延迟和内存传输延迟。</p><p id="4332" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">计算延迟</strong></p><p id="b7a7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在 Volta 和图灵架构中，核心数学运算需要 4 个时钟周期来执行。因此，我们需要流水线中每个 warp 调度程序有 4 个 warp 来隐藏这个延迟。如果每个 SM 有 4 个 warp 调度程序，那么我们需要 16 个 warp 或 512 个线程(16 x 32)来 100%利用计算核心。</p><p id="14ff" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在 GTX 1650 中，有 14 条短信，因此理论上需要 224 条(14 x 16)经线来隐藏计算延迟。</p><p id="3370" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">内存传输延迟</strong></p><p id="fc68" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们可以假设全局内存传输延迟为 350 个时钟周期。</p><p id="c3c3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们需要知道设备的内存带宽和内存时钟速率，以计算隐藏上述延迟所需的扭曲数。这可以通过在 CLI 中使用以下命令来实现</p><pre class="ju jv jw jx fd lq lr ls lt aw lu bi"><span id="58c8" class="lv kn hi lr b fi lw lx l ly lz">$nvidia-smi -a -q -d CLOCK</span></pre><p id="645a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我的系统 4 GHz GTX 1650 GDDR5 中的 GPU 内存时钟速率具有 128 GB/s 的内存带宽。使用这些值，我们可以获得 32 B/时钟周期。</p><p id="91f6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以在 350 个时钟周期内，可以传输 11200 个字节。考虑到 FP32 (4 字节)和 2 个操作数，我们需要每个 SM(11200/32/2/14/32)4 个变形来隐藏内存传输延迟。</p><h1 id="8e83" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">占有</h1><p id="370b" class="pw-post-body-paragraph iu iv hi iw b ix ll iz ja jb lm jd je jf ln jh ji jj lo jl jm jn lp jp jq jr hb bi translated">占用率是每 SM 的活动经线数与每 SM 允许的最大经线数之间的比率。</p><p id="e544" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果内核受计算或内存限制，那么增加占用率可能会提高性能。我们内核的占用率可以计算如下:</p><p id="f0e2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">用下面的命令计算我们内核的寄存器和共享内存使用量</p><pre class="ju jv jw jx fd lq lr ls lt aw lu bi"><span id="a257" class="lv kn hi lr b fi lw lx l ly lz">$nvcc --ptxas-options=-v -o output.exe cuda_file.cu</span></pre><p id="a443" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">使用从 NVIDIA 的占用率计算器工具中获得的值。该工具基本上是一个内置宏的 excel 文件。该工具可从以下<a class="ae js" href="https://docs.nvidia.com/cuda/cuda-occupancy-calculator/index.html" rel="noopener ugc nofollow" target="_blank">链接</a>下载。</p><p id="95a6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">警告</strong> —如果内核不受计算或内存限制，那么增加占用率不一定会提高性能。有时，添加额外的指令或不同的代码可能会降低性能。</p></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><p id="c920" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在下一部分，我将讨论翘曲发散和几种最小化翘曲发散的方法。我们还将讨论如何使用 NVIDIA NSIGHT Compute 来分析我们的内核，以便对其进行优化。</p></div></div>    
</body>
</html>