# å›å½’ç®—æ³•çš„è¯„ä¼°æŒ‡æ ‡(ä»¥åŠå®ƒä»¬åœ¨ Python ä¸­çš„å®ç°)

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/evaluation-metrics-for-regression-algorithms-along-with-their-implementation-in-python-9ec502729dad?source=collection_archive---------4----------------------->

*æœ¬æ–‡ä¸»è¦å…³æ³¨ç”¨äºè¯„ä¼°å›å½’ç®—æ³•çš„è¯„ä¼°æŒ‡æ ‡åŠå…¶åœ¨ Python ä¸­çš„å®ç°ã€‚åœ¨æœ¬æ–‡ç»“æŸæ—¶ï¼Œæ‚¨å°†ç†Ÿæ‚‰å›å½’ç®—æ³•çš„è¯„ä¼°æŒ‡æ ‡ä»¥åŠå®ƒä»¬åœ¨ python ä¸­çš„å®ç°ã€‚*

![](img/cee96007357be006be98c909976f77c8.png)

æ¨¡å‹çš„è¯„ä¼°æ˜¯å»ºç«‹æœ‰æ•ˆçš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„æœ€é‡è¦çš„éƒ¨åˆ†ã€‚åœ¨è¿›å…¥æ­£é¢˜ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆäº†è§£ä¸€ä¸‹ä»€ä¹ˆæ˜¯å›å½’ç®—æ³•ã€‚

## ä»€ä¹ˆæ˜¯å›å½’ç®—æ³•ï¼Ÿ

å›å½’ç®—æ³•å±äºç›‘ç£æœºå™¨å­¦ä¹ ç®—æ³•ã€‚å›å½’ç®—æ³•åŸºäºè¾“å…¥è¦ç´ é¢„æµ‹è¿ç»­å€¼ã€‚ä¾‹å¦‚:åŸºäºæˆ¿å±‹ç‰¹å¾(å§å®¤æ•°é‡ã€æˆ¿å±‹å¤§å°ã€ä½ç½®ã€æˆ¿é¾„ã€è£…ä¿®å¹´ä»½)çš„æˆ¿ä»·é¢„æµ‹ã€‚

## ä»€ä¹ˆæ˜¯è¯„ä¼°æŒ‡æ ‡ï¼Ÿ

è¯„ä¼°æŒ‡æ ‡ç”¨äºè¡¡é‡æœºå™¨å­¦ä¹ ç®—æ³•çš„è´¨é‡ã€‚ä¸åŒç±»å‹çš„ç®—æ³•æœ‰è®¸å¤šè¯„ä¼°æŒ‡æ ‡ã€‚æˆ‘ä»¬å°†è®¨è®ºå›å½’çš„è¯„ä¼°æ ‡å‡†ã€‚

## æœºå™¨å­¦ä¹ å›å½’ç®—æ³•çš„è¯„ä¼°æ ‡å‡†ï¼›

1.  ç»å¯¹å¹³å‡è¯¯å·®
2.  å‡æ–¹è¯¯å·®
3.  å‡æ–¹æ ¹è¯¯å·®
4.  r åˆ†æ•°
5.  è°ƒæ•´åçš„ R åˆ†æ•°

# å¹³å‡ç»å¯¹è¯¯å·®

**å¹³å‡ç»å¯¹è¯¯å·®**æ˜¯å®é™…å€¼å’Œé¢„æµ‹å€¼çš„ç»å¯¹å·®ä¹‹å’Œçš„å¹³å‡å€¼ã€‚å¹³å‡ç»å¯¹è¯¯å·®å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿã€‚å½“æ‚¨åœ¨è§£å†³å›å½’é—®é¢˜å¹¶ä¸”ä¸å¸Œæœ›å¼‚å¸¸å€¼åœ¨é¢„æµ‹ä¸­æ‰®æ¼”é‡è¦è§’è‰²æ—¶ï¼Œåº”è¯¥ä½¿ç”¨ MAEã€‚å¦‚æœæ‚¨çŸ¥é“æ•°æ®çš„åˆ†å¸ƒæ˜¯[å¤šå³°](https://en.wikipedia.org/wiki/Multimodal_distribution#:~:text=In%20statistics%2C%20a%20Multimodal%20distribution,in%20Figures%201%20and%202.)çš„ï¼Œè¿™å¯èƒ½ä¼šå¾ˆæœ‰ç”¨ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å¹³å‡ç»å¯¹è¯¯å·®çš„å…¬å¼:

![](img/690dbe4240676599a7bc2790aa611370.png)

å¹³å‡ç»å¯¹è¯¯å·®å…¬å¼

è®©æˆ‘ä»¬åˆ†è§£è¿™ä¸ªå…¬å¼:

yáµ¢ =é¢„æµ‹å€¼

yáµ¢å¸½=å®é™…ä»·å€¼

è¿™é‡Œ(yáµ¢ - yáµ¢hat)æ˜¯è¯¯å·®å€¼ï¼Œè¯¯å·®çš„ç»å¯¹å€¼è¢«ç”¨æ¥å»é™¤ä»»ä½•è´Ÿå·ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹ä½¿ç”¨ python å®ç°å¹³å‡ç»å¯¹è¯¯å·®çš„éƒ¨åˆ†ã€‚è®¾ X_trainï¼Œy_train ä¸ºè®­ç»ƒæ•°æ®ï¼ŒX_testï¼Œy_test ä¸ºè¯„ä¼°æˆ‘ä»¬æ¨¡å‹çš„æµ‹è¯•æ•°æ®ã€‚

MAE å€¼è¾ƒå°çš„æ¨¡å‹æ¯” MAE å€¼è¾ƒå¤§çš„æ¨¡å‹æ€§èƒ½æ›´å¥½ã€‚

```
# Importing all necessary libraries
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error# Initializing the model and fitting the model with train data
model = LinearRegression()
model.fit(X_train,y_train)# Generating predictions over test data
predictions = model.predict(X_test)# Evaluating the model using MAE Evaluation Metric
print(mean_absolute_error(y_test, predictions))
```

# å‡æ–¹è¯¯å·®

**å‡æ–¹å·®**æ˜¯å®é™…å€¼å’Œé¢„æµ‹å€¼ä¹‹å·®çš„å¹³æ–¹å’Œçš„å¹³å‡å€¼ã€‚

å½“æ•°æ®é›†åŒ…å«å¼‚å¸¸å€¼æˆ–æ„å¤–å€¼(è¿‡é«˜æˆ–è¿‡ä½çš„å€¼)æ—¶ï¼ŒMSE æœ€æœ‰ç”¨ã€‚å› æ­¤ï¼Œåº”è¯¥è€ƒè™‘åˆ°ï¼Œå¦‚æœæˆ‘ä»¬çš„æ¨¡å‹åšå‡ºä¸€ä¸ªéå¸¸ç³Ÿç³•çš„é¢„æµ‹ï¼ŒMSE ä¼šæ”¾å¤§è¯¯å·®ã€‚

å½“å•ä¸ªé”™è¯¯çš„é¢„æµ‹ä¼šç ´åæ•´ä¸ªæ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›æ—¶ï¼Œå³å½“æ•°æ®é›†åŒ…å«å¤§é‡å™ªå£°æ—¶ï¼ŒMSE æ˜¯æœ€æ²¡æœ‰ç”¨çš„ã€‚

MSE çš„å•ä½æ˜¯å‚ç›´è½´æˆ– y è½´ä¸Šç»˜åˆ¶çš„ä»»ä½•ä¸œè¥¿çš„å¹³æ–¹ã€‚å› ä¸ºå‡½æ•°ä¸­å–äº†è¯¯å·®çš„å¹³æ–¹ã€‚

å¤§çš„ MSE å€¼æ„å‘³ç€æ•°æ®å€¼å¹¿æ³›åˆ†æ•£åœ¨æ•°æ®çš„å¹³å‡å€¼å‘¨å›´ï¼Œè€Œå°çš„ MSE å€¼æ„å‘³ç€æ•°æ®å€¼ç´§å¯†åˆ†æ•£åœ¨å¹³å‡å€¼å‘¨å›´ã€‚å³å…·æœ‰å° MSE å€¼çš„æ¨¡å‹å…·æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å‡æ–¹å·®çš„å…¬å¼:

![](img/4a908272c8bb5700ff1cd541c6f0c5f9.png)

å‡æ–¹è¯¯å·®å…¬å¼

è¯¯å·®çš„å¹³æ–¹(yáµ¢-yáµ¢hat)å¯¹äºæ¶ˆé™¤ä»»ä½•è´Ÿå·æ˜¯å¿…è¦çš„ï¼Œå¹¶ä¸”ä¹Ÿç»™äºˆå¤§çš„å·®å¼‚æ›´å¤šçš„æƒé‡ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹ä½¿ç”¨ python å®ç°å‡æ–¹è¯¯å·®çš„éƒ¨åˆ†ã€‚è®¾ X_trainï¼Œy_train ä¸ºè®­ç»ƒæ•°æ®ï¼ŒX_testï¼Œy_test ä¸ºè¯„ä¼°æˆ‘ä»¬æ¨¡å‹çš„æµ‹è¯•æ•°æ®ã€‚

```
# Importing all necessary libraries
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error# Defining our own MSE function
def own_mean_squared_error(actual, predictions):
    return ((predictions - actual) ** 2).mean()# Initializing the model and fitting the model with train data
model = RandomForestRegressor(
               n_estimators = 100,
               criterion = 'mse'
        )
model.fit(X_train,y_train)# Generating predictions over test data
predictions = model.predict(X_test)# Evaluating the model using MSE Evaluation Metric
print(mean_squared_error(y_test, predictions))
print(own_mean_squared_error(y_test, predictions))
```

# å‡æ–¹æ ¹è¯¯å·®(RMSE)

**å‡æ–¹æ ¹è¯¯å·®**ä¸å‡æ–¹è¯¯å·®ç›¸åŒï¼Œä½†åœ¨è¯„ä¼°æ¨¡å‹æ—¶è€ƒè™‘äº† MSE çš„æ ¹ã€‚RMSE å¯¹è™šå‡æ•°æ®(å³å¼‚å¸¸å€¼)çš„å­˜åœ¨æ›´ä¸ºæ•æ„Ÿã€‚å½“å­˜åœ¨è¾ƒå¤§è¯¯å·®æ—¶ï¼ŒRMSE æœ€æœ‰ç”¨ï¼Œè¿™äº›è¯¯å·®ä¼šæ˜¾è‘—å½±å“æ¨¡å‹æ€§èƒ½ã€‚ä»é‚£ä»¥åï¼ŒRMSE å¯¹è¾ƒå¤§çš„è¯¯å·®èµ‹äºˆè¾ƒé«˜çš„æƒé‡ã€‚

RMSE æ˜¯è¯„ä¼°æ¨¡å‹çš„å¸¸ç”¨è¯„ä¼°æŒ‡æ ‡ã€‚ä¸ MSE ä¸åŒï¼Œå‡æ–¹æ ¹è¯¯å·®åœ¨çºµè½´æˆ– y è½´ä¸Šç»˜åˆ¶äº†ç›¸åŒçš„æ•°é‡å•ä½ã€‚å› ä¸º MSE å€¼çš„å¹³æ–¹æ ¹åœ¨ RMSEã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å‡æ–¹æ ¹è¯¯å·®çš„å…¬å¼:

![](img/fe0d90e6da0357b15fe6d9d2616141e5.png)

å‡æ–¹æ ¹è¯¯å·®å…¬å¼

æ²¡æœ‰å¯ç”¨äºè®¡ç®—å‡æ–¹æ ¹è¯¯å·®çš„å†…ç½®å‡½æ•°ã€‚è®©æˆ‘ä»¬é€šè¿‡å®šä¹‰è‡ªå·±çš„å‡½æ•°æ¥ç ”ç©¶å‡æ–¹æ ¹è¯¯å·®çš„å®ç°éƒ¨åˆ†ã€‚è®¾ X_trainï¼Œy_train ä¸ºè®­ç»ƒæ•°æ®ï¼ŒX_testï¼Œy_test ä¸ºè¯„ä¼°æˆ‘ä»¬æ¨¡å‹çš„æµ‹è¯•æ•°æ®ã€‚

```
# Importing all necessary libraries
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error# Defining RMSE function
def root_mean_squared_error(actual, predictions):
    return np.sqrt(mean_squared_error(actual, predictions))# Initializing the model and fitting the model with train data
model = RandomForestRegressor(
               n_estimators = 100,
               criterion = 'mse'
        )
model.fit(X_train,y_train)# Generating predictions over test data
predictions = model.predict(X_test)# Evaluating the model using RMSE Evaluation Metric
print(root_mean_squared_error(y_test, predictions))
```

**æ³¨:**å¯¹äº sklearn ç‰ˆæœ¬â‰¥ 0.22.0ï¼Œsklearn.metrics æœ‰ä¸€ä¸ªå¹³æ–¹ä¸º kwarg çš„ mean_squared_error å‡½æ•°(é»˜è®¤å€¼ä¸º True)ã€‚å°†å¹³æ–¹å€¼è®¾ç½®ä¸º False å°†è¿”å› RMSE å€¼ã€‚

```
# For sklearn versions >= 0.22.0
print(mean_squared_error(y_test, predictions, squared = False))
```

# r åˆ†æ•°

r å¾—åˆ†ä¹Ÿç§°ä¸ºå†³å®šç³»æ•°ï¼Œç”¨äºè¡¡é‡æ¨¡å‹ä¸ç»™å®šæ•°æ®é›†çš„æ‹Ÿåˆç¨‹åº¦ã€‚å®ƒè¡¨ç¤ºé¢„æµ‹å€¼ä¸å®é™…å€¼çš„æ¥è¿‘ç¨‹åº¦ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªå…¬å¼ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£:

![](img/5e4618164308791b0faffe3891b56031.png)

r å…¬å¼

è®©æˆ‘ä»¬åˆ†è§£è¿™ä¸ªå…¬å¼ï¼Œçœ‹çœ‹æ¯ä¸€é¡¹:

SSáµ£â‚‘â‚› =æ®‹å·®å¹³æ–¹å’Œ

SSâ‚œâ‚’â‚œ =æ€»å¹³æ–¹å’Œ

R å€¼çš„èŒƒå›´ä»-âˆåˆ° 1ã€‚R å€¼ä¸ºè´Ÿçš„æ¨¡å‹è¡¨ç¤ºæœ€ä½³æ‹Ÿåˆçº¿çš„è¡¨ç°æ¯”å¹³å‡æ‹Ÿåˆçº¿å·®ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹ R è¯„ä¼°æŒ‡æ ‡çš„å®ç°:

```
# Importing all necessary libraries
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score# Initializing the model and fitting the model with train data
model = LinearRegression()
model.fit(X_train,y_train)# Generating predictions over test data
predictions = model.predict(X_test)# Evaluating the model using RÂ² Evaluation Metric
print(r2_score(y_test, predictions))
```

*R æŒ‡æ ‡çš„ä¸»è¦ç¼ºç‚¹æ˜¯ï¼Œéšç€æ¨¡å‹è¾“å…¥ç‰¹å¾æ•°é‡çš„å¢åŠ ï¼ŒR å€¼ä¹Ÿä¼šå¢åŠ ï¼Œè€Œä¸å¢åŠ çš„ç‰¹å¾ç›¸å¯¹äºè¾“å‡ºå˜é‡çš„é‡è¦æ€§æ— å…³ã€‚å³ï¼Œå³ä½¿æ·»åŠ çš„ç‰¹å¾ä¸è¾“å‡ºå˜é‡æ²¡æœ‰ç›¸å…³æ€§ï¼ŒR å€¼ä¹Ÿä¼šå¢åŠ ã€‚*

# è°ƒæ•´åçš„ R åˆ†æ•°

è°ƒæ•´åçš„ R æ˜¯ R çš„ä¿®æ”¹å½¢å¼ï¼Œå…¶æƒ©ç½šæ–°çš„ç‹¬ç«‹å˜é‡æˆ–é¢„æµ‹å€¼çš„å¢åŠ ï¼Œå¹¶ä¸”ä»…åœ¨æ–°çš„ç‹¬ç«‹å˜é‡æˆ–é¢„æµ‹å€¼å¢å¼ºæ¨¡å‹æ€§èƒ½æ—¶å¢åŠ ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹è°ƒæ•´åçš„ R çš„å…¬å¼:

![](img/9e25f1114433be6c851205ed1aed71e5.png)

è°ƒæ•´åçš„ R å…¬å¼

è®©æˆ‘ä»¬åˆ†è§£è¿™ä¸ªå…¬å¼ï¼Œçœ‹çœ‹å®ƒçš„æ¯ä¸€é¡¹:

R:è¿™æ˜¯ R åˆ†æ•°

n:æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡

k:é¢„æµ‹å€¼çš„æ•°é‡

æ²¡æœ‰ä»…è®¡ç®—è°ƒæ•´å R çš„å†…ç½®å‡½æ•°ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹è°ƒæ•´å R çš„å®ç°éƒ¨åˆ†:

```
# Importing all necessary libraries
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score# Defining the adjusted RÂ² function
def adjusted_r2_score(actual, predictions, num_pred, num_samples):
    n = num_samples
    k = num_pred
    r2 = r2_score(actual, predictions)
    adjusted_r2 = 1 - ((1-r2) * ((n-1)/(n-k-1)))
    return adjusted_r2# Initializing the model and fitting the model with train data
model = LinearRegression()
model.fit(X_train,y_train)# Generating predictions over test data
predictions = model.predict(X_test)# Evaluating the model using Adjusted RÂ² Evaluation Metric
num_samples = X_test.shape[0]
num_predictors = X_test.shape[1]
adjusted_r2_score(y_test, predictions, num_predictors, num_samples)
```

**æ³¨:**è°ƒæ•´åçš„ R å°†å§‹ç»ˆå°äºæˆ–ç­‰äº R å¾—åˆ†ã€‚

ä¸Šè¿°è¯„ä¼°æŒ‡æ ‡æ˜¯è¯„ä¼°å›å½’ç®—æ³•æœ€å¸¸ç”¨çš„ 5 ç§è¯„ä¼°æŒ‡æ ‡ã€‚

> å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè¯·è·Ÿæˆ‘æ¥ã€‚å¦‚æœæ‚¨å‘ç°å…¬å¼ã€ä»£ç æˆ–å†…å®¹ä¸­æœ‰ä»»ä½•é”™è¯¯ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚
> 
> ä½ å¯ä»¥åœ¨ [LinkedIn](https://www.linkedin.com/in/venugopalkadamba) ã€ [GitHub](https://github.com/venugopalkadamba) æ‰¾åˆ°æˆ‘

[](https://github.com/venugopalkadamba) [## éŸ¦åŠªÂ·æˆˆå¸•å°”Â·å¡ä¸¹å·´

### å­¦ç”ŸğŸ‘¨â€ğŸ“å’Œ Python ç¨‹åºå‘˜ã€‚venugopalkadamba æœ‰ 22 ä¸ªå¯ç”¨çš„å­˜å‚¨åº“ã€‚åœ¨ GitHub ä¸Šå…³æ³¨ä»–ä»¬çš„ä»£ç ã€‚

github.com](https://github.com/venugopalkadamba) [](https://www.linkedin.com/in/venugopalkadamba) [## éŸ¦åŠªÂ·æˆˆå¸•å°”Â·å¡ä¸¹å·´

### åœ¨ä¸–ç•Œä¸Šæœ€å¤§çš„èŒä¸šç¤¾åŒº LinkedIn ä¸ŠæŸ¥çœ‹ Venu Gopal Kadamba çš„ä¸ªäººèµ„æ–™ã€‚

www.linkedin.com](https://www.linkedin.com/in/venugopalkadamba) 

# è°¢è°¢å¤§å®¶ï¼