<html>
<head>
<title>Galaxy images classification — Convolutional Neural Network (CNN) explained with codes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">星系图像分类——卷积神经网络(CNN)的代码解释</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/multiclass-image-classification-problem-convolutional-neural-network-trains-on-galaxy-images-6ca6aa74e5d7?source=collection_archive---------5-----------------------#2020-11-21">https://medium.com/analytics-vidhya/multiclass-image-classification-problem-convolutional-neural-network-trains-on-galaxy-images-6ca6aa74e5d7?source=collection_archive---------5-----------------------#2020-11-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1eb20baa34ccc199c6b319d54e52b869.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rSH01Ti3RDFcQ7SJNLg2sQ.jpeg"/></div></div></figure><p id="93af" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一个多类图像分类问题，使用带有TensorFlow (Keras api)的卷积神经网络在Galaxy10数据集上进行训练。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jo"><img src="../Images/b36e0e2ac1c213bff8399c2c0ade204f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Cw4vn1T5FkCi4nTR.png"/></div></div></figure><p id="0403" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先让我们下载数据集。在本教程中，我在Google Colab中运行代码。</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="aae3" class="jy jz hi ju b fi ka kb l kc kd">!pip install astroNN</span></pre><p id="9e1e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们导入库。</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="5d51" class="jy jz hi ju b fi ka kb l kc kd">from astroNN.datasets import galaxy10<br/>from astroNN.datasets.galaxy10 import galaxy10cls_lookup</span><span id="5ae0" class="jy jz hi ju b fi ke kb l kc kd">import keras<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten<br/>from keras.layers import Conv2D, MaxPooling2D<br/>from keras.utils import to_categorical<br/>from keras.preprocessing import image</span><span id="42af" class="jy jz hi ju b fi ke kb l kc kd">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/>from sklearn.model_selection import train_test_split<br/>from tqdm import tqdm</span></pre><p id="a255" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们可以加载数据并对它们进行预处理。每个图像都有一个从0到9的相应标签。为了使后面的计算更有效，我们可以用<code class="du kf kg kh ju b">to_categorical()</code>函数对每个标签进行一次热编码。此外，我们将图像值归一化到0和1之间，这是加快计算时间的一个好方法。</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="5fe0" class="jy jz hi ju b fi ka kb l kc kd">images, labels = galaxy10.load_data()</span><span id="7634" class="jy jz hi ju b fi ke kb l kc kd">labels = labels.astype(np.float32)<br/>labels = to_categorical(labels)<br/>images = images.astype(np.float32)<br/>images = images/255</span></pre><p id="26c4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们可以从培训中看到一些带有相应标签的图片。</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="5383" class="jy jz hi ju b fi ka kb l kc kd">def show_image(image_data,label):<br/>    label = galaxy10cls_lookup(int(label))<br/>    plt.imshow(image_data)<br/>    plt.title(label)<br/>    plt.show()</span><span id="82b4" class="jy jz hi ju b fi ke kb l kc kd">for i in range(3):<br/>    show_image(images[i], i)</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ki"><img src="../Images/aaefe1981e20325e50095b1d0e34aba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*ha6lD2OiVTP4yghdfEWj3w.png"/></div></div></figure><p id="2a92" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来我们用<code class="du kf kg kh ju b">train_test_split()</code>函数从<em class="kj"> sklearn </em>中分离出训练集和测试集。</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="e3cf" class="jy jz hi ju b fi ka kb l kc kd">X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.15)</span><span id="8608" class="jy jz hi ju b fi ke kb l kc kd">print(X_train.shape)<br/>print(y_train.shape)</span></pre><p id="bdaa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">(18517，69，69，3) <br/> (18517，10)</p><p id="4a45" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们也知道了训练集的形状。有18517个69×69像素的图像，具有3个(RGB)通道。测试集的形状应该与训练集的形状相同。</p><h1 id="b467" class="kk jz hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">CNN模型</h1><p id="6568" class="pw-post-body-paragraph iq ir hi is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">第一层是具有32个输出节点的卷积层。我们还应用了一个3x 3滤波器和一个校正的线性单元激活函数。请注意，MaxPooling层和Dropout层有助于防止网络过度拟合。</p><p id="9f4e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，我们将输出数据展平为1D的形状，以便在最后的密集层中，模型可以在0和9之间进行选择，以确定图像应该属于哪个标签。</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="d8c7" class="jy jz hi ju b fi ka kb l kc kd">model = Sequential()</span><span id="e0a8" class="jy jz hi ju b fi ke kb l kc kd">model.add(Conv2D(32, kernel_size=(3,3),activation='relu',<br/>input_shape=(69,69,3)))</span><span id="ff42" class="jy jz hi ju b fi ke kb l kc kd">model.add(Conv2D(64, (3, 3), activation='relu'))</span><span id="a21e" class="jy jz hi ju b fi ke kb l kc kd">model.add(MaxPooling2D(pool_size=(2, 2)))</span><span id="de17" class="jy jz hi ju b fi ke kb l kc kd">model.add(Dropout(0.25))</span><span id="3f0a" class="jy jz hi ju b fi ke kb l kc kd">model.add(Flatten())</span><span id="d195" class="jy jz hi ju b fi ke kb l kc kd">model.add(Dense(128, activation='relu'))</span><span id="4e15" class="jy jz hi ju b fi ke kb l kc kd">model.add(Dropout(0.5))</span><span id="6bbd" class="jy jz hi ju b fi ke kb l kc kd">model.add(Dense(10, activation='softmax'))</span><span id="4d45" class="jy jz hi ju b fi ke kb l kc kd">model.summary()</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/066678c40b9a745ba535c049ed3bd7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_EdSmzhc8e6QNYLeUllVaQ.png"/></div></div></figure><h2 id="63f8" class="jy jz hi bd kl ln lo lp kp lq lr ls kt jb lt lu kx jf lv lw lb jj lx ly lf lz bi translated">编译和训练模型</h2><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="ba3c" class="jy jz hi ju b fi ka kb l kc kd">model.compile(<br/>loss='categorical_crossentropy',<br/>optimizer='Adam',<br/>metrics=['accuracy'])</span><span id="0fe9" class="jy jz hi ju b fi ke kb l kc kd">model.fit(X_train, y_train, epochs=20, <br/>validation_data=(X_test, y_test))</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/19e4b2a4bcef8be2e3bce49c959d5deb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WbrZCgpjP6ILfUImBdepMg.png"/></div></div></figure><h1 id="0866" class="kk jz hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">结果</h1><h2 id="466a" class="jy jz hi bd kl ln lo lp kp lq lr ls kt jb lt lu kx jf lv lw lb jj lx ly lf lz bi translated">培训和验证损失</h2><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="0666" class="jy jz hi ju b fi ka kb l kc kd">plt.plot(model.history.history['loss'],color='b',<br/>label='Training Loss')</span><span id="a77c" class="jy jz hi ju b fi ke kb l kc kd">plt.plot(model.history.history['val_loss'],color='r',<br/>label='Validation Loss')</span><span id="0c06" class="jy jz hi ju b fi ke kb l kc kd">plt.legend()<br/>plt.show()</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/23102568c6cb639c8042c322feac48f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*wGcBR9hG-Ijas_YUA061WQ.png"/></div></figure><h2 id="bd71" class="jy jz hi bd kl ln lo lp kp lq lr ls kt jb lt lu kx jf lv lw lb jj lx ly lf lz bi translated">培训和测试准确性</h2><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="cd44" class="jy jz hi ju b fi ka kb l kc kd">plt.plot(model.history.history['accuracy'],color='b',<br/>label='Training  Accuracy')</span><span id="e274" class="jy jz hi ju b fi ke kb l kc kd">plt.plot(model.history.history['val_accuracy'],color='r',<br/>label='Validation Accuracy')</span><span id="330d" class="jy jz hi ju b fi ke kb l kc kd">plt.legend()<br/>plt.show()</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/4ba065a7440cd2d8c470833fa24dbd9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*nNH92RXQqWCF5jJ5cXu3sQ.png"/></div></figure><h1 id="0f71" class="kk jz hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">结论</h1><p id="a55d" class="pw-post-body-paragraph iq ir hi is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">从精度图中，我们可以看到模型可能过拟合，因为训练精度保持线性上升，而验证精度在早期阶段处于平稳状态。然而，该模型在对图像进行分类时仍有近75 %的准确率，这远远高于随机猜测的结果(10%)。</p></div></div>    
</body>
</html>