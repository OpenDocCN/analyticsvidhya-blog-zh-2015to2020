<html>
<head>
<title>One Stop Solution for Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归的一站式解决方案</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/one-stop-solution-for-logistic-regression-c876cf26d37f?source=collection_archive---------12-----------------------#2020-01-28">https://medium.com/analytics-vidhya/one-stop-solution-for-logistic-regression-c876cf26d37f?source=collection_archive---------12-----------------------#2020-01-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/2911efdbd5a6b2dfaa7e747779dffc57.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*lz6GkXR4VwNMAC6O7in54A.png"/></div></figure><h1 id="7068" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">介绍</h1><p id="b6c9" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">让我首先给出一个逻辑回归在机器学习大图景中的位置。</p><p id="e2b8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">几个世纪以来，我们一直将分析作为一种强大的工具，用于分析和确定我们感兴趣的特定变量与业务中其他变量之间的强度和关系。在过去的几年里，分析学在识别语音和图像方面也取得了长足的发展。强大的软件和高等数学为这一发展铺平了道路。</p><p id="7a14" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">强大的分析框架包括三个不同的步骤:</p><p id="9278" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">I. <strong class="jm hj">描述性分析</strong> -聚集和总结数据以获得有意义的见解。</p><p id="315f" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">二。<strong class="jm hj">预测分析</strong> —使用统计模型和预测技术来预测未来。<strong class="jm hj">机器学习</strong>是一种预测分析方法，它使用各种算法来训练计算机预测未来。</p><p id="a39b" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">三。<strong class="jm hj">说明性分析</strong> -使用描述性和预测性方法强调可操作的结果或来自数据的洞察力。</p><p id="e58a" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">机器学习问题分为以下4类:</p><p id="13b5" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">1.<strong class="jm hj">监督学习</strong> —在这种情况下，要预测的变量是已知的或在数据中被标注。诸如线性回归和逻辑回归传统方法是监督学习算法。</p><p id="4725" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">2.<strong class="jm hj">无监督学习</strong>——这里，要预测的变量是未知的，或者我们手边没有带标签的数据。这些大多是聚类或降维的情况，其中数据根据数据中的变量或特征被分组到有意义的聚类中。像K-means、层次聚类、奇异值分解(SVD)等方法。</p><p id="015c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">3.<strong class="jm hj">半监督学习</strong> —在这种情况下，我们同时拥有标记数据和未标记数据，用于预测算法的算法利用了标记数据和未标记数据中包含的信息。图协议方法是一种流行的半监督算法。</p><p id="438f" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj"> 4。</strong> <strong class="jm hj">强化学习— </strong>反复强调从环境中学习的理念，将情境映射到行动中，以实现回报最大化。这些都是在博弈论，控制理论等研究，并使用马尔可夫决策过程建模。</p><h1 id="2ad0" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">什么是逻辑回归？</h1><p id="31f1" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">监督机器学习问题分为回归和分类两类。</p><p id="5801" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">回归</strong>:用于模拟连续结果，如股票价格</p><p id="2930" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">分类</strong>:用于对分类结果建模，如贷款违约预测</p><p id="b402" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">逻辑回归是一种监督机器学习算法，用于二元分类问题(仅2类)。典型的分类问题是我们希望将数据分类到所需类别的场景。这种传统的算法以其解释能力而闻名，并在银行中广泛用于贷款违约或非违约的分类。</p><h1 id="02b0" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">如何解决logistic回归问题？</h1><p id="dfbb" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">让我们考虑一个包含x1，x2，x3…的数据集。xn，y特征或变量，其中y是需要建模的带标签的二进制变量0或1。这是可能的，通过找出一个简单的连续函数，其余域是(0，1)。如果模型为输入xi返回的值更接近于0，那么我们给xi分配一个负标签；否则，该示例被标记为阳性。两个这样的连续函数是Logit和Probit函数。</p><p id="e58e" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在Logit模型中，累积分布函数是由f(x'β)给出的逻辑分布，如下所示，预测概率限制在0和1之间。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/1f5517a1bc3d24eff9e834a6e0001e0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*Tp2-ajDnhuJ1TpxM-IHGQw.png"/></div></figure><p id="8dbf" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">其中x’β=β1x1+β2 x2+…+βnXn</p><p id="7d4d" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在概率单位模型中，累积分布函数是由f(x'β)给出的标准正态分布，预测概率被限制在0和1之间。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/20723f555f6d5f9d178d2577802ff75e.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*JkA9M1hcqv9s6ZvfMKBnaQ.png"/></div></figure><p id="ea41" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">其中x’β=β1x1+β2 x2+…+βnXn</p><p id="3e78" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">经验结果表明，这两个模型产生相同的结果，尽管不同的系数和因此模型的选择取决于用户。Logit模型是应用最广泛的模型。</p><p id="6f40" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">logit模型的优势比/相对风险</strong></p><p id="f985" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">使用logit模型的一个有趣的事实是，使用奇数比率可以很容易地解释结果。优势比或相对风险定义为p/(1-p)，其中p是结果的概率。它是y=1的概率相对于y=0的概率的比值。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es kt"><img src="../Images/d037ab77fbe190279206bc675a2c950d.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*-kh80kDx9jp2DYFN9CgM6Q.png"/></div></figure><p id="6865" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">其中x'β = β1x1+β2x2+…+βnXn。</p><p id="85c3" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在，如果我们分析上述等式的RHS，就比值比而言的logit模型可以被视为线性回归模型。因此命名为逻辑回归而不是逻辑分类。</p><p id="738c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">优势比为2意味着结果y=1的可能性是结果y=0的两倍。</p><p id="f07b" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在为了求解logit模型，我们需要估计β。</p><h1 id="26d5" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">参数估计</h1><p id="8efd" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">参数估计是来自估计理论的一种方法，估计理论是统计学的一个分支，它利用潜在的概率分布来估计经验数据的参数。常用的估算方法有</p><p id="fdfe" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">最大似然估计量</p><p id="3058" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">贝叶斯估计量</p><p id="e2f8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">矩估计方法</p><p id="78ca" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">最小平方</p><p id="e47f" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">最小均方误差(MMSE)，也称为贝叶斯最小平方误差(BLSE)</p><p id="a4d6" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">当存在潜在的参数分布时，最大似然估计(MLE)是最优选的估计量，因此MLE用于逻辑回归。</p><p id="1f05" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">离散分布的似然函数定义为</strong></p><p id="1776" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">设X为离散随机变量，概率质量函数P取决于参数θ，似然函数L(θ|x)定义为</p><p id="241d" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">L(θ|x) = P(x|θ)</p><p id="fcff" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">连续分布的似然函数定义为</strong></p><p id="8302" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">设X是一个随机变量，其概率密度函数f取决于参数θ，似然函数L(θ|x)定义为</p><p id="61d9" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">L(θ|x) = f(x|θ)</p><p id="6dd5" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">参数空间中使似然函数最大的点称为最大似然估计。</p><p id="6f3a" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">概率给出观察结果的机会，而可能性确定对概率结果的信任。因此，似然性度量模型的拟合优度。</p><p id="74a8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">因为观察N个样本的N个标签的可能性是每个观察的可能性的乘积，所以最大可能性函数可以表示为:</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ku"><img src="../Images/81aae17ab79653e152f7eae7e0ffd5d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Z0IVoiFO7MkQ9f5aVLIAhA.png"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es kv"><img src="../Images/ca2ffe906af03ea55752f746006a59a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*ImE9RfaBcjhfPWJpFAsAVw.png"/></div></figure><p id="193c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们要求解的最终方程是一个非线性方程，因此只能用数值方法求解。</p><p id="19a4" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">牛顿-拉夫逊、拟牛顿等基于梯度下降的方法被认为是数值方法。逻辑回归使用牛顿-拉夫森方法。(点击了解更多关于优化<a class="ae kw" rel="noopener" href="/analytics-vidhya/optimizations-an-essential-mathematical-toolkit-b36e77b0e03a">的信息)</a></p><p id="21b3" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在这里应用了牛顿-拉夫森方法之后，我们得到了β的估计。</p><p id="566b" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">如何解释β，也称为系数？</p><p id="4985" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">系数解释为</p><p id="d464" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">根据系数的符号，x的增加会增加或减少y=1的可能性。</p><p id="7d27" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们解释系数的符号，但不解释大小。不能使用系数来解释大小，因为不同的模型具有不同的系数标度。</p><h1 id="779e" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">逻辑回归模型的拟合优度</h1><p id="96eb" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">以下是适用于逻辑回归模型的拟合优度测试:</p><p id="5555" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">卡方拟合优度和偏差</p><p id="18a3" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">霍斯默-莱梅休试验</p><p id="e5f3" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">伪R广场或麦克法登的R广场</p><p id="9b40" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">准确度分数。</p><p id="9373" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj"> <em class="kx">卡方拟合优度与偏差</em> </strong></p><p id="1d97" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在卡方拟合优度中，我们检验样本是否来自所声明分布的总体。测试统计由下式给出</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/dffa68662afb4fa8e191f4413044dbd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*QQ_GkOFzv3SkZAzXQvtCtw.png"/></div></figure><p id="adbb" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">如果这些加权平方偏差的总和很小，则观察到的频率接近预期的频率，因此没有理由拒绝它来自该分布的说法。只有当总和很大时，才是质疑分配的理由。所以卡方拟合优度检验永远是右尾检验。</p><p id="404b" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">当满足以下假设时，检验统计量具有卡方分布:</p><p id="be7c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">数据是从随机样本中获得的，并且数据是正态分布的。</p><p id="4f28" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">每个类别的预期频率必须至少为5。</p><p id="b3a2" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">以下是拟合优度测试的属性:</p><p id="6ab1" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">数据是观察到的频率。这意味着每个类别只有一个数据值。</p><p id="450f" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">自由度比类别数少一个，而不是比样本量少一个。</p><p id="d155" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">自由度= n-1</p><p id="df09" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">这总是一个右尾测试。</p><p id="cbb7" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">它具有卡方分布。</p><p id="2a3f" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">如果类别的顺序被改变，测试统计的值不会改变。</p><p id="f6f2" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">如果获得的p值大于显著性水平α，那么我们不能拒绝零假设</p><p id="9ad2" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">H0:样本来自同一人群。</p><p id="9c4f" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj"> <em class="kx">霍斯默-勒梅肖试验</em> </strong></p><p id="d756" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">该测试仅用于二进制响应变量。数据首先通过对预测概率进行排序并形成g个相等的子组来重新分组。</p><p id="2b17" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">Hosmer-Lemeshow检验统计量通过以下公式计算:</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es kz"><img src="../Images/cf16202d260a45a13e42ede82cdd46a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*HdV0_TsT80FSQ9vHTFIMKw.png"/></div></figure><p id="0759" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">其中g =组的数量。使用的检验是具有g-2自由度的卡方检验。输出返回一个卡方值(Hosmer-Lemeshow卡方)和一个p值(例如Pr &gt; ChiSq)。较小的p值意味着模型不适合。</p><p id="f605" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">像大多数拟合优度测试一样，这些小的p值(通常低于5%)意味着你的模型不是一个很好的拟合。但是大的p值并不一定意味着你的模型不适合，只是没有足够的证据表明它适合。许多情况会导致较大的p值，包括较差的测试能力。注意:低功耗只是这项测试备受批评的原因之一。</p><p id="444f" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj"> <em class="kx">麦克法登的伪R平方</em> </strong></p><p id="6bda" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">麦克法登的R平方测度定义为</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es la"><img src="../Images/7941e42388f8600de5bfc74649eecd44.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/1*c-AFkVuIum99f38TkPdQRQ.png"/></div></figure><p id="3541" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">其中，Lc表示当前拟合模型的(最大化)似然值，Lnull表示对应的值，但用于零模型，即只有截距且没有协变量的模型。</p><p id="13e0" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">如果模型没有预测能力，尽管当前模型的似然值将(总是)大于零模型的似然值，但也不会大很多。因此，两个对数似然的比率将接近于1，并且R平方麦克法登将接近于零。</p><p id="2a0f" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">逻辑回归模型的目的是预测每个受试者的P(Y=1)，对于Y=1的受试者，我们需要P(Y=1) ~ 1，对于Y=0的受试者，我们需要P(Y=1) ~ 0。如果是这样的话，P(Y=1) ~ 1时看到Y=1的概率几乎是1，同理P(Y=1) ~ 0时看到Y=0的概率也几乎是1。这意味着每次观察的似然值接近1。1的对数是0，因此对数似然值log (Lc)将接近0。那么麦克法登的平方将接近于1。</p><p id="e35d" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj"> <em class="kx"> Somer的D或准确度分数</em> </strong></p><p id="d932" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">Somer's D或Somer's Delta定义如下:</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lb"><img src="../Images/36b2388c6f517022b37d932072b0b4be.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*4hQh5_JbGJdMIXijzcZ5Lw.png"/></div></figure><p id="9148" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在哪里，</p><p id="b3c2" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">nc =一致对的数量</p><p id="7199" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">nd =不一致对的数量</p><p id="8df2" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">p=n(n-1)/2</p><p id="3398" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">如果预测得分的等级顺序与观察得分的等级顺序匹配，则一对预测得分是一致的，否则是不一致的。</p><p id="8554" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">Somer的D值范围从1到-1，接近1的值描述了最理想的模型。</p><p id="87b7" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj"> <em class="kx">感谢维基百科和加州大学洛杉矶分校统计</em> </strong></p></div></div>    
</body>
</html>