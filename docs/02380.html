<html>
<head>
<title>Taming the Hyper-Parameters of Mask RCNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">驯服掩模RCNN的超参数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/taming-the-hyper-parameters-of-mask-rcnn-3742cb3f0e1b?source=collection_archive---------3-----------------------#2019-12-14">https://medium.com/analytics-vidhya/taming-the-hyper-parameters-of-mask-rcnn-3742cb3f0e1b?source=collection_archive---------3-----------------------#2019-12-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b81b15d84bc8f6cb96709955afa39f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WknVs0K6AB2ZDnNvG4akBQ.jpeg"/></div></div></figure><p id="525e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本文简要介绍了Mask R-CNN的发展，并解释了所使用的不同超参数。它还强调了不同的技术，这将有助于调整口罩R-CNN模型的超参数。</p><p id="ff3b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本文描述了Anisha Alluru、Elizabeth Reid Heath、Manas Rai、Ravikiran Bobba、Vishal Ramachandran建造的项目的经验。跟随这个<a class="ae jo" href="https://github.com/RavikiranBobba/iMat-Fashion" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>获取我们关于实现Mask RCNN的完整代码，用于2019 的【this唯物主义时尚挑战赛的实例分割。</p><p id="93aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">简介:</p><p id="691f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">mask-RCNN是基于区域的CNN家族的最新成员之一，由人工智能研究中心(FAIR)的何和团队于2018年1月推出。这里有一个<a class="ae jo" href="https://arxiv.org/pdf/1703.06870.pdf" rel="noopener ugc nofollow" target="_blank">链接</a>到该团队发表的官方论文。Mask R-CNN在Coco分割挑战赛中具有最高的准确性，并在推出后被广泛用于不同的实例分割比赛。掩模R-CNN是更快的R-CNN的扩展，它为检测到的每个对象创建像素级别的掩模。这在工业中有多种应用，用于计数不同的物体，为使用机器人操纵器的操作精确地评估物体的位置等等。mask-RCNN由Matterport为不同的项目实现，并在其Github库中使用R-CNN开源了他们的大量工作。除了这种增强的性能之外，Mask R-CNN还涉及几个超参数，这些参数需要根据应用进行仔细调整。由于最近才出现，关于这些超参数的文献非常有限，本文旨在概述掩模RCNN中涉及的特殊超参数。</p><p id="3b98" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">掩模R-CNN的发展；</p><p id="c185" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Mask R-CNN是一种应用于快速RCNN的元算法，用于实例分割。本文<a class="ae jo" href="https://towardsdatascience.com/computer-vision-a-journey-from-cnn-to-mask-r-cnn-and-yolo-1d141eba6e04" rel="noopener" target="_blank">“计算机视觉——从CNN到Mask R-CNN和YOLO之旅——部分”</a>详细解释了Mask RCNN的发展历程。对这一演变的概述对于理解超参数非常重要，因为它们是基于这些架构的。下面是这一发展的简要概述。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jp"><img src="../Images/d0b9085eb89aa0b6fdf5cee21867a3d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QxXznu9K16gYkuVc"/></div></div></figure><p id="4320" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">掩模R-CNN的发展综述</p><p id="d4e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">屏蔽R-CNN架构:</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ju"><img src="../Images/137f6d42ca24eba1eccb9f30b7b33605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*b3r9VICugOhuADTO"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">屏蔽R-CNN架构</figcaption></figure><p id="5da9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面的框图代表了Mask R-CNN架构。每个步骤的简要描述如下:</p><ol class=""><li id="38e5" class="jz ka hi is b it iu ix iy jb kb jf kc jj kd jn ke kf kg kh bi translated">图像通过卷积网络。</li><li id="cfd6" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn ke kf kg kh bi translated">第一conv网络的输出被传递到区域提议网络(RPN ),该网络基于要检测的任何对象的存在来创建不同的阿克尔盒(感兴趣区域)。</li><li id="dc08" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn ke kf kg kh bi translated">锚定框被发送到ROI对准阶段(用于保护空间方向的掩模RCNN的关键特征之一)，该阶段将ROI转换为进一步处理所需的相同尺寸</li><li id="62ac" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn ke kf kg kh bi translated">该输出被发送到完全连接的层，该层将生成该特定区域中的对象的类的结果以及该对象的边界框的位置</li><li id="2641" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn ke kf kg kh bi translated">ROI对准级的输出被并行发送到Conv网，以便生成对象像素的掩模</li></ol><p id="f69c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有关屏蔽R-CNN步骤的详细说明，请参考本文。</p><p id="589e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">超参数:</p><p id="918d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是屏蔽R-CNN特有的几个超参数</p><ul class=""><li id="a936" class="jz ka hi is b it iu ix iy jb kb jf kc jj kd jn kn kf kg kh bi translated">脊柱</li><li id="d0f5" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">火车_ ROIs _ Per _ Image</li><li id="fbf6" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">最大实例数</li><li id="e9d7" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">检测_最小_置信度</li><li id="7224" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">图像最小尺寸和图像最大尺寸</li><li id="ef5a" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">损失权重:rpn_class_loss</li><li id="11ef" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">损失权重:rpn_bbox_loss</li><li id="8930" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">损失权重:mrcnn_class_loss</li><li id="11e3" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">损失权重:mrcnn_bbox_loss</li><li id="889d" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">损失权重:mrcnn_mask_loss</li></ul><p id="4dd3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">背骨:</p><p id="7bc3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">主干是将在屏蔽R-CNN的第一步中使用的Conv网络架构。主干网的可用选项包括ResNet50、ResNet101和ResNext 101。这种选择应该基于训练时间和准确性之间的权衡。ResNet50将花费相对较少的时间比后来的，并有几个开源的预先训练的权重为庞大的数据集，如可可，这可以大大减少不同的实例分割项目的训练时间。ResNet 101和ResNext 101将花费更多的时间进行训练(由于层数的原因)，但是如果不涉及预先训练的权重并且诸如学习速率和时期数之类的基本参数被很好地调整，则它们往往更准确。</p><p id="f4f8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">理想的方法是从预先训练好的权重开始，如带有ResNet 50的coco，并评估模型的性能。这将在涉及在coco数据集中训练的真实世界对象的检测的模型上更快更好地工作。如果精度至关重要，并且有高计算能力，则可以考虑ResNet101和ResNeXt 101选项。</p><p id="8c53" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">火车_ ROIs _ Per _ Image</p><p id="f0df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是区域建议网络将为图像生成的ROI的最大数量，将在下一阶段对其进行进一步处理以进行分类和屏蔽。如果映像中的实例数量未知，理想的方法是从默认值开始。如果实例数有限，可以减少实例数以减少训练时间。</p><p id="77f1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最大实例数:</p><p id="84eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一幅图像中可以检测到的最大实例数。如果映像中的实例数量有限，可以将其设置为映像中可以出现的最大实例数量。这有助于减少误报并减少训练时间。</p><p id="f35c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">检测_最小_置信度:</p><p id="34f5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是置信水平阈值，超过该阈值将对实例进行分类。初始化可以是缺省的，并根据在模型中检测到的实例数量而减少或增加。如果检测一切都很重要，并且误报是可以的，那么降低阈值以识别每个可能的实例。如果检测的准确性很重要，则通过保证模型只预测可信度非常高的实例，来增加阈值以确保假阳性最小。</p><p id="2827" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图像最小尺寸和图像最大尺寸:</p><p id="80ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图像大小由这些设置控制。默认设置将图像调整为1024x1024大小的正方形。可以使用较小的图像(512x512 ),以减少内存需求和训练时间。理想的方法是在较小的图像尺寸上训练所有的初始模型，以便更快地更新权重，并且在最终阶段使用较大的尺寸来微调最终的模型参数。</p><p id="704f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">损失权重:</p><p id="4316" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">掩模RCNN使用复杂的损失函数，其被计算为在模型的每个状态下不同损失的加权和。减重超参数对应于模型应该分配给其每个阶段的重量。</p><ul class=""><li id="c4e0" class="jz ka hi is b it iu ix iy jb kb jf kc jj kd jn kn kf kg kh bi translated">Rpn_class_loss:这对应于由区域提议网络分配给锚箱的不正确分类(任何对象的存在/不存在)的损失。当模型在最终输出中没有检测到多个对象时，该值应该增加。增加这一点可确保区域提案网络能够捕捉到它。</li><li id="4453" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">Rpn_bbox_loss:这对应于Rpn的定位精度。这是在检测到对象但边界框应该被校正的情况下要调整的权重</li><li id="4218" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">Mrcnn_class_loss:这对应于分配给区域建议中存在的对象的不正确分类的损失。如果从图像中检测到对象，但是分类错误，则该值将增加</li><li id="5ec1" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">Mrcnn_bbox_loss:这是在所识别的类的边界框的定位上分配的损失，如果完成了对象的正确分类，它将增加，但是定位不精确</li><li id="a42f" class="jz ka hi is b it ki ix kj jb kk jf kl jj km jn kn kf kg kh bi translated">Mrcnn_mask_loss:这对应于在被识别对象上创建的遮罩，如果像素级的识别很重要，则该权重将被增加</li></ul><p id="32c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上述超参数显示在下图的框图中。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/e0425c787b25dda04da05e4b3dea1a34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hpDNa1IVtNwm_-KH"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">具有超参数的掩模R-CNN结构</figcaption></figure><p id="459c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用于调整掩模R-CNN的损失权重的理想方法是从基本模型开始，其中每个模型的默认权重为1，并且通过可视化不同图像上的模型性能并查看检测到的对象的数量、分类的对象的准确性、识别的对象的定位以及掩模的定位来评估模型在验证集上的性能。那么应该基于模型性能来调整相应的参数。</p><p id="0c11" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结论:</p><p id="56dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总之，Mask R-CNN对于实例分割是一个很好的架构。然而，超参数的适当调整对于实现其潜力是重要的。像交叉验证的GridSearch这样的方法在CNN的情况下可能没有用，因为对模型有巨大的计算需求，因此理解超参数及其对整体预测的影响是重要的。本文解释了Mask R-CNN特有的最重要的超参数，以及如何对它们进行调整。</p><p id="8e8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您有任何意见或建议，请告诉我们。我们希望这篇文章能帮助你理解超参数，并对你的项目有所帮助。</p><p id="f3d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们要感谢我们的教授Joydeep Ghosh博士，他激励我们在博客中分享我们的学习成果。</p></div></div>    
</body>
</html>