<html>
<head>
<title>Interpreting results of OLS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OLS口译成绩</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-interpret-result-from-linear-regression-3f7ae7679ef9?source=collection_archive---------8-----------------------#2020-07-05">https://medium.com/analytics-vidhya/how-to-interpret-result-from-linear-regression-3f7ae7679ef9?source=collection_archive---------8-----------------------#2020-07-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4ec5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">无论你是数据科学的新手，甚至是经验丰富的老手，解释机器学习算法的结果都可能是一个挑战。挑战在于理解这个模型的结果。这一结果是否意味着该模型与您用来训练它的数据配合得有多好？线性回归是用于推断和预测的最常用方法之一。但是在解释这个结果之前，人们往往会忽略OLS假设。因此，这是分析OLS发布的各种统计数据的重要一步。我将探索房价预测数据集，这是一个小而简单的数据集，包含对各种房屋特征和价格的观察。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/0a55e7e98cf3febe8007b0e6062894e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/1*zY2shtZj4OWSh5aXW8sGxA.gif"/></div></figure><p id="4b9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">相关(预测)</strong>可变价格</p><p id="c827" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">自变量</strong> -大小</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="jl jm l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es jn"><img src="../Images/b00714f4d9b95d4dc7ed307ffddfb491.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s6l7WJgc0H9rfqOR9o87IA.png"/></div></div></figure><h1 id="42ff" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak"> <em class="kq">第一部分(车型总结)解读</em> </strong></h1><p id="f6ed" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">部门。变量:这里的因变量是我们将要通过模型预测的价格。</p><p id="9b17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型:</strong> OLS代表普通最小二乘。<strong class="ih hj">普通最小二乘法</strong> ( <strong class="ih hj"> OLS </strong>)是一种估计线性回归模型中未知参数的线性最小二乘法。OLS通过最小二乘法原理选择一组解释变量的线性函数的参数。</p><p id="5e93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">方法:最小二乘法</strong>是回归分析中的标准方法，通过最小化残差平方和来近似求解。</p><p id="ffae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">观察值数量:</strong>数据集中存在的观察值总数</p><p id="6bd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Df残差:</strong>Df(残差)是样本量减去被估计的参数个数，所以变成Df(残差)= n — (k+1)</p><p id="0a96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的例子中，n=100，k=1</p><p id="946e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">df(残差)=98</p><p id="365e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">R-Squared:</strong><em class="kw">R</em>2是一个统计量，它将给出模型拟合优度的一些信息。范围从0到1。在我们的例子中，R平方的值是0.745，因此它解释了模型解释的74%的方差。</p><p id="ddb7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">"<strong class="ih hj"><em class="kw">R的平方值是多少？"</em> </strong>答将，<strong class="ih hj">【看情况】</strong>。这取决于你的目标和因变量是如何定义的。如果因变量是非平稳(如趋势)时间序列，非常接近1的R平方值可能不会给人留下深刻印象。事实上，如果R平方非常接近1，并且数据由时间序列组成，这通常是一个不好的迹象:误差中通常会有显著的时间模式。另一方面，当您在大量噪声环境中寻找微弱信号时，10%或更小的R平方可能会提供一些信息，在这种环境中，即使是非常微弱的信号也会引起普遍关注。永远不要让自己陷入拟合回归模型的陷阱，这种回归模型看起来R平方不错，但实际上远不如简单的时间序列模型。</p><p id="6f3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kw"> R平方不是底线</em> </strong> <em class="kw">。</em></p><p id="e8a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Adj. R Squared: </strong>每向模型中添加一个自变量，<strong class="ih hj"> R-squared </strong> <strong class="ih hj">增加</strong>，即使自变量不显著。它从不减少。而<strong class="ih hj">调整后的R平方</strong>仅在自变量显著并影响因变量时增加。</p><p id="ea0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kw">为回归模型选择重要预测因子(自变量)时，应使用调整后的R-square。</em>T25】</strong></p><p id="d12a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">F-统计量和概率F-统计量:</strong>“F值”和“概率(F)”统计量测试回归模型的总体显著性。具体来说，他们测试了所有回归系数都等于零的零假设。F值是平均回归平方和除以平均误差平方和的比值。其值的范围从零到任意大的数。</p><p id="ad49" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Prob(F)的值是完整模型的零假设为真的概率(即所有回归系数为零)。例如，如果Prob(F)的值为<strong class="ih hj"> 8.13e-31 </strong>，那么所有回归参数为零的概率几乎为零。</p><p id="f5b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> AIC &amp; BIC: </strong> AIC是<em class="kw">赤池信息标准</em>的缩写<strong class="ih hj"> </strong>，用于选型。在回归方程中加入新变量的情况下，它会对错误模式产生不利影响。它被计算为参数的数量减去整个模型的可能性。较低的AIC意味着更好的模型。然而，BIC代表<em class="kw">贝叶斯信息标准</em>，是AIC的变体，在那里惩罚更加严厉。</p><h1 id="655b" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak"> <em class="kq">第二部分(系数表)释义</em> </strong></h1><p id="0b65" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><strong class="ih hj">系数</strong>:这里我们有常数和大小的系数1.019e+5和223.17，所以如果我说<em class="kw">价格</em>=<em class="kw">B0+B1 *大小</em></p><p id="9391" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就会得到<strong class="ih hj"> <em class="kw">价格=(1.019 e+5)+223.17 *尺寸</em> </strong></p><p id="0ab1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> std err: </strong>显示每次预测的准确性。标准差越低，估计值越好。</p><p id="4c4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> t &amp; p(t): </strong>显示t统计值和p值。这涉及到假设。它回答了这样一个问题，它是一个有用的变量，还是帮助我们解释了这种情况下的可变性。众所周知，p值&lt; 0.05被视为变量显著。在我们的例子中，我们可以说“大小”是预测“价格”的重要预测因素。</p><h1 id="cf78" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak"> <em class="kq">第三部分解读</em> </strong></h1><p id="b6de" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">让我们来看看列出的每个值:</p><p id="9de7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">Omnibus/Prob(Omnibus)</strong>—进行综合检验是为了检查误差是否正态分布(线性回归的假设之一)。这里，零假设是误差是正态分布的。接近零的值是优选的，这将表示正常。Prob(综合)执行统计测试，显示残差呈正态分布的概率。这里优选接近1的值。</p><p id="ba29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">偏斜</strong> —偏斜值最好接近零，表示残差分布正常。注意，这个值也控制综合。</p><p id="aad1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">峰度</strong> —它是数据曲率(峰值)的度量。更高的峰值导致更大的峰度。峰度值越高，表示残差在零附近的聚类越紧密，意味着模型越好，离群值越少。</p><p id="14bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">德宾-沃森 —它测试同质性(误差的独立性)。1和2之间的值是优选的。</p><p id="b116" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">jar que-Bera(JB)/Prob(JB)</strong>—该测试针对残差的正态性(线性回归的假设之一)该测试以Carlos Jarque和Anil K. Bera的名字命名。测试统计总是正的。Jarque-Bera检验的大值表明误差不是正态分布的。</p><p id="3054" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">条件编号</strong> —该测试测量功能输出相对于输入的敏感度。在多重共线性的情况下，我们可以预期数据的微小变化会产生更大的波动。</p><p id="1448" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kw">参考文献:</em> </strong></p><ol class=""><li id="1e63" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated"><a class="ae lg" href="https://people.duke.edu/~rnau/rsquared.htm" rel="noopener ugc nofollow" target="_blank">https://people.duke.edu/~rnau/rsquared.htm</a></li><li id="6587" class="kx ky hi ih b ii lh im li iq lj iu lk iy ll jc lc ld le lf bi translated"><a class="ae lg" rel="noopener" href="/@jyotiyadav99111/statistics-how-should-i-interpret-results-of-ols-3bde1ebeec01">https://medium . com/@ jyotiyadav 99111/statistics-how-should-I-interpret-results-of-ols-3 bde 1 ebeec 01</a></li><li id="9ca8" class="kx ky hi ih b ii lh im li iq lj iu lk iy ll jc lc ld le lf bi translated">https://en.wikipedia.org<a class="ae lg" href="https://en.wikipedia.org/wiki/Main_Page" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>