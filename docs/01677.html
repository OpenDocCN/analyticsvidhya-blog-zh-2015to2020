<html>
<head>
<title>Implement Linear Regression on Boston Housing Dataset by PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PyTorch实现波士顿住房数据集的线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/implement-linear-regression-on-boston-housing-dataset-by-pytorch-c5d29546f938?source=collection_archive---------3-----------------------#2019-11-08">https://medium.com/analytics-vidhya/implement-linear-regression-on-boston-housing-dataset-by-pytorch-c5d29546f938?source=collection_archive---------3-----------------------#2019-11-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/4c9c02f92f7d0bc7d838a5ffc04ab8d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vruoyy8pjgswbAm4"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">由<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae iu" href="https://unsplash.com/@dearseymour?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Ksenia Makagonova </a>拍摄的照片</figcaption></figure><p id="0455" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">本文旨在与您分享一些在真实数据集上实现线性回归的方法，包括数据分析、数据集分割和回归构造本身。为了学好PyTorch，我将演示PyTorch的回归，并向您展示PyTorch在向前和向后方面的魅力。</p><p id="4cfb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个故事有一个假设，即所有的读者都熟悉线性回归的原理。读者要了解方程Y = XW + b的W和b的含义和求解方法，要有更好的体验，最好了解一下可以用来解题的梯度下降法，了解一下用来评估回归性能的MSE。</p><h1 id="30ce" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">波士顿住房数据集处理</h1><p id="eab4" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated"><a class="ae iu" href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html" rel="noopener ugc nofollow" target="_blank">波士顿住房数据集</a>由美国人口普查局收集，涉及波士顿马萨诸塞州地区的住房。</p><p id="a12b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">我们需要的包</strong></p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="f8e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们利用sklearn中构建的数据集来加载我们的住房数据集，并由pandas对其进行处理。</p><p id="1f5e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> Peek数据集</strong></p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="c358" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们加载的数据集已经格式化为一个字典，因此我们可以通过使用。keys()方法。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/26415bd828e7ff9b7ff74785c63dbe9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*nAY7WQSbihWBJ72fKSl5Bg.png"/></div></figure><p id="75e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如我们所见，存在六个字段:</p><ol class=""><li id="5bc7" class="ld le hi ix b iy iz jc jd jg lf jk lg jo lh js li lj lk ll bi translated">数据:特征的内容，这是我们所关注的。</li><li id="8539" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">目标:房价，这是我们需要预测的。</li><li id="29c7" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">feature_names:如其名，特性名。分别存储每一列的含义。</li><li id="a6fe" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">描述:这个数据集的描述。</li><li id="ae2f" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">文件名:该数据集存储的路径。</li></ol><p id="fddc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">更重要的是，观察数据集的大小。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/e9e41f2a616d7b47cfcc6609e04a7e31.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/1*Xpiwg79u0aIf6ugQWF-ofQ.png"/></div></figure><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/3b36cfe51300f4eafabd900b934b1d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:210/format:webp/1*_XrUUFib2kVENWl0hV-xpw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据集的大小</figcaption></figure><p id="48a0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">预处理</strong></p><p id="7aa3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，熊猫把我们的数据加载到DataFrame。DataFrame可以被认为是一个高维的表，我们在这里用它作为一个二维矩阵。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="5a2f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了便于查看，我们将未来的名称映射到数据帧的每一列。然后查看前5行数据。head()在我们的数据中添加了一个“价格”列。</p><p id="5f81" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过检查数据的描述。描述()。</p><pre class="kw kx ky kz fd lt lu lv lw aw lx bi"><span id="f619" class="ly ju hi lu b fi lz ma l mb mc">df.describe()</span></pre><p id="b684" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可见数据的取值范围不同，差异较大，需要进行标准化。假设每个特征在整个数据集上都有一个平均值μ和一个标准差σ。因此，我们可以减去特性的每个值，然后用μ除以σ，得到每个特性的归一化值。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="0e35" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Lambda表达式用于简化代码。</p><p id="3151" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">拆分训练数据和测试数据</strong></p><p id="90f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先在numpy中将数据格式化为数组。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="463c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，把我们的数据分成训练集和测试集。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="a801" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们会得到下面的结果。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es md"><img src="../Images/1b60096f1108da45c9a5de676abe9767.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*8WepT6sLrP0jdYv3mtRbRw.png"/></div></figure><h1 id="9de7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">用PyTorch构建线性回归</h1><p id="174f" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">先导入PyTorch。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="0139" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里我用的是我电脑上的1.3.0版本。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es me"><img src="../Images/0d5ab8a2d891c41b53de817640239c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:134/format:webp/1*kdwQF0rzUZIujwUWS19FYw.png"/></div></figure><p id="dbd7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">数据处理</strong></p><p id="8c10" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将数据转换为PyTorch支持的张量。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="e249" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">构建神经网络</strong></p><p id="e819" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们用nn。顺序定义一个具有一层的神经网络并初始化它。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="9cb1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">nn只接受两个参数。线性，分别是重量维度和产出维度。</p><p id="2c47" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我们的检查中，参数不需要初始化，因为Linear会自动初始化。</p><p id="5cad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">数据加载器的用法</strong></p><p id="6c47" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">DataLoader是在PyTorch中实现的，它会返回一个迭代器来批量迭代训练数据。很好用，我们先从构造张量的数据集开始。</p><pre class="kw kx ky kz fd lt lu lv lw aw lx bi"><span id="93e0" class="ly ju hi lu b fi lz ma l mb mc">datasets = torch.utils.data.TensorDataset(X_train, Y_train)</span></pre><p id="baff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，使用这个数据集生成一个DataLoder。</p><pre class="kw kx ky kz fd lt lu lv lw aw lx bi"><span id="35dd" class="ly ju hi lu b fi lz ma l mb mc">train_iter = torch.utils.data.DataLoader(datasets, batch_size=10, shuffle=True)</span></pre><p id="2d11" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">batch_size是返回数据的每个批处理的大小。如果shuffle为真，数据将以随机顺序返回。</p><p id="0506" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">损失函数和优化器</strong></p><p id="a7f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在训练神经网络之前，我们必须定义损失函数，这里我们使用均方差(MSE)。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/7b42106935bd3c161f1f184851c7cdf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*sLD8xtgF6U9-15L604X-ow.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">均方误差</figcaption></figure><pre class="kw kx ky kz fd lt lu lv lw aw lx bi"><span id="bc15" class="ly ju hi lu b fi lz ma l mb mc">loss = torch.nn.MSELoss()</span></pre><p id="1ca0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，用随机梯度下降法优化神经网络。</p><pre class="kw kx ky kz fd lt lu lv lw aw lx bi"><span id="b47b" class="ly ju hi lu b fi lz ma l mb mc">optimizer = torch.optim.SGD(net.parameters(), lr=0.05)</span></pre><p id="117d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里0.05是学习率。</p><p id="d984" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">培训和评估</strong></p><p id="3aae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们开始训练。</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="7314" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">训练5个时期的训练集。训练过程大致如下。</p><ol class=""><li id="3600" class="ld le hi ix b iy iz jc jd jg lf jk lg jo lh js li lj lk ll bi translated">加载一批数据。</li><li id="3dd2" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">通过<em class="mg">网</em>预测批量数据。</li><li id="f1aa" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">通过预测值和真实值计算损失值。</li><li id="53b7" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">清除优化器存储的梯度值。</li><li id="526c" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">反向传播损失值。</li><li id="2c0e" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">更新优化器。</li></ol><p id="c68e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">训练后将显示以下内容。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/e1bb8394c99a1993370309628575961e.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*dq2WCT9oKX-Fn9Upch-hMw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">培训过程</figcaption></figure><p id="745a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们在测试数据集上检查它的性能。</p><pre class="kw kx ky kz fd lt lu lv lw aw lx bi"><span id="dca3" class="ly ju hi lu b fi lz ma l mb mc">print(loss(net(X_test), Y_test).item())</span></pre><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/4300ff656f8e33034ea23bf4593d655a.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*ia3F9IrH9Y3t3lUD7dbl3Q.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">损失价值</figcaption></figure><p id="0c59" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">和训练集差别不大。</p><p id="02f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们也可以观察一个样本的预测。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/21612ed20fb6c5b0d1e726a7e0a16dad.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*IrSghsFvXVitukG-aoFCyg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">观看一个样本</figcaption></figure><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/7f5a3876c1ba4cac788a169df008ab67.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*q3MAeUcWrPBxgBSOyOODsw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">输出</figcaption></figure></div></div>    
</body>
</html>