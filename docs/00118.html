<html>
<head>
<title>Real-Time Face Pose Estimation with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的实时人脸姿态估计</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-pose-estimation-with-deep-learning-eebd0e62dbaf?source=collection_archive---------0-----------------------#2018-09-24">https://medium.com/analytics-vidhya/face-pose-estimation-with-deep-learning-eebd0e62dbaf?source=collection_archive---------0-----------------------#2018-09-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii"><div class="bz dy l di"><div class="ij ik l"/></div></figure><p id="91cb" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">面部识别是深度学习的一个蓬勃发展的应用。从手机到机场摄像头，它在商业和研究领域都得到了广泛应用。当你把它和姿态估计结合起来，你会得到一个非常有力的匹配。</p><p id="f367" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">上周，我做了一个项目，预测一张脸在镜头前的姿态估计。在这篇文章中，我将开始介绍人脸姿态估计问题。稍后，你会发现我是如何训练一个深度学习模型来解决它的。最后，你还将有机会训练你的模型，并在你自己的形象上进行尝试。</p><h1 id="86ad" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">问题是</h1><p id="a18c" class="pw-post-body-paragraph il im hi in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji hb bi translated">由于人脸是一个3D物体，它可以绕着所有三个轴旋转——当然有一些限制。在面部姿态估计问题中，我们将这些运动称为<strong class="in hj">滚动、俯仰和偏航</strong>，在下图中更直观:</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es km"><img src="../Images/1a07da714b1cb6ce9f8d2a619d9e65fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*U4ZQ8UjzouVMRo2Fgsz7UA.png"/></div></figure><p id="c15c" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">估计这些姿态对于<strong class="in hj">活性检测系统</strong>是有用的。例如，它可以要求用户执行一些预定义的随机移动(例如，“向右旋转你的脸”)来检查他的活跃度。你也可以用它来了解哪些<strong class="in hj">学生在关注老师</strong>解释一个概念，估计<strong class="in hj">哪里有司机在看</strong>，等等。</p><h1 id="6262" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">数据集</h1><p id="3aa0" class="pw-post-body-paragraph il im hi in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji hb bi translated">针对这个问题，我创建了一个<a class="ae kt" href="https://drive.google.com/open?id=1lxwO-A-VBZCVuKKP1FgE_h0ZgfxUvlR4" rel="noopener ugc nofollow" target="_blank">玩具数据库</a>，里面有来自不同人脸数据集的6288张图片。<strong class="in hj">对于每张图像，我用</strong><a class="ae kt" href="http://dlib.net" rel="noopener ugc nofollow" target="_blank"><strong class="in hj">Dlib</strong></a><strong class="in hj">(68个点，见下图)检测面部标志，并计算所有点之间的成对欧几里德距离</strong>。因此，给定68分，我们最终得到(68 * 67)/2 =<strong class="in hj">2278个特征</strong>。每张脸的侧倾、俯仰、偏航都用<strong class="in hj"> </strong> <a class="ae kt" href="https://docs.aws.amazon.com/rekognition/latest/dg/faces-detect-images.html" rel="noopener ugc nofollow" target="_blank"> <strong class="in hj">亚马逊的人脸检测API </strong> </a> <strong class="in hj">进行了标注。</strong></p><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es ku"><img src="../Images/45751a4db0983683fe0afd4af24beefc.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*96UT-D8uSXjlnyvs9DZTog.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">由Dlib库计算的面部标志。</figcaption></figure><h1 id="ade4" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">训练模型</h1><p id="99a6" class="pw-post-body-paragraph il im hi in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji hb bi translated">现在，是时候训练我们的模型了。这一步我用的是Keras<strong class="in hj">。然而，我后来将它导出为TensorFlow格式，以便在C++应用程序中使用。经过几次尝试，我最终得到了以下配置:</strong></p><ul class=""><li id="395a" class="kz la hi in b io ip is it iw lb ja lc je ld ji le lf lg lh bi translated"><strong class="in hj">批量大小</strong> : 32</li><li id="dea4" class="kz la hi in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated"><strong class="in hj">#历元</strong> : 100</li><li id="ad26" class="kz la hi in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated"><strong class="in hj">优化器</strong>:亚当</li><li id="bd44" class="kz la hi in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated"><strong class="in hj">提前停止</strong>耐心= 25</li></ul><p id="c538" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">这是最终的网络架构:</p><figure class="kn ko kp kq fd ii"><div class="bz dy l di"><div class="ln ik l"/></div></figure><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/06e4ea359175ad3da31f263e9b21810c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*2IXaNhtc6PcUEvGsNesTIg.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">模型摘要</figcaption></figure><p id="97cc" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">关于我的模型架构，我想强调几个细节:</p><ul class=""><li id="c845" class="kz la hi in b io ip is it iw lb ja lc je ld ji le lf lg lh bi translated"><strong class="in hj">强正则化</strong>:由于我们有很多特征(2278)，所以我的网络中呈现的正则化类型很少，以<strong class="in hj">防止过度拟合</strong>并处理<a class="ae kt" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank"> <strong class="in hj">维数灾难</strong> </a>。首先，<strong class="in hj">所有层都有L2正则化</strong>，因为我们不希望模型对某些特征给予高度重视，尤其是在第一层。另外，模型的架构本身也是一种正则化。<strong class="in hj">它遵循</strong> <a class="ae kt" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank"> <strong class="in hj">自动编码器</strong> </a>的模式，其中每一层的神经元都比前一层少，以“迫使”网络学习相关信息并忽略不相关的信息。</li><li id="288e" class="kz la hi in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated"><strong class="in hj">由于每层神经元数量较少，我没有使用dropout </strong>。</li><li id="fd96" class="kz la hi in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated">我可以在第一层使用<strong class="in hj"> L1正则化</strong>来迫使网络忽略不必要的特征(因为这种正则化倾向于将与这种信息相关的权重设置为零)。然而，由于网络已经非常规范，我宁愿不这样做。在我的测试中，L2正则化的效果也稍好一些。:)</li></ul><p id="8506" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">你可以在这里查看完整的源代码<a class="ae kt" href="https://github.com/arnaldog12/Deep-Learning/blob/master/problems/Regressor-Face%20Pose/Keras.ipynb" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="d449" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">结果</h1><p id="c262" class="pw-post-body-paragraph il im hi in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji hb bi translated">这是100个时期训练后的train/val损失图:</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/9cd44d39969b8f69903fdb631d9580e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*S7yhhHevpLTHljPMPEbtsw.png"/></div></figure><pre class="kn ko kp kq fd lq lr ls lt aw lu bi"><span id="f2f5" class="lv jk hi lr b fi lw lx l ly lz">Train loss: 29.2128348724<br/>  Val loss: 33.3887316318<br/> Test loss: 39.9278703463</span></pre><p id="62f9" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">正如我们所看到的，我们的模型甚至在测试集上也取得了很好的结果。该图也遵循训练深度学习模型时预期的模式。由于我们使用MSE作为损失函数，<strong class="in hj">我们可以估计我们的模型有6的误差。</strong></p><p id="8b75" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">在下图中，我们可以看到测试集中每个点的实际角度和预测角度之间的差异。正如我们所观察到的，<strong class="in hj">偏航是最容易预测的</strong>，其次分别是滚转和俯仰。然而，我们可以在所有的图中观察到一些异常值。我将在以后的文章中研究它们。</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ma"><img src="../Images/50f1248801048beeb63b3d7037517baa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-4t72im8_NWUhvllMO9Cw.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">每个姿态(原始姿态、俯仰姿态和偏航姿态)的测试结果。图中的每个点代表测试集中每个点的实际角度和预测角度之间的差异。</figcaption></figure><h1 id="8b96" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">最后的话</h1><p id="80cf" class="pw-post-body-paragraph il im hi in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji hb bi translated">我上传了一个<a class="ae kt" href="https://github.com/arnaldog12/Deep-Learning/blob/master/problems/Regressor-Face%20Pose/Keras.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>，你可以看到我解决这个问题的所有步骤。此外，您可以按照同一个存储库中的说明，使用我创建的玩具数据集进行试验，然后在您自己的图像上进行测试。试试吧！</p><p id="14cf" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">对于未来的作品，我有几个想法:</p><ul class=""><li id="a0b9" class="kz la hi in b io ip is it iw lb ja lc je ld ji le lf lg lh bi translated">试着找一个更好的模式。如果有，请告诉我！</li><li id="f653" class="kz la hi in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated">检查测试集结果中的异常值</li><li id="54a9" class="kz la hi in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated">使用TensorFlow创建相同的教程</li><li id="fad2" class="kz la hi in b io li is lj iw lk ja ll je lm ji le lf lg lh bi translated">因为我的架构是一个自动编码器的开始，我可以复制和转置我的权重来使用它作为“解码器”。然后，<strong class="in hj">我会给我的网络滚转、俯仰和偏航作为输入，模型会输出2278个特征</strong>。我可以尝试使用这些功能来绘制68个标志点，并可视化结果。那太棒了！</li></ul><p id="7df3" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">最后，看看在CPU上实时运行模型的视频:</p><figure class="kn ko kp kq fd ii"><div class="bz dy l di"><div class="mf ik l"/></div></figure></div></div>    
</body>
</html>