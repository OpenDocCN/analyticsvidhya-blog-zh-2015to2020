<html>
<head>
<title>Machine Learning : Multi-Label Classification : MPST : Movie Plot Synopses with Tags : Tags Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习:多标签分类:MPST:带标签的电影情节概要:标签预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-multi-label-classification-mpst-movie-plot-synopses-with-tags-tags-8314e6841e17?source=collection_archive---------5-----------------------#2020-01-31">https://medium.com/analytics-vidhya/machine-learning-multi-label-classification-mpst-movie-plot-synopses-with-tags-tags-8314e6841e17?source=collection_archive---------5-----------------------#2020-01-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c86b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">—带有故事相关标签的电影情节概要数据集。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/f3121a7cb79c8c8aa5056b2e6385ac69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OSscN3JmXqCRnDMtTTnT4g.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:谷歌</figcaption></figure><h1 id="2309" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">业务问题:</h1><p id="b4cb" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">摘要电影的社会标签揭示了电影的各种各样的异质信息，如类型、情节结构、原声音乐、元数据、视觉和情感体验。这些信息对于构建自动系统来为电影创建标签是很有价值的。自动标记系统可以帮助推荐引擎改进相似电影的检索，以及帮助观众预先知道从电影中可以期待什么。在本文中，我们着手收集电影情节概要和标签的语料库。我们描述了一种方法，该方法使我们能够建立一个大约70个标签的细粒度集合，暴露电影情节的异构特征以及这些标签与一些14K电影情节概要的多标签关联。我们研究了这些标签如何与电影以及不同类型电影中的情感流动相关联。最后，我们使用这个语料库来探索从情节概要中推断标签的可行性。我们希望该语料库在其他与叙事分析相关的任务中有用。</p><h1 id="ddb7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">问题陈述:</h1><p id="9aa5" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">根据电影标题和简介中的内容建议标签。</p><h1 id="0ff3" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">有用的链接:</h1><p id="c1b1" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><em class="kw">来源:</em><a class="ae kx" href="https://www.kaggle.com/cryptexcode/mpst-movie-plot-synopses-with-tags" rel="noopener ugc nofollow" target="_blank"><em class="kw">https://www . ka ggle . com/cryptexcode/mpst-movie-plot-synopses-with-tags</em></a></p><p id="fb9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kw">研究论文:</em><a class="ae kx" href="https://www.aclweb.org/anthology/L18-1274/" rel="noopener ugc nofollow" target="_blank"><em class="kw">https://www.aclweb.org/anthology/L18-1274/</em></a></p><p id="39e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kw">附加信息:</em><a class="ae kx" href="http://ritual.uh.edu/mpst-2018/" rel="noopener ugc nofollow" target="_blank"><em class="kw">http://ritual.uh.edu/mpst-2018/</em></a></p><h1 id="5770" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">现实世界/业务目标和约束:</h1><ol class=""><li id="e016" class="ky kz hi ih b ii kr im ks iq la iu lb iy lc jc ld le lf lg bi translated">以高精度和召回率预测尽可能多的标签。</li><li id="a2ff" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">不正确的标签可能会影响客户体验。</li><li id="c988" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">没有严格的延迟限制。</li></ol></div><div class="ab cl lm ln gp lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="hb hc hd he hf"><h1 id="d6cd" class="jt ju hi bd jv jw lt jy jz ka lu kc kd ke lv kg kh ki lw kk kl km lx ko kp kq bi translated">机器学习问题:</h1><h2 id="c05f" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">数据概述:</h2><p id="a222" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">所有数据都在一个文件中:mpst_full_data.csv</p><p id="2faf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据分为3个部分，文件<br/>中的Train、Test和Val数据占数据的64%。<br/>测试由20%的数据组成。Val由16%的数据组成。<br/>mpst _ full _ data . CSV中的行数= 14828</p><p id="01c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据字段说明:</strong></p><p id="33f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集包含14，828行。表中的列是:</p><p id="56ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> imdb_id </strong> —电影的IMDB id</p><p id="1ae6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">片名</strong> —电影名称</p><p id="d00e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">剧情_梗概</strong> —电影剧情梗概</p><p id="93c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">标签</strong> —分配给电影的标签，由“，”分隔</p><p id="6021" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> split </strong> —电影在标准数据分割中的位置，如Train、Test或Val</p><p id="5093" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">剧情简介_来源</strong> —从哪里收集的剧情简介</p><h2 id="f4a6" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">数据点示例:</h2><p id="dc40" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><strong class="ih hj">IMDB _ id</strong>:TT 0113862<br/><strong class="ih hj">标题</strong>:荷兰先生的作品</p><blockquote class="mm mn mo"><p id="d851" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated">1964年9月一个明媚的早晨，格伦·霍兰德(Glenn Holland)被他的妻子艾瑞斯(Iris)叫醒。格伦在新更名的约翰·肯尼迪高中找到了一份音乐教师的工作。….</p><p id="ad9f" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated"><strong class="ih hj">标签</strong>:励志、浪漫、愚蠢、感觉良好<br/> <strong class="ih hj">分裂</strong>:火车<br/> <strong class="ih hj">剧情简介_来源</strong> : imdb</p></blockquote><h1 id="221a" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">将现实世界的问题映射到机器学习问题:</h1><h2 id="f34b" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">机器学习问题的类型:</h2><p id="44b3" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">这是一个多标签分类问题<br/> <strong class="ih hj">多标签分类</strong>:多标签分类给每个样本分配一组目标标签。这可以被认为是预测一个数据点的不相互排斥的属性，例如与一个文档相关的主题。一部电影可以是任何类型的，比如爱情片、动作片、惊悚片、恐怖片，或者都不是。<br/>_ _信贷_ _:<a class="ae kx" href="http://scikit-learn.org/stable/modules/multiclass.html" rel="noopener ugc nofollow" target="_blank">http://scikit-learn.org/stable/modules/multiclass.html</a></p><h2 id="5e94" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">绩效指标:</h2><p id="f68a" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><strong class="ih hj">微平均F1分数(平均F分数)</strong>:F1分数可以解释为精确度和召回率的加权平均值，其中F1分数在1时达到其最佳值，在0时达到其最差分数。精确度和召回率对F1分数的相对贡献是相等的。F1分数的公式为:</p><p id="858e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kw"> F1 = 2 *(精度*召回)/(精度+召回)</em></p><p id="a33d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在多类别和多标签的情况下，这是每个类别的F1分数的加权平均值。</p><p id="6184" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">“微f1分数”:</strong> <br/>通过计算总的真阳性、假阴性和假阳性来计算全局指标。当我们有阶级不平衡时，这是一个更好的衡量标准。</p><p id="df9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">‘宏观f1得分’:</strong><br/>计算每个标签的指标，并找出它们的未加权平均值。这没有考虑标签不平衡。</p><p id="ca53" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae kx" href="https://www.kaggle.com/wiki/MeanFScore" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/wiki/MeanFScore</a>T38<a class="ae kx" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . metrics . f1 _ score . html</a></p><p id="4286" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">汉明损失</strong>:汉明损失是被错误预测的标签的分数。https://www.kaggle.com/wiki/HammingLoss<br/>T3</p></div><div class="ab cl lm ln gp lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="hb hc hd he hf"><h1 id="8cd4" class="jt ju hi bd jv jw lt jy jz ka lu kc kd ke lv kg kh ki lw kk kl km lx ko kp kq bi translated">数据分析:</h1><p id="b852" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">让我们看看一些元数据，即关于数据集的数据。</p><p id="888e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总行数:14828</p><p id="e7aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总列数:6</p><p id="b35c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">列:<strong class="ih hj"> imdb_id，</strong> <strong class="ih hj">标题，情节_提要，标签，分割，提要_源，标签_计数</strong></p><p id="17f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">tag_count是一个新添加的列，指定我们的电影包含多少个标签。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ms"><img src="../Images/78feb5db5b3b1ec4d7f69e2713c36a82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-kjwFaCaPo76rYeASyTnHQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">原始数据的快照</figcaption></figure><p id="eabe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">重复的电影:^ 0</p><p id="6f4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">带有0个标签的电影:0</p><h1 id="8371" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">标签分析:</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mt"><img src="../Images/9dadfc159dc210f79e26e7e926a43b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*lKckqhrY1v5_M0mdXf_AnQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">标签计数</figcaption></figure><p id="6a59" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，有5516部电影带有1个标签，同样有2部电影带有3124个标签，一直到我们有1部电影带有25个标签。这给出了电影中标签分布的大量信息。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mu"><img src="../Images/4d9e524550cb67974391b5194bb3d8d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NIv4mCIa9slw3nkqFNSbgA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">我们的数据集中有71个独特的标签</figcaption></figure><p id="d445" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们可以看到的，在我们的数据集中有71个独特的标签，我们将使用这些标签来预测测试数据。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/fc630f2647e79b1bd866528247b3072a.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*lKE9CZAIocSqPvv7-y1PzQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">一些流行的标签</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mw"><img src="../Images/bb8f10f44d9c689b7ca3cb55bc64adbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mVzG4sMYPikXZevXE3F_2Q.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">标签的单词云</figcaption></figure><p id="6496" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到“谋杀”、“暴力”、“浪漫”、“闪回”和“邪教”是数据集中的一些流行标签。</p><p id="74c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">平均值。每部电影的标签数量:2.794578 ~ 3个</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mx"><img src="../Images/596c3dc607283d0df2dc629861145d7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*PKygu8ukmPmLTx0ZadLvCw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">前10个标签频率</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es my"><img src="../Images/c8846db00b37a50a1d186d223b801d05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GIrUDMNQSZzwuk684k7vIA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">关于标签分布的统计</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mz"><img src="../Images/e373959767a13b824a6e0bb0bb6f1c17.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*kmPpvf_xIQygBltMsCxE3A.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">标签的分位数分布</figcaption></figure><h2 id="5863" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">让我们通过分析得出我们的观察结果:</h2><ol class=""><li id="bda0" class="ky kz hi ih b ii kr im ks iq la iu lb iy lc jc ld le lf lg bi translated">总共有20个标签被使用超过500次。</li><li id="6f0d" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">9标签使用超过1000次。</li><li id="3ebc" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">最频繁的标签(即谋杀)被使用了5782次。</li><li id="874d" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">由于一些标签比其他标签出现得更频繁，因此微平均F1分数是解决此问题的合适指标。</li></ol></div><div class="ab cl lm ln gp lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="hb hc hd he hf"><h1 id="9ed5" class="jt ju hi bd jv jw lt jy jz ka lu kc kd ke lv kg kh ki lw kk kl km lx ko kp kq bi translated">数据预处理:</h1><h2 id="f763" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">数据清理:</h2><p id="574d" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我们清理数据，因为我们有原始形式的文本数据，我们删除以下内容:</p><ol class=""><li id="1fbd" class="ky kz hi ih b ii ij im in iq na iu nb iy nc jc ld le lf lg bi translated">标点</li><li id="9576" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">额外空格</li><li id="bf50" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">停止言语</li><li id="dbba" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">我们把像“不会”这样的词改成“不会”，“不能”改成“不能”等等。</li><li id="ab3c" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">我们把像“我有”这样的词改成“我有”，“我会”改成“我会”</li></ol><p id="d8c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">清理数据后，它看起来像:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nd"><img src="../Images/98da644826a77bc0141dfa6a9453e162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rRQ3GW8nkB0KmDneJ9M9XA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">预处理后的数据。</figcaption></figure><h1 id="e9d3" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">机器学习模型:</h1><h2 id="81ac" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">为多标签问题转换标签:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ne"><img src="../Images/2e54efdbba01a162397e5910f50a0bd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*EaWMo6mBcyPyzNBIU9ZsdA.png"/></div></figure><p id="4584" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将所有的71个标签转换成一个二进制的bow，其中对于每部电影，我们将针对该电影中出现的那些标签放置1。</p><p id="4453" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在将所有标签转换成弓形特征之后，我们得到了(14828，71)数据集形式的标签。</p><h2 id="fec8" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">将数据分为测试和训练:</h2><p id="5c28" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我们以(80:20)分割的方式分割数据。分割后，我们有如下数据点:</p><p id="f42b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练数据中的数据点数X : (11862，1) <br/>训练数据中的数据点数Y : (11862，71) <br/>测试数据中的数据点数X : (2966，1) <br/>测试数据中的数据点数Y : (2966，71)</p></div><div class="ab cl lm ln gp lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="hb hc hd he hf"><h1 id="50fb" class="jt ju hi bd jv jw lt jy jz ka lu kc kd ke lv kg kh ki lw kk kl km lx ko kp kq bi translated">特征化数据:任何模型中最重要的部分</h1><p id="0ea3" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">让我们来谈谈任何机器学习模型中最具创造性和最困难的部分，即从原始数据中创建特征..</p><p id="1aba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来看看我在解决问题时想到的功能。</p><h2 id="25f2" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">词汇特征:</h2><ol class=""><li id="7476" class="ky kz hi ih b ii kr im ks iq la iu lb iy lc jc ld le lf lg bi translated">n元语法:1，2，3</li><li id="9f07" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">字符n元语法:2，3</li><li id="1654" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">k跳n元语法</li></ol><p id="3900" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将逐一探究词汇特征:</p><p id="e29a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1。n-Gram : 1，2，3 </strong></p><p id="88b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将通过一个例子来理解这一点:让我们考虑一下这句话“<strong class="ih hj">敏捷的棕色狐狸跳过懒惰的狗</strong></p><p id="0bde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，对于1-gram的特征，它将每个单词视为一个向量:</p><p id="8ded" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kw">那只，快，棕色，狐狸，跳跃，越过，那只，懒惰，狗</em></p><p id="9a66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，对于2-gram的特征，它将把2个单词的组合视为向量:</p><p id="a850" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快速，快速的棕色，棕色狐狸…诸如此类。</p><p id="d508" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，对于3克，需要:</p><p id="4628" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kw">敏捷的棕色，敏捷的棕色狐狸，…等等。</em></p><p id="3415" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它们基本上是给定窗口内的一组共现词。</p><p id="37a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。字符n元语法:2，3 </strong></p><p id="f984" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">字符n-gram意味着与n-Gram相同的概念，唯一的区别是，它在字符级别上工作。</p><p id="7bfb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如:</p><p id="56d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑“机器学习”这个词</p><p id="de01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">char-2-Gram:“ma”、“ac”、“ch”、“hi”…等等</p><p id="ac0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">char-3-Gram:“MAC”、“ach”、“chi”…等等</p><p id="97c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。k-Skip-n-Gram : </strong></p><p id="dbb5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在word2vec的<a class="ae kx" href="https://www.geeksforgeeks.org/implement-your-own-word2vecskip-gram-model-in-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> skip gram </strong> </a>架构中，输入是<strong class="ih hj">中心词</strong>，预测是上下文词。考虑单词W的数组，如果W(i)是输入(中心单词)，那么W(i-2)、W(i-1)、W(i+1)和W(i+2)是上下文单词，如果<em class="kw">滑动窗口大小</em>是2。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nf"><img src="../Images/18ae0034a250de8e8bb393f68de7481c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZwcDVuFF8NUFr_gIc7UHdw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源谷歌。</figcaption></figure><p id="e7a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所说，图片比文字更能说明问题，这是绝对正确的。上面的图片让我免于许多解释。k-Skip-n-Gram的工作原理很清楚。</p><h2 id="b7d5" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">概念包:词性标注</h2><p id="2ffb" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">这是一个将句子转换成形式的过程——单词列表、元组列表(其中每个元组都有一个形式<em class="kw">(单词，标签)</em>)。的标记是词性标记，表示这个词是名词、形容词还是动词等等。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ng"><img src="../Images/fbfb9eb0508eb90b3ada266aefc2be2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*Em8IzWDTBlU7pZsDT1yh9Q.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">词类标注</figcaption></figure><p id="93b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基本上，词性标注是单词智能的，所以我们在使用它们之前必须非常小心，我们应该如何在我们的机器上使用它们，在我的例子中，我计算了我的句子中的词性的数量，并制作了一个弓形模型，更新了计数，这样我们的数据中就不会有维度不匹配。</p><h2 id="0711" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">情绪和情感:</h2><p id="671f" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我使用“SentimentIntensityAnalyzer”来找出特定句子的情感值，该函数返回给我们4个维度特征以及它们对于特定句子的值，这些值基本上是:</p><p id="00b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> neg，neu，pos，compound : </strong>这些是基于给定文本分析的得分。</p><h2 id="6e08" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">单词嵌入:</h2><p id="76bc" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我用了4个词嵌入，即:</p><ol class=""><li id="69c5" class="ky kz hi ih b ii ij im in iq na iu nb iy nc jc ld le lf lg bi translated">弓</li><li id="7fcd" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">TF-IDF</li><li id="ed43" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">平均W2V</li><li id="9e27" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">TFIDF加权AvgW2V</li></ol><p id="f2dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们逐一了解它们，并理解它们的意义:</p><h2 id="1ed3" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">鞠躬:</h2><p id="bdf2" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">词袋模型是在用机器学习算法对文本建模时表示文本数据的一种方式。</p><p id="4730" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器学习算法不能直接处理原始文本；文本必须转换成数字。具体来说，数字的向量。</p><p id="bcea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词袋模型，简称BoW，是一种从文本中提取特征用于建模的方法。</p><p id="d852" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词包是描述单词在文档中出现的文本表示。</p><p id="9ced" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如:让我们考虑2个句子:</p><ol class=""><li id="7dbe" class="ky kz hi ih b ii ij im in iq na iu nb iy nc jc ld le lf lg bi translated">“这是一个停留的好地方”</li><li id="ad49" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">“这是一个吃喝的好地方”</li></ol><p id="2e29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们需要两件东西来组成我们的弓模型，</p><p id="3a61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">已知单词的词汇。</p><p id="9710" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">二。已知单词存在的一种度量。</p><p id="2c11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，让我们考虑一个叫做二进制BoW的东西，它指定了这个句子是否包含这个单词。</p><p id="f637" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们的弓矢会像[这，是，一，好，地方，到，停留，吃，喝]。因此，第一句和第二句的二进制弓形分别为:[1，1，1，1，1，1，0，0]和[1，1，1，1，1，1，1，1，0，1]。</p><h2 id="12b8" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">TF-IDF:</h2><p id="ec8d" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">Tf-idf代表<em class="kw">词频-逆文档频率</em>，tf-idf权重是信息检索和文本挖掘中经常使用的一种权重。该权重是一种统计度量，用于评估一个单词对集合或语料库中的文档有多重要。重要性与单词在文档中出现的次数成比例增加，但是被单词在语料库中的频率抵消。</p><p id="4d15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> TF </strong>:词频，衡量一个词在文档中出现的频率。因为每个文档的长度不同，所以一个术语在长文档中出现的次数可能比短文档多得多。因此，术语频率通常除以文档长度(又名。文档中的术语总数)作为标准化的一种方式:</p><p id="2e69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TF(t) =(术语t在文档中出现的次数)/(文档中的总术语数)。</p><p id="c7be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> IDF </strong>:逆文档频率，衡量一个术语的重要程度。在计算TF时，所有项都被认为是同等重要的。然而，众所周知，某些术语，如“是”、“的”和“那个”，可能会出现很多次，但并不重要。因此，我们需要通过计算以下各项来降低常用术语的权重，同时提高罕见术语的权重:</p><p id="e552" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">IDF(t) = log_e(文档总数/包含术语t的文档数)。</p><h2 id="2cad" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">平均W2V:</h2><p id="26e2" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">Word2vec基本上以这样的方式将单词放置在特征空间中，即它们的位置由其含义决定，即具有相似含义的单词被聚集在一起，并且两个单词之间的距离也具有相同的含义。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nh"><img src="../Images/3064fac3ad63b3f298dadab2d8f5b054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*xFOitNz6zt3Ezl9HlQcfFQ.png"/></div></figure><p id="44b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们首先了解什么是余弦相似度，因为word2vec使用余弦相似度来找出最相似的单词。余弦相似性不仅可以判断两个向量之间的相似性，还可以检验向量的正交性。余弦相似度由公式表示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ni"><img src="../Images/2e810c5144b93710c2b2737fec2a2a6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*M98DKCGbnK_C3m4wr1YiDg.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nj"><img src="../Images/3c48bc06f364cc0668470900314dffa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7dPm-pC5Sl1dW4iw0BFIDw.png"/></div></div></figure><p id="3a4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果角度接近于零，那么我们可以说向量彼此非常相似，如果θ为90度，那么我们可以说向量彼此正交(正交向量彼此不相关)，如果θ为180度，那么我们可以说两个向量彼此相反。</p><p id="cbcd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要给出大型文本语料库，其中每个单词都有一个向量。它试图从原始文本中自动学习向量之间的关系。向量的维数越大，它的信息量就越大。</p><p id="1882" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">属性:</p><ol class=""><li id="de1b" class="ky kz hi ih b ii ij im in iq na iu nb iy nc jc ld le lf lg bi translated">如果字w1和w2相似，则向量v1和v2会更接近。</li><li id="a133" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">自动学习单词/矢量之间的关系。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nk"><img src="../Images/c873a620ec4d8c3ce6bbc8c9f9158388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*vhXRF_vkdsPtN_tGSm1X_w.png"/></div></figure><p id="bafa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们正在观察男女关系图，我们观察到男人和女人之间的距离与国王(男人)和王后(女人)之间的距离相同，不仅性别不同，而且如果我们观察同性，我们观察到王后和女人之间的距离与国王和男人之间的距离相同(国王和男人，王后和女人代表同性比较，因此它们必须是相等的距离)</p><p id="589c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如何把每个文档转换成矢量？</p><p id="da2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设在一个文档(行)中有w1，w2，…wn单词。以便转换成矢量。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nl"><img src="../Images/c662310008e0c6bc0e05cef3b90a55aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*FX5OXo1_dTPoSU1lP50sVQ.png"/></div></figure><p id="8f66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个单词都有一个向量，我们将平均word2vec转换为除以文档中的单词数。</p><h2 id="7c7a" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">TFIDF加权Word2Vec:</h2><p id="a834" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">在这个方法中，我们首先计算每个单词的tfidf值。然后按照与上一节相同的方法，将tfidf值乘以相应的字，然后将总和除以tfidf值总和。</p><p id="68df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，这4种技术被用来作为我的模型训练的一个特征。</p><h2 id="bd2e" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">文本的数字特征:</h2><ol class=""><li id="bf47" class="ky kz hi ih b ii kr im ks iq la iu lb iy lc jc ld le lf lg bi translated">每个剧情梗概的长度:基本上，我把每个剧情梗概的长度作为一个附加特征。</li><li id="baf5" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated"><strong class="ih hj">剧情梗概中独一无二单词的镜头:</strong>统计每一个剧情梗概中的每一个独一无二的单词，并将其作为一个特征。</li></ol><h2 id="0858" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated"><strong class="ak">结合所有手工制作特色:</strong></h2><p id="8168" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">最后，在组合所有特征之后，我们总共有12个特征用于训练我的模型。</p><h1 id="e40c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">型号:</h1><h2 id="f784" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">1.多标签分类:机器学习</h2><h2 id="35f3" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">1.1:1对其余:逻辑回归:</h2><p id="3847" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><strong class="ih hj">一对多</strong> (OvR)多类/多标签策略。也称为一对一，这种策略包括为每个类安装一个分类器。对于每个分类器，该类与所有其他类相匹配。除了它的计算效率(只需要n类分类器)，这种方法的一个优点是它的可解释性。因为每个类仅由一个分类器表示，所以可以通过检查相应的分类器来获得关于该类的知识。这是多类分类最常用的策略，也是一个公平的默认选择。</p><p id="e754" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该策略也可以用于多标签学习，其中分类器用于预测多个标签，例如，通过拟合2-d矩阵，其中如果样本I具有标签j，则单元[i，j]为1，否则为0。</p><p id="7900" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在多标签学习文献中，OvR也被称为二进制相关方法。</p><p id="6ce7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要了解逻辑回归，请参考<a class="ae kx" href="https://www.geeksforgeeks.org/understanding-logistic-regression/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">这一部分...</strong>T3】</a></p><p id="d900" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在使用OVR : LR和超调后，我们得到了以下结果:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nm"><img src="../Images/3c1d121ed26425adc9be10db6d9e59cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kgf6eytrkSKSNhaHWksXMg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nn"><img src="../Images/1247f97da6d0b857d1f0e0e9a0d20da9.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*qNXTlv_4PolGh5hYbKm1tQ.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es no"><img src="../Images/6422fd283b9f72756de5bdfdd318a21a.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*EmOBDEviWv2fq73FJjTdaQ.png"/></div></figure><pre class="je jf jg jh fd np nq nr ns aw nt bi"><span id="e972" class="ly ju hi nq b fi nu nv l nw nx"><strong class="nq hj">Test F1 Score with prob &gt; 0.25 for each tags :  0.6533833574983932</strong></span></pre><p id="8859" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，所有的标签都给出了出现在剧情梗概中的概率，因此我只考虑了那些概率超过0.25的标签</p><h2 id="bb59" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">1.2:一对其余:多项式b</h2><p id="bf1e" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">关于多项式的知识请参考<a class="ae kx" rel="noopener" href="/syncedreview/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation-4f5271768ebf"> <strong class="ih hj">这… </strong> </a></p><p id="4cd4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我用多项式朴素贝叶斯和OVR一起作为分类器，让我们把结果可视化:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ny"><img src="../Images/9a29c674f7249f3e845cba3e79fdd961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xp_vFmepnxFgIDLlJYKnmQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">超参数调谐。</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nz"><img src="../Images/d0af403aeb96563c2cfe501fcee55d1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*7nlahBmPq4CUktO9LUgnnQ.png"/></div></figure><pre class="je jf jg jh fd np nq nr ns aw nt bi"><span id="7d56" class="ly ju hi nq b fi nu nv l nw nx"><strong class="nq hj">Test F1 Score with prob &gt; 0.495000 for each tags : 0.076542</strong></span></pre><p id="491d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">非常少，不能考虑。</p><p id="1d3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">让我们尝试一些不同于机器学习的东西，让我们尝试深度学习模型。</strong></p><h2 id="a9ef" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">2.多标签分类:深度学习</h2><p id="2146" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">对于深度学习，我们需要考虑自定义指标和自定义单词嵌入。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es oa"><img src="../Images/e0d460c0ceda39a2af243159b8058eab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gQDwThegWmuhVQg3uCzozA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">自定义指标。</figcaption></figure><h2 id="3537" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">特色化:</h2><p id="44a9" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我获取了全部原始文本数据，并对其进行了单词嵌入。</p><p id="4c2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以用Tokenizer和with Max_No_Words，Max_Seq_Length和Embedding_Dim。</p><p id="3bc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在单词嵌入中，每个单词都被表示为一个n维密集向量。相似的单词将具有相似的向量。诸如GloVe和Word2Vec之类的单词嵌入技术已经被证明对于将单词转换成相应的密集向量非常有效。向量很小，并且向量中的索引实际上都不是空的。</p><p id="568f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了实现单词嵌入，Keras库包含一个名为Embedding()的层。嵌入层在Keras中以类的形式实现，通常用作NLP任务顺序模型中的第一层。</p><p id="4a44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于嵌入的细节可以在这里找到<a class="ae kx" href="https://stackabuse.com/python-for-nlp-word-embeddings-for-deep-learning-in-keras/" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="309e" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">分割训练和测试数据(80:20):</h2><p id="aaad" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我将数据分成DL模型的训练和测试。</p><h2 id="6025" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">2.1:模型1:嵌入+ Conv1D + Conv1D + LSTM</h2><p id="b754" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">模型包括:<a class="ae kx" href="https://stackabuse.com/python-for-nlp-word-embeddings-for-deep-learning-in-keras/" rel="noopener ugc nofollow" target="_blank">嵌入</a>层、<a class="ae kx" href="https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/" rel="noopener ugc nofollow" target="_blank">脱落</a>、<a class="ae kx" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">凸起</a>、<a class="ae kx" href="https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/" rel="noopener ugc nofollow" target="_blank">脱落</a>、<a class="ae kx" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">凸起</a>、<a class="ae kx" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"> LSTM </a>、<a class="ae kx" href="https://towardsdatascience.com/multi-layer-neural-networks-with-sigmoid-function-deep-learning-for-rookies-2-bf464f09eb7f" rel="noopener" target="_blank">乙状结肠</a>层..</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ob"><img src="../Images/a9139df02ec1b582a85314ea10775940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C3zRtzjJpn_0FT2vIKW8oQ.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es oc"><img src="../Images/c6ba7a559f6bd0d2015f40dc7f37d15b.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*0K_Vhv9IrdWlxy2XojqRDg.png"/></div></figure><pre class="je jf jg jh fd np nq nr ns aw nt bi"><span id="294c" class="ly ju hi nq b fi nu nv l nw nx"><strong class="nq hj">Test F1 Score with prob &gt; 0.500000 for each tags : 0.018086</strong></span></pre><p id="46a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">分数实在不行，就只好试试别的了。</p><h2 id="9560" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">2.2:模型二:嵌入+ Conv1D + Conv1D + LSTM + LSTM</h2><p id="6a35" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">该模型由以下序列组成:</p><p id="071b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嵌入&gt; Conv1D &gt;退出&gt; Conv1D &gt; LSTM &gt; <a class="ae kx" href="https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c" rel="noopener" target="_blank">批次形状</a> &gt; LSTM &gt;乙状结肠</p><p id="c66f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型1中已经提供了解释的参考链接，我在序列中提到了BatchNorm解释链接。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es od"><img src="../Images/e426e0c118df0c18b44880a844619095.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cNjxxph__iakSHng_Qdedg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ni"><img src="../Images/bcbc1999120dd51783136c1e4a0dd66e.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*w7kqCWpqMBMLETEwe8T8eg.png"/></div></figure><pre class="je jf jg jh fd np nq nr ns aw nt bi"><span id="8b88" class="ly ju hi nq b fi nu nv l nw nx"><strong class="nq hj">Test F1 Score with prob &gt; 0.250000 for each tags : 0.296534</strong></span></pre><p id="3b96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">F1的分数仍然不能被认为是好的..我们继续吧。</p><h2 id="fe52" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">2.3:模型3:嵌入+ Conv1D + BN + LSTM</h2><p id="9997" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">在这里，嵌入意味着，我使用手套向量进行了自定义嵌入，并使用那些嵌入来训练和预测测试数据。</p><p id="31b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据上面的解释，我们都知道模型的元素，让我们深入研究结果</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ob"><img src="../Images/dce6ee23f2a0f8d4192fb2122141099c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*reD2UZ5E8PtlcOD7IDXo5g.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es oe"><img src="../Images/3222d3fdf53f1c80456360ecb7f310d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*pCA0FtHneJrUdUlDowtuxA.png"/></div></div></figure><p id="7fda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以F1的分数是0.34，比上面的好，可以考虑，但是让我们看看我们能不能得到更多..</p><h2 id="7615" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">2.4:模型4:嵌入+ Conv1D + Conv1D + LSTM</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es of"><img src="../Images/721753da9d79bfbe480fb2820a849f82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R--JSKtAIWQrgXe2SOUAaQ.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es oc"><img src="../Images/bbc69fed3870558d67af5799c0e5cc04.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*ofym22_Y44ApI2ESnsA6CA.png"/></div></figure><p id="82d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有史以来最差的模型，让我们再试试一个模型。</p><h2 id="6480" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">2.5:模型5:嵌入+ Conv1D + BN + Conv1D + BN + LSTM</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es og"><img src="../Images/43c24e834aa29c4053cb020384bf9f10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f2oLxGPcb3vkujV7tZ_28A.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es oh"><img src="../Images/ceea7de95e441701d62a0b178e3a17b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*MP0qfwfDwyzAyuLE9d3EWw.png"/></div></figure><pre class="je jf jg jh fd np nq nr ns aw nt bi"><span id="5113" class="ly ju hi nq b fi nu nv l nw nx"><strong class="nq hj">Test F1 Score with prob &gt; 0.150000 for each tags : 0.330111</strong></span></pre><p id="179e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">经过尝试，这么多的模型，似乎我们需要更多的微调模型，并拿出更多的功能。</p><p id="9a9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们总结一下结果，给这个问题一个结论。</p><h1 id="6b6b" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">模型摘要:</h1><h2 id="f8d6" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">机器学习:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es oi"><img src="../Images/b28a9c13d05e0bf7471bcbf79f7c41a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*clGuJ1Ou1Q3HefHFF-_x6g.png"/></div></figure><h2 id="6d14" class="ly ju hi bd jv lz ma mb jz mc md me kd iq mf mg kh iu mh mi kl iy mj mk kp ml bi translated">深度学习:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es oj"><img src="../Images/13f24b5c56bbea2b65ec30998ecb2f34.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*zz6i4XxJ_n7wf8wgOl9pkg.png"/></div></figure><h1 id="d1c8" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论:</h1><ol class=""><li id="c5c9" class="ky kz hi ih b ii kr im ks iq la iu lb iy lc jc ld le lf lg bi translated">最大微观平均F1分数是0.4015，最大召回值是0.4827。</li></ol><p id="6edb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.事实证明，字符N元语法特征比单词N元语法特征强大得多。跳过克也是有用的。</p><p id="b0d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.通过使用bow、avg word2vec、tfidf word2vec以及TF-IDF和word2vec特性的组合，我们的模型表现得比以前的实现好得多。</p><p id="21d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.当今时代，我们更习惯看到90%以上的分数。但是给定一个14K数据点的非常有限的数据大小样本，我们实际上已经设法得到一个体面的微观平均f 1分数。</p><h1 id="b5d1" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">进一步改进:</h1><p id="669e" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我们可以在深度学习模型中使用更多功能，一些更精细的架构，可以进行更多的超调。</p><p id="8d4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们添加更多功能，并考虑更深层次的网络时，我们可以获得良好的f1分数..</p><h1 id="e17f" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">参考资料:</h1><blockquote class="mm mn mo"><p id="fa24" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated"><strong class="ih hj">研究论文:</strong>【https://www.aclweb.org/anthology/L18-1274】T2</p><p id="f169" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated">【https://www.appliedaicourse.com/】代号参考: <a class="ae kx" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">代号</a></p><p id="eef1" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated"><strong class="ih hj">思路:</strong>T10】https://en.wikipedia.org/wiki/Multi-label_classification</p><p id="0569" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated"><strong class="ih hj">二元关联:</strong><a class="ae kx" href="http://scikit.ml/api/skmultilearn.problem_transform.br.html" rel="noopener ugc nofollow" target="_blank">http://scikit.ml/api/skmultilearn.problem_transform.br.html</a></p><p id="56c6" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated"><strong class="ih hj">量词:</strong><a class="ae kx" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/</a></p><p id="cdb1" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated"><strong class="ih hj">攻略:</strong><a class="ae kx" href="https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2017/08/introduction-to-multi-label-class ification/</a></p><p id="9d3a" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated"><strong class="ih hj">其他:</strong></p><p id="5208" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated"><a class="ae kx" href="https://towardsdatascience.com" rel="noopener" target="_blank">https://towardsdatascience.com</a><br/><a class="ae kx" href="https://www.analyticsvidhya.com" rel="noopener ugc nofollow" target="_blank">https://www.analyticsvidhya.com</a><br/><a class="ae kx" href="https://www.quora.com" rel="noopener ugc nofollow" target="_blank">https://www.quora.com</a><br/>T35】https://deep sense . ai<br/><a class="ae kx" href="https://datascience.stackexchange.com/" rel="noopener ugc nofollow" target="_blank">https://datascience.stackexchange.com/</a></p><p id="d631" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated"><strong class="ih hj">感谢阅读！</strong></p><p id="651a" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated">如果你想了解更多类似的话题或者看看我还能提供什么，一定要访问我的网站:<a class="ae kx" href="https://digital.allaboutstuffs.com/" rel="noopener ugc nofollow" target="_blank">所有关于东西</a></p><p id="7475" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated">准备好让你的学习更上一层楼了吗？查看我提供的课程:<a class="ae kx" href="https://digital.allaboutstuffs.com/courses/" rel="noopener ugc nofollow" target="_blank">课程</a></p><p id="58dc" class="if ig kw ih b ii ij ik il im in io ip mp ir is it mq iv iw ix mr iz ja jb jc hb bi translated">生活工作压力大？花一点时间来放松和放松我的舒缓和放松的视频！现在就去我的频道，用"<a class="ae kx" href="https://www.youtube.com/c/TheSoulTranquilizer" rel="noopener ugc nofollow" target="_blank">灵魂镇定剂</a>"开始你的内心平和与宁静之旅</p></blockquote></div></div>    
</body>
</html>