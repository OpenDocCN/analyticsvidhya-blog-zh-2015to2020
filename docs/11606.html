<html>
<head>
<title>Optimizers in Deep Learning — Everything you need to know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习中的优化器——你需要知道的一切</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/optimizers-in-deep-learning-everything-you-need-to-know-730099ccbd50?source=collection_archive---------15-----------------------#2020-12-10">https://medium.com/analytics-vidhya/optimizers-in-deep-learning-everything-you-need-to-know-730099ccbd50?source=collection_archive---------15-----------------------#2020-12-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d77c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在前向传播中，在训练神经网络的同时给神经元分配一些随机权重，最后，我们得到一个<strong class="ih hj"> <em class="jd">实际输出</em> </strong>，表示为<strong class="ih hj"> ŷ </strong>。还有，我们知道<strong class="ih hj"> <em class="jd">预测输出</em> </strong>(用<strong class="ih hj"> y </strong>表示)应该是什么。</p><p id="0200" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，损失函数被计算为(y-ŷ)^2.然后，在反向传播期间使用<strong class="ih hj">优化器</strong>来调整权重，并且重复进行直到 y = ŷ</p><p id="3d7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们了解各种类型的优化算法-</p><h1 id="6ef4" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated"><strong class="ak"> 1。梯度下降</strong></h1><p id="098d" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated"><strong class="ih hj">直觉</strong> —考虑一个有 100k 条记录的数据集。在前向传播中考虑整个数据集，然后计算损失函数。此后，在反向传播中使用梯度下降算法来最小化损失函数。</p><p id="7d7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">缺点</strong>:</p><ol class=""><li id="d63a" class="kh ki hi ih b ii ij im in iq kj iu kk iy kl jc km kn ko kp bi translated">在大型数据集上，权重更新可能需要很长时间，因此达到全局最小值需要时间。</li><li id="9beb" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">需要高 RAM</li></ol><p id="8cc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注</strong>:全局最小值是损失函数与权重图上的点，它给出了网络中要添加的正确权重。</p><p id="2c21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于更新权重的公式-</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es kv"><img src="../Images/ca298b09f8966c3647d7e26b514cf06e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*3vHTlqA-Gx7hhAIO-MuRGw.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">权重更新公式</figcaption></figure><h1 id="6bb5" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated"><strong class="ak"> 2。随机梯度下降</strong></h1><p id="e19e" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated"><strong class="ih hj">直觉</strong> —考虑一个有 100k 条记录的数据集。在 1 个时期中，在特定点，在前向传播中获取 1 个记录，然后计算损失函数，之后在反向传播期间使用 SGD，添加适当的权重。</p><p id="5e58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，对所有 99999 条记录都执行此过程。</p><p id="a7c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注</strong>:历元是数据集所有记录的一个正反向传播周期</p><p id="472b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优势</strong></p><p id="8144" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">相比之下，需要较少的 RAM</p><p id="133d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">缺点</strong></p><p id="f359" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为一次只考虑一个记录，所以仅仅完成一个时期就要花费很多时间。</p><h1 id="14ff" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated"><strong class="ak"> 3。小批量随机梯度下降</strong></h1><p id="2206" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated"><strong class="ih hj">直觉:</strong>考虑一个有 100 条记录的数据集。首先，我们必须决定批量大小。例如，让我们考虑批量大小为 20，我们运行 3 个时期。</p><p id="c67d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，在第一时段中，运行 5 次迭代，并且在每次迭代中，处理 20 个记录，因此在 5 次迭代中，处理了所有 100 个记录。</p><p id="c57b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第二时段中，重复相同的过程，即(5 次迭代*每次迭代 20 条记录= 100 条记录)</p><p id="716c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，第三个时期以与上述类似的方式处理。</p><p id="5522" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优势</strong></p><ol class=""><li id="e04c" class="kh ki hi ih b ii ij im in iq kj iu kk iy kl jc km kn ko kp bi translated">更少内存</li><li id="aa29" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">计算成本更低</li></ol><p id="19c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">但是，</strong></p><p id="5967" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在损失函数与权重图中，收敛到全局最小值在时尚上不是线性的，而是偏斜的，如下图所示，这种行为被称为<strong class="ih hj">噪声</strong>。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es kv"><img src="../Images/424956367753ac6a3b528c9ee707301c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*X6lFpAl4GwJ5Qfvgcr-lKw.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">有噪声和无噪声的比较</figcaption></figure><p id="bbd4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为什么会这样？因为我们考虑批次形式的记录，并且特定批次中的记录可能不代表完整的数据集，或者将其视为—所考虑的批次可能有异常值。</p><p id="99cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于噪声达到全局最小值需要一些时间，但小批量 SGD 优于 SGD 和 GD。</p><h1 id="1618" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated"><strong class="ak"> 4。带动量的随机梯度下降</strong></h1><p id="fc66" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">这项工作类似于迷你批量 SGD，但略有修改。在 MBSGD 中，我们遇到了噪音问题，这个问题在这里得到了解决。单词“<strong class="ih hj">动量</strong>”的意思是消除噪音。</p><p id="ef7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是通过使用<a class="ae lh" rel="noopener" href="/@abhinav.mahapatra10/beginners-ml-basics-exponentially-weighted-moving-average-8ce3e75768f6"> <strong class="ih hj">指数加权移动平均</strong> </a>概念来实现的，同时在反向传播中更新权重。</p><p id="0010" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意</strong>:根据研究人员的说法，假设学习率= 0.95 是好的</p><p id="d7f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">让我们回顾一下</strong></p><p id="f51a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">需要高 RAM 小心</strong></p><p id="e750" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">训练网络的计算成本高—已解决</strong></p><p id="14a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">噪音正在影响收敛——不再是了</strong>。</p><p id="d5ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们得出结论，SGD 与动量是最好的优化！？等等…</p><p id="7e4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">继续读下去，</p><h1 id="9c2b" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated"><strong class="ak"> 5。Adagrad(自适应梯度下降)</strong></h1><p id="b648" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">研究人员发现，固定的学习速度效率不高。因此，他们引入了动态学习率的概念</p><p id="c6b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为什么我们需要一个动态的学习率？因为考虑这样一个场景，其中从网络的一组记录中没有新的东西要学习，所以在这种情况下，通过使用学习速率的动态值帮助我们更快地达到全局最小值。参考下图-</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es kv"><img src="../Images/e42c4c42485055ac22ccf17d8e8117a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*ProkW3Jy3SS4jd7QY0adSg.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">动态学习率与固定学习率</figcaption></figure><p id="aefc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">动态学习率的说明</strong></p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es kv"><img src="../Images/f6fa0f9a05b5d410983685e2e50475bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*gkU9hCHTOCanMFewW4OQZQ.png"/></div></figure><p id="a544" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在这里有一个问题——如果它是一个非常深的神经网络，有大约 100+个隐藏层，那么我们的<strong class="ih hj">新的和旧的权重有可能变成相同的</strong>。</p><p id="c12c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们谈谈解决这个问题的优化器，然后我们得到最好的优化器！！！</p><h1 id="d42d" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">6。AdaDelta 和 RMS Prop </h1><p id="58b7" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">通过在学习率公式中使用指数移动加权平均的概念，解决了网络中新加入的权值与旧权值相同的问题。</p><p id="da01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">公式- </strong></p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es li"><img src="../Images/8a22468b34b66fe242e8859980932856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3v_Fyl8SdH1Q5TqStlIQhA.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">AdaDelta 和 RMS Prop 公式—包含 EMWA 而不是 alphaT</figcaption></figure><h2 id="b44e" class="ln jf hi bd jg lo lp lq jk lr ls lt jo iq lu lv js iu lw lx jw iy ly lz ka ma bi translated">我们已经到了最后，要使用的<strong class="ak">最佳优化器</strong>是<strong class="ak"> RMS Prop </strong>和<strong class="ak"> SGD with momentum </strong>的组合，称为<strong class="ak"> Adam 优化器</strong>。</h2><p id="b9a7" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">感谢阅读！</p><p id="e718" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">打电话给我-</p><p id="65c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">电子邮件—tejasta@gmail.com</p><p id="1bac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LinkedIn—<a class="ae lh" href="www.linkedin.com/in/tejas-ta" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/tejasta/</a></p></div></div>    
</body>
</html>