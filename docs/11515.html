<html>
<head>
<title>Providing Data Node Elasticity in Hadoop using LVM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 LVM 在 Hadoop 中提供数据节点弹性</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/providing-data-node-elasticity-in-hadoop-using-lvm-e102035fdd62?source=collection_archive---------24-----------------------#2020-12-06">https://medium.com/analytics-vidhya/providing-data-node-elasticity-in-hadoop-using-lvm-e102035fdd62?source=collection_archive---------24-----------------------#2020-12-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="fdb7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在 AWS 上设置 Hadoop 集群时，启动更多实例作为数据节点会增加所提供的总存储。但是，如果我们需要增加单个数据节点提供的空间呢？这是我们可以使用<strong class="ih hj">逻辑卷管理器</strong>的地方。</p><h2 id="3b7e" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">LVM 用于以下目的:</h2><ul class=""><li id="51a7" class="jy jz hi ih b ii ka im kb iq kc iu kd iy ke jc kf kg kh ki bi translated">创建多个物理卷或整个硬盘的单个逻辑卷(有点类似于<a class="ae kj" href="https://en.wikipedia.org/wiki/RAID_0" rel="noopener ugc nofollow" target="_blank"> RAID 0 </a>，但更类似于<a class="ae kj" href="https://en.wikipedia.org/wiki/JBOD" rel="noopener ugc nofollow" target="_blank"> JBOD </a>)，允许动态调整卷大小。</li><li id="8437" class="jy jz hi ih b ii kk im kl iq km iu kn iy ko jc kf kg kh ki bi translated">结合<a class="ae kj" href="https://en.wikipedia.org/wiki/Hot_swapping" rel="noopener ugc nofollow" target="_blank">热插拔</a>，无需停机或服务中断即可添加和更换磁盘，从而管理大型硬盘群。</li><li id="e60a" class="jy jz hi ih b ii kk im kl iq km iu kn iy ko jc kf kg kh ki bi translated">在小型系统(如台式机)上，LVM 允许文件系统根据需要轻松调整大小，而不必在安装时估计分区需要多大。</li><li id="743d" class="jy jz hi ih b ii kk im kl iq km iu kn iy ko jc kf kg kh ki bi translated">通过拍摄逻辑卷的快照来执行一致的备份。</li><li id="ecd2" class="jy jz hi ih b ii kk im kl iq km iu kn iy ko jc kf kg kh ki bi translated">用一个密码加密多个物理分区。</li></ul><p id="4607" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LVM 可以被视为硬盘和分区之上的一个精简软件层，它为管理硬盘更换、重新分区和备份创建了一个抽象的连续性和易用性。</p><h1 id="085f" class="kp je hi bd jf kq kr ks jj kt ku kv jn kw kx ky jq kz la lb jt lc ld le jw lf bi translated">集成 LVM 和 Hadoop</h1><p id="1487" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">让我们开门见山吧—我将为我的 hadoop 集群使用一个简单的双节点设置(一个名称节点和一个数据节点)。它们都是 AWS EC2 实例，我将在 SSH 客户机(putty)上工作。虽然我个人使用过 AWS 实例，但这个概念甚至可以在本地虚拟机或任何其他基于云的计算服务上实现。运行<strong class="ih hj"> hadoop dfsadmin -report </strong>命令(在名称节点或数据节点上)以检查您的数据节点是否已连接。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="b988" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172-31-38-8 ~]# hadoop dfsadmin -report<br/>.<br/>.<br/>.<br/>-------------------------------------------------<br/>Datanodes available: 1 (1 total, 0 dead)</span><span id="8d76" class="jd je hi lo b fi lw lt l lu lv">Name: 65.0.76.100:50010<br/>Decommission Status : Normal<br/>Configured Capacity: 10724814848 (9.99 GB)<br/>DFS Used: 8192 (8 KB)<br/>Non DFS Used: 1739907072 (1.62 GB)<br/>DFS Remaining: 8984899584(8.37 GB)<br/>DFS Used%: 0%<br/>DFS Remaining%: 83.78%<br/>Last contact: Sat Dec 05 21:34:15 UTC 2020</span></pre><h2 id="f33c" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">添加物理卷</h2><p id="d26a" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">现在，我将在 AWS 中创建一个大小为 10 GiB 的卷，并将其连接到我的 datanode，如果在本地虚拟机上执行此操作，只需向运行您的数据节点的虚拟机添加一个所需大小的额外磁盘。</p><figure class="lj lk ll lm fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lx"><img src="../Images/24464fbde446a384dff846c6023b307b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NBY8N1ZAAwTPp76dK0dm6g.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">将卷附加到数据节点</figcaption></figure><p id="47f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">连接设备后，我们可以打开数据节点的终端，继续为添加的卷创建一个分区，用正确的文件系统对其进行格式化，最后在驱动器上挂载该分区。</p><p id="4917" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于上述步骤，确保系统上安装了<strong class="ih hj"> lvm </strong>。如果没有，使用 yum 安装。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="e388" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–85 ~]# yum install lvm2</span></pre><h2 id="21a7" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated"><strong class="ak">创建物理卷</strong></h2><p id="a65c" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">使用<strong class="ih hj"> fdisk -l </strong>列出您连接的磁盘设备</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="1572" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–85 ~]# fdisk -l<br/>Disk /dev/xvda: 10 GiB, 10737418240 bytes, 20971520 sectors<br/>Units: sectors of 1 * 512 = 512 bytes<br/>Sector size (logical/physical): 512 bytes / 512 bytes<br/>I/O size (minimum/optimal): 512 bytes / 512 bytes<br/>Disklabel type: gpt<br/>Disk identifier: 246B752E-8CB4–41E7-B9B1–365A93ACF890</span><span id="4ff3" class="jd je hi lo b fi lw lt l lu lv">Device Start End Sectors Size Type<br/>/dev/xvda1 2048 4095 2048 1M BIOS boot<br/>/dev/xvda2 4096 20971486 20967391 10G Linux filesystem</span><span id="9089" class="jd je hi lo b fi lw lt l lu lv">Disk /dev/xvdf: 10 GiB, 10737418240 bytes, 20971520 sectors<br/>Units: sectors of 1 * 512 = 512 bytes<br/>Sector size (logical/physical): 512 bytes / 512 bytes<br/>I/O size (minimum/optimal): 512 bytes / 512 bytes</span></pre><p id="3792" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> /dev/xvdf </strong>磁盘是我们新附加的磁盘。我们现在将使用<strong class="ih hj"> pvcreate </strong>命令创建该磁盘的物理卷。您可以使用<strong class="ih hj"> pvdisplay </strong>命令显示创建的物理卷。这可以用来创建多个物理卷。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="8895" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–85 ~]# pvcreate /dev/xvdf<br/> Physical volume “/dev/xvdf” successfully created.<br/>[root@ip-172–31–38–85]# pvdisplay /dev/xvdf<br/> “/dev/xvdf” is a new physical volume of “10.00 GiB”<br/> — — NEW Physical volume — -<br/> PV Name /dev/xvdf<br/> VG Name<br/> PV Size 10.00 GiB<br/> Allocatable NO<br/> PE Size 0<br/> Total PE 0<br/> Free PE 0<br/> Allocated PE 0<br/> PV UUID jVlAEE-ATVj-b0At-8IHp-zoyy-IXtv-Mvhcnu</span></pre><h2 id="b6b7" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">创建卷组</h2><p id="edbe" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">我们可以创建多个物理卷，然后将它们组合起来创建一个<strong class="ih hj">卷组</strong>。要创建卷组，使用<strong class="ih hj">vgcreate&lt;vgname&gt;&lt;pv1&gt;&lt;pv2&gt;…</strong>和<strong class="ih hj">vgdisplay&lt;vgname&gt;</strong>来显示卷组。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="7138" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–85 ~]# vgcreate vgdata /dev/xvdf<br/> Volume group “vgdata” successfully created<br/>[root@ip-172–31–38–85 ~]# vgdisplay vgdata<br/> — — Volume group — -<br/> VG Name vgdata<br/> System ID<br/> Format lvm2<br/> Metadata Areas 1<br/> Metadata Sequence No 1<br/> VG Access read/write<br/> VG Status resizable<br/> MAX LV 0<br/> Cur LV 0<br/> Open LV 0<br/> Max PV 0<br/> Cur PV 1<br/> Act PV 1<br/> VG Size &lt;10.00 GiB<br/> PE Size 4.00 MiB<br/> Total PE 2559<br/> Alloc PE / Size 0 / 0<br/> Free PE / Size 2559 / &lt;10.00 GiB<br/> VG UUID FLipJ0-kzBs-lW2v-IvjG-2HxN-1U1F-HSJwmj</span></pre><h2 id="d7a4" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">创建和装载逻辑卷</h2><p id="8526" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">我们现在可以使用命令<strong class="ih hj">lvcreate-size&lt;size&gt;-name&lt;lvname&gt;&lt;vgname&gt;</strong>从我们的卷组创建逻辑卷。在这里，我创建了一个大小为 5 GiB 的逻辑卷，并使用<strong class="ih hj">lvdisplay&lt;vgname&gt;/&lt;lvname&gt;</strong>显示它</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="fe7c" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172-31-38-85 ~]# lvcreate --size 5G --name lvdata1 vgdata<br/>  Logical volume "lvdata1" created.<br/>[root@ip-172–31–38–85 ~]# lvdisplay vgdata/lvdata1<br/> — — Logical volume — -<br/> LV Path /dev/vgdata/lvdata1<br/> LV Name lvdata1<br/> VG Name vgdata<br/> LV UUID 1C08aW-rTGn-CTjz-UiGg-ksRM-79FK-7WWVNS<br/> LV Write Access read/write<br/> LV Creation host, time ip-172–31–38–85.ap-south-1.compute.internal, 2020–12–05 23:38:10 +0000<br/> LV Status available<br/> # open 0<br/> LV Size 5.00 GiB<br/> Current LE 1280<br/> Segments 1<br/> Allocation inherit<br/> Read ahead sectors auto<br/> — currently set to 8192<br/> Block device 253:0</span></pre><p id="1967" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，让我们用<strong class="ih hj"> ext4 </strong>文件系统格式化逻辑卷。为此我们使用命令<strong class="ih hj">mkfs . ext 4&lt;LV Path&gt;T19】。</strong></p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="af55" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–85 ~]# mkfs.ext4 /dev/vgdata/lvdata1<br/>mke2fs 1.45.6 (20-Mar-2020)<br/>Creating filesystem with 1310720 4k blocks and 327680 inodes<br/>Filesystem UUID: cac48375–3f2f-4c81–9b53–4336043bf423<br/>Superblock backups stored on blocks:<br/> 32768, 98304, 163840, 229376, 294912, 819200, 884736</span><span id="406b" class="jd je hi lo b fi lw lt l lu lv">Allocating group tables: done<br/>Writing inode tables: done<br/>Creating journal (16384 blocks): done<br/>Writing superblocks and filesystem accounting information: done</span></pre><p id="3d12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们通常创建一个目录，可以在其中装入格式化的卷，但在这种情况下，由于我们希望增加数据节点的弹性，我们将把卷装入数据节点目录。您可以在 hadoop 目录中的<strong class="ih hj"> hdfs-site.xml </strong>文件中验证数据节点目录的位置。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="c49e" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–85 ~]# cat /etc/hadoop/hdfs-site.xml<br/>&lt;?xml version=”1.0"?&gt;<br/>&lt;?xml-stylesheet type=”text/xsl” href=”configuration.xsl”?&gt;</span><span id="a4b9" class="jd je hi lo b fi lw lt l lu lv">&lt;! — Put site-specific property overrides in this file. →</span><span id="dd6e" class="jd je hi lo b fi lw lt l lu lv">&lt;configuration&gt;<br/> &lt;property&gt;<br/> &lt;name&gt;dfs.data.dir&lt;/name&gt;<br/> &lt;value&gt;/dn&lt;/value&gt;<br/> &lt;/property&gt;<br/>&lt;/configuration&gt;</span></pre><p id="a57d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我的例子中，数据节点目录是<strong class="ih hj"> /dn </strong>。因此，我将使用<strong class="ih hj"> mount </strong>命令<strong class="ih hj">mount/dev/mapper/&lt;vgname&gt;-&lt;lvname&gt;&lt;mount point&gt;</strong>将卷挂载到这个目录。<br/>使用命令<strong class="ih hj"> df -h </strong>确认安装。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="5f96" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172-31-38-85 ~]# mount /dev/mapper/vgdata-lvdata1 /dn</span></pre><h2 id="c6d8" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">扩展逻辑卷</h2><p id="d626" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">我们可以进一步从卷组向逻辑卷添加存储容量，而不必格式化已经挂载的逻辑卷。这是通过使用两个命令来完成的:<strong class="ih hj"> lvextend </strong>和<strong class="ih hj"> resize2fs </strong>。</p><p id="56cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用<strong class="ih hj">lvextend-size+&lt;size&gt;&lt;device path&gt;</strong>来添加扩展逻辑卷。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="2154" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–85 ~]# lvextend — size +2G /dev/mapper/vgdata-lvdata1 Size of logical volume vgdata/lvdata1 changed from 5.00 GiB (1280 extents) to 7.00 GiB (1792 extents).<br/> Logical volume vgdata/lvdata1 successfully resized.</span></pre><p id="9661" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了使扩展卷可用，我们使用了<strong class="ih hj">resize 2fs</strong><strong class="ih hj">&lt;device path&gt;</strong></p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="a62e" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–85 hadoop]# resize2fs /dev/mapper/vgdata-lvdata1<br/>resize2fs 1.45.6 (20-Mar-2020)<br/>Filesystem at /dev/mapper/vgdata-lvdata1 is mounted on /dn; on-line resizing required<br/>old_desc_blocks = 1, new_desc_blocks = 1<br/>The filesystem on /dev/mapper/vgdata-lvdata1 is now 1835008 (4k) blocks long.</span></pre><p id="7a54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后运行<strong class="ih hj"> df -h </strong>命令来验证扩展卷。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="7879" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–85 hadoop]# df -h<br/>Filesystem Size Used Avail Use% Mounted on<br/>devtmpfs 378M 0 378M 0% /dev<br/>tmpfs 403M 0 403M 0% /dev/shm<br/>tmpfs 403M 11M 393M 3% /run<br/>tmpfs 403M 0 403M 0% /sys/fs/cgroup<br/>/dev/xvda2 10G 1.7G 8.4G 17% /<br/>tmpfs 81M 0 81M 0% /run/user/1000<br/>/dev/mapper/vgdata-lvdata1 6.9G 23M 6.5G 1% /dn</span></pre><p id="729a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在运行<strong class="ih hj"> hadoop dfsadmin -report </strong>命令，我们看到我们的数据节点贡献的存储现在约为 6.8 GB。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="2b75" class="jd je hi lo b fi ls lt l lu lv">[root@ip-172–31–38–8 ~]# hadoop dfsadmin -report<br/>.<br/>.<br/>.</span><span id="0031" class="jd je hi lo b fi lw lt l lu lv">-------------------------------------------------<br/>Datanodes available: 1 (1 total, 0 dead)</span><span id="8c26" class="jd je hi lo b fi lw lt l lu lv">Name: 13.232.125.253:50010<br/>Decommission Status : Normal<br/>Configured Capacity: 7331110912 (6.83 GB)<br/>DFS Used: 45056 (44 KB)<br/>Non DFS Used: 405405696 (386.62 MB)<br/>DFS Remaining: 6925660160(6.45 GB)<br/>DFS Used%: 0%<br/>DFS Remaining%: 94.47%<br/>Last contact: Sun Dec 06 21:08:07 UTC 2020</span></pre></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="141c" class="kp je hi bd jf kq mq ks jj kt mr kv jn kw ms ky jq kz mt lb jt lc mu le jw lf bi translated">结论</h1><p id="faab" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">我们可以附加更多的物理卷，并将它们添加到卷组中，并进一步扩展数据节点目录上装载的逻辑卷的大小，以使我们的数据节点存储可以随时调整大小。这就是我们如何使用 LVM 在 hadoop 上提供数据节点弹性。</p><h2 id="6192" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">希望这有所帮助:)</h2></div></div>    
</body>
</html>