# 只有一张照片的假视频

> 原文：<https://medium.com/analytics-vidhya/a-fake-video-with-one-photo-2ea2650db3c2?source=collection_archive---------9----------------------->

![](img/e6230838ee05dc11c8511db752a9cf41.png)

**形象由** [**马蒂厄斯特恩**](https://unsplash.com/@mathieustern) **起** [**起**](https://unsplash.com/)

现在，假视频是如此容易被创建。在本教程中，我将解释，在几个步骤中，如何在不需要任何数学背景的情况下制作一个深度的伪框架。

![](img/d858e906f38ed5d60bb6f5203ce5067b.png)

图像动画的一阶运动模型【由 [Aliaksandr](https://aliaksandrsiarohin.github.io/first-order-model-website/)

出于对科学的热爱，从研究的角度来看，阿利亚克山大的工作的确令人印象深刻。它已经发表在 [NeurIPS](http://papers.nips.cc/paper/8935-first-order-motion-model-for-image-animation) 上，并且[源代码](https://github.com/AliaksandrSiarohin/first-order-model)可以在网上获得。

你所要做的就是录制一段你自己的视频，并选择一张你想模仿的人的照片。机器学习会跟随你从视频中获得的行为。

## **deep fake 的基本概念**

Deepfake 的概念很简单。假设我们想把一个人 A 的脸转换成一个人 b 的视频。

首先，我们为两个人收集成百上千张照片。我们建立一个编码器，使用深度卷积神经网络 CNN(卷积神经网络)对所有这些图片进行编码。然后我们用解码器重建图像。这个自动编码器(编码器和解码器)有超过 100 万个参数，但还不足以记住所有的图片。因此，编码器需要提取最重要的特征来重建原始输入。就当是犯罪小品吧。这些特征是目击者(编码者)的描述，合成素描师(解码者)用它们来重建嫌疑人的照片。

为了解码特征，我们对人 A 和人 b 使用单独的解码器。现在，我们训练编码器和解码器(使用反向传播),以使输入与输出紧密匹配。这个过程很耗时，用一个 GPU 处理，大概需要 3 天才能生成像样的结果。(在重复处理图像大约 1000 多万次之后)。

![](img/a01cb2458920ed8717f1285eb66e8081.png)

训练结束后，我们逐帧处理视频，将一个人的脸与另一个人的脸进行交换。使用面部检测，我们提取出人物 A 的面部，并将其输入编码器。然而，我们不是馈送给它的原始解码器，而是使用人 B 的解码器来重建图像。也就是说，我们用原始视频中 A 的特征来画人 B。然后，我们将新创建的人脸合并到原始图像中。

![](img/55a85eabc359c1a541017b35e32b6cf0.png)

直观地说，编码器正在检测面部角度、肤色、面部表情、光照和其他对重建人物 a 很重要的信息。当我们使用第二个解码器重建图像时，我们正在绘制人物 B，但带有 a 的上下文。在下图中，重建的图像具有 Trump 的面部特征，同时保持了目标视频的面部表情。

## **基础 DeepFake 怎么做？**

一步一步的使用你想要伪造的人的照片，如果你做的一切都正确的话，应该不到十分钟。如果你对写代码什么的一无所知，你没有创造任何东西，我只是在读[这篇论文](https://arxiv.org/pdf/2003.00196.pdf)并决定尝试一下。

要使用这种技术，你只需要录制一段你自己的视频，添加一张目标对象的图像，运行这种基于学习的算法，就可以了。

![](img/90b14902785f902a03cc7907db600cf0.png)

**生成头部动作【按**[](https://aliaksandrsiarohin.github.io/first-order-model-website/)

****如上所述，许多重要的手势正在被翻译，例如头、嘴和眼睛的运动，但更好的是，甚至全身运动也可以。****

****难以置信！****

****首先，大多数以前的算法需要额外的信息，如面部标志或目标对象的姿态估计。我们的方法不需要图像知识。****

****我们可以创建高质量的 DeepFakes 视频，只需一张目标对象的照片。但它不仅仅是像专业人员一样跳舞或像运动员一样练习运动，它还可以在非人形和卡通模型上工作，我们甚至可以通过使用另一个机器人手臂作为驱动序列来合成一个机器人手臂的动画。****

****![](img/98daf1671ae7df36416984df7a6c7f8f.png)****

****生成全身运动[由 [Aliaksandr](https://aliaksandrsiarohin.github.io/first-order-model-website/) ]****

******那么，为什么它不需要所有这些附加信息呢？******

****好吧，如果我们看看引擎盖下面，我们会看到它是一种基于神经网络的方法，它自己生成所有这些信息！****

****它确定了我们的驾驶视频中正在发生什么样的运动和变换。****

****你可以看到，这里学习到的关键点以出色的表现跟随视频的运动。现在，我们打包所有这些信息，并将其发送到生成器，以适当地扭曲目标图像，同时考虑到可能出现的遮挡。****

****![](img/c28b9a375a810eba7ccd31ebb9a8c48c.png)****

****模型学习识别关键点[通过 [Aliaksandr](https://aliaksandrsiarohin.github.io/first-order-model-website/)****

****在以前的工作中，我们需要额外的信息，如面部标志来绘制头部运动，姿势估计来绘制全身运动。****

****![](img/2a2e72b61ed91ad1524030bdbbe4c802.png)****

****过去的工作需要面部标志和姿势估计[由[阿利亚克山大](https://aliaksandrsiarohin.github.io/first-order-model-website/)****

****然而，在这种情况下，神经网络会自动完成。您可以录制自己的视频，并为照片中的人制作动画。是的，甚至还有一幅蒙娜丽莎的画像。****

****它也适用于全身运动的视频！这意味着你可以让唐纳德·特朗普像迈克尔·杰克逊一样跳太空步。****

****源代码，甚至还有一个 [Colab 笔记本](https://lnkd.in/dwaa3tt)的例子，我认为这是这个领域最容易获得的论文之一。****

## ****Deepfakes 的优势和弊端？****

****研究人员注意到这项技术有很多优点。这将极大地帮助电影和电视行业，允许他们纠正发音不佳的台词而无需重新录制图像，并为说不同语言的演员创造完美的配音。****

****deepfake 的另一个事实优势是，人们对这种新闻变得更加谨慎，它让我们意识到这种虚假的事情，我们不应该相信我们周围看到的一切。****

****但是这些好处足以抵消潜在的损害吗？****

****Deepfakes 的危害是相当明显的。从制造假罪证到“假新闻”和宣传，这种技术很容易被用于邪恶目的和勒索。****

****“所以，感谢 *Deepfakes* 让我们意识到，我们不能把我们看到和听到的一切都视为理所当然。所以怀疑下一个你会在网上看到的视频。见鬼，怀疑你看到的，读到的，听到的一切。更关键！你自己想想。”****

****最后，技术并不完美，但这些类型的限制总是在研究的早期阶段，几乎可以保证它们将被及时克服。这意味着整个社会将很快不得不解决这项研究的基本概念:允许任何人编辑视频中人们所说的内容而无需技术培训的软件的出现。****

******论文链接:**[**https://lnkd.in/dzuGAhB**](https://lnkd.in/dzuGAhB)****

******链接到 GitHub:**[**https://lnkd.in/d3QS7-s**](https://lnkd.in/d3QS7-s)****

******链接谷歌 colab:**[**https://lnkd.in/dwaa3tt**](https://lnkd.in/dwaa3tt)****