<html>
<head>
<title>Learning CNN (with Image Data) using Simple KERAS &amp; PYTHON Programs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用简单的KERAS和PYTHON程序学习CNN(带图像数据)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/learning-cnn-using-simple-keras-python-programs-7be7b9efa852?source=collection_archive---------2-----------------------#2018-04-07">https://medium.com/analytics-vidhya/learning-cnn-using-simple-keras-python-programs-7be7b9efa852?source=collection_archive---------2-----------------------#2018-04-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/4313ceccf4e39eb16ab3673f1c2fd72f.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*b4YRt9UfsjJgymC6ljVZ2A.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">美国有线新闻网；卷积神经网络</figcaption></figure><p id="e17d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我将尝试分享我学习CNN的经验。我放了简单的小例子(代码)来快速理解。Python (≥3.6)和Keras (≥2)在后端与Tensorflow一起使用。Jupyter笔记本最适合这些例子。还有呢？运行代码并享受乐趣…</p><h2 id="3565" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">1.手写识别</h2><p id="ae5d" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">这里是下载MNIST数据集的地方。在训练&amp;验证模型后，使用测试数据评估性能。GPU/更高-运行代码需要RAM。还需要互联网连接。</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="61a3" class="jo jp hi ku b fi ky kz l la lb">#importing libraries<br/>import numpy<br/>from keras.datasets import mnist<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D<br/>from keras.utils import np_utils<br/>from keras import backend as K<br/>K.set_image_dim_ordering(‘tf’)</span><span id="1635" class="jo jp hi ku b fi lc kz l la lb">#seed input for random values<br/>seed = 2018<br/>numpy.random.seed(seed)</span><span id="9bf7" class="jo jp hi ku b fi lc kz l la lb">#loading MNIST data &amp; reshaping<br/>(X_train, y_train), (X_test, y_test) = mnist.load_data()<br/>X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')<br/>X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')</span><span id="3a28" class="jo jp hi ku b fi lc kz l la lb">#data pre-processing<br/>X_train = X_train / 255<br/>X_test = X_test / 255<br/>y_train = np_utils.to_categorical(y_train)<br/>y_test = np_utils.to_categorical(y_test)<br/>num_classes = y_test.shape[1]</span><span id="7c65" class="jo jp hi ku b fi lc kz l la lb">#function for creating deep network model<br/>def create_model():<br/> model = Sequential()<br/> model.add(Conv2D(32, (5, 5), input_shape=(28, 28,1), activation='relu'))<br/> model.add(MaxPooling2D(pool_size=(2, 2)))<br/> model.add(Dropout(0.2))<br/> model.add(Flatten())<br/> model.add(Dense(128, activation='relu'))<br/> model.add(Dense(num_classes, activation='softmax'))<br/> model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])<br/> return model</span><span id="a797" class="jo jp hi ku b fi lc kz l la lb">#training, validating &amp; testing<br/>model = create_model()<br/>model.summary()<br/>model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)<br/>scores = model.evaluate(X_test, y_test, verbose=1)<br/>print("CNN Error: %.2f%%" % (100-scores[1]*100))</span></pre><h2 id="7f65" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">2.物体识别</h2><p id="1b01" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated"><em class="ko">这里用IMAGENET数据集预训练的VGG16网络用于识别一个物体(现实生活中常见的物体)。不需要GPU。需要互联网连接。</em></p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="bdb9" class="jo jp hi ku b fi ky kz l la lb">#importing libraries<br/>import numpy as np<br/>from IPython.display import Image, display<br/>from keras.applications import VGG16, imagenet_utils<br/>from keras.preprocessing.image import img_to_array, load_img</span><span id="c7fe" class="jo jp hi ku b fi lc kz l la lb">#pre-processing input<br/>inputShape = (224, 224)<br/>preprocess = imagenet_utils.preprocess_input</span><span id="22ac" class="jo jp hi ku b fi lc kz l la lb">#loading VGG16 with 'imagenet' pre-trained weights<br/>model = VGG16(weights="imagenet")</span><span id="bf26" class="jo jp hi ku b fi lc kz l la lb">#displaying, loading &amp; pre-processing test image (one needs to give path for his test image)<br/>display(Image('./test.jpg'))<br/>image = load_img("./test.jpg", target_size=inputShape)<br/>image = img_to_array(image)<br/>image = np.expand_dims(image, axis=0)<br/>image = preprocess(image)</span><span id="f60e" class="jo jp hi ku b fi lc kz l la lb">#predicting the output<br/>preds = model.predict(image)<br/>P = imagenet_utils.decode_predictions(preds)<br/>for (i, (imagenetID, label, prob)) in enumerate(P[0]):<br/> print("{}. {}: {:.2f}%".format(i + 1, label, prob * 100))</span></pre><h2 id="319d" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">3.单个对象检测(带边界框)</h2><p id="cb69" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated"><em class="ko">数据集在这里被创建。每个图像包含一个矩形作为对象。使用简单的神经网络。不需要GPU/互联网。</em></p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="474c" class="jo jp hi ku b fi ky kz l la lb">#importing libraries<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import matplotlib</span><span id="c647" class="jo jp hi ku b fi lc kz l la lb">#creating database<br/>num_imgs = 1000</span><span id="739d" class="jo jp hi ku b fi lc kz l la lb">img_size = 8<br/>min_object_size = 1<br/>max_object_size = 4<br/>num_objects = 1</span><span id="02aa" class="jo jp hi ku b fi lc kz l la lb">bboxes = np.zeros((num_imgs, num_objects, 4))<br/>imgs = np.zeros((num_imgs, img_size, img_size))  # set background to 0</span><span id="cbe4" class="jo jp hi ku b fi lc kz l la lb">for i_img in range(num_imgs):<br/>    for i_object in range(num_objects):<br/>        w, h = np.random.randint(min_object_size, max_object_size, size=2)<br/>        x = np.random.randint(0, img_size - w)<br/>        y = np.random.randint(0, img_size - h)<br/>        imgs[i_img, x:x+w, y:y+h] = 1.  # set rectangle to 1<br/>        bboxes[i_img, i_object] = [x, y, w, h]<br/>        <br/>imgs.shape, bboxes.shape</span><span id="d244" class="jo jp hi ku b fi lc kz l la lb">#plotting sample data<br/>i = 0<br/>plt.imshow(imgs[i].T, cmap='Greys', interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])<br/>for bbox in bboxes[i]:<br/>    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='r', fc='none'))</span><span id="b72c" class="jo jp hi ku b fi lc kz l la lb">#reshaping input<br/>X = (imgs.reshape(num_imgs, -1) - np.mean(imgs)) / np.std(imgs)<br/>X.shape, np.mean(X), np.std(X)</span><span id="2352" class="jo jp hi ku b fi lc kz l la lb">#reshaping output<br/>y = bboxes.reshape(num_imgs, -1) / img_size<br/>y.shape, np.mean(y), np.std(y)</span><span id="6677" class="jo jp hi ku b fi lc kz l la lb">#final training &amp; testing data<br/>i = int(0.8 * num_imgs)<br/>train_X = X[:i]<br/>test_X = X[i:]<br/>train_y = y[:i]<br/>test_y = y[i:]<br/>test_imgs = imgs[i:]<br/>test_bboxes = bboxes[i:]</span><span id="68ac" class="jo jp hi ku b fi lc kz l la lb">#creating deep network model<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D <br/>from keras.optimizers import SGD<br/>model = Sequential([<br/>        Dense(500, input_dim=X.shape[-1]),<br/>        Activation('relu'),<br/>        Dense(300), <br/>        Activation('relu'), <br/>        Dense(100), <br/>        Activation('relu'), <br/>        Dropout(0.2), <br/>        Dense(y.shape[-1])<br/>    ])<br/>model.compile('adadelta', 'mse')</span><span id="bd28" class="jo jp hi ku b fi lc kz l la lb">#training &amp; validating<br/>model.fit(train_X, train_y, nb_epoch=50, validation_data=(test_X, test_y), verbose=2)</span><span id="a393" class="jo jp hi ku b fi lc kz l la lb">#predicting on test data<br/>pred_y = model.predict(test_X)<br/>pred_bboxes = pred_y * img_size<br/>pred_bboxes = pred_bboxes.reshape(len(pred_bboxes), num_objects, -1)<br/>pred_bboxes.shape</span><span id="6f8b" class="jo jp hi ku b fi lc kz l la lb">#plotting the prediction<br/>plt.figure(figsize=(12, 3))<br/>for i_subplot in range(1, 6):<br/>    plt.subplot(1, 5, i_subplot)<br/>    i = np.random.randint(len(test_imgs))<br/>    plt.imshow(test_imgs[i].T, cmap='Greys', interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])<br/>    for pred_bbox, exp_bbox in zip(pred_bboxes[i], test_bboxes[i]):<br/>        plt.gca().add_patch(matplotlib.patches.Rectangle((pred_bbox[0], pred_bbox[1]), pred_bbox[2], pred_bbox[3], ec='r', fc='none'))</span></pre><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/a9d58265e9a745ffaf1ca919c67f85a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8CvNytQIK4PGxD52VHgcA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">样本输出</figcaption></figure><h2 id="bdad" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">4.多对象检测(带形状)</h2><p id="bd78" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated"><em class="ko">数据集在这里被创建。仔细阅读评论。不需要GPU/互联网。</em></p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="300a" class="jo jp hi ku b fi ky kz l la lb"># by Sujoy Kumar Goswami<br/># <br/># USE JUPYTER NOTEBOOK ONLY<br/>#<br/># Python(&gt;=3.6) &amp; Keras(&gt;=2.0)</span><span id="9289" class="jo jp hi ku b fi lc kz l la lb"># importing libraries<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import matplotlib</span><span id="b8ef" class="jo jp hi ku b fi lc kz l la lb"># creating dataset<br/># here 0-4 black objects (different shapes with random sizes) are placed in a noisy image (24 x 24). <br/># the image is divided into 4 quadrants (w.r.t. image center) &amp; each quadrant contains 0-1 object randomly.<br/># 4000 such images are taken.<br/># the objects with rectangular &amp; lower-triangular shapes are of our interest.<br/># the upper-traingular shapes are dummy.<br/># due to randomness few images may be blank or with upper-triangular shape (dummy object) only.<br/># bounding boxes of the interested objects are also saved.<br/>num_imgs = 4000<br/>img_size = 24<br/>min_rect_size = 3<br/>max_rect_size = 9<br/>max_num_objects = 5</span><span id="6692" class="jo jp hi ku b fi lc kz l la lb">bboxes = np.zeros((num_imgs, max_num_objects, 4))<br/>imgs = np.random.rand(num_imgs, img_size, img_size)<br/>shapes = np.zeros((num_imgs, max_num_objects, 1))</span><span id="ee1a" class="jo jp hi ku b fi lc kz l la lb">for i_img in range(num_imgs):<br/>    i_object = 0<br/>    if np.random.choice([True, False]):<br/>        width, height = np.random.randint(min_rect_size, max_rect_size, size=2)<br/>        x = np.random.randint(0, img_size/2 - width)<br/>        y = np.random.randint(0, img_size/2 - height)<br/>        imgs[i_img, x:x+width, y:y+height] = 1.<br/>        bboxes[i_img, i_object] = [x, y, width, height]<br/>        shapes[i_img, i_object] = [0]<br/>        i_object += 1<br/>    if np.random.choice([True, False]):<br/>        size = np.random.randint(min_rect_size, max_rect_size)<br/>        x, y = np.random.randint(img_size/2, img_size - size, size=2)<br/>        mask = np.tril_indices(size)<br/>        imgs[i_img, x + mask[0], y + mask[1]] = 1.<br/>        bboxes[i_img, i_object] = [x, y, size, size]<br/>        shapes[i_img, i_object] = [1]<br/>        i_object += 1<br/>    if np.random.choice([True, False]):<br/>        width, height = np.random.randint(min_rect_size, max_rect_size, size=2)<br/>        x = np.random.randint(img_size/2, img_size - width)<br/>        y = np.random.randint(0, img_size/2 - height)<br/>        imgs[i_img, x:x+width, y:y+height] = 1.<br/>        bboxes[i_img, i_object] = [x, y, width, height]<br/>        shapes[i_img, i_object] = [0]<br/>        i_object += 1<br/>    if np.random.choice([True, False]):<br/>        size = np.random.randint(min_rect_size, max_rect_size)<br/>        x = np.random.randint(0, img_size/2 - size)<br/>        y = np.random.randint(img_size/2, img_size - size)<br/>        mask = np.triu_indices(size)<br/>        imgs[i_img, x + mask[0], y + mask[1]] = 1.<br/>        #bboxes[i_img, i_object] = [x, y, size, size]<br/>        #shapes[i_img, i_object] = [1]<br/>        #i_object += 1<br/>    for i in range(i_object, max_num_objects):<br/>        bboxes[i_img, i] = [-1, -1, -1, -1]<br/>        shapes[i_img, i] = [-1]<br/>            <br/>imgs.shape, bboxes.shape</span><span id="138a" class="jo jp hi ku b fi lc kz l la lb"># plotting sample input data<br/># see 5 randomly chosen input images. the bounding boxes of interested objects are marked red.<br/>plt.figure(figsize=(24, 8))<br/>for i_subplot in range(1, 6):<br/>    plt.subplot(1, 5, i_subplot)<br/>    i = np.random.randint(num_imgs)<br/>    plt.imshow(imgs[i].T, cmap='Greys', interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])<br/>    for bbox, shape in zip(bboxes[i], shapes[i]):<br/>        plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='r', fc='none'))</span><span id="4f17" class="jo jp hi ku b fi lc kz l la lb"># pre-processing data<br/>X = (imgs.reshape(num_imgs, img_size, img_size, 1) - np.mean(imgs)) / np.std(imgs)<br/>y = np.concatenate([bboxes / img_size, shapes], axis=-1).reshape(num_imgs, -1)<br/>X.shape, y.shape</span><span id="a581" class="jo jp hi ku b fi lc kz l la lb"># final training &amp; testing data<br/>i = int(0.8 * num_imgs)<br/>train_X = X[:i]<br/>test_X = X[i:]<br/>train_y = y[:i]<br/>test_y = y[i:]<br/>test_imgs = imgs[i:]<br/>test_bboxes = bboxes[i:]</span><span id="ab05" class="jo jp hi ku b fi lc kz l la lb"># creating deep network model<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten<br/>from keras.optimizers import SGD<br/>model = Sequential([<br/>        Convolution2D(8, (3, 3), activation='relu', input_shape=(24, 24, 1)),<br/>        Convolution2D(8, (3, 3), activation='relu'),<br/>        MaxPooling2D(pool_size=(2, 2)),<br/>        Convolution2D(8, (3, 3), activation='relu'),<br/>        MaxPooling2D(pool_size=(2, 2)),<br/>        Flatten(),<br/>        Dense(3000),<br/>        Activation('relu'),<br/>        Dropout(0.3),<br/>        Dense(1500), <br/>        Activation('relu'), <br/>        Dense(500), <br/>        Activation('relu'),<br/>        Dropout(0.3),<br/>        Dense(50),<br/>        Activation('relu'),<br/>        Dense(y.shape[-1])<br/>    ])<br/>model.compile('adadelta', 'mse')</span><span id="d7dc" class="jo jp hi ku b fi lc kz l la lb"># training the model &amp; validating<br/>model.fit(train_X, train_y, nb_epoch=100, validation_data=(test_X, test_y), verbose=2)</span><span id="2d55" class="jo jp hi ku b fi lc kz l la lb"># predicting on test data<br/>pred_y = model.predict(test_X)<br/>pred_y = pred_y.reshape(len(pred_y), max_num_objects, -1)<br/>pred_bboxes = pred_y[..., :4] * img_size<br/>pred_shapes = pred_y[..., 4:5]<br/>pred_bboxes.shape, pred_shapes.shape</span><span id="c3d1" class="jo jp hi ku b fi lc kz l la lb"># plotting the predictions<br/># see 5 randomly chosen output predictions (in blue/ green shapes). <br/># note that no upper-triangular shape has got predicted.<br/># accuracy could be improved by other Deep Models or/and by tuning the various associated parameters/ variables/ methods.<br/>plt.figure(figsize=(24, 8))<br/>for i_subplot in range(1, 6):<br/>    plt.subplot(1, 5, i_subplot)<br/>    i = np.random.randint(len(test_X))<br/>    plt.imshow(test_imgs[i].T, cmap='Greys', interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])<br/>    for pred_bbox, pred_shape in zip(pred_bboxes[i], pred_shapes[i]):<br/>        if pred_shape[0] &lt;= 0.5:<br/>            plt.gca().add_patch(matplotlib.patches.Rectangle((pred_bbox[0], pred_bbox[1]), pred_bbox[2], pred_bbox[3], fc='b', alpha=0.5))<br/>        else:<br/>            xy = ([[pred_bbox[0]+pred_bbox[2], pred_bbox[1]+pred_bbox[3]],<br/>                    [pred_bbox[0]+pred_bbox[2], pred_bbox[1]],<br/>                    [pred_bbox[0], pred_bbox[1]]])<br/>            plt.gca().add_patch(matplotlib.patches.Polygon(xy, True, fc='g', alpha=0.5))</span></pre><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es le"><img src="../Images/bbf57d3f3777cd6b15203ea462cb9135.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I16NrHk2ulK6BC99_iKl0Q.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">随机输入样本</figcaption></figure><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es le"><img src="../Images/27c1e7730baf6e9ef0d6f22a1b6bebc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ShI5zQYlwbU-SVOXryFLTw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">样本随机输出</figcaption></figure><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="af15" class="jo jp hi ku b fi ky kz l la lb">References:</span><span id="14af" class="jo jp hi ku b fi lc kz l la lb">- <a class="ae lj" href="https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491" rel="noopener" target="_blank">https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491</a></span></pre><p id="1391" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">喜欢的请为帖子鼓掌，&amp;也来分享一下。保持连接，我将很快添加更多代码… </strong></p></div></div>    
</body>
</html>