<html>
<head>
<title>Methods to Interpreting Credit Model Predictions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释信用模型预测的方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/methods-to-interpreting-credit-model-predictions-8dbfb10db3d5?source=collection_archive---------16-----------------------#2019-12-08">https://medium.com/analytics-vidhya/methods-to-interpreting-credit-model-predictions-8dbfb10db3d5?source=collection_archive---------16-----------------------#2019-12-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/28e5b1301a41a59580cee5d37b1375f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YiqfIKfKVIdnQ1U-hyhMZw.jpeg"/></div></div></figure><div class=""/><blockquote class="iq"><p id="00e9" class="ir is ht bd it iu iv iw ix iy iz ja dx translated">~“就数学定律所指的现实而言，它们是不确定的；就它们是确定的而言，它们不是指现实。”~爱因斯坦</p></blockquote><p id="3325" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx ja hb bi translated">通过数学框架与人类可以理解的更高维度科学的结合，在时间上向前或向后移动在理论上是有效的。然而，过去可以被用来在某种程度上确定地引领未来，因为历史总是会重演。这种说法受制于人的本性，因为人是创造历史的主要因素，因此人的行为和行动也可以高度确定地预测。为了捕捉这些思维链，数学和统计模型是如何做出决策的基线，是使用过去模式来了解近期或未来的最佳工具。一种方法是根据使用if &amp; else可以淹没某条路径的场景(if和so)做出决策。使用这个概念，if和else框架可以扩展到某个决策。另一种方法是模仿人类的神经系统，该系统连接通过突触的信号细胞，并促使人类的身体移动，并促使大脑对身体部位做出决定。</p><h1 id="3ab3" class="jy jz ht bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">我们的使命宣言</h1><figure class="kx ky kz la fd hk er es paragraph-image"><div class="er es kw"><img src="../Images/5b1980c9aa9cf739671277f382905740.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*lcJqPx8gpzWyGKlabdgPHw.jpeg"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">解码我们的黑盒</figcaption></figure><p id="07cd" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">为了达到我们的目的，一家银行要求我们建立三个预测模型来预测贷款违约，它们如下:</p><ul class=""><li id="8f2c" class="lk ll ht jd b je lf ji lg jm lm jq ln ju lo ja lp lq lr ls bi translated">梯度推进模型</li></ul><p id="11b7" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">梯度推进模型</p><ul class=""><li id="bb03" class="lk ll ht jd b je lf ji lg jm lm jq ln ju lo ja lp lq lr ls bi translated">神经网络</li><li id="b08a" class="lk ll ht jd b je lt ji lu jm lv jq lw ju lx ja lp lq lr ls bi translated">逻辑回归</li></ul><p id="8d8b" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">然后，银行向我们提供了贷款违约的数据集(过去的数据),用于训练和拟合我们的模型。该数据集将用作构建所述模型的过去信息，以基于数据将暴露给模型的特定模式或概率分离做出未来决策。在通过主流数据准备管道运行我们的数据之后，模型被训练、验证，然后在样本数据上进行测试。然后，目标是向银行展示几种技术，说明如何解释每种模型的决策或隐藏的问题解决模式。</p><pre class="kx ky kz la fd ly lz ma mb aw mc bi"><span id="45e7" class="md jz ht lz b fi me mf l mg mh">#Target variable <br/>loan_status = {'Current': 1, 'Fully Paid':1, 'Late (31-120 days)':0, 'In Grace Period': 1, 'Charged Off': 0, 'Late (16-30 days)': 1, 'Default':0,'Does not meet the credit policy. Status:Fully Paid': 1, 'Does not meet the credit policy. Status:Charged Off':0}</span></pre><figure class="kx ky kz la fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mi"><img src="../Images/a74b2a765ae399ecbca642cf8d2ff876.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PG2PPPExsxBlyfChlJGMkg.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">任何预测模型的建模过程</figcaption></figure></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="3d5b" class="jy jz ht bd ka kb mq kd ke kf mr kh ki kj ms kl km kn mt kp kq kr mu kt ku kv bi translated">模型解释</h1><h2 id="90be" class="md jz ht bd ka mv mw mx ke my mz na ki jm nb nc km jq nd ne kq ju nf ng ku nh bi translated">梯度推进分类模型</h2><figure class="kx ky kz la fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ni"><img src="../Images/a2e0b13b56b3eecfa4bbff6ae11a02f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wR-Xq6E084JGi_w6qSXPHg.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">梯度推进模型决策过程</figcaption></figure><p id="fec4" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">boosting模型是一个集合树模型，其中基础学习者是依赖的。每个基础学习器都是建立在来自先前迭代的模型误差上的。在梯度增强模型中，梯度增强通过沿梯度方向移动来最小化误差。</p><p id="99fb" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">为了解释我们的梯度推进模型，可以使用三种技术向银行展示。</p><ul class=""><li id="535e" class="lk ll ht jd b je lf ji lg jm lm jq ln ju lo ja lp lq lr ls bi translated">简单的决策树</li><li id="6710" class="lk ll ht jd b je lt ji lu jm lv jq lw ju lx ja lp lq lr ls bi translated">符合决策树GBM的预测</li><li id="464e" class="lk ll ht jd b je lt ji lu jm lv jq lw ju lx ja lp lq lr ls bi translated">局部观测解释</li></ul><ol class=""><li id="02c3" class="lk ll ht jd b je lf ji lg jm lm jq ln ju lo ja nj lq lr ls bi translated">简单决策树:</li></ol><pre class="kx ky kz la fd ly lz ma mb aw mc bi"><span id="9822" class="md jz ht lz b fi me mf l mg mh">from sklearn.tree import DecisionTreeClassifier<br/>from IPython.display import Image  <br/>from sklearn.externals.six import StringIO  <br/>from sklearn.tree import export_graphviz<br/>import pydotplus<br/>#code to view my feature splitting using dtree<br/>import os<br/>os.environ['PATH'] = os.environ['PATH']+';'+os.environ['CONDA_PREFIX']+r"\Library\bin\graphviz"</span><span id="0b59" class="md jz ht lz b fi nk mf l mg mh">dt = DecisionTreeClassifier(max_depth = 5, random_state=1)</span><span id="72b8" class="md jz ht lz b fi nk mf l mg mh"># fitting the decision tree model on the training set<br/>dt.fit(X_train, y_train)</span><span id="3273" class="md jz ht lz b fi nk mf l mg mh">plt.figure(figsize=(25,25));</span><span id="4136" class="md jz ht lz b fi nk mf l mg mh">dot_data = StringIO()  <br/>export_graphviz(dt, out_file=dot_data,feature_names=X_train.columns,filled=True,rounded=True)</span><span id="9908" class="md jz ht lz b fi nk mf l mg mh">graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  <br/>Image(graph.create_png())</span></pre><figure class="kx ky kz la fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nl"><img src="../Images/57206f3fb35d6eb6e5ff39c102abea8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ugOnO3nU4WKLf_9LteLJQ.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">观察一个简单的决策树是如何将数据分割成最重要的变量的</figcaption></figure><p id="b133" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">2.在决策树上拟合GBMs预测</p><p id="4cd9" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">为了解释梯度推进模型，在简单决策树上拟合训练预测。</p><blockquote class="nm nn no"><p id="5c66" class="jb jc np jd b je lf jg jh ji lg jk jl nq lh jo jp nr li js jt ns lj jw jx ja hb bi translated">另一种方法是将梯度提升的类概率作为决策树中的一个特征进行堆叠。</p></blockquote><pre class="kx ky kz la fd ly lz ma mb aw mc bi"><span id="d42b" class="md jz ht lz b fi me mf l mg mh"># saving the predictions of Random Forest as new target<br/>new_target = GBModel.predict(X_train)</span><span id="3427" class="md jz ht lz b fi nk mf l mg mh"># defining the interpretable decision tree model<br/>dt_model = DecisionTreeClassifier(max_depth=5, random_state=1)</span><span id="7a77" class="md jz ht lz b fi nk mf l mg mh"># fitting the surrogate decision tree model using the training set and new target<br/>dt_model.fit(X_train,new_target)</span><span id="2f4c" class="md jz ht lz b fi nk mf l mg mh">plt.figure(figsize=(25,25));</span><span id="425d" class="md jz ht lz b fi nk mf l mg mh">dot_data_2 = StringIO()  <br/>export_graphviz(dt_model, out_file=dot_data_2,feature_names=X_train.columns,filled=True,rounded=True)</span><span id="5dd0" class="md jz ht lz b fi nk mf l mg mh">graph = pydotplus.graph_from_dot_data(dot_data_2.getvalue())  <br/>Image(graph.create_png())</span></pre><figure class="kx ky kz la fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nt"><img src="../Images/2e02620560fea73d65b2d91f505ea89c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B4eYLHkT5z4aYaHLXZrrfg.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">基于梯度推进预测的树拟合</figcaption></figure><p id="72b7" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">3.LIME(本地可解释模型不可知解释)</p><p id="ceec" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">莱姆解释了一个局部的观察，在这个被解释的预测的附近。当银行希望检查某个客户的预测过程时，该软件包非常有用，可以了解某些变量如何影响接受或拒绝该客户的可能性。例如，如果利率对拒绝客户有影响，则在特定情况下减少/增加。</p><blockquote class="nm nn no"><p id="f0ca" class="jb jc np jd b je lf jg jh ji lg jk jl nq lh jo jp nr li js jt ns lj jw jx ja hb bi translated">源代码:<a class="ae nu" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">https://github.com/marcotcr/lime</a></p></blockquote><pre class="kx ky kz la fd ly lz ma mb aw mc bi"><span id="d928" class="md jz ht lz b fi me mf l mg mh"># import Explainer function from lime_tabular module of lime library<br/>from lime.lime_tabular import LimeTabularExplainer</span><span id="2dfc" class="md jz ht lz b fi nk mf l mg mh"># creating the explainer function<br/>explainer = LimeTabularExplainer(X_train.values, mode="classification", feature_names=X_train.columns)</span><span id="9194" class="md jz ht lz b fi nk mf l mg mh"># fetching any observation <br/>customer = 52<br/>X_observation = X_test.iloc[[customer], :]</span><span id="262b" class="md jz ht lz b fi nk mf l mg mh">GBM_model.predict(X_observation)[0]</span><span id="8c9c" class="md jz ht lz b fi nk mf l mg mh">* 1 <br/># Model predicted Not Default<br/># explanation using the gradient boosting<br/>explanation = explainer.explain_instance(X_observation.values[0], best_model.predict_proba)<br/>explanation.show_in_notebook(show_table=True, show_all=False)</span></pre><figure class="kx ky kz la fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nv"><img src="../Images/66df4702adf35ad06bbc70598522c12f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hBG1bhqt66a_mxKaHJ-Acw.png"/></div></div></figure><p id="ca4c" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">负(蓝色)特征表示“0”(默认)，而正(橙色)特征表示“1”(无默认)。解释权重的方法是将它们应用于预测概率。例如，如果我们从数据中删除变量pymnt_plan_y、purpose_renewable_energy和grade_G，我们期望分类器以0.90–0.29–0.27–0.15 = 0.19(19%)的概率预测“1”(默认)。同样的，去掉分期，difference _ flag _ Y &amp; num _ TL _ 120 DPD _ 2m会把预测0的概率提高到0.1 + 0.15 + 0.05 + 0.04 = 0.34。</p><h2 id="c6fc" class="md jz ht bd ka mv mw mx ke my mz na ki jm nb nc km jq nd ne kq ju nf ng ku nh bi translated">神经网络模型</h2><figure class="kx ky kz la fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nw"><img src="../Images/4152e83e48dbf8a07f51d10c1f8f2f87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KB11LMi6WQv35VISCGwU-w.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">预测贷款违约的神经网络模型有两个隐藏层</figcaption></figure><p id="80a4" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">神经网络旨在模拟人类神经系统和大脑决策过程，是具有隐藏层的复杂模型，其特征是在每个隐藏层中设计新的变量。构成隐藏或输出图层中新要素的每个箭头都有一个权重。这些权重类似于线性或逻辑回归中的系数。然而，每一层都可以采用任何已知的激活(数学)函数来聚合来自先前特征的输入权重；这大大降低了大数据集的维度。权重是使用优化过程建立的，这基本上意味着它是从随机猜测开始的。</p><p id="b6a7" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">为了解释我们的神经网络模型，我们使用以下内容:</p><ul class=""><li id="b912" class="lk ll ht jd b je lf ji lg jm lm jq ln ju lo ja lp lq lr ls bi translated">新变量的层表示方案</li><li id="f632" class="lk ll ht jd b je lt ji lu jm lv jq lw ju lx ja lp lq lr ls bi translated">无隐层神经网络</li></ul><ol class=""><li id="7637" class="lk ll ht jd b je lf ji lg jm lm jq ln ju lo ja nj lq lr ls bi translated">内层表示:</li></ol><pre class="kx ky kz la fd ly lz ma mb aw mc bi"><span id="20ec" class="md jz ht lz b fi me mf l mg mh">NN_model.summary()</span><span id="afcc" class="md jz ht lz b fi nk mf l mg mh">*Model: "sequential_183"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>dense_547 (Dense)            (None, 5)                 420       <br/>_________________________________________________________________<br/>dense_548 (Dense)            (None, 5)                 30        <br/>_________________________________________________________________<br/>dense_549 (Dense)            (None, 1)                 6         <br/>=================================================================<br/>Total params: 456<br/>Trainable params: 456<br/>Non-trainable params: 0<br/>_________________________________________________________________</span><span id="adc4" class="md jz ht lz b fi nk mf l mg mh">import keras.backend as K<br/>inp = NN_model.layers[0].input<br/>out = NN_model.layers[1].output</span><span id="022e" class="md jz ht lz b fi nk mf l mg mh">features_function = K.function([inp], [out])<br/>features_NN = features_function([scaled_test[:6000]])[0]<br/>plt.figure(figsize=(70,30))<br/>plt.scatter(features_NN[:, 0], features_NN[:, 1], c=y_test, cmap='coolwarm')<br/>plt.legend()</span></pre><figure class="kx ky kz la fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nx"><img src="../Images/5c48f75933158465502cd0ceef1c5b77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SVVcltE_CAdgQlc0Po7QzA.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">缺省(0)和无缺省(1)类分离的内层表示</figcaption></figure><p id="6e54" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">在该图中，蓝色(0-负类)与红色(1-正类)明显分开。显然，存在一定的重叠，这也是模型中0类的F值为0.66左右，而1类的F值为0.96的原因。理解和可视化不同层的输出有助于解释哪一层导致了学习表示中的主要错误！特征尺寸应该减少到2-D而不是5-D。5-D特征表示是从2-D观察的，因此我们看到聚类数据点的形状的清晰轮廓。然而，要查看清晰的二维表示，应该通过PCA等方法降低特征的维度，但这超出了本文的范围，然而该表示用于解释神经网络隐藏层的目的。</p><p id="b949" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">2.只有输出层的神经网络</p><p id="9382" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">构建只有一个输出层的神经网络是一个具有许多隐藏层的更复杂的神经网络的解释性表示。如果没有指定隐藏层，并且随后输出的激活函数被设置为sigmoid函数，那么我们有一个逻辑回归模型，这是一个比具有许多隐藏层的完全连接的神经网络要简单得多的模型。</p><pre class="kx ky kz la fd ly lz ma mb aw mc bi"><span id="a3ee" class="md jz ht lz b fi me mf l mg mh">from sklearn.linear_model import LogisticRegression<br/>from keras.regularizers import l2<br/>from keras.optimizers import SGD</span><span id="390a" class="md jz ht lz b fi nk mf l mg mh">def build_logistic_regression_model():<br/>    model = Sequential()<br/>    model.add(Dense(units=1,kernel_initializer='glorot_uniform', activation='sigmoid',kernel_regularizer=l2(0.)))<br/>    model.compile(optimizer='sgd',<br/>                  loss='binary_crossentropy',<br/>                  metrics=['accuracy'])<br/>    return model<br/>print(classification_report(y_test,model_logit.predict(scaled_test)))<br/>*              precision    recall  f1-score   support<br/><br/>           0       0.71      0.34      0.46     85363<br/>           1       0.91      0.98      0.94    592829<br/><br/>    accuracy                           0.90    678192<br/>   macro avg       0.81      0.66      0.70    678192<br/>weighted avg       0.89      0.90      0.88    678192</span></pre><p id="a27b" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">无层神经网络的性能与神经网络模型的性能相差不远，如下所示:</p><pre class="kx ky kz la fd ly lz ma mb aw mc bi"><span id="154f" class="md jz ht lz b fi me mf l mg mh">y_pred_best = NN_model.predict(scaled_test)<br/>y_pred_best = (y_pred_best&gt;0.5)<br/>print(classification_report(y_test_select,y_pred_best))<br/>*precision    recall  f1-score   support<br/><br/>         0.0       0.90      0.52      0.66     85363<br/>         1.0       0.94      0.99      0.96    592829<br/><br/>    accuracy                           0.93    678192<br/>   macro avg       0.92      0.76      0.81    678192<br/>weighted avg       0.93      0.93      0.92    678192</span></pre><p id="3355" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">这验证了使用无层神经网络作为解释更复杂的深度学习框架的方法。</p><h2 id="0de2" class="md jz ht bd ka mv mw mx ke my mz na ki jm nb nc km jq nd ne kq ju nf ng ku nh bi translated">逻辑回归</h2><figure class="kx ky kz la fd hk er es paragraph-image"><div class="er es ny"><img src="../Images/0d2c1a9a9486a465c75e0145aec64350.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*TJsdoeqtnPQN436GVW569g.png"/></div></figure><p id="ab54" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">基于赔率的自然对数，称为Logit。如果我们的预测是分类的，则使用该模型，我们根据数据集中的变量计算Y属于某个类别的概率。</p><p id="3e98" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">逻辑回归(Logit)是二元结果最流行的线性模型。</p><p id="0ebe" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">因为它是一个线性模型，不像梯度推进或神经网络，因此它捕捉数据集中的线性关系，以预测客户是否违约。此外，它相当容易解释，简单地理解求解模型系数的最大似然法将使模型决策非常清楚，最终它是一个线性模型！</p><p id="4f78" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">然而，一个有趣的话题是，如何在SKLEARN的逻辑回归函数中模拟基于KERAS的无隐藏层且激活函数为sigmoid的神经网络。您可以在下面找到链接:</p><div class="hh hi ez fb hj nz"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/build-lookalike-logistic-regression-model-with-sklearn-and-keras-2b03c540cdd5"><div class="oa ab dw"><div class="ob ab oc cl cj od"><h2 class="bd hu fi z dy oe ea eb of ed ef hs bi translated">用SKlearn和Keras建立相似逻辑回归模型</h2><div class="og l"><h3 class="bd b fi z dy oe ea eb of ed ef dx translated">~如果你能细化到每一串颤动的数据，未来将是完全可预测的。~夏洛克</h3></div><div class="oh l"><p class="bd b fp z dy oe ea eb of ed ef dx translated">medium.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on hp nz"/></div></div></a></div><p id="6782" class="pw-post-body-paragraph jb jc ht jd b je lf jg jh ji lg jk jl jm lh jo jp jq li js jt ju lj jw jx ja hb bi translated">构建逻辑回归模型本身就是对神经网络的解释，因为如参考文章中所示，可以使用另一个内置了逻辑回归算法的包来模拟以sigmoid作为激活函数的简单神经网络(无隐藏层)。</p><h1 id="6223" class="jy jz ht bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">结论</h1><p id="c5c4" class="pw-post-body-paragraph jb jc ht jd b je oo jg jh ji op jk jl jm oq jo jp jq or js jt ju os jw jx ja hb bi translated">金融市场越来越复杂，促使市场从业者转向基于高级数学和统计技术的非线性模型，以捕捉金融系统中尚未发现的非线性关系。这些模型让我们看到了近期和未来如何做出改变银行收入、支出以及在某些情况下扩大生存的决策。因此，这些模型不会变得更复杂，因为提供的信贷产品比以前更加混合，更多的因素影响着一个人是否违约。因此，建立某些技术来解码这些模型将揭示它们的黑盒决策过程，以便判断性地观察所做的预测以及为达到这些预测所采取的一系列步骤。</p></div></div>    
</body>
</html>