<html>
<head>
<title>Walmart Sales Forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">沃尔玛销售预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/walmart-sales-forecasting-d6bd537e4904?source=collection_archive---------0-----------------------#2019-09-25">https://medium.com/analytics-vidhya/walmart-sales-forecasting-d6bd537e4904?source=collection_archive---------0-----------------------#2019-09-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4ab0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">简单的模型平均值可以利用问题(此处为销售)的性能和准确性，这在没有深度特征工程的情况下也是如此。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/78bd24cd107f8e84916fc9f4e1e27eaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h0R1nnA19Lrk2dpduah2Sg.jpeg"/></div></div></figure><h1 id="6d1d" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">介绍</h1><p id="dc9a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">预测公司未来的销售是战略规划最重要的方面之一。作为初学者，沃尔玛是最好的例子，因为它拥有最多的零售数据集。此外，沃尔玛也将这个销售预测问题用于招聘目的。</p><p id="c9d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">收集的数据范围从2010年到2012年，全国各地的45家沃尔玛商店被纳入这项分析。每个商店包含几个部门，我们的任务是预测每个商店的部门范围内的销售额。值得注意的是，我们也有外部数据，如每个商场所在区域的CPI、失业率和燃油价格，希望这些数据有助于我们进行更详细的分析。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kt"><img src="../Images/27eaf2278e29dc22a138afacfa0dad7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tgc5PuEaW36qa-60V7_KaA.jpeg"/></div></div></figure><h1 id="d77a" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">数据集概述</h1><p id="e95a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">这个数据集可以在kaggle网站上找到。这些数据集包含关于商店、部门、温度、失业、CPI、假日和降价的信息。</p><p id="c034" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">店铺:</strong> <br/> <em class="jd">店铺</em>:店铺编号。范围从1到45。<br/> <strong class="ih hj"> </strong> <em class="jd">类型</em>:三种类型的门店‘A’、‘B’或‘C’。<br/> <em class="jd">大小</em>:设置一个商店的大小将根据特定商店中的产品数量来计算，范围从34，000到210，000。</p><p id="4224" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">特征<em class="jd"> : <br/> </em> </strong> <em class="jd">温度</em>:该地区当周的温度。<br/> <em class="jd">燃料价格</em>:当周该地区的燃料价格。<br/> <em class="jd">降价1:5 </em>:表示降价的类型以及当周的可用数量。<br/> <em class="jd"> CPI </em> <strong class="ih hj"> : </strong>当周居民消费价格指数。<br/> <em class="jd">失业率</em>:商店所在区域当周的失业率。</p><p id="2dba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">销售<em class="jd"> : </em> </strong> <br/> <em class="jd">日期</em>:进行观察的那一周的日期。<br/> <em class="jd"> Weekly_Sales </em>:当周记录的销售额。<br/><em class="jd">Dept</em>:1-99之一，显示部门。<br/> <em class="jd"> IsHoliday </em>:一个布尔值，表示是否是假日周。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ku"><img src="../Images/0d3f052c6a34cb9730a2ba0b672be791.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OnfBRqqbj2xhZTVcg-YZIw.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">特征</figcaption></figure><p id="9bda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作为竞争的一部分，我们有421570个值用于训练，115064个值用于测试。但是我们将只处理421570个数据，因为我们有标签来测试模型的性能和准确性。</p><h1 id="8c35" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">数据操作</h1><ol class=""><li id="9b7e" class="kz la hi ih b ii ko im kp iq lb iu lc iy ld jc le lf lg lh bi translated">检查空值</li></ol><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="52a1" class="ln jr hi lj b fi lo lp l lq lr">feat.isnull().sum()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ls"><img src="../Images/3413dac22f51418ebeb2c89f3aee1b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*ExaACur5A2isQa5oqPC6CA.png"/></div></figure><p id="62df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于CPI和失业率的NaN很少，因此我们用它们各自的列平均值填充缺失值。由于降价有更多的缺失值，我们分别在缺失的地方补零</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="484b" class="ln jr hi lj b fi lo lp l lq lr">from statistics import mean</span><span id="aa83" class="ln jr hi lj b fi lt lp l lq lr">feat['CPI'] = feat['CPI'].fillna(mean(feat['CPI']))<br/>feat['Unemployment'] = feat['Unemployment'].fillna(mean(feat['Unemployment']))<br/>feat['MarkDown1'] = feat['MarkDown1'].fillna(0)<br/>feat['MarkDown2'] = feat['MarkDown2'].fillna(0)<br/>feat['MarkDown3'] = feat['MarkDown3'].fillna(0)<br/>feat['MarkDown4'] = feat['MarkDown4'].fillna(0)<br/>feat['MarkDown5'] = feat['MarkDown5'].fillna(0)</span></pre><p id="818e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将所有特征与训练数据合并(添加)</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="6498" class="ln jr hi lj b fi lo lp l lq lr">new_data = pd.merge(feat, data, on=['Store','Date','IsHoliday'], how='inner')</span><span id="c0ee" class="ln jr hi lj b fi lt lp l lq lr"># merging(adding) all stores info with new training data<br/>final_data = pd.merge(new_data,stores,how='inner',on=['Store'])</span></pre><p id="929d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于数据是<strong class="ih hj">时间序列</strong>，我们将它们按升序排序，以便模型可以对历史数据执行。</p><p id="da06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在固定时间间隔内测量的任何指标都构成一个时间序列。由于工业需要和相关性，特别是时间序列的预测，时间序列的分析在商业上很重要。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="a4f0" class="ln jr hi lj b fi lo lp l lq lr"># sorting data with respect to date<br/>final_data = final_data.sort_values(by='Date')</span></pre><p id="46fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个被操作的数据集的维数是(421570，16)。</p><h1 id="5006" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">探索性数据分析</h1><p id="5ea0" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">共有3种类型的商店:A型、b型和c型<br/>共有45家商店。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="fb2b" class="ln jr hi lj b fi lo lp l lq lr">sizes=grouped.count()['Size'].round(1)<br/>print(sizes)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lu"><img src="../Images/df78b3c72a586c2169f360418586e984.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*WbDCAR88ZuhKr7uG-X1s4w.png"/></div></figure><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="ad2c" class="ln jr hi lj b fi lo lp l lq lr">labels = 'A store','B store','C store'<br/>sizes = [(22/(45))*100,(17/(45))*100,(6/(45))*100]</span><span id="a9aa" class="ln jr hi lj b fi lt lp l lq lr">fig1, ax1 = plt.subplots()<br/>ax1.pie(sizes, labels=labels, autopct='%1.1f%%',<br/>        shadow=True, startangle=90)<br/>ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.</span><span id="caf4" class="ln jr hi lj b fi lt lp l lq lr">plt.show()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lv"><img src="../Images/c3fb43a371065462847215e2863627e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*zt1d_4qLAGdQCyV2jc1ouQ.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">直观表示商店类型的饼图</figcaption></figure><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="7e16" class="ln jr hi lj b fi lo lp l lq lr"># boxplot for sizes of types of stores</span><span id="b4ad" class="ln jr hi lj b fi lt lp l lq lr">store_type = pd.concat([stores['Type'], stores['Size']], axis=1)<br/>f, ax = plt.subplots(figsize=(8, 6))<br/>fig = sns.boxplot(x='Type', y='Size', data=store_type)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lw"><img src="../Images/aad7ce648ff621795124a57df374f69b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hG6W2CcaRFKzQ1bMwJglsA.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">商店类型与规模的箱线图</figcaption></figure><ul class=""><li id="511d" class="kz la hi ih b ii ij im in iq lx iu ly iy lz jc ma lf lg lh bi translated">通过箱线图和饼图，我们可以说A型商店是最大的商店，C型商店是最小的</li><li id="6263" class="kz la hi ih b ii mb im mc iq md iu me iy mf jc ma lf lg lh bi translated">A、B和c之间没有大小重叠的区域</li></ul><p id="7156" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不同类型商店的周销售额箱线图:</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="fdac" class="ln jr hi lj b fi lo lp l lq lr">store_sale = pd.concat([stores['Type'], data['Weekly_Sales']], axis=1)<br/>f, ax = plt.subplots(figsize=(8, 6))<br/>fig = sns.boxplot(x='Type', y='Weekly_Sales', data=store_sale, showfliers=False)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mg"><img src="../Images/010138b917c9b26ea070d8de326d94a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ksX_VwtT7buQzZzbRMD_5A.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">商店类型与每周销售额的箱线图</figcaption></figure><ul class=""><li id="eda1" class="kz la hi ih b ii ij im in iq lx iu ly iy lz jc ma lf lg lh bi translated">A的中值最高，C的中值最低，即商店规模越大，销售额越高</li></ul><p id="add0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假日销售比非假日销售多一点</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="4127" class="ln jr hi lj b fi lo lp l lq lr"># total count of sales on holidays and non holidays<br/>print('sales on non-holiday : ',data[data['IsHoliday']==False]['Weekly_Sales'].count().round(1))<br/>print('sales on holiday : ',data[data['IsHoliday']==True]['Weekly_Sales'].count().round(1))</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mh"><img src="../Images/1ea059fb9b2beb3384bb9b1f371e096c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9EM8M5pHBQ68DsVSxmXyaA.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">假日/非假日与每周销售额的箱线图</figcaption></figure><h2 id="9b37" class="ln jr hi bd js mi mj mk jw ml mm mn ka iq mo mp ke iu mq mr ki iy ms mt km mu bi translated">特征之间的相关性:</h2><p id="d147" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">相关性是一种双变量分析，用于衡量两个变量之间的关联强度和关系方向。就关系的强度而言，相关系数的值在+1和-1之间变化。</p><p id="c7bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">值为1表示两个变量之间的完美关联程度。随着相关系数值趋向于0，两个变量之间的关系将变弱。关系的方向由系数的符号表示；加号表示正相关，减号表示负相关。通常，在统计学中，我们测量四种类型的相关性:皮尔逊相关性、肯德尔等级相关性和斯皮尔曼相关性。下面的图表会给你一个关于相关性的概念。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="2913" class="ln jr hi lj b fi lo lp l lq lr"># Plotting correlation between all important features<br/>corr = final_data.corr()<br/>plt.figure(figsize=(15, 10))<br/>sns.heatmap(corr, annot=True)<br/>plt.plot()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mv"><img src="../Images/f68c302ac9882bae37ad05e7958c64f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8j_TEQxBOKycyun_ymksKA.png"/></div></div></figure><h1 id="23d9" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">将日期拆分为要素</h1><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="b806" class="ln jr hi lj b fi lo lp l lq lr"># Add column for year<br/>final_data["Year"] = pd.to_datetime(final_data["Date"], format="%Y-%m-%d").dt.year<br/>final_test_data["Year"] = pd.to_datetime(final_test_data["Date"], format="%Y-%m-%d").dt.year</span><span id="26a9" class="ln jr hi lj b fi lt lp l lq lr"># Add column for day<br/>final_data["Day"] = pd.to_datetime(final_data["Date"], format="%Y-%m-%d").dt.day<br/>final_test_data["Day"] = pd.to_datetime(final_test_data["Date"], format="%Y-%m-%d").dt.day</span><span id="54b9" class="ln jr hi lj b fi lt lp l lq lr"># Add column for days to next Christmas<br/>final_data["Days to Next Christmas"] = (pd.to_datetime(final_data["Year"].astype(str)+"-12-31", format="%Y-%m-%d") -<br/>                                   pd.to_datetime(final_data["Date"], format="%Y-%m-%d")).dt.days.astype(int)<br/>final_test_data["Days to Next Christmas"] = (pd.to_datetime(final_test_data["Year"].astype(str) + "-12-31", format="%Y-%m-%d") -<br/>                                   pd.to_datetime(final_test_data["Date"], format="%Y-%m-%d")).dt.days.astype(int)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mw"><img src="../Images/1802c3fb4cfd1760ce4dd6a4239d467e.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*9R6NgqStEAssACkRLmCIpQ.png"/></div></div></figure><h1 id="afed" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">将商店类型拆分为分类特征。</h1><p id="5b96" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">因为我们有三种类型的商店(A、B和C ),它们是分类的。因此将wach类型作为一个特征拆分成一个热码编码</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mx"><img src="../Images/0f32842c9e18d835610610a453242405.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*xsu5e16SeDZjxpOtTzT21Q.png"/></div></figure><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="26e1" class="ln jr hi lj b fi lo lp l lq lr">tp = pd.get_dummies(X.Type)<br/>X = pd.concat([X, tp], axis=1)<br/>X = X.drop(columns='Type')</span></pre><p id="cd84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们总共有15个特征:<br/> -商店<br/> -温度<br/> -燃料价格<br/> - CPI <br/> -失业<br/> -部门<br/> -规模<br/> -假期<br/> -降价3 <br/> -年份<br/> -天数<br/> -临近圣诞节的天数<br/> - A、B、C</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es my"><img src="../Images/5fd495ffd19544195f90757096414d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1mYeVbXUjWZYBS56NifK_w.png"/></div></div></figure><h1 id="4ccc" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">构建训练测试集</h1><p id="03ec" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">将最终数据分为训练和测试。我们保留了80%的训练数据和20%的测试数据。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="1fa1" class="ln jr hi lj b fi lo lp l lq lr">#train-test split<br/>X_train,X_test,y_train,y_test=train_test_split( X, y, test_size=0.20, random_state=0)</span></pre><p id="ee3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在421570个特征中，训练数据包括337256个特征，测试数据包括84314个特征。</p><h1 id="546e" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">机器学习模型</h1><p id="f20d" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我们将使用不同的模型来测试准确性，并将最终训练整个数据来检查与kaggle竞争的分数。</p><p id="e992" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">标准化训练和测试数据:</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="386a" class="ln jr hi lj b fi lo lp l lq lr">from sklearn.preprocessing import StandardScaler<br/>sc_X = StandardScaler()<br/>X_train = sc_X.fit_transform(X_train)<br/>X_test = sc_X.transform(X_test)</span></pre><p id="57ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1) KNN回归量</strong></p><p id="ee69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我遇到的所有机器学习算法中，KNN无疑是最容易上手的。KNN可用于分类和回归问题。该算法使用“<strong class="ih hj">特征相似度</strong>来预测任何新数据点的值。这意味着根据新点与训练集中的点的相似程度为其赋值。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="7ace" class="ln jr hi lj b fi lo lp l lq lr">from sklearn.metrics import mean_absolute_error<br/>from sklearn.neighbors import KNeighborsRegressor<br/>knn = KNeighborsRegressor(n_neighbors=10,n_jobs=4)<br/>knn.fit(X_train,y_train)<br/>y_pred = knn.predict(X_test)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mz"><img src="../Images/c54f0be1a9000a90e52d9bf3b2df51c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*IQzKNFkeQ5oDnbOcvAORpw.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">预测值的散点图</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es na"><img src="../Images/2fb04998dbe3c7b8e1f4c862632522ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*XxLf9ElQsirLysfX7ltWLA.png"/></div></figure><p id="8c71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准确度误差为:56.4656386566686</p><p id="7ec1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2)决策树正则器</strong></p><p id="9ea0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树以树结构的形式建立回归或分类模型。它将一个数据集分解成越来越小的子集，同时一个相关的决策树被增量开发。最终的结果是一个有<strong class="ih hj">决策节点</strong>和<strong class="ih hj">叶节点</strong>的树。决策节点(例如，Outlook)具有两个或多个分支(例如，晴天、阴天和雨天)，每个分支代表所测试的属性值。叶节点(例如，玩的小时数)代表关于数字目标的决策。对应于称为<strong class="ih hj">根节点</strong>的最佳预测器的树中的最高决策节点。决策树可以处理分类数据和数值数据。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="3ce2" class="ln jr hi lj b fi lo lp l lq lr">from sklearn.tree import DecisionTreeRegressor<br/>dt = DecisionTreeRegressor(random_state=0)<br/>dt.fit(X_train,y_train)<br/>y_pred = dt.predict(X_test)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es nb"><img src="../Images/dfc5dbe5579c59b785ae3a7892e8da24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*pGBXX83RXAZ_9pDOHgx3Jw.png"/></div></figure><p id="db99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">DTR准确率:96.20101070234142 %</p><p id="e32b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3)随机森林回归器</strong></p><p id="4c41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随机森林是一种装袋技术，而不是助推技术。随机森林中的树是并行运行的。它通过在训练时构建大量决策树并输出类来运行，该类是各个树的类(分类)或均值预测(回归)的模式。每个节点上可分割的特征数量被限制为总数的某个百分比(称为超参数)</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="48a7" class="ln jr hi lj b fi lo lp l lq lr"># After Hyper-parameter tunning <br/>rfr = RandomForestRegressor(n_estimators = 400,max_depth=15,n_jobs=5)        <br/>rfr.fit(X_train,y_train)<br/>y_pred=rfr.predict(X_test)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es nc"><img src="../Images/23c87fd835928f2c7fb84634d60bcbe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*TzTYiONpTJBg4mW--7nyGw.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es nd"><img src="../Images/cc389309d24bd5aa7feed5b15be1f137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*zE4zc2pjaq-DobOg580sRw.png"/></div></figure><p id="b488" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RandomForestRegressor的准确度:96.768678686887</p><p id="8543" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">4)xgb回归器</strong></p><p id="5fdd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">XGBoost(极限梯度增强)是梯度增强算法的高级实现。XGBRegressor处理稀疏数据。XGBoost有一个分布式加权分位数草图算法，可以有效地处理加权数据。为了加快计算速度，XGBoost可以利用CPU上的多个内核。这是可能的，因为其系统设计中的块结构。数据被分类并存储在称为块的内存单元中。超参数是客观的，n估计量，最大深度，学习率。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="c407" class="ln jr hi lj b fi lo lp l lq lr">xgb_clf = XGBRegressor(objective='reg:linear', nthread= 4, n_estimators= 500, max_depth= 6, learning_rate= 0.5) <br/>xb = xgb_clf.fit(X_train,y_train)<br/>y_pred=xgb_clf.predict(X_test)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ne"><img src="../Images/794b3a8f79c3118cecdfee618e48af59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*xoGeTHAGr2s6d9x3qVXI2g.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es nf"><img src="../Images/fc5694f0c9545dcc18fc5a7b540cc047.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*bAskDcSMduEOK__osUTF_w.png"/></div></figure><p id="279d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">xgb回归方程的精度:97.2971075%</p><p id="977f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4)提取树回归量</strong></p><p id="bbf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">额外树方法(代表<strong class="ih hj"> ext </strong> remely <strong class="ih hj"> ra </strong>随机化<strong class="ih hj">树</strong> s)被提出，其主要目标是在数字输入特征的背景下进一步随机化树构建，其中最佳切割点的选择对诱导树的大部分方差负责。对于随机森林，该方法放弃了使用学习样本的自举副本的想法，并且不是试图在每个节点为K个随机选择的特征中的每一个寻找最佳切割点，而是随机选择切割点。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="8b80" class="ln jr hi lj b fi lo lp l lq lr">from sklearn.ensemble import ExtraTreesRegressor<br/>etr = ExtraTreesRegressor(n_estimators=30,n_jobs=4) <br/>etr.fit(X_train,y_train)<br/>y_pred=etr.predict(X_test)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ng"><img src="../Images/1f06b68a6a51e2664da8761987a0dad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9WA105mjcLqCkt0QslFmLA.png"/></div></div></figure><p id="7d94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回归方程的准确度:96.8986868686886</p><p id="b068" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">所有车型对比:</strong></p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="0145" class="ln jr hi lj b fi lo lp l lq lr">from prettytable import PrettyTable<br/>    <br/>x = PrettyTable()</span><span id="ff10" class="ln jr hi lj b fi lt lp l lq lr">x.field_names = ["Model", "MAE", "RMSE", "Accuracy"]</span><span id="5373" class="ln jr hi lj b fi lt lp l lq lr">x.add_row(["Linear Regression (Baseline)", 14566, 21767, 8.89])<br/>x.add_row(["KNNRegressor", 8769, 14991, 56.87])<br/>x.add_row(["DecisionTreeRegressor", 2375, 7490, 96.02])<br/>x.add_row(["RandomForestRegressor", 1854, 5785, 96.56])<br/>x.add_row(["ExtraTreeRegressor", 1887, 5684, 96.42])<br/>x.add_row(["XGBRegressor", 2291, 5205,97.23 ])</span><span id="7bbd" class="ln jr hi lj b fi lt lp l lq lr">print(x)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es nh"><img src="../Images/d73276709bf8fa620301371be1a9e3bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rny0KlgjSakroKAaJuP2ag.png"/></div></div></figure><h1 id="fe08" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">获取最佳模型的平均值</h1><p id="8c37" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">诀窍是获得前n个最佳模型的平均值。前n个模型由它们的精度和rmse决定。这里我们选取了4个模型，因为它们的准确率都在95%以上。这些模型是DecisionTreeRegressor、RandomForestRegressor、XGBRegressor和ExtraTreesRegressor。</p><p id="33c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，只拿顶级模特不代表不超配。这可以通过检查RMSE或梅来验证。在分类问题的情况下，我们可以使用混淆矩阵。还有，测试精度和训练精度应该不会有太大差别。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="de1c" class="ln jr hi lj b fi lo lp l lq lr"># training top n models<br/>dt = DecisionTreeRegressor(random_state=0)<br/>etr = ExtraTreesRegressor(n_estimators=30,n_jobs=4) <br/>xgb_clf = XGBRegressor(objective='reg:linear', nthread= 4, n_estimators= 500, max_depth= 6, learning_rate= 0.5) <br/>rfr = RandomForestRegressor(n_estimators = 400,max_depth=15,n_jobs=4)</span><span id="f9d1" class="ln jr hi lj b fi lt lp l lq lr">dt.fit(X_train,y_train)<br/>etr.fit(X_train,y_train)<br/>xgb_clf.fit(X_train,y_train)<br/>rfr.fit(X_train,y_train)</span><span id="2cf0" class="ln jr hi lj b fi lt lp l lq lr"># predicting on test data<br/>etr_pred=etr.predict(X_test)<br/>xgb_clf_pred=xgb_clf.predict(X_test)<br/>rfr_pred=rfr.predict(X_test)<br/>dt_pred = dt.predict(X_test)</span></pre><p id="2996" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">获取模型的平均值:</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="a977" class="ln jr hi lj b fi lo lp l lq lr">final = (etr_pred + xgb_clf_pred + rfr_pred + dt_pred)/4.0</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ni"><img src="../Images/5b68929d92b270ba8659858fefbbf56e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*obaAFPs8pkIuMF6V2cP8Mw.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">最终模型的预测</figcaption></figure><h1 id="e9cf" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">结论</strong></h1><p id="719a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">这里我们可以看到，与我们表现最好的单一模型(即RMSE为3804的XGBRegressor)相比，我们的RMSE降低了。因此，我们可以得出结论，取前n个模型的平均值有助于减少损失。</p><p id="840b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于此处可用数据较少，因此损失差异并不显著。但是在以千兆字节和兆兆字节为单位的大型数据集中，这种简单平均的技巧可以在很大程度上减少损失。</p><p id="46bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Kaggle分数</strong></p><p id="2a4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，在没有将整个数据分割成训练测试的情况下，在相同的数据上训练它，并在kaggle提供的未来数据上测试它，得到的分数在3000 <strong class="ih hj">的范围内，而没有</strong>太多深入的特征工程和严格的超调。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es nj"><img src="../Images/61b7a5dd1fedef2517392c203520e088.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*41Uy2BFiIyniN6xynkugcQ.png"/></div></div></figure><h1 id="e1c0" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">未来工作</strong></h1><ul class=""><li id="8dfb" class="kz la hi ih b ii ko im kp iq lb iu lc iy ld jc ma lf lg lh bi translated">将日期功能修改为日、月、周。</li><li id="0e0a" class="kz la hi ih b ii mb im mc iq md iu me iy mf jc ma lf lg lh bi translated">该数据集包括特殊场合，如圣诞节、圣诞节前、黑色星期五、劳动节等。在这些日子里，人们往往比平时购物更多。因此，将这些作为一个特征添加到数据中也将在很大程度上提高准确性。</li><li id="9988" class="kz la hi ih b ii mb im mc iq md iu me iy mf jc ma lf lg lh bi translated">此外，在训练数据和测试数据之间存在一个缺失值差距，这两个数据具有两个特征，即CPI和失业。如果该差距减小，那么性能也可以提高。</li></ul><p id="4754" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献:</strong></p><div class="nk nl ez fb nm nn"><a href="https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/discussion/8055#latest-209789" rel="noopener  ugc nofollow" target="_blank"><div class="no ab dw"><div class="np ab nq cl cj nr"><h2 class="bd hj fi z dy ns ea eb nt ed ef hh bi translated">沃尔玛招聘-商店销售预测</h2><div class="nu l"><h3 class="bd b fi z dy ns ea eb nt ed ef dx translated">下载数千个项目的开放数据集+在一个平台上共享项目。探索热门话题，如政府…</h3></div><div class="nv l"><p class="bd b fp z dy ns ea eb nt ed ef dx translated">www.kaggle.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob jo nn"/></div></div></a></div><p id="011a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">感谢您的关注和阅读我的作品</strong></p><p id="893c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你喜欢这个故事，与你的朋友和同事分享吧！</p><p id="2fc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另外，<strong class="ih hj">请在</strong>关注我</p><div class="nk nl ez fb nm nn"><a href="https://www.linkedin.com/in/aditya-bhosle-07b0a9146" rel="noopener  ugc nofollow" target="_blank"><div class="no ab dw"><div class="np ab nq cl cj nr"><h2 class="bd hj fi z dy ns ea eb nt ed ef hh bi translated">瓦霍迪亚宇宙技术与管理研究所。</h2><div class="nu l"><h3 class="bd b fi z dy ns ea eb nt ed ef dx translated">查看Aditya Bhosle在世界上最大的职业社区LinkedIn上的个人资料。Aditya的教育列在…</h3></div><div class="nv l"><p class="bd b fp z dy ns ea eb nt ed ef dx translated">www.linkedin.com</p></div></div></div></a></div></div></div>    
</body>
</html>