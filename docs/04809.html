<html>
<head>
<title>Hyper-parameters tuning practices: learning rate, batch size, momentum, and weight decay.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超参数调整实践:学习率、批量大小、动量和重量衰减。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hyper-parameters-tuning-practices-learning-rate-batch-size-momentum-and-weight-decay-4b30f3c19ae8?source=collection_archive---------5-----------------------#2020-04-01">https://medium.com/analytics-vidhya/hyper-parameters-tuning-practices-learning-rate-batch-size-momentum-and-weight-decay-4b30f3c19ae8?source=collection_archive---------5-----------------------#2020-04-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ed34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">莱斯利·n·史密斯的技术报告【1】的评论。</p><p id="156b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过网格搜索或随机搜索来调整深度学习(DL)模型的超参数在计算上是昂贵且耗时的。本技术报告给出了选择最佳超参数的几个实用建议和步骤。</p><p id="07b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">充分理解本技术报告的一些先验知识:</p><ol class=""><li id="23f9" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">过度拟合/欠拟合</li><li id="b157" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">学习率</li><li id="e65a" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">批量大小(BS)</li><li id="dd9e" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">动力</li><li id="e0aa" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">重量衰减</li></ol></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="a596" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">目标:</h1><p id="c3e5" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">查看调整超参数的方法，这些方法可以显著减少训练时间并提高性能。</p></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="4b68" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">哪里可以找到调整超参数的线索？</h1><p id="a124" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">测试/验证损失是网络收敛的一个很好的指标，应该检查其线索。在报告中，测试/验证损失用于提供对培训过程的见解，最终测试准确度用于比较绩效。</p><h1 id="7b7e" class="jz ka hi bd kb kc lc ke kf kg ld ki kj kk le km kn ko lf kq kr ks lg ku kv kw bi translated">超参数的影响</h1><p id="c4cf" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">一个良好调整的机器学习模型应该既不欠拟合也不过拟合。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div class="er es lh"><img src="../Images/3cd28e51ac903ad038740270c03352d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*I16ywET-JG2tu8iGlMTryA.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">来自技术报告[1]</figcaption></figure><p id="a730" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当模型容量不足时，它不能很好地适应数据的分布。当模型过于复杂时，会过度拟合数据的分布，泛化能力较低。</p><p id="04cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在实践中，我们提高模型的复杂度来拟合训练数据，并使用正则化技术来克服过拟合。下表总结了每个超参数的影响。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lt"><img src="../Images/6d0d173a186ad4720fcba24fccc689c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7EPpFBm6gMZuhJbY5CEPow.png"/></div></div></figure><p id="73f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong></p><p id="725d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">高水平的正则化量有助于减少过拟合，但是当超过限制时，它可能导致模型不稳定。所以我们必须平衡正规化的数量。</p><p id="64f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">一般原则:减少其他形式的正则化和学习率大的正则化使训练明显更有效率。</strong></p></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="0e7b" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">如何用给定的数据集和架构找到一组好的超参数？</h1><ol class=""><li id="947c" class="je jf hi ih b ii kx im ky iq ly iu lz iy ma jc jj jk jl jm bi translated">学习率(LR):进行学习率范围测试，找出最大学习率。</li><li id="6552" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">总批处理大小(TBS):大的批处理大小可以很好地工作，但是数量通常受到GPU内存的限制。</li><li id="6301" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">动量:动量值为0.99、0.97、0.95和0.9的短距离运行将快速显示动量的最佳值。</li><li id="f211" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">重量衰减(WD):这需要网格搜索来确定合适的量级。</li></ol><h1 id="25c2" class="jz ka hi bd kb kc lc ke kf kg ld ki kj kk le km kn ko lf kq kr ks lg ku kv kw bi translated">学习速度测验</h1><p id="41ca" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">在LR范围测试中，训练以小的学习率开始，在整个预训练过程中缓慢线性增加。当以小的学习速率开始时，网络开始收敛，并且随着学习速率的增加，网络最终变得太大，并且导致测试/验证损失增加和准确度降低。在这个极值的学习率是最大值。</p><p id="1652" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有几种方法可以选择最小学习速率界限:</p><ol class=""><li id="da67" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">比最大界限小3或4倍</li><li id="755a" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">如果仅使用一个循环，则比最大界限小10或20倍，</li><li id="e982" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">通过对具有一些初始学习率的数百次迭代的短测试，选择最大的一个，其允许收敛开始而没有过度拟合的迹象。</li></ol><h1 id="3e98" class="jz ka hi bd kb kc lc ke kf kg ld ki kj kk le km kn ko lf kq kr ks lg ku kv kw bi translated">重量衰减的网格搜索</h1><p id="2e72" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">当LR、BS和动量固定时，测试1e-3、1e-4、1e-5和0作为重量衰减值，并选择最佳值。</p></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="03ba" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">结论</h1><p id="1b27" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">这篇文章总结了:</p><ol class=""><li id="2b98" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">LR、BS、动量和WD的影响</li><li id="7df9" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">选择四个超参数的步骤</li></ol><blockquote class="mb mc md"><p id="c1df" class="if ig me ih b ii ij ik il im in io ip mf ir is it mg iv iw ix mh iz ja jb jc hb bi translated">如果你希望有更多的实验细节和解释，请阅读技术报告[1]。</p></blockquote></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><p id="c1c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考:</p><p id="d1d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[1]神经网络超参数的训练方法:第1部分—学习速率、批量大小、动量和权重衰减</p></div></div>    
</body>
</html>