<html>
<head>
<title>Address class imbalance easily with Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Pytorch轻松解决班级失衡问题</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/augment-your-data-easily-with-pytorch-313f5808fc8b?source=collection_archive---------2-----------------------#2020-04-29">https://medium.com/analytics-vidhya/augment-your-data-easily-with-pytorch-313f5808fc8b?source=collection_archive---------2-----------------------#2020-04-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hg hh ez fb hi hj er es paragraph-image"><div class="ab fe cl hk"><img src="../Images/6ad6976e7f2c97f2ca198a6e87cd86a5.png" data-original-src="https://miro.medium.com/v2/0*bTJw6nZAnelUHDHs"/></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">计算机视觉中的数据增强。图片的制作者名单为<a class="ae hr" href="https://mc.ai/data-augmentation-by-fastai-v1/" rel="noopener ugc nofollow" target="_blank"> fastai </a>。</figcaption></figure><div class=""/><blockquote class="ir is it"><p id="efe7" class="iu iv iw ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hv">注</strong>。这篇文章获得了很多评论。如果你确实喜欢它，请务必<strong class="ix hv">关注我</strong>了解更多。</p></blockquote><p id="c33c" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi jw translated">当您的模型过度拟合您的数据时，您能做些什么？当我们处理不平衡的数据集时，这个问题经常发生。如果您的数据集代表几个类，其中一个比其他的少得多，那么就很难了解代表这样一个小类的真正的底层分布。</p><p id="aa73" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">正如这篇必读的<a class="ae hr" href="https://arxiv.org/abs/1710.05381" rel="noopener ugc nofollow" target="_blank">论文</a>、<strong class="ix hv">中所解释的，解决几乎在所有分析场景中都占主导地位的类不平衡的方法是过采样。</strong>过采样应应用于完全消除不平衡的水平，而最佳欠采样率取决于不平衡的程度。与一些经典的机器学习模型相反，过采样不会导致CNN的过拟合。</p><p id="b5fc" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">在实践中，当训练机器学习模型时，人们将遵循一些关键步骤:</p><ol class=""><li id="e780" class="kf kg hu ix b iy iz jc jd jt kh ju ki jv kj js kk kl km kn bi translated">将数据分成一个训练/测试集(80%，20%)。</li><li id="c3bd" class="kf kg hu ix b iy ko jc kp jt kq ju kr jv ks js kk kl km kn bi translated">通过对训练数据进行拟合来训练机器学习模型。</li><li id="aab8" class="kf kg hu ix b iy ko jc kp jt kq ju kr jv ks js kk kl km kn bi translated">在测试集上评估性能。</li></ol><p id="6989" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">当使用深度学习架构时，通常会将训练数据分成几批，我们在训练期间将这些数据馈送给我们的神经网络。为了构建这样的批次，我们通常按照观察值集的均匀分布从训练集中随机抽样。</p><p id="124c" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">现在需要一些简单的统计数据。假设我们有一个包含两个类<em class="iw"> class_1 </em>和<em class="iw"> class_2 </em>的数据集。<strong class="ix hv">从<em class="iw"> class_1 </em>中随机抽取一个点的概率是多少？</strong></p><p id="033a" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">遵循点集合上的均匀分布，这样的概率很容易表达:</p><figure class="ku kv kw kx fd hj er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es kt"><img src="../Images/d364efcbcb72c91a6df42d9da2c44bd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtowsitgMSSjLhxxhuCZUA.png"/></div></div></figure><p id="824d" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">实际上，在二元问题中，当我们从一个类中得到的观察值比另一个类中得到的多得多时，就会出现类不平衡:</p><figure class="ku kv kw kx fd hj er es paragraph-image"><div class="er es lc"><img src="../Images/ae8869a25f1ac4b8b2ed8766c6d400e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*NC3UsSAWxmFPe_9N8TQP5g.png"/></div></figure><p id="fd61" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">因此，我们有:</p><figure class="ku kv kw kx fd hj er es paragraph-image"><div class="er es ld"><img src="../Images/2f60ec482c70db4af304fe91f2af5e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*O6KwMvYSNsDuL9fG6uuQwA.png"/></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">二元问题中的类别不平衡由从给定类别中得出观察值的不平衡可能性来描述。</figcaption></figure><p id="11a8" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">换句话说，从<em class="iw"> class_1 </em>比从<em class="iw"> class_2 </em>更有可能得出一个点。因为模型看得更少<em class="iw"> class_2 </em>，所以它不能从这样的类中学习有用的特征也就不足为奇了…</p><p id="35b9" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">现在，在深入编码之前，我们需要理解人工扩充数据时的一个关键思想。我们想要的是确保通过人为增加辅修班，我们有:</p><figure class="ku kv kw kx fd hj er es paragraph-image"><div class="er es le"><img src="../Images/88718d55d3448294c83d7c77ed033075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*LrDvb3gERxmC4pGvuvGFWQ.png"/></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">在扩充了我们的数据之后，我们的目标是使从每个类中抽取样本的可能性尽可能接近。</figcaption></figure><p id="b731" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">是时候了！让我们用Pytorch的<a class="ae hr" href="https://pytorch.org/docs/stable/_modules/torch/utils/data/sampler.html#WeightedRandomSampler" rel="noopener ugc nofollow" target="_blank"><em class="iw">weighted random sampler</em></a>来编码解决这个问题。</p><p id="ba85" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated"><strong class="ix hv">数据集</strong>:我们构建了一个数据集，其中包含来自<em class="iw"> class_major </em>的900个观察值(标记为0)和来自<em class="iw"> class_minor </em>的<em class="iw"> </em> 100个观察值(标记为1)。(90%, 10%)</p><figure class="ku kv kw kx fd hj er es paragraph-image"><div class="er es lf"><img src="../Images/61844d7292d7fffcd0cfc22915ab8f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*ltyrdFul4zI_iA63lEVuXA.png"/></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">我们数据集的样本。标签1对应于法语句子，标签0对应于英语句子。</figcaption></figure><figure class="ku kv kw kx fd hj er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lg"><img src="../Images/bcbe29f86f45940b5b11dc02891b1820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEy4_vgBNKONEi2o7u8NWw.png"/></div></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">具有文本数据和两类值0和1的不平衡数据集的类分布。我们有900个0类句子和100个1类句子。</figcaption></figure><p id="57de" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">假设我们构建了10批，每批100个句子，我们最终将得到平均10个第1类句子和90个第0类句子。</p><figure class="ku kv kw kx fd hj er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lh"><img src="../Images/48a32bf929f9050af5cc86bc31068d9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B2UPZA4Xz_5vzuzeiruXYw.png"/></div></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">每班分配10批，每批100句。红色代表小类，蓝色代表大类。我们可以清楚地看到每一批训练数据中的不平衡。0类的估计比例现在是90.5，1类的估计比例是9.5。</figcaption></figure><p id="9a1b" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated"><strong class="ix hv">我怎样才能轻松地重新平衡以上几点？</strong>让我们用Pytorch库写几行代码。</p><figure class="ku kv kw kx fd hj er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es li"><img src="../Images/e2166263e31acde07a87c3e0dfb6207a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PORnRkpDj67KXn4PMFFRNw.png"/></div></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">24行python魔术构建平衡批次。</figcaption></figure><p id="9f37" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">从上面我们可以看到<em class="iw"> WeightedRandomSampler </em>使用数组<em class="iw"> example_weights </em>对应于赋予每个类的权重。目标是给次要类分配更高的权重。这将通过从均匀分布移动到多项式分布来影响从每个类中提取点的可能性。</p><p id="f3b2" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">现在我们可以详细看看<em class="iw"> arr_batch中包含的批次，</em>每个批次实际应该有100个句子。出于形象化的目的，我们只关注这里的标签。</p><figure class="ku kv kw kx fd hj er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lj"><img src="../Images/fa493c762dfb81da18f33b3d9bd94db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vc9Ff9hynbpM7-NUsSpASg.png"/></div></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">0类的估计比例现在是51.4，1类的估计比例是48.6。</figcaption></figure><p id="d624" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">从上图中我们可以看到，我们现在有了平衡的数据批次。因此，在训练期间，我们的模型不会看到一个类比另一个类多得多，从而降低了过度拟合的风险。</p><p id="bc7c" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">总之，我们看到:</p><ol class=""><li id="8c8a" class="kf kg hu ix b iy iz jc jd jt kh ju ki jv kj js kk kl km kn bi translated">过采样是解决类不平衡的关键策略，因此降低了过度拟合的风险。</li><li id="9434" class="kf kg hu ix b iy ko jc kp jt kq ju kr jv ks js kk kl km kn bi translated">当数据集中存在类别不平衡时，从数据集中随机取样是个坏主意。</li><li id="c8cf" class="kf kg hu ix b iy ko jc kp jt kq ju kr jv ks js kk kl km kn bi translated">使用<a class="ae hr" href="https://pytorch.org/docs/stable/_modules/torch/utils/data/sampler.html#WeightedRandomSampler" rel="noopener ugc nofollow" target="_blank"> <em class="iw">加权随机抽样加权随机抽样器</em> </a>通过对次要类进行过抽样来重新平衡我们的训练数据类。</li></ol><p id="caec" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">在下一篇文章中，我们将深入研究<em class="iw"> WeightedRandomSampler </em>的实现，以便<strong class="ix hv">更好地理解加权方案</strong>。我们还将在一个简单的机器学习场景中应用过采样，并分析其对整体性能的影响。</p><p id="4083" class="pw-post-body-paragraph iu iv hu ix b iy iz ja jb jc jd je jf jt jh ji jj ju jl jm jn jv jp jq jr js hb bi translated">感谢阅读，如有任何反馈，请在下方留下评论！🤗</p></div></div>    
</body>
</html>