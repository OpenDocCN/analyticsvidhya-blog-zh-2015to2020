# Spark å¹¶è¡Œä½œä¸šæ‰§è¡Œ

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/spark-parallel-job-submission-38b41220397b?source=collection_archive---------0----------------------->

![](img/8dd7c094cf6a4df5e5387e8807183b66.png)

Spark ä»¥åˆ†è§£å¤§ä»»åŠ¡å’Œå¹¶è¡Œè¿è¡Œå•ä¸ªä»»åŠ¡è€Œé—»åã€‚ä½†æ˜¯ï¼Œè¿™å¹¶ä¸æ„å‘³ç€å®ƒå¯ä»¥å¹¶è¡Œè¿è¡Œä¸¤ä¸ªç‹¬ç«‹çš„ä½œä¸šã€‚æœ¬æ–‡å°†å¸®åŠ©æ‚¨æœ€å¤§é™åº¦åœ°æé«˜ Spark çš„å¹¶è¡Œæ€§ã€‚

## å¼‚æ­¥ç¼–ç¨‹

è¿™æ˜¯ä¸€ç§å¹¶è¡Œç¼–ç¨‹ï¼Œå…è®¸ä¸€ä¸ªå·¥ä½œå•å…ƒç‹¬ç«‹äºä¸»åº”ç”¨ç¨‹åºçº¿ç¨‹è¿è¡Œã€‚å½“å·¥ä½œå®Œæˆæ—¶ï¼Œå®ƒé€šçŸ¥ä¸»çº¿ç¨‹å·¥ä½œçº¿ç¨‹çš„å®Œæˆæˆ–å¤±è´¥ã€‚åœ¨ Scala ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ *Future* æ¥å®ç°è¿™ä¸€ç‚¹ã€‚

## Scala æœŸè´§

æœŸè´§æ˜¯ Scala ä¸­æ‰§è¡Œå¼‚æ­¥ç¼–ç¨‹çš„ä¸€ç§æ–¹å¼ã€‚ä¸€ä¸ª *Future* ä¸ºæ‚¨æä¾›äº†ä¸€ç§åœ¨ spark åº”ç”¨ç¨‹åºä¸­å¹¶å‘è¿è¡Œä½œä¸šçš„ç®€å•æ–¹æ³•ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬ç¼–å†™ Spark ä»£ç çš„é€šå¸¸æ–¹å¼ï¼Œç„¶åçœ‹çœ‹*æœªæ¥*èƒ½å¦‚ä½•å¸®åŠ©æˆ‘ä»¬ã€‚

```
*val* employee = spark.read.parquet("s3://****/employee")
*val* salary = spark.read.parquet("s3://****/salary")
*val* ratings = spark.read.parquet("s3://****/ratings")

*println*("Joining employee with salary")
employee.join(salary, Seq("employee_id"))
  .exportToS3AndJSON("s3://****/employee_salary")

*println*("Joining employee with ratings")
employee.join(ratings, Seq("employee_id"))
  .exportToS3AndJSON("s3://****/employee_ratings")
```

åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬è¯»å–äº† 3 ä¸ªæ•°æ®é›†â€”â€”å‘˜å·¥ã€å·¥èµ„å’Œè¯„çº§ã€‚

*   åœ¨ç¬¬ä¸€ä¸ªè¯­å¥ä¸­ï¼Œæˆ‘ä»¬åŸºäº Employee_ID è¿æ¥ Employee å’Œ Salary è¡¨ï¼Œå¹¶å°†ç»“æœä¿å­˜ä¸º parquet å’Œ JSON æ ¼å¼ã€‚
*   åœ¨ç¬¬äºŒä¸ªè¯­å¥ä¸­ï¼Œæˆ‘ä»¬åŸºäº Employee_ID è¿æ¥ Employee å’Œ Ratings è¡¨ï¼Œå¹¶å†æ¬¡ä»¥ parquet å’Œ JSON æ ¼å¼ä¿å­˜ç»“æœã€‚

ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªè¯­å¥æ²¡æœ‰ä»»ä½•å…³ç³»ï¼Œä½†æ˜¯ Spark ä¼šæŒ‰é¡ºåºè¿è¡Œå®ƒã€‚å¦‚æœä½ çœ‹ä¸€ä¸‹ Spark UI çš„å›¾ç‰‡ï¼Œä½ ä¼šå¯¹æ­¤æœ‰ä¸€ä¸ªæ›´å¥½çš„äº†è§£ã€‚

![](img/5728feddf07de60613c71b4874d31ea0.png)

Spark UI

ä½œä¸š ID 0 â€”é¦–å…ˆå¯åŠ¨å¹¶è¿è¡Œ 5.5 åˆ†é’Ÿï¼Œç¬¬ä¸€ä¸ªä½œä¸šå®Œæˆåï¼Œå°†å¼€å§‹ç¬¬äºŒä¸ªä½œä¸šï¼Œä¾æ­¤ç±»æ¨ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡æŸ¥çœ‹äº‹ä»¶æ—¶é—´è¡¨æ¥æ¨æ–­å‡ºåŒæ ·çš„ç»“è®ºã€‚æ‰€æœ‰ä½œä¸šéƒ½ä¸ä¼šé‡å ï¼Œæ¯ä¸ªä½œä¸šéƒ½æ˜¯åœ¨å‰ä¸€ä¸ªä½œä¸šå®Œæˆåæ‹¾å–çš„ã€‚

å¦‚æœä½œä¸š 0 åˆ©ç”¨äº† 50%çš„ç¾¤é›†ï¼Œåˆ™å‰©ä½™çš„ 50%å°†æœªè¢«åˆ©ç”¨ã€‚

è®©æˆ‘ä»¬äº†è§£å¦‚ä½•é€šè¿‡ä½¿ç”¨ scala futures æ¥æé«˜åˆ©ç”¨ç‡ã€‚ä¸‹é¢æ˜¯åŒæ ·çš„ä»£ç ï¼Œä½†æ˜¯åŠ å…¥äº†æœªæ¥çš„ã€‚

```
*import* java.util.concurrent.Executors
*import* scala.concurrent.duration.Duration
*import* scala.concurrent.{Await, ExecutionContext, Future}*//Allowing a maximum of 2 threads to run
val* executorService = Executors.*newFixedThreadPool*(2)
*implicit val* executionContext = ExecutionContext.*fromExecutorService*(executorService)*val* employee = spark.read.parquet("s3://****/employee")
*val* salary = spark.read.parquet("s3://****/salary")
*val* ratings = spark.read.parquet("s3://****/ratings")*val futureA = Future {
   println*("Joining employee with salary")
   employee.join(salary, Seq("employee_id"))
     .exportToS3AndJSON("s3://****/employee_salary")
   *println*("Future A Complete")
   }val futureB = Future {
   *println*("Joining employee with ratings")
   employee.join(ratings, Seq("employee_id"))
     .exportToS3AndJSON("s3://****/employee_ratings")
   *println*("Future B Complete")
   }Await.result(futureA, Duration.inf)
Await.result(futureB, Duration.inf)
```

è¿™äº›å˜åŒ–åŒ…æ‹¬

*   å¯¼å…¥ ExecutionContext ä»¥è®¿é—®çº¿ç¨‹æ± ã€‚
*   å®šä¹‰è¦è¿è¡Œçš„çº¿ç¨‹æ•°é‡ã€‚
*   å°†è½¬æ¢åŒ…å«åœ¨æœªæ¥çš„æ„é€ ä¸­ã€‚
*   Await.result æ–¹æ³•è°ƒç”¨å£°æ˜å®ƒå°†ç­‰å¾…æœªæ¥æ‰§è¡Œã€‚

è®©æˆ‘ä»¬é€šè¿‡æŸ¥çœ‹ Spark UI æ¥äº†è§£ä¸€ä¸‹è¿™é¡¹å·¥ä½œç°åœ¨æ˜¯å¦‚ä½•æ‰§è¡Œçš„ã€‚

![](img/33716f179e3639310b1734b5b205f6bf.png)

åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥çœ‹åˆ°ä½œä¸š 0 å’Œ 1 å‡ ä¹åŒæ—¶å¼€å§‹ã€‚æ‚¨è¿˜å¯ä»¥ä»äº‹ä»¶æ—¶é—´çº¿ä¸­çœ‹åˆ°ï¼Œè¿™ä¸¤ä¸ªä½œä¸šæ­£åœ¨å¹¶è¡Œè¿è¡Œã€‚

å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè¯·ç‚¹å‡»ğŸ‘æ‰€ä»¥å…¶ä»–äººä¼šåœ¨åª’ä½“ä¸Šçœ‹åˆ°å®ƒã€‚