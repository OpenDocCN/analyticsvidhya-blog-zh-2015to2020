<html>
<head>
<title>DCGAN, cGAN and SAGAN &amp; the CIFAR-10 dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DCGAN、CGAN和SAGAN &amp; CIFAR-10数据集</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/dcgan-cgan-and-sagan-the-cifar-10-dataset-206cbb851327?source=collection_archive---------7-----------------------#2020-03-31">https://medium.com/analytics-vidhya/dcgan-cgan-and-sagan-the-cifar-10-dataset-206cbb851327?source=collection_archive---------7-----------------------#2020-03-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/5e9b232f442cf830d1425c98ab7b0f20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D0mA7bhxDqug8-Zhscu4MA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自CIFAR-10数据集的图像。图片来源:<a class="ae iu" href="http://cs231n.github.io/classification/" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/classification/</a></figcaption></figure><p id="ecee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我的<a class="ae iu" rel="noopener" href="/@shrutibendale/intro-to-generative-adversarial-networks-ca1b14e524f4">上一篇博客</a>中，我谈到了生成性对抗网络。今天，我将谈论深度卷积gan、条件gan和自我关注gan，以及我如何在<a class="ae iu" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10数据集</a>上实现这些模型。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h2 id="bb29" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">深度卷积生成对抗网络；</h2><p id="2bd6" class="pw-post-body-paragraph iv iw hi ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">DCGAN引入了一系列架构指南，目标是稳定GAN训练。它提倡使用交错卷积，而不是合用层。此外，它对生成器和鉴别器网络都使用批量归一化(BN)。最后，它在发生器中使用ReLU和Tanh激活，在鉴别器中使用泄漏ReLU。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/f5ced7f87cafb26ee4ea3d0d4f62b0e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pFVs06l8Yc1Dva_kJ9PAnA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">DCGAN架构。<a class="ae iu" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="9379" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在DCGANs中，<strong class="ix hj">发生器</strong>由一系列转置卷积运算组成。这些操作接受随机噪声向量z，并通过逐渐增加其空间维度同时减少其特征体积深度来对其进行变换。<strong class="ix hj">鉴别器</strong>基本上是一个卷积神经网络。它的任务是对图像进行真伪分类。我们将生成器生成的图像与真实图像一起提供给鉴别器，鉴别器将图像分类为真实或伪造。我们计算鉴频器和发生器的损耗，并反向传播损耗，以改善发生器和鉴频器的性能。</p><p id="a303" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">型号:</strong></p><p id="abb0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">发生器使用Conv2DTranspose(上采样)层从种子(随机噪声)生成图像。我们使用一个密集层，将这个种子作为输入，然后向上采样几次，直到我们达到所需的32x32x3的图像大小。我们对每一层使用LeakyReLU激活，对最后一层使用tanh激活函数。</p><p id="367b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">鉴别器是基于CNN的图像分类器。我们使用鉴别器对生成的图像进行真假分类。该模型将被训练为对真实图像输出正值，对虚假图像输出负值。</p><p id="c054" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们用于实现DCGAN的生成器和鉴别器架构如下:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/a567eb0a954fb32127b183650af534d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*vQ1TCQe2NGcfjvI654iDIg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">发电机网络(左)和鉴别器网络(右)</figcaption></figure><p id="74a2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们使用<strong class="ix hj">二元交叉熵损失函数</strong>来计算发生器和鉴别器的损失。<br/> <strong class="ix hj">亚当优化器</strong>用于生成器和鉴别器。我们使用SA-GANs论文中实现的双时标学习率更新规则(<strong class="ix hj"> TTUR </strong>)，将生成器的学习率设置为0.0001，将鉴别器的学习率设置为0.0004。</p><p id="e153" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">训练:</strong></p><p id="4e41" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将来自CIFAR-10数据集的训练图像以64个为一批传递给训练循环中的生成器。生成器生成的图像与真实图像一起被传递到鉴别器。</p><p id="f697" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">鉴频器和发电机损耗使用以下代码片段计算:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/bc06ba33a53ec3dd47c267f4cdf43a69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yosLt5BUV1P6HT-8tM2PAw.png"/></div></div></figure><p id="402e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我对模型进行了大约3200个时期的训练，并记录了每个时期的发电机损耗和鉴频器损耗。我们还计算每10个时期的FID分数。3200个时期的损失图和FID分数图可在下图中看到。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/6101a5d7934f919e61f0ad3f084ed21b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*exeRI8zCakGAS6dDiWTQ8A.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">3200个时期的模型损失图(左)；3200个时期内模型的FID分数图</figcaption></figure><p id="7111" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">结果:</strong></p><p id="a84b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">DCGAN在3190年的<strong class="ix hj">时段生成的图像如下，我们在该时段获得了最好的FID分数<strong class="ix hj"> 69.09 </strong>:</strong></p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/c820e96b90c17c07a96000674e14a7a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PVHwIPlkPVpz2Y4r0xxSJA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">DCGAN生成的图像</figcaption></figure><p id="c183" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">模式崩溃:</strong></p><p id="516f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">观察到DCGAN产生许多相似的图像。这可以在下图中清楚地观察到。由于模式折叠，高亮显示的图像看起来非常相似:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/5d2bce2a3b8cfdf27cd9782babfdacd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jOl3tMss3flJSvxxlPsedw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">DCGAN中的模式崩溃</figcaption></figure><h2 id="8f74" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">自我关注生成对抗网络；</h2><p id="8f6a" class="pw-post-body-paragraph iv iw hi ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">生成对抗网络的自我注意是对生成对抗网络的一种改进。自关注gan具有允许生成器模拟远程依赖性的架构。主要思想是使生成器能够产生具有全局细节信息的样本。</p><p id="4c0d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">架构:</strong></p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/abd4d114305a67ae2f9429b6b749452e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4bLNQBfwq_ZVTOxCAN3cCQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">自我注意生成对抗网络。<a class="ae iu" href="https://arxiv.org/pdf/1805.08318.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="4858" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们在生成器和鉴别器中的卷积层之后添加了注意层。前一卷积层的输出输出维度(高度x宽度x通道)的卷积特征图。</p><p id="79bf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">给定卷积层L的输入特征，第一步是将L变换成3种不同的表示。我们使用1x1卷积来卷积L，以获得三个特征空间:f、g和h。特征向量f和g与h具有不同的维数。f和g使用的卷积滤波器比h少8倍。这里我们用f和g来计算关注度。为此，我们使用矩阵乘法线性组合f和g，并将结果送入softmax层。从这个操作中得到的张量就是‘注意力地图’。</p><p id="9928" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">为什么要用注意力？</strong></p><p id="5dd7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">传统的深度卷积gan无法捕捉图像中的长程相关性。这些传统的GANs适用于不包含大量结构和几何信息的图像。它们未能忠实地代表全球关系。这些非本地依赖关系始终出现在某些类别的图像中。例如，GANs可以用逼真的毛皮绘制动物图像，但往往无法绘制单独的脚。</p><p id="c130" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在SAGAN中，自我注意模块与卷积网络结合使用，并使用键值查询模型(Vaswani等人，2017)。该模块采用由卷积神经网络创建的特征图，并将其转换成三个特征空间。这些特征空间被称为键f(x)、值h(x)和查询g(x)，它们是通过将原始特征映射通过三个不同的1x1卷积映射来创建的。然后将关键字f(x)和查询g(x)矩阵相乘。接下来，对乘法结果的每一行应用softmax运算。从softmax生成的注意力地图识别网络应该关注图像的哪些区域。</p><p id="14ec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">型号:</strong></p><p id="27d0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">SAGAN架构类似于DCGAN架构，但在发生器的“conv2d_transpose_4”层和鉴频器的“conv2d_11”层之后添加了一个自定义“注意层”。</p><p id="9143" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我尝试使用<strong class="ix hj">铰链损耗</strong>函数和<strong class="ix hj">二元交叉熵损耗</strong>函数来计算SA-GAN论文中指定的发生器和鉴别器的损耗。</p><p id="9e79" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我还对生成器和鉴别器使用了<strong class="ix hj"> RMSprop优化器</strong>和<strong class="ix hj"> Adam优化器</strong>。</p><p id="5b74" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">我发现，当使用BCE损失和Adam优化器的组合时，我的模型给出了最佳输出和更好的FID分数。</strong>我们还使用SA-GANs论文中实现的双时标学习率更新规则(<strong class="ix hj"> TTUR </strong>)，将生成器的学习率设置为0.0001，将鉴别器的学习率设置为0.0004。</p><p id="33f2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">培训:</strong></p><p id="54b8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在对SAGAN模型进行200个时期的训练后，我们获得了以下损失和FID分数的图表。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/cb26527c09a4a95da326146b1eb55d00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c8WnkmV2u8qq1-D5NWKm-Q.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">200个时期内模型的损失图(左)；200个时期内模型的FID分数图</figcaption></figure><p id="8790" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">结果:</strong></p><p id="107d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">SAGAN在<strong class="ix hj"> epoch 198 </strong>生成的图像如下，我们在那里获得了最好的FID分数<strong class="ix hj"> 84.83 </strong>:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/498b8391e1320e353c6c39e21f225ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*NESpHk52Zqso4hKLO8AWbA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">萨根产生的图像</figcaption></figure><h2 id="90fb" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">条件生成对抗网络；</h2><p id="6ba1" class="pw-post-body-paragraph iv iw hi ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">在GAN中，创造始于白噪声。然而，在现实世界中，需要的可能是一种转化形式，而不是创造。例如，黑白图像的彩色化，或者天线到地图的转换。对于这样的应用，<strong class="ix hj">我们以额外的输入为条件</strong>:因此命名为条件对抗网络。</p><p id="b8be" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这意味着向生成器传递的不是(或不仅仅是)白噪声，而是某种输入结构的数据，如边缘或形状。然后，它必须生成具有这些形状的真实物体的逼真图片。鉴别器也可以接收形状或边缘作为输入，此外还有辨别真假物体的任务。</p><p id="6c62" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于cGAN基于条件层来调节输出数据分布，因此在GAN的目标函数中，log(1-D(G(z))和D(x)将被log(1-D(G(z | y))和D(x|y)代替。其余的将由各自的网络负责，即创建潜在的表示和管理权重。这里的主要目标保持不变，只有少许修改:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/7d98551de4e19de2d4159374b32875dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WXq1KJSd-q8lHDAWAG1_sg.png"/></div></div></figure><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/2cc4169eef38ea4f1ce95d8d8ebdfee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DVLTPZL_eAPbTRHMQ1q0fA.png"/></div></div></figure><h2 id="e721" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">条件自我注意生成对抗网络；</h2><p id="8ffd" class="pw-post-body-paragraph iv iw hi ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">我们修改我们的萨根模型，以包括额外的投入，y，该模型可以条件。CIFAR10数据集包含与每个图像相关联的标签。我们将这个标签转换成一个独热编码表示，用它来调节与类相关的生成图像。</p><p id="d415" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">型号:</strong></p><p id="f068" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">实现DCGAN的发生器和鉴别器架构如下:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/735c009c16c524ad53e229fbb87cba73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qhmiuzDE2KFYR3Iu85pgig.png"/></div></div></figure><p id="c408" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">训练:</strong></p><p id="fccd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将随机标签和噪声向量一起传递给生成器。生成器连接这两个输入并生成图像。在训练鉴别器时，我们将生成的带有随机标签的图像传递给生成器，以生成“假输出”。我们还利用真实图像的真实标签来训练鉴别器，以生成“真实输出”。我们计算损耗，并将损耗反向传播到发生器和鉴别器。</p><p id="410d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">结果:</strong></p><p id="da49" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">cSAGAN在获得最佳FID分数<strong class="ix hj"> 92.28 </strong>的<strong class="ix hj">历元96 </strong>生成的图像如下:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/5afee77c27487d43a2cfb49668a015cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*o9-QnJEMk0KxEsyHdexyiA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">cSAGAN生成的图像</figcaption></figure><h2 id="318f" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated"><strong class="ak">总之……</strong></h2><p id="2a86" class="pw-post-body-paragraph iv iw hi ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">下表总结了所有模型的输出和使用的指标:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/80b90dbb491e8b2ce8af3d9945083f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uEDYo7n6fyFSlBXSMKsU8g.png"/></div></div></figure><h2 id="74de" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">其他实验:</h2><p id="4280" class="pw-post-body-paragraph iv iw hi ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">我尝试用WGAN实现光谱归一化机制，但生成器生成的图像并没有随着时间的推移而改善，FID分数也没有降低。</p><p id="c699" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我还试图用SAGAN实现Wasserstein损失，但发电机损失非常低(在负面影响中),模型似乎没有随着时间的推移而学习。每次迭代完成训练也花费了大量时间。</p></div></div>    
</body>
</html>