<html>
<head>
<title>MachNEase — Simple Yawn Activity Detection using Facial Landmarks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MachNEase——使用面部标志的简单哈欠活动检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machnease-simple-yawn-detector-using-facial-landmarks-994e6804d2ba?source=collection_archive---------19-----------------------#2020-05-27">https://medium.com/analytics-vidhya/machnease-simple-yawn-detector-using-facial-landmarks-994e6804d2ba?source=collection_archive---------19-----------------------#2020-05-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if"><p id="e883" class="ig ih hi bd ii ij ik il im in io ip dx translated"><strong class="ak">Nam的MachNEase—Nami tha Guruprasad的机器学习变得简单</strong></p></blockquote><p id="612f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ip hb bi jn translated">T2:有没有想过你每天打哈欠几次？！Naaayyy…我们有更好的事情要做！！！</p><figure class="jx jy jz ka fd kb er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es jw"><img src="../Images/068bc609a988531a1a7b8ef77b0643da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3HgYvUkpNzy-jlmt"/></div></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">照片由<a class="ae km" href="https://unsplash.com/@thirdworldhippy?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">姆旺吉·加塞卡</a>在<a class="ae km" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="a213" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm ip hb bi translated">好奇想知道你打哈欠的次数吗？嗯，你就差一步了！！</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><ul class=""><li id="e4a0" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated"><strong class="is hj">人的面部</strong>由于各种面部肌肉的收缩，有效地交流和表达感情。</li><li id="8e62" class="kz la hi is b it li ix lj jb lk jf ll jj lm ip le lf lg lh bi translated">极度疲劳、无聊和缺乏兴趣是嗜睡和最终打哈欠的根本原因。</li><li id="25bd" class="kz la hi is b it li ix lj jb lk jf ll jj lm ip le lf lg lh bi translated"><strong class="is hj">确定面部标志</strong>是检测打哈欠活动的根本方法。</li><li id="c25e" class="kz la hi is b it li ix lj jb lk jf ll jj lm ip le lf lg lh bi translated">因此，使用<strong class="is hj">计算机视觉可以设计出有效的面部图像处理系统是合乎逻辑的。</strong></li></ul><figure class="jx jy jz ka fd kb er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es lo"><img src="../Images/d609a4eb80c5ea4fdf45b664ad0b563c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XkMUzROw9ORJC0YOGQP4cw.png"/></div></div><figcaption class="ki kj et er es kk kl bd b be z dx translated"><strong class="bd lp">使用面部标志检测哈欠的工作流程</strong></figcaption></figure></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="3466" class="lq lr hi bd lp ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">安装和导入基本库:</h1><ul class=""><li id="0f17" class="kz la hi is b it mn ix mo jb mp jf mq jj mr ip le lf lg lh bi translated"><strong class="is hj"> OpenCV — </strong>主要针对实时计算机视觉的编程函数库(<a class="ae km" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank">文档</a></li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="8638" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">pip install opencv-python</strong></span></pre><ul class=""><li id="9069" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated"><strong class="is hj"> DLib — </strong>用C++编写的通用跨平台软件库(<a class="ae km" href="http://dlib.net/" rel="noopener ugc nofollow" target="_blank">文档</a>)</li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="dd59" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">pip install dlib</strong></span></pre><ul class=""><li id="3f2f" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated"><strong class="is hj">NumPy—</strong>Python编程语言的库，增加了对大型多维数组和矩阵的支持，以及对这些数组进行操作的大量高级数学函数(<a class="ae km" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank">文档</a>)</li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="12dd" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">pip install numpy</strong></span></pre><p id="c6b7" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm ip hb bi translated">现在，导入所有这些库:</p><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="c575" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">import cv2<br/>import dlib<br/>import numpy as np</strong></span></pre></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="d0fe" class="lq lr hi bd lp ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">获取面部标志坐标:</h1><ul class=""><li id="0969" class="kz la hi is b it mn ix mo jb mp jf mq jj mr ip le lf lg lh bi translated">为了找到面部上的界标坐标，使用在<strong class="is hj"> <em class="ln"> dlib </em> </strong>库中实现的形状估计器。</li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="75b9" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">detector = dlib.get_frontal_face_detector()</strong> #For detecting faces<br/><strong class="mt hj">landmark_path="shape_predictor_68_face_landmarks.dat" </strong><br/>#Path of the file - if stored in the same directory. Else, give the relative path<br/><strong class="mt hj">predictor = dlib.shape_predictor(landmark_path) </strong>#For identifying landmarks</span></pre><ul class=""><li id="cf33" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated">估计器给<strong class="is hj"> 68个标志点</strong>，包括眼角、鼻尖、嘴唇等。</li><li id="c3d3" class="kz la hi is b it li ix lj jb lk jf ll jj lm ip le lf lg lh bi translated"><strong class="is hj">识别网络摄像头中检测到的人脸数量</strong>。<em class="ln">确保活动检测只有一个对象。</em></li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="65cf" class="mx lr hi mt b fi my mz l na nb">#Obtaining Facial Landmark coordinates<br/><strong class="mt hj">def get_facial_landmarks(image):<br/>    face = detector(image, 1)</strong><br/>    #Detecting faces in image<br/><strong class="mt hj">    if len(face) &gt; 1:<br/></strong>   <strong class="mt hj">     return "Multiple faces detected in the frame!!"<br/>    if len(face) == 0:<br/>        return "No face detected in the frame!!"</strong><br/>    #Return the coordinates<br/>    #Predictor identifies all the 68 landmarks for the detected face<br/>    <strong class="mt hj">return np.matrix([[pred.x, pred.y] for pred in predictor(image, face[0]).parts()])</strong></span></pre><ul class=""><li id="d52c" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated"><strong class="is hj">在检测到的人脸上标注68个人脸标志坐标</strong></li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="0ff7" class="mx lr hi mt b fi my mz l na nb">#Drawing the landmarks : yellow in color <br/><strong class="mt hj">def landmarks_annotation(image, facial_landmarks):</strong><br/>    #Different image window for facial landmarks<br/>   <strong class="mt hj"> image = image.copy()</strong><br/>    <strong class="mt hj">for coord, p in enumerate(facial_landmarks):</strong><br/>        #Extracting coordinate values and the location / matrix of the coordinates<br/>       <strong class="mt hj"> position = (p[0, 0], p[0, 1])</strong><br/>        #Identify and draw the facial landmarks<br/>       <strong class="mt hj"> cv2.putText(image, str(coord), position, cv2.FONT_HERSHEY_COMPLEX, 0.3, (0, 255, 255))<br/>    return image</strong></span></pre></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="d4b2" class="lq lr hi bd lp ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">计算嘴唇距离:</h1><ul class=""><li id="ace7" class="kz la hi is b it mn ix mo jb mp jf mq jj mr ip le lf lg lh bi translated">使用地标计算<strong class="is hj">上唇</strong>的质心值</li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="cef7" class="mx lr hi mt b fi my mz l na nb">#Landmark coordinates for upper lip identified in the face <br/><strong class="mt hj">def upperlip(facial_landmarks):<br/>    ulip = []</strong><br/>    #create an array to store the landmark coordinates of the upper lip<br/>    <strong class="mt hj">for i in range(50,53):</strong><br/>        #The range is predefined in "shape_predictor_68_face_landmarks.dat"<br/>       <strong class="mt hj"> ulip.append(facial_landmarks[i])</strong><br/>   <strong class="mt hj"> for i in range(61,64):</strong><br/>        #The range is predefined in "shape_predictor_68_face_landmarks.dat"<br/>        <strong class="mt hj">ulip.append(facial_landmarks[i])</strong><br/>    #Locate the mean value of the upper lip coordinates<br/>   <strong class="mt hj"> ulip_mean = np.mean(ulip, axis=0)<br/>    return int(ulip_mean[:,1])</strong>#centroid value</span></pre><ul class=""><li id="46af" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated">使用地标计算<strong class="is hj">下唇</strong>的质心值</li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="3416" class="mx lr hi mt b fi my mz l na nb">#Landmark coordinates for lower lip identified in the face <br/><strong class="mt hj">def lowerlip(facial_landmarks):<br/>    llip = []</strong><br/>    #create an array to store the landmark coordinates of the lower lip<br/>   <strong class="mt hj"> for i in range(65,68):</strong><br/>        #The range is predefined in "shape_predictor_68_face_landmarks.dat"<br/>       <strong class="mt hj"> llip.append(facial_landmarks[i])<br/>    for i in range(56,59):</strong><br/>        #The range is predefined in "shape_predictor_68_face_landmarks.dat"<br/>       <strong class="mt hj"> llip.append(facial_landmarks[i])</strong><br/>    #Locate the mean value of the lower lip coordinates<br/>   <strong class="mt hj"> llip_mean = np.mean(llip, axis=0)<br/>    return int(llip_mean[:,1])</strong>#centroid value</span></pre><ul class=""><li id="ed00" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated">通过<strong class="is hj">使用上下嘴唇各自的质心计算上下嘴唇之间的距离</strong>来检测打哈欠活动</li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="717d" class="mx lr hi mt b fi my mz l na nb">#Detect the yawning activity<br/><strong class="mt hj">def yawning(image):</strong><br/>    #Obtain the facial Landmark coordinates<br/>    <strong class="mt hj">facial_landmarks = get_facial_landmarks(image)<br/>    if type(facial_landmarks) == str:<br/>        return image, 0</strong><br/>    #Obtain the frame / image with annotated facial landmarks<br/><strong class="mt hj">    landmarks_image = landmarks_annotation(image, facial_landmarks)<br/></strong>    #Obtain Lip centroids<br/>   <strong class="mt hj"> upperlip_centroid = upperlip(facial_landmarks)<br/>    lower_lip_centroid = lowerlip(facial_landmarks)<br/></strong>    #Calculate the distance between the centroids<br/>   <strong class="mt hj"> lips_dist = abs(upperlip_centroid - lower_lip_centroid)<br/>    return landmarks_image, lips_dist</strong></span></pre></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="eb64" class="lq lr hi bd lp ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">显示哈欠状态并计数:(游戏现在开始！！！！)</h1><ul class=""><li id="fb91" class="kz la hi is b it mn ix mo jb mp jf mq jj mr ip le lf lg lh bi translated"><strong class="is hj">初始化打哈欠状态并计数</strong></li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="3a1c" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">yawn_status = False <br/>yawn_count = 0</strong></span></pre><ul class=""><li id="928b" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated"><strong class="is hj">创建</strong>现场直播<strong class="is hj">对象</strong></li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="e015" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">video_capture = cv2.VideoCapture(0)</strong></span></pre><ul class=""><li id="b350" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated"><strong class="is hj">通过调用其函数检测打哈欠活动</strong></li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="1ea5" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">while True:<br/>    _, image_frame = video_capture.read()</strong><br/>    #Identify the yawning activity<br/><strong class="mt hj">    landmarks_image, lips_dist = yawning(image_frame)<br/></strong>    #Update the yawn status<br/><strong class="mt hj">    previous_status = yawn_status</strong></span></pre><ul class=""><li id="af2a" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated">检查嘴唇之间的<strong class="is hj">距离是否偏心</strong></li></ul><p id="9fdf" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm ip hb bi translated"><em class="ln">(阈值:主观)</em> <strong class="is hj"> <em class="ln">【这是你的哈欠被检测到并被计数的地方:D】</em></strong></p><ul class=""><li id="e209" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated">如果是，那么<strong class="is hj">显示</strong>状态和你的哈欠数</li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="0923" class="mx lr hi mt b fi my mz l na nb">#comes under while loop<br/>#lips distance is subjective and changes from subject to subject based on their facial structures<br/>   <strong class="mt hj"> if lips_dist &gt; 40:<br/>        yawn_status = True<br/>        output_text = " Number of Yawns: " + str(yawn_count + 1)<br/>        cv2.putText(image_frame, "You are yawning", (50,450), cv2.FONT_HERSHEY_COMPLEX, 1,(255,255,0))<br/>        cv2.putText(image_frame, output_text, (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,0,255))<br/>        <br/>    else:<br/>        yawn_status = False <br/>         <br/>    if previous_status == True and yawn_status == False:<br/>        yawn_count += 1</strong></span></pre><ul class=""><li id="ca94" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated">创建两个独立的<strong class="is hj">窗口</strong>:</li></ul><ol class=""><li id="d5ef" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip nc lf lg lh bi translated"><strong class="is hj">面部标志</strong></li><li id="d34d" class="kz la hi is b it li ix lj jb lk jf ll jj lm ip nc lf lg lh bi translated"><strong class="is hj">打哈欠活动</strong></li></ol><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="067e" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">cv2.imshow('Facial Landmarks', landmarks_image )<br/>cv2.imshow('Yawning Activity Detection', image_frame )</strong></span></pre><ul class=""><li id="b2f3" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated"><strong class="is hj">按Q </strong>停止本次检测活动</li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="470c" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">if cv2.waitKey(1)  &amp; 0xFF == ord('q'):<br/>        break</strong></span></pre><ul class=""><li id="0163" class="kz la hi is b it kn ix ko jb lb jf lc jj ld ip le lf lg lh bi translated">清理你做过的乱七八糟的事情是一个好习惯。因此，终止网络摄像头对象并转储所有打开的窗口。</li></ul><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="9064" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">video_capture.release()<br/>cv2.destroyAllWindows()</strong></span></pre></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="9497" class="lq lr hi bd lp ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">执行:</h1><p id="c1f8" class="pw-post-body-paragraph iq ir hi is b it mn iv iw ix mo iz ja jb nd jd je jf ne jh ji jj nf jl jm ip hb bi translated">转到您的终端，粘贴以下命令:</p><p id="7206" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm ip hb bi translated">这里，文件名:“哈欠_检测器. py”</p><pre class="jx jy jz ka fd ms mt mu mv aw mw bi"><span id="d855" class="mx lr hi mt b fi my mz l na nb"><strong class="mt hj">python yawn_detector.py</strong></span></pre></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="b818" class="lq lr hi bd lp ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">耶，耶！！！你刚打完呵欠，看到嘴巴大张！！！！！！</h1><figure class="jx jy jz ka fd kb er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es ng"><img src="../Images/2fea5ac266f8f2637e142351b12ee901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ThYfpv0tOOZE6s1Ifa_siA.png"/></div></div><figcaption class="ki kj et er es kk kl bd b be z dx translated"><strong class="bd lp">是啊，我知道，我的脸好恶心:P </strong></figcaption></figure><h2 id="0433" class="mx lr hi bd lp nh ni nj lv nk nl nm lz jb nn no md jf np nq mh jj nr ns ml nt bi translated">等等！！你刚刚复制粘贴了所有该死的代码块吗？？？？？嗯，那很辛苦。没关系，你学到了新的令人兴奋的东西…</h2><blockquote class="if"><p id="905f" class="ig ih hi bd ii ij nu nv nw nx ny ip dx translated">你可以在这里找到<strong class="ak">的全部代码</strong>:<a class="ae km" href="https://github.com/nam1410/MachNEase--Simple-Yawn-Detector-using-Facial-Landmarks" rel="noopener ugc nofollow" target="_blank">https://github.com/nam1410/MachNEase——简单哈欠检测器使用面部标志</a></p></blockquote></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h2 id="8afe" class="mx lr hi bd lp nh ni nj lv nk nl nm lz jb nn no md jf np nq mh jj nr ns ml nt bi translated">对机器学习、数据科学等感兴趣..？？：</h2><p id="68de" class="pw-post-body-paragraph iq ir hi is b it mn iv iw ix mo iz ja jb nd jd je jf ne jh ji jj nf jl jm ip hb bi translated">在的帮助下潜入这片海洋</p><blockquote class="if"><p id="b6ad" class="ig ih hi bd ii ij nu nv nw nx ny ip dx translated"><a class="ae km" href="https://github.com/nam1410" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">带Nam的机器</strong> </a></p></blockquote><p id="36e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ip hb bi translated">我将在我的个人资料上传容易/可实施的项目。关注帐户，获取令人惊叹的定制内容。</p><p id="0d71" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm ip hb bi translated"><strong class="is hj"> <em class="ln">联系我:</em> </strong></p><blockquote class="if"><p id="0e0f" class="ig ih hi bd ii ij nu nv nw nx ny ip dx translated"><strong class="ak">LinkedIn</strong>:<a class="ae km" href="https://www.linkedin.com/in/namitha-guruprasad-216362155/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/namitha-guruprasad-216362155/</a></p><p id="8c12" class="ig ih hi bd ii ij nu nv nw nx ny ip dx translated"><strong class="ak"> Namitha Guruprasad，印度班加卢鲁的学生</strong></p></blockquote></div></div>    
</body>
</html>