<html>
<head>
<title>Overfitting: Detection &amp; Prevention</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">过度拟合:检测和预防</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/overfitting-detection-prevention-848e6adeabf8?source=collection_archive---------10-----------------------#2020-02-14">https://medium.com/analytics-vidhya/overfitting-detection-prevention-848e6adeabf8?source=collection_archive---------10-----------------------#2020-02-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9d93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词“过度拟合”定义了模型中的一种情况，其中统计模型开始解释数据中的噪声，而不是数据集中存在的信号。当模型过于复杂或过于灵活时，就会出现这个问题。回归模型中的过度拟合显示了噪声的R平方值、回归系数和p值，而不是总体中的真实关系。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/c85339622b0b18e3a47170754465ef9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*aorb7r6PyHhQEZwwT1-_sw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">参考图片来自facebook</figcaption></figure><p id="b5bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型不是学习数据的一般分布，而是学习每个数据点的<em class="jp">预期</em> <em class="jp">输出</em>。</p><h1 id="46e2" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">如何检测过度拟合</strong></h1><ol class=""><li id="ca6d" class="ko kp hi ih b ii kq im kr iq ks iu kt iy ku jc kv kw kx ky bi translated">为了避免过度拟合，我们可以将数据集分成随机的训练和测试子集。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es kz"><img src="../Images/7d638ac6f0274cd4184da24bd0606cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oAZEh00vl3H2v4Ifihqh4Q.png"/></div></div></figure><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="584f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你的模型在训练集上的表现比在测试集上好得多，那么你很可能过度拟合了。</p><p id="aa15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，如果您的模型在训练集上看到80%的准确性，但在测试集上只有50%的准确性，这将是一个很大的警告。然后，它会自动成为模型的危险信号。</p><p id="2626" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2 </strong>。检测过度拟合<strong class="ih hj"> </strong>的另一种方法是从一个将作为基准的简单基线模型开始。这种方法被称为<strong class="ih hj">奥卡姆剃刀测试</strong>。奥卡姆剃刀被认为是奥卡姆的英国方济各会修士威廉(约1287-1347年)发明的。在两个模型的性能相当的情况下，它基本上选择简单的模型。</p><p id="5338" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据该方法，与过度复杂的机器学习模型相比，简单的机器学习模型可以预测更好的数据洞察力，过度复杂的机器学习模型通常遭受被称为偏差方差权衡的统计噪声。但有时很难判断哪部分数据是噪音。</p><p id="e5e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然检测过度拟合是一个很好的实践，但也有几种技术可以防止过度拟合。让我们来看看防止机器学习中过拟合的几种方法。</p><h1 id="dcbf" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">如何防止过拟合</strong></h1><ol class=""><li id="b167" class="ko kp hi ih b ii kq im kr iq ks iu kt iy ku jc kv kw kx ky bi translated"><strong class="ih hj">用更多数据训练</strong></li></ol><p id="3223" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种技术可能并不是每次都有效，因为大量的训练有助于模型的建立。它有助于模型更好地识别信号。</p><p id="2aa3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。移除特征</strong></p><p id="c312" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然一些算法有内置的特征选择方法，但是如果一个特征不能解释模型中的相关性，我们可以手动删除它。我们甚至可以使用一些特性选择试探法作为一个好的起点。</p><p id="e859" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。交叉验证</strong></p><p id="3b50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在标准的k折叠交叉验证中，我们将数据分成k个大小大致相等的子集，称为折叠。然后，我们通过保留一个用于测试的折叠和其他k-1个用于训练的折叠来迭代地训练该算法。每次不同的一组或一组折叠用于验证。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lg"><img src="../Images/e6ef39ff93252d52aa09ef2a1dc6130e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O-Ex4IQ9L5YBhTp9PHWcOg.png"/></div></div></figure><p id="ec6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。正规化</strong></p><p id="5b4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它通过使用更广泛的技术，人为地迫使我们的模型避免复杂性。最常见的被称为L1和L2(岭回归):</p><ol class=""><li id="2cbb" class="ko kp hi ih b ii ij im in iq lh iu li iy lj jc kv kw kx ky bi translated">L1罚旨在最小化权重的<strong class="ih hj">绝对值</strong> <strong class="ih hj">值</strong></li><li id="da23" class="ko kp hi ih b ii lk im ll iq lm iu ln iy lo jc kv kw kx ky bi translated">L2罚值<strong class="ih hj"> </strong>旨在最小化权重的<strong class="ih hj">平方</strong> <strong class="ih hj">大小</strong>。</li></ol><p id="5d97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp"> L1 </em>具有正则化以及变量选择的优点。它强制特征<strong class="ih hj">、</strong>将<em class="jp">减去</em>、<em class="jp">有用的</em>参数设置为0。它帮助我们在<em class="jp">数据集</em>中识别<strong class="ih hj">最相关的特征</strong>。L1罚分的缺点是它的计算效率通常不如L2罚分那么高。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lp"><img src="../Images/e3c8df22e54cc654125f7222db8c2622.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bh1eN49epT_ROVdxHZVOUw.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">来源:<a class="ae lq" href="https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42" rel="noopener ugc nofollow" target="_blank">https://hacker noon . com/memoring-is-not-learning-6-tricks-to-prevent-fitting-in-machine-learning-820 b 091 DC 42</a></figcaption></figure><p id="7022" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 5。提前停止</strong></p><p id="5f0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以继续进行一定数量的迭代，直到新的迭代改进了模型。之后，模型的能力会耗尽，因为它开始过度拟合训练数据。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lr"><img src="../Images/cada03c3352d04aff568266afe84723d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FFBIFrS33RrXu9AltOToig.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">来源:<a class="ae lq" href="https://www.researchgate.net/figure/Early-stopping-based-on-cross-validation_fig1_3302948" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/figure/Early-stopping-based-on-cross-validation _ fig 1 _ 3302948</a></figcaption></figure><p id="14bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献:</strong></p><ol class=""><li id="f03f" class="ko kp hi ih b ii ij im in iq lh iu li iy lj jc kv kw kx ky bi translated"><a class="ae lq" href="https://elitedatascience.com/overfitting-in-machine-learning" rel="noopener ugc nofollow" target="_blank">https://elitedata science . com/over fitting-in-machine-learning</a></li><li id="0746" class="ko kp hi ih b ii lk im ll iq lm iu ln iy lo jc kv kw kx ky bi translated"><a class="ae lq" href="https://statisticsbyjim.com/regression/overfitting-regression-models/" rel="noopener ugc nofollow" target="_blank">https://statistics byjim . com/regression/over fitting-regression-models/</a></li><li id="f40e" class="ko kp hi ih b ii lk im ll iq lm iu ln iy lo jc kv kw kx ky bi translated"><a class="ae lq" href="https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42" rel="noopener ugc nofollow" target="_blank">https://hacker noon . com/memoring-is-not-learning-6-tricks-to-prevent-fitting-in-machine-learning-820 b 091 DC 42</a></li></ol></div></div>    
</body>
</html>