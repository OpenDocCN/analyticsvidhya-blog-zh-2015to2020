<html>
<head>
<title>What is multicollinearity and how to remove it?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是多重共线性，如何消除多重共线性？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/what-is-multicollinearity-and-how-to-remove-it-413c419de2f?source=collection_archive---------1-----------------------#2020-03-12">https://medium.com/analytics-vidhya/what-is-multicollinearity-and-how-to-remove-it-413c419de2f?source=collection_archive---------1-----------------------#2020-03-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="9a56" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="aba5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">随着机器学习和深度学习的进步，我们现在有一个算法库，可以处理我们抛给他们的任何问题。但是这些高级复杂的算法有一个问题，它们不容易解释。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es kb"><img src="../Images/32c65e8d47430aa8ceca7f8ec870b5e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*agc4XbmjoYu8DAJE"/></div></div></figure><p id="89ae" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">当谈到机器学习模型的可解释性时，没有什么比线性回归更简单和可解释性了。但是，线性回归的可解释性可能存在某些问题，尤其是当违反了线性回归的多重共线性假设时。</p><p id="a9e8" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">我假设你熟悉线性回归的假设。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es ks"><img src="../Images/12637c79ee49fd25dc12ccd324f98f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ATZ5OJNZPu2TEcUp"/></div></div></figure><p id="bf82" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">如果你和他一样，可以参考下面的链接，了解更多“线性回归的假设”。</p><p id="eec4" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><a class="ae kt" href="https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/</a></p><p id="fc7f" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">我们将研究以下关于多重共线性的问题:</p><ol class=""><li id="7568" class="ku kv hi jf b jg kn jk ko jo kw js kx jw ky ka kz la lb lc bi translated">什么是多重共线性？</li><li id="9852" class="ku kv hi jf b jg ld jk le jo lf js lg jw lh ka kz la lb lc bi translated">多重共线性如何影响解释？</li><li id="8168" class="ku kv hi jf b jg ld jk le jo lf js lg jw lh ka kz la lb lc bi translated">我们如何检测并消除它？</li></ol><p id="74e5" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">所以让我们开始逐一回答这些问题。</p><h1 id="3c36" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">1.什么是多重共线性？</h1><p id="b9bb" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">多重共线性是指自变量或预测变量之间存在<em class="li">显著相关性或关联性的情况。自变量之间的显著相关性通常是多重共线性存在的第一个证据。</em></p><p id="7977" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">让我们通过一个例子来理解这一点:</p><p id="7f18" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">假设我正在处理BigMart数据集的子集，如图所示</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lj"><img src="../Images/7d362bfa8e932b8663db24bc528f379d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fupHGR3kJXMB4zYo"/></div></div></figure><p id="ca06" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">正如我们之前所讨论的，当独立变量或预测变量之间存在高度相关性时，就会出现多重共线性。</p><p id="e772" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">让我们来看看相关矩阵</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lj"><img src="../Images/e5487ba0e931f850b8709d39c2a8017d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VXOn6fimE2Wtsx86"/></div></div></figure><p id="fe4d" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">我们可以在相关表中看到，变量Outlet_Establishment_Year和Item_Weight之间存在显著的相关性。这是多重共线性可能存在的第一个线索。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lk"><img src="../Images/2c09c4a53bab5f840248799f7f7fb4fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l_DCXBz6g6cnKXZapDKX3Q.png"/></div></div></figure><h1 id="866f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">2.多重共线性如何影响解释</h1><p id="8751" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">考虑下面的回归模型</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es ll"><img src="../Images/4bd33951c3935812b39d915e5b806758.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*G021lXRSLewtNvsK"/></div></div></figure><p id="6c48" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">在这个模型中，我们可以清楚地看到，有4个自变量作为X，相应的系数作为β。现在考虑一种情况，其中除了X3和X4，所有的变量都是独立的。</p><p id="906b" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">或者换句话说，X3和X4之间有显著的相关性。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lm"><img src="../Images/f5fc150f377742b2f55fc9805c7f2d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*otLdY2QPmkjUqsfd"/></div></div></figure><p id="29fd" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">现在，为了估计每个独立变量相对于Y的β系数，当我们每次稍微改变任意一个独立变量的幅度时，我们观察Y变量幅度的<em class="li">变化。</em></p><h2 id="5176" class="ln ig hi bd ih lo lp lq il lr ls lt ip jo lu lv it js lw lx ix jw ly lz jb ma bi translated">案例1:</h2><p id="e310" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">考虑到变量X1和X2，它们独立于其他变量。如果我们试图<em class="li">改变X1或X2的大小，它们将不会导致任何其他自变量改变其值，或者改变一些可忽略的量</em>。因此，我们可以清楚地观察到自变量X对y的影响。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es mb"><img src="../Images/0d548da4fbd8d4efa4da1267393e5c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nxBt5KmyYerY0DKT"/></div></div></figure><h2 id="91a6" class="ln ig hi bd ih lo lp lq il lr ls lt ip jo lu lv it js lw lx ix jw ly lz jb ma bi translated">案例二:</h2><p id="f1b0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在变量X3和X4的情况下，它们显著相关。你能猜到如果我们采用与案例1相同的程序会发生什么吗？</p><p id="6ee7" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">下图说明了完全相同的情况。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es mc"><img src="../Images/b5fbc700f0f681c276986cf7c6863dbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sHl4BC_7voCAqUDN"/></div></div></figure><p id="9584" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">根据这个图像，<em class="li">如果我们试图改变X3(如红色所示)的大小来观察Y(红色)的变化，X4(橙色)</em>的值也会有显著的差异。结果，我们观察到的Y的变化是由于X3(红色)和X4(橙色)的变化。最终变化(蓝色)大于实际变化(橙色)。</p><p id="856a" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">现在你可能会问，这有问题吗？</p><p id="30c5" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">是的，当我们试图估计对应于X3的系数时，变量X4的贡献导致该系数被高估。正因为如此，系数被高估了。因此，我们的解释可能会产生误导。</p><p id="72c6" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">仅根据相关性移除独立变量可以产生有价值的预测变量，因为相关性只是多重共线性存在的指示。</p><p id="b1dd" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">但是我们决心消除它。让我们来看看我们是怎么做的。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es md"><img src="../Images/a36dbb5ac83961a44591a9d1b43cd1a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yrFHiGFiyZaqW5ySqfaw-w.png"/></div></div></figure><h1 id="6e17" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.我们如何检测和消除多重共线性？</h1><p id="9a3b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">识别多重共线性的最佳方法是计算数据集中每个自变量对应的<strong class="jf hj">方差膨胀因子(VIF) </strong>。</p><p id="5c44" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">VIF告诉我们一个独立变量是如何被其他独立变量预测的。让我们借助一个例子来理解这一点。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es me"><img src="../Images/0a01244cbefb6881185ced0d01352b94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1Hpr4uuhKljPpjgE"/></div></div></figure><p id="8a2d" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">假设我们有9个独立变量，如图所示。为了计算变量V1的VIF，我们分离出变量V1并将其视为目标变量，所有其他变量将被视为预测变量。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es mf"><img src="../Images/ac6a58ed765db705c23d979cd3972326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iB-MIbtUbzrO79ej"/></div></div></figure><p id="701f" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">我们使用所有其他预测变量，并训练一个回归模型，找出相应的R2值。</p><p id="c943" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">使用这个R2值，我们计算如下图所示的VIF值。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es mg"><img src="../Images/364f903de6528ce9b63e3f1dd0d6e4e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oTmfsgtQTQ7YwTDP"/></div></div></figure><p id="fde3" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">从公式中我们可以清楚地看到，随着R2值的增加，VIF值也增加。较高的R2值表示:</p><p id="b606" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><em class="li">“其他自变量很好地解释了目标自变量”</em></p><p id="78da" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">现在，决定是否应该删除变量的VIF阈值应该是什么？</p><p id="7e2a" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">总是希望VIF值尽可能小，但这可能会导致从数据集中移除许多重要的独立变量。因此，VIF = 5通常被作为阈值。这意味着任何大于5的独立变量都将被移除。尽管理想的阈值取决于手头的问题。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es mh"><img src="../Images/8882da10169e467f14df028f796f3cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*jlEuOXGYWzFNsZcG"/></div></figure><p id="0877" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">线性回归的力量在于模型的简单解释。错过多重共线性肯定会扼杀使用线性回归的初衷。假设您已经理解了多重共线性的概念、多重共线性引起的问题以及如何在任何给定的问题中检测和消除多重共线性，我将对本文进行总结。</p></div></div>    
</body>
</html>