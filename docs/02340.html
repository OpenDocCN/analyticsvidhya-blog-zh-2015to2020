<html>
<head>
<title>Implementation framework for reinforcement learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习的实现框架</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/reinforcement-learning-next-step-in-ai-for-banking-and-financial-services-part-3-563c6b0af763?source=collection_archive---------25-----------------------#2019-12-11">https://medium.com/analytics-vidhya/reinforcement-learning-next-step-in-ai-for-banking-and-financial-services-part-3-563c6b0af763?source=collection_archive---------25-----------------------#2019-12-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ca50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结构化的方法和对业务问题、代理、环境、状态、行动和回报的清晰理解对于任何强化学习解决方案的制定都是至关重要的。</p><p id="04b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第一步:选择合适的技术组合</strong></p><p id="0610" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应用——开发者可以从一系列开发<strong class="ih hj">平台、编程语言和深度学习框架</strong>中进行选择。选择标准应包括<em class="jd">功能、效率</em>和<em class="jd">易用性</em>。大多数流行的框架都提供了关键的功能，但是在效率和易用性上有所不同。一些框架由于其计算方法而具有更高的效率，而另一些框架由于具有更少代码行的预建函数而更易于使用。</p><p id="aa55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二步:为近乎无限的体验奉献时间、精力和数据</strong></p><p id="a739" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">强化学习代理需要大量的训练；一个典型的代理可能需要大约1-2亿帧的经验才能达到人类的表现水平。因此，数据可用性大的问题比数据有限的问题更容易解决。它还需要相当多的时间和计算能量，这在某种程度上可以通过更好更快的底层硬件来解决。</p><p id="6cc3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤3:遵循强化学习模型开发生命周期</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/4e586c152dc211b5fbc052d93b0feaaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XI-HJEKAkd3RC8H81tCVoQ.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">DRL执行框架</figcaption></figure><p id="3d67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">问题框架:</strong></p><ul class=""><li id="188d" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">理解业务目标，阐明情况，概述关注点并选择方向</li><li id="e6aa" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">批判性地分析问题动态，评估强化学习对问题的适用性。</li><li id="0fea" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">分析潜在的实施风险和机会</li></ul><p id="09e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模拟环境</strong></p><ul class=""><li id="51c7" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">选择正确反映真实世界动态的模拟环境，以便有效地训练代理。</li><li id="4257" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">清楚地定义环境的元素和边界</li><li id="851b" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">通过使用子采样方案(如历史截止)或方法(如双聚类)来简化状态表示</li></ul><p id="16a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">公式化马尔可夫决策过程(MDP) </strong></p><ul class=""><li id="70ea" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">明确定义状态空间、行动空间、奖励函数和折扣因子</li><li id="7ab8" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">选择低维状态空间以避免维数灾难并简化计算</li><li id="cbd2" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">选择适当的折扣系数来解决信用分配</li></ul><p id="9d55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> RL架构</strong></p><p id="02c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据问题的背景和解决方案的效率，从以下配置中进行选择</p><p id="2951" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">开启/关闭策略:开启策略RL；非政策RL</p><ul class=""><li id="34e9" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">打开/关闭模型:基于模型；无模型</li></ul><p id="1352" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">算法选择</strong></p><ul class=""><li id="09c6" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">确定解决方案的适用算法:Q-Learning；萨尔萨；政策梯度；演员-评论家方法；最接近的策略优化和其他..</li><li id="bf58" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">选择可解释的、稳健的、在不确定情况下具有良好决策能力的算法</li></ul><p id="d7d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模特培训&amp;测评</strong></p><ul class=""><li id="d886" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">使用梯度上升的小批量方法提高训练效率</li><li id="7509" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">对未知场景测试有助于评估模型性能。</li><li id="9b23" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">监控所有超参数的灵敏度，以确保模型的稳健性</li></ul><p id="12e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢大家！</p></div></div>    
</body>
</html>