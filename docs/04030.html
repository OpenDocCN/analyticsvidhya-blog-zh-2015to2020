<html>
<head>
<title>k-Nearest Neighbors for Dummies</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">假人的k-最近邻</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/k-nearest-neighbors-for-dummies-eaaa0f80a62?source=collection_archive---------12-----------------------#2020-03-02">https://medium.com/analytics-vidhya/k-nearest-neighbors-for-dummies-eaaa0f80a62?source=collection_archive---------12-----------------------#2020-03-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="135c" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">你是和你相处时间最长的五个人的平均值</p></blockquote><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es jh"><img src="../Images/16827299720e07a4c1602a9ac776bf87.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/0*J4x5sYusqDcbYRM-"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:谷歌图片</figcaption></figure><p id="a916" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">先说K近邻(简写为kNN)的核心思想。</p><p id="e1a9" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">给定一个查询点xₜ，我们将在给定的数据集中找到该点的k个最近邻，并通过对k个最近邻的类进行多数投票来预测yₜ类。同样的事情也适用于回归，但不是多数投票，而是取k个最近邻的平均值或中值。</p><p id="f900" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><em class="ik">kNN失败案例:</em></p><p id="24cf" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">情况1:正负类随机分布时</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es jw"><img src="../Images/275843c1c71ea056c97c7489438be3c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*MwG1YaDDc1OMqhv6ZnDYxA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:我的电脑</figcaption></figure><p id="e4de" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">情况2:当查询点xₜ远离任一类时。在这种情况下，我们无法确定xₜ属于哪个阶级。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es jx"><img src="../Images/3812cdab0282ca86cf197537c4587cb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*W0MlJUeduBsNW_wN2lgVcg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:我的电脑</figcaption></figure><blockquote class="if ig ih"><p id="30d4" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">如何判断一个点是否离两个类都很远？门槛应该是多少？</p></blockquote><p id="8f3e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">嗯，决定阈值是数据特定的，但一个可接受的决定方式是-</p><ul class=""><li id="a2c7" class="jy jz hi il b im in iq ir jt ka ju kb jv kc jg kd ke kf kg bi translated">为训练数据中的每个点找到第一个最近邻距离。</li><li id="d1dc" class="jy jz hi il b im kh iq ki jt kj ju kk jv kl jg kd ke kf kg bi translated">对所有距离进行排序</li><li id="0252" class="jy jz hi il b im kh iq ki jt kj ju kk jv kl jg kd ke kf kg bi translated">找到，比方说90ᵗʰ或95ᵗʰ百分位值(p’)(或根据要求的任何其他百分位值)。</li><li id="062e" class="jy jz hi il b im kh iq ki jt kj ju kk jv kl jg kd ke kf kg bi translated">现在，如果查询点xₜ的第一最近邻大于p’，那么我们可以说xₜ离每个类都很远。</li></ul><blockquote class="if ig ih"><p id="10c8" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">我们如何找出给定点的邻居？</p></blockquote><p id="e4a8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">这和在现实生活中寻找邻居是一样的。住在你家附近的人是你的邻居。类似地，靠近给定点的数据点将是它的邻居。这种接近度由数据点之间的距离来定义。机器学习中使用了很多距离度量。你可以在<a class="ae km" href="https://towardsdatascience.com/how-to-measure-distances-in-machine-learning-13a396aa34ce" rel="noopener" target="_blank">https://towards data science . com/how-to-measure-distance-in-machine-learning-13 a396 aa 34 ce</a>上了解到它们。通常，在kNN中使用欧几里德距离。</p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><h2 id="d58d" class="ku kv hi bd kw kx ky kz la lb lc ld le jt lf lg lh ju li lj lk jv ll lm ln lo bi translated">kNN简单实现的时间和空间复杂度</h2><ul class=""><li id="c94c" class="jy jz hi il b im lp iq lq jt lr ju ls jv lt jg kd ke kf kg bi translated">给定具有n个数据点和d维的训练数据集X。</li></ul><p id="f456" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">对于查询点xₜ，我们必须找到与训练数据中每个点的距离。</p><p id="832b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">对于1距离计算，我们必须执行d运算(d =数据的维数)</p><p id="b51a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">∴对于n次距离计算，我们将不得不执行n*d次运算或O(n*d)次</p><p id="4b84" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">然后我们必须根据所有的距离选择最近的k点。通常，与数据集的大小相比，k非常小。大多数情况下，k =3，5，11，15左右，因此需要O(n)时间</p><p id="061c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">然后，我们必须决定使用多数表决，这将需要常数或O(1)时间。</p><p id="b4c0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">KNN的∴时间复杂度将为:O(n*d) + O(n) + O(1) = <strong class="il hj"> O(n*d) </strong></p><p id="c228" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">当我们说我们已经训练了一个kNN模型时，这仅仅意味着我们已经将训练数据加载到RAM中。在训练阶段不执行任何操作，因此kNN的空间复杂度将是:<strong class="il hj"> O(n*d) </strong></p><h2 id="a7e7" class="ku kv hi bd kw kx ky kz la lb lc ld le jt lf lg lh ju li lj lk jv ll lm ln lo bi translated">k变化时kNN的决策面</h2><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es lu"><img src="../Images/9f67141d48c05ec99c54c5b8f438020a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0MqMHpZ8Wl_LSiB0m2cX-w.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:GeeksForGeeks</figcaption></figure><p id="d656" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">随着k的增加，曲线的平滑度增加。</p><blockquote class="if ig ih"><p id="a171" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">如果k=n(数据点数)会怎样？</p></blockquote><p id="a147" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">在这种情况下，不会有任何决策表面，整个数据集都将被考虑在内。给定一个查询点，其类别由训练数据中的多数类别决定。这将是一个非常不适合的情况。</p><p id="f8c7" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">过度拟合</strong>基本上是指我们找到了一个非常好的函数，它甚至考虑到了每一分钟的细节，包括有噪声的异常值。该模型在训练数据上几乎不会给出错误，但是在遇到看不见的数据时会失败。<strong class="il hj">当kNN中的k很小时发生</strong>。</p><p id="065f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">欠拟合</strong>基本上是指我们找到了一个与数据松散拟合的函数，或者换句话说，是一种不完美的描述数据的方式。它会在训练和看不见的数据上产生错误。<strong class="il hj">发生在kNN中k大的时候</strong>。</p><h2 id="f658" class="ku kv hi bd kw kx ky kz la lb lc ld le jt lf lg lh ju li lj lk jv ll lm ln lo bi translated">找到k的正确值</h2><p id="bfc1" class="pw-post-body-paragraph ii ij hi il b im lp io ip iq lq is it jt lz iw ix ju ma ja jb jv mb je jf jg hb bi translated">我们已经看到了k的值是如何影响我们的模型的。但是我们应该如何确定k的值呢？</p><p id="eb58" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">在实践中，它是通过交叉验证来完成的，这可能是我下一篇文章的主题，但简而言之，我们将数据集分成三部分:训练数据、CV(交叉验证)数据和测试数据。我们在训练数据上训练我们的模型，对于不同的k值，在CV数据上计算精确度。给出最大精度(或最小误差)的k被选为最终k值。之后，我们测试我们的模型，取测试数据的最终k值。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es mc"><img src="../Images/eab4c1e9086bb90af0fbff3a54696a48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hZTteCYjv_3bXt-m8h0kdQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:Vidhya分析</figcaption></figure><h2 id="2d43" class="ku kv hi bd kw kx ky kz la lb lc ld le jt lf lg lh ju li lj lk jv ll lm ln lo bi translated">加权kNN</h2><p id="b549" class="pw-post-body-paragraph ii ij hi il b im lp io ip iq lq is it jt lz iw ix ju ma ja jb jv mb je jf jg hb bi translated">有时我们希望给予离查询点较近的点比较远的点更大的权重。因此，我们给查询点的k个最近邻居中的每一个赋予权重。</p><p id="6b81" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">分配权重的一种方法是使用反距离函数。让我们用一个例子来理解这一点:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es md"><img src="../Images/3683ecf840f0f276416434cbbea3fa85.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*Ki4H0WQOMmn_kW_5LFR-Lg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:我的电脑</figcaption></figure><p id="39f3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">现在我们计算每一类的权重。</p><p id="8a6d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">重量(-ve等级)= 10+5=15</p><p id="df83" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">重量(+ve类)= 1+0.5+0.25 = 1.75</p><p id="b992" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">因为，权重(-ve类) &gt;权重(+ve类)，∴我们将查询点分配给负类。</p><p id="72df" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">好了，暂时就这些了。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es me"><img src="../Images/ed9af9a20b737cc1f8c36e144531da52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nQnDZSPC4NShi39w.gif"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:谷歌图片</figcaption></figure></div></div>    
</body>
</html>