<html>
<head>
<title>Twitter’s 50 Trending Topics Sentiment Analysis Dashboard</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter的50个热门话题情绪分析仪表板</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/twitters-50-trending-topics-sentiment-analysis-dashboard-aaea632caf18?source=collection_archive---------10-----------------------#2020-12-16">https://medium.com/analytics-vidhya/twitters-50-trending-topics-sentiment-analysis-dashboard-aaea632caf18?source=collection_archive---------10-----------------------#2020-12-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3b3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">在谷歌云平台上训练、部署和自动化深度神经网络</em>……<em class="jd">(免费！</em>)</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/4e84711072c0f551a10dd8743f6411cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4CUSFmwgxwvvtQKN1cdixQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">【fittedcapsandbrownies.wordpress.com T4】</figcaption></figure><p id="a26a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">已经有很多使用Twitter进行情感分析的教程了。所以在我开始之前，让我先解释一下本教程与其他教程的不同之处:</p><ul class=""><li id="bfe0" class="jv jw hi ih b ii ij im in iq jx iu jy iy jz jc ka kb kc kd bi translated">这将解释从构建到自动化模型的整个过程，每一步——我将尝试这样做，以便初学者会发现这很有用。</li><li id="da72" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated">大多数Twitter项目使用类似nltk的情感包，或者如果他们使用神经网络，他们使用Keras，这里我使用Trax，它是由Google Brain团队积极使用和维护的</li><li id="395c" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated">我将使用161万条推文加上它们的表情符号，使用谷歌Colab上的免费GPU来训练模型。</li><li id="d7f2" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated">这种经过训练的模型将存在于云中，每小时自动部署一次，而且是免费的！</li><li id="e54a" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated">不仅仅是一个模型，然后我将使用这个模型用Google Data Studio构建一个交互式仪表板。</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/023677f4e25710d9b48a248d4fc1961c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NN56RpNFsOhQf_Hj_9C5Bw.png"/></div></div></figure><p id="5a5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://datastudio.google.com/reporting/0a22198e-c33c-4c51-a859-ca258ca878e9/page/5DSsB" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">点击此链接查看上面的仪表盘！</strong>T9】</a></p><h1 id="978e" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">目录</h1><ol class=""><li id="ab25" class="jv jw hi ih b ii li im lj iq lk iu ll iy lm jc ln kb kc kd bi translated">介绍</li><li id="9eb2" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">工具和库</li><li id="0dc8" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">Google Colab和Twitter API上的设置</li><li id="16b3" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">获取训练数据</li><li id="3e4f" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">预处理推文</li><li id="d075" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">建立词汇和Tweet到张量函数</li><li id="7309" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">构建批处理生成器</li><li id="52d9" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">构建Trax深度神经网络模型</li><li id="1d67" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">训练模型</li><li id="456f" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">构建精度函数</li><li id="1aa6" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">测试模型</li><li id="ea51" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">授权Tweepy访问Twitter API</li><li id="db11" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">找出美国的50个热门话题</li><li id="aec3" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">为每个热门话题提取最受欢迎的推文</li><li id="d41d" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">建立一个功能来预测新的推文</li><li id="2494" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">建立一个功能，将情感添加到新的推文中</li><li id="8fcc" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">注册谷歌云平台</li><li id="6a62" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">创建项目</li><li id="3bf2" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">设置服务帐户</li><li id="290a" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">设置IAM权限</li><li id="4753" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">设置机密管理器</li><li id="f11d" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">在Google云计算引擎上设置Linux虚拟机实例</li><li id="a00e" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">创建存储桶</li><li id="d09f" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">在虚拟机中安装Google云存储库</li><li id="6179" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">将文件上传到虚拟机</li><li id="0e96" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">将Python库和依赖项安装到虚拟机</li><li id="e56c" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">使用Nano文本编辑器创建Python脚本</li><li id="2e2a" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">使用Cron作业和TMUX自动化脚本</li><li id="b3c8" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">在Google Data Studio中创建仪表板</li><li id="3838" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ln kb kc kd bi translated">结尾和后续步骤</li></ol><h1 id="2f18" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">1.介绍</h1><p id="5f7e" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">最近我一直在玩GCP(谷歌云平台)，我认为这可能是应用我从<a class="ae ju" href="https://www.coursera.org/specializations/natural-language-processing" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> DeepLearning学到的最后一个专业知识的最佳时机。AI——自然语言处理，</strong> </a>在这里我们使用Trax构建了一个深度神经网络进行情感分析。这个想法是提取最受欢迎的推文，并对它们进行情感分析。</p><p id="1c9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Twitter是情感模型的绝佳平台，因为有些推文并不总是看起来那样。有很多讽刺和阴影，人们正在利用这个平台表达一些非常真实和复杂的情绪。正如你在下面看到的，通过使用Trax内置的深度神经网络，我们将能够成功预测甚至是困难的推文！</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/6d55208d12dbfbb734ef8cdb11379585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OPKoKDHUAGgjvAat"/></div></div></figure><h1 id="8f89" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">2.工具和库</h1><p id="2723" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated"><a class="ae ju" href="https://colab.research.google.com/notebooks/intro.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Google Colab笔记本</strong></a>——托管代码，训练，测试，评估模型。</p><p id="cec2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://docs.tweepy.org/en/latest/api.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Tweepy </strong> </a> —访问Twitter API和拉推的python包。</p><p id="e95a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://developer.twitter.com/en/docs/twitter-api/enterprise/search-api/quick-start/enterprise-30-day" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Twitter的API </strong> </a> —注册申请访问和键码。</p><p id="37eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://pypi.org/project/emojis/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">表情符号</strong> </a> —将表情符号转换成文本的python包，反之亦然。</p><p id="beb9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://trax-ml.readthedocs.io/en/latest/trax.html" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">【Trax】</strong></a><strong class="ih hj"/>——构建深度神经网络。</p><p id="3a6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://cloud.google.com/compute/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">谷歌云计算引擎</strong> </a> <strong class="ih hj"> </strong> —云中的一个虚拟机，托管我们的脚本</p><p id="af17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://cloud.google.com/storage/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">谷歌云存储</strong> </a> —云中存储我们数据的桶</p><p id="16fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://cloud.google.com/secret-manager" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">谷歌云秘密管理器</strong></a>——云中存储秘密和密钥的地方</p><p id="36e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://datastudio.google.com/navigation/reporting" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">谷歌数据工作室</strong> </a> —一个交互式仪表盘工作室</p><h1 id="0c0b" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">3.Google Colab和Twitter API上的设置</h1><p id="fe7d" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">这里有一个关于如何设置你的Colab笔记本来访问Twitter API… <a class="ae ju" href="https://towardsdatascience.com/twitter-data-collection-tutorial-using-python-3267d7cfa93e" rel="noopener" target="_blank"> <strong class="ih hj">使用Python的Twitter数据收集教程的优秀教程。</strong> </a>它还会带你获得你的Twitter API代码。一旦您被批准使用Twitter API并收到我们的代码，您应该创建一个json文件来存储您的秘密代码，而不是将它们托管在云或GitHub中。您可以在您的文本编辑器中这样做(确保将它保存为json文件),应该如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/ee019b7dc924df4d4a8fe5e55641e712.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dmSiIQig9necibn0"/></div></div></figure><p id="0082" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们训练模型的时候这只是暂时的。最终我们会使用谷歌云平台的秘密管理器来存储我们的秘密。</p><p id="9693" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我的Google Colab笔记本的链接，我将在免费的GPU上训练和测试我的代码……<a class="ae ju" href="https://colab.research.google.com/drive/1-wkVF8PtwjGQxB5lM8oyNz4cfDuujri_?usp=sharing" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">Google Colab笔记本——训练和测试</strong> </a></p><p id="eecf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">或者你可以直接去我的GitHub Repo找这个项目……<a class="ae ju" href="https://github.com/sam-brady/twitter-sentiment" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">GitHub Repo—Twitter感悟</strong> </a></p><h1 id="818b" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">4.获取训练数据</h1><p id="4303" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated"><em class="jd">垃圾进，垃圾出。</em>笔记本电脑完成所有设置和库安装后，您就可以开始导入数据了。在这里，我将组合两个不同的数据集，以获得161万条推文，其中一半被分类为正面，一半被分类为负面。对于神经网络来说，重要的是训练数据是平衡的。训练集的规模确保了单词语料库足够全面，可以处理模型尚未看到的新推文。由于数据集的规模相当大，我采用了90/10的分割，其中90%的数据用于训练，其余10%用于测试和评估。我摆弄了一下这些数字，发现这种分割是最好的。简单说明一下……对于负面和正面的tweets，Sentiment140数据的标签分别是0和4，因此您应该编写一个快速映射函数，将正面数据的4改为1。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="b36c" class="lx kl hi lt b fi ly lz l ma mb">fmap = {4:1, 0:0}</span><span id="e075" class="lx kl hi lt b fi mc lz l ma mb">sentiment140_tweets['target'] = sentiment140_tweets['target'].map(fmap)</span></pre><p id="88d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以在此找到有关数据集的更多信息:</p><p id="040b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://www.nltk.org/nltk_data/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> NLTK twitter样本(#41) </strong> </a> 10，000条推文</p><p id="309e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://www.tensorflow.org/datasets/catalog/sentiment140" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">感知140</strong></a>160万条推文</p><h1 id="1dd0" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">5.预处理推文</h1><p id="c36f" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">下一步是处理所有的推文，去除所有无关的部分。下面是一个你可以使用的功能，如果这个功能不能满足你的特殊需求，你也可以通过网络搜索找到一个不错的功能。通常我会删除停用词(或最常见的词…“a”、“the”、“and”等…)，但我发现包含停用词后，模型性能会更高。此外，我在这里使用表情包将表情转换成文本描述，并将其添加到单词的训练语料库中。比如说😁表情符号将被转换成类似“笑脸”的东西，我们将捕捉到“微笑”这个词的情感，这是非常积极的。这些单词都被标记化和词条化，只返回实际单词的词根，即“running”会变成“run”。这里有一个预处理函数:</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="604d" class="lx kl hi lt b fi ly lz l ma mb">def process_tweet(tweet):  </span><span id="dd8a" class="lx kl hi lt b fi mc lz l ma mb">    # remove old style retweet text "RT"<br/>    new_tweet = re.sub(r'^RT[\s]+', '', tweet)<br/>    <br/>    # decode emojis to text descriptions<br/>    new_tweet = emojis.decode(new_tweet)</span><span id="3ad0" class="lx kl hi lt b fi mc lz l ma mb">    # remove hyperlinks<br/>    new_tweet = re.sub('((www\.[^\s]+)|(https?://[^\s]+)|(http?://[^\s]+))', '', new_tweet)<br/>    new_tweet = re.sub(r'http\S+', '', new_tweet)</span><span id="ef29" class="lx kl hi lt b fi mc lz l ma mb">    # remove hashtags<br/>    new_tweet = re.sub(r'#', '', new_tweet)<br/>    <br/>    # remove underscores<br/>    new_tweet = re.sub(r'_', '', new_tweet)</span><span id="ebb9" class="lx kl hi lt b fi mc lz l ma mb">    # remove all numbers<br/>    new_tweet = re.sub(r'[0-9]', '', new_tweet)</span><span id="b3b2" class="lx kl hi lt b fi mc lz l ma mb">    # remove usernames<br/>    new_tweet = re.sub('@[^\s]+', '', new_tweet)<br/>    <br/>    # remove punctuation even in the middle of a string "in.the.middle"<br/>    new_tweet = re.sub(r'[^\w\s]',' ', new_tweet)</span><span id="77ea" class="lx kl hi lt b fi mc lz l ma mb">    # instantiate tokenizer class<br/>    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)</span><span id="aadf" class="lx kl hi lt b fi mc lz l ma mb">    # tokenize tweets<br/>    tweet_tokens = tokenizer.tokenize(new_tweet)</span><span id="1514" class="lx kl hi lt b fi mc lz l ma mb">    tweets_clean = []</span><span id="244c" class="lx kl hi lt b fi mc lz l ma mb">    for word in tweet_tokens: # Go through every word in your tokens list<br/>        if (word not in string.punctuation):  # remove punctuation<br/>            tweets_clean.append(word)</span><span id="010f" class="lx kl hi lt b fi mc lz l ma mb">    # Instantiate stemming class<br/>    stemmer = PorterStemmer() </span><span id="73e4" class="lx kl hi lt b fi mc lz l ma mb">    # Create an empty list to store the stems<br/>    tweets_stem = [] </span><span id="ed8a" class="lx kl hi lt b fi mc lz l ma mb">    for word in tweets_clean:<br/>        stem_word = stemmer.stem(word)  # stemming word<br/>        tweets_stem.append(stem_word)  # append to the list<br/>    <br/>    return tweets_stem</span></pre><p id="e5e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个推文预处理和后处理的例子:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/d7b574407f46b66e6372cb3f1d36cca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hKp_2BNaNUe7t3F8"/></div></div></figure><h1 id="8879" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">6.建立词汇和Tweet到张量函数</h1><p id="818f" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">处理完每个单词后，下一件事就是创建一个词汇词典，每个单词都有一个惟一的数字标识符。这将有可能把推文变成一个数字张量。确保在词汇表中包含用于填充张量的“__Pad__ ”,用于标记行尾的“__  __ ”,以及用于训练数据未知的单词的“__Unk__”。将词汇表保存为json文件以便以后在云中使用也非常重要。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="36a4" class="lx kl hi lt b fi ly lz l ma mb"># started with pad, end of line and unk tokens<br/>Vocab = {'__PAD__': 0, '__&lt;/e&gt;__': 1, '__UNK__': 2} </span><span id="6b14" class="lx kl hi lt b fi mc lz l ma mb"># Note that we build vocab using training data<br/>for tweet in train_x: <br/>    processed_tweet = process_tweet(tweet)<br/>    for word in processed_tweet:<br/>        if word not in Vocab: <br/>            Vocab[word] = len(Vocab)</span><span id="b3af" class="lx kl hi lt b fi mc lz l ma mb">#save to json file<br/>json.dump(Vocab, open("Vocab.json", 'w' ))</span></pre><p id="e6a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦完成，我们就可以将每条推文转换成一个数字张量。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="f9ef" class="lx kl hi lt b fi ly lz l ma mb">def tweet_to_tensor(tweet, vocab_dict, unk_token='__UNK__', verbose=False):<br/>    '''<br/>    Input: <br/>        tweet - A string containing a tweet<br/>        vocab_dict - The words dictionary<br/>        unk_token - The special string for unknown tokens<br/>        verbose - Print info during runtime<br/>    Output:<br/>        tensor_l - A python list with<br/>        <br/>    '''  </span><span id="0f5d" class="lx kl hi lt b fi mc lz l ma mb">    # Process the tweet into a list of words<br/>    # where only important words are kept (stop words removed)<br/>    word_l = process_tweet(tweet)<br/>    <br/>    if verbose:<br/>        print("List of words from the processed tweet:")<br/>        print(word_l)<br/>        <br/>    # Initialize the list that will contain the unique integer IDs of each word<br/>    tensor_l = []<br/>    <br/>    # Get the unique integer ID of the __UNK__ token<br/>    unk_ID = vocab_dict[unk_token]<br/>    <br/>    if verbose:<br/>        print(f"The unique integer ID for the unk_token is {unk_ID}")<br/>        <br/>    # for each word in the list:<br/>    for word in word_l:<br/>        <br/>        # Get the unique integer ID.<br/>        # If the word doesn't exist in the vocab dictionary,<br/>        # use the unique ID for __UNK__ instead.<br/>        word_ID = vocab_dict.get(word, unk_ID)</span><span id="856e" class="lx kl hi lt b fi mc lz l ma mb">        <br/>        # Append the unique integer ID to the tensor list.<br/>        tensor_l.append(word_ID) <br/>    <br/>    return tensor_l</span></pre><p id="c040" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果是这样的:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/e0f250778b4ff84e5e3701aa50b7b9e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6d3QbBgCjCvMUSiC"/></div></div></figure><h1 id="014c" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">7.构建批处理生成器</h1><p id="594d" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">这是一个相当大的函数，如果你有兴趣的话，我鼓励你看看我的Colab笔记本中的代码。基本上，这个函数的作用是创建大量的训练数据子集，以便一次输入模型卡盘。填充被添加到每个张量的末尾，使得每个组块的所有张量长度都是相同的。它还加载每个单词的权重，初始值为1，该值将随着模型的训练而变化。</p><h1 id="7528" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">8.构建Trax深度神经网络模型</h1><p id="2b6e" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">Trax的使用和构建相当简单。如果你是一个初学者，我强烈建议你用Keras建立一个模型，原因有两个……1)在编写模型时，它对用户更友好，更重要的是2)与Trax相比，有太多太多的教程可以帮助你使用Keras。如果你使用Keras，你仍然可以完成本教程。也就是说，该模型是具有嵌入层、平均层、密集层和LogSoftmax层的分类器模型。所有这些都将与Trax的串行层联系在一起。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="3ba2" class="lx kl hi lt b fi ly lz l ma mb">def classifier(vocab_size=len(Vocab), embedding_dim=256, output_dim=2, mode='train'):</span><span id="b480" class="lx kl hi lt b fi mc lz l ma mb">    # create embedding layer<br/>    embed_layer = tl.Embedding(<br/>        vocab_size=vocab_size, # Size of the vocabulary<br/>        d_feature=embedding_dim)  # Embedding dimension<br/>    <br/>    # Create a mean layer, to create an "average" word embedding<br/>    mean_layer = tl.Mean(axis=1)<br/>    <br/>    # Create a dense layer, one unit for each output<br/>    dense_output_layer = tl.Dense(n_units = output_dim)<br/>    <br/>    # Create the log softmax layer (no parameters needed)<br/>    log_softmax_layer = tl.LogSoftmax()<br/>    <br/>    # Use tl.Serial to combine all layers<br/>    # and create the classifier<br/>    # of type trax.layers.combinators.Serial<br/>    model = tl.Serial(<br/>      embed_layer, # embedding layer<br/>      mean_layer, # mean layer<br/>      dense_output_layer, # dense output layer <br/>      log_softmax_layer # log softmax layer<br/>    )</span><span id="2ae2" class="lx kl hi lt b fi mc lz l ma mb">    # return the model of type<br/>    return model</span></pre><h1 id="03b4" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">9.训练模型</h1><p id="e67d" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">现在架构已经就位，所有的tweets都已经转换成机器可读的形式(带填充的张量)，是时候训练模型了。我选择使用16条tweets的批处理大小，每个检查点100步，Adam优化器值为0.0001。随意摆弄这些，但对我来说，它们是最好的价值。将模型保存到您的驱动器很重要，因为您稍后需要将它上传到云。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="7ecb" class="lx kl hi lt b fi ly lz l ma mb">batch_size = 16<br/>rnd.seed(42)</span><span id="2e72" class="lx kl hi lt b fi mc lz l ma mb">train_task = training.TrainTask(<br/>    labeled_data=train_generator(batch_size=batch_size, shuffle=True),<br/>    loss_layer=tl.CrossEntropyLoss(),<br/>    optimizer=trax.optimizers.Adam(0.0001),<br/>    n_steps_per_checkpoint=100,<br/>)</span><span id="df1a" class="lx kl hi lt b fi mc lz l ma mb">eval_task = training.EvalTask(<br/>    labeled_data=val_generator(batch_size=batch_size, shuffle=True),<br/>    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],<br/>)</span><span id="3e21" class="lx kl hi lt b fi mc lz l ma mb">model = classifier()</span></pre><p id="7eaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，您应该创建一个函数，该函数创建一个训练循环来训练、评估和保存/更新模型。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="bcef" class="lx kl hi lt b fi ly lz l ma mb">output_dir = '~/content/model_adam0001_90562_9010_/'</span><span id="d575" class="lx kl hi lt b fi mc lz l ma mb">def train_model(classifier, train_task, eval_task, n_steps, output_dir):<br/>    '''<br/>    Input: <br/>        classifier - the model you are building<br/>        train_task - Training task<br/>        eval_task - Evaluation task<br/>        n_steps - the evaluation steps<br/>        output_dir - folder to save your files<br/>    Output:<br/>        trainer -  trax trainer<br/>    '''</span><span id="abea" class="lx kl hi lt b fi mc lz l ma mb">    training_loop = training.Loop(<br/>                                classifier, # The learning model<br/>                                train_task, # The training task<br/>                                eval_tasks = eval_task, # The evaluation task<br/>                                output_dir = output_dir) # The output directory</span><span id="7c64" class="lx kl hi lt b fi mc lz l ma mb">    training_loop.run(n_steps = n_steps)</span><span id="6b58" class="lx kl hi lt b fi mc lz l ma mb">    # Return the training_loop, since it has the model.<br/>    return training_loop</span></pre><p id="7c9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">并调用训练循环来运行模型。确保此时你已经打开了Google Colab的免费GPU来加速这个过程，否则你可能需要几天的时间来训练。我选择90562作为我的n_steps，其逻辑是:</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="f959" class="lx kl hi lt b fi ly lz l ma mb">batches in epoch = training set size / batch_size</span><span id="2ab5" class="lx kl hi lt b fi mc lz l ma mb">training_loop = train_model(model, train_task, eval_task, 90562, output_dir_expand)</span></pre><p id="83d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在是喝杯咖啡休息一下的好时机！</p><h1 id="ea7e" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">10.构建精度函数</h1><p id="1eb0" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">既然模型已经被训练和保存，现在是测试模型的时候了，知道它的准确性也是很好的。我们可以先建立一个函数来确定精确度，然后建立一个函数来测试模型。这里有一个计算精度的函数。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="dd5b" class="lx kl hi lt b fi ly lz l ma mb">def compute_accuracy(preds, y, y_weights):<br/>    """<br/>    Input: <br/>        preds: a tensor of shape (dim_batch, output_dim) <br/>        y: a tensor of shape (dim_batch, output_dim) with the true labels<br/>        y_weights: a n.ndarray with the a weight for each example<br/>    Output: <br/>        accuracy: a float between 0-1 <br/>        weighted_num_correct (np.float32): Sum of the weighted correct predictions<br/>        sum_weights (np.float32): Sum of the weights<br/>    """</span><span id="b46d" class="lx kl hi lt b fi mc lz l ma mb">    # Create an array of booleans, <br/>    # True if the probability of positive sentiment is greater than<br/>    # the probability of negative sentiment<br/>    # else False<br/>    is_pos =  preds[:,1] &gt; preds[:,0]</span><span id="04cc" class="lx kl hi lt b fi mc lz l ma mb">    # convert the array of booleans into an array of np.int32<br/>    is_pos_int = np.array(is_pos, dtype = np.int32)<br/>    <br/>    # compare the array of predictions (as int32) with the target (labels) of type int32<br/>    correct = is_pos_int == y</span><span id="9aa2" class="lx kl hi lt b fi mc lz l ma mb">    # Count the sum of the weights.<br/>    sum_weights = np.sum(y_weights)<br/>    <br/>    # convert the array of correct predictions (boolean) into an arrayof np.float32<br/>    correct_float = np.array(correct, dtype = np.float32)<br/>    <br/>    # Multiply each prediction with its corresponding weight.<br/>    weighted_correct_float = correct_float * y_weights</span><span id="1844" class="lx kl hi lt b fi mc lz l ma mb"># Sum up the weighted correct predictions (of type np.float32), to go in the<br/>    # numerator.<br/>    weighted_num_correct = np.sum(weighted_correct_float)<br/> <br/>    # Divide the number of weighted correct predictions by the sum of the<br/>    # weights.<br/>    accuracy = weighted_num_correct / sum_weights </span><span id="418f" class="lx kl hi lt b fi mc lz l ma mb">    return accuracy, weighted_num_correct, sum_weights<br/>        total_num_pred += batch_num_pred</span><span id="8602" class="lx kl hi lt b fi mc lz l ma mb">    # Calculate accuracy over all examples<br/>    accuracy = total_num_correct / total_num_pred</span><span id="ed73" class="lx kl hi lt b fi mc lz l ma mb">    return accuracy</span></pre><h1 id="2a32" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">11.测试模型</h1><p id="b896" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">这里有一个函数来测试我们的模型。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="4db7" class="lx kl hi lt b fi ly lz l ma mb">def test_model(generator, model):<br/>    '''<br/>    Input: <br/>        generator: an iterator instance that provides batches of inputs and targets<br/>        model: a model instance <br/>    Output: <br/>        accuracy: float corresponding to the accuracy<br/>    '''<br/>    <br/>    accuracy = 0.<br/>    total_num_correct = 0<br/>    total_num_pred = 0</span><span id="c8ab" class="lx kl hi lt b fi mc lz l ma mb">    for batch in generator: <br/>        <br/>        # Retrieve the inputs from the batch<br/>        inputs = batch[0]<br/>        <br/>        # Retrieve the targets (actual labels) from the batch<br/>        targets = batch[1]<br/>        <br/>        # Retrieve the example weight.<br/>        example_weight = batch[2]</span><span id="a805" class="lx kl hi lt b fi mc lz l ma mb">        # Make predictions using the inputs<br/>        pred = model(inputs)<br/>        <br/>        # Calculate accuracy for the batch by comparing its predictions and targets<br/>        batch_accuracy, batch_num_correct, batch_num_pred = compute_accuracy(preds=pred, y=targets, y_weights=example_weight)<br/>        <br/>        # Update the total number of correct predictions<br/>        # by adding the number of correct predictions from this batch<br/>        total_num_correct += batch_num_correct<br/>        <br/>        # Update the total number of predictions <br/>        # by adding the number of predictions made for the batch<br/>        total_num_pred += batch_num_pred</span><span id="3c65" class="lx kl hi lt b fi mc lz l ma mb">    # Calculate accuracy over all examples<br/>    accuracy = total_num_correct / total_num_pred</span><span id="4d5c" class="lx kl hi lt b fi mc lz l ma mb">    return accuracy</span></pre><p id="4289" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果的准确率是……78.52%。不伟大，但也不可怕！现在考虑到推特有多难预测，有多少讽刺，有多少俚语，我对这种准确性很满意。唯一能确定的方法是在Twitter的实时数据上进行测试，并用我自己的双眼进行评估。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/a3fa3215a58e2a8212a9db40563f5b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yYeosaTchV5AEViP"/></div></div></figure><h1 id="5021" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">12.授权Tweepy访问Twitter API</h1><p id="8551" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">在访问Twitter数据之前，我们首先需要使用我们之前保存在json文件中的变量来授权Tweepy。如果您达到了速率限制，您将需要设置“wait_on_rate_limit = True ”,这样它将在几分钟内恢复而不会出错。最终我们将使用谷歌云平台的秘密管理器来完成这项工作，但是现在我们正在读取一个本地json文件。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="a7ea" class="lx kl hi lt b fi ly lz l ma mb"># Load Twitter API secrets from an external JSON file<br/>secrets = json.load(open(r'XXXXXXX(the path to your json file)XXXXXXXX/secrets.json'))</span><span id="f54a" class="lx kl hi lt b fi mc lz l ma mb">access_token = secrets['access_token']<br/>access_token_secret = secrets['access_token_secret']<br/>api_key = secrets['api_key']<br/>api_secret = secrets['api_secret']<br/>bearer_token = secrets['bearer_token']</span><span id="6ba9" class="lx kl hi lt b fi mc lz l ma mb"># authorize api handshake</span><span id="3151" class="lx kl hi lt b fi mc lz l ma mb">auth = tweepy.OAuthHandler(api_key, api_secret)</span><span id="7929" class="lx kl hi lt b fi mc lz l ma mb">auth.set_access_token(access_token, access_token_secret)</span><span id="032a" class="lx kl hi lt b fi mc lz l ma mb">api = tweepy.API(auth,wait_on_rate_limit=True)</span></pre><h1 id="9e6d" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">13.找出美国的50个热门话题</h1><p id="154b" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">因此，Twitter定期更新许多目的地的50个热门话题列表。我们将使用此功能访问专门针对美国的主题。我们需要找出美国的woeid (A <strong class="ih hj"> WOEID </strong>(地球上的标识符)是一个唯一的32位参考标识符，最初由GeoPlanet定义，现在由Yahoo！，可以识别地球上的任何特征。)我们现在有一个美国50个热门话题的列表，我们可以每小时重新运行以获得最新的话题。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="44ad" class="lx kl hi lt b fi ly lz l ma mb">def grab_trending_topics(country_id):   <br/>    <br/>    trending_topics = api.trends_place(country_id)                      <br/>    <br/>    topic_list = []<br/>    <br/>    for k in range(len(trending_topics[0]['trends'])):                <br/>        topic = trending_topics[0]['trends'][k]['name']               <br/>        topic_list.append(topic)<br/>   <br/>    return topic_list</span></pre><h1 id="2c22" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">14.为每个热门话题提取最受欢迎的推文</h1><p id="b9e6" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">现在是时候去搜索推特了。在这里，我遍历之前创建的主题列表中的每个热门主题，并搜索包含这些主题的“热门”推文。有很多种方法可以定制这种类型的Twitter搜索，我很开心地使用了所有的参数。例如，你也可以搜索“最近”的推文，或者只搜索特定的纬度、经度和半径。我鼓励你阅读这些文档，并想出一些适合你的项目的东西。你很可能想要“扩展”的推文，因为它们超过了140个字符。</p><p id="8426" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每一条推文，我都会提取与我相关的信息，但是每条推文中还有更多的信息，所以去阅读文档，确保你得到了与你相关的所有信息！此时，我还会列出所有使用过的标签和表情符号。所有这些数据都被附加到数据帧中。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="6975" class="lx kl hi lt b fi ly lz l ma mb">def grab_popular_tweets(topic_list, max_tweets):             <br/>    <br/>    columns = [ 'pulled_at', 'created_at', 'username', 'user_location', 'region', 'search_type', <br/>               'trending_topic', 'retweetcount', 'favorites', 'text', 'hashtags', 'emojis']         # set up columns for dataframes   <br/>    <br/>    tweets_data_grab = pd.DataFrame(columns = columns)                                  # create empty dataframe    <br/>        <br/>    for topic in topic_list:                # loop though each trending topic<br/>                                                            <br/>                                                                                # grab tweets with Cursor<br/>        tweets = tweepy.Cursor(api.search, q = topic,                           # search for each trending topic                                 <br/>                         lang="en", result_type = 'popular',                    # tweets in english , type is "recent"/"popular"<br/>                          tweet_mode = 'extended').items(max_tweets)            # longer tweets,  grab max_tweets number of tweets<br/>        <br/>        tweet_list = [tweet for tweet in tweets]                                # create list of tweets<br/>                    <br/>        tweets_topic = pd.DataFrame(columns = columns)         # create dataframe to put in current top tweets for this town and trending topic<br/>            <br/>        for tweet in tweet_list:                                      # loop through each tweet that was grabbed<br/>            <br/>            username = tweet.user.screen_name                                    # store username<br/>            user_location = tweet.user.location                                  # store location of user<br/>            retweetcount = tweet.retweet_count                                   # store retweet count<br/>            favorites = tweet.favorite_count                                     # store favorite count<br/>            hashtags = [h['text'].lower() for h in tweet.entities['hashtags']]   # store hashtags    <br/>            search_type = 'popular'                                              # store search type<br/>            region = "USA"                                                       # trending tweets in USA<br/>            created_at = tweet.created_at                                        # time tweet created<br/>            pulled_at = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")    # time tweet was pulled<br/>        <br/>            try:                              <br/>                text = tweet.retweeted_status.full_text    # store text if it's a retweet<br/>            <br/>            except AttributeError: <br/>                text = tweet.full_text                     # store text if it's a regular tweet<br/>                <br/>            emoji = list(emojis.get(text))                 # get the emojis<br/>            <br/>            curr_tweet = [pulled_at, created_at, username, user_location, region,     # store current tweet's data in a list soon to be a row<br/>                          search_type, topic, retweetcount, favorites, text, hashtags, emoji]                             <br/>        <br/>            tweets_topic.loc[len(tweets_topic)] = curr_tweet                         # add current tweet data to dataframe for town and topic         <br/>                                <br/>        tweets_topic.sort_values(by=['retweetcount', 'favorites'], inplace = True, ascending = False)     # sort the retweet values highest first<br/>                                <br/>        tweets_data_grab = pd.concat([tweets_data_grab, tweets_topic], ignore_index = True, sort = False)       # concatenate top n to final dataframe<br/>        <br/>    return tweets_data_grab</span></pre><h1 id="a04d" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">15.建立一个功能来预测新的推文</h1><p id="e48d" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">现在，我们需要一个函数，可以获取新的推文，并使用我们的模型对其进行评估。在模型给每条推文一个正概率和一个负概率之后，这个函数将它们进行比较，看哪一个更大，然后给推文分配适当的情感标签。一些推文可能会返回一个错误(例如，如果没有文本只有一个超链接)，这个函数将捕捉这些错误，不分配任何情绪。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="cbda" class="lx kl hi lt b fi ly lz l ma mb">def predict(sentence):<br/>    inputs = np.array(tweet_to_tensor(sentence, vocab_dict=Vocab))<br/>    <br/>    # Batch size 1, add dimension for batch, to work with the model<br/>    inputs = inputs[None, :]  <br/>     <br/>    try:<br/>    <br/>        # predict with the model<br/>        preds_probs = model(inputs)<br/>    <br/>        # Turn probabilities into categories<br/>        preds = int(preds_probs[0, 1] &gt; preds_probs[0, 0])<br/>    <br/>        sentiment = "negative"<br/>        if preds == 1:<br/>            sentiment = 'positive'<br/>            <br/>    except:<br/>        <br/>        return  'N/A', -0.0, -0.0</span><span id="2d9b" class="lx kl hi lt b fi mc lz l ma mb">    return sentiment, round(float(preds_probs[0, 0]),4), round(float(preds_probs[0, 1]),4)</span></pre><h1 id="92b7" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">16.建立一个功能，将情感添加到新的推文中</h1><p id="2525" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">现在我们可以找到每条tweet的情绪，我们也可以使用下面的函数将这些值添加到tweet数据的现有数据帧中，使用我们刚刚在上面创建的函数。之后，我们可以将数据帧保存到csv文件中！</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="117f" class="lx kl hi lt b fi ly lz l ma mb">def add_sentiment(tweets_data):</span><span id="cb90" class="lx kl hi lt b fi mc lz l ma mb">    for i in range(len(tweets_data)):            </span><span id="2a74" class="lx kl hi lt b fi mc lz l ma mb">        tweets_data.loc[i, 'sentiment'], tweets_data.loc[i, 'neg_prob'], tweets_data.loc[i, 'pos_prob'] = predict(tweets_data['text'].iloc[i])        <br/>                <br/>    return tweets_data</span></pre><p id="c32b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终，我们将把所有这些函数放在一起，稍后在python脚本(一个. py文件)中的云中调用它们。稍后将详细介绍。现在，我们应该在谷歌云平台上设置好一切！</p><h1 id="3a57" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">17.注册谷歌云平台</h1><p id="b7a7" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">谷歌不仅通过Colab免费提供他们的GPU(有一定限度)，他们还在他们的云平台上有一个完整的免费层，并在注册90天后提供300美元的信用。这将允许我们免费运行几个月的模型！…感谢谷歌！！第一步是注册一个账户。如果您想继续并启用计费，您可以现在就这样做，或者您可以等待，直到您进入一些后续步骤，世卫组织的教程将带您完成。这里有一个链接让你开始… <a class="ae ju" href="https://cloud.google.com/free/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">谷歌云平台免费层</strong> </a></p><h1 id="ca0f" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">18.创建项目</h1><p id="f453" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">我们需要做的第一件事是创建一个项目。这将允许我们链接所有的资源，并在一个罩下监控一切。有几种编程方式可以做到这一点，但我建议使用控制台。这里有一个谷歌有用教程的链接……<a class="ae ju" href="https://cloud.google.com/resource-manager/docs/creating-managing-projects#console" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">创建和管理项目</strong> </a></p><h1 id="da9f" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">19.设置服务帐户</h1><p id="5bba" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">服务帐户是实例或应用程序可以用来代表您运行API请求的标识。当您创建新的云项目时，Google Cloud会自动在该项目下创建一个计算引擎服务帐户和一个应用引擎服务帐户。但是为了使我们以后的生活更容易，我们将遵循最佳实践来创建一个新的服务帐户，它将拥有所有必要的权限。您可以在创建服务帐户时或在下面的下一步中设置权限。按照本教程开始… <a class="ae ju" href="https://cloud.google.com/iam/docs/creating-managing-service-accounts" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">创建和管理服务帐户</strong> </a>。为了进一步阅读… <a class="ae ju" href="https://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances#console_1" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">为实例</strong> </a>创建和启用服务帐户。</p><p id="4324" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">强烈建议您为您的应用程序使用Google Cloud客户端库。由于我们将使用Google云存储和Secrets Manager的客户端库，我们将编写的脚本将自动链接到API的密钥和存储桶！Google Cloud客户端库使用一个名为应用程序默认凭证(ADC)的库来自动查找您的服务帐户凭证。你可以在这里了解更多… <a class="ae ju" href="https://cloud.google.com/docs/authentication/production" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">认证为服务帐户</strong> </a></p><h1 id="036c" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">20.设置IAM权限</h1><p id="9a4e" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">我们在创建服务帐户时有机会添加权限，但在这里，我们将导航到IAM权限页面并在那里进行设置。始终确保只授予项目的最低权限。这里有教程，但你也将在接下来的秘密管理器教程中完成这个过程，这里有链接… <a class="ae ju" href="https://cloud.google.com/secret-manager/docs/configuring-secret-manager" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">配置秘密管理器</strong> </a> <strong class="ih hj">。</strong>下面你可以看到我的新服务账户“twitter-test”，这是我们将要授予权限的服务账户。为了访问存储桶，我添加了<strong class="ih hj">存储管理员</strong>角色，为了访问机密和密钥，我向我的新服务帐户添加了<strong class="ih hj">机密管理器机密访问器</strong>角色。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/17505115b8e59bfa66caf8c12c249a9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TEgNTfLazSq_rqFr"/></div></div></figure><h1 id="5b23" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">21.设置机密管理器</h1><p id="df46" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">为了在不泄露你的密钥和秘密的情况下访问Twitter API，你可以使用谷歌的秘密管理器。首先你需要完成教程… <a class="ae ju" href="https://cloud.google.com/secret-manager/docs/configuring-secret-manager" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">为这个项目配置秘密管理器</strong> </a>，然后浏览<a class="ae ju" href="https://cloud.google.com/secret-manager/docs/quickstart" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">快速入门</strong> </a>以获得如何创建和访问秘密的概述。或者更深入的看… <strong class="ih hj"> </strong> <a class="ae ju" href="https://cloud.google.com/secret-manager/docs/creating-and-accessing-secrets#secretmanager-access-secret-version-python" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">创作秘籍和版本</strong> </a>。机密包含一个或多个机密版本，以及标签和复制信息等元数据。秘密的实际内容存储在秘密版本中，当您稍后在代码中调用它们时，您将访问秘密版本。当您创建一个秘密，第一个版本将自动为您创建。如果您需要更改、更新、删除或更改密码，您可以遵循教程… <a class="ae ju" href="https://cloud.google.com/secret-manager/docs/managing-secrets#secretmanager-list-secrets-web" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">管理秘密</strong> </a>。</p><p id="f377" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个项目，我们需要使用Web UI创建一些秘密，然后我们将在python脚本中放置代码来访问它们。首先，我添加了用于访问Twitter API的四个令牌、秘密和密钥，并相应地给它们命名。如果有人想知道，你应该输入不带任何引号(“”或“)的代码<strong class="ih hj"> <em class="jd">。</em></strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/9718f9fe2fe0410f380e77ab96781e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*538eVP1GWYHSTe6R"/></div></div></figure><p id="b755" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦它们被上传，我们可以在我们的python脚本中添加一个小函数来帮助以后访问它们。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="fcaf" class="lx kl hi lt b fi ly lz l ma mb">def access_secret_version(project_id, secret_id, version_id):<br/>    """<br/>    Access the payload for the given secret version if one exists. The version<br/>    can be a version number as a string (e.g. "5") or an alias (e.g. "latest").<br/>    """</span><span id="107c" class="lx kl hi lt b fi mc lz l ma mb">    # Create the Secret Manager client.<br/>    client = secretmanager.SecretManagerServiceClient()</span><span id="6828" class="lx kl hi lt b fi mc lz l ma mb">    # Build the resource name of the secret version.<br/>    name = f"projects/{project_id}/secrets/{secret_id}/versions/{version_id}"</span><span id="7663" class="lx kl hi lt b fi mc lz l ma mb">    # Access the secret version.<br/>    response = client.access_secret_version(request={"name": name})</span><span id="624b" class="lx kl hi lt b fi mc lz l ma mb">    payload = response.payload.data.decode("UTF-8")</span><span id="23d2" class="lx kl hi lt b fi mc lz l ma mb">    return payload</span></pre><p id="7fda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是python脚本后面的函数调用和Twitter API授权。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="38bc" class="lx kl hi lt b fi ly lz l ma mb">project_id = 'twitter-test-298418'<br/>version_id = 'latest'</span><span id="7145" class="lx kl hi lt b fi mc lz l ma mb">access_token = access_secret_version(project_id, 'access_token', version_id)<br/>access_token_secret = access_secret_version(project_id, 'access_token_secret', version_id)<br/>api_key = access_secret_version(project_id, 'api_key', version_id)<br/>api_secret = access_secret_version(project_id, 'api_secret', version_id)</span><span id="d917" class="lx kl hi lt b fi mc lz l ma mb"># authorize api handshake<br/>auth = tweepy.OAuthHandler(api_key, api_secret)<br/>auth.set_access_token(access_token, access_token_secret)<br/>api = tweepy.API(auth, wait_on_rate_limit=True)</span></pre><h1 id="dca0" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">22.在Google云计算引擎上设置Linux虚拟机实例</h1><p id="c3ae" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">接下来是在云中创建并启动一个虚拟机实例。这是我们存储文件、编写和运行代码以及每小时自动创建csv文件的地方。启用计算引擎API的第一步。然后创建一个虚拟机实例。你可以完全按照这个教程，只是按照所有的标准选择… <a class="ae ju" href="https://cloud.google.com/compute/docs/quickstart-linux" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">使用Linux虚拟机</strong> </a>快速入门。你唯一需要确定的是选择你的新服务账户，而不是谷歌提供的那个，见下图。对于其他选项，我选择一切标准，但你总是可以根据你的项目使用较小的CPU。请确保在您单击SSH按钮之前启用弹出窗口！</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/d9471b988cbe2c9e192a2bf7236e34c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*N9mZWR0JhZ27o_Ja"/></div></div></figure><p id="c1e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们稍后将回到VM，但是首先我们应该设置其他组件。</p><h1 id="6543" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">23.创建存储桶</h1><p id="c6b8" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">下一步应该是创建存储桶，您希望在其中存储您的充满tweet数据的csv文件。你可以用谷歌云存储桶轻松做到这一点。您可以在此处跟随本教程，通过快速简单的过程……<a class="ae ju" href="https://cloud.google.com/storage/docs/creating-buckets#storage-create-bucket-console" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">创建存储桶</strong> </a>。我使用了所有预先选择的标准选项。您需要记下这里的bucket名称，以便稍后在您的脚本中使用。</p><h1 id="1b37" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">24.在虚拟机中安装Google云存储库</h1><p id="db10" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">因为我们将在虚拟机中安装和使用客户端库，所以我们不需要在这里下载服务帐户密钥json文件。记住，这样做，我们能够自动访问秘密和存储桶。我们只需要在虚拟机中运行“<strong class="ih hj">安装客户端库代码</strong>”python代码片段。你可以在这里阅读这些教程，但我们将只使用如下所示的小部分python代码……<a class="ae ju" href="https://cloud.google.com/storage/docs/reference/libraries#cloud-console" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">谷歌存储客户端库</strong> </a>和<a class="ae ju" href="https://cloud.google.com/secret-manager/docs/reference/libraries" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">秘密管理器客户端库</strong> </a>。</p><p id="928e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们可以导航回虚拟机实例。我们将首先确保VM拥有所有必要的库来与Google Cloud一起工作。您可以通过键入“<strong class="ih hj"> python3 -V </strong>”来检查您是否已经安装了python3、pip等，这将告诉您当前的版本(如果有的话)。对我来说，这是我需要运行的三个命令来开始使用Google云存储客户端库。</p><p id="54c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> sudo apt-get安装python3-pip </strong></p><p id="f6d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> pip3安装–升级pip </strong></p><p id="ddf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> pip3安装-升级谷歌云存储</strong></p><p id="1822" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> pip3安装-升级Google-cloud-secret-manager</strong></p><p id="2a40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">*注意在“升级”之前应该有一个双连字符</em></p><p id="d46c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您需要将这段代码添加到python脚本的末尾，以便将csv数据发送到存储桶。</p><pre class="jf jg jh ji fd ls lt lu lv aw lw bi"><span id="b5a4" class="lx kl hi lt b fi ly lz l ma mb"># Instantiates a client<br/>storage_client = storage.Client()</span><span id="f925" class="lx kl hi lt b fi mc lz l ma mb"># The name for the bucket<br/>bucket_name = "twitter-test-bucket"             </span><span id="0283" class="lx kl hi lt b fi mc lz l ma mb"># Gets the bucket<br/>bucket = storage_client.get_bucket(bucket_name)</span><span id="60b5" class="lx kl hi lt b fi mc lz l ma mb">data = bucket.blob("tweets_data.csv")</span><span id="be02" class="lx kl hi lt b fi mc lz l ma mb">data.upload_from_filename(r"/home/mr_sam_j_brady/tweets_data.csv")</span></pre><h1 id="5ce7" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">25.将文件上传到虚拟机</h1><p id="320c" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">回到虚拟机…右上角的齿轮图标允许您上传任何文件，我们将从上传之前创建的Vocab.json文件开始。接下来，我们应该上传在模型的训练和评估过程中保存到输出目录的所有文件。如果您使用Keras而不是Trax，请不要担心，只要确保上传训练模型时保存的所有文件，甚至包括单独的文件夹。这里有一个Keras教程的链接，在这里你可以看到更多的细节… <a class="ae ju" href="https://towardsdatascience.com/sentiment-analysis-for-text-with-deep-learning-2f0a0c6472b5" rel="noopener" target="_blank"> <strong class="ih hj"> Keras教程</strong> </a> <strong class="ih hj">。对于我们来说，我们还需要上传一个pickle文件，一个train文件到train文件夹，一个eval文件到eval文件夹，以及一个config.gin文件。在训练模型时，所有这些都保存在输出目录中，因此您可以在那里找到它们。下面是我使用<strong class="ih hj"> ls -lh </strong>命令在VM中上传文件的截图。</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/a70769bbdd326ca7a94d9ecac29d64be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0QKT3QHin7plZAGQ"/></div></div></figure><p id="a0e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我会尽量具体说明我使用的命令，但是如果你需要Linux命令的教程… <a class="ae ju" href="https://www.hostinger.com/tutorials/linux-commands" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">基本Linux命令备忘单</strong> </a></p><p id="f7f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是我最常用的命令，并附有简短的示例和解释:</p><ul class=""><li id="8ef7" class="jv jw hi ih b ii ij im in iq jx iu jy iy jz jc ka kb kc kd bi translated"><strong class="ih hj"> pwd </strong>打印工作驱动器(您当前所在的位置)</li><li id="6f30" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj"> cd </strong>将目录改回主目录</li><li id="c349" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj"> cd列车</strong>更改到列车目录</li><li id="05fc" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj"> mkdir train </strong>制作一个名为train的目录</li><li id="2365" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj"> rmdir train </strong>删除一个名为train的目录</li><li id="c420" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj"> rm file.json </strong>删除名为file.json的文件</li><li id="751c" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj"> rm *py </strong>删除所有以。巴拉圭</li><li id="6224" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated"><strong class="ih hj"> mv doc.json train </strong>将文件doc.json移动到train目录</li><li id="5991" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated">列出当前目录下的所有文件和目录</li></ul><h1 id="be6c" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">26.将Python库和依赖项安装到虚拟机</h1><p id="7b69" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">为了运行python脚本，我们首先必须安装脚本中使用的所有必要的库、包和依赖项。最好的方法是在本地文本编辑器中创建一个<strong class="ih hj"> requirements.txt </strong>文件，然后<strong class="ih hj">将它上传到VM </strong>。下面是一个简短的教程，<a class="ae ju" href="https://note.nkmk.me/en/python-pip-install-requirements/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">如何安装Python包</strong> </a></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es md"><img src="../Images/345ffb3b966520434fc69e7e88281132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bb7cDrSlSHeA7Iil"/></div></div></figure><p id="e39d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后在VM实例中运行下面的命令，在云空间中安装所有的包，供您的脚本使用。</p><p id="5c5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">pip 3 install-r requirements . txt–no-cache-dir</strong></p><p id="7c38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">*注意在“无缓存”之前应该有一个双连字符</em></p><p id="f676" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果在您尝试运行脚本时出现错误，您可能可以通过更改到特定版本来修复它，或者您可能需要在这里添加一些其他库。</p><h1 id="6cc4" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">27.使用Nano文本编辑器创建Python脚本</h1><p id="ef79" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">既然已经上传了一个文件，并且安装了所有的依赖项，那么是时候实际编写/上传python脚本了，该脚本包含了完成从twitter中提取推文、对推文执行情感分析以及在存储桶中创建一个充满数据的csv文件等工作所需的所有函数。为此，最简单的方法是在VM实例中使用内置的Nano文本编辑器。你所要做的就是打开编辑器，输入“nano ”,然后输入你想给你的脚本起的名字。py”。最简单的方法可能是从本地计算机、Jupyter / Colab notebook或GitHub repo上的文件中复制并粘贴，而不是在VM中输入所有内容。这是我的包含python脚本的Colab笔记本的链接，你可以直接从那里复制代码……<a class="ae ju" href="https://colab.research.google.com/drive/1CG5mexiCgmf1ADod7VJLbYldg6tm89fF?usp=sharing" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">Google Colab笔记本Python脚本(Twitter _ perspective . py)</strong></a></p><p id="d57a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">纳米推特_情操. py </strong></p><p id="7fea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要退出编辑器并保存文件，按下<strong class="ih hj"> Control + X </strong>，然后按下<strong class="ih hj"> Y </strong>，然后按下<strong class="ih hj">进入</strong></p><p id="c8bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">既然您的脚本已经完成，并且执行脚本的一切都已就绪，现在可能是测试一切的好时机。您可以通过键入以下命令来运行该脚本…</p><p id="4f0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">python 3 Twitter _情操. py </strong></p><p id="d103" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果没有错误，我们可以继续自动化这个过程。</p><h1 id="98ba" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">28.使用Cron作业和TMUX自动化脚本</h1><p id="58ce" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">如果一切顺利，下一步是使用Cron作业自动安排脚本运行的时间(每天、每小时、每周等)，然后使用TMUX保持脚本运行，即使在关闭虚拟机窗口后也是如此。这里是Google关于cron作业的教程… <a class="ae ju" href="https://cloud.google.com/scheduler/docs/configuring/cron-job-schedules" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">配置Cron作业调度</strong> </a> <strong class="ih hj">，</strong>在这里你可以更详细地看到它是如何工作的。要在虚拟机中执行cron作业，您可以键入:</p><p id="3812" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">crontab–e</strong>然后按<strong class="ih hj">进入</strong>，然后按<strong class="ih hj"> 1 </strong>，然后再按<strong class="ih hj">进入</strong></p><p id="c5e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你将被带到一个新的文本编辑器，应该导航到底部，直接在“m h dom mon dow”下面。在这里，您可以编写新代码来创建自定义日程。要在我们键入的第0分钟每小时运行我们的脚本…</p><p id="12fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">0 * * * * python 3 Twitter _情操. py </strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/5364078f0a623aaf38cdc44fc469ed78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tLpMI3E6LbwRsPxY"/></div></div></figure><p id="4ee3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后键入<strong class="ih hj"> Control + X </strong>，再键入<strong class="ih hj"> Y </strong>，再键入<strong class="ih hj"> Enter </strong></p><p id="7dbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要安装TMUX，您可以键入:</p><p id="8ae7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> sudo apt-get安装tmux </strong>然后<strong class="ih hj">进入</strong>然后<strong class="ih hj"> Y </strong></p><p id="ed96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们应该能够关闭SSH窗口，我们的脚本仍将运行！</p><p id="a9b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，所有困难的工作都完成了！现在您可以高枕无忧了，因为您的python脚本是自动化的，ML模型正在云中运行。前往您的存储桶，等待您的csv文件到达。您甚至可以监控数据收集，以确保它们没有中断，只需查看“虚拟机实例监控”选项卡，每小时查看一次！！</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/ff2a8191354f678440368a03690a1eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pGgc1W4xO_Grb4I3"/></div></div></figure><h1 id="db64" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">29.在Google Data Studio中创建仪表板</h1><p id="7d7d" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">您可以对新的数据文件做很多事情，并且有很多选项来可视化数据。最初，我打算尝试使用大查询和云功能将数据发送到Tableau或其他可视化工具。然而，我偶然在某处看到一篇文章，解释了如何将存储桶直接连接到Google Data Studio。听起来好得令人难以置信，但事实并非如此。你甚至可以更新1小时的新鲜度。这里有一个谷歌教程的链接… <a class="ae ju" href="https://support.google.com/datastudio/answer/7511998?hl=en" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">连接谷歌云存储</strong> </a></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/b8b074e82820bfffdf8597880be7a848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZBCJHkMn9FVYoa-Q"/></div></div></figure><p id="1b0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://datastudio.google.com/reporting/0a22198e-c33c-4c51-a859-ca258ca878e9/page/5DSsB" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">点击此链接看上面的仪表盘！</strong>T13】</a></p><p id="4305" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不会带你创建仪表板，但请看看我的，如果你觉得有趣就分享吧！</p><h1 id="838c" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">30.结尾和后续步骤</h1><p id="ec63" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">希望你能想出一些对你有益甚至让你开心的应用。我想到的几件事是改变tweepy搜索，以获取关于感兴趣的特定主题的twitter数据，也许是一种产品。您甚至可以将tweepy搜索缩小到特定的位置和半径，也许是多个城市。您可以将tweepy搜索从“热门”更改为“最近”。这么多可能性。</p><p id="c557" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对我来说，我认为下一步将是可视化每日twitter数据——创建一个仪表板和存储桶，将twitter数据保存24小时。可能每周！我所知道的是，在接下来的90天里，我仍然有足够的谷歌云存储空间来运行！感谢谷歌！！</p><h1 id="a983" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">一些有用的链接</h1><p id="68bf" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated"><a class="ae ju" href="https://datastudio.google.com/reporting/0a22198e-c33c-4c51-a859-ca258ca878e9/page/5DSsB" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">链接到Twitter情绪分析仪表板</strong> </a></p><p id="9c82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://github.com/sam-brady/twitter-sentiment" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">我的GitHub回购本项目</strong> </a></p><p id="85f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://colab.research.google.com/drive/1-wkVF8PtwjGQxB5lM8oyNz4cfDuujri_?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Google Colab笔记本—训练和测试</strong> </a></p><p id="7319" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://colab.research.google.com/drive/1CG5mexiCgmf1ADod7VJLbYldg6tm89fF?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Google Colab笔记本— Python脚本(twitter _情操. py) </strong> </a></p><p id="32ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://towardsdatascience.com/how-to-process-and-visualize-financial-data-on-google-cloud-with-big-query-data-studio-f37c2417d4ef" rel="noopener" target="_blank"> <strong class="ih hj">如何用大查询在Google Cloud上处理和可视化财务数据&amp; Data Studio </strong> </a></p><p id="f83f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://towardsdatascience.com/how-to-automate-financial-data-collection-with-python-using-tiingo-api-and-google-cloud-platform-b11d8c9afaa1" rel="noopener" target="_blank"> <strong class="ih hj">如何使用API和Google Cloud使用Python自动收集金融数据</strong> </a></p><p id="bed1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://towardsdatascience.com/twitter-data-collection-tutorial-using-python-3267d7cfa93e" rel="noopener" target="_blank"> <strong class="ih hj"> Twitter数据收集教程使用Python </strong> </a></p><p id="270c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://towardsdatascience.com/automate-reports-in-google-data-studio-based-on-data-from-google-bigquery-b7964b2cf893" rel="noopener" target="_blank"> <strong class="ih hj">根据来自Google BigQuery </strong> </a>的数据，在Google Data Studio中自动生成报告</p></div></div>    
</body>
</html>