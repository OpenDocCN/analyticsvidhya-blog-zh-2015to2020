<html>
<head>
<title>Stock Price Prediction: Single Neural Network with Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">股票价格预测:基于张量流的单神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/stock-price-prediction-single-neural-network-with-tensorflow-75b64af74ed6?source=collection_archive---------11-----------------------#2020-05-17">https://medium.com/analytics-vidhya/stock-price-prediction-single-neural-network-with-tensorflow-75b64af74ed6?source=collection_archive---------11-----------------------#2020-05-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b530d8a0a29aabcc63dda7d83c8bb5a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F1WP5r1wndvKYeYE.jpeg"/></div></div></figure><p id="1919" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们学习如何在TensorFlow后端的帮助下，使用单层神经网络来预测股票价格。当您看到这样一个简单的架构在股票价格数据集上的表现有多么不可思议时，您会惊叹不已。<br/>本博客的内容灵感来自Coursera系列:<a class="ae jo" href="https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction/home/welcome" rel="noopener ugc nofollow" target="_blank">序列、时间序列和预测</a>。</p><p id="d4c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是我们关于时间序列预测系列博客的第三篇文章。链接到前两个:</p><ul class=""><li id="351b" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated"><a class="ae jo" rel="noopener" href="/analytics-vidhya/stock-price-prediction-facebook-prophet-34c385ff05a9?source=your_stories_page---------------------------">股票预测:脸书预言家</a></li><li id="8af9" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated"><a class="ae jo" rel="noopener" href="/analytics-vidhya/statistical-approach-to-stock-price-prediction-naive-forecast-moving-average-40f93e221e06?source=your_stories_page---------------------------">股价预测的统计方法:朴素预测、移动平均线</a></li></ul><h1 id="af4f" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">加载数据集</h1><p id="1868" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">我们使用新德国基金的数据。它是作为熊猫数据帧加载的。我们预测开盘价。因此，列OPEN被创建到NumPy数组的一个实例中。总共有996个值，我们决定选择850:146的训练验证分割。</p><h1 id="ace8" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">准备要素和标签</h1><p id="0865" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">我们创建Tensorflow对象数据集的一个实例。下面的函数为我们完成了这项工作:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="b86a" class="lp ke hi ll b fi lq lr l ls lt">def windowed_dataset(series,window_size,batch_size, shuffle_buffer):<br/>   dataset = tf.data.Dataset.from_tensor_slices(series)<br/>   dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)<br/>   dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))<br/>   dataset = dataset.map(lambda window: (window[:-1], window[-1]))<br/>   dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))<br/>   dataset = dataset.batch(batch_size).prefetch(1)<br/>   return dataset</span></pre><p id="e5bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于Tensorflow的新手来说，这似乎需要解释很多东西！让我们逐一了解每个命令。</p><p id="5afd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">变量series是一个NumPy数组，包含您的股票价格值，在我们的例子中是开盘价。NumPy数组中的每个第<em class="lu">n</em>条目对应于第<em class="lu">n</em>天的开盘价。</p><p id="b6ee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了让事情更清楚，让我们一个接一个地检查每个命令。现在，让我们假设变量series存储前十个整数的NumPy数组。我们将为您显示每个命令的相应输出。</p><p id="72b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤1: </strong>用系列值创建一个Tensorflow数据集实例。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="3cb0" class="lp ke hi ll b fi lq lr l ls lt">dataset = tf.data.Dataset.from_tensor_slices(series)</span></pre><p id="6019" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤2: </strong>数据被分割成window_size项的块，每个块移动一个值。这会以表格格式排列数据。参数drop_remainder通过裁剪数据来确保数据窗口中的所有行长度相同。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="28fb" class="lp ke hi ll b fi lq lr l ls lt">dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/5943e950c08ac4cfdf4a7d61568909b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/format:webp/1*4rNHtS1xvJcgDDW_3ez_0Q.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">drop_remainder=False</figcaption></figure><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/5fa256afef61988e900353fadab26512.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/1*3MbYj7NIjSjarwCEraLVKg.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">drop_remainder= True</figcaption></figure><p id="9fb9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第三步:</strong>数据被扁平化，以便于处理。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="da99" class="lp ke hi ll b fi lq lr l ls lt">dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))</span></pre><p id="f7e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第四步:</strong>接下来是将数据拆分成Xs和Ys；那就是特性和标签。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="44b2" class="lp ke hi ll b fi lq lr l ls lt">dataset = dataset.map(lambda window: (window[:-1], window[-1]))</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/112d2bef3fbbc3c4a3cfa617f4ced760.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*7gWzVNR6AQyMJouPsakF7w.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">第三步输出</figcaption></figure><p id="1fc1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第五步:</strong>数据洗牌。请注意，如果第十个X值与第三个X值交换，第十个Y值也会与第三个Y值交换。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="2009" class="lp ke hi ll b fi lq lr l ls lt">dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/0f1a28749c7a8c6222c4026662208eae.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*xb5WGWtyBvtwGdbOOy8hrg.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">输出步骤4</figcaption></figure><p id="a369" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们有10个值的数据集，假设变量<em class="lu"> shuffle_buffer </em> =5。它会用前五个元素填充缓冲区，随机选取一个值，然后在进行下一个随机采样之前用第六个元素替换它。这个过程不断重复。</p><p id="5824" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第六步:</strong>我们更喜欢通过批量发送数据来训练我们的模型。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="7eed" class="lp ke hi ll b fi lq lr l ls lt">dataset = dataset.batch(batch_size).prefetch(1)</span></pre><h1 id="3430" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">模型</h1><p id="db69" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">我们使用一个单一的密集层，本质上就像一个身份功能。命名图层是一个很好的做法，因为它有助于我们稍后研究它的属性。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="2b83" class="lp ke hi ll b fi lq lr l ls lt">l0 = tf.keras.layers.Dense(1, input_shape=[window_size])<br/>model = tf.keras.models.Sequential([l0])<br/>model.compile(loss=”mse”, optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9))<br/>model.fit(dataset,epochs=100,verbose=0)</span></pre><h1 id="ace5" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">预言；预测；预告</h1><p id="1650" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">预测值以橙色显示。验证值用蓝色表示。<br/>平均汇率为0.443。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/6845615d8d6c1d014ac8904b2b1c751f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zEZ5P2ov_TJCc7zSTdyZrw.png"/></div></div></figure><h1 id="46d9" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结论</h1><p id="9316" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">令人惊讶的是，单层神经网络在这个数据集上胜过脸书先知。我们不确定为什么会发生这种情况。也许，我们不能为Prophet恰当地选择超参数。</p><p id="6110" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Tensorflow实现在<a class="ae jo" href="https://github.com/nikita-0209/stock_price_detection/blob/master/Stock_Prediction_Single_NN.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>可用。博客和代码由Nikita Saxena编译。</p></div></div>    
</body>
</html>