<html>
<head>
<title>Seq2seq NLG: The Good, the Bad and the Boring</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLG:好的、坏的和无聊的</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/seq2seq-nlg-the-good-the-bad-and-the-ugly-8de0a05d9da1?source=collection_archive---------10-----------------------#2019-12-29">https://medium.com/analytics-vidhya/seq2seq-nlg-the-good-the-bad-and-the-ugly-8de0a05d9da1?source=collection_archive---------10-----------------------#2019-12-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/31d76caa59426b88db30393c12304aa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IwjhhLvt-TSeiGivk2Paaw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">克林特·伊斯特伍德在塞尔吉奥·莱奥内的电影《善、恶、丑》中</figcaption></figure><p id="b81a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在自然语言生成(NLG)中，依赖于领域的定制架构和基于模板的方法长期以来一直占据主导地位，这是因为输入数据是异构的，需要认知和语言通知任务来将其转换为适合通信的消息。此外，目标文本更不用说成对的输入和目标文本很难得到。</p><p id="f58d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在神经机器翻译之后，NLG的序列对序列(seq2seq)模型出现了，它承诺生成端到端的语法文本，这些文本保留了目标文本的风格，同时仍然传达了输入内容。</p><p id="daf7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">2017端到端(e2e) NLG挑战赛很好地体现了NLG seq2seq的热情。基线本身是一个seq2seq方法，许多提交竞争或后来提出的系统都是基于这个模型。这些方法的综合以及对数据集和评估的详细分析可以在<a class="ae js" href="https://www.sciencedirect.com/science/article/pii/S0885230819300919" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="6586" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在本文中，我首先介绍了这一挑战的关键要素，即数据集、基线、评估和一些为改善基线而提出的seq2seq策略。然后，我介绍了一个基本seq2seq NLG的实现，它使用了NLP 上的<a class="ae js" href="https://github.com/fastai/course-nlp" rel="noopener ugc nofollow" target="_blank"> Fastai课程中为神经机器翻译提供的</a><a class="ae js" href="https://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> Fastai </a>代码，在一些基于单词的指标上取得了比基线wrt更好的分数。Fastai代码的优势在于，它可以随时使用并实现seq2seq学习问题的一些最新解决方案。因此，人们可以专注于尝试不同的想法。</p><p id="137c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">该FastAai seq2seq NLG模型的代码和笔记本以及评估结果的预处理可在github <a class="ae js" href="https://github.com/nadjet/e2e_nlg" rel="noopener ugc nofollow" target="_blank">此处</a>获得。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="0f0f" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">资料组</h1><p id="bc75" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">e2e NLG竞赛数据集由大约50k对含义表示(MRs)和简短自然语言(NL)餐馆描述组成，其中不到10%是验证集。+6k的MR是唯一的，这意味着一个MR可以以不同的方式实现。数据集已经过组织，因此输入不会在验证和测试集中重复，即使在删除了场所名称之后也是如此。</p><p id="72d1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下面是MR的一个例子，它可能有6种不同的表达方式:</p><blockquote class="ld le lf"><p id="f0ff" class="iu iv lg iw b ix iy iz ja jb jc jd je lh jg jh ji li jk jl jm lj jo jp jq jr hb bi translated"><strong class="iw hj">先生:</strong></p><p id="f7a0" class="iu iv lg iw b ix iy iz ja jb jc jd je lh jg jh ji li jk jl jm lj jo jp jq jr hb bi translated"><em class="hi">名称【老鹰】，<br/> eatType【咖啡店】，<br/>美食【英式】，<br/>价格区间【30多】，<br/>定制【高】，<br/>地区【河畔】，<br/> kidsFriendly【是】，<br/>附近【汉堡王】</em></p><p id="bac2" class="iu iv lg iw b ix iy iz ja jb jc jd je lh jg jh ji li jk jl jm lj jo jp jq jr hb bi translated"><strong class="iw hj"> NLs: </strong></p><p id="52cb" class="iu iv lg iw b ix iy iz ja jb jc jd je lh jg jh ji li jk jl jm lj jo jp jq jr hb bi translated">(Eagle是河滨汉堡王附近一家受到高度评价的儿童友好型咖啡店。它有英国食物，价格范围是30多英镑。</p><p id="7b36" class="iu iv lg iw b ix iy iz ja jb jc jd je lh jg jh ji li jk jl jm lj jo jp jq jr hb bi translated">(Eagle是一家价格不菲的家庭咖啡店，供应英国菜。它位于汉堡王附近。</p><p id="75ba" class="iu iv lg iw b ix iy iz ja jb jc jd je lh jg jh ji li jk jl jm lj jo jp jq jr hb bi translated">(3)河滨区汉堡王附近有一家名为Eagle的儿童友好型咖啡店，顾客评价很高，价格适中，在30英镑左右。</p><p id="8cab" class="iu iv lg iw b ix iy iz ja jb jc jd je lh jg jh ji li jk jl jm lj jo jp jq jr hb bi translated">(4)评价很高的The Eagle English咖啡店位于汉堡王附近的riverside，价格区间30多。</p><p id="e938" class="iu iv lg iw b ix iy iz ja jb jc jd je lh jg jh ji li jk jl jm lj jo jp jq jr hb bi translated">(5)有一家叫老鹰的英国咖啡店。它在河边地区的汉堡王附近。它适合儿童，价格在30英镑以上。</p><p id="9494" class="iu iv lg iw b ix iy iz ja jb jc jd je lh jg jh ji li jk jl jm lj jo jp jq jr hb bi translated">(6)老鹰在北部市中心，河的南边，汉堡王附近。</p></blockquote><p id="1bcb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这个例子的含义表示表达了MR可能具有的所有8个属性。这些属性中的两个是自由文本(<em class="lg">名称</em>和附近的<em class="lg">)，其余的有两到六个可能的值。</em></p><p id="1f63" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">上面的参考文献有非常丰富的词汇和结构，从一句到三句不等。此外，许多人并没有把所有的内容都用语言表达出来。事实上，句子(6)提供的信息甚至在MR中也没有。</p><p id="93f0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在这方面，了解挑战的<a class="ae js" href="https://www.sciencedirect.com/science/article/pii/S0885230819300919" rel="noopener ugc nofollow" target="_blank">组织者</a>所解释的数据是如何获得的是很有趣的:它是众包的，其中80%的案例使用如上所述的带括号的MRs呈现(以随机顺序呈现，以便不影响信息在文本中呈现的顺序)，20%的案例使用图像地图MRs(见下图)。因此，句子(6)中的额外信息看起来可能是从图片/地图表示中获得的。事实上，通过使用一项比较图片和文本MRs的预先研究，作者揭示了“<em class="lg">图片MRs引出的文本在语义文本相似性方面与潜在MR明显不太相似”</em>，以及<em class="lg">“与文本MRs相比，图片MRs引出的文本在语义文本相似性方面与潜在MR明显不太相似”。</em></p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/e347f5a43c49d7c81952c84bbe8bf27c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*_S01kCiuVIj96g_-jHskEg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">文本/逻辑vs图片/地图意义表征(<a class="ae js" href="https://www.sciencedirect.com/science/article/pii/S0885230819300919" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="e680" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">根据作者的说法，这些变化引入了NLG系统必须应对的噪声。然而，是否有一个标准来决定是否要用言语表达一些意思呢？例如，在上面的6篇文章中，有5篇提到了30多的价格，所有文章中都提到了与汉堡王的接近度，只有3篇文章提到了高客户评级。此外，不同文本的出处(作者和图片与文本的MR)没有具体说明，因此很难利用这些信息。</p><h1 id="4056" class="ka kb hi bd kc kd lp kf kg kh lq kj kk kl lr kn ko kp ls kr ks kt lt kv kw kx bi translated">估价</h1><p id="d455" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">为了对系统进行基准测试，e2e NLG竞赛组织者提供了一个基线，这是一个基于注意力的seq2seq模型，该模型使用分类器进行数据增强和波束搜索，并对偏离输入的输出进行惩罚。所以他们的底线本身就很强。</p><p id="ad4b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于输出文本的评估，使用三种类型的措施，即单词重叠度量，文本复杂性和多样性度量，以及人的判断。下面我们将简要描述每一种方法，尽管我们将只提供基于单词的度量作为我们的评估。</p><h2 id="81fc" class="lu kb hi bd kc lv lw lx kg ly lz ma kk jf mb mc ko jj md me ks jn mf mg kw mh bi translated">单词重叠度量</h2><p id="1778" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">为了对照参考文本评估输出文本，提供了一个<a class="ae js" href="https://github.com/tuetschek/e2e-metrics" rel="noopener ugc nofollow" target="_blank">评分脚本</a>,用于计算多个单词重叠指标，即BLEU、Meteor、Rouge-L、CIDEr和Nist。以下是它们的简要说明:</p><ul class=""><li id="8fe4" class="mi mj hi iw b ix iy jb jc jf mk jj ml jn mm jr mn mo mp mq bi translated"><a class="ae js" href="https://en.wikipedia.org/wiki/BLEU" rel="noopener ugc nofollow" target="_blank"> BLEU </a>:计算n-gram精度的调和平均值(其中n最大为4)，如果输出比引用短，则降低一个简洁性代价。针对任何参考文本执行n元语法匹配。</li><li id="ecc0" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated">CIDEr:在tf*idf分数加权的<em class="lg"> n </em> -grams，n∈{1，…，4}级别上计算系统输出和参考句子之间的平均余弦相似度。</li><li id="a2ed" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated"><a class="ae js" href="https://en.wikipedia.org/wiki/METEOR" rel="noopener ugc nofollow" target="_blank"> Meteor </a>:测量给定MR的每个人类生成输出的unigrams的精度和召回率，选择最匹配的一个。除了精确的单词匹配，它还使用基于词干和WordNet同义词的模糊匹配。</li><li id="bc01" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated"><a class="ae js" href="https://en.wikipedia.org/wiki/ROUGE_(metric)" rel="noopener ugc nofollow" target="_blank"> Rouge-L </a>:根据最长公共子序列相对于任何人类参考的精确度和召回率来测量f值。</li><li id="f9b7" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated"><a class="ae js" href="https://en.wikipedia.org/wiki/NIST_(metric)" rel="noopener ugc nofollow" target="_blank"> Nist </a>:是BLEU的一个版本，它赋予更稀有的n元文法更多的权重，而对简洁的惩罚更少。</li></ul><p id="9178" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，一些度量标准，如BLEU、Meteor或Rouge-L因子，在给定意义表示的多个参考文本中。</p><h2 id="e8d9" class="lu kb hi bd kc lv lw lx kg ly lz ma kk jf mb mc ko jj md me ks jn mf mg kw mh bi translated">文本复杂性和多样性度量</h2><p id="4613" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">对参考文本的词汇和句法复杂性的测量表明，这些文本表现出高度的词汇和句法复杂性和多样性。使用<a class="ae js" href="https://aihaiyang.com/software/lca/" rel="noopener ugc nofollow" target="_blank">词汇复杂性分析器</a>计算词汇测量，例如类型与标记比率和熵。使用<a class="ae js" href="http://www.personal.psu.edu/xxl13/downloads/d-level.html" rel="noopener ugc nofollow" target="_blank"> D级分析器</a>测量句法复杂程度，该分析器在句法复杂程度的8分制上给句子赋值。结果显示，虽然46%的句子是简单的，但15%的句子具有最高的两种复杂程度。另一方面，研究表明seq2seq系统通常具有较低的句法复杂性和较差的词汇多样性。</p><h2 id="94b6" class="lu kb hi bd kc lv lw lx kg ly lz ma kk jf mb mc ko jj md me ks jn mf mg kw mh bi translated">人类的判断</h2><p id="5d09" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">定量评估有其局限性，通常建议用于系统之间的比较。然而，要评估文本生成系统的输出质量，人类的判断是必不可少的，尽管代价很高，但也并非没有困难。要获得启发，请阅读Ehud Reiter的博客文章<a class="ae js" href="https://ehudreiter.com/2017/05/03/metrics-nlg-evaluation/" rel="noopener ugc nofollow" target="_blank">“如何做NLG评估:指标”</a>。</p><p id="f807" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于这个比赛，两个单独的文本质量判断任务在众包源上执行。一方面，他们被要求判断与他们的输入MRs一起呈现的文本的<strong class="iw hj"><em class="lg"/></strong>，回答以下问题:“<em class="lg">你如何根据其语法正确性、流畅性、充分性和其他重要因素来判断话语的整体质量？</em>”。另一方面，大众信源被要求判断输出文本的<strong class="iw hj"><em class="lg"/></strong>质量，没有他们的MRs，回答问题:“<em class="lg">话语可能是由一个说本族语的人发出的吗？</em></p><h1 id="a970" class="ka kb hi bd kc kd lp kf kg kh lq kj kk kl lr kn ko kp ls kr ks kt lt kv kw kx bi translated">一盒工具和窍门</h1><p id="63da" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">通过查看本次竞赛产生的大量文献，我发现seq2seq系统建议通过以下方式对基线进行改进:(1)调整输入数据集，(2)调整架构，或(3)调整输出，以及这三种方式的任意组合。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mw"><img src="../Images/420946c0423187ae93fcc9c446a42c92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IG74Rx7itKRwqng6k5PJXA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">选择正确的工具</figcaption></figure><h2 id="6766" class="lu kb hi bd kc lv lw lx kg ly lz ma kk jf mb mc ko jj md me ks jn mf mg kw mh bi translated">调整输入</h2><p id="a6b4" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">大多数系统执行的第一件事，seq2seq或其他，是将<strong class="iw hj"><em class="lg"/></strong>输入去具体化，即用一些虚拟值替换自由文本输入(即当前和附近的场馆名称)。</p><p id="0c47" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">许多系统执行的另一种常见方法是进行<strong class="iw hj"> <em class="lg">数据扩充</em> </strong>，它采用多种形式，例如:</p><ul class=""><li id="5553" class="mi mj hi iw b ix iy jb jc jf mk jj ml jn mm jr mn mo mp mq bi translated"><a class="ae js" href="http://www.macs.hw.ac.uk/InteractionLab/E2E/final_papers/E2E-TNT_NLG2.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hj"> <em class="lg">排列</em> </strong> </a>输入中属性值的含义表示、</li><li id="6d8f" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated"><a class="ae js" href="http://www.macs.hw.ac.uk/InteractionLab/E2E/final_papers/E2E-TNT_NLG2.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hj"> <em class="lg">过采样</em> </strong> </a>通过简单地复制输入，或者通过使用槽对齐器添加与属性值匹配的单句，</li><li id="b07a" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated"><strong class="iw hj"> <em class="lg">选择性子采样</em> </strong>，通过使用具有最高平均词频的<a class="ae js" href="http://www.macs.hw.ac.uk/InteractionLab/E2E/final_papers/E2E-Sheffield.pdf" rel="noopener ugc nofollow" target="_blank">引用</a>以增加多样性，或者通过使用具有复杂单句的<a class="ae js" href="https://arxiv.org/abs/1805.06553" rel="noopener ugc nofollow" target="_blank">引用</a>以获得更复杂的输出。</li><li id="f595" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated"><a class="ae js" href="https://www.aclweb.org/anthology/W18-5019.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hj"> <em class="lg">合成文本生成</em> </strong> </a>，通过使用统计生成器来生成根据人格的心理语言学模型而风格各异的大型文本语料库。</li></ul><h2 id="aae3" class="lu kb hi bd kc lv lw lx kg ly lz ma kk jf mb mc ko jj md me ks jn mf mg kw mh bi translated"><strong class="ak">调整架构</strong></h2><p id="f0cf" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">已经提出了许多方法，例如:</p><ul class=""><li id="54b0" class="mi mj hi iw b ix iy jb jc jf mk jj ml jn mm jr mn mo mp mq bi translated"><strong class="iw hj"> <em class="lg">集合</em> </strong>在不同的神经架构上训练的不同模型<a class="ae js" href="https://www.aclweb.org/anthology/N18-1014/" rel="noopener ugc nofollow" target="_blank">(使用LSTMs vs CNNs)或在</a><a class="ae js" href="https://arxiv.org/pdf/1810.04700.pdf" rel="noopener ugc nofollow" target="_blank">表现出相似风格和结构属性的不同句子簇上用相同架构训练的不同模型</a>。</li><li id="1b45" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated"><a class="ae js" href="https://arxiv.org/abs/1910.03484" rel="noopener ugc nofollow" target="_blank"><strong class="iw hj"><em class="lg"/></strong></a>从文本中联合学习NLG夫人和NLU先生，以缓解成对数据集的缺乏。</li><li id="2367" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated">使用属性值的<a class="ae js" href="https://www.aclweb.org/anthology/W18-6557.pdf" rel="noopener ugc nofollow" target="_blank">固定集合</a>作为编码器的输入。</li><li id="bf24" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated">使用<a class="ae js" href="http://www.macs.hw.ac.uk/InteractionLab/E2E/final_papers/E2E-HarvardNLP.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hj"> <em class="lg">复制机制</em></strong></a><strong class="iw hj"><em class="lg"/></strong>，允许在标准生成机制和直接将输入事实复制到输出之间交替。</li></ul><h2 id="abf7" class="lu kb hi bd kc lv lw lx kg ly lz ma kk jf mb mc ko jj md me ks jn mf mg kw mh bi translated">调整输出</h2><p id="9b7b" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">这通常是用<strong class="iw hj"> <em class="lg">波束搜索</em> </strong>来生成k最佳输出，然后通过使用<strong class="iw hj"> <em class="lg">分类器</em> </strong>或<strong class="iw hj"> <em class="lg">长度罚分</em> </strong>和<strong class="iw hj"> <em class="lg">覆盖罚分</em> </strong>来应用<strong class="iw hj"> <em class="lg">重新排序</em> </strong>，这些罚分惩罚那些没有描述所有输入的输出。</p><h1 id="c4a0" class="ka kb hi bd kc kd lp kf kg kh lq kj kk kl lr kn ko kp ls kr ks kt lt kv kw kx bi translated">履行</h1><p id="b06a" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">正如介绍中提到的，我重用了在Fastai NLP课程中介绍的seq2seq的Fastai实现。这包括:</p><ul class=""><li id="0f19" class="mi mj hi iw b ix iy jb jc jf mk jj ml jn mm jr mn mo mp mq bi translated">Fastai文本串加载和预处理。这使用了spacy tokenizer，并将最小词频设置为3。</li><li id="ee7a" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated">输入和输出嵌入。在这个实现中，我使用Fasttext预训练模型将含义表示中的每个单词映射到300维嵌入。</li><li id="bd59" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated">一个1层GRU编码器和解码器架构，具有一些默认的下降值。我发现1层架构比2层架构性能更好，大概是因为它涉及的参数更少。隐藏层中神经元的数量设置为128，批量设置为32。与e2e NLG竞赛的大多数seq2seq解决方案相反，我没有发现与普通版本相比，注意力给最终结果增加了价值。</li><li id="30ef" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated">教师强制，其在步骤t向解码器提供步骤t-1的真实观察值，而不是训练时的预测值，以避免误差传播。这种方法通过计划抽样得到缓解，计划抽样实际上提供真实观察和预测的随机混合，真实观察随着训练的进行而减少。</li></ul><p id="aaba" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我还对参考文本和含义表示进行了去词汇化，并在将输入的含义表示提供给编码器之前对其进行了一些基本的清理，比如在破折号周围和标点符号之前添加空格。</p><p id="e96b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在对MRs和文本进行预处理、清理和上传之后，我最终得到了56个惟一的输入令牌和1216个惟一的输出令牌。</p><p id="2d05" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我尝试了4种不同的设置:</p><ol class=""><li id="25f4" class="mi mj hi iw b ix iy jb jc jf mk jj ml jn mm jr mx mo mp mq bi translated">带贪婪搜索的普通seq2seq</li><li id="7c28" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mx mo mp mq bi translated">基于模板的方法使用与此处<a class="ae js" href="https://www.aclweb.org/anthology/W18-6557/" rel="noopener ugc nofollow" target="_blank">提供的</a>相同的基本模板</li><li id="b42e" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mx mo mp mq bi translated">带贪婪搜索和数据扩充的普通seq2seq</li><li id="fb75" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mx mo mp mq bi translated">带波束搜索和重新分级的普通seq2seq</li></ol><p id="9883" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了增加数据，我对每一对输入使用了3种随机排列，如<a class="ae js" href="http://www.macs.hw.ac.uk/InteractionLab/E2E/final_papers/E2E-TNT_NLG2.pdf" rel="noopener ugc nofollow" target="_blank">这里的</a>(不要忘记将Fastai tokenize预处理器的最小词频从3提高到9，以保持相同的标记)。</p><p id="a53c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于波束搜索，我使用了具有变量k的神经采样，而不是固定的k，变量k的条件是概率p=0.3，因为我发现这比top-k(当p保持较低时)给出了更多的语法输出。为了更好地测量，我还改变了softmax温度(T=1)。已知这两种方法(神经采样和温度)都可以获得更多样的输出。</p><p id="3b6a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了执行重新排序，我使用了一个<a class="ae js" href="https://www.kaggle.com/nadjetba/text-to-meaning-with-multi-label-classification" rel="noopener ugc nofollow" target="_blank">多标签分类器，它是我使用Fastai ULMFit方法在成对的text-MRs </a>上开发的。该分类器在针对<strong class="iw hj"> <em class="lg">个体</em> </strong> MR属性值分配的测试集上实现了90%的F1分数。根据分类器，仅当贪婪输出没有实现所有MR属性值时，才应用神经采样和重新分级，并且仅当神经采样输出的F1值高于贪婪输出的F1值时，才考虑神经采样输出。</p><h1 id="16be" class="ka kb hi bd kc kd lp kf kg kh lq kj kk kl lr kn ko kp ls kr ks kt lt kv kw kx bi translated">结果</h1><p id="86ce" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">下面的两个表显示了seq2seq模型在竞争基准、基于模板的方法以及贪婪搜索(有和没有扩展)下对开发和测试集的评估。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es my"><img src="../Images/ae9f6b6dec1b9f64913dfad1e73eb06b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*rkrFGWEM8O79ee5kaNTQ-Q.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">对开发集的评估</figcaption></figure><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/7201ea23180aeac1d0a7ff35bd6da87f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*HX5MrQY6juWzgPZM3e3GAw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">对测试集的评估</figcaption></figure><p id="109c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">结果表明，对于开发集，基本的Fastai seq2seq实现在所有度量上都优于基于模板的实现和基线实现。相反，数据扩充并没有改善开发集的结果。</p><p id="0014" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在测试集上，基本的Fastai seq2seq实现优于Meteor和Rouge上的基线。具有数据扩充的贪婪搜索比没有数据扩充的贪婪搜索给出了更好的Bleu、Nist和Rouge分数，并且在Bleu和Rouge上优于基线。</p><p id="1feb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">以下是使用seq2seq和贪婪搜索获得的一些示例输出(在“重组”之前):</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/4bb4631452b4c1a39fa304841d44c837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YfbssrXqlE_Pd9NqTrDOqA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">seq2seq的示例输出，使用开发集中的贪婪搜索</figcaption></figure><p id="29ce" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">该示例显示并非所有属性值都在输出列中实现:行688缺少价格，行1211缺少面积。还有一些属性值没有正确实现:当输入中的客户评级为“1/5”时，行497提到了“高客户评级”。</p><p id="e857" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">不幸的是，使用我们的分类器执行重新排序的波束搜索并没有改善结果。事实上，这让他们更糟。对开发集的所有贪婪输出应用分类器揭示了超过93%的输出实现了100%的精度，67%实现了100%的召回。考虑到许多目标文本并不描述所有的输出，这可能解释了为什么提高回忆对表现没有太大的影响。此外，把所有内容都用语言表达会使文本变得更长，这也可能会影响性能。</p><h1 id="c816" class="ka kb hi bd kc kd lp kf kg kh lq kj kk kl lr kn ko kp ls kr ks kt lt kv kw kx bi translated"><strong class="ak">遗言</strong></h1><p id="36ad" class="pw-post-body-paragraph iu iv hi iw b ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn lc jp jq jr hb bi translated">总而言之，我发现令人印象非常深刻的是，我可以生成听起来相当不错的短文，这些短文使用顺序模型来描述大部分输入，而没有任何常见的NLG工具(排序、句子规划、词汇化、语言实现等)。</p><p id="16da" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然而，与我们领域的目标文本相反，得到的文本在语言学上变化不大(根据<a class="ae js" href="https://aihaiyang.com/software/lca/single/" rel="noopener ugc nofollow" target="_blank"> LCA </a>的开发集的贪婪输出中不同单词的数量是53，这接近于输入标记的数量)。我可以以更高的神经采样概率或更高的softmax温度获得更多种类，但这降低了输出的语法性和正确性，即，导致了所谓的<a class="ae js" href="https://www.aclweb.org/anthology/P19-1256/" rel="noopener ugc nofollow" target="_blank">神经幻觉</a>。</p><p id="3b16" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，回到文章的标题，我们得到了“好的”目标文本，“坏的”官样文章(喜欢这个词)输出和“无聊的”seq2seq输出。这种扁平风格的输出对于基于对话的系统来说尤其成问题，<a class="ae js" href="https://arxiv.org/pdf/1907.09527.pdf" rel="noopener ugc nofollow" target="_blank">的一些作品</a>试图通过将风格和文体特征融入训练中来补救这一点。</p><p id="ef85" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后，诚实一点。我花了很多时间尝试不同的选项，试图获得更好的结果，例如:</p><ul class=""><li id="0a7d" class="mi mj hi iw b ix iy jb jc jf mk jj ml jn mm jr mn mo mp mq bi translated">不同型号(vanilla seq2seq，注意，变形金刚)，</li><li id="c55d" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated">在不同的p值下用神经采样重新排序，并用不同的softmax温度进行实验，</li><li id="9078" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated">教师用不同的真实观察值与预测值的比率强迫学生，</li><li id="b6d4" class="mi mj hi iw b ix mr jb ms jf mt jj mu jn mv jr mn mo mp mq bi translated">选择性二次采样(例如，用单句文本进行训练)或仅通过复制数据进行过采样。</li></ul><p id="8867" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我还花了相当多的时间修改超参数，因为验证损失虽然在减少，但其价值比训练损失高得多，这可能是过度拟合的迹象。对于后一个问题，我尝试了不同的漏失值、隐藏层中的单元数、批量大小和权重衰减。</p></div></div>    
</body>
</html>