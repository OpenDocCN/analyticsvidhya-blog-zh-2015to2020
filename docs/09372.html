<html>
<head>
<title>Recent good papers (August 2020)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">近期好论文(2020年8月)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/recent-good-papers-august-2020-ef5ea7645c0d?source=collection_archive---------26-----------------------#2020-09-03">https://medium.com/analytics-vidhya/recent-good-papers-august-2020-ef5ea7645c0d?source=collection_archive---------26-----------------------#2020-09-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ec9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是我在2020年8月看的10篇论文，我觉得特别有意思。</p><p id="f4a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我已经尽量介绍最近的了，但是论文提交日期可能不是2020年8月。</p><h1 id="4bc3" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">1.黑森惩罚:无监督解开的弱先验</h1><p id="6046" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><a class="ae kg" href="https://arxiv.org/abs/2008.10599" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2008.10599</a></p><p id="a7f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在GAN的潜在空间中获得非纠缠表象的研究。使用Hessian提出了一个正则化项，使得一个方向I的变化不会导致另一个方向j(≠i)的变化。对于经过训练的模型，微调也是可能的。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kh"><img src="../Images/892c029b53bc52463a469313a43daac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEA5MXrekZTknR5iNiDbqg.png"/></div></div></figure><h1 id="2e3a" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">2.SRFlow:用归一化流学习超分辨率空间</h1><p id="cad4" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">https://arxiv.org/abs/2006.14200<a class="ae kg" href="https://arxiv.org/abs/2006.14200" rel="noopener ugc nofollow" target="_blank"/></p><p id="84da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用标准化流的高分辨率图像生成。与需要调整多个损失项的GAN不同，它仅通过优化对数似然来学习。它还使用可逆转换，这允许与潜在表示一一对应，因此它还可以使用高分辨率潜在变量来执行样式转换。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kt"><img src="../Images/ac49d6e14031545f9bf8adb4a0c04c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7G4c8Jjo4EVTUjIWoI6QvA.png"/></div></div></figure><h1 id="7c22" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">3.并非所有未标记数据都是相等的:在半监督学习中学习加权数据</h1><p id="8fcc" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">https://arxiv.org/abs/2007.01293</p><p id="1c82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在半监督学习中，通常对未标记数据的权重进行统一处理，但他们提出了一种自动确定个体数据权重的方法，可以将其纳入FixMatch等现有的损失系统中，并显著提高准确性。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es ku"><img src="../Images/4a16932014f86de862ac9965436e6864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CaLATMlDhxESKIpqVUZS5A.png"/></div></div></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kv"><img src="../Images/41731ec7f703e32db751782e357bec67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*taoMfRTpwcDqiTeeDi3zfQ.png"/></div></figure><h1 id="ca3d" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">4.深度学习的计算极限</h1><p id="cb1b" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">【https://arxiv.org/abs/2007.05558 T4】</p><p id="6a79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该论文提出，深度学习通过使用大量的计算能力提高了许多任务的性能，但该论文提出，随着所需的计算能力越来越大，它可能会因硬件的发展而停滞。这表明，财政和环境负担也变得令人望而却步，因此可能有必要进行重大改进。</p><div class="ki kj kk kl fd ab cb"><figure class="kw km kx ky kz la lb paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/215e3ecec57118b79ee48f3039f2a12d.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*z8YijkKZ_uHa5P5tgDovEw.png"/></div></figure><figure class="kw km lc ky kz la lb paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/c9b3e261757af476bac1541e7cfb93d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*2H8I6LlvxdgWt9JUzNISYQ.png"/></div></figure></div><h1 id="67e5" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">5.对抗训练的深网转移得更好</h1><p id="0055" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><a class="ae kg" href="https://arxiv.org/abs/2007.05869" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2007.05869</a></p><p id="e5e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与正常训练的模型相比，用敌对噪音训练的模型在迁移学习中表现更好。可视化的结果表明，他们正在以更像人类的方式进行分类，这可能影响了结果。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es ld"><img src="../Images/cc37b3839f2660d840d79831dbe3b59e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SlnMn-PENxND0vU1K9LnYw.png"/></div></div></figure><h1 id="a8fe" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">6.Vid2Player:可控制的视频精灵，其行为和表现都像职业网球运动员</h1><p id="9f7a" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><a class="ae kg" href="https://arxiv.org/abs/2008.04524" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2008.04524</a></p><p id="2665" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">逼真合成网球比赛的研究。基于网球的领域知识，他们将球员的动作分为“追上击球”和“占据下一个位置”两部分。他们从中选择最接近的帧进行合成。没有阴影，所以可以确定是合成的，但动作本身相当自然。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es le"><img src="../Images/bd9fc518ab669c16a62a512eeaad3d07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_nVcCi5jvM54d08vpnI-lA.png"/></div></div></figure><h1 id="b1c1" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak"> 7。针对长尾数据的特征空间增强</strong></h1><p id="d146" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">https://arxiv.org/abs/2008.03673<a class="ae kg" href="https://arxiv.org/abs/2008.03673" rel="noopener ugc nofollow" target="_blank"/></p><p id="6926" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在长尾数据集中，每个类别的数据数量存在很大差异，他们提出了一种在线数据扩充方法，以混合特征空间中的稀有类别和频繁类别。与现有方法相比，他们成功地大大提高了该方法的准确性。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lf"><img src="../Images/9a3049c14d3225b9955e4f5583f62237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4mHj2TQse_tZ5-NQlJmluQ.png"/></div></div></figure><h1 id="f5e7" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">8.视觉手性</h1><p id="606b" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">【https://arxiv.org/abs/2006.09512 T4】</p><p id="5c85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据扩充中使用的左右翻转假设翻转不会改变数据分布。但是，实际上数据分布有点不一样(大部分人都是把时钟戴在左手边，但是当数据翻转的时候，看起来是戴在右手边，分布和原来左手边有时钟的数据不一样。) )，DL模型可以确定图像是否被翻转。这有望成为一种新的工具，通过这种方式提取分布发生变化的东西。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lg"><img src="../Images/513eb7baf7eb0ec8f1dda820ce4ad782.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ddy82dw1D3PRWvCfNub6Tg.png"/></div></div></figure><h1 id="f013" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">9.数据不平衡NLP任务的骰子丢失</h1><p id="a1f2" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><a class="ae kg" href="https://arxiv.org/abs/1911.02855" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1911.02855</a></p><p id="7285" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">NLP分类任务通常使用F1分数进行评估，但它们使用交叉熵进行优化，如果使用不平衡数据，它们之间存在很大差距。因此，他们提出了DSC的损失，可以解释为平滑F1并乘以一个因子，将易于分类的样本的系数降至零。他们证实，这种损失在许多模型和数据集上都是有效的。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lh"><img src="../Images/32a971bbd32b69814a0b692506291ce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*xqoS36Mt_mhpVphVrai9Ww.png"/></div></figure><h1 id="3f7a" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak"> 10。利用平衡组Softmax </strong>克服长尾对象检测的分类器不平衡</h1><p id="75d6" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><a class="ae kg" href="https://arxiv.org/abs/2006.10408" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2006.10408</a></p><p id="e834" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在对象检测中，次要类别的性能较差。用于这种数据集的分类任务的方法与对象检测不兼容，并且不能如此提高精确度。因此，他们提出了一种方法，根据数据的数量创建组，并在每个组内创建“其他”类。该方法提高了小类别分类的准确性。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es li"><img src="../Images/4bbe7155d7c8c5bcc819056140f86d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rOS3Z4Y--Gbr67TmMIfDHQ.png"/></div></div></figure></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h2 id="5881" class="lq je hi bd jf lr ls lt jj lu lv lw jn iq lx ly jr iu lz ma jv iy mb mc jz md bi translated">github上有我写的许多论文的概述。</h2><div class="me mf ez fb mg mh"><a href="https://github.com/AkiraTOSEI/ML_papers/issues" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hj fi z dy mm ea eb mn ed ef hh bi translated">AkiraTOSEI/ML_papers</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">关于这个项目有问题吗？注册一个免费的GitHub账户来开一期并联系它的…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">github.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv kr mh"/></div></div></a></div><h2 id="d08a" class="lq je hi bd jf lr ls lt jj lu lv lw jn iq lx ly jr iu lz ma jv iy mb mc jz md bi translated">推特，我贴一句纸评论。</h2><p id="61b4" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><a class="ae kg" href="https://twitter.com/AkiraTOSEI" rel="noopener ugc nofollow" target="_blank">https://twitter.com/AkiraTOSEI</a></p></div></div>    
</body>
</html>