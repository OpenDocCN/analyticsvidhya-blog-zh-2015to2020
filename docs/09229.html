<html>
<head>
<title>Bank Institution Term Deposit Predictive Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">银行机构定期存款预测模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/bank-institution-term-deposit-predictive-model-14af2bbba70e?source=collection_archive---------23-----------------------#2020-08-29">https://medium.com/analytics-vidhya/bank-institution-term-deposit-predictive-model-14af2bbba70e?source=collection_archive---------23-----------------------#2020-08-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="e493" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="0768" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">一家银行的投资和投资组合部门希望识别出有可能认购其定期存款的客户。</p></div><div class="ab cl kb kc gp kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="hb hc hd he hf"><h1 id="3494" class="if ig hi bd ih ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc bi translated">目标</h1><p id="fb09" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这项活动旨在找到一个机器学习模型，该模型可以预测哪些未来客户会订阅他们的定期存款。这将提高世行活动的效率和有效性。</p><p id="20df" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">该银行将确定哪些客户会认购他们的定期存款，并利用这些信息向他们进行营销。这就是所谓的目标营销。</p><p id="a408" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">这将有助于他们更好地管理资源，避免浪费。</p></div><div class="ab cl kb kc gp kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="hb hc hd he hf"><h1 id="87c0" class="if ig hi bd ih ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc bi translated">数据</h1><p id="9fe8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这些数据集是从 UCI ML 网站下载的，人们可以从同一个网站上阅读更多关于这些数据的细节。</p></div><div class="ab cl kb kc gp kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="hb hc hd he hf"><h1 id="70a2" class="if ig hi bd ih ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc bi translated">数据预处理</h1><h2 id="39b3" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">编码分类变量</h2><p id="3d14" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了准确处理数据，分类变量需要编码成数值。这可以使用不同类型的编码器来完成。</p><p id="36c0" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">在本练习中，标签编码器用于将分类变量转换为数字变量。它用 0 和 n_classes-1 之间的值对分类变量进行编码。N_classes 是类别的数量。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="28ab" class="kt ig hi lm b fi lq lr l ls lt"><em class="lu"># Replacing categorical values with numerical values</em><br/>label_encoder = LabelEncoder()<br/>all_columns = list(data_bank_additional_full.columns)<br/><strong class="lm hj">for</strong> x <strong class="lm hj">in</strong> all_columns:<br/>  <strong class="lm hj">if</strong> type(data_bank_additional_full[x][0]) == str:<br/>    <strong class="lm hj">try</strong>:<br/>      data_bank_additional_full[x] = label_encoder.fit_transform(data_bank_additional_full[x])<br/>    <strong class="lm hj">except</strong>:<br/>      <strong class="lm hj">continue</strong></span></pre><h2 id="a18d" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">处理异常值</h2><p id="95d3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">众所周知，离群值会扭曲数据。离群值会影响机器学习算法的训练过程，从而导致准确性的损失。这可能导致模型不准确。</p><p id="7379" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">为了得到一个准确的模型，离群值通过用趋势的中心度量来代替它们而被去除。在本活动中，使用的衡量标准是“平均”。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="229c" class="kt ig hi lm b fi lq lr l ls lt">all_columns = list(data_bank_additional_full.iloc[:,:20].columns)<br/><strong class="lm hj">for</strong> x <strong class="lm hj">in</strong> all_columns:<br/>  <strong class="lm hj">try</strong>:<br/>    data_bank_additional_full[x] = np.where(data_bank_additional_full[x] &gt; data_bank_additional_full[x].quantile(0.975), data_bank_additional_full[x].quantile(0.50), data_bank_additional_full[x])<br/>    data_bank_additional_full[x] = np.where(data_bank_additional_full[x] &lt; data_bank_additional_full[x].quantile(0.025), data_bank_additional_full[x].quantile(0.50), data_bank_additional_full[x])<br/>  <strong class="lm hj">except</strong> <strong class="lm hj">TypeError</strong>:<br/>    <strong class="lm hj">continue</strong></span></pre><h2 id="56c8" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">缩放所有数字列</h2><p id="bf33" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">具有不同大小、单位和范围的变量的数据集影响机器学习算法的训练过程。这是因为机器学习中使用的大多数算法在其计算中使用两个数据点之间的欧几里德距离。这给出了不同的结果。</p><p id="b47c" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">标准化使变量具有共同的大小、单位和范围。有许多标准化数据的方法。在本练习中，使用了 StandardScaler()。它通过移除平均值并缩放至单位方差来标准化特征。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="3715" class="kt ig hi lm b fi lq lr l ls lt">scaler = StandardScaler()<br/>scaled_df = scaler.fit_transform(data_bank_additional_full.iloc[:,:20])<br/>data_bank_additional_fullish = pd.DataFrame(scaled_df,columns = all_columns)<br/>data_bank_additional_fullish['y'] = data_bank_additional_full['y']<br/>data_bank_additional_full = data_bank_additional_fullish</span></pre><h2 id="84a7" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">降维技术</h2><p id="3f7e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这些技术可以评估每一列的信息量，并删除那些信息量不足的列。在这项活动中，t 分布随机邻居嵌入，自动编码器和主成分分析分别探讨比较，以找到最好的降维技术使用。</p><p id="38ea" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><strong class="jf hj"> TSNE </strong></p><p id="595d" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">基于数据点之间的非线性局部关系，t 分布随机近邻嵌入(TSNE)降低了降维。它试图最小化联合概率之间的 Kullback-Leibler 散度</p><p id="7230" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><strong class="jf hj">自动编码器</strong></p><p id="49e9" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">Autoencoder 是一种无监督的人工神经网络，使用反向传播算法进行训练，将输入向量复制到输出层。它的过程开始将原始数据压缩成短码，使用编码器忽略噪声。随后是一种算法，该算法使用解码器对短码进行解压缩，以生成尽可能接近原始输入的数据。</p><p id="6ade" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><strong class="jf hj"> PCA </strong></p><p id="bceb" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">主成分分析(PCA)是一种统计过程，它将原始数据的数字列垂直转换为一组新的主成分。这是一种线性降维技术。</p><p id="0aa4" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">人们可以利用它从高维空间中提取信息。它保留数据差异较大的基本列，删除差异较小的非基本列。</p><h2 id="109e" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">选择降维技术</h2><p id="83c4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">选择的降维技术是自动编码器。Autoencoder 输出可以更好地将信息压缩到低维潜在空间，利用其模拟复杂非线性函数的能力。从自动编码器得到的数据集比其他技术给出了更高的精度。</p><p id="45b6" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">使用 t 分布随机邻域嵌入，原本有 21 个要素的数据集的维数会减少。这可以从所使用的机器学习模型的准确性降低中看出来。它是三种技术中精确度最低的。</p><p id="ee57" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">使用主成分分析时，在应用主成分分析的结果数据集时，模型的准确性低于使用自动编码器时的准确性。</p></div><div class="ab cl kb kc gp kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="hb hc hd he hf"><h1 id="8b56" class="if ig hi bd ih ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc bi translated">数据模型</h1><p id="1ac7" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">要选择模型，交叉验证选择最好的机器学习模型。使用的交叉验证技术是分层 K-fold 和 K-fold。</p><p id="be55" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><strong class="jf hj">分层 K 折叠</strong>是选择的交叉验证技术。使用分层 K- Fold，因为它生成包含相同类别分布或尽可能接近的测试集。它保留了数据集排序中的顺序依赖关系。分层 K 倍有一个小范围的交叉验证准确性得分。</p><p id="e991" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">使用的评估指标有:</p><ul class=""><li id="9b94" class="lv lw hi jf b jg kn jk ko jo lx js ly jw lz ka ma mb mc md bi translated"><strong class="jf hj"> AUC 得分</strong> 1 代表完美的分类器，0.5 代表无价值的分类器。</li><li id="c57d" class="lv lw hi jf b jg me jk mf jo mg js mh jw mi ka ma mb mc md bi translated"><strong class="jf hj"> F1 得分</strong>是为预测测试的数据量。</li><li id="9a72" class="lv lw hi jf b jg me jk mf jo mg js mh jw mi ka ma mb mc md bi translated"><strong class="jf hj">精度</strong>是子集精度。为样本预测的标签集必须与 y_true 中对应的标签集完全匹配。</li><li id="93a1" class="lv lw hi jf b jg me jk mf jo mg js mh jw mi ka ma mb mc md bi translated"><strong class="jf hj">精度得分</strong>表示模型预测的精度水平。</li><li id="9ed9" class="lv lw hi jf b jg me jk mf jo mg js mh jw mi ka ma mb mc md bi translated"><strong class="jf hj">召回</strong>是模型可以预测结果的数量。</li></ul><p id="cb6d" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">对于上述内容，类助手将包含代码:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="75b5" class="kt ig hi lm b fi lq lr l ls lt"><strong class="lm hj">class</strong> <strong class="lm hj">helper</strong>:<br/>  <strong class="lm hj">def</strong> __init__(self):<br/>    print ("Helper object created")<br/>  <strong class="lm hj">def</strong> confusion(self, y_pred):<br/>    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)<br/>    class_names=[0,1] <em class="lu"># name  of classes</em><br/>    fig, ax = plt.subplots()<br/>    tick_marks = np.arange(len(class_names))<br/>    plt.xticks(tick_marks, class_names)<br/>    plt.yticks(tick_marks, class_names)<br/><br/>    <em class="lu"># create heatmap</em><br/>    sns.heatmap(pd.DataFrame(cnf_matrix), annot=<strong class="lm hj">True</strong>, cmap=colour_palette ,fmt='g')<br/>    ax.xaxis.set_label_position("top")<br/>    plt.tight_layout()<br/>    plt.title('Confusion matrix', y=1.1)<br/>    plt.ylabel('Actual label')<br/>    plt.xlabel('Predicted label')<br/><br/>  <strong class="lm hj">def</strong> roc_plot(self,model):<br/>    y_pred_proba = model.predict_proba(X_test)[::,1]<br/>    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)<br/>    auc = metrics.roc_auc_score(y_test, y_pred_proba)<br/>    plt.plot(fpr,tpr,label="data 1, auc="+str(auc))<br/>    print("auc="+str(auc))<br/>    plt.legend(loc=4)<br/>    plt.show()<br/><br/>  <strong class="lm hj">def</strong> s_kfold(self,model):<br/>    skfold = StratifiedKFold(n_splits=5, shuffle=<strong class="lm hj">True</strong>, random_state=1)<br/><br/>    scores = cross_val_score(model, X_train, y_train, cv=skfold,scoring='accuracy')<br/>    print('<strong class="lm hj">\n</strong>Cross-Validation Accuracy Scores', scores)<br/><br/>    scores = pd.Series(scores)<br/>    print('<strong class="lm hj">\n</strong>The minimum Cross-Validation Accuracy is  <strong class="lm hj">%.4f</strong> ' % scores.min())<br/>    print('<strong class="lm hj">\n</strong>The mean Cross-Validation Accuracy is  <strong class="lm hj">%.4f</strong> ' % scores.mean())<br/>    print('<strong class="lm hj">\n</strong>The maximum Cross-Validation Accuracy is  <strong class="lm hj">%.4f</strong> ' % scores.max())<br/><br/>  <strong class="lm hj">def</strong> kfold(self,model):<br/>    kfold = KFold(n_splits=5, shuffle=<strong class="lm hj">True</strong>, random_state=1)<br/><br/>    scores = cross_val_score(model, X_train, y_train, cv=kfold,scoring='accuracy')<br/>    print('<strong class="lm hj">\n</strong>Cross-Validation Accuracy Scores', scores)<br/><br/>    scores = pd.Series(scores)<br/>    print('<strong class="lm hj">\n</strong>The minimum Cross-Validation Accuracy is  <strong class="lm hj">%.4f</strong> ' % scores.min())<br/>    print('<strong class="lm hj">\n</strong>The mean Cross-Validation Accuracy is  <strong class="lm hj">%.4f</strong> ' % scores.mean())<br/>    print('<strong class="lm hj">\n</strong>The maximum Cross-Validation Accuracy is  <strong class="lm hj">%.4f</strong> ' % scores.max())<br/><br/>  <strong class="lm hj">def</strong> calc_metrics(self,y_pred):<br/>    print("<strong class="lm hj">\n</strong>F1 Score: <strong class="lm hj">%.4f</strong> " % metrics.f1_score(y_test, y_pred))<br/>    print("<strong class="lm hj">\n</strong>Accuracy: <strong class="lm hj">%.4f</strong> " % metrics.accuracy_score(y_test, y_pred))<br/>    print("<strong class="lm hj">\n</strong>Precision: <strong class="lm hj">%.4f</strong> " % metrics.precision_score(y_test, y_pred))<br/>    print("<strong class="lm hj">\n</strong>Recall: <strong class="lm hj">%.4f</strong> " % metrics.recall_score(y_test, y_pred))</span></pre><h2 id="6ff0" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">逻辑回归模型</h2><p id="c8f5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">逻辑回归是一种预测二元类的统计方法。结果或目标变量只是两个可能的类。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="fa48" class="kt ig hi lm b fi lq lr l ls lt"><em class="lu"># instantiate the model (using the default parameters)</em><br/>logistic_regressor = LogisticRegression()<br/><br/><em class="lu"># fit the model with data</em><br/>logistic_regressor = logistic_regressor.fit(X_train,y_train)<br/><br/><em class="lu"># predict</em><br/>y_pred = logistic_regressor.predict(X_test)</span></pre><p id="1f5b" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最小交叉验证准确度为 0.8916。</p><p id="5fef" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">平均交叉验证准确度为 0.8941。</p><p id="d1cb" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最大交叉验证准确度为 0.8955。</p><p id="d163" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">该病例的 AUC 得分为 0.7894。F1 的分数是 0.2632。精度为 0.8844。精度为 0.6028。召回率为 0.1683</p><h2 id="7b39" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">XGBoost</h2><p id="4a17" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Boosting 是一种顺序技术，它结合了一组弱学习器并提高了预测精度。正确预测的结果权重较低，错误分类的结果权重较高。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="00d2" class="kt ig hi lm b fi lq lr l ls lt"><em class="lu"># instantiate the model (using the default parameters)</em><br/>xgboost_classifier = XGBClassifier()<br/><br/><em class="lu"># fit the model with data</em><br/>xgboost_classifier = xgboost_classifier.fit(X_train,y_train)<br/><br/><em class="lu"># predict</em><br/>y_pred = xgboost_classifier.predict(X_test)</span><span id="6700" class="kt ig hi lm b fi mj lr l ls lt">#XGBoost Tree<br/>xgb.plot_tree(xgboost_classifier,num_trees=0) <br/>plt.rcParams['figure.figsize'] = [50, 10] <br/>plt.show()</span></pre><p id="42e8" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最小交叉验证准确度为 0.8917。</p><p id="78d0" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">平均交叉验证准确度为 0.8942。</p><p id="8512" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最大交叉验证准确度为 0.8953。</p><p id="d58b" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">该病例的 AUC 得分为 0.7927。F1 的分数是 0.2621。精度为 0.8852。精度为 0.6176。召回率为 0.1663。</p><h2 id="598d" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">多层感知器</h2><p id="12b9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">多层感知器收集从用于接收信号的输入层建立的感知器。它有一个输出层，负责关于输入的决策或预测。多层感知器具有任意数量的隐藏层，代表机器学习算法的真实计算能力。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="ef4b" class="kt ig hi lm b fi lq lr l ls lt"><em class="lu"># create mutli-layer perceptron classifier</em><br/>perceptron_classifier = MLPClassifier()<br/><br/><em class="lu"># train</em><br/>perceptron_classifier = perceptron_classifier.fit(X, y)<br/><br/><em class="lu"># make predictions</em><br/>y_pred = perceptron_classifier.predict(X_test)</span></pre><p id="e0cb" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最小交叉验证准确度为 0.8917。</p><p id="2d0e" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">平均交叉验证准确度为 0.8941。</p><p id="0ee1" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最大交叉验证准确度为 0.8949。</p><p id="f0f6" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">该病例的 AUC 得分为 0.7102。F1 的分数是 0.3166。精度为 0.5419。精度为 0.1937。召回率为 0.8653。</p><h2 id="5611" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">支持向量机</h2><p id="6a6c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">支持向量机处理非线性输入空间。它对两组分类问题使用分类算法。</p><p id="9117" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">它被用于各种应用，例如人脸检测、入侵检测、电子邮件、新闻文章和网页的分类、基因的分类和手写识别。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="593a" class="kt ig hi lm b fi lq lr l ls lt"><em class="lu">#Create a svm Classifier</em><br/>support_vector_classifier = svm.SVC(kernel='linear', probability=<strong class="lm hj">True</strong>)<br/><br/><em class="lu">#Train the model using the training sets</em><br/>support_vector_classifier = support_vector_classifier.fit(X_train, y_train)<br/><br/><em class="lu">#Predict the response for test dataset</em><br/>y_pred = support_vector_classifier.predict(X_test)</span></pre><p id="1e1e" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最小交叉验证准确度为 0.8849。</p><p id="5dd0" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">平均交叉验证准确度为 0.8872。</p><p id="178c" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最大交叉验证准确度为 0.8885</p><p id="217d" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">该病例的 AUC 得分为 0.7462。F1 的分数是 0.0000。精度为 0.8774。精度为 0.0000。召回 0.0000。</p><h2 id="9eaf" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">决策树</h2><p id="0755" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">决策树类似于流程图树结构，具有内部节点、分支和叶节点。内部节点表示特征。分支代表一个决策规则。每个叶节点代表结果。根节点是最高的。</p><p id="3b82" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">决策树学习根据属性值进行划分。它使用递归分区对树进行分区。</p><p id="2bb1" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">决策树有助于决策。决策树的可视化就像一个流程图。这使得理解和解释变得容易，因为它模仿了人类水平的思维。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="399e" class="kt ig hi lm b fi lq lr l ls lt"><em class="lu"># Create Decision Tree classifer object</em><br/>decision_tree_classifer = DecisionTreeClassifier(max_depth=5)<br/><br/><em class="lu"># Train Decision Tree Classifer</em><br/>decision_tree_classifer = decision_tree_classifer.fit(X_train,y_train)<br/><br/><em class="lu">#Predict the response for test dataset</em><br/>y_pred = decision_tree_classifer.predict(X_test)</span><span id="b4c8" class="kt ig hi lm b fi mj lr l ls lt">#Decision Tree<br/>dot_data = StringIO()<br/>export_graphviz(decision_tree_classifer, out_file=dot_data, filled=<strong class="lm hj">True</strong>, rounded=<strong class="lm hj">True</strong>, special_characters=<strong class="lm hj">True</strong>,feature_names = X.columns,class_names=['0','1'])<br/>graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  <br/>graph.write_png('Term Deposits.png')<br/>Image(graph.create_png())<br/></span></pre><p id="53a3" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最小交叉验证准确度为 0.8918。</p><p id="24c9" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">平均交叉验证准确度为 0.8936。</p><p id="e51f" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最大交叉验证准确度为 0.8947。</p><p id="79fd" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">该病例的 AUC 得分为 0.7891。F1 的分数是 0.2609。精度为 0.8844。精度为 0.6043。召回率为 0.1663。</p><h2 id="9554" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">随机森林</h2><p id="b455" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">随机森林由树组成。树木越多，森林就越健壮。这些树是随机选择的数据样本上的决策树。这是从每棵树得到一个预测，并使用投票选择最佳解决方案。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="1531" class="kt ig hi lm b fi lq lr l ls lt"><em class="lu"># create classifier object </em><br/>random_forest_classifier = RandomForestClassifier() <br/>  <br/><em class="lu"># fit the classifier with x and y data </em><br/>random_forest_classifier = random_forest_classifier.fit(X_train,y_train)<br/><br/><em class="lu">#Predict the response for test dataset</em><br/>y_pred = random_forest_classifier.predict(X_test)</span></pre><p id="6691" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最小交叉验证准确度为 0.8913。</p><p id="fc3b" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">平均交叉验证准确度为 0.8935。</p><p id="3ac0" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最大交叉验证准确度为 0.8947。</p><p id="bc0a" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">该病例的 AUC 得分为 0.7883。F1 的分数是 0.2646。精度为 0.8840。精度为 0.5931。召回率为 0.1703。</p></div><div class="ab cl kb kc gp kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="hb hc hd he hf"><h1 id="c439" class="if ig hi bd ih ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc bi translated">结论</h1><p id="25c1" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">选择该模型的依据是该模型的准确性、可解释性、复杂性和可扩展性。</p><p id="9598" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">最好的模型应该是<strong class="jf hj"> XGBoost </strong>。</p><p id="60af" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">平均交叉验证准确度为 0.8942。</p><p id="ea10" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">XGBoost 的 AUC 得分为 0.7927。这比所有其他 AUC 分数更接近于 1。F1 的分数是 0.2621。精度为 0.8852。精度为 0.6176。召回率为 0.1663。</p><p id="d541" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">下一个最好的模型是<strong class="jf hj">逻辑回归</strong>和<strong class="jf hj">多层感知器</strong>的结合。</p><p id="fa4b" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><strong class="jf hj">逻辑回归</strong></p><p id="0ea9" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">平均交叉验证准确度为 0.8941</p><p id="9bfc" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">逻辑回归的 AUC 得分为 0.7894。F1 的分数是 0.2632。精度为 0.8844。精度为 0.6028。召回率为 0.1683。</p><p id="4f9c" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><strong class="jf hj">多层感知器</strong></p><p id="b596" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">平均交叉验证准确度为 0.8941。</p><p id="8b01" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">多层感知器的 AUC 分数是 0.7102。F1 的分数是 0.3166。精度为 0.5419。精度为 0.1937。召回率为 0.8653。</p><figure class="lh li lj lk fd ml er es paragraph-image"><div class="er es mk"><img src="../Images/a6203459aa2bb6ed0e777a2c819aacd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*y6oCHN2gA3AecYGVIUzYhw.png"/></div><figcaption class="mo mp et er es mq mr bd b be z dx translated">交叉验证准确性</figcaption></figure><p id="9f74" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">链接到带有项目的 git 存储库—<a class="ae ks" href="https://github.com/mwi-kali/Bank-Institution-Term-Deposit-Predictive-Model" rel="noopener ugc nofollow" target="_blank">https://github . com/mwi-kali/Bank-Institution-Term-Deposit-Predictive-Model</a></p></div><div class="ab cl kb kc gp kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="hb hc hd he hf"><p id="5f1b" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">我把这些放在一起作为第三批<a class="ae ks" href="http://10academy.org/" rel="noopener ugc nofollow" target="_blank">10academy.org</a>培训的一部分。</p></div><div class="ab cl kb kc gp kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="hb hc hd he hf"><h1 id="ab2b" class="if ig hi bd ih ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc bi translated">参考</h1><p id="b15d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae ks" href="https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python" rel="noopener ugc nofollow" target="_blank">纳夫拉尼，a，2018。Python 中的决策树分类。[在线] DataCamp 社区。</a></p><p id="7e82" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><a class="ae ks" href="https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python?utm_source=adwords_ppc&amp;utm_campaignid=1455363063&amp;utm_adgroupid=65083631748&amp;utm_device=c&amp;utm_keyword=&amp;utm_matchtype=b&amp;utm_network=g&amp;utm_adpostion=&amp;utm_creative=278443377086&amp;utm_targetid=aud-299261629574:dsa-429603003980&amp;utm_loc_interest_ms=&amp;utm_loc_physical_ms=9076857&amp;gclid=CjwKCAjwyo36BRAXEiwA24CwGa2OoIYBqmBWZL_KcePBXotc_Ky7MN5xnyT0eF-U0DcAQfgaQ9RS1RoCx0IQAvD_BwE" rel="noopener ugc nofollow" target="_blank">纳夫拉尼，a，2019。支持向量机与 Scikit-Learn。[在线] DataCamp 社区。</a></p><p id="47f0" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">纳夫拉尼，2020 年。理解 Python 中的逻辑回归。[在线] DataCamp 社区。</p><p id="b01f" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><a class="ae ks" href="https://www.datacamp.com/community/tutorials/xgboost-in-python?utm_source=adwords_ppc&amp;utm_campaignid=1455363063&amp;utm_adgroupid=65083631748&amp;utm_device=c&amp;utm_keyword=&amp;utm_matchtype=b&amp;utm_network=g&amp;utm_adpostion=&amp;utm_creative=332602034364&amp;utm_targetid=aud-299261629574:dsa-429603003980&amp;utm_loc_interest_ms=&amp;utm_loc_physical_ms=9076857&amp;gclid=CjwKCAjwyo36BRAXEiwA24CwGU0BzB6TeKG_Ns2Kv7MskUTbIAHkS3ZgfZan1mfSXTqwA9os59WGnxoCiuUQAvD_BwE" rel="noopener ugc nofollow" target="_blank">帕塔克，硕士，2020。在 Python 中使用 Xgboost。[在线] DataCamp 社区。</a></p><p id="d91d" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated">【Pythonprogramminglanguage.com】T4。2020.多层感知器——学习 Python。</p><p id="e8d9" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><a class="ae ks" href="https://quantdare.com/outliers-detection-with-autoencoder-neural-network/" rel="noopener ugc nofollow" target="_blank"> Quantdare。2020.用神经网络⋆量化器 Autoencoder 检测异常值。</a></p><p id="23b3" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><a class="ae ks" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" rel="noopener ugc nofollow" target="_blank">Scikit-learn.org。2020.Sklearn。分解。PCA—sci kit—学习 0.23.2 文档。</a></p><p id="d270" class="pw-post-body-paragraph jd je hi jf b jg kn ji jj jk ko jm jn jo kp jq jr js kq ju jv jw kr jy jz ka hb bi translated"><a class="ae ks" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">Scikit-learn.org。2020.Sklearn。预处理。standard scaler—sci kit—学习 0.23.2 文档。</a></p></div></div>    
</body>
</html>