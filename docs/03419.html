<html>
<head>
<title>Generative Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成对抗网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/generative-adversarial-networks-ffed75143e9e?source=collection_archive---------13-----------------------#2020-01-30">https://medium.com/analytics-vidhya/generative-adversarial-networks-ffed75143e9e?source=collection_archive---------13-----------------------#2020-01-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es im"><img src="../Images/e3febeb68730864c2d2f949d1c5b0001.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/0*1MMZkTD4-qa9UxLF.jpg"/></div></figure></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="700b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">生成对抗网络(GAN's)最初是在2014年的一篇论文(<a class="ae js" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"/>)中提出的。</p><p id="0870" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这个想法主要围绕着一个简单的想法:神经网络相互竞争，希望这种竞争能推动它们超越他人。</p><p id="f32d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最初这个想法让科学家很兴奋，但他花了几年时间来克服困难，我将在博客中讨论这些困难。</p><p id="f504" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于这个例子，我将使用时尚明斯克数据集，这是妥协的衣服图像。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h2 id="44be" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jf ke kf kg jj kh ki kj jn kk kl km kn bi translated"><em class="ko">发电机</em></h2><p id="d309" class="pw-post-body-paragraph iu iv hi iw b ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn kt jp jq jr hb bi translated">敌对网络的一半，接收随机分布(通常为高斯分布)并输出一些数据(通常为图像)。我们可以将输入视为要生成的图像的表示。通过这种方法，它提供了变型自动解码器中解码器的功能，并且可以以同样的方式用于生成新图像。只要给它输入噪音，它就会输出图像。</p><p id="1f8b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们导入我们的库并开始构建一个。</p><pre class="in io ip iq fd ku kv kw kx aw ky bi"><span id="f20c" class="jt ju hi kv b fi kz la l lb lc">import keras<br/>import tensorflow as tf<br/>import matplotlib.pyplot as plt</span><span id="9fe5" class="jt ju hi kv b fi ld la l lb lc">from keras import models<br/>from keras import layers</span><span id="b925" class="jt ju hi kv b fi ld la l lb lc">import numpy as np</span><span id="0dd9" class="jt ju hi kv b fi ld la l lb lc">codings_size = 30</span><span id="cecc" class="jt ju hi kv b fi ld la l lb lc">generator =  tf.keras.models.Sequential([<br/>    tf.keras.layers.Dense(100, activation='selu', input_shape = [codings_size]),<br/>    tf.keras.layers.Dense(150, activation = 'selu'),<br/>    tf.keras.layers.Dense(28 * 28, activation = 'sigmoid'),<br/>    tf.keras.layers.Reshape([28, 28])<br/>])</span></pre></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="3c43" class="le ju hi bd jv lf lg lh jz li lj lk kd ll lm ln kg lo lp lq kj lr ls lt km lu bi translated"><strong class="ak">鉴别器</strong></h1><p id="1bc7" class="pw-post-body-paragraph iu iv hi iw b ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn kt jp jq jr hb bi translated">鉴别器从生成器获取假图像，或者从训练集中获取真实图像，并尝试猜测输入是假还是真。这是一个简单的二元分类器。</p><pre class="in io ip iq fd ku kv kw kx aw ky bi"><span id="2a73" class="jt ju hi kv b fi kz la l lb lc">discriminator = tf.keras.models.Sequential([<br/>    tf.keras.layers.Flatten(input_shape=[28,28]),<br/>    tf.keras.layers.Dense(150, activation = 'selu'),<br/>    tf.keras.layers.Dense(100, activation = 'selu'),<br/>    tf.keras.layers.Dense(1, activation = 'sigmoid')<br/>])</span></pre><p id="baa8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">将这些神经网络组合成一个GAN:</p><pre class="in io ip iq fd ku kv kw kx aw ky bi"><span id="41a4" class="jt ju hi kv b fi kz la l lb lc">gan = tf.keras.models.Sequential([generator, discriminator])</span></pre></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="4c54" class="le ju hi bd jv lf lg lh jz li lj lk kd ll lm ln kg lo lp lq kj lr ls lt km lu bi translated">培养</h1><p id="2a5b" class="pw-post-body-paragraph iu iv hi iw b ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn kt jp jq jr hb bi translated">在训练过程中，生成器和鉴别器的目标是相反的:鉴别器试图区分假图像和真图像，而生成器试图生成看起来足够真实的图像来欺骗鉴别器。</p><p id="66cb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因为有两个网络，每个培训阶段分为两个部分:</p><p id="39b4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在第一阶段，训练鉴别器。一批真实图像是来自训练集的样本，并且与来自生成器的相同数量的虚假图像一起被获取。假图像的标签为0，真图像的标签为1。</p><p id="5fe7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在第二阶段，发电机被训练。首先，它用于产生一批假图像，鉴别器用于辨别它们是假的还是真的(再次)。然而，这一次没有真实图像，所有标签都被设置为1(真实)。这会导致发生器产生鉴别器认为真实的图像。</p><p id="fb51" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">生成器实际上从未看到任何真实图像——它只是知道鉴别器认为什么是真实图像。鉴别器越能分辨真假图像，就有越多关于真实图像的信息反馈给生成器——这样就能取得重大进展。</p><p id="61cb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">由于这个训练循环是不寻常的，我们必须写一个函数来训练它。</p><pre class="in io ip iq fd ku kv kw kx aw ky bi"><span id="78d1" class="jt ju hi kv b fi kz la l lb lc">def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):<br/>    generator, discriminator = gan.layers<br/>    for epoch in range(n_epochs):<br/>        print("Epoch {}/{}".format(epoch + 1, n_epochs))              <br/>        for X_batch in dataset:<br/>            # phase 1 - training the discriminator<br/>            noise = tf.random.normal(shape=[batch_size, codings_size])<br/>            generated_images = generator(noise)<br/>            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)<br/>            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)<br/>            discriminator.trainable = True<br/>            discriminator.train_on_batch(X_fake_and_real, y1)<br/>            # phase 2 - training the generator<br/>            noise = tf.random.normal(shape=[batch_size, codings_size])<br/>            y2 = tf.constant([[1.]] * batch_size)<br/>            discriminator.trainable = False<br/>            gan.train_on_batch(noise, y2)<br/>        plot_multiple_images(generated_images, 8)                     <br/>        plt.show()</span></pre><p id="f0f7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这里我们可以看到代码训练的两个阶段，在第二阶段，图像开始生成。当我们观想这些图像时，我们可以看到它们开始粗略地看起来像衣服！</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es lv"><img src="../Images/cb2d27a0329c9376fbe32afad1e07d78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*cR1HoP_blzVDkWeEkTEKPw.png"/></div></figure><p id="5352" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">其他有趣的例子包括作曲:<a class="ae js" href="https://www.youtube.com/watch?v=UWxfnNXlVy8" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=UWxfnNXlVy8</a></p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="2c44" class="le ju hi bd jv lf lg lh jz li lj lk kd ll lm ln kg lo lp lq kj lr ls lt km lu bi translated">问题</h1><p id="7cc0" class="pw-post-body-paragraph iu iv hi iw b ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn kt jp jq jr hb bi translated">在训练期间，当网络试图智胜对方时，可以达到纳什均衡，其中生成器生成完美逼真的图像，而鉴别器的最佳策略是在真实图像和非真实图像上对半猜测。不幸的是，这不是保证。<em class="lw">模式崩溃</em>发生在生成器变得不那么多样化的时候——例如变得非常擅长生成令人信服的裤子图像。它可以用裤子欺骗鉴别器一段时间，所以只产生那些图像，直到鉴别器改进。一旦鉴别器足够好，它就继续产生鞋子的图像，而忘记了裤子。它在所有这些课程中循环，从来没有真正擅长过任何一门课程。</p><p id="0878" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">除此之外，由于网络不断地相互推挤，它们的参数可能会振荡并变得不稳定。这使得训练可以正常开始，但是也可能会莫名其妙地出现偏差。已经发表了许多纠正这种情况的尝试，包括新的成本函数或稳定方法来限制模式崩溃，例如<em class="lw">经验重放</em>和<em class="lw">小批量鉴别。这两种方法都试图降低过度拟合的可能性。</em></p><h1 id="de9e" class="le ju hi bd jv lf lx lh jz li ly lk kd ll lz ln kg lo ma lq kj lr mb lt km lu bi translated"><strong class="ak">发展</strong></h1><p id="2d4a" class="pw-post-body-paragraph iu iv hi iw b ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn kt jp jq jr hb bi translated">该领域是一个移动的领域，最近的一个发展是深度卷积生成对抗网络。这些仅仅是几年前的技术水平，还没有被完全理解。</p><p id="efdb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">增加卷积层被证明会降低已经不稳定的网络的稳定性，但亚历克·拉德福德等人在2015年成功了<em class="lw"> (www.homl.info/dcgan)。</em>他们提出了以下指导方针:</p><p id="0f1d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">—用鉴别器中的步进卷积和生成器中的转置卷积替换任何池层</p><p id="669b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">—在生成器和鉴别器中使用批量归一化，但生成器输出层和鉴别器输入层除外</p><p id="24e3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">—移除完全连接的隐藏层以实现更深层次的体系结构</p><p id="3a3c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">—在生成器中对所有图层使用ReLU激活，除了应使用tanh的输出图层</p><p id="3f73" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">—在所有层的鉴别器中使用泄漏ReLU激活。</p><p id="3465" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">仅仅两个时期的训练，虽然在计算上更加密集，但产生了以下结果</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es mc"><img src="../Images/6650a56dcc350c3c754b4f4e9cdc1bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*J9N56K7YvjQcXdgKObDalQ.png"/></div></figure><p id="6a68" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这无疑是对我们最初模型的改进。一些很酷的例子包括去除照片上的雨水:</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es md"><img src="../Images/ad1acfffc47ebaeb2477cb552ee33918.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*5UJi8J-D9aCZWvvcJak1-Q.png"/></div></figure><p id="c0bc" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从损坏的照片中填充零件:</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es me"><img src="../Images/0724746378954b3a25405722cc7f440d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*vgmHnm-7HZbSWbpp6BaucA.png"/></div></figure><p id="ed6c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">3D对象生成，等等:</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es mf"><img src="../Images/f61655b5540a0581594a73981d42e431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*Svdbt5Pcii0ZKQfYJwTH4w.png"/></div></figure><h1 id="f7d4" class="le ju hi bd jv lf lx lh jz li ly lk kd ll lz ln kg lo ma lq kj lr mb lt km lu bi translated">参考</h1><p id="a8a4" class="pw-post-body-paragraph iu iv hi iw b ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn kt jp jq jr hb bi translated">Aurelien Geron (2019) <em class="lw">使用Scikit-Learn、Keras和TensorFlow进行动手机器学习:构建智能系统的概念、工具和技术</em>，2</p></div></div>    
</body>
</html>