<html>
<head>
<title>Feed file Generation from data stored in HDFS and exposed using Hive</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从存储在HDFS并使用Hive公开的数据生成Feed文件</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/feed-file-generation-from-data-stored-in-hdfs-and-exposed-using-hive-b19f68f2b3a1?source=collection_archive---------17-----------------------#2019-11-04">https://medium.com/analytics-vidhya/feed-file-generation-from-data-stored-in-hdfs-and-exposed-using-hive-b19f68f2b3a1?source=collection_archive---------17-----------------------#2019-11-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="f377" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">问题陈述:</strong></h1><p id="c472" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">作为分析的一部分，我们可能经常需要发送多个文件馈送(无论是在。txt或者。csv格式等)传送到下游系统用于不同的分析目的。<br/>这可能是为了营销团队找出目标客户，或者是为了数据科学团队的机器学习模型等等。</p><p id="9b0d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在本文中，我们将探讨从存储在HDFS中的数据生成提要的一些选项，以便与第三方下游应用程序共享:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/33df390e5c8d9f227fc70a0e90caf5d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lJuPk4_HK8en_AZ1omiMyw.png"/></div></div></figure><blockquote class="ks kt ku"><p id="fbae" class="jd je kv jf b jg kb ji jj jk kc jm jn kw kd jq jr kx ke ju jv ky kf jy jz ka hb bi translated"><strong class="jf hj">先决条件:<br/> </strong>数据已经存储在HDFS，并使用Hive表向最终用户公开。</p><p id="1feb" class="jd je kv jf b jg kb ji jj jk kc jm jn kw kd jq jr kx ke ju jv ky kf jy jz ka hb bi translated"><strong class="jf hj">注意:</strong>我们也可以使用MapReduce/Spark来生成feed文件，但这需要编码技巧，因为它涉及大量的编码，而且代码的维护也不仅仅是hive。</p><p id="7918" class="jd je kv jf b jg kb ji jj jk kc jm jn kw kd jq jr kx ke ju jv ky kf jy jz ka hb bi translated">因为我们已经将数据公开为hive表，所以我们可以直接使用Hive来生成提要文件。</p></blockquote><p id="06c6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在Hive中，有多种方法可以从可用信息生成文本或csv feed文件:</p><ul class=""><li id="c615" class="kz la hi jf b jg kb jk kc jo lb js lc jw ld ka le lf lg lh bi translated"><strong class="jf hj">使用hive -e的“查询”选项</strong></li><li id="b582" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated"><strong class="jf hj">使用hdfs cat选项</strong></li><li id="dad8" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated"><strong class="jf hj">和我个人最喜欢的(我在用例中使用的)——使用插入覆盖本地目录选项</strong></li></ul><p id="d971" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">让我们逐一讨论它们，并举例说明利弊:</p><ol class=""><li id="b707" class="kz la hi jf b jg kb jk kc jo lb js lc jw ld ka ln lf lg lh bi translated"><strong class="jf hj">使用hive -e的“查询”选项</strong></li></ol><p id="8e32" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">HIVE-e " HIVE _ QUERY " &gt;/FEED _ LOCATION/sample _ FEED . txt</p><blockquote class="ks kt ku"><p id="342e" class="jd je kv jf b jg kb ji jj jk kc jm jn kw kd jq jr kx ke ju jv ky kf jy jz ka hb bi translated">配置单元的“-e”选项用于从命令行运行SQL，然后查询结果被重定向到输出文件，如下面的代码片段所示</p></blockquote><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lo"><img src="../Images/2533df504f2e27d6d58daa741da96ca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9vkxa-5sD2J-TlTrkG78pg.png"/></div></div></figure><p id="6cac" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">可以在下面的代码片段中看到提要的内容:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lp"><img src="../Images/a55910d3799c668985405a301a8545fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wFhfgb9OfkNedGQsCu_QdA.png"/></div></div></figure><p id="40d7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">该命令可以从命令行运行，不需要用户登录到hive cli，并且输出文件也将在客户端节点上生成。</p><p id="7cfa" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">优点:</strong></p><ul class=""><li id="ce76" class="kz la hi jf b jg kb jk kc jo lb js lc jw ld ka le lf lg lh bi translated">易于使用和列标题可以包括在文件饲料</li></ul><p id="c082" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">缺点:</strong></p><ul class=""><li id="6bc9" class="kz la hi jf b jg kb jk kc jo lb js lc jw ld ka le lf lg lh bi translated">输出文件用制表符定界符生成，需要将制表符定界符转换成逗号定界符，这在生成大文件时会花费很多时间</li><li id="bc38" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">如果属性需要用引号括起来，则没有规定</li></ul><p id="2ee2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> 2。使用hdfs cat选项</strong></p><p id="293c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">Hadoop fs-cat HDFS://servername/user/hive/warehouse/databasename/table _ CSV _ export _ data/* &gt; ~/output . CSV copy</p><p id="f449" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们可以从客户端节点发出该命令，输出文件将在本地生成，如下面的代码片段所示:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lq"><img src="../Images/a62f9ba954c6fff366c6849e10a6add5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gxgjt3tC6aZGfaeY6oDPHg.png"/></div></div></figure><p id="3930" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">优点:</p><ul class=""><li id="7011" class="kz la hi jf b jg kb jk kc jo lb js lc jw ld ka le lf lg lh bi translated">简单，在CSV输出中用逗号作为分隔符。</li></ul><p id="9eac" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">缺点:</p><ul class=""><li id="d1a0" class="kz la hi jf b jg kb jk kc jo lb js lc jw ld ka le lf lg lh bi translated">无法生成列标题。</li><li id="18b9" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">生成源时无法执行任何转换或过滤</li></ul><p id="3533" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> 3。使用插入覆盖本地目录选项</strong></p><p id="6cba" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">插入覆盖本地目录' FEED_LOCATION' <br/>行格式分隔的<br/>字段以'，'<br/>结尾存储为文本文件<br/>SELECT * FROM TABLE；</p><blockquote class="ks kt ku"><p id="84f9" class="jd je kv jf b jg kb ji jj jk kc jm jn kw kd jq jr kx ke ju jv ky kf jy jz ka hb bi translated">OVERWRITE-该关键字用该命令生成的文件覆盖“FEED_LOCATION”中的所有内容</p><p id="10c7" class="jd je kv jf b jg kb ji jj jk kc jm jn kw kd jq jr kx ke ju jv ky kf jy jz ka hb bi translated">LOCAL-本地关键字的使用是可选的，如果输出文件预期在HDFS目录中生成，则不使用“本地”关键字，否则如果文件预期在本地目录中生成，则使用“本地”关键字</p></blockquote><p id="ff9b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">示例查询可以在下面的代码片段中看到:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lr"><img src="../Images/2f70a4b6159979853a6786bbf4cad07d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OCcyICoXdoya60n2uZanDA.png"/></div></div></figure><p id="4080" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">输出提要文件可以在下面的代码片段中看到</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es ls"><img src="../Images/26b5ff12e4b0d75c19956c74dc1d5413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ym92hTCfQ-MVN3zsRM8Orw.png"/></div></div></figure><p id="ef28" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">优点:</strong></p><ul class=""><li id="9c29" class="kz la hi jf b jg kb jk kc jo lb js lc jw ld ka le lf lg lh bi translated">在生成输出文件时，可以对hdfs中存储的数据应用任何转换或过滤</li><li id="12b2" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">根据我们的用例，我们可以在HDFS目录或本地目录中生成输出文件</li><li id="fece" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">并不是所有的输出文件都需要用逗号分隔符来生成，我们可以在生成输出文件时定义自定义的分隔符</li><li id="0c17" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">不需要额外的开销来将结果重定向到输出文件，我们只需要定义输出位置</li></ul><p id="5152" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">缺点:</strong></p><ul class=""><li id="c072" class="kz la hi jf b jg kb jk kc jo lb js lc jw ld ka le lf lg lh bi translated">将生成名为“000000_0”的文件，可能需要额外的步骤将文件重命名为所需的名称</li></ul><h1 id="1286" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">生成提要之前需要记住的其他提示</h1><ul class=""><li id="c06b" class="kz la hi jf b jg jh jk jl jo lt js lu jw lv ka le lf lg lh bi translated">Hive加载到表中时默认压缩数据，由于我们需要生成未压缩的数据，需要设置下面的hive参数<br/>T5】SET hive . exec . compress . output = false；</li><li id="3014" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">您总是可以通过在hive<br/><strong class="jf hj">SET hive . execution . engine = tez；上使用tez引擎来加速提要的生成。</strong></li><li id="5185" class="kz la hi jf b jg li jk lj jo lk js ll jw lm ka le lf lg lh bi translated">如果提要的属性需要用引号括起来，那么您可以将<strong class="jf hj"> OpenCSVSerde </strong>与下面的命令一起使用:<br/><strong class="jf hj"><em class="kv">INSERT OVERWRITE LOCATION ' FEED _ LOCATION '<br/>ROW FORMAT SERDE ' org . Apache . Hadoop . hive . SERDE 2 . OpenCSVSerde '<br/>WITH SERDEPROPERTIES(<br/>' separator char ' = '，'，<br/>' quotech</em> </strong></li></ul><blockquote class="ks kt ku"><p id="b3a7" class="jd je kv jf b jg kb ji jj jk kc jm jn kw kd jq jr kx ke ju jv ky kf jy jz ka hb bi translated">SerDe是Serializer/Deserializer的缩写。Hive为IO使用SerDe接口。该接口处理序列化和反序列化，并将序列化的结果解释为要处理的单个字段。</p></blockquote></div></div>    
</body>
</html>