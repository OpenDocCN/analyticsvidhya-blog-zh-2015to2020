<html>
<head>
<title>Intro to Scraping Basketball Reference data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">收集篮球参考数据简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/intro-to-scraping-basketball-reference-data-8adcaa79664a?source=collection_archive---------1-----------------------#2020-12-02">https://medium.com/analytics-vidhya/intro-to-scraping-basketball-reference-data-8adcaa79664a?source=collection_archive---------1-----------------------#2020-12-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="fd69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于如何用python从https://www.basketball-reference.com/的<a class="ae je" href="https://www.basketball-reference.com/" rel="noopener ugc nofollow" target="_blank"><em class="jd"/></a><em class="jd">(或任何其他sports-reference.com网站)抓取数据的简短教程</em></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/687a1ce91dca4e3881827dab4f81ce1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UBWb9XbWbwIcpcZU"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">照片由<a class="ae je" href="https://unsplash.com/@echaparro?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">埃德加·恰帕罗</a>在<a class="ae je" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="d870" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Sports-Reference.com正是体育迷和数据科学汇聚的地方。这是一个巨大的、结构化的干净体育数据仓库。因此，它通常是学术数据科学项目的起点。</p><p id="35e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从体育参考网站，如basketball-reference.com，很容易抓住一个表。不需要编程，可以复制粘贴甚至“导出为CSV”。比如你可以从这个页面获取上赛季的NBA积分榜:<a class="ae je" href="https://www.basketball-reference.com/leagues/NBA_2020_standings.html" rel="noopener ugc nofollow" target="_blank">https://www . basketball-reference . com/league s/NBA _ 2020 _ standings . html</a></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jv"><img src="../Images/b4a2c305833e2ebef65062fa41af5641.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cr8_YvOWmJNKQ2z2VnJtpQ.jpeg"/></div></div></figure><p id="075a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，这并不是很多数据。如果您想从多个页面中聚合数据，以得出关于团队在5年、10年或50年中的排名的有意义的结论，该怎么办？(或者以我的情况来说，坦克战是否有助于一支球队进入决赛？)嗯，你可以用python和三个库做到这一点。</p><p id="9ccd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了说明这一点，我将列举两个例子:</p><ol class=""><li id="d29e" class="jw jx hi ih b ii ij im in iq jy iu jz iy ka jc kb kc kd ke bi translated">抓取一页</li><li id="cf99" class="jw jx hi ih b ii kf im kg iq kh iu ki iy kj jc kb kc kd ke bi translated">抓取许多页面并聚合数据</li></ol></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="cd47" class="kr ks hi bd kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">简单的例子:从一个页面抓取数据</h1><h2 id="1974" class="lp ks hi bd kt lq lr ls kx lt lu lv lb iq lw lx lf iu ly lz lj iy ma mb ln mc bi translated">导入库并定义您的URL:</h2><pre class="jg jh ji jj fd md me mf mg aw mh bi"><span id="72aa" class="lp ks hi me b fi mi mj l mk ml"># needed libraries<br/>from urllib.request import urlopen<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</span><span id="5c82" class="lp ks hi me b fi mm mj l mk ml"># URL to scrape<br/>url = "<a class="ae je" href="https://www.basketball-reference.com/playoffs/" rel="noopener ugc nofollow" target="_blank">https://www.basketball-reference.com/playoffs/</a>"</span></pre><h2 id="f59c" class="lp ks hi bd kt lq lr ls kx lt lu lv lb iq lw lx lf iu ly lz lj iy ma mb ln mc bi translated">收集HTML数据并创建漂亮的汤对象:</h2><pre class="jg jh ji jj fd md me mf mg aw mh bi"><span id="5748" class="lp ks hi me b fi mi mj l mk ml"># collect HTML data<br/>html = urlopen(url)<br/>        <br/># create beautiful soup object from HTML<br/>soup = BeautifulSoup(html, features="lxml")</span></pre><h2 id="b8d2" class="lp ks hi bd kt lq lr ls kx lt lu lv lb iq lw lx lf iu ly lz lj iy ma mb ln mc bi translated">将列标题提取到列表中:</h2><pre class="jg jh ji jj fd md me mf mg aw mh bi"><span id="6672" class="lp ks hi me b fi mi mj l mk ml"># use getText()to extract the headers into a list<br/>headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]</span></pre><h2 id="60ad" class="lp ks hi bd kt lq lr ls kx lt lu lv lb iq lw lx lf iu ly lz lj iy ma mb ln mc bi translated">从表中提取行:</h2><pre class="jg jh ji jj fd md me mf mg aw mh bi"><span id="77fd" class="lp ks hi me b fi mi mj l mk ml"># get rows from table<br/>rows = soup.findAll('tr')[2:]<br/>rows_data = [[td.getText() for td in rows[i].findAll('td')]<br/>                    for i in range(len(rows))]</span><span id="e516" class="lp ks hi me b fi mm mj l mk ml"># if you print row_data here you'll see an empty row<br/># so, remove the empty row<br/>rows_data.pop(20)</span><span id="45b5" class="lp ks hi me b fi mm mj l mk ml"># for simplicity subset the data for only 39 seasons<br/>rows_data = rows_data[0:38]</span></pre><h2 id="0ad7" class="lp ks hi bd kt lq lr ls kx lt lu lv lb iq lw lx lf iu ly lz lj iy ma mb ln mc bi translated">增加“年数”一栏:</h2><pre class="jg jh ji jj fd md me mf mg aw mh bi"><span id="f132" class="lp ks hi me b fi mi mj l mk ml"># we're missing a column for years<br/># add the years into rows_data<br/>last_year = 2020<br/>for i in range(0, len(rows_data)):<br/>    rows_data[i].insert(0, last_year)<br/>    last_year -=1</span></pre><h2 id="bafa" class="lp ks hi bd kt lq lr ls kx lt lu lv lb iq lw lx lf iu ly lz lj iy ma mb ln mc bi translated">最后，创建数据帧并导出到CSV:</h2><pre class="jg jh ji jj fd md me mf mg aw mh bi"><span id="799b" class="lp ks hi me b fi mi mj l mk ml"># create the dataframe<br/>nba_finals = pd.DataFrame(rows_data, columns = headers)</span><span id="a919" class="lp ks hi me b fi mm mj l mk ml"># export dataframe to a CSV <br/>nba_finals.to_csv("nba_finals_history.csv", index=False)</span></pre></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="b043" class="kr ks hi bd kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">复杂示例:从多个页面抓取数据</h1><h2 id="7333" class="lp ks hi bd kt lq lr ls kx lt lu lv lb iq lw lx lf iu ly lz lj iy ma mb ln mc bi translated">创建循环函数:</h2><pre class="jg jh ji jj fd md me mf mg aw mh bi"><span id="ba5a" class="lp ks hi me b fi mi mj l mk ml"># import needed libraries<br/>from urllib.request import urlopen<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</span><span id="af81" class="lp ks hi me b fi mm mj l mk ml"># create a function to scrape team performance for multiple years<br/>def scrape_NBA_team_data(years = [2017, 2018]):<br/>    <br/>    final_df = pd.DataFrame(columns = ["Year", "Team", "W", "L",<br/>                                       "W/L%", "GB", "PS/G", "PA/G",<br/>                                       "SRS", "Playoffs",<br/>                                       "Losing_season"])<br/>    <br/>    # loop through each year<br/>    for y in years:</span><span id="4284" class="lp ks hi me b fi mm mj l mk ml">        # NBA season to scrape<br/>        year = y<br/>        <br/>        # URL to scrape, notice f string:<br/>        url = f"<a class="ae je" href="https://www.basketball-reference.com/leagues/NBA_{year}_standings.html" rel="noopener ugc nofollow" target="_blank">https://www.basketball-reference.com/leagues/NBA_{year}_standings.html</a>"<br/>        <br/>        # collect HTML data<br/>        html = urlopen(url)<br/>        <br/>        # create beautiful soup object from HTML<br/>        soup = BeautifulSoup(html, features="lxml")<br/>        <br/>        # use getText()to extract the headers into a list<br/>        titles = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]<br/>        <br/>        # first, find only column headers<br/>        headers = titles[1:titles.index("SRS")+1]<br/>        <br/>        # then, exclude first set of column headers (duplicated)<br/>        titles = titles[titles.index("SRS")+1:]<br/>        <br/>        # next, row titles (ex: Boston Celtics, Toronto Raptors)<br/>        try:<br/>            row_titles = titles[0:titles.index("Eastern Conference")]<br/>        except: row_titles = titles<br/>        # remove the non-teams from this list<br/>        for i in headers:<br/>            row_titles.remove(i)<br/>        row_titles.remove("Western Conference")<br/>        divisions = ["Atlantic Division", "Central Division",<br/>                     "Southeast Division", "Northwest Division",<br/>                     "Pacific Division", "Southwest Division",<br/>                     "Midwest Division"]<br/>        for d in divisions:<br/>            try:<br/>                row_titles.remove(d)<br/>            except:<br/>                print("no division:", d)<br/>        <br/>        # next, grab all data from rows (avoid first row)<br/>        rows = soup.findAll('tr')[1:]<br/>        team_stats = [[td.getText() for td in rows[i].findAll('td')]<br/>                    for i in range(len(rows))]<br/>        # remove empty elements<br/>        team_stats = [e for e in team_stats if e != []]<br/>        # only keep needed rows<br/>        team_stats = team_stats[0:len(row_titles)]<br/>        <br/>        # add team name to each row in team_stats<br/>        for i in range(0, len(team_stats)):<br/>            team_stats[i].insert(0, row_titles[i])<br/>            team_stats[i].insert(0, year)<br/>            <br/>        # add team, year columns to headers<br/>        headers.insert(0, "Team")<br/>        headers.insert(0, "Year")<br/>        <br/>        # create a dataframe with all aquired info<br/>        year_standings = pd.DataFrame(team_stats, columns = headers)<br/>        <br/>        # add a column to dataframe to indicate playoff appearance<br/>        year_standings["Playoffs"] = ["Y" if "*" in ele else "N" for ele in year_standings["Team"]]<br/>        # remove * from team names<br/>        year_standings["Team"] = [ele.replace('*', '') for ele in year_standings["Team"]]<br/>        # add losing season indicator (win % &lt; .5)<br/>        year_standings["Losing_season"] = ["Y" if float(ele) &lt; .5 else "N" for ele in year_standings["W/L%"]]<br/>        <br/>        # append new dataframe to final_df<br/>        final_df = final_df.append(year_standings)<br/>        <br/>    # print final_df<br/>    print(final_df.info)<br/>    # export to csv<br/>    final_df.to_csv("nba_team_data.csv", index=False)</span></pre><h2 id="cce9" class="lp ks hi bd kt lq lr ls kx lt lu lv lb iq lw lx lf iu ly lz lj iy ma mb ln mc bi translated">在过去的30个赛季中测试它！</h2><pre class="jg jh ji jj fd md me mf mg aw mh bi"><span id="b5e6" class="lp ks hi me b fi mi mj l mk ml">scrape_NBA_team_data(years = [1990, 1991, 1992, 1993, 1994,<br/>                              1995, 1996, 1997, 1998, 1999,<br/>                              2000, 2001, 2002, 2003, 2004,<br/>                              2005, 2006, 2007, 2008, 2009,<br/>                              2010, 2011, 2012, 2013, 2014,<br/>                              2015, 2016, 2017, 2018, 2019,<br/>                              2020])</span></pre></div></div>    
</body>
</html>