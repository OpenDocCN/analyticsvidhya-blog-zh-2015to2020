<html>
<head>
<title>Dog Breed Classifier: How to build a face detector, dog detector &amp; breed classifier using CNN and Transfer Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">狗品种分类器:如何利用CNN和迁移学习构建人脸检测器、狗检测器&amp;品种分类器？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/dog-breed-classifier-how-to-build-a-dog-detector-breed-classifier-using-cnn-from-scratch-and-ee97696d2073?source=collection_archive---------10-----------------------#2020-05-06">https://medium.com/analytics-vidhya/dog-breed-classifier-how-to-build-a-dog-detector-breed-classifier-using-cnn-from-scratch-and-ee97696d2073?source=collection_archive---------10-----------------------#2020-05-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4777" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文概述了<em class="jd"> Kaggle的</em> <strong class="ih hj"> <em class="jd">犬种分类器</em> </strong>项目，恰好是著名的视觉项目之一！</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/b27c2d88ece12c08613758a3d6dfd993.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*Lgl_gdw_mJbuJoXyt7WDpQ.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">此处已建内容概述！</figcaption></figure><h2 id="5efe" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">概述:</h2><p id="da73" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">人类在视觉方面非常优秀，我们的大脑在视觉识别方面非常强大。给一只狗，你可以很容易地发现它的品种，唯一的条件是你必须知道这个星球上所有的狗品种！现在这对于一个正常人来说是一个相当具有挑战性的任务。假设你喜欢一个特定的狗品种(比如说拉布拉多)，想收养一只同一品种的狗，你去商店把你可爱的新朋友带回家。你怎么知道这是不是你得到的正确的狗品种？很多时候，人类很难识别狗的品种。例如，如何对下面给出的两只狗的图片进行分类。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kq"><img src="../Images/c6de42c1dc861928c734edf541f401a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*6O5AL_ZlYRnz6Vd4vXZlew.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">注意两张图片的品种名称！</figcaption></figure><p id="3d22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，这两个怎么样？</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kr"><img src="../Images/12075f5d71b49dff16db06947000eb16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*-pIY0qXLbJCsEo57U0Am4w.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">两只狗都有卷毛，很难辨认，对吧？！</figcaption></figure><p id="8eac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，这张图片上的品种是什么？？</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es ks"><img src="../Images/1339f7a69d69ff3c3bc843909fee8eb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*uoqiCCEbNebVsIBXzGwOgQ.png"/></div></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">这算是狗的形象吗？是啊！人变狗:p</figcaption></figure><p id="91ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面给出的图像不是一只狗，而是一张化了妆的人脸(《星球大战》的虚构人物丘巴卡)。这个项目还将带你通过人脸检测和识别与给定人脸最相似的狗品种！听起来很有趣，对吧？！😄</p><p id="93a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，这成了一项艰难的工作。这就是机器学习/深度学习的需求出现的时候。计算机视觉帮助你建立机器学习模型，你训练一个模型来识别狗的品种！这让你的工作变得简单！<a class="ae kx" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank"> <em class="jd"> CNN </em> </a>是深度学习领域的一项巨大发明，这推动了视觉识别领域的大量应用。我将带您了解如何使用Pytorch从头开始构建CNN，并利用一些流行的CNN架构来完成我们的图像分类任务！</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><p id="f1e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该项目分为不同的阶段，如加载和预处理数据，人脸检测，狗检测，品种分类。你可以在我的<a class="ae kx" href="https://github.com/s-nilesh" rel="noopener ugc nofollow" target="_blank"> <em class="jd"> GitHub </em> </a>上找到代码。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="79d6" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">数据集和输入</h2><ul class=""><li id="1432" class="lf lg hi ih b ii kl im km iq lh iu li iy lj jc lk ll lm ln bi translated">输入:该项目的输入类型必须是图像。</li></ul><p id="2600" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">数据集:</em></p><ul class=""><li id="69f2" class="lf lg hi ih b ii ij im in iq lo iu lp iy lq jc lk ll lm ln bi translated"><strong class="ih hj"> <em class="jd">人形图像</em> </strong>:人形图像分布在<strong class="ih hj"> 5749个文件夹</strong>中，以类似“朱丽安_摩尔”、“丹_阿克罗伊德”等人形名称命名。总共有<strong class="ih hj"> 13233张</strong>人脸图像。图像在文件夹中分布不均匀。链接到数据集的超链接是<a class="ae kx" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip" rel="noopener ugc nofollow" target="_blank"> <em class="jd">这里的</em> </a>。</li><li id="c633" class="lf lg hi ih b ii lr im ls iq lt iu lu iy lv jc lk ll lm ln bi translated"><strong class="ih hj"> <em class="jd">狗图像</em> </strong>:狗图像分布在三个主文件夹中，分别命名为“train”、“T16”、“test”和“valid”，用于训练、测试和验证。此外，所有这些文件夹再次被分配到代表狗品种的<strong class="ih hj"> 133个文件夹</strong>中。因此，我们的狗数据集有133类，即品种(“獒”，“比熊犬_弗里斯”，等等)。链接到数据集的超链接是<a class="ae kx" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip" rel="noopener ugc nofollow" target="_blank"> <em class="jd">这里的</em> </a>。</li></ul><p id="7133" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">关于数据的信息:</em></p><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="1746" class="jq jr hi lx b fi mb mc l md me">Total number of <strong class="lx hj">human face images: 13233</strong><br/>Total number of <strong class="lx hj">human face folders: 5749</strong><br/>Total numner of folders in 'dog_images:' 3<br/>Folders in 'dog_images': train,test,valid<br/><strong class="lx hj">Total folders(breed classes) </strong>in 'train, test, valid' <strong class="lx hj">133</strong><br/>Total images in /dog_images/<strong class="lx hj">train : 6680</strong><br/>Total images in /dog_images/<strong class="lx hj">test : 836</strong><br/>Total images in /dog_images/<strong class="lx hj">valid : 835</strong></span></pre><p id="a978" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">训练数据集中狗品种的分布(平均每类50.22个样本):</em>类别名称不可见，但我们可以看到每类的平均样本，由平行于类别轴的黑线表示。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mf"><img src="../Images/bd796cd39ccb399ea6e517ff94150069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*LKopScgCQNSCCEPADkuiig.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">显示训练数据集中<strong class="bd js">图像分布的柱状图，每个柱状图代表一个犬种。</strong></figcaption></figure></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="7321" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">人脸检测</h2><p id="8985" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">我用了<a class="ae kx" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> OpenCV的Haar级联分类器</strong> </a> <strong class="ih hj"> </strong>来检测人脸。这个OpenCV的分类器在许多带有正点(有脸)和负点(没有脸)标签的图像上被训练。detectMultiScale返回同一图像中所有检测到的面的4个边界框坐标值的列表。对于所有人脸检测算法，将RGB图像转换为灰度图像是一种标准做法，因此请确保转换您的图像。</p><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="de21" class="jq jr hi lx b fi mb mc l md me">import cv2<br/>face_cascade = cv2.CascadeClassifier('haarcascade_frontalface.xml')</span><span id="579c" class="jq jr hi lx b fi mg mc l md me">def face_detector(img_path):<br/>    img = cv2.imread(img_path)<br/>    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br/>    faces = face_cascade.detectMultiScale(gray)<br/>    return len(faces) &gt; 0  #returns bool</span></pre><blockquote class="mh mi mj"><p id="15e1" class="if ig jd ih b ii ij ik il im in io ip mk ir is it ml iv iw ix mm iz ja jb jc hb bi translated"><strong class="ih hj">模型性能</strong> : Haar级联分类器在数据上有很好的性能</p></blockquote><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="772a" class="jq jr hi lx b fi mb mc l md me">Percentage of <em class="jd">human faces detected in human images</em> data: <strong class="lx hj">98.74<br/></strong>Percentage of <em class="jd">human faces detected in dog images </em>data(incorrect detections): <strong class="lx hj">10.83</strong></span></pre><p id="ca3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">哈尔级联分类器给出的样本结果:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mn"><img src="../Images/1a0c4f4310bb608820a69d4701aca650.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*605BiOgsvpBOqXSl-N0z-g.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">用左上角的坐标和边界框的高度、宽度来检测一个面</figcaption></figure></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="6e21" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">狗检测</h2><p id="077a" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">我们现在需要设计一个狗探测器。我使用迁移学习来完成这项任务。我尝试使用了<em class="jd"> VGG16和ResNet50 </em>预训练模型，分别在1000类ImageNet数据的<em class="jd"> 10M图像上进行训练。我已经从<em class="jd">火炬接力</em>下载了这个模型。VGG16  <strong class="ih hj">模型</strong>在我们的狗数据集上表现更好。我们需要加载和转换所需格式的图像(例如，图像大小，转换为RGB，标准化数据)。<em class="jd">这个“load_transform_image”函数也在测试一幅图像的最终工作流程中使用</em>。还制作了一个狗检测器，如果在传递给该函数的图像中检测到狗，则返回<em class="jd">“真”。以下是代码:</em></em></p><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="8f2b" class="jq jr hi lx b fi mb mc l md me"><strong class="lx hj">import</strong> <strong class="lx hj">torch<br/>from</strong> <strong class="lx hj">PIL</strong> <strong class="lx hj">import</strong> <strong class="lx hj">Image</strong><br/><strong class="lx hj">import</strong> <strong class="lx hj">torchvision.transforms</strong> <strong class="lx hj">as</strong> <strong class="lx hj">transforms<br/>import</strong> <strong class="lx hj">torchvision.models</strong> <strong class="lx hj">as</strong> <strong class="lx hj">models</strong></span><span id="f43f" class="jq jr hi lx b fi mg mc l md me"><em class="jd"># define VGG16 model</em><br/>VGG16 = models.vgg16(pretrained=<strong class="lx hj">True</strong>)</span><span id="e0da" class="jq jr hi lx b fi mg mc l md me"><em class="jd"># check if CUDA is available</em><br/>use_cuda = torch.cuda.is_available()</span><span id="8a22" class="jq jr hi lx b fi mg mc l md me"><em class="jd"># move model to GPU if CUDA is available</em><br/><strong class="lx hj">if</strong> use_cuda:<br/>    VGG16 = VGG16.cuda()</span><span id="a5e4" class="jq jr hi lx b fi mg mc l md me"><strong class="lx hj">def</strong> load_transform_image(img_path):<br/>    '''<br/>    Used load &amp; transform image for prediction on single image<br/>    '''</span><span id="9384" class="jq jr hi lx b fi mg mc l md me">img = Image.open(img_path).convert('RGB')<br/>    normalize = transforms.Normalize(<br/>                        mean=[0.485, 0.456, 0.406],<br/>                        std=[0.229, 0.224, 0.225])  <br/>    img_transform = transforms.Compose([<br/>                        transforms.Resize(size=(224, 224)),    <br/>                        transforms.ToTensor(),<br/>                        normalize])<br/>    img = img_transform(img)[:3,:,:].unsqueeze(0)<br/>    <strong class="lx hj">return</strong> img</span><span id="58bb" class="jq jr hi lx b fi mg mc l md me"><strong class="lx hj">def</strong> VGG16_predict(img_path):<br/>    <em class="jd">'''</em><br/><em class="jd">    Use pre-trained VGG-16 model to obtain index corresponding to </em><br/><em class="jd">    predicted ImageNet class for image at specified path</em><br/><em class="jd">    </em><br/><em class="jd">    Args:</em><br/><em class="jd">        img_path: path to an image</em><br/><em class="jd">        </em><br/><em class="jd">    Returns:</em><br/><em class="jd">        Index corresponding to VGG-16 model's prediction</em><br/><em class="jd">    '''</em></span><span id="ab36" class="jq jr hi lx b fi mg mc l md me">    image = load_transform_image(img_path)<br/>    <strong class="lx hj">if</strong> use_cuda:<br/>        image = image.cuda()<br/>    output = VGG16(image)<br/>    <strong class="lx hj">return</strong> torch.max(output,1)[1].item()</span><span id="54c2" class="jq jr hi lx b fi mg mc l md me"><strong class="lx hj">def</strong> dog_detector(img_path):<br/>    prediction = VGG16_predict(img_path)<br/>    <strong class="lx hj">return</strong> (prediction&gt;=151 <strong class="lx hj">and</strong> prediction&lt;=268)</span></pre><p id="9525" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">自定义图像上dog_detector的结果:</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mo"><img src="../Images/e61223bda0fd16061090ce5a27fac905.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*ys0Oq92dKpvQgxtfoDRUaA.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">dog_detector的正确预测</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mp"><img src="../Images/6aa4f573bb89cf5ec09a14268df39667.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*6OhzvvK0vG-xDIWx-ALDpA.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">dog_detector的正确预测</figcaption></figure><blockquote class="mh mi mj"><p id="6a7d" class="if ig jd ih b ii ij ik il im in io ip mk ir is it ml iv iw ix mm iz ja jb jc hb bi translated"><strong class="ih hj">模型性能</strong>:为了节省时间，我们可以对两个数据集中的前100幅图像进行检测。</p></blockquote><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="2f65" class="jq jr hi lx b fi mb mc l md me">Percentage of <em class="jd">dogs detected in human image data</em>(incorrect detections): 1.0%<br/>Percentage of <em class="jd">dogs detected in dog image data</em>: 100.0%</span></pre><p id="7ae0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以尝试不同的架构，比如Inception-v3、ResNets、GoogleNet等等</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="6cce" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">数据加载器</h2><p id="23ed" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">我们需要为训练模型准备数据。我已经按照训练和测试我们的模型所需的格式执行了数据规范化、拆分和排列！在训练你的神经网络时，数据扩充是一个重要的因素，这为你的模型增加了更多的鲁棒性，并使它从我们数据的不同变化中学习。基本上，数据扩充有助于增加数据的变化。给出了生成数据加载器的代码。</p><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="c856" class="jq jr hi lx b fi mb mc l md me"><strong class="lx hj">import</strong> <strong class="lx hj">os</strong><br/><strong class="lx hj">from</strong> <strong class="lx hj">torchvision</strong> <strong class="lx hj">import</strong> <strong class="lx hj">datasets</strong><br/><strong class="lx hj">import</strong> <strong class="lx hj">torchvision.transforms</strong> <strong class="lx hj">as</strong> <strong class="lx hj">transforms</strong></span><span id="0bb9" class="jq jr hi lx b fi mg mc l md me"><em class="jd">data_dir</em> = '/data/dog_images/'<br/><em class="jd">train_dir</em> = os.path.join(data_dir, 'train/')<br/><em class="jd">valid_dir</em> = os.path.join(data_dir, 'valid/')<br/><em class="jd">test_dir</em> = os.path.join(data_dir, 'test/')</span><span id="ca52" class="jq jr hi lx b fi mg mc l md me"><em class="jd">normalize</em> = transforms.Normalize(mean=[0.485, 0.456, 0.406],<br/>                                 std=[0.229, 0.224, 0.225])</span><span id="8b2e" class="jq jr hi lx b fi mg mc l md me"><em class="jd">preprocess_data</em> = {'train': transforms.Compose([<br/>                                 transforms.RandomResizedCrop(224),<br/>                                 transforms.RandomHorizontalFlip(),<br/>                                 transforms.ToTensor(),<br/>                                 normalize]),<br/>                   'valid': transforms.Compose([<br/>                                 transforms.Resize(256),<br/>                                 transforms.CenterCrop(224),<br/>                                 transforms.ToTensor(),<br/>                                 normalize]),<br/>                   'test': transforms.Compose([<br/>                                 transforms.Resize(size=(224,224)),<br/>                                 transforms.ToTensor(), <br/>                                 normalize])}</span><span id="bb40" class="jq jr hi lx b fi mg mc l md me"><em class="jd">train_data</em> = datasets.ImageFolder(<br/>                          train_dir, <br/>                          transform=preprocess_data['train'])<br/><em class="jd">valid_data</em> = datasets.ImageFolder(<br/>                          valid_dir,<br/>                          transform=preprocess_data['valid'])<br/><em class="jd">test_data</em> = datasets.ImageFolder(<br/>                          test_dir, <br/>                          transform=preprocess_data['test'])</span><span id="2c16" class="jq jr hi lx b fi mg mc l md me"><strong class="lx hj"><em class="jd">batch_size</em></strong> = 20<br/><em class="jd">num_workers</em> = 0<br/><strong class="lx hj"><em class="jd">train_loader</em></strong> = torch.utils.data.DataLoader(train_data,<br/>                                           batch_size=batch_size, <br/>                                           num_workers=num_workers,<br/>                                           shuffle=<strong class="lx hj">True</strong>)<br/><strong class="lx hj"><em class="jd">valid_loader</em></strong> = torch.utils.data.DataLoader(valid_data,<br/>                                           batch_size=batch_size, <br/>                                           num_workers=num_workers,<br/>                                           shuffle=<strong class="lx hj">False</strong>)<br/><strong class="lx hj"><em class="jd">test_loader</em></strong> = torch.utils.data.DataLoader(test_data,<br/>                                           batch_size=batch_size, <br/>                                           num_workers=num_workers,<br/>                                           shuffle=<strong class="lx hj">False</strong>)<br/><strong class="lx hj"><em class="jd">loaders_scratch</em></strong> = {<br/>    'train': train_loader,<br/>    'valid': valid_loader,<br/>    'test': test_loader<br/>}</span></pre><p id="fb7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这样现在我们就有了<strong class="ih hj"> <em class="jd">【训练_加载器】</em></strong><strong class="ih hj"><em class="jd">有效_加载器</em> </strong>和<strong class="ih hj"> <em class="jd">测试_加载器</em> </strong>，数据按照定义的<em class="jd">预处理</em>和<em class="jd">数据扩充</em>步骤批量存储。数据准备中执行的步骤说明:</p><ul class=""><li id="1871" class="lf lg hi ih b ii ij im in iq lo iu lp iy lq jc lk ll lm ln bi translated">我对<em class="jd">训练数据</em>使用了<strong class="ih hj"><em class="jd">randomresizedcrop</em></strong>，它将所有训练图像的大小调整为(224，224)，它还对原始图像进行了随机裁剪，以便我们的模型能够学习数据中的复杂变化。我已经使用<strong class="ih hj"><em class="jd">RandomHorizontalFlip</em></strong>(p = . 5)水平翻转了数据，这将水平翻转一半图像，以给原始训练数据添加更多变化。train文件夹中几乎所有的图像都是直的(狗以直的方式排列),所以使用水平翻转而不是垂直翻转更明智。我还使用<strong class="ih hj"> <em class="jd">标准归一化</em> </strong>归一化了图像中的所有通道。</li><li id="bf28" class="lf lg hi ih b ii lr im ls iq lt iu lu iy lv jc lk ll lm ln bi translated">使用大小为(224，224)的<strong class="ih hj"> <em class="jd">中心裁剪</em> </strong>用于<em class="jd">验证数据</em>，因为大多数图像的中心都有一张狗脸，因此这将有助于提高验证的准确性！</li><li id="14c4" class="lf lg hi ih b ii lr im ls iq lt iu lu iy lv jc lk ll lm ln bi translated"><strong class="ih hj"> <em class="jd">调整大小</em> </strong> <em class="jd">测试图像</em>到(224，224)<em class="jd">这里没有做其他变换</em>，因为我们将在原始数据上测试我们的模型</li></ul></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="fd17" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">犬种分类</h2><p id="d8ba" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">为了这个任务，让我们在<em class="jd"> Pytorch </em>中从头开始构建我们自己的<em class="jd">CNN</em>。在这里，我创建了一个Relu激活的3层CNN。对每一层使用不同的内核大小、步幅、填充和最大池，原始图像的大小(224，224)已减少到(7，7)，原始深度3已转换为128: (224，224，3) <strong class="ih hj"> - &gt; </strong> (7，7，128)。这样我们就从给定的图像中提取出了空间特征！我们增加深度或添加更多过滤器，以便网络可以学习图像中更重要的特征，并更好地进行归纳。</p><blockquote class="mh mi mj"><p id="88d7" class="if ig jd ih b ii ij ik il im in io ip mk ir is it ml iv iw ix mm iz ja jb jc hb bi translated">模型架构:</p></blockquote><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="ad85" class="jq jr hi lx b fi mb mc l md me"><strong class="lx hj">import</strong> <strong class="lx hj">torch.nn</strong> <strong class="lx hj">as</strong> <strong class="lx hj">nn</strong><br/><strong class="lx hj">import</strong> <strong class="lx hj">torch.nn.functional</strong> <strong class="lx hj">as</strong> <strong class="lx hj">F</strong></span><span id="1a9d" class="jq jr hi lx b fi mg mc l md me"><em class="jd"># define the CNN architecture</em><br/><strong class="lx hj">class</strong> <strong class="lx hj">Net</strong>(nn.Module):<br/>    <strong class="lx hj">def</strong> __init__(self):<br/>        super(Net, self).__init__()<br/>        <em class="jd"># Conv Layers</em><br/>        self.conv1 = nn.Conv2d(3, 32, 3, stride=2, padding=1)<br/>        self.conv2 = nn.Conv2d(32, 64, 3, stride=2, padding=1)<br/>        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)<br/>        <em class="jd"># maxpool</em><br/>        self.pool = nn.MaxPool2d(2, 2)<br/>        <em class="jd"># fc layers</em><br/>        self.fc4 = nn.Linear(7*7*128, 2048)<br/>        self.fc5 = nn.Linear(2048, 512)<br/>        self.fc6 = nn.Linear(512, 133)    <em class="jd">#number of classes = 133</em><br/>        <em class="jd"># dropout </em><br/>        self.dropout = nn.Dropout(0.25)    <em class="jd">#dropout of 0.25</em><br/>        <em class="jd"># batchNorm layers</em><br/>        self.batch_norm = nn.BatchNorm1d(512)<br/>    <br/>    <strong class="lx hj">def</strong> forward(self, x):<br/>        <em class="jd">## Define forward behavior</em><br/>        x = F.relu(self.conv1(x))<br/>        x = self.pool(x)<br/>        x = F.relu(self.conv2(x))<br/>        x = self.pool(x)<br/>        x = F.relu(self.conv3(x))<br/>        x = self.pool(x)<br/>        <br/>        <em class="jd"># flatten</em><br/>        x = x.view(-1, 7*7*128)<br/>        x = self.dropout(x)<br/>        x = F.relu(self.fc4(x))<br/>        x = self.dropout(x)<br/>        x = F.relu(self.batch_norm(self.fc5(x)))<br/>        x = self.dropout(x)<br/>        x = self.fc6(x)<br/>        <strong class="lx hj">return</strong> x</span><span id="942f" class="jq jr hi lx b fi mg mc l md me"><em class="jd"># instantiate the CNN</em><br/>model_scratch = Net()</span><span id="f000" class="jq jr hi lx b fi mg mc l md me"><em class="jd"># move tensors to GPU if CUDA is available</em><br/><strong class="lx hj">if</strong> use_cuda:<br/>    model_scratch.cuda()</span></pre><p id="3f20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用了<strong class="ih hj"> <em class="jd">交叉熵损失</em> </strong>作为<strong class="ih hj"> <em class="jd"> </em> </strong>一个<strong class="ih hj"> <em class="jd">代价函数</em> </strong>和<strong class="ih hj"> <em class="jd">亚当</em> </strong>作为<strong class="ih hj"> <em class="jd">优化器</em> </strong>，你可以在<strong class="ih hj"> PyTorch </strong> <a class="ae kx" href="https://pytorch.org/docs/stable/nn.html#loss-functions" rel="noopener ugc nofollow" target="_blank"> <em class="jd">这里</em> </a>和各种优化器中阅读更多关于交叉熵损失的实现</p><p id="8a99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在位于狗图像数据集中的训练数据上以批量大小20训练了50个时期之后，我得到了`<strong class="ih hj"> <em class="jd">训练损失</em></strong><em class="jd">:</em><strong class="ih hj"><em class="jd">4.1504</em></strong>和`<strong class="ih hj"> <em class="jd">验证损失</em></strong><em class="jd">:</em><strong class="ih hj"><em class="jd">3.7211</em></strong></p><blockquote class="mh mi mj"><p id="8adb" class="if ig jd ih b ii ij ik il im in io ip mk ir is it ml iv iw ix mm iz ja jb jc hb bi translated"><strong class="ih hj">该车型(model_scratch)在测试数据上的表现</strong>:</p></blockquote><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="ab29" class="jq jr hi lx b fi mb mc l md me">Test Loss: 3.820199<br/>Test Accuracy: 10% (89/836)</span></pre><p id="9cdc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，为了节省时间并获得更好的性能，我选择使用<em class="jd">转移学习</em>和<strong class="ih hj"> <em class="jd">微调</em> </strong>我们训练数据上转移的模型权重。<strong class="ih hj"> <em class="jd"> ResNet-101 </em> </strong>被选为本次<em class="jd">分类任务</em>的<strong class="ih hj"> <em class="jd"> </em> </strong>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es mq"><img src="../Images/cb4e9a74e4e85bc3bcaf856c01444e54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sgm2uv_luh1Ak2FnAmdtCw.png"/></div></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><strong class="bd js">剩余块，显示跳过连接！</strong></figcaption></figure><p id="94cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">选择ResNet </em>的理由:</p><ul class=""><li id="c437" class="lf lg hi ih b ii ij im in iq lo iu lp iy lq jc lk ll lm ln bi translated">众所周知，ResNets在图像分类中表现突出。ResNet是用“<strong class="ih hj"> <em class="jd">”剩余块</em> </strong>构建的，基本上就是层间的<em class="jd">跳过连接</em>。这在初始层和最终层之间创建了一个<em class="jd">身份连接</em>，降低了<em class="jd">消失和爆发梯度问题</em>的风险，这也有助于降低训练数据上<em class="jd">欠拟合和过拟合</em>的风险！Resnet101是一个101层深度神经网络，因此从图像中捕获<em class="jd">粒度空间信息</em>。CNN为每幅输入图像提供了更好的特征表示，残差块产生的身份连接使得梯度流变得容易，因此ResNet有助于提高分类任务</li><li id="89bc" class="lf lg hi ih b ii lr im ls iq lt iu lu iy lv jc lk ll lm ln bi translated">我还将<em class="jd">预训练Resnet </em>的<strong class="ih hj"> <em class="jd">移除了</em></strong><strong class="ih hj"><em class="jd">最后一个全连接层</em> </strong>，并在最后添加了我们的<strong class="ih hj">自定义</strong> <em class="jd">全连接</em>，这是为了输出<strong class="ih hj"><em class="jd">133</em></strong><strong class="ih hj"><em class="jd">大小的矢量</em> </strong>。</li></ul><blockquote class="mh mi mj"><p id="e2b7" class="if ig jd ih b ii ij ik il im in io ip mk ir is it ml iv iw ix mm iz ja jb jc hb bi translated">模型架构:</p></blockquote><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="cc0a" class="jq jr hi lx b fi mb mc l md me"><strong class="lx hj">import</strong> <strong class="lx hj">torchvision.models</strong> <strong class="lx hj">as</strong> <strong class="lx hj">models</strong><br/><strong class="lx hj">import</strong> <strong class="lx hj">torch.nn</strong> <strong class="lx hj">as</strong> <strong class="lx hj">nn</strong></span><span id="313a" class="jq jr hi lx b fi mg mc l md me"><em class="jd">model_transfer</em> = models.resnet101(pretrained=<strong class="lx hj">True</strong>)</span><span id="07e1" class="jq jr hi lx b fi mg mc l md me"><strong class="lx hj">for</strong> param <strong class="lx hj">in</strong> model_transfer.parameters():<br/>    param.requires_grad = <strong class="lx hj">False</strong></span><span id="a8d1" class="jq jr hi lx b fi mg mc l md me"><em class="jd">#replacing last fc with custom fully-connected layer which should output 133 sized vector</em><br/><strong class="lx hj"><em class="jd">model_transfer.fc</em></strong><em class="jd"> = nn.Linear(2048, 133, bias=</em><strong class="lx hj"><em class="jd">True</em></strong><em class="jd">)</em></span><span id="33ef" class="jq jr hi lx b fi mg mc l md me"><em class="jd">#extracting fc parameters</em><br/>fc_parameters = model_transfer.fc.parameters()         <br/><strong class="lx hj">for</strong> param <strong class="lx hj">in</strong> fc_parameters:<br/>    param.requires_grad = <strong class="lx hj">True</strong></span></pre><p id="a1cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练了仅仅20个历元之后，批量大小为20的训练数据位于狗图像数据集中，其`<em class="jd">训练损失=</em><strong class="ih hj"><em class="jd">1.4732</em></strong>和`<em class="jd">验证损失=</em><strong class="ih hj"><em class="jd">0.9333</em></strong>`。如果训练更多的纪元，损失将减少，模型将从数据中学习尽可能多的东西！</p><blockquote class="mh mi mj"><p id="ecf5" class="if ig jd ih b ii ij ik il im in io ip mk ir is it ml iv iw ix mm iz ja jb jc hb bi translated"><strong class="ih hj">模型性能</strong>测试数据:我选择了<strong class="ih hj">精度</strong>和<strong class="ih hj">召回</strong>数作为评价指标。这是因为我们的数据有不平衡，精确回忆总是给我们一个很好的模型性能概述！</p></blockquote><pre class="jf jg jh ji fd lw lx ly lz aw ma bi"><span id="6d77" class="jq jr hi lx b fi mb mc l md me">from <strong class="lx hj">sklearn.metrics</strong> import <strong class="lx hj">confusion_matrix</strong>, <strong class="lx hj">precision_recall_fscore_support</strong></span><span id="09ea" class="jq jr hi lx b fi mg mc l md me"><em class="jd">cm</em> = <strong class="lx hj">confusion_matrix</strong>(ground_truths, predictions)</span><span id="8ddc" class="jq jr hi lx b fi mg mc l md me"><strong class="lx hj"><em class="jd">precision</em></strong> = np.mean(<strong class="lx hj">precision_recall_fscore_support</strong>(ground_truths, predictions)[0])</span><span id="9e8d" class="jq jr hi lx b fi mg mc l md me"><strong class="lx hj"><em class="jd">recall</em></strong> = np.mean(<strong class="lx hj">precision_recall_fscore_support</strong>(ground_truths, predictions)[1])</span></pre><blockquote class="mr"><p id="0d84" class="ms mt hi bd mu mv mw mx my mz na jc dx translated">品种分类器精度数:<em class="nb"> 0.8039343488 </em></p><p id="c4a2" class="ms mt hi bd mu mv nc nd ne nf ng jc dx translated">品种分类器召回编号:<em class="nb"> 0.78137904284 </em></p></blockquote><p id="00e5" class="pw-post-body-paragraph if ig hi ih b ii nh ik il im ni io ip iq nj is it iu nk iw ix iy nl ja jb jc hb bi translated">下面给出了所有测试数据预测的混淆矩阵，不容易阅读/可视化，但您可以集中在一些暗点上，在那里您可以分析在其他类中被错误分类的类。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es nm"><img src="../Images/8494147eba477415f2f3c39d4066c988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*gKbfwOS1Pv2KalADSJoXEQ.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">混淆矩阵</figcaption></figure></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="f127" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">结果</h2><p id="be91" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">现在是测试我们的工作流程(迷你管道)的时候了！下面是我们的工作流程产生的一些有趣的结果！之前模型看不到任何图像(真实世界用户提供的图像)。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es nn"><img src="../Images/570b350cfdd137306ea01b32aafc48b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*ahKrI5xL-LDHwIqobbTXSA.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><strong class="bd js">完全识别的狗，具有正确的品种分类</strong></figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es no"><img src="../Images/76c44404059592db96a346190781386f.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*igTHL0_T5VfQT1IFEIidPA.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><strong class="bd js">狗狗品种分类的搞笑编辑狗形象！</strong></figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/b27c2d88ece12c08613758a3d6dfd993.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*Lgl_gdw_mJbuJoXyt7WDpQ.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><strong class="bd js">完全识别的狗，具有正确的品种分类</strong></figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es np"><img src="../Images/f9e7cc9006c66c34869b4e7a6cb4b8a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*vzE5UT6VCwbCz12pNp5KNw.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><strong class="bd js">完美的人脸识别，产生最像狗的品种！</strong></figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es nq"><img src="../Images/e03c07a3074e6b3ec303e62c151ea0c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*GGNe6ltxu4COeuNLMMkmsg.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">没有检测到任何东西！错误检测，人类存在。</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es nr"><img src="../Images/cb36b80f4467d277897b870757931dba.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*N_1qysIIDudGzkiuYQJOQA.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><strong class="bd js">完全识别的狗，品种分类正确</strong></figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ns"><img src="../Images/e94d72ae6102bc8f85d781249357c481.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*PhykrSwi8L2cNNvGVQUxEA.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><strong class="bd js">没有检测到任何东西！太棒了！</strong></figcaption></figure></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="2a43" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">丰富</h2><ul class=""><li id="672b" class="lf lg hi ih b ii kl im km iq lh iu li iy lj jc lk ll lm ln bi translated">在这种情况下，对更多数据进行培训会有所帮助，而且数据的<em class="jd">增加</em>可能会有所帮助，例如裁剪图像以纠正区域可能会有所帮助。</li><li id="1f05" class="lf lg hi ih b ii lr im ls iq lt iu lu iy lv jc lk ll lm ln bi translated">在dog_images/train中拥有完美的标签和更多的数据肯定会有所帮助。还手动添加一些<em class="jd">变化</em> ( <em class="jd">噪声</em>)到数据中，例如添加虚假图像或在人类数据集中看起来像狗的人类图像。</li><li id="6b1d" class="lf lg hi ih b ii lr im ls iq lt iu lu iy lv jc lk ll lm ln bi translated"><em class="jd">超参数调整</em>总是有帮助的！:)</li><li id="1ba2" class="lf lg hi ih b ii lr im ls iq lt iu lu iy lv jc lk ll lm ln bi translated">使用一个更强大的预先训练过的模型可能也会有所帮助！</li></ul></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="6016" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated"><strong class="ak">结论</strong></h2><p id="ab4c" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">我要探索大范围的数据。摆弄数据和从零开始创建模型非常有趣！CNN是机器学习领域的重要发明。需要注意的一个要点是，现代深度学习框架如何使我们的工作变得简单，我们可以用少量(非常少)行代码来训练我们的模型。用过PyTorch，这是一个很棒的编程框架！必须了解迁移学习如何在我们的应用中帮助我们。</p><p id="f2d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一个值得注意的有趣的事情是，一个训练有素的模型(机器)有时在概括特征方面甚至比人做得更好。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><p id="b8ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你觉得我的<a class="ae kx" href="https://github.com/s-nilesh/Dog-Breed-Classifier" rel="noopener ugc nofollow" target="_blank">代码</a>有用并提出改进建议，请随意使用。请鼓掌，谢谢！</p></div></div>    
</body>
</html>