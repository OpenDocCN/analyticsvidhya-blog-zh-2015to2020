<html>
<head>
<title>Decision Tree Series — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树系列—第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/decision-tree-series-part-1-5866d683615c?source=collection_archive---------18-----------------------#2020-01-11">https://medium.com/analytics-vidhya/decision-tree-series-part-1-5866d683615c?source=collection_archive---------18-----------------------#2020-01-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es im"><img src="../Images/358c458d0e5b627384d255fe9cfa5103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sUnPJ3BJ5taQC-CK6LRtOA.png"/></div></div></figure><p id="3e13" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">在这篇博客中，我们将首先触及决策树的历史，我将通过一个直观的例子给你一个完整的指南来理解决策树背后的概念以及它是如何工作的。</p><p id="26ce" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">决策树模型的开始</strong></p><p id="0030" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">执行决策树分析的最初模型是由悉尼大学的<a class="ae jw" href="http://en.wikipedia.org/wiki/Ross_Quinlan" rel="noopener ugc nofollow" target="_blank"> J .罗斯·昆兰</a>创建的，并在1975年他的书<em class="jx">机器学习</em>第1卷第1号中提出。他的第一个决策树创建算法被称为<a class="ae jw" href="http://en.wikipedia.org/wiki/ID3_algorithm" rel="noopener ugc nofollow" target="_blank">迭代二分法3 (ID3) </a>。该算法是基于奥卡姆剃刀原理创建的，其思想是尽可能创建最小、最有效的决策树。昆兰继续发展这个模型，他创造了<a class="ae jw" href="http://en.wikipedia.org/wiki/C4.5_algorithm" rel="noopener ugc nofollow" target="_blank"> C4.5算法</a>，最后是C5.0算法。</p><p id="ac08" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">什么是决策树？</strong></p><p id="bc3b" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">决策树是一种监督学习算法。决策树是通过基于条件和阈值分割群体和样本数据来生成的，以这种方式，相同的组彼此相似，而这些组彼此显著不同。决策树主要用于分类问题。但是它对分类数据和数字数据都有效。</p><p id="5543" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">数学概念:</strong></p><p id="2500" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">熵:</strong></p><p id="1285" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">信息熵是随机数据源产生信息的平均速率。它衡量信息相对于其大小的重要性。熵是状态不可预测性的度量，或者等价地，是其平均信息量的度量。</p><p id="848f" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">在决策树的上下文中，熵代表数据的方差。</p><p id="090e" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">当数据是异质的(不纯的)时，熵是最大的。当数据是同质的(纯的)时最小。</p><p id="ae0b" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">例如:<br/>如果我们掷硬币，正面的概率与反面的概率相同，那么掷硬币的熵就和两种结果的试验一样高。如果硬币是有偏向的，总是正面朝上，没有反面，熵为零，因为硬币总是正面朝上，结果可以很好地预测。<br/>对于决策树，我们必须计算两种类型的熵:</p><ol class=""><li id="b6e9" class="jy jz hi ja b jb jc jf jg jj ka jn kb jr kc jv kd ke kf kg bi translated">一个属性的熵E(S ),其中S是当前状态(现有结果), P(x)是该状态S的事件x的概率:</li></ol><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es kh"><img src="../Images/91316601ade6793dbbb085ec160e5b25.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/0*ipTkohZHq2b1Jkl6"/></div></figure><p id="76b0" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">2.两个属性的熵<em class="jx"> E(S，A)</em>——<em class="jx">S</em>和<em class="jx"> A </em>，其中<em class="jx"> S </em>是属性<em class="jx"> A </em>的当前状态，<em class="jx"> A </em>是选择的属性，<em class="jx"> P(x) </em>是属性<em class="jx"> A </em>的事件<em class="jx"> x </em>的概率。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es ki"><img src="../Images/e94b4d5011a0b4b9394d3d4b7c2a0219.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/0*v1G_UahbRv6Oi-gg"/></div></figure><p id="1fc8" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">信息增益:</strong></p><p id="5395" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">它代表熵的变化或熵的减少。它衡量分割的质量和一个特征给我们多少关于类的信息。对于已经完全分割的特征，信息将是最大的。</p><p id="a265" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">它也被称为Kullback-Leibler散度。它测量关于独立变量的熵的相对变化。用<em class="jx"> IG(S，A)表示。</em></p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es kj"><img src="../Images/ee5dfba99a11ec6888a8d1e763fa5f22.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*Xf1JsHB4qE-dpGnBcQceIg.png"/></div></figure><p id="b3fc" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj"> ID3 </strong> ( <strong class="ja hj">迭代二分法</strong>)</p><p id="0dad" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">这是最常见和最古老的决策树算法。决策树工作在分而治之的规则上。这里二分法的意思是分成两个相反的部分。该算法以交互方式将特征分为两组，这两组特征彼此完全独立，并基于分割规则构建一棵树。</p><p id="1f41" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">分割标准</strong></p><p id="bde4" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">ID3使用贪婪的自顶向下搜索，在熵和信息增益的帮助下构建树。具有最多信息增益的属性将被认为是分割的最佳属性。</p><p id="722e" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">分类规则</strong></p><p id="b9e8" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">如果单个特征的熵为0，这意味着它是同质节点，无需进一步分类。如果熵为1，则为异构节点，需要进一步分类。</p><p id="e4b8" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">示例</strong></p><p id="bfdf" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">使用两周的训练数据，我们需要使用ID3算法来决定天气是否适合打板球。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es kk"><img src="../Images/46f8532b63e6e4de1ff419cb869deb11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*15TSEk1mY-VmbMoN"/></div></div></figure><p id="d6ae" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">这里输出或目标变量是决策。</p><p id="2740" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">决策变量的熵:</p><blockquote class="kl km kn"><p id="83f4" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">这里:</p><p id="54ff" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">是' = 9</p><p id="bf8a" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">否' = 5</p><p id="bb69" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">总计=14</p></blockquote><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es kr"><img src="../Images/8278ab8b565a2a0f6114ddc7068d135f.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/0*MyLhMcecrxLti-YV"/></div></figure><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es ks"><img src="../Images/24fa3814ee1b8bf020af9e587dd121b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/0*7W7xIHM2NPGQjqiI"/></div></figure><p id="60b9" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">现在，我们有4个输入属性展望，温度，湿度，风。</p><p id="0a9c" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">我们将计算每个变量的信息增益，具有最高信息增益的变量将是根节点。</p><p id="8dbe" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">让我们从outlook属性开始:</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es kt"><img src="../Images/bb057a38d3b8cbd6a8bc7add2a10cf00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cApvw8m55ZIg28qN"/></div></div></figure><p id="96fd" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">展望属性有三个变量晴天，阴天和雨天。</p><blockquote class="kl km kn"><p id="6111" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">Sunny已经:</p><p id="1278" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">2票赞成，3票反对</p><p id="ffab" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">阴有4是0否</p><p id="d0fd" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">雨天有3是2不是。</p></blockquote><p id="93da" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">每个人的计算熵是:</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ku"><img src="../Images/070ea6c216210afeadbbf974e1fce5fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VjVzm8ax7mTEWgZd"/></div></div></figure><p id="2901" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">现在，我们将在分解数据后计算加权熵:</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es kv"><img src="../Images/1f64a52b0641430f886fb0c4fb5f81b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/0*g43BmsXeVlJyw2hh"/></div></figure><p id="7f38" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">最后，outlook属性的信息增益:</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es kw"><img src="../Images/d2d59f18912c14c88647914469ada8cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/0*YEK_zmrTiMOx2cg0"/></div></figure><p id="8ea5" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">同样，我们可以计算温度、湿度和风属性的IG。</p><p id="eac7" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">各个属性的IG为:</p><blockquote class="kl km kn"><p id="e258" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">IG(S，温度):0.029</p><p id="62fa" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">IG(秒，湿度):0.151</p><p id="649a" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">IG(S，有风):0.048</p></blockquote><p id="ea27" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">根据以上观察，IG(S，Outlook)具有最高的信息增益0.246，因此Outlook属性将是根节点:</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es kx"><img src="../Images/6a829c29c0ab22a22e8d12fdb8779740.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/0*_xK-6AEvhWC7CtVY"/></div></figure><p id="0365" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">从上面的树观察展望--&gt;阴总是肯定的(阴的熵是0)。</p><p id="bd67" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">现在我们还有3个属性。</p><p id="8977" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">首先，我们将计算当前景晴朗时的决策熵。</p><blockquote class="kl km kn"><p id="d941" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">e(决策|展望=晴朗)= 0.96</p></blockquote><p id="4309" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">E(Decision | outlook=sunny)可以表示为E(S|outlook=sunny)。</p><p id="5db1" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">现在，我们将以同样的方式计算天气晴朗时温度、湿度和风力属性的信息增益:</p><blockquote class="kl km kn"><p id="9c6c" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">IG(前景=晴朗，温度)= 0.570</p><p id="9c32" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">IG(前景=晴朗，湿度)=0.970</p><p id="9fac" class="iy iz jx ja b jb jc jd je jf jg jh ji ko jk jl jm kp jo jp jq kq js jt ju jv hb bi translated">IG(前景=晴朗，有风)=0.019</p></blockquote><p id="c596" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">从上面的输出来看，湿度具有最高的信息增益，同样地，对于(S|outlook=rain ),风也会给我们最高的信息增益。</p><p id="cbb7" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">因此，最终的决策树将是:</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ky"><img src="../Images/2e3897ca569c3829e0a7ee7f66bbbc41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R7ft2DSlbX4ZuN2r"/></div></div></figure><p id="a50c" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">结论</strong></p><p id="7cf5" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">在ID3中，如果一个变量是数值型的，我们必须把它转换成名义变量。数据可能过度拟合或过度分类。J. Ross Quinlan在C4.5和C5.0中发现并克服了这些问题。我们将在下一部分看到。</p></div></div>    
</body>
</html>