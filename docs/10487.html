<html>
<head>
<title>GANs — What do G , A and N mean in GANs?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GANs——G、A 和 N 在 GANs 中是什么意思？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/gans-what-do-g-a-and-n-mean-in-gans-b0b9275520b5?source=collection_archive---------17-----------------------#2020-10-20">https://medium.com/analytics-vidhya/gans-what-do-g-a-and-n-mean-in-gans-b0b9275520b5?source=collection_archive---------17-----------------------#2020-10-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2087" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">几天前，一个类似于这里的视频激起了我对 GANs 的兴趣，在那里我发现“爱因斯坦先生”在做鬼脸。</p><p id="d707" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将在这里写的关于 GANs 的系列博客更多的是试图通过研究和广泛使用以下两个资源来记录我对这个主题的理解:</p><p id="d813" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1)<a class="ae jd" href="https://livebook.manning.com/book/gans-in-action/gans-in-action-deep-learning-with-generative-adversarial-networks/" rel="noopener ugc nofollow" target="_blank">https://live book . manning . com/book/gans-in-action/gans-in-action-deep-learning-with-generative-adversarial-networks/</a></p><p id="8b0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2)<a class="ae jd" href="https://www.coursera.org/specializations/generative-adversarial-networks-gans" rel="noopener ugc nofollow" target="_blank">https://www . coursera . org/specializations/generative-adversarial-networks-gans</a></p><p id="3306" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我想把条件概率和贝叶斯定理作为这篇文章的先决条件。你可以在这里阅读这些<a class="ae jd" href="https://machinelearningmastery.com/bayes-theorem-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="d2b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GANs(生成对抗网络)是一种所谓的“生成”模型。第一篇文章旨在解释这些问题:</p><p id="8afb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="je">“什么叫生财？为什么是对抗性的？什么网络？</em></p><p id="900e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们将生成模型与判别模型进行比较时，更容易理解生成模型。假设，我们手头有一个分类问题。通常，当我们想到分类器时，脑海中浮现的是将两个组或类分开的某种超平面(一条线)。给定一个新的数据点，我们试图找出它会落在直线的哪一边，就像这样:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/ec367ec1da536e7df36adfe80891d70e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iVFwUXgh_NpKPXCGKaKq9Q.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">图一。区别分类器</figcaption></figure><p id="0229" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种模型被称为区别模型——它们区别或“识别”两个类别之间的区别。两种类型的模型属于判别模型:</p><p id="d793" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.使用概率模型的算法，其中我们找到条件概率 P(y | X；θ)<strong class="ih hj">直接</strong>，例如逻辑回归。</p><p id="3351" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.像 SVM 这样不使用概率模型并学习在输入特征和目标之间进行映射的分类器也被称为鉴别分类器。</p><p id="cfdf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，<em class="je">对于同一个问题</em>，生成学习算法有什么不同？</p><p id="3e1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成模型不仅仅是分类。在对数据点进行分类的过程中，算法的第一步是对每个类别进行“建模”。</p><p id="9306" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们试图对汽车和飞机进行分类，生成算法对飞机的分布和汽车的分布进行建模，然后找出看不见的数据点更可能是从哪种分布中生成的。</p><p id="8708" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用外行人的话说:</p><ul class=""><li id="badd" class="jv jw hi ih b ii ij im in iq jx iu jy iy jz jc ka kb kc kd bi translated">你有一组数据点(比如所有飞机的集合)</li><li id="8343" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated">假设这些点遵循某种未知分布 D <em class="je">飞机</em></li><li id="7ee1" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated">生成模型试图学习分布 D <em class="je">模型 _ 飞机</em>类似于 D <em class="je">飞机</em></li></ul><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es kj"><img src="../Images/a19de60f2232943f87c8491316331e08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*itoa9F3r4KfGnby1WmR4mg.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">图二。简单的生成模型</figcaption></figure><p id="8a5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，学习算法模仿 D <em class="je">汽车</em>分布来找到 D <em class="je">型号 _ 汽车。如果模型的目标是对一个看不见的数据点进行分类，它就利用这些信息来找出它是一辆汽车还是一架飞机的概率。</em></p><p id="c339" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图 2 的底部。指示如何使用学习的分布来生成不一定在原始数据集中的新数据点。这解释了什么是生成性。</p><p id="2f1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就概率而言:</p><p id="de7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在生成分类算法的情况下，我们仍然需要找到称为后验概率的概率 P(y|X)。在这种情况下使用贝叶斯定理，这意味着我们首先找到先验概率 P(X|y)和 P(y)。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es kk"><img src="../Images/b2f3555577dbea44272f7e2a45066d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*32cECyYcSFv1lTzGWXezMw.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">图三。确定后验分布的贝叶斯规则</figcaption></figure><p id="428d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="je">就是这一步求 P(X|y)造成了差别。</em></p><p id="89b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你考虑术语 P(X|y= '飞机')-这实际上近似于飞机的特征分布，类似地，P(X|y= '汽车')近似于或模拟汽车的特征分布。</p><p id="f98e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果不是为了分类，我们实际上感兴趣的只是找到 P(X)，即这些特征一起出现的概率，比如说，在一架飞机上。</p><p id="f4a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个词“生财”就这么多了！</p><p id="59cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">字典上是这么说的:“以冲突或对立为特点”。这个术语是从博弈论中借用的，其中一个玩家的得失被另一个玩家的得失所平衡，正如这里的<a class="ae jd" href="https://en.wikipedia.org/wiki/Zero-sum_game" rel="noopener ugc nofollow" target="_blank">所解释的</a>。</p><p id="8850" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GAN 的目的是生成:生成新的图像，生成语言，以便很难区分生成的项目和真实的项目。</p><p id="e8dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GAN 由两个并行训练的网络组成:一个发生器和一个鉴别器。这些是在竞争，一个试图智取对方。</p><p id="c6b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看怎么做。假设目标是生成真实的汽车图像。生成器网络需要生成尽可能接近真实汽车图像的汽车图像，并试图欺骗其对手鉴别器，鉴别器必须足够聪明，以识别馈送给它的图像是真实汽车还是假汽车；这是一个二元分类器。错误分类误差被反馈给两个网络。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es kl"><img src="../Images/e3c1d0ac07c030c4acebde952d31b220.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lBkcDe6N7rj5cSkJDKJhsA.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">图 4。阿甘</figcaption></figure><p id="006f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成器随着生成类似真实的图像而变得越来越好，鉴别器通过将改进的生成图像识别为假的来进行识别。当鉴别器不再能够区分两者时，就是训练停止的时候——纳什均衡就达到了。在这个阶段，鉴别器的工作完成了，tada，生成器开始生成汽车图像，就好像它们是真实的一样。</p><p id="4881" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我相信这就解释了“生成性”和“对抗性”，而不用说《甘》中的网络指的是生成者网络和鉴别者网络。</p><p id="658c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你仍然对这个想法不感兴趣——请一定要去参观 https://www.thispersondoesnotexist.com/——他们不是真人！</p><p id="657b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您的阅读，如果您愿意和我一起踏上了解和建立 GANs 的旅程，请联系我们。</p><p id="e866" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">文献学</p><ol class=""><li id="1904" class="jv jw hi ih b ii ij im in iq jx iu jy iy jz jc km kb kc kd bi translated"><a class="ae jd" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="noopener ugc nofollow" target="_blank">https://papers . nips . cc/paper/5423-generative-adversarial-nets . pdf</a></li><li id="39d2" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc km kb kc kd bi translated"><a class="ae jd" href="https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf" rel="noopener ugc nofollow" target="_blank">https://ai . Stanford . edu/~ ang/papers/nips 01-discriminative generative . pdf</a></li><li id="640f" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc km kb kc kd bi translated"><a class="ae jd" href="http://cs229.stanford.edu/notes/cs229-notes2.pdf" rel="noopener ugc nofollow" target="_blank">http://cs229.stanford.edu/notes/cs229-notes2.pdf</a></li></ol></div></div>    
</body>
</html>