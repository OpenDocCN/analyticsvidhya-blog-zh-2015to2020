<html>
<head>
<title>Does Ensemble Models Always Improve Accuracy?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集合模型总是能提高准确性吗？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/does-ensemble-models-always-improve-accuracy-c114cdbdae77?source=collection_archive---------3-----------------------#2020-10-12">https://medium.com/analytics-vidhya/does-ensemble-models-always-improve-accuracy-c114cdbdae77?source=collection_archive---------3-----------------------#2020-10-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a23b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">简介</strong></p><p id="16a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器学习模型:</p><p id="3a2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一般来说，机器学习模型按顺序工作，我们提供输入，模型分类器拟合数据，并得出输出。输入数据来自单一样本。数据通常由自变量(X)和因变量(Y)组成。模型预测被表示为(ŷ).</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/eb21d853a31569bd654d7fe26bb92f59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H6RiAyUOeS3uKBMr5_hyxA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jp"><img src="../Images/c68cb74e61f73a794e2837db278143c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xFBKUMmsXijKG2pEG_Dpew.png"/></div></div></figure><p id="232b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在集成机器学习模型中，从单个群体中抽取几个样本，并在这些样本上拟合几个分类器。每个分类器产生一个输出，该输出是该模型分类器的预测值。集合模型的最终输出是单个模型预测的集合。</p><p id="34ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么聚合多个模型分类器的输出有什么帮助呢？为什么我们需要一个集合模型？</p><p id="1453" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">某些机器学习模型，如决策树，容易过度拟合(例如:模型可以很好地学习训练数据，但在新数据(测试数据)上表现不佳)。我们说这种模型的方差很高，这意味着这种模型的输出和精度变化很大。集合模型倾向于减少这种差异。</p><p id="f95d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在实时场景中，我们通常有单个样本输入到机器学习模型中。如上所述，从群体中获取相同大小的多个样本，以适合集成模型中的多个分类器。那么我们如何从同一个人群中获得多个样本呢？这里我们需要理解自举的统计概念。</p><p id="cd46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">自举</strong></p><p id="82c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Bootstrapping 是一种抽样技术，在这种技术中，用替换法从同一群体中抽取多个样本。从数学上证明，bootstrap 样本包含大约 63%的唯一值。中心极限定理也适用于这些 bootstrap 样本(中心极限定理指出，如果从总体中取出所有可能的样本，样本均值将遵循正态分布，总体均值是样本均值的均值，样本均值的标准误差由总体标准差除以样本大小的平方根给出)。在集成模型中，采用与训练数据大小相同的引导样本来拟合单个模型分类器。让我们来看两种集合建模技术——打包和提升。</p><p id="9b01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">自举汇总(装袋)</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jq"><img src="../Images/90135450b4bb908927755913199feeb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ot7NUedD1UVQGSqGUHlm7g.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">装袋模型</figcaption></figure><p id="f34f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于从总体中的单个样本生成多个样本的问题是通过 bootstrapping 解决的，因此在 bagging 模型中，假设我们有一个大小为 n 的样本数据作为我们的训练数据集，我们可以生成 k 个 bootstrap 样本。在生成的 k 个引导样本上，我们拟合 k 个分类器。每个分类器将产生一个输出。所有输出的集合将是我们对 bagging 算法的输出。</p><p id="bd4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数学上，bagging 算法可以写成:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jv"><img src="../Images/cfb49c7bb8af74df9f643d1c9b741616.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*tSZOR8NbfFhwCEe88tcKsA.png"/></div></figure><p id="4c16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中 I 是身份函数，如果为真则为 1，如果为假则为 0。向量 x 是输入向量，而 y 是来自第 I 个分类器的预测值。</p><p id="94e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么装袋如何减少方差呢？直观上我们可以这样理解，假设我们有 n 个随机变量 X1，X2..Xn 是独立且同分布的，并且遵循 N(μ，σ)的正态分布</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jw"><img src="../Images/d879b2a9e47c37caba85c7aea7e287eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/1*uegMZXhpougYk30rzaxsiw.png"/></div></figure><p id="c6f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">跟随一个 N(μ，σ /n)。这里我们可以从中心极限定理看出，当有聚合发生时，方差减少。所以理论上装袋可以提高精确度。Bagging 也使解释变得困难，因为它适合不同引导样本上的多个分类器，并给出和聚集输出。现在让我们讨论另一个叫做 boosting 的系综模型。</p><p id="9371" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">增压</strong></p><p id="8195" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Boosting 是另一种集成建模技术，用于通过将多个分类器组合在一起并基于单个分类器的聚集输出进行预测来提高预测的准确性。那么，为什么我们需要另一个集合模型呢？为了回答这个问题，我们将列出 bagging 算法的一些缺点</p><p id="986a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.在 bagging 中，我们在不同的 bootstrap 样本上拟合多个模型分类器。一些分类器可以准确地对观察值进行分类，而一些分类器不能准确地对观察值进行分类。在 bagging 算法中，无论是好分类器还是坏分类器，所有分类器都被赋予同等的重要性。</p><p id="c20e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.没有给予额外的强调来学习难以分类的观察结果，以便它能够被正确地分类</p><p id="f449" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">升压算法纠正了这些缺点。现在让我们来了解一下 boosting 算法是如何工作的。假设我们有一个包含 6 个观察值的数据集。在 boosting 算法的第一轮中，我们采用概率样本，而 bagging 算法采用引导样本。假设我们在这个数据上安装了两个分类器 C1 和 C2，它们给出了预测值。在增强开始时，对所有观测值分配相等的权重。在这种情况下，分类器 C1 已经正确地预测了 X3、X4 和 X5 的值。而分类器 C2 已经正确地预测了 X2、X3、X4、X5、X6(参考表格)。因此，C2 被证明是一个更好的分类器，因为它正确地分类了大多数观察结果。此外，观察值 X1 是最有问题的观察值，因为没有一个分类器能够正确地对其进行分类。分类器 C3 将其正确分类。在下一轮提升中，被错误分类的观察值的权重增加，而被正确分类的观察值的权重减少。假设分类器 C1、C2、C3 的权重是α1、α2、α3。boosting 算法中的最终预测是预测加权和的符号。升压算法的一些关键点是</p><p id="e386" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.提升算法会认为由分类器 C2 完成的预测是重要的，因为 C2 正确地预测了大多数观察值</p><p id="e175" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.它还认为 C3 是重要的，因为它能够正确地对最有问题的观察结果进行分类(X1)</p><p id="503d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.它使得 C1 的预测变得最不重要，因为它错误地分类了大多数观察结果</p><p id="0e3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.分类器根据其对观察值进行分类的准确程度被划分为重要和不重要</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jx"><img src="../Images/969dec5648bcf155038dba816822499d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MXKByYAKpSMnzsmPsCI6LA.png"/></div></div></figure><p id="3a0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">那么，集合模型总是能提高准确性吗？</strong></p><p id="2987" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们在上面看到的，集合模型的基本目标是减少模型中的方差并提高预测的准确性。那么，你认为集合模型总是能提高我们预测的准确性吗？让我们通过在不同的数据集上实现 bagging 和 boosting 算法来探索这一点，并检查这是否成立。我们将使用 python 来实现这些算法。首先，我们将看到包含 1470 个观察值和 35 个变量的 IBM 流失数据。我们将选择自然减员作为我们的目标变量，因为它是一个二元变量，对于自然减员的员工为是，对于非自然减员的员工为否。一些 x 变量是教育、月收入、总工作年限等。我们在 python 中导入了所有必要的库，读取了数据，分离了 x 和 y 变量，并使用 python 中的 sklearn 库将数据分成训练和测试数据。现在，我们将在训练数据上安装一个决策树分类器，并在测试数据上进行预测。使用 sklearn 软件包生成混淆矩阵，并计算预测的准确性。决策树模型的准确率为 84.80%。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/c3ee416e040cd34dab7e9af92601ae24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*KivGE4YFyn9Mc2FkPS8XYA.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/36938d8268299aa568424d3baaa8bfce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*__vSDtqxrwTmTBNnFAJYwA.png"/></div></figure><p id="8d64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将使用 python 中的 sklearn 包在相同的数据集上使用 bagging 算法。n_estimators 超参数是 bagging 算法在集合模型中使用的树的数量。现在我们用这个来预测我们的产量。在这里，我们可以看到袋装模型的准确性略低于决策树模型(83.90%)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/730daf6e7519c73379ddcd8b215af8c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*4VQd5nF6T5r36RZapg7AcA.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/2bddbe52c9836aeda18f6467d505a678.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*lUJuW7Jc1ppfhlSXgUUWAA.png"/></div></figure><p id="7a5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们在同一个数据集上测试 boosting 算法。我们已经在数据上拟合了 Ada 推进模型。该模型的精度优于 bagging 模型，与个体决策树模型相近。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/c77c5dd60f521e20488444363543072e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*pwFA07vnBZ5P483s-E5BjA.png"/></div></figure><p id="80ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们在一个更小的数据集上实现这些算法。iris 数据集由 150 个观察值和 6 个变量组成，即萼片长度、萼片宽度、花瓣长度、花瓣宽度和由 3 个值组成的花的种类。首先，我们导入 python 中所有必要的库，读取数据并将数据分成训练和测试数据。我们可以在图像中看到数据的快照。我们已经分离出 x 和 y 变量，并对 y 变量使用分层随机抽样，以便在我们的训练和测试数据中有 y 变量的比例值。现在，我们使用 python 中的 Sklearn 包在训练数据上拟合决策树模型，预测测试数据上的值，并生成我们的混淆矩阵来计算我们的模型准确性。决策树分类器能够从 45 个观察值中正确分类 42 个观察值，准确率为 93.33%。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/316f56e00a5c4e51fdf4a59418ae8e74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*z5D84PFTEfU3bK3LY1d_Hg.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/6d6473a24694da055064526f09cb586f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*MAAsXEH2AHQTGqhaT6OZ1A.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/437fb4690d93d6350531c44bd416ae5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*cCRaE6rvPvePXSJIZgBfUw.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/0e0a8e206fd3111eec5e3aa482092342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*jd_Fxu8WwLQxGJds8UmrtA.png"/></div></figure><p id="f042" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们对相同的数据使用 bagging 算法，对测试数据进行预测，并计算模型的准确性。令人惊讶的是，袋装模型的准确性与我们的决策树模型相同！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/1da9ee7cb0135d0a58b1412f195c739b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*-MrGV-ksvFSgNxj8gOtcag.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/1159a5119b0f818937d0260f1e2a6faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*QP1KfYI27u5tQVpuNR3FwQ.png"/></div></figure><p id="c4c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们使用我们的推进算法，看看会发生什么。我们可以在这里看到模型的准确性大幅下降。ada boost 模型的准确率只有 84.4%，而决策树和 bagging 模型的准确率是 93.33%。ada boost 模型仅对第三类的 8 个观察值进行了正确分类，而决策树模型和 bagging 模型能够对第三类的 12 个观察值进行正确分类。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/7467c351d98cee2ac90c4f64a9578120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*ivuai0F2qGH69Gr992IPTA.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jy"><img src="../Images/eccc3f411261514da505e48d7cb87306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*Do4-aUEzLUdHb55TfNGC1Q.png"/></div></figure><p id="b7db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，我们从这个问题开始，集合模型总是能提高准确性吗？从上面的例子中我们可以看出答案是否定的！</p><p id="d04b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结论</strong></p><p id="1eb6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们试图了解为什么我们需要集成模型，以及集成模型如何通过将多个分类器聚合在一起来帮助减少一些模型的方差，从而提高模型预测的准确性。我们探索了两种流行的集合模型:打包和助推。我们学习了这些算法是如何工作的。我们还了解了一种叫做 bootstrapping 的统计抽样技术。我们终于来到了我们试图回答的问题，集合模型总是能提高准确性吗？借助于一些实际例子，我们能够表明集合模型并不总是提高精度。在任何建模练习中，重要的是从简单开始，然后用先进的建模技术即兴创作。如果一个决策树可以对给定的数据集做出充分的预测，那么就没有必要使用集合模型。</p></div></div>    
</body>
</html>