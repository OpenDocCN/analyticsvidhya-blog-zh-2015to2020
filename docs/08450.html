<html>
<head>
<title>Multicollinearity / Ridge / Lasso / Elastic-Net Regression using R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用R的多重共线性/岭/套索/弹性网回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/multicollinearity-ridge-lasso-elastic-net-regression-using-r-6582cbabf7f3?source=collection_archive---------7-----------------------#2020-07-30">https://medium.com/analytics-vidhya/multicollinearity-ridge-lasso-elastic-net-regression-using-r-6582cbabf7f3?source=collection_archive---------7-----------------------#2020-07-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ed0920ccc24af018662ab843c15f88db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MgB3eqwAlLvJKQTg0KcHoA.png"/></div></div></figure><h1 id="7552" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">介绍</h1><p id="8961" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这篇文章是我的<a class="ae km" rel="noopener" href="/@pranjalpandeysta1999/how-to-proceed-from-simple-to-multiple-and-polynomial-regression-in-r-84b77f5673c5?source=friends_link&amp;sk=b15b49da90c1bece7fe935d6dc443135"> <strong class="jq hj">上一篇文章</strong> </a>的延续，在这篇文章中，我向您展示了如何准备多元线性回归，以及如何使用从其诊断图中获得的信息，我们如何进行正交多项式回归，并获得给定数据集(我使用了广告数据集)的更好模型。</p><p id="17ce" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">在上一篇文章中，我创建了正交多项式模型来避免多重共线性问题。但是现在，在本文中<strong class="jq hj">我将首先通过引入预测电视和广播的多项式特征来产生多重共线性问题，然后向您展示如何使用脊、套索和弹性网回归技术来处理这个多重共线性问题</strong>。</p><p id="6c65" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">本文由以下部分组成-</p><ol class=""><li id="fa88" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">加载所需的库</li><li id="69f9" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">加载无异常值数据集</li><li id="e20b" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">(前一篇文章的)摘要</li><li id="5766" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">产生多重共线性问题</li><li id="efe9" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">拟合多项式回归(注:非正交多项式)</li><li id="285c" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">检查假设</li><li id="6333" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">使用多项式回归模型进行预测</li><li id="2384" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">多项式回归模型的平均性能</li><li id="fd64" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">多项式与正交多项式模型的比较</li><li id="0de9" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">为进一步分析准备数据</li><li id="63ea" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">用岭/套索/弹性网回归处理多重共线性</li><li id="2026" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">不同模型的比较(多项式、正交多项式、脊线、套索、弹性网)</li><li id="2100" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">获得最佳模型</li><li id="5522" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">结论</li></ol><p id="73cc" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">我将使用kaggle在线平台进行分析工作。您可以使用任何软件，如R-studio或R-cran版本。</p><h1 id="240e" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">1.加载所需的库</h1><p id="eca9" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">没有必要一开始就加载所有的库，但是我这样做是为了简单。我正在加载另一个库<strong class="jq hj"> glmnet </strong>用于山脊/套索/弹性网回归。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="7ed5" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Loading Libraries</strong><br/>library(tidyverse)<br/>library(caret)<br/>library(car)<br/>library(lmtest)<br/>library(olsrr)<br/>library(glmnet)       <strong class="ll hj"># For Ridge/Lasso/Elastic-Net Regression</strong></span></pre><h1 id="2296" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2.加载无异常值数据集</h1><p id="a609" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">链接下载已经存储在R-objects中的离群值自由数据集-</p><ol class=""><li id="78ce" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated"><a class="ae km" href="https://www.kaggle.com/pranjalpandey12/outlier-free-advertising-data-set/download" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj">数据</strong> </a></li><li id="d4c1" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated"><a class="ae km" href="https://www.kaggle.com/pranjalpandey12/traindata1-and-testdata-for-further-analysis/download" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj">训练数据1和测试数据</strong> </a></li></ol><p id="7aad" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">在我之前的笔记本里。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="8e3c" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Loading Outlier free data set</strong><br/>data = read.csv("../input/outlier-free-advertising-data-set/outlier free advertising data.csv" , header = T)<br/><br/><strong class="ll hj"># Loading outlier free train and test data already splitted in previous notebook</strong><br/>train.data1 &lt;- read.csv("../input/traindata1-and-testdata-for-further-analysis/train.data1.csv", header = T)<br/>test.data &lt;- read.csv("../input/traindata1-and-testdata-for-further-analysis/test.data.csv", header = T)</span></pre><p id="01bb" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">数据集检查- </strong></p><p id="b174" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">看看下面不同的数据集</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="2c2b" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Inspection of data sets</strong><br/>head(data)<br/>head(train.data1)<br/>head(test.data)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/c74de35a199f23c768f274706ee9a097.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zw8ciTNpbAbcqaZsoxyJFg.png"/></div></div></figure><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/651a0d080e4ae7909eb9a42b33b55996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p2LlwTvFb8o3u6yTEKjoBQ.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 1 </strong></figcaption></figure><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="d9fb" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Structure of different data sets</strong><br/>str(data)<br/>str(train.data1)<br/>str(test.data)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/d52204505ba6645f7e018b05ed5d688b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Voun1ZB40QY0JqRrl8Tgrw.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 2 </strong></figcaption></figure><p id="6126" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">注意，这里还出现了报纸变量。我们将在接下来的步骤中删除它，因为该特征在统计上不显著，在之前的笔记本</strong>中已经讨论过。</p><h1 id="0060" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">3.(前一篇文章的)摘要</h1><p id="dee9" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在上一篇文章中，我们得到的更好的模型是<strong class="jq hj">正交多项式模型</strong>，它捕获了目标<strong class="jq hj">销售</strong>的平均93.69% 可变性的<strong class="jq hj">。正交多项式模型的训练、测试和交叉验证结果如下表所示</strong></p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/1900e450e2cac6ac35fc808390f725d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VGvwlPv6CJrm1X3azB8J2A.png"/></div></div></figure><p id="d249" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，在这篇文章中，我将向您展示<strong class="jq hj">多项式回归模型</strong>(注意:非正交)的结果以及解决这个问题的方法。</p><h1 id="ae17" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">4.产生多重共线性问题</h1><p id="1b70" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在让我们在数据集中创建预测电视和广播的多项式特征。在我们之前的笔记中，我们已经看到，高达二阶的预测值TV和三阶的预测值Radio具有统计学意义。因此，创建以下多项式特征-</p><ol class=""><li id="3b07" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated"><strong class="jq hj">预测值TV的二阶</strong></li><li id="5a94" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated"><strong class="jq hj">二阶和三阶预测比值</strong></li></ol><p id="b5b0" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">另外，为了简单起见，在数据集中创建一列电视和广播的交互效果。否则，我们将不得不在函数<strong class="jq hj"> lm() </strong>中单独提及这种交互效应。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="bb9f" class="lp ir hi ll b fi lq lr l ls lt"><em class="mc"># Creating Polynomial Features in R-object data</em><br/>data["TV2"]&lt;- (data$TV)^2<br/>data["Radio2"]&lt;- (data$Radio)^2<br/>data["Radio3"]&lt;- (data$Radio)^3<br/>data["TVRadio"]&lt;- (data$TV)*(data$Radio)<br/><em class="mc"># Removing Newspaper Column as it is Statistically non-significant already discussed in previous notebook</em><br/>data &lt;- data[-3]<br/><br/><br/><em class="mc"># Creating Polynomial Features in R-object train.data1</em><br/>train.data1["TV2"]&lt;- (train.data1$TV)^2<br/>train.data1["Radio2"]&lt;- (train.data1$Radio)^2<br/>train.data1["Radio3"]&lt;- (train.data1$Radio)^3<br/>train.data1["TVRadio"]&lt;- (train.data1$TV)*(train.data1$Radio)<br/><em class="mc"># Removing Newspaper Column </em><br/>train.data1 &lt;- train.data1[-3]<br/><br/><br/><em class="mc"># Creating Polynomial Features in R-object test.data</em><br/>test.data["TV2"]&lt;- (test.data$TV)^2<br/>test.data["Radio2"]&lt;- (test.data$Radio)^2<br/>test.data["Radio3"]&lt;- (test.data$Radio)^3<br/>test.data["TVRadio"]&lt;- (test.data$TV)*(test.data$Radio)<br/><em class="mc"># Removing Newspaper Column </em><br/>test.data &lt;- test.data[-3]</span></pre><p id="1698" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">再次检查数据集- </strong></p><p id="445b" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">再看一下不同的数据集，如下所示</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="c137" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Inspection of data sets</strong><br/>head(data)<br/>head(train.data1)<br/>head(test.data)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/ef51cfd178ac0976179de06027676303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n1S9VJhCXZGKTF6w7ke1Ug.png"/></div></div></figure><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/b8858c19ab4b53c3cd0c1b2142814df8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dqTKI41WTQM9bYh8w_73UA.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 3 </strong></figcaption></figure><p id="e652" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">电视和广播的所有多项式特性和交互作用已成功添加到不同的数据集中。</strong></p><h1 id="9283" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">5.拟合多项式回归(注:非正交多项式)</h1><p id="1e38" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">因为，我们已经在数据集中存储了电视和广播的多项式特征和交互项。因此，我们将仅使用拟合多元线性回归的代码来拟合多项式模型，使用存储在R-object <strong class="jq hj"> train.data1 </strong>中的训练数据集，如下所示-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="fce3" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Fitting Polynomial model (Note : It is not Orthogonal Polynomial)</strong><br/>polynomial_model &lt;- lm(Sales ~ ., data = train.data1)<br/><br/><strong class="ll hj"># Take a look on summary of the model</strong><br/>summary(polynomial_model)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/b5351ad14434db5d4e0a2228d77a2531.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GORs7O_EAC5tOULMNKJh4A.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 4 </strong></figcaption></figure><p id="50ad" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">以上输出显示- </strong></p><ol class=""><li id="35ff" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">由于p值&lt;&lt;&lt; 0.05 (see in the last line of output)</li><li id="f3cc" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">From the coefficients section, it is clear that all coefficients are statistically significant since p-value &lt;&lt;&lt; 0.05</li><li id="bd9c" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">This polynomial model explains 93.21% variability of target (Sales).</li><li id="4d47" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">Residual standard error for the model is 1.347</li></ol><h1 id="6f45" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">6. Checking Assumptions</h1><p id="ebcd" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">Let’s check whether all assumptions of linear regression are satisfied.</p><p id="a32c" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">线性假设- </strong>，创建的多项式模型具有统计显著性</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="db9d" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Residual Plot</strong><br/>plot(polynomial_model,1)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/999faa689a0e26ad1360f67a39bb5593.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*phE5uv5uRBm4NRh3qQZLjA.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 5 </strong></figcaption></figure><p id="2a9e" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">正态假设- </strong></p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="2d76" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Normality Test of Errors</strong><br/>shapiro.test(polynomial_model$residuals)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/6b3c5b4c6039301625e3a0c330a588ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*USIvfJ61F5238dfUJw2gaQ.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 6 </strong></figcaption></figure><p id="a4e7" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">同方差假设- </strong></p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="1a0e" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Hetroscedasticity Test</strong><br/>ols_test_score(polynomial_model)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/3e311e01e5ee5a4179ac2ebbe4d1f6c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mws16J4X41V1zyWWFiI9_A.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 7 </strong></figcaption></figure><p id="e563" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">自相关假设- </strong></p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="ad61" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Auto-correlation Test</strong><br/>durbinWatsonTest(polynomial_model)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/e984e53cb8c2a3d6c73a9c2b42a0e17b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G9ZM0GFZbFNdBdjImJG1zw.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 8 </strong></figcaption></figure><p id="df1b" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">多重共线性假设- </strong></p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="afb9" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Detecting Multicollinearity </strong><br/>vif(polynomial_model)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/bf1b08aa74fe1f41ec487ffa9e3b46fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PH4OlQcSprJk5njv_tAAwQ.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 9 </strong></figcaption></figure><p id="002f" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">从上面的输出可以清楚地看出，除了多重共线性之外，所有的假设都得到了满足。所以我们要处理多重共线性问题。我们将在几步之后处理它。</p><blockquote class="mi mj mk"><p id="ac10" class="jo jp mc jq b jr kn jt ju jv ko jx jy ml kp kb kc mm kq kf kg mn kr kj kk kl hb bi translated">如果你不知道如何解读上述结果，只需阅读我的<a class="ae km" rel="noopener" href="/@pranjalpandeysta1999/how-to-proceed-from-simple-to-multiple-and-polynomial-regression-in-r-84b77f5673c5?source=friends_link&amp;sk=b15b49da90c1bece7fe935d6dc443135"> <strong class="jq hj">上一篇</strong> </a>。我已经详细讨论过了。</p></blockquote><h1 id="b993" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">7.使用多项式回归模型进行预测</h1><p id="fc3c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在，用这个模型在测试数据集上做预测，看看它在看不见的数据集上效果如何。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="ab3d" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Making predictions using Polynomial model</strong><br/>prediction = polynomial_model %&gt;% predict(test.data)<br/><br/><strong class="ll hj"># Checking performance by calculating R2, RMSE and MAE</strong><br/>data.frame( R2 = R2(prediction, test.data$Sales),<br/>            RMSE = RMSE(prediction, test.data$Sales),          <br/>            MAE = MAE(prediction, test.data$Sales))</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/d1cf3229bf4308741fe4a8ce7898a537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2oxPHklWxNzK7ibELoiAcw.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 10 </strong></figcaption></figure><p id="7427" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">我们得到:R = 0.9526385，这表明更好的拟合。</p><h1 id="813a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">8.多项式回归模型的平均性能</h1><p id="d0ab" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">因为，上述结果仅基于一个测试数据集。因此，我们不能确定该模型对所有未知数据都有更好的表现。为了在这方面更有把握，我们将使用重复10重交叉验证的方法在不同的测试数据集上测试模型的性能。</p><p id="c65a" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">这将按如下方式进行</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="8138" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Repeated 10-fold Cross validation using polynomial model</strong><br/>set.seed(123)<br/>train.control &lt;- trainControl(method = "repeatedcv", number = 10, repeats = 3)<br/>                              <br/><strong class="ll hj"># Train the model</strong><br/>poly_model_cv &lt;- train(Sales ~ ., data = data, method = "lm", trControl = train.control)<br/>                  <br/><strong class="ll hj"># Summarize the results</strong><br/>print(poly_model_cv)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/ba7a25326b139a0270a0d97aceed6748.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IsWRH4eJlLJiAgFm3SXGPg.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 11 </strong></figcaption></figure><p id="0421" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">平均而言，这个多项式回归模型捕捉了目标(销售)中93.69%的可变性。</strong></p><h1 id="eb17" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">9.多项式与正交多项式模型的比较</h1><p id="ffe5" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">根据R和RMSE指标对两个模型进行比较，如下所示-</p><p id="a52e" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">下表给出了多项式和正交多项式回归模型的训练、测试和交叉验证结果</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/2fb1d8f75b66dfd076836cf484069d75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*__2raM22qvb2u-noMO28Fw.png"/></div></div></figure><p id="d88f" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">上表显示两种型号的<strong class="jq hj">性能相同</strong>。</p><p id="c4bb" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">但是请看下表——</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/81c80c4e6929b6693a3e9a081aaad87a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AKjSt6jvux4XaeP7y_2gBw.png"/></div></div></figure><p id="2d97" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">上表显示<strong class="jq hj">多重共线性假设被多项式回归模型</strong>违反。</p><p id="5af5" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">因此，有必要处理多重共线性。</p><h1 id="cddc" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">10.为进一步分析准备数据</h1><p id="807c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在，我们将处理多重共线性问题，但在此之前，我们必须准备我们的数据集，以供进一步分析。我们将使用<strong class="jq hj"> glmnet </strong>库，其中<strong class="jq hj">以矩阵形式</strong>分别要求预测器和目标。因此，只需将预测值和目标值分开，并将其转换成矩阵形式，如下所示-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="5bf2" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Storing Predictors and Target in Matrix form (train data set)</strong><br/>x_train &lt;- train.data1 %&gt;% select(-Sales) %&gt;% as.matrix()<br/>y_train &lt;- train.data1  %&gt;% select(Sales) %&gt;%  as.matrix()<br/><br/><strong class="ll hj"># Storing Predictors and Target in Matrix form (test data set)</strong><br/>x_test &lt;- test.data %&gt;% select(-Sales) %&gt;% as.matrix()<br/>y_test &lt;- test.data %&gt;% select(Sales) %&gt;% as.matrix()</span></pre><h1 id="c52c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">11.用岭/套索/弹性网回归处理多重共线性</h1><p id="3533" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">基本上，有三种方法可以处理多重共线性问题-</p><ol class=""><li id="9e5e" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated"><strong class="jq hj">岭回归</strong></li><li id="5514" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated"><strong class="jq hj">套索回归</strong></li><li id="c7db" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated"><strong class="jq hj">弹性网回归</strong></li></ol><p id="2fa1" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">岭回归和套索回归是弹性网回归的特例。弹性网回归中有两个超参数，名为-</p><ol class=""><li id="7ecc" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated"><strong class="jq hj">α</strong>—俗称<strong class="jq hj">混合参数</strong>。</li><li id="8f5c" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated"><strong class="jq hj">λ</strong>——它被称为<strong class="jq hj">正则化罚</strong>。</li></ol><p id="3ce4" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">找出这些超参数的最佳值是我们的职责。为此，我们使用交叉验证方法。我们将在稍后阶段看到它。</p><p id="186e" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">这些超参数的范围-</p><ol class=""><li id="ee6c" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">α位于0到1的封闭区间内</li><li id="1c0d" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">λ介于0到无穷大之间。</li></ol><p id="b552" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">还有三点需要记住-</p><ol class=""><li id="de98" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">对于<strong class="jq hj">岭</strong>回归:<strong class="jq hj">α= 0</strong>，λ可以取其范围内的任何值</li><li id="144f" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">对于<strong class="jq hj"> Lasso </strong>回归:<strong class="jq hj"> alpha = 1 </strong>，Lambda可以取其范围内的任何值</li><li id="282c" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">对于<strong class="jq hj">弹性网</strong>回归:<strong class="jq hj">α位于0和1 </strong>之间，λ可以取其范围内的任何值</li></ol><p id="ab7a" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，我将找出这三种方法中哪一种对给定的广告数据集表现最好。</p><h1 id="5cd6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">岭回归拟合</h1><p id="7bab" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在岭回归的情况下，超参数(即α)的值是固定的。我们的目的是找出λ的最佳值。为此，我们使用交叉验证方法，交叉验证的评价标准将是均方误差。</p><p id="8a3a" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">用于上述目的的r代码如下-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="d30e" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Cross Validation for obtaining best value of lambda for ridge regression (alpha = 0)</strong><br/>cv_for_best_lambda &lt;-  cv.glmnet(x_train, y_train, family = "gaussian", alpha = 0, type.measure = "mse")</span></pre><p id="5c6a" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">对于alpha = 0，上述代码使用训练数据集执行10重(默认)交叉验证，并给出lambda的最佳值。</p><p id="6c1a" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">按如下方式检查λ值-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="ab17" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Checking best value of lambda</strong><br/>print(cv_for_best_lambda)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/ec605191bda4d9a567e14be26fda76c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FuQSMl7o4BX1BOi1-Qa61g.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 12 </strong></figcaption></figure><p id="28b5" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">注意上面的输出- </strong></p><ol class=""><li id="3123" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">最后两行输出中有两个λ值(<strong class="jq hj"> 0.4638 </strong>和<strong class="jq hj"> 0.6729 </strong>)。我将取值<strong class="jq hj"> 0.4638 </strong>，因为<strong class="jq hj"> MSE是该值的最小值(2.573) </strong>。<strong class="jq hj">为什么是这两个值？这两个值用于不同的情况。当我们拟合套索回归时，你会更清楚这一点。但是规则是<strong class="jq hj">选择MSE最小的λ值</strong>。</strong></li><li id="71c7" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">上述输出的最后一列显示，对于λ的两个值，模型中有6个非零系数，我们的数据集中也有6个预测值。这意味着所有的预测因子对于岭回归都是重要的。</li></ol><blockquote class="mi mj mk"><p id="c2c7" class="jo jp mc jq b jr kn jt ju jv ko jx jy ml kp kb kc mm kq kf kg mn kr kj kk kl hb bi translated"><em class="hi">实际上，这些方法(脊/套索/弹性网)也用于选择最佳预测值。在这种情况下，上述输出的最后一列起着非常重要的作用。那个时候，我并不倾向于功能选择。只关注多重共线性问题。</em></p></blockquote><p id="fbbd" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，将λ的最佳值，即<strong class="jq hj"> 0.4638 </strong>存储在R-object <strong class="jq hj"> best_lambda </strong>中，如下所示-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="7d86" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Storing best value of lambda in a R-object best_lambda</strong><br/>best_lambda = cv_for_best_lambda$lambda.min</span></pre><p id="7341" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，拟合岭回归模型，并检查其对训练数据集的性能，如下所示-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="63e5" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Fitting Ridge Regression Model</strong><br/>ridge = glmnet(x_train, y_train, family = "gaussian",alpha = 0, lambda = best_lambda)<br/><br/><strong class="ll hj"># Checking its performance on train data set</strong><br/>predict_train &lt;- ridge %&gt;% predict(x_train)<br/>data.frame( R2 = R2(predict_train, y_train),<br/>            RMSE = RMSE(predict_train, y_train),<br/>            MAE = MAE(predict_train, y_train))</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/24ce72c8867037c2c85f927bd59a7f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ckpjqasQdRhEWh04EwtRPQ.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 13 </strong></figcaption></figure><p id="66fd" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">从上面的输出，我们得到的是——</strong></p><ol class=""><li id="4f4a" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">调整后的R =约90.9%。</li><li id="7d20" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">RMSE = 1.5585</li></ol><p id="789f" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，检查它在看不见的数据上的表现如下-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="48b4" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Checking performance of Ridge regression on test data set</strong><br/>predict_test &lt;- ridge %&gt;% predict(x_test)<br/>data.frame( R2 = R2(predict_test, y_test),<br/>            RMSE = RMSE(predict_test, y_test),<br/>            MAE = MAE(predict_test, y_test))</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/ea9a7bb2b2692aa4a2a6ff9f3456fbdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KGT_XatcFHm1Y1XQkdcLHw.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 14 </strong></figcaption></figure><p id="4618" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">那么，我们得到:<strong class="jq hj"> R = 0.9526385 </strong>和<strong class="jq hj"> RMSE = 1.4779 </strong></p><p id="a573" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">为了对其在未知数据上的表现更有信心，使用重复的K-fold交叉验证计算岭回归的平均表现如下-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="fc82" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Repeated 10-fold cross validation for average performance of Ridge Regression</strong><br/>set.seed(123)<br/>train.control &lt;- trainControl(method = "repeatedcv", number = 10, repeats = 3)<br/>                              <br/><strong class="ll hj"># Train the model</strong><br/>Ridge_model_cv &lt;- train(Sales ~ ., data = data, method="glmnet", trControl = train.control, tuneGrid = expand.grid(alpha = 0, lambda = best_lambda))<br/>                  <br/><strong class="ll hj"># Summarize the results</strong><br/>print(Ridge_model_cv)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mr"><img src="../Images/0394c747d3288a3b0d859598e6c08c9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*50GOhTlbMmOsBavjxbDztQ.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 15 </strong></figcaption></figure><p id="5fae" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">平均而言，岭回归模型捕捉了目标(销售)中91.34%的可变性，该模型的RMSE为1.538825 </strong></p><p id="5f9b" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">这表明<strong class="jq hj">岭回归并没有比多项式/正交多项式模型</strong>表现得更好。</p><p id="3788" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">就此打住，进行套索回归拟合。</p><h1 id="c7b2" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">套索回归拟合</h1><p id="754d" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在套索回归的情况下，超参数的值，即α是固定的。我们的目的是找出λ的最佳值。为此，我们再次使用交叉验证的方法和评价标准，交叉验证将均方误差。</p><p id="a18b" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">用于上述目的的r代码如下-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="865a" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Cross Validation for obtaining best value of lambda for lasso regression (alpha = 1)</strong><br/>cv_for_best_lambda &lt;-  cv.glmnet(x_train, y_train, family = "gaussian", alpha = 1, type.measure = "mse")</span></pre><p id="7ee6" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">对于alpha = 1，上述代码使用训练数据集执行10重(默认)交叉验证，并给出lambda的最佳值。</p><p id="9035" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">按如下方式检查λ值-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="4466" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Checking best value of lambda</strong><br/>print(cv_for_best_lambda)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/e1bd95c3aa0366191243fdc355cf6002.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CdctYS6eUbV6NoZH_8bObQ.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 16 </strong></figcaption></figure><p id="8f20" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">请注意，在上面的输出中- </strong></p><ol class=""><li id="0c55" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">在最后两行输出中有两个lambda值(0.00187和0.04859)。我将取值0.00187，因为MSE是该值的最小值(1.916)。另见最后一列的值，即<strong class="jq hj"> 6 </strong>表示<strong class="jq hj">所有预测值都是重要的</strong>。</li><li id="5407" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">上述输出的最后一行和最后一列中的值，即<strong class="jq hj"> 4 </strong>表示，如果我们只包括四个预测值，则λ值= 0.04859，但是我们不选择这个λ值，因为这种情况下的MSE略高于前一个λ值(0.00187)。</li></ol><blockquote class="mi mj mk"><p id="10d8" class="jo jp mc jq b jr kn jt ju jv ko jx jy ml kp kb kc mm kq kf kg mn kr kj kk kl hb bi translated"><em class="hi">有时，包含较少数量的预测值可能会提供最小的MSE。在这种情况下，我们选择λ的第二个值，但这不是我们的情况。正如我之前所说，这些方法(脊/套索/弹性网)也用于预测选择。</em></p><p id="6425" class="jo jp mc jq b jr kn jt ju jv ko jx jy ml kp kb kc mm kq kf kg mn kr kj kk kl hb bi translated"><em class="hi">但是在我们的例子中，这些方法只处理多重共线性问题，正如我们在上面的输出中看到的，如果我们只包括四个预测值，那么λ的值= 0.04859，但是我们不选择这个λ值，因为在这种情况下MSE略高于之前的λ值(0.00187) </em></p></blockquote><p id="b794" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，在R-object best_lambda中存储lambda的最佳值，即0.00187，如下所示-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="a88d" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Storing best value of lambda in a R-object best_lambda</strong><br/>best_lambda = cv_for_best_lambda$lambda.min</span></pre><p id="ae7d" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，拟合Lasso回归模型，并检查其在如下训练数据集上的性能-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="2030" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Fitting Lasso Regression Model</strong><br/>lasso = glmnet(x_train, y_train, family = "gaussian", alpha = 1, lambda = best_lambda)<br/><br/><strong class="ll hj"># Checking its performance on train data set</strong><br/>predict_train &lt;- lasso %&gt;% predict(x_train)<br/>data.frame( R2 = R2(predict_train, y_train),<br/>            RMSE = RMSE(predict_train, y_train),<br/>            MAE = MAE(predict_train, y_train))</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ms"><img src="../Images/0d4de4b330af271d8d1497012cb2c561.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OP1FylflKMPgu66R4XMLaQ.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 17 </strong></figcaption></figure><p id="c5ef" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">从上面的输出，我们得到的是——</strong></p><ol class=""><li id="dfd3" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">调整后的R =约93.43%。</li><li id="301c" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">RMSE = 1.319708</li></ol><p id="729c" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，检查它在看不见的数据上的表现如下-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="d688" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Checking performance of Lasso regression on test data set</strong><br/>predict_test &lt;- lasso %&gt;% predict(x_test)<br/>data.frame( R2 = R2(predict_test, y_test),<br/>            RMSE = RMSE(predict_test, y_test),<br/>            MAE = MAE(predict_test, y_test))</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/665649278ca0dcc856f9a01fb80bdc0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u-X126zTMxY5mU8KMfQXrQ.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 18 </strong></figcaption></figure><p id="22f4" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">那么，我们得到:<strong class="jq hj"> R = 0.954106 </strong>和<strong class="jq hj"> RMSE = 1.131341 </strong></p><p id="126c" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">为了更有信心，关于它在看不见的数据上的表现，使用重复的K-fold交叉验证计算Lasso回归的平均表现如下-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="493f" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Repeated 10-fold cross validation for average performance of Lasso Regression</strong><br/>set.seed(123)<br/>train.control &lt;- trainControl(method = "repeatedcv", number = 10, repeats = 3)<br/>                              <br/><strong class="ll hj"># Train the model</strong><br/>Lasso_model_cv &lt;- train(Sales ~ ., data = data, method="glmnet", trControl = train.control, tuneGrid = expand.grid(alpha = 1, lambda = best_lambda))<br/>                  <br/><strong class="ll hj"># Summarize the results</strong><br/>print(Lasso_model_cv)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mr"><img src="../Images/55c2f090c1bfa9d7cbcbc42985a849a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yu4IZ2HYt5AEEmh1fDkv4Q.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 19 </strong></figcaption></figure><p id="485c" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">平均而言，Lasso回归模型捕获了目标(销售)中93.58%的可变性，该模型的RMSE为1.304869 </strong></p><p id="0d9f" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">这表明<strong class="jq hj"> Lasso回归比岭回归模型表现更好(捕获了91.34%的可变性)</strong>。</p><p id="58c3" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">就此打住，进行弹性网回归拟合。</p><h1 id="4d76" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">弹性网回归拟合</h1><p id="5afc" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在弹性网回归的情况下，两个超参数的值都是未知的。我们的目标是找出α和λ的最佳值。为此，我们再次使用交叉验证方法。在这里，这种方法以不同的方式使用。因此，看到并注意到在这种情况下使用的代码和在以前的情况下(脊/套索)的区别</p><p id="1490" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">用于上述目的的r代码如下-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="9b2f" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Cross Validation for obtaining best value of alpha and lambda for elasticnet regression </strong><br/><br/><strong class="ll hj"># Define Training Control</strong><br/>set.seed(123)<br/>train.control &lt;- trainControl(method = "repeatedcv", number = 10, repeats = 3 , <strong class="ll hj">search = "random"</strong>)<br/>                              <br/><strong class="ll hj"># Train the model</strong><br/>cv_for_best_value &lt;- train(Sales ~ ., data = train.data1, method="glmnet", trControl = train.control)<br/>                  <br/><br/><strong class="ll hj"># Obtaining Best Value of alpha and lambda</strong><br/>cv_for_best_value$bestTune</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/875456940e7a57b83d2b9a2a3b34d295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WtdIdJzTosoP4t4iLMQLnw.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 20 </strong></figcaption></figure><p id="37a9" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">以上输出给出了α和λ的最佳值。</strong>我们将在弹性网回归拟合中使用这些值。</p><p id="14c6" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，拟合弹性网回归模型，并检查其在如下训练数据集上的性能-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="3aa9" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Fitting Elasticnet Regression Model</strong><br/>enet &lt;- glmnet(x_train, y_train, alpha = 0.4089769, lambda = 0.001472246 ,family = "gaussian")<br/><br/><strong class="ll hj"># Checking its performance on train data set</strong><br/>predict_train &lt;- enet %&gt;% predict(x_train)<br/>data.frame( R2 = R2(predict_train, y_train),<br/>            RMSE = RMSE(predict_train, y_train),<br/>            MAE = MAE(predict_train, y_train))</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/8d288134f31b77ba4e3735f6933e02f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EyXFVhgFe2hyA6S23H8D3Q.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 21 </strong></figcaption></figure><p id="0258" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">从上面的输出中，我们得到了——</strong></p><ol class=""><li id="8fd9" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">调整后的R =约93.46%。</li><li id="d8a6" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">RMSE = 1.317211</li></ol><p id="0157" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，检查它在看不见的数据上的表现如下-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="ff7f" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Checking performance of Elasticnet regression on test data set</strong><br/>predict_test &lt;- enet %&gt;% predict(x_test)<br/>data.frame( R2 = R2(predict_test, y_test),<br/>            RMSE = RMSE(predict_test, y_test),<br/>            MAE = MAE(predict_test, y_test))</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/8f66b13ec39290495f58f1f923febf16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FsH8ZAm5ATiLWtfNRgZ6fw.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 22 </strong></figcaption></figure><p id="8476" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">那么，我们得到:<strong class="jq hj"> R = 0.9538105 </strong>和<strong class="jq hj"> RMSE = 1.134862 </strong></p><p id="1459" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">为了更有把握地了解其在未知数据上的表现，使用重复的K-fold交叉验证来计算弹性网回归的平均表现，如下所示</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="56cd" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Repeated 10-fold cross validation for average performance of Elastic-Net Regression</strong><br/><br/><strong class="ll hj"># Define Training control</strong><br/>set.seed(123)<br/>train.control &lt;- trainControl(method = "repeatedcv", number = 10, repeats = 3)<br/>                              <br/><strong class="ll hj"># Train the model</strong><br/>Elasticnet_model_cv &lt;- train(Sales ~ ., data = data, method="glmnet", trControl = train.control, <strong class="ll hj">tuneGrid = expand.grid(alpha = 0.4089769, lambda = 0.001472246)</strong>)<br/>                  <br/><strong class="ll hj"># Summarize the results</strong><br/>print(Elasticnet_model_cv)</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/733825ee1b70f6efaba816a862c152da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHcXCDK7drDNNPk7Geacsw.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 23 </strong></figcaption></figure><h1 id="baa9" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">伟大的结果！</h1><p id="00b9" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><strong class="jq hj">平均而言，弹性净回归模型捕捉了目标(销售)中93.66%的可变性，该模型的RMSE为1.297969 </strong></p><p id="9901" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">这表明<strong class="jq hj">弹性网回归比岭和套索回归模型</strong>表现更好。</p><h1 id="a504" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">12.不同模型的比较(多项式、正交多项式、脊线、套索、弹性网)</h1><p id="3fc1" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在，是时候比较不同的模式，并获得最好的一个。</p><p id="3f76" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">下表包含所有先前安装的模型的训练、测试和交叉验证结果-</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mv"><img src="../Images/040b8a5964751451d22980eb2e0d6bc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hjsqW_v5ag1QFAiggIMWFg.png"/></div></div></figure><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mw"><img src="../Images/e4d735101bbc6c8b76f62ce960cab83c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uDmLxl_j-EUec0OJFU3RCw.png"/></div></div></figure><p id="d603" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">上表的结果- </strong></p><ol class=""><li id="6036" class="ks kt hi jq b jr kn jv ko jz ku kd kv kh kw kl kx ky kz la bi translated">正交多项式和多项式模型具有相同的性能，因为这两种模型的R和RMSE值相同。</li><li id="b2e5" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">弹性网回归比岭/套索回归表现更好，因为弹性网回归的R值最大，RMSE最小。</li><li id="347f" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">弹性网回归的表现也优于多项式/正交多项式模型，因为弹性网的RMSE最小(1.297969)。</li><li id="85a8" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">还要注意，Lasso回归在测试数据集上比其他模型表现更好，但因为这个结果只基于一个数据集。因此，我们不能确定它是否也适用于其他看不见的数据，这就是为什么我们使用交叉验证来计算平均性能，并得出Lasso并不比给定数据集的Elastic-Net更好。</li><li id="0850" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">到目前为止，<strong class="jq hj">弹性网回归模型是给定广告数据集的最佳模型，平均捕获93.7%的目标(销售)可变性，RMSE = 1.297969 </strong></li></ol><h1 id="733a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">13.获得最佳模型</h1><p id="a6a5" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">最后，我们得到<strong class="jq hj">弹性网回归对于给定的广告数据集表现良好</strong>。那么，<strong class="jq hj">这个模型的方程式是什么？</strong>为此，我们必须获得回归系数的值。</p><p id="c3ee" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">用于上述目的的r代码如下-</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="d498" class="lp ir hi ll b fi lq lr l ls lt"><strong class="ll hj"># Obtaining Coefficients of Elastic-Net Regression Model</strong><br/>enet$beta</span></pre><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/26999afbddd9799b779d24b75df079dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cs7EsjkC68r7zogL3vz-kA.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd is">输出— 24 </strong></figcaption></figure><p id="bb9c" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">因此，弹性网回归模型是- </strong></p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/227f56b74702bf576423b60088bc3cb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ISGZlxd1wQcvbdvyuPlrYg.png"/></div></div></figure><h1 id="9e0d" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">14.结论</h1><p id="0b43" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">最后，我想在这里总结一下，在这本笔记本中，<strong class="jq hj">我从多项式模型的拟合开始，然后向您展示了多项式模型违反了多重共线性假设，为了解决这个问题，我们有三种不同的方法，分别是岭、套索和弹性网回归。我已经向您详细展示了如何拟合这些模型，如何获得这些模型的超参数的最佳值，最后我提到了最佳回归模型，即针对给定广告数据集的弹性网回归</strong>。</p><p id="9ca7" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">仅此而已。</p><p id="ebba" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">自己做一次就更好理解了！</strong></p><p id="7842" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">我的kaggle笔记本<a class="ae km" href="https://www.kaggle.com/pranjalpandey12/multicolinearity-ridge-lasso-elasticnet-regression" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj">链接</strong> </a>。</p><h1 id="65d8" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">感谢阅读我的文章。</h1><p id="44c6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">如果你发现任何错误，请告诉我。</p></div></div>    
</body>
</html>