<html>
<head>
<title>Packaging your Pytorch Model using MLflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用MLflow打包Pytorch模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/packaging-your-pytorch-model-using-mlflow-894d62dd8d3?source=collection_archive---------4-----------------------#2020-05-20">https://medium.com/analytics-vidhya/packaging-your-pytorch-model-using-mlflow-894d62dd8d3?source=collection_archive---------4-----------------------#2020-05-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/e47cb60510ff8c6f9847b49323933e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*C0_F8T1rbo-dFSRI_2wy_A.png"/></div></figure><p id="4cb1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">大多数机器学习项目始于研究环境；通常是一个笔记本，数据科学家在这里收集数据、开发功能、训练和验证模型。最终产品通常是数据预处理代码、机器学习代码、环境依赖、配置文件等的混合。然后，数据科学家转向工程团队，打包他们的代码，并为生产环境做好准备。在这个过程中，更具挑战性的是工程团队在生产环境中精确复制模型的能力。即，给定两种环境中相同的原始输入数据，我们在两种环境中得到相同的输出。</p><p id="78b7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jk" href="https://www.mlflow.org/" rel="noopener ugc nofollow" target="_blank"> MLflow </a>是一个管理端到端机器学习生命周期的开源平台。围绕MLflow有四大支柱:<a class="ae jk" href="https://www.mlflow.org/docs/latest/tracking.html" rel="noopener ugc nofollow" target="_blank"> MLflow跟踪</a>、<a class="ae jk" href="https://www.mlflow.org/docs/latest/projects.html" rel="noopener ugc nofollow" target="_blank"> MLflow项目</a>、<a class="ae jk" href="https://www.mlflow.org/docs/latest/models.html" rel="noopener ugc nofollow" target="_blank"> MLflow模型</a>、<a class="ae jk" href="https://www.mlflow.org/docs/latest/model-registry.html" rel="noopener ugc nofollow" target="_blank"> MLflow注册表</a>。在这个项目中，我使用MLflow模型。MLflow Models定义了一种打包机器学习模型的标准格式，可用于各种下游工具，如通过REST API的实时服务或Apache Spark上的批处理推理。</p><p id="ed70" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本文中，我将在Pytorch中构建一个文本分类模型，并使用MLflow模型对其进行打包。这个帖子包含以下内容:</p><ol class=""><li id="05ca" class="jl jm hi io b ip iq it iu ix jn jb jo jf jp jj jq jr js jt bi translated">使用预训练单词嵌入的文本预处理。</li><li id="da3d" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">模型定义。</li><li id="a26f" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">模特培训。</li><li id="8d9c" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">使用MLflow进行模型打包。</li></ol><p id="e159" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">使用预训练单词嵌入的文本预处理</strong></p><p id="4802" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">每种机器学习算法都与数字打交道。为了使用文本数据作为特征，我们需要将语料库中的每种单词类型转换成某种数字表示。传统的自然语言处理方法大多基于字数统计技术，通常将字符转换为小写，删除标点符号，删除符号或特殊字符，对标记执行词干分析或词汇化。当使用预先训练的嵌入时，最终模型的质量取决于我们的语料库的词汇与嵌入的词汇的匹配程度。我正在使用GloVe嵌入，更具体地说是<a class="ae jk" href="http://nlp.stanford.edu/data/glove.840B.300d.zip" rel="noopener ugc nofollow" target="_blank"> glove.840B.300d.zip </a>，我不会将我的语料库中的字符转换成小写，因为我的嵌入处理字母大小写标记。我通过执行以下操作来清理语料库:</p><ol class=""><li id="463a" class="jl jm hi io b ip iq it iu ix jn jb jo jf jp jj jq jr js jt bi translated">删除嵌入中没有出现的所有字符符号。符号是一种字符，它不是ASCII字符、整数或下面列出的任何拉丁字符，包括空格。</li><li id="c18e" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">使用<a class="ae jk" href="https://kite.com/python/docs/nltk.TreebankWordTokenizer" rel="noopener ugc nofollow" target="_blank"> TreebankTokenizer </a>处理收缩。</li><li id="2de6" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">移除标记开头的撇号。</li></ol><figure class="jz ka kb kc fd ij"><div class="bz dy l di"><div class="kd ke l"/></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">文本预处理:删除符号</figcaption></figure><figure class="jz ka kb kc fd ij"><div class="bz dy l di"><div class="kd ke l"/></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">文本预处理:处理缩写。</figcaption></figure><figure class="jz ka kb kc fd ij"><div class="bz dy l di"><div class="kd ke l"/></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">文本预处理:删除撇号。</figcaption></figure><p id="2058" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">清理完语料库后，我使用Keras Tokenizer对语料库进行标记，以构建我们的语料库的词汇，构建嵌入矩阵，将文本标记转换为索引序列，填充或截断序列以具有相同的长度。</p><figure class="jz ka kb kc fd ij"><div class="bz dy l di"><div class="kd ke l"/></div></figure><h2 id="1915" class="kj kk hi bd kl km kn ko kp kq kr ks kt ix ku kv kw jb kx ky kz jf la lb lc ld bi translated"><strong class="ak">模型定义</strong></h2><p id="e023" class="pw-post-body-paragraph im in hi io b ip le ir is it lf iv iw ix lg iz ja jb lh jd je jf li jh ji jj hb bi translated">为了训练模型，我使用了一种特殊的递归神经网络(RNNs)，称为长短期记忆网络(LSTMs)。LSTMs解决了传统RNNs中遇到的长相关性和消失梯度问题。LSTMs模块包含控制信息流的交互层。它们维持一个单元状态，并使用称为门的结构，在那里信息被添加到单元状态或从单元状态移除。更重要的是，它们通过遗忘门遗忘之前状态的不相关部分，通过更新门选择性地更新状态值，通过输出门选择性地输出单元状态的某些部分。我使用两层双向LSTM。</p><figure class="jz ka kb kc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lj"><img src="../Images/0b15ab47b4be3089f4cbc6bd55c6e236.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*940h3fjfBeGRfgzH"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">LSTM建筑</figcaption></figure><figure class="jz ka kb kc fd ij"><div class="bz dy l di"><div class="kd ke l"/></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">模型代码</figcaption></figure><p id="303d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">模特培训</strong></p><p id="566f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我使用二元交叉熵损失在10个时期上训练模型。</p><figure class="jz ka kb kc fd ij"><div class="bz dy l di"><div class="kd ke l"/></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">培训代码</figcaption></figure><figure class="jz ka kb kc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lo"><img src="../Images/67b19277fc64ea482c3e87ce6ccfc829.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UZUdwuJw7XIatdsPEgHu5A.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">学习曲线</figcaption></figure><p id="7862" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">使用MLflow </strong>打包模型</p><p id="b76f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">既然我们已经训练并验证了模型，那么是时候打包它了。我们需要做以下工作:</p><ol class=""><li id="914e" class="jl jm hi io b ip iq it iu ix jn jb jo jf jp jj jq jr js jt bi translated">序列化记号化器、嵌入矩阵、模型的权重。</li><li id="7811" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">定义包含序列化对象的文件路径的字典工件。</li><li id="49a5" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">定义包含所有依赖项的Conda环境。</li><li id="5a3e" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">定义PythonModel类，它包括“预测”函数逻辑。</li></ol><figure class="jz ka kb kc fd ij"><div class="bz dy l di"><div class="kd ke l"/></div></figure><p id="f190" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们打包的模型可以被任何下游应用程序使用。我只需要加载包并调用“预测”功能。</p><figure class="jz ka kb kc fd ij"><div class="bz dy l di"><div class="kd ke l"/></div></figure></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><p id="f2be" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最终的app<a class="ae jk" href="https://toxicityapi.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">https://toxicityapi.herokuapp.com/</a></p><h1 id="801b" class="lw kk hi bd kl lx ly lz kp ma mb mc kt md me mf kw mg mh mi kz mj mk ml lc mm bi translated">参考</h1><p id="f0f8" class="pw-post-body-paragraph im in hi io b ip le ir is it lf iv iw ix lg iz ja jb lh jd je jf li jh ji jj hb bi translated">数据集:<a class="ae jk" href="https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/jigsaw-unintended-bias-in-toxicity-classification</a></p><p id="4625" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">github Repos:<a class="ae jk" href="https://github.com/jonad/pytorch_mlflow/blob/master/textclassification_with_mlflow.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/jonad/py torch _ ml flow/blob/master/text classification _ with _ ml flow . ipynb</a></p></div></div>    
</body>
</html>