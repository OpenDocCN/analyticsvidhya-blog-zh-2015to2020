<html>
<head>
<title>A Customized Loss Function for Review Rating Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于评论评级预测的定制损失函数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-customized-loss-function-for-review-rating-prediction-7e8bd6eadac5?source=collection_archive---------16-----------------------#2020-06-09">https://medium.com/analytics-vidhya/a-customized-loss-function-for-review-rating-prediction-7e8bd6eadac5?source=collection_archive---------16-----------------------#2020-06-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/8b405d30e10f44bd78e948b0c92d0cd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/1*sV3DKBNL5PyfTKho8m1y6A.gif"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><a class="ae iq" href="https://giphy.com/gifs/201516-BWySufD6KWQzC" rel="noopener ugc nofollow" target="_blank">图像来源</a></figcaption></figure><p id="2519" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在这个项目中，通过使用单词嵌入和深度学习方法来预测动漫评论评分。预测是通过大约1个平均绝对误差(MAE)完成的，并提出了一个专门的损失函数。可以看出，新的损失函数不仅学习速度更快，而且比均方误差(MSE)更能抵抗过拟合。</p><h1 id="8d1b" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">问题</h1><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es kn"><img src="../Images/8de5fa66b0e2a0f4869474cc300a8e5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ovPxF5EgyczVWA4_fceYMw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated"><a class="ae iq" href="https://myanimelist.net/reviews.php?id=175947" rel="noopener ugc nofollow" target="_blank">评论来源</a></figcaption></figure><p id="5dca" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">问题是通过使用评论文本来预测动漫评论的总体评分。收视率满分十分。因此，上述审查样本不是一个积极的，其评级为4分(满分10分)。还有其他流行的作品把IMDB评论分为正面和负面。这项研究更进了一步，给评论打分。</p><h1 id="9cea" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">数据和预处理</h1><p id="e901" class="pw-post-body-paragraph ir is hi it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hb bi translated">kaggle用户NatLee在此收集并分享了myanimelist评论数据:</p><div class="lb lc ez fb ld le"><a href="https://www.kaggle.com/natlee/myanimelist-comment-dataset/" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd hj fi z dy lj ea eb lk ed ef hh bi translated">MyAnimeList注释数据集(MALCoD)</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">包含130，000条来自MyAnimeList.net的评论。</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">www.kaggle.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls ik le"/></div></div></a></div><p id="575e" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我不想写下基本的数据清理过程。其他操作:</p><ul class=""><li id="9a3e" class="lt lu hi it b iu iv iy iz jc lv jg lw jk lx jo ly lz ma mb bi translated">动漫名称从他们的评论中删除。因为它们的含义会影响预测。例如，“伟大的老师Onizuka”本身似乎是一个积极的评论:)</li><li id="0988" class="lt lu hi it b iu mc iy md jc me jg mf jk mg jo ly lz ma mb bi translated">在评论中，所有“不”字符数组都被替换为“不”。</li><li id="edfa" class="lt lu hi it b iu mc iy md jc me jg mf jk mg jo ly lz ma mb bi translated">除了“不”、“大多数”、“不”、“太”和“非常”之外，所有的停用词都从评论中删除。因为被排除的单词会影响评分。</li><li id="729d" class="lt lu hi it b iu mc iy md jc me jg mf jk mg jo ly lz ma mb bi translated">评论中只允许出现英文字符，标点符号和数字也被过滤。</li></ul><p id="d5b8" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">接下来，应该为单词标记化确定最大字数。为此，评论的字数是可视化的。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/adfdd51cf74bc042e237d096d95a7cbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*0klbZjVjP-17Hi-kwUX8nA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">每次评论的字数</figcaption></figure><p id="50d1" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">从上面的图表可以看出，单词的数量呈幂律分布。所以，一小部分评论字数很多，大部分评论字数很少。65%的评论少于250字，这是最大字数。如果评论超过250个字，最后250个字将被考虑。最后，使用nltk分词器对单词进行分词。对于文本编辑和标记化，我利用了来自<a class="ae iq" href="https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17" rel="noopener" target="_blank">的这项研究</a>。</p><h1 id="e31f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">方法</h1><p id="e83c" class="pw-post-body-paragraph ir is hi it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hb bi translated">单词嵌入方法可以在单词标记化之后使用。这是一个根据单词的含义对单词进行矢量化的模型。Keras有一个嵌入层来应用单词嵌入。CNN和LSTM也在模型中使用。下面的网络模型基于另一个模型，在这里<a class="ae iq" href="https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/" rel="noopener ugc nofollow" target="_blank">给出</a>。</p><pre class="ko kp kq kr fd mi mj mk ml aw mm bi"><span id="15ea" class="mn jq hi mj b fi mo mp l mq mr">model = Sequential()<br/>model.add(Embedding(5000, 100, input_length=250))<br/>model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))<br/>model.add(MaxPooling1D(pool_size=2))<br/>model.add(LSTM(100))<br/>model.add(Dense(1, kernel_initializer='normal'))</span></pre><p id="0b3a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">首先，我使用MSE作为损失函数，然后创建一个定制的损失函数，定义如下:</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es ms"><img src="../Images/8c32749354903a136b81839158d838bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hOo6nqfuzYxyfGXkoTbuDA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">新的分段损失函数</figcaption></figure><p id="ae59" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在分段函数的第一部分，忽略了舍入后预测值与真实值相同时的误差。由于每个用户都必须给出一个介于1-10之间的整数，他们也在心中对分数进行四舍五入。例如，如果他们的分数是7.5，他们就给8。在第二部分，它将差值乘以2，然后计算均方误差。乘以2的原因是当差值大于0.5时，增加了误差的影响。MSE给出了小于1的较小值。例如，考虑差值为0，6。这意味着MSE的误差为0.36。在相同情况下，新函数返回1，44。总之，MSE将误差缩小到1以下，将误差提高到1以上。新函数将误差缩小到0，5以下，将误差提高到0，5以上。</p><pre class="ko kp kq kr fd mi mj mk ml aw mm bi"><span id="4e0c" class="mn jq hi mj b fi mo mp l mq mr">from keras import backend as K</span><span id="d21c" class="mn jq hi mj b fi mt mp l mq mr">def piecewise_loss(y_true, y_pred):<br/>    errorGreater = K.greater((y_true-y_pred),0.5)<br/>    errorLess = K.less_equal((y_true-y_pred),-0.5)<br/>    error = K.cast(errorGreater|errorLess, K.floatx())<br/>    return K.mean(K.square(error*2*(y_true-y_pred)))</span></pre><p id="ac79" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">这就是如何在Keras中编写定制的损失函数。函数应该带两个参数:<em class="mu"> y_true，y_pred。</em>和<em class="mu"> </em>张量兼容<em class="mu"> </em>使用Keras后端功能。</p><pre class="ko kp kq kr fd mi mj mk ml aw mm bi"><span id="3f34" class="mn jq hi mj b fi mo mp l mq mr">model.compile(optimizer='sgd', loss=<strong class="mj hj">piecewise_loss</strong>, metrics=['mae'])</span></pre><p id="3117" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">该函数在模型编译中作为损失参数传递。</p><h1 id="2897" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结果</h1><p id="badc" class="pw-post-body-paragraph ir is hi it b iu kw iw ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo hb bi translated">MSE和分段损失函数在精度方面是相同的:MAE约为1。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/40c4b112a45680760ead1ef58df90535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*lwIzzVtmodadGxwl-SPJ3w.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">两种不同损失函数在20个时期的验证数据误差</figcaption></figure><p id="ba1e" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">上图显示了验证数据集的MAE值。蓝色的有分段损失函数，橙色的有MSE损失函数。如图所示，分段损失函数提供了比其他模型更快的学习。14后达到最小误差。新纪元。另一个在18岁时达到最低点。新纪元。分段损失函数具有稳定的误差，而另一个具有波动的误差。此外，MSE损失函数在20秒内开始过度拟合。分段损失函数更能抵抗过度拟合，因为它忽略了小误差。</p></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><p id="c84e" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">感谢阅读！我将很高兴看到大家对我的第一次NLP研究的反馈:)</p></div></div>    
</body>
</html>