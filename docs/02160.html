<html>
<head>
<title>Deep Dive into Back Propagation (Part I )</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入研究反向传播(第一部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-dive-into-back-propagation-part-i-e1a92b6dbdb9?source=collection_archive---------17-----------------------#2019-12-03">https://medium.com/analytics-vidhya/deep-dive-into-back-propagation-part-i-e1a92b6dbdb9?source=collection_archive---------17-----------------------#2019-12-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/cd37dd7b3fb53f2caac728575cc6b43a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*rJF8NHIrEkKA4jfVyJcpFw.png"/></div></figure><p id="3853" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">本文是对神经网络中前馈过程的深入解释的继续。文章链接可在<a class="ae jk" rel="noopener" href="/analytics-vidhya/in-depth-explanation-of-feedforward-in-neural-network-mathematically-448092216b63">这里</a>找到。</p><p id="93b1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">既然我们已经完成了前馈传递，接收了输出，并计算了误差，我们准备返回来改变我们的权重，目标是减少网络误差。当改变权重时，从输出到输入反向进行是我们称之为反向传播的过程，其本质上是使用链规则计算的随机梯度下降。</p><p id="f63f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了能够实现一个基本的神经网络，我们并不真的需要深刻的数学理解，因为现在我们有开源工具。但要真正理解它的工作原理并优化我们的应用，了解数学总是很重要的。</p><p id="00de" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们的目标是找到最小化网络误差的一组权重。我们使用一个迭代过程，每次向网络提供来自我们训练集的一个输入。在每个输入的前馈过程中，我们计算网络误差。然后，我们可以使用这个误差来稍微改变正确的方向，每次只减少一点误差。我们继续这样做，直到我们确定误差足够小。现在让我们看看梯度的考虑。</p><figure class="jm jn jo jp fd ij er es paragraph-image"><div class="er es jl"><img src="../Images/a8fb326d9ede3475e4a3bdc6183d6420.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dbwXfmVWcwlWYl7046DUDg.png"/></div></figure><figure class="jm jn jo jp fd ij er es paragraph-image"><div class="er es jl"><img src="../Images/246c957081efae37a81c0bb5fb5f0fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*BzcItEyGfpcnzqwyHDA2TQ.png"/></div></figure><figure class="jm jn jo jp fd ij er es paragraph-image"><div class="er es jl"><img src="../Images/125c6f8ecdc3515e09885ddcac91b0ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*k0SwtwTjjpkE-P7LFAVTDg.png"/></div></figure><figure class="jm jn jo jp fd ij er es paragraph-image"><div class="er es jq"><img src="../Images/e1fa14fe338384fda0123348aca8501b.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*qLayk0HO7tTJzHMsMhHvpg.png"/></div></figure><figure class="jm jn jo jp fd ij er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jr"><img src="../Images/9d3a3fe0dc7091d62f398e60dc6f2fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PO-gEFXby4LfrrNSbXNdhg.png"/></div></div></figure><p id="9c63" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，您可以找到了解和调整学习率的其他好资源:</p><ul class=""><li id="efb8" class="jw jx hi io b ip iq it iu ix jy jb jz jf ka jj kb kc kd ke bi translated"><a class="ae jk" href="http://blog.datumbox.com/tuning-the-learning-rate-in-gradient-descent/" rel="noopener ugc nofollow" target="_blank">资源1 </a></li><li id="ff0d" class="jw jx hi io b ip kf it kg ix kh jb ki jf kj jj kb kc kd ke bi translated"><a class="ae jk" href="http://cs231n.github.io/neural-networks-3/#loss" rel="noopener ugc nofollow" target="_blank">资源二</a></li></ul><p id="1cdb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">基本上，反向传播归结为计算误差E相对于每个权重的偏导数。然后根据Wij的δ的计算值调整权重。这些计算是针对每一层进行的。</p><figure class="jm jn jo jp fd ij er es paragraph-image"><div class="er es kk"><img src="../Images/aebb7eb2ca6b407dbcdfa1e2f8f1836e.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*bAx_y6sJ_N5iHHSP-2SfQA.png"/></div></figure><h1 id="d46f" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">过度拟合</h1><p id="ac18" class="pw-post-body-paragraph im in hi io b ip lj ir is it lk iv iw ix ll iz ja jb lm jd je jf ln jh ji jj hb bi translated">当我们使用反向传播使网络误差最小化时，我们可以适当地使模型适应数据，也可以过度适应。一般来说，当我们有一个有限的训练集时，会有过度适应的风险。</p><figure class="jm jn jo jp fd ij er es paragraph-image"><div class="er es jl"><img src="../Images/1b47e67a7d194ee5285f3c4603f3ba51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*AJH_nPvx5_n5qYJgAb71Fw.png"/></div></figure><p id="8f4b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">过度拟合意味着我们的模型将过于紧密地拟合训练数据。换句话说，我们过度训练了模型或网络来适应数据。因此，我们无意中也模拟了训练集中的噪声或随机元素。如果发生这种情况，我们的模型在测试新输入时将不能很好地推广。</p><p id="f8cd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">通常有两种主要方法来解决过拟合问题。</p><ol class=""><li id="d2a1" class="jw jx hi io b ip iq it iu ix jy jb jz jf ka jj lo kc kd ke bi translated">尽早停止训练过程</li><li id="2e9e" class="jw jx hi io b ip kf it kg ix kh jb ki jf kj jj lo kc kd ke bi translated">正规化的使用</li></ol><h2 id="3d12" class="lp km hi bd kn lq lr ls kr lt lu lv kv ix lw lx kz jb ly lz ld jf ma mb lh mc bi translated">1.提前停止培训过程</h2><p id="5382" class="pw-post-body-paragraph im in hi io b ip lj ir is it lk iv iw ix ll iz ja jb lm jd je jf ln jh ji jj hb bi translated">当我们提前停止训练过程时，我们在网络开始过度适应的区域这样做。通过这样做，我们减少了测试集的性能下降。如果我们准确地知道何时应该停止训练过程，那将是理想的。确定何时停止训练的一种方法是从训练集中划分出一个小数据集，我们称之为验证集。假设验证集的精度与测试集的精度相似，我们可以用它来估计训练应该何时停止。这种方法的缺点是我们最终用较少的样本来训练我们的模型，所以我们的训练集较小。</p><figure class="jm jn jo jp fd ij er es paragraph-image"><div class="er es kk"><img src="../Images/82a140dc3b4f9fd51c867e730098f6c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*nQsK5Vd5H42fZCH9Y7YcZw.png"/></div></figure><figure class="jm jn jo jp fd ij er es paragraph-image"><div class="er es kk"><img src="../Images/7df3dca9d3a105ea41be841a832951a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*EtDalzLKR2w7WiQJQBzrkQ.png"/></div></figure><h2 id="a58d" class="lp km hi bd kn lq lr ls kr lt lu lv kv ix lw lx kz jb ly lz ld jf ma mb lh mc bi translated">2.正规化的使用</h2><p id="c181" class="pw-post-body-paragraph im in hi io b ip lj ir is it lk iv iw ix ll iz ja jb lm jd je jf ln jh ji jj hb bi translated">正则化意味着我们对网络的训练施加约束，以便可以实现更好的泛化。辍学是一种广泛使用的正规化计划，以这种方式提供帮助。</p><p id="746e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因为偏导数是反向传播中使用的关键数学概念，所以对自己计算偏导数的能力有信心是很重要的。一旦你知道如何计算基本导数，计算偏导数就很好理解了。<br/>欲了解更多关于偏导数的信息，请点击以下<a class="ae jk" href="http://www.columbia.edu/itc/sipa/math/calc_rules_multivar.html" rel="noopener ugc nofollow" target="_blank">链接</a></p><p id="3111" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了在本课的未来测验中进行计算，您可以使用以下链接作为<a class="ae jk" href="http://tutorial.math.lamar.edu/pdf/Common_Derivatives_Integrals.pdf" rel="noopener ugc nofollow" target="_blank">常见衍生工具</a>的参考。</p><p id="5d1b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">内容鸣谢:Udacity深度学习计划</p><p id="9ab7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">第二部分的链接可以在<a class="ae jk" rel="noopener" href="/@aungkyawmyint_26195/deep-dive-into-back-propagation-part-ii-c392f804a784">这里</a>找到。</p></div></div>    
</body>
</html>