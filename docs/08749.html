<html>
<head>
<title>Building An (Amateur) Machine Learning Web App &amp; What I Learnt</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建一个(业余)机器学习网络应用&amp;我学到了什么</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-an-amateur-machine-learning-web-app-what-i-learnt-d6a89bddb025?source=collection_archive---------16-----------------------#2020-08-11">https://medium.com/analytics-vidhya/building-an-amateur-machine-learning-web-app-what-i-learnt-d6a89bddb025?source=collection_archive---------16-----------------------#2020-08-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii"><div class="bz dy l di"><div class="ij ik l"/></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="http://zhijingeu.pythonanywhere.com/" rel="noopener ugc nofollow" target="_blank">http://zhijingeu.pythonanywhere.com</a></figcaption></figure><h1 id="7e8c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">目录</h1><p id="fd1b" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><a class="ae ip" href="#2905" rel="noopener ugc nofollow">简介</a></p><p id="fbde" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><a class="ae ip" href="#7ff5" rel="noopener ugc nofollow"> 1。动机&amp;目标</a></p><p id="6ec3" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><a class="ae ip" href="#8698" rel="noopener ugc nofollow"> 2。开发&amp;部署工作流程</a> <br/> <a class="ae ip" href="#dede" rel="noopener ugc nofollow"> 2.1收集训练数据</a> <br/> <a class="ae ip" href="#ad52" rel="noopener ugc nofollow"> 2.2开发&amp;训练神经网络模型</a> <br/> <a class="ae ip" href="#9faf" rel="noopener ugc nofollow"> 2.2.1文本模型</a> <br/> <a class="ae ip" href="#dcc1" rel="noopener ugc nofollow"> 2.2.2图像模型</a> <br/> <a class="ae ip" href="#43d4" rel="noopener ugc nofollow"> 2.2.3训练云上的GAN模型</a> <br/> <a class="ae ip" href="#18d3" rel="noopener ugc nofollow"> 2.3构建Web App</a><br/><br/></p><p id="019c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><a class="ae ip" href="#e82f" rel="noopener ugc nofollow"> 3。那么我学到了什么…？</a> <br/> <a class="ae ip" href="#2988" rel="noopener ugc nofollow"> 3.1充分理解您的数据是关键！</a> <br/> <a class="ae ip" href="#e2cf" rel="noopener ugc nofollow"> 3.2深度学习可以是计算/硬件密集型的</a> <br/> <a class="ae ip" href="#f833" rel="noopener ugc nofollow"> 3.3(适当的)深度学习需要很多专家知道如何</a> <br/> <a class="ae ip" href="#0e41" rel="noopener ugc nofollow"> 3.4知道“构建自己的”与打包的解决方案之间的权衡</a> <br/> <a class="ae ip" href="#4025" rel="noopener ugc nofollow"> 3.5端到端机器学习开发/部署/运营需要非常不同的技能集</a></p><p id="bc48" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><a class="ae ip" href="#8080" rel="noopener ugc nofollow"> 4。结论</a></p><p id="de94" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><a class="ae ip" href="https://github.com/ZhijingEu/Fake_Anime_Generator" rel="noopener ugc nofollow" target="_blank"> Github回购链接</a></p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es kr"><img src="../Images/dcc40ac5ac2cc56246e401afcdf53a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*W5iXpr9HF1mXU8eEzG7oEA.jpeg"/></div></figure><h1 id="2905" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">介绍</h1><p id="68c6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我先提出一个警告，如果你正在寻找一个详细的“如何指导”以及附带的代码遍历，这篇文章可能不适合你。</p><p id="be36" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">虽然我仍然会在我的Github代码中发布一个l <a class="ae ip" href="https://github.com/ZhijingEu/Fake_Anime_Generator" rel="noopener ugc nofollow" target="_blank"> ink，并快速浏览一下部署设置，但是在其他地方可能会有更好的关于如何开发和部署ML应用程序的教程</a></p><p id="833b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">相反，我的重点将更多地放在我作为一名<strong class="jq hj"> noob </strong>程序员的个人见解上，同时致力于这个‘玩具项目’(希望)对像我一样开始并仍在尝试的其他人有用。</p><h1 id="7ff5" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">1.动机和目标</h1><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="ij ik l"/></div></figure><p id="2161" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在过去的一年里，我一直在尝试学习一些不同的东西——主要是一般的Python编程，但也有一些用于游戏开发的Unity (C++)、用于移动应用的Android Studio (Java)、基本的HTML/Javascript、谷歌云平台以及大量借用和调整他人的Github代码。</p><p id="0687" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">那些在Medium或我的Linkedin个人资料上关注我的人会看到我的一些迷你项目。然而，其中大多数都是独立的项目，只在我的本地笔记本电脑或我自己的手机上运行。</p><p id="1b06" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这一次，我想在web上构建和部署一个机器学习应用程序的粗略演示，目的是:-</p><p id="2e71" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">1.在旅途中的所有不同步骤中边做边学</p><p id="8c72" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">2.深入学习神经网络解决方案的工作原理</p><p id="ac28" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">3.祝你一路实验愉快</p><p id="5e89" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">4 .并且(希望……)用最终的网站给其他人提供几秒钟的娱乐</p><p id="baf9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">就网站的构思而言，这篇文章给了我很大的启发:</p><div class="kz la ez fb lb lc"><a href="https://andymakesgames.tumblr.com/post/167733819029/urzas-dream-engine-the-roborosewater-robodraft" rel="noopener  ugc nofollow" target="_blank"><div class="ld ab dw"><div class="le ab lf cl cj lg"><h2 class="bd hj fi z dy lh ea eb li ed ef hh bi translated">Urza的梦想引擎RoboRosewater RoboDraft:创建一个机器学习算法来…</h2><div class="lj l"><h3 class="bd b fi z dy lh ea eb li ed ef dx translated">Urza的梦想引擎是一个我已经研究了几个月的神经网络项目。这是一个机器人，在…</h3></div><div class="lk l"><p class="bd b fp z dy lh ea eb li ed ef dx translated">andymakesgames.tumblr.com</p></div></div><div class="ll l"><div class="lm l ln lo lp ll lq kw lc"/></div></div></a></div><p id="4dc5" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">作者利用一种称为GAN的特殊类型的神经网络(稍后将详细介绍)，他使用一大套神奇的收集卡(一种非常流行的收集卡游戏)来训练它，以生成全新的<em class="ky">制作的</em>卡。</p><p id="ba92" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我想做一些类似的事情，但日本动漫。有一些网站制作随机的标题，但没有额外制作描述/概要或海报图片。</p><div class="kz la ez fb lb lc"><a href="https://www.generatormix.com/random-anime" rel="noopener  ugc nofollow" target="_blank"><div class="ld ab dw"><div class="le ab lf cl cj lg"><h2 class="bd hj fi z dy lh ea eb li ed ef hh bi translated">随机动画生成器Mix</h2><div class="lj l"><h3 class="bd b fi z dy lh ea eb li ed ef dx translated">只需选择你想要的动漫数量，点击绿色按钮就可以生成一个随机动漫列表。使用此工具，您可以…</h3></div><div class="lk l"><p class="bd b fp z dy lh ea eb li ed ef dx translated">www.generatormix.com</p></div></div><div class="ll l"><div class="lr l ln lo lp ll lq kw lc"/></div></div></a></div><div class="kz la ez fb lb lc"><a href="https://www.seventhsanctum.com/generate.php?Genname=animetitle" rel="noopener  ugc nofollow" target="_blank"><div class="ld ab dw"><div class="le ab lf cl cj lg"><h2 class="bd hj fi z dy lh ea eb li ed ef hh bi translated">第七圣地:生成器之页-艺术、游戏、写作和想象的随机工具。</h2><div class="lj l"><h3 class="bd b fi z dy lh ea eb li ed ef dx translated">关于动漫标题有一种特定的东西。这试图将一些东西煮沸成随机创建的标题…</h3></div><div class="lk l"><p class="bd b fp z dy lh ea eb li ed ef dx translated">www.seventhsanctum.com</p></div></div><div class="ll l"><div class="ls l ln lo lp ll lq kw lc"/></div></div></a></div><p id="d8d4" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">所以我想，为什么不自己造一个呢？！</p><h1 id="8698" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2.开发和部署工作流程</h1><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="ij ik l"/></div></figure><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lt"><img src="../Images/4ec56f1f13e7b66f0c0ed405c75f2a68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1XQg1MQMgs2qI_D7m6LogQ.png"/></div></div></figure><h2 id="dede" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">2.1收集培训数据</h2><p id="e0a9" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我将<a class="ae ip" href="https://myanimelist.net/topanime.php" rel="noopener ugc nofollow" target="_blank"> MyAnimeList </a>作为我的数据来源，因为它有一个顶级列表，每个标题都有一个概要和海报图像。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mm"><img src="../Images/20605ffb0073c32ec8fcae4590b5e4c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2XH47M1u9HAJdYAWOnxJjQ.jpeg"/></div></div></figure><p id="6bc2" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我最初的解决方案是通过Beautiful Soup和Requests等库使用Python进行web抓取，但很快我就遇到了麻烦，甚至是像分页这样简单的事情(如何点击列表中的每个条目，以到达包含我想要的信息的个人节目的子页面)。</p><p id="ad30" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">因此，我找到了一个名为<a class="ae ip" href="https://www.parsehub.com" rel="noopener ugc nofollow" target="_blank"> Parsehub </a>的托管解决方案</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mn"><img src="../Images/1fd5612458d82b3efc707595c69c28c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nlHIsxmBCfsqeW23o1Q93g.png"/></div></div></figure><p id="6b09" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">Parsehub是一个基本上没有代码的解决方案，在你确定了你想要抓取的目标网站后，你只需点击你想要获取的所有字段，就可以构建一个“模板”(如下所示)。该工具负责识别该页面中的相似字段，然后您可以提取这些字段。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mo"><img src="../Images/c22cff84f12e9da2439483d727041801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dw8KD0c1scJNF9kE5YDdHg.jpeg"/></div></div></figure><p id="111d" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">您甚至可以进入列表中的子页面，如下图所示，对于代表一个单独节目的每个子页面，我定义了一个单独的模板来提取节目描述和海报图像。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mp"><img src="../Images/966bfbf57990eddab86c81aa7955cd1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ja5HG13m04kAOLJtRnsHdw.jpeg"/></div></div></figure><p id="4318" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">完成后，您可以将结果下载为简单的CSV或excel文件。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mq"><img src="../Images/1f036d4eb0e8c15690962033ec8991af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xgPy9WCzZ3PuTQFd8eUsUg.jpeg"/></div></div></figure><p id="2757" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">使用这个工具，网页抓取变得容易多了。唯一的障碍是，Parsehub要求你<em class="ky">支付一个高级账户才能下载图片</em>(它直接下载到你的DropBox账户中)所以，作为一个小气鬼，我最终采用了一个折中的解决方案，从Parsehub获得图片的URL链接，但使用Python下载。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mr"><img src="../Images/7716830a257b28ca559fd727b1240363.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0YtsdXEUvhvfCoOvmivkZA.jpeg"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">原始文本数据</figcaption></figure><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es ms"><img src="../Images/fcee457379d84c9f600656c7ad6cbb19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A4kcjNKkr6pn8SQk7-_yDQ.jpeg"/></div></div></figure><h2 id="ad52" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">2.2开发和训练神经网络模型</h2><p id="9faf" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><strong class="jq hj"> 2.2.1文本模式</strong></p><p id="376b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">对于文本生成模型，我使用教程中的现有代码修改了解决方案<a class="ae ip" href="https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb" rel="noopener ugc nofollow" target="_blank">，该教程是Udacity上深度学习Tensorflow简介</a>课程的一部分(如果您想查看代码，请单击链接，我有意避免在此不必要地复制它，因为我的代码很大程度上是根据它修改的)</p><p id="e861" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">第一步包括处理原始数据，清除标点符号、大写字母和空格，然后“<a class="ae ip" href="https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/#:~:text=Tokenization%20is%20the%20process%20of,a%20token%20in%20a%20paragraph" rel="noopener ugc nofollow" target="_blank">标记</a>”文本(将长句子变成单个单词)，以便它可以输入神经网络。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/57cd5948770cc9772a820154decffb47.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*IpVBj4Ti7x8PbjN-S7vOWw.png"/></div></figure><p id="dad0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我使用的例子是一个相当简单的神经网络，使用<a class="ae ip" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>(一个抽象层，简化了<a class="ae ip" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>中的模型构建)，其中使用了两个关键组件。</p><p id="fd73" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">一个<a class="ae ip" href="https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/#:~:text=The%20Embedding%20layer%20is%20defined,vocabulary%20would%20be%2011%20words" rel="noopener ugc nofollow" target="_blank">嵌入层</a>将文本中的单词映射到一个更高维的空间中</p><p id="d2c8" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这然后被输入到<a class="ae ip" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs" rel="noopener ugc nofollow" target="_blank">长短期记忆层</a>中，该层通常在时间序列分析中“记住序列”,从而学习各种单词之间的模式和关系。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/7c0c24246a803eedb8481d52f7474285.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*fdrqhQO6xHHG5YMquTvRyA.gif"/></div><figcaption class="il im et er es in io bd b be z dx translated">单词沙拉——好吃…</figcaption></figure><p id="3558" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">训练后(神经网络遍历所有示例，通过调整节点之间的权重来学习模式的过程)，神经网络可以根据之前出现的单词来“预测”下一个单词，然后在此基础上逐步构建整个段落。</p><p id="dcc1" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 2.2.2图像模型</strong></p><p id="6c80" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">对于图像模型，我使用了一个更复杂的模型设置，称为<a class="ae ip" href="https://pathmind.com/wiki/generative-adversarial-network-gan" rel="noopener ugc nofollow" target="_blank">生成对抗网络</a>，在这里我通过改编这篇中型文章&lt; <a class="ae ip" href="https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4" rel="noopener" target="_blank">中的示例获得了大部分代码</a></p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es mv"><img src="../Images/fb14608f9c5a9d6d92f8851ed0333300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*wbcm1dB8KV8uYtiJaJlQRA.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">(<a class="ae ip" href="https://www.slideshare.net/xavigiro/deep-learning-for-computer-vision-generative-models-and-adversarial-training-upc-2016" rel="noopener ugc nofollow" target="_blank">源链接</a>)</figcaption></figure><p id="9bc3" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">GAN模型在架构方面更复杂一些，但基本思想是建立两个模型——一个“鉴别器”和一个“发生器”。生成器模型使用随机噪声创建人工图像，并且鉴别器被训练来区分由生成器模型创建的“真实样本”和“赝品”</p><p id="774f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">GANs的聪明之处在于，你建立了一个系统，让两个模型玩一个试图胜过对方的游戏——即生成器学习如何制作更好的假货来欺骗鉴别器，而鉴别器试图“捕捉”生成器的假货图像。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/ad1ec86db6303ab0d53f58e7a3817206.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*rLDNkQ8bM6LAvq0gljgmig.png"/></div></figure><p id="ce5f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">从图中可以看出，鉴别器和生成器架构比早期的文本模型更加复杂，包含了更多的层。然而，关键的想法是，他们利用了常用于计算机视觉应用的<a class="ae ip" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank">卷积神经网络层</a>。这些细胞神经网络获取特征，如果你积累了足够多的细胞神经网络，它们就开始学习越来越多的细节特征(例如简单的边缘、曲线、形状、纹理，最后是眼睛的样子，等等)</p><p id="d9dc" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">然而，为了正确地训练GAN，您必须合并这两个模型，这增加了复杂性。</p><p id="812c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">与前面的例子类似，我必须运行一些预处理来将图像从矩形转换成正方形(即使是有形状的图像也更容易处理)。</p><p id="3b2a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">然而，当在我的本地CPU上运行模型训练时，我立即遇到了一个问题。即使是1000个纪元的试运行，也需要超过6-8个小时。我知道我需要找到另一种方法。</p><h2 id="43d4" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">2.2.3在云上训练GAN模型</h2><p id="5ce5" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><a class="ae ip" href="http://www.spell.ml" rel="noopener ugc nofollow" target="_blank">拼ML </a>是一个<em class="ky">机器学习Ops平台，用于机器学习和深度学习。</em>基本上，这是一种允许你租用他们服务器的计算能力来使用GPU运行和训练你的模型的服务。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mx"><img src="../Images/50219216f8b6bfc2d16474c7a9c11711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QFrO-amQSvh16O5GIB_sNg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="http://www.spell.ml" rel="noopener ugc nofollow" target="_blank"> www.spell.ml </a></figcaption></figure><p id="f67c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">从技术上来说，像谷歌云平台或亚马逊网络服务这样的主要云平台也可以做到这一点，但我喜欢Spell ML的简单性，它让你可以从自己的本地机器上运行代码。</p><p id="4243" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我用它来设置一个虚拟机，该虚拟机使用NVIDIA Tesla K80 GPU在5000个时期重新运行该模型，然后在10，000个时期再次运行。这仍然花了几个小时，但绝对比在我自己的本地CPU上做这个要好得多。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es my"><img src="../Images/2d9893f042e9f55d35901bc089ab37bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oo75Lzt4OfyrVhOlataR5A.png"/></div></div></figure><p id="97e6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">Spell ML的工作方式是从本地机器(或者github页面)上的任何git存储库中克隆文件到它的服务器上，然后在它们的服务器环境上运行所选择的命令/文件作为“Run”</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es mz"><img src="../Images/190890cba29aae40b5ac76a65af51270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f4QFto5nB2qowYfnt_pr-w.png"/></div></div></figure><p id="21ba" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">运行完成后，输出(如保存的tensorflow模型文件或任何其他输出，如图像、csv-s等)将存储在运行文件夹中，然后您可以将其保存到本地计算机上以加载到您的模型中。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es na"><img src="../Images/060c964c85171fb9f216351c9fe48d5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MSDLvvL8Z-dNaNx4g45lbg.png"/></div></div></figure><h2 id="18d3" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated"><strong class="ak"> 2.3构建Web应用</strong></h2><p id="b87c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">准备好所有的移动部件后，我使用Python的WGSI (web服务器网关接口)库<a class="ae ip" href="https://flask.palletsprojects.com/en/1.1.x" rel="noopener ugc nofollow" target="_blank"> Flask </a>构建了一个简单的Web应用程序。</p><p id="953c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我编写了几个函数，调用Tensorflow模型来产生文本和图像的输出，然后将这些输出传递给变量，这些变量又被输入到一个非常简单的HTML页面模板中。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nb"><img src="../Images/04abb008e7433b61193687dfd2192f36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Arp2OLwyRfWoMrddTV832w.png"/></div></div></figure><h2 id="a4cf" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">2.4在线部署Web应用程序</h2><p id="a449" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">从技术上讲，我可以在Spell上从网络服务器运行flask应用程序。但是那就像用一辆漂亮的法拉利开到隔壁的杂货店，在那里自行车就可以了。</p><p id="5d77" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">因此，取而代之的是，我使用了一个免费的帐户来托管我的Flask web应用程序。(PythonAnywhere的免费订阅只允许一个web应用程序)</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nc"><img src="../Images/890fcbf0c4645e311c132b32f0dfa372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oed6LsQVjelPIIz5d2-f_A.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">&lt;<a class="ae ip" href="https://www.pythonanywhere.com/" rel="noopener ugc nofollow" target="_blank">https://www.pythonanywhere.com</a>T14】</figcaption></figure><p id="3c55" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我原以为上传Python脚本文件是一件简单的事情，但是我遇到了一个相当大的障碍:PythonAnywhere不支持为web应用程序运行Tensorflow！</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es nd"><img src="../Images/3515b72ee1d63d4ec5a3a595c108ad04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*jhxn3um54eivqAbRJ_YYhw.png"/></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="https://help.pythonanywhere.com/pages/MachineLearningInWebsiteCode" rel="noopener ugc nofollow" target="_blank">https://help . python anywhere . com/pages/machineellinginwebsitecode</a></figcaption></figure><p id="6bdb" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">当然，这无论如何都是一个糟糕的想法，因为最佳实践是将TensorFlow模型划分到一个API中，或者将它作为一个脚本单独托管，异步调用，但为了简单起见，我希望只按原样部署应用程序。</p><p id="e347" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这让我想到了我最后的半成品解决方案。在一次<strong class="jq hj"> <em class="ky"> meta </em> </strong>的事件转折中，我“伪造”了那个山寨动漫生成器。我没有每次都“实时”运行Tensorflow模型，而是上传了100个图像和文本样本输出的缓存，并在Flask应用程序中编写了一个脚本，以便在每次重新加载页面时进行随机选择。</p><p id="4cb7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">你可能会说这是一种逃避，你可能是对的，但是，嘿，我最终还是在公开的网络上获得了网络应用程序</p><h2 id="e82f" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">3.那么我学到了什么…？</h2><figure class="ks kt ku kv fd ii"><div class="bz dy l di"><div class="ij ik l"/></div></figure><h2 id="2988" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">3.1充分理解您的数据是关键！</h2><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ne"><img src="../Images/79084b1fdc27ed152dca6b0ba4212d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*0eZ5FzjFTBWFpN85UqfPYA.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">图片来源:<a class="ae ip" href="https://machinelearnings.co/" rel="noopener ugc nofollow" target="_blank">https://machinelearnings.co</a></figcaption></figure><p id="4b29" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这是一个有点显而易见的说法，但人们常说，在数据科学中，大量时间都花在争论你的数据和建立一个聪明的机器学习模型上。</p><p id="c425" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">你有足够的数量和合适的质量吗？，所有样本的特征在本质上是异质/同质的吗？，在输入模型之前，如何最好地预处理数据以使其成形？等等</p><p id="a5bd" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">对于文本生成模型输出， 标题生成器工作正常，但概要的句子并不总是非常连贯——我怀疑这部分是因为模型本身只是一个浅层神经网络，但也可能是因为我将标记器设置为2500个单词的计数限制(即意味着模型只从总文本中选取最常见的2500个单词进行映射)——我没有尝试使用更大的单词计数，因为它开始变慢 当我增加到5000个单词时，我并不热衷于在拼写ML上花费更多的学分。</p><p id="c9fc" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">对于图像生成，我发现用更大的历元重新运行训练对结果没有什么影响</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es nf"><img src="../Images/2974e362700d067204b78d03708171c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/1*73VBaE9nVuqBM3q8WfRDHw.gif"/></div><figcaption class="il im et er es in io bd b be z dx translated">训练1000个纪元</figcaption></figure><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ng"><img src="../Images/d253616140b684ab86f320526b326070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/1*IV7OFv3cohAkv2qObsglvw.gif"/></div><figcaption class="il im et er es in io bd b be z dx translated">…与训练10，000个纪元的GAN相比</figcaption></figure><p id="917c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">可能是200个图像的图像数据集太小，或者我可以应用更多的预处理技术(例如，没有特征的裁剪区域？颜色调整？).然而，更根本的是，我有一种感觉，也许整个数据集中没有可供神经网络学习的“定义特征”(就像网络如何学习面孔一样，因为大多数面孔无论如何不同，仍然有眼睛、鼻子、耳朵等，但动漫海报有太多的多样性，没有共性)。</p><p id="687e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我还没有测试过，但也许我可以把海报分成几个子类别，比如根据前景/背景的人脸大小等等，然后按类别训练独立模特？</p><h2 id="e2cf" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">3.2深度学习可能是计算/硬件密集型的</h2><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es nh"><img src="../Images/b41214508fa8001fda5028027ba3ff5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*v2SKO439UyzqaDY1ul1IeA.png"/></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="https://www.istockphoto.com/vector/tired-computer-gm132076151-18473325" rel="noopener ugc nofollow" target="_blank">https://www.istockphoto.com</a></figcaption></figure><p id="e5c0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我在上面的2.2.3中提到了这一点，但是当我开始在我过时的笔记本电脑上多次运行时，我才开始欣赏这一点。</p><p id="9a49" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">特别是机器学习和神经网络面临的挑战是，它们在训练期间有太多的权重(即变量)要在内存中处理，你真的需要正确的硬件支持才能让它工作。</p><p id="3609" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">不像简单的程序，你可以通过调整这里的一行或那里的一个变量来快速迭代学习，大多数机器学习代码需要时间来运行(也就是说，如果你只让它运行1或2个时期，你真的看不到输出会发生什么)</p><p id="c773" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">还有一些关于优化你的代码计算速度的问题。特别是对于我用于图像生成的GAN模型，这本来就很棘手，因为本质上需要用许多超参数串联训练两个不同的网络来优化。我确信我可以优化批处理大小或选择一个更有效的优化器来减少计算量，但我没有详细探讨这一点。所有这些很方便地将我引向下一个观点…</p><h2 id="f833" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">3.3.(适当的)深度学习需要很多专业知识</h2><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ni"><img src="../Images/f610a5f56ff30ac3288903d250745825.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*1R8F6N3P7VnKdIF4O7rnCg.png"/></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="https://www.dictionary.com/e/slang/copypasta" rel="noopener ugc nofollow" target="_blank">妈妈的意大利面</a></figcaption></figure><p id="ca9c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我使用的大部分代码都是通过“复制意大利面”制作的——复制大量的示例代码，用胶带将所有的东西粘在一起，并希望它们最终仍然可以工作。</p><p id="b25b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我必须承认，有很多超参数需要优化或调整，我仍在试图理解。</p><p id="9713" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">一个不全面的列表应该是这样的:-</p><p id="613a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi">­</p><p id="7f99" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">批量大小、学习率和优化器的选择</strong> —我坚持使用<a class="ae ip" href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c" rel="noopener" target="_blank"> Adam优化器</a>并用<a class="ae ip" href="https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10" rel="noopener" target="_blank">学习率</a>进行实验——显然0.1的LR训练得更快，但结果看起来比我使用的最终LR 0.0001更差，但用不同的变量进行实验是一个昂贵而痛苦的缓慢过程(参考上一节)。我确实尝试过使用sklearn库的RandomSearchCross验证来运行一些排列，但即使只运行10个时期也要花费很长时间，最后我只是试错了。</p><p id="fc61" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">损失函数的选择</strong>，例如文本生成——我坚持使用样本代码中使用的分类交叉熵损失函数(即下一个单词预测，但最终我不确定较低的分类交叉熵是否真的“捕捉”了像概要这样的长文本的连贯性。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nj"><img src="../Images/963a40042a5dfa54c52dc266e62283e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AgnMPaECIk4zar-3YgQrdA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">1对100个时代的训练</figcaption></figure><p id="71b1" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">与GAN的图像不同，在GAN的图像中，您可以看到运行更长时期的输出在“质量”上的差异，对于文本生成模型，我真的无法分辨，因为两者对我来说似乎都不连贯</p><p id="8b40" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi">­</p><p id="8fbf" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">单词嵌入层的维度&amp;LSTM的节点数量— </strong>我任意使用64个维度来嵌入标题和摘要生成。</p><p id="eb92" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">回想起来，为了更好的性能，我应该为概要增加这个值，因为知道对于概要训练数据有24，900个样本(即反映特定序列中2500个单词标记的不同排列),而对于500个标题单词标记有593个序列。</p><p id="54da" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> GAN模型架构&amp;训练方法</strong>——一般来说，GAN模型，比如我用来生成图像的那个模型，<a class="ae ip" href="https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628" rel="noopener" target="_blank">真的很难训练</a>。有很多文章采用了不同的方法，我还没有尝试过:</p><p id="c0f8" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">-改变生成器和鉴别器之间的学习速率(在我使用的例子中，我保持它们相同)</p><p id="cb50" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">-使用不同的损失函数(称为<a class="ae ip" rel="noopener" href="/@jonathan_hui/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490#:~:text=So%20to%20calculate%20the%20Wasserstein,find%20a%201%2DLipschitz%20function.&amp;text=Indeed%2C%20this%20network%20is%20very,real%20the%20input%20images%20are">瓦瑟斯坦距离</a>)与我使用的二元交叉熵</p><p id="012f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">-在生成器和鉴别器之间平衡权重更新(我复制的例子使用了基本的迷你批量训练策略，但是显然一些机器学习专家对鉴别器的每次更新进行两次或三次生成器更新。)</p><p id="8d46" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">-我似乎也经历了GAN训练的所有常见问题，例如<a class="ae ip" href="https://machinelearningmastery.com/practical-guide-to-gan-failure-modes" rel="noopener ugc nofollow" target="_blank">未能收敛</a>，与鉴别器模型精度相比，发电机模型精度似乎过大且波动</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es nk"><img src="../Images/762aa9f7499fcb6fc95cbf3088de8c80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*q3JE1eSOCxcRDLbavAnlcg.png"/></div></figure><p id="c15f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我想我也有“<a class="ae ip" href="https://developers.google.com/machine-learning/gan/problems" rel="noopener ugc nofollow" target="_blank">模式崩溃”</a>的5000 Epoch运行，所有的样本图像是由发电机输出看起来太相似。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nl"><img src="../Images/b3567442a772ae2709ed5d60feb029ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sEgGBUpOUaRc4sWf8GfUpA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">模式崩溃的迹象？对你来说，这三张照片看起来都像一个留着长长飘逸头发的令人毛骨悚然的大胡子男人吗？</figcaption></figure><p id="3cc6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">然而，当我最终决定为最终版本运行10，000个纪元的训练时，这个问题就不那么明显了。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nm"><img src="../Images/15804b35ec544eb4076c79b3af1bde63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*19bXE9kk1WXg2JUWEbSiZg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">多一点变化——左边和右边看起来像愤怒的骆驼脸，而中间看起来像树枝上的鸟…</figcaption></figure><h2 id="0e41" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated"><strong class="ak"> 3.4了解“自行构建”与打包解决方案之间的权衡</strong></h2><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es nn"><img src="../Images/59c0379a2032c693e830b97fdcfdd614.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*64KyFnT0yOv3AY_QFR5Mag.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:<a class="ae ip" href="https://www.123rf.com/stock-photo/tradeoff.html" rel="noopener ugc nofollow" target="_blank">123rf.com</a></figcaption></figure><p id="b0df" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">打包解决方案很棒，但通常有用的功能是在付费墙后面。</p><p id="fcb5" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">例如，在上一节中，我提到了ParseHub是如何使网页抓取过程变得更加容易的，但是最终下载的图片是一个只有在付费墙后才可用的特性。</p><p id="31bb" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">事后看来，2020年，我可能会更好地使用一家主要云公司的端到端完全托管解决方案。例如，通过GCP或AWS，您可以在他们的ML Ops平台上训练Tensorflow模型，并让它与谷歌的应用引擎和AWS的Lambda中的部署脚本相连接</p><p id="32ee" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">然而，中间解决方案(使用混合的打包服务和构建自己的“清理”后处理)确实提供了一些灵活性和潜在的成本节约，只要知道权衡是什么。</p><h2 id="4025" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">3.5端到端机器学习开发/部署/运营需要非常不同的技能组合</h2><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es no"><img src="../Images/0bd7504c2349bf4235a63192034f2d60.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Lbw6r9hYGpIC6YASIOo9mA.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:<a class="ae ip" href="https://www.publicdomainpictures.net/en/view-image.php?image=2681&amp;picture=swiss-army-knife" rel="noopener ugc nofollow" target="_blank"> PublicDomainPictures </a></figcaption></figure><p id="d321" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我在智力上已经知道了这一点，但直到尝试了所有不同的步骤，甚至是这个简单的“玩具”应用程序，我才真正开始欣赏。</p><p id="b06c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">仅仅是阅读专业人士如何部署机器学习模型就让我意识到有太多东西需要学习。我选择了一个非常简单的方法——转储整个脚本(包括TF模型)并运行它，但正确的方法可能是通过两个文本和图像模型的<a class="ae ip" href="https://www.docker.com/resources/what-container" rel="noopener ugc nofollow" target="_blank">容器化</a>(即<a class="ae ip" href="https://kubernetes.io" rel="noopener ugc nofollow" target="_blank"> Kubernetes </a>)来建立微服务，然后从前端网站调用它们进行输出。(或者，如果定制不是问题，使用托管服务，如谷歌的应用引擎或AWS的Lambda也可以)</p><p id="243f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">另一个例子是关于数据收集步骤——如果我真的想大规模地进行网络搜集(即不仅仅是100个，而是1000个样本) ,我肯定需要更好地理解如何设置请求头和使用代理IP地址，以避免被网站当作机器人“赶走”。</p><h2 id="8080" class="ly ir hi bd is lz ma mb iw mc md me ja jz mf mg je kd mh mi ji kh mj mk jm ml bi translated">4.结论</h2><p id="ea18" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">那么(对我来说)值得吗？简而言之，是的。</p><p id="0e26" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">1.通过尝试所有不同的步骤，我无疑获得了“更丰富”的学习体验。我认为至少从头到尾熟悉解决方案选项和决策过程是有好处的，因为这可能有助于在大型团队中工作时理解如何更好地优化您的“链中的一环”。</p><p id="fdf9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">2.我还从调整超参数的角度获得了一些关于使用神经网络的细微差别，这些是我仅仅通过运行整洁的教程/示例代码无法获得的。</p><p id="c0c7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">3.显然，山寨动画生成器有点像是一个没有人真正依赖的一次性应用程序。这就是为什么我可以用“质量差”的图像和使用“缓存”的样本(而不是实时模型推断)来逃避责任。也就是说，任何最终的解决方案都确实取决于对您预期的用户需求和行为的了解，例如，预测流量水平、人们将如何使用结果等，并决定您可以接受什么(可靠性、延迟、安全/隐私问题等)。</p><p id="c8bb" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">4.不幸的是，至于<a class="ae ip" href="http://zhijingeu.pythonanywhere.com" rel="noopener ugc nofollow" target="_blank">网站</a>是否会给公众带来任何娱乐，这还有待观察…让我知道你在评论中的想法吧！</p><p id="0872" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果您正在寻找代码，这里有github repo:</p><p id="0d40" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">https://github.com/ZhijingEu/Fake_Anime_Generator<a class="ae ip" href="https://github.com/ZhijingEu/Fake_Anime_Generator/" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>