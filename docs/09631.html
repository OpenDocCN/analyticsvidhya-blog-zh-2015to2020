<html>
<head>
<title>Hyderabad AQI Prediction Project From Scratch To Deployment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">海得拉巴AQI预测项目从无到有</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hyderabad-aqi-prediction-project-from-scratch-to-deployment-63f64106745b?source=collection_archive---------5-----------------------#2020-09-14">https://medium.com/analytics-vidhya/hyderabad-aqi-prediction-project-from-scratch-to-deployment-63f64106745b?source=collection_archive---------5-----------------------#2020-09-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0d22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">空气质量指数预测</p><p id="d241" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">目录:</p><p id="611b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">㈠导言</p><p id="483b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">㈡项目的动机</p><p id="339b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">㈢数据收集</p><p id="d314" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">㈣数据预处理</p><p id="e286" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">㈤特征的重要性</p><p id="dba0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">㈥模型制作</p><p id="1e90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">㈦使用streamlit进行部署</p><p id="6bab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">㈧结论</p><p id="d02a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">㈨参考资料</p><h1 id="a3b7" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">(一)简介</strong></h1><p id="6d2a" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">空气是许多气体和尘埃粒子的混合物。它是生物赖以生存和呼吸的透明气体。空气是由大约78%的氮气、21%的氧气、0.9%的氩气、0.04%的二氧化碳和非常少量的其他气体组成的混合物。</p><p id="eab7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">空气质量</strong>用<strong class="ih hj">空气质量</strong> <strong class="ih hj">指数(PM 2.5) </strong>来衡量</p><p id="4cef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PM 2.5是一种细小的颗粒物质，是一种空气污染物，当空气中的PM 2.5含量很高时，人们的健康就会受到影响。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/7e43656afd9fea9d3f62b83caebf4427.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*fKsw211JjtNEWqT0LdIexg.jpeg"/></div></figure><h1 id="4b15" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">(二)项目动机:</strong></h1><p id="be8d" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">由于COVID，世界上没有交通工具，因为空气非常新鲜。我目前住在海德拉巴，这是印度污染最严重的城市，但最近这里的空气也很清新，我在想，现在的空气是多么清新，去年的空气质量如何？去年的空气质量如何？从这个想法出发，这个项目诞生了。</p><h1 id="ae7f" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">(三)数据收集:</strong></h1><p id="e90f" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我使用请求模块从2013年到2018年从<a class="ae ko" href="https://en.tutiempo.net/climate/ws-431280.html" rel="noopener ugc nofollow" target="_blank">https://en.tutiempo.net/climate/ws-431280.html</a>收集数据</p><p id="efc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我创建了一个函数来收集HTML格式的网站数据</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="a719" class="ku je hi kq b fi kv kw l kx ky">import os <br/>import time<br/>import sys<br/>import requests</span><span id="3054" class="ku je hi kq b fi kz kw l kx ky">def data_collection():<br/> for year in range(2013,2019): # for loop for year range<br/> for month in range(1,13): # for loop for month range<br/> if (month&lt;10):<br/> # Condition for if month number below 10<br/> url=’<a class="ae ko" href="https://en.tutiempo.net/climate/0{}-{}/ws-431280.html'.format(month,year)" rel="noopener ugc nofollow" target="_blank">https://en.tutiempo.net/climate/0{}-{}/ws-431280.html'.format(month,year)</a> <br/> else:<br/> # Condition for 10 to 12 months<br/> url=’<a class="ae ko" href="https://en.tutiempo.net/climate/{}-{}/ws-431280.html'.format(month,year)" rel="noopener ugc nofollow" target="_blank">https://en.tutiempo.net/climate/{}-{}/ws-431280.html'.format(month,year)</a><br/> <br/> collected_texts=requests.get(url) # using requests we get the html data into collected_texts variable<br/> collected_text_utf=collected_texts.text.encode(‘utf=8’) # our html contains so many data types so we use utf8 encoding<br/> <br/> # after getting data we need to store the data in a directory so for that we create Html_data directory with year directory<br/> if not os.path.exists(“Data_collection/Html_data/{}”.format(year)):<br/> os.makedirs(“Data_collection/Html_data/{}”.format(year))<br/> <br/> # To store that we need to open the directory<br/> with open (“Data_collection/Html_data/{}/{}.html”.format(year,month),’wb’) as Result:<br/> Result.write(collected_text_utf)<br/> <br/> sys.stdout.flush()</span><span id="8c07" class="ku je hi kq b fi kz kw l kx ky">if __name__==”__main__”:<br/> start_time=time.time()<br/> data_collection() # function calling <br/> stop_time=time.time()<br/> print(‘Time Taken {}’.format(stop_time-start_time)) # Time taken to store the data</span></pre><p id="f797" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行上述功能，我收集了2013年至2018年HTML格式的数据</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es la"><img src="../Images/44c11b14fdd77ab083fe97de5acf784b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DUIoALquKj57UjttYegr6Q.png"/></div></div></figure><p id="bb52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行上述函数会在该目录中创建目录Html_data，我们将2013年至2018年的每年数据放在单独的文件夹中</p><p id="2beb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Html数据中，我们有T =平均温度(°C)，TM =最高温度(°C)，Tm ==最低温度(°C)，SLP =海平面气压(hPa)，H =平均相对湿度(%)，VV =平均能见度(Km)，V =平均风速(Km/h)，VM =最大持续风速(Km/h)。</p><p id="b0fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还需要PM 2.5值，PM 2.5值是从2013年到2018年的付费API中收集的</p><p id="8ddb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想要PM 2.5数据，请访问下面的GitHub链接</p><p id="c595" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ko" href="https://github.com/jani-excergy/Complete_Data_Science_Life_Cycle_Projects/tree/master/Data_collection" rel="noopener ugc nofollow" target="_blank">https://github . com/jani-excel gy/Complete _ Data _ Science _ Life _ Cycle _ Projects/tree/master/Data _ collection</a></p><p id="3902" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PM 2.5 (AQI)是一个依赖特性</p><p id="722c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">t，TM，Tm，SLP，H，VV。VM、V是独立的特征</p><p id="ecb5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的从属特征属于实值，所以现在我们需要解决回归问题</p><p id="0f74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有每小时的PM 2.5值，所以首先，我们需要将小时值转换为一天值</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="d922" class="ku je hi kq b fi kv kw l kx ky">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="1c7c" class="ku je hi kq b fi kz kw l kx ky">def Day_values_2013():<br/> temp_i=0<br/> average=[]<br/> for rows in pd.read_csv(r’C:\Users\Unify\Desktop\janibasha\Complete Data Science life cycle\Data_collection\AQI\aqi2013.csv’,chunksize=24):<br/> add_var=0<br/> avg=0.0<br/> data=[]<br/> df=pd.DataFrame(data=rows)<br/> for index,row in df.iterrows():<br/> data.append(row[‘PM2.5’])<br/> for i in data:<br/> if type(i) is float or type(i) is int:<br/> add_var=add_var+i<br/> elif type(i) is str:<br/> if i!=’NoData’ and i!=’PwrFail’ and i!=’ — -’ and i!=’InVld’:<br/> temp=float(i)<br/> add_var=add_var+temp<br/> avg=add_var/24<br/> temp_i=temp_i+1<br/> <br/> average.append(avg)<br/> return average</span><span id="c86d" class="ku je hi kq b fi kz kw l kx ky">def Day_values_2014():<br/> temp_i=0<br/> average=[]<br/> for rows in pd.read_csv(r’C:\Users\Unify\Desktop\janibasha\Complete Data Science life cycle\Data_collection\AQI\aqi2014.csv’,chunksize=24):<br/> add_var=0<br/> avg=0.0<br/> data=[]<br/> df=pd.DataFrame(data=rows)<br/> for index,row in df.iterrows():<br/> data.append(row[‘PM2.5’])<br/> for i in data:<br/> if type(i) is float or type(i) is int:<br/> add_var=add_var+i<br/> elif type(i) is str:<br/> if i!=’NoData’ and i!=’PwrFail’ and i!=’ — -’ and i!=’InVld’:<br/> temp=float(i)<br/> add_var=add_var+temp<br/> avg=add_var/24<br/> temp_i=temp_i+1<br/> <br/> average.append(avg)<br/> return average</span><span id="6814" class="ku je hi kq b fi kz kw l kx ky">def Day_values_2015():<br/> temp_i=0<br/> average=[]<br/> for rows in pd.read_csv(r’C:\Users\Unify\Desktop\janibasha\Complete Data Science life cycle\Data_collection\AQI\aqi2015.csv’,chunksize=24):<br/> add_var=0<br/> avg=0.0<br/> data=[]<br/> df=pd.DataFrame(data=rows)<br/> for index,row in df.iterrows():<br/> data.append(row[‘PM2.5’])<br/> for i in data:<br/> if type(i) is float or type(i) is int:<br/> add_var=add_var+i<br/> elif type(i) is str:<br/> if i!=’NoData’ and i!=’PwrFail’ and i!=’ — -’ and i!=’InVld’:<br/> temp=float(i)<br/> add_var=add_var+temp<br/> avg=add_var/24<br/> temp_i=temp_i+1<br/> <br/> average.append(avg)<br/> return average</span><span id="722a" class="ku je hi kq b fi kz kw l kx ky">def Day_values_2016():<br/> temp_i=0<br/> average=[]<br/> for rows in pd.read_csv(r’C:\Users\Unify\Desktop\janibasha\Complete Data Science life cycle\Data_collection\AQI\aqi2016.csv’,chunksize=24):<br/> add_var=0<br/> avg=0.0<br/> data=[]<br/> df=pd.DataFrame(data=rows)<br/> for index,row in df.iterrows():<br/> data.append(row[‘PM2.5’])<br/> for i in data:<br/> if type(i) is float or type(i) is int:<br/> add_var=add_var+i<br/> elif type(i) is str:<br/> if i!=’NoData’ and i!=’PwrFail’ and i!=’ — -’ and i!=’InVld’:<br/> temp=float(i)<br/> add_var=add_var+temp<br/> avg=add_var/24<br/> temp_i=temp_i+1<br/> <br/> average.append(avg)<br/> return average</span><span id="45a1" class="ku je hi kq b fi kz kw l kx ky">def Day_values_2017():<br/> temp_i=0<br/> average=[]<br/> for rows in pd.read_csv(r’C:\Users\Unify\Desktop\janibasha\Complete Data Science life cycle\Data_collection\AQI\aqi2017.csv’,chunksize=24):<br/> add_var=0<br/> avg=0.0<br/> data=[]<br/> df=pd.DataFrame(data=rows)<br/> for index,row in df.iterrows():<br/> data.append(row[‘PM2.5’])<br/> for i in data:<br/> if type(i) is float or type(i) is int:<br/> add_var=add_var+i<br/> elif type(i) is str:<br/> if i!=’NoData’ and i!=’PwrFail’ and i!=’ — -’ and i!=’InVld’:<br/> temp=float(i)<br/> add_var=add_var+temp<br/> avg=add_var/24<br/> temp_i=temp_i+1<br/> <br/> average.append(avg)<br/> return average</span><span id="647a" class="ku je hi kq b fi kz kw l kx ky">def Day_values_2018():<br/> temp_i=0<br/> average=[]<br/> for rows in pd.read_csv(r’C:\Users\Unify\Desktop\janibasha\Complete Data Science life cycle\Data_collection\AQI\aqi2018.csv’,chunksize=24):<br/> add_var=0<br/> avg=0.0<br/> data=[]<br/> df=pd.DataFrame(data=rows)<br/> for index,row in df.iterrows():<br/> data.append(row[‘PM2.5’])<br/> for i in data:<br/> if type(i) is float or type(i) is int:<br/> add_var=add_var+i<br/> elif type(i) is str:<br/> if i!=’NoData’ and i!=’PwrFail’ and i!=’ — -’ and i!=’InVld’:<br/> temp=float(i)<br/> add_var=add_var+temp<br/> avg=add_var/24<br/> temp_i=temp_i+1<br/> <br/> average.append(avg)<br/> return average</span><span id="d9b8" class="ku je hi kq b fi kz kw l kx ky">if __name__==”__main__”:<br/> lst2013=Day_values_2013()<br/> lst2014=Day_values_2014()<br/> lst2015=Day_values_2015()<br/> lst2016=Day_values_2016()<br/> lst2017=Day_values_2017()<br/> lst2018=Day_values_2018()<br/> plt.plot(range(0,365),lst2013,label=”2013 data”)<br/> plt.plot(range(0,364),lst2014,label=”2014 data”)<br/> plt.plot(range(0,365),lst2015,label=”2015 data”)<br/> plt.plot(range(0,365),lst2016,label=”2016 data”)<br/> plt.xlabel(‘Day’)<br/> plt.ylabel(‘PM 2.5’)<br/> plt.legend(loc=’upper right’)<br/> plt.show()</span></pre><p id="ebee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行上述函数，我们得到每年每天的PM 2.5值</p><p id="df23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们得到一个从属特征</p><p id="322b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们需要从Html中提取独立的特征，为此我使用Beautifulsoup将Html数据解析成一个CSV文件</p><p id="21bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将独立特性收集到CSV中后，我们需要将相关特性PM 2.5添加到该CSV文件中</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="b07a" class="ku je hi kq b fi kv kw l kx ky">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import requests<br/>from Hours_to_Day import Day_values_2013,Day_values_2014,Day_values_2015,Day_values_2016,Day_values_2017,Day_values_2018<br/>import sys<br/>from bs4 import BeautifulSoup<br/>import os<br/>import csv</span><span id="4bdc" class="ku je hi kq b fi kz kw l kx ky">def html_scraping(month,year):<br/> <br/> # To scrap the data we need to give the path of flies<br/> file_path=open(‘Data_collection/Html_data/{}/{}.html’.format(year,month),’rb’)<br/> <br/> #After scraping the data we need to store it in a variable<br/> <br/> Scaraped_data=file_path.read()<br/> <br/> # Now I create two empty lists for future purpose<br/> <br/> Sample_data=[]<br/> Finale_data=[]</span><span id="a24c" class="ku je hi kq b fi kz kw l kx ky"># Now I intialise the beautifulsoup class beautifulsoup(Scrapedtext,filetype)<br/> <br/> soup=BeautifulSoup(Scaraped_data,”lxml”)<br/> <br/> # We need the table data from html so we loop through the table tag and it’s class from scraped html data<br/> <br/> for table in soup.findAll(‘table’,{‘class’:’medias mensuales numspan’}):<br/> <br/> # In table data we need body of the table to find the features so we loop through the table body<br/> <br/> for tbody in table:<br/> <br/> # In table body we need the rows to get features data so we loop through the table rows<br/> <br/> for tr in tbody:<br/> <br/> # Now we extract the row data <br/> <br/> Extract_data=tr.get_text()<br/> <br/> # Now we append the row data into Sample_data list<br/> <br/> Sample_data.append(Extract_data)<br/> <br/> <br/> # If we manually check in the html we have 15 features so to check the if we are getting 15 features or not<br/> # No of row<br/> <br/> No_rows=len(Sample_data)/15<br/> <br/> <br/> # Now to get the feature values first we need to go through the rows so we loop through the rows<br/> for iterate in range(round(No_rows)):<br/> <br/> # Creating empty list store feature values of each rows<br/> <br/> lst=[]<br/> <br/> # we loop through the feature to get each value <br/> <br/> for i in range(15):<br/> # we add the each row data in to empty lst<br/> <br/> <br/> lst.append(Sample_data[0])<br/> <br/> #Now we remove data from Sample_data<br/> <br/> Sample_data.pop(0)<br/> <br/> # Now we we add the each row values of 15 features in Finale list <br/> <br/> Finale_data.append(lst)</span><span id="26ad" class="ku je hi kq b fi kz kw l kx ky">Length_Finale_data=len(Finale_data)<br/> <br/> Finale_data.pop(Length_Finale_data-1)<br/> Finale_data.pop(0)<br/> <br/> # Now we remove the empty features from table beacause this features doesn’t contain any value<br/> <br/> for feature in range(len(Finale_data)):<br/> Finale_data[feature].pop(6)<br/> Finale_data[feature].pop(13)<br/> Finale_data[feature].pop(12)<br/> Finale_data[feature].pop(11)<br/> Finale_data[feature].pop(10)<br/> Finale_data[feature].pop(9)<br/> Finale_data[feature].pop(0)<br/> <br/> return Finale_data</span><span id="78c1" class="ku je hi kq b fi kz kw l kx ky"># Once scrapiing the html table data<br/># html table features are independet variables<br/># Hours_to_Day PM2.5 feature is dependent features<br/># we need to combine both independent features and dependent features in csv file<br/># for that we write a data</span><span id="706a" class="ku je hi kq b fi kz kw l kx ky">def combine_dependent_independent(year, cs):<br/> for i in pd.read_csv(‘Data_collection/Html_scraping_data/real_’ + str(year) + ‘.csv’, chunksize=cs):<br/> df = pd.DataFrame(data=i)<br/> mylist = df.values.tolist()<br/> return mylist</span><span id="3647" class="ku je hi kq b fi kz kw l kx ky">if __name__==”__main__”:<br/> <br/> # We need to create a directory to store the csv files <br/> if not os.path.exists(“Data_collection/Html_scraping_data”):<br/> os.makedirs(“Data_collection/Html_scraping_data”)<br/> <br/> <br/> # After creating directory we need to write the csv file <br/> # we need years from 2013 t0 2018 so for that we create loop for year<br/> for year in range(2013,2019):<br/> final_data=[]<br/> with open (“Data_collection/Html_scraping_data/real_”+str(year)+”.csv”,’w’) as csvfile:<br/> writting_csv=csv.writer(csvfile, dialect=’excel’)<br/> writting_csv.writerow([‘T’,’TM’,’Tm’,’SLP’,’H’,’VV’,’V’,’VM’,’PM2.5'])<br/> <br/> <br/> # To add the data to the csv files we call the html_scraping function <br/> for month in range(1,13):<br/> temp=html_scraping(month, year)<br/> final_data=final_data+temp<br/> <br/> # To get PM2.5 avg values we need to call the corresponding function <br/> # For the we dinamically write it with getattr<br/> <br/> dependent=getattr(sys.modules[__name__], ‘Day_values_{}’.format(year))()<br/> <br/> # To add the dependent feature PM2.5 to the independent features <br/> for i in range(len(final_data)-1):<br/> final_data[i].insert(8,dependent[i])<br/> <br/> with open(‘Data_collection/Html_scraping_data/real_’ + str(year) + ‘.csv’, ‘a’) as csvfile:<br/> wr = csv.writer(csvfile, dialect=’excel’)<br/> for row in final_data:<br/> flag = 0<br/> for elem in row:<br/> if elem == “” or elem == “-”:<br/> flag = 1<br/> if flag != 1:<br/> wr.writerow(row)<br/> <br/> <br/> # We call the combine_dependent_independent function to combine the both <br/> data_2013 = combine_dependent_independent(2013, 600)<br/> data_2014 = combine_dependent_independent(2014, 600)<br/> data_2015 = combine_dependent_independent(2015, 600)<br/> data_2016 = combine_dependent_independent(2016, 600)<br/> data_2017 = combine_dependent_independent(2017, 600)<br/> data_2018 = combine_dependent_independent(2018, 600)<br/> <br/> <br/> # combining the all years data into single csv<br/> total=data_2013+data_2014+data_2015+data_2016+data_2017+data_2018<br/> <br/> with open(‘Data_collection/Html_scraping_data/Real_Combine.csv’, ‘w’) as csvfile:<br/> wr = csv.writer(csvfile, dialect=’excel’)<br/> wr.writerow(<br/> [‘T’, ‘TM’, ‘Tm’, ‘SLP’, ‘H’, ‘VV’, ‘V’, ‘VM’, ‘PM 2.5’])<br/> wr.writerows(total)<br/> <br/> <br/>df=pd.read_csv(‘Data/Real-Data/Real_Combine.csv’)</span></pre><p id="f774" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在将PM 2.5值删除并附加到CSV之后，我们得到了每个单独年份的CSV文件</p><p id="3a4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将所有年份的数据合并到一个CSV中</p><p id="ed1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们终于得到了Real_combine.csv文件</p><p id="c26b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用这些数据建立ML应用程序来预测未来AQI</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lf"><img src="../Images/71eff18faf3d0168ef9145baffae75b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pZ4fcKLc8h2ZOgO5YZZdYA.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">Real_combine.csv示例数据</figcaption></figure><h1 id="ca72" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">(四)数据预处理:</strong></h1><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="c33b" class="ku je hi kq b fi kv kw l kx ky">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="e058" class="ku je hi kq b fi kz kw l kx ky"># Reading csv file</span><span id="1a4b" class="ku je hi kq b fi kz kw l kx ky">combine_data= pd.read_csv(r'C:\Users\Desktop\janibasha\Complete Data Science life cycle\Data_collection\Html_scraping_data\Real_combine.csv')<br/></span><span id="cc2a" class="ku je hi kq b fi kz kw l kx ky"># checking no of numerical features<br/>combine_data.info()</span><span id="0d7e" class="ku je hi kq b fi kz kw l kx ky"># To get statistical information<br/>combine_data.describe()</span><span id="6cb0" class="ku je hi kq b fi kz kw l kx ky"># Now we need check null values<br/>combine_data.isnull()<br/>combine_data.isnull().sum()</span><span id="2149" class="ku je hi kq b fi kz kw l kx ky"># we also visualize null with seaborn</span><span id="a929" class="ku je hi kq b fi kz kw l kx ky">sns.heatmap(combine_data.isnull(),yticklabels=False)</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lk"><img src="../Images/888739594193279ed02ca31b3fcbe619.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*6VAM9cnQAR3mcRhoXGjrqQ.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">可视化数据框中的空值</figcaption></figure><p id="1816" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过可视化，我们了解到数据框中没有任何空值。</p><p id="afbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有所有的数字特征，没有分类特征，所以不需要编码</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="ccd6" class="ku je hi kq b fi kv kw l kx ky"># checking outliers </span><span id="6481" class="ku je hi kq b fi kz kw l kx ky">combine_data.boxplot(column=’Tm’)<br/>plt.show()</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ll"><img src="../Images/95e7d6f15dff5dd52d94cb01b2720086.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*POS0MofzabyHgmuFSUrlRQ.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">异常值检查</figcaption></figure><p id="2dd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，我们可以检查每个特性的异常值</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="6920" class="ku je hi kq b fi kv kw l kx ky"># Multivariate anlaysis</span><span id="f28f" class="ku je hi kq b fi kz kw l kx ky">sns.pairplot(combine_data)</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lm"><img src="../Images/40ad15842bf44c4b681224868679398a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gqPLdeFa2bF0neRfXgu3eA.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">相关(y轴)与独立(x轴)特征之间的多元分析</figcaption></figure><p id="7b65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们观察上面的分析，在独立和从属特征之间没有线性关系，所以线性算法不会给出好的结果</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="674d" class="ku je hi kq b fi kv kw l kx ky"># We also check the corelation between dependent and independent feature</span><span id="16dd" class="ku je hi kq b fi kz kw l kx ky">combine_data.corr()<br/>relation =combine_data.corr()<br/>relation_index=relation.index</span><span id="98af" class="ku je hi kq b fi kz kw l kx ky">sns.heatmap(combine_data[relation_index].corr(),annot=True)</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ln"><img src="../Images/805563dce7ac19ccca906663daaa5051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*54ur-iBQeAd524EBXttKrw.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">相关热图</figcaption></figure><p id="f7ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的热图中，我们了解了非独立要素(PM 2.5)和独立要素(T、Tm、TM、SLP、H、VV、V、VM)之间的关系</p><h1 id="199f" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">(五)特征重要性:</strong></h1><p id="f2d2" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我们有8个独立的特征，我们不知道哪个特征对预测PM 2.5值重要。</p><p id="b57b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了知道特征的重要性，我们使用ExtraTreesRegressor(基于模型的特征选择)</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="b275" class="ku je hi kq b fi kv kw l kx ky">from sklearn.ensemble import ExtraTreesRegressor<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import accuracy_score as acc</span><span id="709d" class="ku je hi kq b fi kz kw l kx ky">reg= ExtraTreesRegressor()</span><span id="35d1" class="ku je hi kq b fi kz kw l kx ky">reg.fit(X_train,y_train)</span><span id="faa9" class="ku je hi kq b fi kz kw l kx ky">reg.feature_importances_</span><span id="ece3" class="ku je hi kq b fi kz kw l kx ky">feat_importances = pd.Series(reg.feature_importances_, index=X_train.columns)<br/>feat_importances.nlargest(5).plot(kind='barh')<br/>plt.show()</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lo"><img src="../Images/f85d24e3deb6a4fd4f2330e5b8041074.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*M7AXsY-ZS3m3Tm3vxvJXPw.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">预测PM 2.5的五大特征(基于模型的特征选择)</figcaption></figure><h1 id="b27f" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">(六)模型建筑:</strong></h1><p id="f4f1" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我们只有8个功能，所以对于模型的建立，我考虑所有的功能，并检查不同模型的性能</p><p id="d8dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在部署时，我们针对前5大功能训练模型，并将其部署在任何云平台上</p><p id="ae6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">①KNN回归量:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lp"><img src="../Images/b21d1248edfeb9cee7298212ed6ee5d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5-G_rfgYvo4YO8ewCln0Mg.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">超参数调谐(K)</figcaption></figure><p id="e860" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在k=17之后，有一个稳定的条件，所以我们取K=17</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="bda2" class="ku je hi kq b fi kv kw l kx ky"># weighted knn</span><span id="ddc3" class="ku je hi kq b fi kz kw l kx ky">weighted_tuned_reg = KNeighborsRegressor(n_neighbors=17,weights='distance')</span><span id="83fc" class="ku je hi kq b fi kz kw l kx ky">weighted_tuned_reg.fit(X_train,y_train)</span><span id="ade0" class="ku je hi kq b fi kz kw l kx ky">weighted_tuned_reg.score(X_train,y_train)<br/>1.0</span><span id="d36f" class="ku je hi kq b fi kz kw l kx ky"># performance of model on test dataset<br/>weighted_tuned_reg.score(X_test,y_test)<br/>0.5238963653617966</span><span id="92b7" class="ku je hi kq b fi kz kw l kx ky"># cross validation <br/>from sklearn.model_selection import cross_val_score<br/>score=cross_val_score(weighted_tuned_reg,X,y,cv=5)<br/></span><span id="5850" class="ku je hi kq b fi kz kw l kx ky"># cross validation perfomance<br/>score.mean()<br/>0.43669012578295</span><span id="93d4" class="ku je hi kq b fi kz kw l kx ky"># Model evalutation<br/>prediction=weighted_tuned_reg.predict(X_test)</span><span id="e182" class="ku je hi kq b fi kz kw l kx ky"># Comparing predicted PM2.5 and labeld PM 2.5<br/>plt.scatter(y_test,prediction)</span><span id="65c6" class="ku je hi kq b fi kz kw l kx ky">print('MSE:', metrics.mean_squared_error(y_test, prediction))<br/>MSE: 3247.1281849543693</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ln"><img src="../Images/e2d309b9a446c5e8ee65038cfd9cd720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*aSlBK2IhkcrRUICc3p9PdQ.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">y测试和y预测之间的散点图</figcaption></figure><p id="694c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(2)线性、套索和岭回归量:</p><p id="5a8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归器</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="42ec" class="ku je hi kq b fi kv kw l kx ky">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(combine_data.iloc[:,:-1], combine_data.iloc[:,-1], test_size=0.3, random_state=0)</span><span id="9b2c" class="ku je hi kq b fi kz kw l kx ky">from sklearn.linear_model import LinearRegression</span><span id="0b6c" class="ku je hi kq b fi kz kw l kx ky"># creating linear regression model</span><span id="cc07" class="ku je hi kq b fi kz kw l kx ky">reg_model=LinearRegression(normalize=True)</span><span id="438c" class="ku je hi kq b fi kz kw l kx ky"># fit independent varaibles to the dependent variables<br/>reg_model.fit(X_train,y_train)</span><span id="6a62" class="ku je hi kq b fi kz kw l kx ky">reg_model.score(X_train,y_train)<br/>0.40996129270540077</span><span id="4e02" class="ku je hi kq b fi kz kw l kx ky">reg_model.score(X_test,y_test)<br/>0.3894144479464322</span><span id="7bce" class="ku je hi kq b fi kz kw l kx ky"># for slope</span><span id="7c3f" class="ku je hi kq b fi kz kw l kx ky">reg_model.coef_</span><span id="9daa" class="ku je hi kq b fi kz kw l kx ky">array([-8.71256785, -0.78565823, -0.64082652,  2.64932719, -1.44568242,0.27712587, -1.83610819, -1.01908448])</span><span id="065a" class="ku je hi kq b fi kz kw l kx ky"># for intercept</span><span id="57e0" class="ku je hi kq b fi kz kw l kx ky">reg_model.intercept_<br/>-2180.4321527938205</span><span id="12c7" class="ku je hi kq b fi kz kw l kx ky"># cross validation</span><span id="d467" class="ku je hi kq b fi kz kw l kx ky">from sklearn.model_selection import cross_val_score<br/>score=cross_val_score(reg_model,combine_data.iloc[:,:-1],combine_data.iloc[:,-1],cv=5)</span><span id="594b" class="ku je hi kq b fi kz kw l kx ky">score.mean()<br/>0.3229764710803792</span><span id="e558" class="ku je hi kq b fi kz kw l kx ky">prediction=reg_model.predict(X_test)</span><span id="e4f0" class="ku je hi kq b fi kz kw l kx ky"># checking predicted y and labeled y<br/>plt.scatter(y_test,prediction)</span><span id="202a" class="ku je hi kq b fi kz kw l kx ky">print('MSE:', metrics.mean_squared_error(y_test, prediction))<br/>MSE: 4164.32350260401</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lq"><img src="../Images/450c1864fa5e7dbf7be131a131fd71a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*dUYVqmmw_jegYDv7hzIpdw.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">y_test和y_prediction之间的离差</figcaption></figure><p id="a9e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">岭回归量</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="9f04" class="ku je hi kq b fi kv kw l kx ky"># Randomsearch cv</span><span id="950d" class="ku je hi kq b fi kz kw l kx ky">from sklearn.model_selection import RandomizedSearchCV</span><span id="11c9" class="ku je hi kq b fi kz kw l kx ky">from scipy.stats import randint<br/>parameters={'alpha':randint(1e-8,100)}</span><span id="c9d4" class="ku je hi kq b fi kz kw l kx ky">ridge_reg_1=RandomizedSearchCV(reg_model_1,parameters,scoring='neg_mean_squared_error',cv=5)<br/>ridge_reg_1.fit(combine_data.iloc[:,:-1],combine_data.iloc[:,-1])</span><span id="1654" class="ku je hi kq b fi kz kw l kx ky">ridge_reg_1.best_score_<br/>-4265.905962013921</span><span id="74a5" class="ku je hi kq b fi kz kw l kx ky">ridge_reg_1.best_params_<br/>{'alpha': 75}</span><span id="3caf" class="ku je hi kq b fi kz kw l kx ky">prediction=ridge_reg_1.predict(X_test)</span><span id="a6fe" class="ku je hi kq b fi kz kw l kx ky">plt.scatter(y_test,prediction)</span><span id="a97b" class="ku je hi kq b fi kz kw l kx ky">print('MSE:', metrics.mean_squared_error(y_test, prediction))</span><span id="69f7" class="ku je hi kq b fi kz kw l kx ky">MSE: 3912.4550098306554<br/></span></pre><p id="3415" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">套索回归器</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="6daf" class="ku je hi kq b fi kv kw l kx ky">from sklearn.linear_model import Lasso<br/>from sklearn.model_selection import GridSearchCV</span><span id="bce8" class="ku je hi kq b fi kz kw l kx ky"># Intializing the model <br/>reg_model_2=Lasso()</span><span id="89d6" class="ku je hi kq b fi kz kw l kx ky"># hyper parameter range <br/>hyperparameters_range={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100]}</span><span id="430e" class="ku je hi kq b fi kz kw l kx ky"># Searching best hyper parameter</span><span id="0133" class="ku je hi kq b fi kz kw l kx ky">lasso_reg=GridSearchCV(reg_model_2,hyperparameters_range,scoring='neg_mean_squared_error',cv=5)</span><span id="d81f" class="ku je hi kq b fi kz kw l kx ky">lasso_reg.fit(combine_data.iloc[:,:-1],combine_data.iloc[:,-1])</span><span id="f2f5" class="ku je hi kq b fi kz kw l kx ky">lasso_reg.best_params_<br/>{'alpha': 5}</span><span id="4c38" class="ku je hi kq b fi kz kw l kx ky">lasso_reg.best_score_<br/>-4249.911163771522</span><span id="5819" class="ku je hi kq b fi kz kw l kx ky">prediction = lasso_reg.predict(X_test)</span><span id="7e1b" class="ku je hi kq b fi kz kw l kx ky">plt.scatter(y_test,prediction)</span><span id="ad04" class="ku je hi kq b fi kz kw l kx ky">print('MSE:', metrics.mean_squared_error(y_test, prediction))<br/>MSE: 3922.586481270448</span></pre><p id="25ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(3)决策树回归器:</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="e3b5" class="ku je hi kq b fi kv kw l kx ky">from sklearn.tree import DecisionTreeRegressor</span><span id="cadf" class="ku je hi kq b fi kz kw l kx ky"># creating Decision tree regression model</span><span id="eab0" class="ku je hi kq b fi kz kw l kx ky">reg_decision_model=DecisionTreeRegressor()</span><span id="3b87" class="ku je hi kq b fi kz kw l kx ky"># Hyper parameters range intialization for tuning</span><span id="cb19" class="ku je hi kq b fi kz kw l kx ky">parameters={"splitter":["best","random"],<br/>            "max_depth" : [1,3,5,7,9,11,12],<br/>           "min_samples_leaf":[1,2,3,4,5,6,7,8,9,10],<br/>           "min_weight_fraction_leaf":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],<br/>           "max_features":["auto","log2","sqrt",None],<br/>           "max_leaf_nodes":[None,10,20,30,40,50,60,70,80,90] }</span><span id="642f" class="ku je hi kq b fi kz kw l kx ky"># calculating different regression metrics</span><span id="03fa" class="ku je hi kq b fi kz kw l kx ky">from sklearn.model_selection import GridSearchCV</span><span id="ea3c" class="ku je hi kq b fi kz kw l kx ky">tuning_model=GridSearchCV(reg_decision_model,param_grid=parameters,scoring='neg_mean_squared_error',n_jobs=-1,cv=10,verbose=3)</span><span id="aaa5" class="ku je hi kq b fi kz kw l kx ky"># function for calculating how much time take for hyperparameter tuning</span><span id="6df4" class="ku je hi kq b fi kz kw l kx ky">def timer(start_time=None):<br/>    if not start_time:<br/>        start_time=datetime.now()<br/>        return start_time<br/>    elif start_time:<br/>        thour,temp_sec=divmod((datetime.now()-start_time).total_seconds(),3600)<br/>        tmin,tsec=divmod(temp_sec,60)<br/>        print(thour,":",tmin,':',round(tsec,2))</span><span id="35d5" class="ku je hi kq b fi kz kw l kx ky">X=combine_data.iloc[:,:-1]</span><span id="cfaf" class="ku je hi kq b fi kz kw l kx ky">y=combine_data.iloc[:,-1]</span><span id="3f8f" class="ku je hi kq b fi kz kw l kx ky">from datetime import datetime</span><span id="d304" class="ku je hi kq b fi kz kw l kx ky">start_time=timer(None)</span><span id="5fae" class="ku je hi kq b fi kz kw l kx ky">tuning_model.fit(X,y)</span><span id="2b17" class="ku je hi kq b fi kz kw l kx ky">timer(start_time)</span><span id="945c" class="ku je hi kq b fi kz kw l kx ky">tuning_model.best_params_</span><span id="be60" class="ku je hi kq b fi kz kw l kx ky">{'max_depth': 9,<br/> 'max_features': None,<br/> 'max_leaf_nodes': 20,<br/> 'min_samples_leaf': 8,<br/> 'min_weight_fraction_leaf': 0.1,<br/> 'splitter': 'random'}</span><span id="08a4" class="ku je hi kq b fi kz kw l kx ky">tuning_model.best_score_<br/>-3621.0007087939457</span><span id="9bf2" class="ku je hi kq b fi kz kw l kx ky"># Model Evaluation</span><span id="71f4" class="ku je hi kq b fi kz kw l kx ky">prediction=tuning_model.predict(X_test)</span><span id="e7a3" class="ku je hi kq b fi kz kw l kx ky">print('MSE:', metrics.mean_squared_error(y_test, prediction))</span><span id="c2ee" class="ku je hi kq b fi kz kw l kx ky">MSE: 4589.011220616968</span></pre><p id="768e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(4)随机森林回归量</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="3582" class="ku je hi kq b fi kv kw l kx ky"># Hyperparameter tuning with RandomizedSearchCV</span><span id="e061" class="ku je hi kq b fi kz kw l kx ky">from sklearn.model_selection import RandomizedSearchCV</span><span id="f5c7" class="ku je hi kq b fi kz kw l kx ky"># Hyparameter ranges</span><span id="67c3" class="ku je hi kq b fi kz kw l kx ky">from scipy.stats import randint</span><span id="2c90" class="ku je hi kq b fi kz kw l kx ky">parameters = {'n_estimators': randint(100,1200),<br/>               'max_features': ['auto','sqrt'],<br/>               'max_depth': randint(5,40),<br/>               'min_samples_split': randint(2,30),<br/>               'min_samples_leaf': randint(1,10)  }</span><span id="61b6" class="ku je hi kq b fi kz kw l kx ky"># Model for tuning</span><span id="7aac" class="ku je hi kq b fi kz kw l kx ky">base_learner=RandomForestRegressor()</span><span id="ae57" class="ku je hi kq b fi kz kw l kx ky"># Tuning</span><span id="9297" class="ku je hi kq b fi kz kw l kx ky">tuned_model= RandomizedSearchCV(estimator = base_learner, param_distributions = parameters,scoring='neg_mean_squared_error', n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs =-1)</span><span id="2377" class="ku je hi kq b fi kz kw l kx ky">tuned_model.fit(X_train,y_train)</span><span id="6d93" class="ku je hi kq b fi kz kw l kx ky">tuned_model.best_params_</span><span id="f909" class="ku je hi kq b fi kz kw l kx ky">{'max_depth': 5,<br/> 'max_features': 'sqrt',<br/> 'min_samples_leaf': 1,<br/> 'min_samples_split': 16,<br/> 'n_estimators': 901}</span><span id="7ab9" class="ku je hi kq b fi kz kw l kx ky">tuned_model.best_score_<br/>-3425.3665578465598</span><span id="fcae" class="ku je hi kq b fi kz kw l kx ky"># Predicting X_test values using tuned_model<br/>prediction=tuned_model.predict(X_test)</span><span id="4989" class="ku je hi kq b fi kz kw l kx ky">plt.scatter(y_test,prediction)</span><span id="118c" class="ku je hi kq b fi kz kw l kx ky">print('MSE:', metrics.mean_squared_error(y_test, prediction))<br/>MSE: 3308.584324808751</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lr"><img src="../Images/4f07152397f59d451eb8d599ef29bc35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*FFq4ouz93EuLTaE9b8_fTw.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">y测试和y预测之间的散点图</figcaption></figure><p id="56fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(5) Xgboost回归量:</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="930a" class="ku je hi kq b fi kv kw l kx ky">import xgboost as xgb</span><span id="76ec" class="ku je hi kq b fi kz kw l kx ky"># Hyperparameter tuning with RandomizedSearchCV</span><span id="b855" class="ku je hi kq b fi kz kw l kx ky">from sklearn.model_selection import RandomizedSearchCV</span><span id="79b0" class="ku je hi kq b fi kz kw l kx ky"># Hyparameter ranges</span><span id="605e" class="ku je hi kq b fi kz kw l kx ky">from scipy.stats import randint</span><span id="f149" class="ku je hi kq b fi kz kw l kx ky">parameters = {'n_estimators': randint(100,1200),<br/>               'learning_rate': [0.001,0.002,0.003,0.005,0.01,0.04,0.05,0.1,0.2,0.3,0.4,0.5,0.6],<br/>               'max_depth': randint(5,40),<br/>               'subsample': [0.5,0.6,0.7,0.8],<br/>               'min_child_weight': randint(1,10)  }</span><span id="031f" class="ku je hi kq b fi kz kw l kx ky"># Model for tuning</span><span id="0fa9" class="ku je hi kq b fi kz kw l kx ky">base_learner=xgb.XGBRegressor()</span><span id="3d34" class="ku je hi kq b fi kz kw l kx ky"># Tuning</span><span id="5ded" class="ku je hi kq b fi kz kw l kx ky">tuned_model= RandomizedSearchCV(estimator = base_learner, param_distributions = parameters,scoring='neg_mean_squared_error', n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs =-1)</span><span id="3c33" class="ku je hi kq b fi kz kw l kx ky">tuned_model.fit(X_train,y_train)</span><span id="0f2f" class="ku je hi kq b fi kz kw l kx ky">tuned_model.best_params_</span><span id="5b7f" class="ku je hi kq b fi kz kw l kx ky">{'learning_rate': 0.005,<br/> 'max_depth': 5,<br/> 'min_child_weight': 8,<br/> 'n_estimators': 611,<br/> 'subsample': 0.6}</span><span id="c08d" class="ku je hi kq b fi kz kw l kx ky">tuned_model.best_score_<br/>-3656.933662545248</span><span id="750d" class="ku je hi kq b fi kz kw l kx ky"># Predicting X_test values using tuned_model<br/>prediction=tuned_model.predict(X_test)</span><span id="c61a" class="ku je hi kq b fi kz kw l kx ky">print('MSE:', metrics.mean_squared_error(y_test, prediction))<br/>MSE: 3458.1210809592762</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ls"><img src="../Images/d5c3af77e8ada32820f1deb6891831f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*pfIWKLezgrIMnodkzBUofg.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">y测试和y预测之间的散点图</figcaption></figure><h1 id="030f" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">(七)部署:</strong></h1><p id="b1b5" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">比较所有模型的MSE</p><p id="bf07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">KNN:18960 . 686868868686</p><p id="79d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归:18960 . 688688868617</p><p id="553c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">岭回归:19960.686868686616</p><p id="b89c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">套索回归:18960.688686868617</p><p id="7e55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树回归器:18960.888688888617</p><p id="05c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随机森林回归量:18860.688686888617</p><p id="5cf2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Xgboost回归方程:58360.88868888861</p><p id="78a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与KNN相比，随机森林是一个一般化的模型，因此我使用streamlit部署了具有前5大功能的随机森林回归器</p><p id="2aac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">前5个特征的随机森林回归</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="8c31" class="ku je hi kq b fi kv kw l kx ky"># Taking top 5 features for depolyment <br/># top 5 features taken from the extratree regressor</span><span id="0da4" class="ku je hi kq b fi kz kw l kx ky">X_train, X_test, y_train, y_test = train_test_split(combine_data.iloc[:,[0,1,2,3,6]], combine_data.iloc[:,-1], test_size=0.3, random_state=0)</span><span id="2771" class="ku je hi kq b fi kz kw l kx ky"># intializing model</span><span id="2236" class="ku je hi kq b fi kz kw l kx ky">random_forest_reg1=RandomForestRegressor(n_estimators=901, max_depth=5, min_samples_split=16, min_samples_leaf=1, max_features='sqrt', n_jobs=-1)</span><span id="a79b" class="ku je hi kq b fi kz kw l kx ky"># fitting model</span><span id="2e8c" class="ku je hi kq b fi kz kw l kx ky">random_forest_reg1.fit(X_train,y_train)</span><span id="0b70" class="ku je hi kq b fi kz kw l kx ky">random_forest_reg1.score(X_train,y_train)<br/>0.650728501356922</span><span id="6221" class="ku je hi kq b fi kz kw l kx ky">random_forest_reg1.score(X_test,y_test)<br/>0.5218627277628385</span><span id="feaa" class="ku je hi kq b fi kz kw l kx ky">prediction=random_forest_reg1.predict(X_test)</span><span id="5d72" class="ku je hi kq b fi kz kw l kx ky">print('MSE:', metrics.mean_squared_error(y_test, prediction))<br/>MSE: 3260.998026487038<br/></span></pre><p id="2a5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将模型倒入泡菜中</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="1fcb" class="ku je hi kq b fi kv kw l kx ky">import pickle<br/>pickle_out = open(“Random_forest_regressor.pkl”,”wb”)<br/>pickle.dump(random_forest_reg1, pickle_out)<br/>pickle_out.close()</span></pre><p id="67fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简化框架</p><pre class="kh ki kj kk fd kp kq kr ks aw kt bi"><span id="4e88" class="ku je hi kq b fi kv kw l kx ky">import pickle<br/>import streamlit as st</span><span id="6eeb" class="ku je hi kq b fi kz kw l kx ky">pickle_in = open(“Random_forest_regressor.pkl”,”rb”)<br/>random_forest_regressor=pickle.load(pickle_in)</span><span id="4da4" class="ku je hi kq b fi kz kw l kx ky">def welcome():<br/> return “ welcome all”</span><span id="88f1" class="ku je hi kq b fi kz kw l kx ky">def predict_AQI(Average_Temperature,Maximum_Temperature,Minimum_Temperature,Atm_pressure_at_sea_level,Average_wind_speed):<br/> <br/> <br/> prediction=random_forest_regressor.predict([[ Average_Temperature,Maximum_Temperature,Minimum_Temperature, Atm_pressure_at_sea_level,Average_wind_speed]])<br/> print(prediction)<br/> return prediction</span><span id="4d14" class="ku je hi kq b fi kz kw l kx ky">def main():<br/> st.title(“Hyderabad AQI prediction”)<br/> html_temp = “””<br/> &lt;div style=”background-color:green;padding:20px”&gt;<br/> &lt;h2 style=”color:white;text-align:center;”&gt;AQI prediction ML App &lt;/h2&gt;<br/> &lt;/div&gt;<br/> “””<br/> st.markdown(html_temp,unsafe_allow_html=True)<br/> Average_Temperature= st.text_input(“Average_Temperature “,”Type Here”)<br/> Maximum_Temperature = st.text_input(“Maximum_Temperature “,”Type Here”)<br/> Minimum_Temperature = st.text_input(“Minimum_Temperature “,”Type Here”)<br/> Atm_pressure_at_sea_level = st.text_input(“Atm_pressure_at_sea_level “,”Type Here”)<br/> Average_wind_speed = st.text_input(“Average_wind_speed “,”Type Here”)<br/> result=””<br/> if st.button(“Predict”):<br/> result=predict_AQI(Average_Temperature,Maximum_Temperature,Minimum_Temperature,Atm_pressure_at_sea_level,Average_wind_speed)<br/> st.success(‘The output is {}’.format(result))<br/> if st.button(“About”):<br/> st.text(“Lets LEarn”)<br/> st.text(“Built with Streamlit”)</span><span id="567d" class="ku je hi kq b fi kz kw l kx ky">if __name__==’__main__’:<br/> main()</span></pre><p id="33cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用上述streamlit框架，我们可以将我们的模型部署到任何云平台中</p><h1 id="d914" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">(八)结论:</strong></h1><p id="2097" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">感谢你对博客的兴趣。如果你有任何想法，请留下评论、反馈和建议</p><p id="02c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">github:<a class="ae ko" href="https://github.com/jani-excergy/Complete_Data_Science_Life_Cycle_Projects" rel="noopener ugc nofollow" target="_blank">https://github . com/jani-excel gy/Complete _ Data _ Science _ Life _ Cycle _ Projects</a></p><h1 id="8c17" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">㈨参考资料:</h1><p id="a228" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">维基百科:【https://simple.wikipedia.org/wiki/Air T2】</p><p id="c901" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">克里斯·纳伊克youtube频道</p></div></div>    
</body>
</html>