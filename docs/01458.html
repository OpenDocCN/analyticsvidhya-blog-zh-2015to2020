<html>
<head>
<title>Earthquake History (1965 — 2016): Data Visualization and Model Development</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">地震历史(1965 — 2016):数据可视化和模型开发</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/earthquake-history-1965-2016-data-visualization-and-model-development-ee53f3ce83f6?source=collection_archive---------17-----------------------#2019-10-23">https://medium.com/analytics-vidhya/earthquake-history-1965-2016-data-visualization-and-model-development-ee53f3ce83f6?source=collection_archive---------17-----------------------#2019-10-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/31f4951525eb58ac57bbd37806057e41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*C1Gk50Cc8NtyYfEG"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">安德鲁·布坎南在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="de49" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">实施RandomForestRegressor，并使用GridSearchCV找到最佳拟合参数，以根据所选国家预测发生率。</p><p id="4139" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">注:</strong>我开发了这个模型，灵感来自<a class="ae iu" href="https://www.kaggle.com/mahadevmm9/earthquake-prediction?scriptVersionId=6821016" rel="noopener ugc nofollow" target="_blank">这个笔记本</a>，用我的编程技巧和创造力做了很多修改。</p><h2 id="9643" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">逐步程序</h2><ol class=""><li id="ba72" class="ko kp hi ix b iy kq jc kr jg ks jk kt jo ku js kv kw kx ky bi translated">从<a class="ae iu" href="https://www.kaggle.com/usgs/earthquake-database" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据。</li><li id="a591" class="ko kp hi ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">如果我们仔细观察，会发现数据不包含<em class="le">位置</em>列，这对于通过国家对其进行分离非常重要。但是它确实包含了<em class="le">纬度</em>和<em class="le">经度</em>坐标值。</li><li id="99cc" class="ko kp hi ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">为了生成地点列，我们使用openweathermap.org的API并传递纬度和经度值，最终返回地点名称(您可以使用反向地理编码方法)。</li></ol><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="b9a4" class="jt ju hi lk b fi lo lp l lq lr">&gt;&gt;&gt; import pandas as pd<br/>&gt;&gt;&gt; import matplotlib.pyplot as plt</span><span id="7be6" class="jt ju hi lk b fi ls lp l lq lr">&gt;&gt;&gt; data_df = pd.read_csv('quake_db_1965-2016.csv')<br/>&gt;&gt;&gt; ## after geocoding implementation ##<br/>&gt;&gt;&gt; print(data_df['Place'])<br/>&gt;&gt;&gt; ["Ngidihopitonu, ID", "Pangai, TO", "Unknown", "Dapdap, PH" ... "Namie, JP"]</span></pre><p id="c405" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每个值由“，”分隔，带有地名和国家代码。有些是未知的，因为API找不到位置，因此它被验证为未知。JP代表日本，ID代表印度尼西亚等。</p><p id="8f4c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4.根据国家代码计算地震次数。这可以通过pandas value_counts()函数轻松实现和可视化。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="fb99" class="jt ju hi lk b fi lo lp l lq lr">&gt;&gt;&gt; data_df = data_df[data_df['Place'] != 'Unknown']<br/>&gt;&gt;&gt; data_df['CountryCode'] = data_df['Place'].apply(lambda x : x.split(', ')[len(x.split(', ')) - 1])</span><span id="868a" class="jt ju hi lk b fi ls lp l lq lr">&gt;&gt;&gt; top_thirty = data_df['CountryCode'].value_counts()<br/>&gt;&gt;&gt; top_thirty = top_thirty.nlargest(30).index<br/>&gt;&gt;&gt; top_thirty = list(top_thirty)<br/>['ID', 'PG', 'JP', 'PH', 'VU', 'CL', 'RU', 'US', 'SB', 'TO', 'MX', 'PE', 'CN', 'FJ', 'AR', 'TW', 'IR', 'AF', 'NZ', 'GR', 'GT', 'CO', 'TR', 'NI', 'KZ', 'EC', 'PK', 'IN', 'PA', 'MM']</span><span id="df12" class="jt ju hi lk b fi ls lp l lq lr">&gt;&gt;&gt; df_update = data_df['CountryCode'].where(data_df['CountryCode'].isin(top_thirty), other='Other')</span><span id="fa0d" class="jt ju hi lk b fi ls lp l lq lr">&gt;&gt;&gt; df_update.value_counts().plot(kind='bar', figsize=(15, 8))</span></pre><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/5ca8b222b77bd8c564626ca56224d41b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pMS8LK8GLiT8a-9BxgmjSQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">按国家分列的地震总数</figcaption></figure><h2 id="5802" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">让我们做一些数据可视化</h2><p id="c210" class="pw-post-body-paragraph iv iw hi ix b iy kq ja jb jc kr je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">为此，我只考虑了前三十个受影响的国家。</p><p id="c1a9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">创建一个RangeSlider，显示从1965年到2016年的缩放年份</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="348d" class="jt ju hi lk b fi lo lp l lq lr">import numpy as np<br/>import dash<br/>import dash_core_components as dcc<br/>import dash_html_components as html</span><span id="b81f" class="jt ju hi lk b fi ls lp l lq lr">year_marks = np.linspace(1965, 2016, 15)<br/>year_marks = [int(i) for i in year_marks]</span><span id="3ff8" class="jt ju hi lk b fi ls lp l lq lr">range_slider = html.Div([<br/> dcc.Slider(<br/>   id='year-slider',<br/>   min=min(year_marks),<br/>   max=max(year_marks),<br/>   step=1,<br/>   marks={i : '{}'.format(i) for i in year_marks},<br/>   value=year_marks[0]<br/>  )<br/>])</span></pre><p id="fd3a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">制作一个下拉列表，显示前30个受影响国家的列表</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="eb47" class="jt ju hi lk b fi lo lp l lq lr">country_dropdown = html.Div([<br/> dcc.Dropdown(<br/>   id='top-thirty-risky',<br/>   options=[<br/>    {'label' : 'Indonesia', 'value' : 'ID'},<br/>    {'label' : 'Japan', 'value' : 'JP'},<br/>    {'label' : 'India', 'value' : 'IN'}<br/>    ...<br/>    {'label' : 'Myanmar', 'value' : 'MM'}<br/>   ],<br/>   clearable=False,<br/>   searchable=True,<br/>   value='ID'<br/> )<br/>])</span></pre><p id="c235" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出地图，以显示国家明智和每年明智的结果在地图上</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="9c8e" class="jt ju hi lk b fi lo lp l lq lr">country_map = html.Div(id='map-history')</span></pre><p id="ec0f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用一个助手函数来提取基于年份和国家代码的数据。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="c9e7" class="jt ju hi lk b fi lo lp l lq lr">def GetCountryDataByYear(risky_code, year_value):<br/> dataq = pd.read_csv('quake_db_1965-2016.csv')<br/> risky_country = dataq[dataq['Place'].str.contains(risky_code)]<br/> risky_country = risky_country[['Date', 'Latitude', 'Longitude', 'Magnitude', 'Depth', 'Type', 'Place']]<br/> _, _, risky_country['Year'] = risky_country['Date'].str.split('/').str<br/> risky_country.loc[:, 'Year'] = risky_country.loc[:, 'Year'].astype(int)<br/> risky_country = GetDataYearValue(risky_country, year_value)</span><span id="079b" class="jt ju hi lk b fi ls lp l lq lr"> return risky_country</span></pre><p id="5868" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在dash应用程序中显示输出</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="0c8e" class="jt ju hi lk b fi lo lp l lq lr">import plotly.graph_objs as go</span><span id="12bc" class="jt ju hi lk b fi ls lp l lq lr">insightful_history = html.Div([<br/> html.Div([]),<br/> country_dropdown,<br/> country_map,<br/> range_slider,<br/>])</span><span id="b91f" class="jt ju hi lk b fi ls lp l lq lr">app = dash.Dash(__name__)</span><span id="50e1" class="jt ju hi lk b fi ls lp l lq lr">#&lt;top_thirty_countries_occurrences_by_year&gt;<br/><a class="ae iu" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank">@app</a>.callback(<br/> Output('map-history', 'children'),<br/> [Input('top-thirty-risky', 'value'), Input('year-slider', 'value')]<br/>)<br/>def history_scatter_map(risky_code, year_value):<br/> risky_country = GetCountryDataByYear(risky_code, year_value)<br/> if risky_country.shape[0] &gt; 0:<br/>  lats = risky_country['Latitude'].to_list()<br/>  lons = risky_country['Longitude'].to_list()<br/>  magnitudes = risky_country['Magnitude'].to_list()<br/>  mags_info = ['Magnitude : ' + str(m) for m in magnitudes]<br/>  depths = risky_country['Depth'].to_list()<br/>  deps_info = ['Depth : ' + str(d) for d in depths]<br/>  places = risky_country['Place'].to_list()<br/>  country_risky_info = [places[i] + '&lt;br&gt;' + mags_info[i] + '&lt;br&gt;' + deps_info[i] <br/>   for i in range(risky_country.shape[0])]</span><span id="d24e" class="jt ju hi lk b fi ls lp l lq lr">center_lat = risky_country[risky_country['Magnitude'] &lt;= risky_country['Magnitude'].min()]['Latitude'].to_list()[0]<br/>  center_lon = risky_country[risky_country['Magnitude'] &lt;= risky_country['Magnitude'].min()]['Longitude'].to_list()[0]</span><span id="fe0d" class="jt ju hi lk b fi ls lp l lq lr">country_map = PlotScatterMap(lats, lons, 10, magnitudes, default_colorscale, country_risky_info)<br/>  country_layout = LayoutScatter(400, 1000, 'stamen-terrain', center_lat, center_lon, 2.5)<br/>  result_country = html.Div([<br/>   dcc.Graph(<br/>    id='risky-country-result',<br/>    figure={'data' : [country_map], 'layout' : country_layout}<br/>   )<br/>  ], style={'margin-top' : 20, 'margin-left' : 10})<br/>  return result_country<br/> return html.Div([<br/>  html.H6('No Earthquakes found for {} in the year {}'.format(risky_code, year_value))<br/> ], style={'margin-top' : 150, 'margin-bottom' : 150, 'margin-left' : 250})<br/>#&lt;/top_thirty_countries_occurrences_by_year&gt;</span></pre><p id="6bbe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后运行应用程序</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="32fe" class="jt ju hi lk b fi lo lp l lq lr">if __name__ == '__main__':<br/> app.run_server(debug=True, dev_tools_props_check=False, dev_tools_ui=False)</span></pre><h2 id="f8e2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">结果</h2><p id="9a54" class="pw-post-body-paragraph iv iw hi ix b iy kq ja jb jc kr je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">除了可视化，我还做了一些基本的统计，当选择一个特定的年份和国家时，显示发生的总数，每年发生的总数，最高震级，最高震级的深度和每个坐标的实际地名。</p><p id="6b93" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1965年印度尼西亚国家地图结果。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/17762d34ba12314bb262080089081511.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wXtuBU-yNvadLtLbJ7xGPw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">1965年印度尼西亚地震</figcaption></figure><p id="e4fc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2011年日本的国家地图结果(我们都知道它是如此的灾难性)。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/2f8ca57bb59c95c3d222da48a2c67cb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AQWOk2uzppmfJU0fF_Hx9A.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">2011年日本地震</figcaption></figure><h2 id="9bae" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">对日本的预测</h2><p id="f1d0" class="pw-post-body-paragraph iv iw hi ix b iy kq ja jb jc kr je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">为此，我们只考虑日本的数据。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="1a6f" class="jt ju hi lk b fi lo lp l lq lr">&gt;&gt;&gt; qdb = pd.read_csv('quake_db_1965-2016.csv')<br/>&gt;&gt;&gt; japan = qdb[qdb['Place'].str.contains('JP')]<br/>&gt;&gt;&gt; japan.shape<br/>(1347, 22)</span></pre><p id="c56f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了避免NaN值并对这些值进行插值，我们需要一些辅助函数。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="a188" class="jt ju hi lk b fi lo lp l lq lr">def nan_helper(y):    <br/>    return np.isnan(y), lambda z: z.nonzero()[0]</span><span id="6d1c" class="jt ju hi lk b fi ls lp l lq lr">def get_interpolation(my_df, nan_series):<br/>    arr_series = np.array(my_df[str(nan_series)])<br/>    nans, x = nan_helper(arr_series)<br/>    arr_series[nans] = np.interp(x(nans), x(~nans), arr_series[~nans])</span><span id="3200" class="jt ju hi lk b fi ls lp l lq lr">    return arr_series.round(2)</span></pre><p id="6463" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要将NaN转换为实际值，请调用函数。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="e39b" class="jt ju hi lk b fi lo lp l lq lr">japan.loc[:, 'Depth Error'] = get_interpolation(japan, 'Depth Error')<br/>japan.loc[:, 'Depth Seismic Stations'] = get_interpolation(japan, 'Depth Seismic Stations')<br/>japan.loc[:, 'Magnitude Error'] = get_interpolation(japan, 'Magnitude Error')<br/>japan.loc[:, 'Magnitude Seismic Stations'] = get_interpolation(japan, 'Magnitude Seismic Stations')<br/>japan.loc[:, 'Azimuthal Gap'] = get_interpolation(japan, 'Azimuthal Gap')<br/>japan.loc[:, 'Horizontal Distance'] = get_interpolation(japan, 'Horizontal Distance')<br/>japan.loc[:, 'Horizontal Error'] = get_interpolation(japan, 'Horizontal Error')<br/>japan.loc[:, 'Root Mean Square'] = get_interpolation(japan, 'Root Mean Square')</span></pre><p id="cd6b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的模型只支持整数值。我们需要将字符串数据转换成数值。为此，我们必须使用<strong class="ix hj"> LabelEncoder() </strong>类。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="fb23" class="jt ju hi lk b fi lo lp l lq lr">def label_integer_encoder(my_df, series_name):<br/>    arr_name = np.array(list(my_df[str(series_name)]))<br/>    label_arr_encoder = LabelEncoder()<br/>    integer_arr_encoded = label_arr_encoder.fit_transform(arr_name)</span><span id="12e7" class="jt ju hi lk b fi ls lp l lq lr">    return integer_arr_encoded</span><span id="0a47" class="jt ju hi lk b fi ls lp l lq lr">japan.loc[:, 'Type'] = label_integer_encoder(japan, 'Type')<br/>japan.loc[:, 'Status'] = label_integer_encoder(japan, 'Status')<br/>japan.loc[:, 'Magnitude Type'] = label_integer_encoder(japan, 'Magnitude Type')<br/>japan.loc[:, 'Place'] = label_integer_encoder(japan, 'Place')</span></pre><p id="864f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在将数据分为要素和目标。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="964f" class="jt ju hi lk b fi lo lp l lq lr">X = japan[['Depth', 'Magnitude Error', 'Magnitude Type', 'Depth Error', 'Azimuthal Gap', 'Horizontal Distance', 'Horizontal Error', 'Root Mean Square', 'Place']]</span><span id="d35f" class="jt ju hi lk b fi ls lp l lq lr">y = japan[['Latitude', 'Longitude', 'Magnitude']</span></pre><p id="099c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的目标是坐标值和星等，以定位地图上的点。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="4f32" class="jt ju hi lk b fi lo lp l lq lr">&gt;&gt;&gt; X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.2, random_state=5)</span><span id="bcea" class="jt ju hi lk b fi ls lp l lq lr">&gt;&gt;&gt; X_train.shape<br/>(1077, 9)<br/>&gt;&gt;&gt; y_train.shape<br/>(1077, 3)<br/>&gt;&gt;&gt; X_test.shape<br/>(270, 9)<br/>&gt;&gt;&gt; y_test.shape<br/>(270, 3)</span></pre><h2 id="1bbe" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">模型开发</h2><p id="8e13" class="pw-post-body-paragraph iv iw hi ix b iy kq ja jb jc kr je jf jg lu ji jj jk lv jm jn jo lw jq jr js hb bi translated">RandomForestRegressor用于分类，对于大部分数据具有更高的准确性。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="1d10" class="jt ju hi lk b fi lo lp l lq lr">&gt;&gt;&gt; reg = RandomForestRegressor()<br/>&gt;&gt;&gt; reg.fit(X_train, y_train)<br/>&gt;&gt;&gt; preds = reg.predict(X_test)<br/>&gt;&gt;&gt; accuracy = reg.score(X_test, y_test)<br/>&gt;&gt;&gt; accuracy<br/>0.7162181047909523</span></pre><p id="ca2b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">GridSearchCV是确定超参数以拟合数据并给出更好结果的最佳算法。我们只需要定义一堆参数，传入上面的模型。查看<a class="ae iu" href="https://nbviewer.jupyter.org/github/chaotic-enigma/ETS_P/blob/master/JapanPrediction.ipynb" rel="noopener ugc nofollow" target="_blank">这个</a>了解更多信息。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="70ff" class="jt ju hi lk b fi lo lp l lq lr">&gt;&gt;&gt; parameters = {'n_estimators' : [16, 23, 43, 87, 45, 550, 680]}<br/>&gt;&gt;&gt; gs = GridSearchCV(reg, parameters, cv=10)<br/>&gt;&gt;&gt; grid_fit = gs.fit(X_train, y_train)<br/>&gt;&gt;&gt; best_fit = grid_fit.best_estimator_<br/>&gt;&gt;&gt; y_hat = best_fit.predict(X_test)<br/>&gt;&gt;&gt; gs_a = best_fit.score(X_test, y_test)<br/>&gt;&gt;&gt; print(gs_a)<br/>0.7900631674945803</span></pre><p id="42dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们将结果(y_hat)作为数据框，以便以更方便的方式可视化预测。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="b197" class="jt ju hi lk b fi lo lp l lq lr">&gt;&gt;&gt; preds_df = pd.DataFrame()<br/>&gt;&gt;&gt; preds_df['lats'] = [row[0] for row in y_hat]<br/>&gt;&gt;&gt; preds_df['lons'] = [row[1] for row in y_hat]<br/>&gt;&gt;&gt; preds_df['mags'] = [round(row[2], 2) for row in y_hat]<br/>&gt;&gt;&gt; preds_df.head()<br/><strong class="lk hj">lats            lons             mags</strong>                             37.621949       141.460630       5.72                 <br/>39.431155       143.188569       6.72                 <br/>36.210025       141.240586       6.04                 <br/>35.908162       139.069894       6.00                 <br/>36.863911       140.763899       5.85</span></pre><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/a8a20e5682b2698c61ecdf44b4d9fb2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VsnKiAQnLR2MY97oo3TmEQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">日本预测</figcaption></figure><p id="2bb3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样，我们可以对其他国家进行预测。我之所以用日本，是因为它是仅次于印度尼西亚的地震高发国家。</p><p id="4dc4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个项目的完整代码是<a class="ae iu" href="https://github.com/chaotic-enigma/ETS_P" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="1336" class="ma ju hi bd jv mb mc md jz me mf mg kd mh mi mj kg mk ml mm kj mn mo mp km mq bi translated">结论</h1><ol class=""><li id="e2f3" class="ko kp hi ix b iy kq jc kr jg ks jk kt jo ku js kv kw kx ky bi translated">地震是一种非常随机的自然灾害，很难预测下一次实际发生的情况。</li><li id="2592" class="ko kp hi ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">为了能够预测地震，我们需要实时的构造移动数据，即断裂引起地震的时间。</li><li id="a222" class="ko kp hi ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">序列挖掘将非常有助于通过序列的某种模式来预测下一次发生的事件。</li></ol></div></div>    
</body>
</html>