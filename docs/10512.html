<html>
<head>
<title>Installing any version of CUDA on Ubuntu and using Tensorflow and Torch on GPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Ubuntu上安装任何版本的CUDA，在GPU上使用Tensorflow和Torch</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/installing-any-version-of-cuda-on-ubuntu-and-using-tensorflow-and-torch-on-gpu-b1a954500786?source=collection_archive---------2-----------------------#2020-10-22">https://medium.com/analytics-vidhya/installing-any-version-of-cuda-on-ubuntu-and-using-tensorflow-and-torch-on-gpu-b1a954500786?source=collection_archive---------2-----------------------#2020-10-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d45f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">安装Cuda，然后安装两个主要的深度学习库即Tensorflow和Pytorch并在GPU上运行仍然是一项艰巨的任务。AWS和其他GPU提供商为机器提供了所有已安装的库，但通常情况并非如此。</p><p id="7734" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的目标是在Ubuntus上运行下图，让nvidia-smi，nvcc-version，torch.cuda.is_available()，tf.test.gpu_devic_name() 都正常工作。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/ccaca7f97080571951a2788e18157a5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TBbEUuBKIOuOHaGO9IEibw.png"/></div></div></figure><p id="b91b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将看到如何安装任何版本的CUDA，并让它与Pytorch和Tensorflow一起运行。我特别展示了兼容Tensorflow和Pytorch的安装CUDA 10.1。</p><p id="b108" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们先来看看在您的系统上安装CUDA的先决条件。</p><h2 id="a359" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">1.先决条件说明</h2><p id="c4c7" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">1.1使用以下工具验证您是否拥有支持CUDA的GPU:</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="a374" class="jp jq hi kq b fi ku kv l kw kx"><strong class="kq hj">lspci | grep -i nvidia</strong></span></pre><p id="bb47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它列出了您系统上的Nvidia GPU。检查一下https://developer.nvidia.com/cuda-gpus上的<a class="ae ky" href="https://developer.nvidia.com/cuda-gpus" rel="noopener ugc nofollow" target="_blank">。如果列出来了，说明你的GPU是支持CUDA的。另外，看，这是计算能力。。我的GPU具有7.0的计算兼容性</a></p><p id="2769" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.2检查Linux版本</p><p id="84fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Linux有许多版本，一些发行版支持CUDA:要确定您运行的发行版和发行版号，请在命令行中键入以下内容。</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="6fbe" class="jp jq hi kq b fi ku kv l kw kx"><strong class="kq hj">uname -m &amp;&amp; cat /etc/*release</strong></span></pre><p id="4a85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我对最后两个命令的输出如下所示。我的GPU是特斯拉V100。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/f87be0fc4b65213555c0257e7ad47b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QxcTsGW0rHnOR-ts"/></div></div></figure><p id="2e2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.3验证系统是否安装了gcc。</p><p id="9a0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">许多系统都预装了GCC。使用<strong class="ih hj"> gcc - version </strong>检查您的系统上是否安装了gcc。如果没有安装，请使用以下命令。</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="5464" class="jp jq hi kq b fi ku kv l kw kx">sudo apt-get install manpages-dev<br/>sudo apt-get update<br/>sudo apt install build-essential<br/>sudo apt-get install manpages-dev</span></pre><ol class=""><li id="c6d9" class="la lb hi ih b ii ij im in iq lc iu ld iy le jc lf lg lh li bi translated">4验证正确的内核头</li></ol><p id="9b0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您的系统正在运行一些内核版本。在安装和重建库的时候，Cuda需要相同内核版本的内核头文件和开发包。例如，如果您的系统运行的是内核版本3 . 17 . 4–301，则还必须安装3 . 17 . 4–301内核头文件和开发包</p><p id="95cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当前运行的内核的内核头文件和开发包可以用下面的命令安装，其中<strong class="ih hj"> uname -r </strong>给出了系统上当前的内核版本。</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="bb31" class="jp jq hi kq b fi ku kv l kw kx"><strong class="kq hj">sudo apt-get install linux-headers-$(uname -r)</strong></span></pre><h2 id="1ed6" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated"><strong class="ak"> 2。安装CUDA工具包</strong></h2><p id="4473" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">如果我们在这里，您现在已经具备了在您的系统上安装CUDA的所有先决条件。让我们开始安装吧。</p><p id="311e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以使用两种不同的安装机制来安装CUDA工具包:特定于发行版的包(RPM和Deb包)，或者独立于发行版的包(runfile包)。独立于发行版的包的优点是可以在更广泛的Linux发行版上工作，但是不更新发行版的本地包管理系统。特定于发行版的软件包与发行版的本地软件包管理系统相连接。建议尽可能使用特定于发行版的包。出于我们的目的，我们将使用一个特定于发行版的包。</p><p id="deba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以在这里<a class="ae ky" href="https://developer.nvidia.com/cuda-toolkit-archive" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/cuda-toolkit-archive</a>找到与任何CUDA版本相关的文档。我特别为CUDA版本10.1做了这件事。</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="69e0" class="jp jq hi kq b fi ku kv l kw kx"><br/>#download desired version of CUDA, 10.1 in my case. </span><span id="b7cd" class="jp jq hi kq b fi lj kv l kw kx">2.1 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.1.105-1_amd64.deb<br/><br/>2.2 sudo dpkg -i cuda-repo-ubuntu1804_10.1.105-1_amd64.deb<br/> <br/>2.3 sudo apt-key adv --fetch-keys             https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub</span><span id="b055" class="jp jq hi kq b fi lj kv l kw kx">2.4 sudo apt-get update</span></pre><p id="c63b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对大多数人来说，下一行是棘手和令人困惑的。因为它安装了最新的CUDA版本，如果你不想要最新版本的Cuda，就不要使用它。<br/> <strong class="ih hj"> sudo apt-get安装cuda </strong>(不用，用下面一个)</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="95e9" class="jp jq hi kq b fi ku kv l kw kx">2.5 sudo apt-get install cuda-10-1</span></pre><p id="da82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您现在使用nvidia-smi或nvcc版本，它们将无法工作，因为它们尚未添加到bashrc中。现在更新bashrc。</p><p id="9716" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将下面几行添加到您的bashrc中。</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="d36d" class="jp jq hi kq b fi ku kv l kw kx">export PATH="/usr/local/cuda-10.1/bin:$PATH"<br/>export LD_LIBRARY_PATH="/usr/local/cuda-10.1/lib64:$LD_LIBRARY_PATH"</span></pre><p id="ff17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在那之后，</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="14a4" class="jp jq hi kq b fi ku kv l kw kx">source .bashrc</span></pre><p id="ca86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">试试吧，nvidia-smi或者nvcc——现在版本。如果它们中的任何一个现在不工作，尝试重新启动系统。会有用的。</p><p id="e61a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在需要安装Pytorch和TensorFlow。我们可以使用pip或conda环境。如果不想手动安装CuDNN，不如用anaconda。它自动安装CuDNN，省去了很多麻烦。我将使用anaconda来安装Tensorflow的和Pytorch的GPU版本。</p><p id="9ccd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在安装anaconda。我特意点了这个链接<a class="ae ky" href="https://www.digitalocean.com/community/tutorials/how-to-install-anaconda-on-ubuntu-18-04-quickstart" rel="noopener ugc nofollow" target="_blank">https://www . digital ocean . com/community/tutorials/how-to-install-anaconda-on-Ubuntu-18-04-quick start</a></p><p id="b55b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在使用conda创建一个类似的环境并激活它:</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="873c" class="jp jq hi kq b fi ku kv l kw kx">conda create --name my_env python=3<br/>conda activate my_env</span></pre><p id="0204" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个环境即my-env中，安装适当版本的Tensorflow和GPU。</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="1e1b" class="jp jq hi kq b fi ku kv l kw kx">conda install pytorch torchvision cudatoolkit=10.1 -c pytorch<br/>conda install tensorflow-gpu</span></pre><p id="d06c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它将安装PyTorch和TensorFlow。要检查它们是否工作:现在打开python终端，并在其中导入TensorFlow和torch。现在，做:</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="60a0" class="jp jq hi kq b fi ku kv l kw kx">torch.cuda.is_available()</span></pre><p id="2796" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果它返回真，火炬能够使用GPU。现在检查TensorFlow。如果以下命令显示GPU名称，则Tensorflow也可以使用GPU。</p><pre class="je jf jg jh fd kp kq kr ks aw kt bi"><span id="b7a4" class="jp jq hi kq b fi ku kv l kw kx">print (tf.test.gpu_device_name())</span></pre><p id="e0c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，nvidia-smi、nvcc版本都可以工作，事实上，torch和Tensorlfow也可以使用GPU。如何使用docker在GPU上训练深度学习模型，敬请关注。</p></div></div>    
</body>
</html>