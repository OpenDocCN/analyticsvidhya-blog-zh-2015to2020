<html>
<head>
<title>Skip the Data Preprocessing! Accessing 12 Ready-to-Go Datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">跳过数据预处理！访问12个现成的数据集</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/skip-the-data-preprocessing-accessing-12-ready-to-go-datasets-829e53f2d78?source=collection_archive---------12-----------------------#2020-03-04">https://medium.com/analytics-vidhya/skip-the-data-preprocessing-accessing-12-ready-to-go-datasets-829e53f2d78?source=collection_archive---------12-----------------------#2020-03-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="f922" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">CIFAR、IMDB、路透社、MNIST等</h2></div><p id="95b6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当数据集可以被访问而不必从以前下载时，这是很方便的。通常，当数据集直接取自数据源时，需要对数据进行转换、清理和预处理。对于大型NLP数据集，需要对单词进行量化，这对于大型数据集来说会花费大量时间。在本文中，我将概述如何使用Keras和Scikit-Learn加载12个数据集，这些数据集经过预处理，可以进行分析或输入到机器学习模型中。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="530a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意——如果在Kaggle这样的环境中下载，请确保打开互联网。图书馆从网上检索他们的数据，所以他们需要互联网来工作。否则，它将抛出一个错误。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="ec6c" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">CIFAR10和CIFAR100</h1><p id="8dc3" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">加拿大高级研究所(CIFAR-10)数据集包含10个不同类别的60，000幅32乘32的彩色图像。这10个不同的类别是飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。每个类有6000张图片。CIFAR-100数据集有100个不同的类。</p><figure class="ky kz la lb fd lc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es kx"><img src="../Images/55a277576f556371bdb8cbfd8fb56ab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XZ-tSKcekvIYu6b5CjZCew.png"/></div></div></figure><p id="daca" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">CIFAR-10和CIFAR-100数据集通常用于评估图像识别深度学习方法。CIFAR网站有可供下载的数据集，但需要烦人的解压缩和数据转换。Keras可以通过以下方式轻松访问该数据集:</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="31d5" class="lp kb hi ll b fi lq lr l ls lt"><strong class="ll hj">#to import cifar10<br/>import</strong> keras<strong class="ll hj"><br/>from</strong> keras.datasets <strong class="ll hj">import</strong> cifar10  <br/>(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><span id="ed42" class="lp kb hi ll b fi lu lr l ls lt"><strong class="ll hj">#to import cifar100<br/>import</strong> keras<strong class="ll hj"><br/>from</strong> keras.datasets <strong class="ll hj">import</strong> cifar100<br/>(x_train, y_train), (x_test, y_test) = cifar100.load_data()</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="4c5e" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">IMDB电影评论情感数据集</h1><p id="0bb8" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">IMDB电影评论情感数据集由来自IMDB的25，000条电影评论组成，由情感(正面/负面)标记。评论已经过预处理，每个评论都被编码为一系列的单词索引。单词通过数据集中的总频率进行索引，例如，整数“3”编码数据中第三个最频繁的单词。这意味着不需要进行复杂的NLP预处理。</p><p id="4e9c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于其丰富的数据、二进制分类和上下文的一致性，该数据集通常用于测试自然语言处理技术。</p><p id="6929" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Keras图书馆可以帮助—</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="410d" class="lp kb hi ll b fi lq lr l ls lt">import keras<br/>from keras.datasets import imdb<br/>(x_train, y_train), (x_test, y_test) = imdb.load_data(path="imdb.npz",num_words=None,skip_top=0, maxlen=None,seed=1,start_char=1,oov_char=2,index_from=3)</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="33b6" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">路透社新闻主题分类</h1><p id="3f33" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">路透社新闻主题分类数据集包括来自路透社的11，228条新闻，标记了超过46个主题。与IMDB数据集一样，每条线都被编码为一系列字索引(类似于IMDB数据集)。</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="0dd1" class="lp kb hi ll b fi lq lr l ls lt">import keras<br/>from keras.datasets import reuters<br/>(x_train, y_train), (x_test, y_test) = reuters.load_data(path="reuters.npz",num_words=None,skip_top=0, maxlen=None,test_split=0.2,seed=1,start_char=1,oov_char=2,index_from=3)</span><span id="ef0e" class="lp kb hi ll b fi lu lr l ls lt">#Access word index<br/>word_index = reuters.get_word_index(path="reuters_word_index.json")</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="560e" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">MNIST手写数字</h1><p id="27c9" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">MNIST数据库包括60，000幅训练图像和10，000幅28×28像素的手写数字图像，从0到9。</p><figure class="ky kz la lb fd lc er es paragraph-image"><div class="er es lv"><img src="../Images/e168607f48221c880714b0b627c684ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/0*9BGg6nIKj12heOXV.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><a class="ae lj" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="8f7d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">MNIST数据库是测试图像识别的基准标准。Keras以易于加载的格式实现了MNIST(最初的MNIST数据库需要一些预处理):</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="979e" class="lp kb hi ll b fi lq lr l ls lt"><strong class="ll hj">import</strong> keras<strong class="ll hj"><br/>from</strong> keras.datasets <strong class="ll hj">import</strong> mnist  <br/>(x_train, y_train), (x_test, y_test) = mnist.load_data()</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="fc9c" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">时尚MNIST</h1><p id="bb40" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">时尚MNIST数据集由10个时尚类别的60，000个28×28灰度图像组成，以及10，000个图像的测试集。</p><figure class="ky kz la lb fd lc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ma"><img src="../Images/77a8f3da0b492f065a8155fbf3ad3651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wUEZxlfXw2Kf2-lwtdgG0g.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><a class="ae lj" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="73fe" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该数据集可作为MNIST的替代物。类别标签包括:</p><figure class="ky kz la lb fd lc er es paragraph-image"><div class="er es mb"><img src="../Images/363034d61490cb751f8943ea90228da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*fErUDjpalAkvyPggW08kdA.png"/></div></figure><p id="f0f2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">MNIST时装数据集的Keras实现是:</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="bea1" class="lp kb hi ll b fi lq lr l ls lt"><strong class="ll hj">import</strong> keras<strong class="ll hj"><br/>from</strong> keras.datasets <strong class="ll hj">import</strong> fashion_mnist  <br/>(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="ee9a" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">波士顿房价回归</h1><p id="0d92" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">波士顿房价数据集取自卡内基梅隆大学维护的StatLib图书馆。样本包含20世纪70年代末波士顿郊区不同位置房屋的13个属性，目标是某个位置房屋的中值。</p><p id="a0f5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">波士顿住房数据集被视为回归算法的基准数据集。</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="df71" class="lp kb hi ll b fi lq lr l ls lt"><strong class="ll hj">import</strong> keras<strong class="ll hj"><br/>from</strong> keras.datasets <strong class="ll hj">import</strong> boston_housing  <br/>(x_train, y_train), (x_test, y_test) = boston_housing.load_data()</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="9c73" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">鸢尾植物数据集</h1><p id="8e5a" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">著名的鸢尾植物数据集由测量植物的四个特征和鸢尾物种的3类目标组成，由加州大学欧文分校机器学习知识库维护。</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="2b32" class="lp kb hi ll b fi lq lr l ls lt">import sklearn<br/>data = sklearn.datasets.load_iris()</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="5c9c" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">糖尿病数据集</h1><p id="fbcd" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">糖尿病数据集由十个基线变量组成:年龄、性别、体重指数、平均血压和六项血清测量值。这些都是从442名糖尿病患者中获得的。该目标是基线后一年疾病进展的定量测量。</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="b6bd" class="lp kb hi ll b fi lq lr l ls lt">import sklearn<br/>data = sklearn.datasets.load_diabetes()</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="e753" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">葡萄酒识别数据集</h1><p id="10f0" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">UCI葡萄酒识别数据集由13个葡萄酒定量指标和一个代表葡萄酒类型的3级目标值组成。这个著名的数据集是多类分类算法的另一个基准。</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="ae43" class="lp kb hi ll b fi lq lr l ls lt">import sklearn<br/>data = sklearn.datasets.load_wine()</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="6ddb" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">威斯康星州乳腺癌诊断数据集</h1><p id="d6d3" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">著名的威斯康星州乳腺癌诊断数据集由30个数字特征组成，描述了一个癌细胞，最终的二元目标诊断为恶性或良性。该数据集是高维度和使用主成分分析辅助分类的基准数据集。</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="1130" class="lp kb hi ll b fi lq lr l ls lt">import sklearn<br/>data = sklearn.datasets.load_breast_cancer()</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="2d9a" class="ka kb hi bd kc kd ke kf kg kh ki kj kk io kl ip km ir kn is ko iu kp iv kq kr bi translated">Olivetti人脸数据集</h1><p id="877e" class="pw-post-body-paragraph ix iy hi iz b ja ks ij jc jd kt im jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">由剑桥美国电话电报公司实验室收集的Olivetti人脸数据集是一组40个不同人的400个64乘64像素的图像。目标是识别这个人的身份。该数据集对于在具有几个类和很少训练数据的数据集中评估图像识别算法的性能特别有帮助。</p><pre class="ky kz la lb fd lk ll lm ln aw lo bi"><span id="67c5" class="lp kb hi ll b fi lq lr l ls lt">import sklearn<br/>data = sklearn.datasets.fetch_olivetti_faces()</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="d935" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我希望你喜欢这篇文章！如果你看过，请随意看看我的其他作品。</p></div></div>    
</body>
</html>