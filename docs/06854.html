<html>
<head>
<title>Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/various-types-of-linear-regression-937f3c9dda9?source=collection_archive---------19-----------------------#2020-06-04">https://medium.com/analytics-vidhya/various-types-of-linear-regression-937f3c9dda9?source=collection_archive---------19-----------------------#2020-06-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="72d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性和逻辑回归通常是人们在数据科学中学习的第一个算法。由于它们的流行，许多分析家甚至认为它们是回归的唯一形式。稍微参与的人认为他们是所有回归分析形式中最重要的。</p><p id="1f6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">事实是，回归有无数种形式，可以被执行。每种形式都有自己的重要性和最适合应用的特定条件。</p><h1 id="3451" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">线性回归</h1><p id="2dbe" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">这是最广为人知的建模技术之一。线性回归通常是人们在学习预测建模时首先选择的几个主题之一。在这种技术中，因变量是连续的，自变量可以是连续的<a class="ae kg" href="https://en.wikipedia.org/wiki/Continuous_and_discrete_variables" rel="noopener ugc nofollow" target="_blank">或离散的</a>，回归线的性质是线性的。</p><p id="c755" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归使用一条<strong class="ih hj">最佳拟合直线</strong>(也称为回归线)在<strong class="ih hj">因变量(Y) </strong>和一个或多个<strong class="ih hj">自变量(X) </strong>之间建立关系。</p><p id="107c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用公式<strong class="ih hj"> Y=a+b*X + e </strong>表示，其中a为截距，b为直线斜率，e为误差项。该方程可用于根据给定的预测变量预测目标变量的值。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kh"><img src="../Images/40ef892d6955529d067751bdaaabfdbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/0*duI-xLYsMTcj58Y4.png"/></div></figure><p id="157f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简单线性回归和多元线性回归的区别在于，多元线性回归有(&gt; 1)个自变量，而简单线性回归只有1个自变量。现在，问题是“我们如何获得最佳拟合线？”。</p><h2 id="53d2" class="kp je hi bd jf kq kr ks jj kt ku kv jn iq kw kx jr iu ky kz jv iy la lb jz lc bi translated">如何获得最佳拟合线(a和b的值)？</h2><p id="3a62" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">这个任务可以用最小二乘法很容易地完成。这是拟合回归线最常用的方法。它通过最小化从每个数据点到线的垂直偏差的平方和来计算观察数据的最佳拟合线。因为偏差首先被平方，当相加时，正值和负值之间没有抵消。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es ld"><img src="../Images/13755a202b73ac344315a13d63dc2667.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/0*9IGKIcOs3mb-FXFM.png"/></div></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es le"><img src="../Images/19517c0616b3e2ff9a02cc7d33ac6799.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/0*kPvKE4-ppkbFPYm7.gif"/></div></figure><p id="826e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以使用度量标准<strong class="ih hj"> R平方</strong>来评估模型性能。要了解这些指标的更多细节，您可以阅读:模型性能指标<a class="ae kg" href="https://www.analyticsvidhya.com/blog/2015/01/model-performance-metrics-classification/" rel="noopener ugc nofollow" target="_blank">第1部分</a>、<a class="ae kg" href="https://www.analyticsvidhya.com/blog/2015/01/model-perform-part-2/" rel="noopener ugc nofollow" target="_blank">第2部分</a>。</p><h2 id="d36c" class="kp je hi bd jf kq kr ks jj kt ku kv jn iq kw kx jr iu ky kz jv iy la lb jz lc bi translated">要点:</h2><ul class=""><li id="fbdd" class="lf lg hi ih b ii kb im kc iq lh iu li iy lj jc lk ll lm ln bi translated">自变量和因变量之间必须有线性关系</li><li id="357a" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated">多元回归遭受<strong class="ih hj">多重共线性、自相关、异方差</strong>。</li><li id="cb24" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated">线性回归对<strong class="ih hj">异常值</strong>非常敏感。它会严重影响回归线，并最终影响预测值。</li><li id="f8ef" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated">多重共线性会增加系数估计值的方差，并使估计值对模型中的微小变化非常敏感。结果是系数估计不稳定</li><li id="4f73" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated">在多个自变量的情况下，我们可以用<strong class="ih hj">前向选择</strong>、<strong class="ih hj">后向淘汰</strong>和<strong class="ih hj">逐步逼近</strong>来选择最重要的自变量。</li></ul><h1 id="16f1" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">多项式回归</h1><p id="12cc" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">如果自变量的幂大于1，则回归方程是多项式回归方程。下面的等式代表一个多项式等式:</p><pre class="ki kj kk kl fd lt lu lv lw aw lx bi"><span id="a525" class="kp je hi lu b fi ly lz l ma mb">y=a+b*x^2</span></pre><p id="edd6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种回归技术中，最佳拟合线不是直线。而是一条符合数据点的曲线。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es mc"><img src="../Images/d7827ecdcda91f62b9f48f15173ba2a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/0*ZMB3qHq82r55op_t.png"/></div></figure><h2 id="b0bd" class="kp je hi bd jf kq kr ks jj kt ku kv jn iq kw kx jr iu ky kz jv iy la lb jz lc bi translated">要点:</h2><ul class=""><li id="c085" class="lf lg hi ih b ii kb im kc iq lh iu li iy lj jc lk ll lm ln bi translated">虽然可能有拟合更高次多项式以获得更低误差的诱惑，但这可能导致过度拟合。始终绘制关系图，以查看拟合情况，并重点确保曲线符合问题的性质。下面是一个关于绘图如何有所帮助的示例:</li></ul><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es md"><img src="../Images/d4eeb9c7df55db0f83bdcc0c589c6ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/0*aRpMTyEE-o3c1rFv.png"/></div></figure><ul class=""><li id="a69e" class="lf lg hi ih b ii ij im in iq me iu mf iy mg jc lk ll lm ln bi translated">特别是要注意末端的曲线，看看这些形状和趋势是否有意义。更高阶的多项式可能会在外推时产生奇怪的结果。</li></ul><h1 id="dc90" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">结论</h1><p id="c64b" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">线性回归是每个机器学习爱好者都必须知道的算法，也是想学习机器学习的人的正确起点。这确实是一个简单但有用的算法。我希望这篇文章对你有帮助。</p></div></div>    
</body>
</html>