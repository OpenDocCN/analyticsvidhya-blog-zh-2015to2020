<html>
<head>
<title>Spam-Ham Classification Using LSTM in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch中使用LSTM的垃圾邮件-火腿分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spam-ham-classification-using-lstm-in-pytorch-950daec94a7c?source=collection_archive---------5-----------------------#2019-09-04">https://medium.com/analytics-vidhya/spam-ham-classification-using-lstm-in-pytorch-950daec94a7c?source=collection_archive---------5-----------------------#2019-09-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5975" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是如何在PyTorch中建立和训练LSTM模型，并使用它来预测垃圾邮件或火腿。</p><p id="ffa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本指南的Github回购是<a class="ae jd" href="https://github.com/sijoonlee/spam-ham-walkthrough" rel="noopener ugc nofollow" target="_blank">这里的</a>，你可以在回购中看到<a class="ae jd" href="https://github.com/sijoonlee/spam-ham-walkthrough/blob/master/walkthrough.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>。我的建议是下载笔记本，看看这个演练，然后玩一玩。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/fe39cf39bdc6f1197b9780df8bb83659.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HJHpFNh1ZQel1Quc"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">由<a class="ae jd" href="https://unsplash.com/@webhost?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">网站主持</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="d98c" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">一.安然垃圾邮件数据集</h1><p id="8b33" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">研究人员V. Metsis、I. Androutsopoulos和G. Paliouras将安然语料库中的3万多封电子邮件归类为垃圾邮件/垃圾邮件数据集，并向公众开放</p><ol class=""><li id="1bed" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated">进入<a class="ae jd" href="http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html" rel="noopener ugc nofollow" target="_blank">网站</a></li><li id="ac77" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">在站点中找到<code class="du ll lm ln lo b">Enron-Spam in pre-processed form</code></li><li id="f1c0" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">下载恩龙1、恩龙2、恩龙3、恩龙4、恩龙5和恩龙6</li><li id="37f2" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">提取每个tar.gz文件</li><li id="7c00" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">目录enron1，enron2，…，enron6应该在你放置<a class="ae jd" href="https://github.com/sijoonlee/spam-ham-walkthrough/blob/master/walkthrough.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>的同一个目录下</li></ol><h1 id="c935" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">二。处理数据</h1><p id="d831" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">数据将会是</p><ol class=""><li id="dec3" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated">从文件加载</li><li id="1a7f" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">用于建立词汇词典</li><li id="a05c" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">符号化和矢量化</li></ol><p id="c9c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们深入了解每一步</p><h2 id="1569" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">二-1。从文件加载数据</h2><p id="5dfb" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">需要将file_reader.py下载到同一个文件夹中。我简单介绍一下我写的代码(<a class="ae jd" href="https://github.com/sijoonlee/spam-ham-walkthrough/blob/master/file_reader.py" rel="noopener ugc nofollow" target="_blank"> file_reader.py </a>)。</p><p id="a5ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，垃圾邮件和火腿集合将被分别加载到<code class="du ll lm ln lo b">spam</code>和<code class="du ll lm ln lo b">ham</code>中。其次，<code class="du ll lm ln lo b">ham</code>和<code class="du ll lm ln lo b">spam</code>将合并为<code class="du ll lm ln lo b">data</code>。第三，将为垃圾邮件和火腿生成标签，分别为1和0<br/>最后，它返回数据和标签:</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><p id="1e11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">加载的数据包括3000个hams和3000个spam——总共6000个<br/>。如果您设置了<code class="du ll lm ln lo b">max = 0</code>,您可以从文件中获取所有数据。但是对于这个教程，6000套就够了</p><h2 id="3337" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">二-2。建立词汇词典</h2><p id="9dfb" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">词汇词典中有键和值:分别是单词和值。例如{'the': 2，' to': 3}</p><p id="3ad2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">字典里的整数怎么选？</p><p id="2035" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请想象一个来自6000个数据集的单词列表。像“the”、“to”和“and”这样的常用词更有可能在列表中出现多次。我们将计算出现的次数，并根据次数对单词进行排序。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="e9f1" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">二-3。标记化和矢量化数据</h2><p id="65a3" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们先看看示例代码</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><p id="af08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du ll lm ln lo b">Tokenization</code>在这里表示从数据集到单词列表的转换。例如，假设我们有如下数据</p><pre class="jf jg jh ji fd mf lo mg mh aw mi bi"><span id="9827" class="lp jv hi lo b fi mj mk l ml mm">"operations is digging out 2000 feet of pipe to begin the hydro test"</span></pre><p id="12fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">标记化将产生如下单词列表</p><pre class="jf jg jh ji fd mf lo mg mh aw mi bi"><span id="2190" class="lp jv hi lo b fi mj mk l ml mm">['operations', 'is', 'digging', ...</span></pre><p id="7daa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du ll lm ln lo b">Vectorization</code>在这里表示使用II-2中内置的vocab字典将单词转换为整数</p><pre class="jf jg jh ji fd mf lo mg mh aw mi bi"><span id="1189" class="lp jv hi lo b fi mj mk l ml mm">[424, 11, 14683, ...</span></pre><p id="4675" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们可以继续我们的数据集</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><h1 id="5993" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">三。构建数据加载器</h1><p id="e4b9" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">到目前为止，数据是以矢量化的形式处理的。现在，轮到构建数据加载器了，它将把成批的数据集输入到我们的模型中。为此，</p><ol class=""><li id="19ef" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated">需要自定义数据加载器类</li><li id="7642" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">需要三个数据加载器:用于训练、验证和测试</li></ol><h2 id="4a69" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">三-1。自定义数据加载器</h2><p id="cc84" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated"><code class="du ll lm ln lo b">Sequence</code>这里指的是电子邮件中的矢量化单词列表。<br/>由于我们准备了6000封电子邮件，因此我们有6000个序列。</p><p id="fc4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于序列具有不同的长度，所以需要将每个序列的长度传递到我们的模型中，而不是在虚拟数字(0表示填充)上训练我们的模型。</p><p id="12dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们需要定制的数据加载器来返回每个序列的长度以及序列和标签。</p><p id="a34c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另外，数据加载器应该按照每个序列的长度对批处理进行排序，并首先返回批处理中最长的一个，以使用torch的<code class="du ll lm ln lo b">pack_padded_sequence()</code>(稍后您将看到这个函数)</p><p id="1793" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用torch的sampler构建了iterable数据加载器类。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="8026" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">三-2。实例化3个数据加载器</h2><p id="f04e" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">模型将在<strong class="ih hj">训练</strong>数据集上训练，由<strong class="ih hj">验证</strong>数据集验证，最后在<strong class="ih hj">测试</strong>数据集上测试:</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><h1 id="0fab" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">四。构建模型</h1><p id="e76a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">该模型包括</p><ol class=""><li id="3403" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated">把...嵌入</li><li id="39a6" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">打包序列(去掉填料)</li><li id="da01" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">LSTM</li><li id="2e1b" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">解开序列(恢复填充)</li><li id="9612" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">全连接层</li><li id="4b28" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">乙状结肠激活</li></ol><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="1afd" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">IV-1。把...嵌入</h2><p id="08d4" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">根据PyTorch.org的文档，“单词嵌入是一个单词的语义的表示”</p><blockquote class="mo mp mq"><p id="f056" class="if ig mn ih b ii ij ik il im in io ip mr ir is it ms iv iw ix mt iz ja jb jc hb bi translated"><em class="hi">要知道</em> <code class="du ll lm ln lo b"><em class="hi">Word Embeddings</em></code> <em class="hi">是什么，我推荐你去阅读</em> <a class="ae jd" href="https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html" rel="noopener ugc nofollow" target="_blank"> <em class="hi"> PyTorch文档</em> </a></p></blockquote><h2 id="93f2" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">IV-2。pack_padded_sequence()的使用</h2><p id="e699" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">请记住，我们在序列中添加了填充(0)。由于序列具有不同的长度，所以需要将填充添加到较短的序列中，以匹配张量中的维度。问题是模型不应该在填充值上训练。pack_padded_sequence()将删除批数据中的填充并重新组织它</p><p id="613c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">举个例子，</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><blockquote class="mo mp mq"><p id="a2aa" class="if ig mn ih b ii ij ik il im in io ip mr ir is it ms iv iw ix mt iz ja jb jc hb bi translated"><em class="hi">要了解更多关于</em> <code class="du ll lm ln lo b"><em class="hi">pack_padded_sequence()</em></code> <em class="hi">的内容，推荐你去读一下</em> <a class="ae jd" href="https://stackoverflow.com/questions/49466894/how-to-correctly-give-inputs-to-embedding-lstm-and-linear-layers-in-pytorch/49473068#49473068" rel="noopener ugc nofollow" target="_blank"> <em class="hi"> layog的栈溢出贴</em> </a> <em class="hi">和</em> <a class="ae jd" href="https://github.com/HarshTrivedi/packing-unpacking-pytorch-minimal-tutorial" rel="noopener ugc nofollow" target="_blank"> <em class="hi"> HarshTrivedi的教程</em> </a></p></blockquote><h2 id="ee97" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">IV-3。LSTM</h2><p id="05cc" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">LSTM代表“长短期记忆”，一种RNN架构。注意，如果没有提供<code class="du ll lm ln lo b">(h_0, c_0)</code>，根据<a class="ae jd" href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html" rel="noopener ugc nofollow" target="_blank"> PyTorch文档</a>，两个<strong class="ih hj"> h_0 </strong>和<strong class="ih hj"> c_0 </strong>都默认为零</p><blockquote class="mo mp mq"><p id="a0f2" class="if ig mn ih b ii ij ik il im in io ip mr ir is it ms iv iw ix mt iz ja jb jc hb bi translated"><em class="hi">对于</em> <code class="du ll lm ln lo b"><em class="hi">LSTM</em></code> <em class="hi">，我会推荐你去读读</em> <a class="ae jd" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"> <em class="hi"> colah的博客</em> </a></p></blockquote><h1 id="312a" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">动词 （verb的缩写）培训、验证和测试</h1><h2 id="dbb0" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">第一组。培训和验证</h2><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="3e6c" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">V-2。试验</h2><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="a4ea" class="lp jv hi bd jw lq lr ls ka lt lu lv ke iq lw lx ki iu ly lz km iy ma mb kq mc bi translated">不及物动词预测</h2><p id="381f" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">这是我最近得到的英语课广告的一部分。预测它是垃圾邮件似乎有点棘手，不是吗？</p><pre class="jf jg jh ji fd mf lo mg mh aw mi bi"><span id="cce5" class="lp jv hi lo b fi mj mk l ml mm">Have you been really busy this week? Then you'll definitely want to make time for this lesson. Have a wonderful week, learn something new, and practice some English!</span></pre><p id="0c19" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们把它放到模型中，看看结果是否是“垃圾邮件”</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="md me l"/></div></figure><p id="a4f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型算垃圾！</p></div><div class="ab cl mu mv gp mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="hb hc hd he hf"><p id="8f6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您的阅读！</p><p id="0cd6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我从来没有期望自己写一本指南，因为我仍然认为自己是深度学习的初学者。如果您发现有什么问题，请发邮件给我或留下您的意见，我们将不胜感激。</p><p id="7092" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">邮箱:<a class="ae jd" href="mailto:shijoonlee@gmail.com" rel="noopener ugc nofollow" target="_blank">shijoonlee@gmail.com</a>T33】Github:<a class="ae jd" href="https://github.com/sijoonlee" rel="noopener ugc nofollow" target="_blank">github.com/sijoonlee</a></p></div></div>    
</body>
</html>