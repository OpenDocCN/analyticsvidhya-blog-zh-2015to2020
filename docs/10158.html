<html>
<head>
<title>Detecting Covid-19 Using Chest X-Ray Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用胸部 X 射线图像检测新冠肺炎</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/detecting-covid-19-using-chest-x-ray-images-a6fc822b73cc?source=collection_archive---------11-----------------------#2020-10-07">https://medium.com/analytics-vidhya/detecting-covid-19-using-chest-x-ray-images-a6fc822b73cc?source=collection_archive---------11-----------------------#2020-10-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b7445d1b5ea4526f500013ece9a4393c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qxl1AaluFrMJwlIOJdUMXw.jpeg"/></div></div></figure><h1 id="396d" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">介绍</h1><p id="7f5f" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">新冠肺炎就像你小时候养成的坏习惯，现在无论如何都不愿意离开。显然，我们都是这种情况的受害者。但这次不一样。</p><p id="a014" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这家伙在杀人。在过去的几个月里，我们听到的都是数字，说明一个地区的死亡人数，或者受影响的人数。最糟糕的是，这个数字增长如此之快，以至于我们不得不呆在家里过正常的生活。是啊，我知道。这不可能。此外，自疫情以来，许多人失去了工作，研究团队仍然没有积极的迹象。</p><p id="1704" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">有许多机构致力于检测新冠肺炎患者，并在必要时给予他们适当的药物治疗以增进健康。但问题是，该测试需要 3-4 天才能最终确定患者的报告，这是非常危险的，因为这种疾病非常容易传播(不像你高中时喜欢的人)。所以，我突然想到，如果有更好的方法来测试病人，不需要 3-4 天就能出报告，会怎么样？？</p><h1 id="4246" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">履行</h1><p id="c9d4" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">经过一番研究，我发现了一个<a class="ae kr" href="https://www.kaggle.com/tawsifurrahman/covid19-radiography-database" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>数据集，里面有不同人的胸部 x 光图像，这些图像主要分为三类:&lt;正常&gt;、&lt;病毒性肺炎&gt;、&lt;新冠肺炎&gt;。现在，对于一些人来说似乎只是一组图像，对于像我这样的数据科学爱好者来说，却发现了分类问题。在深入研究完整的实现之前，需要导入一些库才能正常工作。下面是相同的代码片段。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="ad04" class="lb ir hi kx b fi lc ld l le lf">%matplotlib inline<br/>import os<br/>import shutil<br/>import random<br/>import torch<br/>import torchvision<br/>import numpy as np<br/><br/>from PIL import Image<br/>from matplotlib import pyplot as plt<br/>torch.manual_seed(0)<br/>from torch.autograd import Variable<br/>print('Using PyTorch version', torch.__version__)</span></pre><p id="0271" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果上面的代码运行良好，输出将显示如下:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="3281" class="lb ir hi kx b fi lc ld l le lf">Using PyTorch version 1.6.0+cpu</span></pre><p id="ed72" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我开始处理数据集，首先要执行的操作是将数据分成训练集和测试集。下面是我如何执行任务的代码片段。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="b28b" class="lb ir hi kx b fi lc ld l le lf">class_names = ['normal', 'viral', 'covid']<br/>root_dir = 'archive/COVID-19 Radiography Database'<br/>source_dirs = ['NORMAL', 'Viral', 'COVID-19']</span><span id="cd4d" class="lb ir hi kx b fi lg ld l le lf">if os.path.isdir(os.path.join(root_dir, source_dirs[1])):<br/>    os.mkdir(os.path.join(root_dir, 'test'))</span><span id="373e" class="lb ir hi kx b fi lg ld l le lf">    for i, d in enumerate(source_dirs):<br/>        os.rename(os.path.join(root_dir, d), os.path.join(root_dir, class_names[i]))</span><span id="ce19" class="lb ir hi kx b fi lg ld l le lf">    for c in class_names:<br/>        os.mkdir(os.path.join(root_dir, 'test', c))</span><span id="7ce3" class="lb ir hi kx b fi lg ld l le lf">    for c in class_names:<br/>        images = [x for x in os.listdir(os.path.join(root_dir, c)) if x.lower().endswith('png')]<br/>        selected_images = random.sample(images, 30)<br/>        for image in selected_images:<br/>            source_path = os.path.join(root_dir, c, image)<br/>            target_path = os.path.join(root_dir, 'test', c, image)<br/>            shutil.move(source_path, target_path)</span></pre><p id="f3ea" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">准备数据集文件夹后的下一步操作是创建一个自定义数据集类，用于循环访问数据集。这个自定义类继承了一个抽象类<strong class="jq hj">数据集</strong></p><p id="eec3" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">并重写两个重要的方法:</p><ol class=""><li id="6028" class="lh li hi jq b jr km jv kn jz lj kd lk kh ll kl lm ln lo lp bi translated"><code class="du lq lr ls kx b"><strong class="jq hj">__len__</strong></code>以便<code class="du lq lr ls kx b"><strong class="jq hj">len(dataset)</strong></code>返回数据集的大小。</li><li id="0ddc" class="lh li hi jq b jr lt jv lu jz lv kd lw kh lx kl lm ln lo lp bi translated"><code class="du lq lr ls kx b"><strong class="jq hj">__getitem__</strong></code>支持索引，这样<code class="du lq lr ls kx b"><strong class="jq hj">dataset[i]</strong></code>可以用来获取第 I 个样本</li></ol><p id="0a19" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们的数据集将接受一个可选参数<strong class="jq hj"> transform </strong>，这样任何需要的处理都可以应用到样本上。</p><p id="ab57" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">下面是我如何创建我的自定义类:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="ca59" class="lb ir hi kx b fi lc ld l le lf">class ChestXRayDataset(torch.utils.data.Dataset):<br/>    def __init__(self, image_dirs, transform):<br/>        def get_images(class_name):<br/>            images = [x for x in os.listdir(image_dirs[class_name]) if x[-3:].lower().endswith('png')]<br/>            print(f'Found {len(images)} {class_name} examples')<br/>            return images<br/>        <br/>        self.images = {}<br/>        self.class_names = ['normal', 'viral', 'covid']<br/>        <br/>        for class_name in self.class_names:<br/>            self.images[class_name] = get_images(class_name)<br/>            <br/>        self.image_dirs = image_dirs<br/>        self.transform = transform<br/>        <br/>    <br/>    def __len__(self):<br/>        return sum([len(self.images[class_name]) for class_name in self.class_names])<br/>    <br/>    <br/>    def __getitem__(self, index):<br/>        class_name = random.choice(self.class_names)<br/>        index = index % len(self.images[class_name])<br/>        image_name = self.images[class_name][index]<br/>        image_path = os.path.join(self.image_dirs[class_name], image_name)<br/>        image = Image.open(image_path).convert('RGB')<br/>        return self.transform(image), self.class_names.index(class_name)</span></pre><p id="2749" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">遇到的一个问题是样本大小不同。大多数神经网络期望固定大小的图像。因此，我们对训练和测试数据集执行一些预处理，如下所示:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="c619" class="lb ir hi kx b fi lc ld l le lf">train_transform = torchvision.transforms.Compose([<br/>    torchvision.transforms.Resize(size = (224,224)),<br/>    torchvision.transforms.RandomHorizontalFlip(),<br/>    torchvision.transforms.ToTensor(),<br/>    torchvision.transforms.Normalize(mean =[0.485,0.456,0.406],std=[0.229,0.224,0.225]),    <br/>])</span><span id="5f13" class="lb ir hi kx b fi lg ld l le lf">test_transform = torchvision.transforms.Compose([<br/>    torchvision.transforms.Resize(size = (224,224)),<br/>    torchvision.transforms.ToTensor(),<br/>    torchvision.transforms.Normalize(mean =[0.485,0.456,0.406],std=[0.229,0.224,0.225]),    <br/>])</span></pre><p id="69c7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">接下来，我们创建一个字典，将关键字作为不同的类名(normal、viral 和 COVID)，每个关键字的值将是它们对应的目录，在该目录中存储该类的图像。之后，我们通过传递训练和测试字典以及它们各自的转换作为参数来创建自定义数据集类的两个对象。下面是相同的代码片段。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="e793" class="lb ir hi kx b fi lc ld l le lf">train_dirs = {<br/>    'normal': 'archive/COVID-19 Radiography Database/normal',<br/>    'viral': 'archive/COVID-19 Radiography Database/viral',<br/>    'covid': 'archive/COVID-19 Radiography Database/covid'<br/>}</span><span id="e9cd" class="lb ir hi kx b fi lg ld l le lf">train_dataset = ChestXRayDataset(train_dirs,train_transform)</span><span id="006a" class="lb ir hi kx b fi lg ld l le lf">test_dirs = {<br/>    'normal': 'archive/COVID-19 Radiography Database/test/normal',<br/>    'viral': 'archive/COVID-19 Radiography Database/test/viral',<br/>    'covid': 'archive/COVID-19 Radiography Database/test/covid'<br/>}</span><span id="e4c7" class="lb ir hi kx b fi lg ld l le lf">test_dataset = ChestXRayDataset(test_dirs,test_transform)</span></pre><p id="a93a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果一切正常，将显示以下输出:</p><p id="a9b3" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">对于培训对象:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="8e59" class="lb ir hi kx b fi lc ld l le lf">Found 1311 normal examples<br/>Found 1315 viral examples<br/>Found 189 covid examples</span></pre><p id="2d6c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">对于测试对象:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6c38" class="lb ir hi kx b fi lc ld l le lf">Found 30 normal examples<br/>Found 30 viral examples<br/>Found 30 covid examples</span></pre><p id="a562" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">下一步是将上一步中创建的对象传递给具有特定批处理大小的数据加载器。数据加载器的目的是允许更容易地实现块读取和动态批量大小(例如，通过每次产生一个批量样本)。下面是我如何定义我的数据加载器的代码片段</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="e7de" class="lb ir hi kx b fi lc ld l le lf">batch_size = 6</span><span id="2e3b" class="lb ir hi kx b fi lg ld l le lf">dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)<br/>dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)</span><span id="0b0d" class="lb ir hi kx b fi lg ld l le lf">print('Number of training batches', len(dl_train))<br/>print('Number of test batches', len(dl_test))</span></pre><p id="4a82" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果一切正常，将显示以下输出:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="df2b" class="lb ir hi kx b fi lc ld l le lf">Number of training batches 470<br/>Number of test batches 15</span></pre><p id="7fd7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">现在，是时候进行一些可视化了。让我们创建一个函数，该函数通过数据加载器迭代器获取真实标签、预测标签和一组图像，并显示一组图像，如果预测正确，即如果图像的预测标签与图像的真实标签匹配，则预测标签将以绿色显示在图像的一侧，如果预测错误，则预测标签将以红色显示。由于我们没有训练我们的模型，我们现在将把真实标签作为预测标签传递。</p><p id="5e6d" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">下面是相同的代码片段:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="0ef8" class="lb ir hi kx b fi lc ld l le lf">class_names = train_dataset.class_names</span><span id="bccd" class="lb ir hi kx b fi lg ld l le lf">def show_images(images, labels, preds):<br/>    plt.figure(figsize=(8, 4))<br/>    for i, image in enumerate(images):<br/>        plt.subplot(1, 6, i + 1, xticks=[], yticks=[])<br/>        image = image.numpy().transpose((1, 2, 0))<br/>        mean = np.array([0.485, 0.456, 0.406])<br/>        std = np.array([0.229, 0.224, 0.225])<br/>        image = image * std + mean<br/>        image = np.clip(image, 0., 1.)<br/>        plt.imshow(image)<br/>        col = 'green'<br/>        if preds[i] != labels[i]:<br/>#             print("label",labels[i])<br/>            col = 'red'<br/>            <br/>        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')<br/>        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)<br/>    plt.tight_layout()<br/>    plt.show()</span></pre><p id="78b6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">现在，我们遍历 dataloader 来传递一批图像，并将其传递给我们刚刚创建的函数。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="a3da" class="lb ir hi kx b fi lc ld l le lf">images,labels = next(iter(dl_train))<br/>show_images(images,labels,labels)</span></pre><p id="b27a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果一切正常，您将看到如下输出:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/41a59364118c691ffd78024c68ae5cc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*fqDNS4HeXMtxDbAmncQqbA.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">带标签的样本数据集</figcaption></figure><p id="7b2a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">现在，我总是想为一个看起来很有前途的任务创建自己的神经网络模型，但后来我决定使用预先训练的模型，然后使用迁移学习来解决分类问题。我脑海中浮现的第一个名字是“Resnet18 ”,正如伊恩·古德菲勒和吴恩达所说，“这是我的想法，在这里会非常合适”。由于我使用 Pytorch，所以我很容易就获得了 resnet18 预训练模型。下面是我如何获得预训练 ResNet 模型的代码片段。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6a75" class="lb ir hi kx b fi lc ld l le lf">resnet18 = torchvision.models.resnet18(pretrained=True)<br/>print(resnet18)</span></pre><p id="940b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果一切正常，将显示 Resnet18 的网络架构。</p><p id="7341" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">接下来，让我们修改预训练模型的最后一个 FC 层，它具有 512 个输入特征和 1000 个输出特征，因为 ResNet 被训练的类的数量是 1000。但是，在我们的例子中，只有三个。然后，我们将<strong class="jq hj">交叉熵损失</strong>分配给模型，因为它是分类任务的明显选择，并使用<strong class="jq hj">亚当</strong>作为学习速率为<strong class="jq hj"> 4e-5 </strong>的优化器</p><p id="faf0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">下面是相同的代码片段:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="b2e5" class="lb ir hi kx b fi lc ld l le lf">resnet18.fc = torch.nn.Linear(in_features=512, out_features=3)<br/>loss_fn = torch.nn.CrossEntropyLoss()<br/>optimizer = torch.optim.Adam(resnet18.parameters(), lr=4e-5)</span></pre><p id="7a37" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">接下来，让我们创建另一个函数，该函数将通过迭代 dataloader 并向修改后的 ResNet 模型传递一批图像来进行预测，并使用我们之前创建的函数显示结果。下面是预测函数的代码片段:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="ec1f" class="lb ir hi kx b fi lc ld l le lf">def show_preds():<br/>    resnet18.eval()<br/>    images, labels = next(iter(dl_test))<br/>    outputs = resnet18(images)<br/>    _, preds = torch.max(outputs, 1)<br/>    show_images(images, labels, preds)</span></pre><p id="598a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">然后，我们为最后一部分创建另一个函数，即模型的训练。我们只需循环遍历我们的数据迭代器，将输入馈送给网络并进行优化。</p><p id="a947" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">下面是我如何创建训练函数来训练模型的代码片段。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="48b7" class="lb ir hi kx b fi lc ld l le lf">def train(epochs):<br/>    print('Starting training..')<br/>    for e in range(0, epochs):<br/>        print('='*20)<br/>        print(f'Starting epoch {e + 1}/{epochs}')<br/>        print('='*20)</span><span id="4634" class="lb ir hi kx b fi lg ld l le lf">        train_loss = 0.<br/>        val_loss = 0.</span><span id="4bfc" class="lb ir hi kx b fi lg ld l le lf">        resnet18.train() # set model to training phase</span><span id="e9ac" class="lb ir hi kx b fi lg ld l le lf">        for train_step, (images, labels) in enumerate(dl_train):<br/>            optimizer.zero_grad()<br/>            outputs = resnet18(images)<br/>            loss = loss_fn(outputs, labels)<br/>            loss.backward()<br/>            optimizer.step()<br/>            train_loss += loss.item()<br/>            if train_step % 20 == 0:<br/>                print('Evaluating at step', train_step)</span><span id="ecb8" class="lb ir hi kx b fi lg ld l le lf">                accuracy = 0</span><span id="64ea" class="lb ir hi kx b fi lg ld l le lf">                resnet18.eval() # set model to eval phase</span><span id="b96d" class="lb ir hi kx b fi lg ld l le lf">                for val_step, (images, labels) in enumerate(dl_test):<br/>#                     print(type(images),images)<br/>                    outputs = resnet18(images)<br/>                    loss = loss_fn(outputs, labels)<br/>                    val_loss += loss.item()</span><span id="52b9" class="lb ir hi kx b fi lg ld l le lf">                    _, preds = torch.max(outputs, 1)<br/>                    accuracy += sum((preds == labels).numpy())</span><span id="81c9" class="lb ir hi kx b fi lg ld l le lf">                val_loss /= (val_step + 1)<br/>                accuracy = accuracy/len(test_dataset)<br/>                <br/>                <br/>                print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')</span><span id="c9b3" class="lb ir hi kx b fi lg ld l le lf">                show_preds()</span><span id="71be" class="lb ir hi kx b fi lg ld l le lf">                resnet18.train()</span><span id="e191" class="lb ir hi kx b fi lg ld l le lf">                if accuracy &gt;= 0.95:<br/>                    print('Performance condition satisfied, stopping..')<br/>                    break</span><span id="5700" class="lb ir hi kx b fi lg ld l le lf">        train_loss /= (train_step + 1)<br/>        print(f'Training Loss: {train_loss:.4f}')<br/>    print('Training complete..')</span></pre><p id="d7f6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">让我们称火车函数 py 通过时期=1:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="24f6" class="lb ir hi kx b fi lc ld l le lf">train(epochs=1)</span></pre><p id="a8ec" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果一切正常，训练将会开始，将会显示如下输出:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es md"><img src="../Images/1bb7c5012afc4b9abfbd86e4dfd03f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*0f3twLQ67pebmaxxjHG6uw.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">培训阶段</figcaption></figure><p id="4f1e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">恭喜，培训已经完成，我们的模型现在可以保存和测试了。让我们首先保存模型:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="319c" class="lb ir hi kx b fi lc ld l le lf">torch.save(resnet18,'./model.pth')</span></pre><p id="5e96" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">记住，我们创建了一个预测函数。现在是打电话的最佳时机。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="f2a5" class="lb ir hi kx b fi lc ld l le lf">show_preds()</span></pre><p id="841b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">输出:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es me"><img src="../Images/0a28c8b0d0004dbb4b57acc1df8f60f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*KABzBBYVRjDh2LxEWooj0w.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">测试阶段</figcaption></figure><h1 id="fa6b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">预测单幅图像上的类别标签</h1><p id="91cb" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">到目前为止，我们已经在不同批次的图像上训练了我们的模型。现在是在单个图像输入上测试它的时候了。为此，我们需要首先转换输入，就像我们转换测试图像一样。之后，我们加载保存的模型的权重，将模式更改为 evaluation，并将图像作为输入进行传递，以产生输出张量。然后，使用字典映射，我们返回预测的标签。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6b16" class="lb ir hi kx b fi lc ld l le lf">model = torch.load('./model.pth')<br/>model.eval()</span><span id="cca9" class="lb ir hi kx b fi lg ld l le lf">loader = torchvision.transforms.Compose([<br/>    torchvision.transforms.Resize(size = (224,224)),<br/>    torchvision.transforms.ToTensor(),<br/>    torchvision.transforms.Normalize(mean =[0.485,0.456,0.406],std=[0.229,0.224,0.225]),    <br/>])<br/>def image_loader(image_name):<br/>    """load image, returns cuda tensor"""<br/>    image = Image.open(image_name).convert('RGB')<br/>    image = loader(image).float()<br/>    image = Variable(image, requires_grad=True)<br/>    image = image.unsqueeze(0)<br/>    return image</span><span id="a247" class="lb ir hi kx b fi lg ld l le lf">#pass the path of the image to be tested<br/>image = image_loader('archive/COVID-19 Radiography Database/test/viral/Viral Pneumonia (416).png')</span><span id="1ce8" class="lb ir hi kx b fi lg ld l le lf">res_dict = {0:"Normal",1:"Viral",2:"Covid"}<br/>output = model(image)<br/># print(output)<br/>_, preds = torch.max(output, 1)<br/># print(preds)<br/>print(res_dict[preds.tolist()[0]])</span></pre><h1 id="05b9" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">输入图像</h1><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/0fc828ce35de1313ec2eea80342c7955.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fW3cUv-Hoe7BGCqkG8CFOA.png"/></div></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">要验证的图像</figcaption></figure><h1 id="b4b8" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">输出</h1><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="5914" class="lb ir hi kx b fi lc ld l le lf">Viral</span></pre><p id="2e12" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">记住一件事，在创建输出字典时，我们需要注意训练时分配的类的顺序。这里[0]对应正常，[1]对应病毒性，[2]对应 COVID。</p><h1 id="1d3e" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论</h1><p id="b39a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">就是这样。我们已经成功创建了一个分类模型，该模型可以对一个人进行胸部 x 光检查，并预测这个人是正常的，即健康的，还是有病毒的，或者是受 COVID 影响的。这个问题的完整代码实现可以在我的<a class="ae kr" href="https://github.com/sjaishanker/Covid19-Detection-Using-Chest-X-Ray-Images" rel="noopener ugc nofollow" target="_blank"> Github </a>库中找到。</p><p id="d4f9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">研究是当务之急，至少尝试成为希望让我们的生活更安全、更健康的群体的一员，这种感觉很好。</p></div></div>    
</body>
</html>