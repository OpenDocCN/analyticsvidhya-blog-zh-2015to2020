<html>
<head>
<title>Water Pump Classification with Catboost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Catboost 的水泵分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/mining-the-water-table-water-pump-classification-5644c7b2635c?source=collection_archive---------14-----------------------#2020-08-07">https://medium.com/analytics-vidhya/mining-the-water-table-water-pump-classification-5644c7b2635c?source=collection_archive---------14-----------------------#2020-08-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b760f0cf6926faacfaa14998ae9625b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xHcRr7kfp7gHtgp-"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">由<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae iu" href="https://unsplash.com/@_mrjn_esf?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> mrjn 摄影</a>拍摄</figcaption></figure><p id="e8c8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇文章中，我使用 CatBoost 分类模型来预测水泵的运行状况。根据<a class="ae iu" href="http://taarifa.org/" rel="noopener ugc nofollow" target="_blank">塔里法</a> &amp; <a class="ae iu" href="http://maji.go.tz/" rel="noopener ugc nofollow" target="_blank">坦桑尼亚水利部</a>提供的数据，这些水泵要么可以使用，需要维修，要么根本不工作。问题由<a class="ae iu" href="https://www.drivendata.org" rel="noopener ugc nofollow" target="_blank">数据驱动</a>主持。</p><p id="6bc0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于这个问题，我使用了 CatBoost 算法，因为数据中有大量的分类变量。其他(失败的)尝试包括尝试一键编码+用截断 SVD 降维。考虑到某些分类特征的高基数，这些结果是意料之中的。对于这个限制，CatBoost 提供了一个解决方案，因为它能够更轻松地处理分类变量。模型评估基于 f1 分数、准确性和在数据驱动网站上托管的最终测试集的性能。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="7066" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak">探索数据</strong></h1><p id="df19" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">有 3 个数据文件用于分析:</p><ul class=""><li id="dcfc" class="ld le hi ix b iy iz jc jd jg lf jk lg jo lh js li lj lk ll bi translated">labels.csv:描述滨水区是功能性的、非功能性的还是功能性的需要修复。这是分析的目标变量</li><li id="f3d8" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">values.csv:包含水泵所有特性的字段</li><li id="ace3" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">competition_test.csv:用于预测地下水位状态的功能，在数据驱动网站上提交预测</li></ul><p id="fa55" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每个记录或滨水区都有 30 多个相关联的要素，有些要素缺少值。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="543b" class="ma kb hi lw b fi mb mc l md me"># Reading in the data<br/>labels = pd.read_csv(“labels.csv”)<br/>values = pd.read_csv(“values.csv”)<br/>df = pd.merge(labels, values, on= “id”)<br/>y = df[[‘status_group’]]<br/>X = df.drop([‘status_group’,’id’], axis = 1)</span><span id="e6a5" class="ma kb hi lw b fi mf mc l md me"><strong class="lw hj">X.info()</strong></span><span id="4faf" class="ma kb hi lw b fi mf mc l md me"><em class="mg">Data columns (total 39 columns):<br/> #   Column                 Non-Null Count  Dtype  <br/>---  ------                 --------------  -----  <br/> 0   amount_tsh             59400 non-null  float64<br/> 1   date_recorded          59400 non-null  object <br/> 2   funder                 55765 non-null  object <br/> 3   gps_height             59400 non-null  int64  <br/> 4   installer              55745 non-null  object <br/> 5   longitude              59400 non-null  float64<br/> 6   latitude               59400 non-null  float64<br/> 7   wpt_name               59400 non-null  object <br/> 8   num_private            59400 non-null  int64  <br/> 9   basin                  59400 non-null  object <br/> 10  subvillage             59029 non-null  object <br/> 11  region                 59400 non-null  object <br/> 12  region_code            59400 non-null  int64  <br/> 13  district_code          59400 non-null  int64  <br/> 14  lga                    59400 non-null  object <br/> 15  ward                   59400 non-null  object <br/> 16  population             59400 non-null  int64  <br/> 17  public_meeting         56066 non-null  object <br/> 18  recorded_by            59400 non-null  object <br/> 19  scheme_management      55523 non-null  object <br/> 20  scheme_name            31234 non-null  object <br/> 21  permit                 56344 non-null  object <br/> 22  construction_year      59400 non-null  int64  <br/> 23  extraction_type        59400 non-null  object <br/> 24  extraction_type_group  59400 non-null  object <br/> 25  extraction_type_class  59400 non-null  object <br/> 26  management             59400 non-null  object <br/> 27  management_group       59400 non-null  object <br/> 28  payment                59400 non-null  object <br/> 29  payment_type           59400 non-null  object <br/> 30  water_quality          59400 non-null  object <br/> 31  quality_group          59400 non-null  object <br/> 32  quantity               59400 non-null  object <br/> 33  quantity_group         59400 non-null  object <br/> 34  source                 59400 non-null  object <br/> 35  source_type            59400 non-null  object <br/> 36  source_class           59400 non-null  object <br/> 37  waterpoint_type        59400 non-null  object <br/> 38  waterpoint_type_group  59400 non-null  object</em></span></pre><p id="f40c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面是数据集中前 5 个泵的样本数据片段。</p><figure class="lr ls lt lu fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/f1340f6f6d4a6235229ba9d67739ef5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ACrKxfxVGgjb7WVT3jJxA.png"/></div></div></figure><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="7d69" class="ma kb hi lw b fi mb mc l md me"># Frequency plot of target values<br/>y[‘status_group’].value_counts().plot(kind=’bar’)<br/>plt.xlabel(‘Water Status’)<br/>plt.ylabel(‘Frequency’)</span></pre><figure class="lr ls lt lu fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/0ce76bdc94f9c181952d831629845a21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*xk-pS605oSxNP9sgT1F0sg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">目标可变频率图</figcaption></figure><p id="62f7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">快速查看目标变量显示，大多数泵都在运行，需要维修的泵较少。这种阶级不平衡将在稍后的建模中触及。</p><p id="3a66" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我将 X 变量分为分类数据和数字数据，以研究关系和缺失值。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="923b" class="ma kb hi lw b fi mb mc l md me">X_categ = X.select_dtypes(include=[‘object’])<br/>X_num_list = list(set(X.columns)-set(X_categ.columns))<br/>X_num = X[X_num_list]</span></pre><p id="d4fc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数字特征的快速绘图显示了变量之间的一些初始相关性。粗略地看一下变量的值计数，<strong class="ix hj"> <em class="mg">构造 _ 年份</em> </strong>和<strong class="ix hj"><em class="mg">GPS _ 高度</em> </strong>具有大量的 0 值，导致高度相关，如下图所示。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="dbc7" class="ma kb hi lw b fi mb mc l md me">sns.heatmap(X_num.corr(), annot=True)</span></pre><figure class="lr ls lt lu fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/25c3f317c065372509f99bd8d0d409a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*jPtOh00GfUbcB1OTLCE3-g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">数值变量的相关图</figcaption></figure><p id="26a2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">地区代码</strong>和<strong class="ix hj"> <em class="mg">地区代码</em> </strong>也显示正相关，因为两者也基于地理位置。</p><p id="5221" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">0 值被编码为缺失值，因为它们是真正缺失的，而不是显示为欺骗模型的 0。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="b316" class="ma kb hi lw b fi mb mc l md me">X_categ.describe()</span></pre><figure class="lr ls lt lu fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/bd9ea4a33dcd60bbd95ae88431392458.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1_hJVhD7XoJQI2lfbFfxJw.png"/></div></div></figure><p id="edf7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一些分类变量有很高的基数，如图所示。有些有超过 19，000 个唯一值。这使得我最初的 One-Hot-Encoding 管道在失败的尝试中变成了一场噩梦。因此，CatBoost 的特征重要性功能被用于识别解释数据中大部分方差的变量。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="7423" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak">方法学&amp;结果</strong></h1><p id="40e9" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">下表总结了模型尝试和每个尝试所采取的步骤。</p><figure class="lr ls lt lu fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/ae3b21c88d3c00d6f3d840388e66023a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L1LVDikADL4MHm62jz7lVg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">模型比较和评估</figcaption></figure><p id="8cd2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">根据微观 F1 评分和数据驱动网站上的持续评分，车型 2 得分最高</strong>。还使用来自 sklearn 的分类报告来评估模型上每个预测类别的精确度和召回率。</p><p id="3ab5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面是获得模型 2 设置的步骤总结，从用于数据清理的<strong class="ix hj"> clean_x </strong>函数和用于输入缺失值的<strong class="ix hj"> ColumnTransformer </strong>开始&amp;缩放数值变量。<br/> <a class="ae iu" href="https://github.com/AdetomiwaO/Mining_the_water_table" rel="noopener ugc nofollow" target="_blank"> <em class="mg">全部代码发布在 GitHub </em> </a>上</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="bba3" class="ma kb hi lw b fi mb mc l md me">#Create a clean_x function to prepare X variables</span><span id="6916" class="ma kb hi lw b fi mf mc l md me">def clean_x(df):<br/><br/> df = df[feat_selected]<br/> #replace 0 values as true NaN<br/> # replace 0 values with np.NaN so they appear as missing rather than 0</span><span id="4bad" class="ma kb hi lw b fi mf mc l md me">df.gps_height.replace(0, np.NaN, inplace = True)<br/>df.construction_year.replace(0, np.NaN, inplace = True)<br/>df.population.replace(0, np.NaN, inplace = True)<br/>df.longitude.replace(0, np.NaN, inplace = True)<br/>df.latitude.replace(-0.00000002, np.NaN, inplace = True)<br/> <br/> # create new column for the year the waterpoint was constructed<br/> df[‘year_recorded’] = pd.to_datetime(df[‘date_recorded’]).dt.year</span><span id="63ae" class="ma kb hi lw b fi mf mc l md me"> #Add new column denoting the estimated age of the waterpoint<br/> df[‘age’] = df[‘year_recorded’] — df[‘construction_year’]</span><span id="124a" class="ma kb hi lw b fi mf mc l md me"> #drop date recorded column since we have a new measure for the estimated age of the water source<br/> df = df.drop([‘date_recorded’], axis = 1)<br/> <br/> # Convert Categorical features to str values<br/> categorical_features = list(df.select_dtypes(include=[‘object’]).columns)</span><span id="a186" class="ma kb hi lw b fi mf mc l md me"> df[categorical_features] = df[categorical_features].astype(str, copy=False)<br/> <br/> return df</span></pre><p id="7886" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">缺失的数值用平均值代替，缺失的分类值用最频繁出现的值代替。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="4442" class="ma kb hi lw b fi mb mc l md me"># Create column transformer pipelines for X variables:<br/># transforming numeric features<br/>numerics = [‘int16’, ‘int32’, ‘int64’, ‘float16’, ‘float32’, ‘float64’]<br/>numeric_features = list(X_train_m1.select_dtypes(include=numerics).columns)</span><span id="836e" class="ma kb hi lw b fi mf mc l md me">numeric_pipe = Pipeline(steps=[<br/> (‘num_imputer’, IterativeImputer(initial_strategy =’mean’, <br/> imputation_order = ‘descending’)),<br/> (‘scaler’, StandardScaler())])</span><span id="b67a" class="ma kb hi lw b fi mf mc l md me"># transforming categorical features <br/>categorical_features = list(X_train_m1.select_dtypes(include=[‘object’]).columns)</span><span id="6637" class="ma kb hi lw b fi mf mc l md me">categ_pipe = Pipeline(steps=[<br/> (‘cat_imputer’, SimpleImputer(strategy=’most_frequent’))<br/> ])</span><span id="65f4" class="ma kb hi lw b fi mf mc l md me"># column transformer<br/>preprocessor = ColumnTransformer(transformers=[<br/> (‘num’, numeric_pipe, numeric_features),<br/> (‘cat’, categ_pipe, categorical_features)<br/> ])</span></pre><p id="767f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我使用列转换器创建了一个函数来准备输入数据。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="6640" class="ma kb hi lw b fi mb mc l md me">def impute_x_m2(X_train_m1, X_test_m1, X_comp_m1):</span><span id="351a" class="ma kb hi lw b fi mf mc l md me"> X_train_m2 = pd.DataFrame(preprocessor.fit_transform(X_train_m1), columns= numeric_features+categorical_features)</span><span id="eab5" class="ma kb hi lw b fi mf mc l md me"> X_test_m2 = pd.DataFrame(preprocessor.transform(X_test_m1), columns = numeric_features+categorical_features)</span><span id="55af" class="ma kb hi lw b fi mf mc l md me"> X_comp_m2 = pd.DataFrame(preprocessor.transform(X_comp_m1), columns = numeric_features+categorical_features)<br/> <br/> return X_train_m2, X_test_m2, X_comp_m2</span><span id="8cf3" class="ma kb hi lw b fi mf mc l md me">X_train_m2, X_test_m2, X_comp_m2 = impute_x_m2(X_train_m1, X_test_m1, X_comp_m1)</span></pre><p id="e0cd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，启动 CatBoost 算法并设置训练和评估集。损失函数设置为“多类”,所有模型都通过 Google Collab 在 GPU 上运行。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="de0d" class="ma kb hi lw b fi mb mc l md me">#Initiate cb2 model<br/>cbm2 = CatBoostClassifier(cat_features = cat_features2, <br/> loss_function = ‘MultiClass’,<br/> random_seed=42,<br/> task_type = ‘GPU’)</span><span id="8135" class="ma kb hi lw b fi mf mc l md me">#Prepare input &amp; eval data<br/>train_dataset_m2 = Pool(data=X_train_m2.astype(str),<br/>                     label=y_train,<br/>                     cat_features=cat_features2)</span><span id="eb7c" class="ma kb hi lw b fi mf mc l md me">eval_dataset_m2 = Pool(data=X_test_m2.astype(str),<br/>                    label=y_test,<br/>                    cat_features=cat_features2)</span></pre><p id="c153" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对一些参数进行了网格搜索。最佳搜索返回{'depth': 10，' iterations': 3000，' l2_leaf_reg': 3，' learning_rate': 0.03}搜索在 GPU 上运行了大约 30 分钟。<strong class="ix hj"> <em class="mg">注:</em> </strong> <em class="mg">该模型不解决数据集的类不平衡问题，因为默认设置将所有类权重设置为 1 进行训练。</em></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="50c8" class="ma kb hi lw b fi mb mc l md me">#Setting up Parameters for model 2<br/>grid2 = {‘depth’: [3,10],<br/>         ‘iterations’: [1000,3000],<br/>         ‘l2_leaf_reg’: [3,5],<br/>         ‘learning_rate’: [0.1, 0.03, 0.05]}</span><span id="d962" class="ma kb hi lw b fi mf mc l md me">gs_catb_m2 = cbm2.grid_search(grid2, <br/> X = X_train_m2, <br/> y = y_train, <br/> plot=True,<br/> cv=3)</span></pre><p id="e739" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最佳参数适用于模型 2 并生成分类报告</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="ae4c" class="ma kb hi lw b fi mb mc l md me"># Fit best parameters on Model 2<br/>cbm2_best.fit(train_dataset_m2)<br/>y_pred_catb_m2 = cbm2_best.predict(eval_dataset_m2, prediction_type = 'Class')</span><span id="8b1d" class="ma kb hi lw b fi mf mc l md me">#Classification report of model 2 <br/>print(classification_report(y_test, y_pred_catb_m2, digits = 5))</span><span id="78bf" class="ma kb hi lw b fi mf mc l md me">                          precision  recall    f1-score   support<br/><br/>             functional    0.80015   0.90539   0.84952      9724<br/>functional needs repair    0.63077   0.28538   0.39297      1293<br/>         non functional    0.84034   0.76981   0.80353      6803<br/><br/>               accuracy                        0.80864     17820<br/>              macro avg    0.75708   0.65353   0.68201     17820<br/>           weighted avg    0.80320   0.80864   0.79884     17820</span></pre><p id="9124" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">模型 2 使用的关键特征解释了数据中 90%的差异。与其他模型相比，缺失值的插补似乎有助于模型得分。</p><p id="0f8a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对持有数据进行了单独的预测，其表现也优于其他模型。</p><h1 id="4597" class="ka kb hi bd kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt mq kv kw kx bi translated"><span class="l mr ms mt bm mu mv mw mx my di"> W </span> <strong class="ak">关于阶级失衡的帽子？</strong></h1><p id="e715" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">回到阶级不平衡的话题(因为数据不平衡)。模型 2 将所有等级视为具有相同的重量，但是模型 3 实际上对于需要修理的未被充分代表的泵等级具有更好的分数。在一个目标集中在需要修理的泵上的世界里。模型 3 有最好的 f1 分数，因为它平衡了培训期间对班级的支持。模型 3 的精度是 43%,而模型 2 是 63%,但是召回率是 46%,而模型 2 是 29%。这意味着模型 2 更有可能不会将需要维修的泵贴错标签，模型 3 更有可能找到更多需要维修的泵。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="a0b2" class="ma kb hi lw b fi mb mc l md me"><strong class="lw hj">#Best Parameters for Model 3</strong><br/>{'auto_class_weights': 'Balanced',<br/> 'depth': 10,<br/> 'iterations': 3000,<br/> 'l2_leaf_reg': 3,<br/> 'learning_rate': 0.03}</span><span id="3b7c" class="ma kb hi lw b fi mf mc l md me"><strong class="lw hj"># Classification report for Model 3</strong><br/>                           precision recall    f1-score   support<br/><br/>             functional    0.82045   0.85006   0.83499      9724<br/>f<strong class="lw hj">unctional needs repair    0.42857   0.45940   0.44345      1293</strong><br/>         non functional    0.83409   0.77966   0.80596      6803<br/><br/>               accuracy                        0.79484     17820<br/>              macro avg    0.69437   0.69637   0.69480     17820<br/>           weighted avg    0.79722   0.79484   0.79550     17820</span></pre><h1 id="c437" class="ka kb hi bd kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt mq kv kw kx bi translated"><strong class="ak">结论</strong></h1><p id="7bdc" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">基于 f1 微分数，模型 2 在所有模型中表现最佳。虽然改进不是很大，但似乎插补、特征选择和一些数据清理使该模型比基于默认参数和无预处理的基本模型更可信。</p><p id="ebef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">鉴于一次性编码和降维的失败尝试，建模的设置最初是一个挑战。数据探索相当有趣，因为许多领域都是相似的，并且有相似的漏洞。现实世界数据和建模前所需清理的非常清晰的例子。</p><p id="e8e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">还有探索其他特征选择方法的空间，如卡方特征选择或互信息特征选择，因为它们都属于分类变量。</p><p id="6269" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我还想象可以有进一步的功能工程，特别是地理位置功能(经度，纬度)。它们可用于计算离主要城市/水体的距离，这可以提供对泵的状态的更多了解。</p><p id="9313" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">未来的探索还可能包括其他处理分类变量的模型，如 LightGBM 和 H2oGBM。我还在下面加入了一些完成这个项目时用到的参考工具和文章。特别感谢<a class="ae iu" href="https://www.drivendata.org/" rel="noopener ugc nofollow" target="_blank"> DataDriven </a>主持并创建了具有社会影响力的数据科学平台。</p><h1 id="c849" class="ka kb hi bd kc kd mm kf kg kh mn kj kk kl mo kn ko kp mp kr ks kt mq kv kw kx bi translated"><strong class="ak">参考文献</strong></h1><div class="mz na ez fb nb nc"><a href="https://catboost.ai/docs/%5C" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hj fi z dy nh ea eb ni ed ef hh bi translated">CatBoost 概述。证明文件</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">CatBoost 是一种机器学习算法，在决策树上使用梯度推进。它是作为一个开放的…</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">catboost.ai</p></div></div><div class="nl l"><div class="nm l nn no np nl nq io nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a href="https://stackoverflow.com/questions/48507651/multiple-classification-models-in-a-scikit-pipeline-python" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hj fi z dy nh ea eb ni ed ef hh bi translated">scikit 管道 python 中的多个分类模型</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">考虑在这里查看类似问题:用 sklearn pipeline Pipeline 比较多个算法:多个…</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">stackoverflow.com</p></div></div><div class="nl l"><div class="nr l nn no np nl nq io nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a href="https://datascience.stackexchange.com/questions/53181/large-no-of-categorical-variables-with-large-no-of-categories" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hj fi z dy nh ea eb ni ed ef hh bi translated">具有大量类别的大量分类变量</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">begingroup$对分类变量进行编码，这样就不会丢失信息，也不会添加不存在的…</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">datascience.stackexchange.com</p></div></div><div class="nl l"><div class="ns l nn no np nl nq io nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a href="https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e" rel="noopener follow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hj fi z dy nh ea eb ni ed ef hh bi translated">Python 机器学习中的特征选择技术</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">新的一天带来新的力量和新的思想——艾拉诺·罗斯福</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="nt l nn no np nl nq io nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a href="https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hj fi z dy nh ea eb ni ed ef hh bi translated">混合类型的色谱柱变压器-sci kit-了解 0.23.2 文档</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">sci kit-learn:Python 中的机器学习</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">scikit-learn.org</p></div></div><div class="nl l"><div class="nu l nn no np nl nq io nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a href="https://colab.research.google.com/" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hj fi z dy nh ea eb ni ed ef hh bi translated">谷歌联合实验室</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">编辑描述</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">colab.research.google.com</p></div></div><div class="nl l"><div class="nv l nn no np nl nq io nc"/></div></div></a></div></div></div>    
</body>
</html>