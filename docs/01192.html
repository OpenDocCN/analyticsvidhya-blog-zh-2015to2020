<html>
<head>
<title>Incremental Gains: Episode 1 — Optimizing Pandas Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">增量收益:第1集—优化熊猫代码</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/incremental-gains-episode-1-optimizing-pandas-code-76788db49e8a?source=collection_archive---------11-----------------------#2019-10-07">https://medium.com/analytics-vidhya/incremental-gains-episode-1-optimizing-pandas-code-76788db49e8a?source=collection_archive---------11-----------------------#2019-10-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/d9914ca152e9298787000241ae906f5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*KFc2SEX-XALojgTvE5yO0Q.jpeg"/></div></figure><p id="e3dd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以我目前正在开发一个音乐推荐系统，它建立在<a class="ae jk" href="https://www.discogs.com/" rel="noopener ugc nofollow" target="_blank"> Discogs </a>数据库之上。在基本层面上，它对数千名Discogs用户的<a class="ae jk" href="https://www.discogs.com/wantlist?user=tosker" rel="noopener ugc nofollow" target="_blank">需求列表</a>和<a class="ae jk" href="https://www.discogs.com/user/tosker/collection?header=1&amp;sort_by=artists_sort" rel="noopener ugc nofollow" target="_blank">收藏</a>使用ALS矩阵分解，为音乐爱好者和黑胶唱片收藏家等提供新的音乐推荐。在Medium上有很多关于协同过滤和其他推荐系统如何工作的优秀文章，其中很多是我在最初创建项目时参考的。相反，这一系列的帖子不是重复已经说得很好的内容，而是旨在记录我在使代码库&amp;管道更适合生产的过程中所经历的考验和磨难。和我一起把这个Jupyter笔记本原型带到野外吧！</p><h1 id="0b87" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">框定问题:</h1><p id="f6be" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">在Discogs上，每个相册都有一个对应的<strong class="io hj">release_id</strong>——因此，对于我拥有个人资料信息的每个用户，我都有一个与他们的Wantlist &amp;集合中的release _ id相对应的数组。在将这些用户-专辑交互的大型稀疏矩阵输入矩阵分解模型后，我只需使用<a class="ae jk" href="https://www.benfrederickson.com/blog/" rel="noopener ugc nofollow" target="_blank"> Ben Frederickson </a>的惊人的<a class="ae jk" href="https://github.com/benfred/implicit" rel="noopener ugc nofollow" target="_blank">隐式</a>库，就能为每个用户获得前N个推荐专辑。</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">基本隐式工作流</figcaption></figure><p id="19fe" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了尽可能减少实时推荐，我选择在模型合适时为每个用户生成前2000个推荐，并将它们全部存储到Mongo数据库中。这样，如果用户已经在系统中，很容易快速获取他们的推荐。2000张专辑可能太多了——但我宁愿要太多也不要太少。</p><p id="7438" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里有一个问题，每个用户的2000个推荐只是一个<em class="lc">类别代码</em>对应一个<strong class="io hj"> release_id </strong>。它只是我们稀疏矩阵中一个专辑的release_id的项目索引。因此，这里的任务是:</p><ol class=""><li id="b111" class="ld le hi io b ip iq it iu ix lf jb lg jf lh jj li lj lk ll bi translated">将推荐<em class="lc">类别代码</em>，我称之为<strong class="io hj"> release_idx </strong>，映射到专辑的<strong class="io hj"> release_id </strong>。</li><li id="d49b" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">提取所有相关的专辑元数据— <em class="lc">艺术家、标题、唱片公司、流派等。</em> —并合并到每个建议中。(因为用户仅仅从一个<strong class="io hj"> release_id </strong>中获得的价值很小，咄。)</li><li id="315c" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">提取用户已经交互过的相册的所有相册元数据。这主要用于自定义用户过滤，即，如果用户想要隐藏他们已经知道或已经与之交互的艺术家或标签的推荐项目。</li><li id="7ae5" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">将每个用户的推荐和previous_interactions存储到Mongo。</li><li id="da25" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">做得<strong class="io hj">快</strong>。</li></ol><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">用户推荐的JSON输出示例</figcaption></figure><p id="5b55" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">第五步——动作要快——</strong>是这里的关键，因为理想情况下，我想每晚都改装一下模型。我让抓取器不断抓取新的用户资料，所以推荐会根据新信息略有变化。但更重要的是，我希望能够根据用户与web应用程序的在线交互来修改模型参数和测试，例如，考虑到随后添加到用户需求列表甚至购买的推荐的验证方案。</p><blockquote class="lr"><p id="9003" class="ls lt hi bd lu lv lw lx ly lz ma jj dx translated">简而言之，<em class="mb">我如何尽可能快地为所有用户收集并存储2000条带有元数据的推荐</em> <strong class="ak"> <em class="mb">？</em>T9】</strong></p></blockquote><blockquote class="mc md me"><p id="ef8f" class="im in lc io b ip mf ir is it mg iv iw mh mi iz ja mj mk jd je ml mm jh ji jj hb bi translated">TL；DR —借助smarter Pandas代码，我能够将每用户处理时间从标准偏差为0.7秒的约1.8秒降至标准偏差为约150毫秒的约500毫秒。</p></blockquote><h1 id="57dd" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">基线</h1><p id="56e2" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">我最初的设计计划是相当快速和肮脏的。我在一个bootcamp项目周期中，在这个阶段更专注于设置一个基本的Flask应用程序。由于必须建立数据库基础设施，我的脑袋已经在SQL领域了，所以我想为什么不让Postgres来处理获取元数据的工作呢？对于几千名用户来说，这是一个不错的方案:</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">基线方法—主要显示在user references . get _ rec _ metadata()中</figcaption></figure><p id="e60d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">基线流程的要点是:</p><ol class=""><li id="2549" class="ld le hi io b ip iq it iu ix lf jb lg jf lh jj li lj lk ll bi translated">遍历每个用户</li><li id="ab61" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">在Postgres数据库中查询每个推荐专辑的元数据(4个连接)</li><li id="8140" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">在Postgres数据库中查询用户需求列表和集合的元数据</li><li id="ec7f" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">将元数据格式化为JSON并作为文档存储到Mongo</li></ol><h2 id="ccc3" class="mn jm hi bd jn mo mp mq jr mr ms mt jv ix mu mv jz jb mw mx kd jf my mz kh na bi translated">结果</h2><p id="2cf5" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">这不是<em class="lc">可怕的</em>表现。它的一个好处是非常节省内存，因为大部分工作都是在SQL中完成的。但是你能发现问题吗？</p><pre class="ks kt ku kv fd nb kr nc nd aw ne bi"><span id="36ca" class="mn jm hi kr b fi nf ng l nh ni"># for 1000 Users // GCP n2-highmem-16 (16 cores/128GB RAM)<br/># time in seconds<br/>mean        1.7690<br/>std         0.7683<br/>min         1.4863<br/>25%         1.5930<br/>50%         1.6309<br/>75%         1.6871<br/>max        14.5993</span><span id="01bc" class="mn jm hi kr b fi nj ng l nh ni">Total Time<br/>w/  1 core :  29min 29sec // around 3GB of memory consumption<br/>*w/ 16 cores: 4min 50sec // tops out around 10GB memory-consumption<br/>(multiprocessing evaluation done now in retrospect - see end of V2)</span></pre><h2 id="5e9f" class="mn jm hi bd jn mo mp mq jr mr ms mt jv ix mu mv jz jb mw mx kd jf my mz kh na bi translated">问题</h2><ul class=""><li id="01c5" class="ld le hi io b ip kj it kk ix nk jb nl jf nm jj nn lj lk ll bi translated">许多用户会有重叠的推荐— <strong class="io hj">为每个用户执行一个查询会对相同的元数据产生大量冗余请求。</strong></li><li id="8855" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">每个推荐上限为2000张专辑，但需求列表和收藏可以扩大几个数量级——一些用户的需求列表中有100，000多张专辑。所以这些超级用户会比其他人花更长的时间。同样，与上面的处理相同——许多冗余的查询。</li><li id="47dc" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">与最后一点相关:除了每个查询本身的处理时间之外，首先还有进行数据库调用的I/O开销。对于可能已经查询过的数据，每个用户有两个Postgres <strong class="io hj">。那是一些不必要的等待。</strong></li></ul><p id="c8a9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当时我只需要存储几千名用户来演示应用程序的基本功能，所以我让它运行了几个小时，然后就让它去了。不过，现在我必须拥有20，000名用户，所以肯定还有改进的空间。再来看下一个版本。</p><h1 id="5187" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">版本2.0</h1><p id="9cc9" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">我已经暗示过，我们可以减少对Postgres数据库的冗余查询。方便的是，我们已经通过创建我们的原始<code class="du ko kp kq kr b">sparse_item_user</code>矩阵创建了一组我们的用户已经交互过的所有独特的相册。任何被推荐的专辑实际上都是该集合的成员，就像用户想要的列表或收藏中的任何专辑一样。</p><blockquote class="lr"><p id="0d5a" class="ls lt hi bd lu lv lw lx ly lz ma jj dx translated">为什么不将元数据合并到这个主列表中，并为每个用户过滤这个大表呢？</p></blockquote><figure class="no np nq nr ns ij"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="d44c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这一过程的要点是:</p><ol class=""><li id="97da" class="ld le hi io b ip iq it iu ix lf jb lg jf lh jj li lj lk ll bi translated">创建一个大的数据帧，包含所有用于训练模型的专辑以及相关的元数据，在代码中命名为<code class="du ko kp kq kr b">all_interactions</code>。</li><li id="bed0" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">为用户的Wantlist &amp;集合过滤<code class="du ko kp kq kr b">all_interactions</code>，以获取先前交互的关联元数据。</li><li id="44f9" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">对用户推荐的专辑进行过滤<code class="du ko kp kq kr b">all_interactions</code>，以获得这些推荐的相关元数据。</li><li id="cefc" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj li lj lk ll bi translated">将元数据格式化为JSON并作为文档存储到Mongo</li></ol><h2 id="533e" class="mn jm hi bd jn mo mp mq jr mr ms mt jv ix mu mv jz jb mw mx kd jf my mz kh na bi translated">结果</h2><p id="07c7" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">不是一个很好的开始…</p><p id="e25a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在尝试修改以SQL为中心的框架的逻辑时，我移植了大量低效使用Pandas的操作。</p><pre class="ks kt ku kv fd nb kr nc nd aw ne bi"><span id="5823" class="mn jm hi kr b fi nf ng l nh ni"># for 1000 Users // GCP n2-highmem-16 (16 cores/128GB RAM)<br/># time in seconds<br/>mean        7.909150<br/>std         0.323563<br/>min         7.090000<br/>25%         7.860000<br/>50%         7.970000<br/>75%         8.080000<br/>max        10.760000</span><span id="a664" class="mn jm hi kr b fi nj ng l nh ni">Total Time<br/>w/  1 core :    2hr 12min  // around 10GB of memory consumption<br/>w/ 16 cores: 22 min 48sec // tops out around 70GB memory-consumption</span></pre><h2 id="66dc" class="mn jm hi bd jn mo mp mq jr mr ms mt jv ix mu mv jz jb mw mx kd jf my mz kh na bi translated">注意:大约有2分钟的开销不包括在构建元数据的大数据帧所需的总时间内，但是该操作只需要发生一次。</h2><h2 id="128d" class="mn jm hi bd jn mo mp mq jr mr ms mt jv ix mu mv jz jb mw mx kd jf my mz kh na bi translated">问题</h2><ul class=""><li id="7aaf" class="ld le hi io b ip kj it kk ix nk jb nl jf nm jj nn lj lk ll bi translated">在第172行合并数据帧是一个缓慢的操作，特别是因为我的相册有重复的行，我实际上并不需要这些行，它们将在下一行中删除。</li><li id="d5b8" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">在Pandas/NumPy中，布尔屏蔽通常很快，但是我在第107 &amp; 110行设置为复合条件<em class="lc">的方式使它变慢了。在<code class="du ko kp kq kr b">'username'</code>列中搜索用户不需要发生两次——我可以只为用户选择<code class="du ko kp kq kr b">raw_interactions</code>数据帧的子集，然后只在<code class="du ko kp kq kr b">'score'</code>列上设置掩码。</em></li><li id="b2c3" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">内存使用的膨胀是因为大表需要被复制到独立内核上的每个工作线程。可能有一种我还没有发现的方法可以解决这个问题…</li></ul><p id="1e27" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这似乎是一个悲惨的失败，但是需要注意的是加工时间的标准偏差下降了。并且所用的最大时间也减少了。汇总统计数据向我表明，处理更加一致。这给了我希望，如果我能收紧代码，我可以保持这种更紧密的分布，并进一步降低所有时间。</p><p id="818b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">此时，我应该注意到我开始集成一个<strong class="io hj">多处理</strong>选项，因为这是一个非常适合并行化的任务。使用concurrent.futures模块，这是一个非常简单的代码添加:</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">这将取代v2.py中的第230–233行</figcaption></figure><h1 id="bb86" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">版本2.5</h1><p id="0fb7" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">在上面的2.0版本中，我在<em class="lc">问题</em>下列出的许多见解，当时对我来说并不完全明显，所以在这一点上，我开始寻找其他并行处理的替代方案。GPU包装器、NumPy加速器、底层编译器等。也许我可以用<a class="ae jk" href="https://github.com/rapidsai/cudf" rel="noopener ugc nofollow" target="_blank"> cuDF </a>，或者<a class="ae jk" href="https://github.com/numba/numba" rel="noopener ugc nofollow" target="_blank"> Numba </a>，或者Cython…</p><blockquote class="lr"><p id="6652" class="ls lt hi bd lu lv lw lx ly lz ma jj dx translated">我在寻找一些更好的、更重要的工具，它们可以神奇地修复我的问题，而不是面对不可避免的事情，一行一行地完善我对代码需要什么的理解。</p></blockquote><p id="e7c2" class="pw-post-body-paragraph im in hi io b ip mf ir is it mg iv iw ix mi iz ja jb mk jd je jf mm jh ji jj hb bi translated">然而，我无法让cuDF的最新版本在Ubuntu上正确运行——所以那是不可能的。</p><p id="8faa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果我可以将我的Pandas数据结构转换成NumPy对象，Numba似乎是一个不错的选择。我想，你知道，也许头顶上的熊猫才是罪魁祸首！🤔</p><p id="998f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">将我的数据帧转换成<a class="ae jk" href="https://jakevdp.github.io/PythonDataScienceHandbook/02.09-structured-data-numpy.html" rel="noopener ugc nofollow" target="_blank"> <em class="lc">数组</em> </a>并不太难:这些数组可以处理列之间的多种数据类型，并支持命名字段。在我的专辑元数据的大数据帧上使用这种方法需要更改代码:</p><pre class="ks kt ku kv fd nb kr nc nd aw ne bi"><span id="bb8b" class="mn jm hi kr b fi nf ng l nh ni">pd.DataFrame.to_records(column_dtypes=specify_dtypes_here)</span></pre><p id="c046" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以及用Numpy等价物替代其他熊猫功能:<code class="du ko kp kq kr b">np.concatenate</code>、<code class="du ko kp kq kr b">np.isin</code>等。</p><p id="49ca" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">通过大量非正式的<code class="du ko kp kq kr b">%%timeit</code>测试，看起来几乎所有的操作都要快得多。</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="kw kx l"/></div></figure><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/0dbfa1e70853835af2f5b0da4b023e63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*kp4BYReQOjALb7Nhij_YLg.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">简单布尔掩码</figcaption></figure><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/88d7dfce529c6d4f72f5ea435f718ed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*thl9ICI0FzpRxzz-IjSVnA.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">多个值的布尔掩码</figcaption></figure><p id="ddb0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我在匆忙中没有考虑到的是，这些行动在magnitude⁴.的不同等级是如何扩展的我天真的理解是Pandas是建立在NumPy之上的，因此所有基本的NumPy函数都应该更快，对吗？</p><p id="1ce6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">事实并非如此。要了解熊猫和熊猫在规模上的差异，请看这里。主要的发现是，在大约50万到1百万的记录之后，熊猫实际上在很多操作上表现得更好一点。</p><p id="fe14" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我将省去这个中间实验的全部代码，只强调结果。</p><h2 id="7240" class="mn jm hi bd jn mo mp mq jr mr ms mt jv ix mu mv jz jb mw mx kd jf my mz kh na bi translated">结果</h2><p id="9067" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">OMG这么糟糕👎</p><p id="8d9d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">160秒，仅10个用户。我迫不及待地想要测试更大的样本量。</p><h2 id="33c5" class="mn jm hi bd jn mo mp mq jr mr ms mt jv ix mu mv jz jb mw mx kd jf my mz kh na bi translated">问题</h2><ul class=""><li id="29cd" class="ld le hi io b ip kj it kk ix nk jb nl jf nm jj nn lj lk ll bi translated">对于基本的索引和屏蔽来说，1兆以上记录的NumPy数组有点慢。</li><li id="0706" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">不知何故，将Psycopg光标直接放入NumPy比直接将SQL查询读入Pandas要慢得多。所以不管怎样，我都浪费了时间将查询导入Pandas，然后转换成recarray。</li><li id="0953" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">json.dump不接受NumPy数据类型，所以需要进行额外的转换。</li></ul><h1 id="526c" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">版本3 —我们现在所处的位置</h1><p id="2a88" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">尽管遇到了一点挫折，与NumPy的相处教会了我一些关于熊猫更好表现的有用的东西。我也开始意识到:</p><blockquote class="lr"><p id="33f0" class="ls lt hi bd lu lv lw lx ly lz ma jj dx translated">定义明确的数据帧索引的索引速度很快</p></blockquote><blockquote class="mc md me"><p id="cc42" class="im in lc io b ip mf ir is it mg iv iw mh mi iz ja mj mk jd je ml mm jh ji jj hb bi translated"><em class="hi">定义明确，我特别指的是</em>唯一的、不重复的<em class="hi">键。与访问列的元素相比，您实际上是在引用一个</em> <a class="ae jk" href="https://en.wikipedia.org/wiki/Hash_table" rel="noopener ugc nofollow" target="_blank"> <em class="hi">散列表</em></a><em class="hi">——后者的功能更像一个list⁵.</em></p></blockquote><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="808d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这最后一点是成功的关键，因为我意识到在我的<code class="du ko kp kq kr b">all_interactions</code>数据框架中，每张专辑的<code class="du ko kp kq kr b">'release_idx'</code>相当于index⁶.的数据框架出于存储目的，我将删除任何重复的行，在这些行中，SQL查询可能为一个专辑获取了多个艺术家。所以我真的可以利用这些快速散列查找来过滤<code class="du ko kp kq kr b">all_interactions</code>数据帧。</p><p id="4adf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，获取每个用户的完整推荐列表变得更加简单和高效:</p><ul class=""><li id="3b78" class="ld le hi io b ip iq it iu ix lf jb lg jf lh jj nn lj lk ll bi translated">在前面的步骤中:对行进行重复数据删除，并将<code class="du ko kp kq kr b">all_interactions</code>数据帧的索引设置为<code class="du ko kp kq kr b">['release_idx']</code>列。这个数据帧将被称为<code class="du ko kp kq kr b">all_interactions_dedupe</code>。</li><li id="7ed2" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">将用户的一系列建议传递给<code class="du ko kp kq kr b">all_interactions.loc[recommendations_array]</code></li><li id="ecf9" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">将用户的交互数组传递给<code class="du ko kp kq kr b">all_interactions.loc[wantlist&amp;collection]</code>。筛选唯一的艺术家和标签。</li><li id="c42a" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">格式化为JSON并存储到Mongo。</li></ul><p id="9833" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">代码如下所示。我将逻辑模块化到两个文件中——一个用于类和函数(store.py ),另一个用于实际运行批处理(v3.py)。这更好地将业务逻辑与后台逻辑分离开来:</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">类别和功能</figcaption></figure><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">运行批处理函数的脚本</figcaption></figure><h2 id="cb0e" class="mn jm hi bd jn mo mp mq jr mr ms mt jv ix mu mv jz jb mw mx kd jf my mz kh na bi translated">结果</h2><pre class="ks kt ku kv fd nb kr nc nd aw ne bi"><span id="926f" class="mn jm hi kr b fi nf ng l nh ni"># for 1000 Users // GCP n2-highmem-16 (16 cores/128GB RAM)<br/># time in seconds<br/>mean        0.4825<br/>std         0.1610<br/>min         0.2925<br/>25%         0.4132<br/>50%         0.4559<br/>75%         0.5237<br/>max         4.1009</span><span id="a58d" class="mn jm hi kr b fi nj ng l nh ni">Total Time<br/>w/  1 core :   8min  2sec  // around 11GB of memory consumption<br/>w/ 16 cores:   1min 42sec // tops out around 80GB memory-consumption</span></pre><p id="4452" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">好多了！与蹩脚的Pandas代码相比，速度提高了16倍，与SQL相比，速度提高了3.5倍，行为更加一致。内存激增意味着我确实需要一台稍微贵一点的GCP机型，但节省时间是值得的，尤其是当我扩大用户群的时候。</p><p id="75d0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我可以在半小时多一点的时间内完成我当前的用户量(大约20，000)，此外，<strong class="io hj">我每月节省大约20美元</strong>。这不是一个疯狂的成本降低，但考虑到它的规模每一块。我仍然可以在另一个数量级或两个数量级上实现相对及时和经济高效的处理。</p><h1 id="86ea" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">结论</h1><p id="7056" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">希望这是这个小应用程序迭代生命周期中的一次信息之旅。<strong class="io hj">我认为下一步是将Mongo写操作削减到一个更大的批量操作，并减少一些I/O时间。</strong> <a class="ae jk" href="https://github.com/modin-project/modin" rel="noopener ugc nofollow" target="_blank">摩丁</a>看起来也是一条有趣的往下走的大道。但是现在，我很满足。</p><h2 id="dfe5" class="mn jm hi bd jn mo mp mq jr mr ms mt jv ix mu mv jz jb mw mx kd jf my mz kh na bi translated">吸取的教训:</h2><ul class=""><li id="54bd" class="ld le hi io b ip kj it kk ix nk jb nl jf nm jj nn lj lk ll bi translated">如果您有唯一的键，或者甚至有一个排序的数组，可以通过在列上设置索引来利用筛选数据帧。</li><li id="a40d" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">对于较小的数据集，NumPy重排列可以很快，但会受到50万到100万条记录的影响。</li><li id="7cd0" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">复合布尔屏蔽还会降低某些操作的速度。试试<a class="ae jk" href="https://jakevdp.github.io/PythonDataScienceHandbook/03.12-performance-eval-and-query.html" rel="noopener ugc nofollow" target="_blank"> pd。DataFrame.query() </a>如果有多个条件要匹配。</li><li id="9448" class="ld le hi io b ip lm it ln ix lo jb lp jf lq jj nn lj lk ll bi translated">在盲目信任%%timeit stats之前，请彻底考虑您的使用案例！</li></ul><p id="370a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">更多的帖子将会出现，请稍后回来查看web应用程序本身的链接！评论你发现的任何改进，或者你是否喜欢这样做！</p><p id="f5f5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">也可以联系:</p><p id="aa22" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jk" href="https://github.com/otosky" rel="noopener ugc nofollow" target="_blank"> github </a></p><p id="e97b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jk" href="https://www.linkedin.com/in/olivertosky/" rel="noopener ugc nofollow" target="_blank">领英</a></p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es nu"><img src="../Images/d63acd39b3149656f5b0ec93b7b4a7c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/1*9T1UPR8bjTQfpKR_9OUFLg.gif"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">熊猫成功后的我</figcaption></figure></div><div class="ab cl nv nw gp nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="hb hc hd he hf"><p id="faa6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">[1]这个库怎么推荐都不够(哈)。大部分是用Cython编写的，支持多处理，<strong class="io hj">和</strong> GPU CUDA集成。</p><p id="af4b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">[2] implicit通过将recalculate_user参数集成到ALS模型类的recommend方法中，使这变得稍微方便一些</p><p id="1340" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">[3]我在这里掩饰一个技术细节。模型推荐的一些项目将不会出现在用户的最终推荐列表中，如果它们太新，以至于我还没有获得最近发布的专辑的元数据——查询数据库时的内部合并将丢弃该专辑。Discogs每月都会对他们的整个档案进行数据库转储，所以在最坏的情况下，我只落后一个月。</p><p id="9f94" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">[4]你可以看到我在第5-6行只用了100个样本。</p><p id="08af" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">[5]一些关于熊猫索引复杂性的好的StackOverflow帖子:<a class="ae jk" href="https://stackoverflow.com/questions/45240803/pandas-dataframe-search-is-linear-time-or-constant-time" rel="noopener ugc nofollow" target="_blank">这里</a>，<a class="ae jk" href="https://stackoverflow.com/questions/27238066/what-is-the-point-of-indexing-in-pandas" rel="noopener ugc nofollow" target="_blank">这里</a>，<a class="ae jk" href="https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas" rel="noopener ugc nofollow" target="_blank">这里</a>，这里<a class="ae jk" href="https://stackoverflow.com/questions/50779617/pandas-pd-series-isin-performance-with-set-versus-array" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="cf41" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">[6]注意:在我对release _ ids进行重复数据删除后。对Postgres数据库的原始查询以获取专辑元数据有时会导致某些专辑的重复条目，如果它们有不止一个艺术家的话。例如，<a class="ae jk" href="https://www.discogs.com/Doc-Scott-Goldie-Unreleased-Metal/master/680310" rel="noopener ugc nofollow" target="_blank">Goldie&amp;Doc Scott的这个分割EP </a>会有两个artist _ ids，因此合并会复制发布的行。</p></div></div>    
</body>
</html>