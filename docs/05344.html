<html>
<head>
<title>Exploring Fashion MNIST with Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Tensorflow探索时尚MNIST</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/exploring-fashion-mnist-with-tensorflow-cnn-9283c4bcf0a?source=collection_archive---------16-----------------------#2020-04-18">https://medium.com/analytics-vidhya/exploring-fashion-mnist-with-tensorflow-cnn-9283c4bcf0a?source=collection_archive---------16-----------------------#2020-04-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/147733b730d5f800114bbb3dfb83c967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JEQbd3-KWhaD2coA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">时尚MNIST数据集</figcaption></figure><p id="7152" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">图像分类是计算机视觉中最琐碎但又最具挑战性的问题之一。为了更好地理解，我们尝试在一个非常著名的基准数据集:时尚MNIST上进行图像分类。该数据集旨在取代MNIST，因为:</p><ul class=""><li id="edcf" class="js jt hi iw b ix iy jb jc jf ju jj jv jn jw jr jx jy jz ka bi translated">MNIST太容易了。</li><li id="2d50" class="js jt hi iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">MNIST被滥用了。</li><li id="39dc" class="js jt hi iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">MNIST不能代表现代CV任务。</li></ul><h1 id="c850" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">预处理数据集</h1><p id="1ab2" class="pw-post-body-paragraph iu iv hi iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr hb bi translated">Kaggle上的时尚MNIST数据集由两个文件组成:train.csv和test.csv。这两个文件都有785列，第一列是标签，后面的784列是28x28图像的像素值。来自我们训练数据集的0.1 %的图像形成了验证数据集。</p><p id="dfb5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">卷积神经网络需要输入形状(batch_size，28，28，1)。因此，一维数组被重塑为三维数组。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="e284" class="ls kh hi lo b fi lt lu l lv lw"><strong class="lo hj">def reshape_image</strong> <strong class="lo hj">(data, size):</strong><br/>data=np.array(data)<br/>data=data.reshape(size, 28, 28,1)<br/>return data</span></pre><blockquote class="lx ly lz"><p id="ae4b" class="iu iv ma iw b ix iy iz ja jb jc jd je mb jg jh ji mc jk jl jm md jo jp jq jr hb bi translated">由于我们使用<em class="hi"> ' </em> <strong class="iw hj">【分类交叉熵】'</strong>作为我们的损失函数，我们需要将图像标签转换成多类向量用于训练目的。如果标签是数字，函数<strong class="iw hj">' to _ categorial '</strong>会直接把它们转换成向量。但是如果它们是字符串，就需要对它们进行标签编码，然后使用<strong class="iw hj">' to _ categorial '</strong><em class="hi">。</em></p></blockquote><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="d130" class="ls kh hi lo b fi lt lu l lv lw"><strong class="lo hj">def preprocessY (lst):</strong><br/>integer_encoded = label_encoder.fit_transform(np.array(lst))<br/>trainY=to_categorical(integer_encoded)<br/>return trainY</span></pre><h1 id="c2b2" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">模型架构</h1><p id="7d0b" class="pw-post-body-paragraph iu iv hi iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr hb bi translated">卷积神经网络是图像分类的最佳选择。他们被训练提取相关的特征用于分类。</p><p id="d80b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">输入形状:</strong> (batch_size，28，28，1)<br/><em class="ma">(CNN的输入应该是四维的。)</em></p><p id="add2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">架构:<br/> </strong>使用两个卷积层<em class="ma">(核大小为5×5)</em>，每个卷积层具有128个滤波器。<em class="ma"> MaxPooling </em> <em class="ma">(步幅为2) </em>用于下采样。<em class="ma"> ReLu </em>激活用于确定每个神经元的输出。具有<em class="ma"> 256个输出神经元的全连接层</em>之后是具有10个输出的<em class="ma"> Softmax </em>层。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="594a" class="ls kh hi lo b fi lt lu l lv lw">model=Sequential()<br/>model.add(Conv2D(128, kernel_size=(5, 5), activation=’relu’, input_shape=input_shape))<br/>model.add(MaxPooling2D((2, 2)))<br/>model.add(Conv2D(128, kernel_size=(5, 5), activation=’relu’))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Flatten())<br/>model.add(Dense(256, activation=’relu’))<br/>model.add(Dense(10, activation=’softmax’))<br/>model.compile(loss=CategoricalCrossentropy(), optimizer=Adam(),<br/>metrics=[‘accuracy’])</span></pre><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es me"><img src="../Images/c7a58c0de2e41f581d9bec1b643aed16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/0*WVc7Aud-8lQn79J7"/></div></figure><p id="d945" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">过滤器的数量越多，一次提取的特征就越多。MaxPooling优于average，因为感兴趣的对象可能会产生最高的像素值。</p><h1 id="40b2" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">训练模型</h1><p id="30e9" class="pw-post-body-paragraph iu iv hi iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr hb bi translated">时尚MNIST模型首先被训练10个时代，然后50个时代。这样做是为了观察精度对历元数的依赖程度。</p><p id="7249" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Keras的ImageDataGenerator用于执行数据扩充。</p><pre class="lj lk ll lm fd ln lo lp lq aw lr bi"><span id="03e4" class="ls kh hi lo b fi lt lu l lv lw">gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3, height_shift_range=0.08, zoom_range=0.08)</span></pre><h2 id="494e" class="ls kh hi bd ki mf mg mh km mi mj mk kq jf ml mm ku jj mn mo ky jn mp mq lc mr bi translated">十个时代</h2><p id="742d" class="pw-post-body-paragraph iu iv hi iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr hb bi translated">在批量为128的情况下，最终训练准确率达到88.11%，验证准确率达到87.50%。</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/3089d30f027d37e2018da650bb2be142.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/0*Iy_cP25OvmSj3LEq"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ki">训练和验证准确性趋势</strong></figcaption></figure><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es mt"><img src="../Images/2d583bb1427e0f4b991c7a3b9d4ec1b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/0*99Yc5Mab3v-js6g3"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ki">培训和验证损失趋势</strong></figcaption></figure><h2 id="7367" class="ls kh hi bd ki mf mg mh km mi mj mk kq jf ml mm ku jj mn mo ky jn mp mq lc mr bi translated">五十个时代</h2><p id="f9e8" class="pw-post-body-paragraph iu iv hi iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr hb bi translated">在批量为128的情况下，最终训练准确率达到91.75%，验证准确率达到90.32%。</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es mu"><img src="../Images/ffe73316522358505c862e650641f4a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/0*S6CQ7rPuQaznhlPD"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ki">训练和验证准确性趋势</strong></figcaption></figure><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/cb06cc69ca51d6bc869326cceb2b382a.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/0*4CGyQbKZXNKbURQp"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ki">培训和验证损失趋势:</strong></figcaption></figure><h1 id="7874" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结果</h1><h2 id="9ff6" class="ls kh hi bd ki mf mg mh km mi mj mk kq jf ml mm ku jj mn mo ky jn mp mq lc mr bi translated">十个时代</h2><p id="8654" class="pw-post-body-paragraph iu iv hi iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr hb bi translated"><strong class="iw hj">测试准确率:</strong> 90.21%</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es mw"><img src="../Images/3e233a316f2d126cf8333de5417c90e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*_W8-s8wVHx_-pfiR"/></div></figure><p id="a0fa" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">精准度和召回率:</strong>6级的表现似乎有所下降。</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mx"><img src="../Images/a41d81b4519e5215c7593ac6756a002a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*205u74DsZIiL2XNE"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">混淆矩阵</figcaption></figure><h2 id="da22" class="ls kh hi bd ki mf mg mh km mi mj mk kq jf ml mm ku jj mn mo ky jn mp mq lc mr bi translated">五十个时代</h2><p id="71c4" class="pw-post-body-paragraph iu iv hi iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr hb bi translated">测试准确度: 91.59%</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es my"><img src="../Images/3ea4b73672a917f219f978e0408966a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/0*g34qooAw9CeLeDUX"/></div></figure><p id="1a24" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">精准度和召回率:</strong>成绩再次骤降为6级。</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/1eaf614781dda68c823d53d121412fa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/0*LB-td00RMFLzJfRq"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ki">混淆矩阵</strong></figcaption></figure><p id="d277" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">尼基塔·萨克塞纳<a class="ae na" href="https://github.com/nikita-0209/image-classification/blob/master/GitHub_Fashion_MNIST.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="ma"> (gihub知识库在此)</em> </a>创造并开发了10个时代的代码。50个时代的代码是由奈提克·汗德尔瓦尔<em class="ma"> ( </em> <a class="ae na" href="https://github.com/Naitik1502/Image-Classification/blob/master/Fashion_MNIST.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="ma"> gihub库此处</em> </a> <em class="ma"> ) </em>创造和开发的。</p></div></div>    
</body>
</html>