<html>
<head>
<title>Performance Improving in Spark-Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark 的性能改进-第 2 部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/performance-improving-in-spark-part-2-dc5e6356a964?source=collection_archive---------27-----------------------#2020-09-09">https://medium.com/analytics-vidhya/performance-improving-in-spark-part-2-dc5e6356a964?source=collection_archive---------27-----------------------#2020-09-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a52fedf07b841a8ba0e759eb648798ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sa5keMDzFfg2MGmRxlP3vQ.png"/></div></div></figure><p id="dc46" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上一篇文章中，我们学习了许多提高 spark 工作性能的技巧。我们将在本文中继续同样的内容。如果你没有浏览过前面的文章，下面的链接是给你的。</p><div class="jo jp ez fb jq jr"><a rel="noopener follow" target="_blank" href="/@sunilsharma_72857/performance-improving-in-spark-part-1-d21da06b655e"><div class="js ab dw"><div class="jt ab ju cl cj jv"><h2 class="bd hj fi z dy jw ea eb jx ed ef hh bi translated">Spark 的性能改进-第 1 部分</h2><div class="jy l"><h3 class="bd b fi z dy jw ea eb jx ed ef dx translated">在本文中，我们将讨论如何通过设置 spark 配置来提高 spark 作业的性能…</h3></div><div class="jz l"><p class="bd b fp z dy jw ea eb jx ed ef dx translated">medium.com</p></div></div><div class="ka l"><div class="kb l kc kd ke ka kf io jr"/></div></div></a></div><p id="97be" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">好了，让我们来讨论一些提高性能的方法。</p><p id="4837" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">最大化 Spark 并行性:</strong>Spark 的效率很大程度上是因为它能够大规模并行运行多个任务。要了解如何最大限度地提高并行性，即并行读取和处理尽可能多的数据，您必须了解 Spark 如何将数据从存储读取到内存，以及分区对 Spark 意味着什么。</p><p id="56ec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在数据管理术语中，分区是一种将数据安排到磁盘上可配置和可读的块或连续数据块的子集的方式。如果需要，这些数据子集可以由一个进程中的多个线程独立并行地读取或处理。这种独立性很重要，因为它允许数据处理的大规模并行。<strong class="is hj">为了优化资源利用和最大化并行性，理想的情况是至少要有与执行器上的内核一样多的分区。</strong>如果每个执行器上的分区数量多于核心数量，那么所有的核心都会保持忙碌。您可以将分区视为并行性的原子单位:在单个内核上运行的单个线程可以在单个分区上工作。</p><p id="9865" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark 中分区的大小由<code class="du kg kh ki kj b">spark.sql.files.maxPartitionBytes</code>决定。默认值为 128 MB。您可以减小文件大小，但这可能会导致所谓的“小文件问题”，即许多小分区文件，由于文件系统操作(如打开、关闭和列出目录，这些操作在分布式文件系统上可能会很慢)而导致大量磁盘 I/O 和性能下降。</p><p id="3d04" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有许多方法可以创建分区或者增加或减少分区，但最重要的是<strong class="is hj">随机分区。</strong> <em class="kk">洗牌分区</em>是在洗牌阶段创建的。默认情况下，随机分区的数量在<code class="du kg kh ki kj b">spark.sql.shuffle.partitions</code>中设置为 200。您可以根据您拥有的数据集的大小来调整这个数字，以减少通过网络发送给执行者任务的小分区的数量。</p><p id="3a3e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">无序分区主要是在像<code class="du kg kh ki kj b">groupBy()</code>或<code class="du kg kh ki kj b">join()</code>这样的操作期间创建的，也称为<strong class="is hj">范围转换</strong>，无序分区消耗网络和磁盘 I/O 资源。在这些操作中，shuffle 会将结果溢出到<code class="du kg kh ki kj b">spark.local.directory</code>中指定位置的执行程序的本地磁盘上。<strong class="is hj">为此操作配备高性能 SSD 磁盘将提升性能。</strong></p><p id="c37f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">没有为洗牌阶段设置洗牌分区数量的神奇公式；这个数字可能会根据您的用例、数据集、内核数量和可用的 executor 内存量而有所不同——这是一种试错法。</p><p id="7b1e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数据的缓存/持久化:</strong> <code class="du kg kh ki kj b">cache()</code>将在内存允许的情况下，跨 Spark 执行器存储尽可能多的分区。虽然数据帧可以部分缓存，但分区不能部分缓存(例如，如果有 8 个分区，但只有 4.5 个分区可以放入内存，则只有 4 个分区会被缓存)。但是，如果不是所有的分区都被缓存，当您想要再次访问数据时，没有被缓存的分区将不得不重新计算，从而降低 Spark 作业的速度。而<code class="du kg kh ki kj b">persist(StorageLevel.<em class="kk">LEVEL</em>)</code>则有细微差别，通过<code class="du kg kh ki kj b">StorageLevel</code>提供对如何缓存数据的控制。磁盘上的数据总是使用 Java 或 Kryo 序列化进行序列化。有关持久性和存储级别的更多信息，请参考 spark 文档<a class="ae kl" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> spark_documentation。</a></p><p id="ea3d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> Spark Joins: </strong> Join 操作是大数据分析中一种常见的转换类型，在这种转换中，两个数据集以表或数据帧的形式通过一个通用匹配键进行合并。与关系数据库类似，Spark DataFrame 和 Dataset APIs 以及 Spark SQL 提供了一系列连接转换:内部连接、外部连接、左连接、右连接等。所有这些操作都会触发 Spark 执行器之间的大量数据移动。</p><p id="d740" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些转换的核心是 Spark 如何计算要产生的数据，将哪些键和相关数据写入磁盘，以及如何将这些键和数据作为操作的一部分传输到节点，如<code class="du kg kh ki kj b">groupBy()</code>、<code class="du kg kh ki kj b">join()</code>、<code class="du kg kh ki kj b">agg()</code>、<code class="du kg kh ki kj b">sortBy()</code>和<code class="du kg kh ki kj b">reduceByKey()</code>。这个动作通常被称为<em class="kk">洗牌。</em></p><p id="ad72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark 有五种不同的连接策略，通过这五种策略，它可以跨执行器交换<em class="kk">、</em>移动、排序、分组和合并数据:广播散列连接(BHJ)、混洗散列连接(SHJ)、混洗排序合并连接(SMJ)、广播嵌套循环连接(BNLJ)和混洗复制嵌套循环连接(又称为笛卡儿积连接)。</p><p id="b5a7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将在另一篇文章中讨论连接，因为连接中涉及的内容很多。</p><p id="d7c1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本文中，我们讨论了许多用于调优 Spark 应用程序的优化技术。正如您所看到的，通过调整一些默认的 Spark 配置，您可以提高大型工作负载的可伸缩性，增强并行性，并最小化 Spark 执行器之间的内存不足。您还了解了如何使用适当级别的缓存和持久化策略来加快对常用数据集的访问。</p><p id="d6d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果我们能够通过避免跨节点移动数据来减少洗牌阶段，这将是一个很好的做法。如果可能，请使用“按关键字减少”而不是“按分组”。在联接中，如果您的表足够小，可以容纳在内存中，请始终使用广播联接。您还可以使用 select api 而不是 withColumn api 向数据框架添加新列，这将提高您的性能。</p><p id="2f2b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我将在这里结束这篇文章，并将在下一篇文章中详细讨论连接。在那之前继续学习。:)</p></div></div>    
</body>
</html>