<html>
<head>
<title>A Survey of Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络综述</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-survey-of-convolutional-neural-networks-8bdf74a21a31?source=collection_archive---------12-----------------------#2020-05-15">https://medium.com/analytics-vidhya/a-survey-of-convolutional-neural-networks-8bdf74a21a31?source=collection_archive---------12-----------------------#2020-05-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="6407" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">分析、应用和前景</h2></div><h1 id="c356" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated"><strong class="ak">CNN简介</strong></h1><p id="cc10" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">卷积神经网络(CNN)是一种具有一个或多个卷积层的神经网络，主要用于图像处理、分类、分割以及其他自相关数据。CNN已经实现了几年前不可能完成的任务，如人脸识别、自动驾驶汽车、自助超市和智能医疗。卷积本质上是在输入上滑动滤波器。与其一次查看整个图像来寻找某些特征，不如查看图像的较小部分会更有效。</p><h1 id="822d" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">CNN模型的组成部分</h1><ol class=""><li id="233b" class="kl km hi jr b js jt jv jw jy kn kc ko kg kp kk kq kr ks kt bi translated"><em class="ku">卷积:</em>它是特征提取的重要步骤。卷积输出<em class="ku">特征图</em>。</li><li id="5f0c" class="kl km hi jr b js kv jv kw jy kx kc ky kg kz kk kq kr ks kt bi translated">填充:当卷积被应用时，我们丢失了边界中的信息。因此，添加填充以放大零值输入。</li><li id="08c6" class="kl km hi jr b js kv jv kw jy kx kc ky kg kz kk kq kr ks kt bi translated"><em class="ku">步距</em>:步距是在输入矩阵上移动的像素数。步幅越大，密度越低</li><li id="103d" class="kl km hi jr b js kv jv kw jy kx kc ky kg kz kk kq kr ks kt bi translated">池化:添加它是为了减少冗余。它也被称为下树苗。最大池化和平均池化是几种池化技术。</li></ol><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es la"><img src="../Images/62f0d69a90e55880eab81609c7a26b9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t50jiz9YqCFFap3UD9cHYQ.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">二维CNN的程序</figcaption></figure><h1 id="108c" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">CNN模型的分类</h1><ul class=""><li id="9ca6" class="kl km hi jr b js jt jv jw jy kn kc ko kg kp kk lq kr ks kt bi translated"><strong class="jr hj"> LeNet-5 </strong></li></ul><p id="dcfa" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">LeNet-5由七个可训练层组成，包括两个卷积层、两个汇集层和三个全连接层。它结合了局部感受野、共享权重和空间或时间子采样，可以确保移位、缩放和失真不变性。这对识别手写字符很有用。然而，它没有超过支持向量机(SVM)和boosting算法。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lw"><img src="../Images/c9801b58ace8ffd839e5b33442b45ade.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M3weF5q_GB0PqrOrR4k1wg.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">Lenet-5的架构</figcaption></figure></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><ul class=""><li id="a2ba" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated"><strong class="jr hj"> AlexNet </strong></li></ul><p id="b539" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">AlexNet有八层，包含五个卷积层和三个全连接层。它使用ReLU作为激活函数，这有助于解决消失梯度的问题。为了避免过度拟合，在最后几个完全连接的层中使用了dropout。Dropout忽略了模型中的少数神经元。重叠最大池用于避免模糊结果并提高特征的丰富性。LRN是增强模型泛化能力的一种方法。它使用两个强大的GPU来训练组卷积。AlexNet在训练中采用了两种数据增强方法。首先是获得水平反射以获得更多的训练数据。此外，主成分分析(PCA)用于改变训练集的RGB值。在进行预测时，AlexNet会对数据集进行扩展，然后对他们的预测进行平均，作为最终结果。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lw"><img src="../Images/13d4c989605e15f953ea6aecfa03416e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5s7aMjtrHEmZu7lFYMmGog.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">AlexNet的体系结构</figcaption></figure></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><ul class=""><li id="0d45" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated"><strong class="jr hj"> VGGNets </strong></li></ul><p id="a4f7" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">VGGNets是由牛津大学视觉几何小组(VGG)提出的一系列卷积神经网络算法。由于局部响应标准化(LRN)层的效果不明显，因此将其移除。VGGNets使用3 × 3卷积核，而不是5 × 5或5 × 5卷积核。</p></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><ul class=""><li id="0e42" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">谷歌网</li></ul><p id="4ef2" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">它是第一个由Inception模块堆叠而成的大型CNN。它有四个版本，即。初始版本v1、v2、v3和v4。</p><ul class=""><li id="3445" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">盗梦空间v1</li></ul><p id="f55e" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">Inception v1设置了1 × 1、3× 3、5 × 5卷积核来构建一个<em class="ku">宽的</em>网络。不同大小的卷积核提取不同尺度的图像特征图。这些特征地图然后被堆叠以获得更具代表性的特征地图。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es mh"><img src="../Images/e8550be6cbdb30ac497303711e2399af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*BLmgaR9K27ZiNOPAZOB8jg.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">初始版本1模块</figcaption></figure><ul class=""><li id="9810" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">盗梦空间v2</li></ul><p id="b608" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">Inception v2利用批量标准化来解决内部协变量偏移问题。正态分布应用于每一层的输出。这增加了模型的鲁棒性，并以相对较大的学习率训练模型。Inception v2表明，单个5 × 5卷积层可以由两个3 × 3卷积层代替。一个n×n卷积层可以由一个1×n和一个n×1卷积层代替。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mi"><img src="../Images/dd80201bdbcedf362500c551026bca9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5cjp2tjFuXBdqcByjDDaAg.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">Inception v2模块</figcaption></figure><ul class=""><li id="42e3" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">盗梦空间v3</li></ul><p id="35d6" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">将5 × 5和3 × 3卷积核分解为两个一维核。这种操作加速了训练，并进一步增加了网络的深度和网络的非线性。它使用RMSProp作为优化器。</p><ul class=""><li id="fa97" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">初始版本4</li></ul><p id="10bd" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">这个模型是建立在Inception v3之上的。这种架构模块更多，更紧凑。这个模型比它的所有前辈都好。</p></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><ul class=""><li id="8c14" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated"><strong class="jr hj">雷斯内特</strong></li></ul><p id="13be" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">深度神经网络存在梯度消失或爆炸的问题。为了解决这个问题，ResNet有两层由快捷连接构成的剩余块。ResNet可以减轻梯度消失问题，而不会在深度神经网络中退化，因为梯度可以直接流经快捷连接。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es mj"><img src="../Images/625f2f3076da7e5005738d5f2b75e1a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*TSHwMMsD10PIUYxqv8eGeg.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">ResNet块的结构</figcaption></figure></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><ul class=""><li id="dcbe" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated"><strong class="jr hj"> DCGAN </strong></li></ul><p id="f2dd" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">GAN包含生成模型G和判别模型D。G和D都可以是非线性函数。G的目的是生成尽可能真实的数据，而D的目的是将G生成的假数据与真实数据区分开。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mk"><img src="../Images/d48b4eef593230d3a87f6a5fa69ce9c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ATmVM4xNJ6X1zz3_j8hlFQ.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">GAN流程图</figcaption></figure></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><ul class=""><li id="42f1" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated"><strong class="jr hj">移动网络</strong></li></ul><p id="7ebe" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">他们使用深度方向的可分离卷积和几种先进的技术来构建薄的深度神经网络。这些是重量轻的型号，主要用于移动电话。</p><ul class=""><li id="e6b8" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">MobileNet v1</li></ul><p id="b9ab" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">MobileNet v1利用深度方向可分离卷积，将标准卷积分解为深度方向卷积和点方向卷积(1 × 1卷积)。这种分解可以大大减少参数的数量。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es ml"><img src="../Images/034ba8eb82cd6a21fe89c04deae586e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-qAuzvsYlvJRaEJtmuX7qQ.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">MobileNet中的深度可分卷积</figcaption></figure><ul class=""><li id="504a" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">MobileNet v2</li></ul><p id="6744" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">它引入了两个改进:反向剩余块和线性瓶颈模块。首先通过1 × 1卷积核对反转残差块的输入进行卷积以进行信道扩展，然后通过3 × 3深度方向可分离卷积进行卷积，最后通过1 × 1卷积核进行卷积以压缩回信道数量。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es mm"><img src="../Images/76eecad5f916b75bd32b9f537706bd81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*2zDnydja1eRcxfeJmGzynQ.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">(a)残差块(b) MobileNet v2块:反向残差块</figcaption></figure><ul class=""><li id="e780" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">MobileNet v3</li></ul><p id="256d" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">MobileNet v3利用挤压和激励(se)来重新加权每一层的通道，以实现轻量级注意力模型。在反向残差块的深度方向卷积之后，添加se模块。首先执行全局池操作，然后在全连接层之后，通道的数量减少到1/4。第二个全连接层用于恢复通道的数量并获得每层的权重。最后，将权重和深度方向卷积相乘以获得重新加权的特征图。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mn"><img src="../Images/fc76cfba1b4a7caf6624f5b5bc6c3b95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KjZAHq18ksPDSjP2qAZrtw.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">MobileNet v3块</figcaption></figure></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><ul class=""><li id="ef53" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated"><strong class="jr hj">沙狐球</strong></li></ul><p id="6b71" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">这些模型结合了逐点群卷积、通道混洗和其他一些技术，在不损失精度的情况下显著降低了计算成本。</p><ul class=""><li id="85b6" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">ShuffleNet v1</li></ul><p id="9e10" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">逐点组卷积要求每个卷积运算只在相应的输入通道组上进行，这样可以降低计算复杂度。提出信道洗牌操作，帮助不同组的信息随机流向其他组。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mo"><img src="../Images/ac866641fe77a2ca4244f2bc538d5d34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aqEmHuo6YHCXDlQCTMk8Sw.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">ShuffleNet v1中的逐点群卷积和频道混洗</figcaption></figure><ul class=""><li id="b7ed" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">ShuffleNet v2</li></ul><p id="16f4" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">发现当输入通道数等于输出通道数时，MAC最小。改变卷积的组数对网络训练速度有影响。通过调整网络的分段结构和每个基本结构中的卷积层数，发现网络分段降低了并行度。在设计网络时，研究人员应该尽可能减少元素运算的使用。ShuffleNet v2就是根据这些原则设计的。</p></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><ul class=""><li id="c4a0" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated"><strong class="jr hj">幽灵网</strong></li></ul><p id="cdeb" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">由于现有的细胞神经网络提取大量冗余特征用于图像认知，GhostNet被用来有效降低计算成本。在传统的被称为重影的卷积层中有许多相似的特征图。他们将传统的卷积层分为两部分。在第一部分中，较少的卷积核直接用于特征提取，这与原始卷积相同。然后，对这些特征进行线性变换，得到多个特征图。他们证明了Ghost模块适用于其他CNN模型。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mp"><img src="../Images/c678e7daa70727ce876118dd5ce24485.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MnJgEqptsPojlYjZ1Knrpg.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">幽灵模块</figcaption></figure></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><h1 id="54f1" class="ix iy hi bd iz ja mq jc jd je mr jg jh io ms ip jj ir mt is jl iu mu iv jn jo bi translated">选择神经网络的经验法则</h1><p id="444b" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">对于二元分类问题，最后一层可以驾驭sigmoid。对于多分类问题，最后一层可以利用Softmax。通常在隐藏层中，ReLU或者漏ReLU都是不错的选择。Leaky ReLU中的负斜率可以设置为0.02，以加快训练速度。</p><ol class=""><li id="3f7f" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk kq kr ks kt bi translated"><em class="ku">损失函数</em></li></ol><p id="c2cf" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">利用损失函数或成本函数来计算预测值和实际值之间的距离。损失函数通常被用作优化问题的学习准则。常见的损失函数包括平均绝对误差(MAE)、均方误差(MSE)、交叉熵等。</p><ul class=""><li id="2ccc" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">回归损失函数</li></ul><p id="1577" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">在处理回归问题时，我们很可能使用MAE或MSE。MAE比MSE对异常值更稳健。如果在训练集中有大量的异常值，优先选择MAE，否则，应该考虑MSE。</p><ul class=""><li id="2f85" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">分类损失函数</li></ul><p id="ff7f" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">交叉熵损失将每个类别中的预测概率与实际输出值(0或1)进行比较，并根据它们之间的距离计算惩罚值。对比损失扩大了不同类别之间的距离，缩小了同一类别内的距离。它可用于卷积神经网络的降维。三重损失基于三个图像。这三个图像是锚图像、正面图像和负面图像。正面图像和锚图像来自同一个人，而负面图像和锚图像来自不同的人。它试图拉近锚和积极者之间的距离，进一步拉近锚和消极者之间的距离。中心损失试图集中在同一类内分布的均匀性上。</p><ul class=""><li id="1070" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated">选择的经验法则</li></ul><p id="28a1" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">使用CNN模型处理回归问题时，可以选择L1损失或L2损失作为损失函数。在处理分类问题时，我们可以选择其余的损失函数。交叉熵损失是最受欢迎的选择，通常出现在CNN模型中，最后有一个softmax层。</p><h1 id="58f1" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">CNN的应用</h1><ul class=""><li id="4d62" class="kl km hi jr b js jt jv jw jy kn kc ko kg kp kk lq kr ks kt bi translated"><strong class="jr hj">一维CNN的应用</strong></li></ul><p id="4f38" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">1D CNN可用于数据的时间序列预测，如心电图时间序列、天气预报和交通流量预测。</p><p id="e406" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">信号识别——可应用于ECG信号识别、结构损伤识别和系统故障识别。</p><ul class=""><li id="dc69" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated"><strong class="jr hj">二维CNN的应用</strong></li></ul><p id="f181" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">图像分类是将图像分类到一个类别的任务。目标检测是基于图像分类的任务。系统不仅需要识别输入图像属于哪个类别，还需要用边界框来标记它。图像分割是将图像分成不同区域的任务。它必须标记图像中不同语义实体的边界。人脸识别是一种基于人脸特征的生物识别技术。</p><ul class=""><li id="a3d7" class="kl km hi jr b js lr jv ls jy me kc mf kg mg kk lq kr ks kt bi translated"><strong class="jr hj">多维CNN的应用</strong></li></ul><p id="d84b" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">人体动作识别是指机器自动识别视频中的人体动作。物体识别/检测。</p><h1 id="d4c7" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">CNN的安全性</h1><p id="46d1" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">对抗性攻击也是深度神经网络面临的威胁之一。首先，对于训练样本，可以利用对立的样本来增强模型的鲁棒性。第二，可以调整网络架构以忽略噪声。最后，额外的网络可以用来帮助主干网络抵御恶意攻击。</p><h1 id="1777" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">结论</h1><p id="4b44" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">由于卷积神经网络具有局部连接、权重共享和降采样降维等优点，因此在研究和工业项目中得到了广泛的应用。本文对CNN进行了详细的介绍，包括常见的构建模块、经典网络、相关功能、应用和前景。</p><p id="a148" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">本文是以下IEEE论文的概述—</p><p id="f69d" class="pw-post-body-paragraph jp jq hi jr b js lr ij ju jv ls im jx jy lt ka kb kc lu ke kf kg lv ki kj kk hb bi translated">https://arxiv.org/abs/2004.02806<a class="ae mv" href="https://arxiv.org/abs/2004.02806" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>