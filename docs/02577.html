<html>
<head>
<title>Unsupervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/unsupervised-learning-de1a106c2524?source=collection_archive---------21-----------------------#2019-12-23">https://medium.com/analytics-vidhya/unsupervised-learning-de1a106c2524?source=collection_archive---------21-----------------------#2019-12-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5805" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使聚集</p><ul class=""><li id="c187" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">是将数据集分成由相似数据点组成的组的过程。同一组中的数据尽可能相似，而不同于其他组</li><li id="7216" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">用于推荐引擎。</li></ul><p id="6d51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类型:</p><ol class=""><li id="3112" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc jr jj jk jl bi translated">排他聚类-每个数据点只能位于一个聚类中。例如:K均值聚类</li><li id="3fbc" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc jr jj jk jl bi translated">重叠聚类——允许将数据对象分组到两个或更多的聚类中。例如:模糊/C均值聚类</li></ol><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es js"><img src="../Images/80180f740518924e0a011b180cbb0804.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*Vn-pyZvgLahSrddx4NPvHQ.png"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">A-独占，B-重叠</figcaption></figure><p id="fac8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.分层聚类-</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es ke"><img src="../Images/ad9bcf42e7f1d03b571fa036dc3787b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*LtIrktZ6EIU6mIVgIS7eTg.png"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">根据层次聚类进行分组</figcaption></figure><h2 id="d053" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">k均值聚类</h2><ul class=""><li id="770c" class="jd je hi ih b ii la im lb iq lc iu ld iy le jc ji jj jk jl bi translated">将相似的元素组合成一个簇</li><li id="5cc6" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">应用—行为分割、检测机器人。</li></ul><p id="d98e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤1:选择要识别的聚类数。假设K=3</p><p id="d626" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤2:随机选择3个不同数据点</p><p id="e03a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤3:测量第一个点和所选的3个簇之间的距离</p><p id="25ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤4:将第一个点分配给最近的簇</p><p id="bee5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤5:计算平均值，包括第一组的新点</p><p id="a4e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤6:对剩余的集群重复步骤3–5</p><p id="b8a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于步骤2的变化，这些迭代由模型进行多次，直到我们得到总变化最小</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es lf"><img src="../Images/c5d4a85831e31d699b9a041bc1e28ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*eK8mSll-PRhaDccv8ubPKw.png"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">步骤3，随机选择聚类的点，执行步骤4和5，计算方差并继续迭代</figcaption></figure><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es lg"><img src="../Images/ae7ac90f29ef22d0ee7e9cac7fc2e8e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*lW2yGtbOOuTKQPOA3E6L2Q.png"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">因为我们在所选聚类点的迭代中具有更好的方差。迭代可以停止</figcaption></figure><p id="9eda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我之前的帖子中给出的使用scipy模块的Kmeans集群:</p><div class="lh li ez fb lj lk"><a rel="noopener follow" target="_blank" href="/@azamsayeed123/module-3-numpy-8d5840c2773e"><div class="ll ab dw"><div class="lm ab ln cl cj lo"><h2 class="bd hj fi z dy lp ea eb lq ed ef hh bi translated">模块3 — Numpy</h2><div class="lr l"><h3 class="bd b fi z dy lp ea eb lq ed ef dx translated">Numpy数组简介</h3></div><div class="ls l"><p class="bd b fp z dy lp ea eb lq ed ef dx translated">medium.com</p></div></div><div class="lt l"><div class="lu l lv lw lx lt ly jy lk"/></div></div></a></div><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es lz"><img src="../Images/12432ca96be2e50a1426a83cb2902e22.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*a2i3HdxUDpVFFFC5qgFofQ.png"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">为了找到最佳K值，我们使用肘图变异对K数</figcaption></figure><h2 id="0cdc" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">关联规则挖掘</h2><ul class=""><li id="d631" class="jd je hi ih b ii la im lb iq lc iu ld iy le jc ji jj jk jl bi translated">是一种基于规则的机器学习方法，用于发现实体之间的有趣关系</li></ul><p id="811e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">前提(如果)，结果(然后)—模式，如如果购买了牛奶，那么购买者可能会购买面包</p><p id="b479" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应用市场篮子分析</p><ul class=""><li id="e9d1" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">用于标识客户购买的商品之间的关联</li></ul><p id="482d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">衡量关联性的方法</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es ma"><img src="../Images/8d44ce369ee73817cd29f903eeb82d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/0*76ES7FPh4KZAq1cu.png"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">x:前提，y:结果，x=&gt;y，x =[项目列表]</figcaption></figure><ol class=""><li id="e942" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc jr jj jk jl bi translated">Support —包含x，y的事务数，基于事务总数</li><li id="6878" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc jr jj jk jl bi translated">置信度——具有x，y的事务数除以x的事务数</li><li id="48c4" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc jr jj jk jl bi translated">提升—检查公式</li></ol><p id="b3e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">lift (x=&gt;y) &gt;1，如果x被买入，y可能被买入</p><p id="d908" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">lift(x=&gt;y) &lt;1，y如果买了x不太可能买</p><h2 id="dff7" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">Kmeans和关联规则演示:</h2><div class="lh li ez fb lj lk"><a href="https://nbviewer.jupyter.org/gist/MohdAzamSayeed/593dc86760083d3a926378c615c4dccc" rel="noopener  ugc nofollow" target="_blank"><div class="ll ab dw"><div class="lm ab ln cl cj lo"><h2 class="bd hj fi z dy lp ea eb lq ed ef hh bi translated">nbviewer笔记本</h2><div class="lr l"><h3 class="bd b fi z dy lp ea eb lq ed ef dx translated">看看这个Jupyter笔记本！</h3></div><div class="ls l"><p class="bd b fp z dy lp ea eb lq ed ef dx translated">nbviewer.jupyter.org</p></div></div><div class="lt l"><div class="mb l lv lw lx lt ly jy lk"/></div></div></a></div><h2 id="9172" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">推荐引擎</h2><ul class=""><li id="ac2e" class="jd je hi ih b ii la im lb iq lc iu ld iy le jc ji jj jk jl bi translated">预测和显示用户感兴趣的项目的过滤系统。用在数字领域像亚马逊，Flipkart。可以显著提高收入、点击率、用户体验、转化率和其他imp指标</li><li id="f6a4" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">类似于销售人员，接受过向上销售和交叉销售培训。根据兴趣显示各种产品(基于浏览历史数据)</li><li id="2a4c" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">冷统计问题</li></ul><figure class="jt ju jv jw fd jx er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mc"><img src="../Images/81f5068ec0adac6b15cdf493c68f0178.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q2WmuDMOH8a8dNKvy-JRDA.png"/></div></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">推荐引擎示例</figcaption></figure><p id="ba26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类型:</p><ol class=""><li id="388b" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc jr jj jk jl bi translated">协同过滤:收集和分析大量用户数据，如行为、喜欢、活动等，并根据其他类似用户的兴趣预测用户会喜欢什么产品。[相似的客户被归入同一群]</li></ol><p id="5380" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1a。基于用户的协同过滤</p><ul class=""><li id="48c8" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">如果两个用户在过去有相似的口味，那么他们在将来很可能有相似的喜好。</li></ul><p id="8972" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，如果用户A已经像用户B一样购买了polo衫，并且用户A还额外购买了polo夹克，则可以基于过去的行为向用户B推荐polo夹克。</p><p id="f71f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">相似性度量</p><ul class=""><li id="c883" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">余弦相似性</li></ul><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es mh"><img src="../Images/7f5ce3d5c60ec1098d660c08c3f7280a.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/0*0aDg6oq6KlCHU7aU.png"/></div></figure><p id="5d40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1b。基于项目的协同过滤——根据项目偏好计算项目相似度，并为用户找到最相似的项目。</p><p id="c1da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.基于内容的过滤:基于产品特征，关键词指产品</p><p id="d8bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.混合推荐系统:1+2类型组合例如:网飞[基于项目的聚类]</p><h2 id="9247" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">降维</h2><ul class=""><li id="64b1" class="jd je hi ih b ii la im lb iq lc iu ld iy le jc ji jj jk jl bi translated">减少大量维数的过程。</li></ul><p id="6f25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">降维的类型</p><ol class=""><li id="7270" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc jr jj jk jl bi translated">特征消除:当某些维度对其他变量来说是多余的或者对信息没有贡献时，将其完全删除</li></ol><p id="0c7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">adv:将庞大的数据集缩减为较小的块</p><p id="44da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">缺点:我们可能会丢失一些有价值的数据</p><p id="af60" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.特征提取:从旧变量中提取新变量</p><p id="e57a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">主成分分析致力于特征提取</p><p id="c847" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应用:图像处理</p><h2 id="ea9f" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">主成分分析</h2><ul class=""><li id="98db" class="jd je hi ih b ii la im lb iq lc iu ld iy le jc ji jj jk jl bi translated">通过识别低维轴集，减少给定数据集的随机变量数量</li></ul><p id="eddc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如:将车辆分类为轿车和公共汽车；公共汽车和小汽车的标准车轮数为6，绝对为4，因此差异较小，而车辆的高度可以独立变化。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es mi"><img src="../Images/33cb855c30fe23ada0a91eb4851e799a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*uN-fiVnpKnwo1WLIEYslrQ.png"/></div></figure><figure class="jt ju jv jw fd jx er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mj"><img src="../Images/c5346214062baa7bce1bdfe20befbc5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*ltucCqWG1724V9jf82XhuA.png"/></div></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">与线B相比，a具有较低的变量，这是因为来自线B的数据传播较低。所以B可以是主分量的方向。特征向量和特征值如上所述</figcaption></figure><p id="fca6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">具有最高特征值的特征向量是主成分线(数据从特征向量最分散)</p><p id="5b4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:特征向量是相互正交的</p><p id="7fcd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">示例:</p><p id="995a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们有3个变量:手机使用时间、互联网使用时间和年龄</p><p id="e20b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在xy平面上的基准点上画出3个相互正交的特征向量。由于数据点不在z平面上，我们可以认为ev3为零，将其移除(主成分分析的概念)</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es mk"><img src="../Images/6db679c2274bee2140d2b0e69f314a11.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*5NoWgw1bA28xCBvrIRsE-A.png"/></div></figure><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es ml"><img src="../Images/6b0d4dad8f4357f1faf72059fed86c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*_2ebvRepAwbqGjl_xfDU7g.png"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated">使用主成分分析将3D简化为2D</figcaption></figure><p id="76da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVM演示，运行jupyter笔记本中的以下代码</p><pre class="jt ju jv jw fd mm mn mo mp aw mq bi"><span id="ddc5" class="kf kg hi mn b fi mr ms l mt mu">from sklearn import datasets<br/>cancer =datasets.load_breast_cancer()<br/>print("Features: ",cancer.feature_names)<br/>print("Labels:",cancer.target_names)<br/>print(cancer.data[0:5])<br/>print(cancer.target)</span><span id="1e1b" class="kf kg hi mn b fi mv ms l mt mu">from sklearn.model_selection import train_test_split</span><span id="e46b" class="kf kg hi mn b fi mv ms l mt mu">X_train,X_test,Y_train,Y_test =train_test_split(cancer.data,cancer.target,test_size=0.3,random_state=109)<br/>from sklearn import svm</span><span id="139d" class="kf kg hi mn b fi mv ms l mt mu">clf=svm.SVC(kernel='linear')<br/>clf.fit(X_train,Y_train)</span><span id="3179" class="kf kg hi mn b fi mv ms l mt mu">y_pred =clf.predict(X_test)</span><span id="287e" class="kf kg hi mn b fi mv ms l mt mu">from sklearn import metrics</span><span id="1ff2" class="kf kg hi mn b fi mv ms l mt mu">metrics.confusion_matrix(Y_test,y_pred)<br/>metrics.accuracy_score(Y_test,y_pred)</span></pre></div></div>    
</body>
</html>