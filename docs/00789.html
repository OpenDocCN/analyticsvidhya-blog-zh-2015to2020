<html>
<head>
<title>Evaluation Metrics in Machine Learning Models using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python评估机器学习模型中的度量</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/evaluation-metrics-in-machine-learning-models-using-python-fb6199450fba?source=collection_archive---------4-----------------------#2019-09-06">https://medium.com/analytics-vidhya/evaluation-metrics-in-machine-learning-models-using-python-fb6199450fba?source=collection_archive---------4-----------------------#2019-09-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/c06f836392cb2f226b0c7ef82e67b23b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQfXn20hpbJqD-ziZ0_exg.png"/></div></div></figure><div class=""/><p id="f606" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将尝试在不同的误差指标上评估我们的机器学习模型。在评估模型时，我们需要记住，如果我们的数据集是不平衡数据集的经典例子，那么它应该不受类别不平衡的影响。我们将在接下来的博客中处理典型的不平衡数据集示例。下面列出了一些流行的评估指标。</p><p id="9c09" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">对于分类问题:<br/> </strong> 1。混乱矩阵<br/> 2。精度/召回<br/> 3。F1比分<br/> 4。ROC曲线下面积(AUC — ROC) <br/> 5。科恩的卡帕</p><p id="d770" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">对于回归问题:<br/> </strong> 1。均方根误差(RMSE) <br/> 2。R平方/调整的R平方</p><p id="258a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们试着按顺序理解它们。</p><h1 id="2bb0" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">混淆矩阵:</h1><p id="0611" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">这个矩阵代表了模型的准确性。混淆矩阵是一个N×N矩阵，其中N是被预测的类的数量。让我们以信用卡公司的两类问题为例，该公司希望使用您必须构建的算法来检测欺诈。可能的两个类别将是其<strong class="is hu">欺诈</strong>或<strong class="is hu">非欺诈</strong>交易<strong class="is hu">。</strong></p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kr"><img src="../Images/cea4d7007d2aea4c33e928b3895bb52f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pFtcroGSKUSTwnUF8vpx7g.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图:混淆矩阵</strong></figcaption></figure><p id="78a2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，<br/> <strong class="is hu">真阳性(TP) </strong> = 1即实际<strong class="is hu">欺诈</strong>同时也预测<strong class="is hu">欺诈<br/>假阳性(FP) </strong> = 1即实际<strong class="is hu">不欺诈</strong>但预测<strong class="is hu">欺诈</strong> <br/> <strong class="is hu">假阴性(FN) </strong> = 2即实际<strong class="is hu">欺诈</strong>但预测<strong class="is hu">不欺诈【T38</strong></p><p id="8b5e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">模型的准确率由<br/> <strong class="is hu">给出准确率=(TP+TN)/(TP+TN+FP+FN)<br/></strong>在上面的矩阵中，我们已经计算了所有评估案例中真阳性和真阴性的比例。</p><h1 id="32e5" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">精确度/召回率:</h1><p id="a4b3" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated"><strong class="is hu">精度</strong>:正确预测与该类预测总数的比率。它回答了所有被预测为属于“欺诈”类的值，正确的百分比是多少？<strong class="is hu"> <br/> <em class="la">精度</em>(<em class="la">P</em>)=<em class="la">TP/(TP+FP</em>)<br/></strong>在我们上面的矩阵例子中，精度是=(1)/(1 + 1)=1/2=0.5</p><p id="5b4d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">回忆:</strong>它是正确预测的数量与类的实际实例总数的比率。它回答了类“X”的所有实例的问题，我们正确预测的百分比是多少？<br/> <strong class="is hu"> <em class="la">召回</em>(<em class="la">R</em>)=<em class="la">TP/(TP+FN)</em><br/></strong>我们上面矩阵例子中的召回是=(1)/(1+2) = 1/3 =0.34</p><p id="ebf7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假设在信用欺诈数据集上实现了两个模型:模型1和模型2，其中0表示不欺诈，1表示欺诈。以下是观察结果:</p><p id="cf6d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">模型1能够比模型2更好地正确预测<code class="du lb lc ld le b">0</code>【非欺诈】。因此，模型1具有更少的假阳性，从而具有更高的精度</p><p id="9b01" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">模型2能够比模型1更好地正确预测<code class="du lb lc ld le b">1</code>【欺诈】。因此，模型2具有较少的假阴性，从而具有较高的召回率。</p><p id="4453" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这被称为<strong class="is hu">精确-召回权衡。</strong>选择精确还是召回完全取决于业务需求，反之亦然。在这种情况下，我们应该更加关注召回。由于欺诈如果未被发现，将会给企业带来损失，因此通过进行额外的监控或手动验证，可以将预测非欺诈对欺诈的影响降至最低。</p><p id="304f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">精确度指标更重要的一个例子是推荐系统(youtube播放列表推荐、TED X推荐)、股票预测、房价等。<br/>召回指标更重要例子是疾病预测、恐怖分子预测、欺诈案件、贷款拖欠者。</p><h1 id="f3d3" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">F1分数:</h1><p id="c240" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">如果我们希望在一个模型中既有好的精度又有好的回忆，该怎么办呢？<br/>在这种情况下，我们使用F1评分。它只不过是精确和回忆的调和手段。<br/> <strong class="is hu"> F1得分= 2PR / (P+R) <br/> </strong>我们上面矩阵例子中的F1得分<br/> F1得分=(2 * 0.5 * 0.34)/(0.5+0.34)= 0.34/0.84 = 0.40<br/>在你的阶级分布不均匀的时候更有用。</p><h1 id="4d7f" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">ROC曲线下面积(AUC — ROC):</h1><p id="8e04" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">ROC曲线是灵敏度(也称为真阳性率)和(1-特异性)(也称为假阳性率)之间的图。<strong class="is hu"> <br/>真阳性率(TPR) = </strong> TP / (TP+FN) <br/> <strong class="is hu">假阳性率(FPR) = </strong> FP / (FP+FN)</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lf"><img src="../Images/6128381f204b66762e6819f4cd9ad3ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pBWwjymZTeGCeE-R4Cms3g.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图:混淆矩阵</strong></figcaption></figure><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/f01cd3e4c23ef480efea45b96c590051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PG4eSntI__UqaIkkBra7wA.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图:Roc曲线</strong></figcaption></figure><p id="c854" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">曲线下的面积越大，模型越好。随机线表示模型的随机预测，0.5被认为是最坏的情况。所以我们曲线应该在随机模型线之上，这样模型才会好。</p><p id="d2a6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi lh translated"><span class="l li lj lk bm ll lm ln lo lp di"> P </span> <em class="la">对于上述矩阵的分类问题ython实现可以在这里探讨。</em><a class="ae lq" href="https://github.com/ManojSingh0302/machineLearning/blob/master/foundations_Course/Ensemble/Excercise_2/Ensembling_Code%20ALong.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="la">Github _ link _ for _ class ification _ matrix</em></a></p><h1 id="e3fb" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">科恩的卡帕:</h1><p id="cc87" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">这是一种将观察到的准确性与预期的准确性(随机机会)进行比较的度量。让我们试着借助矩阵来理解。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es lr"><img src="../Images/617d96ae72d0a20315edb80d0476d09b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*2STHDSwfVZITLQwqAMCTIA.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">图:科恩的卡帕矩阵</figcaption></figure><pre class="ks kt ku kv fd ls le lt lu aw lv bi"><span id="a64e" class="lw jp ht le b fi lx ly l lz ma">kappa is defined as</span><span id="fc96" class="lw jp ht le b fi mb ly l lz ma"><strong class="le hu">K = (Po - Pe) /(1- Pe)</strong></span><span id="a035" class="lw jp ht le b fi mb ly l lz ma">Where,<strong class="le hu"> <br/>Po = Observed Accuracy<br/>Pe = Expected Accuracy</strong></span><span id="8bf7" class="lw jp ht le b fi mb ly l lz ma">Po simply is number of instances that were classified correctly. From above matrix we can ‘a’ and ‘d’ were classified correctly.</span><span id="8d2d" class="lw jp ht le b fi mb ly l lz ma">Po = (a+d) / (a+b+c+d)</span><span id="0c65" class="lw jp ht le b fi mb ly l lz ma">Pe  = Probability by random chance<br/>    =  P (yes) or P (no) <br/>    = (Classifier classifies it as yes) * (Actual yes) + <br/>      (Classifier classifies it as no) * (Actual no)<br/>   <br/> Pe = [(a+b)/(a+b+c+d)] * [(a+c)/(a+b+c+d)] + [(c+d)/(a+b+c+d)] *                 [(b+d)/(a+b+c+d)]</span></pre><p id="1a6c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果观察到的精度值比预期的精度好，那么这个模型就是好的。</p><h1 id="18a5" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">均方根误差(RMSE):</h1><p id="abed" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">它用于回归问题。它遵循一个假设，即误差是无偏的，并遵循正态分布。它由下面的公式给出。<br/>其中N是观测值的总数。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es mc"><img src="../Images/d486fabdaacf46d132f0d554bc4d3b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*h8yW2xMFfZwq8_uq8F52Kw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">图:RMSE</figcaption></figure><p id="32f3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注1)对于更多样本，使用RMSE重建误差分布被认为更可靠。<br/> 2)受离群值影响较大。与平均绝对误差相比，RMSE给出了更高的权重，并惩罚大的误差。</p><h1 id="944a" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">R平方/调整后的R平方:</h1><p id="4cdd" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在AUC-ROC中，我们了解到我们的模型应该比随机机会的准确性更好，因此这里我们有一个基准来比较我们在分类问题中的模型，但是在回归模型的情况下，当RMSE降低时，模型性能提高，但是我们仍然没有基准来比较它。这就是我们需要<strong class="is hu"> R平方/调整R平方的原因。</strong>测量回归模型中直线的拟合优度。<br/> R平方始终介于0和100%之间。<br/>让我们再了解一些术语，以便更好地理解R平方。</p><p id="0225" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">误差平方和(SSE): </strong>无非就是残差平方和。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es md"><img src="../Images/072cf3bc67a703fa7788a65d93259933.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*LUW-mIpvfHB6iCEezrkfOA.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图:SSE </strong></figcaption></figure><p id="db93" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> <em class="la">易</em> : </strong>实际值<br/> <strong class="is hu"> y^i: </strong>预测值</p><p id="2c04" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">总平方和(SST): </strong>无非是实际值(<strong class="is hu"><em class="la"/></strong>)和我们数据集的均值(<strong class="is hu"><em class="la">y</em>ˇ<em class="la">I</em></strong>)的平方差。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es me"><img src="../Images/bcfda9e47eb75fb61bb722fb12af0617.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*Uw_c6I1AHjOS4IMh7f58sQ.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图:SST </strong></figcaption></figure><p id="961d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">回归平方和</strong> ( <strong class="is hu"> SS(回归)</strong>):是预测值(<em class="la"> y </em> ^ <em class="la"> i </em>)与均值(<em class="la">y</em>ˇ<em class="la">I</em>)的平方差。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es mf"><img src="../Images/4b52bf7e856201778bdce348e08afd7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*DusIqdcb1shZ1eSDBwtXpA.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图:SS(回归)</strong></figcaption></figure><p id="a9f0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以观察如下，<br/> <strong class="is hu"> <em class="la"> SS </em> ( <em class="la">总计</em> )= <em class="la"> SS </em> ( <em class="la">回归</em> ) + <em class="la"> SSE </em> </strong></p><p id="c9b8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> R平方</strong>现在定义为:</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es mg"><img src="../Images/d3fbd88c36ae5889f4c4ad0cd091ea7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*hfl1MFUV7bpCNx31t-Tfog.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图:R平方公式</strong></figcaption></figure><p id="1e7c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">R平方值越高，模型越好。具有所有正确预测的最佳模型会给出R平方为1。R平方的问题是，可以通过添加更多数量的独立变量(特征)来人为地提高它，尽管它们可能是不相关的。但是，在向模型中添加新要素时，R平方值要么增加，要么保持不变。R-Squared不会因添加对模型没有任何价值的要素而受到惩罚。因此，R平方的改进版本是<strong class="is hu">调整的R平方</strong>。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mh"><img src="../Images/fe563cc5bfcf66cf0bdeda17f97eebef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I1STaLQlDiGz_1VjKhWu1w.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd jq">图:调整后的R平方公式</strong></figcaption></figure><p id="6899" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其中，<br/> n =数据点的数量<br/> p =特征/独立变量的数量<br/> <strong class="is hu">注:R平方告诉您模型与数据点的拟合程度，而调整后的R平方告诉您特定特征对模型的重要性。</strong></p><p id="c187" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi lh translated"><span class="l li lj lk bm ll lm ln lo lp di"> P </span> <em class="la"> ython对上述矩阵进行线性回归的实现可以在这里探讨。</em><a class="ae lq" href="https://github.com/ManojSingh0302/machineLearning/blob/master/foundations_Course/linearRegression/Excercise_2/RentBike-Code-Along.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="la">github _ link _ for _ regression</em></a></p><p id="3e83" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，无论何时您构建一个模型，本文都应该帮助您弄清楚这些参数是如何评估误差度量的，以及您的模型表现得有多好。</p><p id="f93c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我希望这个博客对你有用。如果您认为我遗漏了任何重要的细节，或者您对此主题有任何其他问题或反馈，请留下评论或给我发电子邮件。</p></div></div>    
</body>
</html>