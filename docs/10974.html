<html>
<head>
<title>Recommendation system using Collaborative Filtering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用协同过滤的推荐系统</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/recommendation-system-using-collaborative-filtering-eab10541529?source=collection_archive---------7-----------------------#2020-11-11">https://medium.com/analytics-vidhya/recommendation-system-using-collaborative-filtering-eab10541529?source=collection_archive---------7-----------------------#2020-11-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/bf4662f6b035a1098ddac78d9e7a980d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4o6MgHcp7Ot16tEE0Yn3Zw.png"/></div></div></figure><p id="a488" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每当我们从亚马逊或 Flipkart 等电子商务网站购买东西时，我们都会看到类似“购买 X 商品的人也购买了 Y 商品”的建议。我一直很好奇这些网站是如何为用户找到相关产品的，又是如何为如此庞大的用户群维持如此惊人的推荐系统的？</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jo"><img src="../Images/a44618bfef644778360513ddcea5e6da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wocRc3QdUCAcYx1abbSKLQ.png"/></div></div></figure><p id="0caf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">世界领先的互联网电视网络和世界上最有价值的最大流媒体服务公司网飞惊人的数字成功故事，如果不提及其专注于个性化的推荐系统，是不完整的。个性化始于网飞的主页，主页上水平排列着一组视频。每个水平行都有一个与该组中的视频相关的标题。大多数个性化推荐都是基于行的选择方式和项目的排列顺序开始的。网飞大学的推荐系统跨越了各种算法方法，如强化学习、神经网络、因果建模、概率图形模型、矩阵分解、集成、土匪。</p><p id="240a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2006 年 10 月，网飞举办了 Netflix 奖公开比赛，评选最佳算法，根据之前的评分预测用户对电影的评分，而不考虑用户或电影的任何其他信息。这个比赛的主要目标是找到一个更准确的电影推荐系统来取代他们当时自己的系统，叫做 Cinematch。<strong class="is hj"/>协同过滤是一种经常被用来创建高度准确和高效的推荐系统的技术，自从网飞奖竞赛以来，它受到了极大的关注。</p><blockquote class="ju jv jw"><p id="97c1" class="iq ir jx is b it iu iv iw ix iy iz ja jy jc jd je jz jg jh ji ka jk jl jm jn hb bi translated">这个故事强调了协同过滤，这是基于这样一个假设，即人们喜欢与他们喜欢的其他事物相似的事物，以及被具有相似品味的其他人喜欢的事物。在这个<a class="ae jt" href="https://github.com/cjb123/Netflix_Movie_Recommendation" rel="noopener ugc nofollow" target="_blank"> github 知识库</a>中，你可以找到为<a class="ae jt" href="https://www.kaggle.com/netflix-inc/netflix-prize-data" rel="noopener ugc nofollow" target="_blank">网飞奖竞赛数据</a>实现的一些想法。</p></blockquote><h2 id="968e" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jb km kn ko jf kp kq kr jj ks kt ku kv bi translated">输入类型:</h2><p id="f7ba" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">推荐系统依赖于不同类型的输入。最方便的是高质量的<strong class="is hj"> <em class="jx">显式反馈</em> </strong>，其中包括用户关于他们对项目的兴趣的显式输入(如黑暗骑士的 5 颗星评级)。然而，明确的反馈并不总是可用的。因此，推荐系统可以从更丰富的<strong class="is hj"> <em class="jx">隐性反馈</em> </strong>中推断用户偏好，隐性反馈通过观察用户的行为间接反映用户的意见，如页面浏览量、点击量、购买记录、浏览历史、是否听音乐曲目、搜索模式，甚至鼠标移动。</p><h2 id="cc4e" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jb km kn ko jf kp kq kr jj ks kt ku kv bi translated">理解数据:</h2><p id="38c3" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">我们有一个 m× n 的评级矩阵，用户 u ∈ [1，m]和项目 i ∈ [1，n]。评级 rᵤᵢ表示用户 u 对项目 I 给出的评级。通常绝大多数评级是未知的。例如，在网飞的数据中，99%的可能分级都丢失了，因为用户通常只对电影的一小部分进行分级。</p><h2 id="6134" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jb km kn ko jf kp kq kr jj ks kt ku kv bi translated">基线估计:</h2><p id="e8ef" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">有一种系统化的趋势，一些用户比其他用户给出更高的评级，而一些项目比其他项目得到更高的评级。我们需要通过考虑这些影响来调整数据，我们将这些影响封装在基线估计中。未知评级 rᵤᵢ的基线估计由 bᵤᵢ表示，并考虑了用户和项目影响:</p><p id="48b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">bᵤᵢ = μ + bᵤ + bᵢ</p><p id="9637" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">参数 bᵤ和 bᵢ分别表示用户 u 和项目 I 相对于平均值的观测偏差。例如，假设我们想要一个名为贝恩的用户对电影<em class="jx">黑暗骑士</em>评级的基线估计。现在，假设所有电影的平均评分μ是 3.8 星。再者，<em class="jx">黑暗骑士</em>比一般的电影好，所以倾向于比平均高出 0.4 星的评分。另一方面，贝恩是一个挑剔的用户，他倾向于比平均水平低 0.2 颗星。因此，贝恩对<em class="jx">黑暗骑士</em>的评分基线估计为:3.8-0.2+0.4 = 4.0 颗星。</p><p id="6082" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了估计 bᵤ和 bᵢ，我们可以解决下面给出的损失函数的最小二乘优化问题:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lb"><img src="../Images/f1abae0f80b1d1e48a3b1a11fb8a64a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/1*bp5r65pJoIE5fVmswryUaw.gif"/></div></figure><p id="00d9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里，加号之前的第一项，努力找到符合给定评级的 bᵤs 和 bᵢs，第二项是调节项，通过惩罚参数的大小来避免过度拟合。</p><h2 id="c923" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jb km kn ko jf kp kq kr jj ks kt ku kv bi translated">邻居模型:</h2><p id="f4d9" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">协作过滤的标准方法被称为最近邻算法。它的原始形式是基于<strong class="is hj">用户-用户</strong>的方法。它根据志同道合的用户给出的评分来估计未知的评分。几乎所有早期的 CF 系统都使用用户-用户方法。后来，<strong class="is hj">项目-项目</strong>方法也变得流行起来，该方法使用同一用户对类似项目的已知评分来估计用户对项目的评分。</p><p id="31b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">更好的可伸缩性和更高的准确性使得逐项方法在许多情况下更受欢迎。此外，项目-项目方法在提供预测背后的某种可解释性或推理方面更成功，因为用户熟悉他们先前偏好的项目，但不知道那些据称志同道合的用户。</p><p id="583e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们在项目-项目方法中的目标是预测 rᵤᵢ帽，即用户 u 对项目 I 给出的未观察到的评级。我们确定由 u 评级的 k 个项目，它们与项目 I 最相似。这 k 个项目的最相似项目是使用<strong class="is hj">相似性度量</strong>找到的，通常基于皮尔逊相关系数ρ ᵢⱼ，它度量用户对项目 I 和 j 相似评级的倾向。rᵤᵢ的预测值被作为以相似性作为权重的相邻项目的评级的加权平均值。，同时通过基线估计 bᵤᵢ.调整用户和项目的影响</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/42804f7202f3526e8ddaddb766671171.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/1*VsjW5SGy069BNUfh9Bw5jg.gif"/></div></figure><p id="1c44" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其中 bᵤᵢ是(用户、电影)评级的基线预测；bᵤᵢ = μ + bᵤ + bᵢ和 Nᵤᵏ (i)是用户(u)评分的电影(I)的 k-相似电影(邻居)集合；sim (i，j)指的是由用户‘u’评价的电影 I 和 j 之间的相似性。此外，rᵤⱼ是用户“u”对项目“j”给出的评级，而 bᵤⱼ是用户“u”对项目“j”的预测基线模型评级。</p><p id="9944" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通常，使用的相似性度量是余弦相似性或皮尔逊相关系数。<br/>但是我们也可以使用一个<strong class="is hj"> <em class="jx">收缩皮尔逊基线相关系数</em> </strong>，它是基于<em class="jx">皮尔逊基线相似度</em>(即我们采用基线预测而不是用户/项目的平均评级)。它由下式给出:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/31e790dd452bc9ffa60009daf211934d.png" data-original-src="https://miro.medium.com/v2/resize:fit:302/1*DG0DIGGdew7Lrcd_jLBjmA.gif"/></div></figure><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es le"><img src="../Images/e827cada57d12e90665f37da5d9e7904.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/1*Ca9jI0kwp7qoNGunMvbAUQ.gif"/></div></figure><p id="6b70" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">变量 nᵢⱼ表示评价 I 和 j 的用户数量</p><p id="770c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">类似地，在用户-用户方法中，我们识别与用户 u 最相似的 k 个用户(邻居)。rᵤᵢ的预测值<br/>被取为用户 u 的 k 个邻居给予项目 I 的评级的加权平均值，同时通过基线估计 bᵤᵢ.对用户和项目影响进行调整其给出如下:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/d987c18d19fc3cdb59e76fe3c6cef89e.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/1*Ey1b49RFZOqD6b9NZTT1jA.gif"/></div></figure><blockquote class="ju jv jw"><p id="a1cd" class="iq ir jx is b it iu iv iw ix iy iz ja jy jc jd je jz jg jh ji ka jk jl jm jn hb bi translated">同样在这个故事中，我们使用了一个与传统邻居模型略有不同的模型，传统邻居模型通常是基于记忆的协作过滤方法。基于记忆的方法<strong class="is hj">是非参数化的</strong>，我们不使用任何优化方法来学习参数。仅使用<strong class="is hj">余弦相似度或皮尔逊相关系数</strong>计算最接近的用户或项目，仅基于算术运算，直接使用它们进行预测。这里讨论的邻域方法是基于形式优化一个全局成本函数。这提高了预测准确性，同时保持了邻域方法的优点，例如预测的可解释性和处理新评级(或新用户)的能力，而无需重新训练模型。</p></blockquote><h2 id="9af4" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jb km kn ko jf kp kq kr jj ks kt ku kv bi translated">潜在因素模型:</h2><p id="5ac2" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">旨在揭示潜在特征以解释观察到的评级的协作过滤的替代方法是潜在因素模型。在这个故事中，我们了解了由奇异值分解(SVD)诱发的潜在因素模型，奇异值分解是一种矩阵分解技术，基于用户项目评级矩阵。</p><p id="56ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">稀疏性和可扩展性是标准 CF 方法的两个最大挑战，因此矩阵分解带来了一种更先进的方法，即将原始稀疏矩阵分解为具有潜在因子/特征和较少稀疏性的低维矩阵。它们将项目和用户转换到相同的潜在因素空间，从而使它们可以直接比较。</p><p id="c5cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">潜在特征表达了用户和电影的更高层次的属性，如电影的类型、动作的数量、对儿童的定位、角色发展的深度或古怪等等。直觉上，用户可以给电影《钢铁侠》、《源代码》和《x 战警》很好的评级。然而，它们并不代表用户的三种不同意见。相反，它表明该用户喜欢科幻电影，并且可能有更多该用户喜欢的科幻电影。科幻类是这种情况下的潜在特征之一。</p><p id="6874" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">典型的 SVD 模型将每个用户 u 与用户因素向量 pᵤ ∈ Rᶠ相关联，将每个项目 I 与项目因素向量 qᵢ ∈ Rᶠ.相关联当矩阵 r 是稠密的，pᵤ和 qᵢ可以很容易地解析分解。然而，一个电影评级矩阵是超级稀疏的。因此，我们不是通过奇异值分解来分解 Rᶠ，而是试图找到 pᵤ和 qᵢ，目的是当 pᵤ和 qᵢ相乘时，得到的输出矩阵 r’是 Rᶠ的最接近的近似值，而不再是稀疏矩阵。因此，r '中的预测由用户因素向量和项目因素向量的内积表示，并通过偏差项 bᵤᵢ:进行调整</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/c70b01c3e2b89087db7e1bd7ec918078.png" data-original-src="https://miro.medium.com/v2/resize:fit:294/1*GQPpFOIR4WE1o0Or4Gox9A.gif"/></div></figure><p id="9ada" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其中 bᵤᵢ = μ + bᵤ + bᵢ，我们解决下面的<em class="jx">优化问题以最小化损失函数</em>来找到最优的 bᵤ、bᵢ、qᵢ、pᵤ:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/1ec968499d38a7baa6616dbc0f3795b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/1*0Tt7wuJbaUNr3OlsAQp-Bg.gif"/></div></figure><p id="2d90" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，奇异值分解模型在提供可解释性方面面临着真正的困难，即当它需要解释它所做的预测时。它通过用户因素的中间层来抽象用户。这个中间层将计算出的预测与过去的用户行为分开，并使解释变得复杂。类似地，在反映新的评级时，它需要重新学习用户因素，并且不能像在邻居模型中那样以几乎没有成本的方式完成。因此，尽管这些模型的精度较高，但在实际应用中，邻域模型仍有望成为一种常见的选择。</p><h2 id="7f98" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jb km kn ko jf kp kq kr jj ks kt ku kv bi translated"><strong class="ak">隐性反馈模型:</strong></h2><p id="7b15" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">显式评级，是用户给一个项目的评级，如国际零售商的 5 颗星。这是来自用户的直接反馈，表明他们有多喜欢一个项目。<strong class="is hj"><em class="jx"/></strong>隐性评分，间接暗示用户偏好，如页面浏览量、点击量、购买历史、浏览历史、搜索模式、是否听音乐曲目，甚至鼠标移动。然而，<em class="jx">网飞奖数据集</em>中没有这样的数据。然而，在提到的数据集中确实存在一种不太明显的隐式数据，可以用来显著提高我们构建的推荐模型的预测准确性。数据集不仅告诉我们评级值，还告诉我们用户对哪些电影进行了评级，而不管他们对这些电影的评级如何。换句话说，用户通过选择表达自己的意见和<br/>投票来含蓄地告诉我们她的偏好。我们可以使用一个集成模型，将<br/>项目-项目模型与一个潜在因素模型结合起来，称为<strong class="is hj"> SVD++。</strong></p><p id="b465" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在该模型中，评级预测 rᵤᵢ由下式给出:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es li"><img src="../Images/28b48d5f7acef3bd889506bcad185ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/1*eiKIPAmbfqqcOA4FjAjcyQ.gif"/></div></figure><p id="36ba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其中，<strong class="is hj"> Iᵤ </strong>是由用户 u 评价的所有项目的集合，<strong class="is hj"> |Iᵤ| </strong>是该集合的长度，<strong class="is hj"> yⱼ </strong>是我们捕获用户 u 的隐式评价的新的项目因子集合。这里，如已经陈述的，隐式评价描述了用户 u 评价项目 j 的事实，而不考虑评价值。</p><p id="54ba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们解决下面关于损失函数的最优化问题，以找到最优的 bᵤ、bᵢ、qᵢ、pᵤ、yⱼ:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/9b509b2cb919e8fa89fecc040cf64526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/1*20wMWRS5SbLeTOz0xc84Kg.gif"/></div></figure><h2 id="2db3" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jb km kn ko jf kp kq kr jj ks kt ku kv bi translated"><strong class="ak">最终想法:</strong></h2><p id="89fd" class="pw-post-body-paragraph iq ir hi is b it kw iv iw ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn hb bi translated">这个故事提供了对各种协同过滤方法的全面理解，这是一种广泛流行的构建高度准确和高效的推荐系统的技术。我们主要关注<strong class="is hj">邻域法</strong>(一种传统的基于记忆的方法，稍加改动使其参数化)和<strong class="is hj">潜在因素法</strong>(一种基于模型的方法，参数化方法)。我们还讨论了如何获取用户非常基本的<strong class="is hj">隐式评级</strong>，并使用它来显著提高推荐模型的预测准确性。</p><p id="65f5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，这两种模型都有一些优点和缺点，因此这两种模型可以互换使用，或者在现实生活中与其他类型的推荐系统一起使用。</p><p id="4c2c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当用户期望系统给出其预测的理由，而不是面对“黑盒”建议时，邻居模型大放异彩。它们自然地为推荐背后的推理提供了直观的解释，这通常会增强用户体验。此外，只要用户向系统提供反馈，项目-项目邻域模型就可以立即提供更新的推荐，而不需要重新训练模型和估计新的参数。但是，它没有很好地处理稀疏性。此外，当用户和项目数量增加时，计算效率也不高。</p><p id="4473" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">潜在因素模型提供了高度的表达能力来描述数据的各个方面。因此，它们往往比邻域模型提供更准确的结果。但是潜在特征所表达的潜在品味是不可解释的。</p><p id="4bfe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">尽管有这些优点和缺点，但是协同过滤面临着冷启动问题，当添加没有交互或者交互很少的新项目时，就会出现这种问题。当一个新的项目出现时，直到它被大量用户评价，该模型才能够做出任何个性化的推荐。类似地，对于没有获得太多数据的尾部项目，模型倾向于给它们较少的权重，并通过推荐更受欢迎的项目来产生<strong class="is hj">受欢迎程度偏差</strong>。因此，建议将是穷人。</p><p id="e993" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">目前就这些了..</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/0996c458ce8d11dedbc22d2dd86d62f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*dk2OY5_ADFx3m8DYKh75sg.gif"/></div></figure><h2 id="8cad" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jb km kn ko jf kp kq kr jj ks kt ku kv bi translated">参考资料:</h2><ol class=""><li id="881c" class="ll lm hi is b it kw ix kx jb ln jf lo jj lp jn lq lr ls lt bi translated"><a class="ae jt" href="https://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf" rel="noopener ugc nofollow" target="_blank">https://courses . is chool . Berkeley . edu/i290-DM/S11/SECURE/a1-Koren . pdf</a></li><li id="9108" class="ll lm hi is b it lu ix lv jb lw jf lx jj ly jn lq lr ls lt bi translated"><a class="ae jt" href="https://towardsdatascience.com/various-implementations-of-collaborative-filtering-100385c6dfe0" rel="noopener" target="_blank">https://towards data science . com/variable-implementations-of-collaborative-filtering-100385 c 6 dfe 0</a></li><li id="72cf" class="ll lm hi is b it lu ix lv jb lw jf lx jj ly jn lq lr ls lt bi translated"><a class="ae jt" href="https://www.kaggle.com/netflix-inc/netflix-prize-data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/netflix-inc/netflix-prize-data</a></li><li id="0ac7" class="ll lm hi is b it lu ix lv jb lw jf lx jj ly jn lq lr ls lt bi translated"><a class="ae jt" href="https://towardsdatascience.com/intro-to-recommender-system-collaborative-filtering-64a238194a26" rel="noopener" target="_blank">https://towards data science . com/intro-to-recommender-system-collaborative-filtering-64a 238194 a26</a></li></ol></div></div>    
</body>
</html>