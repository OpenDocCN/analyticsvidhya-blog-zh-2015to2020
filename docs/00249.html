<html>
<head>
<title>Must-Read Tutorial to Learn Sequence Modeling (deeplearning.ai Course #5)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习序列建模的必读教程(deeplearning.ai课程#5)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/must-read-tutorial-to-learn-sequence-modeling-deeplearning-ai-course-5-55bbc0d8827?source=collection_archive---------0-----------------------#2019-01-21">https://medium.com/analytics-vidhya/must-read-tutorial-to-learn-sequence-modeling-deeplearning-ai-course-5-55bbc0d8827?source=collection_archive---------0-----------------------#2019-01-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d6d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">预测序列中接下来会发生什么的能力令人着迷。这也是我对数据科学感兴趣的原因之一！有趣的是，人类的大脑确实很擅长这个，但机器却不是这样。给定一本书中的神秘情节，人脑将开始创造结果。但是，如何教会机器做类似的事情呢？</p><p id="7b9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">多亏了深度学习——我们今天能做的比几年前多得多。处理序列数据的能力，如音乐歌词、句子翻译、理解评论或构建聊天机器人——所有这一切现在都有可能归功于<strong class="ih hj">序列建模</strong>。</p><p id="ce67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是我们将在本文中学到的东西。由于这是我们deeplearning.ai专业化系列的一部分，我希望读者能够意识到某些概念。如果您还没有浏览之前的文章，或者只是需要快速复习一下，这里有一些链接:</p><ul class=""><li id="1ae4" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><a class="ae jm" href="https://www.analyticsvidhya.com/blog/2018/10/introduction-neural-networks-deep-learning/" rel="noopener ugc nofollow" target="_blank"> <em class="jn">《深度学习和神经网络入门指南》(deeplearning.ai课程#1笔记)</em> </a></li><li id="8fb5" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated"><a class="ae jm" href="https://www.analyticsvidhya.com/blog/2018/11/neural-networks-hyperparameter-tuning-regularization-deeplearning/" rel="noopener ugc nofollow" target="_blank"> <em class="jn">改进神经网络——超参数调整、正则化等(deeplearning.ai课程#2) </em> </a></li><li id="beda" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated"><a class="ae jm" href="https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/" rel="noopener ugc nofollow" target="_blank"> <em class="jn">从头开始学习卷积神经网络的综合教程(deeplearning.ai课程#4) </em> </a></li></ul><p id="96ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这最后一部分，我们将看到序列模型如何应用于不同的现实应用，如情感分类、图像字幕和许多其他场景。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es jt"><img src="../Images/1e1bcfa50db0f4bbe2c8dce47908b8fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/0*Zb7IO8KxNNeSfaZW.jpg"/></div></figure><h1 id="8c3b" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">目录</h1><ol class=""><li id="fcef" class="jd je hi ih b ii kz im la iq lb iu lc iy ld jc le jj jk jl bi translated">课程结构</li><li id="ead9" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc le jj jk jl bi translated">课程5:序列模型<br/> 1。模块1:递归神经网络。模块2:自然语言处理(NLP)和单词嵌入<br/> 2.1单词嵌入介绍<br/> 2.2学习单词嵌入:Word2vec &amp; GloVe <br/> 2.3使用单词嵌入的应用<br/> 3 .模块3:序列模型&amp;注意机制</li></ol><h1 id="b771" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">课程结构</h1><p id="d522" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">到目前为止，我们已经在这个系列中介绍了很多内容。下面是我们所学概念的快速回顾:</p><ul class=""><li id="defc" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">深度学习和神经网络的基础</li><li id="36f0" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">浅层和深层神经网络如何工作</li><li id="1301" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">如何通过超参数调整、正则化和优化来提高深度神经网络的性能</li><li id="94cf" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">卷积神经网络的工作和实现</li></ul><p id="fb97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">是时候把重点转向序列建模了。本课程(官方标签为吴恩达教授的深度学习专业化课程#5)分为三个模块:</p><ol class=""><li id="41ea" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc le jj jk jl bi translated">在模块1中，我们将学习递归神经网络及其工作原理。我们还将在本模块中讲述gru和LSTMs</li><li id="52a2" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc le jj jk jl bi translated">在模块2中，我们的重点是自然语言处理和单词嵌入。我们将看到Word2Vec和GloVe框架如何用于学习单词嵌入</li><li id="ae4a" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc le jj jk jl bi translated">最后，模块3将介绍注意力模型的概念。我们将会看到如何将大而复杂的句子从一种语言翻译成另一种语言</li></ol><p id="545e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准备好了吗？让我们进入模块1！</p><h1 id="0b13" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">课程5:序列模型</h1><h1 id="b043" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">模块1:递归神经网络</h1><p id="a030" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">课程5第一单元的目标是:</p><ul class=""><li id="5ecc" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">了解什么是递归神经网络</li><li id="b7b9" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">学习几种变体，包括LSTMs、GRUs和双向RNNs</li></ul><p id="229f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果这些缩写听起来令人生畏，请不要担心，我们会很快澄清它们。</p><h1 id="87fa" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">但是首先，为什么是序列模型？</h1><p id="d135" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">为了回答这个问题，我将向您展示几个在真实场景中使用序列模型的例子。</p><p id="3125" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jn">语音识别:</em>T3】</strong></p><p id="8af9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如今这是一个很常见的应用程序(每个有智能手机的人都会知道这一点)。这里，输入是一个音频剪辑，模型必须生成文本副本。随着时间的推移，音频被视为一个序列。此外，抄本是一个单词序列。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es li"><img src="../Images/0a0f585385241baeb48b55c0b59bd813.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/0*ZqwTAFGH1TgDR-qZ.png"/></div></figure><p id="c3f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jn">情感分类:</em> </strong></p><p id="12f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">序列模型的另一个流行应用。我们传递一个文本句子作为输入，该模型必须预测句子的情绪(积极，消极，愤怒，兴高采烈等)。).输出也可以是评级或星级的形式。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lj"><img src="../Images/52aa61f02fe8f18fe4e20a78060d3445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/0*aDeYQGkM-033DBJ_.png"/></div></figure><p id="3e11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jn"> DNA序列分析:</em> </strong></p><p id="aa5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">给定一个DNA序列作为输入，我们希望我们的模型预测DNA的哪个部分属于哪个蛋白质。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lk"><img src="../Images/62a62ebfd087dab6589f49d8d9629101.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/0*ZTMGTgUnRf0yyC95.png"/></div></figure><p id="d8f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">T13】机器翻译:T15】</strong></p><p id="b629" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们用一种语言输入一个句子，比如说法语，我们希望我们的模型把它转换成另一种语言，比如说英语。这里，输入和输出都是序列:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ll"><img src="../Images/ba283194ea8de09a049727cd53e4cc41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/0*5gzBtWIJ48jtSgW3.png"/></div></figure><p id="a1ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jn">视频活动识别:</em> </strong></p><p id="5920" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这实际上是序列模型的一个即将到来的(和当前的趋势)应用。该模型预测给定视频中正在进行的活动。这里，输入是一系列帧。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lm"><img src="../Images/3e11a5fadfafca065f1d488914aa9e50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*jEO8UG-_g7L3RYxb.png"/></div></figure><p id="62a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jn">名称实体识别:</em> </strong></p><p id="50c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">绝对是我最喜欢的序列模型用例。如下所示，我们传递一个句子作为输入，并希望我们的模型识别该句子中的人:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/4305aeb6972412c70150120d911e8ab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-rvjFgsZ74oLH36c.png"/></div></div></figure><p id="b2d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，在我们进一步讨论之前，我们需要讨论一些你将在整篇文章中看到的重要符号。</p><h1 id="d4cb" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">我们将在本文中使用的符号</h1><p id="d18e" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">我们用X代表一个句子。为了理解进一步的通知，我们来看一个例句:</p><blockquote class="ls lt lu"><p id="b903" class="if ig jn ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated">哈利和赫敏发明了一个新的咒语。</p></blockquote><p id="646d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，为了表示句子中的每个单词，我们使用x <t>:</t></p><ul class=""><li id="33ca" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">x &lt;1&gt; =哈利</li><li id="40d0" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">x &lt;2&gt; = Hermoine，以此类推</li></ul><p id="1f8e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于上面的句子，输出将是:</p><p id="e705" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">y = 1 0 1 0 0 0 0</p><p id="e988" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，1表示这个词代表一个人的名字(0表示它绝不是)。下面是我们通常使用的一些常用符号:</p><ul class=""><li id="8415" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">Tx =输入句子的长度</li><li id="511e" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">Ty =输出句子的长度</li><li id="d18c" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">x(i)=第I个训练示例</li><li id="f591" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">x(i) <t> =第I个训练示例的第t个训练</t></li><li id="b10b" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">Tx(i)=第I个输入句子的长度</li></ul><p id="5879" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一点上，有理由怀疑——我们如何在一个序列中表示n个单词？嗯，这就是我们学习词汇或字典的地方。这是我们在陈述中使用的单词列表。词汇表可能是这样的:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ly"><img src="../Images/2a82cb39d7139b606e8f85f1d5e613f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:234/format:webp/0*ZzcFmBE6G0sNvGTw.png"/></div></figure><p id="ac70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">词汇表的大小可能因应用程序而异。建立词汇表的一个潜在方法是从训练集中挑选最频繁出现的单词。</p><p id="5cee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，假设我们想要表示单词“harry ”,它在我们的词汇表中位于第4075位。我们一次性编码这个词汇来表示“哈利”:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lz"><img src="../Images/dfa9a472b1071603848158fb7774beca.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/0*KJbrhYCQYlCrYziq.png"/></div></figure><p id="658d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">概括地说，x <t>是一个独热编码向量。我们将在第4075个位置放置1，所有剩余的字将表示为0。</t></p><p id="eb84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果这个单词不在我们的词汇表中，我们创建一个未知的<unk>标签，并将其添加到词汇表中。就这么简单！</unk></p><h1 id="d94b" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">递归神经网络(RNN)模型</h1><p id="53e3" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">当X或Y，或者X和Y都是一些序列时，我们使用递归神经网络来学习从X到Y的映射。但是为什么我们不能用一个标准的神经网络来解决这些序列问题呢？</p><p id="4c13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很高兴你问了！让我用一个例子来解释。假设我们建立下面的神经网络:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ma"><img src="../Images/55514b1806641f31d1884566362330cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/0*xk0yR7Jon18NVgQi.png"/></div></figure><p id="79d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这主要有两个问题:</p><ol class=""><li id="f99d" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc le jj jk jl bi translated">输入和输出没有固定的长度，即一些输入句子可以是10个单词，而其他句子可以是&lt;&gt; 10个单词。最终输出也是如此</li><li id="f441" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc le jj jk jl bi translated">如果我们使用一个标准的神经网络，我们将不能共享在文本的不同位置学习到的特征</li></ol><p id="462d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要一种表示，它将帮助我们解析不同的句子长度，并减少模型中的参数数量。这就是我们使用递归神经网络的地方。这是典型的RNN的样子:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mb"><img src="../Images/be4135118e772b7388a905200a3780da.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/0*weBS94X5fUGYelK-.png"/></div></div></figure><p id="1078" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RNN提取第一个字(x &lt;1&gt;)并将其输入神经网络层，该神经网络层预测输出(y’&lt;1&gt;)。重复该过程，直到产生最后输出y’<ty>的最后时间步骤x <tx>。这是一个输入和输出的字数相同的网络。</tx></ty></p><p id="29d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RNN按从左到右的顺序扫描数据。请注意，RNN用于每个时间步长的参数是共享的。我们将在每个输入和隐藏层(Wax)，每个时间步(魏如萱)和隐藏层和输出(Wya)之间共享参数。</p><p id="fd0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，如果我们对x &lt;3&gt;进行预测，我们也将获得关于x &lt;1&gt;和x &lt;2&gt;的信息。RNN的一个潜在弱点是，它只从前面的时间点获取信息，而不从后面的时间点获取信息。这个问题可以用双向RNNs来解决，我们将在后面讨论。现在，让我们看看RNN模型中的正向传播步骤:</p><p id="2ed7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">&lt;0&gt;是全零向量，我们计算类似于标准神经网络的进一步激活:</p><ul class=""><li id="4d7e" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">一个&lt;0&gt; = 0</li><li id="b45c" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">a &lt;1&gt; = g(魏如萱* a &lt;0&gt; +蜡* x &lt;1&gt; + ba)</li><li id="f0cb" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">y &lt;1&gt; = g'(Wya * a &lt;1&gt; + by)</li></ul><p id="89c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，我们可以计算每个时间步的输出。这些公式的一般形式可以写成:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mc"><img src="../Images/af256f5604187b31b2371f40517681c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/0*WzPRSEn8F6gjhhvq.png"/></div></figure><p id="4234" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以用更简单的方式写出这些方程:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es md"><img src="../Images/726fc11ec120d1cc71dfa761bdc863d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/0*MOrlQVXciVxFxJG_.png"/></div></figure><p id="7bac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们水平堆叠魏如萱和Wya得到Wa。a <t-1>和x <t>垂直堆叠。我们现在只有1个矩阵，而不是2个参数矩阵。简而言之，这就是前向传播对于递归神经网络的工作方式。</t></t-1></p><h1 id="b4da" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">穿越时间的反向传播</h1><p id="7e3f" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">您可能会看到这种情况—反向传播步骤的工作方向与正向传播相反。我们有一个损失函数，我们需要尽量减少，以产生准确的预测。损失函数由下式给出:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es me"><img src="../Images/ff58cc742e7be2054d792535b5f9b9b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QLgmFMSAxV9JAfhO.png"/></div></div></figure><p id="558f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们计算每个时间步的损失，最后对所有这些损失求和，以计算序列的最终损失:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mf"><img src="../Images/77e84057c559140041be574ab3d9d266.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/0*6jPfRB51ZZ5C-9ud.png"/></div></figure><p id="f4ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在前向传播中，我们从左向右移动，即增加时间t的索引。在反向传播中，我们从右向左移动，即在时间上向后移动(因此称为时间反向传播)。</p><p id="554a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我们已经看到了输入和输出序列长度相等的场景。但是如果长度不同呢？让我们在下一节看看这些不同的场景。</p><h1 id="b45a" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">不同类型的rnn</h1><p id="a6de" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">我们可以有不同类型的rnn来处理序列长度不同的用例。这些问题可以分为以下几类:</p><p id="d377" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jn">多对多</em> </strong></p><p id="cf68" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们前面看到的名称实体识别例子就属于这一类。我们有一个单词序列，对于每个单词，我们必须预测它是否是一个名字。对于这样一个问题，RNN的架构看起来是这样的:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mg"><img src="../Images/b1566409f85eaaeeee94f9f84ed7d7a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/0*lljXYmU4xVzoATmB.png"/></div></figure><p id="edc9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每个输入单词，我们预测相应的输出单词。</p><p id="0de5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jn">多对一</em> </strong></p><p id="0152" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑情感分类问题。我们将一个句子传递给模型，它会返回与该句子相对应的情感或评级。这是一个多对一的问题，输入序列可以有不同的长度，而只有一个输出。针对此类问题的RNN体系结构如下所示:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mh"><img src="../Images/3b392adfa3fa0d906c0e8d04c897cae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/0*wIldfvLM6WftKP-N.png"/></div></figure><p id="a8cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们在句子的末尾得到一个输出。</p><p id="7746" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jn">一对多</em> </strong></p><p id="e155" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑音乐生成的例子，我们希望使用音乐作为输入来预测歌词。在这种情况下，输入只是一个单词(或一个整数)，输出可以是不同的长度。此类问题的RNN架构如下所示:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mi"><img src="../Images/7892b0e92d776d65e7d0be139ca0ccac.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/0*YPWFPU1D-ImbCYEU.png"/></div></figure><p id="fbe9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有一种工业上普遍使用的RNN。考虑机器翻译应用程序，我们将一种语言的输入句子翻译成另一种语言。这是一个多对多的问题，但是输入序列的长度可能等于也可能不等于输出序列的长度。</p><p id="5411" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，我们有编码器部分和解码器部分。编码器部分读取输入句子，解码器将其翻译成输出句子:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mj"><img src="../Images/fe4b8db7f0eafbaa26ff69da8c3daa5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/0*h5jK8ZNaK1TyGnGN.png"/></div></figure><h1 id="cac3" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">语言模型和序列生成</h1><p id="a963" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">假设我们正在构建一个语音识别系统，我们听到一句话“苹果和梨沙拉很好吃”。该模型将预测什么——“苹果和沙拉很好吃”或“苹果和梨沙拉很好吃”？</p><p id="42b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望第二句话！语音识别系统通过使用预测每个句子的概率的语言模型来挑选这个句子。</p><p id="9aa3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是我们如何建立一个语言模型呢？</p><p id="024f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们有一个输入句子:</p><blockquote class="ls lt lu"><p id="f34c" class="if ig jn ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated">猫平均每天睡15个小时。</p></blockquote><p id="7858" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">构建语言模型的步骤如下:</p><ul class=""><li id="a397" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">步骤1 —对输入进行标记，即创建一个字典</li><li id="eb87" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">步骤2 —将这些单词映射到一个独热编码向量。我们可以添加代表句子结束的标签</li><li id="f130" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">步骤3——建立一个RNN模型</li></ul><p id="a66f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们取第一个输入单词并对其进行预测。这里的输出告诉我们字典中任何单词的概率是多少。给定第一个输入单词，第二个输出告诉我们预测单词的概率:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mk"><img src="../Images/472ef98a552229620566c7ee783b26c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/0*-oSRlFKSxmZNsvvC.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl ml"><img src="../Images/5bd8d68fe33c7b021d0ea1de96c06ace.png" data-original-src="https://miro.medium.com/v2/format:webp/0*-CBZ2veEWDFMhPFn.png"/></div></figure><p id="db5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的RNN模型中的每一步都着眼于一些前面的单词来预测下一个单词。训练RNN模型会面临各种挑战，我们将在下一节讨论这些挑战。</p><h1 id="4066" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">使用RNNs的消失渐变</h1><p id="5b4f" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">递归神经网络的最大问题之一是它会遇到消失梯度。怎么会？考虑这两句话:</p><p id="d0a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">已经吃了一堆食物的猫吃饱了。</em></p><p id="8d72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">已经吃了一堆食物的猫已经饱了。</p><p id="2d65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面两句话哪个语法正确？是第一个(再看一遍以防错过！).</p><p id="9b34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">基本rnn不擅长捕捉长期依赖关系。</strong>这是因为在反向传播期间，来自输出y的梯度将很难反向传播以影响早期层的权重。因此，在基本的RNNs中，输出受更接近该单词的输入的影响很大。</p><p id="d029" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果梯度爆炸，我们可以通过设置预定义的阈值来修剪它们。</p><h1 id="c5d6" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">门控循环单元</h1><p id="5380" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">gru是RNNs的一种修改形式。它们在捕捉更长的距离依赖性方面非常有效，也有助于解决消失梯度问题。计算时间步长t激活的公式为:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mm"><img src="../Images/b3695da39dcd078d7657421a1922558a.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/0*UKkyTOb7YKL1f4vt.png"/></div></figure><p id="41b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RNN的一个隐藏单元如下图所示:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mn"><img src="../Images/0e0b0d9d1040c61325a6d5b260b1c1e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/0*RvAxw6lszqcTTs5b.png"/></div></figure><p id="5641" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个单元的输入是来自前一个单元的激活和那个时间步长的输入字。我们在这一步计算激活和输出。我们给这个RNN增加一个存储单元，以便记住远离当前单词的单词。让我们看看GRU的方程式:</p><p id="7d8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">c <t> = a <t/></t></p><p id="3164" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中c是存储单元。</p><p id="79b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在每个时间步长，我们将c <t>值改写为:</t></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mo"><img src="../Images/59e11f685805702e06fa24f887b18a3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/0*JwlUZ0VPK5jaJLYb.png"/></div></figure><p id="4160" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这作为更新c <t>值的候选。我们还定义了一个更新门，它决定是否更新存储单元。更新门的公式为:</t></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mp"><img src="../Images/58af6e506d76dd592989dc366c5cf542.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/0*FDMrAeglv7EXfxal.png"/></div></figure><p id="fd7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，我们使用sigmoid来计算更新值。因此，更新门的输出将总是在0和1之间。我们使用先前的存储单元值和更新门输出来更新存储单元。c <t>的更新公式如下:</t></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mq"><img src="../Images/7d2e3974c37e9b937c6a3de14e1194e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/0*1U0-VsAZ8QcU_7YD.png"/></div></figure><p id="f5ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当门值为0时，c <t> = c <t-1>，即我们不更新c <t>。当门值为1时，c <t> = c <t>并且该值被更新。让我们用一个例子来理解这个令人费解的概念:</t></t></t></t-1></t></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mr"><img src="../Images/4bfbe5df35dcdf9767205285081628d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/0*H7CiPT7mdb_oOkhK.png"/></div></figure><p id="d58c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们看到单词cat时，门值为1。对于序列中的所有其他字，门值是0，因此猫的信息将一直携带到字“was”为止。我们期望模型预测<em class="jn">是</em>而不是<em class="jn">是</em>。</p><p id="08a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是GRUs帮助记忆长期依赖的方式。以下是帮助您理解GRU工作原理的可视化效果:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ms"><img src="../Images/cfba4d3a75763f46e1bc313053b0b563.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/0*07Yl7ZOBsPyfQDeJ.png"/></div></figure><p id="f949" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每个单元，我们有三个输入:a <t-1>，c <t-1>和x <t>和三个输出:a <t>，c <t>和y(hat) <t>。</t></t></t></t></t-1></t-1></p><h1 id="5eb6" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">长短期记忆(LSTM)</h1><p id="1fcb" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">LSTMs如今在深度学习领域风靡一时。由于其复杂性，他们现在可能没有很多行业应用程序，但相信我，很快就会有了。花时间学习这个概念是值得的——它将来会派上用场。</p><p id="a984" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在为了理解LSTMs，让我们回忆一下我们看到的所有GRU方程:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mt"><img src="../Images/7bf2731dfeaba30f370cc4f470bed33a.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/0*TxygGdZ2ye0KFWDH.png"/></div></figure><p id="370d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们刚刚在计算c <t>的相关性时增加了一个门，这个门告诉我们c <t-1>与更新c <t>的相关性如何。对于GRUs来说，a <t> = c <t>。</t></t></t></t-1></t></p><p id="dbd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> LSTM是GRU的一个更一般化、更强大的版本。</strong>LSTM的方程式是:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mu"><img src="../Images/28fbfe012edf0d9e1a5f60a1da3eaa48.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/0*MYE7nvkAenuJxW2t.png"/></div></figure><p id="97fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这和GRU的情况相似，对吗？我们只是用了一个<t-1>而不是c <t-1>。我们还有一个更新门:</t-1></t-1></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mv"><img src="../Images/942aa3ec85a883c65e000fc29f752eb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/0*fwx2gE4Fq8cNnR8s.png"/></div></figure><p id="a6e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在LSTM也有一个遗忘门和一个输出门。这些门的公式类似于更新门的公式:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mw"><img src="../Images/e23c32cb51c25b30b32fcae4074575d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/0*tRtypk5OGgjAVwmP.png"/></div></figure><p id="17b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将c <t>值更新为:</t></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mx"><img src="../Images/bc3ff62734617c0eecf65972bb5721de.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/0*65TK4BFUXQ-BQykb.png"/></div></figure><p id="e50c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一层的激活将是:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es my"><img src="../Images/cbbffd8a939915293bef3c7819fe0f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/0*joJR7TobAtHvcP34.png"/></div></figure><p id="d566" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，你应该使用哪种算法——GRU还是LSTM？</p><p id="9437" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每种算法都有其优点。你会发现它们的准确性会根据你要解决的问题的类型而有所不同。GRU的优势在于它的架构更简单，因此我们可以建造更大的模型，但LSTM更强大、更有效，因为它有3个门，而不是2个。</p><h1 id="c47e" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">双向RNN</h1><p id="0cae" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">到目前为止，我们看到的RNN架构只关注序列中的前一个信息。如果我们的模型能够在特定的时间步长进行预测时，同时考虑序列的先前和后来的信息，那该有多棒？</p><p id="bed8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">是的，有可能！欢迎来到双向RNNs的世界。但是在我向您介绍什么是双向rnn以及它们是如何工作的之前，让我们先来看看为什么我们需要它们。</p><p id="504e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑命名实体识别问题，我们想知道序列中的一个单词是否代表一个人。我们有以下例子:</p><blockquote class="ls lt lu"><p id="3af3" class="if ig jn ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated">他说:“泰迪熊打折了！”</p></blockquote><p id="801d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们把这个句子输入一个简单的RNN，这个模型会预测“泰迪”是一个人的名字。它只是没有考虑到这个词后面的内容。我们可以在双向rnn的帮助下解决这个问题。</p><p id="42c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在假设我们有一个4个单词的输入序列。双向RNN看起来像这样:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mz"><img src="../Images/1d83cbe19a67d598175b18d2ad0250a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/0*vp_xzmr8FKRZZngU.png"/></div></figure><p id="10f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了计算RNN单位的输出，我们使用以下公式:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es na"><img src="../Images/c5050cbe91547d19077ee5e45018ad68.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/0*3J6ZuSYWV9eT4u2k.png"/></div></figure><p id="1453" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，我们可以有双向gru和双向LSTMs。使用双向RNNs的一个缺点是，我们必须在做出任何预测之前查看整个数据序列。但是标准的B-RNN算法实际上对于构建和设计大多数NLP应用程序是非常有效的。</p><h1 id="6041" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">深层RNNs</h1><p id="bd5c" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">还记得深度神经网络长什么样吗？</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nb"><img src="../Images/2cdd94c7a0facb219a47dfd392a7c328.png" data-original-src="https://miro.medium.com/v2/resize:fit:196/format:webp/0*dhLUzPHJYtkJhcXf.png"/></div></figure><p id="94dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有一个输入层，一些隐藏层，最后是一个输出层。深邃的RNN也是这个样子。我们取一个类似的网络，并及时展开:</p><p id="706a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，激活的通用符号如下所示:</p><p id="690a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a[l] <t> =稍后在时间t激活l</t></p><p id="557a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们要计算一个[2] &lt;3&gt;:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nc"><img src="../Images/03344eb86b63c6eb7ad7b34fb0dfb4c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/0*kuT4ij1yed0x1Dxz.png"/></div></figure><p id="1fd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度RNNs到此为止。深吸一口气，这是相当多的一口气消化。现在，是时候进入模块2了！</p><h1 id="e51b" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">模块2:自然语言处理和单词嵌入</h1><p id="7ad3" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">学习第二单元的目标是:</p><ul class=""><li id="3ea7" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">使用深度学习技术学习自然语言处理</li><li id="8065" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">了解如何使用单词矢量表示和嵌入层</li><li id="3da1" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">让我们看看自然语言处理的各种应用，比如情感分析、命名实体识别和机器翻译，来丰富我们的学习</li></ul><h1 id="95e4" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">第1部分—单词嵌入简介</h1><h1 id="cb41" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">单词表示法</h1><p id="ab29" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">至此，我们已经用一个词汇来表示单词:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nd"><img src="../Images/8600e4915eca509dbbd0a1d6cedb724d.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/0*RmJBElTIxgZ4KNdz.png"/></div></figure><p id="52e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了表示一个单词，我们创建了一个hot vector:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mm"><img src="../Images/2541ed3455a689a80edddbb84b0b5a72.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/0*YhJDtu0IyLYF1k56.png"/></div></figure><p id="9133" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，假设我们希望我们的模型在不同的单词之间进行归纳。我们根据下面的句子训练模型:</p><blockquote class="ls lt lu"><p id="8286" class="if ig jn ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated"><em class="hi">我想要一杯苹果汁。</em></p></blockquote><p id="335f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们给了“我想要一杯苹果”作为训练序列，给了“果汁”作为目标。我们希望我们的模型能够概括出，比如说:</p><blockquote class="ls lt lu"><p id="2087" class="if ig jn ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated">我想要一杯橘子汁。</p></blockquote><p id="b445" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为什么我们以前的词汇方法行不通？因为它缺乏概括的灵活性。我们将尝试计算代表单词Apple和Orange的向量之间的相似度。我们将不可避免地得到零作为输出，因为任何两个一热向量的乘积总是零。</p><p id="992b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们用一组特征来表示每个单词，而不是用一个热点向量来表示，会怎么样呢？看看这张表:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ne"><img src="../Images/8bee0ca832da6b717f6e0202e4258c3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KYKw6SYP_J_ZQZfn.png"/></div></div></figure><p id="1db7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以用这种方法找到相似的单词。挺有用的吧？</p><p id="e3ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比方说，每个单词有300个特征。例如，单词“Man”将由一个名为e5391的300维向量来表示。</p><p id="d537" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还可以将这些表示用于可视化目的。将300维向量转换为二维向量，然后绘制它。有相当多的算法可以做到这一点，但我最喜欢的是简单的<a class="ae jm" href="https://www.analyticsvidhya.com/blog/2017/01/t-sne-implementation-r-python/" rel="noopener ugc nofollow" target="_blank"> t-SNE </a>。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nf"><img src="../Images/f0e8bece3e1302552bd5a6fedebd531a.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/0*9jzfIa8jwYteHAwP.png"/></div></figure><h1 id="3bb5" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">使用单词嵌入</h1><p id="6608" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">当使用单词表示时，单词嵌入确实有助于我们更好地进行概括。</p><p id="4e68" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设您正在执行命名实体识别任务，并且在训练集中只有少量记录。在这种情况下，您可以在线获取预训练的单词嵌入，也可以创建自己的嵌入。这些嵌入将具有该词汇表中所有单词的特征。</p><p id="f4b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是用单词嵌入替换独热编码表示的两个主要步骤:</p><ol class=""><li id="193d" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc le jj jk jl bi translated">从大型文本语料库中学习单词嵌入(或下载预训练的单词嵌入)</li><li id="91c7" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc le jj jk jl bi translated">将这些嵌入转移到具有较小训练集的新任务中</li></ol><p id="ba43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将看看单词嵌入的属性。</p><h1 id="57dd" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">单词嵌入的性质</h1><p id="c037" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">假设你得到一个问题——“如果男人是女人，那么国王是？”。大多数敏锐的解谜者以前都见过这类问题！</p><p id="b18b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个问题的答案可能是女王。但是模型将如何决定呢？这实际上是理解单词嵌入最广泛使用的例子之一。我们嵌入了男人、女人、国王和王后。男人的嵌入向量将类似于女人，国王的嵌入向量将类似于王后。</p><p id="83e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以使用下面的等式:</p><p id="b058" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">eman — ewoman = eking —？</p><p id="1bd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解决这个问题给了我们一个300维的向量，其值等于queen的嵌入。我们也可以使用相似性函数来确定两个单词嵌入之间的相似性。相似性函数由下式给出:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ng"><img src="../Images/4725e0e6405572801ca4295413f0f27e.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/0*mJECue-9v-ELsnKI.png"/></div></figure><p id="590b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是余弦相似性。我们也可以使用欧几里德距离公式:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nh"><img src="../Images/320dfb5cc372a5c1965c798deafcfefc.png" data-original-src="https://miro.medium.com/v2/resize:fit:204/format:webp/0*PgY0ucNc3g8tHGnV.png"/></div></figure><p id="f729" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在核心推荐系统中，还有一些其他不同类型的相似性度量。</p><h1 id="223a" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">嵌入矩阵</h1><p id="4725" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">当我们实现一个单词嵌入算法时，我们实际上最终学习了一个嵌入矩阵。如果我们有一个10，000个单词的词汇表，每个单词有300个特征，嵌入矩阵表示为E，如下所示:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ni"><img src="../Images/e4e6ad4aef1b472b12182c67fe0a88d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/0*yo-x5bhama5YpcXj.png"/></div></figure><p id="dfc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了找到单词“orange”在第6257个位置的嵌入，我们将上面的嵌入矩阵乘以orange的独热向量:</p><p id="d441" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">e。O6257 = e6257</p><p id="5854" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">E的形状是(300，10k)，O的形状是(10k，1)。因此，嵌入向量e将具有(300，1)的形状。</p><h1 id="842a" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">第2部分—学习单词嵌入:Word2Vec &amp; GloVe</h1><h1 id="413a" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">学习单词嵌入</h1><p id="2362" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">假设我们正在使用神经网络构建一个语言模型。模型的输入是“我想要一杯橘子汁”，我们希望模型预测下一个单词。</p><p id="58f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将首先使用预训练的单词嵌入矩阵来学习序列中每个单词的嵌入，然后将这些嵌入传递给神经网络，该神经网络将在末端具有softmax分类器来预测下一个单词。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nj"><img src="../Images/cb3d2d291cce73b65642921bdccb10ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8ury_JJKrf6vDZT-.png"/></div></div></figure><p id="141d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是建筑的样子。在这个例子中，我们有6个输入单词，每个单词由300维向量表示，因此序列的输入将是6*300 = 1800维。该模型的参数是:</p><ul class=""><li id="7e71" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">嵌入矩阵(E)</li><li id="09ab" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">W[1]，b[1]</li><li id="66ed" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">W[2]，b[2]</li></ul><p id="1097" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以减少输入单词的数量，降低输入维数。我们可以说，我们希望我们的模型仅使用前面的4个单词来进行预测。在这种情况下，输入将是1200维的。输入也可以被称为上下文，并且可以有各种方式来选择上下文。几种可能的方法是:</p><ul class=""><li id="efa4" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">取最后4个单词</li><li id="5982" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">从左边取4个单词，从右边取4个单词</li><li id="a788" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">最后一个词</li><li id="b73e" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">我们也可以用一个邻近的词</li></ul><p id="4156" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是我们如何解决语言建模问题，我们输入上下文并预测一些目标词。在下一节中，我们将看看Word2Vec如何应用于学习单词嵌入。</p><h1 id="ba7b" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">Word2Vec</h1><p id="f7f0" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">这是一种简单且更有效的学习单词嵌入的方法。假设我们的训练集中有一个句子:</p><blockquote class="ls lt lu"><p id="067a" class="if ig jn ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated">我要一杯橙汁配麦片。</p></blockquote><p id="b01e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用skip gram模型来挑选一些上下文和目标单词。这样，我们创建了一个监督学习问题，其中我们有一个输入和相应的输出。对于上下文，我们不是只有最后4个单词或最后1个单词，而是随机选取一个单词作为上下文单词，然后在某个窗口内随机选取另一个单词(比如左右各5个)并将其设置为目标单词。一些可能的上下文-目标对可以是:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nk"><img src="../Images/879ed1725ba66a309b88746a064785b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/1*J06_RSB_93KTO8ST7Id8Lw.png"/></div></figure><p id="9ce8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这只是几双，我们还可以有更多双。以下是该模型的详细信息:</p><p id="d876" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Vocab大小= 10，000k</p><p id="0762" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们想学习从某个上下文到某个目标(t)的映射。我们是这样做映射的:</p><p id="f078" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Oc -&gt; E -&gt; ec -&gt; softmax -&gt; y(hat)</p><p id="614a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，ec = E.Oc</p><p id="cb9f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，softmax计算在给定上下文单词(c)的情况下获得目标单词(t)作为输出的概率。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nl"><img src="../Images/6026b0efeb841d486de207a553b0f3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/0*2KIi0LWtG-23Y4Mt.png"/></div></figure><p id="7287" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将损失计算为:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nm"><img src="../Images/fa061857d1847347e451574b2203a107.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/0*hNX_immB9mGhBiwf.png"/></div></figure><p id="7d59" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用softmax函数给算法带来了几个问题，其中之一是计算成本。每次我们计算概率时:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nn"><img src="../Images/ff37c0a1e43176a0816979b1e9deeca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/0*_BHXJTG-WZzvks0o.png"/></div></figure><p id="07fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们必须对词汇表中的所有10，000个单词进行求和。如果我们使用更大的词汇量，比如100，000个单词或者更多，计算会变得非常慢。这个问题的几种解决方案是:</p><p id="2f03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用分层的softmax分类器。因此，我们不是一次把一个词分成10，000个类别，而是先把它分成5000个类别，或者5000个类别，以此类推。这样，我们不必每次都计算所有10，000个单词的总和。分层softmax分类器的流程如下所示:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es no"><img src="../Images/164aafc4fb449b0c3a3b1bbd23ea117f.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/0*U_IOOQ5viJFc81q9.png"/></div></figure><p id="08b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你脑海中可能出现的一个问题是如何选择上下文c？一种方法是随机抽取上下文单词。随机抽样的问题是，像is，The这样的常见词会出现得更频繁，而像orange，apple这样的独特词可能一次也不会出现。因此，我们尝试选择一种方法，对不常用的词给予较大的权重，对较常用的词给予较小的权重。</p><p id="f7fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在下一节中，我们将看到一种帮助我们减少计算成本和学习更好的单词嵌入的技术。</p><h1 id="708e" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">负采样</h1><p id="eefb" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">在skip gram模型中，正如我们前面看到的，我们将上下文单词映射到目标单词，这允许我们学习单词嵌入。该模型的一个缺点是softmax带来的高计算成本。考虑我们之前举的同一个例子:</p><p id="d449" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我想要一杯橙汁配我的麦片。</p><p id="36a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">负采样会做的是，它创建了一个新的监督学习问题，其中给定一对单词“orange”和“juice ”,我们将预测它是否是上下文-目标对？对于上面的例子，新的监督学习问题将看起来像:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es np"><img src="../Images/6ba2ea3a5c72332a01cfaaf2d6eae37a.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*4g6D0WUAWb7zVvhFJvmfPA.png"/></div></figure><p id="6abd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于orange-juice是一个上下文-目标对，我们将目标值设置为1，而orange-king不是上例中的一对，因此目标值为0。这些0值表示它是负样本。我们现在应用逻辑回归来计算该对是否是上下文-目标对的概率。概率由下式给出:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nq"><img src="../Images/2878901eacddaca20e164e319b702b06.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/0*VULiGxqXanH814bj.png"/></div></figure><p id="1cc9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以有k对单词来训练模型。对于较小的数据集，k可以在5-20之间，而对于较大的数据集，我们选择较小的k(2-5)。因此，如果我们建立一个神经网络，输入是橙色(橙色的一个热点向量):</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nr"><img src="../Images/0a9aa8a940cac96531783bd10f515627.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/0*pamBzyiwgvp24y4A.png"/></div></figure><p id="4ace" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将有10，000个可能的分类问题，每个问题对应于词汇表中的不同单词。所以，这个网络会告诉所有与上下文单词orange对应的可能的目标单词。这里，不是有一个巨大的10，000路softmax，这在计算上非常慢，而是有10，000个二进制分类问题，这与softmax相比相对非常慢。</p><p id="f5bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从序列中选择上下文单词，一旦它被选择，我们从序列中随机选取另一个单词作为正样本，然后从词汇表中随机选取几个其他单词作为负样本。这样，我们可以使用简单的二进制分类问题来学习单词嵌入。接下来我们将看到学习单词嵌入的更简单的算法。</p><h1 id="0d91" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">手套词向量</h1><p id="501f" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">我们将研究同一个例子:</p><p id="c178" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我想要一杯橙汁配我的麦片。</p><p id="7eb7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">之前，我们通过从文本语料库中挑选两个彼此非常接近的单词来对单词对(上下文和目标)进行采样。用于单词表示的手套或全局向量使其更加明确。假设:</p><p id="dcb9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Xij =在j的上下文中出现的次数</p><p id="dbb9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，I类似于目标(t)，j类似于上下文。手套最大限度地减少了以下情况:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ns"><img src="../Images/ecf8c97068bdd96089120be2e73d5e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/0*lMNNNFZjqjh4_MwD.png"/></div></figure><p id="e450" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，f(Xij)是加权项。它对更频繁出现的单词(例如像这样的停用词，is，of，a，..)和较不常用的单词的较大权重。同样，当(Xij) = 0时，f(Xij) = 0。已经发现，最小化上述等式最终导致良好的单词嵌入。现在，我们已经看到了许多学习单词嵌入的算法。接下来，我们将看到使用单词嵌入的应用程序。</p><h1 id="8fc0" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">第3部分—使用单词嵌入的应用程序</h1><h1 id="3afa" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">情感分类</h1><p id="eb6c" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">你一定很清楚什么是情感分类，所以我长话短说。查看下表，其中包含一些文本及其相应的情绪:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nt"><img src="../Images/c6063d19bf89c59ddd1df823dc94ec71.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*MlEECJuwKBUSYr6VVSJfFw.png"/></div></figure><p id="e1d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">X (text) y(感悟)甜品棒极了。****服务很慢。**适合速食，但没什么特别的。***完全缺乏好品味*</p><p id="7a73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">情感分类的应用多种多样，种类繁多，规模巨大。但是在大多数情况下，你会遇到，这种训练并没有贴上标签。这就是单词嵌入派上用场的地方。让我们看看如何使用单词嵌入来建立情感分类模型。</p><p id="2c60" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们得到的反馈是:“甜点太棒了”。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nu"><img src="../Images/76961e464495d39ba19c3013c7596243.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aD-oP4DE-Rk5OyNU.png"/></div></div></figure><p id="09c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，E是预训练的嵌入矩阵，比如说，1000亿个单词。我们将每个单词的独热编码向量与嵌入矩阵相乘，以获得单词表示。接下来，我们总结所有这些嵌入，并应用softmax分类器来决定该评论的评级。</p><p id="46a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它只取所有单词的平均值，所以如果评论是负面的，但有更多正面的单词，那么模型可能会给它更高的评级。不是个好主意。因此，我们可以使用RNN来进行情感分类，而不是仅仅对嵌入求和来获得输出。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nv"><img src="../Images/101266bf8bb7026e6433e8f768013b53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*u3XHqixk4gPwxY1S.png"/></div></div></figure><p id="6ec0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个多对一的问题，我们有一个输入序列和一个输出。你现在完全有能力解决这个问题。🙂</p><h1 id="ecd9" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">模块3:序列模型和注意机制</h1><p id="73c1" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">欢迎来到本系列的最后一个模块！下面是我们将在本模块中主要实现的两个目标:</p><ul class=""><li id="980c" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">理解注意力机制</li><li id="e3e6" class="jd je hi ih b ii jo im jp iq jq iu jr iy js jc ji jj jk jl bi translated">为了理解在给定输入序列的情况下模型应该将注意力集中在哪里</li></ul><h1 id="e7df" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">基本型号</h1><p id="f387" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">我将保持这一部分与行业相关，因此我们将涵盖对机器翻译、语音识别等应用有用的模型。考虑这个例子——我们的任务是构建一个序列到序列模型，我们想输入一个法语句子并将其翻译成英语。问题将会是这样的:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nw"><img src="../Images/d5a73db2ee466305c8ab23c466bdacda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/0*vx3mYhL-8MqRf0k8.png"/></div></figure><p id="3859" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里x &lt;1&gt;，x &lt;2&gt;是输入，y &lt;1&gt;，Y &lt;2&gt;是输出。为了建立一个模型，我们有一个编码器部分，它接受一个输入序列。编码器被构建为RNN，或LSTM，或GRU。在编码器部分之后，我们构建解码器网络，该网络将编码输出作为输入，并被训练以生成句子的翻译。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nx"><img src="../Images/fe24e6ba3eb382173f7cf2059d52bd30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/0*L0H768QI-LypQpUQ.png"/></div></figure><p id="9c35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个网络也普遍用于图像字幕。作为输入，我们有图像的特征(使用卷积神经网络生成)。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ny"><img src="../Images/daaccc727f1802a30614970f61b66470.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g3s3cHjcDUrY9jV3.png"/></div></div></figure><h1 id="fd29" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">挑选最可能的句子</h1><p id="ff26" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">机器翻译系统的解码器模型与语言模型非常相似。但是两者之间有一个关键的区别。在语言模型中，我们从全零向量开始，而在机器翻译中，我们有一个编码器网络:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es nz"><img src="../Images/c480aa388f1154332bda21e0d21f806a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/0*RZTg9Qn_eeHdnSSa.png"/></div></figure><p id="3e69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器翻译模型的编码器部分是一个条件语言模型，其中我们计算给定输入的输出概率:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es oa"><img src="../Images/f57330c32c51525caffef1cbac6ecd5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/0*FAnSoKjlCqv_ZGzZ.png"/></div></figure><p id="82f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，对于输入句子:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ob"><img src="../Images/1a0b97bae817a60bf91d2895ec7caa82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/0*_ZkCCKRc3KOqhsYa.png"/></div></figure><p id="8298" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以有多种翻译，例如:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es oc"><img src="../Images/a835335332b87f48aa400b07610661ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/0*p_k9YeoIKqowC0CH.png"/></div></figure><p id="34d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们想要以上所有句子的最佳翻译。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es od"><img src="../Images/8597e13ee1477373703c17dd569c60f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/0*mbDwDfn0A7KMfKXE.png"/></div></figure><p id="ffd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好消息是什么？有一种算法可以帮助我们选择最可能的翻译。</p><h1 id="1f8d" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">波束搜索</h1><p id="faea" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">这是生成最可能翻译的最常用算法之一。使用以下3个步骤可以理解该算法:</p><p id="5fa8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第一步:</strong>选择第一个翻译的单词并计算其概率:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es oe"><img src="../Images/d4a2929e836c9607cee7adde4f2d4e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/format:webp/0*WAp16MpsQZXsC56Z.png"/></div></figure><p id="8156" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以设置一个豆宽(B)来表示B=3，而不是只选择一个单词。它将挑选可能是第一个翻译单词的前3个单词。这三个词然后被存储在计算机的内存中。</p><p id="5733" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤2: </strong>现在，对于步骤1中选择的每个单词，该算法计算第二个单词可能是什么的概率:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es of"><img src="../Images/b21052b11a6e700b77b2cf14af9bc665.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*ObG-KSRGZeSQDcXW.png"/></div></figure><p id="e865" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果波束宽度为3，词汇表中有10，000个单词，则可能的组合总数将是3 * 10，000 = 30，000。我们评估所有这30，000个组合，并挑选出前3个组合。</p><p id="861b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第三步:我们重复这个过程，直到句子结束。</p><p id="5ac2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过一次添加一个单词，beam search为任何给定的句子决定最可能的翻译。让我们来看看我们可以对波束搜索做的一些改进，以使它更有效。</p><h1 id="cf90" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">光束搜索的改进</h1><p id="9fee" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">波束搜索使这种可能性最大化:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es og"><img src="../Images/4745662138ffb8309e97f45e0f1b0f5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/0*xC_lMa0j_c-K4n3l.png"/></div></figure><p id="a650" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个概率是通过将不同单词的概率相乘来计算的。由于特定的概率是非常小的数字(在0和1之间)，如果我们将这样小的数字乘以多次，最终的输出是非常小的，这在计算中产生了问题。因此，我们可以使用下面的公式来计算概率:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es oh"><img src="../Images/22c8d8b82e651ae0068d6d9fc4f18ab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/0*gg97Fnq2JU55dpgx.png"/></div></figure><p id="2175" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们不是最大化产品，而是最大化产品的日志。即使使用这个目标函数，如果翻译的句子有更多的单词，它们的乘积将下降到更多的负值，因此我们可以将函数归一化为:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es oi"><img src="../Images/0aecf9e8a7e500b5636525940a24382d.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/0*2djaj4ap0u7tt4CZ.png"/></div></figure><p id="be22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，对于使用波束搜索选择的所有句子，我们计算这个归一化的对数似然，然后选择给出最高值的句子。还有一个细节我想分享，那就是如何决定波束宽度B？</p><p id="74c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果波束宽度更大，我们会有更好的结果，但算法会变得很慢。另一方面，选择较小的B会使算法运行更快但结果不会准确。选择波束宽度没有硬性规定，可以根据应用而变化。我们可以尝试不同的值，然后选择产生最佳结果的值。</p><h1 id="f842" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">波束搜索中的误差分析</h1><p id="6d6e" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">波束搜索是一种近似算法，根据波束宽度输出最可能的平移。但是并不总是需要每次都能产生正确的翻译。如果我们没有得到正确的翻译，我们必须分析是由于光束搜索还是我们的RNN模型导致了问题。如果我们发现波束搜索导致问题，我们可以增加波束宽度，希望我们会得到更好的结果。如何决定是重点改进波束搜索还是模型？</p><p id="45ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设实际的翻译是:</p><p id="d0a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">简九月访问非洲(y*) </em></p><p id="8647" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们从算法中得到的翻译是:</p><p id="a127" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">简去年九月访问了非洲</em></p><p id="7827" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RNN将计算P(y* | x)和P(y(hat) | x)</p><p id="2236" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">案例一:</strong> P(y* | x) &gt; P(y(hat) | x)</p><p id="fce4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这意味着波束搜索选择了y(hat ),但是y*获得了更高的概率。因此，波束搜索是错误的，我们可以考虑增加波束宽度。</p><p id="481e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">情况二:</strong> P(y* | x) &lt; = P(y(hat) | x)</p><p id="3bb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这意味着y*是比y(hat)更好的翻译，但RNN预测相反。在这里，RNN是错误的，我们必须改进模型。</p><p id="d8fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，对于每一个翻译，我们决定是RNN错了还是光束搜索错了。最后，我们计算出波束搜索与RNN模型相比所导致的误差比例，并基于哪一个错误更大来更新波束搜索或RNN模型。这样我们可以改进翻译。</p><h1 id="05f9" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">注意力模型</h1><p id="b722" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">到目前为止，我们已经看到了机器翻译的编码器-解码器架构，其中一个RNN读取输入，另一个输出句子。但是当我们得到很长的句子作为输入时，模型很难记住整个句子。</p><p id="a4f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意力模型所做的是从长句中提取小样本并翻译它们，然后再提取另一个样本并翻译它们，等等。</p><p id="3458" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用一个alpha参数来决定在生成输出时应该对特定的输入单词给予多大的关注。</p><p id="cbaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">⍺ &lt;1,2&gt; =为了生成第一个单词，应该对第二个输入单词给予多少关注</p><p id="d07e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们用一个例子来理解这一点:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es oj"><img src="../Images/58b5983b734a1f6b3f39765220cab437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/0*lH71NkF3K3nI181U.png"/></div></figure><p id="65fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，为了生成第一个输出y &lt;1&gt;，我们为每个单词取注意力权重。我们是这样计算注意力的:</p><p id="c1af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们有Tx个输入单词和Ty个输出单词，那么总的注意参数将是Tx * Ty。</p><p id="3e30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">你可能已经知道了——注意力模型是深度学习中最强大的想法之一。</strong></p><h1 id="7944" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">结束注释</h1><p id="8531" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">序列模型很牛逼吧？它们有大量的实际应用——我们只需要知道在特定情况下使用的正确技术。我希望你能在本指南中学到这些技巧。</p><p id="29b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词嵌入是表示单词的一种很好的方式，我们已经看到了如何构建和使用这些单词嵌入。我们已经讨论了单词嵌入的不同应用，最后我们还讨论了注意力模型，这是构建序列模型的最强大的思想之一。</p><p id="ed81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你对这篇文章有任何疑问或反馈，欢迎在下面的评论区分享。期待您的回复！</p></div><div class="ab cl ok ol gp om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="hb hc hd he hf"><p id="524d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">原载于2019年1月21日</em><a class="ae jm" href="https://www.analyticsvidhya.com/blog/2019/01/sequence-models-deeplearning/" rel="noopener ugc nofollow" target="_blank"><em class="jn">www.analyticsvidhya.com</em></a><em class="jn">。</em></p></div></div>    
</body>
</html>