<html>
<head>
<title>RDD, DataFrame, and DataSet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RDD、数据框和数据集</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/rdd-dataframe-and-dataset-d92d95d873a4?source=collection_archive---------9-----------------------#2020-01-16">https://medium.com/analytics-vidhya/rdd-dataframe-and-dataset-d92d95d873a4?source=collection_archive---------9-----------------------#2020-01-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="b632" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">弹性分布式数据集(RDD)</h1><p id="5da3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">RDD是整个Spark发展的基础逻辑抽象。它们是集群或环境中的逻辑分布式模型。</p><p id="ab35" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">弹性</strong></p><p id="f75f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">RDD的主要优势是它们具有弹性，这意味着能够在执行过程中的任何时间点进行重新创建。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/4b541521a87e9c206f4f781f77bf7348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o0kM2jJFc5G-ihNib4_1fA.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">RDD谱系图</figcaption></figure><p id="66c5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">让我们考虑一下，我们有RDD1，我们对它执行转换，它将被转换为RDD2，在下一次转换后，它将被转换为RDD3。所有这些转变都被记录为它的起源。因此，如果出了什么问题，RDD可以重建自己。</p><p id="525f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">不可改变的</strong></p><p id="b69c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">当我们对RDD应用变换时，原始的RDD保持不变。Spark没有改变RDD，而是创建了一个非循环图。Spark可以使用这个非循环图重新创建RDD。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kw"><img src="../Images/fa8f677ae89b704a12f84c840ba9cada.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*0ziFgaqlIXt_KTEPU9vafw.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">有向无环图</figcaption></figure><p id="14d3" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">RDD的其他特色是</p><ul class=""><li id="50a8" class="kx ky hi jf b jg kb jk kc jo kz js la jw lb ka lc ld le lf bi translated">编译时类型安全</li><li id="fe36" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">支持结构化和非结构化数据。</li><li id="a1f7" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">Lazy只有在需要某个动作时才会被具体化。Spark为rdd创建非循环图的原因是，它们并不像我们编码时那样执行每个转换。相反，Spark将这些转换记录在一个非循环图中，并将所有内容保存在内存中，并将指针返回给操作。最后，当我们调用一个动作时，Spark执行非循环图的整个链。</li></ul><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es ll"><img src="../Images/62c1c2f7981a3614226984d9c6f044d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RvgyEQ8izP6QFtM3xGjhbA.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">火花懒惰RDD</figcaption></figure><p id="75c2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">为什么使用rdd</strong></p><ul class=""><li id="80c3" class="kx ky hi jf b jg kb jk kc jo kz js la jw lb ka lc ld le lf bi translated">提供控制和灵活性</li><li id="b6de" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">提供低级API</li><li id="9542" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">类型安全</li></ul><p id="c6b6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">rdd的问题</strong></p><ul class=""><li id="9bcb" class="kx ky hi jf b jg kb jk kc jo kz js la jw lb ka lc ld le lf bi translated">我们表达如何解决问题，而不是做什么。</li><li id="045d" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">未通过Spark优化</li><li id="1a03" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">对于Python这样的非JVM语言来说很慢</li><li id="a499" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">Spark不理解记录在非循环图中的转换。因此，它不会修改执行计划来以更好的方式执行它。</li></ul><h1 id="36e4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结构化API</h1><p id="0fc5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">数据帧和数据集是Spark中的结构化API。它为您提供了一系列代码错误的早期检测。在结构化API中，我们告诉Spark我们在做什么，它评估我们的查询或lambda函数，以找出如何以更好的方式完成它。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lm"><img src="../Images/ae154252cc77996ac40e14fe41a9bd7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DkKviblx5piJSm05YSeslw.png"/></div></div></figure><p id="d04a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在数据帧和数据集的情况下，比方说，如果你拼错了一个列名，你将得到一个编译时错误，而不是运行时错误，这为我们节省了大量的时间和金钱。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es ln"><img src="../Images/9600423fe5105d3a986d5d2a31b8c7b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LKi6n5MIkhgHG1CH-NAYYA.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">Spark 2.0中API的统一</figcaption></figure><p id="e974" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">Spark版融合了数据帧和数据集。因此，如果您使用Spark 2.0或更高版本，您将只使用一组数据集API。SCALA中的DataFrame是数据集[Row](即Row类型的数据集)的别名。尽管我们最终有了数据帧和数据集，但它们都将被转换成rdd。rdd是Spark的最低级别，可以处理数据。</p><h1 id="9900" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">数据帧</h1><p id="dc92" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">像RDD一样，数据帧是不可变的分布式数据集合。数据帧可以被视为具有与之相关联的模式的表，它包含行和列，并且列可以具有与之相关联的类型。DataFrames比RDD更快的原因是Spark的Catalyst Optimizer。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lo"><img src="../Images/40232b9815cabd317b665d7bcd21a4ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I5D276NXF3cf4FMyKEne_w.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">火花催化剂优化器</figcaption></figure><p id="e6df" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">让我们了解Catalyst Optimizer的工作原理。当一个查询提交给Spark时，它会创建一个未解析的逻辑计划，然后检查Spark目录，查看我们引用的是哪些表或列。一旦模式得到验证，Spark就会创建一个逻辑计划，然后创建一个优化的逻辑计划，这又会创建多个物理计划，并计算每个物理计划的成本，然后选择最佳的一个。在计算出最佳物理规划后，它创建rdd。这些在选择最佳物理计划后创建的rdd与我们通过直接读取文件创建的rdd有很大不同。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lp"><img src="../Images/623c5624adcecd89380db60eda7f4cf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k4lBrtinLV0_AGirwq3dQA.png"/></div></div></figure><p id="11dc" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">假设我们正在连接两个表，然后应用一个过滤器。Spark推断这是一个合乎逻辑的计划。在物理规划期间，Spark甚至可以在连接之前进行过滤，从而大大降低了执行成本。</p><h1 id="4251" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">资料组</h1><p id="dbe3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Dataset是一组强类型的JVM对象，由Scala中定义的case类或Java中的类决定。Dataset API的核心是一个称为编码器的新概念，它负责JVM对象和表格表示之间的转换。表格表示使用Spark的内部钨二进制格式存储，允许对序列化数据进行操作并提高内存利用率。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lr"><img src="../Images/8e26e1aa89ac6fc4fd30522dd292bc9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNu6u5QuvrMs9y6SvdbXsQ.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">数据集内部</figcaption></figure><blockquote class="ls lt lu"><p id="cffc" class="jd je lq jf b jg kb ji jj jk kc jm jn lv kd jq jr lw ke ju jv lx kf jy jz ka hb bi translated">Dataset提供了rdd的便利、数据帧的性能优化和Scala强大的静态类型安全。给Dataframe带来强类型安全的最后一个特性使得Dataset如此吸引人。所有这些特性一起为您提供了一个更具功能性的编程接口来处理结构化数据。</p></blockquote><p id="1e80" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">数据集的好处</strong></p><ul class=""><li id="9d70" class="kx ky hi jf b jg kb jk kc jo kz js la jw lb ka lc ld le lf bi translated">空间效率</li></ul><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ly"><img src="../Images/5b2621d6713702288f9b6cd4303b7c80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*AQoWYqmIhxJNj5URmUO2Ng.png"/></div></figure><p id="b8be" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">Spark作为一个编译器理解你的数据集类型JVM对象，它使用编码器将你的特定类型JVM对象映射到钨的内存表示。因此，钨编码器可以有效地序列化/反序列化JVM对象，并生成能够以超快的速度执行的紧凑字节码。</p><p id="623c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">何时使用数据集</strong></p><ul class=""><li id="d0a6" class="kx ky hi jf b jg kb jk kc jo kz js la jw lb ka lc ld le lf bi translated">如果您想在编译时获得更高程度的类型安全，想要类型化的JVM对象，利用Catalyst优化，并受益于钨的高效代码生成，请使用Dataset。</li></ul><p id="6384" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">为什么使用数据集</strong></p><ul class=""><li id="2c2d" class="kx ky hi jf b jg kb jk kc jo kz js la jw lb ka lc ld le lf bi translated">高级API</li><li id="0e05" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">强类型安全</li><li id="81e2" class="kx ky hi jf b jg lg jk lh jo li js lj jw lk ka lc ld le lf bi translated">易用性和可读性</li></ul><p id="bff4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">本文是使用Databricks视频参考资料编写的。</p><p id="7314" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">如果你喜欢这篇文章，请点击👏所以其他人会在媒体上看到它。</p></div></div>    
</body>
</html>