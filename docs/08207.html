<html>
<head>
<title>Building ML Model to predict whether the cancer is benign or malignant on Breast Cancer Wisconsin Data Set !! Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在乳腺癌Wisconsin数据集上建立ML模型预测癌症是良性还是恶性！！第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-ml-model-to-predict-whether-the-cancer-is-benign-or-malignant-on-breast-cancer-wisconsin-a09b6c32e7b8?source=collection_archive---------3-----------------------#2020-07-21">https://medium.com/analytics-vidhya/building-ml-model-to-predict-whether-the-cancer-is-benign-or-malignant-on-breast-cancer-wisconsin-a09b6c32e7b8?source=collection_archive---------3-----------------------#2020-07-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d3b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">做机器学习模型预测癌症是良性还是恶性的步骤包括:</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="a02c" class="jm jn hi ji b fi jo jp l jq jr"><strong class="ji hj">Step 1: Define Problem Statement<br/>Step 2: Data Source<br/>Step 3: Cleaning the Data<br/>Step 4: Data Analysis and Exploration</strong><br/>Step 5: Feature Selection<br/>Step 6: Data Modelling<br/>Step 7: Model Validation<br/>Step 8: Hyperparameter Tuning<br/>Step 9: Deployment</span><span id="df22" class="jm jn hi ji b fi js jp l jq jr">In this part 1, We will explore <strong class="ji hj">step 1 to 4</strong></span><span id="d029" class="jm jn hi ji b fi js jp l jq jr">We are using the Breast Cancer Wisconsin <a class="ae jt" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29" rel="noopener ugc nofollow" target="_blank"><strong class="ji hj">dataset</strong></a> available on UCI Machine Learning Repository.</span></pre><h2 id="aaf4" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">步骤1:定义问题陈述</h2><p id="8c31" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们的目标是确定哪些特征最有助于预测恶性或良性癌症，并对乳腺癌进行良性或恶性分类。</p><h2 id="aca8" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">步骤2:数据源</h2><p id="4711" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们已经使用了公开可用的数据集乳腺癌威斯康星州，并已从UCI机器学习库下载。资源库:<a class="ae jt" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29" rel="noopener ugc nofollow" target="_blank">https://archive . ics . UCI . edu/ml/datasets/Breast+Cancer+Wisconsin+% 28 diagnostic % 29</a>属性信息:</p><p id="cd15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.<em class="ks">身份证号</em></p><p id="90bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> 2。诊断(M =恶性，B =良性)</em></p><p id="9b5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">3–32为每个细胞核计算十个实值特征:</em></p><p id="4245" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> a .半径(从中心到圆周上各点的平均距离)</em></p><p id="1745" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> b .纹理(灰度值的标准偏差)</em></p><p id="cf62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> c .周长</em></p><p id="380e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> d)区域</em></p><p id="da7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> e)平滑度(半径长度的局部变化)</em></p><p id="4a4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> f .密实度(周长/面积— 1.0) </em></p><p id="28b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> g .凹度(轮廓凹陷部分的严重程度)</em></p><p id="04a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> h .凹点(轮廓的凹入部分的数量)</em></p><p id="d108" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">一、对称性j)分形维数(“海岸线近似”——1)</em></p><p id="372a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对每幅图像计算这些特征的平均值、标准误差和“最差”或最大值(三个最大值的平均值),得到30个特征。例如，字段3是平均半径，字段13是半径SE，字段23是最差半径。</p><h2 id="972c" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">步骤3:清理数据</h2><p id="7259" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">“数据质量是数据管理中最重要的问题之一，因为肮脏的数据通常会导致不准确的数据分析结果和错误的业务决策<strong class="ih hj">伊哈布·易勒雅斯(作者)</strong>。”</p><p id="94a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据分析师/科学家花费大量时间清理数据集，并将它们转换成他们可以使用的形式。据我个人估计，数据探索、清理和准备可能会占用项目总时间的70%。</p><p id="3a5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集中存在许多类型的错误，尽管一些最简单的错误包括不包含太多信息的列和重复的行。</p><p id="9f6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我将介绍以下内容:</p><ol class=""><li id="dffa" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">检查缺失或空数据点</li><li id="567a" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">删除数据集中不必要的列</li><li id="3d31" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">检查并识别包含重复记录的行</li></ol><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="8f0e" class="jm jn hi ji b fi jo jp l jq jr"><strong class="ji hj"># importing the libraries</strong><br/>import numpy as np <br/><strong class="ji hj"># data processing, CSV file I/O</strong><br/>import pandas as pd <br/><strong class="ji hj"># data visualization library</strong><br/>import seaborn as sns  <br/>import matplotlib.pyplot as plt<br/>import time</span></pre><p id="a0ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">导入数据集</strong></p><p id="aa1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我从我的Github帐户导入数据。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="e628" class="jm jn hi ji b fi jo jp l jq jr">dataset = pd.read_csv('<a class="ae jt" href="https://raw.githubusercontent.com/Muhd-Shahid/Breast-Cancer-Wisconsin/master/data_breast-cancer-wiscons.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/Muhd-Shahid/Breast-Cancer-Wisconsin/master/data_breast-cancer-wiscons.csv'</a>)</span></pre><p id="8a65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">检查我们的数据…快</strong></p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="93ad" class="jm jn hi ji b fi jo jp l jq jr">dataset.head()</span><span id="9298" class="jm jn hi ji b fi js jp l jq jr"><strong class="ji hj"># Get the dimensions of the data</strong><br/>print("Cancer data set dimensions : {}".format(dataset.shape))</span><span id="ae8a" class="jm jn hi ji b fi js jp l jq jr"><strong class="ji hj">Outcome: </strong><br/>Cancer data set dimensions : (569, 33)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lh"><img src="../Images/c6069834f15c7b4abc3c732eb60ff4da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtCTalmhRyQoQWprW7BffA.jpeg"/></div></div></figure><p id="a08d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">检查缺失或空数据点</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="4e3a" class="jm jn hi ji b fi jo jp l jq jr">#dataset.isnull().sum()<br/>#dataset.isna().sum()<br/><strong class="ji hj"># Get column data types and missing values in Columns</strong><br/>dataset.info()</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es lp"><img src="../Images/7ed2f973a0643c3022fc20fa4ea318a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*H_at8Q7ttcz7LqJ3PgMmbA.jpeg"/></div></figure><h2 id="321e" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">还让我们检查该列是否是唯一的</h2><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="3c0c" class="jm jn hi ji b fi jo jp l jq jr"><strong class="ji hj"># Get column names</strong><br/>column_names = dataset.columns <br/>for i in column_names:<br/>  print('{} is unique: {}'.format(i, dataset[i].is_unique))</span></pre><p id="8fe6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们发现只有<strong class="ih hj"> ID列</strong>是唯一的。</p><h2 id="4ada" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">删除数据集中不必要的列</h2><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="3234" class="jm jn hi ji b fi jo jp l jq jr"><strong class="ji hj"># Get column names</strong><br/>col = dataset.columns # .columns gives columns names in data <br/>print(col)</span><span id="70d1" class="jm jn hi ji b fi js jp l jq jr"><strong class="ji hj">Outcome:</strong><br/>Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',<br/>       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',<br/>       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',<br/>       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',<br/>       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',<br/>       'fractal_dimension_se', 'radius_worst', 'texture_worst',<br/>       'perimeter_worst', 'area_worst', 'smoothness_worst',<br/>       'compactness_worst', 'concavity_worst', 'concave points_worst',<br/>       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],<br/>      dtype='object')</span></pre><p id="2fdd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有4件事引起了我的注意</p><ol class=""><li id="859b" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">有一个<strong class="ih hj"> id </strong>不能用于分类</li><li id="4967" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated"><strong class="ih hj">诊断</strong>是我们的阶级标签</li><li id="82a8" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated"><strong class="ih hj">未命名:32 </strong>特性包含NaN，所以我们不需要它。</li><li id="751f" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">我对其他功能名称没有任何想法，实际上我不需要，因为机器学习太棒了:)</li></ol><p id="e1d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，放弃这些不必要的功能。但是，不要忘记这不是一个功能选择过程，我们只是试图理解数据。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="5854" class="jm jn hi ji b fi jo jp l jq jr"><strong class="ji hj"># y includes our labels and x includes our features</strong><br/>y = dataset.diagnosis # M or B <br/>list_drp = [‘Unnamed: 32’,’id’,’diagnosis’]<br/>x = dataset.drop(list_drp,axis = 1 )</span></pre><h2 id="a13e" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">检查并识别包含重复记录的行</h2><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="ba8b" class="jm jn hi ji b fi jo jp l jq jr"><strong class="ji hj"># calculate duplicates</strong><br/>dups = x.duplicated()<br/><strong class="ji hj"># report if there are any duplicates</strong><br/>print(dups.any())<br/><strong class="ji hj"># list all duplicate rows</strong><br/>print(x[dups])</span></pre><p id="0895" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">释义:</strong></p><p id="abae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据的每一行代表对一个患者的观察，列保存变量。共有33列569名患者。有31个数字列、1个ID列和1个分类类列。数据集中没有缺失和重复的值。</p><h2 id="0b76" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">步骤4:数据分析和探索</h2><p id="a4e4" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">这是一个弄清楚数据能告诉我们什么的过程，我们使用探索性数据分析(EDA)来寻找模式、关系或异常，以通知我们的后续分析。我们将寻找解决我们感兴趣的问题的模式、差异和其他特征，也将试图揭示不同变量之间的关系。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="3e1a" class="jm jn hi ji b fi jo jp l jq jr">ax = sns.countplot(y,label="Count")       # M = 212, B = 357<br/>B, M = y.value_counts()<br/>print('Number of Benign: ',B)<br/>print('Number of Malignant : ',M)<br/>ax.set_ylabel('Number of patients')<br/>bars = ax.patches<br/>half = int(len(bars)/2)<br/>left_bars = bars[:half]<br/>right_bars = bars[half:]<br/>for left, right in zip(left_bars, right_bars):<br/>    height_l = left.get_height()<br/>    height_r = right.get_height()<br/>    total = height_l + height_r<br/>    ax.text(left.get_x() + left.get_width()/2., height_l + 40, '{0:.0%}'.format(height_l/total), ha="center")<br/>    ax.text(right.get_x() + right.get_width()/2., height_r + 40, '{0:.0%}'.format(height_r/total), ha="center")</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es lq"><img src="../Images/ad8c562c0971d722b6dd340ba05dc4fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*elh2FIQg8soC9FTMLMlR3A.jpeg"/></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">阶级分布</figcaption></figure><h2 id="5c6c" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">检查基本统计数据</h2><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="8ee0" class="jm jn hi ji b fi jo jp l jq jr">x.describe()</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lv"><img src="../Images/2bafdbd1ccef9771efe7fc50d1c1cb75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rzyabhbMojWQhKKKCrw65w.jpeg"/></div></div></figure><p id="cb26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在有特性了，但是它们是什么意思或者我们需要知道这些特性的什么？答案是，我们不需要知道这些特征的含义，但是为了在我们的头脑中想象，我们应该知道像方差、标准差、样本数(计数)或最大最小值这样的东西。这种类型的信息有助于理解数据发生了什么。例如，我想到的问题是，面积平均特征的最大值是2500，平滑度平均特征的最大值是0.16340。因此，在可视化、特征选择、特征提取或分类之前，我们是否需要标准化或规范化？答案是肯定的。无论如何，让我们一步一步来，开始可视化过程。</p><h2 id="cb91" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">可视化数据开发</h2><p id="2a4c" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">为了可视化数据，我们将使用<a class="ae jt" href="https://seaborn.pydata.org/introduction.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> seaborn plots </strong> </a>。现实生活中我用的大多是<a class="ae jt" href="https://seaborn.pydata.org/generated/seaborn.violinplot.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> violinplot </strong> </a>和<a class="ae jt" href="https://seaborn.pydata.org/generated/seaborn.swarmplot.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> swarmplot </strong> </a>。不要忘记，我们不是在选择特征，我们是在尝试了解数据。</p><p id="43b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在绘制我们的数据之前，我们需要规范化或标准化。因为在图上观察到的特征值之间的差异非常大。我将特征分成3组，每组包括10个特征，以便更好地观察。</p><h2 id="e1be" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">使用violinplot探索数据</h2><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="5eb2" class="jm jn hi ji b fi jo jp l jq jr"><strong class="ji hj"># first ten features</strong><br/>data_dia = y<br/>data = x<br/><strong class="ji hj"># standardization of the data</strong><br/>data_n_2 = (data - data.mean()) / (data.std())</span><span id="d706" class="jm jn hi ji b fi js jp l jq jr">data = pd.concat([y,data_n_2.iloc[:,0:10]],axis=1)<br/>data = pd.melt(data,id_vars="diagnosis",<br/>                    var_name="features",<br/>                    value_name='value')<br/>plt.figure(figsize=(10,10))<br/>sns.violinplot(x="features", y="value", hue="diagnosis", data=data,split=True, inner="quart",palette ="Set2")<br/>plt.xticks(rotation=90)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es lw"><img src="../Images/1cc805c3655b72eba54bc094e533629e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*EZ3PvfokqPhnsx8jLk7hWA.png"/></div></figure><p id="04a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">释义:</strong></p><p id="bafa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们一起来解读上面的情节。例如，在texture_mean特征中，恶性和良性的中值看起来像是分开的，因此它有利于分类。然而，在分形维数均值特征中，恶性肿瘤和良性肿瘤的中值看起来不像是分开的，因此不能提供很好的分类信息。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="e7ea" class="jm jn hi ji b fi jo jp l jq jr"># Next ten features<br/>data = pd.concat([y,data_n_2.iloc[:,10:20]],axis=1)<br/>data = pd.melt(data,id_vars="diagnosis",<br/>                    var_name="features",<br/>                    value_name='value')<br/>plt.figure(figsize=(10,10))<br/>sns.violinplot(x="features", y="value", hue="diagnosis", data=data,split=True, inner="quart",palette ="Set2")<br/>plt.xticks(rotation=90)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es lx"><img src="../Images/f7a8ae05ed184d9c80f5c2988b9e72c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*OlqRay-t33O5Zp6p3CDUrw.png"/></div></figure><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="eeea" class="jm jn hi ji b fi jo jp l jq jr"># Last ten features<br/>data = pd.concat([y,data_n_2.iloc[:,20:31]],axis=1)<br/>data = pd.melt(data,id_vars="diagnosis",<br/>                    var_name="features",<br/>                    value_name='value')<br/>plt.figure(figsize=(10,10))<br/>sns.violinplot(x="features", y="value", hue="diagnosis", data=data,split=True, inner="quart",palette ="Set2")<br/>plt.xticks(rotation=90)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es ly"><img src="../Images/5f80f2134e34786d03ab33f740704952.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*Qx4OrDr1LyBuc1ajP_NwCw.png"/></div></figure><p id="d610" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们再解释一下上面的图，凹度_最差变量和凹点_最差变量看起来很相似，但是我们如何确定它们之间是否相关。(并不总是如此，但基本上，如果这些特性相互关联，我们可以删除其中一个)</p><p id="f71d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了更深入地比较两个特性，让我们用<a class="ae jt" href="https://seaborn.pydata.org/generated/seaborn.jointplot.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">连带</strong> </a>。在下面的联合情节中看看这个，它确实是相关的。Pearsonr值为相关值，1为最高。因此，0.86看起来足以说明它们是相关的。不要忘记，我们还没有选择功能，我们只是希望对它们有一个想法。</p><h2 id="9a00" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">使用联合绘图探索数据</h2><p id="46c2" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">使用联合图检查凹点_最差和凹点_最差之间的相关性。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="0e62" class="jm jn hi ji b fi jo jp l jq jr">import scipy.stats as stats<br/>sns.set(style="white",color_codes=True)<br/>jp=sns.jointplot(x.loc[:,'concavity_worst'], x.loc[:,'concave points_worst'], kind="regg",color="g")<br/>#jp=sns.jointplot(x.loc[:,'smoothness_se'], x.loc[:,'texture_se'], kind="regg",color="b")<br/>jp.annotate(stats.pearsonr)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es lz"><img src="../Images/cdf25fa43460cac4978877bffbcd4f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*b8I0OMb_z5DMQO1LN-N-zg.png"/></div></figure><p id="51fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用联合图检查凹点平均值和凹点平均值之间的相关性。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="f60d" class="jm jn hi ji b fi jo jp l jq jr">jp=sns.jointplot(x.loc[:,’concavity_mean’], x.loc[:,’concave points_mean’], kind=”regg”,color=”b”)<br/>jp.annotate(stats.pearsonr)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es ma"><img src="../Images/b9887da315b994eccb0164483c627438.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*sScp1Xh0aaH7d1QyGz5EzQ.png"/></div></figure><p id="d01b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用联合图检查凹度se和凹点se之间的相关性。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="c49e" class="jm jn hi ji b fi jo jp l jq jr">jp=sns.jointplot(x.loc[:,'concavity_se'], x.loc[:,'concave points_se'], kind="regg",color="r")<br/>jp.annotate(stats.pearsonr)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es ma"><img src="../Images/05360f873ecb3644c3cf25998d7d9f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*f7WkB_Z-It5Jg1u73IJAgA.png"/></div></figure><p id="e87c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">三个或更多变量比较呢？为此，我们可以使用配对图或配对网格图。而且看起来很酷:)我们还发现了一件事，半径最差，周长最差和面积最差是相关的，正如我们可以看到的对网格图。我们肯定会将这些发现用于特征选择。</p><h2 id="732e" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">使用pairplot探索数据</h2><p id="fe50" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">检查单个变量的分布和两个变量之间的关系。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="cf73" class="jm jn hi ji b fi jo jp l jq jr"># Function to calculate correlation coefficient between two arrays<br/>def corr(x, y, **kwargs):<br/>    <br/>    # Calculate the value<br/>    coef = np.corrcoef(x, y)[0][1]<br/>    # Make the label<br/>    label = r'$\rho$ = ' + str(round(coef, 2))<br/>    <br/>    # Add the label to the plot<br/>    ax = plt.gca()<br/>    ax.annotate(label, xy = (0.2, 0.95), size = 11, xycoords = ax.transAxes)<br/># First six features<br/>data = pd.concat([y,data_n_2.iloc[:,0:6]],axis=1)<br/>plt.figure(figsize=(10,10))<br/>grid=sns.pairplot(data=data,kind ="scatter",hue="diagnosis",palette="Set1")<br/># Map the plots to the locations<br/>#grid = grid.map_upper(plt.scatter, color = 'darkred')<br/>grid = grid.map_upper(corr)</span><span id="4d77" class="jm jn hi ji b fi js jp l jq jr"># First six features<br/>data = pd.concat([y,data_n_2.iloc[:,6:12]],axis=1)<br/>plt.figure(figsize=(10,10))<br/>grid=sns.pairplot(data=data,kind ="scatter",hue="diagnosis",palette="Set1")<br/># Map the plots to the locations<br/>#grid = grid.map_upper(plt.scatter, color = 'darkred')<br/>grid = grid.map_upper(corr)<br/>#grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')<br/>#grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred');</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es mb"><img src="../Images/77924b472b72a0235aa0a441548584a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*GkXtejNjyYDaoXwQl20_Ew.png"/></div></figure><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="7857" class="jm jn hi ji b fi jo jp l jq jr"># Next six features<br/>data = pd.concat([y,data_n_2.iloc[:,6:12]],axis=1)<br/>plt.figure(figsize=(10,10))<br/>grid=sns.pairplot(data=data,kind ="scatter",hue="diagnosis",palette="Set1")<br/># Map the plots to the locations<br/>#grid = grid.map_upper(plt.scatter, color = 'darkred')<br/>grid = grid.map_upper(corr)<br/>#grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')<br/>#grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred');</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es mc"><img src="../Images/343f4a0c52eb53871732aa66e5773360.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*qR_Y7Y5SO63CtUjdOy4THw.png"/></div></figure><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="8e26" class="jm jn hi ji b fi jo jp l jq jr"># Next six features<br/>data = pd.concat([y,data_n_2.iloc[:,12:18]],axis=1)<br/>plt.figure(figsize=(10,10))<br/>grid=sns.pairplot(data=data,kind ="scatter",hue="diagnosis",palette="Set1")<br/># Map the plots to the locations<br/>#grid = grid.map_upper(plt.scatter, color = 'darkred')<br/>grid = grid.map_upper(corr)<br/>#grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')<br/>#grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred');</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es md"><img src="../Images/f1c15088b5b2331a0aebbce4e3ae4127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*7K-x4YOFJN-OjvuKqaZhrA.png"/></div></figure><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="5b9d" class="jm jn hi ji b fi jo jp l jq jr"># Next six features<br/>data = pd.concat([y,data_n_2.iloc[:,18:24]],axis=1)<br/>plt.figure(figsize=(10,10))<br/>grid=sns.pairplot(data=data,kind =”scatter”,hue=”diagnosis”,palette=”Set1")<br/># Map the plots to the locations<br/>#grid = grid.map_upper(plt.scatter, color = ‘darkred’)<br/>grid = grid.map_upper(corr)<br/>#grid = grid.map_lower(sns.kdeplot, cmap = ‘Reds’)<br/>#grid = grid.map_diag(plt.hist, bins = 10, edgecolor = ‘k’, color = ‘darkred’);</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es me"><img src="../Images/299da9e154c30a956412f63ada023757.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*Unc7gIpENs4rhCiyYGfpmA.png"/></div></figure><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="0fc7" class="jm jn hi ji b fi jo jp l jq jr"># Next six features<br/>data = pd.concat([y,data_n_2.iloc[:,24:32]],axis=1)<br/>plt.figure(figsize=(10,10))<br/>grid=sns.pairplot(data=data,kind ="scatter",hue="diagnosis",palette="Set1")<br/># Map the plots to the locations<br/>#grid = grid.map_upper(plt.scatter, color = 'darkred')<br/>grid = grid.map_upper(corr)<br/>#grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')<br/>#grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred');</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es mf"><img src="../Images/5b1b70a17cc4e7bac57832dc7243c6b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*u6Ljw01oY8jNh8kRLVf_JA.png"/></div></figure><p id="da5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">至此，我们已经对数据做出了一些评论和发现。如果你喜欢我们所做的，我确信虫群图将帮助你更好地理解数据。</p><p id="c081" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在群体情节中，我会像小提琴情节那样做三个部分，以使情节看起来不那么复杂</p><h2 id="65b9" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">使用群集图探索数据</h2><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="d85a" class="jm jn hi ji b fi jo jp l jq jr"># First ten features<br/>sns.set(style="whitegrid", palette="Set1")<br/>data_dia = y<br/>data = x<br/>data_n_2 = (data - data.mean()) / (data.std())              # standardization<br/>data = pd.concat([y,data_n_2.iloc[:,0:10]],axis=1)<br/>data = pd.melt(data,id_vars="diagnosis",<br/>                    var_name="features",<br/>                    value_name='value')<br/>plt.figure(figsize=(10,10))<br/>tic = time.time()<br/>sns.swarmplot(x="features", y="value", hue="diagnosis", data=data)</span><span id="5103" class="jm jn hi ji b fi js jp l jq jr">plt.xticks(rotation=90)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es mg"><img src="../Images/2408959e1518713b67f99c61bfe104d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*m1ex9oOTlDvF5a5-AOI2QA.jpeg"/></div></figure><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="0dc9" class="jm jn hi ji b fi jo jp l jq jr"># Next ten features<br/>data = pd.concat([y,data_n_2.iloc[:,10:20]],axis=1)<br/>data = pd.melt(data,id_vars="diagnosis",<br/>                    var_name="features",<br/>                    value_name='value')<br/>plt.figure(figsize=(10,10))<br/>sns.swarmplot(x="features", y="value", hue="diagnosis", data=data)<br/>plt.xticks(rotation=90)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es mh"><img src="../Images/139c0640738f7b44251d9fdbae0b1a77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*qmoNU7F3oeQBxGohqfO_oQ.jpeg"/></div></figure><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="16f1" class="jm jn hi ji b fi jo jp l jq jr"># Next ten features<br/>data = pd.concat([y,data_n_2.iloc[:,20:31]],axis=1)<br/>data = pd.melt(data,id_vars="diagnosis",<br/>                    var_name="features",<br/>                    value_name='value')<br/>plt.figure(figsize=(10,10))<br/>sns.swarmplot(x="features", y="value", hue="diagnosis", data=data)<br/>toc = time.time()<br/>plt.xticks(rotation=90)<br/>print("swarm plot time: ", toc-tic ," s")</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es mi"><img src="../Images/5f88948f91bbd2d9c826de4d8d96b09c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*WB_HPNIyPZ2xM6zpx5YmJQ.jpeg"/></div></figure><p id="fef3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们看起来很酷吧。你可以更清楚地看到差异。让我问你一个问题，在这三个情节中，哪一个特征在分类方面看起来更清楚。在我看来，上一个蜂群中最差的区域看起来像是恶性和良性没有完全分开，而是大部分分开了。然而，群图2中的smooth _ se看起来像是恶性和良性混合，因此在使用该特征时很难分类。</p><p id="c148" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们想要观察特征之间的所有相关性呢？是的，你是对的。答案是<a class="ae jt" href="https://seaborn.pydata.org/generated/seaborn.heatmap.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">热图</strong> </a>那是古老却强大的剧情方法。</p><h2 id="7aca" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">使用热图浏览数据</h2><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="f904" class="jm jn hi ji b fi jo jp l jq jr">#correlation map<br/>f,ax = plt.subplots(figsize=(18, 18))<br/>sns.heatmap(x.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es mj"><img src="../Images/c2ffb6900f5963e122d83493d70b624b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*Yf35LY7bczMWWhcYuh6wtQ.png"/></div></figure><p id="cc87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">释义:</strong></p><p id="2231" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从地图热图中可以看出，半径平均值、周长平均值和面积平均值相互关联，因此我们将仅使用面积平均值。如果你问我如何选择area_mean作为要使用的特征，那么实际上没有正确的答案，我只是看着群体图，area_mean对我来说看起来很清楚，但我们不能在不尝试的情况下在其他相关特征中进行精确的分离。因此，让我们寻找其他相关的特征，并期待与随机森林分类器的准确性。</p><p id="ecfa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">紧密度均值、凹度均值和凹点均值是相互关联的。所以我只选择凹度_均值。除此之外，半径se、周长se和面积se是相关的，我只使用面积se。半径_最差、周长_最差和面积_最差是相关的，所以我使用面积_最差。紧致_最差，凹度_最差和凹点_最差所以我用凹度_最差。紧致性_se，凹度_se和凹点_se所以我用凹度_se。texture_mean和texture_worst是相关的，我使用texture_mean。area_worst和area_mean是相关的，我用area_mean。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="b4fd" class="jm jn hi ji b fi jo jp l jq jr">drop_list1 = ['perimeter_mean','radius_mean','compactness_mean','concave points_mean','radius_se','perimeter_se','radius_worst','perimeter_worst','compactness_worst','concave points_worst','compactness_se','concave points_se','texture_worst','area_worst']<br/>x_1 = x.drop(drop_list1,axis = 1 )        </span></pre><p id="97d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">删除相关特征后，如下面的相关矩阵所示，不再有相关特征。实际上，我知道，你也看到了，凹度均值和凹度最差之间的相关值是0.9，但是让我们一起看看如果我们不放弃它会发生什么。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="caca" class="jm jn hi ji b fi jo jp l jq jr">#correlation map<br/>f,ax = plt.subplots(figsize=(14, 14))<br/>sns.heatmap(x_1.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)</span></pre><figure class="jd je jf jg fd li er es paragraph-image"><div class="er es mk"><img src="../Images/443ee1fad7e38d22057b7f6b45bcba71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*yN548AgV2LCQRhIE_xddzQ.png"/></div></figure><p id="3a00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结束注释</strong></p><p id="bbe0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如前所述，投入到数据探索中的质量和努力区分了好模型和坏模型。</p><p id="7d7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就结束了我们的<strong class="ih hj">第1部分</strong>关于问题陈述到数据分析和探究。本<strong class="ih hj">第1部分</strong>的目的是为数据科学中一个极其重要的过程提供一个深入的逐步指南。</p><p id="ed1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就我个人而言，我很喜欢写这篇文章，也很想从你的反馈中学习。你觉得这个<strong class="ih hj">第1部分</strong>有用吗？我将感谢你的建议/反馈。请随时通过下面的评论提出你的问题。</p><h2 id="185b" class="jm jn hi bd ju jv jw jx jy jz ka kb kc iq kd ke kf iu kg kh ki iy kj kk kl km bi translated">我们将在第2部分的<a class="ae jt" rel="noopener" href="/@shahid_dhn/building-ml-model-to-predict-whether-the-cancer-is-benign-or-malignant-on-breast-cancer-wisconsin-b8249b55fc62">中探讨第5步:特征选择</a></h2><p id="c3da" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">敬请期待！</p><p id="fe5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文使用的所有代码和数据集都可以从我的<a class="ae jt" href="https://github.com/Muhd-Shahid/Breast-Cancer-Wisconsin" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> GitHub </strong> </a>中访问。</p><p id="834f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该代码也可作为一个<a class="ae jt" href="https://github.com/Muhd-Shahid/Breast-Cancer-Wisconsin/blob/master/BCW_Exploratory_Data_Analysis_Part%201.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Jupyter笔记本</strong> </a>。<a class="ae jt" href="https://www.kaggle.com/code/itsmohammadshahid/classification-of-breast-cancer-part-1-eda" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="ks"/></strong></a></p></div></div>    
</body>
</html>