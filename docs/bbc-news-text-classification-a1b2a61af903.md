# BBC 新闻文本分类

> 原文：<https://medium.com/analytics-vidhya/bbc-news-text-classification-a1b2a61af903?source=collection_archive---------2----------------------->

![](img/e2115d21410edea1527a9691e72efa8b.png)

如今，互联网上有很多来源，产生了大量的每日新闻。此外，用户对信息的需求一直在不断增长，因此对新闻进行分类以允许用户快速有效地访问感兴趣的信息至关重要。通过这种方式，用于自动新闻分类的机器学习模型可以用于识别未跟踪新闻的主题和/或基于用户先前的兴趣提出个人建议。因此，我们的目标是建立模型，以新闻标题和简短描述为输入，输出新闻类别。

新闻文章通常有多个主题标签。例如，一篇关于足球俱乐部所有权转让的文章可能被标在体育、商业和世界新闻下。人类可以识别并正确提供一篇文章的多个相关标签，但机器学习系统能得到类似的结果吗？

文本分类数据集用于根据内容对自然语言文本进行分类。例如，考虑按主题对新闻文章进行分类，或者根据积极或消极的回应对书评进行分类。文本分类还有助于语言检测、组织客户反馈和欺诈检测。

虽然手动完成这一过程很耗时，但可以通过机器学习模型实现自动化。

类别分类，对于新闻来说，是一个多标签的文本分类问题。目标是为一篇新闻文章分配一个或多个类别。多标签文本分类中的标准技术是使用一组二元分类器。

# **了解数据**

我们从 Kaggle 收到了 2225 个数据，总共包括 5 个类别。我们想要确定的五个类别是体育、商业、政治、科技和娱乐。

![](img/fb5870fa342a41232e28f4b15a53be14.png)

# **数据清洗和预处理**

对你的文本进行预处理简单地说就是把你的文本变成一种对你的任务来说 ***可预测*** 和 ***可分析*** 的形式。这里的任务是方法和领域的结合。我们的任务是用 TF-IDF (approach)从 Kaggle 数据集(领域)中抽取热门关键词。

## 用小写字体书写

尽管经常被忽视，但是将文本数据全部小写是最简单也是最有效的文本预处理方式之一。它适用于大多数文本挖掘和 NLP 问题，在数据集不是很大的情况下会有所帮助，并对预期输出的一致性有很大帮助。

![](img/a843f670d6dc48bb22274c5d8ba27bd0.png)

## 停止单词删除

停用词是一种语言中的一组常用词。英语中停用词的例子有“a”、“the”、“is”、“are”等。使用停用词背后的直觉是，通过从文本中移除低信息量的词，我们可以专注于重要的词。

![](img/a9fa904f4628fa1840ae90ae25f052f6.png)

## 词汇化

表面上的词汇化与词干化非常相似，目标是去除词形变化并将单词映射到其词根形式。唯一的区别是，术语化试图以正确的方式来实现它。它不只是砍掉一些东西，它实际上是将单词转化为实际的词根。

![](img/810d440ecf4177396146ce355a46533e.png)

删除重复数据后，我的数据集的行数减少到了 2126。

![](img/ad6ce388e3b3ac9279cdee4cf5e6ff26.png)

# **探索性数据分析(EDA)**

下图显示了我们数据集中每个类别的文章数量。

![](img/6d5652c497d249376e807905ab463265.png)

下图显示了卡方分析，以找出特征(词的重要性)和标签(新闻类别)之间的相关性。

![](img/5b6ed205faccb8040b9dd45a81ab13c2.png)

# **模型分析**

文本需要转换成向量，以便算法能够做出预测。在这种情况下，将使用术语频率-逆文档频率(TFIDF)权重来评估单词对于文档集合中的文档有多重要。

删除标点符号、小写字母、停用词和词汇化后，单词的重要性根据其出现频率来确定。

原始数据分为特征(X)和目标(y)，然后分为训练集(80%)和测试集(20%)。因此，算法将在一组数据上训练，并在一组完全不同的数据上测试(算法以前没有见过)。

我对集合模型使用了 5 种算法，如随机森林、逻辑回归、多项朴素贝叶斯、线性 SVC 和逻辑回归 GridSearchCV。我比较了测试准确度分数、精确度、回忆和 F1 分数。

![](img/4ca92a698f8265e17b96a33026aab9a0.png)

对于这个数据集，我发现与其他分类器相比，线性 SVC 分类器表现出最好的性能。

# **结论**

最后，当我们看测试准确性分数时，我们可以说线性 SVC 将为我们带来最准确的结果。

用于网页抓取和数据预处理的 GitHub 库在这里是。

谢谢你的时间和阅读我的文章。如果您有任何问题或想分享您的意见，请随时联系我。