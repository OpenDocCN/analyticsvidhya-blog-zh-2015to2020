<html>
<head>
<title>Self-supervised Representation Learning in Computer Vision — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉中的自我监督表示学习——第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/self-supervised-representation-learning-in-computer-vision-part-1-215af945d23a?source=collection_archive---------13-----------------------#2020-07-04">https://medium.com/analytics-vidhya/self-supervised-representation-learning-in-computer-vision-part-1-215af945d23a?source=collection_archive---------13-----------------------#2020-07-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a0ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">计算机视觉领域(使用深度学习)的任何最新进展都源于半监督学习技术的兴起，这更典型地归因于自然语言处理。</p><p id="4f00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你看看过去一年左右表征学习领域的最重要的发展，许多杰出的作品来自于在半监督环境下的表演(MoCo，西姆CLR v1 &amp; v2，BYOL)。</p><p id="a24e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一系列文章中，我将讨论以下主题:</p><p id="02d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第一部</strong></p><ol class=""><li id="a973" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated">什么是表征学习？</li><li id="8456" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc jr js jt ju bi translated">走向自我监督学习</li></ol><p id="8521" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二部</strong></p><ol class=""><li id="2110" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated">动量对比(MoCo)</li><li id="5ca3" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc jr js jt ju bi translated">视觉表征的对比学习</li></ol><p id="6bf3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第三部分</strong></p><ol class=""><li id="e48f" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated">大型自我监督模型是强大的半监督学习器(SimCLR v2)</li><li id="4260" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc jr js jt ju bi translated">引导你自己的潜能(BYOL)</li></ol><p id="e047" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一篇文章将是自我监督表示学习的一般介绍，后续文章将集中在执行半监督学习的SotA方法上。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h1 id="0b31" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">表象学习:</strong></h1><figure class="lg lh li lj fd lk er es paragraph-image"><div class="er es lf"><img src="../Images/faeaa84825b0e112f538c3edad9ac466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*a-RiC3DUeHs1_f4-UwUMMQ.png"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated"><strong class="bd kj">表示:</strong>输入图像(224×224×3)通过特征提取器(通常是经过训练的CNN网络),该特征提取器将图像的空间特征非线性地变换到512维的向量空间。</figcaption></figure><p id="fbba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">计算机视觉中的表示</strong>是从原始数据中提取的特征。特征提取包括将原始数据(通常具有较大维度)处理到向量空间(具有较低维度)，捕获代表数据的潜在时空信息<strong class="ih hj">。历史上，系统使用一系列手工设计的过滤器来提取这些信息。</strong></p><p id="bac0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di"> R </span>这通常包括训练一个卷积神经网络(CNN ),让<em class="lr">学习</em>,以发现符号化数据中隐藏表示的最佳方式。</p><p id="2cd8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">表征学习的经典范式被归入迁移学习方法的一部分。<strong class="ih hj">迁移学习</strong>是一个过程，在这个过程中，一个模型在一个任务上被训练，然后通过一些额外的训练，被重新用于另一个任务。</p><p id="924f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们想要在由20个不同类组成的特定数据集上执行图像分类(其中每个类代表一种不同的汽车)。迁移学习的经典方法包括:</p><ol class=""><li id="d54d" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated"><strong class="ih hj">预培训</strong></li></ol><p id="7684" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在包含大量标签和各种类的大型数据集上训练一个卷积神经网络(比如ResNet-50)。ImageNet(由跨越1000个类别的120万幅图像组成)通常被用作执行预训练的标准。</p><p id="5061" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这通常是表示学习发生的地方，因为CNN层学习理解将原始输入转换到低维向量空间的最佳方式。然后，学习到的表示被传递到(一个或多个)完全连接的层上，通常以Softmax(预测类别标签)结束。梯度下降的魔力允许CNN学习分类这个大数据集的任务的最佳表示。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/50fe7d66ee628fb8f56d19da1b9d8a71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pUgXKnjOURms44WQpnf2LA.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">34层剩余网络。<a class="ae lx" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="9dba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">微调</strong></p><p id="95e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一阶段包括通过使用感兴趣的数据集重新训练CNN，使用学习到的表示来执行<em class="lr">任务特定的适应</em>。在我们的特殊情况下，这将是包含20种不同类别汽车的数据集。</p><p id="ce98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过移除表示层之后的最终层(来自CNN的最后一层的输出)，将一组新的层附加到该基础网络，并在当前数据集上重新训练，对所学习的表示进行微调以适应特定任务。</p><p id="d741" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自<a class="ae lx" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank"> Krizhevsky，Alex等人(2012) </a>以来，这种范式已被用于实现几乎所有计算机视觉任务的SotA结果。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h1 id="bd8a" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">自我监督学习:</strong></h1><p id="170d" class="pw-post-body-paragraph if ig hi ih b ii ly ik il im lz io ip iq ma is it iu mb iw ix iy mc ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di">大多数基于CNN的计算机视觉目标(以及一般的深度学习)面临的一个主要问题是它们的数据效率极低。你经常需要大量的<strong class="ih hj">标签数据</strong>来获得好的结果。在许多情况下，大量的标记会很麻烦，因此迁移学习被用作克服这一点的解决方案。</span></p><figure class="lg lh li lj fd lk er es paragraph-image"><div class="er es md"><img src="../Images/b85103c9c7bfd654fc8a4b2fa21cfd5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*PF5XJNRx63cNvTC0"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">强制性模因。</figcaption></figure><p id="4002" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">但是，如果有一种更有效的方法来解决没有大型标签数据存储库的问题呢？</strong></p><p id="5a0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果有办法:</p><p id="aa3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.有大量的<strong class="ih hj">未标记图像</strong>可用于学习隐藏表示</p><p id="9dfb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.然后可以在一个更小的带标签的数据集上进行微调。</p><p id="eca5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将<strong class="ih hj">在很大程度上缓解数据低效</strong>，因为没有为学习特定任务而标记大量数据的开销。</p><p id="fd91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">自我监督学习</strong>背后的想法来自NLP的世界，在那里一个<strong class="ih hj">大型无标签语料库</strong>被用来识别该语言所有标记的潜在表示(通过<strong class="ih hj">表示学习</strong>)。这就产生了所谓的“语言模型”。<em class="lr">任务特定的训练</em>然后用<strong class="ih hj">标记的数据集完成(使用语言模型作为基本特征提取器)。</strong>这通常比用于学习语言模型的语料库小得多，并且用于生成特定于任务的结果(如情感分析等)。).</p><blockquote class="me mf mg"><p id="0e58" class="if ig lr ih b ii ij ik il im in io ip mh ir is it mi iv iw ix mj iz ja jb jc hb bi translated">我们是否可以为视觉数据创建“语言模型”的解决方案在于我们如何人为增加计算机视觉中迁移学习的经典范式的训练集— <strong class="ih hj">图像增强</strong>。</p></blockquote></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h1 id="5710" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">图像增强</strong></h1><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mk"><img src="../Images/eb71ba0be11ab6eb4ede4807391d29be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XNh2Mr-qGG2gHxjUIA2vXw.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">使用PyTorch转换器的一系列图像转换的输出给了我这些增强的图像。这通常是用于训练任何图像分类器的标准流水线的一部分。</figcaption></figure><p id="b85d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过执行一种或多种图像处理技术，例如随机移位、旋转、随机剪辑、移位、剪切、颜色抖动、高斯模糊等，图像增强通常被用作数据集增强的人工形式。</p><p id="c9dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它主要有两个功能:</p><ol class=""><li id="23c4" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated">增加训练数据集的大小，而无需收集和标记更多数据</li><li id="a0d6" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc jr js jt ju bi translated">通过对同一图像执行一系列不同的变换以给出不同的“视角”,减少了训练偏差并增加了数据集中的可变性。</li></ol><p id="514e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在自我监督学习中，我们利用图像增强引入数据集的“可变性”。基本思想是来自同一图像的两个增强应该具有相似的特征表示，来自两个不同图像的增强应该具有不相似的特征表示。</p><blockquote class="me mf mg"><p id="0f18" class="if ig lr ih b ii ij ik il im in io ip mh ir is it mi iv iw ix mj iz ja jb jc hb bi translated">你几乎可以直观地认为，这是试图训练一个系统，其中来自同一图像的增强的特征表示相互“吸引”,来自不同图像的增强的特征表示相互“排斥”。</p></blockquote><p id="cf05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，你可以想象，这个问题定义的损失函数将包含某些相似性的最小化(也可能是其他相似性的最大化)。但是我们将把这方面的细节留给后续的文章。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><p id="0174" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本系列的下一部分将讨论允许我们执行自我监督学习的特定架构和设计。</p><p id="aa47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望这篇文章有所帮助！</p><p id="430d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你在这篇文章中注意到任何问题/错误，请随时在Twitter上联系我，我会做出必要的更正。欢迎大家提出建议！</p></div></div>    
</body>
</html>