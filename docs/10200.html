<html>
<head>
<title>CUDA — Memory Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CUDA —内存模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cuda-memory-model-823f02cef0bf?source=collection_archive---------2-----------------------#2020-10-09">https://medium.com/analytics-vidhya/cuda-memory-model-823f02cef0bf?source=collection_archive---------2-----------------------#2020-10-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/cb076c9e83a555df54dad51babd0430a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UNx603Eys8VA3wscIDwaSw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来自<a class="ae iu" href="https://www.pexels.com/photo/analogue-business-close-up-computer-117729/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a></figcaption></figure><p id="7f64" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇文章详细介绍了 CUDA 内存模型，是 CUDA 系列的第四部分。</p><p id="6d58" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第 1 部分— <a class="ae iu" rel="noopener" href="/analytics-vidhya/cuda-compute-unified-device-architecture-part-1-8f9ff3179440">异构计算</a></p><p id="e115" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第 2 部分— <a class="ae iu" rel="noopener" href="/analytics-vidhya/cuda-compute-unified-device-architecture-part-2-f3841c25375e"> CUDA 内核及其发布参数</a></p><p id="fc2c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第 3 部分— <a class="ae iu" rel="noopener" href="/analytics-vidhya/cuda-compute-unified-device-architecture-part-3-f52476576d6d"> GPU 设备架构</a></p><h1 id="e25c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">分级存储器体系</h1><p id="f7a6" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">在计算机应用程序的执行过程中，指令更经常地倾向于在短时间内重复访问同一组存储单元。这种现象被称为局域性原理。有两种类型的局部性—时间局部性和空间局部性。</p><p id="a9a8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">时间局部性—在相对较短的时间内重复访问同一内存位置的趋势。</p><p id="6705" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">空间局部性—访问与当前访问位置相对接近的内存位置的趋势。</p><p id="cebe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于这一原理的存在，任何计算机体系结构都将具有存储器的层次结构，从而优化指令的执行。随着存储器与处理器的距离增加，从该存储器访问的数据需要更多的时钟周期来处理。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/cbac28abf201e904d9bdac70dc55939c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wx18pwQvSSFzga0eX8h4FA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">GPU 内存层次结构</figcaption></figure><p id="9e82" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在 NVIDIA GPU 的情况下，共享内存、L1 缓存和常量内存缓存位于流式多处理器模块内。因此，它们比 L2 缓存和 GPU RAM 更快。</p><h1 id="4f20" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">GPU 执行模型</h1><p id="47bb" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">正如本系列第 1 部分所讨论的，GPU 是一个协处理器。GPU 内核启动，数据初始化和传输从 CPU 开始。下面举个例子进一步讨论。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="efe2" class="lg ju hi lc b fi lh li l lj lk">__global__ void array_sum (int *d_a, int *d_b, int *d_c, int size)<br/>{<br/>    int gid = blockDim.x * blockIdx.x + threadIdx.x;<br/>    if (gid &lt; size)<br/>        c[gid] = a[gid] + b[gid];</span><span id="942a" class="lg ju hi lc b fi ll li l lj lk">}</span></pre><p id="0cea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的内核代码中，我们接收两个数组<em class="lm"> a </em>和<em class="lm"> b </em>作为输入，并在第三个数组<em class="lm"> c </em>中累加这两个数组的和。<em class="lm">大小</em>是每个数组的大小。全球指数(<em class="lm"> gid </em>)的计算在这篇<a class="ae iu" rel="noopener" href="/analytics-vidhya/cuda-compute-unified-device-architecture-part-2-f3841c25375e">文章</a>中详细阐述。</p><p id="9b52" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了在 GPU 中处理上面的内核，数组 a、b、c 要在 CPU 中初始化，并转移到 GPU 中。因此，在 CPU 中执行的主要函数应该如下所示。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="ced4" class="lg ju hi lc b fi lh li l lj lk">int main()<br/>{<br/>    int size = 1 &lt;&lt; 20;<br/>    int block_size = 128;<br/>    int NO_BYTES = sizeof(int) * size;</span><span id="84e4" class="lg ju hi lc b fi ll li l lj lk"> //Host memory allocation<br/>    int *h_a, *h_b, *h_c;<br/>    h_a = (int *)malloc(NO_BYTES);<br/>    h_b = (int *)malloc(NO_BYTES);<br/>    h_c = (int *)malloc(NO_BYTES);</span><span id="16be" class="lg ju hi lc b fi ll li l lj lk">//Host memory initialization<br/>    for(int i = 0; i &lt; size; i++)<br/>    {<br/>        h_a[i] = 10;<br/>        h_b[i] = 20;<br/>    }<br/>    memset(h_c, 0, NO_BYTES);</span><span id="69a4" class="lg ju hi lc b fi ll li l lj lk">//Device memory initialization<br/>    int *d_a, *d_b, *d_c;<br/>    cudaMalloc((int **)&amp;d_a, NO_BYTES);<br/>    cudaMalloc((int **)&amp;d_b, NO_BYTES);<br/>    cudaMalloc((int **)&amp;d_c, NO_BYTES);</span><span id="21d6" class="lg ju hi lc b fi ll li l lj lk">//Host to device input data transfer<br/>    cudaMemcpy(d_a, h_a, NO_BYTES, cudaMemcpyHostToDevice);<br/>    cudaMemcpy(d_b, h_b, NO_BYTES, cudaMemcpyHostToDevice);</span><span id="bc47" class="lg ju hi lc b fi ll li l lj lk">//Kernel launch<br/>    dim3 block(block_size);<br/>    dim3 grid(size/block.x);</span><span id="a7ff" class="lg ju hi lc b fi ll li l lj lk">    array_sum &lt;&lt;&lt; grid, block &gt;&gt;&gt; (d_a, d_b, d_c, size);<br/>    cudaDeviceSynchronize();</span><span id="8c24" class="lg ju hi lc b fi ll li l lj lk">//Device to host output data transfer<br/>    cudaMemcpy(d_b, h_b, NO_BYTES, cudaMemcpyDeviceToHost);</span><span id="3d50" class="lg ju hi lc b fi ll li l lj lk">    free(h_a);<br/>    free(h_a);<br/>    free(h_a);</span><span id="f7d4" class="lg ju hi lc b fi ll li l lj lk">    cudaFree(d_a);<br/>    cudaFree(d_b);<br/>    cudaFree(d_c);</span></pre><p id="95b1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> malloc </strong> —在主机内存中分配内存</p><p id="8dc9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> cudaMalloc </strong> —在设备内存中分配内存</p><p id="3b32" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">cudamemacpy</strong>—将数据从主机复制到设备或从设备复制到主机。cudaMemcpyHostToDevice 和 cudaMemcpyDeviceToHost 标志用于指示数据传输的方向。</p><p id="b36a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">释放</strong> —恢复分配的主机内存</p><p id="e7ba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> cudaFree </strong> —恢复分配的设备内存</p><h1 id="8490" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">内存分配类型</h1><p id="5ef6" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">CUDA 中有四种类型的内存分配。</p><ol class=""><li id="c248" class="ln lo hi ix b iy iz jc jd jg lp jk lq jo lr js ls lt lu lv bi translated">可分页内存</li><li id="b8b0" class="ln lo hi ix b iy lw jc lx jg ly jk lz jo ma js ls lt lu lv bi translated">固定存储器</li><li id="7f24" class="ln lo hi ix b iy lw jc lx jg ly jk lz jo ma js ls lt lu lv bi translated">映射存储器</li><li id="4c4a" class="ln lo hi ix b iy lw jc lx jg ly jk lz jo ma js ls lt lu lv bi translated">统一存储器</li></ol><h1 id="d72e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">可分页内存</strong></h1><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/992e8820dd09ca7075bc31d0a521725b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V3yMvguRMaHKYNH9zv2Jwg.jpeg"/></div></div></figure><p id="a003" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">默认情况下，主机中分配的内存是可分页内存。该存储器位置的数据可由主机使用。为了将这些数据传输到设备，CUDA 运行时将这些内存复制到一个临时固定内存中，然后传输到设备内存中。因此，有两次内存传输。因此，这种类型的内存分配和传输很慢。</p><p id="cd29" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">主机分配语法:</strong></p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="7203" class="lg ju hi lc b fi lh li l lj lk">int *h_a, *h_b, *h_c;<br/>h_a = (int *)malloc(NO_BYTES);<br/>h_b = (int *)malloc(NO_BYTES);<br/>h_c = (int *)malloc(NO_BYTES);<br/><br/>for (int i = 0; i &lt; size; i++)<br/>{<br/>h_a[i] = 10;<br/>h_b[i] = 20;<br/>}<br/><br/>memset(h_c, 0, NO_BYTES);</span></pre><p id="42ce" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">设备分配语法:</strong></p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="6ebe" class="lg ju hi lc b fi lh li l lj lk">int *d_a, *d_b, *d_c;<br/>cudaMalloc((int **)&amp;d_a, NO_BYTES);<br/>cudaMalloc((int **)&amp;d_b, NO_BYTES);<br/>cudaMalloc((int **)&amp;d_c, NO_BYTES);<br/><br/>cudaMemcpy(d_a, h_a, NO_BYTES, cudaMemcpyHostToDevice);<br/>cudaMemcpy(d_b, h_b, NO_BYTES, cudaMemcpyHostToDevice);</span></pre><h1 id="a90d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">固定内存</strong></h1><p id="33d8" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">数据可以直接在主机固定存储器中初始化。通过这样做，我们可以避免在可分页内存中的两次数据传输。这将加快进程，但会牺牲主机性能。当数据在固定存储器中初始化时，用于主机处理的存储器可用性降低。</p><p id="aae0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">主机分配语法:</strong></p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="4586" class="lg ju hi lc b fi lh li l lj lk">int *h_a1, *h_b1, *h_c1;<br/>cudaMallocHost((int **)&amp;h_a1, NO_BYTES);<br/>cudaMallocHost((int **)&amp;h_b1, NO_BYTES);<br/>cudaMallocHost((int **)&amp;h_c1, NO_BYTES);</span><span id="04b0" class="lg ju hi lc b fi ll li l lj lk">for (int i = 0; i &lt; size; i++)<br/>{<br/> h_a1[i] = 10;<br/> h_b1[i] = 20;<br/>}</span><span id="05ac" class="lg ju hi lc b fi ll li l lj lk">memset(h_c1, 0, NO_BYTES);</span></pre><p id="4766" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">设备分配语法:</strong></p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="96aa" class="lg ju hi lc b fi lh li l lj lk">int *d_a1, *d_b1, *d_c1;<br/>cudaMalloc((int **)&amp;d_a1, NO_BYTES);<br/>cudaMalloc((int **)&amp;d_b1, NO_BYTES);<br/>cudaMalloc((int **)&amp;d_c1, NO_BYTES);</span><span id="bea6" class="lg ju hi lc b fi ll li l lj lk">cudaMemcpy(d_a1, h_a1, NO_BYTES, cudaMemcpyHostToDevice);<br/>cudaMemcpy(d_b1, h_b1, NO_BYTES, cudaMemcpyHostToDevice);</span></pre><h1 id="fad2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">映射存储器(零拷贝存储器)</strong></h1><p id="6af7" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">零拷贝内存是映射到设备地址空间的固定内存。主机和设备都可以直接访问这个存储器。</p><p id="6d6f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">优点</strong>:</p><ol class=""><li id="ba4d" class="ln lo hi ix b iy iz jc jd jg lp jk lq jo lr js ls lt lu lv bi translated">当设备内存不足时，可以利用主机内存。</li><li id="ac35" class="ln lo hi ix b iy lw jc lx jg ly jk lz jo ma js ls lt lu lv bi translated">可以避免主机和设备之间的显式数据传输。</li><li id="f8b6" class="ln lo hi ix b iy lw jc lx jg ly jk lz jo ma js ls lt lu lv bi translated">提高 PCIe 传输速率</li></ol><p id="a0f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">缺点</strong>:</p><ol class=""><li id="5575" class="ln lo hi ix b iy iz jc jd jg lp jk lq jo lr js ls lt lu lv bi translated">因为它被映射到设备地址空间，所以数据不会被复制到设备存储器中。在执行过程中会发生传输，这将大大增加处理时间。</li></ol><p id="6fae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">主机分配语法:</strong></p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="6b71" class="lg ju hi lc b fi lh li l lj lk">int *h_a2, *h_b2, *h_c2;<br/>cudaHostAlloc((int **)&amp;h_a2, NO_BYTES, cudaHostAllocMapped);<br/>cudaHostAlloc((int **)&amp;h_b2, NO_BYTES, cudaHostAllocMapped);<br/>cudaHostAlloc((int **)&amp;h_c2, NO_BYTES, cudaHostAllocMapped);</span><span id="793c" class="lg ju hi lc b fi ll li l lj lk">for (int i = 0; i &lt; size; i++)<br/>{<br/> h_a2[i] = 10;<br/> h_b2[i] = 20;<br/>}</span><span id="f00e" class="lg ju hi lc b fi ll li l lj lk">memset(h_c2, 0, NO_BYTES);</span></pre><p id="a9b8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">设备分配语法:</strong></p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="f046" class="lg ju hi lc b fi lh li l lj lk">int *d_a2, *d_b2, *d_c2;<br/>//<br/>cudaHostGetDevicePointer((int **)&amp;d_a2, (int *)h_a2, 0);<br/>cudaHostGetDevicePointer((int **)&amp;d_b2, (int *)h_b2, 0);<br/>cudaHostGetDevicePointer((int **)&amp;d_c2, (int *)h_c2, 0);</span></pre><p id="01cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里我们使用<em class="lm">cudaHostGetDevicePointer</em>函数来获取设备指针，而不是为设备分配新的内存。</p><h1 id="fb5b" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">统一内存</strong></h1><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/76098abcc0148c246d1ec37e56a0a02e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W1nXPC7BTmyNG83m4jTwpw.jpeg"/></div></div></figure><p id="3921" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这将创建一个托管内存池，其中来自该内存池的每个分配都可以在主机和设备上使用相同的地址或指针进行访问。底层系统将数据迁移到主机和设备。</p><p id="87ab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">优点</strong> —无需为设备显式分配和回收内存。这降低了编程的复杂性。</p><p id="6b31" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">缺点</strong> —为内存管理添加了额外的指令。</p><p id="56b9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">语法</strong>:</p><p id="ddc1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于这种类型是统一的，我们只有 1 个初始化。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="19aa" class="lg ju hi lc b fi lh li l lj lk">// int *a, *b, *c;<br/>//<br/>// cudaMallocManaged((int **)&amp;a, NO_BYTES);<br/>// cudaMallocManaged((int **)&amp;b, NO_BYTES);<br/>// cudaMallocManaged((int **)&amp;c, NO_BYTES);<br/>//<br/>// for (int i = 0; i &lt; size; i++)<br/>// {<br/>// a[i] = 10;<br/>// b[i] = 20;<br/>// }<br/>//<br/>// memset(c, 0, NO_BYTES);</span></pre></div><div class="ab cl md me gp mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="hb hc hd he hf"><h1 id="8b94" class="jt ju hi bd jv jw mk jy jz ka ml kc kd ke mm kg kh ki mn kk kl km mo ko kp kq bi translated">比较</h1><p id="c048" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">让我们从内存传输时间和内核执行时间两个方面对以上四种方法进行比较和对比。</p><p id="6842" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了进行比较，我采用了同样的数组大小为 1 &lt; &lt; 20 的<em class="lm"> array_sum </em>内核。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/21c023c57e97241055b064afb69487da.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*CXWo4g3NushJu1J7Kb6aVg.png"/></div></figure><p id="cb28" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以上数字是通过使用 NVIDIA NSIGHT Systems profiler 分析编译的 CUDA 代码获得的。</p><h1 id="c549" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">观察结果</strong></h1><ol class=""><li id="77ea" class="ln lo hi ix b iy kr jc ks jg mq jk mr jo ms js ls lt lu lv bi translated">与可分页内存相比，固定内存只有一次内存传输。因此，固定内存的内存传输时间比可分页内存短。</li><li id="362c" class="ln lo hi ix b iy lw jc lx jg ly jk lz jo ma js ls lt lu lv bi translated">在映射内存中，地址被映射到设备地址空间。因此，没有显式的内存传输。所以转移时间为 0。但是由于它类似于底层的固定内存操作，所以两者的总时间差不多。</li><li id="4583" class="ln lo hi ix b iy lw jc lx jg ly jk lz jo ma js ls lt lu lv bi translated">在统一内存中，数据驻留在受管池中，并在需要时传输到机箱下的设备。因此，内存传输时间更少，但内核执行时间更多。这种类型类似于可分页内存，但两者之间的区别在于统一内存中的隐式内存传输。</li></ol></div><div class="ab cl md me gp mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="hb hc hd he hf"><p id="fe57" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在下一篇文章中，我将讨论流式多处理器内部的内存模型。谢了。</p></div></div>    
</body>
</html>