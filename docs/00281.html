<html>
<head>
<title>Facenet on Mobile — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">手机上的Facenet第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/facenet-on-mobile-cb6aebe38505?source=collection_archive---------0-----------------------#2019-02-28">https://medium.com/analytics-vidhya/facenet-on-mobile-cb6aebe38505?source=collection_archive---------0-----------------------#2019-02-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="0a0a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated"><em class="ix">转换Facenet(。pb)到Facenet(。tflite) </em></h2></div></div><div class="ab cl iy iz gp ja" role="separator"><span class="jb bw bk jc jd je"/><span class="jb bw bk jc jd je"/><span class="jb bw bk jc jd"/></div><div class="hb hc hd he hf"><blockquote class="jf jg jh"><p id="403a" class="ji jj jk jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">帮助弱者！打击网络犯罪<a class="ae kf" href="https://forms.gle/JWAPHzf2gd7jGq2YA" rel="noopener ugc nofollow" target="_blank">了解如何</a>。</p></blockquote></div><div class="ab cl iy iz gp ja" role="separator"><span class="jb bw bk jc jd je"/><span class="jb bw bk jc jd je"/><span class="jb bw bk jc jd"/></div><div class="hb hc hd he hf"><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/59adcd953d77142853cfe47a975739b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vchO4FQzA5kefb1SPM9q3A.png"/></div></div></figure><p id="cc9b" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated"><em class="jk">如果你没有读过我关于FaceNet架构的故事，我会推荐你去浏览一下</em><a class="ae kf" rel="noopener" href="/@tomdeore/facenet-architecture-part-1-a062d5d918a1"><em class="jk">part-1</em></a><em class="jk">。在接下来的</em><a class="ae kf" rel="noopener" href="/@tomdeore/facenet-on-modile-part-3-cc6f6d5752d6"><em class="jk">part-3</em></a><em class="jk">中，我会比较</em> <code class="du kv kw kx ky b"><em class="jk">.pb</em></code> <em class="jk">和</em> <code class="du kv kw kx ky b"><em class="jk">.tflite</em></code> <em class="jk">车型。</em></p><p id="ea75" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">当人脸识别/认证需要最先进的准确性时，Facenet是Android和IOS平台的显而易见的选择。但是在移动设备上运行Facenet需要一些特殊的处理，本文讨论了这个问题和潜在的解决方案。</p><p id="a1e8" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">在Android上，每个应用程序都有Dalvik VM强制限制的内存使用量。Android NDK没有这个限制，但这并不意味着本地代码可以消耗尽可能多的内存。同样的逻辑也适用于AI模型，它们应该是精益和精简的。</p><p id="fe32" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">AI模型是以特定文件格式构造的大型数据文件，以便推理引擎可以快速解析和加载它们。读取这样的数据文件可能会导致各种问题:解析开销、由于大小导致的性能下降、加载时间长，并且可能会导致低端设备上的内存节流。</p><p id="64c8" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">Tensorflow的<code class="du kv kw kx ky b">.tflite</code>文件格式，主要用于解决资源受限设备上的此类问题。<code class="du kv kw kx ky b">.tflite</code>实际上将完整的模型数据转换成一种叫做<a class="ae kf" href="https://nervanasystems.github.io/distiller/quantization/" rel="noopener ugc nofollow" target="_blank">的量化</a>和精简结构化格式(即<a class="ae kf" href="https://google.github.io/flatbuffers/" rel="noopener ugc nofollow" target="_blank"> flatbuffers </a>)。</p><p id="cb02" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">非量化的Facenet模型大小约为95MB，而且它位于<a class="ae kf" href="https://developers.google.com/protocol-buffers/" rel="noopener ugc nofollow" target="_blank">协议缓冲区</a>(另一种文件格式)。与flatbuffers相比，protocol-buffer慢得惊人，下图显示了比较结果:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kz"><img src="../Images/4eeea3635af5ec6c51cdaecdec68b646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OfX8u-n1BVpObFzI7cBmyw.png"/></div></div></figure><p id="6379" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">如果您想了解<a class="ae kf" href="https://www.tensorflow.org/lite/tf_ops_compatibility" rel="noopener ugc nofollow" target="_blank">与<code class="du kv kw kx ky b">.tflite</code>支持的操作</a>。您还可以直接从<a class="ae kf" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/kernels" rel="noopener ugc nofollow" target="_blank">代码库</a>中查看所有最新的重大变更。</p><p id="873d" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">无论如何，让我们开始支付代码…</p><h2 id="b862" class="la lb hi bd lc ld le lf lg lh li lj lk ks ll lm ln kt lo lp lq ku lr ls lt lu bi translated">步骤1:克隆Facenet存储库</h2><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="fb96" class="la lb hi ky b fi lz ma l mb mc">$ git clone <a class="ae kf" href="https://github.com/davidsandberg/facenet.git" rel="noopener ugc nofollow" target="_blank">https://github.com/davidsandberg/facenet.git</a></span></pre><p id="ea05" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">我们将量化预训练的具有512个嵌入大小的Facenet <a class="ae kf" href="https://drive.google.com/open?id=1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-" rel="noopener ugc nofollow" target="_blank">模型</a>，但是您可以选择使用具有128个嵌入大小的模型。该模型在量化前大小约为95MB。</p><p id="2ac2" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated"><code class="du kv kw kx ky b">wget</code>模型到<code class="du kv kw kx ky b">../facenet/models/</code>目录</p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="b148" class="la lb hi ky b fi lz ma l mb mc">$ ls -l models/</span><span id="55f0" class="la lb hi ky b fi md ma l mb mc">total 461248<br/>-rw-rw-r — @ 1 milinddeore staff <strong class="ky hj">95745767</strong> Apr 9 2018 20180402–114759.pb</span></pre><p id="0a1c" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated"><em class="jk">在您的机器上安装tensor flow:</em></p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="38f3" class="la lb hi ky b fi lz ma l mb mc">$ pip3 install tensorflow</span></pre><p id="85cd" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated"><em class="jk">确保安装了python ≥ 3.4版本。</em></p><h2 id="9862" class="la lb hi bd lc ld le lf lg lh li lj lk ks ll lm ln kt lo lp lq ku lr ls lt lu bi translated">步骤2:分条训练分支</h2><p id="c13b" class="pw-post-body-paragraph ji jj hi jl b jm me ij jo jp mf im jr ks mg ju jv kt mh jy jz ku mi kc kd ke hb bi translated">这里我们剥离掉'<strong class="jl hj"> <em class="jk"> phase_train </em> </strong>'输入分支，这将减少总的操作数并使它只推论图形。</p><p id="02c9" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">如果您尝试将facenet型号<code class="du kv kw kx ky b">.pb</code>转换为<code class="du kv kw kx ky b">.tflite</code>，您将得到<strong class="jl hj"> BatchNorm </strong>错误，如下所示:</p><p id="c11f" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">错误:'<em class="jk">平均值、乘数和偏移量需要是常数</em>'。</p><p id="2b56" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">让我们详细了解这一点:</p><blockquote class="jf jg jh"><p id="4bad" class="ji jj jk jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">什么是BatchNormalization？</p></blockquote><p id="097e" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated"><strong class="jl hj"> BatchNormalization(又名batch normal)</strong>:输入数据预处理是必须的，在输入神经网络之前，这通常在输入数据集上完成。</p><p id="1693" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">同样，我们也对DNN层之间的数据进行归一化，这被称为<strong class="jl hj"> BatchNorm </strong>。它在相同的尺度上转换数据，并避免任何不稳定性。这有两个部分:</p><ol class=""><li id="8029" class="mj mk hi jl b jm jn jp jq ks ml kt mm ku mn ke mo mp mq mr bi translated">归一化:通常我们在<em class="jk"> 0到</em>1的尺度上<strong class="jl hj">缩小数据。让我们假设我有<em class="jk">data _ values =【1，200，100000，500】</em>。这是一个相当大的值范围，我们需要将它们缩小到0到1的范围，中间有很多浮点。这一点很重要，否则网络将变得不稳定，数据点的范围很广，训练将花费很长时间，而且也不能保证网络会正确收敛。</strong></li><li id="a512" class="mj mk hi jl b jm ms jp mt ks mu kt mv ku mw ke mo mp mq mr bi translated">标准化:这实际上是计算Z分数，并使<strong class="jl hj">数据集具有‘零’均值和‘一’标准差</strong>。</li></ol><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="d74b" class="la lb hi ky b fi lz ma l mb mc">                                  x — m<br/>                              Z = -----<br/>                                    S<br/>Where: <br/>x = data point<br/>m = Mean of dataset<br/>S = Standard deviation</span></pre><p id="0d9e" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">现在我们需要了解BatchNorm是如何在Tensorflow中实现的。“训练”和“推理”的效果不同</p><p id="a49c" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated"><strong class="jl hj">培训</strong>:</p><ol class=""><li id="c37a" class="mj mk hi jl b jm jn jp jq ks ml kt mm ku mn ke mo mp mq mr bi translated">基于小批量统计，标准化层激活。其中，小批量统计数据为:小批量平均值和小批量标准偏差。</li><li id="8d4c" class="mj mk hi jl b jm ms jp mt ks mu kt mv ku mw ke mo mp mq mr bi translated">通过小批量统计的移动平均值更新总体统计近似值。其中人口统计为:人口均值和人口标准差。</li></ol><p id="1094" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated"><strong class="jl hj">推论</strong>:</p><ol class=""><li id="d5fa" class="mj mk hi jl b jm jn jp jq ks ml kt mm ku mn ke mo mp mq mr bi translated">估计人口统计，以标准化层激活。</li><li id="b690" class="mj mk hi jl b jm ms jp mt ks mu kt mv ku mw ke mo mp mq mr bi translated">不要根据小批量统计数据更新总体统计数据，因为这是测试数据。</li></ol><p id="540c" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">在代码中:我们需要设置<code class="du kv kw kx ky b">is_training = False</code>以便BatchNorm按照推理模式的建议工作。下面的代码片段设置了<code class="du kv kw kx ky b">arg_scope</code>,因此对于图中的所有<code class="du kv kw kx ky b">BatchNorm</code>,这个配置都是适用的。</p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="1344" class="la lb hi ky b fi lz ma l mb mc">inception_resnet_v1.inference(data_input, keep_probability=0.8, phase_train=False, bottleneck_layer_size=512)</span><span id="defb" class="la lb hi ky b fi md ma l mb mc">Here: <br/><strong class="ky hj">is_training = phase_train = False </strong></span></pre><p id="e841" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">为了创建一个只包含推理的模型，将下面的代码粘贴到<code class="du kv kw kx ky b">../facenet/</code>目录下的<code class="du kv kw kx ky b">inference_graph.py</code>文件中</p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="eaf0" class="la lb hi ky b fi lz ma l mb mc">import tensorflow as tf<br/>from src.models import inception_resnet_v1<br/>import sys<br/></span><span id="8b3d" class="la lb hi ky b fi md ma l mb mc">def main():<br/>    <br/>    traning_checkpoint = “models/model-20180402-114759.ckpt-275”<br/>    eval_checkpoint = “model_inference/imagenet_facenet.ckpt”<br/>    <br/>    data_input = tf.placeholder(name=’input’, dtype=tf.float32, shape=[None, 160, 160, 3])<br/>    output, _ = inception_resnet_v1.inference(data_input, keep_probability=0.8, phase_train=False, bottleneck_layer_size=512)<br/>    label_batch= tf.identity(output, name=’label_batch’)<br/>    embeddings = tf.identity(output, name=’embeddings’)<br/>    <br/>    init = tf.global_variables_initializer()</span><span id="8d83" class="la lb hi ky b fi md ma l mb mc">    with tf.Session() as sess:<br/>        sess.run(init)<br/>        saver = tf.train.Saver()<br/>        saver.restore(sess, traning_checkpoint)<br/>        save_path = saver.save(sess, eval_checkpoint)<br/>        print(“Model saved in file: %s” % save_path)<br/></span><span id="aadc" class="la lb hi ky b fi md ma l mb mc">if __name__ == “__main__”:<br/>    main()</span></pre><p id="bf77" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">运行脚本并创建仅推理模型，将其保存在<code class="du kv kw kx ky b">../facenet/model_inference/</code>下</p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="7828" class="la lb hi ky b fi lz ma l mb mc">$ python3 inference_graph.py models/ model_inference/</span></pre><p id="f19e" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">Facenet提供了<code class="du kv kw kx ky b">freeze_graph.py</code>文件，我们将用它来冻结推理模型。</p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="a622" class="la lb hi ky b fi lz ma l mb mc">$ cd ./facenet<br/>$ python3 src/freeze_graph.py model_inference/ facenet_frozen.pb</span></pre><p id="30d5" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">一旦生成了冻结模型，就该将其转换为<code class="du kv kw kx ky b">.tflite</code></p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="c670" class="la lb hi ky b fi lz ma l mb mc">$ tflite_convert --output_file model_mobile/my_facenet.tflite --graph_def_file facenet_frozen.pb --input_arrays “input” --input_shapes “1,160,160,3” --output_arrays "embeddings" --output_format TFLITE — mean_values 128 --std_dev_values 128 --default_ranges_min 0 --default_ranges_max 6 --inference_type QUANTIZED_UINT8 --inference_input_type QUANTIZED_UINT8<br/></span></pre><p id="1edd" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">我们将float32量子化为quint8，使大小缩小了三倍。让我们检查量化模型的大小:</p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="5bf9" class="la lb hi ky b fi lz ma l mb mc">$ ls -l model_mobile/</span><span id="fcc5" class="la lb hi ky b fi md ma l mb mc">total 47232<br/>-rw-r — r — @ 1 milinddeore staff 23667888 Feb 25 13:39 my_facenet.tflite<br/></span></pre><p id="be5a" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">为了验证<code class="du kv kw kx ky b">.tflite</code>型号，我们需要如下的参数间代码:</p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="10b4" class="la lb hi ky b fi lz ma l mb mc">import numpy as np<br/>import tensorflow as tf</span><span id="51a9" class="la lb hi ky b fi md ma l mb mc"># Load TFLite model and allocate tensors.<br/>interpreter = tf.lite.Interpreter(model_path=”/Users/milinddeore/facenet/model_mobile/my_facenet.tflite”)</span><span id="7ec2" class="la lb hi ky b fi md ma l mb mc">interpreter.allocate_tensors()</span><span id="48d2" class="la lb hi ky b fi md ma l mb mc"># Get input and output tensors.<br/>input_details = interpreter.get_input_details()<br/>output_details = interpreter.get_output_details()</span><span id="a699" class="la lb hi ky b fi md ma l mb mc"># Test model on random input data.<br/>input_shape = input_details[0][‘shape’]<br/>input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)</span><span id="89fb" class="la lb hi ky b fi md ma l mb mc">interpreter.set_tensor(input_details[0][‘index’], input_data)<br/>interpreter.invoke()</span><span id="314d" class="la lb hi ky b fi md ma l mb mc">output_data = interpreter.get_tensor(output_details[0][‘index’])</span><span id="f24f" class="la lb hi ky b fi md ma l mb mc">print(‘INPUTS: ‘)<br/>print(input_details)<br/>print(‘OUTPUTS: ‘)<br/>print(output_details)</span></pre><p id="cc91" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">参数间输出:</p><pre class="kh ki kj kk fd lv ky lw lx aw ly bi"><span id="dcf0" class="la lb hi ky b fi lz ma l mb mc">$ python inout.py</span><span id="1c8e" class="la lb hi ky b fi md ma l mb mc">INPUTS:<br/>[{‘index’: 451, ‘shape’: array([ 1, 160, 160, 3], dtype=int32), ‘quantization’: (0.0078125, 128L), ‘name’: ‘input’, ‘dtype’: &lt;type ‘numpy.uint8’&gt;}]<br/>OUTPUTS:<br/>[{‘index’: 450, ‘shape’: array([ 1, 512], dtype=int32), ‘quantization’: (0.0235294122248888, 0L), ‘name’: ‘embeddings’, ‘dtype’: &lt;type ‘numpy.uint8’&gt;}]</span></pre><p id="430e" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">输出与我们预期的一样，现在是时候在目标设备上运行它并查看性能了。</p><p id="eeed" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">在接下来的<a class="ae kf" rel="noopener" href="/@tomdeore/facenet-on-modile-part-3-cc6f6d5752d6"> part-3 </a>中，我将稍微深入一点比较<code class="du kv kw kx ky b">.pb</code>和<code class="du kv kw kx ky b">.tflite</code>无量化模型比较。理论上他们应该吐出相同的嵌入。</p><p id="289d" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated">第三集见…</p><p id="e045" class="pw-post-body-paragraph ji jj hi jl b jm jn ij jo jp jq im jr ks jt ju jv kt jx jy jz ku kb kc kd ke hb bi translated"><strong class="jl hj">你可以在|</strong><a class="ae kf" href="https://www.linkedin.com/in/mdeore/" rel="noopener ugc nofollow" target="_blank"><strong class="jl hj">LinkedIn</strong></a><strong class="jl hj">|</strong><a class="ae kf" href="https://tomdeore.wixsite.com/epoch" rel="noopener ugc nofollow" target="_blank"><strong class="jl hj">网站</strong></a><strong class="jl hj">|</strong><a class="ae kf" href="https://github.com/milinddeore" rel="noopener ugc nofollow" target="_blank"><strong class="jl hj">Github</strong></a><strong class="jl hj">|</strong></p></div></div>    
</body>
</html>