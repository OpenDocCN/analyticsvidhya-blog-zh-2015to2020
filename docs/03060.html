<html>
<head>
<title>Detecting what’s on the plate with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Keras检测盘子里有什么</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/detecting-whats-on-the-plate-with-keras-64c7cfa70c86?source=collection_archive---------19-----------------------#2020-01-14">https://medium.com/analytics-vidhya/detecting-whats-on-the-plate-with-keras-64c7cfa70c86?source=collection_archive---------19-----------------------#2020-01-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9b7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我是一个吃货，我是一个计算机视觉爱好者。唯一有意义的是，我最终会做这样的事情。在Kaggle中筛选有趣的数据集以实现我从Coursera上的<a class="ae jd" href="https://www.coursera.org/learn/device-based-models-tensorflow" rel="noopener ugc nofollow" target="_blank"> deeplearning.ai的tensor flow:Data and Deployment</a>中学到的东西后，我偶然发现了<a class="ae jd" href="https://www.kaggle.com/kmader/food41" rel="noopener ugc nofollow" target="_blank"> Food-101数据集</a>，瞧！</p><p id="50be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">顾名思义，Food-101数据集包含从苹果派到华夫饼等101种菜肴的1000张图片(我有点惭愧地说，尽管我对食物很感兴趣，但我没有听说过其中的很多)。考虑到我不太可能遇到鹅肝或huevos ranchos，为了简单起见，数据集从101个类削减到20个。</p><div class="je jf jg jh fd ab cb"><figure class="ji jj jk jl jm jn jo paragraph-image"><img src="../Images/869adc34fc5461bd066d360db8536a91.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*CJmKp60aZynPHGK7JjGOZg.jpeg"/></figure><figure class="ji jj jr jl jm jn jo paragraph-image"><img src="../Images/a92c34cf292850f2261bb487cc7a3070.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*kC9tvsR1NALPmdSeqB3B-Q.jpeg"/><figcaption class="js jt et er es ju jv bd b be z dx jw di jx jy translated">Huevos牧场和鹅肝。</figcaption></figure></div><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="4848" class="ke kf hi ka b fi kg kh l ki kj">chicken curry	    fried rice	     samosa<br/>chicken wings	    garlic bread     sandwich<br/>chocolate cake	    hamburger        soup<br/>cup cake	    hot-dog	     spring rolls<br/>donuts	            ice-cream	     sushi<br/>dumplings	    omelette         waffles<br/>french fries	    pizza</span></pre><p id="fa90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述每个类别都有1000张图片，数据太少，无法从头开始训练一个准确的模型。引入迁移学习，使用在ImageNet数据集上预训练的MobileNetV1中的层。</p><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="097b" class="ke kf hi ka b fi kg kh l ki kj">conv_base = applications.MobileNet(weights = "imagenet", include_top=False, input_shape = (256, 256, 3))</span></pre><p id="0c4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">添加GlobalMaxPooling2D层和密集层后，模型架构如下所示:</p><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="0344" class="ke kf hi ka b fi kg kh l ki kj">Model: "sequential_8" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= mobilenet_1.00_224 (Model)   (None, 8, 8, 1024)        3228864    _________________________________________________________________ global_average_pooling2d_6 ( (None, 1024)              0          _________________________________________________________________ dense_13 (Dense)             (None, 1024)              1049600    _________________________________________________________________ dropout_25 (Dropout)         (None, 1024)              0          _________________________________________________________________ dense_14 (Dense)             (None, 20)                20500      ================================================================= Total params: 4,298,964 Trainable params: 4,277,076 Non-trainable params: 21,888</span></pre><p id="57dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了避免过度拟合，数据增强应用了增强技术，包括图像旋转、线性移位、缩放、照明变化和翻转。</p><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="4f46" class="ke kf hi ka b fi kg kh l ki kj">from keras.preprocessing.image import ImageDataGenerator</span><span id="79bf" class="ke kf hi ka b fi kk kh l ki kj">train_datagen = ImageDataGenerator(rescale = 1./255, rotation_range=360,width_shift_range=0.2,height_shift_range=0.2, shear_range = 0.2,zoom_range = [0.5, 1.0],brightness_range = [0.2, 1.0],horizontal_flip = True,vertical_flip =False,zca_whitening=True, zca_epsilon=1e-06)</span><span id="f986" class="ke kf hi ka b fi kk kh l ki kj">training_set=train_datagen.flow_from_directory(path_training,target_size =(256,256),batch_size=64,class_mode='categorical',shuffle=True)</span></pre><p id="266d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于初始时期，转移的层被冻结。</p><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="74a1" class="ke kf hi ka b fi kg kh l ki kj">for layer in conv_base.layers:<br/>  layer.trainable=False</span></pre><p id="017b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最初的训练是用学习率递减的Adam Optimizer完成的，随后<a class="ae jd" href="https://arxiv.org/abs/1712.07628" rel="noopener ugc nofollow" target="_blank">在以后的时期</a>切换到SGD。在遇到验证损失的平台期后，被转移的层被解冻，并恢复训练以进一步微调模型。获得了91.34%的训练准确率和85.51%的验证准确率。</p><h2 id="fca2" class="ke kf hi bd kl km kn ko kp kq kr ks kt iq ku kv kw iu kx ky kz iy la lb lc ld bi translated">测试</h2><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="5cff" class="ke kf hi ka b fi kg kh l ki kj">imn = '/content/test/testimage.jpg' #test image path<br/>img = load_img(imn, target_size=(256, 256))<br/>img = np.asarray(img)<br/>img = img.astype('float32')<br/>img = img/255<br/>img = np.expand_dims(img, axis=0)<br/>img = img.reshape(1,256,256,3)<br/>res = model2.predict(img)<br/>ord = np.argsort(res)<br/>ind = np.argmax(res)</span><span id="ff12" class="ke kf hi ka b fi kk kh l ki kj">li = ['chicken curry', 'chicken wings', 'ch cake', 'cup cake', 'donuts', 'dumplings', 'fries','fried rice', 'garlic bread', 'hamburger', 'hot-dog', 'ice-cream', 'omelette', 'pizza', 'samosa', 'sandwich','soup','spring rolls', 'sushi', 'waffle']</span><span id="071a" class="ke kf hi ka b fi kk kh l ki kj">lis = []</span><span id="9481" class="ke kf hi ka b fi kk kh l ki kj">for i in range(0, 5):<br/>  lis.append(li[(ord[0][19 - i])])</span><span id="a3aa" class="ke kf hi ka b fi kk kh l ki kj">print(lis) # Top-5 predictions</span></pre><figure class="je jf jg jh fd jj er es paragraph-image"><div class="er es le"><img src="../Images/84c4ee9c8b6dfc56425dc1b9aeca542c.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*URlys-KYr9FV0DG34AlXtQ.jpeg"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">['披萨'，'寿司'，'蒜味面包'，'三明治'，'煎蛋']</figcaption></figure><figure class="je jf jg jh fd jj er es paragraph-image"><div class="er es le"><img src="../Images/eb05aa2891e3a029ad69ffe9fd7b559f.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*ysZm6C8iy2FZEJ2q8NNZ_w.jpeg"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">['汉堡包'，'三明治'，'热狗'，'炒饭'，'煎蛋']</figcaption></figure><p id="582f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在可以保存keras .h5模型。该模型占用大约32.9 MB的空间。</p><h2 id="f636" class="ke kf hi bd kl km kn ko kp kq kr ks kt iq ku kv kw iu kx ky kz iy la lb lc ld bi translated">转换为TensorFlow lite</h2><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="a437" class="ke kf hi ka b fi kg kh l ki kj">image_shape = (256, 256, 3)</span><span id="0bbb" class="ke kf hi ka b fi kk kh l ki kj">def representative_dataset_gen():<br/>  num_calibration_images = 10<br/>  for i in range(num_calibration_images):<br/>    image = tf.random.normal([1] + list(image_shape))<br/>    yield [image]</span><span id="9714" class="ke kf hi ka b fi kk kh l ki kj">converter=lite.TFLiteConverter.from_keras_model_file('model.h5')</span><span id="8727" class="ke kf hi ka b fi kk kh l ki kj">converter.default_ranges_stats=[0,255]<br/>converter.optimizations = [tf.lite.Optimize.DEFAULT]<br/>converter.representative_dataset = representative_dataset_gen</span><span id="f0e2" class="ke kf hi ka b fi kk kh l ki kj">converter.target_spec.supported_ops =[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]</span><span id="7b30" class="ke kf hi ka b fi kk kh l ki kj">converter.inference_input_type = tf.uint8<br/>converter.inference_output_type = tf.uint8<br/>model = converter.convert()<br/>file = open( 'model.tflite' , 'wb' )<br/>file.write(model)</span></pre><p id="027a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终的tflite模型大小为16.29 MB，几乎是h5模型大小的一半。</p><h2 id="aa55" class="ke kf hi bd kl km kn ko kp kq kr ks kt iq ku kv kw iu kx ky kz iy la lb lc ld bi translated">用tflite测试</h2><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="5a51" class="ke kf hi ka b fi kg kh l ki kj">imn = '/content/test/testimage.jpg'<br/>img = load_img(imn, target_size=(256, 256))<br/>img = np.asarray(img)<br/>img = img.astype('float32')<br/>img = img/255<br/>img = np.expand_dims(img, axis=0)<br/>img = img.reshape(1,256,256,3)</span><span id="ff89" class="ke kf hi ka b fi kk kh l ki kj">interpreter = lite.Interpreter(model_path="model.tflite")<br/>interpreter.allocate_tensors()</span><span id="cff4" class="ke kf hi ka b fi kk kh l ki kj"># Get input and output tensors.<br/>input_details = interpreter.get_input_details()<br/>output_details = interpreter.get_output_details()<br/>interpreter.set_tensor(input_details[0]['index'], img)<br/>interpreter.invoke()</span><span id="2676" class="ke kf hi ka b fi kk kh l ki kj">output_data = interpreter.get_tensor(output_details[0]['index'])<br/>ord = np.argsort(output_data)<br/>ind = np.argmax(output_data)</span><span id="fbbf" class="ke kf hi ka b fi kk kh l ki kj">lis = []<br/>for i in range(0, 5):<br/>  lis.append(li[(ord[0][19 - i])])<br/>print(lis)</span></pre><p id="a084" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经完成了TFlite！</p><h2 id="59b8" class="ke kf hi bd kl km kn ko kp kq kr ks kt iq ku kv kw iu kx ky kz iy la lb lc ld bi translated">机器人</h2><p id="c56d" class="pw-post-body-paragraph if ig hi ih b ii lf ik il im lg io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">从<a class="ae jd" href="https://github.com/paarthbir77/WhatFood-Android-App" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">克隆github库到这里</strong> </a>。</p><p id="7b96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将tflite模型和带有标签的label.txt文件添加到应用程序的assets目录中。txt文件应该是这样的:</p><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="855b" class="ke kf hi ka b fi kg kh l ki kj">label 1<br/>label 2<br/>label 3<br/>..<br/>..<br/>..</span></pre><p id="d428" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Kotlin文件MainAct.kt中，根据需要编辑变量mInputSize、mModelPath和mLabelPath。我们正在考虑分类器中指定的阈值分数0.40，为了获得最佳结果，请随意使用！</p><p id="44e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是应用程序的屏幕截图:</p><figure class="je jf jg jh fd jj er es paragraph-image"><div class="er es lk"><img src="../Images/7bf7496a6fd6d922dfbceb737dca4292.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*WtkzsYMW9t4WodpGmATAlg.jpeg"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">好(App)tit！</figcaption></figure></div></div>    
</body>
</html>