<html>
<head>
<title>Computer Vision Tutorial: Implementing Mask R-CNN for Image Segmentation (with Python Code)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉教程:实现用于图像分割的掩模R-CNN(带Python代码)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/computer-vision-tutorial-implementing-mask-r-cnn-for-image-segmentation-with-python-code-fe34da5b99cd?source=collection_archive---------1-----------------------#2019-07-22">https://medium.com/analytics-vidhya/computer-vision-tutorial-implementing-mask-r-cnn-for-image-segmentation-with-python-code-fe34da5b99cd?source=collection_archive---------1-----------------------#2019-07-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b689" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我对自动驾驶汽车很着迷。构建自动驾驶汽车系统的复杂性和不同计算机视觉技术的混合是像我这样的数据科学家的梦想。</p><p id="8834" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我开始尝试理解自动驾驶汽车如何潜在地检测物体背后的计算机视觉技术。简单的对象检测框架可能不起作用，因为它只是检测对象并在其周围绘制固定的形状。</p><p id="d514" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在现实世界中，这是一个有风险的提议。想象一下，如果前方的道路有一个急转弯，我们的系统会在道路周围绘制一个矩形框。汽车可能无法理解是转弯还是直行。那是潜在的灾难！</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/8d22d85ff17b2ed85c3490391d3fcd3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sn2fMwQx9gwy8A7j.jpg"/></div></div></figure><p id="ab47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">相反，我们需要一种可以检测道路准确形状的技术，这样我们的自动驾驶汽车系统也可以安全地导航急转弯。</p><p id="0197" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以用来构建这样一个系统的最新最先进的框架？那是面具R-CNN！</p><p id="beed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，在本文中，我们将首先快速了解什么是图像分割。然后我们再来看这篇文章的核心——Mask R-CNN框架。最后，我们将深入用Python实现我们自己的Mask R-CNN模型。我们开始吧！</p><h1 id="2c37" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">图像分割概述</h1><p id="9ced" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我们在本系列的第1部分中详细学习了<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/?utm_source=blog&amp;utm_medium=computer-vision-implementing-mask-r-cnn-image-segmentation" rel="noopener ugc nofollow" target="_blank">图像分割的概念。我们讨论了什么是图像分割及其不同的技术，如基于区域的分割、边缘检测分割和基于聚类的分割。</a></p><p id="76c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你需要快速复习(或者想从头开始学习图像分割)，我建议你先看看那篇文章。</p><p id="08dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将在这里快速回顾一下这篇文章。图像分割为图像中的每个对象创建逐像素的遮罩。这项技术让我们对图像中的物体有了更细致的了解。下图将帮助您理解什么是图像分割:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kt"><img src="../Images/aaa8c0ca7604b52be001e73565c3114c.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/0*9BNYnWeveRWqk1bh.png"/></div></div></figure><p id="7303" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，您可以看到每个对象(在这个特定的图像中是细胞)已经被分割。这就是图像分割的工作原理。</p><p id="832d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还讨论了图像分割的两种类型:语义分割和实例分割。同样，让我们举个例子来理解这两种类型:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ku"><img src="../Images/a0d22746c7b17eb6db0b2799a88e827c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NVQv8dxPL2gpIEsu.png"/></div></div></figure><p id="a351" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">左图中的5个物体都是人。因此，<strong class="ih hj">语义分割</strong>会将所有人归类为单个实例。现在，右边的图像也有5个对象(都是人)。但是在这里，同一个类的不同对象被指定为不同的实例。这是一个<strong class="ih hj">实例分割的例子。</strong></p><p id="e040" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一部分介绍了解决这类图像分割问题的不同技术及其在Python中的实现。在本文中，我们将实现一种称为Mask R-CNN的最新图像分割技术来解决实例分割问题。</p><h1 id="0343" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">了解屏蔽R-CNN</h1><p id="8aea" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">Mask R-CNN基本上是<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/?utm_source=blog&amp;utm_medium=computer-vision-implementing-mask-r-cnn-image-segmentation" rel="noopener ugc nofollow" target="_blank">更快R-CNN </a>的延伸。更快的R-CNN广泛用于对象检测任务。对于给定的图像，它返回图像中每个对象的类标签和边界框坐标。因此，假设您传递了以下图像:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kv"><img src="../Images/8cea75c19ccc51555535eb0a6432a8be.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/0*HwksQiYFE7Gukc_q.png"/></div></figure><p id="66ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快速R-CNN模型将返回如下内容:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kw"><img src="../Images/813c79e070d7885c1334269b6e7365fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/0*_kInhyd1kyCF8vLf.png"/></div></figure><p id="29cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">Mask R-CNN框架建立在更快的R-CNN之上。</strong>所以，对于一个给定的图像，Mask R-CNN，除了每个对象的类标签和包围盒坐标，还会返回对象Mask。</p><p id="4687" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们先快速了解一下R-CNN的工作速度有多快。这将有助于我们理解R-CNN背后的直觉。</p><ul class=""><li id="4c22" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated">更快的R-CNN首先使用ConvNet从图像中提取特征地图</li><li id="a94f" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">这些特征图然后通过区域提议网络(RPN)传递，该网络返回候选边界框</li><li id="d9a0" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">然后，我们在这些候选边界框上应用RoI池层，以使所有候选对象具有相同的大小</li><li id="866a" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">最后，建议被传递到完全连接的层，以分类和输出对象的包围盒</li></ul><p id="2ea6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦你理解了R-CNN的工作原理，理解Mask R-CNN就变得非常容易了。所以，让我们从输入开始一步一步地理解它，预测类标签、边界框和对象遮罩。</p><h2 id="cf11" class="ll jr hi bd js lm ln lo jw lp lq lr ka iq ls lt ke iu lu lv ki iy lw lx km ly bi translated">主干模型</h2><p id="d48d" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">与我们在更快的R-CNN中使用的从图像中提取特征图的<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/?utm_source=blog&amp;utm_medium=computer-vision-implementing-mask-r-cnn-image-segmentation" rel="noopener ugc nofollow" target="_blank"> ConvNet </a>类似，我们在Mask R-CNN中使用ResNet 101架构从图像中提取特征。因此，第一步是拍摄图像，并使用ResNet 101架构提取特征。这些特征作为下一层的输入。</p><h2 id="99b5" class="ll jr hi bd js lm ln lo jw lp lq lr ka iq ls lt ke iu lu lv ki iy lw lx km ly bi translated">区域提案网络</h2><p id="8972" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">现在，我们采用上一步中获得的特征地图，并应用区域建议网络(RPM)。这基本上预测了该区域中是否存在物体。在这一步中，我们得到模型预测包含一些对象的那些区域或特征图。</p><h2 id="788e" class="ll jr hi bd js lm ln lo jw lp lq lr ka iq ls lt ke iu lu lv ki iy lw lx km ly bi translated">感兴趣区域</h2><p id="2dbe" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">从RPN获得的区域可能具有不同的形状，对吗？因此，我们应用一个池层，并将所有区域转换为相同的形状。接下来，这些区域通过完全连接的网络，以便预测类别标签和边界框。</p><p id="d933" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，这些步骤几乎与更快的R-CNN的工作方式相似。现在来看两个框架之间的区别。除此之外，<strong class="ih hj"> Mask R-CNN还生成分段掩码。</strong></p><p id="eed8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们首先计算感兴趣区域，以便可以减少计算时间。对于所有预测的区域，我们用基础真值盒计算并集上的交集(IoU)。我们可以这样计算借据:</p><p id="436b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">IoU =交叉点面积/并集面积</p><p id="f7fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">现在，只有当IoU大于或等于0.5时，我们才认为是感兴趣的区域。否则，我们就会忽略这个特定的区域。我们对所有区域都这样做，然后只选择IoU大于0.5的一组区域。</strong></p><p id="a811" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们用一个例子来理解一下。考虑这张图片:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lz"><img src="../Images/94473e5371e689390f0be9959d68dc9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ykeCJ_f9YAxzgwAd.png"/></div></div></figure><p id="832f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，红色的盒子是这幅图像的地面真相盒。现在，假设我们从RPN中得到4个区域，如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ma"><img src="../Images/15ff9907c2754191a06abb132e805387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bYq08kOKfolTK3c3.png"/></div></div></figure><p id="3e50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，框1和框2的IoU可能小于0.5，而框3和框4的IoU大约大于0.5。因此。我们可以说框3和框4是该特定图像的感兴趣区域，而框1和框2将被忽略。</p><p id="a873" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们来看看屏蔽R-CNN的最后一步。</p><h2 id="8175" class="ll jr hi bd js lm ln lo jw lp lq lr ka iq ls lt ke iu lu lv ki iy lw lx km ly bi translated">分段掩码</h2><p id="b805" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">一旦我们有了基于IoU值的ROI，我们就可以向现有架构添加一个屏蔽分支。这将返回包含对象的每个区域的分段掩码。它为每个区域返回大小为28 X 28的遮罩，然后按比例放大以进行推断。</p><p id="ddeb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还是那句话，让我们从视觉上来理解。考虑下面的图像:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mb"><img src="../Images/ca00ad2fc8c35f014efb3287e82a7ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*d7DFd0UmG0-GJc5B.jpg"/></div></div></figure><p id="8d94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此图像的分段掩码如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mc"><img src="../Images/860c331e3a94b51b7d93a21a46d89433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/0*qknP6t4nkAqo5nXZ.png"/></div></figure><p id="eca8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们的模型已经分割了图像中的所有对象。这是掩模R-CNN的最后一步，我们预测图像中所有物体的掩模。</p><p id="ad79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">记住口罩R-CNN的训练时间是相当高的。我花了大约1到2天的时间在著名的<a class="ae jd" href="http://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO数据集</a>上训练Mask R-CNN。因此，就本文的范围而言，我们将不训练我们自己的Mask R-CNN模型。</p><p id="a4c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将改为使用在COCO数据集上训练的掩模R-CNN模型的预训练权重。现在，在我们深入Python代码之前，让我们看一下使用Mask R-CNN模型执行实例分割的步骤。</p><h1 id="7e94" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">实现屏蔽R-CNN的步骤</h1><p id="4e5e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">是时候执行一些图像分割任务了！我们将使用由脸书人工智能研究所(FAIR)的数据科学家和研究人员创建的<a class="ae jd" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank"> mask rcnn框架</a>。</p><p id="0ec8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看使用掩模R-CNN执行图像分割的步骤。</p><h1 id="faba" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">步骤1:克隆存储库</h1><p id="8011" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">首先，我们将克隆具有Mask R-CNN架构的<em class="md"> mask rcnn </em>库。使用以下命令克隆存储库:</p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="f38f" class="ll jr hi mf b fi mj mk l ml mm"><em class="md">git clone </em><a class="ae jd" href="https://github.com/matterport/Mask_RCNN.git" rel="noopener ugc nofollow" target="_blank">https://github.com/matterport/Mask_RCNN.git</a></span></pre><p id="8bcc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦完成，我们需要安装Mask R-CNN所需的依赖项。</p><h1 id="1f96" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">步骤2:安装依赖项</h1><p id="90ed" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">以下是掩码R-CNN的所有依赖项列表:</p><p id="efe9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">在使用Mask R-CNN框架之前，你必须安装所有这些依赖项。</strong></p><h1 id="bade" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">步骤3:下载预先训练的重量(在COCO上训练)</h1><p id="274f" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">接下来，我们需要下载预训练的重量。您可以使用<a class="ae jd" href="https://github.com/matterport/Mask_RCNN/releases" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">这个链接</strong> </a>来下载预先训练好的重量。这些权重是从在MS COCO数据集上训练的模型获得的。下载完权重后，将该文件粘贴到我们在步骤1中克隆的Mask_RCNN存储库的samples文件夹中。</p><h1 id="f2b3" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">第四步:预测我们的形象</h1><p id="08ef" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">最后，我们将使用Mask R-CNN架构和预训练的权重来为我们自己的图像生成预测。</p><p id="89e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦你完成了这四个步骤，是时候进入你的Jupyter笔记本了！我们将在Python中实现所有这些东西，然后为图像中的对象生成遮罩以及类和边界框。</p><h1 id="69c8" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">在Python中实现掩码R-CNN</h1><p id="79eb" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">Sp，你准备好钻研Python，编码自己的图像分割模型了吗？我们开始吧！</p><p id="530c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了执行我将在本节中介绍的所有代码块，在克隆的Mask_RCNN存储库的“samples”文件夹中创建一个新的Python笔记本。</p><p id="0553" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从导入所需的库开始:</p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="4a74" class="ll jr hi mf b fi mj mk l ml mm">import os<br/>import sys<br/>import random<br/>import math<br/>import numpy as np<br/>import skimage.io<br/>import matplotlib<br/>import matplotlib.pyplot as plt<br/><br/># Root directory of the project<br/>ROOT_DIR = os.path.abspath("../")<br/><br/>import warnings<br/>warnings.filterwarnings("ignore")<br/><br/># Import Mask RCNN<br/>sys.path.append(ROOT_DIR)  # To find local version of the library<br/>from mrcnn import utils<br/>import mrcnn.model as modellib<br/>from mrcnn import visualize<br/># Import COCO config<br/>sys.path.append(os.path.join(ROOT_DIR, "samples/coco/"))  # To find local version<br/>import coco<br/><br/>%matplotlib inline</span></pre><p id="9ef6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将定义预训练权重的路径以及我们要对其执行分割的图像:</p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="521f" class="ll jr hi mf b fi mj mk l ml mm"># Directory to save logs and trained model<br/>MODEL_DIR = os.path.join(ROOT_DIR, "logs")<br/><br/># Local path to trained weights file<br/>COCO_MODEL_PATH = os.path.join('', "mask_rcnn_coco.h5")<br/><br/># Download COCO trained weights from Releases if needed<br/>if not os.path.exists(COCO_MODEL_PATH):<br/>    utils.download_trained_weights(COCO_MODEL_PATH)<br/><br/># Directory of images to run detection on<br/>IMAGE_DIR = os.path.join(ROOT_DIR, "images")</span></pre><p id="2fc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您没有将砝码放入样品文件夹，这将再次下载砝码。现在，我们将创建一个推理类，它将用于推理掩码R-CNN模型:</p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="338a" class="ll jr hi mf b fi mj mk l ml mm">class InferenceConfig(coco.CocoConfig):<br/>    # Set batch size to 1 since we'll be running inference on<br/>    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU<br/>    GPU_COUNT = 1<br/>    IMAGES_PER_GPU = 1<br/><br/>config = InferenceConfig()<br/>config.display()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mn"><img src="../Images/6d5f1be1dc79041bc85b616e55c472f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/0*uTNH7wNRr0-OD118.png"/></div></figure><p id="2359" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的总结中你能推断出什么？我们可以看到我们将使用的面罩R-CNN模型的多种规格。</p><p id="1e6d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，主干是resnet101，我们之前也讨论过。该模型将返回的遮罩形状是28X28，因为它是在COCO数据集上训练的。而且我们一共81节课(包括后台)。</p><p id="e25e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还可以看到其他各种统计数据，例如:</p><ul class=""><li id="903f" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated">输入形状</li><li id="d344" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">要使用的GPU数量</li><li id="1def" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">验证步骤等等。</li></ul><p id="4230" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您应该花一些时间来理解这些规范。如果你对这些规范有任何疑问，欢迎在下面的评论区问我。</p><h2 id="4727" class="ll jr hi bd js lm ln lo jw lp lq lr ka iq ls lt ke iu lu lv ki iy lw lx km ly bi translated">装载重量</h2><p id="009a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">接下来，我们将创建我们的模型并加载我们之前下载的预训练权重。<em class="md">确保预训练的砝码与笔记本在同一个文件夹中，否则您必须给出砝码文件的位置:</em></p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="b3de" class="ll jr hi mf b fi mj mk l ml mm"># Create model object in inference mode.<br/>model = modellib.MaskRCNN(mode="inference", model_dir='mask_rcnn_coco.hy', config=config)<br/><br/># Load weights trained on MS-COCO<br/>model.load_weights('mask_rcnn_coco.h5', by_name=True)</span></pre><p id="83f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将定义COCO数据集的类，这将在预测阶段帮助我们:</p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="b6b5" class="ll jr hi mf b fi mj mk l ml mm"># COCO Class names<br/>class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',<br/>               'bus', 'train', 'truck', 'boat', 'traffic light',<br/>               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',<br/>               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',<br/>               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',<br/>               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',<br/>               'kite', 'baseball bat', 'baseball glove', 'skateboard',<br/>               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',<br/>               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',<br/>               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',<br/>               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',<br/>               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',<br/>               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',<br/>               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',<br/>               'teddy bear', 'hair drier', 'toothbrush']</span></pre><p id="66f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们加载一个图像，并尝试查看模型的执行情况。您可以使用您的任何图像来测试模型。</p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="6551" class="ll jr hi mf b fi mj mk l ml mm"># Load a random image from the images folder<br/>image = skimage.io.imread('sample.jpg')<br/><br/># original image<br/>plt.figure(figsize=(12,10))<br/>skimage.io.imshow(image)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mo"><img src="../Images/8b52f7869184eda7551005a8aa1b52da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DLeQ2604UDj9XXVX.png"/></div></div></figure><p id="47c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我们将要处理的图像。你可以清楚地看到有几辆汽车(一辆在前，一辆在后)和一辆自行车。</p><h2 id="0498" class="ll jr hi bd js lm ln lo jw lp lq lr ka iq ls lt ke iu lu lv ki iy lw lx km ly bi translated">做预测</h2><p id="28d1" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">预测时间到了！我们将使用掩模R-CNN模型和预训练的权重，并观察它如何分割图像中的对象。我们将首先从模型中获取预测，然后绘制结果以将其可视化:</p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="4720" class="ll jr hi mf b fi mj mk l ml mm"># Run detection<br/>results = model.detect([image], verbose=1)<br/><br/># Visualize results<br/>r = results[0]<br/>visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mp"><img src="../Images/9b5641182b314ff068178ea3545c0af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/0*cu2CfX_2zFOuo1pL.png"/></div></figure><p id="aece" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有意思。该模型在分割图像中的汽车和自行车方面做得非常好。我们也可以分别查看每个遮罩或被分割的对象。让我们看看我们能做些什么。</p><p id="9c3d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将首先获取我们的模型预测的所有掩码，并将它们存储在掩码变量中。现在，这些掩码是布尔形式的(真和假)，因此我们需要将它们转换成数字(1和0)。让我们先这样做:</p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="34f1" class="ll jr hi mf b fi mj mk l ml mm">mask = r['masks']<br/>mask = mask.astype(int)<br/>mask.shape</span></pre><p id="5513" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">输出:</strong></p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="3aa3" class="ll jr hi mf b fi mj mk l ml mm">(480,640,3)</span></pre><p id="872e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将给我们一个由0和1组成的数组，其中0表示在那个特定的像素上没有物体，1表示在那个像素上有物体。请注意，遮罩的形状与原始图像的形状相似(您可以通过打印原始图像的形状来验证这一点)。</p><p id="3c14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">然而，这里的3并不代表渠道形状的面具。</strong>相反，它表示由我们的模型分割的对象的数量。由于模型已经在上面的样本图像中识别了3个对象，所以遮罩的形状是(480，640，3)。如果有5个对象，这个形状应该是(480，640，5)。</p><p id="3584" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在有了原始图像和蒙版阵列。为了从图像中打印或获取每个片段，我们将为循环创建一个<em class="md">，并将每个蒙版与原始图像相乘以获取每个片段:</em></p><pre class="jf jg jh ji fd me mf mg mh aw mi bi"><span id="a7c0" class="ll jr hi mf b fi mj mk l ml mm">for i in range(mask.shape[2]):<br/>    temp = skimage.io.imread('sample.jpg')<br/>    for j in range(temp.shape[2]):<br/>        temp[:,:,j] = temp[:,:,j] * mask[:,:,i]<br/>    plt.figure(figsize=(8,8))<br/>    plt.imshow(temp)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mq"><img src="../Images/da5fc1c90665af37ff78839e942004a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*eRSSzFCR7fDmdY1m.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mr"><img src="../Images/3f3d24df26cd380cb32b570fd3842f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/0*CJNN-SVpp30X3OmI.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ms"><img src="../Images/13481c69691fed92d52954b892d4650f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/0*eRz0maCvx5SMrnBW.png"/></div></figure><p id="ee39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是我们如何从图像中绘制每个遮罩或对象。这可能有很多有趣且有用的用例。从整个图像中获取片段可以减少计算成本，因为我们现在不必预处理整个图像，而只需预处理片段。</p><h2 id="b958" class="ll jr hi bd js lm ln lo jw lp lq lr ka iq ls lt ke iu lu lv ki iy lw lx km ly bi translated">结论</h2><p id="3b58" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">下面是我用我们的掩模R-CNN模型得到的一些结果:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mt"><img src="../Images/a84c1fec243d6dba9d3bb26eda80e244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*r70DLLLB-v93naB6.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mu"><img src="../Images/aa875aec630e750ad788dac8dbaa25a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9nMG1D2dw4sr1Ac9.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mv"><img src="../Images/3674cc8a885ba7499908ae5abd69f413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uteplKy3XQQCbi7x.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mw"><img src="../Images/93f54b6a0736e3a133f8d573f86da0d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vKqPeiGSwZN3_wIT.png"/></div></div></figure><p id="1638" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看起来棒极了！您刚刚使用Mask R-CNN构建了自己的图像分割模型——干得好。</p><h1 id="4ca2" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结束注释</h1><p id="a28a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我喜欢使用这个可怕的R-CNN框架。也许我现在会尝试将其集成到自动驾驶汽车系统中。🙂</p><p id="51c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图像分割具有广泛的应用，从医疗保健行业到制造业。我建议你在不同的图像上尝试这个框架，看看它的表现如何。请随时与社区分享您的成果。</p><p id="890e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你对这篇文章有任何问题、疑问或反馈，请在下面的评论区发表。</p></div><div class="ab cl mx my gp mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="hb hc hd he hf"><p id="ab9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="md">原载于2019年7月22日</em><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2019/07/computer-vision-implementing-mask-r-cnn-image-segmentation/" rel="noopener ugc nofollow" target="_blank"><em class="md">【https://www.analyticsvidhya.com】</em></a><em class="md">。</em></p></div></div>    
</body>
</html>