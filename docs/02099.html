<html>
<head>
<title>Pyspark CSV Reader deep dive</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pyspark CSV阅读器深度潜水</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/pyspark-csv-reader-deep-dive-6096cb2c2880?source=collection_archive---------6-----------------------#2019-11-30">https://medium.com/analytics-vidhya/pyspark-csv-reader-deep-dive-6096cb2c2880?source=collection_archive---------6-----------------------#2019-11-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/34ce1a12998ab5610e8353bc6da6a768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9ZKX5lvDCF5_TYv3"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Jez Timms 在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="e4aa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">大家好！</p><p id="7412" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Spark是大数据世界中的一个伟大框架。</p><p id="c57a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我在发表这篇文章的时候，考虑到了一个拥有spark理论知识的开发人员，并且必须着手使用spark</p><p id="428a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">csv和tsv是广泛使用的格式，所以让我们用spark分析一些数据。</p><p id="d1d5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们把博客分成几个步骤。</p><ol class=""><li id="1765" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">创建Spark会话</li><li id="cbbd" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">阅读CSV</li><li id="4706" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">添加标题</li><li id="3440" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">处理模式</li><li id="64a7" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">处理畸形数据</li><li id="a253" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">处理日期、时间戳(续..)</li><li id="268c" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">处理压缩数据(续..)</li><li id="b270" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">csv阅读器中的其他选项</li></ol><p id="9dd4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第一步:创造火花</strong></p><p id="72fb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过导入如下所示的SparkSession，如果一切顺利，您将看到如下输出</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/ad42405b0ee0a30ba08e9f4d19a38f45.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*3h03j7rvUFxe6QwQAQQe2w.png"/></div></figure><p id="5a15" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第二步:读取Csv </strong></p><p id="7c44" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">spark提供了一个非常好的api来处理Csv数据，如下所示</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es km"><img src="../Images/040ef0dad477800ea789622319b8e459.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FaJ1eHZs-0ngLEvgHk3mag.png"/></div></div></figure><p id="56c1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第三步:添加标题</strong></p><p id="5c4b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们注意到没有可用的头，所以spark默认填充_c0头来添加头，我们可以使用设置为true的头选项</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/2f9a6ccc824d0f766542cdc66c6a790a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5EEb5qb39dum2_ubR-dc7g.png"/></div></div></figure><p id="4ed0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是这里又有一个问题，列名有一些空格，在读取列时会影响spark parser。因此，我们最好创建一个带有自己标题的数据帧</p><p id="62f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，我们使用regex清除列名，用“_”替换空格和/</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/5ff4dd9e5f5e1c0ee8449a757d9c63c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BZpizeJuHk8RCZA14aOLVA.png"/></div></div></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/94313d11c958def4f6119dad20de4880.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yTxG8YPw6s-UxmQMbyjFGg.png"/></div></div></figure><p id="421c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里的问题是我们的数据中也有重复的标题列。但是spark没有跳过顶部几行的选项。因此，我们将从DF中过滤第一个</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/91f67c22a2352cc06a5e711bce8c8e3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pBw-_ymHMj4PYloNCXzJMQ.png"/></div></div></figure><p id="8701" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤4:处理模式</strong></p><p id="b849" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">默认情况下，spark会将所有列读取为字符串，我们可以使用dtypes来确认这一点</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/9ea42fee25880e790cc444d2b46bea0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*LrOb9kyWiKbVqEIM-bN5Kg.png"/></div></figure><p id="c3b8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以使用inferschema来允许spark解析器推断模式，但是对于大的csv文件来说，这是很昂贵的，因为它必须读取文件</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ks"><img src="../Images/e29d8b1e956193681b89864922705d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RzoPYUgVL_VxyMQW4hebCg.png"/></div></div></figure><p id="a8ed" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">相反，我们可以通过导入spark.sql.types并在单个步骤中添加头和模式，轻松地将模式指定为int、string等</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/a572a8bcb49b3449798dcf2ddacaf30e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sqJouaQy0VBuASV5gICHgw.png"/></div></div></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/06586dd0b83a891a0055c8b626cc9de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ybjK_hCnz9OMixZs5_We7Q.png"/></div></div></figure><p id="baa4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第五步:处理格式错误的数据</strong></p><p id="dca4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们上面看到的，如果数据不符合模式，我们可以看到数据被转换为null，因此我们可以通过使用模式选项“drop formattered”来更改这一点</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/3983dd8f4c000352780cf93d2bcd2420.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wc6Nj9RvNEWZH-BWycqnTQ.png"/></div></div></figure><p id="8f02" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是，上面的方法删除了所有格式错误的行，因此效果不好。相反，我们可以添加一个损坏的列和模式，我们可以使用它来查看损坏的数据，这样我们就不会丢失任何信息</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/c8bd45efd3957fb494fe7b18561db430.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0rlqW4YJnK3cyxDzuvltBg.png"/></div></div></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/ffb96da1976d9089bf98cef6429a4a8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GK6vHTVNnqWwghJdX4snrQ.png"/></div></div></figure><p id="4f10" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Github链接:<a class="ae iu" href="https://github.com/SomanathSankaran/spark_medium/tree/master/spark_csv" rel="noopener ugc nofollow" target="_blank">https://github . com/SomanathSankaran/spark _ medium/tree/master/spark _ CSV</a></p><p id="102c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="ky">请把我在spark中必须涉及的话题发给我，并给我提供改进写作的建议:)</em> </strong></p><p id="eb36" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">延续:</strong></p><div class="kz la ez fb lb lc"><a rel="noopener follow" target="_blank" href="/@somanathsankaran/spark-csv-deep-dive-part-ii-6d3389904f71"><div class="ld ab dw"><div class="le ab lf cl cj lg"><h2 class="bd hj fi z dy lh ea eb li ed ef hh bi translated">火花CSV深潜-第二部分</h2><div class="lj l"><h3 class="bd b fi z dy lh ea eb li ed ef dx translated">这是我上一篇文章的延续</h3></div><div class="lk l"><p class="bd b fp z dy lh ea eb li ed ef dx translated">medium.com</p></div></div><div class="ll l"><div class="lm l ln lo lp ll lq io lc"/></div></div></a></div><p id="55df" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">学习并让别人学习！！</strong></p></div></div>    
</body>
</html>