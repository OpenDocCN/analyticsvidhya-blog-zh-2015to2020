<html>
<head>
<title>Implementing NLP on Spam Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在垃圾邮件分类器上实现自然语言处理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/implementing-nlp-on-spam-classifier-8135e2762a6a?source=collection_archive---------24-----------------------#2020-07-19">https://medium.com/analytics-vidhya/implementing-nlp-on-spam-classifier-8135e2762a6a?source=collection_archive---------24-----------------------#2020-07-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a0de2aff241ab4b447418ee16d5d226a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j_L5Spz6CDuUtX141HZ-cw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Lifewire提供的图片</figcaption></figure><h1 id="a859" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">什么是垃圾邮件？</h1><p id="f7f9" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">垃圾电子邮件也称为垃圾电子邮件，是通过电子邮件批量发送的未经请求的消息。这个名字来自于Monty Python sketch，其中垃圾邮件无处不在，不可避免，并且重复出现。自20世纪90年代初以来，垃圾电子邮件一直在稳步增长，到2014年，估计占总电子邮件流量的90%左右</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/46241fbf6d5592fab7e3fcaedd89f797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T8gMUqRikoNeZN08fKLGGQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片由CanopyLAB提供</figcaption></figure><p id="fc4a" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated"><strong class="ju hj">自然语言处理</strong> ( <strong class="ju hj"> NLP </strong>)是语言学、计算机科学、信息工程和人工智能的一个子领域，涉及计算机和人类(自然)语言之间的交互，特别是如何编写计算机程序来处理和分析大量自然语言数据。</p><blockquote class="la lb lc"><p id="8001" class="js jt ld ju b jv kv jx jy jz kw kb kc le kx kf kg lf ky kj kk lg kz kn ko kp hb bi translated"><strong class="ju hj">你可以从这个</strong> <a class="ae lh" href="https://github.com/MayankkYogi/SpamClassifier" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hj"> <em class="hi">链接</em> </strong> </a>下载数据集和代码</p></blockquote><h1 id="b658" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">主要字段/列:</h1><p id="4e67" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">因为数据集中没有列，所以我指定了列名，即</p><ul class=""><li id="3b61" class="li lj hi ju b jv kv jz kw kd lk kh ll kl lm kp ln lo lp lq bi translated">标签—邮件是垃圾邮件还是ham(非垃圾邮件)</li><li id="d676" class="li lj hi ju b jv lr jz ls kd lt kh lu kl lv kp ln lo lp lq bi translated">消息—实际的邮件正文</li></ul><p id="6cd4" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated"><strong class="ju hj">问题描述:</strong></p><p id="0d95" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">在这个模型中，主要任务是通过使用NLP和各种其他库来预测邮件是否是垃圾邮件。</p><p id="e91c" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated"><strong class="ju hj">注:</strong></p><p id="1e6e" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">使用命令nltk.download()下载所有相应的库</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/589688db81249917474749a5e2c8f1a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kP9woIeq4nMqu89f1Ne1rw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者图片</figcaption></figure><p id="7565" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">上面的弹出窗口将在命令执行后出现，然后选择“全部”列并点击下载按钮，这将下载实现NLP所需的所有库</p><p id="d8a2" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated"><strong class="ju hj">导入库:</strong></p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/6413d727ad1b712b57bb6d99260d5c7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vybql2VD5pdc1QUJrEUSiA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者图片</figcaption></figure><p id="b1e4" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">我正在导入所有需要的库。这样做的原因是一次性使用所有的导入语句变得更容易，并且我们不需要在每个点再次导入语句。我们可以在一个地方找到所有的导入语句，而不用在整个笔记本上找到，并且还可以更新。</p><p id="fc77" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">在这里，我将数据集加载到一个变量中，即“df ”,并处理前5行。</p><p id="4fa0" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">在数据集中，我们可以看到有两列标签和消息，其中标签是我们的目标/输出/因变量，消息是输入/自变量</p><p id="6c6a" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">我使用“sep = \t”的原因是第一列和第二列之间存在制表符差异</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/d8613ad30e2355e442a84fa15723ead5.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*epOZUZohAJlOoHA2NXlsRw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者图片</figcaption></figure><p id="b9b8" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">所以在这个数据集中总共有5572行和2列</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/45997939380703242058112fc5ddb6da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pyA8iRFaLp3GRFCK_Lo9_g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者图片</figcaption></figure><p id="82f9" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">这里我使用tf-idf而不是单词包，因为TF-IDF将根据单词的重要性唯一地给每个单词赋值</p><p id="9188" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated"><strong class="ju hj">什么是TF-IDF </strong></p><p id="0f95" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">在信息检索中，<strong class="ju hj">TF</strong>–<strong class="ju hj">IDF</strong>或<strong class="ju hj"> TFIDF </strong>，是词频——逆文档频率的缩写，是一种数字统计，旨在反映一个词对集合或语料库中的文档有多重要。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/0ede696fd021f2a4b3812a77ca8a6206.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*MWeT7qOOes3MDNIiS8r2uA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片由Quora提供</figcaption></figure><p id="483a" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">让我们通过例子来理解，在上面的图像中有两个句子，即句子1和句子2，然后我们从两个句子中取出每个单词，在上表中制作一个名为“单词”的列。</p><p id="9670" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">列“TF(句子1)”计算该特定单词的总出现次数除以相应句子中的总单词数，对于“TF(句子2)”也是如此</p><p id="dabc" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">列IDF现在取由下式给出的对数:log(句子的数量/包含单词的句子的数量),因此通过使用该公式，我们可以计算每个单词的IDF</p><p id="c9ff" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">然后我们可以简单地将IDF与特定的句子相乘并得到输出。</p><p id="e53d" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">在最后2列中，我们可以看到一些值是0，一些是大于0的十进制值，因此大于0的值被赋予更大的重要性，而具有值0的单词意味着这些单词对于预测邮件是否是垃圾邮件是有用的或唯一的</p><p id="6cbb" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">我希望你们现在能理解tf-idf..</p><p id="7211" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">所以我使用WordNetLemmatizer()库来使用tf-idf</p><p id="a52d" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">我将所有多余的标点符号(可能是特殊字符)替换为空格，之后我将所有的句子降级，然后使用停用词删除所有多余的无用词，如“is，a，the，them，for”等，然后应用tf-idf</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/bbc130c4806ac89482684d7c9e2259a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6xymlPm4rJZhTeWTbg-QiQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者图片</figcaption></figure><p id="ba93" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">在这里，我将字符串转换为向量，并将最大特征数取为5000，这意味着在数据集中有5572个特征，因此我只随机取5000个特征(您可以指定任何特征)</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/9d43c25bc424f585520d1c86659c6979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hpR4Oz2yh2fpVZKtsDkyDQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者图片</figcaption></figure><p id="a3a9" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">此外，在输出变量中有2个类别是垃圾邮件或火腿，所以我把它转换成1和0，为此我使用了get dummies(你也可以尝试使用标签编码器)</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/c912336c3b76f1ebc062459213358f42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JKCdYf4DrlsfCIg0qyZ5yg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者图片</figcaption></figure><p id="aca2" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">现在，我将数据分为训练和测试，对于预测，我使用朴素贝叶斯算法，因为它为文本处理语言提供了最好的结果</p><p id="08a2" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">最后，为了检查预测分数，我使用了混淆矩阵和准确度分数，结果非常好，准确度达到98%，大多数值都在TP和TN之下，这意味着该模型能够将邮件分类为垃圾邮件或ham。</p><blockquote class="la lb lc"><p id="f67e" class="js jt ld ju b jv kv jx jy jz kw kb kc le kx kf kg lf ky kj kk lg kz kn ko kp hb bi translated"><strong class="ju hj">如需进一步查询，您可以在我的</strong><a class="ae lh" href="https://www.linkedin.com/in/mayank-yogi-806ba9156/" rel="noopener ugc nofollow" target="_blank"><strong class="ju hj"><em class="hi">LinkedIn</em></strong></a>上联系我</p></blockquote></div></div>    
</body>
</html>