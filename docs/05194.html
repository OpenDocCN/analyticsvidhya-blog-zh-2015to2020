<html>
<head>
<title>Classification Loss: Cross-Entropy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类损失:交叉熵</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classification-loss-cross-entropy-6ed6d598bf8f?source=collection_archive---------33-----------------------#2020-04-13">https://medium.com/analytics-vidhya/classification-loss-cross-entropy-6ed6d598bf8f?source=collection_archive---------33-----------------------#2020-04-13</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><p id="f2e0" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hh bi translated">我最近从事计算机视觉项目的分类任务。论文和教程提到<strong class="in hp">交叉熵</strong>作为最常用的损失函数来衡量预测和标签之间的差异。现在，问题是我们用交叉熵做什么，怎么用，为什么用？</p><p id="5d88" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hh bi translated">本文基于Tensorflow使用MNIST数据集的<a class="ae jj" href="https://www.tensorflow.org/tutorials/keras/classification" rel="noopener ugc nofollow" target="_blank"> <strong class="in hp">对服装图像</strong> </a> <strong class="in hp"> </strong>进行分类教程。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jk"><img src="../Images/43ee057fc9501403bab5e72a13ca3792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Z3BIL4CeK47vqY4S.png"/></div></div><figcaption class="jw jx et er es jy jz bd b be z dx translated">MNIST数据集的服装图像</figcaption></figure></div></div>    
</body>
</html>