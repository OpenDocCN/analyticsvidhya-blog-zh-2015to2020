<html>
<head>
<title>Regression analysis with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch 回归分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/regression-analysis-with-pytorch-5f473ad5f3bb?source=collection_archive---------9-----------------------#2020-11-06">https://medium.com/analytics-vidhya/regression-analysis-with-pytorch-5f473ad5f3bb?source=collection_archive---------9-----------------------#2020-11-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/70a0089e12a9c2054b6c69c9acfe6192.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xNKdr4bgzIxBK54FLUuQSQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://www.kdnuggets.com/2019/08/pytorch-cheat-sheet-beginners.html" rel="noopener ugc nofollow" target="_blank">图片由</a>提供</figcaption></figure><p id="496c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这可能是第一千篇讨论使用 PyTorch 实现回归分析的文章。那么有什么不同呢？</p><p id="cd1c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我回答这个问题之前，让我先写一系列导致这篇文章的事件。所以，当我开始学习 PyTorch 时，我很兴奋，但我有太多的为什么和为什么不，我一度感到沮丧。所以，我想为什么不从头开始，更好地理解深度学习框架，然后深入研究复杂的概念，如 CNN，RNN，LSTM 等。最简单的方法是利用一个熟悉的数据集，尽可能多地探索，以便理解基本的构建模块和关键的工作原理。</p><p id="5f46" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我试图解释导入的模块，为什么某些步骤是强制性的，以及我们如何评估一个模型。</p><p id="d8a2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以，人们，如果你像我一样刚刚开始或正在寻找答案，那么你绝对是在正确的地方。:)</p><p id="7572" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">好的，让我们先从进口开始:</p><h2 id="75fd" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">进口</h2><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="433d" class="jt ju hi kt b fi kx ky l kz la"><strong class="kt hj">import </strong>torch<br/><strong class="kt hj">import </strong>torch.nn <strong class="kt hj">as </strong>nn </span></pre><p id="a317" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">torch.nn 模块帮助我们创建和训练神经网络。所以我们确实需要它。让我们继续:</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="aaa0" class="jt ju hi kt b fi kx ky l kz la"><strong class="kt hj">import </strong>pandas <strong class="kt hj">as </strong>pd<br/><strong class="kt hj">import </strong>numpy <strong class="kt hj">as </strong>np<br/><strong class="kt hj">import </strong>matplotlib.pyplot <strong class="kt hj">as </strong>plt<br/><strong class="kt hj">from </strong>sklearn.preprocessing <strong class="kt hj">import </strong>MinMaxScaler</span></pre><p id="7aad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">他们看起来很眼熟，对吧？我们需要它们，因为我们必须对将要使用的数据集进行一些预处理。</p><h2 id="4037" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">数据</h2><p id="bcdc" class="pw-post-body-paragraph iv iw hi ix b iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">我要使用的数据集是从<strong class="ix hj">摄氏度</strong>到<strong class="ix hj">华氏度</strong>的数据，可以在这里找到:<a class="ae iu" href="https://www.kaggle.com/domnic/celsius-to-fahrenheit" rel="noopener ugc nofollow" target="_blank">链接</a></p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/76a3bb2c33c08aa90e13eec0f763a68b.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*kmSQeVXKK7h_t4MqpkJvQw.png"/></div></figure><p id="28ff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">数据预处理步骤 1:分离出特征和标签</strong></p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="138b" class="jt ju hi kt b fi kx ky l kz la">X_train = train_data.iloc[:,0].values<br/>y_train = train_data.iloc[:,-1].values</span></pre><p id="37f1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">数据预处理步骤 2:由于数值非常大且变化多端，因此要对数据进行标准化。</strong>因此，如果您在这种特殊情况下不这样做，那么稍后在训练模型时，您可能会获得 inf 或 nan 损失值，这意味着模型无法正确执行反向传播，并将导致错误的模型。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="7a71" class="jt ju hi kt b fi kx ky l kz la">sc = MinMaxScaler()<br/>sct = MinMaxScaler()<br/>X_train=sc.fit_transform(X_train.reshape(-1,1))<br/>y_train =sct.fit_transform(y_train.reshape(-1,1))</span></pre><p id="47f9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们必须确保 X_train 和 y_train 是二维的。</p><p id="47e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">好的，目前为止还不错。现在让我们进入张量的世界。</p><p id="d0e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">数据预处理步骤 3:将 numpy 数组转换为张量</strong></p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="77e8" class="jt ju hi kt b fi kx ky l kz la">X_train = torch.from_numpy(X_train.astype(np.float32)).view(-1,1)<br/>y_train = torch.from_numpy(y_train.astype(np.float32)).view(-1,1)</span></pre><p id="f544" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">view 会像在 numpy 中一样处理 tensor 中的 2d 内容。</p><h2 id="f0c6" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated"><strong class="ak">模型构建</strong></h2><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="d87f" class="jt ju hi kt b fi kx ky l kz la">input_size = 1<br/>output_size = 1</span></pre><p id="6151" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输入=摄氏度</p><p id="dcc1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出=华氏温度</p><p id="fddd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">定义图层</strong></p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="d8b2" class="jt ju hi kt b fi kx ky l kz la"><strong class="kt hj">class </strong>LinearRegressionModel(torch.nn.Module):<br/><br/>    <strong class="kt hj">def </strong>__init__(self):<br/>        super(LinearRegressionModel, self).__init__()<br/>        self.linear = torch.nn.Linear(1, 1)  <em class="lh"># One in and one out<br/><br/>    </em><strong class="kt hj">def </strong>forward(self, x):<br/>        y_pred = self.linear(x)<br/>        <strong class="kt hj">return </strong>y_pred</span></pre><p id="71c9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">或者我们可以简单地这样做(因为它只是一个单层)</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="4e3a" class="jt ju hi kt b fi kx ky l kz la">model = nn.Linear(input_size , output_size)</span></pre><p id="1489" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这两种情况下，我们都使用 nn。线性为了创建我们的第一个线性图层，这基本上是对数据进行线性变换，比如说对于一条直线，它将简单到:y = w*x，其中 y 是标注，x 是要素。当然 w 是重量。在我们的数据中，摄氏温度和华氏温度遵循线性关系，因此我们对一个层感到满意，但在某些情况下，关系是非线性的，我们会添加额外的步骤来处理非线性，例如添加一个 sigmoid 函数。</p><p id="7d97" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">定义损失和优化器</strong></p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="31b4" class="jt ju hi kt b fi kx ky l kz la">learning_rate = 0.0001<br/>l = nn.MSELoss()<br/>optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate )</span></pre><p id="0f88" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可以看到，这种情况下的损失函数是“<strong class="ix hj"> mse </strong>或“<strong class="ix hj">均方误差</strong>”。我们的目标是减少损失，这可以通过使用优化器来实现，在这种情况下，<strong class="ix hj">随机梯度下降</strong>。SGD 需要一个初始模型参数或权重以及一个学习率。</p><p id="0663" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">好的，现在我们开始训练。</p><h2 id="35f7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">培养</h2><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="dabf" class="jt ju hi kt b fi kx ky l kz la">num_epochs = 100</span><span id="57b5" class="jt ju hi kt b fi li ky l kz la"><strong class="kt hj">for </strong>epoch <strong class="kt hj">in </strong>range(num_epochs):<br/>    <em class="lh">#forward feed<br/>    </em>y_pred = model(X_train.requires_grad_())<br/><br/>    <em class="lh">#calculate the loss<br/>    </em>loss= l(y_pred, y_train)<br/><br/>    <em class="lh">#backward propagation: calculate gradients<br/>    </em>loss.backward()<br/><br/>    <em class="lh">#update the weights<br/>    </em>optimizer.step()<br/><br/>    <em class="lh">#clear out the gradients from the last step loss.backward()<br/>    </em>optimizer.zero_grad()<br/>    <em class="lh"><br/>    </em>print(<strong class="kt hj">'epoch {}, loss {}'</strong>.format(epoch, loss.item()))</span></pre><p id="6b89" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">前馈</strong>:在这个阶段，我们只是通过使用一些初始权重和特征值来计算 y_pred。</p><p id="9b1d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">损失阶段</strong>:在 y_pred 之后，我们需要衡量发生了多大的预测误差。我们用<strong class="ix hj"> mse </strong>来衡量。</p><p id="d5db" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">反向传播</strong>:在此阶段计算梯度。</p><p id="9be2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤</strong>:权重现已更新。</p><p id="73a4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> zero_grad </strong>:最后，清除上一步的渐变，为新的渐变腾出空间。</p><h2 id="bd31" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">估价</h2><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="0e51" class="jt ju hi kt b fi kx ky l kz la">predicted = model(X_train).detach().numpy()</span></pre><p id="3ebc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">detach()是说我们不再需要存储梯度，所以从张量中分离出来。现在，让我们用前 100 个数据点来可视化模型质量。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="f14b" class="jt ju hi kt b fi kx ky l kz la">plt.scatter(X_train.detach().numpy()[:100] , y_train.detach().numpy()[:100])<br/>plt.plot(X_train.detach().numpy()[:100] , predicted[:100] , <strong class="kt hj">"red"</strong>)<br/>plt.xlabel(<strong class="kt hj">"Celcius"</strong>)<br/>plt.ylabel(<strong class="kt hj">"Farenhite"</strong>)<br/>plt.show()</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/866d3c383a3a140900efc9e0c58ff92b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*bcf0ct8fNftJc8eq1KuZCA.png"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/9a420237222251658b936d2a7388fa25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*1-G6oHaMBez0rz0MT3kbBA.png"/></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/190117318865148acc3159b7b211f9c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*EIuxho-IFfdgkr-jAikkKA.png"/></div></figure><p id="8379" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意，随着时代数量的增加，预测变得越来越好。有多种其他策略来优化网络，例如改变学习速率、权重初始化技术等等。</p><p id="c1a8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，尝试使用已知的摄氏温度值，看看该模型是否能够正确预测华氏温度值。这些值是经过转换的，所以请确保执行 sc.inverse_transform()和 sct.inverse_transform()来获取实际值。</p><p id="4bfb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">感谢您阅读这篇文章。请留下您的评论或分享您的反馈。:)</p><p id="bc2c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="lh">参考文献:</em></p><p id="da13" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://pytorch.org/tutorials/beginner/nn_tutorial.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/tutorials/beginner/nn_tutorial.html</a></p><div class="lm ln ez fb lo lp"><a href="https://www.geeksforgeeks.org/linear-regression-using-pytorch/" rel="noopener  ugc nofollow" target="_blank"><div class="lq ab dw"><div class="lr ab ls cl cj lt"><h2 class="bd hj fi z dy lu ea eb lv ed ef hh bi translated">使用 PyTorch - GeeksforGeeks 进行线性回归</h2><div class="lw l"><h3 class="bd b fi z dy lu ea eb lv ed ef dx translated">线性回归是一种非常常用的统计方法，它允许我们确定和研究…</h3></div><div class="lx l"><p class="bd b fp z dy lu ea eb lv ed ef dx translated">www.geeksforgeeks.org</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md io lp"/></div></div></a></div><div class="lm ln ez fb lo lp"><a href="https://stackoverflow.com/questions/54916135/what-is-the-class-definition-of-nn-linear-in-pytorch" rel="noopener  ugc nofollow" target="_blank"><div class="lq ab dw"><div class="lr ab ls cl cj lt"><h2 class="bd hj fi z dy lu ea eb lv ed ef hh bi translated">nn 的类定义是什么？pytorch 线性</h2><div class="lw l"><h3 class="bd b fi z dy lu ea eb lv ed ef dx translated">nn 的类定义是什么？pytorch 中的线性？来自文档:CLASS torch . nn . linear(in _ features…</h3></div><div class="lx l"><p class="bd b fp z dy lu ea eb lv ed ef dx translated">stackoverflow.com</p></div></div><div class="ly l"><div class="me l ma mb mc ly md io lp"/></div></div></a></div><p id="96db" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://towardsdatascience.com/logistic-regression-on-mnist-with-pytorch-b048327f8d19" rel="noopener" target="_blank">https://towards data science . com/logistic-regression-on-Mn ist-with-py torch-b 048327 f8d 19</a></p></div></div>    
</body>
</html>