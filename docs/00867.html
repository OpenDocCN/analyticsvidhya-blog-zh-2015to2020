<html>
<head>
<title>NLP Preprocessing with Ease</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">轻松进行NLP预处理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/nlp-preprocess-with-ease-9a93e563df47?source=collection_archive---------10-----------------------#2019-09-14">https://medium.com/analytics-vidhya/nlp-preprocess-with-ease-9a93e563df47?source=collection_archive---------10-----------------------#2019-09-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="0d65" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated"><strong class="ak">加速自然语言处理的数据清理</strong></h2></div><p id="1929" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">本文旨在让读者了解用最少的代码处理常见的自然语言预处理所需的信息</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/4b0c23ebdb60eaa18ce2ab7a578b7d52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0zqeMSxTFnAHdlDoxLGYNg.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">资料来源:knowyourmeme.com</figcaption></figure><p id="9904" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">值得注意的是，无论是数据科学还是机器学习工程，预处理都是必不可少的过程。有些人可能会花很多时间在网上闲逛，寻找完成这一过程所需的工具。所以我决定撰写这篇文章，向您展示如何利用现有的NLP相关工具和框架。</p><p id="8985" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在很大程度上，NLP的预处理包括以下步骤:</p><ol class=""><li id="30e5" class="kj kk hi iz b ja jb jd je jg kl jk km jo kn js ko kp kq kr bi translated">去掉标点符号</li><li id="7a58" class="kj kk hi iz b ja ks jd kt jg ku jk kv jo kw js ko kp kq kr bi translated">转换为小写</li><li id="9a13" class="kj kk hi iz b ja ks jd kt jg ku jk kv jo kw js ko kp kq kr bi translated">标记化</li><li id="89bf" class="kj kk hi iz b ja ks jd kt jg ku jk kv jo kw js ko kp kq kr bi translated">删除姓名(或不在英语词典中的单词)</li><li id="37f0" class="kj kk hi iz b ja ks jd kt jg ku jk kv jo kw js ko kp kq kr bi translated">删除停用词</li><li id="e4c1" class="kj kk hi iz b ja ks jd kt jg ku jk kv jo kw js ko kp kq kr bi translated">堵塞物</li><li id="4b19" class="kj kk hi iz b ja ks jd kt jg ku jk kv jo kw js ko kp kq kr bi translated">填充/截断</li><li id="aad4" class="kj kk hi iz b ja ks jd kt jg ku jk kv jo kw js ko kp kq kr bi translated">呈现模型可读的数据</li><li id="75f2" class="kj kk hi iz b ja ks jd kt jg ku jk kv jo kw js ko kp kq kr bi translated">检查拼写并修复</li></ol><p id="bc5d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">与最初导入所有需要的库相反，您必须一直向上滚动才能看到方法是从哪个库导入的，我将在它们即将被使用之前导入它们。</p><p id="39ac" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设我们已经有了所有需要的数据，并且已经在两个变量<em class="kx"> </em> <strong class="iz hj"> <em class="kx"> X </em> </strong>和<strong class="iz hj"> Y </strong>中有了它们，这两个变量分别是数据和标签。由于<strong class="iz hj"> Y </strong>很多时候应该不会出现什么问题来处理，所以本文围绕<strong class="iz hj"> X </strong>展开。为了一次涵盖所有情况，我将设置<strong class="iz hj"> X </strong>如下:</p><pre class="ju jv jw jx fd ky kz la lb aw lc bi"><span id="50bb" class="ld le hi kz b fi lf lg l lh li">X = [‘Despite    the rain, a boy is walking his.    dog \n on the streets   ‘]</span></pre><p id="da8e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个例子涵盖了大多数关于自然语言的常见情况(换行符、连续空格、逗号、句号)。</p><p id="f989" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们从第一行代码开始。</p><pre class="ju jv jw jx fd ky kz la lb aw lc bi"><span id="de14" class="ld le hi kz b fi lf lg l lh li">from keras.preprocessing.text import text_to_word_sequence</span><span id="92b2" class="ld le hi kz b fi lj lg l lh li">X = [text_to_word_sequence(X_point, filters=string.punctuation+"\n", lower=True, split=' ') for X_point in X]</span></pre><p id="ac9f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的代码做了三件事:<strong class="iz hj"> (1) </strong>删除标点符号(也包括空格、连续空格、换行)，<strong class="iz hj"> (2) </strong>将字符转换成小写，<strong class="iz hj"> (3) </strong>标记文本。</p><p id="da10" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对X进行这种处理后的结果将是:</p><pre class="ju jv jw jx fd ky kz la lb aw lc bi"><span id="ef95" class="ld le hi kz b fi lf lg l lh li">print(X)</span><span id="9119" class="ld le hi kz b fi lj lg l lh li"># -OUTPUT-<br/>[[‘despite’, ‘the’, ‘rain’, ‘a’, ‘boy’, ‘is’, ‘walking’, ‘his’, ‘dog’, ‘on’, ‘the’, ‘streets’]]</span></pre><p id="45b0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">拼写检查<strong class="iz hj"> (9) </strong>在数据准备中也起着非常重要的作用。所以我们可能想尝试一下，但是如果你有一个大的数据集，这个过程可能需要很长时间才能完成。</p><pre class="ju jv jw jx fd ky kz la lb aw lc bi"><span id="292d" class="ld le hi kz b fi lf lg l lh li">from spellchecker import SpellChecker</span><span id="def7" class="ld le hi kz b fi lj lg l lh li">spell = SpellChecker()<br/>X = [[spell.correction(word) for word in x] for x in X]</span></pre><p id="2aad" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们将继续用下面的代码处理X变量:</p><pre class="ju jv jw jx fd ky kz la lb aw lc bi"><span id="2b9e" class="ld le hi kz b fi lf lg l lh li">from nltk.stem.snowball import SnowballStemmer<br/>from nltk.corpus import stopwords</span><span id="88db" class="ld le hi kz b fi lj lg l lh li">stemmer = SnowballStemmer(‘english’)<br/>stop_words = stopwords.words('english')<br/>tmp_X = []</span><span id="7c2b" class="ld le hi kz b fi lj lg l lh li">for each in X:<br/>    tmp_X.append([stemmer.stem(token) for token in each if token in eng_words and token not in stop_words])<br/>X = tmp_X</span></pre><p id="a68b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的代码做了3件事:<strong class="iz hj"> (4) </strong>删除英语词典中没有的单词，<strong class="iz hj"> (5) </strong>删除停用词，<strong class="iz hj"> (6) </strong>词干。</p><p id="b917" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当然，结果会是:</p><pre class="ju jv jw jx fd ky kz la lb aw lc bi"><span id="6ac6" class="ld le hi kz b fi lf lg l lh li">print(X)</span><span id="addb" class="ld le hi kz b fi lj lg l lh li"># -OUTPUT-<br/>[['despit', 'rain', 'boy', 'walk', 'dog', 'street']]</span></pre><blockquote class="lk ll lm"><p id="65a0" class="ix iy kx iz b ja jb ij jc jd je im jf ln jh ji jj lo jl jm jn lp jp jq jr js hb bi translated">词干是单词的核心或心脏。</p><p id="bdc9" class="ix iy kx iz b ja jb ij jc jd je im jf ln jh ji jj lo jl jm jn lp jp jq jr js hb bi translated">换句话说。词干是一个单词的最简单的形式，无论它是什么形式，它都可以使自己区别于其他任何单词。</p></blockquote><p id="85a7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如你所看到的，我们已经成功地摆脱了停用词，并且在这样的变量中的所有单词都如我们所愿被词干化了。最重要的是，单词的顺序保持不变。</p><p id="c0bc" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一步可能会根据个人需求而有所不同。我们有多种方法将预处理数据转换为大多数现有机器学习模型可读的“进一步预处理”数据。</p><p id="448d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了简单起见，我将向那些不熟悉NLP的人演示一种最基本也是最常用的技术，来掌握它的窍门，那就是<strong class="iz hj"> (8) </strong>将每个单词转换成一个特定的整数。其余的需要先验知识，我可能会专门写一篇关于文本矢量化的文章<strong class="iz hj">。</strong></p><p id="2ddc" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将利用keras中可用的tokenizer。因为它需要一个文档列表作为输入，所以我们需要做一些小的步骤来满足这样的要求，然后将其输入到<em class="kx"> texts_to_sequences </em>方法中。</p><pre class="ju jv jw jx fd ky kz la lb aw lc bi"><span id="4bb2" class="ld le hi kz b fi lf lg l lh li">from keras.preprocessing.text import Tokenizer</span><span id="e812" class="ld le hi kz b fi lj lg l lh li">doc = [' '.join(doc) for doc in X]<br/>t = Tokenizer(split=' ', num_words=num_words)<br/>t.fit_on_texts(doc)<br/>X = t.texts_to_sequences(doc)</span></pre><p id="10cb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">num_words控制tokenizer只接受在X中出现次数最多的一定数量的单词。num_words为None的X的结果如下(因为通常您希望保留所有单词):</p><pre class="ju jv jw jx fd ky kz la lb aw lc bi"><span id="0a72" class="ld le hi kz b fi lf lg l lh li">print(X)</span><span id="fc32" class="ld le hi kz b fi lj lg l lh li"># -OUTPUT-<br/>[[1, 2, 3, 4, 5, 6]]</span></pre><p id="233d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请记住，所有现有模型都接收固定长度的数据点。所以我们需要把它们塑造成同样的长度。填充和截断来了<strong class="iz hj"> (7) </strong>！</p><pre class="ju jv jw jx fd ky kz la lb aw lc bi"><span id="0857" class="ld le hi kz b fi lf lg l lh li">from keras.preprocessing.sequence import pad_sequences</span><span id="504d" class="ld le hi kz b fi lj lg l lh li">X = pad_sequences(X, maxlen=maxlen, padding=”post”, truncating=”post”)</span></pre><p id="de04" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kx"> maxlen: int要将数据点整形到的长度。</em></p><p id="74f4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kx">填充:字符串，“前”或“后”:在每个序列之前或之后填充。</em></p><p id="40ac" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kx">截断:字符串，“前”或“后”:在每个序列之前或之后截断，直到达到所需长度。</em></p><p id="aa82" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> <em class="kx">现在它已经准备好输入你的模型了！！！</em>T19】</strong></p><h1 id="43aa" class="lr le hi bd ls lt lu lv lw lx ly lz ma io mb ip mc ir md is me iu mf iv mg mh bi translated"><strong class="ak">一些想法</strong></h1><p id="1926" class="pw-post-body-paragraph ix iy hi iz b ja mi ij jc jd mj im jf jg mk ji jj jk ml jm jn jo mm jq jr js hb bi translated">希望你们喜欢这篇文章，并且已经真正了解了NLP预处理。</p><p id="1aaf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我自己花了太多时间寻找解决这个任务所需的库，我认为我需要将其中一些库限制在一个更窄的范围内。因此，这篇文章。</p><p id="c290" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">感谢您的阅读。请随时在下面留下您的评论，这样我可以让我的下一篇文章更好。你的话是我的成长。</p></div></div>    
</body>
</html>