<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/grid-a-grid-world-environment-based-on-openai-gym-725189dcada6?source=collection_archive---------3-----------------------#2020-05-22">https://medium.com/analytics-vidhya/grid-a-grid-world-environment-based-on-openai-gym-725189dcada6?source=collection_archive---------3-----------------------#2020-05-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="e1bd" class="hg hh hi bd hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie bi translated"><a class="ae if" href="https://github.com/addy1997/Grid" rel="noopener ugc nofollow" target="_blank">网格</a>:基于<a class="ae if" href="https://gym.openai.com/" rel="noopener ugc nofollow" target="_blank"> openAI-gym </a>的网格世界环境</h2><figure class="ih ii ij ik fd il er es paragraph-image"><div role="button" tabindex="0" class="im in di io bf ip"><div class="er es ig"><img src="../Images/24b26a51f49164c98db5b58943139a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rWlyMGy3FHBgCNHO"/></div></div><figcaption class="is it et er es iu iv bd b be z dx translated"><a class="ae if" href="https://unsplash.com/s/photos/time-lapse" rel="noopener ugc nofollow" target="_blank">时间流逝</a>(演员表:李维斯)</figcaption></figure><p id="6380" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi jr translated"><span class="l js jt ju bm jv jw jx jy jz di">如果</span>你是强化学习领域的绝对初学者，在翻阅<em class="ka">萨顿&amp;巴尔托:强化学习入门</em> (II版)的页面时，很有可能你要解决的第一个问题就是网格世界。</p><p id="2320" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">在这篇文章中，我们将深入探讨强化学习中最有趣的问题之一；电网问题。</p><p id="1a62" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated"><strong class="iy kb">先决条件- </strong></p><ol class=""><li id="3738" class="kc kd hi iy b iz ja jd je hs ke hw kf ia kg jq kh ki kj kk bi translated">对C++/ Python有很好的理解。(不！！我不是招聘，这只是为了让你理解代码)</li><li id="6188" class="kc kd hi iy b iz kl jd km hs kn hw ko ia kp jq kh ki kj kk bi translated">对深度学习、数学(代数和微积分)和强化学习有很好的理解。</li></ol><p id="8f44" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated"><strong class="iy kb">注</strong> : <em class="ka">在开始本教程之前，我会推荐你先看看这个来自章晓虎的</em> <a class="ae if" href="https://towardsdatascience.com/reinforcement-learning-implement-grid-world-from-scratch-c5963765ebff" rel="noopener" target="_blank"> <em class="ka">帖子</em> </a> <em class="ka">。</em></p><p id="0b2d" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">完成本教程后，你将能够理解-</p><ol class=""><li id="eefd" class="kc kd hi iy b iz ja jd je hs ke hw kf ia kg jq kh ki kj kk bi translated"><strong class="iy kb">什么是网格世界问题？</strong></li><li id="9c97" class="kc kd hi iy b iz kl jd km hs kn hw ko ia kp jq kh ki kj kk bi translated">哪种方法适合解决这个问题？</li></ol><p id="b115" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">那么，让我们从问题陈述开始。</p></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="f453" class="kx hh hi bd hj ky kz la hn lb lc ld hr le lf lg hv lh li lj hz lk ll lm id ln bi translated">问题陈述</h1><figure class="ih ii ij ik fd il er es paragraph-image"><div class="er es lo"><img src="../Images/7ab540be43cf6e4ef350eabc106e801d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/0*FAVPL7yo0G5Jg-E0.png"/></div><figcaption class="is it et er es iu iv bd b be z dx translated">网格</figcaption></figure><blockquote class="lp lq lr"><p id="80d1" class="iw ix ka iy b iz ja jb jc jd je jf jg ls jh ji jj lt jk jl jm lu jn jo jp jq hb bi translated">该图使用矩形网格来说明简单有限MDP的值函数。网格的单元对应于环境的状态。在每个单元中，可能有四个动作:北、南、东和西，它们确定性地导致代理在网格上的相应方向上移动一个单元。将代理从网格中移除的动作保持其位置不变，但也会导致奖励1。除了那些将代理移出特殊状态A和b的动作之外，其他动作导致奖励为0。从状态A开始，所有四个动作产生+10的奖励并将代理带到A’。从状态B开始，所有动作产生+5的奖励，并把代理带到B’。</p></blockquote><h1 id="e7f4" class="kx hh hi bd hj ky lv la hn lb lw ld hr le lx lg hv lh ly lj hz lk lz lm id ln bi translated">逻辑</h1><p id="e5c4" class="pw-post-body-paragraph iw ix hi iy b iz ma jb jc jd mb jf jg hs mc ji jj hw md jl jm ia me jo jp jq hb bi translated">首先，这个问题是一个我们称之为<strong class="iy kb">有限MDP </strong>或马尔可夫决策过程的完美例子。现在，当一个任务严格遵循如下所示的马尔可夫性质时，它可以被分类为<strong class="iy kb"> MDP </strong></p><p id="ef19" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated"><strong class="iy kb">p(s′，r|s，a)= Pr { St+1 = s′，Rt+1 =r|St=s，At=a} ……。(1) </strong></p><p id="b0f2" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">这里p是一个动作<strong class="iy kb"><em class="ka"/></strong>跟随一个策略从当前状态<strong class="iy kb"> <em class="ka"> s </em> </strong> <em class="ka"> </em>到达连续状态<em class="ka"/><strong class="iy kb"><em class="ka">【s’</em></strong><em class="ka">的概率。</em>到达<em class="ka"/><strong class="iy kb"><em class="ka">s’</em></strong><em class="ka"/>代理人得到奖励<em class="ka"/><strong class="iy kb"><em class="ka">r</em></strong><em class="ka">。请注意，这里的代理是指计算机程序。</em></p><figure class="ih ii ij ik fd il er es paragraph-image"><div class="er es mf"><img src="../Images/7c1a1fecbaaaa2d723c5d62a3824e887.png" data-original-src="https://miro.medium.com/v2/resize:fit:230/format:webp/1*66EG-syGCV6vzQIUjUwIdg.png"/></div><figcaption class="is it et er es iu iv bd b be z dx translated">具有终端状态的网格</figcaption></figure><p id="5bcd" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">在图中，网格用浅灰色的<strong class="iy kb"><em class="ka"/></strong>区域表示端子状态。一个结束状态和目标状态是一样的，在那里代理人应该结束游戏。</p><h1 id="5c7d" class="kx hh hi bd hj ky lv la hn lb lw ld hr le lx lg hv lh ly lj hz lk lz lm id ln bi translated">目标</h1><p id="fa5e" class="pw-post-body-paragraph iw ix hi iy b iz ma jb jc jd mb jf jg hs mc ji jj hw md jl jm ia me jo jp jq hb bi translated">为了解决这个问题，我们应该推导出一个策略，将代理指向终端状态，一个在网格的左上角，另一个在网格的右下角。我们所说的策略是指π，它只不过是一个规则，指导代理根据代理所处的状态采取最合适的行动。用数学术语来说，π不过是从状态<strong class="iy kb"> S </strong>到动作<strong class="iy kb"> A </strong>的映射，如下图所示。</p><figure class="ih ii ij ik fd il er es paragraph-image"><div class="er es mg"><img src="../Images/02df6ba437748c5cefaf292dc3bbb27c.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/0*bHzPQln5wAo8TkMt.png"/></div><figcaption class="is it et er es iu iv bd b be z dx translated">从状态到动作的映射</figcaption></figure><h1 id="c5c4" class="kx hh hi bd hj ky lv la hn lb lw ld hr le lx lg hv lh ly lj hz lk lz lm id ln bi translated">履行</h1><p id="dc63" class="pw-post-body-paragraph iw ix hi iy b iz ma jb jc jd mb jf jg hs mc ji jj hw md jl jm ia me jo jp jq hb bi translated">我会尽我最大的努力让它尽可能简单。实现过程如下:</p><ol class=""><li id="b093" class="kc kd hi iy b iz ja jd je hs ke hw kf ia kg jq kh ki kj kk bi translated"><strong class="iy kb">导入包</strong></li></ol><figure class="ih ii ij ik fd il"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="2796" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated"><strong class="iy kb"> 2。创建网格环境</strong></p><figure class="ih ii ij ik fd il"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="7a9e" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated"><strong class="iy kb"> 3。实现步骤函数来计算代理对特定行为的回报。</strong></p><figure class="ih ii ij ik fd il"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="c252" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated"><strong class="iy kb"> 4。我们通过加载文件来构建网格，并从网格环境中获取观察值，基于这些观察值，代理将执行动作并获得奖励。</strong></p><figure class="ih ii ij ik fd il"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="e98f" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated"><strong class="iy kb"> 5。获取代理的状态:这是最重要的一步，在这一步中，我们为代理分配开始状态和目标状态，代理将根据这些状态启动任务。</strong></p><figure class="ih ii ij ik fd il"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="dbc4" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated"><strong class="iy kb">结论</strong></p><p id="0efe" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">总之，我们已经成功地实现了网格世界问题。我希望这段代码不会很恐怖，虽然它很长，但是相信我，一旦你尝试过，它会很容易。</p><p id="2857" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">我知道这不是重点，我应该详细解释这些步骤，但如前所述，本教程假设读者有RL的相关背景，最重要的是openAI-gym包。</p><p id="0e83" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">如果您需要详细的实现，下面给出了我的库的链接。欢迎在下面的评论区提出你的问题，但我可能会慢一些回复。</p><p id="712e" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">链接:<a class="ae if" href="https://github.com/addy1997/Grid" rel="noopener ugc nofollow" target="_blank">https://github.com/addy1997/Grid</a></p><p id="8434" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg hs jh ji jj hw jk jl jm ia jn jo jp jq hb bi translated">谢谢！！！</p></div></div>    
</body>
</html>