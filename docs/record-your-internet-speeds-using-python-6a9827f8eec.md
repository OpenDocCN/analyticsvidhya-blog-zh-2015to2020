# 使用 Python 记录你的网速

> 原文：<https://medium.com/analytics-vidhya/record-your-internet-speeds-using-python-6a9827f8eec?source=collection_archive---------4----------------------->

![](img/57d95fde5a09450f1777ca29d9d776d5.png)

[(来源)](https://www.pexels.com/photo/person-writing-on-notebook-669615/)

上周，我写了一篇关于在微软 Power BI 中可视化数据集有多容易的文章。今天，我想向大家展示我是如何在 pandas 和 speedtest-cli 库的帮助下，用 Python 收集我的网速数据集的。

首先，您需要在终端上用常用的`pip install`命令安装两个库:

```
pip install 
pip install speedtest-cli
```

如果你用的是 Windows，别忘了以管理员身份运行。

现在您已经安装了必要的库，让我简单介绍一下我们将要使用的数据。目标是创建一个包含以下四列的 CSV:

*   日期:测试日期
*   Ping(毫秒):测试连接的 ping，以毫秒为单位
*   下载(Mb/s):记录的下载速度，单位为每秒兆位
*   上传(Mb/s):记录的上传速度，单位为每秒兆位

使用 speedtest-cli 库可以很容易地获得所有这些值，我们只需要转换下载和上传速度，因为它们最初是以比特每秒为单位的。在将值写入 CSV 文件方面，我们将让 pandas 及其数据帧帮助我们更新文件，并确保每天只记录一个测试，也就是说，“日期”列将用作索引，因此每个日期只能出现一次。

现在您对我们的最终结果有了更好的了解，让我们进入代码。我将首先展示完整的脚本，然后我们将一步一步来。

这个脚本有两个主要功能:`get_new_speeds()`，负责执行互联网速度测试，以及`update_csv()`，用最新的测试结果更新保存在 CSV 文件中的数据集。

第一个函数`get_new_speeds()`中的代码与 speedtest-cli 库文档中的演示代码非常相似:创建一个`Speedtest`对象，获得执行测试的最佳服务器，获得连接的 ping，然后执行下载和上传速度测试。

唯一增加的是下载和上传速度从每秒比特转换为每秒兆比特。对于转换，我们只需将每个值除以一百万(10 的 6 次方)，四舍五入到两位小数。

`get_new_speeds()`到此为止。最后，我们返回一个三项元组，其中包含 ping(毫秒)以及下载和上传速度(都以每秒兆比特为单位)。

在`update_csv()`中，我们用新的测试结果更新数据集 CSV(它接收前面函数返回的元组作为参数)。但是，正如您在 try/except 块(第 30 到 39 行)中看到的，如果 CSV 文件不能被加载，则假定该文件不存在，因此数据集是从头开始创建的。如果数据集加载成功，`csv_dataset`数据帧代表已经存在的数据集；否则它就是一个空的数据帧。

然后(第 42 到 46 行)，我们创建一个新的单行 DataFrame，它包含今天的日期作为索引(一个在函数的第一行格式化的字符串)和每个测试速度度量的一列。

现在，我们需要将这个单行数据帧附加到数据集上(`csv_dataset`)。无论 try/except 块中出现了什么(加载现有数据集或从头创建数据集)，我们只需将这一行数据添加到`csv_dataset`数据帧中。

旧结果和新结果都在同一个数据帧中，我们需要确保没有重复的行。例如，假设您今天已经记录了一个测试，忘记了它并再次运行脚本。这意味着您现在有两行相同日期的数据，我们不能让这种情况发生，之所以选择“date”列作为索引，是因为它不想有重复的值。

这就是第 51 行发生的事情，删除重复日期的行，只保留最后一次出现的日期:

```
updated_df.loc[~updated_df.index.duplicated(keep="last")]
```

让我们打破这种界限。

`updated_df.index.duplicated()`返回一个 Numpy 数组，其中包含每个索引值的布尔值。被视为重复的值为 True，唯一的值为 False。因为我们已经向它传递了值为`last`的`keep`参数，这意味着对于每个重复值，除了最后一个之外的所有出现都将被标记为重复(True)。查看官方文档中的示例，如果我们的数据帧具有以下索引值:

```
'lama', 'cow', 'lama', 'beetle', 'lama'
```

当在其上调用`updated_df.index.duplicated(keep="last")`时，将返回下面的数组:

```
[ True, False, True, False, False ]
```

lama，重复值，只有前两次出现标记为重复(True)。最后一次出现被标记为 unique (False)，因为我们指定要保留最后一次重复出现。

既然我们知道哪些行包含重复的索引，我们需要实际删除它们。为此，我们使用了`loc[]`方法，它允许我们通过索引来定位行。幸运的是，这个方法接受布尔数组作为参数，这正是我们从调用`duplicated()`中得到的。

但是，这次行动还有最后一个细节。当遍历布尔数组时，`loc[]`将返回它接收到 True 值的行，这与标记为重复的行相对应。换句话说，`loc[]`将删除我们实际想要保留的行。因此在`updated_df.index.duplicated(keep="last")`调用前使用了波浪号(`~`)。我们接收相同的布尔数组，但是波浪号在传递给`loc[]`之前反转数组中的每个值。换句话说，数组中的每个 True 都变成 False，每个 False 都变成 True。

这就是为什么这条线

```
updated_df.loc[~updated_df.index.duplicated(keep="last")]
```

仅返回具有唯一索引的行以及具有重复索引的行的最后一次出现。`duplicated()`将索引标记为重复或唯一，然后波浪号反转这些值以确保`loc[]`只定位我们想要保留的行。

最后，现在我们有了过滤后的数据帧，我们可以将它写入 internet_speeds_dataset CSV 文件，将“Date”列标记为索引列(第 52 行)。如果文件不存在，它被创建；如果它已经存在，它会用新数据更新。

仅此而已。现在，您可以使用这个脚本来记录您的互联网速度，然后，也许，可视化的数据收集与 matplotlib，甚至微软电力 BI！