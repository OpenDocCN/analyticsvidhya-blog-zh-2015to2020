<html>
<head>
<title>Image Classification: Cats and Dogs — Pre-trained Neural Network vs Constructed</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像分类:猫和狗——预训练神经网络与构建神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-classification-cats-and-dogs-pre-trained-neural-network-vs-constructed-6370d5c79fde?source=collection_archive---------8-----------------------#2020-10-10">https://medium.com/analytics-vidhya/image-classification-cats-and-dogs-pre-trained-neural-network-vs-constructed-6370d5c79fde?source=collection_archive---------8-----------------------#2020-10-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/89ec8d0007ed555658badeda172e173b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qejv1I-FYujIjqev.jpg"/></div></figure><p id="f7f9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Python神经网络项目的第4章介绍了一个从微软提供的数据集中对猫和狗进行分类的指导性项目。在我看来，对图像进行分类的最佳方式是使用卷积神经网络(CNN)。</p><p id="8c41" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我已经使用VGG-16 CNN对澳大利亚的金矿进行了分类，这是我在熨斗学校沉浸式数据科学训练营的压轴戏项目。CNN可以用于各种图像分类和分割问题。</p><p id="21d7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这个场景是一个非常基本的分类，二进制，它甚至不需要GPU。要用CNN运行更复杂的图像分类问题，推荐使用好的GPU。对多个高分辨率图像进行分类将需要比CPU大得多的计算能力。Kaggle是利用云计算和访问GPU的一种很好的方式，但是，它有30小时/周的限制。</p><p id="976f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我碰巧能够用我的笔记本电脑CPU在大约一个半小时内为这个数据集训练一个CNN。我还使用了一个预训练的模型，VGG16，以缩短学习/训练时间并比较结果。</p><p id="efeb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下是第一个模型的代码:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="3b06" class="ju jv hi jq b fi jw jx l jy jz"><strong class="jq hj">from</strong> <strong class="jq hj">keras.models</strong> <strong class="jq hj">import</strong> Sequential<br/><strong class="jq hj">from</strong> <strong class="jq hj">keras.layers</strong> <strong class="jq hj">import</strong> Conv2D, MaxPooling2D<br/><strong class="jq hj">from</strong> <strong class="jq hj">keras.layers</strong> <strong class="jq hj">import</strong> Dropout, Flatten, Dense<br/><strong class="jq hj">from</strong> <strong class="jq hj">keras.preprocessing.image</strong> <strong class="jq hj">import</strong> ImageDataGenerator</span><span id="9bbd" class="ju jv hi jq b fi ka jx l jy jz">model = Sequential()</span></pre><p id="3e79" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[47]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="96c8" class="ju jv hi jq b fi jw jx l jy jz">FILTER_SIZE = 3<br/>NUM_FILTERS = 32<br/>INPUT_SIZE = 32<br/>MAXPOOL_SIZE = 2<br/>BATCH_SIZE = 16<br/>STEPS_PER_EPOCH = 20000//BATCH_SIZE<br/>EPOCHS = 10</span></pre><p id="b0d3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[21]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="3ba7" class="ju jv hi jq b fi jw jx l jy jz">model.add(Conv2D(NUM_FILTERS,(FILTER_SIZE,FILTER_SIZE), input_shape = (INPUT_SIZE,INPUT_SIZE,3), activation = 'relu'))</span></pre><p id="6da8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[22]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="cce5" class="ju jv hi jq b fi jw jx l jy jz">model.add(MaxPooling2D(pool_size = (MAXPOOL_SIZE,MAXPOOL_SIZE)))</span></pre><p id="7be3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[23]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="1de2" class="ju jv hi jq b fi jw jx l jy jz">model.add(Conv2D(NUM_FILTERS,(FILTER_SIZE,FILTER_SIZE), input_shape = (INPUT_SIZE,INPUT_SIZE,3), activation = 'relu'))</span></pre><p id="5490" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[24]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="bceb" class="ju jv hi jq b fi jw jx l jy jz">model.add(MaxPooling2D(pool_size = (MAXPOOL_SIZE,MAXPOOL_SIZE)))</span></pre><p id="2cac" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[25]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="065e" class="ju jv hi jq b fi jw jx l jy jz">model.add(Flatten())</span></pre><p id="a47c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[26]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="0cc0" class="ju jv hi jq b fi jw jx l jy jz">model.add(Dense(units=128,activation ='relu'))</span></pre><p id="3ba2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[27]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="1cb8" class="ju jv hi jq b fi jw jx l jy jz">model.add(Dropout(0.5))</span></pre><p id="0cc9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[28]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="8291" class="ju jv hi jq b fi jw jx l jy jz">model.add(Dense(units=1,activation = 'sigmoid'))</span></pre><p id="99ea" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[29]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="ffa7" class="ju jv hi jq b fi jw jx l jy jz">model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])</span></pre><p id="c054" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[30]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="1ed9" class="ju jv hi jq b fi jw jx l jy jz">training_data_generator = ImageDataGenerator(rescale = 1./255)</span><span id="db85" class="ju jv hi jq b fi ka jx l jy jz">training_set = training_data_generator.flow_from_directory('Dataset/PetImages/Train', target_size = (INPUT_SIZE,INPUT_SIZE),<br/>                                                          batch_size = BATCH_SIZE,class_mode='binary')<br/>model.fit_generator(training_set,steps_per_epoch = STEPS_PER_EPOCH, epochs = EPOCHS, verbose = 1)</span><span id="7d6a" class="ju jv hi jq b fi ka jx l jy jz">Found 19997 images belonging to 2 classes.<br/>WARNING:tensorflow:From C:\Users\mmsub\Anaconda3\envs\learn-env\lib\site-packages\tensorflow\python\ops\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.<br/>Instructions for updating:<br/>Use tf.cast instead.<br/>Epoch 1/10<br/>1250/1250 [==============================] - 80s 64ms/step - loss: 0.6250 - accuracy: 0.6488<br/>Epoch 2/10<br/>1250/1250 [==============================] - 76s 61ms/step - loss: 0.5393 - accuracy: 0.7292<br/>Epoch 3/10<br/>1250/1250 [==============================] - 80s 64ms/step - loss: 0.4925 - accuracy: 0.7648<br/>Epoch 4/10<br/>1250/1250 [==============================] - 84s 67ms/step - loss: 0.4660 - accuracy: 0.7787<br/>Epoch 5/10<br/>1250/1250 [==============================] - 76s 61ms/step - loss: 0.4353 - accuracy: 0.7956<br/>Epoch 6/10<br/>1250/1250 [==============================] - 76s 61ms/step - loss: 0.4123 - accuracy: 0.8112<br/>Epoch 7/10<br/>1250/1250 [==============================] - 86s 69ms/step - loss: 0.3876 - accuracy: 0.8257<br/>Epoch 8/10<br/>1250/1250 [==============================] - 84s 67ms/step - loss: 0.3650 - accuracy: 0.8354<br/>Epoch 9/10<br/>1250/1250 [==============================] - 76s 61ms/step - loss: 0.3448 - accuracy: 0.84520s - loss: 0.3<br/>Epoch 10/10<br/>1250/1250 [==============================] - 78s 62ms/step - loss: 0.3277 - accuracy: 0.8557</span></pre><p id="3ba8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[33]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="9afb" class="ju jv hi jq b fi jw jx l jy jz">testing_data_generator = ImageDataGenerator(rescale = 1./255)</span><span id="5ae9" class="ju jv hi jq b fi ka jx l jy jz">test_set = testing_data_generator.flow_from_directory('Dataset/PetImages/Test/', target_size = (INPUT_SIZE,INPUT_SIZE),<br/>                                                     batch_size =BATCH_SIZE, class_mode = 'binary')<br/>score = model.evaluate_generator(test_set,steps =len(test_set))<br/><strong class="jq hj">for</strong> idx, metric <strong class="jq hj">in</strong> enumerate(model.metrics_names):<br/>    print("<strong class="jq hj">{}</strong>: <strong class="jq hj">{}</strong>".format(metric,score[idx]))</span></pre><p id="e4d8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">OUT[33]:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="e53c" class="ju jv hi jq b fi jw jx l jy jz">Found 5000 images belonging to 2 classes.<br/>loss: 0.4586998224258423<br/>accuracy: 0.7900000214576721</span></pre><p id="f9de" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我构建的模型有相当不错的79%的准确率，但也花了一个半小时来训练。用VGG16预先训练的第二个模型花费27分钟来训练，并且具有87%的更好的准确度分数。</p><p id="4ef2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">预训练的VGG16型号代码:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="6ede" class="ju jv hi jq b fi jw jx l jy jz"><strong class="jq hj">from</strong> <strong class="jq hj">keras.applications.vgg16</strong> <strong class="jq hj">import</strong> VGG16</span></pre><p id="effc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[71]:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="2fd4" class="ju jv hi jq b fi jw jx l jy jz">INPUT_SIZE = 128<br/>vgg16 = VGG16(include_top = <strong class="jq hj">False</strong>, weights = 'imagenet',input_shape=(INPUT_SIZE,INPUT_SIZE,3))</span></pre><p id="04ce" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[72]中:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="a97f" class="ju jv hi jq b fi jw jx l jy jz"><strong class="jq hj">for</strong> layer <strong class="jq hj">in</strong> vgg16.layers:<br/>    layer.trainable=<strong class="jq hj">False</strong></span></pre><p id="c92e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[73]:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="48f1" class="ju jv hi jq b fi jw jx l jy jz"><strong class="jq hj">from</strong> <strong class="jq hj">keras.models</strong> <strong class="jq hj">import</strong> Model<br/><br/>input_ = vgg16.input<br/>output_=vgg16(input_)<br/>last_layer = Flatten(name='flatten')(output_)<br/>last_layer = Dense(1,activation ='sigmoid')(last_layer)<br/>model = Model(input=input_, output = last_layer)</span></pre><p id="3817" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[74]:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="396e" class="ju jv hi jq b fi jw jx l jy jz">BATCH_SIZE = 16<br/>STEPS_PER_EPOCH = 200<br/>EPOCHS = 3</span></pre><p id="6b72" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[75]:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="9f66" class="ju jv hi jq b fi jw jx l jy jz">model.compile(optimizer ='adam',loss = 'binary_crossentropy',metrics=['accuracy'])</span></pre><p id="48b7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[77]:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="0418" class="ju jv hi jq b fi jw jx l jy jz">training_data_generator = ImageDataGenerator(rescale = 1./255)<br/>testing_data_generator = ImageDataGenerator(rescale = 1./255)<br/><br/>training_set = training_data_generator.flow_from_directory('Dataset/PetImages/Train/', target_size=(INPUT_SIZE,INPUT_SIZE),<br/>                                                           batch_size = BATCH_SIZE, class_mode = 'binary')<br/>test_set = testing_data_generator.flow_from_directory('Dataset/PetImages/Test/',<br/>                                             target_size = (INPUT_SIZE, INPUT_SIZE),<br/>                                             batch_size = BATCH_SIZE,<br/>                                             class_mode = 'binary')<br/>model.fit_generator(training_set, steps_per_epoch = STEPS_PER_EPOCH, epochs = EPOCHS, verbose =1)</span><span id="831f" class="ju jv hi jq b fi ka jx l jy jz">Found 19997 images belonging to 2 classes.<br/>Found 5000 images belonging to 2 classes.<br/>Epoch 1/3<br/>200/200 [==============================] - 560s 3s/step - loss: 0.4012 - accuracy: 0.8041<br/>Epoch 2/3<br/>200/200 [==============================] - 575s 3s/step - loss: 0.2994 - accuracy: 0.8711<br/>Epoch 3/3<br/>200/200 [==============================] - 488s 2s/step - loss: 0.2669 - accuracy: 0.8894</span></pre><p id="8fac" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Out[77]:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="712d" class="ju jv hi jq b fi jw jx l jy jz">&lt;keras.callbacks.callbacks.History at 0x1e18ad49ba8&gt;</span></pre><p id="e973" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在[78]:</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="5f30" class="ju jv hi jq b fi jw jx l jy jz">score = model.evaluate_generator(test_set,len(test_set))<br/><br/><strong class="jq hj">for</strong> idx, metric <strong class="jq hj">in</strong> enumerate(model.metrics_names):<br/>    print("<strong class="jq hj">{}</strong>: <strong class="jq hj">{}</strong>".format(metric,score[idx]))</span><span id="016b" class="ju jv hi jq b fi ka jx l jy jz">loss: 0.6551424264907837<br/>accuracy: 0.8781999945640564</span></pre><p id="10cf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">正如我们所见，使用预先训练的模型比从头开始构建CNN要快得多，也更准确。使用预先训练好的模型的好处是，大部分工作已经完成，我们可以添加到它们上面。它们还需要更少的训练时间，这对大型数据集很重要。我的这个项目的完整代码可以在这里找到<a class="ae jk" href="https://github.com/geomms/Neural-Network-Projects-with-Python/blob/master/Chapter04-Cats%20Versus%20Dogs%20-%20Image%20Classification%20Using%20CNNs.ipynb" rel="noopener ugc nofollow" target="_blank"/>。</p></div></div>    
</body>
</html>