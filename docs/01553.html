<html>
<head>
<title>Create Tensorflow Image Classification Model with Your Own Dataset in Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Google Colab中使用您自己的数据集创建Tensorflow图像分类模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/create-tensorflow-image-classification-model-with-your-own-dataset-in-google-colab-63e9d7853a3e?source=collection_archive---------1-----------------------#2019-10-31">https://medium.com/analytics-vidhya/create-tensorflow-image-classification-model-with-your-own-dataset-in-google-colab-63e9d7853a3e?source=collection_archive---------1-----------------------#2019-10-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3ea8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文旨在展示基于自定义数据集，在Google Colab中训练用于图像分类的Tensorflow模型。我们将会看到一个TFLite模型是如何被训练并用于图像分类的。例如，我们将尝试对我们的鞋子图像进行训练和测试。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/b1ed8779727334e31ac10b81a6b656b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WbBRhlbJ24aixhv9F6Rc9Q.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">照片由<a class="ae jt" href="https://unsplash.com/@miladamasio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">卡蜜拉·达马西奥</a>拍摄</figcaption></figure><h1 id="75ca" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">准备Colab笔记本</h1><p id="f10d" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">首先你要用你的GPU进行快速训练。为此，点击“<em class="kx">运行时- &gt;更改运行时类型”</em>，将您的硬件加速器设置为GPU。</p><p id="0bc9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了在Google Colab中训练我们的模型，我们应该通过执行下面定义的一些指令来准备我们的模型；</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="56c9" class="ld jv hi kz b fi le lf l lg lh">pip install tensorflow-gpu==2.0.0-beta0<br/>pip install tensorflow_hub</span><span id="eb4b" class="ld jv hi kz b fi li lf l lg lh">from __future__ import absolute_import, division, print_function, unicode_literals</span><span id="a477" class="ld jv hi kz b fi li lf l lg lh">import matplotlib.pylab as plt</span><span id="7960" class="ld jv hi kz b fi li lf l lg lh">import tensorflow as tf</span><span id="30e5" class="ld jv hi kz b fi li lf l lg lh">import tensorflow_hub as hub</span><span id="6987" class="ld jv hi kz b fi li lf l lg lh">import numpy as np</span><span id="47d3" class="ld jv hi kz b fi li lf l lg lh">import pandas as pd</span></pre><p id="b55e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">提高显示数据的精确度，以便更好地进行并排比较</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="1a2f" class="ld jv hi kz b fi le lf l lg lh">pd.set_option("display.precision", 8)</span></pre><h1 id="7d1b" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">正在准备数据集</h1><p id="fae8" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们将使用我们的Google Drive存储来训练这个模型。您也可以<a class="ae jt" href="https://github.com/rifatcakir/TensorflowLite_Image_Classification_Training/tree/master/sample_inputs" rel="noopener ugc nofollow" target="_blank">下载</a>本文档中使用的培训文件夹。</p><p id="7c7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你应该为你的图像创建一个根目录，这是我们的“鞋_图像”。然后，您可以为您的每个实例创建一个文件夹。</p><p id="71c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比如说；</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/c8ae5b23c5be8558e5366b385e361792.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*609AMNzTRqK4ldUZnQje7Q.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Google Drive中的分类图像文件夹</figcaption></figure><p id="c464" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">只要在这些文件夹里放上和它名字对应的图片就可以了。</p><h1 id="a38f" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">连接数据集</h1><p id="025a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们连接Colab中的Google Drive，</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="ed6d" class="ld jv hi kz b fi le lf l lg lh">from google.colab import drive</span><span id="7150" class="ld jv hi kz b fi li lf l lg lh">drive.mount('/content/drive')</span></pre><p id="a203" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用存储训练数据集的驱动器帐户进行身份验证。</p><p id="ab8a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们将培训文件夹设置到data_root中。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="007f" class="ld jv hi kz b fi le lf l lg lh">data_root='/content/drive/My Drive/TFLITE/shoe_images'</span></pre><p id="d57d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建用于培训和验证的数据生成器</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="2df0" class="ld jv hi kz b fi le lf l lg lh">IMAGE_SHAPE = (224, 224)</span><span id="cecd" class="ld jv hi kz b fi li lf l lg lh">TRAINING_DATA_DIR = str(data_root)</span><span id="bfc0" class="ld jv hi kz b fi li lf l lg lh">print(TRAINING_DATA_DIR);</span><span id="bb9b" class="ld jv hi kz b fi li lf l lg lh">datagen_kwargs = dict(rescale=1./255, validation_split=.20)</span><span id="e6e2" class="ld jv hi kz b fi li lf l lg lh">valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)</span><span id="0b97" class="ld jv hi kz b fi li lf l lg lh">valid_generator = valid_datagen.flow_from_directory(</span><span id="8751" class="ld jv hi kz b fi li lf l lg lh">TRAINING_DATA_DIR,</span><span id="5a61" class="ld jv hi kz b fi li lf l lg lh">subset="validation",</span><span id="e021" class="ld jv hi kz b fi li lf l lg lh">shuffle=True,</span><span id="01a4" class="ld jv hi kz b fi li lf l lg lh">target_size=IMAGE_SHAPE</span><span id="5911" class="ld jv hi kz b fi li lf l lg lh">)</span><span id="60ef" class="ld jv hi kz b fi li lf l lg lh">train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)</span><span id="5a41" class="ld jv hi kz b fi li lf l lg lh">train_generator = train_datagen.flow_from_directory(</span><span id="8a39" class="ld jv hi kz b fi li lf l lg lh">TRAINING_DATA_DIR,</span><span id="4a9a" class="ld jv hi kz b fi li lf l lg lh">subset="training",</span><span id="2cb9" class="ld jv hi kz b fi li lf l lg lh">shuffle=True,</span><span id="ab9f" class="ld jv hi kz b fi li lf l lg lh">target_size=IMAGE_SHAPE)</span></pre><p id="7647" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">了解有关数据批处理的更多信息</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="6d7d" class="ld jv hi kz b fi le lf l lg lh">image_batch_train, label_batch_train = next(iter(train_generator))</span><span id="b230" class="ld jv hi kz b fi li lf l lg lh">print("Image batch shape: ", image_batch_train.shape)</span><span id="06f1" class="ld jv hi kz b fi li lf l lg lh">print("Label batch shape: ", label_batch_train.shape)</span><span id="cd00" class="ld jv hi kz b fi li lf l lg lh">dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])</span><span id="8102" class="ld jv hi kz b fi li lf l lg lh">dataset_labels = np.array([key.title() for key, value in dataset_labels])</span><span id="8891" class="ld jv hi kz b fi li lf l lg lh">print(dataset_labels)</span></pre><p id="dcd6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们模型的结果是:</p><p id="5ad8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图像批次形状:(32，224，224，3)标签批次形状:(32，5)[' Nike _ Air _ Max _ Plus ' ' Nike _ Court _ Royale ' ' Nike _ down shift er ' ' Nike _ Md _ Runner ' ' Nike _ night gazer ']</p></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h1 id="0c24" class="ju jv hi bd jw jx lr jz ka kb ls kd ke kf lt kh ki kj lu kl km kn lv kp kq kr bi translated">培养</h1><p id="f34a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">作为迁移学习的基础模型，我们将使用存储在TensorFlow Hub上的MobileNet v2模型。这种模式的优势在于能够在移动应用程序上工作。更多信息:<a class="ae jt" href="https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4" rel="noopener ugc nofollow" target="_blank">https://tfhub . dev/Google/tf2-preview/mobilenet _ v2/feature _ vector/4</a></p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="933b" class="ld jv hi kz b fi le lf l lg lh">model = tf.keras.Sequential([</span><span id="420d" class="ld jv hi kz b fi li lf l lg lh">hub.KerasLayer("https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4",</span><span id="9cbf" class="ld jv hi kz b fi li lf l lg lh">output_shape=[1280],</span><span id="0ec6" class="ld jv hi kz b fi li lf l lg lh">trainable=False),</span><span id="891b" class="ld jv hi kz b fi li lf l lg lh">tf.keras.layers.Dropout(0.4),</span><span id="f2bd" class="ld jv hi kz b fi li lf l lg lh">tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')</span><span id="3e5b" class="ld jv hi kz b fi li lf l lg lh">])</span><span id="48d1" class="ld jv hi kz b fi li lf l lg lh">model.build([None, 224, 224, 3])</span><span id="34e4" class="ld jv hi kz b fi li lf l lg lh">model.summary()</span><span id="6da8" class="ld jv hi kz b fi li lf l lg lh">model.compile(</span><span id="7f17" class="ld jv hi kz b fi li lf l lg lh">optimizer=tf.keras.optimizers.Adam(),</span><span id="c46e" class="ld jv hi kz b fi li lf l lg lh">loss='categorical_crossentropy',</span><span id="aa55" class="ld jv hi kz b fi li lf l lg lh">metrics=['acc'])</span></pre><p id="27e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们可以训练我们的模型。您可以修改epoches并测试准确性。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="a862" class="ld jv hi kz b fi le lf l lg lh">steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)</span><span id="6f4b" class="ld jv hi kz b fi li lf l lg lh">val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)</span><span id="68b0" class="ld jv hi kz b fi li lf l lg lh">hist = model.fit(</span><span id="911f" class="ld jv hi kz b fi li lf l lg lh">train_generator,</span><span id="7d14" class="ld jv hi kz b fi li lf l lg lh">epochs=10,</span><span id="e3ff" class="ld jv hi kz b fi li lf l lg lh">verbose=1,</span><span id="a08d" class="ld jv hi kz b fi li lf l lg lh">steps_per_epoch=steps_per_epoch,</span><span id="bb01" class="ld jv hi kz b fi li lf l lg lh">validation_data=valid_generator,</span><span id="a3de" class="ld jv hi kz b fi li lf l lg lh">validation_steps=val_steps_per_epoch).history</span></pre><p id="b34a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你会看到这样一个屏幕，</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lw"><img src="../Images/2be8507d67e5f40cf2a5db3823860ebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtZn-3wYym3dOHAP3AIvDw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">训练时刻</figcaption></figure><h1 id="23ec" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">导出模型</h1><p id="ca33" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们应该在训练后导出我们的模型。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="08ab" class="ld jv hi kz b fi le lf l lg lh">SHOE_SAVED_MODEL = "saved_models/shoe"</span><span id="a988" class="ld jv hi kz b fi li lf l lg lh">tf.keras.experimental.export_saved_model(model, SHOE_SAVED_MODEL)</span><span id="2fcc" class="ld jv hi kz b fi li lf l lg lh">shoe_model = tf.keras.experimental.load_from_saved_model(SHOE_SAVED_MODEL,</span><span id="6326" class="ld jv hi kz b fi li lf l lg lh">custom_objects={'KerasLayer':hub.KerasLayer})</span></pre><p id="2dcf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从验证数据集生成器获取图像和标签批次</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="aa47" class="ld jv hi kz b fi le lf l lg lh">val_image_batch, val_label_batch = next(iter(valid_generator))</span><span id="c458" class="ld jv hi kz b fi li lf l lg lh">true_label_ids = np.argmax(val_label_batch, axis=-1)</span><span id="7a2f" class="ld jv hi kz b fi li lf l lg lh">print("Validation batch shape:", val_image_batch.shape)</span></pre><h1 id="766a" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">测试我们的模型</h1><p id="325a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们计算整批的预测。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="fac8" class="ld jv hi kz b fi le lf l lg lh">tf_model_predictions = shoe_model.predict(val_image_batch)</span><span id="2a2c" class="ld jv hi kz b fi li lf l lg lh">tf_pred_dataframe = pd.DataFrame(tf_model_predictions)</span><span id="86f9" class="ld jv hi kz b fi li lf l lg lh">tf_pred_dataframe.columns = dataset_labels</span><span id="a0a0" class="ld jv hi kz b fi li lf l lg lh">print("Prediction results for the first elements")</span><span id="5a2c" class="ld jv hi kz b fi li lf l lg lh">tf_pred_dataframe.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lx"><img src="../Images/6fb6232c735b41b90636c2f5ff384cf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eePrKXPTJzKGXow2DHAcQw.png"/></div></div></figure><p id="0dcd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">打印图像批次和标签预测</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="8e9d" class="ld jv hi kz b fi le lf l lg lh">predicted_ids = np.argmax(tf_model_predictions, axis=-1)</span><span id="3c83" class="ld jv hi kz b fi li lf l lg lh">predicted_labels = dataset_labels[predicted_ids]</span><span id="d31b" class="ld jv hi kz b fi li lf l lg lh">plt.figure(figsize=(10,9))</span><span id="7eb9" class="ld jv hi kz b fi li lf l lg lh">plt.subplots_adjust(hspace=0.5)</span><span id="123a" class="ld jv hi kz b fi li lf l lg lh">for n in range(20):</span><span id="0c7a" class="ld jv hi kz b fi li lf l lg lh">plt.subplot(6,5,n+1)</span><span id="f8ee" class="ld jv hi kz b fi li lf l lg lh">plt.imshow(val_image_batch[n])</span><span id="f4e9" class="ld jv hi kz b fi li lf l lg lh">color = "green" if predicted_ids[n] == true_label_ids[n] else "red"</span><span id="443b" class="ld jv hi kz b fi li lf l lg lh">plt.title(predicted_labels[n].title(), color=color)</span><span id="1bf9" class="ld jv hi kz b fi li lf l lg lh">plt.axis('off')</span><span id="f273" class="ld jv hi kz b fi li lf l lg lh">_ = plt.suptitle("Model predictions (green: correct, red: incorrect)")</span></pre><p id="b61c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果会告诉我们</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/713aaedf13e309c0dea2b1b5940361ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*Nr9oFOs9LLG-ojgV78aMgw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">对一些输入图像进行测试</figcaption></figure><h1 id="336d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">将模型转换为TFLite</h1><p id="0703" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">将我们的模型转换成TFLite是如此简单。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="bed6" class="ld jv hi kz b fi le lf l lg lh">!mkdir "tflite_models"</span><span id="50ef" class="ld jv hi kz b fi li lf l lg lh">TFLITE_MODEL = "tflite_models/shoe.tflite"</span><span id="133a" class="ld jv hi kz b fi li lf l lg lh">TFLITE_QUANT_MODEL = "tflite_models/shoe_quant.tflite"</span></pre><p id="e2cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">开始转换状态，</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="6b46" class="ld jv hi kz b fi le lf l lg lh"># Get the concrete function from the Keras model.</span><span id="9506" class="ld jv hi kz b fi li lf l lg lh">run_model = tf.function(lambda x : shoe_model(x))</span><span id="ad52" class="ld jv hi kz b fi li lf l lg lh"># Save the concrete function.</span><span id="fdfa" class="ld jv hi kz b fi li lf l lg lh">concrete_func = run_model.get_concrete_function(</span><span id="b858" class="ld jv hi kz b fi li lf l lg lh">tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)</span><span id="8520" class="ld jv hi kz b fi li lf l lg lh">)</span><span id="e762" class="ld jv hi kz b fi li lf l lg lh"># Convert the model</span><span id="e446" class="ld jv hi kz b fi li lf l lg lh">converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])</span><span id="d084" class="ld jv hi kz b fi li lf l lg lh">converted_tflite_model = converter.convert()</span><span id="37f7" class="ld jv hi kz b fi li lf l lg lh">open(TFLITE_MODEL, "wb").write(converted_tflite_model)</span><span id="42c2" class="ld jv hi kz b fi li lf l lg lh"># Convert the model to quantized version with post-training quantization</span><span id="a5ed" class="ld jv hi kz b fi li lf l lg lh">converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])</span><span id="b2fe" class="ld jv hi kz b fi li lf l lg lh">converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]</span><span id="0bf1" class="ld jv hi kz b fi li lf l lg lh">tflite_quant_model = converter.convert()</span><span id="27bb" class="ld jv hi kz b fi li lf l lg lh">open(TFLITE_QUANT_MODEL, "wb").write(tflite_quant_model)</span><span id="8c6b" class="ld jv hi kz b fi li lf l lg lh">print("TFLite models and their sizes:")</span><span id="db80" class="ld jv hi kz b fi li lf l lg lh">!ls "tflite_models" -lh</span></pre><p id="d2b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经在Drive中训练了TFLite和量化的TFLite模式。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/603b79d9ce02abb0c96f59ba0fdcbada.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*lE9K1EmQkOLiG0fJfaoadw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Google Drive内容</figcaption></figure><p id="7cd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kx">想知道TFLite和量化TFLite有什么区别吗？查看下方！</em>T3】</strong></p><div class="ma mb ez fb mc md"><a rel="noopener follow" target="_blank" href="/@rifatcakira/artificial-intelligence-for-small-devices-with-tensorflow-quantization-d0aa5c581b33"><div class="me ab dw"><div class="mf ab mg cl cj mh"><h2 class="bd hj fi z dy mi ea eb mj ed ef hh bi translated">用于具有张量流量子化的小型设备的人工智能</h2><div class="mk l"><h3 class="bd b fi z dy mi ea eb mj ed ef dx translated">这篇文章探讨了张量流量化如何提高小型设备上的机器学习性能。</h3></div><div class="ml l"><p class="bd b fp z dy mi ea eb mj ed ef dx translated">medium.com</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr jn md"/></div></div></a></div><h1 id="21c1" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">源代码</h1><p id="036d" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">你可以在<a class="ae jt" href="https://colab.research.google.com/drive/1L-XkOFzTRj5x4ZqRy_TyDzuk8Cd6famu" rel="noopener ugc nofollow" target="_blank"> <em class="kx">这个colab笔记本</em> </a> <em class="kx">中找到我们是如何训练我们的模型以及我们是如何将它转化为结果的。</em></p><p id="8573" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文中使用的所有代码和数据集都可以在<a class="ae jt" href="https://github.com/rifatcakir/TensorflowLite_Image_Classification_Training" rel="noopener ugc nofollow" target="_blank"> my Github repo </a>中找到。</p><p id="27c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有，如果你喜欢这篇文章，请关注我的<a class="ae jt" rel="noopener" href="/@rifatcakira"> <em class="kx">中</em> </a>和<a class="ae jt" href="https://github.com/rifatcakir" rel="noopener ugc nofollow" target="_blank"> <em class="kx"> Github </em> </a>。它给了我创造更多的正能量:)</p></div></div>    
</body>
</html>