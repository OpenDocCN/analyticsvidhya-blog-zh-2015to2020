<html>
<head>
<title>Building Tensorflow 2.0 with GPU support and TensorRT on Ubuntu 18.04 LTS [Part 2]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Ubuntu 18.04 LTS上使用GPU支持和TensorRT构建Tensorflow 2.0第二部分]</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-tensorflow-2-0-with-gpu-support-and-tensorrt-on-ubuntu-18-04-lts-part-2-ff2b1482c0a3?source=collection_archive---------5-----------------------#2020-04-07">https://medium.com/analytics-vidhya/building-tensorflow-2-0-with-gpu-support-and-tensorrt-on-ubuntu-18-04-lts-part-2-ff2b1482c0a3?source=collection_archive---------5-----------------------#2020-04-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/678ef425c8ee1bf2c7bf742904fd7679.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LtgpwS2Ly3WDFOv_MIHFiw.png"/></div></div></figure><p id="7f5f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">欢迎回来！</p><p id="fea8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后一部分我们安装了NVIDIA驱动，CUDA和cuDNN库。本部分是它的延续，提供了安装TensorRT和Tensorflow的必要步骤。</p><p id="0c71" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第一部分:</strong> <a class="ae jo" rel="noopener" href="/@shivam.iitmandi/building-tensorflow-2-0-with-gpu-support-and-tensorrt-on-ubuntu-18-04-lts-part-1-e04ce41f885c">安装NVIDIA驱动、CUDA、cuDNN </a>。</p><p id="7dba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第二部分:</strong> <a class="ae jo" rel="noopener" href="/@shivam.iitmandi/building-tensorflow-2-0-with-gpu-support-and-tensorrt-on-ubuntu-18-04-lts-part-2-ff2b1482c0a3">安装TensorRT和Tensorflow </a>。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><p id="8fb4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jw">在Ubuntu 16.04上构建有GPU支持的Tensorflow 1.14和TensorRT，请参考此</em> <a class="ae jo" rel="noopener" href="/analytics-vidhya/building-tensorflow-1-14-with-gpu-support-and-tensorrt-on-ubuntu-16-04-84bbd356e03"> <em class="jw">链接</em> </a> <em class="jw">。</em></p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="1f34" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">步骤7:安装所需的TensorRT版本。</h1><p id="1d08" class="pw-post-body-paragraph iq ir hi is b it kv iv iw ix kw iz ja jb kx jd je jf ky jh ji jj kz jl jm jn hb bi translated">下载<em class="jw">。TensorRT — 5的deb </em>包文件从<a class="ae jo" href="https://developer.nvidia.com/nvidia-tensorrt-5x-download" rel="noopener ugc nofollow" target="_blank">到这里</a>。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="6bca" class="lj jy hi lf b fi lk ll l lm ln">$ cd ~ <em class="jw">#Or the directory containing the downloaded .deb package</em></span><span id="c24f" class="lj jy hi lf b fi lo ll l lm ln">$ sudo dpkg -i nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.0.2.6-ga-20181009_1-1_amd64.deb</span><span id="d1ad" class="lj jy hi lf b fi lo ll l lm ln">$ sudo apt-key add /var/nv-tensorrt-repo-cuda10.0-trt5.0.2.6-ga-20181009/7fa2af80.pub</span><span id="485b" class="lj jy hi lf b fi lo ll l lm ln">$ sudo apt-get update</span><span id="9595" class="lj jy hi lf b fi lo ll l lm ln">$ sudo apt-get install libnvinfer5=5.0.2-1+cuda10.0</span><span id="da0b" class="lj jy hi lf b fi lo ll l lm ln">$ sudo apt-get install libnvinfer-dev=5.0.2-1+cuda10.0</span><span id="7c4c" class="lj jy hi lf b fi lo ll l lm ln">$ sudo apt-mark hold libnvinfer5 libnvinfer-dev</span></pre><p id="4e61" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第一个命令是将目录更改为包含<em class="jw">的目录。deb </em>包的TensorRT。第二个和第三个命令分别安装存储库的元数据和它的公共GPG密钥。第四个命令是更新APT存储库缓存。第五和第六个命令安装TensorRT版本的5.0.2.6，而第六个命令是阻止他们升级(这是最令人沮丧的问题<em class="jw">)。deb </em>包)。</p><p id="fe07" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您想升级软件包，请使用以下命令:</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="6aaf" class="lj jy hi lf b fi lk ll l lm ln">$ sudo apt-mark unhold libnvinfer5 libnvinfer-dev</span></pre><h2 id="1994" class="lj jy hi bd jz lp lq lr kd ls lt lu kh jb lv lw kl jf lx ly kp jj lz ma kt mb bi translated">验证TensorRT的安装:</h2><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="c1c4" class="lj jy hi lf b fi lk ll l lm ln">$ dpkg -l | grep TensorRT</span></pre><p id="6b16" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">运行上面的命令，如果输出与下面给出的类似，TensorRT就启动并运行了。</p><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/3ce5b4b8739327270587c6471e4a4858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HHgNggCfoahTAGo6t_4eog.png"/></div></div></figure><h1 id="5eb3" class="jx jy hi bd jz ka md kc kd ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku bi translated">步骤8:构建Tensorflow 2.0</h1><h2 id="57e5" class="lj jy hi bd jz lp lq lr kd ls lt lu kh jb lv lw kl jf lx ly kp jj lz ma kt mb bi translated">构建前的步骤:</h2><ul class=""><li id="ca2f" class="mi mj hi is b it kv ix kw jb mk jf ml jj mm jn mn mo mp mq bi translated"><strong class="is hj">安装bazel版本0.26.1: </strong></li></ul><p id="01e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从<a class="ae jo" href="https://github.com/bazelbuild/bazel/releases/download/0.26.1/bazel-0.26.1-installer-linux-x86_64.sh" rel="noopener ugc nofollow" target="_blank">这里</a>下载bazel脚本文件<em class="jw">bazel-0 . 26 . 1-installer-Linux-x86 _ 64 . sh、</em>。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="4006" class="lj jy hi lf b fi lk ll l lm ln">$ cd ~ <em class="jw">#Or the directory containing the downloaded .sh package</em></span><span id="f3d0" class="lj jy hi lf b fi lo ll l lm ln">$ sudo chmod +x bazel-0.26.1-installer-linux-x86_64.sh</span><span id="2d3c" class="lj jy hi lf b fi lo ll l lm ln">$ ./bazel-0.26.1-installer-linux-x86_64.sh --user</span></pre><p id="d8f0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将目录更改为包含脚本文件的目录的第一个命令。第二个命令让系统知道文件是可执行的。在一个文件上(你的脚本)仅仅意味着，你将使它可执行。右键单击您的脚本并执行<strong class="is hj">属性</strong> - &gt; <strong class="is hj">权限</strong> - &gt; <strong class="is hj">允许将文件作为程序</strong>执行，给您留下与终端中的命令完全相同的结果。最后一个命令只是运行脚本，<code class="du mr ms mt lf b">--user</code>标志将Bazel安装到系统上的<code class="du mr ms mt lf b">$HOME/bin</code>目录，并将<code class="du mr ms mt lf b">.bazelrc</code>路径设置为<code class="du mr ms mt lf b">$HOME/.bazelrc</code>。</p><p id="22cf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将在您的系统上安装bazel。现在将其路径添加到path变量中。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="f8a2" class="lj jy hi lf b fi lk ll l lm ln">$ echo 'export PATH="$PATH:$HOME/bin"' &gt;&gt; ~/.bashrc^C</span><span id="e904" class="lj jy hi lf b fi lo ll l lm ln">$ source ~/.bashrc</span><span id="9d6e" class="lj jy hi lf b fi lo ll l lm ln">$ sudo ldconfig</span></pre><ul class=""><li id="d4f3" class="mi mj hi is b it iu ix iy jb mu jf mv jj mw jn mn mo mp mq bi translated"><strong class="is hj">安装必要的依赖项:</strong></li></ul><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="7ab6" class="lj jy hi lf b fi lk ll l lm ln">$ pip3 install -U --user pip six numpy wheel setuptools mock</span><span id="e80f" class="lj jy hi lf b fi lo ll l lm ln">$ pip3 install -U --user keras_applications==1.0.8 --no-deps</span><span id="0e9a" class="lj jy hi lf b fi lo ll l lm ln">$ pip3 install -U --user keras_preprocessing==1.0.8 --no-deps</span></pre><p id="923d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果在虚拟环境中安装，则省略<code class="du mr ms mt lf b">--user</code> <em class="jw"> </em>。</p><ul class=""><li id="fee2" class="mi mj hi is b it iu ix iy jb mu jf mv jj mw jn mn mo mp mq bi translated"><strong class="is hj">克隆tensorflow存储库并配置构建:</strong></li></ul><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="445d" class="lj jy hi lf b fi lk ll l lm ln">$ cd ~ <em class="jw">#Or the path to the directory you want to clone in</em></span><span id="2240" class="lj jy hi lf b fi lo ll l lm ln">$ git clone <a class="ae jo" href="https://github.com/tensorflow/tensorflow.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/tensorflow.git</a></span></pre><p id="ba40" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">克隆完成后，将目录更改为tensorflow，并签出到版本分支。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="9ff2" class="lj jy hi lf b fi lk ll l lm ln">$ cd tensorflow</span><span id="81eb" class="lj jy hi lf b fi lo ll l lm ln">$ git checkout r2.0</span></pre><ul class=""><li id="c569" class="mi mj hi is b it iu ix iy jb mu jf mv jj mw jn mn mo mp mq bi translated"><strong class="is hj">配置构建:</strong></li></ul><p id="885a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要在开始构建过程之前配置参数。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="c8ce" class="lj jy hi lf b fi lk ll l lm ln">$ cd tensorflow <em class="jw">#If not already in the directory</em></span><span id="5419" class="lj jy hi lf b fi lo ll l lm ln">$ ./configure</span></pre><p id="3796" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将在终端上加载一个参数解析器，询问路径和特性。像这样:</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="18e4" class="lj jy hi lf b fi lk ll l lm ln">Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3</span><span id="d431" class="lj jy hi lf b fi lo ll l lm ln">Do you wish to build TensorFlow with XLA JIT support? [Y/n]: Y</span><span id="b9e0" class="lj jy hi lf b fi lo ll l lm ln">Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N<br/><br/>Do you wish to build TensorFlow with ROCm support? [y/N]: N<br/><br/>Do you wish to build TensorFlow with CUDA support? [y/N]: Y</span><span id="41d0" class="lj jy hi lf b fi lo ll l lm ln">Do you wish to build TensorFlow with TensorRT support? [y/N]: Y</span></pre><p id="1586" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它将自动检测到CUDA、cuDNN和TensorRT的路径，如下所示:</p><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mx"><img src="../Images/ed1d2fc6d1a6d01490fd3d3b6469d564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2tvjJY3pjaohDWeJK4BDxQ.png"/></div></div></figure><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="6d92" class="lj jy hi lf b fi lk ll l lm ln">Enter the compute capability to use. Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1] {<strong class="lf hj">Enter the compute capability noted before</strong>}</span><span id="167b" class="lj jy hi lf b fi lo ll l lm ln">Do you want to use clang as CUDA compiler? [y/N]: N</span><span id="c891" class="lj jy hi lf b fi lo ll l lm ln">Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/gcc</span><span id="fcf7" class="lj jy hi lf b fi lo ll l lm ln">Do you wish to build TensorFlow with MPI support? [y/N]: N<br/><br/>Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]: -march=native<br/><br/>Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:N</span></pre><p id="2f28" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将配置构建。</p><h2 id="aaeb" class="lj jy hi bd jz lp lq lr kd ls lt lu kh jb lv lw kl jf lx ly kp jj lz ma kt mb bi translated">开始构建过程:</h2><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="acf8" class="lj jy hi lf b fi lk ll l lm ln">$ cd tensorflow <em class="jw">#If not already in the directory</em></span><span id="a81f" class="lj jy hi lf b fi lo ll l lm ln">$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package</span></pre><p id="1b4e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">***旁注***</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="0f90" class="lj jy hi lf b fi lk ll l lm ln">add "--config=mkl" if you want Intel MKL support for newer intel cpu for faster training on cpu</span><span id="369c" class="lj jy hi lf b fi lo ll l lm ln">add "--config=monolithic" if you want static monolithic build (try this if build failed)</span><span id="ef52" class="lj jy hi lf b fi lo ll l lm ln">add "--local_resources 2048,.5,1.0" if your PC has low RAM causing Segmentation fault or other related errors</span><span id="3aeb" class="lj jy hi lf b fi lo ll l lm ln">add "--config=v1"<!-- --> to build TensorFlow 1.x instead of 2.x, but that would defy the whole purpose of this article :p</span></pre><p id="e3d4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个过程需要很长时间。根据您的系统规格，可能需要2-3个小时。因此，等待和期待任何建设失败，他们应该来了。如果发生这种情况，请查看其背后的错误，并使用Google查找解决方案。如果你不明白或者找不到解决方案，请在下面评论或者尝试关闭bazel本地服务器:</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="be80" class="lj jy hi lf b fi lk ll l lm ln">$ bazel clean --expunge</span></pre><p id="d74b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">并再次运行构建过程。</p><h2 id="a95d" class="lj jy hi bd jz lp lq lr kd ls lt lu kh jb lv lw kl jf lx ly kp jj lz ma kt mb bi translated">构建后步骤:</h2><ul class=""><li id="96c1" class="mi mj hi is b it kv ix kw jb mk jf ml jj mm jn mn mo mp mq bi translated"><strong class="is hj">创造出<em class="jw"> *。要安装的张量流的文件:</em></strong></li></ul><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="fb8a" class="lj jy hi lf b fi lk ll l lm ln">$ cd tensorflow <em class="jw">#If not already in the directory</em></span><span id="769d" class="lj jy hi lf b fi lo ll l lm ln">$ bazel-bin/tensorflow/tools/pip_package/build_pip_package tensorflow_pkg</span></pre><p id="abcd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该命令将创建<em class="jw"> *。tensorflow的whl </em>文件，可以使用pip安装并将其存储在文件夹<em class="jw">即</em> <strong class="is hj"> tensorflow_pkg </strong>在tensorflow本地存储库中，</p><ul class=""><li id="0640" class="mi mj hi is b it iu ix iy jb mu jf mv jj mw jn mn mo mp mq bi translated"><strong class="is hj">用pip安装tensor flow:</strong></li></ul><p id="1a72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们有了<em class="jw"> *。whl </em>文件我们终于可以安装tensorflow了。</p><p id="73ec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果不使用虚拟环境:</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="795b" class="lj jy hi lf b fi lk ll l lm ln">$ cd tensorflow <em class="jw">#If not already in the directory</em></span><span id="0c29" class="lj jy hi lf b fi lo ll l lm ln">$ cd tensorflow_pkg$ pip3 install tensorflow*.whl</span></pre><p id="838f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于虚拟环境:</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="96b7" class="lj jy hi lf b fi lk ll l lm ln">$ sudo apt-get install virtualenv</span><span id="92d7" class="lj jy hi lf b fi lo ll l lm ln">$ cd <strong class="lf hj">{path/to/desired/directory/for/virtualenv}</strong></span><span id="8a93" class="lj jy hi lf b fi lo ll l lm ln">$ virtualenv TF_2.0 -p /usr/bin/python3</span><span id="cd9b" class="lj jy hi lf b fi lo ll l lm ln">$ source TF_2.0/bin/activate</span><span id="0001" class="lj jy hi lf b fi lo ll l lm ln">(TF_2.0)$ cd tensorflow/tensorflow_pkg</span><span id="4553" class="lj jy hi lf b fi lo ll l lm ln">(TF_2.0)$ pip3 install tensorflow*.whl</span></pre><h2 id="6956" class="lj jy hi bd jz lp lq lr kd ls lt lu kh jb lv lw kl jf lx ly kp jj lz ma kt mb bi translated">验证Tensorflow安装:**</h2><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="46b1" class="lj jy hi lf b fi lk ll l lm ln">(TF_2.0)$ python3</span><span id="8b72" class="lj jy hi lf b fi lo ll l lm ln">&gt;&gt;&gt; import tensorflow as tf</span><span id="e997" class="lj jy hi lf b fi lo ll l lm ln">&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')</span><span id="624d" class="lj jy hi lf b fi lo ll l lm ln">&gt;&gt;&gt; print(hello)</span></pre><p id="a9c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果系统输出结果，那么万岁！您已经准备好使用Tensorflow了。</p><p id="1494" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">**运行tensorflow 2.0代码时可能出现的错误是:</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="dee5" class="lj jy hi lf b fi lk ll l lm ln">Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR<br/>Failed to get convolution algorithm. This is probably because cuDNN failed to initialize</span></pre><p id="3166" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，出现此错误是因为以下两个问题之一:</p><ul class=""><li id="774f" class="mi mj hi is b it iu ix iy jb mu jf mv jj mw jn mn mo mp mq bi translated"><strong class="is hj">分配GPU内存的问题</strong></li></ul><p id="dedf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于某种原因，Tensorflow 2.0将所有可用的GPU内存分配给该进程，这导致了如上所述的复杂性，而不像1.x版本。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="9d47" class="lj jy hi lf b fi lk ll l lm ln">tf.config.experimental.set_memory_growth</span></pre><p id="4c3d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它试图只分配运行时分配所需的GPU内存:它开始时分配很少的内存，随着程序的运行，需要更多的GPU内存，它会扩展分配给TensorFlow进程的GPU内存区域。注意，我们不释放内存，因为这会导致内存碎片。</p><p id="ace8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在代码中导入tensorflow后，使用以下代码片段:</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="d7ab" class="lj jy hi lf b fi lk ll l lm ln">gpus = tf.config.experimental.list_physical_devices('GPU')<br/>if gpus:<br/>  try:<br/>    # Currently, memory growth needs to be the same across GPUs<br/>    for gpu in gpus:<br/>      tf.config.experimental.set_memory_growth(gpu, True)<br/>    logical_gpus = tf.config.experimental.list_logical_devices('GPU')<br/>    print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")<br/>  except RuntimeError as e:<br/>    # Memory growth must be set before GPUs have been initialized<br/>    print(e)</span></pre><ul class=""><li id="e816" class="mi mj hi is b it iu ix iy jb mu jf mv jj mw jn mn mo mp mq bi translated"><strong class="is hj">版本不兼容:</strong></li></ul><p id="cd77" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是最可怕的噩梦。你永远不会希望这成为理由。唯一可能的解决方案是使用兼容版本的NVIDIA驱动程序、CUDA、cuDNN Librarry和TensorRT重新开始这个过程。</p><p id="c180" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要检查安装的这些软件包的版本，请使用以下命令:</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="2418" class="lj jy hi lf b fi lk ll l lm ln"><strong class="lf hj"># NVIDIA Display Driver Version</strong><br/>$ nvidia-smi | grep "Driver Version" | awk '{print $6}' | cut -c1-</span><span id="6418" class="lj jy hi lf b fi lo ll l lm ln"><strong class="lf hj"># CUDA Toolkit Version</strong><br/>$ nvcc --version | grep "release" | awk '{print $6}'</span><span id="6dae" class="lj jy hi lf b fi lo ll l lm ln"><strong class="lf hj"># cuDNN Library Version</strong><br/>$ locate cudnn | grep "libcudnn.so." | tail -n1 | sed -r 's/^.*\.so\.//'</span><span id="b255" class="lj jy hi lf b fi lo ll l lm ln"># <strong class="lf hj">NCCL Version</strong><br/>$ locate nccl| grep "libnccl.so" | tail -n1 | sed -r 's/^.*\.so\.//'</span><span id="bab7" class="lj jy hi lf b fi lo ll l lm ln"># <strong class="lf hj">TensorRT Version</strong><br/>$ dpkg -l | grep TensorRT</span></pre><h1 id="e3c2" class="jx jy hi bd jz ka md kc kd ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku bi translated">我们完了。！</h1><p id="93cf" class="pw-post-body-paragraph iq ir hi is b it kv iv iw ix kw iz ja jb kx jd je jf ky jh ji jj kz jl jm jn hb bi translated">这都是我的想法。我希望这篇文章对你有所帮助。如果你做到了，别忘了鼓掌…这会鼓励我写更多。在下面的评论区留下你的想法和建议。如果你对这个过程有任何疑问，或者在构建过程中出现了错误，也可以在评论区留下。</p><p id="c5dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谢谢大家！爱你Tensorflow！</p><p id="23de" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一路平安！</p><p id="444d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">参考号:</strong></p><div class="my mz ez fb na nb"><a href="https://www.tensorflow.org/install/gpu" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab dw"><div class="nd ab ne cl cj nf"><h2 class="bd hj fi z dy ng ea eb nh ed ef hh bi translated">GPU支持| TensorFlow</h2><div class="ni l"><h3 class="bd b fi z dy ng ea eb nh ed ef dx translated">注意:GPU支持适用于带有CUDA卡的Ubuntu和Windows。TensorFlow GPU支持需要…</h3></div><div class="nj l"><p class="bd b fp z dy ng ea eb nh ed ef dx translated">www.tensorflow.org</p></div></div><div class="nk l"><div class="nl l nm nn no nk np io nb"/></div></div></a></div><div class="my mz ez fb na nb"><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab dw"><div class="nd ab ne cl cj nf"><h2 class="bd hj fi z dy ng ea eb nh ed ef hh bi translated">安装指南Linux :: CUDA工具包文档</h2><div class="ni l"><h3 class="bd b fi z dy ng ea eb nh ed ef dx translated">Linux上CUDA工具包的安装说明。</h3></div><div class="nj l"><p class="bd b fp z dy ng ea eb nh ed ef dx translated">docs.nvidia.com</p></div></div><div class="nk l"><div class="nq l nm nn no nk np io nb"/></div></div></a></div><div class="my mz ez fb na nb"><a href="https://docs.nvidia.com/deeplearning/sdk/cudnn-install/" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab dw"><div class="nd ab ne cl cj nf"><h2 class="bd hj fi z dy ng ea eb nh ed ef hh bi translated">cuDNN安装指南::NVIDIA深度学习SDK文档</h2><div class="ni l"><h3 class="bd b fi z dy ng ea eb nh ed ef dx translated">本cuDNN 7.6.5安装指南提供了如何安装和检查是否正确的分步说明…</h3></div><div class="nj l"><p class="bd b fp z dy ng ea eb nh ed ef dx translated">docs.nvidia.com</p></div></div></div></a></div><div class="my mz ez fb na nb"><a href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-archived/tensorrt-502/tensorrt-install-guide/" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab dw"><div class="nd ab ne cl cj nf"><h2 class="bd hj fi z dy ng ea eb nh ed ef hh bi translated">TensorRT安装指南::NVIDIA深度学习SDK文档</h2><div class="ni l"><h3 class="bd b fi z dy ng ea eb nh ed ef dx translated">本TensorRT 7.0.0安装指南提供了安装要求，以及包含在…</h3></div><div class="nj l"><p class="bd b fp z dy ng ea eb nh ed ef dx translated">docs.nvidia.com</p></div></div></div></a></div></div></div>    
</body>
</html>