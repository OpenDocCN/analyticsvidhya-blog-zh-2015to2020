<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/future-with-artificial-intelligence-understanding-neural-nets-and-a-gentle-walk-through-over-cnns-956f6fc8ab1a?source=collection_archive---------26-----------------------#2020-04-12">https://medium.com/analytics-vidhya/future-with-artificial-intelligence-understanding-neural-nets-and-a-gentle-walk-through-over-cnns-956f6fc8ab1a?source=collection_archive---------26-----------------------#2020-04-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><p id="6f32" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">那么，现在这个世界是怎么回事呢？为什么机器人通过视觉处理事物，并比人类更好地正确分类？很快我们能期待机器人和我们玩捉迷藏吗？我们临近审判日了吗？</p><p id="0a20" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">还有，在<a class="ae if" href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener ugc nofollow" target="_blank"> <em class="ig">计算机视觉</em></a><a class="ae if" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank"><em class="ig">CNN</em></a><em class="ig">’</em>s的领域里真正的嗡嗡声是什么？</p><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es ih"><img src="../Images/a03ee332878ec973c319aaafd0d6806a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xcNy6X4RTJ9jYaI7B5AQjw.jpeg"/></div></div></figure><p id="8d29" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">一大堆这样的问题现在一定在我们的脑海里直跑。因此，在用最好、最简单的方式回答这些问题之前，强烈建议你最好喝杯黑咖啡，坐下来，让我们大脑中的神经网络来完成剩下的工作。</p><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es it"><img src="../Images/b1119070597364e048af4d7acf2c2116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yvhX-yPFazqNj0OOkS1XeA.jpeg"/></div></div></figure><p id="640b" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">是的，电脑一天比一天好，这是肯定的！。世界上不是一切都越来越好吗？或者至少努力成为比现有版本稍微好一点的版本？。<em class="ig"> </em> <a class="ae if" href="https://builtin.com/artificial-intelligence" rel="noopener ugc nofollow" target="_blank"> <strong class="hj iu"> <em class="ig">人工智能</em> </strong> </a> <strong class="hj iu"> <em class="ig">的领域也是如此。</em> </strong>在这个数据驱动的世界中，受海量数据速度的影响，It不断发展，以更有效的方式学习和适应这个快速发展的世界。</p><p id="5f06" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">人工智能领域早在20世纪50年代就已经存在，约翰·麦卡锡首先创造了术语“人工智能”，后来在历史上被称为人工智能的创始人之一。然而，人们可以强烈地争辩说，人类在历史上一直在不断地致力于自动化事物，以使他们的日常生活更加舒适，减少涉及人类的错误和风险。过去，一些专家总是对A.I.    <em class="ig">表示<a class="ae if" href="https://www.forbes.com/sites/cognitiveworld/2020/12/29/ethical-concerns-of-ai/#5277b38123a8" rel="noopener ugc nofollow" target="_blank"> <strong class="hj iu"> <em class="ig">的关注；然而，今天的研究将帮助我们更好地准备和预防未来潜在的负面后果，从而享受人工智能的好处，同时避免陷阱。</em></strong></a></em></p><p id="b9ff" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">真相在这两种方法的中间；在某些方面，人工智能将使人类的工作更加舒适和简单，而另一方面，机器人和智能机器将取代人类从事不太安全的工作。然而，我在某些领域接手的这个建设性的人工智能不会对任何人类就业构成任何威胁。自动化是现代革命的真正本质，潜在地，不是所有的职业都会被摧毁；事实上，这意味着创造更多新的就业机会。</p><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es iv"><img src="../Images/422300b97f3fad4717b94c473659bdde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Vfci96vMrYkQmoeE.jpg"/></div></div><figcaption class="iw ix et er es iy iz bd b be z dx translated">图片来源:<a class="ae if" href="https://techinsight.com.vn/language/en/sparkling-profile-of-3-god-fathers-of-ai/" rel="noopener ugc nofollow" target="_blank">https://tech insight . com . VN/language/en/sparkling-profile-of-3-god-fathers-of-ai/</a></figcaption></figure><p id="415e" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">由于现代系统的计算能力增加，制造设备增加，以相对较低的成本大规模生产系统组件，也由于科学家的革命性工作，如<a class="ae if" href="https://research.google/people/GeoffreyHinton/" rel="noopener ugc nofollow" target="_blank"> <strong class="hj iu"> <em class="ig">【杰弗里·辛顿】</em></strong></a><strong class="hj iu"><em class="ig"/></strong><a class="ae if" href="https://en.wikipedia.org/wiki/Yann_LeCun" rel="noopener ugc nofollow" target="_blank"><strong class="hj iu"><em class="ig">扬·勒昆</em> </strong> </a> <em class="ig">和</em> <a class="ae if" href="https://mila.quebec/en/person/bengio-yoshua/" rel="noopener ugc nofollow" target="_blank"> <strong class="hj iu"> <em class="ig">约舒瓦·本吉奥</em> </strong> </a> <em class="ig"> </em>和许多</p><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es ja"><img src="../Images/4a247c1f33284cc72f4042c20fb883c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rNCEyZ-cqebSXDLG.gif"/></div></div></figure><p id="b737" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">现在让我们深入到<a class="ae if" href="https://algorithmia.com/blog/introduction-to-computer-vision" rel="noopener ugc nofollow" target="_blank"> <strong class="hj iu"> <em class="ig">计算机视觉</em> </strong> </a>的领域以及背后的底层神经概念。答案在于我们人类如何处理我们在现实世界中看到的事物。我们都必须知道我们的大脑是如何运作的，对于那些不知道的人，这里有一个更简单的解释。人脑是一个非常复杂的结构。它通过一个叫做<strong class="hj iu">神经元的简单单元结构发送能量脉冲，不断地交流和协调信息。</strong>数百万这样的神经元通过突触(试着想象一个人(神经元)彼此手拉手(通过树突连接)来进行适当的信息传递)相互连接。它们通过能量信号定期更新自己，在大脑中产生特定的反应，进而负责我们的日常活动。</p><figure class="ii ij ik il fd im er es paragraph-image"><div class="er es jb"><img src="../Images/1de3956d96377a6dde36cdf863394edf.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/0*TCwI31GpFopzcAs2"/></div></figure><p id="0598" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">将大脑行为直接部署到人工智能领域的概念被称为神经网络。有几种类型的神经网络，如<a class="ae if" href="https://en.wikipedia.org/wiki/Artificial_neural_network" rel="noopener ugc nofollow" target="_blank"> <strong class="hj iu"> <em class="ig">人工神经网络</em></strong></a><strong class="hj iu"><em class="ig"/></strong><a class="ae if" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank"><strong class="hj iu"><em class="ig">卷积神经网络</em></strong></a><strong class="hj iu"><em class="ig"/></strong><a class="ae if" href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="noopener ugc nofollow" target="_blank"><strong class="hj iu"><em class="ig">递归神经网络</em> </strong> </a> <strong class="hj iu"> <em class="ig">，以及许多</em> </strong>其他类型。大多数情况下，一方或另一方相互依赖才能取得有效的结果。今天，我们将集中讨论卷积神经网络(又名CNN)及其在图像处理中的作用。</p><figure class="ii ij ik il fd im er es paragraph-image"><div class="er es jc"><img src="../Images/e941c40708500759515ff770d59e184c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Bm15-zgfz-somWt07zbgXw.jpeg"/></div></figure><p id="dead" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iu">计算机如何看待一幅图像？</strong></p><p id="e758" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">当计算机查看一幅图像(将一幅图像作为输入)时，它会看到一组像素值。根据图像的分辨率和大小，它会看到一个<strong class="hj iu"> 32 x 32 x 3 </strong>的数字数组(这三个是指RGB值)。为了说明这一点，假设我们有一个JPG形式的彩色图像，其大小为480 x 480。代表性阵列将是<strong class="hj iu"> 480 x 480 x 3 </strong>。这些数字中的每一个都被赋予一个从0到255的值，这将描述像素强度。当我们进行图像分类时，这些数字对我们毫无意义，它们是计算机唯一可用的输入。这个想法是，给计算机这个数字数组，它将输出描述图像属于特定类别的概率的数字(猫是0.80，狗是0.15，鸟是0.05，诸如此类)。</p><figure class="ii ij ik il fd im er es paragraph-image"><div class="er es jd"><img src="../Images/17159d970905e7ee7941438d17586757.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/0*Gyxi69PGC1QE2laL.png"/></div></figure><h1 id="c6f8" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">我们希望计算机做什么</h1><p id="80aa" class="pw-post-body-paragraph hg hh hi hj b hk kc hm hn ho kd hq hr hs ke hu hv hw kf hy hz ia kg ic id ie hb bi translated">现在我们知道了输入和输出的问题，让我们考虑如何解决这个问题。我们希望计算机能够区分提供的所有图像，并找出使狗成为狗或猫成为猫的独特特征。这也是我们潜意识中进行的过程。当我们看一只狗的图片时，我们可以通过爪子或四条腿等可识别的特征对它进行分类。同样，计算机可以通过寻找边缘和曲线等低级特征来执行图像分类，然后通过一系列<strong class="hj iu">卷积层建立更抽象的概念。</strong></p><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es kh"><img src="../Images/10b68324c73e253f342060873edec326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3U5oH0pP4lvpb5LI.png"/></div></div><figcaption class="iw ix et er es iy iz bd b be z dx translated">CNN架构</figcaption></figure><p id="d179" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">上图所示的卷积网络有四个主要阶段:</p><ol class=""><li id="fa85" class="ki kj hi hj b hk hl ho hp hs kk hw kl ia km ie kn ko kp kq bi translated"><strong class="hj iu">卷积</strong></li><li id="ca1f" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie kn ko kp kq bi translated"><strong class="hj iu">非线性(ReLU) </strong></li><li id="1519" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie kn ko kp kq bi translated"><strong class="hj iu">汇集或子采样</strong></li><li id="077f" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie kn ko kp kq bi translated"><strong class="hj iu">分类(全连通层)</strong></li></ol><blockquote class="kw kx ky"><p id="05e0" class="hg hh ig hj b hk hl hm hn ho hp hq hr kz ht hu hv la hx hy hz lb ib ic id ie hb bi translated"><strong class="hj iu">第一阶段:召集</strong></p></blockquote><h2 id="1569" class="lc jf hi bd jg ld le lf jk lg lh li jo hs lj lk js hw ll lm jw ia ln lo ka lp bi translated">什么是卷积？</h2><p id="099d" class="pw-post-body-paragraph hg hh hi hj b hk kc hm hn ho kd hq hr hs ke hu hv hw kf hy hz ia kg ic id ie hb bi translated">理解<em class="ig">卷积</em>最简单的方法是把它想象成一个应用于矩阵的滑动窗口函数。这是一个拗口的问题，但是看一下图像就很清楚了:</p><p id="b33c" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">假设左边的矩阵代表黑白图像。每个条目对应一个像素，0代表黑色，1代表白色(对于灰度图像，通常在<strong class="hj iu"> 0 </strong>和<strong class="hj iu"> 255 </strong>之间)。滑动窗口被称为<strong class="hj iu"> <em class="ig">内核、</em> <em class="ig">滤波器、</em>或<em class="ig">特征检测器。</em> </strong>这里我们使用一个<strong class="hj iu"> 3×3滤波器，</strong>将其值与原始矩阵逐元素相乘，然后求和。为了获得完整的卷积，我们通过在整个矩阵上滑动滤波器来对每个元素重复相同的过程。</p><p id="6502" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">有人可能想知道如何处理这个问题。这里有一些直观的例子。取一个像素与其相邻像素之间的差来检测边缘:</p><figure class="ii ij ik il fd im er es paragraph-image"><div class="er es lq"><img src="../Images/0e7de8a67e0c197106c87d417e45b499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*ZCjPUFrB6eHPRi4eyP6aaA.gif"/></div><figcaption class="iw ix et er es iy iz bd b be z dx translated">与3×3滤波器卷积。来源:<a class="ae if" href="http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution" rel="noopener ugc nofollow" target="_blank">http://deep learning . Stanford . edu/wiki/index . PHP/Feature _ extraction _ using _ convolution</a></figcaption></figure><p id="619e" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">(为了直观地理解这一点，想想在图像的平滑部分会发生什么，其中一个像素的颜色等于其相邻像素的颜色:相加相消，结果值为0或黑色。如果在强度上有明显的边缘，例如从白色到黑色的过渡，可以假设有很大的差异和最终的白色值)</p><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es lr"><img src="../Images/17759c409b31a8639603aa5c25d17aba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xE2GzcfrTvypsD918UKmgA.jpeg"/></div></div><figcaption class="iw ix et er es iy iz bd b be z dx translated">泰姬陵的图片以错综复杂的矩阵形式表现出来。</figcaption></figure><blockquote class="kw kx ky"><p id="3cd7" class="hg hh ig hj b hk hl hm hn ho hp hq hr kz ht hu hv la hx hy hz lb ib ic id ie hb bi translated"><strong class="hj iu">第二阶段:非线性(ReLU) </strong></p></blockquote><p id="ecfa" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在每次卷积运算之后使用的一种称为ReLU的附加运算。ReLU代表<strong class="hj iu">整流线性单元</strong>，是<strong class="hj iu">非线性运算</strong>。其输出由下式给出:</p><figure class="ii ij ik il fd im er es paragraph-image"><div class="er es ls"><img src="../Images/10e22dec26df9b36a24a5eebff64a105.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/0*lrSYSuNRoJpbPsCB"/></div><figcaption class="iw ix et er es iy iz bd b be z dx translated">ReLU操作</figcaption></figure><p id="73b9" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">ReLU是一个基于<strong class="hj iu">元素的</strong>操作(应用于每个像素),将特征图中的所有负像素值替换为零。ReLU的目的是在我们的ConvNet中引入非线性，因为大多数真实世界的数据都希望我们的ConvNet学习非线性。(卷积是一种线性运算，即基于元素的矩阵乘法和加法，因此我们通过引入ReLU等非线性函数来解决非线性问题)。</p><p id="451a" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">从下图可以清楚地理解ReLU操作。它显示了应用于图中获得的特征映射之一的ReLU操作。这里的输出特征图被称为<strong class="hj iu">‘已校正’</strong>特征图。</p><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es lt"><img src="../Images/2c7ea3aac71975532b1ca26a40c5cb68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*--kQCRqFbRZxMFoe"/></div></div></figure><p id="757c" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">其他非线性函数，如<strong class="hj iu"> tanh </strong>或<strong class="hj iu"> sigmoid </strong>也可以用来代替ReLU，但发现ReLU在大多数情况下表现更好。</p><blockquote class="kw kx ky"><p id="2c63" class="hg hh ig hj b hk hl hm hn ho hp hq hr kz ht hu hv la hx hy hz lb ib ic id ie hb bi translated"><strong class="hj iu">第三阶段:汇集步骤</strong></p></blockquote><p id="a571" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iu">空间池</strong>(也称为子采样或下采样)减少了每个特征地图的维度，并保留了最关键的信息。空间池可以有不同的类型:<strong class="hj iu">最大、平均、总和等等。</strong></p><p id="1d97" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在最大池情况下，我们定义一个空间邻域(例如，一个2×2的窗口)，并从该窗口内的校正特征图中提取最重要的元素。除了取最丰富的元素，我们还可以取该窗口中所有元素的平均值(平均池)或总和。在实践中，因为结果更好，所以更倾向于使用最大池。</p><p id="0e20" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">下图显示了通过使用<strong class="hj iu"> 2×2窗口对矫正后的特征图(卷积+ ReLU操作后获得)进行最大汇集操作的示例。</strong></p><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es lu"><img src="../Images/ad2d3f3e2a92b94c38796a3d8d76809c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EmPtQbZUoXvBp3UE"/></div></div><figcaption class="iw ix et er es iy iz bd b be z dx translated">最大池化</figcaption></figure><p id="a545" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">我们将2 x 2窗口滑动两个单元格(也称为<strong class="hj iu">‘stride’</strong>)，并取每个区域的最大值。如图所示，这降低了我们的特征图的维数。</p><p id="bffb" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在所示的网络<strong class="hj iu">，</strong>中，汇集操作分别应用于每个特征映射(注意，由于这一点，我们从三个输入映射中获得三个输出映射)。</p><figure class="ii ij ik il fd im er es paragraph-image"><div class="er es lv"><img src="../Images/792fd9f4d85298b5670a8cf7fd0442ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/0*ZF6blJ_KLILDFH1r"/></div><figcaption class="iw ix et er es iy iz bd b be z dx translated">应用于校正的要素地图的池。</figcaption></figure><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es lt"><img src="../Images/4cd1a8e2ffc75e9934e5555e289e7980.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5PJWGj1J9QF9Bcxy"/></div></div></figure><p id="403f" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">汇集的功能是逐渐减少输入表示的空间大小。特别是，</p><p id="d2dc" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">池化使输入表示(特征维度)更小，更易于管理。</p><p id="239c" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">它减少了网络中的参数和计算量，从而控制<a class="ae if" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank"> <strong class="hj iu">过拟合</strong> </a>。</p><p id="54dd" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">使网络对输入图像中的小变换、扭曲和平移保持不变(输入中的小扭曲不会改变池化的输出，因为我们在局部邻域中取<strong class="hj iu">最大值/平均值</strong>)。</p><p id="391e" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">这有助于我们获得图像的几乎比例不变的表示(确切的术语是“<strong class="hj iu"> equivariant </strong>”)。这种方法是引人注目的，因为我们可以检测图像中的对象，而不管它们的位置。</p><h2 id="8de4" class="lc jf hi bd jg ld le lf jk lg lh li jo hs lj lk js hw ll lm jw ia ln lo ka lp bi translated">故事到此为止</h2><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es lt"><img src="../Images/8ecabeaf00eed2985b08535f857fea41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PBea3hQhMtnbULGV"/></div></div></figure><p id="2ddb" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">到目前为止，我们已经看到了<strong class="hj iu">卷积、ReLU和池化</strong>是如何工作的。理解这些层是任何CNN的基本构建块是很重要的。如上图所示，我们有两组卷积，ReLU &amp;池图层-第二个卷积图层使用六个过滤器对第一个池图层的输出执行卷积，以生成总共六个要素地图。ReLU然后被单独应用于所有这六个特征图上。然后，我们对六个校正后的特征图中的每一个分别执行<strong class="hj iu">最大池化</strong>操作。</p><p id="8d8f" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">这些层一起从图像中提取有用的特征，在我们的网络中引入非线性，并降低特征维度，同时旨在使特征在某种程度上与缩放和平移等变。</p><p id="233e" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">第二池层的输出充当全连接层的输入；下一节讨论全连接层的概念。</p><blockquote class="kw kx ky"><p id="76cc" class="hg hh ig hj b hk hl hm hn ho hp hq hr kz ht hu hv la hx hy hz lb ib ic id ie hb bi translated"><strong class="hj iu">第四阶段:全连通层</strong></p></blockquote><p id="7c11" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">全连接层是一个传统的多层感知器，在输出层使用softmax激活函数(也可以使用其他分类器，如<strong class="hj iu"> SVM </strong>，但在本文中会坚持使用<strong class="hj iu"> softmax </strong>)。术语“完全连接”意味着前一层中的每个神经元都连接到下一层中的每个神经元。</p><p id="f075" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">来自<strong class="hj iu">卷积</strong>和<strong class="hj iu">池层</strong>的输出代表输入图像的高级特征。全连接图层的目的是使用这些特征根据训练数据集将输入影像分类到不同的类别中。例如，我们着手执行的图像分类任务有四种可能的输出，如下图所示(注意，该图没有显示完全连接层中节点之间的连接)</p><figure class="ii ij ik il fd im er es paragraph-image"><div class="er es lw"><img src="../Images/c189dd9e63f5950c0e8e47d0d16f5dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/0*VX_TK37Xrldvo-_T"/></div></figure><p id="5e22" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">全连接层-每个节点都与相邻层中的所有其他节点相连</p><p id="3808" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">除了分类之外，添加全连接图层也是(通常)学习这些特征的非线性组合的一种廉价方式。卷积图层和池图层中的大多数要素可能适合分类任务，但这些要素的组合可能会更好。</p><p id="ea58" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">全连接层的输出概率之和为1。概率可以通过使用<a class="ae if" href="http://cs231n.github.io/linear-classify/#softmax" rel="noopener ugc nofollow" target="_blank"> Softmax </a>作为全连接层的输出层中的激活函数。<strong class="hj iu"> Softmax </strong>函数获取一个任意实值分数的向量，并将其压缩为一个介于零和一之间的值的向量，其总和为一。</p><h2 id="060b" class="lc jf hi bd jg ld le lf jk lg lh li jo hs lj lk js hw ll lm jw ia ln lo ka lp bi translated">将所有这些放在一起——使用反向传播进行训练。</h2><p id="aebf" class="pw-post-body-paragraph hg hh hi hj b hk kc hm hn ho kd hq hr hs ke hu hv hw kf hy hz ia kg ic id ie hb bi translated">如上所述，<strong class="hj iu">卷积+汇集</strong>层充当输入图像的特征提取器，而全连接层充当分类器。</p><p id="e1a3" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在下图中，由于输入图像是一艘船，因此船只类别的目标概率为1，其他三个类别的目标概率为0，即</p><p id="2c39" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">输入图像=船</p><p id="565d" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">目标向量= [0，0，1，0]</p><figure class="ii ij ik il fd im er es paragraph-image"><div role="button" tabindex="0" class="in io di ip bf iq"><div class="er es lt"><img src="../Images/5a643a3bce6fd1a3a4981cd1e3e0ed23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*72-kpsGkI2XQSi6t"/></div></div><figcaption class="iw ix et er es iy iz bd b be z dx translated">培训网络</figcaption></figure><p id="c8d7" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">卷积网络的整体训练过程包括:</p><ul class=""><li id="6dd8" class="ki kj hi hj b hk hl ho hp hs kk hw kl ia km ie lx ko kp kq bi translated"><strong class="hj iu">步骤1: </strong>我们用随机值初始化所有过滤器和参数/权重</li><li id="5129" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated"><strong class="hj iu">第二步:</strong>网络将训练图像作为输入，经过正向传播步骤(卷积、ReLU和汇集操作以及全连接层中的正向传播)，并找到每个类别的输出概率。</li><li id="55f7" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated">假设上面的船图像的输出概率是[0.2，0.4，0.1，0.3]</li><li id="3aa3" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated">由于第一个训练示例的权重是随机分配的，因此输出概率也是随机的。</li><li id="6921" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated"><strong class="hj iu">步骤3: </strong>计算输出层的总误差(所有四个类别的总和)</li><li id="6253" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated"><strong class="hj iu">总误差= ∑(目标概率-输出概率)</strong></li><li id="0b06" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated"><strong class="hj iu">步骤4: </strong>使用反向传播计算关于网络中所有权重的误差的<em class="ig">梯度</em>，并使用<em class="ig">梯度下降</em>更新所有滤波器值/权重和参数值，以最小化输出误差。</li><li id="2cd8" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated">权重根据它们对总误差的贡献成比例地进行调整。</li><li id="7cde" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated">当再次输入相同的图像时，输出概率现在可能是[0.1，0.1，0.7，0.1]，这更接近于目标向量[0，0，1，0]。</li><li id="9835" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated">现在，网络<em class="ig">已经学会</em>通过调整其权重/滤波器来正确分类该图像，从而减少输出误差。</li><li id="0e82" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated">像几个过滤器、过滤器尺寸、网络结构和许多其他特征这样的参数在步骤1之前已经固定。它们在训练过程中不会改变，只有过滤器矩阵和连接权重的值会更新。</li><li id="a4cf" class="ki kj hi hj b hk kr ho ks hs kt hw ku ia kv ie lx ko kp kq bi translated"><strong class="hj iu">步骤5:现在，</strong>对训练集中的所有图像重复步骤2–4。</li></ul><p id="a353" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">因此这篇文章应该是理解CNN的一个好的开始，这绝不是一个全面的概述。它旨在给CNN的世界一个连续的开始。关于这一点，一篇关于CNN 在M <strong class="hj iu"> edium的程序化实施的文章将很快发表在</strong> real time上。直到<strong class="hj iu">保持安全</strong>和<strong class="hj iu">健康</strong>！</p><p id="cb5d" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iu">进一步参考和感谢:</strong> <br/> 1。<a class="ae if" href="https://techinsight.com.vn/language/en/sparkling-profile-of-3-god-fathers-of-ai/" rel="noopener ugc nofollow" target="_blank">https://tech insight . com . VN/language/en/sparkling-profile-of-3-god-fathers-of-ai/</a><br/>2 .<a class="ae if" href="https://cacm.acm.org/magazines/2019/6/236990-neural-net-worth/fulltext?mobile=false" rel="noopener ugc nofollow" target="_blank">https://cacm . ACM . org/magazines/2019/6/236990-neural-net-worth/full text？mobile=false </a> <br/> 3。<a class="ae if" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank">https://towards data science . com/a-comprehensive-guide-to-convolutionary-neural-networks-the-Eli 5-way-3bd2b 1164 a53</a><br/>4 .<a class="ae if" href="https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/" rel="noopener ugc nofollow" target="_blank">https://adeshpande 3 . github . io/A-初学者% 27s-理解指南-卷积神经网络/ </a> <br/> 5。<a class="ae if" href="https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/convolutionary-layers-for-deep-learning-neural-networks/</a><br/>6 .<a class="ae if" href="http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution" rel="noopener ugc nofollow" target="_blank">http://deep learning . Stanford . edu/wiki/index . PHP/Feature _ extraction _ using _ convolution</a>T20】7 .<a class="ae if" href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/" rel="noopener ugc nofollow" target="_blank">http://www . wild ml . com/2015/11/understanding-convolutionary-neural-networks-for-NLP/</a><br/>8 .<a class="ae if" href="https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/" rel="noopener ugc nofollow" target="_blank">https://www . freecodecamp . org/news/an-intuitive-guide-to-convolutionary-neural-networks-260 C2 de 0a 050/</a><br/>9 .<a class="ae if" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" rel="noopener ugc nofollow" target="_blank">https://ujjwalkarn . me/2016/08/11/直观-解释-convnets/ </a></p></div></div>    
</body>
</html>