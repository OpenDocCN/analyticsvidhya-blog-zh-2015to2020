<html>
<head>
<title>Gradient Boosting — A birds eye view into one of the most widely used ML Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">梯度增强——最广泛使用的最大似然算法之一的鸟瞰图</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/gradient-boosting-a-birds-eye-view-into-widely-used-ml-algorithm-part-2-6684c68fc262?source=collection_archive---------16-----------------------#2019-10-11">https://medium.com/analytics-vidhya/gradient-boosting-a-birds-eye-view-into-widely-used-ml-algorithm-part-2-6684c68fc262?source=collection_archive---------16-----------------------#2019-10-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="21f2" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">第2部分:可视化、直觉和梯度推进的实际演示</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/df3a5cf3e8e813350c8ddbe24f5363a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*t8OQ_xWBbqUUJaGT"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae jn" href="https://unsplash.com/@kmuza?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Carlos Muza </a>拍摄的照片</figcaption></figure><p id="b1f3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我的上一篇文章中，我简要解释了梯度推进算法背后的数学原理。尽管理解任何最大似然算法的本质对于它的应用都是必不可少的，但它还不足以充分发挥它的潜力。在这篇文章中，我将使用可视化来提供梯度推进算法的良好直觉，以及每个估计器(在这种情况下是决策树)如何在预测的最终集成中做出贡献。</p><p id="6bdd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我以前的文章中，我已经解释了“适合梯度”是什么意思。你可以在下面找到文章的链接:</p><p id="ae92" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><a class="ae jn" rel="noopener" href="/@palash.jhr/gradient-boosting-a-birds-eye-view-into-widely-used-ml-algorithm-a95db080d256">https://medium . com/@ palash . jhr/gradient-boosting-a-birds-eye-view-into-wide-used-ml-algorithm-a95db 080d 256</a></p><p id="3793" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在损失函数为均方误差(MSE)的典型回归任务中，以下等式成立:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kk"><img src="../Images/7cc7c436aa840ae50354bfa407f7dee2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*U-PJ5ZOfQuX5ULN3zwHXQg.png"/></div></figure><p id="3dba" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">请注意，我将1/2乘以平方损耗，这不会产生任何影响，因为最小化平方损耗与最小化一半平方损耗是一样的。</p><p id="f57f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如我在上一篇文章中解释的</p><div class="kl km ez fb kn ko"><a rel="noopener follow" target="_blank" href="/@palash.jhr/gradient-boosting-a-birds-eye-view-into-widely-used-ml-algorithm-a95db080d256"><div class="kp ab dw"><div class="kq ab kr cl cj ks"><h2 class="bd hj fi z dy kt ea eb ku ed ef hh bi translated">梯度推进——对广泛使用的ML算法的鸟瞰</h2><div class="kv l"><h3 class="bd b fi z dy kt ea eb ku ed ef dx translated">理解梯度增强背后的数学。</h3></div><div class="kw l"><p class="bd b fp z dy kt ea eb ku ed ef dx translated">medium.com</p></div></div></div></a></div><p id="9394" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">通过优化找出区域，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kx"><img src="../Images/383f407805f3ce14ba74dad8e7d8da60.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*JzIb3Rz0bzyEdKjf-e-zGw.png"/></div></figure><p id="2f08" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">并且通过优化给出预测，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ky"><img src="../Images/bb7888da1d014dbb4a9a731c53e7ee7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*GZC7lpm4zQqnuFxj-1VS6Q.png"/></div></figure><p id="6e41" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果损失函数是MSE，那么在这种情况下，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es et"><img src="../Images/75d909d8a3ee5786b9a77b71eb22af0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QNKwsEq41_8ZpE18KAlDZA.png"/></div></div></figure><p id="2e9a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，等式(B)现在可以写成:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kz"><img src="../Images/52d52646dff15b0fe0f2465863f003c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*he_FMN89m_Nz5jWjfby6eg.png"/></div></figure><p id="0e03" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，每个实例<strong class="jq hj"><em class="la">【I】</em></strong>将属于某个区域Rj(树的末端叶子)，并且对于每个Rj将有一个预测值。这些值是通过等式(c)获得的<strong class="jq hj"> γj </strong>和通过等式(a)获得的T(x,ʘ。因为等式(A和C)都在优化每个区域平方损失函数，</p><p id="3749" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们可以这么说，</p><p id="5a06" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">γj = T(xi,ʘ)为i ͼ Rj</p><p id="2c18" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，等式(C)现在可以写成:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lb"><img src="../Images/e2cf4de8bf0a740f92e4ae7bfa31b887.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*jNhzpOU_0gZplBs2C-CNHQ.png"/></div></figure><p id="15a4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">其中，</strong></p><p id="18d9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">T(x,ʘ)是ʘ.地区的预测值</p><p id="c0bc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，现在用于生长下一棵树的后续优化目标函数是:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lb"><img src="../Images/15acb1967f091865704e7d691be53557.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*EoGdyt6r8BWhRBwNdrO5ow.png"/></div></figure><p id="d435" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="la">为了找到最佳区域，</em></p><p id="0a3a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">和</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lc"><img src="../Images/2c2c56166dd9a46d99efb887fde930a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*U42-Ooh-uQSDrNX9ig1m_g.png"/></div></figure><p id="a1c7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="la">用于评估对一个地区的预测。</em></p><p id="8886" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这些等式(A和E)与生成决策树是一样的。然而，请注意，这里后续的树是在梯度为负的<strong class="jq hj"> (-gi)上生长的，该梯度等于来自先前基本估计器的残差</strong>(来自等式2)。</p><p id="63d1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，使用MSE作为损失函数的梯度推进等价于在来自先前估计器的残差上拟合随后的基础估计器(决策树)。T3】</p><h1 id="758f" class="ld le hi bd lf lg lh li lj lk ll lm ln io lo ip lp ir lq is lr iu ls iv lt lu bi translated"><strong class="ak">逐步实施梯度推进</strong></h1><p id="3567" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">下面是我在本文中用于演示的样本数据图:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ma"><img src="../Images/a79f663b904519b89c1556c7388eb5a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*ZawdWn--etkj7IUgiaJMIQ.png"/></div></figure></div><div class="ab cl mb mc gp md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="hb hc hd he hf"><p id="3155" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这一节中，我已经展示了不同的估计量如何拟合先前的残差，以及这些基本估计量的集合如何逐渐拟合数据。为了实现这一点，遵循以下步骤:</p><p id="666b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">1.使用解释变量x和响应变量y拟合第一个决策树。</p><p id="0510" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">2.评估第一个决策树(resd_1)的残差，并使用解释变量x和响应变量resd_1拟合第二个决策树。</p><p id="724f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对来自第一决策树和第二决策树的预测求和，以产生总预测。</p><p id="6775" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">3.评估第二个决策树(resd_2)的残差，并使用解释变量x和响应变量resd_2拟合第三个决策树。</p><p id="eda5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">将来自第一、第二决策树和第三决策树的预测相加，以产生总预测。</p><p id="7c3f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">4.类似地，对随后的树进行上述计算。</p><p id="ac88" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="la">遵循上述程序，观察到以下结果</em></p><p id="c7d0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">集合中树的数量为1时的模型拟合</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mi"><img src="../Images/8c0f1ef8f97c40683e8fc4bece1148ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aKspYo3eTBYTX7-zevpB0w.png"/></div></div></figure><p id="46ef" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">集合中的树数为2时的模型拟合</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mj"><img src="../Images/c0e4391d34a4631b6ed2ac801f98aee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*Z2m5iznjRknIl1CFRueA0A.png"/></div></figure><p id="d3ff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">集合中的树数为3时的模型拟合</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mk"><img src="../Images/8a156e67d0789a48c520d41e33f19dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*kEiUU_NGP883a3OLTvh7_A.png"/></div></figure><p id="79a3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">集合中的树数为4时的模型拟合</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ml"><img src="../Images/7e11e9f74ba4e705877ab19bfe52c667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*RfkkZFs-E5RmU3sE6NAt-Q.png"/></div></figure><p id="676a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">可以看出，每个估计器拟合来自先前估计器的残差，并且它们的集合逐渐拟合原始数据。</p><h1 id="114d" class="ld le hi bd lf lg lh li lj lk ll lm ln io lo ip lp ir lq is lr iu ls iv lt lu bi translated"><strong class="ak"> Scikit学习梯度增强的实现</strong></h1><p id="be68" class="pw-post-body-paragraph jo jp hi jq b jr lv ij jt ju lw im jw jx lx jz ka kb ly kd ke kf lz kh ki kj hb bi translated">在本节中，我使用了scikit learn实现梯度增强。虽然由于scikit-learn实现中使用了不同的hyper参数，结果与上述结果不完全相同，但是先前实现和scikit-learn实现之间的结果模式的相似性足以给出梯度增强算法如何在幕后工作的合理直觉。</p><p id="5fb8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">使用的超级参数有:</p><p id="f44c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">学习率</strong> = 0.1</p><p id="1d4e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">最大深度</strong> = 2</p><p id="4b26" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">n _估计量</strong> = 250</p><p id="8740" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">以下是MSE v/s拟合树数的图表:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kk"><img src="../Images/06b8f16e6063e59cb7bf9754b046d6d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*rkNNue51kM4EvRD9luJPMg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd lf"> MSE V/S树木数量</strong></figcaption></figure><p id="b588" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">可以看出，MSE在大约100棵树处弯曲。虽然随着树木数量的增加，MSE会进一步降低，但继续增加树木数量并不是明智的选择。<em class="la">(其原因是数据过度拟合的可能性，偏差方差权衡，这将在不同的文章中讨论)</em></p><p id="a3bf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，对于所选的超参数，看起来树的数量接近100是最佳的。</p><p id="b197" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">注意，这里我使用了最大深度2。也就是说，每棵树将只有4个终端节点<strong class="jq hj"> <em class="la">。在任何提升算法中，需要控制每个估计器的复杂度。boosting的思想是每个估计器的表现应该比随机情况稍好，然后我们使用boosting来改进每个阶段的预测，然后集合每个估计器的预测来产生最终预测。</em>T3】</strong></p><p id="287a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">下面我展示了不同数量的树的集合是如何拟合scikit-learn实现的数据的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/79e795e945c54b5b58e3e7d0e8533921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KA_krhiyRQ1NlBE5mSEiMQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd lf">树的数量是1(左边)，树的数量是50(右边)</strong></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/11c2dcfb39e022509d5362590944c076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dfq9DFM5LCnSiyT1qIAqcA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd lf">左侧的树数是150，右侧的树数是250</strong></figcaption></figure><p id="fb39" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">可以看出，随着估计数的增加，模型更适合数据。然而，当估计器的数量达到150，250时，它开始模拟噪声，这似乎对任何最大似然模型都不好。因此，识别学习率、最大深度和估计器数量的正确组合是适当调整梯度推进模型的关键。</p><p id="9c94" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">梯度推进非常灵活，通常可以很好地执行各种ML任务(分类和回归)。有大量的hyper参数<em class="la">(查看sklearn文档)</em>需要调整，这可能会给初学者带来一些麻烦。然而，sklearn中有各种模型选择方法，如GridsearchCV、RandomizedSearchCV等，可以用来对算法进行微调。</p><p id="607a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">损失函数的选择也是选择的重要参数。有许多损失函数可以使用。一些例子是指数(分类)、偏差(分类)、最小绝对偏差(回归)、MSE(回归)。使用不同的损失函数会导致不同的算法性能。例如，如果我们使用指数损失函数，那么梯度增强将与AdaBoost算法相同。甚至，当选择指数损失函数时，梯度推进调用SAMME。r算法，用于AdaBoost分类器。</p><p id="e52b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我想用一句告诫的话来结束我的文章。提升算法和梯度提升算法很容易很快过度拟合数据，因此在使用这些算法和部署这些算法以生成真实世界问题的预测时必须非常小心。有不同的方法来检查我们是否真的过度拟合了数据，尽管这是不同文章的主题。</p></div></div>    
</body>
</html>