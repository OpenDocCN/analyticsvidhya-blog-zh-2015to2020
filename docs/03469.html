<html>
<head>
<title>End-to-End Hyperparameter Tuning with Katib, Tensorflow, Keras and Nvidia GPU on a gaming laptop</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在游戏笔记本电脑上使用Katib、Tensorflow、Keras和Nvidia GPU进行端到端超参数调整</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hyperparameter-tuning-with-katib-tensorflow-keras-and-nvidia-gpu-on-a-gaming-laptop-3ada6a8a01a9?source=collection_archive---------4-----------------------#2020-02-03">https://medium.com/analytics-vidhya/hyperparameter-tuning-with-katib-tensorflow-keras-and-nvidia-gpu-on-a-gaming-laptop-3ada6a8a01a9?source=collection_archive---------4-----------------------#2020-02-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b147" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当谈到可扩展的GPU加速的机器学习应用程序时，并不是每个人都有在云中加入<a class="ae jd" href="https://www.youtube.com/watch?v=dIZt-Ahzew0" rel="noopener ugc nofollow" target="_blank">大规模kubernetes集群</a>的奢侈。如果您没有花大价钱购买多GPU服务器，那么熟悉允许您这样做的工具和方法也是很重要的。</p><p id="d1a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，如果你是一个精力充沛的数据科学家，只有一台运行Ubuntu的GPU机器，你会很高兴。继续阅读，也许你最终会使用Kubeflow在单个GPU中同时训练多个深度学习模型。或者像我一样，使用Katib调整一些超参数，从GPU中挤出每一滴内存。</p><p id="02e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不用担心，代码可用:【https://github.com/fabiononato/do-katib T2】</p><h1 id="cd1d" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">重大免责声明</h1><p id="60d9" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">这个博客并不打算成为一个完整的操作指南，而是为那些喜欢探索机器学习和数据科学作为工程学科的人收集了一些提示和技巧。我会确保沿途放置链接，以帮助端到端的故事。</p><p id="f37a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将涵盖Kubernetes、容器和Kubeflow的概念，这些概念不一定是数据科学家的日常工作。但希望这足以让一个人开始。</p><p id="10db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将这篇文章分成以下几个部分:<strong class="ih hj">钻机</strong>——在那里你会找到更多关于我正在使用的机器的信息。Kluster  —围绕如何建立单节点Kubernetes集群和部署所有所需应用程序的建议集合。<strong class="ih hj">代码</strong> —我们将使用一个示例<a class="ae jd" href="https://github.com/fabiononato/do-katib" rel="noopener ugc nofollow" target="_blank">开源项目</a>来测试我们的部署，并查看我们正在使用的工具的具体需求。最后<strong class="ih hj">运行</strong>——使用Kubeflow Katib对超参数调谐进行执行和监控的快速入门指南。</p><h1 id="efa0" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">钻机</h1><p id="81ce" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">我用来部署这个单节点集群的机器是一台<a class="ae jd" href="https://www.asus.com/us/Laptops/ROG-ZEPHYRUS-S-GX701/" rel="noopener ugc nofollow" target="_blank">华硕ROG游戏笔记本电脑</a>，配有英伟达GTX 1070 8GB，运行Ubuntu 18.04。除了必须设置Docker、CUDA和适当的NVIDIA驱动程序之外，对系统本身没有什么需要做的。我知道这不一定是一个简单的任务，所以这里有一个<a class="ae jd" href="https://gist.github.com/fabiononato/be351e39b34497530156a3103b22e985" rel="noopener ugc nofollow" target="_blank">要点</a>来帮助你开始。</p><p id="b35b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运行Ubuntu 18.04带来了开箱即用的<a class="ae jd" href="https://snapcraft.io/microk8s" rel="noopener ugc nofollow" target="_blank"> Snap </a>的好处，这就是我们将用来配置我们的集群。你会注意到，这种设置也可以在具有单个或多个GPU的云实例上复制，在已经为深度学习应用程序加载了所有驱动程序的虚拟机上复制。</p><h1 id="08f6" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">克鲁斯特号</h1><p id="603c" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated"><em class="kh">这就是乐趣的开始！</em></p><p id="dfd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用一个漂亮的工具来部署kubernetes集群:<a class="ae jd" href="https://snapcraft.io/microk8s" rel="noopener ugc nofollow" target="_blank"> Microk8s </a>。这非常简单，有几个教程可用，包括一个来自Ubuntu的教程，这就是我们所需要做的:<a class="ae jd" href="https://tutorials.ubuntu.com/tutorial/install-a-local-kubernetes-with-microk8s" rel="noopener ugc nofollow" target="_blank"> Kubernetes on Ubuntu教程</a></p><p id="299d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在跳head first之前，有几件事你需要知道。正如我们所说的，Microk8s的开发正在全速前进，最新版本1.17已经承诺将Kubeflow作为一个插件。在这篇博客中，我们将探索如何部署Kubeflow，但1.17版应该是一个非常方便的快捷方式。考虑到这一点，我们将一直追溯到1.15版，这样我们就可以将docker作为默认的<em class="kh"> kubelet运行时</em>。</p><p id="0796" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们休息一下…前一段中太多的术语和一些想当然的概念。不要害怕！让我写下必要的步骤，以确保我们部署Kubeflow时一切正常。</p><p id="5935" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，应该安装带有标志<code class="du ki kj kk kl b"> — channel=1.15/stable</code>的microk8s</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="5132" class="ku jf hi kl b fi kv kw l kx ky">snap install microk8s --classic --channel=1.15/stable</span></pre><p id="142a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦完成，确保运行<code class="du ki kj kk kl b">microk8s.inspect </code>来检查您的<em class="kh"> IPTables </em>规则是否设置正确。一切就绪后，我们需要通过运行<code class="du ki kj kk kl b">microk8s.enable dns storage gpu</code>来启用dns、存储和GPU。</p><p id="a7e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要检查集群状态，您可以运行:</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="9fb4" class="ku jf hi kl b fi kv kw l kx ky">microk8s.kubectl get all --all-namespaces</span></pre><figure class="km kn ko kp fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kz"><img src="../Images/dcc2fa7ac35e0112bff25f3cd9945628.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0bH5Ri3SB4gQCCgM"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">一旦你的集群看起来有点像这样，我们就快成功了。</figcaption></figure><p id="ee8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们确保我们已经正确启用了GPU，并且我们的docker守护程序将运行Nvidia运行时。</p><p id="3518" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们检查在用<code class="du ki kj kk kl b">microk8s.kubectl describe node</code>描述节点时，是否将<code class="du ki kj kk kl b">nvidia.com/gpu: 1</code>视为可分配的资源。如果没有，让我们在kubelet配置中添加几行代码。</p><p id="1d96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，在<code class="du ki kj kk kl b">/var/snap/microk8s/current/args</code>下，我们需要将<code class="du ki kj kk kl b"> — container-runtime=docker</code>添加到kubelet文件中。您的本地docker安装的docker应该包含标志<code class="du ki kj kk kl b">“default-runtime”: “nvidia”</code>，这使得您的所有docker运行命令运行nvidia运行时。该文件通常位于:<code class="du ki kj kk kl b">/etc/docker/daemon.json</code>下。即使可分配的GPU从一开始就存在，作为一种安全措施，我通常会检查运行时。</p><p id="2edd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，部署Kubeflow就像遵循本教程的部署部分一样简单:<a class="ae jd" href="https://www.docker.com/blog/depend-on-docker-for-kubeflow/" rel="noopener ugc nofollow" target="_blank">依赖于Kubeflow的Docker</a>。我再一次把你的注意力带到老的Kubeflow版本0.6.2。这里有一个简单的原因，它更适合单主机部署。我们不必过多地处理单节点kubernetes中的负载平衡器。但是请放心，所有的功能都可以让我们烧掉GPU！</p><p id="47f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后一件事是使用以下命令对部署的入口网关进行端口转发:</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="2aa4" class="ku jf hi kl b fi kv kw l kx ky">microk8s.kubectl port-forward -n istio-system svc/istio-ingressgateway 8081:80 </span></pre><p id="b8a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这为我们提供了位于http://localhost:808  1的Kubeflow UI。</p><h1 id="5315" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">代码</h1><p id="51d3" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">Habemus Kubeflow，现在呢？</p><p id="c5b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kubeflow本身可以做很多事情。管道、整流罩等。事实上，全新的部署为您提供了在单节点群集中运行的30多个pod:</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="2559" class="ku jf hi kl b fi kv kw l kx ky">microk8s.kubectl get pods -n kubeflow</span></pre><figure class="km kn ko kp fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ll"><img src="../Images/944e5210ca878b3a737958c0838f8cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*J1-SyVyvBqMk7oRt"/></div></div></figure><p id="d65f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将重点关注<a class="ae jd" href="https://www.kubeflow.org/docs/components/hyperparameter-tuning/hyperparameter/" rel="noopener ugc nofollow" target="_blank">卡提卜</a>。基本的概念是:如果您有一项工作需要接受参数并筛选度量，那么您可以在Katib中使用不同的算法来搜索这些度量的最小/最大值。</p><blockquote class="lm ln lo"><p id="bcc8" class="if ig kh ih b ii ij ik il im in io ip lp ir is it lq iv iw ix lr iz ja jb jc hb bi translated">简单。</p></blockquote><p id="c5f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以这些论点就是我们所说的超参数，而度量就是我们的目标。在这种情况下，单一目标，因为Katib不是为运行多目标优化而构建的。我将让您更深入地了解有哪些算法，<a class="ae jd" href="https://www.kubeflow.org/docs/components/hyperparameter-tuning/experiment/#search-algorithms-in-detail" rel="noopener ugc nofollow" target="_blank">这里是开始的地方</a>。</p><p id="f85d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您已经熟悉python中的主要机器学习框架，您可能已经在考虑如何编写代码来接受参数并打印出指标。在全力以赴之前，请确保遵守一些概念，这将使你与Katib的生活更加轻松。</p><p id="e130" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一部分是如何接受论点。Katib有一种非常奇特的方式来为你提供这些输入参数。我们需要熟悉python中的<a class="ae jd" href="https://pypi.org/project/argparse/" rel="noopener ugc nofollow" target="_blank"> argparse库</a>。您可以在这里查看一个简单的例子<a class="ae jd" href="https://github.com/fabiononato/do-katib/blob/master/Container-Root/src/my_awesome_model.py" rel="noopener ugc nofollow" target="_blank">使用argparse参数作为参数，将模型训练作业包装在一个方法中。</a></p><figure class="km kn ko kp fd la"><div class="bz dy l di"><div class="ls lt l"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">使用argparse进行方法调用的简单模板</figcaption></figure><p id="5971" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将输出打印到屏幕上也需要遵守Katib形式主义，不过这很容易，只需遵循docs: <a class="ae jd" href="https://www.kubeflow.org/docs/components/hyperparameter-tuning/experiment/#metrics-collector" rel="noopener ugc nofollow" target="_blank"> Metrics Collection </a>中的打印方案。</p><p id="f455" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您正在运行一个Keras模型，比如我们示例中的模型，收集指标的最佳解决方案是在<code class="du ki kj kk kl b">.fit()</code>方法上设置<code class="du ki kj kk kl b">verbose=0</code>，并在每次我们想要绘制指标时添加一个<code class="du ki kj kk kl b">callbacks</code>。你可以在我们的项目或者下面查看一个<a class="ae jd" href="https://github.com/fabiononato/do-katib/blob/master/Container-Root/src/my_awesome_model.py#L14" rel="noopener ugc nofollow" target="_blank">例子回调。</a></p><figure class="km kn ko kp fd la"><div class="bz dy l di"><div class="ls lt l"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">将指标打印到屏幕的示例Keras回调方法</figcaption></figure><p id="368c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，对于这个难题最关键的部分:将单个GPU训练分成两个任务。为此，我们将利用tensorflow中的这个漂亮特性，它允许为每个tf会话分配部分GPU。</p><p id="8db0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对enable的方法调用如下所示:</p><figure class="km kn ko kp fd la"><div class="bz dy l di"><div class="ls lt l"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">Tensorflow和Keras中的部分GPU分配示例</figcaption></figure><p id="3f4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://github.com/fabiononato/do-katib/blob/master/Container-Root/src/my_awesome_model.py#L34" rel="noopener ugc nofollow" target="_blank">在我们的示例项目</a>中，GPU分配被设置为接受另一个输入参数，这使我们能够根据可用的基础设施灵活地分割GPU内存。</p><p id="ebec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的示例模型可以使用大约3GB的内存安全地进行训练。这意味着这个钻机在任何时候至少有两个平行的模型。在我们的实验中，我们将它设置为总内存的0.35–35%，这样我就不会扼杀GPU内存。如果我碰巧有一台32GB的V100，我们可以同时运行10次实验。</p><h1 id="b293" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">跑步</h1><p id="587e" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">现在，是激动人心的时刻了！</p><p id="3045" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要的不仅仅是python脚本。至于任何其他的Katib实验，我们需要我们项目的容器化版本。幸运的是，我们可以利用像<a class="ae jd" href="https://github.com/iankoulski/depend-on-docker" rel="noopener ugc nofollow" target="_blank">依赖码头</a>这样的东西来做到这一点。我们的示例项目已经完全容器化，可以通过Docker Hub 获得<a class="ae jd" href="https://hub.docker.com/repository/docker/fabiononato/do-katib" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="a209" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">项目报告包含<a class="ae jd" href="https://github.com/fabiononato/do-katib/tree/master/katib" rel="noopener ugc nofollow" target="_blank"> YAML模板</a>我们将需要从命令行启动kubeflow中的实验。在kubernetes中，大多数脏活都是通过控制平面完成的，这意味着发出<code class="du ki kj kk kl b">kubectl</code>命令，比如:</p><pre class="km kn ko kp fd kq kl kr ks aw kt bi"><span id="6f0e" class="ku jf hi kl b fi kv kw l kx ky">microk8s.kubectl apply -f <a class="ae jd" href="https://raw.githubusercontent.com/fabiononato/do-katib/master/katib/random-experiment.yaml" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/fabiononato/do-katib/master/katib/random-experiment.yaml</a></span></pre><figure class="km kn ko kp fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lu"><img src="../Images/1ccd37bc22b619e181ebc8c11d37052f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AHwFE0TAiHipMCwZrUDlbQ.png"/></div></div></figure><p id="47cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">是的，上面一行应该可以启动您的实验，即使您不需要克隆基本repo或提取docker映像。Kubernetes就是这样有趣。我们还可以在文档中从UI 中了解更多关于<a class="ae jd" href="https://www.kubeflow.org/docs/components/hyperparameter-tuning/experiment/#running-the-experiment-from-the-katib-ui" rel="noopener ugc nofollow" target="_blank">运行实验的信息。</a></p><p id="df7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们看到了<code class="du ki kj kk kl b">Experiment Created</code>输出，我们现在可以在Katib UI中查看我们的结果。</p><figure class="km kn ko kp fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lv"><img src="../Images/fc0311947a86889869047cdf437170eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*boiclYydDLlog12K53HrzA.png"/></div></div></figure><p id="25db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于那些喜欢将结果和运行结果保存在一个文件中的人来说，只需执行<code class="du ki kj kk kl b">microk8s.kubectl get trials -o json &gt; trials.json</code>就可以获得一个包含每次运行所有信息的json文件。</p><p id="a11b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了确保我们将GPU挤压到最后一滴，我们可以开始观察我们正在运行的实验的<code class="du ki kj kk kl b">nvidia-smi</code>。正如你所看到的，尽管内存几乎用完了，但我们最多只能使用53%的GPU计算。</p><figure class="km kn ko kp fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lw"><img src="../Images/c152fce8cbb760298baa04d76f86af21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qhRS0QIoRjme-HyYrG3U-A.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">节点上“watch -n 1 nvidia-smi”的输出</figcaption></figure><h1 id="7628" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">概括起来</h1><p id="66a9" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">我们简要介绍了在单节点集群上开始使用Kubeflow所需的所有步骤。此外，关于如何利用Tensorflow上的部分GPU分配，以便我们可以并行训练多个模型，并从Katib的实验管理功能中受益，即使我们只有一个GPU可以使用。</p><p id="8faa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望这篇博文能给你一些建议，告诉你如何在日常实验中使用Katib和Kubeflow。这也是一种摆脱仅基于成熟的Kubeflow部署进行原型开发的方法。拥有一个你将要大规模处理的API的本地版本确实非常有帮助，这样你就可以像没有明天一样开始实验了！希望你和我一样开心。</p><blockquote class="lm ln lo"><p id="1e32" class="if ig kh ih b ii ij ik il im in io ip lp ir is it lq iv iw ix lr iz ja jb jc hb bi translated"><em class="hi">保持牛逼！</em></p></blockquote><p id="dd43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kh">致谢:</em> </strong></p><p id="4ba4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些年来，我在基于MLOps和GPU的分布式系统上的冒险经历中，有很多人都是我的参考。非常感谢你们所有人和那些直接为这项工作做出贡献的人: <a class="lx ly ge" href="https://medium.com/u/5cf1411dd79a?source=post_page-----3ada6a8a01a9--------------------------------" rel="noopener" target="_blank"> <em class="kh">阿伦·k·苏布拉马尼扬</em> </a> <em class="kh">，</em> <a class="lx ly ge" href="https://medium.com/u/41b3be1bfb74?source=post_page-----3ada6a8a01a9--------------------------------" rel="noopener" target="_blank"> <em class="kh">亚历克斯·伊恩库尔斯基</em> </a> <em class="kh">，舒尔亚·奥塔，</em> <a class="lx ly ge" href="https://medium.com/u/983ba08de2a9?source=post_page-----3ada6a8a01a9--------------------------------" rel="noopener" target="_blank"> <em class="kh">马哈德万·巴拉苏布拉马尼安</em> </a></p><h2 id="dce0" class="ku jf hi bd jg lz ma mb jk mc md me jo iq mf mg js iu mh mi jw iy mj mk ka ml bi translated"><strong class="ak">资源:</strong></h2><p id="1352" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">katib docs:<a class="ae jd" href="https://www.kubeflow.org/docs/components/hyperparameter-tuning/" rel="noopener ugc nofollow" target="_blank">https://www . kube flow . org/docs/components/hyperparameter-tuning/</a></p><p id="210f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">github回购样本:<a class="ae jd" href="https://github.com/fabiononato/do-katib" rel="noopener ugc nofollow" target="_blank">https://github.com/fabiononato/do-katib</a></p><p id="d31e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">依赖码头工程:<a class="ae jd" href="https://github.com/iankoulski/depend-on-docker" rel="noopener ugc nofollow" target="_blank">https://github.com/iankoulski/depend-on-docker</a></p><p id="50b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Ubuntu Turotial上的kubernetes:<a class="ae jd" href="https://tutorials.ubuntu.com/tutorial/install-a-local-kubernetes-with-microk8s" rel="noopener ugc nofollow" target="_blank">https://tutorials . Ubuntu . com/tutorial/install-a-local-kubernetes-with-micro k8s</a></p></div></div>    
</body>
</html>