<html>
<head>
<title>Linear Regression implementation using Python (easy code)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python(简单代码)实现线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-implementation-using-python-easy-code-b07eed13a26e?source=collection_archive---------9-----------------------#2019-11-26">https://medium.com/analytics-vidhya/linear-regression-implementation-using-python-easy-code-b07eed13a26e?source=collection_archive---------9-----------------------#2019-11-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="95b0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi jk translated"><span class="l jl jm jn bm jo jp jq jr js di">在</span>这篇文章中，我将向您介绍实施线性回归模型的基本技术，该模型使用由<br/>提出的算法来预测值和/或分类问题，该算法由亚塞尔·s·阿布-穆斯塔法、马利克·马格东-伊斯梅尔、宣天利和他们在《从数据中学习》一书中提出。</p><p id="ab51" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我将一步一步地解释每一段代码。这是代码</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="ec19" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">import</strong> <strong class="jy hj">numpy</strong> <strong class="jy hj">as</strong> <strong class="jy hj">np</strong><br/><br/><strong class="jy hj">class</strong> <strong class="jy hj">LinearRegression</strong>:<br/><br/>    <strong class="jy hj">def</strong> __init__(self):<br/>        self.weights = 0<br/><br/>    <strong class="jy hj">def</strong> fit(self, X, y):<br/>        X = np.insert(X.T, 0, 1, axis=0)<br/>        X_cross = np.matmul(np.linalg.pinv(np.matmul(X, X.T)), X)<br/>        self.weights = np.matmul(X_cross, y)<br/>        <strong class="jy hj">return</strong> self.weights<br/><br/>    <strong class="jy hj">def</strong> predict(self, x):<br/>        y_pred = np.sign(np.dot(self.weights.T, x))<br/>        <strong class="jy hj">return</strong> y_pred<br/><br/>    <strong class="jy hj">def</strong> error(self, X, y):<br/>        error = 0<br/>        X = np.insert(X.T, 0, 1, axis=0)<br/>        <strong class="jy hj">for</strong> i, x <strong class="jy hj">in</strong> enumerate(X.T):<br/>            <strong class="jy hj">if</strong> self.predict(x)!=y[i]:<br/>                error += 1<br/>        <strong class="jy hj">return</strong> error/len(y)</span></pre><p id="c5ad" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">首先，我必须导入<strong class="io hj"> numpy </strong>库，因为我需要一些<strong class="io hj"> numpy </strong>函数来实现代码。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="accd" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">import</strong> <strong class="jy hj">numpy</strong> <strong class="jy hj">as</strong> <strong class="jy hj">np</strong></span></pre><p id="a62e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我定义了一个名为“LinearRegression”的类，以初始化开始，这是一些类函数所需要的。我给<strong class="io hj"> self.weights </strong>参数赋值0(不是数组)，因为它将被进一步的函数修改，这些函数将训练我们的模型，最终返回数组值。此外，不限于将0分配给初始权重，可以分配任何随机数。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="12ee" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">class</strong> <strong class="jy hj">LinearRegression</strong>:<br/><br/>    <strong class="jy hj">def</strong> __init__(self):<br/>        self.weights = 0</span></pre><p id="295f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来是<strong class="io hj"> fit() </strong>函数，它返回训练数据后的最终权重。它将需要参数X和y，因为它将基于训练数据找到权重，即X=X_train和y=y_train。因此，当您想要拟合数据时，请发送这个特定函数的X_train和y_train值。然后，我为X的转置的每一列(X.T[0，0]=0，X.T[0，1]=0，X.T[0，2]=0，…，X.T[0，n]=0)插入0作为第一个元素。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="2931" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">def</strong> fit(self, X, y):<br/>        X = np.insert(X.T, 0, 1, axis=0)</span></pre><p id="10e5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">按照《从数据中学习》一书中的算法，我正在寻找矩阵<strong class="io hj"> X_cross </strong>，这是寻找权重所必需的。寻找<strong class="io hj"> X_cross </strong>的公式如下</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="8d0d" class="kc kd hi jy b fi ke kf l kg kh">X_cross = (X^T*X)^(-1)*X^T</span></pre><p id="44f8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我使用<strong class="io hj"> pinv </strong>函数来确保我们的乘积矩阵是可逆的，因为仅仅使用<strong class="io hj"> inv </strong>函数将会抛出矩阵不可逆的异常。<strong class="io hj"> Pinv </strong>函数是求矩阵逆的通用求逆方法，即使矩阵不可逆(非常强大的工具)。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="16ae" class="kc kd hi jy b fi ke kf l kg kh">X_cross = np.matmul(np.linalg.pinv(np.matmul(X, X.T)), X)</span></pre><p id="4ff5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然后，找到两个矩阵的乘积，我将它赋给self.weights变量，这是mx1数组，其中m是X_train矩阵中的行数。最后，退货。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="02aa" class="kc kd hi jy b fi ke kf l kg kh">self.weights = np.matmul(X_cross, y)<br/>        <strong class="jy hj">return</strong> self.weights</span></pre><p id="2d9b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，我将使用用于分类问题的符号函数。因此，如果您不想对预测值进行分类，只需删除np.dot(self.weights.T，x)前面的符号项。为了对事物进行分类，我正在寻找self.weights的值和X_test的每个点的值的点积。x参数是小写的，因为它表示一个单点，这意味着我的函数predict()只预测特定点的符号，然后返回给误差函数。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="30d6" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">def</strong> predict(self, x):<br/>        y_pred = np.sign(np.dot(self.weights.T, x))<br/>        <strong class="jy hj">return</strong> y_pred</span></pre><p id="15ac" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下一个函数，误差函数，是针对分类问题的。与<strong class="io hj"> sklearn </strong>库中的<strong class="io hj"> accuracy_metric </strong>函数相同。它需要X_test和y_test。最初，我将误差定义为零。然后，再次在矩阵X_test^T.循环通过新定义的矩阵x的行的开头插入1的行，我通过调用<strong class="io hj"> self.predict() </strong>函数并检查我的预测是否等于实际的y_test值来预测点x的值，这是矩阵的行。如果不是，则将误差变量加1。毕竟，我将返回平均误差。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="577c" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">def</strong> error(self, X, y):<br/>        error = 0<br/>        X = np.insert(X.T, 0, 1, axis=0)<br/>        <strong class="jy hj">for</strong> i, x <strong class="jy hj">in</strong> enumerate(X.T):<br/>            <strong class="jy hj">if</strong> self.predict(x)!=y[i]:<br/>                error += 1<br/>        <strong class="jy hj">return</strong> error/len(y)</span></pre></div></div>    
</body>
</html>