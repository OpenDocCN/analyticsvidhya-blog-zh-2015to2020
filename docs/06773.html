<html>
<head>
<title>NLP — Feature Selection using TF-IDF</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP使用TF-IDF进行特征选择</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/nlp-feature-selection-using-tf-idf-db2f9eb484fb?source=collection_archive---------3-----------------------#2020-06-02">https://medium.com/analytics-vidhya/nlp-feature-selection-using-tf-idf-db2f9eb484fb?source=collection_archive---------3-----------------------#2020-06-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/72333e81881d0e854069ee7a92c1cab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*XwdHVtNeIWtZCTeABXuecQ.png"/></div></figure><p id="6528" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">TF-IDF是术语频率和逆文档频率的首字母缩写词，是一种强大的特征工程技术，用于识别文本数据中的重要单词，或者更准确地说，是罕见单词。</p><p id="d230" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">几乎所有文本数据的应用，如分类、信息检索系统、文本数据挖掘等。</p><p id="ad37" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">另一个简单的定义是，TF-IDF将字符串转换为数字，以便机器学习模型可以使用数字格式的数据。</p><p id="5d81" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本文中，我们将打开TF-IDF方法来理解它的基本原理和Python代码。</p><h1 id="347a" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">词频— TF </strong></h1><p id="2a23" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">词频或TF是文档中可用的唯一词的总数。数学上，如果我们有I是j文档中的词频，那么一个词在文档中出现的次数除以文档中的总字数。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/bf2ed94df0350b40f190f6f4cfbf5fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*RvCWc1WOMbqTKeCEE8OvrQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">术语频率</figcaption></figure><p id="f799" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">例如，在虚拟分数的帮助下，将在内存中创建一个矩阵，其中包含各个文档的频率，如下所示</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kw"><img src="../Images/28487f21791291a83b4ed1efbe841fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kUy5FcHlxGf33YHiUPvWjQ.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">术语-频率矩阵的图示</figcaption></figure><h1 id="04dd" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">逆文档频率— IDF </strong></h1><p id="f368" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">逆文档频率用于确定稀有词或重要词的权重。</p><p id="3948" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">简而言之，在上面的例子a、an中，这些是频繁出现的单词，由于这些单词的权重与像梅西、沙钦、足球等有意义的单词相比在非常高的范围内。这是TF或字数统计矩阵的问题。这就是IDF的用武之地，它表现为</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lb"><img src="../Images/f0db939419ee94e5dc6440e3a5c584b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*03VSsx43ojgmFMmzjSZKdA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">综合资料的文件（intergrated Data File）</figcaption></figure><p id="fbe6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们通过一个简单的例子来理解使用TF-IDF的权重生成。为了便于计算，我们将做一些假设。假设有64个文档可用，那么对于一个文档，IDF计算将如下所示</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lc"><img src="../Images/e6049957acce033442f7f2b05f5c1972.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*intrHs_6CWal9WXB7g_q8A.png"/></div></div></figure><p id="a735" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，log的属性是，当log 0 = 1和log 1 = 0时，它为较高的数字生成较低的值，为较低的数字生成较高的值。因此，通过使用这一属性，罕见词将获得更高的分数，而常见词将具有接近零的权重。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es ld"><img src="../Images/da01e39bc75ada42ed269c667e3ce4c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y906Mg4z2CgzQA3n_3jyhw.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">逆文档频率矩阵的图解</figcaption></figure><h1 id="325a" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">词频-逆文档频— TFIDF </strong></h1><p id="08b7" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">最后，将为术语频率和逆文档频率生成的矩阵相乘，并且将获得另一个矩阵，该矩阵将具有可用的归一化权重，并且通常被称为TF-IDF矩阵。</p><p id="8190" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">TFIDF = TF * IDF</p><p id="3c1d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下面是使用上面讨论的数学公式的TFIDF的Python代码:</p><pre class="ko kp kq kr fd le lf lg lh aw li bi"><span id="d35f" class="lj jl hi lf b fi lk ll l lm ln">import math<br/>from textblob import TextBlob as tb</span><span id="a395" class="lj jl hi lf b fi lo ll l lm ln">def tf(word, blob):<br/>    return blob.words.count(word) / len(blob.words)</span><span id="83e1" class="lj jl hi lf b fi lo ll l lm ln">def n_containing(word, bloblist):<br/>    return sum(1 for blob in bloblist if word in blob.words)</span><span id="b792" class="lj jl hi lf b fi lo ll l lm ln">def idf(word, bloblist):<br/>    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))</span><span id="aa30" class="lj jl hi lf b fi lo ll l lm ln">def tfidf(word, blob, bloblist):<br/>    return tf(word, blob) * idf(word, bloblist)</span><span id="495b" class="lj jl hi lf b fi lo ll l lm ln">document1 = tb("""Python is a 2000 made-for-TV horror movie directed by Richard Clabaugh. The film features several cult favorite actors, including William Zabka of The Karate Kid fame, Wil Wheaton, Casper Van Dien, Jenny McCarthy,Keith Coogan, Robert Englund (best known for his role as Freddy Krueger in the A Nightmare on Elm Street series of films), Dana Barron, David Bowe, and Sean Whalen. The film concerns a genetically engineered snake, a python, that escapes and unleashes itself on a small town. It includes the classic final girl scenario evident in films like Friday the 13th. It was filmed in Los Angeles,California and Malibu, California. Python was followed by two sequels: Python II (2002) and Boa vs. Python (2004), both also made-for-TV films.""")</span><span id="c0ea" class="lj jl hi lf b fi lo ll l lm ln">document2 = tb("""Python, from the Greek word (πύθων/πύθωνας), is a genus of nonvenomous pythons[2] found in Africa and Asia. Currently, 7 species are recognised.[2] A member of this genus, P. reticulatus, is among the longest snakes known.""")</span><span id="68b5" class="lj jl hi lf b fi lo ll l lm ln">document3 = tb("""The Colt Python is a .357 Magnum caliber revolver formerly manufactured by Colt's Manufacturing Company of Hartford, Connecticut. It is sometimes referred to as a "Combat Magnum".[1] It was first introduced in 1955, the same year as Smith &amp;amp; Wesson's M29 .44 Magnum. The now discontinued Colt Python targeted the premium revolver market segment. Some firearm collectors and writers such as Jeff Cooper, Ian V. Hogg, Chuck Hawks, Leroy Thompson, Renee Smeets and Martin Dougherty have described the Python as the finest production revolver ever made.""")</span><span id="e20b" class="lj jl hi lf b fi lo ll l lm ln">bloblist = [document1, document2, document3]<br/>for i, blob in enumerate(bloblist):<br/>    print("Top words in document {}".format(i + 1))<br/>    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}<br/>    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)<br/>    for word, score in sorted_words[:3]:<br/>        print("\tWord: {}, TF-IDF: {}".format(word, round(score, 5)))</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/d762e5e5c972d28f8fb09a2605058c5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*Cfxn29kG2mIZ6Uvjh1RySA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">TFIDF输出</figcaption></figure><p id="85c5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">TFIDF由sklearn库提供，因此可以进行直接转换。下面是相同的片段:</p><pre class="ko kp kq kr fd le lf lg lh aw li bi"><span id="cb49" class="lj jl hi lf b fi lk ll l lm ln">vectorizer = TfidfVectorizer()<br/>vectors = vectorizer.fit_transform([documentA, documentB])<br/>feature_names = vectorizer.get_feature_names()</span></pre><p id="2bc1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，根据选择，可以使用任何方法。</p></div></div>    
</body>
</html>