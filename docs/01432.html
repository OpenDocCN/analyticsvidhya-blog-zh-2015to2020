<html>
<head>
<title>Solving “Container Killed by Yarn For Exceeding Memory Limits” Exception in Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解决Apache Spark中的“容器因超出内存限制而被Yarn杀死”异常</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/solving-container-killed-by-yarn-for-exceeding-memory-limits-exception-in-apache-spark-b3349685df16?source=collection_archive---------0-----------------------#2019-10-22">https://medium.com/analytics-vidhya/solving-container-killed-by-yarn-for-exceeding-memory-limits-exception-in-apache-spark-b3349685df16?source=collection_archive---------0-----------------------#2019-10-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8d2fe1b9ddc72224e363a4decaffc525.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8lcmQZoelmRZCbIKFMiiDQ.png"/></div></div></figure><p id="1caf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">简介<br/> </strong> <a class="ae jo" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>是一个用于分布式大数据处理的开源框架。它最初是用Scala编写的，也有Java、Python和R编程语言的原生绑定。它还支持SQL、流数据、机器学习和图形处理。</p><blockquote class="jp jq jr"><p id="2797" class="iq ir js is b it iu iv iw ix iy iz ja jt jc jd je ju jg jh ji jv jk jl jm jn hb bi translated"><em class="hi">总而言之，Apache Spark通常被称为用于大规模数据处理的</em> <strong class="is hj">统一分析引擎。</strong></p></blockquote><p id="3ed9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您使用Apache Spark已经有一段时间了，您可能会遇到类似这样的异常:<br/> <em class="js">容器因超出内存限制而被YARN杀死，5 GB中的5GB被使用</em></p><p id="c19b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">原因可能在驱动程序节点上，也可能在执行器节点上。简而言之，异常表示，在处理时，spark必须在内存中获取更多的数据，而实际上执行器/驱动程序已经拥有了这些数据。<br/>这可能有几个原因，可以通过以下方式解决:</p><ul class=""><li id="d113" class="jw jx hi is b it iu ix iy jb jy jf jz jj ka jn kb kc kd ke bi translated">您的<em class="js">数据是倾斜的</em>，这意味着您在处理过程中没有正确地对数据进行分区，从而导致需要为特定任务处理更多的数据。在这种情况下，您可以检查您的数据，并尝试使用一个<em class="js">自定义分区器</em>对数据集进行统一分区。</li><li id="f5a3" class="jw jx hi is b it kf ix kg jb kh jf ki jj kj jn kb kc kd ke bi translated">您的Spark工作可能会在网络上传输大量数据。在可供执行器使用的内存中，只有一部分被分配给洗牌周期。尝试使用高效的Spark API，如<em class="js"> reduceByKey </em>而不是<em class="js"> groupByKey </em>等，如果还没有这样做的话。有时候，洗牌是不可避免的。在这种情况下，我们需要增加内存配置，我们将在后面的内容中讨论</li></ul><p id="92ba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果以上两点不适用，按顺序尝试以下<em class="js"/>直到错误解决。在继续之前，恢复您可能对spark配置文件所做的任何更改。</p><ul class=""><li id="ae3d" class="jw jx hi is b it iu ix iy jb jy jf jz jj ka jn kb kc kd ke bi translated"><strong class="is hj">增加内存开销<br/> </strong>内存开销是分配给每个执行器的堆外内存量。默认情况下，内存开销被设置为执行器内存的10%或384 mb之间的较高值。内存开销用于Java NIO直接缓冲区、线程堆栈、共享本机库或内存映射文件。<br/>上述异常可能发生在驱动程序或执行程序节点。无论错误在哪里，尝试逐渐增加<strong class="is hj"> <em class="js">的开销内存，只存放</em> </strong> <em class="js"> </em> <strong class="is hj"> <em class="js">(驱动程序或执行程序)</em> </strong> <em class="js"> </em>并重新运行作业。建议的最大内存开销是执行程序内存的25%<br/><strong class="is hj"><em class="js">注意</em> </strong> <em class="js">:确保驱动程序或执行程序内存加上驱动程序或执行程序内存开销的总和始终小于</em><strong class="is hj"><em class="js">yarn . nodemanager . resource . memory-MB</em></strong><br/>的值，即 <code class="du kk kl km kn b">spark.driver/executor.memory + spark.driver/executor.memoryOverhead &lt; yarn.nodemanager.resource.memory-mb</code> <br/>您必须通过编辑<em class="js"> spark-defaults.conf </em>文件来更改该属性</li></ul><pre class="ko kp kq kr fd ks kn kt ku aw kv bi"><span id="fb33" class="kw kx hi kn b fi ky kz l la lb">sudo vim /etc/spark/conf/spark-defaults.conf  </span><span id="3b54" class="kw kx hi kn b fi lc kz l la lb">spark.driver.memoryOverhead 1024 <br/>spark.executor.memoryOverhead 1024</span></pre><p id="3cff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以在群集范围内为所有作业指定上述属性，也可以将其作为单个作业的配置进行传递，如下所示</p><pre class="ko kp kq kr fd ks kn kt ku aw kv bi"><span id="bc08" class="kw kx hi kn b fi ky kz l la lb">spark-submit --class org.apache.spark.examples.WordCount --master yarn --deploy-mode cluster --conf spark.driver.memoryOverhead=512 --conf spark.executor.memoryOverhead=512 &lt;path/to/jar&gt; </span></pre><p id="7144" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果这不能解决您的问题，请尝试下一点</p><ul class=""><li id="87a9" class="jw jx hi is b it iu ix iy jb jy jf jz jj ka jn kb kc kd ke bi translated"><strong class="is hj">减少执行核心的数量<br/> </strong>如果执行核心的数量增加，所需的内存量也会增加。因此，尝试减少每个执行器的内核数量，这样可以减少可以在执行器上运行的任务数量，从而减少所需的内存。同样，根据错误所在更改驱动程序或执行器的配置。</li></ul><pre class="ko kp kq kr fd ks kn kt ku aw kv bi"><span id="bbe5" class="kw kx hi kn b fi ky kz l la lb">sudo vim /etc/spark/conf/spark-defaults.conf <br/>spark.driver.cores  3 <br/>spark.executor.cores  3</span></pre><p id="7c3e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">与上一点类似，您可以在群集范围内为所有作业指定上述属性，也可以将其作为单个作业的配置进行传递，如下所示:</p><pre class="ko kp kq kr fd ks kn kt ku aw kv bi"><span id="ead9" class="kw kx hi kn b fi ky kz l la lb">spark-submit --class org.apache.spark.examples.WordCount --master yarn --deploy-mode cluster <strong class="kn hj">--executor-cores 5--driver-cores 4 </strong>&lt;path/to/jar&gt;</span></pre><p id="61df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果这个不行，看下一点</p><ul class=""><li id="d393" class="jw jx hi is b it iu ix iy jb jy jf jz jj ka jn kb kc kd ke bi translated"><strong class="is hj">增加分区数量<br/> </strong>如果有更多的分区，每个分区所需的内存量就会更少。内存使用可以由Ganglia监控。您可以通过调用<em class="js">来增加分区的数量。在RDD或数据帧上重新分区(&lt; num_partitions &gt; ) </em></li></ul><p id="734f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">还没找到吗？增加执行器或驱动程序内存。</p><ul class=""><li id="c6c6" class="jw jx hi is b it iu ix iy jb jy jf jz jj ka jn kb kc kd ke bi translated"><strong class="is hj">增加驱动程序或执行程序的内存<br/> </strong>根据错误发生的位置，增加驱动程序或执行程序的内存<br/> <strong class="is hj"> <em class="js">注意:<br/> </em> </strong> <code class="du kk kl km kn b">spark.driver/executor.memory + spark.driver/executor.memoryOverhead &lt; yarn.nodemanager.resource.memory-mb</code></li></ul><pre class="ko kp kq kr fd ks kn kt ku aw kv bi"><span id="0855" class="kw kx hi kn b fi ky kz l la lb">sudo vim /etc/spark/conf/spark-defaults.conf  <br/>spark.executor.memory  2g <br/>spark.driver.memory  1g</span></pre><p id="d13c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">就像其他属性一样，这也可以被每个作业覆盖</p><pre class="ko kp kq kr fd ks kn kt ku aw kv bi"><span id="b368" class="kw kx hi kn b fi ky kz l la lb">spark-submit --class org.apache.spark.examples.WordCount --master yarn --deploy-mode cluster --executor-memory 2g --driver-memory 1g &lt;path/to/jar&gt;</span></pre><p id="22c0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，您很可能已经解决了这个异常。</p><p id="c00b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果没有，那么您的集群可能需要更多的内存优化实例！</p><p id="bbf3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">编码快乐！<br/>参考:<a class="ae jo" href="https://aws.amazon.com/premiumsupport/knowledge-center/emr-spark-yarn-memory-limit/" rel="noopener ugc nofollow" target="_blank">https://AWS . Amazon . com/premium support/knowledge-center/EMR-spark-yarn-memory-limit/</a></p></div></div>    
</body>
</html>