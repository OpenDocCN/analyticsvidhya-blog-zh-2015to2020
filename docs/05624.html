<html>
<head>
<title>Step-by-Step TensorFlow / Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逐步张量流/ Keras</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/step-by-step-tensorflow-keras-38fa7fdbec38?source=collection_archive---------10-----------------------#2020-04-27">https://medium.com/analytics-vidhya/step-by-step-tensorflow-keras-38fa7fdbec38?source=collection_archive---------10-----------------------#2020-04-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="cd5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第1部分:深度神经网络</p><p id="63bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Tensorflow是深度学习最流行的框架之一。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/b429a5d694452c34b69805c3d5e2ff2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*QLvZzPvNge4ivYabLXis7w.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated"><a class="ae jp" href="https://www.tensorflow.org" rel="noopener ugc nofollow" target="_blank">TensorFlow.org</a></figcaption></figure><p id="44d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度学习是机器学习的一部分。并且，如果我们恰当地使用它，它比机器学习更强。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jq"><img src="../Images/83d00e7fe5d06f8f56f97de2988ec114.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*680J_4ak33QrOVl8LP4wnQ.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">深度学习</figcaption></figure><p id="3523" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，深度学习结构具有输入层、输出层和隐藏层。所以，基本的例子是人工神经网络。如果这种结构只有一个隐含层，则称为浅层神经网络。如果隐含层的数目大于1，则称为深度神经网络。对于基本的神经网络来说，如果这个数字非常非常高，就没有用了。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jv"><img src="../Images/09bd4b7a7b3efa1278e805c00ed75a7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_WhPTI429LcidSN6GTDBiA.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">深度神经网络流程</figcaption></figure><p id="dce8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人工神经网络有许多节点，就像大脑结构一样。这个节点叫做神经元。神经元需要一个输入、一个输出和一个用于决策的激活函数(因为决策阈值)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jw"><img src="../Images/e06d0d0afd9f3c095f53cd9b432a2fa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MnDDBuHVHqK2mB0jw2tc9w.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">神经元的进展</figcaption></figure><p id="1758" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在介绍了主题之后，我们可以设计一个学习网络。首先，我们将从单个神经元开始…对于这种体验，我们可以使用Tensorflow的Keras API，如下所示。</p><pre class="je jf jg jh fd jx jy jz ka aw kb bi"><span id="3f32" class="kc kd hi jy b fi ke kf l kg kh"># TensorFlow framework &amp; version                       <br/>import <strong class="jy hj">tensorflow </strong>as tf                       <br/>print(tf.__version__)<br/>                                                                       # keras API                       <br/>from tensorflow import <strong class="jy hj">keras   </strong><br/>                                                                    # model                       <br/>model = keras.<strong class="jy hj">Sequential</strong>([keras.layers.<strong class="jy hj">Dense</strong>(units=1, <br/>                                             input_shape=[1])])                       <br/>model.compile(optimizer='sgd', loss='mean_squared_error')                       model.fit(X_train, y_train,  epochs=100)                       model.predict(X_test)</span></pre><p id="658a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个起点。所以，你可以用你的想象来改善它…</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="cb86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们设计更广泛的人工神经网络，称为深度神经网络。</p><pre class="je jf jg jh fd jx jy jz ka aw kb bi"><span id="1c79" class="kc kd hi jy b fi ke kf l kg kh"># TensorFlow framework &amp; version<br/>import tensorflow as tf<br/>print(tf.__version__)</span><span id="592d" class="kc kd hi jy b fi kp kf l kg kh"># keras API<br/>from tensorflow import keras</span><span id="3810" class="kc kd hi jy b fi kp kf l kg kh"># model<br/>model = tf.keras.Sequential([<br/>keras.layers.Dense(units=250, input_shape=[300], <br/>                   activation=tf.nn.relu),<br/>keras.layers.Dense(units=150, <br/>                   activation=tf.nn.relu), # activation='relu'<br/>keras.layers.Dense(units=100, activation=tf.nn.relu),<br/>keras.layers.Dense(units=50, activation=tf.nn.relu),<br/>keras.layers.Dense(units=25, activation=tf.nn.relu),<br/>keras.layers.Dense(units=10, activation=tf.nn.relu),<br/>keras.layers.Dense(units=1)<br/>])</span><span id="b539" class="kc kd hi jy b fi kp kf l kg kh">model.compile(optimizer='<strong class="jy hj">sgd</strong>', loss='<strong class="jy hj">mean_squared_error</strong>')<br/>model.fit(X_train, y_train, epochs=100)<br/>model.predict(X_test)</span></pre><p id="91a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型流程如下…</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es kq"><img src="../Images/17005cb508c9effd5a94bb30dfd92fcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IQpn6xUmhiGC5ZckaeUjyw.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">DNN流</figcaption></figure></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="3cb1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面设计的模型是一个回归模型示例。因此，如果我们想显示模型摘要(输入和输出大小，层参数大小等。)我们可以用summary()方法…</p><pre class="je jf jg jh fd jx jy jz ka aw kb bi"><span id="abf6" class="kc kd hi jy b fi ke kf l kg kh">model.summary()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es kr"><img src="../Images/eef83bfc146c0de453dc40c37081946e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zhP8XzFgc3jpquRzEHQACA.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">模型摘要</figcaption></figure></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="bf40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们正在改变问题类型，设计一个多类分类模型…</p><pre class="je jf jg jh fd jx jy jz ka aw kb bi"><span id="c85c" class="kc kd hi jy b fi ke kf l kg kh"># TensorFlow framework &amp; version<br/>import tensorflow as tf<br/>print(tf.__version__)</span><span id="e3d2" class="kc kd hi jy b fi kp kf l kg kh"># keras API<br/>from tensorflow import keras</span><span id="a73e" class="kc kd hi jy b fi kp kf l kg kh"># model<br/>model = tf.keras.Sequential([<br/>keras.layers.Dense(units=250, input_shape=[300],<br/>                   activation=tf.nn.relu),<br/>keras.layers.Dense(units=100, <br/>                   activation=tf.nn.relu), # activation='relu'<br/>keras.layers.Dense(units=50, activation=tf.nn.relu), <br/>keras.layers.Dense(units=10, activation='<strong class="jy hj">softmax</strong>')<br/>])</span><span id="9402" class="kc kd hi jy b fi kp kf l kg kh">model.compile(<br/>optimizer='<strong class="jy hj">adam</strong>',<br/>loss='<strong class="jy hj">sparse_categorical_crossentropy</strong>',<br/>metrics=['<strong class="jy hj">accuracy</strong>']<br/>)</span><span id="ccfe" class="kc kd hi jy b fi kp kf l kg kh">history = model.fit(X_train, y_train, epochs=100)</span></pre><p id="829a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型的度量是准确性，损失函数是分类交叉熵(由于多类模型)。</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="1d7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你决定设计一个二进制分类模型，你可以改变最后一层和模型编译参数如下…</p><pre class="je jf jg jh fd jx jy jz ka aw kb bi"><span id="c894" class="kc kd hi jy b fi ke kf l kg kh">…<br/># model<br/>model = tf.keras.Sequential([<br/>keras.layers.Dense(units=250, input_shape=[300], <br/>                   activation=tf.nn.relu),<br/>keras.layers.Dense(units=100, <br/>                   activation=tf.nn.relu), # activation='relu'<br/>keras.layers.Dense(units=50, activation=tf.nn.relu),<br/>keras.layers.Dense(units=1, activation='<strong class="jy hj">sigmoid</strong>')<br/>])</span><span id="84cc" class="kc kd hi jy b fi kp kf l kg kh">model.compile(<br/>loss='<strong class="jy hj">binary_crossentropy</strong>',<br/>optimizer=<strong class="jy hj">RMSprop</strong>(lr=0.001),<br/>metrics=['<strong class="jy hj">accuracy</strong>']<br/>)</span><span id="027f" class="kc kd hi jy b fi kp kf l kg kh">history = model.fit(X_train, y_train, epochs=100)</span></pre><p id="62b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型的度量是准确性，其定义如下，用于二元分类…</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ks"><img src="../Images/1d56a6092ef0b9ff020978677ab73e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*IIdVqDNA1-vcA4etQE6ARA.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">混淆矩阵</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es kt"><img src="../Images/14c3032259bb9783a8a69f4372d5f6e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vfA13Qg_fIoNpMB2lVAYXA.jpeg"/></div></div></figure><pre class="je jf jg jh fd jx jy jz ka aw kb bi"><span id="cde2" class="kc kd hi jy b fi ke kf l kg kh"><strong class="jy hj">Accuracy </strong>= (TP + TN) / (TP + TN + FP + FN)</span><span id="a680" class="kc kd hi jy b fi kp kf l kg kh"><strong class="jy hj">Sensitivity </strong>= TP / (TP + FN)<br/><strong class="jy hj">Recall </strong>= TP / (TP + FN)<br/><strong class="jy hj">Specificity </strong>= TN / (TN + FP)</span><span id="c02d" class="kc kd hi jy b fi kp kf l kg kh"><strong class="jy hj">Precision </strong>= TP / (TP + FP)<br/><strong class="jy hj">Negative Predictive Value</strong> = TN / (TN + FN)</span><span id="281d" class="kc kd hi jy b fi kp kf l kg kh"><strong class="jy hj">F1 Score</strong> = 2 x (Precision x Recall) / (Precision + Recall)</span></pre><p id="d4a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在模型代码的末尾，我们将模型赋给了一个名为history的变量。为什么？</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="b595" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型对象包含一些元素。经过模型训练，我们可以发现它们。因此，如果将训练好的模型分配给一个变量，这将非常有用。例如，让我们根据训练集和验证集绘制准确度图…</p><pre class="je jf jg jh fd jx jy jz ka aw kb bi"><span id="a9c7" class="kc kd hi jy b fi ke kf l kg kh"># plotting framework<br/>import matplotlib.pyplot as plt</span><span id="6570" class="kc kd hi jy b fi kp kf l kg kh"># accuracy values &amp; number of epoch<br/>acc = history.<strong class="jy hj">history['accuracy']</strong><br/>val_acc = history.<strong class="jy hj">history['val_accuracy']</strong><br/>epochs = range(len(acc))</span><span id="09a5" class="kc kd hi jy b fi kp kf l kg kh"># creating a graph<br/>plt.plot(epochs, acc, 'bo', label='Training accuracy')<br/>plt.plot(epochs, val_acc, 'b', label='Validation accuracy')<br/>plt.title('Training and validation accuracy')</span><span id="7196" class="kc kd hi jy b fi kp kf l kg kh">plt.figure()<br/>plt.legend()<br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ku"><img src="../Images/8a7ee00df185453182506941159e603d.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*18GmWoKV3EGDAVPXyRCwdQ.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">准确(性)</figcaption></figure><p id="7ef3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们想要访问损失值，我们可以使用历史。<strong class="ih hj">历史【损失】</strong>和历史。<strong class="ih hj">历史['瓦尔_洛斯'] </strong> …</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="45f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们应该避免过度拟合问题。在人工神经网络结构中，我们使用了一个预防层。这叫辍学…</p><pre class="je jf jg jh fd jx jy jz ka aw kb bi"><span id="aac7" class="kc kd hi jy b fi ke kf l kg kh">...<br/># model<br/>model = tf.keras.Sequential([<br/>keras.layers.Dense(units=250, input_shape=[300], <br/>                   activation=tf.nn.relu),<br/>keras.layers.Dense(units=150, <br/>                   activation=tf.nn.relu), # activation='relu'<br/>keras.layers.Dense(units=100, activation=tf.nn.relu),<br/>keras.layers.<strong class="jy hj">Dropout</strong>(0.2),<br/>keras.layers.Dense(units=50, activation=tf.nn.relu),<br/>keras.layers.Dense(units=25, activation=tf.nn.relu),<br/>keras.layers.<strong class="jy hj">Dropout</strong>(0.2),<br/>keras.layers.Dense(units=10, activation=tf.nn.relu),<br/>keras.layers.Dense(units=1)<br/>])<br/>...</span></pre><p id="c0e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">差值介于0和1之间。例如，如果我们使用0.2，这意味着模型层将会忘记其输入数据的%20。换句话说，这一层有20%的神经元会随机关闭…</p><h1 id="04eb" class="kv kd hi bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">然后</h1><p id="90af" class="pw-post-body-paragraph if ig hi ih b ii ls ik il im lt io ip iq lu is it iu lv iw ix iy lw ja jb jc hb bi translated">我将解释1D，2D和三维数据的卷积过程。另外，我们将在TensorFlow / Keras上设计一个卷积神经网络。最后，我们将计算输出大小和参数数量…</p><h1 id="88fa" class="kv kd hi bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">参考</h1><blockquote class="lx ly lz"><p id="3176" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">deeplearning.ai专业化讲义，Coursera</p><p id="f3a3" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">实践专业化讲义，Coursera</p><p id="cfaa" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">IBM人工智能工程专业讲义，Coursera</p><p id="3eb7" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">Deniz Yuret的深度学习介绍讲义，Koc大学</p></blockquote></div></div>    
</body>
</html>