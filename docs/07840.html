<html>
<head>
<title>Logistic Regression Part II— Cost Function &amp; Error Metrics:</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归第二部分——成本函数和误差指标:</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/logistic-regression-part-ii-cost-function-error-metrics-bbffbe93eb36?source=collection_archive---------15-----------------------#2020-07-09">https://medium.com/analytics-vidhya/logistic-regression-part-ii-cost-function-error-metrics-bbffbe93eb36?source=collection_archive---------15-----------------------#2020-07-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div class="er es hg"><img src="../Images/40b28d05fb911256e7c4a843214b49ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*p-kzd-CQc_vEcsFRf4hBcg.png"/></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">ROC曲线— AUC得分</figcaption></figure><div class=""/><p id="198f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇文章中，我们将探索逻辑回归的成本函数和误差度量。</p><p id="9126" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">逻辑回归是一种用于预测离散值的分类算法。</p><blockquote class="jo jp jq"><p id="64dc" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hu">逻辑回归的工作方式类似于线性回归，首先找出X系数和斜率，除此之外，它还将Y预测值应用于sigmoid函数，以将接收到的真实值(范围从-无穷大到+无穷大)映射为二进制值(范围从0到1)。</strong></p></blockquote><p id="7016" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解更多关于这种映射的信息，请查看<a class="ae jv" rel="noopener" href="/analytics-vidhya/logistic-regression-part-i-transformation-of-linear-to-logistic-395cb539038b">逻辑回归第一部分——线性到逻辑的转换</a>。</p><p id="1646" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">逻辑回归通过将Y预测值放入Sigmoid函数中，将Y预测值转换为二进制值。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div class="er es jw"><img src="../Images/8832dbb6ac44bb218ae664356c16b136.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*_KCfH9l14ETr98wymCi8Fw.png"/></div></figure><p id="5db6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，Y预测值成为介于0和1之间的概率值范围。</p><p id="01c3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们新的Y值落在了Sigmoid曲线上。</p><p id="7db4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果p &gt;= 0.5那么我们把它设为1，如果p &lt; 0.5 then we make it as 0.</p><p id="5724" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">The point 0.5 is called decision boundary.</p><p id="1f60" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">In Linear Regression, the cost function is defined as,</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div class="er es kb"><img src="../Images/45252bbb8ed30858c6a7228222d74f6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*oM_UgrMzOuhkSa4y0KaarA.png"/></div></figure><p id="776f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">But for Logistic Reg. this will not be suitable as we already took logistic (Sigmoid) of the Y value received.</p><p id="364e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Thus, the Cost Function becomes,</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es kc"><img src="../Images/d5154dcb52c212bd4b882af992908d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*zPbg5jSnlfYpz4Dm1q5YAg.png"/></div></div></figure><figure class="jx jy jz ka fd hk er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es kh"><img src="../Images/8ab85790dadcb75f3914caea2584488f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LVgezMMjzOY-E9QjKTxnAA.png"/></div></div></figure><h1 id="16ff" class="ki kj ht bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated"><strong class="ak">误差度量:</strong></h1><h2 id="148c" class="lg kj ht bd kk lh li lj ko lk ll lm ks jb ln lo kw jf lp lq la jj lr ls le lt bi translated"><strong class="ak">混乱矩阵:</strong></h2><p id="baf1" class="pw-post-body-paragraph iq ir ht is b it lu iv iw ix lv iz ja jb lw jd je jf lx jh ji jj ly jl jm jn hb bi translated">我们的分类模型的预测将属于以下任何类别:</p><p id="33ab" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">真正TP: </strong>实际值为正；预测值为正值</p><p id="7e44" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">真负值TN: </strong>实际值为负值；预测值为负</p><p id="2ba5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">假阳性FP: </strong>实际值为负；但是模型给出的是肯定的，这是一个错误的预测。</p><p id="8625" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">假阴性FN: </strong>实际值为正；但是模型给出的是否定的，这是一个错误的预测。</p><p id="6671" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">迷惑对吗？如果我们把这个总结成一个表格，那么就叫混淆矩阵。</p><p id="8da0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Lol。它的名字叫混淆矩阵，但肯定不是因为它一开始很难理解。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div class="er es lz"><img src="../Images/1d074cadc686e50c38c2600e58da8d6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*Dz_WsuRSA_2xohSqYGFa4Q.png"/></div></figure><p id="3e2a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是正确预测的清晰表示。所有正确的预测都按对角线顺序排列(用红圈标出)。举个例子，</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div class="er es ma"><img src="../Images/edd42ec737e1570160135c47ab6828cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*I7cBTAGUeD_6AF_wlb_jxQ.png"/></div></figure><h2 id="8fe8" class="lg kj ht bd kk lh li lj ko lk ll lm ks jb ln lo kw jf lp lq la jj lr ls le lt bi translated">分类准确度:</h2><p id="049d" class="pw-post-body-paragraph iq ir ht is b it lu iv iw ix lv iz ja jb lw jd je jf lx jh ji jj ly jl jm jn hb bi translated">在分类算法中，也存在准确性度量。但它是通过计算TP、FP、TN和FN的总数来衡量的。此指标衡量正确预测占预测总数的比率。对于更高的精度，该模型给出最好的结果。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div class="er es mb"><img src="../Images/979c839741498927a26caf88e8766782.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*k0VK37JmjBbz2X7AtXpJZA.png"/></div></figure><h2 id="93bd" class="lg kj ht bd kk lh li lj ko lk ll lm ks jb ln lo kw jf lp lq la jj lr ls le lt bi translated"><strong class="ak">召回率/灵敏度/真阳性率:</strong></h2><blockquote class="jo jp jq"><p id="1983" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hu">在所有阳性类别中，有多少实例被正确识别。即，敏感度描述了模型在预测正类方面有多好。</strong></p></blockquote><p id="0c38" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">TPR = TP/P = TP / (TP + FN)</p><p id="cf68" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">灵敏度值<strong class="is hu">越高，意味着您的模型在预测阳性类别</strong>方面表现良好，只有少数阳性被预测为错误。</p><p id="7e80" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如，如果测试数据有10个阳性类，并且10个中有8个被正确预测(真阳性)，那么这意味着2个阳性被预测为阴性(假阴性)。</p><p id="fa7d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">TPR = 8/8+2 = 0.8</p><p id="10d2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当分母FN(错误预测)增加得比分子TP多时，TPR的值减少。因此，<strong class="is hu">TPR越高，正确的正面预测就越高。</strong></p><p id="e4cb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在某些模型中，我们可以接受一定的假阳性率，但不鼓励假阴性。例如，在恶性肿瘤检测中，如果恶性肿瘤阳性患者被预测为阴性，则比阴性患者被预测为阳性更危险。</p><p id="44d4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个时候，我们需要专注于获得一个好的敏感率。</p><p id="184f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假阴性率是TPR的倒数。</p><p id="ef2e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">FNR = 1 — TPR = FN/ (FN + TP)</p><h2 id="b6cc" class="lg kj ht bd kk lh li lj ko lk ll lm ks jb ln lo kw jf lp lq la jj lr ls le lt bi translated"><strong class="ak">特异性/选择性/真阴性率:</strong></h2><blockquote class="jo jp jq"><p id="b49c" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hu">假阳性数除以假阳性数和真阴性数之和。特异性描述了一个模型在预测积极的类别方面有多好。</strong></p></blockquote><p id="4024" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">TNR = TN/N = TN / (TN+ FP)</p><p id="654f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如:如果测试数据有10个阴性类别，10个中有8个被正确预测(真阴性)，那么这意味着2个阴性被预测为阳性(假阳性)。</p><p id="dad9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">TNR = 8/8+2 = 0.8</p><p id="966e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当分母FP(错误预测)比分子TN增加得多时，TNR的值减少。因此，TNR越高，正确的负面预测就越高。</p><p id="0236" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在某些情况下，假阳性是不可接受，但是假阴性的比率是可以协商的，我们需要关注特异性而不是敏感性。例如，如果球员的药物消耗测试的阳性结果受到法律的严厉惩罚，那么当一个没有消耗药物的人被错误地指控时，这是很危险的。</p><p id="9526" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这种情况下，我们需要关注特殊性。</p><p id="7c76" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假阳性率是TNR的倒数。</p><p id="20e9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">FPR = 1 — TNR = FP/ (FP + TN)</p><h2 id="484d" class="lg kj ht bd kk lh li lj ko lk ll lm ks jb ln lo kw jf lp lq la jj lr ls le lt bi translated"><strong class="ak">精度/阳性预测值:</strong></h2><p id="affb" class="pw-post-body-paragraph iq ir ht is b it lu iv iw ix lv iz ja jb lw jd je jf lx jh ji jj ly jl jm jn hb bi translated">在所有预测的正面事例中，有多少是正确的。</p><p id="cf61" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">精度= TP / (TP + FP)</p><h2 id="5eff" class="lg kj ht bd kk lh li lj ko lk ll lm ks jb ln lo kw jf lp lq la jj lr ls le lt bi translated"><strong class="ak"> F值:</strong></h2><p id="2e96" class="pw-post-body-paragraph iq ir ht is b it lu iv iw ix lv iz ja jb lw jd je jf lx jh ji jj ly jl jm jn hb bi translated">从查准率和查全率来看，F-Measure是计算出来的，有时也用作度量。f-Measure只不过是精度和召回率的调和平均值。</p><p id="92d5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">F-Score = (2 *召回率*准确率)/(召回率+准确率)</p><h2 id="5b89" class="lg kj ht bd kk lh li lj ko lk ll lm ks jb ln lo kw jf lp lq la jj lr ls le lt bi translated"><strong class="ak"> ROC曲线:</strong></h2><p id="459d" class="pw-post-body-paragraph iq ir ht is b it lu iv iw ix lv iz ja jb lw jd je jf lx jh ji jj ly jl jm jn hb bi translated">即使分类精度是单个值，从该值我们可以知道模型的精度，但是该信息对于分类算法来说是不够的。</p><p id="5cd9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于二元响应变量，出于某些原因，我们可能需要知道一个模型可以预测每个类别的好坏。</p><blockquote class="jo jp jq"><p id="2c05" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hu"> ROC(受试者工作特征)曲线是假阳性率(x轴)和真阳性率(y轴)的可视化。</strong></p></blockquote><p id="5f4b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">尽管我们有敏感度比率来发现预测阳性结果的优点，ROC曲线提供了更好理解的可视化。</p><p id="910f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ROC曲线上的每个点代表一个灵敏度/特异性对。</p><p id="4701" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">蓝色虚线是随机分类器，即每个无价值类别有50%的机会。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div class="er es mc"><img src="../Images/2ff02cebb2e78840ff61bbdc6ecb298d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*36RgMFnoaY6mZwcMYqo05Q.png"/></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">ROC曲线图解——了解好曲线和坏曲线</figcaption></figure><p id="cb0d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上图可以辨别出ROC曲线中哪些是好的，哪些是不好的。这张图是手绘的，只是为了比较什么是好的，什么是坏的。</p><p id="60bf" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从糖尿病训练数据集获得的原始ROC曲线在本文的顶部“ROC曲线AUC得分”中提到，我们将在本系列的下一部分中查看该曲线。</p><p id="be12" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">从ROC曲线观察:</strong></p><p id="2022" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">👉Y轴的急剧增加意味着高数量的真阳性，即高数量的正确预测。</p><p id="d44f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">👉曲线越靠近左侧边界和顶部边界，测试就越准确。</p><p id="0d2f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">👉曲线越接近45度对角线，测试越不准确。</p><p id="bac7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">👉如果曲线上升到左上角，那么曲线将覆盖其下的更多区域。计算该面积并表示为AUROC曲线下面积)得分或AUROC得分。</p><p id="dfa9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">👉如果AUC分数是0.5，那么曲线只是随机选择。</p><p id="4b16" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">👉如果AUC分数是1，那么所有面积都是正确的预测。即完美模型。</p><p id="0227" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">👉AUC分数越高，模型越好。</p><h1 id="ebdc" class="ki kj ht bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">结论:</h1><p id="f752" class="pw-post-body-paragraph iq ir ht is b it lu iv iw ix lv iz ja jb lw jd je jf lx jh ji jj ly jl jm jn hb bi translated">在本文中，我们已经看到了成本函数和误差度量。</p><p id="6489" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本系列的下一篇文章中，我们将研究使用Python进行逻辑回归的编程部分。</p><p id="23d9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上一部分— <a class="ae jv" rel="noopener" href="/analytics-vidhya/logistic-regression-part-i-transformation-of-linear-to-logistic-395cb539038b?source=your_stories_page---------------------------">逻辑回归第一部分—线性到逻辑的转换</a></p><p id="9f15" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你发现任何更正，我真的很感激知道，请在评论中添加它。</p><p id="d355" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谢谢大家！👍</p><p id="45c0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">喜欢支持？只需点击拍手图标👏想吃多少就吃多少。</p><p id="a063" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">编程快乐！🎈</p></div></div>    
</body>
</html>