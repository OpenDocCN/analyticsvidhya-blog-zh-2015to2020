<html>
<head>
<title>The Math behind Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归背后的数学</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/the-math-behind-linear-regression-fe1306bf0d8c?source=collection_archive---------23-----------------------#2020-03-21">https://medium.com/analytics-vidhya/the-math-behind-linear-regression-fe1306bf0d8c?source=collection_archive---------23-----------------------#2020-03-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4e52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我们将深入研究线性回归的数学。我会尽量不使用多元微积分把背后的方程解释透彻。希望最终我们能够用python编写我们自己的线性回归类。作为先决条件，你需要知道基本的微分和矩阵乘法，你会很好地跟进。那我们开始吧。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/b44cac218190c88d4c5b15a74657bc8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RmWLl7FJuMdBFQLSWzkyAA.jpeg"/></div></div></figure><h1 id="280d" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是线性回归？</h1><p id="f87b" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">简而言之，如果我不得不这么说，那么线性回归就是寻找预测变量(x)和因变量(y)之间的线性关系的过程。需要注意的一点是，当我说线性时，我指的是一次方程。所以一个有p列的预测器将有一个形式方程</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ks"><img src="../Images/171e23a45eb8282befe2ca1bc8936fa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*59Q59irpo4t4wkaK4J9JZg.png"/></div></figure><h1 id="190c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">寻找解决方案:</h1><p id="5e2c" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">先说最简单的情况。一个数据点和一个预测值。然后，</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kt"><img src="../Images/6e32ca2cb12e7e5ab52cbfb07a257a61.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*LnRebYmKuptQxxq9KA3u9Q.png"/></div></figure><p id="7a4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以定义一个值始终为1的预测值x₀。这将有助于我们在前进时简化方程式。所以现在这个等式会变成</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ku"><img src="../Images/ef29281446bb74f2669a12fe221a6e0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*GPBaI6EYuIeIFk_Mz7F22g.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated"><strong class="bd jr">(方程式1) </strong></figcaption></figure><p id="f2ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们定义一个行矩阵X</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kz"><img src="../Images/39563a65f2c1f6167aaff85442252efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:226/format:webp/1*nNpORAMmQcFnFVD_wj0MNA.png"/></div></figure><p id="c7e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和列矩阵β</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es la"><img src="../Images/8e2a2b1bfd07b997a10a48fce4ca27c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:162/format:webp/1*BRY8EhcdlEMgL1RwM8LL-g.png"/></div></figure><p id="54e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么做Xβ会给出</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lb"><img src="../Images/7ab47e369d07b1fe44cc2d8b6b0066dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*tr6lWS8nfpdZeaY7ZHEquA.png"/></div></figure><p id="d551" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它看起来很像等式1的RHS。那如果我们定义Y = [y]呢？然后我们可以写作</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lc"><img src="../Images/55a99da78073deff5c7117b8e5bcd8c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:192/format:webp/1*ohNtecT1ZjjewYOgWkradQ.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated"><strong class="bd jr">(方程式2) </strong></figcaption></figure><p id="ed69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们把这个放在一边，专注于等式1。我们知道这个等式不成立。除非有人给出正好位于一条直线上的点，否则这永远不会发生。那么下一个最好的选择是什么？我们可以最小化与原始值的差异/误差。我们将使用平方误差作为误差度量。(选择这个作为误差度量有很多好的理由。如果你想了解它，我会附上一些链接)</p><p id="021a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我们的误差函数是，</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ks"><img src="../Images/637cd6c214623ed808b1eac71f17d497.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*Gr86j4GCC1YTTi428_KhsA.png"/></div></figure><p id="8107" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意误差是β0和β1的函数。那是因为数据点已经给了。我们唯一能改变的是系数。我们的目标是尽量减少误差。如果你还记得微积分的话，我们对一个函数求导，然后把它设置为0来找到最小点。因为这里有两个变量，我们将对β0和β1做偏导数。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ld"><img src="../Images/c15f526c833b1293412612db591e94b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*VBJroGTriRqn1XEyE4KAiw.png"/></div></figure><p id="e20f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你熟悉微积分，这是一个相当简单的微分。我想让你注意一件事。看看在每一行中x0和x1是如何按行主顺序排列的，但是在外面相乘的x0和x1是按列主顺序排列的。有印象吗？是啊！矩阵的转置。</p><p id="e1e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们知道表达式[y-(x0β0 + x1β1)]与Y-Xβ相同。如果我们将列向量de/dβ定义为</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/27099bc329c5842da0bdb0b5222a3fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:166/format:webp/1*8B5gDcjf793_Qv8sEvMnsw.png"/></div></figure><p id="301e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我们可以将矩阵形式的方程修正为</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/96fbb66c7be18d480b70302e94e23a90.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*rShDIHoSCqimluu7g441qQ.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated"><strong class="bd jr">(方程式3) </strong></figcaption></figure><p id="2f6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好吧！但是如果我们有两个数据点呢？然后我们将误差定义为两点的误差之和。这些我就不多解释了，不过和我们之前做的很像。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lg"><img src="../Images/fac8973a393a3049c01c324cf953475a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*coQ7ogwEiPBGgpjzug-YOw.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lg"><img src="../Images/703a1bd8bf76ba6838b8326ff54c9e2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*r8Mddtsld1hY26e4vBZ_8g.png"/></div></figure><p id="59ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看起来有点复杂。但我们确实有一个简单的公式，如公式3所示。如果我们只是扩展定义呢？</p><p id="bb09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">y成为一个列向量</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lh"><img src="../Images/f96a804e0542905266238023d72fbbe5.png" data-original-src="https://miro.medium.com/v2/resize:fit:146/format:webp/1*RdoaLiKfdKHOwK2WuPsnIA.png"/></div></figure><p id="208b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">X变成了一个矩阵</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es li"><img src="../Images/a2b612fa0a22039b907bf469e49ebc47.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*uw5MwAIPanhChc0vjI-M1A.png"/></div></figure><p id="9252" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">转置操作在x上仍然有效。如果我们计算等式3的RHS，我们有</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lj"><img src="../Images/604f3ac321300ffdfc84f6e066b755b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*TX_Ssict1kzinO-wUGjUJQ.png"/></div></figure><p id="7b01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很酷吧？我们也可以简单地通过观察外围的x <a class="ae lk" href="https://www.compart.com/en/unicode/U+1D62" rel="noopener ugc nofollow" target="_blank"> ᵢ </a> ⱼ的排列方式和它们在Xᵀ.的排列方式一样来完成</p><p id="1fea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们已经验证了将数据点的数量增加到2，矩阵方程仍然有效。实际上，对于给定的任何数量的预测值和数据点，这都是正确的。我们的导数是</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/96fbb66c7be18d480b70302e94e23a90.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*rShDIHoSCqimluu7g441qQ.png"/></div></figure><p id="d251" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们可以让导数等于0来得到最小值。但是把一个矩阵等同于0是什么意思呢？简单。如果我们有一个条目(普通数学)，那么我们做x=0。如果两点说x，y那么[x y] = [0 0]。</p><p id="edc6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于de/dβ有p+1个条目(每个预测值和β0有一个系数)，零/空向量O将为</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/28ec76966e3b1002df48ff41727ac825.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/1*zw7jTg9MSZSTZQH2HZJ7NA.png"/></div></figure><p id="dbcc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">酷毙了。我们正在到达那里。现在求解de/dβ = O，我们有</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lm"><img src="../Images/84e6798f8e38539d2b3ff46b26cb69f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*LnED8YmoQ2umVQJN-vz7Cg.png"/></div></figure><p id="2111" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后…就这样。我们有我们想要的公式。多亏了numpy库，用python实现所有这些实际上相当容易。让我们把它编码。</p><h1 id="5378" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">代码:</h1><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="561a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以测试性能，并将其与sci-kit learn LinearRegression库进行比较，以检查它的执行情况。我们可以使用均方误差作为我们的性能指标。(从某种意义上来说，我们应该这样做，因为这是我们试图最小化的)。</p><p id="f32b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是实现这一点的代码</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="270e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">输出:</strong></p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="08f4" class="lu jq hi lq b fi lv lw l lx ly">MSE of LinearRegressor 27.13405546067299<br/>MSE of Sklearn Implementation 27.134055460672986</span></pre><p id="920c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">瞧！！结果是一样的。这是意料之中的，因为这正是sci-kit learn Library中实现线性回归的方式。所以在你到处使用你的回归类之前，这里有几点你应该记住。</p><h1 id="498f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">警告:</h1><p id="1835" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">虽然这种方法非常快速和准确，但也不是没有问题。主要有两个缺点。</p><ol class=""><li id="e22d" class="lz ma hi ih b ii ij im in iq mb iu mc iy md jc me mf mg mh bi translated">还记得我说过在最简单的情况下，取1个数据点和1个预测值吗？这实际上是不成立的。想想吧。在2D，如果我们不得不画一条线，我们至少需要2分。在3D中，对于一个平面，我们至少需要3个点。所以X有p个预测值，那么我们至少需要p+1个点(作为p个预测值轴和一个y轴)。经验法则是n&gt;p。</li><li id="e4b9" class="lz ma hi ih b ii mi im mj iq mk iu ml iy mm jc me mf mg mh bi translated">其次，如果我们有两个相关的列，比如说<em class="mn">x</em><a class="ae lk" href="https://www.compart.com/en/unicode/U+1D62" rel="noopener ugc nofollow" target="_blank"><em class="mn">ᵢ</em></a><em class="mn">=c*xⱼ</em>(其中c是某个常数)，那么我们的方法就行不通。还记得方程中的XᵀX)⁻吗？如果我们有两个相关的列，就不能计算这个值。这个解释有点复杂。一个简单直观的解释是，</li></ol><p id="3888" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“正如我们有<em class="mn">x</em><a class="ae lk" href="https://www.compart.com/en/unicode/U+1D62" rel="noopener ugc nofollow" target="_blank"><em class="mn">ᵢ</em></a><em class="mn">=c*xⱼ</em>那就是说<em class="mn"> x </em> <a class="ae lk" href="https://www.compart.com/en/unicode/U+1D62" rel="noopener ugc nofollow" target="_blank"> <em class="mn"> ᵢ </em> </a>可以通过<em class="mn"> xⱼ </em>来预测。所以在X矩阵中，我们有p-1个预测值。但是我们已经将X定义为具有p列的预测值。所以X矩阵将作为0或零矩阵(阅读奇异矩阵)。正如我们所知，0⁻，即1/0，是无法计算的。”</p><p id="e6d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实际上，即使我们可以将预测值列评估为多个列的线性组合，也是如此，例如，如果我们有</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mo"><img src="../Images/227b4e645aac4ca9e4ab6185cad35388.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*OoaaDJ5KlCGsG5euZeIkFA.png"/></div></figure><p id="b9ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么逆也不能被评估。这不是一个大问题，除非在运行回归之前删除任何相关的列。</p><p id="3d93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些就是为什么有时我们可能需要使用梯度下降的原因。我们可以在以后的文章中讨论这个问题。🙂</p><p id="d804" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以通过下面的链接在我的github repo中找到本文的代码。</p><pre class="je jf jg jh fd lp lq lr ls aw lt bi"><span id="5dae" class="lu jq hi lq b fi lv lw l lx ly"><a class="ae lk" href="https://github.com/Samarendra109/ML-Models/blob/master/linear_model/LinearRegressor.py" rel="noopener ugc nofollow" target="_blank">https://github.com/Samarendra109/ML-Models/blob/master/linear_model/LinearRegressor.py</a></span></pre><p id="4621" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您完成这篇文章。这是我第一篇关于媒介的文章。我打算写更多关于机器学习的文章。如果你喜欢这篇文章，请鼓掌。请在评论中留下你的想法。建议和意见将不胜感激。</p></div></div>    
</body>
</html>