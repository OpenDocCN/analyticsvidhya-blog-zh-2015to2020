<html>
<head>
<title>An Introduction to Natural Language Processing (NLP) Terms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理(NLP)术语介绍</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/an-introduction-to-natural-language-processing-nlp-terms-f8fe9e0a273?source=collection_archive---------11-----------------------#2020-10-05">https://medium.com/analytics-vidhya/an-introduction-to-natural-language-processing-nlp-terms-f8fe9e0a273?source=collection_archive---------11-----------------------#2020-10-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="3c0b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">什么是NLP </strong></h1><p id="3df0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">自然语言处理是一种从人类语言中提取意义的方法。它使用计算机科学、语言学和人工智能的研究成果。它通常包括执行一项任务或使一项工作变得更容易。</p><h1 id="110d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">现实生活中的NLP</strong></h1><p id="ef48" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">您将已经在实际工作中遇到过许多种NLP。这里有几个例子:</p><p id="3b31" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">-在网上搜索，让谷歌帮你完成搜索</p><p id="9057" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">-语音助手——像Alexa、Siri、Cortana、Google……能够提问，并接收智能回复</p><p id="7576" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">-拼写和语法纠正</p><p id="bfc7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">-自动将一种语言翻译成另一种语言，例如从英语翻译成西班牙语，无需人工干预。</p><p id="dd16" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">那么，计算机真的理解语言吗？不完全是。我们需要以机器可以处理的方式为模型提供语言。实际上，这意味着将单词转换成数字。在机器学习中，我们经常用向量来表示，所以在我们看一些例子之前，让我们快速复习一下向量。</p><h1 id="630b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">矢量</strong></h1><p id="9478" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">矢量的定义是一个有大小和方向的量，通常用线段来表示。</p><p id="6b1a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">如果我们组成一个两个单词的短语“国王戒指”，我们可以将它表示为一个二维向量——每个单词一个，“国王”和“戒指”。因为每个单词有一个计数，所以我们的坐标是(1，1)。</p><p id="5521" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">当然，这是一个过于简化的例子。我们现在转向多维度，其中单词而不是短语是向量。以下是一些如何将单词翻译成机器可读的数字格式的例子。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/55260abade0a63940d46552ef52908b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*HK-QnLK1_n38Fq0ELBYNyQ.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">“king ring”向量(图片基于《自然语言处理入门》中的一个示例)</figcaption></figure><h1 id="07af" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">一键编码</strong></h1><p id="96f5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">第一个例子叫做一键编码。让我们扩展一下我们之前的短语，把它改成一个句子:“<strong class="jf hj"> <em class="ks">国王戴上戒指</em> </strong>”。我们现在有了这些词:“the”、“king”、“put”、“on”、“ring”。单词“The”出现了两次。我们可以将这个句子显示为一个矩阵，其中每个单词用一列表示，每个<em class="ks">唯一的</em>单词用一行表示。每当一个单词在行和列中出现时，我们用1标记它，所有其他的例子都是0。下图对此进行了说明:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kt"><img src="../Images/33223b8c3092eb41d1f3131b4ba5581f.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*RrK2atb3HjMYo0CG6gIL9Q.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">一键编码</figcaption></figure><p id="9842" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">单词king将由向量[0，1，0，0，0，0]表示。</p><p id="2662" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">然而，这种方法效率很低。它创建了一个非常大的矩阵。即使在这个简单的例子中，你也可以看到比1多得多的0。我们称之为<strong class="jf hj">稀疏</strong>向量空间，因为大多数值都是零，只有少数值分散在其中。想象一个有几千个单词的更大的文本文档，现在我们有一个向量空间，其中不到0.1%的元素有任何值。</p><h1 id="1955" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">每个单词得到一个唯一的数字</strong></h1><p id="0737" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">第二种方法是给每个单词分配一个唯一的编号。我们的例句可以表示为:[1，2，3，4，1，5]。这被认为是一个<strong class="jf hj">密集</strong>向量，因为所有的元素都有值。这是一种更有效的资源利用。</p><p id="8f7d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">然而，这种方法也有一些问题。首先，我们分配的数字是任意的，因此它们不能反映单词之间的任何关系。第二，当我们对数据建模时，模型学习每个单词的权重。因为在单词编码的相似性和单词的相似性之间没有关系，所以加权没有意义。</p><h1 id="03b9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">单词嵌入</strong></h1><p id="39c9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">第三种方法叫做单词嵌入。单词嵌入捕获关于单词含义和位置的信息。它们之所以被称为嵌入，是因为它们将原始文本中的信息映射成几个数字，将大量信息编码成更简洁、更有意义的东西。单词嵌入模型中的值是在模型训练期间学习的，而不是由程序员分配的。</p><p id="7fd5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">单词嵌入是高维向量到低维空间的转换。每个单词由一个多维向量表示。这比稀疏单词表示所需的维数要少得多，稀疏单词表示的维数可能高达数百万。</p><p id="2773" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">更高维的单词嵌入捕捉单词之间更详细的关系，但是需要更多的数据来训练。通常，我们无法解释每个维度的含义——它们是从数据中推断出来的。这些维度被称为<strong class="jf hj">潜在维度</strong>。有意义的是嵌入空间中单词之间的距离，而不是沿着任何给定维度的数值。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ku"><img src="../Images/74e2f5f922fe4507103c5af02e44cbd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*dRkPK59s5J8lKOysYTUIew.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">单词嵌入</figcaption></figure><p id="9e3e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">上面是一个4维向量空间(每一列都是一个维度)的例句图。这些值本身并不重要，但单词之间的相似性很重要。在嵌入空间中，单词king的矢量化表示将是[1.1，-1.0，-0.8，-0.1]</p><h1 id="0fd3" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">单词嵌入可视化</strong></h1><p id="64a9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了帮助说明单词嵌入的概念，我们可以使用单词作为三维坐标的图像。距离和方向揭示了词的意义和相似性。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kv"><img src="../Images/073afea8529b21d5049132d34a5b3995.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RqHD_g5ZG4-I1vJILMOX-w.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">词语嵌入类比</figcaption></figure><p id="db15" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">来源:<a class="ae la" href="https://developers.google.com/machine-learning/crash-course/images/linear-relationships.svg" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/crash-course/images/linear-relationships . SVG</a></p><p id="f9e6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在上面的图表中，单词嵌入显示了单词“国王”和“王后”的关系与“男人”和“女人”的关系相同，即男女关系。我们也看到动词意义和国家及其首都之间的关系。还要注意，亚洲国家和欧洲国家被分组在一起。这些关系的不同寻常之处在于，模型完全是从文本中生成的，而不是从任何编程指令中生成的，比如“安卡拉是土耳其的首都”。</p><p id="702a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">也许最吸引人的是我们可以进行单词向量运算。将“国王”的维度相加，将“男人”的维度相减，再加上“女人”，我们就非常接近“女王”的向量了。同样，我们可以对国家和城市做同样的事情。</p><p id="a9f8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">国王-男人+女人=王后</strong></p><p id="e9be" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">东京-日本+德国=柏林</strong></p><h1 id="fc39" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">关于上下文的一切</strong></h1><p id="7849" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">所有这些魔法是如何发生的？该模型根据单词周围单词的上下文来计算单词的含义。</p><blockquote class="lb lc ld"><p id="4f27" class="jd je ks jf b jg kb ji jj jk kc jm jn le kd jq jr lf ke ju jv lg kf jy jz ka hb bi translated">"从一个人交的朋友，你就可以知道这个人说的话."弗斯，J. (1957)。语言分析研究。</p></blockquote><p id="60f3" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">有两种方法可以从上下文中确定意思。第一种方法叫做<strong class="jf hj">连续词袋(CBOW) </strong>。CBOW查看周围的单词，试图预测我们的目标世界。在我们的例句中，它试图从“戴上戒指”来预测“国王”。</p><p id="7c22" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> Skip-gram </strong>的工作方式与CBOW相反。它使用单词作为输入，并试图预测它周围的单词。</p><p id="183f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这两种方法都在<strong class="jf hj"> word2vec </strong>模型中使用。据word2vec的作者称，CBOW速度更快，而skip-gram在处理不常用词方面做得更好。</p><h1 id="ca43" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">下一次</strong></h1><p id="2bda" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在未来的博客中，我们将探索所有这些部分如何在实践中协同工作</p><h1 id="5024" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">参考文献</strong></h1><p id="e660" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae la" href="https://code.google.com/archive/p/word2vec/" rel="noopener ugc nofollow" target="_blank"> word2vec </a></p><p id="0a3a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae la" href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture" rel="noopener ugc nofollow" target="_blank">机器学习/速成班/嵌入</a></p><p id="7b31" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae la" href="https://www.tensorflow.org/tutorials/text/word_embeddings" rel="noopener ugc nofollow" target="_blank">tensorflow.org/tutorials/text/word_embeddings</a></p><p id="2e6d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae la" href="https://israelg99.github.io/2017-03-23-Word2Vec-Explained/" rel="noopener ugc nofollow" target="_blank">word 2 vec-已解释</a></p><p id="2867" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae la" href="https://machinelearningmastery.com/what-are-word-embeddings/" rel="noopener ugc nofollow" target="_blank">machinelearningmastery.com</a></p><p id="323c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">《深度学习图解:人工智能的可视化互动指南》,作者:克罗恩·乔恩</p><p id="151c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">《从零到人工智能:人工智能时代的非技术性、无炒作的繁荣指南》,作者Nicolò Valigi，Gianluca Mauro</p><p id="3520" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">《自然语言处理入门》，作者Kochmar，Ekaterina</p></div></div>    
</body>
</html>