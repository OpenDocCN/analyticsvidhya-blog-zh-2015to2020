<html>
<head>
<title>Deep Learning book in plain English Ch1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">浅显英语深度学习书Ch1</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-book-in-plain-english-ch1-2f73e9b71acb?source=collection_archive---------18-----------------------#2019-12-05">https://medium.com/analytics-vidhya/deep-learning-book-in-plain-english-ch1-2f73e9b71acb?source=collection_archive---------18-----------------------#2019-12-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7cddce257a7ff058088647f021069da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hSD1T-V1MpGkgz4i"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">比阿特丽斯·佩雷斯·莫亚在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="93ff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个故事是我对伊恩·古德菲勒、约舒阿·本吉奥和亚伦·库维尔的《深度学习》一书(Ch2)的直觉总结</p><h2 id="7ee9" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">向量和张量</h2><p id="fd74" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">我将从任何系统的这两个关键模块开始，我跳过矩阵和标量值，因为我认为它们对许多读者来说是非常明显的。</p><h2 id="e9eb" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">向量</h2><p id="d16f" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">一组数字，我们可以认为是一组坐标，每个值在不同的轴上，例如x = [1，2]，x是一个向量，值在两个不同的轴上。</p><h2 id="8a96" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">张量</h2><p id="b806" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">我之所以从向量开始，实际上是为了将它们与张量进行比较，因为这种比较总是让我很困惑。张量是具有多于2个值的数组，例如x = (1，2，3，..)</p><h2 id="9c4e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">乘法矩阵</h2><p id="07ef" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">深度学习的主要运算之一是矩阵乘法。例如，让我们考虑一个输入数据[0，1，2]和一个密集的权重向量转置层([0.1，0.2，0.3])(注意，我添加了转置，因为我需要将行向量转换为列向量，以便能够用它执行矩阵乘法)</p><p id="31a8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该操作转换为A = XB，执行如下:</p><p id="1f78" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">0*0.1 + 1*0.2 + 0.3*2 = value，这就是我们数据的行向量和权重的列向量之间的点积。当您在网络中添加密集层时，就会发生这种情况。这不同于所谓的hadamard乘积(元素式乘积)，其执行如下:</p><p id="8a0b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">结果= [0*0.1，1*0.2，0.3*2] = [0，0.2，0.6]</p><p id="7aa5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">欲了解更多关于矩阵乘法和哈达玛乘积的区别，<a class="ae iu" rel="noopener" href="/linear-algebra/part-14-dot-and-hadamard-product-b7e0723b9133">链接</a></p><h2 id="d22e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">矩阵特征</h2><p id="d20e" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">矩阵乘法是不可交换的，</p><p id="7f34" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">AB！= BA</p><p id="3bb7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而向量之间的点积是可交换的，</p><p id="e384" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">转置(x) * y =转置(y)*x</p><h2 id="0005" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">什么是规范？</h2><p id="dac3" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">有时我们需要测量一个给定向量的大小，所以我们简单地使用范数函数来做，范数函数只是简单地将向量映射到非负值，因为它们是从原点pt到向量x的距离。</p><p id="d79c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">机器学习中最常用的范数之一是L2范数，它被称为欧几里德范数，并被简单地计算为x *转置(x)</p><p id="c9e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一个范数函数是L1范数，当向量中的零和非零元素之间的差异非常重要时使用，因为当值从零变为非零时，它赋予很大的权重。例如，如果向量中的值从0变到10，L1增加10</p><p id="bae6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一个范数函数是最大范数，它是向量中的最大元素。</p><h2 id="ba88" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">特殊类型的矩阵和向量</h2><p id="f816" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">对角矩阵</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es kt"><img src="../Images/5a1c3cf90719f271d18c348eaa0fb3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*CSUd91qYjOAFbO_gfh0w4g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">只有对角线上的非零值</figcaption></figure><p id="c1f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对称矩阵</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/2844d10cd2dd0decec82a9caf6014b91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*u6Hq5yGlyyMASPZupL9vmw.png"/></div></figure><p id="98cf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">A =转置(A)</p><p id="e2fd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正交向量</p><p id="d9f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">是范数大于0并且彼此成90度的向量，这意味着如果向量x正交于向量y，则转置(x) * y = 0</p><p id="8992" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由此产生正交矩阵，其向量(列)相互正交。因此，如果我们有矩阵A和B，它们是正交的，那么，转置(A)*B = A *转置(B) =单位矩阵</p><h2 id="f86b" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">特征分解</h2><p id="b6e5" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">把它想象成把物体的大部分分解成更小更直观的部分。这本书实际上给出了一个很好的例子:如果我们可以用2*2*3来表示数字12，那么这些微小的部分给了我们什么信息呢？也许12能被2除尽，但不能被5除尽</p><p id="6d01" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样的想法也适用于特征分解，我们需要将矩阵分为向量和特征值，这是一个简单的计算矩阵a的方程。</p><p id="999b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">a* x =λ* x</p><p id="50a5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们举个例子来知道这是从哪里来的。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/9d3572a2b4b995b38618f643a89a4f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FVbgZh6qB4ZJwgteCG6O3A.png"/></div></div></figure><p id="dee9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们有一个矩阵A，我们把它乘以一个向量x，如果你注意到结果是向量的3倍，实际上我们可以把整个操作重写如下。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es la"><img src="../Images/6a2296dbf54e612842e4b3c7ae716c5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*rdGDtKKHyX4jZu8ge1ELiQ.png"/></div></figure><p id="af73" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这告诉我们，3实际上是一个特征值，向量[1，1，2]是一个特征向量，矩阵A的特征向量是一个向量，对于某个数λ给出这个方程</p><p id="9e56" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">ax =λx</p><p id="45e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有无限数量的特征向量，但是有限数量的特征值——每个特征值有它自己的特征向量集。我们需要找到特征值来得到特征向量</p><h2 id="c2bc" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">奇异值分解</h2><p id="f58b" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">遵循相同的思想，但是SVD是3个矩阵U * E *转置(V)的乘积，对于大小为m*n的矩阵A，U的大小为m*m，E的大小为m*n，V的大小为n*n，其中V是转置(A)* A的特征向量，U是转置(A)的特征向量</p><p id="0acb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">计算V:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lb"><img src="../Images/0abb82db0fe219f04a502501c05bb84c.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*mC1lKuAqPkGus4-PxMQtBg.png"/></div></figure><p id="5a42" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">计算E:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/ab0b59ed3f5ce0a11ab658a80c810b30.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*vb6nfeWfdjLiz4PmrKXGXA.png"/></div></figure><p id="5180" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">u = V as a*转置(A) =转置(A)*A</p><p id="45da" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们有了SVD的3个分量，我们可以很容易地计算它了！</p><h2 id="ffe7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">决定因素</h2><p id="540b" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">通过计算给定矩阵的所有特征向量的和，将矩阵映射到标量值</p><h2 id="aad6" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">简单机器学习算法</h2><h2 id="82a2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">主成分分析</h2><p id="a5c8" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">它只是简单地将巨大的数据解码成更小的数据，但这怎么可能呢？我们只是表示同一数据的一个低维版本，因此它可能会更小。有时我们会丢失数据中的一些重要特征，这就是问题所在。为了找到一种解码数据而丢失较少信息的方法，PCA函数就是y(x) =转置(D)* x，其中D是解码器向量，x是我们的原始数据，所以我现在想到了一个重要的问题。</p><p id="b8b5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们实际上如何得到这个D向量，简单地说，我们得到Di使得xi的L2范数和所代表的pt xi(Xi在低维中的代表)是最小的，我听到你我如何计算所代表的pt Xi首先，会告诉你</p><p id="2fb6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">主要等式是，</p><p id="5f7b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">D = min(sqrt(sum(xj-r(xj))))，r(xj)是表示的pt</p><p id="3feb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但实际上:r(x)= D *转置(D)*x</p><p id="ef79" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以我们可以代入第一个方程，得到满足要求的D。这个等式在书中有很长的实现，但我只是给出了它背后的主要直觉。</p><p id="e882" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我希望你喜欢这个漫长系列的第一部分！</p><p id="745b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谢谢</p></div></div>    
</body>
</html>