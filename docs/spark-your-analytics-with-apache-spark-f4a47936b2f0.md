# å€ŸåŠ© Apache Spark æ¿€å‘æ‚¨çš„åˆ†æžèƒ½åŠ›ðŸŒŸ

> åŽŸæ–‡ï¼š<https://medium.com/analytics-vidhya/spark-your-analytics-with-apache-spark-f4a47936b2f0?source=collection_archive---------8----------------------->

åœ¨æ·±å…¥åˆ°ä¸€ä¸ªç®€å•çš„ç”¨ä¾‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆäº†è§£ä¸€ä¸‹ Apache Spark çš„å®šä¹‰ã€‚
**Apache Spark:** Spark æ˜¯ä¸€ä¸ªå†…å­˜ä¼˜åŒ–çš„æ•°æ®å¤„ç†å¼•æ“Žï¼Œå¯ä»¥å¯¹ Hadoop æ•°æ®(åœ¨ HDFS)æ‰§è¡Œæ“ä½œï¼Œæ€§èƒ½ä¼˜äºŽ MapReduceã€‚

è¿™æ„å‘³ç€ï¼ŒApache Spark æä¾›äº†ä»¥åˆ†å¸ƒå¼æ–¹å¼è¿è¡Œå•ä¸ªä½œä¸šçš„èƒ½åŠ›ï¼Œå…¶ä¸­ï¼ŒèŒƒå›´ä»Žä¸¤ä¸ªèŠ‚ç‚¹åˆ° 1000 ä¸ªèŠ‚ç‚¹çš„èŠ‚ç‚¹ç¾¤é›†(ä¸ºç®€å•èµ·è§ï¼Œæ˜¯ä¸€ç»„è®¡ç®—æœº)è¢«ç»„è£…èµ·æ¥åœ¨å†…å­˜ä¸­æ‰§è¡Œä¸€é¡¹ä½œä¸šï¼Œå¹¶ä¸”å…·æœ‰è¶³å¤Ÿçš„å®¹é”™èƒ½åŠ›æ¥è·Ÿè¸ªä»»ä½•ä¸¢å¤±çš„èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶ä»»åŠ¡(èŒè´£)åˆ†é…ç»™ç¾¤é›†ä¸­ä»»ä½•å…¶ä»–å¯ç”¨çš„èŠ‚ç‚¹ï¼Œæœ€ç»ˆæ‰€æœ‰èŠ‚ç‚¹éƒ½å‘é©±åŠ¨ç¨‹åºèŠ‚ç‚¹(é¢†å¯¼èŠ‚ç‚¹)æŠ¥å‘Šä½œä¸šçš„ç»“æžœã€‚

![](img/c37dbd8685e99527ff8eb3817a1b2885.png)

å›¾ç‰‡æ¥æº:[https://unsplash.com](https://unsplash.com/)

ä¸€ä¸ªç®€å•çš„ç”¨ä¾‹æ˜¯å‡è®¾ç”¨æˆ·æƒ³è¦æ‰¾åˆ°ä»–çš„å•†åº—ä¸­é”€é‡æœ€å¤§çš„æ‚è´§é¡¹ç›®ï¼Œè¯¥å•†åº—åœ¨ 2010 å¹´è‡³ 2011 å¹´æœŸé—´æ‹¥æœ‰å¤§çº¦ 10ï¼Œ000 åå®¢æˆ·ï¼Œç”¨æˆ·åªéœ€è¿è¡Œä¸€ä¸ªæä¾›è¯¥é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯çš„ SQL æŸ¥è¯¢ã€‚
çŽ°åœ¨ï¼ŒåŒä¸€ç”¨æˆ·å¸Œæœ›ç¡®å®š 2000 å¹´è‡³ 2019 å¹´æœŸé—´æ¯ä½é¡¾å®¢è´­ä¹°æœ€å¤šçš„æ‚è´§ï¼Œå‡è®¾é”€å”®é¢å¾ˆé«˜ï¼Œå¹¶ä¸”åœ¨æŸä¸€å¤©è‡³å°‘æœ‰ 3000 ç¬”é”€å”®é¢ã€‚è¿™ä¸ºæˆ‘ä»¬æä¾›äº†æ¯ä¸ªå®¢æˆ·çš„é”€å”®è®°å½•è®¡æ•°(2000â€“2019)æ€»è®¡ _ å¤©æ•°*æ€»è®¡ _ é”€å”®æ•°é‡= 9ã€***ã€***ã€***..æˆ–è€…å¯èƒ½æ›´å¤šã€‚åœ¨è¿™ä¸ªç”¨ä¾‹ä¸Šè¿è¡Œä¼ ç»Ÿçš„ SQL æŸ¥è¯¢ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚
Apache Spark å¼€å§‹è¡ŒåŠ¨ï¼Œæ‹¯æ•‘æˆ‘ä»¬çš„åˆ›é€ åŠ›ã€‚

**ç¤ºä¾‹ç”¨ä¾‹:**
è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªç®€å•çš„ CSV(é€—å·åˆ†éš”å€¼)æ–‡ä»¶ï¼Œå®ƒåŒ…å« 4 åˆ—ï¼Œå¤§çº¦æœ‰ 9997851 æ¡è®°å½•ã€‚
userIdï¼Œmovieï¼Œratingï¼Œtimestamp
18295ï¼Œ909090ï¼Œ2.5ï¼Œ1515203646000
åœ¨ä¸Šè¿°æ•°æ®çš„å¸®åŠ©ä¸‹ï¼Œå¯ä»¥å¯¼å‡º n ä¸ªåˆ—ï¼Œè¿™æœ‰åŠ©äºŽå¼€å‘è€…å’Œ/æˆ–æ•°æ®åˆ†æžå¸ˆåŸºäºŽç”¨æˆ·è¡Œä¸ºåšå‡ºå»ºè®¾æ€§çš„å†³ç­–ã€‚
å¯¹äºŽè¿™ä¸ªåœºæ™¯ï¼Œæˆ‘åœ¨è£…æœ‰ **IntelliJ IDE** å¹¶å®‰è£…äº†**Spark çš„æœ¬åœ°æœºå™¨(ç¬”è®°æœ¬ç”µè„‘)ä¸Šè¿è¡Œ Spark(æˆ‘å°†åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­è®¨è®ºå¦‚ä½•è®¾ç½® IntelliJ å’Œ Spark)**ã€‚å¦‚æžœæ‚¨æ„¿æ„çš„è¯ï¼Œä¹Ÿå¯ä»¥åœ¨ä¸€ä¸ª 100 å€èŠ‚ç‚¹çš„é›†ç¾¤ä¸Šä½¿ç”¨ spark session-cluster_level è®¾ç½®è¿è¡Œã€‚

**è®¡åˆ’å¯¹æ•°æ®æ‰§è¡Œä»»ä½•ç±»åž‹çš„åˆ†æžæ—¶è¦é—®çš„é—®é¢˜ï¼Ÿ
-æ•°æ®è´¨é‡å¦‚ä½•ï¼Ÿ
-æ•°æ®ä¸­æœ‰å¤šå°‘ç©ºå€¼æˆ–ç©ºå­—ç¬¦ä¸²ï¼Ÿ
-è¿™äº›æ•°æ®æ˜¯å¦åŒ…å«è¶³å¤Ÿçš„ç”¨æˆ·æ ‡è¯†æˆ–äº§å“æ ‡è¯†ï¼Œä»¥ä¾¿åšå‡ºå†³ç­–ï¼Ÿ
-æ˜¯å¦éœ€è¦æ ¼å¼æ ‡å‡†åŒ–ï¼Ÿæ¯”å¦‚æ—¥æœŸæ ¼å¼ã€User_id æ ¼å¼æˆ–æ›¿æ¢ç©ºå€¼ç­‰â€¦â€¦
-æˆ‘å¯ä»¥åŸºäºŽä»»ä½•åˆ—å€¼(æ¯”å¦‚æ—¥æœŸ****-**-01ã€æ—¥æœŸ****-**-02)å¯¹æ•°æ®è¿›è¡Œåˆ†åŒºä»¥æé«˜æ€§èƒ½å—ï¼Ÿ**

åœ¨è¿™ä¸ªæ•…äº‹ä¸­ï¼Œè®©æˆ‘ä»¬åŸºäºŽå•ä¸ª User_Id å¯¼å‡ºä¸‹é¢çš„åˆ—ã€‚

```
user_id â€” The User ID.
mov_watch_count â€” No. of Movies watched by that User. 
latest_movie_rated â€” The Movie_id which User recently rated.
first_movie_rated â€” The Movie_id which User First rated.
more_than_six_rtngs â€” Does the user rated more than 6 movies? Y/N
less_than_two_rtngs â€” Does the user rated less than 2 movies? Y/N
highest_rating â€” The Highest rating given by the User ever.
lowest_rating â€” The Lowest rating given by the User ever.
```

è®©æˆ‘ä»¬å¿«é€Ÿæµè§ˆä¸€ä¸‹å¦‚ä½•å®žçŽ°è¿™ä¸€ç‚¹çš„ä»£ç ç‰‡æ®µï¼Œä¸‹é¢å°†åŒ…å«é‡è¦çš„ã€‚

åˆ›å»ºä¸€ä¸ª spark ä¼šè¯ï¼Œå®ƒæ˜¯ Spark åº“ä¸–ç•Œçš„å…¥å£ã€‚

```
**//Create your sparkSession to Light it up.**
val spark = SparkSession
  .*builder*()
  .appName("userIdAndRatings")
  .master("local[*]")
  .config("spark.sql.warehouse.dir", "file:///C:/temp")
  .getOrCreate()
**//Read the CSV File(There are multiple ways to do this.)**
val rawRecords = spark.read.format("csv")
  .option("header", "true")
  .option("delimiter", ",")
  .option("inferSchema", "true")
  .load("C:/sparktempfiles/training.csv")
rawRecords.printSchema()
rawRecords.createOrReplaceTempView("raw_records_view")
**//Fix the Time Column from Epoch time to Human readable Date**
val rawRecordsTimeFix =
  """
    |select userId, movieId, rating, date_format(from_unixtime(timestamp/1000), 'yyyy-MM-dd') as dateOfRating
    |from raw_records_view
  """.stripMargin
```

æƒ³å‡ºæœ€ç»ˆè¡¨æ ¼æˆ–æ•°æ®å¸§æˆ– CSV å¤´æ–‡ä»¶çš„å¸ƒå±€ã€‚

```
**//Create LayOut for your Output Table** val *userRatingsLayout* = *StructType*(
  StructField("user_id", IntegerType, true) ::
    StructField("mov_watch_count", IntegerType, true) ::
    StructField("latest_movie_rated", IntegerType, true) ::
    StructField("first_movie_rated", IntegerType, true) ::
    StructField("more_than_six_rtngs", StringType, true) ::
    StructField("less_than_two_rtngs", StringType, true) ::
    StructField("highest_rating", DoubleType, true) ::
    StructField("lowest_rating", DoubleType, true) ::
    *Nil*)
```

åˆ›å»ºä¸€ä¸ªåŽŸå§‹è®°å½•å¯¹è±¡ï¼Œç„¶åŽå¯¹ user_id è¿›è¡Œåˆ†ç»„ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼Œä¸ºæ¯ä¸ªç”¨æˆ·æ´¾ç”Ÿæ–°åˆ—ã€‚

```
**//Construct DataFrame which can shown on Console, can be saved as CSV file or as a Table.**
val rawRecordsConstruct = spark.sql(rawRecordsTimeFix).map(RawRatings.*parse*(_)).groupByKey(_.user_id).mapGroups {
  case (user_id, ratings_iter) => {
    val ratings_List = ratings_iter.toList
val ratings_attr_vals = *getRatingsAttributes*(ratings_List) *Row*(user_id, ratings_attr_vals.mov_watch_count, ratings_attr_vals.latest_movie_rated, ratings_attr_vals.first_movie_rated, ratings_attr_vals.more_than_six_rtngs, ratings_attr_vals.less_than_two_rtngs, ratings_attr_vals.highest_rating, ratings_attr_vals.lowest_rating)
  }
}(*userRatingsColumnsEncoder*)
```

åˆ›å»ºä¸€ä¸ªä¸ºæˆ‘ä»¬çš„è¡¨å¸ƒå±€è®¡ç®—åˆ—å€¼çš„æ–¹æ³•ã€‚

```
def getRatingsAttributes(rawList: List[RawRecords]): ratingsRec = {
 **//Create variables which has to be returned.** var user_id = 999999
  var mov_watch_count = 999999
  var latest_movie_rated = 999999
  var first_movie_rated = 999999
  var more_than_six_rtngs = "NA"
  var less_than_two_rtngs = "NA"
  var highest_rating: Double = 999999.0
  var lowest_rating: Double = 999999.0 user_id = rawList.map(x => x.user_id).head.toInt
  mov_watch_count = rawList.map(x => x.movie_id).size
  latest_movie_rated = rawList.sortWith(_.date_of_rating > _.date_of_rating).map(x => x.movie_id).head
  first_movie_rated = rawList.sortWith(_.date_of_rating < _.date_of_rating).map(x => x.movie_id).head
  more_than_six_rtngs = if (rawList.map(x => x.rating).size > 6) "Y" else "NA"
  less_than_two_rtngs = if (rawList.map(x => x.rating).size < 2) "Y" else "NA"
  highest_rating = rawList.map(x => x.rating).sortWith(_ > _).head
  lowest_rating = rawList.map(x => x.rating).sortWith(_ < _).head *ratingsRec*(user_id, mov_watch_count, latest_movie_rated, first_movie_rated, more_than_six_rtngs, less_than_two_rtngs, highest_rating, lowest_rating)
}***//Show the Results on IntelliJ Run Window.*** *println*("Showing the Results now")
rawRecordsConstruct.show(false)
```

æ˜¯æ—¶å€™ç‚¹å‡» IntelliJ ä¸Šç»¿è‰²æŒ‰é’®(æˆ–)è¿è¡Œç¨‹åºæ¥æŸ¥çœ‹è¾“å‡ºç»“æžœäº†ã€‚Spark å¼€å§‹å·¥ä½œï¼Œä¸åˆ°ä¸€åˆ†é’Ÿå°±è¿”å›žç»“æžœã€‚

**æ³¨æ„**:ä¸Šé¢çš„ User_id å’Œ movie_id éƒ½æ˜¯é‡æž„çš„ã€‚

å¥½äº†ï¼Œä½ è®¤ä¸ºæˆ‘ä»¬è¿˜å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å“ªäº›åˆ—ï¼Œæ¯”å¦‚ç»™å®šç”¨æˆ·çš„**ä¸€å¹´å†…æ²¡æœ‰ç”µå½±è¢«è§‚çœ‹ï¼Œä¸€ä¸ªæœˆå†…æ²¡æœ‰ç”µå½±è¢«è§‚çœ‹ï¼Œ**ç­‰ç­‰..
å¦‚æžœæˆ‘ä»¬å¯ä»¥ç”¨**â€˜movie_idâ€™s and Movie _ Nameâ€™**åŠ å…¥ Movie _ Id çš„ backï¼Œå¹¶æ ¹æ®ç”¨æˆ·è¯„çº§æ‰¾åˆ°æœ€å—æ¬¢è¿Žçš„ç”µå½±æˆ–å‘ç”¨æˆ·æŽ¨èç”µå½±ï¼Œæˆ‘ä»¬å°†å¾ˆå¿«çœ‹åˆ°è¿™äº›ç»“æžœã€‚

æ¬¢è¿Žä»»ä½•å»ºè®®ã€‚
æ‰¾åˆ°æˆ‘çš„ GitHub å­˜å‚¨åº“é¡µé¢ï¼Œå…¶ä¸­åŒ…å«äº†æœ¬æ–‡ä½¿ç”¨çš„å…¨éƒ¨ä»£ç :[https://github.com/pavanobj/spark_series](https://github.com/pavanobj/spark_series)
ç½‘ä¸Šæœ‰å¾ˆå¤šå…è´¹çš„æ•°æ®é›†ï¼Œå¯ä»¥ç”¨æ¥è¿›è¡Œå„ç§åˆ†æžã€‚

æ„Ÿè°¢æ‚¨èŠ±æ—¶é—´é˜…è¯»æœ¬æ–‡ï¼Œä¸‹æ¬¡å†è§ðŸ˜ƒ