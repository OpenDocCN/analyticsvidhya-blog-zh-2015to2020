<html>
<head>
<title>ML13: PyTorch — Simple Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML13: PyTorch —简单线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ml13-e52e251d41c5?source=collection_archive---------18-----------------------#2020-12-18">https://medium.com/analytics-vidhya/ml13-e52e251d41c5?source=collection_archive---------18-----------------------#2020-12-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ddd1" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用 torch.nn 构建一个简单的用例</h2></div><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="dcf0" class="jg jh hi jc b fi ji jj l jk jl">Read time: 25 min</span><span id="09f4" class="jg jh hi jc b fi jm jj l jk jl">Complete code on Colab: <a class="ae jn" href="https://bit.ly/2J7d9YG" rel="noopener ugc nofollow" target="_blank">https://bit.ly/2J7d9YG</a></span></pre><p id="1f4c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们从零开始建立两个非常相似的 NN 简单线性回归模型—<strong class="jq hj">NN by torch . NN</strong>&amp;<strong class="jq hj">NN</strong>；尽管如此，我们将主要关注 torch 的<strong class="jq hj">NN . NN</strong>模型，因为它更适用于现实世界的场景，并将<strong class="jq hj"> NN 从零开始</strong>模型放在附录中。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><blockquote class="kr ks kt"><p id="e880" class="jo jp ku jq b jr js ij jt ju jv im jw kv jy jz ka kw kc kd ke kx kg kh ki kj hb bi translated"><strong class="jq hj"> <em class="hi">大纲</em></strong><em class="hi"><br/>【1】</em><a class="ae jn" href="#07c6" rel="noopener ugc nofollow"><em class="hi">准备数据</em></a><em class="hi"><br/>【2】</em><a class="ae jn" href="#b13d" rel="noopener ugc nofollow"><em class="hi">数据拆分</em></a><em class="hi"><br/>【3】</em><a class="ae jn" href="#3bb0" rel="noopener ugc nofollow"><em class="hi">训练数据散点图</em></a><em class="hi"><br/></em><a class="ae jn" href="#3d41" rel="noopener ugc nofollow"><em class="hi">训练模型— NN </em> </a><a class="ae jn" href="#57d8" rel="noopener ugc nofollow"> <em class="hi">试验数据拟合线—1</em></a><em class="hi"><br/>(8)</em><a class="ae jn" href="#fd85" rel="noopener ugc nofollow"><em class="hi">试验数据拟合线—2</em></a><em class="hi"><br/>(9)</em><a class="ae jn" href="#2078" rel="noopener ugc nofollow"><em class="hi">汇总</em></a><em class="hi"><br/>(10)</em><a class="ae jn" href="#9b40" rel="noopener ugc nofollow"><em class="hi">附录</em></a></p></blockquote></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><p id="2711" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们已经在<strong class="jq hj"> ML05 </strong>中仅仅通过 NumPy 建立了一个 NN 模型，并且在<strong class="jq hj"> ML12 </strong>中介绍了 PyTorch 中的一些张量运算。所以，是时候在 PyTorch 中建立 NN 模型了。</p><div class="ky kz ez fb la lb"><a href="https://merscliche.medium.com/ml12-59d2a56737ac" rel="noopener follow" target="_blank"><div class="lc ab dw"><div class="ld ab le cl cj lf"><h2 class="bd hj fi z dy lg ea eb lh ed ef hh bi translated">ML12:详细的 PyTorch 教程</h2><div class="li l"><h3 class="bd b fi z dy lg ea eb lh ed ef dx translated">关于张量运算的一切</h3></div><div class="lj l"><p class="bd b fp z dy lg ea eb lh ed ef dx translated">merscliche.medium.com</p></div></div><div class="lk l"><div class="ll l lm ln lo lk lp lq lb"/></div></div></a></div><div class="ky kz ez fb la lb"><a href="https://merscliche.medium.com/ml05-8771620a2023" rel="noopener follow" target="_blank"><div class="lc ab dw"><div class="ld ab le cl cj lf"><h2 class="bd hj fi z dy lg ea eb lh ed ef hh bi translated">ML05:Numpy 的 iris 上的神经网络</h2><div class="li l"><h3 class="bd b fi z dy lg ea eb lh ed ef dx translated">由感知器从零开始发现神经网络元素</h3></div><div class="lj l"><p class="bd b fp z dy lg ea eb lh ed ef dx translated">merscliche.medium.com</p></div></div><div class="lk l"><div class="lr l lm ln lo lk lp lq lb"/></div></div></a></div></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="07c6" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated"><strong class="ak"> (1)准备数据</strong></h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="6b0c" class="jg jh hi jc b fi ji jj l jk jl">import torch<br/>from torch.autograd import Variable</span><span id="5b47" class="jg jh hi jc b fi jm jj l jk jl"># set seed<br/>torch.manual_seed(20201217)<br/># create a straight line with a random term<br/>x = Variable(torch.linspace(0,100).type(torch.FloatTensor))<br/>rand = Variable(torch.randn(100)) * 20<br/>y = x + rand</span></pre><p id="9170" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">用随机项生成一条直线。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="b13d" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated">(2) <em class="mj">数据拆分</em></h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="4e68" class="jg jh hi jc b fi ji jj l jk jl">x_train = x[:-10]<br/>x_test = x[-10:]<br/>y_train = y[:-10]<br/>y_test = y[-10:]</span></pre><ul class=""><li id="e73b" class="mk ml hi jq b jr js ju jv jx mm kb mn kf mo kj mp mq mr ms bi translated">总共 100 个数据点。</li><li id="f14e" class="mk ml hi jq b jr mt ju mu jx mv kb mw kf mx kj mp mq mr ms bi translated">90 个训练数据点和 10 个测试数据点。</li></ul></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="3bb0" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated">(3)训练数据散点图</h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="fb8c" class="jg jh hi jc b fi ji jj l jk jl">import matplotlib.pyplot as plt<br/>plt.figure(figsize=(8, 5))<br/>points, *_ = plt.plot(x_train, y_train, 'o') # OR plt.scatter(x_train, y_train)</span><span id="51b8" class="jg jh hi jc b fi jm jj l jk jl">plt.xlabel('x_train', fontsize = 'x-large')<br/>plt.ylabel('y_train', fontsize = 'x-large')<br/>plt.title('Scatterplot of training data', fontname='Comic Sans MS', fontsize = 'xx-large') <br/>plt.legend([points], ['Training data'], fontsize = 'xx-large')<br/>plt.show()</span></pre><figure class="ix iy iz ja fd mz er es paragraph-image"><div class="er es my"><img src="../Images/d500cfc0e58c47411ad966be618ed012.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*kjaUrqeSmjoMCqyJe0_92g.png"/></div><figcaption class="nb nc et er es nd ne bd b be z dx translated">图 1:训练数据的散点图</figcaption></figure></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="3d41" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated"><em class="mj"> (4)用 torch.nn 训练模型—NN</em></h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="ade0" class="jg jh hi jc b fi ji jj l jk jl"># 1. Generate a class by torch.nn.Linear<br/>input_size = 1; output_size = 1</span><span id="6674" class="jg jh hi jc b fi jm jj l jk jl">class LinearRegression(nn.Module):<br/>  def __init__(self, input_size, output_size):<br/>    super(LinearRegression, self).__init__()<br/>    self.linear = nn.Linear(input_size, output_size)<br/>  <br/>  def forward(self,x):<br/>    out = self.linear(x)<br/>    return out</span><span id="0752" class="jg jh hi jc b fi jm jj l jk jl"># 2. Instantiating the class<br/>model = LinearRegression(input_size, output_size)</span><span id="fbe0" class="jg jh hi jc b fi jm jj l jk jl"># 3. Set learning rate, loss function and optimizer<br/>learning_rate = 0.0001 # learning rate<br/>criterion = nn.MSELoss() # MSE <br/>optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # SGD</span><span id="edc8" class="jg jh hi jc b fi jm jj l jk jl"># 3. Train the model<br/>num_epochs = 1000<br/>x_train_reshape = x_train.view(90,1)<br/>y_train_reshape = y_train.view(90,1)</span><span id="116d" class="jg jh hi jc b fi jm jj l jk jl">for epoch in range(num_epochs):<br/>  inputs = Variable(x_train_reshape)<br/>  targets = Variable(y_train_reshape)</span><span id="3c20" class="jg jh hi jc b fi jm jj l jk jl"># BP (backpropagation)<br/>  optimizer.zero_grad()<br/>  outputs = model(inputs)</span><span id="c71e" class="jg jh hi jc b fi jm jj l jk jl"># loss function<br/>  loss = criterion(outputs, targets)<br/>  loss.backward()</span><span id="7f36" class="jg jh hi jc b fi jm jj l jk jl"># update the parameters<br/>  optimizer.step()</span><span id="49e8" class="jg jh hi jc b fi jm jj l jk jl">if (epoch+1) % 250 == 0:<br/>    print('Epoch [%4d/%d], Loss = %.4f' % (epoch+1, num_epochs, loss.data))</span><span id="1431" class="jg jh hi jc b fi jm jj l jk jl">print('\n')</span></pre><figure class="ix iy iz ja fd mz er es paragraph-image"><div class="er es nf"><img src="../Images/20e6ddb8051b1bb15a93a2b80b4c0979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*x3wJ3nHjDi8ltHL-U6oPaw.png"/></div><figcaption class="nb nc et er es nd ne bd b be z dx translated">图 2:损失</figcaption></figure><ul class=""><li id="c724" class="mk ml hi jq b jr js ju jv jx mm kb mn kf mo kj mp mq mr ms bi translated">这里采用<em class="ku"> torch.nn.Linear </em>建立一个线性函数，或者所谓的简单线性回归，即 y = ax + b</li><li id="eac3" class="mk ml hi jq b jr mt ju mu jx mv kb mw kf mx kj mp mq mr ms bi translated">纪元= 1000；批量= 90。</li><li id="cf6f" class="mk ml hi jq b jr mt ju mu jx mv kb mw kf mx kj mp mq mr ms bi translated">学习率= 0.0001</li><li id="c7a2" class="mk ml hi jq b jr mt ju mu jx mv kb mw kf mx kj mp mq mr ms bi translated">损失函数= MSE</li><li id="9957" class="mk ml hi jq b jr mt ju mu jx mv kb mw kf mx kj mp mq mr ms bi translated">优化器= SGD</li><li id="102b" class="mk ml hi jq b jr mt ju mu jx mv kb mw kf mx kj mp mq mr ms bi translated">观察<strong class="jq hj">纪元[1000/1000]，损耗= 384.2534 </strong>(参见“NN 从头开始”部分损耗= 384.7248)</li></ul></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="0de4" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated"><em class="mj"> (5)在训练数据上拟合直线</em></h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="f7f4" class="jg jh hi jc b fi ji jj l jk jl"># test methods: .named_parameters() &amp; .parameters()<br/>print(list(model.named_parameters())); print('-----')<br/>print(list(model.parameters())); print('-----')<br/>print(list(model.parameters())[1]); print('-----')</span><span id="0d5e" class="jg jh hi jc b fi jm jj l jk jl"># predictions of the training data<br/>prediction_train = model(Variable(x_train_reshape)).data</span><span id="8d83" class="jg jh hi jc b fi jm jj l jk jl">plt.figure(figsize = (9, 6))<br/>points, *_ = plt.plot(x_train, y_train, 'o') # points<br/>line, *_ = plt.plot(x_train, prediction_train, linewidth = 3, color = 'darkorange') # line</span><span id="9a63" class="jg jh hi jc b fi jm jj l jk jl">a1 = list(model.parameters())[0].detach()[0][0]<br/>b1 = list(model.parameters())[1].detach()[0]<br/>str1 = '{:.3f} x + ( {:.3f}) '.format(a1, b1)</span><span id="cb01" class="jg jh hi jc b fi jm jj l jk jl">plt.xlabel('x_train', fontsize = 'x-large')<br/>plt.ylabel('y_train', fontsize = 'x-large')<br/>plt.title('A NN Simple Linear Regression Model: NN by torch.nn', fontname='Comic Sans MS', fontsize = 'xx-large')</span><span id="28ca" class="jg jh hi jc b fi jm jj l jk jl">plt.legend([points, line], ['Training data', str1], fontsize = 'xx-large')<br/>plt.show()</span></pre><figure class="ix iy iz ja fd mz er es paragraph-image"><div class="er es ng"><img src="../Images/4871bca6fb0576f30d0f1196b1d03e45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*U9YszEv4Hjt_WuZ6k6c2hg.png"/></div><figcaption class="nb nc et er es nd ne bd b be z dx translated">图 3:拟合训练数据线</figcaption></figure><ul class=""><li id="71fa" class="mk ml hi jq b jr js ju jv jx mm kb mn kf mo kj mp mq mr ms bi translated">注意拟合线是<strong class="jq hj"> 0.984 x + (-0.055) </strong>(比较“NN 从头开始”部分的 0.973 x + ( 0.610)</li></ul></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="fc06" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated"><em class="mj"> (6)测试数据的预测</em></h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="a3e8" class="jg jh hi jc b fi ji jj l jk jl">predictions_test = model(Variable(x_test.view(10,1))).data<br/>print(predictions_test.t())</span></pre><figure class="ix iy iz ja fd mz er es paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="er es nh"><img src="../Images/9f722cf58ac2010b31abf9a254649b65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tnojSk676aDeYDbP6dEF5Q.png"/></div></div><figcaption class="nb nc et er es nd ne bd b be z dx translated">图 4:10 个测试数据点的预测</figcaption></figure></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="57d8" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated"><em class="mj"> (7)在测试数据上拟合直线— 1 </em></h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="22fb" class="jg jh hi jc b fi ji jj l jk jl">import numpy as np</span><span id="c89f" class="jg jh hi jc b fi jm jj l jk jl">plt.figure(figsize = (12, 6))<br/>points_train, *_ = plt.plot(x_train, y_train, 'o') # circle marker<br/>points_test, *_ = plt.plot(x_test, y_test, 's', color = 'red') # square marker</span><span id="d3b3" class="jg jh hi jc b fi jm jj l jk jl">prediction_train = model(Variable(x_train_reshape)).data<br/>prediction_test = model(Variable(x_test.view(10,1))).data</span><span id="6bdf" class="jg jh hi jc b fi jm jj l jk jl"># fitting line of training data<br/>line, *_ = plt.plot(x_train, prediction_train, linewidth = 3, color = 'darkorange')<br/># prediction of the test data by the fitting line<br/>points_test_prediction, *_ = plt.plot(x_test, prediction_test, 'o', color = 'green')</span><span id="c7b6" class="jg jh hi jc b fi jm jj l jk jl">a1 = list(model.parameters())[0].detach().numpy()[0][0]<br/>b1 = list(model.parameters())[1].detach().numpy()[0]<br/>str1 = '{:.3f} x + ( {:.3f}) '.format(a1, b1)</span><span id="4a5a" class="jg jh hi jc b fi jm jj l jk jl">plt.xlabel('x_all', fontsize = 'x-large')<br/>plt.ylabel('y_all', fontsize = 'x-large')<br/>plt.title('A NN Simple Linear Regression Model: NN by torch.nn', fontname='Comic Sans MS', <br/>          fontsize = 'xx-large')</span><span id="6c1d" class="jg jh hi jc b fi jm jj l jk jl">plt.legend([points_train, points_test, points_test_prediction, line], <br/>           ['Training data', 'Test data', 'Predictions', str1], <br/>           fontsize = 'xx-large')<br/>plt.show()</span></pre><figure class="ix iy iz ja fd mz er es paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="er es nm"><img src="../Images/8cbf8d11f7b412c9345278ab3884b508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zj2JDul4cOv8k9TIwukjqw.png"/></div></div><figcaption class="nb nc et er es nd ne bd b be z dx translated">图 5:测试数据的训练数据和预测数据点的拟合线</figcaption></figure></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="fd85" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated"><em class="mj"> (8)在测试数据上拟合直线— 2 </em></h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="ce83" class="jg jh hi jc b fi ji jj l jk jl">import numpy as np</span><span id="da22" class="jg jh hi jc b fi jm jj l jk jl">plt.figure(figsize = (12, 6))<br/>points_train, *_ = plt.plot(x_train, y_train, 'o') # circle marker<br/>points_test, *_ = plt.plot(x_test, y_test, 's', color = 'red') # square marker</span><span id="49be" class="jg jh hi jc b fi jm jj l jk jl">prediction_train = model(Variable(x_train_reshape)).data<br/>prediction_test = model(Variable(x_test.view(10,1))).data</span><span id="f9e2" class="jg jh hi jc b fi jm jj l jk jl">x_data_2 = np.r_[x_train, x_test] # merge<br/>y_data_2 = np.r_[prediction_train, prediction_test]</span><span id="2826" class="jg jh hi jc b fi jm jj l jk jl"># extend the fitting line of training data<br/>line, *_ = plt.plot(x_data_2, y_data_2, linewidth = 3, color = 'darkorange')</span><span id="8bf2" class="jg jh hi jc b fi jm jj l jk jl">a1 = list(model.parameters())[0].detach()[0][0]<br/>b1 = list(model.parameters())[1].detach()[0]<br/>str1 = '{:.3f} x + ( {:.3f}) '.format(a1, b1)</span><span id="1f56" class="jg jh hi jc b fi jm jj l jk jl">plt.xlabel('x_all', fontsize = 'x-large')<br/>plt.ylabel('y_all', fontsize = 'x-large')<br/>plt.title('A NN Simple Linear Regression Model: NN by torch.nn', fontname='Comic Sans MS', <br/>          fontsize = 'xx-large')</span><span id="7dd6" class="jg jh hi jc b fi jm jj l jk jl">plt.legend([points_train, points_test, line], <br/>           ['Training data', 'Test data', str1], <br/>           fontsize = 'xx-large')<br/>plt.show()</span></pre><figure class="ix iy iz ja fd mz er es paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="er es nm"><img src="../Images/ebc6f97c1525b4b1b29489d6fd96b612.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*40eaqnF4dmpIwdZkYkT27g.png"/></div></div><figcaption class="nb nc et er es nd ne bd b be z dx translated">图 6:将拟合线延伸到测试数据区域</figcaption></figure></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="2078" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated"><em class="mj"> (9)总结</em></h1><p id="bf82" class="pw-post-body-paragraph jo jp hi jq b jr nn ij jt ju no im jw jx np jz ka kb nq kd ke kf nr kh ki kj hb bi translated">涵盖了神经网络的基本组成，现在我们认识到如何利用<em class="ku"> torch.nn </em>模块，如何设置学习率、损失函数、优化器，以及如何训练神经网络模型和检查预测结果。</p><p id="af22" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">下面的附录显示了如何创建我们自己的损失函数、优化器和训练 NN 模型，而不是导入<em class="ku"> torch.nn </em>模块。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="9b40" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated"><em class="mj"> (10)附录:</em>从零开始训练模型— NN</h1><p id="157b" class="pw-post-body-paragraph jo jp hi jq b jr nn ij jt ju no im jw jx np jz ka kb nq kd ke kf nr kh ki kj hb bi translated">与“由 torch.nn 创建神经网络”不同，我们在“从零开始创建神经网络”部分自行构建神经网络中的元素，如反向传播、损失函数和优化器。主要差异如下所示:</p><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="6b2c" class="jg jh hi jc b fi ji jj l jk jl">from torch.autograd import Variable</span><span id="f554" class="jg jh hi jc b fi jm jj l jk jl"># 1. Set autograds<br/>a = Variable(torch.rand(1), requires_grad= True)<br/>b = Variable(torch.rand(1), requires_grad= True)</span><span id="df8a" class="jg jh hi jc b fi jm jj l jk jl"># 2. Set learning rate<br/>learning_rate = 0.0001</span><span id="1fb8" class="jg jh hi jc b fi jm jj l jk jl"># 3. Training the model<br/>num_epochs = 1000</span><span id="223a" class="jg jh hi jc b fi jm jj l jk jl">for epoch in range(num_epochs):</span><span id="e17a" class="jg jh hi jc b fi jm jj l jk jl"># predictions of the training data<br/>  predictions = a.expand_as(x_train) * x_train + b.expand_as(x_train)</span><span id="fb10" class="jg jh hi jc b fi jm jj l jk jl"># loss function: MSE<br/>  loss = torch.mean((predictions - y_train) ** 2)</span><span id="9091" class="jg jh hi jc b fi jm jj l jk jl"># BP (backpropagation)<br/>  loss.backward()</span><span id="d888" class="jg jh hi jc b fi jm jj l jk jl"># update the parameters (optimizer = SGD)<br/>  a.data.add_( - learning_rate * a.grad.data)<br/>  b.data.add_( - learning_rate * b.grad.data)</span><span id="fca6" class="jg jh hi jc b fi jm jj l jk jl"># clear the gradients<br/>  a.grad.data.zero_()<br/>  b.grad.data.zero_()</span><span id="6d44" class="jg jh hi jc b fi jm jj l jk jl">if (epoch+1) % 250 == 0:<br/>    print('Epoch [%4d/%d], Loss = %.4f' % (epoch+1, num_epochs, loss.data))</span></pre><p id="f829" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">同样，本文中我们只展示了完整的“NN by torch.nn”代码。点击这里查看“NN 从头开始”的完整代码:<br/><a class="ae jn" href="https://bit.ly/2WjFuOs" rel="noopener ugc nofollow" target="_blank">https://bit.ly/2WjFuOs</a></p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="408e" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated">(11)总结</h1><p id="7c63" class="pw-post-body-paragraph jo jp hi jq b jr nn ij jt ju no im jw jx np jz ka kb nq kd ke kf nr kh ki kj hb bi translated">到目前为止，我们从:NN/DL 理论(<a class="ae jn" href="https://becominghuman.ai/ml04-ce0b172deb2b" rel="noopener ugc nofollow" target="_blank"> ML04 </a> ) = &gt;一个仅仅由 NumPy ( <a class="ae jn" href="https://becominghuman.ai/ml05-8771620a2023" rel="noopener ugc nofollow" target="_blank"> ML05 </a> ) = &gt;一个详细的 PyTorch 教程(<a class="ae jn" href="https://merscliche.medium.com/ml12-59d2a56737ac" rel="noopener"> ML12 </a> ) = &gt; NN 简单的线性回归使用 PyTorch (ML13。这一个。).接下来，我们将使用 ML14 中的 PyTorch 继续前往 MNIST 的 FNN<em class="ku">。</em></p><div class="ky kz ez fb la lb"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/ml14-f03f75254934"><div class="lc ab dw"><div class="ld ab le cl cj lf"><h2 class="bd hj fi z dy lg ea eb lh ed ef hh bi translated">ML14:py torch——MNIST 的 MLP</h2><div class="li l"><h3 class="bd b fi z dy lg ea eb lh ed ef dx translated">图像分类的第一步(98.13%的准确率)</h3></div><div class="lj l"><p class="bd b fp z dy lg ea eb lh ed ef dx translated">medium.com</p></div></div><div class="lk l"><div class="ns l lm ln lo lk lp lq lb"/></div></div></a></div></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="b1e8" class="ls jh hi bd lt lu lv lw lx ly lz ma mb io mc ip md ir me is mf iu mg iv mh mi bi translated">(12)参考文献</h1><h2 id="09a2" class="jg jh hi bd lt nt nu nv lx nw nx ny mb jx nz oa md kb ob oc mf kf od oe mh of bi translated">(中文)</h2><p id="04ac" class="pw-post-body-paragraph jo jp hi jq b jr nn ij jt ju no im jw jx np jz ka kb nq kd ke kf nr kh ki kj hb bi">[1] 張校捷 (2020)。深入淺出 PyTorch：從模型到源碼。北京，中國：電子工業。</p><p id="03fe" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi">[2] 集智俱樂部 (2019)。深度學習原理與 PyTorch 實戰。北京，中國：人民郵電。</p><p id="4ede" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi">[3] 邢夢來等人 (2018)。深度学习框架 PyTorch 快速开发与实战。北京，中國：電子工業。</p></div></div>    
</body>
</html>