<html>
<head>
<title>Monte Carlo Methods in Reinforcement Learning — Part 2 off-policy Methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习中的蒙特卡罗方法——第二部分非策略方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/monte-carlo-methods-in-reinforcement-learning-part-2-off-policy-methods-b9766d3e60d7?source=collection_archive---------6-----------------------#2020-04-29">https://medium.com/analytics-vidhya/monte-carlo-methods-in-reinforcement-learning-part-2-off-policy-methods-b9766d3e60d7?source=collection_archive---------6-----------------------#2020-04-29</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><figure class="ev ex im in io ip er es paragraph-image"><div class="er es il"><img src="../Images/96e80e95a98d1300b37ddc0a95f4e9ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*mr-mIMgLYHLeEFpMBGsvZA.jpeg"/></div></figure><p id="b1f1" class="pw-post-body-paragraph is it ho iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hh bi translated">这篇文章是上一篇<a class="ae jq" rel="noopener" href="/@sebastian.dittert3692/monte-carlo-methods-in-reinforcement-learning-part-1-on-policy-methods-1f004d59686a"> <strong class="iu hp">文章</strong> </a>的延续，也就是保单蒙特卡罗方法。在这篇文章中，非政策蒙特卡罗方法将提出。</p><p id="2776" class="pw-post-body-paragraph is it ho iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hh bi translated">本文涵盖了以下主题:</p><ul class=""><li id="ddce" class="jr js ho iu b iv iw iz ja jd jt jh ju jl jv jp jw jx jy jz bi translated"><strong class="iu hp">偏离政策的蒙特卡罗预测</strong></li><li id="7e23" class="jr js ho iu b iv ka iz kb jd kc jh kd jl ke jp jw jx jy jz bi translated"><strong class="iu hp">非策略蒙特卡罗控制</strong></li></ul></div></div>    
</body>
</html>