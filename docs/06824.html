<html>
<head>
<title>How to pre-process large datasets for machine learning using Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Spark为机器学习预处理大数据集</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-pre-process-large-datasets-for-machine-learning-using-spark-19500155b521?source=collection_archive---------18-----------------------#2020-06-03">https://medium.com/analytics-vidhya/how-to-pre-process-large-datasets-for-machine-learning-using-spark-19500155b521?source=collection_archive---------18-----------------------#2020-06-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/87c6f5585e48961e8d5a38cec3905f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dSTTYRDbaLqRHvFMPbVPxg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片鸣谢:<a class="ae iu" href="https://unsplash.com/@sortino" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@sortino</a></figcaption></figure><h2 id="c7b8" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">介绍</h2><p id="1a0b" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">在本文中，我将展示如何克服纯python解决方案的一个限制，对大型数据集进行预处理，以训练机器学习模型</p><h2 id="68d3" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">动机</h2><p id="042e" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">我正在处理一个棋盘游戏评论数据集，我必须建立一个模型来预测关于游戏的给定评论的评分。当我使用<em class="ko"> scikit-learn </em>来训练模型并预测给定评论的评分时，我注意到我机器上的所有资源并没有被利用。</p><h2 id="1101" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">资料组</h2><p id="bcf4" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated"><a class="ae iu" href="https://www.kaggle.com/jvanelteren/boardgamegeek-reviews" rel="noopener ugc nofollow" target="_blank">数据集</a>是2019年5月2日使用<a class="ae iu" href="https://boardgamegeek.com/wiki/page/BGG_XML_API2" rel="noopener ugc nofollow" target="_blank"> BGG XML API2 </a>查询的棋盘游戏评论和评级的集合。该数据集的总容量约为1GB，包含约1300万条记录，其中约260万条记录有注释。</p><h2 id="0cd3" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">问题是</h2><p id="3d60" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">我的目的是评估一些线性模型，如Linear、Lasso、Ridge Regression和一些分类模型，如Naive Bayes和Logistic Regression，以了解什么模型最适合这些数据。</p><p id="01a4" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">因为我在这里处理的是文本特征，所以需要将它转换成数字向量来训练上面提到的一些模型。最流行的技术之一是<a class="ae iu" href="https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/" rel="noopener ugc nofollow" target="_blank"> TF-IDF矢量化</a></p><p id="4d30" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">无论采用何种技术，净化数据都很重要，这样我们可以消除任何无用的信息，减少训练时间，并最终提高训练模型的质量。</p><p id="5350" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">根据数据集的复杂程度，需要执行几个操作来清理数据。对于此数据集，以下是步骤</p><ol class=""><li id="78af" class="ku kv hi jv b jw kp ka kq jg kw jk kx jo ky kn kz la lb lc bi translated">转换为小写</li><li id="eb94" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">删除HTML标签、标点符号、链接、带数字的单词、特殊字符</li><li id="c49e" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">排除长度小于3的单词</li><li id="aa6d" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">删除停用词(这些是经常出现的词，不会提供有用的信息，如a、an、the等)</li></ol><p id="b249" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">所有上述操作都是非常基本的，它们的实现在python中非常简单</p><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="1fbe" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">整体剧本用了<strong class="jv hj"> <em class="ko"> ~3m22s </em> </strong>完成。那么问题出在哪里？性能瓶颈在哪里？到底有没有？</p><p id="74c7" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">下面是我对数据集运行cleanup方法时发生的情况。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/764ecbf6c880917182b5218ab9093401.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DAfGWs0TIILEKDonYiG6jA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">资源利用:Python实现</figcaption></figure><p id="42d3" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">它只使用了我笔记本电脑上12个可用内核中的一个(6个物理内核+ 6个虚拟内核)。这促使我思考是否可以利用机器上的其他内核？我可以并行化部分逻辑吗？我的解决方案是否能像我的数据一样扩展？</p><p id="2f66" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">最后，为什么这些问题听起来很熟悉？这就是Spark等大数据工具的用途——大容量数据的分布式处理。</p><h2 id="4df4" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">火花溶液</h2><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/c89aca5b1c8500f1b293815b915eca9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*3QcLH5NDCbeVMVpk1NVdig.jpeg"/></div></figure><p id="5875" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">Apache spark可能是最流行的大数据处理工具，它允许您表达处理逻辑，而不必担心并行化。并行化在其编程模型中进行了优雅的抽象，使用它构建的解决方案可以在各种环境中工作，包括但不限于本地、独立集群、YARN和Mesos</p><p id="b980" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">总之，如果您必须在并行的大规模数据集上执行操作，spark允许您构建一个不仅是分布式的，而且是可横向扩展并在各种部署环境中工作的解决方案。</p><p id="b447" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">那么spark是如何帮助我优化解决方案的呢？</p><p id="8934" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">还记得python的实现只利用了一个内核吗？有了spark，我能够实现并行化，而无需实现并行化逻辑。</p><p id="6f07" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">以下是步骤，</p><ol class=""><li id="f47c" class="ku kv hi jv b jw kp ka kq jg kw jk kx jo ky kn kz la lb lc bi translated">初始化spark会话并指定并行度</li></ol><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="fa8d" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">即使用多少个内核。我选择使用8核。</p><p id="4a89" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">2.从文件加载数据并执行清理</p><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="lm ln l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">Spark代码片段加载csv文件到RDD和清理</figcaption></figure><p id="e346" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">可以注意到，清理逻辑和python中的一样简单。</p><p id="9724" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">只是这一次，文件中的数据被读取为8个块(下面是可用的屏幕截图)，清理操作是在我的笔记本电脑上使用8个内核并行执行的。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/e9b985bfd181af25b26234d979d50dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NzOaIJ-oTu55m4HTjClUwg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Spark作业日志</figcaption></figure><p id="8a9a" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">总而言之，这个火花工作用了<strong class="jv hj"> <em class="ko"> ~2m8s </em> </strong>完成。</p><p id="1d6f" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">但是等等！！这并不是很大的性能提升。快不了一分钟。spark真的值得这么麻烦吗？这篇文章到底有什么意义？</p><p id="3098" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">让我后退一步，像这样修改spark实现的一行代码</p><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="lm ln l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">我删除了最后一行的合并(1)</figcaption></figure><p id="707c" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">这次有什么改进？这个作业的实现用了<strong class="jv hj"> <em class="ko"> ~50.6秒</em> </strong> <em class="ko"> </em>才完成。哇哦。！这几乎是python实现时间的三分之一。</p><p id="2292" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">这到底是怎么回事？</p><p id="239d" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">如果到目前为止您已经仔细阅读了本文，那么您可能已经明白了<code class="du lr ls lt lu b">coalesce(1)</code>是用来通过混洗将数据合并到一个分区中的。本质上，这意味着如果没有<code class="du lr ls lt lu b">coalesce(1)</code>，作业的结果将被保存到8个不同的文件中。这是spark的一个默认行为，我不会在这篇文章中解释原因，因为这已经超出了范围。</p><p id="e58f" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">虽然这项工作的结果不能被像<code class="du lr ls lt lu b">scikit-learn</code>这样的库直接使用，但很明显，预处理可以得到优化，基于spark的架构可以更好地利用硬件/环境。</p><h2 id="42e5" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">结论</h2><p id="a056" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">这绝不是一个完美的解决方案。相反，这是一个更好地利用数据工程环境并促进高效下游消费(如训练机器学习模型)的工作流。</p><p id="d260" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">这种解决方案对于概念验证可能没有意义。但是，如果您正在构建一个最终必须扩展的企业项目，那么明智的做法是构建一个数据管道，它可以在对源代码进行最小更改的情况下进行水平扩展。Spark也是为了同样的用途而构建的。</p><p id="0c15" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">那么，仅仅为了准备数据而学习另一种语言和一套工具值得吗？可能是。可能不是。要看项目整体。</p><h2 id="10aa" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">参考/链接</h2><p id="331c" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">我用这种数据工程的方法构建了一个评估预测应用程序。我最终继续使用这个spark作业，通过TF-IDF矢量化来矢量化注释字段。该应用程序现已上线，应可通过此<a class="ae iu" href="https://bgreview.netlify.app/" rel="noopener ugc nofollow" target="_blank">链接</a>访问</p><p id="1310" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">这个app的演示:【https://www.youtube.com/watch?v=L5gGwx_F_H4】T2&amp;feature = youtu . be</p><p id="1e03" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">星火工作—【https://github.com/harsha993/bgreview-etl T4】</p><p id="46f1" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">车型评测笔记本:<a class="ae iu" href="https://github.com/harsha993/bgreview-notebook" rel="noopener ugc nofollow" target="_blank">https://github.com/harsha993/bgreview-notebook</a></p><p id="bbc9" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">整个项目的博文—<a class="ae iu" href="https://harshavardhan.netlify.app/blog/2020-05-11-bggratings" rel="noopener ugc nofollow" target="_blank">https://harshavardhan . netlify . app/blog/2020-05-11-bggratings</a></p><p id="356d" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">如果这篇文章对你有帮助，请不要犹豫，分享它。最后，这是我的第一篇媒体文章。所以如果有什么建议，欢迎评论。</p></div></div>    
</body>
</html>