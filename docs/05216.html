<html>
<head>
<title>Improve Spark Write Performance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提高火花写入性能</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/improve-spark-write-performance-d187efb8c8bf?source=collection_archive---------9-----------------------#2020-04-14">https://medium.com/analytics-vidhya/improve-spark-write-performance-d187efb8c8bf?source=collection_archive---------9-----------------------#2020-04-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/fbd7c335cb4a333d0e9d295436341ce6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*auKfT2hVGHZRIWF9.jpg"/></div></div></figure><p id="d4d4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">EMRFS S3优化提交器是一个新的输出提交器，从Amazon EMR 5.19.0开始，可以与Apache Spark作业一起使用。当使用<a class="ae jo" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-fs.html" rel="noopener ugc nofollow" target="_blank"> E </a> MR文件系统(EMRFS)将Apache Parquet文件写到<a class="ae jo" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank"> S </a> 3时，这个提交器提高了性能。在本文中，我们运行了一个性能基准来比较这个新的优化提交器和现有的提交器算法，即FileOutputCommitter算法版本1和2。最后，我们讨论了新提交者的当前限制，并在可能的情况下提供了解决方法。</p><h2 id="b5f7" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">与FileOutputCommitter的比较</h2><p id="77ef" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">在亚马逊EMR版本5.19.0和更早版本中，将拼花写入亚马逊S3的Spark作业默认使用名为FileOutputCommitter的Hadoop提交算法。这个算法有两个版本，版本1和版本2。两个版本都依赖于将中间任务输出写入临时位置。它们随后执行重命名操作，使数据在任务或作业完成时可见。</p><p id="1a6b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">算法版本1有两个重命名阶段:一个阶段提交单个任务输出，另一个阶段提交已完成/成功任务的整体作业输出。算法版本2更有效，因为任务将重命名文件直接提交到最终输出位置。这消除了第二个重命名阶段，但它使部分数据在作业完成前可见，这不是所有工作负载都能容忍的。</p><p id="2512" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在Hadoop分布式文件系统(HDFS)上执行的重命名是快速的纯元数据操作。然而，当输出被写入对象存储(如Amazon S3)时，重命名是通过将数据复制到目标然后删除源来实现的。这种重命名“损失”随着目录重命名而加剧，这可能发生在FileOutputCommitter v1的两个阶段。尽管在HDFS上只有单个元数据操作，但提交者必须在S3上执行N次复制和删除操作。</p><p id="28af" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了部分缓解这种情况，在Spark中使用emrf将拼花数据写入S3时，Amazon EMR 5.14.0+默认使用FileOutputCommitter v2。新的EMRFS S3优化提交器改进了这项工作，通过使用Amazon S3多部分上传的事务属性来完全避免重命名操作。然后，任务可以将其数据直接写入最终输出位置，但是将每个输出文件的完成推迟到任务提交时间。</p><h2 id="ab68" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">特性试验</h2><p id="e011" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">当通过执行下面的<code class="du kp kq kr ks b">INSERT OVERWRITE</code> Spark SQL查询来评估不同提交者的写性能时。<code class="du kp kq kr ks b">SELECT * FROM range(…)</code>子句在执行时生成数据。这在亚马逊S3的100个拼花文件中产生了大约15 GB的数据。</p><pre class="kt ku kv kw fd kx ks ky kz aw la bi"><span id="8480" class="jp jq hi ks b fi lb lc l ld le">SET rows=4e9; -- 4 Billion <br/>SET partitions=100;  <br/>INSERT OVERWRITE DIRECTORY ‘s3://${bucket}/perf-test/${trial_id}’ USING PARQUET SELECT * FROM range(0, ${rows}, 1, ${partitions});</span></pre><p id="a507" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注意</strong>:EMR集群和S3 <code class="du kp kq kr ks b">bucket</code>运行在同一个AWS区域。属性使用了一个UUID生成器来确保测试运行之间没有冲突。</p><p id="de55" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们在使用emr-5.19.0版本标签创建的EMR集群上执行了测试，主组中有一个m5d.2xlarge实例，核心组中有八个m5d.2xlarge实例。我们使用Amazon EMR为这个集群配置设置的默认Spark配置属性，包括以下内容:</p><pre class="kt ku kv kw fd kx ks ky kz aw la bi"><span id="c779" class="jp jq hi ks b fi lb lc l ld le">spark.dynamicAllocation.enabled true <br/>spark.executor.memory 11168M <br/>spark.executor.cores 4</span></pre><p id="672d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在为每个提交者运行10次试验之后，我们在下面的图表中捕获并总结了查询执行时间。FileOutputCommitter v2平均耗时49秒，而EMRFS S3优化提交器平均耗时仅为31秒，速度提高了1.6倍。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/490f6b15281270fc6313fd647ad83e0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hBSyjVKj61kkxCWK.png"/></div></div></figure><p id="301c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如前所述，FileOutputCommitter v2消除了FileOutputCommitter v1使用的一些(但不是全部)重命名操作。为了说明重命名对S3的全部性能影响，我们使用FileOutputCommitter v1重新运行测试。在这个场景中，我们观察到平均运行时间为450秒，比EMRFS S3优化提交器慢14.5倍。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/7f69a81c6fae30bba9f362692f887a41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hQglTDFpktvSmJF_.png"/></div></div></figure><p id="cb88" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们评估的最后一个场景是启用<a class="ae jo" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-consistent-view.html" rel="noopener ugc nofollow" target="_blank"> EMRFS一致视图</a>的情况，这解决了亚马逊S3数据一致性模型可能引起的问题。在这种模式下，EMRFS S3优化的提交器时间不受此更改的影响，仍然平均为30秒。另一方面，FileOutputCommitter v2的平均时间为53秒，比关闭一致视图功能时要慢，从而将整体性能差异扩大到1.8倍。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/6dcaa148e2b09aaee42a8ae6e1d77b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wckd2aghM-htih7g.png"/></div></div></figure><h1 id="14fb" class="lg jq hi bd jr lh li lj jv lk ll lm jz ln lo lp kc lq lr ls kf lt lu lv ki lw bi translated">启用EMRFS S3优化提交器</h1><p id="df3d" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">从Amazon EMR版本5.20.0开始，默认情况下启用EMRFS S3优化提交器。在Amazon EMR版本5.19.0中，您可以通过在Spark中或者在创建集群时将<code class="du kp kq kr ks b">spark.sql.parquet.fs.optimized.committer.optimization-enabled</code>属性设置为<code class="du kp kq kr ks b">true</code>来启用提交器。当您使用Spark的内置拼花支持通过EMRFS将拼花文件写入亚马逊S3时，提交器生效。这包括将Parquet数据源与Spark SQL、DataFrames或Datasets一起使用。然而，在一些用例中，EMRFS S3优化提交器不起作用，在一些用例中，Spark完全在提交器之外执行自己的重命名。有关提交器和这些特殊情况的更多信息，请参见<em class="lx">亚马逊EMR发布指南</em>中的<a class="ae jo" href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-s3-optimized-committer.html" rel="noopener ugc nofollow" target="_blank">使用EMRFS S3优化提交器</a>。</p><h1 id="6336" class="lg jq hi bd jr lh li lj jv lk ll lm jz ln lo lp kc lq lr ls kf lt lu lv ki lw bi translated">摘要</h1><p id="d922" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">与FileOutputCommitter相比，EMRFS S3优化提交器提高了写入性能。从亚马逊EMR版本5.19.0开始，可以通过Spark内置的拼花支持来使用它。</p><p id="ae8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这篇文章摘自亚马逊网络服务博客。</p><p id="7e6d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你喜欢这篇文章，请点击👏所以其他人会在媒体上看到它。</p></div></div>    
</body>
</html>