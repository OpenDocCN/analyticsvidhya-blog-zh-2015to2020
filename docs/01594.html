<html>
<head>
<title>Disclose the Secret of Randomness in Random Forests</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭示随机森林中随机性的秘密</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/disclose-the-secret-of-randomness-in-random-forests-705eb751d4d7?source=collection_archive---------8-----------------------#2019-11-02">https://medium.com/analytics-vidhya/disclose-the-secret-of-randomness-in-random-forests-705eb751d4d7?source=collection_archive---------8-----------------------#2019-11-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c42a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">随机</strong> <strong class="ih hj">森林</strong>是一种机器学习算法的技术，通过在训练过程中构建多个<strong class="ih hj">决策</strong> <strong class="ih hj">树</strong>来运行。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/721c877453c8d48fb109dd474f267640.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*RDKFKmeRlFoLd-OzPh9Baw.jpeg"/></div></figure><h2 id="8f17" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">随机森林的用例:-</h2><ol class=""><li id="0096" class="kg kh hi ih b ii ki im kj iq kk iu kl iy km jc kn ko kp kq bi translated">银行欺诈和忠诚客户的检测。</li><li id="b6f4" class="kg kh hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">通过分析患者的医疗报告帮助预测疾病。</li><li id="aaf8" class="kg kh hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">股价预测。</li></ol><h2 id="aebb" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">随机森林算法是如何工作的？→</h2><p id="d63a" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">如前所述<strong class="ih hj"> <em class="kz">随机森林是一个决策树</em> </strong>的集合，最初当我们得到数据集时我们会<strong class="ih hj"> <em class="kz">将数据集分成n等份</em> </strong>。这些<strong class="ih hj"> <em class="kz"> n个相等的部分被称为随机森林算法的n-估计器</em> </strong>。</p><p id="07bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将开始为主数据集的每个子数据集构建决策树。因此，在构建决策树时，我们必须知道在第一个标签处，数据集的所有属性或特征将在根标签处。因此，我们可以从数据集的所有属性中选择最佳属性。对于这个，我们有两个具体的算法→一个是信息增益，一个是基尼指数。这里我们将使用<strong class="ih hj"> <em class="kz">基尼指数法</em> </strong>从决策树的所有属性中选择最佳属性进行决策。</p><p id="3b3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，让我们用这个数据集来理解随机森林。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es la"><img src="../Images/c28e2a358567717e6b65af06fb5deffb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*oTeRXZEnMz3GLaoa5PJ3CQ.png"/></div></figure><p id="87f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，计算基尼指数的<strong class="ih hj"> <em class="kz">公式为:→ </em> </strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lb"><img src="../Images/3219ba1bed1d8b4c0ae988bb97479eb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*ACG1xQzOxQUIvvt-xXloQA.png"/></div></figure><p id="b215" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里，</p><ul class=""><li id="6093" class="kg kh hi ih b ii ij im in iq lc iu ld iy le jc lf ko kp kq bi translated"><strong class="ih hj"> <em class="kz"> p() </em> </strong>指的是概率，</li><li id="f7c2" class="kg kh hi ih b ii kr im ks iq kt iu ku iy kv jc lf ko kp kq bi translated"><strong class="ih hj"> <em class="kz"> i </em> </strong>表示特征栏中出现的不同组</li><li id="4f57" class="kg kh hi ih b ii kr im ks iq kt iu ku iy kv jc lf ko kp kq bi translated"><strong class="ih hj"> <em class="kz"> t </em> </strong>表示特征栏中出现的元素总数</li></ul><p id="258c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kz">基尼指数→ </em> </strong>基尼指数是从数据集中出现的其他属性中选择最佳属性的过程，借助于它我们可以生成进一步的子树。它测量整个数据集的列属性的不纯度或不相等性。将选择具有最低杂质的特定组来表示该特征列的基尼指数值。基尼系数为0是最坏的情况，理想情况下，我们希望该系数为1。因此，我们将在用于生成子树的属性中挑选最高的基尼值。</p><p id="672f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，在获得数据集<strong class="ih hj">后，我们应该将数据集分成n等份</strong>。对于每个部分，我们将构建一个决策树。由于我们在这里取了一个小数据集，<strong class="ih hj">我们将为数据集</strong>构建3种不同类型的决策树。</p><p id="039e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，为了构建我们的第一个决策树，我们将<strong class="ih hj">从计算数据集</strong>中因变量(即“标签”)的基尼指数开始。因此，列标签的基尼指数是1-(2/6) -(2/6) -(2/6) = 0.66，因为在我们的数据集中，6个标签中有2个柠檬、2个苹果和2个葡萄。现在我们将开始计算每一列的最佳基尼系数。为此，我们必须将每列的元素分成两个一组。因此，对于“颜色”列，可能的子集可以是2 = 8。因为基尼指数对每个属性和3使用二进制分割计算，因为颜色列只有3个不同的属性，即红色、紫色、黄色。因此，在所有8个可能的子分裂中，可能的<strong class="ih hj">二进制子分裂</strong>是→ {(红色，紫色)，黄色}，{(紫色，黄色)，红色}，{(红色，黄色)，紫色}。现在，我们必须通过公式计算每个二元细分的基尼指数:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lg"><img src="../Images/45a97d7f973f8c75d540350bafb4fbfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*yQFDg2UV4ZJGzBp7iIQhFA.png"/></div></figure><p id="b5e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中，如果我们先取split {(红，紫)，黄}</p><p id="26cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后D1表示(红色、紫色)，D2表示黄色，D表示训练样本的数量</p><p id="2e56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，{(红色、紫色)、黄色}的基尼指数为(4/6)*(1-(2/4)-(2/4))+(2/6)*(1-(2/2))= 1/3，计算请查看此视频:<a class="ae lh" href="https://www.youtube.com/watch?v=6614umIqeOc" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> <em class="kz">基尼指数详细计算</em> </strong> </a></p><p id="ff7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算三个等级的基尼指数后({(红、紫)、黄}、{(紫、黄)、红}、{(红、黄)、紫})，取三个等级中基尼指数值最低的等级。同样，通过使用二元分割计算数据集其他要素的最低基尼系数。最后，在特征中，具有最高基尼指数值的特征将被选择作为用于分类目的的根节点。</p><p id="b9d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同时，在接下来的步骤中，我们将继续重复相同的步骤，为下一个最佳特征计算基尼指数以进行分类，并构建决策树的下一个节点，留下先前使用的特征用于分类。</p><p id="6e01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们将得到第一个决策树:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es li"><img src="../Images/42738009d5035645bda6292bbc9698a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*vl7fHwgZhBmcWL8FI2O3Yw.png"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">第一决策树</figcaption></figure><p id="d871" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们重复相同的步骤时，将从数据集的子部分形成的决策树的另外两个部分/类型是:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/5b588e3df93833e256be4427d4e70179.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*jOwE6eb6QINYmXjBSxPKdw.png"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">第二决策树</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/ad52fae00c125e765af1b959be74622a.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*-zG2jF0P2HPh6ee3vAZ3yw.png"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">第三决策树</figcaption></figure><p id="5ca9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，如果我们想要将一个新的水果分类为苹果、柠檬或葡萄<strong class="ih hj">T11(注意:-图片中柠檬用橙色表示，葡萄用樱桃表示) </strong>类，那么我们将遍历3棵不同的树的规格以获得我们的答案，获得<strong class="ih hj">最大</strong> <strong class="ih hj">权重的类</strong>将是新测试对象的答案。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lp"><img src="../Images/01b761c14f698d51f0bdfcb3687210a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*US1AI8_kfAJ4rxbn2eTCkQ.png"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">新测试对象</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es lq"><img src="../Images/bce9a50e6a7a2a98cb46e48c914a671a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jy2pR6OEbGBkG0J6ZNvakg.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">行动中的随机森林算法</figcaption></figure><p id="d863" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为Orange从决策树的预测答案中获得了最多票数。所以，对测试对象的正确预测是柠檬或橙。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/591a3e4de462479edb9a0988949b4ff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:276/format:webp/1*27RdYh5ccKi2BfrE7-EJfA.png"/></div></figure><p id="ed63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是随机森林算法处理一堆决策树的方式。我希望你喜欢阅读这篇博客。如果您有任何意见、疑问或问题，请在评论区告诉我。在那之前享受学习。</p></div></div>    
</body>
</html>