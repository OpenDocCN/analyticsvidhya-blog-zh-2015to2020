<html>
<head>
<title>Understanding Spark RDDs — Part 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解Spark RDDs第3部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-spark-rdds-part-3-3b1b9331652a?source=collection_archive---------8-----------------------#2020-07-10">https://medium.com/analytics-vidhya/understanding-spark-rdds-part-3-3b1b9331652a?source=collection_archive---------8-----------------------#2020-07-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/a3fbe96a7c03b0465c8dd66b06051531.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/0*RHAxHRD8HJOFAuwO.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来源:Java开发者专区</figcaption></figure><p id="e171" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">欢迎光临！前一篇博客简要介绍了Spark中的rdd。在本文中，我们将讨论Spark RDDs上的两个重要操作——<strong class="is hj">转换和动作</strong>以及示例。在本博客结束时，您将对rdd以及如何使用rdd编写PySpark程序有一个清晰的概念。</p><h2 id="0fab" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">在PySpark中创建rdd</h2><p id="b7c4" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">在我们研究可以在rdd上执行的操作之前，让我们学习如何在PySpark中创建rdd。我希望你已经在电脑上安装并配置了PySpark。如果没有，参考<a class="ae jo" rel="noopener" href="/@anveshrithaas/introduction-to-pyspark-part-2-6d6113e31592">之前的博客</a>获取快速安装指南。</p><p id="6331" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建rdd的方法不止一种。一种简单的方法是通过将驱动程序中的现有集合传递给SparkContext的<em class="kp">parallelise()</em>方法来并行化它。在这里，集合的元素被复制到一个RDD中，并且可以被并行处理。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="9841" class="jp jq hi kv b fi kz la l lb lc">data= [“Scala”, “Python”, “Java”, “R”]</span><span id="b5e4" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span></pre><p id="7951" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kp">注意:</em> </strong> <em class="kp">不要忘记创建SparkContext sc(除非您使用的是PySpark shell，它会自动创建sc)。这是编写任何Spark程序时应该做的第一件事。</em></p><p id="fbd6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，并行化集合中的数据被分割成多个分区，一个任务将在集群的每个分区上执行。默认情况下，Spark根据集群设置分区数量。也可以通过将分区数量作为第二个参数传递给<em class="kp"> parallelize() </em>方法来手动设置。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="fab9" class="jp jq hi kv b fi kz la l lb lc">data= [“Scala”, “Python”, “Java”, “R”]</span><span id="788e" class="jp jq hi kv b fi ld la l lb lc">#data split into two partitions<br/>myRDD= sc.parallelize(data,2) </span></pre><p id="4e0b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建Spark RDD的另一种方式是从其他数据源，如本地文件系统、Cassandra、HDFS等。这里，数据是从外部数据集加载的。为此，我们使用SparkContext的<em class="kp"> textFile </em>方法，该方法将文件的URL作为其参数。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="9074" class="jp jq hi kv b fi kz la l lb lc">#text file to RDD<br/>myRDD= sc.textFile(“/path_to_file/textdata.txt”)</span><span id="c372" class="jp jq hi kv b fi ld la l lb lc"># CSV file to RDD<br/>myRDD=sc.textFile(“/path_to_file/csvdata.csv”)</span></pre><p id="f0e7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kp">注意:</em> </strong> <em class="kp">确保如果您正在使用本地文件系统中的文件，那么该文件也可以在worker节点上的相同路径中访问。</em></p><p id="6f0e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark的rdd支持两种类型的操作，即转换和操作。一旦创建了rdd，我们就可以对它们执行转换和操作。</p><h1 id="cb44" class="le jq hi bd jr lf lg lh jv li lj lk jz ll lm ln kc lo lp lq kf lr ls lt ki lu bi translated">转换</h1><p id="7fd1" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">转换是对RDD的操作，它通过对原始RDD进行更改来创建新的RDD。简而言之，它们是将现有的RDD作为输入，将新的RDD作为输出的函数，而不需要对原始的RDD进行修改(注意，rdd是不可变的！)将RDD变换为新的过程是通过诸如filter、map、reduceByKey、sortBy等操作来完成的。正如在前面的博客中看到的，rdd遵循懒惰评估。也就是说，rdd上的转换将不会被执行，直到它在需要时被触发。因此，只要在数据上调用一个动作，就可以在任何时候执行这些操作。RDD的转变可以分为两类:狭义的和广义的。</p><ul class=""><li id="53f3" class="lv lw hi is b it iu ix iy jb lx jf ly jj lz jn ma mb mc md bi translated">在<strong class="is hj">窄转换</strong>中，转换的结果是，在输出RDD中，每个分区都有来自父RDD中相同分区的记录。像Map、FlatMap、Filter、Sample这样的操作属于狭义转换。</li><li id="8782" class="lv lw hi is b it me ix mf jb mg jf mh jj mi jn ma mb mc md bi translated">而在<strong class="is hj">宽转换</strong>中，结果RDD的每个分区中的数据来自父RDD中的多个不同分区。像groupByKey()、reduceByKey()这样的转换函数属于广泛转换的范畴。</li></ul><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mj"><img src="../Images/0d1f69e71569d1dd193ac5ba2a7dbdba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6dYzs4GK3Q9nSPkMp-3w2w.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">来源:Pinterest</figcaption></figure><p id="0c4e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们来看看RDD的一些变化。</p><h2 id="5315" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">地图()</h2><p id="ead6" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> map() </em>通过对原始RDD中的每个元素应用一个函数来返回一个新的RDD。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="c472" class="jp jq hi kv b fi kz la l lb lc">data= [1, 2, 3, 4, 5]</span><span id="4679" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="ef9c" class="jp jq hi kv b fi ld la l lb lc">#Returns a new RDD by multiplying all elements of parent RDD by 2<br/>newRDD= myRDD.map(lambda x: x*2)</span><span id="1af0" class="jp jq hi kv b fi ld la l lb lc">print(newRDD.collect())</span></pre><p id="17c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kp">输出:</em> </strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="bc66" class="jp jq hi kv b fi kz la l lb lc">[2, 4, 6, 8, 10]</span></pre><h2 id="2a79" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">平面地图()</h2><p id="c18d" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> flatMap() </em>通过将函数应用于父RDD的每个元素，然后将结果展平，返回一个新的RDD。我们来看一个例子，了解一下<em class="kp"> map() </em>和<em class="kp"> flatMap() </em>的区别。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="1130" class="jp jq hi kv b fi kz la l lb lc">data= [1, 2, 3]<br/>myRDD= sc.parallelize(data)</span><span id="fc93" class="jp jq hi kv b fi ld la l lb lc"><strong class="kv hj">#map() returns [[1], [1, 2], [1, 2, 3]]</strong><br/>mapRDD= myRDD.map(lambda x: range(1,x))</span><span id="e0c3" class="jp jq hi kv b fi ld la l lb lc"><strong class="kv hj">#flatmap() returns [1, 1, 2, 1, 2, 3]</strong><br/>flatMapRDD = myRDD.flatMap(lambda x: range(1,x))</span></pre><h2 id="0040" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">过滤器()</h2><p id="46cd" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> filter() </em>返回一个新的RDD，仅包含父RDD中满足filter内部函数的元素。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="5d3c" class="jp jq hi kv b fi kz la l lb lc">data= [1, 2, 3, 4, 5, 6]</span><span id="11a9" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="25c8" class="jp jq hi kv b fi ld la l lb lc">#returns an RDD with only the elements that are divisible by 2<br/>newRDD= myRDD.filter(lambda x: x%2 == 0)</span><span id="8cfd" class="jp jq hi kv b fi ld la l lb lc">print(newRDD.collect())</span></pre><p id="7220" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kp">输出:</em> </strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="3c09" class="jp jq hi kv b fi kz la l lb lc">[2, 4, 6]</span></pre><h2 id="6524" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">独特()</h2><p id="64af" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> distinct() </em>返回一个新的RDD，它只包含父RDD中的distinct元素</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="f2a5" class="jp jq hi kv b fi kz la l lb lc">data= [1, 2, 2, 3, 3, 3]</span><span id="fdc0" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="32d6" class="jp jq hi kv b fi ld la l lb lc">newRDD= myRDD.distinct()</span><span id="8df1" class="jp jq hi kv b fi ld la l lb lc">print(newRDD.collect())</span></pre><p id="a256" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kp">输出:</em> </strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="379b" class="jp jq hi kv b fi kz la l lb lc">[1, 2, 3]</span></pre><h2 id="033b" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">groupByKey()</h2><p id="257e" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> groupByKey() </em>将RDD的(Key，value)对中每个键的值分组到一个序列中。我们得到的是一个允许我们迭代结果的对象。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="6f44" class="jp jq hi kv b fi kz la l lb lc">myRDD = sc.parallelize([(“a”, 1), (“a”, 2), (“a”, 3), (“b”, 1)])</span><span id="592f" class="jp jq hi kv b fi ld la l lb lc">#print result as list<br/>resultList= myRDD.groupByKey().mapValues(list)</span><span id="c43f" class="jp jq hi kv b fi ld la l lb lc">reultList.collect()</span></pre><p id="ef16" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">T31】输出:T33】</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="4a64" class="jp jq hi kv b fi kz la l lb lc">[(‘a’, [1, 2, 3]), (‘b’, [1])]</span></pre><h2 id="1cb2" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">reduceByKey()</h2><p id="6729" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> reduceByKey() </em>在(Key，value)对的数据集上调用时，返回一个新的数据集，其中聚合了每个键的值。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="4235" class="jp jq hi kv b fi kz la l lb lc">from operator import add</span><span id="1d25" class="jp jq hi kv b fi ld la l lb lc">myRDD = sc.parallelize([(“a”, 1), (“a”, 2), (“a”, 3), (“b”, 1)])</span><span id="bdd2" class="jp jq hi kv b fi ld la l lb lc">#adds the values by keys<br/>newRDD= myRDD.reduceByKey(add)</span><span id="7caf" class="jp jq hi kv b fi ld la l lb lc">newRDD.collect()</span></pre><p id="1674" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">T37】输出:T39】</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="9d7a" class="jp jq hi kv b fi kz la l lb lc">[(‘a’, 6), (‘b’, 1)]</span></pre><p id="f791" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kp">注意:</em> </strong> <em class="kp"> groupByKey()和reduceByKey()可能看起来差不多。它们之间的区别在于，当在RDD上调用groupByKey时，分区中的数据在网络上被打乱，然后它们才被分组。这导致大量数据不必要地在网络上传输。然而，reduceByKey()在对数据进行洗牌以提高效率之前，在本地根据它们各自分区上的键来组合这些对。因此，reduceByKey()用于大型数据集以获得更好的性能。</em></p><h2 id="4905" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">sortByKey()</h2><p id="428d" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> sortByKey() </em>返回一个新的RDD，其父RDD(key，value)对按照键的排序顺序排列。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="a863" class="jp jq hi kv b fi kz la l lb lc">myRDD = sc.parallelize([(“c”, 1), (“d”, 2), (“a”, 3), (“b”, 4)])</span><span id="6b13" class="jp jq hi kv b fi ld la l lb lc">#sort by key<br/>newRDD= myRDD.sortByKey()</span><span id="0cdc" class="jp jq hi kv b fi ld la l lb lc">newRDD.collect()</span></pre><p id="fdc5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kp">输出:</em> </strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="e475" class="jp jq hi kv b fi kz la l lb lc">[(‘a’, 3), (‘b’, 4), (‘c’, 1), (‘d’, 2)]</span></pre><h2 id="1200" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">联合()</h2><p id="f794" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> union() </em>返回父RDD的并集的新RDD。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="9ba0" class="jp jq hi kv b fi kz la l lb lc">myRDD1 = sc.parallelize([1, 2, 3, 4])</span><span id="0c8f" class="jp jq hi kv b fi ld la l lb lc">myRDD2 = sc.parallelize([ 3, 4, 5, 6, 7])</span><span id="368b" class="jp jq hi kv b fi ld la l lb lc">#union of myRDD1 and myRDD2<br/>newRDD = myRDD1.union(myRDD2)</span><span id="7d42" class="jp jq hi kv b fi ld la l lb lc">newRDD.collect()</span></pre><p id="9d74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输出:</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="3bdc" class="jp jq hi kv b fi kz la l lb lc">[1, 2, 3, 4, 3, 4, 5, 6, 7]</span></pre><p id="f357" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">类似地，我们有intersection()返回两个rdd的交集。</p><h1 id="f76b" class="le jq hi bd jr lf lg lh jv li lj lk jz ll lm ln kc lo lp lq kf lr ls lt ki lu bi translated">行动</h1><p id="c0a3" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">动作是在RDD上执行计算并将最终结果返回给驱动程序的操作。在将数据加载到RDD之后，它触发执行来执行中间转换，并最终将结果传递回来。这些动作是产生非RDD值的操作。正如我们已经看到的，只有当一个动作需要返回一个结果时，转换才会被执行。收集、减少、计数键、计数是一些动作。</p><p id="53be" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们用例子来看看rdd上的一些动作。</p><h2 id="7d20" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">收集()</h2><p id="f223" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">看了上面的例子，现在你应该知道<em class="kp"> collect() </em>是做什么的了。它返回一个包含RDD所有元素的列表。</p><h2 id="4f74" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">计数()</h2><p id="5bf3" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> count() </em>返回RDD中元素的个数</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="d955" class="jp jq hi kv b fi kz la l lb lc">data= [“Scala”, “Python”, “Java”, “R”]</span><span id="3935" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="1ba3" class="jp jq hi kv b fi ld la l lb lc">#Returns 4 as output<br/>myRDD.count()</span></pre><h2 id="3784" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">减少()</h2><p id="77e1" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> reduce() </em>使用一个以RDD的两个元素为输入并给出结果的函数来聚合RDD的元素。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="dbda" class="jp jq hi kv b fi kz la l lb lc">data= [1, 2, 3, 4, 5]</span><span id="e70a" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="2a00" class="jp jq hi kv b fi ld la l lb lc">#returns the product of all the elements<br/>myRDD.reduce( lambda x, y: x * y)</span></pre><p id="dbb9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输出:</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="8d5b" class="jp jq hi kv b fi kz la l lb lc">120</span></pre><p id="0601" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它也可以用于字符串。在这种情况下，结果也将是一个字符串。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="2f07" class="jp jq hi kv b fi kz la l lb lc">data= [“Scala”, “Python”, “Java”, “R”]</span><span id="7fa6" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="61b4" class="jp jq hi kv b fi ld la l lb lc">#Concatenate the string elements<br/>myRDD.reduce( lambda x, y: x + y)</span></pre><p id="f896" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输出:</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="7974" class="jp jq hi kv b fi kz la l lb lc">‘ScalaPythonJavaR’</span></pre><h2 id="ace7" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">foreach()</h2><p id="b51e" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">将函数应用于RDD中的每个元素</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="f82a" class="jp jq hi kv b fi kz la l lb lc">def fun(x):<br/>    print(x)</span><span id="444a" class="jp jq hi kv b fi ld la l lb lc">data= [“Scala”, “Python”, “Java”, “R”]</span><span id="8f9c" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="61c5" class="jp jq hi kv b fi ld la l lb lc">#function applied to all the elements<br/>myRDD.foreach(fun)</span></pre><p id="87b3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输出:</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="5777" class="jp jq hi kv b fi kz la l lb lc">Scala<br/>Python<br/>Java<br/>R</span></pre><h2 id="18db" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">countByValue()</h2><p id="4d31" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">它将RDD中每个唯一值的计数作为字典以(值，计数)对的形式返回。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="b466" class="jp jq hi kv b fi kz la l lb lc">data= [“Python”, “Scala”, “Python”, “R”, “Python”, “Java”, “R”, ]</span><span id="8b54" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="dd2c" class="jp jq hi kv b fi ld la l lb lc">#items() returns a list with all the dictionary keys and values returned by countByValue()</span><span id="f775" class="jp jq hi kv b fi ld la l lb lc">myRDD.countByValue().items()</span></pre><p id="d25a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输出:</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="7570" class="jp jq hi kv b fi kz la l lb lc">[(‘Python’, 3), (‘R’, 2), (‘Java’, 1), (‘Scala’, 1)]</span></pre><h2 id="4c26" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">计数键()</h2><p id="95ee" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">它计算RDD中每个唯一键的值的数量，并将其作为字典返回。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="ea23" class="jp jq hi kv b fi kz la l lb lc">data= [(“a”, 1), (“b”, 1), (“c”, 1), (“a”, 1)]</span><span id="7852" class="jp jq hi kv b fi ld la l lb lc">myRDD = sc.parallelize(data)</span><span id="7cec" class="jp jq hi kv b fi ld la l lb lc">myRDD.countByKey().items()</span></pre><p id="b4eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输出:</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="5655" class="jp jq hi kv b fi kz la l lb lc">[(‘a’, 2), (‘b’, 1), (‘c’, 1)]</span></pre><h2 id="f938" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">拿走</h2><p id="cad1" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><em class="kp"> take(n) </em>以同样的顺序返回RDD的前n个元素</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="fe05" class="jp jq hi kv b fi kz la l lb lc">data= [2, 5, 3, 8, 4]</span><span id="1c2f" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="b8d0" class="jp jq hi kv b fi ld la l lb lc">#return the first 2 elements<br/>myRDD.take(3)</span></pre><p id="4b0b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输出:</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="c356" class="jp jq hi kv b fi kz la l lb lc">[2, 5, 3]</span></pre><h2 id="7836" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">顶部(n)</h2><p id="6b0c" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">返回按降序排列的所有RDD元素中的前n个元素。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="4aee" class="jp jq hi kv b fi kz la l lb lc">data= [2, 5, 3, 8, 4]</span><span id="542d" class="jp jq hi kv b fi ld la l lb lc">myRDD= sc.parallelize(data)</span><span id="e5da" class="jp jq hi kv b fi ld la l lb lc">#return the first 2 elements<br/>myRDD.take(3)</span></pre><p id="f0aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输出:</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="b6b0" class="jp jq hi kv b fi kz la l lb lc">[8, 5, 4]</span></pre></div><div class="ab cl mo mp gp mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="hb hc hd he hf"><h2 id="61a9" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">让我们动手吧！</h2><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mv"><img src="../Images/443c6f4138916f33e2e11c0e7ba53073.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/0*2jSujqlJ-QNP1XOP.jpg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来源:Freepik</figcaption></figure><p id="4b58" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">既然我们已经熟悉了PySpark中rdd上的基本转换和操作，是时候全面了解这些在一个完整的Spark程序中是如何工作的了。为了证明这一点，这里有几个PySpark的简单用例，它们将清晰地展示SparkContext、rdd、转换和动作是如何在Spark程序中使用的。这些都是简单的程序，你可以试着自己编码。因此，在查看代码之前，请尝试自己编写代码。</p><p id="f4aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kp">注意:</em> </strong> <em class="kp">要运行PySpark应用程序，在命令提示符下执行以下命令</em></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="9b73" class="jp jq hi kv b fi kz la l lb lc"><strong class="kv hj">spark-submit filename.py</strong></span></pre><h2 id="14e0" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">问题陈述1 —流行电影:</h2><p id="3bba" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">想出一个Spark程序，根据观看次数找到最受欢迎的电影<strong class="is hj"> </strong>，并显示电影名称而不是电影ID。要使用的数据集是包含100k电影分级的movielens数据集。电影id存储在u.data文件中，相应的电影名称存储在u.item文件中。数据集可以在<a class="ae jo" href="https://github.com/Anveshrithaa/Apache-Spark-Projects/tree/master/popular-movies/ml-100k" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="b9c8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kp">注意:</em> </strong> <em class="kp">为此，我们将使用广播变量来保存所有节点的公共数据副本。这个变量被缓存在所有工作节点上，而不是将数据与其任务一起显式发送，以提高效率。</em></p><figure class="kq kr ks kt fd ij"><div class="bz dy l di"><div class="mw mx l"/></div></figure><p id="0488" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输出:</strong></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="b204" class="jp jq hi kv b fi kz la l lb lc">(‘Star Wars (1977)’, 583)<br/>(‘Contact (1997)’, 509)<br/>(‘Fargo (1996)’, 508)<br/>(‘Return of the Jedi (1983)’, 507)<br/>(‘Liar Liar (1997)’, 485)<br/>(‘English Patient, The (1996)’, 481)<br/>(‘Scream (1996)’, 478)<br/>(‘Toy Story (1995)’, 452)<br/>(‘Air Force One (1997)’, 431)<br/>(‘Independence Day (ID4) (1996)’, 429)</span></pre><h2 id="980c" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">问题陈述2 —字数:</h2><p id="f958" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">找出一本书中所有独特的单词，以及每个单词出现的次数。要使用的数据集是book.txt，可以在这里找到<a class="ae jo" href="https://github.com/Anveshrithaa/Apache-Spark-Projects/blob/master/word-count/Book.txt" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="33b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过删除任何标点符号或其他不属于单词的东西，只列出单词。在考虑独特的单词时，单词不应该区分大小写。也就是说，例如,“spark”和“Spark”被认为是一个唯一的单词，与大小写无关。</p><figure class="kq kr ks kt fd ij"><div class="bz dy l di"><div class="mw mx l"/></div></figure><p id="ebfa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你觉得它很有趣，那就去选择一个你自己喜欢的问题陈述，并尝试一下吧！</p><p id="6b53" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇博客中，我们看到了如何创建rdd，以及更多关于rdd的操作和一些例子。我希望这让您对Spark内核的基础有了清晰的了解。现在让我们转到Apache Spark的其他组件。是时候开始最有趣的部分了——用PySpark进行机器学习！一定要看看下一篇文章中关于使用python的Spark的机器学习方面的实践会议。期待在那里见到你！</p></div><div class="ab cl mo mp gp mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="hb hc hd he hf"><p id="855e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">查看本系列中的其他博客</p><p id="cb9e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@anveshrithaas/getting-started-with-apache-spark-part-1-91b379204ae0"> <strong class="is hj"> <em class="kp">第1部分Apache Spark入门</em> </strong> </a></p><p id="c258" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@anveshrithaas/introduction-to-pyspark-part-2-6d6113e31592"> <strong class="is hj"> <em class="kp">第二部分—PySpark</em></strong></a>介绍</p><p id="48ca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@anveshrithaas/machine-learning-in-pyspark-part-4-5813e831922f"> <strong class="is hj"> <em class="kp">第四部分PySpark中的机器学习</em> </strong> </a></p><p id="9e9f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@anveshrithaas/end-to-end-machine-learning-pipeline-on-databricks-part-5-c10273e2cd88"> <strong class="is hj"> <em class="kp">第五部分——数据块上端到端的机器学习流水线</em> </strong> </a></p></div></div>    
</body>
</html>