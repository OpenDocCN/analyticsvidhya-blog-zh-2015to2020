<html>
<head>
<title>Trumpy Tweets — Trump Tweet Classifiers and Generators</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特朗普推文—特朗普推文分类器和生成器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/trumpy-tweets-trump-tweet-classifiers-and-generators-9ccfddc7764e?source=collection_archive---------10-----------------------#2019-12-18">https://medium.com/analytics-vidhya/trumpy-tweets-trump-tweet-classifiers-and-generators-9ccfddc7764e?source=collection_archive---------10-----------------------#2019-12-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ebe9ce270b284e2bb6e20fc99697ba85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g1Nx3ZZ9UQaw0v614813KA.png"/></div></div></figure><h1 id="e0d6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">摘要</h1><ul class=""><li id="c5b2" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">使用特朗普的大约24k条推文来训练特朗普推文生成器。</li><li id="4898" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">增加了来自奥巴马、希拉里和金·卡戴珊的另外24k条推文来训练推文分类器。</li><li id="926b" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">比较不同分类器的性能，使用性能更好的分类器来评估推文生成器的性能，并挑选出最“特朗普式”的虚假推文。</li></ul><h1 id="3330" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">动机</h1><p id="9db8" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">我是特雷弗·诺亚主持的每日秀的粉丝，我喜欢看他模仿川普。他的节目提醒我，特朗普有一种非常独特的说话方式——这有望被NLP模型识别和模仿。此外，特朗普如此沉迷于Twitter，以至于它为我提供了大量数据来训练我的机器人。</p><h1 id="7acf" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">计划</h1><p id="cf33" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">我计划建立两个推文生成器和两个推文分类器，并使用性能更好的分类器来评估生成器的性能，并选择最“特朗普式”的推文。</p><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ddb8d9a869946bf6a516c68e4813f862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uc3DzvymNHrafRYppl5OQA.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">这个计划</figcaption></figure><p id="b546" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">我计划尝试传统的统计方法和现代的神经网络方法。因此，对于分类器，我将训练一个多项式朴素贝叶斯模型和一个长短期记忆(LSTM)模型；对于生成器，我将训练一个马尔可夫链模型和一个LSTM模型。</p><h2 id="d4bd" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">分类者</h2><ul class=""><li id="d11d" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">多项式朴素贝叶斯</li><li id="bb56" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">LSTM</li></ul><h2 id="54aa" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">发电机</h2><ul class=""><li id="75fc" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">马尔可夫链模型</li><li id="5327" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">LSTM</li></ul><h1 id="eb8a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">数据</h1><h2 id="d3cd" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">特朗普的推文</h2><p id="9c39" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">Twitter API有许多限制——它只能访问用户的最后3200条推文，但布伦丹·布朗(Brendan Brown)创建了一个名为“<a class="ae mb" href="http://www.trumptwitterarchive.com" rel="noopener ugc nofollow" target="_blank">特朗普Twitter Archive </a>”的伟大网站，收集了几乎所有特朗普的推文。所以我使用这个档案来获取特朗普的推文数据。原始的。csv文件包含在这个项目的GitHub repo[此处添加链接]的数据文件夹中，但确定的来源是<a class="ae mb" href="https://github.com/bpb27/trump_tweet_data_archive" rel="noopener ugc nofollow" target="_blank">布朗的GitHub资源库。</a></p><h2 id="2e0f" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">其他人的推文</h2><p id="818e" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">为了训练一个可以对特朗普和非特朗普推文进行分类的分类器，我需要一些非特朗普的数据。这个<a class="ae mb" href="https://www.kaggle.com/speckledpingu/RawTwitterFeeds/data" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集</a>收集了几位政治家和名人的推文。在这个项目中，我将奥巴马、希拉里和金·卡戴珊的推文作为“非特朗普”推文。</p><h1 id="cb1c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">数据预处理</h1><p id="89b2" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">我做了两个层次的数据预处理:1)对所有推文的基本清理，2)对训练分类器的进一步预处理。之所以分两步完成，是因为我希望分类器学习的数据与生成器学习的数据略有不同。例如，对于生成器，我想保留@提及、#标签和特殊字符(比如！？,.)在我们的数据集中，因为我们确实希望我们的机器人能够@提及、#标记或使用感叹号。然而，像@、#和特殊字符这样的东西给标记化带来了很多困难，所以我需要在训练分类器之前删除它们。</p><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/80c0e5f70d513664f63a654029421a63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XovfFZCFxwfANbvit4ChUw.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">数据预处理有两个部分。</figcaption></figure><h2 id="08d4" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">数据预处理第1部分</h2><p id="8f99" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">首先，删除所有转发。这样，特朗普发了24595条推文，奥巴马、希拉里和金·卡戴珊发了24127条推文。</p><p id="b8fe" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">然后我从tweets中删除了引用、URL、' n's，并用' and '替换了' &amp;amp '。</p><pre class="la lb lc ld fd mc md me mf aw mg bi"><span id="3a7d" class="ln ir hi md b fi mh mi l mj mk">def clean_tweet(t):<br/>    # remove quotes<br/>    t = re.sub(r'"@.*', '', t)<br/>    t = re.sub(r'^“.*”$', '', t)</span><span id="2223" class="ln ir hi md b fi ml mi l mj mk">    # remove URLs<br/>    t = re.sub(r'https*:\/\/\S*', '', t)<br/>    t = re.sub(r'pic\.twitter\.com\/\S*', '', t)</span><span id="c3ba" class="ln ir hi md b fi ml mi l mj mk">    # remove \n<br/>    t = re.sub('\n', ' ', t)</span><span id="38dc" class="ln ir hi md b fi ml mi l mj mk">    # remove extra whitespaces<br/>    t = re.sub(r'\s+', ' ', t)</span><span id="f95e" class="ln ir hi md b fi ml mi l mj mk">    # replace '&amp;amp' with 'and'<br/>    t = re.sub('&amp;amp;', 'and', t) </span><span id="693a" class="ln ir hi md b fi ml mi l mj mk">    return(t)</span></pre><p id="2c41" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">上面清理的数据后来被用来训练发电机。</p><h2 id="3104" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">数据预处理第2部分</h2><p id="82c9" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">除了上面的清理，为了训练分类器，我们需要先去掉@和#这样的东西。</p><pre class="la lb lc ld fd mc md me mf aw mg bi"><span id="3472" class="ln ir hi md b fi mh mi l mj mk">def prepare_tweet_clf(t):<br/>    # clean<br/>    t = t.lower()<br/>    t = re.sub("'ll", ' will', t) # replace abbreviations<br/>    t = re.sub("won't", 'will not', t)<br/>    t = re.sub("n't", ' not', t) <br/>    t = re.sub(r'@[A-Za-z0-9_]+', '', t) # remove @mention<br/>    t = re.sub(r'#[A-Za-z0-9_]+', '', t) # remove #tag<br/>    t = re.sub(r'[^a-zA-Z ]', '', t) # remove special characters</span><span id="4d65" class="ln ir hi md b fi ml mi l mj mk">    # remove stopwords <br/>    stop = set(stopwords.words('english')) <br/>    stop.update(['rt', 'cc']) <br/>    stop = stop - set(['no', 'not', 'never']) <br/>    t = [word for word in t.split(' ') if word not in stop] <br/>    t = ' '.join(t)<br/>    <br/>    return t</span></pre><p id="6780" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">经过第二清洗步骤的数据用于训练分类器。</p><h1 id="0984" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">模型</h1><p id="e869" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">本项目有两种模式:</p><ol class=""><li id="3e51" class="jo jp hi jq b jr li jt lj jv mm jx mn jz mo kb mp kd ke kf bi translated">对特朗普的推文和其他人的推文进行分类的文本分类器</li><li id="c204" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb mp kd ke kf bi translated">生成特朗普风格的虚构推文的文本生成器</li></ol><p id="3896" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">在测试集上具有最高预测准确度的分类器被认为是最佳分类器，并用于评估文本生成器。</p><h1 id="6c6a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">推特分类器</h1><h2 id="c6ae" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">分割数据</h2><p id="beb3" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">特朗普和其他人的推文首先被合并成一个数据集，然后数据集被随机拆分成一个训练集(80%)和一个测试集(20%)。</p><pre class="la lb lc ld fd mc md me mf aw mg bi"><span id="0f2b" class="ln ir hi md b fi mh mi l mj mk">df_train, df_test = train_test_split(df_combine, test_size=0.2)</span><span id="effa" class="ln ir hi md b fi ml mi l mj mk">x_train, y_train = df_train['cleaned_text_clf'], df_train['author']<br/>x_test, y_test = df_test['cleaned_text_clf'], df_test['author']</span></pre><h2 id="de06" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">公制的</h2><p id="c565" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">分类器针对精度进行了优化，精度等于</p><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/8203cd65df9ddd1b577ce6f6101e5437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dW6zOSSMYuZ1lPDBGqIk_g.png"/></div></div></figure><p id="27cb" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">在这种情况下，它可以写成</p><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/365cccce689b2152c18cd79843be5aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Spm6fccUpvVDejeXhs3sHw.png"/></div></div></figure><p id="e2e1" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">直观上，精确度是分类器不将虚假推文标记为特朗普的能力。</p><h2 id="5021" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">分类器1 —多项式朴素贝叶斯</h2><p id="4135" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated"><a class="ae mb" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html" rel="noopener ugc nofollow" target="_blank">多项式朴素贝叶斯分类器</a>适用于具有离散特征的分类，例如文本分类。</p><p id="ebb3" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">这个模型的流水线由三部分组成:用CountVectorizer()矢量化，用TfidfTransformer()转换，用MultinomialNB()建模。我使用10重交叉验证网格搜索来优化参数，模型的最佳超参数集是:使用一元、二元和三元模型；使用原始计数代替tf-idf，并使用0.1的平滑系数。</p><p id="a999" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">该模型在训练集上进行训练，并使用数据集的其余部分评估其性能。正如下面的混淆矩阵所示，多项式朴素贝叶斯分类器令人印象深刻——它的精度大约是<strong class="jq hj"> 0.9791 </strong>。</p><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/7c9302541b0aae037e56548b55108fa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*5gm-0mw0Tf7rXYn2TBo94Q.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">多项式朴素贝叶斯分类器的混淆矩阵</figcaption></figure><h2 id="2b3c" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">分类器2 — LSTM</h2><p id="fc85" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">第二个分类器基于LSTM。长短期记忆(LSTM)是一种具有反馈网络的递归神经网络(RNN)架构。它被开发来处理在训练传统的RNNs时可能遇到的爆炸和消失梯度问题。作为RNN的变体，LSTM非常适合对序列数据进行分类、处理和预测。</p><p id="baca" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">该项目中实现的模型有两个双向LSTM层、两个密集层和一个输出层。这个模型的灵感来自Manash Pratim Barman发明的<a class="ae mb" href="https://github.com/manashpratim/Tweet-Classification" rel="noopener ugc nofollow" target="_blank">仇恨推特探测器</a>。</p><p id="3ad4" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">我使用来自手套的<a class="ae mb" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank"> Twitter预训练单词嵌入对令牌进行矢量化(200d个向量)，并对模型进行20个时期的训练。</a></p><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/c5d0c8f01b7714cbc1b17a7dcfab273c.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*rTFCUsOb93kpYcTCT9AWVw.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">LSTM分类器的混淆矩阵</figcaption></figure><p id="364e" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">LSTM模型在测试集上获得了0.8955的准确率，这还不错。但是由于多项式朴素贝叶斯分类器获得了更高的准确性，我将使用它来评估tweet生成器的性能。</p><h2 id="afbe" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">模型比较</h2><p id="79c2" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">对于给定的任务和数据集，多项式朴素贝叶斯分类器优于LSTM分类器。我认为这是因为文本分类是一项相对简单的任务，我们的数据集不够大，所以像LSTM这样的复杂模型可能会过度拟合。换句话说，如果我们有更多的数据，LSTM的表现可能会更好。</p><h1 id="99d8" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">Tweet生成器</h1><h2 id="73e1" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">生成器1 —马尔可夫链模型</h2><p id="3fdc" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">马尔可夫链基于这样的思想:可能的下一个状态完全依赖于当前状态。基于这个想法，我们可以训练一个马尔可夫链模型来学习这样的事情:你在“喜欢”之后找到“香蕉”/“橙子”/“苹果”的可能性有多大。</p><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/372c33b39af394b703e35d02f4fe85e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-MahqW4TBtrvslC14TNNSg.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">马尔可夫链的例子</figcaption></figure><p id="d69b" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">换句话说，在生成文本时，我们随机选择第一个单词，然后在概率基础上连续选择“下一个单词”。</p><p id="b130" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">对于第一个tweet生成器，我使用了一个名为<a class="ae mb" href="https://github.com/jsvine/markovify" rel="noopener ugc nofollow" target="_blank"> Markovify </a>的包。它是一个基于马尔可夫链的文本生成器包，由Jeremy Singer-Vine开发。它为用户提供了设置<code class="du mt mu mv md b">state_size</code>(一元/二元/三元)和使用词性(POS)标记的选项。</p><p id="b2c7" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">训练三个模型:二元模型基线模型、三元模型基线模型和三元模型+位置模型基线模型。然后，我分别用这三个模型生成了1000条推文，并根据它们的推文欺骗之前训练的分类器的程度来评估它们的性能。</p></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><p id="3ca6" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated"><strong class="jq hj">二元马尔可夫链模型:</strong>推文愚弄分类器的比例为0.93。也就是说，在生成的1000条虚假推文中，有930条推文被我们的多项分类器归类为“特朗普的”。最‘特朗普式’的推文(概率= 0.9999)是:</p><blockquote class="nd ne nf"><p id="0bae" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">从一大批军用武器和供给品到我在苏格兰Trump国际高尔夫球场的会员！</p></blockquote><p id="4769" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">具有75%的“特朗普”概率(概率= 0.98)的推文是:</p><blockquote class="nd ne nf"><p id="1aa9" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">看，应该为使用名人的名字感到羞耻，然后是新冠军克里斯·韦德曼！</p></blockquote><p id="9caa" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">“特朗普”推文的中位数(概率=0.94)是:</p><blockquote class="nd ne nf"><p id="e5ce" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">#辩论。美国有胆量承受更高的失业率。</p></blockquote></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><p id="5d55" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated"><strong class="jq hj"> Trigram马尔可夫链模型:</strong>Trigram生成器生成的tweets欺骗了我们的分类器的比例为0.946。我们收到的最“特朗普式”的推文(概率= 0.9999)是:</p><blockquote class="nd ne nf"><p id="073c" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">由13名愤怒的民主党人和其他完全腐败和/或矛盾的人领导的操纵政治迫害。</p></blockquote><p id="5100" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">第75百分位的“特朗普”推文(概率= 0.99):</p><blockquote class="nd ne nf"><p id="103c" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">谢谢你，这是一个非常明智的举动，但特德·克鲁兹忘记提交了。</p></blockquote><p id="cf48" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">中值推文(概率= 0.96):</p><blockquote class="nd ne nf"><p id="8e46" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">与此同时，他们继续被它所吸引。</p></blockquote></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><p id="0e98" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated"><strong class="jq hj"> Trigram + POS马尔可夫链模型:</strong>对于这个生成器，tweets愚弄我们的分类器的比例是0.947。最‘特朗普式’的推文(概率= 0.9999)是:</p><blockquote class="nd ne nf"><p id="a796" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">我们想要胜利..苏格兰特朗普国际高尔夫球场。</p></blockquote><p id="15a1" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">第75百分位的“特朗普”推文(概率= 0.99):</p><blockquote class="nd ne nf"><p id="cd1c" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">我会轻而易举地击败希拉里，但林赛·格雷厄姆说我不会在这里呆太久了，这叫嫉妒。</p></blockquote><p id="ea12" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">中值推文(概率= 0.95):</p><blockquote class="nd ne nf"><p id="6efc" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">。代表整个国家，感谢你今天的更新和伟大的工作！</p></blockquote><p id="0a1a" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">——看起来更复杂的模型在欺骗分类器方面做得(稍微)更好，我们得到的虚假推文甚至对“中值特朗普”的推文也很好。</p><h2 id="7d6b" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">LSTM</h2><p id="b69b" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">在这一部分，我使用了Max Woolf开发的<a class="ae mb" href="https://github.com/minimaxir/textgenrnn" rel="noopener ugc nofollow" target="_blank"> textgenrnn </a>包来构建生成器。textgenrnn 是一个基于Keras/TensorFlow的Python 3模块，用于创建char-rnn，它可以在字符级或单词级生成文本。</p><p id="9890" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">与前面的模型类似，我用每个生成器生成了1000条tweets，并计算它们愚弄分类器的成功率。这是推特——</p><p id="98a9" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated"><strong class="jq hj">人物级LSTM模型:</strong>推文愚弄我们分类器的比例是0.985。最‘特朗普式’的推文(概率= 0.99999)是:</p><blockquote class="nd ne nf"><p id="0053" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">。@marklevinshow访谈讨论名人学徒和歪希拉里只会在世界上出生。我将是《纽约时报》上拥有仇恨者和真相的最佳人选——刚刚报道说我是唯一一个被假新闻媒体报道的人</p></blockquote><p id="6d3a" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">第75百分位的“特朗普”推文(概率= 0.99595):</p><blockquote class="nd ne nf"><p id="a6a0" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">我的@SquawkCNBC采访讨论了美利坚合众国的董事会会议室，这将是一个很好的事实，即中国将永远是世界上最伟大的，所有其他人，准备好迎接胜利者吧！</p></blockquote><p id="737a" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">中值推文(概率= 0.97986):</p><blockquote class="nd ne nf"><p id="4209" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">一个必须花费的记录和积极的过程爱德华总统奥巴马在一个失败的政策中所做的悲惨交易@SecretaryZinkens将是一个伟大的家伙，在美国军队的领域将是美国人民和Stoc受害者的耻辱</p></blockquote></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><p id="bcd7" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated"><strong class="jq hj">词级LSTM模型:</strong>推文愚弄我们分类器的比例是#。最“特朗普式”的推文(概率= 0.99996)是:</p><blockquote class="nd ne nf"><p id="617f" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">假新闻媒体拒绝为cnn报道我的大新闻。我很荣幸能在亚利桑那号上发言。谢谢大家！#特朗普2016</p></blockquote><p id="d14b" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">第75百分位的“特朗普”推文(概率= 0.97720):</p><blockquote class="nd ne nf"><p id="1474" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">“我非常尊重代表美国医疗保险的人们。还记得伟大的总统吗？他是个好人！</p></blockquote><p id="4f0b" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">中值推文(概率= 0.89935):</p><blockquote class="nd ne nf"><p id="c9f9" class="kl km ng jq b jr li kn ko jt lj kp kq nh lk ks kt ni ll kv kw nj lm ky kz kb hb bi translated">。@ hillaryclinton上了伊利诺斯报的头版。。。但是要写a，因为这应该是墨西哥的经济失败。问题12。你们两个都是。</p></blockquote><h2 id="faaa" class="ln ir hi bd is lo lp lq iw lr ls lt ja jv lu lv je jx lw lx ji jz ly lz jm ma bi translated">模型比较</h2><p id="d8b8" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">通过阅读生成的推文，我认为马尔可夫链模型和LSTM模型在模仿川普的推文方面做得很好。他们愚弄分类器的表现证实了我的观察——至少93%的推文愚弄了分类器。尽管根据我的个人判断，马尔可夫链和LSTM生成的推文都很不错，但LSTM生成器似乎更擅长欺骗分类器——它有更高比例的推文成功欺骗了分类器。</p><p id="9a26" class="pw-post-body-paragraph kl km hi jq b jr li kn ko jt lj kp kq jv lk ks kt jx ll kv kw jz lm ky kz kb hb bi translated">我认为这可能是因为马尔可夫链模型在预测下一个令牌时只考虑当前令牌，这往往会导致上下文的丢失(换句话说，马尔可夫链模型是“无记忆的”)。另一方面，LSTM模型特别擅长长时间记忆信息。这种行为可能使LSTM模型在这个任务上胜过马尔可夫链模型。</p><h1 id="10ae" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">未来计划</h1><ul class=""><li id="064e" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">润色输出的句子，例如拼写纠正、必要时的大写和标点符号纠正。</li><li id="b9be" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">使用生成对抗网络来提高文本生成器和文本分类器的性能</li></ul><h1 id="21dd" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">笔记</h1><p id="38a7" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">这个包的所有数据和代码都可以在这个<a class="ae mb" href="https://github.com/SUN-Wenjun/Trump_Tweet_Generator" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>和这个<a class="ae mb" href="https://github.com/SUN-Wenjun/Trump_Tweet_Generator/blob/master/trumpy_tweet.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>上找到。</p></div></div>    
</body>
</html>