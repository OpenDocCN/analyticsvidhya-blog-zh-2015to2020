# 使用 Dask 的探索性数据分析

> 原文：<https://medium.com/analytics-vidhya/exploratory-data-analysis-using-dask-b145417c029a?source=collection_archive---------10----------------------->

第一步是下载数据集。你可以从 Kaggle 选择一个数据集，或者使用我在这篇博客中使用的数据集，它来自给定的链接[https://www.kaggle.com/new-york-city/nyc-parking-tickets](https://www.kaggle.com/new-york-city/nyc-parking-tickets)。

让我们从导入所需的库开始。

![](img/fdb164001ca69f97c6fc0c2e4252f9ab.png)

在浏览 NYC 停车罚单 zip 文件时，我们看到文件夹中有 4 个 CSV 文件。让我们一个一个地阅读它们。

![](img/a338d99a7b656d65a5fab1fed135676f.png)

让我们打印 2017 财年的前几行，并检查其列名。

![](img/7a84e831d00739274f9cb1718b9e700f.png)

在这里，我们可以看到，尽管已经打印了 2017 财年，但这些值尚未更新。数据类型是通过快速浏览每一列中的值来指定的，以后可以修改。

下一步是在单个数据帧中一起读取所有文件。这就是达斯克的妙处。

为了实现这一点，我们必须匹配不同文件中相同的列名。

![](img/9bbc227988413973132e7096bbb6c2e4.png)

当您运行它时，您将获得数据集中所有公共列的列表。

![](img/8c3a565ca08d2536c34ca468cdb9cd18.png)

让我们在 2017 财年文件中应用这组公共列名，并检查其标题。

![](img/dec042df919e84ee7182a6cd1a7019f7.png)

虽然不是必需的，但是检查每个列名的数据类型是一个很好的做法。

![](img/b87834b74ade0fba01b02ef47b251582.png)

现在让我们在单个数据帧中读取所有 CSV 文件。

![](img/0c44db51481f11660f4233519d31f259.png)

我们现在可以从 EDA 开始。

我将在这个博客中讨论 3 个难度不断增加的问题以及它们的答案。

Q1。数据集中的车辆在 2014 年购买的唯一年份总数是多少？

A1。让我们使用常见的列再次阅读 2014 年的文件，这次是为了得到答案。我们还将在这里使用进度条来计时提取过程。

![](img/0b2046cfc3efb1b651cb0caba59e41ca.png)![](img/bec74a6d48c2d87e6e2c5b15e7471979.png)

如我们所见，2014 年的数据集中有 155 个独特的年份。

Q2。有多少缺失值？

![](img/aa483323771545a993b17af8bcdeaab9.png)

我们计算缺失值占整个数据集的百分比。

上面的代码应该给出以下输出:

![](img/6ebdf008af0b03de4a7ab09d81221759.png)

因此，我们可以看到该数据集中列方向缺失值的百分比。

问题已经得到了回答，但是我正在运行几行可选的额外代码来清理我们的数据。

这里，我们将删除缺失值超过 50%的列，以清理我们的数据。

![](img/dd41fdfc87525fba742027b9a3d4fc36.png)![](img/da1252d066035fffe11b9f17dbdaaad4.png)![](img/76c3dff19546a0d761d1e293b0067487.png)

最后，所有缺失的值都被删除了。

Q3。独特板块类型出现的频率是多少？

![](img/5b8cbf8d2a5da87b72b7cd7dcbb5ba04.png)

因为我们已经移除了所有缺失的值，所以我们可以获得板类型的准确频率。上面的代码产生以下输出。

![](img/cd16639f503b43d308ef0609632e8803.png)

我们可以在这里看到每个独特的孔板类型编号的数量。

现在，您可以尝试使用不同的变量和 Dask 操作来探索数据集。

编码快乐！:)