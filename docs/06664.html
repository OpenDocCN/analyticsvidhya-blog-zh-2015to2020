<html>
<head>
<title>AlexNet in a Nutshell</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简而言之AlexNet</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/alexnet-in-a-nutshell-4a9445e92d6d?source=collection_archive---------18-----------------------#2020-05-29">https://medium.com/analytics-vidhya/alexnet-in-a-nutshell-4a9445e92d6d?source=collection_archive---------18-----------------------#2020-05-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1c67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你好，欢迎回到我的博客，我是<strong class="ih hj">里提克·杜塔</strong>，在这个博客中，我将向你展示另一个CNN模型<strong class="ih hj"> AlexNet的工作和架构。</strong>我们还在AlexNet中首次看到了不同的技术。最后我们看看如何训练自己的AlexNet模型。</p><p id="3980" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，为什么有人关心另一个CNN的模特名叫<strong class="ih hj"> AlexNet。</strong>如果我告诉你这是计算机视觉中<strong class="ih hj">最大的突破</strong> <strong class="ih hj">之一，不信跟我来，让我们开始吧。</strong></p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="f9cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AlexNet由Alex <strong class="ih hj"> Krizhevsky、Ilya Sutskever和Geoffrey E. Hinton </strong>于2012年开发。</p><p id="65d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AlexNet在ImageNet数据集上接受了训练，数据集由<strong class="ih hj">120万个数据(图像)</strong>组成，其中包含<strong class="ih hj"> 1000个不同的类</strong>具有<strong class="ih hj">6000万个参数</strong>和<strong class="ih hj"> 650000个神经元</strong>组成<strong class="ih hj"> 5个卷积层</strong></p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><h1 id="1803" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">AlexNet架构</h1><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ki"><img src="../Images/262d47bc905d17992278be803d8440b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hddET1hyVK0Cg7StxDDFUQ.png"/></div></div></figure><blockquote class="ku kv kw"><p id="d392" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">第一层</strong> (Conv1)</p></blockquote><p id="d4d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第一层中，我们应用了<strong class="ih hj">大小为11*11 </strong>的<strong class="ih hj"> 96个内核</strong>，其中<strong class="ih hj">跨距为4 </strong>，并且<strong class="ih hj">没有填充</strong>，因此我们得到了55*55*96 的<strong class="ih hj">输入</strong></p><p id="0f2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">55因为，当前输入= <em class="kx">(先前输入-内核大小)/步幅+(填充* 2)=(227–11)/4+(0 * 2)</em></p><p id="a94f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于使用了<strong class="ih hj">激活ReLU</strong></p><blockquote class="ku kv kw"><p id="e6aa" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">第二层</strong></p></blockquote><p id="b839" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一层<strong class="ih hj">中使用了<strong class="ih hj">内核大小为3*3 </strong>的</strong>与<strong class="ih hj">步距为2 </strong>的<strong class="ih hj">重叠最大池，因此我们得到的<strong class="ih hj">输入为27</strong>=<em class="kx">(55–3)/2+1</em></strong></p><p id="bffc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有了重叠，过度拟合模型会稍微困难一些</p><blockquote class="ku kv kw"><p id="833e" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">第三层</strong> (Conv2)</p></blockquote><p id="b65f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与上面类似，我们有:</p><p id="acd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核数量= 256</p><p id="1b83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核大小= 5*5</p><p id="10d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步幅= 1</p><p id="45ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">填充= 2</p><p id="bd9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入= 27 =(27–5)/1+1+(2 * 2)</p><p id="77c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如你所看到的，输入大小与前一层相同，这是因为我们使用了填充= 2，步幅= 1</p><p id="7b5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过使用填充为<em class="kx">(内核大小-1)/2 </em>，跨距为1，我们得到与前一层相同的输入。</p><blockquote class="ku kv kw"><p id="69d6" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">第四层</strong></p></blockquote><p id="f869" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核大小= 3*3</p><p id="5e72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步幅= 2</p><p id="cf93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入= 13 =(27–3)/2+1</p><blockquote class="ku kv kw"><p id="5e4c" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">第五层</strong> (Conv3)</p></blockquote><p id="1315" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核数量= 384</p><p id="2377" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核大小= 3*3</p><p id="ee2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步幅= 1</p><p id="b8d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">填充= 1</p><p id="9c16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入= 13 =(13–3)/1+1+(2 * 1)</p><blockquote class="ku kv kw"><p id="8594" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">第六层</strong> (Conv4)</p></blockquote><p id="4a49" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核数量= 384</p><p id="5829" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核大小= 3*3</p><p id="1e7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步幅= 1</p><p id="6f8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">填充= 1</p><p id="d7d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入= 13 =(13–3)/1+1+(2 * 1)</p><blockquote class="ku kv kw"><p id="fc28" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">第七层</strong> (Conv5)</p></blockquote><p id="e798" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核数量= 256</p><p id="2106" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核大小= 3*3</p><p id="0926" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步幅= 1</p><p id="72fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">填充= 1</p><p id="a932" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入= 13 =(13–3)/1+1+(2 * 1)</p><blockquote class="ku kv kw"><p id="55a8" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">第八层</strong></p></blockquote><p id="bc57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内核大小= 3*3</p><p id="4284" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步幅= 2</p><p id="8b23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">填充= 0</p><p id="5472" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入= 5 =(13–3)/2+(2 * 0)</p><blockquote class="ku kv kw"><p id="9d29" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">第九层，第十层</strong></p></blockquote><p id="d105" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些层是完全连接的层，由4096个神经元组成</p><blockquote class="ku kv kw"><p id="3c10" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">输出层</strong></p></blockquote><p id="0a80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终层由1000个输出类组成。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><h1 id="5a72" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">AlexNet中使用的新功能</h1><blockquote class="ku kv kw"><p id="0b40" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">热卢</strong></p></blockquote><p id="d79c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所知，tanh的复杂性比ReLU更高，因为tanh是一个非线性函数，所以最好使用ReLU作为激活函数，这样训练时间会更短。</p><p id="caf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据AlexNet的记录，ReLU的训练时间比tanh快6倍</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lb"><img src="../Images/8e5465a915f563aceeeb6ac3eef1a006.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*vYR3vI9Kl5_yNUR7gdzlug.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated">MaxPooling2D</figcaption></figure><blockquote class="ku kv kw"><p id="0bb9" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">在多个GPU上训练</strong></p></blockquote><p id="e460" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用单个GPU限制了网络的最大规模，120万条记录对于单个GPU来说太大了，所以他们所做的是将任务分散到两个GPU上，称为GPU并行化</p><blockquote class="ku kv kw"><p id="3f73" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">局部反应正常化</strong></p></blockquote><p id="42cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">也称为数据标准化</p><p id="7494" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是第一次使用LRN，LRN被用来鼓励横向居住的概念。这个概念来自神经学，它认为横向抑制是神经元减少其邻居活动的能力。就深度神经网络而言，它用于执行局部对比度增强t，因此局部最大像素值用于激励下一层。</p><blockquote class="ku kv kw"><p id="0d77" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">重叠池</strong></p></blockquote><p id="7ca1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们设置S=Z (stride = keral size ),我们得到传统的局部池，但是如果我们设置Z&gt;S，我们得到重叠池，我们将能够提取更多的特征。好吧，让我们用简单的语言来理解它。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lg"><img src="../Images/7973714c60339217dced1e6bdea1be53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*PCoWzV0GB85QQkMzESsCJw.png"/></div></figure><p id="556f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们有上图所示的1D元素列表，并且我们有两个参数用于步幅和内核大小。因此，可以清楚地看到，如果我们设置S=Z(左部)，我们从不同的列表中获得相同的输出，但如果我们设置Z&gt;S，我们获得不同的输出(右部)。这是因为当S=Z时信息丢失导致数据收缩(从3个数据集到1个数据集),从而导致过拟合。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><h1 id="ed60" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">还使用了一些技术</h1><blockquote class="ku kv kw"><p id="66ec" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">数据扩充</strong></p></blockquote><p id="fde7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种技术用于增加数据的多样性，包括合并、翻转、平移、增亮等。因此，当测试任何图像是否异常缩放或光线不足时，该模型可以正确预测。</p><blockquote class="ku kv kw"><p id="4130" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated"><strong class="ih hj">辍学</strong></p></blockquote><p id="8b77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度神经网络倾向于在样本较少的情况下过度拟合训练数据集。但是通过使用不同的模型配置，过拟合的机会减少了，但是这也需要更多的计算能力，因为我们需要训练那些额外的模型。但是通过在训练期间随机删除节点，单个模型可以具有不同的网络架构。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><h1 id="7a7a" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">如何训练AlexNet模型</h1><blockquote class="ku kv kw"><p id="4afb" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">import warnings<br/>warnings . filter warnings(" ignore ")<br/>从keras.models导入顺序<br/>从keras.layers导入Dense、Activation、Dropout、Flatten、Conv2D、MaxPooling2D <br/>从keras.layers.normalization导入批处理规范化<br/>导入numpy作为np <br/> np.random.seed(1000)</p></blockquote><p id="ee30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">检索数据</p><blockquote class="ku kv kw"><p id="f60f" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">将tflearn.datasets.oxflower17导入为oxflower17 <br/> x，y = ox flower 17 . load _ data(one _ hot = True)</p></blockquote><p id="deb7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建顺序模式</p><blockquote class="ku kv kw"><p id="cd6b" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">模型=顺序()</p></blockquote><p id="d58b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一卷积层</p><blockquote class="ku kv kw"><p id="ed82" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(Conv2D(filters=96，input_shape=(224，224，3)，kernel_size=(11，11)，strides=(4，4)，padding = ' valid ')<br/>model . add(Activation(' relu '))</p></blockquote><p id="31c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">联营</p><blockquote class="ku kv kw"><p id="be2b" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model . add(MaxPooling2D(pool _ size =(3，3)，strides=(2，2)，padding='valid '))</p></blockquote><p id="f67e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在传递到下一层之前进行批量标准化</p><blockquote class="ku kv kw"><p id="d5a4" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(BatchNormalization())</p></blockquote><p id="2db6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二卷积层</p><blockquote class="ku kv kw"><p id="ff40" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(Conv2D(filters=256，kernel_size=(11，11)，strides=(1，1)，padding = ' valid ')<br/>model . add(Activation(' relu '))</p></blockquote><p id="abdf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">联营</p><blockquote class="ku kv kw"><p id="8ede" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model . add(MaxPooling2D(pool _ size =(3，3)，strides=(2，2)，padding='valid '))</p></blockquote><p id="303d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批量标准化</p><blockquote class="ku kv kw"><p id="fb58" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(BatchNormalization())</p></blockquote><p id="21af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第三卷积层</p><blockquote class="ku kv kw"><p id="795e" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(Conv2D(filters=384，kernel_size=(3，3)，strides=(1，1)，padding = ' valid ')<br/>model . add(Activation(' relu ')</p></blockquote><p id="1c61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批量标准化</p><blockquote class="ku kv kw"><p id="b60a" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(BatchNormalization())</p></blockquote><p id="5044" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第四卷积层</p><blockquote class="ku kv kw"><p id="4ad1" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(Conv2D(filters=384，kernel_size=(3，3)，strides=(1，1)，padding = ' valid ')<br/>model . add(Activation(' relu '))</p></blockquote><p id="6dd9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批量标准化</p><blockquote class="ku kv kw"><p id="c5dd" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(BatchNormalization())</p></blockquote><p id="8345" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第五卷积层</p><blockquote class="ku kv kw"><p id="9b44" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(Conv2D(filters=256，kernel_size=(3，3)，strides=(1，1)，padding = ' valid ')<br/>model . add(Activation(' relu '))</p></blockquote><p id="6c2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">联营</p><blockquote class="ku kv kw"><p id="7c32" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model . add(MaxPooling2D(pool _ size =(3，3)，strides=(2，2)，padding='valid '))</p></blockquote><p id="10c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批量标准化</p><blockquote class="ku kv kw"><p id="1fa4" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(BatchNormalization())</p></blockquote><p id="eacd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将它传递到致密层</p><blockquote class="ku kv kw"><p id="d596" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(Flatten())</p></blockquote><p id="f7cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一致密层</p><blockquote class="ku kv kw"><p id="2d5e" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(Dense(4096，input_shape=(224*224*3)，)<br/> model.add(Activation('relu '))</p></blockquote><p id="cc48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">添加下降以防止过度拟合</p><blockquote class="ku kv kw"><p id="5981" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(辍学(0.4))</p></blockquote><p id="9741" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批量标准化</p><blockquote class="ku kv kw"><p id="5ba8" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(BatchNormalization())</p></blockquote><p id="5700" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二致密层</p><blockquote class="ku kv kw"><p id="5036" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model . add(Dense(4096))<br/>model . add(激活(' relu '))</p></blockquote><p id="4174" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">并且比较不同激活函数的准确度和不同激活函数和丢失的准确度</p><blockquote class="ku kv kw"><p id="cfce" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(辍学(0.4))</p></blockquote><p id="f937" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批量标准化</p><blockquote class="ku kv kw"><p id="2c57" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(BatchNormalization())</p></blockquote><p id="bf67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第三致密层</p><blockquote class="ku kv kw"><p id="ca51" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model . add(Dense(1000))<br/>model . add(激活(' relu '))</p></blockquote><p id="84c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">添加辍学</p><blockquote class="ku kv kw"><p id="341f" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(辍学(0.4))</p></blockquote><p id="4d42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批量标准化</p><blockquote class="ku kv kw"><p id="76f2" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.add(BatchNormalization())</p></blockquote><p id="c841" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出层</p><blockquote class="ku kv kw"><p id="d84f" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model . add(Dense(17))<br/>model . add(Activation(' soft max '))</p><p id="cd39" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">模型.摘要()</p></blockquote><p id="d034" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">编制</p><blockquote class="ku kv kw"><p id="8c9d" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model . compile(loss = ' categorial _ cross entropy '，optimizer='adam '，\ <br/> metrics=['accuracy'])</p></blockquote><p id="643f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(5)火车</p><blockquote class="ku kv kw"><p id="f08a" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">model.fit(x，y，batch_size=64，epochs=5，verbose=0，validation_split=0.2，shuffle=True)</p><p id="2d77" class="if ig kx ih b ii ij ik il im in io ip ky ir is it kz iv iw ix la iz ja jb jc hb bi translated">score = model.evaluate(x，y) <br/> print('测试损失:'，score[0]) <br/> print('测试准确度:'，score[1])</p></blockquote><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es lh"><img src="../Images/32553d7d7dba3a39e9c0b0dba2db87fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vdfeBcXvMqBhAZDXDgRxEg.jpeg"/></div></div></figure><p id="c7ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到aquiracy相当不错，你也可以尝试一下tanh激活功能。</p><p id="57c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">型号总结</strong></p><pre class="kj kk kl km fd li lj lk ll aw lm bi"><span id="512b" class="ln jl hi lj b fi lo lp l lq lr">Model: "sequential_2"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_6 (Conv2D)            (None, 54, 54, 96)        34944     <br/>_________________________________________________________________<br/>activation_10 (Activation)   (None, 54, 54, 96)        0         <br/>_________________________________________________________________<br/>max_pooling2d_4 (MaxPooling2 (None, 27, 27, 96)        0         <br/>_________________________________________________________________<br/>batch_normalization_9 (Batch (None, 27, 27, 96)        384       <br/>_________________________________________________________________<br/>conv2d_7 (Conv2D)            (None, 17, 17, 256)       2973952   <br/>_________________________________________________________________<br/>activation_11 (Activation)   (None, 17, 17, 256)       0         <br/>_________________________________________________________________<br/>max_pooling2d_5 (MaxPooling2 (None, 8, 8, 256)         0         <br/>_________________________________________________________________<br/>batch_normalization_10 (Batc (None, 8, 8, 256)         1024      <br/>_________________________________________________________________<br/>conv2d_8 (Conv2D)            (None, 6, 6, 384)         885120    <br/>_________________________________________________________________<br/>activation_12 (Activation)   (None, 6, 6, 384)         0         <br/>_________________________________________________________________<br/>batch_normalization_11 (Batc (None, 6, 6, 384)         1536      <br/>_________________________________________________________________<br/>conv2d_9 (Conv2D)            (None, 4, 4, 384)         1327488   <br/>_________________________________________________________________<br/>activation_13 (Activation)   (None, 4, 4, 384)         0         <br/>_________________________________________________________________<br/>batch_normalization_12 (Batc (None, 4, 4, 384)         1536      <br/>_________________________________________________________________<br/>conv2d_10 (Conv2D)           (None, 2, 2, 256)         884992    <br/>_________________________________________________________________<br/>activation_14 (Activation)   (None, 2, 2, 256)         0         <br/>_________________________________________________________________<br/>max_pooling2d_6 (MaxPooling2 (None, 1, 1, 256)         0         <br/>_________________________________________________________________<br/>batch_normalization_13 (Batc (None, 1, 1, 256)         1024      <br/>__________________________________and compare accuracy with different activation functionsand compare accuracy with different activation functionsand compare accuracy with different activation functions_______________________________<br/>flatten_2 (Flatten)          (None, 256)               0         <br/>_________________________________________________________________<br/>dense_5 (Dense)              (None, 4096)              1052672   <br/>_________________________________________________________________<br/>activation_15 (Activation)   (None, 4096)              0         <br/>_________________________________________________________________<br/>dropout_4 (Dropout)          (None, 4096)              0         <br/>_________________________________________________________________<br/>batch_normalization_14 (Batc (None, 4096)              16384     <br/>_________________________________________________________________<br/>dense_6 (Dense)              (None, 4096)              16781312  <br/>_________________________________________________________________<br/>activation_16 (Activation)   (None, 4096)              0         <br/>_________________________________________________________________<br/>dropout_5 (Dropout)          (None, 4096)              0         <br/>_________________________________________________________________<br/>batch_normalization_15 (Batc (None, 4096)              16384     <br/>_________________________________________________________________<br/>dense_7 (Dense)              (None, 1000)              4097000   <br/>_________________________________________________________________<br/>activation_17 (Activation)   (None, 1000)              0         <br/>_________________________________________________________________<br/>dropout_6 (Dropout)          (None, 1000)              0         <br/>_________________________________________________________________<br/>batch_normalization_16 (Batc (None, 1000)              4000      <br/>_________________________________________________________________<br/>dense_8 (Dense)              (None, 17)                17017     <br/>_________________________________________________________________<br/>activation_18 (Activation)   (None, 17)                0         <br/>=================================================================<br/>Total params: 28,096,769<br/>Trainable params: 28,075,633<br/>Non-trainable params: 21,136<br/>_________________________________________________________________<br/>Train on 1088 samples, validate on 272 samples</span></pre><p id="4b7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是我的博客，希望你喜欢。祝你有美好的一天</p></div></div>    
</body>
</html>