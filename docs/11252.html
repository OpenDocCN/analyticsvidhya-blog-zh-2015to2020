<html>
<head>
<title>A Game of Prediction (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测的游戏(第一部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-game-of-prediction-part-1-coalition-games-to-explain-dnn-1e8d83ba6be4?source=collection_archive---------9-----------------------#2020-11-25">https://medium.com/analytics-vidhya/a-game-of-prediction-part-1-coalition-games-to-explain-dnn-1e8d83ba6be4?source=collection_archive---------9-----------------------#2020-11-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="d15c" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">基于SHAPLEY值的解释方法比较</h2><div class=""/><p id="e6a1" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">解释DNN的联盟游戏</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jm"><img src="../Images/02cea586a5405a424716ea7cadd6acfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wrgjhH6hdc0YndcoNTMcZQ.jpeg"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">图片来自:<a class="ae kc" href="https://unsplash.com/@grizzlybear" rel="noopener ugc nofollow" target="_blank">乔纳森·彼得森</a>——<a class="ae kc" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ed26" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">深度神经网络受到了极大的关注，因为它可以证明在某些假设下，它们是通用的近似器。但是网络是如何达到某个预测的，还不是很了解。因此，深度神经网络被称为黑盒算法。</p><p id="0081" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">为了了解深度神经网络如何产生某种预测，以及哪些输入特征对预测最负责，已经引入了名为<strong class="iq hs">解释方法</strong>的算法。这些方法中的大多数是基于试探法和反向传播。</p><p id="367e" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">这种解释方法的一个新类别是基于联合博弈理论的<strong class="iq hs"> Shapley值</strong>:<em class="kd">满足效率、虚拟玩家、对称和线性四个公理的联合博弈的解决方案概念，并允许在一条航道上的玩家之间分配收益。</em></p><blockquote class="ke kf kg"><p id="aee7" class="io ip kd iq b ir is it iu iv iw ix iy kh ja jb jc ki je jf jg kj ji jj jk jl hb bi translated"><strong class="iq hs"> SHAP方法</strong>不同于所有其他方法，它基于<em class="hi">坚实的理论背景:合作博弈论。</em></p></blockquote><p id="b20a" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">在深度神经网络预测的解释中，输入特征被认为是玩家和最终预测，即游戏。Shapley值是一种在球道中分配特征重要性的方法。</p><p id="db9e" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><em class="kd">Shapley值的数值计算计算量很大</em>，因此介绍了几种试图逼近Shapley值的解释方法，如KernelSHAP、DeepSHAP、DASP和Shapley采样。</p><blockquote class="ke kf kg"><p id="0c12" class="io ip kd iq b ir is it iu iv iw ix iy kh ja jb jc ki je jf jg kj ji jj jk jl hb bi translated">本研究的目的是对这些基于Shapley值的解释方法进行比较。</p></blockquote><h1 id="2407" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">合作博弈</h1><p id="2bf7" class="pw-post-body-paragraph io ip hi iq b ir li it iu iv lj ix iy iz lk jb jc jd ll jf jg jh lm jj jk jl hb bi translated">合作(或联盟)游戏是一些玩家合作，形成联盟，以最大化他们的利润的问题。</p><p id="4f59" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">在机器学习(ML)环境中，参与者由输入的不同部分(特征)来表示，他们一起合作产生网络输出。</p><h1 id="2e92" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">什么是解释？</h1><blockquote class="ke kf kg"><p id="c475" class="io ip kd iq b ir is it iu iv iw ix iy kh ja jb jc ki je jf jg kj ji jj jk jl hb bi translated">解释是将网络获得的知识翻译成人类可解释的数据，如文本、数字或图像。</p><p id="1d26" class="io ip kd iq b ir is it iu iv iw ix iy kh ja jb jc ki je jf jg kj ji jj jk jl hb bi translated">在我们的上下文中，解释是根据输入要素对生成网络输出的重要性，为SHAP方法中的每个输入要素分配一个值。</p></blockquote><p id="74e0" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">使用博弈论的语言:“解释为每个像素分配一个值，该值对应于该玩家对每个可能联盟的边际贡献的加权平均值。</p><p id="7158" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">修正一个联盟，边际贡献反映了玩家对联盟价值的贡献。"</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ln"><img src="../Images/81e998120fa8349539af2019ff42e88e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ITbyl4ft1B3gV0Mwe6hAKQ.png"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">来源:github.com/slundberg/shap</figcaption></figure><p id="297e" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">例如(对于计算机视觉任务)，图像中的每个像素都是一个特征(玩家)。最终目标可能是识别照片中的一个对象(网络输出)。在这个例子中，解释可以是其中最相关的像素被突出显示的地图。换句话说，是网络回答问题时最关注的领域的指示。</p><h1 id="9783" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">玩家的边际贡献</h1><p id="3e96" class="pw-post-body-paragraph io ip hi iq b ir li it iu iv lj ix iy iz lk jb jc jd ll jf jg jh lm jj jk jl hb bi translated">一旦玩家实现了他们的目标，如何公平地分配荣誉？2012年，劳埃德·沙普利凭借其提出的名为“沙普利价值法”的解决方案获得了诺贝尔经济学奖。<em class="kd">Shapley值给每个玩家分配一个玩家对每个可能联盟的边际贡献的加权平均值，权重由联盟形式的概率给出。</em></p><p id="a5d6" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">让我们一步一步来看这个方法:</p><ol class=""><li id="6f94" class="lo lp hi iq b ir is iv iw iz lq jd lr jh ls jl lt lu lv lw bi translated">修正一个玩家<br/> 1.1。考虑一个不包含固定玩家的联盟。计算该联盟的结果和通过将固定玩家添加到所考虑的联盟<br/> 1.2而形成的新联盟的结果。根据Shapley值公式<br/> 1.3计算该考虑联盟的权重。对所有可能的联盟(不包含固定玩家)重复该过程<br/> 1.4固定玩家的Shapley值是计算的边际贡献的加权平均值</li><li id="1eac" class="lo lp hi iq b ir lx iv ly iz lz jd ma jh mb jl lt lu lv lw bi translated">对所有玩家重复上述步骤</li></ol><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es mc"><img src="../Images/6ddfc4ce4e044f71d969c74d95a66d99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YXPBW8OFpxhefXGzuli4lA.jpeg"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">来自<a class="ae kc" href="http://Making Sense of Shapley Values" rel="noopener ugc nofollow" target="_blank">的完整Shapley值公式，由<a class="md me ge" href="https://medium.com/u/fb156392bae9?source=post_page-----1e8d83ba6be4--------------------------------" rel="noopener" target="_blank"> Marko Cotra </a>解释Shapley值</a></figcaption></figure><p id="bcb4" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">如果你需要更多Shapely价值观的意义，你可以阅读美丽的“<a class="ae kc" href="https://towardsdatascience.com/making-sense-of-shapley-values-dc67a8e4c5e8" rel="noopener" target="_blank">Shapley价值观的意义</a>”或查看此视频:<a class="ae kc" href="https://youtu.be/-PGAF-XO-PA" rel="noopener ugc nofollow" target="_blank"> Shapley价值观成本分配方法</a>。</p><h1 id="5f63" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">从沙普利到沙普</h1><p id="c5e0" class="pw-post-body-paragraph io ip hi iq b ir li it iu iv lj ix iy iz lk jb jc jd ll jf jg jh lm jj jk jl hb bi translated">Shapley方法需要大量的计算，这取决于玩家的数量。正如我们最初所说的，</p><blockquote class="ke kf kg"><p id="3626" class="io ip kd iq b ir is it iu iv iw ix iy kh ja jb jc ki je jf jg kj ji jj jk jl hb bi translated">在计算机视觉环境中，输入图像中的每个像素都是玩家。</p><p id="16ae" class="io ip kd iq b ir is it iu iv iw ix iy kh ja jb jc ki je jf jg kj ji jj jk jl hb bi translated">例如，对于分辨率为64x64像素的简单图像，我们应该为每个玩家尝试2⁴⁰⁹⁶ (4096是64*64的结果)可能的联盟。</p></blockquote><p id="4892" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">对于他们中的每一个人，我们应该让网络做一个预测。不可能产生所有这些计算，因此，不可能精确地计算出Shapley值。</p><p id="b5ac" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">正因如此，斯科特·m·伦德伯格(Scott M. Lundberg)等人在2017年引入了<strong class="iq hs">SH</strong>apley<strong class="iq hs">A</strong>additive ex<strong class="iq hs">P</strong>lanation(<strong class="iq hs">SHAP</strong>)，这是一个包括几种解释方法的框架，用于计算沙普利值近似值。</p><p id="1686" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">我们分析了四种SHAP方法:</p><p id="1982" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><strong class="iq hs"> Shapley Samplings: </strong>该算法对所有可能的联盟中的一些进行采样，并仅计算它们的贡献。当提供足够的样本时，该方法产生收敛到精确Shapley值的无偏近似。</p><p id="24bf" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><strong class="iq hs">深度近似Shapley传播(DASP): </strong>这里，Shapley值是通过采样过程近似的；它不同于Shapley采样，因为可能的联盟根据它们的大小被分成不同的类。然后，对于每个特性，我们只考虑每个类的一个，而不是考虑它所有可能的联合。</p><p id="3a13" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><strong class="iq hs"> KernelSHAP: </strong> <em class="kd">是</em> <strong class="iq hs"> SHAP </strong>和另一个叫做<strong class="iq hs">局部可解释模型不可知解释(LIME) </strong>的算法的组合。LIME是一种解释方法，不是专门为某个特定算法设计的，它可以应用于任何ML模型(模型不可知)。名字中的“局部解释”表明，这种方法与本文中介绍的所有其他方法一样，不直接解释模型，而是解释其预测。为了做到这一点，它使用线性模型(不太强大，但更容易理解)。<em class="kd">在特定假设和特定选择的LIME公式下，LIME返回的值产生Shapley值的近似值，作为最小二乘问题的解决方案</em>。因此，这种解释方法包含在SHAP框架中。</p><p id="613b" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated"><strong class="iq hs"> DeepSHAP: </strong> <em class="kd">是</em> <strong class="iq hs"> SHAP </strong>和<strong class="iq hs"> DeepLIFT </strong>的组合。这种方法的基本思想是，如果输入发生变化，预测会如何变化。特别是，通过遮挡(设置为0)输入要素值来更改输入。该算法为每个特征分配一个分数，因此所有这些分数的总和等于预测值与基线预测值之间的差值。基线是黑色图像。<em class="kd">该方法包含在SHAP框架中，因为在特定的假设条件下，使用DeepLIFT方法计算的分数提供了Shapley值的近似值</em>。</p><p id="447b" class="pw-post-body-paragraph io ip hi iq b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl hb bi translated">在下一篇文章中，我们将研究这些方法的可靠性(健全性检查)，并从计算成本和正确近似的角度评估产生的结果。</p></div></div>    
</body>
</html>