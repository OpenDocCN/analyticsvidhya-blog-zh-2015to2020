<html>
<head>
<title>All About Apache Kafka</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于阿帕奇卡夫卡的一切</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/all-about-apache-kafka-67819094a1b2?source=collection_archive---------17-----------------------#2019-12-11">https://medium.com/analytics-vidhya/all-about-apache-kafka-67819094a1b2?source=collection_archive---------17-----------------------#2019-12-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c337" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">什么是阿帕奇卡夫卡？</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/30d3155b98731689656ef9c868271fd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OstRGnyPUZ_0WzYQB0mI4w.png"/></div></div></figure><p id="f3b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kafka是一个开源的流处理平台，用于构建实时数据管道。我们也称之为高吞吐量分布式消息服务。它也被称为“分布式提交日志”。</p><p id="4bde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">阿帕奇卡夫卡的一些特征是</p><ol class=""><li id="2c42" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated">它是水平可扩展的，即如果需要，可以增加代理的数量来处理负载。</li><li id="959d" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">它是容错的，即系统/集群可以像代理一样承受一定数量组件的不可用性。</li><li id="86f2" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">它具有非常高的吞吐量，即可以同时处理大量的消息。</li><li id="3e91" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">它可以以非常低的延迟处理数据，即实时工作</li><li id="ee05" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">已经被很多大公司使用，比如LinkedIn、优步、VMware，还有很多其他公司。</li><li id="3586" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">可用于<a class="ae kd" href="https://martinfowler.com/eaaDev/EventSourcing.html" rel="noopener ugc nofollow" target="_blank">事件源</a></li></ol><h2 id="e02c" class="ke kf hi bd kg kh ki kj kk kl km kn ko iq kp kq kr iu ks kt ku iy kv kw kx ky bi translated"><strong class="ak">历史</strong></h2><p id="b96f" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">Apache Kafka是LinkedIn开发的。它于2011年初开源。它是以弗朗兹·卡夫卡命名的。卡夫卡的名字来源于Kafkaesque，意思是噩梦般的情况。因为LinkedIn开发者对如此多的数据和基础设施也有类似的感觉。因此，他们给了“卡夫卡”这个名字，这是非常贴切的。</p><h2 id="c652" class="ke kf hi bd kg kh ki kj kk kl km kn ko iq kp kq kr iu ks kt ku iy kv kw kx ky bi translated">它与传统系统有何不同？</h2><p id="10d8" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">传统系统处理大量数据的方式有很多</p><ol class=""><li id="8fbd" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated">原木运输</li><li id="9d41" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">ETL过程(提取、转换和加载)</li><li id="eee8" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">消息传递(传统方法)</li><li id="e5d1" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">数据库层的复制</li></ol><p id="d64b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然有几种方法，但没有一种像卡夫卡那样有效。所有这些系统都有一定的缺陷。</p><ol class=""><li id="6b7a" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated">日志传送和数据库复制:非常特定于数据库。跨数据库使用非常困难。日志传送传输速率、传输大小会对性能产生一些影响。它高度依赖于数据库模式。如果源数据库中的模式发生变化，需要在我们希望进行复制的所有数据库中修改新的模式。</li><li id="e8d7" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">ETL方法:执行ETL需要领域知识。工具也非常昂贵。</li><li id="9217" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">消息传递:大多数消息传递系统不是分布式的。因此，处理规模非常困难。许多传统的消息传递系统缺乏容错能力。消息大小和消费者行为(尤其是他们消费的速度)可能会影响整个系统。</li><li id="bd5c" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">中间件的使用:很难创建。根据新的需求对中间件进行更改可能会很乏味。难以管理和保持一致性。</li></ol><h1 id="e9f6" class="le kf hi bd kg lf lg lh kk li lj lk ko ll lm ln kr lo lp lq ku lr ls lt kx lu bi translated">体系结构</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lv"><img src="../Images/f54b73d382ed8b3bf41f4d9c11165062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jG6OuJu5JOVkFoqkihY_OA.jpeg"/></div></div></figure><p id="9e8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是Apache Kafka的架构，它作为一个信息系统工作。让我们看看阿帕奇卡夫卡的不同组成部分</p><ol class=""><li id="a464" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated">代理:它是处理读写操作的组件。它在执行任务时是高效和优化的。一个代理每秒可以处理数百万次读/写操作。它可以处理数TB的数据，而不会有任何性能损失。代理是短暂的，所以所有与quorum相关的信息和集群细节都使用ZooKeeper保存。我们可以在设置中有任意数量的代理。因此，很容易实现缩放。</li><li id="6055" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">控制者:在所有经纪人中选择一个作为控制者。这一决定是基于它们的性能、它们所具有的负载、活跃性和几个其他因素做出的。它的职责是监控其他经纪人的可用性，可以交给他们完成某项任务。它还维护需要由其他代理处理的任务相关信息。它还不断检查其他经纪人的进展。当分配工作时，它会要求其他代理创建一个法定人数。作为领导者，成功创造法定人数的经纪人得到工作。然后，领导者与其追随者(在该领导者下工作的对等体)一起执行复制任务，以处理故障场景。</li><li id="478f" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">ZooKeeper:它也是一个分布式服务，用于维护一个分布式节点集群的元数据。它还负责帮助卡夫卡的领袖选举。它还有助于维护系统启动时(即引导时)所需的配置信息。它有助于维护分布式系统的健康状态。它维护分布式系统中节点的组成员资格，例如kafka集群中的代理成员资格。</li><li id="b880" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">生产者:是生成消息的应用程序。它将消息传递给代理。可以有多个生产者同时工作。生产者完全不了解消费者。这使得卡夫卡“松散耦合”。</li><li id="673f" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">消费者:应用程序从代理获取消息并处理该消息。可以有多个消费者同时工作。它不知道生成消息的生产者。它维护偏移量来标记已经被处理的消息。</li></ol><h1 id="4dda" class="le kf hi bd kg lf lg lh kk li lj lk ko ll lm ln kr lo lp lq ku lr ls lt kx lu bi translated">装置</h1><p id="449f" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们将在ubuntu机器上看到Kafka的安装。可以参考apache kafka提供的文档进行安装。</p><ol class=""><li id="ecea" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated">获取二进制文件</li></ol><pre class="je jf jg jh fd lw lx ly lz aw ma bi"><span id="74c2" class="ke kf hi lx b fi mb mc l md me">wget http://mirrors.estointernet.in/apache/kafka/2.3.0/kafka_2.12-2.3.0.tgz</span></pre><p id="d293" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.提取文件</p><pre class="je jf jg jh fd lw lx ly lz aw ma bi"><span id="325e" class="ke kf hi lx b fi mb mc l md me">tar -xvf kafka_2.12-2.3.0.tgz</span></pre><p id="c226" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<strong class="ih hj"> lib </strong>目录中，kafka维护了所有它需要的库。在那个目录中，它还保存了zookeeper jar。所以，我们不需要单独安装zookeeper。它是独立的。</p><p id="f2b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<strong class="ih hj"> config </strong>目录下，保存了所有的配置文件。<code class="du mf mg mh lx b">server.properties</code>用于维护代理配置，<code class="du mf mg mh lx b">zookeeper.properties</code>用于维护zookeeper配置，还有其他几个配置文件。</p><p id="5f43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<strong class="ih hj"> bin </strong>文件夹中，保存了使用kafka所需的所有脚本，如<code class="du mf mg mh lx b">kafka-server-start.sh</code>启动Kafka服务器、<code class="du mf mg mh lx b">kafka-topics.sh</code>进行主题级配置等。</p><p id="f20f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.启动动物园管理员</p><pre class="je jf jg jh fd lw lx ly lz aw ma bi"><span id="0757" class="ke kf hi lx b fi mb mc l md me">bin/zookeeper-server-start.sh config/zookeeper.properties</span></pre><p id="2333" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.启动卡夫卡</p><pre class="je jf jg jh fd lw lx ly lz aw ma bi"><span id="1979" class="ke kf hi lx b fi mb mc l md me">bin/kafka-server-start.sh config/server.properties</span></pre><blockquote class="mi mj mk"><p id="0cb9" class="if ig ml ih b ii ij ik il im in io ip mm ir is it mn iv iw ix mo iz ja jb jc hb bi translated">如果想在Kubernetes上部署Apache Kafka，请访问此链接<a class="ae kd" rel="noopener" href="/@aishwarymuz/apache-kafka-deployment-on-kubernetes-5695aca260f"><strong class="ih hj">https://medium . com/@ aishwarymuz/Apache-Kafka-deployment-on-Kubernetes-5695 ACA 260 f</strong></a></p></blockquote><h1 id="0991" class="le kf hi bd kg lf lg lh kk li lj lk ko ll lm ln kr lo lp lq ku lr ls lt kx lu bi translated">卡夫卡主题</h1><p id="08fa" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">卡夫卡的主题就像一个邮政地址，所有的信息都将被传递到那里，感兴趣的人将从那里获得信息。它是一个逻辑实体，用于对消息进行分类。它是一种队列类型的数据结构。我们可以在Kafka集群上定义许多主题，每个主题代表并保存特定类型的消息。</p><p id="ac5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个主题也可以跨越多个卡夫卡经纪人。及时存储在kafka topic中的所有记录/消息都是不可变的，即主题本质上是仅附加的。主题中的消息有一个全局排序。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mp"><img src="../Images/7c61d09307218237f1844380ac4e0fe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*bXiA3Fe6KrMyQiXwIm7HSA.jpeg"/></div></div><figcaption class="mq mr et er es ms mt bd b be z dx translated">卡夫卡的主题</figcaption></figure><p id="1319" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上图中，T0是id #1的消息到达的时间。过了一段时间x，id为#2的消息来了，以此类推。生产者继续在主题中推送消息，消费者从主题中获取消息。消费者维护一个指针(称为Offset ),帮助它处理新到达的消息。可能有许多生产者和消费者在同一主题上工作。</p><p id="7b1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">主题中的每条消息都有三个内容</p><ol class=""><li id="8a8a" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated">标识号(Id)</li><li id="63bf" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">时间戳:消息到达的时间</li><li id="e4fc" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">实际消息内容</li></ol><p id="2918" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个主题只能由一个消费者组中的一个消费者访问。来自其他消费者群体的消费者可以同时访问相同的主题。他们将保持他们自己的补偿，该补偿可能不同于属于不同消费者群体的任何其他消费者。</p><h2 id="6544" class="ke kf hi bd kg kh ki kj kk kl km kn ko iq kp kq kr iu ks kt ku iy kv kw kx ky bi translated">主题的划分</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mu"><img src="../Images/93d15ea027c5eed2b219a2885347146f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*V0wccb6xWyNfRLe3OCpf0g.jpeg"/></div></figure><p id="417b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在kafka系统中创建的任何主题都至少有一个分区，即分区的默认数量是1。为了实现并行性和更好的吞吐量，我们可以增加任何主题的分区数量。在物理上，主题的每个分区都以日志文件的形式出现在kafka代理上，主题就出现在这个代理上。然而，分区有其自身的成本。在为一个主题创建了多个分区之后，没有保留全局排序。分区也给zookeeper增加了负担。我们为主题创建的分区越多，领导者选举的故障转移时间就越长。</p><p id="da80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了控制任何主题的分区数量，我们可以在<code class="du mf mg mh lx b">config/server.properties</code>文件中设置<code class="du mf mg mh lx b">num.partitions</code>的值，即代理配置。默认值为1。我们还可以改变已经创建的主题的分区数量。为了应用这些改变，我们需要使用<code class="du mf mg mh lx b">bin/kafka-topics.sh</code>脚本。</p><pre class="je jf jg jh fd lw lx ly lz aw ma bi"><span id="b0f4" class="ke kf hi lx b fi mb mc l md me">bin/kafka-topics.sh --zookeeper &lt;Zookeeper_URI&gt; --alter --topic &lt;Topic_Name&gt; --partitions 10</span></pre><p id="9605" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">卡夫卡是如何处理分区的？</strong></p><p id="5c50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们请求创建一个具有一定数量分区的主题时，比如说3个分区，需要执行一系列步骤</p><ol class=""><li id="b664" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated">Zookeeper检查kafka代理的状态，如健康、负载等。对于每个分区，zookeeper决定应该选择哪个代理作为领导者。</li><li id="9cf5" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">然后zookeeper将分区分配给这些代理。</li><li id="50e0" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">然后，这些代理在其文件系统中创建各自的日志目录。目录的格式类似于{主题名称}-{分区}。例如，如果主题名称是ABC，并且配置了三个分区，我们将得到类似于<code class="du mf mg mh lx b"><strong class="ih hj">/path_to_log_directory/ABC-0</strong></code> <strong class="ih hj">、</strong> <code class="du mf mg mh lx b"><strong class="ih hj">/path_to_log_directory/ABC-1</strong></code> <strong class="ih hj">和</strong> <code class="du mf mg mh lx b"><strong class="ih hj">/path_to_log_directory/ABC-2</strong></code> <strong class="ih hj">的目录。</strong></li><li id="6dfd" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">然后，每个代理维护关于分区位置的信息，即哪个分区在哪个代理上。同样的信息也出现在Zookeeper中。当生产者在一些分区上执行一些操作，但是他所联系的代理不是领导者时，这是有帮助的。在这种情况下，代理将返回元数据，帮助生产者联系维护该分区领导者的正确代理。</li><li id="c0cb" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">然后，代理将状态发送回动物园管理员。这有助于将一致意见保持在适当的状态。</li></ol><h2 id="90e6" class="ke kf hi bd kg kh ki kj kk kl km kn ko iq kp kq kr iu ks kt ku iy kv kw kx ky bi translated">实现容错</h2><p id="5581" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">为了实现容错，我们为主题的每个分区创建多个副本。我们维护的副本数量被称为<strong class="ih hj">复制因子</strong>。<strong class="ih hj"> </strong>在任何给定时间，我们都可以通过检查ISR(同步副本)来检查任何主题的复制状态。在所有复制品中，选择一个作为领导者。该主副本负责处理所有读/写操作。如果由于网络故障、代理不可用或任何其他原因，该主副本在任何特定时间不可用，则其他副本将被提升为主副本。复制因子保证N-1代理容错。</p><p id="1a18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">领导者的工作是选择对等体，并为复制日志和实现所需的复制因子(即冗余级别)创建法定人数。当ISR与复制因子匹配时，我们认为主题及其分区是健康的。如果由于某种原因无法创建法定人数，并且ISR低于所需值，我们需要手动解决该问题并检查该问题。</p><blockquote class="mi mj mk"><p id="aed2" class="if ig ml ih b ii ij ik il im in io ip mm ir is it mn iv iw ix mo iz ja jb jc hb bi translated">注意:如果我们有许多代理，而ISR少于预期，Kafka将尝试添加一些其他代理来代替失败的代理，并开始将日志复制到这个新选择的代理中。</p></blockquote><p id="6693" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了控制复制因子，我们可以在<code class="du mf mg mh lx b">config/server.properties</code>文件中设置<code class="du mf mg mh lx b">default.replication.factor</code>的值，即代理配置。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/cea519e85bd642e36baf09d32aea649b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*YZb0VGk4H-i_ktsC9K13zA.jpeg"/></div><figcaption class="mq mr et er es ms mt bd b be z dx translated">卡夫卡中一个主题的分割与复制</figcaption></figure><h2 id="915e" class="ke kf hi bd kg kh ki kj kk kl km kn ko iq kp kq kr iu ks kt ku iy kv kw kx ky bi translated">kafka如何处理数据保留？</h2><p id="c116" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">正如我上面提到的，对于一个主题的每个分区，都有一个保存数据的日志文件。该日志文件位于该分区所在的同一个代理上。主题的每个日志文件被进一步划分为一个段文件。这些片段只不过是信息的集合。这些段文件将数据作为键和值保存。保留是在分段级别/主题级别而不是消息级别提供的。Kafka提供了两种类型的保留策略</p><ol class=""><li id="6472" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated">基于时间的保留策略</li><li id="0f2e" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">基于大小的保留策略</li></ol><p id="4387" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在基于时间的保留策略中，Kafka定期清理主题范围内的旧内容。我们将在下一节中看到清理操作的类型。它是通过在server.properties中使用<code class="du mf mg mh lx b">log.retention.ms</code>指定的，该选项的默认值是7天。</p><p id="a966" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们也可以在稍后的时间点按主题级别指定它。参见下面的命令</p><pre class="je jf jg jh fd lw lx ly lz aw ma bi"><span id="75b3" class="ke kf hi lx b fi mb mc l md me">./bin/kafka-topics.sh --zookeeper &lt;ZooKeeper_Endpoint&gt; --alter --topic &lt;Topic_Name&gt; --config retention.ms=&lt;Time_In_Millis&gt;</span></pre><p id="258f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在基于大小的保留策略中，Kafka检查保存数据的日志文件的大小。如果大小超过配置中指定的值，Kafka将开始清除文件中的内容，直到其大小低于指定的值。在server.properties中使用<code class="du mf mg mh lx b">log.retention.bytes</code>来指定，默认情况下对此没有限制。</p><p id="1bd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们也可以在稍后的时间点按主题级别指定它。参见下面的命令</p><pre class="je jf jg jh fd lw lx ly lz aw ma bi"><span id="7c5f" class="ke kf hi lx b fi mb mc l md me">./bin/kafka-topics.sh --zookeeper &lt;ZooKeeper_Endpoint&gt; --alter --topic &lt;Topic_Name&gt; --config retention.bytes=&lt;Time_In_Millis&gt;</span></pre><p id="f2e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">清理是如何进行的？</strong></p><p id="4cfd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然在Kafka中，我们可以保留大量数据，但在某个时间点之后，我们需要执行清理，因为Kafka并不意味着消息会持续很长时间。对于更长时间的消息持久性，我们通常使用数据库。卡夫卡提供了两种类型清理操作</p><ol class=""><li id="bd33" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated"><strong class="ih hj">删除</strong> : Kafka broker将在考虑保留策略后删除消息。<code class="du mf mg mh lx b">log.retention.ms</code>和<code class="du mf mg mh lx b">log.retention.bytes</code>是主要的决定因素。</li><li id="2236" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated"><strong class="ih hj">压缩:</strong> Kafka broker将保留任何消息的单一和最新副本。因为消息有一个键和值。当消息再次出现在日志中时，密钥再次相同。因此，在后台会有一个清理线程一直运行，执行这种压缩。它主要用于当我们想要获得Kafka系统在崩溃/失败之前的最后状态时，在应用程序重启后重新加载缓存。我们进行活动采购时也会用到它。我们需要了解几个重要的配置选项，例如</li></ol><p id="4ac2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a.<code class="du mf mg mh lx b"><strong class="ih hj"><em class="ml">cleanup.policy=compact</em></strong></code> <strong class="ih hj"> <em class="ml"> </em> </strong>启用日志压缩</p><p id="88d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b.<code class="du mf mg mh lx b"><strong class="ih hj"><em class="ml">delete.retention.ms</em></strong></code> <strong class="ih hj"> <em class="ml"> </em> </strong>在消费者到达主题标题之前，消费者可以看到逻辑删除(标记为删除的消息)的持续时间。只有当清理政策是<code class="du mf mg mh lx b">compact</code>时才有意义。</p><p id="2a66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">c.<code class="du mf mg mh lx b"><strong class="ih hj"><em class="ml">log.cleaner.threads</em></strong></code> <strong class="ih hj"> <em class="ml"> </em> </strong>它决定了将要执行清理操作的线程数量。清理线程使用日志文件的脏比率来决定首先处理哪个日志文件。</p><pre class="je jf jg jh fd lw lx ly lz aw ma bi"><span id="9610" class="ke kf hi lx b fi mb mc l md me">dirty ratio = number of bytes in the head / total number of bytes in the log(tail + head)</span></pre><p id="2628" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">d.<code class="du mf mg mh lx b"><strong class="ih hj"><em class="ml">log.cleaner.min.compaction.lag.ms</em></strong></code> <em class="ml"> </em>用于保证在消息被压缩之前必须经过的最短时间。</p><blockquote class="mi mj mk"><p id="d692" class="if ig ml ih b ii ij ik il im in io ip mm ir is it mn iv iw ix mo iz ja jb jc hb bi translated">要了解更多关于阿帕奇卡夫卡压缩的内容，请访问此链接:<a class="ae kd" href="https://kafka.apache.org/documentation/#compaction" rel="noopener ugc nofollow" target="_blank">https://kafka.apache.org/documentation/#compaction</a></p><p id="a7a5" class="if ig ml ih b ii ij ik il im in io ip mm ir is it mn iv iw ix mo iz ja jb jc hb bi translated"><a class="ae kd" href="https://towardsdatascience.com/log-compacted-topics-in-apache-kafka-b1aa1e4665a7" rel="noopener" target="_blank">https://towards data science . com/log-compacted-topics-in-Apache-Kafka-B1 aa1e 4665 a 7</a></p></blockquote><h2 id="ac2f" class="ke kf hi bd kg kh ki kj kk kl km kn ko iq kp kq kr iu ks kt ku iy kv kw kx ky bi translated">要了解更多关于生产者，请访问此链接</h2><p id="c732" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated"><a class="ae kd" rel="noopener" href="/@aishwarymuz/all-about-apache-kafka-710ee1f0b395">https://medium . com/@ aishwarymuz/all-about-Apache-Kafka-710 E1 f0b 395</a></p><h2 id="0402" class="ke kf hi bd kg kh ki kj kk kl km kn ko iq kp kq kr iu ks kt ku iy kv kw kx ky bi translated">注意:如果您发现有任何遗漏或错误，请告诉我。</h2><p id="9448" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated"><strong class="ih hj">其他一些好文章:<br/></strong><a class="ae kd" href="https://aws.amazon.com/blogs/big-data/best-practices-for-running-apache-kafka-on-aws/" rel="noopener ugc nofollow" target="_blank">https://AWS . Amazon . com/blogs/big-data/best-practices-for-running-Apache-Kafka-on-AWS/</a></p></div></div>    
</body>
</html>