<html>
<head>
<title>Deep Learning: Image segmentation and localization — U-Net Architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习:图像分割和定位——U-Net架构</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-image-segmentation-and-localization-u-net-architecture-ea4cff5595d9?source=collection_archive---------4-----------------------#2019-12-30">https://medium.com/analytics-vidhya/deep-learning-image-segmentation-and-localization-u-net-architecture-ea4cff5595d9?source=collection_archive---------4-----------------------#2019-12-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="150a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"> 1。简介</strong></h1><p id="f2c1" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj">人工智能(AI) </strong>一直是媒体激烈炒作的主题。机器学习、深度学习和人工智能出现在无数的文章中，通常是在技术型出版物之外。在过去的两年中，深度卷积网络在许多视觉识别任务中已经超越了最先进的技术。</p><p id="7d8f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">但是你注意到这些视觉识别任务的复杂性了吗？不太容易。</p><p id="7c54" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">卷积网络(CNN)的出现使得研究取得了前所未有的进展。使用CNN，我们可以将一幅图像分类，归属于它自己的类别。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/b322185b5ba39d83e377fe4ee00ce128.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*qFCvBYgYQn37vilPJAb33A.png"/></div></figure><p id="b9f9" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">卷积网络通常用于分类任务，其中图像的输出是单个类别标签。然而，在许多视觉任务中，特别是在图像处理中，期望的输出应该包括定位，即应该为每个像素分配一个类别标签。</p><p id="0ed7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">因此，我们需要一个CNN网络，它可以通过在输入中的像素周围提供一个局部区域(小块)来预测每个像素的类别标签。这被称为检测图像中的对象并预测其像素周围的类别标签。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/8c2024804f646b5b131d3efa74473300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*s0sliq_LN9a9PxSFEa6bSg.png"/></div></figure><p id="2689" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">卷积神经网络在较简单的图像分割问题上给出了不错的结果，但在复杂的图像分割问题上没有取得任何进展。这就是U-Net出现的原因。U-Net最初是专门为医学图像分割而设计的。它显示出如此好的效果，以至于后来它被用于许多其他领域。</p><h1 id="c100" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">2.U-net架构(看起来像U)</h1><p id="1c0a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了预测同一图像上的类别，我们将使用语义分割的概念，其中我们对图像进行逐像素分类。我们可以认为语义分割是像素级的图像分类。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="er es ko"><img src="../Images/1879fd46db9ce76b06e9b8aeb1c8d377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R8dRyYGzDtnrg6wEOyRHXg.png"/></div></div></figure><p id="99a8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">该架构由两部分组成:</p><blockquote class="kt ku kv"><p id="63fb" class="jd je kw jf b jg kb ji jj jk kc jm jn kx kd jq jr ky ke ju jv kz kf jy jz ka hb bi translated">收缩/下采样层(左侧)</p><p id="5626" class="jd je kw jf b jg kb ji jj jk kc jm jn kx kd jq jr ky ke ju jv kz kf jy jz ka hb bi translated">扩展/上采样层(右侧)</p><p id="ada8" class="jd je kw jf b jg kb ji jj jk kc jm jn kx kd jq jr ky ke ju jv kz kf jy jz ka hb bi translated">输出层</p></blockquote><h2 id="37bb" class="la ig hi bd ih lb lc ld il le lf lg ip jo lh li it js lj lk ix jw ll lm jb ln bi translated">收缩/下采样层</h2><p id="aab4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">收缩路径遵循卷积网络的典型架构。它由两个3×3卷积(无填充卷积)的重复应用组成，每个卷积后跟一个整流线性单元(ReLU)和一个2×2最大池操作，步长为2，用于下采样。</p><p id="9a82" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在每个下采样步骤中，我们将特征通道的数量增加一倍。</p><p id="277d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">该收缩路径的目的是捕获输入图像的上下文，以便能够进行分割。</p><p id="098b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">以下是收缩层的keras代码:</p><p id="f0a6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">#签约层数:</strong></p><p id="34aa" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">取初始核大小为8，在下一个收缩层加倍。我们可以添加多个收缩层来获得更好的功能。</strong></p><blockquote class="lo"><p id="e0c5" class="lp lq hi bd lr ls lt lu lv lw lx ka dx translated">第1层:收缩层</p></blockquote><pre class="ly lz ma mb mc md me mf mg aw mh bi"><span id="dd6d" class="la ig hi me b fi mi mj l mk ml"><strong class="me hj">c1 = Conv2D(8, (3, 3), padding=’same’ (inputs)</strong></span><span id="edf9" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">c1 = Activation(‘relu’) (c1)</strong></span><span id="746c" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">c1 = Conv2D(8, (3, 3), padding=’same’ (c1)</strong></span><span id="3f81" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">c1 = Activation(‘relu’) (c1)</strong></span><span id="03ae" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">p1 = MaxPooling2D((2, 2)) (c1)</strong></span></pre><blockquote class="lo"><p id="2594" class="lp lq hi bd lr ls mn mo mp mq mr ka dx translated">第2层:收缩层</p></blockquote><pre class="ly lz ma mb mc md me mf mg aw mh bi"><span id="728a" class="la ig hi me b fi mi mj l mk ml"><strong class="me hj">c2 = Conv2D(16, (3, 3), padding=’same’ (p1)</strong></span><span id="393d" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">c2 = Activation(‘relu’) (c2)</strong></span><span id="6558" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">c2 = Conv2D(16, (3, 3), padding=’same’ (c2)</strong></span><span id="aa1e" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">c2 = Activation(‘relu’) (c2)</strong></span><span id="7902" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">p2 = MaxPooling2D((2, 2)) (c2)</strong></span></pre><blockquote class="lo"><p id="0bc8" class="lp lq hi bd lr ls mn mo mp mq mr ka dx translated">第三层:收缩层</p></blockquote><pre class="ly lz ma mb mc md me mf mg aw mh bi"><span id="2ba3" class="la ig hi me b fi mi mj l mk ml"><strong class="me hj">c3 = Conv2D(32, (3, 3), padding=’same’ (p2)</strong></span><span id="81c0" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">c3 = Activation(‘relu’) (c3)</strong></span><span id="28ec" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">c3 = Conv2D(32, (3, 3), padding=’same’ (c3)</strong></span><span id="121e" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">c3 = Activation(‘relu’) (c3)</strong></span><span id="1c30" class="la ig hi me b fi mm mj l mk ml"><strong class="me hj">p3 = MaxPooling2D((2, 2)) (c3)</strong></span></pre><p id="4229" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">下采样会发生什么？</strong></p><p id="b280" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">该路径用于通过在每个阶段加倍过滤器的数量来获得图像的更多特征。</p><p id="04a5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在进入下一阶段时，我们将进行2x2 max-pooling以获得最大像素值，因此失去了一些功能，但保留了最大像素值。</p><p id="257a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">所以在下采样的最后一层，我们得到了图像的低级特征。</p><p id="0d1a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">假设，一个图像有两个类别，猫和狗，这些类别通过分配像素值反映在像素中。</p><p id="72a0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">例如，我们正在按像素方式进行类别分割:</p><p id="3c03" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">类别CAT-图层上的像素值要素-135</p><p id="4757" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">图层上的类狗-像素值要素-150</p><p id="f871" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">对于无缺陷像素值为0。</p><p id="7bfb" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">通过这种方式，我们可以按像素进行分类，也可以对类别进行分段。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ms"><img src="../Images/2e24e0dc4d2ecc8fd947f9b0b07fbe6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*h8AqZQxCNV0yBAGkAx1oZg.png"/></div></figure><h2 id="ad92" class="la ig hi bd ih lb lc ld il le lf lg ip jo lh li it js lj lk ix jw ll lm jb ln bi translated">扩展/上采样层</h2><p id="808f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">类似于收缩层，也是由几个膨胀块组成。扩展路径中的每一步都包括特征图的上采样，随后是将特征通道数量减半的2×2卷积(上卷积)，与收缩路径中相应裁剪的特征图的连接，以及两个3×3卷积，每个卷积之后是ReLU。</p><p id="05f0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">该扩展路径的目的是实现与来自收缩路径的上下文信息相结合的精确定位。</p><p id="f36b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">以下是扩展层的keras代码:</p><p id="23f9" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">#扩展层:</strong></p><p id="4276" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">取初始籽粒大小为8。</strong></p><blockquote class="lo"><p id="99c4" class="lp lq hi bd lr ls lt lu lv lw lx ka dx translated">第1层:膨胀层</p></blockquote><pre class="ly lz ma mb mc md me mf mg aw mh bi"><span id="ca6c" class="la ig hi me b fi mi mj l mk ml">u4 = Conv2DTranspose(32, (2, 2),strides=(2, 2), padding=’same’) (c3)</span><span id="0eb6" class="la ig hi me b fi mm mj l mk ml">u4 = concatenate([u4, c3])</span><span id="2695" class="la ig hi me b fi mm mj l mk ml">c4 = Conv2D(32, (3, 3), padding=’same’) (u4)</span><span id="22bb" class="la ig hi me b fi mm mj l mk ml">c4 = Activation(‘relu’) (c4)</span><span id="b7f4" class="la ig hi me b fi mm mj l mk ml">c4 = Conv2D(32, (3, 3), padding=’same’) (c4)</span><span id="537d" class="la ig hi me b fi mm mj l mk ml">c4 = Activation(‘relu’) (c4)</span></pre><blockquote class="lo"><p id="e66a" class="lp lq hi bd lr ls mn mo mp mq mr ka dx translated">第2层:膨胀层</p></blockquote><pre class="ly lz ma mb mc md me mf mg aw mh bi"><span id="b3dc" class="la ig hi me b fi mi mj l mk ml">u5 = Conv2DTranspose(16, (2, 2),strides=(2, 2), padding=’same’) (c4)</span><span id="f92e" class="la ig hi me b fi mm mj l mk ml">u5 = concatenate([u5, c2])</span><span id="afb3" class="la ig hi me b fi mm mj l mk ml">c5 = Conv2D(16, (3, 3), padding=’same’) (u5)</span><span id="2ff0" class="la ig hi me b fi mm mj l mk ml">c5 = Activation(‘relu’) (c5)</span><span id="f37b" class="la ig hi me b fi mm mj l mk ml">c5 = Conv2D(16, (3, 3), padding=’same’) (c5)</span><span id="596d" class="la ig hi me b fi mm mj l mk ml">c5 = Activation(‘relu’) (c5)</span></pre><blockquote class="lo"><p id="688d" class="lp lq hi bd lr ls mn mo mp mq mr ka dx translated">第三层:膨胀层</p></blockquote><pre class="ly lz ma mb mc md me mf mg aw mh bi"><span id="8743" class="la ig hi me b fi mi mj l mk ml">u6 = Conv2DTranspose(8, (2, 2),strides=(2, 2), padding=’same’) (c5)</span><span id="0a6e" class="la ig hi me b fi mm mj l mk ml">u6 = concatenate([u6, c1])</span><span id="acf2" class="la ig hi me b fi mm mj l mk ml">c6 = Conv2D(8, (3, 3), padding=’same’) (u6)</span><span id="3acc" class="la ig hi me b fi mm mj l mk ml">c6 = Activation(‘relu’) (c6)</span><span id="510d" class="la ig hi me b fi mm mj l mk ml">c6 = Conv2D(8, (3, 3), padding=’same’) (c6)</span><span id="2bf5" class="la ig hi me b fi mm mj l mk ml">c6 = Activation(‘relu’) (c6)</span></pre><p id="2104" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">上采样发生了什么？</strong></p><p id="5f65" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们将在同一阶段进行上采样，以保持图像的相同大小。</p><p id="1eb1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">现在在下采样中，我们已经得到了所有类的像素特征值。由于使用最大池，我们失去了一些降采样的特性，所以不必担心。</p><p id="0a92" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在上采样中，我们通过将具有相同下采样滤波器的级别的特征图复制到相同上采样滤波器的级别，从而保留特征，来得到完整的图像。因此，我们得到完整的图像，并可以定位每一类图像中存在缺陷的位置。这就是所谓的转置卷积。</p><p id="164e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">然后，我们再次通过应用卷积学习全尺寸图像。</p><p id="09e6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">因此在上采样中，基本上下采样侧的每个特征层都被添加到上采样侧的相应特征层，以获得全分辨率图像，从而定位类别。</p><p id="ae14" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">整合图像的局部信息和全局信息。</p><h2 id="678b" class="la ig hi bd ih lb lc ld il le lf lg ip jo lh li it js lj lk ix jw ll lm jb ln bi translated">输出层</h2><pre class="kh ki kj kk fd md me mf mg aw mh bi"><span id="47cb" class="la ig hi me b fi mi mj l mk ml"><strong class="me hj">outputs = Conv2D(2, (1, 1), activation=’sigmoid’) (c9)</strong></span></pre><p id="be2e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在最后一层中，我们有两个与每个类相关的输出，猫和狗</p><p id="6599" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">猫- C1</p><p id="588b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">狗- C2</p><p id="a9b6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">每个类都有自己的1 X 1过滤器。</p><p id="da3b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">因此，c1过滤器将遍历每个像素地图，并预测CAT类出现的概率。</p><p id="0d16" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在理想情况下，c1=1和c2的概率为零。</p><p id="09b0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">输出图层将给出每个像素属于所有过滤器的特定类别的概率。像素属于该类别的概率越大。</p><h2 id="cdc8" class="la ig hi bd ih lb lc ld il le lf lg ip jo lh li it js lj lk ix jw ll lm jb ln bi translated">3.损失函数</h2><p id="3340" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们使用<strong class="jf hj">二元交叉熵</strong>作为损失函数，因为它将给出属于该区域的每个像素的逐像素损失或概率。</p><h1 id="a53b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">参考</h1><ol class=""><li id="4820" class="mt mu hi jf b jg jh jk jl jo mv js mw jw mx ka my mz na nb bi translated">https://arxiv.org/pdf/1505.04597.pdf<a class="ae nc" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank"/></li><li id="4132" class="mt mu hi jf b jg nd jk ne jo nf js ng jw nh ka my mz na nb bi translated">【https://www.youtube.com/watch?v=NzY5IJodjek T4】</li><li id="8dde" class="mt mu hi jf b jg nd jk ne jo nf js ng jw nh ka my mz na nb bi translated"><a class="ae nc" href="https://developers.arcgis.com/python/guide/how-unet-works/" rel="noopener ugc nofollow" target="_blank">https://developers.arcgis.com/python/guide/how-unet-works/</a></li></ol></div></div>    
</body>
</html>