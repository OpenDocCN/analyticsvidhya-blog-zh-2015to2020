<html>
<head>
<title>Split Neural Networks on PySyft</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PySyft上的分裂神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/split-neural-networks-on-pysyft-ed2abf6385c0?source=collection_archive---------2-----------------------#2019-12-21">https://medium.com/analytics-vidhya/split-neural-networks-on-pysyft-ed2abf6385c0?source=collection_archive---------2-----------------------#2019-12-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/3a980395cc79113555da9f5ef99c35d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wbb8NxbZgqwGAHvviyKozg.jpeg"/></div></div></figure><p id="e8a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">摘要:</strong>在这篇博客中，我们将介绍一种新的分散式学习方法，叫做“分裂神经网络”。我们将研究一些理论，然后深入一些代码，让我们能够在PySyft上运行它们。</p><h1 id="c2a5" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">隐私和数据产业</h1><p id="2cf9" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">从历史上看，机器学习架构建立在所有机器学习算法都将被集中的假设之上，其中训练数据和模型都在相同的位置，并且为研究人员所知。然而，越来越多的人希望将学习技术应用于数据传统上敏感或隐私的领域，如医疗保健、运营物流或金融。在医疗保健领域，这些类型的应用有能力通过增强诊断准确性和通过使用合格的临床决策支持系统增加医生对患者的时间效率来改善患者的结果。</p><p id="692b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，直到最近这种创新的道路上还存在一个障碍，<em class="kr"> </em>数据隐私<em class="kr">。</em>目前，数据所有者不可能<em class="kr">真正</em>知道他们的数据没有被出售，没有被用于他们之前不同意的事情，也没有被保留超过预期的时间。这导致了数据处理者和数据所有者之间的信任问题。当数据被收集后，充分管理其所有者的同意就更加困难了。这使得传统的、集中的行业模式不可能应用于GDPR会议后的数据实践。</p><p id="28c5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">出于这些原因，集中式学习架构要么成为创新的障碍，要么成为相关数据所有者的隐私风险。对私人数据的研究要么因隐私分歧而受阻，要么继续进行，给数据主体带来潜在的灾难性社会和政治后果。</p><p id="f116" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">科技行业仍在努力追赶我们这个时代的标志性创新之一；区块链。然而，尽管分布式账本技术将成为下一代互联网的核心，但它只是标志着系统架构更大变革的开始。离开瓶子的精灵是<strong class="is hj">去中心化</strong>。</p><p id="e6ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">采用这一原则是为了建立工具，使资源分散化和多所有者治理体现公民的隐私权和安全权。这通过以前无法获得的信息资源打开了创新之门；私人数据。处于这一转变前沿的一个社区是露天开采的。他们的私人AI工具叫做<a class="ae ks" href="https://www.openmined.org/" rel="noopener ugc nofollow" target="_blank"> PySyft </a>。</p><h1 id="0be3" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">分裂神经网络</h1><p id="e54b" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">传统上，<a class="ae ks" href="https://www.openmined.org/" rel="noopener ugc nofollow" target="_blank"> PySyft </a>已经被用来促进<a class="ae ks" href="https://blog.openmined.org/upgrade-to-federated-learning-in-10-lines/" rel="noopener ugc nofollow" target="_blank">联邦学习</a>。然而，我们也可以利用这个框架中包含的工具来实现分布式神经网络。这使得研究人员能够处理远程保存的数据，并以一种完全分散的方式计算预测。SplitNNs由麻省理工学院于2018年12月首次推出，代表了一种全新的架构机制，供隐私保护的ML研究人员使用。</p><h2 id="d707" class="kt jp hi bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">什么是分裂？</h2><p id="a7d6" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">神经网络(NN)的训练在两台或多台主机上“分开”进行。每个模型段都是一个独立的神经网络，它为前面的模型段提供信息。在这个例子中，Alice具有未标记的训练数据和网络的底部，而Bob具有相应的标签和网络的顶部。下图显示了这个训练过程，其中Bob拥有所有标签，并且有多个带有<em class="kr"> X </em>数据<a class="ae ks" href="https://arxiv.org/abs/1810.06060" rel="noopener ugc nofollow" target="_blank">【1】</a>的Alices。一旦第一个Alice训练完毕，她会将她的底层模型副本发送给下一个Alice，一旦所有Alice都训练完毕，训练就完成了。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/8d989e1ebd434d47651b82fb3f7624e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*c13zYTBkGmKWusYUGuqwnA.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated"><a class="ae ks" href="https://arxiv.org/abs/1810.06060" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1810.06060</a></figcaption></figure><h2 id="8154" class="kt jp hi bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">为什么使用SplitNN？</h2><p id="e326" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">SplitNN已被证明可以显著降低训练的计算负担，同时在训练大量客户端时保持较高的精度[ <a class="ae ks" href="https://arxiv.org/abs/1812.00564" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]。在下图中，蓝线表示使用splitNN的分布式深度学习，红线表示联邦学习(FL)，绿线表示大批量随机梯度下降(LBSGD)。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/c897a12f0cc85c3bedbd6824b3778a54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qzhkh1stXT0HMjZrBLo4Dw.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated"><a class="ae ks" href="https://arxiv.org/abs/1812.00564" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1812.00564</a></figcaption></figure><p id="3130" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">表1显示了在VGG上空训练CIFAR 10时消耗的计算资源。这些只是FL和LBSGD资源的一小部分。表2显示了在ResNet上训练CIFAR 100时的带宽使用情况。少于100个客户端的联合学习对带宽的要求较低。然而，随着客户端数量的增长，SplitNN优于其他方法。</p><h2 id="5fab" class="kt jp hi bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">训练分裂</h2><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/47be6274d9a81f8df4aa7c7fff3e3ad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*AZn3aORQnIyilBpILIalSw.gif"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">训练分裂</figcaption></figure><p id="6b98" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用SplitNN作出的预测非常简单。我们所要做的就是得到我们的数据，使用底部的部分进行预测，并将预测发送到下一个模型部分。当分段器接收到预测时，我们使用先前预测作为我们的输入数据来进行新的预测。然后，我们将它发送给下一个模型。我们一直走，直到到达最后一层。在预测的最后，我们有最终的预测和每个模型的计算图。计算图表记录了从输入数据到预测的转换，在反向投影阶段非常有用。</p><p id="3927" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在PyTorch中，计算图允许自动签名的函数快速区分函数中使用的变量和损失函数。自动签名产生梯度，然后我们可以用它来更新模型。然而，在PyTorch中，这个方法并没有被设计成分布式的。为了进行这种自动计算，我们没有将计算图中的所有变量放在一个地方。在我们的方法中，我们通过在每个模型段上执行部分反向投影来解决这个问题，因为我们向后处理损失。我们通过在进行过程中发回相关梯度来实现这一点。</p><p id="0c60" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">考虑下面的计算图的例子。我们想计算一直回到<em class="kr"> W₀ </em>和<em class="kr"> B₀ </em>的梯度，它们是<em class="kr">网络1 </em>中的权重和偏差。然而，我们的模型在A₁.分裂这是<em class="kr">网络1 </em>的输出和<em class="kr">网络2 </em>的输入。为了解决这个问题，我们计算网络2的输出<em class="kr"> O </em>的损耗，并计算回到<em class="kr"> A₁、W₁ </em>和<em class="kr"> B₁ </em>的梯度。然后，我们将计算出的<em class="kr"> A₁ </em>的梯度发送回<em class="kr">网络1 </em>，并使用它们继续该位置的梯度计算。一旦我们有了梯度，所有的权重和偏差都回到了<em class="kr"> W₀ </em>和<em class="kr">b₀</em>，我们就可以朝着这些梯度的方向前进。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/e358a4287513d363bae5805b0145c293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ucoLSAcVmU5mnIsWAEi0Yg.png"/></div></div></figure><p id="9819" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们在各个时期重复这一过程来训练模型。一旦我们训练了足够多的时期，我们就把模型片段送回给研究者。然后，研究人员可以汇总更新的片段，并保留训练好的模型。</p><h1 id="e147" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">实现拆分NN</h1><p id="0f35" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">接下来，我们将进入一个小代码示例，其中我们使用splitNN对MNIST数据集进行预测。首先我们定义SplitNN类。它将一组模型及其链接的优化器作为其输入。</p><pre class="li lj lk ll fd lt lu lv lw aw lx bi"><span id="bb2f" class="kt jp hi lu b fi ly lz l ma mb"><strong class="lu hj">class</strong> <strong class="lu hj">SplitNN</strong>:<br/>    <strong class="lu hj">def</strong> __init__(self, models, optimizers):<br/>        self.models = models<br/>        self.optimizers = optimizers<br/>        <br/>    <strong class="lu hj">def</strong> forward(self, x):<br/>        a = []<br/>        remote_a = []<br/>        <br/>        a.append(models[0](x))<br/>        <strong class="lu hj">if</strong> a[-1].location == models[1].location:<br/>            remote_a.append(a[-1].detach().requires_grad_())<br/>        <strong class="lu hj">else</strong>:<br/>            remote_a.append(a[-1].detach().move(models[1].location).requires_grad_())<br/><br/>        i=1    <br/>        <strong class="lu hj">while</strong> i &lt; (len(models)-1):<br/>            <br/>            a.append(models[i](remote_a[-1]))<br/>            <strong class="lu hj">if</strong> a[-1].location == models[i+1].location:<br/>                remote_a.append(a[-1].detach().requires_grad_())<br/>            <strong class="lu hj">else</strong>:<br/>                remote_a.append(a[-1].detach().move(models[i+1].location).requires_grad_())<br/>            <br/>            i+=1<br/>        <br/>        a.append(models[i](remote_a[-1]))<br/>        self.a = a<br/>        self.remote_a = remote_a<br/>        <br/>        <strong class="lu hj">return</strong> a[-1]<br/>    <br/>    <strong class="lu hj">def</strong> backward(self):<br/>        a=self.a<br/>        remote_a=self.remote_a<br/>        optimizers = self.optimizers<br/>        <br/>        i= len(models)-2   <br/>        <strong class="lu hj">while</strong> i &gt; -1:<br/>            <strong class="lu hj">if</strong> remote_a[i].location == a[i].location:<br/>                grad_a = remote_a[i].grad.copy()<br/>            <strong class="lu hj">else</strong>:<br/>                grad_a = remote_a[i].grad.copy().move(a[i].location)<br/>            a[i].backward(grad_a)<br/>            i-=1<br/><br/>    <br/>    <strong class="lu hj">def</strong> zero_grads(self):<br/>        <strong class="lu hj">for</strong> opt <strong class="lu hj">in</strong> optimizers:<br/>            opt.zero_grad()<br/>        <br/>    <strong class="lu hj">def</strong> step(self):<br/>        <strong class="lu hj">for</strong> opt <strong class="lu hj">in</strong> optimizers:<br/>            opt.step()</span></pre><p id="d9b1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，我们用PySyft导入我们所有的常规导入来进行训练，设置一个torch钩子，并拉入MNIST数据。</p><pre class="li lj lk ll fd lt lu lv lw aw lx bi"><span id="48c9" class="kt jp hi lu b fi ly lz l ma mb"><strong class="lu hj">import</strong> <strong class="lu hj">numpy</strong> <strong class="lu hj">as</strong> <strong class="lu hj">np</strong><br/><strong class="lu hj">import</strong> <strong class="lu hj">torch</strong><br/><strong class="lu hj">import</strong> <strong class="lu hj">torchvision</strong><br/><strong class="lu hj">import</strong> <strong class="lu hj">matplotlib.pyplot</strong> <strong class="lu hj">as</strong> <strong class="lu hj">plt</strong><br/><strong class="lu hj">from</strong> <strong class="lu hj">time</strong> <strong class="lu hj">import</strong> time<br/><strong class="lu hj">from</strong> <strong class="lu hj">torchvision</strong> <strong class="lu hj">import</strong> datasets, transforms<br/><strong class="lu hj">from</strong> <strong class="lu hj">torch</strong> <strong class="lu hj">import</strong> nn, optim<br/><strong class="lu hj">import</strong> <strong class="lu hj">syft</strong> <strong class="lu hj">as</strong> <strong class="lu hj">sy</strong><br/><strong class="lu hj">import</strong> <strong class="lu hj">time</strong><br/>hook = sy.TorchHook(torch)</span></pre><p id="ce43" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们定义将要分布的网络。在这里，我们要建立一个简单的三层网络。然而，我们可以对任何大小或形状的网络进行此操作。每个部分都有自己的独立网络。重要的是一段与下一段连接处的层的形状。发送层的输出形状必须与接收层的输入形状相同。有关如何为这个特定数据集选择模型参数的更多信息，请阅读这篇精彩的教程。</p><pre class="li lj lk ll fd lt lu lv lw aw lx bi"><span id="2f90" class="kt jp hi lu b fi ly lz l ma mb">torch.manual_seed(0)  <em class="kr"># Define our model segments</em></span><span id="c433" class="kt jp hi lu b fi mc lz l ma mb">input_size = 784<br/>hidden_sizes = [128, 640]<br/>output_size = 10</span><span id="1fa7" class="kt jp hi lu b fi mc lz l ma mb">models = [<br/>    nn.Sequential(<br/>                nn.Linear(input_size, hidden_sizes[0]),<br/>                nn.ReLU(),<br/>    ),<br/>    nn.Sequential(<br/>                nn.Linear(hidden_sizes[0], hidden_sizes[1]),<br/>                nn.ReLU(),<br/>    ),<br/>    nn.Sequential(<br/>                nn.Linear(hidden_sizes[1], output_size),<br/>                nn.LogSoftmax(dim=1)<br/>    )<br/>]</span><span id="82a3" class="kt jp hi lu b fi mc lz l ma mb"><em class="kr"># Create optimisers for each segment and link to them</em><br/>optimizers = [<br/>    optim.SGD(model.parameters(), lr=0.03,)<br/>    <strong class="lu hj">for</strong> model <strong class="lu hj">in</strong> models<br/>]</span></pre><p id="9075" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在是时候定义一些工人来管理我们的模型，并将模型发送到他们的位置。</p><pre class="li lj lk ll fd lt lu lv lw aw lx bi"><span id="f8ff" class="kt jp hi lu b fi ly lz l ma mb"><em class="kr"># create some workers</em><br/>alice = sy.VirtualWorker(hook, id="alice")<br/>bob = sy.VirtualWorker(hook, id="bob")<br/>claire = sy.VirtualWorker(hook, id="claire")<br/><br/><em class="kr"># Send Model Segments to model locations</em><br/>model_locations = [alice, bob, claire]<br/><strong class="lu hj">for</strong> model, location <strong class="lu hj">in</strong> zip(models, model_locations):<br/>    model.send(location)</span></pre><p id="40c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们建立splitNN。要做到这一点，所需要做的就是让模型段处于它们的起始位置，并与它们各自的优化器配对。</p><pre class="li lj lk ll fd lt lu lv lw aw lx bi"><span id="8b5a" class="kt jp hi lu b fi ly lz l ma mb"><em class="kr">#Instantiate a SpliNN class with our distributed segments and their respective optimizers</em><br/>splitNN =  SplitNN(models, optimizers)</span></pre><p id="9f69" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们定义一个训练函数。splitNN的用法与传统模型非常相似。所需要的只是第二个反向投影阶段，以将梯度推回到片段上。</p><pre class="li lj lk ll fd lt lu lv lw aw lx bi"><span id="e56f" class="kt jp hi lu b fi ly lz l ma mb"><strong class="lu hj">def</strong> train(x, target, splitNN):<br/>    <br/>    <em class="kr">#1) Zero our grads</em><br/>    splitNN.zero_grads()<br/>    <br/>    <em class="kr">#2) Make a prediction</em><br/>    pred = splitNN.forward(x)<br/>    <br/>    <em class="kr">#3) Figure out how much we missed by</em><br/>    criterion = nn.NLLLoss()<br/>    loss = criterion(pred, target)<br/>    <br/>    <em class="kr">#4) Backprop the loss on the end layer</em><br/>    loss.backward()<br/>    <br/>    <em class="kr">#5) Feed Gradients backward through the network</em><br/>    splitNN.backward()<br/>    <br/>    <em class="kr">#6) Change the weights</em><br/>    splitNN.step()<br/>    <br/>    <strong class="lu hj">return</strong> loss</span></pre><p id="e531" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，我们进行训练，在训练过程中向起始位置发送数据。</p><pre class="li lj lk ll fd lt lu lv lw aw lx bi"><span id="1cee" class="kt jp hi lu b fi ly lz l ma mb"><strong class="lu hj">for</strong> i <strong class="lu hj">in</strong> range(epochs):<br/>    running_loss = 0<br/>    <strong class="lu hj">for</strong> images, labels <strong class="lu hj">in</strong> trainloader:<br/>        images = images.send(models[0].location)<br/>        images = images.view(images.shape[0], -1)<br/>        labels = labels.send(models[-1].location)<br/>        loss = train(images, labels, splitNN)<br/>        running_loss += loss.get()<br/><br/>    <strong class="lu hj">else</strong>:<br/>        print("Epoch <strong class="lu hj">{}</strong> - Training loss: <strong class="lu hj">{}</strong>".format(i, running_loss/len(trainloader)))</span></pre><p id="8cba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae ks" href="https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/Split%20Neural%20Network/Tutorial%202%20-%20MultiLayer%20Split%20Neural%20Network.ipynb" rel="noopener ugc nofollow" target="_blank">完整的例子可以在PySyft Github上看到。</a></p><h1 id="120c" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">结论</h1><p id="c04f" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">现在你有了它，一个在准确性、计算复杂性和网络资源方面与联邦学习竞争的新工具。关注与隐私保护方法相关的更多更新，如同态加密和安全多方计算。</p><p id="203f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你喜欢这样，那么你可以通过多种方式为OpenMined做贡献。</p><h2 id="8b3f" class="kt jp hi bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">GitHub上的Star PySyft</h2><p id="8ac5" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">帮助我们的社区的最简单的方法就是启动存储库！这有助于提高我们正在构建的酷工具的知名度。</p><ul class=""><li id="9372" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated"><a class="ae ks" href="https://github.com/OpenMined/PySyft" rel="noopener ugc nofollow" target="_blank">明星PySyft </a></li></ul><h2 id="fa5d" class="kt jp hi bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">试试我们在GitHub上的教程吧！</h2><p id="7c9a" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">我们制作了非常好的教程，以更好地理解保护隐私的机器学习以及我们为使其易于实现而创建的构建模块！</p><ul class=""><li id="daf2" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated"><a class="ae ks" href="https://github.com/OpenMined/PySyft/tree/master/examples/tutorials" rel="noopener ugc nofollow" target="_blank">查看PySyft教程</a></li></ul><h2 id="e28c" class="kt jp hi bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">加入我们的队伍！</h2><p id="dfa6" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">了解最新进展的最佳方式是加入我们的社区！</p><ul class=""><li id="ba96" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated"><a class="ae ks" href="http://slack.openmined.org/" rel="noopener ugc nofollow" target="_blank">加入slack.openmined.org</a></li></ul><h2 id="14cc" class="kt jp hi bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">加入一个代码项目！</h2><p id="3d5b" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">为我们的社区做贡献的最好方式就是成为代码贡献者！如果你想开始“一次性”的迷你项目，你可以去PySyft GitHub问题页面搜索标有<code class="du mm mn mo lu b">Good First Issue</code>的问题。</p><ul class=""><li id="5811" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated"><a class="ae ks" href="https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22" rel="noopener ugc nofollow" target="_blank">先发行好门票</a></li></ul><h2 id="2501" class="kt jp hi bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">捐赠</h2><p id="e40e" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">如果您没有时间为我们的代码库做出贡献，但仍然愿意提供支持，您也可以成为我们开放集体的支持者。所有捐款将用于我们的虚拟主机和其他社区开支，如黑客马拉松和聚会！</p><ul class=""><li id="eab6" class="md me hi is b it iu ix iy jb mf jf mg jj mh jn mi mj mk ml bi translated"><a class="ae ks" href="https://opencollective.com/openmined" rel="noopener ugc nofollow" target="_blank">通过OpenMined的开放集体页面捐赠</a></li></ul></div></div>    
</body>
</html>