<html>
<head>
<title>Training YOLO with keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用keras训练YOLO</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-yolo-with-keras-85c33cdefe21?source=collection_archive---------5-----------------------#2020-07-09">https://medium.com/analytics-vidhya/training-yolo-with-keras-85c33cdefe21?source=collection_archive---------5-----------------------#2020-07-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/f1b11703190c91cdeea08f74dcbf985e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*9miBCykuyRoReexkqxN-vw.png"/></div></figure><p id="df13" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">由于其快速和实时检测物体的能力，YOLO在执行物体检测方面正得到广泛的欢迎。现在，训练自定义检测是可能的，它可以按照他们的官方<a class="ae jk" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank"> github </a>链接中给出的那样执行。但是，因为没有多少人想在不知道自己在做什么的情况下直接训练它。因此，我们将为此使用keras。</p><p id="58d7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果直接想看实现，切换到<a class="ae jk" href="https://github.com/AshishGusain17/via_google_colab/blob/master/keras_yolo.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ashishgusain 17/via _ Google _ colab/blob/master/keras _ yolo . ipynb</a></p><p id="0fa9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">首先，我们将准备我们的数据集。我要检测摩托车的脚踏板是否关闭。我把所有的照片都保存在一个名为“我的照片”的文件夹里。因为这些图像大小不同。让我们把它修好。下面是一个小脚本，它将转换所有尺寸(624*832*3)的图像，并存储在“small_images”文件夹中。</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="91cc" class="ju jv hi jq b fi jw jx l jy jz">import os<br/>import cv2<br/>def prep_small_images():<br/>   myimages = os.path.join(os.getcwd(),”myimages”)<br/>   print(myimages)<br/>   for img in os.listdir(myimages):<br/>      image_path = cv2.imread(os.path.join(myimages,img))<br/>      image_path = cv2.resize(image_path,(624,832))<br/>      print(image_path.shape)<br/>      cv2.imwrite(os.path.join(os.getcwd(),"small_images",img),<br/>                  image_path)</span><span id="a8ab" class="ju jv hi jq b fi ka jx l jy jz">prep_small_images():</span></pre><p id="e544" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我们必须在脚凳关闭的情况下标记所有图像。我只是用一个单独的类来执行此操作，即“关闭”。您可以在工作中使用多个类。下载<a class="ae jk" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">标签</a>，这是一个给图像加标签的工具包。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kb"><img src="../Images/cfd08fe4bda44e3186fa4b1009d24283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhhlAThUzrdjyjHK3Q9wlA.png"/></div></div></figure><p id="f8e1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">点击打开目录，选择“小图片”文件夹。他们有两个选项来标记图像帕斯卡沃克和YOLO，选择YOLO。单击创建矩形框并为您的对象绘制一个框。输入对象的标签。对所有图像都这样做。<br/>现在，它们将是为每个图像创建的带有边界框信息的各种txt文件。运行下面的脚本，为你所有的注释和图片路径准备一个txt文件。</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="1255" class="ju jv hi jq b fi jw jx l jy jz">def prep_train_txt():<br/>   width = 624<br/>   height = 832<br/>   small_images = os.path.join(os.getcwd(),”small_images”)<br/>   file_object = open(‘train.txt’, ‘a’)</span><span id="dfa6" class="ju jv hi jq b fi ka jx l jy jz">   for img in os.listdir(small_images):<br/>      if img[-3:] == ‘txt’:<br/>         with open(os.path.join(small_images,img)) as f:<br/>            lines = f.readlines()<br/>            ans = lines[0]<br/>            line = ans.split(“ “)<br/>            x1 , y1 , w , h = float(line[1]) , <br/>                              float(line[2]) ,      <br/>                              float(line[3]) , <br/>                              float(line[4][:-1])<br/>            x1 , y1 , w , h = x1 — w/2 , y1-h/2 , w , h<br/>            x1 , y1 , w , h = int(x1*width) , <br/>                             int(y1*height) ,  <br/>                             int(w*width) , <br/>                             int(h*height)<br/>            nameee = img[:-3] + “jpg”<br/>            img_name = os.path.join(“small_images” , nameee)<br/>            img_name = cv2.imread(img_name)<br/>            text = “small_images/” + nameee + “ “ + str(x1) + <br/>                  “,” +  str(y1) + “,” + str(x1+w) + “,” + <br/>                  str(y1+h) + “,” + str(0) + “\n”<br/>            file_object.write(text)<br/>prep_train_txt()</span></pre><p id="fe6b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">记住，我在每个图像中只有一个边界框。如果您有多个盒子，可能需要对上面的脚本进行一些修改。</p><p id="ef29" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">此外，当您完成对象注释时，会创建一个单独的txt文件，其中包含所有标签名称。将其重命名为“my_classes.txt”。有了这个，我们所有的文件和数据都准备好了。</p><p id="0e17" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从现在开始的需求:<br/># Keras 2 . 1 . 5<br/># tensor flow 1 . 6 . 0<br/>从头实现完整的模型是一个有点忙乱和耗时的过程，所以我们将使用Keras中已经创建的yolo模型。原始重量可以从这个<a class="ae jk" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank">链接</a>下载。将这些重量存储在keras-yolo3文件夹中。现在，运行下面的命令。这将创建模型架构，您可以看到完整的模型概要。</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="392a" class="ju jv hi jq b fi jw jx l jy jz">git clone <a class="ae jk" href="https://github.com/qqwweee/keras-yolo3" rel="noopener ugc nofollow" target="_blank">https://github.com/qqwweee/keras-yolo3</a><br/>cd keras-yolo3<br/>python convert.py yolov3.cfg yolov3.weights model_data/yolo_weights.h5</span></pre><p id="deb5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">它们的一些功能将根据。只是复制它们。这些不需要改变。</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="ed23" class="ju jv hi jq b fi jw jx l jy jz"><strong class="jq hj">import</strong> <strong class="jq hj">numpy</strong> <strong class="jq hj">as</strong> <strong class="jq hj">np</strong><br/><strong class="jq hj">import</strong> <strong class="jq hj">keras.backend</strong> <strong class="jq hj">as</strong> <strong class="jq hj">K</strong><br/><strong class="jq hj">from</strong> <strong class="jq hj">keras.layers</strong> <strong class="jq hj">import</strong> Input, Lambda<br/><strong class="jq hj">from</strong> <strong class="jq hj">keras.models</strong> <strong class="jq hj">import</strong> Model<br/><strong class="jq hj">from</strong> <strong class="jq hj">keras.optimizers</strong> <strong class="jq hj">import</strong> Adam<br/><strong class="jq hj">from</strong> <strong class="jq hj">keras.callbacks</strong> <strong class="jq hj">import</strong> TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping<br/><strong class="jq hj">from</strong> <strong class="jq hj">yolo3.model</strong> <strong class="jq hj">import</strong> preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss<br/><strong class="jq hj">from</strong> <strong class="jq hj">yolo3.utils</strong> <strong class="jq hj">import</strong> get_random_data<br/><br/><br/><strong class="jq hj">def</strong> get_classes(classes_path):<br/>    <strong class="jq hj">with</strong> open(classes_path) <strong class="jq hj">as</strong> f:<br/>        class_names = f.readlines()<br/>    class_names = [c.strip() <strong class="jq hj">for</strong> c <strong class="jq hj">in</strong> class_names]<br/>    <strong class="jq hj">return</strong> class_names<br/><br/><strong class="jq hj">def</strong> get_anchors(anchors_path):<br/>    <strong class="jq hj">with</strong> open(anchors_path) <strong class="jq hj">as</strong> f:<br/>        anchors = f.readline()<br/>    anchors = [float(x) <strong class="jq hj">for</strong> x <strong class="jq hj">in</strong> anchors.split(',')]<br/>    <strong class="jq hj">return</strong> np.array(anchors).reshape(-1, 2)<br/><br/><strong class="jq hj">def</strong> create_model(input_shape, anchors, num_classes,  <br/>load_pretrained=<strong class="jq hj">True</strong>, freeze_body=2,<br/>            weights_path='model_data/yolo_weights.h5'):<br/>    K.clear_session() <em class="kg"># get a new session</em><br/>    image_input = Input(shape=(<strong class="jq hj">None</strong>, <strong class="jq hj">None</strong>, 3))<br/>    h, w = input_shape<br/>    num_anchors = len(anchors)<br/><br/>    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \<br/>        num_anchors//3, num_classes+5)) <strong class="jq hj">for</strong> l <strong class="jq hj">in</strong> range(3)]<br/><br/>    model_body = yolo_body(image_input, num_anchors//3, num_classes)<br/>    print('Create YOLOv3 model with <strong class="jq hj">{}</strong> anchors and <strong class="jq hj">{}</strong> classes.'.format(num_anchors, num_classes))<br/><br/>    <strong class="jq hj">if</strong> load_pretrained:<br/>        model_body.load_weights(weights_path, by_name=<strong class="jq hj">True</strong>, skip_mismatch=<strong class="jq hj">True</strong>)<br/>        print('Load weights <strong class="jq hj">{}</strong>.'.format(weights_path))<br/>        <strong class="jq hj">if</strong> freeze_body <strong class="jq hj">in</strong> [1, 2]:<br/>            <em class="kg"># Freeze darknet53 body or freeze all but 3 output layers.</em><br/>            num = (185, len(model_body.layers)-3)[freeze_body-1]<br/>            <strong class="jq hj">for</strong> i <strong class="jq hj">in</strong> range(num): model_body.layers[i].trainable = <strong class="jq hj">False</strong><br/>            print('Freeze the first <strong class="jq hj">{}</strong> layers of total <strong class="jq hj">{}</strong> layers.'.format(num, len(model_body.layers)))<br/><br/>    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',<br/>        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(<br/>        [*model_body.output, *y_true])<br/>    model = Model([model_body.input, *y_true], model_loss)<br/><br/>    <strong class="jq hj">return</strong> model<br/><br/><br/><br/><br/><strong class="jq hj">def</strong> data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):<br/>    <em class="kg">'''data generator for fit_generator'''</em><br/>    n = len(annotation_lines)<br/>    i = 0<br/>    <strong class="jq hj">while</strong> <strong class="jq hj">True</strong>:<br/>        image_data = []<br/>        box_data = []<br/>        <strong class="jq hj">for</strong> b <strong class="jq hj">in</strong> range(batch_size):<br/>            <strong class="jq hj">if</strong> i==0:<br/>                np.random.shuffle(annotation_lines)<br/>            image, box = get_random_data(annotation_lines[i], input_shape, random=<strong class="jq hj">True</strong>)<br/>            image_data.append(image)<br/>            box_data.append(box)<br/>            i = (i+1) % n<br/>        image_data = np.array(image_data)<br/>        box_data = np.array(box_data)<br/>        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)<br/>        <strong class="jq hj">yield</strong> [image_data, *y_true], np.zeros(batch_size)<br/><br/><strong class="jq hj">def</strong> data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):<br/>    n = len(annotation_lines)<br/>    <strong class="jq hj">if</strong> n==0 <strong class="jq hj">or</strong> batch_size&lt;=0: <strong class="jq hj">return</strong> <strong class="jq hj">None</strong><br/>    <strong class="jq hj">return</strong> data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)</span></pre><p id="4080" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在运行下面的命令，并确保所有的文件位置提供正确。annotation_path将具有包含所有注释的train.txt文件的文件位置。log_dir将包含训练后的模型。classes_path包含包含标签名称的txt文件的路径。anchors_path具有将在训练时使用的锚点。</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="ca46" class="ju jv hi jq b fi jw jx l jy jz">annotation_path = 'train.txt'<br/>log_dir = 'logs/000/'<br/>classes_path = 'my_classes.txt'<br/>anchors_path = 'model_data/yolo_anchors.txt'<br/>class_names = get_classes(classes_path)<br/>num_classes = len(class_names)<br/>anchors = get_anchors(anchors_path)<br/><br/>input_shape = (416,416) <em class="kg"># multiple of 32, hw</em><br/><br/>model = create_model(input_shape, anchors, num_classes,freeze_body=2, weights_path='model_data/yolo_weights.h5') <em class="kg"># make sure you know what you freeze</em><br/><br/>logging = TensorBoard(log_dir=log_dir)<br/>checkpoint = ModelCheckpoint(log_dir + 'ep<strong class="jq hj">{epoch:03d}</strong>-loss<strong class="jq hj">{loss:.3f}</strong>-val_loss<strong class="jq hj">{val_loss:.3f}</strong>.h5',<br/>    monitor='val_loss', save_weights_only=<strong class="jq hj">True</strong>, save_best_only=<strong class="jq hj">True</strong>, period=3)<br/>reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)<br/>early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)<br/><br/>val_split = 0.1<br/><strong class="jq hj">with</strong> open(annotation_path) <strong class="jq hj">as</strong> f:<br/>    lines = f.readlines()<br/>np.random.seed(10101)<br/>np.random.shuffle(lines)<br/>np.random.seed(<strong class="jq hj">None</strong>)<br/>num_val = int(len(lines)*val_split)<br/>num_train = len(lines) - num_val</span></pre><p id="0e27" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有了这个，我们就可以出发了。现在，我们可以编译和训练我们的模型。</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="6981" class="ju jv hi jq b fi jw jx l jy jz">model.compile(optimizer=Adam(lr=1e-3), loss={<br/>    <em class="kg"># use custom yolo_loss Lambda layer.</em><br/>    'yolo_loss': <strong class="jq hj">lambda</strong> y_true, y_pred: y_pred})<br/><br/>batch_size = 32<br/>print('Train on <strong class="jq hj">{}</strong> samples, val on <strong class="jq hj">{}</strong> samples, with batch size <strong class="jq hj">{}</strong>.'.format(num_train, num_val, batch_size))<br/><br/>model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),<br/>        steps_per_epoch=max(1, num_train//batch_size),<br/>        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),<br/>        validation_steps=max(1, num_val//batch_size),<br/>        epochs=50,<br/>        initial_epoch=0,<br/>        callbacks=[logging, checkpoint])<br/><br/>model.save_weights(log_dir + 'trained_weights_stage_1.h5')</span></pre><p id="8b00" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">每3个时期后，不同的模型存储在日志文件夹中。您可以使用它们中任何一个来进行预测。</p><p id="e519" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，对于预测，运行下面的命令，你会得到不同的边界框结果。应用<strong class="io hj">非</strong> - <strong class="io hj">最大抑制</strong> (NMS)可以检测到物体。</p><pre class="jl jm jn jo fd jp jq jr js aw jt bi"><span id="bee6" class="ju jv hi jq b fi jw jx l jy jz">python yolo_video.py  --image --input="/content/img1.jpg"</span></pre><p id="3f1e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里可以看到<a class="ae jk" href="https://github.com/AshishGusain17/via_google_colab/blob/master/keras_yolo.ipynb" rel="noopener ugc nofollow" target="_blank">的实现</a>。</p><p id="e467" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你可以通过<a class="ae jk" href="http://ashishgusain12345@gmail.com" rel="noopener ugc nofollow" target="_blank">邮件</a>、<a class="ae jk" href="https://www.linkedin.com/in/ashish-gusain-257b841a2/" rel="noopener ugc nofollow" target="_blank"> linkedIn </a>、<a class="ae jk" href="https://github.com/AshishGusain17" rel="noopener ugc nofollow" target="_blank"> github </a>联系我。</p></div></div>    
</body>
</html>