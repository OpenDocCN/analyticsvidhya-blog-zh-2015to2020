<html>
<head>
<title>Data pre-processing in Python using requests library and BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用请求库和BeautifulSoup在Python中进行数据预处理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-pre-processing-in-python-using-requests-library-and-beautifulsoup-305f3d07f6ce?source=collection_archive---------22-----------------------#2020-03-13">https://medium.com/analytics-vidhya/data-pre-processing-in-python-using-requests-library-and-beautifulsoup-305f3d07f6ce?source=collection_archive---------22-----------------------#2020-03-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es im"><img src="../Images/4dc86a8687cafeea16baf91bf2b9e86a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HopvMARY6pZupQQSDDkF6Q.jpeg"/></div></div></figure><h1 id="a712" class="iy iz hi bd ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv bi translated"><strong class="ak"> <em class="jw">我们在这里要做什么？</em>T3】</strong></h1><blockquote class="jx jy jz"><p id="a84d" class="ka kb kc kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky hb bi translated">我将从<strong class="kd hj"> goodreads </strong>网站(网址为“<a class="ae kz" href="https://www.goodreads.com/quotes" rel="noopener ugc nofollow" target="_blank">https://www.goodreads.com/quotes</a>”)读取内容(本质上是引用)，然后对其进行数据预处理。目标是最终将检索到的数据以有组织的格式(提取的报价以及作者姓名&amp;报价上的赞数)保存在数据帧中，然后保存在. csv文件中。格式非常简单，因为我们将在dataframe &amp;中有三列“Authorname”、“Likes”和“Quote ”,然后将其写入csv文件。</p></blockquote><p id="fc70" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — -</p><p id="d211" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated">代码:<br/><em class="kc">(*考虑你那端的缩进)</em></p><p id="96c8" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated"><em class="kc">#这里，我们将导入Python的库用于查询一个网站的</em> <br/> <strong class="kd hj">导入请求</strong></p><p id="67ee" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated"><em class="kc">#我们将在这里导入熊猫来创建一个数据帧最终<br/> </em> <strong class="kd hj">导入熊猫作为PD</strong><br/><br/><em class="kc">#在这里，我们将导入Beautiful soup函数来解析从bs4导入Beautiful soup</em><br/><strong class="kd hj">网站返回的数据#从</strong></p><p id="cbaa" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated"><em class="kc">#让我们在这里指定url，内容(引号)必须从这里读取</em> <br/> <strong class="kd hj">引号= "</strong><a class="ae kz" href="https://www.goodreads.com/quotes" rel="noopener ugc nofollow" target="_blank"><strong class="kd hj">https://www.goodreads.com/quotes</strong></a><strong class="kd hj">"</strong></p><p id="4b88" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated"><em class="kc">#在这里，我们将查询网站/url，并将html返回到变量' page '</em><br/><strong class="kd hj">page = requests . get(quotes)</strong><br/><br/><em class="kc">#现在将获取网站的内容作为文档</em><br/><strong class="kd hj">soup = beautiful ul soup(page . text，' html.parser') </strong></p><p id="5671" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated"><em class="kc">#这将会找到文档中的所有行，它们的类是“quote details”#其中包含所有引号的详细信息— Authorname，quote</em><br/><strong class="kd hj">quote _ text = soup . find _ all(class _ = " quote details ")</strong></p><p id="91d0" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated"><em class="kc">#我们现在将创建一个空数据帧来存储检索到的细节</em> <br/> <strong class="kd hj"> df1=pd。DataFrame() </strong></p><p id="f0b3" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated">现在让我们运行一个循环来分别获取每个类别——author name，quote #并打印它们。<br/><strong class="kd hj">for text 1 in quote _ text:</strong><br/><br/><em class="kc">#找到类为“authorOrTitle”时取作者名。当发现类为“quoteText”时，获取报价。当它发现类是“正确的”时，获取喜欢。</em><br/><strong class="kd hj">likes = text 1 . find(class _ = " right ")<br/>num _ like = likes . find(' a ')<br/>for num _ like中的num _ like new:<br/>author _ name = text 1 . find _ all(class _ = " author orttitle ")<br/>quote text = text 1 . find _ all(class _ = " quote text ")<br/>for quote text中的屈:<br/>for author _ name中的人名:<br/> </strong>替换(' \n '，'')，<br/> "Quote" : qu.contents[0]。替换(' \n '，'')，<br/>“喜欢”:num_likenew }，<br/> ignore_index=True) </p><p id="e04a" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated"><strong class="kd hj">print(df1 . head())</strong><br/><em class="kc">#将数据存储到一个csv文件</em> <br/> <strong class="kd hj"> df1.to_csv(r "提供你的路径。csv文件此处")</strong></p><p id="ca0f" class="pw-post-body-paragraph ka kb hi kd b ke kf kg kh ki kj kk kl la kn ko kp lb kr ks kt lc kv kw kx ky hb bi translated"><em class="kc">*确保csv文件路径以。csv(例如C:\Users\my\filename.csv) </em></p></div></div>    
</body>
</html>