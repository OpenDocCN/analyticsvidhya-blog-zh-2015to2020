<html>
<head>
<title>Understanding and Coding a neural network for XOR logic classifier from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始理解和编码用于XOR逻辑分类器的神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/coding-a-neural-network-for-xor-logic-classifier-from-scratch-b90543648e8a?source=collection_archive---------4-----------------------#2020-03-30">https://medium.com/analytics-vidhya/coding-a-neural-network-for-xor-logic-classifier-from-scratch-b90543648e8a?source=collection_archive---------4-----------------------#2020-03-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9918" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个项目中，我实现了我所有神经网络理论知识的概念证明，以便在不使用任何机器学习库的情况下，从零开始用Python编写一个简单的神经网络。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/62010545c2bf7ab8ea141a4d8420728c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B5uB2VJdROs3JT10YQy87w.jpeg"/></div></div></figure><h1 id="c239" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">简介</strong></h1><p id="9250" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">一些像神经网络这样的机器学习算法已经是一个黑盒，我们在其中输入输入，并期待奇迹发生。尽管如此，理解神经网络中幕后发生的事情是很重要的。我们可以使用Keras等库来简化我们的生活，但如果我们不了解神经网络内部发生了什么，那么我们很容易陷入无限循环，而不知道我们的神经网络出了什么问题。从零开始编码一个简单的神经网络作为这方面的概念证明，并进一步加强我们对神经网络的理解。</p><p id="9f3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在该项目中，使用单个隐藏层神经网络，隐藏层单元中具有sigmoid激活函数，输出层也具有sigmoid激活函数，因为XOR逻辑的输出是二进制的，即0或1，在输出层中只有一个神经元。神经网络背后的数学原理解释如下:</p><h1 id="4205" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">神经网络背后的数学解释:</strong></h1><p id="5494" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">以下工作显示了单个隐藏层神经网络背后的数学原理:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/62010545c2bf7ab8ea141a4d8420728c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B5uB2VJdROs3JT10YQy87w.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ks"><img src="../Images/23d6d2ebfb0fd48bedcf53393dbf641f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S3a8LZ0hJf1NSbuBvFvWIA.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kt"><img src="../Images/92a77333ac94c11195578d1ad84da11c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B7jlUQwOe8vFzkVGyTpF5g.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ku"><img src="../Images/6070e152f2d0a734c80bc5f650e45cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CmQ9Zgb2wFS7iEF0evP3qA.jpeg"/></div></div></figure><h1 id="9aaa" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">密码</h1><p id="348f" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">以下代码要点显示了神经网络参数的初始化。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="3efe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的代码要点展示了Python中的激活函数和向前向后传播函数</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="f340" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们运行神经网络10000个时期，并查看损失函数如下:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kv kw l"/></div></figure><h1 id="985c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">结果</strong></h1><p id="a554" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">下图显示了我们网络的损耗函数，可以看出它正在下降。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kx"><img src="../Images/5e614bc432c0bfeec1a05a2e50c55f2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*isX4s7VoUFNvT5IVGYxGmg.jpeg"/></div></figure><p id="1755" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是神经网络对测试输入的预测:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kv kw l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ky"><img src="../Images/aef54753861832f2b2141c02d6d66046.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*u2UkStyEy0PZgljhWRNXeg.jpeg"/></div></figure><p id="7e32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">众所周知，对于XOR，输入1，0和0，1将产生输出1，输入1，1和0，0将产生输出0。这正是神经网络正在做的。</p><h1 id="0bdd" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">代码</strong></h1><p id="5d41" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">请在<a class="ae kz" href="https://github.com/shayanalibhatti/Coding-neural_network-for-XOR-logic-from-scratch" rel="noopener ugc nofollow" target="_blank">https://Github . com/shayanalibhatti/Coding-neural _ network-for-XOR-logic-from-scratch</a>查看Github上的完整代码，代码带有注释，便于读者理解。</p><h1 id="ed04" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">结论</strong></h1><p id="ed87" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">从头开始编写一个神经网络增强了我对神经网络幕后发生的事情的理解。我希望神经网络的数学解释以及它在Python中的编码将帮助其他读者理解神经网络的工作。</p></div></div>    
</body>
</html>