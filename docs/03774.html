<html>
<head>
<title>Cloud Web Scraper — The Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">云网络抓取器——代码</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cloud-web-scraper-the-code-d2081b8d5787?source=collection_archive---------11-----------------------#2020-02-18">https://medium.com/analytics-vidhya/cloud-web-scraper-the-code-d2081b8d5787?source=collection_archive---------11-----------------------#2020-02-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c142" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">欢迎再次回来(或者可能是第一次)。继续设置基于云的web scraper的旅程，我将最终使用实际代码来简化抓取过程，并设置我们将使用的必要的数据库表和API。(API将在Oracle APEX上构建，因此如果您不使用Oracle云，这一部分对您来说可能有点多余)。</p><p id="9f9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您无意中发现了这一点，并想知道我已经看了什么，您会发现我已经谈到了<a class="ae jd" rel="noopener" href="/analytics-vidhya/cloud-web-scraper-the-setup-c542ca77c6ae">设置Oracle云环境</a>，以及<a class="ae jd" rel="noopener" href="/analytics-vidhya/cloud-web-scraper-the-web-server-1a5b57cc8e4">设置两个虚拟机(VM)中的一个作为web服务器</a>。</p><h1 id="80cc" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">数据库</h1><p id="8664" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">直入主题，让我们用这个项目需要的所有表格建立我们的数据库！这将保存我们收集的数据，以便可以随时查看和跟踪。在我们将所有需要的SQL放在一起之前，请前往<a class="ae jd" href="https://www.oracle.com/cloud/sign-in.html" rel="noopener ugc nofollow" target="_blank"> Oracle Cloud </a>上的数据仓库页面。从那里单击数据库名称，然后移动到“工具”选项卡，并单击“打开APEX”按钮。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kh"><img src="../Images/ca283ef627307be4364f83ebf379958c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sQbvHQAj50js0RinYEbClg.png"/></div></div></figure><p id="3668" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当它打开时，您将被要求创建另一个(非管理员)用户和一个工作区。在我的例子中，我使用了“HUGH_INTERN”作为两者，因此有必要适当地用您自己的用户名替换它。完成后，使用“工具”选项卡导航回页面。这次我们将单击“打开SQL Developer Web”选项。现在我们将设置数据库。</p><p id="4d6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面您将找到每个表的SQL。这很长，所以我会尽量简单地解释一下。然而，当您开始设置表时，它可以一次性运行。</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="caba" class="ky jf hi ku b fi kz la l lb lc">-- table to hold each post information<br/>CREATE TABLE HUGH_INTERN.POST_TABLE <br/>    ( <br/>     URL              VARCHAR2 (150) , <br/>     DATE_OF_CREATION DATE  NOT NULL , <br/>     IDENTIFIER       VARCHAR2 (60)  NOT NULL,<br/>    ) <br/>    TABLESPACE DATA <br/>    LOGGING <br/>;</span><span id="9fce" class="ky jf hi ku b fi ld la l lb lc">-- create and add primary key<br/>CREATE UNIQUE INDEX HUGH_INTERN.POST_TABLE_PK ON HUGH_INTERN.POST_TABLE <br/>    ( <br/>     URL ASC <br/>    ) <br/>    TABLESPACE DATA <br/>    LOGGING <br/>;</span><span id="798d" class="ky jf hi ku b fi ld la l lb lc">ALTER TABLE HUGH_INTERN.POST_TABLE <br/>    ADD CONSTRAINT POST_TABLE_PK PRIMARY KEY ( URL ) <br/>    USING INDEX HUGH_INTERN.POST_TABLE_PK ;</span><span id="9929" class="ky jf hi ku b fi ld la l lb lc">-- create table to hold daily scraped data for each post<br/>CREATE TABLE HUGH_INTERN.STAT_TABLE <br/>    ( <br/>     COLLECTION_DATE DATE , <br/>     POST_REACTS     NUMBER (*,0) , <br/>     POST_VIEWS      NUMBER (*,0) , <br/>     POST_URL        VARCHAR2 (160) <br/>    ) <br/>    TABLESPACE DATA <br/>    LOGGING <br/>;</span><span id="83be" class="ky jf hi ku b fi ld la l lb lc">-- create and add primary key<br/>CREATE UNIQUE INDEX HUGH_INTERN.STAT_TABLE_PK ON HUGH_INTERN.STAT_TABLE <br/>    ( <br/>     COLLECTION_DATE ASC , <br/>     POST_URL ASC <br/>    ) <br/>    TABLESPACE DATA <br/>    LOGGING <br/>;</span><span id="b209" class="ky jf hi ku b fi ld la l lb lc">ALTER TABLE HUGH_INTERN.STAT_TABLE <br/>    ADD CONSTRAINT STAT_TABLE_PK PRIMARY KEY ( COLLECTION_DATE, POST_URL ) <br/>    USING INDEX HUGH_INTERN.STAT_TABLE_PK ;</span><span id="7fa1" class="ky jf hi ku b fi ld la l lb lc">-- create table to hold 'API key'<br/>CREATE TABLE HUGH_INTERN.API_KEYS<br/> (<br/>     KEY_VALUE VARCHAR2 (64)<br/>    )<br/> TABLESPACE DATA <br/>    LOGGING <br/>;</span><span id="a0ca" class="ky jf hi ku b fi ld la l lb lc">-- create and add primary key<br/>CREATE UNIQUE INDEX HUGH_INTERN.API_KEYS_PK ON HUGH_INTERN.API_KEYS <br/>    ( <br/>     KEY_VALUE ASC<br/>    ) <br/>    TABLESPACE DATA <br/>    LOGGING <br/>;</span><span id="c931" class="ky jf hi ku b fi ld la l lb lc">ALTER TABLE HUGH_INTERN.API_KEYS <br/>    ADD CONSTRAINT API_KEYS_PK PRIMARY KEY ( KEY_VALUE ) <br/>    USING INDEX HUGH_INTERN.API_KEYS_PK ;</span></pre><p id="9006" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们创建的第一个表是HUGH_INTERN工作区中的POST_TABLE。该表包含3条信息；URL、创建日期和标识符。</p><p id="413d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">网址来自你要刮的帖子。如果你还希望建立一个web服务器来显示一些信息(特别是以我所做的同样的方式)，这需要以一种非常特殊的方式获得。我复制了嵌入的URL，这样以后我就可以显示一个iframe，并从URL中删除' embed/'文本。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es le"><img src="../Images/e045f664827e6ca0a1566d94dc30a776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cRC8j7crcmtvOS7JFNVDxg.png"/></div></div></figure><p id="6c93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如您稍后将看到的，当您添加新帖子时，创建日期将通过API生成。最后，标识符只是一个用来标识文章的简短文本字符串。本质上只是一个人类可读的名称。例如，我与这篇文章分享的帖子可能会被赋予标识符“Web Scraper The Code”。</p><p id="b63d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一个表是STAT_TABLE。这是每天访问日志统计每个职位。因此，它需要POST_URL(如上所述，与URL相同)和COLLECTION_DATE来惟一地标识每个表行。绑定到每一行的是POST_REACTS和POST_VIEWS。简而言之，分别是帖子的回复数和帖子的浏览量。</p><p id="be57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后是小的API_KEYS表。你可以自己决定是否需要这个。这是一种非常简单的方式来增加谁可以添加到数据库中的安全性。所有的添加都将通过一个API，这本身就是一个额外的安全层。在这里，我保存了一个64字符的散列字，作为添加到数据库时必须提供的键。</p><h2 id="ebe5" class="ky jf hi bd jg lf lg lh jk li lj lk jo iq ll lm js iu ln lo jw iy lp lq ka lr bi translated">API</h2><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es ls"><img src="../Images/f433c525d73f9dedd9f1a6b1118b500a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*fDLDXzzOSEcjmkrFKvJ9Zg.png"/></div></figure><p id="2cbd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将回到Oracle APEX来设置我们所有的API。在Oracle APEX主页上，打开下拉菜单“SQL Workshop”，然后选择“RESTful Services”选项。</p><p id="15ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从这里，您将需要登录到您在上面创建的工作区，同时创建用户。登录后，在屏幕中央寻找标有“模块”的部分。如果您将鼠标悬停在上面，请单击应该显示“添加模块”的小加号。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lt"><img src="../Images/1fd6e327957cab969bbe7120a007c778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-6TuMR1HOM2TBn3cOU8emw.png"/></div></div></figure><p id="6384" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你会看到一张需要填写的表格。在我的例子中，我对“模块名”和“基路径”使用了几乎相同的名称:分别是“scrape”和“/scrape/”。如果您更改“已发布”滑块，将会更改API的可用性。“分页大小”指的是API将返回多少结果，这也可以在每个API中进一步细化。</p><p id="23b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当你进入模块菜单时，你需要点击“创建模板”按钮来创建你的API。您需要提供一个“URI模板”名称，我们将从一个名为“帖子”的模板开始。这将保存我们的GET和POST方法，供web scraper使用。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lu"><img src="../Images/6134a225acc6bb4fe0fd843c15198a92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1POmd327TPOdqN3js889SQ.png"/></div></div></figure><p id="2732" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建模板后，在模板菜单中单击“创建处理程序”。你会看到左边图片中的菜单。在“方法”下拉菜单中，选择“获取”，并在“源类型”中选择“收集查询”。然后在菜单下方的“源”中添加以下内容:</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="9414" class="ky jf hi ku b fi kz la l lb lc">select URL<br/>from HUGH_INTERN.POST_TABLE JOIN HUGH_INTERN.STAT_TABLE <br/>ON URL=POST_URL <br/>WHERE COLLECTION_DATE = (SELECT MAX(COLLECTION_DATE) FROM HUGH_INTERN.STAT_TABLE WHERE URL = POST_URL GROUP BY POST_URL) <br/>ORDER BY COLLECTION_DATE ASC</span></pre><p id="d3b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将返回数据库中的URL列表，按照从最早抓取到最近抓取的顺序排列。这种排序的原因是，由于LinkedIn超时，python脚本偶尔会无法抓取一些页面。因为它被设计为每天晚上运行，所以它引导我们找到了“最终正确”的方法。这是不理想的，但不幸的是无法帮助。</p><p id="3acc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">导航回模板以创建另一个处理程序。这次我们将创建一个POST方法API。这个将用于记录我们收集的与每个帖子相关的统计数据。当您选择一个POST方法时，源类型将变为PL/SQL，这就是我们想要的。其来源如下:</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="972b" class="ky jf hi ku b fi kz la l lb lc">BEGIN<br/>    INSERT INTO HUGH_INTERN.STAT_TABLE(COLLECTION_DATE, POST_REACTS, POST_VIEWS, POST_URL)<br/>    VALUES (CURRENT_DATE,:GETREACT,:GETVIEW,:GETURL);<br/>    UPDATE HUGH_INTERN.POST_TABLE<br/>    WHERE URL = :GETURL;<br/>    COMMIT;<br/>END;</span></pre><p id="33c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面每个以冒号(:)开头的变量表示它是在POST请求的头中发送的。“CURRENT_DATE”只是以日期格式传递API运行时的本地时间。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="5c00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将创建另一个模板来处理一些网页可视化。在这种情况下，我称之为“观想”。像以前一样，我们将创建一个GET和POST方法。我将提供代码，然后简要讨论每一个。</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="2b13" class="ky jf hi ku b fi kz la l lb lc">--GET<br/>SELECT URL<br/>FROM HUGH_INTERN.POST_TABLE  <br/>WHERE DATE_OF_CREATION = (SELECT MAX(DATE_OF_CREATION) FROM HUGH_INTERN.POST_TABLE)</span></pre><p id="c45d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的GET API将返回您正在跟踪的最近添加的帖子。这仅仅是为了将它与网页上浏览最多和反应最强烈的帖子放在一起。</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="b64b" class="ky jf hi ku b fi kz la l lb lc">--POST<br/>DECLARE<br/>    API_KEY_COUNT NUMBER;<br/>    NEW_POST NUMBER;<br/>BEGIN<br/>    SELECT COUNT(1) INTO API_KEY_COUNT FROM HUGH_INTERN.API_KEYS WHERE KEY_VALUE = :API_KEY;<br/>    SELECT COUNT(1) INTO NEW_POST FROM HUGH_INTERN.POST_TABLE WHERE URL = :GETURL;<br/>    IF (API_KEY_COUNT) = 1 THEN<br/>        IF (NEW_POST) = 0 THEN<br/>            INSERT INTO HUGH_INTERN.POST_TABLE(DATE_OF_CREATION, URL, IDENTIFIER)<br/>            VALUES (CURRENT_DATE,:GETURL,:GETIDENTIFIER);<br/>            COMMIT;<br/>        END IF;<br/>    ELSE<br/>        DBMS_OUTPUT.PUT_LINE('Invalid API Key');<br/>    END IF;<br/>END;</span></pre><p id="04de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的帖子API用于将需要跟踪的新帖子插入数据库。这将出现在网页上。DECLARE语句允许我们在PL/SQL代码中创建变量。API_KEY_COUNT通过返回值1来检查我们的(相当初级的)API键是惟一的，并且在API表上。以类似的方式，NEW_POST通过返回值0来检查我们正在添加的文章是否已经在数据库中。如果这两个值都满足，那么新帖子将被添加到数据库中。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="14b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的最后两个模板是“maxViews”和“maxReacts”。这两个函数用来保存GET处理程序，这两个处理程序将分别返回具有最多浏览量的帖子和具有最多反应的帖子。像前面一样创建这些模板，并在每个模板中创建一个GET处理程序。</p><p id="9b8e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为这两个GET方法非常相似，所以我将提供这两个方法的代码，然后讨论一般的工作方式，同时指出它们的区别。</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="3503" class="ky jf hi ku b fi kz la l lb lc">--maxViews<br/>SELECT URL<br/>FROM HUGH_INTERN.POST_TABLE <br/>JOIN HUGH_INTERN.STAT_TABLE ON URL=POST_URL <br/>WHERE POST_VIEWS = (SELECT MAX(POST_VIEWS) FROM HUGH_INTERN.STAT_TABLE)</span><span id="e5fd" class="ky jf hi ku b fi ld la l lb lc">-----</span><span id="3548" class="ky jf hi ku b fi ld la l lb lc">--maxReacts<br/>SELECT URL <br/>FROM HUGH_INTERN.POST_TABLE <br/>JOIN HUGH_INTERN.STAT_TABLE ON URL=POST_URL <br/>WHERE POST_REACTS = (SELECT MAX(POST_REACTS) FROM HUGH_INTERN.STAT_TABLE)</span></pre><p id="0e71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如您所见，两个GET方法都将查询与STAT_TABLE连接的POST_TABLE，以找到哪个帖子(分别)有最多的浏览量或反应，并返回找到的帖子的URL。</p><h2 id="5a69" class="ky jf hi bd jg lf lg lh jk li lj lk jo iq ll lm js iu ln lo jw iy lp lq ka lr bi translated">Python代码(Web抓取位)</h2><p id="3b01" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">所以python代码相对较长(本文也是如此)，所以你可以在我的<a class="ae jd" href="https://github.com/HughGDA/LIWebScraper/blob/master/python_scraper.py" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到它来阅读。我将确保它被注释，但是我将在这里画出它的一些更关键的部分(连同相关的行号)。</p><p id="9218" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使python脚本正常工作的关键编辑如下:</p><ul class=""><li id="177b" class="mc md hi ih b ii ij im in iq me iu mf iy mg jc mh mi mj mk bi translated">在第11行，将[Full URL Here]替换为您的模块的完整URL。如下，点击下拉菜单中的模块名称，然后点击完整URL旁边的复制按钮进行复制。</li><li id="ec41" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated">编辑。Python文件附带的env文件。将[您的密码]替换为您的LinkedIn密码，将[您的电子邮件地址]替换为与您的LinkedIn帐户关联的电子邮件地址。</li></ul><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es mq"><img src="../Images/34cdd0a5fad49e548d9ca916b1fc2f47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WQ_G0VMMfbbuTzGPfVomwA.png"/></div></div></figure><h2 id="6986" class="ky jf hi bd jg lf lg lh jk li lj lk jo iq ll lm js iu ln lo jw iy lp lq ka lr bi translated">自动化</h2><p id="42ab" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">那么，我们如何自动化刮擦过程呢？通过内置的cron守护进程写入crontab文件。</p><p id="85bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在你的Web Scraper虚拟机上(如果你正在学习我的教程)，保存python和。env文件(我们将在下一节返回html文件)。记下python文件的路径。这可以通过运行以下命令轻松完成:</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="57b3" class="ky jf hi ku b fi kz la l lb lc">readlink -f [PYTHON FILE NAME]</span></pre><p id="440f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">复制路径，我们将把它添加到crontab中。为此，请使用以下命令:</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="08a1" class="ky jf hi ku b fi kz la l lb lc">sudo EDITOR=nano crontab -e</span></pre><p id="befb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“EDITOR=nano”不是必需的，但是nano是我选择的文本编辑器，所以我明确地确保它是crontab打开的那个编辑器。将以下几行添加到打开的文件中:</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="b665" class="ky jf hi ku b fi kz la l lb lc">PATH = [$PATH]:[Path to gecko]<br/>0 2 * * * /usr/bin/python3 [Path to Python] &gt;&gt; [Path to Log] 2&gt;&amp;1</span></pre><p id="aa28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我已经讨论过Python之路]已经解释过了。[日志路径]只是一个保存python文件输出的文件；例如，任何打印声明、遇到的异常等。你可以自己决定。您可以简单地将它保存到与python文件相同的目录中。请记住，路径还需要日志文件的名称，类似于“webscraper.log”的名称就足够了。</p><p id="91bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我现在将解释路径线。[$PATH]将被您的PATH变量替换。这是通过运行以下命令获得的:</p><pre class="ki kj kk kl fd kt ku kv kw aw kx bi"><span id="ba0b" class="ky jf hi ku b fi kz la l lb lc">echo $PATH</span></pre><p id="2426" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">只需复制它的输出，并用它替换[$PATH]。[壁虎之路]将被你的壁虎之路所取代。这是根据<a class="ae jd" rel="noopener" href="/analytics-vidhya/cloud-web-scraper-the-setup-c542ca77c6ae">我的关于设置云环境的教程</a>安装的。如果您已经学习了该教程，那么它应该已经在您的path变量中了，但是crontab中的这个附加内容是为了精确，以确保python脚本可以找到它。</p><h2 id="2a46" class="ky jf hi bd jg lf lg lh jk li lj lk jo iq ll lm js iu ln lo jw iy lp lq ka lr bi translated">基本网页</h2><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es mr"><img src="../Images/b87e28535c198586174393f1cfcfa744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4JkndQcd7IFRVTUQsLJxgQ.png"/></div></div></figure><p id="1823" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，最后我们将看看如何设置一个非常基本的网页来查看我们收集的一些结果。这个文件可以在我的GitHub上找到，还有python和。环境文件。与python文件非常相似，我不会将代码放在本文中，而是简单地讨论您需要进行的一些编辑。</p><p id="4798" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第7行和第63行，像以前一样用模块URL替换[MODULE_URL HERE]。然后只需将文件保存到服务器网页的位置。如果使用默认的Apache设置，就像这里设置的那样，它应该是'/var/www/html/'。将它保存为“index.html ”,你的网页就可以运行了。</p><p id="3574" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它将显示你最常浏览的帖子，对帖子的最大反应，最近的帖子，以及一个将帖子添加到数据库的表单。这是在2x2网格上完成的，如上图所示。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="2262" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我意识到这篇文章比预期的扩展了一点，但是这结束了我的多部分web scraper教程。我希望你喜欢它！</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="28e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">问题，评论？你可以在<a class="ae jd" href="https://www.linkedin.com/in/hugh-gallagher/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上找到我。</p><blockquote class="ms"><p id="912d" class="mt mu hi bd mv mw mx my mz na nb jc dx translated"><em class="nc"> *所有观点均为本人观点，不代表甲骨文* </em></p></blockquote></div></div>    
</body>
</html>