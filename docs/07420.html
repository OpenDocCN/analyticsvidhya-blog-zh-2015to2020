<html>
<head>
<title>Kernel-based approaches in machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中基于核的方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/kernel-based-approaches-in-machine-learning-aaf174bdf49a?source=collection_archive---------5-----------------------#2020-06-25">https://medium.com/analytics-vidhya/kernel-based-approaches-in-machine-learning-aaf174bdf49a?source=collection_archive---------5-----------------------#2020-06-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f424" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">核是一种使用线性分类器来解决非线性问题的方法，这是通过将线性不可分的数据转换为线性可分的数据来完成的。</p><p id="52d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">举个例子，我们要对以下几个类进行分类，这几个类是线性不可分的，所以要让这两个类都是线性可分的，就要用到核的技巧。我们将使用一些核心技巧将二维非线性观测映射到三维。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/46fc81f05256267c15d6040f1d44c372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*AjTkd9I_2aa5P4pvXIc-jg.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">内核技巧</figcaption></figure><p id="8b60" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在机器学习中，有不同类型的基于核的方法，如正则化径向基函数(Reg RBFNN)，支持向量机(SVM)，核-费舍尔判别(KFD)分析，正则化Adaboost (Reg AB)等。在所有这些算法中，广泛使用的方法是SVM。</p><p id="48cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们详细讨论SVM，并尝试使用感知器方法对不能线性分离的异或逻辑进行分类。</p><p id="3e0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基本上，支持向量机是用于使用具有一些优雅特性的二进制学习机的二进制分类。</p><p id="0f4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个想法可以总结为</p><p id="d908" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp">给定一个训练样本，主要目标是构建一个超平面作为决策边界，使得决策边界和支持向量之间的距离最大化，即正负样本之间的分离裕度最大化</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jq"><img src="../Images/864759066ce0997d3d263e14ab67a0ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*nclsaiTdSP9tGJ4MtRfl7w.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">线性SVM</figcaption></figure><p id="9822" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有两种类型的SVM</p><p id="dd38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.线性SVM</p><p id="c3e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.非线性SVM</p><p id="6205" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"/>线性SVM 处理二元分类，考虑监督学习，用训练样本(<em class="jp">、【易】)</em>其中<em class="jp">、</em>是输入模式，<em class="jp">易</em>是目标输出。假设有2个类；<em class="jp"> yi </em> = +1和<em class="jp"> yi </em> = -1，它们是线性可分的，那么分离这两个类的判定边界的方程变成</p><p id="5ae3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp"> (Wx+) </em> + b =1 — — — —为正类</p><p id="c84e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp"> (Wx-) </em> + b =-1 — — — —为否定类</p><p id="3ebf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">w是重量，b是偏差</p><p id="afad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从1中减去等式2，我们得到，</p><p id="e2d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp">W(x+-x-)</em>= 2 = M———&gt;M =两个等级之间的最佳间隔值，因此等式变为</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/c6a512354101b4e970e8e82e89035a47.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*W-2tEmGhNnQ5KNP4DV4Gzw.png"/></div></figure><p id="f060" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp">上述等式表明，二元类之间的分离裕度相当于最小化权重向量W的欧几里德范数| | W | | T21】</em></p><p id="043f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">使用<strong class="ih hj">直线SVM </strong>时需要检查两个条件</strong></p><p id="d0f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp"> 1。</em><em class="jp"/>+b = 1表示正类，w <em class="jp"> Wx </em> + b = -1表示负类</p><p id="aa1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp"> 2。</em> || <em class="jp"> W </em> ||(欧几里德范数)应该是最小值</p><p id="6d7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有一种方法叫做<strong class="ih hj">拉格朗日方法(L) </strong>，可以总结为</p><p id="5a60" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于支持向量，L必须通过改变拉格朗日乘数(αi)来最大化</p><p id="bab7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">远离边界的图案。对他们来说，αi太小了</p><p id="ecbf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接近判定边界的模式，对它们来说αi将太大</p><p id="3a16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jp">这种技术也被称为最大边距分隔符或硬边距分隔符</em> </strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es js"><img src="../Images/d01cbb79e04e9ed12f94c3ef5a330125.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*Xh2AMQviuSOrO5Z1XOqFlw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">过度拟合</figcaption></figure><p id="2782" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当出现过拟合情况时，我们不能使用硬边距分隔符，为此，我们必须使用软边距分隔符</p><p id="71c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">软边距分隔符</strong>在不同标签的数据混淆时使用，然后使用软边距分隔符，我们必须考虑边距板内的样本来绘制最佳分隔线</p><p id="8b18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果数据点(<em class="jp">yi)</em>违反以下条件，则类之间的分离界限被称为软的，</p><p id="35ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp"> di(Wx+ </em> + b) &gt; = +1</p><p id="a5fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于不可分离的数据点，我们使用一组非负标量变量，ξi进入分离超平面(决策边界)的定义如图所示，</p><p id="8c72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp"> di(Wx+ </em> + b) &gt; = 1 — ξi</p><p id="c6be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ξi被称为<strong class="ih hj">松弛变量</strong>。它们测量数据点与模式可分性理想条件的偏差</p><p id="0546" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">非线性支持向量机</strong>是使用核技巧的地方，其中发生模式从较低维度到较高维度的映射，并且为了进行该映射，使用了核技巧。</p><p id="91bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">核方法的基本思想是处理线性不可分的数据，并创建原始特征的非线性组合，以通过映射函数(ϕ()将它们投影到更高维的空间，在那里它变得线性可分。</p><p id="deb0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于SVM的最常用的核是RBF核或高斯核</p><p id="f1c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在非线性SVM中，C(用户指定的正参数)，ξi需要变化。ξi值越大，适合的噪波越多。</p><p id="684e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们使用SVM核技巧对异或逻辑进行线性分类，使用感知器方法无法对其进行线性分离。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="jt ju l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jv"><img src="../Images/1f58da00a9d44fafed93585a4f0e7bf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*EQk94oEilufE5BRXBxwf3w.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">异或问题——不能线性分离</figcaption></figure><p id="5c2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们取400个样本，其中200个属于第1类，200个属于第1类，查看代码和输出</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="jt ju l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jw"><img src="../Images/300e5b4f862961ef42ae4ba84783c7a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*PmsTRDx5RShTmqSAdqFing.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">大数据的异或绘图</figcaption></figure><p id="180b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用SVM径向基函数核，我们得到了下面的结果，它能够画出一个分离数据的非线性决策边界，</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="jt ju l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jx"><img src="../Images/3cf4c87913e4ed6078eaf2a793c027c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*CITu4zwpeX5i9qVs95WeTQ.png"/></div></figure><p id="51a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了比较不同类型的基于核的方法，我们研究了一篇名为“<strong class="ih hj">基于核的高光谱图像分类方法</strong>的研究论文，以下是我们注意到的要点</p><p id="e9b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVM-保利和SVM-RBF给出了最好的整体表现。</p><p id="c57f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当附加噪声(高斯、均匀和脉冲)被添加到测试集时，信噪比在16和40 dB之间变化，获得的结果如下，当引入中等噪声(SNR &gt;25dB)时，SVM-RBF显示出比KFD更高的总体精度，然而在复杂情况下，(SNR &lt; 25db)模拟，KFD显示出比SVM-RBF更好的精度，但不如SVM-Poly。</p><p id="5849" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比较不同组训练数据集的结果，结果记录如下:</p><p id="b41f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">分析五种不同的情况，原始训练样本的0.25%、5%、10%、25%和100%，并从训练集中随机选择，以训练模型并评估它们在总测试集上的准确性。这些情况对应于分别由12，229，459，1147，4588个样本组成的训练集。当考虑12个样本作为训练集时，SVM(两个内核)显示出比其他模型更好的性能，尽管总体精度非常低(50%)，随着训练样本比率的增加，SVMs和Reg-AB相对于KFD和Reg-RBFNN总是具有3%到8%的更高精度。然而，KFD在大多数情况下表现不佳，并且随着样本的增加需要昂贵的计算成本。</p><p id="0060" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当考虑高光谱数据的特定特征时，稀疏解决方案主要是首选的，因为在训练过程中，算法选择最相关的样本进行分类，并在解决方案中为它们分配权重。SVM给出的解决方案本质上是稀疏的，但是为了从SVM获得更好的结果，至少需要40%的训练样本(支持向量)。在Reg- RBFNN和Reg-AB的情况下，稀疏性是通过选择分别由隐藏神经元和假设的数量给出的最合适的权重数量来施加的。SVM和Reg-AB在高维特征空间中工作，并且都导致不同空间中的稀疏解。KFD考虑了所有的训练样本。</p><p id="2029" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从本文中可以得出以下结论:</p><p id="acd9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">支持向量机(两种内核)在计算成本方面产生了极好的结果。准确性，对普通噪声水平的鲁棒性，并确保稀疏性。SVM的缺点是不容易产生概率输出。</p><p id="33d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Reg-AB生成了与SVMs相当的结果，提高了Reg-RBFNN的鲁棒性，并有效地处理了少量的标记样本。</p><p id="bfd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">仅当考虑正常条件时，KFD给出了良好的精度。还应注意，这种方法计算效率低。</p><p id="458a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Reg-RBFNN在精度和计算成本之间提供了一个特殊的折衷，但是在所有测试中的精度都低于其他非线性模型提供的精度。</p><p id="0a70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从结果中，我们可以得出结论，与所有其他核方法相比，支持向量机更好，因为它具有较高的整体精度，以低得多的计算成本确保了稀疏性。</p><p id="1dfd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考资料:</p><p id="73fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[1] scikit机器学习支持向量机(SVM)<a class="ae jy" href="https://www.bogotobogo.com/python/scikit-learn/scikit_machine_learning_Support_Vector_Machines_SVM_2.php" rel="noopener ugc nofollow" target="_blank">https://www . bogotobogo . com/python/sci kit-learn/sci kit _ machine _ learning _ Support _ Vector _ Machines _ SVM _ 2 . PHP</a></p><p id="634b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2]基于核的高光谱图像分类方法<a class="ae jy" href="https://ieeexplore.ieee.org/document/1433032" rel="noopener ugc nofollow" target="_blank">https://ieeexplore.ieee.org/document/1433032</a></p></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><p id="de27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要了解更多关于机器学习算法的信息，请阅读我之前的文章</p><div class="kg kh ez fb ki kj"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/an-overview-of-machine-learning-algorithms-4a9a881a1a4b"><div class="kk ab dw"><div class="kl ab km cl cj kn"><h2 class="bd hj fi z dy ko ea eb kp ed ef hh bi translated">机器学习算法综述</h2><div class="kq l"><h3 class="bd b fi z dy ko ea eb kp ed ef dx translated">机器学习是让计算机在没有程序员明确编程的情况下行动的科学。它…</h3></div><div class="kr l"><p class="bd b fp z dy ko ea eb kp ed ef dx translated">媒介</p></div></div><div class="ks l"><div class="kt l ku kv kw ks kx jj kj"/></div></div></a></div></div></div>    
</body>
</html>