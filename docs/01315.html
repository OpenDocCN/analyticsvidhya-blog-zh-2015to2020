<html>
<head>
<title>SVM Linear Classifier in Simplest words</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最简单的词中的SVM线性量词</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/svm-linear-classifier-in-simplest-words-6e52a7c84631?source=collection_archive---------11-----------------------#2019-10-14">https://medium.com/analytics-vidhya/svm-linear-classifier-in-simplest-words-6e52a7c84631?source=collection_archive---------11-----------------------#2019-10-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b8ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过这个博客，我只想让我的读者尽可能简单地理解SVM分类器是如何工作的。</p><p id="bee2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，支持向量机(SVM)被用于通过在由每个类所代表的各种数据点组成的类之间画出判定边界来分离不同类的数据点。在数据点集合之间创建的决策边界被称为<strong class="ih hj">超平面</strong>，SVM帮助创建它。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/d6c3fb939cdc01960a71fa5effa6e735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*VijGPT9cLN-4oNPrBm0dMA.png"/></div></figure><p id="2940" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以使用SVM的问题陈述:—</p><ul class=""><li id="bcb9" class="jl jm hi ih b ii ij im in iq jn iu jo iy jp jc jq jr js jt bi translated">聚类(将数据点分组到n维空间中的各个簇)</li><li id="0a2a" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">时间序列检测</li><li id="0336" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">回归(如股票价格预测)</li><li id="ab76" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">异常值检测(检测相似数据点组中异常数据点的存在)</li><li id="966f" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">分类</li></ul><p id="3c9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVM是伟大的，我们有大约<strong class="ih hj"> 1000个数据点</strong>的小数据集，用于鉴别分类器。</p><p id="efe7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们构建上图中两个类之间的超平面或决策边界的方法是最大化余量，即该线和两组类之间的空间意味着每个类中最接近决策边界的点。如图所示，这些点被称为<strong class="ih hj">支持向量</strong>。之所以这样称呼它们，是因为它们在超平面的创建过程中起支撑作用。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jz"><img src="../Images/883d1df3d24638d3b0651d3cd9fbdfbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*Z3Msm7PINQcol5hVWgKRFg.gif"/></div></figure><p id="6966" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要创建的超平面将总是具有<strong class="ih hj"> n-1维，其中n是数据集中的特征(列)</strong>的集合，例如，在用于分离数据点的<strong class="ih hj"> 2D图</strong>中，我们的超平面将是<strong class="ih hj">2–1 = 1维</strong>，即一条线。同样，对于<strong class="ih hj"> 3D图形</strong>超平面将是<strong class="ih hj">3–1 = 2维</strong>超平面。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ka"><img src="../Images/25bd1007fcca6092a411ff7dcaeb6637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FwrX8viaCLljRAAxiSAp8Q.png"/></div></div></figure><p id="f4c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在SVM问题中，我们使用<strong class="ih hj">铰链损耗</strong>函数进行最大裕度分类。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kf"><img src="../Images/ed2ff7afa47b205488c5237ddec1713c.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*H1q2ak7hjvzg7mph0kayAw.png"/></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">铰链损失函数</figcaption></figure><p id="61db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中，<strong class="ih hj"> <em class="kk"> x </em> </strong>是迭代数据点的集合</p><p id="4fd3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kk"> y </em> </strong>是我们的x数据点对应的实际输出组\</p><p id="3f84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kk"> f(x) </em> </strong>是预测输出</p><p id="e248" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">+号</strong>表示当我们继续增加损失时，如果我们对<strong class="ih hj"> <em class="kk"> (1 — y*f(x))求和后得到负值，那么我们可以保持它不变，否则我们将使它为0。</em> </strong></p><p id="0a4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将为我们的SVM类定义我们的<strong class="ih hj">目标函数(就像线性回归中的y = MX+c)</strong>，它被定义为:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kl"><img src="../Images/0d168d2cacb7b2a2a2506ea1742ca181.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*uaEAUzd3YzU-uGtcuaZEjg.png"/></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">SVM目标函数</figcaption></figure><p id="9e41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中，<strong class="ih hj"> <em class="kk"> min λ ||w||^2 </em> </strong>称为<strong class="ih hj"> <em class="kk">正则化子</em> </strong>。调节器是一个<strong class="ih hj">调谐旋钮</strong>。它告诉我们如何最好地拟合我们的数据。<strong class="ih hj"> </strong>因此，如果正则项太高，我们的模型可能会过拟合我们的数据点，并且不能推广到我们的新数据点，或者如果它的值太低，那么它将会过拟合，并且永远不会收敛。因此，我们需要一个完美的正则项来使我们的模型尽可能地一般化并适合我们的训练数据。<strong class="ih hj">目标</strong> <strong class="ih hj">函数</strong>中的<strong class="ih hj">下一个</strong>项是将产生<strong class="ih hj">总损失的<strong class="ih hj">损失函数</strong>。</strong></p><p id="cecf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们将优化这个由<strong class="ih hj">正则项</strong>和<strong class="ih hj">损失函数</strong>项组成的目标函数。我们将通过使用<strong class="ih hj">梯度下降优化器</strong>来实现这一点。所以我们将在训练过程中对我们的<strong class="ih hj">优化</strong>目标<strong class="ih hj">目标</strong>函数<strong class="ih hj">函数</strong>的两个项做<strong class="ih hj">偏导数</strong>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es km"><img src="../Images/008125193054dc9d09773b45ebaa3c61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2IMvqBNsDoQoyEljexcnVw.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">目标函数中正则项和损失函数项的偏导数</figcaption></figure><p id="94f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，在每个训练过程的迭代期间，我们将根据两种情况更新<strong class="ih hj"> <em class="kk"> w(权重)的值:</em> </strong></p><p id="a9e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kk"> 1 —误分类(未正确分类)情况当总损耗值小于1时，则w = w +η(yi*xi -2*λ*w)。</em> </strong></p><p id="ccd3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kk"> 2 —正确分类(总损失值为零)那么我们的权重值将更新为w = w + η( -2*λ*w)因为我们已经正确分类，所以这里不需要更新我们的总损失。</em>T47】</strong></p><p id="1eeb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，<strong class="ih hj"> <em class="kk"> η是</em> </strong>的另一个<strong class="ih hj"> <em class="kk">调谐旋钮，用于调节车型</em> </strong>可以学习到的速度<strong class="ih hj"> <em class="kk">。因此，如果η(学习率)太高，它可能会超过并完全跳过最小损失，如果太低，它可能需要太长时间才能达到最小损失，并且永远不会收敛。所以我们需要为我们的η</em></strong>设定一个最优值</p><p id="087c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还应该记住的一点是<strong class="ih hj">正则项</strong>项<strong class="ih hj"> || <em class="kk"> λ </em> || </strong> = (1/(我们训练我们的模型的次数(<strong class="ih hj"> Epoch </strong>))。因此，正则项随着<strong class="ih hj">历元</strong>数量的增加而不断减少。</p><p id="e948" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，通过优化我们的目标函数，我们的误差或总损失(<strong class="ih hj">铰链</strong>损失)将随时间减少。从而最大化属于不同类别的数据点之间的空间。从而我们可以绘制最佳超平面，并且我们可以通过将正则项包含在目标函数中来使用正则项来找到其最佳值，从而我们的模型将最适合我们的训练和测试数据。这就是SVM模式的运作方式。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kn"><img src="../Images/84e798a1cd95e2b8d16dae3b1db2224b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*-Wi-U88jBUya1G02La0ysw.gif"/></div></div></figure><p id="080c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在训练过程(历元)的每一步获得的损失称为梯度。梯度是其分量由导数组成的向量。所以在所有的微分计算中，我们都有导数。我们之所以要求导，以使训练过程中每一步的损失最小化，是因为我们想知道梯度移动方向的变化率。所以我们也可以说<strong class="ih hj">梯度是一个向量，它的分量由我们所逼近的系数或函数的偏导数组成。</strong></p><p id="c9ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，我希望我的读者对SVM的作品有一些直觉。如果你遇到问题，请在评论中告诉我。<strong class="ih hj"> <em class="kk">直到那时才享受学习。</em> </strong></p><p id="835b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鸣谢——SIRAJ RAVAL(你管SVM分类器上的视频)</p></div></div>    
</body>
</html>