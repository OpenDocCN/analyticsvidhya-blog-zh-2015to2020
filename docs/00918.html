<html>
<head>
<title>Super Resolution GAN(SRGAN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超分辨率氮化镓(SRGAN)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/super-resolution-gan-srgan-5e10438aec0c?source=collection_archive---------3-----------------------#2019-09-19">https://medium.com/analytics-vidhya/super-resolution-gan-srgan-5e10438aec0c?source=collection_archive---------3-----------------------#2019-09-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1101" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是使用生成式对抗网络实现的纸张<a class="ae jd" href="https://arxiv.org/abs/1609.04802" rel="noopener ugc nofollow" target="_blank">照片级单幅图像超分辨率。在本文中，PyTorch库被用来实现本文。</a></p><p id="2caa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SRGAN使用GAN从低分辨率图像产生高分辨率图像。在该实现中，使用GAN的概念将64×64图像转换成256×256图像。为了训练，使用高斯模糊将高分辨率图像下采样为低分辨率图像，然后将其大小调整为64 X 64。总的来说，SRGAN将图像向上采样4倍，产生高分辨率图像。生成器用于从64×64图像生成256×256图像，鉴别器用于将生成的图像与HR图像区分开。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/7cc6fd8aa8300496ad6a010a740729f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nGCRwZxmYoNjaMdOrxz9xA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><a class="ae jd" href="https://arxiv.org/pdf/1609.04802.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="c0ae" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">网络体系结构</h1><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ks"><img src="../Images/3ebb1a4dc57278a31dd1d5666a700d86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T_vCYUgD8UygdMWlgV3ciw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><a class="ae jd" href="https://arxiv.org/pdf/1609.04802.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="d959" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以上是参考文献中使用的发生器和鉴别器的架构。k9n64s1表示大小为9的内核，64个通道，步距为1。在鉴别器中使用残余块。网络架构中使用的两个新概念是<strong class="ih hj"> PRelu </strong>和<strong class="ih hj"> PixelShuffler。</strong></p><blockquote class="kt ku kv"><p id="77ed" class="if ig kw ih b ii ij ik il im in io ip kx ir is it ky iv iw ix kz iz ja jb jc hb bi translated"><strong class="ih hj"> PRelu </strong>是一种leakyRelu，它不是预定义的斜率0.01，而是神经网络自己决定斜率值的参数。当x &lt; 0时y=ax，当x &gt; 0时y=x，其中a是由网络确定的参数。</p><p id="ddd2" class="if ig kw ih b ii ij ik il im in io ip kx ir is it ky iv iw ix kz iz ja jb jc hb bi translated">P <strong class="ih hj">像素重排</strong>将形状张量(N，C，H，W)重排为(N，C/r*r，H*r，W*r)其中r为重排因子。它基本上将深度(通道)转换为空间(高度和宽度)。在生成器中，pixelshuffling用于对图像大小进行向上采样。</p></blockquote><h2 id="60f1" class="la jv hi bd jw lb lc ld ka le lf lg ke iq lh li ki iu lj lk km iy ll lm kq ln bi translated"><strong class="ak">发电机</strong></h2><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lo"><img src="../Images/bbcf3a24c387a913f152fc8d0059307b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*dp9v_G6gQwg1gRzNsywEpw.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">发电机组</figcaption></figure><p id="e10e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是实现中使用的生成器模块。首先在构造函数中定义必要的操作，然后在forword函数中使用它们来构建网络。块2至块6是剩余网络，PRelu用于块9和块10。</p><h2 id="8a6b" class="la jv hi bd jw lb lc ld ka le lf lg ke iq lh li ki iu lj lk km iy ll lm kq ln bi translated"><strong class="ak">鉴别器</strong></h2><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lp"><img src="../Images/e869aa36f0663bf420d5ecfe16aa7821.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*l1ypTau4V2F7kurJKG30VA.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">鉴别器</figcaption></figure><p id="793c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是参考文献中使用的鉴频器网络。增加一个额外的脱落层，以停用一定比例的鉴别器神经元，从而防止鉴别器超过发生器的功率。</p><h1 id="aafc" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">损失函数</h1><p id="c40f" class="pw-post-body-paragraph if ig hi ih b ii lq ik il im lr io ip iq ls is it iu lt iw ix iy lu ja jb jc hb bi translated">在这个实现中，对于鉴别器正常的反向串行丢失。</p><h2 id="10c1" class="la jv hi bd jw lb lc ld ka le lf lg ke iq lh li ki iu lj lk km iy ll lm kq ln bi translated"><strong class="ak">鉴别器损耗</strong></h2><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lv"><img src="../Images/e5806444b82d1aa53ff9162822eb801d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*6l97OAUDkMaIJS7aM_dmrg.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">鉴频器损耗</figcaption></figure><p id="84ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，LR图像被传递到生成器中以生成高分辨率图像，然后将这些生成的图像以及原始HR图像传递到鉴别器以分别获得伪标签和真标签。然后，通过给原始HR图像分别标上0和1的标签，训练鉴别器来鉴别生成的图像是假图像，而原始HR图像是真实图像。disc_loss实际上是二元交叉熵损失。</p><h2 id="b5e9" class="la jv hi bd jw lb lc ld ka le lf lg ke iq lh li ki iu lj lk km iy ll lm kq ln bi translated"><strong class="ak">发电机损耗</strong></h2><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lw"><img src="../Images/e90a75877a4afb67a14dd3dde5caaba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jiR2qHR2QaIsmhj6yFkGfA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">发电机损耗</figcaption></figure><p id="160d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">发生器损耗实际上是GAN中使用的正常发生器损耗、内容损耗和像素间平均损耗之和。首先，将生成的图像传入鉴别器得到的假标签作为一个标签。这意味着生成器正在传送鉴别器，该鉴别器正在生成高分辨率图像，而鉴别器认为该图像不是高分辨率图像。</p><p id="043f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这样就实现了GAN的最小-最大博弈规则。同时，还使用了内容损失(vgg损失)。在这种情况下，生成的图像和HR图像通过第二层预训练的vgg19(用于匹配特征),然后计算平均损失。同时，还计算生成的图像和HR图像之间的像素到像素均方误差。所有这3个损耗相加，形成SRGAN的发电机损耗。</p><p id="784c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了优化，Adam optimizer以0.0001的学习率使用。</p><h1 id="bb6d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">参考</h1><p id="9ee8" class="pw-post-body-paragraph if ig hi ih b ii lq ik il im lr io ip iq ls is it iu lt iw ix iy lu ja jb jc hb bi translated"><a class="ae jd" href="https://arxiv.org/pdf/1609.04802.pdf" rel="noopener ugc nofollow" target="_blank">斯尔根纸业</a></p><h1 id="8e58" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">履行</h1><p id="1c80" class="pw-post-body-paragraph if ig hi ih b ii lq ik il im lr io ip iq ls is it iu lt iw ix iy lu ja jb jc hb bi translated"><a class="ae jd" href="https://github.com/vishal1905/Super-Resolution" rel="noopener ugc nofollow" target="_blank"> Github </a></p></div></div>    
</body>
</html>