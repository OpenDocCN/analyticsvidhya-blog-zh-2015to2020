<html>
<head>
<title>Probabilities in Machine Learning| Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的概率|第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/probabilities-in-machine-learning-bf9344e93b9?source=collection_archive---------27-----------------------#2020-08-17">https://medium.com/analytics-vidhya/probabilities-in-machine-learning-bf9344e93b9?source=collection_archive---------27-----------------------#2020-08-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/79baaa3d227d6eb0b51047fde3652fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MMlBbNggQ4LQKZI-4sOA2A.jpeg"/></div></div></figure><h1 id="8736" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">简介:</h1><p id="c91c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">当人类基于有限的经验和信息做出决策时，我们会做出推论来填补空白。在机器学习中，这是通过朴素贝叶斯分类来完成的。</p><h1 id="9a35" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是朴素贝叶斯分类？</h1><p id="b547" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">朴素贝叶斯分类是一种通过对特征的概率实施贝叶斯定理来对数据进行分类的算法。</p><h2 id="affd" class="km ir hi bd is kn ko kp iw kq kr ks ja jz kt ku je kd kv kw ji kh kx ky jm kz bi translated">朴素贝叶斯分类的优点:</h2><ul class=""><li id="2b56" class="la lb hi jq b jr js jv jw jz lc kd ld kh le kl lf lg lh li bi translated">处理小型数据集</li></ul><p id="0d18" class="pw-post-body-paragraph jo jp hi jq b jr lj jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ln kj kk kl hb bi translated">与传统的神经网络不同，在传统的神经网络中，每个神经元与其他每个神经元直接相连，概率被认为是独立的。</p><ul class=""><li id="916e" class="la lb hi jq b jr lj jv lk jz lo kd lp kh lq kl lf lg lh li bi translated">计算不密集</li></ul><p id="a96f" class="pw-post-body-paragraph jo jp hi jq b jr lj jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ln kj kk kl hb bi translated">与驱动神经网络的权重不同，朴素贝叶斯分类的参数不会在每次迭代中改变。这使得该算法的计算量大大降低。</p><h2 id="bcd8" class="km ir hi bd is kn ko kp iw kq kr ks ja jz kt ku je kd kv kw ji kh kx ky jm kz bi translated">朴素贝叶斯分类的缺点:</h2><ul class=""><li id="b2b4" class="la lb hi jq b jr js jv jw jz lc kd ld kh le kl lf lg lh li bi translated">不擅长学习大数据</li></ul><p id="4692" class="pw-post-body-paragraph jo jp hi jq b jr lj jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ln kj kk kl hb bi translated">当数据足以优化所有参数时，神经网络的复杂映射胜过朴素贝叶斯算法的简单结构。</p><h1 id="723b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">在Python中实现朴素贝叶斯分类；</h1><p id="6603" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">朴素贝叶斯分类实际上非常简单。让我们以分类一串文本来自垃圾邮件还是合法邮件为例。</p><h2 id="6123" class="km ir hi bd is kn ko kp iw kq kr ks ja jz kt ku je kd kv kw ji kh kx ky jm kz bi translated"><strong class="ak">第一步|创建数据:</strong></h2><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="dcb6" class="km ir hi lw b fi ma mb l mc md">len_normal = 500</span><span id="d53b" class="km ir hi lw b fi me mb l mc md">normal_dict = {<br/>    'Hello':10,<br/>    'Dinner':10,<br/>    'Dear':400,<br/>    'Please':300,<br/>    'Money':0<br/>}</span><span id="ab8b" class="km ir hi lw b fi me mb l mc md">len_spam = 150</span><span id="9ad8" class="km ir hi lw b fi me mb l mc md">spam_dict = {<br/>    'Hello':100,<br/>    'Dinner':0,<br/>    'Dear':0,<br/>    'Please':2,<br/>    'Money':100<br/>}</span></pre><p id="aa91" class="pw-post-body-paragraph jo jp hi jq b jr lj jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ln kj kk kl hb bi translated">这是在正常电子邮件或垃圾邮件的数据集中可以找到的某个单词的数量。len_normal和len_spam稍后用于计算该术语出现在电子邮件中的概率。</p><h2 id="6245" class="km ir hi bd is kn ko kp iw kq kr ks ja jz kt ku je kd kv kw ji kh kx ky jm kz bi translated">第2步|将计数改为概率:</h2><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="c044" class="km ir hi lw b fi ma mb l mc md">def count_to_probability(normal_dict,spam_dict,len_normal,len_spam):<br/>    for term in normal_dict:<br/>        normal_dict[term] = normal_dict[term]/len_normal<br/>    for term in spam_dict:<br/>        spam_dict[term] = spam_dict[term]/len_spam<br/>    return normal_dict,spam_dict</span></pre><p id="1846" class="pw-post-body-paragraph jo jp hi jq b jr lj jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ln kj kk kl hb bi translated">通过将每个计数除以所有正常或垃圾邮件中的总字数，一个单词出现在电子邮件中的概率。</p><h2 id="9099" class="km ir hi bd is kn ko kp iw kq kr ks ja jz kt ku je kd kv kw ji kh kx ky jm kz bi translated">步骤3|计算新字符串的概率:</h2><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="bdd8" class="km ir hi lw b fi ma mb l mc md">X = 'Hello Please Money'<br/>def calculate_probability(dictionary,X):<br/>    split = X.split()<br/>    probability = 1<br/>    for term in split:<br/>        probability *= dictionary[term]<br/>    return probability</span></pre><p id="50e5" class="pw-post-body-paragraph jo jp hi jq b jr lj jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ln kj kk kl hb bi translated">根据贝叶斯定理，通过乘以相应项的概率，可以找到整个字符串是垃圾邮件还是正常的概率。我不打算深入贝叶斯定理的细节，但是你可以在这里<a class="ae mf" href="https://www.youtube.com/watch?v=HZGCoVF3YvM" rel="noopener ugc nofollow" target="_blank">研究一下</a>。计算出最终概率后，比较将该函数应用于垃圾邮件字典时的值。较高的值是网络的最终预测值。</p><p id="ce5d" class="pw-post-body-paragraph jo jp hi jq b jr lj jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ln kj kk kl hb bi translated"><strong class="jq hj">奖励步骤|填充:</strong></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="b5b8" class="km ir hi lw b fi ma mb l mc md">def padding(dictionary,alpha):<br/>    for term in dictionary:<br/>        dictionary[term] += alpha<br/>    return dictionary</span></pre><p id="d7e0" class="pw-post-body-paragraph jo jp hi jq b jr lj jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ln kj kk kl hb bi translated">您会注意到，字符串X中的一些单词在字典中的值为0。这使得很难做出好的预测，因为当值乘以0时，计算的概率也将是0。一种常见的做法是为字典中的每个术语添加一个alpha值，以防止值为0。</p><h1 id="48e3" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">感谢您阅读本文！</h1></div></div>    
</body>
</html>