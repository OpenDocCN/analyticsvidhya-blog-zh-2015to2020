<html>
<head>
<title>Speech detection using Mel-Frequency(MFCC) in R Studio!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">语音检测使用梅尔频率(MFCC)在 R 工作室！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/speech-detection-using-mel-frequency-mfcc-in-r-studio-c8582f6ecfe0?source=collection_archive---------2-----------------------#2020-08-05">https://medium.com/analytics-vidhya/speech-detection-using-mel-frequency-mfcc-in-r-studio-c8582f6ecfe0?source=collection_archive---------2-----------------------#2020-08-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="5407" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">借助 MFCC(梅尔频率倒谱系数)特征提取实现语音检测的实用指南。</h2></div><p id="4925" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">研究的目的是从数据库中提取特征。wav 文件。讲话也反映了人的心情和他们说话时的情绪状态。</p><p id="1d07" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">例如，当我们最喜欢的球队赢了比赛，一个朋友打电话给我们，通常我们会带着兴奋的语气和朋友交谈。同样，如果你早上和男朋友吵了一架，你的语气或与出租车司机的对话可能是愤怒或悲伤的(基于你的情绪状况)。</p><p id="0668" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这个实验中，我们展示了从语音信号中提取特征的实际实现。</p><p id="aa67" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里，我们没有解释音频信号是如何形成的，或者 MFCC 的步骤..比如什么是预加重和 Mel-filter 等等。关于这一点有很多研究和文章，你可以从网上查阅或者从这里了解。</p><p id="de40" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请注意，除了 MFCC，还有许多其他技术可以从音频信号中提取特征，如线性预测系数(LPC)、离散小波变换(DWT)等。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es kb"><img src="../Images/615bf995e6d6f4b7e03c607d1cc55ff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HjdczhtrKFPSnRFx"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">由<a class="ae jt" href="https://unsplash.com/@jasonrosewell?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰森·罗斯韦尔</a>在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="f5ef" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该项目可以从商业角度实施，</p><ol class=""><li id="02e6" class="kr ks hi iz b ja jb jd je jg kt jk ku jo kv js kw kx ky kz bi translated"><strong class="iz hj"> Telecallers: </strong>团队中哪个人更有效率，为什么！我们能否从最好的远程呼叫者中找出参数(如语气、交谈时间、潜在客户互动等)来培训初级远程呼叫者！</li><li id="6cab" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js kw kx ky kz bi translated"><strong class="iz hj">销售:</strong>更好和正确的销售电话分析，这可以通过使用 NLP 和语音分析来完成。哪个业务员谈什么？用哪种情绪，哪种语气？客户的反应和语气如何？这些和更多的参数可以帮助公司微调他们的销售人员。</li><li id="1c76" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js kw kx ky kz bi translated"><strong class="iz hj">招聘:</strong>借助过去的面试数据，以及当前表现最佳的资源，可以引导企业精心挑选未来最聪明的头脑。一般来说，面试官会说，只需不到 2-4 分钟的初步互动，就能决定受访者是否适合该公司。这也是面试官根据他们长期的面试经验和谈话方式以及他们谈话时的自信和情绪来决定的。</li></ol></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lf"><img src="../Images/dcb65247ac9d07d6ccee1baa53a45d72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EyJzTz0TMzl0rj6-"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated"><a class="ae jt" href="https://unsplash.com/@magicbowls?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">神奇碗</a>在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="f8a5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">MFCC(Mel-频率倒谱系数)在 R Studio 中的实现:</strong></p><p id="31c2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这项研究中，我们使用了 R studio 中的内置库，</p><pre class="kc kd ke kf fd lg lh li lj aw lk bi"><span id="e7a5" class="ll lm hi lh b fi ln lo l lp lq">library(wrassp)</span><span id="e351" class="ll lm hi lh b fi lr lo l lp lq">library(readr)</span><span id="45b6" class="ll lm hi lh b fi lr lo l lp lq">library(tuneR)</span><span id="dd5a" class="ll lm hi lh b fi lr lo l lp lq">library(signal)</span><span id="6a9a" class="ll lm hi lh b fi lr lo l lp lq">library(oce)</span></pre><p id="2b25" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">任何数据分析的一个重要部分是数据收集。为了这项研究，我们对一些进行了分类。wav 文件具有不同的音调/情绪，如愤怒、激动、正常、悲伤等。</p><p id="b45f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，在我们为一项研究处理实际数据之前，我将让您基本了解为什么 MFCC 对于使用声谱图进行特征提取很重要。这里我们取一个简单的。wav 文件并创建了一个没有 MFCC 和 MFCC 数据矩阵的声谱图。</p><p id="a226" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">加载。wav 文件数据，以及</p><pre class="kc kd ke kf fd lg lh li lj aw lk bi"><span id="d74e" class="ll lm hi lh b fi ln lo l lp lq">path = 'male.wav'</span><span id="61bd" class="ll lm hi lh b fi lr lo l lp lq">audio = readWave('male.wav')</span></pre><p id="d4a4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">检查的组件和结构。wav 文件数据。</p><pre class="kc kd ke kf fd lg lh li lj aw lk bi"><span id="1437" class="ll lm hi lh b fi ln lo l lp lq">&gt; str(audio)</span><span id="c22b" class="ll lm hi lh b fi lr lo l lp lq">Formal class ‘Wave’ [package “tuneR”] with 6 slots<br/> ..@ left : int [1:408226] -79 -104 -153 -175 -201 -209 -231 -224 -233 -221 …<br/> ..@ right : num(0) <br/> ..@ stereo : logi FALSE<br/> ..@ samp.rate: int 8000<br/> ..@ bit : int 16<br/> ..@ pcm : logi TRUE</span></pre><blockquote class="ls lt lu"><p id="d1ca" class="ix iy lv iz b ja jb ij jc jd je im jf lw jh ji jj lx jl jm jn ly jp jq jr js hb bi translated"><strong class="iz hj"> <em class="hi">我们在实际的语音检测分析中也面临着一些限制，</em> </strong></p><p id="563c" class="ix iy lv iz b ja jb ij jc jd je im jf lw jh ji jj lx jl jm jn ly jp jq jr js hb bi translated"><em class="hi"> 1。如果音频文件是 1000 或 5000，我们需要加载每个文件。因此，我们需要重复相同的代码将文件加载到系统中。这意味着我们每次都需要使用 readWave()来加载文件。</em></p><p id="b4a5" class="ix iy lv iz b ja jb ij jc jd je im jf lw jh ji jj lx jl jm jn ly jp jq jr js hb bi translated"><em class="hi"> 2。在现实生活中，并不是每个文件都有相同的大小，例如在 telecallers 数据文件中，没有一个调用具有相同的元素和信号大小。因此，为了训练语音检测模型，我们需要确保每个元素都具有相同的大小，例如，@ left: int [1: 1000000]等，</em></p><p id="5479" class="ix iy lv iz b ja jb ij jc jd je im jf lw jh ji jj lx jl jm jn ly jp jq jr js hb bi translated"><em class="hi">把这两点记下，我会在学习中进一步说明。</em></p></blockquote><p id="285f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是怎么回事？wav 文件看起来像信号形式，为此我们使用 plot()绘制图形。</p><pre class="kc kd ke kf fd lg lh li lj aw lk bi"><span id="3ec6" class="ll lm hi lh b fi ln lo l lp lq">plot(audio@left[10:408226], type ='l', col = 'seagreen', xlab = 'Elements / Time', ylab = 'Freq', main = 'Audio Frequency Wave')</span></pre><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lz"><img src="../Images/f108b4ca26116d0442a97fc6fb13079a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gNc9WxNVpqAfervIpyJcUQ.png"/></div></div></figure><blockquote class="ls lt lu"><p id="1924" class="ix iy lv iz b ja jb ij jc jd je im jf lw jh ji jj lx jl jm jn ly jp jq jr js hb bi translated"><em class="hi">注意:在这个音频文件中，一名男性正在连续讲话，因此我们看不到信号中断。我们选择了从 10 到 408226 的元素。</em></p></blockquote></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="5b6b" class="ll lm hi bd ma mb mc md me mf mg mh mi jg mj mk ml jk mm mn mo jo mp mq mr ms bi translated">用 R studio 中的 MFCC 进行特征提取</h2><p id="60dc" class="pw-post-body-paragraph ix iy hi iz b ja mt ij jc jd mu im jf jg mv ji jj jk mw jm jn jo mx jq jr js hb bi translated">有关 melfcc()函数的更多详细信息，也可以访问— <a class="ae jt" href="https://www.rdocumentation.org/packages/tuneR/versions/1.3.3/topics/melfcc" rel="noopener ugc nofollow" target="_blank"> RDocumentation </a></p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es my"><img src="../Images/c29e682b322fcc5c68b1be69d30dbcd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*22YaH1ooHEJfdNlIVTYj7w.jpeg"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">IFC.com</figcaption></figure><pre class="kc kd ke kf fd lg lh li lj aw lk bi"><span id="92e3" class="ll lm hi lh b fi ln lo l lp lq">sr = audio@samp.rate         # samp rate in Hz<br/> <br/> <br/> mfcc.m = melfcc(audio, sr = sr,<br/>     wintime = 0.015,        # Window length<br/>     hoptime = 0.005,        # Successive windown inbetween<br/>   # numcep = 3,             # By default it will be 12 features<br/>     sumpower = TRUE,        # frequence scale transformation based on powerspectrum<br/>     nbands = 40,            # Number of spectra bands, filter banks<br/>     bwidth = 1,             # Width of spectral bands<br/>     preemph = 0.95,         # pre Emphasis<br/>   # frames_in_rows = TRUE)</span></pre><p id="5710" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">melfcc()函数的输出存储在 mfcc.m 中，它有 12 个特性。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es mz"><img src="../Images/f212fbcf8d60b72340371a72b95e2c3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gqdYHAZIPlpm0WjukFUtvQ.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">输出矩阵</figcaption></figure><p id="262a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">几个重要提示:</strong></p><ul class=""><li id="ad47" class="kr ks hi iz b ja jb jd je jg kt jk ku jo kv js na kx ky kz bi translated">mfcc.m 数据集是一个 10203 * 12 的矩阵，其中的行有 10203 个观测值。</li><li id="0be6" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js na kx ky kz bi translated">行数取决于音频文件的长度，因为您记得“音频”文件包含从 0:408226 开始的元素。</li><li id="4df4" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js na kx ky kz bi translated">如果我们有 1000 或 5000 个。wav 文件，那么我们需要为所有不同长度的。wav 文件。</li><li id="a145" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js na kx ky kz bi translated">这是非常重要的，因为一般来说，从卡格尔和 UCI 的数据集的长度。wav 数据文件被设置(让我们说 0:50000 元素，这对于所有的。wav 数据文件)。但是在现实世界中，数据文件的长度并不相同。</li><li id="d06a" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js na kx ky kz bi translated">为什么设置所有的？具有相同元素的 wav 文件。因为，正如我们从 melfcc()中观察到的，该函数将创建 n 个观察值(在上面的例子中是 10203)。这将有助于我们进一步的研究，语音检测的研究。</li><li id="0496" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js na kx ky kz bi translated">要运行任何监督学习模型来预测结果，假设在这种情况下，我们想知道客户是否对某个特定的远程呼叫者满意！基于语音检测技术，我们可以在与客户互动时对好的远程呼叫员或粗鲁/不良的远程呼叫员进行分类。突然之间，我们可以采取相应的行动，而不是等待客户投诉或因为电话公司的不良行为而失去客户。</li><li id="5129" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js na kx ky kz bi translated">比如基于 5000。wav 数据文件我们以矩阵形式提取特征，现在要使用这些数据作为监督学习模型的输入，我们需要将这 5000 个矩阵转换成一个数据帧。</li><li id="c00d" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js na kx ky kz bi translated">对于数据帧，我们首先简单地将所有矩阵转换成向量，然后将它们绑定到一个数据帧中。</li><li id="6df7" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js na kx ky kz bi translated">现在，如果向量的大小不同，将不会创建数据框，因此将所有 5000 的元素大小设置为相同非常重要。wav 数据文件。</li></ul></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="ac53" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">小技术！休息一下，然后重新开始:)听听这首歌— <a class="ae jt" href="https://www.youtube.com/watch?v=FM7MFYoylVs" rel="noopener ugc nofollow" target="_blank">这里</a></p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es nb"><img src="../Images/2e4d01dca1130ca6d01eeccb2cee0ff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LAKw1QkR9d2RJpfL"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">由<a class="ae jt" href="https://unsplash.com/@mvdheuvel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马腾·范登赫维尔</a>在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="99f5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">好了，到目前为止，我们已经讨论了声音信号的特征提取，以及如何从商业角度利用这一点。</p><p id="8a74" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，我还会展示原始信号数据和 mfcc 特性数据的频谱图。我们将比较这两个声谱图，并检查 MFCC 特征提取在语音检测中是否真的有所不同！</p><p id="9a0b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">在绘制频谱图之前，我们做了两件事，</strong></p><ol class=""><li id="0f1f" class="kr ks hi iz b ja jb jd je jg kt jk ku jo kv js kw kx ky kz bi translated">定义了光谱图的参数，并</li><li id="4849" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js kw kx ky kz bi translated">将全局函数()设置为 spectrogram {…}(您可以为函数取任何名称)</li></ol><pre class="kc kd ke kf fd lg lh li lj aw lk bi"><span id="0f5b" class="ll lm hi lh b fi ln lo l lp lq">1. </span><span id="7ff2" class="ll lm hi lh b fi lr lo l lp lq"># Determine duration</span><span id="ef62" class="ll lm hi lh b fi lr lo l lp lq">dur = length(mfcc.m)/audio@samp.rate<br/>dur # in seconds</span><span id="351c" class="ll lm hi lh b fi lr lo l lp lq"># d=Determine sample rate</span><span id="16ea" class="ll lm hi lh b fi lr lo l lp lq">fs = audio@samp.rate<br/>fs # in Hz</span><span id="0e7d" class="ll lm hi lh b fi lr lo l lp lq">## Spectrogram parameters</span><span id="6757" class="ll lm hi lh b fi lr lo l lp lq">nfft = 512    #Fast Fourier Transformation size can be 512 (default), 1024 or 2048.</span><span id="896e" class="ll lm hi lh b fi lr lo l lp lq">window = 1500</span><span id="c0a6" class="ll lm hi lh b fi lr lo l lp lq">overlap = 500</span></pre><p id="f15c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi">.</p><pre class="kc kd ke kf fd lg lh li lj aw lk bi"><span id="6bd7" class="ll lm hi lh b fi ln lo l lp lq">2. </span><span id="221c" class="ll lm hi lh b fi lr lo l lp lq"># Creater a global function called 'spectrogram'</span><span id="955b" class="ll lm hi lh b fi lr lo l lp lq">spectrogram = function(a) {</span><span id="d273" class="ll lm hi lh b fi lr lo l lp lq"># Define Parameters</span><span id="5180" class="ll lm hi lh b fi lr lo l lp lq">spec = specgram(x = a,<br/>                n = nfft,<br/>                Fs = fs,<br/>                window = window,<br/>                overlap = overlap)</span><span id="5fe0" class="ll lm hi lh b fi lr lo l lp lq"># Structure of 'spec'</span><span id="d88f" class="ll lm hi lh b fi lr lo l lp lq">str(spec)</span><span id="4f51" class="ll lm hi lh b fi lr lo l lp lq">P = abs(spec$S)</span><span id="e91a" class="ll lm hi lh b fi lr lo l lp lq"># Normalize<br/>P = P/max(P)     # If we do without abs(*) it will creat NA</span><span id="7f3d" class="ll lm hi lh b fi lr lo l lp lq"># Convert to dB<br/>P = 10*log10(P)</span><span id="5e92" class="ll lm hi lh b fi lr lo l lp lq"># config time axis<br/>t = spec$t</span><span id="1aa5" class="ll lm hi lh b fi lr lo l lp lq"># plot spectrogram</span><span id="a689" class="ll lm hi lh b fi lr lo l lp lq">imagep(x = t,<br/>       y = spec$f,<br/>       z = t(P),<br/>       col = oce.colorsViridis,<br/>       ylab = 'Frequency in Hz',<br/>       xlab = 'Time in Sec',<br/>       main = 'Spectrogram',<br/>       drawPalette = T,<br/>       decimate = F)</span><span id="3b94" class="ll lm hi lh b fi lr lo l lp lq">}</span><span id="bc69" class="ll lm hi lh b fi lr lo l lp lq"># Spectrogram without MFCC</span><span id="400e" class="ll lm hi lh b fi lr lo l lp lq">without.mfcc = spectrogram(as.matrix(audio@left))</span><span id="0843" class="ll lm hi lh b fi lr lo l lp lq"># Spectrogram with MFCC</span><span id="5c2d" class="ll lm hi lh b fi lr lo l lp lq">with.mfcc = spectrogram(mfcc.m)</span></pre><p id="bbdf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">没有 MFCC: </strong></p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es nc"><img src="../Images/866d7d12bed30b899d4ac3b68e46f161.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C9Fz1ojVwLxpofKAu8t3ig.png"/></div></div></figure><p id="75b1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">与 MFCC: </strong></p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es nc"><img src="../Images/2f738fb523a36406eac5c468dbef5fa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LoNpwePT3PwPQYVXq1e3-w.png"/></div></div></figure><p id="7a59" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在比较两个频谱图之后，我们可以清楚地识别出频率被转换到 Mel 频率标度。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="4ef9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">R studio 中的详细代码，也可以访问— <a class="ae jt" href="https://github.com/RutvijBhutaiya/Speech-detection-using-Mel-Frequency-MFCC" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="ceaa" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在 Github 上，我添加了两个代码文件，</p><ol class=""><li id="8557" class="kr ks hi iz b ja jb jd je jg kt jk ku jo kv js kw kx ky kz bi translated">基础知识。r 用于特征提取和声谱图，</li><li id="a563" class="kr ks hi iz b ja la jd lb jg lc jk ld jo le js kw kx ky kz bi translated">MFCC 函数+声谱图函数。r 代表一个以上。wav 文件。在这个文件中，我捕获了四个。wav 文件，但也可以加载更多。wav 文件根据他们的研究要求。</li></ol><div class="nd ne ez fb nf ng"><a href="https://github.com/RutvijBhutaiya/Speech-detection-using-Mel-Frequency-MFCC" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">rutvijbhutaya/使用 Mel 频率的语音检测-MFCC</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">一个实用指南，以实现语音检测的帮助下，MFCC(梅尔频率倒谱系数)的特点…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">github.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu kl ng"/></div></div></a></div></div></div>    
</body>
</html>