<html>
<head>
<title>Walmart Recruiting — Store Sales Forecasting — Kaggle Competition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">沃尔玛招聘—商店销售预测— Kaggle竞争</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/walmart-recruiting-store-sales-forecasting-kaggle-competition-856c72c9265a?source=collection_archive---------1-----------------------#2019-11-25">https://medium.com/analytics-vidhya/walmart-recruiting-store-sales-forecasting-kaggle-competition-856c72c9265a?source=collection_archive---------1-----------------------#2019-11-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if"><p id="fa2a" class="ig ih hi bd ii ij ik il im in io ip dx translated">一个不老练的预测者使用统计数据，就像一个醉汉使用灯柱一样——为了支持而不是为了照明<em class="iq">—安德鲁·朗之后</em></p></blockquote><div class="ir is it iu iv ab cb"><figure class="iw ix iy iz ja jb jc paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/a768a7da9a0f146395a7426e6d5eb1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*VfoHjOy5D3FPAYXiupM0Vg.jpeg"/></div></figure><figure class="iw ix jj iz ja jb jc paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/d1bd40e6ed57ef84b6e5c42ac36f10c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*WYB4NUppOhTTuaRgM8yLBA.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx jo di jp jq translated"><strong class="bd jr">图一:沃尔玛零售店</strong></figcaption></figure></div></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><blockquote class="jz ka kb"><p id="bee9" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">销售预测是估计未来销售的过程。准确的销售预测使公司能够做出明智的商业决策，并预测短期和长期业绩。</p><p id="6539" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">公司可以根据过去的销售数据、行业范围的比较和经济趋势做出预测。</p><p id="8076" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">在这种情况下，这家公司就是沃尔玛。名字够好听！！！</p></blockquote><h1 id="77e7" class="la lb hi bd jr lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">项目概述:</h1><ul class=""><li id="8fdf" class="lx ly hi kf b kg lz kk ma mb mc md me mf mg ip mh mi mj mk bi translated"><strong class="kf hj">第1部分:</strong>带评估指标的Kaggle问题定义。</li><li id="e5bb" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated"><strong class="kf hj"> Part-2: </strong>探索性数据分析(EDA) <em class="ke">。</em></li><li id="0185" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated"><strong class="kf hj">第三部分:</strong>数据预处理</li><li id="1cd9" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated"><strong class="kf hj">第四部分:</strong>时间序列模型。</li><li id="b42d" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated"><strong class="kf hj">第五部分:</strong>机器学习回归模型。</li></ul></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="a679" class="la lb hi bd jr lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw bi translated"><strong class="ak">第1部分:</strong>带评估指标的Kaggle问题定义:</h1><h2 id="4ac9" class="mv lb hi bd jr mw mx my lf mz na nb lj mb nc nd ln md ne nf lr mf ng nh lv ni bi translated">问题定义:</h2><ul class=""><li id="a674" class="lx ly hi kf b kg lz kk ma mb mc md me mf mg ip mh mi mj mk bi translated">沃尔玛提供了位于不同地区的45家沃尔玛商店的历史销售数据。每个商店包含许多部门，给定的任务是预测每个商店的部门范围内的销售额。</li><li id="5d6b" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">此外，沃尔玛全年都会举办几次促销活动。这些降价发生在重要的节日之前，其中四个最大的节日是超级碗、劳动节、感恩节和圣诞节。</li><li id="88b9" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">包含这些假期的周在评估中的权重是非假期周的五倍。这项比赛的部分挑战是在缺乏完整/理想的历史数据的情况下，模拟降价对这些假日周的影响。</li><li id="8b0c" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">ka ggle-这个问题的链接可以在<a class="ae nj" href="https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting" rel="noopener ugc nofollow" target="_blank"> <em class="ke">这里找到</em> </a>。</li></ul><h2 id="51df" class="mv lb hi bd jr mw mx my lf mz na nb lj mb nc nd ln md ne nf lr mf ng nh lv ni bi translated">评估指标:</h2><ul class=""><li id="0452" class="lx ly hi kf b kg lz kk ma mb mc md me mf mg ip mh mi mj mk bi translated">沃尔玛提供了加权平均绝对误差(WMAE)指标，其数学函数如下所示。</li></ul><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es nk"><img src="../Images/973045867ef89bedffef3a8b8853384f.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*VKYKK85ViLYUUjyOWVURfw.jpeg"/></div></figure><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es np"><img src="../Images/7b4e7a5946375dbcc32db34191f2447d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6pIxKUm6bTJcSt5n2igyjQ.jpeg"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图3:绩效指标(WMAE) </strong></figcaption></figure><ul class=""><li id="7c10" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">sklearn的任何库中都没有这个性能指标，因此挑战在于为这个评估指标编写数学脚本。很明显，我们的目标是在预测每周销售额的同时，尽可能降低这一分数。我们将在回归模型中使用这个性能指标。</li></ul></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="ff88" class="la lb hi bd jr lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw bi translated"><strong class="ak">第二部分:</strong>探索性数据分析(EDA):</h1><blockquote class="jz ka kb"><p id="72ca" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">在机器学习/深度学习中，必须知道什么是什么和如何是什么？到目前为止，我们已经知道了问题的定义，我们也清楚我们想要达到的目标。但我们如何实现它才是最重要的。为了前进，我们需要已经提供给我们的数据。我们将执行称为探索性数据分析的过程，这是一种分析数据集以总结其主要特征的方法，通常采用可视化方法。</p></blockquote><ul class=""><li id="d977" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">让我们先导入一组库。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="60bd" class="mv lb hi nu b fi ny nz l oa ob">import numpy as np<br/>import pandas as pd<br/>import scipy.stats as stats<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import mean_squared_error, mean_absolute_error<br/>from datetime import datetime<br/>import math</span><span id="fc0f" class="mv lb hi nu b fi oc nz l oa ob"># Importing the most popular regression libraries.<br/>from sklearn.linear_model import LinearRegression, <br/>from sklearn.neighbors import KNeighborsRegressor,<br/>from sklearn.linear_model import Ridge,<br/>from sklearn.linear_model import Lasso,<br/>from sklearn.tree import DecisionTreeRegressor,<br/>from sklearn.ensemble import RandomForestRegressor,<br/>from sklearn.ensemble import ExtraTreesRegressor,<br/>from xgboost import XGBRegressor<br/></span></pre><ul class=""><li id="dc0d" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">接下来，我们将csv文件中的数据加载到pandas数据框中，并检查其属性。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="b824" class="mv lb hi nu b fi ny nz l oa ob">#Loading the data from csv files.<br/>train=pd.read_csv('train.csv')<br/>features=pd.read_csv('features.csv')<br/>stores = pd.read_csv('stores.csv')</span></pre><div class="nl nm nn no fd ab cb"><figure class="iw ix od iz ja jb jc paragraph-image"><img src="../Images/af36b9f89df80e8b43ebe4a2913df643.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*Lw0lPnsu8gUvxtNjQqrQ-A.jpeg"/></figure><figure class="iw ix oe iz ja jb jc paragraph-image"><img src="../Images/87dca420fa300c73a8c00ad891cb6096.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*vfBhpWvZ11vQuJlRcUTW8g.jpeg"/><figcaption class="jk jl et er es jm jn bd b be z dx of di og jq translated"><strong class="bd jr">图-4: train.csv和store.csv </strong></figcaption></figure></div><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oh"><img src="../Images/55df5856c3992e54cedffcc03e19abac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IklhOVhmcXogF3V9n5JdHw.jpeg"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图5: features.csv </strong></figcaption></figure><ul class=""><li id="d32d" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">因为我们已经得到了三个不同的文件，所以我们将这些文件连接起来，形成新的数据文件作为数据。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="f6a5" class="mv lb hi nu b fi ny nz l oa ob">data = train.merge(features, on=['Store', 'Date'], how='inner').merge(stores, on=['Store'], how='inner')<br/>print(data.shape)</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oi"><img src="../Images/a77dbda6393dc44fc964f1414ca2c4bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qh77pRr5Z0aDBmiWRd9hzw.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图6:合并数据</strong></figcaption></figure><ul class=""><li id="3f46" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">总共有3种类型的店铺:A型，Type Band型C. <br/>总共有45家店铺。有关销售类型的更多信息如下所示。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="d77a" class="mv lb hi nu b fi ny nz l oa ob">sorted_type = stores.groupby('Type')<br/>plt.style.use('ggplot')<br/>labels=['A store','B store','C store']<br/>sizes=sorted_type.describe()['Size'].round(1)<br/>sizes=[(22/(17+6+22))*100,(17/(17+6+22))*100,(6/(17+6+22))*100] # convert to the proportion</span><span id="21a3" class="mv lb hi nu b fi oc nz l oa ob">fig, axes = plt.subplots(1,1, figsize=(10,10))</span><span id="0990" class="mv lb hi nu b fi oc nz l oa ob">wprops={'edgecolor':'black',<br/>      'linewidth':2}</span><span id="3219" class="mv lb hi nu b fi oc nz l oa ob">tprops = {'fontsize':30}</span><span id="a47c" class="mv lb hi nu b fi oc nz l oa ob">axes.pie(sizes,<br/>        labels=labels,<br/>        explode=(0.0,0,0),<br/>        autopct='%1.1f%%',<br/>        pctdistance=0.6,<br/>        labeldistance=1.2,<br/>        wedgeprops=wprops,<br/>        textprops=tprops,<br/>        radius=0.8,<br/>        center=(0.5,0.5))<br/>plt.show()</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es oj"><img src="../Images/6bc8bd8033a3ef84aeba62542e37b059.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/0*0E4Gvzgylh6-JKp_.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-7:店铺类型饼图</strong></figcaption></figure><ul class=""><li id="9710" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">我们了解到，A类商店的中位数高于其他商店类型的中位数，因此A类商店的周销售额高于其他商店类型。</li><li id="85d8" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">我们检查了节假日和非节假日的每周销售额。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="869a" class="mv lb hi nu b fi ny nz l oa ob">holiday = train_stores['Weekly_Sales'].loc[train_stores['IsHoliday']== True] # Weekly Sales in Holidays<br/>non_holiday = train_stores['Weekly_Sales'].loc[train_stores['IsHoliday']== False] #Weekly Sales in Non-holidays.</span><span id="47a2" class="mv lb hi nu b fi oc nz l oa ob">sns.barplot(x='IsHoliday', y='Weekly_Sales', data=train_stores)</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es ok"><img src="../Images/4ae3e70191cf473f8b1b7d1bf4de54bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*ltsZPQtFUQaF4EVDVKtziw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-8:周销售额与节假日</strong></figcaption></figure><ul class=""><li id="3f45" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">我们绘制了按部门和假日划分的每周销售额的箱线图。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="0594" class="mv lb hi nu b fi ny nz l oa ob">data_11= pd.concat([train_stores['Dept'], train_stores['Weekly_Sales'], train_stores['IsHoliday']], axis=1)<br/>plt.figure(figsize=(20,6))<br/>plt.title('Box Plot of Weekly Sales by Department and Holiday')<br/>fig = sns.boxplot(x='Dept', y='Weekly_Sales', data=data_11, showfliers=False, hue="IsHoliday")</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ol"><img src="../Images/a0be2e57481d5623af6217ded2b00216.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sRUsbFeBzHz22wz49lbB3Q.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-9:按部门和节假日划分的周销售额</strong></figcaption></figure><ul class=""><li id="9ef5" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">每月每周销售可视化也以下列方式进行。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="6a46" class="mv lb hi nu b fi ny nz l oa ob">data_14 = pd.concat([train_stores['Month'], train_stores['Weekly_Sales'], train_stores['IsHoliday']], axis=1)<br/>plt.figure(figsize=(20,6))<br/>plt.title('Box Plot of Weekly Sales by Month and Holiday')<br/>fig = sns.boxplot(x='Month', y='Weekly_Sales', data=data_14, showfliers=False, hue='IsHoliday')</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es om"><img src="../Images/ad1260335f9497b4bf2bdc8012d9eb34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RAV0r6Ew8DqmcY9C53qB5Q.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-10:按月份和节假日统计的周销售额</strong></figcaption></figure></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="3cc6" class="la lb hi bd jr lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw bi translated"><strong class="ak">第三部分:</strong>数据预处理:</h1><ul class=""><li id="fb46" class="lx ly hi kf b kg lz kk ma mb mc md me mf mg ip mh mi mj mk bi translated">这里，我们首先检查合并的数据文件中是否存在空值，我们发现在一些列中存在空值。我们用零代替空值。</li></ul><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es on"><img src="../Images/7aec2342ea8ab0e40d8dfc32524c21e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/1*Ah8oZsb3elVsr3_OCYSpxA.png"/></div></figure><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="c033" class="mv lb hi nu b fi ny nz l oa ob">data=data.fillna(0)<br/>data.isna().sum()</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es oo"><img src="../Images/f465821fd4bd8cf51cd685f5a9f2bd36.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*yyP48NViqj7erh0CVb8IbQ.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-11:每周销售额估算</strong></figcaption></figure><ul class=""><li id="d832" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">通过查看数据框的统计数据，我们知道有些行的周销售额为负值。由于销售额不能为负，我们跳过了周销售额为负的那些行。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="531b" class="mv lb hi nu b fi ny nz l oa ob">data = data[data['Weekly_Sales'] &gt;= 0]</span></pre><ul class=""><li id="f6df" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">我们绘制了相关矩阵，以查看这些特征之间是否存在任何相关性。我们执行此步骤是因为使用高度相关的特征没有意义，因为相关的特征在放入模型进行预测时会给出相同的信息。因此，更好的办法是识别这些，并级联相关的那些。我们来多了解一下吧。</li></ul><blockquote class="jz ka kb"><p id="0509" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated"><strong class="kf hj">相关矩阵:</strong></p><p id="250d" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">相关性是一种双变量分析，衡量两个变量之间的关联强度和关系方向。就关系的强度而言，相关系数的值在+1和-1之间变化。</p><p id="285d" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">值为1表示两个变量之间的完美关联程度。随着相关系数值趋向于0，两个变量之间的关系将变弱。关系的方向由系数的符号表示；加号表示正相关，减号表示负相关。通常，在统计学中，我们测量四种类型的相关性:皮尔逊相关性、肯德尔等级相关性和斯皮尔曼相关性。下面的图表会给你一个关于相关性的概念。</p></blockquote><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es op"><img src="../Images/45592ab4acb58c2ac6787eee63dcbee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sZIRmTtANB_dr0aC.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图12:相关矩阵</strong></figcaption></figure></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="2d00" class="la lb hi bd jr lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw bi translated"><strong class="ak">第四部分:</strong>时间序列模型:</h1><ul class=""><li id="4da9" class="lx ly hi kf b kg lz kk ma mb mc md me mf mg ip mh mi mj mk bi translated">因为数据文件包含日期字段，所以给定的数据集是一个时间序列数据集，其中根据每个日期提供了关于商店和部门的每周销售额。</li><li id="ffa9" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">因此，我们将应用一些流行的时间序列预测模型，即:<br/> 1。汽车ARIMA型号<br/> 2。霍尔特-温特斯模型</li></ul><h2 id="ebbd" class="mv lb hi bd jr mw mx my lf mz na nb lj mb nc nd ln md ne nf lr mf ng nh lv ni bi translated"><strong class="ak"> 1。自动ARIMA(自回归综合移动平均线):</strong></h2><blockquote class="jz ka kb"><p id="7b0a" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">ARIMA代表自回归综合移动平均模型。</p><p id="b2ae" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">单变量(单向量)ARIMA是一种预测技术，它完全基于序列自身的惯性来预测序列的未来值。</p></blockquote><ul class=""><li id="2072" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">下面给出了接近自动ARIMA模型的步骤。<br/> →加载数据。<br/> →及时可视化可用的单变量数据。<br/> →查看季节性分解参数，检查季节性、趋势等。有没有空。<br/> →使用一种时间序列平稳性方法进行平稳性测试。<br/> →如果时间序列是非平稳的，则使其平稳。<br/> →如果时间序列是平稳的，则无需使其平稳。<br/> →分割训练和测试中的单变量数据。<br/> →最重要的步骤是通过绘制ACF和PACF图，找到三元组p、d、q的适当值，其中p是自回归数，d是积分或差分，q是移动平均数。<br/> →一旦获得p、d、q的值，根据列车数据拟合ARIMA模型。<br/> →预测测试数据值，并在单一图表上绘制列车、测试和预测测试数据值的可视化。<br/> →计算预测值的均方根误差(RMSE)。</li></ul><blockquote class="jz ka kb"><p id="7d16" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">请注意，ARIMA或霍尔特-温特斯模型考虑了单变量数据。因此，我们使用Weekly_Sales列进行分析，因为我们需要预测该列在不久的将来的值。下图是迄今为止每周销售额的大致情况。</p></blockquote><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="4b02" class="mv lb hi nu b fi ny nz l oa ob">data.Date = pd.to_datetime(data.Date,format='%Y-%m-%d')<br/>data.index = data.Date<br/>data = data.drop('Date', axis=1)</span><span id="e74f" class="mv lb hi nu b fi oc nz l oa ob">data = data.resample('MS').mean() # Resmapling the time series data with month starting first.</span><span id="1908" class="mv lb hi nu b fi oc nz l oa ob"># Train-Test splitting of time series data<br/>train_data = data[:int(0.7*(len(data)))]<br/>test_data = data[int(0.7*(len(data))):]</span><span id="50b9" class="mv lb hi nu b fi oc nz l oa ob"># ARIMA takes univariate data.</span><span id="c9e3" class="mv lb hi nu b fi oc nz l oa ob">train_data = train_data['Weekly_Sales']<br/>test_data = test_data['Weekly_Sales']</span><span id="df85" class="mv lb hi nu b fi oc nz l oa ob"># Plot of Weekly_Sales with respect to years in train and test.<br/>train_data.plot(figsize=(20,8), title= 'Weekly_Sales', fontsize=14)<br/>test_data.plot(figsize=(20,8), title= 'Weekly_Sales', fontsize=14)<br/>plt.show()</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oq"><img src="../Images/c43c835a93239423ebf98090e2c19e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dijqe3BnzUZkF_tiSen0sw.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-13:周销售额</strong></figcaption></figure><ul class=""><li id="af47" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">时间序列模型假设给定的时间序列数据集在平稳意义下具有恒定的均值和恒定的方差。如果数据集是不稳定的，那么我们不会将时间序列模型原样应用于数据集。首先，我们使用平稳性方法使序列平稳，然后我们在其上应用时间序列模型。我们执行了Dicky Fuller检验来检查序列是否平稳。下面是它的实现。</li></ul><blockquote class="jz ka kb"><p id="951d" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">d<strong class="kf hj">Dicky Fuller平稳性检验:</strong> <br/> Dicky-Fuller检验时间序列数据中存在单位根的零假设。为了使事情更加清楚，这个测试检查平稳性或非平稳数据。该测试试图拒绝零假设，即单位根的存在和数据是非平稳的。如果零假设被拒绝，则替代假设可以被认为是有效的(例如，数据是固定的)。<br/>当我们运行测试时，我们将得到一个ADF值和一个p值。ADF数应该是负数，并且p值应该低于置信水平的某个阈值(例如1%或5%等)。这里，我们将使用5%(或95%的置信水平)，因此如果p值大于0.05，那么我们说我们无法拒绝零假设，因为数据有一个单位根，并且是非平稳的。如果p值小于或等于0.05，我们可以说我们拒绝零假设，因为数据没有单位根，是平稳的。</p></blockquote><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="f487" class="mv lb hi nu b fi ny nz l oa ob">from statsmodels.tsa.stattools import adfuller<br/>result = adfuller(data['Weekly_Sales'])<br/>print('ADF Statistic: {}'.format(result[0]))<br/>print('p-value: {}'.format(result[1]))<br/>print('Critical Values:')<br/>for key, value in result[4].items():<br/>    print('\t{}: {}'.format(key, value))</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es or"><img src="../Images/d9ec45c19fb8470dcd1e9f667a4aeff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*723pPpBtHv3YLwkA1bkXZA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图14:迪基-富勒平稳性检验</strong></figcaption></figure><ul class=""><li id="d973" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">正如我们可以看到的，我们的p值肯定小于0.5，甚至小于0.01，因此我们可以非常自信地说，我们可以拒绝零(单位根，非平稳数据)，并可以假设我们的数据是平稳的。此外，我们的ADF远小于我们的1%置信值-3.43，所以我们有另一个确认，我们可以拒绝零假设。</li><li id="de65" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">现在我们可以应用ARIMA模型了，因为数据集是固定的。</li><li id="e1ab" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">我们应用ARIMA模型进行了手动检查。它确实工作得很好，但是有一些小的限制。为了应用ARIMA，我们需要计算三联体值，即(p，d，q)。p的值是自动回归数，d的值是使序列稳定所需的差值数，q是移动平均数。为了计算p、d、q值，我们需要绘制自相关函数(ACF)和部分自相关函数(PACF)图。</li><li id="a54b" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">为了避免这种情况，我们使用了自动ARIMA而不是ARIMA，因为在ARIMA模型中，我们需要找到自动回归数(p)、移动平均数(q)和积分数(差值，d)的适当值，这既繁琐又耗时。在自动ARIMA中，我们可以看到三元组(p，q，d)值自动基于最少的AIC和BIC分数，更重要的是最符合模型。</li><li id="8476" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">这里需要注意的一点是，汽车ARIMA并不存在于统计模型中，它实际上存在于<strong class="kf hj">金字塔</strong>中。所以我们安装了金字塔，然后导入auto arima库。下面是实施汽车ARIMA到沃尔玛的数据集(每周销售额)。</li><li id="ab47" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">这里我们给出(p，q，d)三元组的范围为0到10。你可以把这想象成执行三个for循环，从p开始，然后q，最后计算AIC和BIC的分数。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="8f0f" class="mv lb hi nu b fi ny nz l oa ob">pip install pyramid-arima</span><span id="9987" class="mv lb hi nu b fi oc nz l oa ob"># Applying auto_arima model on train data.<br/>from pyramid.arima import auto_arima</span><span id="babb" class="mv lb hi nu b fi oc nz l oa ob">model_auto_arima = auto_arima(train_data, trace=True, error_action='ignore', suppress_warnings=True)<br/>model_auto_arima = auto_arima(train_data, trace=True,start_p=0, start_q=0, start_P=0, start_Q=0, max_p=10, max_q=10, max_P=10, max_Q=10, seasonal=True,stepwise=False, suppress_warnings=True, D=1, max_D=10,error_action='ignore',approximation = False)</span><span id="8bfb" class="mv lb hi nu b fi oc nz l oa ob">model_auto_arima.fit(train_data)</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es os"><img src="../Images/aaf9c50ce0ec9e090b49c24978180a2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L_vvO0OdUans6P11N6En0w.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-15:汽车ARIMA车型输出</strong></figcaption></figure><ul class=""><li id="eb42" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">应用自动ARIMA后我们得到的结果如下所示。该模型自动选择AIC和BIC得分最小的p、d、q值。在我们的例子中，p=0，q=0，d=2。</li></ul><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es ot"><img src="../Images/49960ff8951fdd1ac8c2de3c9650ec62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*3dSzBnLJHSmMG3R3OztqsA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图16:自动ARIMA最佳模型输出</strong></figcaption></figure><ul class=""><li id="fa9c" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">这里我们不需要知道p，d，q值。一旦我们得到了最佳拟合的模型，我们就继续预测测试值，并在单个图表上绘制训练、测试和预测值，随后我们找到MSE、RMSE和MAD值。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="eaf8" class="mv lb hi nu b fi ny nz l oa ob"># Predicting the test values using predict function.<br/>forecast = model_auto_arima.predict(n_periods=len(test_data))<br/>forecast = pd.DataFrame(forecast,index = test_data.index,columns=['Prediction'])<br/>plt.figure(figsize=(20,6))<br/>plt.title('Prediction of Weekly Sales using Auto ARIMA model', fontsize=20)<br/>plt.plot(train_data, label='Train')<br/>plt.plot(test_data, label='Test')<br/>plt.plot(forecast, label='Prediction using ARIMA Model')<br/>plt.legend(loc='best')<br/>plt.xlabel('Date', fontsize=14)<br/>plt.ylabel('Weekly Sales', fontsize=14)<br/>plt.show()</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es om"><img src="../Images/64316ecfa0f40b5dad194ca161373854.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lhBNMzoNhFgQMe6oW1KyLA.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图17:自动ARIMA结果</strong></figcaption></figure><ul class=""><li id="f3ee" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">以下是自动ARIMA的性能指标。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="9e06" class="mv lb hi nu b fi ny nz l oa ob"># Performance metric for ARIMA model -MSE/RMSE<br/>print('Mean Squared Error (MSE) of ARIMA: ', mean_squared_error(test_data, forecast))<br/>print('Root Mean Squared Error (RMSE) of ARIMA: ', math.sqrt(mean_squared_error(test_data, forecast)))<br/>print('Mean Absolute Deviation (MAD) of ARIMA: ', mean_absolute_error(test_data, forecast))</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es ou"><img src="../Images/4f4c65ce1044bd4df8cbc466a1bf35f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*b0n32k8IF82HfOT0elPIlg.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-18:自动ARIMA的性能指标</strong></figcaption></figure><p id="89ae" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><strong class="kf hj"> 2。霍尔特-温特斯法:</strong></p><blockquote class="jz ka kb"><p id="576f" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">Holt-Winters是一种时间序列模型，是一种对时间序列的三个方面进行建模的方法:典型值(平均值)、一段时间内的斜率(趋势)和周期性重复模式(季节性)。</p><p id="c919" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">Holt-Winters使用指数平滑对过去的大量值进行编码，并使用它们来预测现在和未来的“典型”值。</p></blockquote><ul class=""><li id="698e" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">以下是执行霍尔特-温特斯法所需的步骤。<br/> →加载数据。<br/> →及时可视化可用的单变量数据。<br/> →使用霍尔特-温特斯法对列车数据拟合模型。<br/> →使用测试数据预测数值。<br/> →在单一图形上可视化训练数据、测试数据和预测数据<br/> →计算预测数据的均方根误差(RMSE)。</li></ul><blockquote class="jz ka kb"><p id="6ef3" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">霍尔特-温特斯模型有水平，趋势和季节性参数可以寻找。在Holt-linear模型的早期版本中，没有引入季节性参数，因此如果数据集有季节性参数，那么早期模型将会失败。因此引入了Holt-Winters模型，它考虑了季节性参数。</p><p id="5a70" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">这也被称为三重指数平滑算法，因为它平滑水平，趋势和季节性指数。下面是霍尔特-温特斯方法的实现。</p></blockquote><ul class=""><li id="14c1" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">由于数据已经以时间序列格式组织，这里我们只需要应用Holt-Winters方法。下面是它的实现。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="f95d" class="mv lb hi nu b fi ny nz l oa ob"># Fitting the Holt-Winters method for Weekly Sales.<br/>from statsmodels.tsa.api import ExponentialSmoothing</span><span id="d029" class="mv lb hi nu b fi oc nz l oa ob">model_holt_winters = ExponentialSmoothing(train_data, seasonal_periods=7, trend='additive', seasonal='additive').fit() </span><span id="f543" class="mv lb hi nu b fi oc nz l oa ob">pred = model_holt_winters.forecast(len(test_data))# Predict the test data</span><span id="6c46" class="mv lb hi nu b fi oc nz l oa ob">#Visualize train, test and predicted data.<br/>plt.figure(figsize=(20,6))<br/>plt.title('Prediction of Weekly Sales using Holt-Winters model', fontsize=20)<br/>plt.plot(train_data, label='Train')<br/>plt.plot(test_data, label='Test')<br/>plt.plot(pred, label='Prediction using Holt Winters Methods')<br/>plt.legend(loc='best')<br/>plt.xlabel('Date', fontsize=14)<br/>plt.ylabel('Weekly Sales', fontsize=14)<br/>plt.show()</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ov"><img src="../Images/1d59e65e05fe15819eb1f438adeccb28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aoLOAp8AQLuKeyCTJaelZg.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-19:使用霍尔特-温特斯法的训练、测试和预测值</strong></figcaption></figure><p id="4523" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated">我们看到这种方法非常正确地拟合了试验值。下面是霍尔特-温特斯法的性能指标。</p><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="45e4" class="mv lb hi nu b fi ny nz l oa ob">print('Mean Squared Error (MSE) of Holt-Winters: ', mean_squared_error(test_data, pred))<br/>print('Root Mean Squared Error (RMSE) of Holt-Winters: ', math.sqrt(mean_squared_error(test_data, pred)))<br/>print('Mean Absolute Deviation (MAD) of Holt-Winters: ', mean_absolute_error(test_data, pred))</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es ow"><img src="../Images/b06f57607e8a914aafa29050928db62e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*dl8Qt7qR0p3OX-NOu7_ezw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图20:霍尔特-温特斯法的性能指标</strong></figcaption></figure></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="b6bb" class="la lb hi bd jr lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw bi translated"><strong class="ak">第五部分:</strong>机器学习回归模型:</h1><ul class=""><li id="309a" class="lx ly hi kf b kg lz kk ma mb mc md me mf mg ip mh mi mj mk bi translated">到目前为止，我们讨论的是使用时间序列方法预测每周销售额。现在，我们将使用传统的回归算法来预测销售额。</li><li id="629b" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">在这里，我们将使用以下回归模型进行每周销售预测。</li></ul><p id="a1b4" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><em class="ke"> 1。线性回归</em></p><p id="e53e" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><em class="ke"> 2。k最近邻回归</em></p><p id="5916" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><em class="ke"> 3。岭回归</em></p><p id="a3fa" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><em class="ke"> 4。拉索回归</em></p><p id="2e8d" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><em class="ke"> 5。决策树回归</em></p><p id="b814" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><em class="ke"> 6。随机森林回归</em></p><p id="12b9" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><em class="ke"> 7。树外回归</em></p><p id="8eec" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><em class="ke"> 8。XGBoost回归</em></p><p id="c4b6" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated">在下面的每个模型中，将执行以下步骤。</p><ul class=""><li id="153f" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">定义每个库采用的参数。</li><li id="d83d" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">根据训练数据拟合模型。</li><li id="a63a" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">超级参数-使用简单的for循环调整参数。</li><li id="7015" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">根据调整后的参数重新训练模型。</li><li id="2157" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">获得加权平均绝对误差(WMAE)分数。</li></ul><p id="924d" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><em class="ke">注意:但是在应用任何模型之前，我们需要数据为数字格式。例如，如果任何列是字符串格式，并且如果我们对字符串类型的列应用回归模型，那么模型将抛出一个错误。<br/>在现有的数据集中，有一些列被我们转换为数值数据类型。</em></p><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="c2b0" class="mv lb hi nu b fi ny nz l oa ob">train_data = [train]</span><span id="1924" class="mv lb hi nu b fi oc nz l oa ob"># Converting Categorical Variable 'Type' into Numerical Variables.<br/>type_mapping = {"A": 1, "B": 2, "C": 3}<br/>for dataset in train_data:<br/>    dataset['Type'] = dataset['Type'].map(type_mapping)</span><span id="1864" class="mv lb hi nu b fi oc nz l oa ob"># Converting Categorical Variable 'IsHoliday' into Numerical Variables.<br/>type_mapping = {False: 0, True: 1}<br/>for dataset in train_data:<br/>    dataset['IsHoliday'] = dataset['IsHoliday'].map(type_mapping)</span></pre><ul class=""><li id="dbd2" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">为了增加预测的复杂性，沃尔玛增加了一系列新的假期，即超级碗、感恩节、劳动节和圣诞节。竞争对手需要了解这些假期对每周销售参数的影响。因此，我们在现有的IsHoliday中添加了这些功能，并相应地将它们标记为0和1。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="ce0a" class="mv lb hi nu b fi ny nz l oa ob"><br/>train['Super_Bowl'] = np.where(<br/>(train['Date']==datetime(2010,2,10))|<br/>(train['Date'] == datetime(2011,2,11))| <br/>(train['Date'] == datetime(2012,2,10))|<br/>(train['Date'] == datetime(2013,2,8)), 1, 0)</span><span id="e9a2" class="mv lb hi nu b fi oc nz l oa ob">train['Labor_day'] = np.where(<br/>(train['Date'] == datetime(2010,9,10))|<br/>(train['Date'] == datetime(2011,9,9))| <br/>(train['Date'] == datetime(2012,9,7))|<br/>(train['Date'] == datetime(2013,9,6)), 1, 0)</span><span id="b87c" class="mv lb hi nu b fi oc nz l oa ob">train['Thanksgiving'] = np.where(<br/>(train['Date']==datetime(2010, 11, 26)) | (train['Date']==datetime(2011, 11, 25)) | <br/>(train['Date']==datetime(2012, 11, 23)) | (train['Date']==datetime(2013, 11, 29)),1,0)</span><span id="9068" class="mv lb hi nu b fi oc nz l oa ob">train['Christmas'] = np.where(<br/>(train['Date']==datetime(2010, 12, 31))| (train['Date']==datetime(2011, 12, 30))| <br/>(train['Date']==datetime(2012, 12, 28))| (train['Date']==datetime(2013, 12, 27)),1,0)</span></pre><ul class=""><li id="c8c5" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">然后，我们在训练、交叉验证和测试中分割数据集，如下所示。因为我们按升序排列日期，所以我们将数据分成70:30的比例，分别用于训练:测试和训练:cv。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="6a85" class="mv lb hi nu b fi ny nz l oa ob">train = train.sort_values(by='Date', ascending=True) # Sorting the data in increasing order of Date and then splitting.<br/>y = train['Weekly_Sales']<br/>X = train.drop(['Weekly_Sales'], axis=1)</span><span id="2eaf" class="mv lb hi nu b fi oc nz l oa ob">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # Train:Test = 70:30 splitting.</span><span id="db00" class="mv lb hi nu b fi oc nz l oa ob">X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.3) #Train:CV = 70:30 splitting.</span></pre><ul class=""><li id="e34b" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">但是，在应用任何回归模型之前，我们定义了最重要的指标，即加权平均绝对误差。请注意前面显示的公式。我们用下面的逻辑计算WMAE。我们分别计算了训练数据、cv数据和测试数据的WMAE损失。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="bbf5" class="mv lb hi nu b fi ny nz l oa ob">def wmae_train(test, pred): <br/>  weights = X_train['IsHoliday'].apply(lambda is_holiday:5 if   is_holiday else 1)<br/>  error = np.sum(weights * np.abs(test - pred), axis=0) / np.sum(weights)<br/>  return error</span><span id="cbb0" class="mv lb hi nu b fi oc nz l oa ob">def wmae_cv(test, pred): # WMAE for CV<br/>  weights = X_cv['IsHoliday'].apply(lambda is_holiday:5 if is_holiday else 1)<br/>  error = np.sum(weights * np.abs(test - pred), axis=0) / np.sum(weights)<br/>  return error</span><span id="64d3" class="mv lb hi nu b fi oc nz l oa ob">def wmae_test(test, pred): # WMAE for test<br/>  weights = X_test['IsHoliday'].apply(lambda is_holiday:5 if is_holiday else 1)<br/>  error = np.sum(weights * np.abs(test - pred), axis=0) / np.sum(weights)<br/>  return error</span></pre><ul class=""><li id="4944" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">现在我们应用上述回归模型，计算每个模型的WMAE分数。是时候使用标准的机器学习算法了！</li><li id="c17e" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">我们展示了获得最佳WMAE分数的最佳模型。我们没有使用GridSearch/RandomSearch优化技术，因为Kaggle提供的损失函数不属于skleran的库(例如MSE、准确性、F1分数等)。).相反，我们执行了简单' for '循环，以获得各个模型最佳超参数。</li><li id="1ded" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">在最佳模型中应用的程序也适用于所有其他的回归技术。</li></ul><p id="4c93" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><strong class="kf hj">步骤1 </strong> : <strong class="kf hj">应用随机森林回归来调整超参数(最大深度和n估计值)。</strong></p><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="f109" class="mv lb hi nu b fi ny nz l oa ob"># Define the list of errors and list of hyper parameters.<br/>error_cv_rf = []<br/>error_train_rf = []<br/>max_depth = [1,5,10,15,20,25,30,35]<br/>n_estimators = [10,20,30,40,50,60,70,80]<br/>rf_hyperparams = []</span><span id="6b6a" class="mv lb hi nu b fi oc nz l oa ob">"""Calculating train and CV errors for maximum depth and number of estimators parameters."""</span><span id="0830" class="mv lb hi nu b fi oc nz l oa ob">for i in max_depth: <br/>    for j in n_estimators: <br/>        rf = RandomForestRegressor(max_depth=i, n_estimators=j) <br/>        rf.fit(X_train, y_train) <br/>        y_pred_cv_rf = rf.predict(X_cv) <br/>        y_pred_train_rf = rf.predict(X_train) <br/>        error_cv_rf.append(wmae_cv(y_cv, y_pred_cv_rf)) <br/>        error_train_rf.append(wmae_train(y_train, y_pred_train_rf)) <br/>        rf_hyperparams.append({'Maximum Depth':i, 'No. of Estimators':j}) </span></pre><p id="475c" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><strong class="kf hj">第二步:获取训练和交叉验证误差表。形成此表是因为我们需要在创建热图时提供此表。</strong></p><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="cb37" class="mv lb hi nu b fi ny nz l oa ob">rf_dataframe = pd.DataFrame(rf_hyperparams)<br/>rf_dataframe['Train Error']=error_train_rf<br/>rf_dataframe['CV Error']=error_cv_rf<br/>rf_dataframe.sort_values(by=['CV Error'], ascending=True)<br/>rf_dataframe.head()</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es ox"><img src="../Images/fd86eeefb82902785c0cd5327548630e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*4aN9LDgEguGy2bbYIS0MTw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-21:随机森林数据帧</strong></figcaption></figure><p id="7e3a" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><strong class="kf hj">第三步:创建热图并确定适当的超级参数值。</strong></p><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="773e" class="mv lb hi nu b fi ny nz l oa ob">sns.set(font_scale=1.0)</span><span id="6b16" class="mv lb hi nu b fi oc nz l oa ob">train_rf = pd.pivot_table(rf_dataframe,'Train Error','Maximum Depth','No. of Estimators') # Pivot table of Train data.</span><span id="afd8" class="mv lb hi nu b fi oc nz l oa ob">cv_rf = pd.pivot_table(rf_dataframe, 'CV Error','Maximum Depth','No. of Estimators') # Pivot table of CV data.</span><span id="71af" class="mv lb hi nu b fi oc nz l oa ob">fig, ax = plt.subplots(1,2, figsize=(20,6))<br/>ax_train = sns.heatmap(train_rf, annot=True, fmt='2g', ax=ax[0], linewidths=0.01)<br/>ax_cv = sns.heatmap(cv_rf, annot=True, fmt='4g', ax=ax[1], linewidths=0.01)</span><span id="4d94" class="mv lb hi nu b fi oc nz l oa ob">bottom_train, top_train = ax_train.get_ylim()<br/>ax_train.set_ylim(bottom_train + 0.5, top_train - 0.5)</span><span id="e62f" class="mv lb hi nu b fi oc nz l oa ob">bottom_cv, top_cv = ax_cv.get_ylim()<br/>ax_cv.set_ylim(bottom_cv + 0.5, top_cv - 0.5)</span><span id="c223" class="mv lb hi nu b fi oc nz l oa ob">ax[0].set_title('Training set')<br/>ax[1].set_title('CV set')<br/>plt.show()</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oy"><img src="../Images/042153bf94fb36cad1e7833ccf3fbfbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fzbgzMTYjFYhuiQimW0OUg.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-22:列车和CV错误的热图</strong></figcaption></figure><p id="f7a1" class="pw-post-body-paragraph kc kd hi kf b kg kh ki kj kk kl km kn mb kp kq kr md kt ku kv mf kx ky kz ip hb bi translated"><strong class="kf hj">第四步:预测测试数据，计算WMAE分数。</strong></p><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="3fab" class="mv lb hi nu b fi ny nz l oa ob">model_rf = RandomForestRegressor(max_depth= 35, n_estimators=80).fit(X_train, y_train) # Fit the model with best hyper parameter values.</span><span id="f7c2" class="mv lb hi nu b fi oc nz l oa ob">y_pred = model_rf.predict(X_test) # Predict the test data.</span><span id="9eda" class="mv lb hi nu b fi oc nz l oa ob">print('Weighted Mean Absolute Error (WMAE) for Random Forest Regression:', wmae_test(y_test, y_pred)) # Get WMAE score.</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es oz"><img src="../Images/11b59fd76aeb031a1b4008fbb12c81cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*FdQQUkpybrOrMtZAm6GL6A.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-23:随机森林的WMAE分数</strong></figcaption></figure><ul class=""><li id="d566" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">同样，我们计算了其余模型的加权平均绝对误差(WMAE ),并列出每个模型的WMAE分数。下面是每个回归模型性能的简要总结。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="5faf" class="mv lb hi nu b fi ny nz l oa ob">models = pd.DataFrame({<br/>'Model Name': <br/>['Linear Regression','KNN Regression','Ridge Regression','Lasso Regression','Decision Tree Regression','Random Forest Regression','ExtraTrees Regression','XGBoost Regession'],<br/>    <br/>'WMAE Score': <br/>['14904.66', '11887.99', '14824.52', '14810.89', '2134.17', '1785.20', '1986.29', '2765.22']<br/> })</span><span id="2f3f" class="mv lb hi nu b fi oc nz l oa ob">Index = pd.Series([1, 2, 3, 4, 5, 6, 7, 8])<br/>models.set_index(Index, inplace=True)<br/>models</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es pa"><img src="../Images/51fe35629e854f8b64699b82176ae401.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*bzpfF9h-5k_iWgiB3QtEjA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-24:所有回归模型的WMAE得分</strong></figcaption></figure><ul class=""><li id="4e37" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">我们观察到随机森林回归模型的WMAE分数最小，即1785.20，因此最好使用的回归模型是随机森林回归。我们利用这个模型来计算测试文件(test.csv)中给定的未来日期的每周销售额。每周销售额按以下方式预测。</li></ul><h2 id="7318" class="mv lb hi bd jr mw mx my lf mz na nb lj mb nc nd ln md ne nf lr mf ng nh lv ni bi translated">结果(提交文件):</h2><ul class=""><li id="3f66" class="lx ly hi kf b kg lz kk ma mb mc md me mf mg ip mh mi mj mk bi translated">我们对test.csv进行了与训练合并数据文件相同的预处理。我们最后对test.csv应用了具有最佳超参数的随机森林回归。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="bebc" class="mv lb hi nu b fi ny nz l oa ob">model_rf = RandomForestRegressor(max_deth= 35, n_estimators=80).fit(train) <br/>y_pred = model_rf.predict(test_kaggle) </span></pre><ul class=""><li id="99eb" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">最后，使用Kaggle提供的sampleSubmission.csv文件格式生成每周销售预测csv文件。下面是它的实现。</li></ul><pre class="nl nm nn no fd nt nu nv nw aw nx bi"><span id="5736" class="mv lb hi nu b fi ny nz l oa ob">submission = pd.DataFrame({<br/>"Id": <br/>test_kaggle.Store.astype(str)+'_'+<br/>test_kaggle.Dept.astype(str)+'_'+<br/>test_kaggle.Date.astype(str), </span><span id="e986" class="mv lb hi nu b fi oc nz l oa ob">"Weekly_Sales": y_pred <br/> })</span><span id="9f11" class="mv lb hi nu b fi oc nz l oa ob">submission.to_csv('Weekly Sales Prediction.csv', index=False) # Final submission.</span></pre><figure class="nl nm nn no fd ix er es paragraph-image"><div class="er es pb"><img src="../Images/40dd166e88559eb186e3efd59ca6287d.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*UJ3gpEpFplti6PvnpKgjMw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-25:每周销售预测文件</strong></figcaption></figure><ul class=""><li id="2e73" class="lx ly hi kf b kg kh kk kl mb nq md nr mf ns ip mh mi mj mk bi translated">这是这个卡格尔竞赛的完整故事，它包含了所学和所用的东西。</li><li id="e069" class="lx ly hi kf b kg ml kk mm mb mn md mo mf mp ip mh mi mj mk bi translated">值得庆幸的是，当在Kaggle上传预测销售文件时，得到了3202.24的WMAE分数，排名160！！</li></ul><figure class="nl nm nn no fd ix er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es pc"><img src="../Images/49b91e8f645df736e30d80c523b5abd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dUyQBoVACPNUDmHSI1kWsQ.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jr">图-26: Kaggle比赛WMAE得分</strong></figcaption></figure></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h2 id="7c26" class="mv lb hi bd jr mw mx my lf mz na nb lj mb nc nd ln md ne nf lr mf ng nh lv ni bi translated">项目的GitHub <a class="ae nj" href="https://github.com/shubhamkabre/Machine-Learning-Project---Walmart_Recruiting_Store_Sales_Forecasting" rel="noopener ugc nofollow" target="_blank">链接</a>。请务必查看我的LinkedIn <a class="ae nj" href="http://linkedin.com/in/shubham-kabra-45878b16b" rel="noopener ugc nofollow" target="_blank">简介</a>。</h2></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><blockquote class="jz ka kb"><p id="1cdf" class="kc kd ke kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ip hb bi translated">机器学习领域就是学习未知的事物，并通过应用来试验它们..！！！</p></blockquote><blockquote class="if"><p id="9f64" class="ig ih hi bd ii ij ik il im in io ip dx translated">如果你愿意，请在下面留下一些评论和建议。毕竟，我希望通过阅读这篇文章，你可能已经开始了解你不知道的:D的概念</p><p id="e7a0" class="ig ih hi bd ii ij pd pe pf pg ph ip dx translated">感谢您阅读这篇文章…！！</p></blockquote></div></div>    
</body>
</html>