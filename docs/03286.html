<html>
<head>
<title>The Bernoulli and Binomial Distributions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">伯努利和二项式分布</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/the-bernoulli-and-binomial-distributions-5d6247d48c6a?source=collection_archive---------5-----------------------#2020-01-24">https://medium.com/analytics-vidhya/the-bernoulli-and-binomial-distributions-5d6247d48c6a?source=collection_archive---------5-----------------------#2020-01-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/074dd75193ae54fa657a038adee8f13f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gOeQzEI0jJqQsurN"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">一枚硬币的图像</figcaption></figure><h1 id="29bf" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">概率分布—二项式分布</h1><p id="b89d" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">离散随机变量的概率可以用离散概率分布来概括。</p><blockquote class="kq kr ks"><p id="85de" class="js jt kt ju b jv ku jx jy jz kv kb kc kw kx kf kg ky kz kj kk la lb kn ko kp hb bi translated">离散概率分布用于机器学习，最显著的是用于二进制和多类分类问题的建模，但也用于评估二进制分类模型的性能，例如置信区间的计算，以及用于自然语言处理的文本中单词分布的建模。</p><p id="cc9f" class="js jt kt ju b jv ku jx jy jz kv kb kc kw kx kf kg ky kz kj kk la lb kn ko kp hb bi translated"><em class="hi">在为分类任务选择深度学习神经网络输出层的激活函数和选择合适的损失函数时，也需要离散概率分布的知识。</em></p><p id="fa9a" class="js jt kt ju b jv ku jx jy jz kv kb kc kw kx kf kg ky kz kj kk la lb kn ko kp hb bi translated"><em class="hi">离散概率分布在应用机器学习中扮演着重要的角色，有一些分布是从业者必须了解的。</em></p><p id="fc0c" class="js jt kt ju b jv ku jx jy jz kv kb kc kw kx kf kg ky kz kj kk la lb kn ko kp hb bi translated"><em class="hi">在本教程中，你会发现机器学习中使用的离散概率分布</em> <strong class="ju hj"> <em class="hi">(伯努利和二项式分布)</em> </strong> <em class="hi">。</em></p><p id="4387" class="js jt kt ju b jv ku jx jy jz kv kb kc kw kx kf kg ky kz kj kk la lb kn ko kp hb bi translated"><em class="hi">我们开始吧。</em></p></blockquote><h1 id="3a12" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">随机变量</h1><p id="5ea2" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">随机变量是由随机过程产生的量。</p><p id="be93" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">离散随机变量是一种随机变量，它可以有一组有限的特定结果。机器学习中最常用的两种离散随机变量是二进制和分类变量。</p><p id="203c" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">二元随机变量:x在{0，1}分类随机变量:x在{1，2，…，K}中。二元随机变量是离散随机变量，其中有限的结果集在{0，1}中。分类随机变量是离散随机变量，其中有限的结果集在{1，2，…，K}中，其中K是唯一结果的总数。</p><p id="1f8e" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">离散随机变量的每个结果或事件都有一个概率。</p><p id="9460" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">离散随机变量的事件与其概率之间的关系被称为离散概率分布，由<strong class="ju hj">概率质量函数</strong>或简称为PMF来概括。</p><p id="14a1" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">对于可排序的结果，事件等于或小于给定值的概率由<em class="kt">累积分布函数</em>或简称CDF定义。</p><p id="9383" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">CDF的逆函数称为百分点函数，将给出小于或等于某个概率的离散结果。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="73b1" class="ll iv hi lh b fi lm ln l lo lp">PMF: Probability Mass Function, returns the probability of a given outcome.<br/>CDF: Cumulative Distribution Function, returns the probability of a value less than or equal to a given outcome.<br/>PPF: Percent-Point Function, returns a discrete value that is less than or equal to the given probability.</span></pre><p id="f864" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">常见的离散概率分布有很多。</p><p id="deed" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">最常见的是分别针对二元和分类离散随机变量的伯努利分布和多伯努利分布，以及将每个分布推广到多个独立试验的二项式分布和多项式分布。</p><p id="079e" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[3]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="647b" class="ll iv hi lh b fi lm ln l lo lp"># for inline plots in jupyter<br/>%matplotlib inline<br/># import matplotlib<br/>import matplotlib.pyplot as plt<br/># for latex equations<br/>from IPython.display import Math, Latex<br/># for displaying images<br/>from IPython.core.display import Image</span></pre><p id="d01c" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[4]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="c963" class="ll iv hi lh b fi lm ln l lo lp"># import seaborn<br/>import seaborn as sns<br/># settings for seaborn plotting style<br/>sns.set(color_codes=True)<br/># settings for seaborn plot sizes<br/>sns.set(rc={'figure.figsize':(5,5)})</span></pre><h1 id="a11e" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">二项分布</h1><p id="11c9" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">伯努利分布是一种离散的概率分布，它涵盖了事件的二进制结果为0或1的情况。</p><p id="0be1" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">{0，1}中的x</p><p id="48fe" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">“伯努利试验”是一个结果遵循伯努利分布的实验或案例。这个分布和试验是以瑞士数学家雅各布·伯努利的名字命名的。</p><p id="f7e7" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">伯努利试验的一些常见例子包括:掷一次硬币，结果可能是正面(0)或反面(1)。一胎生男孩(0)或女孩(1)。机器学习中伯努利试验的一个常见示例可能是将单个示例二进制分类为第一类(0)或第二类(1)。</p><p id="9dbe" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">伯努利分布只有两种可能的结果，即1(成功)和0(失败)，以及一次尝试，例如抛硬币。因此，具有伯努利分布的随机变量X可以取值1和成功概率p，取值0和失败概率q或1p，成功和失败的概率不一定相等。伯努利分布是二项分布的一种特殊情况，其中进行了一次试验(n=1)。</p><p id="aeee" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">该分布可以用定义结果1的概率的单个变量p来概括。给定该参数，每个事件的概率可以计算如下:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="fabb" class="ll iv hi lh b fi lm ln l lo lp">P(x=1) = p<br/>P(x=0) = 1 – p<br/>In the case of flipping a fair coin, the value of p would be 0.5, giving a 50% probability of each outcome.</span></pre><p id="b4f1" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">其概率质量函数由下式给出:</p><p id="b087" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">您可以使用scipy.stats模块的bernoulli.rvs()方法生成伯努利分布的离散随机变量，该方法将p(成功概率)作为形状参数。要改变分布，请使用loc参数。大小决定了重复试验的次数。如果希望保持再现性，请包含一个分配给某个数字的random_state参数。</p><p id="e67a" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[5]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="dc8d" class="ll iv hi lh b fi lm ln l lo lp">from scipy.stats import bernoulli<br/>data_bern = bernoulli.rvs(size=10000,p=0.6)</span></pre><p id="572b" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">再次可视化分布，您可以观察到您只有两种可能的结果:</p><p id="f8ec" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[6]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="0200" class="ll iv hi lh b fi lm ln l lo lp">ax= sns.distplot(data_bern,<br/>                 kde=False,<br/>                 color="skyblue",<br/>                 hist_kws={"linewidth": 15,'alpha':1})<br/>ax.set(xlabel='Bernoulli Distribution', ylabel='Frequency')</span><span id="1e73" class="ll iv hi lh b fi lq ln l lo lp">C:\Users\user\New folder\lib\site-packages\scipy\stats\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.<br/>  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval</span></pre><p id="4ad3" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">Out[6]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="07d2" class="ll iv hi lh b fi lm ln l lo lp">[Text(0, 0.5, 'Frequency'), Text(0.5, 0, 'Bernoulli Distribution')]</span></pre><h1 id="7582" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">二项分布</h1><p id="f8b6" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">多次独立伯努利试验的重复称为伯努利过程。</p><p id="a8a7" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">伯努利过程的结果将遵循二项式分布。因此，伯努利分布将是具有单一试验的二项分布。</p><p id="4805" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">机器学习算法在二元分类问题上的性能可以被分析为伯努利过程，其中模型对来自测试集的示例的预测是伯努利试验(正确或不正确)。</p><p id="7e8e" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">二项式分布总结了给定数量的伯努利试验n中的成功数量k，以及每个试验p的给定成功概率。</p><p id="c753" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">只有两种可能结果的分布，如成功或失败，获得或损失，赢或输，并且所有试验的成功和失败概率都相同，这种分布称为<strong class="ju hj">二项式分布</strong>。然而，结果不一定是一样的，每个试验都是相互独立的。</p><p id="4ade" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">二项分布的参数是n和p，其中n是试验的总数，p是每次试验成功的概率。其概率分布函数由下式给出:</p><p id="cdcb" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">其中:</p><h1 id="40da" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">二项分布方法综述</h1><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="26eb" class="ll iv hi lh b fi lm ln l lo lp">rvs(n, p, loc=0, size=1, random_state=None)---&gt; Random variates.</span><span id="7758" class="ll iv hi lh b fi lq ln l lo lp">pmf(k, n, p, loc=0)---&gt; Probability mass function.</span><span id="341f" class="ll iv hi lh b fi lq ln l lo lp">logpmf(k, n, p, loc=0)---&gt; Log of the probability mass function.</span><span id="4e23" class="ll iv hi lh b fi lq ln l lo lp">cdf(k, n, p, loc=0) ---&gt; Cumulative distribution function.</span><span id="8102" class="ll iv hi lh b fi lq ln l lo lp">logcdf(k, n, p, loc=0) ---&gt; Log of the cumulative distribution function.</span><span id="f312" class="ll iv hi lh b fi lq ln l lo lp">sf(k, n, p, loc=0) ---&gt; Survival function (also defined as 1 - cdf, but sf is sometimes more accurate).</span><span id="04b3" class="ll iv hi lh b fi lq ln l lo lp">logsf(k, n, p, loc=0) ---&gt; Log of the survival function.</span><span id="5926" class="ll iv hi lh b fi lq ln l lo lp">ppf(q, n, p, loc=0) ---&gt; Percent point function (inverse of cdf — percentiles).</span><span id="b3f9" class="ll iv hi lh b fi lq ln l lo lp">isf(q, n, p, loc=0) ---&gt; Inverse survival function (inverse of sf).</span><span id="e2ff" class="ll iv hi lh b fi lq ln l lo lp">stats(n, p, loc=0, moments=’mv’) ---&gt; Mean(‘m’), variance(‘v’), skew(‘s’), and/or kurtosis(‘k’).</span><span id="d47b" class="ll iv hi lh b fi lq ln l lo lp">entropy(n, p, loc=0) ---&gt; (Differential) entropy of the RV.</span><span id="e283" class="ll iv hi lh b fi lq ln l lo lp">expect(func, args=(n, p), loc=0, lb=None, ub=None, conditional=False) ---&gt; Expected value of a function (of one argument) with respect to the distribution.</span><span id="aca2" class="ll iv hi lh b fi lq ln l lo lp">median(n, p, loc=0) ---&gt; Median of the distribution.</span><span id="8f43" class="ll iv hi lh b fi lq ln l lo lp">mean(n, p, loc=0) ---&gt; Mean of the distribution.</span><span id="8f41" class="ll iv hi lh b fi lq ln l lo lp">var(n, p, loc=0) ---&gt; Variance of the distribution.</span><span id="1663" class="ll iv hi lh b fi lq ln l lo lp">std(n, p, loc=0) ---&gt; Standard deviation of the distribution.</span><span id="ec13" class="ll iv hi lh b fi lq ln l lo lp">interval(alpha, n, p, loc=0) ---&gt; Endpoints of the range that contains alpha percent of the distribution</span></pre><h1 id="c8ce" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">为二项分布生成随机变量</h1><p id="4878" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">您可以使用scipy.stats模块的binom.rvs()方法生成二项式分布离散随机变量，该方法将n(试验次数)和p(成功概率)作为形状参数。要改变分布，请使用loc参数。大小决定了重复试验的次数。如果希望保持再现性，请包含一个分配给某个数字的random_state参数。</p><p id="b464" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[7]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="5a97" class="ll iv hi lh b fi lm ln l lo lp">from scipy.stats import binom<br/>data_binom = binom.rvs(n=10,p=0.5,size=10000)</span></pre><p id="d40f" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[8]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="6611" class="ll iv hi lh b fi lm ln l lo lp">ax = sns.distplot(data_binom,<br/>                  kde=False,<br/>                  color='skyblue',<br/>                  hist_kws={"linewidth": 15,'alpha':1})<br/>ax.set(xlabel='Binomial Distribution', ylabel='Frequency')</span></pre><p id="ac8e" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">Out[8]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="7cf9" class="ll iv hi lh b fi lm ln l lo lp">[Text(0, 0.5, 'Frequency'), Text(0.5, 0, 'Binomial Distribution')]</span></pre><p id="f0dc" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">或者，可以调用分布对象(作为一个函数)来确定形状和位置。这将返回一个“冻结的”RV对象，其中包含固定的给定参数。</p><p id="68e8" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">冻结分配并显示冻结的pmf:</p><p id="2984" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[30]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="50cf" class="ll iv hi lh b fi lm ln l lo lp">import numpy as np<br/>fig, ax = plt.subplots(1, 1)<br/>n=10<br/>p=0.5<br/>x = np.arange(0,11)# ppf is the inverse of cdf<br/>ax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')<br/>ax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)</span><span id="dcd9" class="ll iv hi lh b fi lq ln l lo lp">#plot the frozen binomial distribution<br/>rv = binom(n,p)<br/>ax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,<br/>        label='frozen pmf')</span><span id="31d3" class="ll iv hi lh b fi lq ln l lo lp">ax.legend(loc='best', frameon=False)<br/>plt.show()</span></pre><p id="43b7" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[31]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="5242" class="ll iv hi lh b fi lm ln l lo lp">x</span></pre><p id="0dd9" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">Out[31]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="2a02" class="ll iv hi lh b fi lm ln l lo lp">array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])</span></pre><p id="9def" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">我们可以使用binom.stats() SciPy函数计算这个分布的矩，特别是期望值或均值和方差。</p><p id="e42a" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated"><em class="kt"> μ </em> = <em class="kt"> np </em></p><p id="e26d" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">根据上述二项式分布(也等于分布的平均值)，预计10次试验中有5次成功的概率最高。</p><p id="cb51" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[32]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="0688" class="ll iv hi lh b fi lm ln l lo lp">n, p = 10, 0.5<br/>mean, var, skew, kurt = binom.stats(n, p, moments='mvsk')<br/>print('Mean=%.3f,Variance=%.3f'%(mean,var) )</span><span id="c2a2" class="ll iv hi lh b fi lq ln l lo lp">Mean=5.000,Variance=2.500</span></pre><p id="c1be" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">检查cdf和ppf的准确性:</p><p id="3c93" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[45]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="9752" class="ll iv hi lh b fi lm ln l lo lp">prob = binom.cdf(x, n, p)<br/>np.allclose(x, binom.ppf(prob, n, p))</span></pre><p id="de9a" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">Out[45]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="5d76" class="ll iv hi lh b fi lm ln l lo lp">True</span></pre><p id="006a" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">让我们使用binom.cdf函数手动检查</p><p id="fc1a" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[46]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="9998" class="ll iv hi lh b fi lm ln l lo lp">for k in range(11):<br/>    print('P of %d successes in 10 trials: %.3f%%' %(k, binom.pmf(k,n,p)*100))</span><span id="b4d7" class="ll iv hi lh b fi lq ln l lo lp">P of 0 successes in 10 trials: 0.098%<br/>P of 1 successes in 10 trials: 0.977%<br/>P of 2 successes in 10 trials: 4.395%<br/>P of 3 successes in 10 trials: 11.719%<br/>P of 4 successes in 10 trials: 20.508%<br/>P of 5 successes in 10 trials: 24.609%<br/>P of 6 successes in 10 trials: 20.508%<br/>P of 7 successes in 10 trials: 11.719%<br/>P of 8 successes in 10 trials: 4.395%<br/>P of 9 successes in 10 trials: 0.977%<br/>P of 10 successes in 10 trials: 0.098%</span></pre><p id="ad13" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">这可以比作抛硬币试验，其中n= 10，成功被定义为获得正面。上面我们问的问题是“在k为0，1，2…10的情况下，n次试验得到k个头的概率是多少”。请注意，<em class="kt">P</em>(<em class="kt">k</em>= 0)=<em class="kt">P</em>(<em class="kt">k</em>= 10)P(k = 0)= P(k = 10)对于p =0.5的公平硬币</p><p id="3ccf" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[47]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="e9af" class="ll iv hi lh b fi lm ln l lo lp">for k in range(11):<br/>    print('P of %d success in 10 trials: %.3f%%' %(k, binom.cdf(k,n,p)*100))</span><span id="d169" class="ll iv hi lh b fi lq ln l lo lp">P of 0 success in 10 trials: 0.098%<br/>P of 1 success in 10 trials: 1.074%<br/>P of 2 success in 10 trials: 5.469%<br/>P of 3 success in 10 trials: 17.187%<br/>P of 4 success in 10 trials: 37.695%<br/>P of 5 success in 10 trials: 62.305%<br/>P of 6 success in 10 trials: 82.812%<br/>P of 7 success in 10 trials: 94.531%<br/>P of 8 success in 10 trials: 98.926%<br/>P of 9 success in 10 trials: 99.902%<br/>P of 10 success in 10 trials: 100.000%</span></pre><p id="6c8c" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">运行上面的代码定义了二项式分布，并使用binom.pmf函数计算每个成功结果的概率。记住x是一个从1到10的数组，包括1和10。</p><p id="9cf1" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">我们可以看到，5个成功结果的概率最高，约为24.609%</p><p id="b074" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">假设一次试验的成功概率为50%，我们预计10次试验中有10次或更少成功的概率接近100%。我们可以用累积分布函数来计算，如上所示。</p><h1 id="3119" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">重复抛硬币实验</h1><p id="2fe5" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">在上面的例子中，我们投掷一枚硬币“n=10”次。这是我们唯一的实验。通常，为了看看我们的掷硬币实验有多可靠，我们可能想要多次重复这个实验(或者考虑投掷多个硬币)。我们可以通过numpy.random.binomial函数或scipy.binom.rvs函数中的“大小”选项轻松模拟多个实验</p><p id="33e3" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">让我们重复掷硬币实验100次，其中每个实验我们掷10次公平的硬币。让我们问一下，在100次实验中，我们每次看到多少个头。</p><p id="fb47" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[86]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="9492" class="ll iv hi lh b fi lm ln l lo lp">np.random.binomial?</span></pre><p id="4393" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[88]中:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="e186" class="ll iv hi lh b fi lm ln l lo lp">x= np.random.binomial(n,p,size=100)<br/>n=10<br/>p=0.5<br/># let us repeat our experiment for 100 times<br/>size = 100<br/>x</span></pre><p id="2e75" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">Out[88]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="3f0d" class="ll iv hi lh b fi lm ln l lo lp">array([5, 5, 7, 3, 5, 4, 5, 5, 7, 7, 6, 6, 6, 5, 2, 2, 7, 4, 4, 5, 2, 8,<br/>       3, 8, 6, 7, 2, 5, 8, 6, 5, 6, 4, 6, 4, 4, 5, 2, 2, 2, 6, 2, 3, 5,<br/>       5, 4, 4, 7, 3, 7, 4, 5, 8, 6, 4, 8, 6, 4, 5, 5, 5, 3, 6, 4, 4, 5,<br/>       4, 7, 5, 3, 3, 6, 7, 3, 5, 6, 7, 2, 4, 3, 5, 4, 5, 6, 8, 3, 6, 7,<br/>       5, 6, 4, 2, 3, 3, 7, 8, 5, 6, 4, 5])</span></pre><p id="c40a" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[89]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="5b4d" class="ll iv hi lh b fi lm ln l lo lp">ax = sns.distplot(x,<br/>                  kde=False,<br/>                  color='skyblue',<br/>                  hist_kws={"linewidth": 15,'alpha':1})<br/>ax.set(xlabel='Binomial Distribution', ylabel='Frequency')</span></pre><p id="cdf3" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">Out[89]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="6f88" class="ll iv hi lh b fi lm ln l lo lp">[Text(0, 0.5, 'Frequency'), Text(0.5, 0, 'Binomial Distribution')]</span></pre><p id="baa5" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在n=10次抛硬币中看到x个正面的概率我们从一个简单的实验开始，将一枚公平的硬币抛10次。我们将实验重复了100次，并测量了我们观察到的成功次数/人头数。我们可以用多种方式观察到的成功次数(人头数)来理解概率的基础。例如，我们可以简单地数一数在掷硬币的过程中，我们看到了多少次0头、1头、2头，等等。</p><p id="f873" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">我们可以看到，在我们的100次实验中，我们从来没有看到所有正面和所有反面(因为第一个和最后一个元素都是零)。我们还可以看到，我们观察到更多次4，或5，或6个头。上述成功的总数为100，即我们的实验总数。我们可以用观察到的成功除以100来估计在n=10次抛硬币中获得x次成功的概率。</p><p id="cc27" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[90]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="17b4" class="ll iv hi lh b fi lm ln l lo lp">probs_100 =[sum(np.random.binomial(n,p,size=100) == i)/100 for i in range(n+1)]<br/>probs_100</span></pre><p id="c657" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">Out[90]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="2c7d" class="ll iv hi lh b fi lm ln l lo lp">[0.0, 0.0, 0.07, 0.1, 0.22, 0.25, 0.18, 0.12, 0.03, 0.01, 0.0]</span></pre><p id="1ee0" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">让我们画出我们刚刚计算的x成功的概率。</p><p id="144d" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[91]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="713c" class="ll iv hi lh b fi lm ln l lo lp">plt.xticks(range(n+1))<br/>plt.plot(list(range(n+1)), probs_100, color='blue', marker='o')<br/>plt.xlabel('Number of Heads',fontsize=14)<br/>plt.ylabel('Probability',fontsize=14)</span></pre><p id="5512" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">Out[91]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="be45" class="ll iv hi lh b fi lm ln l lo lp">Text(0, 0.5, 'Probability')</span></pre><p id="572f" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">从上面的剧情我们可以看出，看到5个头的概率是最高的。注意，这个观察结果可能会根据我们随机模拟的实现而变化。</p><h1 id="4dfb" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">10万次重复实验</h1><p id="8bbd" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">我们知道这是一个公平的硬币，所以我们预计，如果我们重复实验更多次，我们应该看到看到5个头的概率应该是最高的。所以，让我们重复我们的掷硬币实验100，000次，并计算看到n个像上面这样的头的概率。此外，请记住，观察结果可能会有所不同，因为这是一个随机过程。</p><p id="9096" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[118]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="24c4" class="ll iv hi lh b fi lm ln l lo lp">from ipywidgets import interact,IntSlider<br/>def plot_probab(size=100):<br/>    np.random.seed(42)<br/>    n=10<br/>    p=0.5<br/># let us repeat our experiment for 100000 times</span><span id="dd60" class="ll iv hi lh b fi lq ln l lo lp">    x=np.random.binomial(n=n, p=p, size=size)<br/>    probs_100= [sum(np.random.binomial(n,p,size=size) == i)/size for i in range(n+1)]<br/>    plt.xticks(range(n+1))<br/>    plt.plot(list(range(n+1)), probs_100, color='blue', marker='o')<br/>    plt.xlabel('Number of Heads',fontsize=14)<br/>    plt.ylabel('Probability',fontsize=14)<br/>    <br/>    <br/>size_slider = IntSlider(min=100, max=100000, step=100, value=100, description='$\\nu$')   <br/>interact(plot_probab,size=size_slider);</span></pre><p id="6777" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">现在我们可以看到，看到5个头的概率是我们预期的最高。巧妙的是，即使我们不知道硬币是否公平，但如果我们像上面一样反复做实验，观察成功的次数，我们就可以推断出硬币是否公平。</p><h1 id="2e7e" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">扔有偏见的硬币</h1><p id="23e4" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">让我们用有偏差的硬币做实验。假设我们有一个硬币，我们怀疑它是一个有偏差的硬币。让我们像以前一样通过反复实验来推断硬币有多不公平。</p><p id="ebca" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">就像之前描述的那样，让我们把不公平的硬币抛10次，重复10万次，数一数成功的次数。让我们用成功的次数来得到x次成功的概率，并把它画出来。</p><p id="76c4" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[119]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="7077" class="ll iv hi lh b fi lm ln l lo lp">def plot_probab_unfair(size=100):<br/>    np.random.seed(42)<br/>    n=10<br/>    p=0.7<br/># let us repeat our experiment for 100000 times</span><span id="5df7" class="ll iv hi lh b fi lq ln l lo lp">    x=np.random.binomial(n=n, p=p, size=size)<br/>    probs_100= [sum(np.random.binomial(n,p,size=size) == i)/size for i in range(n+1)]<br/>    plt.xticks(range(n+1))<br/>    plt.plot(list(range(n+1)), probs_100, color='blue', marker='o')<br/>    plt.xlabel('Number of Heads',fontsize=14)<br/>    plt.ylabel('Probability',fontsize=14)<br/>    <br/>    <br/>size_slider = IntSlider(min=100, max=100000, step=100, value=100, description='$\\nu$')   <br/>interact(plot_probab_unfair,size=size_slider);</span></pre><p id="6e3c" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">从上面的图中我们可以看出，当成功/人头数为7时，成功的概率最高。因此，我们可以推断，偏硬币的成功概率p=0.7。</p><h1 id="cdeb" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">二项式分布的应用(现实生活中的例子)</h1><p id="795e" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">一家公司钻了9口野猫石油勘探井，每口井的成功概率估计为0.1。九口井全部失败。发生这种情况的可能性有多大？</p><p id="393d" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">让我们对模型进行20，000次试验，并计算产生零阳性结果的数量。</p><p id="c31a" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">在[122]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="6688" class="ll iv hi lh b fi lm ln l lo lp">sum(np.random.binomial(9, 0.1, 20000) == 0)/20000.<br/># answer = 0.38885, or 38%.</span></pre><p id="cbbf" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">Out[122]:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="9ffc" class="ll iv hi lh b fi lm ln l lo lp">0.38495</span></pre><p id="d5c6" class="pw-post-body-paragraph js jt hi ju b jv ku jx jy jz kv kb kc kd kx kf kg kh kz kj kk kl lb kn ko kp hb bi translated">参考</p><ol class=""><li id="ade3" class="lr ls hi ju b jv ku jz kv kd lt kh lu kl lv kp lw lx ly lz bi translated">杰森·布朗利的掌握数据科学博客</li><li id="fac0" class="lr ls hi ju b jv ma jz mb kd mc kh md kl me kp lw lx ly lz bi translated">Scipy。统计数据</li></ol></div></div>    
</body>
</html>