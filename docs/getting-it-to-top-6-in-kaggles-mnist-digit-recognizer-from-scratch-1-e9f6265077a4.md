# 让它在 Kaggle 的 MNIST 数字识别器中从零开始达到 6%。

> 原文：<https://medium.com/analytics-vidhya/getting-it-to-top-6-in-kaggles-mnist-digit-recognizer-from-scratch-1-e9f6265077a4?source=collection_archive---------32----------------------->

在本文中，我们将逐步构建我们的神经网络，并尝试在 Kaggle 的 MNIST 数字识别比赛中达到**前 6%** 或更高。数据集包含大小为 28 * 28 的 42k 训练图像和 28k 测试图像。我们将使用的库是 TensorFlow 和 Keras。

![](img/08ae00a05b664c2d49c81dfa38516992.png)

## 第 0.0 部分:Tensorflow 的基础知识以及如何在 Tensorflow 中构建神经网络

代码的第 4 行允许您创建一个没有层的模型，然后您可以继续添加具有不同数量的神经元和不同激活函数的层。

神经元数目的一些初始值是 64、128、256、512、1024，而激活函数可以是 relu、双曲线 tan、leaky relu、softmax，这取决于应用。在我们的例子中，我们将对隐藏层使用 relu，对输出层使用 softmax。

第 20 行:输出类别的数量是 10，因为数字是 0，1，2 …9。如果我们正在处理二进制分类问题，我们通常对输出层使用 sigmoid 激活，因为我们只需要将其分类为 0 或 1 两个类别。Softmax 充当多类 sigmoids，因为它允许我们获得超过 2 类的概率。这为我们神经网络的创建奠定了基础。

## 第 0.1 部分:导入训练和测试数据集

没有什么比导入数据集，从 CSV 文件中分离图像和标签，然后最终将其转换为 NumPy 数组更简单的了。我们将通过除以 255 来使数组正常化，因为这将使数组的范围在 0 到 1 之间。

## 第 0.2 部分:训练模型:

编译函数使用定义的优化器、损失函数和度量来编译模型。准确性度量在 TensorFlow 中预定义，但我们始终可以通过定义函数并将该函数的名称添加到度量数组来创建自己的度量。

拟合函数将根据第 0.1 部分中的训练图像和标签开始对模型进行训练，并按照定义的历元数运行模型。

## 第 1.1 部分:构建第一个神经网络

经过 30 个周期后，训练准确率达到 99.88 左右，在 Kaggle 的测试得分为 0.88885。到目前为止还不错，因为这是最简单的神经网络模型，而且预测效果很好。期望排名:2000+左右。

上面显示了具有 1 个隐藏层和不同数量的神经元的模型，以及 Kaggle 测试分数及其相应的排名。具有 512 个神经元的模型是所有模型中最好的，它将我们带到了几乎 1350 个。

## 第 1.2 部分制作深网

即使增加了一个隐藏层，我也不能跳到 1350 年之前。你可以尝试调整参数，比如神经元的数量，或者增加一个隐藏层。

> 在 [***下一部分***](/@rushikesh0203/getting-it-to-top-6-in-kaggles-mnist-digit-recognizer-from-scratch-2-815869d643a2) 中，我们将实现 ***CNN 的*** ，看看它是如何在 MNIST 数字数据集上工作的。