<html>
<head>
<title>K- Means Clustering Explained | Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k均值聚类解释|机器学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/k-means-clustering-explained-419ee66d095e?source=collection_archive---------2-----------------------#2020-09-25">https://medium.com/analytics-vidhya/k-means-clustering-explained-419ee66d095e?source=collection_archive---------2-----------------------#2020-09-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/68f8a4da5cf02624a94260b1f27a36bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ivbTkH5Ciw8IoZoNOoN-RQ.jpeg"/></div></div></figure><p id="7cf1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们开始讨论K-Means聚类之前，让我们看一些事情。什么是集群<br/> 2。欧几里德距离<br/> 3。寻找多个点的中心或平均值<br/>如果你已经熟悉这些东西，可以直接跳到K-Means算法</p><h1 id="fb19" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是集群？</h1><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/e4c5045b8c517a17fbdc9afd18d8790e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*pGfkUYvATbDLZIehXGqEbA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">图1.1</figcaption></figure><p id="2b18" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">聚类无非就是分组。给我们一些数据，我们必须在数据中找到一些模式，并将相似的数据组合在一起，形成聚类。这是聚类的基础。这是在欧几里德距离的帮助下完成的。</p><p id="9441" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">比如:<br/> 1。一个体育俱乐部可能希望根据他们的速度(一维)将他们的跑步者分成3个不同的组<br/> 2。一家公司可能希望根据两个因素将他们的客户分成三个不同的群:带来的商品数量、退回的商品数量(二维)</p><h1 id="8c73" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是欧氏距离？</h1><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/125db6cabdffff84fabb890418478dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*XrN4sQqHOmMQbdaHJbFsXQ.png"/></div></div></figure><p id="ee7e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">两个坐标之间的距离可以在欧几里德距离的帮助下找到。如果数据是二维的，在一个平面上，那么上式中<strong class="is hj"> n </strong>将为2，可以表示为<strong class="is hj"> (x，y) </strong>。如果是三维数据，<strong class="is hj"> n </strong>将为3，可以表示为<strong class="is hj"> (x，y，z)。</strong></p><h1 id="67a1" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">寻找多个点的中心或平均值</strong></h1><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/3c3028e511dfdd2e7fb6653c3beb0be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hp6P0ePn8zSRzZTZIxL2ig.jpeg"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">图2.1</figcaption></figure><p id="98da" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，考虑图2.1中的黑点。我们需要找到所有黑点的中心。</p><p id="6afe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们知道这是二维数据，因为它有一个<strong class="is hj"> x </strong>和<strong class="is hj"> y </strong>，并表示为<strong class="is hj"> (x，y) <br/> </strong>为了找到中心，这就是我们要做的。</p><p id="ea40" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.获得所有黑点的x坐标，并取平均值，假设它是<strong class="is hj"> x_mean </strong>。<br/> 2。对所有黑点的y坐标做同样的操作，我们称之为<strong class="is hj"> y_mean。</strong> <br/> 3。现在，中心点将只是<strong class="is hj"> (x_mean，y_mean) </strong>，这将导致红色多边形出现在黑点的中心</p><p id="5947" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">至此，我们已经成功地完成了K均值聚类的先决条件。</p><h1 id="6a66" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">k均值聚类</h1><p id="613a" class="pw-post-body-paragraph iq ir hi is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hb bi translated"><strong class="is hj">什么是K均值聚类？</strong></p><p id="1d01" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一种借助欧几里德距离将具有相似特征的数据聚集在一起的聚类算法</p><p id="1a2c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">工作原理？</strong></p><p id="1114" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，我们举一个数据集的例子</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/330aaa3282877526244bb229bc737bf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*unSLJMv_9dl0n1_PVTMUfg.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">图3.1</figcaption></figure><p id="538b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图3.1代表了我们的数据点。<br/>现在。比方说，我们需要将这些数据分为两类。<br/>只看这个，就可以说<br/> <strong class="is hj"> x &lt; -2 </strong>的数据点可以分组在一起，<strong class="is hj"> x &gt; -2 </strong>的数据点可以分组在一起。</p><p id="a5b7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样，如果我们想将这些数据分成3类，我们可以说左边的数据可以组合在一起，中间的数据可以组合在一起，右边的数据可以组合在一起，如图3.2所示。最初，我们不知道应该用给定的数据形成多少个集群。我稍后会处理这个问题。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/f5f4c2c868421596275386d07870a749.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*zdIiG8ka9Ob9DmBPckY1sA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">图3.2</figcaption></figure><p id="eb47" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">很抱歉中间数据点的颜色(是白色的，几乎与背景相匹配)</em></p><p id="84e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">现在，让我们在给定的数据上实现K均值</strong></p><ol class=""><li id="362e" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">将质心(c1)随机初始化为数据集中的一些数据点(聚类质心的数量=您要创建的聚类的数量)。</li><li id="c7ae" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated"><strong class="is hj">将点映射到质心:</strong>对于数据集中的每一个数据，计算所有可用质心中最接近它的质心，然后该数据点将被视为最接近它的特定质心的一部分<em class="jo">(您可以给每个质心赋予不同的颜色，属于该质心的数据点也将具有相同的颜色)</em></li><li id="6938" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated"><strong class="is hj">将质心移动到中心:</strong>对于属于特定质心的所有点，使用上述方法计算中心，并将这些点的质心移动到该中心。<em class="jo">(对所有质心重复此操作)</em></li></ol><p id="fc27" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.现在，当我们改变质心的位置时，数据点需要映射到基于新的质心位置的质心上。因此，重复步骤2和3若干次迭代，直到所有的质心停止移动。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/e9d3ed319e868a63f59c13782a364326.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/1*5IUsINt2vcXPPKdXQ5aziQ.gif"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">图3.4</figcaption></figure><p id="3eb0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果还是不明白，看一下图3.4，再读一遍上面的4个步骤。</p><p id="35f6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它包括3个步骤:初始化，映射点到质心，移动质心到所有点的平均值，重复这个过程，直到没有变化发生。</p><p id="41b8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，如果我对图3.1所示的上述数据执行这些过程。我将最终得到这个图，其中黑点是每个集群的质心</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/de33d8539363be8f770e171e9f639c70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*lb0p84pTWZocxjrklCZTnA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">图3.5</figcaption></figure><p id="2e5a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请注意，这可能与我们人类预期的略有不同。但是，没关系。这就是K-均值聚类的工作原理</p><h1 id="d067" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">还有一点</h1><p id="0c85" class="pw-post-body-paragraph iq ir hi is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hb bi translated">正如我已经说过的，我们不知道要选择的集群数量的确切值。但是，有一种方法叫做<strong class="is hj">肘法，</strong>用它我们可以大致做到这一点。这将在另一篇博客文章中讨论。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/329c257593f4840daa1c783ee0497221.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*ZjuVI958aEikh0-VK08IPg.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">图4.1</figcaption></figure><p id="27fe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">对于上述数据，如果我们选择聚类数为</em> <strong class="is hj"> <em class="jo"> 2 </em> </strong> <em class="jo">，图4.1就是聚类的表示。</em></p><p id="4419" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">质心的初始化点在我们得到的合成簇中也有一定的发言权。因为我们随机初始化质心，所以最好多次运行该算法并绘制图形，然后选择多数投票结果。</p><h1 id="db0d" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论</h1><p id="aeec" class="pw-post-body-paragraph iq ir hi is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hb bi translated">这可能看起来有点难以理解。但是，这是最简单的算法之一，聚类分析在许多领域都有应用。其中一些是:推荐系统，模式识别和图像处理。</p><h1 id="cc61" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">谢谢你</h1></div></div>    
</body>
</html>