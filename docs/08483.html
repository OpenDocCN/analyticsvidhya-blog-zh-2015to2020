<html>
<head>
<title>Weight Initializer in Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络中的权重初始化器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/weight-initializer-in-deep-learning-cdfe3ce179ee?source=collection_archive---------10-----------------------#2020-07-31">https://medium.com/analytics-vidhya/weight-initializer-in-deep-learning-cdfe3ce179ee?source=collection_archive---------10-----------------------#2020-07-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e26378e9d3c452bec8c910d249480a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J-UoYRKR7ffsQ_e1ITOFOQ.jpeg"/></div></div></figure><blockquote class="iq ir is"><p id="4cd6" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为什么我们应该使用权重初始化器，因为它将被优化器更新？</p></blockquote><p id="91bd" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在神经网络中，非常有必要了解权重是如何更新的，以帮助优化器找到最适合数据降落到全局最小值的参数。</p><p id="db1a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">即使在使用了不同类型的优化器之后，很多问题还是会产生。  <em class="iv"> </em>因此，为我们的神经网络选择初始权值是非常必要的。然而，在大多数情况下，权重的初始值是随机的，偏差为零。</p><blockquote class="iq ir is"><p id="595a" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果我们用零或者一个随机的高值初始化权重会怎么样？</p></blockquote><p id="4f46" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在这种情况下，当更新权重时，权重相对于损失的导数在所有随后的迭代中将是相同的，因此在每个时期之后权重将没有变化。这会导致渐变消失的问题。然而，如果选择一个随机的高值作为初始值，那么它将导致爆炸梯度的问题，使得更新的权重为负。因此，新的和旧的权重将变化很大，梯度下降将永远不会收敛到全局最小值。</p><blockquote class="iq ir is"><p id="824a" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们可以用什么来克服上述问题？</p></blockquote><p id="57cf" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">权重初始化器(内核初始化器)的需求来了。它有助于克服与使用不适当的初始权重相关联的问题，同时创建深度神经网络。因此，在这篇博文中，我们将学习各种权重初始化器，它们可以用来优化我们神经网络的结果。</p><blockquote class="iq ir is"><p id="2ab2" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在继续讨论初始化器之前，了解扇入和扇出的概念是很重要的。</p></blockquote><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jw"><img src="../Images/485aa728dc3b6501c73b3d1f0537133d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q5LhpXUc5Ms1iVoM7UNqSw.jpeg"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">解释扇入和扇出概念的神经网络。</figcaption></figure><p id="c564" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">上图描述了一个三层神经网络，在第一和第二隐藏层分别有3和2个神经元。因此，对于第一隐藏层中的所有神经元，扇入=3，因为有三个神经元作为第一隐藏层的输入，扇出=2，因为其输出作为输入被馈送到第二隐藏层中的其他两个神经元。</p><p id="cfb5" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">类似地，对于第二隐藏层中的神经元，扇入=3，扇出=1。这样，可以为神经网络中的每个神经元确定扇入和扇出值。</p><blockquote class="iq ir is"><p id="4357" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">权重初始化器的类型:</strong></p></blockquote><ol class=""><li id="1ca0" class="kf kg hi iw b ix iy jb jc js kh jt ki ju kj jr kk kl km kn bi translated">均匀分布初始化器</li><li id="f802" class="kf kg hi iw b ix ko jb kp js kq jt kr ju ks jr kk kl km kn bi translated">Xavier (Glorot)初始化器</li><li id="6632" class="kf kg hi iw b ix ko jb kp js kq jt kr ju ks jr kk kl km kn bi translated">何初始化器</li></ol><p id="d153" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi kt translated"><span class="l ku kv kw bm kx ky kz la lb di">U</span><strong class="iw hj"><em class="iv">n form分布初始化器:</em> </strong></p><p id="64cb" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">这有助于通过从-1/sqrt(扇入)到1/sqrt(扇入)之间的值范围中选择权重来识别我们的神经网络的最佳初始值。</p><p id="c08b" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">建议将这种初始化技术与Sigmoid激活函数一起使用，因为它在许多测试案例中一直显示出很好的结果。</p><p id="7dd7" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi kt translated"><span class="l ku kv kw bm kx ky kz la lb di">X</span><strong class="iw hj">T3】阿维尔(Glorot)初始值:T5】</strong></p><p id="0016" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在这种初始化技术下，有两种类型的权重初始化器，</p><p id="6491" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> 1。Xavier Normal: </strong>这里的权重是从均值(<strong class="iw hj"> μ)= </strong> 0 <strong class="iw hj"> </strong>和标准差(<strong class="iw hj">σ</strong>)=√2/√扇入+扇出的正态分布值范围中选择的。</p><p id="4137" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> <em class="iv"> Keras代码:</em></strong><em class="iv">model . add(Dense(32，kernel _ initializer = " glorat _ normal ")</em></p><p id="d902" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> 2。Xavier Uniform: </strong>这个初始化器从一个均匀分布中选择初始权重，该分布在由<strong class="iw hj">W∞U[-√6/√扇入+扇出，√6/√扇入+扇出]给出的值之间。</strong></p><p id="f53d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> <em class="iv"> Keras代码:</em></strong><em class="iv">model . add(Dense(32，kernel _ initializer = " glorat _ uniform ")</em></p><p id="44cc" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi kt translated"><span class="l ku kv kw bm kx ky kz la lb di">何</span> <strong class="iw hj"> <em class="iv">初始值:</em> </strong></p><p id="0b29" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">Bengio和Glorot在提出权重初始化概念时使用了sigmoid激活函数，因为这是唯一的选择。然而，当与这项技术一起使用时，ReLU激活函数超过了Sigmoid的结果。这种技术平衡了被命名为初始化器的激活的差异。</p><p id="293e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在这种技术下有两种类型的权重初始化器。<strong class="iw hj"> 1。何(均匀):</strong>该技术从<strong class="iw hj">W∞U[-√6/√Fan-in，√6/√Fan-in ]给定的值范围内选取初始权值。</strong></p><p id="11cc" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> <em class="iv"> Keras代码:</em></strong><em class="iv">model . add(Dense(16，input_dim=self.state_size，activation="relu "，kernel _ initializer = " he _ uniform ")</em></p><p id="39a0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> 2。He(Normal): </strong>而He Normal初始化器从均值(<strong class="iw hj"> μ)= </strong> 0 <strong class="iw hj"> </strong>、标准差(<strong class="iw hj">σ</strong>)=√2/√扇入的正态分布值中选择权重。<strong class="iw hj">W∞N(0，σ) </strong></p><p id="e9a8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> <em class="iv"> Keras代码:</em></strong><em class="iv">initializer = TF . Keras . initializer . he _ normal</em></p><p id="19fa" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><em class="iv"> model.add(Dense(16，input_dim=self.state_size，activation="relu "，kernel _ initializer = initializer)</em></p><blockquote class="iq ir is"><p id="5198" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我发表这篇博文是为了阐述我的学习，并让它对那些开始数据科学领域之旅的人有用。如果你喜欢，请阅读并鼓掌回应。</p></blockquote><blockquote class="lc"><p id="b031" class="ld le hi bd lf lg lh li lj lk ll jr dx translated">关注我，获取更多关于数据科学的文章。感谢阅读。</p></blockquote></div></div>    
</body>
</html>