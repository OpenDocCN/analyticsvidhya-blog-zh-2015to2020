<html>
<head>
<title>Inventory Prediction (Intermittent Demands) with KNN &amp; RNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">KNNå’ŒRNNçš„åº“å­˜é¢„æµ‹(é—´æ­‡éœ€æ±‚)</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/analytics-vidhya/inventory-prediction-intermittent-demands-with-knn-rnn-b14f9388bdbf?source=collection_archive---------7-----------------------#2020-03-20">https://medium.com/analytics-vidhya/inventory-prediction-intermittent-demands-with-knn-rnn-b14f9388bdbf?source=collection_archive---------7-----------------------#2020-03-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/db0f2d559f5d6afaf82097be3d0e270d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mO2o_dGJvDm1uT1RPa22UA.jpeg"/></div></div></figure><p id="8ae0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">å“‡å“¦ï¼</p><p id="a7ee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æœºå™¨å­¦ä¹ å·²ç»è¿›è¡Œäº†6ä¸ªæœˆï¼Œè¿™æ˜¯æˆ‘çš„â€œç¬¬ä¸€ä¸ªâ€æŒ‘æˆ˜(å°è¯•ç”¨æˆ‘åœ¨è¿‡å»6ä¸ªæœˆé‡Œå­¦åˆ°çš„ä¸œè¥¿é‡åšæˆ‘è¿‡å»çš„é¡¹ç›®)</p><p id="309e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">â­ <em class="jo">å…ˆå†³æ¡ä»¶</em> <br/> <em class="jo"> 1) Kè¿‘é‚»<br/> 2)é€’å½’ç¥ç»ç½‘ç»œ</em></p><p id="38ea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">â­ <em class="jo">è¿™ç¯‡æ–‡ç« çš„ç›®çš„<br/>è¯¦è¿°äº†æˆ‘çš„é¡¹ç›®æ–¹æ³•ã€‚æˆ‘æ˜¯æ¥å­¦ä¹ çš„ï¼ä»»ä½•äººæœ‰ä»»ä½•å»ºè®®/åé¦ˆï¼Œè¯·éšæ—¶åœ¨ä¸‹é¢è¯„è®ºï¼</em></p><p id="4dbd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æˆ‘ä»¬å¼€å§‹å§ï¼ğŸ’ª</p><h1 id="98bc" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">ç›®å½•</h1><p id="9185" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">ğŸ¼<a class="ae ks" href="#2ef6" rel="noopener ugc nofollow"> <strong class="is hj">é¡¹ç›®æ¦‚è¿°</strong> </a> <br/>ğŸ¼<a class="ae ks" href="#c991" rel="noopener ugc nofollow"> <strong class="is hj">ã€æˆ‘çš„å°è¯•ã€‘é¡¹ç›®#1 (RNN) </strong> </a> <br/>ğŸ¼<a class="ae ks" href="#0232" rel="noopener ugc nofollow"> <strong class="is hj">é¡¹ç›®å¤–å¸¦</strong> </a></p><h1 id="2ef6" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">é¡¹ç›®æ¦‚è¿°</strong></h1><p id="a889" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">æ›¾ç»æœ‰ä¸€ä¸ªé¡¹ç›®è¦æ±‚æ‚¨é¢„æµ‹åº“å­˜é”€å”®ï¼Œè€Œæ‚¨çš„å›¢é˜Ÿæ”¶åˆ°çš„å”¯ä¸€æ•°æ®æ˜¯æ¯ä¸ªåº“å­˜é¡¹ç›®çš„æ¯æœˆé”€å”®æ•°å­—ï¼Ÿé”€å”®ç”šè‡³æ˜¯ç¨€ç–å’Œæ–­æ–­ç»­ç»­çš„(å³ä¸å®šæœŸå‘ç”Ÿ)ï¼Œä½¿å¾—ä»»ä½•ç§ç±»çš„é¢„æµ‹ä¹ä¸€çœ‹ä¼¼ä¹æ˜¯ä¸å¯èƒ½çš„ã€‚</p><p id="7ecd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ä¸ºäº†æ›´æ¸…æ¥šåœ°äº†è§£æˆ‘çš„å›¢é˜Ÿéœ€è¦å¤„ç†ä»€ä¹ˆï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹æ•°æ®æˆªå›¾(æ•°æ®è¢«å±è”½ä»¥éšè—æ•æ„Ÿä¿¡æ¯)ã€‚ç”±äºä¸šåŠ¡æ€§è´¨(ä¿®ç†å·¥ä¸šæœºæ¢°)ï¼Œé”€å”®æ˜¯æ–­æ–­ç»­ç»­çš„ã€‚</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/f3f76328e6c87debb9b3ab29542a9f2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dB1os_lPMeSsFEamLVbZ4g.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">å›¾1:æ•°æ®æˆªå›¾</figcaption></figure><p id="972e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æˆ‘ä»¬çš„ç¬¬ä¸€ååº”æ˜¯è·å–æ›´å¤šçš„æ•°æ®ï¼Œå¦åˆ™æˆ‘ä»¬æ€ä¹ˆèƒ½ä»…å‡­ä¸Šé¢çš„æ•°æ®è¿›è¡Œé¢„æµ‹å‘¢ï¼Ÿä¸å¹¸çš„æ˜¯ï¼Œå¯¹äºæˆ‘çš„å›¢é˜Ÿæ¥è¯´ï¼Œè¿™å¹¶æ²¡æœ‰æŒ‰è®¡åˆ’è¿›è¡Œï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸å¾—ä¸åˆ©ç”¨æˆ‘ä»¬æ‰€æ‹¥æœ‰çš„ã€‚</p><p id="fa58" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æœ€ç»ˆï¼Œç»“æœæ˜¯<strong class="is hj">ä¸ä»¤äººæ»¡æ„</strong>ã€‚</p><p id="8b02" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">åœ¨äº†è§£äº†å„ç§æœºå™¨å­¦ä¹ æ¨¡å‹åï¼Œæˆ‘å†³å®šå†æ¬¡å°è¯•è¿™ä¸ªé¡¹ç›®ï¼Œå¸Œæœ›èƒ½å–å¾—æ›´å¥½çš„ç»“æœã€‚</p><h1 id="c991" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">æˆ‘å°è¯•è§£å†³é¡¹ç›®#1 (RNN)</h1><p id="801e" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated"><strong class="is hj">ä¸ºè§£å†³é—®é¢˜è€Œé‡‡å–çš„æ­¥éª¤æ¦‚è¿°:</strong></p><ol class=""><li id="a863" class="lc ld hi is b it iu ix iy jb le jf lf jj lg jn lh li lj lk bi translated"><a class="ae ks" href="#995a" rel="noopener ugc nofollow">æ¢ç´¢æ€§æ•°æ®åˆ†æ(â€˜EDAâ€™)</a></li><li id="d2c1" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated"><a class="ae ks" href="#da6e" rel="noopener ugc nofollow">æ•°æ®é¢„å¤„ç†</a></li><li id="48ab" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated"><a class="ae ks" href="#7281" rel="noopener ugc nofollow">ç”¨æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹(RNN) </a></li></ol></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><h2 id="995a" class="lx jq hi bd jr ly lz ma jv mb mc md jz jb me mf kd jf mg mh kh jj mi mj kl mk bi translated">æ­¥éª¤1)æ¢ç´¢æ€§æ•°æ®åˆ†æ(â€œEDAâ€)</h2><p id="665a" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">æˆ‘ä¸ä¼šæ·±å…¥æ¢è®¨ä¸ºEDAåšäº†ä»€ä¹ˆã€‚ä¸ºäº†èŠ‚çœä½ çš„æ—¶é—´ï¼Œè®©æˆ‘ä»¬ç›´æ¥è·³åˆ°ç»“æœã€‚å¯¹äºé‚£äº›ä¸ç¡®å®šEDAæ˜¯ä»€ä¹ˆçš„äººï¼Œè¿™é‡Œæœ‰ä¸€ç¯‡å…³äºå®ƒçš„å¥½æ–‡ç« ã€‚<a class="ae ks" rel="noopener" href="/code-heroku/introduction-to-exploratory-data-analysis-eda-c0257f888676">ç‚¹å‡»è¿™é‡Œ</a></p><p id="f1dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">æ ¹æ®EDAï¼Œä»¥ä¸‹æ˜¯è°ƒæŸ¥ç»“æœ:</strong></p><ol class=""><li id="0b31" class="lc ld hi is b it iu ix iy jb le jf lf jj lg jn lh li lj lk bi translated">æ•°æ®é›†ç¨€ç–ï¼Œè¶…è¿‡95%çš„æ•°æ®é”€å”®æ—¶é—´å°‘äº15/33ä¸ªæœˆï¼›</li><li id="2bfe" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">æŸäº›åº“å­˜é¡¹ç›®çš„é”€å”®é«˜åº¦ç›¸å…³ï¼Œå› ä¸ºå·¥ä¸šæœºæ¢°çš„ç»´ä¿®é€šå¸¸éœ€è¦åº“å­˜çš„ç»„åˆï¼›</li><li id="ad33" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">è¿‡å»å‡ ä¸ªæœˆçš„é”€å”®å¯¹äºé¢„æµ‹å½“æœˆçš„é”€å”®å¾ˆæœ‰ç”¨(é”€å”®é€šå¸¸åŸºäºæŒç»­å‡ ä¸ªæœˆçš„é¡¹ç›®ï¼›</li><li id="6452" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">æ•°æ®é›†æ˜¯æœ‰é™çš„ï¼Œæ¯ä¸ªåº“å­˜é¡¹ç›®ä»…æä¾›äº†30+æœˆé”€å”®é¢ã€‚æ€»å…±æœ‰400å¤šä¸ªç‹¬ç‰¹çš„åº“å­˜é¡¹ç›®ã€‚</li></ol><p id="7df2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">åŸºäºä»¥ä¸Šå‘ç°ï¼Œä»¥ä¸‹æ˜¯æˆ‘çš„è¡ŒåŠ¨è®¡åˆ’:</p><ol class=""><li id="5581" class="lc ld hi is b it iu ix iy jb le jf lf jj lg jn lh li lj lk bi translated">ä»…å¯¹é”€å”®é¢â‰¥15/33ä¸ªæœˆçš„åº“å­˜è¿›è¡Œé¢„æµ‹ã€‚å¯¹äºé‚£äº›æœ‰&lt;15/33 months, I believe that the client should not stock up;</li><li id="5e67" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">Categorize each inventory item using K-nearest neighbors algorithm (â€˜KNNâ€™);</li><li id="4ff6" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">Use Recurrent Neural Network (â€˜RNNâ€™) model where the past 3 months sales will be used to predict current months sales;</li><li id="9781" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">Assume that all inventories in a category behaves similarly. We will train the RNN model using all data from all inventories in a category. Prediction of an inventory will be based on the category it belongs to.</li></ol><p id="ba25" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">é”€å”®çš„äºº(ä»¥ä¸Šæ˜¯æˆ‘ç›®å‰èƒ½åšå‡ºçš„æœ€ä½³åˆ¤æ–­ï¼Œå¦‚æœæœ‰äººæœ‰æ›´å¥½çš„æ–¹æ³•ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼)</em></p></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><h2 id="da6e" class="lx jq hi bd jr ly lz ma jv mb mc md jz jb me mf kd jf mg mh kh jj mi mj kl mk bi translated">æ­¥éª¤2)æ•°æ®çš„é¢„å¤„ç†</h2><p id="56e5" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated"><strong class="is hj">é‡‡å–ä»¥ä¸‹æ­¥éª¤å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†:</strong></p><ol class=""><li id="13a7" class="lc ld hi is b it iu ix iy jb le jf lf jj lg jn lh li lj lk bi translated"><a class="ae ks" href="#73ce" rel="noopener ugc nofollow">ä»æ•°æ®é›†</a>ä¸­è¿‡æ»¤å‡º&lt; 15/33æœˆé”€å”®é¢çš„å­˜è´§é¡¹ç›®</li><li id="b67b" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated"><a class="ae ks" href="#d2e1" rel="noopener ugc nofollow">K-æœ€è¿‘é‚»(â€˜KNNâ€™)å¯¹å‰©ä½™åº“å­˜é¡¹ç›®è¿›è¡Œåˆ†ç±»</a></li><li id="c817" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated"><a class="ae ks" href="#2826" rel="noopener ugc nofollow">å°†åˆ†ç±»æ•°æ®é›†åˆ†å‰²æˆè®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†</a></li><li id="9e62" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated"><a class="ae ks" href="#7281" rel="noopener ugc nofollow">å°†è®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†æ‹†åˆ†ä¸ºX (3ä¸ªæœˆå‰)å’Œy(å½“æœˆ)</a></li><li id="0ed2" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated"><a class="ae ks" href="#62ab" rel="noopener ugc nofollow">ç¼©æ”¾æ•°æ®é›†</a></li></ol><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="5db9" class="lx jq hi mm b fi mq mr l ms mt"># Import libraries<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="fafc" class="lx jq hi mm b fi mu mr l ms mt">import math<br/>from sklearn.metrics import r2_score, mean_squared_error<br/>from sklearn.preprocessing import MinMaxScaler, RobustScaler<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.cluster import KMeans</span><span id="a24e" class="lx jq hi mm b fi mu mr l ms mt">from keras.models import Sequential<br/>from keras.layers import Dense<br/>from keras.layers import LSTM<br/>from keras.layers import Dropout<br/>from keras import optimizers</span></pre><p id="73ce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 1ã€‚ä»æ•°æ®é›†</strong>ä¸­è¿‡æ»¤å‡º&lt; 15/33æœˆé”€å”®é¢çš„åº“å­˜é¡¹ç›®</p><p id="efde" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æˆ‘è¿è¡Œäº†ä¸‹é¢çš„ä»£ç æ¥è·å–ä¸€ä¸ªæ•°æ®é›†â€˜inventory _ df â€™,å®ƒåŒ…å«é”€å”®é¢â‰¥ 15/33ä¸ªæœˆçš„åº“å­˜ã€‚</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="4261" class="lx jq hi mm b fi mq mr l ms mt"># Importing the training set<br/>dataset = pd.read_csv("Data_Modified.csv")</span><span id="4ed2" class="lx jq hi mm b fi mu mr l ms mt"># Extract the inventories features<br/>inventory_df = dataset.iloc[:,1:].astype('int')</span><span id="d4de" class="lx jq hi mm b fi mu mr l ms mt"># Filter out inventories that has sales of &lt;15/33 months<br/>number_of_zeroes = (inventory_df == 0).astype(int).sum(axis=0)</span><span id="f8e7" class="lx jq hi mm b fi mu mr l ms mt">insufficient_data_columns = []<br/>for inventory in range (0, inventory_df.shape[1]):<br/>    if inventory_df.shape[0] - number_of_zeroes[inventory] &lt;=17:<br/>        insufficient_data_columns.append(inventory)</span><span id="0644" class="lx jq hi mm b fi mu mr l ms mt">inventory_df = inventory_df.drop(inventory_df.iloc[:, insufficient_data_columns], axis=1)</span></pre><p id="d2e1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2ã€‚k-æœ€è¿‘é‚»(' KNN ')å¯¹å‰©ä½™åº“å­˜é¡¹ç›®è¿›è¡Œåˆ†ç±»</strong></p><p id="f74a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ç„¶åï¼Œæˆ‘ç»§ç»­ç»˜åˆ¶ç±»å†…å¹³æ–¹å’Œ(wcss)ä¸ç±»æ•°çš„å…³ç³»å›¾ï¼Œä»¥æ‰¾åˆ°åº“å­˜é¡¹ç›®çš„æœ€ä½³ç±»åˆ«æ•°ã€‚</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="3e94" class="lx jq hi mm b fi mq mr l ms mt">from sklearn.cluster import KMeans</span><span id="a8ac" class="lx jq hi mm b fi mu mr l ms mt"># Using the elbow method to find the optimal number of clusters<br/>inventory_array = inventory_df.T.iloc[:,:].astype('int').values<br/>wcss = []<br/>for i in range(1,15):<br/>    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)<br/>    kmeans.fit(inventory_array)<br/>    wcss.append(kmeans.inertia_)<br/>plt.plot(range(1, 15), wcss)<br/>plt.title('The Elbow Method')<br/>plt.xlabel('Number of clusters')<br/>plt.ylabel('WCSS')<br/>plt.show()</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/9f908202223f5ddf89ab8f64c4ef6601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*mwcmsHy2mBlyVPvVY9HZwQ.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">å›¾2:è‚˜æ³•</figcaption></figure><p id="f2b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ä»æ¨¡å‹ä¸­ï¼Œæˆ‘é€‰æ‹©èšç±»ä¸º4ã€‚å¦‚æœä½ æƒ³æ›´å¤šåœ°äº†è§£KNNï¼Œæˆ‘å‘ç°äº†ä¸€ç¯‡å¯¹æˆ‘å¾ˆæœ‰ç”¨çš„æ–‡ç« ã€‚<a class="ae ks" href="https://towardsdatascience.com/a-simple-introduction-to-k-nearest-neighbors-algorithm-b3519ed98e" rel="noopener" target="_blank">ç‚¹å‡»è¿™é‡Œ</a></p><p id="0c13" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">å°†k-meansåº”ç”¨äºæ•°æ®é›†ï¼Œä»¥è·å¾—ä¸€ä¸ªåˆ—è¡¨â€œinventory_with__categories â€,è¯¥åˆ—è¡¨å°†æ¯ä¸ªåº“å­˜ç¼–å·ä¸å…¶å„è‡ªçš„ç±»åˆ«(0â€“3)ç›¸åŒ¹é…ã€‚</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="7337" class="lx jq hi mm b fi mq mr l ms mt"># Applying k-means to the dataset<br/>kmeans = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=0)<br/>categories = kmeans.fit_predict(X)</span><span id="9aa6" class="lx jq hi mm b fi mu mr l ms mt"># Create a list matching inventory numbers with their category<br/>inventory_with_categories = []<br/>for i in range (len(inventory_df.columns)):<br/>    one_inventory_with_category = [inventory_df.columns[i], categories[i]]<br/>    inventory_with_categories.append(one_inventory_with_category)</span></pre><p id="e926" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æ ¹æ®ç±»åˆ«â€œinventory_with_categoriesâ€æ‹†åˆ†åŸå§‹æ•°æ®é›†â€œinventory_dfâ€ã€‚è¿™å…è®¸æˆ‘å¾—åˆ°â€˜complete _ datasetâ€™ï¼Œä¸€ä¸ªåŒ…å«æ¯ä¸ªç±»åˆ«æ•°æ®é›†çš„åˆ—è¡¨ã€‚</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="dc85" class="lx jq hi mm b fi mq mr l ms mt"># Split the dataset by categories<br/>def split_dataset_by_category (inventory_dataset, inventory_categories, number_of_categories=4):<br/>    complete_dataset = []<br/>    for i in range(number_of_categories):<br/>        training_set_cat = pd.DataFrame()<br/>        for inventorynumber, category in inventory_categories:<br/>            if category == i:<br/>                if training_set_cat.empty:<br/>                    training_set_cat = inventory_dataset.loc[:,[inventorynumber]]<br/>                else:<br/>                    training_set_cat = pd.concat([training_set_cat, inventory_dataset.loc[:, [inventorynumber]]], axis=1)<br/>        complete_dataset.append(training_set_cat)<br/>    <br/>    return complete_dataset</span><span id="5119" class="lx jq hi mm b fi mu mr l ms mt">complete_dataset = split_dataset_by_category (inventory_df, inventory_with_categories, number_of_categories=4)</span></pre><p id="3e38" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æ­¤æ—¶ï¼Œæˆ‘æ³¨æ„åˆ°æœ‰äº›ç±»åˆ«åŒ…å«è¶…è¿‡5ä¸ªåº“å­˜é¡¹ç›®ï¼Œè¿™å¯¹æ¨¡å‹çš„è®­ç»ƒæ¥è¯´å¤ªå°‘äº†ã€‚</p><p id="cf3e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æˆ‘å°è¯•ç”¨ä¸åŒçš„å˜åŒ–é‡åšæ•´ä¸ªè¿‡ç¨‹(ä¾‹å¦‚ï¼Œæ”¹å˜ç±»åˆ«çš„æ•°é‡ï¼Œå°†â‰¤ 15/33ä¸ªæœˆæ”¹ä¸ºâ‰¤ 10/33ä¸ªæœˆç­‰ã€‚)ï¼Œå¸Œæœ›èƒ½åœ¨æ¯ä¸ªå“ç±»ä¸­è·å¾—æ›´å¤šçš„åº“å­˜å•†å“ã€‚ç„¶è€Œï¼Œä¸€äº›ç±»åˆ«ä»ç„¶åªæœ‰å¾ˆå°‘çš„åº“å­˜é¡¹ç›®ã€‚</p><p id="65ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æ— è®ºå¦‚ä½•ï¼Œæˆ‘å†³å®šç»§ç»­è¿™ä¸ªé¡¹ç›®ï¼Œå¹¶ä½¿ç”¨åº“å­˜é¡¹ç›®æ•°é‡æœ€å¤šçš„ç±»åˆ«(ç±»åˆ«= 0ï¼Œåº“å­˜æ•°é‡= 69)æ¥ç²—ç•¥äº†è§£ä½¿ç”¨RNNæ˜¯å¦æ˜¯ä¸€ç§åˆç†çš„æ–¹æ³•ã€‚</p><p id="2826" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3ã€‚å°†åˆ†ç±»æ•°æ®é›†åˆ†æˆè®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†</strong></p><p id="4c46" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">å°†â€œå®Œæ•´æ•°æ®é›†â€æ‹†åˆ†ä¸ºâ€œå®Œæ•´è®­ç»ƒæ•°æ®é›†â€å’Œâ€œå®Œæ•´æµ‹è¯•æ•°æ®é›†â€ã€‚ä¸¤è€…éƒ½æ˜¯åŒ…å«æ¯ä¸ªç±»åˆ«çš„è®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†çš„åˆ—è¡¨ã€‚</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="40c7" class="lx jq hi mm b fi mq mr l ms mt"># Split into training and test set<br/>def split_train_test(complete_dataset):<br/>    complete_train_dataset = []<br/>    complete_test_dataset = []<br/>    for dataset in complete_dataset:<br/>        dataset_train, dataset_test = train_test_split(dataset, test_size=0.2, shuffle=False, random_state=0)<br/>        complete_train_dataset.append(dataset_train)<br/>        complete_test_dataset.append(dataset_test)<br/>    return complete_train_dataset, complete_test_dataset</span><span id="3623" class="lx jq hi mm b fi mu mr l ms mt">complete_train_dataset, complete_test_dataset = split_train_test(complete_dataset)</span></pre><p id="7281" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 4ã€‚å°†è®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†åˆ†æˆX(å‰3ä¸ªæœˆ)å’Œy(å½“å‰æœˆ)</strong></p><p id="33dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">å°†â€œcomplete_train_datasetâ€å’Œâ€œcomplete_test_datasetâ€æ‹†åˆ†ä¸ºXå’Œyã€‚X(è¿‡å»3ä¸ªæœˆçš„é”€å”®é¢)å°†ç”¨äºé¢„æµ‹y(å½“æœˆé”€å”®é¢)ã€‚è¿™å…è®¸æˆ‘è¿”å›â€˜split _ complete _ train _ datasetâ€™å’Œâ€˜split _ complete _ test _ dataset â€™,è¿™ä¸¤ä¸ªåˆ—è¡¨éƒ½åŒ…å«æ¯ä¸ªç±»åˆ«Xå’Œyã€‚</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="e2da" class="lx jq hi mm b fi mq mr l ms mt">def split_into_batches(complete_dataset, batch=3):<br/>    split_dataset = []<br/>    for dataset in complete_dataset:<br/>        dataset = dataset.values<br/>        <br/>        X_total = [] # 3 month input for EACH COLUMN<br/>        y_total = [] # 1 month output for EACH COLUMNS<br/>        for inventory in range (0, dataset.shape[1]):<br/>            X = []<br/>            y = []<br/>            for i in range(batch, dataset.shape[0]):<br/>                X.append(dataset[i-batch:i, inventory])<br/>                y.append(dataset[i, inventory])<br/>                <br/>            X, y = np.array(X), np.array(y)<br/>        <br/>            X_total.append(X)<br/>            y_total.append(y)<br/>        <br/>        X_total = np.concatenate(X_total)<br/>        y_total = np.concatenate(y_total)<br/>        <br/>        split_dataset.append([X_total, y_total])<br/>        <br/>    return split_dataset</span><span id="c08b" class="lx jq hi mm b fi mu mr l ms mt">split_complete_train_dataset = split_into_batches(complete_train_dataset, batch=3)<br/>split_complete_test_dataset = split_into_batches(complete_test_dataset, batch=3)</span></pre><p id="62ab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 5ã€‚ç¼©æ”¾æ•°æ®é›†</strong></p><p id="99bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">å¯¹äºé¢„å¤„ç†çš„æœ€åä¸€æ­¥ï¼Œæˆ‘ä½¿ç”¨äº†<a class="ae ks" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html" rel="noopener ugc nofollow" target="_blank"> sklearné²æ£’å®šæ ‡å™¨</a>ã€‚æˆ‘é€‰æ‹©äº†è¿™ä¸ªå®šæ ‡å™¨ï¼Œå› ä¸ºå®ƒå¯¹â€œå¼‚å¸¸å€¼â€å…·æœ‰å¾ˆå¼ºçš„é²æ£’æ€§ï¼Œå› ä¸ºæ•°æ®ç¨€ç–ï¼Œé”€å”®æ–­æ–­ç»­ç»­ï¼Œé”€å”®å¯ä»¥è¢«è§†ä¸ºâ€œå¼‚å¸¸å€¼â€ã€‚</p><p id="4ab7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ç¼©æ”¾åï¼Œæˆ‘å¾—åˆ°' scaled _ split _ complete _ train _ dataset 'ï¼Œ' scaled _ split _ complete _ test _ dataset 'å’Œ' complete_y_train_scalers 'ã€‚â€œcomplete_y_train_scalersâ€æ˜¯æœ€åé¢„æµ‹çš„é€†å˜æ¢æ‰€å¿…éœ€çš„ã€‚</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="a194" class="lx jq hi mm b fi mq mr l ms mt"># Scale using RobustScaler<br/>def robust_scaler_reshape(split_complete_train_dataset, split_complete_test_dataset):<br/>    scaled_split_complete_train_dataset = []<br/>    complete_y_train_scalers = []<br/>    <br/>    scaled_split_complete_test_dataset = []<br/>    <br/>    for i in range (len(split_complete_train_dataset)):<br/>        # Scale and reshape X_train<br/>        sc_train_X = RobustScaler(quantile_range=(25.0, 75.0))<br/>        X_train_scaled = sc_train_X.fit_transform(split_complete_train_dataset[i][0])<br/>        X_train_scaled = np.reshape(X_train_scaled, (X_train_scaled.shape[0], X_train_scaled.shape[1], 1))<br/>        <br/>        # Scale and reshape X_test<br/>        X_test_scaled = sc_train_X.transform(split_complete_test_dataset[i][0])<br/>        X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0], X_test_scaled.shape[1], 1))<br/>        <br/>        # Scale and reshape y_train<br/>        sc_train_y = RobustScaler(quantile_range=(25.0, 75.0))<br/>        y_train_scaled = sc_train_y.fit_transform(split_complete_train_dataset[i][1].reshape(-1, 1))<br/>        <br/>        # Scale and reshape y_test<br/>        y_test_scaled = sc_train_y.transform(split_complete_test_dataset[i][1].reshape(-1, 1))<br/>        <br/>        scaled_split_complete_train_dataset.append([X_train_scaled, y_train_scaled])<br/>        scaled_split_complete_test_dataset.append([X_test_scaled, y_test_scaled])<br/>        complete_y_train_scalers.append(sc_train_y)<br/>        <br/>    return scaled_split_complete_train_dataset, scaled_split_complete_test_dataset, complete_y_train_scalers    <br/>    <br/>scaled_split_complete_train_dataset, scaled_split_complete_test_dataset, complete_y_train_scalers = robust_scaler_reshape(split_complete_train_dataset, split_complete_test_dataset)</span></pre></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><h2 id="15f9" class="lx jq hi bd jr ly lz ma jv mb mc md jz jb me mf kd jf mg mh kh jj mi mj kl mk bi translated">æ­¥éª¤3)ç”¨æ¨¡å‹(RNN)è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹</h2><p id="a48c" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">ç”±äºé—®é¢˜çš„æ€§è´¨ï¼Œæˆ‘é€‰æ‹©äº†RNN(ä¹Ÿå°±æ˜¯è¯´ï¼Œæœ¬æœˆçš„é”€å”®é¢å¯ä»¥ç”¨ä¸Šæœˆçš„é”€å”®é¢æ¥é¢„æµ‹)ã€‚æˆ‘è¿˜å°è¯•ä½¿ç”¨å…¶ä»–ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹(å¦‚XGBoost)æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å¦‚æœæœ‰äººæƒ³çŸ¥é“è¿›å±•å¦‚ä½•ï¼Œä¸€å®šè¦è®©æˆ‘çŸ¥é“ï¼Œæˆ‘å¯ä»¥åœ¨ä»¥åå†™ä¸€ç¯‡æ–‡ç« æ¥è·Ÿè¿›ï¼ğŸ˜Š</p><p id="4999" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">é‡‡ç”¨ä»¥ä¸‹æ­¥éª¤è®­ç»ƒæ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹</strong></p><ol class=""><li id="a00b" class="lc ld hi is b it iu ix iy jb le jf lf jj lg jn lh li lj lk bi translated"><a class="ae ks" href="#fea9" rel="noopener ugc nofollow">è®­ç»ƒæ¨¡å‹</a></li><li id="fa95" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated"><a class="ae ks" href="#d14f" rel="noopener ugc nofollow">åˆ©ç”¨æµ‹è¯•æ•°æ®é¢„æµ‹</a></li><li id="a86e" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated"><a class="ae ks" href="#9c0f" rel="noopener ugc nofollow">å¯è§†åŒ–ç»“æœ</a></li></ol><p id="fea9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 1ã€‚è®­ç»ƒæ¨¡å‹</strong></p><p id="d281" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æˆ‘åˆ†åˆ«ä¸ºæ¯ä¸ªç±»åˆ«è®­ç»ƒRNNæ¨¡å‹ï¼Œå¹¶è¿”å›â€œall_modelsâ€ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«æ¯ä¸ªç±»åˆ«çš„è®­ç»ƒæ¨¡å‹çš„åˆ—è¡¨ã€‚</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="eb5a" class="lx jq hi mm b fi mq mr l ms mt">def model_training(scaled_split_complete_train_datase):<br/>    category = 0<br/>    all_models = []<br/>    for training_category in scaled_split_complete_train_datase:<br/>        <br/>        regressor = Sequential()<br/>        # Adding the first LSTM layer and some Dropout regularisation<br/>        regressor.add(LSTM(units = 500, return_sequences = True, input_shape = (training_category[0].shape[1], 1)))<br/>        regressor.add(Dropout(rate = 0.2))<br/>        <br/>        # Adding the second LSTM layer and some Dropout regularisation<br/>        regressor.add(LSTM(units = 100, return_sequences = True))<br/>        regressor.add(Dropout(rate = 0.2))<br/>        <br/>        # Adding the third LSTM layer and some Dropout regularisation<br/>        regressor.add(LSTM(units = 50, return_sequences = True))<br/>        regressor.add(Dropout(rate = 0.2))<br/>        <br/>        # Adding the fourth LSTM layer and some Dropout regularisation<br/>        regressor.add(LSTM(units = 25, return_sequences = False))<br/>        regressor.add(Dropout(rate = 0.2))<br/>        <br/>        # Adding the output layer<br/>        regressor.add(Dense(units = 1))<br/>        <br/>        # Compiling the RNN<br/>        adam = optimizers.Adam(lr=0.001)<br/>        regressor.compile(optimizer = adam, loss = 'mean_squared_error')</span><span id="6f43" class="lx jq hi mm b fi mu mr l ms mt"># Fitting the RNN to the Training set<br/>        history = regressor.fit(training_category[0], training_category[1], epochs = 500, batch_size = 10, use_multiprocessing=True) #Usually 200 epochs<br/>        <br/>        category += 1<br/>        print(f'MSE for category {category}: {str(history.history["loss"])}')<br/>        <br/>        all_models.append(regressor)<br/>        <br/>    return all_models</span><span id="05c4" class="lx jq hi mm b fi mu mr l ms mt">all_models = model_training(scaled_split_complete_train_dataset)</span></pre><p id="d14f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2ã€‚åˆ©ç”¨æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹</strong></p><p id="fbf3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ä½¿ç”¨ä¸Šé¢è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ‘å¯¹æµ‹è¯•æ•°æ®é›†è¿›è¡Œäº†é¢„æµ‹ï¼Œå¹¶è¿”å›äº†â€œæ¨¡å‹_æ€§èƒ½â€å’Œâ€œæ‰€æœ‰_é¢„æµ‹â€ã€‚<br/>â€œæ¨¡å‹_æ€§èƒ½â€åŒ…å«æ¯ä¸ªæ¨¡å‹çš„R2å’ŒRMSEã€‚<br/>â€˜all _ predictionsâ€™æ˜¯åŒ…å«æ¯ä¸ªé¢„æµ‹çš„æ•°æ®å¸§çš„åˆ—è¡¨ã€‚æ¯ä¸ªæ•°æ®å¸§éƒ½æœ‰é¢„æµ‹æ•°æ®é›†å’Œå®é™…æ•°æ®é›†ã€‚</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="d569" class="lx jq hi mm b fi mq mr l ms mt">def model_predict(all_models, scaled_split_complete_test_dataset, complete_y_train_scalers):<br/>    model_performance = []<br/>    all_predictions = []<br/>    for i in range(len(all_models)):<br/>        predicted_inventory_sale = all_models[i].predict(scaled_split_complete_test_dataset[i][0])<br/>        predicted_inventory_sale = complete_y_train_scalers[i].inverse_transform(predicted_inventory_sale)<br/>        tested_inventory_sale = complete_y_train_scalers[i].inverse_transform(scaled_split_complete_test_dataset[i][1])<br/>        <br/>        # Analysis of model performance<br/>        R_squared = r2_score(tested_inventory_sale, predicted_inventory_sale)<br/>        RMSE = math.sqrt(mean_squared_error(tested_inventory_sale, predicted_inventory_sale))<br/>        model_performance.append([i, R_squared, RMSE])<br/>        <br/>        # Combine predictions into a dataframe<br/>        predictions = np.concatenate([tested_inventory_sale.reshape(-1,1), predicted_inventory_sale.reshape(-1,1)], axis=1)<br/>        predictions = pd.DataFrame(predictions, columns=['total_test', 'total_pred'])  <br/>        all_predictions.append(predictions)<br/>        <br/>    model_performance = pd.DataFrame(model_performance, columns=['category', 'R2', 'RMSE'])  <br/>    <br/>    return model_performance, all_predictions</span><span id="fa71" class="lx jq hi mm b fi mu mr l ms mt">model_performance, all_predictions = model_predict(all_models, scaled_split_complete_test_dataset, complete_y_train_scalers)</span></pre><p id="9c0f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3ã€‚å¯è§†åŒ–æˆ‘ä»¬çš„ç»“æœï¼</strong></p><p id="a917" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">è®©æˆ‘ä»¬é¦–å…ˆæ¥çœ‹çœ‹æˆ‘ä»¬çš„æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®ä¸Šçš„è¡¨ç°</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mw"><img src="../Images/7fc63dc119f00d13d0facbc642c7397b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*tVJzc5W0B8s0s9px29uksw.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">å›¾3:æ¯ä¸ªç±»åˆ«çš„æ¨¡å‹æ€§èƒ½</figcaption></figure><p id="367d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ä¸Šè¡¨æ˜¾ç¤ºäº†æ¯ä¸ªç±»åˆ«çš„æ¨¡å‹æ€§èƒ½ã€‚å¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬å°†åªæŸ¥çœ‹ç±»åˆ«0å’Œç±»åˆ«1ï¼Œç±»åˆ«2å’Œç±»åˆ«3ä¸­åªæœ‰1ä¸ªåº“å­˜é¡¹ç›®ã€‚</p><p id="3c39" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ä»è¡¨ä¸­å¯ä»¥çœ‹å‡ºï¼Œè¯¥æ¨¡å‹çš„R2å¾—åˆ†è¾ƒä½ï¼Œè¡¨ç°ä¸ä½³ã€‚</p><p id="6dad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä¸ºç±»åˆ«0ç»˜åˆ¶ä¸€ä¸ªç®€å•çš„å›¾å½¢ï¼</p><pre class="ku kv kw kx fd ml mm mn mo aw mp bi"><span id="8c3a" class="lx jq hi mm b fi mq mr l ms mt"># Visualise predictions for category 0<br/>plt.plot(all_predictions[1].loc[:, 'total_test'].values, color = 'red', label = 'Pred')<br/>plt.plot(all_predictions[1].loc[:, 'total_pred'].values, color = 'blue', label = 'Real')<br/>plt.title('Inventory Sale Prediction')<br/>plt.xlabel('Time')<br/>plt.ylabel('Inventory Sale')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mx"><img src="../Images/c1d1e62fe5d4d1f06f76be0853eb74fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*tf9fIjxQVba1-IQ5HRbUJQ.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">å›¾4:ç±»åˆ«0çš„é¢„æµ‹ä¸å®é™…(åº“å­˜é”€å”®)çš„å›¾è¡¨</figcaption></figure><p id="deab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ä»å›¾è¡¨æ¥çœ‹ï¼Œè¿™ä¸ªæ¨¡å‹ä¼¼ä¹é¢„æµ‹å¾—å¾ˆå¥½ã€‚ä½R2åˆ†æ•°å¾ˆå¯èƒ½æ¥è‡ªäºå°–å³°ä¿¡å·ã€‚ç”¨RNNæ¨¡å‹çš„å…¶ä»–å‚æ•°é‡æ–°è®­ç»ƒè¯¥æ¨¡å‹å¾ˆå¯èƒ½ä¼šäº§ç”Ÿæ›´å¥½çš„ç»“æœã€‚</p><h1 id="0232" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">å¤–å–é£Ÿå“</h1><p id="13d6" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">å”·ï¼ç»ˆäºæå®šäº†ã€‚è¿™ä¸ªé¡¹ç›®æ€»å…±èŠ±äº†æˆ‘2å¤©æ—¶é—´ï¼Œä»¥ä¸‹æ˜¯æˆ‘çš„ä¸»è¦æ”¶è·:</p><ol class=""><li id="ded6" class="lc ld hi is b it iu ix iy jb le jf lf jj lg jn lh li lj lk bi translated">RNNæ¨¡å‹è‚¯å®šå¯ä»¥ç”¨æ¥é¢„æµ‹è¿™æ ·çš„æ•°æ®é›†ã€‚æˆ‘ç›¸ä¿¡å¦‚æœåº“å­˜åˆ†ç±»èƒ½å¤Ÿå’Œå®¢æˆ·ä¸€èµ·å®Œæˆï¼Œæ¨¡å‹çš„æ€§èƒ½ä¼šæ›´å¥½ã€‚æ­¤å¤–ï¼Œæ›´å¤šçš„æ•°æ®(ä¾‹å¦‚ï¼Œæ›´å¤šçš„æœˆé”€å”®é¢)è‚¯å®šä¼šäº§ç”Ÿæ›´å¥½çš„æ¨¡å‹ã€‚</li></ol><p id="dccb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">æœºå™¨å­¦ä¹ é¢†åŸŸæˆ‘è¿˜æ˜¯æ–°æ‰‹ã€‚å¦‚æœæ‚¨å¯¹å¦‚ä½•æ”¹è¿›è¯¥æ–¹æ³•æœ‰ä»»ä½•å»ºè®®/åé¦ˆï¼Œè¯·åœ¨ä¸‹é¢ç•™ä¸‹æ‚¨çš„è¯„è®ºï¼ğŸ™‡</p></div></div>    
</body>
</html>