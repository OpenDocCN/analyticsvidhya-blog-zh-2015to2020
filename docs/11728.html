<html>
<head>
<title>A guide to underrated Machine Learning Algorithms— Alternatives to Decision-Tree and Random Forest classifiers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">被低估的机器学习算法指南——决策树和随机森林分类器的替代品</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-guide-to-underrated-machine-learning-algorithms-alternatives-to-decision-tree-and-random-forest-6e2f8336d4d5?source=collection_archive---------5-----------------------#2020-12-16">https://medium.com/analytics-vidhya/a-guide-to-underrated-machine-learning-algorithms-alternatives-to-decision-tree-and-random-forest-6e2f8336d4d5?source=collection_archive---------5-----------------------#2020-12-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="00cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">决策树</strong>分类器是大多数数据科学家和Kagglers每天用来拟合和评估他们的数据以进行监督学习的第一批方法之一。有时，他们确实给出了一个令人满意的结果，而有时却没有。因此，在此之后，我们转向其他选择。</p><p id="9ac1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是我们能不能暂时尝试一个非常好的方法来代替随机森林或者决策树来进行快速评估？我想我们可以，但我们没有。我们只是继续在更复杂的模型(深度学习)上拟合和评估我们的数据，这可能是富有成效的(有时)。</p><p id="1fc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，我将要讨论的替代方法可以用决策树和随机森林分类器来代替，以获得更好的结果和更易于使用的方法:</p><p id="2a73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di"> 1 </span> <strong class="ih hj"> XGBoost: </strong>这个模型是大部分数据科学竞赛的心脏和灵魂。它现在也广泛用于常规项目。它用于监督学习问题，我们使用数据集中的一些特征来预测目标变量。那么使用XGBoost背后的心态是什么？</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es jm"><img src="../Images/55bf674e61394b7ec5257e076e63168d.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*p3GHXLVZsouT4bUsnjvD-Q.jpeg"/></div></figure><p id="0623" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a) XGBoost代表极限梯度提升，这是一种基于决策树的机器学习算法。它使用起来高效灵活。实践证明，该方法提高了计算速度和模型性能。</p><p id="7595" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b)虽然大型训练数据集可能需要很长时间才能适应决策树或随机森林，但XGBoost脱颖而出，适应数据的速度比以前快10倍。</p><p id="b5c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">c)它对数据集中的缺失数据进行了高效的内置处理。</p><p id="ced9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">d)更好性能背后的主要因素是用于避免过拟合的内置正则化。</p><p id="ab66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">e)其高速度背后的主要因素是它具有支持并行树构造和使用深度优先方法的块结构。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="c3d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">AdaBoost: 大多数人没听说过，有些人听说过，但没用过。但是实施过它的人知道它的能力。Yoav Freund和Robert Schapire制定了AdaBoost算法。那么为什么要用AdaBoost呢？</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kb"><img src="../Images/8dc683487714ec4f8601d61f2fda7235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ojr51_pcODmS1MmWLkgF9A.jpeg"/></div></div></figure><p id="54a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a) AdaBoost代表自适应增强，这是一种监督学习的有效方法，已知可提高整体性能。</p><p id="1636" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b)它最适合用于提升决策树在二元分类问题上的性能。</p><p id="dae8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">c)众所周知，它在准确性方面优于决策树和随机森林(没有过拟合)，尽管计算速度比后者低。</p><p id="c7b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">d)它表现如此之好的原因是，它通过组合多个表现不佳的分类器来构建一个强大的分类器，因此您将获得高精度的评估。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="585b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di"> 3 </span> <strong class="ih hj"> LightGBM: </strong>从名字上，你可能已经猜到它代表的是光线渐变增强机，由微软开发。也是除XGBoost之外，机器学习竞赛中应用最广泛的算法之一。那么为什么要选择LightGBM呢？</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kg"><img src="../Images/00a3d20114193a08573059b2866c60c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vqaO-Rrwkx0jloeVX3pe5Q.png"/></div></div></figure><p id="532d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a)众所周知，LightGBM训练速度快，效率高。</p><p id="4a53" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b)它比XGBoost更快，有时提供的结果也比XGBoost更准确。</p><p id="3381" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">c)由于其低内存使用率，其计算速度相当快，并为GPU学习提供并行支持。</p><p id="0cb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">d)它的低内存使用率也使它能够非常容易地处理大规模数据。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="f2bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di">4</span><strong class="ih hj">CatBoost:</strong>CatBoost是另一种基于决策树梯度推进的机器学习算法，由Yandex开发。同样的问题，为什么是CatBoost？</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kh"><img src="../Images/9743d1117e9b343a6be3dbcd66295f6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7RwjCnGeJ0FJgB-zfgyRkQ.png"/></div></div></figure><p id="65b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a) CatBoost算法具有较浅的树深度，与其他boosting算法相比，这导致较少的预测时间。</p><p id="e2b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b)它优雅地处理分类特征，最重要的是，它比XGBoost快8倍。</p><p id="9b8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">c)它可以像XGBoost一样有效地处理缺失值。</p><p id="b669" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">d)它减少了为提高性能而调整超参数的必要性，也降低了过拟合的机会。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="7f99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快速注意:每个模型的性能取决于您定义和调整其超参数的好坏。但是应该记住，参数的调整不会导致过度拟合。</p><p id="106d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我希望你对上面的算法有一个基本的了解，并在你未来的项目和比赛中使用它们。您可以查看它们的文档，以获得关于如何使用它们的详细见解。</p><p id="32e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，您可以查看下面提到的Kaggle笔记本，了解如何实现上述算法:</p><div class="ki kj ez fb kk kl"><a href="https://www.kaggle.com/dhruvanurag20/divorce-prediction-rf-adaboost-xgb-lgbm" rel="noopener  ugc nofollow" target="_blank"><div class="km ab dw"><div class="kn ab ko cl cj kp"><h2 class="bd hj fi z dy kq ea eb kr ed ef hh bi translated">离婚预测- RF + ADABoost + XGB + LGBM</h2><div class="ks l"><h3 class="bd b fi z dy kq ea eb kr ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用离婚预测中的数据</h3></div><div class="kt l"><p class="bd b fp z dy kq ea eb kr ed ef dx translated">www.kaggle.com</p></div></div><div class="ku l"><div class="kv l kw kx ky ku kz js kl"/></div></div></a></div><p id="27ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">祝你学习愉快！</p></div></div>    
</body>
</html>