<html>
<head>
<title>Comprehensive Hands on Guide to Twitter Sentiment Analysis with Dataset and Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">包含数据集和代码的Twitter情感分析综合实践指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/comprehensive-hands-on-guide-to-twitter-sentiment-analysis-with-dataset-and-code-960c055ada3f?source=collection_archive---------2-----------------------#2018-07-30">https://medium.com/analytics-vidhya/comprehensive-hands-on-guide-to-twitter-sentiment-analysis-with-dataset-and-code-960c055ada3f?source=collection_archive---------2-----------------------#2018-07-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9fde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自然语言处理(NLP)是目前数据科学研究的温床，NLP最常见的应用之一是情感分析。从民意调查到创建完整的营销策略，这个领域已经完全重塑了企业的工作方式，这就是为什么这是每个数据科学家都必须熟悉的领域。</p><p id="426a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以针对情感(以及包括命名实体、话题、主题等在内的其他特征)来处理数千个文本文档。)在几秒钟内，相比之下，一组人手工完成同样的任务需要几个小时。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/4dcfcee0542f96bf7ce3cbdf834751aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UjDXQPo4uXOEI4Ud.jpg"/></div></div></figure><p id="2557" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将学习如何解决<a class="ae jp" href="https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/" rel="noopener ugc nofollow" target="_blank"> Twitter情感分析练习题</a>。</p><p id="8f65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将按照解决一般情感分析问题所需的一系列步骤来完成。我们将从预处理和清理推文的原始文本开始。然后，我们将探索干净的文本，并尝试获得一些关于推文上下文的直觉。之后，我们将从数据中提取数字特征，并最终使用这些特征集来训练模型并识别推文的情绪。</p><p id="8896" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是NLP中最有趣的挑战之一，所以我很高兴能和你一起踏上这段旅程！</p><h1 id="ee19" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">目录</h1><ol class=""><li id="c7df" class="ko kp hi ih b ii kq im kr iq ks iu kt iy ku jc kv kw kx ky bi translated">理解问题陈述</li><li id="9b09" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">Tweets预处理和清理</li><li id="5ec0" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">推文中的故事生成和可视化</li><li id="af0e" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">从干净的推文中提取特征</li><li id="729c" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">模型构建:情感分析</li><li id="620e" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">下一步是什么</li></ol><h1 id="8d65" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">1.理解问题陈述</h1><p id="56f7" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">让我们看一下问题陈述，因为在处理数据集之前理解目标是非常重要的。问题陈述如下:</p><p id="c045" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh">该任务的目标是检测推文中的仇恨言论。为了简单起见，如果一条推文带有种族主义或性别歧视的情绪，我们就说这条推文包含仇恨言论。所以，任务是将种族主义或性别歧视的推文从其他推文中分类。</em> </strong></p><p id="8e44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">形式上，给定一个推文和标签的训练样本，其中标签“1”表示该推文是种族主义/性别歧视的，标签“0”表示该推文不是种族主义/性别歧视的，你的目标是预测给定测试数据集上的标签。</p><p id="a84b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">注:本练习题的评价指标为</em><strong class="ih hj"><em class="lh">F1-得分</em> </strong> <em class="lh">。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/566a5368d380361fd4fcad0f8c7c4e1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YPKl4XY1hvmQbxra.png"/></div></div></figure><p id="dcb9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就我个人而言，我非常喜欢这项任务，因为仇恨言论、网络钓鱼和社交媒体欺凌已经成为这些天的严重问题，一个能够检测这些文本的系统肯定会在使互联网和社交媒体成为一个更好和无欺凌的地方方面发挥巨大作用。现在让我们详细看看每个步骤。</p><h1 id="7ae9" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">2.Tweets预处理和清理</h1><p id="9447" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">看看下面的图片，它们描绘了办公空间的两种场景——一种是不整洁的，另一种是整洁有序的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/2863bffd72ef4acb66bde0e1b3ac2890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/0*AtlIe2Ws_DKg0jin.jpg"/></div></div></figure><p id="3a60" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您正在此办公空间中搜索文档。在哪种情况下，您更容易找到文档？当然，在不太杂乱的地方，因为每件物品都放在适当的位置。数据清理练习非常类似。如果数据以结构化的格式排列，那么就更容易找到正确的信息。</p><p id="ee44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">文本数据的预处理是必不可少的步骤，因为它使原始文本为挖掘做好准备，即，从文本中提取信息并对其应用机器学习算法变得更容易。如果我们跳过这一步，那么很有可能您正在处理有噪声和不一致的数据。这一步的目的是清除那些与寻找推文情感不太相关的噪音，如标点符号、特殊字符、数字和在文本上下文中没有多少分量的术语。</p><p id="0094" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在后面的一个阶段，我们将从Twitter文本数据中提取数字特征。该特征空间是使用整个数据中存在的所有唯一单词创建的。因此，如果我们对数据进行良好的预处理，那么我们将能够获得质量更好的特征空间。</p><p id="e92c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们首先读取数据并加载必要的库。你可以从<a class="ae jp" href="https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据集。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="6ff6" class="lp jr hi ll b fi lq lr l ls lt"><strong class="ll hj">import</strong> re <br/><strong class="ll hj">import</strong> pandas <strong class="ll hj">as</strong> pd  <br/><strong class="ll hj">import</strong> numpy <strong class="ll hj">as</strong> np  <br/><strong class="ll hj">import</strong> matplotlib.pyplot <strong class="ll hj">as</strong> plt  <br/><strong class="ll hj">import</strong> seaborn <strong class="ll hj">as</strong> sns <br/><strong class="ll hj">import</strong> string <br/><strong class="ll hj">import</strong> nltk <br/><strong class="ll hj">import</strong> warnings  <br/>warnings.filterwarnings("ignore", category=DeprecationWarning) %matplotlib inline</span><span id="70af" class="lp jr hi ll b fi lu lr l ls lt">train  = pd.read_csv('train_E6oV3lV.csv') <br/>test = pd.read_csv('test_tweets_anuFYb8.csv')</span></pre><p id="03fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们检查训练数据集的前几行。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="61a6" class="lp jr hi ll b fi lq lr l ls lt">train.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lv"><img src="../Images/96bdce8717f71d5d99bd9bebec27bf0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TMCjFekU5r-valFD.png"/></div></div></figure><p id="7068" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据有3列<strong class="ih hj"><em class="lh">id</em></strong><em class="lh"/><strong class="ih hj"><em class="lh">标签</em></strong><strong class="ih hj"><em class="lh">tweet</em></strong>。<strong class="ih hj"> <em class="lh">标签</em> </strong>是二进制目标变量，<strong class="ih hj"> <em class="lh"> tweet </em> </strong>包含我们将要清理和预处理的tweet。</p><p id="fd5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看前5条记录后，我们可以想到的初始数据清理要求:</p><ul class=""><li id="fdb8" class="ko kp hi ih b ii ij im in iq lw iu lx iy ly jc lz kw kx ky bi translated">出于隐私考虑，Twitter账号已经被屏蔽为@user。因此，这些Twitter句柄几乎没有给出任何关于推文性质的信息。</li><li id="8344" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">我们也可以考虑去掉标点符号、数字甚至特殊字符，因为它们无助于区分不同类型的推文。</li><li id="2c4b" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">大部分较小的字并没有增加多少价值。比如' pdx '，' his '，' all '。因此，我们将尝试从我们的数据中删除它们。</li><li id="ed06" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">一旦我们执行了上面的三个步骤，我们就可以将每条tweet拆分成单独的单词或标记，这是任何NLP任务中必不可少的一步。</li><li id="ef6d" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">在第四条推文中，有一个词“爱”。我们也可能会有爱、可爱、可爱等术语。在剩下的数据中。这些术语经常在相同的上下文中使用。如果我们能把它们简化为词根，也就是“爱”，那么我们就能减少数据中独特词汇的总数，而不会丢失大量信息。</li></ul><h2 id="e9ce" class="lp jr hi bd js ma mb mc jw md me mf ka iq mg mh ke iu mi mj ki iy mk ml km mm bi translated">a)移除Twitter句柄(@user)</h2><p id="2eda" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">如上所述，tweets包含许多twitter句柄(@user)，这是一个Twitter用户在Twitter上承认的。我们将从数据中删除所有这些twitter句柄，因为它们没有传达太多信息。</p><p id="4da5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了方便起见，我们先把训练集和测试集结合起来。这省去了在测试和训练中两次执行相同步骤的麻烦。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="af3d" class="lp jr hi ll b fi lq lr l ls lt">combi = train.append(test, ignore_index=<strong class="ll hj">True</strong>)</span></pre><p id="6e51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面给出了一个用户定义的函数，用于从推文中删除不需要的文本模式。它有两个参数，一个是文本的原始字符串，另一个是我们想要从字符串中移除的文本模式。该函数返回相同的输入字符串，但没有给定的模式。我们将使用这个函数从我们数据中的所有tweets中删除模式' @user '。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="493f" class="lp jr hi ll b fi lq lr l ls lt"><strong class="ll hj">def</strong> <strong class="ll hj">remove_pattern</strong>(input_txt, pattern):     <br/>    r = re.findall(pattern, input_txt)     <br/>    <strong class="ll hj">for</strong> i <strong class="ll hj">in</strong> r:         <br/>        input_txt = re.sub(i, '', input_txt)              <br/>    <strong class="ll hj">return</strong> input_txt</span></pre><p id="32c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们创建一个新的列<strong class="ih hj"> tidy_tweet，</strong>它将包含经过清理和处理的tweet。注意，我们已经将“@[\w]*”作为模式传递给了<em class="lh"> remove_pattern </em>函数。它实际上是一个正则表达式，可以选择任何以“@”开头的单词。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="2eb9" class="lp jr hi ll b fi lq lr l ls lt"><em class="lh"># remove twitter handles (@user)</em> </span><span id="ce14" class="lp jr hi ll b fi lu lr l ls lt">combi['tidy_tweet'] = np.vectorize(remove_pattern)(combi['tweet'], "@[\w]*")</span></pre><h2 id="9d25" class="lp jr hi bd js ma mb mc jw md me mf ka iq mg mh ke iu mi mj ki iy mk ml km mm bi translated">b)删除标点、数字和特殊字符</h2><p id="8bb1" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">如前所述，标点符号、数字和特殊字符没有太大帮助。最好将它们从文本中删除，就像我们删除twitter句柄一样。这里我们将用空格替换除字符和标签之外的所有内容。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="c445" class="lp jr hi ll b fi lq lr l ls lt"><em class="lh"># remove special characters, numbers, punctuation</em></span><span id="5457" class="lp jr hi ll b fi lu lr l ls lt">combi['tidy_tweet'] = combi['tidy_tweet'].str.replace("[^a-zA-Z#]", " ")</span></pre><h2 id="dadb" class="lp jr hi bd js ma mb mc jw md me mf ka iq mg mh ke iu mi mj ki iy mk ml km mm bi translated">c)删除短词</h2><p id="0141" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">在选择要删除的单词的长度时，我们必须小心一点。所以，我决定删除所有长度不超过3的单词。例如，像“嗯”、“哦”这样的术语用处很小。最好摆脱他们。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="544d" class="lp jr hi ll b fi lq lr l ls lt">combi['tidy_tweet'] = combi['tidy_tweet'].apply(<strong class="ll hj">lambda</strong> x:' '.join([w                            <strong class="ll hj">for</strong> w <strong class="ll hj">in</strong> x.split() <strong class="ll hj">if</strong> len(w)&gt;3]))</span></pre><p id="b5c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们再看一看组合数据帧的前几行。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="03f7" class="lp jr hi ll b fi lq lr l ls lt">combi.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mn"><img src="../Images/e33f0eb805f2f95ce2d256ebbf3239de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Eu0ihlpRfBGvT1d2.png"/></div></div></figure><p id="fba4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以非常清楚地看到原始推文和干净推文(tidy_tweet)之间的差异。只有推文中的重要单词被保留，噪音(数字、标点符号和特殊字符)被删除。</p><h2 id="6044" class="lp jr hi bd js ma mb mc jw md me mf ka iq mg mh ke iu mi mj ki iy mk ml km mm bi translated">d)标记化</h2><p id="dece" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">现在，我们将对数据集中所有清理过的推文进行标记。记号是单独的术语或单词，记号化是将一串文本拆分成记号的过程。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="0063" class="lp jr hi ll b fi lq lr l ls lt">tokenized_tweet = combi['tidy_tweet'].apply(<strong class="ll hj">lambda</strong> x: x.split()) tokenized_tweet.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mo"><img src="../Images/ff87b88de75e179c963737072a837f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cm2vwwSodzVyQekd.png"/></div></div></figure><h2 id="3d13" class="lp jr hi bd js ma mb mc jw md me mf ka iq mg mh ke iu mi mj ki iy mk ml km mm bi translated">e)词干</h2><p id="8277" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">词干提取是一个基于规则的过程，从单词中去除后缀(“ing”、“ly”、“es”、“s”等)。举个例子，比如—“玩”“玩家”“玩过”“玩”“玩”是“玩”这个词的不同变体。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="b2e3" class="lp jr hi ll b fi lq lr l ls lt">from nltk.stem.porter import * <br/>stemmer = PorterStemmer() </span><span id="d13c" class="lp jr hi ll b fi lu lr l ls lt">tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]</span><span id="6d78" class="lp jr hi ll b fi lu lr l ls lt">tokenized_tweet.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mp"><img src="../Images/e80a361396be56be8b158e6cea5ead26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*96nHrg0eP3uvu6Px.png"/></div></div></figure><p id="8c73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们把这些代币缝合在一起。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="cc71" class="lp jr hi ll b fi lq lr l ls lt">for i in range(len(tokenized_tweet)): <br/>    tokenized_tweet[i] = ' '.join(tokenized_tweet[i]) </span><span id="50a5" class="lp jr hi ll b fi lu lr l ls lt">combi['tidy_tweet'] = tokenized_tweet</span></pre><h1 id="86d1" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">3.推文中的故事生成和可视化</h1><p id="5272" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">在这一节中，我们将探索清理后的tweets文本。探索和可视化数据，无论是文本还是其他数据，都是获得洞察力的重要步骤。不要只局限于本教程中讲述的这些方法，尽可能自由地探索数据。</p><p id="d21f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们开始探索之前，我们必须思考并提出与手头数据相关的问题。一些可能的问题如下:</p><ul class=""><li id="7e79" class="ko kp hi ih b ii ij im in iq lw iu lx iy ly jc lz kw kx ky bi translated">整个数据集中最常见的词是什么？</li><li id="46ce" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">数据集中最常见的负面和正面推文分别是什么？</li><li id="e3b7" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">一条推文中有多少标签？</li><li id="0a60" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">哪些趋势与我的数据集相关联？</li><li id="edee" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">哪些趋势与这两种情绪有关？它们与情感相容吗？</li></ul><h1 id="ad9b" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">a)了解推文中使用的常用词:WordCloud</h1><p id="7776" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">现在，我想看看给定的情感在训练数据集中分布得如何。完成这项任务的一种方法是通过绘制单词云来理解常用单词。</p><p id="e382" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词云是一种可视化，其中最频繁出现的单词以大尺寸出现，不太频繁出现的单词以小尺寸出现。</p><p id="c656" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们用词云图来可视化我们数据中的所有词。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="a08c" class="lp jr hi ll b fi lq lr l ls lt">all_words = ' '.join([text <strong class="ll hj">for</strong> text <strong class="ll hj">in</strong> combi['tidy_tweet']]) <br/>from wordcloud <strong class="ll hj">import</strong> WordCloud </span><span id="3a13" class="lp jr hi ll b fi lu lr l ls lt">wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words) </span><span id="b65e" class="lp jr hi ll b fi lu lr l ls lt">plt.figure(figsize=(10, 7)) <br/>plt.imshow(wordcloud, interpolation="bilinear") <br/>plt.axis('off') <br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/7373be25e679fa6a88d09f21ad88f1bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/0*4C3hynpycpYLks19.png"/></div></figure><p id="0edf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到大多数单词是积极的或中性的。其中<em class="lh">快乐</em>和<em class="lh">爱情</em>是最常见的。它没有给我们任何关于种族主义/性别歧视推文相关词汇的概念。因此，我们将在我们的训练数据中为两个类别(种族主义/性别歧视或非种族主义)绘制单独的词云。</p><h1 id="dac5" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">b)非种族主义/性别歧视推文中的词语</h1><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="5896" class="lp jr hi ll b fi lq lr l ls lt">normal_words =' '.join([text <strong class="ll hj">for</strong> text <strong class="ll hj">in</strong> combi['tidy_tweet'][combi['label'] == 0]]) </span><span id="7fb4" class="lp jr hi ll b fi lu lr l ls lt">wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(normal_words) </span><span id="062e" class="lp jr hi ll b fi lu lr l ls lt">plt.figure(figsize=(10, 7)) <br/>plt.imshow(wordcloud, interpolation="bilinear") <br/>plt.axis('off') <br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mr"><img src="../Images/ee1c625fc91c76deec3990e3a6ac0bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/0*A8q6WiExREfizuWb.png"/></div></figure><p id="7eb0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到大多数单词是积极的或中性的。随着<em class="lh">开心，微笑，</em>和<em class="lh">爱</em>是最频繁的。因此，大多数常用词与非种族主义/性别歧视推特的情绪是一致的。类似地，我们将为另一种情绪绘制单词cloud。期待看到负面的、种族主义的和性别歧视的词语。</p><h1 id="c7fd" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">c)种族主义/性别歧视的推文</h1><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="0eb2" class="lp jr hi ll b fi lq lr l ls lt">negative_words = ' '.join([text for text in combi['tidy_tweet'][combi['label'] == 1]]) </span><span id="bd5d" class="lp jr hi ll b fi lu lr l ls lt">wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(negative_words) </span><span id="3530" class="lp jr hi ll b fi lu lr l ls lt">plt.figure(figsize=(10, 7)) <br/>plt.imshow(wordcloud, interpolation="bilinear") <br/>plt.axis('off') <br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ms"><img src="../Images/ae83d3fe1feb2c03e7c9cabb1e75480d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/0*f5HEWqwJ4-gSL6zd.png"/></div></div></figure><p id="dc3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以清楚地看到，大多数单词都有负面含义。所以，看起来我们有一个很好的文本数据要处理。接下来，我们将讨论twitter数据中的标签/趋势。</p><h1 id="a0d0" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">d)理解标签对推文情绪的影响</h1><p id="f198" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">twitter中的标签是twitter上任何特定时间点上正在进行的趋势的同义词。我们应该尝试检查这些标签是否给我们的情感分析任务增加了任何价值，也就是说，它们有助于将推文区分为不同的情感。</p><p id="d527" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，下面是我们数据集的一条推文:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mt"><img src="../Images/5244fca2efe4e87bac2aadf8b47d8f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8ZEZSgakZ3JqGmf-.png"/></div></div></figure><p id="e892" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这条推文本质上似乎带有性别歧视，推文中的标签也传达了同样的感觉。</p><p id="4632" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将所有的趋势术语存储在两个单独的列表中——一个用于非种族主义/性别歧视的推文，另一个用于种族主义/性别歧视的推文。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="1876" class="lp jr hi ll b fi lq lr l ls lt"><em class="lh"># function to collect hashtags</em> <br/><strong class="ll hj">def</strong> <strong class="ll hj">hashtag_extract</strong>(x):     <br/>    hashtags = []     <br/>    <em class="lh"># Loop over the words in the tweet</em>     <br/>    <strong class="ll hj">for</strong> i <strong class="ll hj">in</strong> x:         <br/>        ht = re.findall(r"#(\w+)", i)         <br/>        hashtags.append(ht)     <br/>    <br/>    <strong class="ll hj">return</strong> hashtags</span><span id="62d3" class="lp jr hi ll b fi lu lr l ls lt"><em class="lh"># extracting hashtags from non racist/sexist tweets</em> <br/>HT_regular = hashtag_extract(combi['tidy_tweet'][combi['label'] == 0]) </span><span id="2c8b" class="lp jr hi ll b fi lu lr l ls lt"><em class="lh"># extracting hashtags from racist/sexist tweets</em> <br/>HT_negative = hashtag_extract(combi['tidy_tweet'][combi['label'] == 1]) </span><span id="6b80" class="lp jr hi ll b fi lu lr l ls lt"><em class="lh"># unnesting list</em> <br/>HT_regular = sum(HT_regular,[]) <br/>HT_negative = sum(HT_negative,[])</span></pre><p id="2ac1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经为这两种情绪准备了标签列表，我们可以绘制前n个标签了。所以，首先让我们检查一下非种族主义/性别歧视推文中的标签。</p><p id="ca5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">非种族主义/性别歧视的推文</strong></p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="f654" class="lp jr hi ll b fi lq lr l ls lt">a = nltk.FreqDist(HT_regular) <br/>d = pd.DataFrame({'Hashtag': list(a.keys()),                   'Count': list(a.values())}) </span><span id="eaf7" class="lp jr hi ll b fi lu lr l ls lt"><em class="lh"># selecting top 10 most frequent hashtags     </em> <br/>d = d.nlargest(columns="Count", n = 10)  </span><span id="f9a7" class="lp jr hi ll b fi lu lr l ls lt">plt.figure(figsize=(16,5)) <br/>ax = sns.barplot(data=d, x= "Hashtag", y = "Count") <br/>ax.set(ylabel = 'Count') <br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mu"><img src="../Images/e65b7d0bf53cbcae6f3c8445d10c4658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/0*RYeT2H6_L8sQ4ops.png"/></div></figure><p id="27fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所有这些标签都是积极的，有意义的。我预计在第二个列表的情节中会出现负项。让我们来看看种族主义/性别歧视推文中出现频率最高的标签。</p><p id="a337" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">种族主义/性别歧视推文</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="9948" class="lp jr hi ll b fi lq lr l ls lt">b = nltk.FreqDist(HT_negative) <br/>e = pd.DataFrame({'Hashtag': list(b.keys()), 'Count': list(b.values())}) </span><span id="00dc" class="lp jr hi ll b fi lu lr l ls lt"><em class="lh"># selecting top 10 most frequent hashtags</em> <br/>e = e.nlargest(columns="Count", n = 10) <em class="lh">  </em> </span><span id="269f" class="lp jr hi ll b fi lu lr l ls lt">plt.figure(figsize=(16,5)) <br/>ax = sns.barplot(data=e, x= "Hashtag", y = "Count") <br/>ax.set(ylabel = 'Count') <br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/38ea96d7b1dac83d0ca33d1cd6078eca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/0*MVxis11k8URsT2-T.png"/></div></figure><p id="4eee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不出所料，大多数术语都是负面的，也有一些中性术语。因此，在我们的数据中保留这些标签并不是一个坏主意，因为它们包含有用的信息。接下来，我们将尝试从标记化的推文中提取特征。</p><h1 id="72cb" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">4.从干净的推文中提取特征</h1><p id="472c" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">为了分析预处理过的数据，需要将其转换为特征。根据使用情况，可以使用各种技术来构造文本特征——单词包、TF-IDF和单词嵌入。在本文中，我们将只涉及词汇袋和TF-IDF。</p><h1 id="70d7" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">词袋特征</h1><p id="d2aa" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">词袋是一种将文本表示成数字特征的方法。考虑一个名为C of D documents {d1，d2…..dD}和从语料库c中提取出的N个唯一记号。这N个记号(单词)将形成一个列表，单词袋矩阵M的大小将由D×N给出。矩阵M中的每一行都包含文档D(i)中记号的频率。</p><p id="3836" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们用一个简单的例子来理解这一点。假设我们只有两个文档</p><p id="944c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">D1:他是一个懒惰的男孩。她也很懒。</p><p id="f517" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">D2:史密斯是一个懒惰的人。</p><p id="9a63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所创建的列表将由语料库c中的所有唯一标记组成</p><p id="b551" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">= ['他'，'她'，'懒惰'，'男孩'，'史密斯'，'人']</p><p id="4921" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，D=2，N=6</p><p id="5845" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大小为2 X 6的矩阵M将表示为</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mw"><img src="../Images/c8e1dd763dfa584cf749c93ecb5a4579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/0*WJNvbHFgn5uEBFAo.png"/></div></figure><p id="00b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，上述矩阵中的列可以用作构建分类模型的特征。使用sklearn的<em class="lh">计数矢量器</em>函数可以很容易地创建单词袋特征。我们将设置参数max_features = 1000，只选择语料库中按词频排序的前1000个词。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="7190" class="lp jr hi ll b fi lq lr l ls lt"><strong class="ll hj">from</strong> sklearn.feature_extraction.text <strong class="ll hj">import</strong> CountVectorizer </span><span id="71e1" class="lp jr hi ll b fi lu lr l ls lt">bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english') </span><span id="9b10" class="lp jr hi ll b fi lu lr l ls lt"><em class="lh"># bag-of-words feature <br/>matrix</em> bow = bow_vectorizer.fit_transform(combi['tidy_tweet'])</span></pre><h1 id="fc3b" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">TF-IDF功能</h1><p id="8778" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">这是另一种基于频率方法的方法，但它不同于词袋方法，因为它考虑的不仅仅是一个词在单个文档(或tweet)中的出现，而是整个语料库。</p><p id="e53c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TF-IDF的工作原理是通过给常用词分配较低的权重来惩罚它们，同时给那些在整个语料库中很少见但在少数文档中出现次数较多的词赋予重要性。</p><p id="3baa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来看看与TF-IDF相关的重要术语:</p><ul class=""><li id="de0c" class="ko kp hi ih b ii ij im in iq lw iu lx iy ly jc lz kw kx ky bi translated">TF =(术语t在文档中出现的次数)/(文档中的术语数)</li><li id="f04f" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">IDF = log(N/n)，其中，N是文档数，N是术语t出现的文档数。</li><li id="06f2" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">TF-IDF = TF*IDF</li></ul><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="170a" class="lp jr hi ll b fi lq lr l ls lt"><strong class="ll hj">from</strong> sklearn.feature_extraction.text <strong class="ll hj">import</strong> TfidfVectorizer </span><span id="fed0" class="lp jr hi ll b fi lu lr l ls lt">tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english') </span><span id="4d5e" class="lp jr hi ll b fi lu lr l ls lt"><em class="lh"># TF-IDF feature matrix</em> <br/>tfidf = tfidf_vectorizer.fit_transform(combi['tidy_tweet'])</span></pre><h1 id="c848" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">5.模型构建:情感分析</h1><p id="8eeb" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">现在，我们已经完成了以正确的形式获取数据所需的所有预建模阶段。现在，我们将使用两个特征集(词袋和TF-IDF)在数据集上构建预测模型。</p><p id="126f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用逻辑回归来建立模型。它通过将数据拟合到logit函数来预测事件发生的概率。</p><p id="824e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">逻辑回归中使用以下等式:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mx"><img src="../Images/3fe351d6f8c4c1217d7c7f0978bbeb2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/0*HK8X5l990WclqRJF.png"/></div></figure><p id="6fb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">阅读这篇<a class="ae jp" href="https://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/" rel="noopener ugc nofollow" target="_blank">文章</a>了解更多关于逻辑回归的知识。</p><p id="e4ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">注:如果你有兴趣尝试随机森林、支持向量机或XGBoost等其他机器学习算法，https://trainings.analyticsvidhya.com</em><a class="ae jp" href="https://trainings.analyticsvidhya.com." rel="noopener ugc nofollow" target="_blank"><em class="lh">将很快为你提供一门成熟的情感分析课程。</em> </a></p><h1 id="df7e" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">a)使用词袋特征建立模型</h1><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="0155" class="lp jr hi ll b fi lq lr l ls lt"><strong class="ll hj">from</strong> sklearn.linear_model <strong class="ll hj">import</strong> LogisticRegression <br/><strong class="ll hj">from</strong> sklearn.model_selection <strong class="ll hj">import</strong> train_test_split <br/><strong class="ll hj">from</strong> sklearn.metrics <strong class="ll hj">import</strong> f1_score </span><span id="cc09" class="lp jr hi ll b fi lu lr l ls lt">train_bow = bow[:31962,:] <br/>test_bow = bow[31962:,:] </span><span id="b6ae" class="lp jr hi ll b fi lu lr l ls lt"><em class="lh"># splitting data into training and validation set</em> <br/>xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, train['label'], random_state=42, test_size=0.3) </span><span id="ac04" class="lp jr hi ll b fi lu lr l ls lt">lreg = LogisticRegression() <br/>lreg.fit(xtrain_bow, ytrain) <em class="lh"># training the model</em> </span><span id="5fa5" class="lp jr hi ll b fi lu lr l ls lt">prediction = lreg.predict_proba(xvalid_bow) <em class="lh"># predicting on the validation set</em> </span><span id="b925" class="lp jr hi ll b fi lu lr l ls lt">prediction_int = prediction[:,1] &gt;= 0.3 <em class="lh"># if prediction is greater than or equal to 0.3 than 1 else 0</em> </span><span id="519e" class="lp jr hi ll b fi lu lr l ls lt">prediction_int = prediction_int.astype(np.int) f1_score(yvalid, prediction_int) <em class="lh"># calculating f1 score</em></span></pre><p id="be71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">输出:0.53 </strong></p><p id="e291" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在词袋特征上训练了逻辑回归模型，它给我们的验证集的F1值是0.53。现在我们将使用这个模型来预测测试数据。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="c955" class="lp jr hi ll b fi lq lr l ls lt">test_pred = lreg.predict_proba(test_bow) <br/>test_pred_int = test_pred[:,1] &gt;= 0.3 <br/>test_pred_int = test_pred_int.astype(np.int) <br/>test['label'] = test_pred_int <br/>submission = test[['id','label']] </span><span id="1bab" class="lp jr hi ll b fi lu lr l ls lt"><em class="lh"># writing data to a CSV file</em><br/>submission.to_csv('sub_lreg_bow.csv', index=<strong class="ll hj">False</strong>) </span></pre><p id="96d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大众排行榜F1分0.567。现在，我们将再次训练一个逻辑回归模型，但这次是基于TF-IDF特征。让我们看看它的表现如何。</p><h1 id="6878" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">b)使用TF-IDF功能构建模型</h1><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="81e8" class="lp jr hi ll b fi lq lr l ls lt">train_tfidf = tfidf[:31962,:] <br/>test_tfidf = tfidf[31962:,:] <br/>xtrain_tfidf = train_tfidf[ytrain.index] <br/>xvalid_tfidf = train_tfidf[yvalid.index] </span><span id="5908" class="lp jr hi ll b fi lu lr l ls lt">lreg.fit(xtrain_tfidf, ytrain) <br/>prediction = lreg.predict_proba(xvalid_tfidf) <br/>prediction_int = prediction[:,1] &gt;= 0.3 <br/>prediction_int = prediction_int.astype(np.int) </span><span id="129a" class="lp jr hi ll b fi lu lr l ls lt">f1_score(yvalid, prediction_int)</span></pre><p id="fd42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">输出:0.544 </strong></p><p id="fd19" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">验证分数为0.544，公共排行榜F1分数为0.564。因此，通过使用TF-IDF功能，验证分数有所提高，公共排行榜分数或多或少相同。</p><h1 id="95bc" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">6.下一步是什么？</h1><p id="c27c" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">如果你有兴趣学习更先进的情感分析技术，我们为你准备了一个关于同一问题的免费课程，不久将在<a class="ae jp" href="https://trainings.analyticsvidhya.com/" rel="noopener ugc nofollow" target="_blank">https://trainings.analyticsvidhya.com/</a>发布。该课程将有先进的技术，如用于特征提取的word2vec模型，更多的机器学习算法，模型微调等等。</p><p id="5929" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本课程中，您将学到以下内容:</p><ul class=""><li id="22a3" class="ko kp hi ih b ii ij im in iq lw iu lx iy ly jc lz kw kx ky bi translated">使用单词嵌入(word2vec和doc2vec)来创建更好的特性。</li><li id="a278" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">应用先进的机器学习算法，如SVM、随机森林和XGBoost。</li><li id="0c47" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">模型微调</li><li id="33cb" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lz kw kx ky bi translated">创建自定义指标</li></ul><h1 id="7eb2" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结束注释</h1><p id="a8b3" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">在本文中，我们学习了如何处理情感分析问题。我们从数据的预处理和探索开始。然后，我们使用词袋和TF-IDF从清洗后的文本中提取特征。最后，我们能够使用这两个特征集建立几个模型来对推文进行分类。</p><p id="1c3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你觉得这篇文章有用吗？你有什么有用的窍门吗？你用其他方法提取特征了吗？欢迎在下面的评论中或在<a class="ae jp" href="https://discuss.analyticsvidhya.com/" rel="noopener ugc nofollow" target="_blank">讨论门户</a>上讨论你的经历，我们将非常乐意讨论。</p></div><div class="ab cl my mz gp na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="hb hc hd he hf"><p id="d697" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">原载于2018年7月30日</em><a class="ae jp" href="https://www.analyticsvidhya.com/blog/2018/07/hands-on-sentiment-analysis-dataset-python/" rel="noopener ugc nofollow" target="_blank"><em class="lh">【www.analyticsvidhya.com】</em></a><em class="lh">。</em></p></div></div>    
</body>
</html>