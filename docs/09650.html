<html>
<head>
<title>ESRGAN: Enhanced Super-Resolution Generative Adversarial Network using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ESRGAN:使用 Keras 的增强超分辨率生成对抗网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/esrgan-enhanced-super-resolution-generative-adversarial-network-using-keras-a34134b72b77?source=collection_archive---------3-----------------------#2020-09-15">https://medium.com/analytics-vidhya/esrgan-enhanced-super-resolution-generative-adversarial-network-using-keras-a34134b72b77?source=collection_archive---------3-----------------------#2020-09-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d21d13c52c55e421c06f961dae462913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pCM9Qk5GsN9jO0xQ-OGApA.png"/></div></div></figure><p id="e884" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ESRGAN 是 SRGAN 的增强版本。ESRGAN 的作者试图通过修改模型架构和损失函数来增强 SRGAN。</p><h1 id="8eb3" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">开始</h1><p id="7be9" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在深入研究 ESRGAN 之前，我们先来了解一下 GAN。GANs 能够生成看起来很真实的假数据。GAN 的一些应用是为了提高图像质量。GAN 的高层架构包含两个主要网络，即<strong class="is hj">发生器网络</strong>和<strong class="is hj">鉴别器网络</strong>。发生器网络试图产生假数据，鉴别器网络试图区分真实数据和假数据，从而帮助发生器产生更真实的数据。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kr"><img src="../Images/56b7f5ae91a7b8913a879c58ae3138d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NqNDgEmAZHhFOyNLp4sJ3w.png"/></div></div></figure><h1 id="9fc3" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">埃斯甘</h1><p id="d9d0" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">ESRGAN 的主要架构与 SRGAN 相同，但有一些修改。ESRGAN 在残差密集块(RRDB)中有残差，残差密集块结合了多级残差网络和密集连接，无需批量归一化。</p><p id="61ae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">网络架构</strong></p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/e7ef545e77a312ef9c052caacb711477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mr7NA-EEcdYvdlQMKIpr3w.png"/></div></div></figure><p id="1335" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">残中残密块(RRDB) </strong></p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/d7ee83d60a256a3a2e6ac6c08d99c91e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mqxL9uUy2RHmXiYCsnPKjw.png"/></div></div></figure><pre class="ks kt ku kv fd kx ky kz la aw lb bi"><span id="3882" class="lc jp hi ky b fi ld le l lf lg">from keras.layers import Add, Concatenate, LeakyReLU, Conv2D, Lambda</span><span id="e386" class="lc jp hi ky b fi lh le l lf lg">def dense_block(inpt):<br/>    """<br/>    Dense block containes total 4 conv blocks with leakyRelu <br/>    activation, followed by post conv layer</span><span id="bc5c" class="lc jp hi ky b fi lh le l lf lg">    Params: tensorflow layer<br/>    Returns: tensorflow layer<br/>    """<br/>    b1 = Conv2D(64, kernel_size=3, strides=1, padding='same')(inpt)<br/>    b1 = LeakyReLU(0.2)(b1)<br/>    b1 = Concatenate()([inpt,b1])</span><span id="bb33" class="lc jp hi ky b fi lh le l lf lg">    b2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(b1)<br/>    b2 = LeakyReLU(0.2)(b2)<br/>    b2 = Concatenate()([inpt,b1,b2]) </span><span id="6905" class="lc jp hi ky b fi lh le l lf lg">    b3 = Conv2D(64, kernel_size=3, strides=1, padding='same')(b2)<br/>    b3 = LeakyReLU(0.2)(b3)<br/>    b3 = Concatenate()([inpt,b1,b2,b3])</span><span id="a9c8" class="lc jp hi ky b fi lh le l lf lg">    b4 = Conv2D(64, kernel_size=3, strides=1, padding='same')(b3)<br/>    b4 = LeakyReLU(0.2)(b4)<br/>    b4 = Concatenate()([inpt,b1,b2,b3,b4])</span><span id="c099" class="lc jp hi ky b fi lh le l lf lg">    b5 = Conv2D(64, kernel_size=3, strides=1, padding='same')(b4)<br/>    b5 = Lambda(lambda x:x*0.2)(b5)<br/>    b5 = Add()([b5, inpt])<br/>    <br/>    return b5</span><span id="556f" class="lc jp hi ky b fi lh le l lf lg">def RRDB(inpt):<br/>    """<br/>    RRDB(residual in residual dense block) contained three dense  <br/>    block, each block followed by beta contant multiplication(0.2) <br/>    and addition with dense block input layer.</span><span id="9c21" class="lc jp hi ky b fi lh le l lf lg">    Params: tensorflow layer<br/>    Returns: tensorflow layer<br/>    """<br/>    x = dense_block(inpt)<br/>    x = dense_block(x)<br/>    x = dense_block(x)<br/>    x = Lambda(lambda x:x*0.2)(x)<br/>    out = Add()([x,inpt])</span><span id="e63c" class="lc jp hi ky b fi lh le l lf lg">    return out</span></pre><p id="323d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">相对论鉴别器</strong></p><p id="2a47" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">除了使用标准鉴别器，ESRGAN 还使用相对论 GAN，它试图预测真实图像比假图像相对更真实的概率。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/e625b945099e261dd395b61f53b5f370.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jq3iXHKxy0boSM60DK_zAw.png"/></div></div></figure><pre class="ks kt ku kv fd kx ky kz la aw lb bi"><span id="fc98" class="lc jp hi ky b fi ld le l lf lg">from keras import backend as K</span><span id="ee62" class="lc jp hi ky b fi lh le l lf lg"><strong class="ky hj">def</strong> relativistic_loss(x):<br/>    real, fake = x<br/>    fake_logits = K.sigmoid(fake - K.mean(real))<br/>    real_logits = K.sigmoid(real - K.mean(fake))<br/>            <br/>    <strong class="ky hj">return</strong> [fake_logits, real_logits]</span></pre><p id="1aa9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">鉴别损失和对抗损失定义如下。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/e40dcb78f2f62a6217d3d32e50c71da6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cdyehCB3VHGcA8IoUdLm1g.png"/></div></div></figure><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/b004c6bff3feb7607b3b1425d26f0b24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XU9dPRswc2w8GWvELCAXvQ.png"/></div></div></figure><pre class="ks kt ku kv fd kx ky kz la aw lb bi"><span id="9522" class="lc jp hi ky b fi ld le l lf lg">dis_loss =<br/>K.mean(K.binary_crossentropy(K.zeros_like(fake_logits),fake_logits)+                    K.binary_crossentropy(K.ones_like(real_logits),real_logits))</span><span id="915e" class="lc jp hi ky b fi lh le l lf lg">gen_loss = K.mean(K.binary_crossentropy(K.zeros_like(real_logit),real_logit)+K.binary_crossentropy(K.ones_like(fake_logit),fake_logit))</span></pre><p id="d19d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">知觉丧失</strong></p><p id="b264" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过在激活函数之前约束特征来引入更有效的感知损失。</p><pre class="ks kt ku kv fd kx ky kz la aw lb bi"><span id="23b5" class="lc jp hi ky b fi ld le l lf lg">from keras.applications.vgg19 import preprocess_input</span><span id="ef5b" class="lc jp hi ky b fi lh le l lf lg">generated_feature = vgg(preprocess_vgg(img_hr))<br/>original_fearure = vgg(preprocess_vgg(gen_hr))</span><span id="a01f" class="lc jp hi ky b fi lh le l lf lg">percept_loss = tf.losses.mean_squared_error(generated_feature,original_fearure)</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/9f6d0b0e728a31fb505015eb3cbc43b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UW8ekH0MX73tg1wkjlHEyw.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">图像'狒狒'激活前后代表性特征图。随着网络的深入，激活后的大多数特征变得不活跃，而激活前的特征包含更多信息。</figcaption></figure><p id="ebd0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">培训详情</strong></p><p id="071a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ESRGAN 将低分辨率(LR)图像缩放为高分辨率图像，放大系数为 4。</p><p id="cf3e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于优化，Adam optimizer 使用默认值。</p></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><p id="5d74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">参考文献</strong></p><div class="lx ly ez fb lz ma"><a href="https://arxiv.org/abs/1809.00219" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab dw"><div class="mc ab md cl cj me"><h2 class="bd hj fi z dy mf ea eb mg ed ef hh bi translated">ESRGAN:增强的超分辨率生成对抗网络</h2><div class="mh l"><h3 class="bd b fi z dy mf ea eb mg ed ef dx translated">超分辨率生成对抗网络(SRGAN)是一个开创性的工作，能够生成现实的…</h3></div><div class="mi l"><p class="bd b fp z dy mf ea eb mg ed ef dx translated">arxiv.org</p></div></div></div></a></div><div class="lx ly ez fb lz ma"><a href="https://arxiv.org/abs/1609.04802" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab dw"><div class="mc ab md cl cj me"><h2 class="bd hj fi z dy mf ea eb mg ed ef hh bi translated">使用生成对抗网络的照片级单幅图像超分辨率</h2><div class="mh l"><h3 class="bd b fi z dy mf ea eb mg ed ef dx translated">尽管使用更快和更深的卷积在单幅图像超分辨率的准确性和速度方面取得了突破…</h3></div><div class="mi l"><p class="bd b fp z dy mf ea eb mg ed ef dx translated">arxiv.org</p></div></div></div></a></div></div></div>    
</body>
</html>