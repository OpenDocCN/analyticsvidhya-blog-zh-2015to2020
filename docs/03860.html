<html>
<head>
<title>Using scikit-learn’s Iterative Imputer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用scikit-learn的迭代估算器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/using-scikit-learns-iterative-imputer-694c3cca34de?source=collection_archive---------1-----------------------#2020-02-23">https://medium.com/analytics-vidhya/using-scikit-learns-iterative-imputer-694c3cca34de?source=collection_archive---------1-----------------------#2020-02-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="85f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我对数据模式非常着迷，任何分析的结果都取决于数据集的健壮性。但是，在当前时代，由于诸多原因——传感器故障、调查受访者偏差、缺失值、不正确的数据输入或记录等等，实现数据集中的稳健性几乎是不可能的。</p><p id="2bad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我最讨厌的事情之一是数据集中缺少值。通过对给定数据集的精心设计的假设，我相信通过某些算法，您可以智能地填充缺失的值。</p><p id="ef48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Rubin和Little所著的《缺失数据的统计分析》一书详细讨论了几种技术。我建议查看一下，但总的来说，它们涉及了处理缺失值的三个主要思想:</p><ol class=""><li id="c906" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">删除缺失值。</strong>只要与现有记录相比数量非常少，这是可以接受的。</li><li id="2043" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><strong class="ih hj">用从给定字段/列中的其他值导出的统计值填充所有缺失值。</strong>我在这里讨论了一些不足之处:<a class="ae jr" rel="noopener" href="/swlh/practical-technique-for-filling-missing-values-in-a-data-set-f8d541492b1f">https://medium . com/swlh/practical-technique-for-filling-missing-values-in-a-data-set-f8d 541492 b1f</a></li><li id="de70" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><strong class="ih hj">通过回归估算缺失值。</strong></li></ol><figure class="jt ju jv jw fd jx er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es js"><img src="../Images/8fba571826a7e0ba9a851efdc4e33bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bV4f6iYH3vVzYqnHYomyxg.jpeg"/></div></div></figure><p id="25b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当然，现代软件让它变得简单了。</p><p id="6bd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我了解了sklearn的迭代估算器，发现它令人印象深刻。你可以在这里了解sklearn的<em class="ke">实验性</em>迭代估算器的实现:<a class="ae jr" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . impute . iterative imputr . html</a></p><p id="e770" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个类实现了书中讨论的一些算法，非常有用。我想对它进行如下测试:</p><ol class=""><li id="d8b6" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">获取完整的数据集，假设可用数据是干净的。</li><li id="a064" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">随机选取一些列，随机去掉一些数据点。</li><li id="c6a5" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">使用迭代估算器上的污损数据集来填充缺失值。</li><li id="7916" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">将新数据集与原始数据集进行比较，以评估sklearn的迭代估算器的性能。</li></ol><p id="240c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用来自Kaggle 的<a class="ae jr" href="https://www.kaggle.com/wkirgsn/electric-motor-temperature" rel="noopener ugc nofollow" target="_blank">电机温度数据集来演示这一点。这是一个大约有一百万个数据点的数字数据集。我加载了数据集并删除了列“Profile ID ”,这是一个键。其余的列如下:</a></p><pre class="jt ju jv jw fd kf kg kh ki aw kj bi"><span id="f81d" class="kk kl hi kg b fi km kn l ko kp">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 998070 entries, 0 to 998069<br/>Data columns (total 12 columns):<br/>ambient           998070 non-null float64<br/>coolant           998070 non-null float64<br/>u_d               998070 non-null float64<br/>u_q               998070 non-null float64<br/>motor_speed       998070 non-null float64<br/>torque            998070 non-null float64<br/>i_d               998070 non-null float64<br/>i_q               998070 non-null float64<br/>pm                998070 non-null float64<br/>stator_yoke       998070 non-null float64<br/>stator_tooth      998070 non-null float64<br/>stator_winding    998070 non-null float64<br/>dtypes: float64(12)<br/>memory usage: 91.4 MB</span></pre><figure class="jt ju jv jw fd jx er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es kq"><img src="../Images/3faab473e91d583a7513ece8e9b52c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y62Ef9fUvJYkYQxYbgW-tQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">数据集中每一列的分布</figcaption></figure><p id="9a44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我编写了下面的函数，随机选择数据集中40%的列，并在每一列中抽取15%到50%的值。</p><pre class="jt ju jv jw fd kf kg kh ki aw kj bi"><span id="8d16" class="kk kl hi kg b fi km kn l ko kp">def defile_dataset(df, col_selection_rate=0.40):<br/>    cols = np.random.choice(df.columns, int(len(df.columns)*col_selection_rate))<br/>    df_cp = df.copy()<br/>    for col in cols:<br/>        data_drop_rate = np.random.choice(np.arange(0.15, 0.5, 0.02), 1)[0]<br/>        drop_ind = np.random.choice(np.arange(len(df_cp[col])), size=int(len(df_cp[col])*data_drop_rate), replace=False)<br/>        df_cp[col].iloc[drop_ind] = np.nan<br/>    return df_cp, cols</span></pre><p id="4aaa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在数据帧上调用上述函数后的结果:</p><pre class="jt ju jv jw fd kf kg kh ki aw kj bi"><span id="6be8" class="kk kl hi kg b fi km kn l ko kp">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 998070 entries, 0 to 998069<br/>Data columns (total 12 columns):<br/><strong class="kg hj">ambient           509016 non-null float64</strong><br/>coolant           998070 non-null float64<br/>u_d               998070 non-null float64<br/>u_q               998070 non-null float64<br/>motor_speed       998070 non-null float64<br/><strong class="kg hj">torque            768514 non-null float64</strong><br/>i_d               998070 non-null float64<br/>i_q               998070 non-null float64<br/><strong class="kg hj">pm                628785 non-null float64</strong><br/>stator_yoke       998070 non-null float64<br/>stator_tooth      998070 non-null float64<br/><strong class="kg hj">stator_winding    628785 non-null float64</strong><br/>dtypes: float64(12)<br/>memory usage: 91.4 MB</span></pre><p id="4d0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在使用下面的类之前，你必须确保启用sklearn的迭代估算器:</p><pre class="jt ju jv jw fd kf kg kh ki aw kj bi"><span id="4850" class="kk kl hi kg b fi km kn l ko kp">from sklearn.experimental import enable_iterative_imputer  <br/>from sklearn.impute import IterativeImputer</span></pre><p id="72c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我设置好了，我就使用下面的函数，大部分默认参数用于迭代估算，但迭代次数(n_iter)为100，以确保我给的足够多，使函数收敛。</p><pre class="jt ju jv jw fd kf kg kh ki aw kj bi"><span id="026f" class="kk kl hi kg b fi km kn l ko kp">def impute_once(df_orig):<br/>    df_miss, cols = defile_dataset(df_orig)<br/>    df_orig_slice = df_orig[cols]<br/>    imputer = IterativeImputer(max_iter=100)<br/>    df_stg = df_miss.copy()<br/>    imp_arr = imputer.fit_transform(df_stg)<br/>    return df_orig_slice, df_miss[cols], pd.DataFrame(imp_arr[:,[df_orig.columns.get_loc(i) for i in cols]], columns=cols), imputer.n_iter_</span></pre><p id="e2ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我调用函数并检查一些信息:</p><pre class="jt ju jv jw fd kf kg kh ki aw kj bi"><span id="fa14" class="kk kl hi kg b fi km kn l ko kp">df_og, df_def, df_imp, n_iter = impute_once(df)<br/>print(df_og.columns)<br/>print(df_imp.columns)<br/>print(n_iter)</span><span id="59a0" class="kk kl hi kg b fi kv kn l ko kp">Index(['i_q', 'stator_winding', 'u_q', 'stator_tooth'], dtype='object')<br/>Index(['i_q', 'stator_winding', 'u_q', 'stator_tooth'], dtype='object')<br/>23</span></pre><p id="1834" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看起来它在23次迭代中收敛了。</p><p id="aa56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了比较迭代估算与用一个统计值(如平均值)填充所有缺失值的最基本技术(sklearn的简单估算或pandas的fillna ),我在数据集副本上使用简单估算填充缺失值，并评估两种情况下的均方误差。</p><p id="7ee2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简单估算器:</p><pre class="jt ju jv jw fd kf kg kh ki aw kj bi"><span id="845e" class="kk kl hi kg b fi km kn l ko kp">for i in range(len(df_og.columns)):<br/>    print("Simple Imputer: MSE for {} is {:.4f}.".format(df_og.columns[i], mean_squared_error(df_og[df_og.columns[i]], df_simimp[df_simimp.columns[i]])))</span><span id="00ab" class="kk kl hi kg b fi kv kn l ko kp"><strong class="kg hj">Simple Imputer: MSE for i_q is 0.3498.<br/>Simple Imputer: MSE for stator_winding is 0.1499.<br/>Simple Imputer: MSE for u_q is 0.3909.<br/>Simple Imputer: MSE for stator_tooth is 0.3498.</strong></span></pre><p id="ecd3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">迭代估算器:</p><pre class="jt ju jv jw fd kf kg kh ki aw kj bi"><span id="99bb" class="kk kl hi kg b fi km kn l ko kp">for i in range(len(df_og.columns)):<br/>    print("Iterative Imputer: MSE for {} is {:.4f}.".format(df_og.columns[i], mean_squared_error(df_og[df_og.columns[i]], df_imp[df_imp.columns[i]])))</span><span id="ced3" class="kk kl hi kg b fi kv kn l ko kp"><strong class="kg hj">Iterative Imputer: MSE for i_q is 0.0016.<br/>Iterative Imputer: MSE for stator_winding is 0.0023.<br/>Iterative Imputer: MSE for u_q is 0.0724.<br/>Iterative Imputer: MSE for stator_tooth is 0.0009.</strong></span></pre><p id="00c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结论:你可以看到，当使用迭代估算时，MSE要低得多。接下来我将尝试并分享的是多次运行上述方法，以查看MSE的分布，尝试调整迭代估算类的其他参数，尤其是更改估计值。默认值是BayesianRidge()。</p><p id="ae0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我鼓励你尝试一下，并在评论中分享你的想法！</p></div></div>    
</body>
</html>