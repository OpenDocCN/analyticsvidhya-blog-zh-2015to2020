# 基于 knn 和 Logistic 回归的糖尿病分类

> 原文：<https://medium.com/analytics-vidhya/diabetes-classification-with-knn-and-logistic-regression-2edd3760a8c7?source=collection_archive---------22----------------------->

**简介**
机器学习在医疗保健领域有许多新颖而伟大的应用，考虑到适量的数据在大小方面被使用并且与问题有有意义的关系，它可以使患者诊断更加容易和准确。

**问题**

**方法**

**K-Nearest neighborhood**
K-Nearest 是一种基于距离的算法，这意味着它在学习数据集时会考虑距离，K-Nearest 会尝试对数据点进行分类， 假设我们在图上有有限数量的数据点，从这些有限数量的数据点中，我们有五个数据点彼此靠近，这意味着它们有很多共同点，所以假设可以安全地将它们视为一个类，这就是 K-nearest 试图通过将彼此相似的点聚类为一个类来将点分类到一个类的目的。

你有没有想过 K 是什么，K 是一个变量，它会随着问题的不同而变化，这似乎并不明显，但是 K 最常见的值在 5 到 10 之间， K 代表的是我们在形成类或对数据点进行分类时考虑的数据点的数量，例如，如果您选择 K 为 2 或 3，那么您尝试分类的点将会寻找最近的 2 或 3 个点，以及它们属于哪个类，它将被分类到距离最短的类。

![](img/64ca9605d8ba62303b9c374804fc1e90.png)

KNN 分类

逻辑回归
回归听起来是一个完全不同的问题，似乎我们期望的是连续的而不是离散的输出，但这不是真的逻辑回归是一种分类，但我们为什么要使用回归这个词呢？
因为逻辑回归是算法所基于的函数的另一个学名，称为 Sigmoid 函数，所以这只是一个命名惯例，所以为了很好地掌握逻辑回归，应该首先理解 Sigmoid 函数。 Sigmoid 函数是一个输出范围在 0 和 1 之间的函数，因此它广泛用于概率预测模型，例如在逻辑回归中，当我们尝试对一个类别进行分类时，例如一个人是否患有糖尿病，逻辑回归根据 Sigmoid 算法输出病例(输入数据)是否属于某个类别的概率，例如，如果给定输入的输出小于 0.5，则他不是糖尿病患者，否则他就是糖尿病患者。

**实施**
首先，我们必须对数据集进行一些特征工程，因为我们知道 KNN 是一种基于距离的算法，它使用像曼哈顿或欧几里德这样的距离函数来计算两点之间的距离。我们必须将属性值保持在可控的小范围内，以避免计算能力和复杂性的浪费。因此，我们将对数据集进行归一化，因为我们在本质上具有不同范围的特征。之后，我们搜索缺失值 0 或 NaN，有时空值表示为“？”还要注意的是，一些值可以为 0，而不会有任何问题，例如兄弟姐妹的数量，但如果 0 与我们的血压情况不相似，在某些情况下，我们必须进行所谓的插补，使用不同的策略(如缺失值列的平均值或模式)用相关值替换空数据值，或者使用回归来预测缺失值，然后我们使用 Sklearn 在 knn 和逻辑分类器上训练数据，然后使用进化矩阵展示我们的指标，就这样

完整的笔记本可以在这里找到:-
[https://www . ka ggle . com/mohanedmashaly/KNN-classifier-vs-logistic-regression](https://www.kaggle.com/mohanedmashaly/knn-classifier-vs-logistic-regression)