<html>
<head>
<title>A Complete Guide for Visualising and Understanding Convolutional Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可视化和理解卷积网络的完整指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-complete-guide-for-visualising-and-understanding-convolutional-networks-dc26f71c979f?source=collection_archive---------2-----------------------#2020-11-07">https://medium.com/analytics-vidhya/a-complete-guide-for-visualising-and-understanding-convolutional-networks-dc26f71c979f?source=collection_archive---------2-----------------------#2020-11-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1ab3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">免责声明:如果您只对DeConvNet的代码感兴趣，它会在文章的最后以ConvNet为例给出。</em></p><p id="3cda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最近，由LeCun等人于1989年提出的卷积网络(ConvNets)在挑战视觉分类任务方面取得了最先进的成果。</p><p id="4950" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">是什么引起了人们对ConvNet模型的兴趣？</strong></p><ol class=""><li id="64b6" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">训练集的可用性</li><li id="2ec7" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">计算能力显著提高</li><li id="c06c" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">新型模型正则化技术</li></ol><p id="6384" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">从业者之间有一个普遍的类比，即洞察这些模型的内部操作和行为，或者它们如何实现如此好的性能的原因是一项繁琐的任务(如果不是不可能的话)。</em></p><p id="9911" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">但是这个类比正确吗？</strong></p><p id="f7c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">没有对CNN(或任何其他模型)的架构和功能背后的原因的清楚理解，这些模型被简化为试错法。从模型可解释性的角度来看，这是非常不令人满意的。</p><p id="535c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">是否有可能解读一个ConvNet模型？</strong></p><p id="5c4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">的确是！</p><p id="a23b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">泽勒等人。艾尔。</strong> <a class="ae js" href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" rel="noopener ugc nofollow" target="_blank"> </a>提出了<strong class="ih hj"> DeConvNet </strong>(多层去卷积网络)。提议的<strong class="ih hj">去配置网络</strong>的主要特征如下:</p><ol class=""><li id="28e1" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">想象激发个体特征的输入刺激。</li><li id="d9de" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">将特征激活投影回输入像素。</li><li id="231e" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">分类器输出的灵敏度分析。</li><li id="de6d" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">观察训练过程中特征的演变。</li></ol></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="d318" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">DeConvNet是如何工作的？</strong></p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ka"><img src="../Images/61b7abcc8f0c98d298e5d8f3a9ac8ad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*lb-xXoKS9yFfa_UpD3Tc7w.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">图(1):由泽勒等人提出的DeConvNet架构。艾尔。在可视化和理解卷积网络，计算机视觉ECCV 2014</figcaption></figure><p id="8ca2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">DeConvNet连接到ConvNet的每一层。图(1)显示了一个解卷积网络的架构。</p><p id="4e55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">图片在此</em></p><p id="23c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从图(1)中可以看出，执行了以下步骤</p><ol class=""><li id="0390" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated"><strong class="ih hj"> Unpooling </strong>:要理解这一点，我们需要先理解池。池化是一种降低输入图像维数的技术。最常用的池技术是最大池。<br/> <strong class="ih hj"> Max-Pooling </strong>:给定过滤器中的所有元素，我们返回最大值。现在，凭着一个非常基本的直觉，很明显池化是不可逆的，我们将永远无法检索相同的元素！然而，我们可以通过记录每个汇集区域内的最大值的位置来获得近似的倒数。DeConvNet根据找到的最大值将来自上一层的重构放置到适当的位置。</li><li id="f5da" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated"><strong class="ih hj">校正</strong> : ConvNet使用ReLU非线性校正特征图。为了在每一层获得有效的特征重构，重构的信号因此也通过ReLU非线性。</li><li id="ea60" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated"><strong class="ih hj">过滤</strong> : ConvNet使用学习过的过滤器将特征图卷积到一个较低的维度。去卷积网络使用该学习滤波器转置到来自上述步骤的校正表示，以重构去卷积层输出。</li></ol></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="b519" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">实现</strong></p><p id="1b91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面使用Keras和Tensorflow实现的示例代码给出了一个DeConvNet的上述功能的小例子。</p><p id="444a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尝试使用不同的权重和偏差，检查卷积-2D转置的功能。</p><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="km kn l"/></div></figure><div class="kb kc kd ke fd ab cb"><figure class="ko kf kp kq kr ks kt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/1517879b42fb1172813b6c0c00b6d286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*0RfTNmldmnqSaLCfLcQe9w.png"/></div></figure><figure class="ko kf kp kq kr ks kt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/446238f5165111b5490d75df8381024c.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*20MkTqGwARxh1vYVxGSWkA.jpeg"/></div><figcaption class="ki kj et er es kk kl bd b be z dx ky di kz la translated">图(2):去卷积图像(左)和实际图像(右)</figcaption></figure></div><p id="bfd3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看以下VGG网的代码，用于可视化VGG Net卷积块的特征映射。</p><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="km kn l"/></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es lb"><img src="../Images/29af5d34d9d40adf3731c07594a6d9a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*R-qaeL34Dio1kUZRzfZBSw.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">图3:由VGGNet卷积块重建的特征图</figcaption></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="b565" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">可选阅读</strong></p><p id="2898" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">进一步以“袋鼠”为例，我们可以使用DeConvNet或Conv2DTranspose重建图像。下面的代码是一个典型的例子。</p><p id="b1da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Protip:尝试使用不同的数据集、卷积网络、内核和过滤器进行试验。</p><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="km kn l"/></div></figure><p id="0d73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">干杯！</p><p id="24dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快乐学习！</p><h1 id="d190" class="lc ld hi bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">参考文献</strong></h1><p id="b3ca" class="pw-post-body-paragraph if ig hi ih b ii ma ik il im mb io ip iq mc is it iu md iw ix iy me ja jb jc hb bi translated">[1]<a class="ae js" href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" rel="noopener ugc nofollow" target="_blank">https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf</a>:泽勒等人。艾尔。，计算机视觉ECCV 2014</p><p id="82e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2]<a class="ae js" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/keras/layers/conv 2d transpose</a></p></div></div>    
</body>
</html>