<html>
<head>
<title>Fundamental concepts for Model Selection and Model Evaluation — Part2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型选择和模型评估的基本概念——第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fundamental-concepts-for-model-selection-and-model-evaluation-part2-e72b384f8ab6?source=collection_archive---------28-----------------------#2020-05-04">https://medium.com/analytics-vidhya/fundamental-concepts-for-model-selection-and-model-evaluation-part2-e72b384f8ab6?source=collection_archive---------28-----------------------#2020-05-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="eb05" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">解决机器学习中心问题的核心概念背后的直觉。</h2></div><p id="5ea3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你还没有看完第一部分，我建议你先看一遍。在<a class="ae jt" rel="noopener" href="/analytics-vidhya/fundamental-concepts-for-model-selection-and-model-evaluation-part1-b91f78efaea0">第一部分</a>中，我们谈到了选择更好的模型类别所需的基本概念。在本文中，我们将首先讨论超参数，然后将重点放在模型评估的概念上。</p><p id="3b37" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我把思维导图放在这里是为了直观的总结，但是先浏览一下这篇文章，稍后再回到这里。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ju"><img src="../Images/04eeb6c54bad86f70891e22a0fefd5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sPNWjvRIrt6Lh0kg"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">模型选择和模型评估概念—思维导图</figcaption></figure><h2 id="5a3f" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">我们将在本文中讨论以下主题。</h2><ul class=""><li id="0482" class="lf lg hi iz b ja lh jd li jg lj jk lk jo ll js lm ln lo lp bi translated">超参数的意义和使用。</li><li id="6592" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">超参数与模型参数有何不同。</li><li id="2681" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">超参数调谐。</li><li id="1e5f" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">交叉验证策略(K倍CV)。</li><li id="7cf2" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">GridSearchCV。</li></ul></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><h1 id="ff14" class="mc kl hi bd km md me mf kq mg mh mi ku io mj ip kx ir mk is la iu ml iv ld mm bi translated">超参数调谐</h1><p id="d3e6" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg mn ji jj jk mo jm jn jo mp jq jr js hb bi translated">正如我们在上一篇文章中讨论的，可以通过正则化和超参数调整来减少模型的过度拟合。我们讨论了正则化，在本文中，我们将看到超参数调整。</p><p id="cbb3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">超参数调整是寻找超参数的最佳值的过程，用于控制模型复杂性，使其不会过度拟合。我们将看到如何实现这一点，但在前进之前，让我们先明确一些基本概念。</p><h2 id="f3fe" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">参数和超参数</h2><p id="ac1b" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg mn ji jj jk mo jm jn jo mp jq jr js hb bi translated">参数是模型进行预测时需要学习的值。例如，在回归的情况下，我们需要学习变量的系数，这些值被称为参数。</p><p id="ffb3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是超参数是不同的，请注意，它不会成为最终模型的一部分，而是学习算法用来建立模型的东西。</p><p id="beac" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们来看看不同类别的模型的超参数究竟是什么。</p><ul class=""><li id="6940" class="lf lg hi iz b ja jb jd je jg mq jk mr jo ms js lm ln lo lp bi translated">对于回归模型，回想一下，它们的复杂性随着变量数量的增加而增加。这里变量的数量是我们的超参数，我们需要找到它的最佳值。</li><li id="aa5d" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">对于像决策树这样的树模型，树的深度会影响模型的复杂性。所以这里树的深度是需要优化的超参数。</li><li id="8d68" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">对于神经网络，影响复杂性的是连接的数量，因此使用丢弃，并且需要丢弃的神经元的百分比可以被认为是超参数。</li></ul><p id="8d7d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是超参数的一些例子，请明确，超参数不是可以预先知道的或者它的值是固定的，它必须通过尝试不同的值来找出，看看哪个最适合。</p><p id="f125" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们强调，我们需要找到一个最佳的超参数值，让我们看看如何优化它。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><h1 id="2f3d" class="mc kl hi bd km md me mf kq mg mh mi ku io mj ip kx ir mk is la iu ml iv ld mm bi translated">交叉验证策略</h1><p id="09c0" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg mn ji jj jk mo jm jn jo mp jq jr js hb bi translated">维基百科定义</p><blockquote class="mt mu mv"><p id="9335" class="ix iy mw iz b ja jb ij jc jd je im jf mx jh ji jj my jl jm jn mz jp jq jr js hb bi translated"><strong class="iz hj">交叉验证</strong>，有时也称为<strong class="iz hj">旋转估计</strong>或<strong class="iz hj">样本外测试</strong>，是各种类似的<a class="ae jt" href="https://en.wikipedia.org/wiki/Model_validation" rel="noopener ugc nofollow" target="_blank">模型验证</a>技术中的任何一种，用于评估<a class="ae jt" href="https://en.wikipedia.org/wiki/Statistics" rel="noopener ugc nofollow" target="_blank">统计</a>分析的结果如何推广到一个独立的数据集。</p></blockquote><p id="89d4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们通过一个例子来理解它，假设我们正在解决一个线性回归问题，我们希望根据我们拥有的50个独立变量来预测“y”。这里，在我们的模型中使用的变量的数量是一个超参数，我们的目标是找出它的最佳值。</p><p id="4833" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于模型构建，我们需要弄清楚两件事</p><ul class=""><li id="3174" class="lf lg hi iz b ja jb jd je jg mq jk mr jo ms js lm ln lo lp bi translated">要使用的变量数量。</li><li id="4953" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">使用哪些变量？<br/> -为此，我们可以使用<a class="ae jt" href="https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/" rel="noopener ugc nofollow" target="_blank"> RFE </a>，我们不会在本文中涉及RFE，但是，你可以通过“进一步阅读”部分的链接。</li></ul><p id="9b2f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一种方法是使用坚持策略将数据分成训练集和测试集。并尝试建立不同超参数值的模型。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es na"><img src="../Images/31f6fe0cfecc061dbc0965078ed620a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KJCi9BkCwvAuM5Wb9SMSuA.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">坚持策略的说明</figcaption></figure><p id="35ac" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是这种方法存在问题。</p><p id="4d48" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">问题1 </strong> —我们将打破窥视测试集的基本规则，在相同的测试集上针对不同的超参数值评估我们的模型。</p><p id="f6fb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">问题2 </strong> —结果将取决于特定的测试和训练分割，如果我们的数据分布不均匀，即我们的测试分割可能具有与训练集不同的分布，该怎么办。</p><p id="616f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">问题3 </strong> —我们正在手动执行该过程，需要花费大量精力来测试我们的不同模型的大范围超参数。</p><p id="30fe" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们看看如何解决这些问题。</p><h2 id="07c2" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">解决问题1 <strong class="ak">(窥视测试集)</strong> &amp;问题2(依赖于特定的数据分割)</h2><p id="162a" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg mn ji jj jk mo jm jn jo mp jq jr js hb bi translated">窥视测试数据的问题可以通过将数据集分成训练、<strong class="iz hj"> <em class="mw">验证、</em> </strong>和测试集来避免。因此，我们可以在验证集而不是测试集上迭代地验证我们的模型。但是请注意，通过采用这种方法，我们将最终得到更少的数据用于训练，并且我们很少有丰富的数据可用。因此，我们有另一个问题要解决(记住，只有当我们有更少的数据，否则你可以使用验证集)。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es nb"><img src="../Images/d66487e9dbb059a049a9e828f61b1490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZtRm3ia7BjZtErwBiwAxQ.png"/></div></div></figure><p id="3431" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就是可以使用交叉验证策略来避免更多地消耗训练数据的地方。我们将看看交叉验证中最常见的技术，即<strong class="iz hj"> <em class="mw"> K倍交叉验证</em> </strong>。参考“进一步阅读”部分的链接，找到其他的验证策略。</p><p id="d4ff" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在<em class="mw"> K-Fold交叉验证</em> <strong class="iz hj"> <em class="mw">，</em> </strong>中，我们将数据集只分为训练集和测试集，训练集又进一步分为K个Fold，这里我们取K为4。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es nc"><img src="../Images/73be50bca380106a0dc833b5deb7e737.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fcslPKZlIUO1KkFKl5dEUg.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">K-Fold交叉验证的说明，请注意，上面显示的测试数据实际上是从训练数据中采样的验证集。</figcaption></figure><p id="b377" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们可以使用不同的测试集迭代地创建多个模型，而不是使用相同的测试集创建单个模型。k倍交叉验证运行的结果通常用模型得分的平均值进行总结，如上图所示。</p><blockquote class="mt mu mv"><p id="7ceb" class="ix iy mw iz b ja jb ij jc jd je im jf mx jh ji jj my jl jm jn mz jp jq jr js hb bi translated"><em class="hi">窥视是使用测试集性能来选择假设并对其进行评估的结果。避免这种情况的方法是把测试集真正拿出来——把它锁起来，直到你完全完成学习，只是希望获得对最终假设的独立评估。(然后，如果你不喜欢这个结果……如果你想回去找到一个更好的假设，你必须获得并锁定一个全新的测试集。)</em></p></blockquote><p id="cdb3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">— Jason Brownlee在他的文章中提到了上述段落，作者:Stuart Russell和Peter Norvig，709页，<a class="ae jt" href="http://www.amazon.com/dp/0136042597?tag=inspiredalgor-20" rel="noopener ugc nofollow" target="_blank">人工智能:一种现代方法</a>，2009年(第三版)</p><p id="1fe2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用K-Fold交叉验证，我们解决了这两个问题。</p><ul class=""><li id="3c40" class="lf lg hi iz b ja jb jd je jg mq jk mr jo ms js lm ln lo lp bi translated">问题1——我们通过在训练数据集的多个样本上迭代地训练和测试我们的模型，避免了窥视测试集。</li><li id="03e1" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">问题2 —我们的模型在不同的数据分割上进行训练和测试，这避免了模型结果对特定数据分割的依赖性。</li></ul><h2 id="1d4d" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">解决问题3(手动调整超参数)</h2><p id="5ea1" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg mn ji jj jk mo jm jn jo mp jq jr js hb bi translated">我们知道如何避免窥视测试集并消除对特定数据分割的依赖，现在我们需要一些方法来自动化超参数调整过程，显然，当我们的变量在100–150范围内时，就不可能手动执行这个过程。</p><p id="e8f3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就是我们可以使用<strong class="iz hj"> GridSearch </strong>技术的地方，它将自动为您的模型找到最佳的超参数值。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es nd"><img src="../Images/ac153fbc79e3190a2749157529a347e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HnPTPWiR_YvY_weaWFK8zg.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">GridSearchCV的插图</figcaption></figure><p id="ac5d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">GridSearchCV是一个用来指代GridSearch和交叉验证技术的术语，现在我们需要为GridSearchCV提供超参数的一系列值。</p><p id="e651" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上图显示了使用GridSearchCV在1–50的范围内进行超参数调整的过程。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="ccf2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">乡亲们，现在我将推荐你们浏览一次视觉总结(思维导图)。</p><p id="ebc8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我希望你获得了基本概念背后的直觉，并理解我们如何在解决机器学习问题的同时解决共同的挑战。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><h1 id="d3e9" class="mc kl hi bd km md me mf kq mg mh mi ku io mj ip kx ir mk is la iu ml iv ld mm bi translated">摘要</h1><ul class=""><li id="4dda" class="lf lg hi iz b ja lh jd li jg lj jk lk jo ll js lm ln lo lp bi translated">我们看到了超参数的含义以及它与模型参数的不同之处</li><li id="55d1" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">超参数不是我们最终模型的一部分，但它们将被学习算法用来正则化我们的模型。</li><li id="4b15" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">超参数需要调整，我们看到了如何在避免一些基本问题的同时做到这一点。</li><li id="6417" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">交叉验证技术可以用来解决窥视测试集的问题。</li><li id="adec" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">GridSearch技术可以与交叉验证技术一起使用，以自动化在不同的超参数值上验证我们的模型的繁琐过程。</li></ul></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><h1 id="371e" class="mc kl hi bd km md me mf kq mg mh mi ku io mj ip kx ir mk is la iu ml iv ld mm bi translated">进一步阅读</h1><ul class=""><li id="dd9f" class="lf lg hi iz b ja lh jd li jg lj jk lk jo ll js lm ln lo lp bi translated">RFE—<a class="ae jt" href="https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/feature-selection-in-python-with-scikit-learn/</a></li><li id="34d6" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">不同的交叉验证技术—<a class="ae jt" href="https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f" rel="noopener" target="_blank">https://towards data science . com/Cross-Validation-in-machine-learning-72924 a 69872 f</a></li><li id="1c47" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">更多深度讲解—<a class="ae jt" href="https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html" rel="noopener ugc nofollow" target="_blank">https://sebastianraschka . com/blog/2016/model-evaluation-selection-part 1 . html</a></li><li id="96f3" class="lf lg hi iz b ja lq jd lr jg ls jk lt jo lu js lm ln lo lp bi translated">有关验证集的详细信息—<a class="ae jt" href="https://machinelearningmastery.com/difference-test-validation-datasets/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/difference-test-validation-datasets/</a></li></ul></div></div>    
</body>
</html>