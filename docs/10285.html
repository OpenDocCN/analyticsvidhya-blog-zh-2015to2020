<html>
<head>
<title>Predicting Ethereum (ETH) Prices With RNN-LSTM in Keras (TensorFlow)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测以太坊(ETH)价格与 RNN LSTM 在 Keras (TensorFlow)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/predicting-ethereum-eth-prices-with-rnn-lstm-in-keras-tensorflow-9ae2709de270?source=collection_archive---------4-----------------------#2020-10-12">https://medium.com/analytics-vidhya/predicting-ethereum-eth-prices-with-rnn-lstm-in-keras-tensorflow-9ae2709de270?source=collection_archive---------4-----------------------#2020-10-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0d0735ba6f2a556c4fd2f6a9260f708d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tiI2D8YEKVIpGObseuZQtg.png"/></div></div></figure><p id="d460" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本主题的想法是提出一种使用探索性分析和递归神经网络(RNN)预测以太坊加密货币未来价格的简单方法，主要是 LSTMs。</p><p id="109c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我不会详细讨论加密货币和 LSTMs 的操作，关于这个主题已经有很多文章了。</p><p id="ef48" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您对这些主题仍然不清楚，我邀请您看看这些文章:</p><p id="0b30" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以太坊到底是如何运作的？<a class="ae jo" rel="noopener" href="/@preethikasireddy/how-does-ethereum-work-anyway-22d1df506369">https://medium . com/@ preethikasireddy/how-does-ether eum-work-anyway-22d 1 df 506369</a></p><p id="e83e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">了解 LSTM 及其图</strong><br/><a class="ae jo" rel="noopener" href="/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714">https://medium . com/ml review/Understanding-lstm-and-its-diagrams-37 e2f 46 f 1714</a></p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><p id="fbd0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我使用了提供 REST API 的币安市场来检索 ETH/USDT 的历史数据。</p><p id="bc6e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以参考此处的文档:</p><p id="73a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://github.com/binance/binance-spot-api-docs/blob/master/rest-api.md" rel="noopener ugc nofollow" target="_blank">https://github . com/币安/币安-spot-API-docs/blob/master/rest-API . MD</a></p><p id="d587" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">或者使用 python 包来简化这个过程，如下所示:</p><p id="3222" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://python-binance.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://python-binance.readthedocs.io/en/latest/</a></p><p id="f1eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是熊猫的数据集:</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jw"><img src="../Images/8d7660cf1fd11ba16086f6918d006f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UkMBBRAu2gIgnyZ7ZGCnUQ.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">埃胡斯德·达弗雷姆</figcaption></figure><p id="28fe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在继续之前，执行一些数据结构化操作很重要:</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="a698" class="kk kl hi kg b fi km kn l ko kp">df_ethusd.dtypes</span></pre><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/8aeb1b228fcde236b0608eb694c1204c.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*ZwLNH36SZijCRSMGqf0uQw.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">ethusd 数据类型函数</figcaption></figure><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="41e9" class="kk kl hi kg b fi km kn l ko kp"># convert date format to datetime<br/>df_ethusd['Date'] = pd.to_datetime(df_ethusd['Date'], format='%Y-%m-%d %H-%p').dt.strftime('%Y-%m-%d %H:%M')<br/>df_ethusd['Date'] = pd.to_datetime(df_ethusd['Date'])</span><span id="34a0" class="kk kl hi kg b fi kr kn l ko kp"># sort values by date<br/>df_ethusd = df_ethusd.sort_values(by='Date')</span><span id="0edf" class="kk kl hi kg b fi kr kn l ko kp">df_ethusd.rename(columns = {'Date':'datetime'}, inplace = True)</span><span id="a1d3" class="kk kl hi kg b fi kr kn l ko kp">del df_ethusd['Symbol']<br/>del df_ethusd['Unix Timestamp']</span></pre><p id="525b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对空值的简单检查:</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="8a2e" class="kk kl hi kg b fi km kn l ko kp">df_ethusd.isnull().sum()</span></pre><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/8ace3488be04007c4d6576996b715acc.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*E7skhEmVHwyyAJPpIiSG_A.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">简单检查空值</figcaption></figure><p id="5484" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在开始相关性分析之前，对定量变量使用数值很重要:</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="6e9f" class="kk kl hi kg b fi km kn l ko kp"># Convert all quantitative variables to numeric format<br/>df_ethusd = pd.concat([<br/>    df_ethusd.iloc[:,0],<br/>    df_ethusd.iloc[:, 1:len(df_ethusd.columns)].astype('float')<br/>], axis = 1)</span><span id="95a6" class="kk kl hi kg b fi kr kn l ko kp">df_ethusd.dtypes</span></pre><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es kt"><img src="../Images/e1c69dab45c5a69fea396efb252f4d79.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*wyfHk7Bax-g_JQS59r8Dnw.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">ethusd 数据类型函数</figcaption></figure></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="bad7" class="ku kl hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">相关</h1><p id="31b3" class="pw-post-body-paragraph iq ir hi is b it lr iv iw ix ls iz ja jb lt jd je jf lu jh ji jj lv jl jm jn hb bi translated">数据准备完成后，下一步是分析不同的相关性，以确定最感兴趣的变量。</p><p id="9bf9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个想法是预测“接近”价格的未来值。因此，了解其他变量是否能解释这个变量的可变性是很重要的。</p><p id="1d16" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里，我们将首先绘制<a class="ae jo" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" rel="noopener ugc nofollow" target="_blank"> Pearson </a>相关性热图，并查看自变量与输出变量 Close 的相关性。我们将只选择与输出变量的相关性<strong class="is hj">大于 0.5 </strong>(取绝对值)的特征。</p><p id="9392" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">相关系数的值在-1 到 1 之间<br/> —越接近 0 的值意味着相关性越弱(恰好 0 意味着无相关性)<br/> —越接近 1 的值意味着正相关性越强<br/> —越接近-1 的值意味着负相关性越强</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/901354ece257c1760869a799557e1656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wQk0TsLwn4LqhoHATsRWSw.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">df_ethusd 上的热图</figcaption></figure><p id="aefb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，我恢复不同的相关性对，以检查它们的 p 值，并只保留阈值低于 0.05%的显著相关性。</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/88d79b27cc594b7ecad0baaace061e61.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*nLHLDr1mSmuzp_qzzjqc7g.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">df_ethusd 相关性</figcaption></figure><p id="c784" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如我们所见，只有特征<strong class="is hj">高、低</strong>和<strong class="is hj">打开</strong>与输出变量关闭高度相关</p><p id="b2d7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了确保第一个假设，使用<a class="ae jo" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html" rel="noopener ugc nofollow" target="_blank">递归特征消除</a> (RFE)方法进行第二次分析。RFE 方法的工作原理是递归地删除属性，并在那些保留的属性上建立一个模型。它使用准确性度量来根据特征的重要性对其进行排序。</p><p id="55d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果如下:</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/4fc8910fe610ba4c7226383307e06d36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*qpB9Wet6sbi9pUKoI7JTTA.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">递归特征消除</figcaption></figure><p id="4db0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">RFE 方法也推荐与皮尔逊系数的第一种方法相同的变量。</p><p id="1b39" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，我们将保持<strong class="is hj">打开，高</strong>和<strong class="is hj">低</strong>变量来预测<strong class="is hj">关闭</strong>价格。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="e6b5" class="ku kl hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">数据预处理</h1><p id="3391" class="pw-post-body-paragraph iq ir hi is b it lr iv iw ix ls iz ja jb lt jd je jf lu jh ji jj lv jl jm jn hb bi translated">我们现在进入预处理阶段。选择不同的变量和定义时间步长是很重要的。</p><p id="37f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">指定的时间步数定义了用于预测下一个时间步(<em class="lz"> y </em>)的输入变量(<em class="lz"> X </em>)的数量。因此，对于制图表达中使用的每个时间步长，都必须从数据集的开头移除那么多行。</p><p id="0715" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的例子中，我将时间步长设置为 24。这意味着模型每次都将使用过去的 24 小时来预测未来的一个小时。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="89c6" class="kk kl hi kg b fi km kn l ko kp"># Select features (columns) to be involved intro training and predictions<br/>cols = list(['Close','High', 'Low', 'Open'])</span><span id="693b" class="kk kl hi kg b fi kr kn l ko kp"># Target feature<br/>y_target = 'Close'</span><span id="b018" class="kk kl hi kg b fi kr kn l ko kp"># Number of time steps use to predict the future <br/>n_time_steps = 24</span><span id="cba7" class="kk kl hi kg b fi kr kn l ko kp"># Extract dates (will be used in visualization)<br/>dataset_datelist = list(dataset['datetime'])</span><span id="c645" class="kk kl hi kg b fi kr kn l ko kp"># Parse training set timestamp for better visualization<br/>dataset = pd.DataFrame(dataset, columns=cols)<br/>dataset.index = dataset_datelist<br/>dataset.index = pd.to_datetime(dataset.index)</span><span id="ade8" class="kk kl hi kg b fi kr kn l ko kp">print('Training set shape == {}'.format(dataset.shape))<br/>print('All timestamps == {}'.format(len(dataset_datelist)))<br/>print('Featured selected: {}'.format(cols))<br/>print('Featured target selected: {}'.format(y_target))<br/>print('Number of time steps selected: {}'.format(n_time_steps))</span></pre><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/ebeb07bc4eb2647612965017da889348.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*QEMc79dYknQH15D09-buQA.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">功能选择</figcaption></figure><p id="8b5f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是此时的数据集:</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/d4ea7c3a1162afe6d3535710f3f0081f.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*RAXEHGB-RF-lsEEMd9I-Ew.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">选择要素后的数据集</figcaption></figure></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="4b67" class="ku kl hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">评估所选要素的正态分布</h1><p id="30ea" class="pw-post-body-paragraph iq ir hi is b it lr iv iw ix ls iz ja jb lt jd je jf lu jh ji jj lv jl jm jn hb bi translated">下一步是将数据标准化，使 LSTM 模型不受尺度变化的影响。输入变量尺度的差异可能会增加建模问题的难度。</p><p id="df60" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有几种方法，ScikitLearn 提供了两种主要方法:</p><p id="694a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">标准缩放器</strong>:去除平均值，并将数据缩放至单位方差。<br/> <strong class="is hj"> MinMaxScaler </strong>:重新缩放数据集，使所有函数值都在范围[0，1]内。</p><p id="9a5a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了使用最佳方法，重要的是事先知道我们的变量是否遵循正态分布。</p><p id="56e1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，我们必须观察变量的分布，并将它们与正态密度进行比较。</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/406b3c111868d193e4cf4ba8658e3b36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z77stycEWsW563u5JXDXLQ.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">所选特征的正态分布</figcaption></figure><p id="8cde" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以得出结论，这些变量似乎不遵循正态分布。</p><p id="c608" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了确保这一点，Kolmogorov Smirnov 测试应用于每个变量，Kolmogorov-Smirnov 方法也是另一种拟合优度方法，它比较实验<a class="ae jo" href="https://www.sciencedirect.com/topics/engineering/cumulative-distribution" rel="noopener ugc nofollow" target="_blank">累积分布</a>函数和理论累积分布函数之间的最大距离。</p><p id="36ed" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果如下:</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/038511b83765ca206434ed23a92c8751.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*EDrBfuNCw5VQ_awbAI2yUQ.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">科尔莫戈罗夫斯米尔诺夫试验</figcaption></figure><p id="a99f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">变量的 p 值不大于 0.05%的显著阈值，这导致我们拒绝正态假设。这可能与时间序列中的大量异常值有关。在这种情况下，StandardScaler 标准化似乎非常合适。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="03a5" class="ku kl hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">列车测试分离</h1><p id="9164" class="pw-post-body-paragraph iq ir hi is b it lr iv iw ix ls iz ja jb lt jd je jf lu jh ji jj lv jl jm jn hb bi translated">现在是时候将我们的数据集分成两部分了，一部分用于训练模型，另一部分用于数据验证。</p><p id="d70b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我使用了标准的<strong class="is hj"> 80/20 </strong>分割，这为我们带来了 22，999 个用于训练的样本和 5749 个用于验证数据的样本，这对于我们的情况来说已经足够了。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="0f90" class="kk kl hi kg b fi km kn l ko kp">import math</span><span id="c095" class="kk kl hi kg b fi kr kn l ko kp">train_split = 0.8</span><span id="5e80" class="kk kl hi kg b fi kr kn l ko kp">Data = dataset.values #converting numpy array<br/>train_data_size = math.ceil(len(Data)*train_split)<br/>test_data_size = len(dataset) - train_data_size</span><span id="bb1b" class="kk kl hi kg b fi kr kn l ko kp">print('train size == {}.'.format(train_data_size))<br/>print('test size == {}.'.format(test_data_size))</span><span id="c493" class="kk kl hi kg b fi kr kn l ko kp"># split the actual dataframe in train/test set<br/>train, test = dataset[0:train_data_size], dataset[train_data_size:len(dataset)]<br/>print('train shape == {}.'.format(train.shape))<br/>print('test shape == {}.'.format(test.shape))</span></pre><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es me"><img src="../Images/256027085efd971dddd767ceda22cad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*DMAUT8YvgrvGq8VfTf5JXg.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">训练/测试规模</figcaption></figure><p id="de7f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练和试验数据的可视化；</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/6ab4d8ea7e6bf6bcc2d3aa52dc722d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*96zXjkKuGtOMl5g2ugXxkg.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">列车测试分离</figcaption></figure></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="bde6" class="ku kl hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">特征缩放归一化</h1><p id="82b1" class="pw-post-body-paragraph iq ir hi is b it lr iv iw ix ls iz ja jb lt jd je jf lu jh ji jj lv jl jm jn hb bi translated">然后，我们可以用<strong class="is hj"> StandardScaler </strong>方法标准化这两个数据集。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="a3fb" class="kk kl hi kg b fi km kn l ko kp">from sklearn.preprocessing import StandardScaler</span><span id="3d4e" class="kk kl hi kg b fi kr kn l ko kp">scaler = StandardScaler()<br/>training_scaled_data = scaler.fit_transform(train)<br/>print('training scaled data shape == {}.'.format(training_scaled_data.shape))</span><span id="0bf4" class="kk kl hi kg b fi kr kn l ko kp">look_back_train_data = train.tail(n_time_steps) #look back n_time_steps<br/>testing_data = look_back_train_data.append(test)</span><span id="b4ef" class="kk kl hi kg b fi kr kn l ko kp">scaler_test = StandardScaler()<br/>testing_scaled_data = scaler_test.fit_transform(testing_data)</span><span id="2373" class="kk kl hi kg b fi kr kn l ko kp">scaler_test_predict = StandardScaler()<br/>scaler_test_predict.fit_transform(testing_data.iloc[:, 0:1])</span><span id="c7ae" class="kk kl hi kg b fi kr kn l ko kp">print('testing scaled data shape == {}.'.format(testing_scaled_data.shape))</span></pre><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/a692cdc6c3f9050ec999cc1f6e4b7dc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*PxULGG-nk7JUFUHklEqO0g.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">训练/测试缩放形状</figcaption></figure><p id="f29f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在数据已经标准化，将数据结构转换为 LSTM 模型所期望的输入数据变得非常重要。</p><p id="225a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你必须给出一个三维数组作为你的 LSTM 网络的输入。其中第一维代表<strong class="is hj">批量</strong>，第二维代表<strong class="is hj">时间步长</strong>，第三维代表一个输入序列中<strong class="is hj">单元</strong>的数量。例如，输入形状看起来像<em class="lz"> (batch_size，time_steps，units)。</em></p><p id="bb20" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有许多方法可以转换数据，这里有一种方法可以实现 3 个方面的目标:</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="270b" class="kk kl hi kg b fi km kn l ko kp">def split_sequences_multivariate_output(sequences, n_steps):<br/><br/>  X, y = list(), list()<br/>  for i in range(len(sequences)):<br/>      # find the end of this pattern<br/>      end_ix = i + n_steps<br/>      # check if we are beyond the dataset<br/>      if end_ix &gt; len(sequences)-1:<br/>          break<br/>      # gather input and output parts of the pattern<br/>      seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]<br/>      X.append(seq_x)<br/>      y.append(seq_y)<br/>  return array(X), array(y)</span><span id="2c69" class="kk kl hi kg b fi kr kn l ko kp"># convert into input/output<br/>X_train, y_train = split_sequences_multivariate_output(training_scaled_data, n_time_steps)</span><span id="3ad8" class="kk kl hi kg b fi kr kn l ko kp">X_test, y_test = split_sequences_multivariate_output(testing_scaled_data, n_time_steps)</span><span id="4ba4" class="kk kl hi kg b fi kr kn l ko kp">print('X_train shape == {}.'.format(X_train.shape))<br/>print('y_train shape == {}.'.format(y_train.shape))</span><span id="83b8" class="kk kl hi kg b fi kr kn l ko kp">print('X_test shape == {}.'.format(X_test.shape))<br/>print('y_test shape == {}.'.format(y_test.shape))</span></pre><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/0cb413ab21a38c066509ef7d1491a81b.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*qz_NnrGAs1sXIiNZbgxc6w.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">输入形状</figcaption></figure><p id="cbc2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">开始训练前(再次)检查形状:</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/07ee6011a1bade197b3dde8cca31aa82.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*Hfd39J0Exjf68CqkSjFrbA.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">输入形状</figcaption></figure><p id="72b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们在<strong class="is hj"> X_train </strong>和<strong class="is hj"> X_test </strong>数据集上有<strong class="is hj"> 24 个时间步长</strong>，使用了<strong class="is hj"> 4 个特征</strong>，并且在<strong class="is hj"> y_train </strong>和<strong class="is hj"> y_test </strong>上也使用了 4 个特征。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="2d73" class="ku kl hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">建立 LSTM 网络</h1><p id="0403" class="pw-post-body-paragraph iq ir hi is b it lr iv iw ix ls iz ja jb lt jd je jf lu jh ji jj lv jl jm jn hb bi translated">现在是准备 LSTM 模型的时候了，我定义了一个函数，它将训练和测试数据以及一些超参数作为输入。</p><p id="8f73" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后模型由<strong class="is hj">两个 LSTM 隐藏层</strong>组成，每个隐藏层有<strong class="is hj"> 50 个单元</strong>。</p><p id="efea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">在每个 LSTM 隐藏层之间也使用 25%的下降层</strong>。</p><p id="4dc3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输入丢失意味着对于给定的概率，每个 LSTM 块的输入连接上的数据将被排除在节点激活和权重更新之外。</p><p id="deb9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在 Keras 中，这是在创建 LSTM 图层时用<em class="lz"> dropout </em>参数指定的。压差值是介于 0(无压差)和 1(无连接)之间的百分比。</p><p id="58f7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在第一个 LSTM 隐藏层上指定输入形状很重要，这样它就可以使用与训练数据相同的形状。</p><p id="9643" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">然后在密集输出层上使用线性激活</strong>。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="6bc6" class="kk kl hi kg b fi km kn l ko kp">def train_keras_model(X_train, y_train, X_test, y_test, epochs, batch_size, shuffle=False):</span><span id="d797" class="kk kl hi kg b fi kr kn l ko kp">  from tensorflow.keras.models import Sequential<br/>  from tensorflow.keras.layers import LSTM, Dropout, Dense</span><span id="2751" class="kk kl hi kg b fi kr kn l ko kp"># Initializing the Neural Network based on LSTM<br/>  model = Sequential()  <br/>  model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))<br/>  model.add(Dropout(0.25))<br/>  model.add(LSTM(units=50))<br/>  model.add(Dropout(0.25))<br/>  model.add(Dense(units=X_train.shape[2], activation='linear'))<br/>  model.compile(optimizer='adam',loss='mean_squared_error')<br/>  <br/>  history = model.fit(X_train, y_train, shuffle=shuffle, validation_data=(X_test, y_test), epochs=epochs, verbose=2, batch_size=batch_size).history<br/>  <br/>  return history, model</span></pre><p id="b904" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练可以开始了，我用了<strong class="is hj"> 30 个纪元</strong>，将<strong class="is hj">批量设置为 256 </strong>。这些值似乎可以使模型快速收敛。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="1965" class="kk kl hi kg b fi km kn l ko kp"># Fit model<br/>history, model = train_keras_model(X_train, y_train, X_test, y_test, epochs=30, batch_size=256, shuffle=False)</span></pre><p id="d681" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是训练和验证损失曲线:</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/7be3abd32a7045bc2339d7aea73e6087.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gs6PnVr64Pm_oSY46N6bGQ.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">模型损失</figcaption></figure><p id="f728" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在训练和验证数据上，该模型似乎很快收敛到 0。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="c1f9" class="ku kl hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">使用测试集的性能可视化</h1><p id="1645" class="pw-post-body-paragraph iq ir hi is b it lr iv iw ix ls iz ja jb lt jd je jf lu jh ji jj lv jl jm jn hb bi translated">用不同的指标而不仅仅是损失曲线来检查模型的性能变得很重要。</p><p id="79a6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最有趣的指标是:<strong class="is hj"> MAE、MAPE、MSE、RMSE、R 平方和调整后的 R 平方。</strong></p><p id="4557" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它们必须根据验证数据的预测值进行计算:</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="6d16" class="kk kl hi kg b fi km kn l ko kp"># Perform predictions<br/>predictions_test = model.predict(X_test)</span><span id="ed5d" class="kk kl hi kg b fi kr kn l ko kp"># Inverse the predictions to original measurements<br/>y_pred_test = scaler_test_predict.inverse_transform(np.array(predictions_test)[:,0])</span><span id="dc9b" class="kk kl hi kg b fi kr kn l ko kp">y_actual_test = scaler_test_predict.inverse_transform(np.array(y_test)[:,0])</span></pre><p id="da1f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后可以对<strong class="is hj"> y_pred_test </strong>和<strong class="is hj"> y_actual_test </strong>应用不同的指标。</p><p id="99e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果如下:</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/882b17e22ea4ba1f693a9f43daf8b15d.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*9Fkt_nqskUczHX4rye2HLQ.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">韵律学</figcaption></figure><p id="b957" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们得到的<strong class="is hj"> MAPE 值为 3.43% </strong>，这意味着实际值与模型预测值之间的平均误差非常低。</p><p id="98fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，<strong class="is hj">调整后的 R2 和 R2 系数</strong>非常<strong class="is hj">接近 1 </strong>，这意味着预测值与真实值高度相关，因此解释了真实值上的许多差异。</p><p id="0fb9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以用图表来直观显示模型的性能，为此，我定义了两个时间序列，一个包含验证数据，另一个包含预测数据:</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="0f5b" class="kk kl hi kg b fi km kn l ko kp">y_test_serie = pd.DataFrame(y_actual_test, columns=[y_target]).set_index(testing_data[n_time_steps:].index)</span><span id="adb8" class="kk kl hi kg b fi kr kn l ko kp">y_pred_serie = pd.DataFrame(y_pred_test, columns=[y_target]).set_index(testing_data[n_time_steps:].index)</span></pre><p id="b79e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后只查看两个系列:</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="e868" class="kk kl hi kg b fi km kn l ko kp">plt.plot(y_test_serie.index, y_test_serie[y_target], color='green', linewidth=2, label='Actual')<br/>plt.plot(y_pred_serie.index, y_pred_serie[y_target], color='red', linewidth=2, label='Testing predictions')</span><span id="22a6" class="kk kl hi kg b fi kr kn l ko kp">plt.grid(which='major', color='#cccccc', alpha=0.5)</span><span id="6aed" class="kk kl hi kg b fi kr kn l ko kp">plt.legend(shadow=True)<br/>plt.title('Testing predictions Vs Acutal')<br/>plt.xlabel('Timeline', fontsize=10)<br/>plt.ylabel('Value', fontsize=10)<br/>plt.xticks(rotation=45, fontsize=8)<br/>plt.show()</span></pre><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1fa6623cb44ff61af6330d04d573bca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-d2VSOHj8B9ihJmGdFgixA.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">测试预测与实际</figcaption></figure><p id="6b43" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以关注上个月:</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/2c084ab9f409c5a949a2a96725a79fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*21Rj-vWv4LL-85KOna6hhw.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">测试上个月的预测与实际</figcaption></figure><p id="17b7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">尽管仍然需要对数据处理和模型参数进行改进以提高预测的质量。模型做出的预测遵循测试数据的主要趋势。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="e6c2" class="ku kl hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">预测未来</h1><p id="7f4e" class="pw-post-body-paragraph iq ir hi is b it lr iv iw ix ls iz ja jb lt jd je jf lu jh ji jj lv jl jm jn hb bi translated">然后就可以用这个模型来预测未来，未来几个小时以太坊的价格。</p><p id="03ce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有几种方法可以预测未来。直接预测或递归预测。</p><p id="8fdd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我用递归预测来预测未来 12 小时。该模型每次预测 1 个时间步长的 4 个特征。</p><p id="c66b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以我使用了预测变量，并在最后一个窗口中，通过每次移动一步，将它们整合为输入变量。</p><p id="c062" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种方法对于小型预测很有意思，因为它每次都会增加预测误差，这可能会对长期预测的质量产生相当大的影响。</p><p id="9c89" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是接下来 12 小时的结果:</p><figure class="jx jy jz ka fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0d0735ba6f2a556c4fd2f6a9260f708d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tiI2D8YEKVIpGObseuZQtg.png"/></div></div></figure><h1 id="2495" class="ku kl hi bd kv kw mm ky kz la mn lc ld le mo lg lh li mp lk ll lm mq lo lp lq bi translated">摘要</h1><p id="6c0e" class="pw-post-body-paragraph iq ir hi is b it lr iv iw ix ls iz ja jb lt jd je jf lu jh ji jj lv jl jm jn hb bi translated">以太坊时间序列与开盘、盘高和盘低变量一起用于测量收盘变量上的网络性能。</p><p id="7b37" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将获得的估计结果与图表进行比较。MSE、MAPE 和 R 值被作为预测成功的标准。</p><p id="a63b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，通过更多的数据点和修改 LSTM 网络的超参数，有可能获得更成功的结果。</p><p id="eb72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">就是这样！希望这篇文章对使用 LSTM 预测时间序列有一个很好的理解。</p><p id="4377" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="lz">参考文献:</em></p><p id="b379" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://machinelearningmastery.com/use-dropout-lstm-networks-time-series-forecasting/" rel="noopener ugc nofollow" target="_blank">https://machineellingmastery . com/use-dropout-lstm-networks-time-series-forecasting/</a><br/><a class="ae jo" href="https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/" rel="noopener ugc nofollow" target="_blank">https://machineellingmastery . com/multi variable-time-series-forecasting-lst ms-keras/</a><br/><a class="ae jo" href="https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/" rel="noopener ugc nofollow" target="_blank">https://machineellingmastery . com/use-time steps-lstm-networks-time-series-forecasting/</a><br/><a class="ae jo" href="https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b" rel="noopener" target="_blank">https://towards datascience . com/feature-selection-with-pandas-E3</a></p><p id="0442" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lz">跟我来</em> </strong> <a class="ae jo" href="https://twitter.com/AdrienBorderon" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> <em class="lz">这里</em> </strong> </a> <strong class="is hj"> <em class="lz">。</em> </strong></p></div></div>    
</body>
</html>