<html>
<head>
<title>Natural Language Processing: From Basics to using RNN and LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理:从基础到使用RNN和LSTM</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/natural-language-processing-from-basics-to-using-rnn-and-lstm-ef6779e4ae66?source=collection_archive---------0-----------------------#2019-05-17">https://medium.com/analytics-vidhya/natural-language-processing-from-basics-to-using-rnn-and-lstm-ef6779e4ae66?source=collection_archive---------0-----------------------#2019-05-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="dab0" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">对自然语言处理领域中流行的所有概念的详细介绍</h2></div><p id="dc47" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">机器学习领域最引人入胜的进步之一，是开发了教会机器如何理解人类交流的能力。机器学习的这个分支被称为自然语言处理。</p><p id="34e9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇文章试图解释自然语言处理的基础知识，以及随着深度学习和神经网络的发展，自然语言处理如何取得快速进展。</p><p id="4fc9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我们深入探讨这个问题之前，有必要了解一些基础知识</p><h2 id="9626" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">什么是语言？</h2><p id="d899" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">一种语言，基本上是一个固定的词汇，由一群人共享，用来表达和交流他们的思想。</p><p id="f042" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这些词汇是作为人类成长过程的一部分教给他们的，并且大部分都是固定的，每年都有少量增加。</p><p id="7653" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">精心制作的资源，如字典，被保留下来，这样如果一个人遇到一个新单词，他或她可以参考字典来查找它的意思。一旦这个人接触到这个单词，它就会被添加到他或她的词汇中，并可以用于进一步的交流。</p><h2 id="a3e2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">计算机是如何理解语言的？</h2><p id="0f6d" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">计算机是根据数学规则工作的机器。它缺乏人类可以轻松完成的复杂解释和理解，但可以在几秒钟内完成复杂的计算。</p><blockquote class="kt ku kv"><p id="aff4" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">为了使计算机能够处理任何概念，有必要用数学模型的形式来表达所述概念。</p></blockquote><p id="5568" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个约束极大地限制了计算机可以处理的自然语言的范围和领域。迄今为止，机器在执行分类和翻译任务方面非常成功。</p><p id="1555" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">分类基本上是将一段文本归类到一个类别中，而翻译是将这段文本转换成任何其他语言。</p><h2 id="d0e1" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated"><strong class="ak">什么是自然语言处理？</strong></h2><blockquote class="kt ku kv"><p id="b2f3" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">自然语言处理，简称NLP，广义上定义为软件对自然语言的自动操作，如语音和文本。</p></blockquote><p id="eeba" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">自然语言处理的研究已经有50多年的历史了，并且随着计算机的兴起而从语言学领域发展出来。[1]</p><p id="7374" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有关NLP基础的详细教程，请访问</p><div class="la lb ez fb lc ld"><a href="https://www.mygreatlearning.com/blog/natural-language-processing-tutorial/" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hj fi z dy li ea eb lj ed ef hh bi translated">自然语言处理教程:什么是自然语言处理&amp;它是如何工作的</h2><div class="lk l"><h3 class="bd b fi z dy li ea eb lj ed ef dx translated">人工智能。自然语言处理是如何产生的？自然语言处理是如何工作的…</h3></div><div class="ll l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">www.mygreatlearning.com</p></div></div><div class="lm l"><div class="ln l lo lp lq lm lr ls ld"/></div></div></a></div><p id="0da4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">基本转变</strong></p><p id="1619" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如前所述，要让机器理解自然语言(人类使用的语言)，它需要转换成某种可以建模的数学框架。下面提到的，是一些最常用的技术，帮助我们实现这一点。</p><p id="77fd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">标记化、词干化和词汇化</strong></p><p id="fdf4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">标记化</strong>是将文本分解成单词的过程。标记化可以发生在任何字符上，但是最常见的标记化方式是在空格字符上进行。</p><p id="8e54" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">词干提取</strong>是一种简单的方法，通过截断词尾来获得基本单词，通常包括去除派生词缀。一个<strong class="iz hj">派生词缀</strong>是一个<strong class="iz hj">词缀</strong>，通过它一个词从另一个词形成(派生)。派生单词通常与原始单词属于不同的词类。最常用的算法是波特算法。</p><p id="9dd2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">词汇化</strong>对单词进行词汇和词形分析，通常仅用于去除屈折词尾。一个<strong class="iz hj">屈折词尾</strong>是加在一个单词末尾改变其意思的一组字母。一些<strong class="iz hj">屈折词尾</strong>有:-s. bat。蝙蝠。</p><blockquote class="kt ku kv"><p id="1174" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">由于词干提取是基于一组规则进行的，词干提取返回的词根可能不总是英语单词。另一方面，词汇化适当地减少了屈折词，确保词根属于英语。</p></blockquote><p id="cc5b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> N-Grams </strong></p><p id="9bd9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">N元语法指的是出于表示目的将邻近单词组合在一起的过程，其中N表示要组合在一起的单词的数量。</p><p id="2e08" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于eg，考虑一句话，“<strong class="iz hj"> <em class="kw">自然语言处理对于计算机科学来说是必不可少的。</em> </strong></p><p id="5a92" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个<strong class="iz hj"> 1-gram </strong>或<strong class="iz hj"> unigram </strong>模型将把句子标记成一个单词组合，因此输出将是"<strong class="iz hj">自然、语言、处理、is、本质、计算机、科学</strong></p><p id="4484" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一方面，<strong class="iz hj">二元模型</strong>将把它符号化为每个2个单词的组合，输出将是"<strong class="iz hj">自然语言，语言处理，处理是，是必要的，对计算机，计算机科学是必要的</strong>"</p><p id="db92" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">类似地，三元模型将把它分解为“自然语言处理，语言处理是，处理是必要的，是必要的，对计算机，对计算机科学是必要的”，并且n元模型因此将把句子标记为n个单词的组合。</p><blockquote class="kt ku kv"><p id="860a" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">将自然语言分解成n元语法对于维护句子中出现的单词数是必不可少的，句子中出现的单词数形成了自然语言处理中使用的传统数学过程的主干。</p></blockquote><h1 id="d9b1" class="lt ju hi bd jv lu lv lw jz lx ly lz kd io ma ip kg ir mb is kj iu mc iv km md bi translated"><strong class="ak">转换方法</strong></h1><p id="47ad" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">在单词包表示中实现这一点的最常见方法之一是tf-idf</p><p id="d310" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> TF-IDF </strong></p><blockquote class="kt ku kv"><p id="e84a" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">TF-IDF是一种对词汇进行评分的方法，以便根据单词对句子意思的影响比例为单词提供足够的权重。分数是两个独立分数的乘积，术语频率(tf)和逆文档频率(idf) </p></blockquote><figure class="mf mg mh mi fd mj er es paragraph-image"><div class="er es me"><img src="../Images/408305ee2a55e11c7f5bb08a2b508f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*YKVMQoUGdROeKJljTTpmnA.png"/></div><figcaption class="ml mm et er es mn mo bd b be z dx translated">图片来源:谷歌</figcaption></figure><p id="1e62" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">词频</strong> (TF):词频定义为词在当前文档中出现的频率。</p><p id="20a5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">逆文档频率</strong> ( IDF):衡量单词提供了多少信息，即在所有文档中是常见还是罕见。它的计算方法是log (N/d ),其中N是文档总数，d是出现该单词的文档数。</p><p id="693a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">一键编码</strong></p><blockquote class="kt ku kv"><p id="42c9" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">一种热编码是用数字形式表示单词的另一种方式。<strong class="iz hj">单词向量的长度等于词汇的长度，每个观察用一个矩阵表示，矩阵的行等于词汇的长度，列等于观察的长度，观察中出现词汇的单词时取值1，不出现时取值0。</strong></p></blockquote><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mp"><img src="../Images/178ddfa3036b53c51cf2cf390b6d7c08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ArM6Z5jeptCQ082DYn9nDQ.png"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated">图片来源——<a class="mu mv ge" href="https://medium.com/u/e6be2cb902a1?source=post_page-----ef6779e4ae66--------------------------------" rel="noopener" target="_blank">乔恩·克罗恩</a>(通过谷歌搜索获得)</figcaption></figure><p id="fcdc" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">单词嵌入</strong></p><blockquote class="kt ku kv"><p id="ba42" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated"><strong class="iz hj">单词嵌入是一组语言建模和特征学习技术的统称，其中来自词汇表的单词或短语被映射到实数的向量。该技术主要用于神经网络模型</strong>。</p></blockquote><p id="1b4f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从概念上讲，它包括将一个单词从一个相当于词汇长度的维度投影到一个更低维度的空间，其思想是相似的单词将被投影到彼此更近的地方。</p><p id="29d7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了便于理解，我们可以把嵌入想象成每个单词被投射到一个特征空间，如下图所示。</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mw"><img src="../Images/dca05ab6963b7b2ad1cf4a7352f4fae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ymADBM6YuDmA6eg79qxcsg.png"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated">图片来源:吴恩达，Coursera。每个单词都在一个特征空间(性别、皇室、年龄、食物)中表示</figcaption></figure><blockquote class="kt ku kv"><p id="b848" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">然而，在现实中，这些维度并不是那么清晰或容易理解。当算法训练维度之间的数学关系时，这不会出现问题。从训练和预测的角度来看，维度所表示的内容对于神经网络来说是没有意义的。</p></blockquote><p id="8bdc" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果有人对直观理解线性代数、投影和变换感兴趣，它们是许多机器学习算法背后的核心数学原理，我会强烈鼓励他们访问3Blue1Brown的“<strong class="iz hj">线性代数的本质</strong>”。</p><figure class="mf mg mh mi fd mj"><div class="bz dy l di"><div class="mx my l"/></div></figure><h1 id="a8a8" class="lt ju hi bd jv lu lv lw jz lx ly lz kd io ma ip kg ir mb is kj iu mc iv km md bi translated">表现方法</h1><h2 id="b145" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">一袋单词</h2><p id="c046" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">对于导出文本数据之间关系的算法，它需要以清晰的结构化格式来表示。</p><blockquote class="kt ku kv"><p id="c30f" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">单词包是一种以表格格式表示数据的方式，其中列表示语料库的总词汇，每行表示单个观察。单元格(行和列的交叉点)表示在该特定观察中由列表示的单词的计数。</p><p id="c0a2" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated"><strong class="iz hj">它帮助机器理解一个易于解释的矩阵范式中的句子，从而使各种线性代数运算和其他算法能够应用于数据，以建立预测模型。</strong></p></blockquote><p id="4566" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下是医学期刊文章样本的单词袋模型示例</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mz"><img src="../Images/9404b072e8aa48994042ab6e60bab4bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CF7T5TIUCa6ZrQfh-aHrkQ.png"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated"><strong class="bd jv">图片来源:取自谷歌搜索，未提及出处。让我知道这是否是你的形象，我可以添加信用</strong></figcaption></figure><p id="2f70" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这种表示工作得非常好，并负责为一些最常用的机器学习任务(如垃圾邮件检测、情感分类器等)生成模型。</p><p id="c89d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，这种表示法有两个主要缺点:</p><ol class=""><li id="8234" class="na nb hi iz b ja jb jd je jg nc jk nd jo ne js nf ng nh ni bi translated">它忽略了文本的顺序/语法，因此失去了单词使用的上下文</li><li id="de54" class="na nb hi iz b ja nj jd nk jg nl jk nm jo nn js nf ng nh ni bi translated"><strong class="iz hj">这种表示产生的矩阵是高度稀疏的</strong>，更偏向于最常见的单词。想想看，算法主要是对单词进行计数，而在语言中，单词的重要性实际上与出现的频率成反比。出现频率较高的单词是更一般的单词，如the、is、an，它们不会显著改变句子的意思。因此，恰当地权衡这些词以反映它们对句子意义的充分影响变得很重要。</li></ol><p id="5019" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">嵌入矩阵</strong></p><p id="dc89" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">嵌入矩阵是一种表示词汇表中每个单词的嵌入情况的方法。行代表单词嵌入空间的维度，列代表词汇表中存在的单词。</p><blockquote class="kt ku kv"><p id="f3d6" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated"><strong class="iz hj">为了将样本转换成其嵌入形式，其一个热编码形式中的每个单词乘以嵌入矩阵，以给出样本的单词嵌入</strong>。</p></blockquote><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es no"><img src="../Images/721a09bc0b212c694732f3aca40a9502.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WmIDJULhsKejfBg9Qftmzw.png"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated">图片鸣谢:吴恩达深度学习课程</figcaption></figure><p id="a509" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要记住的一件事是，这里的一个热点编码仅仅是指一个n维向量，其值为词汇表中单词位置处的1，其中n是词汇表的长度。这些一次性编码是从词汇表中提取的，而不是从一批观察数据中提取的。</p><h1 id="dcac" class="lt ju hi bd jv lu lv lw jz lx ly lz kd io ma ip kg ir mb is kj iu mc iv km md bi translated">递归神经网络(RNN)</h1><p id="f549" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">递归神经网络或简称为RNN，是在自然语言处理中大量使用的神经网络的一个非常重要的变体。</p><blockquote class="kt ku kv"><p id="2ea8" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">从概念上讲，它们不同于标准神经网络，因为RNN中的标准输入是一个单词，而不是标准神经网络中的整个样本。这使得网络可以灵活地处理不同长度的句子，这是标准神经网络由于其固定的结构而无法实现的。它还提供了一个额外的优势，即<strong class="iz hj">共享在文本</strong>的不同位置学习到的特征，这在标准的神经网络中是无法获得的。</p></blockquote><p id="64b5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">RNN将句子中的每个单词视为在时间“t”出现的单独输入，并且还使用在“t-1”的激活值，作为除了在时间“t”的输入之外的输入。下图显示了RNN架构的详细结构。</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es np"><img src="../Images/f33d4b9806801bf9390ce2c03c5bc5ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*901chLVbYLHQLc5EeZWIAw.jpeg"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated">图片来源:kdnuggets.com</figcaption></figure><p id="ec15" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上述架构也称为多对多架构，其中(Tx = Ty)，即输入数量=输出数量。这种结构在层序建模中非常有用。</p><p id="8254" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">除了上面提到的建筑，还有三种其他类型的RNN建筑是常用的。</p><ol class=""><li id="b353" class="na nb hi iz b ja jb jd je jg nc jk nd jo ne js nf ng nh ni bi translated"><strong class="iz hj">多对一RNN </strong>:多对一架构指的是一种RNN架构，其中许多输入(Tx)用于给出一个输出(Ty)。使用这种架构的一个合适的例子是<strong class="iz hj">分类任务</strong>。</li></ol><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es nq"><img src="../Images/0a576e45f9f30449698220a613b25287.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rqPCvf3mRrl9pGKW76wcTw.jpeg"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated"><strong class="bd jv">图片来源:取自谷歌搜索，未提及出处。让我知道这是否是你的形象，我可以添加信用</strong></figcaption></figure><p id="8135" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上图中，H代表激活函数的输出。</p><p id="8cfb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.<strong class="iz hj">一对多RNN </strong>:一对多架构是指RNN基于单一输入值生成一系列输出值的情况。使用这种架构的一个主要例子是<strong class="iz hj">音乐生成</strong>任务，其中输入是一个音符或第一个音符。</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mp"><img src="../Images/c19d8fe500a01f83ebd820a0204f82f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U5iGv9COU86x-H5dx3pP6Q.png"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated"><strong class="bd jv">图片来源:取自谷歌搜索，未提及出处。让我知道这是否是你的图像，我可以添加信用</strong></figcaption></figure><p id="1290" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.多对多架构(Tx不等于Ty):这种架构指的是读取许多输入以产生许多输出，其中输入的长度不等于输出的长度。使用这种架构的一个主要例子是机器翻译任务。</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mp"><img src="../Images/99a325906f75b6fc6e45660be374e357.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f2jwV3DXJLLO5rCx-bPQRQ.png"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated"><strong class="bd jv">图片来源:取自谷歌搜索，未提及出处。让我知道这是否是你的图像，我可以添加信用</strong></figcaption></figure><p id="4b48" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">编码器</strong>是指读取待翻译句子的网络部分，<strong class="iz hj">解码器</strong>是将句子翻译成所需语言的网络部分。</p><h2 id="d851" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">RNN的局限性</h2><p id="b3c8" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">除了它所有的用处之外，RNN也有一些限制，主要是:</p><ol class=""><li id="3d3a" class="na nb hi iz b ja jb jd je jg nc jk nd jo ne js nf ng nh ni bi translated">上述RNN体系结构的例子只能够捕捉语言的一个方向上的依赖性。基本上，在自然语言处理的情况下，它假设后面的单词对前面的单词的意思没有影响。根据我们的语言经验，我们知道这肯定不是真的。</li><li id="08bb" class="na nb hi iz b ja nj jd nk jg nl jk nm jo nn js nf ng nh ni bi translated">RNN也不太擅长捕捉长期依赖性，渐变消失的问题在RNN再次出现。</li></ol><p id="0f64" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这两个限制导致了下面将要讨论的新型RNN体系结构的出现。</p><h2 id="723e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">门控循环单元</h2><p id="3b44" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">这是对基本循环单元的修改，有助于捕捉长程相关性，也有助于解决消失梯度问题。</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div class="er es nr"><img src="../Images/ce2fa2052cd118556d3c88af750d9d90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*xtEkE4BDySwNJ4FF2RlakA.png"/></div><figcaption class="ml mm et er es mn mo bd b be z dx translated"><strong class="bd jv">图片来源:取自谷歌搜索，未提及出处。让我知道这是否是你的图像，我可以添加信用</strong></figcaption></figure><blockquote class="kt ku kv"><p id="eb7a" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">GRU由通常称为更新门或复位门的附加存储单元组成。<strong class="iz hj">除了具有sigmoid功能和softmax输出的常用神经单元外，它还包含一个附加单元，具有tanh激活功能</strong>。使用Tanh是因为它的输出可以是正的也可以是负的，因此可以用于放大和缩小。然后，该单元的输出与激活输入相结合，以更新存储单元的值。</p></blockquote><p id="761e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，在每一步，隐藏单元和存储单元的值都被更新。存储单元中的值在决定传递给下一个单元的激活值时起作用。</p><p id="1829" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">更详细的解释可以参考<a class="ae ns" href="https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be" rel="noopener" target="_blank">https://towards data science . com/understanding-gru-networks-2ef 37 df 6 c 9 be</a></p><p id="e2f5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> LSTM </strong></p><p id="ec89" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在LSTM体系结构中，不是像GRU那样只有一个更新门，而是有一个更新门和一个遗忘门。</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es nt"><img src="../Images/b793194486b9f4ed9e4f53aa2760b555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MpQK5P9Ihx2TEhRGvE-U4Q.png"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated">图片鸣谢:吴恩达深度学习Coursera</figcaption></figure><p id="6bf9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这种结构给存储单元一个选择，即在时间t-1保持旧值，并在时间t将值加到其上</p><p id="3125" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">http://colah.github.io/posts/2015-08-Understanding-LSTMs/有关于LSTM的更详细的解释</p><h2 id="b3b8" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">双向RNN</h2><p id="dc44" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">在上述RNN体系结构中，可以考虑仅在先前时间戳发生的影响。在NLP的情况下，这意味着它考虑了仅在当前单词之前书写的单词的影响。但在语言结构中却不是这样，因此双向RNN来帮忙了。</p><figure class="mf mg mh mi fd mj er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es nu"><img src="../Images/eef1588b33ef70e3143a54d76df51cc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*80HEc6uNib9RX1bE4YR2hA.png"/></div></div><figcaption class="ml mm et er es mn mo bd b be z dx translated">图片鸣谢:吴恩达，深度学习Coursera</figcaption></figure><blockquote class="kt ku kv"><p id="d6a2" class="ix iy kw iz b ja jb ij jc jd je im jf kx jh ji jj ky jl jm jn kz jp jq jr js hb bi translated">双向RNN由一个前向和一个后向递归神经网络组成，最终预测是在任何给定时间t结合两个网络的结果进行的，如图所示。</p></blockquote></div><div class="ab cl nv nw gp nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="hb hc hd he hf"><p id="62ef" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇博客中，我试图涵盖自然语言处理领域中流行的所有相关实践和神经网络架构。对于那些有兴趣深入了解神经网络的人，我强烈建议他们参加吴恩达Coursera的课程。</p><h1 id="0bd1" class="lt ju hi bd jv lu lv lw jz lx ly lz kd io ma ip kg ir mb is kj iu mc iv km md bi translated"><strong class="ak">参考文献</strong></h1><ol class=""><li id="542b" class="na nb hi iz b ja ko jd kp jg oc jk od jo oe js nf ng nh ni bi translated"><a class="ae ns" href="https://machinelearningmastery.com/natural-language-processing/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/natural-language-processing/</a></li><li id="045d" class="na nb hi iz b ja nj jd nk jg nl jk nm jo nn js nf ng nh ni bi translated">深度学习课程，吴恩达</li><li id="a10d" class="na nb hi iz b ja nj jd nk jg nl jk nm jo nn js nf ng nh ni bi translated"><a class="ae ns" href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" rel="noopener ugc nofollow" target="_blank">http://www . wild ml . com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/</a></li><li id="619e" class="na nb hi iz b ja nj jd nk jg nl jk nm jo nn js nf ng nh ni bi translated">3Blue1Brown系列油管</li><li id="59a4" class="na nb hi iz b ja nj jd nk jg nl jk nm jo nn js nf ng nh ni bi translated"><a class="ae ns" href="https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be" rel="noopener" target="_blank">https://towards data science . com/understanding-gru-networks-2ef 37 df 6 c 9 be</a></li><li id="8c8a" class="na nb hi iz b ja nj jd nk jg nl jk nm jo nn js nf ng nh ni bi translated"><a class="ae ns" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"><strong class="iz hj">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</strong></a></li></ol></div></div>    
</body>
</html>