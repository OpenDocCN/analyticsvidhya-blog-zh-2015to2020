# 具有机器学习的信号处理(人类活动识别)

> 原文：<https://medium.com/analytics-vidhya/signal-processing-with-machine-learning-human-activity-recognition-part-iii-neural-networks-fe5bcecc7e64?source=collection_archive---------8----------------------->

## 第三部分:神经网络

![](img/3d45d7590619dfa8f209d4a85b1ca41e.png)

欢迎回来，这是机器学习实践信号处理的最后一部分。我们将在加速度计和陀螺仪信号的相同数据集上利用深度学习的力量进行人类活动分类。

> 什么是深度学习？
> 深度学习是一种先进的机器学习技术，基于受人脑启发的神经网络。深度学习是使用神经网络来执行的，神经网络在数学上是类似于 fed 数据的自学习特征的矩阵或张量。深度学习在建模时间、准确性和最重要的费用方面优于经典的机器学习技术。深度学习的工作原理是通过网络反复传递一批通常称为张量的高维数据。
> 
> 网络的每个神经元都与一些线性或非线性权重和可选偏差相关联。在传递每一批数据之后，每个神经元的权重由优化器使用反向传播来调整，这是通过神经元反向传递损失，以便神经元可以使用梯度下降技术来调整它们的权重以减少最终损失。深度学习最有用的因素是一个模型的低成本开发。
> 
> 想知道为什么吗？？
> 
> 机器学习最重要的部分是特征工程和特征选择。组织在领域专家和数据分析师身上花费很多，他们为模型开发过滤和生成最重要的特征。神经网络最好的部分是我们可以跳过特征工程部分，直接将预处理数据输入神经网络。深度和密集的神经网络自己计算出重要和不重要的特征，并调整它们的权重。深度学习不需要领域专业知识，只需要一个开发团队就可以开发出来。

我们将看到深度学习如何在我们的人类活动分类任务中显示类似的预测性能，其中原始传感器数据被输入到深度神经网络，如 LSTM(长短期记忆)和 CNN(卷积神经网络)

我们将与 Keras 合作，这是一个基于 TensorFlow 的深度学习包装器，用于设计和测试我们的神经网络。

首先，我们将导入来自 9 个传感器的原始时间切片信号数据。时间片是对应于每毫秒传感器值的 128 个浮点值的序列。窗口滑动 1 步，下一个数据点是 128 个值的序列，其中有 127 个旧值和 1 个新值。标签是分类活动。

下面是我们将如何导入数据，并分成训练集和测试集。这一部分还有一些我们最常使用的帮助函数。

现在，当我们准备好信号数据集时，我们将首先创建一个 LSTM 网络。LSTM 网络是一种 RNN(递归神经网络),旨在解决时间序列或序列数据问题。LSTM 是一种先进的 RNN，旨在解决深度神经网络中经常出现的消失梯度问题。下面是 LSTM 的实现，只有 4 行代码，多简单啊。您可以简单地将这与经典机器学习实现的前一部分进行比较，在前一部分中，我们必须使用领域专家处理的数据集，这需要几个月的时间和一个专门的信号处理专家团队。

只需 10 行代码和 30 分钟的训练时间，就能达到 90%的准确率。混乱矩阵看起来也很有希望。

这就是深度学习的力量，原型制作要快得多。然而，它并没有击败经典的精度，但经过一些超调，并使用其他网络如卷积神经网络，精度不会有任何差异。让我们分析混淆矩阵，并将其与使用经典算法获得的最佳混淆矩阵进行比较。

我们将做一些超参数调整，看看模型的表现如何。下面是实现。我已经使用 gridsearchCV 进行了最佳模型选择。

超参数调整精度提高 1%后。坐类和站类的混淆也分别减少了 1%和 4%。我们可以用一个更深的神经网络做进一步的实验，并尝试添加另一个 LSTM 层，看看模型性能是否会提高。

添加另一个 LSTM 层后，模型性能进一步提高了 0.5%。卷积神经网络在顺序机器学习中也越来越受欢迎。让我们尝试 som ConvNets 以及 ConvNets 与 LSTMs 的组合，看看这是否能显著提高模型的性能。

在尝试了一些 ConvNets 和 LSTMs 的组合后，我们可以看到，使用神经网络，我们获得了大约 95%的准确性。我甚至达到了 96.5%的准确率，甚至超过了领域专家的工程数据集。

这是使用人类活动识别数据集的机器学习实现的信号处理的结尾。我试图在这个系列中涵盖机器学习的所有方面，从探索性数据分析到经典机器学习再到高级深度学习。

这个实现只是简单地展示了我们如何对原始信号进行深度学习，这不是最好的神经网络实现。可以尝试进一步的性能调整技术，如早期停止和正则化，以获得更好的模型性能并避免过度拟合。希望你喜欢这篇文章，如果你能帮助它传播和分享，我会非常感激。

快乐学习…:)