<html>
<head>
<title>A Practical Implementation of the Faster R-CNN Algorithm for Object Detection (Part 2 — with Python codes)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于目标检测的快速R-CNN算法的实际实现(第2部分Python代码)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-practical-implementation-of-the-faster-r-cnn-algorithm-for-object-detection-part-2-with-cac45dada619?source=collection_archive---------0-----------------------#2018-11-04">https://medium.com/analytics-vidhya/a-practical-implementation-of-the-faster-r-cnn-algorithm-for-object-detection-part-2-with-cac45dada619?source=collection_archive---------0-----------------------#2018-11-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1217" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您使用哪种算法来执行对象检测任务？为了在最少的时间内构建最精确的模型，我已经尝试了相当多的方法。这个旅程跨越了多个黑客马拉松和真实世界的数据集，通常会将我引向R-CNN算法家族。</p><p id="e19c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它对我来说是一个非常有用的框架，这就是为什么我决定以一系列文章的形式写下我的学习成果。这个系列的目的是展示不同类型的R-CNN算法是多么有用。第一部分从我们的社区获得了压倒性的积极回应，我很高兴能够呈现第二部分！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/6aea87b501ffb3bd46b34b3817c2d1c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*4h5t8PKm0q3KS4el.jpg"/></div></figure><p id="5e7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将首先简要总结我们在第1部分中学到的内容，然后深入研究R-CNN家族中速度最快的成员—更快的R-CNN的实现。如果您需要首先更新您的对象检测概念，我强烈推荐您通读这篇文章:<a class="ae jl" href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/" rel="noopener ugc nofollow" target="_blank">基本对象检测算法的逐步介绍(第1部分)</a>。</p><p id="cc96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将在这里处理一个非常有趣的数据集，所以让我们开始吧！</p><h1 id="0b11" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">目录</h1><ol class=""><li id="2a62" class="kk kl hi ih b ii km im kn iq ko iu kp iy kq jc kr ks kt ku bi translated">目标检测的不同R-CNN算法概述</li><li id="dd6b" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">理解问题陈述</li><li id="83d2" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">设置系统</li><li id="b6ff" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">数据探索</li><li id="2602" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">实现更快的R-CNN</li></ol><h1 id="a8e6" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">目标检测的不同R-CNN算法概述</h1><p id="1a35" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">让我们快速总结一下我们在第一篇文章中看到的R-CNN家族中的不同算法(R-CNN、快速R-CNN、更快速R-CNN)。这将有助于为我们稍后的实现部分打下基础，那时我们将预测出现在以前看不见的图像(新数据)中的边界框。</p><p id="e327" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">R-CNN使用选择性搜索从给定图像中提取一系列区域，然后检查这些框中是否包含物体。我们首先提取这些区域，对于每个区域，使用CNN提取特定的特征。最后，这些特征然后被用于检测物体。不幸的是，R-CNN变得相当慢，因为这一过程涉及多个步骤。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ld"><img src="../Images/08a7d801afaa730290f37ab62a6cfa56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/0*MDhnwEeQ8DNhlBCp.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">R-CNN</figcaption></figure><p id="5284" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一方面，快速R-CNN将整个图像传递给生成感兴趣区域的ConvNet(而不是传递从图像中提取的区域)。此外，它不是使用三个不同的模型(如我们在R-CNN中看到的)，而是使用一个模型，该模型从区域中提取特征，将它们分类到不同的类中，并返回边界框。</p><p id="0d2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所有这些步骤都是同时进行的，因此与R-CNN相比，它的执行速度更快。然而，快速R-CNN在应用于大型数据集时不够快，因为它还使用选择性搜索来提取区域。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es li"><img src="../Images/957d4f2bd3407d1c51620756837f61ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CujJJIQdtknezWqw.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">快速R-CNN</figcaption></figure><p id="2715" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更快的R-CNN通过用区域提议网络(RPN)代替它来解决选择性搜索的问题。我们首先使用ConvNet从输入图像中提取特征映射，然后将这些映射传递给RPN，RPN返回对象建议。最后，对这些图进行分类并预测包围盒。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/d0fda188a8e2a9413fd2320af452bf24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/0*u_9CANl-M3OTxmmC.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">更快的R-CNN</figcaption></figure><p id="67cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我在下面总结了快速R-CNN算法检测图像中的对象所遵循的步骤:</p><ol class=""><li id="0338" class="kk kl hi ih b ii ij im in iq lo iu lp iy lq jc kr ks kt ku bi translated">获取一个输入图像，并将其传递给ConvNet，后者返回该图像的特征映射</li><li id="aad2" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">在这些特征地图上应用区域提议网络(RPN)并获得对象提议</li><li id="33d1" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">应用投资回报池层，将所有提案缩小到相同的大小</li><li id="effb" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">最后，将这些建议传递给完全连接的层，以便对图像的任何预测边界框进行分类</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lr"><img src="../Images/4299d8235f59a327419456342a25ef8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*OXekY-RMa0jG0jlD2v5WHQ.png"/></div></figure><p id="837d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有什么比用表格形式更好的方法来比较这些不同的算法呢？所以给你！</p><p id="2d46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">既然我们已经掌握了这个话题，是时候从理论跳到文章的实践部分了。让我们使用一个非常酷(而且相当有用)的数据集实现更快的R-CNN，它具有潜在的现实生活应用！</p><h1 id="4fa0" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">理解问题陈述</h1><p id="db26" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">我们将研究医疗保健相关的数据集，目的是解决血细胞检测问题。我们的任务是通过显微图像读数检测每幅图像中的所有红细胞(RBCs)、白细胞(WBCs)和血小板。下面是我们最终预测的样本:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/ed09db9fc61a81f1253ebb13b6347fc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*yETIYss9gVadX2bD.jpg"/></div></figure><p id="c836" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">选择这个数据集的原因是，我们血流中的红细胞、白细胞和血小板的密度提供了许多关于免疫系统和血红蛋白的信息。这可以帮助我们潜在地确定一个人是否健康，如果在他们的血液中发现任何差异，可以迅速采取行动进行诊断。</p><p id="4736" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过显微镜手动观察样品是一个繁琐的过程。这就是深度学习模型发挥如此重要作用的地方。他们可以从显微图像中以令人印象深刻的精度对血细胞进行分类和检测。</p><p id="ce1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们挑战的全血细胞检测数据集可以从这里</strong><a class="ae jl" href="https://github.com/Shenggan/BCCD_Dataset" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a><strong class="ih hj">下载。</strong>针对本文的范围，我对数据做了一点小小的修改:</p><ul class=""><li id="8961" class="kk kl hi ih b ii ij im in iq lo iu lp iy lq jc lt ks kt ku bi translated">边界框已从给定的。xml格式转换为. csv格式</li><li id="153f" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated">我还在整个数据集上创建了训练集和测试集分割，方法是随机挑选图像进行分割</li></ul><p id="f205" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lu">请注意，我们将使用流行的Keras框架和Python中的TensorFlow后端来训练和构建我们的模型。</em></p><h1 id="e56f" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">设置系统</h1><p id="0b22" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在我们真正进入模型构建阶段之前，我们需要确保已经安装了正确的库和框架。运行此项目需要以下库:</p><ul class=""><li id="e5cc" class="kk kl hi ih b ii ij im in iq lo iu lp iy lq jc lt ks kt ku bi translated">熊猫</li><li id="b40a" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated">matplotlib</li><li id="4233" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated">张量流</li><li id="7368" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated">keras — 2.0.3</li><li id="5345" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated">numpy</li><li id="d548" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated">opencv-python</li><li id="7935" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated">sklearn</li><li id="e638" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated">h5py</li></ul><p id="76b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您安装了Anaconda和Jupyter笔记本，上面提到的大多数库都已经在您的机器上了。另外，我建议<strong class="ih hj">从</strong> <a class="ae jl" href="https://drive.google.com/file/d/1R4O0stMW9Wjksg-o7c54svntDiyask1B/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">这个链接</strong> </a>下载requirement.txt文件，并使用它来安装其余的库。为此，请在终端中键入以下命令:</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="2399" class="ma jn hi lw b fi mb mc l md me">pip install -r requirement.txt</span></pre><p id="3b16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，我们的系统现在设置好了，我们可以继续处理数据了！</p><h1 id="1c97" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">数据探索</h1><p id="5628" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">首先探索我们拥有的数据总是一个好主意(坦白地说，是一个强制性的步骤)。这不仅有助于我们发掘隐藏的模式，而且有助于我们对正在处理的东西有一个有价值的全面的了解。我从整个数据集创建的三个文件是:</p><ol class=""><li id="00cd" class="kk kl hi ih b ii ij im in iq lo iu lp iy lq jc kr ks kt ku bi translated"><strong class="ih hj"> train_images: </strong>我们将用来训练模型的图像。我们在这个文件夹中有类和每个类的实际边界框。</li><li id="6554" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated"><strong class="ih hj"> test_images: </strong>该文件夹中的图像将用于使用训练好的模型进行预测。该集合缺少类和这些类的边界框。</li><li id="c89e" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated"><strong class="ih hj"> train.csv: </strong>包含每个图像的名称、类别和边界框坐标。一个图像可以有多行，因为一个图像可以有多个对象。</li></ol><p id="4adb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们读一下。csv文件(您可以创建自己的。csv文件)并打印出前几行。为此，我们需要首先导入以下库:</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="c2f9" class="ma jn hi lw b fi mb mc l md me"># importing required libraries<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>from matplotlib import patches</span><span id="bcba" class="ma jn hi lw b fi mf mc l md me"># read the csv file using read_csv function of pandas<br/>train = pd.read_csv(‘train.csv’)<br/>train.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mg"><img src="../Images/57c2ac08c58d9d2118fd1d891866d44d.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/0*AepzfIS70agwYB-R.png"/></div></figure><p id="f934" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练文件中有6列。让我们了解一下每一列代表什么:</p><ol class=""><li id="9d45" class="kk kl hi ih b ii ij im in iq lo iu lp iy lq jc kr ks kt ku bi translated"><strong class="ih hj">图像名称:</strong>包含图像的名称</li><li id="d787" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated"><strong class="ih hj">单元格类型:</strong>表示单元格的类型</li><li id="b6f5" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated"><strong class="ih hj"> xmin: </strong>图像左下部分的x坐标</li><li id="1dc3" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated"><strong class="ih hj"> xmax: </strong>图像右上部分的x坐标</li><li id="9f2b" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated"><strong class="ih hj"> ymin: </strong>图像左下部分的y坐标</li><li id="2b45" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated"><strong class="ih hj"> ymax: </strong>图像右上部分的y坐标</li></ol><p id="c59f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们打印一张图像来直观显示我们正在处理的内容:</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="70c7" class="ma jn hi lw b fi mb mc l md me"># reading single image using imread function of matplotlib<br/>image = plt.imread('images/1.jpg')<br/>plt.imshow(image)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mh"><img src="../Images/91a8f9977482ba862c631c4b65b8788b.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/0*WCrpU2ch5uimJFqW.png"/></div></figure><p id="c487" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是血细胞图像的样子。这里，蓝色部分代表白细胞，略带红色的部分代表红细胞。让我们看看在我们的训练集中有多少图像和不同类型的类。</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="34cb" class="ma jn hi lw b fi mb mc l md me"># Number of unique training images<br/>train['image_names'].nunique()</span></pre><p id="5d39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，我们有254张训练图像。</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="c6c9" class="ma jn hi lw b fi mb mc l md me"># Number of classes<br/>train['cell_type'].value_counts()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mi"><img src="../Images/b403128001818c927ceb4727bd0b51f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/0*p--j4ncSVz7y5s3m.png"/></div></figure><p id="51c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有三种不同的细胞，即红细胞、白细胞和血小板。最后，让我们看看带有检测到的对象的图像是什么样子的:</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="2aaf" class="ma jn hi lw b fi mb mc l md me">fig = plt.figure()<br/><br/>#add axes to the image<br/>ax = fig.add_axes([0,0,1,1])<br/><br/># read and plot the image<br/>image = plt.imread('images/1.jpg')<br/>plt.imshow(image)<br/><br/># iterating over the image for different objects<br/>for _,row in train[train.image_names == "1.jpg"].iterrows():<br/>    xmin = row.xmin<br/>    xmax = row.xmax<br/>    ymin = row.ymin<br/>    ymax = row.ymax<br/>    <br/>    width = xmax - xmin<br/>    height = ymax - ymin<br/>    <br/>    # assign different color to different classes of objects<br/>    if row.cell_type == 'RBC':<br/>        edgecolor = 'r'<br/>        ax.annotate('RBC', xy=(xmax-40,ymin+20))<br/>    elif row.cell_type == 'WBC':<br/>        edgecolor = 'b'<br/>        ax.annotate('WBC', xy=(xmax-40,ymin+20))<br/>    elif row.cell_type == 'Platelets':<br/>        edgecolor = 'g'<br/>        ax.annotate('Platelets', xy=(xmax-40,ymin+20))<br/>        <br/>    # add bounding boxes to the image<br/>    rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = 'none')<br/>    <br/>    ax.add_patch(rect)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mj"><img src="../Images/541874fe1ad8f61703ef8f4c69cfd3d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/0*MbqaH3Q3ozTcwtc0.png"/></div></figure><p id="6f0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个培训示例的样子。我们有不同的类和它们相应的边界框。现在让我们在这些图像上训练我们的模型。我们将使用<em class="lu"> keras_frcnn </em>库来训练我们的模型，并对测试图像进行预测。</p><h1 id="1672" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">实现更快的R-CNN</h1><p id="b827" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">为了实现更快的R-CNN算法，我们将遵循Github库中提到的步骤。因此，作为第一步，确保您克隆了这个存储库。打开一个新的终端窗口，键入以下命令:</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="24a6" class="ma jn hi lw b fi mb mc l md me">git clone <a class="ae jl" href="https://github.com/kbardool/keras-frcnn.git" rel="noopener ugc nofollow" target="_blank">https://github.com/kbardool/keras-frcnn.git</a></span></pre><p id="b0db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将<em class="lu"> train_images </em>和<em class="lu"> test_images </em>文件夹以及<em class="lu"> train.csv </em>文件移动到克隆的存储库中。为了在新数据集上训练模型，输入的格式应该是:</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="6a9d" class="ma jn hi lw b fi mb mc l md me">filepath,x1,y1,x2,y2,class_name</span></pre><p id="ec5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里，</p><ul class=""><li id="7f99" class="kk kl hi ih b ii ij im in iq lo iu lp iy lq jc lt ks kt ku bi translated"><em class="lu">文件路径</em>是训练图像的路径</li><li id="8a40" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated"><em class="lu"> x1 </em>是包围盒的xmin坐标</li><li id="72a5" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated"><em class="lu"> y1 </em>是包围盒的ymin坐标</li><li id="1a94" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated"><em class="lu"> x2 </em>是包围盒的xmax坐标</li><li id="a82c" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated"><em class="lu"> y2 </em>是包围盒的ymax坐标</li><li id="c247" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lt ks kt ku bi translated"><em class="lu"> class_name </em>是该边界框中的类的名称</li></ul><p id="0135" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要将。csv格式转换为. txt文件，该文件将具有与上述相同的格式。创建一个新的数据帧，按照格式将所有值填入该数据帧，然后保存为. txt文件。</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="d84c" class="ma jn hi lw b fi mb mc l md me">data = pd.DataFrame()<br/>data['format'] = train['image_names']<br/><br/># as the images are in train_images folder, add train_images before the image name<br/>for i in range(data.shape[0]):<br/>    data['format'][i] = 'train_images/' + data['format'][i]<br/><br/># add xmin, ymin, xmax, ymax and class as per the format required<br/>for i in range(data.shape[0]):<br/>    data['format'][i] = data['format'][i] + ',' + str(train['xmin'][i]) + ',' + str(train['ymin'][i]) + ',' + str(train['xmax'][i]) + ',' + str(train['ymax'][i]) + ',' + train['cell_type'][i]<br/><br/>data.to_csv('annotate.txt', header=None, index=None, sep=' ')</span></pre><p id="7999" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是什么？</p><p id="d7af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练我们的模特！我们将使用<em class="lu"> train_frcnn.py </em>文件来训练模型。</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="0b26" class="ma jn hi lw b fi mb mc l md me">cd keras-frcnn<br/>python train_frcnn.py -o simple -p annotate.txt</span></pre><p id="f843" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于数据的大小，需要一段时间来训练模型。如果可能的话，你可以使用GPU来加快训练的速度。作为一种替代选择，您也可以尝试减少历元的数量。要更改时期数，请转到克隆存储库中的<em class="lu"> train_frcnn.py </em>文件，并相应地更改<em class="lu"> num_epochs </em>参数。</p><p id="637f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每当模型看到改进时，该特定时期的权重将保存在与“<em class="lu"> model_frcnn.hdf5 </em>”相同的目录中。当我们对测试集进行预测时，将使用这些权重。</p><p id="51bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练模型和获取权重可能需要很长时间，这取决于您的机器配置。我建议使用我在训练模型大约500个时期后得到的权重。<strong class="ih hj">你可以从这里</strong> 下载这些权重 <a class="ae jl" href="https://drive.google.com/file/d/1OmCKlUEYmTjg_jaaN-IQm81eHROU-Gyl/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">。确保将这些权重保存在克隆的存储库中。</strong></a></p><p id="5936" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我们的模型已经训练好了，权重也设定好了。预测时间到了！<em class="lu"> Keras_frcnn </em>对新图像进行预测，并将其保存在新文件夹中。我们只需在<em class="lu"> test_frcnn.py </em>文件中做两处修改来保存图像:</p><ol class=""><li id="1682" class="kk kl hi ih b ii ij im in iq lo iu lp iy lq jc kr ks kt ku bi translated">删除这个文件最后一行的注释:<br/> <em class="lu"> cv2.imwrite('。/results_imgs/{}。巴布亚新几内亚。格式(idx)，img) </em></li><li id="78a4" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">在这个文件的倒数第二行和倒数第三行添加注释:<br/> # <em class="lu"> cv2.imshow('img '，img) <br/> # cv2.waitKey(0) </em></li></ol><p id="2fb0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们对新图像进行预测:</p><pre class="je jf jg jh fd lv lw lx ly aw lz bi"><span id="03e1" class="ma jn hi lw b fi mb mc l md me">python test_frcnn.py -p test_images</span></pre><p id="9a76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，带有检测对象的图像将保存在“results_imgs”文件夹中。下面是我在实现更快的R-CNN后得到的几个预测的例子:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/9405290a07454914ea735958b7f96ce8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*M6vsid_45EWO7spv.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><em class="mk">结果1 </em></figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/4bf53e1585b143c8d989434ed88bc254.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*yHNVHR_DuXNlhSYS.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><em class="mk">结果二</em></figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/4a3e8885b294c8ce734bf7d4176e984e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*UklpaFyL2qny8S02.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><em class="mk">结果3 </em></figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/af71adaf51f0d69fc90a590633b8657e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*a_mKVJzWW3AoTCuZ.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><em class="mk">结果4 </em></figcaption></figure><h1 id="3d82" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">结束注释</h1><p id="9a00" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">R-CNN算法已经真正成为物体探测任务的游戏规则改变者。近年来，计算机视觉应用程序的数量突然激增，R-CNN是其中大多数的核心。</p><p id="b6c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lu"> Keras_frcnn </em>被证明是一个优秀的对象检测库，在本系列的下一篇文章中，我们将关注更高级的技术，如YOLO、SSD等。</p><p id="7067" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你对我们这里的内容有任何疑问或建议，请在下面的评论区发表，我很乐意与你联系！</p></div><div class="ab cl ml mm gp mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hb hc hd he hf"><p id="6405" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lu">原载于2018年11月4日</em><a class="ae jl" href="https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/" rel="noopener ugc nofollow" target="_blank"><em class="lu">www.analyticsvidhya.com</em></a><em class="lu">。</em></p></div></div>    
</body>
</html>