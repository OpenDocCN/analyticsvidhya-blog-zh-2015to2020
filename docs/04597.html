<html>
<head>
<title>Classification Model Evaluation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类模型评估</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classification-model-evaluation-cc18a80861ec?source=collection_archive---------23-----------------------#2020-03-25">https://medium.com/analytics-vidhya/classification-model-evaluation-cc18a80861ec?source=collection_archive---------23-----------------------#2020-03-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="ab fe cl ij"><img src="../Images/a39fad13a8de658b7c4aa7959b095f2f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1WPbfzztdv50V22TpA6njw.png"/></div></figure><h1 id="e34b" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">混淆矩阵</h1><p id="bb7b" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">对于分类问题，我们首先需要知道的是混淆矩阵。从这个矩阵中，我们可以获得一些有用的信息，包括准确度、精确度、召回率和f1分数。</p><p id="25a9" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在这里，我们假设只有两种可能的结果，积极的和消极的。在二元分类问题中，正(或者用数字1)总是指人们真正关心的结果。例如，如果我们正在构建一个银行欺诈检测模型，则肯定的结果意味着存在欺诈交易。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es kn"><img src="../Images/1597bfc96e464f1cf9b741813233c095.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*ql1Zxx50NLQezrDibc8mYQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">混淆矩阵</figcaption></figure><p id="e60d" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">根据上图，我们有一个包括TP、FP、FN和TN的矩阵。第二封信指的是我们样本的预测，第一封信显示我们的预测是否正确。我们在Python中使用sklearn的时候，矩阵是不一样的，但是思路是一样的，只是一些行和列的交换。让我们在sklearn中实现吧。</p><pre class="ko kp kq kr fd kw kx ky kz aw la bi"><span id="a49d" class="lb in hi kx b fi lc ld l le lf">binary classification, the count of true negatives is<br/>:math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is<br/>:math:`C_{1,1}` and false positives is :math:`C_{0,1}`</span></pre><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es lg"><img src="../Images/507178095daca2719024dd0248b38cf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*YOjLLn61MxOF7acJIXGwUA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">sklearn中的混淆矩阵</figcaption></figure><pre class="ko kp kq kr fd kw kx ky kz aw la bi"><span id="dbfb" class="lb in hi kx b fi lc ld l le lf">from sklearn import metrics</span><span id="a730" class="lb in hi kx b fi lh ld l le lf">y_true = [0, 1, 0, 1, 1, 1, 0, 0] # raw data<br/>y_pred = [0, 1, 1, 1, 1, 1, 0, 1] # final prediction</span><span id="ef44" class="lb in hi kx b fi lh ld l le lf">metr = metrics.classification.confusion_matrix(y_true, y_pred)<br/>metr</span></pre><p id="c4fb" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">这个问题的混淆矩阵是:</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es li"><img src="../Images/0f885bf6d86ebee3458ece7ad3ad6341.png" data-original-src="https://miro.medium.com/v2/resize:fit:142/format:webp/1*OSgRI75UVWVBqOVTQjKxbw.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">抽样输出</figcaption></figure><p id="bfde" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">样本数据中有4个正类和4个负类。所以每列的总和是4。</p><p id="7ae0" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">TN:原始数据和预测都是0。我们有两个。</p><p id="64b2" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">FP:预测是1，但原始数据是0。我们有两个。</p><p id="37d9" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">FN:预测是0，但原始数据是1。这些都不是。</p><p id="0bb6" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">TP:原来和预测是1。我们有四个。</p><p id="4990" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们也可以使用Seaborn来可视化我们的混淆矩阵。</p><pre class="ko kp kq kr fd kw kx ky kz aw la bi"><span id="38ec" class="lb in hi kx b fi lc ld l le lf">from sklearn.metrics import confusion_matrix<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="87cd" class="lb in hi kx b fi lh ld l le lf"># visualize<br/>figure = plt.figure(figsize=(4, 4))<br/>sns.heatmap(metr, cmap='Blues')<br/>plt.xlabel('Predicted labels')<br/>plt.ylabel('True labels')<br/>plt.show()</span></pre><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es lj"><img src="../Images/8f2ec32459c34d7331d24d1d34f57b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*c5CJ0r3GWBYbNL9b4VQWQg.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">样本混淆矩阵</figcaption></figure><h1 id="2612" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">评估指标</h1><p id="89f5" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">对于以前没有见过的人来说，矩阵本身可能会令人困惑。也许这就是它被称为混乱矩阵的原因。从矩阵中提取一些可理解的数据是一个好主意，这就是为什么我们有精确度、准确度、召回率和F1分数。</p><p id="fee7" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">准确率:正确预测/预测总数。</strong></p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/e1a64c30b07ab575900a8525200363c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*eHqxW6Qpx8PGmTTSrCplog.png"/></div></figure><p id="f9fe" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">那是对角线上的项目总和除以项目总数！</p><p id="7fa5" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">精度:正确正预测/正预测总数</strong></p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es ll"><img src="../Images/15fe5aab2be09c450f1da85c0f24e124.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*XfaADzu5bNDdrfJ-pXSFSA.png"/></div></figure><p id="c3d2" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">Precision大多数时候只关心正类(有时候我们有负的预测值，它只关心负类)。</p><p id="3e79" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">灵敏度(回忆):正确的阳性预测/阳性类别总数(在原始数据中)</strong></p><figure class="ko kp kq kr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lm"><img src="../Images/24816bf09f4826f121bb6fd7c0454b94.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*5MB518Z6u9SqrYuvBloChQ.png"/></div></div></figure><p id="9aef" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">回忆显示了我们的模型捕捉正面类的能力。例如，它显示了我们的模型可以检测到多少百分比的银行卡欺诈。我们一直希望召回规模越大越好，因为我们不想遭受任何交易欺诈。</p><p id="3269" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">简而言之，准确性不依赖于标签，但精确度和召回率依赖于标签，我们需要指定数据的正面标签。对于一个不平衡的数据集，准确率总是不能成为一个好的指标，我们应该用准确率和召回率来代替。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lr"><img src="../Images/2a7ea666f3b430f65f2ba64e758b950b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Shd1c_FdI8mrYfVY0hit6w.png"/></div></div></figure><p id="afd6" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">使用sklearn计算这些指标非常容易。只需注意pos_label参数！</p><h1 id="ae45" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak"> ROC曲线</strong></h1><p id="b885" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated"><strong class="jm hj"> ROC </strong>指<strong class="jm hj">接收机工作特性</strong>。那是一个相当长的时期。但背后的想法并没有那么复杂。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es ls"><img src="../Images/05b4acb13b4be933f1f968f9b88b359e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XZxVrISt-bAuuSOJ.jpg"/></div></div></figure><p id="33f7" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj"> AUC </strong>指<strong class="jm hj">曲线下面积</strong>，顾名思义，曲线下面积。我们使用AUC来评估我们的模型。</p><p id="cc6e" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">首先，让我们绘制一个样本ROC曲线！</p><pre class="ko kp kq kr fd kw kx ky kz aw la bi"><span id="bdbf" class="lb in hi kx b fi lc ld l le lf">y_true = [0, 1, 0, 1, 1, 1, 0, 0] # raw data<br/>y_score = [0.2, 0.7, 0.6, 0.6, 0.5, 0.9, 0.4, 0.6] # problistic likelyhood <br/># y_pred = [0, 1, 1, 1, 1, 1, 0, 1]</span><span id="20a7" class="lb in hi kx b fi lh ld l le lf">x, y, thed = metrics.roc_curve(y_true, y_score, pos_label=1)</span><span id="d1a8" class="lb in hi kx b fi lh ld l le lf">import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>plt.plot(x, y)</span></pre><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es lt"><img src="../Images/8ea244ed7415026b05aa5f3e4868b59a.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*jptH0S0NmCJETv3Q95wdmA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">样本ROC曲线</figcaption></figure><p id="2bbc" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">纵轴显示<strong class="jm hj">真阳性率(TPR)</strong>，等于阳性回忆。而x轴表示<strong class="jm hj">假阳性率(FPR) </strong>，等于1-(负类召回)。总体数字显示了我们的模型在所有阈值下的性能。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lu"><img src="../Images/8d5d4d925e23d8d99e51a52ce92ce24d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ncs6tyO3XlkoGjd-LJl9A.png"/></div></div></figure><p id="a569" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">对于TPR，如果它等于1，则意味着FN为0，并且我们的模型已经捕获了所有正项。</p><p id="95d6" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">对于FPR，它是1-(我们的模型捕获了多少个负类)，这意味着，我们的模型没有捕获多少个负类。我们希望它是0，对吗？</p><p id="6ba4" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在，我们来谈谈我们之前提到的门槛。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lu"><img src="../Images/58df42be0aac6a0326b7cf69a783b482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yXkj10qMY7o9FAIeNslcLg.png"/></div></div></figure><p id="543f" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">当概率结果大于阈值时，我们的预测将是1。因此，对于不同的阈值，我们可以在ROC曲线中得到不同的点。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lv"><img src="../Images/2a8a3d9641066270973a1bb1a9a91980.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ktA7AFrmlRs0kVHTggIDGw.png"/></div></div></figure><p id="1ed6" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">通过使用不同的阈值𝜃值(默认为0.5，范围为[0，1])，我们可以得到许多TPR和FPR对，并将这一点绘制成图，我们将得到ROC曲线。</p><p id="2668" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">如何选择最佳阈值？</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es lt"><img src="../Images/4879120245ab82a36bd4b50153c9cc18.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*DWjL_FrOzMpRFmHcXqk5nA.png"/></div></figure><p id="1095" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们来看点y2和y1，它们的x轴是一样的，但是y2的y轴更高，所以y2更好。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es lw"><img src="../Images/c8124d836234316cf18fe90d3b53766f.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*wqLN6vwgVe3-XP3sZLAYfA.png"/></div></figure><p id="1550" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">y3和y2呢？答案是，看情况。在某些场景中，例如，银行欺诈检测，y3更好，因为我们希望尽可能多地捕获正面类。相比之下，对于一些推广欺诈检测(有人可能注册了很多账户)，也许我们可以容忍一些欺诈，因为我们的目标是激励客户。</p></div></div>    
</body>
</html>