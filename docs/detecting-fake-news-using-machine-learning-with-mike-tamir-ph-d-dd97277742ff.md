# 与 Mike Tamir 博士一起使用机器学习检测假新闻

> 原文：<https://medium.com/analytics-vidhya/detecting-fake-news-using-machine-learning-with-mike-tamir-ph-d-dd97277742ff?source=collection_archive---------1----------------------->

# 介绍

假新闻是我们数字化互联世界中最大的祸害之一。这一点也不夸张。它不再局限于小争吵——假新闻像野火一样传播，每天都在影响着数百万人。

你如何处理这样一个敏感的问题？互联网上每天都有数百万篇文章被炮制出来——你如何辨别真假？这不像求助于一个简单的事实检查器那么容易。它们通常是建立在一个故事接一个故事的基础上。我们可以转向机器学习吗？

这是一个普遍而紧迫的问题——因此我们邀请了迈克·塔米尔博士作为我们 DataHack 电台的嘉宾。迈克一直致力于一个名为 FakerFact 的项目，旨在识别和区分真实与虚构。他的团队的方法是基于使用各种自然语言处理(NLP)的机器学习算法。

在这一集里，Kunal 和 Mike 讨论了 FakerFact 算法的几个方面，包括:

*   FakerFact 背后的想法
*   Mike 和他的团队如何收集数据来训练 FakerFact NLP 算法
*   更新现有数据集和重新训练这些算法的重要性
*   处理数据中的偏差

还有很多很多。我会向每一位数据科学家推荐这个播客，它触及了困扰我们社会的一个关键问题。

![](img/f9f502b0703a3cc56a45355b16210dce.png)

*我们所有的 DataHack 电台播客都可以在以下平台上获得——立即订阅！*

*   [**音云**](https://soundcloud.com/datahack-radio)
*   [**分析 Vidhya**](https://www.analyticsvidhya.com/blog/category/podcast/?utm_source=blog&utm_medium=datahack-radio-21-mike-tamir)
*   [**iTunes**](https://itunes.apple.com/in/podcast/datahack-radio/id1397786677?mt=2)
*   [**谷歌播客**](https://www.google.com/podcasts?feed=aHR0cDovL2ZlZWRzLnNvdW5kY2xvdWQuY29tL3VzZXJzL3NvdW5kY2xvdWQ6dXNlcnM6NDU5MzM1NzYwL3NvdW5kcy5yc3M%3D)

我在这篇文章中总结了插曲讨论。快乐聆听！

# FakerFact 背后的想法

> 错误信息的挑战已经普遍存在了很多年，但我们整个社会仍然没有解决这个问题

如果你从事过 NLP 项目，你可能会知道检测文本中的意图有多困难。人类语言的层次之多让人感到难以承受！要让一台机器理解它，需要付出很多努力。

然而，在过去几年里，情况一直在改善。NLP 框架有了巨大的飞跃。我们在这里 展示了突破性的进展 [**。简而言之，NLP 技术现在可以解析给定的文本并执行各种人工任务。**](https://www.analyticsvidhya.com/blog/tag/nlp/?utm_source=blog&utm_medium=datahack-radio-21-mike-tamir)

FakerFact 是 Mike Tamir 的项目，几年前他和几个研究员一起开始的。大多数网上可用的事实检查器往往是非黑即白的——它们试图告诉你一条给定的信息是真是假。FakerFact 从一个不同的角度来检查事实:

> *“我们能不能教机器学习算法来区分仅仅是关于教育、报道等的文本。相对于表达观点、使用讽刺、充满仇恨言论、有不可告人的目的等的文本。?"*

![](img/b1e56353a20b8ef0f6fa3e8fd620317a.png)

你可以在这里阅读更多关于 FakerFact 如何工作以及如何在你的浏览器中使用它的信息。

# 收集用于训练 FakerFact 算法和对抗偏差的数据

> *“这是数据科学中最困难的挑战之一。”*

Mike 和他的团队从顶级域名开始。他们使用不同的算法进行反向自举过程。这有助于团队从领域级别向下进行单个文章级别的培训。

他们必须注意的最重要的事情之一是分层。这很容易理解——你不希望模型因为样本而有偏差，对吗？迈克用一个右翼和左翼文章的精彩例子来说明这一点。

作为一名数据科学家，你会喜欢播客的这一部分。对我们来说，从数据收集流程的一开始就了解并减少偏见非常重要。可以想象这对 FakerFact 这样基于事实的应用程序来说有多关键。

我们在网上看到的大多数假新闻数据集都是基于某些事件，比如 2016 年美国大选。这是一个非常特殊的样本，如果单独使用，可能会导致模型出现严重偏差。使用不同的领域和时间段来多样化是很重要的。

现在，FakerFact 的目标是将真相与虚构分开。这意味着它依赖于观众告诉算法某篇文章是否可信。但是你能完全依靠你的观众来产生这种洞察力吗？不要！Fakerfact 团队有几个策略来减少来自用户反馈的偏见。

# 更新数据集以跟上文章数量的增长

鉴于当今互联世界的信息传播速度之快以及大量文章的产生，收集一次数据并不能解决问题。迈克和他的团队不断更新他们的数据集。他们现在正在进行第五次迭代。

> *“我们在不断地搜集数据。我们的数据集中有数百万篇文章。”*

当然，这意味着每次更新，团队都需要运行并再次检查他们的基线结果。他们的表现水平一样吗？他们需要改变架构吗？诸如此类的问题对于保持 FakerFact 在游戏中的领先地位至关重要。

# 处理数据中的未知偏差

任何参与过哪怕是稍微复杂的 NLP 项目的人都知道，构建模型并不是一帆风顺的。前进的道路上会有障碍。你可能会错过某一点，或者一个未知的偏见可能会蔓延，没有人会想到在一百万年。

Mike 挑选了他的团队在构建 FakerFact 模型时遇到的两个例子。第一个是关于作者在 Twitter 上推销自己。

但这是第二个让我印象深刻的例子。在某个网站(播客中提到的名字)，FakerFact 算法始终如一地调出文章。这个团队不知道为什么——这些文章看起来像普通的新闻报道。你能猜到是什么问题吗？

这些算法分析了每篇文章的评论部分。所以结果总是有偏差(这是大多数政治或新闻网站的状态)。未知偏差的经典例子。

# 迈克·塔米尔的行业经验

改变话题时，Kunal 请 Mike 谈谈他丰富的行业经验，尤其是他之前在优步担任数据科学主管的经历。我将播客的这一部分总结如下:

*   为自动驾驶汽车创建模拟:在优步大学，迈克的团队就创建 Q-learning 适应性压力测试开展了研究。事实上，有些作品很快就要出版了！
*   迈克的其他角色包括现货定价、优步 Eats 应用程序的推荐以及自动驾驶汽车的其他各个方面

# 自然语言处理的未来

最后，Mike Tamir 认为 NLP 在未来几年将走向何方？

> *“可以肯定的是，我们将继续看到我们在文本处理方面的巨大进步。”*

2018 年是 NLP 突破性的一年。我们看到了诸如 BERT、ULMFiT、Transformer-XL 等框架和库。但那个基地是 2017 年建的。展望未来，也许在未来 2-3 年内，Mike 说他可以看到这些技术的融合。

这已经在 2019 年发生，并且应该继续加快前进的步伐。真正有趣的时代就在前方！

# 结束注释

假新闻再也不是闹着玩的了。它已经从一个纯粹的麻烦迅速转变为在世界范围内造成生命损失。朝着正确处理这一问题迈出的任何一步都是可喜的。我个人非常喜欢 FakerFact 的做法。

我喜欢迈克解释复杂概念并将它们结合成一种易于理解的格式的能力。了解 FakerFact 在幕后是如何运作的，以及团队用来减轻偏见的不同方法，肯定会有所帮助。对于我们这些在 NLP 工作的人来说，这是一座信息的金矿。

*原载于 2019 年 4 月 11 日*[*【https://www.analyticsvidhya.com】*](https://www.analyticsvidhya.com/blog/2019/04/datahack-radio-machine-learning-identify-fake-news-mike-tamir/)*。*