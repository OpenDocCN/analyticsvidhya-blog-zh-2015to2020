<html>
<head>
<title>Training AlexNet from scratch in TensorFlow 2.1.0 for our own classification task.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为了我们自己的分类任务，在TensorFlow 2.1.0中从头开始训练AlexNet。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/alexnet-tensorflow-2-1-0-d398b7c76cf?source=collection_archive---------3-----------------------#2020-04-30">https://medium.com/analytics-vidhya/alexnet-tensorflow-2-1-0-d398b7c76cf?source=collection_archive---------3-----------------------#2020-04-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d016" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“人工智能是新的电力。”—吴恩达</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/6532afff5336807032ba3af8a83d1d0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BzZC_LWHYK1LWISMxPmXuw.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">揭秘深度学习</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="64cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi kb translated"><span class="l kc kd ke bm kf kg kh ki kj di"> H </span> <em class="jd">大家好！这是我在Medium网站上的第一篇帖子。来这里真的花了很长时间。我是一名汽车软件测试工程师，有电气工程背景。嗯，我知道你现在脑子里想的是</em> <strong class="ih hj"> <em class="jd">“他用深度学习搞什么鬼”。</em> </strong> <em class="jd">等等吧，</em> <strong class="ih hj"> <em class="jd"> </em> </strong> <em class="jd">我等会儿再回答因为先有要事。</em></p><p id="a209" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将从头开始创建AlexNet并在five Flowers数据集上训练它。本节将专门讨论在<a class="ae kk" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a> 2.1.0中创建<a class="ae kk" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>，这是一个端到端的开源机器学习平台。</p><h1 id="530e" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak"> <em class="lj">为什么选择TensorFlow 2.x？</em>T25】</strong></h1><p id="d8cc" class="pw-post-body-paragraph if ig hi ih b ii lk ik il im ll io ip iq lm is it iu ln iw ix iy lo ja jb jc hb bi translated">TensorFlow 2.x让ML应用的开发变得容易多了。通过将Keras紧密集成到TensorFlow中，缺省情况下的急切执行，以及Pythonic函数执行。</p><blockquote class="lp lq lr"><p id="0fc8" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">不像在TensorFlow 1.x中那样，您不再需要创建会话来运行计算图，而是直接查看代码的结果，而不需要创建会话。</p><p id="7c17" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">那多酷啊！</p></blockquote><h1 id="9e12" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">AlexNet</h1><p id="8e89" class="pw-post-body-paragraph if ig hi ih b ii lk ik il im ll io ip iq lm is it iu ln iw ix iy lo ja jb jc hb bi translated">AlexNet是发表在计算机视觉上的一篇有影响力的论文，采用CNN和GPU来加速深度学习。根据作者的谷歌学术个人资料，截至2020年，AlexNet的论文已被引用超过61015次。</p><p id="c265" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AlexNet是ILSRVC-2012的大赢家。该网络展示了<strong class="ih hj">使用广泛可用的游戏<strong class="ih hj">GPU在大规模数据集上快速训练大型神经网络</strong>的潜力。</strong></p><blockquote class="lp lq lr"><p id="494b" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">高计算能力和大型数据集的可用性is❤️️ <br/>耶！深度学习正在腾飞的原因之一。<br/>“打破里氏震级的地震移位！”</p></blockquote><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lv"><img src="../Images/a017f82cc5c0cc6507305937c9513c3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*kQonmTVE73r5K449TIEvyQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">研究论文中给出的AlexNet架构</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="9a30" class="lw km hi bd kn lx ly lz kr ma mb mc kv iq md me kz iu mf mg ld iy mh mi lh mj bi translated"><strong class="ak">Alex net的六大理念</strong></h2><p id="6024" class="pw-post-body-paragraph if ig hi ih b ii lk ik il im ll io ip iq lm is it iu ln iw ix iy lo ja jb jc hb bi translated"><strong class="ih hj"> 1。<em class="jd"> ReLU非线性</em>T39】</strong></p><p id="7a8a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd"> ReLU </em> </strong> <em class="jd">是所谓的不饱和激活。这意味着对于正向激活，梯度永远不会接近零，因此，训练会更快。换句话说，当激活(a)为负时ReLu(a) = 0，当激活(a)为正时ReLu(a) = a. </em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mk"><img src="../Images/32a494d390288878b22c87fa8af552b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*w48zY6o9_5W9iesSsNabmQ.gif"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><strong class="bd kn"> ReLU可视化</strong></figcaption></figure><p id="75e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd"> 2。用于训练的多个GPU</em></strong></p><p id="41c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd"> 3。局部响应归一化</em> </strong></p><p id="1459" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd"> 4。数据扩充</em> </strong></p><p id="efcd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd"> 5。测试时间数据扩充</em> </strong></p><p id="b8a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">拍摄单个测试图像的五个裁剪(4个角&amp;中心)及其水平翻转，对这10个增强图像进行预测。随后，对预测进行平均，以做出最终预测。</em></p><p id="da7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd"> 6。</em>辍学</strong></p><p id="1155" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它在训练时使用0.5的辍学。这意味着在正向传递期间，该层所有激活的50%被设置为零，并且也不参与反向传播。<strong class="ih hj">在测试过程中，没有单个神经元像实时推理中那样被丢弃</strong>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ml"><img src="../Images/24975a1db516d8072c9e426e3a14f20d.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/1*qM6ZRfezI6mVLz7B9X0LvA.gif"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">辍学者的直觉</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="4190" class="kl km hi bd kn ko mm kq kr ks mn ku kv kw mo ky kz la mp lc ld le mq lg lh li bi translated">TensorFlow实现</h1><blockquote class="lp lq lr"><p id="ec53" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">是的，终于实现了！你刚刚发现了一个对你有用的小理论。老实说，为自己工作是一种享受。人，<strong class="ih hj">就是这么回事，</strong>我们去拿吧。</p></blockquote></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="c8ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">使用环境:</em> </strong></p><p id="e201" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">编辑:<a class="ae kk" href="https://www.jetbrains.com/pycharm/" rel="noopener ugc nofollow" target="_blank">py charm IDE</a><br/><em class="jd">OS:Windows 10(64位)<br/>GPU:Nvidia GeForce GTX 1050<br/>CPU:Intel i7–8750h</em></p><p id="5807" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">培训时间:大约17分钟</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="b2e7" class="kl km hi bd kn ko mm kq kr ks mn ku kv kw mo ky kz la mp lc ld le mq lg lh li bi translated">我们在做什么？</h1><ol class=""><li id="736e" class="mr ms hi ih b ii lk im ll iq mt iu mu iy mv jc mw mx my mz bi translated">导入必要的包。</li><li id="fd56" class="mr ms hi ih b ii na im nb iq nc iu nd iy ne jc mw mx my mz bi translated">获取数据集并分析它们。</li><li id="59a1" class="mr ms hi ih b ii na im nb iq nc iu nd iy ne jc mw mx my mz bi translated">定义模型架构，耶！！！！！<strong class="ih hj"><em class="jd">AlexNet</em></strong><em class="jd">来了… </em></li><li id="3ad6" class="mr ms hi ih b ii na im nb iq nc iu nd iy ne jc mw mx my mz bi translated">为我们的深度学习模型的训练过程预处理数据集中的图像。</li><li id="45e1" class="mr ms hi ih b ii na im nb iq nc iu nd iy ne jc mw mx my mz bi translated">用损失函数和优化器对其进行编译以用于训练。</li><li id="fc82" class="mr ms hi ih b ii na im nb iq nc iu nd iy ne jc mw mx my mz bi translated">定义培训时要使用的回调。</li><li id="ae0b" class="mr ms hi ih b ii na im nb iq nc iu nd iy ne jc mw mx my mz bi translated">最后，我们训练模型并保存它。</li><li id="ee48" class="mr ms hi ih b ii na im nb iq nc iu nd iy ne jc mw mx my mz bi translated">TensorBoard.dev中训练过程和模型的可视化</li><li id="2a27" class="mr ms hi ih b ii na im nb iq nc iu nd iy ne jc mw mx my mz bi translated">对训练好的模型进行评估。</li><li id="8e65" class="mr ms hi ih b ii na im nb iq nc iu nd iy ne jc mw mx my mz bi translated">验证数据集的重要性。</li></ol><p id="65ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一步:<br/> 我将从导入必要的包开始。TensorFlow，NumPy，pathlib，Datetime。我会把版本打印出来供参考。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="nf ng l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">入门指南</figcaption></figure><pre class="jf jg jh ji fd nh ni nj nk aw nl bi"><span id="b47c" class="lw km hi ni b fi nm nn l no np">Tensor Flow Version: 2.1.0<br/>numpy Version: 1.18.2</span></pre></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="0a3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二步:</strong></p><p id="fb65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一节中，我已经指定了解压缩后的<a class="ae kk" href="https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz" rel="noopener ugc nofollow" target="_blank">数据集</a>的目录。</p><p id="e7b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I)然后打印图像总数。<br/> ii)通过读取数据集中子目录的名称，将类名打印为列表。iii)打印班级总数。</p><p id="7a43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解压缩后数据集的文件夹结构如下所示。</p><pre class="jf jg jh ji fd nh ni nj nk aw nl bi"><span id="9082" class="lw km hi ni b fi nm nn l no np">flower_photos<br/>|__daisy<br/>|__dandelion<br/>|__roses<br/>|__sunflowers<br/>|__tulips<br/>|__LICENSE.txt</span></pre><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="nf ng l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">获取数据</figcaption></figure><pre class="jf jg jh ji fd nh ni nj nk aw nl bi"><span id="f467" class="lw km hi ni b fi nm nn l no np">3670<br/>['daisy' 'dandelion' 'roses' 'sunflowers' 'tulips']<br/>5</span></pre></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="5123" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第三步:</strong></p><p id="3a6d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们定义一个<em class="jd"> AlexNet </em>的模型架构。</p><p id="40ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I)如您所见，在每个卷积层之后使用批量归一化，而不是局部响应归一化。ii)在两个完全连接的层上，没有添加脱落层，而是在注释部分给出，因此如果你愿意，你可以调整它。像步幅和内核大小这样的参数被稍微调整了一下(<em class="jd">耶！我们正在成为深度学习的实践者</em>，然而内核的数量与AlexNet保持相同。</p><blockquote class="lp lq lr"><p id="6c4b" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">我没有添加一个脱落层的原因是，有时，它在神经网络的反向传播中表现得很奇怪。</p><p id="55f6" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">使用批量标准化的好处不仅仅是减少过度拟合，例如，通过为网络优化器提供使用更高学习速率的能力来加速训练。</p><p id="2a42" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">正如吴君如解释的那样，我说的是那些<strong class="ih hj">“小小的婴儿步伐”</strong> ❤️</p></blockquote><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="nf ng l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">AlexNet架构</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="35a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第四步:</strong></p><p id="5068" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本节中，我们准备用于训练的数据，这意味着在将数据输入神经网络之前对其进行预处理。定义批次大小、高度、宽度和每个时期的步数。稍后调整大小，并根据需要使用ImageDataGenerator对图像进行预处理，这让您可以动态地完成所有工作，这是Keras的一个好礼物。</p><blockquote class="nq"><p id="705e" class="nr ns hi bd nt nu nv nw nx ny nz jc dx translated">我怎么强调ImageDataGenerator对深度学习有多有用都不为过。</p></blockquote><blockquote class="lp lq lr"><p id="7eb9" class="if ig jd ih b ii oa ik il im ob io ip ls oc is it lt od iw ix lu oe ja jb jc hb bi translated">ImageDataGenerator接受原始数据，根据我们的需要用我们给出的参数对其进行随机转换，并只返回<em class="hi">新的、转换后的数据供训练时使用。</em></p></blockquote><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="nf ng l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">为培训准备数据</figcaption></figure><pre class="jf jg jh ji fd nh ni nj nk aw nl bi"><span id="b537" class="lw km hi ni b fi nm nn l no np">Found 3670 images belonging to 5 classes.</span></pre></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="bc54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第五步:</strong></p><p id="406c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本节中，我们将使用我们准备的数据来训练我们的深度学习模型。我们指定损失函数和优化器。要了解更多关于随机梯度优化，以及它如何不同于正常梯度下降看看下面的视频。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="nf ng l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">编译和总结模型</figcaption></figure><pre class="jf jg jh ji fd nh ni nj nk aw nl bi"><span id="23e7" class="lw km hi ni b fi nm nn l no np">Model: "sequential"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d (Conv2D)              (None, 55, 55, 96)        34944     <br/>_________________________________________________________________<br/>batch_normalization (BatchNo (None, 55, 55, 96)        384       <br/>_________________________________________________________________<br/>max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         <br/>_________________________________________________________________<br/>conv2d_1 (Conv2D)            (None, 27, 27, 256)       2973952   <br/>_________________________________________________________________<br/>batch_normalization_1 (Batch (None, 27, 27, 256)       1024      <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 27, 27, 384)       885120    <br/>_________________________________________________________________<br/>batch_normalization_2 (Batch (None, 27, 27, 384)       1536      <br/>_________________________________________________________________<br/>conv2d_3 (Conv2D)            (None, 27, 27, 384)       1327488   <br/>_________________________________________________________________<br/>batch_normalization_3 (Batch (None, 27, 27, 384)       1536      <br/>_________________________________________________________________<br/>conv2d_4 (Conv2D)            (None, 27, 27, 256)       884992    <br/>_________________________________________________________________<br/>batch_normalization_4 (Batch (None, 27, 27, 256)       1024      <br/>_________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         <br/>_________________________________________________________________<br/>flatten (Flatten)            (None, 43264)             0         <br/>_________________________________________________________________<br/>dense (Dense)                (None, 4096)              177213440 <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 4096)              16781312  <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 5)                 20485     <br/>=================================================================<br/>Total params: 200,127,237<br/>Trainable params: 200,124,485<br/>Non-trainable params: 2,752<br/>_________________________________________________________________</span></pre><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="of ng l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">获得对随机梯度下降的直觉。</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="6385" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第六步:</strong></p><p id="ab4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们定义了模型训练时要使用的回调函数。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="nf ng l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">定义模型训练时要使用的回调</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="fd5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第七步:</strong></p><p id="d1af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们训练模型。值得注意的是，即使当我们指定epochs = 50时，模型也只训练了17个epochs，这是因为当达到一定程度的准确性和损失时，我们使用回调来停止训练。</p><blockquote class="lp lq lr"><p id="502d" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">很长一段时间，我都在说训练模型，嗯！那是什么意思？<br/>这意味着我们的模型是<strong class="ih hj">学习神经元的权重</strong>，以将输入映射到输出。我们正在处理的是一个监督学习问题。也就是说，我们向神经网络展示，对于这个输入，这是输出。然后，我们的模型使用输入和输出数据进行学习，优化器将尝试减少我们指定的损失。<br/>该模型可用于对我们将实时提供的图像进行预测。</p></blockquote><p id="7137" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">保存模型是很重要的，因为以后您可以使用它在任何您想要的地方部署它。我们可以使用它来部署在轻量级嵌入式设备上，如Raspberry Pi，通过将其转换为<a class="ae kk" href="https://www.tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"> TFLite </a>模型来移动设备。或者你甚至可以使用<a class="ae kk" href="https://www.tensorflow.org/js" rel="noopener ugc nofollow" target="_blank"> TensorFlow.js </a>在浏览器上部署它</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="nf ng l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">定型和保存模型。</figcaption></figure><p id="788a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我的博客越来越长了🤯😅<em class="jd"> …所以你可以在这里</em> 找到培训进度 <a class="ae kk" href="https://drive.google.com/file/d/1xwyT1GcV4P2INzvt-tP2wH8f8eW9W5sw/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <em class="jd"/></a></p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="cf58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第八步:</strong></p><p id="5ed9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TensorBoard是一个使实现透明的好工具。这样你就可以请其他的<em class="jd">深度学习者</em>来调试你的模型，或者演示为什么你的模型表现良好。<br/>您可以按照cmd中的以下命令将其上传到TensorBoard.dev并获取TensorBoard可视化的链接。</p><p id="b8bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PS:“日志”是培训期间将存储的日志目录。</p><blockquote class="lp lq lr"><p id="bede" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">关于TensorBoard有趣的事情是，你可以跟踪你的模型在训练后的表现。酷！</p></blockquote><pre class="jf jg jh ji fd nh ni nj nk aw nl bi"><span id="27b5" class="lw km hi ni b fi nm nn l no np">tensorboard dev upload --logdir logs \<br/>    --name "AlexNet TensorFlow 2.1.0" \                               <br/>    --description "AlexNet Architecture Implementation in TensorFlow 2.1.0 from scratch with list of callbacks for stopping training when the required metrics are met. Callbacks are also used for Tensorboard Visuals."</span></pre><p id="9fe5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里可以看到张量板可视化<a class="ae kk" href="https://tensorboard.dev/experiment/xh8yDX2kR2SvPZgIVqIqNg/" rel="noopener ugc nofollow" target="_blank"><em class="jd"/></a><em class="jd">。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es og"><img src="../Images/3f1a45a438f4071a7e6596d96e8e1f71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AWzCt5iTICD5QJ50sHLbXA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><strong class="bd kn">精度</strong> (y轴)对<strong class="bd kn">时期</strong> (x轴)和<strong class="bd kn">损耗</strong> (y轴)对<strong class="bd kn">时期</strong> (x轴)的曲线图</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es oh"><img src="../Images/abc661b4874371c24f7df63a4302a33d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BOp-7uNBpHGV9L9lyck_3w.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">张量板上的模型图</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="b28f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第九步:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es oi"><img src="../Images/c19d611ab31311184e6bcc5f430fb29b.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/1*SqpTVIO5ZCNxj6JESE0tnw.gif"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">示例:神经网络识别<a class="ae kk" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">手写数字</a></figcaption></figure><p id="ca43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本节中，我们将评估模型性能。尽管我可以在训练文件本身中完成，但我是在一个单独的文件<strong class="ih hj">中完成的，只是为了让您知道我们可以在以后使用保存的模型对实时数据进行推断或评估。<br/> </strong>我在<a class="ae kk" href="https://www.google.com/imghp?hl=en" rel="noopener ugc nofollow" target="_blank">谷歌图片</a>为5个班级的每一个班级随机下载了10张图片(总共50张)。将它存储在与训练数据集相同的目录结构中，以便使用ImageDataGenerator进行评估。</p><pre class="jf jg jh ji fd nh ni nj nk aw nl bi"><span id="5032" class="lw km hi ni b fi nm nn l no np">Test_set<br/>|__daisy<br/>|__dandelion<br/>|__roses<br/>|__sunflowers<br/>|__tulips</span></pre><p id="104d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">代码与模型训练中已经解释过的代码相同。但不同的是，我们加载的是一个已保存的模型。后来，使用我们从网上获得的测试数据来做推断，以找出我们的模型在<strong class="ih hj">看不见的数据上表现如何。</strong></p><p id="96a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后打印精度。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="nf ng l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">对训练模型的评估</figcaption></figure><pre class="jf jg jh ji fd nh ni nj nk aw nl bi"><span id="692a" class="lw km hi ni b fi nm nn l no np">48<br/>['daisy' 'dandelion' 'roses' 'sunflowers' 'tulips']<br/>5<br/>Found 50 images belonging to 5 classes.</span><span id="6ea5" class="lw km hi ni b fi oj nn l no np">Model: "sequential"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d (Conv2D)              (None, 55, 55, 96)        34944     <br/>_________________________________________________________________<br/>batch_normalization (BatchNo (None, 55, 55, 96)        384       <br/>_________________________________________________________________<br/>max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         <br/>_________________________________________________________________<br/>conv2d_1 (Conv2D)            (None, 27, 27, 256)       2973952   <br/>_________________________________________________________________<br/>batch_normalization_1 (Batch (None, 27, 27, 256)       1024      <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 27, 27, 384)       885120    <br/>_________________________________________________________________<br/>batch_normalization_2 (Batch (None, 27, 27, 384)       1536      <br/>_________________________________________________________________<br/>conv2d_3 (Conv2D)            (None, 27, 27, 384)       1327488   <br/>_________________________________________________________________<br/>batch_normalization_3 (Batch (None, 27, 27, 384)       1536      <br/>_________________________________________________________________<br/>conv2d_4 (Conv2D)            (None, 27, 27, 256)       884992    <br/>_________________________________________________________________<br/>batch_normalization_4 (Batch (None, 27, 27, 256)       1024      <br/>_________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         <br/>_________________________________________________________________<br/>flatten (Flatten)            (None, 43264)             0         <br/>_________________________________________________________________<br/>dense (Dense)                (None, 4096)              177213440 <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 4096)              16781312  <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 5)                 20485     <br/>=================================================================<br/>Total params: 200,127,237<br/>Trainable params: 200,124,485<br/>Non-trainable params: 2,752<br/>_________________________________________________________________</span><span id="c511" class="lw km hi ni b fi oj nn l no np">1/2 [==============&gt;...............] - ETA: 3s - loss: 1.4212 - accuracy: 0.7188<br/>2/2 [==============================] - 5s 2s/step - loss: 1.1020 - accuracy: 0.7000<br/>accuracy:70.00%</span></pre><p id="c241" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">万岁！<strong class="ih hj"> 70%精度</strong>。对于一个在训练时甚至没有使用验证集的模型来说，这是公平的。嗯！对于一个模型来说，通过让它对没有接触到的数据进行更好的归纳，它有可能在看不见的数据上表现得更好。</p><blockquote class="nq"><p id="f3cd" class="nr ns hi bd nt nu nv nw nx ny nz jc dx translated">然而，我们做了很好的工作，为从网上随机下载的花卉图片建立了5类分类模型。T12】</p></blockquote></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="7d9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第十步:</strong></p><blockquote class="lp lq lr"><p id="1ffd" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">我们的模型可能对训练数据有一点过度拟合。如果它在测试数据上表现不好。因此，我们需要在训练时使用验证数据，这样我们就可以轻松地调试我们的模型。我们还应该考虑调整网络的参数和超参数。</p></blockquote><p id="9f48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以在ImageDataGenerator中指定validation_split，以使用可用数据的一部分作为验证集。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="0c67" class="lw km hi bd kn lx ly lz kr ma mb mc kv iq md me kz iu mf mg ld iy mh mi lh mj bi translated">参考资料:</h2><blockquote class="lp lq lr"><p id="e5d0" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">💭“冬天来了。”</p></blockquote><p id="6e3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">链接到花卉数据集是<a class="ae kk" href="https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz" rel="noopener ugc nofollow" target="_blank">这里</a>。<br/>此处为<a class="ae kk" href="https://drive.google.com/file/d/1r1wMFZ6khj11a5WppqD7U-UsHyuL5EQW/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">到随机下载的测试图像数据集的链接。<br/>链接到保存的模型是</a><a class="ae kk" href="https://drive.google.com/file/d/1qecUu7ptWbPvJo6NM_OyVBbyTeVnAVs0/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里的</a>。<br/>链接到仓库是<a class="ae kk" href="https://github.com/PraveenKumar-Rajendran/AlexNet_TF2.1.0" rel="noopener ugc nofollow" target="_blank">这里是</a>。<br/>链接到AlexNet的论文是<a class="ae kk" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="ea92" class="kl km hi bd kn ko mm kq kr ks mn ku kv kw mo ky kz la mp lc ld le mq lg lh li bi translated">完成事情</h1><blockquote class="lp lq lr"><p id="ba3b" class="if ig jd ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">大多数读者没能坚持到博客结束，但你做到了，因为你是特别的，不会放弃阅读。</p></blockquote><p id="ee6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望我教会了你一些东西。如果你觉得这篇文章很有用，那么<strong class="ih hj">请鼓掌</strong>并拿着它一会儿，以便我的博客能更好地接触到需要它的人。<br/>如果您有任何疑问、澄清、改进建议，请在LinkedIn上联系我，并在GitHub上提出问题。</p><p id="7b88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">阿哈！我差点忘了回答你一开始就想到的问题。没问题，我明白了！嗯，我的职业是软件测试员，但这并不能阻止我做我想做的事情。</p><blockquote class="nq"><p id="2934" class="nr ns hi bd nt nu nv nw nx ny nz jc dx translated">"当某件事足够重要时，即使机会对你不利，你也要去做。"——埃隆·马斯克</p></blockquote></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><div class="jf jg jh ji fd ok"><a href="https://praveenkumar-rajendran.github.io/" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab dw"><div class="om ab on cl cj oo"><h2 class="bd hj fi z dy op ea eb oq ed ef hh bi translated">普拉文作品集</h2><div class="or l"><h3 class="bd b fi z dy op ea eb oq ed ef dx translated">写一些我喜欢的人是我不经意的事情，那时他们都很矮。希望能进化一下。它…</h3></div><div class="os l"><p class="bd b fp z dy op ea eb oq ed ef dx translated">praveenkumar-raje ndran . github . io</p></div></div></div></a></div></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><div class="jf jg jh ji fd ok"><a href="https://www.linkedin.com/in/praveenkumar-rajendran/" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab dw"><div class="om ab on cl cj oo"><h2 class="bd hj fi z dy op ea eb oq ed ef hh bi translated">Praveenkumar Rajendran -汽车嵌入式软件测试工程师- SL公司| LinkedIn</h2><div class="or l"><h3 class="bd b fi z dy op ea eb oq ed ef dx translated">具有电气工程背景的热情的学习者和工程师。外部照明软件测试仪</h3></div><div class="os l"><p class="bd b fp z dy op ea eb oq ed ef dx translated">www.linkedin.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy jo ok"/></div></div></a></div></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><div class="jf jg jh ji fd ok"><a href="https://github.com/PraveenKumar-Rajendran" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab dw"><div class="om ab on cl cj oo"><h2 class="bd hj fi z dy op ea eb oq ed ef hh bi translated">PraveenKumar-Rajendran -概述</h2><div class="or l"><h3 class="bd b fi z dy op ea eb oq ed ef dx translated">在GitHub上注册你自己的个人资料，这是托管代码、管理项目和构建软件的最佳地方…</h3></div><div class="os l"><p class="bd b fp z dy op ea eb oq ed ef dx translated">github.com</p></div></div><div class="ot l"><div class="oz l ov ow ox ot oy jo ok"/></div></div></a></div></div></div>    
</body>
</html>