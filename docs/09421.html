<html>
<head>
<title>The Art of Transfer Learning (Part-II)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">迁移学习的艺术(下)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/the-art-of-transfer-learning-part-ii-7bc4370e9b8f?source=collection_archive---------19-----------------------#2020-09-05">https://medium.com/analytics-vidhya/the-art-of-transfer-learning-part-ii-7bc4370e9b8f?source=collection_archive---------19-----------------------#2020-09-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/81ae043ec9961ef698826c5ff0daa057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*044NbjqCaxiCjXt-MAWyhA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">布鲁斯·蒂曼纳在<a class="ae iu" href="https://unsplash.com/images/nature?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="61ea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">各位读者好，很高兴看到大家回来，今天的博文是我之前关于迁移学习的博文的第二部分，如果你错过了，我建议你浏览一下，你可以点击下面的链接<a class="ae iu" rel="noopener" href="/@hd150295/the-art-of-transfer-learning-e6aea8fc0b8c"> <strong class="ix hj"> <em class="jt">这里</em> </strong> </a>。在本帖中，我将尝试在<a class="ae iu" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>和python编程语言中实现第一种迁移学习技术，我在之前的博客中解释过这种技术是<strong class="ix hj"> <em class="jt">“网络作为任意特征提取器”</em> </strong>。</p><p id="f2b0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">完成本博客后，您将能够实现:</p><ul class=""><li id="36a2" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><strong class="ix hj"> <em class="jt">将要素写入HDF5数据集格式的自定义类。</em>T19】</strong></li><li id="52e3" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><strong class="ix hj"> <em class="jt">如何从不同的输入图像数据集中提取特征，这些数据来自一个预先训练好的模型，而这个模型最初并没有被训练过。</em> </strong></li><li id="303f" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><strong class="ix hj"> <em class="jt">在提取的特征上训练图像分类器，并显示分类器在不同类别上的性能。</em> </strong></li></ul><p id="029d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以让我们开始吧，如果你想跳过阅读并想要代码，那么你可以按照这个<a class="ae iu" href="https://github.com/harishdasari1595/Personal_projects/tree/master/transfer-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> <em class="jt">链接</em> </strong> </a>。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ki"><img src="../Images/414fa2bc85a098076695c4d35a6860da.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*PZLPS-m1_iGNudZPyfhewA.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fgiphy.com%2Fexplore%2Fkpop-starts&amp;psig=AOvVaw1CylXNLx0YkuCe1LXOJX70&amp;ust=1599305200099000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCKD-x6Cwz-sCFQAAAAAdAAAAABAQ" rel="noopener ugc nofollow" target="_blank">谷歌gif图片</a></figcaption></figure><p id="d366" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下项目的目录结构是:</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/96536b86a229fe4afd10441c9ff61fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*4qm06i4wy3PYp4wJ5YNVxQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">外部目录结构。</figcaption></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ko"><img src="../Images/4e83c4006b91984ad436eaa507e80176.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*G2o5eRPGY1_TyNJm_nQZlg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">内部目录结构</figcaption></figure><p id="e22f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面两张图片中，你可以看到我们的特征提取项目的目录结构，我们将在这个博客中探索每个文件。</p><ol class=""><li id="fd32" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js kp ka kb kc bi translated"><strong class="ix hj">数据集集合:</strong></li></ol><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/1f8784a1e82dd9f27f6cfb15251e86ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jhmciuhxy9xg6JRkTtQH_w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自动物数据集的猫、狗和熊猫样本图像。</figcaption></figure><p id="f277" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了解决任何与人工智能相关的任务，我们首先必须收集相关的数据，因此创建一个名为Dataset的新文件夹，其中我使用了Kaggle的<a class="ae iu" href="https://www.kaggle.com/ashishsaxena2209/animal-image-datasetdog-cat-and-panda" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> <em class="jt">动物数据集</em> </strong> </a>，其中有三个类，如<strong class="ix hj"> <em class="jt">狗</em> </strong>、<strong class="ix hj"> <em class="jt">猫、</em> </strong>和<strong class="ix hj"> <em class="jt">熊猫。</em> </strong>我将数据集保存在一个名为animals的文件夹下，您可以在上面的图像中看到，它还有一个名为hdf5的文件夹，其中有各自的功能。hdf5文件，这样您可以保存多个类别数据集。</p><p id="6e7e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 2。HDF5数据集创建脚本:</strong></p><p id="016a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在有一个utils文件夹，其中将包含项目所需的所有实用程序文件。在DatasetWriter文件夹下有我们的第一个名为<strong class="ix hj"><em class="jt">hdf 5 DatasetWriter . py</em></strong>script的脚本。选择一个代码编辑器，创建一个名为HDF5DatasetWriter.py或任何相关内容的脚本。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kr"><img src="../Images/1ecf23fb723c17d7453e4bcf7d88e7fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IwDPzbj-E3zPpwNvOyuhzA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Hdf5DatasetWriter.py代码片段2.1</figcaption></figure><p id="81d1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在整个博客中，我将尝试解释代码的主旨和每个方法或函数的核心功能，因为逐行代码解释会非常长，您很容易迷路，所以请耐心听我说一会儿。从上面的代码片段可以看出，我基本上创建了一个名为HDF5DatasetWriter的类，构造函数接受四个参数，其中两个是可选的。</p><p id="19b7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">dims:</strong>dims参数控制我们将存储在数据集中的数据的<em class="jt">尺寸</em>或<em class="jt">形状</em>。把dims想象成。NumPy数组的形状。如果我们存储28 ^ 28 = 784<a class="ae iu" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"><em class="jt"/></strong></a><strong class="ix hj"><em class="jt"/></strong>数据集的(展平的)原始像素亮度，那么dims=(70000，784)因为在MNIST有70，000个例子，每个例子的维数为784。在未来的脚本中，我们将使用VGG16网络进行特征提取，获取池图层的最终输出。展平后，输出图层形状将为(512 X 7 X 7) = 25，088特征向量。dims = (N，25088)其中N是我们数据集中的图像总数。</p><p id="a98e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> Outputpath: </strong>这是一个必需的参数，指定我们的输出HDF5文件在磁盘上的存储路径。</p><p id="896d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> dataKey: </strong>它是一个可选参数，指定HDF5文件的名称，默认为“images”，因为我们主要只处理图像。</p><p id="c6b4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">bufSize:</strong>另一个可选参数bufSize控制我们的内存缓冲区的大小，我们默认为1000个特征向量/图像。一旦达到bufSize，我们将把缓冲区刷新到HDF5数据集。</p><p id="f7e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，我们正在使用<strong class="ix hj"> <em class="jt">数据键</em> </strong>创建一个数据库，并创建两个数据集，一个用于存储图像/特征，另一个用于存储类别标签，然后初始化缓冲区。</p><p id="6a05" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">add方法:add方法需要两个参数:我们将要添加到数据集的行，以及它们对应的类标签。行和标签都被添加到它们各自的缓冲区，一旦缓冲区满了，就调用flush方法将缓冲区写入文件并重置它们。</p><p id="625a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">刷新方法:</strong>刷新方法用于将当前索引记录到下一个可用索引中，我们可以在该索引中存储数据(不覆盖现有数据)。它还应用NumPy数组切片来存储缓冲区中的数据和标签，然后重置缓冲区。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/3e0ddc19aee8b75fd4296554e77af953.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*s5VnZB05zMewvSPD3DxorQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">Hdf5DatasetWriter.py代码片段2.2</figcaption></figure><p id="492a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的代码片段中，还剩下两个方法，它们是:</p><p id="7b2a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">storeclassplabels方法:</strong>在调用此方法<strong class="ix hj"> </strong>时，它<strong class="ix hj"> </strong>会将类标签的原始字符串名称存储在一个单独的数据集中</p><p id="55f0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">关闭方法:</strong>该<strong class="ix hj"> </strong>方法用于检查缓冲区中其他需要刷新到磁盘的条目，然后关闭数据库。</p><p id="c271" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如你所看到的，这些方法不需要任何花哨的深度学习库，也没有执行任何深度学习特定的功能，它主要是一个以HDF5数据格式存储数据的简单类。</p><p id="c56c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 3。特征提取过程:</strong></p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/f79b8e75c2e8fb76fdfa7fbef591d1e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oSqkgmRIthQ3KyBb_0M95g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">深度学习系统如何建立对图像的理解的内部表示，从第一层的边缘和纹理到更深层的图案、零件和对象</figcaption></figure><p id="aca5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们的HDF5DatasetWriter已经实现，我们可以继续使用预训练的卷积神经网络实际提取特征。启动编辑器，定义一个名为feature _ extractor . py&amp;follow me的python脚本</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ku"><img src="../Images/da70cc37c58d932db3f0ef57dfdc90be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*CW2AOyQdQOulWOGD-_q7aw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">3.1 feature_extractor.py代码片段</figcaption></figure><p id="fdb7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的代码片段中，我首先导入了必要的库，然后声明了argparse类的一个对象，用于将不同的参数作为输入数据集的路径、HDF5文件的路径、图像的批处理大小以及前面脚本的缓冲区大小的输入。在随机排列一系列图像之后，这使得训练和测试分割变得容易。类别标签是从图像路径中提取的，例如，如果从混洗中随机选择一张猫图像，那么它的路径看起来将是这样的<strong class="ix hj"><em class="jt">" Dataset \ animals \ cats \ cats _ 00026 "</em></strong>，因此由<strong class="ix hj">"</strong>分隔的倒数第二个字符，即"<strong class="ix hj"> <em class="jt"> cats" </em> </strong>，将被编码为整数<strong class="ix hj"> <em class="jt">(我们将在训练过程中执行一次热编码)</em> </strong> <em class="jt"> </em>，使用</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/cee1b641232418306d58c75dbea1f366.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WNK6Wlz0KP19TrIGbwb8Cw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">3.2 Feature_extractor.py代码片段</figcaption></figure><p id="1e9d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，在排列了来自Keras库的标签之后，我们将首先加载预训练模型VGG16，直到最终的<strong class="ix hj"> <em class="jt">池</em> </strong>层，忽略最终的<strong class="ix hj"> <em class="jt"> FC </em> </strong>层，方法是写入下面的行<strong class="ix hj"><em class="jt">“vgg 16(weights = " imagenet "，include_top=False)”。</em> </strong>这里取imagenet权重，所以我们做的和我之前的<a class="ae iu" rel="noopener" href="/@hd150295/the-art-of-transfer-learning-e6aea8fc0b8c#2c01-2fa448dbc886"> <strong class="ix hj"> <em class="jt">博客</em></strong></a><strong class="ix hj"><em class="jt"/></strong>中解释的完全一样，会把<strong class="ix hj"> VGG16 </strong>当作任意的特征提取器。名为<strong class="ix hj"> <em class="jt"> "dataset" </em> </strong>的HDF5DatasetWriter类对象是通过将参数值设置为<strong class="ix hj"><em class="jt">"(dims =(len(image paths)，512 * 7 * 7)，args["output"]，dataKey="features "，bufSize=args["buffer_size"])来创建的。</em> </strong>关于各参数的深入解释，请参考HDF5DatasetWriter代码解释部分。根据标签编码器的类标签的字符串名存储在<strong class="ix hj"> <em class="jt">【数据集】</em> </strong>对象中。</p><p id="33f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在是执行实际特征提取的时候了:从L <strong class="ix hj"> ines </strong> <strong class="ix hj"> 57 </strong>到<strong class="ix hj"> 77 </strong>这基本上是一个外循环中的孪生for循环在外for循环中，我们开始以批量大小循环我们的图像路径。<strong class="ix hj">第59行和第60行</strong>提取相应批次的图像路径和标签，而<strong class="ix hj">第61行</strong>初始化一个列表，以存储将要加载并送入VGG16的图像。为特征提取准备图像与通过CNN为分类准备图像完全相同:在内部for循环中，我们遍历批处理中的每个图像路径。每个图像从磁盘加载并转换成Keras兼容的数组(<strong class="ix hj">行67和68 </strong>)。然后，我们对第<strong class="ix hj">行第73和74 </strong>行的图像进行预处理，随后将其添加到批量图像中(<strong class="ix hj">行第77 </strong>)。为了获得批量图像中图像的特征向量，我们需要做的就是调用。模型的预测方法。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/f1dacf9d4727431ce2231294a56d6938.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*ZFRHhU1UqvmEPHD1s3WMAQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">3.3 feature_extractor.py代码片段</figcaption></figure><p id="cfb2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们使用。第81 行的NumPy的vstack方法“垂直堆叠”我们的图像，使它们具有形状(N，224，224，3 ),其中N是批次的大小。通过我们的网络传递batchImages产生了我们实际的特征向量——记住，我们在VGG16的头部切断了完全连接的层，所以现在我们只剩下最后的max-pooling操作之后的值(<strong class="ix hj">第82行</strong>)。但是，池的输出具有(N，512，7，7)的形状，这意味着有512个过滤器，每个大小为7 X 7。为了将这些值作为一个特征向量，我们需要将它们展平成一个形状为(N，25088)的数组，这正是<strong class="ix hj">行86 </strong>所完成的。<strong class="ix hj">第89行</strong>将我们的特性和批处理标签添加到我们的HDF5数据集，最后几行处理关闭我们的HDF5数据集。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/f2180a45ecf0ea3c26f3c0958d9a8b00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NRy0LU7VCJ2TVfwe9rFBrA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">3.4 CMD _输出快照。</figcaption></figure><p id="2aab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的代码片段中，feature extractor.py的用法命令显示为"<strong class="ix hj"><em class="jt">python feature _ extractor . py-d Dataset \ animals-o Dataset \ animals \ hdf "</em></strong>，这是我们脚本的名称，后面跟有输入参数，如<strong class="ix hj"> <em class="jt"> -d "输入数据集的路径"，"-o输出路径，用于以HDF5格式存储提取的要素。"。</em> </strong>请忽略下面的警告，我们观察这个"<strong class="ix hj"> <em class="jt">提取特征:100% | # # # # # # # # # # # # |时间:0:04:46" </em> </strong>你可以在上面看到一个进度条，它给出了提取特征的进度，我花了大约4分46秒从所有3000张图像中提取特征，如果你有GPU，它会变得更快。</p><p id="f54c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> 4.1在提取的特征上训练一个分类器。</em> </strong></p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/1de9f144e4858b65b2edc98640f29e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*9sjVBvY647cQCRJpmaEm-g.gif"/></div></figure><p id="637b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于我们已经使用预训练的CNN模型成功地从我们的目标数据集提取了特征，让我们看看<strong class="ix hj"> <em class="jt">如何区分</em> </strong>这些特征，<em class="jt">尤其是</em>鉴于VGG16是在ImageNet和<em class="jt">而不是</em>动物上训练的。因此，让我们看看线性模型在这些提取的特征之上会有多好，以及我们在模型精确度方面能达到多高？任何超过90%的都是非常好的，所以让我们创建一个名为training.py的新python文件，并开始编写下面的代码。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/fc79acdf5c22a11fd94386bd2b4bceb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LU-xcUIXae5Tzmh90n7FCA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">4.1 training.py代码片段。</figcaption></figure><p id="ee83" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的代码片段中，您可以看到从<strong class="ix hj"> <em class="jt">第2–7行</em> </strong>所需的python包在脚本开始时被导入，我们使用一个<strong class="ix hj"> <em class="jt"> sklearn </em> </strong>包来导入<a class="ae iu" href="https://en.wikipedia.org/wiki/Logistic_regression#:~:text=Logistic%20regression%20is%20a%20statistical,a%20form%20of%20binary%20regression)." rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"><em class="jt">LogisticRegression</em></strong></a><strong class="ix hj"><em class="jt"/></strong>作为我们的图像分类器的线性模型，该分类器将对3种类型的类标签进行分类，即<strong class="ix hj">(狗、猫、猫<strong class="ix hj"> <em class="jt"> GridSearchCV </em> </strong>用于调优超参数<strong class="ix hj"> <em class="jt">分类报告</em> </strong>用于显示我们新分类器在各种指标方面的报告，如<strong class="ix hj">精度</strong>，R <strong class="ix hj"> ecall，</strong>和<strong class="ix hj"> <em class="jt">精度。</em> </strong>我们将在培训后使用<strong class="ix hj"> <em class="jt"> pickle </em> </strong>将我们的逻辑回归模型序列化到磁盘中。最后，将使用<strong class="ix hj"> <em class="jt"> h5py </em> </strong>，这样我们就可以与我们的HDF5要素数据集进行交互。</strong></p><p id="c13a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们声明参数解析器，用于从用户<strong class="ix hj"> <em class="jt"> -d </em> </strong>获取输入:包含提取的特性和类标签的HDF5数据集的路径</p><p id="e9e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> -m: </em> </strong>存储线性模型输出模型文件的路径</p><p id="8468" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> -j: </em> </strong>用于选择同时作业的数量，同时使用网格搜索技术调整线性模型的超参数。</p><p id="d2f9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在之前的脚本中，在创建HDF5特征数据库时，我们有意打乱了图像路径，原因已在第20至21行<strong class="ix hj"><em class="jt"/></strong>中阐明。鉴于我们的数据集太大，无法放入内存，我们需要一种有效的方法来确定我们的训练和测试分割。由于我们知道HDF5数据集中有多少条目(并且我们知道我们希望将75%的数据用于训练，25%用于评估)，我们可以简单地将75%的索引I计算到数据库中。之前的任何数据<em class="jt">索引<strong class="ix hj"> i </strong>都被认为是训练数据<strong class="ix hj"> i </strong>之后的任何数据都是测试数据。</em></p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es la"><img src="../Images/f211bef67ba37b094951842941d4ac16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*MNx9L4Q--uDD6kS_jT34dQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">4.2 training.py代码片段。</figcaption></figure><p id="cdd1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">既然我们已经有了训练和测试分割，现在我们可以通过使用<strong class="ix hj"> <em class="jt"> GridSearchCV </em> </strong>从调整超参数“<strong class="ix hj"> <em class="jt"> C </em> </strong>”开始训练我们的逻辑回归分类器，在这里您还可以指定各种参数来有效训练我们的模型。的。拟合模型被称为采用(X，Y)的模型，因此这里X是我们的<strong class="ix hj"><em class="jt">db[特征][:i] </em> </strong> <em class="jt">，Y是我们的类标签</em><strong class="ix hj"><em class="jt">db[标签][:I]</em>【T27]，一旦找到最佳超参数，我们就对来自<strong class="ix hj"> <em class="jt">行32到34的测试数据评估分类器。</em> </strong>注意这里我们的<em class="jt">测试数据</em>和<em class="jt">测试标签</em>是通过数组切片访问的:</strong></p><p id="0fcb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">索引I是我们测试集的一部分。即使我们的HDF5数据集驻留在磁盘上(并且太大而不适合内存)，我们仍然可以将其视为NumPy数组，这是将HDF5和h5py一起用于深度学习和机器学习任务的<em class="jt">巨大</em>优势之一。最后，我们将LogisticRegression模型保存到磁盘并关闭数据库。</p><p id="a27d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> 4.2在动物数据集上训练分类器:</em> </strong></p><p id="daae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要在通过动物数据集上的VGG16网络提取的特征上训练逻辑回归分类器，只需在输出快照中执行以下命令。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lb"><img src="../Images/de0448ddfce87db7bd84ea2c53d2b540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ij3bk83zmMtnW12WkjlmLw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">4 . 2 . 1 training . py的输出快照</figcaption></figure><p id="8d39" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的快照中，您可以看到我们得到的最佳超参数是<strong class="ix hj"><em class="jt">【C】:10.0，</em> </strong>，在对测试数据进行模型评估后，我们得到了宏观和加权平均准确度、精确度、召回率，f1值约为98%，这对于一个不费力的图像分类器来说是非常好的。</p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><p id="752f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以从我的Github资源库中找到博客中使用的代码:<a class="ae iu" href="https://github.com/harishdasari1595/Personal_projects/tree/master/transfer-learning" rel="noopener ugc nofollow" target="_blank">https://Github . com/harishdasari 1595/Personal _ projects/tree/master/transfer-learning</a></p><h1 id="9a0d" class="lj lk hi bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak"> <em class="mh">概要:</em> </strong></h1><ol class=""><li id="9c1e" class="ju jv hi ix b iy mi jc mj jg mk jk ml jo mm js kp ka kb kc bi translated"><strong class="ix hj">我们可以使用两个<em class="jt">extract _ features . py</em>&amp;<em class="jt">train _ model . py</em>来基于从预训练的CNN提取的特征快速构建鲁棒的图像分类器。</strong></li><li id="7f0b" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js kp ka kb kc bi translated"><strong class="ix hj">显然，VGG等网络能够执行迁移学习，将它们的区别特征编码到输出激活中，我们可以使用这些输出激活来训练我们自己的自定义图像分类器。</strong></li><li id="a6d5" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js kp ka kb kc bi translated"><strong class="ix hj">在这里，我们严格关注迁移学习的特征提取能力，证明深度预训练的CNN能够执行强大的特征提取机器，甚至比手工设计的算法更强大，如</strong><a class="ae iu" href="https://www.learnopencv.com/histogram-of-oriented-gradients/" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"><em class="jt">HOG</em></strong></a><strong class="ix hj"/><a class="ae iu" rel="noopener" href="/data-breach/introduction-to-sift-scale-invariant-feature-transform-65d7f3a72d40"><strong class="ix hj"><em class="jt">SIFT</em></strong></a><strong class="ix hj"/><a class="ae iu" href="#_bookmark216" rel="noopener ugc nofollow"><strong class="ix hj"/></a><strong class="ix hj">和</strong> <a class="ae iu" href="https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">T47】</strong></a></li><li id="fe4b" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js kp ka kb kc bi translated"><strong class="ix hj">每当用深度学习和卷积神经网络处理一个新问题时，总是要考虑应用特征提取是否会获得合理的准确性——如果是这样，你可以完全跳过网络训练过程，为你节省大量的时间、精力和头痛。</strong></li></ol><h1 id="0006" class="lj lk hi bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak"> <em class="mh">参考文献:</em> </strong></h1><div class="mn mo ez fb mp mq"><a href="https://www.kaggle.com/ashishsaxena2209/animal-image-datasetdog-cat-and-panda" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hj fi z dy mv ea eb mw ed ef hh bi translated">动物图像数据集(狗、猫和熊猫)</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">图像分类实践数据集</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">www.kaggle.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne io mq"/></div></div></a></div><div class="mn mo ez fb mp mq"><a href="https://distill.pub/2017/feature-visualization/" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hj fi z dy mv ea eb mw ed ef hh bi translated">特征可视化</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">越来越多的人意识到神经网络需要能够被人类理解。神经网络领域…</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">蒸馏. pub</p></div></div><div class="mz l"><div class="nf l nb nc nd mz ne io mq"/></div></div></a></div><div class="mn mo ez fb mp mq"><a href="https://amethix.com/deep-feature-extraction-and-transfer-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hj fi z dy mv ea eb mw ed ef hh bi translated">3深度特征提取和迁移学习的优势</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">没有真正的新闻表明特征提取[1]是任何机器学习的基础步骤…</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">amethix.com</p></div></div><div class="mz l"><div class="ng l nb nc nd mz ne io mq"/></div></div></a></div></div></div>    
</body>
</html>