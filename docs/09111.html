<html>
<head>
<title>Neural network from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从无到有的神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/neural-network-from-scratch-ed75e5e14cd?source=collection_archive---------23-----------------------#2020-08-25">https://medium.com/analytics-vidhya/neural-network-from-scratch-ed75e5e14cd?source=collection_archive---------23-----------------------#2020-08-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ef050fff1ee2c7b266165eef61a19a0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AoAZVFtEJP7nbMAh"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@nezelenoe?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Artyom Kim </a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="8db5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated">owadays神经网络在科技领域是一个响当当的名字，就像达斯·维德在《星球大战》中一样。许多技术人员确实钦佩神经网络的美丽，但同时又把它当作一个黑匣子。东西进进出出。所以我决定写这篇文章来解释神经网络背后的直觉、理论和数学结构，以便更好地理解。</p><p id="4d2c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">神经网络背后的想法是人类大脑内部神经元的映射。人类大脑有大量的神经元(根据最近的一项研究，有860亿个)，用于执行各种各样的任务。大脑有三个主要部分:大脑、小脑和脑干。</p><p id="1e32" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">大脑:</strong> <em class="kc">是大脑最大的部分，由左右半球组成。它执行更高级的功能，如解释触觉、视觉和听觉、语言、推理、情感、学习和对运动的精细控制。</em></p><p id="3d10" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">小脑:</strong> <em class="kc">位于大脑下方。它的功能是协调肌肉运动，保持姿势和平衡。</em></p><p id="6471" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">脑干:</strong> <em class="kc">作为连接大脑和小脑与脊髓的中继中枢。它执行许多自动功能，如呼吸、心率、体温、觉醒和睡眠周期以及吞咽等。</em></p><p id="5970" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于大多数研究来说，<strong class="ix hj">Why</strong>一直是<strong class="ix hj">T21的一个重要因素，神经网络也是如此。如果我们的大脑中有一张神经元地图，那么我们为什么不能用数字方式实现它呢？这导致了1944年芝加哥大学的两位研究人员Warren McCullough和Walter Pitts创立了神经网络，他们于1952年搬到麻省理工学院，成为第一个认知科学系的创始成员。</strong></p><p id="8d6d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从这里，我们将深入研究这些网络背后的理论和数学。</p><h1 id="10b1" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">什么是神经网络？</h1><p id="f1dd" class="pw-post-body-paragraph iv iw hi ix b iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">有很多定义强调数字神经元(感知器)与人类神经元的相似性，所以我不会去那里，我会尽量保持它的新鲜和更数学化。</p><p id="eaf6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">神经网络是一组算法，它将一个数学量作为输入，对其进行处理并产生输出，同时不断更新权重和偏差(分别在神经元之间和与神经元一起),以降低预测的不确定性。</p><h1 id="311e" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">人工神经网络的应用:</h1><ol class=""><li id="6118" class="lg lh hi ix b iy lb jc lc jg li jk lj jo lk js ll lm ln lo bi translated">异常检测</li><li id="23ec" class="lg lh hi ix b iy lp jc lq jg lr jk ls jo lt js ll lm ln lo bi translated">语音识别</li><li id="e093" class="lg lh hi ix b iy lp jc lq jg lr jk ls jo lt js ll lm ln lo bi translated">数据分类</li><li id="3956" class="lg lh hi ix b iy lp jc lq jg lr jk ls jo lt js ll lm ln lo bi translated">时间序列分析</li><li id="9989" class="lg lh hi ix b iy lp jc lq jg lr jk ls jo lt js ll lm ln lo bi translated">计算机视觉</li><li id="bb2b" class="lg lh hi ix b iy lp jc lq jg lr jk ls jo lt js ll lm ln lo bi translated">还有很多。</li></ol><h1 id="f723" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">神经网络的数学结构:</h1><figure class="lv lw lx ly fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/b42145744aae4ba5ab33341c9e78f053.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*qcqm1_dqyuRdfEPQGWMQcA.jpeg"/></div></figure><p id="4cc7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">像任何神经元一样，神经网络分为3个阶段:输入阶段、处理阶段和输出阶段。</p><p id="f8e8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">感知器</strong>:感知器是一个没有任何隐藏层的神经网络。感知器只有一个输入层和一个输出层。</p><p id="7834" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个网络有一个输入层，两个隐藏层和一个输出层。输入层包含5个感知器，隐藏层有5个(3+2)感知器，输出层有1个感知器。</p><p id="f8f0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">一个神经网络由以下组件组成:</strong></p><ul class=""><li id="f4d5" class="lg lh hi ix b iy iz jc jd jg lz jk ma jo mb js mc lm ln lo bi translated">一个输入层，<em class="kc"> x </em></li><li id="f926" class="lg lh hi ix b iy lp jc lq jg lr jk ls jo lt js mc lm ln lo bi translated">任意数量的隐藏层(本例中为2层)</li><li id="70a5" class="lg lh hi ix b iy lp jc lq jg lr jk ls jo lt js mc lm ln lo bi translated">输出图层，ŷ</li><li id="d980" class="lg lh hi ix b iy lp jc lq jg lr jk ls jo lt js mc lm ln lo bi translated">各层之间的一组权重和偏差，<em class="kc"> W和b </em></li><li id="4717" class="lg lh hi ix b iy lp jc lq jg lr jk ls jo lt js mc lm ln lo bi translated">为每个隐藏层选择激活函数，<em class="kc">∑</em>。</li></ul><h1 id="7607" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">基于理论的简单神经网络类:</strong></h1><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/be5d336cc554665da584a1e44b4d02a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U14yO8iha51ROdpaIw23ZQ.png"/></div></div></figure><p id="d086" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个有输入x，输出y，2个权重矩阵和1个输出预测变量的类。</p><h1 id="2093" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">神经网络背后的理论:</strong></h1><p id="6322" class="pw-post-body-paragraph iv iw hi ix b iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">上面已经解释了神经网络的结构。现在让我们来关注一下这种安排是如何工作的。</p><p id="f26c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">训练神经网络:针对输入数据微调网络的权重和偏差的过程称为训练神经网络。该培训涉及2个参数。这些参数如下所述:</p><p id="61ce" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">任何神经网络的主干都是<strong class="ix hj">前馈过程</strong>和<strong class="ix hj">反向传播。</strong>这两者结合起来给出了机器学习领域的最佳预测之一。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div class="er es me"><img src="../Images/4a55c0659e411cea3d22d2a9e543c1c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*ryNDXcGsqk8aQDfics5aMg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">前馈和反向传播</figcaption></figure><p id="96d4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">前馈过程:</strong>将通过每层激活函数获得的值传递给输入值&amp;(加上偏差，乘以权重)以预测输出的过程称为前馈过程。简单来说，计算预测输出<strong class="ix hj"><em class="kc"/></strong>，就是所谓的前馈。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/e11986db44e80f1a81cf87d36c0b61da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XKpEaiscNehspZCjy9aPDQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">两层系统的流程图</figcaption></figure><p id="b278" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2层神经网络的输出是:</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/0d19fe7f715ae83a8ee15c18bd998ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*dctRdSz8L-V2SwRS6Di__g.png"/></div></figure><p id="39d8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于3层或n层系统，可以通过将权重和偏差添加到(n-1)层(即前一层)的输出来扩展方程。</p><p id="1677" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的表达式中，有一个函数应用于感知器的加权输入，这个函数被称为激活函数。在我们的例子中，我们使用了sigmoid函数，将输出限制在0和1之间。</p><p id="45a0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">反向传播:</strong>更新感知器的权重和偏差的连续过程被称为反向传播。反向传播用于减少输出预测中的误差。输入是恒定的，因此我们减少误差的唯一方法是更新权重和偏差矩阵，以便获得所需的值。</p><p id="2426" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">编辑</strong> : <em class="kc">输入值以矩阵的形式出现，这些矩阵上的所有数学运算都是逐位进行的，即逐元素进行。上面描述的等式下面的&amp;是针对标量值的。在实际情况下，相同的方程对输入矩阵的每个元素都起作用。</em></p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/2366d2eabe3640f2524437bd9e116d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FlJ_ZPMSlpCdeuAYzC0gPw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd kf">编辑</strong></figcaption></figure><p id="68e5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">总之，还是回到正题吧。我们需要更新权重和偏差矩阵，但是用什么值来更新它呢？这是成本函数的图像。</p><p id="de1d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">代价函数</strong>:对于给定的数据，<strong class="ix hj">衡量机器学习模型</strong>的性能的函数。成本函数量化预测值和期望值之间的误差，并且<strong class="ix hj">以单个实数</strong>的形式呈现。</p><p id="eca2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">预测或分类系统的目标是最小化成本函数，从而获得更高的精度。</p><p id="b1d6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我们的例子中，成本函数可以被描述为真实产出(Y)值与预测产出(Y_cap)值之差。</p><p id="6598" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这个例子中，我们将使用误差平方和作为我们的成本函数，但我也将添加我编写的不同成本函数的代码。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/239d8da13f91a130d9ebc63eb5346774.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*GXZPFujNPTHS3Qb2MoU9YQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd kf">上交所</strong></figcaption></figure><p id="a4af" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">平方和误差就是每个预测值和实际值之差的总和。对差值求平方以获得绝对误差值。</p><p id="2d85" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">既然我们已经找到了误差，我们需要一种方法来反向传播计算出的误差，以便更新权重和偏差。现在我们将需要微积分，尤其是链式法则，这条法则帮助我们找到一个量相对于另一个量的<strong class="ix hj">梯度</strong>(或变化)，同时具有中间依赖性。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/4a3813916191dd130f42f6c1c37ae42e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cAHeNlCw98RtWvqqgUVmIQ.png"/></div></div></figure><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/176d3ea77b0804684ba7efb0f63a0a69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*31falsuxSc6sAd8I6_dNeQ.png"/></div></div></figure><p id="143f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="kc">梯度下降法是一种寻找可微函数局部极小值的一阶迭代优化算法。</em>T19】</strong></p><p id="1bc4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，如果我们想要更新权重和偏差，我们需要找出一种方法来检查损失函数对权重(w)的响应，为此，我们需要应用链式法则，因为损失函数和网络权重之间没有直接关系。</p><p id="ae5f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">梯度下降算法试图找到图上的局部极小值。局部最小值是成本函数值最小的权重值，即可以预测更高精度的结果。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/5d932e4a6b86c9cf4a6ea5f15aefc3d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kAGEqsmd8A2vuk9RyAGeZw.png"/></div></div></figure><p id="2dc4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里我们有一个关于权重的损失函数的结果或导数，帮助我们反向传播误差，更新权重和偏差。</p><p id="4ba2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在理论已经被解释了，我们应该用python来实现。所以在这里我在神经网络类中增加了两个函数。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/16c352f0ddac5abe5a4fd69fe30c6e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DIaZpvXlcf6A7mqzqe9ssA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">前馈和反向传播</figcaption></figure><p id="551a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">想了解更多关于神经网络的视觉见解，请观看这个播放列表。</p><h1 id="b5d4" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">包装完毕</strong></h1><p id="802e" class="pw-post-body-paragraph iv iw hi ix b iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">现在一切都差不多完成了，所以我们应该尝试将基本的神经网络模型应用于一些输入值。</p><p id="c870" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">X=[[0，0，1] [0，1，1] [1，0，1] [1，1，1]]#训练集输入</p><p id="29e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Y=[0，1，1，0] #训练集输出</p><p id="f84d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于数据集很小，我们应该训练模型，即多次训练前馈和反向传播。让我们选择2500作为迭代速率。</p><p id="2a8f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每次迭代的误差朝着最小值单调递减。过度迭代会导致错误增加，因为模型对训练数据拟合得太紧&amp;因此对测试数据来说表现不佳。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/c431597ef27dec37f7d84419be95a7ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jz4j8sJ0k4SHKppvED049Q.png"/></div></div></figure><p id="807a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">搞定了！！！我们的模型运行良好。经过2500次迭代后，它训练了模型并微调了权重和偏差，这为我们的目标值(Y)提供了非常接近的预测。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/20704da8e945a65f444fbcb7af3f1547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mhSPIdCBpzP9M089"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">我们终于和平了</figcaption></figure><h1 id="90d6" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">临时演员</h1><p id="4704" class="pw-post-body-paragraph iv iw hi ix b iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">在这一部分，我们将探索不同的激活和成本函数。</p><h2 id="754e" class="mp ke hi bd kf mq mr ms kj mt mu mv kn jg mw mx kr jk my mz kv jo na nb kz nc bi translated">激活功能</h2><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nd"><img src="../Images/13dd4e1dd884889ef2c939efe62a23e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aELZz_ams6I0v7FOqvuZ3Q.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">激活功能</figcaption></figure><p id="f170" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">激活函数是限制加权和有偏输入值的函数，这样值不会变得模糊&amp;系统可以处理它。它们限制了功能，并且所获得的输出被作为输入传递给下一层。</p><p id="5990" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在大多数情况下，神经网络从业者使用sigmoid &amp; Relu(校正线性单元)函数，但还有许多其他的函数可供探索。记住这一点，我写了几个可以在不同环境下使用的激活函数。以下是其中的几个。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ne"><img src="../Images/ea288ce57878d7e5ae9af802e9da5544.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z333m9zFvwaovvCOG1b_uQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd kf">不同类型的激活功能</strong></figcaption></figure><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nf"><img src="../Images/9e094324991d9358e1a9317122b45adf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JjuLBuQw14xqYuVPwZPylw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd kf">不同类型的激活功能</strong></figcaption></figure><p id="7c4b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我发现在这里讨论这些激活函数的数学公式并不合适，因为这会增加这篇已经很长的文章的长度，所以我张贴这个链接来帮助理解<a class="ae iu" href="https://en.wikipedia.org/wiki/Activation_function" rel="noopener ugc nofollow" target="_blank">激活函数</a>。</p><h2 id="f8c4" class="mp ke hi bd kf mq mr ms kj mt mu mv kn jg mw mx kr jk my mz kv jo na nb kz nc bi translated">价值函数</h2><figure class="lv lw lx ly fd ij er es paragraph-image"><div class="er es ng"><img src="../Images/bbd83232f6cf62b91cbb1d2b6f1dc102.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/1*hxnqRIxiyCgDToM5hXb09Q.gif"/></div></figure><p id="9293" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我已经讨论过什么是成本函数，我想我们应该选择不同类型的成本函数。这里有一个理解不同类型的成本函数的好来源- <a class="ae iu" rel="noopener" href="/machine-learning-for-li/a-walk-through-of-cost-functions-4767dff78f7">来源</a>。</p><p id="ef37" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面是我写的一些成本函数:</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nh"><img src="../Images/0bca1fc4dea329ca99110e4394c91ada.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MEH44kvmNA7irx8laSAF6g.png"/></div></div></figure><h1 id="39b8" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">下一步是什么</strong></h1><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b5498a56037dc1c9376e5ebd6045fc77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OPMGuihsXC8GO3I2"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">下一步是什么？</figcaption></figure><p id="682f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在神经网络领域有很多东西需要学习和理解，比如用于图像分类的卷积网络、生成对抗网络等等。我以后也会写关于他们的文章。</p><p id="3158" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">超越障碍，尝试理解黑盒背后更深层的算法总是更好的。</p><p id="b0aa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">事实上，学习语言会让你变得更聪明。语言学习的结果是大脑中的神经网络得到加强。T3】</p><p id="aff1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">结局</strong></p></div></div>    
</body>
</html>