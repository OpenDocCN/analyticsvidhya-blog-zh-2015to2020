<html>
<head>
<title>How to do a Content-Based Filtering using TF-IDF?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用TF-IDF进行基于内容的过滤？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-do-a-content-based-filtering-using-tf-idf-f623487ed0fd?source=collection_archive---------5-----------------------#2020-11-10">https://medium.com/analytics-vidhya/how-to-do-a-content-based-filtering-using-tf-idf-f623487ed0fd?source=collection_archive---------5-----------------------#2020-11-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/71a0ac142f813551b31f6cd5443b3436.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OP8Q8iX11kTDYAU-cUANpQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">卡米洛·希门尼斯在<a class="ae iu" href="https://unsplash.com/s/photos/social-media?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="a2b8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">基于内容的过滤是关于从内容中提取知识。</em></p><p id="c8e8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在基于内容的推荐系统中，使用关键字来描述项目，并且建立用户简档来指示该用户喜欢的项目类型。换句话说，这些算法试图推荐与用户过去喜欢的(或现在正在检查的)项目相似的项目。</p><ul class=""><li id="c397" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated">基于用户以前进行的交互创建用户配置文件。</li><li id="de07" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">基于内容创建内容分析器。在某种程度上，它为每个项目创建了一个配置文件。</li><li id="e71c" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">通过比较不同项目配置文件中的用户配置文件，为用户检索项目</li></ul><h1 id="4675" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated"><strong class="ak"> TF-IDF </strong></h1><ul class=""><li id="0d14" class="ju jv hi ix b iy lg jc lh jg li jk lj jo lk js jz ka kb kc bi translated">代表<em class="jt">术语频率和逆文档频率</em></li><li id="4966" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">这是两个矩阵<em class="jt"> </em>，它们紧密相关，在给定大量文档的情况下，搜索并计算出给定单词与文档的相关性，例如，维基百科的每篇文章都可能有一个与之相关联的<strong class="ix hj"> TF </strong>。对于出现在该文档中的每个单词，web上的每个页面都可以有与之相关联的词频。</li><li id="fad4" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">所有的<strong class="ix hj"> TF </strong>的意思是一个给定的单词在一个给定的文档中出现的频率，所以在一个网页的一篇维基百科文章中，一个给定的单词在那个文档中有多常见，那个单词在那个文档中所有单词中出现的比率是多少，就是这样。TF只是测量一个单词在文档中出现的频率。频繁出现的单词可能对文档的含义很重要。</li><li id="7558" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">DF是一个单词在一整套文档中出现的频率，也就是说，在维基百科或每个网页中出现的频率。这告诉我们一些无论什么话题都会出现的常用词，比如“a”、“the”、“and”等等。<br/>具有高<strong class="ix hj"> TF </strong>和<strong class="ix hj"> DF </strong>的单词可能都不是衡量单词与文档相关性的重要指标。</li></ul><blockquote class="ll lm ln"><p id="1b14" class="iv iw jt ix b iy iz ja jb jc jd je jf lo jh ji jj lp jl jm jn lq jp jq jr js hb bi translated">因此，一个单词与一个文档的相关性度量可能是:<strong class="ix hj"> TF/DF </strong></p></blockquote><p id="6943" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">或者:术语频率*逆文档频率</p><p id="4c51" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">也就是说，单词在文档中出现的频率，而不是它在任何地方出现的频率。这给了你一个衡量这个单词对这个文档有多重要和独特的标准。</p><ul class=""><li id="f61e" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated">我们实际上使用IDF的日志，因为词频呈指数分布。这给了我们一个更好的单词总体流行度的权重。</li><li id="6ad7" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">TF-IDF假设文档只是一个“单词包”</li><li id="ee4c" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">将文档解析成一个单词包可能是大部分工作</li><li id="c58e" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">为了提高效率，可以将单词表示为哈希值(数字)</li><li id="0f9c" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">同义词呢？各种时态？缩写？拼写错误？</li><li id="e1e1" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">大规模做到这一点才是最难的部分！</li></ul><p id="f2e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">基于用户的社交媒体活动，应用TF-IDF为用户查找相似的帖子</p><p id="7c8f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据集描述-</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/78d3d0d69fd589c573b8587859b2b116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kDSkX6k2My8Qh7D5X4sGSA.png"/></div></div></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/8612f782ce8ef597f8be980cdd2a0b63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KMH9tZSXs33vSmH0swuHYw.png"/></div></div></figure><pre class="ls lt lu lv fd lx ly lz ma aw mb bi"><span id="7dda" class="mc kj hi ly b fi md me l mf mg">from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer</span><span id="6cbf" class="mc kj hi ly b fi mh me l mf mg">tf = TfidfVectorizer(analyzer=’word’, ngram_range=(1, 2), min_df=0, stop_words=’english’)</span></pre><p id="710a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里，TfidfVectorizer用于将原始文档创建为TF-IDF特征矩阵。ngram_range=(1，2)意味着我只想要一元词和二元词，min_df=0意味着在特征向量中取词，即使它的频率只有1。</p><pre class="ls lt lu lv fd lx ly lz ma aw mb bi"><span id="91e1" class="mc kj hi ly b fi md me l mf mg">import matplotlib.pylab as plt<br/>import scipy.sparse as sparse<br/>tf_matrix1 = tf.fit_transform(df_posts[‘title’])<br/>plt.spy(tf_matrix1)</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/5a7399afa567cfa572ca8baaa9fc13c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*9eFa6nQD-D6Du1QWEfXVeg.png"/></div></figure><pre class="ls lt lu lv fd lx ly lz ma aw mb bi"><span id="4a75" class="mc kj hi ly b fi md me l mf mg">tf_matrix2 = tf.fit_transform(df_posts[‘category’])<br/>plt.spy(tf_matrix2)</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/9b73a2af8db128efaa251f15addc0208.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*9fA3oQtG6pYtQp_gvnLX2g.png"/></div></figure><pre class="ls lt lu lv fd lx ly lz ma aw mb bi"><span id="cc12" class="mc kj hi ly b fi md me l mf mg">from sklearn.metrics.pairwise import linear_kernel<br/>csm1 = linear_kernel(tf_matrix1, tf_matrix1)<br/>csm2 = linear_kernel(tf_matrix2, tf_matrix2)<br/>csm_tf = (csm1 + csm2)/3</span></pre><p id="f19e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里linear_kernel计算矩阵中每个点到矩阵中每隔一个点的余弦距离</p><pre class="ls lt lu lv fd lx ly lz ma aw mb bi"><span id="81be" class="mc kj hi ly b fi md me l mf mg">def cleanData(x):<br/> if isinstance(x, list):<br/> return str.lower(x)<br/> else:<br/> if isinstance(x, str):<br/> return str.lower(x)<br/> else:<br/> return ‘’<br/><br/>def combine(x):<br/> # new columns for algo application and to prevent affecting the original data <br/> return x[‘title1’] + ‘ ‘ + x[‘category1’]</span><span id="5e97" class="mc kj hi ly b fi mh me l mf mg">features = [‘title’, ‘category’]</span><span id="e1fd" class="mc kj hi ly b fi mh me l mf mg">for feature in features:<br/> df_posts[feature + ‘1’] = df_posts[feature].apply(cleanData)</span><span id="d76f" class="mc kj hi ly b fi mh me l mf mg">df_posts[‘merged’] = df_posts.apply(combine, axis=1)</span><span id="feaf" class="mc kj hi ly b fi mh me l mf mg">count = CountVectorizer(stop_words=’english’)<br/>count_matrix = count.fit_transform(df_posts[‘merged’])<br/>csm_count = cosine_similarity(count_matrix, count_matrix)<br/># delete the new columns as processing is done on the merged column<br/>df_posts.drop(columns=[‘title1’, ‘category1’, ‘merged’], inplace=True)<br/>df_posts.drop(columns=’post_id’, inplace=True)</span><span id="fa79" class="mc kj hi ly b fi mh me l mf mg">def recommend(post, csm=(csm_tf + csm_count)/2): # choosing this csm as it covers both aspects<br/> idx = indices[post]<br/> score_series = list(enumerate(csm[idx]))<br/> score_series = sorted(score_series, key=lambda x: x[1], reverse=True)<br/> score_series = score_series[1:11] # not recommending the original post itself, starting from 1<br/> post_indices = [i[0] for i in score_series]<br/> return df_posts.loc[post_indices].style.hide_index()</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/1e7bdcd123dbf9d7ebfcc43e56d4729f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HKG9msvc8A19Awn4XFE0Bg.png"/></div></div></figure><p id="f9a2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">推荐功能根据你要搜索的文章标题给你相似的文章。</p><p id="c42d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">链接到代码</strong></p><p id="3710" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://github.com/ankurdhuriya/Content-Based-Recommendation-System" rel="noopener ugc nofollow" target="_blank">https://github . com/ankurdhuriya/Content-Based-Recommendation-System</a></p></div></div>    
</body>
</html>