<html>
<head>
<title>an overview of GPT-3: AI of the future</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GPT-3概述:未来的人工智能</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-simple-explanation-of-gpt-3-571aca61208c?source=collection_archive---------10-----------------------#2020-07-21">https://medium.com/analytics-vidhya/a-simple-explanation-of-gpt-3-571aca61208c?source=collection_archive---------10-----------------------#2020-07-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e41bd0aeefd1eec0ca502318db7d5e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9OhMqtYOMT8orc4k"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae iu" href="https://unsplash.com/@azhar93?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Azharul Islam </a>拍摄</figcaption></figure><figure class="iv iw ix iy fd ij"><div class="bz dy l di"><div class="iz ja l"/></div></figure><p id="9ea7" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">我最近注意到在我的推特时间线上到处都是关于<a class="ae iu" href="https://openai.com/" rel="noopener ugc nofollow" target="_blank"> OpenAI的</a> GPT-3的非常酷的推文。GPT TLDR-3是开创性的基于变形金刚的人工智能模型的下一个迭代，它用来自互联网各地的文本进行训练，你可以在这里找到完整的论文<a class="ae iu" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"/>。我花了整整一个晚上通读它，它令人着迷，提出了许多关于人工智能模型及其能力的未来的问题。</p><p id="239a" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">还可以看看谢里夫·沙米姆的推文——它们令人兴奋不已！他创建了一个<a class="ae iu" href="https://debuild.co/" rel="noopener ugc nofollow" target="_blank"> GPT-3代码生成器</a>，任何用户都可以描述他们想要构建什么样的应用，GPT-3为其生成代码。Sharif通过展示GPT 3如何创建UI组件并为全功能应用程序生成实际代码，虚拟化了它的一些功能。但是这些是精选的例子，还是它们准确地代表了GPT-3的能力？更紧迫的是，GPT 3号正在可靠地编码吗？</p><figure class="iv iw ix iy fd ij"><div class="bz dy l di"><div class="iz ja l"/></div></figure></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><p id="f831" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">文本生成模型是如何工作的？前提很简单。</p><ol class=""><li id="dfe4" class="kg kh hi jd b je jf ji jj jm ki jq kj ju kk jy kl km kn ko bi translated">处理从提示符给出的输入。</li><li id="dd2f" class="kg kh hi jd b je kp ji kq jm kr jq ks ju kt jy kl km kn ko bi translated">使用训练数据，预测下一个文本块。</li><li id="3501" class="kg kh hi jd b je kp ji kq jm kr jq ks ju kt jy kl km kn ko bi translated">从包含最新位的文本聚合块中，做出另一个预测。</li><li id="ca46" class="kg kh hi jd b je kp ji kq jm kr jq ks ju kt jy kl km kn ko bi translated">重复步骤3，直到达到所需的文本长度。</li></ol><p id="1364" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">这个过程适用于多种语言，甚至是<em class="ku">编程语言</em>，这就是为什么GPT-3知道如何生成代码。</p><p id="eb74" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated"><strong class="jd hj">关键想法</strong></p><p id="43a6" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">如果你熟悉机器学习，你可能听说过传统的微调。这是使用大量示例任务通过重复梯度更新<em class="ku">来训练模型的地方。请注意，这不是GPT-3的学习方式。因为它是在大规模语料库(基本上是整个互联网)上训练的，<strong class="jd hj"> GPT-3是一个少量学习者</strong>，不需要被灌输许多示例任务。假设GPT-3可以从其训练数据中提取模式并建立联系。以下是本文评估GPT-3的三种设置:</em></p><figure class="iv iw ix iy fd ij er es paragraph-image"><div class="er es kv"><img src="../Images/a8c25c5795c28937af15a35a23014515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*wFYHhiRVHQ_iMFykQAIbjQ.png"/></div></figure></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><p id="6076" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">让我们回顾一下GPT的前任GPT-2。在发布时，GPT-2是其前身的大规模升级版本，输入参数比最初的GPT增加了10倍。</p><figure class="iv iw ix iy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/4f0f9adc6c72c7e07f7d9b40fc132c95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qPao_uBbHlzHIzOL7ejI8w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">人工智能研究实验室</figcaption></figure><p id="137f" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">当建立这样的人工智能模型时，一个重要的问题是<strong class="jd hj">收益递减</strong>——也就是说，你不能简单地永远扩大模型。在某种程度上，模型的某些因素将趋于平稳，无论是生成的信息、数据集大小、训练机制等。然而，在GPT-2的水平上，没有迹象表明已经达到这一稳定水平。因此,“更大更好”的策略继续着，给我们带来了GPT-3。</p><p id="debc" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">下面是GPT 3号和它之前的GPT 2号的对比:</p><ul class=""><li id="d28b" class="kg kh hi jd b je jf ji jj jm ki jq kj ju kk jy kx km kn ko bi translated">2020年5月发布对比2019年2月发布(仅一年多一点！)</li><li id="f330" class="kg kh hi jd b je kp ji kq jm kr jq ks ju kt jy kx km kn ko bi translated">1750亿个输入参数对15亿个输入参数(增加了<strong class="jd hj">117倍</strong></li><li id="4dc9" class="kg kh hi jd b je kp ji kq jm kr jq ks ju kt jy kx km kn ko bi translated">计算量大，而只能在单台机器上运行</li></ul><p id="2646" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">因为GPT-3计算量大且成本高，它需要一个分布式集群来运行。它目前作为OpenAI API的一部分公开提供，并处于仅限邀请的测试阶段，随后将很快发布一个盈利性版本。疯狂的事情是，图表仍然表明，在GPT-3之后还有改进的空间！我们仍然没有达到前面提到的稳定期。</p></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><p id="d35a" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">OpenAI的论文描述了GPT 3号可以完成的许多令人难以置信的任务。</p><p id="b043" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated"><strong class="jd hj">任务:新闻文章生成</strong></p><p id="a547" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">例如，给定一些文本输入，它可以惊人地预测接下来会发生什么。在一项研究中，测试对象被要求区分人类写的500字长的文章或GTP-3写的文章。当GPT-3与1750亿个参数一起使用时，他们只能以52%的比率正确识别来自其他人的文本。这意味着GPT-3在最大容量下几乎可以复制人类写的文章！</p><figure class="iv iw ix iy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/f83356d86be2a7c16fccf84ab2800348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*67_X5_YeuloIgY3cCmM95Q.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">区分人类和GPT-3写作</figcaption></figure><p id="15a4" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">下面是一篇GPT-3生成的文章，人类很难从人类文章中区分出来，准确率只有12%。</p><figure class="iv iw ix iy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/bffcb4987c3c2c3ad99962fe1e99b8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t1QHDXlRkw_Kly486goYrg.png"/></div></div></figure><p id="16ef" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated"><strong class="jd hj">任务:算术</strong></p><p id="3916" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">GPT 3并不像算术那样擅长写作……好吧，这是个问题。下图显示了GPT-3在位数较少时的表现，“两位数加法的准确率达到100%，两位数减法的准确率达到98.9%，三位数加法的准确率达到80.2%，三位数减法的准确率达到94.2%。”当位数增加时，它会挣扎，但仍然保持一定程度的准确性，“这表明至少有一些能力概括更多的位数。”(语言模型是很少使用的学习器，OpenAI)</p><figure class="iv iw ix iy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/963ca96f749aeac34cc04bd719a90c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uwMoemQZ-AkCMJJOy3qB3g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">GPT 3承担算术</figcaption></figure><p id="d480" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">与文本不同，算术更多的是一组确定的问题。想想你小时候所有的加减乘除表。如果这些问题是馈入GPT-3的训练数据的一部分(例如互联网上某处的一系列算术问题)，模型可以使用它们以直接的方式回答问题，但随着位数的增加，训练数据不太可能包含所有可能的算术问题。一种选择是记住所有这些问题，但这似乎不可行，因为这是对计算和空间的有效利用。那么，这里到底发生了什么来实现这些级别的准确性呢？</p><p id="3091" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">言下之意是，GPT-3正在从其训练数据中建立联系，并从本质上进行学习！OpenAI的研究人员通过在训练数据的测试集中搜索所有3位数的算术问题，抽查了人工智能是否正在记忆特定的算术问题:“在2000个加法问题中，我们只找到了17个匹配项(0.8%)，在2000个减法问题中，我们只找到了2个匹配项(0.1%)，这表明只有一小部分正确答案可能被记住了。”此外，在检查错误时，似乎该模型犯了类似人类的错误，例如忘记携带“1”，这表明该模型实际上<em class="ku">正在</em>尝试学习！*插入心智成熟的表情符号*(语言模型是一次性学习工具，OpenAI)</p><p id="5f65" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated"><strong class="jd hj">任务:用造词造句</strong></p><p id="8be3" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">我最喜欢的一项研究是，研究人员为模型引入造词，并要求它用新词造句。这里有一个任务的例子，要求模型用“yalubalu”造一个句子:</p><p id="ff8f" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">这是作为输入输入的</p><blockquote class="lb lc ld"><p id="f88e" class="jb jc ku jd b je jf jg jh ji jj jk jl le jn jo jp lf jr js jt lg jv jw jx jy hb bi translated">“yalubalu”是一种看起来像大南瓜的蔬菜。使用单词yalubalu的句子的一个例子是:</p></blockquote><p id="9a5c" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">模型对此做出了响应</p><blockquote class="lb lc ld"><p id="1429" class="jb jc ku jd b je jf jg jh ji jj jk jl le jn jo jp lf jr js jt lg jv jw jx jy hb bi translated">我去非洲旅行的时候，尝了尝这种生长在那里一个花园里的蔬菜。味道很好。</p></blockquote><p id="0264" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">这句话不仅有意义，而且GPT-3还为它添加了上下文(非洲之旅)!这项任务的其他输出显示，该模型甚至可以结合新词并以适当的语法使用它们，这表明GPT-3至少在这项任务中是熟练的。</p><p id="cfef" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated"><strong class="jd hj">其他</strong></p><p id="4920" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">还有一些额外的研究，我在这篇文章中没有提到，但我建议也阅读一下！</p></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><p id="d635" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">但是当然，这种模式也有缺点。本文开头提到的沙里夫的演示令人惊叹，但并不一定准确地描绘了GPT-3。我相信Twitter上的大肆宣传表明了对GPT-3 <em class="ku">和</em>工作良好的例子的选择偏见，但还有同样多(如果不是更多)的例子没有被报道。</p><p id="62a1" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">最明显的弱点是GPT-3的<strong class="jd hj">高延迟</strong>，正如1750亿参数模型所预期的那样。当您向GPT-3提供输入时，可能需要大量时间来生成输出。当在需要快速响应的环境中使用时，这可能会导致糟糕的用户体验。</p><p id="f9be" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">GPT-3需要<strong class="jd hj">强大的基础设施</strong>，很难用自己的数据定制或训练。使用beta版本的人群很可能都使用OpenAI提供的相同版本的模型。</p><figure class="iv iw ix iy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/f15436e64e366855e035964099c91bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SwZAzgqoTWH3cZncbliJ-w.png"/></div></div></figure><p id="ac0c" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">像许多神经网络一样，GPT-3是一个<strong class="jd hj">黑盒</strong>，用户并不真正理解它为什么做出某些决定。我们只能观察输入和输出，这限制了我们更好地理解它的内部工作。</p></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><p id="9759" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">归根结底，GPT-3是一个令人印象深刻的人工智能模型<em class="ku"> </em>，它的预测基于数量多得离谱的训练数据，甚至没有针对特定任务进行微调。然而，它不是魔法，也不会引发一场人工智能革命。人工智能模型即服务产品仍然有许多典型的问题和缺点。GPT-3无疑是人工智能研究的一个飞跃，但也有缺点，如高延迟(当API公开发布时，可能成本也很高)和黑盒特性等问题。我们还有很多事情要弄清楚，但我们正朝着正确的方向前进。</p><p id="3f0a" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">有趣的事实:GPT-3是根据2019年10月的测试数据进行训练的，所以它不知道新冠肺炎或2020年发生的所有混乱。多美好的时光。</p><p id="b385" class="pw-post-body-paragraph jb jc hi jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated"><strong class="jd hj">其他酷读</strong></p><div class="li lj ez fb lk ll"><a rel="noopener follow" target="_blank" href="/@kirkouimet/my-mind-blowing-conversations-openais-latest-ai-gpt-3-235ba5fb9453"><div class="lm ab dw"><div class="ln ab lo cl cj lp"><h2 class="bd hj fi z dy lq ea eb lr ed ef hh bi translated">与GPT的对话-3</h2><div class="ls l"><h3 class="bd b fi z dy lq ea eb lr ed ef dx translated">我花了太多时间玩OpenAI的GPT 3测试版API。这种语言给我留下了深刻的印象…</h3></div><div class="lt l"><p class="bd b fp z dy lq ea eb lr ed ef dx translated">medium.com</p></div></div></div></a></div><div class="li lj ez fb lk ll"><a href="https://uxdesign.cc/lets-talk-about-that-gpt-3-ai-tweet-that-shook-designers-to-the-core-d2b31ad3d63b" rel="noopener follow" target="_blank"><div class="lm ab dw"><div class="ln ab lo cl cj lp"><h2 class="bd hj fi z dy lq ea eb lr ed ef hh bi translated">让我们来谈谈GPT-3的人工智能推文，它从根本上震撼了设计师</h2><div class="ls l"><h3 class="bd b fi z dy lq ea eb lr ed ef dx translated">拥抱人工智能和自动化</h3></div><div class="lt l"><p class="bd b fp z dy lq ea eb lr ed ef dx translated">uxdesign.cc</p></div></div><div class="lu l"><div class="lv l lw lx ly lu lz io ll"/></div></div></a></div></div></div>    
</body>
</html>