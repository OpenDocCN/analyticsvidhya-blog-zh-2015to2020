<html>
<head>
<title>Detecting and Fighting Neural Fake News using NLP and Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用NLP和深度学习检测和打击神经假新闻</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/an-exhaustive-guide-to-detecting-and-fighting-neural-fake-news-using-nlp-70550f3f4ecc?source=collection_archive---------19-----------------------#2019-12-16">https://medium.com/analytics-vidhya/an-exhaustive-guide-to-detecting-and-fighting-neural-fake-news-using-nlp-70550f3f4ecc?source=collection_archive---------19-----------------------#2019-12-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8172" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假新闻是目前我们社会的一个主要问题。</p><p id="a4b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它与数据驱动时代的兴起齐头并进，考虑到我们每秒钟生成的庞大数据量，这不是巧合！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/6589b2ad24b79ce38ccfc3b2be92dcef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*STx1w0qjMb-iLkF6.jpg"/></div></div></figure><p id="c183" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么机器学习在这其中起到了什么作用呢？</p><p id="fbd8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我相信你一定听说过一种机器学习技术，它可以生成模仿名人的虚假视频。</p><p id="d34b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，自然语言处理(NLP)技术正被用于生成假新闻——这是一种被称为“神经假新闻”的概念。</p><p id="50aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这加剧了他们被利用来进行宣传和制造社会混乱的风险。</p><h1 id="f7c7" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是神经假新闻？</h1><p id="1b82" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">神经假新闻是使用基于神经网络的模型生成的任何假新闻。或者更正式地定义它:</p><blockquote class="ks"><p id="cf75" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated">神经假新闻是一种有针对性的宣传，它密切模仿由神经网络生成的真实新闻的风格。</p></blockquote><p id="9e4b" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">下面是<a class="ae li" href="https://www.analyticsvidhya.com/blog/2019/07/openai-gpt2-text-generator-python/?utm_source=blog&amp;utm_medium=exhaustive-guide-detecting-fighting-neural-fake-news-nlp" rel="noopener ugc nofollow" target="_blank"> OpenAI的GPT-2模型</a>产生的神经假新闻的一个例子:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/4480dacfa85140980e635259f1b83137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LvabNMX9wmDsWyk1.png"/></div></div></figure><p id="23c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“系统提示”是人给模型的输入，“模型完成”是GPT-2模型产生的文本。</p><p id="fa20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你是不是凭直觉猜到后半部分是机器写的？</p><p id="e73d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，如果我告诉你，GPT-2模型是任何人都可以免费下载和运行的呢？这正是研究界所关心的，也是我决定写这篇文章的原因。</p><h1 id="d0ad" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">大型语言模型如何被误用生成神经假新闻？</h1><p id="a0b9" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><a class="ae li" href="https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/?utm_source=blog&amp;utm_medium=exhaustive-guide-detecting-fighting-neural-fake-news-nlp" rel="noopener ugc nofollow" target="_blank">语言建模</a>是一种<a class="ae li" href="https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp?utm_source=blog&amp;utm_medium=exhaustive-guide-detecting-fighting-neural-fake-news-nlp" rel="noopener ugc nofollow" target="_blank"> NLP </a>技术，模型通过理解句子本身的上下文来学习预测句子中的下一个单词或缺失的单词。以谷歌搜索为例:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lk"><img src="../Images/be124a6882f8f94df690eca561ea1ea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/0*l-8SgDcx8nZIJuIF.png"/></div></figure><p id="5a13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个语言模型运行的例子。</p><blockquote class="ks"><p id="3d4a" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated">通过让模型预测句子中的下一个单词或缺失的单词，我们让模型学习语言本身的复杂性。</p></blockquote><p id="72b3" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">该模型能够理解语法如何工作，不同的写作风格等。这就是模型如何能够生成一段在未经训练的人看来可信的文本。</p><p id="e908" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有一些非常强大的最先进的语言模型，它们非常擅长生成文本:Google的BERT，OpenAI的GPT-2模型和AllenNLP的Grover。</p><h1 id="8317" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">如何检测神经假新闻？</h1><p id="80b7" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们如何检测或判断一条新闻是否是假的？目前，有三种主要的方法来处理神经假新闻，并显示出良好的效果。</p><h1 id="558e" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">一.事实核查</h1><p id="c55c" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">检验网上传播的新闻是真是假的最基本的方法是什么？</p><p id="1b0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以简单地谷歌一下，参考值得信赖的新闻网站，并核实它们是否有相同或相似的故事。</p><p id="44fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管这一步看起来像是常识，但它实际上是确定一条新闻真实性的最有效的方法之一。</p><h1 id="4135" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">二。使用GLTR (HarvardNLP)的统计分析</h1><p id="7b5f" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">GLTR 或<strong class="ih hj"> G </strong> iant <strong class="ih hj"> L </strong>语言模型<strong class="ih hj"> T </strong> est <strong class="ih hj"> R </strong> oom是由哈佛大学和麻省理工学院-IBM沃森实验室的杰出人士设计的工具。</p><blockquote class="ks"><p id="6701" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated"><em class="lc">GLTR用于识别机器生成文本的主要方法是通过对给定文本进行统计分析和可视化的巧妙结合。</em></p></blockquote><p id="eaee" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">以下是GLTR界面的外观:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/fab15f0fbbd80f555ed88334fa83c53b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*Zyzk80wpsHECD4KJ.gif"/></div></figure><p id="359a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GLTR检测生成文本的中心思想是使用与最初生成文本相同(或相似)的模型。</p><p id="63b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">原因很简单，语言模型直接生成的单词来自概率分布,而概率分布是语言模型从训练数据中学习而来的。</p><p id="6cf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">并且因为我们已经知道用于从给定的概率分布中采样单词的技术，例如最大采样等。我们可以很容易地交叉检查给定文本中的单词是否遵循特定的分布。</p><p id="f353" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果确实如此，并且在给定的文本中有多个这样的单词，那么这将基本上确认它是机器生成的。</p><p id="2b44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们在一个例子上运行GLTR来理解这个概念！</p><h1 id="83bc" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">安装GLTR</h1><p id="e873" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在我们可以使用GLTR之前，我们需要在我们的系统上安装它。首先克隆项目的GitHub存储库:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="8574" class="lr jq hi ln b fi ls lt l lu lv">git clone <a class="ae li" href="https://github.com/HendrikStrobelt/detecting-fake-text.git" rel="noopener ugc nofollow" target="_blank">https://github.com/HendrikStrobelt/detecting-fake-text.git</a></span></pre><p id="51c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦您克隆了存储库，将cd放入其中并进行pip安装:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="50a3" class="lr jq hi ln b fi ls lt l lu lv">cd detecting-fake-text &amp;&amp; pip install -r requirements.txt</span></pre><p id="35ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，下载预先训练好的语言模型。您可以通过运行服务器来实现:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="b2e9" class="lr jq hi ln b fi ls lt l lu lv">python server.py</span></pre><p id="4317" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GLTR目前支持两种模型——BERT和GPT-2。你可以在两者之间选择；如果没有给出选项，则使用GPT-2:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="212a" class="lr jq hi ln b fi ls lt l lu lv">python server.py --model BERT</span></pre><p id="d82a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将开始在您的机器上下载相应的预训练模型。如果你的网络连接很慢，给它一些时间。</p><p id="1c6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一切准备就绪后，服务器将从5001端口启动，您可以直接进入<a class="ae li" href="http://localhost:5001" rel="noopener ugc nofollow" target="_blank"><em class="lw">http://localhost:5001</em></a>进行访问:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lx"><img src="../Images/7c0017985e387ebc9359c452db6e6b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9Z9IXw7-b0ntYhoO.png"/></div></div></figure><h1 id="a9ae" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">GLTR是如何工作的？</h1><p id="1117" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">假设我们有下面这段文字。我们要检查它是否是由像GPT-2这样的语言模型生成的:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="2332" class="lr jq hi ln b fi ls lt l lu lv">How much wood would a woodchuck chuck if a woodchuck could chuck wood?</span></pre><p id="54e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GLTR将接受这一输入，并分析GPT-2对输入的每个位置的预测。</p><p id="a5ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请记住，语言模型的输出是模型知道的所有单词的排名。因此，根据GPT-2，我们将很快能够看到输入文本的每个单词的排名。</p><p id="88f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们对每个单词进行颜色编码，根据它的排名是前10名为绿色，前100名为黄色，前1000名为红色，我们会得到这样的输出:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/5652e349b7716bbd48c7603ca133cf1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/0*XME-fBFbNF4etBnf.png"/></div></figure><p id="2938" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们可以直观地看到每个单词根据GPT-2的概率有多大</p><p id="5e01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你需要更多的信息，你可以把鼠标悬停在一个单词上，比如“木头”。您将看到一个小框，其中显示了该职位的前5个预测单词及其概率:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/cfc98168db9acd0fd05519fe6fdfc0f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/0*hXz3zk12u1-pxu_8.png"/></div></figure><p id="112c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一点上，我强烈建议你使用GLTR来尝试不同的文本，包括人类生成的和机器生成的。工具本身已经提供了几个例子: </p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ma"><img src="../Images/036e27f40524b9e8159c5456a7a8292d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qvZ00F9J3ZK2U9vG.png"/></div></div></figure><p id="34ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你会注意到，当你转向真实文本时，<strong class="ih hj">红色</strong>和<strong class="ih hj">紫色</strong>单词，即<strong class="ih hj">不太可能</strong>或<strong class="ih hj">罕见</strong>预测的数量会增加。</p><p id="5599" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，GLTR显示了三个不同的直方图，其中包含了整个文本的聚合信息(查看下图以供参考):</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/9974b13c0b87eb4d4080e237947b2ed5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HqYAZ5Yfs4qOaxfq.png"/></div></div></figure><p id="8a79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">下面是这些直方图的帮助:</strong></p><ul class=""><li id="2550" class="mc md hi ih b ii ij im in iq me iu mf iy mg jc mh mi mj mk bi translated">前两个直方图有助于理解输入文本中的单词是否是从分布的顶部采样的(对于机器生成的文本来说是这样)</li><li id="1ec1" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated">最后一个直方图说明了单词的上下文对于检测系统是否是已知的，因为它(非常)确定其下一个预测</li></ul><p id="9e33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很聪明，对吧？通过结合这些多种可视化和概率分布的知识，GLTR模型可以用作理解和识别机器生成文本的有效取证工具。</p><p id="a5fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是作者关于GLTR成功的报道:</p><blockquote class="ks"><p id="f5bc" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated"><em class="lc">“在一项人类受试者研究中，我们表明，GLTR提供的标注方案在没有任何预先训练的情况下，将虚假文本的人类检测率从</em><strong class="ak"><em class="lc">54%</em></strong><em class="lc">提高到</em><strong class="ak"><em class="lc">72%</em></strong><em class="lc">。”——格尔曼等人。艾尔</em></p></blockquote><p id="977f" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">你可以在原研究论文中阅读更多关于GLTR <a class="ae li" href="https://arxiv.org/pdf/1906.04043.pdf" rel="noopener ugc nofollow" target="_blank">的内容。</a></p><h1 id="2b98" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">三。利用模型检测神经假新闻</h1><p id="6119" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">GLTR相当令人印象深刻，因为它使用概率分布和可视化的简单知识来检测神经假新闻。但是如果我们能做得更好呢？</p><blockquote class="ks"><p id="796a" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated"><em class="lc">如果我们可以训练一个大模型来预测一段文字是不是神经假新闻呢？</em></p></blockquote><p id="94d4" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">这正是我们将在本节中学习的内容！</p><h1 id="17e2" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">a) GPT-2探测器模型</h1><p id="3bdf" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">GPT-2探测器模型是一个<a class="ae li" href="https://arxiv.org/pdf/1907.11692.pdf" rel="noopener ugc nofollow" target="_blank">罗伯塔</a>(BERT的一种变体)模型，它已经被微调以预测给定的一段文本是否是通过使用GPT-2生成的(作为一个简单的分类问题)。</p><p id="2965" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看它的实际效果吧！</p><h1 id="c117" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">安装GPT-2探测器模型</h1><p id="6efb" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">这种探测器模型的安装步骤非常简单，就像GLTR一样。</p><p id="a744" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们首先需要克隆存储库:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="5377" class="lr jq hi ln b fi ls lt l lu lv">git clone <a class="ae li" href="https://github.com/openai/gpt-2-output-dataset.git" rel="noopener ugc nofollow" target="_blank">https://github.com/openai/gpt-2-output-dataset.git</a></span></pre><p id="2bf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">再次，光盘到它和做<em class="lw"> pip </em>安装:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="c5aa" class="lr jq hi ln b fi ls lt l lu lv">cd gpt-2-output-dataset/ &amp;&amp; pip install -r requirements.txt</span></pre><p id="53ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们需要下载预先训练好的语言模型。通过运行以下命令来完成此操作:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="50ca" class="lr jq hi ln b fi ls lt l lu lv">wget <a class="ae li" href="https://storage.googleapis.com/gpt-2/detector-models/v1/detector-base.pt" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/gpt-2/detector-models/v1/detector-base.pt</a></span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/7e2bcde129ac195012b455c57c4a8bbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/0*x2FXH_f_pc6Ex_OZ.png"/></div></figure><h1 id="cabc" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">识别神经假新闻</h1><p id="ae60" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">让我们用GPT-2生成的一段文本来测试这个模型:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mr"><img src="../Images/5730432d0b4920f8bfa1609eaa872352.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IBBpP_n3dYNj2hsN.png"/></div></div></figure><p id="e3b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">正如你所看到的，尽管文本看起来非常令人信服和连贯，但模型立即以99.97%的准确率将其归类为“假的”。</strong></p><p id="b720" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个非常有趣的工具，我建议你继续尝试不同的生成和非生成文本的例子，看看它的表现如何！</p><p id="13d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我的例子中，我注意到这个模型只在识别由GPT-2模型生成的文本时有效。</p><h1 id="b479" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">格罗弗公司</h1><p id="fa1e" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在本文讨论的所有工具中，AllenNLP的Grover是我最喜欢的工具。</p><p id="2c80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">它能够识别由多种类型的大量语言模型生成的一段文本，而不像GLTR和GPT-2检测器模型那样局限于特定的模型。</strong></p><p id="3735" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据作者的说法，检测一段文本为神经假新闻的最佳方法是使用一个模型，该模型本身就是一个可以生成此类文本的生成器。用他们自己的话说:</p><blockquote class="ks"><p id="ca99" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated"><em class="lc">“生成器最熟悉的</em><strong class="ak"><em class="lc"/></strong><em class="lc">与自己的</em> <strong class="ak"> <em class="lc">习惯</em></strong><em class="lc"/><strong class="ak"><em class="lc">怪癖</em> </strong> <em class="lc">，以及</em> <strong class="ak"> <em class="lc">特质</em> </strong> <em class="lc">，以及那些来自类似AI模型的，特别是那些基于类似数据训练的，即公开可获得的消息。”泽勒斯等人。艾尔</em></p></blockquote><p id="3990" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">乍听起来有些违反直觉，不是吗？</p><p id="02f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了创造一个能够<strong class="ih hj"> <em class="lw">检测</em> </strong>神经假新闻的模型，他们先行一步，开发了一个真正擅长<strong class="ih hj"> <em class="lw">首先生成</em> </strong>这样假新闻的模型！</p><p id="79f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">听起来很疯狂，但背后有科学逻辑。</p><h1 id="ccf5" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">那么格罗弗是如何工作的呢？</h1><p id="e6d0" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">Grover将检测神经假新闻的任务定义为一个对抗性的游戏，有两个模型作为参与者。这是它的意思:</p><ul class=""><li id="6ecd" class="mc md hi ih b ii ij im in iq me iu mf iy mg jc mh mi mj mk bi translated">设置中有两个<strong class="ih hj">模块</strong>用于检测生成的文本</li><li id="c268" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated"><strong class="ih hj">对抗性</strong>模式的目标是制造假新闻，这些假新闻可以像病毒一样传播，或者对人类和<strong class="ih hj">验证者</strong>模式都有足够的说服力</li><li id="d0a7" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated"><strong class="ih hj">验证器</strong>对给定文本的真伪进行分类:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ms"><img src="../Images/984f496c64ded5a243b15fb20c6b5d33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MqkwWZHVWKlcr62d.png"/></div></div></figure><ul class=""><li id="1dd4" class="mc md hi ih b ii ij im in iq me iu mf iy mg jc mh mi mj mk bi translated">用于<strong class="ih hj">验证者</strong>的训练数据由无限的真实新闻故事组成，但是只有一些来自特定对手的假新闻故事</li><li id="a6e5" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated">这样做是为了复制真实世界的场景，在真实世界中，对手提供的假新闻数量与真实新闻相比要少得多</li></ul><p id="6e34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着验证者模型变得更好，对抗者模型也变得更好。</p><h2 id="830f" class="lr jq hi bd jr mt mu mv jv mw mx my jz iq mz na kd iu nb nc kh iy nd ne kl nf bi translated">神经假新闻的条件生成</h2><p id="ee50" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">神经假新闻最明显的特性之一是，它通常是“有针对性”的内容，如clickbait或宣传。大多数语言模型如BERT等。不要让我们创造受控制的一代。欢迎—格罗弗。</p><blockquote class="ks"><p id="c028" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated"><em class="lc"> Grover支持“受控”文本生成。</em></p></blockquote><p id="912b" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">但是这些参数是什么呢？考虑新闻文章——有助于定义新闻文章的结构参数是什么？以下是格罗弗的作者认为生成一篇文章所必需的一些参数:</p><ul class=""><li id="410d" class="mc md hi ih b ii ij im in iq me iu mf iy mg jc mh mi mj mk bi translated"><strong class="ih hj">域:</strong>文章发表的地方，间接影响风格</li><li id="49f7" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated"><strong class="ih hj">日期:</strong>出版日期</li><li id="c747" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated"><strong class="ih hj">作者:</strong>作者姓名</li><li id="a1a9" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated"><strong class="ih hj">标题:</strong>文章的标题，这影响到正文的生成</li><li id="677c" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated"><strong class="ih hj">正文:</strong>文章的正文</li></ul><p id="0370" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结合所有这些参数，我们可以通过联合概率分布来对文章建模:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ng"><img src="../Images/1dc54ec098260369624240e1bc371721.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/0*oQRNsMhvyQWo8zaB.png"/></div></figure><p id="8ff3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我不会过多地探究这是如何实现的底层数学，因为这超出了本文的范围。但是为了让您对整个生成过程有一个大致的了解，这里有一个示意图:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nh"><img src="../Images/206f38b12c43cd47add786d7edac6cb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nBMbEFsyh7NkU7pl.png"/></div></div></figure><p id="0602" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是正在发生的事情:</p><ul class=""><li id="c6fd" class="mc md hi ih b ii ij im in iq me iu mf iy mg jc mh mi mj mk bi translated">在行a)中，主体是从部分上下文生成的(缺少作者字段)</li><li id="1b7d" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated">在b)中，模型生成作者</li><li id="61e6" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated">在c)中，模型使用新的世代将提供的标题重新生成为更真实的标题</li></ul><h2 id="5b03" class="lr jq hi bd jr mt mu mv jv mw mx my jz iq mz na kd iu nb nc kh iy nd ne kl nf bi translated">架构和数据集</h2><p id="7e78" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">Grover使用与GPT2相同的架构:</p><ul class=""><li id="cf59" class="mc md hi ih b ii ij im in iq me iu mf iy mg jc mh mi mj mk bi translated">有3种型号。最小的模型Grover-Base有12层和1.24亿个参数，与GPT和伯特-Base相当</li><li id="05c0" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated">下一个模型，Grover-Large，有24层和3.55亿个参数，与BERT-Large相当</li><li id="58e0" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc mh mi mj mk bi translated">最大的模型Grover-Mega有48层和15亿个参数，与GPT2相当</li></ul><p id="a5db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于训练Grover的数据集是由Grover的作者自己创建的。</p><h1 id="341b" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">安装Grover</h1><p id="c529" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">你可以按照<a class="ae li" href="https://github.com/rowanz/grover" rel="noopener ugc nofollow" target="_blank">安装说明</a>来安装Grover，并在你自己的机器上运行它的生成器和检测器工具。记住型号尺寸巨大(46.2G压缩！)所以在你的系统上安装它可能是一个挑战。</p><p id="9db4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是为什么我们将使用可用的在线检测器和生成器工具。</p><h1 id="dca0" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">使用Grover进行生成和检测</h1><p id="2698" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">您可以通过以下链接访问该工具:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="28f8" class="lr jq hi ln b fi ls lt l lu lv"><a class="ae li" href="https://grover.allenai.org/" rel="noopener ugc nofollow" target="_blank">https://grover.allenai.org/</a></span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ni"><img src="../Images/ebfc8f8efb2660b411381b3b77d3e9cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8bRzf6CmJhBZPHBh.png"/></div></div></figure><p id="a55b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以尝试使用Generate选项，看看Grover生成神经假新闻的能力有多强。由于我们有兴趣检查Grover的检测能力，让我们前往“检测”选项卡(或转到以下链接):</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="1c71" class="lr jq hi ln b fi ls lt l lu lv"><a class="ae li" href="https://grover.allenai.org/detect" rel="noopener ugc nofollow" target="_blank">https://grover.allenai.org/detect</a></span></pre><h2 id="b718" class="lr jq hi bd jr mt mu mv jv mw mx my jz iq mz na kd iu nb nc kh iy nd ne kl nf bi translated">案例研究1:</h2><p id="9054" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们要测试的这段文本与我们之前看到的GPT-2协议生成的文本相同:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="298e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当你点击“检测假新闻”按钮时，你会注意到格罗弗非常容易地识别出这是机器生成的:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nl"><img src="../Images/673a4fed2a2f21d22ea5c342cdb44d42.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/0*YAB9UpSfR7KcBp1b.png"/></div></figure><h2 id="6ce7" class="lr jq hi bd jr mt mu mv jv mw mx my jz iq mz na kd iu nb nc kh iy nd ne kl nf bi translated">案例研究2:</h2><p id="a636" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们要测试的下一篇文章来自纽约时报:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="1364" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你会发现格罗弗确实能够辨认出这是人写的:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/110502a4901da615fb704e122a7f1b64.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/0*_xpd6hWG40AAOyp3.png"/></div></figure><h2 id="38c0" class="lr jq hi bd jr mt mu mv jv mw mx my jz iq mz na kd iu nb nc kh iy nd ne kl nf bi translated">案例研究3:</h2><p id="d7b6" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">这些都是简单的例子。如果我给它一段技术性的文字呢？就像分析网站Vidhya的一篇文章中的解释？</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="4bf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于上面的文字，Grover失败了，因为它没有受过这类技术文章的训练:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nl"><img src="../Images/4942379405bec4761e172cbcda5fc59a.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/0*3NIK03N6wojIU4Wi.png"/></div></figure><p id="a68f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但正是在这里，GPT-2探测器模型大放异彩，因为它在各种各样的网页上进行了训练(800万！).</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nm"><img src="../Images/0e1db8aa4ea8ab629e66cb50fe0d4c27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OKyGQCLepG8EA3JT.png"/></div></div></figure><p id="ec6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这表明没有一种工具是完美的，你必须根据你要检测的文本类型来选择使用哪一种。</p><h2 id="64fb" class="lr jq hi bd jr mt mu mv jv mw mx my jz iq mz na kd iu nb nc kh iy nd ne kl nf bi translated">案例研究4:</h2><p id="6097" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">她是我们将做的最后一个实验。我们将测试机器生成的新闻，这些新闻不是“假的”，而只是自动化新闻生成的一个例子。这篇文章摘自<strong class="ih hj">华盛顿邮报</strong>，它使用一个程序自动更新分数:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="4670" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，这里有趣的事情是GPT-2探测器模型说它根本不是机器生成的新闻:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nn"><img src="../Images/ccb8daa3bcb5b9cbd7e7b0480761807b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iNZ9eC53ZjpuSjQR.png"/></div></div></figure><p id="64be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但与此同时，Grover能够以稍低的概率识别出它是机器编写的文本(但它仍然能够识别出它！):</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es no"><img src="../Images/0290f43435e3ef5eb71f750afd3cdba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/0*r9Wip19zu_JgQ0OQ.png"/></div></figure><p id="4171" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，不管你是否认为这是“假”新闻，事实是它是由一台机器产生的。你将如何对这类文本进行分类将取决于你的目标和你的项目想要达到的目标。</p><blockquote class="ks"><p id="f7a0" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated"><em class="lc">简而言之，检测神经假新闻的最佳方式是综合使用所有这些工具，并得出一个比较结论。</em></p></blockquote><h1 id="d99f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka np kc kd ke nq kg kh ki nr kk kl km bi translated">当前假新闻检测技术的局限性</h1><p id="9dae" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">显而易见，目前的检测技术并不完美，它们还有发展的空间。麻省理工学院最近对现有的检测神经假新闻的方法进行了一项研究，他们的一些发现令人大开眼界。</p><blockquote class="ks"><p id="f6bf" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated">这项研究的主要结果是现有的方法，如GLTR、Grover等。用来检测神经假新闻是不完整的。</p></blockquote><p id="3c7b" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">这是因为仅仅发现一段文本是否是“机器生成的”是不够的，<strong class="ih hj">在自动完成、文本摘要</strong>等工具的帮助下，可能有一段合法的新闻是机器生成的。</p><p id="0fc5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，著名的写作应用程序<strong class="ih hj">在语法上</strong>使用某种形式的<a class="ae li" href="https://arxiv.org/pdf/1906.01733.pdf" rel="noopener ugc nofollow" target="_blank"> GPT-2来帮助纠正文本中的语法错误</a>。</p><p id="576f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种情况的另一个例子是本文前一节的案例研究#4 ，其中一个<strong class="ih hj">程序</strong>被《华盛顿邮报》用来自动生成体育更新。</p><p id="b8d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">反之亦然，可能存在被攻击者轻微破坏/修改的<strong class="ih hj">人类书写文本，其将被现有方法分类为非神经假新闻。</strong></p><p id="5e11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图总结了探测器模型的上述困境:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ns"><img src="../Images/f11b53684779a838c1b6d0035acba43b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/0*xMGkuY74i0GQ16hL.png"/></div></figure><p id="6811" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不会深入细节，但作者进行了多次实验来得出这些结论，你可以<a class="ae li" href="https://arxiv.org/pdf/1908.09805.pdf" rel="noopener ugc nofollow" target="_blank">阅读他们非常有趣的论文来了解更多</a>。</p><blockquote class="ks"><p id="60e9" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated"><em class="lc">这些结果使作者得出结论，为了定义/检测神经假新闻我们不得不考虑</em> <strong class="ak"> <em class="lc">【真实性】</em> </strong> <em class="lc">而不是</em> <strong class="ak"> <em class="lc">出处(来源，不管是机器写的还是人类写的)。</em>T25】</strong></p></blockquote><p id="2034" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">我认为这是一个让我们大开眼界的发现。</p><h1 id="32c2" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">未来的研究方向是什么？</h1><p id="aa67" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在处理神经假新闻问题的方向上迈出了一步，当<a class="ae li" href="https://arxiv.org/pdf/1803.05355.pdf" rel="noopener ugc nofollow" target="_blank">剑桥大学和亚马逊去年发布FEVER </a>时，这是世界上最大的事实核查数据集，可用于训练神经网络来检测假新闻。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nt"><img src="../Images/4b329c1547a8fdeffad1795b15a6827c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g11iZmWsulybP6pi.png"/></div></div></figure><p id="6048" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管当发烧被同一个麻省理工小组(Schuster等人)分析时。al)，他们发现它有某些偏见，这使得神经网络更容易通过使用文本中的模式来检测虚假文本。</p><p id="957f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当他们纠正数据集中的一些偏差时，他们发现模型的准确性如预期的那样下降了。</p><p id="0d56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，他们在GitHub 上开源了经过修正的数据集<a class="ae li" href="https://github.com/TalSchuster/FeverSymmetric" rel="noopener ugc nofollow" target="_blank"> Fever Symmetric，作为其他研究人员测试其模型的基准，我认为这对于积极试图解决神经假新闻问题的研究社区来说是一个很好的举措。</a></p><p id="3628" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你有兴趣了解更多关于他们的方法和实验，请随意阅读他们的原创论文<a class="ae li" href="https://arxiv.org/pdf/1908.05267.pdf" rel="noopener ugc nofollow" target="_blank">去偏见事实验证模型</a>。</p><p id="f90e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lw">因此，我认为创建大规模无偏数据集是未来研究方向的良好开端。</em></p><blockquote class="ks"><p id="e865" class="kt ku hi bd kv kw kx ky kz la lb jc dx translated"><em class="lc">这和过去几年我们在NLP (GLUE，SQUAD)和CV (ImageNet)中看到的一样。</em></p></blockquote><p id="8e3b" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">除此之外，还有一些我们可以进一步探索的方向:</p><ol class=""><li id="69ee" class="mc md hi ih b ii ij im in iq me iu mf iy mg jc nu mi mj mk bi translated">我们需要在这个方向上进行进一步的研究，<strong class="ih hj">改进现有的工具</strong>，不仅针对数据集，而且在<strong class="ih hj">真实世界的环境中</strong>对它们进行更多的验证。</li><li id="5247" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc nu mi mj mk bi translated">发烧数据集的发布是一个受欢迎的举措，它将有利于我们探索和<strong class="ih hj">建立更多这样的数据集</strong>。</li><li id="f9c9" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc nu mi mj mk bi translated">通过模型发现文本的准确性是一个具有挑战性的问题。因此，这方面的进一步研究是受欢迎的。</li><li id="5cb0" class="mc md hi ih b ii ml im mm iq mn iu mo iy mp jc nu mi mj mk bi translated">正如Grover和GLTR的作者正确提到的，我们需要通过在未来发布大型语言模型，如GPT-2、Grover等，来继续研究社区的开放性。</li></ol><p id="d8cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你以前处理过假新闻的问题吗？有没有尝试过建立一个识别神经假新闻的模型？</p><p id="4149" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你认为在考虑未来发展方向时，我们还需要关注其他领域吗？请在下面的评论中告诉我！</p></div><div class="ab cl nv nw gp nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="hb hc hd he hf"><p id="1c5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lw">原载于2019年12月16日</em><a class="ae li" href="https://www.analyticsvidhya.com/blog/2019/12/detect-fight-neural-fake-news-nlp/" rel="noopener ugc nofollow" target="_blank"><em class="lw">https://www.analyticsvidhya.com</em></a><em class="lw">。</em></p></div></div>    
</body>
</html>