<html>
<head>
<title>Spark 2.2.0 Dataframe Repartitioning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark 2.2.0数据帧重新分区</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spark-2-2-0-dataframe-repartitioning-b3943323d95b?source=collection_archive---------3-----------------------#2019-10-20">https://medium.com/analytics-vidhya/spark-2-2-0-dataframe-repartitioning-b3943323d95b?source=collection_archive---------3-----------------------#2019-10-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="0dff" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">讨厌的隐藏陷阱解释！</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/64fa4cb3623de6546fd0684a0f5032c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/0*WcIVhBRJ2efKzCxQ.jpg"/></div></figure><p id="ae3a" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">尽管Spark是一个非常聪明的数据处理引擎，并且将大数据开发人员从所涉及的分布式基础设施的所有本质细节中解放出来，但这里那里还是有一些需要明确处理的地方。其中之一就是分区。由于Spark通常将数据存储在节点集群的内存中，因此数据应该在机器之间保持平衡，否则性能会受到影响。想象一下，你在一个超级市场有10个收银员，90%的顾客去找其中一个，剩下的去找另外9个收银员。这不是一个健康的情况。</p><p id="b491" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Spark提供了几种在集群节点间公平分配数据的方法。这可以使用散列来完成，使得散列到相同键的所有行将进入相同的分区。还有处理输入数据有偏差情况的存储桶。我最近在Spark 2.2.0中遇到了一个令人讨厌的行为，它导致Spark作业运行非常缓慢，甚至可能根本无法完成。这个问题似乎是从2.3.0开始修复的，但我找不到吉拉问题特别提到这个问题。Spark 2.3.0 <a class="ae kb" href="https://spark.apache.org/releases/spark-release-2-3-0.html" rel="noopener ugc nofollow" target="_blank">发行说明</a>在“性能和稳定性”部分有一些关于重新分区的参考，所以它可能是处理我将在下面解释的问题的修复之一。</p><h2 id="952a" class="kc kd hi bd ke kf kg kh ki kj kk kl km jo kn ko kp js kq kr ks jw kt ku kv kw bi translated">准备输入数据</h2><p id="9ab3" class="pw-post-body-paragraph jf jg hi jh b ji kx ij jk jl ky im jn jo kz jq jr js la ju jv jw lb jy jz ka hb bi translated">假设我们有下面这个有一百万行的虚构数据帧。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lc"><img src="../Images/9a649bddd5d37f1ec0f58c5e0db24dc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4x2Oq7l2pNsw0hWI25a9Wg.png"/></div></div></figure><p id="b3f2" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">让我们定义一个小函数来打印出数据帧的分区信息。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lh"><img src="../Images/cae250aaa180dfd899d1bde3cbef5012.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*upDPyjXAAShxcKPWyp2VEw.png"/></div></div></figure><p id="13e0" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">根据集群中节点的数量和其他一些Spark配置，我们可能会得到不同的输出，但通常应该是一组记录数大致相等的分区。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es li"><img src="../Images/0ecd86572bf864277e4b340b8d56221e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zTE8y7P239RhuiznkEuQpg.png"/></div></div></figure><h2 id="ef21" class="kc kd hi bd ke kf kg kh ki kj kk kl km jo kn ko kp js kq kr ks jw kt ku kv kw bi translated">玩分区</h2><p id="4005" class="pw-post-body-paragraph jf jg hi jh b ji kx ij jk jl ky im jn jo kz jq jr js la ju jv jw lb jy jz ka hb bi translated">假设出于某种原因需要更多的分区，这可以使用<code class="du lj lk ll lm b">dataset.repartition</code>函数来实现，该函数有许多重载，但其中一个重载需要所需数量的分区。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ln"><img src="../Images/1affdc9643da0a9ddb4b50648af7441f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YYnBjZFRxJkGPHHD5RLm2g.png"/></div></div></figure><p id="98c4" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这很有意义，因为我们有8个分区，每个分区有125，000条记录，而不是2个分区，每个分区有50万条记录。但是让我们尝试一个没有任何参数的额外重载。实际上这不是很准确，我所说的重载采用可变长度参数，这意味着它可以接受零长度。以下是Spark 2.2.0所有<code class="du lj lk ll lm b">repartition</code>过载的一瞥。</p><pre class="iy iz ja jb fd lo lm lp lq aw lr bi"><span id="ded3" class="kc kd hi lm b fi ls lt l lu lv"><strong class="lm hj">def </strong>repartition(numPartitions: Int): Dataset[T]<br/><strong class="lm hj">def </strong>repartition(numPartitions: Int, partitionExprs: Column*): Dataset[T]<br/><strong class="lm hj">def </strong>repartition(partitionExprs: Column*): Dataset[T]</span></pre><p id="a97a" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在最后一个重载中，我们可以传递一个用于分区过程的列(或表达式)数组。Spark对这些列的值进行散列，然后对整数散列结果进行取模操作，将记录分配给正确的分区。那么，如果我们根本不传递任何列，会是什么情况呢？</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lw"><img src="../Images/6c53d3526f0071738adcf502b2e9d6c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YC_a-EyUa30UAaT4inr4qQ.png"/></div></div></figure><p id="26e3" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">嘣，简直是灾难。所有记录都被分配到一个分区中，所有其他分区都是空的。这可能会导致一些内存不足的异常，但这不是我所面临的问题。我有一个非常CPU密集的阶段，由于所有记录都被分配到一个分区，这导致了整个Spark作业的严重延迟。单个分区由单个执行器处理，这限制了可用于处理数据的CPU内核的数量。因此，即使没有抛出OOM异常，延迟也是不可接受的。</p><p id="33c0" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">另一个很酷的发现是上面截图中突出显示的分区号。它是42，这个数字在Spark中是非常独特的，因为它在许多地方被用作种子🌱</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lx"><img src="../Images/3d7e2624e5b1330bdcd2a4a08992dedd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_WeQiT8ZfLnzKSXzcdj3fQ.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ly"><img src="../Images/fcff98f1495bb10e9b9b58199a494f94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gW18BUSoRUBayWfrPHGkPg.png"/></div></div></figure><h2 id="42a0" class="kc kd hi bd ke kf kg kh ki kj kk kl km jo kn ko kp js kq kr ks jw kt ku kv kw bi translated">那么，为什么所有数据都在一个分区中呢？</h2><p id="a16d" class="pw-post-body-paragraph jf jg hi jh b ji kx ij jk jl ky im jn jo kz jq jr js la ju jv jw lb jy jz ka hb bi translated">回到我们的问题:这有点像猜测，但这是我的解释。当使用空列列表调用repartition时，这会导致所有记录散列到相同的值，该值实际上是默认种子。假设默认的分区数量(由Spark-SQL配置控制)大于42，那么所有记录都将存放在分区42中。即使该配置小于42，模数操作符也将为所有记录生成一个数字，这只是一个不同的分区Id。执行哈希运算的代码如下所示:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="0685" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这只是猜测，但是在第8行，如果children (columns参数)为空，那么while循环将永远不会进入，并且<strong class="jh hj"> eval </strong>函数的结果将始终是种子值。</p><p id="f639" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">作为双重检查，使用像person Id这样的唯一列进行分区可以在分区之间很好地分配记录。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es mb"><img src="../Images/87f978db651d7358d1908a553ea6608d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bJ-BV5TmyfYjNSeZqDIWHw.png"/></div></div></figure><p id="4d12" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对常量列进行同样的尝试会导致所有记录都位于一个分区中的相同问题。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es mc"><img src="../Images/bb820b5477cdb147bdb3f644f5a713ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n6V2FS46zr0hHr4Ij_k6KA.png"/></div></div></figure><h2 id="ed94" class="kc kd hi bd ke kf kg kh ki kj kk kl km jo kn ko kp js kq kr ks jw kt ku kv kw bi translated">我的2美分</h2><p id="56f6" class="pw-post-body-paragraph jf jg hi jh b ji kx ij jk jl ky im jn jo kz jq jr js la ju jv jw lb jy jz ka hb bi translated">升级到2.3或更高版本会很棒，但是最坏的情况是不要使用空列列表的重新分区，如果你使用一些列列表，确保它会导致分区间的平均分布。如果目标是在节点间均匀分布行，只需使用<code class="du lj lk ll lm b">dataset.repartition(rand())</code>。</p><h2 id="b3ea" class="kc kd hi bd ke kf kg kh ki kj kk kl km jo kn ko kp js kq kr ks jw kt ku kv kw bi translated">问题的症状</h2><p id="59ea" class="pw-post-body-paragraph jf jg hi jh b ji kx ij jk jl ky im jn jo kz jq jr js la ju jv jw lb jy jz ka hb bi translated">在帖子的最后列出问题症状很尴尬，但我查看了一些运行缓慢的作业的Spark历史，发现了一些值得分享的模式。</p><p id="295e" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">首先，当我们使用空表达式进行重新分区时，所有数据都位于单个分区中，这反映如下:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es md"><img src="../Images/eb457c11b889f3918a98b30c2ffd3aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4kmTX5sKm6Syv_SwbvTukg.png"/></div></div></figure><p id="b894" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这是一个运行时间过长的阶段，而且200个任务中有199个已经成功，只有一个任务尚未完成。您可以想象这199个任务是每个分区都没有记录的任务。这里的200是<code class="du lj lk ll lm b">spark.sql.shuffle.partitions</code>的默认值。</p><p id="e259" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">接下来，如果我们深入到运行时间最长的阶段，并根据持续时间对任务进行排序，很明显会有一个运行速度较慢的任务，它的神奇ID为42。所有其他任务都以成功状态完成。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es me"><img src="../Images/cb9155945f3b12157d5c7a3a8712c5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t8nUFUJ-sdvfE7Tn1JvJYA.png"/></div></div></figure><p id="8f64" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">以上是我们从Spark控制台/历史记录中检测此类问题的方法，以防由于偏斜或其他原因出现类似的模式。</p></div></div>    
</body>
</html>