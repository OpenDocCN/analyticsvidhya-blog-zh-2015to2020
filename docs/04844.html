<html>
<head>
<title>Creating Art Using AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用人工智能创造艺术</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/creating-art-using-ai-dcee46793028?source=collection_archive---------16-----------------------#2020-04-02">https://medium.com/analytics-vidhya/creating-art-using-ai-dcee46793028?source=collection_archive---------16-----------------------#2020-04-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="7e47" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">不需要画笔，只需要PyTorch</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/f2fe261feac1a1da9e3b2c1c0e123577.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qJfUGXZlusvHmY946V4u6w.jpeg"/></div></div></figure><p id="16d7" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">有了人工智能，你可以把两张图片合成一张新的，就像这样:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kf"><img src="../Images/5e969ea1076c48d5436e997a82ee7647.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qRYDkE0dqJIYkbUK2A3WwA.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">图像芝加哥结合雨公主画。</figcaption></figure><p id="6406" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这被称为风格转移，它的工作原理是采用一个图像的内容和另一个图像的风格，创建一个新的目标图像，它结合了以前图像的内容和风格。</p><p id="4f0c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">下面的解释和代码来自Udacity的<a class="ae kk" href="https://colab.research.google.com/drive/1rXkHKJzH9u2hs-OAqxDLNvotVxieg9S1" rel="noopener ugc nofollow" target="_blank">风格迁移练习笔记本</a>，来自他们的<a class="ae kk" href="https://www.udacity.com/course/deep-learning-pytorch--ud188" rel="noopener ugc nofollow" target="_blank">用Pytorch介绍深度学习课程</a>，是我最近完成的。我觉得这是一个很好的方式让人们开始使用风格转移的概念，并希望分享我用它创造的东西。</p></div><div class="ab cl kl km gp kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="hb hc hd he hf"><p id="4e43" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">风格转换可以使用PyTorch和预先训练好的<a class="ae kk" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> VGG19网络</a>中的功能来完成。该网络将彩色图像作为输入，并将其通过一系列卷积/池层，以及三个完全连接的层，这些层对传入的图像进行分类，并提取内容和风格特征。从这些特征中产生损失，以迭代地更新目标图像，直到获得期望的结果。</p><p id="b49c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为了实现这一点，网络将获取内容图像，通过前馈过程，直到它到达网络中的卷积层。该层的输出将是输入图像的内容表示。当它看到样式图像时，它将从不同的层获取代表图像样式的特征。最后，它将使用内容和样式表示来创建目标图像。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ks"><img src="../Images/06570797b44f48521df5e80704bb8fdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mb5QnG5cPQcsEoaghzXf4w.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">VGG19架构</figcaption></figure><p id="4381" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我用笔记本上的代码创作了我可爱的艺术作品，我将它命名为“着火了”<a class="ae kk" href="https://www.vox.com/2017/4/3/14685348/gudetama-sanrio-hello-kitty-explained" rel="noopener ugc nofollow" target="_blank"> <em class="kt"> Gudetama </em> </a> <em class="kt">！</em>'</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ku"><img src="../Images/549064e65406bf9399344af52fd02274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AsVh_yguefVdGBaZnnruDw.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">Gudetama着火了！</figcaption></figure><p id="e389" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">要开始，首先打开<a class="ae kk" href="https://colab.research.google.com/notebooks/intro.ipynb" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>，这样你就可以创建一个笔记本，而不用担心进口和使用他们的GPU。</p><p id="b536" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">导入适当的资源。</p><pre class="iy iz ja jb fd kv kw kx ky aw kz bi"><span id="d66c" class="la lb hi kw b fi lc ld l le lf">%matplotlib inline<br/>from PIL import Image<br/>from io import BytesIO<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import torch<br/>import torch.optim as optim<br/>import requests<br/>from torchvision import transforms, models</span></pre><p id="a0c0" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">加载预训练的VGG19网络。</p><pre class="iy iz ja jb fd kv kw kx ky aw kz bi"><span id="9828" class="la lb hi kw b fi lc ld l le lf"># use the convolutional and pooling layers to get the "features" <br/># portion of VGG19 <br/>vgg = models.vgg19(pretrained=True).features</span><span id="97d4" class="la lb hi kw b fi lg ld l le lf"># freeze all VGG parameters as we're only optimizing the target <br/># image<br/>for param in vgg.parameters():<br/>    param.requires_grad_(False)</span></pre><p id="6ff9" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">你应该知道这个:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lh"><img src="../Images/809e5af34473452ee42447c82e37edbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JTogqUlsElHEVOJ6yeQ7Bw.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">下载VGG19预训练模型。</figcaption></figure><p id="649b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您可以通过运行以下命令来查看VGG模型:</p><pre class="iy iz ja jb fd kv kw kx ky aw kz bi"><span id="f01d" class="la lb hi kw b fi lc ld l le lf"># move the model to GPU, if available (but since I'm using colab<br/># it doesn't really matter<br/>device = torch.device("cuda" if torch.cuda.is_available() else\ "cpu")</span><span id="ad36" class="la lb hi kw b fi lg ld l le lf">print (vgg)</span></pre><p id="5a52" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您应该得到这样的结果:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es li"><img src="../Images/b6ff70b004a531d757f62f75c5845db0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*uoRDaNclY1KGxFP7qoPedA.png"/></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">VGG网络的片段。</figcaption></figure><p id="ec10" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">将您的内容和风格图片上传到Colab。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lj"><img src="../Images/b50b8d778f4b2cbf0dd17908fcb12d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*C_DxkKP_3OoQfIqEHT0t8g.png"/></div></figure><p id="c3ef" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这个辅助函数将帮助你加载任何类型和大小的图像，并将它们转换成归一化张量。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="ac89" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">接下来，通过文件名加载图像。我们还将确保样式图像与内容图像的大小相同。</p><pre class="iy iz ja jb fd kv kw kx ky aw kz bi"><span id="4601" class="la lb hi kw b fi lc ld l le lf"># load in content and style image<br/>content = load_image('Gudetama.png').to(device)<br/># Resize style to match content, makes code easier<br/>style = load_image('Leaves.jpg',shape=content.shape[-2:]).to(device)</span></pre><p id="2947" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在，这个辅助函数将用于对图像进行非归一化处理，并将其从张量图像转换为numpy图像以供显示。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="41db" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们展示我们的内容和风格图像！</p><pre class="iy iz ja jb fd kv kw kx ky aw kz bi"><span id="beca" class="la lb hi kw b fi lc ld l le lf"># display the content and style images side-by-side<br/>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))<br/>ax1.imshow(im_convert(content))<br/>ax2.imshow(im_convert(style))</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lm"><img src="../Images/d4cc013695fd0671148be2d748603dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*25_jErZ_1EQIu1cK2kcV2g.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">显示我们的内容和样式图像。</figcaption></figure><p id="a563" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们现在可以通过VGG19网络传递一个图像，以获取它的内容和样式表示。这是重复的，直到我们得到我们想要的层和输出。</p><p id="d263" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">接下来，下面的函数将图层名称映射到VGG19网络中的名称，我们用它来获取内容和样式表示。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="987e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">下面是一个得到一个卷积层的<a class="ae kk" href="https://en.wikipedia.org/wiki/Gramian_matrix" rel="noopener ugc nofollow" target="_blank">克矩阵</a>的计算的函数。</p><pre class="iy iz ja jb fd kv kw kx ky aw kz bi"><span id="1c25" class="la lb hi kw b fi lc ld l le lf">def gram_matrix(tensor):<br/>    ## get the batch_size, depth, height, and width of the Tensor<br/>    _, d, h, w = tensor.size()<br/>    <br/>    # reshape so we're multiplying the features for each channel<br/>    tensor = tensor.view(d, h * w)</span><span id="1cb8" class="la lb hi kw b fi lg ld l le lf">    # calculate the gram matrix<br/>    gram = torch.mm(tensor, tensor.t())</span><span id="1fb9" class="la lb hi kw b fi lg ld l le lf">    return gram</span></pre><p id="3b52" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">通过编写这些函数，我们可以从图像中提取特征，并计算样式表示中每一层的gram矩阵。</p><pre class="iy iz ja jb fd kv kw kx ky aw kz bi"><span id="67a1" class="la lb hi kw b fi lc ld l le lf"># get content and style features only once before forming the target # image<br/>content_features = get_features(content, vgg)<br/>style_features = get_features(style, vgg)</span><span id="60bd" class="la lb hi kw b fi lg ld l le lf"># calculate the gram matrices for each layer of our style <br/># representation<br/>style_grams = {layer: gram_matrix(style_features[layer]) for layer\ in style_features}</span><span id="e20a" class="la lb hi kw b fi lg ld l le lf"># create a third "target" image and prep it for change<br/># it is a good idea to start off with the target as a copy of our <br/># *content* image then iteratively change its style<br/>target = content.clone().requires_grad_(True).to(device)</span></pre><h2 id="2a41" class="la lb hi bd ln lo lp lq lr ls lt lu lv js lw lx ly jw lz ma mb ka mc md me mf bi translated">内容样式和权重</h2><p id="358b" class="pw-post-body-paragraph jj jk hi jl b jm mg ij jo jp mh im jr js mi ju jv jw mj jy jz ka mk kc kd ke hb bi translated">可以为每个相关层的样式表示赋予权重(范围在0到1之间)。通过给第一层(<code class="du ml mm mn kw b">conv1_1</code>和<code class="du ml mm mn kw b">conv2_1</code>)更大的权重，你可以期望在最终的目标图像中得到更大的风格特征。将权重添加到后面的层，将导致目标图像上的特征变小。</p><p id="a343" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><code class="du ml mm mn kw b">content_weight</code>和<code class="du ml mm mn kw b">style_weight</code>将影响你最终图像的风格化程度。建议将<code class="du ml mm mn kw b">content_weight</code>设为1，并根据您想要的目标图像风格设置<code class="du ml mm mn kw b">style_weight</code>。</p><pre class="iy iz ja jb fd kv kw kx ky aw kz bi"><span id="128b" class="la lb hi kw b fi lc ld l le lf"># weights for each style layer<br/># weighting earlier layers more will result in *larger* style <br/># features<br/>style_weights = {'conv1_1': 1.,<br/>                 'conv2_1': 0.8,<br/>                 'conv3_1': 0.5,<br/>                 'conv4_1': 0.3,<br/>                 'conv5_1': 0.1}</span><span id="a4e1" class="la lb hi kw b fi lg ld l le lf">content_weight = 1  <br/>style_weight = 1e6  </span></pre><h2 id="a6ab" class="la lb hi bd ln lo lp lq lr ls lt lu lv js lw lx ly jw lz ma mb ka mc md me mf bi translated">更新目标和计算损失</h2><p id="929e" class="pw-post-body-paragraph jj jk hi jl b jm mg ij jo jp mh im jr js mi ju jv jw mj jy jz ka mk kc kd ke hb bi translated">我们现在将创建一个迭代循环来计算内容和样式损失，这将只更新目标图像。这将通过将样式和内容损失相加并用您指定的<code class="du ml mm mn kw b">content_weight</code> &amp; <code class="du ml mm mn kw b">style_weight</code>进行加权来产生总损失。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="6cd9" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">你可以看到你的目标形象改变了！</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mo"><img src="../Images/6d0e1a45b5db6631d8e85ad98321b953.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*UDbhjs9-aPQO0ImnVWTZWw.png"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mp"><img src="../Images/7198757ddee1463a96c3a9c7404e7104.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*f_Nf5-cuBYwOMU0rYSXe3w.png"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mp"><img src="../Images/6aacd56ae10565fa01e962b24d977ab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*LyPnhM74ERAWkmKiRKOQBw.png"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mq"><img src="../Images/758b744acbee7b512b0f269259d1b403.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*_Gxw0XpL4mdqdQqAHyD5HA.png"/></div></figure><h2 id="59c1" class="la lb hi bd ln lo lp lq lr ls lt lu lv js lw lx ly jw lz ma mb ka mc md me mf bi translated">显示最终结果</h2><pre class="iy iz ja jb fd kv kw kx ky aw kz bi"><span id="8074" class="la lb hi kw b fi lc ld l le lf"># display content and final target image<br/>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))<br/>ax1.imshow(im_convert(content))<br/>ax2.imshow(im_convert(target))</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lm"><img src="../Images/0536191ccb81909f698102cfba5268c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*my9eHON7xmI7yVYd-Rvcng.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">内容图像与目标图像</figcaption></figure></div><div class="ab cl kl km gp kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="hb hc hd he hf"><p id="71f6" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">感谢您的阅读，我希望您在阅读过程中感到愉快！</p><p id="401b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">小时候我上过艺术课，但我一直认为艺术不重要，没有用处。随着年龄的增长，我开始更多地欣赏艺术，并发现风格转移很有趣，因为它可以让人工智能创造艺术。我相信人工智能也可以从零开始创造艺术，而不需要结合图像，我期待着更多地探索这个主题！</p><p id="ae4d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果您有任何问题或意见，请在下面留下您的反馈。你也可以在社交媒体<a class="ae kk" href="https://linktr.ee/oscarkwok" rel="noopener ugc nofollow" target="_blank">这里</a>和我联系。</p></div></div>    
</body>
</html>