<html>
<head>
<title>Meet the Spark MLlib’s Multilayer Perceptron Classifier (MLPC) — Hands-on</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">亲身体验Spark MLlib的多层感知器分类器(MLPC)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spark-mllibs-multilayer-perceptron-classifier-mlpc-hands-on-32ac4014eee9?source=collection_archive---------3-----------------------#2019-12-11">https://medium.com/analytics-vidhya/spark-mllibs-multilayer-perceptron-classifier-mlpc-hands-on-32ac4014eee9?source=collection_archive---------3-----------------------#2019-12-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/908d57d1a52a45d757d93621e27cba86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g8xBL4mAaof3CK0TZXcYgQ.jpeg"/></div></div></figure><div class=""/><p id="4e92" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我的<a class="ae jo" rel="noopener" href="/data-science-simplified/simplified-guide-to-hidden-layer-neural-networks-by-dl-practitioner-with-python-code-4e498504716b">上一篇文章</a>中，我已经介绍并讨论了隐层神经网络(HNN)的架构。MLlib基于相同的架构实现其多层感知器分类器(MLPC)。有多层节点，每层都是完全连接的。具有权重和偏差的节点的线性组合被输入到激活函数中，并且可以表示如下:</p><figure class="jq jr js jt fd hk er es paragraph-image"><div class="er es jp"><img src="../Images/e45443545fd13f9354277612f7364000.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*URgFWmuVyOrOJUmIkJ5Ufg.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">前馈公式(<a class="ae jo" href="https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6" rel="noopener" target="_blank">来源</a></figcaption></figure><blockquote class="jy jz ka"><p id="c1c7" class="iq ir kb is b it iu iv iw ix iy iz ja kc jc jd je kd jg jh ji ke jk jl jm jn hb bi translated">隐藏层使用<strong class="is hu"> sigmoid </strong> <em class="ht">激活函数</em>，而输出层使用<strong class="is hu"> softmax </strong> <em class="ht">激活函数</em>来计算输出。逻辑损失函数用于在反向支持学习期间优化权重和偏差。提供的输入数量等于特征向量，输出数量等于标签总数。</p></blockquote><h1 id="1838" class="kf kg ht bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">MLlib类定义和参数:</h1><p id="7244" class="pw-post-body-paragraph iq ir ht is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated"><strong class="is hu"> <em class="kb">多层感知器分类器</em>对于任何机器学习算法，都有几个称为“超参数”的参数，微调它们有助于提高模型的准确性。对于多层感知器分类器，以下参数用于超参数的目的:</strong></p><ul class=""><li id="d8f2" class="li lj ht is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated"><strong class="is hu"> tol: </strong>收敛容差描述了那些开始向产生正确结果的输出收敛的权重集。默认值为<em class="kb"> 1e-06。</em>较小的值产生更精确的结果，而较大的值可能导致过度拟合。</li><li id="6e9e" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hu"> seed: </strong>这是一个随机种子值，将使用它来生成随机数。提供该值可确保生成真正的随机数。该参数确保每次测试算法时产生相同的随机值<strong class="is hu"> </strong>。</li><li id="2098" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hu">层:</strong>该参数接受代表输入、隐藏和输出层的整数列表。格式如下[780，200，100，10] 780表示输入值的个数，200和100表示隐藏层，10表示输出层。更多的隐藏层将使神经网络更复杂，但不能确保更高的精度。</li><li id="d8c3" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hu"> blockSize: </strong>它是每次迭代中要包含的输入的数量。例如，blockSize = 100意味着在算法的一次迭代中要包括100个输入。默认值为128。较小的块大小以延长学习时间为代价提高了精度，反之亦然。</li><li id="3db4" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hu">步长:</strong>这是算法的学习速率，通常在0.0到1.0之间。基本上就是模型学习的快慢。默认值为0.03。较小的值可以提高精度，而较大的值会导致过度拟合。</li><li id="b840" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hu">解算器:</strong>该参数指定应使用哪个优化程序来寻找局部最小值，如梯度下降。默认值为l-bfgs。</li></ul><h1 id="dd4f" class="kf kg ht bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">代码示例:</h1><p id="04ee" class="pw-post-body-paragraph iq ir ht is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">在这一节中，我们将看到<a class="ae jo" href="https://github.com/ahmed141/my-code-rep/blob/master/Python/Machine%20Learning/pySpark/MLlib-mlpc-medium.ipynb" rel="noopener ugc nofollow" target="_blank">一个使用样本数据制作多层感知器分类器的例子</a>。</p><p id="fe03" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们需要导入以下模块来启动spark会话，构建和训练模型，并最终评估模型。</p><figure class="jq jr js jt fd hk"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="d874" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">初始化一个spark会话，并加载<em class="kb"> libsvm </em>格式的样本数据。然后将数据分成7:3比例的训练集和测试集。</p><figure class="jq jr js jt fd hk"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="9cd0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">样本数据集有四个输入要素和三个输出类。在我们的实验中，我们将通过改变不同的超参数来构建如图所示的DNN，并分析它们的效果。</p><figure class="jq jr js jt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ly"><img src="../Images/dae6d248269a959bdd36be397db27cf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnHS6UvgzgFtBqVxcITHcQ.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated"><strong class="bd kh">图:</strong>示例中使用的示例架构，具有四个输入特性和三个输出类(<a class="ae jo" href="https://hackernoon.com/everything-you-need-to-know-about-neural-networks-8988c3ee4491" rel="noopener ugc nofollow" target="_blank">源</a>)</figcaption></figure><p id="5b2a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面的代码片段是pyspark中这样一个模型的实现，有两个隐藏层，分别是5个和6个神经元。</p><figure class="jq jr js jt fd hk"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="546b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，返回一个经过训练的MLPC模型，准备对测试数据进行评估。使用<em class="kb">多类分类评估器</em>对模型进行测试，以<em class="kb">准确度</em>作为评估标准<em class="kb">。</em></p><figure class="jq jr js jt fd hk"><div class="bz dy l di"><div class="lw lx l"/></div></figure><h2 id="6ba8" class="lz kg ht bd kh ma mb mc kl md me mf kp jb mg mh kt jf mi mj kx jj mk ml lb mm bi translated">实验:</h2><p id="80b0" class="pw-post-body-paragraph iq ir ht is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">通过改变层数和求解器(优化)方法进行了三个实验。这些实验的结果在下表中给出。</p><figure class="jq jr js jt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mn"><img src="../Images/7c1d0f59df912af4b6df93ad7d93ef0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y9sf21JuVlhBXJZGv2TPBA.jpeg"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">表:MLPC超参数调整实验的结果，绿色突出显示为性能最佳的配置。</figcaption></figure><p id="1bb1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上表中我们可以观察到，性能最好的模型是具有l-bfgs优化器且只有一个隐藏层的模型，添加另一个隐藏层会使评估结果更差。这是因为对于这个特定的数据，模型开始过度拟合训练数据，从而在测试集上表现不佳。因此，从这些实验中可以得出一个重要的结论:增加更多的隐藏层并不总是有帮助的。</p><h1 id="6e3d" class="kf kg ht bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">为什么要用PySpark的MLlib？</h1><p id="aaaf" class="pw-post-body-paragraph iq ir ht is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">尽管有其他可用的框架可用于在实际意义上实现机器学习。MLlib提供了一些附加的功能，这些功能在大多数浏览器中是没有的。</p><p id="39bb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">MLlib的一些主要功能如下:</p><ul class=""><li id="d519" class="li lj ht is b it iu ix iy jb lk jf ll jj lm jn ln lo lp lq bi translated">它支持许多著名的ML算法:支持的常见学习算法包括分类、回归、聚类和协同过滤。</li><li id="85c1" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hu">高效轻松的特征化</strong>:特征提取、变换、降维、选择。</li><li id="0a74" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hu">管道支持:</strong>这些是用于构建、评估和调优ML管道的工具。</li><li id="a229" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hu">持久化:</strong>保存和加载算法、模型和管道。</li><li id="23fb" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated">支持常用的工具:线性代数、统计、数据处理等。</li><li id="ecd8" class="li lj ht is b it lr ix ls jb lt jf lu jj lv jn ln lo lp lq bi translated"><strong class="is hu">可伸缩性(轻松处理大量数据):</strong>PySpark的分布式特性，支持在集群和<strong class="is hu">分布式</strong>方式中处理大量数据，快速高效。</li></ul><h1 id="367d" class="kf kg ht bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">为什么要用MLlib的MLPC:</h1><p id="8c7f" class="pw-post-body-paragraph iq ir ht is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">有了MLlib中绝大多数可供使用的机器学习算法，人们可能会问哪一个更好。每种模型都有其优点和缺点，使用特定的模型在很大程度上取决于手头的问题。以下是使用MLlib的MLPC的一些优点:</p><p id="290f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用MLPC最普遍的特点是它可以自己找到特征之间的关系。另一个优点是，它可以有任意数量的输出，可以一次训练一个n数组分类器，而支持向量机只有一个。MLPC也是固定大小的，因为它们是参数化的，而支持向量机是非参数化的。有了足够大和多样化的数据集，MLPC可以比SVM和决策树更准确。此外，它可以处理在线数据，即如果新数据不断到来，MLPC可以更新，而决策树将需要重新训练。</p></div></div>    
</body>
</html>