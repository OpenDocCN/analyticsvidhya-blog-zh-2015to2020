<html>
<head>
<title>Model Selection Techniques — Part 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型选择技术—第3部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/model-selection-techniques-part-3-d5ebb6ea4c77?source=collection_archive---------19-----------------------#2020-09-13">https://medium.com/analytics-vidhya/model-selection-techniques-part-3-d5ebb6ea4c77?source=collection_archive---------19-----------------------#2020-09-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/af2f348004467b0db85652a1c8ce4869.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6asJUcMzK6gXTs-IUvTGqg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由昆泰·德威迪拍摄</figcaption></figure><p id="8074" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这么久，我们经历了不同的<a class="ae js" rel="noopener" href="/@kountaydwivedi/different-model-evaluation-methodologies-part-2-679fcb064c55"> <strong class="iw hj">模型评估技术(第二部分)</strong> </a>，我们已经看到了<a class="ae js" rel="noopener" href="/@kountaydwivedi/why-is-model-evaluation-a-crucial-step-in-machine-learning-part-1-eeb4882e7c8a"> <strong class="iw hj">基本概念</strong>需要<strong class="iw hj">(第一部分)</strong> </a>。</p><p id="5153" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在让我们进入故事的最后一部分— <strong class="iw hj">模型选择技术。</strong></p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><blockquote class="ka"><p id="9c53" class="kb kc hi bd kd ke kf kg kh ki kj jr dx translated">回顾:超参数的需求</p></blockquote><ul class=""><li id="dd24" class="kk kl hi iw b ix km jb kn jf ko jj kp jn kq jr kr ks kt ku bi translated">如本<a class="ae js" href="https://arxiv.org/abs/1811.12808" rel="noopener ugc nofollow" target="_blank">论文</a>所述，<strong class="iw hj"> <em class="kv">超参数</em> </strong>(如历元数、正则化参数等。)是学习算法用来计算最佳<strong class="iw hj"> <em class="kv">模型参数的变量。</em> </strong>它们需要由实验者先验地、外在地加以规定。</li><li id="16b6" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">超参数不受任何固定协议或算法的控制。实验者或数据科学家需要用完全的试凑法彻底探索，以便为这些变量找到合适的值。</li><li id="98a8" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">现在，需要注意的一点是，当我们改变超参数值时，我们会得到一个新的模型表现。因此，<strong class="iw hj"> <em class="kv">在所有这些模型中找出最佳模型的过程称为模型选择。</em>T25】</strong></li><li id="ca32" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated"><strong class="iw hj"> <em class="kv">模型选择</em> </strong>无非是<strong class="iw hj"> <em class="kv">超参数优化过程。</em> </strong>由于我们选择了适当的超参数，这间接意味着我们正在探索超参数的值，这将有助于算法找到最佳的模型参数，这是模型拟合的全部要点！</li></ul></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><blockquote class="ka"><p id="8b6a" class="kb kc hi bd kd ke kf kg kh ki kj jr dx translated">模型选择技术</p></blockquote><blockquote class="lb lc ld"><p id="f696" class="iu iv kv iw b ix km iz ja jb kn jd je le lf jh ji lg lh jl jm li lj jp jq jr hb bi translated"><strong class="iw hj">三路保持方法</strong></p></blockquote><ul class=""><li id="17d0" class="kk kl hi iw b ix iy jb jc jf lk jj ll jn lm jr kr ks kt ku bi translated">我们已经研究了伟大的<strong class="iw hj">保持方法。</strong>有没有可能把它的思路也延伸到型号选择上？让我看看。</li><li id="32e6" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">在维持方法中，我们通常将数据集分为两部分—训练集和测试集。这已经完成了，所以我们可以先验地获得一些看不见的数据，然后我们可以根据这些数据来评估我们的模型的性能。</li><li id="23f5" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">如果我们<strong class="iw hj">进一步将训练集</strong>分成2个子部分——一个训练集和一个验证集。这个训练集将用于拟合我们的模型(像往常一样)，测试集将是我们评估拟合模型的性能的测试集(也像往常一样)。但是<strong class="iw hj">这个</strong>的验证集是什么？</li><li id="71c3" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">这个<strong class="iw hj">验证集</strong>实际上是用来选择最佳模型的。使用验证集，我们将优化超参数，从而选择最合适的值，为我们提供最佳的模型参数(从而获得最佳的模型性能)。我们将在各种超参数值上运行算法，并且我们将在验证集上评估模型的性能(考虑所有这些值)。我们获得最大性能的值将最终被选择。</li><li id="6448" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated"><strong class="iw hj"> <em class="kv">因此，我们比较模型的性能估计，并选择有助于最大性能的最佳超参数值。</em> </strong></li><li id="77d5" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">随后，我们合并训练集和验证集，以消除任何悲观偏见(由于缺乏数据集而导致)。我们再次使用这个合并的集合和获得的超参数值来拟合模型。</li><li id="4886" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">最后，我们使用单独保存的测试集来评估模型的性能。</li><li id="dc79" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">或者，我们可以将训练集、验证集和测试集合并在一起，以便获得最大的可用数据集。</li></ul><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/a3e41cc1c74b451d1917a988c3efd32e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V-Yl-duO4fcUn6rsCRqDyQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">用于型号选择的三路保持方法流程图(照片由Kountay Dwivedi提供)</figcaption></figure><blockquote class="lb lc ld"><p id="2154" class="iu iv kv iw b ix iy iz ja jb jc jd je le jg jh ji lg jk jl jm li jo jp jq jr hb bi translated"><strong class="iw hj">k<em class="hi">-折叠交叉验证</em>方法</strong></p></blockquote><ul class=""><li id="0350" class="kk kl hi iw b ix iy jb jc jf lk jj ll jn lm jr kr ks kt ku bi translated">可以说，在数据集不足的情况下，这是最有效的模型选择方法。</li><li id="77a0" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">关键思想是:<br/> <strong class="iw hj">给每个数据例子一个测试的机会。</strong></li><li id="fee9" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">一个伪代码程序如下:<br/> For <strong class="iw hj"> <em class="kv"> k </em> </strong>迭代次数:<br/> <strong class="iw hj"> <em class="kv"> **步骤1: </em> </strong>将数据集分成<strong class="iw hj"> <em class="kv"> k </em> </strong>部分。保留一部分用于测试，合并剩余的<strong class="iw hj"> <em class="kv"> k </em> </strong> -1部分用于训练。<br/> <strong class="iw hj"> <em class="kv"> **步骤2: </em> </strong>使用合并的训练集和任何适当的学习算法来拟合模型。<br/> <strong class="iw hj"> <em class="kv"> **第三步:</em> </strong>模型拟合后，在独立测试集上评估其性能，并计算性能准确度得分。<br/> <strong class="iw hj"> <em class="kv"> **第四步:</em> </strong>存储这个准确率分数。</li><li id="acf5" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">在<strong class="iw hj"> <em class="kv"> k </em> </strong>次迭代后，计算最终准确度，作为所有存储的准确度分数的平均值<strong class="iw hj"> <em class="kv">。</em>T55】</strong></li></ul><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/38c17df7f0c0b4a39eb0d1fbbbd72bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n1QYaO5t_RsrIxe2t5is8w.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ls"> <em class="lt"> k倍交叉验证</em> </strong> <em class="lt">与</em><strong class="bd ls"><em class="lt">k = 4</em></strong><em class="lt">流程图(Kountay Dwivedi拍摄)</em></figcaption></figure><ul class=""><li id="6e04" class="kk kl hi iw b ix iy jb jc jf lk jj ll jn lm jr kr ks kt ku bi translated"><strong class="iw hj"><em class="kv">【k】</em></strong>-Fold CV看起来像重复保持方法，但实际上，<strong class="iw hj">b/w<em class="kv">k</em>-Fold CV和重复保持方法的区别在于，在前一种方法中，测试集从不重叠，而在后一种方法中，它们有时可能会重叠。</strong>正如我们所知，<strong class="iw hj"> <em class="kv"> k- </em> Fold CV </strong>承诺每个数据点成为一个测试点，因此，它也不同于简单的维持方法，在简单的维持方法中，由于单次迭代，所有的数据点都没有机会得到测试。</li><li id="29fa" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated"><strong class="iw hj">两种特殊情况的<em class="kv">k</em>——折CV: </strong> <br/> <strong class="iw hj"> <em class="kv"> ** 2折CV: </em> </strong>这相当于简单的<strong class="iw hj">墨守法，</strong>自<strong class="iw hj"> <em class="kv"> k= </em> 2 </strong>。但是有一个条件:应该通过在第二次迭代中轮换训练集和验证集来执行两次。<br/> <strong class="iw hj"> <em class="kv"> **留一法交叉验证(LOOCV): </em> </strong>当<strong class="iw hj"><em class="kv">【k】</em>= n</strong>时，即折叠数设为训练样本数，则称为<strong class="iw hj"><em class="kv"/></strong>。如果训练集的大小非常大，这在计算上可能是昂贵的。假设我们在训练集中有一千个数据点。那么在LOOCV，迭代的次数将是1000，并且在每次迭代中，将有1个测试点和999个训练数据点。这也是为什么<strong class="iw hj"> LOOCV方差很高而偏差</strong>很低的原因；因为不存在训练集的不足(因此，偏差被消除)，但是明显缺乏未看到的/测试数据，正好1个测试点(引入了高方差)。<br/>如果我们看流程图(如上)，我们就能非常清楚地理解LOOCV。它用一个规模为4的训练集说明了LOOCV方法。</li><li id="ac0a" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">下面是<strong class="iw hj"><em class="kv">k</em>-折叠交叉验证的一些常见趋势的实现:</strong></li></ul><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/32dc3abffdcb1d1479c1778503182401.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*AXSyJi7IYJM5LcW6RUs8JQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图示<strong class="bd ls">二折CV。</strong>注意平均准确度分数。(Kountay Dwivedi摄)</figcaption></figure><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/9f822061a2978cdcb7ba21adb4d34481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*6d2bkMHbO1VFxkO0Aa2lug.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">用<strong class="bd ls"> k = 10 </strong>说明<strong class="bd ls"> k倍CV</strong>(koun tay DWI vedi摄影)</figcaption></figure><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/c8c863837dea3f7e3c0b6d97a2245b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fZgyBq1pWvZG1Ui9R7Ct6A.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">用数据集的<strong class="bd ls"> k = </strong> <strong class="bd ls">大小来说明<strong class="bd ls"> LOOCV </strong>。注意LOOCV的准确性是三者中最高的。但需要记住的一点是，数据集越大，LOOCV就越耗时。因此，当数据集很大时，不建议使用<strong class="bd ls"> k倍</strong>。(Kountay Dwivedi摄)</strong></figcaption></figure><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/46d3ce768338b90a898def057056a4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*PMq6oTtt82UIMOXu_FR_Pg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">我们可以看到，虽然准确性得分最高的是LOOCV，但在前一幅图像中，所用的时间约为。<strong class="bd ls"> 3分钟</strong>，而在后一张图片中只花了<strong class="bd ls"> 2秒</strong>！！我们得到这种结果是由于数据集的大小</figcaption></figure><ul class=""><li id="052b" class="kk kl hi iw b ix iy jb jc jf lk jj ll jn lm jr kr ks kt ku bi translated">经验表明，<strong class="iw hj"> k的最佳值是10(“最佳点”)。</strong>但是，应注意数据集的大小。</li></ul><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/cfe72eba5cfb2b66c2f4b98dfc42f54a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*YIqzq56VscNKbs58puWy8g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">这是取自<a class="ae js" href="https://arxiv.org/abs/1811.12808" rel="noopener ugc nofollow" target="_blank">论文</a>的图像。它显示了不同的模型评估和选择过程如何将数据集分割成训练/测试集。注意在<strong class="bd ls">重复维持中，</strong>测试集是如何重叠的，不像<strong class="bd ls"> k-Fold CV </strong>(图片来源:Sabastian Raschka)</figcaption></figure><ul class=""><li id="5511" class="kk kl hi iw b ix iy jb jc jf lk jj ll jn lm jr kr ks kt ku bi translated"><strong class="iw hj"> <em class="kv">通过k-Fold CV进行模型选择:<br/> **第一步:</em> </strong>类似于三向维持方法，将数据集分成两部分——训练集和测试集。进一步将训练集分为训练集和验证集。<br/> <strong class="iw hj"> <em class="kv"> **第二步:</em> </strong>尝试各种超参数值。对于每个超参数配置，在训练集上应用<strong class="iw hj"> <em class="kv"> k </em> -Fold CV </strong>方法，拟合模型并在验证集上验证其性能。这将导致多个模型和性能评估。最后，选择产生最佳模型的超参数值。<br/> <strong class="iw hj"> <em class="kv"> **步骤3: </em> </strong>采用在上面的<strong class="iw hj"><em class="kv">k</em>-折叠CV </strong>过程中产生最佳结果的超参数设置，合并训练和验证集，并最终使用该合并的训练集以及所获得的超参数和模型参数值来拟合模型。<br/> <strong class="iw hj"> <em class="kv"> **步骤4: </em> </strong>现在，对<strong class="iw hj"> <em class="kv">步骤1中保留的独立测试集进行模型评估。<br/> **步骤5: </em> </strong>可选地，将完整的测试集与训练集合并以避免任何悲观偏见，并在完整的可用数据集上拟合最终模型。</li></ul></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><blockquote class="ka"><p id="6211" class="kb kc hi bd kd ke kf kg kh ki kj jr dx translated">摘要</p></blockquote><ul class=""><li id="26d4" class="kk kl hi iw b ix km jb kn jf ko jj kp jn kq jr kr ks kt ku bi translated">维持方法通常被认为是基于K-Fold CV，尤其是在今天的人工智能世界中。为什么？</li><li id="596b" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">我们仍然缺乏庞大的数据集，但我们有大量的数据，像数百万和数十亿。随着时间的推移，解决机器学习问题的新算法和方法每时每刻都在增长。例如<strong class="iw hj">深度神经网络，生成对抗算法</strong>等。这些算法旨在解决非常大的问题，因此需要花费大量时间进行模型拟合。</li><li id="a277" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">因此，我们无法承受在整个数据集上重复<strong class="iw hj"> k </strong>次。其中一些模型甚至需要几周的时间来优化。因此，使用<strong class="iw hj"> <em class="kv"> k- </em> Fold CV </strong>进行庞大数据集和复杂算法的模型拟合实际上是不可行的。</li><li id="eb93" class="kk kl hi iw b ix kw jb kx jf ky jj kz jn la jr kr ks kt ku bi translated">此外，正如我们已经看到的，从理论上讲，大型数据集有益于模型的性能。假设我们的数据集中有一百万个数据点。因此，在这种情况下，如果我们将数据集划分为70/30比率或80/20比率，这根本不会损害性能，因为我们将有足够的训练数据点来使模型适应其容量，以及足够的测试数据点来适当地评估模型的性能。因此，我们将实际关注<strong class="iw hj">大型数据集和维持方法的偏差和方差问题</strong>。</li></ul></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><blockquote class="ka"><p id="9930" class="kb kc hi bd kd ke kf kg kh ki kj jr dx translated">结论</p></blockquote><p id="fad8" class="pw-post-body-paragraph iu iv hi iw b ix km iz ja jb kn jd je jf lf jh ji jj lh jl jm jn lj jp jq jr hb bi translated">因此，我们终于结束了这个关于<strong class="iw hj">模型评估和模型选择概念和技术的3部分故事。</strong>这一步在建立模型时非常关键，因为如果我们不调整我们的模型参数，如果我们不选择最合适的超参数值，那么我们可能会以<strong class="iw hj"> <em class="kv">不太好的模型结束。</em>T13】</strong></p><p id="71d7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们看到了不同的<strong class="iw hj"> <em class="kv">模型评估方法</em> </strong>，从简单的<strong class="iw hj">替代方法开始，</strong>由于其过拟合的性质，不推荐使用。然后，我们研究了<strong class="iw hj">维持方法</strong>的不同方面(最适合大型数据集)。之后，我们看了看<strong class="iw hj"> Bootstrap方法</strong>背后的直觉，以及它的变体<strong class="iw hj"> LOOB(省去一个Bootstrap)。</strong>使用<strong class="iw hj">采样和替换</strong>来建立我们自己的数据集是一个很棒的想法，但由于计算效率低，只能用于小数据集。</p><p id="9239" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后我们来到<strong class="iw hj"> <em class="kv">型号选择标准</em> </strong>，在这里我们看一下<strong class="iw hj">三路维持方法</strong>，一种简单维持方法的扩展，用于型号选择。这里，我们将数据分成3个部分——训练集、验证集和测试集。最后，我们看了最有前景的方法，<strong class="iw hj"><em class="kv">-</em>交叉折叠验证，</strong>广泛用于小型数据集，因为它可以处理任何类型的悲观偏差以及方差问题。但是我们也认为它的缺点是<strong class="iw hj"> </strong> — <strong class="iw hj">如果在大型数据集上使用，计算量非常大。</strong></p><p id="c16a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我希望你们真的喜欢这个故事，并且它符合你们的期望。请以任何你喜欢的方式支持我，这样我会有越来越多的动力去进步。谢谢大家。敬请关注，学习愉快。😊</p><p id="517e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi">:-}</p></div></div>    
</body>
</html>