<html>
<head>
<title>Linear Regression: A complete story</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归:完整的故事</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-a-complete-story-c5edd37296c8?source=collection_archive---------9-----------------------#2020-01-12">https://medium.com/analytics-vidhya/linear-regression-a-complete-story-c5edd37296c8?source=collection_archive---------9-----------------------#2020-01-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="e49e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">关于回归分析你需要知道的一切。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/24aa6fda806a6415c41cf1ed50e9332f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s2ty0_VKlrL4wXB3--6f1g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://internationalsales.lexisnexis.com/hk/image/Predictive-Analytics.png" rel="noopener ugc nofollow" target="_blank">https://international sales . lexisnexis . com/hk/image/Predictive-analytics . png</a></figcaption></figure><p id="c12c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">线性回归是预测分析领域中广泛使用的最简单的机器学习算法之一。这种方法多用于预测和找出变量之间的因果关系。它是一个线性模型，即假设因变量(Y)和一个或多个自变量(X)之间存在线性关系。在这种技术中，因变量是连续的，自变量可以是连续的或离散的，回归线的性质是线性的。</p><p id="7533" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">该算法属于监督学习，即训练数据集中因变量的值是已知的。</p><p id="52b2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">线性回归模型在所有领域都有许多实际应用，例如预测零售业的销售额、预测房地产的房价、预测气象学中的天气、预测金融中的股票价格、预测医疗保健中生物因素引发的疾病等。因此，理解模型背后的直觉以及如何实现它将有助于我们解决预测分析中的问题。</p><p id="b57e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">目录:</strong></p><p id="7aa7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">1.线性回归假设</p><p id="d111" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">2.模型背后的数学</p><ul class=""><li id="7d4f" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj kp kq kr ks bi translated">2.1.简单线性回归</li><li id="b92b" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated">2.2多元线性回归</li></ul><p id="fcde" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">3.评估指标</p><p id="1b7e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">4.动手示例</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="91d8" class="lf lg hi bd lh li lj lk ll lm ln lo lp io lq ip lr ir ls is lt iu lu iv lv lw bi translated">1.线性回归假设:</h1><p id="3bf7" class="pw-post-body-paragraph jo jp hi jq b jr lx ij jt ju ly im jw jx lz jz ka kb ma kd ke kf mb kh ki kj hb bi translated">回归是一种参数方法。“参数化”意味着它对用于分析的数据做出假设。如果数据集无法满足其假设，那么模型在数据集上的表现将会很差。因此，验证这些假设对于成功的回归分析是至关重要的。</p><p id="76da" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">回归分析中的重要假设是:</p><p id="f277" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> 1。</strong> <strong class="jq hj">线性:</strong>假设因变量(Y)和自变量(X)之间存在线性关系。</p><p id="8f58" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> 2。</strong> <strong class="jq hj">自相关:</strong>残差(误差)项之间应该没有相关性。如果存在某种相关性，则意味着模型无法识别数据中的某种关系。</p><p id="9c6f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> 3。</strong> <strong class="jq hj">多重共线性:</strong>自变量之间应该没有相关性。如果自变量中度相关或高度相关，那么就很难找出哪个变量有助于预测因变量(响应变量)。</p><p id="8481" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> 4。</strong> <strong class="jq hj">同方差:</strong>误差项必须有常方差。误差项中非恒定方差的存在导致异方差。这种非恒定方差出现在异常值的情况下。当这种现象发生时，样本外预测的置信区间往往过宽或过窄。</p><p id="01c5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> 5。</strong> <strong class="jq hj">正态:</strong>误差项必须正态分布。非正态分布的存在表明，必须仔细研究一些不寻常的数据点，以建立更好的模型。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="0b50" class="lf lg hi bd lh li lj lk ll lm ln lo lp io lq ip lr ir ls is lt iu lu iv lv lw bi translated">2.模型背后的数学:</h1><p id="a696" class="pw-post-body-paragraph jo jp hi jq b jr lx ij jt ju ly im jw jx lz jz ka kb ma kd ke kf mb kh ki kj hb bi translated">尽管我们有python库，可以在一行代码中完成回归分析，但了解模型背后的数学知识真的很重要。因为只有当你从头开始了解一个模型是如何工作的，你才能够根据你的问题陈述和手头的数据集来调整不同的模型参数，以获得想要的结果。</p><p id="d4b2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">线性回归模型中有两种变量:</p><ul class=""><li id="2598" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj kp kq kr ks bi translated"><strong class="jq hj"> <em class="mc">输入</em> </strong> <em class="mc"> </em>或<strong class="jq hj"> <em class="mc">独立</em> </strong> <em class="mc"> </em>或<strong class="jq hj"> <em class="mc">预测器</em> </strong> <em class="mc"> </em>变量是模型的输入，它有助于预测输出变量。表示为<strong class="jq hj"> X </strong>。</li><li id="86fc" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj"> <em class="mc">输出</em> </strong> <em class="mc"> </em>或<strong class="jq hj"> <em class="mc">因变量</em> </strong> <em class="mc"> </em>是模型的输出，即我们要预测的变量。表示为<strong class="jq hj"> Y </strong>。</li></ul><h2 id="364d" class="md lg hi bd lh me mf mg ll mh mi mj lp jx mk ml lr kb mm mn lt kf mo mp lv mq bi translated">2.1简单线性回归:</h2><p id="7d4d" class="pw-post-body-paragraph jo jp hi jq b jr lx ij jt ju ly im jw jx lz jz ka kb ma kd ke kf mb kh ki kj hb bi translated">当有一个输入变量/自变量(X)时，它被称为简单线性回归。</p><p id="e231" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">简单的线性回归方程如下所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mr"><img src="../Images/c9c863b0f34b228f4a6c325d1bf9d2e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*1UXLim1XTXRWtnTR7qMm0Q.jpeg"/></div></figure><p id="6636" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这个模型背后的主要思想是在数据中拟合一条直线。为了获得最佳拟合线，我们必须找到系数/参数β0和β1的最佳值，使预测值和实际值之间的误差最小。</p><p id="3376" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">那么，我们如何找到β0和β1的最佳值呢？简单的线性回归可以使用<strong class="jq hj"> <em class="mc">【普通最小二乘法(OLS) </em> </strong>【统计方法】求解，以找到模型参数。</p><p id="05d0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">普通最小二乘法:</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ms"><img src="../Images/6c43145f175e227ca10ea3cf238c5e67.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*McDwJWqonW-w_YifJpcWsQ.png"/></div></figure><p id="fa94" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">普通最小二乘(OLS)回归是一种统计分析方法，用于估计一个或多个自变量和因变量之间的关系。最小二乘法的目标是找到使y和Yₑ.之间的平方差之和最小的β0和β1的值</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mt"><img src="../Images/c95061722acb5311bd0bca5e3639429b.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*pBBLk1cmpReevmJt1O3P8w.jpeg"/></div></figure><h1 id="3463" class="lf lg hi bd lh li mu lk ll lm mv lo lp io mw ip lr ir mx is lt iu my iv lv lw bi translated">2.2多元线性回归:</h1><p id="90b7" class="pw-post-body-paragraph jo jp hi jq b jr lx ij jt ju ly im jw jx lz jz ka kb ma kd ke kf mb kh ki kj hb bi translated">当有多个输入变量/独立变量(X1，X2，X3…)那么就叫多元线性回归。</p><p id="14e0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">多元线性回归方程如下所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mz"><img src="../Images/424c7e25033733f0731c237300f12327.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*KA9sHM9etD6CPhnRLpjyWw.jpeg"/></div></div></figure><p id="21b6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在简单的线性回归中，我们使用OLS方法来寻找最佳拟合线。然而在这种情况下，我们有一个以上的预测变量，这使得我们很难使用简单的OLS方法。</p><p id="24db" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">但是我们可以使用以下方法之一实现线性回归模型来执行普通最小二乘回归:</p><ul class=""><li id="db5e" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj kp kq kr ks bi translated"><strong class="jq hj"> <em class="mc">解析求解模型参数</em> </strong> <em class="mc"> </em>(正规方程组法)</li><li id="948f" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj"> <em class="mc">使用优化算法</em> </strong>(梯度下降，随机梯度下降等。)</li></ul><h2 id="31f5" class="md lg hi bd lh me mf mg ll mh mi mj lp jx mk ml lr kb mm mn lt kf mo mp lv mq bi translated">正规方程(封闭解)</h2><p id="02aa" class="pw-post-body-paragraph jo jp hi jq b jr lx ij jt ju ly im jw jx lz jz ka kb ma kd ke kf mb kh ki kj hb bi translated">这种方法将数据视为矩阵，并使用线性代数运算来估计模型参数的最佳值。这意味着所有的数据都必须可用，并且必须有足够的内存来容纳数据和执行矩阵运算。因此，对于较小的数据集，应该首选这种方法。</p><p id="bb79" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">多元线性回归看起来像这样:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es na"><img src="../Images/7b2f45fe75767f51b9675f213822f96f.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*C0K-zhBRH36O3ZPhqgn5ww.jpeg"/></div></figure><p id="ce2b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，采用矩阵形式的模型参数θ和X:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nb"><img src="../Images/119dfdca4df728ff30d9d7efbdc9fe5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*rwtosxxyynskdrB7RIttxA.jpeg"/></div></figure><p id="8864" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，多元线性回归方程的矢量化形式如下所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nc"><img src="../Images/3db592a2697b1b583405dbbb6c8e088a.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*cgsLUpJUI-4NDuaOp8Ve7w.jpeg"/></div></figure><p id="5e72" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">寻找模型参数最佳值的封闭解为:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nd"><img src="../Images/250a5b9c5cbe3ca3addd331aa9450195.png" data-original-src="https://miro.medium.com/v2/resize:fit:346/format:webp/1*Aog-sXCIsIU4YezN6e1BwQ.jpeg"/></div></figure><p id="9955" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于非常大的数据集，计算矩阵的逆矩阵代价很高，或者在某些情况下，逆矩阵不存在(矩阵是不可逆的或奇异的，例如，在完全多重共线性的情况下)。在这种情况下，以下解释的梯度下降方法是首选。</p><h2 id="9ceb" class="md lg hi bd lh me mf mg ll mh mi mj lp jx mk ml lr kb mm mn lt kf mo mp lv mq bi translated">梯度下降:</h2><p id="620a" class="pw-post-body-paragraph jo jp hi jq b jr lx ij jt ju ly im jw jx lz jz ka kb ma kd ke kf mb kh ki kj hb bi translated">梯度下降是一种非常通用的优化算法，能够找到各种问题的最优解。梯度下降的一般思想是迭代地调整参数以最小化成本函数。</p><p id="8f61" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这里的误差/成本表示预测值和实际值之间的误差平方和。该误差以函数的形式定义，称为<em class="mc">均方误差(MSE)成本函数</em>。因此，该梯度下降优化算法的目标是最小化MSE成本函数。</p><p id="e427" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">假设让我们假设我们站在浓雾中的山顶上；你只能感觉到脚下地面的坡度。快速到达谷底的一个好策略是朝着坡度最陡的方向下山。这正是梯度下降所做的:它测量误差函数相对于参数向量θ的局部梯度，并沿着梯度下降的方向前进。一旦梯度为零，你就达到了最小值。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ne"><img src="../Images/edfb34435222e508e3069e0555a54267.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*tzFQCy9grSCzAmc6oFK-5Q.png"/></div></figure><p id="0034" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">梯度下降中的一个重要参数是步长，由<em class="mc">学习速率</em>超参数决定。如果学习率太小，算法要经过多次迭代才能收敛，耗时较长。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nf"><img src="../Images/009498dc48924ccef5288a34bc230f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*0TXFEOTfe-w9Y9XIRvNRJw.png"/></div></figure><p id="cb7c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">另一方面，如果学习率太高，算法将跳过最小值，使其发散。因此算法不会达到最小值。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ng"><img src="../Images/3793d279c61be4f4a8cb75d9fbb2b088.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*_uKykymIJLQ3uAnEH5mhrQ.png"/></div></figure><p id="a911" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了实现梯度下降，需要计算关于参数向量θ的成本函数的梯度。这里梯度是指如果参数向量θ有很小的变化，代价函数会有多大的变化。为了得到梯度，我们需要对成本函数求偏导数。</p><p id="a5a8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">MSE成本函数被定义为，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nh"><img src="../Images/aa4a2885afaf350fa90889cf3e937c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*QpRr3HdxmIjZ-dssahBg_w.jpeg"/></div></figure><p id="8f5a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">其中m =数据集中的样本数。</p><p id="9f61" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">成本函数的偏导数是，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ni"><img src="../Images/31dfea3a243de17a3946d99bfed9ad21.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*9mxvpzTb8uB550WE6O0L5g.jpeg"/></div></figure><p id="1b3d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">上面的等式单独计算每个数据点的偏导数。我们可以一次性计算所有的梯度，而不是使用矢量化的形式。</p><p id="6a33" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">矢量化的形式看起来像，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nj"><img src="../Images/e1431023dce57953e45ecffae1eed52e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*VXSv1qbCOdYXe3XpLU8bmQ.jpeg"/></div></figure><p id="aea3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">上面的梯度向量包含成本函数的所有偏导数(每个模型参数一个)。下面给出了获得更新的权重/参数的更新规则，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nk"><img src="../Images/98d7d1dd65e73291973c6e62538e0f60.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*7sL4gPj7TIE6NbaApyhOIQ.jpeg"/></div></figure><p id="6314" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">其中<em class="mc">α</em>是学习率超参数。</p><p id="cd63" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这总结了寻找线性回归模型参数的方法。从实际应用的角度来说，我们不需要每次需要应用线性回归模型的时候都从头开始写算法。Python提供了一个名为scikit-learn的机器学习库，其中包含线性回归算法，我们可以通过一行代码来使用它，您将在下一节中看到。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="a3b0" class="lf lg hi bd lh li lj lk ll lm ln lo lp io lq ip lr ir ls is lt iu lu iv lv lw bi translated">3.评估指标:</h1><p id="8691" class="pw-post-body-paragraph jo jp hi jq b jr lx ij jt ju ly im jw jx lz jz ka kb ma kd ke kf mb kh ki kj hb bi translated">到目前为止，您已经了解了线性回归模型的工作原理以及该模型中的参数。一旦您训练了您的模型并获得了预测的输出，您需要检查与实际输出相比，该预测有多好。如果模型的预测能力非常差，您需要返回并调整超参数或使用不同的算法，以便降低模型的误差，从而提高其预测能力。</p><p id="ba60" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">线性回归最常用的评价指标有<strong class="jq hj"> <em class="mc">平均绝对误差(MAE)、均方误差(MSE)、均方根误差(RMSE)。</em> </strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nl"><img src="../Images/f279af2e8273d90ed52635cdf3fc04b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O8kvsS7c1E7oE9umdi6XeA.jpeg"/></div></div></figure><p id="0da4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们在真实数据集中应用这个线性回归模型，看看它是如何工作的！</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="bc2d" class="lf lg hi bd lh li lj lk ll lm ln lo lp io lq ip lr ir ls is lt iu lu iv lv lw bi translated">4.动手示例:</h1><p id="9453" class="pw-post-body-paragraph jo jp hi jq b jr lx ij jt ju ly im jw jx lz jz ka kb ma kd ke kf mb kh ki kj hb bi translated">在本节中，我们将了解如何使用python应用线性回归。我们将在这里做多元线性回归问题，因为你将面临的几乎所有现实世界的问题都有两个以上的变量。但是要知道，我们进行多元线性回归的步骤和简单线性回归的步骤是一样的。</p><p id="c66d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们这里要用的数据集是红酒质量数据集。该数据集与葡萄牙“Vinho Verde”葡萄酒的红色变种相关。</p><p id="5073" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">你可以从<a class="ae jn" href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据集。</p><p id="bb8b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这个动手示例只是为了展示如何使用scikit-learn应用线性回归模型，所以我没有深入探讨探索性数据分析(EDA)部分。</p><p id="4d9c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们开始编码:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nm"><img src="../Images/4d49f2b93e30c6b55472e73ae44457b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k56f6_G7aBl7gLDpK2seQQ.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nn"><img src="../Images/72d398c45b33d74ac7cff8bad540a131.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z38hmbHo-qp3AzqaS7kZIg.png"/></div></div></figure><p id="9303" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们检查数据集中的行数和列数。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es no"><img src="../Images/8ae5d0e0600af01c2c71e187223e087f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s8Zu43DW4gmonE_8f9cyTg.png"/></div></div></figure><p id="edaa" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">该数据集包含1599行和12列。该数据集中的每一行都代表葡萄酒，每一列都代表特定葡萄酒的特性。</p><p id="ee9a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，让我们检查数据集中是否有丢失的值。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es np"><img src="../Images/c1dccc8800e0524e8eb9efd337a3a326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0-DWvGSD3N_adBmB4TZxsQ.png"/></div></div></figure><p id="ef4b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如您在输出中看到的，数据集中没有丢失值。如果数据集中存在任何缺失值，我们需要首先处理它，然后继续下一步。因为该算法无法处理缺失值，因此要么需要将其删除，要么用其他值进行估算。</p><p id="6b5e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，我们将检查数据集的描述性统计数据，以了解数据:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nq"><img src="../Images/a99dad79a9c14f4e97f67adb50d1c16d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HkqqRPHK5zmrqFWVpXuBnQ.png"/></div></div></figure><p id="ed19" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从上面的统计中，我们可以对数据集中的每个自变量有一个整体的了解，如计数、均值、标准差、最小值和最大值等。</p><p id="bbdf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这个数据集中，我们将预测葡萄酒的质量，因此因变量是“质量”。其余的都是独立/预测变量，这是葡萄酒的特征，使用它我们将发现质量。</p><p id="5cbf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，让我们从数据集中分离出自变量和因变量。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nr"><img src="../Images/016a0aecc1611690dfced0480ac4aeb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4s4pKTQRs8Kxq6kurDxdeA.png"/></div></div></figure><p id="e3a4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们把X和Y分开。同样，我们将把这些数据集分成训练集和测试集，因为一旦我们的线性回归模型被训练，我们就需要一些数据来检查我们的模型表现如何。</p><p id="5bc9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们将把完整的数据集分成70%的训练数据和30%的测试数据。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ns"><img src="../Images/a209a88a02d7c962c475f772345774e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*adaMhZlxzWfAAOV7QzJ1dA.png"/></div></div></figure><p id="d7ad" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从输出中可以看出，训练集有1119个观察值，测试集有480个观察值。</p><p id="ee12" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，让我们训练我们的模型:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nt"><img src="../Images/f64ffe54c799b68a76cff7de5d6721a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IqgiiUg8MsM_Cono691NFQ.png"/></div></div></figure><p id="9199" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">就像我已经提到的，训练一个线性回归模型只是一行代码。现在模型已经定型，可以预测测试集的值了。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nu"><img src="../Images/735188b830b3cd1eb574914e06e46d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cqrH2fJCXQP5CchknPYc5Q.png"/></div></div></figure><p id="d1e7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们比较一下测试集的实际值和预测值。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nv"><img src="../Images/67d7bda3a8db9d7ab254afb350ad4eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VxEKmRfZNkP6rBz7L2NqYQ.png"/></div></div></figure><p id="7f3c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从输出中可以看出，模型预测得相当不错。为了更好地理解，我们来绘制实际值和预测值。出于可视化的目的，我们将只从测试集中选取25个观察值。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nw"><img src="../Images/1b181184bdbded596b42cdd2ba7d65c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QabQC61JZFblv_g1KKepaA.png"/></div></div></figure><p id="018c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">最后一步是评估模型的性能。我们将使用平均绝对误差(MAE)、均方误差(MSE)和均方根误差(RMSE)等评估指标。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nx"><img src="../Images/3149bc36bde09feaee60e6b19031be0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hYFTNxnKJ7y27nrBnf6fjw.png"/></div></div></figure><p id="8165" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，我们使用scikit-learn在红酒质量数据集上成功应用了线性回归模型。这个例子只是给你一个如何执行回归分析的要点。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><p id="46d1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">希望这篇文章能帮助你详细了解线性回归模型。还有一些主题，如多项式回归，正则化技术，优化算法，如随机梯度下降(SGD)，批量梯度下降，小批量梯度下降等。，这将在下一篇文章中讨论。</p><p id="727e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在那之前，学习愉快！！！！</p></div></div>    
</body>
</html>