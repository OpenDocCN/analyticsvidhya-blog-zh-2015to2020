<html>
<head>
<title>Bag Of Tricks for Deep Learning — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习的锦囊妙计—第1部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/bag-of-tricks-for-deep-learning-part1-a832cc0964e3?source=collection_archive---------10-----------------------#2019-11-29">https://medium.com/analytics-vidhya/bag-of-tricks-for-deep-learning-part1-a832cc0964e3?source=collection_archive---------10-----------------------#2019-11-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4da3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于其在计算机视觉和机器学习方面的最新进展，深度学习是人工智能世界中最时髦和最有趣的词之一。时不时地，新的和新的深度学习技术正在诞生，胜过最先进的(SOTA)机器学习，甚至现有的深度学习技术。由于深度学习正在以巨大的速度发展，很难跟踪有规律的进步。我将简要讨论过去几年深度学习在以下领域的最新进展</p><ol class=""><li id="693b" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">视力</li><li id="3ecc" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">文本</li><li id="a77e" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">声音的</li></ol><p id="4b55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我将把重点放在视野上，随后的博文中会有文字和音频。</p><p id="8e96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">开始之前，我们需要一组图像。我将使用大约包含以下内容的吉他数据集。来自11个不同吉他类别的8500张图片(五个芬达模型和六个吉布森)。数据集可以从<a class="ae jr" href="https://www.dropbox.com/s/2a9oboj6dcoykt0/guitars.tgz?dl=1" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">这里</strong> </a>下载。</p><p id="620c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:- </strong>我将使用<a class="ae jr" href="https://docs.fast.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> fastai </strong> </a>库版本1.0.59(因为其用户友好的内置函数)在<a class="ae jr" href="https://www.nvidia.com/en-gb/data-center/tesla-k80/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Tesla K80 GPU </strong> </a>上进行演示</p><h1 id="05f5" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">问题</h1><p id="51f2" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">问题是给定的图像分类成11个不同的吉他类别</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/bb40ae6a6f2791d52f986fc5280c1b57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WRczagDx0ynmdt8uBObnaw.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">吉他课</figcaption></figure><h1 id="88bd" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">渐进调整大小</h1><p id="3748" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">这是一种技术，其中我们在训练开始时使用较小尺寸的图像，并随着训练的进行逐渐增加尺寸。这样，当模型在早期非常不准确时，它可以快速看到大量图像并取得快速进展，然后在训练中，它可以看到更大的图像以了解更精细的区别。</p><p id="8bba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我发现最有用的两个主要优势是:-</p><ol class=""><li id="5889" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">我们可以在训练时使用较大的批量，与从较小批量获得的梯度相比，这使得梯度更不稳定，并且有助于更快地向最佳方向收敛</li><li id="da72" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">这有助于在更长的时间内训练我们的模型，而不用担心随着输入图像的大小逐渐变化而过度拟合，这有助于我们获得更好的性能，特别是在我们只有很少数据点的情况下</li></ol><p id="4a80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用这种技术的一个很好的方法是使用较小的图像大小(比如64x64)训练一个模型，然后使用该模型的权重在128x128等大小的图像上训练另一个模型。每个较大比例的模型在其架构中结合了先前较小比例的模型层和权重。</p><p id="d4e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:- </strong>如果您的数据集与Imagenet非常相似，并且您正在使用迁移学习，那么您不应该从较小尺寸的图像开始，因为这会破坏预训练的权重，这会影响您的模型的性能</p><p id="d284" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我的数据集与Imagenet非常相似，所以我开始用224x224的图像尺寸训练我的模型，然后是299x299</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ll"><img src="../Images/730ffb9761f51acdadea20b7956f702d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1nGRoMdxG3cWCzNWZfaNOg.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">渐进调整大小</figcaption></figure><h1 id="6095" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">混合增强</h1><p id="c95a" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated"><a class="ae jr" href="https://arxiv.org/abs/1710.09412" rel="noopener ugc nofollow" target="_blank"> Mixup </a>由张、西塞、多芬、洛佩兹-帕兹于2018年首次推出。这个想法不是将单个图像传递给模型，而是在两个独立的训练图像(不一定来自同一个类)之间执行线性插值，并将其传递给模型。使用与图像相同的λ系数，图像的一个热编码标签也被内插。</p><p id="9f93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">新图像=λ*图像1+(1-λ)*图像2 </strong></p><p id="e96c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">新目标=λ*目标1+(1-λ)*目标2 </strong></p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es lm"><img src="../Images/d53db3b1c28ba6f0b115329b2e705aa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*hGBrh_Us5f-rc027FVGO5Q.png"/></div></figure><p id="bb13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度学习领域的主要问题是缺乏数据。在Mixup增强的帮助下，我们可以创建许多这样的图像线性组合，这也给了我们更长时间训练模型的灵活性，而不用担心过度拟合。</p><p id="4442" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们的新目标是40%吉布森_火鸟，60%吉布森_SG(来自上图)。所以我们希望输出向量理想情况下用0.4代替gibson_firebird，用0.6代替gibson_SG，所有其他类用0。但是如果我们使用softmax，它不会给出这样的输出，它会集中在一个类上。于是我们用一种叫做<a class="ae jr" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">的方法平滑</strong> </a>。这是Szegedy等人和他的团队在2015年首次引入的技术。Geoffrey Hinton与Rafael和Simon在2019年发表的论文<a class="ae jr" href="https://arxiv.org/abs/1906.02629" rel="noopener ugc nofollow" target="_blank">中解释了这种技术在各种任务中的使用。</a></p><p id="da73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们要求它预测正确类别的<strong class="ih hj"> 1- 𝛆 </strong>和所有其他类别的<strong class="ih hj">𝛆/(n-1</strong>，而不是预测正确类别的1和所有其他类别的0，其中<strong class="ih hj"> 𝛆 </strong>为(小)正数，n为类别数。那么损失函数可以写成</p><h2 id="272e" class="ln jt hi bd ju lo lp lq jy lr ls lt kc iq lu lv kg iu lw lx kk iy ly lz ko ma bi translated">损失=(<strong class="ak">1-𝛆)*crossentropy(i)+𝛆*∑(交叉熵(j)) / (N-1) </strong></h2><p id="d12a" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">其中交叉熵(I)是正确类别的交叉熵</p><p id="ded3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在最初的文章中，作者提出了四点建议:</p><ol class=""><li id="e04f" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">创建两个独立的数据加载器，并在每次迭代中从每个数据加载器中抽取一批数据来混合它们</li><li id="e3e3" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">根据带有参数α(他们的论文中建议0.4)的贝塔分布为t画一个值</li><li id="a80e" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">将具有相同t值的两个批次混合</li><li id="7d57" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">使用一键编码目标</li></ol><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es mb"><img src="../Images/478387a71f617f283f7ca8dad88f6ead.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*JARYJD7Cu5IJX4p5rnP4NQ.png"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">混合</figcaption></figure><p id="d692" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，α需要根据数据集进行调整。当α值较小时，贝塔分布的大部分权重在尾部，接近0或1。随着α的增加，分布变得均匀，然后在0.5左右逐渐达到峰值。因此，α可以被视为控制混合的强度；较小的值只会导致少量的混合，而较大的值偏向于最大混合(50/50)。在极端情况下，α=0导致完全没有混合，当α→∞，β接近以0.5为中心的狄拉克δ分布。作者建议从0.75开始，如下图所示，大部分重量仍然在尾部。本文对原方法做了一处修改，即把λ设为max(λ，1-λ)；这使混音偏向原始图像。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mc"><img src="../Images/9e354491a91e5432a4b92bc5298c9872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kr2vSZXBH0Hglf_ZXeNJ1A.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">不同α值的贝塔分布</figcaption></figure><p id="72d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:- </strong>用mixup训练时，最终损失(训练或验证)会比不用它训练时高，即使精度远好。这是因为像这样训练的模型会做出不太自信的预测。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es md"><img src="../Images/8b69bf5a36dd1ec26540fb67e7959aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m9MjhHqx4QJjEKDQd-kMBw.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">混合增强</figcaption></figure><h1 id="938c" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">混合精确训练</h1><p id="ab18" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">它允许你的神经网络的向前和向后传递在fp16中完成(也称为<em class="me">半精度</em>)。如果你有一个带<a class="ae jr" href="https://www.nvidia.com/en-us/data-center/tensorcore/" rel="noopener ugc nofollow" target="_blank">张量核</a>的NVIDIA GPU，这一点尤其重要，因为它可以将你的训练速度提高3倍或更多。</p><p id="62bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用混合精度训练需要两个步骤:</p><ol class=""><li id="fd86" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">移植模型以在适当的地方使用FP16数据类型。</li><li id="7e10" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">添加损失缩放以保留小的梯度值，使其不会下溢fp16，从而导致精度损失(在转换回fp32后，这对于最终梯度计算是相反的)。</li></ol><p id="cb6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">半精度浮点格式(FP16)使用16位，而单精度浮点格式(FP32)使用32位。降低所需的内存可以训练更大的模型或训练更大的小批量。这是使用混合精确训练的最大优势。利用这一点，我能够在Tesla K80 GPU上使用批量大小为128的Resnet152架构训练大小为224x224的图像</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mf"><img src="../Images/07ce3550c9f1799a82a7835488702419.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vU1-mLijrmhhbpDjiIvZvA.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">混合精确训练</figcaption></figure><h1 id="9113" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">学习率调整</h1><p id="25f4" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">学习率是训练神经网络最重要的超参数之一。如果太低，你的神经网络将永远学习，如果太高，你的每一步都将超过最小值，你永远不会达到可接受的损失。所以我们必须选择正确的值，不能太高也不能太低。Leslie Smith在2017年描述了一种设置学习率的新方法，名为<a class="ae jr" href="https://arxiv.org/abs/1506.01186" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a>循环学习率，它实际上消除了通过实验寻找全局学习率的最佳值和时间表的需要</p><p id="60f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在一个时期内，以非常低的学习率(如10–810-8)开始SGD(随机梯度下降),但在每个小批量中改变它(如乘以某个因子),直到它达到非常高的值(如1或10)。记录每次迭代的损失，一旦你完成了，就把这些损失和学习速度对应起来。你会发现这样的东西:</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es mg"><img src="../Images/5aa6bb59bea8bab750fdf17ba62aecfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*PXAGLK46HFnsq8T9WL_DCA.png"/></div></figure><p id="c112" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将选择一个比最小值稍早的值，此时损失仍会增加。在这里，10^-2将是一个不错的选择</p><p id="5308" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">动量和学习率密切相关。在SGD的权重更新方程中可以看出，动量对权重更新的影响与学习速率相似。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es mh"><img src="../Images/0b66895712cee99dfdee7af33a2acc16.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*LcHW3qHU9BkDDQiEApfD-w.png"/></div></figure><p id="39cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">莱斯利·史密斯在他们的实验中发现，当学习速度增加时，减少动量会产生更好的结果。这支持了直觉，即在训练的那一部分，我们希望SGD快速进入新的方向以找到更好的最小值，因此新的梯度需要被赋予更多的权重。</p><p id="ef78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将应用1周期策略，将选择的学习率作为最大学习率。</p><p id="a97c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们从一个较低的学习率逐渐增加到一个较高的学习率，而不是回到最小值。最大值应该是上面选取的值(10^-2)，较低的值可以低10倍，同时我们从最大值到最小值逐渐减小动量。在实践中，本文建议选择两个值，如0.85和0.95</p><p id="5469" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们做的正好相反:我们从较高的学习速率到较低的学习速率逐渐降低，同时随着学习速率的降低，我们又回到较高的动量</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mi"><img src="../Images/7090550e5b7b9e1baad44f30a1f63ae3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YTPf0I6oG_AlZ_jlMkLZRw.jpeg"/></div></div></figure><p id="6ccb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一种叫做<em class="me">带重启的随机梯度下降(SGDR) </em>的技术，是<em class="me">学习速率退火</em>的变体，随着训练的进行，逐渐降低学习速率。这很有帮助，因为当我们越来越接近最佳重量时，我们希望迈出更小的步伐。<br/>然而，我们可能会发现自己处于一个不太有弹性的重量空间——也就是说，重量的小变化可能会导致损失的大变化。我们希望鼓励我们的模型找到既准确又稳定的权重空间部分。因此，我们不时地增加学习速率(这是“SGDR”中的“重启”)，如果当前区域是“尖峰”，这将迫使模型跳到权重空间的不同部分。</p><h1 id="9a08" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">测试时间增加</h1><p id="f19e" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">虽然增强技术有助于给我们一个更好的模型，但预测准确性可以通过所谓的测试时间增强(TTA)来进一步提高。在了解它是什么之前，我们首先需要了解我们为什么需要它</p><p id="f914" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了在GPU中高效处理，我们需要批处理，并且批处理中的所有图像都应该是相同的大小。Nvidia dali 可能是一个替代方案，因为他们正在构建定制的Cuda内核，可以处理不同大小的图像。但它仍处于早期阶段。</p><p id="b6ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，当我们在测试期间将图像传递给模型以获得预测时，我们通过进行某种转换将它们调整为正方形，中心裁剪是最常用的一种。因此，当模型试图预测图像时，它只看到图像的中心，这很多时候会使模型困惑，因为实际上重要的特征被剪掉了，因此模型最终会对图像进行错误分类</p><p id="115d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了减少这种错误，我们使用了一种叫做TTA的东西。TTA不仅仅对我们的验证集中的图像进行预测，还对它们的许多随机增强版本进行预测(默认情况下，它使用原始图像和4个随机增强版本)。然后它从这些图像中取平均值并使用它。</p><p id="c0ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">直觉是，图像的至少一个增强版本将捕获用于预测正确类别的重要特征，因此当我们取平均值时，与从原始图像获得的预测相比，它将最终预测正确的类别。这种方法通常可以减少10-20%的误差</p><p id="92eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用上面提到的所有技巧和技术，我只用了8500张图像就能够实现上述问题99.4%的准确率(将给定的图像分为11个不同的吉他类别)。你可以使用下面的链接找到代码和工作细节</p><div class="mj mk ez fb ml mm"><a href="https://github.com/statsguysam/Deep-Learning/blob/master/Guitar_Multiclass.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mn ab dw"><div class="mo ab mp cl cj mq"><h2 class="bd hj fi z dy mr ea eb ms ed ef hh bi translated">statsguysam/深度学习</h2><div class="mt l"><h3 class="bd b fi z dy mr ea eb ms ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="mu l"><p class="bd b fp z dy mr ea eb ms ed ef dx translated">github.com</p></div></div><div class="mv l"><div class="mw l mx my mz mv na lf mm"/></div></div></a></div><h1 id="6131" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">结论</h1><ol class=""><li id="e72d" class="jd je hi ih b ii kq im kr iq nb iu nc iy nd jc ji jj jk jl bi translated">始终使用渐进式调整大小开始训练您的模型(如果图像与Imagenet数据集不相似)</li><li id="3809" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">尝试没有通用增强的混合增强(如翻转、扭曲、缩放等)。)反之亦然。评估模型的性能，如果需要，将混合增强与一般增强相结合</li><li id="bdb6" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">混合精度训练是非常有用的，特别是如果你的资源有限，你想使用更大的模型或训练更大的小批量</li><li id="7fea" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">长期以来，寻找最佳学习速度一直是一个尝试和观察的游戏。有了循环学习率的概念，我们不再需要玩这个游戏，并且可以在更少的迭代中收敛到最佳学习率。</li><li id="47d5" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">推断过程中的TTA总是有助于获得更好的预测，而不是使用原始的中心裁剪图像。</li></ol><h1 id="ad85" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">参考资料:</h1><ol class=""><li id="b065" class="jd je hi ih b ii kq im kr iq nb iu nc iy nd jc ji jj jk jl bi translated"><a class="ae jr" href="https://arxiv.org/abs/1710.09412" rel="noopener ugc nofollow" target="_blank">混乱:超越经验风险最小化</a></li><li id="dd4b" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><a class="ae jr" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank">重新思考计算机视觉的初始架构</a></li><li id="32ab" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><a class="ae jr" href="https://arxiv.org/abs/1906.02629" rel="noopener ugc nofollow" target="_blank">标签平滑什么时候有帮助？</a></li><li id="565b" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><a class="ae jr" href="https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html" rel="noopener ugc nofollow" target="_blank">混合精确训练</a></li><li id="3f97" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><a class="ae jr" href="https://arxiv.org/abs/1506.01186" rel="noopener ugc nofollow" target="_blank">训练神经网络的循环学习率</a></li><li id="1172" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><a class="ae jr" href="https://github.com/fastai" rel="noopener ugc nofollow" target="_blank"> Fastai库</a></li></ol><p id="eded" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="me">如果你喜欢这篇文章，请一定给我一个掌声，并关注我以获取我未来文章的更新。</em></p><p id="6aa4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="me">还有，随时在</em><a class="ae jr" href="https://www.linkedin.com/in/salim-shaikh-a082a7162/" rel="noopener ugc nofollow" target="_blank"><em class="me">LinkedIn</em></a>上联系我</p></div></div>    
</body>
</html>