<html>
<head>
<title>Introduction to Web Scraping</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网页抓取简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-web-scraping-258d5f117357?source=collection_archive---------24-----------------------#2020-04-14">https://medium.com/analytics-vidhya/introduction-to-web-scraping-258d5f117357?source=collection_archive---------24-----------------------#2020-04-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="c26e" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">“让我们深入数据世界”</p></blockquote><p id="80a3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">在本文中，我们将废弃BookMyShow网站，以提取最新的即将上映的电影。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jk"><img src="../Images/352037f3e6d505927d60788b40b9ca75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*YjjHcvvYtMdcfOZvBGafkA.jpeg"/></div></figure></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h2 id="1ef6" class="jz ka hi bd kb kc kd ke kf kg kh ki kj jh kk kl km ji kn ko kp jj kq kr ks kt bi translated">什么是网络抓取</h2><blockquote class="if ig ih"><p id="9989" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">Web抓取是指从许多网站中提取数据。它基本上涉及到以网页形式下载数据，这也被称为获取数据。获取数据后，可以借助Python中的工具和库来提取数据。<br/>beautiful soup就是这样一个工具，我们将用它来进行网页抓取。<br/> <a class="ae ku" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">美汤</a>是一个从HTML和XML文件中提取数据的Python库。</p></blockquote><h2 id="15b0" class="jz ka hi bd kb kc kd ke kf kg kh ki kj jh kk kl km ji kn ko kp jj kq kr ks kt bi translated">网页抓取组件</h2><blockquote class="if ig ih"><p id="699a" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><strong class="il hj">抓取:</strong>是指通过发出HTTP请求，导航目标网站来下载网页。<br/> <strong class="il hj">解析和转换:</strong>一旦网页下载完毕，就使用BeautifulSoup之类的HTML解析器提取所需数据。<br/> <strong class="il hj">存储:</strong>数据提取后，需要以JSON或CSV文件的形式存储。</p></blockquote></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="021f" class="kv ka hi bd kb kw kx ky kf kz la lb kj lc ld le km lf lg lh kp li lj lk ks ll bi translated">1.爬行</h1><blockquote class="if ig ih"><p id="b4ad" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">导航到目标网站，下载网页并检查源代码。这将在<a class="ae ku" href="https://requests.readthedocs.io/en/master/" rel="noopener ugc nofollow" target="_blank"> <strong class="il hj">请求</strong> </a> <strong class="il hj"> </strong>库的帮助下完成。</p></blockquote><pre class="jl jm jn jo fd lm ln lo lp aw lq bi"><span id="915d" class="jz ka hi ln b fi lr ls l lt lu">import requests<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</span><span id="adfc" class="jz ka hi ln b fi lv ls l lt lu">url = "<a class="ae ku" href="https://in.bookmyshow.com/national-capital-region-ncr/movies/comingsoon" rel="noopener ugc nofollow" target="_blank">https://in.bookmyshow.com/national-capital-region-ncr/movies/comingsoon</a>"</span><span id="5637" class="jz ka hi ln b fi lv ls l lt lu">headers = {<br/>    'User-Agent': "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36"<br/>    }</span><span id="940e" class="jz ka hi ln b fi lv ls l lt lu">response = requests.request("GET", url, headers=headers)<br/>data = BeautifulSoup(response.text, 'html.parser')<br/>print(data)</span></pre><h1 id="a911" class="kv ka hi bd kb kw lw ky kf kz lx lb kj lc ly le km lf lz lh kp li ma lk ks ll bi translated">2.解析和转换</h1><blockquote class="if ig ih"><p id="8755" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">下一步是将这些数据解析到HTML解析器中，为此，我们将使用<em class="hi"> BeautifulSoup </em>库。现在，如果你已经注意到我们的目标网页，一部特定电影的细节和大多数网页一样在不同的<em class="hi">部门</em>。现在到那个特殊的<em class="hi">部门检查元件。</em></p></blockquote><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mb"><img src="../Images/9dd0239190f94a60620bc0b71014eab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jr_K_1Rk8S22kh_JnMy83Q.png"/></div></div></figure><blockquote class="if ig ih"><p id="48e2" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">所有部门的类名都是相同的，我们可以通过传递标签名和属性(如带有名称的<class>标签)来获得这些卡片的列表，如下所示:</class></p></blockquote><pre class="jl jm jn jo fd lm ln lo lp aw lq bi"><span id="1e09" class="jz ka hi ln b fi lr ls l lt lu">movie_data = data.find_all('div', attrs={'class', 'cards cs-card-  regular'})<br/>print(movie_data)<br/>print(len(movie_data))</span></pre><blockquote class="if ig ih"><p id="5b99" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">现在，对于每个部门，我们必须找到上面的电影名称，它只能从<h4>标签中提取。这是因为有一个<h4>标签，它包含每个部分的电影名称，电影日期由<span>标签连同<class>标签和类名，电影语言<li>标签连同<class>标签和类名:</class></li></class></span></h4></h4></p></blockquote><pre class="jl jm jn jo fd lm ln lo lp aw lq bi"><span id="a317" class="jz ka hi ln b fi lr ls l lt lu">for movie in movie_data:<br/>    movie_name = movie.find('h4')<br/>    movie_date = movie.find('span', attrs ={'class', 'day'})<br/>    movie_language = movie.find('li', attrs ={'class',  '__language'})<br/>    print(movie_name.text, movie_date.text, movie_language.text)</span></pre><h1 id="7d10" class="kv ka hi bd kb kw lw ky kf kz lx lb kj lc ly le km lf lz lh kp li ma lk ks ll bi translated">3.存储提取的数据</h1><blockquote class="if ig ih"><p id="6493" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">最后一步是将提取的数据存储在CSV文件中。在这里，对于每个部门，我们将提取电影名称、日期和语言，并将其存储在Python字典中。然后我们将最终把它添加到一个列表中。</p></blockquote><pre class="jl jm jn jo fd lm ln lo lp aw lq bi"><span id="9944" class="jz ka hi ln b fi lr ls l lt lu">file = []</span><span id="530b" class="jz ka hi ln b fi lv ls l lt lu">for movie in movie_data:<br/>    movie_details = {}<br/>    movie_name = movie.find('h4')<br/>    movie_date = movie.find('span', attrs ={'class', 'day'})<br/>    movie_language = movie.find('li', attrs ={'class', '__language'})<br/>    movie_details['movie_name']=movie_name.text<br/>    movie_details['movie_date']=movie_date.text<br/>    movie_details['movie_language']=movie_language.text<br/>    file.append(movie_details)<br/>dataframe = pd.DataFrame.from_dict(file)<br/>dataframe.to_csv('movie_data.csv', index=False)</span></pre><h1 id="7446" class="kv ka hi bd kb kw lw ky kf kz lx lb kj lc ly le km lf lz lh kp li ma lk ks ll bi translated">结论</h1><blockquote class="if ig ih"><p id="7f34" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">在本文中，我们已经成功创建了一个基本的web scraper，将提取的数据存储在CSV文件中。更多更新敬请关注。如果你有疑问，那么评论区就是你的了。我会尽我所能回答你的问题。如果你喜欢这篇文章，并从中学到了一些东西，那么请鼓掌。</p><p id="ac0d" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">谢谢你。</p></blockquote><h1 id="1e40" class="kv ka hi bd kb kw lw ky kf kz lx lb kj lc ly le km lf lz lh kp li ma lk ks ll bi translated">参考</h1><p id="a1de" class="pw-post-body-paragraph ii ij hi il b im mg io ip iq mh is it jh mi iw ix ji mj ja jb jj mk je jf jg hb bi translated">你可以在我的Github上找到上面的代码:</p><div class="ml mm ez fb mn mo"><a href="https://github.com/kpiyush04/web-scrapping" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">KPI yush 04/web-报废</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">网络报废。在GitHub上创建一个帐户，为kpiyush 04/web-screwing开发做出贡献。</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">github.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc jq mo"/></div></div></a></div></div></div>    
</body>
</html>