<html>
<head>
<title>Web Scraping using Beautiful Soup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用美汤刮网</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-using-python-and-beautiful-soup-d3d29bf5b7e9?source=collection_archive---------13-----------------------#2020-05-05">https://medium.com/analytics-vidhya/web-scraping-using-python-and-beautiful-soup-d3d29bf5b7e9?source=collection_archive---------13-----------------------#2020-05-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e485d6df83d8ec76188f2df2034ec1fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qZXE8sSXmtT-b9LdTIHLqQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来源:【https://hackernoon.com/web-scraping-bf2d814cc572 T2】</figcaption></figure><p id="ba87" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">网页抓取</strong>或<strong class="ix hj">网页数据提取</strong>用于自动化从网站提取数据的过程。Web scraping省去了手动下载或复制任何数据的麻烦。</p><p id="9403" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇文章中，我们将直接跳到代码。关于网页抓取的更多信息和应用，请看这篇<a class="ae iu" href="https://towardsdatascience.com/https-medium-com-hiren787-patel-web-scraping-applications-a6f370d316f4" rel="noopener" target="_blank"> <strong class="ix hj">文章</strong> </a>。</p><p id="86b2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们准备从这个<a class="ae iu" href="https://indianbloggers.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">站点</strong> </a> <strong class="ix hj">中提取博主的姓名和网址链接。</strong></p><p id="1d06" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在开始编码之前，我们需要去我们想要抓取的站点。<strong class="ix hj">开发者工具</strong>可以帮助你了解一个网站的结构。您也可以通过在页面上点击右键并选择chrome中的<em class="jt">检查</em>选项来访问它们。这将显示页面的HTML内容。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ju"><img src="../Images/c4b8305cc37ca5eca82a8d18e8eacd62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8msr8D2bwsRdvgWtxhl68Q.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">网站网址:<a class="ae iu" href="https://indianbloggers.org/" rel="noopener ugc nofollow" target="_blank">https://indianbloggers.org/</a></figcaption></figure><p id="93ac" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤1 </strong>:导入需要的库。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="b115" class="ke kf hi ka b fi kg kh l ki kj">import requests<br/>from bs4 import BeautifulSoup, Comment<br/>import pandas as pd<br/>import csv<br/>import re</span></pre><p id="dbd4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第二步</strong>:用<a class="ae iu" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">美汤</a>解析HTML代码</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="7653" class="ke kf hi ka b fi kg kh l ki kj">url=’https://indianbloggers.org/'<br/>content = requests.get(url).text<br/>soup = BeautifulSoup(content, ‘html.parser’)</span></pre><p id="461a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第三步</strong>:查找元素</p><p id="4bfd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">您可以使用ID或HTML类名通过<code class="du kk kl km ka b">soup.find()</code>和<code class="du kk kl km ka b">soup.find_all()</code>属性找到元素。在这里，我将提取的数据保存在标题为“名称”和“网络链接”的<em class="jt"> blog_list.csv </em>文件中。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="4222" class="ke kf hi ka b fi kg kh l ki kj">with open(‘Blog_list.csv’,’w’,newline=’’) as file:<br/> <br/> fieldnames = [‘name’,’web link’] <br/> writer = csv.DictWriter(file, fieldnames=fieldnames)<br/> writer.writeheader() </span><span id="c6d5" class="ke kf hi ka b fi kn kh l ki kj">  for link in soup.find_all(‘a’,): </span><span id="653b" class="ke kf hi ka b fi kn kh l ki kj">   if (len(link.text.strip()) &gt; 1 and  <br/>   bool(re.match(‘^http’,link[‘href’])) and not <br/>   bool(re.search(‘indianbloggers|twitter|facebook’,link[‘href’])): </span><span id="e7d6" class="ke kf hi ka b fi kn kh l ki kj">    data[‘title’].append(link.text)<br/>    data[‘links’].append(link[‘href’])<br/>    writer.writerow({‘name’:data[‘title’], ‘link’:data[‘links’]}) <br/>    #finding type of blog <br/>    if re.search(‘blogspot’,link[‘href’]): <br/>     poll[‘blogspot’]+=1 <br/>    elif re.search(‘wordpress’,link[‘href’]): <br/>     poll[‘wordpress’]+=1 <br/>    else: <br/>     poll[‘others’]+=1 </span><span id="2bb5" class="ke kf hi ka b fi kn kh l ki kj">blog_list = pd.DataFrame(data).set_index(‘title’)<br/>print(blog_list.head())<br/>blog_list.to_csv(‘blog_list.csv’, encoding=’utf-8')<br/>print(str(len(blog_list.index))+’ rows written’)<br/>print(poll)</span></pre><p id="1bbb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里是<em class="jt"> blog_list.csv </em>文件的快照。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/33424fa4b9853173e7f7b6b9ffda694f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uGBRMJ61OHcV-pR9Exp3iA.png"/></div></div></figure><p id="55b0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你也可以在找到<a class="ae iu" href="https://www.simplyrecipes.com/?s" rel="noopener ugc nofollow" target="_blank">这个</a>网站的网页抓取，收集配方名称、配料和配方链接<a class="ae iu" href="https://github.com/shwetapardeshi1/Web-Scraping" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="3b18" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇文章由Sameer Ahire 合著。</p><h2 id="bb26" class="ke kf hi bd kr ks kt ku kv kw kx ky kz jg la lb lc jk ld le lf jo lg lh li lj bi translated">参考</h2><div class="lk ll ez fb lm ln"><a href="https://realpython.com/beautiful-soup-web-scraper-python/" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">美丽的汤:用Python构建一个Web刮刀——真正的Python</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">在本教程中，你将走过网页抓取过程的主要步骤。你将学习如何写剧本…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">realpython.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb io ln"/></div></div></a></div><div class="lk ll ez fb lm ln"><a href="https://www.simplyrecipes.com/?s" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">|搜索结果| SimplyRecipes.com |第1页</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">井然有序的厨房不一定要超简约；它只需要运行良好。这些编辑认可的厨房…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">www.simplyrecipes.com</p></div></div><div class="lw l"><div class="mc l ly lz ma lw mb io ln"/></div></div></a></div><div class="lk ll ez fb lm ln"><a href="https://towardsdatascience.com/https-medium-com-hiren787-patel-web-scraping-applications-a6f370d316f4" rel="noopener follow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">网络抓取是如何通过它的应用改变世界的</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">猜猜看，设想新公司的企业家、财富500强公司的首席执行官、股票分析师…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">towardsdatascience.com</p></div></div><div class="lw l"><div class="md l ly lz ma lw mb io ln"/></div></div></a></div><div class="lk ll ez fb lm ln"><a href="https://indianbloggers.org/" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">最好的印度博客</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">印度最受欢迎的博客目录。你可以在这里认识一些最好的印度博主，甚至添加你自己的博客…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">indianbloggers.org</p></div></div><div class="lw l"><div class="me l ly lz ma lw mb io ln"/></div></div></a></div><div class="lk ll ez fb lm ln"><a href="https://www.datacamp.com/community/tutorials/web-scraping-using-python" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">使用Python进行Web抓取</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">网络抓取是一个术语，用来描述使用程序或算法来提取和处理大量数据…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">www.datacamp.com</p></div></div><div class="lw l"><div class="mf l ly lz ma lw mb io ln"/></div></div></a></div></div></div>    
</body>
</html>