<html>
<head>
<title>Processing data for Machine Learning with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用TensorFlow处理机器学习数据</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/processing-data-for-machine-learning-with-tensorflow-9119a0d45954?source=collection_archive---------22-----------------------#2020-06-23">https://medium.com/analytics-vidhya/processing-data-for-machine-learning-with-tensorflow-9119a0d45954?source=collection_archive---------22-----------------------#2020-06-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/456457648cc6e81df5a99d7445a02e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fv4PWzGbOUj3V8m7"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">凯文·Ku在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="43ea" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">一步一步地将你的数据集转换成张量流</h1><p id="afd8" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">当使用TensorFlow训练数据时，看到显示形状或数据类型的错误是不正确的，这是非常令人困惑的。这是我的笔记，试图以一种简单的方式组织tf数据集，用于电影评论分类。</p><p id="7162" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在本文中，我将处理<a class="ae iu" href="https://homl.info/imdb" rel="noopener ugc nofollow" target="_blank">大型电影评论数据集</a>，并训练一个Keras.models.Sequential模型，这是一个简单的层堆栈模型。</p><p id="f186" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我的步骤:</p><blockquote class="kw kx ky"><p id="aa23" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">1.加载数据集</p><p id="8772" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">2.为输入创建tf.data.Dataset</p><p id="bf2c" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">3.创建文本矢量化图层(包括标记化和填充)</p><p id="b312" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">4.创建单词包</p><p id="9133" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">5.创建模型</p><p id="1042" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">6.健身和训练模型</p></blockquote><h1 id="9bf3" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">加载数据集</h1><p id="7b58" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">从检查zip文件中有哪些文件开始，我们可以使用os.walk(filepath)。然后我们会有这样的东西:</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">加载数据</figcaption></figure><blockquote class="kw kx ky"><p id="3ffa" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">/root/。keras/datasets/aclImdb[' IMDB . vocab '，' imdbEr.txt '，' README']</p><p id="f11e" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">/root/。keras/datasets/aclImdb/train[' labeled bow . feat '，' unsupBow.feat '，' urls_neg.txt '，' urls_unsup.txt '，' urls_pos.txt']</p></blockquote><p id="a471" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">所有文件都在其文件夹下的列表中。我们将使用这4个文件夹下的评论，分别是正面和负面语义的训练和测试数据集。</p><blockquote class="kw kx ky"><p id="4807" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">/root/。keras/datasets/aclImdb/train/pos</p><p id="31de" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">/root/。keras/datasets/aclImdb/train/neg</p><p id="ddd3" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">/root/。keras/datasets/aclImdb/test/pos</p><p id="6440" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">/root/。keras/datasets/aclImdb/train/pos</p></blockquote><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">4条路径</figcaption></figure><p id="5bab" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">制作4条路径。它们都包含12500条评论。(12500, 12500, 12500, 12500)</p><h2 id="91b5" class="lj iw hi bd ix lk ll lm jb ln lo lp jf ke lq lr jj ki ls lt jn km lu lv jr lw bi translated"><strong class="ak">使用tf.data.TextLineDataset创建TensorFlow数据集</strong></h2><p id="2e2f" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">为了简化，我在这里不做函数。我们可以直接把路径列表放入tf.data.TexLineDataset，记得把路径变成字符串格式。我们是这样做的:</p><blockquote class="kw kx ky"><p id="fd34" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">1.将路径传递到tf.data.TexLineDataset()并生成6个tf.data.Dataset</p><p id="a615" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">2.使用tf.data.Dataset.map()的方法将标注添加到数据集中。0表示阴性，1表示阳性。</p><p id="d335" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">3.使用tf.data.Dataset.concatenate()组合neg和pos</p><p id="4e92" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">4.洗牌训练集，批处理，并预取所有三个集合。(我们现在也可以跳过prefetcf)</p></blockquote><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="d9c9" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><em class="kz"> &lt;【预取数据集】形状:((无，)，(无，))，类型:(tf.string，tf.int32) &gt; </em></p><h2 id="5d37" class="lj iw hi bd ix lk ll lm jb ln lo lp jf ke lq lr jj ki ls lt jn km lu lv jr lw bi translated">处理评论</h2><p id="b79f" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">我们创建一个简单的tf.constant来确保我们的步骤是正确的，然后创建一个函数。</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">预处理单词和填充</figcaption></figure><p id="129c" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj">预处理后_word(X_example)对于简单的例子，应该是这样的:</strong></p><blockquote class="kw kx ky"><p id="b0ad" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated"><tf.tensor: shape="(3," dtype="string," numpy="array([[b”It’s”," b="">'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'。 ！!'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad> b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b '<pad>' !'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b '<pad>' b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b' <pad>'，b</pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></pad></tf.tensor:></p></blockquote><h1 id="9e7f" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">创建文本矢量化图层</h1><blockquote class="kw kx ky"><p id="d494" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">1.按词频获取所有词汇</p><p id="4cef" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">2.制作单词和索引的张量来创建初始化器</p><p id="7e85" class="jt ju kz jv b jw kr jy jz ka ks kc kd la kt kg kh lb ku kk kl lc kv ko kp kq hb bi translated">3.做一张桌子</p></blockquote><p id="ce58" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">词频:使用前1000个单词作为词汇表</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">词频</figcaption></figure><h2 id="6b06" class="lj iw hi bd ix lk ll lm jb ln lo lp jf ke lq lr jj ki ls lt jn km lu lv jr lw bi translated">接下来，我们将输出一个max_size最常用单词的列表(现在设置为1000)，确保<pad>是第一个。</pad></h2><h2 id="f264" class="lj iw hi bd ix lk ll lm jb ln lo lp jf ke lq lr jj ki ls lt jn km lu lv jr lw bi translated">创建文本矢量层</h2><p id="2866" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">在词汇表中查找每个单词的索引</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="f056" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在我们的模型中使用它之前，我们必须创建文本向量类并对其进行修改。</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div></figure><h1 id="f590" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">一袋单词</h1><p id="8bf3" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">这也是我们需要添加到模型中的一层。这可以让你有一个字数的总结。举个例子，</p><p id="f598" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">tf.constant([[1，3，1，0，0]，[2，2，0，0，0]])</p><p id="7060" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们计算发生的次数并得到这个(不是输出)</p><p id="cb82" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi">[[ 0:2 , 1: 2 , 2:0 , 3:1 ] , [ 0:3 , 1:0 , 2:2 , 3: 0 ] ]</p><p id="f369" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">去掉0 ( <pad>，所以是[[2。, 0., 1.] , [0., 2., 0.,]]</pad></p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="23ef" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">稍后创建一个类添加到模型中，我们将在模型中传递我们的输入。</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">一袋单词</figcaption></figure><p id="3c8e" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">总结和训练模型</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lh li l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">基于张量流的电影评论分类</figcaption></figure><p id="b72e" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">如果不微调参数，我们可以得到大约0.73的精度。</p><pre class="ld le lf lg fd lx ly lz ma aw mb bi"><span id="cd73" class="lj iw hi ly b fi mc md l me mf">Epoch 1/5<br/>782/782 [==============================] - 12s 15ms/step - loss: 0.1737 - accuracy: 0.9498 - val_loss: 0.6392 - val_accuracy: 0.7236<br/>Epoch 2/5<br/>782/782 [==============================] - 12s 15ms/step - loss: 0.1060 - accuracy: 0.9794 - val_loss: 0.7092 - val_accuracy: 0.7214<br/>Epoch 3/5<br/>782/782 [==============================] - 12s 15ms/step - loss: 0.0605 - accuracy: 0.9944 - val_loss: 0.7724 - val_accuracy: 0.7258<br/>Epoch 4/5<br/>782/782 [==============================] - 12s 15ms/step - loss: 0.0327 - accuracy: 0.9989 - val_loss: 0.8467 - val_accuracy: 0.7179<br/>Epoch 5/5<br/>782/782 [==============================] - 12s 15ms/step - loss: 0.0177 - accuracy: 0.9998 - val_loss: 0.9208 - val_accuracy: 0.7253</span><span id="c43a" class="lj iw hi ly b fi mg md l me mf">&lt;tensorflow.python.keras.callbacks.History at 0x7fb437eb2d68&gt;</span></pre><p id="e881" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">下一篇文章，我将尝试总结我在使用TensorFlow和Keras处理用于训练的图像数据方面的笔记。</p><p id="86e8" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><em class="kz">参考:使用Scikit-Learn、Keras和TensorFlow进行机器实践学习:构建智能系统的概念、工具和技术第二版</em></p></div></div>    
</body>
</html>