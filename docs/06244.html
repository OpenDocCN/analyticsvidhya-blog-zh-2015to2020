<html>
<head>
<title>How Bayesian Inference works in Data Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯推理在数据分析中的工作原理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-bayesian-inference-works-in-data-analysis-578af48ab6b8?source=collection_archive---------27-----------------------#2020-05-15">https://medium.com/analytics-vidhya/how-bayesian-inference-works-in-data-analysis-578af48ab6b8?source=collection_archive---------27-----------------------#2020-05-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="90e6" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">我们可以通过随机实验为我们先前的信念提供证据</p></blockquote><p id="b1af" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">在高中，你可能学过贝叶斯定理，它指出，如果一个事件(随机实验)依赖于不同的其他事件(或者这里我们说信念)的概率是已知的，那么我们可以找到我们的一个信念依赖于随机实验的概率。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jk"><img src="../Images/2f5d9c32a0df9105c72ec4c8622c971d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*H-UCKO96ZkeUFD0TWYe56A.jpeg"/></div></figure><p id="5363" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">例如，随机实验A依赖于事件B(信念),</p><p id="06fc" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">P(A) = P(A ∩ B) + P(A ∩ notB)，这给出</p><p id="a968" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">P(A)= P(A | B)P(B)+P(A | notB)P(notB)</p><p id="dfdd" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">当我们知道A对B和notB的依赖概率时，我们就可以计算我们信念的条件概率，即P(B)</p><p id="31a7" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">P(B|A) = 1 - P(A|notB)/ P(A)</p><p id="7afd" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">在贝叶斯推理中，我们把我们之前信念的概率称为<strong class="il hj">先验</strong>，把我们随机实验的概率称为<strong class="il hj">后验</strong>。</p><p id="ddcb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">在真实世界场景中，后验概率是从我们想要分析的实际数据中生成的，并且我们的先验信念的概率是作为我们的后验的函数来计算的。</p><p id="ddc3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">概率编程</strong>纯粹是贝叶斯推理的结果，用于预测和信心测试我们对数据科学的信念。概率编程比机器学习模型有一个优势，它显示了与预测相关的风险以及我们可以对我们的模型显示多少信心。基本上，它不是用于模型生成或在软件中实现，而是用于通过测试参数值超过一千次甚至更多次来获得洞察力或推断。</p><p id="0622" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">我将借助两个例子来说明贝叶斯推理是如何工作的。第一个是简单的数学难题，第二个是概率规划的介绍性例子。</p><p id="c678" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">假设我们有两个名为A和B的乞丐，分别装着红色和蓝色的球，袋子A有5个红色和7个蓝色的球，乞丐B有4个红色和8个蓝色的球。现在我从一个袋子里抽出一个球(不知道是哪个袋子)，发现是红色的，让我们用X表示这个事件。</p><p id="f02a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这里，我有一个信念，球是从袋子A中取出的(这个信念可以是任何直觉、经验或领域知识)，让我们把从袋子A中取出球的事件表示为‘A’，从袋子B中取出球的事件表示为‘B’。从两个袋子里抽出球的可能性是一样的。</p><p id="82f2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">P(A)=P(B) =0.5，也</p><p id="53fa" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">P(X|A ),即球从袋中取出时是红色的，A = 5/12</p><p id="3b90" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">类似地，P(X|B) = 4/12</p><p id="82be" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在，假设在不同的独立抽奖中，我们发现P(X)即红色的球是0.3，这是我们的<strong class="il hj">后验</strong>和我们的<strong class="il hj">先验</strong>是P(A|X)，为了找到它，我们将使用贝叶斯定理，</p><p id="9e21" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">P(A | X)= P(X | A)P(A)/(P(X | A)P(A)+P(X | B)P(B))。这给了</p><p id="bd3e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">p(A | X)=(0.5 X 5/12)/(0.5 X 5/12+0.5 X 4/12)= 0.55</p><p id="d35b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这是我们先验信念的概率。根据这些结果，我们可以更新我们的信念。这就是贝叶斯推理如何塑造我们的信念。现在我们更新的信念是，如果抽一个红球，球有55 %的机会从袋子A被拿走。</p><p id="4453" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">另一个例子来自《黑客的贝叶斯方法》这本书。它是贝叶斯方法在损失函数最小化中的应用。损失函数用于通过寻找回归线的最佳参数来使我们的回归线最佳拟合数据，例如，如果您试图将一条直线拟合到您的数据中，则该直线的方程将为:Yhat = aX +b</p><p id="ce63" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">x和Y是表示数据点坐标的变量，a和b是线参数，而Yhat(读作Y- hat)是使用线性回归模型的预测变量。如果我们使用MSE(均方误差)作为误差度量，我们的损失函数将看起来像，</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es js"><img src="../Images/e5f179e59b109c05355a96956acb09ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/0*1mW9T5xquX8TuM6b.png"/></div></figure><p id="370f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这是我们的损失函数，用aX +b代替Yhat，我们试图找出a和b的最佳值。如果我们的数据是线性的，使用线性回归是可以的，但是如果我们的数据是非线性的或者带有噪声的线性，那么线性回归不会产生好的结果。假设我们的数据看起来像这样，</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es jt"><img src="../Images/4ce52383f328f209401673f180d10a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1LYVQsacBcHR1gf-yN9jhw.png"/></div></div></figure><p id="03a0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这是我们的交易信号数据(模拟的)，显然我们的线性回归线不能很好地拟合数据。这里进入图片贝叶斯方法，假设我们修改我们的线的方程为Yhat = aX +b +c</p><p id="5606" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这里，我们引入了一个新的变量“c”来改善数据，c被称为变量，因为它的值不是固定的，而是相对于x而变化的。c变量说明了数据与线性的差异，并使直线更好地拟合数据。</p><p id="8470" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">使用概率编程，如pyMC3，它主要用于“黑客的贝叶斯方法”一书中，我们可以生成变量c的样本，假设它是正态分布的。我们不去研究概率规划或pyMC的细节，在这里我只是告诉你，你可以使用pyMC建模找到我们的随机变量‘c’的最佳值。一旦我们观察到pyMC建模的结果，我们就可以用旧的回归线绘制新的回归线，如下所示</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jy"><img src="../Images/14eab9a1e9814328a25efa7ea1dc1821.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*2X23IfjSc7fxwrUefwgelw.png"/></div></figure><p id="6102" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这里我们使用了贝叶斯推断，假设变量c为正态分布，这比单独使用线性回归要好得多。</p><p id="d68e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">霍普，你会对贝叶斯方法有所了解。</p></div></div>    
</body>
</html>