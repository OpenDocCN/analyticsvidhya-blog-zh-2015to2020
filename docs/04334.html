<html>
<head>
<title>L1 vs L2 Regularization: The intuitive difference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">L1 vs L2正规化:直观的差异</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/l1-vs-l2-regularization-which-is-better-d01068e6658c?source=collection_archive---------1-----------------------#2020-03-15">https://medium.com/analytics-vidhya/l1-vs-l2-regularization-which-is-better-d01068e6658c?source=collection_archive---------1-----------------------#2020-03-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="aea1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练机器学习模型时，许多人通常会弄不清哪种正则化技术更好，以避免过拟合。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/8b877034850f9e177329dfb90773402f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*-LydhQEDyg-4yy5hGEj5wA.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">来源—<a class="ae jp" href="http://laid.delanover.com/difference-between-l1-and-l2-regularization-implementation-and-visualization-in-tensorflow/" rel="noopener ugc nofollow" target="_blank">http://layed . delanover . com/difference-between-L1-and-L2-正则化-实现和可视化-in-tensorflow/ </a></figcaption></figure><p id="5cf8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不会详细谈论数学方面的内容。取而代之的是试图解释它们之间的直观差异。</p><blockquote class="jq jr js"><p id="0508" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">L1正则化和L2正则化之间的主要直观差异是L1正则化试图估计数据的中值，而L2正则化试图估计数据的平均值以避免过拟合。</p></blockquote><p id="d6ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从L1和L2正则化的公式中可以看出，L1正则化通过增加权重(Wj)参数的绝对值在代价函数中增加了惩罚项，而L2正则化在代价函数中增加了权重(Wj)的平方值。</p><p id="dd1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在对成本函数求导时，在<strong class="ih hj"> L1正则化</strong>中，它将在数据的中值附近进行估计。让我这样解释吧——假设你从数据中取一个任意值(假设数据沿着一条水平线展开)。如果你随后在一个方向上移动到某个距离<strong class="ih hj">d，T7】假设在向后的方向上，那么在计算损耗时，所选点的一侧(比如左侧)的值将具有较小的损耗值，而另一侧的值将在损耗函数计算中贡献更多。</strong></p><p id="17f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，为了使损失函数最小化，我们应该尝试估计一个位于数据分布中间的值。该值也将是数学上数据分布的<strong class="ih hj"> <em class="jt">中值</em> </strong>。</p><p id="d8a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">而在<strong class="ih hj"> L2正则化中，</strong>在梯度计算步骤中计算损失函数时，损失函数试图通过从数据分布的平均值中减去损失来最小化损失。</p><p id="b51a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是L1(套索)和L2(山脊)正则化技术之间的主要直观差异。</p><blockquote class="jx"><p id="3d61" class="jy jz hi bd ka kb kc kd ke kf kg jc dx translated">它们之间的另一个区别是L1正则化通过消除不重要的特征来帮助特征选择。当特征点的数量很大时，这是有帮助的。</p></blockquote><p id="698c" class="pw-post-body-paragraph if ig hi ih b ii kh ik il im ki io ip iq kj is it iu kk iw ix iy kl ja jb jc hb bi translated">这次都是我这边的。希望我能够解释两种正则化技术之间的直观差异。</p></div></div>    
</body>
</html>