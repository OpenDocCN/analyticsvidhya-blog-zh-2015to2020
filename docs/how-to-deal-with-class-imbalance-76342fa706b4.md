# 如何应对阶层失衡？

> 原文：<https://medium.com/analytics-vidhya/how-to-deal-with-class-imbalance-76342fa706b4?source=collection_archive---------26----------------------->

![](img/b97d66b24c7bd4677764ab23e9d91859.png)

# 为什么不平衡会成为一个问题？

有很多这样的例子，人们不会以 50/50 的比例分开:欺诈没有合法的银行交易多；大多数疾病只影响全球人口的一部分；使用网络的人(可以是内部网、论坛/网站，甚至是地下网络)大多都被允许这样做，只有少数“用户”是非法的。

不幸的是，数据集中的高类别不平衡意味着模型将倾向于对主要类别中给定的任何值进行分类。如果 90%的数据为“1”，则该模型将在 90%的情况下预测为“1”。

话虽如此，但重要的是要注意，线性回归和逻辑回归等模型并没有真正受到阶层失衡的影响。

# 对此我们能做些什么？

## 欠采样多数类

解决这种不平衡的一个方法是减少主要班级的人数。正如您可能已经猜到的，这种方法需要丢弃观察值。这是不理想的，因为它意味着丢失信息，但同时，它减少了处理数据所需的处理能力，这总是好的。

有各种方法来执行类欠采样，例如:

*   丢弃随机选择的观察值。
*   使用 K-最近邻聚类方法并使用质心作为数据点。

关于欠采样方法的更详细列表，参见[本页](https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/under-sampling/plot_comparison_under_sampling.html#sphx-glr-auto-examples-under-sampling-plot-comparison-under-sampling-py)。

*注意:本文中解决的许多方法都没有在* `scikit-learn` *库中实现，但是运行* `pip install -U imbalanced-learn` *将安装* `imblearn` *库，这是一个专门解决类不平衡的库。*

## 对少数民族阶层进行过度采样

这种方法的优势在于使少数类更加强大，可以通过两种方式实现:

*   在数据收集期间。例如，如果研究一种有 10%机会发展的疾病，与未受影响的患者相比，查询 5 倍多的受影响患者将导致 50/50 的分裂。
*   在收集了数据之后。有一系列方法允许创建“人工”数据点。

我将再次推荐`imblearn` [对比页面](https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/over-sampling/plot_comparison_over_sampling.html#sphx-glr-auto-examples-over-sampling-plot-comparison-over-sampling-py)来评估过采样的不同(后数据收集)技术。但是，简而言之，解决方案是:

*   复制样本(所有样本或少数类的随机子集)。
*   SMOTE(合成少数过采样技术)将在数据点之间生成合成样本。正如这个网站上的[所说，理解合成概念的最简单方法是在不同的少数数据点之间画线，SMOTE 会用数据点填充这些线。](http://rikunert.com/SMOTE_explained)
*   [ADASYN](https://sci2s.ugr.es/keel/pdf/algorithm/congreso/2008-He-ieee.pdf) (自适应合成采样)是 SMOTE 的改进。它使用 SMOTE 来生成那些线性相关的样本，然后将一定(少量)的随机性添加到那些样本中。

## 使用针对等级不平衡优化的模型

有时，在建模步骤中解决不平衡更容易。但是请记住，大多数情况下，它会显著增加计算时间。

*   RUSboost 是一种在提升的每次迭代中随机欠采样的方法(Adaboost 是该模型的基础)。
*   SMOTEboost 将在提升过程的每次迭代中使用 SMOTE(同样，它将使用 Adaboost)。
*   SMOTEbagging 将在装袋过程的每个步骤中使用 SMOTE。

## class_weight 参数

大多数分类器/回归器都有一个`class_weight=`参数，该参数预期:

*   例如，在二进制分类器的情况下，字典“class_label:class_weight”，`{0:1, 1:2}`。
*   例如，在诸如具有 4 个结果的随机森林的多类输出的情况下，字典列表“class_label:class_weight”，`[{0:1,1:4}, {0:1,1:1}, {0:1,1:1}, {0:1, 1:1}]`。
*   `balanced`其中 y 值将自动调整输入数据中与类别频率成反比的权重:`n_samples / (n_classes * np.bincount(y))`

这是解决职业不平衡的最简单的方法之一(尤其是`balanced`选项),而且总是值得一试。

## 阈值选择

不管是否已经使用了一些预处理方法，下面的方法总是对模型的一个很好的补充。尤其是考虑到这种方法的第一步是理解问题，并且能够评估错误的成本。任何统计模型都会产生预测，可分类如下:

![](img/d87e82479eda84f6d6ad1dda1e1142e7.png)

*   真阳性(TP)是模型预测为阳性(1)而实际值为真(1)的值。
*   假阳性(TN)是模型预测为阴性(0)而实际值为假(0)的值。
*   假阳性(FP)，也称为**I 型误差**，是模型预测为阳性(1)而实际值为假(0)的值。
*   假阴性(FN)，也称为**II 型误差**，是模型预测为阴性(0)而实际值为真(1)的值。

有了模型误差，阈值选择方法就开始有意义了！根据模型提供解决方案的问题，假阳性的成本可能没有假阴性的成本糟糕(反之亦然)，因此人们可能希望将这些成本最小化。

让我们用垃圾邮件来说明这个理论:我们大多数人可能只收到几封不想要的电子邮件(类别不平衡)，但我非常确定我们都在垃圾邮件文件夹中找到了一封合法的电子邮件(假阳性)，我希望我们没有人点击过那个欺诈链接，尽管该电子邮件在收件箱而不是垃圾邮件文件夹中(假阴性)。从用户的角度来看，时不时地访问垃圾邮件文件夹比感染病毒或被诈骗要简单得多。虽然从模型的角度来看，将所有电子邮件分类为非垃圾邮件是非常准确的，但是因为误报的成本比误报的成本低得多，所以强烈建议选择一个阈值，这可能意味着模型不太准确，但是其错误的后果被最小化。

为了实现一个好的阈值选择，关键是要了解一些指标是什么，以便选择一个将很好地为您服务。下图总结了大多数可用的指标。

## 结论

有很多方法可以解决不平衡的数据集。有些解决方案实现起来非常繁琐，有些内置于`sklearn`(或`imblearn`)中，使用起来非常简单。

总的来说，没有最终的解决方案来解决这个问题，再次实验将是确保哪种方法最适合您正在处理的数据的唯一方法。

我建议的唯一一件事是认真考虑这一点，无论您决定采用哪种解决方案，使用阈值选择作为微调模型的最后一步。