<html>
<head>
<title>Deeply Explained Cross-Validation in ML/AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入解释ML/AI中的交叉验证</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deeply-explained-cross-validation-in-ml-ai-2e846a83f6ed?source=collection_archive---------4-----------------------#2020-05-01">https://medium.com/analytics-vidhya/deeply-explained-cross-validation-in-ml-ai-2e846a83f6ed?source=collection_archive---------4-----------------------#2020-05-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/692955dcf0ea64063b101b31e3f9e011.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*30w58uz0cFn-ZO1cyzNa9w.jpeg"/></div></div></figure><h2 id="7136" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">博客里程碑</strong></h2><ul class=""><li id="d847" class="jo jp hi jq b jr js jt ju jb jv jf jw jj jx jy jz ka kb kc bi translated">背景信息</li><li id="dc95" class="jo jp hi jq b jr kd jt ke jb kf jf kg jj kh jy jz ka kb kc bi translated">为什么要交叉验证？</li><li id="256c" class="jo jp hi jq b jr kd jt ke jb kf jf kg jj kh jy jz ka kb kc bi translated">什么是交叉验证？<br/> -类型<br/> -应用</li><li id="5b76" class="jo jp hi jq b jr kd jt ke jb kf jf kg jj kh jy jz ka kb kc bi translated">代码实现<br/> -手动<br/>-Scikit-学习库</li><li id="7491" class="jo jp hi jq b jr kd jt ke jb kf jf kg jj kh jy jz ka kb kc bi translated">建议和推论</li></ul></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="85e3" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi lg translated">呈现一个有趣的学习，关于如何处理ML/AI模型的训练和评估。博客将回答选择哪个模型，或者哪些是您的模型性能最佳的调整参数。<em class="lp">所以..<br/>准备好！滚！就位。走吧。</em></p><h1 id="d9ab" class="lq ir hi bd is lr ls lt iw lu lv lw ja lx ly lz je ma mb mc ji md me mf jm mg bi translated">背景信息</h1><p id="eb87" class="pw-post-body-paragraph kp kq hi jq b jr js ks kt jt ju kv kw jb mh ky kz jf mi lb lc jj mj le lf jy hb bi translated">在构建任何ML模型时，通常都要遵循某些步骤，如数据预处理、数据划分为训练/测试、训练和评估。从技术上讲，训练在训练集上进行，模型在验证集上调整，在测试集上评估。可以看出，来自相同整个数据集的不同数据集产生不同的度量分数，这造成了模型性能的不确定性。因此，交叉验证对于模型的精确估计是有意义的。</p><h1 id="5b46" class="lq ir hi bd is lr ls lt iw lu lv lw ja lx ly lz je ma mb mc ji md me mf jm mg bi translated">为什么要交叉验证？</h1><p id="6597" class="pw-post-body-paragraph kp kq hi jq b jr js ks kt jt ju kv kw jb mh ky kz jf mi lb lc jj mj le lf jy hb bi translated">为了创建模型，对训练数据执行训练，并对测试数据进行测试，这需要以以下不同方式划分整个数据。</p><ol class=""><li id="d683" class="jo jp hi jq b jr kr jt ku jb mk jf ml jj mm jy mn ka kb kc bi translated"><strong class="jq hj">使用全部数据作为训练/测试</strong> <br/>模型使用全部数据进行训练和测试，有意义吗？得了吧，一点也不！让我们以这种方式，你为你的考试学习了10个问题，你的知识将在考试中根据同样的10个问题进行评估。Lol，你会得到100分。</li></ol><p id="1356" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated"><strong class="jq hj"> 2。将数据分为训练和测试<br/> </strong>数据按比例分为训练和测试。这可以通过使用sklearn的<em class="lp"> train_test_split </em>功能来实现。</p><figure class="mo mp mq mr fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="3608" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">每次运行代码时，使用<em class="lp"> random_state </em>都会产生一组相同的随机数。因此，除非您更改random_state值，否则您的结果不会改变。如果不使用random_state，每次运行代码都会得到不同的分数。所以，你不确定你的模型在看不见的数据上会有怎样的表现。<br/> <strong class="jq hj">这种不确定性在结果突起的交叉验证中变成了图画。</strong></p><p id="b0e7" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated"><strong class="jq hj"> 3。交叉验证<br/> </strong>数据虽然像train_test_split一样分为训练/测试，但事实上是在不同的数据集上重复训练和评估。这就像，你的数据被分成5次训练/测试，每次都被训练和评估。每次分割的方式都不同于之前的评估，并取所有5个评估结果的平均值。<em class="lp">仍未清除。不要担心，深入的解释仍在等待。</em></p><p id="0e71" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">我们多喝点。</p><h1 id="0253" class="lq ir hi bd is lr ls lt iw lu lv lw ja lx ly lz je ma mb mc ji md me mf jm mg bi translated">什么是交叉验证？</h1><p id="d84a" class="pw-post-body-paragraph kp kq hi jq b jr js ks kt jt ju kv kw jb mh ky kz jf mi lb lc jj mj le lf jy hb bi translated">交叉验证基本上是一种重采样技术，以确保我们的模型在未知数据上的效率和准确性。简而言之，模型验证技术，可用于其他应用。</p><p id="8e6c" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated"><strong class="jq hj">一组训练/测试分割——测试每个分割的精确度——对它们进行平均</strong></p><p id="5ba6" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">快速步骤为:<br/> 1:将数据分成K个分区。这些分区将具有相同的大小。<br/> 2:将fold-1视为测试Fold，而将K-1视为训练Fold。<br/> 3:计算测试分数。<br/> 4:对所有褶皱重复步骤3，将另一个褶皱作为测试，同时保持为列。<br/> 5:取所有褶皱的平均值。</p><p id="bad8" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">它将我们的数据划分为训练/测试，这样前一组数据就不会重复，并且对每一组数据只进行一次训练和测试。<strong class="jq hj">每个分区</strong> ( <em class="lp">又名折叠</em> ) <strong class="jq hj">大小相等</strong>。可以说，每一个数据点都是它人生旅途中的一次锻炼和考验。这是交叉验证的基本功能，在调整超参数或选择ML模型(如用于分类问题的逻辑或决策树)时非常有用。</p><p id="375b" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">它<strong class="jq hj">通过选择K <strong class="jq hj">的最佳值来防止过配合和欠配合</strong>。</strong>同样，<strong class="jq hj">比train_test_split方法更精确的模型估计</strong>。</p><h2 id="bb4a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">交叉验证的类型</h2><figure class="mo mp mq mr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/487129f8fb8acb7147ae3832b92b59c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*nk0514O3cRWid25TKn7IIA.png"/></div></div><figcaption class="mv mw et er es mx my bd b be z dx translated">图一</figcaption></figure><p id="147c" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">上面举例说明了常用的类型。让我们了解一下他们。</p><ul class=""><li id="7330" class="jo jp hi jq b jr kr jt ku jb mk jf ml jj mm jy jz ka kb kc bi translated"><strong class="jq hj">留一交叉验证(LOOCV): <br/> </strong>这是一种非常古老的技术，已被k折叠和分层k折叠所取代，但在某些场景中仍然有用。<strong class="jq hj">数据被分割成块，每块代表一个记录作为测试，而其余的作为序列</strong>。每一条记录都被视为测试，并对每一条记录进行多次迭代评估。<br/> <em class="lp">我们来举个例子。</em><br/>20条记录的数据是指20个分区，每个分区有一条记录。这导致训练和评估的20次迭代。</li></ul><figure class="mo mp mq mr fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/6d2de2e452180a0c64b1ee86ffc91979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*qx1UY2yM4Vn4N4kEg8mqzA.png"/></div><figcaption class="mv mw et er es mx my bd b be z dx translated">图2</figcaption></figure><p id="10b7" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">在第一次迭代中，在第一个区块(褶皱)上测试模型，并在剩余的19个褶皱上测试模型，给出一个精确度。在下一次迭代中，将下一个记录作为测试集同时保持为训练集的另一个块给出了另一个精度。LOOCV在20次迭代中对所有20条记录进行测试和训练，因此<strong class="jq hj">计算能力昂贵</strong>。然后计算所有组的平均值，并作为最终准确度(也称为k倍分数)抛出。</p><p id="f4a0" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated"><strong class="jq hj">优点:<br/></strong>——当在看不见的数据上测试时，它给出了模型性能的确定性。</p><p id="2888" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated"><strong class="jq hj">限制:</strong> <br/> -与train_test_split相比，它需要更多的<strong class="jq hj">计算能力</strong>。<br/> -由于一切都经过测试和训练，导致<strong class="jq hj">方差</strong>更高，测试 <strong class="jq hj">生产</strong>中看不见的数据<strong class="jq hj">导致<strong class="jq hj">结果不佳</strong>。<br/>结果可能导致<strong class="jq hj">较高的变化</strong>，如测试异常数据点时。</strong></p><ul class=""><li id="e6ac" class="jo jp hi jq b jr kr jt ku jb mk jf ml jj mm jy jz ka kb kc bi translated"><strong class="jq hj"> K倍交叉验证:</strong></li></ul><p id="a4f4" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">交叉验证的一种变体，其中<strong class="jq hj">数据被划分为基于“K”</strong>的训练/测试分区。这里，K是指任何整数，而fold是指一个分区(或迭代)。模型在K-1个分区上执行训练，并在数据的第K个分区上执行测试。<br/> <strong class="jq hj"> <em class="lp">例为4重交叉验证，</em> </strong> <br/>例为20条记录的数据，给出4重。数据分为4个分区。每个分区有(20/4=)5条记录。</p><figure class="mo mp mq mr fd ij er es paragraph-image"><div class="er es na"><img src="../Images/c8cef7017c5d2fd809a5eeaad48ca3b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*AckPZznvp6gAb9XyaIMytQ.png"/></div><figcaption class="mv mw et er es mx my bd b be z dx translated">图3</figcaption></figure><p id="b90a" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">在第一次迭代中，模型在第一个区块进行了测试，并在剩余的4个区块进行了训练，结果是准确的。在下一次迭代中，另一个块作为测试集，同时保持为训练集，从而产生另一个精度。这一划分和评估过程针对所有5个折叠进行。计算所有集合的平均值，并将其作为最终精度，该精度被视为模型精度。</p><p id="3062" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated"><strong class="jq hj">优点:<br/> - </strong>一定程度上克服了类似LOO中的计算能力问题。<br/> -由于不是每个记录都像LOOCV一样被视为测试集，因此，如果数据中存在任何异常值，模型可能不会受到太大影响。克服了<strong class="jq hj">可变性</strong>的问题。</p><p id="3f02" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated"><strong class="jq hj">限制:<br/> - </strong>在任何迭代中，测试集都有可能只有一个类的记录。这将使数据<strong class="jq hj">不平衡</strong>并影响我们的模型。</p><ul class=""><li id="7532" class="jo jp hi jq b jr kr jt ku jb mk jf ml jj mm jy jz ka kb kc bi translated"><strong class="jq hj">分层K-Fold交叉验证:<br/> </strong>这是K-Fold的<strong class="jq hj">改进版本，其中现在每个Fold具有每个目标类的相同百分比的样本</strong>。假设二进制分类的依赖类为1/0。当只有类别1的记录落入测试集并且模型被训练和评估时，事情会出错，导致数据不平衡的情况。这样，分层就出现了。</li></ul><h2 id="ef3f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">交叉验证的应用</h2><ul class=""><li id="b0a8" class="jo jp hi jq b jr js jt ju jb jv jf jw jj jx jy jz ka kb kc bi translated">通过超参数调整改进模型</li><li id="509d" class="jo jp hi jq b jr kd jt ke jb kf jf kg jj kh jy jz ka kb kc bi translated">比较模型，帮助选择一个</li><li id="d4d6" class="jo jp hi jq b jr kd jt ke jb kf jf kg jj kh jy jz ka kb kc bi translated">为模型选择的最佳特性</li></ul><p id="cdb3" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">有关实现，请参考此处的代码。</p><h1 id="73ff" class="lq ir hi bd is lr ls lt iw lu lv lw ja lx ly lz je ma mb mc ji md me mf jm mg bi translated">代码实现</h1><p id="3f14" class="pw-post-body-paragraph kp kq hi jq b jr js ks kt jt ju kv kw jb mh ky kz jf mi lb lc jj mj le lf jy hb bi translated">交叉验证的关键基本上是评估作为测试集的每个折叠和它们的平均值。交叉验证的整个过程可以通过循环的<strong class="jq hj">手动完成，也可以使用sklearn的库<strong class="jq hj"> cross_val_score </strong>来完成。</strong></p><h2 id="0ffc" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">用手</h2><p id="0e3d" class="pw-post-body-paragraph kp kq hi jq b jr js ks kt jt ju kv kw jb mh ky kz jf mi lb lc jj mj le lf jy hb bi translated">根据下面的演示，<br/> - KFold类被实例化，folds通过<em class="lp"> n_splits </em>指定，因此是5-fold CV。<br/> -在每次迭代中循环迭代来自KFold.split() <br/>的训练/测试数据，<br/>-数据被分割成一组训练/测试(就像train_test_split一样)<br/>-对训练折叠进行逻辑回归训练<br/>-计算测试折叠的准确度分数<br/>附加每次迭代中测试折叠的分数，并取所有分数的平均值计算交叉验证分数。</p><figure class="mo mp mq mr fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><h2 id="8da0" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">sci kit-学习库</h2><p id="7ffa" class="pw-post-body-paragraph kp kq hi jq b jr js ks kt jt ju kv kw jb mh ky kz jf mi lb lc jj mj le lf jy hb bi translated">Python的scikit-learn库提供了交叉验证类来划分和计算平均分。<br/><strong class="jq hj"><em class="lp">cross _ val _ score</em></strong>是scikit-learn库，它返回每个测试文件夹的分数，即每次迭代中的准确度分数列表。K-fold是分数的平均值，通过取cross_val_score结果的平均值来推导。<br/><strong class="jq hj"><em class="lp">cross _ val _ predict</em></strong>是另一个scikit-learn库，返回每个测试折叠的预测值。</p><figure class="mo mp mq mr fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="91dc" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">默认情况下，整型cv参数假定为分层K-Fold。如上所述，它是分层5倍。若要使用K折叠，请作为cv=KFold(n_splits=5)传递。</p><h1 id="047b" class="lq ir hi bd is lr ls lt iw lu lv lw ja lx ly lz je ma mb mc ji md me mf jm mg bi translated">建议和推论</h1><ul class=""><li id="ccda" class="jo jp hi jq b jr js jt ju jb jv jf jw jj jx jy jz ka kb kc bi translated">当分类技术出现时，使用分层K-Fold。</li><li id="8e8d" class="jo jp hi jq b jr kd jt ke jb kf jf kg jj kh jy jz ka kb kc bi translated">明智地选择K值，以保持任何模型更好地执行所需的偏差和方差的平衡。<br/> <strong class="jq hj">较低的k </strong>导致<strong class="jq hj">更多偏差</strong>，<strong class="jq hj">更少方差</strong>(欠拟合)<br/> <strong class="jq hj">较高的k </strong>导致<strong class="jq hj">更少偏差</strong>，<strong class="jq hj">更多方差</strong>(过拟合)</li><li id="9e08" class="jo jp hi jq b jr kd jt ke jb kf jf kg jj kh jy jz ka kb kc bi translated">如果数据本身很小，k倍就没有意义。在这种情况下，LOOCV会被拖下水。</li></ul><blockquote class="nb"><p id="52de" class="nc nd hi bd ne nf ng nh ni nj nk jy dx translated"><strong class="ak">请找到我的</strong> <a class="ae nl" href="https://github.com/shachi01/machine-learning/blob/master/ml_cross_validation.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> github代码</strong> </a> <strong class="ak">来确认这篇博客中涉及的概念。</strong></p></blockquote><h1 id="20e8" class="lq ir hi bd is lr ls lt iw lu lv lw ja lx nm lz je ma nn mc ji md no mf jm mg bi translated">参考</h1><p id="373f" class="pw-post-body-paragraph kp kq hi jq b jr js ks kt jt ju kv kw jb mh ky kz jf mi lb lc jj mj le lf jy hb bi translated">值得一看，以了解更多关于交叉验证。</p><figure class="mo mp mq mr fd ij"><div class="bz dy l di"><div class="np mt l"/></div></figure><p id="9538" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">借此机会访问这个<a class="ae nl" href="https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/" rel="noopener ugc nofollow" target="_blank">博客</a>，了解CV如何帮助改进模型。</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="e98a" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">如果你喜欢这个作者的博客，你可以自由关注他，因为他保证会回来分享更多有趣的人工智能技术。此外，如果有任何理解或概念上的错误，请随时告诉我。</p><p id="305b" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">谢谢，</p><p id="6dc7" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated">快乐阅读！:)</p><p id="ee99" class="pw-post-body-paragraph kp kq hi jq b jr kr ks kt jt ku kv kw jb kx ky kz jf la lb lc jj ld le lf jy hb bi translated"><strong class="jq hj"> <em class="lp">可以通过</em></strong><a class="ae nl" href="https://www.linkedin.com/in/kaul-shachi" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"><em class="lp">LinkedIn</em></strong></a><strong class="jq hj"><em class="lp">取得联系。</em>T49】</strong></p></div></div>    
</body>
</html>