<html>
<head>
<title>(Visually) Interpreting the confusion-matrix:</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">(视觉上)解释混淆矩阵:</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/visually-interpreting-the-confusion-matrix-787a70b65678?source=collection_archive---------3-----------------------#2020-11-01">https://medium.com/analytics-vidhya/visually-interpreting-the-confusion-matrix-787a70b65678?source=collection_archive---------3-----------------------#2020-11-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="bf90" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">标准化与非标准化混淆矩阵</h2><div class=""/><div class=""><h2 id="1361" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated">..作为一名数据科学家，您如何更直观、更有效地从混乱矩阵中获得洞察力。</h2></div><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/8897e3077c7bf3866a98b1078e7b8ffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E-L9IpNzPKeY_paeLTPxhg.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">标准化与非标准化。模型解释哪个好？</figcaption></figure><p id="8f6c" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi ks translated"><span class="l kt ku kv bm kw kx ky kz la di"> B </span> ut首先，什么是混淆矩阵？在机器学习中，混淆矩阵是一种混淆表，用于了解我们的模型预测执行得有多好(<em class="lb">尤其是</em>当我们有多个类而不是经典的二进制0/1问题时会混淆)。然而，渐渐地，我发现混淆矩阵并不那么令人困惑，它对我理解模型行为和解释结果有很大帮助。所以我会试着在这里做同样的事情..<strong class="jy hs"> <em class="lb">让它少一些迷惑，多一些趣味，更容易解读</em> </strong>！</p><p id="32e1" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">在写这篇博客的时候，我假设读者已经有了一些先验知识，并打算回答:</p><ol class=""><li id="a607" class="lc ld hi jy b jz ka kc kd kf le kj lf kn lg kr lh li lj lk bi translated">如何利用可视化工具解读混淆矩阵？</li><li id="adf2" class="lc ld hi jy b jz ll kc lm kf ln kj lo kn lp kr lh li lj lk bi translated">为什么要使用归一化的混淆矩阵进行解释？</li></ol><p id="c6f2" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">首先，让我们看一个简单的二元分类(0/1)混淆矩阵:</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es lq"><img src="../Images/1fc20ab3227dde4a27e4da8a3e9fb108.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P75CJXJLFtFvJ7kKHfQrvQ.png"/></div></div></figure><p id="4239" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">列表示我们的模型做出的预测，行表示实际的类(这是非常流行的Python库ML: <code class="du lr ls lt lu b">sklearn</code>的格式)。一些书有相反的说法，但我将坚持这种格式)。因此<code class="du lr ls lt lu b">cell(0,0)</code>代表真正的否定..即。实际为阴性(属于<code class="du lr ls lt lu b">class 0</code>)的样本数量，我们预测它们也为阴性。类似地，真阳性是我们的模型正确分类为阳性并且实际上是阳性的样本数。</p><p id="dffb" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">假阳性意味着我们预测这些样本为阳性(<code class="du lr ls lt lu b">class 1</code>)，但它们实际上是阴性(<code class="du lr ls lt lu b">class 0</code>)，反之亦然。</p><p id="813e" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">现在，让我们看看随着类别数量的增加，混淆矩阵是如何变得稍微复杂一些的。让我们考虑3类:<code class="du lr ls lt lu b">cats</code>、<code class="du lr ls lt lu b">dogs</code>和<code class="du lr ls lt lu b">fishes.</code></p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es lv"><img src="../Images/3ec890dbc56607a4f51b62037b13b4e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b5FxmrSTdcjnre99EdoNBQ.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">对于100个样本的多类分类</figcaption></figure><p id="e9d4" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">在上图中，<code class="du lr ls lt lu b">cell A</code>代表被我们的模型正确分类的猫的数量。我们可以看到总共<code class="du lr ls lt lu b">30</code>只猫中只有<code class="du lr ls lt lu b">10</code>只被正确分类。<code class="du lr ls lt lu b">Cell E</code>代表<code class="du lr ls lt lu b">30/30</code>正确分类的狗(yaay🐶 ).<code class="du lr ls lt lu b">Cell H</code>代表<code class="du lr ls lt lu b">5</code>被错误归类为狗的鱼。由此可见，我们的模型对狗来说表现最好的是<strong class="jy hs"><em class="lb"/></strong>，对鱼来说表现一般的是<strong class="jy hs"><em class="lb"/></strong>，但对猫来说确实不好的是<strong class="jy hs"><em class="lb"/></strong>。这就是多类混淆矩阵的样子。</p><p id="79b3" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">现在，让我们来到<strong class="jy hs"> <em class="lb">直观地解读</em></strong><strong class="jy hs"><em class="lb">混淆矩阵</em> </strong>:</p><p id="8bb6" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">我创建了一个虚拟混淆矩阵来解释这个概念。这里，我们考虑具有5个标签的多类分类模型的预测输出:<code class="du lr ls lt lu b">label 0 to 4</code>。班级是不平衡的。每个类别的真实样本数不相同。在我的例子中，<code class="du lr ls lt lu b">label 0</code>有<code class="du lr ls lt lu b">100</code>个真实样本，所有<code class="du lr ls lt lu b">other labels</code>都有<code class="du lr ls lt lu b">50</code>个真实样本。所以总共有<code class="du lr ls lt lu b">300</code>个样本。</p><pre class="jh ji jj jk fd lw lu lx ly aw lz bi"><span id="6a67" class="ma mb hi lu b fi mc md l me mf">#Create dummy Confusion Matrix</span><span id="d591" class="ma mb hi lu b fi mg md l me mf">import numpy as np<br/>confusion_matrix = np.array([[79, 1,4,10,6],[0,48,1,1,0],[5,6,25,14,0],[0,0,0,50,0],[9,8,9,19,5]])</span><span id="9b18" class="ma mb hi lu b fi mg md l me mf">print(confusion_matrix)<strong class="lu hs"><br/>OUTPUT:</strong> <br/>[[79 1 4 10 6]<br/> [ 0 48 1 1 0]<br/> [ 5 6 25 14 0]<br/> [ 0 0 0 50 0]<br/> [ 9 8 9 19 5]]</span></pre><p id="ac30" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">正如你所看到的，上面的混乱矩阵很难解释和得出结论。因此，我们使用视觉工具使其更容易解释。我倾向于使用Python中的<code class="du lr ls lt lu b">seaborn</code>库来实现可视化，因为它非常快速且易于使用。让我们根据上面的矩阵创建一个热图。</p><pre class="jh ji jj jk fd lw lu lx ly aw lz bi"><span id="2255" class="ma mb hi lu b fi mc md l me mf">#Create a Confusion Matrix heatmap from the above data<br/>import seaborn as sns<br/>sns.heatmap(cm, annot=True, linewidths = 0.01)</span></pre><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mh"><img src="../Images/b2e607ad04b0a1ed5c2f483a287f0de2.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*PHqSoroxzEYa4fJZ_Rpq4Q.png"/></div></figure><p id="2afd" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">浏览一下矩阵，我们知道:</p><ul class=""><li id="59d5" class="lc ld hi jy b jz ka kc kd kf le kj lf kn lg kr mi li lj lk bi translated"><code class="du lr ls lt lu b">diagonal elements</code>代表每类预测的总正确值。例如:<code class="du lr ls lt lu b">79</code>值已被正确预测为属于<code class="du lr ls lt lu b">100</code>值中的<code class="du lr ls lt lu b">class 0 </code>。(但是请注意，我们并不知道标签0的总班级人数是100)</li><li id="e0e3" class="lc ld hi jy b jz ll kc lm kf ln kj lo kn lp kr mi li lj lk bi translated"><strong class="jy hs"> <em class="lb">颜色越浅，数字越大</em> </strong>..我们可以从侧面的颜色条上看到。因此，我们很自然地会假设——对角线元素上的颜色较浅，而所有其他元素上的颜色较深，这意味着我们的模型表现良好，反之亦然。(然而，这是不正确的，我们将从归一化矩阵中看到。)</li><li id="1bfd" class="lc ld hi jy b jz ll kc lm kf ln kj lo kn lp kr mi li lj lk bi translated">再多保持一点你的好奇心，让我给这个热图更多的解释。<code class="du lr ls lt lu b">class 1</code>和<code class="du lr ls lt lu b">class 3</code>的对角线元素几乎是同样的红色。所以我们也假设这两个类表现一样差。</li><li id="a0c4" class="lc ld hi jy b jz ll kc lm kf ln kj lo kn lp kr mi li lj lk bi translated">对角线元素<code class="du lr ls lt lu b">(0,0)</code>的浅色暗示我们的模型在<code class="du lr ls lt lu b">class 0</code>中表现非常好。</li><li id="2af3" class="lc ld hi jy b jz ll kc lm kf ln kj lo kn lp kr mi li lj lk bi translated">最后但同样重要的是，<code class="du lr ls lt lu b">class 2</code>和<code class="du lr ls lt lu b">class 4</code>表现最差。</li></ul><p id="0f8d" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">现在，让我们来看看这张热图的标准化版本。为了得到规范化的版本，我们将每个行元素除以整行的总和。由于每一行代表每个类标签的实际值的总数，最终的归一化矩阵将向我们显示百分比ie。在特定类别的所有真实标签中，我们的模型对该特定真实标签做出的每个类别的预测百分比是多少。</p><pre class="jh ji jj jk fd lw lu lx ly aw lz bi"><span id="8a7e" class="ma mb hi lu b fi mc md l me mf">#Create normalized Confusion Matrix<br/>cm_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]</span><span id="d2a2" class="ma mb hi lu b fi mg md l me mf">sns.heatmap(cm_normalized, annot=True, linewidths = 0.01)</span></pre><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mj"><img src="../Images/db4e44db8144b7fcf486b7e3ea9c52ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*FMg9t7T-55sY1Sv3I1yeXQ.png"/></div></div></figure><p id="c0ea" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">现在，每个<code class="du lr ls lt lu b">cell (i,j)</code>表示<code class="du lr ls lt lu b">class i</code>标签中的<code class="du lr ls lt lu b">P %</code>被预测为<code class="du lr ls lt lu b">class j</code>。希望这有意义。解释这个矩阵:</p><ul class=""><li id="9cf5" class="lc ld hi jy b jz ka kc kd kf le kj lf kn lg kr mi li lj lk bi translated">第一个主要区别。<code class="du lr ls lt lu b">class 1</code>和<code class="du lr ls lt lu b">class 3</code>的对角线元素，我们认为它们被错误地分类了…实际上被分配到了一个更亮的颜色。更高的数字(或者百分比，如果你愿意的话)。事实上，<code class="du lr ls lt lu b">class 3</code>被完全分类，因为它的值是<code class="du lr ls lt lu b">1</code>。接下来是<code class="du lr ls lt lu b">class 1</code>和<code class="du lr ls lt lu b">0.96</code>正确的预测。</li><li id="a1a7" class="lc ld hi jy b jz ll kc lm kf ln kj lo kn lp kr mi li lj lk bi translated">我们认为<code class="du lr ls lt lu b">class 0</code>是最好的分类类别的假设只是误入歧途。现在是第三好的班级。在<code class="du lr ls lt lu b">class 0</code>的所有真实标签中，我们的模型只能正确分类其中的<code class="du lr ls lt lu b">79%</code>。</li><li id="cc01" class="lc ld hi jy b jz ll kc lm kf ln kj lo kn lp kr mi li lj lk bi translated">根据我们的非归一化混淆矩阵，<code class="du lr ls lt lu b">Class 2</code>表现最差，现在向我们显示它表现相对较好，因为在<code class="du lr ls lt lu b">class 2</code>的所有真实标签中，它正确地将<code class="du lr ls lt lu b">50% </code>分类。</li><li id="d2ea" class="lc ld hi jy b jz ll kc lm kf ln kj lo kn lp kr mi li lj lk bi translated">但是为什么会有这种差异呢..标准化和非标准化混淆矩阵之间的区别？<strong class="jy hs"> <em class="lb">这种差异是由于阶级的不平衡而产生的</em> </strong>。并非所有类别都具有相同数量的总样本，因此非标准化矩阵输出绝对值，而没有考虑总类别大小中有多少比例被正确预测，这导致由于热图的彩色化而导致不正确的结论。</li><li id="50de" class="lc ld hi jy b jz ll kc lm kf ln kj lo kn lp kr mi li lj lk bi translated">因此，从这个矩阵得出最终正确的结论，我们的模型对<code class="du lr ls lt lu b">class 1</code>和<code class="du lr ls lt lu b">class 3</code>表现良好，对<code class="du lr ls lt lu b">class 0</code>表现中等，对<code class="du lr ls lt lu b">class 2</code>和<code class="du lr ls lt lu b">class 4.</code>表现差。因此，作为一名数据科学家，你现在可以专注于为什么你的模型对<code class="du lr ls lt lu b">class 2 and 4</code>表现差。</li></ul><p id="beb7" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">因此，通过对混淆矩阵使用正确的可视化技术，我们能够获得关于我们的模型的正确见解，这就是混淆矩阵可视化的力量。总之，<em class="lb">总是使用标准化的混淆矩阵来解释你的结果。</em></p><p id="9b48" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">以上代码可以在<a class="ae mk" href="https://github.com/riddhinn99/medium-articles-code/blob/main/confusion_matrix_normalized_vs_unnormalized.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="jy hs"> <em class="lb">这里找到</em> </strong> </a>！幸运的是，sklearn还提供了一个内置函数来创建这两种类型的混淆矩阵。你可以在这个<strong class="jy hs"><em class="lb"/></strong><a class="ae mk" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html" rel="noopener ugc nofollow" target="_blank"><em class="lb">sk learn文档</em> </a> <em class="lb">中找到代码和用法。</em></p></div><div class="ab cl ml mm gp mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hb hc hd he hf"><p id="5799" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">感谢阅读！如果你觉得这篇文章很有见地和/或有趣，请为它鼓掌，关注<a class="ae mk" rel="noopener" href="/@riddhinn"> <strong class="jy hs"> <em class="lb">了解更多！😋</em></strong></a></p><p id="fd70" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">一如既往，你和我一起学习。如果你发现一些不正确的东西或者我遗漏了一些明显的东西，请留下回复，我会检查一下。干杯！✨ </p></div></div>    
</body>
</html>