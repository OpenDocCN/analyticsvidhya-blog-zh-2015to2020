<html>
<head>
<title>Information Retrieval (Part 1): Extracting webpages</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">信息检索(第一部分):提取网页</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/information-retrieval-part-1-extracting-webpages-a9d0b715535d?source=collection_archive---------14-----------------------#2019-09-24">https://medium.com/analytics-vidhya/information-retrieval-part-1-extracting-webpages-a9d0b715535d?source=collection_archive---------14-----------------------#2019-09-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1c99b17f86ef0954df3b033b9d62e4c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j5PzJtbnc7ks75ng"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">由<a class="ae iu" href="https://unsplash.com/@samuelzeller?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">塞缪尔·泽勒</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><blockquote class="iv iw ix"><p id="4da7" class="iy iz ja jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">信息检索是从这些资源的集合中获取与信息需求相关的信息系统资源的活动。</p></blockquote><p id="543d" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">在我们继续从数据中提取相关信息之前，让我提供一个关于如何从互联网上搜集信息的简短教程。</p><p id="12fe" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">首先，我们看一下Python中需要导入的库:</p><p id="d865" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated"><strong class="jb hj">注:我用过Python 3.6.5 </strong></p><ul class=""><li id="c6b6" class="ka kb hi jb b jc jd jg jh jx kc jy kd jz ke jw kf kg kh ki bi translated">要求</li><li id="7737" class="ka kb hi jb b jc kj jg kk jx kl jy km jz kn jw kf kg kh ki bi translated">美丽的声音</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="39de" class="kx ky hi kt b fi kz la l lb lc">import requests #for making HTTP requests in Python<br/>from bs4 import BeautifulSoup # pulling data from HTML or XML files</span></pre><p id="e0a4" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">接下来，我们设置一个查询，这是我们感兴趣的提取网页的主题。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="5b66" class="kx ky hi kt b fi kz la l lb lc">query = "deep neural network"</span></pre><p id="0679" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">让我们驾驭<strong class="jb hj">请求</strong>的力量</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="05dc" class="kx ky hi kt b fi kz la l lb lc">r = requests.get('<a class="ae iu" href="https://www.google.com/search?q={}'.format(query))" rel="noopener ugc nofollow" target="_blank">https://www.google.com/search?q={}'.format(query))</a></span></pre><p id="f115" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">现在，我们有一个名为<code class="du ld le lf kt b">r</code>的<code class="du ld le lf kt b"><a class="ae iu" href="https://2.python-requests.org/en/master/api/#requests.Response" rel="noopener ugc nofollow" target="_blank">Response</a></code>对象。我们可以从这个物体中得到我们需要的所有信息。</p></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="5a59" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated"><strong class="jb hj"> <em class="ja">注意:您可能会遇到如下错误</em> </strong></p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="e612" class="kx ky hi kt b fi kz la l lb lc">IOPub data rate exceeded.<br/>The notebook server will temporarily stop sending output<br/>to the client in order to avoid crashing it.</span></pre><p id="2da2" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">要解决这个问题，请参考<strong class="jb hj"> stackoverflow: </strong>上的答案</p><p id="fcf8" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated"><a class="ae iu" href="https://stackoverflow.com/a/43420383/8385813" rel="noopener ugc nofollow" target="_blank"><strong class="jb hj">https://stackoverflow.com/a/43420383/8385813</strong></a></p></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="9176" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">这就是美丽的T21派上用场的地方。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="fce2" class="kx ky hi kt b fi kz la l lb lc">soup = BeautifulSoup(r.text, "html.parser")</span></pre><p id="4d99" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">在透露<strong class="jb hj">汤</strong>储存什么之前，先看看下图</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/b50596cb45cd91787f5f999e1a72c7b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*36mqdrJlNVlIcoD6_z438g.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">在谷歌上搜索“深度神经网络”的前三个结果</figcaption></figure><p id="912e" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">继续，<strong class="jb hj"> soup </strong>变量存储了上述web页面的HTML代码。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="709f" class="kx ky hi kt b fi kz la l lb lc">soup</span></pre><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><p id="1d37" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">很糟糕，对吧？让我们美化这个..</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="5a9a" class="kx ky hi kt b fi kz la l lb lc">print(soup.prettify())</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/dfebeff96b4f75d372627439b1762a2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cQCIEmMt2zwzeNA7EF7tAQ.jpeg"/></div></div></figure><p id="7483" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">在HTML中，<a href="">属性为我们提供了网页的链接。为了获得所有这样的链接，我们运行下面几行代码:</a></p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="f3c8" class="kx ky hi kt b fi kz la l lb lc">links = []<br/>for item in soup.find_all('a'):<br/>    links.append(item.get('href'))</span></pre></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="6faa" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">对于本文，我们的目标是只提取第一个搜索页面的所有链接。</p><p id="1344" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">第三方网页的链接看起来与上图中的相似，以下列字符开头，“/url？q= "，所以我们需要过滤掉这样的字符串。</p><p id="64b2" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">上述任务的代码如下所示:</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="acf5" class="kx ky hi kt b fi kz la l lb lc">final = []<br/>for item in links:<br/>    str = item[0:7]<br/>    if str=="/url?q=":<br/>        final.append(item)</span></pre><p id="7dc2" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">这是变量<strong class="jb hj">最终</strong>存储的内容:</p><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><p id="ce4f" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">假设我们想从第一个网页中访问所有的<p>属性，并将它们连接成一个字符串<strong class="jb hj">文本</strong>。下面几行代码实现了这一点</p></p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="6cbf" class="kx ky hi kt b fi kz la l lb lc">webpage1 = requests.get('<a class="ae iu" href="https://www.google.com/'" rel="noopener ugc nofollow" target="_blank">https://www.google.com/'</a> + final[0]) #final[0] refers to the first web page link<br/>webpagetext = BeautifulSoup(webpage1.text, "html.parser")<br/>all_p = webpagetext.find_all('p')<br/>text = ""<br/>for item in all_p:<br/>    text = text + item.get_text()<br/>print(text)</span></pre><figure class="ko kp kq kr fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><p id="b6a9" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">该文本可能包含许多不必要的内容，如空格、特殊字符等。我们可能不需要提取任何信息。处理它们的技术将在下一个教程中介绍。</p><p id="71d4" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">在下面找到本教程的第2部分:</p><div class="lr ls ez fb lt lu"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/information-retrieval-part-2-simplifying-the-information-53880b930ebd"><div class="lv ab dw"><div class="lw ab lx cl cj ly"><h2 class="bd hj fi z dy lz ea eb ma ed ef hh bi translated">信息检索(第二部分):简化信息</h2><div class="mb l"><h3 class="bd b fi z dy lz ea eb ma ed ef dx translated">在前一篇文章中，我们探索了一种提取信息的技术。现在让我们看看一些关键术语…</h3></div><div class="mc l"><p class="bd b fp z dy lz ea eb ma ed ef dx translated">medium.com</p></div></div><div class="md l"><div class="me l mf mg mh md mi io lu"/></div></div></a></div><p id="cbe2" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">本文的完整代码发布在以下链接中:</p><div class="lr ls ez fb lt lu"><a href="https://github.com/arnabsinha99/MListheroxx/blob/master/Mini_Projects/WebPageExtraction/Extract.py" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab dw"><div class="lw ab lx cl cj ly"><h2 class="bd hj fi z dy lz ea eb ma ed ef hh bi translated">arnabsinha99/MListheroxx</h2><div class="mb l"><h3 class="bd b fi z dy lz ea eb ma ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="mc l"><p class="bd b fp z dy lz ea eb ma ed ef dx translated">github.com</p></div></div><div class="md l"><div class="mj l mf mg mh md mi io lu"/></div></div></a></div></div></div>    
</body>
</html>