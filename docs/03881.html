<html>
<head>
<title>Image classification with VGG convolutional neural network using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Keras的VGG卷积神经网络图像分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-classification-with-vgg-convolutional-neural-network-using-keras-for-beginners-61767950c5dd?source=collection_archive---------2-----------------------#2020-02-24">https://medium.com/analytics-vidhya/image-classification-with-vgg-convolutional-neural-network-using-keras-for-beginners-61767950c5dd?source=collection_archive---------2-----------------------#2020-02-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/57a6ff88ddd6c9d44b620fc5c5c90577.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-g2eF6Y6aZltNYqFPOJOEQ.png"/></div></div></figure><p id="b68a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图像分类和检测是计算机视觉和机器学习领域中最重要的任务之一。在这篇博客中，我训练了一个机器学习模型，使用类似VGG(视觉几何组)的卷积神经网络对不同种类的服装进行分类(<a class="ae jo" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"> Simonyan等人，2014 </a>)。</p><p id="d452" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个博客对那些对CNN有基本了解，并且正在寻找使用Keras实现它们的实用前景的人会很有用。读完这篇博客后，你会熟悉:</p><ul class=""><li id="8208" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">如何组织自定义数据集并为您自己的分类任务配置模型。</li><li id="ef67" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">如何训练图像分类模型，在训练、评估和预测新的看不见的图像上的类别标签时使用不同的回调函数来监控进度。</li></ul><p id="5405" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在VGG架构中，所有卷积层都使用大小为3×3的滤波器，跨距=1，填充与<em class="kd">相同，所有最大池层都使用大小为2×2的滤波器，跨距= 2。对于每组卷积层，过滤器的数量增加一倍，而对于每一个合并层，图像的宽度和高度减少一半。在这里，我使用一个更小的类似VGG的模型来执行分类任务。我没有使用完整的VGG模型，因为它庞大的体积和大量的参数(众所周知VGG有)。尽管有许多其他模型的表现超过了VGG，如ResNet、Inception等，但VGG对初学者来说很容易理解，并给出了一个关于如何实现卷积网的直观概念。如果你想重温一下关于卷积神经网络的记忆，可以参考<a class="ae jo" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank">这篇</a>博客。</em></p><p id="f45f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">博客被分为几乎所有图像分类任务共有的四个主要步骤:</p><ul class=""><li id="b4e5" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated"><strong class="is hj">步骤1: </strong> <strong class="is hj">加载数据</strong>(设置工作目录，初始化图像，调整大小，并执行测试序列分割)</li><li id="d8f9" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated"><strong class="is hj">步骤2:配置模型</strong>(数据扩充、构建模型、设置回调和其他超参数)</li><li id="a52b" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated"><strong class="is hj">第三步:</strong> <strong class="is hj">训练模型</strong>(训练并监控进度)</li><li id="adfe" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated"><strong class="is hj">第四步:</strong> <strong class="is hj">评估和预测</strong>(获得分类报告，预测新的未看见图像的类别标签)</li></ul><p id="d0bd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://www.kaggle.com/trolukovich/apparel-images-dataset/kernels" rel="noopener ugc nofollow" target="_blank">数据集</a>已从Kaggle下载。虽然原始数据集包含大约24种不同类别的服装，但在这篇博客中，我只包括了其中的8种。代码可以在我的Github repo <a class="ae jo" href="https://github.com/ashima0109/VGG-classification" rel="noopener ugc nofollow" target="_blank">这里</a>获得。下载数据集后，您可以在该目录结构下组织数据(您可以通过进入目标目录并在终端中使用<code class="du ke kf kg kh b">tree --filelimit=15</code>来生成该结构)。</p><pre class="ki kj kk kl fd km kh kn ko aw kp bi"><span id="a6c4" class="kq kr hi kh b fi ks kt l ku kv">.<br/>├── Dataset<br/>│   ├── black_dress [450 entries]<br/>│   ├── black_pants [539 entries]<br/>|   .  <br/>|   .<br/>│   └── white_dress [506 entries]<br/>├── Output<br/>├── logs<br/>├── main.py<br/>├── predict.py<br/>├── train.py<br/>└── vgg.py</span></pre><p id="b5db" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">不同类别的数据存储在文件夹<em class="kd">数据集</em>下。每个类别有大约450-550个条目，给我们一个平衡的数据集。训练模型和损失精度图将保存在<em class="kd">输出</em>文件夹中。<em class="kd"> logs </em>文件夹用于存储检查点，用于在模型被训练时监控<em class="kd"> tensorboard </em>上的实时损失和精确度的进度。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">导入vgg.py模块和必要的包</figcaption></figure><h2 id="f0e9" class="kq kr hi bd lc ld le lf lg lh li lj lk jb ll lm ln jf lo lp lq jj lr ls lt lu bi translated"><strong class="ak">第一步:加载数据</strong></h2><p id="0355" class="pw-post-body-paragraph iq ir hi is b it lv iv iw ix lw iz ja jb lx jd je jf ly jh ji jj lz jl jm jn hb bi translated">对于分类，我们需要初始化我们的输入X和输出Y，其中X和Y是图像和它们各自的类标签。在下面的代码块中，我们定义了工作目录，并将所有图片的路径从<code class="du ke kf kg kh b">data_dir</code>加载到列表<code class="du ke kf kg kh b">imagePaths</code>中。在加载之前打乱输入图像的顺序是一个很好的做法，这样可以避免数据序列中的任何偏差。我们遍历所有的图像路径，从路径中提取图像并调整大小(64 x 64像素大小)。图像(输入X)和它们各自的标签(输出Y)现在分别存储在<code class="du ke kf kg kh b">data</code>和<code class="du ke kf kg kh b">labels</code>列表中。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">从图像目录加载数据</figcaption></figure><p id="fbb2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是对数据集的快速浏览:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/7985a9ba4ed57c20cf30e3d452566167.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BvcML4mkCRe9xhiSc002tg.png"/></div></div></figure><p id="40ce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将<code class="du ke kf kg kh b">data</code>和<code class="du ke kf kg kh b">labels</code>列表转换为NumPy数组，并对<code class="du ke kf kg kh b">data</code>进行规范化以加快收敛。为了训练模型，分类标签必须被转换成独热向量编码。对于多个标签，我们使用<strong class="is hj"><em class="kd">label binarizer</em></strong>，但是如果你只有两个类别，你可以使用<strong class="is hj"> <em class="kd"> LabelEncoder </em> </strong>来代替，这将产生整数编码。编码的类名以序列化的方式存储在pickle文件中，以便以后在预测时查找类名。</p><p id="6fa1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们已经有了正确格式的数据(X)和它们的标签(Y)，使用<strong class="is hj"><em class="kd">train _ test _ split</em></strong><em class="kd"/>函数将数据分割成训练集和测试集(顾名思义，用于训练和测试)。它采用诸如<em class="kd">数据(</em> X <em class="kd"> ) </em>和它们的<em class="kd">标签(</em> Y <em class="kd"> ) </em>、确定分割比例的<em class="kd"> test_size </em>和决定洗牌参数的<em class="kd"> random_state </em>等参数。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">保存标签二进制化器并将数据分成训练和测试</figcaption></figure><h2 id="0360" class="kq kr hi bd lc ld le lf lg lh li lj lk jb ll lm ln jf lo lp lq jj lr ls lt lu bi translated">步骤2:配置模型</h2><p id="8c89" class="pw-post-body-paragraph iq ir hi is b it lv iv iw ix lw iz ja jb lx jd je jf ly jh ji jj lz jl jm jn hb bi translated">分割数据集后，我们通过生成线性平移、反射、旋转和剪切不同的原始数据的相似图像来扩充数据，以防止过度拟合并提高泛化能力。也可以人为地将转换后的图像添加到数据集中，但是Keras有<a class="ae jo" href="https://keras.io/preprocessing/image/" rel="noopener ugc nofollow" target="_blank"><strong class="is hj"><em class="kd">imagedata generator</em></strong></a>类，它会根据提供的参数自动执行此操作。可以根据数据集调整<em class="kd"> rotation_range、width_shift_range、height_shift_range、shear_range、zoom_range、horizontal_flip </em>等参数的值<em class="kd"> </em>。如果您选择人工添加转换后的图像，请记住只在训练集而不是测试集上这样做，因为这将导致数据泄漏，从而导致高错误精度。VGG模型架构可以通过从<em class="kd"> vgg.py </em>模块<em class="kd">导入来初始化。</em></p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">数据扩充和模型初始化</figcaption></figure><p id="6475" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Keras中非常有用的功能之一是<a class="ae jo" href="https://keras.io/callbacks/" rel="noopener ugc nofollow" target="_blank"> <em class="kd">回调</em> </a> <em class="kd"> </em>，它们在模型的训练期间用于监控、记录和调试目的。这里我们在训练<strong class="is hj"> <em class="kd">时使用<strong class="is hj"> <em class="kd"> ModelCheckpoint，TerminateOnNaN，ReduceLROnPlateau，</em> </strong>和<strong class="is hj"> <em class="kd"> TensorBoard </em> </strong>。</em>T49】</strong></p><ul class=""><li id="e061" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated"><strong class="is hj"> <em class="kd">模型检查点</em> </strong>每隔几个时期(数量由<em class="kd">周期</em>参数指定)创建一个检查点，文件名包含该特定时期的值。例如:<em class="kd">' VGG _纪元-{纪元:02d } _损失-{损失:. 4f } _瓦尔_损失-{瓦尔_损失:. 4f}.h5' </em>将在检查点文件的名称中包含纪元编号、训练损失和验证损失。</li><li id="169c" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated"><strong class="is hj"> <em class="kd">终止NaN </em> </strong>如果在任意一点损失值变为NaN，则停止训练。</li><li id="cffc" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated"><strong class="is hj"><em class="kd">ReduceLROnPlateau</em></strong>在某个量(此处为验证损失)不随历元数减少的情况下，以某个因子降低学习率。参数<em class="kd"> patience </em>决定了如果没有观察到改进，学习率将会降低的周期数。</li><li id="24a7" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated"><strong class="is hj"> <em class="kd"> TensorBoard </em> </strong>可让您动态可视化并监控训练进度。日志存储在由参数<em class="kd"> log_dir给出的文件夹路径中。要打开tensorboard，请确保tensorboard已安装。在终端<code class="du ke kf kg kh b"><em class="kd">tensorboard --logdir=/path_to_logs</em></code> <em class="kd"> </em>中使用该命令，然后在您的浏览器<em class="kd">中打开<em class="kd"> localhost:6006 </em>，可以可视化该训练。</em>对于这种特定的目录结构，使用<em class="kd"> </em> <code class="du ke kf kg kh b"><em class="kd">tensorboard --logdir='./logs</em></code> <em class="kd">。</em></em></li></ul><p id="94a8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于预测属于每个已知类别标签的样本的概率的分类任务，我们使用交叉熵作为损失函数。这里，<em class="kd">分类_交叉熵</em>被选择<em class="kd"> </em>作为我们的损失函数，因为我们有两个以上的类，并且我们假设每个图像只有一个真正的类，即这是多类问题(而不是在一个图像中可以有一个以上的类标签的多标签问题)。在这种情况下，为一个类别计算的对数损失也会影响其他类别的决策(因为只有一个正确答案)。如果我们手头有一个多标签分类问题，我们会使用'<em class="kd"> binary_crossentropy '。</em>有关分类问题损失函数的更多信息和数学解释，请参考<a class="ae jo" href="https://gombru.github.io/2018/05/23/cross_entropy_loss/" rel="noopener ugc nofollow" target="_blank">这篇</a>博客。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">准备回调并编译模型</figcaption></figure><h2 id="ce04" class="kq kr hi bd lc ld le lf lg lh li lj lk jb ll lm ln jf lo lp lq jj lr ls lt lu bi translated">第三步:培训</h2><p id="6d23" class="pw-post-body-paragraph iq ir hi is b it lv iv iw ix lw iz ja jb lx jd je jf ly jh ji jj lz jl jm jn hb bi translated">在配置模型之后，我们根据一次一批生成的数据对其进行训练。我们使用<code class="du ke kf kg kh b">flow()</code>创建一个迭代器，为每次迭代返回一批增强图像。训练完成后，模型应该保存在本地输出目录中。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">训练模型并在完成时保存它</figcaption></figure><p id="7caa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该模型用Adam optimizer训练超过100个时期，在这种情况下，初始学习率为0.0007，批次大小为64。我最初开始使用学习率0.001，这是使用Adam的默认参数。然而，精确度和损失值显示出很大的波动，所以我降低了学习率，并得出最佳值0.0007。</p><pre class="ki kj kk kl fd km kh kn ko aw kp bi"><span id="9e78" class="kq kr hi kh b fi ks kt l ku kv">Epoch 1/100<br/>53/53 [==============================] - 109s 2s/step - loss: 1.3691 - acc: 0.5699 - val_loss: 1.2561 - val_acc: 0.7312<br/>.<br/>.<br/>.<br/>Epoch 100/100<br/>53/53 [==============================] - 86s 2s/step - loss: 0.0825 - acc: 0.9653 - val_loss: 0.0921 - val_acc: 0.9666</span></pre><p id="4a82" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">损失和准确度的训练图表明，当损失处于平稳状态时，使用<strong class="is hj"> <em class="kd">降低学习率</em> </strong>会产生显著的差异。该模型实现了97%的总体准确率。</p><h2 id="8cef" class="kq kr hi bd lc ld le lf lg lh li lj lk jb ll lm ln jf lo lp lq jj lr ls lt lu bi translated">第四步:评估和预测</h2><p id="c9d1" class="pw-post-body-paragraph iq ir hi is b it lv iv iw ix lw iz ja jb lx jd je jf ly jh ji jj lz jl jm jn hb bi translated">通过对批量大小的训练模型进行预测，可以找到各个类别的分类报告。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">评估并生成分类报告</figcaption></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/352d0ae278c182716e40404c6ac007ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VvrM6q-4Ndhw4lGN4n3aNw.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">分类报告</figcaption></figure><p id="6f38" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用<em class="kd"> matplotlib </em>绘制训练和验证损失和准确度，可视化增加的准确度和减少的损失。70个周期后损失没有减少，所以我也可以在那之后停止训练。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">用历元数绘制训练/测试损失和准确度曲线</figcaption></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/66933722efbedf039477635a35b7a470.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*VY17vCOclUuNLYdGqyl76g.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">随着时期数的训练和验证损失/准确性</figcaption></figure><p id="026d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是一些由经过训练的模型所做预测的图像。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/dca0f1ac819545a45cd225077b29bd52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UYcekphWtr6zCnpGE1ibFQ.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">预测标签及其置信度值</figcaption></figure><p id="804e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该模型预测准确，可信度高。显然，人们可以找到服装是两种或三种不同类别的组合的例子。在这些情况下，置信度值会下降，标签会减少到两个类别中的任何一个。例如:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/34dafb6f7dd2f0ef87b539b9c05fbedc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UcDo-kB7FiSjuEXJBv_q-Q.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">对混乱情况的预测</figcaption></figure><p id="04b0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了处理这种情况，应该训练一个多标签分类模型，它可以在一个图像中包含不同颜色和类型的服装。</p><p id="d700" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总而言之，在这篇博客中，我们了解了:</p><ul class=""><li id="da45" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">如何从零开始建立图像分类模型？</li><li id="8c29" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">配置模型，设置回调函数，并对其进行训练。</li><li id="a63f" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">根据训练好的模型进行评估和预测。</li></ul><p id="88e2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以在我的Github <a class="ae jo" href="https://github.com/ashima0109/VGG-classification" rel="noopener ugc nofollow" target="_blank"> repo </a>找到源代码和安装说明。请随时提出任何意见或建议来改进我的代码或进一步解释。</p></div><div class="ab cl me mf gp mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="hb hc hd he hf"><p id="c06d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我还想感谢Adrian Rosebrock，感谢他在计算机视觉方面的博客带给我的一切。</p><h2 id="c706" class="kq kr hi bd lc ld le lf lg lh li lj lk jb ll lm ln jf lo lp lq jj lr ls lt lu bi translated">参考</h2><ul class=""><li id="769a" class="jp jq hi is b it lv ix lw jb ml jf mm jj mn jn ju jv jw jx bi translated"><a class="ae jo" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1409.1556</a></li><li id="60cd" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated"><a class="ae jo" href="https://gombru.github.io/2018/05/23/cross_entropy_loss/" rel="noopener ugc nofollow" target="_blank">https://gombru.github.io/2018/05/23/cross_entropy_loss/</a></li><li id="0a1c" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated"><a class="ae jo" href="https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/</a></li></ul></div></div>    
</body>
</html>