<html>
<head>
<title>Matrix Factorization — Deep Dive</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">矩阵分解—深入探讨</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/matrix-factorization-deep-dive-9e112a241307?source=collection_archive---------26-----------------------#2019-12-11">https://medium.com/analytics-vidhya/matrix-factorization-deep-dive-9e112a241307?source=collection_archive---------26-----------------------#2019-12-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/21e95cce5fe2fd37445eceb925f857bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KdR0Xu4mFlBS3Q3xj2cYoQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来源— <a class="ae iu" href="https://techcrunch.com/2019/03/18/how-to-build-the-matrix/" rel="noopener ugc nofollow" target="_blank"> TechCrunch </a>、<a class="ae iu" href="https://www.netflix.com/browse" rel="noopener ugc nofollow" target="_blank">网飞</a> &amp; <a class="ae iu" href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwiW0fWc9qzmAhWhzDgGHb4ED8YQjRx6BAgBEAQ&amp;url=https%3A%2F%2Fwww.kdnuggets.com%2F2018%2F06%2Fintuitive-introduction-gradient-descent.html&amp;psig=AOvVaw2ysNe17I9GtdyUev_l0b4l&amp;ust=1576130610769904" rel="noopener ugc nofollow" target="_blank"> Kdnuggets </a></figcaption></figure><p id="efa7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">本文是<a class="ae iu" rel="noopener" href="/analytics-vidhya/matrix-factorization-for-collaborative-filtering-eaedd7e0bbca">矩阵分解协同过滤</a>的延续。</p><p id="3fe2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里，我们以用户项矩阵A为例，试图理解分解和预测是如何发生的。这是用python实现的。</p><p id="178c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">矩阵A包含以行表示的所有用户和以列表示的所有电影，如图1所示。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jt"><img src="../Images/128e94e45b76bc4e9d6770195e732c03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/1*Tav9gPdfjKyr0msJv0kO7A.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图1</figcaption></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jy"><img src="../Images/9d2a1d68da6d941d5d3250f8f157a845.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/1*VqDBJDxXJ_8jqIYFUAfVpQ.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图2</figcaption></figure><p id="e70c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对矩阵A进行矩阵分解(MF ),我们得到下面的等式。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jz"><img src="../Images/afd0d2c9ae8f09d1d6ba54f25081d451.png" data-original-src="https://miro.medium.com/v2/resize:fit:188/1*FnIxBISy7hfa1edifKw21Q.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图3</figcaption></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/375719503d1a255eaf85c5632f10786d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/1*sy9dHV607oqTHD8YL0U4-Q.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图4</figcaption></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kb"><img src="../Images/cb4fd602c8372dcbb81c126d726c7302.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/1*gBE7y6rFmMXKTQJfdW2XiQ.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图5</figcaption></figure><p id="3205" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里，B和C分别是维数为(n×d)和(m×d)的矩阵。这里，n是用户数，m是电影数，d是代表矩阵B和c中用户和电影向量维数的超参数。</p><p id="db11" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">MF的目标函数是找到B和C的值，从而满足图3中的等式。如图6所示。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kc"><img src="../Images/3033d63e890c7b1818e719aed3bf4b8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/1*nvXHPaXs2SjKKPPcakXeog.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图6</figcaption></figure><p id="3cd7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于图6中的目标函数是一个凸优化问题，我们可以使用梯度下降(GD)来获得b和c的最佳值。更新Bᵢ和Cⱼ值的方程如图7所示。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kd"><img src="../Images/9c0e5ab617d7b8665781d044023ba6ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*wnYdc6p8Mz3nFXLE9W_aXA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图7</figcaption></figure><p id="e233" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们举一个例子来更好地理解它。假设用户数量为3，电影数量为4，矩阵A如图8所示。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es ke"><img src="../Images/c5b4a361642dfb41c8b0054f16c60a04.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/1*QxCuTkMV4zrJYIB2Vp9MIw.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图8</figcaption></figure><p id="816e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了重申我们的目标，基于A的非零值，我们必须使用MF来预测A的零值(这些值是否可以保持为0或者应该为1)。</p><p id="a778" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们通过从正态分布中随机抽取样本来初始化矩阵B和C，如下所示。</p><pre class="ju jv jw jx fd kf kg kh ki aw kj bi"><span id="37af" class="kk kl hi kg b fi km kn l ko kp">B = np.random.normal(scale=1.0, size=(n,d)) <br/>C = np.random.normal(scale=1.0, size=(m,d))</span></pre><p id="28a6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下代码用于执行图7中等式(5)和(6)中提供的更新规则。</p><pre class="ju jv jw jx fd kf kg kh ki aw kj bi"><span id="badb" class="kk kl hi kg b fi km kn l ko kp"><strong class="kg hj">for</strong> i <strong class="kg hj">in</strong> range(n):<br/>    <strong class="kg hj">for</strong> j <strong class="kg hj">in</strong> range(m):<br/>      <strong class="kg hj">if</strong>(A[i][j] &gt; 0): <em class="kq"># Consider only non-zero elements of A</em><br/>        B_new[i] = B[i]<br/>        B[i] += r * (2 * C[j]) * (A[i][j] - np.dot(B[i], C[j]))<br/>        C[j] += r * (2 * B_new[i]) * (A[i][j] - np.dot(B_new[i], C[j]))</span></pre><p id="83e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在更新了向量Bᵢ和Cⱼ的所有值之后，我们找到了Aᵢⱼ的预测值以及Aᵢⱼ的实际值和Aᵢⱼ.的预测值之间的平方误差值以下代码对此进行了描述。</p><pre class="ju jv jw jx fd kf kg kh ki aw kj bi"><span id="b44f" class="kk kl hi kg b fi km kn l ko kp">rmse += np.power(A[i][j] - np.dot(B[i], C[j]), 2)</span></pre><p id="88dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦计算出所有非零Aᵢⱼ值的平方误差，就计算出所有这些值的均方根误差(RMSE ),并将其附加到一个数组中，该数组记录每次迭代的RMSE值。以下代码对此进行了描述。</p><pre class="ju jv jw jx fd kf kg kh ki aw kj bi"><span id="66d5" class="kk kl hi kg b fi km kn l ko kp">rmse_arr.append(np.round(np.sqrt(np.mean(rmse))))</span></pre><p id="cceb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">运行上述过程，直到获得期望的RMSE。A (Aₚ)的最终预测值如图9所示。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/fd26b51ef21d1404a841907f8c098675.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*DhFDrDrMjlriEUzJkqqlnw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图9</figcaption></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/9d5ef1a6edd28b3d2f715870406ff61f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*YBDRT19TMHKtvf03gAHtLQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图10</figcaption></figure><p id="31e7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们将A [A₁₁、A₁₂、A₁₃、A₂₁、A₂₂、A₂₄、A₃₁]的非零值与Aₚ的非零值进行比较，如图10所示，它们之间的差异非常小。这意味着我们的模型(矩阵B和C的值)正确地预测了非零值(用户已经观看的电影)。同样的模型也给了我们一些a值为零的地方的值[A₁₄，A₂₃，A₃₂，A₃₃，a₃₄].]这些是我们的预测值。</p><p id="f6e9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，预测值是分数形式的，而我们需要它们是1或0。为了将这些十进制数转换成二进制形式，我们可以使用一个阈值，低于该阈值的值将被视为0，高于该阈值的值将被视为1。阈值可以由领域专家或通过建立交叉验证系统来确定。</p><p id="139d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们将预测值的阈值保持为0.5，我们将得到如图11所示的结果。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kt"><img src="../Images/176c469a1aea842d1e9519392293e2c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*pj3UUhm1WjpqOIl-AmU5UA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图11</figcaption></figure><p id="fd63" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">得到的预测值不是绝对的，它必然是错误的。因此，为了提高预测的准确性，必须使用更新的非零值A定期训练模型。此外，我们的模型过拟合矩阵A，并且不会泛化，因为我们没有在图6中指定的目标函数中添加任何正则化参数。</p><p id="b286" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用正则化的相同实现可以在这里找到<a class="ae iu" href="https://github.com/suhaskv/Matrix-Factorization-Python" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="cc2f" class="ku kl hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">参考</h1><ol class=""><li id="8172" class="lr ls hi ix b iy lt jc lu jg lv jk lw jo lx js ly lz ma mb bi translated"><a class="ae iu" href="http://www.albertauyeung.com/post/python-matrix-factorization/" rel="noopener ugc nofollow" target="_blank">http://www . albertau yeung . com/post/python-matrix-factorization/</a></li></ol></div></div>    
</body>
</html>