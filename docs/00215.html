<html>
<head>
<title>A Technical Overview of AI &amp; ML (NLP, Computer Vision, Reinforcement Learning) in 2018 &amp; Trends for 2019</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2018年人工智能和人工智能(NLP，计算机视觉，强化学习)的技术概述和2019年的趋势</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-technical-overview-of-ai-ml-nlp-computer-vision-reinforcement-learning-in-2018-trends-6a24647456af?source=collection_archive---------0-----------------------#2018-12-19">https://medium.com/analytics-vidhya/a-technical-overview-of-ai-ml-nlp-computer-vision-reinforcement-learning-in-2018-trends-6a24647456af?source=collection_archive---------0-----------------------#2018-12-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/4bacddc0c4f123c67c818adedeee5ed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_spceXDqSGpcnAMh.png"/></div></div></figure><h1 id="8347" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">介绍</h1><p id="a852" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">过去的几年对于人工智能爱好者和机器学习专业人士来说是梦幻之旅。这些技术已经从小众发展成为主流，并影响着今天数百万人的生活。各国现在都有专门的人工智能部长和预算，以确保他们在这场竞赛中保持相关性。</p><p id="5d71" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">对于数据科学专业人员来说也是如此。几年前——如果知道一些工具和技术，你会感觉很舒服。不再是了！这个领域发生了太多的事情，有太多的事情需要跟上——有时感觉令人难以置信。</p><p id="a6d9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这就是为什么我想到后退一步，从数据科学从业者的角度来看待人工智能的一些关键领域的发展。这些突破是什么？2018年发生了什么，2019年有哪些可以期待的？阅读这篇文章，找出答案！</p><p id="b2a2" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><em class="kr">附:和任何预测一样，这些是我的看法。这些都是基于我试图把这些点联系起来。如果你有不同的观点，我很想听听。一定要让我知道你认为2019年可能会发生什么变化。</em></p><h1 id="9cbe" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">我们将在本文中涉及的领域</h1><ul class=""><li id="5f83" class="ks kt hi jq b jr js jv jw jz ku kd kv kh kw kl kx ky kz la bi translated">自然语言处理</li><li id="ca59" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">计算机视觉</li><li id="74e4" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">工具和库</li><li id="7d74" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">强化学习</li><li id="c0f4" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">人工智能为好——走向伦理人工智能</li></ul><h1 id="d627" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">自然语言处理</h1><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/096fff5e3639b7410310a00d16306b42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/0*FaLbRy0F0r7jhHWQ.jpg"/></div></figure><p id="4028" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">让机器解析单词和句子似乎一直是一个梦想。一门语言有太多的细微差别和方面，有时甚至人类都难以理解。<strong class="jq hj">但是2018年对于NLP </strong>来说确实是一个分水岭。</p><p id="8fe9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们看到了一个又一个引人注目的突破——乌尔姆菲特、ELMO、OpenAI的Transformer和谷歌的BERT，仅举几例。迁移学习(能够将预先训练的模型应用于数据的艺术)在NLP任务中的成功应用为潜在的无限应用打开了大门。我们与Sebastian Ruder的播客进一步巩固了我们对他的领域在最近已经走过了多远的信念。<em class="kr">顺便提一下，这是所有NLP爱好者必听的播客。</em></p><p id="a82a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">让我们更详细地看一下这些关键发展。如果你想学习自然语言处理的诀窍，并且正在寻找一个入门的地方，请务必参加这个“<a class="ae ll" href="https://trainings.analyticsvidhya.com/courses/course-v1:AnalyticsVidhya+NLP101+2018_T1/about" rel="noopener ugc nofollow" target="_blank">使用Python的自然语言处理</a>”课程。这是一个开始你文字驱动之旅的好地方！</p><h1 id="1cbd" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">乌尔菲特</h1><p id="9833" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">由Sebastian Ruder和fast.ai的杰瑞米·霍华德设计的ULMFiT是第一个让NLP迁移学习党今年开始的框架。对于外行来说，它代表通用语言模型微调。Jeremy和Sebastian真正把这个词放在了ULMFiT中——这个框架可以应用于几乎所有的NLP任务！</p><p id="d582" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">关于ULMFiT和我们很快将看到的后续框架，最好的部分是什么？不需要从零开始训练模特！这些研究人员已经为你完成了困难的部分——把他们的知识应用到你自己的项目中。在六个文本分类任务中，ULMFiT优于最先进的方法。</p><p id="c60e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">你可以阅读Prateek Joshi的这篇优秀教程,学习如何使用ULMFiT解决任何文本分类问题。</p><h1 id="01c3" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">工程与后勤管理局</h1><p id="8602" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">想猜猜ELMo代表什么吗？它是语言模型嵌入的简称。很有创意，是吧？除了它的名字很像著名的芝麻街角色之外，ELMo一发行就吸引了ML社区的注意。</p><p id="0f8a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">ELMo使用语言模型来获得每个单词的嵌入，同时还考虑单词在句子或段落中的上下文。上下文是自然语言处理的一个非常重要的方面，以前大多数人都没有理解。ELMo使用双向LSTMs来创建嵌入。如果这听起来有点拗口，不要担心——查看<a class="ae ll" href="https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>,获得LSTMs是什么以及它们如何工作的简单概述。</p><p id="640a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">像ULMFiT一样，ELMo显著提高了各种NLP任务的性能，如情感分析和问题回答。点击阅读更多关于<a class="ae ll" href="https://allennlp.org/elmo" rel="noopener ugc nofollow" target="_blank">的信息。</a></p><h1 id="7abe" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">谷歌的伯特</h1><p id="302d" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">相当多的专家声称BERT的发布标志着NLP的一个新时代。继ULMFiT和ELMo之后，BERT凭借其出色的性能彻底击败了竞争对手。正如<a class="ae ll" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank">原始论文</a>所说，“BERT概念简单，经验强大”。</p><p id="bb07" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">伯特在11日获得了最先进的结果(是的，11日！)NLP任务。查看他们在班基准上的结果:</p><p id="f253" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">SQuAD v1.1排行榜(2018年10月8日)测试EMTest F11st第一名合奏— BERT <strong class="jq hj"> 87.493.2 </strong>第二名合奏—nlnet 86 . 091 . 71第一名单人模式— BERT <strong class="jq hj"> 85.191.8 </strong>第二名单人模式— nlnet83.590.1</p><p id="4e40" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">有兴趣开始吗？你可以使用<a class="ae ll" href="https://github.com/huggingface/pytorch-pretrained-BERT" rel="noopener ugc nofollow" target="_blank"> PyTorch实现</a>或者谷歌自己的<a class="ae ll" href="https://github.com/google-research/bert" rel="noopener ugc nofollow" target="_blank"> TensorFlow代码</a>来尝试在你自己的机器上复制结果。</p><p id="98b7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我相当肯定你想知道伯特在这一点上代表什么。</p><p id="bd32" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这是变压器的双向编码器表示。如果你第一次就答对了，那就是满分。</p><h1 id="1335" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">脸书的PyText</h1><p id="e0a6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">脸书怎么能置身事外呢？他们开源了自己的深度学习NLP框架，名为PyText。它是在本周早些时候发布的，所以我仍在对它进行实验，但早期的评论非常有希望。根据FB发布的研究，PyText使对话模型的准确性提高了10%,并减少了训练时间。</p><p id="5cb3" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">PyText实际上是脸书自己的一些产品的幕后推手，比如FB Messenger。因此，从事这项工作会给你自己的投资组合增加一些真实世界的价值(除了你将明显获得的无价知识之外)。</p><p id="0903" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">你可以从<a class="ae ll" href="https://github.com/facebookresearch/pytext" rel="noopener ugc nofollow" target="_blank">这个GitHub repo </a>下载代码自己试试。</p><h1 id="bccd" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">谷歌双工</h1><p id="5d6f" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">如果你还没听说过Google Duplex，那你去过哪里？！桑德尔·皮帅凭借这个演示一举成名，从那以后它就一直是头条新闻:</p><p id="0e70" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">由于这是谷歌的产品，他们开源其背后代码的可能性很小。但是哇！这是一个非常棒的音频处理应用程序。当然，这引发了许多伦理和隐私问题，但这将在本文后面讨论。现在，只需陶醉于近年来我们在ML方面取得的进步。</p><h1 id="7364" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2019年NLP趋势展望</h1><p id="6a4d" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">谁比Sebastian Ruder本人更适合提供NLP在2019年走向何处的线索？以下是他的想法:</p><ul class=""><li id="2b52" class="ks kt hi jq b jr km jv kn jz lm kd ln kh lo kl kx ky kz la bi translated">预训练语言模型嵌入将变得无处不在。很少会有不使用它们的最先进的模型</li><li id="24fd" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">我们将看到<strong class="jq hj">预训练的表示，它可以编码专门的信息</strong>，这是对语言模型嵌入的补充。我们将能够根据任务的要求组合不同类型的预训练表示</li><li id="05f5" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">我们将看到更多关于多语言应用和跨语言模型的工作。特别是，在跨语言单词嵌入的基础上，我们将看到深度预训练的跨语言表征的出现</li></ul><h1 id="d5b8" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">计算机视觉</h1><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/4ae6605144ddfa422ed581ef6f022305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SNj1SfcnAhB-KoK5.jpg"/></div></div></figure><p id="9fde" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这无疑是目前深度学习领域最受欢迎的领域。我觉得我们已经在很大程度上摘下了计算机视觉的低挂果实，并且已经处于提炼阶段。无论是图像还是视频，我们已经看到了大量的框架和库，它们使计算机视觉任务变得轻而易举。</p><p id="291a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们Analytics Vidhya今年花了很多时间致力于这些概念的民主化。点击这里查看我们的<a class="ae ll" href="https://www.analyticsvidhya.com/blog/category/deep-learning/" rel="noopener ugc nofollow" target="_blank">计算机视觉特定文章，涵盖从视频和图像中的对象检测到预训练模型列表的主题，以开始您的深度学习之旅。</a></p><p id="bda0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">以下是我挑选的今年我们在CV上看到的最好的发展。</p><p id="6a67" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果你对这个奇妙的领域(实际上很快就会成为行业内最热门的工作之一)感到好奇，那么继续前进，通过我们的“<a class="ae ll" href="https://trainings.analyticsvidhya.com/courses/course-v1:AnalyticsVidhya+CVDL101+CVDL101_T1/about" rel="noopener ugc nofollow" target="_blank">计算机视觉使用深度学习</a> g”课程开始你的旅程。</p><h1 id="a1a6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">释放比根斯</h1><p id="d1fa" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">Ian Goodfellow在2014年设计了GANs，此后这个概念衍生出了多种多样的应用。年复一年，我们看到最初的概念被调整以适应实际的用例。但有一件事一直保持到今年，那就是机器生成的图像很容易被发现。框架中总会有一些不一致的地方，这使得区别相当明显。</p><p id="7fe7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">但最近几个月，这一界限已经开始消失。随着<a class="ae ll" href="https://arxiv.org/pdf/1809.11096.pdf" rel="noopener ugc nofollow" target="_blank">比根斯</a>的诞生，这一界限将被永久消除。看看下面用这种方法生成的图像:</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/3e3a4a55e5c1bffbf29da256c8394a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*J5zykKlS2o4Y5N4Z.png"/></div></div></figure><p id="e051" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">除非你拿着显微镜去观察，否则你无法判断这些收藏品是否有问题。关于或令人兴奋的？我把这个问题留给你，但毫无疑问，GANs正在改变我们感知数字图像(和视频)的方式。</p><p id="e016" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">对于数据科学家来说，这些模型首先在ImageNet数据集上进行训练，然后在JFT-300M数据上进行训练，以展示这些模型可以很好地从一个集合转移到另一个集合。我还会把你引向<a class="ae ll" href="https://gandissect.csail.mit.edu/" rel="noopener ugc nofollow" target="_blank"> GAN解剖页面</a>——一种非常酷的可视化和理解GAN的方式。</p><h1 id="2aa3" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">Fast.ai的模型在18分钟内在ImageNet上接受训练</h1><p id="a541" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这是一个非常酷的发展。有一种非常普遍的观点认为，你需要大量的数据以及大量的计算资源来执行适当的深度学习任务。这包括在ImageNet数据集上从头开始训练模型。我理解这种看法——在fast.ai的几个人找到一种方法证明我们所有人都错了之前，我们大多数人都是这么想的。</p><p id="3cf9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">他们的模型在令人印象深刻的18分钟内给出了93%的准确率。他们使用的硬件，在他们的博客文章中有详细描述，包含16个公共AWS云实例，每个实例有8个NVIDIA V100 GPUs。他们使用fastai和PyTorch库构建算法。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/b4cbd7536eb4c43e0b9bde877f1d0c1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qRjBMkf09RMNtJ6w.jpg"/></div></div></figure><p id="8c45" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">把整个事情放在一起的总成本出来只是<strong class="jq hj"> $40 </strong>！<strong class="jq hj">杰瑞米已经详细描述了他们的方法，包括技巧</strong> <a class="ae ll" href="http://www.fast.ai/2018/08/10/fastai-diu-imagenet/" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj">这里</strong> </a> <strong class="jq hj">。</strong>大家都赢了！</p><h1 id="9dab" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">NVIDIA的vid2vid技术</h1><p id="b70a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">图像处理在过去的4-5年里突飞猛进，但是视频呢？事实证明，将方法从静态框架转换到动态框架比大多数人想象的要困难一些。能不能拍一段视频序列，预测下一帧会发生什么？之前有人对此进行过探索，但发表的研究最多也只是含糊其辞。</p><p id="afac" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">今年早些时候，NVIDIA决定开源他们的方法，并获得了广泛的赞誉。他们的vid2vid方法的目标是从给定的输入视频中学习映射函数，以便产生以难以置信的精度描述输入视频内容的输出视频。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/a803111a3133677c611f761d08372b77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4uXcoRIeoJ6O90rD.png"/></div></div></figure><p id="4956" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">你可以在GitHub上试用他们的PyTorch实现。</p><h1 id="719a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2019年预计的计算机视觉趋势</h1><p id="5838" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">就像我之前提到的，我们可能会在2019年看到修改而不是发明。这可能感觉更像是一样的——自动驾驶汽车、面部识别算法、虚拟现实等。在这里，你可以不同意我的观点，也可以添加你的观点——我很想知道明年我们还能期待些什么我们还没有看到的东西。</p><p id="95e2" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">等待政治和政府批准的无人机最终可能会在美国获得绿灯(印度远远落后于美国)。就个人而言，我希望看到大量的研究在现实世界中实施。像CVPR和ICML这样的会议描绘了这个领域的最新发展，但是这些项目离实际应用有多近呢？</p><p id="05ea" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">视觉问答和视觉对话系统终于可以在不久的将来首次亮相了。这些系统缺乏概括的能力，但是我们期望很快会看到一个集成的多模态方法。</p><p id="e16e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">今年，自我监督学习走到了前台。我敢打赌，明年会有更多的研究采用这种方法。这是一条非常酷的学习路线——标签直接从我们输入的数据中确定，而不是浪费时间手动标记图像。手指交叉！</p><h1 id="847c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">工具和库</h1><p id="5da6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这一部分将吸引所有数据科学专业人士。工具和库是数据科学家的面包和黄油。我参与了许多关于哪个工具是最好的，哪个框架取代了另一个框架，哪个库是经济计算的缩影等等的辩论。我相信你们中的很多人也会有同感。</p><p id="61b4" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">但有一点我们都同意——我们需要掌握该领域的最新工具，否则就有被抛在后面的风险。Python超越其他一切并成为行业领导者的速度足以说明这一点。当然，这在很大程度上归结于主观选择(您的组织使用什么工具，从当前框架转换到新框架的可行性如何，等等。)，但是如果你甚至没有考虑到最先进的技术，那么我恳求你现在就开始。</p><p id="0ad0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">那么今年的头条是什么呢？让我们来了解一下！</p><h1 id="aa0b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">PyTorch 1.0</h1><p id="6688" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">PyTorch的炒作是怎么回事？我在本文中已经多次提到过它(稍后您会看到更多的实例)。我会让我的同事Faizan Shaikh来让你们熟悉这个框架。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/7d624bfc5091be093e38310e7c4407ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OKleQ6jLXWamsbUm.png"/></div></div></figure><p id="ca96" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这是我最喜欢的AV深度学习文章之一——必读！鉴于TensorFlow有时可能会非常慢，它为PyTorch在双快的时间内占领深度学习市场打开了大门。我在GitHub上看到的大部分开源代码都是PyTorch概念的实现。这不是巧合——py torch超级灵活，最新版本(1.0版)已经大规模支持许多脸书产品和服务，包括每天执行60亿次文本翻译。</p><p id="7636" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">PyTorch的采用率只会在2019年上升，所以现在是加入的好时机。</p><h1 id="8ed5" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">AutoML —自动化机器学习</h1><p id="9f0f" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在过去的几年里，自动机器学习(AutoML)已经逐渐取得进展。RapidMiner、KNIME、DataRobot和H2O.ai等公司发布了优秀的产品，展示了这项服务的巨大潜力。</p><p id="bddf" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">你能想象在一个ML项目中，你只需要使用拖放界面而不需要编码吗？这是一个在未来不太遥远的场景。但是除了这些公司之外，在ML/DL领域还有一个重要的发布——<strong class="jq hj">Auto Keras</strong>！</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/f3cf6cccbebff0e9e14a91c9f2342ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6yO9Fp0EF-yemhf4.png"/></div></div></figure><p id="68af" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这是一个用于执行AutoML任务的开源库。其背后的想法是让深度学习对于那些可能没有ML背景的领域专家来说变得容易。<strong class="jq hj">请务必在这里查看</strong><a class="ae ll" href="https://autokeras.com/" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"/></a><strong class="jq hj">。在未来几年，它将会有一个巨大的飞跃。</strong></p><h1 id="f926" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">TensorFlow.js —浏览器中的深度学习</h1><p id="7ef3" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">自从我们进入这一行以来，我们一直在我们最喜欢的ide和笔记本上构建和设计机器学习和深度学习模型。走出去尝试一些不同的东西怎么样？没错，我说的就是在你的网页浏览器本身进行深度学习！</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/478084ea8e8107edd1fe11521863c259.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*I1w9egDlV_vvEUvA.png"/></div></div></figure><p id="a82f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">多亏了<a class="ae ll" href="https://js.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj"> TensorFlow.js </strong> </a>的发布，现在这已经成为现实。这个链接也有一些演示，展示了这个开源概念有多酷。TensorFlow.js主要有三个优点/功能:</p><ul class=""><li id="f8b6" class="ks kt hi jq b jr km jv kn jz lm kd ln kh lo kl kx ky kz la bi translated">用JavaScript开发和部署机器学习模型</li><li id="2281" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">在浏览器中运行预先存在的TensorFlow模型</li><li id="e03f" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">重新培训现有模型</li></ul><h1 id="fcb7" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">预计2019年的汽车趋势</h1><p id="a41f" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我想在这个帖子中特别关注AutoML。为什么？因为我觉得它将在未来几年内改变数据科学领域的游戏规则。但是不要只相信我的话！以下是H2O.ai的<a class="ae ll" href="https://soundcloud.com/datahack-radio/episode-3-marios-michailidis" rel="noopener ugc nofollow" target="_blank"> Marios Michailidis </a>，Kaggle大师，他对2019年AutoML的期望:</p><blockquote class="lv lw lx"><p id="53ea" class="jo jp kr jq b jr km jt ju jv kn jx jy ly ko kb kc lz kp kf kg ma kq kj kk kl hb bi translated">机器学习继续进军，成为未来最重要的趋势之一——世界将走向何方。这种扩张增加了该领域对技术应用的需求。鉴于其增长，自动化是尽可能利用数据科学资源的关键。应用是无限的:信贷、保险、欺诈、计算机视觉、声学、传感器、推荐器、预测、NLP——你能想到的。在这个领域工作是一种特权。将继续发挥重要作用的趋势可以定义为:</p></blockquote><ul class=""><li id="013a" class="ks kt hi jq b jr km jv kn jz lm kd ln kh lo kl kx ky kz la bi translated">提供智能可视化和洞察力来帮助描述和理解数据</li><li id="c4e0" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">为给定数据集查找/构建/提取更好的要素</li><li id="1ed0" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">快速构建更强大/更智能的预测模型</li><li id="129c" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">通过机器学习可解释性(mli)弥合黑盒建模和这些模型的生产之间的差距</li><li id="fb6c" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">促进这些模型的生产</li></ul><h1 id="8871" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">强化学习</h1><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/8e0c9dfef88a0ca948c6095704954687.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6GlIxR4ZnagSXA32.png"/></div></div></figure><p id="80b1" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果我必须选择一个我希望看到更多渗透的领域，那就是强化学习。除了我们偶尔看到的头条新闻，还没有一个改变游戏规则的突破。我在社区中看到的普遍看法是，它太重数学了，而且没有真正的行业应用程序可做。</p><p id="de26" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">虽然在某种程度上这是真的，但我希望明年RL能有更多实际的用例。在我每月的GitHub和Reddit系列文章中，我倾向于保留至少一个关于RL的知识库或讨论，以至少促进围绕该主题的讨论。这很可能是所有研究中的下一件大事。</p><p id="73d8" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">OpenAI已经发布了一个非常有用的工具包来帮助初学者开始这个领域，我在下面提到过。你也可以看看<a class="ae ll" href="https://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/" rel="noopener ugc nofollow" target="_blank">这个对初学者友好的关于这个话题的介绍</a>(它对我有超级大的帮助)。</p><p id="5dd9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果我错过了什么，我很想听听你的想法。</p><h1 id="c121" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">OpenAI在深度强化学习中快速发展</h1><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/af9f5c42332cf67e00ab45e56174bf4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dACRsOMnTbt7VCa9.png"/></div></div></figure><p id="9c4d" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果说在RL方面的研究进展缓慢，那么围绕它的教育材料也很少(最多)。但是说到做到，OpenAI已经公开了一些关于这个主题的很棒的材料。他们称这个项目为“在深度RL中旋转”,你可以在这里<a class="ae ll" href="https://spinningup.openai.com/en/latest/" rel="noopener ugc nofollow" target="_blank">阅读全部内容。</a></p><p id="6b41" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这实际上是一个相当全面的关于RL的资源列表，他们试图保持代码和解释尽可能简单。有相当多的材料，包括RL术语，如何成长为一个RL研究角色，重要论文的列表，非常完善的代码库，甚至还有一些练习来帮助您开始。</p><p id="4704" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">现在不要再拖延了——如果你正计划开始学习RL，你的时机已经到了！</p><h1 id="a8b0" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">谷歌多巴胺</h1><p id="baf9" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">为了加速研究并让社区更多地参与强化学习，谷歌人工智能团队开源了多巴胺，这是一个TensorFlow框架，旨在通过使研究更加灵活和可重复来创建研究。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es md"><img src="../Images/7088d1b26ce561ec6504b43465051b90.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/0*egY9CrJSuKafSa7q.png"/></div></figure><p id="eaa4" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">您可以找到整个训练数据以及TensorFlow代码(只有15个Python笔记本！)上<a class="ae ll" href="https://github.com/google/dopamine" rel="noopener ugc nofollow" target="_blank">这个GitHub资源库</a>。这是在可控和灵活的环境中进行简单实验的完美平台。听起来像是任何数据科学家的梦想。</p><h1 id="ce3e" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2019年的强化学习趋势</h1><p id="73c7" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">DataHack Summit 2018的发言人兼ArxivInsights频道的创始人史云光·斯廷布鲁格(Andrew Steenbrugge)是强化学习方面的专家。以下是他对RL现状的看法以及对2019年的期待:</p><ul class=""><li id="6fcf" class="ks kt hi jq b jr km jv kn jz lm kd ln kh lo kl kx ky kz la bi translated">我目前在RL领域看到三个主要问题:</li><li id="e525" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated"><strong class="jq hj">样本复杂度</strong>(代理为了学习需要看到/收集的经验量)</li><li id="3b74" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated"><strong class="jq hj">概括</strong>和迁移学习(任务A的培训，相关任务B的测试)</li><li id="daa3" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated"><strong class="jq hj">分层RL </strong>(自动子目标分解)</li><li id="a3c3" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">我相信前两个问题可以用一套类似的技术来解决，这些技术都与<strong class="jq hj">无监督表示学习</strong>有关。目前在RL中，我们正在训练深度神经网络，该网络使用稀疏的奖励信号(例如Atari游戏的分数或机器人抓取的成功)以端到端的方式(例如反向传播)从原始输入空间(例如像素)映射到动作。这里的问题是:</li><li id="30df" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">因为信噪比非常低，所以实际“生长”有用的特征检测器需要非常长的时间。RL基本上从随机行为开始，直到它足够幸运地偶然发现一个奖励，然后需要弄清楚这个特定的奖励实际上是如何产生的。进一步的探索要么是硬编码的(ε-贪婪探索)，要么是鼓励使用像<a class="ae ll" href="https://pathak22.github.io/large-scale-curiosity/" rel="noopener ugc nofollow" target="_blank">好奇心驱动的探索</a>这样的技术。这是没有效率的，并且这导致了问题1。</li><li id="eb20" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">其次，众所周知，这些深度神经网络架构非常容易过度拟合，在RL中，我们通常倾向于在训练数据上测试代理——在这种范式中，过度拟合实际上是被鼓励的。</li><li id="daff" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">我非常感兴趣的一条可能的前进道路是利用无监督表示学习(<a class="ae ll" href="https://youtu.be/9zKuYvjFFS8" rel="noopener ugc nofollow" target="_blank">自动编码器，VAE的</a>，甘斯……)将杂乱的高维输入空间(如像素)转换为低维的“概念”空间，该空间具有某些理想的属性，如:</li><li id="3698" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">线性度、解纠缠度、对噪声的鲁棒性……</li><li id="fa43" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">一旦你能把像素映射到这样一个有用的潜在空间，学习突然变得容易/快速(问题1。)而且你也希望在这个领域学到的策略会有更强的<a class="ae ll" href="https://www.vicarious.com/2017/08/07/general-game-playing-with-schema-networks/" rel="noopener ugc nofollow" target="_blank">泛化</a>，因为上面提到的属性(问题2。)</li><li id="b232" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">我不是层次问题的专家，但上面提到的一切也适用于这里:在潜在空间中解决复杂的层次任务比在原始输入空间中更容易。</li></ul><p id="c4dc" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">奖励:查看</strong> <a class="ae ll" href="https://www.youtube.com/watch?v=0Ey02HT_1Ho" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj">史云光关于在深度RL中克服稀疏奖励的视频</strong> </a> <strong class="jq hj">(上面重点提到的第一个挑战)。</strong></p><ul class=""><li id="8f52" class="ks kt hi jq b jr km jv kn jz lm kd ln kh lo kl kx ky kz la bi translated">由于增加了越来越多的辅助学习任务，增加了稀疏的外部奖励信号，样本的复杂性将继续提高(如好奇心驱动的探索、自动编码器风格的预训练、解开环境中的因果因素等)。这在奖励非常少的环境下尤其有效(比如最近关于蒙特祖马复仇的<a class="ae ll" href="https://eng.uber.com/go-explore/" rel="noopener ugc nofollow" target="_blank"> Go-explore结果</a></li><li id="a98a" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">正因为如此，直接在物理世界中训练系统将变得越来越可行(而不是目前的应用大多是在模拟环境中训练，然后使用<a class="ae ll" href="https://blog.openai.com/generalizing-from-simulation/" rel="noopener ugc nofollow" target="_blank">域随机化</a>转移到真实世界。)我预测，2019年将会带来第一批真正令人印象深刻的机器人演示，这些演示只有使用深度学习方法才有可能实现，并且无法硬编码/人工设计(不像我们迄今为止看到的大多数演示)</li><li id="f5b7" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">随着Deep RL在AlphaGo故事中的巨大成功(特别是最近的<a class="ae ll" href="https://deepmind.com/blog/alphafold/" rel="noopener ugc nofollow" target="_blank"> AlphaFold </a>结果)，我相信RL将逐渐开始交付实际的商业应用，在学术空间之外创造现实世界的价值。这将最初限于应用，其中精确的模拟器可用于对这些代理进行大规模的虚拟培训(例如药物发现、电子芯片架构优化、车辆&amp;包裹路由等)</li><li id="76f7" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated">正如已经开始发生的那样(见<a class="ae ll" href="https://contest.openai.com/2018-1/" rel="noopener ugc nofollow" target="_blank">此处</a>或<a class="ae ll" href="https://blog.openai.com/quantifying-generalization-in-reinforcement-learning/" rel="noopener ugc nofollow" target="_blank">此处</a>)，RL开发将会有一个总体转变，在这种转变中，根据培训数据测试代理将不再被认为是“允许的”。泛化度量将成为核心，就像监督学习方法一样</li></ul><h1 id="ff3b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">人工智能为好——走向伦理人工智能</h1><p id="207a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">想象一个由算法统治的世界，这些算法决定了人类采取的每一个行动。不太乐观，是吧？人工智能中的伦理是我们Analytics Vidhya一直热衷于谈论的话题。当它应该与这些主题一起考虑时，它在所有技术讨论中陷入困境。</p><p id="414e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">今年，脸书的剑桥分析公司丑闻和谷歌内部关于设计武器的谣言登上了丑闻排行榜的首位，这让不少组织颜面扫地。但所有这些都导致大型科技公司写下了它们打算遵循的章程和准则。</p><p id="0240" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">没有一个现成的解决方案或一个适合所有人的解决方案来处理人工智能的伦理方面。它需要一种细致入微的方法，结合领导层提出的结构化路径。让我们来看看今年早些时候震撼全球的几项重大举措。</p><h1 id="f5d5" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">谷歌和微软的活动</h1><p id="4dee" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">看到大公司强调人工智能的这一方面令人振奋(尽管通往这一点的道路并不平坦)。我想让你们注意一下这些公司发布的指导方针和原则:</p><ul class=""><li id="15d6" class="ks kt hi jq b jr km jv kn jz lm kd ln kh lo kl kx ky kz la bi translated"><a class="ae ll" href="https://www.blog.google/technology/ai/ai-principles/" rel="noopener ugc nofollow" target="_blank">谷歌的人工智能原则</a></li><li id="0482" class="ks kt hi jq b jr lb jv lc jz ld kd le kh lf kl kx ky kz la bi translated"><a class="ae ll" href="https://www.microsoft.com/en-us/ai/our-approach-to-ai" rel="noopener ugc nofollow" target="_blank">微软的人工智能原则</a></li></ul><p id="ee97" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这些本质上都是在谈论人工智能中的公平以及何时何地划清界限。当你开始一个新的基于人工智能的项目时，参考它们总是一个好主意。</p><h1 id="8159" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">GDPR是如何改变游戏的</h1><p id="97d5" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">GDPR，即通用数据保护条例，无疑对构建人工智能应用程序的数据收集方式产生了影响。GDPR开始发挥作用，以确保用户对他们的数据有更多的控制权(收集和分享关于他们的信息)。</p><p id="8385" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">那么这对人工智能有什么影响呢？好吧，如果数据科学家没有数据(或者没有足够的数据)，那么构建任何模型都是不可能的。这无疑对社交平台和其他网站过去的工作方式产生了影响。GDPR将成为一个令人着迷的案例研究，但就目前而言，它限制了人工智能在许多平台上的用途。</p><h1 id="341e" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2019年人工智能的伦理趋势</h1><p id="de4a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这是一个有点灰色的领域。就像我提到的，没有唯一的解决方案。我们必须作为一个社区走到一起，将伦理整合到人工智能项目中。我们如何才能做到这一点？正如Analytics Vidhya的创始人兼首席执行官Kunal Jain在2018年DataHack峰会上的讲话中强调的那样，我们需要制定一个其他人可以遵循的框架。</p><p id="f3e1" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我期望看到主要处理道德人工智能的组织中增加新的角色。随着人工智能成为公司愿景的核心，公司最佳实践将需要重新构建，治理方法也需要重新制定。我还希望政府在这方面发挥更积极的作用，出台新的或修改后的政策。2019年将会是非常有趣的一年，的确。</p><h1 id="004a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结束注释</h1><p id="2357" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">有影响力——唯一一个简洁描述2018年惊人发展的词。今年，我已经成为ULMFiT的忠实用户，我期待着尽快探索BERT。确实是激动人心的时刻。</p><p id="825e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我也很想收到你的来信！你觉得哪些发展最有用？您正在使用本文中提到的框架/工具/概念进行任何项目吗？你对来年有什么预测？我期待在下面的评论区听到你的想法和主意。</p></div><div class="ab cl me mf gp mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="hb hc hd he hf"><p id="b742" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><em class="kr">原载于2018年12月19日</em><a class="ae ll" href="https://www.analyticsvidhya.com/blog/2018/12/key-breakthroughs-ai-ml-2018-trends-2019/" rel="noopener ugc nofollow" target="_blank"><em class="kr">【www.analyticsvidhya.com】</em></a><em class="kr">。</em></p></div></div>    
</body>
</html>