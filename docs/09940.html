<html>
<head>
<title>Understanding Ensemble Techniques!!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解合奏技巧！！！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-ensemble-techniques-4a70a4382cfd?source=collection_archive---------15-----------------------#2020-09-27">https://medium.com/analytics-vidhya/understanding-ensemble-techniques-4a70a4382cfd?source=collection_archive---------15-----------------------#2020-09-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b43636e3a67b13908bbf72b38b622396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pkRmArH7fqKLfGdhvjQuIQ.png"/></div></div></figure><h1 id="31a7" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">内容:</h1><ol class=""><li id="8e00" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">什么是系综方法？</li><li id="1916" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">集合方法背后的直觉！</li><li id="23c2" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">不同的合奏方法<br/> *装袋<br/>→装袋背后的直觉<br/> *助推<br/>→助推背后的直觉<br/> *堆叠<br/>→堆叠背后的直觉<br/> *桶模型</li></ol><h1 id="8475" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是系综方法？</h1><ul class=""><li id="f4c4" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kl kd ke kf bi translated">集成方法是创建多个模型，然后将它们组合起来以产生改进结果的技术。</li><li id="f7d2" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated"><em class="km">与单一模型相比，这种方法可以产生更好的预测性能。</em></li><li id="59a6" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">集合方法通常比单一模型产生更精确的解。这是许多机器学习竞赛中的情况，获胜的解决方案使用了集成方法。</li></ul><h1 id="9f0c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">合奏背后的直觉:</h1><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/c3d33f25f0ac88bdd10f117cc2a59b4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SWc491Y5xEUCd532"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">布鲁斯·马尔斯在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="fcd6" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">→假设你是一个建筑巨头，被给予一个建造摩天大楼的项目，你请来了一位建筑师为你建造结构蓝图，你喜欢这个设计，但你发现它有很多缺陷。</p><p id="8388" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">→所以你请来了一群建筑师，他们互相讨论，创造出最好的建筑，几乎没有缺陷。</p><p id="df12" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">集成技术是相似的，建立多个模型以做出最准确的预测。</p><h1 id="cd08" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">不同类型的集成技术</h1><p id="b52d" class="pw-post-body-paragraph kx ky hi jq b jr js la lb jt ju ld le jv lo lg lh jx lp lj lk jz lq lm ln kb hb bi translated">集成技术有 3 种类型:</p><h2 id="2381" class="lr ir hi bd is ls lt lu iw lv lw lx ja jv ly lz je jx ma mb ji jz mc md jm me bi translated">→装袋:</h2><ul class=""><li id="12ef" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kl kd ke kf bi translated"><strong class="jq hj"> Bootstrap Aggregation(或 Bagging) </strong>是一种机器学习集成元算法，旨在提高统计分类和回归中使用的机器学习算法的稳定性和准确性。</li><li id="c6db" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">这也减少了<em class="km">差异，并有助于避免过度拟合</em>。虽然它通常应用于决策树方法，但它可以用于任何类型的方法。</li><li id="a808" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated"><strong class="jq hj">装袋</strong>是模型平均法的一个特例。</li><li id="f12f" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated"><strong class="jq hj"><em class="km">Bootstrapping</em></strong>是对单个数据集进行重采样以创建多个模拟样本的统计过程。<br/>样本是通过一次从数据总体中取出一个观察值，并在选择后将其返回给数据总体而得到的。<br/>这允许一个给定的观察值被多次包含在一个给定的小样本中。</li><li id="71a0" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated"><strong class="jq hj">聚合</strong>就是事物结合的过程。也就是说，把那些东西放在一起，这样我们就可以统称它们。<br/>换句话说，自举样本被建模，结果被组合和产生。</li></ul><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/2395652f77ab401a98ff43c2554e54e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O8wGgRGpWmPH98yUaolIMg.png"/></div></div></figure><p id="23ed" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated"><strong class="jq hj">装袋背后的直觉:<br/> </strong>让我们继续前面为合奏技法产生的直觉。</p><p id="3a7b" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">→指定的建筑师小组被赋予一项任务，即查看设计，并提出一些东西来消除设计中的缺陷。这些建筑师现在分别针对缺陷提出了一个解决方案，并召开了一次会议，会上他们提出了解决方案，同时使用了每位建筑师提出的最合适的解决方案。</p><p id="b49e" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated"><strong class="jq hj">装袋代码:</strong></p><pre class="ko kp kq kr fd mg mh mi mj aw mk bi"><span id="e70f" class="lr ir hi mh b fi ml mm l mn mo">from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.ensemble import BaggingClassifier</span><span id="5170" class="lr ir hi mh b fi mp mm l mn mo">dt = DesicionTreeClassifier()<br/>bagging = BaggingClassifier(base_estimator = dt).fit(x,y)</span></pre><h2 id="8850" class="lr ir hi bd is ls lt lu iw lv lw lx ja jv ly lz je jx ma mb ji jz mc md jm me bi translated">→升压:</h2><blockquote class="mq"><p id="a00b" class="mr ms hi bd mt mu mv mw mx my mz kb dx translated">Boosting 指的是将弱学习者转换为强学习者的一系列算法。</p></blockquote><ul class=""><li id="5f11" class="jo jp hi jq b jr na jt nb jv nc jx nd jz ne kb kl kd ke kf bi translated"><strong class="jq hj"> Boosting </strong>是一种集成方法，用于改进任何给定学习算法的模型预测。</li><li id="5a2b" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated"><strong class="jq hj">助推</strong>的思路是顺序训练弱学习者，每个人都试图纠正前任。</li><li id="ff52" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">这是通过从训练数据构建模型，然后创建第二个模型来尝试纠正第一个模型的错误来实现的。添加模型，直到训练集被完美预测或者添加了最大数量的模型。</li><li id="8c19" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">它<em class="km">减少了模型的偏差</em>。</li></ul><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nf"><img src="../Images/a4c5518048cac774f5ede6a990ff0c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S3iotIOoNo996-JPTE1lDw.png"/></div></div></figure><p id="574f" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated"><strong class="jq hj">助推背后的直觉:<br/> </strong>继续使用早期的直觉方法进行集成</p><p id="8cdf" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">→建筑师可以采用的完成完美设计的另一种方法是。</p><p id="489b" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">→许多建筑师中的一个从设计中的修正开始，当他/她完成时，他/她将他的结果传递给另一个。</p><p id="8762" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">→另一位建筑师查看修改后的设计，再次进行必要的修改，然后交给另一位建筑师。</p><p id="878e" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">→这个过程会一直持续下去，直到设计的文案经过所有建筑师，到达最后一个。</p><p id="11a1" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">→结果将会有一个新的设计副本，其中包含已纠正的缺陷。</p><p id="ffed" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated"><strong class="jq hj">升压代码:</strong></p><pre class="ko kp kq kr fd mg mh mi mj aw mk bi"><span id="5635" class="lr ir hi mh b fi ml mm l mn mo">from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.ensemble import AdaBoostClassifier</span><span id="21bf" class="lr ir hi mh b fi mp mm l mn mo">dt = DecisionTreeClassifier()</span><span id="6034" class="lr ir hi mh b fi mp mm l mn mo">boosting = AdaBoostClassifier(base_estimator=dt)</span></pre><blockquote class="mq"><p id="ea64" class="mr ms hi bd mt mu ng nh ni nj nk kb dx translated">装袋并行处理工作，增压则按顺序进行。</p></blockquote><figure class="nm nn no np nq ij er es paragraph-image"><div class="er es nl"><img src="../Images/38e2c15e3acb91018c5be1965a72ce3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*4l4hDceHaJ_fAtwcN329yA.png"/></div></figure><h2 id="ef97" class="lr ir hi bd is ls lt lu iw lv lw lx ja jv ly lz je jx ma mb ji jz mc md jm me bi translated">→堆叠</h2><ul class=""><li id="df71" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kl kd ke kf bi translated"><strong class="jq hj">堆叠(或堆叠泛化)</strong>是一种集成学习技术，将多个分类或回归模型与元分类器或元回归器相结合。</li><li id="f6e1" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">基于完整的训练集来训练基础级模型，然后在基础级模型类特征的输出上训练元模型。</li><li id="72bb" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">堆叠的好处在于，它可以利用一系列表现良好的模型在分类或回归任务中的能力，并做出比集合中的任何单个模型都更好的预测。</li></ul><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es nr"><img src="../Images/4a5a97e346e4918a52debbfe817fc73d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*2CJovbQiehf1muo3ABlrsQ.png"/></div></figure><p id="b889" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated"><strong class="jq hj">堆叠背后的直觉:<br/> </strong>继续举一个例子，一个建筑巨头想要一个完美的设计，于是带来了多个建筑师。</p><ul class=""><li id="02a0" class="jo jp hi jq b jr kz jt lc jv ns jx nt jz nu kb kl kd ke kf bi translated">现在，每个建筑师都做出了自己最好的设计</li><li id="b9c8" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">设计完成后，这些设计被发送给首席架构师。</li><li id="485d" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">然后，每一个设计都要经过首席建筑师的审核，并组合成一个完美的建筑设计。</li></ul><p id="3a52" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated"><strong class="jq hj">堆垛代码:</strong></p><pre class="ko kp kq kr fd mg mh mi mj aw mk bi"><span id="d8cd" class="lr ir hi mh b fi ml mm l mn mo">from sklearn.linear_model import LogisticRegression<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.ensemble import RandomForestClassifier</span><span id="fc0d" class="lr ir hi mh b fi mp mm l mn mo">from mlxtend.classifier import StackingClassifier</span><span id="5d34" class="lr ir hi mh b fi mp mm l mn mo">Log_model = LogisticRegression()<br/>KNN_model = KNeighborsClassifer()<br/>Rnd_model = RandomForestClassifier()</span><span id="2868" class="lr ir hi mh b fi mp mm l mn mo">stack = StackingClassifier(classifier = <br/>                           [KNN_model,Rnd_model],<br/>                           meta_classifier = Log_model)</span></pre><h2 id="7e2a" class="lr ir hi bd is ls lt lu iw lv lw lx ja jv ly lz je jx ma mb ji jz mc md jm me bi translated">→一桶模型</h2><ul class=""><li id="9065" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kl kd ke kf bi translated">“模型桶”是一种集成技术，其中模型选择算法用于为每个问题选择最佳模型。</li><li id="f5d0" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">当只对一个问题进行测试时，一组模型不会比集合中的最佳模型产生更好的结果，但是当对许多问题进行评估时，它通常会产生比集合中的任何模型平均好得多的结果。</li><li id="605e" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">输入:<br/> —您想要使用的型号。<br/> —一个数据集。</li><li id="12da" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kl kd ke kf bi translated">学习算法:<br/> —使用 10-CV 估计所有模型的误差<br/> —挑选最佳(10-CV 误差最低)模型。<br/> —在数据集上训练模型并返回结果。</li></ul><h1 id="de58" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">快乐学习！！！</h1></div><div class="ab cl nv nw gp nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="hb hc hd he hf"><p id="2673" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">喜欢我的文章？请为我鼓掌并分享它，因为这将增强我的信心。此外，我每周日都会发布新文章，所以请保持联系，以了解数据科学和机器学习基础系列的未来文章。</p><p id="7c14" class="pw-post-body-paragraph kx ky hi jq b jr kz la lb jt lc ld le jv lf lg lh jx li lj lk jz ll lm ln kb hb bi translated">另外，请务必在 LinkedIn 上与我联系。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oc"><img src="../Images/57cf2eec64a7c19552703156e0d5b88f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6dAsijdQwd2DOxiz"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">弗雷德里克·杜比蒙特在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure></div></div>    
</body>
</html>