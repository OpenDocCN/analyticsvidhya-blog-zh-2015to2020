<html>
<head>
<title>Fast — CNN : Subsitution of Convolution layers with FFT layers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Fast — CNN:用FFT层替代卷积层</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fast-cnn-substitution-of-convolution-layers-with-fft-layers-a9ed3bfdc99a?source=collection_archive---------5-----------------------#2020-04-13">https://medium.com/analytics-vidhya/fast-cnn-substitution-of-convolution-layers-with-fft-layers-a9ed3bfdc99a?source=collection_archive---------5-----------------------#2020-04-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2c45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最近我一直在思考卷积神经网络。无论是否有n个通道，卷积核的主要优点是从图像中提取最大特征。主要动机是提取特征，以便我们可以区分目标对象。核的数量越多，精度越高，但在某种程度上。但是更多的数字核意味着更多的计算成本。虽然CNN是迄今为止最好的图像分类算法。但是有两大缺点，第一是计算成本。由于每个像素与内核相乘是耗时的，如果我们增加过滤器的数量，可能需要几个星期来训练一个模型(O(n2))。如果不使用强大的GPU，使用CNN的实时预测几乎不可能有很高的准确性。另一个主要缺点是，如果我们不使用填充，卷积后的结果大小会减小。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/1eacc1b78767978a062e0f8ec13db5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*V5ZIZg7cGHLASKbnRbKBJQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" rel="noopener" href="/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807">源</a>卷积后的输出尺寸</figcaption></figure><p id="bf93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积丢失了边缘信息，为了防止它，我们使用填充。它可以是任何东西，例如，0或旋转图像等。但填充后也有一些损失。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ju"><img src="../Images/51b38ebea49546feaebca6167addba59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JyHNFTEFEV27Wf9TZhBBcQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://stats.stackexchange.com/questions/128880/number-of-feature-maps-in-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">来源</a>这是CNN的工作方式</figcaption></figure><p id="cd46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我提出了一种新的图像与核卷积的方法。我们可以使用<strong class="ih hj">傅立叶变换</strong>来代替卷积。利用卷积和傅里叶变换的性质，可以大大减少运算时间，避免边缘。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jv"><img src="../Images/b0ba8f84e3c18f88665b12f519e5ace0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*_vfCuMioaTkAKW3iHBY5pA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">傅立叶变换公式</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jw"><img src="../Images/c27fb34502a690f46b86dca7f4b4661f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/1*N4vcSU7HfVyZy951-KJcqA.gif"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://www-structmed.cimr.cam.ac.uk/Course/Convolution/convolution.html" rel="noopener ugc nofollow" target="_blank">源</a> FT —卷积属性</figcaption></figure><p id="330b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">该性质表示，通过对图像和核进行傅里叶变换，并在频域相乘，然后进行傅里叶逆变换，可以得到与卷积结果相同或非常相似的结果。</strong>由于傅立叶变换也是繁琐的过程。但是快速傅立叶变换真的非常快，我们可以在O(nlog(n))时间复杂度内得到输出。这里我引用这篇论文<a class="ae jt" href="http://ecmlpkdd2017.ijs.si/papers/paperID11.pdf" rel="noopener ugc nofollow" target="_blank">http://ecmlpkdd2017.ijs.si/papers/paperID11.pdf</a>进行反向传播。但是现在我们采用一个训练好的模型权重，所以我们只需要设计正向传播。</p><p id="82f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以训练一个模型几个小时，但对于实时分析，CNN非常慢。因此，我们用FFT算法代替了前向卷积传播。我得到了非常漂亮的结果，但由于去除了边缘，结果并不精确。这是非常有用的实时算法，如YOLO，R-CNN，更快的R-CNN。因为每个图像被分成几个小部分，并且需要对每个片段运行算法来预测结果。所以，想象一下要花多长时间才能分辨出你的脸是否在照片里。对视频分析也很有用。例如，自动驾驶汽车的智能使用大部分图像处理，这将需要大量处理。但是通过FFT，我们产生与卷积相同的输出。</p><p id="8acf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">FFT如何减少时间？</p><p id="c2c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们有256乘256的图像，并且我们想要对步幅= 1的图像进行3乘3的核卷积，则仅生成一个结果图像就需要64516个步骤(不考虑每次乘法)。这些步骤可以很容易地由我们的通用CPU来执行。但是，假设我们在单个网络中有1000个内核，那么它会变成~64516*1000(如果我们保持图像大小不变)。这有许多工作要做。现在让每一步花t秒，这非常非常小。而CNN算法仅针对一幅图像所花费的总时间是64516000*t秒。虽然“t”很小，但是通过与步长相乘，它会将时间提高很多。为了训练一个神经网络，我们需要大量的图像，这可能需要64516000*t*m秒。因此，我们的主要目标是尽量减少步骤，以便减少时间消耗。主图来了。对图像进行FFT，可能需要50-60步，具体取决于图像的尺寸和大小。计算内核FFT的步骤相同或更少。但是在进行核心的快速傅立叶变换之前，我们需要填充0来获得和图像一样的大小。现在将频域中的图像和内核相乘。下一步是对乘法结果进行FFT逆运算。现在，FFT逆运算的结果将与我们在64516步后得到的卷积输出相同或非常相似。但是在FFT方法中，它需要更少的步骤和时间。在步骤数量上有很大的变化。我们可以使用傅立叶方法在不改变精度的情况下快速得到结果。由于我们得到了与卷积相似的输出，我们需要用FFT层代替卷积层。不需要任何其他改变。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jx"><img src="../Images/f0e7d064f011d731c24a252118697bd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*45hcj3iRD1TTw8zAV6FXQQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">卷积输出</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jy"><img src="../Images/0a1f02a66266235911a2398d0410aed2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zTRA1WWn8N8DH3h_Cw-skQ.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">FFT的输出</figcaption></figure><p id="ccce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我从kaggle获取了脑肿瘤数据集，并训练了一个深度学习模型，该模型有3个卷积层，每个卷积层有1个内核，3个最大池层和640个神经元层。我的模型做得过拟合，精度也不好。因为它帮助我们比较卷积层输出和FFT层输出。因为我们主要关心的是用FFT层代替卷积层。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jz"><img src="../Images/f199812da4f85b3d0c9161fd175cfb3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*1RSL8zrF8A9Y_78y02L4CA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">训练模型的层次</figcaption></figure><p id="c84a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我替换卷积层的步骤如下:</p><ol class=""><li id="ac79" class="ka kb hi ih b ii ij im in iq kc iu kd iy ke jc kf kg kh ki bi translated">我拿了训练过的重量和一张照片。</li><li id="6236" class="ka kb hi ih b ii kj im kk iq kl iu km iy kn jc kf kg kh ki bi translated">对两者进行FFT。</li><li id="167f" class="ka kb hi ih b ii kj im kk iq kl iu km iy kn jc kf kg kh ki bi translated">将它们在频域相乘。</li><li id="4541" class="ka kb hi ih b ii kj im kk iq kl iu km iy kn jc kf kg kh ki bi translated">并对乘法结果进行逆FFT。</li><li id="9ef2" class="ka kb hi ih b ii kj im kk iq kl iu km iy kn jc kf kg kh ki bi translated">将这一层的输出送入另一层。</li><li id="0a9b" class="ka kb hi ih b ii kj im kk iq kl iu km iy kn jc kf kg kh ki bi translated">每次重复这些步骤。</li></ol><p id="f22c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">重复这些步骤后，我得到了非常相似的结果。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ko"><img src="../Images/d5b06fc916bdfb24a7e30876643387d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tUEJqBOTPA8cT8h6z1i8Dg.png"/></div></div></figure><p id="ae40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我用这两种模型预测了253个不同的图像。CNN预测253幅图像的类别所用的时间是<strong class="ih hj">188.133300151825</strong>，FFT预测253幅图像的类别所用的时间是<strong class="ih hj">39</strong>。48665.68668686666它将时间缩短了<strong class="ih hj"> 4.807856811 </strong>倍。</p><p id="9c47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结论:<strong class="ih hj"> FFT层数比卷积层数快大约5倍。</strong>并且我们在没有填充的FFT层之后达到<strong class="ih hj">相同的尺寸。</strong></p><p id="41ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里是我的GitHub库<a class="ae jt" href="https://github.com/pushkar-khetrapal/Fast-CNN" rel="noopener ugc nofollow" target="_blank">https://github.com/pushkar-khetrapal/Fast-CNN</a>。</p><p id="86d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢阅读！我希望你喜欢这篇文章，并获得了一些额外的见解。如果你做了，请随意留下掌声！感谢建设性的反馈。请随时联系我<a class="ae jt" href="https://www.linkedin.com/in/pushkar-khetrapal-bb8935169/" rel="noopener ugc nofollow" target="_blank">这里</a>或者pushkarkhetrapal12@outlook.com。</p><p id="0be1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">普什卡尔·赫特拉帕尔</p></div></div>    
</body>
</html>