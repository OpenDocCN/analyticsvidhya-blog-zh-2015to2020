<html>
<head>
<title>Sentiment Analysis: Building from the Ground Up</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">情感分析:从头开始构建</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sentiment-analysis-building-from-the-ground-up-e12e9195fac4?source=collection_archive---------19-----------------------#2020-05-09">https://medium.com/analytics-vidhya/sentiment-analysis-building-from-the-ground-up-e12e9195fac4?source=collection_archive---------19-----------------------#2020-05-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/2b57b707f6113558fceb6b77e9f51333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*jHzNpL-KagnaHUSHzPTPkA.jpeg"/></div></figure><p id="102a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">情感分析是使用文本分析技术对文本数据中的情感(积极的、消极的和中性的)进行解释和分类。情感分析允许企业在在线对话和反馈中识别客户对产品、品牌或服务的情感。</p><p id="7a8b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">嗯，听起来不错。但是我们到底打算怎么做呢？答案就在相当长一段时间以来引起我们注意的某件事情上。<strong class="io hj">机器学习。</strong></p><p id="bd3c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">老实说，作为一名全栈开发人员，我总是能找到不开始学习ML的理由。用“我怎么会有时间去做这件事”这样的保证来说服自己，或者“我最了解软件工程，我们坚持下去吧。”我把这位美丽的女主人拒之门外。</p><p id="e9e2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">但老实说，那些只是我给自己的一堆借口，让自己不去面对事实。我被它吓倒的事实。然而，我决定一劳永逸地解决这个问题，令我惊讶的是，ML既有趣又吸引人。</p><p id="33bf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以我决定写这篇博客，在构建一个<strong class="io hj">情绪分析</strong>模型的同时，描绘出我进入ML的技术之旅。我将映射出所有的步骤，代码片段，所需的数据操作。所以让我们开始吧。</p><h1 id="6007" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">概观</h1><p id="d19c" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">我们的目标是建立一个情绪分析模型，一旦准备好，将预测用户对所给出的声明的情绪。在我工作的领域中，客户不断给我们的页面提供大量的评论和反馈。因此，我的目标是建立一个模型，将这些输入的情绪映射出来。我自己最近开始使用ML，我会认为这是一个巨大的成就。</p><p id="df5f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">处理文本分类和分析的ML和语言学的子领域被称为<strong class="io hj">自然语言处理。但稍后会详细介绍。</strong></p><h1 id="009e" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">问题陈述</h1><p id="a149" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">构建情感分析模型，将输入文本分类为正面<strong class="io hj">或负面</strong>或<strong class="io hj">负面</strong>。输入将是用户的评论或反馈，但也可以扩展到其他类型的文本消息，如社交媒体帖子或推文。这是通过在已经标记的亚马逊产品评论的数据集上训练我们的模型来实现的。</p><h1 id="e934" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">公制的</h1><p id="9686" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">模型的有效性将在文章的最后基于包括<strong class="io hj">精确度、召回率、F1分数、</strong>和<strong class="io hj">精确度</strong>在内的参数进行评估。我们也会明白这些到底意味着什么。</p><h1 id="0ac1" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">一切开始的地方</h1><p id="fb4a" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">我们打算开始研究每一个ML项目的基础。<strong class="io hj">数据。</strong>我们将使用亚马逊产品评论的数据集。这些数据是从<a class="ae kn" href="https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M" rel="noopener ugc nofollow" target="_blank">张翔的Google Drive d </a> ir中提取的。它包含大约300万条评论，这些评论已经被评为1到5级。我们的模型将从中学习。数据集是CSV格式的。</p><h1 id="064b" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">数据加载和清理</h1><p id="a169" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">我正在为这个项目使用python。这个名为Pandas的令人敬畏的库使加载和读取数据变得超级容易。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="98a6" class="kx jl hi kt b fi ky kz l la lb">import pandas as pd</span><span id="8e34" class="kx jl hi kt b fi lc kz l la lb">df = pd.read_csv('../input/amazon/train.csv')<br/>df_test = pd.read_csv('../input/amazontest/test.csv')</span></pre><p id="a167" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">df是一只熊猫<a class="ae kn" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" rel="noopener ugc nofollow" target="_blank">的数据帧</a>。就这样，我们在CSV中读到了。</p><p id="3838" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们应该经常熟悉我们正在处理的数据类型。我指的是数据集的结构。所以让我们检查行数和列数。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ld"><img src="../Images/7f99837304d4baac09c398efd9e8b966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OXVsCkdyCDzFAMdjfdIM2A.png"/></div></div></figure><p id="c061" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有不到3M的行和3列。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es li"><img src="../Images/a3cb2223059cbad4e6d2249fff9f4d22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TYHx9MtqCI-SG8u8pMh2QA.png"/></div></div></figure><p id="369f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如您所见，这些列的名称有点混乱。让我们解决这个问题。此外，让我们最初用60，000条记录而不是3百万条记录来训练我们的模型。因此我们需要取样。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="4cb4" class="kx jl hi kt b fi ky kz l la lb">#Taking 60000 random samples from the data<br/>df_sam = df.sample(n=60000, random_state=1)</span><span id="1549" class="kx jl hi kt b fi lc kz l la lb">df_sam.columns = ['rating', 'title', 'text']</span><span id="fd3c" class="kx jl hi kt b fi lc kz l la lb">df_test_sam = df_test.sample(n=12000, random_state=1)</span><span id="1d4b" class="kx jl hi kt b fi lc kz l la lb">df_test_sam.columns = ['rating', 'title', 'text']</span></pre><p id="8ac8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">就这样，我们对60k行进行了采样，并将这些列重命名为“评级”、“标题”和“文本”。“评级”包含相应评论的评级,“文本”包含实际评论。</p><p id="cd56" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果你想提高模型的准确性，数据清理是非常重要的。你不希望你的模型现在从错误的数据中学习，是吗？</p><p id="b71c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们首先检查数据集中是否有空值。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="84b4" class="kx jl hi kt b fi ky kz l la lb">print(df_sam.isnull().sum())</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lj"><img src="../Images/396f14bbcaf2862e1484772419c09aac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0qcO46zJrF7mTZD6XX1J4Q.png"/></div></div></figure><p id="2226" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有一条记录的标题为空。我们有多种选择来处理空值，比如删除那一行，用模式或方法替换空记录。但是由于rating和text列中没有空记录，所以我们认为数据是干净的，因为我们只需要那些to列。</p><p id="72d6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们看看我们的数据是什么样子的。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="5e12" class="kx jl hi kt b fi ky kz l la lb">print(df_sam.head())</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lk"><img src="../Images/0132bffd34c68483bfe4953f9652dd7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bbVYB3q7HMYkM2PPMtQncg.png"/></div></div></figure><p id="bc64" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在我们开始从数据集中提取特征之前，让我们先谈一下NLP。计算机不像人类那样解释文本。因此，我们需要找到一种方法，将文本转换为模型可以理解的数字或向量。</p><p id="fa4a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们有了干净的数据，让我们来谈谈类。目前，我们的评分值从1到5不等。从模型预测文本到这样的粒度可能是困难的，因此我们自己给它加标签。1–2被认为是负的，4–5被认为是正的。3是中性的，因此我们现在将删除所有带有3的行。它可用于分类为<strong class="io hj">中性</strong>但让我们保持简单。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="77c4" class="kx jl hi kt b fi ky kz l la lb">def convertToLabel(rating) :<br/>    if rating &gt; 3 :<br/>        return 'Positive'<br/>    else :<br/>        return 'Negative'</span><span id="bf22" class="kx jl hi kt b fi lc kz l la lb">#Converting ratings to positive and negative</span><span id="f40d" class="kx jl hi kt b fi lc kz l la lb">df_new = df_sam.drop(df_sam[df_sam.rating == 3].index, axis=0)<br/>df_new.rating = df_new.rating.apply(convertToLabel)</span><span id="55a3" class="kx jl hi kt b fi lc kz l la lb">df_new_test = df_test_sam.drop(df_test_sam[df_test_sam.rating == 3].index, axis=0)<br/>df_new_test.rating = df_new_test.rating.apply(convertToLabel)</span></pre><p id="6bbf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们需要注意的另一件事是数据中的偏差。有偏见的数据会导致扭曲的预测。因此，我们想要数量几乎相等的<strong class="io hj">阴性</strong>和<strong class="io hj">阳性</strong>。让我们用一个图形表示来验证一下。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="7afa" class="kx jl hi kt b fi ky kz l la lb">df_new.rating.value_counts().reset_index().plot(kind = 'bar' ,x='index', y='rating', figsize=(8,8))</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ll"><img src="../Images/d39330c5fe9f23e85b6e5cb1747fe119.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xX2JaqkiEA4Wys5ew7DG7Q.png"/></div></div></figure><p id="ff94" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">正如我们所看到的，数据没有偏差，因此不需要执行任何删除操作。</p><p id="32ee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我们需要对文本执行操作，去掉数据中没有意义的单词。这些包括网址，HTML标签，甚至在某些情况下是数字。我们还需要删除那些不会改变句子意思的单词。这些包括冠词，如“a”、“the”，但不限于此。这些被称为停用词。</p><p id="b3e0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">记号化</strong>是将大量文本分割成称为记号的较小部分的过程。NLTK是一个了不起的库，它帮助我们实现了这一点，甚至更多。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="da81" class="kx jl hi kt b fi ky kz l la lb">import nltk<br/>nltk.download('punkt')<br/>nltk.download('stopwords')<br/>nltk.download('wordnet')<br/>from nltk.tokenize import word_tokenize<br/>from nltk.stem.wordnet import WordNetLemmatizer<br/>from nltk.corpus import stopwords</span><span id="a6b5" class="kx jl hi kt b fi lc kz l la lb">#tokenizer function will be passed to CountVectorizer at a later stage</span><span id="af2b" class="kx jl hi kt b fi lc kz l la lb">def tokenize(text) :<br/>    text = text.lower()<br/>    #Remove punctuations<br/>    text_normalized = re.sub(r"[^a-zA-Z0-9]", " ", text)<br/>    <br/>    tokens = word_tokenize(text_normalized)<br/>    lemmatizer = WordNetLemmatizer()<br/>    clean_tokens = [lemmatizer.lemmatize(w).strip() for w in tokens if w not in stopwords.words('english')]<br/>    return clean_tokens</span><span id="97fc" class="kx jl hi kt b fi lc kz l la lb">#Create X and y</span><span id="c84b" class="kx jl hi kt b fi lc kz l la lb">X_train = df_new['text']<br/>y_train = df_new['rating']</span><span id="4add" class="kx jl hi kt b fi lc kz l la lb">X_test = df_new_test['text']<br/>y_test = df_new_test['rating']</span></pre><p id="4d64" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们本可以使用sklearn提供的train_test_split这个强大的功能，但是我导入了一个完全不同的测试数据集。</p><h1 id="e52b" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">特征提取和ML流水线</h1><p id="3baf" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">如前所述，计算机不像我们一样理解文本。因此，需要将其转换为令牌计数矩阵。它只是一个矩阵，保存文档中每个标记的出现次数。这可以通过sklearn提供的CountVectorizer来实现。</p><p id="0187" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我在这里使用了一个管道，它有助于链接训练模型所需的步骤。在本文中，我不会深入讨论管道的细节。</p><p id="385d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">仅仅统计单词出现的次数有时是不够的。因此，我们使用另一个称为术语频率逆文档频率的转换器，它基本上也考虑了一个词在整个语料库中的常见程度，因此建立了它的重要性或权重。</p><p id="8c32" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最后，我们将为模型选择一个分类器。我们在这里有多种选择。我们可以使用多项式朴素贝叶斯、支持向量机、随机森林或其他方法。他们实现不同的算法来训练和预测模型。我们用不同的模型获得不同的精度。我已经用多项式NB、SVC和RandomForestClassifier运行了我的代码。</p><p id="9c71" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在让我们看一下代码。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="28d2" class="kx jl hi kt b fi ky kz l la lb">from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import classification_report<br/>from sklearn.pipeline import Pipeline, FeatureUnion<br/>from sklearn.naive_bayes import MultinomialNB<br/>from sklearn.svm import SVC</span><span id="ddd1" class="kx jl hi kt b fi lc kz l la lb">pipeline = Pipeline([<br/>    <br/>    ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1, 2))),<br/>    ('tfidf', TfidfTransformer()),<br/>    ('clf', RandomForestClassifier(n_estimators=100, n_jobs=-1))</span><span id="6a3d" class="kx jl hi kt b fi lc kz l la lb">])</span><span id="1d1a" class="kx jl hi kt b fi lc kz l la lb">start_time = time.time()<br/>pipeline.fit(X_train, y_train)<br/>print("time taken to fit {}s".format(time.time() - start_time))</span></pre><p id="1d0e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里，我们简单地将文本转换成令牌，然后转换成TFIDF矩阵，并将其传递给RandomForestClassifier模型。我们通过调用模型的'<strong class="io hj"> fit' </strong>函数来拟合模型(在本例中是管道)。</p><p id="1c9f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一旦模型被训练，我们就对测试数据调用预测函数。鉴于我们已经有了当前的成果，请将此视为我们为我们的模型设定了一个基准。然后，我们将预测结果与预期结果或y检验进行比较。这告诉我们我们的模型在看不见的数据上表现得有多好。请注意，准确度实际上并不是分类器性能的最佳衡量标准。但这是事实，我还在学习。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="5395" class="kx jl hi kt b fi ky kz l la lb">y_pred = pipeline.predict(X_test)<br/>print("Accuracy is {}".format((y_test.values == y_pred).mean()))</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lm"><img src="../Images/45619ce7e55d2f5068a75d39454e6684.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AergHu411jTYaNwM_RtHKA.png"/></div></div></figure><p id="103b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们用RandomForestClassifier得到了81.74%的准确率。我们很快就会将它与其他分类器进行比较。</p><p id="1834" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">定义模型性能的其他参数有:</p><p id="65e0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">精度</strong>定义为真阳性的数量除以真阳性的数量加上假阳性的数量。真阳性是模型预测为真的结果，并且在预期结果中也是真的。假阳性是模型预测为真但实际上是假的结果。</p><p id="725b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">召回</strong>定义为真阳性的数量除以真阳性的数量加上假阴性的数量。</p><p id="2131" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> F1得分</strong>是准确率和召回率的加权平均值。</p><p id="7faf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们看看我们的模型在这些类别中表现如何。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="66d2" class="kx jl hi kt b fi ky kz l la lb">from sklearn.metrics import classification_report</span><span id="4897" class="kx jl hi kt b fi lc kz l la lb">res = classification_report(y_test, y_pred)<br/>print(res)</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ln"><img src="../Images/94a1d968ffd8869510c1b32583b1de13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KBJdCU-QTxI4oC7EtaABoA.png"/></div></div></figure><p id="a7c2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">是时候检验我们的模型了。我将通过两个用户对我从事的产品的两个评论。我会把评估留给你。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lo"><img src="../Images/ae782fb3775862c62c601619a32db10c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nXaIhx29u4rg_tnT-eHMuA.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">这被预测为负面的</figcaption></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lt"><img src="../Images/855b362a07aae799cf19953fff7d2468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bWqVAfT5s8AXMobKTy35Ow.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">这被预测为积极的</figcaption></figure><p id="f890" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下是多项朴素贝叶斯分类器的分类报告。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lu"><img src="../Images/8c9a90da24d888e61b3e53cc7e0593f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s643DQv9oCdX9gfLgeg9LA.png"/></div></div></figure><p id="6804" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">多项式NB获得的准确度是56%，这比RandomForestClassifier低得多。</p><h1 id="72c8" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">增加班级数量</h1><p id="d54b" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">让我们在数据集中再添加一个类。让我们将3定为中性，看看它如何影响我们的参数。</p><p id="bfc6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下面是函数convertToLabel的修改代码。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="ae66" class="kx jl hi kt b fi ky kz l la lb">def convertToLabel(rating) :<br/>    if rating == 3 :<br/>        return 'Neutral'<br/>    elif rating &lt; 3 :<br/>        return 'Negative'<br/>    else:<br/>        return 'Positive'</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lv"><img src="../Images/3261bdecfe0e5ae8a3ebfe1866bf9fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FRq1y4eU6qP7ssr2oDAoZw.png"/></div></div></figure><p id="28b4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">可以注意到，增加类的数量减少了参数。直观地</p><p id="c161" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我还调整了正面和负面的分布，使它们不平衡。以下是我为我的模型得到的参数值。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lw"><img src="../Images/ba0162dd04c7bbde3c37d0d76aa55dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ZmznIDrQ4Hkts3gjqi_QQ.png"/></div></div></figure><h1 id="61a6" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">好玩的部分</strong></h1><p id="7d4f" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">我还围绕这个模型建立了一个网站，从用户那里获取输入，并将其分为积极或消极。不幸的是，它没有部署在任何地方，但是可以从我的GitHub仓库中克隆这个项目，并在本地运行它。</p><p id="7bff" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">请阅读GitHub上该项目的自述文件，了解关于运行该项目的详细信息。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lx"><img src="../Images/278424241fe2214de2346fa64b114f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jrcA8mr7hir2gEl9s2rkPg.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">行动中的项目</figcaption></figure><h1 id="bf82" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">结论</strong></h1><p id="3565" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">从我们进行的实验中可以得出以下关键结论:</p><ol class=""><li id="8c82" class="ly lz hi io b ip iq it iu ix ma jb mb jf mc jj md me mf mg bi translated">我们在数据清理后获得的许多东西都取决于数据清理的程度。因此，它被认为是任何ML模型的关键部分。当我第一次开始处理数据中不均匀分布的类时，我获得了接近76%的准确率。但是一旦数据被清理，我的模型的准确率就上升到了82%。</li><li id="3055" class="ly lz hi io b ip mh it mi ix mj jb mk jf ml jj md me mf mg bi translated">数据的适当标记化非常重要。去掉所有的停用词减少了词汇频率矩阵所基于的记号的大小。</li><li id="2d23" class="ly lz hi io b ip mh it mi ix mj jb mk jf ml jj md me mf mg bi translated">在仅仅使用术语频率矩阵还是超越并构建术语频率逆文档矩阵之间进行选择是至关重要的。因为某些单词将具有较高的术语频率，但是它们可能在语料库中非常频繁地出现。</li><li id="994e" class="ly lz hi io b ip mh it mi ix mj jb mk jf ml jj md me mf mg bi translated">选择正确的分类器当然可以增加模型的性能度量值。</li></ol><h1 id="7ee0" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">改进</strong></h1><p id="2271" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">这种模式远非完美。有很多事情我可以用不同的方式来进一步提高它的性能。</p><ol class=""><li id="99f8" class="ly lz hi io b ip iq it iu ix ma jb mb jf mc jj md me mf mg bi translated">调整分类器的超参数。</li><li id="5617" class="ly lz hi io b ip mh it mi ix mj jb mk jf ml jj md me mf mg bi translated">下面是我添加到我的管道中的一个转换器的代码，它计算句子的长度，并把它作为一个特性。</li></ol><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="1bb0" class="kx jl hi kt b fi ky kz l la lb">class TextCountExtractor(BaseEstimator, TransformerMixin):</span><span id="cec0" class="kx jl hi kt b fi lc kz l la lb">def getlength(self, text):<br/>        return len(text)</span><span id="4ae8" class="kx jl hi kt b fi lc kz l la lb">def fit(self, X, y=None):<br/>        return self</span><span id="c24f" class="kx jl hi kt b fi lc kz l la lb">def transform(self, X):<br/>        X_tagged = pd.Series(X).apply(self.getlength)<br/>        return pd.DataFrame(X_tagged)</span></pre><p id="3d35" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下面是管道的样子，包括这个转换器。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="53eb" class="kx jl hi kt b fi ky kz l la lb">pipeline = Pipeline([<br/>    <br/>    ('features', FeatureUnion([<br/>        ('text_pipeline', Pipeline([<br/>            ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1, 2))),<br/>            ('tfidf', TfidfTransformer())<br/>        ])),<br/>        ('text-length', TextCountExtractor())<br/>        <br/>    ])),<br/>    <br/>    ('clf', RandomForestClassifier())</span><span id="da72" class="kx jl hi kt b fi lc kz l la lb">])</span></pre></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><p id="f337" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我将转述N.H .克莱因鲍姆的一段话来结束我的演讲。<strong class="io hj">“在你之前已经有过数据科学家，如果你仔细听，你可以听到他们向你耳语他们的遗产。及时行乐，只争朝夕，让您以数据为中心的生活与众不同。”</strong></p></div></div>    
</body>
</html>