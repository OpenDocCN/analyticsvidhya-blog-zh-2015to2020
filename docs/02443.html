<html>
<head>
<title>Adapting BERT question answering for the medical domain</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将BERT问题回答应用于医学领域</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/adapting-bert-question-answering-for-the-medical-domain-2085ada8ceb1?source=collection_archive---------0-----------------------#2019-12-17">https://medium.com/analytics-vidhya/adapting-bert-question-answering-for-the-medical-domain-2085ada8ceb1?source=collection_archive---------0-----------------------#2019-12-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/19a83cfa147cb3c4b57bb5085c9ea491.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2-4v4funQ5ajN4aEOZY5gA.jpeg"/></div></figure><blockquote class="im in io"><p id="089e" class="ip iq ir is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">BERT是去年自然语言处理领域的突破性模型之一，它改变了我们处理文本数据的方式。尽管它已经超越了大范围自然语言处理任务的最新成果，但是围绕它的领域适应和问答任务扩展的一些问题仍然没有被探索。本文旨在总结在<a class="ae jo" href="https://peltarion.com/" rel="noopener ugc nofollow" target="_blank"><strong class="is hj">pelta rion</strong></a><strong class="is hj">暑期实习期间所做的研究，以使BERT适应数量有限的特定领域数据集，用于具有长输入上下文的问答任务。</strong></p></blockquote><p id="0e31" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">在许多具有挑战性的NLP任务中，BERT取得了重大进展，问答就是其中之一。在这项任务中表现良好的模型可以在不同的行业中直接应用，例如，Peltarion的一个客户，一家大型电信公司希望使用深度学习来优化他们的RFP流程。一个可以查看产品文档并突出RFP中所提问题的相关答案或证据的模型可以显著提升RFP流程。来自客户的预期数据将是产品文档、来自RFP的问题以及作为从相应产品文档中提取的答案的注释。在我们要求客户执行昂贵的数据收集任务之前，我们从BERT开始在<a class="ae jo" href="https://github.com/panushri25/emrQA" rel="noopener ugc nofollow" target="_blank"> emrQA </a>数据集上构建概念验证。你可以在[1]和[2]中阅读更多关于BERT和<a class="ae jo" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank">班</a>数据集的问答模型。假设你对BERT模型有一个相当好的理解，这篇博客将带你浏览指导我们实验的研究问题，它们的结果和结论。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es js"><img src="../Images/32cb36e4f3d7e9e2be5763c5d959ce7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*UUJK41lfWp1vIr-DzQx9tw.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">来源—伯特纸业</figcaption></figure><h1 id="31d5" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">研究问题</strong></h1><p id="80ae" class="pw-post-body-paragraph ip iq hi is b it kz iv iw ix la iz ja jp lb jd je jq lc jh ji jr ld jl jm jn hb bi translated">今年早些时候，许多论文[3，4]关注于将BERT应用于不同的领域，如科学和生物医学。常见的方法是要么用大型特定领域语料库(如科学论文)从头开始训练BERT，并使用特定领域词汇，要么用大型特定领域语料库微调BERT的语言模型，同时使用BERT的原始词汇。他们在特定任务的数据集上进一步微调了适应的模型，并在句子分类和NER上进行评估，这是比问答相对容易的任务。此外，现有工作中使用的数据集通常具有较小的上下文长度，通常小于512个标记。BERT有512个输入令牌的限制，但来自客户的产品文档或来自emrQA数据集的临床记录通常比BERT可接受的输入长度大得多。在我们为有限数量的特定于领域的数据集构建QA模型的过程中，面对这些挑战，我们定义了以下研究问题:</p><ol class=""><li id="098c" class="le lf hi is b it iu ix iy jp lg jq lh jr li jn lj lk ll lm bi translated">当输入上下文或段落大于512的n倍时，问答任务的方法是什么？</li><li id="193b" class="le lf hi is b it ln ix lo jp lp jq lq jr lr jn lj lk ll lm bi translated">如何利用有限数量的特定领域语料库(仅产品文档或仅临床笔记)为特定领域问答数据集调整BERT模型？</li><li id="cb16" class="le lf hi is b it ln ix lo jp lp jq lq jr lr jn lj lk ll lm bi translated">将BERT词汇表中的占位符替换为常见的特定于领域的单词有帮助吗？</li><li id="8a32" class="le lf hi is b it ln ix lo jp lp jq lq jr lr jn lj lk ll lm bi translated">需要多少训练数据才能达到像样的准确度？</li></ol><h1 id="819a" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">处理长上下文</h1><p id="465c" class="pw-post-body-paragraph ip iq hi is b it kz iv iw ix la iz ja jp lb jd je jq lc jh ji jr ld jl jm jn hb bi translated">BERT-QA模型接受以下格式的输入:一个“[CLS]”标记，标记化的问题，一个“[SEP]”标记，来自文档内容的标记，以及一个最终的“[SEP]”标记，将每个实例的总大小限制为512个标记。如前所述，临床记录的长度大约是512的5倍，为了处理这个问题，我们修改了训练数据，以便它可以在不修改其架构的情况下由BERT模型使用。诀窍是将临床笔记分成多个子笔记，使得每个子笔记在与输入问题连接时，给出接近512个记号。将输入问题与子笔记串联后，有两种可能:1)如果子笔记包含地面真值答案，则在子笔记中标注答案的起始和结束位置2)如果子笔记不包含地面真值答案，则将起始和结束位置标注为0(指向【CLS】token)。在推断过程中，我们将输入的临床笔记分解成多个子笔记，方式与训练时相似，并将每个部分与输入的问题连接起来。预测给定问题的临床笔记的所有子笔记上答案的开始和结束位置。它是通过为上下文<em class="ir"> c </em>计算<em class="ir"> span_score(c，s，e) </em>来完成的，开始于位置<em class="ir"> s </em>，结束于<em class="ir"> e </em>。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/a92a99b096d9937db4be160babe4fffb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C7_C71RhyM1g5I01rDSsiA.png"/></div></div></figure><p id="7789" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">将临床笔记的子部分<em class="ir"> c </em>中具有最高<em class="ir"> span_score(c，s，e) </em>的答案span <em class="ir"> (s，e) </em>预测为答案。这种方法部分受到[5]的启发。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lx"><img src="../Images/5aa899ef5b24ccc01ac48c9cba4a93f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V1I_3AfVFIzv9KWQsCJCTQ.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">长临床笔记问答的推理阶段</figcaption></figure><h1 id="ef43" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">实验和结果</strong></h1><p id="98ef" class="pw-post-body-paragraph ip iq hi is b it kz iv iw ix la iz ja jp lb jd je jq lc jh ji jr ld jl jm jn hb bi translated">在设计了问答中处理长上下文的方法后，我们做了几个实验来探索剩下的研究问题。对于评估，使用F1分数和EM_5度量。EM_5是精确匹配(EM)度量的修改版本，并且可以被定义为多少次预测的开始和结束位置位于地面真实位置的+/-5个标记的附近。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ly"><img src="../Images/1902910a3753b401bce04327058fcd33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n-NBj5X_0_C4cY2pB4ASJQ.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">评估指标</figcaption></figure></div><div class="ab cl lz ma gp mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="hb hc hd he hf"><p id="aae4" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated"><em class="ir">下图中的实验可以被视为按照从左到右的时间顺序完成的多个训练阶段，其中箭头的颜色表示训练的类型，一个箭头中的两种颜色表示在该训练阶段进行的额外修改。对于所有实验，从预训练的BERT基本无壳模型的权重初始化模型。</em></p></div><div class="ab cl lz ma gp mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="hb hc hd he hf"><p id="be61" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">所有实验可以大致分为三个部分:</p><ol class=""><li id="feff" class="le lf hi is b it iu ix iy jp lg jq lh jr li jn lj lk ll lm bi translated"><strong class="is hj">初步实验</strong></li></ol><p id="9740" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">初步实验是为了找出SQUAD微调的BERT-QA模型在特定领域数据集(如emrQA)上的性能。它验证了我们的直觉，即由于缺乏领域知识，该模型将表现不佳。也是为了找出通过使用emrQA进行任务驱动的微调可以获得多少领域相关的知识。此外，有趣的是，通过使用有限数量的文本数据(即来自emrQA的临床记录)来训练语言模型，可以看出该模型是否可以适应该领域。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mg"><img src="../Images/7fd27dc0df332706cf62c89a4abe8f13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XIA2iS-af2DbhLkre3DwZg.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">初步实验的结果</figcaption></figure><p id="723d" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated"><strong class="is hj"> 2。LM培训的效果</strong></p><p id="e3fd" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">正如从初步实验中观察到的，在特定领域数据集上的任务相关的微调是最有希望的步骤，并且即使在有限数量的领域文本上训练LM也进一步推动了性能。在LM训练期间不使用下一个句子预测任务，因为临床笔记中的两个连续句子即使彼此不相邻，也大多会保持笔记的结构和意图。第一组实验是为了使用LM训练来提高适应性而进行的。可以尝试的一件事是将BERT原始词汇表中的1k占位符替换为最常见的特定领域的单词，以查看它是否有助于模型更好地学习这些单词。另一个想法是通过使用来自另一个名为CliCR的数据集的临床记录来扩充领域语料库。CliCR注释增加的低性能可归因于来自CliCR(源)和emrQA数据集(目标)的临床注释的结构和内容的差异。以下是两种修改的结果:</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mh"><img src="../Images/8e3afaf6bdf44763bff7af114186c10f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xFlBd1BBV0yt_-DTqX_GtA.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">LM训练实验的结果</figcaption></figure><p id="212d" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated"><strong class="is hj"> 3。微调的效果</strong></p><p id="69d9" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">为了更好地进行任务相关的微调，我探索了两个方向。首先，在BERT的基础上添加一个分类器，从临床笔记中筛选出可能有输入问题的潜在答案的相关子部分。简而言之，分类器将采用上下文(来自临床记录的512个标记的窗口)和问题来预测上下文是否与给定的问题相关。如果是，那么可以计算开始和结束分数。另一个问题是，在对领域数据集emrQA进行微调之前，对大型通用领域QA数据集(即SQUAD)进行微调是否会增加价值？结果如下:</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mi"><img src="../Images/497ae54f51cd003b2567ed373531a298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GZ5WfUD7QI0k4DP_Ec3TaQ.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">微调实验的结果</figcaption></figure><blockquote class="im in io"><p id="818a" class="ip iq ir is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“我们假设，当模型直接针对下游任务进行微调，并且仅使用非常少量的随机初始化的附加参数时，任务特定的模型可以受益于更大的、更具表现力的预训练表示，即使下游任务数据非常小。”<em class="hi">摘自伯特的论文</em></p></blockquote><p id="09e4" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated"><strong class="is hj"> 4。训练数据量的影响</strong></p><p id="61f4" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">注释数据既费钱又费时，因此了解真正需要多少注释数据是很重要的。来自上述实验的步骤用于在保持测试数据固定的同时，在不同大小的训练数据上训练模型。下图解释了相同的结果:</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mj"><img src="../Images/0b52c8d97c11351473ce046acd01db8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pqaKKG2xDCm0Pr-8OcwGvQ.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">数据集大小与性能—红色曲线(全部)显示:替换词汇表中的单词，添加分类器层，进行LM训练，SQUAD微调和emrQA微调。</figcaption></figure><h1 id="9e6e" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">结论</strong></h1><ul class=""><li id="14c1" class="le lf hi is b it kz ix la jp mk jq ml jr mm jn mn lk ll lm bi translated">在通用领域数据集上训练的模型在特定领域数据集上表现不佳。</li><li id="aa87" class="le lf hi is b it ln ix lo jp lp jq lq jr lr jn mn lk ll lm bi translated">为了适应领域，任务驱动的特定领域问答数据集微调是最重要的步骤之一。</li><li id="938c" class="le lf hi is b it ln ix lo jp lp jq lq jr lr jn mn lk ll lm bi translated">利用有限数据(只有来自QA数据集的可用段落或临床记录)通过LM训练进行的领域适应在性能上给出了边际改进。</li><li id="a903" class="le lf hi is b it ln ix lo jp lp jq lq jr lr jn mn lk ll lm bi translated">通过替换原始词汇表中的占位符来添加特定于领域的单词有助于模型更好地学习这些单词。</li><li id="f41d" class="le lf hi is b it ln ix lo jp lp jq lq jr lr jn mn lk ll lm bi translated">当特定于领域的数据集有限时，在对特定于领域的QA数据集进行微调之前，用大型通用领域QA数据集对BERT-QA模型进行微调可能会有所帮助。</li></ul><p id="26fd" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">感谢<a class="ae jo" rel="noopener" href="/@anders_9654"> Anders </a>在实习期间的指导以及对本文的宝贵反馈。</p><p id="13a9" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">附:所有方法的代码都可以在我的<a class="ae jo" href="https://github.com/shipra25jain/BERT_medical_QA" rel="noopener ugc nofollow" target="_blank"> Github </a>账号上找到。所有的实验都是在谷歌实验室的免费TPU上进行的</p></div><div class="ab cl lz ma gp mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="hb hc hd he hf"><p id="0f50" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated"><strong class="is hj">参考文献</strong></p><p id="9a62" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">[1]<a class="ae jo" href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2018/11/open-sourcing-Bert-state-of-art-pre . html</a></p><p id="65e3" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">[2]<a class="ae jo" rel="noopener" href="/datadriveninvestor/extending-google-bert-as-question-and-answering-model-and-chatbot-e3e7b47b721a">https://medium . com/datadriveninvestor/extending-Google-Bert-as-question-and-answering-model-and-chatbot-e 3e 7b 47 b 721 a</a></p><p id="7b5b" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">[3] SciBERT:科学文本的预训练语言模型，Beltagy等</p><p id="f8db" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">[4] BioBERT:用于生物医学文本挖掘的预训练生物医学语言表示模型，Lee等</p><p id="c101" class="pw-post-body-paragraph ip iq hi is b it iu iv iw ix iy iz ja jp jc jd je jq jg jh ji jr jk jl jm jn hb bi translated">[5]自然问题的伯特基线，阿尔贝提等</p></div></div>    
</body>
</html>