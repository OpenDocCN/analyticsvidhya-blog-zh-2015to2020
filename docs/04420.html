<html>
<head>
<title>How to Build your First Real-Time Streaming(CDC) system(Verification-Part 4)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何构建您的第一个实时流(CDC)系统(验证-第4部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-build-your-first-real-time-streaming-cdc-system-verification-part-4-295399f78edd?source=collection_archive---------17-----------------------#2020-03-18">https://medium.com/analytics-vidhya/how-to-build-your-first-real-time-streaming-cdc-system-verification-part-4-295399f78edd?source=collection_archive---------17-----------------------#2020-03-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b2cfa479d2e9b4ccc53fccdf2e74c3b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eus7YSXonuePTTnx81L_zQ.jpeg"/></div></div></figure><p id="6085" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本文是我们关于Kafka streams的系列文章的继续，在该系列文章中，我们着手构建了一个实时流系统。在本概念验证的第<a class="ae jo" rel="noopener" href="/@rohan.mudaliar/how-to-build-your-first-real-time-streaming-cdc-system-introduction-part-1-5d61b2d9d511">篇第1 </a>中，我们了解了构建系统所需的关键概念，在第<a class="ae jo" rel="noopener" href="/@rohan.mudaliar/how-to-build-your-first-real-time-streaming-cdc-system-setup-part-2-bac2c5397d5e">篇第2 </a>中，我们了解了MySql设置和本地基础架构设置。在<a class="ae jo" rel="noopener" href="/analytics-vidhya/how-to-build-your-first-real-time-streaming-cdc-system-kafka-steams-and-aggregation-part-3-8a331e98961d">第3篇</a>中，我们使用Kafka stream和Elasticsearch构建了java后端。让我们快速回顾一下我们已经解决的问题。</p><h1 id="441a" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">问题陈述摘要</h1><p id="bddb" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们有一家电子商务公司，该公司的业务团队需要包含一些实时更新的报告来做出决策。我们的后端是用java构建的，它使用微服务。架构如下所示:</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ks"><img src="../Images/f5b28ece65d30961008ba13820e9d1fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dOIenWSvxFLCI-Iv0OoOGA.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">系统图</figcaption></figure><p id="aad5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">业务团队希望使用这些数据构建一个仪表板，并利用它做出一些营销决策。所有这些数据都存在于3个不同的数据库中，分别用于我们需要获取信息的3个不同的系统。我们决定使用Debezium和Kafka Connect来传输这些变化。</p><h1 id="71f6" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">总体技术任务:</h1><p id="b6c9" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">因此，就整体任务而言，我们将把它们划分如下</p><ol class=""><li id="01a9" class="lb lc hi is b it iu ix iy jb ld jf le jj lf jn lg lh li lj bi translated"><strong class="is hj">使用docker建立本地基础设施。</strong></li><li id="b3f9" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated"><strong class="is hj">使用Kafka connect将数据从MySQL数据库提取到Kafka。</strong></li><li id="285b" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated"><strong class="is hj">在Java后端使用Kafka流读取数据。</strong></li><li id="a8b3" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated"><strong class="is hj">为聚集视图创建弹性搜索索引。</strong></li><li id="8847" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated"><strong class="is hj">实时监听事件并更新事件。</strong></li><li id="a815" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">验证elasticSearch中的更新</li><li id="ae8f" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">设置本地并运行java代码</li></ol><h1 id="04e7" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">6.查看创建的索引，验证Kibana中的更新并提取报告:</h1><p id="9f7d" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">现在我们已经创建了我们的索引，下一步是验证这些索引是通过Kibana创建的，并提取一个pdf文件提供给业务用户。让我们看看我们怎样才能做得差不多。</p><p id="7a7d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从浏览器前往基巴纳:</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="2ff8" class="lu jq hi lq b fi lv lw l lx ly">&lt;http://localhost:5601/app/kibana#/dev_tools/console?_g=()</span></pre><p id="7ba5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">点击开发工具(<strong class="is hj">带有螺丝刀符号</strong>的工具)，您可以在此执行您的命令。</p><p id="026d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">查看创建的索引:</strong></p><p id="ad78" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是用于验证索引是否已创建的命令。</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="a1f4" class="lu jq hi lq b fi lv lw l lx ly">GET _cat/indices</span></pre><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/b579a79300d611922831cfcaa4ad8c65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nMK6uIGALb5YiKN-Ll28xw.png"/></div></div></figure><p id="5e01" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我的例子中，latestoutboundreport_es是创建的索引。</p><p id="330b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们需要验证索引中是否有数据，运行以下命令:-</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="52b8" class="lu jq hi lq b fi lv lw l lx ly">GET latestoutboundreport_es/_search<br/>{<br/>    "query": {<br/>        "match_all": {}<br/>    }<br/>}</span></pre><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/d45ca556f6c70aaa15d96b2adedc9f2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S0W7wHNebZRQX7ubhhb8UQ.png"/></div></div></figure><h1 id="fa7f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">测试更新</h1><p id="4455" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">为了测试事件流和实时更新，我们需要模拟这个场景。我们可以通过对用于创建聚集索引的三个表进行更新来测试这一点。</p><p id="2b22" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用的SQL查询如下:</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="6daf" class="lu jq hi lq b fi lv lw l lx ly">update wms_demo set item_qty=4 where id =1;<br/>update order_demo set order_description='Apple Iphone X Black-64 GB' where id=1;<br/>update logistics_demo set shipment_cost=25.5 where id=2;</span></pre><p id="fe49" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">更新前:</strong></p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/d750890561afe91b5928bbc40a4955d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aRYO2xQy-xLR-f9z7LJU7g.png"/></div></div></figure><p id="4f8e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">更新后</strong></p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/ea1b566561337b59ac0e158c52fa7627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3OP1qB8G1O3gdVndxgtzQw.png"/></div></div></figure><p id="c086" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我正在更新数量(1到2)和项目描述(64 GB到128 GB)。</p><p id="a8fc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">导出CSV: </strong></p><p id="a178" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们有了记录，下一步是将这些数据导出到pdf中，幸运的是，Kibana确实有导出CSV的选项。</p><p id="a714" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">单击discover选项卡，这将显示正在接收的连续数据流。现在您可以提供您的搜索过滤器，一旦您的搜索结果出现。</p><p id="b7d7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">点击保存并导出CSV。参考下面的截图:-</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/76683e6818a2c8bdb93cdd0767f47c7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v0zyeg2kuqQP6TPfNtGe9g.png"/></div></div></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/35903448e71a73716b501c036f373eed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dWyWBuD1gqrLaFFYD209nQ.png"/></div></div></figure><p id="aa46" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">总结:</strong></p><p id="f0a2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">现在我们已经到了最后一步，让我们回顾一下我们在本练习中所做的一切:- </strong></p><ul class=""><li id="8464" class="lb lc hi is b it iu ix iy jb ld jf le jj lf jn mf lh li lj bi translated">我们首先在MySQL数据库上启用了Binlogs。</li><li id="a560" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated">我们使用docker在本地为应用程序创建了所需的服务。</li><li id="b47d" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated">接下来，我们使用Debezium-Kafka connect创建了一个连接器，它将监听MySQL数据库中的创建/更新，并将更改推送到Kafka。</li><li id="8c2a" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated">我们编写了一个Kafka streams应用程序，它可以实时监听Kafka事件并创建聚合视图。</li><li id="e8e2" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated">我们使用RestHighLevelClient在Elasticsearch上创建了一个索引。</li><li id="fafc" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated">我们使用Kafka流编写了另一个监听器，监听单个Kafka事件并推送更新。</li></ul><h1 id="5593" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">7.在本地运行代码库。：</h1><p id="4dbe" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">该代码可从以下网址获得</p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="13f1" class="lu jq hi lq b fi lv lw l lx ly"><a class="ae jo" href="https://github.com/rohan-mudaliar/big_data_pocs/tree/master/kafkastreams-elasticsearch-demo" rel="noopener ugc nofollow" target="_blank">rohan_gitrepo</a></span></pre><p id="a83f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感兴趣的项目是<strong class="is hj">kafk streams-elastic search-demo</strong>。一旦您获得了代码，下一步就是做同样的maven构建。</p><p id="0d2a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> SQL设置:</strong></p><p id="78d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要在三个不同的数据库中创建三个表wms_demo、order_demo和logistics_demo。相同的SQL脚本存在于项目中，如下所示。</p><p id="afed" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">创建脚本:</strong></p><p id="914e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> WMS_DEMO </strong></p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="7356" class="lu jq hi lq b fi lv lw l lx ly">CREATE TABLE `wms_demo` (<br/>  `id` bigint(20) NOT NULL AUTO_INCREMENT,<br/>  `order_id` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `item_type` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `courier` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `item_qty` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `item_localtion` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `shipment_id` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `created_at` datetime(6) DEFAULT NULL,<br/>  PRIMARY KEY (`id`)<br/>) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;</span></pre><p id="255b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">订单_演示</strong></p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="118f" class="lu jq hi lq b fi lv lw l lx ly">CREATE TABLE `order_demo` (<br/>  `id` bigint(20) NOT NULL AUTO_INCREMENT,<br/>  `order_id` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `order_date` datetime(6) DEFAULT NULL,<br/>  `order_description` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `order_value` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `customer_address` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `created_at` datetime(6) DEFAULT NULL,<br/>  PRIMARY KEY (`id`)<br/>) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;</span></pre><p id="5856" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">物流_演示</strong></p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="ab17" class="lu jq hi lq b fi lv lw l lx ly">CREATE TABLE `logistics_demo` (<br/>  `id` bigint(20) NOT NULL AUTO_INCREMENT,<br/>  `wmsrecord_id` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `item_type` datetime(6) DEFAULT NULL,<br/>  `shipment_cost` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  `created_at` datetime(6) DEFAULT NULL,<br/>  `courier` varchar(40) COLLATE utf8mb4_unicode_ci NOT NULL,<br/>  `order_id` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,<br/>  PRIMARY KEY (`id`)<br/>) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;</span></pre><p id="27a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意:所有这三个表都是在不同的数据库中创建的。</p><p id="2364" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">插入脚本:</strong></p><p id="8995" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> WMS_DEMO </strong></p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="9665" class="lu jq hi lq b fi lv lw l lx ly">INSERT INTO `wms_demo` (`id`, `order_id`, `item_type`, `courier`, `item_qty`, `item_localtion`, `shipment_id`, `created_at`)<br/>VALUES(1,'1','electronics','DHL','2','RACK12BA3','2','2020-02-03 12:28:44.000000');</span></pre><p id="75ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">订单_演示</strong></p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="7f05" class="lu jq hi lq b fi lv lw l lx ly">INSERT INTO `order_demo` (`id`, `order_id`, `order_date`, `order_description`, `order_value`, `customer_address`, `created_at`)<br/>VALUES<br/>    (1,'1','2020-02-02 12:23:25.000000','Apple Iphone X Black-128 GB','Rs 52755','Jotaro Kujo,No 1,2nd cross,RK Puram, Bangalore -5600103','2020-02-02 12:23:25.000000');<br/>INSERT INTO `wms_demo` (`id`, `order_id`, `item_type`, `courier`, `item_qty`, `item_localtion`, `shipment_id`, `created_at`)<br/>VALUES(1,'1','electronics','DHL','2','RACK12BA3','2','2020-02-03 12:28:44.000000');</span></pre><p id="28ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">物流_演示:</strong></p><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="1f7c" class="lu jq hi lq b fi lv lw l lx ly">INSERT INTO `logistics_demo` (`id`, `wmsrecord_id`, `item_type`, `shipment_cost`, `created_at`, `courier`, `order_id`)<br/>VALUES(2,'1','0000-00-00 00:00:00.000000','24.5','2020-02-04 00:04:05.000000','FETCHR','1');<br/>​</span></pre><p id="48c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">出于概念验证的目的，我只有5个订单，其中5个记录在wms表中，5个记录在logistics表中。您可以使用insert语句在本地添加更多记录。</p><p id="812a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">运行代码:</strong></p><p id="0d2c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">完成SQL设置后，要使用docker设置基础设施，请遵循以下步骤</p><ol class=""><li id="bb59" class="lb lc hi is b it iu ix iy jb ld jf le jj lf jn lg lh li lj bi translated">将<em class="mg"> docker-compose.yml </em>中的“<strong class="is hj"> ADVERTISED_HOST_NAME </strong>”编辑为您机器的IP</li><li id="d923" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">运行'<code class="du mh mi mj lq b">docker-compose up -d</code>'</li><li id="b33d" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">运行<code class="du mh mi mj lq b">curl -H "Accept:application/json" localhost:8083/</code>检查Kafka connect是否启动</li><li id="eb4e" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">在本地创建一个连接器(参考步骤<strong class="is hj">使用Kafka connect创建一个MySQL连接器</strong>)。</li><li id="6338" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">一旦Kafka connect启动<code class="du mh mi mj lq b">curl -H "Accept:application/json" localhost:8083/connectors/</code>,检查您的连接器是否启动</li><li id="1b4a" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">运行“<code class="du mh mi mj lq b">kafka-topics --zookeeper localhost:2181 --list</code>”以获取已创建主题的列表</li><li id="53dd" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">使用'【T3]'阅读主题</li></ol><p id="8239" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意:</p><ol class=""><li id="98c5" class="lb lc hi is b it iu ix iy jb ld jf le jj lf jn lg lh li lj bi translated">我们用于连接的用户应该拥有<strong class="is hj">重新加载</strong>和<strong class="is hj">复制</strong>权限。</li><li id="7fce" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">如果您的任何docker容器意外关闭，最可能的原因之一是docker内存不足。按照以下步骤进行纠正:</li></ol><p id="dbc4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a)打开docker桌面偏好设置</p><p id="2dfb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">b)转到高级</p><p id="911a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">c)将滑块设置为<strong class="is hj"> 4GB RAM </strong></p><p id="0d37" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦基础设施建立起来，进入终端，输入下面的命令。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/66c0b4fa95d5f782e2852fa7891f051e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnNdWauUuXFrKmzydP5niQ.png"/></div></div></figure><p id="66e8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将运行应用程序，并在Elasticsearch中创建初始索引。下一步是通过在MySql终端上执行脚本并在Elasticsearch中进行验证来检查更新。</p><h1 id="10eb" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">总而言之:</h1><h1 id="f3b9" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">问题/拦路虎:</strong></h1><p id="a140" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">现在我们已经建立了我们的系统，我想谈的一件事是我确实面临挑战和解决方法的一般地方。</p><ul class=""><li id="8a88" class="lb lc hi is b it iu ix iy jb ld jf le jj lf jn mf lh li lj bi translated"><strong class="is hj">数据库设置- </strong>对于amazon rds和独立服务器，Binlogs设置有所不同。所以权限也不同。根据debezium文档，必须注意这一点。</li><li id="20fd" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated"><strong class="is hj">连接器问题- </strong>连接器的许多问题都与配置有关。所以理解Kafka connect和debezium的配置参数将会节省您很多时间。</li><li id="9f13" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated"><strong class="is hj">生产中的主题创建问题- </strong>我们经常面临的一个问题是连接器最初读取一些数据，然后停止，并显示如下错误消息。</li></ul><pre class="kt ku kv kw fd lp lq lr ls aw lt bi"><span id="214d" class="lu jq hi lq b fi lv lw l lx ly"><em class="mg">connector stopped after creating 880 topics with Got error produce response with correlation id 1895609 on topic-partition testdeb04030642pm.catalog.catalog_optical_frame_eav-0, retrying (2147483646 attempts left). Error: KAFKA_STORAGE_ERROR</em></span></pre><ul class=""><li id="61e1" class="lb lc hi is b it iu ix iy jb ld jf le jj lf jn mf lh li lj bi translated">问题是debezium从数据库中读取的速度比写入的速度快。所以你必须调整配置。</li></ul><h1 id="849a" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">我学到的:</h1><p id="13dc" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我想说，对我来说，这个练习最大的收获是卡夫卡  <strong class="is hj"> </strong>和卡夫卡生态系统 中的<a class="ae jo" href="https://www.confluent.io/blog/event-streaming-platform-1/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">事件流的想法。所以我们可能都读过或读过卡夫卡。因此，在我建立这个平台的过程中，我确实更好地理解了为什么Kafka要在LinkedIn上建立，Kafka Connect、Kafka streams是如何以及为什么被添加到这个平台以及它们的功能。更上一层楼，我也可以理解大数据、物联网和处理海量数据的一切是如何联系在一起的。对于那些对事件流感兴趣的人，我留下了下面我觉得有趣的链接:-</strong></a></p><p id="a024" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://www.confluent.io/blog/event-streaming-platform-1/" rel="noopener ugc nofollow" target="_blank">https://www.confluent.io/blog/event-streaming-platform-1/</a></p><p id="5c71" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://www.confluent.io/blog/event-streaming-platform-2/" rel="noopener ugc nofollow" target="_blank">https://www.confluent.io/blog/event-streaming-platform-2/</a></p><p id="7995" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来是关于理解平台中使用的各个组件、它们背后的故事以及它们的功能</p><ul class=""><li id="0cdf" class="lb lc hi is b it iu ix iy jb ld jf le jj lf jn mf lh li lj bi translated"><a class="ae jo" href="https://docs.confluent.io/current/connect/index.html" rel="noopener ugc nofollow" target="_blank">卡夫卡-连接</a></li><li id="09a8" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated"><a class="ae jo" href="https://kafka.apache.org/documentation/streams/" rel="noopener ugc nofollow" target="_blank">卡夫卡——溪流</a></li><li id="92cb" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated"><a class="ae jo" href="https://www.elastic.co/guide/en/elasticsearch/client/java-rest/master/java-rest-high.html" rel="noopener ugc nofollow" target="_blank"> ElasticSearch-Java-API的</a></li><li id="d1b4" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated">Debezium </li></ul><p id="9c86" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">进一步范围:</strong></p><ul class=""><li id="d21e" class="lb lc hi is b it iu ix iy jb ld jf le jj lf jn mf lh li lj bi translated">目前，在这个项目中，我们只在构建数据管道项目的数据工程方面进行了工作，业务所需的最终报告需要进行一些分析工作。</li><li id="49fb" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated">目前，我们只处理了三个表，这可以扩展到多个表，我们可以创建复杂的聚合视图。</li><li id="954b" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated">这个技术栈的一个特点是没有ml，如果java需要，我们可以使用java中的spark MLlib功能来完成ML任务。</li><li id="694b" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn mf lh li lj bi translated">将Debezium与部署在AWS/cloud上的MySql一起使用的一个挑战是，它会创建一个读锁。这可能会影响性能。</li></ul><blockquote class="ml"><p id="f7bf" class="mm mn hi bd mo mp mq mr ms mt mu jn dx translated">如果您确实喜欢这篇文章，请务必阅读后续文章并分享您的反馈。在LinkedIn上找到我，地址是<a class="ae jo" href="https://www.linkedin.com/in/rohanganesh0506/" rel="noopener ugc nofollow" target="_blank"> rohan_linkedIn </a>。</p></blockquote></div></div>    
</body>
</html>