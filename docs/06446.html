<html>
<head>
<title>YOLOv4 implementation to detect custom objects using Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLOv4实现使用Google Colab检测自定义对象</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/implementing-yolov4-to-detect-custom-objects-using-google-colab-6691c98b15ff?source=collection_archive---------1-----------------------#2020-05-23">https://medium.com/analytics-vidhya/implementing-yolov4-to-detect-custom-objects-using-google-colab-6691c98b15ff?source=collection_archive---------1-----------------------#2020-05-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/c285f30b2fc594927df6849b52f6be3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/1*gyUSrfu4svv_kqO-YsTuRg.gif"/></div><figcaption class="im in et er es io ip bd b be z dx translated">演示</figcaption></figure><p id="67f5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我在这段视频中测试了探测器，这段视频来自布鲁克林九九事件中霍尔特和佩拉尔塔患腮腺炎的一集。这部剧的超级粉丝，你一定要看！</p><p id="6019" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，在本文中，我将解释如何实现YOLOv4来检测定制对象。当我想写这个的时候，我计划使用一个玩具数据集，但是因为这些不幸的时刻，我们所有人都必须戴上面具，我想这个特别的应用会更有用。因此，我决定构建一个对象检测器，它可以识别某人是否戴着面具。</p><h2 id="1efb" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">YOLO简介…</h2><p id="7d95" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">你只看一次(YOLO)是一个实时对象检测系统，它可以在单帧中精确地检测多个对象。它非常快，根据Yolo <a class="ae jo" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank">官方网站</a>的说法，它比R-CNN快1000倍，比快速R-CNN快100倍。</p><p id="596a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最新的第四版是由Alexey Bochkovskiy——Github上著名的AlexeyAB，Chien，Hong-Yuan Mark Liao——于上个月发布的。最初的作者停止了开发YOLO，Joseph Redmon在推特上说“我停止了简历研究，因为我看到了我的工作产生的影响。我热爱这项工作，但军事应用和隐私问题最终变得不容忽视。”另一方面，阿里·法尔哈迪创建了xnor.ai公司，该公司现在被苹果公司收购。</p><p id="26ab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从<a class="ae jo" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank">的论文</a>，你可以理解，主要目标是设计一个更快更准确的对象检测器，可以在任何传统的GPU上训练和测试，以实现实时、高质量和令人信服的结果。我不打算详细讨论YOLO的工作原理，因为这篇文章主要关注实现。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es kp"><img src="../Images/53f98218c2471a9e87eb10efb0456d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yLe9jJTMmdYPT_TZSDdb-w.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">YOLOV4与最先进的物体探测器的比较[ <a class="ae jo" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="6adf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如图所示，YOLOv4比谷歌开发的<a class="ae jo" href="https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html" rel="noopener ugc nofollow" target="_blank"> EfficientDet </a>快2倍，性能相当。它在COCO数据集上获得了43.5的AP(65.7%ap₅₀)，在Tesla V100上也实现了65 FPS的实时推理速度。与YOLOv3相比，AP和FPS分别提高了10%和12%。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="9d6b" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">让我们开始行动吧！</h2><p id="9fa4" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated"><strong class="is hj"> <em class="lf">先决条件</em> </strong>:</p><ul class=""><li id="0ab6" class="lg lh hi is b it iu ix iy jb li jf lj jj lk jn ll lm ln lo bi translated">CMake &gt;= 3.12</li><li id="2b4a" class="lg lh hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">CUDA 10.0</li><li id="9583" class="lg lh hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">OpenCV &gt;= 2.4</li><li id="3508" class="lg lh hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">cuDNN &gt;= 7.0，适用于CUDA 10.0</li><li id="2147" class="lg lh hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">Windows或Linux</li></ul><p id="8fbb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你不想设置CUDA的麻烦，cuDNN然后使用<a class="ae jo" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Colab </a>，并且它也有相当好的GPU(NVIDIA Tesla K80)。对于这个例子，我使用了<strong class="is hj">的Google Colab </strong>。如果您在本地计算机上运行，请相应地更改下面命令中的路径。</p><p id="a8d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf">提示:</em> </strong> <em class="lf">如果你遇到任何与路径相关的问题，记住路径应该总是相对于暗网文件。</em></p><p id="7ee7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf">面具数据:</em> </strong>我开始从谷歌和其他网站搜集数据，但偶然发现了这个真实世界的面具人脸数据集<a class="ae jo" href="https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset" rel="noopener ugc nofollow" target="_blank"> (RMFD) </a>。有很多人戴口罩和不戴口罩的图像，我拍了一小部分。因此，我使用的最终数据集包含600张图像— 300(mask) &amp; 300(no_mask)。</p><p id="1dcb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf">标注:</em> </strong>现在我们需要对图片进行标注，对于YOLOv4来说每张图片都需要有一个对应的。txt文件放在同一个目录下同名。每个文本文件包含每个对象的类id和边界框的坐标，如下所示。</p><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="5745" class="jp jq hi lv b fi lz ma l mb mc">&lt;object-class&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</span></pre><ul class=""><li id="8ba5" class="lg lh hi is b it iu ix iy jb li jf lj jj lk jn ll lm ln lo bi translated">对象类基本上是一个从0到类-1的整数。在这种情况下，因为有两个类— 0: mask，1: no_mask</li><li id="427f" class="lg lh hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated"><x_center> <y_center> <width> <height>是相对于图像宽度和高度的浮点值，它可以等于(0.0-1.0)</height></width></y_center></x_center></li></ul><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es md"><img src="../Images/d854de7717a01a37e33bfff07a4a2e52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QIOsCpZnHsdgb7OohQHCHw.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">标记图像的示例</figcaption></figure><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es me"><img src="../Images/ab4ca3f0ce64cdf42c414edf66ebeb9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SfBFtIarUM5AVNIaWFEvFA.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">的样本。' txt '文件</figcaption></figure><p id="13a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于任何标记目的，我总是使用<a class="ae jo" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> labelImg </a>，它支持YOLO和帕斯卡VOC格式，GUI设计有非常好的快捷方式。在标签的最后，确保你有一个相同但不同扩展名的图像的文本文件。例如，我有600个图像文件和600个文本文件。</p><p id="640e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf">训练数据的步骤:</em> </strong></p><ol class=""><li id="3147" class="lg lh hi is b it iu ix iy jb li jf lj jj lk jn mf lm ln lo bi translated"><strong class="is hj"><em class="lf">Darknet build</em></strong>—我会用Darknet，它是一个开源的神经网络框架。让我们下载并安装暗网。您可以下载或克隆它。</li></ol><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="8f42" class="jp jq hi lv b fi lz ma l mb mc">git clone <a class="ae jo" href="https://github.com/AlexeyAB/darknet.git" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexeyAB/darknet.git</a></span></pre><p id="9c0d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">之后在darknet目录中，打开<em class="lf"> Makefile </em>，然后将GPU、CUDNN和OPENCV设置为1，这样可以利用GPU加速训练。现在运行以下命令来构建Darknet。如果您使用的是Windows，请按照这些<a class="ae jo" href="https://github.com/AlexeyAB/darknet#how-to-compile-on-windows-using-cmake" rel="noopener ugc nofollow" target="_blank">步骤</a>进行编译。(<a class="ae jo" rel="noopener" href="/analytics-vidhya/installing-darknet-on-windows-462d84840e5a">在Windows上安装Darknet的备用源</a></p><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="beb3" class="jp jq hi lv b fi lz ma l mb mc">os.chdir('darknet')<br/>make</span></pre><p id="eff2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要首先验证暗网构建，下载<a class="ae jo" href="https://drive.google.com/open?id=1cewMfusmPjYWbrnuJRuKhPMwRe_b9PaT" rel="noopener ugc nofollow" target="_blank"> Yolo-v4权重</a>并将其放在根目录中，然后运行下面的命令。</p><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="b84c" class="jp jq hi lv b fi lz ma l mb mc">./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights data/person.jpg -dont_show</span></pre><p id="ac4b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以查看根目录下保存为<em class="lf">predictions.jpg</em>的预测。如果你在Windows下运行，使用<code class="du mg mh mi lv b">darknet.exe</code>而不是<code class="du mg mh mi lv b">./darknet</code></p><p id="8555" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，如果它成功地工作，因为下载的权重是从训练COCO数据集获得的，它对所有的<a class="ae jo" href="https://gist.github.com/SrikarNamburu/0945de8f9a8714ec245dde3443e9d487" rel="noopener ugc nofollow" target="_blank"> 80 coco类</a>都有效。</p><p id="c0c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.<strong class="is hj"> <em class="lf">配置</em> </strong> —根据您的需求选择一个YOLOv4配置文件。我选中<code class="du mg mh mi lv b">yolov4-custom.cfg</code>，把<code class="du mg mh mi lv b">cfg/yolov4-custom.cfg</code> <em class="lf"> </em>的内容复制到一个新文件<code class="du mg mh mi lv b">cfg/yolo-obj.cfg</code>。相应地调整batch、subdivisions、steps、max_batches等参数。有关参数的更多信息，请参考此<a class="ae jo" href="https://github.com/AlexeyAB/darknet/wiki/CFG-Parameters-in-the-%5Bnet%5D-section" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="aff5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf">提示</em> </strong> <em class="lf">:设置max_batches值最小为2000*类，步数为max_batches的80% - 90%。还有宽度，高度参数应该是32的倍数(我用过416x416)。</em></p><p id="d2d7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将<em class="lf"> classes </em>参数更新为第<em class="lf"> 970、1058、1146 </em>行<code class="du mg mh mi lv b">yolo-obj.cfg</code>文件中3 <em class="lf"> yolo </em>层的对象数量，因为我们只有2个类(mask、no_mask)。现在类似地，在每个<em class="lf"> yolo </em>层之前的3个<em class="lf">卷积</em>层中，将filters参数更新为filters=(classes + 5) x 3。在这种情况下，classes = 2因此，在行<em class="lf"> 963、1051、1139 </em>中将过滤器设置为21(不要在<em class="lf">中编写过滤器= (classes + 5) x 3)。cfg </em>文件)</p><p id="7eb1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了开始培训，我们需要创建以下文件:</p><p id="ab53" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用类名在目录<code class="du mg mh mi lv b">build\darknet\x64\data\</code>中创建<code class="du mg mh mi lv b">obj.names</code>，在本例中是— mask，no_mask。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/22503ca53018631955612f83369c08e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*uS3gNJTrUfMg6B5CWX7RBA.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">obj.names文件示例</figcaption></figure><p id="d377" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们必须在包含图像路径的目录<code class="du mg mh mi lv b">build\darknet\x64\data\</code>中创建<em class="lf"> train.txt </em>和<em class="lf"> test.txt </em>文件。使用以下代码创建文件。</p><figure class="kq kr ks kt fd ij"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="ce7e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，这两个文件应该如下所示:</p><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="adb7" class="jp jq hi lv b fi lz ma l mb mc">/content/gdrive/My Drive/darknet/build/darknet/x64/data/obj/273.jpg<br/>/content/gdrive/My Drive/darknet/build/darknet/x64/data/obj/294.jpg<br/>/content/gdrive/My Drive/darknet/build/darknet/x64/data/obj/15.jpg</span></pre><p id="0ba5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">把所有的图像文件(。jpg)和标签文件(。txt)放在同一个目录下也就是<code class="du mg mh mi lv b">build\darknet\x64\data\obj</code></p><p id="3a75" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">之后，在目录<code class="du mg mh mi lv b">build\darknet\x64\data\</code>中创建<code class="du mg mh mi lv b">obj.data</code>文件，它应该包含类的数量、train.txt、test.txt、obj.names的路径和权重。</p><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="f161" class="jp jq hi lv b fi lz ma l mb mc">classes= 2<br/>train = build/darknet/x64/data/train.txt<br/>valid = build/darknet/x64/data/test.txt<br/>names = build/darknet/x64/data/obj.names<br/>backup = build/darknet/x64/backup/</span></pre><p id="bf9d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后一步，下载卷积层的预训练权值并放入目录<code class="du mg mh mi lv b">build\darknet\x64</code>。我们正在使用<em class="lf"> yolov4-custom.cfg </em>因此，下载<a class="ae jo" href="https://drive.google.com/open?id=1JKF-bdIklxOOVy-2Cr5qdvjgGpmGfcbp" rel="noopener ugc nofollow" target="_blank"> yolov4.conv.137 </a>对于Yolo的其他配置或版本，请相应地下载权重。</p><p id="987b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf">提示:</em> </strong>假设您只想检测COCO数据中出现的4个类别——人、笔记本电脑、冰箱、电视，首先分别编辑配置，然后使用<a class="ae jo" href="https://github.com/AlexeyAB/darknet#pre-trained-models" rel="noopener ugc nofollow" target="_blank">预训练权重</a>进行训练。由于权重是从由您的4个类组成的训练MS COCO数据集获得的，您不需要再次收集数据，只需为每个类标注大约10张图像并训练它。瞧，目标探测器准备好了！</p><p id="0a2b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf"> 3。训练</em></strong>——现在我们已经有了所有的文件，让我们开始训练吧！</p><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="e685" class="jp jq hi lv b fi lz ma l mb mc">./darknet detector train build/darknet/x64/data/obj.data build/darknet/x64/cfg/yolo-obj.cfg build/darknet/x64/yolov4.conv.137 -dont_show</span></pre><p id="a749" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练完成后，每100次迭代的权重将保存为<code class="du mg mh mi lv b">yolo-obj_last.weights</code>,每1000次迭代的权重将保存为<code class="du mg mh mi lv b">yolo-obj_xxxx.weights</code>,保存在<code class="du mg mh mi lv b">build\darknet\x64\backup</code>目录中</p><p id="8f93" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">继续训练，直到损失达到一定的阈值。1000次迭代后我就不再训练了。</p><p id="e7b3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf">提示:</em> </strong> <em class="lf">在</em><strong class="is hj"><em class="lf"/></strong><code class="du mg mh mi lv b"><em class="lf">yolo-obj.cfg</em></code><em class="lf">文件中把flag随机设置为1，它会通过训练Yolo来提高不同分辨率的精度。您可以随时提高网络分辨率以获得更好的性能。(如果遇到内存不足的错误，只需将细分参数增加到更高的值)</em></p><p id="149b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf"> 4。检测— </em> </strong>您可以对视频文件或图像运行检测。</p><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="0c16" class="jp jq hi lv b fi lz ma l mb mc">./darknet detector demo build/darknet/x64/data/obj.data build/darknet/x64/cfg/yolo-obj.cfg build/darknet/x64/backup/yolo-obj_1000.weights build/darknet/x64/data/peralta_holt_mumps.mp4 -out_filename result.avi -ext_output -dont_show</span></pre><p id="64db" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面的命令是对将要保存为<em class="lf"> result.avi </em>的视频执行对象检测。要对图像进行测试，运行下面的命令。你可以在这里看到结果<a class="ae jo" href="#67f5" rel="noopener ugc nofollow"/>。</p><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="0311" class="jp jq hi lv b fi lz ma l mb mc">./darknet detector test build/darknet/x64/data/obj.data build/darknet/x64/cfg/yolo-obj.cfg build/darknet/x64/backup/yolo-obj_1000.weights test.jpg -dont_Show</span></pre><p id="8c3a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您还可以为实时提要实现这种检测</p><pre class="kq kr ks kt fd lu lv lw lx aw ly bi"><span id="6604" class="jp jq hi lv b fi lz ma l mb mc">./darknet detector demo build/darknet/x64/data/obj.data build/darknet/x64/cfg/yolo-obj.cfg build/darknet/x64/backup/yolo-obj_1000.weights -c 0</span></pre><p id="9060" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lf">提示:</em> </strong> <em class="lf">经过训练提升性能后，将</em> <code class="du mg mh mi lv b"><em class="lf">yolo-obj.cfg</em></code> <em class="lf">中的网络分辨率提高到608x608或832 x832——这使得检测小物体成为可能。</em></p><p id="d09a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个项目可以帮助组织监控人们是否在入口处戴口罩。未来，我计划通过实现一个即使戴着面具也能工作的人脸识别系统来进一步改进这一想法。</p><p id="1cfa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我很高兴在新冠肺炎造成的这些不幸时期为社会做贡献。如果您在收集数据时遇到任何错误或问题，请联系我，我很乐意帮助您。</p><h2 id="93eb" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">参考</h2><p id="2ca3" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">如果您想深入了解YOLOv4的新特性，请参考以下文章。</p><ol class=""><li id="4e2c" class="lg lh hi is b it iu ix iy jb li jf lj jj lk jn mf lm ln lo bi translated"><a class="ae jo" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexeyAB/darknet</a></li><li id="6d2b" class="lg lh hi is b it lp ix lq jb lr jf ls jj lt jn mf lm ln lo bi translated"><a class="ae jo" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2004.10934</a></li><li id="a67b" class="lg lh hi is b it lp ix lq jb lr jf ls jj lt jn mf lm ln lo bi translated"><a class="ae jo" rel="noopener" href="/@jonathan_hui/yolov4-c9901eaa8e61">https://medium.com/@jonathan_hui/yolov4-c9901eaa8e61</a></li><li id="bc47" class="lg lh hi is b it lp ix lq jb lr jf ls jj lt jn mf lm ln lo bi translated"><a class="ae jo" href="https://towardsdatascience.com/yolo-v4-optimal-speed-accuracy-for-object-detection-79896ed47b50" rel="noopener" target="_blank">https://towards data science . com/yolo-v4-optimal-speed-accuracy-for-object-detection-79896 ed 47 b 50</a></li></ol></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h2 id="2b6b" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated"><strong class="ak">关于我:</strong></h2><p id="1ba7" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">我是新加坡国立大学的研究生，学习人工智能和机器人技术。我喜欢用数据解决日常问题！</p></div></div>    
</body>
</html>