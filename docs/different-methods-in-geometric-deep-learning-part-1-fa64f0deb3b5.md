# 几何深度学习中的不同方法

> 原文：<https://medium.com/analytics-vidhya/different-methods-in-geometric-deep-learning-part-1-fa64f0deb3b5?source=collection_archive---------1----------------------->

## 第 1 部分:这里我们开始一个系列，讨论不同网络类型的各种几何深度学习算法。

# 介绍

在这一系列故事中，我们将解释基于不同方法的不同几何深度学习(GDL)算法。从下一个故事开始，我们将为每一个算法花费一个完整的故事，并且将尽可能地跨越更多的想法。目前，计划是讨论 DeepWalk、GraphSAGE 和 NeoDTI，它们在不同方面对 GDL 都很重要。尽管如此，这个列表也可能扩大、缩小或改变。在这个故事中，我们将为下一个故事奠定基础，并定义一些术语。因此，如果你已经熟悉几何深度学习，请随意跳到下一个故事。

[](/analytics-vidhya/an-intuitive-explanation-of-deepwalk-84177f7f2b72) [## 对 DeepWalk 的直观解释

### 网络上的机器学习有明显的优势。在这个故事中，我们讨论 DeepWalk 来学习节点嵌入。

medium.com](/analytics-vidhya/an-intuitive-explanation-of-deepwalk-84177f7f2b72) 

# 动机

机器学习(ML)是在给定一组观察值的情况下进行预测的艺术。观察可以是各种形式，例如文本、图像、视频，并且可以具有明确的标签，例如主题、类别、注释等等。深度学习(DL)是最近出现的 ML 的子领域，主要集中在神经网络上。DL 算法比传统的 ML 算法更复杂，可以利用数据中微妙和间接的关系。DL 模型捕捉了这些关系，提高了大量任务的性能。

在大多数 ML&DL 应用程序中，观察是相互独立处理的。例如，在图像标记问题中，每个图像被视为一个单独的实例，并且实例不共享任何信息。尽管独立性假设适用于各种各样的问题，但观测值之间可以有不同类型的关系或相互作用。利用这些交互意味着向模型提供丰富的信息，并捕获否则无法捕获的关系。鉴于 DL 的改进是由于捕捉到了微妙的交互，显式地表示交互也有助于对性能建模。

为了表示输入实例之间的复杂交互，我们需要一个比将所有实例放在一个集合中并独立处理它们更强大的输入表示方案。网络或图形是广泛使用的数据结构，用于对交互丰富的数据进行建模。

# 网络

网络由代表实体的*节点*和代表实体间关系或互动的*边*组成。他们的建模范围包括但不限于道路、文本、社交平台、蛋白质-蛋白质和蛋白质-药物相互作用。现在让我们一步一步地构建一个示例引用网络。

在引用网络中，实体就是论文。因此，我们可以用一个节点来模拟每篇论文。如果一篇论文引用了另一篇，我们可以在两个节点之间插入边。从下面的例子中，我们可以推断论文 A 和 B 有引用关系，而 A 和 D 是不相交的作品。

![](img/2614675139a37d2d23d24c85b2d95dc1.png)

每个节点是一篇论文，每个边对应一个引文。

我们可以通过向节点或边添加特征来丰富模型。对于引用网络，我们可以使用每个文档的分布式表示或任何其他特征作为节点特征，并将更多信息合并到我们的表示中。在下一个模式中，我们可以看到与其分布式表示相关联的每个文档。

![](img/578020082a75f5adb07c768696b7a1a2.png)

我们可以用外部信息丰富节点。

到目前为止，我们已经看到了如何用实例的特性和内部交互来建模实例。然而，监督机器学习的不可或缺的组成部分仍然缺失:标签！对于引用网络，论文主题可以被视为标签，我们可以将它们作为节点标签集成到我们的模型中。下面我们可以看到每篇论文都根据主题进行了着色。我们可以推断论文 A、B 和 C 是同一主题，而 D 和 E 是不同主题的成员。

![](img/1854db5dd3d9e2d7b1134302c5ccf5bf.png)

我们可以将每个节点与标签相关联。

我们已经提到了如何表示特征，以及实例的标签和它们之间的交互。尽管与集合表示相比，表示实例之间的交互已经赋予了我们更多的能力，但是我们还可以做得更多，并向我们的模型中引入不同类型的实体。举例来说，我们可以将作者添加为不同于论文的节点类型，并将作者链接到以前合作创作过作品的作者。此外，如果作者是论文的作者，我们可以将作者链接到论文。

具有多个实体和/或交互类型的网络称为*异构网络，*而具有单一实体和交互类型的网络称为*同构网络。*下面我们可以看到一个由作者和论文组成的异构引用网络。我们可以推断出 Bob 和 Alice 以前曾合著过一篇论文，Bob 是论文 a 的作者。请注意，为了简洁起见，该图既不包含一个作者的所有论文，也不包含一篇论文的所有作者。出于同样的目的，分布式表示也是隐藏的。

![](img/4807b934d026d6172dbfc2abdba830da.png)

我们可以在网络中引入不同的实体和关系类型。每种关系类型都用不同的颜色强调。

这里我们应该注意不同节点标签和实体类型的区别。标签是同一类型的实例的类别。尽管两份报纸的标签不同，但它们有着相同的本质:作为一份报纸。另一方面，作者和论文是两个独立的概念，具有不同的交互类型、特征等。

# 几何深度学习

几何深度学习(GDL)是一个发展中的领域，专注于开发显式利用输入网络结构的神经网络。这种神经网络被称为*图神经网络*并吸引了巨大的关注。下图显示了*图形神经网络*是 ICLR 2020 年提交中最受欢迎的关键词。注意 ICLR 是 DL 的顶级会议之一。

![](img/a4c52e7b374247da3d4405d87ef7b606.png)

ICLR 提案中关键字用法的变化[1]。

有了这样一个强大的建模技术，我们可以直接在网络上和 GDL 的引擎盖下定义四个广泛的任务。

**节点分类**

在引用网络的例子中，每个节点可以与一个标签相关联。在节点分类中，目标是在已知标签的情况下预测未知标签。虽然这个问题可以通过将每个节点视为具有显式标签的独立实例、基于网络的公式以及图形神经网络来进行公式化，但是我们可以利用网络结构并在节点之间共享信息。

一个示例用例是在引用网络中给定论文的参考文献和引用，用主题来标记论文。

**链接预测**

链路或边是网络的核心组成部分。在链路预测中，目标是预测两个节点之间是否可能存在链路，即使没有声明。请注意，这个问题也可以公式化为一个二元分类任务，然而这不会让利用网络结构。

作为一个示例用例，我们可以陈述社交网络中的朋友推荐。将用户表示为节点，将友谊表示为节点之间的链接，链接预测对应于预测两个用户是否可以成为朋友。

**节点聚类**

节点集群是我们熟悉的集群的网络对应物。节点聚类的目的是根据预定义的相似性度量对相似的节点进行分组。节点聚类可用于社交平台中的社区检测或引用网络中的论文聚类。

**网络分类**

这项任务不同于以前的任务，因为它是在多个网络上定义的，而不是在单个网络上定义的。在网络分类中，目标是根据已知的图标签匹配将每个网络与一个标签相关联。

我们可以使用网络分类将分子映射到化学性质，其中我们将每个分子建模为一个独立的网络，原子是节点，键是边。在这种情况下，我们可以通过很少或不通过实验来推断新化学品的性质。

# 结论

在这个故事中，我们介绍了几何深度学习，并讨论了它如何在各种任务中有用。我们已经使用网络来明确表示模型的输入实例之间的交互，并提出这些交互可以提高模型性能。在接下来的故事中，我们将看到从不同节点聚合信息并显式利用交互的不同方法。

## 参考

[1][https://twitter.com/prlz77/status/1178662575900368903](https://twitter.com/prlz77/status/1178662575900368903)