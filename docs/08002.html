<html>
<head>
<title>Extracting text from images using python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用python从图像中提取文本</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/extracting-text-from-images-using-python-315ed54d90e8?source=collection_archive---------10-----------------------#2020-07-14">https://medium.com/analytics-vidhya/extracting-text-from-images-using-python-315ed54d90e8?source=collection_archive---------10-----------------------#2020-07-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="3476" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">“让我们通过让每个人都可以使用人工智能来共同推动人类进步！”</p></blockquote><p id="489f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">基于图像的序列识别一直是计算机视觉领域的一个长期研究课题。在本文中，研究人员研究了场景文本识别问题，这是基于图像的序列识别中最重要和最具挑战性的任务之一。提出了一种新的神经网络结构，它将特征提取、序列建模和转录集成到一个统一的框架中。与以前的场景文本识别系统相比，所提出的体系结构具有四个显著的特性:(1)它是端到端可训练的，这与大多数现有算法的组件是单独训练和调整的不同。(2)它自然地处理任意长度的序列，不涉及字符分割或水平标度归一化。(3)它不局限于任何预定义的词典，并且在无词典和基于词典的场景文本识别任务中都取得了显著的性能。(4)它生成有效但小得多的模型，这对于真实世界的应用场景更实用。在包括IIIT-5K、街景文本和ICDAR数据集在内的标准基准上的实验表明，所提出的算法优于现有技术。此外，该算法在基于图像的乐谱识别任务中表现良好，明显验证了其通用性。</p><div class="jk jl ez fb jm jn"><a href="https://arxiv.org/abs/1507.05717" rel="noopener  ugc nofollow" target="_blank"><div class="jo ab dw"><div class="jp ab jq cl cj jr"><h2 class="bd hj fi z dy js ea eb jt ed ef hh bi translated">一种用于图像序列识别的端到端可训练神经网络及其在图像识别中的应用</h2><div class="ju l"><h3 class="bd b fi z dy js ea eb jt ed ef dx translated">基于图像的序列识别一直是计算机视觉领域的一个长期研究课题。在本文中，我们…</h3></div><div class="jv l"><p class="bd b fp z dy js ea eb jt ed ef dx translated">arxiv.org</p></div></div></div></a></div></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><h1 id="4859" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">实施</h1><p id="2ebf" class="pw-post-body-paragraph ii ij hi il b im lb io ip iq lc is it jh ld iw ix ji le ja jb jj lf je jf jg hb bi translated">我已经在Google Colab中实现了这项工作，我选择了GPU作为运行时类型，因为我必须从预训练的模型中进行预测。</p><p id="86ff" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">EasyOCR是Python中的一个库，它从图像中提取文本。这个库是由<a class="ae lg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shi%2C+B" rel="noopener ugc nofollow" target="_blank">包光石</a>、<a class="ae lg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bai%2C+X" rel="noopener ugc nofollow" target="_blank">、</a>、<a class="ae lg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+C" rel="noopener ugc nofollow" target="_blank">丛瑶</a>在2019年开发的。这是最好的和目前使用的从图像中提取文本的库。</p><p id="f327" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">为了运行EasyOCR，我们必须通过运行下面给出的命令来安装库，然后它会要求您重新启动运行时。</p><p id="23f5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">pip安装<strong class="il hj"> easyocr </strong></p><p id="63b2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">导入</strong> matplotlib.pyplot <strong class="il hj">作为</strong>PLT #这些是必需的头文件</p><p id="6b6c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">导入</strong> cv2</p><p id="c1d4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">导入</strong> easyocr</p><p id="4059" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">从</strong> pylab <strong class="il hj">导入</strong> rcParams</p><p id="f8c0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">从</strong> IPython.display <strong class="il hj">导入</strong>图像</p><p id="02c8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">rcParams['figure.figsize'] = 8，16</p><p id="1952" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">reader = easyocr。reader([' en '])#这是检测和识别的预训练模型，括号中是必须检测的文字书写的语言类型。en代表英语。预训练模型被保存到一个名为reader的变量中。</p><p id="9e5b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">image(" image . jpg ")#显示必须通过其检测文本的输入图像</p><figure class="li lj lk ll fd lm er es paragraph-image"><div class="er es lh"><img src="../Images/0b15939d81b4217800deab5b4676033b.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*70fRbIpydLrMcJtu8vJtrg.jpeg"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">输入图像</figcaption></figure><p id="33f5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">output = reader . read text(' image . jpg ')#已经将预先训练好的模型保存到一个名为reader的变量中。调用函数“readtext ”,该函数实际上获取输入图像并从该图像中读取文本。我将readtext的输出保存在一个名为output的变量中。</p><h1 id="5b72" class="kd ke hi bd kf kg lt ki kj kk lu km kn ko lv kq kr ks lw ku kv kw lx ky kz la bi translated">输出:</h1><p id="a27c" class="pw-post-body-paragraph ii ij hi il b im lb io ip iq lc is it jh ld iw ix ji le ja jb jj lf je jf jg hb bi translated">输出变量的输出#内容</p><p id="5ccf" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">[([[43，87]，[211，87]，[211，131]，[43，131]，#第一部分是边界框坐标</p><p id="2d77" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">“晚安”，#第二部分是从图中生成的文本</p><p id="e7ce" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">0.6844154000282288)] #预测或生成文本的置信度。</p></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><h1 id="a0ad" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">致谢和参考:</h1><p id="5a96" class="pw-post-body-paragraph ii ij hi il b im lb io ip iq lc is it jh ld iw ix ji le ja jb jj lf je jf jg hb bi translated">这个项目基于几篇论文/开源库的研究/代码。</p><p id="7e45" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">检测部分采用了本文中的CRAFT算法</p><div class="jk jl ez fb jm jn"><a href="https://arxiv.org/abs/1904.01941" rel="noopener  ugc nofollow" target="_blank"><div class="jo ab dw"><div class="jp ab jq cl cj jr"><h2 class="bd hj fi z dy js ea eb jt ed ef hh bi translated">用于文本检测的字符区域意识</h2><div class="ju l"><h3 class="bd b fi z dy js ea eb jt ed ef dx translated">基于神经网络的场景文本检测方法最近已经出现，并且已经显示出有希望的结果。上一个…</h3></div><div class="jv l"><p class="bd b fp z dy js ea eb jt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="945a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">识别模型是CRNN:</p><div class="jk jl ez fb jm jn"><a href="https://arxiv.org/abs/1507.05717" rel="noopener  ugc nofollow" target="_blank"><div class="jo ab dw"><div class="jp ab jq cl cj jr"><h2 class="bd hj fi z dy js ea eb jt ed ef hh bi translated">一种用于图像序列识别的端到端可训练神经网络及其在图像识别中的应用</h2><div class="ju l"><h3 class="bd b fi z dy js ea eb jt ed ef dx translated">基于图像的序列识别一直是计算机视觉领域的一个长期研究课题。在本文中，我们…</h3></div><div class="jv l"><p class="bd b fp z dy js ea eb jt ed ef dx translated">arxiv.org</p></div></div></div></a></div></div></div>    
</body>
</html>