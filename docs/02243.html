<html>
<head>
<title>Monitoring in Spark using spark.sql</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用spark.sql在Spark中进行监控</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/monitoring-in-spark-using-spark-sql-89f8c1907fa6?source=collection_archive---------14-----------------------#2019-12-07">https://medium.com/analytics-vidhya/monitoring-in-spark-using-spark-sql-89f8c1907fa6?source=collection_archive---------14-----------------------#2019-12-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e5136104d1c71fde908e07d668fefabc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3z4TujHkwlDCpRQU"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Jez Timms 在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="af6d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们通常需要了解我们的spark应用程序是如何运行的，并且我们需要收集spark指标。我们可以使用spark Monitoring以更结构化的方式查看它，而不是通过web UI查看。在这个指标中，我们将看到</p><ol class=""><li id="cabd" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">正在启动火花历史服务器。</li><li id="bd91" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">配置spark历史服务器</li><li id="4f36" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">使用Spark sql查看Spark日志</li><li id="5f63" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">使用</li></ol><p id="714b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤1:启动星火历史服务器</strong></p><p id="10b7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了激活应用程序，我们需要在SPARK_HOME/sbin下激活历史服务器</p><p id="1f0f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">。/SPARK _ HOME/sbin/start-history-server . sh如下图</strong></p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kh"><img src="../Images/dc576034969b7fc43a140aec2ac17132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kk5a5kwDohJk-ojzrmU1wg.png"/></div></div></figure><p id="02bf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤2:配置spark历史服务器</strong></p><p id="049d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在查看日志文件时，我发现spark需要/tmp/spark-events</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es km"><img src="../Images/eaeacfdc1c0f92dc803e4e786ad7ed08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cYH8qxhLuwWK9ud1v46UAQ.png"/></div></div></figure><p id="ed95" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我在hdfs中创建了目录，并重启了历史服务器</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/5141a077d111e386118b2a2cc3f4b488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QuknZLDDGGR6dfeaI9zZiQ.png"/></div></div></figure><p id="3773" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后我在<strong class="ix hj"> /SPARK_HOME/conf/ </strong>下的<strong class="ix hj"> spark-defauts.conf </strong>中添加了这个目录</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es ko"><img src="../Images/fec01611295bd2b6b1de91b026b8a50b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*A_vNbX6RSCRcHhsyIiM4FA.png"/></div></figure><p id="0d7c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我发现spark历史服务器在localhost:18080端口下监听</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/56cbbb761f903389dc7d45d220715781.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lkeMLwNqtO8AVL8cOLt4ng.png"/></div></div></figure><p id="b2fe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤3:使用Spark查看Spark日志</strong></p><p id="97e9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">运行中和完成的应用程序的事件日志可以在/tmp/spark-logs下以json格式获得。因此，我将使用spark.read.json读取该目录，如下所示，在此之前，我将确保spark.eventLog已启用并且logdir已设置</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/be834084aebeb778bfaae1d4081b8b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*h_UweP8TXN0gomLMzes1OQ.png"/></div></figure><p id="4b9d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过阅读如下所示的目录，可以找到正在运行的应用程序的各种spark指标。一些值得注意的指标包括</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/03ee9a9eba59911a3316979037c3bdd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*uxVhX6Q4jbX2dZkdCtjC4g.png"/></div></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ks"><img src="../Images/54114790e868e12561ec81c9697ef00d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_qCLo_P0UF-inWXRU-V9AA.png"/></div></div></figure><p id="2c46" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为我没有运行任何任务，所以在上面的截图中，我的大部分指标都是空的</p><p id="1b8e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">用途</strong>:</p><p id="9aa1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以用它来监控spark应用程序，并以结构化的方式对我们的工作进行详细的日志分析</p><p id="e06d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.我们可以使用该指标来读取集群利用率的应用程序指标和用户指标</p><p id="3981" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">今天就到这里吧！！:)</p><p id="857e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Github链接:<a class="ae iu" href="https://github.com/SomanathSankaran/spark_medium/tree/master/spark_csv" rel="noopener ugc nofollow" target="_blank">https://github . com/SomanathSankaran/spark _ medium/tree/master/spark _ CSV</a></p><p id="69fd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="kt">请给我发spark中我必须涉及的话题，并给我改进写作的建议:)</em> </strong></p><p id="9496" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">学习，也让别人学习！！</strong></p></div></div>    
</body>
</html>