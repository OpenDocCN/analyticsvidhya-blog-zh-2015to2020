<html>
<head>
<title>Tutorial: A quick overview of tensorflow2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">教程:tensorflow2.0 快速概述</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tutorial-a-quick-overview-of-tensorflow2-0-b28e5c6906fa?source=collection_archive---------19-----------------------#2020-08-02">https://medium.com/analytics-vidhya/tutorial-a-quick-overview-of-tensorflow2-0-b28e5c6906fa?source=collection_archive---------19-----------------------#2020-08-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii"><div class="bz dy l di"><div class="ij ik l"/></div><figcaption class="il im et er es in io bd b be z dx translated">很开心吧！</figcaption></figure><p id="b647" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi jn translated">首先，让我告诉你。这只是对 tensorflow2.0 的一个概述，我不知道你的情况，但我在开始学习时对它感到非常困惑。许多博客和教程直接从<strong class="ir hj">功能 API </strong>或<strong class="ir hj">顺序 API</strong>(Keras 框架的)<strong class="ir hj"> </strong>开始，我就想“这是什么？”，“它们之间有什么联系？”，“先学什么？”诸如此类。</p><p id="3515" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">但是不要担心，我会在拥有它之前解决你所有的困惑。嗯，很抱歉还有第三个，即<strong class="ir hj">子类化。</strong></p><blockquote class="jw jx jy"><p id="1d2d" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">不要慌！又不是火箭科学什么的！</p></blockquote><p id="7a27" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated"><strong class="ir hj">那么</strong>我们开始吧！</p><figure class="kd ke kf kg fd ii"><div class="bz dy l di"><div class="kh ik l"/></div></figure><blockquote class="jw jx jy"><p id="7f2e" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">我也是！<strong class="ir hj">兴奋</strong>嗯</p></blockquote><h1 id="6922" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">什么是张量流？</h1><p id="f3a7" class="pw-post-body-paragraph ip iq hi ir b is lg iu iv iw lh iy iz ja li jc jd je lj jg jh ji lk jk jl jm hb bi translated"><strong class="ir hj">张量流。</strong>是一个<a class="ae ll" href="https://en.wikipedia.org/wiki/Free_software" rel="noopener ugc nofollow" target="_blank">免费的</a>和<a class="ae ll" href="https://en.wikipedia.org/wiki/Open-source_software" rel="noopener ugc nofollow" target="_blank">开源的</a> <a class="ae ll" href="https://en.wikipedia.org/wiki/Library_(computing)" rel="noopener ugc nofollow" target="_blank">软件库</a>，用于<a class="ae ll" href="https://en.wikipedia.org/wiki/Dataflow_programming" rel="noopener ugc nofollow" target="_blank">数据流</a>和<a class="ae ll" href="https://en.wikipedia.org/wiki/Differentiable_programming" rel="noopener ugc nofollow" target="_blank">跨一系列任务的差异化编程</a>。它是一个符号数学库，也用于<a class="ae ll" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>应用，如<a class="ae ll" href="https://en.wikipedia.org/wiki/Neural_networks" rel="noopener ugc nofollow" target="_blank">神经网络</a>。它被用于谷歌的研究和生产。</p><blockquote class="jw jx jy"><p id="51d4" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">等一下。现在越来越理论化了，好吧！而上面的那一段，就是从维基上抄来的。</p></blockquote><p id="82bc" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">但是你知道这些技术知识也很重要。所以我会坚持下去，</p><p id="5491" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">在更技术性的方面，TensorFlow 允许你在 PC/Mac (CPU &amp; GPU)、Android、iOS 和更多地方进行计算。当然，它是由谷歌创造的，旨在给你的反向传播思考带来巨大的并行性。所有魔术背后的主要抽象是<a class="ae ll" href="https://arxiv.org/pdf/1603.04467.pdf" rel="noopener ugc nofollow" target="_blank">有状态数据流图</a>。</p><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lm"><img src="../Images/213829997058d443705e239307599cf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/0*WCdpeOLceRqWDLVW.gif"/></div><figcaption class="il im et er es in io bd b be z dx translated">你的数据在 TensorFlow 中的图表中流动</figcaption></figure><p id="c9ae" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">上图显示了在 Tensorflow 中流经图表的数据。虽然这是张量流的一个基本机制。但是现在这在 Tensorflow2.0 中被抽象了。你现在已经有了<strong class="ir hj">急切的执行</strong>。</p><blockquote class="jw jx jy"><p id="be2d" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">等一下！什么是急切执行？</p></blockquote><p id="d0a5" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">TensorFlow 的急切执行是一个命令式的编程环境，<strong class="ir hj">立即计算运算</strong> ( <em class="jz">简而言之，它允许我们以 Pythonic 方式</em>执行运算，而无需构建图形:运算返回具体值，而不是构建一个计算图形供以后运行。这使得开始使用 TensorFlow 和调试模型变得容易，并且减少了样板文件。</p><p id="55d9" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">在 Tensorflow 2.0 中，默认情况下启用急切执行。现在可以运行 TensorFlow 操作，结果会立即返回。</p><figure class="kd ke kf kg fd ii er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es lp"><img src="../Images/c2c43ede4e74fd35946e058a6a3c4349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zw5OaQyeDk2nezAw2M-rSQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">在笔记本中运行上述程序块。</figcaption></figure><blockquote class="jw jx jy"><p id="021b" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">首先，告诉你知道 NumPy 吗？对！</p><p id="6048" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">NumPy 是一个用于处理数组的 python 库。它还具有在线性代数、傅立叶变换和矩阵领域工作的功能。</p></blockquote><p id="8497" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">牢记在心。Tensorflow 也有自己的 NumPy 来处理数组。有点类似于 NumPy，但可能更有效。它叫做<strong class="ir hj">张量</strong>。</p><h1 id="8e98" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated"><strong class="ak">张量是什么？</strong></h1><p id="e7d8" class="pw-post-body-paragraph ip iq hi ir b is lg iu iv iw lh iy iz ja li jc jd je lj jg jh ji lk jk jl jm hb bi translated"><em class="jz">张量是一个类型化的多维数组。例如，一个 4-D 浮点数数组，表示一个小批量的图像，其尺寸为[批次、高度、宽度、通道]。</em></p><p id="f6d5" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">张量的基本运算，我们将在下一个博客中看到，因为这只是一个介绍性的博客。感兴趣的可以去查看<a class="ae ll" href="https://www.tensorflow.org/guide/tensor" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="kd ke kf kg fd ii"><div class="bz dy l di"><div class="lu ik l"/></div><figcaption class="il im et er es in io bd b be z dx translated">嘿，别这样！说重点</figcaption></figure><blockquote class="jw jx jy"><p id="4522" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">好吧！</p></blockquote><h1 id="ffad" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">我们先安装 Tensorflow2.0</h1><blockquote class="jw jx jy"><p id="5820" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">转到<a class="ae ll" href="https://www.tensorflow.org/install" rel="noopener ugc nofollow" target="_blank">这里</a>获得在 Mac/ Windows/ Ubantu 中安装它的详细说明。</p></blockquote><p id="6716" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">我首选的运行 tensorflow2.0 的方式是 Google Colab。它为我们提供 CPU/ GPU/ TPU 支持。在 Google Colab 中，直接导入 TensorFlow，它会返回给你最新的版本。</p><pre class="kd ke kf kg fd lv lw lx ly aw lz bi"><span id="6e11" class="ma kj hi lw b fi mb mc l md me">import tensorflow as tf<br/># you can check version with this command<br/>print(tf.__version__)</span></pre><h1 id="b49e" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">1.对于初学者</h1><p id="8df6" class="pw-post-body-paragraph ip iq hi ir b is lg iu iv iw lh iy iz ja li jc jd je lj jg jh ji lk jk jl jm hb bi translated">最好的起点是用户友好的<strong class="ir hj"> <em class="jz">顺序 API </em> </strong>。你可以通过组合积木来创建模型。运行下面的“Hello World”示例，然后访问<a class="ae ll" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank">教程</a>了解更多信息。</p><pre class="kd ke kf kg fd lv lw lx ly aw lz bi"><span id="316f" class="ma kj hi lw b fi mb mc l md me">import tensorflow as tf<br/>mnist = tf.keras.datasets.mnist<br/><br/>(x_train, y_train),(x_test, y_test) = mnist.load_data()<br/>x_train, x_test = x_train / 255.0, x_test / 255.0<br/><br/>model = tf.keras.models.Sequential([<br/>  tf.keras.layers.Flatten(input_shape=(28, 28)),<br/>  tf.keras.layers.Dense(128, activation='relu'),<br/>  tf.keras.layers.Dropout(0.2),<br/>  tf.keras.layers.Dense(10, activation='softmax')<br/>])<br/><br/>model.compile(optimizer='adam',<br/>              loss='sparse_categorical_crossentropy',<br/>              metrics=['accuracy'])<br/><br/>model.fit(x_train, y_train, epochs=5)<br/>model.evaluate(x_test, y_test)</span></pre><blockquote class="jw jx jy"><p id="02f9" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">那么什么是顺序 API 呢？</p></blockquote><p id="ecca" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">这只是<strong class="ir hj">将 Keras 层排列在彼此之上</strong>。正如你在程序中看到的，首先，我们从<strong class="ir hj"> tf.keras </strong>中定义了顺序模型。现在有了它的帮助，我们可以安排层次。因此，第一层是展平层，它采用(28 X 28)的形状输入，并将其展平为(1 X 784)的形状。稍后，第一层将处理后的输入传递给下一层，即具有 128 个单元的密集层，这些单元具有 ReLu 激活。最后一个密集层输出 shape (1 X 10)的输出。你可以在这里了解更多<a class="ae ll" href="https://github.com/tejassathe117/TF2.0/blob/master/TF%20Fundamentals/k1.theSequentialModel.ipynb" rel="noopener ugc nofollow" target="_blank">，在这里</a>了解更多<a class="ae ll" href="https://www.tensorflow.org/guide/keras/sequential_model" rel="noopener ugc nofollow" target="_blank">。</a></p><blockquote class="jw jx jy"><p id="be60" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">简单来说，顺序 API 的意思是“用预制的墙和屋顶建造木屋”。我们只是把它放在一起。”</p></blockquote><p id="417b" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">我已经写了非常简单的关于顺序 API 的教程。看看这里的<a class="ae ll" rel="noopener" href="/@tejassathe117/tutorial-a-detailed-notebook-on-keras-sequential-api-tensorflow-2-0-30480ca8ea73"/>。</p><h1 id="81ac" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">2.对于专家来说</h1><p id="f055" class="pw-post-body-paragraph ip iq hi ir b is lg iu iv iw lh iy iz ja li jc jd je lj jg jh ji lk jk jl jm hb bi translated"><strong class="ir hj"> <em class="jz">子类化 API </em> </strong>为高级研究提供了一个由运行定义的接口。为您的模型创建一个类，然后强制性地编写正向传递。轻松创作自定义层、激活和训练循环。运行下面的“Hello World”示例，然后访问<a class="ae ll" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank">教程</a>了解更多信息。</p><pre class="kd ke kf kg fd lv lw lx ly aw lz bi"><span id="3e09" class="ma kj hi lw b fi mb mc l md me">class MyModel(tf.keras.Model):<br/>  def __init__(self):<br/>    super(MyModel, self).__init__()<br/>    self.conv1 = Conv2D(32, 3, activation='relu')<br/>    self.flatten = Flatten()<br/>    self.d1 = Dense(128, activation='relu')<br/>    self.d2 = Dense(10, activation='softmax')</span><span id="0dce" class="ma kj hi lw b fi mf mc l md me">  def call(self, x):<br/>    x = self.conv1(x)<br/>    x = self.flatten(x)<br/>    x = self.d1(x)<br/>    return self.d2(x)<br/>model = MyModel()</span><span id="6fc7" class="ma kj hi lw b fi mf mc l md me">with tf.GradientTape() as tape:<br/>  logits = model(images)<br/>  loss_value = loss(logits, labels)<br/>grads = tape.gradient(loss_value, model.trainable_variables)<br/>optimizer.apply_gradients(zip(grads, model.trainable_variables))</span></pre><blockquote class="jw jx jy"><p id="870a" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated"><strong class="ir hj">那么什么是 API 的子类化呢？</strong></p></blockquote><p id="9431" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">它只是从废料中制造一切。我们可以借助预定义的结构 Keras 模型和 Keras 层类。Keras 模型和 Keras 层都有明确定义的结构。你可以在这里了解更多<a class="ae ll" href="https://github.com/tejassathe117/TF2.0/blob/master/TF%20Fundamentals/k4.subClassing.ipynb" rel="noopener ugc nofollow" target="_blank">，在这里</a>了解更多<a class="ae ll" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models" rel="noopener ugc nofollow" target="_blank">。</a></p><blockquote class="jw jx jy"><p id="1949" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">简单来说，对 API 进行子类化意味着“从砍树开始建造木屋，然后用木头切割出墙壁和屋顶的形状。然后把它们组合在一起。”</p></blockquote><h1 id="b769" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">我们现在完成了吗？</h1><figure class="kd ke kf kg fd ii"><div class="bz dy l di"><div class="mg ik l"/></div><figcaption class="il im et er es in io bd b be z dx translated">不要。</figcaption></figure><blockquote class="jw jx jy"><p id="9df2" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">还有一种左功能 API</p></blockquote><h1 id="1ee7" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">功能 API</h1><p id="95ba" class="pw-post-body-paragraph ip iq hi ir b is lg iu iv iw lh iy iz ja li jc jd je lj jg jh ji lk jk jl jm hb bi translated">Keras <strong class="ir hj"> <em class="jz">功能 API </em> </strong>是一种创建比<code class="du mh mi mj lw b"><a class="ae ll" href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential" rel="noopener ugc nofollow" target="_blank">tf.keras.Sequential</a></code> API 更灵活的模型的方法。功能 API 可以处理具有非线性拓扑的模型、具有共享层的模型以及具有多个输入或输出的模型。</p><p id="897d" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">深度学习模型的主要思想通常是层的有向无环图(DAG)。因此，函数式 API 是一种构建层的<em class="jz">图的方式。</em></p><pre class="kd ke kf kg fd lv lw lx ly aw lz bi"><span id="8cf6" class="ma kj hi lw b fi mb mc l md me">dense = layers.Dense(64, activation="relu")<br/>x = dense(inputs)<br/>x = layers.Dense(64, activation="relu")(x)<br/>outputs = layers.Dense(10)(x)<br/>model= keras.Model(inputs=inputs,outputs=outputs,name="mnist_model")<br/>model.summary()</span></pre><blockquote class="jw jx jy"><p id="1f9d" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated"><strong class="ir hj">那么什么是函数式 API 呢？</strong></p></blockquote><p id="ce9b" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">只是排列不同的 Keras 层。您可以在不同的地方和不同的模型中重用已经定义的层。这里可以了解更多<a class="ae ll" href="https://github.com/tejassathe117/TF2.0/blob/master/TF%20Fundamentals/k2.theFunctionApi.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a><a class="ae ll" href="https://www.tensorflow.org/guide/keras/functional" rel="noopener ugc nofollow" target="_blank">可以了解更多</a>。</p><blockquote class="jw jx jy"><p id="ccf8" class="ip iq jz ir b is it iu iv iw ix iy iz ka jb jc jd kb jf jg jh kc jj jk jl jm hb bi translated">简单来说，功能 API 意味着“建造两层楼的房子”。正如我们所知，我们使用地下房屋的屋顶作为上层房屋的地板”</p></blockquote><h1 id="63d0" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">到目前为止我们所做的</h1><p id="814e" class="pw-post-body-paragraph ip iq hi ir b is lg iu iv iw lh iy iz ja li jc jd je lj jg jh ji lk jk jl jm hb bi translated">最重要的是，你知道一点张量流。以及<strong class="ir hj"> tensorflow.keras </strong>中不同类型的 API。接下来——用一个真实的例子详细解释顺序 API。</p><h1 id="227f" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">参考</h1><ul class=""><li id="83fc" class="mk ml hi ir b is lg iw lh ja mm je mn ji mo jm mp mq mr ms bi translated"><a class="ae ll" href="https://www.tensorflow.org/learn" rel="noopener ugc nofollow" target="_blank">了解 TensorFlow </a></li><li id="abc3" class="mk ml hi ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated"><a class="ae ll" href="https://github.com/tejassathe117/TF2.0" rel="noopener ugc nofollow" target="_blank">Tejas Sathe 的 GitHub</a></li><li id="e52f" class="mk ml hi ir b is mt iw mu ja mv je mw ji mx jm mp mq mr ms bi translated"><a class="ae ll" href="https://en.wikipedia.org/wiki/TensorFlow" rel="noopener ugc nofollow" target="_blank">张量流的维基百科</a></li></ul></div></div>    
</body>
</html>