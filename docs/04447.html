<html>
<head>
<title>Beginner’s guide to optimize Linear Regression models.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优化线性回归模型初学者指南。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/beginners-guide-to-optimize-linear-regression-models-41272e6b5d91?source=collection_archive---------1-----------------------#2020-03-20">https://medium.com/analytics-vidhya/beginners-guide-to-optimize-linear-regression-models-41272e6b5d91?source=collection_archive---------1-----------------------#2020-03-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b5e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归是机器学习问题中使用最广泛的统计工具之一。对于那些不熟悉什么是线性回归模型的人；线性回归是一种对一个<strong class="ih hj">因变量</strong>和几个不同的<strong class="ih hj">自变量</strong>之间的关系进行建模的方法。简而言之，借助一个或多个已知变量来预测未知变量是很困难的。但是，本文主要讨论如何创建一个线性回归模型，该模型不会过度拟合，能够很好地概括训练数据，同时计算效率也很高。</p><p id="371b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">读者可能会想为什么这值得深思。如果线性回归过度概括或过度拟合，其输入依赖于线性回归的输出的大型机器学习模型的可靠性可能存在合理的缺陷。更糟糕的是，线性回归模型的计算费用<strong class="ih hj">随着<strong class="ih hj">解释变量</strong>(用于预测的变量)的增加而增加</strong>。要快速了解线性回归方程，请参见下图。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/571d5564a7c6125068c5013fc5c1112f.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*8IF8XumCJY5vfcl5IS0y9w.jpeg"/></div></figure><p id="465e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设可用的数据集包含数百个不同的特征和相应的目标值来训练我们的回归模型并获得系数的估计值(b0，b1，b2…).然而，在计算能力有限的情况下，不仅要选择<strong class="ih hj">合适的特征</strong>，还要估计要使用的特征的<strong class="ih hj">最佳数量</strong>的难题仍然存在。感谢内置的python库，如scikit learn和numpy，它们很容易提供回归系数的估计值。现在，我们将深入研究选择适当特征的方法，以及我们希望在回归方程中出现的特征数量。假设我们要预测的变量叫做“Y”。我们的主要目标是分别获得Y的<strong class="ih hj">相关系数</strong>和我们的每个独立变量的<strong class="ih hj">。为此，我们可以使用numpy库中的corrcoef()函数。下面给出了示例实现。这里train_set是训练数据(一个数据帧)。</strong></p><p id="2f28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在(解释变量数)中迭代x:</p><p id="c83c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">print(np.corrcoef(Y，train_set['列名']))</p><p id="ca4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出将是因变量和每个相应的自变量之间的相关系数。不熟悉相关系数的建议通过<a class="ae jl" href="https://youtu.be/bCpfd2PxBVA" rel="noopener ugc nofollow" target="_blank">环节</a>。现在列出以<strong class="ih hj">递增</strong>数量级的相关系数的变量(记住相关系数也可以是负的)。准备并预处理这些要素，使其成为回归方程的一部分。过多的独立变量将<strong class="ih hj">过度拟合</strong>训练数据，并导致不太好的回归模型。您还可以通过搜索<a class="ae jl" href="https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942" rel="noopener" target="_blank">偏差-方差权衡来深入了解过度拟合和欠拟合。对于那些熟悉但希望回忆起来的人来说，也有一个简单的图来说明偏差-方差的权衡。</a></p><div class="je jf jg jh fd ab cb"><figure class="jm ji jn jo jp jq jr paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/3dea23ebba7c02faacce6674a8fc0110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*ePMqfevdkn4GBgvsZKrCcw.png"/></div></figure><figure class="jm ji jw jo jp jq jr paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/8fd17ceb0450bba706dd577b1764116f.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*ZDWeg1VaHH84rxgwmcZ35Q.png"/></div></figure></div><p id="485e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">已经准备了足够的特征作为实际训练数据集的一部分，现在准备检查添加更多独立变量的<strong class="ih hj">是否提高了模型的准确性，并且没有过度拟合。为此我们用<strong class="ih hj">的概念解释了变异</strong>和<strong class="ih hj">未解释的</strong> <strong class="ih hj">变异</strong>。一般来说，解释的变化越好，我们模型的预测能力就越强。然而，我们应该明白，在寻求更大的预测能力时，我们往往会过度拟合我们的模型。现在让我们学习如何估计我们的回归模型的预测能力。<strong class="ih hj"> R的平方</strong>是<strong class="ih hj">解释变化量</strong>与<strong class="ih hj">总变化量</strong>的比值，其数值始终小于1。直观上，R平方表示我们模型的<strong class="ih hj">预测能力</strong>。因此，当我们添加一个独立变量作为回归模型的一部分时，它总是会增加。调整后的R-square来了。调整后的-R-square是<strong class="ih hj">不是</strong> <strong class="ih hj">总是</strong> <strong class="ih hj">递增</strong>；它就像R-square的一个修改版本，如果另一个独立变量<strong class="ih hj">的添加没有像<strong class="ih hj">预期的那样提高</strong>模型的预测能力，那么它的值<strong class="ih hj">就会减少</strong>。因此，如果在增加额外的独立变量后，调整后的R平方值降低，我们的模型并没有提高其预测的准确性。相反，它刚刚开始过度拟合训练数据集。点击了解更多关于调整后的R_square <a class="ae jl" href="https://analyticsindiamag.com/r-squared-vs-adjusted-r-squared/" rel="noopener ugc nofollow" target="_blank">的信息。可以使用下面的公式计算调整后的R平方。而R平方可以通过将预测(Y)值与实际平均值(mean(Y))的平方偏差的<strong class="ih hj">总和</strong>除以实际(Y)值与实际平均值(mean(Y))的平方偏差的<strong class="ih hj">总和</strong>来容易地计算。</a></strong></strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jx"><img src="../Images/72646548d88417acdce7bdee6f9dc672.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*rzqE8JVeqxoLobr6pg-34g.jpeg"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">p是要估计的参数的数目</figcaption></figure><p id="89e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">继续<strong class="ih hj">向模型中添加</strong>独立变量，直到你发现调整后的r平方的值最终开始<strong class="ih hj">下降</strong>。这是加入自变量会招致<strong class="ih hj">过拟合</strong>的点帖。在这里停下来，使用scikit-learn、numpy等在线性回归模型中传递<strong class="ih hj">选择的变量</strong>。这是创建回归模型背后的拟议方法，该模型不会过度拟合、概括良好且计算效率高，因为还检查了特征(独立变量)数量的存在。</p></div></div>    
</body>
</html>