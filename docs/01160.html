<html>
<head>
<title>One Hot Encoding-Method of Feature Engineering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特征工程的一种热编码方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/one-hot-encoding-method-of-feature-engineering-11cc76c4b627?source=collection_archive---------5-----------------------#2019-10-05">https://medium.com/analytics-vidhya/one-hot-encoding-method-of-feature-engineering-11cc76c4b627?source=collection_archive---------5-----------------------#2019-10-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6de5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一节中，我将描述一种将分类变量的字符串转换为数字的方法，以便我们可以使用sklearn在机器学习算法中输入这些变量。</p><p id="308e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一种热编码包括用不同的布尔变量替换分类变量，布尔变量取值为0或1，以指示该变量的某个类别/标签是否存在于该观察中。</p><p id="2361" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每一个布尔变量也被称为<strong class="ih hj">虚拟变量</strong>或二进制变量。</p><p id="f932" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，从带有标签“女性”和“男性”的分类变量“性别”中，我们可以生成布尔变量“女性”，如果人是女性，则取1，否则取0。我们还可以生成变量male，如果这个人是“男性”，则取1，否则取0。</p><p id="771a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">见下文:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/117d9c57589a7232db8e058d12b19c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8UkTGW2bVGtL6qb64JgKcw.png"/></div></div></figure><p id="9ecf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可能已经注意到，我们只需要两个虚拟变量中的一个来表示原始分类变量性别。这两个中的任何一个都可以，我们选择哪一个都没关系，因为它们是等价的。</p><p id="0321" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，要用2个标签对分类变量进行编码，我们需要1个哑变量。</p><p id="a893" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了扩展这个概念，用k个标签编码分类变量，我们需要k-1个虚拟变量。</p><p id="c7fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们如何用熊猫来得到这个？</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jp"><img src="../Images/344d83e71f52b0fdca74045b73c90d8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3T1ueJMl80-qJBWNNZjENQ.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jp"><img src="../Images/92893a86d1fc6f037727521b8e01e641.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1INox7-k0vxa3wSkELKNbw.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jq"><img src="../Images/34faf723ebd350ec1f95d176e6b1ece2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OIbOtWgGuB6yXGKsZO-fNA.png"/></div></div></figure><h1 id="5133" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">笔记</h1><p id="5d5f" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">熊猫和sklearn都将从一个分类变量中提供一整套虚拟变量。也就是说，它们将返回k，而不是返回k-1个二进制变量，在pandas中可以选择删除第一个二进制变量并获得k-1。</p><h1 id="dba3" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">什么时候应该用k，什么时候用k-1？</h1><p id="cdb8" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">当原始变量是二进制时，也就是说，当原始变量只有2个标签时，那么你应该创建<strong class="ih hj">一个且只有一个</strong>二进制变量。</p><p id="0ae1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当原始变量有2个以上的标签时，以下几点很重要:</p><h2 id="7e4f" class="ku js hi bd jt kv kw kx jx ky kz la kb iq lb lc kf iu ld le kj iy lf lg kn lh bi translated">一个热编码到k-1:</h2><p id="f57e" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">一种热编码成k-1个二进制变量的方法考虑到我们可以少用1个维度，仍然表示全部信息:如果在所有的二进制变量中观察值都是0，那么在最终的(去掉的)二进制变量中它一定是1。例如，对于编码为男性的变量性别，如果观察值为0，那么它必须为女性。我们不需要额外的女性变量来解释。</p><p id="5158" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归中应使用k-1个二进制变量的热编码，以保持正确的自由度数量(k-1)。线性回归在训练时可以访问所有的特征，因此可以检查整个虚拟变量集。这意味着k-1个二元变量为线性回归提供了关于(完全代表)原始分类变量的全部信息。</p><p id="9ba1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">并且对于所有在训练过程中同时查看所有特征的机器学习算法来说也是如此。例如，支持向量机和神经网络。和聚类算法。</p><h2 id="0c46" class="ku js hi bd jt kv kw kx jx ky kz la kb iq lb lc kf iu ld le kj iy lf lg kn lh bi translated">一次热编码成k个虚拟变量</h2><p id="d5e3" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">然而，基于树的模型在每次迭代中仅选择一组特征来做出决定。这是为了在每个节点分离数据。因此，最后一个类别，即在k-1个变量的一次性编码中被删除的类别，将只被那些一次使用整个二进制变量集的分割或甚至树考虑。这种情况很少发生，因为每次拆分通常使用1-3个特征来做出决定。因此，基于树的方法永远不会考虑那个被丢弃的附加标签。因此，如果分类变量将在基于树的学习算法中使用，将它编码成k个二进制变量而不是k-1个是好的实践。</p><p id="004f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，如果您计划进行特征选择，您还需要整个二元变量集(k ),以便让机器学习模型选择最具预测能力的变量。</p><p id="dfc6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们用一个热编码对分类变量重新编码的数据训练一个模型。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/7babc590e4393a5d1120b7f8ea466f95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J8gD6iX4qK_JvYKQyYx85Q.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/fc26719332cceb970bce5acdb1f47c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w89qxHuU73y783FdGbZ3pA.png"/></div></div></figure><h1 id="e2aa" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">一个热门编码:最终笔记</h1><h1 id="727b" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">优势</h1><ul class=""><li id="7fb3" class="lk ll hi ih b ii kp im kq iq lm iu ln iy lo jc lp lq lr ls bi translated">易于实施</li><li id="3a22" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated">不做假设</li><li id="3b4d" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated">保留分类变量的所有信息</li></ul><h1 id="f8ed" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">不足之处</h1><ul class=""><li id="32c5" class="lk ll hi ih b ii kp im kq iq lm iu ln iy lo jc lp lq lr ls bi translated">不添加任何可能使变量更具预测性的信息</li><li id="42a0" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated">如果变量有很多类别，那么OHE会显著增加特征空间。</li></ul><p id="174f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">见下文:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ly"><img src="../Images/6007af62cc73ed9a2d9839a39f2146b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WLmZxSzVzlU-TEZE3Bd0IQ.png"/></div></div></figure><p id="61e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们在包含148个不同标签的变量舱中执行OHE，我们将得到147个变量，而原来只有一个。如果我们有一些像这样的分类变量，我们最终会得到巨大的数据集。因此，OHE并不总是编码分类变量的最佳选择。</p><h1 id="5088" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">笔记</h1><p id="5b06" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">如果我们的数据集有一些多标签变量，我们很快就会得到有数千列或更多列的数据集。这可能会使我们的算法训练速度变慢。</p><p id="9361" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，这些虚拟变量中的许多可能彼此相似，因为两个或更多变量共享相同的1和0的组合并不罕见。</p><h1 id="acf0" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">页（page的缩写）如果你喜欢这个博客，请在下面评论:)</h1></div></div>    
</body>
</html>