<html>
<head>
<title>How to develop a speech corpus for Sinhala</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何开发僧伽罗语语音语料库</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-develop-a-speech-corpus-for-sinhala-5e2c320003f9?source=collection_archive---------13-----------------------#2020-03-15">https://medium.com/analytics-vidhya/how-to-develop-a-speech-corpus-for-sinhala-5e2c320003f9?source=collection_archive---------13-----------------------#2020-03-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/602158b4341f272e22f5bc1254b9481a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QhclDhSM-sYB056i5JATuw.jpeg"/></div></div></figure><p id="f6c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随着技术的进步，语音识别系统发挥了重要作用。为了开发一个语音识别系统，我们可以使用各种方法，包括动态时间弯曲(DTW)，隐马尔可夫模型(HMM)，语音识别工具包，如CMU斯芬克斯等。虽然有许多方法，但我们可以认为深度神经网络(DNN)模型是最有效和最流行的方法。为了训练深度神经网络(DNN)模型，我们需要一个语音语料库。语音语料库是语音数据及其相应文本转录的集合。这篇文章将向你解释，如何从头开始为僧伽罗语开发一个语音语料库🙂。</p></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><p id="958b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">主要有两种不同的方法可用于开发语音语料库，即收集现有的语音数据并手动将其转换成相应的文本，以及设计文本语料库并通过读取收集的文本来记录音频。当有足够数量的现有语音数据可用时，可以使用第一种方法。如果你想从头开始开发一个语音语料库，那么你必须采用第二种方法。所以我们先来讨论一下如何设计文本语料库。</p><p id="b2ea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要识别哪些语句必须包含在语音语料库中。然后把它们列出来。例如，我们可以将这些陈述视为:</p><ol class=""><li id="eb22" class="jv jw hi is b it iu ix iy jb jx jf jy jj jz jn ka kb kc kd bi">මේකේ ගාන කීයද</li></ol><p id="1632" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi">2. මේක පන්සීයේ කොලයක්ද කියන්න</p><p id="66e7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi">3. මේ නෝට්ටුවේ අගය කීයද</p><p id="ca0e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">之后，我们可以确定哪些独特的词包含在这些陈述中，如මේකේ、ගාන、කීයද、මේක、පන්සීයේ等。我们将为这些独特的单词开发语音语料库，语音识别系统将能够预测由这些单词组成的句子的转录。现在我们必须通过阅读每个单词来记录音频。</p><p id="0097" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有两种类型的语音识别系统，即与说话者相关的系统和与说话者无关的系统。如果你想开发一个依赖于说话者的系统，那么你可以让有限数量的参与者参与进来进行记录。另一方面，如果你想开发一个与说话者无关的系统，那么你需要让许多不同的参与者参与进来。</p><p id="6d2a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">使用Praat录制音频</strong></p><p id="1e73" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了录制音频，我们使用了一个名为“Praat”的软件。你可以从这里下载Praat for windows:http://www.fon.hum.uva.nl/praat/download_win.html</p><p id="37a2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">安装软件后，我们可以开始记录。当你打开Praat时，你需要进入新记录单声道声音。这将打开一个窗口，您需要更改所需的采样频率。通常是16000赫兹。还要确保该通道是单声道通道。保存录制的音频时，请使用“.wav”格式。</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div class="er es ke"><img src="../Images/fa9ece5f1c8df387a87f61f4bca364a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*pXpKwgH_yYvp96Pe_8xLVg.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx translated">使用Praat录制音频</figcaption></figure><p id="b55b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">整理音频Wav文件</strong></p><p id="6b7a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有各种方法来组织一个语音语料库。在这里，我使用的方法是首先由用户组织它们，然后由被记录的单词组织它们。你可以给用户唯一的id，也可以给单词一些唯一的id。可以首先根据用户ID来组织文件夹，然后在每个用户文件夹中，我们可以根据单词ID为每个单词组织不同的文件夹。id可以用来命名音频Wav文件。例如，用户可以有像01、02…这样的id，而单词可以有像104、105…这样的id。命名音频Wav文件时，您可以遵循01_104_1.wav这样的结构。您可以通过同一用户多次朗读同一单词来录制音频。然后就成了01_104_1.wav，01_104_2.wav，…从总数据集来看，2/3可以被分配为训练数据集，1/3可以被分配为验证数据集。</p><p id="b841" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">创建train_corpus.json和validation_corpus.json </strong></p><p id="8da8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在通过记录音频创建语音语料库之后，我们需要通过相应地组织这些音频的文本转录来创建文本语料库。为了完成这项任务，可以使用不同类型的文件格式。这里我使用JSON格式来创建训练和验证文本语料库。对于我正在使用的方法，要创建JSON文件，我们首先需要在每个包含音频文件ID和音频文件转录的文件夹中包含一个. txt文件。之后，我们可以使用如下的python代码段来创建。json文件。</p><pre class="kf kg kh ki fd kn ko kp kq aw kr bi"><span id="010e" class="ks kt hi ko b fi ku kv l kw kx">labels = []<br/>durations = []<br/>keys = []<br/>for group in os.listdir(data_directory):<br/>    if group.startswith('.'):<br/>        continue<br/>    speaker_path = os.path.join(data_directory, group)<br/>    for speaker in os.listdir(speaker_path):<br/>        if speaker.startswith('.'):<br/>            continue<br/>        labels_file = os.path.join(speaker_path, speaker,<br/>                                   '{}-{}.trans.txt'<br/>                                   .format(group, speaker))<br/>        for line in open(labels_file):<br/>            split = line.strip().split()<br/>            file_id = split[0]<br/>            label = ' '.join(split[1:]).lower()<br/>            audio_file = os.path.join(speaker_path, speaker,<br/>                                      file_id) + '.wav'<br/>            print(audio_file)<br/>            audio = wave.open(audio_file)<br/>            duration = float(audio.getnframes()) / audio.getframerate()<br/>            audio.close()<br/>            keys.append(audio_file)<br/>            durations.append(duration)<br/>            labels.append(label)<br/>with open(output_file, 'w') as out_file:<br/>    for i in range(len(keys)):<br/>        line = json.dumps({'key': keys[i], 'duration': durations[i],<br/>                          'text': labels[i]})<br/>        out_file.write(line + '\n')</span></pre><p id="cc74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">按照这些步骤，你可以有一个僧伽罗语的语音语料库。通过使用这些步骤，你不仅可以为任何语言开发一个语音语料库。</p></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><p id="5ed2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">开发语音语料库后，我们需要确定我们将使用什么作为神经网络模型输入层的输入。我们将使用提取的特征向量作为输入，而不是原始音频波形。在下一篇文章中，我将向您解释两种原始音频波形的特征表示技术。然后，让我们讨论使用MFCC从波形文件中提取特征😀。</p></div></div>    
</body>
</html>