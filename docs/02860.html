<html>
<head>
<title>Machine Learning Steps Explained Using Credit Card Approval Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用信用卡审批数据集解释机器学习步骤</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-steps-explained-using-credit-card-approval-dataset-b18555c48b5a?source=collection_archive---------15-----------------------#2020-01-05">https://medium.com/analytics-vidhya/machine-learning-steps-explained-using-credit-card-approval-dataset-b18555c48b5a?source=collection_archive---------15-----------------------#2020-01-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c8cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我解释了我如何处理信用卡审批数据集，以建立一个预测信用卡是否必须被批准的机器学习模型。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/9185d392a90fffaf22ca14c877f0cb19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DI0BhcEb1zfixWU9HR7leg.png"/></div></div></figure><h1 id="94b5" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">定义目标</strong></h1><p id="6d78" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">机器学习的第一步是定义问题陈述。这里，我们的目标是建立一个模型，根据用户提供的一些细节来预测信用卡是否必须被批准。</p><h1 id="12cd" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">数据采集</h1><p id="9b9b" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">现在目标很明确。现在是收集与问题陈述相关的数据的时候了，这里是信用卡批准，因此将收集年收入、经验和许多银行熟知的特征等细节。我从<a class="ae ks" href="https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/" rel="noopener ugc nofollow" target="_blank">https://archive . ics . UCI . edu/ml/machine-learning-databases/credit-screening/</a>收集数据集</p><h1 id="c3b0" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">数据清理</h1><p id="80c4" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">众所周知的事实是，数据从来不是结构化的，它总是有一些异常，如丢失值，不一致，冗余数据。一个好的机器学习模型可以用好的数据集来构建。因此，在训练模型之前，要确保数据集没有这些错误。现在观察我们的信用卡数据集，它有16列，其中最后一列是必须预测的一列。数据集的一些细节如下</p><ol class=""><li id="7115" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">标题:信用审批</li><li id="b1be" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">相关信息:该文件涉及信用卡申请。为了保护数据的机密性，所有的属性名称和值都已更改为无意义的符号。<br/>这个数据集很有趣，因为它很好地混合了<br/>属性——连续的、带有少量<br/>值的名义值，以及带有大量值的名义值。还有<br/>也有一些缺失值。</li><li id="d7bb" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">实例数量:690</li><li id="5397" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">属性数量:15 +类属性</li><li id="6cee" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">属性信息:</li></ol><p id="74fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">A1: b，a. <br/> A2:连续。<br/> A3:连续。<br/> A4: u，y，l，t. <br/> A5: g，p，gg。<br/> A6: c、d、cc、I、j、k、m、r、q、w、x、e、aa、ff。<br/> A7: v，h，bb，j，n，z，dd，ff，o. <br/> A8:连续。<br/> A9: t，f. <br/> A10: t，f. <br/> A11:连续。<br/> A12: t，f. <br/> A13: g，p，s. <br/> A14:连续。<br/> A15:连续。<br/> A16: +，-(类属性)</p><p id="2099" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.缺失属性值:<br/> 37例(5%)有一个或多个缺失值。特定属性中缺少的<br/>值是:</p><p id="9219" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a1:12<br/>A2:12<br/>A4:6<br/>A5:6<br/>A6:9<br/>A7:9<br/>A14:13</p><p id="d7f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.阶层分布<br/><br/>+:307(44.5%)<br/>-:383(55.5%)</p><p id="ac37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是关于数据集的一些可用的详细信息。</p><p id="459e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集中总共有690个实例，其中37个实例有缺失值，总共有67个缺失值，我们必须在本节中注意这些情况。</p><p id="583c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">处理缺失值的不同方法:</p><ol class=""><li id="979a" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">删除缺少值的行。</li><li id="0d8b" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">如果变量是连续的，用属性的平均值或中值替换所有缺失的值。</li><li id="5988" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">如果分类中的变量替换为该变量最常见的值</li><li id="9204" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">对于分类变量，替换变量的每个值，然后执行聚类以获得最佳数据分析。</li></ol><p id="e077" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我使用的方法是第四种，也是最好的一种，因为没有数据丢失，每个值都会有合适的结果。</p><p id="6ba5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最初使用pandas读取数据集</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="8de3" class="lm jq hi li b fi ln lo l lp lq">import pandas as pd</span><span id="a1a4" class="lm jq hi li b fi lr lo l lp lq">data = pd.read_csv(“creditcard.csv”)</span></pre><p id="71db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在确定在这个数据集中，缺失的值表示为“？”因此，检查有缺失值的行。我将所有这些行放入另一个数据框，如果发现连续变量的任何值丢失，则用该变量的平均值替换。如果发现任何分类变量丢失，则通过用连续变量的不同可能值替换来创建行。现在有机会创建重复的行，所以我从数据框中删除了重复的行。</p><p id="3544" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，丢失值被替换的行可能没有正确的输出(类)，我认为它是没有标签的数据，并使用两个聚类执行聚类算法。我使用K-Means聚类来创建聚类。幸运的是，数据能够形成没有重叠的定义良好的集群。</p><p id="3dad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应用K-均值聚类分析数据</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="0ccd" class="lm jq hi li b fi ln lo l lp lq">kmeans = KMeans(n_clusters=2)</span><span id="08c8" class="lm jq hi li b fi lr lo l lp lq">y = kmeans.fit_predict(df)</span><span id="1efe" class="lm jq hi li b fi lr lo l lp lq">df['Cluster'] = y<br/>### Run PCA on the data and reduce the dimensions in pca_num_components dimensions<br/>reduced_data = PCA(n_components=2).fit_transform(df)<br/>results = pd.DataFrame(reduced_data,columns=['pca1','pca2'])</span><span id="9c1b" class="lm jq hi li b fi lr lo l lp lq">sns.scatterplot(x="pca1", y="pca2", hue=y, data=results)<br/>plt.title('K-means Clustering with 2 dimensions')<br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/981c28699eb1759cc64b229a6db4f1ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*LaKWMOzjk6tBJEA-RUUhsw.png"/></div></figure><p id="ae93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在预测了丢失值被更新的行的输出</p><h1 id="2f2b" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">探索性数据分析</h1><p id="7728" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">这是机器学习中非常重要的一步，你必须成为一名侦探，观察数据中的一些模式，在此基础上，你必须找到适合当前数据的算法。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="a48c" class="lm jq hi li b fi ln lo l lp lq">#importing packages<br/>import scipy.stats as stats<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import pandas as pd<br/>plt.style.use('ggplot')</span></pre><p id="4fe1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更新后的数据集中存在的行和列(没有缺失值的数据集)</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="3aed" class="lm jq hi li b fi ln lo l lp lq">#shape<br/>print('This data frame has {} rows and {} columns.'.format(data.shape[0], data.shape[1]))</span></pre><p id="572d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们来看一个数据样本，以了解数据的情况</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="c004" class="lm jq hi li b fi ln lo l lp lq">data.sample(5)</span></pre><p id="fef9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要了解每个属性及其数据类型</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="02a6" class="lm jq hi li b fi ln lo l lp lq">data.info()</span></pre><p id="1822" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在根据批准和未批准的实例数量绘制数据</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="d734" class="lm jq hi li b fi ln lo l lp lq">plt.figure(figsize=(8,6))<br/>sns.barplot(x=counts.index, y=counts)<br/>plt.title('Count of approved vs. Not approved Credit cards')<br/>plt.ylabel('Count')<br/>plt.xlabel('Class (+:approved, -:Not approved)')</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lt"><img src="../Images/a42ef5e1336d32598ce0a39a799af19c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*hBanLPw7Zx0FVy05bkLgZQ.png"/></div></figure><p id="70c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以发现没有被批准的卡变少了。</p><p id="9c45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在观察连续变量之间的相关性。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="c398" class="lm jq hi li b fi ln lo l lp lq">#heatmap<br/>corr = data.corr()<br/>plt.figure(figsize=(12,10))<br/>heat = sns.heatmap(data=corr)<br/>plt.title('Heatmap of Correlation')</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lu"><img src="../Images/f31f6e8d7187364c613d82ef29df7507.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*6Kz9JHKSExu7SlbStqV8DA.png"/></div></figure><p id="62d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果一个变量是分类的，我们就不能处理它，因为算法可以理解有数字数据的数据。所以分类变量必须转换成数字。</p><p id="410f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，它将增加数据集的大小，因为它为分类数据中的每个值创建新列，现在16列将变成47列。</p><p id="a570" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在将数据分为训练和测试，从中创建一个子样本。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="98e5" class="lm jq hi li b fi ln lo l lp lq">splittig the data into train and test<br/>#manual train test split using numpy's random.rand<br/>mask = np.random.rand(len(X)) &lt; 0.9<br/>train = X[mask]<br/>test = X[~mask]<br/>print('Train Shape: {}\nTest Shape: {}'.format(train.shape, test.shape))</span><span id="d78c" class="lm jq hi li b fi lr lo l lp lq">no_of_notapprov = train.A16.value_counts()[0]<br/>not_approv = train[train['A16'] == 0]<br/>approv = train[train['A16'] == 1]<br/>selected = approv.sample(no_of_notapprov)<br/>subsample = pd.concat([selected, not_approv])<br/>len(subsample)</span></pre><p id="04f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在寻找子样本中的数据。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="5185" class="lm jq hi li b fi ln lo l lp lq">#shuffling our data set<br/>subsample = subsample.sample(frac=1).reset_index(drop=True)<br/>subsample.head(10)</span></pre><p id="21d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建子样本是为了使两个类别分布相等。在子样本中，批准和未批准的实例数量相等。现在我们可以进行分析了</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="c75e" class="lm jq hi li b fi ln lo l lp lq">new_counts = subsample.A16.value_counts()<br/>plt.figure(figsize=(8,6))<br/>sns.barplot(x=new_counts.index, y=new_counts)<br/>plt.title(‘Count of Approved vs. Not-Approved CreditCards In Subsample’)<br/>plt.ylabel(‘Count’)<br/>plt.xlabel(‘Class (0:Not-Approved, 1:Approved)’)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/7f386144d4fc4b2dc0a9ab890c1f7171.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*Tw4M3N397u35wD4dAOCrTQ.png"/></div></figure><p id="1320" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在执行T-SNE来降低数据的维度。在这里，数据维度减少到2。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="935b" class="lm jq hi li b fi ln lo l lp lq">from sklearn.manifold import TSNE</span><span id="fb66" class="lm jq hi li b fi lr lo l lp lq">x = X.drop('A16', axis=1)<br/>y = X['A16']<br/>X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(x.values)<br/>import matplotlib.patches as mpatches</span><span id="73b2" class="lm jq hi li b fi lr lo l lp lq">f, ax = plt.subplots(figsize=(24,16))</span><span id="2f56" class="lm jq hi li b fi lr lo l lp lq">blue_patch = mpatches.Patch(color='#0A0AFF', label='Approved')<br/>red_patch = mpatches.Patch(color='#AF0000', label='Not Approved')</span><span id="bd1e" class="lm jq hi li b fi lr lo l lp lq">ax.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Approved', linewidths=2)<br/>ax.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='Not Approved', linewidths=2)<br/>ax.set_title('t-SNE', fontsize=14)</span><span id="a262" class="lm jq hi li b fi lr lo l lp lq">ax.grid(True)</span><span id="4942" class="lm jq hi li b fi lr lo l lp lq">ax.legend(handles=[blue_patch, red_patch])</span></pre><h1 id="caad" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">构建模型</h1><p id="9f4b" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">这一步之后必须进行交叉验证，评估不同算法的准确性，并从中选择最佳算法。首先，我们必须确定这是哪种类型的问题，这显然是分类问题，因为我们必须预测输出属于哪个类别(批准或不批准)。评估分类算法的性能，如逻辑回归、SVM、决策树、随机森林、第k个最近邻。</p><p id="c3fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为这里的数据是线性可分的，SVM给出了最好的准确性。用支持向量机算法训练数据。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="7a4a" class="lm jq hi li b fi ln lo l lp lq">from sklearn.preprocessing import StandardScaler, scale<br/>from sklearn.svm import LinearSVC<br/>from sklearn.metrics import confusion_matrix</span><span id="6c22" class="lm jq hi li b fi lr lo l lp lq">from sklearn.svm import SVC<br/>svclassifier = SVC(kernel='linear')<br/>svclassifier.fit(X_train, y_train)</span></pre><h1 id="8624" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">预测产量</h1><p id="ac75" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">现在模型构建已经完成，是时候预测结果并在测试数据集上检查模型的准确性了。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="294b" class="lm jq hi li b fi ln lo l lp lq">y_pred = svclassifier.predict(X_test)<br/>from sklearn.metrics import classification_report, confusion_matrix<br/>print(confusion_matrix(y_test,y_pred))<br/>print(classification_report(y_test,y_pred))</span></pre><p id="756f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，使用混淆矩阵评估模型性能。如果模型性能不佳，我们可以采用不同的方法，如改变算法的参数、增加数据集的大小、交叉验证。</p></div></div>    
</body>
</html>