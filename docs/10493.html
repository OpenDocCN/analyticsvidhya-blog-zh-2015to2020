<html>
<head>
<title>ResNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">雷斯内特</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c?source=collection_archive---------2-----------------------#2020-10-21">https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c?source=collection_archive---------2-----------------------#2020-10-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c5ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">cifar 10 上的残差神经网络</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/86ca7412aa968c68bbe98896ab751920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Qyh9Rzwp53JlDdIG.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">有时候，跳过比一个一个处理好</figcaption></figure><p id="1f2d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我之前的帖子中，我们已经讨论过了</p><ol class=""><li id="9845" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated"><a class="ae kd" rel="noopener" href="/analytics-vidhya/deep-learning-artificial-neural-network-ann-13b54c3f370f?source=your_stories_page---------------------------">深度学习——人工神经网络(ANN) </a></li><li id="b389" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><a class="ae kd" rel="noopener" href="/@arun.purakkatt/tensors-basics-of-pytorch-programming-5de82ea45ebf?source=your_stories_page---------------------------">张量 PyTorch 编程基础</a></li><li id="7247" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><a class="ae kd" rel="noopener" href="/analytics-vidhya/linear-regression-with-pytorch-147fed55f138">使用 PyTorch 进行线性回归</a></li><li id="e408" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated">【PyTorch 图像分类<em class="jd"> —逻辑回归</em> </li><li id="f2e3" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><a class="ae kd" rel="noopener" href="/analytics-vidhya/training-deep-neural-networks-on-a-gpu-with-pytorch-2851ccfb6066">用 PyTorch 在 GPU 上训练深度神经网络</a></li><li id="dfad" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><a class="ae kd" rel="noopener" href="/swlh/image-classification-with-cnn-4f2a501faadb">用 CNN 进行图像分类</a></li></ol><p id="f04b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">本文基于何等人【2】(微软研究院)</em><a class="ae kd" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank"><em class="jd"/></a>的图像识别深度残差学习</p></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><p id="9f2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">残差网络(ResNet)是一种卷积神经网络(CNN)架构，可以支持数百或更多的卷积层。ResNet 可以添加许多具有强大性能的层，而以前的体系结构每增加一层，效率就会下降。<br/> ResNet 提出了“消失梯度”问题的解决方案。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kq"><img src="../Images/4d3c61699c84c4cf2ca52e52b979320a.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*h83Qyw1nU4-xoqfRsfL7KQ.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">ResNet 块</figcaption></figure><p id="2e75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">神经网络通过反向传播来训练，反向传播依赖于梯度下降来寻找最小化损失函数的最佳权重。当增加更多层时，其导数的重复相乘最终会使梯度变得极小，这意味着增加层不会提高性能，甚至会降低性能。</p></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kr"><img src="../Images/debfb495f07b766791ec4289cefa32c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*YvhUXgT3MRoodimUAN2BTQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><a class="ae kd" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="67e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ResNet 使用“身份快捷连接”解决了这个问题，这些层最初什么也不做。在训练过程中，跳过这些相同的层，重用来自先前层的激活函数。</p><p id="4b73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将网络缩减为几层，从而加快了学习速度。当网络再次训练时，相同的层扩展并帮助网络探索更多的特征空间。</p><h2 id="af1f" class="ks kt hi bd ku kv kw kx ky kz la lb lc iq ld le lf iu lg lh li iy lj lk ll lm bi translated">内置 PyTorch ResNet 实现:</h2><p id="c48b" class="pw-post-body-paragraph if ig hi ih b ii ln ik il im lo io ip iq lp is it iu lq iw ix iy lr ja jb jc hb bi translated">PyTorch 提供了<a class="ae kd" href="https://pytorch.org/docs/stable/torchvision/models.html" rel="noopener ugc nofollow" target="_blank"> torchvision.models </a>，其中包括多个深度学习模型，在 ImageNet 数据集上进行了预训练，随时可以使用。</p><p id="8e57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">预训练让您可以利用迁移学习-一旦模型在庞大的 ImageNet 数据集上学习了许多对象、特征和纹理，您就可以将这种学习应用到您自己的图像和识别问题中。</p><p id="4845" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">torchvision.models 包括以下 ResNet 实现:ResNet-18、34、50、101 和 152(数字表示模型中的层数)，以及 Densenet-121、161、169 和 201。</p></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><h1 id="6e6a" class="ls kt hi bd ku lt lu lv ky lw lx ly lc lz ma mb lf mc md me li mf mg mh ll mi bi translated">ResNet 块</h1><p id="fb0d" class="pw-post-body-paragraph if ig hi ih b ii ln ik il im lo io ip iq lp is it iu lq iw ix iy lr ja jb jc hb bi translated">ResNet 中使用了两种主要类型的块，这主要取决于输入和输出维度是相同还是不同。</p><ul class=""><li id="0050" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc mj ka kb kc bi translated">身份块:当输入和输出激活维度相同时。</li><li id="9f86" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc mj ka kb kc bi translated">卷积块:当输入和输出激活维数彼此不同时。</li></ul><p id="a0ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，要将激活维数(HxW)减少 2 倍，可以使用步长为 2 的 1x1 卷积。</p><p id="cb9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图显示了剩余块的外观以及这些块中的内容。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mk"><img src="../Images/42fb6c0997c6661afba66d31ae8684d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XiMgGSZsNBKi4Dla.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><em class="ml">来源:</em><a class="ae kd" href="https://www.coursera.org/lecture/convolutional-neural-networks/resnets-HAhz9" rel="noopener ugc nofollow" target="_blank"><em class="ml">Coursera:Andrew NG</em></a></figcaption></figure></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><p id="b862" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第一步:准备数据集</em> </strong></p><p id="4582" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下载数据集并创建 PyTorch 数据集来加载数据。</p><p id="d1cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在创建 PyTorch 数据集时，我们将进行一些重要的更改:</p><ol class=""><li id="1a94" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated"><strong class="ih hj">使用测试集进行验证</strong>:我们将简单地使用测试集作为我们的验证集，而不是从训练集中留出一小部分(例如 10%)数据进行验证。这只是为训练提供了更多的数据。</li><li id="bc48" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><strong class="ih hj">通道式数据标准化</strong>:我们将通过减去平均值并除以每个通道的标准偏差来标准化图像张量。</li><li id="0e1c" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><strong class="ih hj">随机数据扩充</strong>:我们将在从训练数据集中加载图像时应用随机选择的变换。具体来说，我们将每个图像填充 4 个像素，然后随机裁剪大小为 32 x 32 像素的图像，然后以 50%的概率水平翻转图像。</li></ol><pre class="jf jg jh ji fd mm mn mo mp aw mq bi"><span id="a7a1" class="ks kt hi mn b fi mr ms l mt mu"><em class="jd"># Data transforms (normalization &amp; data augmentation)</em><br/>stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))<br/>train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'), <br/>                         tt.RandomHorizontalFlip(), <br/>                         tt.ToTensor(), <br/>                         tt.Normalize(*stats,inplace=True)])<br/>valid_tfms = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])</span><span id="4715" class="ks kt hi mn b fi mv ms l mt mu"><em class="jd"># PyTorch datasets</em><br/>train_ds = ImageFolder(data_dir+'/train', train_tfms)<br/>valid_ds = ImageFolder(data_dir+'/test', valid_tfms)</span></pre><p id="ce2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，创建用于批量检索图像的数据加载器。我们将使用相对较大的批量 400，以利用 GPU RAM 的较大部分。如果遇到“内存不足”的错误，您可以尝试减少批处理的大小&amp;重新启动内核。</p><pre class="jf jg jh ji fd mm mn mo mp aw mq bi"><span id="ad3d" class="ks kt hi mn b fi mr ms l mt mu">batch_size = 400</span><span id="31d7" class="ks kt hi mn b fi mv ms l mt mu"><em class="jd"># PyTorch data loaders</em><br/>train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)<br/>valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True)</span></pre><p id="449b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第二步:使用 GPU </em> </strong></p><p id="fc4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了无缝地使用 GPU，如果有可用的 GPU，我们定义了几个助手函数(<code class="du mw mx my mn b">get_default_device</code> &amp; <code class="du mw mx my mn b">to_device</code>)和一个助手类<code class="du mw mx my mn b">DeviceDataLoader</code>，以便根据需要将我们的模型&amp;数据移动到 GPU。</p><pre class="jf jg jh ji fd mm mn mo mp aw mq bi"><span id="e1c8" class="ks kt hi mn b fi mr ms l mt mu">device = get_default_device()<br/>device</span><span id="1c4c" class="ks kt hi mn b fi mv ms l mt mu">train_dl = DeviceDataLoader(train_dl, device)<br/>valid_dl = DeviceDataLoader(valid_dl, device)</span></pre><p id="28ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第三步:残留块</em> </strong></p><p id="0041" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个非常简单的剩余块</p><pre class="jf jg jh ji fd mm mn mo mp aw mq bi"><span id="62bf" class="ks kt hi mn b fi mr ms l mt mu">class <strong class="mn hj">SimpleResidualBlock</strong>(nn.Module):<br/>    def <strong class="mn hj">__init__</strong>(self):<br/>        super().__init__()<br/>        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)<br/>        self.relu1 = nn.ReLU()<br/>        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)<br/>        self.relu2 = nn.ReLU()<br/>        <br/>    def <strong class="mn hj">forward</strong>(self, x):<br/>        out = self.conv1(x)<br/>        out = self.relu1(out)<br/>        out = self.conv2(out)<br/>        return self.relu2(out) + x <em class="jd"># ReLU can be applied before or after adding the input</em></span><span id="8893" class="ks kt hi mn b fi mv ms l mt mu">simple_resnet = to_device(SimpleResidualBlock(), device)<br/><br/>for images, labels in train_dl:<br/>    out = simple_resnet(images)<br/>    print(out.shape)<br/>    break<br/>    <br/>del simple_resnet, images, labels<br/>torch.cuda.empty_cache()</span></pre><p id="2465" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我们的 resnet 架构，resnet 9</p><pre class="jf jg jh ji fd mm mn mo mp aw mq bi"><span id="8fab" class="ks kt hi mn b fi mr ms l mt mu">def <strong class="mn hj">conv_block</strong>(in_channels, out_channels, pool=False):<br/>    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), <br/>              nn.BatchNorm2d(out_channels), <br/>              nn.ReLU(inplace=True)]<br/>    if pool: layers.append(nn.MaxPool2d(2))<br/>    return nn.Sequential(*layers)<br/><br/>class <strong class="mn hj">ResNet9</strong>(ImageClassificationBase):<br/>    def <strong class="mn hj">__init__</strong>(self, in_channels, num_classes):<br/>        super().__init__()<br/>        <br/>        self.conv1 = conv_block(in_channels, 64)<br/>        self.conv2 = conv_block(64, 128, pool=True)<br/>        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))<br/>        <br/>        self.conv3 = conv_block(128, 256, pool=True)<br/>        self.conv4 = conv_block(256, 512, pool=True)<br/>        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))<br/>        <br/>        self.classifier = nn.Sequential(nn.MaxPool2d(4), <br/>                                        nn.Flatten(), <br/>                                        nn.Linear(512, num_classes))<br/>        <br/>    def <strong class="mn hj">forward</strong>(self, xb):<br/>        out = self.conv1(xb)<br/>        out = self.conv2(out)<br/>        out = self.res1(out) + out<br/>        out = self.conv3(out)<br/>        out = self.conv4(out)<br/>        out = self.res2(out) + out<br/>        out = self.classifier(out)<br/>        return out</span><span id="1d0b" class="ks kt hi mn b fi mv ms l mt mu">model = to_device(ResNet9(3, 10), device)<br/>model</span></pre><p id="c482" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第四步:训练模型</em> </strong></p><p id="f44c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们训练模型之前，我们将对我们的<code class="du mw mx my mn b">fit</code>函数做一些小而重要的改进:</p><ul class=""><li id="bc92" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc mj ka kb kc bi translated"><strong class="ih hj">学习率调度</strong>:我们不使用固定的学习率，而是使用学习率调度器，它会在每一批训练后改变学习率。在训练过程中有许多改变学习率的策略，我们将使用的一种策略称为<strong class="ih hj">“一个周期学习率策略”</strong>，它涉及从低学习率开始，在大约 30%的时期内逐批逐渐增加到高学习率，然后在剩余时期内逐渐减少到非常低的值。</li><li id="9fd3" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc mj ka kb kc bi translated"><strong class="ih hj">权重衰减</strong>:我们也使用权重衰减，这是另一种正则化技术，它通过向损失函数添加一个附加项来防止权重变得太大。</li><li id="03db" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc mj ka kb kc bi translated"><strong class="ih hj">渐变裁剪</strong>:除了层权重和输出，将渐变值限制在一个小的范围内也有助于防止由于大的渐变值而导致参数发生不希望的变化。这种简单而有效的技术被称为渐变裁剪。</li></ul><pre class="jf jg jh ji fd mm mn mo mp aw mq bi"><span id="3629" class="ks kt hi mn b fi mr ms l mt mu"><strong class="mn hj">@torch.no_grad()</strong><br/>def <strong class="mn hj">evaluate</strong>(model, val_loader):<br/>    model.eval()<br/>    outputs = [model.validation_step(batch) for batch in val_loader]<br/>    return model.validation_epoch_end(outputs)<br/><br/>def <strong class="mn hj">get_lr</strong>(optimizer):<br/>    for param_group in optimizer.param_groups:<br/>        return param_group['lr']<br/><br/>def <strong class="mn hj">fit_one_cycle</strong>(epochs, max_lr, model, train_loader, val_loader, <br/>                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):<br/>    torch.cuda.empty_cache()<br/>    history = []<br/>    <br/>    <em class="jd"># Set up cutom optimizer with weight decay</em><br/>    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)<br/>    <em class="jd"># Set up one-cycle learning rate scheduler</em><br/>    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, <br/>                                                steps_per_epoch=len(train_loader))<br/>    <br/>    for epoch in range(epochs):<br/>        <em class="jd"># Training Phase </em><br/>        model.train()<br/>        train_losses = []<br/>        lrs = []<br/>        for batch in train_loader:<br/>            loss = model.training_step(batch)<br/>            train_losses.append(loss)<br/>            loss.backward()<br/>            <br/>            <em class="jd"># Gradient clipping</em><br/>            if grad_clip: <br/>                nn.utils.clip_grad_value_(model.parameters(), grad_clip)<br/>            <br/>            optimizer.step()<br/>            optimizer.zero_grad()<br/>            <br/>            <em class="jd"># Record &amp; update learning rate</em><br/>            lrs.append(get_lr(optimizer))<br/>            sched.step()<br/>        <br/>        <em class="jd"># Validation phase</em><br/>        result = evaluate(model, val_loader)<br/>        result['train_loss'] = torch.stack(train_losses).mean().item()<br/>        result['lrs'] = lrs<br/>        model.epoch_end(epoch, result)<br/>        history.append(result)<br/>    return history</span></pre><p id="bc45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了训练我们的模型而不是 SGD(随机梯度下降),我们将使用 Adam 优化器，它使用动量和自适应学习率等技术来加快训练。</p><pre class="jf jg jh ji fd mm mn mo mp aw mq bi"><span id="1e60" class="ks kt hi mn b fi mr ms l mt mu">epochs = 8<br/>max_lr = 0.01<br/>grad_clip = 0.1<br/>weight_decay = 1e-4<br/>opt_func = torch.optim.Adam</span><span id="131a" class="ks kt hi mn b fi mv ms l mt mu">%%time<br/>history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, <br/>                             grad_clip=grad_clip, <br/>                             weight_decay=weight_decay, <br/>                             opt_func=opt_func)</span></pre><p id="951e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的模型仅用 4 分钟就训练出超过 90%的准确率！</p><p id="dd8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第五步:精度绘图</em> </strong></p><p id="111b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">绘图精度与历元数</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mz"><img src="../Images/d4f659446d5723c1027e92b608098eea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*ZKRpYw1y6aePXAJl5Mr8gQ.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">精确度与纪元数量</figcaption></figure><p id="5c03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">绘制损失与时代数。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es na"><img src="../Images/e3d1a98abfd15fd732501a1b336153c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*E3ur6KdqdwazIqMyCXLTJA.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">丢失与纪元数量</figcaption></figure><p id="60bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从趋势来看，我们的模型显然还没有过度符合训练数据。最后，让我们想象一下学习率是如何随着时间的推移而变化的，一批接一批地变化。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es nb"><img src="../Images/1af58ce3522706914f5602328c183f44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*B-upKqZYujBgmanVZL3qVQ.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">学习率与批号</figcaption></figure></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><p id="683a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请在笔记本<a class="ae kd" href="https://github.com/Arun-purakkatt/Deep_Learning_Pytorch" rel="noopener ugc nofollow" target="_blank"> <em class="jd"> Github </em> </a>上查看完整代码，在 中链接<em class="jd"> </em> <a class="ae kd" href="https://www.linkedin.com/in/arun-purakkatt-mba-m-tech-31429367/" rel="noopener ugc nofollow" target="_blank"> <em class="jd">与我保持联系。</em></a></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es nc"><img src="../Images/f581ef77bdb3784cf9141a6682d0f549.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TKl6BlSWH441e_2D.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><a class="ae kd" href="https://www.dashe.com/blog/motivation/inspiring-learning-quotes/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="1438" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">演职员表&amp;参考文献:</em> </strong></p><ol class=""><li id="e7a9" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">【https://arxiv.org/pdf/1512.03385.pdf】T5<a class="ae kd" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">T6</a></li><li id="047e" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><a class="ae kd" href="https://jovian.ml/arun-purakkatt/05b-cifar10-resnet-2009f" rel="noopener ugc nofollow" target="_blank">https://jovian.ml/arun-purakkatt/05b-cifar10-resnet-2009f</a></li><li id="8445" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><a class="ae kd" href="https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec" rel="noopener" target="_blank">https://towards data science . com/residual-blocks-building-blocks-of-resnet-FD 90 ca 15d 6 EC</a></li><li id="b1cc" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><a class="ae kd" href="https://towardsdatascience.com/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd" rel="noopener" target="_blank">https://towards data science . com/batch-normalization-and-dropout-in-neural-networks-explained-with-py torch-47d 7a 8459 BCD</a></li><li id="7944" class="ju jv hi ih b ii ke im kf iq kg iu kh iy ki jc jz ka kb kc bi translated"><a class="ae kd" href="https://ruder.io/optimizing-gradient-descent/index.html" rel="noopener ugc nofollow" target="_blank">https://ruder.io/optimizing-gradient-descent/index.html</a></li></ol></div></div>    
</body>
</html>