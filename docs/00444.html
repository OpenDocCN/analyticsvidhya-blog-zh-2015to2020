<html>
<head>
<title>Simplifying Google AI’s Best Paper at ICML 2019 on Unsupervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简化谷歌人工智能在ICML 2019年关于无监督学习的最佳论文</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/simplifying-google-ais-best-paper-at-icml-2019-on-unsupervised-learning-70694ff4a7a4?source=collection_archive---------0-----------------------#2019-06-20">https://medium.com/analytics-vidhya/simplifying-google-ais-best-paper-at-icml-2019-on-unsupervised-learning-70694ff4a7a4?source=collection_archive---------0-----------------------#2019-06-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b0752150ab0397385a06758850942e4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5cl3pKaHmEeal6rx.jpg"/></div></div></figure><h1 id="4df1" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">介绍</h1><p id="8f71" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">吸引该领域顶尖大脑的<a class="ae km" href="https://www.analyticsvidhya.com/datahack-summit-2019/?utm_source=blog&amp;utm_medium=simplifying-google-ai-best-paper-icml-2019" rel="noopener ugc nofollow" target="_blank">机器学习大会</a>全球屈指可数。一个这样的会议，我是一个狂热的追随者，是机器学习国际会议(ICML)。</p><p id="7948" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">来自顶级<a class="ae km" href="https://courses.analyticsvidhya.com/courses/applied-machine-learning-beginner-to-professional?utm_source=blog&amp;utm_medium=simplifying-google-ai-best-paper-icml-2019" rel="noopener ugc nofollow" target="_blank">机器学习</a>研究公司的人，如谷歌人工智能、脸书、优步等。一起展示他们的最新研究。这是任何数据科学家都不想错过的会议。</p><p id="8e6f" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">上周在美国南加州举行的2019年ICML奥运会上，记录以令人震惊的方式被打破。收到的论文数量和会议接受的论文数量都打破了以往的记录。看看这些数字:</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/a7d8e4036adb6f3e6e4e8a15731c1bbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2SRjl2vowjbvSUcQ.png"/></div></figure><p id="fb96" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">一个精心挑选的评委小组负责从这份名单中选出最好的论文。获得这个最佳论文奖是一个很有声望的成就——研究界的每个人都为之奋斗！</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es kx"><img src="../Images/751ddd5db65d41a8c3e1a6c14a52267b.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/0*ZIeQeFlxS3nahJEB.png"/></div></figure><p id="2db1" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">解密这些来自2019年ICML的最佳论文让我大开眼界。我喜欢浏览这些论文并分解它们，这样我们的社区也可以参与机器学习中最热门的事情。</p><p id="8d6b" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">在这篇文章中，我们将看看2019年ICML大会上谷歌人工智能的最佳论文。人们非常关注无监督学习，所以有很多东西需要解开。让我们开始吧。</p><p id="5b6d" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj"> <em class="ky">你也可以在这里查看我的文章</em></strong><a class="ae km" href="https://www.analyticsvidhya.com/blog/2019/05/best-papers-iclr-2019/" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"><em class="ky">【ICLR 2019最佳论文】</em> </strong> </a> <strong class="jq hj"> <em class="ky">。</em> </strong></p><h1 id="eb79" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2019年ICML最佳论文奖授予:</h1><p id="9bde" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们的主要关注点是谷歌人工智能团队的第一篇论文。因此，让我们看看谷歌为我们的社区提出了什么。</p><p id="62e6" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><em class="ky">注意:在深入本文之前，您应该了解某些无监督的深度学习概念。如果你需要快速复习，我建议你先浏览下面的指南:</em></p><p id="e9f1" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">让我们首先了解什么是无纠缠的表示。以下是谷歌人工智能对这一概念的简洁而简单的定义:</p><blockquote class="kz la lb"><p id="3fd5" class="jo jp ky jq b jr kn jt ju jv ko jx jy lc kp kb kc ld kq kf kg le kr kj kk kl hb bi translated">理解高维数据，并以无监督的方式将这些知识提取为有用的表示的能力，仍然是深度学习中的一个关键挑战。解决这些挑战的一种方法是通过解开表征<em class="hi">，模型捕捉给定场景的独立特征，如果一个特征发生变化，其他特征不受影响。—谷歌人工智能</em></p></blockquote><p id="a081" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">正如论文所言，在表征学习中，人们通常假设现实世界的观察<strong class="jq hj"> x，</strong>像图像或视频，是通过两步生成过程生成的:</p><ul class=""><li id="80be" class="lf lg hi jq b jr kn jv ko jz lh kd li kh lj kl lk ll lm ln bi translated">第一步包括从分布<em class="ky"> P(z) </em>中取样多元潜在随机变量<em class="ky"> z </em>。直观上，这个随机变量对应于观察值变化的语义上有意义的因素</li><li id="84ed" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">在第二步中，从条件分布<em class="ky"> P(x|z) </em>中采样观察值<em class="ky"> x </em></li></ul><p id="e611" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">换句话说，映射到高维观察空间的低维实体可以用来解释高维观察。</p><h1 id="0b0a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">本文的目的</h1><blockquote class="kz la lb"><p id="2dbf" class="jo jp ky jq b jr kn jt ju jv ko jx jy lc kp kb kc ld kq kf kg le kr kj kk kl hb bi translated"><em class="hi">本研究的目的是指出未来工作的改进领域，以使无监督的解缠结方法更好。</em></p></blockquote><p id="d6fa" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">作者发布了<strong class="jq hj">一项针对七个不同数据集的可重复的大规模实验研究，其中包括12，000个经过训练的模型，涵盖了最著名的方法和评估指标。</strong></p><p id="be2a" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">目前还没有一个被广泛接受的正式的概念。因此，关键的直觉是，一个清晰的表示应该将数据中不同的、信息丰富的因素分开。</p><h1 id="984a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">当前最先进的方法</h1><p id="b5d7" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">当前最先进的无监督解纠缠学习方法主要基于变分自动编码器(VAEs)。在潜在空间上假设一个特定的分布<em class="ky"> P(z) </em>，然后使用深度神经网络来参数化条件概率<em class="ky"> P(x|z) </em>。</p><p id="9576" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">类似地，使用变分分布<em class="ky"> Q(z|x) </em>来近似分布<em class="ky"> P(z|x) </em>。然后通过最小化负对数似然的合适近似值来训练该模型。</p><h1 id="399c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">本文对该领域的贡献</h1><p id="b31c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">谷歌人工智能研究人员已经挑战了该领域普遍持有的假设。我将他们的贡献总结如下:</p><ul class=""><li id="5fee" class="lf lg hi jq b jr kn jv ko jz lh kd li kh lj kl lk ll lm ln bi translated">当前的方法和它们的归纳偏差在一个可重复的大规模实验研究中进行了调查，该研究采用了一个用于无监督解缠结学习的合理的实验方案。研究人员:</li><li id="4fc7" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">实施了6种最新的无监督解缠结学习方法</li><li id="681c" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">从零开始创造了6个解决方法</li><li id="d39a" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">在七个不同的数据集上训练了超过12，000个模型</li><li id="827d" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">他们发布了一个新的库<strong class="jq hj">distanglement _ lib</strong>来训练和评估解开的表示。由于结果的产生需要大量的计算工作，该团队还发布了超过10，000个经过训练的模型，这些模型可以用作未来研究的基线</li></ul><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/9e0f8f521f8f01885c8c886a6045c3fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/0*WUYMDBsDDZEFp-_4.gif"/></div></figure><p id="baa5" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><em class="ky">shapes 3d数据集的地面真实因素的可视化:地板颜色(左上)、墙壁颜色(中上)、对象颜色(右上)、对象大小(左下)、对象形状(中下)和摄像机角度(右下)</em></p><ul class=""><li id="28b7" class="lf lg hi jq b jr kn jv ko jz lh kd li kh lj kl lk ll lm ln bi translated">谷歌人工智能团队考虑的所有方法都被证明是有效的，可以确保聚合后验概率(被采样)的各个维度不相关。然而，他们观察到表征的维度(取平均值)实际上是相关的</li><li id="b341" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">他们没有发现证据表明所考虑的模型可以作为随机种子以无监督的方式可靠地学习解开的表示</li><li id="fccc" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated"><strong class="jq hj">超参数似乎比模型选择更重要。</strong>此外，即使我们被允许跨数据集传递良好的超参数值，如果无法访问真实标签，训练有素的模型似乎也无法被识别</li><li id="7793" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">对于所考虑的模型和数据集，团队无法验证解开对下游任务有用的假设</li></ul><h1 id="8694" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">Google AI提出的实验设计</h1><p id="fb1b" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我从报纸本身中摘录了这一节。如果你有任何疑问，你可以在文章下面的评论区联系我，我很乐意为你解答。</p><p id="ee85" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">考虑方法</strong>:</p><p id="eb5f" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">所有考虑的方法都用某种正则化方法来增加VAE(变分自动编码器)损失。</p><ul class=""><li id="c5d6" class="lf lg hi jq b jr kn jv ko jz lh kd li kh lj kl lk ll lm ln bi translated"><strong class="jq hj"> β-VAE </strong>在普通VAEs的KL正则化子前面引入了一个超参数来限制VAE瓶颈的容量</li><li id="758f" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated"><strong class="jq hj">anneal advae</strong>逐渐增加瓶颈容量，以便编码器可以一次专注于学习一个变化因素(对小重构误差贡献最大的因素)</li><li id="de79" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated"><strong class="jq hj">因子</strong>和<strong class="jq hj"> β-TCVAE </strong>分别惩罚对抗性训练或易处理但有偏差的蒙特卡罗估计的总相关性</li><li id="08dd" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated"><strong class="jq hj">迪普-VAE-I </strong>和<strong class="jq hj">迪普-VAE-II </strong>都惩罚聚合后验概率和分解后验概率之间的不匹配</li></ul><p id="e80d" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">考虑的指标:</strong></p><ul class=""><li id="b4ff" class="lf lg hi jq b jr kn jv ko jz lh kd li kh lj kl lk ll lm ln bi translated"><strong class="jq hj"> BetaVAE </strong>度量将解缠结测量为线性分类器的准确度，该线性分类器预测固定变化因子的指数</li><li id="0ddb" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated"><strong class="jq hj">互信息间隙(MIG) </strong>为每个变化因素测量在<em class="ky"> r(x) </em>中最高和第二高坐标之间的归一化互信息间隙</li><li id="5f32" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">里奇韦&amp;莫泽尔的<strong class="jq hj">解纠缠度量计算通过标准化学习表示的每个维度的重要性获得的分布的熵，用于预测变异因子的值</strong></li></ul><p id="6141" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj">数据集:</strong></p><ul class=""><li id="a386" class="lf lg hi jq b jr kn jv ko jz lh kd li kh lj kl lk ll lm ln bi translated">在<strong class="jq hj">颜色-图案</strong>中，形状用随机颜色着色</li><li id="217d" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">在<strong class="jq hj">噪声-图像中，考虑噪声背景上的</strong>白色形状</li><li id="90c6" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">最后，在<strong class="jq hj"> Scream-dSprites </strong>中，背景被替换为随机颜色阴影中的随机补丁，该随机颜色阴影是从著名的<strong class="jq hj">Scream绘画</strong>中提取的:</li></ul><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/d3c967f2a6b02979a8b8b525cae7cb98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8yMrNyugnLhyNfj0.jpg"/></div></div></figure><p id="1feb" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><em class="ky">尖叫绘画</em></p><h1 id="4f2c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">关键实验结果</h1><p id="8d09" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这是让每个数据科学家都兴奋不已的部分！研究人员通过回答一系列问题展示了他们的成果。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/64449bfa89948fc50b51b7faab257b72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/0*9VYOLrTte1bS1Ktm.png"/></div></figure><p id="3674" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><em class="ky">基于采样(左)和平均表示(右)的拟合高斯图的总相关性，针对颜色-深度和方法(除AnnealedVAE外)的正则化强度绘制。随着正则化强度的增加，采样表示的总相关性降低，而平均表示的总相关性增加</em></p><ul class=""><li id="62dd" class="lf lg hi jq b jr kn jv ko jz lh kd li kh lj kl lk ll lm ln bi translated"><strong class="jq hj">解开指标有多一致？</strong></li><li id="9f78" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">除了模块性之外，所有的解缠结指标似乎都是相互关联的。但是，不同数据集之间的相关性水平会发生变化</li><li id="60a0" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated"><strong class="jq hj">不同的模型和超参数对解纠缠有多重要？</strong></li><li id="6223" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">无监督模型的解缠结分数受到随机性(以随机种子的形式)和超参数的选择(以正则化强度的形式)的严重影响。目标函数似乎影响较小</li></ul><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/7a25c152ce9832923a681e781704a9b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*upVARZ1j2mtVuhWp.png"/></div></div></figure><p id="e7a8" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><em class="ky">(左)Cars3D上每种方法的因子得分。模型是缩写的(0=β- VAE，1=FactorVAE，2=β-TCVAE，3 =迪普-VAE-I，4 =迪普-VAE-II，5=AnnealedVAE)。分数严重重叠。(右)Cars3D上不同正则化强度的FactorVAE模型的FactorVAE分数分布。</em></p><ul class=""><li id="9307" class="lf lg hi jq b jr kn jv ko jz lh kd li kh lj kl lk ll lm ln bi translated"><strong class="jq hj">有可靠的选型食谱吗？</strong></li><li id="8663" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">无监督模型选择仍然是一个未解决的问题。度量和数据集之间好的超参数的转移似乎不起作用，因为似乎没有无监督的方式来区分目标任务上好的和坏的随机种子</li><li id="440c" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">就学习的样本复杂性而言，这些解开的表征对下游任务有用吗？</li><li id="89c2" class="lf lg hi jq b jr lo jv lp jz lq kd lr kh ls kl lk ll lm ln bi translated">虽然本节的实证结果是负面的，但也应谨慎解读。毕竟，我们在前面的章节中已经看到，本研究中考虑的模型无法可靠地产生清晰的表示。因此，如果考虑一组不同的模型(例如，半监督或完全监督的模型)，本节中的结果可能会发生变化</li></ul><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/7971f344c8fda8e470882fa7a35063ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*VT0JBwFmYk2z7zAQ.png"/></div></div></figure><p id="a31b" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">在dSprites上学习GBT下游任务的FactorVAE分数的统计效率。</p><h1 id="a576" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结束注释</h1><p id="b31d" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">谷歌人工智能团队继续钉钉其机器学习研究。他们继续关注最新的进展，今年的机器学习国际会议。</p><p id="7bd3" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">选择的第二篇论文是基于如何在高斯过程回归中得到更好的结果，您可以通过本文提供的链接查看这篇论文。</p><p id="3bf2" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">在下面的评论区让我知道你对谷歌人工智能研究论文的看法。继续学习！</p><p id="c35f" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">你也可以在分析Vidhya的Android应用上阅读这篇文章</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/99fdf2bcee7792d4d984e89bebe58836.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/0*ySYUyqRROrxrQA5Y.png"/></div></div></figure></div><div class="ab cl lz ma gp mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="hb hc hd he hf"><p id="44f6" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><em class="ky">原载于2019年6月20日</em><a class="ae km" href="https://www.analyticsvidhya.com/blog/2019/06/simplifying-google-ai-best-paper-icml-2019/" rel="noopener ugc nofollow" target="_blank"><em class="ky">【https://www.analyticsvidhya.com</em></a><em class="ky">。</em></p></div></div>    
</body>
</html>