<html>
<head>
<title>A Practical Guide To Logistic Regression in Python for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向初学者的Python逻辑回归实用指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-practical-guide-to-logistic-regression-in-python-for-beginners-f04cf6b63d33?source=collection_archive---------2-----------------------#2020-11-10">https://medium.com/analytics-vidhya/a-practical-guide-to-logistic-regression-in-python-for-beginners-f04cf6b63d33?source=collection_archive---------2-----------------------#2020-11-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ca7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">逻辑回归的根源可以追溯到19世纪，当时比利时数学家<a class="ae jd" href="https://en.wikipedia.org/wiki/Pierre_François_Verhulst" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a>在为人口增长建模的一系列三篇论文中提出了<em class="je">逻辑函数/逻辑增长</em>。后来在1883年，威廉·奥斯特瓦尔德<a class="ae jd" href="https://en.wikipedia.org/wiki/Wilhelm_Ostwald" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a><strong class="ih hj"/>将它应用于化学中的自动催化模型。大约200年后，逻辑回归现在是各个领域中使用最广泛的统计模型之一，包括机器学习、经济学、医学等。</p><h1 id="d31e" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak"> 1.0。天啊。一些数学定义😞</strong></h1><p id="c81f" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">简而言之，逻辑回归模型使用逻辑函数:</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ki"><img src="../Images/0e0b5d6fa9ed32bf0b88f4c057c81fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*SFAzUNWgOdpKgm4sI9R0rw.png"/></div></figure><p id="8596" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将线性方程的输出压缩到0到1之间。逻辑曲线是一种常见的S形曲线，如下所示:</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es kq"><img src="../Images/69e99b38b69abfc0191c051223cd318c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnSW1b5LdpFlBx5hR54J0w.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">来源:<a class="ae jd" href="https://hvidberrrg.github.io/deep_learning/activation_functions/sigmoid_function_and_derivative.html" rel="noopener ugc nofollow" target="_blank"> hvidberrrg </a></figcaption></figure><h1 id="406f" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">2.0.重要假设🧐</h1><p id="24e6" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">在使用逻辑回归建模之前，有4个主要假设需要考虑。这些是:</p><ol class=""><li id="d033" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated"><strong class="ih hj">因变量/响应变量/目标变量必须是二元或二分变量</strong>:一个数据点必须只适合两个类别中的一个。例如，预测一个人是否有肿瘤——是(1)，否(0)。</li><li id="7fcc" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><strong class="ih hj">缺乏多重共线性</strong>:独立/预测变量之间必须很少或没有共线性，这意味着它们应该相互独立。方差膨胀因子(VIF)是可用于检查多重共线性的简单测试之一。如果一个因子的VIF分数高于5，最好是删除一个相关的独立变量以减少冗余。</li><li id="ab93" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">大样本量:和任何统计模型一样，过去的数据是稳健模型的关键。同样，样本量越大，逻辑回归分析的结果越好，越可靠。</li><li id="4195" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><strong class="ih hj">对数优势关系</strong>:自变量必须与对数优势呈线性相关。</li></ol><h1 id="85ba" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak"> 3.0。Python代码分步指南🤓</strong></h1><p id="5e5e" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">本节作为逻辑回归<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets/bank+marketing" rel="noopener ugc nofollow" target="_blank">银行营销</a>数据集实施的完整指南/教程。这个机器学习任务的目标是预测客户是否会订阅定期存款。本文使用的数据集和代码可以在这个<a class="ae jd" href="https://github.com/akbarhusnoo/Logistic-Regression-Portuguese-Bank-Marketing" rel="noopener ugc nofollow" target="_blank"> GitHub资源库</a>中找到。</p><h2 id="1156" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">I .导入库</h2><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="ff00" class="ln jg hi mc b fi mg mh l mi mj">import pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>import statsmodels<br/>import sklearn</span></pre><h2 id="6743" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">二。了解数据集</h2><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="41f7" class="ln jg hi mc b fi mg mh l mi mj">#access dataset from GitHub link<br/>url_link = '<a class="ae jd" href="https://raw.githubusercontent.com/akbarhusnoo/Logistic-Regression-Portuguese-Bank-Marketing/main/Portuguese%20Bank%20Marketing%20Dataset.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/akbarhusnoo/Logistic-Regression-Portuguese-Bank-Marketing/main/Portuguese%20Bank%20Marketing%20Dataset.csv'</a></span><span id="5e88" class="ln jg hi mc b fi mk mh l mi mj">#read file<br/>df_bank = pd.read_csv(url_link)</span><span id="1acb" class="ln jg hi mc b fi mk mh l mi mj">#display top 5 rows<br/>display(df_bank.head())</span><span id="aab6" class="ln jg hi mc b fi mk mh l mi mj">#display number of rows and columns<br/>print('\nShape of dataset = ', df_bank.shape)</span><span id="42a8" class="ln jg hi mc b fi mk mh l mi mj">#display list of attributes present in dataset<br/>print('\nList of Attributes:\n ', list(df_bank.columns))</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es ml"><img src="../Images/fdd6041b386c3ef8a659777db8fcb8c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IkJL-1baRKu2Wj5qWUeu3A.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">产出3(二)——按作者分类的图像</figcaption></figure><p id="8d8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个数据集由21个属性/列和41188条记录/行组成。年龄、工作等变量。是特性列表，而变量是y —客户是否已预订定期存款？是目标变量，1表示“是”，0表示“否”。</p><h2 id="cc66" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">三。目标变量可以用于逻辑回归吗？</h2><p id="f03b" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">是的。这是因为目标变量是<strong class="ih hj">二元/二元</strong>。</p><h2 id="614e" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">四。检查缺少的值</h2><p id="c58f" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">有几种方法可以处理数据集中缺失值造成的麻烦。在这种情况下，由于样本量足够大，如果存在缺失值，可以丢弃这些值。</p><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="f217" class="ln jg hi mc b fi mg mh l mi mj">#check if there are missing values in dataset<br/>print(df_bank.isnull().values.any())</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es mm"><img src="../Images/c419cd88b15d6900b368d5b0e52228f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xCJRarXUifXFjYJRd6ipPg.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">产出3㈣——按作者分类的图像</figcaption></figure><p id="c515" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的例子中，数据集不包含任何缺失值。</p><h2 id="83a9" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated"><strong class="ak">五、数据探索</strong></h2><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="c2dd" class="ln jg hi mc b fi mg mh l mi mj">#visualise the target variable<br/>sns.countplot(x ='y', data = df_bank)<br/>plt.show()</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es mn"><img src="../Images/2e15b1181af92777c61a935364d22831.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*v9fcaORzaHQJytM-eR01IQ.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">输出3(V) —按作者分类的图像</figcaption></figure><p id="a4a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">0级和1级极不平衡。因此，对于这个场景，准确性不是一个好的性能评估指标。</p><h2 id="eddf" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated"><strong class="ak">六。编码分类变量</strong></h2><p id="ff8c" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">使用<a class="ae jd" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" rel="noopener ugc nofollow" target="_blank">标签编码器</a>对数据集中出现的分类变量进行编码。</p><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="8c4e" class="ln jg hi mc b fi mg mh l mi mj">#label encoding for all categorical variables in dataset<br/>from sklearn.preprocessing import LabelEncoder</span><span id="c638" class="ln jg hi mc b fi mk mh l mi mj">label_encoder = LabelEncoder()<br/>df_bank['job'] = label_encoder.fit_transform(df_bank['job'])<br/>df_bank['marital'] = label_encoder.fit_transform(df_bank['marital'])<br/>df_bank['education'] = label_encoder.fit_transform(df_bank['education'])<br/>df_bank['default'] = label_encoder.fit_transform(df_bank['default'])<br/>df_bank['housing'] = label_encoder.fit_transform(df_bank['housing'])<br/>df_bank['loan'] = label_encoder.fit_transform(df_bank['loan'])<br/>df_bank['contact'] = label_encoder.fit_transform(df_bank['contact'])<br/>df_bank['month'] = label_encoder.fit_transform(df_bank['month'])<br/>df_bank['day_of_week'] = label_encoder.fit_transform(df_bank['day_of_week'])<br/>df_bank['poutcome'] = label_encoder.fit_transform(df_bank['poutcome'])</span></pre><h2 id="e15e" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">七。特征工程</h2><p id="f6e3" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated"><strong class="ih hj"> A .从整个数据集分割特征集</strong></p><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="134c" class="ln jg hi mc b fi mg mh l mi mj">#segment dataset into features set<br/>X = df_bank.loc[:, list(df_bank.columns)[0:20]]</span></pre><p id="a8f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> B .检查多重共线性</strong></p><p id="5546" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了检查自变量中的多重共线性，使用了<a class="ae jd" href="https://en.wikipedia.org/wiki/Variance_inflation_factor" rel="noopener ugc nofollow" target="_blank"> <em class="je">方差膨胀因子(VIF) </em> </a> <em class="je"> </em>技术。VIF得分为&gt; 10的变量意味着它们非常强相关。因此，它们在逻辑回归模型中被丢弃和排除。</p><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="ed58" class="ln jg hi mc b fi mg mh l mi mj">#calculate Variance Inflation Factor<br/>from statsmodels.stats.outliers_influence import variance_inflation_factor<br/>vif_scores = pd.DataFrame() <br/>vif_scores["Attribute"] = X.columns <br/>  <br/># calculating VIF for each feature <br/>vif_scores["VIF Scores"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))] <br/>  <br/>display(vif_scores)</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es mo"><img src="../Images/f6ff2cb80e42be9d90eef50b9dd86a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kgp3NCDdeEix4p2Zgdo1Wg.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">产出3(七。B) —作者提供的图片</figcaption></figure><h2 id="eb00" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">八。将数据分为训练和测试</h2><p id="6b3c" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">建议将数据分成70-30份，其中训练数据集占70%，测试数据集占30%。</p><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="67fc" class="ln jg hi mc b fi mg mh l mi mj">#segment dataset into significant features and target<br/>X = df_bank.loc[:, ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'previous']]<br/>y = df_bank['y']</span><span id="bda3" class="ln jg hi mc b fi mk mh l mi mj">#split dataset into training and testing features and targets<br/>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3)</span></pre><h2 id="eaf2" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated">九。用逻辑回归模型拟合数据</h2><p id="0b6a" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">训练数据被馈送到逻辑回归模型，用于训练后者。</p><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="a2cc" class="ln jg hi mc b fi mg mh l mi mj">#fit logistic regression model to data<br/>from sklearn.linear_model import LogisticRegression</span><span id="87a1" class="ln jg hi mc b fi mk mh l mi mj">logistic_regression_model = LogisticRegression()<br/>logistic_regression_model.fit(X_train, y_train)</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es mp"><img src="../Images/c191a6a593788e07c5ddbf6b65e8c388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sJl8BzEfKezQAv7Gbxg6NA.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">产出3(IX)——按作者分类的图像</figcaption></figure><h2 id="3168" class="ln jg hi bd jh lo lp lq jl lr ls lt jp iq lu lv jt iu lw lx jx iy ly lz kb ma bi translated"><strong class="ak">十、评价Logistic回归模型</strong></h2><p id="c2d1" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">然后将测试特征输入到逻辑回归模型中。然后，性能指标和混淆矩阵计算如下:</p><pre class="kj kk kl km fd mb mc md me aw mf bi"><span id="36af" class="ln jg hi mc b fi mg mh l mi mj">#evaluate model using test data<br/>y_predicted = logistic_regression_model.predict(X_test)<br/>display(y_predicted)</span><span id="a619" class="ln jg hi mc b fi mk mh l mi mj">#compute confusion matrix<br/>from sklearn.metrics import confusion_matrix<br/>confusion_matrix = confusion_matrix(y_test, y_predicted)<br/>print('\nThe Confusion Matrix is as follows:\n', confusion_matrix)</span><span id="7942" class="ln jg hi mc b fi mk mh l mi mj">#compute performance metrices<br/>from sklearn.metrics import precision_score<br/>from sklearn.metrics import roc_auc_score<br/>print('\nArea Under the Receiver Operating Characteristic Curve:', roc_auc_score(y_test, y_predicted))<br/>print('\nPrecision:', precision_score(y_test, y_predicted))</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es mq"><img src="../Images/2e6157a6d2d8d4049e7d2db9f607f493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-thwwfSo41-ovS4YDdJFjg.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">产出3(IX)——按作者分类的图像</figcaption></figure><p id="300e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，模型正确预测了<strong class="ih hj"> 11111 </strong> (10767+344)数据<strong class="ih hj"/>，错误预测了<strong class="ih hj"> 1246 </strong> (194+1052)数据。</p><h1 id="8860" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">4.0.参考</h1><p id="2b6b" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">[1]统计解决方案。(2013).<em class="je">什么是逻辑回归？—统计解决方案</em>。[在线]请访问:<a class="ae jd" href="https://www.statisticssolutions.com/what-is-logistic-regression/." rel="noopener ugc nofollow" target="_blank">https://www . statistics solutions . com/what-is-logistic-regression/。</a></p><p id="c11f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2]杰森·布朗利(2016)。<em class="je">用于机器学习的逻辑回归</em>。[在线]机器学习掌握。可从以下网址获得:<a class="ae jd" href="https://machinelearningmastery.com/logistic-regression-for-machine-learning/." rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/logistic-regression-for-machine-learning/。</a></p><p id="5b24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[3]罗杰尔-萨拉扎，J. (2017)。<em class="je">使用Python进行数据科学和分析</em>。佛罗里达州博卡拉顿:Crc出版社，泰勒&amp;弗朗西斯集团。</p><p id="ca20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">‌[4]Miller，T.W. (2015)。<em class="je">营销数据科学:使用R和Python的预测分析建模技术</em>。上马鞍河:金融时报/Prentice Hall。</p></div></div>    
</body>
</html>