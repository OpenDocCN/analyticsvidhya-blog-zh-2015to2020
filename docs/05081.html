<html>
<head>
<title>Techniques you need to know while handling Imbalanced Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理不平衡数据时你需要知道的技巧</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/techniques-you-need-to-know-while-handling-imbalanced-data-d48a586c848d?source=collection_archive---------20-----------------------#2020-04-10">https://medium.com/analytics-vidhya/techniques-you-need-to-know-while-handling-imbalanced-data-d48a586c848d?source=collection_archive---------20-----------------------#2020-04-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><blockquote class="im"><p id="d022" class="in io hi bd ip iq ir is it iu iv iw dx translated">“我们的目标是将数据转化为信息，将信息转化为洞察力。”</p><p id="4599" class="in io hi bd ip iq ir is it iu iv iw dx translated">—卡莉·菲奥莉娜</p></blockquote><p id="f5a1" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt iw hb bi translated">我们在处理真实世界数据集时遇到的一个主要挑战是不平衡的数据比例。欺诈检测是这类数据的最佳例子。</p><p id="f736" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">在本文中，我们将使用来自<a class="ae jz" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank"> kaggle </a>的信用卡欺诈检测数据集。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ka"><img src="../Images/cde5ffa8ea56e1b31ac1eed369cbbcd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p51RsV_qmiIg6TRwNUMGhQ@2x.png"/></div></div></figure><p id="8a82" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">欺诈事件在整个数据中不到1%。这种来自特定类的实例非常少的数据称为不平衡数据。</p><h1 id="2e86" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">取样技术</h1><h2 id="8ebc" class="lk kn hi bd ko ll lm ln ks lo lp lq kw ji lr ls la jm lt lu le jq lv lw li lx bi translated">过采样</h2><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ly"><img src="../Images/94fcef81f29b7a6bc5511bf0b5a03fee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZzHTP35dS09DdoLOxB8cPQ.png"/></div></div></figure><p id="46fb" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">来自少数类(数据集中实例较少的类)的数据被复制以增加少数类的比例。这种技术的一个主要问题是过度拟合。</p><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="5e4b" class="lk kn hi ma b fi me mf l mg mh">from imblearn.over_sampling import RandomOverSampler</span><span id="5b5f" class="lk kn hi ma b fi mi mf l mg mh">oversample = RandomOverSampler(sampling_strategy='minority')</span><span id="9238" class="lk kn hi ma b fi mi mf l mg mh">X_over, y_over = oversample.fit_resample(X_train, y_train)</span></pre><h2 id="b8ac" class="lk kn hi bd ko ll lm ln ks lo lp lq kw ji lr ls la jm lt lu le jq lv lw li lx bi translated">欠采样</h2><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es mj"><img src="../Images/a23287d66583ac7136bd71c1e8687440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtSLxueHpPjCdeJUWUs9kw.png"/></div></div></figure><p id="52aa" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">对多数类(数据集中实例较多的类)中的数据进行采样，以降低多数类的比例。这种技术的一个主要问题是信息的丢失。</p><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="8eac" class="lk kn hi ma b fi me mf l mg mh">from imblearn.over_sampling import RandomUnderSampler</span><span id="0c1e" class="lk kn hi ma b fi mi mf l mg mh">undersample = RandomUnderSampler(sampling_strategy='majority')</span><span id="0c44" class="lk kn hi ma b fi mi mf l mg mh">X_over, y_over = oversample.fit_resample(X_train, y_train)</span></pre><h2 id="86b4" class="lk kn hi bd ko ll lm ln ks lo lp lq kw ji lr ls la jm lt lu le jq lv lw li lx bi translated">合成少数过采样技术(SMOTE)</h2><p id="7193" class="pw-post-body-paragraph ix iy hi iz b ja mk jc jd je ml jg jh ji mm jk jl jm mn jo jp jq mo js jt iw hb bi translated">我们将通过这种过采样技术产生样本，而不是盲目复制。SMOTE按照以下步骤生成数据。</p><ol class=""><li id="d776" class="mp mq hi iz b ja ju je jv ji mr jm ms jq mt iw mu mv mw mx bi translated">对于少数类中的每个样本x，选择k个最近邻来形成Q{y0，y1 …k值}(k的默认值是5)。</li><li id="6234" class="mp mq hi iz b ja my je mz ji na jm nb jq nc iw mu mv mw mx bi translated">新样本x '是从少数样本的线性插值中获得的，公式如下:</li></ol><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es nd"><img src="../Images/f0426fb25a72fb91269712597780fb53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*mcG1-zKNxuUtcY_R4RZi5A.png"/></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">击打前的t-sne图</figcaption></figure><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="da14" class="lk kn hi ma b fi me mf l mg mh"><strong class="ma hj">from</strong> <!-- -->imblearn.over_sampling <strong class="ma hj">import</strong> <!-- -->SMOTE</span><span id="73a5" class="lk kn hi ma b fi mi mf l mg mh">sm <strong class="ma hj">=</strong> <!-- -->SMOTE(random_state <strong class="ma hj">=</strong> <!-- -->2)</span><span id="b6e0" class="lk kn hi ma b fi mi mf l mg mh">X_train_res, y_train_res <strong class="ma hj">=</strong> <!-- -->sm.fit_sample(X_train, y_train)</span></pre><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es nd"><img src="../Images/c0199ef170ce8ac61aace9ff7c34969d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*N98kbRXulv7Eej_TVO7wgg.png"/></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">击打后的t-sne图</figcaption></figure><p id="a4ee" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">SMOTE和欠采样的组合用于获得更好的结果。</p><h1 id="469e" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">集成学习技术</h1><p id="a4ad" class="pw-post-body-paragraph ix iy hi iz b ja mk jc jd je ml jg jh ji mm jk jl jm mn jo jp jq mo js jt iw hb bi translated">据信，集成学习技术在不平衡数据上表现良好。集成技术将多个分类器的结果结合起来，以提高单个分类器的性能。集成技术的目标是减少分类器的多样性。</p><h2 id="75f7" class="lk kn hi bd ko ll lm ln ks lo lp lq kw ji lr ls la jm lt lu le jq lv lw li lx bi translated">随机森林</h2><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ni"><img src="../Images/63a7df43e3851d631b70b7ec5ee3f7ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o8PxOS_CIHrSLGkQWXrq0A.png"/></div></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">集成学习</figcaption></figure><p id="2d6a" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">随机森林是一种集成学习技术，旨在减少决策树分类器的多样性。随机森林从基于采样数据构建的多个决策树中获得最佳解决方案。</p><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="f4e4" class="lk kn hi ma b fi me mf l mg mh">from sklearn.ensemble import RandomForestClassifier</span><span id="535b" class="lk kn hi ma b fi mi mf l mg mh">model = RandomForestClassifier(n_estimators=100, <br/>                               bootstrap = True,<br/>                               max_features = 'sqrt')<br/>model.fit(X_train,y_train)</span><span id="b53d" class="lk kn hi ma b fi mi mf l mg mh">y_pred2= model.predict(X_test)</span></pre><p id="0e75" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">我们发现了72起欺诈/总共98起欺诈。因此，发现欺诈的概率是0.734。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es nj"><img src="../Images/83202d0e394fb4cd27e08cefce3aee3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*Q8nGFJzTfXB67Gz2Y48UUA.png"/></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">随机森林的混淆矩阵</figcaption></figure><h2 id="2934" class="lk kn hi bd ko ll lm ln ks lo lp lq kw ji lr ls la jm lt lu le jq lv lw li lx bi translated">XGBoost</h2><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es nk"><img src="../Images/8795d151f85b1779928e5abe17217188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VbhmsQGioXt-B8DIPOGmnQ.png"/></div></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">助推</figcaption></figure><p id="df78" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">随机森林并行构建树。在boosting技术中，通过纠正先前训练的树的错误来训练树。</p><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="e36b" class="lk kn hi ma b fi me mf l mg mh">import xgboost as xgb</span><span id="68a4" class="lk kn hi ma b fi mi mf l mg mh">alg = xgb.XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5,min_child_weight=3, gamma=0.2, subsample=0.6, colsample_bytree=1.0,objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)</span><span id="6898" class="lk kn hi ma b fi mi mf l mg mh">alg.fit(X_train, y_train, eval_metric='auc')</span><span id="09f5" class="lk kn hi ma b fi mi mf l mg mh">y_pred = alg.predict(X_test)<br/>y_score = alg.predict_proba(X_test)[:,1]</span></pre><p id="b27f" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">我们发现了74起欺诈/总共98起欺诈。因此，发现欺诈的概率是0.755。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es nj"><img src="../Images/87dd3a72b19cd61af9b0bd3de93a3661.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*9g2OEyp6wmutV98p2MZFDw.png"/></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">XGBoost的混淆矩阵</figcaption></figure><h2 id="db45" class="lk kn hi bd ko ll lm ln ks lo lp lq kw ji lr ls la jm lt lu le jq lv lw li lx bi translated">轻型GBM</h2><p id="95c4" class="pw-post-body-paragraph ix iy hi iz b ja mk jc jd je ml jg jh ji mm jk jl jm mn jo jp jq mo js jt iw hb bi translated">轻型GBM提高了XGBoost的性能。</p><p id="962a" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">XGBoost允许逐级增长。但是轻的GBM允许叶向生长。这使得轻量级GBM内存高效，并兼容大型数据集。</p><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="ee35" class="lk kn hi ma b fi me mf l mg mh">import lightgbm as lgbm</span><span id="2135" class="lk kn hi ma b fi mi mf l mg mh">lgbm_clf = lgbm.LGBMClassifier(boosting_type='gbdt',<br/>        class_weight=None,<br/>        colsample_bytree=0.5112837457460335,importance_type='split',<br/>        learning_rate=0.02, max_depth=7, metric='None',<br/>        min_child_samples=195, min_child_weight=0.01,<br/>        min_split_gain=0.0,<br/>        n_estimators=3000, n_jobs=4, num_leaves=44, objective=None,<br/>        random_state=42, reg_alpha=2, reg_lambda=10, silent=True,<br/>        subsample=0.8137506311449016, subsample_for_bin=200000,<br/>        subsample_freq=0)</span><span id="d6cf" class="lk kn hi ma b fi mi mf l mg mh">lgbm_clf.fit(X_train, y_train)</span><span id="5626" class="lk kn hi ma b fi mi mf l mg mh">y_pred1 = lgbm_clf.predict(X_test)<br/>y_score1 = lgbm_clf.predict_proba(X_test)[:,1]</span></pre><p id="3ad4" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">我们发现了76起欺诈/总共98起欺诈。因此，发现欺诈的概率是0.775。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es nj"><img src="../Images/87dd3a72b19cd61af9b0bd3de93a3661.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*9g2OEyp6wmutV98p2MZFDw.png"/></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">光GBM的混淆矩阵</figcaption></figure><h1 id="1030" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">深度学习技术</h1><h2 id="30c2" class="lk kn hi bd ko ll lm ln ks lo lp lq kw ji lr ls la jm lt lu le jq lv lw li lx bi translated">自动编码器</h2><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es nl"><img src="../Images/eceef424bba8c8fad7069c3e13726da1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xj7gkmxTQ9tJ7s6kFX7QJQ.png"/></div></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">自动编码器</figcaption></figure><p id="3e3b" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">自动编码器试图重建给定的输入。自动编码器用于降维和深度异常检测。</p><p id="e859" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">这些深度学习技术也可以应用于图像和视频。</p><p id="07ac" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">我们将训练我们的公平或正常交易的自动编码器。每当遇到欺诈检测时，自动编码器无法重建它。这导致欺诈交易的更多重构误差。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es nm"><img src="../Images/61b19d24ec72b47e98176ff78ec265bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MxJpqOUDqEFcEnK2jU4eyQ.png"/></div></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es nn"><img src="../Images/aeee38378646dc8fadb0bd8ec952d7e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*63awYlevZw6kXYqqjwMTTA.png"/></div></div></figure><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="c5a7" class="lk kn hi ma b fi me mf l mg mh">autoencoder = tf.keras.models.Sequential([<br/>    <br/>   <br/>    tf.keras.layers.Dense(input_dim, activation='relu', input_shape=(input_dim, )), <br/>    <br/><br/>    tf.keras.layers.GaussianNoise(),<br/>    <br/><br/>    tf.keras.layers.Dense(latent_dim, activation='relu'),<br/>    <br/>    <br/>    tf.keras.layers.Dense(input_dim, activation='relu')<br/>    <br/>])</span><span id="f0bc" class="lk kn hi ma b fi mi mf l mg mh"><br/>autoencoder.compile(optimizer='adam', <br/>                    loss='mse',<br/>                    metrics=['acc'])</span><span id="f986" class="lk kn hi ma b fi mi mf l mg mh"><br/>autoencoder.summary()</span><span id="ca71" class="lk kn hi ma b fi mi mf l mg mh">#output<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>dense (Dense)                (None, 29)                870       <br/>_________________________________________________________________<br/>gaussian_noise (Gaussian Noise (None, 29)                0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 2)                 60        <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 29)                87        <br/>=================================================================<br/>Total params: 1,017<br/>Trainable params: 1,017<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="821c" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">现在，我们将训练自动编码器，并观察公平交易和欺诈交易的重构误差。</p><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="1b54" class="lk kn hi ma b fi me mf l mg mh">X_test_transformed = pipeline.transform(X_test)</span><span id="a409" class="lk kn hi ma b fi mi mf l mg mh">reconstructions = autoencoder.predict(X_test_transformed)</span><span id="c4bd" class="lk kn hi ma b fi mi mf l mg mh">mse = np.mean(np.power(X_test - reconstructions, 2), axis=1)</span></pre><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es nj"><img src="../Images/51fe65fb1f17850b4f15a67eb5b9cbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*sCQ4M5rxzm7lmHI_UdjBSg.png"/></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">标签-0是公平的，标签-1是欺诈</figcaption></figure><p id="9f75" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">欺诈交易重构误差相当高。现在我们需要设置阈值来区分欺诈和公平交易。</p><p id="65ab" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">对于好精度值，我们可以使用高阈值，对于好的召回，我们需要降低它。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es no"><img src="../Images/d79b845faa82aef0d495734c57041498.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2dOf9xaDADk8Us0Facy6fw.png"/></div></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">使用MAD阈值— 3</figcaption></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es no"><img src="../Images/5eecbed12dc89b645e56a8687b96255c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DERg4s-bbdJhNZONfuAkYw.png"/></div></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">使用MAD阈值-5</figcaption></figure><h2 id="8f75" class="lk kn hi bd ko ll lm ln ks lo lp lq kw ji lr ls la jm lt lu le jq lv lw li lx bi translated">偏差网络</h2><p id="3d8e" class="pw-post-body-paragraph ix iy hi iz b ja mk jc jd je ml jg jh ji mm jk jl jm mn jo jp jq mo js jt iw hb bi translated">偏差网络(DevNet)定义了高斯先验和基于Z分数的偏差损失，以便能够利用端到端神经异常分数学习器直接优化异常分数。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es np"><img src="../Images/39ec88b0dd2a3c4530e15a2e72435042.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lhf9ERx3473jGYjsV1OnVg.png"/></div></div><figcaption class="ne nf et er es ng nh bd b be z dx translated">发展网</figcaption></figure><p id="d001" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">该网络中使用的损失函数为:</p><p id="e0cb" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">l􏰁φ(x；θ)=(1y)| dev(x)|+y max(􏰁0,a−dev(x))</p><p id="b4d8" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">dev(x)=φ(x；θ)μR/σR</p><p id="044e" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">其中a是Z得分置信区间。</p><blockquote class="nq nr ns"><p id="a263" class="ix iy nt iz b ja ju jc jd je jv jg jh nu jw jk jl nv jx jo jp nw jy js jt iw hb bi translated"><strong class="iz hj">中心极限定理</strong>陈述了如果你有一个均值为μ，标准差为σ的总体，并且从替换的总体中取足够大的随机样本，那么样本均值的分布将近似为正态分布。</p></blockquote><p id="d53f" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">从中心极限定理可以得出结论，高斯分布符合从网络中获得的异常分数数据。我们将在实验中设置μ = 0和σ = 1，这有助于DevNet在不同数据集上实现稳定的检测性能。</p><p id="731d" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">对于所有公平交易(y=0):</p><p id="555d" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">l􏰁φ(x；θ)=(1 0)| dev(x)| = | dev(x)|</p><p id="dbba" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">对于所有欺诈交易(y=1):</p><p id="6a9d" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">l􏰁φ(x；θ)= 1(最大(􏰁0,a−dev(x))) =最大(􏰁0,a−dev(x))</p><p id="3454" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">因此，偏差损失相当于将所有异常的异常分数与正常对象的异常分数进行统计上显著的偏差。</p><p id="64c5" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">网络的代码是:</p><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="369e" class="lk kn hi ma b fi me mf l mg mh">def dev_network(input_shape):   <br/>    x_input = Input(shape=input_shape)    intermediate = Dense(1000<br/>                ,activation='relu',              <br/>                 kernel_regularizer=regularizers.l2(0.01), name =     <br/>                 'hl1')(x_input)    <br/>    intermediate = Dense(250, activation='relu',             <br/>                    kernel_regularizer=regularizers.l2(0.01), name =   <br/>                    'hl2')(intermediate)    <br/>    intermediate = Dense(20, activation='relu',                <br/>                    kernel_regularizer=regularizers.l2(0.01), name = <br/>                    'hl3')(intermediate)    <br/>    intermediate = Dense(1, activation='linear', name = 'score')  <br/>                      (intermediate)    <br/>   return Model(x_input, intermediate)</span></pre><p id="0576" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">偏差损失的代码是:</p><pre class="kb kc kd ke fd lz ma mb mc aw md bi"><span id="2900" class="lk kn hi ma b fi me mf l mg mh">def deviation_loss(y_true, y_pred):  <br/>    confidence_margin = 5.         <br/>    ref = K.variable(np.random.normal(loc = 0., scale= 1.0, size = <br/>                     5000) , dtype='float32')    <br/>    dev = (y_pred - K.mean(ref)) / K.std(ref)    <br/>    inlier_loss = K.abs(dev)     <br/>    outlier_loss = K.abs(K.maximum(confidence_margin - dev, 0.))       <br/>    return K.mean((1 - y_true) * inlier_loss + <br/>                                 y_true * outlier_loss)</span><span id="4d77" class="lk kn hi ma b fi mi mf l mg mh">model = dev_network_d(input_shape)</span><span id="5311" class="lk kn hi ma b fi mi mf l mg mh">model.compile(loss=deviation_loss, optimizer=rms)</span></pre><h1 id="2f94" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">韵律学</h1><p id="b722" class="pw-post-body-paragraph ix iy hi iz b ja mk jc jd je ml jg jh ji mm jk jl jm mn jo jp jq mo js jt iw hb bi translated">对于不平衡的数据，准确性不是一个好的衡量标准。相反，我们可以考虑回忆和F1分数。</p><p id="a304" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">我们也可以从ROC曲线转移到精确回忆曲线。</p><p id="7991" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">ROC曲线介于真阳性率(召回率)和假阳性率之间。</p><p id="2d44" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">Precision对不平衡数据的变化更敏感，因为负样本的数量相当高。</p><p id="eff3" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">FPR = FP/(FP+TN)</p><p id="c5cb" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">精度= TP/(TP+FP)</p><p id="249d" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">TN(正确识别的非欺诈交易)总是相当高。所以，FPR对FP的变化不敏感(被错误地认定为欺诈)。但是精度变化很大。</p><h1 id="b6a8" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">什么时候去学深度学习技术？</h1><ol class=""><li id="0423" class="mp mq hi iz b ja mk je ml ji nx jm ny jq nz iw mu mv mw mx bi translated">为了从图像或视频相关数据中检测异常，深度学习是优选的。</li><li id="ec75" class="mp mq hi iz b ja my je mz ji na jm nb jq nc iw mu mv mw mx bi translated">与集成方法相比，深度学习中需要调整的参数更多。因此，理解模型对于深度学习中的调优起着关键作用。</li></ol><h1 id="943f" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">外卖</h1><ul class=""><li id="985e" class="mp mq hi iz b ja mk je ml ji nx jm ny jq nz iw oa mv mw mx bi translated">不平衡数据的抽样技术。</li><li id="d82a" class="mp mq hi iz b ja my je mz ji na jm nb jq nc iw oa mv mw mx bi translated">不平衡数据的集成学习技术。</li><li id="0d44" class="mp mq hi iz b ja my je mz ji na jm nb jq nc iw oa mv mw mx bi translated">深度异常检测网络。</li><li id="34e7" class="mp mq hi iz b ja my je mz ji na jm nb jq nc iw oa mv mw mx bi translated">什么时候去深度学习？</li></ul><p id="a472" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated">感谢阅读:)</p><h1 id="9629" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">参考</h1><div class="ob oc ez fb od oe"><a href="https://www.kdd.org/kdd2019/accepted-papers/view/deep-anomaly-detection-with-deviation-networks" rel="noopener  ugc nofollow" target="_blank"><div class="of ab dw"><div class="og ab oh cl cj oi"><h2 class="bd hj fi z dy oj ea eb ok ed ef hh bi translated">KDD 2019 |偏差网络深度异常检测</h2><div class="ol l"><h3 class="bd b fi z dy oj ea eb ok ed ef dx translated">Guansong Pang(阿德莱德大学)；沈春华(阿德莱德大学)；安东·范·登·亨格尔</h3></div><div class="om l"><p class="bd b fp z dy oj ea eb ok ed ef dx translated">www.kdd.org</p></div></div><div class="on l"><div class="oo l op oq or on os kk oe"/></div></div></a></div><p id="c9e7" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated"><a class="ae jz" href="https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/ml-handling-unbalanced-data-with-smote-and-near-miss-algorithm-in-python/</a></p><p id="4332" class="pw-post-body-paragraph ix iy hi iz b ja ju jc jd je jv jg jh ji jw jk jl jm jx jo jp jq jy js jt iw hb bi translated"><a class="ae jz" href="http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Probability/BS704_Probability12.html" rel="noopener ugc nofollow" target="_blank">http://SPH web . bumc . bu . edu/otlt/MPH-Modules/BS/BS 704 _ Probability/BS 704 _ Probability 12 . html</a></p></div></div>    
</body>
</html>