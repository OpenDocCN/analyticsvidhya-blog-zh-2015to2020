<html>
<head>
<title>A Practical Guide to Object Detection using the Popular YOLO Framework — Part III (with Python codes)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用流行的YOLO框架进行目标检测的实用指南——第三部分(带Python代码)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-practical-guide-to-object-detection-using-the-popular-yolo-framework-part-iii-with-python-67b4cdaf1e2?source=collection_archive---------1-----------------------#2018-12-06">https://medium.com/analytics-vidhya/a-practical-guide-to-object-detection-using-the-popular-yolo-framework-part-iii-with-python-67b4cdaf1e2?source=collection_archive---------1-----------------------#2018-12-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c202" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们简单地采用一个已经设计好的框架，执行它，并得到想要的结果，我们的生活会有多简单？最小的努力，最大的回报。这不正是我们在任何职业中努力追求的吗？</p><p id="8524" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我感到非常幸运，能够成为我们机器学习社区的一员，在这里，即使是顶尖的科技巨头也拥抱开源技术。当然，在实施概念之前理解和掌握它们是很重要的，但是当顶级行业数据科学家和研究人员为您打下基础时，这总是很有帮助的。</p><p id="1c39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于像计算机视觉这样的深度学习领域来说尤其如此。不是每个人都有从零开始构建DL模型的计算资源。这就是预定义框架和预训练模型派上用场的地方。在本文中，我们将研究一个这样的对象检测框架——YOLO。这是一个非常快速和准确的框架，我们很快就会看到。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/eb6ff2bc4f5a82e1ebd9f0dfd562d880.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f-D91oYrhAnPRoge.png"/></div></div></figure><p id="093f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，在我们详细介绍对象检测的系列文章(下面的链接)中，我们已经看到了所使用的各种算法，以及我们如何使用R-CNN家族的算法检测图像中的对象并预测边界框。我们还研究了用Python实现Faster-RCNN。</p><p id="7bcf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第3部分中，我们将学习YOLO的工作原理，为什么你应该使用它而不是其他的物体检测算法，以及YOLO使用的不同技术。一旦我们彻底理解了这个概念，我们将会用Python来实现它。这是获得宝贵知识，然后以实际动手的方式应用它的理想指南。</p><p id="d445" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp">我强烈建议在开始阅读本指南之前先阅读前两部分:</em></p><ul class=""><li id="b00c" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated"><a class="ae jz" href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/" rel="noopener ugc nofollow" target="_blank"> <em class="jp">基本物体检测算法分步介绍(上)</em> </a></li><li id="ba6f" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc jv jw jx jy bi translated"><a class="ae jz" href="https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/" rel="noopener ugc nofollow" target="_blank"> <em class="jp">快速R-CNN算法在目标检测中的实际应用(下)</em> </a></li></ul><h1 id="1465" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">目录</h1><ol class=""><li id="65dd" class="jq jr hi ih b ii ld im le iq lf iu lg iy lh jc li jw jx jy bi translated">什么是YOLO，为什么有用？</li><li id="b176" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc li jw jx jy bi translated">YOLO框架是如何运作的？</li><li id="88d2" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc li jw jx jy bi translated">如何对包围盒进行编码？</li><li id="5511" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc li jw jx jy bi translated">并集上的交集和非最大抑制</li><li id="1bab" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc li jw jx jy bi translated">锚箱</li><li id="7039" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc li jw jx jy bi translated">结合以上所有的想法</li><li id="1668" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc li jw jx jy bi translated">用Python实现YOLO</li></ol><h1 id="cd3d" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">什么是YOLO，为什么有用？</h1><p id="c815" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">我们在第1部分中看到的R-CNN系列技术主要使用区域来定位图像中的对象。该网络不查看整个图像，只查看图像中包含物体的可能性较高的部分。</p><p id="b16e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一方面，YOLO框架(你只看一次)以不同的方式处理对象检测。它在单个实例中获取整个图像，并预测这些框的边界框坐标和类别概率。使用YOLO的最大优势是其超强的速度——速度快得令人难以置信，每秒可以处理45帧。YOLO也理解广义对象表示。</p><p id="bfc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是用于对象检测的最佳算法之一，并且已经显示出与R-CNN算法相当类似的性能。在接下来的章节中，我们将学习YOLO算法中使用的不同技术。下面的解释是受<a class="ae jz" href="https://www.coursera.org/learn/convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank"> Andrew NG的目标探测课程</a>的启发，该课程对我理解YOLO的工作有很大帮助。</p><h1 id="41c8" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">YOLO框架是如何运作的？</h1><p id="4af0" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">既然我们已经理解了为什么YOLO是一个如此有用的框架，让我们进入它实际上是如何工作的。在这一节中，我已经提到了YOLO在给定图像中检测物体所遵循的步骤。</p><ul class=""><li id="f223" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">YOLO首先拍摄一张输入图像:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lm"><img src="../Images/27cd5acede85b446d8c2b6151b5c4d00.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/0*JA_Mgj2LJCs_6VVd.png"/></div></figure><ul class=""><li id="b54b" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">然后，该框架将输入图像划分成网格(比如3×3网格):</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/d19db09ab7149a9fbd87e0f60bddaedb.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/0*f0ZjWsM36LCaQRGM.png"/></div></figure><ul class=""><li id="764d" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">在每个网格上应用图像分类和定位。然后，YOLO预测物体的边界框及其相应的类别概率(当然，如果找到的话)。</li></ul><p id="c916" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很简单，不是吗？让我们分解每一个步骤，以便更好地理解我们刚刚学到的内容。</p><p id="a9f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要将标记的数据传递给模型，以便对其进行训练。假设我们已经将图像划分成大小为3×3的网格，并且总共有3个类别，我们希望将对象分类到这些类别中。假设这些类分别是行人、汽车和摩托车。因此，对于每个网格单元，标签y将是一个八维向量:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/1f17b1e9d568aa9241702f9cced33c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/0*bri5MSTGbBpzU9j5.png"/></div></figure><p id="c246" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，</p><ul class=""><li id="7165" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">pc定义一个对象是否出现在网格中(它是概率)</li><li id="3e95" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc jv jw jx jy bi translated">如果有对象，bx，by，bh，bw指定边界框</li><li id="3a27" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc jv jw jx jy bi translated">c1、c2、c3代表类别。因此，如果对象是汽车，c2将是1，c1 &amp; c3将是0，依此类推</li></ul><p id="9ac3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们从上面的示例中选择了第一个网格:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lp"><img src="../Images/47d83778da3f71f61a346faa24043b25.png" data-original-src="https://miro.medium.com/v2/resize:fit:188/format:webp/0*sLXLK3BioOGOi8si.png"/></div></figure><p id="f59d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于此网格中没有对象，pc将为零，此网格的y标签将为:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/c09c4a8a2cf6f76ac8b5ef8e53480d3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/0*A36oTqeP31A5QkYS.png"/></div></figure><p id="14ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，'？'意味着bx、by、bh、bw、c1、c2和c3包含什么并不重要，因为网格中没有对象。让我们取另一个网格，其中有一辆汽车(c2 = 1):</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lr"><img src="../Images/752bb8d07e613ca06d7a9f4ec9212737.png" data-original-src="https://miro.medium.com/v2/resize:fit:184/format:webp/0*_m6x7VR_QqFOvzLH.png"/></div></figure><p id="a83a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们为这个网格写y标签之前，重要的是先理解YOLO是如何决定网格中是否真的有一个物体的。在上面的图像中，有两个对象(两辆汽车)，所以YOLO将采取这两个对象的中点，这些对象将被分配到包含这些对象的中点的网格。汽车左中网格的y标签将是:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/2515cb999ec15fe56d87280baff6803e.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/0*c16R3H0yafZuhBRd.png"/></div></figure><p id="8c4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于这个网格中有一个对象，pc将等于1。bx，by，bh，bw将相对于我们正在处理的特定网格单元进行计算。由于car是第二类，c2 = 1，c1和c3 = 0。因此，对于9个网格中的每一个，我们都有一个8维的输出向量。该输出将具有3 X 3 X 8的形状。</p><p id="0740" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们有了一个输入图像和它对应的目标向量。使用上面的例子(输入图像100 X 100 X 3，输出3 X 3 X 8)，我们的模型将被训练如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ls"><img src="../Images/882547d26a0286b8c5c8d4f6b7db19df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Al17Aas0pGeafECL.png"/></div></div></figure><p id="25b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将运行前向和后向传播来训练我们的模型。在测试阶段，我们将图像传递给模型，并向前传播，直到我们获得输出y。为了保持简单，我在这里使用3 X 3网格解释了这一点，但通常在现实世界中，我们采用更大的网格(可能是19 X 19)。</p><p id="c87b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">即使一个对象跨越多个网格，它也只会被指定给其中点所在的单个网格。我们可以通过增加网格的数量(例如19 X 19)来减少多个对象出现在同一个网格单元中的机会。</p><h1 id="89c3" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">如何对包围盒进行编码？</h1><p id="994f" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">正如我前面提到的，bx、by、bh和bw是相对于我们正在处理的网格单元计算的。让我们用一个例子来理解这个概念。考虑包含汽车的中右网格:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lr"><img src="../Images/7b16c166180623ad5631eeba07da89ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:184/format:webp/0*FgV2lXtLqDBsTsTb.png"/></div></figure><p id="370d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，bx、by、bh和bw将仅相对于该网格进行计算。此网格的y标签将为:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/022a2a1f0cd72cd4023948e8e7864cff.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/0*lVeYqLE9NRSkVW7u.png"/></div></figure><p id="59fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">pc = 1，因为在这个网格中有一个对象，并且它是一辆汽车，所以c2 = 1。现在，让我们看看如何决定bx，by，bh和bw。在YOLO，分配给所有网格的坐标是:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lt"><img src="../Images/ac33b053c4f622fe8610082de62790c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/0*It258Sv1F73n6hyv.png"/></div></figure><p id="b360" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">bx，by是对象中点相对于该网格的x和y坐标。在这种情况下，它将(大约)bx = 0.4，by = 0.3:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lu"><img src="../Images/f9b7e3f89aeb1a23d39a05d54c339d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/0*cVyWB_L_JSQO8A3T.png"/></div></figure><p id="feeb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">bh是边界框(上例中的红框)的高度与相应网格单元的高度之比，在我们的例子中大约是0.9。所以，bh = 0.9。bw是边界框的宽度与网格单元的宽度之比。所以，bw = 0.5(近似值)。此网格的y标签将为:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/9936d7e4b50d43b9c2ae95ee5edf1c9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/0*U_Nu80aNoDgoKqpg.png"/></div></figure><p id="8e98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，bx和by的范围始终在0和1之间，因为中点始终位于网格内。而在边界框的尺寸大于网格尺寸的情况下，bh和bw可以大于1。</p><p id="fe07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在下一节中，我们将看到更多的想法，这些想法有可能帮助我们使这个算法的性能更好。</p><h1 id="6917" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">并集上的交集和非最大抑制</h1><p id="56f6" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">这里有一些值得思考的东西——我们如何决定预测的边界框给我们的是好结果(还是坏结果)?这就是交集超过并集的地方。它计算实际边界框和预测结合框的交集。考虑汽车的实际和预测边界框，如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/bce5a56e748971619c4c5bf04bab664f.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/0*KrDXMXe4sTZkqY2M.png"/></div></figure><p id="c14d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，红框是实际的边界框，蓝框是预测的边界框。我们如何决定它是否是一个好的预测？IoU，或交集除以并集，将计算这两个盒子的交集除以并集的面积。该区域将是:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lw"><img src="../Images/74bc72c2b7e69e99eb373b3b2ec223d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/0*4AGqrgZpBcxAz9Ef.png"/></div></figure><p id="8253" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">IoU =交点面积/并集面积，即</p><p id="04dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">IoU =黄框面积/绿框面积</p><p id="effb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果IoU大于0.5，我们可以说预测足够好。0.5是我们这里任意取的一个阈值，但是可以根据你的具体问题来改变。直觉上，阈值越大，预测就越好。</p><p id="ff92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有一种技术可以显著提高YOLO的输出，即非最大值抑制。</p><p id="3ecd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对象检测算法最常见的问题之一是，它们可能会多次检测一个对象，而不是只检测一次。考虑下图:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lx"><img src="../Images/cec17b0bd151b58241eccecd54a7c55c.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/0*ZVv30uj7fNieuSyJ.png"/></div></figure><p id="ee5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，车辆被识别了不止一次。非最大值抑制技术消除了这一点，因此我们只能对每个对象进行一次检测。让我们看看这种方法是如何工作的。</p><p id="0c3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.它首先查看与每个检测相关联的概率，并取最大的一个。在上图中，0.9是概率最高的，所以将首先选择概率为0.9的框:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ly"><img src="../Images/a1a7285c2a4eb27659c4fbfdc86f341c.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/0*GqjtM7pc-zESZjas.png"/></div></div></figure><p id="aa79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.现在，它会查看图像中的所有其他框。与当前框具有高IoU的框被抑制。因此，在我们的示例中，概率为0.6和0.7的框将被抑制:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/7a6ee942fc7816a28ea005fdc8137f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*PkdSknLaskIm5Roi.png"/></div></figure><p id="6cb5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.在框被抑制后，它从所有框中选择下一个概率最高的框，在我们的例子中是0.8:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/e7f65f82121502c53c346dd103d8b408.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/0*FVshX7NJ-p-pzRIp.png"/></div></figure><p id="4d9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.同样，它将查看该框与其余框的IoU，并压缩具有高IoU的框:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mb"><img src="../Images/eeb1466a6d466404cc05d5185a3866f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/0*grbtcpTznMCiC0PZ.png"/></div></figure><p id="7079" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.我们重复这些步骤，直到所有的框都被选择或压缩，并且我们得到最终的边界框:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/884c7f78eb891a23f71472370b94ac6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*jJlCWF3aIiOV2Wow.png"/></div></figure><p id="94a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是非最大抑制的意义所在。我们选择具有最大概率的盒子，并抑制附近具有非最大概率的盒子。让我们快速总结一下我们在本节中看到的关于非最大值抑制算法的要点:</p><ol class=""><li id="324c" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc li jw jx jy bi translated">丢弃所有概率小于或等于预定义阈值(比如0.5)的盒子</li><li id="d2b9" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc li jw jx jy bi translated">其余盒子:<br/> 1。挑选概率最高的盒子，并将其作为输出预测<br/> 2。将IoU大于阈值的任何其他框与上述步骤中的输出框一起丢弃</li><li id="7949" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc li jw jx jy bi translated">重复步骤2，直到所有的盒子要么被作为输出预测，要么被丢弃</li></ol><p id="eeda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以使用另一种方法来提高YOLO算法的性能——让我们来看看吧！</p><h1 id="bee8" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">锚箱</h1><p id="7cb8" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">我们已经看到，每个网格只能识别一个对象。但是如果一个网格中有多个对象呢？现实中经常会出现这种情况。这就引出了锚盒的概念。考虑下面的图像，分成3 X 3的网格:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/bd2101d451b32c7b8538bbb598545337.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/0*yfskY606TpcQ45AH.png"/></div></figure><p id="916f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还记得我们是如何将一个对象分配给网格的吗？我们取了对象的中点，并根据它的位置，将对象分配到相应的网格中。在上面的例子中，两个对象的中点位于同一网格中。对象的实际边界框将是这样的:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/685700c8ae3cd0c5ec4e1f83a29e5371.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/0*LsLp_qHti51R8qdA.png"/></div></figure><p id="3ecc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们只能得到两个箱子中的一个，要么是车的，要么是人的。但是如果我们使用锚盒，我们也许能输出两个盒子！我们如何着手做这件事？首先，我们预定义两种不同的形状，称为锚盒或锚盒形状。现在，对于每个网格，我们将有两个输出，而不是一个输出。我们也可以增加锚箱的数量。为了让这个概念更容易理解，我在这里举了两个例子:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es me"><img src="../Images/7543643ceffee229f2999ca84afa791b.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/0*ZtV6LDfGbDouBjjY.png"/></div></figure><p id="4a28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是没有锚定框的YOLO的y标签的样子:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/b44df65e47c7c9959befa73799b2525b.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/0*rjObK2uH-cN_rcqb.png"/></div></figure><p id="c713" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们有2个锚盒，你认为y标签会是什么？我希望你在进一步阅读之前花点时间思考一下这个问题。明白了吗？y标签将是:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mf"><img src="../Images/5dd0fe5f653a00c90e9c015169435b7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:250/format:webp/0*pHkDY7KD_gsTHeDa.png"/></div></figure><p id="4f0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">前8行属于锚盒1，其余8行属于锚盒2。基于边界框和锚定框形状的相似性，将对象分配给锚定框。因为锚定框1的形状类似于人的边界框，所以后者将被指定给锚定框1，而汽车将被指定给锚定框2。这种情况下的输出不是3 X 3 X 8(使用3 X 3的网格和3个类)，而是3 X 3 X 16(因为我们使用了2个锚点)。</p><p id="bc2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，对于每个网格，我们可以根据锚点的数量来检测两个或更多的对象。让我们把我们到目前为止讨论过的所有观点结合起来，并把它们整合到YOLO框架中。</p><h1 id="91f7" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">结合这些想法</h1><p id="9167" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">在这一节中，我们将首先看到一个YOLO模型是如何被训练的，然后是如何对一个新的和以前看不到的图像进行预测。</p><p id="c55a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jp">训练</em> </strong></p><p id="81e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练我们的模型的输入显然是图像和它们相应的y标签。让我们看一个图像，并制作它的y标签:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mg"><img src="../Images/d5d701ab36d6fe6785f8d582a329ecf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/0*yLW0p51RJboqHI8r.png"/></div></figure><p id="73fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑这样一个场景，我们使用一个3 X 3的网格，每个网格有两个锚点，有3个不同的对象类。因此相应的y标签将具有3×3×16的形状。现在，假设我们每个网格使用5个锚盒，并且类的数量已经增加到5个。所以目标将是3 X 3 X 5 X 5 = 3 X 3 X 25。这就是训练过程是如何完成的——拍摄特定形状的图像，并用3 X 3 X 16的目标对其进行映射(这可能会根据网格大小、锚框数量和类别数量而变化)。</p><p id="6eae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jp">测试</em> </strong></p><p id="f1db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">新的图像将被分成与我们在训练期间选择的相同数量的网格。对于每个网格，模型将预测形状为3 X 3 X 16的输出(假设这是目标在训练期间的形状)。该预测中的16个值将与训练标签的格式相同。前8个值将对应于锚定框1，其中第一个值将是该网格中对象的概率。值2–5将是该对象的边界框坐标，最后三个值将告诉我们该对象属于哪个类。接下来的8个值将用于锚框2，并且采用相同的格式，即，首先是概率，然后是边界框坐标，最后是类。</p><p id="d951" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，非最大值抑制技术将被应用到预测的盒子上，以获得每个对象的单个预测。</p><p id="5b0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这让我们结束了理解YOLO算法如何工作的理论方面，从训练模型开始，然后为对象生成预测框。以下是YOLO算法遵循的确切维度和步骤:</p><ul class=""><li id="8b74" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">获取形状(608，608，3)的输入图像</li><li id="702d" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc jv jw jx jy bi translated">将该图像传递给卷积神经网络(CNN ),后者返回(19，19，5，85)维输出</li><li id="d012" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc jv jw jx jy bi translated">将上述输出的最后两个维度扁平化得到的输出体积为(19，19，425): <br/> a .这里，一个19 X 19的网格的每个单元格返回425个数字<br/> b. 425 = 5 * 85，其中5是每个网格的锚盒数<br/> c. 85 = 5 + 80，其中5是(pc，bx，by，bh，bw)80是我们要检测的类数</li><li id="0bde" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc jv jw jx jy bi translated">最后，我们进行IoU和非最大值抑制，以避免选择重叠的框</li></ul><h1 id="7d08" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">用Python实现YOLO</h1><p id="a6da" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">是时候启动我们的Jupyter笔记本(或您喜欢的IDE)并最终以代码的形式实现我们的学习了！这就是我们到目前为止所做的，所以让我们开始吧。</p><p id="b75c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将在本节中看到的实现YOLO的代码摘自<a class="ae jz" href="https://github.com/enggen/Deep-Learning-Coursera" rel="noopener ugc nofollow" target="_blank"> Andrew NG的GitHub知识库</a>中关于深度学习的内容。您还需要下载这个<a class="ae jz" href="https://drive.google.com/file/d/1X79ZtIBp-Q70THZapcTeLqffxIqbLx_I/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> zip文件</a>，其中包含运行这个代码所需的预训练权重。</p><p id="563b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们首先定义一些函数，这些函数将帮助我们选择高于某个阈值的框，找到IoU，并对它们应用非最大抑制。然而，在做任何事情之前，我们将首先导入所需的库:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="1536" class="mm kg hi mi b fi mn mo l mp mq">import os<br/>import matplotlib.pyplot as plt<br/>from matplotlib.pyplot import imshow<br/>import scipy.io<br/>import scipy.misc<br/>import numpy as np<br/>import pandas as pd<br/>import PIL<br/>import tensorflow as tf<br/>from skimage.transform import resize<br/>from keras import backend as K<br/>from keras.layers import Input, Lambda, Conv2D<br/>from keras.models import load_model, Model<br/>from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes<br/>from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body<br/><br/>%matplotlib inline</span></pre><p id="8a0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们创建一个基于概率和阈值过滤盒子的函数:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="5658" class="mm kg hi mi b fi mn mo l mp mq">def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):<br/>    box_scores = box_confidence*box_class_probs<br/>    box_classes = K.argmax(box_scores,-1)<br/>    box_class_scores = K.max(box_scores,-1)<br/>    filtering_mask = box_class_scores&gt;threshold<br/>    scores = tf.boolean_mask(box_class_scores,filtering_mask)<br/>    boxes = tf.boolean_mask(boxes,filtering_mask)<br/>    classes = tf.boolean_mask(box_classes,filtering_mask)<br/> <br/>    return scores, boxes, classes</span></pre><p id="48e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将定义一个函数来计算两个盒子之间的IoU:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="dffe" class="mm kg hi mi b fi mn mo l mp mq">def iou(box1, box2):<br/>    xi1 = max(box1[0],box2[0])<br/>    yi1 = max(box1[1],box2[1])<br/>    xi2 = min(box1[2],box2[2])<br/>    yi2 = min(box1[3],box2[3])<br/>    inter_area = (yi2-yi1)*(xi2-xi1)<br/>    box1_area = (box1[3]-box1[1])*(box1[2]-box1[0])<br/>    box2_area = (box2[3]-box2[1])*(box2[2]-box2[0])<br/>    union_area = box1_area+box2_area-inter_area<br/>    iou = inter_area/union_area<br/> <br/>    return iou</span></pre><p id="c6a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们为非最大值抑制定义一个函数:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="5933" class="mm kg hi mi b fi mn mo l mp mq">def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):<br/>    max_boxes_tensor = K.variable(max_boxes, dtype='int32')<br/>    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))<br/>    nms_indices = tf.image.non_max_suppression(boxes,scores,max_boxes,iou_threshold)<br/>    scores = K.gather(scores,nms_indices)<br/>    boxes = K.gather(boxes,nms_indices)<br/>    classes = K.gather(classes,nms_indices)<br/><br/>    return scores, boxes, classes</span></pre><p id="efec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在有了计算IoU和执行非最大值抑制的函数。我们从形状(19，19，5，85)的CNN得到输出。因此，我们将创建一个形状为(19，19，5，85)的随机体积，然后预测边界框:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="e6c9" class="mm kg hi mi b fi mn mo l mp mq">yolo_outputs = (tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),<br/>                   tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),<br/>                   tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),<br/>                   tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))</span></pre><p id="4b6d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将定义一个函数，该函数将CNN的输出作为输入，并返回被抑制的框:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="554b" class="mm kg hi mi b fi mn mo l mp mq">def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):<br/>    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs<br/>    boxes = yolo_boxes_to_corners(box_xy, box_wh)<br/>    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)<br/>    boxes = scale_boxes(boxes, image_shape)<br/>    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)<br/><br/>    return scores, boxes, classes</span></pre><p id="40e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看如何使用<em class="jp"> yolo_eval </em>函数来预测我们上面创建的随机体积:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="453d" class="mm kg hi mi b fi mn mo l mp mq">scores, boxes, classes = yolo_eval(yolo_outputs)</span></pre><p id="f4d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">前景如何？</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="0d23" class="mm kg hi mi b fi mn mo l mp mq">with tf.Session() as test_b:<br/>    print("scores[2] = " + str(scores[2].eval()))<br/>    print("boxes[2] = " + str(boxes[2].eval()))<br/>    print("classes[2] = " + str(classes[2].eval()))</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mr"><img src="../Images/8edb0b5449420cd7a27e416cc9150f65.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/0*GCoxEuK8qNKE12Rf.png"/></div></figure><p id="6c2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“分数”表示对象出现在体积中的可能性。“box”返回检测到的对象的(x1，y1，x2，y2)坐标。“类”是已识别对象的类。</p><p id="7695" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们对新图像使用预训练的YOLO算法，看看它是如何工作的:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="9c7c" class="mm kg hi mi b fi mn mo l mp mq">sess = K.get_session()<br/>class_names = read_classes("model_data/coco_classes.txt")<br/>anchors = read_anchors("model_data/yolo_anchors.txt")<br/><br/>yolo_model = load_model("model_data/yolo.h5")</span></pre><p id="7ba8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在加载了类和预训练模型之后，让我们使用上面定义的函数来获得<em class="jp"> yolo_outputs </em>。</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="686a" class="mm kg hi mi b fi mn mo l mp mq">yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))</span></pre><p id="1d5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将定义一个函数来预测边界框并保存包含这些边界框的图像:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="7efe" class="mm kg hi mi b fi mn mo l mp mq">def predict(sess, image_file):<br/>    image, image_data = preprocess_image("images/" + image_file, model_image_size = (608, 608))<br/>    out_scores, out_boxes, out_classes = sess.run([scores, boxes, classes], feed_dict={yolo_model.input: image_data, K.learning_phase(): 0})<br/><br/>    print('Found {} boxes for {}'.format(len(out_boxes), image_file))<br/><br/>    # Generate colors for drawing bounding boxes.<br/>    colors = generate_colors(class_names)<br/><br/>    # Draw bounding boxes on the image file<br/>    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)<br/><br/>    # Save the predicted bounding box on the image<br/>    image.save(os.path.join("out", image_file), quality=90)<br/><br/>    # Display the results in the notebook<br/>    output_image = scipy.misc.imread(os.path.join("out", image_file))<br/><br/>    plt.figure(figsize=(12,12))<br/>    imshow(output_image)<br/><br/>    return out_scores, out_boxes, out_classes</span></pre><p id="022d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将读取一幅图像，并使用<em class="jp">预测</em>功能进行预测:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="7588" class="mm kg hi mi b fi mn mo l mp mq">img = plt.imread('images/img.jpg')<br/>image_shape = float(img.shape[0]), float(img.shape[1])<br/>scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)</span></pre><p id="a840" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，让我们绘制预测图:</p><pre class="je jf jg jh fd mh mi mj mk aw ml bi"><span id="f842" class="mm kg hi mi b fi mn mo l mp mq">out_scores, out_boxes, out_classes = predict(sess, "img.jpg")</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ms"><img src="../Images/84240a92727f321c264d2dae358e6fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*z91aevlAUFvYpBrQ.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="ab fe cl mt"><img src="../Images/fc62e52e78fc4e6dc94947537cfbddb0.png" data-original-src="https://miro.medium.com/v2/format:webp/0*hN2ScGYeIjFdfjlP.png"/></div></figure><p id="cabb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还不错！我尤其喜欢的是，模型正确地搭载了微型面包车中的人。</p><h1 id="2a95" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">结束注释</h1><p id="e65f" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">以下是我们在本指南中涵盖和实施的内容的简要总结:</p><ul class=""><li id="79f8" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">YOLO是一种最先进的对象检测算法，它的速度和准确性令人难以置信</li><li id="5cf2" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc jv jw jx jy bi translated">我们将输入图像发送到CNN，它输出一个19×19×5×85维度的体积。</li><li id="5798" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc jv jw jx jy bi translated">这里，网格大小为19×19，每个网格包含5个盒子</li><li id="a073" class="jq jr hi ih b ii ka im kb iq kc iu kd iy ke jc jv jw jx jy bi translated">我们使用非最大值抑制过滤所有的框，只保留精确的框，并消除重叠的框</li></ul><p id="01a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO是我一直以来最喜欢的框架之一，我相信一旦你在自己的机器上实现了代码，你就会明白为什么了。这是一个用流行的计算机视觉算法弄脏手的好方法。如果您对本指南有任何问题或反馈，请在下面的评论区联系我。</p></div><div class="ab cl mu mv gp mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="hb hc hd he hf"><p id="1f4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jp">原载于2018年12月6日</em><a class="ae jz" href="https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/" rel="noopener ugc nofollow" target="_blank"><em class="jp">www.analyticsvidhya.com</em></a><em class="jp">。</em></p></div></div>    
</body>
</html>