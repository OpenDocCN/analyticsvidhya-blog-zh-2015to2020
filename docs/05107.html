<html>
<head>
<title>Introduction to Logistic Regression with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python逻辑回归简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-logistic-regression-with-python-58cfca44bf48?source=collection_archive---------14-----------------------#2020-04-11">https://medium.com/analytics-vidhya/introduction-to-logistic-regression-with-python-58cfca44bf48?source=collection_archive---------14-----------------------#2020-04-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="0a3b" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">预测信用卡申请的结果</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/1e63c7863dbcd359455af1bb13f5bbba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tad3Gv_F1KT_0UP8Yokv7w.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">信用卡申请</figcaption></figure><p id="7d6b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">随着信用卡申请的大量增加，银行发现手动评估信用卡申请很麻烦。数据科学和机器学习的力量有助于银行预测申请是被接受还是被拒绝。写这篇文章是为了展示机器学习算法如何有助于自动评估任务，如信用卡申请。</p><p id="c6e8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">对于这个项目，我们将使用来自UCI ML知识库的信用卡审批数据集，可以在这里找到<a class="ae kj" href="http://archive.ics.uci.edu/ml/datasets/credit+approval" rel="noopener ugc nofollow" target="_blank"/>。下载数据并保存到“数据集/”文件夹中</p><p id="b863" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">先决条件:</strong></p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="5ffb" class="kp kq hi kl b fi kr ks l kt ku">pip install pandas<br/>pip install numpy<br/>pip install sklearn</span></pre><h2 id="99c1" class="kp kq hi bd kv kw kx ky kz la lb lc ld jw le lf lg ka lh li lj ke lk ll lm ln bi translated"><strong class="ak">导入数据集</strong></h2><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="94da" class="kp kq hi kl b fi kr ks l kt ku"><strong class="kl hj">import pandas as pd<br/>import matplotlib.pyplot as plt</strong></span><span id="c0c3" class="kp kq hi kl b fi lo ks l kt ku">credit_app = <strong class="kl hj">pd.read_csv</strong>("datasets/credit_application.csv", headers=None)<br/></span></pre><h2 id="7a50" class="kp kq hi bd kv kw kx ky kz la lb lc ld jw le lf lg ka lh li lj ke lk ll lm ln bi translated"><strong class="ak">了解我们的数据</strong></h2><p id="212f" class="pw-post-body-paragraph jn jo hi jp b jq lp ij js jt lq im jv jw lr jy jz ka ls kc kd ke lt kg kh ki hb bi translated">这个数据集是匿名的，但是我们可以从这篇<a class="ae kj" href="http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html" rel="noopener ugc nofollow" target="_blank">博客文章</a>中大致了解这些列的意思。典型的信用卡应用中的特征是<code class="du lu lv lw kl b">Gender</code>、<code class="du lu lv lw kl b">Age</code>、<code class="du lu lv lw kl b">Debt</code>、<code class="du lu lv lw kl b">Married</code>、<code class="du lu lv lw kl b">BankCustomer</code>、<code class="du lu lv lw kl b">EducationLevel</code>、<code class="du lu lv lw kl b">Ethnicity</code>、<code class="du lu lv lw kl b">YearsEmployed</code>、<code class="du lu lv lw kl b">PriorDefault</code>、<code class="du lu lv lw kl b">Employed</code>、<code class="du lu lv lw kl b">CreditScore</code>、<code class="du lu lv lw kl b">DriversLicense</code>、<code class="du lu lv lw kl b">Citizen</code>、<code class="du lu lv lw kl b">ZipCode</code>、<code class="du lu lv lw kl b">Income</code>以及最后的<code class="du lu lv lw kl b">ApprovalStatus</code></p><p id="7ea7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们可以计算我们的描述性统计数据，并观察到该数据集包含数字和分类特征，可以通过对数据进行一些处理来处理这些特征。</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="7d80" class="kp kq hi kl b fi kr ks l kt ku">credit_app.<strong class="kl hj">describe()</strong><br/>credit_app.<strong class="kl hj">info()</strong></span></pre><h2 id="fd56" class="kp kq hi bd kv kw kx ky kz la lb lc ld jw le lf lg ka lh li lj ke lk ll lm ln bi translated"><strong class="ak">数据清理</strong></h2><p id="7e86" class="pw-post-body-paragraph jn jo hi jp b jq lp ij js jt lq im jv jw lr jy jz ka ls kc kd ke lt kg kh ki hb bi translated">我们的数据有三个关键问题需要解决</p><ul class=""><li id="3b42" class="lx ly hi jp b jq jr jt ju jw lz ka ma ke mb ki mc md me mf bi translated">首先，我们有float、int和object类型的数值和分类数据。</li><li id="01c2" class="lx ly hi jp b jq mg jt mh jw mi ka mj ke mk ki mc md me mf bi translated">其次，我们的数据中有多个数值范围，这使得我们无法从数据中做出准确的统计推断。</li><li id="6330" class="lx ly hi jp b jq mg jt mh jw mi ka mj ke mk ki mc md me mf bi translated">第三，我们必须估算所有缺失值，以确保我们的模型不会表现不佳。</li></ul><p id="4b6a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们可以看到缺失值被表示为“？”在我们的数据中，现在我们将使用均值插补来填充缺失的数值。</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="4951" class="kp kq hi kl b fi kr ks l kt ku">credit_app.<strong class="kl hj">fillna</strong>(credit_app.mean(), inplace=True)<br/># Printing the number of left over null values <br/>print(credit_app.<strong class="kl hj">isnull()</strong>)</span></pre><p id="88e4" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们观察到仍然有120个空值，并且这些都是非数字数据类型。我们可以通过选择每列最常见的循环值来处理这些值。</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="2f45" class="kp kq hi kl b fi kr ks l kt ku"><strong class="kl hj">for</strong> val <strong class="kl hj">in</strong> credit_app:<br/>    <em class="ml"># Check if the column is of object type</em><br/>    <strong class="kl hj">if</strong> credit_app[val].dtypes == 'object':<br/>        <em class="ml"># Impute with the most frequent value</em><br/>        credit_app = credit_apps.fillna(credit_app[val].value_counts().index[0])</span></pre><h2 id="a004" class="kp kq hi bd kv kw kx ky kz la lb lc ld jw le lf lg ka lh li lj ke lk ll lm ln bi translated"><strong class="ak">数据预处理</strong></h2><p id="5e88" class="pw-post-body-paragraph jn jo hi jp b jq lp ij js jt lq im jv jw lr jy jz ka ls kc kd ke lt kg kh ki hb bi translated">在数据预处理阶段，我们将在拟合我们的模型之前完成某些任务</p><ul class=""><li id="e32b" class="lx ly hi jp b jq jr jt ju jw lz ka ma ke mb ki mc md me mf bi translated">将所有非数字数据转换为数字数据。这个过程是使用一种称为标签编码的技术来完成的，这种技术有利于将标签转换成数字形式，从而提高机器的可读性。然后，机器学习算法可以以更好的方式决定这些标签必须如何操作。</li></ul><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="c18d" class="kp kq hi kl b fi kr ks l kt ku"><strong class="kl hj">from</strong> <strong class="kl hj">sklearn.preprocessing</strong> <strong class="kl hj">import</strong> LabelEncoder<br/><em class="ml"># Instantiate LabelEncoder</em><br/>le = LabelEncoder()<br/><br/><strong class="kl hj">for</strong> val <strong class="kl hj">in</strong> credit_app:<br/>    <em class="ml"># Compare if the dtype is object</em><br/>    <strong class="kl hj">if</strong> credit_app[val].dtypes=='object':<br/>        credit_app[val]=le.fit_transform(credit_app[val])</span></pre><ul class=""><li id="0bea" class="lx ly hi jp b jq jr jt ju jw lz ka ma ke mb ki mc md me mf bi translated">接下来，我们将数据分成训练集和测试集。这个过程是为机器学习建模的两个不同阶段准备数据:训练和测试。理想情况下，来自测试数据的任何信息都不应用于调整训练数据，也不应用于指导机器学习模型的训练过程。我们将对该型号进行70-30分割。像<code class="du lu lv lw kl b">DriversLicense</code>和<code class="du lu lv lw kl b">ZipCode</code>这样的特征没有数据集中预测信用卡批准的其他特征重要。我们应该放弃它们，选择最好的功能集。这就是<strong class="jp hj">特征选择</strong>的过程。</li></ul><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="0a06" class="kp kq hi kl b fi kr ks l kt ku"><strong class="kl hj">from</strong> <strong class="kl hj">sklearn.model_selection</strong> <strong class="kl hj">import</strong> train_test_split</span><span id="d027" class="kp kq hi kl b fi lo ks l kt ku">credit_app = credit_app.drop([11, 13], axis=1)<br/>credit_app = credit_app.values<br/><br/><em class="ml"># Segregate features and labels into separate variables</em><br/>X,y = credit_app[:,0:13] , credit_app[:,13]<br/><br/><em class="ml"># Split into train and test sets</em><br/>X_train, X_test, y_train, y_test = train_test_split(X,<br/>                                y,<br/>                                test_size=0.30,<br/>                                random_state=42)</span></pre><ul class=""><li id="b86a" class="lx ly hi jp b jq jr jt ju jw lz ka ma ke mb ki mc md me mf bi translated">将我们的数据扩展到一个统一的范围。让我们用<code class="du lu lv lw kl b">CreditScore</code>作为缩放工作的真实例子。一个人的信用评分决定了他偿还信用卡账单的价值。这个数字越高，一个人被认为在财务上越值得信任。因此，1的<code class="du lu lv lw kl b">CreditScore</code>是最高的，因为我们将把所有值缩放到0-1的范围。</li></ul><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="8c66" class="kp kq hi kl b fi kr ks l kt ku"><strong class="kl hj">from</strong> <strong class="kl hj">sklearn.preprocessing</strong> <strong class="kl hj">import</strong> MinMaxScaler<br/><em class="ml"># Instantiate MinMaxScaler and use it to rescale X_train and X_test</em><br/>scaler = MinMaxScaler(feature_range=(0, 1))<br/>rescaledX_train = scaler.fit_transform(X_train)<br/>rescaledX_test = scaler.fit_transform(X_test)</span></pre><h2 id="f8af" class="kp kq hi bd kv kw kx ky kz la lb lc ld jw le lf lg ka lh li lj ke lk ll lm ln bi translated"><strong class="ak">拟合模型并预测结果</strong></h2><p id="5d8a" class="pw-post-body-paragraph jn jo hi jp b jq lp ij js jt lq im jv jw lr jy jz ka ls kc kd ke lt kg kh ki hb bi translated"><a class="ae kj" href="http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.names" rel="noopener ugc nofollow" target="_blank">根据UCI </a>，数据集包含更多对应于“拒绝”状态的实例，而不是对应于“批准”状态的实例。具体来说，在690个案例中，有383个(55.5%)申请被拒绝，307个(44.5%)申请获得批准。”为了建立一个好的模型，我们的结果应该在统计上与这些结果一致。</p><p id="b067" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">机器学习过程中最困难的部分是选择最适合我们业务问题的模型。我们必须就我们的数据提出问题，例如:<em class="ml">这些特征是否显示出彼此之间的线性关联？</em>在检查该数据的相关性时，我们可以观察到我们的特征是相关的，因此，我们可以选择广义线性模型来预测我们的结果变量。预测信用卡申请是否会被批准是一项分类任务，因此我们将选择使用逻辑回归模型。</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="c4dc" class="kp kq hi kl b fi kr ks l kt ku"><strong class="kl hj">from</strong> <strong class="kl hj">sklearn.linear_model</strong> <strong class="kl hj">import</strong> LogisticRegression<br/><em class="ml"># Instantiate a LogisticRegression classifier with default parameter values</em><br/>logreg = LogisticRegression()<br/><br/><em class="ml"># Fit model to the train set</em><br/>logreg.fit(rescaledX_train, y_train)</span></pre><p id="638c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Out []:</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="ef91" class="kp kq hi kl b fi kr ks l kt ku">LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',<br/>random_state=None, solver='warn', tol=0.0001, verbose=0,warm_start=False)</span></pre><p id="cfd2" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">现在，我们将在测试集上评估我们的模型的分类准确性。在预测信用卡申请的情况下，同样重要的是看看我们的机器学习模型是否能够预测那些最初被拒绝的申请的批准状态。如果我们的模型在这方面表现不好，那么它最终可能会批准本不应该批准的申请。使用混淆矩阵来计算我们的假阳性和假阴性是一个有用的任务，以找到我们的模型的错误分类率。</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="b2cf" class="kp kq hi kl b fi kr ks l kt ku"><strong class="kl hj">from</strong> <strong class="kl hj">sklearn.metrics</strong> <strong class="kl hj">import</strong> confusion_matrix<br/>y_pred = logreg.predict(rescaledX_test)<br/><br/>print("Accuracy of logistic regression classifier: ", logreg.score(rescaledX_test, y_test))<br/><br/><em class="ml"># Print the confusion matrix of the logreg model</em><br/>confusion_matrix(y_test, y_pred)</span></pre><p id="eca7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Out[]:</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="c646" class="kp kq hi kl b fi kr ks l kt ku">Accuracy of logistic regression classifier:  0.8377192982456141<br/>[92, 11<br/> 26, 99]</span></pre><p id="9552" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">上面的输出显示了我们的准确度和混淆矩阵。我们可以看到我们的预测率相当不错，大约84%！尽管如此，我们仍然可以使用其他技术来提高我们的模型精度。</p><h2 id="ffe4" class="kp kq hi bd kv kw kx ky kz la lb lc ld jw le lf lg ka lh li lj ke lk ll lm ln bi translated"><strong class="ak">通过超参数调整提高模型效率</strong></h2><p id="f762" class="pw-post-body-paragraph jn jo hi jp b jq lp ij js jt lq im jv jw lr jy jz ka ls kc kd ke lt kg kh ki hb bi translated">为了进一步增强我们的模型，我们可以使用一种众所周知的叫做网格搜索的技术来提高预测信用卡批准的能力。因此，超参数优化的目标是找到最小化模型验证误差函数的一组值。这一点非常重要，因为整个模型的性能取决于指定的超参数值。在本例中，我们将搜索参数</p><ul class=""><li id="9619" class="lx ly hi jp b jq jr jt ju jw lz ka ma ke mb ki mc md me mf bi translated">tol:停止标准的容差</li><li id="d157" class="lx ly hi jp b jq mg jt mh jw mi ka mj ke mk ki mc md me mf bi translated">max_iter:求解器收敛所需的最大迭代次数。</li></ul><p id="796d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Scikit-Learn为网格搜索的实现提供了很好的文档，如果你想了解更多，你可以在这里找到文档<a class="ae kj" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="9442" class="kp kq hi kl b fi kr ks l kt ku"><strong class="kl hj">from</strong> <strong class="kl hj">sklearn.model_selection</strong> <strong class="kl hj">import</strong> GridSearchCV<br/><em class="ml"># Define the grid of values for tol and max_iter</em><br/>tol = [0.01, 0.001, 0.0001]<br/>max_iter = [100, 150, 200]<br/><br/>parameter_grid = dict(tol=tol, max_iter=max_iter)</span></pre><p id="a086" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">现在，我们将开始网格搜索，看看哪些值表现最好。</p><p id="4395" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们将用我们拥有的所有数据用我们早期的模型实例化<code class="du lu lv lw kl b">GridSearchCV()</code>。我们将提供x和y的缩放版本。我们还将指示<code class="du lu lv lw kl b">GridSearchCV()</code>执行五重交叉验证。<a class="ae kj" href="https://www.cs.cmu.edu/~schneide/tut5/node42.html" rel="noopener ugc nofollow" target="_blank">在K-Fold交叉验证</a>中，数据集被分成<em class="ml"> k </em>个子集，holdout方法被重复<em class="ml"> k </em>次。每一次，<em class="ml"> k个</em>子集中的一个作为测试集，其他<em class="ml"> k-1个</em>子集放在一起形成一个训练集。然后计算所有<em class="ml"> k次</em>试验的平均误差。</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="f9ed" class="kp kq hi kl b fi kr ks l kt ku">grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)<br/><br/>rescaledX = scaler.fit_transform(X)<br/><br/>grid_model_result = grid_model.fit(rescaledX, y)<br/><br/><em class="ml"># Summarize results</em><br/>best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_<br/>print("Best: <strong class="kl hj">%f</strong> using <strong class="kl hj">%s</strong>" % (best_score, best_params))</span></pre><p id="88fe" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Out[]:</p><pre class="iy iz ja jb fd kk kl km kn aw ko bi"><span id="8c53" class="kp kq hi kl b fi kr ks l kt ku">Best: 0.853623 using {'max_iter': 100, 'tol': 0.01}</span></pre><p id="e4ef" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们的模型成功地将其效率提高了1%以上！网格搜索帮助我们完成了这项任务。我们完成了一些机器学习来预测一个人的信用卡申请是否会被批准，给定这个人的一些信息。</p><h2 id="5701" class="kp kq hi bd kv kw kx ky kz la lb lc ld jw le lf lg ka lh li lj ke lk ll lm ln bi translated">参考资料:</h2><ol class=""><li id="d762" class="lx ly hi jp b jq lp jt lq jw mm ka mn ke mo ki mp md me mf bi translated"><a class="ae kj" href="http://archive.ics.uci.edu/ml/datasets/credit+approval" rel="noopener ugc nofollow" target="_blank">http://archive.ics.uci.edu/ml/datasets/credit+approval</a></li><li id="2bbc" class="lx ly hi jp b jq mg jt mh jw mi ka mj ke mk ki mp md me mf bi translated"><a class="ae kj" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . linear _ model。LogisticRegression.html</a></li><li id="9c09" class="lx ly hi jp b jq mg jt mh jw mi ka mj ke mk ki mp md me mf bi translated">【https://www.datacamp.com】T4/</li><li id="6917" class="lx ly hi jp b jq mg jt mh jw mi ka mj ke mk ki mp md me mf bi translated"><a class="ae kj" href="https://www.cs.cmu.edu/~schneide/tut5/node42.html" rel="noopener ugc nofollow" target="_blank">https://www.cs.cmu.edu/~schneide/tut5/node42.html</a></li></ol><p id="b662" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">感谢你阅读我的文章，我希望你觉得有趣！</p></div><div class="ab cl mq mr gp ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hb hc hd he hf"><p id="82a8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">你可以在社交媒体上找到我！</p><blockquote class="mx my mz"><p id="49e9" class="jn jo ml jp b jq jr ij js jt ju im jv na jx jy jz nb kb kc kd nc kf kg kh ki hb bi translated"><a class="ae kj" href="https://www.linkedin.com/in/aditya-nar/" rel="noopener ugc nofollow" target="_blank">领英</a></p><p id="d608" class="jn jo ml jp b jq jr ij js jt ju im jv na jx jy jz nb kb kc kd nc kf kg kh ki hb bi translated"><a class="ae kj" href="https://www.github.com/AdiNar1106" rel="noopener ugc nofollow" target="_blank"> Github </a></p></blockquote></div></div>    
</body>
</html>