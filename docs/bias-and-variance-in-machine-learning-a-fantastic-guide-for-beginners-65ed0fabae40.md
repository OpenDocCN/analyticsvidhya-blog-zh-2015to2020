# 机器学习中的偏差和差异——初学者的绝佳指南！

> 原文：<https://medium.com/analytics-vidhya/bias-and-variance-in-machine-learning-a-fantastic-guide-for-beginners-65ed0fabae40?source=collection_archive---------15----------------------->

# 概观

*   学会解释给定模型中的偏差和方差。
*   偏倚和方差的区别是什么？
*   如何使用机器学习工作流实现偏差和方差的权衡

# 介绍

让我们来谈谈天气。只有稍微潮湿的时候才会下雨，刮风、炎热或寒冷的时候不会下雨。在这种情况下，您将如何训练一个预测模型，并确保在预测天气时没有错误？你可能会说有很多学习算法可以选择。它们在很多方面都是不同的，但是我们的预期和模型的预测有很大的不同。这就是偏差和方差权衡的概念。

![](img/60fcdcb5ebad42e6d293bca81132488b.png)

来源:[https://ai-pool . com/a/s/bias-variance-trade-in-machine-learning](https://ai-pool.com/a/s/bias-variance-tradeoff-in-machine-learning)

通常，偏差和方差的权衡是通过密集的数学公式教授的。但是在这篇文章中，我试图尽可能简单地解释偏差和方差！

> *我的重点将是引导你理解问题陈述的过程，并确保你选择偏差和方差误差最小的最佳模型。*

为此，我采用了流行的皮马印第安人糖尿病数据集。该数据集由印第安皮马土著成年女性患者的诊断测量数据组成。对于这个数据集，我们将重点关注“结果”变量，它表明患者是否患有糖尿病。显然，这是一个二元分类问题，我们将深入研究并学习如何解决它。

如果你对此和数据科学概念感兴趣，并想实际学习，请参考我们的课程- [数据科学简介](https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2?utm_source=blog&utm_medium=)

# 目录

1.  评估机器学习模型
2.  问题陈述和主要步骤
3.  什么是偏见？
4.  什么是方差？
5.  偏差-方差权衡

# 评估你的机器学习模型

机器学习模型的主要目的是从给定的数据中学习，并根据学习过程中观察到的模式生成预测。然而，我们的任务并没有就此结束。我们需要根据模型产生的结果不断改进模型。我们还使用准确性、均方差(MSE)、F1 分数等指标来量化模型的性能，并尝试改进这些指标。当我们必须保持模型的灵活性而不损害其正确性时，这通常会变得棘手。

受监督的机器学习模型旨在以这样的方式对输入变量(X)进行自我训练，使得预测值(Y)尽可能接近实际值。实际值和预测值之间的差异就是**误差**，它用于评估模型。任何受监督的机器学习算法的误差包括 3 个部分:

1.  偏移误差
2.  方差误差
3.  噪音

虽然噪声是我们无法消除的不可约误差，但其他两个误差(即偏差和方差)是可约误差，我们可以尝试尽可能将其最小化。

在以下部分，我们将讨论偏差误差、方差误差和偏差-方差权衡，这将有助于我们选择最佳模型。令人兴奋的是，我们将通过使用一个示例数据集来介绍一些处理这些错误的技术。

# 问题陈述和主要步骤

如前所述，我们采用了[皮马印第安人糖尿病数据集](https://github.com/purva91/Bias_Variance_Knn/blob/master/diabetes.csv)，并在其上形成了一个分类问题。让我们从评估数据集开始，观察我们正在处理的数据类型。为此，我们将导入必要的库:

现在，我们将把数据加载到一个数据框中，并观察一些行以深入了解数据。

![](img/9cf8b9e9af99b420104182f3ad3c36e4.png)

我们需要预测“结果”栏。让我们把它分离出来，赋给一个目标变量‘y’。数据帧的其余部分将是输入变量 x 的集合

现在，让我们缩放预测变量，然后分离训练和测试数据。

由于结果以二进制形式分类，我们将使用最简单的[K-最近邻分类器(Knn)](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/?utm_source=blog&utm_medium=bias-variance-tradeoff) 对患者是否患有糖尿病进行分类。

然而，我们如何决定 k 的值呢？

*   也许我们应该使用 k = 1，这样我们将在我们的训练数据上得到非常好的结果？这可能行得通，但我们不能保证该模型在我们的测试数据上表现得一样好，因为它可能会变得过于具体。
*   使用高 k 值怎么样，比如 k = 100，这样我们就可以考虑大量最近的点来说明远处的点。然而，这种模型过于一般化，我们无法确定它是否正确考虑了所有可能的影响因素。

让我们取几个可能的 k 值，并在所有这些值的训练数据上拟合模型。我们还将计算所有这些值的训练分数和测试分数。

为了从中获得更多的见解，让我们绘制训练数据(红色)和测试数据(蓝色)。

![](img/5b2ddca68aed7f24d3a708f5359796c1.png)

为了计算特定 k 值的分数，

![](img/1824918aa5ef97dd3938bbe646921ebb.png)

从上面的情节我们可以得出以下结论:

*   对于低 k 值，训练分数高，而测试分数低
*   随着 k 值的增加，测试分数开始增加，训练分数开始减少。
*   然而，在 k 的某个值处，训练分数和测试分数彼此接近。

这就是偏见和差异出现的原因。

# 什么是偏见？

用最简单的话来说，偏差就是预测值和期望值之间的差异。为了进一步解释，模型在根据所提供的数据进行训练时会做出某些假设。当引入测试/验证数据时，这些假设可能并不总是正确的。

在我们的模型中，如果我们使用大量的最近邻，模型完全可以决定一些参数根本不重要。例如，它可以只考虑血糖水平和血压来决定患者是否患有糖尿病。这个模型会对不影响结果的其他参数做出非常强的假设。当数据点清楚地表明一个更复杂的关系时，您也可以将它视为一个预测简单关系的模型:

![](img/74432c4a7286affa6c3a64e5173dd455.png)

数学上，假设输入变量是 X，目标变量是 y。我们使用函数 f 来映射两者之间的关系。

因此，

> **Y = f(X) + e**

这里的“e”是正态分布的误差。我们的模型 f'(x)的目的是预测尽可能接近 f(x)的值。这里，模型的偏差是:

> **Bias[f '(X)]= E[f '(X)—f(X)]**

正如我上面解释的，当模型进行概括时，即当存在高偏差误差时，它导致一个非常简单的模型，没有很好地考虑变化。由于它没有很好地学习训练数据，因此被称为**欠拟合。**

# 什么是方差？

与偏差相反，方差是指模型考虑了数据中的波动，即噪声。那么，当我们的模型有很高的方差时会发生什么呢？

模型仍然会将方差视为可以学习的东西。也就是说，模型从训练数据中学到了太多，以至于当面对新的(测试)数据时，它无法基于它进行准确的预测。

数学上，模型中的方差误差为:

> **方差[f(X))= E[X]—E[X]**

由于在高方差的情况下，模型从训练数据中学习了太多，所以称为**过拟合。**

在我们的数据环境中，如果我们使用非常少的最近邻，就像是说，如果怀孕次数超过 3 次，血糖水平超过 78，舒张压低于 98，皮肤厚度小于 23 毫米等等，对于每个特征…..判定患者患有糖尿病。所有其他不符合上述标准的患者都不是糖尿病患者。虽然对于训练集中的一个特定患者来说这可能是真的，但是如果这些参数是异常值或者甚至被错误地记录了呢？显然，这种模式可能会非常昂贵！

此外，该模型将具有高方差误差，因为对患者是否患有糖尿病的预测随着我们提供的训练数据的种类而变化很大。因此，即使将血糖水平改为 75，模型也会预测患者没有糖尿病。

更简单地说，当二次方程已经足够时，模型预测结果和输入要素之间非常复杂的关系。这是当存在高方差误差/当**过度拟合**时分类模型的样子:

![](img/ee034323f3ba1e22815b070bb2f6cc18.png)

总结一下，

*   具有高偏差误差的模型会对数据进行欠拟合，并对数据做出非常简单的假设
*   具有高方差误差的模型会过度拟合数据，并从中学习到太多东西
*   一个好的模型是偏差和方差都平衡的

# 偏差-方差权衡

我们如何将上述概念与之前的 kNN 模型联系起来？让我们来了解一下！

在我们的模型中，比方说，对于 k = 1，将考虑最接近所讨论的数据点的点。这里，对于特定的数据点，预测可能是准确的，因此偏差误差会更小。

但是，方差误差会很高，因为只考虑了一个最近的点，而没有考虑其他可能的点。你觉得这对应的是什么场景？是的，你想的没错，这意味着我们的模型过度拟合了。

另一方面，对于较高的 k 值，将考虑更多更接近所讨论的数据点的点。这将导致更高的偏置误差和欠拟合，因为许多更靠近数据点的点被考虑，因此它不能从训练集中学习细节。然而，对于具有未知值的测试集，我们可以考虑较低的方差误差。

为了实现偏置误差和方差误差之间的平衡，我们需要一个 k 值，使得模型既不会从噪声中学习(对数据过度拟合)，也不会对数据进行全面假设(对数据欠拟合)。为了简单起见，平衡模型应该是这样的:

![](img/cc3cbdc7bfdcc085b1588e9bd9a94a8b.png)

尽管有些点分类不正确，但该模型通常能准确地拟合大多数数据点。偏差误差和方差误差之间的平衡是**偏差-方差权衡**。

下面的靶心图更好地解释了这种权衡:

![](img/e1aff82aeb885c8e4e0f508dc5d57fc9.png)

[http://scott.fortmann-roe.com/docs/BiasVariance.html](http://scott.fortmann-roe.com/docs/BiasVariance.html)

中心(即靶心)是我们想要实现的模型结果，它可以完美地正确预测所有值。随着我们远离靶心，我们的模型开始做出越来越多的错误预测。

具有低偏差和高方差的模型预测的点通常在中心附近，但是彼此相距很远。具有高偏差和低方差的模型离靶心相当远，但是由于方差低，预测的点彼此更接近。

就模型复杂性而言，我们可以使用下图来决定模型的最佳复杂性。

![](img/0e274ab6bc1e33b8e1129262d067dfe6.png)

那么，你认为 k 的最佳值是多少？

从上面的解释中，我们可以得出这样的结论，k 为哪

*   测试分数是最高的，并且
*   测试分数和训练分数都很接近

是 k 的最佳值。因此，即使我们在较低的训练分数上妥协，我们仍然可以在更重要的测试数据上获得高分——测试数据毕竟是未知数据。

让我们为不同的 k 值制作一个表来进一步证明这一点:

![](img/c11dcfaa3404ae45b3409d394c3ac736.png)

# 结论

总之，在本文中，我们了解到理想的模型应该是偏差误差和方差误差都很低的模型。但是，我们应该始终以这样的模型为目标，即训练数据的模型得分尽可能接近测试数据的模型得分。

这就是我们如何选择一个既不太复杂(高方差和低偏差)导致过度拟合，又不太简单(高偏差和低方差)导致欠拟合的模型。

偏差和方差在决定使用哪个预测模型时起着重要的作用。我希望这篇文章很好地解释了这个概念。

如果你有任何后续问题，请在下面留下评论，我会尽力回答。

您也可以在我们的移动应用程序上阅读这篇文章

*原载于 2020 年 8 月 10 日*[*【https://www.analyticsvidhya.com】*](https://www.analyticsvidhya.com/blog/2020/08/bias-and-variance-tradeoff-machine-learning/)*。*