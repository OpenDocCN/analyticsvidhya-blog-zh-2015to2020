<html>
<head>
<title>Machine Learning # 2 — Correlation Matrix, Feature Selection, Class Imbalance, Decision Trees, Precision / Recall/ F1 Score</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习# 2 —相关矩阵、特征选择、类别不平衡、决策树、精确度/召回率/ F1分数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-2-correlation-matrix-feature-selection-class-imbalance-decision-trees-9a447fdb825?source=collection_archive---------2-----------------------#2020-12-14">https://medium.com/analytics-vidhya/machine-learning-2-correlation-matrix-feature-selection-class-imbalance-decision-trees-9a447fdb825?source=collection_archive---------2-----------------------#2020-12-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a709" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章是我的机器学习系列的第二篇文章，旨在巩固和分享我所学到的知识。对于本系列的第一篇文章:<a class="ae jd" rel="noopener" href="/analytics-vidhya/machine-learning-1-432f458ddc51">链接</a></p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><p id="4cea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你对这篇文章的土耳其语不感兴趣，你可以跳过这一段。</p><p id="2eac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jl"> Bu yaz，orendklerimi peki TIR MEK ve paylamak I in kale me ALD m机器学习yaz dizimin ikin ci yaz SDR . serin in ilk yaz si in:</em><a class="ae jd" href="https://gokerguner.medium.com/machine-learning-1-7d4581caa291" rel="noopener"><em class="jl">链接</em> </a></p><p id="a323" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">bu yaz n n türke versiyonu I in:<a class="ae jd" href="https://gokerguner.medium.com/machine-learning-2-korelasyon-matrisi-özellik-seçimi-sınıfların-dengesizliği-karar-ağaçları-af993bd8ea66" rel="noopener">链接</a></p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es jm"><img src="../Images/d7d7bbe54c86242eaf092edf7d0171af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Djmc3JnfGgu2XbyFmfh4KQ.jpeg"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">来源:<a class="ae jd" href="https://www.medicalnewstoday.com/articles/322300" rel="noopener ugc nofollow" target="_blank">https://www.medicalnewstoday.com/articles/322300</a></figcaption></figure><p id="eb1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你好，在我的机器学习系列的第二篇文章中</p><ul class=""><li id="6c7d" class="jy jz hi ih b ii ij im in iq ka iu kb iy kc jc kd ke kf kg bi translated">将使用新的分类模型</li><li id="6f03" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">将检查预测变量和目标变量之间的关系。</li><li id="196c" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">将会看到数据预处理的新方法</li><li id="7a9e" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">将讨论我们可以用来衡量模型性能的新方法。</li></ul><p id="c825" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这也将是一篇我们将讨论阶级不平衡，我们在评估模型性能时可能犯的错误，以及可以做些什么来修复它们的文章。</p><p id="59ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们从导入核心库开始。</p><pre class="jn jo jp jq fd km kn ko kp aw kq bi"><span id="de39" class="kr ks hi kn b fi kt ku l kv kw">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>df = pd.read_csv(‘winequality-red.csv’)</span></pre><p id="4b15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将开发一个品酒模型，试图根据葡萄酒样品的化学价值来预测它们的质量。我从我们在第一篇文章中使用的来源获得了数据集。你可以在这里找到<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets/wine+quality" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="0fd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将不详细阐述我们在本系列的第一篇文章中提到的方法。首先，我们从探索性数据分析部分开始。你可以通过查看<a class="ae jd" rel="noopener" href="/analytics-vidhya/machine-learning-1-432f458ddc51">这篇文章</a>来获得关于这一节的信息。</p><h2 id="5f26" class="kr ks hi bd kx ky kz la lb lc ld le lf iq lg lh li iu lj lk ll iy lm ln lo lp bi translated">数字EDA</h2><pre class="jn jo jp jq fd km kn ko kp aw kq bi"><span id="f2db" class="kr ks hi kn b fi kt ku l kv kw">df.info()</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lq"><img src="../Images/c1c887a6d1d3905c504e8517a44c6834.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*yDaA1DtAwMVXWN5UFXacZQ.png"/></div></figure><p id="fa96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的数据集由1599行和12列组成。我们将通过学习前11个属性来尝试预测质量属性。</p><pre class="jn jo jp jq fd km kn ko kp aw kq bi"><span id="fdf8" class="kr ks hi kn b fi kt ku l kv kw">df.describe()</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lr"><img src="../Images/d81cb4e1c06994e2ea3a3b63cf1842d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*FQLuzuDNbL4e8Y4b1ux5RA.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">您可以在我的GitHub资源库中找到该表的原始版本，我将在文章末尾分享其链接，或者您可以在本地Jupyter-notebook中运行代码并查看输出。由于截屏和左栏中的术语不在同一个方块中，我没有在截屏中包括质量值。</figcaption></figure><p id="4cf5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们看到我们的财产价值的一些总结。除了每列的平均值、最大值、标准值和最小值，我们还有像25%、50%和75%这样的表达式。</p><ul class=""><li id="343d" class="jy jz hi ih b ii ij im in iq ka iu kb iy kc jc kd ke kf kg bi translated">Min和max，该列中的最小和最大数值，</li><li id="c410" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">平均值是列值、std标准偏差值，</li><li id="c52c" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">25%、50%和75%的值还显示了该列中的值等于或低于该值的百分比。</li></ul><p id="3603" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们检查表中的quality列时，我们看到值在3和8之间变化(最小值是3，最大值是8)。并且，该列中四分之一的数据是5及以下(3，4，5)，而四分之三的数据是6及以下(3，4，5，6)。我们的平均值是5.63。</p><p id="594e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些值向我们表明，我们的数据集中的大多数质量值都有平均值(比如5和6)，并且分布是不平衡的。</p><p id="e48b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">问题:这种不平衡将导致我们的模型能够区分中等质量的葡萄酒，但不能区分低质量或高质量的葡萄酒。我们将尝试开发一个解决这个问题的方法，在相关的标题中叫做阶级不平衡。</p><pre class="jn jo jp jq fd km kn ko kp aw kq bi"><span id="1bff" class="kr ks hi kn b fi kt ku l kv kw">df.head(10)</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lr"><img src="../Images/f1a06b8ad1928e46001d7a608b9664a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*AofIiMifP-MhxdFNIaBDHQ.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">数据集前10行的列值</figcaption></figure><p id="d18b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到<em class="jl">挥发酸</em>、<em class="jl">柠檬酸</em>等数值都相当接近0，而<em class="jl">游离二氧化硫</em>和<em class="jl">总二氧化硫</em>数值一般都远高于0。</p><p id="522a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">记住像kNN这样的分类器，我们在<a class="ae jd" rel="noopener" href="/analytics-vidhya/machine-learning-1-432f458ddc51">第一篇文章</a>中提到过，是通过计算距离来工作的。在这种情况下，数值较大的值将位于分析平面的外角，由于距离计算中的较大值，我们的模型可能会做出不正确的预测。我们将提到这种情况的解决方案。</p><h1 id="1e60" class="ls ks hi bd kx lt lu lv lb lw lx ly lf lz ma mb li mc md me ll mf mg mh lo mi bi translated">特征选择和相关矩阵</h1><p id="bb46" class="pw-post-body-paragraph if ig hi ih b ii mj ik il im mk io ip iq ml is it iu mm iw ix iy mn ja jb jc hb bi translated">我们将考察的另一种情况是预测变量之间的增减关系。在解决任何机器学习问题时，特征选择是第一步也是最重要的一步。数据集中的每个要素都简单地用一列表示。每个列(属性)对目标变量的影响可能不一样。</p><p id="784d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将与目标变量关系较弱的预测变量添加到模型中会对性能产生一些负面影响。更多的预测变量导致更长的训练时间、增加的计算复杂性和一些潜在的重要特征的减少的影响。</p><p id="3ac0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种情况产生了对特征选择的需求。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es mq"><img src="../Images/f846da1fa2c85bb8f213cb70a55a8c4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*32u3JXjF_VeG6_Jqtzrp1g.png"/></div></figure><p id="10a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经使用seaborn库创建了一个关联矩阵。这个矩阵向我们展示了调色板中所有属性之间的关系。</p><p id="cb4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在相关矩阵中，值位于-1和+1之间。接近-1的值被解释为负相关，接近+1的值被解释为正相关。</p><p id="00fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正相关的两个变量的值一起增加或减少。</p><p id="1da7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当负相关的两个变量中的一个的值增加时，另一个的值减少。</p><p id="8dc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果值接近0，说明这两个变量之间没有联系。我们的目标是找到与<em class="jl">质量</em>属性相关值接近0的属性，并消除它们。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es mr"><img src="../Images/d4ef70dd08f5a8963448e559d82f7581.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*XGdiV2c_YiqHxJhbN_NWLA.png"/></div></figure><p id="13e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将相关值在-0.1和+0.1之间的属性分配给我们创建的名为<em class="jl"> relevant_features </em>的变量。其中一个变量是我们的<em class="jl">质量</em>变量，它通常有一个相关值1。我们将使用剩余的8个变量作为预测值。</p><pre class="jn jo jp jq fd km kn ko kp aw kq bi"><span id="2192" class="kr ks hi kn b fi kt ku l kv kw">to_drop = cor_target[cor_target&lt;0.1]</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ms"><img src="../Images/6575ab69780ef59709543102fc8ed799.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*Bax4UgloWevo7NbJ_-kDLw.png"/></div></figure><p id="46fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jl">残糖</em>、<em class="jl">游离二氧化硫</em>和<em class="jl"> pH </em>变量也是我们检测低相关性的特征，不会使用。我们还将它们收集在<em class="jl"> to_drop </em>变量中。</p><p id="2d4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们检查<em class="jl"> to_drop </em>变量时，又有两个名为<em class="jl"> Name </em>和<em class="jl"> dtype </em>的信息返回给我们。所以这个变量不是我们现在知道的Python列表。然而，为了将它从我们的训练集中删除，我们必须将其列出。让我们用<em class="jl"> type() </em>命令来学习数据类型。</p><pre class="jn jo jp jq fd km kn ko kp aw kq bi"><span id="00ea" class="kr ks hi kn b fi kt ku l kv kw">type(to_drop)</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="er es mt"><img src="../Images/ff5b004739a4f91e48716d7af89c680b.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*3w7FxP70m8QZGvrGEzVzKw.png"/></div></div></figure><p id="2a14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们首先将数据类型转换为frame，这是另一种pandas数据类型。</p><pre class="jn jo jp jq fd km kn ko kp aw kq bi"><span id="09d0" class="kr ks hi kn b fi kt ku l kv kw">to_drop_frame = to_drop.to_frame()</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es my"><img src="../Images/f2344fff1704a6e5f5d6cec0f81d151f.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*Q6HFjCEyK-NkPkGFm9mdUg.png"/></div></figure><p id="3971" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将这些变量转换成一个列表，并通过添加变量<em class="jl"> quality </em>最终确定我们将删除的变量列表。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h1 id="570d" class="ls ks hi bd kx lt lu lv lb lw lx ly lf lz ma mb li mc md me ll mf mg mh lo mi bi translated">阶级不平衡</h1><p id="cbe2" class="pw-post-body-paragraph if ig hi ih b ii mj ik il im mk io ip iq ml is it iu mm iw ix iy mn ja jb jc hb bi translated">在确定了我们的估计量和目标变量并把它们赋给X和y变量之后，在这一部分还有一个操作要做。正如df.describe() 向我们展示的那样，我们的质量属性取值为3、4、5、6、7和8。对于测试集，我们预计它会将大约320个样本分成6个不同的类，考虑到我们将从总集中的1599个数据中分离出大约1个。这可能会降低我们模型的性能。</p><p id="a9da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们在<em class="jl"> df.describe() </em>一节中提到的，我们拥有的例子一般都是中等质量的。</p><p id="a9f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，为了识别高和低质量的葡萄酒，我们考虑3和4点的葡萄酒是低质量的，5和6点的葡萄酒是中等质量的，7和8点的葡萄酒是高质量的。让我们开始吧。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="3af6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们拥有的数据集更大，就有可能开发出更有效的算法解决方案，并在文献中占有一席之地。</p><p id="2649" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作为这些解决方案的高级读物:<a class="ae jd" rel="noopener" href="/quantyca/how-to-handle-class-imbalance-problem-9ee3062f2499">https://medium . com/quantyca/how-to-handle-class-unbalancy-problem-9ee 3062 f 2499</a></p><h1 id="439e" class="ls ks hi bd kx lt lu lv lb lw lx ly lf lz ma mb li mc md me ll mf mg mh lo mi bi translated">决策树</h1><p id="96a8" class="pw-post-body-paragraph if ig hi ih b ii mj ik il im mk io ip iq ml is it iu mm iw ix iy mn ja jb jc hb bi translated">决策树是一种结构，用于通过应用一组决策规则将数据集划分为更小的集合。</p><p id="8214" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树是统计学、数据挖掘和机器学习中使用的预测建模方法之一。它使用决策树(预测模型)从对项目的观察(分支中表示的预测变量)导航到关于项目目标值的结论(叶中表示的目标变量)。目标变量可以取一组独立值的树模型称为分类树；在这些树形结构中，树叶代表类标签，树枝代表导致这些类标签的特征的组合。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lr"><img src="../Images/1f3669a1784c799bef91a1b5d132c538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*zyNi5mvHiDp15jneV8odtw.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">决策树的表示</figcaption></figure><p id="9fab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树中的顶点称为根。每个观察值都根据根的情况进行分类。</p><p id="9dea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">干细胞下有节点。使用节点对每个观察值进行分类。随着节点数量的增加，模型的复杂性也会增加。</p><p id="d289" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树的底部是叶子。树叶给了我们结果。</p><p id="a61a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在创建管道时，我们将使用两个参数进行网格搜索，scikit-learn的<em class="jl">决策树分类器</em>的<em class="jl">标准</em>和<em class="jl">最大深度</em>参数。基本上，我们将寻找问题的答案，当分支数据时，我们的模型将使用哪些信息标准，以及最多有多少步骤将优化信息。</p><p id="4b9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有关此参数和所有其他决策树参数的详细信息；您可以检查<a class="ae jd" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn文档</a>并尝试使用不同的参数和不同的值。</p><p id="8a12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们开始编写决策树之前，我们还需要为我们的模型做一件事。</p><h1 id="28b1" class="ls ks hi bd kx lt lu lv lb lw lx ly lf lz ma mb li mc md me ll mf mg mh lo mi bi translated">标准化(居中或缩放)</h1><p id="b5db" class="pw-post-body-paragraph if ig hi ih b ii mj ik il im mk io ip iq ml is it iu mm iw ix iy mn ja jb jc hb bi translated">在文章的引言部分，我们提到了一些预测变量的值非常接近于0，而一些则比0大得多。这导致具有较大值的变量对模型的影响更大(负面)。我们希望用相似的尺度来表示我们所有的预测变量。</p><p id="fc39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们将使用scikit-learn的<em class="jl"> StandardScaler </em>方法。</p><p id="d41a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们必须对我们描述的所有预处理过程进行编码。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="1a21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一步，如果我们简单讲一下基尼和熵的概念，</p><p id="7e1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基尼系数:数据集中随机选择的项目被错误分类的概率。</p><p id="1b87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">熵:一个变量的熵是该变量的可能结果中固有的“信息”、“惊喜”或“不确定性”的平均水平。在决策树的根部分，分类从熵值最小的特征开始。</p><p id="b1e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果用一个例子来解释熵的概念，那么无论是晴天还是雨天的信息的熵都低于电影院放映的电影的信息的熵。这意味着在决定如何度过一天时，你更有可能从天气入手。如果下雨，你宁愿坐在家里也不去看电影，这样就不用去想电影院在放什么电影了。</p><p id="bd9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于熵和信息论概念的进一步阅读:<a class="ae jd" href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Entropy _(information _ theory)</a></p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es mz"><img src="../Images/7eaa8588f7b3280663c6f7ef01b1a5d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*t1gaoQLj3VXENCrWlhzHVQ.png"/></div></figure><p id="f8c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用我们在第一篇文章中提到的网格搜索技术，我们得出结论，我们的最佳标准是g <em class="jl"> ini </em>，我们的最佳深度是4。当我们使用这些标准时，我们看到我们的模型取得了86%的成功。那么我们的模型真的有那么好吗？</p><h1 id="f9b1" class="ls ks hi bd kx lt lu lv lb lw lx ly lf lz ma mb li mc md me ll mf mg mh lo mi bi translated">精确度/召回率/ F1分数</h1><p id="398c" class="pw-post-body-paragraph if ig hi ih b ii mj ik il im mk io ip iq ml is it iu mm iw ix iy mn ja jb jc hb bi translated">仅仅模型的准确性是不够的，尤其是对于不均匀的数据集。为了全面衡量我们模型的性能，需要一些不同的指标。</p><p id="84bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这一点，我们先来参考一下混淆矩阵的概念。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es na"><img src="../Images/6e92cbd7c45a55d46f730455b421d87b.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*q6oxgmlxn21m32yuSE80tA.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">混淆矩阵</figcaption></figure><p id="3777" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">真阳性和真阴性是包含我们正确预测的字段，假阳性和假阴性是包含我们错误预测的字段。举个例子，假设我们的工作是在一组邮件中识别垃圾邮件。</p><ul class=""><li id="1450" class="jy jz hi ih b ii ij im in iq ka iu kb iy kc jc kd ke kf kg bi translated">绝对肯定:我们的模型预测该电子邮件是垃圾邮件，这是正确的。</li><li id="bab6" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">否定答案:我们的模型预测该电子邮件不是垃圾邮件，这是正确的。</li><li id="5016" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">误报:我们的模型预测该邮件是垃圾邮件，这是错误的。</li><li id="b6f9" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">假阴性:我们的模型预测电子邮件不是垃圾邮件，这是错误的。</li></ul><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es nb"><img src="../Images/12e4a409707fd35704b466c51192da32.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*0wax33m6Kf-Uc9JC1PKVuw.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">准确(性)</figcaption></figure><p id="9c36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型的准确性是通过将真实预测值除以总数得到的。假设100个人口中有10个癌症患者，90个健康人。如果我们的模型预测这整个群体是健康的，它将实现90%的成功。然而，由于它也预测这10个患者是健康的，所以它成为一个成功的致命模型。</p><p id="14f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们需要不同的指标来衡量模型的性能。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es nc"><img src="../Images/33ea71111fd81d9b060626e46feff20f.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*LU6w5VkXlWjd-WDZPRf00Q.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">精度给出了我们估计为正的值中有多少实际上是正的比率。</figcaption></figure><p id="83be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在假阳性预测的成本很高的情况下，精确度非常重要。例如，如果您需要发送到收件箱的电子邮件由于对您的模型的错误估计而落入垃圾邮件箱，那么您将无法看到您需要看到的重要电子邮件，您将处于亏损状态。在这种情况下，高精度值是评估模型性能的重要标准。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es nd"><img src="../Images/574b466c8fd18d2a7efdd68b4cfc7143.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*NahqrRl51lKInPAEJti14w.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">另一方面，回忆显示了我们应该猜测多少样本是肯定的。</figcaption></figure><p id="2d97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于邮件示例，我们需要作为垃圾邮件捕获的一些电子邮件落入收件箱可能看起来无害，但是具有高召回分数可能是至关重要的，特别是在关于健康和银行的数据集中。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ne"><img src="../Images/92c2ab30e0475e38a618ac8e2d2cf295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*k-EgJUi1YNjM8hwhrP7apQ.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">F1分数值向我们展示了精确值和召回值的调和平均值。使用F1分数是为了不在不一致的数据集中做出不正确的模型选择，并且具有包括所有错误成本的测量度量。</figcaption></figure><p id="e12d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，使用我们已经获得的最佳参数，让我们通过将我们的决策树分配给名为<em class="jl"> best_tree </em>的变量来重新运行训练/预测过程，并基于我们学习的性能度量来检查模型性能。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es nf"><img src="../Images/e9e1fedad7da44ae8e8ec699291e07e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*RBGEEVLAxYJdZiaqDHd46g.png"/></div></figure><p id="328a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到我们的模型不能识别任何质量差的葡萄酒(17个样品)。所以可能更准确的是有一个模型，识别精度少几个点，但也是低品质的葡萄酒。</p><p id="937c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些例子不能被区分的原因之一可能是它们没有被训练足够的前缀。因此，在下一步中，让我们通过缩小test_size来重新开始训练过程。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ng"><img src="../Images/469ff51b2dc1ca1e97347f447d0acbdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*TKX2zDObgKZozsawvmSZTA.png"/></div></figure><p id="6d26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们将新模型分配给具有最佳参数的best_tree变量，并再次检查我们的成功指标。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es nh"><img src="../Images/07223557d4509f27f56a2c14e677206a.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*RP_z1AWTLRabVtNb8hV1fg.png"/></div></figure><p id="e00f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一次，我们看到他标记为低品质的葡萄酒中有75%(精度)确实是低品质，他正确预测了30%(召回)的低品质葡萄酒。</p><p id="b150" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在之前的实验中，我们无法准确预测17个样本中的任何一个，但这次我们看到低质量葡萄酒类的性能有所提高，尽管有10个样本。</p><p id="4c3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于在我们的训练集中有更多标记为0的样本，我们能够增加测试集中剩余的劣质葡萄酒的预测得分。</p><p id="f2ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您还可以研究随机采样技术来解决像该数据集中的不平衡问题(但可以应用于更大的数据集来查看其效果)。基本上有两种方法来应用这种技术:</p><ul class=""><li id="3e35" class="jy jz hi ih b ii ij im in iq ka iu kb iy kc jc kd ke kf kg bi translated">过采样，通过增加少数类的例子</li><li id="4777" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">欠采样，减少大多数类的实例</li></ul><p id="e974" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以得到更平衡的班级。</p><p id="a640" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有一个Python语言的库就是为这个问题开发的。您可以在<a class="ae jd" href="https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/index.html#examples-based-on-real-world-datasets" rel="noopener ugc nofollow" target="_blank">链接</a>中查看这个库的例子，</p><p id="0c57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于这种方法的详细阅读，你可以查看<a class="ae jd" href="https://towardsdatascience.com/oversampling-and-undersampling-5e2bbaf56dcf" rel="noopener" target="_blank">这篇文章</a>。</p><p id="41d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们用scikit-learn库的树方法画出决策树的形状来结束我们的文章。下一篇文章再见。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ni"><img src="../Images/2e5abc7a448af7d075cfa8835e2eb296.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*rXBWzJRZFLlMbA13_j2Pvw.png"/></div></figure><p id="032d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">源代码</strong></p><div class="nj nk ez fb nl nm"><a href="https://github.com/gokerguner/notebooks/tree/main/ml02" rel="noopener  ugc nofollow" target="_blank"><div class="nn ab dw"><div class="no ab np cl cj nq"><h2 class="bd hj fi z dy nr ea eb ns ed ef hh bi translated">gokerguner/笔记本</h2><div class="nt l"><h3 class="bd b fi z dy nr ea eb ns ed ef dx translated">恩]:媒体的文章和我写的笔记本的主题是我对机器的了解和疑惑…</h3></div><div class="nu l"><p class="bd b fp z dy nr ea eb ns ed ef dx translated">github.com</p></div></div><div class="nv l"><div class="nw l nx ny nz nv oa js nm"/></div></div></a></div></div></div>    
</body>
</html>