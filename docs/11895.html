<html>
<head>
<title>Engaging customers through unsupervised and supervised learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过无监督和有监督的学习吸引客户</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/engaging-customers-through-unsupervised-and-supervised-learning-b2dfaf90f98f?source=collection_archive---------26-----------------------#2020-12-22">https://medium.com/analytics-vidhya/engaging-customers-through-unsupervised-and-supervised-learning-b2dfaf90f98f?source=collection_archive---------26-----------------------#2020-12-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="1682" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用无监督和有监督的方法在人口统计数据上吸引新客户和现有客户。</h2></div><h2 id="5493" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">概观</h2><p id="9e4a" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">本文将介绍两种选择邮件活动目标客户的方法:非监督方法和监督方法。使用python在jupyter笔记本中进行分析。</p><p id="a072" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">对于非监督方法，我有两个可用的数据集:德国的一般人口统计数据(891221行，366列)和包含客户人口统计数据的数据集(191652行，368列)。客户数据集包含人口统计数据集的所有列。我将训练一个KNN模型来识别德国的人群。之后，我将使用训练好的模型来识别客户数据中的分类。理想情况下，客户数据将由几个集群主导，然后可以在一般人群中定位。</p><p id="0f71" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">对于监督方法，我有一个客户数据集，其中有一个额外的列，指示客户过去是否对某个活动做出过响应。</p><h2 id="34d3" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">问题陈述</h2><p id="835b" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">问题是双重的:一方面，数据集包含许多包含分类值的列和许多nan。分类值需要被热编码，并在后面的步骤中通过主成分分析来减少。由于算法无法处理它们，因此需要移除、替换或估算nan。</p><p id="1ee9" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">另一方面，分析的问题或目标是找到一个在客户中代表过多的人口统计组，并预测现有客户对活动的反应。</p><p id="1e4b" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">我希望客户的无监督聚类会有好的结果，因为数据集包含了关于客户的详细人口统计信息。然而，对于客户响应的监督预测，我只期望得到一般的分数，因为只有少数响应出现在训练数据中。</p><h2 id="2531" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">韵律学</h2><p id="fbf5" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">我将专注于两个指标来评估无监督和有监督学习是否成功。对于非监督聚类，我希望人口统计数据中的聚类分布与客户数据中的显著不同。这将证明某些人口统计方面与对金融产品的兴趣相关，并因此有可能更准确地锁定新客户。</p><p id="f970" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">在客户反应的监督预测中，我将测量<a class="ae kt" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html" rel="noopener ugc nofollow" target="_blank">接收器操作特性曲线下的面积</a>，这是一个用于回忆处理概率的有用指标。我选择这个指标是因为我对尽可能多的正确预测(真阳性)感兴趣，并且不介意是否有假阳性。我不介意误报，因为邮寄几个不会回答的人成本比较低。这将有助于捕捉更多罕见的响应。</p><h2 id="a338" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">图书馆</h2><p id="67e6" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">我在项目中使用的库有:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="9543" class="ix iy hi kz b fi ld le l lf lg">import numpy as np<br/>import pandas as pd</span><span id="705d" class="ix iy hi kz b fi lh le l lf lg">import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="c6e7" class="ix iy hi kz b fi lh le l lf lg">from sklearn.model_selection import train_test_split<br/>from sklearn.ensemble import RandomForestRegressor<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.metrics import roc_auc_score<br/>from sklearn.svm import SVR</span><span id="837a" class="ix iy hi kz b fi lh le l lf lg">%matplotlib inline</span></pre><p id="ce67" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">由于每个数据科学项目都有80%的准备工作，所以让我们从数据检查开始，然后展开讨论。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><figure class="ku kv kw kx fd lq er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es lp"><img src="../Images/90cf7a4cb5549ff985d219caa44b19ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uhBhMQxCU5qmUt9kA8mSag.jpeg"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">由<a class="ae kt" href="https://unsplash.com/@markuswinkler?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">马库斯·温克勒</a>在<a class="ae kt" href="https://unsplash.com/s/photos/magnifying--blue?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="fc53" class="mb iy hi bd iz mc md me jd mf mg mh jh io mi ip jl ir mj is jp iu mk iv jt ml bi translated">数据检查</h1><p id="0e71" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">加载数据集后，最好通过各种函数全面了解您的数据，例如:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="0852" class="ix iy hi kz b fi ld le l lf lg">df.head()<br/>df.tail()<br/>df.shape # Not a function but an attribute!<br/>df.describe() </span><span id="bc73" class="ix iy hi kz b fi lh le l lf lg"># if you have a lot of columns you want to pass the follwing arguments to get a detailed report<br/>df.info(verbose = True, null_counts = True)</span></pre><p id="0c18" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">查看具有如下功能的单个列:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="00b5" class="ix iy hi kz b fi ld le l lf lg"># shows the unique values and how often they appear<br/>df.column_name.value_counts() </span></pre><p id="87d0" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">我使用以下功能检查了所有色谱柱的不平衡情况:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="fadc" class="ix iy hi kz b fi ld le l lf lg">def balance(df):<br/> data = []<br/> print(“Column balances printed in percent:”)<br/> for idx, column in enumerate(df.columns):<br/> bar_data = 100*df[column].value_counts()/df.shape[0]<br/> print(“{}: {}”.format(column, bar_data))<br/> data.append(bar_data)<br/> return data</span></pre><p id="71b0" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">大多数列的类别呈正态分布，但有些严重倾斜。例如，“阿格_TYP”在9年级有30 %的学生。</p><p id="dc08" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">此外，建议进行一些目视检查，特别是确定数据集中有多少NaN值。</p><p id="5b3d" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">计算NaN值的百分比，方法是对列中的值进行计数，然后除以列的长度。任何值都计为1，NaNs计为0。通过绘制百分比列表与列名的关系，可以得到下图。</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="8788" class="ix iy hi kz b fi ld le l lf lg">nan_values = []</span><span id="01b0" class="ix iy hi kz b fi lh le l lf lg">for column in df.columns:<br/>   n_nan = (len(df[column]) - df[column].count())/ len(df[column])<br/>   n_nan *= 100 #show values in percent<br/>   nan_values.append(n_nan)<br/><br/>plt.figure(figsize = (30,10))<br/>plt.bar(df.columns[:], nan_values[:])<br/>plt.xticks(rotation = 70);</span></pre><figure class="ku kv kw kx fd lq er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es mm"><img src="../Images/f7f9a22ac29fd844c8a3ee59659cb5a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*plfetC1s08rabaUvqcIA-w.png"/></div></div></figure><p id="f8d5" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">这是一个调查数据状态的图，所以记住它需要提供信息，但不要太漂亮，这一点很重要。重点是我想知道我在处理多少个NaN值。条形图很好地显示了我有几个可以删除的主要是nan的列。</p><p id="e19a" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">对于有15%-20%缺失数据的许多列，需要花费更多的时间进行决策。有三种可能的选择:</p><ul class=""><li id="ff7e" class="mn mo hi jx b jy ko kb kp ji mp jm mq jq mr kn ms mt mu mv bi translated">估算缺失值:查看<a class="ae kt" href="https://towardsdatascience.com/pandas-tricks-for-imputing-missing-data-63da3d14c0d6" rel="noopener" target="_blank">这篇文章</a>了解不同的策略。</li><li id="5452" class="mn mo hi jx b jy mw kb mx ji my jm mz jq na kn ms mt mu mv bi translated">检查缺少值的行，如果NaN值集中在10%的行中，则删除它们。</li><li id="1efc" class="mn mo hi jx b jy mw kb mx ji my jm mz jq na kn ms mt mu mv bi translated">对于数字列，用0替换它们，对于分类列，用one-hot编码它们。</li></ul><p id="79e2" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">在我的例子中，我选择了丢弃缺失值超过10%的行和对分类NaNs进行一次性编码的混合方法。我将在下一部分讨论这个问题。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h1 id="112b" class="mb iy hi bd iz mc nb me jd mf nc mh jh io nd ip jl ir ne is jp iu nf iv jt ml bi translated">数据争论</h1><figure class="ku kv kw kx fd lq er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es ng"><img src="../Images/7475ac3474536e78a65797319207c4cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OErh7TGJWDkQ0q06_pgaxA.jpeg"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">在<a class="ae kt" href="https://unsplash.com/s/photos/lego-white?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kt" href="https://unsplash.com/@elodieoudot?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Elodie Oudot </a>拍摄的照片</figcaption></figure><h2 id="5930" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">与NaNs打交道</h2><p id="a0dc" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">数据争论就是组织混乱，并将其转换成一种格式，以便我们的模型进行训练。</p><p id="a57d" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">首先，我开始处理我在检查部分确定的NaN值。</p><p id="a051" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">我创建了一个包含每行缺失值计数的列，然后在数据框中查询该列中的数字。因为我有超过200个专栏，所以20个大概不到10%。</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="caf7" class="ix iy hi kz b fi ld le l lf lg"># count how many values are missing per row<br/> df[“missing”] = df.apply(lambda x: (df.shape[1] — x.count()), axis = 1)<br/> # keep only rows with less than 20 values missing<br/> df_full = df.query(“missing &lt; 20”)</span></pre><h2 id="3fee" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">独热编码</h2><p id="0b6a" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">机器学习算法无法处理分类值。因此，我需要创建虚拟变量，这也被称为一次性编码。Pandas让一键编码变得非常简单:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="7e3e" class="ix iy hi kz b fi ld le l lf lg">df_dum = pd.get_dummies(df_full, columns = dummy_cols, drop_first = True, dummy_na = True)</span></pre><ul class=""><li id="a85b" class="mn mo hi jx b jy ko kb kp ji mp jm mq jq mr kn ms mt mu mv bi translated">dummy_cols是包含分类值的列的列表</li><li id="9f74" class="mn mo hi jx b jy mw kb mx ji my jm mz jq na kn ms mt mu mv bi translated">drop_first意味着如果一个列中有四个唯一的类别，它将创建三个虚拟列，因此它们是相互独立的</li><li id="d128" class="mn mo hi jx b jy mw kb mx ji my jm mz jq na kn ms mt mu mv bi translated">dummy_na = True为所有nan创建虚拟列</li></ul><h2 id="21e9" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">特征缩放</h2><p id="3659" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">少数数值列需要重新调整，因此具有大值的列不会对算法产生不适当的影响。这由以下人员完成</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="7f8d" class="ix iy hi kz b fi ld le l lf lg">from sklearn.preprocessing import StandardScaler<br/>scaler = StandardScaler()<br/>df[scale_cols] = scaler.fit_transform(df[scale_cols])</span></pre><p id="9fcc" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">“scale_cols”是数字列的列表。</p><h2 id="7e52" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">降维</h2><p id="71ae" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">拥有一个包含许多分类列的数据集，然后对它们进行一次性编码会产生大量的列。主成分分析(PCA)有助于显著减少列数。目标是保留足够的列来解释数据中90%以上的可变性。</p><p id="1899" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">下面的代码将有助于确定实现这一目的的主要组件的数量:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="c5f7" class="ix iy hi kz b fi ld le l lf lg">from sklearn.decomposition import PCA<br/>pca = PCA()</span><span id="d2b2" class="ix iy hi kz b fi lh le l lf lg">df_pca = pca.fit_transform(df)</span><span id="d888" class="ix iy hi kz b fi lh le l lf lg">cumm_values = []<br/>former = 0</span><span id="110c" class="ix iy hi kz b fi lh le l lf lg"># variable that makes sure the success print is only printed once<br/>first = True</span><span id="4ac2" class="ix iy hi kz b fi lh le l lf lg">for idx,value in enumerate(pca.explained_variance_ratio_):<br/> cumm_values.append(value+former)<br/> former += value<br/> if former &gt;= 0.9 and first:<br/> print(“{:.2f} % variance explained with {} components”.format(former*100, idx))<br/> first = False</span><span id="9bda" class="ix iy hi kz b fi lh le l lf lg">plt.plot(cumm_values);</span></pre><p id="adf1" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">除了2458列中的728列对于90%的可变性是足够的信息之外，我们还得到了下面的图表，它显示了附加组件的递减效用。</p><figure class="ku kv kw kx fd lq er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es nh"><img src="../Images/014be60c60874b727b3679e6d496f15e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bGYzX1ZFNGJexid2msjRsw.png"/></div></div></figure><p id="da1e" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">现在数据集可以用于机器学习算法了！将所有的数据清理步骤放在一个清理函数中是一个很好的做法，因为您将不得不对其他两个数据集执行相同的步骤。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h1 id="1fdb" class="mb iy hi bd iz mc nb me jd mf nc mh jh io nd ip jl ir ne is jp iu nf iv jt ml bi translated">无监督机器学习</h1><figure class="ku kv kw kx fd lq er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es ni"><img src="../Images/807674462a7a686c37e7a8cd1b5dd6b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jSly7GEj9b6ZDNu4rRrbUw.jpeg"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">照片由<a class="ae kt" href="https://unsplash.com/@alexblock?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Alex Block </a>在<a class="ae kt" href="https://unsplash.com/s/photos/sort?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="8a4f" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">为了识别人口统计数据集中的聚类，我使用了KMeans。一个重要的决定是我们应该为算法选择多少个聚类。这可以通过以下方式实现</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="65b1" class="ix iy hi kz b fi ld le l lf lg">from sklearn.cluster import KMeans</span><span id="1070" class="ix iy hi kz b fi lh le l lf lg">clusters = [2,4,6,8,10,12,14,16,18,20]</span><span id="331c" class="ix iy hi kz b fi lh le l lf lg"># Over a number of different cluster counts…<br/>kmeans_score = []<br/>for idx,n_cluster in enumerate(clusters):<br/> print(“Fitting kmeans with {} clusters”.format(n_cluster))<br/> # run k-means clustering on the data and…<br/> kmeans = KMeans(n_clusters=n_cluster, random_state=0).fit(df_pca)<br/> print(“Calculating the score…”)<br/> # compute the average within-cluster distances.<br/> kmeans_score.append(np.abs(kmeans.score(df_pca)))</span></pre><p id="5386" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">这将产生一个显示聚类数误差的图。理想的聚类数量位于“肘部”，在这里曲线的梯度变得明显更平坦。然而，正如你在下面看到的，在这种情况下没有明显的“肘”。我选择了12个集群，因为梯度在这一点上相对平坦。</p><figure class="ku kv kw kx fd lq er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es nh"><img src="../Images/39e081905cd0c98899293f95b1f3de59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZWn8VVDoBOlDGZaZkMmIvQ.png"/></div></div></figure><p id="21cc" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">人口统计数据的结果聚类可以通过首先在12个聚类上再次训练然后在数据上预测来确定:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="9ef4" class="ix iy hi kz b fi ld le l lf lg">kmeans = KMeans(n_clusters=12, random_state=0).fit(df_pca)<br/>preds = kmeans.predict(df_pca)<br/>df[“cluster”] = preds</span></pre><p id="1fd5" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">并且可视化为</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="b77e" class="ix iy hi kz b fi ld le l lf lg">sns.countplot(x = “cluster”,data = df, color = “grey” )</span></pre><figure class="ku kv kw kx fd lq er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es nj"><img src="../Images/93703923c4f7dfd876afd2c90ea839ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ba7BbP6xxq31XrlZkwYdog.png"/></div></div></figure><p id="6c78" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">然后，可以对客户数据使用经过训练的KMeans模型来预测其中的分类。<strong class="jx hj">确保对该数据集应用相同的数据争论步骤！</strong></p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="076a" class="ix iy hi kz b fi ld le l lf lg">customer_preds = kmeans.predict(customer_pca)<br/>customer_df["cluster"] = customer_preds<br/># Visualize the clusters in the customer dataset<br/>sns.countplot(x = "cluster", data = customer_df, color = "grey")</span></pre><p id="e8b1" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">这将导致以下集群分布:</p><figure class="ku kv kw kx fd lq er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es nj"><img src="../Images/ec03de742f03c2c2dfcf7e704eed6e5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WnCH_5rzsRjvPjZXIlZPFA.png"/></div></div></figure><p id="d09a" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">与德国的一般人口相比，客户主要集中在第5类。第11组中有中等数量，第2、4和8组中有少量。对于获取新客户，建议关注这些集群。</p><h2 id="2de1" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">集群的含义</h2><p id="e535" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">随着所有的数据转换，在这一点上不可能理解谁是客户获取的目标。但是，可以通过以下方式恢复所做的转换并深入了解集群</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="ec36" class="ix iy hi kz b fi ld le l lf lg">cluster_centers = kmeans.cluster_centers_<br/>cc = pca.inverse_transform(cluster_centers)<br/># -1 because we do not want the last "cluster column"<br/>cc_org = pd.DataFrame(cc, columns = customer_df.columns[:-1])</span></pre><p id="a92b" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">现在，使用反向PCA，检索每个聚类的10个最有影响力的列</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="7ee9" class="ix iy hi kz b fi ld le l lf lg">cc_org.iloc[11:12,:].T.sort_values(by = 11, ascending = False)[:10]</span></pre><p id="07aa" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">11是群集11。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h1 id="1662" class="mb iy hi bd iz mc nb me jd mf nc mh jh io nd ip jl ir ne is jp iu nf iv jt ml bi translated">监督学习</h1><figure class="ku kv kw kx fd lq er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es nk"><img src="../Images/d382feb4b801249de66edf24473e5d17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lRcRNTdUiE7NV-uItubmTA.jpeg"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">由<a class="ae kt" href="https://unsplash.com/@loomzing?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">米哈尔·洛姆扎</a>在<a class="ae kt" href="https://unsplash.com/s/photos/glass-sphere?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="3ab2" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">预测客户反应</h2><p id="42b1" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">对于最后一部分，我将利用第三个数据集和客户人口统计数据，包括客户是否对之前的活动作出回应的特征。</p><p id="2bb8" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">响应特征严重倾斜，有42430名客户没有响应，只有532名客户响应。</p><p id="5034" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">可以应用与无监督学习任务中相同的数据争论步骤。要开始训练一个模型，我们需要通过以下方式来分割训练和测试数据</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="f245" class="ix iy hi kz b fi ld le l lf lg"># splitting for training and testing<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)</span></pre><p id="9a7a" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">因为我将使用包含交叉验证的GridSearchCV，所以我只需要一小部分数据来测试模型。我训练的第一个模型是随机森林回归，因为我想要一个答案的概率，而不仅仅是1或0的分类。</p><h2 id="e0b9" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">随机森林回归量</h2><p id="a999" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">一个随机森林回归器需要相当长的时间来训练，所以在这个时候，我只搜索了四个不同的参数。</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="c469" class="ix iy hi kz b fi ld le l lf lg"># set up model<br/>reg = RandomForestRegressor()</span><span id="96b3" class="ix iy hi kz b fi lh le l lf lg"># set up parameters for grid search<br/>parameters = {‘n_estimators’:[20, 80], <br/>                 ‘max_depth’:[20, 30]}<br/>reg = GridSearchCV(reg, parameters, verbose = 10, scoring = “roc_auc”, cv = 5)<br/>reg.fit(X_train, y_train)</span></pre><p id="3e5c" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">我们不是通过准确性，而是通过回忆来判断结果。更有价值的是确定每个将回答活动的客户(真阳性)，并得到几个不会回答的错误客户(假阳性)。当我们预测概率时，<a class="ae kt" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html" rel="noopener ugc nofollow" target="_blank"> roc_auc_score </a>用于衡量绩效。</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="afe1" class="ix iy hi kz b fi ld le l lf lg">rfg_test_preds = reg.predict(X_test)</span><span id="c033" class="ix iy hi kz b fi lh le l lf lg">roc_auc_score(y_test, rfg_test_preds)<br/>&gt;&gt;&gt;0.5895173685828465</span></pre><p id="5ac7" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">调整前ROC得分:0.5563</p><p id="887a" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">调整后的ROC得分:0.5895</p><p id="8608" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">最佳超参数为:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="1754" class="ix iy hi kz b fi ld le l lf lg">{'bootstrap': True,<br/> 'ccp_alpha': 0.0,<br/> 'criterion': 'mse',<br/> 'max_depth': 20,<br/> 'max_features': 'auto',<br/> 'max_leaf_nodes': None,<br/> 'max_samples': None,<br/> 'min_impurity_decrease': 0.0,<br/> 'min_impurity_split': None,<br/> 'min_samples_leaf': 1,<br/> 'min_samples_split': 2,<br/> 'min_weight_fraction_leaf': 0.0,<br/> 'n_estimators': 20,<br/> 'n_jobs': None,<br/> 'oob_score': False,<br/> 'random_state': None,<br/> 'verbose': 0,<br/> 'warm_start': False}</span></pre><p id="a24f" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">只有很少的客户回答使预测变得非常棘手，并导致低分数。</p><h2 id="fc75" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">支持向量回归机</h2><p id="c582" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">支持向量回归机具有训练速度明显更快的优点，因此可以在搜索中包括更多的参数。它也是用GridSearchCV和</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="51a3" class="ix iy hi kz b fi ld le l lf lg"># set up model<br/>svc = SVR()</span><span id="e407" class="ix iy hi kz b fi lh le l lf lg"># set up parameters for grid search<br/>parameters = {‘C’:[0.1, 0.5, 1.5, 5], <br/> ‘degree’:[3, 4, 5],<br/> ‘kernel’: [“poly”, “rbf”]}<br/>reg_svc = GridSearchCV(svc, parameters, verbose = 10, scoring = “roc_auc”, cv = 5)<br/>reg_svc.fit(X_train, y_train)</span><span id="d109" class="ix iy hi kz b fi lh le l lf lg"># evaluating performance<br/>svc_test_preds = reg.predict(X_test)<br/>roc_auc_score(y_test, svc_test_preds)<br/>&gt;&gt;&gt; 0.6117327595040477</span></pre><p id="9b56" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">调整前ROC得分:0.59885</p><p id="a483" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">调整后的ROC得分:0.6248</p><p id="7e50" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">(交叉验证的平均值，因为测试集非常小)</p><p id="fa10" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">最佳参数为:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="7ffa" class="ix iy hi kz b fi ld le l lf lg">{'C': 5,<br/> 'cache_size': 200,<br/> 'coef0': 0.0,<br/> 'degree': 3,<br/> 'epsilon': 0.1,<br/> 'gamma': 'scale',<br/> 'kernel': 'rbf',<br/> 'max_iter': -1,<br/> 'shrinking': True,<br/> 'tol': 0.001,<br/> 'verbose': False}</span></pre><p id="4a32" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">支持向量回归机不仅训练速度更快，而且产生更好的结果。但是，结果仍然不在理想范围内。</p><h2 id="3fd3" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">模型评估和验证</h2><p id="6a2d" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">C的大值表明，当分类错误受到严重惩罚时，可以获得最好的结果，并且rbf核通常对于具有多个维度的复杂问题表现良好。</p><p id="0628" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">在训练中，交叉验证用于确保结果稳定，模型不会过度拟合:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="8c92" class="ix iy hi kz b fi ld le l lf lg">[CV] C=5, degree=3, kernel=rbf <br/>[CV] ...... C=5, degree=3, kernel=rbf, score=0.643, total=  46.6s<br/>[CV] C=5, degree=3, kernel=rbf <br/>[CV] ...... C=5, degree=3, kernel=rbf, score=0.584, total=  47.0s<br/>[CV] C=5, degree=3, kernel=rbf <br/>[CV] ...... C=5, degree=3, kernel=rbf, score=0.627, total=  47.6s<br/>[CV] C=5, degree=3, kernel=rbf <br/>[CV] ...... C=5, degree=3, kernel=rbf, score=0.609, total=  43.7s<br/>[CV] C=5, degree=3, kernel=rbf <br/>[CV] ...... C=5, degree=3, kernel=rbf, score=0.613, total=  47.5s</span></pre><h2 id="30c0" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">挑战</h2><p id="95a4" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">培训需要大量的时间，这使得迭代不同的方法非常困难。总响应量低使得很难识别数据中的模式，并且很难用监督学习算法获得好的结果。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h1 id="466d" class="mb iy hi bd iz mc nb me jd mf nc mh jh io nd ip jl ir ne is jp iu nf iv jt ml bi translated">正当理由；辩解</h1><p id="99d6" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">客户的非监督聚类工作得非常好，因为我能够提取客户所属的一个主要聚类，与一般人群进行比较。这将使公司能够很好地瞄准新客户，并推动转换率上升。</p><p id="b463" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">监督预测哪些客户会对活动作出反应，结果一般，但与向所有现有客户发送邮件相比，这已经大大提高了转化率。因此，这是朝着正确方向迈出的良好的第一步。</p><h1 id="825d" class="mb iy hi bd iz mc md me jd mf mg mh jh io mi ip jl ir mj is jp iu mk iv jt ml bi translated">结论</h1><p id="55f5" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">不出所料，数据争论耗费了大量时间。尤其困难的是处理大量的分类列和存在的许多NaN值。通过一键编码和随后的PCA降维，最终可能得到中等数量的列。</p><p id="e2ec" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">人口数据的无监督聚类和识别客户数据中的聚类是识别新的潜在客户以获取的好方法。它可以显著影响销售部门的转化率并降低成本。</p><p id="52b7" class="pw-post-body-paragraph jv jw hi jx b jy ko ij ka kb kp im kd ji kq kf kg jm kr ki kj jq ks kl km kn hb bi translated">客户反应的监督预测对于利用现有客户群中的潜力是极好的；然而，它只能提供平庸的结果。</p><h1 id="a3c9" class="mb iy hi bd iz mc md me jd mf mg mh jh io mi ip jl ir mj is jp iu mk iv jt ml bi translated">丰富</h1><p id="8ed6" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">更多的时间可以花在两个监督预测的参数搜索上，或者实现可以提供更好结果的神经网络。因为对随机森林回归器和支持向量回归器的两次网格搜索已经花费了很长时间，所以这次我没有包括更多的参数。</p></div></div>    
</body>
</html>