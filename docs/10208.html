<html>
<head>
<title>Face Mask Detector with OpenCV, Keras/Tensorflow and Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有OpenCV、Keras/Tensorflow和深度学习的人脸面具检测器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-mask-detector-with-opencv-keras-tensorflow-and-deep-learning-d2dcabdf5e2c?source=collection_archive---------10-----------------------#2020-10-09">https://medium.com/analytics-vidhya/face-mask-detector-with-opencv-keras-tensorflow-and-deep-learning-d2dcabdf5e2c?source=collection_archive---------10-----------------------#2020-10-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d40eefe9fb1cb818d9bb22790050720a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oID3e2UHdCJryGSdbw3NBQ.png"/></div></div></figure><p id="7308" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每个人都知道正在发生的新型冠状病毒疫情的情况。几乎每个国家都受到了毁灭性的冠状病毒(新冠肺炎)疾病的影响。疫情有可能逆转过去十年在全球卫生和人力资本方面来之不易的成果。强制隔离和社会隔离措施在很长一段时间内有效，这将有利于使传播曲线变平。人工智能可以在后COVID复苏中发挥重要作用，有助于提高生产率和培育新一代创新公司。虽然这种情况每天都在恶化，但为了保持安全，每个人都必须遵守一些规则，以免受到其后果的严重影响。</p><p id="3b6b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">前线战士正在努力挽救许多生命，但更多的是个人的责任，打好自己的仗，不损害自己的健康。建议的几个方法是:定期洗手，保持社交距离，定期戴口罩，如果身体不适，保持隔离</p><p id="4d41" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我尝试使用OpenCV、Keras/Tensorflow库设计了一个定制的深度学习模型，用于检测个人是否戴着面罩并发出警报。</p><h1 id="e70a" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">履行</h1><p id="a988" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">这里，在两个不同的阶段中应用人脸面具检测。第一阶段构成人脸面具检测器的训练，第二阶段处理将人脸面具检测器模型应用于测试图像或实时视频流。在第一阶段，我们首先加载人脸面具数据集，然后使用Keras和Tensorflow库训练人脸面具分类器，最后将人脸面具分类器序列化到磁盘。在第二阶段，首先我们从磁盘上加载人脸面具分类器。我们用它来检测图像或视频流中的人脸，并提取每个人脸的感兴趣区域。然后对人脸的每个感兴趣区域应用人脸面具分类器来判断人是否戴了面具，最后显示结果。我们还发现在确定正确结果时获得的准确性。</p><p id="3bb0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据集描述:这里用于训练模型的数据集是由PyImageSearch阅读器之一创建的。它由大约1376个图像组成，并且图像被分类为两个一组，即，具有包含690个图像的掩模和不具有包含686个图像的掩模。</p><p id="fb69" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们对<a class="ae kr" href="https://arxiv.org/abs/1801.04381" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> MobileNet V2架构</strong> </a>进行了微调，这是一种高效的架构，可应用于计算能力有限的嵌入式设备。将我们的面罩检测器部署到嵌入式设备将有助于降低制造这种面罩检测系统的成本，因此我们选择使用这种架构。</p><p id="e004" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们导入实现所需的所有必要的库，其中一些是:</p><ul class=""><li id="17bc" class="ks kt hi is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la bi translated"><em class="lb"> tensorflow.keras </em>用于数据扩充，加载MobilNetV2分类器，构建新的全连接(FC)头，预处理，加载图像数据，sklearn，imutils，matplotlib，numpy等。</li><li id="0502" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">sklearn 用于二值化类别标签、分割数据集以及打印分类报告。</li><li id="6539" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated"><a class="ae kr" href="https://github.com/jrosebr1/imutils/" rel="noopener ugc nofollow" target="_blank"><em class="lb">imutils</em></a><strong class="is hj"/>路径实现在我们的数据集中查找并列出图像。</li><li id="f8ae" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated"><em class="lb"> matplotlib </em>绘制我们的训练曲线。</li></ul><p id="9bfb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，我们构造参数解析器，解析运行代码时所需的命令行参数。然后，我们指定超参数常数，包括初始学习速率、训练时期数和批量大小。</p><h2 id="8cb9" class="lh jp hi bd jq li lj lk ju ll lm ln jy jb lo lp kc jf lq lr kg jj ls lt kk lu bi translated"><strong class="ak">第一阶段:培训</strong></h2><p id="16eb" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated"><strong class="is hj">步骤1: </strong>加载并预处理我们的训练数据，然后为数据扩充做准备，包括:</p><ul class=""><li id="62b3" class="ks kt hi is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la bi translated">获取数据集目录中的图像列表，然后初始化数据(即图像)和类图像列表</li><li id="6b11" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">预处理图像</li><li id="9ca5" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">将训练数据转换为Numpy数组格式</li><li id="cc59" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">编码标签(一键编码)</li><li id="3ac8" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">使用scikit-learn库将数据集划分为训练集(80%)和测试集(20%)</li></ul><p id="5983" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">准备<strong class="is hj"> MobileNetV2 </strong>进行微调:</p><ul class=""><li id="483e" class="ks kt hi is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la bi translated">用预先训练好的<a class="ae kr" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> ImageNet </strong> </a>权重加载MobileNet，离开网络头部</li><li id="33db" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">构建一个新的FC头，并将其附加到基础上以代替旧的头</li><li id="6d3d" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">冻结网络的基础层。在反向传播过程中，这些基本层的权重不会被更新，而头部层的权重将被调整。</li></ul><p id="9e84" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第二步:</strong>编译和训练面罩检测器网络:</p><ul class=""><li id="94c6" class="ks kt hi is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la bi translated">使用Adam优化器、学习率衰减计划和二进制交叉熵编译模型(因为只有2个类)</li><li id="ee53" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">使用model.fit方法及其所需参数训练网络的头</li></ul><p id="5f13" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过在测试集上进行预测，抓取最高概率类标签索引，在测试集上评估结果模型。然后，我们打印一份分类报告供检查。</p><p id="8ff8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤3: </strong>然后，我们将我们的面罩分类模型序列化到磁盘上。此外，我们还绘制了精度和损耗曲线。</p><figure class="lw lx ly lz fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/285b702caa1e92834f831868ed6d9696.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*lbD33B4P3TxdXpRIzpyHrw.png"/></div></figure><p id="d1fe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们可以观察到，我们的测试集几乎有97%的准确率。</p><h1 id="c8f5" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">实现图像的面罩检测器</h1><p id="2ce7" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">我们导入tensorflow和keras库来加载MaskNet模型并对图像进行预处理。</p><p id="12da" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">OpenCV用于读取、写入、显示图像和视频，并在其中进行一些操作。</p><p id="9afa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">命令行参数包括:</p><ul class=""><li id="c850" class="ks kt hi is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la bi translated">—图像:包含用于推断的面的输入图像的路径</li><li id="824e" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">— face:人脸检测器模型目录的路径(我们需要在分类之前定位人脸)</li><li id="da19" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">—模型:我们在本教程前面训练的面罩检测器模型的路径</li><li id="e2fe" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">—置信度:可选的概率阈值可以设置为覆盖50%,以过滤弱面部检测</li></ul><h2 id="371f" class="lh jp hi bd jq li lj lk ju ll lm ln jy jb lo lp kc jf lq lr kg jj ls lt kk lu bi translated"><strong class="ak">第二阶段:部署</strong></h2><p id="c136" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated"><strong class="is hj">步骤1: </strong>我们加载人脸检测器和人脸面具分类器模型。下一步是加载和预处理输入图像。预处理由<strong class="is hj"> OpenCV的blobFromImage函数处理。</strong></p><p id="208f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤2: </strong>然后，我们循环检查我们的检测，并提取置信度，以对照置信度阈值进行测量。</p><p id="0bf0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤3: </strong>然后，我们计算特定人脸的边界框值，并确保该框落在图像的边界内。</p><p id="dd68" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤4: </strong>接下来，我们将通过我们的MaskNet模型运行面部ROI(通过Numpy切片提取)。</p><p id="3d48" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤5: </strong>之后，我们基于掩模检测器模型返回的概率确定类别标签，并为注释分配相关联的颜色。此处的颜色将为“绿色”表示有_mask，为“红色”表示无_mask。然后，我们使用OpenCV绘图函数绘制标签文本(包括类别和概率)，以及人脸的边界框矩形。处理完所有检测后，将显示输出。</p><h1 id="4c9c" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">输出</h1><figure class="lw lx ly lz fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/85813a71fba1d199e8e262a01c916e67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*3xVuFEE2txHhpH0idJ7nZg.jpeg"/></div></figure><p id="2260" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，我们看到，在上述样本图像中，人脸面具检测器模型以96.56%的置信度正确地标记了“面具”，以99.52%的置信度正确地标记了“无面具”。</p><h1 id="6232" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">实时视频流中人脸检测器的实现</h1><p id="47a8" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">为了检测一个人是否戴着面具，我们需要处理视频中的每一帧。要做到这一点，我们只需要将VideoStream类导入到我们的代码中，其余的过程与我们对图像应用面具检测器模型的过程相同。</p><p id="da13" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们定义了一个函数来检测和预测人脸面具。该函数被传递了三个参数</p><ul class=""><li id="067d" class="ks kt hi is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la bi translated">帧:从实时网络摄像头流中捕获</li><li id="7bce" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">faceNet:检测图像中人脸的训练模型</li><li id="fed8" class="ks kt hi is b it lc ix ld jb le jf lf jj lg jn kx ky kz la bi translated">maskNet:人脸面具分类模型</li></ul><p id="e8f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们从循环面部检测开始，并过滤掉小于最小置信度阈值的面部检测。之后，我们从图像中提取所需的边界框。然后，提取的ROI通过掩模预测器。首先，我们检查帧中是否至少有一个人脸，如果没有，我们直接从那里返回，但是如果我们在整批帧中找到人脸，我们预测它的位置，并了解遮罩是否存在。根据我们得到的预测，我们然后确定要在图像上打印的标签作为蒙版/无蒙版的标签，并且如果没有蒙版，边界框的颜色设置为红色，如果有蒙版，则设置为绿色。</p><p id="f766" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我的Github资源库链接<a class="ae kr" href="https://github.com/ManaliSeth/Face-Mask-Detection" rel="noopener ugc nofollow" target="_blank"><strong class="is hj"/></a>中提供了完整的源代码供参考</p><p id="3cba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">希望这整个文档对所有致力于OpenCV、深度学习和面具检测概念的人有用。</p></div></div>    
</body>
</html>