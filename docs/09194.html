<html>
<head>
<title>Classification of COVID-19 victims using Machine Learning Models.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习模型对新冠肺炎受害者进行分类。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classification-of-covid-19-victims-using-machine-learning-models-d70daee964ff?source=collection_archive---------17-----------------------#2020-08-28">https://medium.com/analytics-vidhya/classification-of-covid-19-victims-using-machine-learning-models-d70daee964ff?source=collection_archive---------17-----------------------#2020-08-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="24cd" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">介绍(当前需要)</h2></div><p id="c815" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">机器学习主要应用于医学领域，自动化破解数字运算算法等。</p><p id="d567" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">新冠肺炎是人类有史以来面临的最黑暗的时代之一，它全力以赴争取 2020 年，给我们的后代留下了一个黑点。</p><p id="8e02" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">研究人员、学者和专业人士在他们各自的领域都在努力使我们摆脱疫情的困境。</p><p id="08a2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在是我们在各自的专业领域为他们的工作做出贡献的时候了。这个博客是关于 COVID 受害者的分类，分为轻度、重度和危重。基于此，我们可以建议是否将患者隔离、送入医院或使用呼吸机，这只是解决问题的一种幼稚方法，可以通过批判性思维和利用复杂的算法进入下一阶段。</p><h2 id="4928" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">关于数据集</h2><p id="d979" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">数据集取自 Kaggle，它包含许多对构建模型至关重要的属性，还包含特定患者的病史、血样、糖尿病、疾病等。</p><p id="6dc5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据集非常庞大，包含浮点数据和分类数据。</p><p id="10f6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">主要观察结果</strong></p><ol class=""><li id="784a" class="kt ku hi iz b ja jb jd je jg kv jk kw jo kx js ky kz la lb bi translated">这里的关键观察点是，数据集作为一个整体是稀疏的，并且没有特定字段下的所有必需数据，由于样本未被收集或不可用于该字段，一些数据丢失。</li><li id="3444" class="kt ku hi iz b ja lc jd ld jg le jk lf jo lg js ky kz la lb bi translated">数据集中的所有属性对我们将要构建的机器学习模型都没有显著贡献。</li><li id="73d1" class="kt ku hi iz b ja lc jd ld jg le jk lf jo lg js ky kz la lb bi translated">输入分类特征可能会导致没有意义的虚假元组。所以我们忽略了数据集中的分类特征。</li></ol><p id="b73d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是数据集的几幅图像</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lh"><img src="../Images/b2c97b99d94cfca2fe5f5facd6a0d61f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VDtL9r0u8vZvogrAfV2jbw.png"/></div></div></figure><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lt"><img src="../Images/3f944ec16b16dbbc430cdef26dc7619b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JTZWjvZ863A3TfWKvvMa9w.png"/></div></div></figure><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lu"><img src="../Images/c6f5830fd049df769d320e2f83b376b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TqklG1y1Bf5L-5WfnVNHvA.png"/></div></div></figure><p id="f2f1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这只是数据集的样本视图。</p><p id="290f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们所见，有许多值是未知的或 Nan 值，因此我们必须在应用模型之前填补这些漏洞。</p><h2 id="6411" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">如何估算数据集？</h2><p id="74c9" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">在跳到我们的想法之前，让我们先探索一下常规的方法。</p><ol class=""><li id="d57d" class="kt ku hi iz b ja jb jd je jg kv jk kw jo kx js ky kz la lb bi translated"><strong class="iz hj">简单地忽略列— </strong>但在这种情况下不能这样做，因为这是一个稀疏的数据集，删除后我们将只剩下少量的属性，重要的属性可能会丢失。</li><li id="8025" class="kt ku hi iz b ja lc jd ld jg le jk lf jo lg js ky kz la lb bi translated"><strong class="iz hj">用集中趋势</strong>进行估算——在传统的机器学习模型中，我们使用整个列的<strong class="iz hj"> NaN </strong>值和<strong class="iz hj"> <em class="lv"> mean </em> </strong>进行估算，因为每个列都很稀疏，所以很难找到平均值，因为由于缺少太多的值，找到的平均值不会接近实际平均值。</li></ol><p id="07d7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，在这种情况下，我们必须打破常规，因为非常时期需要非常手段。</p><p id="9a6c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们首先训练一个模型来预测丢失的值，但这也不简单，因为我们必须拥有领域和统计方面的专业知识。</p><p id="3ebb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但这是为了说明多元线性回归在剔除无关紧要的属性中的应用。</p><p id="7474" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对数据集进行插补的方式是:</p><ol class=""><li id="16c6" class="kt ku hi iz b ja jb jd je jg kv jk kw jo kx js ky kz la lb bi translated">在分类的第一阶段忽略分类数据，因为由于它们的二元“是”或“否”属性，输入它们是没有意义的。</li><li id="4d6e" class="kt ku hi iz b ja lc jd ld jg le jk lf jo lg js ky kz la lb bi translated">用适当的集中趋势度量来估算真实值。</li></ol><h2 id="24a1" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">机器学习模型是如何应用的？</h2><p id="1459" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">一旦我们估算了数据集，现在我们需要使用反向消除法(多元线性回归)从数据集中消除无关紧要的属性。</p><p id="9611" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">逆向淘汰的概念在我之前的博客里有详细的解释，这只是之前博客的延续。</p><p id="b5c7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦上述程序完成，现在就可以开始应用各种分类模型了。</p><p id="42ad" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">给出最佳结果的模型是</p><ol class=""><li id="01e9" class="kt ku hi iz b ja jb jd je jg kv jk kw jo kx js ky kz la lb bi translated">支持向量机(90.8%)</li><li id="b124" class="kt ku hi iz b ja lc jd ld jg le jk lf jo lg js ky kz la lb bi translated">决策树分类器(89.54%)</li></ol><p id="91e4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我利用混淆矩阵来形象化输出如何分布在不同的类中。</p><p id="5611" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">代码如下所示</p><pre class="li lj lk ll fd lw lx ly lz aw ma bi"><span id="e4b2" class="jt ju hi lx b fi mb mc l md me">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt</span><span id="7580" class="jt ju hi lx b fi mf mc l md me">dataset = pd.read_csv("dataset1.csv",encoding = 'latin1')<br/>dataset</span><span id="4779" class="jt ju hi lx b fi mf mc l md me">x = dataset.iloc[:,1:-4].values<br/>y = dataset.iloc[:,-4].values</span><span id="8320" class="jt ju hi lx b fi mf mc l md me"><strong class="lx hj">#Imputing values</strong><br/>from sklearn.preprocessing import Imputer<br/>imputer = Imputer(missing_values = 'NaN',strategy = 'mean')<br/>imputer = imputer.fit(x[:,:])<br/>x[:,:] = imputer.transform(x[:,:])</span><span id="8376" class="jt ju hi lx b fi mf mc l md me"><strong class="lx hj">#LabelEncoding Y part</strong><br/>from sklearn.preprocessing import LabelEncoder<br/>labelencoder_y = LabelEncoder()<br/>y = labelencoder_y.fit_transform(y) </span><span id="de08" class="jt ju hi lx b fi mf mc l md me"><strong class="lx hj">#Dividing the dataset into training and testing</strong><br/>from sklearn.model_selection import train_test_split<br/>x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 0)</span><span id="350d" class="jt ju hi lx b fi mf mc l md me">#<strong class="lx hj">Standardize using StandardScaler<br/></strong>from sklearn.preprocessing import StandardScaler<br/>sc_X = StandardScaler()<br/>x_train = sc_X.fit_transform(x_train)<br/>x_test = sc_X.fit(x_test)</span><span id="a512" class="jt ju hi lx b fi mf mc l md me">import statsmodels.formula.api as sm<br/><strong class="lx hj">#Applying the Backward Elimination</strong><br/>def BackwardElim(x,sl):<br/>    n = len(x[0])<br/>    for i in range(0,n):<br/>        regressor_OLS = sm.OLS(y,x).fit()<br/>        maxp = max((regressor_OLS.pvalues).astype(float))<br/>        if maxp &gt; sl:<br/>            for j in range(0,n-i):<br/>                if(maxp == regressor_OLS.pvalues[j].astype(float)):<br/>                    x = np.delete(x,j,1)<br/>                    <br/>    regressor_OLS.summary()<br/>    return x</span><span id="c1ed" class="jt ju hi lx b fi mf mc l md me">sl = 0.05<br/>x_opt = x<br/>x_model = BackwardElim(x_opt,sl)<br/>x_model.shape</span><span id="042b" class="jt ju hi lx b fi mf mc l md me">from sklearn.model_selection import train_test_split<br/>x_train,x_test,y_train,y_test = train_test_split(x_model,y,test_size = 0.2,random_state = 0)</span><span id="ae0e" class="jt ju hi lx b fi mf mc l md me"><strong class="lx hj">#Applying RandomForest<br/></strong>from sklearn.ensemble import RandomForestClassifier<br/>classifier = RandomForestClassifier(n_estimators = 10,criterion = 'entropy',random_state = 0)<br/>classifier.fit(x_train,y_train)</span><span id="04fe" class="jt ju hi lx b fi mf mc l md me">y_pred = classifier.predict(x_test)</span><span id="6279" class="jt ju hi lx b fi mf mc l md me">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix(y_test,y_pred)<br/>classifier.score(x_test,y_test)</span><span id="87a8" class="jt ju hi lx b fi mf mc l md me"><strong class="lx hj">#Applying SVM<br/></strong>from sklearn.svm import SVC<br/>classifier = SVC(kernel = 'linear',C=1)<br/>classifier.fit(x_train,y_train)</span><span id="48e9" class="jt ju hi lx b fi mf mc l md me">y_pred = classifier.predict(x_test)</span><span id="56a0" class="jt ju hi lx b fi mf mc l md me">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix(y_test,y_pred)<br/>classifier.score(x_test,y_test)</span><span id="4596" class="jt ju hi lx b fi mf mc l md me"><strong class="lx hj">#Applying Decision Tree<br/></strong>from sklearn.tree import DecisionTreeClassifier<br/>classifier = DecisionTreeClassifier(criterion = 'entropy',random_state = 0)<br/>classifier.fit(x_train,y_train)</span><span id="3a3c" class="jt ju hi lx b fi mf mc l md me">y_pred = classifier.predict(x_test)</span><span id="d1d1" class="jt ju hi lx b fi mf mc l md me">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix(y_test,y_pred)<br/>classifier.score(x_test,y_test)</span></pre><p id="112f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以上是我用于分类的确切代码，如果有人需要数据集，他们可以给我发消息。</p><h2 id="9b1d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">未来范围</h2><p id="3913" class="pw-post-body-paragraph ix iy hi iz b ja ko ij jc jd kp im jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">该模型可以在其应用和准确性方面进一步完善。</p><ol class=""><li id="05ad" class="kt ku hi iz b ja jb jd je jg kv jk kw jo kx js ky kz la lb bi translated">为了提高精确度，我们可以利用我们忽略的分类变量。</li><li id="2983" class="kt ku hi iz b ja lc jd ld jg le jk lf jo lg js ky kz la lb bi translated">我们可以使用 k-fold 交叉验证、梯度增强、集成学习等来调整参数。</li></ol><p id="7c3f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">剩下的就交给你了，让你集思广益来解决这个问题。</p></div></div>    
</body>
</html>