<html>
<head>
<title>Scraping A to Z of Amazon using Scrapy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scrapy从A到Z抓取亚马逊</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-a-to-z-using-scrapy-6ece8b303793?source=collection_archive---------0-----------------------#2020-03-14">https://medium.com/analytics-vidhya/web-scraping-a-to-z-using-scrapy-6ece8b303793?source=collection_archive---------0-----------------------#2020-03-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/3bf8581b9d531cdcfae641b0a83c4ded.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nnOHvjAk-4p6NcR6NKOC4w.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">Pexels.com</figcaption></figure><div class=""/><blockquote class="iu iv iw"><p id="0ee1" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">Scrapy是一个用Python编写的快速、开源的web爬行框架，用于在基于XPath的选择器的帮助下从网页中提取数据。</p></blockquote><p id="d33e" class="pw-post-body-paragraph ix iy hx ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv hb bi translated">在这篇文章中，我们将了解如何使用Scrapy来抓取所有的亚马逊产品评论，并在几秒钟内将所有抓取的数据自动存储到一个JSON文件中。</p></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><blockquote class="iu iv iw"><p id="b61a" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">快速注释:报废的项目:</p></blockquote><ol class=""><li id="7de0" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv kl km kn ko bi translated"><em class="iz">审核人姓名</em></li><li id="697d" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated"><em class="iz">点评人简介链接</em></li><li id="8e5f" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated"><em class="iz">审查评级</em></li><li id="9f49" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated"><em class="iz">复习题目</em></li><li id="72dc" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated"><em class="iz">文字回顾</em></li><li id="6acf" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated"><em class="iz">审查日期</em></li><li id="d980" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated"><em class="iz">已验证的采购标签</em></li><li id="1abc" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated"><em class="iz">对复习有帮助的次数</em></li></ol></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><h1 id="fd8f" class="ku kv hx bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">我们开始吧</h1><blockquote class="iu iv iw"><p id="7ae6" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">设置项目</p></blockquote><ul class=""><li id="845c" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">在此，我假设你已经运行了你的pip，并且知道如何创建和激活一个Python虚拟环境，如果没有的话，查看一下这个<a class="ae lt" href="https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/" rel="noopener ugc nofollow" target="_blank">官方文档</a>了解一下。</li><li id="a566" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv ls km kn ko bi translated">现在首先，进入你的终端，激活你的虚拟环境，如果你还没有安装Scrapy，那么使用，</li></ul><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="59d7" class="md kv hx lz b fi me mf l mg mh">pip install scrapy</span></pre><ul class=""><li id="ecb9" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">现在从您的终端进入您想要启动和运行项目的目录(注意:教程是我们正在创建的项目的名称)</li></ul><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="d6c8" class="md kv hx lz b fi me mf l mg mh">scrapy startproject tutorial</span></pre><ul class=""><li id="6f21" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">在此之后，您的项目结构将如下所示，</li></ul><figure class="lu lv lw lx fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mi"><img src="../Images/f42274591c3958f098cd3c6ec8d4c2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jgjx5e6K97BOo41_LcQfRA.jpeg"/></div></div></figure><ul class=""><li id="a631" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">现在在spiders目录中创建一个“amazon_scraping.py”文件</li></ul><blockquote class="iu iv iw"><p id="9b6b" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">编写代码</p></blockquote><p id="3d2e" class="pw-post-body-paragraph ix iy hx ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv hb bi translated">打开您刚刚创建的“amazon_scraping.py”文件，让我们开始编码，</p><ul class=""><li id="85da" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">首先，导入这些基本库，</li></ul><figure class="lu lv lw lx fd hk"><div class="bz dy l di"><div class="mj mk l"/></div></figure><ul class=""><li id="9e4d" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">创建一个python类，定义我们想要抓取的所有变量</li></ul><figure class="lu lv lw lx fd hk"><div class="bz dy l di"><div class="mj mk l"/></div></figure><ul class=""><li id="dbed" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">创建一个主类，Scrapy将在这个主类上收集数据</li></ul><figure class="lu lv lw lx fd hk"><div class="bz dy l di"><div class="mj mk l"/></div></figure><ul class=""><li id="fe28" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">在同一个类中定义一个函数，该函数将用于抓取你上面提到的链接，以获得亚马逊页面上“所有评论标签”的链接。</li></ul><figure class="lu lv lw lx fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ml"><img src="../Images/65a56969ef71b80676ff88d6a9aee1b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nanQbfmsjlhtEQvsHzo59Q.png"/></div></div></figure><figure class="lu lv lw lx fd hk"><div class="bz dy l di"><div class="mj mk l"/></div></figure><ul class=""><li id="686b" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">现在Scrapy在亚马逊的“所有评论页面”上，所以现在我们将编写一个函数，该函数将为所有上述项目抓取该页面，并将其存储在JSON文件中。</li></ul><figure class="lu lv lw lx fd hk"><div class="bz dy l di"><div class="mj mk l"/></div></figure><ul class=""><li id="a026" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">现在，我们已经得到了所有的项目，并已被追加到JSON文件，现在是时候告诉Scrapy去下一页，并重复上述过程。</li></ul><figure class="lu lv lw lx fd hk"><div class="bz dy l di"><div class="mj mk l"/></div></figure><figure class="lu lv lw lx fd hk er es paragraph-image"><div class="er es mm"><img src="../Images/a7e4d6c2ad5dfd8aedc81f27514ba583.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*7iFYhYdlUSYVAvR5YGghlA.jpeg"/></div></figure><blockquote class="iu iv iw"><p id="d3cf" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">运行代码</p></blockquote><ul class=""><li id="35d7" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">进入教程目录并在终端中运行以下命令，</li></ul><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="c34f" class="md kv hx lz b fi me mf l mg mh">scrapy crawl reviewspider -t json -o outputfile.json</span></pre><ul class=""><li id="2b2b" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">在此之后，您应该会看到在教程文件夹中创建了一个文件名为<outputfile.json>的文件，其中包含了所有抓取的数据。</outputfile.json></li><li id="70b9" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv ls km kn ko bi translated">您可能会在终端<strong class="ja hy">、</strong>中得到<strong class="ja hy"> 503服务不可用</strong>这是因为我们可能会给服务器带来太多负载，要解决这个问题，请转到tutorial/settings.py并添加以下代码，然后尝试运行，</li></ul><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="60d0" class="md kv hx lz b fi me mf l mg mh">DOWNLOAD_TIMEOUT = 540<br/>DOWNLOAD_DELAY = 5</span><span id="4a6a" class="md kv hx lz b fi mn mf l mg mh">DEPTH_LIMIT = 10</span><span id="30e8" class="md kv hx lz b fi mn mf l mg mh">EXTENSIONS = {<br/>    'scrapy.extensions.telnet.TelnetConsole': None,<br/>    'scrapy.extensions.closespider.CloseSpider': 1<br/>}</span></pre><ul class=""><li id="e68c" class="kg kh hx ja b jb jc jf jg jw ki jx kj jy kk jv ls km kn ko bi translated">上面几行代码是为了确保我们不会给amazon服务器带来太多的负载，你可以随时调整上面的参数来让它运行。更多设置请查看<a class="ae lt" href="https://docs.scrapy.org/en/latest/topics/settings.html" rel="noopener ugc nofollow" target="_blank">剪贴簿文档</a>。</li></ul><h1 id="3439" class="ku kv hx bd kw kx mo kz la lb mp ld le lf mq lh li lj mr ll lm ln ms lp lq lr bi translated">结论</h1><ul class=""><li id="622f" class="kg kh hx ja b jb mt jf mu jw mv jx mw jy mx jv ls km kn ko bi translated">因此，在短短几行代码中，我们编写了整个Scrapy项目，该项目将只使用产品URL来抓取每个页面上产品评论的所有细节。</li><li id="a5f8" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv ls km kn ko bi translated">欢迎在评论区提出你对这篇文章的疑问。</li><li id="78b5" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv ls km kn ko bi translated">在<a class="ae lt" href="https://www.linkedin.com/in/rohan-goel-b0a6ab160/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系。</li><li id="2794" class="kg kh hx ja b jb kp jf kq jw kr jx ks jy kt jv ls km kn ko bi translated">在后续的<a class="ae lt" rel="noopener" href="/analytics-vidhya/integrating-scrapy-with-flask-8611debc4579">文章</a>中，我已经解释了我们如何进一步将这个<strong class="ja hy">碎片代码</strong>与<strong class="ja hy"> FLASK </strong>集成，并构建一个web表单，这样点击一个按钮，你就可以运行整个代码并获得碎片数据。</li></ul></div></div>    
</body>
</html>