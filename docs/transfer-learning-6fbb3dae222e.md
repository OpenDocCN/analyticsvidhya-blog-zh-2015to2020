# 转学！

> 原文：<https://medium.com/analytics-vidhya/transfer-learning-6fbb3dae222e?source=collection_archive---------16----------------------->

![](img/e03ecace20ba430029388a35d7c32d3b.png)

# **简介**

迁移学习是一种机器学习方法，其中为一项任务开发的模型被重新用作第二项任务模型的起点。

这是深度学习中的一种流行方法，其中预先训练的模型被用作计算机视觉和自然语言处理任务的起点，因为开发这些问题的神经网络模型需要大量的计算和时间资源，并且它们在相关问题上提供了巨大的技能飞跃。

这种在深度学习中使用的迁移学习形式叫做归纳迁移。这是通过在不同但相关的任务上使用模型拟合，以有益的方式缩小可能模型的范围(模型偏差)的地方。

**如何利用迁移学习？**

迁移学习可以用于你自己的预测建模问题。

两种常见的方法如下:

1.  开发一种模型方法
2.  预训练模型方法

**开发模型方法**

1.  **选择源任务**。您必须选择具有大量数据的相关预测建模问题，其中输入数据、输出数据和/或在从输入数据到输出数据的映射过程中学习到的概念之间存在某种关系。
2.  **开发源模型**。接下来，你必须为第一个任务开发一个熟练的模型。该模型必须比天真的模型更好，以确保已经执行了一些特征学习。
3.  **复用模式**。然后，源任务上的模型拟合可以用作感兴趣的第二个任务上的模型的起点。这可能涉及使用模型的全部或部分，取决于所使用的建模技术。
4.  **调谐模式**。可选地，该模型可能需要根据可用于感兴趣的任务的输入-输出对数据进行调整或改进。

# 预训练模型方法

1.  **选择源型号**。从可用模型中选择预训练的源模型。许多研究机构发布大型和挑战性数据集上的模型，这些数据集可能包含在候选模型池中以供选择。
2.  **复用模式**。然后，模型预训练模型可以用作感兴趣的第二任务的模型的起点。这可能涉及使用模型的全部或部分，取决于所使用的建模技术。
3.  **调谐模式**。可选地，该模型可能需要根据可用于感兴趣的任务的输入-输出对数据进行调整或改进。

# 微调模型的方法

**1。特征提取** —我们可以使用预先训练的模型作为特征提取机制。我们可以做的是，我们可以删除输出层(给出 1000 个类别中每个类别的概率的层)，然后使用整个网络作为新数据集的固定特征提取器。

**2。使用预训练模型的架构—** 我们可以做的是使用模型的架构，同时随机初始化所有权重，并根据我们的数据集再次训练模型。

**3。训练一些层，同时冻结其他层** —使用预训练模型的另一种方式是训练部分。我们能做的是保持模型初始层的权重不变，而只重新训练较高的层。我们可以尝试和测试冻结多少层，训练多少层。

# **场景**

以下给出了四种不同的场景

**场景 1 —数据集的大小很小，而数据相似度很高—** 在这种情况下，由于数据相似度很高，我们不需要重新训练模型。我们需要做的就是根据我们的问题陈述定制和修改输出层。我们使用预先训练的模型作为特征提取器。假设我们决定使用在 Imagenet 上训练的模型来识别新的图像集是否有猫或狗。这里，我们需要识别的图像类似于 imagenet，但是，我们只需要两个类别作为我的输出——猫或狗。在这种情况下，我们所做的只是修改密集层和最终的 softmax 层，以输出 2 个类别，而不是 1000。

**场景 2 —数据规模很小，数据相似性很低** —在这种情况下，我们可以冻结预训练模型的初始(假设为 k)层，并再次训练剩余的(n-k)层。然后，顶层将根据新数据集进行定制。由于新数据集具有低相似性，因此根据新数据集重新训练和定制更高层是很重要的。数据集的小尺寸通过以下事实得到补偿，即初始层保持预训练(其先前已经在大数据集上训练过),并且这些层的权重被冻结。

**场景 3——数据集的规模很大，但是数据相似性很低** —在这种情况下，由于我们有一个大型数据集，我们的神经网络训练将是有效的。然而，由于我们拥有的数据与用于训练我们的预训练模型的数据相比非常不同。使用预先训练的模型做出的预测是无效的。因此，最好根据你的数据从头开始训练神经网络。

**场景 4 —数据量很大，并且数据相似度很高—** 这是理想的情况。在这种情况下，预训练模型应该是最有效的。使用模型的最佳方式是保留模型的架构和模型的初始权重。然后，我们可以使用预训练模型中初始化的权重来重新训练该模型。

感谢阅读！！！

我希望你喜欢这个博客。欢迎在评论区分享你的想法，你也可以和我联系:-
Linkedin—[https://www.linkedin.com/in/shreyak007/](https://www.linkedin.com/in/shreyak007/)
Github—[https://github.com/Shreyakkk](https://github.com/Shreyakkk)
Twitter—[https://twitter.com/Shreyakkkk](https://twitter.com/Shreyakkkk)
insta gram—[https://www.instagram.com/shreyakkk/](https://www.instagram.com/shreyakkk/)
脸书—[https://www.facebook.com/007shreyak](https://www.facebook.com/007shreyak)
谢谢。