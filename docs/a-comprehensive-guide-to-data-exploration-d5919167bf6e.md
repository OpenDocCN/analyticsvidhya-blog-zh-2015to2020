# 数据探索综合指南

> 原文：<https://medium.com/analytics-vidhya/a-comprehensive-guide-to-data-exploration-d5919167bf6e?source=collection_archive---------0----------------------->

*   关于数据探索(EDA)的完整教程
*   我们涵盖了几个数据探索方面，包括缺失值插补，离群点消除和特征工程的艺术

# 介绍

数据探索没有捷径。如果你有这种想法，机器学习可以让你远离每一场数据风暴，相信我，它不会。过一段时间后，你会意识到你正在努力提高模型的准确性。在这种情况下，数据探索技术将帮助您。

我可以自信地说，因为我经历过很多这样的情况。

我成为商业分析专家已经将近三年了。在我最初的日子里，我的一位导师建议我花大量时间探索和分析数据。听从他的建议对我很有好处。

我创建本教程是为了帮助您理解数据探索的底层技术。和往常一样，我尽力以最简单的方式解释这些概念。为了更好地理解，我举了几个例子来演示复杂的概念。

![](img/34787922d0f02fe939c5e4d5e70fd3e1.png)

# 目录

1.  [**数据探索和准备的步骤**](https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#one)
2.  [**缺失值处理**](https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#two)

*   为什么需要缺失值处理？
*   为什么数据有缺失值？
*   处理缺失值的方法有哪些？

[**3。离群点检测和处理技术**](https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#three)

*   什么是离群值？
*   离群值有哪些类型？
*   离群值产生的原因是什么？
*   离群值对数据集有什么影响？
*   如何检测离群值？
*   如何剔除离群值？

[**4。特征工程的艺术**](https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/#four)

*   什么是特征工程？
*   特征工程的流程是怎样的？
*   什么是变量变换？
*   什么时候应该使用变量变换？
*   变量变换的常用方法有哪些？
*   什么是特征变量创建及其好处？

# 我们开始吧

# 1.数据探索和准备的步骤

记住你输入的质量决定了你输出的质量。所以，一旦你准备好了你的商业假设，花大量的时间和精力在这里是有意义的。据我个人估计，数据探索、清理和准备可能会占用项目总时间的 70%。

以下是理解、清理和准备用于构建预测模型的数据的步骤:

1.  变量识别
2.  单变量分析
3.  双变量分析
4.  缺失值处理
5.  异常值处理
6.  变量变换
7.  变量创建

最后，我们需要多次迭代步骤 4–7，才能得出我们的优化模型。

现在让我们详细研究每个阶段

# 变量识别

首先，确定**预测器**(输入)和**目标**(输出)变量。接下来，确定变量的数据类型和类别。

让我们举个例子来更清楚地理解这一步。

举例:-假设，我们想预测，学生是否会打板球(参考下面的数据集)。这里你需要确定预测变量，目标变量，变量的数据类型和变量的类别。

![](img/03f24d0b03a2f261bc28dd4b2c5d5a0b.png)

下面，变量被定义在不同的类别中:

![](img/7d0bb15747708157ee3a8e61b4e67be5.png)

# 单变量分析

在这个阶段，我们逐个探索变量。执行单变量分析的方法将取决于变量类型是分类的还是连续的。让我们分别来看看分类变量和连续变量的这些方法和统计测量:

**连续变量:-** 对于连续变量，我们需要了解变量的集中趋势和扩散情况。这些是使用各种统计指标可视化方法测量的，如下所示:

![](img/d8a59b18308695a4e1a8e58269f7ba36.png)

**注意:**单变量分析也用于突出缺失值和异常值。在本系列接下来的部分中，我们将研究处理缺失值和异常值的方法。想了解更多这些方法，可以参考 Udacity 的课程[描述性统计。](https://www.udacity.com/course/ud827)

**分类变量:-** 对于分类变量，我们将使用频率表来了解每个类别的分布。我们还可以读取每个类别下的值的百分比。可以使用两个指标来衡量，针对每个类别的**计数**和**计数%** 。条形图可以用作可视化。

# 双变量分析

双变量分析找出两个变量之间的关系。这里，我们在预定义的显著性水平上寻找变量之间的关联和分离。我们可以对分类变量和连续变量的任意组合进行双变量分析。组合可以是:分类与分类、分类与连续和连续与连续。在分析过程中，使用不同的方法来处理这些组合。

让我们详细了解一下可能的组合:

**连续&连续:**在对两个连续变量进行双变量分析时，我们要看散点图。这是一个找出两个变量之间关系的好方法。散点图的模式表明了变量之间的关系。该关系可以是线性的或非线性的。

![](img/2e979087e298620eb0c5a9960161105a.png)

散点图显示了两个变量之间的关系，但并不表示它们之间的关系强度。为了找到关系的强度，我们使用相关性。相关性在-1 和+1 之间变化。

*   -1:完全负线性相关
*   +1:完美的正线性相关和
*   0:无相关性

可以使用以下公式推导相关性:

**相关性=协方差(X，Y) / SQRT( Var(X)* Var(Y))**

各种工具都具有识别变量之间相关性的功能。在 Excel 中，函数 CORREL()用于返回两个变量之间的相关性，SAS 使用过程 PROC CORR 来确定相关性。这些函数返回皮尔逊相关值，以确定两个变量之间的关系:

![](img/a9fd9928b40482f00f296921b28c7d03.png)

在上面的例子中，我们在两个变量 X 和 y 之间有很好的正相关(0.65)。

**分类&分类:**要找出两个分类变量之间的关系，我们可以使用以下方法:

*   **双向表:**我们可以通过创建 count 和 count%的双向表来开始分析关系。行代表一个变量的类别，列代表另一个变量的类别。我们显示了行和列类别的每个组合中可用的观察值的计数或计数%。
*   **堆积柱形图:**这种方法更多的是双向表的可视化形式。

![](img/0cd1da5ec919d556570a8549dcca7dcf.png)

概率为 0:表示两个分类变量都是相关的

概率为 1:说明两个变量都是独立的。

概率小于 0.05:表示变量之间的关系在 95%的置信度下显著。两个分类变量独立性检验的卡方检验统计量由下式得出:

![](img/b1ce282ded8dd49989fd038ad7c34572.png)

其中 *O* 代表观察到的频率。 *E* 是零假设下的预期频率，计算公式如下:

![](img/f2e1b79d764473d25de875c68736199d.png)

根据之前的双向表，产品类别 1 的小尺寸预期计数为 0.22。它是通过将大小(9)的行总和乘以产品类别(2)的列总和，然后除以样本大小(81)得出的。对每个细胞进行这一过程。用于分析关系力量的统计方法有:

*   名义分类变量的克拉默 V
*   有序分类变量的 Mantel-Haenszed 卡方检验。

不同的数据科学语言和工具有特定的方法来执行卡方检验。在 SAS 中，我们可以使用 **Chisq** 作为选项，并使用 **Proc freq** 来执行该测试。

**分类的&连续的:**在探索分类变量和连续变量之间的关系时，我们可以为每一级分类变量绘制箱线图。如果水平在数量上很小，就不会显示出统计意义。为了查看统计显著性，我们可以进行 Z 检验、T 检验或 ANOVA。

*   **Z-检验/T-检验:-** 任一检验评估两组平均值在统计上是否彼此不同。

![](img/5c2819c4a84115c0e32321a6c3152428.png)

*   如果 Z 的概率很小，则两个平均值的差异更显著。T-检验与 Z-检验非常相似，但是当两个类别的观察数都小于 30 时使用。

![](img/9571d3167f2c41773c9c731a5e79705a.png)

*   **ANOVA:-** 它评估两个以上组的平均值是否存在统计差异。

**举例:**假设，我们要测试五种不同运动的效果。为此，我们招募了 20 名男性，并将一种类型的运动分配给 4 名男性(5 组)。几周后记录他们的体重。我们需要弄清楚这些练习对他们的影响是否有显著的不同。这可以通过比较 5 组(每组 4 人)的体重来实现。

至此，我们已经了解了数据探索、变量识别、单变量和双变量分析的前三个阶段。我们还研究了各种统计和视觉方法，以确定变量之间的关系。

现在，我们来看看缺失值的处理方法。更重要的是，我们还将了解为什么数据中会出现缺失值，以及为什么有必要处理它们。

# 2.缺失值处理

# 为什么需要缺失值处理？

训练数据集中的缺失数据会降低模型的功效/拟合度，或者会导致模型有偏差，因为我们没有正确分析行为以及与其他变量的关系。它会导致错误的预测或分类。

![](img/3e9f5966e17978396e79c827c7a7fe9e.png)

注意上图中缺失的值:在左边的场景中，我们没有处理缺失的值。从这个数据集中得出的推论是，男性打板球的几率比女性高。另一方面，如果你看第二个表，它显示了处理缺失值(基于性别)后的数据，我们可以看到女性比男性有更高的机会打板球。

# 为什么我的数据缺少值？

我们研究了处理数据集中缺失值的重要性。现在，让我们找出这些缺失值出现的原因。它们可能发生在两个阶段:

1.  **数据提取**:可能是提取过程有问题。在这种情况下，我们应该与数据监护人一起仔细检查数据是否正确。一些哈希程序也可以用来确保数据提取是正确的。数据提取阶段的错误通常很容易发现，也很容易纠正。
2.  **数据收集**:这些错误发生在数据收集的时候，很难纠正。它们可以分为四种类型:

*   **完全随机缺失:**这是所有观测值缺失变量的概率相同的情况。例如:数据收集过程中的受访者决定在抛公平硬币后宣布他们的收入。如果出现 head，被调查者申报其收入&反之亦然。在这里，每个观察值都有相同的丢失值的机会。
*   **随机缺失:**这是一种变量随机缺失的情况，缺失率随其他输入变量的不同值/水平而变化。例如:我们正在收集年龄数据，与男性相比，女性的缺失值更高。
*   **依赖于未观察到的预测值的缺失:**这是一种缺失值不是随机的并且与未观察到的输入变量相关的情况。例如:在一项医学研究中，如果某项特定的诊断导致不适，那么退出研究的可能性会更高。这个缺失值不是随机的，除非我们将“不适”作为所有患者的输入变量。
*   **依赖于缺失值本身的缺失:**这是缺失值的概率与缺失值本身直接相关的情况。例如:收入较高或较低的人很可能对他们的收入提供不回应。

# 处理缺失值的方法有哪些？

1.  **删除:**有两种类型:列表式删除和配对式删除。

*   在列表删除中，我们删除任何变量缺失的观察值。简单是这种方法的主要优点之一，但是这种方法降低了模型的功效，因为它减少了样本量。
*   在成对删除中，我们对存在感兴趣的变量的所有情况进行分析。这种方法的优点是，它保持尽可能多的案例可供分析。这种方法的一个缺点是，它对不同的变量使用不同的样本量。

![](img/2a3c7eaee80615d3a38721c962c82159.png)

*   当缺失数据的性质是“**完全随机缺失**时，使用删除方法，否则非随机缺失值会使模型输出产生偏差。

**2。均值/众数/中位数插补:**插补是一种用估计值填充缺失值的方法。目标是利用已知的关系，这些关系可以在数据集的有效值中识别，以帮助估计缺失值。均值/众数/中位数插补是最常用的方法之一。它包括用该变量所有已知值的平均值或中值(定量属性)或众数(定性属性)替换给定属性的缺失数据。它可以有两种类型:-

*   **广义插补:**在这种情况下，我们计算该变量所有非缺失值的平均值或中值，然后用平均值或中值替换缺失值。如上表所示，变量“**人力”**缺失，因此我们取“**人力”** ( **28.33** )所有非缺失值的平均值，然后用它替换缺失值。
*   **类似情况插补:**在这种情况下，我们分别计算非缺失值的性别“**男“**”(29.75)和“**女**”(25)的平均值，然后根据性别替换缺失值。对于“**男**”，我们将用 29.75 替换缺失的人力值，对于“**女**”用 25 替换缺失的人力值。

**3。预测模型**:预测模型是处理缺失数据的复杂方法之一。在这里，我们创建了一个预测模型来估计将替代缺失数据的值。在这种情况下，我们将数据集分成两组:一组没有变量的缺失值，另一组有缺失值。第一个数据集成为模型的训练数据集，而具有缺失值的第二个数据集是测试数据集，并且具有缺失值的变量被视为目标变量。接下来，我们创建一个模型，根据训练数据集的其他属性预测目标变量，并填充测试数据集的缺失值。我们可以使用回归、方差分析、逻辑回归和各种建模技术来实现这一点。这种方法有两个缺点:

1.  模型估计值通常比真实值表现得更好
2.  如果与数据集中的属性和具有缺失值的属性没有关系，那么模型对于估计缺失值将是不精确的。
3.  **KNN 插补:**在这种插补方法中，使用与缺失值的属性最相似的给定数量的属性对属性的缺失值进行插补。使用距离函数来确定两个属性的相似性。众所周知它也有一定的优点&缺点。

**优点:**

*   k 近邻可以预测定性和定量属性
*   不需要为具有缺失数据的每个属性创建预测模型
*   具有多个缺失值的属性很容易处理
*   考虑数据的相关结构

**劣势:**

*   KNN 算法在分析大型数据库时非常耗时。它在所有数据集中搜索最相似的实例。
*   k 值的选择非常关键。较高的 k 值将包括与我们所需要的显著不同的属性，而较低的 k 值意味着遗漏了重要的属性。

处理完缺失值后，下一个任务是处理异常值。通常，我们在构建模型时会忽略异常值。这是一种令人沮丧的做法。离群值往往会使您的数据失真并降低准确性。让我们了解更多关于异常值处理的知识。

# 3.异常检测和处理技术

# 什么是离群值？

异常值是分析师和数据科学家常用的术语，因为它需要密切关注，否则会导致非常错误的估计。简单地说，离群值是一个出现在远处的观察值，它偏离了样本中的整体模式。

举个例子，我们做客户侧写，发现客户的平均年收入是 80 万美元。但是，有两个客户的年收入分别为 400 万美元和 420 万美元。这两位顾客的年收入远高于其他人群。这两个观察值将被视为异常值。

![](img/02e98c9f8b524942937e26dcdbde9cf0.png)

# 离群值有哪些类型？

异常值可以有两种类型:**单变量**和**多变量**。上面，我们已经讨论了单变量异常值的例子。当我们观察单个变量的分布时，可以发现这些异常值。多变量异常值是 n 维空间中的异常值。为了找到它们，你必须看多维度的分布。

让我们用一个例子来理解这一点。假设我们正在理解身高和体重之间的关系。下面，我们有身高、体重的单变量和双变量分布。看一下方框图。我们没有任何异常值(高于和低于 1.5*IQR，最常见的方法)。现在来看散点图。在这里，我们有两个低于平均值的值和一个高于平均值的值。

![](img/28a314ad792affc3cea857415fdc2932.png)

# 什么导致了异常值？

每当我们遇到离群值时，处理它们的理想方法是找出产生这些离群值的原因。处理它们的方法将取决于它们发生的原因。异常值的原因可以分为两大类:

让我们更详细地了解各种类型的异常值:

*   **数据输入错误:-** 人为错误，如数据收集、记录或输入过程中产生的错误，会导致数据中出现异常值。例如:一个客户的年收入是 100，000 美元。数据输入操作员不小心在数字中加了一个零。现在收入变成了 100 万美元，是原来的 10 倍。显然，与总体的其余部分相比，这将是异常值。
*   **测量误差:**这是异常值最常见的来源。这是由于使用的测量仪器出现故障造成的。例如:有 10 台称重机。其中 9 个是正确的，1 个是错误的。故障机器上的人测得的重量将高于/低于该组中的其他人。在故障机器上测量的重量可能会导致异常值。
*   **实验误差:**离群值的另一个原因是实验误差。举个例子:在一场 7 人参加的 100 米短跑中，一名运动员没有集中精力听“开始”的口令，这导致他起跑晚了。因此，这导致跑步者的跑步时间比其他跑步者多。他的总运行时间可能是一个异常值。
*   **有意异常值 *:*** 这通常出现在涉及敏感数据的自我报告测量中。例如:青少年通常会少报他们的饮酒量。其中只有一小部分会报告实际价值。在这里，实际值可能看起来像异常值，因为其余的青少年都少报了消费量。
*   **数据处理错误:**每当我们执行数据挖掘时，我们都会从多个来源提取数据。一些操作或提取错误可能会导致数据集中的异常值。
*   **抽样误差:**比如我们要测量运动员的身高。由于失误，我们在样本中包括了一些篮球运动员。这种包含可能会导致数据集中的异常值。
*   **自然离群值:**当一个离群值不是人为的(由于误差)时，它就是自然离群值。例如:我在一家著名保险公司的最后一次任务中，我注意到前 50 名财务顾问的表现远远高于其他人。令人惊讶的是，这不是由于任何错误。因此，每当我们使用 advisors 执行任何数据挖掘活动时，我们通常会单独处理这一部分。

# 离群值对数据集有什么影响？

异常值会极大地改变数据分析和统计建模的结果。数据集中的异常值有许多不利影响:

*   它增加了误差方差，降低了统计检验的能力
*   如果异常值是非随机分布的，它们会降低正态性
*   他们可以偏见或影响估计，可能是实质性的利益
*   它们还会影响回归的基本假设、方差分析和其他统计模型假设。

为了更深入地理解这种影响，让我们举一个例子来检查数据集在有和没有离群值的情况下会发生什么。

**举例:**

![](img/457784c29c385f76deb4912867c14aae.png)

如您所见，带有异常值的数据集具有显著不同的均值和标准差。在第一个场景中，我们会说平均值是 5.45。但有了异常值，平均值飙升至 30。这将完全改变估计。

# 如何检测异常值？

最常用的检测异常值的方法是可视化。我们使用各种可视化方法，如**箱线图**、**直方图**、**散点图**(上面，我们使用了箱线图和散点图进行可视化)。一些分析师也用各种经验法则来检测异常值。其中一些是:

*   超出-1.5 倍 IQR 到 1.5 倍 IQR 范围的任何值
*   使用封顶方法。任何超出 5%和 95%范围的值都可以被认为是异常值
*   偏离平均值三个或更多标准偏差的数据点被认为是异常值
*   离群点检测仅仅是对有影响的数据点进行数据检查的一个特例，它也依赖于对业务的理解
*   双变量和多变量异常值通常使用影响或杠杆指数或距离来衡量。Mahalanobis 的距离和 Cook 的 *D* 等流行指数经常被用来检测异常值。
*   在 SAS 中，我们可以使用 PROC 单变量，PROC SGPLOT。为了识别异常值和有影响观察值，我们还查看了统计测量值，如 STUDENT、COOKD、RSTUDENT 等。

# 如何剔除离群值？

处理异常值的大多数方法类似于缺失值的方法，如删除观察值、转换观察值、宁滨观察值、将观察值作为单独的组对待、输入值和其他统计方法。这里，我们将讨论用于处理异常值的常用技术:

**删除观测值:**如果是由于数据录入错误、数据处理错误或者异常值观测值数量非常少，我们就删除异常值。我们也可以在两端使用修剪来移除异常值。

**变换和宁滨值:**变换变量也可以剔除异常值。值的自然对数减少了由极值引起的变化。宁滨也是变量变换的一种形式。决策树算法允许很好地处理由于变量的宁滨引起的异常值。我们也可以使用为不同的观察值分配权重的过程。

![](img/15f492a16b05f1465cc7be212360baf7.png)

**估算:**像[估算缺失值](https://www.analyticsvidhya.com/blog/2015/02/7-steps-data-exploration-preparation-building-model-part-2/)一样，我们也可以估算异常值。我们可以使用均值、中值、众数插补方法。在输入值之前，我们应该分析它是自然离群值还是人为的。如果是人为的，我们可以用输入值。我们还可以使用统计模型来预测离群值，然后我们可以用预测值对其进行估算。

**分别对待:**如果有大量的异常值，我们应该在统计模型中分别对待。一种方法是将两个组视为两个不同的组，为两个组建立单独的模型，然后合并输出。

至此，我们已经了解了数据探索的步骤、缺失值的处理以及异常值检测和处理的技术。这三个阶段将使你的原始数据在信息可用性和准确性方面更好。现在让我们进入数据探索的最后阶段。它是特征工程。

# 4.特征工程的艺术

# 什么是特征工程？

特征工程是从现有数据中提取更多信息的科学(和艺术)。您没有在这里添加任何新的数据，但是您实际上使您已经拥有的数据变得更加有用。

例如，假设您正试图根据日期预测在购物中心的跌倒情况。如果你试图直接使用数据，你可能无法从数据中提取有意义的见解。这是因为脚跌倒受一个月中某一天的影响比受一周中某一天的影响要小。现在，关于星期几的信息隐含在您的数据中。你需要把它拿出来让你的模型更好。

这种从数据中提取信息的活动被称为特征工程。

# 特征工程的流程是怎样的？

一旦完成数据探索中的前 5 个步骤，即[变量识别、单变量、双变量分析](https://www.analyticsvidhya.com/blog/2015/02/data-exploration-preparation-model/)、[缺失值插补](https://www.analyticsvidhya.com/blog/2015/02/7-steps-data-exploration-preparation-building-model-part-2/)和[异常值处理](https://www.analyticsvidhya.com/blog/2015/02/outliers-detection-treatment-dataset/)，就可以执行特征工程。特征工程本身可以分为两个步骤:

*   变量变换。
*   变量/特征创建。

这两种技术在数据探索中至关重要，并对预测能力有显著影响。让我们更详细地了解每个步骤。

# 什么是变量变换？

在数据建模中，转换是指用函数替换变量。例如，用平方根/立方根或对数 x 替换变量 x 就是一种变换。换句话说，变换是改变一个变量与其他变量的分布或关系的过程。

让我们看看变量变换有用的情况。

# 什么时候应该使用变量变换？

以下是变量转换必不可少的情况:

![](img/def748a974ea68c2873659cca8f5902c.png)![](img/c7e86c34d4a9314ea3098a77aa4ce5af.png)

# 变量变换的常用方法有哪些？

有各种方法用来转换变量。如上所述，其中一些包括平方根，立方根，对数，宁滨，倒数和许多其他。让我们通过强调这些转换方法的优缺点来详细了解这些方法。

# 什么是特征/变量创建及其好处？

特征/变量创建是基于现有变量生成新变量/特征的过程。例如，我们将日期(dd-mm-yy)作为数据集中的输入变量。我们可以生成新的变量，如日、月、年、周、工作日，它们可能与目标变量有更好的关系。此步骤用于突出显示变量中的隐藏关系:

![](img/c6029141f3bb2224a5c0c7083971879d.png)

创建新特征有多种方法。让我们来看看一些常用的方法:

![](img/5c6b6e864c4e07c8a71b307950b45068.png)

# 结束注释

正如在开始时提到的，投入到数据探索中的质量和努力区分了好的模型和坏的模型。

我们的数据探索和准备指南到此结束。在本综合指南中，我们详细介绍了数据探索的七个步骤。本系列的目的是为数据科学中一个极其重要的过程提供一个深入的逐步指南。

就我个人而言，我很喜欢写这个指南，也很乐意从你的反馈中学习。你觉得这本指南有用吗？我将感谢你的建议/反馈。请随时通过下面的评论提出你的问题。

*原载于 2016 年 1 月 10 日*[*【https://www.analyticsvidhya.com】*](https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/)*。*