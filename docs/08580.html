<html>
<head>
<title>Gradient Descent with Momentum, RMSprop And Adam Optimizer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">动量梯度下降、RMSprop和Adam优化器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/momentum-rmsprop-and-adam-optimizer-5769721b4b19?source=collection_archive---------3-----------------------#2020-08-04">https://medium.com/analytics-vidhya/momentum-rmsprop-and-adam-optimizer-5769721b4b19?source=collection_archive---------3-----------------------#2020-08-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="67aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">优化器是一种我们用来最小化损失或增加准确性的技术。我们通过寻找成本函数的局部最小值来做到这一点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/f46f6eefa6fe285c33bc331a9ea991da.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*95fgV8pvjrD0WZXomABDIg.png"/></div></figure><p id="d36a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的参数更新如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jl"><img src="../Images/15476de3f129943f45b4ee8751f3ae45.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*MLdZvgHWzcgzaiKIBCgUYw.jpeg"/></div></figure><p id="f9a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们的成本函数本质上是凸的，只有一个最小值，这是它的全局最小值。我们可以简单地使用梯度下降优化技术，这将在超参数的一点调整后收敛到全局最小值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jm"><img src="../Images/657f57abf69726122ba0da91dd044a7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*hf_5r1yZr7JiOWc48TKv9g.jpeg"/></div></figure><p id="cabc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是在现实世界的问题中，成本函数有很多局部极小值。梯度下降技术在这里失败了，我们可能会陷入局部极小值而不是全局极小值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es jn"><img src="../Images/acfdca122622f108c6f56a07e1ced431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t4aYsxpCqz2eymJ4zkUS9Q.png"/></div></div></figure><p id="f3ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，为了避免我们的模型陷入局部极小值，我们使用了梯度下降的高级版本，其中我们使用了动量。</p><p id="b28b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">想象一个球，我们从某个点开始，然后球向下坡或下降的方向运动。如果球具有足够的动量，那么球将从井或我们的成本函数图中的局部最小值中逃逸。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es js"><img src="../Images/56901a9bcd45f3e8a2be1dfc234da890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*X9SaxFM6_sBOAMY9TaGsKw.png"/></div></figure><p id="01cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">具有动量的梯度下降考虑过去的梯度以平滑更新。它计算梯度的指数加权平均值，然后使用该梯度更新权重。</p><p id="826b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们的偏差参数为“b ”,权重为“w ”,因此当使用动量梯度下降时，我们的参数更新方程为:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jt"><img src="../Images/44c2b9aa7c6134eeb1e9b8d176ebe34c.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*dxkWGW5lG_8i2GR83fsK-w.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ju"><img src="../Images/c78d1348f2e2709c88536fd4561e44bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*sbqpNOHfVwr0-5pL2QiRng.png"/></div></figure><h1 id="2543" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">RMSprop优化器:</h1><p id="6027" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">下面是一个2D等高线图，用于可视化RMSprop算法的工作，实际上有更高的维度。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es ky"><img src="../Images/4a1a042f394978de64e45265b318a2f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*qoNZTsyaQppaZ41LRG70zg.gif"/></div></div></figure><p id="21ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们处理大型数据集时，我们一次使用一批数据。由于它包含巨大的变化和噪声，梯度下降在其路径上产生巨大的振荡，并且需要长时间和更多的迭代来收敛。在RMSprop优化技术中，我们以这样的方式更新我们的参数，使得权重w方向上的移动大于‘b’方向上的移动。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kz"><img src="../Images/bbe32c4c15fb5909077c06cf3def47e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*LfCI7jA-MADtwf9HWycghA.png"/></div></figure><p id="a87d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是梯度的指数平均值。我们假设dw小于db，因此dw的指数平均值小于db的指数平均值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es la"><img src="../Images/a912938542c6e684d4b7149a557d681d.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*4ghOPMUl5VL9NhHCKBC23Q.png"/></div></div></figure><p id="0117" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，当我们将梯度除以它们各自的指数平均值的根时，“W”中的更新将比“b”中的更新更多，这允许我们在水平方向上采取更大的步骤并更快地收敛，这也减少了收敛到最优值的迭代次数。这就是该算法的名称“均方根传播”。</p><h1 id="82d5" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">Adam优化器:</h1><p id="0a75" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">事实证明，当我们一起使用momentum和RMSprop时，我们最终会得到一个更好的优化算法，称为自适应动量估计。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es lb"><img src="../Images/1ddcfeb6bd66cb53be718f5519d16afb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AxAgUJYhXaATA0bXJW4hQg.png"/></div></div></figure><p id="f5ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，第一个方程考虑了我们在上面看到的动量，第二个方程来自RMSprop优化算法。我们还引入了一个新的超参数'<strong class="ih hj">ε'</strong>ε，它确保我们不会以除以非常小的指数平均值结束，默认情况下，超参数为:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lc"><img src="../Images/bb368bb2526fd83e44e19e0fb501f159.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*dekKFHafBYBzmh9iwoitAw.png"/></div></figure><p id="0e1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">必须调整学习率的值。</p><p id="02de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Adam优化算法在深度学习的许多不同问题中表现非常好。</p><h1 id="eaf0" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">结论:</h1><p id="a2ab" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">有许多优化器可供选择，了解它们的工作原理将有助于您为自己的应用选择一种优化技术。我希望这篇文章对您有所帮助；)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ld"><img src="../Images/c28cb0600835668a8bc09fc5f1ec06ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/1*s8p9I_7jL8VBvOcGu_TWBA.gif"/></div></figure></div></div>    
</body>
</html>