<html>
<head>
<title>Spark Parallelism Deep Dive Writing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火花并行深潜写作</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spark-parallelism-deep-dive-writing-ea9b9394831?source=collection_archive---------4-----------------------#2020-03-07">https://medium.com/analytics-vidhya/spark-parallelism-deep-dive-writing-ea9b9394831?source=collection_archive---------4-----------------------#2020-03-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2796" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我在《火花深潜》中的一个故事</p><p id="9d56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" rel="noopener" href="/@somanathsankaran">https://medium.com/@somanathsankaran</a></p><p id="1678" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark是一个分布式并行处理框架，它的并行性是由分区定义的。让我们详细讨论一下spark的分区。</p><p id="1ced" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">spark中有3种类型的并行。</p><ol class=""><li id="3b08" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">阅读中的平行</li><li id="ccfc" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">洗牌中的平行</li><li id="95c6" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">写作中的平行</li></ol><p id="0a1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在以前的博客中已经讨论了读写的并行性</p><div class="js jt ez fb ju jv"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/spark-parallelism-deep-dive-i-reading-8d63e22f3bce"><div class="jw ab dw"><div class="jx ab jy cl cj jz"><h2 class="bd hj fi z dy ka ea eb kb ed ef hh bi translated">火花并行性深潜-I(阅读)</h2><div class="kc l"><h3 class="bd b fi z dy ka ea eb kb ed ef dx translated">这是我在火花深潜系列中的一个故事。</h3></div><div class="kd l"><p class="bd b fp z dy ka ea eb kb ed ef dx translated">medium.com</p></div></div><div class="ke l"><div class="kf l kg kh ki ke kj kk jv"/></div></div></a></div><div class="js jt ez fb ju jv"><a rel="noopener follow" target="_blank" href="/@somanathsankaran/spark-parallelism-deep-dive-part-ii-95a06e2443c4"><div class="jw ab dw"><div class="jx ab jy cl cj jz"><h2 class="bd hj fi z dy ka ea eb kb ed ef hh bi translated">火花并行深入探讨-第二部分</h2><div class="kc l"><h3 class="bd b fi z dy ka ea eb kb ed ef dx translated">这是我在《火花深潜》中的一个故事</h3></div><div class="kd l"><p class="bd b fp z dy ka ea eb kb ed ef dx translated">medium.com</p></div></div><div class="ke l"><div class="kl l kg kh ki ke kj kk jv"/></div></div></a></div><p id="25fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">写作中的平行分为两部分</p><ol class=""><li id="9b9c" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">写入时控制文件</li><li id="1b78" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">写入时控制文件大小</li></ol><p id="1928" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">一边写一边控制文件</strong></p><p id="a16a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们读取一个示例数据帧，看看它有多少个分区</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es km"><img src="../Images/826958bba2454b349a275f4271e85f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F2fPU0fumJvtKCRTCHl1HQ.png"/></div></div></figure><p id="3ba0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们用拼花格式写df</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es kx"><img src="../Images/1f9d2d2b3d7274306628d8f64f25422c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9ff8bVR3nsRkQr18QOt1g.png"/></div></div></figure><p id="2dbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在研究书面目录时，我们可以发现部分文件的数量等于输入分区的数量</p><p id="5598" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们打乱数据，看看数据是如何分布的</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es ky"><img src="../Images/76caaeb92b07232c4d01279102d02477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AVwT9K6QSgAZEh4pBOFUtw.png"/></div></div></figure><p id="b5cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此spark会根据rdd的分区数量将数据写入多个部件文件</p><p id="5bcd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们检查spark.shuffle分区是否对写入有影响</p><p id="a071" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将shuffle.partition更改为较小的值，以检查是否发生了任何更改</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es kz"><img src="../Images/712d3849f176dfdb11e562db1bb50bad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YxhGeQ2gVX4XYVBJzY0TAw.png"/></div></div></figure><p id="d875" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以从上面的图像来看，在书写的时候没有洗牌分区的效果</p><p id="6ce8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为写入的数据依赖于rdd分区</p><p id="14d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">写入时控制文件大小</strong></p><p id="5428" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，一旦我们写入数据，单个分区下的所有数据都将写入单个文件，该文件的大小可能不均匀。</p><p id="cf33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，让我们尝试控制单个分区下的最大文件大小，以便我们可以有更均匀分布的大小(128 mb)</p><p id="3c0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有一个属性，利用它我们可以控制每个rdd分区下每个文件的记录数</p><p id="7e1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">所以我们可以利用maxRecordsPerFile来控制每个文件写入的记录数量</strong></p><p id="6554" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我们有887条记录，所以我们将每个文件的记录分为200条</p><p id="2f1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如下所示</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es la"><img src="../Images/bffcbb92115c47f835737cd19ea3b94c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SoUo1hTukD1t6vMaz3P3nQ.png"/></div></div></figure><p id="dc3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上图中我们可以看到，即使只有一个分区，我们也有5个文件，我们可以根据您的数据使用max records来获得大小为128 mb的文件</p><p id="217b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结论:</strong></p><p id="4cef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lb">因此得出结论，spark写入部分文件由rdd.partitions控制，我们可以利用每个文件的最大记录数将数据保存为统一大小的文件</em> </strong></p><p id="bfcd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">今天就到这里吧！！:)</p><p id="698a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Github链接:<a class="ae jd" href="https://github.com/SomanathSankaran/spark_medium/tree/master/spark_csv" rel="noopener ugc nofollow" target="_blank">https://github . com/SomanathSankaran/spark _ medium/tree/master/spark _ CSV</a></p><p id="84ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"/></p><p id="9916" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">学习并让别人学习！！</strong></p></div></div>    
</body>
</html>