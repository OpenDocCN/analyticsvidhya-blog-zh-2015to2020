<html>
<head>
<title>Complete Pipeline for Bounding Box Detection for fashion material (YOLOv3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时装材料边界框检测的完整管道(YOLOv3)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/complete-pipeline-for-bounding-box-detection-for-fashion-material-yolov3-cae64c48fb78?source=collection_archive---------14-----------------------#2020-06-03">https://medium.com/analytics-vidhya/complete-pipeline-for-bounding-box-detection-for-fashion-material-yolov3-cae64c48fb78?source=collection_archive---------14-----------------------#2020-06-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="47b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">大家好，我最近在研究时尚材料的包围盒检测。从这份工作中，我学到了很多东西，而且我知道大部分东西都可以在网上找到。这个博客是为了把所有有用的东西都集中到一个地方。我将分享我的学习，并带你通过这个管道。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jm"><img src="../Images/e304378e1655bc891dec3e5b418d8e9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bSLNlG7crv-p-m4LVYYk3Q.png"/></div></div></figure><blockquote class="jy jz ka"><p id="e43f" class="if ig kb ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><em class="hi"/>数据集中的偏差或方差越低，模型精度越高<em class="hi"/></p></blockquote><h2 id="10bd" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">数据收集</h2><ol class=""><li id="6fa5" class="la lb hi ih b ii lc im ld iq le iu lf iy lg jc lh li lj lk bi translated"><a class="ae ll" href="https://drive.google.com/drive/folders/0B7EVK8r0v71pQ2FuZ0k0QnhBQnc" rel="noopener ugc nofollow" target="_blank"> DeepFashion1 </a>是一个大规模布料数据集。它包含大约80万张46种流行服装的图片。</li><li id="7721" class="la lb hi ih b ii lm im ln iq lo iu lp iy lq jc lh li lj lk bi translated"><a class="ae ll" href="https://drive.google.com/drive/folders/125F48fsMBz2EF0Cpqk6aaHet5VH399Ok" rel="noopener ugc nofollow" target="_blank"> DeepFashion2 </a>是一个全面的时尚数据集。它包含13个流行服装类别的491，000个不同的图像。</li></ol><h2 id="6fb2" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">数据集预处理</h2><p id="d651" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq lr is it iu ls iw ix iy lt ja jb jc hb bi jd translated">这些数据集都是以不同的方式组织的。DeepFashion1就像一个有一个边界框的图像，所有的注释都存储在一个文本文件中，而DeepFashion2就像一个有一个或多个边界框的图像，每个图像都有自己的JSON格式的注释文件。</p><blockquote class="jy jz ka"><p id="5d34" class="if ig kb ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">进口熊猫作为pd</p></blockquote><p id="8fb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个人都熟悉这个命令。我组合了这两个数据集，并制作了如下所示格式的数据帧。给每个类和模式列分配Id是为了知道这个图像是否属于训练、测试或验证数据。Source是想知道这个图片是来自deepfashion1还是deepfashion2。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es lu"><img src="../Images/24031d23849586ebba48c7496dd6c8df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I8kgn7sX2PN7T1ASveVOKg.jpeg"/></div></div></figure><p id="441b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不分享我的代码，因为这个博客背后的想法是通过管道启发你。不过，如果你在编码时遇到任何问题，请告诉我，我一定会帮你解决。</p><p id="889f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">处理如此庞大的数据集既忙碌又耗时。构建数据框架的过程会花费很多时间。<a class="ae ll" href="https://towardsdatascience.com/why-every-data-scientist-should-use-dask-81b2b850e15b" rel="noopener" target="_blank"> <strong class="ih hj"> DASK </strong> </a>是用Python编写的并行计算开源库。下面是Dask的一瞥。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="585d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TF record:TF record格式是一种以二进制序列存储数据的简单格式。您应该对如何创建tfrecord有一个基本的了解。在我们的数据帧中，有属于一个图像的注释。我们的任务是使用python“集合”库将它们组合在一起，然后创建tf示例。这里有一个想法的代码，将有助于您在分组。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="3be2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于我们的数据集很大，我们的tfrecord创建脚本需要时间。我们可以使用DASK进行并行计算，也可以共享tfrecord，即分割tfrecord文件。tfrecord的分片最好在这个<a class="ae ll" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md#sharding-datasets" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">博客</strong> </a> <strong class="ih hj"> </strong>用代码解释。</p><h2 id="beab" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">模型训练</h2><p id="ac8f" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq lr is it iu ls iw ix iy lt ja jb jc hb bi translated">YOLO9000 ，使用改进的YOLOv2模型可以检测多达9000个对象类别。在每秒67帧的速度下，该探测器在视觉对象类别挑战赛VOOC 2007上获得了76.8 mAP(平均精度)，击败了更快的RCNN等方法。</p><p id="5647" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">损失函数</strong>:平方和误差</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lx"><img src="../Images/1af39abd14aeaa5cbf0be211afb034cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:332/format:webp/1*qvoJisPsaE4DjmZ6kZRMWw.png"/></div></figure><p id="2813" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">分类</strong> <strong class="ih hj">损失</strong>:交叉熵</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ly"><img src="../Images/05cf8592cbf7140d3a55a64517ecb004.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*Fv6XXTwhwNm1b42NLafDMA.png"/></div></figure><p id="26f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您将在这个<a class="ae ll" href="https://github.com/zzh8829/yolov3-tf2" rel="noopener ugc nofollow" target="_blank"> git </a>仓库中找到完整的架构。根据您的tfrecord文件进行更改，还需要对hyperparameter进行微调。</p><p id="fe24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要么我们可以从头开始训练我们的网络，要么我们可以使用在线提供的预训练权重。训练时使用“eager_fit”模式，因为eager模式非常适合调试。</p><h2 id="1aae" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">估价</h2><p id="cb75" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq lr is it iu ls iw ix iy lt ja jb jc hb bi translated">评估指标用于衡量模型的准确性。有许多不同类型的评估指标可用于测试模型。使用多个评估指标来测试一个模型是很重要的。这是因为模型可能在一个评估指标上表现良好，但在其他评估指标上表现不佳。</p><p id="27f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用平均精度(mAP)评估指标。这篇<a class="ae ll" href="https://towardsdatascience.com/breaking-down-mean-average-precision-map-ae462f623a52#d439" rel="noopener" target="_blank">博客</a>很好地解释了平均精度。看一看</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lz"><img src="../Images/ed653cc85c5b738cc6801085740cc4bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*LM0FG6E6M-vMyH6XA2sv7g.png"/></div><figcaption class="ma mb et er es mc md bd b be z dx translated">平均精度公式</figcaption></figure><p id="537f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中AP(平均精度)和N是数据集中的类的数量。</p><p id="1385" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">编写一个python脚本，使用训练模型预测测试数据集的边界框，并将其保存到一个文件夹中。将地面真相保存到另一个文件夹中。克隆这个<a class="ae ll" href="https://github.com/rafaelpadilla/Object-Detection-Metrics" rel="noopener ugc nofollow" target="_blank"> git </a>仓库。将您的预测数据和基本事实输入到这个git存储库中的python脚本中。这将给你的终端带来地图价值。</p><h2 id="fe72" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">初步结果</h2><div class="jn jo jp jq fd ab cb"><figure class="me jr mf mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/46bae65d2550cc5d2afff35829f6f51e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*IeCajSQCiwihmIFnnRcQag.png"/></div></figure><figure class="me jr mf mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/ff1af082e84e49b72177dda4393db196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*BADnUiSvi7MkqWEmjYpPIg.png"/></div><figcaption class="ma mb et er es mc md bd b be z dx mk di ml mm translated">myntra图像上的测试模型</figcaption></figure></div><p id="1c30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">雅尔加尔吼！！</p></div><div class="ab cl mn mo gp mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="hb hc hd he hf"><p id="fa54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kb">发现错误，不吝赐教</em></p></div></div>    
</body>
</html>