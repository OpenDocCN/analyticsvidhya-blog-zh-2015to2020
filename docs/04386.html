<html>
<head>
<title>Optimising different Apache Spark SQL Joins</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优化不同的Apache Spark SQL连接</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/optimising-different-apache-spark-sql-joins-dc6120c3ff6a?source=collection_archive---------13-----------------------#2020-03-17">https://medium.com/analytics-vidhya/optimising-different-apache-spark-sql-joins-dc6120c3ff6a?source=collection_archive---------13-----------------------#2020-03-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/608d3141cb919a56fb4b8edf4e581c93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*ON8-2LwG33UulzvHFblmEw.png"/></div></figure><p id="521a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Spark SQL中有不同类型的连接:</p><ul class=""><li id="cf3b" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">无序散列连接</li><li id="5f0e" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">广播散列连接</li><li id="77c6" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">笛卡尔连接</li><li id="3c56" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">θ连接</li><li id="9e4e" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">一对多加入</li></ul><h1 id="c0ac" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">无序散列连接</h1><p id="f428" class="pw-post-body-paragraph im in hi io b ip kw ir is it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj hb bi translated">无序散列连接是最基本的连接类型，也是它所使用的MapReduce基础</p><ul class=""><li id="53fe" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">映射两个不同的数据框/表</li><li id="bbad" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">使用连接条件中的字段作为输出键</li><li id="3296" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">通过输出键混洗两个数据集</li><li id="1541" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">在reduce阶段，连接两个数据集。相同的钥匙将在同一台机器上，并进行分类</li></ul><h2 id="324b" class="lb jz hi bd ka lc ld le ke lf lg lh ki ix li lj km jb lk ll kq jf lm ln ku lo bi translated">无序散列连接性能</h2><p id="9189" class="pw-post-body-paragraph im in hi io b ip kw ir is it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj hb bi translated">在以下情况下效果最佳:</p><ul class=""><li id="8e42" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">密钥均匀分布</li><li id="0887" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">足够数量的并行键</li></ul><p id="29b9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这实质上意味着数据不应该是倾斜的。如果有数百万条记录，但唯一键的数量非常少，则混洗散列连接的性能将无法利用并行性，其性能将会降低。</p><h2 id="5670" class="lb jz hi bd ka lc ld le ke lf lg lh ki ix li lj km jb lk ll kq jf lm ln ku lo bi translated">让我们看几个例子:</h2><p id="7ebb" class="pw-post-body-paragraph im in hi io b ip kw ir is it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj hb bi translated"><strong class="io hj">案例1: </strong></p><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="cf36" class="lb jz hi lu b fi ly lz l ma mb">rdd = sqlContext.sql("select * FROM software_jobs JOIN indian_states ON software_jobs.state = states.name")</span></pre><p id="9013" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">由于表2(状态数)中唯一键的数量将非常少，并且大多数记录将仅来自第二个表中的几个键，这将导致<strong class="io hj">不均匀共享和有限并行性的问题。</strong></p><p id="4708" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">table2只有35个键(州数+ UT ),大多数行将来自卡纳塔克邦或安得拉邦键。</p><p id="997a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">同样在这种情况下，如果我们将节点增加到35个以上，这并不能解决问题，因为我们只有35个键。</p><p id="2730" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">如果table2足够小，可以放入内存，广播散列连接可以解决这个问题。</strong>(我们很快会讨论这个问题)</p><p id="46db" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">案例二:</strong></p><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="9e36" class="lb jz hi lu b fi ly lz l ma mb">rdd = sqlContext.sql("select * from people_in_tamil_nadu <br/>LEFT JOIN people_in_india<br/>ON people_in_tamil_nadu.id = people_in_india.id</span></pre><p id="83ed" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">查看这个查询，我们假设输出文件的大小等于people_in_tamil_nadu的大小。然而，这并不是混洗散列连接的工作方式！</p><p id="7263" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">table1和table2中的所有行将在网络上混洗以连接，然后它将意识到大多数记录来自单个键，其余的被丢弃。</p><p id="3c34" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这可以通过在执行连接之前分析数据并删除未使用的数据来解决。这将极大地提高查询速度，并减少不必要的数据在网络上传输。</p><p id="86a0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">检测洗牌问题:</strong></p><p id="5256" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">检查shuffle问题的最佳位置是查看Spark UI屏幕。</p><p id="1af1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在spark UI中，在作业→任务下，我们可以检查:</p><ul class=""><li id="db80" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">哪项任务比其他任务花费的时间多</li><li id="cdd1" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">正在启动推测性任务</li></ul><h1 id="379b" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">广播散列连接</h1><p id="9dba" class="pw-post-body-paragraph im in hi io b ip kw ir is it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj hb bi translated">当连接中的一个表足够小，可以放入内存时，可以使用广播散列连接。本质上，spark获取小表并将其复制到每台机器的内存中。<strong class="io hj">这确保了网络中不会出现数据混排，并且大型数据集的并行性也将得以保持</strong>。</p><p id="1410" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果我们使用拼花文件格式，spark catalyst optimiser会自动将这个决定广播到内存小表中。但是，如果我们使用其他文件格式，如文本文件，spark catalyst optimiser可能无法计算表格的大小，我们需要明确给出提示来广播表格。</p><h1 id="3452" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">笛卡尔连接</h1><p id="d2a6" class="pw-post-body-paragraph im in hi io b ip kw ir is it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj hb bi translated">笛卡尔连接可以很容易地分解输出行数:</p><p id="63b0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">10万* 10万= 100亿</p><p id="dd7b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了优化这种连接，我们需要增加集群的大小。决定聚类大小的更好方法是计算样本集的时间，然后根据原始数据集的大小进行相应的调整。</p><h1 id="9a23" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">一对多加入</h1><p id="e4af" class="pw-post-body-paragraph im in hi io b ip kw ir is it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj hb bi translated">一个表上的一行可以映射到另一个表上的多行。这也会导致输出行数激增。</p><p id="d31a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这种类型连接可以通过使用拼花文件格式来优化。输出文件的大小将会减小，因为parquet对重复数据进行了编码。</p><p id="0c12" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此输出文件的大小将小于输入表的大小。</p><h1 id="8070" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">θ连接</h1><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="1f8d" class="lb jz hi lu b fi ly lz l ma mb">rdd = sqlContext.sql("select * from table1 JOIN table2 ON (key1 &lt; key2 + 10)")</span></pre><p id="1053" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这种类型的连接是当连接条件不相等时，而是在某个范围的键上连接。</p><p id="f5f6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这种情况下，spark在内部执行一个完整的笛卡尔连接，并遍历每个记录来执行条件。即使输出文件删除了大部分记录，查询也会运行得非常慢。</p><p id="e988" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了优化theta连接，我们可以使用bucketing。我们可以用一种方式创建存储桶，这种方式可以在更少的数据集上以相同的条件连接查询。</p></div></div>    
</body>
</html>