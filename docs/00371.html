<html>
<head>
<title>Coding a batch processing pipeline with Google Dataflow and Apache Beam</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Google数据流和Apache Beam编写批处理流水线</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/coding-a-pipeline-for-batch-processing-with-google-dataflow-and-apache-beam-e3726ef96998?source=collection_archive---------0-----------------------#2019-05-04">https://medium.com/analytics-vidhya/coding-a-pipeline-for-batch-processing-with-google-dataflow-and-apache-beam-e3726ef96998?source=collection_archive---------0-----------------------#2019-05-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/81872bdcb047d9efb32ceabbd0ddfc89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FDttEYL6RFn09aYWBbN5Rg.png"/></div></div></figure><figure class="iq ir is it fd ij"><div class="bz dy l di"><div class="iu iv l"/></div></figure><h1 id="ae32" class="iw ix hi bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">语境</h1><p id="e8c3" class="pw-post-body-paragraph ju jv hi jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">几个月前，我有一个需求，要处理来自不同来源的一些信息，然后将所有信息放入Bigquery，使业务部门能够做出数据驱动的决策。</p><p id="daac" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">这些信息分布在不同的数据库中。因此，我有三个不同的Google Datastore实例，一个是运行在Compute Engine上的CouchDb，另一个是Firebase。</p><p id="3bd0" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">对于不知道CouchDb如何工作的人来说？嗯，主要是它的特点是它的API和它的工作原理是基于map reduce算法。因此，从couchdb消费数据的唯一方式是通过它的API使用HTTP请求。</p><p id="746f" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">所以如果你仔细想想。我们正在讨论数据流的一个常见用例，在故事的开头给出了特征图像。唯一的区别是firebase和couchdb是摄取列中的另外两个组件。</p><h1 id="117c" class="iw ix hi bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">挑战</h1><p id="79c6" class="pw-post-body-paragraph ju jv hi jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">创建管道，因为该公司主要与谷歌云平台合作。他们决定使用谷歌数据流，你可以想象我会遇到一些挑战:</p><ol class=""><li id="6995" class="kx ky hi jw b jx ks kb kt kf kz kj la kn lb kr lc ld le lf bi translated">首先，通过不同Google项目的认证。</li></ol><p id="e44c" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">2.最困难的事情是连接到CouchDb。Dataflow使用一个名为Apache Bean的强大python支持库来转换和操作数据。因此，为了建立到数据库的连接，Apache Bean已经有了一些驱动程序。但不幸的是，对于CouchDb来说，它没有一个本地连接器来检索数据。</p><p id="676f" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">3.这是我第一次使用数据流。所以，我对Apache Bean和Dataflow的主要概念一无所知。</p><h1 id="ecf4" class="iw ix hi bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">面对挑战</h1><p id="4340" class="pw-post-body-paragraph ju jv hi jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">因为我有这些问题。今天，我想分享一些代码，讲述我是如何使用apache beam构建的自定义连接器从couchdb检索数据的，然后我将向您展示如何将数据格式化为所需的格式，然后将最终数据写入Bigquery。</p><h1 id="fa74" class="iw ix hi bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">1.第一个挑战:启用身份认证:</h1><p id="c116" class="pw-post-body-paragraph ju jv hi jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">对于认证没有太大的问题，因为Google Dataflow通过不同的Google项目支持本地认证。我唯一要做的事情是，在数据存储实例所在的项目中，从Google cloud控制台的IAM和Admin菜单中启用对数据流代理的访问。</p><p id="ca85" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">比如说。假设我有两个谷歌项目。一个项目Id为501078922177，其中数据流作为appengine flex实例运行，另一个数据存储所在的项目Id为576371170178:因此，我想从数据流所在的另一个数据存储访问数据存储。</p><p id="7523" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">我要做的是在IAM和项目576371170178的管理是授予数据流用户作为云数据存储所有者。数据流用户它有一个你将在下面看到的格式。但是，在您的Google项目中启用数据流服务后，您可以在项目中找到它。</p><p id="601a" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">501078922177-compute@developer.gserviceaccount.com-&gt;数据流用户</p><p id="ac90" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">576373870178-compute@developer.gserviceaccount.com-&gt;数据存储用户</p><figure class="iq ir is it fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/bd4e4d31285ecddbce3a217d212f2565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*46QHlH8Dsx4fgKkAfjYBWA.png"/></div></div></figure><h1 id="21a5" class="iw ix hi bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">2.第二个挑战:使用数据流:</h1><p id="18d1" class="pw-post-body-paragraph ju jv hi jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">数据流是谷歌提供的最大的服务之一，通过支持流和批处理来转换和操作数据。为Dataflow上的代码提供的主要库是Apache beam，它不仅支持Google Dataflow，还支持我稍后将提到的另一个类似的服务。Apache beam也可用于java、python和Go。</p><p id="4eae" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">在开始分享代码之前，我建议您阅读一些关于Beam和数据流的关键术语:p集合、输入、输出、管道和转换。我们将在后面的代码中看到它们中的大部分，但是你可以在这里阅读更多关于<a class="ae lh" href="https://beam.apache.org/documentation/programming-guide/" rel="noopener ugc nofollow" target="_blank">的内容。</a></p><p id="dd6d" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">现在，让我们开始编码:</p><p id="6534" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">我们的示例将使用Flask和python创建一个http触发器来触发批处理管道执行，但是您也可以使用<a class="ae lh" href="https://cloud.google.com/pubsub/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=na-US-all-en-dr-skws-all-all-trial-p-dr-1006141&amp;utm_content=text-ad-none-any-DEV_c-CRE_338002380621-ADGP_Hybrid+%7C+AW+SEM+%7C+SKWS+%7C+RLSA+%7C+US+%7C+en+%7C+PHR+~+Big+Data+~+Pub/Sub+~+pub+sub-KWID_43700042031920858-aud-663326727744:kwd-380893598623&amp;utm_term=KW_pub%20sub-ST_pub+sub&amp;gclid=Cj0KCQjwnpXmBRDUARIsAEo71tQGfKVF1nDfuknqV3_KcSWAEp9Zg_0hRiyQUULQcG8RQCt8TGUsl5caAi8XEALw_wcB" rel="noopener ugc nofollow" target="_blank"> pubsub </a>作为触发器。</p><p id="d125" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">我们的文件夹结构如下:</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="b23c" class="ln ix hi lj b fi lo lp l lq lr">pipelines<br/>  __init__.py<br/>  api<br/>     __init__.py<br/>     endpoints<br/>       __init__.py<br/>       http_trigger.py</span><span id="693d" class="ln ix hi lj b fi ls lp l lq lr">     tools<br/>        pipe_options.py<br/>        __init__.py  <br/>  couch<br/>    __init__.py<br/>    beam<br/>      __init__.py # Beam connector to retrieve data from CouchDb<br/>      helper<br/>    services<br/>      __init__.py<br/>      paginator.py<br/>  tools<br/>    __init__.py<br/>    datastore.py</span><span id="814a" class="ln ix hi lj b fi ls lp l lq lr">  transforms <br/>    __init__.py<br/>    couch_data.py</span><span id="2a13" class="ln ix hi lj b fi ls lp l lq lr">main.py<br/>requirements.txt<br/>app.yaml<br/>setup.py<br/>appengine_config.py<br/>README.md</span></pre><p id="c565" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">第一步是创建main.py文件:</p><p id="8dbf" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj"> 2.1- &gt; main.py: </strong>基本定义了烧瓶App</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="a13a" class="ln ix hi lj b fi lo lp l lq lr"><strong class="lj hj">"""main.py"""</strong></span><span id="ac91" class="ln ix hi lj b fi ls lp l lq lr">from __future__ import absolute_import</span><span id="ec65" class="ln ix hi lj b fi ls lp l lq lr">import os<br/>from flask import Flask<br/>from pipelines.api.endpoints.http_trigger import *</span><span id="0d79" class="ln ix hi lj b fi ls lp l lq lr">APP = Flask(__name__)</span><span id="bd15" class="ln ix hi lj b fi ls lp l lq lr">if __name__ == '__main__':<br/>   print('serving on 0.0.0.0:8000')<br/>   APP.run(host='0.0.0.0', port=8000, debug=True</span></pre><p id="9d46" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj">2.2-&gt;pipelines/API/tools/pipe _ options . py:</strong></p><p id="6dfb" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">在这个文件中，我们将定义关于如何执行管道的管道选项；作业名称、工人数量、运行者，可以是下列之一:</p><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/3dff6699c8532d7e41958681ee0d0ff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*hd6p9QNPBa1GLY6tQvgCVg.png"/></div></figure><p id="d59a" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">在我们的例子中，我们将使用DataflowRunner，因为我们的项目将在Google Dataflow上运行。如果你想在阿帕奇射束可用的跑步者中潜水更多，在这里阅读更多<a class="ae lh" href="https://beam.apache.org/documentation/runners/capability-matrix/" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="e01b" class="ln ix hi lj b fi lo lp l lq lr">"""<strong class="lj hj">pipelines/api/tools/pipe_options.py</strong>"""</span><span id="a595" class="ln ix hi lj b fi ls lp l lq lr">def get_pipeline_options(job_name, runner='DataflowRunner',m<br/>   max_num_workers=10):<br/>   """Build pipeline options for profile_api."""<br/>   <br/>   project = 'PROJECT_ID' #replace with your projectId<br/>   bucket = 'BUCKET' # replace with your cloudstorage bucket<br/>   <br/>   pipe_options = {<br/>      'project': project,<br/>      'staging_location': 'gs://%s/dataflow' % bucket,<br/>      'runner': runner,<br/>      'setup_file': './setup.py',<br/>      'job_name': '%s-%s' % (project, job_name),<br/>      'max_num_workers': max_num_workers,<br/>      'temp_location': 'gs://%s/temp' % bucket<br/>   }</span><span id="bbc1" class="ln ix hi lj b fi ls lp l lq lr">   return pipe_options</span></pre><p id="60c4" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj"> 2.3 - &gt;管道/API/端点/http_trigger.py </strong> - &gt;烧瓶路线</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="f1be" class="ln ix hi lj b fi lo lp l lq lr">"""<strong class="lj hj">pipelines/api/endpoints/http_trigger.py</strong>"""</span><span id="be71" class="ln ix hi lj b fi ls lp l lq lr">from __future__ import absolute_import</span><span id="5f70" class="ln ix hi lj b fi ls lp l lq lr">from pipelines.api.tools.pipe_options import get_pipe_options<br/>from pipelines.transform_couchdata import transform_couchdata</span><span id="c71b" class="ln ix hi lj b fi ls lp l lq lr">from main import APP</span><span id="64b8" class="ln ix hi lj b fi ls lp l lq lr">@APP.route('/services/v1/pipeline_trigger')<br/>def migrate_session_data():<br/>   pipe_options = get_pipeline_options('transform-couchdata')<br/>   transform_couchdata(pipe_options)</span><span id="7609" class="ln ix hi lj b fi ls lp l lq lr">   return 'Done', 200</span></pre><p id="0f59" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">看到参数<strong class="jw hj"> transform-couchdata </strong>是我们的作业名，而<strong class="jw hj">migrate _ data _ fromcuchdb</strong>是执行我们的批处理的函数。</p><p id="fe21" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj"> 2.4 - &gt;管道/治疗床/服务/分页器. py </strong></p><p id="b71a" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">您将在下面看到的分页装饰器帮助我们从Couchdb中检索数据。</p><p id="8f0c" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">为了创建我们的连接器，我们将利用CouchDb上可用的一个特性，即视图。</p><p id="d070" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">CouchDb上的视图是如何工作的？</p><p id="eb2d" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">基本上，CouchDb上的视图公开了存储在Couchdb上的数据，以便通过http请求使用。请在这里阅读更多关于couchdb视图的内容。</p><p id="e51d" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">假设我们已经在couchdb上构建了一个视图，我们能够在来自<a class="ae lh" href="http://35.226.21.246:5984/profile/_design/passport/_view/users_with_education" rel="noopener ugc nofollow" target="_blank">http://yourcuchdburl:5984/&lt;数据库&gt;/_ design/&lt;design&gt;/_ view/&lt;v</a>view _ name&gt;的所有http请求中使用该视图，并且该视图以以下格式公开数据:</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="93bb" class="ln ix hi lj b fi lo lp l lq lr">{<br/>  "total_rows": "1000000",<br/>  "offset": "",<br/>  "rows": [<br/>      {<br/>        "<strong class="lj hj">id</strong>": "<strong class="lj hj">1344fdfa-f057-460d-906f-3421ddf..0000785e-f057-460d-906f-822ad7d43969..career</strong>",<br/>        "key": "0000785e-f057-460d-906f-822ad7d43969",<br/>        "value": "Software Engineering"<br/>     },<br/>     ...<br/>  ]<br/>}</span></pre><p id="6b12" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">如您所见，视图基本上是一个以json格式公开数据的web服务。在最后一个例子中，<strong class="jw hj"> id </strong>属性的格式为<strong class="jw hj">客户端..用户标识..doc_name </strong>，所以我们将使用双点作为分隔符将其拆分，然后将其转换为下面的格式，然后将其写入Bigquery中名为<strong class="jw hj"> UserCareer </strong>的表中:</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="0dff" class="ln ix hi lj b fi lo lp l lq lr">{<br/>   "client": "1344fdfa-f057-460d-906f-3421ddf",<br/>   "user_id": "0000785e-f057-460d-906f-822ad7d43969",<br/>   "value": "Software Engineering"<br/>}</span></pre><p id="dc03" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">我们如何将这些数据处理到我们的管道中，然后进行转换？</p><p id="89a2" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">请记住，数据流的主要思想是在数百台服务器之间执行数百个并行进程，以加快进程。因此，想象一下，我们将几乎同时使用不同的参数对couchdb视图执行数百个请求，以进行分页和其他操作。然后，我们将使用波束转换合并不同的响应，将所有内容放入同一个pcollection中。这个过程通常基于分布式编程的概念。因此，下面的python装饰器有助于处理http请求。</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="fde7" class="ln ix hi lj b fi lo lp l lq lr"><strong class="lj hj">"""pipelines/couch/service/paginator.py"""</strong></span><span id="dc3c" class="ln ix hi lj b fi ls lp l lq lr">import logging<br/>import requests<br/>import urllib</span><span id="41a3" class="ln ix hi lj b fi ls lp l lq lr">def paginate(func):<br/>   """Paginator."""</span><span id="6afe" class="ln ix hi lj b fi ls lp l lq lr">   def func_wrapper(self, *args, **kwargs):<br/>       """<br/>         Request a couchdb view.<br/>         This decorator can be used to decorate<br/>         methods part of the Requester class.<br/>       """</span><span id="0de5" class="ln ix hi lj b fi ls lp l lq lr">       couch_host = 'your couchdb host url or ip'<br/>       couch_port = '5984' # default port <br/>       database = self.database<br/>       design = self.design<br/>       view = self.view<br/>       limit = kwargs.get('limit', self.default_limit)<br/>       skip = kwargs.get('skip', self.default_skip)<br/>       params = {<br/>          'limit': limit,<br/>          'skip': skip<br/>      }<br/>      view_url = \<br/>         '{host}:port}/{database}/_design/{design}/_view/{view}?\<br/>           {params}'.format(<br/>              host=couch_host, port=couch_port,<br/>              database=database, design=design,<br/>              view=view, params=urllib.urlencode(params))</span><span id="2bf3" class="ln ix hi lj b fi ls lp l lq lr">      try:</span><span id="241d" class="ln ix hi lj b fi ls lp l lq lr">         req = requests.get(view_url)</span><span id="cc11" class="ln ix hi lj b fi ls lp l lq lr">         if req.status_code != 200 and req.status_code != 204:</span><span id="a1c8" class="ln ix hi lj b fi ls lp l lq lr">             raise Exception(<br/>                'Couch response with error, %s' % req.status_code)<br/>         response = req.json()</span><span id="cdc2" class="ln ix hi lj b fi ls lp l lq lr">         total_rows = response.get('total_rows')<br/>         offset = response.get('offset')<br/>         result = response.get('rows')<br/>         more = True<br/>        <br/>         if total_rows == offset:<br/>             more = False<br/>         <br/>         setattr(self, 'total_rows', total_rows)<br/>         setattr(self, 'offset', offset)<br/>         setattr(self, 'result', result)<br/>         setattr(self, 'more', more)</span><span id="8070" class="ln ix hi lj b fi ls lp l lq lr">         return func(self, *args, **kwargs)</span><span id="4f22" class="ln ix hi lj b fi ls lp l lq lr">      except ValueError, err:<br/>          msg = 'Invalid response in: %s: %s' % (view_url, err)</span><span id="a9b0" class="ln ix hi lj b fi ls lp l lq lr">          logging.error(msg)<br/>          raise ValueError(msg)</span><span id="ece9" class="ln ix hi lj b fi ls lp l lq lr">   return func_wrapper</span></pre><p id="3874" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj"> 2.5 - &gt;管道/治疗床/服务/__init__。py </strong></p><p id="fa7e" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">在这个文件中，我将定义一个对向couchdb api发出http请求有用的类。</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="dc60" class="ln ix hi lj b fi lo lp l lq lr"><strong class="lj hj">"""pipelines/couch/service/__init__.py"""</strong></span><span id="fb7a" class="ln ix hi lj b fi ls lp l lq lr">import logging<br/>import urllib<br/>import requests</span><span id="f380" class="ln ix hi lj b fi ls lp l lq lr">from pipelines.couch.services.paginator import paginate</span><span id="7c81" class="ln ix hi lj b fi ls lp l lq lr">class Requester(object):<br/>   """Implement methods to retrieve documents from CouchDb<br/>     using http calls."""</span><span id="ee7a" class="ln ix hi lj b fi ls lp l lq lr">    def __init__(self, database, design, view, limit=10, skip=0):<br/>        self.database = database<br/>        self.design = design<br/>        self.view = view<br/>        self.default_limit = limit<br/>        self.default_skip = skip</span><span id="9a2f" class="ln ix hi lj b fi ls lp l lq lr">    @paginate<br/>    def request_view(self, *args, **kwargs):<br/>       """Request the user-interests view using limit and skip  <br/>          parameters""" </span><span id="85eb" class="ln ix hi lj b fi ls lp l lq lr">        result = self.result<br/>        total_rows = self.total_rows<br/>        more = self.more</span><span id="3bae" class="ln ix hi lj b fi ls lp l lq lr">        logging.debug(total_rows)<br/>        <br/>        return result, total_rows, more</span><span id="a00e" class="ln ix hi lj b fi ls lp l lq lr">class Couch(object):<br/>   """Implement methods to manage documents from couch"""</span><span id="695e" class="ln ix hi lj b fi ls lp l lq lr">   def __init__(self):<br/>      self.couch_host = 'http: # your ip or dns'<br/>      self.couch_port = '5984' # default couchdb port </span><span id="6538" class="ln ix hi lj b fi ls lp l lq lr">   def get_document(self, database, document):<br/>      """Request a couchdb document"""</span><span id="87cf" class="ln ix hi lj b fi ls lp l lq lr">     document_url = '{host}:{port}/{database}/{document}'.format(<br/>        host=self.couch_host,<br/>        port=self.couch_port,<br/>        database=database,<br/>        document=document<br/>     )</span><span id="3746" class="ln ix hi lj b fi ls lp l lq lr">     try:</span><span id="96e5" class="ln ix hi lj b fi ls lp l lq lr">        req = requests.get(document_url)<br/>        if req.status_code != 200 and req.status_code != 204:<br/>           raise Exception(<br/>              'Couch response with error, %s' % req.status_code)</span><span id="fdb9" class="ln ix hi lj b fi ls lp l lq lr">        response = req.json()</span><span id="c2dc" class="ln ix hi lj b fi ls lp l lq lr">        return response</span><span id="7fd0" class="ln ix hi lj b fi ls lp l lq lr">     except ValueError, err:<br/>        msg = 'Invalid response in: %s: %s' % (document_url, err)<br/>        logging.error(msg)<br/>        raise ValueError(msg)</span></pre><p id="f40e" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj">2.6-&gt;pipelines/transform _ couch data . py</strong></p><p id="25e7" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">该文件包含管道定义。正如您将看到的，代码的关键和平是ReadFromCouchDb类，它在文件pipelines/couch/beam/__init__中定义。你将在2.7项中看到。此文件的另一个关键是自定义转换，它定义在文件pipelines/transforms/couch _ data . py中，您将在2.8项中看到。基本上，最后一个函数将数据转换成我们在Bigquery中需要的格式。最后<strong class="jw hj">readfromcuchdb</strong>返回一个pcollection，它是一组带有格式键值元组的项目。然后，我们使用<strong class="jw hj">formatcuchdatafn</strong>将数据转换为格式client，user_id，doc_name。</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="7004" class="ln ix hi lj b fi lo lp l lq lr">"""<strong class="lj hj">pipelines/transform_couchdata.py</strong>"""</span><span id="1ed1" class="ln ix hi lj b fi ls lp l lq lr">from __future__ import absolute_import</span><span id="7f95" class="ln ix hi lj b fi ls lp l lq lr">import logging<br/>import time</span><span id="34a6" class="ln ix hi lj b fi ls lp l lq lr">import apache_beam as beam</span><span id="aa85" class="ln ix hi lj b fi ls lp l lq lr">from apache_beam.options.pipeline_options import PipelineOptions<br/>from apache_beam.transforms import ParDo</span><span id="1fff" class="ln ix hi lj b fi ls lp l lq lr">from pipelines.couch import services<br/>from pipelines.couch.beam import ReadFromCouchDb</span><span id="1f1a" class="ln ix hi lj b fi ls lp l lq lr">COUCHDB_DATA_SCHEMA = ( # Bigquery schema<br/>    'user_id:STRING, client:STRING, value:STRING')</span><span id="6dc6" class="ln ix hi lj b fi ls lp l lq lr">def transform_couchdata(pipe_options):<br/>   pipe = beam.Pipeline(<br/>       options=PipelineOptions.from_dictionary(pipe_options))</span><span id="f5f8" class="ln ix hi lj b fi ls lp l lq lr">   couchdb_data = (pipe | 'read data from couch' &gt;&gt;<br/>       ReadFromCouchDb(services.Requester(<br/>            'database', 'design',   'couchdb_view')))<br/>   <br/>   formatted_couchdb_data = (<br/>      couchdb_data | 'Format Data' &gt;&gt; ParDo(FormatCouchDataFn()))</span><span id="559e" class="ln ix hi lj b fi ls lp l lq lr">   output_couchdb_table = '{project}:Dataset.UserCareer'.format(<br/>          project=project)</span><span id="904d" class="ln ix hi lj b fi ls lp l lq lr">formatted_couchdb_data | <br/>      'Write Couchdb data to BigQuery' &gt;&gt; beam.io.WriteToBigQuery(<br/>      output_couchdb_table, # table name in bigquery<br/>      schema=COUCHDB_DATA_SCHEMA,<br/>      create_disposition=\<br/>      beam.io.BigQueryDisposition.CREATE_IF_NEEDED,<br/>      write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE<br/>   )</span></pre><p id="5fa9" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj"> 2.7 - &gt;管道/治疗床/横梁/__init__。py </strong></p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="7c16" class="ln ix hi lj b fi lo lp l lq lr">"""<strong class="lj hj">pipelines/couch/beam/__init__.py</strong>"""</span><span id="3734" class="ln ix hi lj b fi ls lp l lq lr">from __future__ import print_function, absolute_import</span><span id="b8c2" class="ln ix hi lj b fi ls lp l lq lr">import logging</span><span id="8b8e" class="ln ix hi lj b fi ls lp l lq lr">from apache_beam.io import iobase<br/>from apache_beam.transforms import (<br/>     PTransform, Create, ParDo, DoFn, GroupByKey, FlatMap)</span><span id="b5f8" class="ln ix hi lj b fi ls lp l lq lr">from apache_beam.transforms.util import Values<br/>from pipelines.couch import services</span><span id="4a6c" class="ln ix hi lj b fi ls lp l lq lr">__all__ = ['ReadFromCouchDb']</span><span id="61c6" class="ln ix hi lj b fi ls lp l lq lr">class ReadFromCouchDb(PTransform):<br/>    """Read data from couchdb."""<br/>    _NUM_QUERY_SPLITS_MAX = 50000<br/>    _NUM_QUERY_SPLITS_MIN = 12</span><span id="49ef" class="ln ix hi lj b fi ls lp l lq lr">    def __init__(self, request, batch_size=20):<br/>        """Constructor."""<br/>        super(ReadFromCouchDb, self).__init__()</span><span id="c8bc" class="ln ix hi lj b fi ls lp l lq lr">        if not request:<br/>            ValueError('database cannot be empty')</span><span id="635f" class="ln ix hi lj b fi ls lp l lq lr">        self._request = request<br/>        self._batch_size = batch_size</span><span id="3154" class="ln ix hi lj b fi ls lp l lq lr">    def expand(self, pcollection):<br/>        """Read From Couch expand"""</span><span id="8b2b" class="ln ix hi lj b fi ls lp l lq lr">        requests = (pcollection.pipeline <br/>            | 'UserQuery' &gt;&gt; Create(['1'])<br/>            | 'CouchRequest' &gt;&gt; ParDo(ReadFromCouchDb.SplitQueryFn(<br/>                self._request, self._batch_size)))</span><span id="c375" class="ln ix hi lj b fi ls lp l lq lr">        shared_requests = (requests<br/>            | GroupByKey() <br/>            | Values()<br/>            | 'Flatten' &gt;&gt; FlatMap(lambda x: x))</span><span id="ca2c" class="ln ix hi lj b fi ls lp l lq lr">        documents = (shared_requests<br/>            | 'Read' &gt;&gt; ParDo(ReadFromCouchDb.ReadFn()))</span><span id="3bf6" class="ln ix hi lj b fi ls lp l lq lr">        return documents</span><span id="dd09" class="ln ix hi lj b fi ls lp l lq lr"><br/>class SplitQueryFn(DoFn):<br/>    """Split query"""</span><span id="0528" class="ln ix hi lj b fi ls lp l lq lr">    def __init__(self, request, batch_size):<br/>        self._request = request<br/>        self._batch_size = batch_size</span><span id="f3f2" class="ln ix hi lj b fi ls lp l lq lr">    def process(self, element):<br/>        """Splitting Requests"""</span><span id="9628" class="ln ix hi lj b fi ls lp l lq lr">        result, total, more = self._request.request_view(1, 0)<br/>        batch_size = self._batch_size<br/>        skip = 0</span><span id="d087" class="ln ix hi lj b fi ls lp l lq lr">        number_of_splits = total / batch_size<br/>        requested_splits = []</span><span id="9d5b" class="ln ix hi lj b fi ls lp l lq lr">        logging.debug(<br/>          'total: %s and more: %s, number_of_splits:%s',<br/>          total, more, number_of_splits)</span><span id="ddd8" class="ln ix hi lj b fi ls lp l lq lr">        for split in range(1, number_of_splits):<br/>            requested_splits.append(<br/>               (split, services.Requester(<br/>                  self._request.database,<br/>                  self._request.design,<br/>                  self._request.view,<br/>                  limit=batch_size,<br/>                  skip=skip)))</span><span id="aec0" class="ln ix hi lj b fi ls lp l lq lr">            skip += batch_size</span><span id="6f71" class="ln ix hi lj b fi ls lp l lq lr">        return requested_splits</span><span id="be31" class="ln ix hi lj b fi ls lp l lq lr">class ReadFn(DoFn):<br/>    """Make request to couch"""<br/>    def __init__(self):<br/>        super(ReadFromCouchDb.ReadFn, self).__init__()<br/>    <br/>    def process(self, request):<br/>        """Execute the request for each Requester object."""</span><span id="dd34" class="ln ix hi lj b fi ls lp l lq lr">        results, total, more = request.request_view()<br/>        documents = []</span><span id="76ae" class="ln ix hi lj b fi ls lp l lq lr">        if results:<br/>           for document in results:<br/>               documents.append((document.get('id'), document))</span><span id="531a" class="ln ix hi lj b fi ls lp l lq lr">        logging.debug('total: %s, more: %s', total, more)</span><span id="06a4" class="ln ix hi lj b fi ls lp l lq lr">        return documents</span></pre><p id="200e" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">这个文件是最重要的文件之一，也是我投入大量时间的地方。这里我们定义了couchdb连接器来从couchdb中检索数据。它所做的基本上是多次请求couchdb，将每个结果追加到最后返回的pcollection中。</p><p id="5830" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj"> 2.8 - &gt; </strong> <strong class="jw hj">管道/转换/couchdb_data.py </strong></p><p id="fece" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">一个有用的Beam类是DoFn类，它允许定义一个转换，然后返回一个pcollection。因此，下面的类定义了一个名为FormatGoalFn的转换。</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="af93" class="ln ix hi lj b fi lo lp l lq lr">"""<strong class="lj hj">pipelines/transforms/couchdb_data.py</strong>"""</span><span id="2de8" class="ln ix hi lj b fi ls lp l lq lr">import logging</span><span id="0b2c" class="ln ix hi lj b fi ls lp l lq lr">from apache_beam.transforms import DoFn</span><span id="ba99" class="ln ix hi lj b fi ls lp l lq lr"><br/>class FormatGoalFn(DoFn):</span><span id="a106" class="ln ix hi lj b fi ls lp l lq lr">   def process(self, element):<br/>       """Process user goals before write to bigquery."""</span><span id="56ef" class="ln ix hi lj b fi ls lp l lq lr">       doc_id, document = element<br/>       splited_doc_id = doc_id.split('..')<br/>       client_id = splited_doc_id[0]<br/>       user_id = splited_doc_id[1]<br/>       document_value = document.get('value')</span><span id="0fd6" class="ln ix hi lj b fi ls lp l lq lr">       value = {<br/>          'client_id': client_id,<br/>          'profile_id': profile_id,<br/>          'career_name': document_value<br/>       }<br/>       <br/>       yield value # used to add a row to the PCollection</span></pre><p id="be5c" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj"> 2.9 - &gt; </strong> <strong class="jw hj">管道/app.yaml </strong></p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="8840" class="ln ix hi lj b fi lo lp l lq lr">service: couchdataflow # the name of our appengine flex service<br/>runtime: python<br/>env: flex # runs on appengine flexible</span><span id="cf66" class="ln ix hi lj b fi ls lp l lq lr">entrypoint: gunicorn -b :$PORT main:APP</span><span id="a0c5" class="ln ix hi lj b fi ls lp l lq lr">runtime_config:<br/>  python_version: 2</span></pre><p id="9b55" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj"> 2.10 - &gt; </strong> <strong class="jw hj">管道/需求. txt </strong></p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="4207" class="ln ix hi lj b fi lo lp l lq lr">Flask==0.12.2<br/>apache-beam[gcp]==2.5.0<br/>gunicorn==19.9.0 <br/>google-cloud-dataflow==2.5.0<br/>google-cloud-storage==1.10.0<br/>httplib2==0.11.3<br/>requests</span></pre><p id="2bc5" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated"><strong class="jw hj">2.11-&gt;</strong><strong class="jw hj">pipelines/setup . py</strong></p><p id="b93c" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">这个文件是干什么用的？我之前告诉过你，你可能会想象我们的管道将在多个服务器上执行。因此，您可以推断我们的管道需要是一个python包。</p><p id="f3d4" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">因此，这个文件定义了一个使用setuptools构建的python包，可以安装在任何运行python 2的机器上。</p><pre class="iq ir is it fd li lj lk ll aw lm bi"><span id="a060" class="ln ix hi lj b fi lo lp l lq lr">from distutils.command.build import build as _build</span><span id="c50b" class="ln ix hi lj b fi ls lp l lq lr">import subprocess<br/>import setuptools</span><span id="5009" class="ln ix hi lj b fi ls lp l lq lr"># This class handles the pip install mechanism.</span><span id="447b" class="ln ix hi lj b fi ls lp l lq lr">class build(_build):  # pylint: disable=invalid-name<br/>    """A build command class that will be<br/>       invoked during package install. The package built<br/>       using the current setup.py will be staged and<br/>       later installed in the worker using <br/>       `pip install package'. This class will be <br/>        instantiated during install for this specific<br/>        scenario and will trigger running the <br/>        custom commands specified."""</span><span id="16ee" class="ln ix hi lj b fi ls lp l lq lr">    sub_commands = _build.sub_commands + [('CustomCommands', None)]</span><span id="9286" class="ln ix hi lj b fi ls lp l lq lr">    # Some custom command to run during setup. <br/>    # The command is not essential for this workflow.<br/>    # It is used here as an example. <br/>    # Each command will spawn a child process. <br/>    # Typically, these commands will include <br/>    # steps to install non-Python packages. For instance, <br/>    # to install a C++-based library libjpeg62 the following <br/>    # two commands will have to be added:</span><span id="57d4" class="ln ix hi lj b fi ls lp l lq lr">      ['apt-get', 'update'],<br/>      ['apt-get', '--assume-yes', install', 'libjpeg62'],</span><span id="be07" class="ln ix hi lj b fi ls lp l lq lr">    # First, note that there is no need to use the<br/>    # sudo command because the setup script runs with <br/>    # appropriate access.</span><span id="a50a" class="ln ix hi lj b fi ls lp l lq lr">    # Second, if apt-get tool is used then the first <br/>    # command needs to be 'apt-get</span><span id="dd8c" class="ln ix hi lj b fi ls lp l lq lr">    # update' so the tool refreshes itself and initializes <br/>    # links to download</span><span id="e07f" class="ln ix hi lj b fi ls lp l lq lr">    # repositories. Without this initial step the <br/>    # other apt-get install commands</span><span id="65df" class="ln ix hi lj b fi ls lp l lq lr">    # will fail with package not found errors. <br/>    # Note also --assume-yes option which</span><span id="b48b" class="ln ix hi lj b fi ls lp l lq lr">    # shortcuts the interactive confirmation.</span><span id="2731" class="ln ix hi lj b fi ls lp l lq lr">    # The output of custom commands (including failures) <br/>    # will be logged in the worker-startup log.</span><span id="36fd" class="ln ix hi lj b fi ls lp l lq lr">    CUSTOM_COMMANDS = [['echo', 'Custom command worked!']]</span><span id="1c9e" class="ln ix hi lj b fi ls lp l lq lr">class CustomCommands(setuptools.Command):<br/>    """A setuptools Command class able to run arbitrary commands."""</span><span id="780f" class="ln ix hi lj b fi ls lp l lq lr">    def initialize_options(self):<br/>        pass</span><span id="caef" class="ln ix hi lj b fi ls lp l lq lr">    def finalize_options(self):<br/>        pass</span><span id="4e2f" class="ln ix hi lj b fi ls lp l lq lr">    def RunCustomCommand(self, command_list):<br/>        print 'Running command: %s' % command_list</span><span id="b969" class="ln ix hi lj b fi ls lp l lq lr">        p = subprocess.Popen(<br/>           command_list, <br/>           stdin=subprocess.PIPE,<br/>           stdout=subprocess.PIPE,<br/>           stderr=subprocess.STDOUT)</span><span id="7845" class="ln ix hi lj b fi ls lp l lq lr">        # Can use communicate(input='y\n'.encode()) <br/>        # if the command run requires some confirmation.</span><span id="1123" class="ln ix hi lj b fi ls lp l lq lr">        stdout_data, _ = p.communicate()</span><span id="75c4" class="ln ix hi lj b fi ls lp l lq lr">        print 'Command output: %s' % stdout_data</span><span id="8f38" class="ln ix hi lj b fi ls lp l lq lr">        if p.returncode != 0:<br/>            raise RuntimeError('Command %s failed: exit code: %s' %\<br/>                   (command_list, p.returncode))</span><span id="b012" class="ln ix hi lj b fi ls lp l lq lr">    def run(self):<br/>        for command in CUSTOM_COMMANDS:<br/>            self.RunCustomCommand(command)</span><span id="e666" class="ln ix hi lj b fi ls lp l lq lr">REQUIRED_PACKAGES = []</span><span id="04f7" class="ln ix hi lj b fi ls lp l lq lr">setuptools.setup(<br/>    name='dataflow_python_pipeline',<br/>    version='0.0.1',<br/>    description='DataFlow Python Pipeline package.',<br/>    install_requires=REQUIRED_PACKAGES,<br/>    packages=setuptools.find_packages(),<br/>    cmdclass={'build': build, 'CustomCommands': CustomCommands},<br/>    include_package_data=True,<br/>    zip_safe=False<br/>)</span></pre><h1 id="198b" class="iw ix hi bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">3.第三个挑战:这是我第一次使用数据流</h1><p id="4df1" class="pw-post-body-paragraph ju jv hi jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">我很确定使用数据流和它的概念是非常困难的，总的来说，因为当我做这个项目的时候，有一个非常小的文档。</p><p id="ad3b" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">所以，我做的第一件事就是尽可能多的阅读。一切关于谷歌数据流和阿帕奇梁。</p><p id="2216" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">但是，在那一刻，我记得的主要事情是单元测试的重要性和价值。所以，我所做的就是克隆Apache Beam库，然后一遍又一遍地阅读和分析单元测试。这是我对刚开始学习的人的主要建议。</p><p id="b154" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">非常感谢。</p><p id="9605" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">我希望这个故事对你有用，如果你有任何问题或意见，请随时联系我<a class="ae lh" href="mailto:handerson.contreras@gmail.com" rel="noopener ugc nofollow" target="_blank">handerson.contreras@gmail.com</a>，或者更好的请在这里评论。</p><h1 id="6af8" class="iw ix hi bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">结论:</h1><p id="7137" class="pw-post-body-paragraph ju jv hi jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">不管你现在使用哪种服务来托管你的应用，重要的是你为产品增加的价值。因此，在决定迁移或升级到新服务或新技术之前，您应该考虑附加值，而不是受欢迎程度或趋势。</p><p id="07ec" class="pw-post-body-paragraph ju jv hi jw b jx ks jz ka kb kt kd ke kf ku kh ki kj kv kl km kn kw kp kq kr hb bi translated">作为一名软件开发人员，接触最新的技术是很好的，但是我们必须先考虑商业价值。</p><h1 id="88e4" class="iw ix hi bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated"><strong class="ak">参考文献:</strong></h1><div class="lu lv ez fb lw lx"><a href="https://beam.apache.org/documentation/" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">了解Beam</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">Apache Beam是一个开源、统一的模型和一组特定于语言的SDK，用于定义和执行数据…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">beam.apache.org</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml io lx"/></div></div></a></div><div class="lu lv ez fb lw lx"><a href="https://cloud.google.com/dataflow/" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">云数据流-流和批量数据处理|云数据流|谷歌云</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">简化的流和批处理数据处理，具有同等的可靠性和表现力</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">cloud.google.com</p></div></div><div class="mg l"><div class="mm l mi mj mk mg ml io lx"/></div></div></a></div></div></div>    
</body>
</html>