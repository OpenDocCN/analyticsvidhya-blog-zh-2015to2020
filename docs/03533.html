<html>
<head>
<title>Model inference comparison with TFlite &amp; Coral USB Accelerator device</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">与TFlite和Coral USB加速器设备的模型推理比较</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/model-inference-comparison-with-tflite-coral-usb-accelerator-device-f639e13d6e49?source=collection_archive---------12-----------------------#2020-02-06">https://medium.com/analytics-vidhya/model-inference-comparison-with-tflite-coral-usb-accelerator-device-f639e13d6e49?source=collection_archive---------12-----------------------#2020-02-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c4e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们准备一个实验，比较一个具有相似特征的模型，一个使用传统的台式机CPU，另一个使用EDGE TPU，会怎么样？</p><blockquote class="jd je jf"><p id="410a" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">单个Edge TPU每秒能够执行4万亿次运算(万亿次运算)，每个TOPS使用0.5瓦(每瓦2 TOPS)。这如何转化为应用程序的性能取决于多种因素。每个神经网络模型都有不同的需求，如果您使用USB加速器设备，总性能也会因主机CPU、USB速度和其他系统资源而异。<a class="ae jk" href="https://coral.ai/docs/edgetpu/benchmarks/" rel="noopener ugc nofollow" target="_blank">参考</a></p></blockquote><p id="e204" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">今天让我们探索一下选择使用USB加速器的体验，</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es jl"><img src="../Images/8040dea54fa487a4d3f50b33fe7f7d52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*JSoAXq_yaVvd15bo8H42mA.png"/></div></figure><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es jt"><img src="../Images/1621944041ba9c62db454b2018ecc6d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AcmdXlYu-lwW0oXRm0iSjA.jpeg"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">触摸设备</figcaption></figure><h2 id="3722" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated">开始实验分析</h2><p id="5d6b" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">探索<a class="ae jk" href="https://coral.ai/docs/edgetpu/benchmarks/" rel="noopener ugc nofollow" target="_blank">“每次推理的时间”表</a>，我很好奇使用桌面CPU和相同的主机CPU来试验模型推理，将推理委托给Coral accelerator。因此，这里的最初挑战是使用最同质的实验来探索两种环境之间的差异。</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es lc"><img src="../Images/e0bb0079b95725fa5f6ac7dc6b901f97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mNFnUmWgYamz9saFP-G2tQ.png"/></div></div></figure><h2 id="64eb" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated"><strong class="ak">最初的问题是关于推理方法的</strong></h2><blockquote class="jd je jf"><p id="908d" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">Edge TPU仅与TensorFlow Lite型号兼容。因此，通常我们必须训练一个TensorFlow模型，将其转换为TensorFlow Lite，并为Edge TPU编译它。<a class="ae jk" href="https://coral.ai/docs/edgetpu/inference/" rel="noopener ugc nofollow" target="_blank">参考</a></p></blockquote><p id="e151" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个实验，我将选择一个通用模型和等效的量化…方法，为整个python实现中的边缘TPU做准备。</p><h2 id="689d" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated">哪里可以下载模型？</h2><p id="74a6" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">我们当然可以使用TF Hub并探索不同版本的模型，也可以在<a class="ae jk" href="https://coral.ai/models/" rel="noopener ugc nofollow" target="_blank"> Coral页面</a>中看到许多量化模型。</p><p id="db0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们开始实验，我决定探索与MobileNet v2模型架构和224作为图片大小。<br/>我会试着遵循两个简单的步骤:</p><ul class=""><li id="df2b" class="ld le hi ih b ii ij im in iq lf iu lg iy lh jc li lj lk ll bi translated">创建一个使用桌面CPU分析图片的实现</li><li id="de03" class="ld le hi ih b ii lm im ln iq lo iu lp iy lq jc li lj lk ll bi translated">创建一个实现来使用边缘TPU珊瑚加速器和分析图像。</li></ul><p id="f1fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们应该将结果与建议的初始表进行比较，注意我们将使用不同的CPU类型主机。</p><h2 id="0c65" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated">履行</h2><p id="f67b" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">对于最初的场景，我创建了一个简单的<a class="ae jk" href="https://github.com/nbortolotti/tflite-tpu-experiences/tree/master/inference_exploration/cpu" rel="noopener ugc nofollow" target="_blank"> python脚本</a>来探索桌面CPU推理，作为替代，我还在Colab中提出了一个<a class="ae jk" href="https://github.com/nbortolotti/tflite-tpu-experiences/tree/master/inference_exploration/colab" rel="noopener ugc nofollow" target="_blank">等价实现</a>。(与TensorFlow Hub集成以获取模型的解决方案)</p><p id="533a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于Edge TPU应用程序，我使用了Coral加速器，这里的<a class="ae jk" href="https://github.com/nbortolotti/tflite-tpu-experiences/tree/master/inference_exploration/tflite" rel="noopener ugc nofollow" target="_blank"/>是为进行推理而创建的解决方案。*在代码库中，我添加了一个" *。sh”文件来完成初始要求并简化实验的表示。</p><div class="lr ls ez fb lt lu"><a href="https://github.com/nbortolotti/tflite-tpu-experiences/tree/master/inference_exploration" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab dw"><div class="lw ab lx cl cj ly"><h2 class="bd hj fi z dy lz ea eb ma ed ef hh bi translated">nbortolotti/tflite-TPU-体验</h2><div class="mb l"><h3 class="bd b fi z dy lz ea eb ma ed ef dx translated">使用Coral edge tpu加速器执行的示例记住:tflite_runtime是对tflite的依赖…</h3></div><div class="mc l"><p class="bd b fp z dy lz ea eb ma ed ef dx translated">github.com</p></div></div><div class="md l"><div class="me l mf mg mh md mi jr lu"/></div></div></a></div><h2 id="4d4d" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated">结论</h2><p id="105c" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">最后，正如我提到的那样，推理的性能取决于CPU类型、USB和主机性能，但一般来说，边缘TPU的执行速度要快10倍以上。</p><p id="9b55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图片224x224，架构MobileNet v2带CPU<br/>* i7–7500 u CPU 2.70 GHz×2<br/>* Linux内核:5 . 3 . 0–28-通用<br/> * <strong class="ih hj">推理平均:50毫秒</strong> <br/>图片224x224，架构MobileNet v2用Coral Edge TPU加速器量化。<br/> * <strong class="ih hj">平均推断时间:2.6毫秒</strong></p><p id="ac63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很好很类似于最初的性能表:)。现在你可以使用<a class="ae jk" href="https://github.com/nbortolotti/tflite-tpu-experiences/tree/master/inference_exploration" rel="noopener ugc nofollow" target="_blank">版本提供的</a>自己进行实验。</p><p id="6dba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这只是一个简单的例子，但是…你想看到更多使用Coral设备的项目吗？看看这个<a class="ae jk" href="https://coral.ai/projects/teachable-sorter/" rel="noopener ugc nofollow" target="_blank">可教分类器</a></p><figure class="jm jn jo jp fd jq"><div class="bz dy l di"><div class="mj mk l"/></div></figure></div></div>    
</body>
</html>