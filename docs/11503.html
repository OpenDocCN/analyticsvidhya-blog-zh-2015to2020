<html>
<head>
<title>A Brief study of Convolutional Neural Network(CNN) using MNIST Digit Recognizer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 MNIST 数字识别器研究卷积神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-brief-study-of-convolutional-neural-network-cnn-using-mnist-digit-recognizer-e054cf8863bf?source=collection_archive---------12-----------------------#2020-12-06">https://medium.com/analytics-vidhya/a-brief-study-of-convolutional-neural-network-cnn-using-mnist-digit-recognizer-e054cf8863bf?source=collection_archive---------12-----------------------#2020-12-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="feaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人工智能在过去十年里有了巨大的增长，看起来在不久的将来不会放缓。人工智能一直处于许多行业变革的前沿。科学家和工程师还有很多未开发的潜力。正如许多像我一样的工程师一样，对我们来说，具备参与这一新时代革命所需的知识是很重要的。</p><p id="980c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我解释了深度学习的一个最重要的概念:卷积神经网络。首先介绍了 CNN 的基础知识，然后完成了一个 MNIST 数字识别项目。我选择 MNIST 数据集，因为它被初学者广泛用来掌握神经网络，以开始他们的机器学习之旅。</p><h1 id="5bda" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">简介</strong></h1><p id="78ea" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">卷积神经网络是深度神经网络的一部分，在图像识别和处理方面已经非常成功。它有多种应用，包括人脸识别、物体检测、交通标志识别和为机器人的计算机视觉提供动力。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/a347e22b9a63abe2d362fe0885d39129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/0*ZdUYspjz3gl6yie1"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">这就是 CNN 对图像分类的工作方式(<a class="ae ks" href="https://github.com/cs231n/cs231n.github.io/blob/master/assets/classify.png" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="ed67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">几个经典的神经网络如下:</p><ol class=""><li id="084d" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated"><strong class="ih hj"> LeNet - 5 </strong></li></ol><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lc"><img src="../Images/305e36f9e24f8eca319a8377dae0525b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mmIazTRB8a7aWbrpgBs-hA.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">来源:<a class="ae ks" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" rel="noopener ugc nofollow" target="_blank">基于梯度的学习应用于文档识别(研究论文)</a></figcaption></figure><p id="f244" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LeNet 是一个经典的多层神经网络，已经成功地用于识别手写数字和机器印刷字符。它使用<strong class="ih hj">s 形</strong>非线性函数。按照现代标准，这尤其是一个拥有 60，000 个参数的较小的神经网络。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lh"><img src="../Images/c5927e7e7396a0640147d25f96f6edd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/0*PiOj2q4t0-EFkx_G"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">SIGMOID 函数</figcaption></figure><p id="5ca0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。AlexNet </strong></p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es li"><img src="../Images/eb6401061a8a7ad2dfad3a36d03cd979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aEtsEzSAyeRj0jF0h_qF6A.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">来源:<a class="ae ks" href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" rel="noopener ugc nofollow" target="_blank">深度卷积神经网络的 ImageNet 分类(研究论文)</a></figcaption></figure><p id="0dd8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AlexNet 是一个大型深度卷积神经网络，用于将 ImageNet LSVRC-2010 竞赛中的 120 万幅高分辨率图像分类为 1000 个不同的类别。它使用<strong class="ih hj"> ReLU 非线性函数</strong>。这个网络有 6000 万个参数和 650，000 个神经元，由五个卷积层组成，一些是最大池层，三个全连接层，最后是 1000 路 softmax。这些层被划分并在多个 GPU 上训练。一种叫做<strong class="ih hj">脱落</strong>的技术被用来防止过度拟合。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lj"><img src="../Images/779b41533844a03c046d50a87105a77a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/0*zGGyTbDgoEc_a5QY"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">脱落技术</figcaption></figure><p id="de5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。VGG——16</strong></p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lk"><img src="../Images/8d60c19686a4964b5b7b88bc14e7bb92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Deyrja_o9oMvafv-.jpg"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">VGG-16 建筑(<a class="ae ks" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="e0b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">VGG-16 是一个大型卷积神经网络，大约有 1.38 亿个参数。VGG16 中的 16 指的是它有 16 层有权重。VGG16 具有大量的超参数，这些参数集中于具有步幅为 1 的 3×3 滤波器的卷积层，并且总是使用步幅为 2 的 2×2 滤波器的相同填充和最大池层。整个架构都遵循卷积层和最大池层的这种安排。最后，它有 2 个完全连接的层，后面是 softmax(非线性函数)输出。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ll"><img src="../Images/7d4a1b94fb183459a3964a4288f958bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/0*fpA8R4N_n59i2VuJ"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">ReLU 非线性函数</figcaption></figure><h1 id="bb64" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">卷积神经网络</h1><h2 id="f2e5" class="lm je hi bd jf ln lo lp jj lq lr ls jn iq lt lu jr iu lv lw jv iy lx ly jz lz bi translated">卷积层(CONV)</h2><p id="ac26" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">这一层是 CNN 架构的基本构件。它获取输入图像，并对导致激活的图像使用过滤器。在滤波器和输入之间执行点积。</p><p id="7133" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入和滤波器之间的点积计算如下:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ma"><img src="../Images/edd2ae54f7ee28a3279c4f12a2cf744c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BM6dd116iPZi6shs.gif"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">(参考:CS231n 注释。)</figcaption></figure><p id="12d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于水平和垂直边缘检测，使用这些滤波器:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mb"><img src="../Images/5f8629bd89d2bca91e5e59349052b738.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/0*G-pDo2a7Ns_bsQ1J.png"/></div></figure><p id="1e0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积有两个缺点</p><ol class=""><li id="8b2e" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">图像尺寸缩小。</li><li id="b378" class="kt ku hi ih b ii mc im md iq me iu mf iy mg jc ky kz la lb bi translated">角上的像素比中心的像素用得少。因此存在信息损失。</li></ol><p id="477b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了克服这些缺点，我们使用<strong class="ih hj">填充</strong>技术:这是一个添加零层到我们的输入图像的过程。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mh"><img src="../Images/95164f3cffb8758aa8f6d2fe1bfc2029.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/0*vctQ0GNdHA6s0bmq.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">来源:geeksforgeeks</figcaption></figure><p id="237e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">填充类型:</p><ol class=""><li id="99bb" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated"><strong class="ih hj">有效填充:</strong>表示根本没有填充。输入图像保持不变。</li><li id="ceac" class="kt ku hi ih b ii mc im md iq me iu mf iy mg jc ky kz la lb bi translated"><strong class="ih hj">相同填充:</strong>在这种情况下，我们添加“p”个填充层，这样输出图像与输入图像具有相同的尺寸。</li></ol><h2 id="fbad" class="lm je hi bd jf ln lo lp jj lq lr ls jn iq lt lu jr iu lv lw jv iy lx ly jz lz bi translated">汇集层(池)</h2><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mi"><img src="../Images/4118752b84ab30f1c54f62e79b74796b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/0*c35KDTJyr_kp0ZlR"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">来源:<a class="ae ks" href="https://github.com/cs231n/cs231n.github.io/blob/master/assets/cnn/pool.jpeg" rel="noopener ugc nofollow" target="_blank">斯坦福 CS231 课程</a></figcaption></figure><p id="5bde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用池层来减少图像的尺寸，这将有助于加快计算速度。通过对大小为 F×F、步幅为 S 的邻域应用某个函数，池独立地调整输入特征向量的每个通道的大小。这里，F 是滤波器大小，S 是步幅。</p><p id="fabd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">联营类型:</strong></p><p id="ed72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">最大池化</strong></p><p id="d5ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从每个邻域中选取最大值。</p><p id="4999" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">平均池</strong></p><p id="4273" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算每个邻域的平均值。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es mj"><img src="../Images/7c1651baa1fb8c8254ac93a57605aac1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*o3Of0_0BAz7cXpnt.jpg"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">来源:斯坦福 CS217</figcaption></figure><h2 id="5ec9" class="lm je hi bd jf ln lo lp jj lq lr ls jn iq lt lu jr iu lv lw jv iy lx ly jz lz bi translated"><strong class="ak">全连接层(FC) </strong></h2><p id="1113" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我们使用完全连接的层来获取汇集/卷积层的输出，并使用它来将图像分类到标签中。在这一层中，汇集层的输出被展平成单个矢量输出，该矢量输出由表示图像属于特定标签的概率的值组成。</p><blockquote class="mk ml mm"><p id="2c15" class="if ig mn ih b ii ij ik il im in io ip mo ir is it mp iv iw ix mq iz ja jb jc hb bi translated">FC 层和 CONV 层之间的唯一区别在于，CONV 层中的神经元仅连接到输入中的局部区域，并且 CONV 体积中的许多神经元共享参数，而 FC 层中的神经元与前一层中的所有激活完全连接。然而，两层中的神经元仍然计算点积，因此它们的功能形式是相同的。</p></blockquote><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mr"><img src="../Images/7689453c0b1054ecf2be776d83cf58a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*ZfFUq_5N4BMBBSoQpTQyiw.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">完全连接的层</figcaption></figure></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><h1 id="1135" class="jd je hi bd jf jg mz ji jj jk na jm jn jo nb jq jr js nc ju jv jw nd jy jz ka bi translated">MNIST 数字识别器</h1><p id="9764" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">现在我们知道了卷积神经网络的基本原理，让我们开始这个项目。</p><p id="01d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集:-<a class="ae ks" href="https://www.kaggle.com/c/digit-recognizer/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/digit-recognizer/data</a></p><p id="d3ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="mn">注意——使用 Google Colab 作为它的 GPU 有助于神经网络的更快计算。</em></p><p id="93b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第一步</strong>:导入需要的库</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="79b2" class="lm je hi nf b fi nj nk l nl nm">import numpy as np</span><span id="18d4" class="lm je hi nf b fi nn nk l nl nm">import pandas as pd</span><span id="9225" class="lm je hi nf b fi nn nk l nl nm">import numpy as np</span><span id="4c9a" class="lm je hi nf b fi nn nk l nl nm">import tensorflow as tf</span><span id="d9cd" class="lm je hi nf b fi nn nk l nl nm">from tensorflow import keras</span></pre><p id="bae0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二步:</strong>导入数据集并保存在 dataframe 中</p><p id="014c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有两种方法可以做到这一点:</p><ol class=""><li id="4bcc" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">将文件从本地存储导入 Google Colab(较慢的方式)。</li></ol><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="c255" class="lm je hi nf b fi nj nk l nl nm">from google.colab import files</span><span id="2828" class="lm je hi nf b fi nn nk l nl nm">uploaded = files.upload()</span><span id="5495" class="lm je hi nf b fi nn nk l nl nm">import io</span><span id="2a1b" class="lm je hi nf b fi nn nk l nl nm">train = pd.read_csv(io.BytesIO(uploaded['train.csv']))</span><span id="ca57" class="lm je hi nf b fi nn nk l nl nm">test = pd.read_csv(io.BytesIO(uploaded['test.csv']))</span></pre><p id="9aab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.将文件从 Google Drive 导入 Google Colab(更快的方法)。</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="5440" class="lm je hi nf b fi nj nk l nl nm">from google.colab import drive</span><span id="2999" class="lm je hi nf b fi nn nk l nl nm">drive.mount('/content/drive/', force_remount=True)</span><span id="e057" class="lm je hi nf b fi nn nk l nl nm">train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Colab Datasets/MNIST/train.csv')</span><span id="3fa2" class="lm je hi nf b fi nn nk l nl nm">test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Colab Datasets/MNIST/test.csv')</span></pre><p id="cf61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是训练数据集的样子:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es no"><img src="../Images/a7573095c7c584015272c6acbfc9b4d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7UP-yTru0jw6DChb1ltERA.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">训练数据集视图</figcaption></figure><p id="3873" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤 3 </strong>:分离数据和标签</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="321a" class="lm je hi nf b fi nj nk l nl nm">train_data = train.loc[:,"pixel0":]</span><span id="3701" class="lm je hi nf b fi nn nk l nl nm">train_label= train.loc[:, "label"]</span></pre><p id="8d41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤 3 </strong>:将训练和测试数据转换为 numpy 数组</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="80d4" class="lm je hi nf b fi nj nk l nl nm">train_data = np.array(train_data)</span><span id="447e" class="lm je hi nf b fi nn nk l nl nm">train_label = tf.keras.utils.to_categorical(train_label, num_classes=10, dtype='float32')</span><span id="b111" class="lm je hi nf b fi nn nk l nl nm">test_data = test.loc[:, "pixel0":]</span><span id="2f44" class="lm je hi nf b fi nn nk l nl nm">test_data = np.array(test_data)</span></pre><p id="66ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第四步:</strong>对数据进行整形和归一化。</p><p id="e6e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们在这里写“1 ”,让 keras 知道它是一个灰度图像，它实际上不会改变值的数量。</strong></p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="e4f9" class="lm je hi nf b fi nj nk l nl nm">train_data = train_data.reshape(train_data.shape[0],28,28,1)</span><span id="4645" class="lm je hi nf b fi nn nk l nl nm">test_data  = test_data.reshape(test_data.shape[0],28,28,1)</span><span id="91c3" class="lm je hi nf b fi nn nk l nl nm">#Normalize the values between 0 to 1</span><span id="19a2" class="lm je hi nf b fi nn nk l nl nm">train_data = train_data/255.0</span><span id="1b06" class="lm je hi nf b fi nn nk l nl nm">test_data  = test_data/255.0</span></pre><p id="1937" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤 5: </strong>定义 CNN 层</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="cee3" class="lm je hi nf b fi nj nk l nl nm">model = tf.keras.models.Sequential([</span><span id="d0d2" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Conv2D(32, (5,5), activation='relu',input_shape=(28,28,1), padding= 'same'),</span><span id="4fe1" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Conv2D(32, (5,5), activation = 'relu', padding='same'),</span><span id="b9f0" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.MaxPooling2D(2,2),</span><span id="82ea" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Dropout(0.25),</span><span id="74ec" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Conv2D(64,(3,3),activation = 'relu',padding = 'same'),</span><span id="eee5" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Conv2D(64,(3,3),activation = 'relu',padding = 'same'),</span><span id="a964" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.MaxPooling2D(2,2),</span><span id="88cf" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Dropout(0.25),</span><span id="aa9b" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Flatten(),</span><span id="855a" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Dense(1024,activation = 'relu'),</span><span id="c233" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Dropout(0.5),</span><span id="276e" class="lm je hi nf b fi nn nk l nl nm">tf.keras.layers.Dense(10,activation = 'softmax')</span><span id="436b" class="lm je hi nf b fi nn nk l nl nm">])<br/></span><span id="6340" class="lm je hi nf b fi nn nk l nl nm">model.compile(optimizer = "adam", loss='categorical_crossentropy',</span><span id="c9cc" class="lm je hi nf b fi nn nk l nl nm">metrics=['accuracy'])</span></pre><p id="f4c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第六步:</strong>拟合模型</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="cc74" class="lm je hi nf b fi nj nk l nl nm">history = model.fit(train_data,train_label,epochs = 25)</span></pre><p id="458f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出:</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="4b5c" class="lm je hi nf b fi nj nk l nl nm">Epoch 1/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.1634 - accuracy: 0.9488 Epoch 2/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0609 - accuracy: 0.9809 Epoch 3/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0469 - accuracy: 0.9856 Epoch 4/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0392 - accuracy: 0.9880 Epoch 5/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0358 - accuracy: 0.9889 Epoch 6/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0300 - accuracy: 0.9909 Epoch 7/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0311 - accuracy: 0.9905 Epoch 8/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0288 - accuracy: 0.9912 Epoch 9/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0246 - accuracy: 0.9924 Epoch 10/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0233 - accuracy: 0.9930 Epoch 11/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0214 - accuracy: 0.9937 Epoch 12/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0206 - accuracy: 0.9933 Epoch 13/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0206 - accuracy: 0.9938 Epoch 14/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0218 - accuracy: 0.9936 Epoch 15/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0201 - accuracy: 0.9941 Epoch 16/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0189 - accuracy: 0.9945 Epoch 17/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0188 - accuracy: 0.9944 Epoch 18/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0161 - accuracy: 0.9948 Epoch 19/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0172 - accuracy: 0.9950 Epoch 20/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0175 - accuracy: 0.9953 Epoch 21/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0165 - accuracy: 0.9950 Epoch 22/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0166 - accuracy: 0.9955 Epoch 23/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0180 - accuracy: 0.9950 Epoch 24/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0149 - accuracy: 0.9959 Epoch 25/25 1313/1313 [==============================] - 6s 5ms/step - loss: 0.0195 - accuracy: 0.9949</span></pre><p id="27ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第 7 步</strong>:检查型号汇总使用:</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="8680" class="lm je hi nf b fi nj nk l nl nm">model.summary()</span></pre><p id="206e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出:</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="bca6" class="lm je hi nf b fi nj nk l nl nm">Model: "sequential" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= conv2d (Conv2D)              (None, 28, 28, 32)        832        _________________________________________________________________ conv2d_1 (Conv2D)            (None, 28, 28, 32)        25632      _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0          _________________________________________________________________ dropout (Dropout)            (None, 14, 14, 32)        0          _________________________________________________________________ conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496      _________________________________________________________________ conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928      _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0          _________________________________________________________________ dropout_1 (Dropout)          (None, 7, 7, 64)          0          _________________________________________________________________ flatten (Flatten)            (None, 3136)              0          _________________________________________________________________ dense (Dense)                (None, 1024)              3212288    _________________________________________________________________ dropout_2 (Dropout)          (None, 1024)              0          _________________________________________________________________ dense_1 (Dense)              (None, 10)                10250      ================================================================= Total params: 3,304,426 Trainable params: 3,304,426 Non-trainable params: 0 _________________________________________________________________</span></pre><p id="5900" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第八步</strong>:进行预测并保存。</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="fa63" class="lm je hi nf b fi nj nk l nl nm">predictions = model.predict(test_data)</span><span id="8355" class="lm je hi nf b fi nn nk l nl nm">prediction = []</span><span id="915d" class="lm je hi nf b fi nn nk l nl nm">for i in predictions:</span><span id="a7a4" class="lm je hi nf b fi nn nk l nl nm">      prediction.append(np.argmax(i))</span><span id="e566" class="lm je hi nf b fi nn nk l nl nm">#making a dataframe to save predictions and data values</span><span id="bd6d" class="lm je hi nf b fi nn nk l nl nm">submission =  pd.DataFrame({</span><span id="9640" class="lm je hi nf b fi nn nk l nl nm">"ImageId": test.index+1,</span><span id="facd" class="lm je hi nf b fi nn nk l nl nm">"Label": prediction</span><span id="582b" class="lm je hi nf b fi nn nk l nl nm">})</span><span id="f3ee" class="lm je hi nf b fi nn nk l nl nm">submission.to_csv('submission.csv', index=False)</span></pre><p id="65b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我们提交的内容的样子:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es np"><img src="../Images/7e93b27c7957ba2079c11fa286c62237.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/1*FmNoBGaI615wEvdRgividQ.png"/></div></figure><p id="55fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第 9 步:</strong>使用模型预测单个示例的结果</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="9f1e" class="lm je hi nf b fi nj nk l nl nm">import matplotlib.pyplot as plt</span><span id="fb6b" class="lm je hi nf b fi nn nk l nl nm">image = train_data[0].reshape(28,28)</span><span id="3acc" class="lm je hi nf b fi nn nk l nl nm">plt.imshow(image)</span></pre><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es nq"><img src="../Images/9afda958df41f5441a19ab4d6fe2df34.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*7VN04q0p74S1sUp9mEMzRg.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">我们将试图识别的图像</figcaption></figure><p id="0511" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">识别图像的代码:</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="4470" class="lm je hi nf b fi nj nk l nl nm">result = model.predict(np.array([train_data[0]]))</span><span id="254e" class="lm je hi nf b fi nn nk l nl nm">predicted_value = np.argmax(result)</span><span id="d9a5" class="lm je hi nf b fi nn nk l nl nm">print(predicted_value)</span></pre><p id="9ac7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出:</p><pre class="kh ki kj kk fd ne nf ng nh aw ni bi"><span id="01a4" class="lm je hi nf b fi nj nk l nl nm">1</span></pre><p id="f8c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Github 链接:<a class="ae ks" href="https://github.com/Atharva1604/MNIST-Digit-Recognizer-CNN" rel="noopener ugc nofollow" target="_blank">https://github.com/Atharva1604/MNIST-Digit-Recognizer-CNN</a></p><p id="fad8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请和我分享你对 CNN 和深度学习的想法。</p><p id="1cc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢大家！！！</p></div></div>    
</body>
</html>