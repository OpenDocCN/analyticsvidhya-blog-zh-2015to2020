<html>
<head>
<title>What are GAN’s? An Introduction to Generative Adversarial Networks.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">甘是什么？生成对抗网络导论。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/what-are-gans-an-introduction-to-generative-adversarial-networks-92efd00623d5?source=collection_archive---------22-----------------------#2020-05-17">https://medium.com/analytics-vidhya/what-are-gans-an-introduction-to-generative-adversarial-networks-92efd00623d5?source=collection_archive---------22-----------------------#2020-05-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><blockquote class="im"><p id="bca3" class="in io hi bd ip iq ir is it iu iv iw dx translated">“生成对抗网络是过去十年机器学习中最有趣的想法”</p><p id="7801" class="in io hi bd ip iq ir is it iu iv iw dx translated">-Yann LeCun，脸书公司董事</p></blockquote><figure class="iy iz ja jb jc jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es ix"><img src="../Images/adc62a9d5d98dc6876b35f4282ac4a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MwxEuCtEcCiN-jiq"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">在<a class="ae jo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae jo" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Franck V. </a>拍摄的照片</figcaption></figure><p id="9657" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi km translated"><span class="l kn ko kp bm kq kr ks kt ku di"> G </span>生成对抗网络(GANs)是一类用于无监督机器学习的人工智能算法，由两个神经网络在零和游戏框架中相互竞争的系统实现。生成建模是机器学习中的一项无监督学习任务，它涉及自动发现和学习输入数据中的规则或模式，以这种方式，模型可以用于生成或输出新的示例，这些示例很可能是从原始数据集中提取的。</p><p id="364f" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">gan是一种训练生成模型的聪明方法，它通过将问题构建为具有两个子模型的监督学习问题:我们训练以生成新示例的生成器模型，以及尝试将示例分类为真实(来自领域)或虚假(生成)的鉴别器模型。这两个模型在一个零和游戏中一起训练，对抗，直到鉴别器模型被愚弄了大约一半的时间，这意味着生成器模型正在生成似是而非的例子。</p><p id="0a7b" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">这两个神经网络模型被称为<strong class="jr hj">发生器</strong>和<strong class="jr hj">鉴别器</strong>模型。</p><p id="b130" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">发电机模型通过将噪声作为输入来产生样本。</p><p id="79a2" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">鉴别器模型接收来自训练数据和生成器的样本，并且必须能够区分这两个来源。</p><p id="32a6" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">在GANs中，有一个生成器和一个鉴别器。生成器生成虚假的数据样本(无论是图像、音频等。)并试图愚弄鉴别者。另一方面，鉴别器试图区分真假样品。发生器和鉴别器都是神经网络，它们在训练阶段相互竞争。这些步骤重复几次，这样，在每次重复之后，发生器和鉴别器在各自的工作中变得越来越好。</p><p id="0671" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">生成器，生成新的数据实例，而另一个，鉴别器，评估它们的真实性；即鉴别器决定它检查的每个数据实例是否属于实际的训练数据集。</p><p id="462f" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">所以，基本上，训练一个GAN有两个部分:</p><p id="c34a" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated"><strong class="jr hj">第1部分</strong>:鉴别器在发电机空闲时被训练。鉴别器在真实数据上被训练，并且看它是否能正确地预测它们是真实的。此外，在这个阶段，鉴别器也在来自生成器的假生成数据上被训练，并且看它是否能够正确地预测它们是假的。</p><p id="92de" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated"><strong class="jr hj">第2部分</strong>:鉴别器空闲时，发电机被训练。在鉴别器被生成器生成的假数据训练之后，我们可以得到它的预测，并且使用结果来训练生成器，并且从先前的状态变得更好，以试图欺骗鉴别器。</p><p id="cb88" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">这种GAN算法基于最小-最大算法的人工智能原理，其中鉴别器试图最小化奖励，而发生器试图最小化鉴别器的奖励或试图最大化其损失。</p><p id="8129" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated"><strong class="jr hj">甘的步骤:- </strong></p><p id="709c" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">1) <strong class="jr hj">定义问题</strong>——要生成假图片还是假文字。在此收集数据。</p><p id="d5f4" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">2) <strong class="jr hj">定义GAN的架构</strong> -定义GAN的架构，其中可能包括我们将使用哪种类型的神经网络。</p><p id="e8d1" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">3) <strong class="jr hj">训练鉴别器</strong> -获取您想要生成假的数据，并训练鉴别器正确预测它们为真。这里，值n可以是1到无穷大之间的任何自然数。</p><p id="10e4" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">4) <strong class="jr hj">根据假数据为发电机和列车鉴别器生成假输入</strong>。获取生成的数据，并让鉴别器正确地预测它们是假的。</p><p id="ba81" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">5) <strong class="jr hj">带鉴频器输出</strong>的列车发电机。现在，当鉴别器被训练时，您可以获得它的预测，并将其用作训练生成器的目标。训练发电机骗过鉴别器。</p><p id="85e3" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">6)重复步骤3至步骤5几次。</p><p id="9485" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">7)如果看起来合法，手动检查数据是否是伪造的。如果合适，停止训练，否则转到步骤3。这有点像手工操作，因为手工评估数据是检查真伪的最佳方式。当这一步结束时，您可以评估GAN的性能是否足够好。</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es kv"><img src="../Images/4d66bacbb61d1c47b996d4a60d93ef65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DNPtUcwet-pATV0o0dNDhw.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">一个典型的生成性对抗网络模型。</figcaption></figure><p id="361c" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated"><strong class="jr hj">氮化镓的应用:- </strong></p><p id="a3b5" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">1)文本到图像</p><p id="b11d" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">2)图像到图像生成</p><p id="1aaf" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">3)照片到表情符号</p><p id="2043" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">4)图像生成</p><p id="6ddc" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">5)绘画中的照片</p><p id="6cc6" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated"><strong class="jr hj">如果你想了解更多，你必须阅读的研究论文:- </strong></p><ol class=""><li id="d9a3" class="la lb hi jr b js jt jw jx ka lc ke ld ki le iw lf lg lh li bi translated">伊恩·古德菲勒等人的生成对抗网络</li></ol><figure class="kw kx ky kz fd jd er es paragraph-image"><div class="er es lj"><img src="../Images/024122b3cdd7d0a83d159fd012c0b364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*xYot1GacCJ7GVPNauh1oPQ.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">a) MNIST b) TFD c) CIFAR-10(全连接模型)d) CIFAR-10(卷积鉴别器和“去卷积”生成器)来自Goodfellow等人。</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1406.2661" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">生成对抗网络</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">我们提出了一个新的框架，通过一个对抗的过程来估计生成模型，在这个过程中，我们同时…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="4786" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">2.比根-布洛克等人(2019年)</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es lw"><img src="../Images/6ac99f293eadb86c90b3bd662968550e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JVUMTQpiBZOD22xQJXTHJQ.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">在Brock等人的论文BigGan中比较生成的狗图像的类别。</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1809.11096" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">用于高保真自然图像合成的大规模GAN训练</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">尽管最近在生成图像建模方面取得了进展，但成功地从图像生成高分辨率、多样化的样本…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="07d7" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">3.由Tero Karras等人设计的GAN风格</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es lx"><img src="../Images/59783008f892e140a879c1133b42c67b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2iTDSX_6YuqBM_ZzVKvPcg.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">两组图像和图像的融合在矩阵从纸风格甘</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1812.04948" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">一种基于风格的生成对抗网络生成器体系结构</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">我们借鉴风格转移理论，提出了一种新的生成对抗网络生成器结构</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="2ede" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">4.使用循环一致的对抗网络的不成对的图像到图像翻译，朱俊彦等人</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es ly"><img src="../Images/d271abf52b7b986f1c2423dab8025919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wHk0cMFPPeyMgPMXrCS_gQ.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">自动“翻译”图像从一个到另一个，反之亦然</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1703.10593" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">使用循环一致对抗网络的不成对图像到图像翻译</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">图像到图像的翻译是一类视觉和图形问题，其目标是学习图像和图形之间的映射</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="66fb" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">5.Grigory Antipov等人用GAN进行面部老化</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es lz"><img src="../Images/6f96a331c940970bbc2bbdd8adb4024f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RH6lRK0-LIDnYzw8z3uO0g.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">原始图像与来自Grigory Antipov等人的具有GAN的面部老化的重建图像</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1702.01983" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">基于条件生成对抗网络的人脸老化</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">最近的研究表明，生成敌对网络可以产生特殊的合成图像…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="7dd5" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">6.Yaniv Taigman等人的无监督跨域图像生成</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es ma"><img src="../Images/f5be4b3f415b22581ddeff68618904e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U19_38zUR6RSJLSs0iHWTQ.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">偶数列包含输入，而奇数列包含使用Yaniv Taigman等人的论文《无监督的跨域图像生成》中的GANs生成的图像的输出</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1611.02200" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">无监督跨域图像生成</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">我们研究将一个领域中的样本转移到另一个领域中的模拟样本的问题。鉴于两个相关的…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="13b2" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">7.Scott Reed等人的生成性对立文本到图像合成</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es mb"><img src="../Images/8926fe68f45705b28ce8c0f13a54484f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eo_Y5jBJfihERNwPnFXjWg.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">斯科特·里德等人提出了文本到图像的合成</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1605.05396" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">生成对立文本到图像合成</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">从文本中自动合成真实的图像将会是有趣和有用的，但是目前的人工智能系统还远远不能…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="6ae4" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">8.用生成对抗网络实现动漫角色的自动生成金等。</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es mc"><img src="../Images/2a780176209f4e7ea38037924d32a625.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FtM16mjZmB_3v2UUPNLTgg.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">由提出的方法生成的样本图像金等</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1708.05509" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">基于生成对抗网络的动画角色自动生成</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">自生成对抗网络(GAN)问世以来，人脸图像的自动生成得到了广泛的研究</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="1ba7" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">9.使用条件对抗网络的图像到图像翻译。</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es md"><img src="../Images/e5b4f9a8ccfdc253e12fce00cd296577.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5pTqAAiWeRw6-ZJMQtIcaQ.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">图像翻译从输入图像到相应的图像，从图像到图像的翻译与条件敌对网络。</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1611.07004" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">基于条件对抗网络的图像到图像翻译</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">我们研究条件对抗网络作为图像到图像翻译问题的通用解决方案…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="dbb9" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl iw hb bi translated">10.通过三维生成-对抗模型学习物体形状的概率潜在空间。</p><figure class="kw kx ky kz fd jd er es paragraph-image"><div class="er es me"><img src="../Images/401685e1d4ae832da954a43eab3c2abf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*_CzUwwBF51_YrcTr5ly48g.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">来源:-通过3D生成-对抗建模学习物体形状的概率潜在空间。吴家军等。</figcaption></figure><div class="lk ll ez fb lm ln"><a href="https://arxiv.org/abs/1610.07584" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">通过3D生成-对抗建模学习物体形状的概率潜在空间</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">我们研究三维物体的生成问题。我们提出了一个新的框架，即三维生成对抗网络…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">arxiv.org</p></div></div></div></a></div></div></div>    
</body>
</html>