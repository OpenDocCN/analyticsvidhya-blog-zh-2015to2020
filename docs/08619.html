<html>
<head>
<title>Deep dive into ResNets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入研究 ResNets</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-dive-into-resnets-eb4ec48dfcb0?source=collection_archive---------10-----------------------#2020-08-05">https://medium.com/analytics-vidhya/deep-dive-into-resnets-eb4ec48dfcb0?source=collection_archive---------10-----------------------#2020-08-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="c556" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">本文详细讨论了 ResNet 模型的基本架构，并对 ResNet 的构建块进行了解释。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/71b4b4028a9cce21a84a2e4f983cd750.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XBNcWO7FxfOjJGzJUYA46w.jpeg"/></div></figure><p id="5d56" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">几乎所有在深度学习领域工作的人，或者更具体地说是卷积神经网络，都熟悉 ResNet 这个名字。虽然它很受欢迎，但理解 ResNets 的基本工作原理是至关重要的。在使用这个网络的同时，我们也应该了解 ResNets 背后的架构。</p><p id="2ceb" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">人们普遍认为网络越深，精确度越高。然而，并不是所有的情况都是如此。</p><p id="cbcf" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">自 2013 年以来，深度学习社区开始建立像 AlexNet、VGG、Google Net(Inception Network)这样的深度卷积网络，因为它们能够实现高精度值。此外，这些更深的网络可以表示更复杂的特征，因此可以提高模型的鲁棒性和性能。然而，堆积更多的层对研究人员来说并不起作用。当训练更深的网络时，观察到精度下降的问题。换句话说，向网络中添加更多图层要么会使精度值饱和，要么会突然开始下降。精度下降的罪魁祸首是<strong class="jh hj">消失<em class="kb">梯度效应</em>。</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es kc"><img src="../Images/3817f4af979f0e38613fce87f3d732d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Kox5QUDSimV1BsLh"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">CIFAR-10 数据集的较大平原网络的误差增加</figcaption></figure><h1 id="9b50" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak">什么是消失渐变效果？</strong></h1><p id="20af" class="pw-post-body-paragraph jf jg hi jh b ji ld ij jk jl le im jn jo lf jq jr js lg ju jv jw lh jy jz ka hb bi translated">在机器学习中，当用梯度学习方法和反向传播训练网络时，网络的每个权重接收与误差函数相对于当前权重的偏导数成比例的更新。有时这个梯度变得很小，几乎不会引起重量的变化。由于这个问题，精度在特定值时开始下降或饱和。</p><p id="1f94" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">ResNet 解决了这个问题。所以，</p><h1 id="020d" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak">什么是 ResNet？</strong></h1><p id="553a" class="pw-post-body-paragraph jf jg hi jh b ji ld ij jk jl le im jn jo lf jq jr js lg ju jv jw lh jy jz ka hb bi translated">残差神经网络或最常见的 ResNet 几乎类似于具有卷积、汇集、激活和完全连接层的网络。使深度卷积网络成为剩余网络的唯一构造是层之间的身份连接。下图显示了网络中使用的基本残差块。同一性连接是从输入开始并下沉到剩余块末端的弯曲箭头。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es li"><img src="../Images/5a77b5b76d8f9d4d3e9e56ce416a4044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uTJG36GAYYCNAAc3DKUang.jpeg"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">残余块</figcaption></figure><p id="1e5f" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">再多了解一点<strong class="jh hj">残块。</strong>现在</p><h1 id="193a" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak">残块背后的直觉是什么？</strong></h1><p id="ef3a" class="pw-post-body-paragraph jf jg hi jh b ji ld ij jk jl le im jn jo lf jq jr js lg ju jv jw lh jy jz ka hb bi translated">ResNet 的作者观察到，无论一个网络有多深，它都不应该比一个较浅的网络差。这是因为如果我们认为神经网络可以逼近任何复杂的函数，那么它也可以学习相同的函数，即输入=输出，有效地跳过某些层的学习过程。但是，在现实世界中，由于消失梯度和维数灾难问题，情况并非如此。</p><p id="d3f7" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">每个网络都有一组达到最高分数所需的理想函数。实际上，在基本模型中，网络直接试图学习这些输出函数，即没有任何额外的支持，并且网络不可能学习理想的函数。然而，我们假设的深度网络太差，无法理解这些理想函数，因为梯度消失效应，也因为不支持的训练方式。</p><p id="cede" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对训练的支持将由添加到剩余输出的身份映射给出。首先，让我们看看身份映射的含义是什么？对输入应用身份映射将得到与输入相同的输出(<em class="kb"> XI = X </em>:其中<em class="kb"> X </em>是输入矩阵，<em class="kb"> I </em>是身份映射)。</p><p id="6bb4" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">ResNet 的创建者认为:<strong class="jh hj">“如果多个非线性层可以渐近逼近复杂函数，那么等价于假设它们可以渐近逼近剩余函数”</strong>。</p><p id="95e9" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在你想到的第一个问题是:</p><h1 id="a232" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak">什么是剩余函数，它是如何工作的？</strong></h1><p id="e06f" class="pw-post-body-paragraph jf jg hi jh b ji ld ij jk jl le im jn jo lf jq jr js lg ju jv jw lh jy jz ka hb bi translated">不严格地说，残差意味着误差。这里，残差函数是残差块的输入和真实输出之间的差。从上图我们可以清楚的看到<em class="kb"> x </em>是输入，<em class="kb"> H(x) </em>是残差块的真实输出。所以很明显剩余函数是<strong class="jh hj"><em class="kb">F(x)</em></strong>其中<strong class="jh hj"><em class="kb">F(x)</em>=<em class="kb">H(x)-x</em></strong>。</p><p id="c8b3" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">作者没有期望堆叠的层学习近似的<em class="kb">H(x)</em>，而是让层近似为剩余函数，<strong class="jh hj"> <em class="kb"> F(x) </em> </strong> <em class="kb">。</em></p><p id="0a0b" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">上面的陈述意味着，如果网络可以学习残差块(即残差函数)的输入和输出之间的差异，则整体精度增加。这就是 ResNet 和传统神经网络的区别。传统的神经网络将直接学习 H(x ),而 ResNet 对层进行建模，以学习子网输入和输出的残差。这将通过使<em class="kb"> </em> <strong class="jh hj"> <em class="kb"> F(x) = 0 </em> </strong>使得<strong class="jh hj"> <em class="kb"> H(x) = x </em> </strong> ( <strong class="jh hj">身份映射</strong>)来给予网络跳过子网的选项。换句话说，特定子网的输出只是最后一个子网的输出。</p><p id="615c" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">因此，这给了 ResNet 一个额外的选项，这可能是有用的，而不仅仅是严格地在所有层中进行计算。</p><h1 id="5251" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak">身份映射如何给网络带来如此巨大的变化？</strong></h1><p id="e381" class="pw-post-body-paragraph jf jg hi jh b ji ld ij jk jl le im jn jo lf jq jr js lg ju jv jw lh jy jz ka hb bi translated">仅仅一个简单的身份映射就能给我们的网络带来巨大的变化，这真是令人惊讶。我们已经讨论过简单深网中的消失梯度问题。现在我们将借助身份映射来解释同样的问题。我们知道在一个残差块中，<strong class="jh hj"> y = F(x，{Wi}) + x </strong>，其中<strong class="jh hj"> {Wi} </strong>是 CNN 层的权重数组，<strong class="jh hj"> x </strong>是输入，<strong class="jh hj"> F </strong>是残差函数。</p><p id="5b1c" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">让我们考虑网络的第三层的上述函数。然后</p><p id="47f5" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">F(x，{ wi })= w3*(𝞂(w2*x)——( 1)</p><p id="2145" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">其中，𝞂是<em class="kb">整流线性单元(ReLU) </em>激活函数。</p><p id="ef14" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在反向传播过程中，由于身份映射和剩余函数，ResNet 中存在两条路径。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es lj"><img src="../Images/6fa0c9ab3037e4fadb8eeb4965f9c83f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7QfJYW8W1HnMZf4rNVm6qg.jpeg"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">残余阻滞中的梯度路径</figcaption></figure><p id="afde" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">当上述方程(1)的计算梯度通过梯度路径-2 时，在剩余函数<strong class="jh hj"> <em class="kb"> F </em> </strong>中遇到两个权重层，即<strong class="jh hj"> W2 </strong>和<strong class="jh hj"> W3 </strong>。在反向传播期间，更新这些权重层，并计算新的梯度值。由于这种传播，初始层中的更新值要么变得非常小，要么消失。为了避免这个消失的问题，跳过连接或身份映射出现了。梯度可以直接通过<em class="kb">梯度路径-1，如上图中的</em>所示。在<em class="kb">梯度路径-1 中，</em>梯度不必遇到任何权重层，因此，计算的梯度值不会有任何变化。残余块将被立即跳过，并且梯度可以到达初始层，这将帮助它们学习正确的权重。此外，ResNet 版本 1 在加法运算后具有 ReLU 功能，因此，梯度值将在进入残差块后立即改变。</p><p id="8fe9" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">标识映射的另一个特性是它避免了额外的参数。因此，简单深度网络和 ResNet 的计算复杂度是相同的。</p><h2 id="f867" class="lk km hi bd kn ll lm ln kr lo lp lq kv jo lr ls kx js lt lu kz jw lv lw lb lx bi translated">函数定义的改进:</h2><p id="580a" class="pw-post-body-paragraph jf jg hi jh b ji ld ij jk jl le im jn jo lf jq jr js lg ju jv jw lh jy jz ka hb bi translated">由于相加，输入和剩余输出的维数必须相同。在某些情况下，图层的输出和身份输入具有不同的维度。例如，如果我们考虑一个 CNN，其中我们知道在卷积运算之后，输入的大小减小了(维度上)，那么将输入添加到新的输出是一个问题。因此，这里可以做的是，在跳过连接中，我们添加一些运算或函数(在本例中为卷积运算),以便将输入更改或配置为所需的维度。定义可以更新如下，<strong class="jh hj"> y = <em class="kb"> f </em> (x，{Wi}) + Ws*x </strong>，其中 Ws 项可以用某种卷积配置实现，使输入和输出的维数相等。</p><h1 id="01aa" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak">网络体系结构:</strong></h1><p id="a7bf" class="pw-post-body-paragraph jf jg hi jh b ji ld ij jk jl le im jn jo lf jq jr js lg ju jv jw lh jy jz ka hb bi translated">每个 ResNet 的名称后面都有一个数字，表示该 ResNet 中深层的层数。ResNet18、ResNet34 等。浏览下面给出的表格。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es ly"><img src="../Images/c0f2c7757984d46f9f2c526bc1fbd0f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sYG6nBinEuyvzBtk"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">重新划分图层</figcaption></figure><p id="6f13" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">每个 ResNet 架构都可以分成一系列具有一定数量滤波器的卷积层块，就像普通的卷积网络一样。在每两层的间隙处进行跳跃连接，即从一层的输入到第二层的输出，再从第三层的输入到第四层的输出。下图说明了这种机制。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lz"><img src="../Images/6e906db6cacf4a29d7c9fa7314133be6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/0*xtUTnH9Dod_4-fr1"/></div></figure><p id="2ec0" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">因此，可以用同样的想法来构建具有更多层的更大的网络。</p><p id="9274" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">由于现在网络很深，时间复杂度很高。瓶颈设计用于降低复杂性，如下所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ma"><img src="../Images/60dded0ebc32285c663363251f880c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/0*_KIAAmqpX-o4lJB_"/></div></figure><p id="b8d0" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">如图所示，1×1 conv 层被添加到网络的起点和终点。这是在<strong class="jh hj">Network In Network</strong>(<em class="kb">NiN</em>)和<strong class="jh hj">GoogLeNet</strong>(<em class="kb">Inception-v1</em>)中建议的技术。事实证明，1×1 conv 可以减少连接(参数)的数量，同时不会使网络性能下降太多。</p><p id="65e8" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">值得注意的是，VGG-16/19 有 153/196 亿次翻牌。ResNet-152 的复杂度仍然低于 VGG-16/19。</p><h2 id="207a" class="lk km hi bd kn ll lm ln kr lo lp lq kv jo lr ls kx js lt lu kz jw lv lw lb lx bi translated"><strong class="ak">雷斯内特·V2:</strong></h2><p id="7933" class="pw-post-body-paragraph jf jg hi jh b ji ld ij jk jl le im jn jo lf jq jr js lg ju jv jw lh jy jz ka hb bi translated">到目前为止，我们已经讨论了版本 1 ResNet，即 ResNet-V1。ResNet 或 ResNet-V2 的版本 2 使用预激活，而不是权重层的后激活。下图会给你一个清晰的概念。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es mb"><img src="../Images/49594be489ca39cbda3552ed7f8a5733.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*r29KJfYQUoPKvDqG"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">变体剩余块</figcaption></figure><p id="20dd" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">前三个图使用了重量层的后激活，因此很明显这些是雷斯网-V1 的基本结构。其余两个图在配重层之前采用预激活。</p><p id="64d4" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">让我们看看这两个版本之间的差异。</p><p id="7881" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">ResNet-V1 使用添加<strong class="jh hj"> x </strong>和<strong class="jh hj"> F(x) </strong>后的第二个激活函数。雷斯纳-V2 在加法之前激活非线性，以恒等函数的形式清除输入到输出的路径。</p><p id="6011" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">V1 先执行乘法，然后进行批量归一化和 ReLU 激活，而 V2 在与权重图层相乘之前将批量归一化和 ReLU 激活添加到输入中。</p><p id="4076" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">雷斯内特-V2 致力于将第二个非线性化为身份映射。因此，在输出层中计算的梯度可以容易地到达初始层，而无需网络中的任何改变。</p><h1 id="b023" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak">结果:</strong></h1><p id="5b68" class="pw-post-body-paragraph jf jg hi jh b ji ld ij jk jl le im jn jo lf jq jr js lg ju jv jw lh jy jz ka hb bi translated">ResNet 模型是 2015 年 ILSVRC 图像分类、检测和定位的获胜者，也是 2015 年 MS COCO 检测和分割的获胜者。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mc"><img src="../Images/9763188b71f7f17a8a0ef23fc3d6cb84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/0*fhvvKd1ZVl8zCc2i"/></div></figure><p id="eedb" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">上述结果(10-crop 测试)表明，具有 152 层的 ResNet 模型表现最佳，具有 5.71%的 top-5 错误率。</p><p id="1142" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">用 10 个作物测试+多尺度完全 conv+6 模式集成技术，误差率为 3.57%。</p><p id="2ff4" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于 CIFAR-10 数据集，结果如下:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es md"><img src="../Images/059d386a8b7144398158491596cbed16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cRP_MVrtFDatFT_N"/></div></div></figure><p id="7800" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">通过跳过连接，我们可以更深入。然而，当层数从 110 增加到 1202 时，错误率从 6.43%增加到 7.93%。尽管如此，它仍可用于训练，因为它确实收敛到最优解。</p><p id="092d" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><em class="kb">来源:</em></p><p id="c8f4" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae me" href="https://d2l.ai/chapter_convolutional-modern/resnet.html" rel="noopener ugc nofollow" target="_blank">https://d2l.ai/chapter_convolutional-modern/resnet.html</a></p><p id="158a" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae me" href="https://neurohive.io/en/popular-networks/resnet/#:~:text=Each%20ResNet%20block%20is%20either,ResNet%20(see%20above%20table)." rel="noopener ugc nofollow" target="_blank">https://neuro hive . io/en/popular-networks/ResNet/#:~:text = Each %20 ResNet%20 block % 20 is % 20 要么，ResNet % 20(见% 20 上表% 20)。</a></p><p id="19f9" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae me" href="https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec" rel="noopener" target="_blank">https://towards data science . com/residual-blocks-building-blocks-of-resnet-FD 90 ca 15d 6 EC</a></p><p id="2f92" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae me" rel="noopener" href="/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624">https://medium . com/@ 14 Prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-art-image-cf 51669 e 1624</a></p><p id="3589" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae me" href="https://cv-tricks.com/keras/understand-implement-resnets/" rel="noopener ugc nofollow" target="_blank">https://cv-tricks.com/keras/understand-implement-resnets/</a></p><p id="0278" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae me" href="https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8" rel="noopener" target="_blank">https://towardsdatascience . com/review-resnet-winner-of-ils vrc-2015-image-class ification-localization-detection-e 39402 bfa5d 8</a></p><p id="2035" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">ResNet 论文:<a class="ae me" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1512.03385</a></p></div></div>    
</body>
</html>