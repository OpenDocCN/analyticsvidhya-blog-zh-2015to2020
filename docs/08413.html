<html>
<head>
<title>Paper review-AsynDGAN:Train deep learning Without Sharing Medical Image Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文综述-AsynDGAN:在不共享医学图像数据的情况下训练深度学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/paper-review-asyndgan-train-deep-learning-without-sharing-medical-image-data-ac93b5592be4?source=collection_archive---------21-----------------------#2020-07-28">https://medium.com/analytics-vidhya/paper-review-asyndgan-train-deep-learning-without-sharing-medical-image-data-ac93b5592be4?source=collection_archive---------21-----------------------#2020-07-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="94cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每一个数字、表格都来自于论文。(如果来自其他论文或其他网站，则标记。)</p><h1 id="bd88" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">内容</h1><ol class=""><li id="daaa" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc ki kj kk kl bi translated">摘要</li><li id="e323" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">方法</li><li id="9015" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">结果和实验</li><li id="04bb" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">我的看法</li></ol><h1 id="5751" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">1.摘要</h1><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kr"><img src="../Images/ee00625ed9d7cac90bc042fe51d114f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g4zrfpIeS551jXjHLEpTYw.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">图一。AsynDGAN合成的脑肿瘤图像与真实图像的比较</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lh"><img src="../Images/73354d56a1cafc7ead28f8fa357deff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hV95uXnMEpfnFoLnNeMT6A.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">图二。AsynDGAN合成核图像与真实图像的比较</figcaption></figure><p id="ec00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae li" href="https://arxiv.org/abs/2006.00080" rel="noopener ugc nofollow" target="_blank">本文</a>被CVPR 2020接受。一般来说，由于医疗数据关系到患者的隐私，往往无法与他人分享。因此，由于公布的医疗数据很少，作者认为需要大量数据的模型，如深度学习，很难应用于医疗数据。</p><p id="25dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作者认为，从分布式鉴别器学习中心生成器G，并使用从G创建的图像，可以在医院之间不共享数据的情况下进行学习，并解决隐私问题。</p><p id="7974" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们还说，提出的模型可以解决以下问题:</p><ul class=""><li id="83a0" class="kb kc hi ih b ii ij im in iq lj iu lk iy ll jc lm kj kk kl bi translated">我们的实验表明，我们的方法可以从多个数据集学习真实图像的分布，而无需共享患者的原始数据</li><li id="5267" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc lm kj kk kl bi translated">实验表明，与其他分布式深度学习方法相比，我们的方法效率更高，所需带宽更低</li><li id="f709" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc lm kj kk kl bi translated">我们的实验表明，与由一个真实数据集训练的模型相比，我们的方法获得了更高的性能，而与由所有真实数据集训练的模型相比，我们的方法获得了几乎相同的性能</li><li id="24a3" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc lm kj kk kl bi translated">我们的实验表明，我们的方法有可证明的保证，发电机可以学习分布式分布</li></ul><p id="f293" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">代码可从<a class="ae li" href="https://github.com/tommy-qichang/AsynDGAN" rel="noopener ugc nofollow" target="_blank">这里</a>获得</p><h1 id="0592" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">2.方法</h1><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es ln"><img src="../Images/6712466d8fa1e95ddd589d84e2fdd4c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xVYVvXVQYwfevgCP5paPHg.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">图三。整个模型结构。</figcaption></figure><p id="e820" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如图2所示，中央生成器G接收特定于任务的输入(本文中的分段)。g创建一个合成图像来欺骗本地鉴别器(D1，D2，…，D_n)。D_n需要区分合成数据(x)和真实数据(G(x_n))。在G和D之间，只传输渐变和合成图像。因此，作者认为数据隐私没有被侵犯，因为只有本地医疗实体访问他们自己的真实数据(G(x_n))。</p><h2 id="fd1a" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">AsynDGAN的目标</h2><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mc"><img src="../Images/2778a61bc3bf8a0167ffd915b058fc7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IRyK-ZQ017U5m_qebV2-8g.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">Eq 1。经典条件GAN的目标</figcaption></figure><p id="a501" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在AsynDGAN中，G由N个不同的D监督，每个D与数据集的一个子集相关联。因此，s(x)可以表示如下。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es md"><img src="../Images/a002a30b521c880f1c471386389f5eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*qCFjQdigYvPvWq3UNoBJaA.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">Eq 2。辅助变量x上的混合分布</figcaption></figure><p id="2e2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，损失函数可以写成如下形式。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es me"><img src="../Images/5e4de578397a27a118a71833aace72e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*dQAS_-61mMyn414hXBiiQg.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">Eq 3。完全损失函数</figcaption></figure><h1 id="c1d1" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">优化过程</h1><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es mf"><img src="../Images/125cb3dafdc270cf5c462f85f17946fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*TFf3VhxaxvNxnvuFXCYeHg.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">图4。AsynDGAN的优化过程。</figcaption></figure><p id="f483" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在图3中，实线箭头表示正向传递，虚线箭头表示在我们的迭代更新过程的反向传递期间的梯度流。实线块表示它正在被更新，而虚线块表示它们在更新步骤中被冻结。红色和蓝色矩形分别是源遮罩和目标实像。</p><p id="63b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型更新遵循以下过程。</p><ol class=""><li id="e1ce" class="kb kc hi ih b ii ij im in iq lj iu lk iy ll jc ki kj kk kl bi translated">D-update:计算第j个鉴别器的对抗损失D_j，并更新D_j，其中j = 1，2，…，n。</li><li id="ebcd" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">G-update:在更新所有鉴别器之后，G将使用如下的对抗性损失进行更新。</li></ol><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es mg"><img src="../Images/9eba43694221c63df538abc03a0d2481.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*DG9xDjpY7RhZVsMkFzp6wA.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">Eq 4。对抗性损失</figcaption></figure><p id="e365" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这可以描述如下。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es mh"><img src="../Images/1357ffb018b25f8b8c19473a285183f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*BeBH6-rQFG9UvdsBd_bDeg.png"/></div></figure><h1 id="0e98" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">3.结果和实验</h1><h2 id="53a2" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">数据。</h2><p id="312a" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq mi is it iu mj iw ix iy mk ja jb jc hb bi translated">作者使用合成数据集，<a class="ae li" href="https://www.med.upenn.edu/sbia/brats2018/data.html" rel="noopener ugc nofollow" target="_blank"> BraTS2018 </a>，<a class="ae li" href="https://ieeexplore.ieee.org/document/7872382" rel="noopener ugc nofollow" target="_blank">多器官</a>。<br/>合成数据集由3个一维高斯组合而成。<br/>即y= ∑ (y_j + E_x=j)。此时，每个y_j遵循y _ 1 ~ N(3，2)、y_2 ~N (1，1)和y_3~N (3，0.5)。j = {1，2，3}。</p><h2 id="624a" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">合成数据集上的实验</h2><h2 id="c131" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">环境</h2><ul class=""><li id="8b66" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc lm kj kk kl bi translated">Syn-All:使用数据集中的所有样本训练常规GAN。</li><li id="faa2" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc lm kj kk kl bi translated">Syn-Subset-n:仅使用局部子集n中的样本训练常规GAN，其中n ∈ {1，2，3}。</li><li id="2a78" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc lm kj kk kl bi translated">AsynDGAN:以分布式方式使用所有子集中的样本来训练AsynDGAN。</li></ul><h2 id="023f" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">结果</h2><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es ml"><img src="../Images/c35a9e98b6083bbd375286a57a129b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2QfwrdD4Nruc4CQZ8c4AXw.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">图五。不同方法生成的分布</figcaption></figure><p id="b1d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在图4中，假设a是基线，c的结果看起来比b的结果好。</p><h2 id="86ea" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">脑肿瘤分割实验，细胞核分割</h2><h2 id="2e25" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">环境</h2><ul class=""><li id="d009" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc lm kj kk kl bi translated">真实全部:使用来自整个训练集的真实图像进行训练</li><li id="c8f3" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc lm kj kk kl bi translated">实数子集-n:实数子集-n。使用来自第n个子集的实数图像进行训练，其中n = 1，2，，10。用于脑瘤分割和<br/>n∈{乳腺、肝脏、肾脏、前列腺}。对于细胞核分割</li><li id="971b" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc lm kj kk kl bi translated">Syn-All:使用从常规GAN生成的合成图像进行训练。使用所有真实图像直接训练GAN</li><li id="949b" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc lm kj kk kl bi translated">AsynDGAN:使用来自提议的AsynDGAN的合成图像进行训练</li></ul><h2 id="2bf5" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">脑肿瘤分割结果</h2><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mm"><img src="../Images/f10d175a0e8601ef162d4589b6a36ed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7fxO8G3mUjdrxwYNdKgRKg.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">图六。典型的脑肿瘤分割结果。</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mn"><img src="../Images/2f65f173f28134d7a9b2daf4d6e0485a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kk4S1FGVIYbYFYQ7M-a6-A.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">表1。脑瘤分割结果。</figcaption></figure><h2 id="2119" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">细胞核分割结果</h2><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mo"><img src="../Images/cb49d7eaa443247a0677256b6b3c016d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pJcv03zxMDcEcQSJUbrFoA.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">图7。典型细胞核分割结果</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es mp"><img src="../Images/26fd7fd4192b27951b5ee33847441572.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*v6kh3ASpEuKkTOyl3D8RRA.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">表二。细胞核分割结果</figcaption></figure><h2 id="a976" class="lo je hi bd jf lp lq lr jj ls lt lu jn iq lv lw jr iu lx ly jv iy lz ma jz mb bi translated">结果</h2><p id="57f7" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq mi is it iu mj iw ix iy mk ja jb jc hb bi translated">当然Real-All表现最好。但是存在隐私问题，所以很多数据集无法访问。因此，在现实中，该模型显示了真实子集的性能。</p><p id="e099" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，AsynDGAN解决了隐私问题，并且比Real-Subset-n更好。此外，它显示了类似于Syn-All的结果，该结果是在使用所有真实数据学习后合成的。</p><h1 id="3e8a" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">我的看法</h1><p id="a128" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq mi is it iu mj iw ix iy mk ja jb jc hb bi translated">本文的观点为我们将深度学习应用于医学数据提供了重要的启示。</p><p id="87bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，为了实际实现，从分布式鉴别器更新G的过程，即</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es mq"><img src="../Images/e2e3d0c5ba2ce57b26c30e911860d540.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*0CxAokKSDfbR9g5-G7SlFQ.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">算法二。从D更新G</figcaption></figure><p id="2a21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，实际上，梯度和合成图像应该由几个医学实体从D转移到G。这个实现看起来是非常具有挑战性的任务。</p></div></div>    
</body>
</html>