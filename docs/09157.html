<html>
<head>
<title>Deployment Ready Deep Learning Models with TensorRT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorRT 的部署就绪深度学习模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deployment-ready-deep-learning-models-with-tensorrt-aff26c778566?source=collection_archive---------9-----------------------#2020-08-27">https://medium.com/analytics-vidhya/deployment-ready-deep-learning-models-with-tensorrt-aff26c778566?source=collection_archive---------9-----------------------#2020-08-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/83cfdf384ff29fa2c9d39f078615b025.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7APuC3ktqxPNnO0IadUoLQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">《机器人商业评论》供图</figcaption></figure><p id="e826" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">深度学习具有广泛的应用，例如自动驾驶汽车、空中监控、实时人脸识别解决方案、实时语言处理解决方案等等。但是这些应用程序之间只有一个相似之处。<strong class="iw hj">实时</strong>。考虑到这些模型的实时性能(吞吐量)的需要，我们需要优化训练的模型，以便它是精简的，但提供接近训练的准确性。</p><p id="9fa0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">TensorRT 是英伟达的深度学习推理平台。它基于 NVIDIA CUDA 编程模型构建，有助于我们利用 NVIDIA GPUs 提供的巨大并行性能。几乎所有流行框架的深度学习模型都可以使用 TensorRT 在 NVIDIA GPUs 上进行低延迟和高吞吐量推理的解析和优化。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es js"><img src="../Images/625fb40fe8ce1ae2660440f3523c3fd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZrPnoBMkaCkUo-GUbkdpMA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由英伟达提供</figcaption></figure><p id="f2f3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">使用 TensorRT，我们可以毫不费力地进行各种优化。以下是使用 TensorRT 可以完成的一些重要优化。</p><p id="02c9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">1.混合精度推理</p><p id="354d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">2.层融合</p><p id="a9c7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">3.定量</p><p id="25d5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">混合精度推断</strong></p><p id="7544" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">单精度浮点或简称 FP32 是深度学习训练时精度的选择。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es jx"><img src="../Images/c7920420392d31b9deca59f5ba14018d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/0*BChN2EIytL0fCbBa.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片由维基百科提供</figcaption></figure><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es jy"><img src="../Images/6044e7255805a138776670b0b7986b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/0*o8OovH9F1UGYmEju.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片由维基百科提供</figcaption></figure><p id="17f9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">FP32 有 8 位表示指数，23 位表示分数，非常适合所有这些梯度计算和更新。在推断过程中，如果模型给出接近训练精度，并且如果它是训练过程中的一半重，那么我们具有较少的存储器使用和高吞吐量的优势。使用 TensorRT，我们可以创建 FP16 精度或 INT 8 或 INT 4 精度的生产模型。</p><p id="6b2a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">图层融合</strong></p><p id="e6bc" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在讨论层融合之前，让我们看看指令是如何处理的。为了处理一条指令，存储器中的操作数必须传送到寄存器，然后由处理器执行操作，结果再次复制回存储器。有了这个粗略的想法，让我们看看层融合。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es jz"><img src="../Images/8875d1554e30a8bb35cbfc813c01529e.png" data-original-src="https://miro.medium.com/v2/resize:fit:190/format:webp/0*5Mk2XC6GQoYdhEfh.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">层融合</figcaption></figure><p id="9dcd" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">大多数深度学习模型中的层遵循一个序列。例如，卷积层之后是批处理规范化层，然后是激活层。这里我们有三个操作要顺序执行。通过层融合，我们不再针对每个操作在内存和寄存器之间来回传输数据，而是将数据从内存传输到寄存器，按顺序执行所有三个操作，并将最终结果传输回内存。通过这样做，我们节省了四个昂贵的数据传输周期。</p><p id="1ca5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">配料</strong></p><p id="dcc2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">GPU 有上千个处理核心；只是我们需要有效地使用它们。通过根据部署的目标平台规划适当的输入数据批量，我们可以最佳地利用大量的可用内核。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><h1 id="02e6" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">我和 TensorRT 的实验</strong></h1><p id="3c72" class="pw-post-body-paragraph iu iv hi iw b ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn lj jp jq jr hb bi translated">我尝试用 TensorRT 做实验，结果和 NVIDIA 声称的一样好。我用的是 NGC 的 NVIDIA GeForce GTX 1650 GPU 和 PyTorch 容器。稍后我会单独写一篇关于 NGC 的文章。PyTorch 容器装载了我实验所需的所有库，消除了所有安装障碍。</p><p id="ef97" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于这个实验，我使用了 CIFAR10 数据集和一个简单的定制 CNN。达到 95%以上的准确率并不是这项工作的目的。因此，我并不太关注架构和超参数，但我有兴趣与 TensorRT 合作，体验它带来的性能提升。</p><p id="005a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">工艺流程</strong></p><ol class=""><li id="6923" class="lk ll hi iw b ix iy jb jc jf lm jj ln jn lo jr lp lq lr ls bi translated">在 CIFAR10 数据集上训练 CNN</li><li id="8c07" class="lk ll hi iw b ix lt jb lu jf lv jj lw jn lx jr lp lq lr ls bi translated">将最佳模型保存在中。pth 格式</li><li id="7597" class="lk ll hi iw b ix lt jb lu jf lv jj lw jn lx jr lp lq lr ls bi translated">创造。已保存模型的 onnx 版本</li><li id="ea7a" class="lk ll hi iw b ix lt jb lu jf lv jj lw jn lx jr lp lq lr ls bi translated">从 ONNX 模型创建一个 TensorRT 引擎，并将其保存为. plan 文件以供重用</li><li id="a451" class="lk ll hi iw b ix lt jb lu jf lv jj lw jn lx jr lp lq lr ls bi translated">使用 TensorRT 引擎进行高性能深度学习推理</li></ol><p id="12ac" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="ly">我已经把 github 链接附在了我用于这个实验的 Jupyter 笔记本上。</em></p><div class="lz ma ez fb mb mc"><a href="https://github.com/Raj-Prasanna/TensorRT" rel="noopener  ugc nofollow" target="_blank"><div class="md ab dw"><div class="me ab mf cl cj mg"><h2 class="bd hj fi z dy mh ea eb mi ed ef hh bi translated">拉吉-普拉桑纳/滕索特</h2><div class="mj l"><h3 class="bd b fi z dy mh ea eb mi ed ef dx translated">在 GitHub 上创建一个帐户，为 Raj-Prasanna/TensorRT 的发展做出贡献。</h3></div><div class="mk l"><p class="bd b fp z dy mh ea eb mi ed ef dx translated">github.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq io mc"/></div></div></a></div></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><p id="93ca" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">我在 FP16 中使用 TensorRT 引擎的观察精度</strong></p><p id="ca68" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">1.当我的模型很浅时，性能并没有太大的提高。例如，只有 6 个卷积层，后面是各自的 ReLU 激活层和几个完全连接的层，我看不到任何可观的吞吐量增益。</p><p id="36b4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">2.当我将模型的深度增加到 20 个卷积层，然后是相应的 ReLU 层和几个完全连接的层时，我能够看到稳定的性能增益。我注意到吞吐量增加了 3 倍。</p><p id="ba2f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">3.TensorRT 发动机的尺寸大约是原 PyTorch 型号的一半。</p><p id="c3db" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="ly">感谢阅读。请留下你的建设性意见，关注我关于深度学习的文章。</em></p></div></div>    
</body>
</html>