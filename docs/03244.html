<html>
<head>
<title>Predicting user churn with PySpark (Part 3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PySpark预测用户流失(第三部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/predicting-user-churn-with-pyspark-part-3-89536234fa79?source=collection_archive---------26-----------------------#2020-01-21">https://medium.com/analytics-vidhya/predicting-user-churn-with-pyspark-part-3-89536234fa79?source=collection_archive---------26-----------------------#2020-01-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="08d1" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">这是由三部分组成的系列文章的最后一篇，解释了如何设置AWS EMR集群来训练和评估精心制作的模型</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/a92a08fca47b533eb37bcb046d2af257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zHsRLXWzeNYHtanEDeY3YQ.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">虚拟流媒体平台Sparkify的徽标</figcaption></figure><h1 id="a090" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">介绍</h1><p id="b832" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">这是一个三部分系列的最后一部分，在这个系列中，我描述了一种使用<a class="ae lb" href="https://pypi.org/project/pyspark/" rel="noopener ugc nofollow" target="_blank"> pyspark </a>预测用户流失的方法。在这里找到第一部分<a class="ae lb" rel="noopener" href="/@jcm.orlando/predicting-user-churn-with-pyspark-part-1-f13befbf04c3">，在这里</a>找到第二部分<a class="ae lb" rel="noopener" href="/@jcm.orlando/predicting-user-churn-with-pyspark-part-2-90874e6807bd">。</a></p><p id="4116" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">在本文中，我们将介绍设置一个<a class="ae lb" href="https://aws.amazon.com/emr/" rel="noopener ugc nofollow" target="_blank"> AWS EMR </a>集群所需的步骤，以便在完整的12GB数据集上运行前几篇文章中构建的预测管道。</p><h1 id="d9f4" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">设置EMR集群</h1><h2 id="529e" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">创建AWS帐户</h2><p id="d205" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">访问<a class="ae lb" href="https://aws.amazon.com/" rel="noopener ugc nofollow" target="_blank">aws.amazon.com</a>，点击“创建AWS账户”按钮。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lv"><img src="../Images/194afba7606450da7969467495b07a9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*GPcLwLFDH0i0l3S2T79WpQ.png"/></div></figure><p id="dd5a" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">如果您已经有AWS帐户，请登录。如果您没有AWS帐户，请注册。</p><ul class=""><li id="a08f" class="lw lx hi kh b ki lc kl ld ko ly ks lz kw ma la mb mc md me bi translated">当你注册时，你需要提供一张信用卡。但是不要担心，你还不会被收取任何费用。</li><li id="5111" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated">您还需要选择一个支持计划。您可以选择免费的基本支持计划。</li><li id="13f6" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated">一旦您完成注册，等待几分钟，以收到您的AWS帐户确认电子邮件。然后返回<a class="ae lb" href="https://aws.amazon.com/" rel="noopener ugc nofollow" target="_blank">aws.amazon.com</a>并签到。</li></ul><h2 id="251d" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">启动EMR集群</h2><p id="f663" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">前往<a class="ae lb" href="https://console.aws.amazon.com/elasticmapreduce/" rel="noopener ugc nofollow" target="_blank">亚马逊EMR控制台</a>。然后在左侧菜单中选择“集群”，并单击“创建集群”按钮。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mk"><img src="../Images/c76c9918ab1270862aa8c65923b26726.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*Neffbr47akx7-plB24Ea1g.png"/></div></figure><p id="5f56" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">使用以下设置配置您的群集:</p><ul class=""><li id="19f8" class="lw lx hi kh b ki lc kl ld ko ly ks lz kw ma la mb mc md me bi translated"><strong class="kh hj">版本:</strong> emr-5.28.0或更高版本</li><li id="2ffa" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated"><strong class="kh hj">应用:</strong> Spark 2.4.4或更高版本</li><li id="7cdf" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated"><strong class="kh hj">实例类型:</strong> m5.xlarge</li><li id="492a" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated">例数: 3</li><li id="30d1" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated"><strong class="kh hj"> EC2密钥对:</strong>没有EC2密钥对也可以继续，如果您愿意，可以随意使用自己创建的密钥对</li></ul><p id="833f" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">您可以保留其余的默认设置，并单击右下角的“创建集群”。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/1975b6b58980b31b6dc09c019f4ab6d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZ0roZLuQV7Fi0ELfoAyNg.png"/></div></div></figure><p id="4d69" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">创建集群后，您会在名称旁边看到一个状态，显示“正在启动”。在进入下一步之前，请稍等片刻，让此状态变为“正在等待”。</p><h2 id="b6dd" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">创建Jupyter笔记本</h2><p id="1cdd" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">现在您已经成功地启动了集群，让我们创建一个笔记本来在集群上运行PySpark代码。在左侧菜单中选择“笔记本”，然后单击“创建笔记本”按钮。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mm"><img src="../Images/2fbec7b40df9131cd663e392ac4c9b8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*A2o9eUV1K5sZ3uBvuz5jEA.png"/></div></figure><p id="e904" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">配置您的笔记本</p><ul class=""><li id="3d88" class="lw lx hi kh b ki lc kl ld ko ly ks lz kw ma la mb mc md me bi translated">输入笔记本的名称</li><li id="6df3" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated">选择“选择现有集群”，然后选择您刚刚创建的集群</li><li id="97a6" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated">使用“AWS服务角色”的默认设置—如果您以前没有这样做过，应该是“EMR_Notebooks_DefaultRole”或“创建默认角色”。</li></ul><p id="4ce1" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">您可以保留其余的默认设置，然后单击右下角的“创建笔记本”。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/b09ca8ac18055abbbc79e10a55f77d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lws47jPvBBikTrzEO9c6nA.png"/></div></div></figure><p id="7552" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">等待笔记本进入“就绪”状态，然后点击“在JupyterLab中打开”来访问笔记本。</p><h2 id="1534" class="lh jo hi bd jp li lj lk jt ll lm ln jx ko lo lp jz ks lq lr kb kw ls lt kd lu bi translated">复制功能</h2><p id="8002" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">在左侧面板中打开您创建的笔记本。如果它要求内核，选择PySpark。然后将代码复制粘贴到我创建的这个<a class="ae lb" href="https://gist.github.com/ojcastillo/2e139ac0f69796b6158afb9db220fa51" rel="noopener ugc nofollow" target="_blank"> public gist </a>中，在本系列的前几篇文章中定义了所有需要的函数，所以这里没有什么函数对你来说是新的。</p><h1 id="6088" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">在大型数据集上尝试模型</h1><p id="359d" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">如果您完成了前面的所有步骤，现在您应该已经在AWS上打开了一个Jupyter笔记本，并复制了一个启动代码。我们现在可以开始加载12GB的数据集，我们可以轻松地从笔记本电脑上下载，因为数据存储在S3上:</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="77ad" class="lh jo hi mp b fi mt mu l mv mw"># Set up SparkSession and load the 12GB dataset <br/>spark = SparkSession \<br/>    .builder \<br/>    .appName("Sparkify") \<br/>    .getOrCreate()<br/>df_large = load_df_for_ml(<br/>    's3n://udacity-dsnd/sparkify/sparkify_event_data.json')<br/>df_large.sort('userId').show()</span><span id="359a" class="lh jo hi mp b fi mx mu l mv mw"><strong class="mp hj"><em class="my">+-------+-------+---------------+<br/>| userId|churned|number_sessions|<br/>+-------+-------+---------------+<br/>|1000025|      1|             17|<br/>|1000035|      0|             22|<br/>|1000083|      1|             11|<br/>|1000103|      0|              4|<br/>|1000164|      0|             18|<br/>|1000168|      0|              8|<br/>|1000182|      0|              4|<br/>|1000194|      0|              3|<br/>|1000214|      0|             27|<br/>|1000233|      0|              5|<br/>|1000244|      0|              2|<br/>|1000248|      0|             15|<br/>|1000280|      1|             22|<br/>|1000353|      1|              4|<br/>|1000407|      0|             25|<br/>|1000409|      0|             29|<br/>|1000446|      0|              6|<br/>|1000503|      1|              3|<br/>|1000527|      0|             10|<br/>|1000611|      0|             26|<br/>+-------+-------+---------------+<br/>only showing top 20 rows</em></strong></span><span id="6142" class="lh jo hi mp b fi mx mu l mv mw"># Get number of users and percentage of churned users<br/>nrows = df_large.count()<br/>churned_users = df_large.where('churned=1').count()<br/>print(f'Number of users in dataset: {total_rows}')<br/>print(<br/>    f'Percentage churned users: {100 * churned_users / nrows:.2f}')</span><span id="da9b" class="lh jo hi mp b fi mx mu l mv mw"><strong class="mp hj"><em class="my">Number of users in dataset: 22278<br/>Percentage churned users: 22.46</em></strong></span></pre><p id="a9c6" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">我们已经到了真相大白的时刻！现在，我们可以继续使用完整的数据集来训练和测试我们的预测管道。使用上一节中提供的示例集群配置，这可能需要近1个小时:</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="4efb" class="lh jo hi mp b fi mt mu l mv mw"># Split dataset into 80% for training and 20% for validation<br/>large_train_df, large_validation_df = df_large.withColumnRenamed('churned', 'label').randomSplit(<br/>    [0.8, 0.2], seed=42)</span><span id="0c55" class="lh jo hi mp b fi mx mu l mv mw"><em class="my"># Apply k-fold cross-validation to try to find better hyperparameters</em><br/>cv = build_cross_validator()<br/>cv_model = cv.fit(large_train_df)</span><span id="cb10" class="lh jo hi mp b fi mx mu l mv mw"><em class="my"># Evaluate the performance of the cross-validated model</em><br/>results = cv_model.transform(large_validation_df)<br/>results = eval_model(cv_model, large_validation_df)</span><span id="918d" class="lh jo hi mp b fi mx mu l mv mw"><strong class="mp hj"><em class="my">Performance Stats<br/>Accuracy: 0.8034<br/>Precision = 0.5958<br/>Recall = 0.3947<br/>F1 Score = 0.4748</em></strong></span></pre><p id="2d9c" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">在尝试大型数据集时，模型的回忆能力得到了提高，因此更多的数据确实有助于提高模型的概括能力！我们的精度变得有点差，但总体来说F1的得分比以前好，所以我认为这是对较小数据集所取得的进步。</p><h1 id="12e0" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">结论</h1><p id="0a35" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">在这三篇文章中，我向您展示了如何有效地使用pyspark在虚构的Sparkify音乐流媒体平台的12GB数据集上预测用户流失。</p><p id="ff20" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">我们开始在一个更小的128MB的数据集上工作，这样我们可以更快地迭代。经过一些数据探索后，我们能够识别从平台中流失的用户，并根据为每个用户提取的以下特征构建一个模型来预测流失:</p><ul class=""><li id="bc85" class="lw lx hi kh b ki lc kl ld ko ly ks lz kw ma la mb mc md me bi translated"><code class="du mz na nb mp b">number_sessions</code>:会话总数</li><li id="581c" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated"><code class="du mz na nb mp b">seconds_since_genesis</code>:从第一次记录的出现开始的总秒数</li><li id="5c65" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated"><code class="du mz na nb mp b">avg_actions_per_session</code>:每次会话的平均操作量</li><li id="4a7a" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated"><code class="du mz na nb mp b">avg_seconds_per_session</code>:每次会话花费的平均秒数</li></ul><p id="e16c" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">在本地尝试了该模型并对其预测能力有了信心之后，我们接着使用由AWS EMR支持的分布式集群在12GB数据集上尝试了相同的代码。</p><p id="5ec0" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">使用大数据集训练和验证模型的结果令人鼓舞。将模型应用于随机抽取的20%数据集进行验证时，获得了以下指标:</p><ul class=""><li id="d703" class="lw lx hi kh b ki lc kl ld ko ly ks lz kw ma la mb mc md me bi translated"><strong class="kh hj">精度</strong> : 0.8034</li><li id="cec6" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated"><strong class="kh hj">精度</strong> : 0.5958</li><li id="65ed" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated"><strong class="kh hj">回忆:</strong> 0.3947</li><li id="2baa" class="lw lx hi kh b ki mf kl mg ko mh ks mi kw mj la mb mc md me bi translated"><strong class="kh hj"> F1得分:</strong> 0.4748</li></ul><p id="b936" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">所获得的高准确度和精确度水平向我表明，该模型为某一类流失用户建立了一致的档案:那些没有太多地使用该平台的用户。但不太高的召回率告诉我，我们错过了捕捉其他类型的用户决定流失的行为。</p><h1 id="6f0d" class="jn jo hi bd jp jq jr js jt ju jv jw jx io jy ip jz ir ka is kb iu kc iv kd ke bi translated">潜在的后续步骤</h1><p id="df70" class="pw-post-body-paragraph kf kg hi kh b ki kj ij kk kl km im kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">一个好的下一步可能是回到特征工程阶段。也许可以从用户在搅动之前访问的页面中提取更多的信息，或者也许用户是否为服务付费也是一个强有力的指标。</p><p id="6534" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">之后，使用更大的EMR集群和/或更加努力地优化代码可能会释放并行评估多个机器学习模型的能力。例如，pyspark提供了对<a class="ae lb" href="https://spark.apache.org/docs/2.3.1/api/python/pyspark.mllib.html#pyspark.mllib.classification.SVMModel" rel="noopener ugc nofollow" target="_blank">支持向量机</a>的支持，这些支持向量机通常可以在数据中提取捕获复杂的非线性模式。</p></div><div class="ab cl nc nd gp ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="hb hc hd he hf"><p id="8bfd" class="pw-post-body-paragraph kf kg hi kh b ki lc ij kk kl ld im kn ko le kq kr ks lf ku kv kw lg ky kz la hb bi translated">感谢阅读！你学到什么了吗？你认为我可以用更好的方式来展示这些材料吗？你能进一步改进这个模型吗？我总是对向别人学习感兴趣，所以欢迎评论！</p></div></div>    
</body>
</html>