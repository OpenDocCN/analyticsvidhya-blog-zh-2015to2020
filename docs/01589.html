<html>
<head>
<title>The recipe of instability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不稳定的秘诀</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/the-recipe-of-instability-f2e914e31f5a?source=collection_archive---------3-----------------------#2019-11-02">https://medium.com/analytics-vidhya/the-recipe-of-instability-f2e914e31f5a?source=collection_archive---------3-----------------------#2019-11-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="2c01" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">Spark UDFs非纯计算</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/49a5ae313e4e0e5f2134e5a8867baa3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*MRV-8IDha2PtdDI0.jpg"/></div></figure><p id="1984" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">火花是快速的，火花是灵活的，火花是可怕的，但有时它碰巧也是令人兴奋的。当Spark应用程序中需要大量的逻辑时，最简单的处理方法是编写一个用户定义的函数或简称为UDF。有一种传统认为UDF对性能不太好，因为它们阻止了许多优化，如预测下推等，但有时它们是不可避免的。</p><p id="60f6" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这篇文章中，我将分享一些关于UDF在调用非纯函数时如何变得棘手的想法。</p><h2 id="7d44" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jo km kn ko js kp kq kr jw ks kt ku kv bi translated">设置</h2><p id="41b9" class="pw-post-body-paragraph jf jg hi jh b ji kw ij jk jl kx im jn jo ky jq jr js kz ju jv jw la jy jz ka hb bi translated">几乎所有事情都可以使用本地Spark安装来完成，但有时真实集群上的行为与本地实例不同，所以我将使用Azure HDInsight Spark集群。只要工作节点数大于1，任何大小都可以。本例中使用的版本是HDI 4.0上的Spark 2.4。我会用齐柏林飞艇，用的笔记本会在帖子最后分享。</p><p id="938b" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">同样在Zeppelin中，<strong class="jh hj"> livy2 </strong>解释器必须被更新以引用一个以后会用到的外部依赖。所以配置值<strong class="jh hj"> livy.spark.jars.packages </strong>应该设置为<strong class="jh hj">io . SGR:S2-geometry-library-Java:1 . 0 . 0</strong></p><h2 id="38a3" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jo km kn ko js kp kq kr jw ks kt ku kv bi translated">数据帧和UDF</h2><p id="2448" class="pw-post-body-paragraph jf jg hi jh b ji kw ij jk jl kx im jn jo ky jq jr js kz ju jv jw la jy jz ka hb bi translated">从一些经典的数据帧和UDF基础开始，让我们启动Zeppelin，从一个100万行的简单数据帧开始，它有一个id列和一个包含id值的文本列。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lb"><img src="../Images/ecc77cebb0c1f27c6dc984e0dc481e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jSRb6Xvd4SoCjJmewko9YQ.png"/></div></div></figure><p id="9150" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">假设需要一个复杂的逻辑，使得文本列必须被转换成一个表示文本列的第一、第二和第三个字符的3个值的元组。这可以使用Spark SQL中的<code class="du lg lh li lj b">substring</code>函数来实现，但是现在，我们将使用UDF。UDF还引用了一个累加器，用于计算UDF被调用的次数。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lk"><img src="../Images/aeb322c84b230e0b9d7ef39ac63bc122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZVTuPBmWeM-sFIt5PCcw9A.png"/></div></div></figure><p id="3ccf" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">UDF应该像预期的那样将文本列转换成包含3个元素的元组。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es ll"><img src="../Images/09fbf767409823f7c896f0310506e112.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*714QQEr0hon0u1QGZIeEog.png"/></div></div></figure><p id="9c12" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">预计如果上述转换后的列在整个数据帧中具体化，那么将为数据帧中的每一行调用UDF，在我们的例子中是1M。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lm"><img src="../Images/9a6c703ab8f3426ba85511aa93ac1051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ez-_54Io1nm6PAmYC1tvpQ.png"/></div></div></figure><p id="34b3" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">使用DataFrame的<code class="du lg lh li lj b">explain</code>函数，上述查询的执行计划显示了对UDF的一次调用，这是预期的，加上Spark聪明地将创建文本列的表达式包含到相同的计算中。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es ln"><img src="../Images/53cf75e336af022e9df9ec2f383b63db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3s3oPcHO9qHhacWetphEwQ.png"/></div></div></figure><p id="1b3f" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">但是，如果想要提取UDF产生的元组的单个元素并对它们做一些事情，会是什么情况呢？UDF会被每行调用一次吗？</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lo"><img src="../Images/6571d1e3630c5075beea5e7c4163c183.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GwUDny4l56CPQXYzJGWKDQ.png"/></div></div></figure><p id="2348" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">哇！300万次UDF调用，这意味着每个依赖于UDF输出的表达式都会被调用一次。另一个事实是调用的数量是300万而不是400万，因为列<code class="du lg lh li lj b">transformed_text</code>本身在最终的动作结果中是不需要的，所以只有用于拉元组元素的单个表达式才是满足查询所需要的。执行计划清楚地表明了这一事实。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lp"><img src="../Images/50dc5e7dbd7e1a947d6516182b82274e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tFoSeDSI2tA7KqZ-fFisKA.png"/></div></div></figure><p id="410b" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">那么为什么会出现这种行为呢？默认情况下，Spark将任何UDF视为确定性函数。这意味着它可以针对相同的输入被多次调用，而没有风险，因为输出将是相同的。这个概念听起来像是由两个主要属性确定的纯函数(复制自维基百科):</p><ol class=""><li id="6edc" class="lq lr hi jh b ji jj jl jm jo ls js lt jw lu ka lv lw lx ly bi translated">对于相同的参数，它的返回值是相同的</li><li id="00a0" class="lq lr hi jh b ji lz jl ma jo mb js mc jw md ka lv lw lx ly bi translated">它的评估没有副作用</li></ol><p id="f994" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">默认情况下将UDF视为确定性的这一决定很可能与Spark查询执行计划优化有关。</p><h2 id="6dbd" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jo km kn ko js kp kq kr jw ks kt ku kv bi translated">每行一次调用</h2><p id="f5f2" class="pw-post-body-paragraph jf jg hi jh b ji kw ij jk jl kx im jn jo ky jq jr js kz ju jv jw la jy jz ka hb bi translated">假设我们希望每行调用一次UDF，如何实现呢？第一个想法可能是在涉及UDF的表达式之后直接引入缓存(外加一个动作)。这听起来像一个计划，但它更像一个黑客，而不是一个适当的解决方案。</p><p id="00f1" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Spark社区从2.3.0版本就已经提供了这个问题的解决方案。解决方案是将UDF标记为非确定性，这样Spark将被迫具体化其结果，从而每行调用一次。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es me"><img src="../Images/53ce17cef3975fc019a58fd533f0c84a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*06b8QB4-YTB1R8jaSslFfw.png"/></div></div></figure><p id="50b2" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">每行调用一次UDF，然后后续表达式从该点开始继续。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mf"><img src="../Images/ad48fd6ce95f82e7bfaf9fbd3035aba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z9QCECCBUr2_F_11LnhIBA.png"/></div></div></figure><p id="4ddc" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">因为如果UDF内部的逻辑很复杂，对相同的输入重复UDF在计算上会很昂贵，所以一些人放置了一个SPARK <a class="ae mg" href="https://issues.apache.org/jira/browse/SPARK-27761" rel="noopener ugc nofollow" target="_blank">吉拉票</a>来使UDF在未来SPARK主版本中默认为不确定的。此外，围绕UDF的简单直觉可能导致非确定性模式应该是默认模式的假设，因为这是用户自然期望他们的代码运行的方式。</p><p id="ab89" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">令人惊讶的是，当我在Azure上的DataBricks集群上尝试相同的代码时，我不需要将UDF标记为非确定性来获得每行一个调用的行为。出于某种原因，它似乎被默认纳入了DataBricks Spark发行版。</p><p id="b1c0" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jh hj">不稳定怎么办？</strong></p><p id="4b06" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">即使我们有无限的计算能力，并且不介意每行多次执行UDF，也可能有其他因素需要考虑。在某些特定情况下，UDF内部的代码可能会为相同的输入返回不同的结果。这清楚地表明了另一个问题，但由于大数据应用的性质，这可能不是很明显，但肯定会造成很多混乱。</p><p id="70c8" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">稍微偏离一下Spark world，我们来说一个在空间应用中使用的库。<a class="ae mg" href="https://s2geometry.io/" rel="noopener ugc nofollow" target="_blank"> S2几何</a>是谷歌的一个库，用于空间映射和操作几何形状。不幸的是，这个库的maven依赖项基于一个自2011年以来就没有进行过功能更新的fork。该库本身是健壮的，与定义空间形状和执行其他操作(如相交等)的功能相关。</p><p id="f989" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">尽管如此，任何事物都有其极限和工作条件。让我们使用Spark的这个库做一个简单的实验。我在设置部分提到过，我们可以通过更新<strong class="jh hj"> livy2 </strong>解释器的配置值来引用这个库。</p><h2 id="a30e" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jo km kn ko js kp kq kr jw ks kt ku kv bi translated">十字路口的困境</h2><p id="cc64" class="pw-post-body-paragraph jf jg hi jh b ji kw ij jk jl kx im jn jo ky jq jr js kz ju jv jw la jy jz ka hb bi translated">这个实验中涉及的形状基本上是一个多边形，代表墨尔本附近的一个矩形区域，另一个多边形实际上是一条与矩形相交的线段。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mh"><img src="../Images/7d44691aa33fa2f5bad309a2962b120b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sOMNAYXsRt0Zc9_vHfJKug.png"/></div></div></figure><p id="3ea0" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这些形状可以在实际应用中找到，虽然这不是一个非常常见的用例，但非常适合我们在这里的讨论。这些形状可以在同一个笔记本中表示，如下所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mi"><img src="../Images/d8f143f095c04be55cc0b2896d6def58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qMMxrAnCkBJBZpH-gr94MA.png"/></div></div></figure><p id="17be" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">有几个函数可以从一组点中创建S2多边形，还有一个函数可以使两个多边形相交并返回相交多边形。由于我不擅长命名，请记住<strong class="jh hj">形状1 </strong>是矩形，而<strong class="jh hj">形状2 </strong>是线段。我们可以利用S2找出他们各自的领域。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mj"><img src="../Images/904185f4cec1aa036075be9e313dc26e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bul1mlE-iV8OXvsevz6zKA.png"/></div></div></figure><p id="3ce0" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">看到这么小的数字有点奇怪，但这是有原因的。S2将地球上的点投影到单位1的球面上。所以S2的多边形面积表示单位球面上多边形的面积。例如，要获得以平方公里为单位的人类可读区域，可以计算如下:</p><blockquote class="mk"><p id="d3bb" class="ml mm hi bd mn mo mp mq mr ms mt ka dx translated">(S2面积)×(地球表面积)/ 4 π</p></blockquote><p id="c144" class="pw-post-body-paragraph jf jg hi jh b ji mu ij jk jl mv im jn jo mw jq jr js mx ju jv jw my jy jz ka hb bi translated">在我们的例子中，矩形的面积约为0.06平方公里。该线段的面积为5.15007217004638平方米😯</p><p id="25ca" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">无论如何，让我们将两个图形相交，并获得交点的面积。我就开门见山，重复这个操作10次，看看会发生什么。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mz"><img src="../Images/4f08fb38950fba5f3f778d1f0a103868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37SXSMNYsdNuqLBgWzOTJg.png"/></div></div></figure><p id="8973" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这是完全不可靠的，S2交集对同一组输入随机返回两个不同的结果。实际上，一个结果是预期的接近零的面积，另一个是12.566…这是4π，或者说是地球的表面积。我对谁对谁错并不感兴趣，这可能是一个哲学问题。这里我主要关心的是计算的不确定性。</p><h2 id="e865" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jo km kn ko js kp kq kr jw ks kt ku kv bi translated">UDF是如何工作的？</h2><p id="e156" class="pw-post-body-paragraph jf jg hi jh b ji kw ij jk jl kx im jn jo ky jq jr js kz ju jv jw la jy jz ka hb bi translated">我想现在你已经明白我想强调的是什么了；非确定性计算将导致混乱的结果，如果从一个火花UDF没有被标记为非确定性，但让我们来看看自己。为了模拟这种情况，需要一个UDF来相交两个形状并返回相交面积和任何其他计算，例如相交面积与其中一个形状的面积之比。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es na"><img src="../Images/0a4ade7b6d3908387a1f4a0a48b16ebe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJkxbZWO1GFalaJcSIV4yg.png"/></div></div></figure><p id="7377" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">接下来，创建一个10行的数据帧，其中每行有两列，包含我们之前看到的两个相同形状的点。然后调用UDF，并创建两个额外的列来挑选由UDF生成的元组的各个元素。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es nb"><img src="../Images/62568fc44923471100ed7ad5c6cc56e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PqsTzJMwybP1gXRDQgKh7w.png"/></div></div></figure><p id="4429" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">预计面积列将在这个非常小的数字和12.566之间波动。但是，对于相同的相交面积值，相交比率列不一致。例如，两个红色突出显示的行具有相同的交集面积，但交集比率完全不同，尽管它们的列表达式来自同一个源列。如果你还记得这篇文章中的前几个例子，你会注意到根本原因是对同一输入行多次调用UDF，而每次调用可能会对相交区域面产生不同的结果，从而导致不一致。</p><p id="9fd9" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在，我认为确定性Spark UDFs与非纯/稳定计算一起使用的复合效果是显而易见的。</p><p id="3506" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">如果UDF被标记为非确定性的，结果会很好。仍然会有波动，但是每行都是一致的。换句话说，每一行的所有列值都有意义，因为它们来自同一个UDF调用。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es nc"><img src="../Images/6162f2cfddb06a934f59b499fe694de9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i8xsjE0lV3GPptKOPRLyEg.png"/></div></div></figure><h2 id="5dac" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jo km kn ko js kp kq kr jw ks kt ku kv bi translated">包裹</h2><p id="de36" class="pw-post-body-paragraph jf jg hi jh b ji kw ij jk jl kx im jn jo ky jq jr js kz ju jv jw la jy jz ka hb bi translated">我并不是因为这种行为而责怪S2或Spark，只是想强调一个特例，它让我更好地理解了Spark UDFs是如何在幕后工作的。将一条直线段和一个普通的多边形相交并不是一个常见的用例，但它是一个使模式和含义非常清晰的工具。在类似的情况下，我的建议是将UDF标记为非确定性，但更重要的是制定一些方法使底层计算变得纯粹和稳定。在我们的例子中，我有一个先验UDF，它过滤掉任何形状面积小于某个阈值的行，或者任何识别它们的标准。最有可能的是，它们代表数据集中的极少数，如果值得进一步研究，这些不规则形状可以存储在日志文件中以供研究。无论如何，像大多数软件问题一样，答案将从“视情况而定”开始，上下文和业务领域将影响最佳解决方案。了解事物内部的工作方式对设计和验证最佳解决方案大有帮助。</p><h2 id="a918" class="kb kc hi bd kd ke kf kg kh ki kj kk kl jo km kn ko js kp kq kr jw ks kt ku kv bi translated">导出的笔记本</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="nd ne l"/></div></figure></div></div>    
</body>
</html>