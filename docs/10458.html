<html>
<head>
<title>Compare Tensorflow Deep Learning Model with Classical Machine Learning models — KNN, Naive Bayes, Logistic Regression, SVM — IRIS Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">比较Tensorflow深度学习模型与经典机器学习模型-KNN、朴素贝叶斯、逻辑回归、SVM-虹膜分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/compare-tensorflow-deep-learning-model-with-classical-machine-learning-models-knn-naive-bayes-61b40bb3382?source=collection_archive---------13-----------------------#2020-10-19">https://medium.com/analytics-vidhya/compare-tensorflow-deep-learning-model-with-classical-machine-learning-models-knn-naive-bayes-61b40bb3382?source=collection_archive---------13-----------------------#2020-10-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2758" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本练习中，我们将为鸢尾花预测构建经典的机器学习模型，您将学习如何为KNN、朴素贝叶斯、逻辑回归和SVM构建模型。然后将结果与使用Tensorflow/Keras框架构建的深度学习模型进行比较</p><p id="cadf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虹膜数据集总共有150个样本。有3种不同类型的花，鸢尾、海滨鸢尾和杂色鸢尾，每种50朵。每个花样品由花的4种不同属性/特征组成，即萼片和花瓣的长度和宽度，以厘米为单位。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/2d473efcb99f0301953da723580db2da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vVQiaTZVaK5rK31vizP0zA.png"/></div></div></figure><h1 id="fb04" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">导入库</strong></h1><p id="9038" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><em class="ks">导入os <br/>导入熊猫为pd <br/>导入numpy为np <br/>导入matplotlib.pyplot为plt <br/>导入seaborn为sns <br/>从sklearn.model_selection导入train_test_split </em></p><p id="44fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">从sklearn导入数据集、svm、指标<br/>从sklearn.naive_bayes导入高斯B <br/>从sklearn.metrics导入混淆_marix，accuracy_score <br/>从sklearn.linear_model导入逻辑回归</em></p><h1 id="9ca0" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">加载数据</strong></h1><p id="4bce" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><em class="ks">iris = datasets . load _ iris()</em></p><p id="0bd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">检查数据(iris.data，iris . target iris . feature _ names)</strong></p><p id="aa47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虹膜.数据.形状</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="be77" class="ky jq hi ku b fi kz la l lb lc">(150, 4)</span></pre><p id="913f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虹膜.目标.形状</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="a0ff" class="ky jq hi ku b fi kz la l lb lc">(150,)</span></pre><p id="bcbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">iris.feature _ names</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="9b40" class="ky jq hi ku b fi kz la l lb lc">['sepal length (cm)',<br/> 'sepal width (cm)',<br/> 'petal length (cm)',<br/> 'petal width (cm)']</span></pre><p id="9b5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虹膜目标</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="7878" class="ky jq hi ku b fi kz la l lb lc">array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,<br/>       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,<br/>       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,<br/>       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,<br/>       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,<br/>       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,<br/>       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])</span></pre><p id="f442" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">创建一个熊猫数据框架</strong>来保存iris.data和iris.target以及特性iris.feature_names</p><p id="81e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> df = pd。DataFrame(iris.data，columns = iris . feature _ names)<br/>df[' target ']= PD。系列(iris.target) </em></p><p id="d6dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">检查数据框</strong></p><p id="1916" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">df.head()</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ld"><img src="../Images/d657ccccf809086178cc78c2558e7c77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VHygr9ANLqimzAZHgssUoA.png"/></div></div></figure><p id="2123" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">df['目标']。每种类型有50朵花</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="cf65" class="ky jq hi ku b fi kz la l lb lc">2    50<br/>1    50<br/>0    50<br/>Name: target, dtype: int64</span></pre><p id="957d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">根据萼片宽度绘制萼片长度图</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/60403a9ae031162077441d7672acdaf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*J3p9BSLrvsF_n2ZGOMwcOw.png"/></div></figure><h1 id="ee28" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">检查特征相关性</strong></h1><p id="2dac" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">特性关联是通过调用pandas函数df.corr()来完成的，这将告诉我们哪些特性与目标变量最相关，这里我们注意到所有4个特性都与目标有很好的关联。因此，我们需要使用ML模型中的所有4个特征来预测虹膜花型</p><p id="caa3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">导入seaborn作为snssns.set(style="ticks "，color _ codes = True)<br/>PLT . fig(figsize =(10，10)) <br/> #plot热图<br/>corr _ matrix = df . corr()<br/>g = SNS . heat map(corr _ matrix，annot=True，cmap="RdYlGn") </em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/bba2d26e3c9c07af2df633dd6ab94142.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*s_bfyovZ6cNgOSxLxbR7eg.png"/></div></figure><h1 id="56e9" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">提取X和Y </strong></h1><p id="52c6" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><em class="ks"> X=df.iloc[:，0:4] <br/> y = df['target'] </em></p><h1 id="0b9c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">分割测试和训练数据</h1><p id="0211" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">分裂训练和测试，这里分裂的比例是80:20，这在大多数ML问题中是非常典型的。还要注意，我们已经设置了“分层=y ”,这将确保测试和训练数据中目标标签的比率保持不变。在这种情况下，我们的比例为1:1:1，目标标签的这一比例在拆分过程中保持不变。</p><p id="10de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> X_train，X_test，y_train，y_test = train_test_split(X，y，test_size =0.2，shuffle=True，random_state=35，strategy = y)</em></p><h1 id="60c7" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">定义模型，训练和测试模型</h1><p id="c21e" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">这包括三个步骤</p><ol class=""><li id="76cf" class="lg lh hi ih b ii ij im in iq li iu lj iy lk jc ll lm ln lo bi translated">通过实例化SKLEARN函数来定义模型</li></ol><p id="c982" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.Model . fit()-训练模型</p><p id="9551" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.model.predict() —对测试数据的预测</p><h1 id="5c69" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">1.SKLearn的k-最近邻分类器(KNN)</h1><p id="eec7" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><em class="ks">从sklearn.neighbors导入KNeighborsClassifier<br/>KNN = KNeighborsClassifier(n _ neighbors = 5)<br/>KNN . fit(X _ train，y _ train)<br/>y _ pred = KNN . predict(X _ test)<br/>KNN . score(X _ test，y_test) </em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="05b7" class="ky jq hi ku b fi kz la l lb lc">0.9333333333333333</span></pre><p id="00e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">混淆_矩阵(y _测试，y _预测)</em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="5f6f" class="ky jq hi ku b fi kz la l lb lc">array([[10,  0,  0],<br/>       [ 0,  9,  1],<br/>       [ 0,  1,  9]], dtype=int64)</span></pre><h1 id="83d3" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak"> 2。SKLearn的GuassianNB分类器</strong></h1><p id="8bbe" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><em class="ks">classifier = GaussianNB()<br/>classifier . fit(X _ train，y _ train)<br/>y _ pred = classifier . predict(X _ test)<br/>score = Accuracy _ score(y _ test，y_pred) <br/> print("Accuracy "，score) </em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="b188" class="ky jq hi ku b fi kz la l lb lc">Accuracy 0.8666666666666667</span></pre><p id="2cb9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">混淆_矩阵(y _测试，y _预测)</em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="7d69" class="ky jq hi ku b fi kz la l lb lc">array([[10,  0,  0],<br/>       [ 0,  8,  2],<br/>       [ 0,  2,  8]], dtype=int64)</span></pre><h1 id="0410" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">3.SKLearn的逻辑回归分类器</h1><p id="c716" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><em class="ks">logistic _ regression = logistic regression(C = 25.0，solver='lbfgs '，multi_class='auto '，max _ ITER = 1000)<br/>logistic _ regression . fit(X _ train，y _ train)<br/>y _ pred = logistic _ regression . predict(X _ test)<br/>score = accuracy _ score(y _ test，y_pred) <br/> score </em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="dd89" class="ky jq hi ku b fi kz la l lb lc">0.9333333333333333</span></pre><p id="2668" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">混淆_矩阵(y _测试，y _预测)</em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="8ff3" class="ky jq hi ku b fi kz la l lb lc">array([[10,  0,  0],<br/>       [ 0,  9,  1],<br/>       [ 0,  1,  9]], dtype=int64)</span></pre><h1 id="a0b2" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak"> 4。SVM分类器</strong></h1><p id="01b1" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><em class="ks">分类器= svm。SVC(gamma = 0.001)<br/>classifier . fit(X _ train，y _ train)<br/>y _ pred = classifier . predict(X _ test)<br/>score = accuracy _ score(y _ test，y_pred) <br/> score </em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="f15d" class="ky jq hi ku b fi kz la l lb lc">0.8</span></pre><p id="ce3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">混淆_矩阵(y _测试，y _预测)</em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="a218" class="ky jq hi ku b fi kz la l lb lc">array([[10,  0,  0],<br/>       [ 0,  9,  1],<br/>       [ 0,  5,  5]], dtype=int64)</span></pre><h1 id="c3b7" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak"> 5。利用Tensorflow/Keras进行深度学习</strong></h1><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lp"><img src="../Images/f8825121a1ab2f3f090b4d1d29d2fd32.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*wjU3TxDiqdPpvs35KkFX3Q.png"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">一个简单的神经网络</figcaption></figure><p id="1cfd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">从tensorflow导入keras </em>导入tensorflow作为tf <br/></p><p id="e259" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">定义张量流/Keras模型</strong></p><p id="babc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">定义输入形状= 4的深度神经网络模型，因为我们有4个输入特征，3层，分别具有5、3、3个神经元单元。产量必须是3个单位，我们有3个类来预测。</p><p id="649e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入(4个输入)→ X1，X2，X3，X4 → 5个神经元→ 3个神经元→ 3个输出神经元</p><p id="e401" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，可以在第一层(目前5个神经元)和第二层(目前3个神经元)中用不同数量的神经元进行实验</p><p id="3c92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">型号= keras。顺序([ <br/> keras.layers.Dense(5，activation=tf.nn.relu，input_shape=[4])、<br/> keras.layers.Dense(3，activation=tf.nn.relu)、<br/> keras.layers.Dense(3，activation = TF . nn . soft max)<br/>)</em></p><p id="fa37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">定义优化器、损失函数和指标</strong></p><p id="3dc2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">optimizer = TF . keras . optimizer . Adam()<br/>model . compile(optimizer = ' Adam '，<br/>loss = TF . keras . loss . sparsecategoricalcrossentropy(from _ logits = True)，<br/> metrics=['accuracy']) </em></p><p id="ed7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">最后用model.fit函数训练模型</strong></p><p id="b079" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> model.fit(X_train，y_train，epochs=2000) </em></p><p id="7a5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型在第一个历元以低精度开始</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="b6ce" class="ky jq hi ku b fi kz la l lb lc">Epoch 1/2000<br/>4/4 [==============================] - 0s 2ms/step - loss: 1.1194 - accuracy: 0.3333</span></pre><p id="1a1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以接近2000个历元的高精度收敛</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="41b4" class="ky jq hi ku b fi kz la l lb lc">Epoch 2000/2000<br/>4/4 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.9750</span></pre><p id="a458" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">根据测试数据预测</strong></p><p id="0700" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">y _ pred = model . predict(X _ test)</em></p><p id="0906" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将为每个输入生成一个包含3个数字的数组，但是正如所预测的，我们只需要一个目标标签</p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="3181" class="ky jq hi ku b fi kz la l lb lc">array([[1.4601685e-03, 3.7447622e-03, 9.9479502e-01],<br/>       [9.9999571e-01, 4.8816267e-09, 4.2581619e-06],<br/>       [1.4601685e-03, 3.7447622e-03, 9.9479502e-01],<br/>       [3.4476686e-03, 9.1026098e-02, 9.0552616e-01],<br/>       [1.4601685e-03, 3.7447622e-03, 9.9479502e-01],<br/>       [2.5093075e-06, 9.9999738e-01, 1.2542409e-07],<br/>       [1.4601685e-03, 3.7447622e-03, 9.9479502e-01],<br/>       [8.4952539e-04, 9.5092177e-01, 4.8228655e-02],</span></pre><p id="50d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">预测标签是这三个数字的最大值的索引，所以这是由np.argmax()得到的</p><p id="fc56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks"> y_pred_new = np.argmax(y_pred，axis=1) </em></p><p id="a9f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">得分=准确度_得分(y _测试，y _预测_新)<br/>得分</em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="bea8" class="ky jq hi ku b fi kz la l lb lc">0.9666666666666667</span></pre><p id="af0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ks">混淆_矩阵(y _测试，y _预测)</em></p><pre class="je jf jg jh fd kt ku kv kw aw kx bi"><span id="de9c" class="ky jq hi ku b fi kz la l lb lc">array([[10,  0,  0],<br/>       [ 0,  9,  1],<br/>       [ 0,  0, 10]], dtype=int64)</span></pre><h1 id="a3cb" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论</h1><p id="5cbd" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">注意这里不同模型的精度，我们得到的<strong class="ih hj"> SVM、高斯朴素贝叶斯、逻辑回归、KNN和深度学习模型</strong>的精度分别为0.8 →0.86 → 0.93 →0.93 →0.967</p><p id="0c01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度学习技术可以学习和预测任何目标函数。我们可以微调深度学习模型，使其性能优于经典的机器学习模型，但深度学习的缺点是网络的复杂性和对大数据集的需求。深度学习模型更容易过度拟合，但有一些技术可以用来对抗过度拟合。</p></div></div>    
</body>
</html>