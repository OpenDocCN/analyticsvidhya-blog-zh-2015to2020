<html>
<head>
<title>Computer Vision and Pneumonia Detection Part 1: Technical</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉和肺炎检测第1部分:技术</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/computer-vision-and-pneumonia-detection-part-1-technical-4e3592de208b?source=collection_archive---------11-----------------------#2020-08-10">https://medium.com/analytics-vidhya/computer-vision-and-pneumonia-detection-part-1-technical-4e3592de208b?source=collection_archive---------11-----------------------#2020-08-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="264c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">最近，我让自己负责分析胸部x光图像，以确定病人是否患有肺炎。这些x光片由中国广州的广州妇女儿童医疗中心提供，对象为1-5岁的儿童。图像集包含“正常”、“病毒性”&amp;“细菌性”肺炎的图像，分为两类:“正常”和“肺炎”。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es jm"><img src="../Images/dfe17836307f7247fcf61be8e451be1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*kyJ88BU3JAZP8U4pLrETGw.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">描绘儿科病人肺部的胸部x光片。蓝色标注的区域显示了肺炎造成的损伤。</figcaption></figure><p id="6b64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集是在理想的条件下提供的，没有低质量的扫描。在建立模型之前，我检查了类不平衡的训练数据。有<strong class="ih hj"> 1341次正常</strong>扫描和<strong class="ih hj"> 3875次肺炎</strong>扫描。一石二鸟，我添加了2534张额外的图像，并扩大它们以反映现实世界的场景-模糊，扭曲的图像，移动/旋转的图像，以及放大和缩小的图像。</p><pre class="jn jo jp jq fd jy jz ka kb aw kc bi"><span id="2b7b" class="kd ke hi jz b fi kf kg l kh ki"># Set criteria for image augmentation<br/>datagen = ImageDataGenerator(<br/>            rotation_range = 40,<br/>            width_shift_range = 0.2,<br/>            height_shift_range = 0.2,<br/>            rescale = 1./255,<br/>            shear_range = 0.2,<br/>            zoom_range = 0.2,<br/>            horizontal_flip = True,<br/>            fill_mode = 'nearest')</span><span id="566b" class="kd ke hi jz b fi kj kg l kh ki"># Select an image from the dataset<br/>img = load_img('chest_xray/train/NORMAL/IM-0757-0001.jpeg')</span><span id="d5fc" class="kd ke hi jz b fi kj kg l kh ki"># Convert image to an array<br/>img_array = img_to_array(img)</span><span id="2ef9" class="kd ke hi jz b fi kj kg l kh ki"># Reshape the array to a (1 X n X m X 3) array<br/>img_array = img_array.reshape((1,) + img_array.shape)</span><span id="ec7a" class="kd ke hi jz b fi kj kg l kh ki"># Set the path where the updated images should be saved<br/>norm_dir = 'chest_xray/train/NORMAL/'</span><span id="364e" class="kd ke hi jz b fi kj kg l kh ki"># Add 2534 photos to the directory in batches of 150<br/>count = 0<br/>for batch in datagen.flow(img_array, batch_size=150, save_to_dir=norm_dir, save_prefix='IM', save_format='jpeg'):<br/>    count +=1<br/>    if count == 2534:<br/>        break<br/>        <br/>print('2534 images have been generated at', norm_dir)</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es kk"><img src="../Images/36b3a7ca1cb1e4d9b8679c40a1dafb18.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*KkgzbB1wm-lFVB-h8YhVTw.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">样本增强图像。</figcaption></figure><p id="e46c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">添加完图像后，我将图像的大小减少到64 x 64，这样大小就统一了，输入到模型中的计算开销也更小，并将更新后的图像保存到原始文件目录中。使用next()函数，我遍历图像文件并返回存储在变量“__images”和“__labels”中的图像和标签，然后通过将像素除以255来规范化图像。</p><pre class="jn jo jp jq fd jy jz ka kb aw kc bi"><span id="c815" class="kd ke hi jz b fi kf kg l kh ki"># Train set<br/>train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(train_dir,                                                                           <br/>                        target_size = (64, 64), batch_size= 7685)</span><span id="84a2" class="kd ke hi jz b fi kj kg l kh ki"># Validation Set<br/>val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(val_dir,                                                    <br/>                           target_size=(64, 64), batch_size=16)</span><span id="3401" class="kd ke hi jz b fi kj kg l kh ki"># Test Set<br/>test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(test_dir,                                                            <br/>                         target_size = (64, 64), batch_size=624)</span><span id="0318" class="kd ke hi jz b fi kj kg l kh ki"># Create the image-label datasets<br/>train_images, train_labels = next(train_generator)<br/>val_images, val_labels = next(val_generator)<br/>test_images, test_labels = next(test_generator)</span></pre><p id="3899" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后的预处理步骤是将标签的大小调整为(1 x 1)数组，然后预览图像和标签，以确保正确的标签与相应的图像相对应。</p><pre class="jn jo jp jq fd jy jz ka kb aw kc bi"><span id="71f1" class="kd ke hi jz b fi kf kg l kh ki">train_labels_final = np.reshape(train_labels[:,0], (7685,1))<br/>val_labels_final = np.reshape(val_labels[:,0], (16,1))<br/>test_labels_final = np.reshape(test_labels[:,0], (624,1))</span><span id="cef7" class="kd ke hi jz b fi kj kg l kh ki"># Sanity check on image 4000<br/>array_to_img(train_images[4000])<br/>train_labels_final[4000, :]</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es kk"><img src="../Images/77f64d1d8e19d7cf7dffea84de6c7f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*lGGxHkhNWvV3ZhYcducqpA.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">样本图像4000的预览，增强图像。</figcaption></figure><p id="be0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在开始构建模型。初始模型使用默认设置运行，然后在每次迭代后进行阐述，以查看哪些参数有助于模型实现最佳性能。下面是一个代码片段，它遍历不同的优化器，同时适应训练和验证数据。运行代码块后，您可以通过折线图直观地检查优化器的性能。</p><pre class="jn jo jp jq fd jy jz ka kb aw kc bi"><span id="17e1" class="kd ke hi jz b fi kf kg l kh ki"># Create a dictionary of optimizers<br/>optimizers = {"RMSprop": {"optimizer": RMSprop(), "color":"blue"},<br/>              "adam_01": {"optimizer": Adam(lr=0.01),"color":"red"},<br/>              "sgd": {"optimizer": SGD(), "color":"purple"},<br/>              "adadelta": {"optimizer": Adadelta(), "color":"pink"},<br/>              "adagrad": {"optimizer": Adagrad(), "color":"yellow"}}</span><span id="3339" class="kd ke hi jz b fi kj kg l kh ki">for optimizer, d in optimizers.items():<br/>    print(f'Testing {optimizer}')<br/>    <br/>    # Build the CNN<br/>    <br/>    model = Sequential()</span><span id="2e40" class="kd ke hi jz b fi kj kg l kh ki">    model.add(layers.Conv2D(32, (3, 3), activation='relu',    <br/>    input_shape=(64, 64, 3)))</span><span id="ac16" class="kd ke hi jz b fi kj kg l kh ki">    model.add(layers.MaxPooling2D((2, 2)))<br/>    model.add(layers.Conv2D(32, (4, 4), activation='relu'))<br/>    model.add(layers.MaxPooling2D((2, 2)))</span><span id="2480" class="kd ke hi jz b fi kj kg l kh ki">    model.add(layers.Conv2D(64, (3, 3), activation='relu'))<br/>    model.add(layers.MaxPooling2D((2,2)))</span><span id="a8c0" class="kd ke hi jz b fi kj kg l kh ki">    # Flattening<br/>    model.add(layers.Flatten())<br/>    model.add(layers.Dense(64, activation = 'relu'))<br/>    model.add(layers.Dense(1, activation='softmax'))<br/>     model.compile(optimizer=d['optimizer'],loss='binary_crossentropy',    <br/>   metrics=['accuracy'])</span><span id="4f17" class="kd ke hi jz b fi kj kg l kh ki">  results = model.fit(train_images, train_labels_final,   <br/>  epochs=15, batch_size=500, validation_data=(val_images,   <br/>  val_labels_final))</span><span id="5c86" class="kd ke hi jz b fi kj kg l kh ki">  print("Stored Results")<br/>  d['loss'] = history.history['loss'] <br/>  print('='*125) # Add a partition in between optimizer results</span></pre><p id="910f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，评估模型的最终损失和准确性，然后对验证图像进行预测。结合使用混淆矩阵和分类报告来评估模型的总体性能。我的最终模型产生了零个假阴性和八个假阳性，这证明了最好的情况，因为最好标记一个病人进行额外的测试，而不是释放一个携带肺炎的病人，他们的症状恶化或他们将病毒性肺炎传播给亲人。</p><pre class="jn jo jp jq fd jy jz ka kb aw kc bi"><span id="97b6" class="kd ke hi jz b fi kf kg l kh ki"># Evaluate the model on the metrics accuracy and loss<br/>model.evaluate(train_images, train_labels_final)<br/>model.evaluate(val_images, val_labels_final)</span><span id="2457" class="kd ke hi jz b fi kj kg l kh ki"># Make predictions on the validation set<br/>preds = model.predict(val_images)<br/>plot_confusion_matrix(val_labels_final, preds)</span><span id="37a3" class="kd ke hi jz b fi kj kg l kh ki"># Print the Classification Report, which returns Recall, Precision, and F1-Score<br/>classification_report =classification_report(val_labels_final, preds)</span></pre><p id="ae9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">继续调整您的超参数，并根据您的测试数据训练您的最佳表现模型，然后重复。将您的结果与预先训练的模型进行比较。下面我用的是<strong class="ih hj"> VGG16。</strong></p><pre class="jn jo jp jq fd jy jz ka kb aw kc bi"><span id="d7b5" class="kd ke hi jz b fi kf kg l kh ki"># Import Pretrained Model<br/>from keras.applications.vgg16 import preprocess_input<br/>from keras.applications.vgg16 import VGG16</span><span id="d949" class="kd ke hi jz b fi kj kg l kh ki"># Edit the default image size to (64, 64, 3)<br/>pretrain_mod = VGG16(include_top= False, input_shape=(64,64,3))</span><span id="192a" class="kd ke hi jz b fi kj kg l kh ki"># Initialize a model<br/>model = Sequential()<br/>model.add(pretrain_mod)<br/>model.add(layers.Flatten())<br/>model.add(layers.Dense(132, activation='tanh'))<br/>model.add(layers.Dense(1, activation='softmax'))</span><span id="c7e8" class="kd ke hi jz b fi kj kg l kh ki"># Freeze layers (do this to speed up <br/>pretrain_mod.trainable = False<br/>for layer in model.layers:<br/>    print(layer.name, layer.trainable)<br/>print(len(model.trainable_weights))</span><span id="38f3" class="kd ke hi jz b fi kj kg l kh ki">model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])</span><span id="bfa9" class="kd ke hi jz b fi kj kg l kh ki">results = model.fit(train_images, train_labels_final, epochs=11, batch_size=750, validation_data=(test_images, test_labels_final))</span></pre><p id="aeaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">别忘了保存你最好的模型！</p><pre class="jn jo jp jq fd jy jz ka kb aw kc bi"><span id="7e19" class="kd ke hi jz b fi kf kg l kh ki">print('saving model to disk \n')<br/>mod = './/Models/pretrained_mod'<br/>model.save(mod)</span></pre></div></div>    
</body>
</html>