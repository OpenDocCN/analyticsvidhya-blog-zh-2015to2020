<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-science-random-forest-6f82577be93c?source=collection_archive---------19-----------------------#2020-04-29">https://medium.com/analytics-vidhya/data-science-random-forest-6f82577be93c?source=collection_archive---------19-----------------------#2020-04-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/36348919f152cb35000afc73871617d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tMUALqAHN77loIph7Yuhrw.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">礼貌用语:抱树者:有多棵树的森林。</figcaption></figure></div><div class="ab cl hv hw gp hx" role="separator"><span class="hy bw bk hz ia ib"/><span class="hy bw bk hz ia ib"/><span class="hy bw bk hz ia"/></div><div class="hb hc hd he hf"><h1 id="6f10" class="ic id ie bd if ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja bi translated"><strong class="ak">数据科学:随机森林</strong></h1><p id="5096" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">兰登森林轻松地解释道。</p><h2 id="a979" class="jz id ie bd if ka kb kc ij kd ke kf in jm kg kh ir jq ki kj iv ju kk kl iz km bi translated"><strong class="ak">背景:</strong></h2><p id="6428" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">我们每天都在使用决策树技术来规划我们的生活。我们已经在我以前的博客中看到了决策树，它也在数据科学领域发挥作用。</p><div class="hh hi ez fb hj kn"><a rel="noopener follow" target="_blank" href="/@anjanimca2007/data-science-decision-tree-f87c2e272749"><div class="ko ab dw"><div class="kp ab kq cl cj kr"><h2 class="bd ks fi z dy kt ea eb ku ed ef kv bi translated">数据科学:决策树</h2><div class="kw l"><h3 class="bd b fi z dy kt ea eb ku ed ef dx translated">决策树解释</h3></div><div class="kx l"><p class="bd b fp z dy kt ea eb ku ed ef dx translated">medium.com</p></div></div><div class="ky l"><div class="kz l la lb lc ky ld hp kn"/></div></div></a></div><p id="bce8" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks">决策树有下面提到的各种缺点:</strong></p><p id="c695" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">1.决策树有<a class="ae lj" href="http://Since Decision Tree learns from the given dataset if it is trained to it complete depth,it generally have Low Training error.That is called Low Bias." rel="noopener ugc nofollow" target="_blank">低偏差</a>和<a class="ae lj" href="http://Since Decision Tree learns training data set so well that it fails when there is new data set or fails to generalize with test dataset." rel="noopener ugc nofollow" target="_blank">高方差</a></p><p id="e49e" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">2.<strong class="jd ks">过度拟合</strong>(当模型学习训练数据如此之好，以致于它不能概括并且不能准确预测测试数据时)。</p><p id="ab34" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">3.它创造了<strong class="jd ks">不稳定的树</strong>。数据中微小变化可能导致生成完全不同的树。这就叫方差。</p><p id="d0ca" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">4.如果某个类别(在目标特征中)占主导地位，决策树学习器<strong class="jd ks">创建偏向树</strong>。</p><p id="beb9" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">决策树中上述所有问题的解决方案是随机森林。</p><h2 id="5ac8" class="jz id ie bd if ka kb kc ij kd ke kf in jm kg kh ir jq ki kj iv ju kk kl iz km bi translated"><strong class="ak">直觉:</strong></h2><p id="3913" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">随机森林是一种监督机器学习算法，用于分类和回归问题。它使用集成建模技术，该技术结合了许多基础模型，如<strong class="jd ks">决策树</strong>，以产生一个最佳预测模型。</p><p id="cc76" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">它使用<strong class="jd ks"> Bagging </strong>也称为<strong class="jd ks"> Bootstrap aggregation </strong>(使用带替换的随机采样)来选择行的随机子集和特征的随机子集，以在随机森林中构建每棵树。</p><p id="c4df" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">树是平行建造的。稍后，随机森林中的每个决策树将给出其决定，并基于<strong class="jd ks">多数投票预测发生。</strong></p><p id="3990" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks">在回归问题</strong>的情况下，基于数据的分布，通过取回归值(由随机森林中的每个决策树预测的)的平均值(平均值)或中值来进行预测。</p><h2 id="92cd" class="jz id ie bd if ka kb kc ij kd ke kf in jm kg kh ir jq ki kj iv ju kk kl iz km bi translated"><strong class="ak">下面是实现随机森林的步骤:</strong></h2><p id="d344" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated"><strong class="jd ks"> 1 </strong>。假设训练数据集中有N个观测值(行)和M个特征(列)。</p><p id="1284" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> 2 </strong>。从训练数据集中随机抽取样本，该样本具有随机选择的行和随机选择的特征。</p><p id="4b92" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> 3 </strong>。决策树是使用基尼指数或熵(特征分裂标准)构建的。</p><p id="5d3b" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> 4 </strong>。根据估计数(n_ estimators参数)创建所有决策树。</p><p id="7a20" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> 5 </strong>。森林中的每棵树都会给出它的预测，基于多数票，最终的预测会发生。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lk"><img src="../Images/ec7060faeab6d42ba2b62587e7e50149.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*RJLxu3aZp_gej2-C8ItrWw.png"/></div></figure><p id="637c" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks">下面是随机森林的样本</strong></p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lp"><img src="../Images/010508accd06300f7eec1b63fa6aded4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*MOrqeFNpK8m4cVRPorhnJQ.png"/></div></div></figure><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lp"><img src="../Images/60319c82518f721d780a72a84bb7be46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*ljxB0wTS1qE0SxXKFn0z9g.png"/></div></div></figure><p id="8e25" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks">参考代码:</strong></p><figure class="ll lm ln lo fd hk"><div class="bz dy l di"><div class="lq lr l"/></div></figure><p id="c5b0" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks">随机森林分类器可视化:</strong></p><p id="fb71" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">请为这种可视化安装sklearn或更高版本(如果尚未安装)。</p><figure class="ll lm ln lo fd hk"><div class="bz dy l di"><div class="lq lr l"/></div></figure><h2 id="cee2" class="jz id ie bd if ka kb kc ij kd ke kf in jm kg kh ir jq ki kj iv ju kk kl iz km bi translated"><strong class="ak">随机森林分类器中的重要参数:</strong></h2><p id="02e4" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">随机森林中有许多参数，但重要的参数如下:</p><p id="16ba" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> Bootstrap </strong>:数据点采样方法(有无替换)</p><p id="b36e" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks">判据</strong>:分割树形ie的方法。基尼或熵。</p><p id="ae46" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> max_depth </strong>:树的最大深度。</p><p id="56d8" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> n_estimators </strong>:创建森林的树木总数。</p><p id="5241" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> min_samples_split </strong>:分割节点前，放置在节点中的最小数据点数</p><p id="a54a" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> min_samples_leaf : </strong>叶节点中允许的最小数据点数</p><p id="93c4" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks"> Out-of-bag </strong> (OOB)误差，也称为<strong class="jd ks"> out-of-bag </strong>估计，是一种利用bootstrap aggregating (bagging)子<strong class="jd ks">样本</strong>数据<strong class="jd ks">样本</strong>用于训练的测量随机森林、boosted决策树和其他机器学习模型预测误差的方法。</p><h2 id="5499" class="jz id ie bd if ka kb kc ij kd ke kf in jm kg kh ir jq ki kj iv ju kk kl iz km bi translated"><strong class="ak">随机森林里的‘随机’是什么？</strong></h2><p id="7c11" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hb bi translated">在随机森林中，由于特征/变量和记录/行是随机选择来建立这个模型的，所以称之为随机森林。</p><p id="461e" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks">随机森林的优势:</strong></p><p id="e322" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">1.其减少了过拟合，预测精度高(基本上是低方差，但可能是高偏差)</p><p id="90d3" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">2.在大型数据集上非常有效。</p><p id="77c5" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">3.不受多重共线性的影响。<strong class="jd ks"> </strong>当回归模型中两个或两个以上的自变量高度相关时，就会出现这种情况。</p><p id="a88d" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">4.预测基于被认为对分类很重要的输入特征。</p><p id="e25d" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">5.在缺少数据的情况下工作良好，仍能提供更好的预测准确性</p><p id="6d77" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks">随机森林的缺点:</strong></p><ul class=""><li id="5ffd" class="ls lt ie jd b je le ji lf jm lu jq lv ju lw jy lx ly lz ma bi translated">你也得不到一个方程，所以它也被称为无方程模型。</li><li id="6a90" class="ls lt ie jd b je mb ji mc jm md jq me ju mf jy lx ly lz ma bi translated">这有点像黑箱，因为你不知道哪棵树预测了什么值，因此在一些行业如银行中不用于风险建模。</li><li id="af81" class="ls lt ie jd b je mb ji mc jm md jq me ju mf jy lx ly lz ma bi translated">执行时比决策树使用更多的CPU资源。</li></ul><p id="56f4" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated"><strong class="jd ks">结论</strong>:因此，我们可以得出结论，在大多数情况下，随机森林比具有上述所有特征的决策树更好，我们通常会获得良好的准确性。希望你喜欢阅读。如果你喜欢我的文章并想看更多，请张贴<strong class="jd ks"> 50个掌声</strong>和<strong class="jd ks">关注</strong>我的博客。</p><p id="04f1" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">想要连接:</p><p id="68ee" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">联系方式:<a class="ae lj" href="https://www.linkedin.com/in/anjani-kumar-9b969a39/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/anjani-kumar-9b969a39/</a></p><p id="458e" class="pw-post-body-paragraph jb jc ie jd b je le jg jh ji lf jk jl jm lg jo jp jq lh js jt ju li jw jx jy hb bi translated">如果你喜欢我在Medium上的帖子，并希望我继续做这项工作，请考虑在<a class="ae lj" href="https://www.patreon.com/anjanikumar" rel="noopener ugc nofollow" target="_blank"> <strong class="jd ks"> patreon </strong> </a>上支持我</p></div></div>    
</body>
</html>