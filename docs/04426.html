<html>
<head>
<title>Extracting YouTube comments using Selenium</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Selenium提取YouTube评论</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/extracting-youtube-comments-using-selenium-b29ee4f743ef?source=collection_archive---------2-----------------------#2020-03-19">https://medium.com/analytics-vidhya/extracting-youtube-comments-using-selenium-b29ee4f743ef?source=collection_archive---------2-----------------------#2020-03-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/675b52a3b32a3d0bcdcd00efb9378161.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*zH0xa3M2xOW2iU1WAcvAMQ.jpeg"/></div></figure><p id="f283" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">比方说，当你在youtube上搜索任何东西的时候，你想找出出现的前10个链接。与此同时，您还想为前10个链接中的每个链接收集前50条评论，并最终对收集到的数据进行情感分析。你当然不想手动做。</p><p id="b3ef" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你会怎么做？</p><p id="6eaa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下是你可以采取的步骤。</p><ol class=""><li id="fb6b" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated"><strong class="io hj">数据收集:</strong>你可以用Selenium从Youtube网站做网页报废。请注意，注释本质上是递归的。当我说递归的时候，意思是人们可以在一个注释之上进行注释。你还需要决定你做分析所需要的所有数据点。以下是你可以从十大视频列表中提取的一些细节</li></ol><p id="d061" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">视频标题文本<br/>视频URL <br/>订阅频道<br/>观看次数<br/>发布日期链接</p><p id="152c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 2。数据清理:</strong>这会耗费很多时间，因为人们可以用任何语言发表评论，可以使用笑脸、讽刺等。有许多python库可以帮助你清理数据。继续深入探讨这个问题。</p><p id="cbcb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 3。情感分析:</strong>一旦你有了干净的数据，你就可以进行自然语言处理和情感分析，最后在此基础上进行可视化。</p><p id="37a4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下面是代码的步骤。</p><p id="64ac" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">步骤1:导入所有必需的库</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="31bc" class="kc kd hi jy b fi ke kf l kg kh">from selenium import webdriver<br/>import time<br/>import os<br/>import csv<br/>import pandas as pd<br/>from math import ceil</span></pre><p id="b1fb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">步骤2:打开文件，写入从youtube提取的数据</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="8385" class="kc kd hi jy b fi ke kf l kg kh"><em class="ki"># Creates a new .csv file that the data will be written to</em><br/><br/>csv_file = open('c:<strong class="jy hj">\\</strong>ISB<strong class="jy hj">\\</strong>output_scraping.csv', 'w', encoding="UTF-8", newline="")<br/>writer = csv.writer(csv_file)</span></pre><p id="959f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">步骤3:在打开的csv文件中写入数据列标题</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="caa4" class="kc kd hi jy b fi ke kf l kg kh"><em class="ki"># write header names</em><br/>writer.writerow(<br/>    ['url', 'link_title', 'channel', 'no_of_views', 'time_uploaded', 'comment', 'author', 'comment_posted', <br/>     'no_of_replies','upvotes','downvotes'])</span></pre><p id="86a7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">步骤4:调用webdriver并启动youtube站点。</p><p id="a9d2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">步骤5:使用驱动程序动态搜索任何关键字，如下例所示，我搜索了“Kishore Kumar ”,然后睡了几秒钟，给浏览器加载页面的时间</p><p id="7048" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">步骤6:对于每个前10个链接，提取以下元素并保存在各自的列表中</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="1ef8" class="kc kd hi jy b fi ke kf l kg kh">•   Video Title text<br/>•   Video URL<br/>•   Subcription Channel<br/>•   No of Views<br/>•   Date link posted</span></pre><p id="a742" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">第7步:启动前十个提取链接的url。对于每个URL，向下滚动到所需位置以加载评论部分。-按顶部评论排序-向下滚动两次以加载至少50条评论-对于每条评论(50条或更少)，提取下面的元素并将其放入try catch块中，以便在评论中没有特定元素时处理异常评论文本作者姓名发表评论的日期查看次数投票数/投票数</p><p id="0fe1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">步骤8:为从主链接和子链接中提取的元素创建字典，并写入打开的csv文件。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="bb28" class="kc kd hi jy b fi ke kf l kg kh"><em class="ki"># open chrome </em><br/>youtube_pages = "https://www.youtube.com/"<br/>locationOfWebdriver = "c:<strong class="jy hj">\\</strong>ISB<strong class="jy hj">\\</strong>chromedriver.exe"<br/>driver = webdriver.Chrome(locationOfWebdriver)<br/>driver.get(youtube_pages)<br/>time.sleep(10)<br/><strong class="jy hj">try</strong>:<br/>    print("=" * 40)  <em class="ki"># Shows in terminal when youtube summary page with search keyword is being scraped</em><br/>    print("Scraping " + youtube_pages)<br/>    search = driver.find_element_by_id('search')<br/>    search.send_keys("Kishore Kumar")    <br/>    driver.find_element_by_id('search-icon-legacy').click()<br/>    time.sleep(20)    <br/>    vtitle = driver.find_elements_by_id('video-title')<br/>    subscription = driver.find_elements_by_id('byline')<br/>    views = driver.find_elements_by_xpath('//div[@id="metadata-line"]/span[1]')<br/>    posted = driver.find_elements_by_xpath('//div[@id="metadata-line"]/span[2]')<br/>    <br/>    tcount = 0<br/>    href = []<br/>    title = []<br/>    channel = []<br/>    numview = []<br/>    postdate = []<br/>        <br/>    <strong class="jy hj">while</strong> tcount &lt; 10:<br/>        href.append(vtitle[tcount].get_attribute('href'))<br/>        channel.append(subscription[tcount].get_attribute('title'))<br/>        title.append(vtitle[tcount].text)<br/>        numview.append(views[tcount].text)<br/>        postdate.append(posted[tcount].text)  <br/>        tcount = tcount +1<br/>    <br/>    <em class="ki"># launch top ten extracted links and extract comment details</em><br/>    tcount = 0    <br/>    <strong class="jy hj">while</strong> tcount &lt; 10:  <br/>        youtube_dict ={}<br/>        <em class="ki"># extract comment section of top ten links</em><br/>        url = href[tcount]<br/>        print (url)<br/>        driver.get(url)<br/>        time.sleep(5)<br/>        <br/>        <strong class="jy hj">try</strong>:<br/>            print("+" * 40)  <em class="ki"># Shows in terminal when details of a new video is being scraped</em><br/>            print("Scraping child links ")<br/>            <em class="ki">#scroll down to load comments</em><br/>            driver.execute_script('window.scrollTo(0,390);')<br/>            time.sleep(15)<br/>            <em class="ki">#sort by top comments</em><br/>            sort= driver.find_element_by_xpath("""//*[@id="icon-label"]""")<br/>            sort.click()<br/>            time.sleep(10)<br/>            topcomments =driver.find_element_by_xpath("""//*[@id="menu"]/a[1]/paper-item/paper-item-body/div[1]""")<br/>            topcomments.click()<br/>            time.sleep(10)<br/>            <em class="ki"># Loads 20 comments , scroll two times to load next set of 40 comments. </em><br/>            <strong class="jy hj">for</strong> i <strong class="jy hj">in</strong> range(0,2):<br/>                driver.execute_script("window.scrollTo(0,Math.max(document.documentElement.scrollHeight,document.body.scrollHeight,document.documentElement.clientHeight))")<br/>                time.sleep(10)<br/>            <br/>            <em class="ki">#count total number of comments and set index to number of comments if less than 50 otherwise set as 50. </em><br/>            totalcomments= len(driver.find_elements_by_xpath("""//*[@id="content-text"]"""))<br/>         <br/>            <strong class="jy hj">if</strong> totalcomments &lt; 50:<br/>                index= totalcomments<br/>            <strong class="jy hj">else</strong>:<br/>                index= 50 <br/>                <br/>            ccount = 0<br/>            <strong class="jy hj">while</strong> ccount &lt; index: <br/>                <strong class="jy hj">try</strong>:<br/>                    comment = driver.find_elements_by_xpath('//*[@id="content-text"]')[ccount].text<br/>                <strong class="jy hj">except</strong>:<br/>                    comment = ""<br/>                <strong class="jy hj">try</strong>:<br/>                    authors = driver.find_elements_by_xpath('//a[@id="author-text"]/span')[ccount].text<br/>                <strong class="jy hj">except</strong>:<br/>                    authors = ""<br/>                <strong class="jy hj">try</strong>:<br/>                    comment_posted = driver.find_elements_by_xpath('//*[@id="published-time-text"]/a')[ccount].text<br/>                <strong class="jy hj">except</strong>:<br/>                    comment_posted = ""<br/>                <strong class="jy hj">try</strong>:<br/>                    replies = driver.find_elements_by_xpath('//*[@id="more-text"]')[ccount].text                    <br/>                    <strong class="jy hj">if</strong> replies =="View reply":<br/>                        replies= 1<br/>                    <strong class="jy hj">else</strong>:<br/>                        replies =replies.replace("View ","")<br/>                        replies =replies.replace(" replies","")<br/>                <strong class="jy hj">except</strong>:<br/>                    replies = ""<br/>                <strong class="jy hj">try</strong>:<br/>                    upvotes = driver.find_elements_by_xpath('//*[@id="vote-count-middle"]')[ccount].text<br/>                <strong class="jy hj">except</strong>:<br/>                    upvotes = ""<br/>                        <br/>                youtube_dict['url'] = href[tcount]<br/>                youtube_dict['link_title'] = title[tcount]<br/>                youtube_dict['channel'] = channel[tcount]<br/>                youtube_dict['no_of_views'] = numview[tcount]<br/>                youtube_dict['time_uploaded'] =  postdate[tcount]<br/>                youtube_dict['comment'] = comment<br/>                youtube_dict['author'] = authors<br/>                youtube_dict['comment_posted'] = comment_posted<br/>                youtube_dict['no_of_replies'] = replies<br/>                youtube_dict['upvotes'] = upvotes<br/>                <br/>                writer.writerow(youtube_dict.values())<br/>                ccount = ccount +1<br/>                <br/>        <strong class="jy hj">except</strong> <strong class="jy hj">Exception</strong> <strong class="jy hj">as</strong> e:<br/>            print(e)<br/>            driver.close()<br/>        tcount = tcount +1 <br/>    print("Scrapping process Completed")   <br/>    csv_file.close()    <br/><strong class="jy hj">except</strong> <strong class="jy hj">Exception</strong> <strong class="jy hj">as</strong> e:<br/>    print(e)<br/>    driver.close()</span></pre><p id="6a5e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里是输出控制台。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="b7a1" class="kc kd hi jy b fi ke kf l kg kh">========================================<br/>Scraping https://www.youtube.com/<br/>https://www.youtube.com/watch?v=b_iSFNJmAhU<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>https://www.youtube.com/watch?v=GSmXU2Q7TU8<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>https://www.youtube.com/watch?v=uA67M0Lihz0<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>https://www.youtube.com/watch?v=6vCbtPN9skk<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>https://www.youtube.com/watch?v=aqBHgUkoZCE<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>https://www.youtube.com/watch?v=duee3ROzuKg<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>https://www.youtube.com/watch?v=nEnLt3pasxE<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>https://www.youtube.com/watch?v=lKVIElw2IZM<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>https://www.youtube.com/watch?v=AMuRRXCuy-4<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>https://www.youtube.com/watch?v=MDXFi3avqo0<br/>++++++++++++++++++++++++++++++++++++++++<br/>Scraping child links <br/>Scrapping process Completed</span></pre><p id="7afd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这是从csv文件中提取的示例输出。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es kj"><img src="../Images/9b65a8f37d4919c11eabaf29df8a74ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B3m-C3iiL5AP3tPTw6L2mw.png"/></div></div></figure><p id="e383" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一旦获得csv文件中的数据，就可以使用各种python库做进一步的分析。</p><p id="309e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Selenium是一个著名的使用python进行web抓取的库。继续使用这个库，从各种其他网站提取数据。但在此之前，请检查从他们的网站上抓取数据是否合法。我认为你可以将网络抓取用于学习目的，但不能用于商业用途。</p><p id="6e4a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果你有任何问题，请随时联系我。</p></div></div>    
</body>
</html>