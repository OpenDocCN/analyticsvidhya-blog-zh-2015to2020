# 使用 K-Means 聚类不同的向量

> 原文：<https://medium.com/analytics-vidhya/clustering-dissimilar-vectors-using-k-means-d4f09ddd3b0a?source=collection_archive---------12----------------------->

![](img/32aa7f908fa273de235f88b28ff01a19.png)

最近，一组同行找到我，为他们的项目寻求帮助。他们的一个子问题是基于词汇和频率对句子进行聚类。虽然大多数聚类算法基于在特定索引处具有相同特征的向量，但是这里的特征是唯一的词，并且值是它们出现的计数。

```
training_dataset = [
    {'advance': 2, 'happy': 3, 'new': 1, 'year': 3},
    {'happy': 2, 'christmas': 3, 'ajay': 3},
    {'happy': 1, 'birthday': 2},
    {'happy': 2, 'new': 2, 'year': 2, 'hello': 3},
    {'hello': 2, 'world': 3},
    {'hello': 1, 'world': 2, 'ajay': 3},
    {'happy': 3, 'day': 2},
    {'hello': 1, 'ajay': 4},
]
```

因为我们需要容纳特征和它们的频率，所以字典是一个合适的数据结构。这里我们看到一组问候。这些问候可以分为两类，普通的和个性化的。属于后一类的问候被索引为 1、5 和 7，而前一类问候是其余的向量。

K-Means 更适合这个项目，因为它给出了聚类中心。可以为聚类中心的每个属性分配一个权重，以确定答案在预测到该特定聚类时应该得到的分数。然而，使用 K-意味着所有的向量应该表示相似的特征，而对于与自然语言处理相关的数据集，情况并非如此。一些单词出现在更多的句子中，而另一些出现在精选的几个句子中。因此，我们建立一个特征表。

```
>>> model.features
['year', 'hello', 'happy', 'ajay', 'world', 'advance', 'birthday', 'christmas', 'day', 'new']
```

该特征表由给定数据集中的所有特征(本例中为单词)组成。然后，对于每个数据点，我们取一个具有特征表大小的零数组。提取数据点中的每个特征，并将其值(在本例中为频率)放入数组中该特定特征在特征表中的索引处。

```
>>> model.normalized_X
[[1\. 3\. 0\. 0\. 0\. 3\. 0\. 2\. 0\. 0.]
 [0\. 2\. 3\. 3\. 0\. 0\. 0\. 0\. 0\. 0.]
 [0\. 1\. 0\. 0\. 2\. 0\. 0\. 0\. 0\. 0.]
 [2\. 2\. 0\. 0\. 0\. 2\. 0\. 0\. 3\. 0.]
 [0\. 0\. 0\. 0\. 0\. 0\. 0\. 0\. 2\. 3.]
 [0\. 0\. 0\. 3\. 0\. 0\. 0\. 0\. 1\. 2.]
 [0\. 3\. 0\. 0\. 0\. 0\. 2\. 0\. 0\. 0.]
 [0\. 0\. 0\. 4\. 0\. 0\. 0\. 0\. 1\. 0.]]
```

我们称这个过程为规范化(不要与 DBMS 规范化相混淆)。一旦完成，我们就可以将这些向量传递给常规的 K-Means 算法。Sci-Kit Learn 拥有 K-Means 和许多其他机器学习算法的最佳实现之一。默认情况下，它训练 10 个模型，并返回最适合的模型。因此，为了我们的目的，我们继承了它们的实现。这也有助于保存 sklearn 的命名约定。在应用 K-Means 时，我们得到以下标签。

```
>>> model.fit(normalized_X)
>>> model.labels_
[0 1 0 0 0 1 0 1]
```

很明显，个性化的问候被标记为 1，而普通的问候被标记为 0。因此，我们的方法是可行的。但是集群中心对于使用这个 API 的开发人员来说没有意义。

```
>>> model.cluster_centers_
[1\. 0.66666667 0.66666667 0.66666667 0\.  0\.  0\.  0\.  3.33333333 0\. ]
[0\. 0.6        1.8        1\.         0.4 0.4 0.6 1\.  0\.         0.4]
```

在这里，您可以看到标准化形式的聚类中心。使用我们的特征表，我们将聚类中心反规格化回它们的字典形式，以便更好地理解和使用。为此，我们使用一个新的变量 cluster_centers，它是去掉了尾部下划线的 cluster_centers 的变体。

```
>>> model.cluster_centers
[{'ajay': 3.3333333333333335, 'christmas': 1.0, 'world': 0.6666666666666666, 'hello': 0.6666666666666666, 'happy': 0.6666666666666666},
{'year': 1.0, 'day': 0.4, 'advance': 0.4, 'birthday': 0.4, 'world': 0.6, 'hello': 1.0, 'happy': 1.8, 'new': 0.6}]
```

这对开发人员来说更有意义，因为这些值都标有它们的特性。现在，我们传递一个个性化的问候来验证模型。

```
testing_dataset = [
    {'happy': 1, 'day': 2, 'ajay': 3, 'raj': 1}
]
>>> model.predict(testing_dataset)
[1]
```

这里，预测标签是 1，这是个性化消息的集群。因此，我们可以断定我们的模型是经过训练和验证的。如果开发人员不想要频率的权重，而只想基于单个出现对单词进行聚类，他们可以将所有频率设置为 1。由于我们没有调整任何与 K-Means 相关的超参数，我们的模型将产生与现有 K-Means 算法完全相同的精度。此外，因为我们从 sklearn 继承了现有的 K-Means 类，所以我们保留了机器学习开发人员习惯的所有参数。这使得它非常适合实时应用。

如果你喜欢我的作品，一定要打开我的 Github 库。