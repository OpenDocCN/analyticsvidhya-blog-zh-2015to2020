<html>
<head>
<title>Stock Market Prediction Using Deep Learning and Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用深度学习和Python进行股市预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/stock-market-prediction-using-python-article-4-the-next-recession-923185a2736f?source=collection_archive---------5-----------------------#2019-09-24">https://medium.com/analytics-vidhya/stock-market-prediction-using-python-article-4-the-next-recession-923185a2736f?source=collection_archive---------5-----------------------#2019-09-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="4aee" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">第四条:预测印度经济下一次可能的衰退</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/db6ff4285189c03d36fc731cd15b0384.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*TtVMRxIcTXCDxUVpez0pDg.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated"><strong class="bd jj">衰退</strong></figcaption></figure><p id="ae97" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi kg translated">著名电视剧《权力的游戏》的整个剧本围绕着冬天的到来展开。从第一季到第七季，那里的角色不断地为冬天做准备。最后，冬天在最后一季来临了，而且只持续了那一季的几集。这让包括我在内的很多GOT粉丝很失望。我们想在接下来的几个赛季中享受这种娱乐，因此希望有一个完整的冬季。然而，这是一场戏剧，但事实上，如果我们不得不面对它，我们也会祈祷最短的冬季。</p><p id="0bc2" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">维斯特洛的冬天给我们上了重要的一课，不管冬天有多短，但它总是毁灭性的。冬天让所有像夜王、疯皇后这样的怪物登场。临冬城被摧毁，君临被烧成灰烬，数百万人死去。然而，最终它带来了新的王国和新的希望。这部剧与经济世界有很多相似之处。</p><p id="3d48" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">经济衰退正在向我们所有人袭来，这一次<strong class="jm hj">是真的了。你是想坐以待毙，等待它的到来，还是做好准备迎接它的到来。决定权在你。<strong class="jm hj"> </strong>是的，还剩下一些时间。</strong></p><p id="52b9" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">在早期，只有经济学家和专家预测经济衰退。而我们这些普通人，是在它到来之后才知道它的。只有在失业和投资股票赔钱之后，我们才会相信它。我们听过一位印度储备银行前行长的故事，他在2005年写的论文中预测了2008年的经济衰退。我们还可以看到许多经济学家在互联网上吹嘘他们是第一个预测下一次衰退的人。恕我直言，他们的知识和能力，现在时代已经变了，我们普通人在机器学习算法的帮助下也可以预测下一次衰退！！我们现在就去看看！！</p><p id="840e" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">在前三篇文章中，我们尝试了各种回归技术和时间序列预测算法，如来自脸书的先知。然而，我们意识到股票市场问题太复杂了，无法用所有这些技术来解决。因此，在这篇文章中，我们正在探索神经网络，看看它是否可以做现实的预测。</p><p id="c7fc" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">神经网络是神经元的网络或回路，或者现代意义上的人工神经网络，由人工神经元或节点组成。因此，神经网络或者是由真实生物神经元组成的生物神经网络，或者是用于解决人工智能(AI)问题的人工神经网络。</p><p id="e659" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">与冯·诺依曼模型计算不同，人工神经网络没有将记忆和处理分开，而是通过网络连接的信号流进行操作，有点类似于生物网络。</p><p id="2d4e" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">这些人工网络可用于预测建模、自适应控制和可通过数据集训练的应用。从经验中产生的自我学习可以发生在网络中，网络可以从一组复杂且看似不相关的信息中得出结论。</p><p id="ad91" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">让我们试着用一个逻辑与门来理解一个神经元、一个神经网络和一个神经网络计算算法。下图是一个逻辑神经元的表示。它有两个输入x1和x2，接受二进制值，即0或1。神经元有一个偏置节点+1。假设我们的目标函数是y = x1和x2。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kp"><img src="../Images/1e90e3435ac666942d4d69586c20700b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*G6D9UlMxMmkAtG6c9ilfbA.jpeg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">人工神经元</figcaption></figure><p id="69e8" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">在这个只有一个神经元的神经网络中。我们的假设函数是hɵ (x) = g ( w1 * 1+ w2 * x1 + w3 * x2)。这里g(x)是一个sigmoid函数，如果x为正，则产生1，如果x为负，则产生0。在C语言中这可以写成“int g(x) { return (x &gt; 0？1 : 0);}"</p><p id="c95d" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">在计算开始时，我们需要准备好神经网络的设计，我们还需要一个预定义的假设函数，它通常是输入值和与之相关的权重的乘积的总和。最初，权重w1、w2和w3是未知数。</p><p id="2153" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">下一步，我们通过输入样本数据来训练神经网络。在我们的例子中，为了训练它像与门一样工作，我们将向它提供以下数据。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kq"><img src="../Images/fd32b4eabc1ba8f1883bb3c08be3a135.png" data-original-src="https://miro.medium.com/v2/resize:fit:498/format:webp/1*bQuU_tXYlqsTCsuNzhbwJg.jpeg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">神经元样本数据</figcaption></figure><p id="c2f1" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">现在，神经网络计算算法的工作是找出权重w1、w2和w3的适当值，使得假设函数将产生期望的输出。在我们的例子中，它应该表现得像一个与门。分析输入数据后，算法可能得出w1 = -3、w2 = 2和w3 = 2的值。现在，假设函数变成了hɵ (x) = g ( -3 + 2 * x1 + 2 * x2)。</p><p id="451c" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">现在，让我们看看这个小小的单神经元网络将计算什么。让我们看看x1和x2的四个可能的输入值，并看看假设在这种情况下会输出什么。如果x1和x2都等于0，那么hɵ (x) = g (-3 + 2 * 0 + 2 * 0) = g (-3)，g(-3)将产生0。如果x1或x2中的任何一个等于0，那么hɵ (x) = g(-1)，g(-1)将产生0。当x1和x2都等于1时，假设将是hɵ (x) = g (-3 + 2 * 1 + 2 * 1) = g(1)，g(1)将产生1。如果您查看下图中的输出hɵ (x)列，您会发现这正是逻辑AND函数的行为。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kr"><img src="../Images/d2923b4d93ce8a6185b1a57abec7c974.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*s_OZC8J3lCsNElsyl5rkmg.jpeg"/></div></figure><p id="48af" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">这里，我们通过使用一个小的神经网络而不是使用一个实际的与门来构建计算机中的一个基本操作。神经网络也可以用来模拟所有其他的逻辑门。同一个神经元可以被训练得像逻辑“或”门一样。在这种情况下，计算的权重可以是w1 = -1，w2 = 2，w3 = 2。假设将是hɵ (x) = g ( -1 + 2 * x1 + 2 * x2)。如果你为这个新的假设函数写一个真值表，你会发现它就像一个逻辑或门。</p><p id="d787" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">现在，让我们回到我们的股市预测之谜。在本练习中，我们将探索一种叫做“LSTM”的神经网络算法。长短期记忆(LSTM)是一种用于深度学习领域的人工递归神经网络(RNN)架构。与标准的前馈神经网络不同，LSTM有反馈连接，这使它成为一台“通用计算机”(也就是说，它可以计算图灵机可以计算的任何东西)。</p><p id="5d91" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">普通的LSTM单元由一个单元、一个输入门、一个输出门和一个遗忘门组成。细胞在任意的时间间隔内记忆数值，三个门调节进出细胞的信息流。</p><p id="4aaf" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">LSTM网络非常适合基于时间序列数据进行分类、处理和预测，因为时间序列中的重要事件之间可能存在未知持续时间的滞后。</p><p id="b4b8" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">与之前尝试的时间序列预测算法不同，我们将股票市场数据直接输入到算法中，在这种情况下，对于LSTM，我们需要对股票市场数据进行一些预处理。输入数据集成为LSTM的预测边界。在进行预测时，它无法得出输入数据集之外的数字。例如，如果输入数据集中的最小值为600点，最大值为39000点，则未来预测值将仅在600到39000点的范围内。如果我们做未来十年的预测，那么这将永远不会发生，因为从长期来看，股票市场总是上涨的。因此，我们必须将股票市场数据转换为相对于之前收盘价的相对增减百分比的形式。通过这样做，我们消除了范围边界。因为我们现在在玩相关数据，实际上我们没有任何边界。现在，LSTM可以使用相对百分比数据进行真正的预测。让我们借助下面的例子来理解这一点。</p><p id="5055" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">表A显示了股票市场数据集。表B是表a的转换版本。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ks"><img src="../Images/2ab4e6c7fd8df574c2087d1136c88fba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*E23m5VdRyFya_a5oZxhIRA.jpeg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">样本股票市场数据集</figcaption></figure><p id="fee4" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">对于第一个项目1-1月，由于我们没有任何以前的值进行比较，因此相对百分比变化为0%。对于1月2日，当前收盘价为102点，之前的收盘价为100点，因此相对百分比变化为+2%。对于1月4日，当前收盘价为103点，先前收盘价为105点，因此相对百分比变化为-1.93%。同样，我们也计算了所有其他条目的值。</p><p id="3cbb" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">现在，让我们在真实数据上尝试这个神经网络解决方案。我们可以从https://www.bseindia.com/indices/IndexArchiveData.html下载。我已经下载了从1989年到现在的数据。下载的数据表共有五列；日期，开盘价，最高价，最低价和收盘价。为简单起见，我们从数据表中删除三列开盘价、最高价和最低价，只保留日期和收盘列。</p><p id="b1ff" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">以下是完整的python代码。代码被足够注释来解释这个问题的每一个方面。将它复制粘贴到python IDE上，并运行它以图形格式查看预测。</p><pre class="iy iz ja jb fd ku kv kw kx aw ky bi"><span id="648a" class="kz la hi kv b fi lb lc l ld le">#importing required libraries<br/>import numpy as np<br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, LSTM<br/>#to plot within notebook<br/>import matplotlib.pyplot as plt<br/><br/># function to calculate percentage difference considering baseValue as 100%<br/>def percentageChange(baseValue, currentValue):<br/>    return((float(currentValue)-baseValue) / abs(baseValue)) *100.00<br/><br/># function to get the actual value using baseValue and percentage<br/>def reversePercentageChange(baseValue, percentage):<br/>    return float(baseValue) + float(baseValue * percentage / 100.00)<br/><br/># function to transform a list of values into the list of percentages. For calculating percentages for each element in the list<br/># the base is always the previous element in the list.<br/>def transformToPercentageChange(x):<br/>    baseValue = x[0]<br/>    x[0] = 0<br/>    for i in range(1,len(x)):<br/>        pChange = percentageChange(baseValue,x[i])<br/>        baseValue = x[i]<br/>        x[i] = pChange<br/><br/># function to transform a list of percentages to the list of actual values. For calculating actual values for each element in the list<br/># the base is always the previous calculated element in the list.<br/>def reverseTransformToPercentageChange(baseValue, x):<br/>    x_transform = []<br/>    for i in range(0,len(x)):<br/>        value = reversePercentageChange(baseValue,x[i])<br/>        baseValue = value<br/>        x_transform.append(value)<br/>    return x_transform<br/><br/>#read the data file<br/>df = pd.read_csv('D:\\python3\\data\\SensexHistoricalData.csv')<br/># store the first element in the series as the base value for future use.<br/>baseValue = df['Close'][0]<br/><br/># create a new dataframe which is then transformed into relative percentages<br/>data ​= df.sort_index(ascending=True, axis=0)<br/>new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])<br/>for i in range(0,len(data)):<br/>    new_data['Date'][i] = data['Date'][i]<br/>    new_data['Close'][i] = data['Close'][i]<br/><br/># transform the 'Close' series into relative percentages<br/>transformToPercentageChange(new_data['Close'])<br/><br/># set Dat column as the index<br/>new_data.index = new_data.Date<br/>new_data.drop('Date', axis=1, inplace=True)<br/><br/># create train and test sets<br/>dataset = new_data.values<br/>train, valid = train_test_split(dataset, train_size=0.99, test_size=0.01, shuffle=False)<br/><br/># convert dataset into x_train and y_train.<br/># prediction_window_size is the size of days windows which will be considered for predicting a future value.<br/>prediction_window_size = 60<br/>x_train, y_train = [], []<br/>for i in range(prediction_window_size,len(train)):<br/>    x_train.append(dataset[i-prediction_window_size:i,0])<br/>    y_train.append(dataset[i,0])<br/>x_train, y_train = np.array(x_train), np.array(y_train)<br/>x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))<br/><br/>##################################################################################################<br/># create and fit the LSTM network<br/># Initialising the RNN<br/>model = Sequential()<br/># Adding the first LSTM layer and some Dropout regularisation<br/>model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))<br/>model.add(Dropout(0.2))<br/><br/># Adding a second LSTM layer and some Dropout regularisation<br/>model.add(LSTM(units = 50, return_sequences = True))<br/>model.add(Dropout(0.2))<br/><br/># Adding a third LSTM layer and some Dropout regularisation<br/>model.add(LSTM(units = 50, return_sequences = True))<br/>model.add(Dropout(0.2))<br/><br/># Adding a fourth LSTM layer and some Dropout regularisation<br/>model.add(LSTM(units = 50))<br/>model.add(Dropout(0.2))<br/><br/># Adding the output layer<br/>model.add(Dense(units = 1))<br/># Compiling the RNN<br/>model.compile(optimizer = 'adam', loss = 'mean_squared_error')<br/><br/># Fitting the RNN to the Training set<br/>model.fit(x_train, y_train, epochs = 100, batch_size = 32)<br/><br/>##################################################################################################<br/><br/>#predicting future values, using past 60 from the train data<br/># for next 10 yrs total_prediction_days is set to 3650 days<br/>total_prediction_days = 3650<br/>inputs = new_data[-total_prediction_days:].values<br/>inputs = inputs.reshape(-1,1)<br/><br/># create future predict list which is a two dimensional list of values.<br/># the first dimension is the total number of future days<br/># the second dimension is the list of values of prediction_window_size size<br/>X_predict = []<br/>for i in range(prediction_window_size,inputs.shape[0]):<br/>    X_predict.append(inputs[i-prediction_window_size:i,0])<br/>X_predict = np.array(X_predict)<br/><br/># predict the future<br/>X_predict = np.reshape(X_predict, (X_predict.shape[0],X_predict.shape[1],1))<br/>future_closing_price = model.predict(X_predict)<br/><br/>train, valid = train_test_split(new_data, train_size=0.99, test_size=0.01, shuffle=False)<br/>date_index = pd.to_datetime(train.index)<br/><br/>#converting dates into number of days as dates cannot be passed directly to any regression model<br/>x_days = (date_index - pd.to_datetime('1970-01-01')).days<br/><br/># we are doing prediction for next 5 years hence prediction_for_days is set to 1500 days.<br/>prediction_for_days = 1500<br/>future_closing_price = future_closing_price[:prediction_for_days]<br/><br/># create a data index for future dates<br/>x_predict_future_dates = np.asarray(pd.RangeIndex(start=x_days[-1] + 1, stop=x_days[-1] + 1 + (len(future_closing_price))))<br/>future_date_index = pd.to_datetime(x_predict_future_dates, origin='1970-01-01', unit='D')<br/><br/># transform a list of relative percentages to the actual values<br/>train_transform = reverseTransformToPercentageChange(baseValue, train['Close'])<br/><br/># for future dates the base value the the value of last element from the training set.<br/>baseValue = train_transform[-1]<br/>valid_transform = reverseTransformToPercentageChange(baseValue, valid['Close'])<br/>future_closing_price_transform = reverseTransformToPercentageChange(baseValue, future_closing_price)<br/><br/># recession peak date is the date on which the index is at the bottom most position.<br/>recessionPeakDate =  future_date_index[future_closing_price_transform.index(min(future_closing_price_transform))]<br/>minCloseInFuture = min(future_closing_price_transform);<br/>print("The stock market will reach to its lowest bottom on", recessionPeakDate)<br/>print("The lowest index the stock market will fall to is ", minCloseInFuture)<br/><br/># plot the graphs<br/>plt.figure(figsize=(16,8))<br/>df_x = pd.to_datetime(new_data.index)<br/>plt.plot(date_index,train_transform, label='Close Price History')<br/>plt.plot(future_date_index,future_closing_price_transform, label='Predicted Close')<br/><br/># set the title of the graph<br/>plt.suptitle('Stock Market Predictions', fontsize=16)<br/><br/># set the title of the graph window<br/>fig = plt.gcf()<br/>fig.canvas.set_window_title('Stock Market Predictions')<br/><br/>#display the legends<br/>plt.legend()<br/><br/>#display the graph<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lf"><img src="../Images/18adb40a2684e49468357979f5a927c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Suw09RoNsKtn4ULWQMzfzg.jpeg"/></div></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">衰退图</figcaption></figure><p id="5328" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated"><strong class="jm hj">如何解读上面的图像？</strong></p><p id="1ab3" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">图表的x轴显示了从1989年到2025年的日期，Y轴显示了市场收盘价。</p><p id="58d8" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">蓝色图表显示了从1989年到2019年的收盘价历史。橙色的图表代表从2019年到2025年的未来预测。</p><p id="31c2" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated"><strong class="jm hj">有哪些预言？</strong></p><p id="4427" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">1.股市将跌至的最低指数是<strong class="jm hj">17574</strong>。</p><p id="fa37" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">2.在2020年12月18日，股票市场将到达最低点。</p><p id="4133" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">3.从2020年第二季度开始，经济将陷入衰退。</p><p id="ee19" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">4.股市还需要五年时间才能从衰退中复苏。</p><p id="25b7" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">5.忘掉股票市场的回报吧，只需担心如何保护你的投资！！</p><p id="a6ba" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated"><strong class="jm hj">预测图分析:</strong></p><p id="60dc" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">看了这些预测后，我现在既高兴又担心。我很高兴，因为我们可以找到一种使用最大似然算法来预测衰退的技术。我很担心，因为我们真的将不得不面对这种可怕的现象。</p><p id="c497" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">与早期使用各种回归技术进行的预测不同，使用LSTM算法进行的预测似乎是真实的。橙色的预测图与蓝色的真实生活图一样动态。现在，我们已经通过识别一个正确的算法破解了股票市场预测之谜中最困难的部分。下一个挑战是对其进行微调，以获得更准确的预测。</p><p id="d908" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">所有这些预测都是用时间这一维度来完成的。正如智者所说，时间能解答所有的疑问。在这里，我们用时间来预测下一次衰退的到来。但是让我们把哲学放在一边，回到现实中来。现实情况是，包括时间在内的许多因素影响着股市行为。我们绝不能忽视它们。上述预测可能不准确，日期可能不同，但底线不会改变。底线是衰退即将到来。</p><p id="0f18" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">世界在80年代、90年代和21世纪初创造了最多的财富，然后是我们这一代人，他们在2010年开始挣钱。我们都知道股票市场在过去十年中的暗淡表现，我们所有的预测都向我们展示了一幅暗淡的前景。我们这一代被诅咒了！！我们已经开始在长期经济周期的低谷中赚钱。让我们承认，我们现在不能利用股票市场创造财富。我们应该找到一些其他的方法。可能是闪亮的东西，闪光的东西可能会让我们变得富有。也许我们拥有的股票需要点石成金才能让我们变得富有。是的，点金术。但是记住点金术是对强大的迈达斯国王的诅咒。然而，它能成为我们的福音吗？让我们在下一篇文章《点金术》中找出那个诅咒。直到那时快乐的预言…..</p><p id="5353" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated"><strong class="jm hj">参考文献:</strong></p><p id="d764" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">https://en.wikipedia.org/wiki/Neural_network<a class="ae kt" href="https://en.wikipedia.org/wiki/Neural_network" rel="noopener ugc nofollow" target="_blank"/></p><p id="3c99" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">【https://en.wikipedia.org/wiki/Long_short-term_memory T4】</p></div></div>    
</body>
</html>