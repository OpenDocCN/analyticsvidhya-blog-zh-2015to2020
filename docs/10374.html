<html>
<head>
<title>Natural Language Processing with Restaurant Reviews (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">餐馆评论的自然语言处理(下)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/natural-language-processing-with-restaurant-reviews-part-2-ad240d1a7393?source=collection_archive---------9-----------------------#2020-10-16">https://medium.com/analytics-vidhya/natural-language-processing-with-restaurant-reviews-part-2-ad240d1a7393?source=collection_archive---------9-----------------------#2020-10-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="bb06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本博客的第1部分，我们致力于分析和理解餐馆评论数据集。我们发现，单词云和词频计算将带来有价值的见解。除此之外，我们还研究了基本的自然语言处理技术，比如去除标点符号、单词标记化、将文本转换成小写字母。还实现了一些重要的概念，如停用词的移除、词干提取和词汇化。</p><p id="2816" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一部分，请访问-</p><div class="jd je ez fb jf jg"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/natural-language-processing-with-restaurant-reviews-part-1-46e228585a32"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hj fi z dy jl ea eb jm ed ef hh bi translated">餐馆评论的自然语言处理(上)</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">这些天每个人似乎都在谈论机器学习，每个人似乎都想成为数据…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">medium.com</p></div></div><div class="jp l"><div class="jq l jr js jt jp ju jv jg"/></div></div></a></div><figure class="jx jy jz ka fd kb er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es jw"><img src="../Images/eafeb2a6e6301ae4b0b3f179a198fdfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gcp4Vrgta-b4_jvG1b0yyg.jpeg"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">使用文本数据可能很有趣。</figcaption></figure><h1 id="6578" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">构建分类器</h1><p id="5e29" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">由于数据集包含正面和负面评论，现在我们将构建一个分类器，它能够将新的给定评论分类为正面或负面。分类是一个有监督的机器学习问题。它指定数据元素所属的类，最适合在输出具有有限值和离散值时使用。在这里，我们将指定什么类型的审查是积极的，什么类型的审查是消极的，什么类型的审查是积极的。所以让我们进入编码。</p><pre class="jx jy jz ka fd lo lp lq lr aw ls bi"><span id="2dca" class="lt km hi lp b fi lu lv l lw lx"><strong class="lp hj">import</strong> <strong class="lp hj">nltk</strong> <br/><strong class="lp hj">import</strong> <strong class="lp hj">pandas</strong> <strong class="lp hj">as</strong> <strong class="lp hj">pd</strong> <br/><strong class="lp hj">import</strong> <strong class="lp hj">re</strong> <br/><strong class="lp hj">import</strong> <strong class="lp hj">string</strong> <br/><strong class="lp hj">from</strong> <strong class="lp hj">nltk.stem</strong> <strong class="lp hj">import</strong> WordNetLemmatizer</span></pre><p id="7dbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我们导入数据。</p><pre class="jx jy jz ka fd lo lp lq lr aw ls bi"><span id="48c6" class="lt km hi lp b fi lu lv l lw lx"><em class="ly"># Reading the dataset<br/></em>dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '<strong class="lp hj">\t</strong>', quoting = 3)<br/>dataset.head()</span></pre><figure class="jx jy jz ka fd kb er es paragraph-image"><div class="er es lz"><img src="../Images/db6b7e0862ab146025c4ee35ffbce6ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*YFuMgsVrTlyzPf8wX-rh_g.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">最多5个条目的数据概览。</figcaption></figure><p id="688e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将在最后提供Github上的数据文件和笔记本链接。</p><pre class="jx jy jz ka fd lo lp lq lr aw ls bi"><span id="9d7c" class="lt km hi lp b fi lu lv l lw lx">stopwords = nltk.corpus.stopwords.words('english')<br/>lemmatizer = WordNetLemmatizer()</span></pre><p id="2b77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将继续进行停用词删除和词条化。停用词是任何语言中最常见和重复的词。更多关于停用词和词汇化的信息，请访问我的博客1。现在进行文本预处理。</p><pre class="jx jy jz ka fd lo lp lq lr aw ls bi"><span id="cb9a" class="lt km hi lp b fi lu lv l lw lx"><em class="ly"># Preprocessing<br/></em>nltk.download('stopwords')<br/>corpus = []<br/><strong class="lp hj">for</strong> i <strong class="lp hj">in</strong> range(0, 1000): #as the data as 1000 data points<br/>    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])<br/>    review = review.lower()<br/>    review = review.split()<br/>    review = [lemmatizer.lemmatize(word) <strong class="lp hj">for</strong> word <strong class="lp hj">in</strong> review <strong class="lp hj">if</strong> <strong class="lp hj">not</strong> word <strong class="lp hj">in</strong> set(stopwords)]<br/>    review = ' '.join(review)<br/>    corpus.append(review)</span></pre><h1 id="394d" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">计数矢量化</strong></h1><p id="1d96" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">计数矢量化用于根据每个单词在整个文本中出现的频率(计数)将给定文本转换为矢量。有关计数矢量化技术的更多信息，请访问-</p><div class="jd je ez fb jf jg"><a href="https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hj fi z dy jl ea eb jm ed ef hh bi translated">使用计数向量器从文本中提取特征</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">CountVectorizer是Python中的scikit-learn库提供的一个很棒的工具。它用于转换给定的文本…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">www.geeksforgeeks.org</p></div></div><div class="jp l"><div class="ma l jr js jt jp ju jv jg"/></div></div></a></div><pre class="jx jy jz ka fd lo lp lq lr aw ls bi"><span id="3f30" class="lt km hi lp b fi lu lv l lw lx"><strong class="lp hj">from</strong> <strong class="lp hj">sklearn.feature_extraction.text</strong> <strong class="lp hj">import</strong> CountVectorizer<br/><em class="ly"># Creating the Bag of Words model<br/></em>cv = CountVectorizer(max_features = 2000)</span><span id="00c8" class="lt km hi lp b fi mb lv l lw lx"><em class="ly">#the X and y<br/></em>X = cv.fit_transform(corpus).toarray()<br/>y = dataset.iloc[:, 1].values</span><span id="3cf7" class="lt km hi lp b fi mb lv l lw lx">#X- data<br/>#y- labels</span></pre><p id="a45a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将把数据分成训练集和测试集。</p><pre class="jx jy jz ka fd lo lp lq lr aw ls bi"><span id="6493" class="lt km hi lp b fi lu lv l lw lx"><strong class="lp hj">from</strong> <strong class="lp hj">sklearn.model_selection</strong> <strong class="lp hj">import</strong> train_test_split<br/><em class="ly"># Splitting the dataset into the Training set and Test set<br/></em>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 7)</span><span id="2410" class="lt km hi lp b fi mb lv l lw lx">print(X_train.shape)<br/>print(y_train.shape)<br/>print(X_test.shape)<br/>print(y_test.shape)</span></pre><figure class="jx jy jz ka fd kb er es paragraph-image"><div class="er es mc"><img src="../Images/7d3855d9334d6ec81245ed9c9631980b.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*zmF1aikgISAVfvrSR6FE5A.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">我们得到了形状。</figcaption></figure><p id="8222" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将数据输入随机森林分类器。有关随机森林分类器的更多信息，请访问-</p><div class="jd je ez fb jf jg"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hj fi z dy jl ea eb jm ed ef hh bi translated">3.2.4.3.1.sk learn . ensemble . randomforestclassifier-sci kit-learn 0 . 23 . 2文档</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">class sk learn . ensemble . RandomForestClassifier(n _ estimators = 100，*，criterion='gini '，max_depth=None…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">scikit-learn.org</p></div></div><div class="jp l"><div class="md l jr js jt jp ju jv jg"/></div></div></a></div><pre class="jx jy jz ka fd lo lp lq lr aw ls bi"><span id="31a8" class="lt km hi lp b fi lu lv l lw lx"><strong class="lp hj">from</strong> <strong class="lp hj">sklearn.ensemble</strong> <strong class="lp hj">import</strong> RandomForestClassifier<br/><em class="ly"># Random Forest<br/></em>classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 7)<br/>classifier.fit(X_train, y_train)<br/>y_pred = classifier.predict(X_test)</span></pre><p id="5ff3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据已经“适合”到模型中，并且使用测试数据集的预测也已经生成。现在可以查看准确性得分和分类报告。</p><pre class="jx jy jz ka fd lo lp lq lr aw ls bi"><span id="a898" class="lt km hi lp b fi lu lv l lw lx"><strong class="lp hj">from</strong> <strong class="lp hj">sklearn.metrics</strong> <strong class="lp hj">import</strong> accuracy_score<br/><strong class="lp hj">from</strong> <strong class="lp hj">sklearn.metrics</strong> <strong class="lp hj">import</strong> classification_report</span><span id="3074" class="lt km hi lp b fi mb lv l lw lx">accuracy_score(y_test, y_pred)</span></pre><figure class="jx jy jz ka fd kb er es paragraph-image"><div class="er es me"><img src="../Images/c07744ea174374e3a744a21184ca6a49.png" data-original-src="https://miro.medium.com/v2/resize:fit:138/format:webp/1*tHfY0BI7YWhEI0REAtscNg.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">输出。</figcaption></figure><p id="e649" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们得到0.712或71.2%的分数，即分类器能够正确预测(在测试数据中)评论是正面还是负面的次数为71.2%。值得注意的一点是，使用计数矢量化，许多事情取决于一个单词在评论中出现的频率。比方说，如果像“坏”、“最差”、“陈旧”这样的词以高数量出现在负面评论的训练数据中，并且样本测试数据也包含这些词，则模型将确定该评论是负面的。这是使用计数矢量器的基本思想。</p><p id="63c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在，打印分类报告。</p><pre class="jx jy jz ka fd lo lp lq lr aw ls bi"><span id="c80a" class="lt km hi lp b fi lu lv l lw lx">print(classification_report(y_test, y_pred))</span></pre><figure class="jx jy jz ka fd kb er es paragraph-image"><div class="er es mf"><img src="../Images/fa733385b6673fdc3f54194ee902c5ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*_uQGQeAyTlTeIOp5lVe1wg.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">分类报告。</figcaption></figure><p id="6813" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这样，模型得到训练，我们也得到分类报告。博客的这一部分涉及机器学习管道。预处理、清理数据、完成NLP先决条件，最后将数据输入模型。</p><p id="c62e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ly">博客的第三部分也是最后一部分，我们将进行一次预测测试，使用pickle保存模型，并创建一个小的Python应用程序来进行预测。</em></p><p id="0609" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">项目代码及相关文件-</p><div class="jd je ez fb jf jg"><a href="https://github.com/prateekmaj21/Restaurant-Reviews-NLP-Project" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hj fi z dy jl ea eb jm ed ef hh bi translated">prateekma 21/餐厅-评论-NLP-项目</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">一个基于餐馆评论的自然语言处理项目。GitHub是超过5000万开发人员的家园，他们在…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">github.com</p></div></div><div class="jp l"><div class="mg l jr js jt jp ju jv jg"/></div></div></a></div><p id="c35f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">博客的第三部分-</p><div class="jd je ez fb jf jg"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/natural-language-processing-with-restaurant-reviews-part-3-2e08da61b8e5"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hj fi z dy jl ea eb jm ed ef hh bi translated">餐馆评论的自然语言处理(第三部分)</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">到目前为止，在这个博客的前两部分，我们致力于数据的分析，并创造了机器…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">medium.com</p></div></div><div class="jp l"><div class="mh l jr js jt jp ju jv jg"/></div></div></a></div><h1 id="0cad" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">谢谢你。</h1></div></div>    
</body>
</html>