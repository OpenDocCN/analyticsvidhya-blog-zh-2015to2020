<html>
<head>
<title>Finetuning BERT using ktrain for Disaster Tweets Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用ktrain对灾难推文分类进行微调</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/finetuning-bert-using-ktrain-for-disaster-tweets-classification-18f64a50910b?source=collection_archive---------5-----------------------#2020-06-28">https://medium.com/analytics-vidhya/finetuning-bert-using-ktrain-for-disaster-tweets-classification-18f64a50910b?source=collection_archive---------5-----------------------#2020-06-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="4989" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">问题陈述</h1><p id="d409" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">推特已经成为紧急时刻的重要沟通渠道。智能手机的普及使人们能够实时宣布他们正在观察的紧急情况。正因为如此，越来越多的机构对有计划地监控Twitter感兴趣(即救灾组织和新闻机构)。然而，识别这样的推文一直是一项艰巨的任务，因为推文的语言结构模糊不清，因此并不总是清楚个人的话是否实际上在宣布一场灾难。例如，如果一个人发推文:</p><blockquote class="kb kc kd"><p id="46eb" class="jd je ke jf b jg kf ji jj jk kg jm jn kh ki jq jr kj kk ju jv kl km jy jz ka hb bi translated">"从好的方面来看，昨晚的天空是<strong class="jf hj">闪亮的</strong>"</p></blockquote><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es kn"><img src="../Images/be364d5171817a8b892a1a0bd6157598.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*LgCKmw6OY-_IvXJsk44JxQ.png"/></div></figure><p id="02f7" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">这个人在这里明确地使用了“<strong class="jf hj">闪亮的</strong>”这个词，但它是隐喻性的。对于一个人来说，更容易理解它，特别是如果有一些视觉帮助的话。然而，对于机器来说，这并不总是清楚的。</p><p id="7b06" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">Kaggle举办了一场名为<strong class="jf hj">真实与否</strong>的挑战，其目的是使用最初由figure-figure公司创建的灾难推文的Twitter数据，将谈论真实灾难的推文与隐喻性谈论灾难的推文进行分类。</p><h1 id="313a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">方法</h1><p id="e435" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">BERT ( <a class="ae kv" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank">来自变形金刚</a>的双向编码器表示)是谷歌开发的深度学习模型。自从它被Google开源以来，它已经被许多研究人员和行业采用，并应用于解决许多NLP任务。该模型已经能够在它所应用的大多数问题上实现最先进的性能。</p><p id="fc0d" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated"><a class="ae kv" href="https://github.com/amaiya/ktrain" rel="noopener ugc nofollow" target="_blank"> <em class="ke"> ktrain </em> </a>是深度学习库<a class="ae kv" href="https://www.tensorflow.org/guide/keras/overview" rel="noopener ugc nofollow" target="_blank"> TensorFlow Keras </a>(以及其他库)的轻量级包装器，用于帮助构建、训练和部署神经网络和其他机器学习模型。受ML框架扩展如<em class="ke"> fastai </em>和<em class="ke"> ludwig </em>的启发，它旨在使深度学习和人工智能更容易获得，更容易应用于新人和有经验的从业者。</p><p id="f102" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated"><em class="ke"> ktrain </em>为在自然语言处理领域应用许多预先训练好的深度学习架构提供支持，BERT就是其中之一。为了解决这个问题，我们将使用由<em class="ke"> ktrain </em>提供的预训练BERT的实现，并对其进行微调，以分类灾难推文是否真实。</p><h1 id="5c73" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">解决办法</h1><p id="077d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">数据集由三个文件组成:</p><ol class=""><li id="b36a" class="kw kx hi jf b jg kf jk kg jo ky js kz jw la ka lb lc ld le bi translated">train.csv</li><li id="858d" class="kw kx hi jf b jg lf jk lg jo lh js li jw lj ka lb lc ld le bi translated">test.csv</li><li id="e0af" class="kw kx hi jf b jg lf jk lg jo lh js li jw lj ka lb lc ld le bi translated">sample_submission.csv</li></ol><p id="0dd9" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">文件train.csv的结构如下:</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/ce4721ba69bfa1548207b1a63a26e713.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wz_UluOzVukVneosHJ9u0Q.png"/></div></div></figure><ul class=""><li id="5493" class="kw kx hi jf b jg kf jk kg jo ky js kz jw la ka lp lc ld le bi translated"><code class="du lq lr ls lt b">id</code> -每条推文的唯一标识符</li><li id="632f" class="kw kx hi jf b jg lf jk lg jo lh js li jw lj ka lp lc ld le bi translated"><code class="du lq lr ls lt b">text</code> -推文的文本</li><li id="3a81" class="kw kx hi jf b jg lf jk lg jo lh js li jw lj ka lp lc ld le bi translated"><code class="du lq lr ls lt b">location</code> -发送推文的位置(可能为空)</li><li id="513f" class="kw kx hi jf b jg lf jk lg jo lh js li jw lj ka lp lc ld le bi translated"><code class="du lq lr ls lt b">keyword</code> -推文中的特定关键词(可能为空)</li><li id="b6a6" class="kw kx hi jf b jg lf jk lg jo lh js li jw lj ka lp lc ld le bi translated"><code class="du lq lr ls lt b">target</code> -仅在train.csv中，这表示一条推文是否是关于真实的灾难(<code class="du lq lr ls lt b">1</code>)或不是(<code class="du lq lr ls lt b">0</code>)</li></ul><p id="6f06" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">我们只对<strong class="jf hj">文本</strong>和<strong class="jf hj">目标</strong>栏感兴趣，并将使用它们对推文进行分类。</p><h2 id="7a2d" class="lu ig hi bd ih lv lw lx il ly lz ma ip jo mb mc it js md me ix jw mf mg jb mh bi translated">步骤1:安装ktrain</h2><pre class="ko kp kq kr fd mi lt mj mk aw ml bi"><span id="1b2d" class="lu ig hi lt b fi mm mn l mo mp">!pip3 install ktrain</span></pre><h2 id="2c21" class="lu ig hi bd ih lv lw lx il ly lz ma ip jo mb mc it js md me ix jw mf mg jb mh bi translated">步骤2:导入模块并读取培训文件</h2><pre class="ko kp kq kr fd mi lt mj mk aw ml bi"><span id="0ed2" class="lu ig hi lt b fi mm mn l mo mp">import ktrain<br/>from ktrain import text<br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split</span></pre><p id="112a" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">我们将读取训练文件，并对<strong class="jf hj">目标</strong>列执行分层拆分，并将20%的数据定义为验证集。</p><pre class="ko kp kq kr fd mi lt mj mk aw ml bi"><span id="0229" class="lu ig hi lt b fi mm mn l mo mp">train_df = pd.read_csv("train.csv")</span><span id="e655" class="lu ig hi lt b fi mq mn l mo mp">random_seed = 12342</span><span id="d7d8" class="lu ig hi lt b fi mq mn l mo mp">x_train, x_val, y_train, y_val = train_test_split(train_df['text'], train_df['target'], shuffle=True, test_size = 0.2, random_state=random_seed, stratify=train_df['target'])</span></pre><h2 id="49ae" class="lu ig hi bd ih lv lw lx il ly lz ma ip jo mb mc it js md me ix jw mf mg jb mh bi translated">步骤3:将数据转换为BERT的要素</h2><p id="aed6" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><em class="ke"> ktrain </em>提供了一个非常方便的功能，可以直接将文本数据转换成模型所需的特征。所有的文本预处理步骤都不需要手动执行，将由库本身负责。因为我们将从pandas系列对象中读取数据，所以我们将使用函数<code class="du lq lr ls lt b">texts_from_array</code>。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mr"><img src="../Images/1bc79b37cca4e4f1e5f70d53a46f101c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v8djSORoB-ZkjSulha-eRQ.png"/></div></div></figure><p id="00f1" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">该函数自动下载预先训练好的BERT及其词汇。因为对于伯特来说，文本必须以特定的方式进行预处理，所以我们必须将<code class="du lq lr ls lt b">preprocess_mode </code>指定为“<strong class="jf hj">伯特</strong>”。</p><h2 id="6a91" class="lu ig hi bd ih lv lw lx il ly lz ma ip jo mb mc it js md me ix jw mf mg jb mh bi translated">步骤3:将Bert加载到学习者对象中</h2><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ms"><img src="../Images/1c9ccde052bceec96f2a965770c364d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bGuzEXmOq4X_HjfXLJRsvw.png"/></div></div></figure><p id="0563" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">第一个函数<code class="du lq lr ls lt b">text_classifier</code>用随机初始化的最终<strong class="jf hj">密集层</strong>加载预训练的BERT模型。值得一提的是，虽然最终的<strong class="jf hj">密集层</strong>是随机初始化的，但在训练过程中不会只有一个被更新。因为我们没有冻结任何层，并且模型的所有层都是可训练的，所以模型的所有层的权重将在反向传播期间更新。</p><p id="f7f2" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">第二个函数<code class="du lq lr ls lt b">get_learner</code>创建一个带有训练和验证数据的学习器对象，可用于微调分类器。<code class="du lq lr ls lt b">get_learner</code>的最后一个参数是<strong class="jf hj">批量</strong>。我们使用16个小批量。</p><h2 id="9f45" class="lu ig hi bd ih lv lw lx il ly lz ma ip jo mb mc it js md me ix jw mf mg jb mh bi translated">步骤4:训练(微调BERT分类器)</h2><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mt"><img src="../Images/4d68bcaf7d1c2cb82d34a6fda3badbae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ZaXk06iMath2KkPfmoP4g.png"/></div></div></figure><p id="b70a" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">为了训练模型，我们将首先找到最适合我们问题的最佳学习率。<em class="ke"> ktrain </em>提供了一个非常好的方法，名为<code class="du lq lr ls lt b">lr_find</code>，它以不同的学习速率训练模型，并绘制出模型随着学习速率增加的损失。</p><p id="80f5" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">可以通过调用以下方法来观察学习率图:</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mu"><img src="../Images/0a85e359c77edef3cf104630fcb8b447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*H20iXyxYEKT8--bT4mNizw.png"/></div></figure><p id="0b49" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">我们可以观察到，当学习率为1e-5时，分类器提供最小的损失。</p><p id="933d" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">我们现在将使用<code class="du lq lr ls lt b">autofit</code>方法训练模型。该方法训练分类器并自动选择最佳表现的分类器，防止模型的欠拟合和过拟合。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ca"><img src="../Images/23dbbbd500b4498b61c8069a3f7355e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ou4DoTV6Ddoga-v9J6ew1Q.png"/></div></div></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mv"><img src="../Images/1e111ae0584b8f78535e17446cd18574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*xYSrBdt8WxcM7fRK4JVCZA.png"/></div></figure><p id="296d" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">我们能够实现<strong class="jf hj"> 84% </strong>的验证准确性，并且每个预测类都有很好的F-1分数。由于我们使用了<code class="du lq lr ls lt b">autofit</code>方法，我们确信我们的模型已经训练好，现在可以根据测试数据给出预测了。</p><h2 id="b4c3" class="lu ig hi bd ih lv lw lx il ly lz ma ip jo mb mc it js md me ix jw mf mg jb mh bi translated">步骤5:根据测试数据进行预测</h2><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mw"><img src="../Images/6ffadedb5536a221aecb7bb952971db8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*UQPEOjfFmBvAondESanVcg.png"/></div></figure><p id="24e4" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">预测变量是通过在<code class="du lq lr ls lt b">get_predictor</code>方法中传递<strong class="jf hj">模型</strong>和<strong class="jf hj"> preproc </strong>对象获得的。然后，该预测器可用于直接对测试数据进行预测。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mx"><img src="../Images/26a0d7e33238fb23cf2aa9e484e8d393.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*JkrjMdLw-EjtkmWE0mNaOQ.png"/></div></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es my"><img src="../Images/dfb11f92fdb163a89e86c1b996a66f3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*Js4VO-Obk8vopJ18Dkgkgg.png"/></div></figure><h2 id="7e7d" class="lu ig hi bd ih lv lw lx il ly lz ma ip jo mb mc it js md me ix jw mf mg jb mh bi translated">步骤6:在Kaggle上上传测试数据预测</h2><p id="13da" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">最后一步是在Kaggle上上传预测，并检查我们的分数。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mz"><img src="../Images/38260f636959e7da168a30f71a039461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o3GuoRnTC9dMKfgYU57rlw.png"/></div></div></figure><p id="12b4" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">我们能够在测试集上达到83.4%的准确率。相当令人印象深刻！！</p><p id="ec35" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">完整的代码可以从我的<a class="ae kv" href="https://github.com/hamiz-ahmed/Machine-Learning-Notebooks/blob/master/disaster_tweets_classification_using_BERT.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>账号获得。</p><h1 id="0ca5" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结论</h1><p id="a0d2" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们使用了<em class="ke"> ktrain </em>的特性来解决Kaggle挑战——不管是真是假。我们发现使用<em class="ke"> ktrain在任何问题域中实现像BERT这样的复杂模型是多么容易。</em>最终，我们能够实现83%左右的测试准确率。</p><h1 id="c32a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">丰富</h1><p id="518f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">伯特的一个主要问题是它需要很长时间的训练。为了迎合这一点，可以应用BERT的一个较轻的变体，如<a class="ae kv" href="https://arxiv.org/abs/1910.01108" rel="noopener ugc nofollow" target="_blank"> distilBERT </a>，可以试用它来解决这个问题。此外，为了减少训练时间，可以冻结除最后一层之外的所有层的权重。然而，这种方法的性能还需要测试。</p><p id="36a0" class="pw-post-body-paragraph jd je hi jf b jg kf ji jj jk kg jm jn jo ki jq jr js kk ju jv jw km jy jz ka hb bi translated">此外，人们还可以尝试不同的具有预训练单词嵌入的深度神经架构，并测试它们在这个问题上的性能。</p><h1 id="7c66" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">参考文献和致谢</h1><ul class=""><li id="0027" class="kw kx hi jf b jg jh jk jl jo na js nb jw nc ka lp lc ld le bi translated"><em class="ke"> ktrain </em> github回购—<a class="ae kv" href="https://github.com/amaiya/ktrain" rel="noopener ugc nofollow" target="_blank">https://github.com/amaiya/ktrain</a></li><li id="ee66" class="kw kx hi jf b jg lf jk lg jo lh js li jw lj ka lp lc ld le bi translated">用于语言理解的深度双向转换器的BERT预训练—【https://arxiv.org/abs/1810.04805 T21】</li><li id="2cad" class="kw kx hi jf b jg lf jk lg jo lh js li jw lj ka lp lc ld le bi translated">卡格尔是真的还是假的？灾难推文NLP—<a class="ae kv" href="https://www.kaggle.com/c/nlp-getting-started/overview" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/nlp-getting-started/overview</a></li><li id="0e84" class="kw kx hi jf b jg lf jk lg jo lh js li jw lj ka lp lc ld le bi translated">本项目Github笔记本—<a class="ae kv" href="https://github.com/hamiz-ahmed/Machine-Learning-Notebooks/blob/master/disaster_tweets_classification.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/hamiz-Ahmed/Machine-Learning-Notebooks/blob/master/disaster _ tweets _ classification . ipynb</a></li></ul></div></div>    
</body>
</html>