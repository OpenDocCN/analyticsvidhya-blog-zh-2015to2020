<html>
<head>
<title>How Are You Feeling? — Answered with A Real-Time Emotion Detector</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你感觉怎么样？—用实时情绪检测器回答</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-real-time-emotion-detector-towards-machine-with-e-q-c20b17f89220?source=collection_archive---------5-----------------------#2019-12-25">https://medium.com/analytics-vidhya/building-a-real-time-emotion-detector-towards-machine-with-e-q-c20b17f89220?source=collection_archive---------5-----------------------#2019-12-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7564" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“他感觉怎么样？”随着关于心理健康的对话越来越普遍，这个问题也越来越频繁地出现在我的脑海中。由于小丑对精神疾病的有力描述，我们开始谈论保持良好精神健康的方法。</p><p id="ac52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">情绪跟踪是这样做的方法之一，因为它可以帮助我们调节我们的情绪。如果我们能够及早发现我们情绪模式的变化，我们就可以开始采取措施来管理它们。</p><p id="a52a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这让我想到……如果我们可以利用机器学习的力量来预测某人的内心感受——而不必问一个问题，会怎么样？</p><p id="28aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我建立了自己的情绪检测器(在这个<a class="ae jd" href="https://github.com/travistangvh/emotion-detection-in-real-time" rel="noopener ugc nofollow" target="_blank"> Github库</a>)。</p><div class="je jf jg jh fd ab cb"><figure class="ji jj jk jl jm jn jo paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><img src="../Images/01ffd11cfa670c3122dadc729329fe15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*FaUX_C1WCEGEbaU-IyxBcA.gif"/></div></figure><figure class="ji jj jk jl jm jn jo paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><img src="../Images/705a36dd4c3902cfbc56d510c82cf3d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*ZiASBi6xOakFcyMNMKwZTQ.gif"/></div><figcaption class="jv jw et er es jx jy bd b be z dx jz di ka kb translated">终于，有人知道我的感受…</figcaption></figure></div><p id="86ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是方法。</p><h1 id="0c3e" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">该过程总结如下</h1><p id="ceef" class="pw-post-body-paragraph if ig hi ih b ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc hb bi translated">首先，我收集了大量带有各种情绪的人脸数据。然后，我使用Keras训练了一个卷积神经网络来识别各种情绪。为了实时预测情绪，来自网络摄像头的实时视频被输入一个网络，该网络可以检测人脸并预测情绪。</p><ol class=""><li id="951d" class="lf lg hi ih b ii ij im in iq lh iu li iy lj jc lk ll lm ln bi translated"><strong class="ih hj">收集数据</strong></li></ol><p id="25ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用的数据是<a class="ae jd" href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data" rel="noopener ugc nofollow" target="_blank">面部情感识别数据集</a>。它由35，887张48x48灰度级的人脸组成，分为7种情绪类型，训练验证测试分为75-12.5-12.5。</p><figure class="je jf jg jh fd jj er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es lo"><img src="../Images/fec78671343e0a9da07bcd2395384331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aqfU5K1HUUKU9Nm798Zqyw.jpeg"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">FER2013图像的一些样本(0 =愤怒，1 =厌恶，2 =恐惧，3 =快乐，4 =悲伤，5 =惊讶，6 =中性)</figcaption></figure><p id="8f23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们研究一下数据的分布。频率图显示数据集是倾斜的。虽然有9000多张快乐的脸，但只有不到1000张“厌恶”的脸。这告诉我们，利用这个数据集，我们可能无法有效地识别“厌恶”的面孔。</p><figure class="je jf jg jh fd jj er es paragraph-image"><div class="er es lp"><img src="../Images/bd1258e8bcd099ffc8c9836a017c2acd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*iyLl2mko6akbs_G04Hh0CQ.jpeg"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">FER2013数据集的频率表</figcaption></figure><p id="8243" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">架构</strong></p><p id="c1ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很自然会考虑使用<a class="ae jd" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>来完成图像识别任务。与传统的机器学习技术(如决策树或梯度提升)相比，卷积神经网络允许有效地检测特征。这样的网络允许早期在网络中检测到的简单特征(如线条)拼凑在一起，形成复杂的特征(如组成左眼的简单曲线)，使卷积神经网络在识别图像方面特别有效。</p><p id="4408" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，这里使用的架构是由牛津大学的一组研究人员提出的名为VGGFace 的<a class="ae jd" href="http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf" rel="noopener ugc nofollow" target="_blank">卷积神经网络。网络的输入馈入8个卷积块和3个全连接层。每个卷积块包含一个线性卷积层，后面是非线性层(例如ReLU和max pooling)。最终的softmax层输出每种情绪的概率。</a></p><p id="9a68" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑到网络接受大小为226 x 226的输入比我们的大小为48 x 48的训练图像大得多，网络可能会过度适应训练图像。换句话说，网络可能会记住训练集中的面孔——它可能会在以前见过的面孔上表现得很好，但在没有见过的面孔上则不然。因此，网络以两种方式改变:</p><ul class=""><li id="c09f" class="lf lg hi ih b ii ij im in iq lh iu li iy lj jc lq ll lm ln bi translated">首先，卷积块(Conv)的数量从8减少到5。</li><li id="e69f" class="lf lg hi ih b ii lr im ls iq lt iu lu iy lv jc lq ll lm ln bi translated">其次，全连接(FC)层的数量从3个减少到1个。在这个全连接层之后是一个概率为0.5的脱落层。</li></ul><figure class="je jf jg jh fd jj er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es lw"><img src="../Images/db62f13f04c9632350ac6e05bfe66444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nWTS-wPtWU5QJbXzfK70Ew.jpeg"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">用于情感识别任务的改变的VGGFace的图示</figcaption></figure><p id="a3d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.<strong class="ih hj">训练过程</strong></p><p id="4004" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型使用深度学习库Keras进行训练。在训练时，分类交叉熵损失随着学习率为0.001的随机梯度下降而最小化。该模型用90个历元进行训练，批次大小为32。</p><p id="232e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着训练的进行，模型在训练和验证集上的准确性增加，而损失减少。此外，我们看到训练集和验证集的值彼此非常接近。</p><p id="7a57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简单地说，我们的模型在以前见过的人脸上的表现有所提高。瞧，这就是健康神经网络的标志。</p><div class="je jf jg jh fd ab cb"><figure class="ji jj lx jl jm jn jo paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><img src="../Images/e72bb9fb3964778440dc6a78ed5058c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*lpOE0SeqeqP_0UrobPeEfg.jpeg"/></div></figure><figure class="ji jj ly jl jm jn jo paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><img src="../Images/af558bad485771bceb7ed29ee19f0800.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*0h-Q81P8Z0YoS_QZAw6SpA.jpeg"/></div><figcaption class="jv jw et er es jx jy bd b be z dx lz di ma kb translated">训练和验证集的<strong class="bd ke">准确度和损失相对于历元数的图表</strong></figcaption></figure></div><p id="e75a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.<strong class="ih hj">性能</strong></p><p id="f0fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练我们的模型之后，我们将使用测试集(使用模型以前没有见过的人脸)来测试模型。可以说，该模型的性能最好使用对面部情绪进行分类的F1分数来评估，而不是准确性、精确度或回忆等指标。直观地说，准确性是相对于整个测试集做出的正确预测的比例。</p><p id="bf0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">测试集的准确度=测试集中正确分类的人脸数量/测试集中的人脸总数。</p><p id="be5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，<a class="ae jd" href="https://tryolabs.com/blog/2013/03/25/why-accuracy-alone-bad-measure-classification-tasks-and-what-we-can-do-about-it/" rel="noopener ugc nofollow" target="_blank">当数据集偏斜时，一个差的模型可能报告高精度</a>。对于这些情况，首选精度或召回率等替代指标。这两个指标可以合并为一个指标，即F1得分，这与在FER2013这样的倾斜数据集上训练和测试的模型特别相关。</p><figure class="je jf jg jh fd jj er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es mb"><img src="../Images/5c8f112a84db93c8c68f3e75f6e66d6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BBL-sx0sWhp9tOm9dMx6dA.jpeg"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">f1-7种情绪测试集的分数</figcaption></figure><p id="b71f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从F1分数的条形图中，我们可以看到我们的模型能够很好地预测快乐、惊讶、中性、悲伤和愤怒的表情。然而，它在表现厌恶和恐惧的脸上表现较差。为了研究错误分类的情况，我们绘制了数据集的混淆矩阵。</p><p id="f02c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="mc">归一化混淆矩阵</em>报告正确或错误分类的人脸比例。在矩阵的纵轴和横轴上分别是人脸的真实和预测标签。混淆矩阵的对角线显示了正确分类的人脸比例，以及错误分类的人脸比例。</p><figure class="je jf jg jh fd jj er es paragraph-image"><div class="er es md"><img src="../Images/5680d5d1249b5a0a00eb2bd6045f4663.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*DENp6rhSaeZfg-I0jWi_lQ.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">测试集的混淆矩阵</figcaption></figure><p id="36ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有了矩阵，我们可以通过查看混淆矩阵中真正的标签是“厌恶”或“恐惧”的行来分析为什么模型在“厌恶”和“恐惧”上表现不佳。</p><p id="c256" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">啊，现在清楚了。大多数“厌恶”的脸被错误地预测为愤怒、悲伤或恐惧，而大多数“恐惧”的脸被错误地预测为悲伤或愤怒。这不应该令人惊讶，因为训练集中有限数量的“厌恶”面孔可能不足以训练该模型。</p><p id="e345" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更重要的是，更多的时候，我们在脸上表达的情绪不止一种。一个人可以经历和表达不同程度的恐惧、悲伤和愤怒——所有这些都用一个表情来表达。因此，<em class="mc">甚至</em>一个人都可能无法从一张脸上准确地分辨出负面情绪的类型，更不用说一台机器了。不用说，<a class="ae jd" href="https://dl.acm.org/citation.cfm?id=3295710" rel="noopener ugc nofollow" target="_blank">超越人类水平的精确度是具有挑战性的</a>，尽管并非不可能。</p><p id="53eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.<strong class="ih hj">局限与改进</strong></p><p id="3440" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们所讨论的可能是这个模型的最大限制。它不能将我们经历的情绪简单地归类为7个小盒子——仅仅是因为我们经历了7种以上的情绪，以及它们的无限组合。因此，这个模型的更好版本应该识别不同情绪的组合。例如，如果一张脸同时表达了悲伤和愤怒，这两种情绪都会作为输出显示出来。这可以通过设置一个概率阈值来实现——只要特定情绪的概率高于阈值，就会显示为输出之一。</p><p id="a780" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型的另一个明显的局限性是使用了具有许多参数的大型网络，这可能会限制其预测速度。事实上，修改后的VGGFace网络(1950万个参数)明显大于类似于<a class="ae jd" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"> MobileNet </a>这样的轻量级网络(230万个参数)。其他值得探索的模型还有<a class="ae jd" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231219310045" rel="noopener ugc nofollow" target="_blank"> LightFace </a>和<a class="ae jd" href="https://arxiv.org/abs/1602.07360" rel="noopener ugc nofollow" target="_blank"> SqueezeNet、</a>都是用于计算机视觉的轻量级模型。</p><p id="6bc2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.<strong class="ih hj">实时预测</strong></p><p id="7625" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了实时预测，首先使用python上的CV2捕获直播视频，并将其输入到人脸检测网络mt CNN<a class="ae jd" href="https://kpzhang93.github.io/MTCNN_face_detection_alignment/" rel="noopener ugc nofollow" target="_blank">中，该网络可以实现出色的实时性能。检测到的人脸然后被输入到我们训练好的网络中，在那里模型输出预测。</a></p><p id="4aa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.<strong class="ih hj">接下来的步骤</strong></p><p id="9fda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我很高兴能继续改进模型的局限性，并最终部署到一个应用程序中。特别是，我对开发一个可以根据相机图像检测用户情绪下降的应用程序很感兴趣。该应用能够及早发现负面情绪，可以帮助提升用户的情绪——通过冥想、锻炼或其他方式。为了构建这个应用程序，我计划在使用Tensorflow Lite时遵循deeplearning.ai的<a class="ae jd" href="https://www.coursera.org/specializations/tensorflow-data-and-deployment?" rel="noopener ugc nofollow" target="_blank">Laurence mono Rey</a>的步骤。</p><p id="c2fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你对项目代码感兴趣，可以随意参考我的<a class="ae jd" href="https://github.com/travistangvh/emotion-detection-in-real-time/" rel="noopener ugc nofollow" target="_blank"> Github资源库</a>。欢迎任何反馈:)</p><div class="me mf ez fb mg mh"><a href="https://github.com/travistangvh/emotion-detection-in-real-time" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hj fi z dy mm ea eb mn ed ef hh bi translated">travistangvh/实时情绪检测</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">以下存储库是实时人脸检测和情感分类模型。</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">github.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv jt mh"/></div></div></a></div><h1 id="ecf1" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">确认</h1><ul class=""><li id="2d6e" class="lf lg hi ih b ii la im lb iq mw iu mx iy my jc lq ll lm ln bi translated"><a class="ae jd" href="http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf" rel="noopener ugc nofollow" target="_blank">深度人脸识别</a>由Parkhi等人完成。艾尔。</li></ul><p id="f149" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">P.S .这是我的第一个深度学习项目，我非常高兴它成功了。我鼓励任何人尝试新项目，并尝试做同样的事情。</p><figure class="je jf jg jh fd jj er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es mz"><img src="../Images/310cfa4eb7fe9d6be1250065949fe74e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BZdIWoAC98ziDUuF2ZHWOw.jpeg"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">感谢您的阅读！</figcaption></figure></div></div>    
</body>
</html>