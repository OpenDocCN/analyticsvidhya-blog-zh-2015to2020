<html>
<head>
<title>Speaker Identification Using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习的说话人识别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/speaker-identification-using-machine-learning-3080ee202920?source=collection_archive---------4-----------------------#2019-12-02">https://medium.com/analytics-vidhya/speaker-identification-using-machine-learning-3080ee202920?source=collection_archive---------4-----------------------#2019-12-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8b29888bdcb891a5a09514969bc78189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VJhEGdRSNS-n-jGJ"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">杰森·罗斯韦尔在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h2 id="9633" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">简介:</h2><p id="4e1d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">在当今的数据技术时代，音频信息在增加数据量方面起着重要的作用；因此需要一种方法来揭开这些内容的神秘面纱，从中获得有意义的见解。语音识别是一种旨在识别说话人而不是单词本身的方法。随着技术的发展，语音识别已经越来越多地嵌入到我们的日常生活中，在每天的数字设备中都有语音驱动的应用。语音识别主要分为说话人确认和说话人识别两部分。说话人识别从一组已知的说话人中确定哪个注册的说话人提供给定的话语。说话人确认接受或拒绝说话人的身份声明。</p><h2 id="aacb" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">程序:</h2><p id="e979" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">1)使用Pyaudio记录音频样本:</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/3bd60f3b3ada2db5765891e05073931a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yVW2RI4fW0sVE5UN"/></div></div></figure><p id="809a" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">2)从音频样本中提取特征:</p><p id="f826" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">其思想是通过使用高斯混合模型来进行说话人的正确识别。处理音频样本的第一步是从中提取特征，即从音频信号中识别成分。我们使用梅尔频率倒谱系数(MFCC)从音频样本中提取特征。MFCC将信号映射到模拟人类听觉的非线性Mel尺度上，并提供单独描述单个帧的功率谱包络的MFCC特征向量。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/9ff7bc8edbe0951d05929d1e4fb615d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fj1IHOhXFfudiM5x"/></div></div></figure><p id="67d0" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">我们考虑了具有调谐参数的MFCC作为主要特征，以及也被称为微分和加速度系数的δMFCC，其被用于处理与动力学相关的语音信息，即MFCC系数随时间的轨迹，其结果是这些轨迹的计算。</p><p id="95cf" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">3)使用GMM训练机器学习模型:</p><p id="2d06" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">高斯混合模型(GMM)是处理音频数据时最常用的训练模型之一，所以我们使用MFCC和GMM来达到正确识别说话人的目的。GMM用于在(MFCC+德尔塔MFCC)提取的特征上训练模型。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/ad0e28dc7e0385b303333b024452bd1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9rkSHga8K0eTB6Ou"/></div></div></figure><p id="eb75" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">4)用于预测样本语音的说话人的测试模型:</p><p id="8e54" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">GMM模型将用于计算所有模型的特征分数。具有最大得分的说话人模型被预测为测试语音的被识别的说话人。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/c983d3a93d7b0e117c1e051628c8843f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gP7k3cwDwpIv-PIS"/></div></div></figure><blockquote class="lb lc ld"><p id="938c" class="jt ju le jv b jw kt jy jz ka ku kc kd lf kv kf kg lg kw ki kj lh kx kl km kn hb bi translated">您可以在下面资源库中查看代码库，</p></blockquote><div class="li lj ez fb lk ll"><a href="https://github.com/VaibhavBhapkar/Speaker-Identification-Using-Machine-Learning" rel="noopener  ugc nofollow" target="_blank"><div class="lm ab dw"><div class="ln ab lo cl cj lp"><h2 class="bd hj fi z dy lq ea eb lr ed ef hh bi translated">VaibhavBhapkar/使用机器学习的说话人识别</h2><div class="ls l"><h3 class="bd b fi z dy lq ea eb lr ed ef dx translated">按照下面的步骤执行这个项目，下载存储库。执行SpeakerIdentification.py文件。安装…</h3></div><div class="lt l"><p class="bd b fp z dy lq ea eb lr ed ef dx translated">github.com</p></div></div><div class="lu l"><div class="lv l lw lx ly lu lz io ll"/></div></div></a></div><p id="2b3c" class="pw-post-body-paragraph jt ju hi jv b jw kt jy jz ka ku kc kd jg kv kf kg jk kw ki kj jo kx kl km kn hb bi translated">谢谢大家！！</p><blockquote class="lb lc ld"><p id="6342" class="jt ju le jv b jw kt jy jz ka ku kc kd lf kv kf kg lg kw ki kj lh kx kl km kn hb bi translated">你可以在这里联系我，</p><p id="659e" class="jt ju le jv b jw kt jy jz ka ku kc kd lf kv kf kg lg kw ki kj lh kx kl km kn hb bi translated">领英:<a class="ae iu" href="https://www.linkedin.com/in/vaibhav-bhapkar" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/vaibhav-bhapkar</a></p><p id="4f08" class="jt ju le jv b jw kt jy jz ka ku kc kd lf kv kf kg lg kw ki kj lh kx kl km kn hb bi translated">电子邮件:vaibhavbhapkar.medium@gmail.com</p></blockquote></div></div>    
</body>
</html>