<html>
<head>
<title>Jigsaw Unintended Bias Toxic Comment Classification.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">拼图无意偏见有毒评论分类。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/jigsaw-unintended-bias-toxic-comment-classification-fa68fe3a27c8?source=collection_archive---------9-----------------------#2019-09-27">https://medium.com/analytics-vidhya/jigsaw-unintended-bias-toxic-comment-classification-fa68fe3a27c8?source=collection_archive---------9-----------------------#2019-09-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="969c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我将总结我自己和通过阅读kaggle上其他人的笔记本来解决问题的方法，这个问题是由对话人工智能团队(由<a class="ae jd" href="https://jigsaw.google.com/" rel="noopener ugc nofollow" target="_blank"> Jigsaw </a>和谷歌创立的一个研究项目)放到kaggle上的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/a98cc02980a65a6111371d7e9b744e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHr-cn3ups2J7Lbyck6TWg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">取自Kaggle</figcaption></figure><h1 id="a8ea" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">问题陈述:</h1><p id="60a7" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">目标是检测有害评论并减少模型的非预期偏差。</p><h1 id="48a4" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">背景:</h1><p id="0df1" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在这次比赛之前，Jigsaw在前一年也举办过一次比赛，目的是检测有毒的评论。他们建立的模型错误地学会了将毒性与一些<strong class="ih hj">身份词汇</strong>联系起来，例如<strong class="ih hj">(同性恋、黑人、家庭性等。)</strong>。因此，它会将诸如“我是同性恋女性”这样的句子归类为有毒评论。<strong class="ih hj">因此，本次比赛的目的是减少对身份词的偏见。</strong></p><h1 id="5c3c" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">数据集概述:</strong></h1><p id="f2cf" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">Jigsaw提供的数据集很大，有180万条评论。数据集包含45列，但其中只有几列对我们有用。“comment_text”列包含评论,“target”列显示评论的毒性。这是我们的模型在测试时应该预测的值。值≥0.5表示评论有毒(阳性)。</p><p id="6ec1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其他感兴趣的列是<strong class="ih hj"> 9个身份列(子组)</strong>，即<strong class="ih hj">‘男性’、‘女性’、‘黑人’、‘基督徒’、‘犹太人’、‘穆斯林’、‘白人’、‘精神病患者’或‘精神病患者’、‘同性恋者’或‘同性恋者’</strong>。我们将使用这些列来提高模型的性能。在这篇博客的后面部分，你会了解到这一点。</p><p id="66e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集非常不平衡，大约8%的点属于第1类(有毒评论)，92%属于第0类(无毒评论)。</p><h1 id="438d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">评估指标:</h1><p id="526b" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在这种情况下，我们得到了一个定制的指标，旨在克服模型的意外偏差。这个新度量是各种子度量的加权组合。我将在下面定义每一个。</p><p id="1d95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">总体AUC: </strong>这是将在整个测试数据集上计算的roc-auc。</p><p id="06c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">偏倚AUC: </strong>现在我们将再次计算roc-auc以对抗模型的偏倚。我们将计算以下三个测试数据集子集的roc-auc，每个子集捕获非预期偏倚的不同方面。</p><ol class=""><li id="d381" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated"><strong class="ih hj"> <em class="lg">亚组auc </em> </strong>:我们将计算每个亚组的auc(标识列)。auc值低意味着如果评论包含身份词，模型会混淆。</li><li id="62f8" class="kx ky hi ih b ii lh im li iq lj iu lk iy ll jc lc ld le lf bi translated"><strong class="ih hj"> <em class="lg">背景阳性&amp;亚组阴性(bpsn) </em> </strong>:这里我们将计算测试集的auc，其中毒性评论未提及身份，而无毒评论提及身份。低auc将意味着模型混淆了不提及身份的毒性评论和提及身份的非毒性评论。</li><li id="326c" class="kx ky hi ih b ii lh im li iq lj iu lk iy ll jc lc ld le lf bi translated"><strong class="ih hj"> <em class="lg">背景阴性&amp;亚组阳性(bnsp) </em> </strong>:这里我们将计算提及身份的毒性评论和未提及身份的无毒评论的测试集的auc。较低的auc意味着模型混淆了提及身份的毒性评论和未提及身份的无毒评论。</li></ol><p id="5183" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将合并三个有偏差的AUC，并按如下方式计算它们的平均值。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lm"><img src="../Images/ffa47574481dddd40cd6906967ce19c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GEVCY5VKTKrRTuUJLeI03Q.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">取自卡格尔。</figcaption></figure><p id="76da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这次比赛中，p取-5。选择这个p值是为了提高模型对于性能较差的身份子群的性能。<strong class="ih hj">为了理解这种说法，让我们看看下面的例子</strong>。</p><p id="52fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们选取auc为0.95、0.98、0.97和0.70的四个亚组。如果我们取简单平均值，我们将得到0.90的值，这给了我们一个错误的印象，即我们的模型表现良好，但当我们使用上述方法计算平均值时，我们得到0.84的值。因此，我们可以看到，如果一个或多个子组表现不佳，我们的指标会给出较低的auc。</p><p id="c32e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们来看看如何计算最终指标<strong class="ih hj"/>。下面是公式。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ln"><img src="../Images/00ac766709178b5b6cec93d97aa118b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*Ra233ArKoNxIORhX5myo5g.jpeg"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">取自kaggle</figcaption></figure><p id="86bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据清理</strong>:我们<strong class="ih hj">从文本数据<strong class="ih hj">中去掉了<strong class="ih hj">所有的</strong>和<strong class="ih hj">停用词</strong>除了<strong class="ih hj">辱骂词</strong>的</strong>如<strong class="ih hj">符*k </strong>、<strong class="ih hj">迪*k </strong>、<strong class="ih hj">蒲**y </strong>等。</strong></p><h1 id="3e22" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">方法:</h1><ol class=""><li id="c226" class="kx ky hi ih b ii ks im kt iq lo iu lp iy lq jc lc ld le lf bi translated"><strong class="ih hj">使用经典机器学习:</strong>在我们的第一种方法中，我们使用了<strong class="ih hj">逻辑</strong> <strong class="ih hj">回归</strong>，并且我们在私有排行榜上获得了<strong class="ih hj">分数</strong>为<strong class="ih hj"> 0.89 </strong>。我们已经使用<strong class="ih hj"> tf-idf </strong>对我们的数据进行了矢量化，以训练我们的模型。然后我们尝试了其他模式，如<strong class="ih hj">天真巴爷的</strong>，但我们的分数没有提高。因此，我们没有在解决方案中保留这一点。我们也尝试将<strong class="ih hj"> char grams </strong>与tf-idf结合使用，但是我们的分数并没有提高。</li><li id="63f9" class="kx ky hi ih b ii lh im li iq lj iu lk iy ll jc lc ld le lf bi translated"><strong class="ih hj">使用深度学习</strong>:在使用机器学习模型后，我们尝试了深度学习模型来提高我们的分数。首先，我们使用<strong class="ih hj">爬行300d </strong>和<strong class="ih hj">手套</strong> <strong class="ih hj"> 100d </strong>作为我们的嵌入来训练所有的深度学习模型。我们从LSTMs开始，但我们的分数徘徊在0.50到0.51之间。如果你想了解LSTMs是如何工作的，那么我建议你去看看Christopher Ola的博客。这表明我们的模型表现得像一个随机模型。然后，我们训练了bi-lstm的各种架构和变体，给出最佳分数0.93309的架构如下所述。</li></ol><p id="e0b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一层是嵌入层，然后是0.2的空间落差。然后我们有两层128个单元的双LSTMs，一个接一个。我们对输出分别应用<strong class="ih hj">关注层</strong>和<strong class="ih hj">全局最大值</strong> <strong class="ih hj">池层</strong>。然后，我们将这两层串联起来，并在此基础上使用了两层完全密集连接的层，其中包括跳跃连接。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/d071c51a3e2d95e99550fecd352ef1cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*44wqA6tUWCMgwBgBVXz0ZA.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">最终建筑</figcaption></figure><p id="413d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以通过使用<strong class="ih hj"> keras.layers.add. </strong>跳过连接。这可以通过添加前一层的输出和密集层的输出来实现。这个密集层将前一层的输出作为输入。当网络很深时，这有助于改善梯度的流动。</p><p id="e279" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">提高我们分数的最重要的事情是给每个数据点加权。现在在这里你要注意把握这一点。现在我将解释我是如何给一个数据点分配权重的。所有数据点最初都被赋予0.25的权重。如果一个数据点属于任何一个子组(9个身份组)，那么它被分配一个额外的权重0.25。如果数据点属于bpsn组或bnsp组，则分配0.25的额外权重。该权重用于计算损失，计算损失时，损失乘以数据点的权重。在使用这些重量之前，我的得分是0.92。使用这种方法后，分数提高到0.93309。</p><p id="70ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以查看我的github账号了解更多细节和更好的理解。Github链接:<a class="ae jd" href="https://github.com/riteshranjan110/Jigsaw-Unintended-Bias-Toxic-Comment-Classification/blob/master/Jigsaw4.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/riteshranjan 110/Jigsaw-Unintended-Bias-Toxic-Comment-class ification/blob/master/Jigsaw 4 . ipynb</a></p></div></div>    
</body>
</html>