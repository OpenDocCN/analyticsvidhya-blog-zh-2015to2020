<html>
<head>
<title>Style Transfer with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习中的风格转移</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/styletransfer-3a74c2cb1202?source=collection_archive---------10-----------------------#2019-11-15">https://medium.com/analytics-vidhya/styletransfer-3a74c2cb1202?source=collection_archive---------10-----------------------#2019-11-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="24bf" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">用Pytorch实现</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/72f22f2a4e961a7f4ea5a0d4915bc14b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QIS7Y945yC2Q38H0qzCgxw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://github.com/Nielspace/AI-From-Scratch/blob/master/Transfer%20Learning/02_Transfer_Learning_with_pytorch.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jo">风格转移与深度学习</strong> </a></figcaption></figure><p id="a530" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我们大多数人都非常熟悉编辑软件，比如Adobe Photoshop、Coral draw等等。这些软件在编辑图片方面做得很好，特别是混合各种背景和一次呈现一幅图像。许多艰苦的工作都是为了制作这样的软件。</p><p id="ee46" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">但是如果我们可以用深度学习做同样的事情呢？</p><p id="71bd" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">问题的答案是肯定的！我们能做到。我们所需要的是一个<strong class="jr hj">稳定的编码背景</strong>，有点像对<strong class="jr hj">线性代数</strong>的中级和基本理解，以及一些<strong class="jr hj">研究论文</strong>，它们会帮助你达到你的目标。</p><p id="fc8b" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我们将使用的深度学习技术被称为<strong class="jr hj">迁移学习。</strong></p><h2 id="2846" class="kl km hi bd jo kn ko kp kq kr ks kt ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">这是什么？</h2><p id="e6d4" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">迁移学习是一种机器学习技术，我们使用现有的训练模型来满足我们的需求。这就像借朋友的车来完成你的工作。</p><h1 id="78be" class="lk km hi bd jo ll lm ln kq lo lp lq ku io lr ip kx ir ls is la iu lt iv ld lu bi translated">为什么？</h1><p id="a921" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">因为种种原因:</p><ol class=""><li id="1d3f" class="lv lw hi jr b js jt jv jw jy lx kc ly kg lz kk ma mb mc md bi translated">如果我们不能在大量的试验和错误之后为我们的特定需求产生一个好的模型。</li><li id="9d0e" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">我们希望a开发一个快速模型，将满足我们的要求。</li><li id="d4f7" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">如果我们特定需求的模型已经存在，我们需要做的就是获得所需的数据，并用这些数据训练模型。<strong class="jr hj">我们不想再重新发明轮子</strong>。</li></ol><p id="c16d" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">这种方法广泛用于:</p><ol class=""><li id="9be6" class="lv lw hi jr b js jt jv jw jy lx kc ly kg lz kk ma mb mc md bi translated">计算机视觉</li><li id="db0e" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">自然语言处理</li></ol><blockquote class="mj mk ml"><p id="bf92" class="jp jq mm jr b js jt ij ju jv jw im jx mn jz ka kb mo kd ke kf mp kh ki kj kk hb bi translated">我的工作是让这篇文章尽可能简单，让你能够理解。</p></blockquote><h1 id="5295" class="lk km hi bd jo ll lm ln kq lo lp lq ku io lr ip kx ir ls is la iu lt iv ld lu bi translated">获得研究论文</h1><p id="1b61" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">我们的第一个要求是找到一篇研究论文。现在，找到一篇研究论文是一件乏味的工作，我们必须非常耐心才能找到。确保您在搜索引擎中输入了准确的关键字，并浏览显示给您的结果。</p><p id="2c54" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">arxiv.org是你可以免费找到研究论文的最好的网站之一。一个好的经验法则是下载并收集一堆随机的pdf文件，然后浏览所有的文件。寻找对主题有透彻解释的论文。还有一个附带说明是在一张纸上记下要点，复制粘贴，甚至截屏保存你认为有价值的信息。</p><p id="5c4a" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">需要注意的一点是，研究论文总是会驱使你去搜索你第一次遇到的关键词。因此，一个建议是有一个分屏，这将有助于你轻松地浏览不同的窗口。</p><p id="f474" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我将使用的研究论文将是使用卷积神经网络  <strong class="jr hj">的<a class="ae jn" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jr hj">图像风格转换。</strong>您可以点击链接为自己下载。它是开源的。</a></strong></p><p id="1331" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">接下来读<strong class="jr hj">摘要</strong>然后是<strong class="jr hj">结论。我知道这听起来很奇怪，但事实就是如此。你不会想把你的时间浪费在这篇论文上，因为它没有提供你所寻找的主题的具体细节或答案。</strong></p><p id="be4b" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">一旦你完成了同样的浏览整篇论文，突出你遇到的值得注意的关键词和公式。</p><blockquote class="mj mk ml"><p id="0fc2" class="jp jq mm jr b js jt ij ju jv jw im jx mn jz ka kb mo kd ke kf mp kh ki kj kk hb bi translated">不要担心你无法处理的信息。一旦你开始写代码，你几乎会看到和观察到你略读时漏掉的小细节。</p></blockquote><p id="c59a" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">一旦完成，我们可以开始我们的编码。但在此之前，我们应该知道什么是深度学习的<em class="mm">风格迁移</em>。</p><h1 id="d7be" class="lk km hi bd jo ll lm ln kq lo lp lq ku io lr ip kx ir ls is la iu lt iv ld lu bi translated">深度学习中的风格转移</h1><p id="f41b" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">我在上面提到的论文中概述的风格转换方法。</p><p id="f517" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我将尝试分解每一个步骤，以获得更直观的知识。我将向你展示如何将一篇论文分解成基本的组成部分。</p><blockquote class="mj mk ml"><p id="3a1e" class="jp jq mm jr b js jt ij ju jv jw im jx mn jz ka kb mo kd ke kf mp kh ki kj kk hb bi translated">我们的方法是修改CNN的架构。</p></blockquote><h2 id="6ea1" class="kl km hi bd jo kn ko kp kq kr ks kt ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">那么什么是风格转移呢？</h2><p id="49e2" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">风格转移是一种通过采用其他图像的风格来修改图片的方法。我们已经在photoshop、coral等软件中使用了这种技术。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/489f6c3dff6a4b87ace670a776219a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L6phcpYgWeKGMK3da9tV7A.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">内容图片(左)；风格图像(中间)；目标图像(右)</figcaption></figure><p id="70e5" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">这个项目背后的想法和灵感是使用神经网络从风格图像中捕捉一些次要细节，并将其部署在原始图像上。</p><p id="aac4" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">为此，我们使用卷积神经网络。为什么？因为，CNN包含多个层，每个层都像一个过滤器，允许我们提取最终结果或渲染所需的特征。</p><p id="c704" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我将使用预先训练好的VGG19 Net从传入的图像中提取内容或样式特征。然后形式化内容和风格损失的概念，并使用它们迭代更新我们的目标图像，直到我们得到我们想要的结果。</p><h1 id="dd95" class="lk km hi bd jo ll lm ln kq lo lp lq ku io lr ip kx ir ls is la iu lt iv ld lu bi translated">让我们编码</h1><p id="e81e" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">重要的事情先来。确保您的环境已准备就绪。</p><p id="c8dd" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我将使用google colab进行代码编辑——因为它给了我一个GPU选项，可以更快地渲染代码。</p><h2 id="1d5b" class="kl km hi bd jo kn ko kp kq kr ks kt ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">进口</h2><p id="efb5" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">我们将导入依赖项。由于我们将使用pytorch作为基本库，我们需要pip安装torch和torchvision，然后将其导入到我们的笔记本中。</p><p id="9fd7" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我们将从torchvision.models导入我们的vgg19 CNN模型。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mr"><img src="../Images/93cd7ed99026895247ec0576f8526ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ks3L7m3MeKZ5FwqadtR5BA.png"/></div></div></figure><p id="cbbf" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">VGG19分为两部分:</p><ul class=""><li id="5ff7" class="lv lw hi jr b js jt jv jw jy lx kc ly kg lz kk ms mb mc md bi translated">vgg19.features —指所有卷积层和池层</li><li id="dd42" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ms mb mc md bi translated">vgg19 .分类器——线性层:<strong class="jr hj">密集线性层</strong></li></ul><p id="c33a" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我们将只使用特征，以便我们可以提取造型细节和<strong class="jr hj">使我的方式来优化输出图像</strong>。正因为如此，我们没有使用线性层。我们的想法是，我们将优化输出图像，这也导致我们冻结所有层的优化。</p><p id="23f7" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><em class="mm">注意:由于上述原因，我们不会优化任何参数。</em></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mt"><img src="../Images/c624cbe1a3f2e5b1bba8d35225794c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_SFgzY8d7CWhHfxCM62VHw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jo">利用卷积神经网络进行图像风格转移</strong> </a></figcaption></figure><p id="7967" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">上图告诉我们，内容图像，<em class="mm">a</em>——将被修改的图像——和样式图像，<em class="mm">p</em>——将用于样式化内容图像——将通过CNN传递，在我们的例子中是VGG19。CNN将从这些图像中过滤出模式，然后使用一个空图像来呈现它在处理这两个图像时找到的模式。</p><blockquote class="mu"><p id="4ff6" class="mv mw hi bd mx my mz na nb nc nd kk dx translated">想象一下，一个画家在一张空白的画布上画出他眼前的风景作为参考，并添加了画笔的笔触和颜色。</p></blockquote><h2 id="cf20" class="kl km hi bd jo kn ne kp kq kr nf kt ku jy ng kw kx kc nh kz la kg ni lc ld le bi translated">制作助手功能</h2><p id="6790" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">然后，我们将编写一个函数来加载图像。该函数将把像素值转换成张量，然后可以将该张量馈送到网络中，或者在馈送到网络中之前进行任何其他操作。</p><p id="b2cf" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">在制作一个函数时，我们必须记住所有的图像应该有相同的尺寸。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nj"><img src="../Images/71ef1d88399ee8449e71d795844979b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J5-LeGkwUb9pQKU9AJSa1A.png"/></div></div></figure><p id="6364" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我们还应该注意到，我们必须对图像进行标准化。在将像素值输入网络或任何其他操作之前，在两个值的范围之间转换像素值。</p><p id="eed8" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">接下来，我们将形象化。</p><p id="8384" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我们也将创建一个函数来做这件事。现在，当我们使用matplotlib进行任何可视化时，我们必须记住它只对numpy数组有效。如果您的数据不是numpy数组，那么它将引发一个错误。</p><p id="50be" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">此外，如果图像的形状不是(宽度*高度*通道)，它将再次引发错误。为了达到要求的格式，我们可以使用转置函数。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/2b0e1973f2274693fae2f29f6e0f7523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2tT5hQ_yw9Uu0hXtvT1Ueg.png"/></div></div></figure><h2 id="1ceb" class="kl km hi bd jo kn ko kp kq kr ks kt ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">抓住内容和风格特征</h2><p id="61ea" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">根据这篇论文，我们必须隔离某些层来表现内容和风格。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nl"><img src="../Images/7748f3b1ad682bf644421d1c1986be32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AdxmPWP36ZL7UymbABboMw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jo">利用卷积神经网络进行图像风格转移</strong> </a></figcaption></figure><p id="5685" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">内容表示将在“<em class="mm"> conv4_2 </em>上合成，而风格表示将在<em class="mm"> conv1_1、conv2_1、conv3_1、conv4_1 </em>和<em class="mm"> conv5_1上合成。</em></p><p id="2b6c" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">为了找到CNN模型中的所有层，我们可以使用for循环来遍历这些层，或者我们可以只打印vgg19存储的变量。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nm"><img src="../Images/2c87f8d73b8763179c464556b702f834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AkRGulk2iuSJMYFjh2OZyQ.png"/></div></div></figure><p id="e73a" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">一旦我们得到了输出，我们就可以为内容和风格表现制作函数，为我们合成图像。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nn"><img src="../Images/e67af4469544630ad3748099f52241d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMpKC8kEbTw_c4F96BZmIg.png"/></div></div></figure><p id="83ca" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">特征功能的工作是将图像传递到特别选择的CNN层，而保持其余部分不变。</p><h2 id="09ef" class="kl km hi bd jo kn ko kp kq kr ks kt ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">格拉姆矩阵</h2><p id="6a9d" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">Gram矩阵或gramian矩阵是内积空间中的一组向量{ <em class="mm"> v1，v2，v3，v4，vn </em> }，其项由<em class="mm"> Gij = &lt; vi，VJ&gt;T3】给出。</em></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es no"><img src="../Images/4c92ce16a6e6135c60fa9d1c4e5a97ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*e9LeXKlog5f3D0-ATi45Qg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jo">利用卷积神经网络进行图像风格转移</strong> </a></figcaption></figure><p id="932c" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">这告诉我们它是一个<em class="mm"> v </em>的方阵。即。我们可以计算出<em class="mm"> v*v.T </em></p><p id="b345" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">gramian的一个重要应用是计算线性无关性:一组向量线性无关当且仅当Gram行列式(Gram矩阵的行列式)非零。换句话说，grammian有助于发现CNN中不同滤波器之间的相关性。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es np"><img src="../Images/dfe8e59e7f8407303e8d1372ee6e54d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KHQ_rim1Oz18EtjRkf8fpw.png"/></div></div></figure><blockquote class="mj mk ml"><p id="9c09" class="jp jq mm jr b js jt ij ju jv jw im jx mn jz ka kb mo kd ke kf mp kh ki kj kk hb bi translated">获得风格损失的最佳方法是测量gram矩阵。</p></blockquote><h2 id="a74f" class="kl km hi bd jo kn ko kp kq kr ks kt ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">优化和权重</h2><p id="be8b" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">优化就是通过减少<em class="mm">误差</em>和增加<em class="mm">精度</em>来改进模型。阅读我最近写的文章<a class="ae jn" rel="noopener" href="/analytics-vidhya/understanding-gradient-descent-8dd88a4c60e6"> <strong class="jr hj">了解梯度下降</strong> </a>中优化的详细版本。</p><p id="1a4c" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我们还为我们选择的每个风格层初始化了随机权重，这些权重将被运算到目标和特征图矩阵的均方误差中。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nq"><img src="../Images/929450b37150a5b169c8bbcecb477ada.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ZoXuvH-nRZEoTPCEYDcGA.png"/></div></div></figure><p id="a6dc" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">一旦我们完成了所有要求的编码，我们就可以进入最后一部分，即。使用for循环进行优化。</p><p id="f648" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">但是在我们把所有东西放入循环之前，我们必须初始化我们将使用的优化器，在我们的例子中，Adam和我们将优化目标图像或空白画布。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nr"><img src="../Images/01537714122ae6e4315bf74e3d2f307c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*78vjoyOs0j6X0SUh7sIvzQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jo">利用卷积神经网络进行图像风格转移</strong> </a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ns"><img src="../Images/91aaf73ccdca10f06994d867d570b1ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qa6aMHynilW3lDWcPMwgvA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jo">利用卷积神经网络进行图像风格转移</strong> </a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nt"><img src="../Images/6f213eddb3e692bd4ac6f63742ea1bbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b_KJ5X41DpeitIRQUsRbWQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jo">利用卷积神经网络进行图像风格转移</strong> </a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nr"><img src="../Images/a0f8aae4b4371dd88629f2344cdc3109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WEkeGAHIoPaHFmjCEd-RWQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jo">利用卷积神经网络进行图像风格转移</strong> </a></figcaption></figure><p id="f1a4" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">一旦我们定义了所有内容，我们就可以开始for循环，并将所有损失计算放入其中，包括:</p><ol class=""><li id="748f" class="lv lw hi jr b js jt jv jw jy lx kc ly kg lz kk ma mb mc md bi translated">内容损失</li><li id="f447" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">风格丧失</li><li id="16c6" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">全损</li></ol><blockquote class="mj mk ml"><p id="01eb" class="jp jq mm jr b js jt ij ju jv jw im jx mn jz ka kb mo kd ke kf mp kh ki kj kk hb bi translated">我们将使用文中提到的L2范数或均方误差。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nu"><img src="../Images/c4c550241ec18c379f00d64ec700050d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LvIFr0DME4nhuvbjMoF4cg.png"/></div></div></figure><p id="8319" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">总损失将包含我们定义的α和β以及权重。这些alpha和beta是决定内容和样式图像混合以获得输出图像的权重因子。</p><p id="6d3a" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">下面是我制作的一些图片:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nv"><img src="../Images/e51213368caf72a2f7c09482cabbe79f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fCn2giS-9003tGdvO1rSMA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">阿尔法=1，贝塔=1e3，纪元=1000</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nw"><img src="../Images/3b34e7a73b7862772a24ac48622e32e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A8wVNDRhSliKiym7fzwSHA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">阿尔法=1，贝塔=1e6，纪元=1000</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/72f22f2a4e961a7f4ea5a0d4915bc14b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QIS7Y945yC2Q38H0qzCgxw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">阿尔法=1，贝塔=1e10，纪元=2000</figcaption></figure><h1 id="925e" class="lk km hi bd jo ll lm ln kq lo lp lq ku io lr ip kx ir ls is la iu lt iv ld lu bi translated">结论</h1><p id="80d1" class="pw-post-body-paragraph jp jq hi jr b js lf ij ju jv lg im jx jy lh ka kb kc li ke kf kg lj ki kj kk hb bi translated">本质上我们已经看到:</p><ol class=""><li id="d246" class="lv lw hi jr b js jt jv jw jy lx kc ly kg lz kk ma mb mc md bi translated">我们如何阅读一篇论文，并记下重要而有价值的信息。</li><li id="0117" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">理解概念和图表，特别是解释和绘制我们的过程。</li><li id="4cd4" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">一步一步地执行函数以及精心编写的公式。</li><li id="e362" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">使用for循环优化模型。</li><li id="75e8" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">最后，要有耐心。</li></ol><h1 id="530f" class="lk km hi bd jo ll lm ln kq lo lp lq ku io lr ip kx ir ls is la iu lt iv ld lu bi translated">读物</h1><ol class=""><li id="1b7d" class="lv lw hi jr b js lf jv lg jy nx kc ny kg nz kk ma mb mc md bi translated"><a class="ae jn" href="https://arxiv.org/abs/1703.07511" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1703.07511</a></li><li id="4f75" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated"><a class="ae jn" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">使用卷积神经网络的图像风格转换</a></li><li id="70ce" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated"><a class="ae jn" href="https://arxiv.org/abs/1603.08155" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1603.08155</a></li><li id="3d38" class="lv lw hi jr b js me jv mf jy mg kc mh kg mi kk ma mb mc md bi translated">用GitHub中的深度学习 检查我的代码<a class="ae jn" href="https://github.com/Nielspace/AI-From-Scratch/blob/master/Transfer%20Learning/02_Transfer_Learning_with_pytorch.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="jr hj">风格转移。</strong></a></li></ol></div></div>    
</body>
</html>