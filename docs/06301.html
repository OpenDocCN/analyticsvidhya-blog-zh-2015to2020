<html>
<head>
<title>A guide to the object detection exercise using YOLO model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用YOLO模型的目标探测练习指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-guide-to-the-object-detection-exercise-using-yolo-model-c551f65df637?source=collection_archive---------24-----------------------#2020-05-17">https://medium.com/analytics-vidhya/a-guide-to-the-object-detection-exercise-using-yolo-model-c551f65df637?source=collection_archive---------24-----------------------#2020-05-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/fb6904828697b107c5039135e1563174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ivhk4q4u8gCvsX7sFy3FsQ.png"/></div></div></figure><p id="defd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">目标检测是计算机视觉领域中的一项新兴技术，它使我们能够检测和识别图像或视频中的目标。对象检测可用于计算场景中的对象，并使用定位方法跟踪它们的精确位置。</p><p id="fce0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是对象检测视频示例的链接:</p><p id="f1a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://www.youtube.com/watch?v=A5r1jp4t8u8" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=A5r1jp4t8u8</a></p><p id="bbc0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">深度学习如何帮助建立一个健壮的计算机视觉框架？</strong></p><p id="6ff5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">与其他计算机视觉任务一样，深度学习已被证明是在人工智能世界中执行对象检测的一种示范性方法。在本文中，我将尝试展示图像分类和定位的结合，它不仅检测对象的类别，还检测给定图像的相应位置。</p><p id="03ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在进入检测阶段之前，让我们深入研究一下模型架构。</p><p id="1748" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">什么是YOLO模式？</strong></p><p id="fe92" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“你只看一次”(YOLO)是一种流行的算法，因为它实现了高精度，同时还能够实时运行。这种算法“只看一次”图像，因为它只需要一次通过网络的前向传播来进行预测。在非最大值抑制之后，它会将识别的对象与边界框一起输出。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jp"><img src="../Images/6972c7eeda5f8e604b0b6f019b2b9ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TvEd3pNCKe2KBK-p.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">来源:<a class="ae jo" href="https://arxiv.org/pdf/1506.02640v5.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.02640v5.pdf</a></figcaption></figure><p id="8608" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上图中，检测网络有24个卷积层，后面是2个全连接层。交替的1 × 1卷积层减少了来自前面层的特征空间。ImageNet分类任务中的相关卷积层以一半的分辨率(224 × 224输入图像)执行，然后以两倍的分辨率进行检测。</p><h1 id="2e81" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">输入和输出</h1><ul class=""><li id="f375" class="kw kx hi is b it ky ix kz jb la jf lb jj lc jn ld le lf lg bi translated"><strong class="is hj">输入</strong>是一批图像，每个图像的形状为(m，608，608，3)</li><li id="363b" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj">输出</strong>是一个包含已识别类的边界框列表。如上所述，每个边界框由6个数字(pc，bx，by，bh，bw，c)表示。如果你把c展开成一个80维的向量，那么每个边界框由85个数字表示。变量c表示模型将用于检测目的的类的数量。(例如汽车、卡车、交通灯等。)</li></ul><p id="7d86" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于该模型使用5个锚盒，因此19个x19单元中的每一个编码了关于5个盒的信息。锚定框仅由其宽度和高度定义。</p><p id="79d4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为简单起见，该模型展平了形状(19，19，5，85)编码的最后两个维度。所以深度CNN的输出是(19，19，425)。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/6d219f5c3a841cfc4858faa40c690bcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/0*TXHzLA20ZmowCLjh.jpeg"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">来源:<a class="ae jo" href="https://www.coursera.org/" rel="noopener ugc nofollow" target="_blank">https://www.coursera.org/</a></figcaption></figure><h1 id="a97e" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">非最大抑制</h1><p id="a324" class="pw-post-body-paragraph iq ir hi is b it ky iv iw ix kz iz ja jb ln jd je jf lo jh ji jj lp jl jm jn hb bi translated">在上图中，边界框绘制在那些模型分配了高概率的对象上，但这仍然是太多的框。您希望将算法的输出减少到更少的检测到的对象数量。</p><p id="4639" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，您将使用<strong class="is hj">非最大抑制</strong>。具体来说，您将执行以下步骤:</p><ul class=""><li id="eca5" class="kw kx hi is b it iu ix iy jb lq jf lr jj ls jn ld le lf lg bi translated">去掉分数低的盒子(意思是，盒子对检测一个类不是很有信心；或者由于任何对象的低概率，或者这个特定类的低概率)。</li><li id="f5ae" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">当几个框相互重叠并检测同一对象时，仅选择一个框。</li></ul><p id="7dda" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了移除那些重叠的盒子，模型将使用一种叫做<strong class="is hj">的技术。这种技术可以使用称为IoU的评估指标来实现，IoU用于测量特定数据集上的对象检测器的精度。</strong></p><p id="b2b8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> IoU: </strong>这个验证度量对于确定地面实况框和预测框之间的交集和并集面积的比率很有用。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/8737efb6ceac047567b87024a1e416cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/0*EQiZYUScv9RCl6gG.jpeg"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">借据计算(来源:<a class="ae jo" href="https://www.coursera.org/" rel="noopener ugc nofollow" target="_blank">https://www.coursera.org/</a>)</figcaption></figure><p id="c557" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上图中，B1和B2是用于计算精度度量的预测和基本事实框。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/b207f8a0f037bac5178c5598de4fc8e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/0*v0vIvxeXSKdlgUz1.jpeg"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">来源:<a class="ae jo" href="https://www.coursera.org/" rel="noopener ugc nofollow" target="_blank">https://www.coursera.org/</a></figcaption></figure><p id="d0c5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总而言之，对YOLO的总结看起来是这样的:</p><ul class=""><li id="98d0" class="kw kx hi is b it iu ix iy jb lq jf lr jj ls jn ld le lf lg bi translated">输入图像(608，608，3)</li><li id="33d1" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">输入图像通过CNN，产生(19，19，5，85)维输出。</li><li id="cd31" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">展平最后两个维度后，输出是一个体积形状(19，19，425):</li><li id="eae8" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">输入图像上19x19网格中的每个单元格给出425个数字。</li><li id="b91b" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">425 = 5 x 85，因为每个单元格包含5个框的预测，对应于5个锚框，如讲座中所示。</li><li id="98ca" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">85 =图像数组中的5 + 80，其中5表示(pc，bx，by，bh，bw)，80是我们想要检测的类的数量</li><li id="e4d4" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">然后，根据以下条件选择几个框:</li><li id="fa76" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">分数阈值:丢弃检测到分数低于阈值的类的盒子</li><li id="a8c3" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">非最大抑制:计算并集上的交集，避免选择重叠的框</li><li id="658c" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">这给了你YOLO的最终输出。</li></ul><p id="53d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">预测:</strong></p><p id="5905" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多个类对象的检测:</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/448c0a0fe9e6329fed22e72ee6035915.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_rLWe1RSD3qhFIYGqHlmog.png"/></div></div></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/21bb810e910ad9bbb19a1d3ef72b39cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/0*HTpDnMQ7Nce3cIvt.jpeg"/></div></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/e63c44ba27f2c7e3e0d4b9cc9ba55ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/0*s1YIo8GOpYJb-7jR.jpeg"/></div></figure><p id="992a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">未来改进:</strong></p><p id="0dad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1)使用YOLO模型的更新版本，这可能会解决在此练习中注意到的一些检测问题。</p><p id="2d22" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2)在移动对象上实现相同的模型，或者使用视频文件代替静态图像。</p><p id="9a4d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3)使用不同组的图像来训练YOLO模型，而不是加载预先训练的模型。添加新的类以增加对象分类器的范围。</p><p id="6259" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">参考文献:</strong></p><ul class=""><li id="74bc" class="kw kx hi is b it iu ix iy jb lq jf lr jj ls jn ld le lf lg bi translated">约瑟夫·雷德蒙、桑托什·迪夫瓦拉、罗斯·吉斯克、阿里·法尔哈迪— <a class="ae jo" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">你只看一次:统一的实时物体检测</a> (2015)</li><li id="5cc4" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">约瑟夫·雷德蒙，阿里·法尔哈迪——<a class="ae jo" href="https://arxiv.org/abs/1612.08242" rel="noopener ugc nofollow" target="_blank">yolo 9000:更好、更快、更强</a> (2016)</li><li id="6668" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">艾伦·泽伦纳— <a class="ae jo" href="https://github.com/allanzelener/YAD2K" rel="noopener ugc nofollow" target="_blank"> YAD2K:又一个黑暗网络2 Keras </a></li><li id="3cf2" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">https://pjreddie.com/darknet/yolo/ YOLO官方网站(<a class="ae jo" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank"/>)</li><li id="8c76" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><a class="ae jo" href="https://www.tensorflow.org/datasets/catalog/rock_paper_scissors" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/datasets/catalog/rock _ paper _ scissors</a></li><li id="48df" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><a class="ae jo" href="https://www.tensorflow.org/tutorials/images/classification" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tutorials/images/classification</a></li><li id="e619" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><a class="ae jo" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.02640</a></li></ul><p id="1a70" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">汽车检测数据集</strong>:</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/3482337e48660310d6428c65f11d2799.png" data-original-src="https://miro.medium.com/v2/resize:fit:176/format:webp/0*91SfrEKRGNjdRIZK.png"/></div></figure><p id="f005" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Drive.ai样本数据集(由drive.ai提供)获得了<a class="ae jo" href="http://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享署名4.0国际许可</a>的许可。我们感谢Brody Huval、Chih Hu和Rahul Patel提供这些数据。</p><p id="cfad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">GitHub链接到源代码和测试图片:</p><div class="lx ly ez fb lz ma"><a href="https://github.com/soudey123/Autonomous-car-detection-using-YOLO-model" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab dw"><div class="mc ab md cl cj me"><h2 class="bd hj fi z dy mf ea eb mg ed ef hh bi translated">GitHub-soudey 123/自动汽车检测-使用YOLO模型</h2><div class="mh l"><h3 class="bd b fi z dy mf ea eb mg ed ef dx translated">要记住的事情:YOLO是一个艺术级的物体检测模型，它运行一个输入图像…</h3></div><div class="mi l"><p class="bd b fp z dy mf ea eb mg ed ef dx translated">github.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo io ma"/></div></div></a></div></div></div>    
</body>
</html>