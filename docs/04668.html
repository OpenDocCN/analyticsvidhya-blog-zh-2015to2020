<html>
<head>
<title>In-depth tutorial of Recurrent Neural Network (RNN) and Long - Short Term Memory (LSTM) Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">递归神经网络(RNN)和长短期记忆(LSTM)网络的深度教程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/in-depth-tutorial-of-recurrent-neural-network-rnn-and-long-short-term-memory-lstm-networks-3a782712a09f?source=collection_archive---------5-----------------------#2020-03-28">https://medium.com/analytics-vidhya/in-depth-tutorial-of-recurrent-neural-network-rnn-and-long-short-term-memory-lstm-networks-3a782712a09f?source=collection_archive---------5-----------------------#2020-03-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1790" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然，研究论文是了解任何尖端技术的最佳途径，但是，理解它们并不容易。它有许多数学方程式和术语，需要大量的努力。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/5a04c887e76667e6f5cb69deee5c2287.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*S-Y3iOuUY6N-r8fkepz5jg.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">artpal.com</figcaption></figure><p id="c0f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我会尽我最大的努力以非常结构化的格式解释RNN，但是如果你遇到任何困难，请在最后的评论框中写下，让我知道。那么，你准备好了吗！，我们开始吧！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jp"><img src="../Images/b6f04a86c53c7bee93595fa7ee561264.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*WfRELAvfW2xCwSdN51rAww.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">facebook.com</figcaption></figure><h1 id="6d1a" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">什么是RNN？？？</h1><p id="f6bb" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">RNN是一类强大的神经网络，用于对时序或自然语言等序列数据进行建模。基本上，这个架构背后主要思想是使用顺序信息。</p><p id="1e7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">你知道谷歌的自动完成功能是如何工作的吗？？？</strong></p><p id="35da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基本上，收集大量最频繁出现的连续单词输入= = = = = = &gt; &gt;<strong class="ih hj">【RNN网】</strong>= = = = = = = =&gt;&gt;它通过找到频繁出现的单词序列来分析数据，并建立模型来预测句子中的下一个单词。</p><p id="bf61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，你看到RNN在我们日常生活中的重要性了吧。其实已经让我们变懒了！</p><p id="50c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在生活中已经有这么多的问题，现在为什么要通过引入一个新的网络(RNN)来使它变得更复杂，当我们已经有了前馈神经网络的时候？</p><p id="82d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在前向神经网络中，信息只从输入节点通过隐含层流向输出节点。网络中没有循环或环路。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es kt"><img src="../Images/cb7a51c8b0cbc37639087f59bd2a5507.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o-by790hDyIz5ad_bUqipA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">对两个输出进行分类的前馈神经网络。</figcaption></figure><p id="611f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ky">前馈神经网络中的问题:- </em> </strong></p><ol class=""><li id="971f" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">不能处理顺序数据。</li><li id="f001" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">仅考虑电流输入。</li><li id="6d67" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">记不住之前的输入。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ln"><img src="../Images/bed7ac92520c6083b771f7a539e36da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8WphMopgERgNflz8Eu6Uw.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">RNN的基本建筑</figcaption></figure><p id="a3ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，从上图可以清楚地看出，RNN是一种特殊类型的前馈神经网络。如图所示，在RNN，任何层的输出不仅取决于当前输入，还取决于之前输入的集合。这一特性使它比其他神经网络具有更大的优势，因为它可以利用以前获得的输入来预测以后阶段的输出。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es lo"><img src="../Images/d2ae63843b56d0824ac86b34983bbd63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SSe5iEoUvdKT-6HAGfVa-A.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">显示RNN基本方程的图像(http://cs231n.stanford.edu)</figcaption></figure><h1 id="d341" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">RNN的申请:——</strong></h1><ol class=""><li id="cf8f" class="kz la hi ih b ii ko im kp iq lp iu lq iy lr jc le lf lg lh bi translated">图像字幕—用于通过分析图像中的活动来为图像添加字幕。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ls"><img src="../Images/e3763425f91dffc50179bffa7d569c1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_m1Gsfxnn4FgIUEWOceQQ.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图像字幕示例</figcaption></figure><p id="d9a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.时间序列预测</p><p id="dcbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.自然语言处理—文本挖掘和情感分析</p><p id="b469" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.机器翻译——通过接受一种语言的输入，RNN可以用来将其翻译成不同的语言作为输出。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es lt"><img src="../Images/38045ae985ebff06296d0000306d17ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_gnorLcNSt_ySWTYSKeCpg.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">将英语作为输入并将其转换成不同的语言</figcaption></figure><h1 id="e3ae" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">RNN建筑类型:——</strong></h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es lu"><img src="../Images/b6f5c4e3a7b5f18014777302cca27ff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VCxoP7Siu0YB501L_-eg1w.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">基本RNN建筑(斯坦福cs231讲座)</figcaption></figure><ol class=""><li id="9fd2" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">一对一:它也被称为香草神经网络。它用于基本的机器学习问题。</li><li id="a3d2" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">一对多:—它有单个输入和多个输出。应用:用于图像标题，就像我们以前在狗在空中接球中看到的那样。</li><li id="80b6" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">多对一:—它有许多输入和一个输出。这基本上用于分析情感，我们给出一个句子作为输入，情感作为输出。</li><li id="abd3" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">多对多:—它接受一系列输入并生成一系列输出。应用:机器翻译</li></ol><h1 id="cf2b" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">训练RNN时的问题:—</h1><ol class=""><li id="22b7" class="kz la hi ih b ii ko im kp iq lp iu lq iy lr jc le lf lg lh bi translated">消失梯度问题</li><li id="0fb8" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">爆炸梯度问题</li></ol><p id="fe5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当梯度反向传播回到初始层时，在深度神经网络的训练期间出现问题。因为由于链式法则，梯度必须经历连续的矩阵乘法。因此，如果它们的值很小(&lt;1) they shrink exponentially till the time they vanish and this is called <strong class="ih hj">消失梯度问题</strong>)。这导致信息随时间丢失。此外，如果梯度值很大(&gt; 1)，它们会变得更大，最终会破坏模型，这被称为<strong class="ih hj">爆炸梯度问题。</strong></p><p id="8fce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ky">问题由于这些问题:</em> </strong></p><ol class=""><li id="a37d" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">训练时间长</li><li id="b28e" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">性能差</li><li id="35fb" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">精确度差</li></ol><p id="fedc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ky">让我们用更实际的方式来理解这一点:——</em></strong></p><p id="f11d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑下面两个例子来理解序列中的下一个单词应该是什么:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es lv"><img src="../Images/7f7c766be6cb3f54a08d5313a8390656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pw4uQQdkDsm8bV8ztkjLyA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图片:SimpliLearn</figcaption></figure><p id="925c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了理解序列中下一个单词是什么，RNN必须记住<strong class="ih hj">之前的上下文</strong>无论主语是单数名词还是复数名词。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es lw"><img src="../Images/96dcd8b3dd615f63b1e877743f1aa761.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FRSlRd2wB5VDCy7IPBaFuQ.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">反向传播</figcaption></figure><p id="3f0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，有时可能很难将错误反向传播到序列的开头，以预测输出应该是什么。</p><p id="f5df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">现在，让我们试着用更统计学的方法来理解上述问题:</strong></p><p id="aab3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不要看到标题就害怕。我会尽力用简单的方式解释所有深入的概念。</p><p id="e528" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设，我们有一个架构，它接受一个英语句子并给出法语句子作为输出。因此，为了实现这一点，架构必须在其隐藏的激活中存储尽可能多的信息。</p><p id="b020" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个句子可能有20个单词长，这表明从它看到一个输入到它使用这个输入进行预测之间有一个很长的时间间隔。学习异地恋是非常艰难的。因此，为了基于第一输入调整输入-隐藏权重，需要误差信号通过整个路径反向传播。</p><p id="d08d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ky">现在问题来了，为什么这个梯度问题在向前传球的时候不会发生？？？</em>T19】</strong></p><p id="4ce1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实际上，在正向传递中，每一步的激活都通过一个非线性激活函数，该函数通常会压缩值，防止它们爆炸。因为向后传递完全是线性的，没有什么可以阻止导数爆炸。</p><p id="51d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们试着用RNN计算的函数来解释这个问题:</p><p id="0741" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所知，每一层计算机都是当前输入和先前隐藏激活的函数</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lx"><img src="../Images/aab963abbc1c8aec10046cf367992588.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*6eWscohO7xtDD9xRg4nm3A.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">RNN的基本方程</figcaption></figure><p id="5707" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过递归展开，我们得到—</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ly"><img src="../Images/0f6521cc739b45ba842bcbb5cf82fb80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9IMW5WyHYMP67k9gPByZJw.png"/></div></div></figure><p id="961b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是迭代函数(迭代多次的函数)。</p><p id="4c13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们以一个简单的二次函数为例来理解上面的概念:—</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es lz"><img src="../Images/7a3d72d444572a76b291092f7b28a436.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6p0N_nciQfoThCWGxNP1nA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">简单二次方程</figcaption></figure><p id="c57c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们多次迭代，我们会得到一些复杂的行为，如下图2所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ma"><img src="../Images/e89dc79e4fdf651b8863acdd275332ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7p5g68zH84sMaNMg7jA_rg.png"/></div></div></figure><p id="bcaa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过一个单调的例子使它变得更简单:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mb"><img src="../Images/2a7abee4674b3a06249a3b9573f75621.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*0DJAB48PjsefQP5QelQNfA.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">在[0，1]上单调</figcaption></figure><p id="0f5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，视觉上理解它的重复行为</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/cf263a54e13f12d1648ccc31f125f0a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*lIgKZcF-QIvsn8LrtCHK-g.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">红线表示函数迭代的轨迹</figcaption></figure><p id="9045" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终，迭代要么射向无穷远，要么在一个固定点结束，即x = f(x)的点，这里x的图形与虚线相交。</p><p id="8029" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">定点有两种类型:—</p><ol class=""><li id="85d1" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">来源:排斥迭代(上图中的0.82)。它的导数f'(x) &gt; 1。</li><li id="05fa" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">Sinks/ Attractors:吸引迭代(上图中的0.17)。它有导数f'(x) &lt; 1.</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/72c15e6585b4efb8989df5301569438c.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*HZAhTTvHaDrWcVpg47Vo1Q.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">Phase plot explaining source and sink in a single plot</figcaption></figure><p id="bf3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Because of the source point we have gradient exploding issue and due to sink point we face gradient vanishing issue.</p><h1 id="bf97" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">对梯度爆炸和消失梯度问题的解:——</strong></h1><ol class=""><li id="3b10" class="kz la hi ih b ii ko im kp iq lp iu lq iy lr jc le lf lg lh bi translated"><strong class="ih hj">渐变裁剪:</strong></li></ol><p id="9c4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它有助于通过重新缩放梯度来防止梯度膨胀，因此它们的范数至多是一个特定值η，即，如果‖g‖&gt; η，其中g是梯度，我们设置</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es me"><img src="../Images/1246138f70431a048c955ea343c74cf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*Tr0C4yDxdosPHGt2C69Y4Q.png"/></div></figure><p id="5904" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过这样做，我们在训练过程中引入了偏差，因为结果值实际上不是成本函数的梯度。下图显示了一个带有悬崖和狭窄山谷的示例；如果你碰巧落在悬崖的表面，你会迈出一大步，把你推到好的区域之外。使用渐变剪辑，您可以停留在山谷中。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mf"><img src="../Images/3efdb7e0a7de3e2054faaa41b484ae8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w4jjis5ACoMd-Rtob2DSLg.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">该图显示了裁剪如何有助于防止渐变爆炸。</figcaption></figure><p id="8d3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">输入反转:</strong></p><p id="8392" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在开始时，我们了解到，网络很难了解远距离依赖性。因此，这影响了建筑的学习能力。这可以通过颠倒输入句子中单词的顺序来解决，通过分析下图可以清楚地理解这一点:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mg"><img src="../Images/ab1a3943f2280f9242ccedf036e1bc40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6DVibDLmzIc5f6pZVuZiVw.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">输入反转</figcaption></figure><p id="0443" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的图表中，我们可以看到在第一个单词被读取和需要它的时候只有一个时间间隔。这允许网络学习第一个单词之间的关系。一旦它学会了这一点，它可以被进一步训练，以学习句子中更难的单词之间的依赖关系。</p><p id="e953" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。身份初始化:</strong></p><p id="0c33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">除了可以多次迭代的恒等函数f(x) = x之外，其他迭代函数可能具有复杂和混沌的行为。因此，如果网络计算单位函数，梯度计算将是完全稳定的，因为雅可比矩阵仅仅是单位矩阵。</p><p id="bed0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在恒等RNN架构中，所有的激活函数都是RELU，权重被初始化为恒等矩阵。此外，RELU激活函数将激活剪辑为非负的，但是对于非负的激活，它相当于身份函数。</p><p id="efde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。长期短期记忆(LSTM): </strong></p><p id="a858" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LSTM是一种特殊的RNN，主要用于学习长期依赖关系。这个名字是指网络的激活对应于短期记忆，而权重对应于长期记忆。如果激活可以远距离保存信息，这就使它们成为长期短期记忆。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mh"><img src="../Images/724326e67063597b7e6612a9c012ebdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sA1ozS0KNlsp4MRrf15jwA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">LSTM的基本建筑</figcaption></figure><p id="7bf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们来做一下LSTM的操作，了解一下它是如何运作的:——</strong></p><p id="cc56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基本上，LSTM分三步走:</p><p id="a375" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ky">第一步——决定应该记住多少过去的事情</em> </strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mi"><img src="../Images/a81981ec41ec34dc7164f954e8e01e19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vuoADDg7deNGjcXdNICqWg.png"/></div></div></figure><p id="46aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述步骤的示例:</p><p id="4bf4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上一期输出h(t-1):爱丽丝物理不错。另一方面，约翰擅长化学。</p><p id="6bf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当前输入x(t):约翰足球踢得很好。他昨天在电话里告诉我，他担任了足球队的队长。</p><p id="4665" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a.在遇到第一个句号后，遗忘门意识到上下文可能会发生变化。</p><p id="5b45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b.在x(t)处与当前输入句子进行比较。</p><p id="cba5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">c.下一句说的是约翰，所以删除了爱丽丝的信息。</p><p id="3b1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">d.主语的位置空出来，分配给约翰。</p><p id="2f82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ky">第二步——决定这个单位应该给当前状态增加多少。</em>T13】</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mj"><img src="../Images/9f4f60cb503527fd61235a18637c9c7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EWJ3iMcJkK0kT9gXlo0VxA.png"/></div></div></figure><p id="cdac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述步骤的示例:</p><p id="478c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当前输入x(t):约翰足球踢得很好。他昨天在电话里告诉我，他担任了足球队的队长。</p><p id="53b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入门分析上述句子的重要性为:</p><p id="b424" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[约翰踢足球，他是他足球队的队长] ( <em class="ky">比</em>更重要)【他在电话里告诉我】(<em class="ky">不太重要，因此被遗忘了</em></p><p id="c56a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ky">第三步——决定当前单元格的哪一部分输出。</em> </strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mk"><img src="../Images/ada20c2e5b422fc3d5000616900eeb75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XgZ2pnbRal6KmAjT0hmGVw.png"/></div></div></figure><p id="5cb0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本示例将尝试预测句子中的下一个单词:</p><p id="0183" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">约翰在与对手的比赛中表现出色，赢得了他的球队。勇敢的___________因其对团队的贡献被授予最佳球员。</p><p id="0cd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对人类来说，决定什么应该来这里是非常容易的，然而，对机器来说却不是这样。空白空间可以有多种选择。</p><p id="6118" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，在这一步系统首先检查什么是brave == &gt;形容词(描述一个名词)</p><p id="7239" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，经过一系列步骤后，它决定John应该是这里的最佳选择。</p><p id="6885" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们讨论了与RNNs相关的各种事情，如它是什么，我们为什么需要它，它的应用，RNN面临的问题以及解决它的各种方法，包括LSTM的细节。这是一个有点长的博客，但它是值得的，因为在写之前，我确信我想写一个关于RNN的详细博客，它涵盖了它的大部分。读完所有这些东西后，我发现自己已经有足够的装备去打一场仗，我的意思是拿着数据集，把我所有的知识应用到它上面。我对你有同感，因此，我将写下一篇关于RNN实际应用的系列博客。所以，如果你喜欢这个博客，请通过鼓掌和评论让我知道，如果你对此有任何疑问。</p><p id="1cdd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">#机器学习#深度学习#神经网络# RNN # LSTM #递归神经网络#人工智能</p></div></div>    
</body>
</html>