<html>
<head>
<title>Handling Imbalanced Classes!!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理不平衡的班级！！！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/handling-imbalanced-classes-3057a88e2a19?source=collection_archive---------11-----------------------#2020-09-13">https://medium.com/analytics-vidhya/handling-imbalanced-classes-3057a88e2a19?source=collection_archive---------11-----------------------#2020-09-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7d38c35c875f8f63bbf63d3895af4a05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XcvgSzurnRxSrTc0dJnFSw.png"/></div></div></figure><p id="2213" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi jo translated">现实世界机器学习分类问题的许多问题之一是不平衡数据的问题。<br/>不平衡数据是指当我们的数据中存在的类不成比例时，也就是说，每个类的比例不同，其中一个类主要存在于数据集中，而另一个类次要存在。</p><h1 id="0051" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">不平衡数据的问题？</h1><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/809c24a8c0ec8a6e6a1a562be0003f35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xy_4LQkTErZcRHVT"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图为<a class="ae le" href="https://unsplash.com/@officestock?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">塞巴斯蒂安·赫尔曼</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><ul class=""><li id="7ee7" class="lf lg hi is b it iu ix iy jb lh jf li jj lj jn lk ll lm ln bi translated">虽然模型训练导致模型偏向少数类，这意味着，我们的模型将很好地学习我们的多数类的特征，而不能捕捉我们的少数类的特征。</li><li id="fc9a" class="lf lg hi is b it lo ix lp jb lq jf lr jj ls jn lk ll lm ln bi translated">准确度分数可能会产生误导。</li></ul><h1 id="9627" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">处理不平衡数据集的方法！</h1><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/f5769e131255c9e7ce2a42f06f340408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8KZ29vPczJjijq5H"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated"><a class="ae le" href="https://unsplash.com/@campaign_creators?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">活动创建者</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="510f" class="lu jy hi bd jz lv lw lx kd ly lz ma kh jb mb mc kl jf md me kp jj mf mg kt mh bi translated">→收集更多数据。</h2><p id="feee" class="pw-post-body-paragraph iq ir hi is b it mi iv iw ix mj iz ja jb mk jd je jf ml jh ji jj mm jl jm jn hb bi translated">这种方法经常被忽视，因为它对于大多数用例来说是不可能的。但是，这种方法减少了由于重采样技术而在数据中引入的偏差量。</p><h2 id="8f13" class="lu jy hi bd jz lv lw lx kd ly lz ma kh jb mb mc kl jf md me kp jj mf mg kt mh bi translated">→使用不同的绩效指标</h2><p id="d45a" class="pw-post-body-paragraph iq ir hi is b it mi iv iw ix mj iz ja jb mk jd je jf ml jh ji jj mm jl jm jn hb bi translated">性能指标在解释我们的训练模型的优点方面起着重要的作用。应该使用的一些度量标准是:<br/> *精确分数<br/> *召回分数<br/> * f-1 分数<br/> *精确召回曲线<br/> * kappa</p><blockquote class="mn mo mp"><p id="6eac" class="iq ir mq is b it iu iv iw ix iy iz ja mr jc jd je ms jg jh ji mt jk jl jm jn hb bi translated">ROC 曲线不应用于不平衡数据，因为这可能会解释错误的结果。如果模型在不平衡数据上表现良好，我们应该使用精确-召回曲线。<br/>因为在<a class="ae le" rel="noopener" href="/analytics-vidhya/understanding-the-auc-roc-curve-cdc754d7b58a"> ROC-AUC 曲线</a>中，假阳性率(假阳性/真阴性总数)在真阴性总数巨大时不会急剧下降。而精度(真阳性/(真阳性+假阳性) )对假阳性高度敏感，并且不受大的总真阴性分母的影响。</p></blockquote><h2 id="562d" class="lu jy hi bd jz lv lw lx kd ly lz ma kh jb mb mc kl jf md me kp jj mf mg kt mh bi translated">→尝试不同的算法</h2><p id="547c" class="pw-post-body-paragraph iq ir hi is b it mi iv iw ix mj iz ja jb mk jd je jf ml jh ji jj mm jl jm jn hb bi translated">很多时候，尝试不同的算法往往会给我们最好的结果。<br/>特别是在像决策树这样的不平衡数据算法的情况下，RandomForest 往往会给我们最好的结果。</p><h2 id="08dc" class="lu jy hi bd jz lv lw lx kd ly lz ma kh jb mb mc kl jf md me kp jj mf mg kt mh bi translated">→重新采样数据</h2><p id="a840" class="pw-post-body-paragraph iq ir hi is b it mi iv iw ix mj iz ja jb mk jd je jf ml jh ji jj mm jl jm jn hb bi translated">它是处理不平衡数据最常用的技术之一。它随机地对数据进行重采样，以平衡类。<br/>它包括从多数类中移除样本(欠采样)和(或)从少数类中添加更多样本(过采样)。</p><ul class=""><li id="459a" class="lf lg hi is b it iu ix iy jb lh jf li jj lj jn lk ll lm ln bi translated">随机重采样为不平衡数据集重新平衡类分布提供了一种简单的技术。</li><li id="dd2b" class="lf lg hi is b it lo ix lp jb lq jf lr jj ls jn lk ll lm ln bi translated">随机过采样复制训练数据集中少数类的示例，可能会导致某些模型过度拟合。</li><li id="9812" class="lf lg hi is b it lo ix lp jb lq jf lr jj ls jn lk ll lm ln bi translated">随机欠采样从多数类中删除样本，并可能导致丢失对模型非常重要的信息。</li></ul><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/85c752f5755b2571633ee3d48fbcd331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YP2cGJEnsmZS7TiMurNmuQ.png"/></div></div></figure><p id="6325" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">过采样:<br/> </strong>在这种技术中，少数类被随机复制，以匹配多数类的数量。</p><p id="5006" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.这种技术对于那些受偏斜分布影响的机器学习算法是有效的，并且其中给定类的多个重复示例会影响模型的拟合。</p><p id="29e7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.这可能包括迭代学习系数的算法，如使用随机梯度下降的人工神经网络。它还会影响寻求良好数据分割的模型，如支持向量机和决策树。</p><pre class="kw kx ky kz fd mv mw mx my aw mz bi"><span id="c2b4" class="lu jy hi mw b fi na nb l nc nd">import imblearn<br/>from imblearn.over_sampling import RandomOverSampler</span><span id="8643" class="lu jy hi mw b fi ne nb l nc nd">oversample = RandomOverSampler(sampling_strategy='minority')<br/><br/>X_over, y_over = oversample.fit_resample(X, y)</span></pre><blockquote class="nf"><p id="794a" class="ng nh hi bd ni nj nk nl nm nn no jn dx translated"><a class="ae le" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.RandomOverSampler.html" rel="noopener ugc nofollow" target="_blank">参考此链接了解更多关于过采样功能的信息。</a></p></blockquote><p id="db06" class="pw-post-body-paragraph iq ir hi is b it np iv iw ix nq iz ja jb nr jd je jf ns jh ji jj nt jl jm jn hb bi translated"><strong class="is hj">欠采样:<br/> </strong>在这种技术中，通过从多数类中随机删除数据点，多数类被下采样到少数类的大小。</p><ol class=""><li id="5af8" class="lf lg hi is b it iu ix iy jb lh jf li jj lj jn nu ll lm ln bi translated">欠采样的一个限制是来自多数类的样本被删除，这些样本对于拟合稳健的决策边界可能是有用的、重要的或者可能是关键的。</li><li id="5837" class="lf lg hi is b it lo ix lp jb lq jf lr jj ls jn nu ll lm ln bi translated">这种方法可能更适合于那些存在类不平衡的数据集，尽管在少数类中有足够数量的例子，这种有用的模型是适合的。</li></ol><pre class="kw kx ky kz fd mv mw mx my aw mz bi"><span id="adf0" class="lu jy hi mw b fi na nb l nc nd">import imblearn<br/>from imblearn.over_sampling import RandomUnderSampler</span><span id="5d02" class="lu jy hi mw b fi ne nb l nc nd">undersample = RandomUnderSampler(sampling_strategy='minority')<br/><br/>X_under, y_under = undersample.fit_resample(X, y)</span></pre><blockquote class="nf"><p id="1d56" class="ng nh hi bd ni nj nk nl nm nn no jn dx translated"><a class="ae le" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.RandomUnderSampler.html" rel="noopener ugc nofollow" target="_blank">参考此链接了解有关欠采样功能的更多信息。</a></p></blockquote><h2 id="0dff" class="lu jy hi bd jz lv nv lx kd ly nw ma kh jb nx mc kl jf ny me kp jj nz mg kt mh bi translated">生成合成样本:</h2><p id="9e31" class="pw-post-body-paragraph iq ir hi is b it mi iv iw ix mj iz ja jb mk jd je jf ml jh ji jj mm jl jm jn hb bi translated">有系统的算法可以用来生成合成样本。这种算法中最流行的叫做 SMOTE，即合成少数过采样技术。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es oa"><img src="../Images/540d9bafd93587d1cf96e73bde6c6d12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*Y2HGpoVp8hEkYb51BTWG3A.jpeg"/></div></figure><p id="712d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="mq"> SMOTE 是一种过采样方法。</em> </strong>它的工作原理是从 minor 类创建合成样本，而不是创建副本。<br/>该算法选择两个或多个相似的实例(使用距离度量),并在与相邻实例的差异范围内，一次一个属性地随机扰动一个实例。</p><pre class="kw kx ky kz fd mv mw mx my aw mz bi"><span id="9c3c" class="lu jy hi mw b fi na nb l nc nd">from imblearn.over_sampling import SMOTE</span><span id="9a69" class="lu jy hi mw b fi ne nb l nc nd">sm = SMOTE(random_state = 123)<br/>X_train_res,Y_train_res = sm.fit_sample(X,Y.ravel())</span></pre><h2 id="b178" class="lu jy hi bd jz lv lw lx kd ly lz ma kh jb mb mc kl jf md me kp jj mf mg kt mh bi translated">手动分配类别权重:</h2><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ob"><img src="../Images/5a0e7245931b4c746650595f751468cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*EIvMomyI_m4OGLvltQW1MA.png"/></div></figure><p id="43f6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">避免任何外来偏见进入数据的技术之一是手动给类分配权重。</p><p id="b7db" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将较高的权重分配给少数类，以便我们的模型对这两个类给予同等的重视。</p><p id="4abf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每个分类算法都有一个超参数，即“<strong class="is hj"> class_weight”。<br/> </strong>默认情况下，当没有值被传递时，分配给每个类的权重是相等的，例如 1。</p><ul class=""><li id="702a" class="lf lg hi is b it iu ix iy jb lh jf li jj lj jn lk ll lm ln bi translated">一种常见的技术是在创建算法实例时分配<strong class="is hj"> class_weight="balanced" </strong>。</li></ul><pre class="kw kx ky kz fd mv mw mx my aw mz bi"><span id="4f6a" class="lu jy hi mw b fi na nb l nc nd">Logistic_model = LogisiticRegression(class_weight =<br/>                                    "balanced").fit(x_train,y_train)</span></pre><ul class=""><li id="5e97" class="lf lg hi is b it iu ix iy jb lh jf li jj lj jn lk ll lm ln bi translated">另一种技术是使用诸如<strong class="is hj"> class_weight={0:2，1:1} </strong>之类的语法手动将权重分配给不同的类标签。类别 0 的权重为 2，类别 1 的权重为 1。</li></ul><pre class="kw kx ky kz fd mv mw mx my aw mz bi"><span id="5903" class="lu jy hi mw b fi na nb l nc nd">#class_weights = {class_label : weight}</span><span id="d211" class="lu jy hi mw b fi ne nb l nc nd">class_weights = {0:2, 1:1}<br/>Logistic_model = LogisiticRegression(class_weight =<br/>                                 class_weights).fit(x_train,y_train)</span></pre><blockquote class="nf"><p id="1c96" class="ng nh hi bd ni nj nk nl nm nn no jn dx translated">我们可以使用网格搜索来搜索模型训练的最佳权重值</p></blockquote><pre class="oc od oe of og mv mw mx my aw mz bi"><span id="b1eb" class="lu jy hi mw b fi na nb l nc nd">from sklearn.model_selection import GridSearchCV</span><span id="6696" class="lu jy hi mw b fi ne nb l nc nd">class_weight = np.linespace(0.05, 1.5, 20)</span><span id="7fff" class="lu jy hi mw b fi ne nb l nc nd">grid_para = {'class_weight' : [{0: x, 1: 1.0-x} for x in <br/>             class_weight]</span><span id="ad56" class="lu jy hi mw b fi ne nb l nc nd">gridsearch = GridSearchCV(estimator = LogisticRegression(),<br/>                          param_grid = grid_para,<br/>                          scoring = 'f1',<br/>                          cv = 3)</span><span id="2a1a" class="lu jy hi mw b fi ne nb l nc nd">gridsearch.fit(x_train, y_train)<br/>print(gridsearch.best_params_)</span></pre><blockquote class="nf"><p id="20ce" class="ng nh hi bd ni nj nk nl nm nn no jn dx translated">找到最佳的权重集后，我们可以通过这个权重来训练我们的模型。</p></blockquote><p id="1ccf" class="pw-post-body-paragraph iq ir hi is b it np iv iw ix nq iz ja jb nr jd je jf ns jh ji jj nt jl jm jn hb bi translated">这些是可以用来解决不平衡数据问题的少数技术。<br/>没有一种方法可以说是最好的，我强烈推荐你去试验一下，找出哪种方法最适合。</p><h2 id="b0cd" class="lu jy hi bd jz lv lw lx kd ly lz ma kh jb mb mc kl jf md me kp jj mf mg kt mh bi translated">快乐学习！！！！！</h2></div><div class="ab cl oh oi gp oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="hb hc hd he hf"><p id="9590" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">喜欢我的文章？请为我鼓掌并分享它，因为这将增强我的信心。此外，我每周日都会发布新文章，所以请保持联系，以了解数据科学和机器学习基础系列的未来文章。</p><p id="c460" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另外，请务必在 LinkedIn<a class="ae le" href="http://www.linkedin.com/in/abhigyan-singh-b13651121" rel="noopener ugc nofollow" target="_blank">上与我联系。</a></p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oo"><img src="../Images/2569f1c2fdaf41459d1ccb9285f3b755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UhlAKenZcsQApgex"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated"><a class="ae le" href="https://unsplash.com/@alx_andru?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Alex </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure></div></div>    
</body>
</html>