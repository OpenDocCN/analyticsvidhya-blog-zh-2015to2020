<html>
<head>
<title>Web Scraping Times of India with Python and Beautifulsoup4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python和Beautifulsoup4实现印度的网络抓取时代</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-times-of-india-with-python-and-beautifulsoup4-2829c75f4d4b?source=collection_archive---------7-----------------------#2020-03-28">https://medium.com/analytics-vidhya/web-scraping-times-of-india-with-python-and-beautifulsoup4-2829c75f4d4b?source=collection_archive---------7-----------------------#2020-03-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c214cceefba75bf368ef036eb48b5b56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7UC2vK4bndXcEv0VKfLtCQ.png"/></div></div></figure><p id="db05" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇文章中，我们将回顾我在2019年11月做的一个例子，但我现在与大家分享它。考虑到全球目前的形势，由于冠状病毒已经让世界陷入瘫痪，许多企业已经关闭，跨国公司建议在家工作。考虑到这种情况，许多报社已经停止在印度发行报纸。没有IT背景的人也在网上阅读它，但是这篇文章主要关注的是提高他们在Python和网络搜集方面的技能。任何一个业内人士或者有Python基础知识的人，都可以借助Python和BeautifulSoup4库来抓取任何网站。</p><p id="918e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是在我们深入研究这个程序之前，让我给你一个关于网络抓取的简单概念。</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/401c5d2a45ba586138f857e8e39257b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EUFK91Mjr4-lRlQ8RZa9EQ.jpeg"/></div></div></figure><p id="f88d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">网页抓取</strong>是一种从网站上自动获取和提取大量信息的技术，可以节省大量的时间和精力。</p><p id="2e14" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">网页抓取器是如何工作的？</strong></p><p id="cb3c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">自动化web抓取器的工作方式相当简单，但也很复杂。毕竟网站是给人类看懂的，不是给机器看的。</p><p id="a1e0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，在抓取之前，web抓取器将被给予一个或多个要加载的URL。然后，scraper加载相关页面的整个HTML代码。更高级的抓取器会渲染整个网站，包括CSS和Javascript元素。</p><p id="6365" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，scraper将在项目运行之前提取页面上的所有数据或用户选择的特定数据。</p><p id="da24" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">理想情况下，用户将经历从页面中选择他们想要的特定数据的过程。例如，您可能想在亚马逊产品页面上搜索价格和型号，但不一定对产品评论感兴趣。</p><p id="0f82" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，web scraper会将收集到的所有数据输出为对用户更有用的格式。</p><p id="36eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大多数web抓取器将数据输出到CSV或Excel电子表格，而更高级的抓取器将支持其他格式，如可用于API的JSON。</p><p id="ccfa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一个信息丰富的练习，适合正在寻找如何抓取网站的初学者。我将教程分解成更小的部分，这样你可以更好地理解每一步。</p><p id="9ed2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">先决条件:</strong> Python3，BeautifulSoup4。</p><blockquote class="js jt ju"><p id="2345" class="iq ir jv is b it iu iv iw ix iy iz ja jw jc jd je jx jg jh ji jy jk jl jm jn hb bi translated">我假设您的机器上已经安装了python。如果不是，请从<a class="ae jz" href="https://www.python.org/downloads/" rel="noopener ugc nofollow" target="_blank">https://www.python.org/downloads/</a>安装beautifulsoup4库类型- <em class="hi"> pip安装beautifulsoup4 </em></p></blockquote><p id="e0ae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">Beautiful Soup:</strong>Beautiful Soup是一个库，可以很容易的从网页中抓取信息。它位于HTML或XML解析器之上，为迭代、搜索和修改解析树提供了Pythonic习惯用法。</p><p id="3f47" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">我想给我的同事们一些建议:</strong></p><ol class=""><li id="48ad" class="ka kb hi is b it iu ix iy jb kc jf kd jj ke jn kf kg kh ki bi translated">阅读网站的条款和条件，了解如何合法使用他们的数据。大多数网站禁止你将数据用于商业目的。</li><li id="a279" class="ka kb hi is b it kj ix kk jb kl jf km jj kn jn kf kg kh ki bi translated">请确保您不要快速下载他们的数据，因为这可能会破坏网站，可能会使您被阻止！</li></ol><p id="dc5e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">视察网站</strong></p><p id="98ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要做的第一件事是找出在多层HTML标签中我们可以在哪里找到我们想要下载的文件的链接。简而言之，网站页面上有大量代码，我们希望找到包含我们数据的相关代码。如果你不熟悉HTML标签，参考<a class="ae jz" href="https://www.w3schools.com/" rel="noopener ugc nofollow" target="_blank"> W3Schools教程</a>。理解HTML的基础知识对于成功抓取网页是很重要的。</p><p id="47f5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在网站上，右键点击“检查”。这可以让你看到网站背后的原始代码。</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/51df7817e68e8edd8d9c43a2d3824d05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uE0OpPPF98dhE7TnaktQHQ.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">单击“Inspect”后，您应该会看到此控制台弹出。</figcaption></figure><figure class="jo jp jq jr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/5d951ac813d97d8eefcad6548c104336.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*782mKkTBwOk7GC-Bms3egA.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">注意，在控制台的左上角有一个箭头符号。</figcaption></figure><p id="711b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您单击箭头符号，然后单击站点本身的某个区域，该特定项目的代码将在控制台中突出显示。或者你可以直接去<a class="ae jz" href="https://timesofindia.indiatimes.com/home/headlines" rel="noopener ugc nofollow" target="_blank">网站</a>然后执行这些任务。</p><p id="e299" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">终点站！<strong class="is hj">Python代码</strong></p><figure class="jo jp jq jr fd ij"><div class="bz dy l di"><div class="kt ku l"/></div></figure><p id="0780" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">成功访问URL后，我们用BeautifulSoup解析HTML，这样我们就可以使用可管理的BeautifulSoup数据结构。Beautifulsoup是一个多功能的库，我强烈推荐你去看看他们的文档。然后我们使用了这个方法。findAll()来定位我们所有的<div>标签，使用的技术与我们使用的方法相同。findAll()来定位divtags中的所有<ul>标签，我们只是将计数器设置为小于等于10，因为我们想要当天的前10个标题。最后一步，我们应用了同样的技术来查找<ul>标签中的所有<li>标签，并打印出前10个标题的列表。</li></ul></ul></div></p><p id="d3c6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果如下:- </p><figure class="jo jp jq jr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/18ba4b6b5d741410efd0142ce75774ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X1MeuvZOUzcpDSJJiHXE3g.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">今天有12个头条新闻，而不是10个！</figcaption></figure><p id="5230" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">作为一个Pythonista，你的网络抓取之旅才刚刚开始，还有其他的网络抓取库。我建议你学习Scrapy，因为它比BeautifulSoup更高级。你可以在我的Github上找到我的Jupyter笔记本。</p><p id="7eb2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">或者，你也可以得到一份<a class="ae jz" href="https://amzn.to/3K6HiCu" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">用Python </strong> </a>进行网页抓取的副本，深入了解使用beautifulsoup4和scrapy进行网页抓取。</p><p id="aa68" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">更多关于这本书的信息，请点击:<a class="ae jz" href="https://amzn.to/3K6HiCu" rel="noopener ugc nofollow" target="_blank">https://amzn.to/3K6HiCu</a></p><p id="d0a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感谢您的阅读，祝您网游愉快！</p></div></div>    
</body>
</html>