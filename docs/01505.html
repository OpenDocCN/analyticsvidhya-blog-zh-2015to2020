<html>
<head>
<title>Age Detection of Indian Actors using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习检测印度演员的年龄</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/age-detection-of-indian-actors-using-deep-learning-b4c24e39e36e?source=collection_archive---------3-----------------------#2019-10-27">https://medium.com/analytics-vidhya/age-detection-of-indian-actors-using-deep-learning-b4c24e39e36e?source=collection_archive---------3-----------------------#2019-10-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/55db61e2bc1cc1cf2d5cf445a2c39b8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NWNPlVXXx00Oic0c8lusFQ.jpeg"/></div></div></figure><h1 id="8c5f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">问题陈述</strong></h1><p id="0ec2" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">印度电影人脸数据库(IMFDB)是一个大型的无约束人脸数据库，由从100多个视频中收集的100名印度演员的34512张图像组成。这项任务是根据一个人的面部特征来预测他或她的年龄。这个问题已经转化为一个多阶级问题，阶级分为青年、中年和老年。(<em class="km">这是一个来自Analytics Vidhya的竞争问题)</em></p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/893ff0f32fd0e0bd3d377d3295d58930.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jp31rGM3Ia32DRwtXppMOQ.png"/></div></div></figure><p id="e4bd" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated"><strong class="jq hj">数据集</strong></p><p id="aabd" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">数据集经过清理和格式化，总共有26742幅图像，其中19906幅图像在训练中，6636幅图像在测试中。<br/>数据的属性如下:<br/> ID —图像的唯一ID<br/>Class—图像中人的年龄层</p><h1 id="8c3c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">加载数据</strong></h1><p id="a2cf" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们将使用keras，因为它对用户友好，并且类似于scikit-learn。</p><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="aa29" class="lc ir hi ky b fi ld le l lf lg">#---- Reading file<br/>train_csv = pd.read_csv("train.csv")<br/>train_csv["Class"].unique()</span><span id="cca3" class="lc ir hi ky b fi lh le l lf lg">train_csv.head()</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es li"><img src="../Images/e19e32f4640da75b1d454cba7a7c3381.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*MTNYe3mibuubOE95AGgneg.png"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">train.csv文件</figcaption></figure><p id="8b33" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">现在所有的阶级形象都是混合的，根据3个阶级来划分，即青年、中年、老年。我们将所有3类图像存储在3个不同的文件夹中。python中的Shutil方法有助于做到这一点。</p><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="9f2d" class="lc ir hi ky b fi ld le l lf lg">#--- Separating images in 3 classes<br/>for index, row in train_csv.iterrows():<br/>    shutil.copy2("Train/"+row["ID"],row["Class"])</span></pre><p id="1d28" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">现在，下图显示了训练数据集中的3个类。</p><div class="ko kp kq kr fd ab cb"><figure class="ln ij lo lp lq lr ls paragraph-image"><img src="../Images/e1e2edcc6195ded2afcb9f66c15253ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*pL6o0u8FIk5k6ChAkoT6uQ.png"/></figure><figure class="ln ij lo lp lq lr ls paragraph-image"><img src="../Images/6d6e34dc269e9535f23bc9f75dd63200.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*fdkLSu8sMuSVKO4wEXzXLw.png"/></figure><figure class="ln ij lo lp lq lr ls paragraph-image"><img src="../Images/b64beca221693f5dc2fc7278c3f20abf.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*2Cptg9UduULESxMcR0W6Bw.png"/><figcaption class="lj lk et er es ll lm bd b be z dx lt di lu lv translated">年轻|中年|老年</figcaption></figure></div><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="1dd5" class="lc ir hi ky b fi ld le l lf lg">##inspecting the distribution of classes</span><span id="a01e" class="lc ir hi ky b fi lh le l lf lg">plt.figure(figsize = (16,6))<br/>plt.style.use("fivethirtyeight")<br/>train_csv['Class'].value_counts(dropna = False).plot(kind = 'bar',grid = True)<br/>plt.title("Distribtuion of class counts")<br/>plt.xticks(rotation = 0)</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/331203303cd927f385ab18f23c3f3653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tdjq3CWYm-LCoc6zVrOXQw.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">班级人数条形图</figcaption></figure><p id="718b" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">从上图我们可以看出，中年演员较多，老年人演员最少。</p><p id="cac8" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">为了分类，我们将使用以下技术:<br/> -基本卷积神经网络(CNN) <br/> - Resnet50</p><h1 id="831a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">准备列车测试数据</strong></h1><p id="40e4" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们将使用keras的ImageDataGenerator API来分割数据，这里是直接从文件夹中分割图像。<em class="km"> flow_from_directory </em>方法有助于这样做。ImageDataGenerator也有助于增强。<br/> <strong class="jq hj">图像增强</strong>通过不同的处理方式或多种处理方式的组合，如随机旋转、平移、剪切、翻转等，人工创建训练图像。<br/>图像增强很好地改善了模型性能，因为测试图像可能与训练图像不同。</p><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="aa62" class="lc ir hi ky b fi ld le l lf lg">batch_size=32</span><span id="1682" class="lc ir hi ky b fi lh le l lf lg"># To handle image loading problem<br/>from PIL import Image, ImageFile<br/>ImageFile.LOAD_TRUNCATED_IMAGES = True</span><span id="316e" class="lc ir hi ky b fi lh le l lf lg">train_datagen = ImageDataGenerator(rescale = 1./255,<br/>                                   shear_range = 0.2,<br/>                                   zoom_range = 0.2,<br/>                                   horizontal_flip = True)</span><span id="29a0" class="lc ir hi ky b fi lh le l lf lg">test_datagen = ImageDataGenerator(rescale = 1./255)</span><span id="9e18" class="lc ir hi ky b fi lh le l lf lg">training_set = <br/>train_datagen.flow_from_directory('dataset/training',<br/>                                   target_size = (64, 64),<br/>                                   batch_size = batch_size,<br/>                                   class_mode = 'categorical')</span><span id="58b8" class="lc ir hi ky b fi lh le l lf lg">validation_set = test_datagen.flow_from_directory('dataset/validation_set',<br/>                                  target_size = (64, 64),<br/>                                  batch_size = batch_size,<br/>                                  class_mode = 'categorical')</span><span id="8832" class="lc ir hi ky b fi lh le l lf lg">print(training_set.class_indices)</span></pre><h1 id="b040" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">基本CNN</h1><p id="410c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在神经网络中，卷积神经网络(ConvNets或CNN)是进行图像识别、图像分类的主要类别之一。物体检测、人脸识别等。，是CNN被广泛使用的一些领域。</p><p id="307a" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">卷积是从输入图像中提取特征的第一层。卷积通过使用输入数据的小方块学习图像特征来保持像素之间的关系。这是一种数学运算，需要两个输入，如图像矩阵和过滤器或内核</p><p id="7b7d" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">Python中的Keras库使得构建CNN变得非常简单。我们使用keras的顺序模型，因为顺序API允许我们为大多数问题逐层创建模型。</p><p id="a288" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">此外，我们使用了最大池，批量正常化，辍学和一个简单的黑客，即泄漏relu作为激活。</p><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="b865" class="lc ir hi ky b fi ld le l lf lg">model = Sequential()<br/>model.add(Conv2D(64, (3, 3), input_shape = (64, 64, 3)))<br/>model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3)))<br/>model.add(LeakyReLU(alpha=0.3))</span><span id="9947" class="lc ir hi ky b fi lh le l lf lg">model.add(BatchNormalization())<br/>model.add(MaxPooling2D(pool_size = (2, 2)))</span><span id="87e1" class="lc ir hi ky b fi lh le l lf lg"># Dropout<br/>model.add(Dropout(0.4))</span><span id="cc0f" class="lc ir hi ky b fi lh le l lf lg">#Max Pooling</span><span id="9ccf" class="lc ir hi ky b fi lh le l lf lg">model.add(Conv2D(32, (3, 3)))<br/>model.add(MaxPooling2D(pool_size = (2, 2)))<br/>model.add(LeakyReLU(alpha=0.3))<br/>model.add(BatchNormalization())</span><span id="1593" class="lc ir hi ky b fi lh le l lf lg"># Dropout<br/>model.add(Dropout(0.3))</span><span id="b026" class="lc ir hi ky b fi lh le l lf lg">#Flatten<br/>model.add(Flatten())<br/>model.add(Dense(128))<br/>model.add(LeakyReLU(alpha=0.3))<br/>model.add(Dense(64))</span><span id="0d2d" class="lc ir hi ky b fi lh le l lf lg">model.add(Dropout(0.5))<br/>model.add(Dense(3, activation = 'softmax'))</span></pre><p id="053c" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">我们将准确性作为衡量标准，将adam作为优化工具。我们运行该模型30个时期。</p><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="46a1" class="lc ir hi ky b fi ld le l lf lg"># compiling the model<br/>model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])</span><span id="5be5" class="lc ir hi ky b fi lh le l lf lg">#fitting model<br/>history = model.fit_generator(training_set,<br/>                         steps_per_epoch = len(training_set),<br/>                         epochs = 30,<br/>                         validation_data = validation_set,<br/>                         validation_steps = len(validation_set),<br/>                         callbacks=[tensorboard1],<br/>                         verbose=2)</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/c6fb9e415a8d6a61874c18996957481d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*GYFL36pTn3ZJJXXM118lIQ.png"/></div></figure><div class="ko kp kq kr fd ab cb"><figure class="ln ij ly lp lq lr ls paragraph-image"><img src="../Images/04bea08765397e17bf00e0bbfd559d11.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*ckGd6dgaM9yuEcxCcCGu4Q.png"/></figure><figure class="ln ij lz lp lq lr ls paragraph-image"><img src="../Images/ef0161af5d1ecbb957b08cdff5713f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*qEcE9darLfCJKrg-mLghQg.png"/><figcaption class="lj lk et er es ll lm bd b be z dx ma di mb lv translated">模型精度和损耗图</figcaption></figure></div><p id="f89b" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">在基本CNN顺序模式下，我们的准确率为77%，损耗为0.55。从上面的图表中，我们可以说，增加历元大小可以进一步减少损失。<br/>但是这次失利也让我的<strong class="jq hj">竞技成绩</strong>为<strong class="jq hj"> 0.77 </strong>和<strong class="jq hj">当时排名149 </strong>。这里的主要技巧是使用leaky relu作为激活，但是使用像max-pooling和batch normalization这样的层也有助于提高准确性。</p><p id="3222" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">批量标准化减少了隐藏单元值的移动量(协方差移动),最大池使用前一层每个神经元集群的最大值。</p><h1 id="48a7" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">ResNet50</h1><p id="9415" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们现在将使用迁移学习模型，即来自keras的ResNet50 API。ResNet是残差网络的缩写，是一种经典的神经网络，用作许多计算机视觉任务的主干。在ResNet训练之前，由于梯度消失的问题，非常深的神经网络是困难的。ResNet首先引入了跳过连接的概念。下图说明了跳过连接。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/8b0727aa234d7b516d5313ef78aa44fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hSbYwQdB9rcXCrZCd56GjA.png"/></div></div></figure><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es me"><img src="../Images/56d327fde53422fb09b9efbe55e288ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*6WFtpTFAIXZhxay7gqK2-g.png"/></div></figure><p id="18af" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">从keras获取Resnet50模型，对imagenet数据进行预处理。因此，我们不改变他们的权重，我们削减了最后一层，因为我们必须对3类进行分类。我们用RGB通道保持图像大小为64x64。</p><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="5ee1" class="lc ir hi ky b fi ld le l lf lg"># loading resnet model<br/>Rsnt_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))</span></pre><p id="b6b1" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">这里的主要技巧是微调最后一层，即resnet模型的输出。我们不直接将密集层连接到resnet输出。相反，我们添加了一些层，如GlobalAveragePooling2D，BatchNormalization。这里，批量标准化也有助于缩放来自上面层的输出。辍学也总是有助于减少联系。</p><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="3b72" class="lc ir hi ky b fi ld le l lf lg">av1 = GlobalAveragePooling2D()(Rsnt_model.output)<br/>fc1 = Dense(256, activation='relu')(av1)</span><span id="4184" class="lc ir hi ky b fi lh le l lf lg">drp1=Dropout(0.35)(fc1)<br/>fc2 = Dense(128, activation='relu')(drp1)<br/>drp2=Dropout(0.4)(fc2)<br/>bat_norm=BatchNormalization()(drp2)<br/>fc3 = Dense(68, activation='relu')(bat_norm)<br/>drp3=Dropout(0.25)(fc3)<br/>fc4 = Dense(34, activation='relu')(drp3)</span><span id="e745" class="lc ir hi ky b fi lh le l lf lg">out = Dense(3, activation='softmax')(fc3)</span><span id="dfa9" class="lc ir hi ky b fi lh le l lf lg">tl_model = Model(inputs=Rsnt_model.input,outputs=out)<br/>tl_model.summary()</span></pre><p id="75f4" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">我们将准确性作为衡量标准，将adam作为优化工具。我们运行该模型10个时期。</p><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="9e64" class="lc ir hi ky b fi ld le l lf lg"># compiling the model<br/>tl_model.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])</span><span id="697a" class="lc ir hi ky b fi lh le l lf lg"># fitting the model<br/>history = tl_model.fit_generator(training_set,<br/>                         steps_per_epoch = len(training_set),<br/>                         epochs = 10,<br/>                         validation_data = validation_set,<br/>                         validation_steps = len(validation_set),<br/>                         callbacks=[tensorboard3],<br/>                         verbose =2)</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/d6a86947e2316f89a30dde6eac7d31c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*Gh5looZKQ89k4H7WiNVVZQ.png"/></div></figure><div class="ko kp kq kr fd ab cb"><figure class="ln ij mg lp lq lr ls paragraph-image"><img src="../Images/be8c5869e59b2c925ff712b2c2ef83c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*BDujbUY-m4ZAjjKX4M72og.png"/></figure><figure class="ln ij mh lp lq lr ls paragraph-image"><img src="../Images/fbad7ddaae82e706bd6ae209a44a6e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*iadYzd9zLDhrfYPTAght7g.png"/><figcaption class="lj lk et er es ll lm bd b be z dx mi di mj lv translated">模型损失和精确度图表</figcaption></figure></div><p id="62d1" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">在具有最后一层调整的Resnet模型上，我们的准确度是96%,损耗是0.11。<br/>但是这次输了，我的<strong class="jq hj">竞技成绩</strong>是<strong class="jq hj"> 0.847 </strong>当时<strong class="jq hj">排名45 </strong>。这里还有一个技巧，就是使用像池化和批量标准化这样的层也有助于提高准确性。从图中我们可以看出，模型略有过度拟合，但这可以通过改变密集层之间的辍学率来改善。在这里，我们已经观察到，我们需要更少的历元来获得这种精度和损失，事实上，我们可以看到我们的损失在第4和第6个历元之间甚至减少到小于0.1。</p><h2 id="bc16" class="lc ir hi bd is mk ml mm iw mn mo mp ja jz mq mr je kd ms mt ji kh mu mv jm mw bi translated"><strong class="ak">所有型号对比:</strong></h2><pre class="ko kp kq kr fd kx ky kz la aw lb bi"><span id="54c3" class="lc ir hi ky b fi ld le l lf lg">from prettytable import PrettyTable<br/>    <br/>x = PrettyTable()</span><span id="aaf5" class="lc ir hi ky b fi lh le l lf lg">x.field_names = ["Model", "Loss", "train Accuracy", "Validation Accuracy","epochs"]</span><span id="5e83" class="lc ir hi ky b fi lh le l lf lg">x.add_row(["Basic CNN", 0.55, 75, 71.5,30])<br/>x.add_row(["VGG19", 0.71, 68, 58.4,10])<br/>x.add_row(["Resnet V1", 0.186, 93, 80,30])<br/>x.add_row(["Resnet  V2", 0.114, 96, 81,10])<br/>x.add_row(["Inceptionnet", 0.333, 86, 76,25])</span><span id="9ba3" class="lc ir hi ky b fi lh le l lf lg">print(x)</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es mx"><img src="../Images/4bd1a7650ade2d7bf895a47e7e12e355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*lGRet3MWztpC1wvoawXDmg.png"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">所有型号比较</figcaption></figure><p id="6fb1" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">这里我们可以看到，像VGG19这样的迁移学习模型表现不佳，因为它是19层的深度网络，没有任何跳跃层，Resnet在这方面有优势。所以Resnet表现不错。<br/>但是在Resnet中也存在时段差异，即在V1使用了30个时段，而在V2仅使用了10个时段，因此它显示了调整最后一层如何显著改变性能、损耗和精度。</p><h1 id="461a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论</h1><p id="24bb" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">Resnet模型在所有模型中表现较好。在迁移学习中，最后几层的调整是非常重要的，以便在更短的时间内获得有效的结果，就像在上面的Resnet中，V1用了30个周期，而V2只用了10个周期就获得了更好的准确性。像池化和批处理规范化这样的层在减少损失方面起着重要的作用。因此，增加时期的数量可能会增加过度拟合的机会，但通过调整迁移学习模型的最后几层，我们可以用更少的时期来减少过度拟合。</p><p id="06d2" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated"><strong class="jq hj">分析Vidhya排名</strong></p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es my"><img src="../Images/4de13733f908eb95316c52c60702d485.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8oZGcCqx9eie5xtGOBkQrw.png"/></div></div></figure><h1 id="718a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">未来的工作</h1><ul class=""><li id="ec03" class="mz na hi jq b jr js jv jw jz nb kd nc kh nd kl ne nf ng nh bi translated">改变密集层之间的漏失率可以进一步降低损耗。</li><li id="18d5" class="mz na hi jq b jr ni jv nj jz nk kd nl kh nm kl ne nf ng nh bi translated">对训练图像进行更严格的图像增强。</li><li id="fd23" class="mz na hi jq b jr ni jv nj jz nk kd nl kh nm kl ne nf ng nh bi translated">用不同的优化器试验密集层的大小和调整学习率。</li></ul><h1 id="f4da" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">资源:</h1><p id="0fd2" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">原数据集及竞赛规则:<br/><a class="ae mc" href="https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/" rel="noopener ugc nofollow" target="_blank">https://data hack . analyticsvidhya . com/contest/practice-problem-age-detection/</a></p></div><div class="ab cl nn no gp np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="hb hc hd he hf"><p id="bae5" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated"><strong class="jq hj">感谢您的关注和阅读我的作品</strong></p><p id="d20e" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">如果你喜欢这个故事，与你的朋友和同事分享吧！</p><p id="6ba7" class="pw-post-body-paragraph jo jp hi jq b jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh kw kj kk kl hb bi translated">还有，<strong class="jq hj">跟着我上</strong></p><div class="nu nv ez fb nw nx"><a href="https://www.linkedin.com/in/aditya-bhosle-07b0a9146" rel="noopener  ugc nofollow" target="_blank"><div class="ny ab dw"><div class="nz ab oa cl cj ob"><h2 class="bd hj fi z dy oc ea eb od ed ef hh bi translated">阿迪蒂亚·博斯勒</h2><div class="oe l"><h3 class="bd b fi z dy oc ea eb od ed ef dx translated">查看Aditya Bhosle在世界上最大的职业社区LinkedIn上的个人资料。Aditya的教育列在…</h3></div><div class="of l"><p class="bd b fp z dy oc ea eb od ed ef dx translated">www.linkedin.com</p></div></div></div></a></div></div></div>    
</body>
</html>