<html>
<head>
<title>Computational Humor Identification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算幽默识别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/unsupervised-computational-humor-classification-8615ad0f0134?source=collection_archive---------15-----------------------#2020-02-04">https://medium.com/analytics-vidhya/unsupervised-computational-humor-classification-8615ad0f0134?source=collection_archive---------15-----------------------#2020-02-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="c3c9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="c5ee" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这个项目是由佐治亚理工学院的Lew Lefton博士和Pete Ludovice博士提出的幽默理论激发的，该理论认为幽默是同一句话中高度熟悉和高度不一致的结果。这里熟悉的含义是双重的。首先，读者熟悉句子的主题和词汇。第二，可以合理使用彼此“熟悉”的单词和短语，组成一个可理解的句子。简而言之，熟悉意味着这个句子对读者有意义。另一方面，不一致意味着句子由一些不相容的词汇和话题混合在一起组成。这一理论与阿尔伯特·李的幽默理论[1]相联系，高度不一致对应于惊讶阶段，高度熟悉对应于解散阶段。</p><p id="a960" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在这个项目中，我专注于检测与句子连贯这一假设的不一致，从而包含高度熟悉性。我模拟了句子中的主题流动和变化，以便测量不一致。</p><h1 id="6202" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">方法</h1><p id="3043" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">首先，使用笑话数据集和新闻数据集建立潜在狄利克雷分配(LDA)模型，并产生100个不同的主题。对于每个句子，长度为4的滑动窗口在每次迭代时通过LDA模型输出一个主题。如果句子是W个单词长，那么将产生W-4个主题。每个话题都是一个字典映射<word: probability="">，表示如果基于这个话题生成，有<probability>的机会生成<word>。对于每个主题，使用手套单词嵌入模型将映射中的每个词汇转换成向量。一个主题中的所有词汇通过一个加权求和操作来组合，其中嵌入的向量作为加数，概率作为权重。在这个操作之后，每个主题可以被直接嵌入到一个向量中，这个向量具有关于这个主题的语义的信息。因此，W-4主题被转换成W-4向量。对于W-4个向量，计算每个相邻向量之间的欧几里德距离。最后，距离列表被归一化以输出表示主题变化的最终向量。在这个最终向量中，值越高，主题在该确切位置的变化越突然，因此暗示不一致。通过设置向量值的阈值，我能够以0.85的准确度对幽默句子进行分类。最佳阈值0.3123是通过随机重启的爬山随机优化找到的。</word></probability></word:></p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/d9c4ceae75bd9301084c19164b9c6334.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pfXkf040EJSu3_1vh612lQ.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">高级管道图</figcaption></figure><ul class=""><li id="b379" class="kw kx hi jf b jg kb jk kc jo ky js kz jw la ka lb lc ld le bi translated">代号:<a class="ae lf" href="https://github.com/JingboWang1997/HumorAnalysis" rel="noopener ugc nofollow" target="_blank">https://github.com/JingboWang1997/HumorAnalysis</a></li></ul><h1 id="4b7e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结果</h1><p id="e8df" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这个管道在500个笑话和500个新闻(非笑话)数据上进行了测试。</p><p id="3317" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">准确率:85%</p><p id="eb5b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">一些有趣的检测:</p><ol class=""><li id="69cc" class="kw kx hi jf b jg kb jk kc jo ky js kz jw la ka lg lc ld le bi translated"><strong class="jf hj">笑话检测</strong>(执行点)<strong class="jf hj"> : </strong></li></ol><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lh"><img src="../Images/4e311b707344e434f85403a3e266eef8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7zOUAi1BN9Kafm1BUOZUDw.png"/></div></div></figure><p id="0871" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">2.<strong class="jf hj">笑话设置检测</strong>(引入新话题的点)<strong class="jf hj"> : </strong></p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es li"><img src="../Images/a865096c397f6d921578823fcb810a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zpqb1Ki3NecKjBtIPxf7Pw.png"/></div></div></figure><p id="a972" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">3.<strong class="jf hj">双关检测</strong>(一个词包含在不同话题中的点):</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lj"><img src="../Images/71bf4170f8fbbe51d549b826b7d5302e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7TidW_P6lPgderfNxNUJjg.png"/></div></div></figure><p id="0a37" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">正如所展示的，这个管道可以检测幽默的各个方面，因为这个管道对新话题的引入很敏感。</p><h1 id="475c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">未来的工作</h1><ul class=""><li id="f30e" class="kw kx hi jf b jg jh jk jl jo lk js ll jw lm ka lb lc ld le bi translated">通用LDA</li><li id="ec51" class="kw kx hi jf b jg ln jk lo jo lp js lq jw lr ka lb lc ld le bi translated">更高的精度</li></ul><h1 id="5311" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">引用作品:</h1><p id="07f5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae lf" href="http://www.cogsys.org/papers/ACSvol4/paper6.pdf" rel="noopener ugc nofollow" target="_blank">【1】李，伯阳人。《幽默:一个包含计算因素的动态双过程理论》<em class="ls">认知系统进展</em>4(2016):57–74。</a></p></div></div>    
</body>
</html>