<html>
<head>
<title>Long Short Term Memory Networks(LSTM) in Tensor flow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流中的长短期记忆网络(LSTM)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/long-short-term-memory-networks-lstm-in-tensorflow-e986dac5cf27?source=collection_archive---------7-----------------------#2020-01-26">https://medium.com/analytics-vidhya/long-short-term-memory-networks-lstm-in-tensorflow-e986dac5cf27?source=collection_archive---------7-----------------------#2020-01-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2800" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章试图为理解RNN和LSTM提供一些直觉。本文还尝试使用TensorFlow框架将长短期记忆网络应用于python中的股票价格预测。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/132e230b5073629e5358a9675da95a14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pNnyZfCM5nH1fPUs"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">由<a class="ae ju" href="https://unsplash.com/@punttim?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">蒂姆·高</a>在<a class="ae ju" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="e452" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jv translated">当前神经网络是一类神经网络，特别适用于输出数据严重依赖于过去的输入序列的情况，或者简单地说，RNN被设计用于处理顺序/有序数据。因此，它们在时间序列预测，文本生成，序列学习和语音到文本理解中的应用，其中你的输出/决策不仅取决于时间' t '的当前输入，还取决于时间' t-n '的先前输入。</p><p id="116f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">在前馈神经网络中，数据通过一系列层向前传递，其中每一层都是特征的表示。当我们前进到下一层时，每一层都变成了特征的组合。当我们移动时，这些表示被丢弃。然而，对于RNN，它不仅考虑来自当前时间步的输入，而且考虑来自先前层的输出被一起传递，这负责RNN的记忆状态。</em></p><p id="9638" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">下面是RNN单元格</em> </strong>的表示</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ke"><img src="../Images/0624453e2ee5749586d10adfdaada16a.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*aEYBqmOIbYahtNr8-KsHnA.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">来源:<a class="ae ju" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></figcaption></figure><p id="ec15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">尽管与前馈网络相比，RNN可以更好地处理序列数据，但它们会遇到消失梯度或爆炸梯度问题。然而，为了克服这些问题，引入了LSTM，它是RNN的变体。为了更深入地了解，我建议阅读T21的这篇博客。</em></p><p id="99b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">什么是长短期记忆网络？</em>T29】</strong></p><p id="fa65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">长短期记忆(LSTM)网络是递归神经网络的一种变体，旨在记忆非常长的数据序列。在高层次上，LSTM网络有三个门，一个用于处理当前输入的“输入”门，一个用于在每个时间步产生预测的“输出”门，还有一个用于丢弃信息的“忘记”门。我推荐阅读<a class="ae ju" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"> Colah的博客</a>来了解完整的机制和变化。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kf"><img src="../Images/cace770db820b756504598221c2c97d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J5W8FrASMi93Z81NlAui4w.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">https://colah.github.io/posts/2015-08-Understanding-LSTMs/<a class="ae ju" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="e94d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集</strong></p><p id="1ade" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据可以在<a class="ae ju" href="https://www.kaggle.com/dgawlik/nyse" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到。该数据集包含各种股票报价机大约5年的历史股价。然而，我选择<a class="ae ju" href="https://finance.yahoo.com/quote/MSFT/" rel="noopener ugc nofollow" target="_blank">微软</a> ticker进行这个模型构建活动。</p><p id="bf75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">导入依赖关系</strong></p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="kg kh l"/></div></figure><p id="cc13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">读取数据集</strong></p><p id="9a34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在读取数据集并执行数据探索和预处理。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="kg kh l"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ki"><img src="../Images/f882bea60e99a47627588611677ff729.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xIWzNhKxjaPWCYEKa_Avsw.png"/></div></div></figure><p id="3e6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">标准化和分割数据</strong></p><p id="84e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">规范化数据有助于算法收敛。我用过sklearn的MinMaxScaler方法。将数据分成训练集和测试集，以3:1的比例构建模型。此外，我们正在创建新的功能，即一个时间滞后(t-1)变量，作为我们的功能工程的一部分。因为股票价格取决于最后一天的收盘价。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="kg kh l"/></div></figure><p id="6e6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型构建</strong></p><p id="df28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用tensorflow的Keras建立我们的LSTM模型，然后像下面这样训练它。然而，在转换到LSTM模型之前，我们需要对输入数据集进行整形。我们使用Adam作为优化器，使用均方差作为模型验证指标。为了超参数化学习率，我们可以使用keras回调API的ReduceLROnPlateau和ModelCheckpoint在迭代期间保存最佳模型。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="kg kh l"/></div></figure><p id="f26a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型训练vs验证损失比较</strong></p><p id="fdc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在对这些参数进行70个时期的训练后，训练损失为2.68，验证数据集损失为19.74。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kj"><img src="../Images/a19f5db2b47eb2604053ba942e8fde20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*20glXsf_2nGplesRLun4eg.png"/></div></div></figure><p id="c796" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结论</strong></p><p id="e4c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从下面的<strong class="ih hj">实际与预测股价对比</strong>中我们可以看到，我们的模型与实际股价趋势预测非常接近。然而，LSTMs强大的是用于分析时间序列和序列数据，还有其他传统的算法，如ARIMA，移动平均，facebook的fbprophet等来处理时间序列数据。源代码是我的<a class="ae ju" href="https://github.com/nayaksu7/StockPrediction_Tensorflow" rel="noopener ugc nofollow" target="_blank"> githubrepo </a>供进一步参考和评论。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kk"><img src="../Images/a073f4545bd92f0ae4fb866076f639c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*thlcActCbrxtgv9lPH8OJA.png"/></div></div></figure></div></div>    
</body>
</html>