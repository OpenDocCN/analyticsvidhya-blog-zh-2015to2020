<html>
<head>
<title>Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/neural-networks-simply-explained-79f759468867?source=collection_archive---------28-----------------------#2020-05-26">https://medium.com/analytics-vidhya/neural-networks-simply-explained-79f759468867?source=collection_archive---------28-----------------------#2020-05-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/232b6a856af5d099714d61833a20cd62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9D3EMl7-g0j9ihtp6YXzzQ.png"/></div></div></figure><h1 id="d6d8" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是神经网络？</h1><p id="6011" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">神经网络由一系列用于模拟人脑的机器学习技术组成。神经网络能够提取数据中隐藏的模式；他们能够通过将一堆节点相互连接(密集)来做到这一点。每个节点一起工作，找出隐藏的细节，然后将其传递给下一个节点，以找到这些细节中的联系。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es km"><img src="../Images/3da5c927411f5ea3f4095e9b9524b4d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hiMWlghq1xY1bvVTH6J_zg.jpeg"/></div></div></figure><h2 id="8a14" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">输入层</h2><p id="68f1" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">神经网络的输入层是我们在模型中使用的变量/特征列表。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/74d5d0febb7f83c7ae9b98aeca6d6a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nX6L9rclTnx0Hph5i01wzg.jpeg"/></div></div></figure><h2 id="ab64" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">砝码</h2><p id="f367" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在逻辑回归的情况下，这里的权重是我们为适应模型而调整的系数。在其他神经网络中，权重是对任何输入变量的标量变换和矩阵乘法的组合。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/d96f504bfa7053e2bc07493358620beb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*Dd5JHauRBU_horvnuX402Q.png"/></div></div></figure><h2 id="e22d" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">激活功能</h2><p id="ba63" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在逻辑回归中，我们使用一个<strong class="jq hj"> sigmoid </strong>激活函数。你可能看到的其他选项有<strong class="jq hj">线性</strong>、<strong class="jq hj"> Tanh </strong>和<strong class="jq hj"> ReLU </strong>。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/653ba35c81649419ba67a5042a578c16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8SVj1DckQ70wix1oklS8A.png"/></div></div></figure><h2 id="cdb6" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">更深的网络=更多的隐藏层</h2><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es li"><img src="../Images/1cbccd804635fe6c262b66ccd8dee329.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*9B7vt9e7uNoiSxE__6Be0Q.png"/></div></figure><h2 id="5d77" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">为什么要隐藏图层？</h2><p id="01b6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">它们是隐藏的，因为我们没有指定它们。它们可以表示潜在的因素(如矩阵分解)，或者将现有的变量组合成新的特征。</p><h2 id="c329" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">反向传播—调整权重</h2><p id="7ccf" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">此外，神经网络是动态的，在一定数量的数据点通过模型后，权重将<em class="lj">更新</em>，着眼于优化我们的损失函数。(回想一下生物神经元，这就像是修改它们的激活电位。)通常，这是通过使用某种形式的梯度下降来完成的，但是<a class="ae lk" href="https://arxiv.org/abs/1605.02026" rel="noopener ugc nofollow" target="_blank">已经尝试了其他方法</a>。</p><h1 id="e808" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">卷积神经网络</h1><p id="c03c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">CNN主要用于图像识别/分类。它们可以用于视频分析、NLP(情感分析、主题建模)和语音识别。今天我们将讨论如何使用CNN对图像进行分类。</p><h2 id="a310" class="kr ir hi bd is ks kt ku iw kv kw kx ja jz ky kz je kd la lb ji kh lc ld jm le bi translated">计算机如何看图像</h2><p id="6f15" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">对计算机来说，图像是一个3D对象——由3个矩阵组成——每个矩阵对应一种原色，可以以不同的强度组合来创建不同的颜色。矩阵中的每个元素代表一个像素的位置，并且包含一个0到255之间的数字，该数字指示该像素中相应原色的强度。</p></div></div>    
</body>
</html>