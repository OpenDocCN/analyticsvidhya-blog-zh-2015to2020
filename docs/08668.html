<html>
<head>
<title>Carnivores Image Classification using Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Google Colab 的食肉动物图像分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/carnivores-image-classification-using-google-colab-add14f7c3e4f?source=collection_archive---------4-----------------------#2020-08-08">https://medium.com/analytics-vidhya/carnivores-image-classification-using-google-colab-add14f7c3e4f?source=collection_archive---------4-----------------------#2020-08-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="d098" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">具有数据增强和迁移学习能力的卷积神经网络！</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/474eabb8de7ca96995eec3d7c71f0967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*CUS6fAT0rDjrgig3"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es jf"><img src="../Images/26cedf31ba9907c08a92026f827d8969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*7C3LbPYhJMJrSBdZpiDiBA.png"/></div></figure><h1 id="6f89" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">总说明</h1><p id="6490" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">美国有线电视新闻网</p><p id="59bb" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">卷积神经网络(CNN)是大多数计算机视觉技术的基础。与传统的<a class="ae kz" href="https://missinglink.ai/guides/neural-network-concepts/perceptrons-and-multi-layer-perceptrons-the-artificial-neuron-at-the-core-of-deep-learning/" rel="noopener ugc nofollow" target="_blank">多层感知器</a>架构不同，它使用两种称为“卷积”和“汇集”的操作来将图像简化为其基本特征，并使用这些特征来理解和分类图像。</p><div class="la lb ez fb lc ld"><a href="https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hj fi z dy li ea eb lj ed ef hh bi translated">去神秘化的卷积神经网络结构</h2><div class="lk l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">www.analyticsvidhya.com</p></div></div><div class="ll l"><div class="lm l ln lo lp ll lq jd ld"/></div></div></a></div><p id="e69b" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated"><strong class="ka hj">数据增强</strong></p><p id="2c3e" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">这是一种可用于通过在数据集中创建图像的修改版本来人为扩展训练数据集大小的技术。在更多数据上训练深度学习神经网络模型可以创建图像的变体，这些变体可以提高 fit 模型将它们已经学习到的知识推广到新图像的能力。</p><div class="la lb ez fb lc ld"><a href="https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hj fi z dy li ea eb lj ed ef hh bi translated">数据扩充|在数据有限的情况下如何使用深度学习</h2><div class="lk l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">nanonets.com</p></div></div><div class="ll l"><div class="lr l ln lo lp ll lq jd ld"/></div></div></a></div><p id="cd52" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated"><strong class="ka hj">迁移学习</strong></p><p id="1b14" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">这是一种克服孤立的学习范式，并利用为一项任务获得的知识来解决相关问题的思想。我们冻结网络的早期卷积层，只训练最后几层进行预测。其思想是卷积层提取适用于所有图像的一般、低级特征，而后面的层识别特定特征。</p><div class="la lb ez fb lc ld"><a href="https://data-flair.training/blogs/transfer-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hj fi z dy li ea eb lj ed ef hh bi translated">用 CNN-data flaer 实现深度学习的迁移学习</h2><div class="lk l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">数据-天赋.培训</p></div></div><div class="ll l"><div class="ls l ln lo lp ll lq jd ld"/></div></div></a></div><h1 id="c300" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">为什么选择 Google Colab？</h1><p id="2eb3" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">在普通笔记本电脑上训练深度学习模型需要大量的计算能力，并且经常会无休止地运行。这可能会阻止初学者亲自探索深度学习的世界。</p><p id="d4e6" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">有了 Colab，你可以通过利用谷歌硬件的能力在谷歌的云服务器上执行代码，包括 GPU 和 TPU，而不管你的机器的能力如何。</p><h2 id="a4d2" class="lt jh hi bd ji lu lv lw jm lx ly lz jq kh ma mb js kl mc md ju kp me mf jw mg bi translated">创建新笔记本</h2><p id="0471" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">要在 Colab 上创建新笔记本，打开<a class="ae kz" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank">https://colab.research.google.com/</a>，它会自动显示你之前的笔记本，并给出创建新笔记本的选项。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mh"><img src="../Images/f036f37c075ca218ebb39042f9bd76b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/0*pNPlqJY4qIzQlbVa.png"/></div></figure><p id="17e4" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">在这里，您可以单击“新建笔记本”来启动一个新笔记本，并开始在其中运行您的代码。默认是 Python 3 笔记本。</p><p id="7bd8" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">默认情况下，你在 Google Colab 中创建的所有笔记本都存储在你的 Google Drive 中。在你的驱动器中有一个名为“Colab 笔记本”的文件夹，在那里你可以找到所有你从 Google Colab 创建的笔记本。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="er es mi"><img src="../Images/1639e3a6779f2a16b701e4638ba783f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*y1XqFtYFvraBUghM.png"/></div></div></figure><p id="4ef1" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">要从 Colab 中的 Drive 打开笔记本，右键单击所需的笔记本，然后“打开方式&gt; Google 协同实验室”。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="er es mn"><img src="../Images/397ca93514f1066959e5b48daa7af8c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0XyfLjK1rdNXC75Y.png"/></div></div></figure><h2 id="e721" class="lt jh hi bd ji lu lv lw jm lx ly lz jq kh ma mb js kl mc md ju kp me mf jw mg bi translated">从驱动器加载数据</h2><p id="71b0" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">你可以通过将 Google Drive 安装到笔记本电脑上来轻松加载数据。为此，请在笔记本中键入以下代码。</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="568c" class="lt jh hi mp b fi mt mu l mv mw">from google.colab import drive<br/>drive.mount('/content/drive')</span></pre><p id="467a" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">它会给你一个打开的链接，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="er es mx"><img src="../Images/451ad592a78e58f1e9a1bbf5c058eb73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VtU5CKRb4nUJaefl.png"/></div></div></figure><ul class=""><li id="e8c9" class="my mz hi ka b kb ku ke kv kh na kl nb kp nc kt nd ne nf ng bi translated">转到链接</li><li id="10bd" class="my mz hi ka b kb nh ke ni kh nj kl nk kp nl kt nd ne nf ng bi translated">登录您的 Google 帐户</li><li id="a430" class="my mz hi ka b kb nh ke ni kh nj kl nk kp nl kt nd ne nf ng bi translated">复制代码</li><li id="85ff" class="my mz hi ka b kb nh ke ni kh nj kl nk kp nl kt nd ne nf ng bi translated">粘贴到笔记本上</li></ul><p id="45a2" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">现在如果你在你的“<strong class="ka hj">文件”</strong>部分看到，你会找到你的“<strong class="ka hj">驱动器”</strong>。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nm"><img src="../Images/36812b767b8125821e5c7c495ae6cfd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*-xN_VyI0LrcGcgj49JK54Q.png"/></div></figure><p id="ddce" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">假设你上传了食肉动物文件夹下的图片。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nn"><img src="../Images/75d502a370630a5677a8555fb0031623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*qM6N9ygXlJ1_zX3lKIkH4w.png"/></div></figure><p id="2a5d" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">您可以通过复制图像的路径并将其粘贴到路径变量中来获取图像。</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="a88e" class="lt jh hi mp b fi mt mu l mv mw">train_path='/content/drive/My Drive/carnivores/train'<br/>test_path='/content/drive/My Drive/carnivores/test'</span></pre><h1 id="b5df" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">食肉动物图像分类</h1><p id="2196" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">该数据由来自 3 大洲的 4 种食肉动物的图像组成→猎豹和鬣狗(非洲)、美洲虎(南美洲)和老虎(亚洲)。训练集由 3600 幅图像组成(每种食肉动物 900 幅)，测试集有 400 幅图像(每种食肉动物 100 幅)。数据中可供学习的例子非常少，因此这是一个具有挑战性的机器学习问题，但也是一个现实的问题:在许多现实世界的用例中，即使是小规模的数据收集也可能非常昂贵，有时几乎是不可能的。</p><p id="6fa6" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">要下载数据，请访问以下链接:</p><div class="la lb ez fb lc ld"><a href="https://drive.google.com/drive/folders/1PDjKvn9TqB5jTxuaPts4Fe05kLWWB0SX?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hj fi z dy li ea eb lj ed ef hh bi translated">食肉动物-谷歌驱动</h2><div class="lk l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">drive.google.com</p></div></div><div class="ll l"><div class="no l ln lo lp ll lq jd ld"/></div></div></a></div><div class="iy iz ja jb fd ab cb"><figure class="np jc nq nr ns nt nu paragraph-image"><img src="../Images/85fdded7893fc1a23ecaa7a4c9784668.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*iWyj9MqIIH_sDWwHcUxtYw.jpeg"/></figure><figure class="np jc nq nr ns nt nu paragraph-image"><img src="../Images/b9532ebb530b526abda080b599d6effc.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*bpt5Gk2pAyYSFq586aKa1w.jpeg"/></figure></div><div class="ab cb"><figure class="np jc nq nr ns nt nu paragraph-image"><img src="../Images/61d1550aa33f34a8893765386a57ae73.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*EkYyuF-Ti5urK-qjzr_36g.jpeg"/></figure><figure class="np jc nq nr ns nt nu paragraph-image"><img src="../Images/7de28ade3212d8d696afbba08a3f2216.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*1xubOLkCWcO5wi--OZom1Q.jpeg"/></figure></div><p id="f81b" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">我们将使用 Keras 深度学习神经网络库，它提供了通过<em class="nv"> ImageDataGenerator </em>类使用图像数据增强来拟合模型的能力。我们还将使用预训练的 InceptionV3 模型进行迁移学习。</p><h1 id="a952" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">导入包</h1><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="1524" class="lt jh hi mp b fi mt mu l mv mw">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import sklearn<br/>import mathimport warnings<br/>warnings.filterwarnings("ignore")</span></pre><h1 id="1c0c" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">作为特征提取器的预训练 CNN 模型</h1><p id="86a1" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">让我们利用 Keras，加载 InceptionV3 模型，并冻结卷积块，以便我们可以将它用作图像特征提取器。</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="19ec" class="lt jh hi mp b fi mt mu l mv mw">import keras<br/>from keras.applications.inception_v3 import InceptionV3<br/>from keras.models import Model,load_model</span><span id="b678" class="lt jh hi mp b fi nw mu l mv mw">conv_base =  InceptionV3(weights='imagenet',include_top=False,<br/>                         input_shape=(300, 300, 3))</span><span id="93a0" class="lt jh hi mp b fi nw mu l mv mw">output = conv_base.layers[-1].output<br/>output = keras.layers.Flatten()(output)<br/>model_tl = Model(conv_base.input, output)</span><span id="fd27" class="lt jh hi mp b fi nw mu l mv mw">model_tl.trainable = False</span><span id="26cc" class="lt jh hi mp b fi nw mu l mv mw">for layer in model_tl.layers:<br/>    layer.trainable = False</span><span id="5372" class="lt jh hi mp b fi nw mu l mv mw">layers = [(layer, layer.name, layer.trainable) for layer in  <br/>               model_tl.layers]<br/>model_layers=pd.DataFrame(layers, columns=['Layer Type', 'Layer  <br/>                 Name', 'Layer Trainable'])</span><span id="437d" class="lt jh hi mp b fi nw mu l mv mw">print(model_layers) </span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nx"><img src="../Images/a9f022e9e80fd2d9d5d3f5ac48c4b598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*llXLRXNKddpeL4LbJKXT8w.png"/></div></figure><p id="1fcb" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">InceptionV3 模型的所有层现在都被冻结了(Layer Trainable 对于所有层都是假的)，因为我们不希望它们的权重在模型训练期间发生变化。InceptionV3 模型中的最后一个激活特征映射为我们提供了瓶颈特征，然后可以将其展平并馈入完全连接的深度神经网络分类器。</p><h1 id="97df" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">数据预处理和数据扩充</h1><p id="ed3c" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">为了充分利用我们为数不多的训练示例，我们将通过一些随机转换来“扩充”它们，以便我们的模型永远不会看到两次完全相同的图片。这有助于防止过度拟合，并帮助模型更好地概括。</p><p id="2c81" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">在 Keras 中，这可以通过<em class="nv"> ImageDataGenerator </em>类来完成。本课程允许您:</p><ul class=""><li id="9023" class="my mz hi ka b kb ku ke kv kh na kl nb kp nc kt nd ne nf ng bi translated">在训练过程中，配置要对图像数据执行的随机变换和归一化操作</li><li id="37de" class="my mz hi ka b kb nh ke ni kh nj kl nk kp nl kt nd ne nf ng bi translated">通过<code class="du ny nz oa mp b">.flow_from_directory(directory)</code>实例化增强图像批次(及其标签)的生成器。然后，这些生成器可以与接受数据生成器作为输入的 Keras 模型方法一起使用。</li></ul><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="084d" class="lt jh hi mp b fi mt mu l mv mw">from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten<br/>from keras.preprocessing.image import ImageDataGenerator<br/>from keras import optimizers</span><span id="2536" class="lt jh hi mp b fi nw mu l mv mw">test_size=400<br/>batch_size=32<br/>epochs=25</span><span id="eddf" class="lt jh hi mp b fi nw mu l mv mw">train_path='/content/drive/My Drive/carnivores/train'<br/>test_path='/content/drive/My Drive/carnivores/validation'</span><span id="eefa" class="lt jh hi mp b fi nw mu l mv mw">target_size=(300,300) #resize all images to 300x300</span><span id="3eae" class="lt jh hi mp b fi nw mu l mv mw">train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3,  <br/>                                   rotation_range=50,<br/>                                   width_shift_range=0.2, <br/>                                   height_shift_range=0.2, <br/>                                   shear_range=0.2,<br/>                                   horizontal_flip=True,<br/>                                   brightness_range = [0.8, 1.2],<br/>                                   fill_mode='nearest',        <br/>                                   <strong class="mp hj">validation_split=0.2</strong>)</span><span id="8cfb" class="lt jh hi mp b fi nw mu l mv mw">test_datagen = ImageDataGenerator(rescale=1./255)</span><span id="b746" class="lt jh hi mp b fi nw mu l mv mw"># The list of classes will be automatically inferred from the subdirectory names/structure under train_dir</span><span id="ead6" class="lt jh hi mp b fi nw mu l mv mw">train_generator = train_datagen.flow_from_directory(<br/>                  <strong class="mp hj">train_path,</strong><br/>                  target_size=target_size,#  <br/>                  batch_size=batch_size,<br/>                  class_mode='categorical',<br/>                  <strong class="mp hj">subset='training'</strong>)</span><span id="4eaa" class="lt jh hi mp b fi nw mu l mv mw">validation_generator = train_datagen.flow_from_directory(<br/>                       <strong class="mp hj">train_path,</strong><br/>                       target_size=target_size,<br/>                       batch_size=batch_size,<br/>                       class_mode='categorical',<br/>                       <strong class="mp hj">subset='validation'</strong>)</span></pre><p id="74fe" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">Keras 现在使用 ImageDataGenerator 从单个目录中添加了训练/验证分割。使用 ImageDataGenerator 中的 validation_split，将训练数据分成 2 个子集→训练和验证。</p><h1 id="f69f" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">建筑模型架构</h1><p id="6150" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">现在让我们构建我们的深度神经网络分类器的架构，它将把上述平坦化的瓶颈特征作为输入。</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="c311" class="lt jh hi mp b fi mt mu l mv mw">from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten<br/>from keras import optimizers</span><span id="be63" class="lt jh hi mp b fi nw mu l mv mw"># building a linear stack of layers with the sequential model<br/>model =Sequential()<br/>model.add(model_tl)</span><span id="a788" class="lt jh hi mp b fi nw mu l mv mw"># hidden layer<br/>model.add(Dense(128, activation='relu'))<br/>model.add(Dropout(0.2))</span><span id="9d80" class="lt jh hi mp b fi nw mu l mv mw"># output layer<br/>model.add(Dense(4, activation='softmax'))</span><span id="79ee" class="lt jh hi mp b fi nw mu l mv mw"># compiling the sequential model<br/>model.compile(loss='categorical_crossentropy',<br/>              optimizer=optimizers.RMSprop(lr=1e-4),<br/>              metrics=['acc'])</span><span id="ffe3" class="lt jh hi mp b fi nw mu l mv mw">print(model.summary())</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ob"><img src="../Images/e160e3358a3e254059c0ccd8e0c87880.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*6pNpaXo_nEv8dtT6y20t5w.png"/></div></figure><h1 id="7fa0" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">保存模型检查点</h1><p id="c15f" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">Google Colab 提供了一次 12 小时的最大 gpu 运行时间,“理想情况下”,如果他们检测到不活动(90 分钟)或有重负载时，它可能会在此之前断开连接。因此，我们将在拟合模型之前使用 Keras 中的回调来保存检查点，这样我们的进度就不会丢失。</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="c7fb" class="lt jh hi mp b fi mt mu l mv mw">from keras.callbacks import *</span><span id="0150" class="lt jh hi mp b fi nw mu l mv mw">filepath="/content/drive/My Drive/MyCNN/epochs:{epoch:03d}-val_acc: <br/>          {val_acc:.3f}.hdf5"</span><span id="ff6c" class="lt jh hi mp b fi nw mu l mv mw">checkpoint = ModelCheckpoint(filepath, <br/>                             monitor='val_acc', <br/>                             verbose=1,<br/>                             save_best_only=False,<br/>                             save_freq='epoch',     <br/>                             mode='max')</span><span id="fe05" class="lt jh hi mp b fi nw mu l mv mw">callbacks_list = [checkpoint]</span></pre><ul class=""><li id="4ec7" class="my mz hi ka b kb ku ke kv kh na kl nb kp nc kt nd ne nf ng bi translated"><strong class="ka hj"> filepath : </strong>用于 drive 中名为<strong class="ka hj"> <em class="nv"> MyCNN </em> </strong>的文件夹(在你的 drive 中创建这个新文件夹)，每个文件将存储有纪元编号和验证精度，这些文件包含你的神经网络的权重。</li><li id="5bb2" class="my mz hi ka b kb nh ke ni kh nj kl nk kp nl kt nd ne nf ng bi translated"><strong class="ka hj"> ModelCheckpoint : </strong>对于上述代码中传递的参数，它监视验证精度，并在每个时期后存储验证精度。</li><li id="ba0e" class="my mz hi ka b kb nh ke ni kh nj kl nk kp nl kt nd ne nf ng bi translated"><strong class="ka hj"> callbacks_list : </strong>创建一个列表，这样你就可以在这个列表中添加任何其他的回调函数，并在训练时将它传递给 fit 函数。</li></ul><h1 id="5952" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">断开后恢复训练</h1><ul class=""><li id="3ee2" class="my mz hi ka b kb kc ke kf kh oc kl od kp oe kt nd ne nf ng bi translated">在新的运行时装载驱动器</li><li id="23e2" class="my mz hi ka b kb nh ke ni kh nj kl nk kp nl kt nd ne nf ng bi translated">使用相同的架构并创建模型</li><li id="fc8c" class="my mz hi ka b kb nh ke ni kh nj kl nk kp nl kt nd ne nf ng bi translated"><code class="du ny nz oa mp b">model.load_weights('/content/drive/My Drive/MyCNN/epochs:020-val_acc:0.985.hdf5')</code>从一个检查点加载重量，该检查点在第 20 个时期达到 98.5%的验证准确度。</li><li id="b0c1" class="my mz hi ka b kb nh ke ni kh nj kl nk kp nl kt nd ne nf ng bi translated">然后编译拟合模型(在 model.fit()中增加一个额外的参数→initial _ epoch = 20；直到你的模型被保存的最后一个纪元)，从第 21 个纪元继续等等。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="er es of"><img src="../Images/ae90382c1396e6fee5b19e0783c5b9fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t5ZckhykPZYq-l1Dj6if1w.png"/></div></div></figure><h1 id="5ce7" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">培训模式</h1><p id="7870" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">我们将使用带有检查点的体系结构，并使模型适合训练数据。</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="a8b0" class="lt jh hi mp b fi mt mu l mv mw">history = model.fit(<br/>          train_generator,<br/>          steps_per_epoch=train_generator.samples//batch_size,    <br/>          validation_data=validation_generator,<br/>          validation_steps=validation_generator.samples//batch_size,<br/>          epochs=epochs,<br/>          verbose=1,<br/>          shuffle=True,<br/>          <strong class="mp hj">callbacks=callbacks_list</strong>)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="er es og"><img src="../Images/da00ac7107b672773ec45d38f434775d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qDvm6eIx5O4VjqUgdJYxzg.png"/></div></div></figure><p id="e859" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">您可以清楚地看到，它在每个时期后开始保存模型</p><h1 id="1164" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">模型性能</h1><p id="3cbf" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">为了评估和可视化模型性能，我们创建了一个函数:</p><ul class=""><li id="9e77" class="my mz hi ka b kb ku ke kv kh na kl nb kp nc kt nd ne nf ng bi translated"><strong class="ka hj">学习曲线:</strong>在每个时期后绘制<strong class="ka hj"> </strong>模型精度和损失，以了解模型是否合适。</li></ul><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="bc1d" class="lt jh hi mp b fi mt mu l mv mw"># Model evaluation</span><span id="10fa" class="lt jh hi mp b fi nw mu l mv mw">scores_train = model.evaluate(train_generator,verbose=1)<br/>scores_validation = model.evaluate(validation_generator,verbose=1)<br/>print("Train Accuracy: %.2f%%" % (scores_train[1]*100))<br/>print("Validation Accuracy: %.2f%%" % (scores_validation[1]*100))</span><span id="173d" class="lt jh hi mp b fi nw mu l mv mw">#For plotting Accuracy and Loss</span><span id="f3b5" class="lt jh hi mp b fi nw mu l mv mw">def LearningCurve(history):<br/># summarize history for accuracy<br/>plt.plot(history.history['acc'])<br/>plt.plot(history.history['val_acc'])<br/>plt.title('model accuracy')<br/>plt.ylabel('accuracy')<br/>plt.xlabel('epoch')<br/>plt.legend(['train', 'validation'], loc='upper left')<br/>plt.show()</span><span id="27a0" class="lt jh hi mp b fi nw mu l mv mw"># summarize history for loss<br/>plt.plot(history.history['loss'])<br/>plt.plot(history.history['val_loss'])<br/>plt.title('model loss')<br/>plt.ylabel('loss')<br/>plt.xlabel('epoch')<br/>plt.legend(['train', 'validation'], loc='upper left')<br/>plt.show()</span><span id="0721" class="lt jh hi mp b fi nw mu l mv mw">LearningCurve(history)<br/></span><span id="a547" class="lt jh hi mp b fi nw mu l mv mw">#Save the trained model to a file </span><span id="7ba3" class="lt jh hi mp b fi nw mu l mv mw">model_weight_file='/content/drive/MyDrive/MyCNN/<br/>                   carnivores_tlearn_img_aug_cnn.h5'<br/>model.save(model_weight_file)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es oh"><img src="../Images/a4c8f898ce99bbd935812f09a15f1a83.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*v4A3UFvCM9cIq-8h8rY0bg.png"/></div></figure><p id="0e51" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">我们可以看到，我们的模型的训练准确率为<strong class="ka hj"> 99.51% </strong>，验证准确率为<strong class="ka hj"> 99.03%。</strong>训练和验证精度彼此相当接近，表明该模型是很好的拟合。</p><h1 id="7e4f" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">做预测</h1><p id="db3c" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">我们将使用测试数据进行预测，看看我们的模型在看不见的数据上表现如何。</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="7e50" class="lt jh hi mp b fi mt mu l mv mw"># We take the ceiling because we do not drop the remainder of the batch</span><span id="3159" class="lt jh hi mp b fi nw mu l mv mw">compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / batch_size))</span><span id="4872" class="lt jh hi mp b fi nw mu l mv mw">test_steps = compute_steps_per_epoch(test_size)</span><span id="aa06" class="lt jh hi mp b fi nw mu l mv mw">test_generator = test_datagen.flow_from_directory(<br/>                 test_path,<br/>                 target_size=target_size, <br/>                 batch_size=batch_size,<br/>                 class_mode=None,<br/>                 shuffle=False)</span><span id="47df" class="lt jh hi mp b fi nw mu l mv mw">test_generator.reset()</span><span id="0ee9" class="lt jh hi mp b fi nw mu l mv mw">#Calling the saved model for making predictions<br/>tl_img_aug_cnn = load_model(model_weight_file)</span><span id="aed6" class="lt jh hi mp b fi nw mu l mv mw">pred=tl_img_aug_cnn.predict(test_generator,<br/>                            verbose=1,<br/>                            steps=test_steps)</span><span id="42c3" class="lt jh hi mp b fi nw mu l mv mw">predicted_class_indices=np.argmax(pred,axis=1)<br/>labels = (test_generator.class_indices)<br/>labels = dict((v,k) for k,v in labels.items())<br/>predictions = [labels[k] for k in predicted_class_indices]</span><span id="ad51" class="lt jh hi mp b fi nw mu l mv mw">filenames=test_generator.filenames<br/>results=pd.DataFrame({"Filename":filenames,<br/>                      "Predictions":predictions})<br/></span><span id="090f" class="lt jh hi mp b fi nw mu l mv mw">#create a function for visualizing model performance</span><span id="7ac0" class="lt jh hi mp b fi nw mu l mv mw">import seaborn as sns</span><span id="95d9" class="lt jh hi mp b fi nw mu l mv mw">def PerformanceReports(conf_matrix,class_report,labels):<br/>    ax= plt.subplot()<br/>    sns.heatmap(conf_matrix, annot=True,ax=ax)<br/>    #labels, title and ticks<br/>    ax.set_xlabel('Predicted labels')<br/>    ax.set_ylabel('True labels')<br/>    ax.set_title('Confusion Matrix')<br/>    ax.xaxis.set_ticklabels(labels)<br/>    ax.yaxis.set_ticklabels(labels)<br/>    plt.show()<br/>    ax= plt.subplot()<br/>    sns.heatmap(pd.DataFrame(class_report).iloc[:-1, :].T,  <br/>                annot=True,ax=ax)<br/>    ax.set_title('Classification Report')<br/>    plt.show()</span><span id="fbc7" class="lt jh hi mp b fi nw mu l mv mw">from sklearn.metrics import confusion_matrix,classification_report,accuracy_score</span><span id="bcc0" class="lt jh hi mp b fi nw mu l mv mw">labels=['cheetah','hyena','jaguar','tiger']<br/>test_labels = [fn.split('/')[0] for fn in filenames]</span><span id="d6e2" class="lt jh hi mp b fi nw mu l mv mw">cm=confusion_matrix(test_labels,predictions)<br/>print(cm)</span><span id="43a1" class="lt jh hi mp b fi nw mu l mv mw">cr=classification_report(test_labels, predictions)<br/>class_report=classification_report(test_labels, predictions,<br/>                                   target_names=labels,<br/>                                   output_dict=True)<br/>print(cr)</span><span id="bbe2" class="lt jh hi mp b fi nw mu l mv mw">PerformanceReports(cm,class_report,labels)</span></pre><p id="3100" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">使用<code class="du ny nz oa mp b">.predict()</code>函数将给出概率输出，因此我们需要将它们转换成类别号。在这种情况下，它是 4 个类，所以类号是 0，1，2 和 3。</p><p id="80f0" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated"><code class="du ny nz oa mp b">predicted_class_indices=np.argmax(pred,axis=1)</code></p><p id="814a" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">下一步是我们需要类的名字:</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="4ed4" class="lt jh hi mp b fi mt mu l mv mw">labels = (train_generator.class_indices)<br/>labels = dict((v,k) for k,v in labels.items())<br/>predictions = [labels[k] for k in predicted_class_indices]</span></pre><p id="43c7" class="pw-post-body-paragraph jy jz hi ka b kb ku ij kd ke kv im kg kh kw kj kk kl kx kn ko kp ky kr ks kt hb bi translated">类别编号将由类别名称替换。最后，将它安排在一个数据帧中，并在图像名称后附加预测的类。</p><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="0536" class="lt jh hi mp b fi mt mu l mv mw">filenames=test_generator.filenames<br/>results=pd.DataFrame({"Filename":filenames,<br/>                      "Predictions":predictions})</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es oi"><img src="../Images/61b8bc989093acbe8625c2a76435ad42.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*i-Hlc_R2W5ZutX5ntQdcVw.png"/></div></figure><div class="iy iz ja jb fd ab cb"><figure class="np jc oj nr ns nt nu paragraph-image"><img src="../Images/e73e5253dc5f9c7b52980d2fad7f6fda.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*JwwQAg9c87sgGgJrbvFc1g.png"/></figure><figure class="np jc ok nr ns nt nu paragraph-image"><img src="../Images/18c4b677830e0af9dd9deec81d609ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*u1V20fRFlvLvRii_hPiUOg.png"/></figure></div><h1 id="68c8" class="jg jh hi bd ji jj jk jl jm jn jo jp jq io jr ip js ir jt is ju iu jv iv jw jx bi translated">在你走之前</h1><p id="5541" class="pw-post-body-paragraph jy jz hi ka b kb kc ij kd ke kf im kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated"><strong class="ka hj"> <em class="nv">感谢</em> </strong> <em class="nv">的阅读！请随意将这种方法应用于您的图像分类问题。如果你有任何困难或疑问，请在下面评论。非常感谢你的支持。如果你想和我联系，打 jatin.kataria94@gmail.com 找我。</em></p></div></div>    
</body>
</html>