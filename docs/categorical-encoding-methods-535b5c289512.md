# 分类编码方法

> 原文：<https://medium.com/analytics-vidhya/categorical-encoding-methods-535b5c289512?source=collection_archive---------24----------------------->

![](img/0ac142ab1139fd7dfb76addc5785585a.png)

尼克·希利尔在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

在这篇博客中，我们将探讨为什么我们需要分类编码和不同的方法来对变量进行分类编码。

顾名思义，对分类类型的变量执行分类编码。这意味着变量中的每个类别都被分配了一个数值来表示实际值。编码是必需的，因为大多数机器学习算法不能处理分类值。它们需要数值才能发挥作用，有时算法的性能取决于编码的执行方式。

有各种方法来执行编码，例如

1.  一个热编码。
2.  标签/序数/整数编码。
3.  频率或百分比编码。
4.  平均编码。
5.  概率比编码。

大多数时候，在解决方案中使用一种热编码或标签编码。我们将讨论这些编码方法是什么，以及 python 中可以用来实现这些方法的库。

1.  **一个热编码** —这里分类变量的每个值都有自己的列。该列为布尔类型，根据记录是否包含值，包含 1 和 0。1 表示该值存在，否则为 0。这种方法有几个优点，因为它覆盖了变量的所有值，并且变量几乎没有信息损失。然而，当基数变量很高时，缺点就很明显了。在这种情况下，它会增加数据集中的列数，从而增加数据集的大小。Python 实现可以通过使用 pandas 的 [getdummies( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) 方法或 scikit-learn 的 [OneHotEncoder( )](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) 方法来实现。这两者之间的一个重要区别是，pandas 库不负责在训练集和测试集中保持相同的列，但 scikit-learn 会这样做。但是，scikit-learn 不返回数据帧，而是返回一个数组。
2.  **标签/序数/整数编码** —在标签编码中，分类值被赋予任意整数。无论如何，这个数字和这个数字所属的类别没有任何关系。这种方法很快，但会带来一个问题，即算法可能会将列的编码值作为序号，并假定这些值之间的关系是有序的。该方法不会添加任何新信息，如果有新的类别添加到列中，结果可能会很糟糕。标签编码可以通过 scikit-learn 库中的 [LabelEncoder( )](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) 方法来实现。
3.  **频率或百分比编码** —该方法用具有值的观察值数量或观察值百分比替换类别。这将捕获所有的类别表示。这对于基于树的方法很有效。但是，这种方法有一些缺点，因为它涉及到以频率或百分比的形式为一个类别分配数字。因此，如果有两个类别具有相同的频率或百分比值，它们将被赋予相同的值，这可能导致一些信息丢失。要用 python 实现这一点，我们需要使用 value_counts()方法计算这些值，然后用结果替换实际的类别值。
4.  **平均值编码** —此处类别被替换为目标变量相对于类别值的平均值。这种方法很快，可以处理回归问题。但是，当两个类别具有相同的平均值并导致相同的赋值时，可能会出现潜在的信息丢失。该实现相对较快，并且涉及目标变量相对于类别的平均值的计算，并且可以通过 group by 来完成。
5.  **概率比编码** —这种方法最有可能用于二进制分类的情况。它包括计算目标变量为真的概率或类别为 1 的概率以及目标为假/ 0 的概率。然后计算两者的比率，并用该比率替换类别值。这意味着比率[P (1) / 1 — P (1)]。这种方法的 python 实现需要使用 group by 函数。同样，这也适用于二元分类的情况。

任何编码方法都应该首先应用于训练集，然后使用相同的输出对测试集进行编码以保持一致性，否则会导致不同的输出。