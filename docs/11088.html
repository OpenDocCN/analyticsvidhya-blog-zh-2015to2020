<html>
<head>
<title>Handle missing values in Categorical Features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理分类要素中的缺失值</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/handle-missing-values-in-categorical-features-b7c5b073dda2?source=collection_archive---------5-----------------------#2020-11-17">https://medium.com/analytics-vidhya/handle-missing-values-in-categorical-features-b7c5b073dda2?source=collection_archive---------5-----------------------#2020-11-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="9b90" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">用用例正确处理缺失分类数据的有用指南</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/9842642c6780543d7f65dc1787a8e2d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*07Ac8zdKM9wJEwuyg9oNUw.jpeg"/></div></div></figure><p id="95d2" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这篇文章中，我们将通过几个相互比较的例子来展示如何处理带有缺失值的分类特征。将使用<a class="ae kf" href="https://www.kaggle.com/mirosval/personal-cars-classifieds" rel="noopener ugc nofollow" target="_blank">汽车分类广告</a>数据集，通过简单的线性回归模型预测广告价格。</p><p id="b2c3" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为了显示各种策略和相关的利弊，我们将关注该数据集的一个特定分类特征，即<strong class="jl hj">制造商</strong>，汽车品牌的名称(丰田、起亚、福特、宝马……)。</p><h2 id="e347" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">发布步骤:</h2><ul class=""><li id="1933" class="lb lc hi jl b jm ld jp le js lf jw lg ka lh ke li lj lk ll bi translated"><strong class="jl hj">显示原始数据</strong>:让我们看看我们的数据集是什么样子。</li><li id="0d0e" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated"><strong class="jl hj">处理分类特征中的缺失值</strong>:我们将通过比较不同的技术来处理缺失值。</li><li id="f7fc" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated">1 — <strong class="jl hj">删除</strong>整列<strong class="jl hj">制作者</strong>。</li><li id="4591" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated">2 — <strong class="jl hj">用<em class="lr">最常用的值替换</em></strong>缺失的值。</li><li id="46cb" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated">3 — <strong class="jl hj">删除具有空值的</strong>行。</li><li id="5a84" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated">4 — <strong class="jl hj">使用分类器算法预测</strong>值(监督或非监督)。</li><li id="42f3" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated"><strong class="jl hj">结论！</strong></li></ul></div><div class="ab cl ls lt gp lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="hb hc hd he hf"><h2 id="2beb" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">显示原始数据</h2><p id="da60" class="pw-post-body-paragraph jj jk hi jl b jm ld ij jo jp le im jr js lz ju jv jw ma jy jz ka mb kc kd ke hb bi translated">让我们开始导入一些库</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="8b7c" class="kg kh hi md b fi mh mi l mj mk">import pandas as pd<br/>import numpy as np<br/><br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import mean_squared_error, r2_score<br/>from sklearn.model_selection import train_test_split<br/>from scipy import stats<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/><br/>%matplotlib inline</span></pre><p id="8f2d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">首先，让我们看看我们的数据集是什么样子的</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="8b4d" class="kg kh hi md b fi mh mi l mj mk">filename = "cars.csv"<br/><br/>dtypes = {<br/>    "maker": str, # brand name<br/>    "model": str,<br/>    "mileage": float, # km<br/>    "manufacture_year": float,<br/>    "engine_displacement": float,<br/>    "engine_power": float,<br/>    "body_type": str, # almost never present<br/>    "color_slug": str, # also almost never present<br/>    "stk_year": str,<br/>    "transmission": str, # automatic or manual<br/>    "door_count": str,<br/>    "seat_count": str,<br/>    "fuel_type": str, # gasoline or diesel<br/>    "date_created": str, # when the ad was scraped<br/>    "date_last_seen": str, # when the ad was last seen<br/>    "price_eur": float} # list price converted to EUR<br/><br/>df_cleaned = pd.read_csv(filename, dtype=dtypes)<br/>print(f"Raw data has {df_cleaned.shape[0]} rows, and   {df_cleaned.shape[1]} columns")</span></pre><p id="d789" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><code class="du ml mm mn md b">Raw data has 3552912 rows, and 16 columns</code></p><p id="703e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在清除了所有缺少数据和无用特征的列之后(整个过程显示在我的<a class="ae kf" href="https://github.com/daniele-salerno/Handle-missing-values-in-Categorical-Features" rel="noopener ugc nofollow" target="_blank"> github </a>上)，除了<strong class="jl hj"> maker </strong>、<br/>之外，我们会发现自己处于这种情况:</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="a454" class="kg kh hi md b fi mh mi l mj mk"># Missing values<br/>print(df_cleaned.isna().sum())</span><span id="b7a6" class="kg kh hi md b fi mo mi l mj mk">maker                  212897<br/>mileage                     0<br/>manufacture_year            0<br/>engine_displacement         0<br/>engine_power                0<br/>price_eur                   0<br/>fuel_type_diesel            0<br/>fuel_type_gasoline          0<br/>ad_duration                 0<br/>seat_str_large              0<br/>seat_str_medium             0<br/>seat_str_small              0<br/>transmission_auto           0<br/>transmission_man            0<br/>dtype: int64<!-- --> </span></pre><h2 id="313c" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">相关矩阵</h2><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="40b7" class="kg kh hi md b fi mh mi l mj mk">corr = df_cleaned.corr()<br/>plt.subplots(figsize=(15,10))<br/>sns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns, annot=True, )</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl mp"><img src="../Images/fcbed631b1eeb2de555f9cb676ebf4b5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1gh0w1AQWRKw4bCVvkqbpw.png"/></div></figure><h2 id="44a0" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">处理分类特征中的缺失值</h2><p id="025b" class="pw-post-body-paragraph jj jk hi jl b jm ld ij jo jp le im jr js lz ju jv jw ma jy jz ka mb kc kd ke hb bi translated">现在我们只需要处理<strong class="jl hj"> maker </strong>特性，我们将用四种不同的方式来完成。然后我们将为每种预测价格的方法创建一个简单的线性回归模型。</p><ul class=""><li id="d862" class="lb lc hi jl b jm jn jp jq js mq jw mr ka ms ke li lj lk ll bi translated"><strong class="jl hj">第一个模型</strong>:删除整列<strong class="jl hj">制造者</strong>。</li><li id="2fc9" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated"><strong class="jl hj">第二模型</strong>:用<em class="lr">最常用值</em>替换缺失值。</li><li id="5d23" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated"><strong class="jl hj">第三种模式</strong>:删除空值行。</li><li id="f901" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated"><strong class="jl hj">第四个模型</strong>:用RandomForestClassifier预测缺失值。</li></ul><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="0553" class="kg kh hi md b fi mh mi l mj mk">mse_list = []<br/>r2_score_list = []<br/><br/>def remove_outliers(dataframe):<br/>    '''<br/>    return a dataframe without rows that are outliers in any column<br/>    '''<br/>    return dataframe\<br/>    .loc[:, lambda df: df.std() &gt; 0.04]\<br/>    .loc[lambda df: (np.abs(stats.zscore(df)) &lt; 3).all(axis=1)]<br/><br/>def plot_regression(Y_test, Y_pred):<br/>    '''<br/>    method that plot a linear regression line on a scatter plot<br/>    '''<br/>    x = Y_test<br/>    y = Y_pred<br/><br/>    plt.xlabel("True label")<br/>    plt.ylabel("Predicted label")<br/>    plt.plot(x, y, 'o')<br/><br/>    m, b = np.polyfit(x, y, 1)<br/><br/>    plt.plot(x, m*x + b)<br/><br/>def train_and_score_regression(df):<br/>    <br/>    df_new = remove_outliers(df) <br/>    <br/>    # split the df<br/>    X = df_new.drop("price_eur", axis=1).values<br/>    Y = np.log1p(df_new["price_eur"].values)<br/><br/>    X_train, X_test, Y_train, Y_test = train_test_split(X,Y,<br/>    test_size=0.1, random_state=0)<br/><br/>    # train and test of the model<br/>    ll = LinearRegression()<br/>    ll.fit(X_train, Y_train)<br/>    Y_pred = ll.predict(X_test)<br/><br/>    mse_list.append(mean_squared_error(Y_test, Y_pred))<br/>    r2_score_list.append(r2_score(Y_test, Y_pred))<br/>    <br/>    # print the metrics<br/>    print("MSE: "+str(mean_squared_error(Y_test, Y_pred)))<br/>    print("R2 score: "+str(r2_score(Y_test, Y_pred)))<br/>    <br/>    # plot the regression <br/>    plot_regression(Y_test, Y_pred)</span></pre><h2 id="b96b" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">删除整个栏目<em class="mt">制作者</em></h2><p id="9215" class="pw-post-body-paragraph jj jk hi jl b jm ld ij jo jp le im jr js lz ju jv jw ma jy jz ka mb kc kd ke hb bi translated">我们的第一个基本方法是创建一个没有列<strong class="jl hj">生成器</strong>的模型。当大量丢失的数据有可能使整个特性失效时，这种“无交易”实践是必要的。</p><p id="9f37" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这种情况下，我们可能会有最差的度量分数，但是我们可以用它们来比较其他方法</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="b35a" class="kg kh hi md b fi mh mi l mj mk">df_no_maker = df_cleaned.copy()<br/><br/># delete the entire column maker<br/>df_no_maker = df_no_maker.drop("maker", axis="columns")<br/><br/>train_and_score_regression(df_no_maker)</span><span id="f62c" class="kg kh hi md b fi mo mi l mj mk"># MSE: 0.1384341569294906<br/># R2 score: 0.8401186412746953</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl mp"><img src="../Images/4054a65ecb4f24dbc1a3f115d728f9c1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*B7d8TtBnxOB14HOjAO1gJg.png"/></div></figure><p id="0cfe" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这是我们的第一次尝试。我们能改进它吗？</p><h2 id="0512" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">用最频繁的数据替换缺失值</h2><p id="d99b" class="pw-post-body-paragraph jj jk hi jl b jm ld ij jo jp le im jr js lz ju jv jw ma jy jz ka mb kc kd ke hb bi translated">当然更有效的方法是用最频繁的数据赋值缺失值:众数。但是请注意，如果丢失的值相当多，这可能会导致不平衡的数据集。</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="2e85" class="kg kh hi md b fi mh mi l mj mk">df_replace_mode = df_cleaned.copy()<br/><br/># replace missing values with the mode<br/>replace_with = df_replace_mode["maker"].mode() <br/>df_replace_mode["maker"].fillna(replace_with,inplace=True)<br/><br/>df_replace_mode = pd.get_dummies(df_replace_mode,columns=["maker"])<br/><br/>train_and_score_regression(df_replace_mode)</span><span id="fc71" class="kg kh hi md b fi mo mi l mj mk"># MSE: 0.10243504754361979<br/># R2 score: 0.8703379824571595</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl mp"><img src="../Images/9e9a6391f8426a4911755811cd5abc33.png" data-original-src="https://miro.medium.com/v2/format:webp/1*We4oV_DW6dciudQ52BMW2A.png"/></div></figure><p id="62d6" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">正如预期的那样，我们在没有丢失任何行的情况下获得了比以前更好的度量分数</p><h2 id="b86b" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">删除具有空值的行</h2><p id="0ca5" class="pw-post-body-paragraph jj jk hi jl b jm ld ij jo jp le im jr js lz ju jv jw ma jy jz ka mb kc kd ke hb bi translated">另一种选择是删除具有空值的行。如果我们的数据集非常小，绝对不推荐，但是如果只有很少的值丢失或者如果我们有一个非常大的数据集，这很容易实现</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="d998" class="kg kh hi md b fi mh mi l mj mk">df_del_rows = df_cleaned.copy()<br/><br/># deleteing row with null maker<br/>df_del_rows = df_del_rows[df_del_rows['maker'].notna()]<br/><br/>df_del_rows = pd.get_dummies(df_del_rows,columns=["maker"])<br/><br/>train_and_score_regression(df_del_rows)</span><span id="788e" class="kg kh hi md b fi mo mi l mj mk"># MSE: 0.10465841311348424<br/># R2 score: 0.8580395349902117</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl mp"><img src="../Images/51c58403e7a78b0875bc153f551f8738.png" data-original-src="https://miro.medium.com/v2/format:webp/1*8c3esFrjLSTh5LkPWDh5dQ.png"/></div></figure><p id="60cc" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这一次，我们得到了比上一次更差的得分指标。当然部分原因是这次我们决定删除一些行，这使我们丢失了信息</p><h2 id="4f8e" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">用RandomForestClassifier预测缺失值</h2><p id="78c3" class="pw-post-body-paragraph jj jk hi jl b jm ld ij jo jp le im jr js lz ju jv jw ma jy jz ka mb kc kd ke hb bi translated">最有趣的方法无疑是用分类算法预测缺失值。这将使我们有机会不浪费数据集的很大一部分，从而不浪费大量信息。如果我们的预测足够准确，用这种技术我们应该有最好的评分标准。</p><p id="90ea" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">因此:</p><ul class=""><li id="9d5e" class="lb lc hi jl b jm jn jp jq js mq jw mr ka ms ke li lj lk ll bi translated">我们必须在列<em class="lr"> maker </em>赋值的行和空值的行之间分割数据集。</li><li id="a937" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated">第一个数据帧将成为我们创建分类模型的数据帧，以<em class="lr">制造者</em>作为目标特征。</li><li id="2138" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated">使用由此创建的模型来预测具有空值的数据帧中的缺失值</li><li id="162f" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated">将两个数据帧合并成一个</li><li id="ecea" class="lb lc hi jl b jm lm jp ln js lo jw lp ka lq ke li lj lk ll bi translated">像以前一样训练线性回归模型</li></ul><p id="ddbf" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们将数据集一分为二</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="3fd4" class="kg kh hi md b fi mh mi l mj mk">df_with_maker = df_cleaned[df_cleaned['maker'].notna()]<br/>print("N. rows with maker not null:", df_with_maker.shape[0])<br/><br/>df_no_maker = df_cleaned[df_cleaned['maker'].isna()]<br/>print("N. rows with maker null:", df_no_maker.shape[0])</span><span id="31e0" class="kg kh hi md b fi mo mi l mj mk"># N. rows with maker not null: 1690186<br/># N. rows with maker null: 212897</span></pre><p id="6242" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这里，我们创建分类模型，并查看它的指标</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="cfe1" class="kg kh hi md b fi mh mi l mj mk">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import log_loss<br/>from sklearn.metrics import accuracy_score<br/><br/>X = df_with_maker.drop("maker", axis=1).values<br/>Y = df_with_maker["maker"].values<br/><br/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=0)<br/><br/>forest = RandomForestClassifier(n_estimators=45, max_depth=25, random_state=False, <br/>                                max_features=0.6, min_samples_leaf=3, n_jobs=-1)<br/><br/>forest.fit(X_train, Y_train)<br/><br/>y_pred_train = forest.predict(X_train)<br/>y_pred = forest.predict(X_test)<br/><br/>y_pred_proba = forest.predict_proba(X_test)<br/><br/>accuracy_train = accuracy_score(Y_train, y_pred_train)<br/>accuracy_test = accuracy_score(Y_test, y_pred)<br/><br/>print("ACCURACY: TRAIN=%.4f TEST=%.4f" % (accuracy_train,accuracy_test))<br/>print("LOG LOSS: "+str(log_loss(Y_test, y_pred_proba)))<br/><br/>importances = forest.feature_importances_<br/>indices = list(np.argsort(importances))[::-1]<br/><br/>plt.title("Feature importances")<br/>plt.barh(range(len(indices)), importances[indices], color="g", align="center")<br/>plt.yticks(range(len(indices)), df_with_maker.iloc[:, 1:].columns[indices])<br/># plt.ylim([-1, len(indices)])<br/>plt.gca().invert_yaxis()</span><span id="aa82" class="kg kh hi md b fi mo mi l mj mk"># ACCURACY: TRAIN=0.9424 TEST=0.8962<br/># LOG LOSS: 0.3384233751455516</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl mp"><img src="../Images/1a626f258b78e654d4530e29b9e10a3f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*9clWfweWADSf-ZjOPgxpGw.png"/></div></figure><p id="0d33" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">不出所料，模型告诉我们<strong class="jl hj">发动机_排量</strong>和<strong class="jl hj">发动机_功率</strong>是能够定义<strong class="jl hj">制造商</strong>的关键特征</p><p id="6dcf" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在我们有了模型，让我们用预测值填充第二个数据框…</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="896a" class="kg kh hi md b fi mh mi l mj mk">df_no_maker = df_no_maker.drop('maker', axis=1)<br/>prediction = forest.predict(df_no_maker)<br/><br/>df_no_maker.insert(0, 'maker', prediction)</span></pre><p id="fd82" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">…然后，将两个数据帧合并在一起</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="c40a" class="kg kh hi md b fi mh mi l mj mk">frames = [df_with_maker, df_no_maker]<br/>df_final = pd.concat(frames)</span></pre><p id="ebed" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这是我们最后的数据框架</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="f51d" class="kg kh hi md b fi mh mi l mj mk">df_final.head()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl mp"><img src="../Images/3da68cb0e6b884e3e1f449a993fd44a9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*IPlC3rBUNGPpHXvTYQHc7Q.png"/></div></figure><p id="0d99" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在我们的最终数据集已经准备好了，我们可以重新创建线性回归模型，并检查我们是否改进了它的指标</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="8008" class="kg kh hi md b fi mh mi l mj mk">df_final = pd.get_dummies(df_final,columns=["maker"])<br/><br/>train_and_score_regression(df_final)</span><span id="787b" class="kg kh hi md b fi mo mi l mj mk"># MSE: 0.08867003817099878<br/># R2 score: 0.8825117873840629</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl mp"><img src="../Images/61cebce61b4fe9487df85d9aa2c2b541.png" data-original-src="https://miro.medium.com/v2/format:webp/1*WLOkTXHBn7VmvB3LnNAkrg.png"/></div></figure><p id="83e1" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这里，我们可以看到最好的指标值，这要归功于通过上述数据集合并保存的行</p><h2 id="1c85" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">结论！</h2><p id="faef" class="pw-post-body-paragraph jj jk hi jl b jm ld ij jo jp le im jr js lz ju jv jw ma jy jz ka mb kc kd ke hb bi translated">我们的考虑是由指标驱动的。从数据集中删除要素应该是我们最后的手段。如果缺少的数据很少或者数据集非常大，用最频繁的数据替换空数据或者删除行可能是一个方便的解决方案。相反，如果我们有很多缺失值或一个小数据集，预测/聚类可以为我们节省有价值的信息，否则这些信息将会丢失。</p><pre class="iy iz ja jb fd mc md me mf aw mg bi"><span id="613b" class="kg kh hi md b fi mh mi l mj mk">options_list = [<br/>    "Delete the entire column Maker", <br/>    "Replace null values with the mode", <br/>    "Delete rows with null values", <br/>    "Predict the missing values"<br/>]<br/><br/>df_metrics = pd.DataFrame({<br/>    "": options_list,<br/>    "MSE": mse_list,<br/>    "R2_score": r2_score_list,<br/>})<br/>df_metrics.head()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mu"><img src="../Images/c9709ef9a1338672def8ab3eac438fff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*jQwZnVHqcJs7e4VcL4O8Hg.png"/></div></figure><h2 id="d2cc" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">感谢阅读！</h2></div></div>    
</body>
</html>