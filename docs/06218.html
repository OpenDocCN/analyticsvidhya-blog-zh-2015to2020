<html>
<head>
<title>Google analytics customer revenue prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌分析客户收入预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/google-analytics-customer-revenue-prediction-e41da071d942?source=collection_archive---------1-----------------------#2020-05-15">https://medium.com/analytics-vidhya/google-analytics-customer-revenue-prediction-e41da071d942?source=collection_archive---------1-----------------------#2020-05-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/d6ed80a944d280404496e98695e6248c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QMGv9xwW0oltW9EEW7ry1A.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">谷歌商品商店</figcaption></figure><div class=""/><div class=""><h2 id="8fe4" class="pw-subtitle-paragraph iu hw hx bd b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl dx translated">预测GStore客户的消费金额</h2></div><h1 id="02e2" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">目录:</h1><ol class=""><li id="4ea7" class="ke kf hx kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">商业问题</li><li id="8fad" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">关于数据</li><li id="2ef3" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">关于功能</li><li id="da58" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">问题的性能指标</li><li id="2051" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">机器学习问题公式</li><li id="d362" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">数据加载和预处理</li><li id="4a62" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">数据清理</li><li id="dcd4" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">探索性数据分析</li><li id="4ad7" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">特征工程</li><li id="e07f" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">时间序列特征化</li><li id="69b3" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">附加功能</li><li id="1eee" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">准备训练和测试数据集</li><li id="129c" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">机器学习模型</li><li id="2b07" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">分类模型的超参数调整</li><li id="15c3" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">回归模型的超参数调整</li><li id="7a3e" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">最终模型</li><li id="1882" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">结果</li><li id="abd7" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">特征重要性</li><li id="1201" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">用bagging尝试集合模型</li><li id="1c37" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">未来的工作</li><li id="d8b5" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">GitHub、LinkedIn个人资料链接</li><li id="8864" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ks kt ku kv bi translated">参考</li></ol></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><ol class=""><li id="a83c" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ks kt ku kv bi translated"><strong class="kg hy">业务问题:</strong></li></ol><ul class=""><li id="d964" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">在每一个行业中，都证明了80-20法则。这条规则告诉我们，80%的收入将由20%的潜在客户创造。因此，我们的目标是预测这些潜在客户在近期特性中产生的收入。以便营销团队在促销策略上投入适当的资金来吸引潜在客户。</li><li id="ad7c" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">简而言之，我们获得了用户过去的数据和交易(当他们登录G-store时)。因此，通过使用这些数据，我们需要预测这些客户将创造的未来收入。</li><li id="08b9" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">因此，谷歌提供了商品客户数据集和每个客户的交易数量。我们将使用G-store数据集建立一个预测模型，以预测每个客户的总收入，这有助于更好地利用营销预算，我们还将使用不同的模型解释对总收入预测影响最大的因素。</li></ul><p id="9113" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 2。关于数据:</strong></p><p id="7b2d" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">我们已经从下面的Kaggle链接下载了数据:</p><div class="hh hi ez fb hj mb"><a href="https://www.kaggle.com/c/ga-customer-revenue-prediction/data" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hy fi z dy mg ea eb mh ed ef hw bi translated">谷歌分析客户收入预测</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">预测GStore客户的消费金额</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">www.kaggle.com</p></div></div><div class="mk l"><div class="ml l mm mn mo mk mp hp mb"/></div></div></a></div><ul class=""><li id="8151" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">我们需要下载train_v2.csv和test_v2.csv。</li><li id="9d05" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">我们将预测发布的测试集中所有用户的目标:test_v2.csv，用于他们在2018年12月1日至2019年1月31日期间的交易。</li><li id="11df" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">数据集中的每一行都是对商店的一次访问。因为我们预测的是每个用户的总收入的日志，所以test.csv中的所有行都不会对应于提交中的一行，但是所有唯一的<strong class="kg hy"> fullVisitorIds </strong>都会对应于提交中的一行。</li><li id="e28b" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">一些功能已经包含在。json格式，所以我们需要解析这些json列。关于这一点，我们将在数据读取时简要介绍。</li></ul><p id="3755" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 3。关于特征/列/自变量:</strong></p><ul class=""><li id="d568" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated"><em class="mq">full visitorid:</em>Google商品商店每个用户的唯一标识符。</li><li id="f904" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq">渠道分组:</em>用户来商店的渠道。</li><li id="7e00" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq">日期:</em>用户访问商店的日期。</li><li id="dd8c" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq">设备:</em>用于访问商店的设备的规格。</li><li id="2f5b" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq">地理网络</em>:此部分包含用户的地理信息。</li><li id="0c96" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq"> sessionId : </em>这次访问商店的唯一标识符。</li><li id="06e6" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq">社交管理类型:</em>参与类型，可以是“社交参与”或“非社交参与”。</li><li id="9ef3" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq">总计:</em>此部分包含整个会话的总计值。</li><li id="7726" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq"> trafficSource : </em>此部分包含有关发起会话的流量源的信息。</li><li id="b98c" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq"> visitId : </em>该会话的标识符。这是通常存储为utmb cookie的值的一部分。这对用户来说是唯一的。对于完全唯一的ID，应该使用fullVisitorId和visitId的组合。</li><li id="cb8e" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq"> visitNumber : </em>该用户的会话号。如果这是第一个会话，则将其设置为1。</li><li id="4c1a" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><em class="mq"> visitStartTime : </em>时间戳(表示为POSIX时间)。</li></ul><blockquote class="mr ms mt"><p id="ad4c" class="lo lp mq kg b kh li iy lq kj lj jb lr mu ls lt lu mv lv lw lx mw ly lz ma kr hb bi translated"><em class="hx">关于特性描述的更多细节:</em><a class="ae mx" href="https://support.google.com/analytics/answer/3437719?hl=en" rel="noopener ugc nofollow" target="_blank"><em class="hx">https://support.google.com/analytics/answer/3437719?hl=en</em></a></p></blockquote><p id="563f" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 4。问题的性能指标:</strong></p><ul class=""><li id="ec5b" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">根据均方根误差对提交的内容进行评分。</li><li id="d890" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">RMSE被定义为:</li></ul><figure class="mz na nb nc fd hk er es paragraph-image"><div class="er es my"><img src="../Images/983e5d72790599401a1e5b1621f30326.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*RSYTYpqyGDYWPmI0rD8zqA.png"/></div></figure><p id="ac83" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">其中y hat是客户预测收入的自然对数，y是实际总收入值加1的自然对数。</p><p id="3c9c" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 5。机器学习问题公式化:</strong></p><ul class=""><li id="55f2" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">因此，我们将预测顾客光顾商店时产生的收入(以美元计)。，所以我们可以把这个问题提出来作为回归问题</li><li id="3d05" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">通过关注一些kaggle讨论和赢家解决方案。，他们正在用这种方法解决这个问题。</li><li id="afeb" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">他们正在建立一个分类模型，该模型将预测用户是否会在测试期间访问商店，然后假设如果他有机会访问商店，那么通过使用回归模型，我们将预测客户将产生的收入。</li></ul><p id="1244" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">作为分类+回归的解题动机是<a class="ae mx" href="https://seananderson.ca/2014/05/18/gamma-hurdle/" rel="noopener ugc nofollow" target="_blank"> <strong class="kg hy">跨栏模型</strong> </a>。<br/> <br/> <strong class="kg hy">跨栏模式:- </strong></p><ul class=""><li id="b24a" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">这种模型是解决目标变量中零的数量多于一个值的问题的首选方法。<br/> <br/>推荐使用:<br/> *分类值是否趋向非零<br/> *然后预测金额。<br/>针对此次挑战实施的解决方案基于上述模型。</li><li id="093a" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">无论如何，我们将在特征化和模型构建时对此进行更多的讨论。</li></ul><p id="007a" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 6。数据加载和预处理:</strong></p><figure class="mz na nb nc fd hk"><div class="bz dy l di"><div class="nd ne l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">数据加载和解析json列</figcaption></figure><ul class=""><li id="aa2d" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">训练数据集形状为:(1708337，60)</li><li id="5e6e" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">测试数据集形状为:(401589，59)</li><li id="8f3e" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">这里，每条记录对应一次商店访问。</li></ul><p id="8d73" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy">注意:我使用的是更高配置的虚拟机，因此在读取大量数据时不会出现任何内存问题。但是，如果您的系统配置较低，那么您可以使用</strong><a class="ae mx" href="https://examples.dask.org/dataframes/01-data-access.html" rel="noopener ugc nofollow" target="_blank"><strong class="kg hy">【dask数据帧】</strong> </a> <strong class="kg hy">来避免内存问题，并且您可以加快操作速度。</strong></p><p id="be4e" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 7。数据清理:</strong></p><ul class=""><li id="2551" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">我们将检查每列数据中有多少个唯一值:</li></ul><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="466f" class="nk jn hx ng b fi nl nm l nn no">column_names = train_df.columns.to_list()</span><span id="b0fb" class="nk jn hx ng b fi np nm l nn no">unique_value_columns=[]</span><span id="ea04" class="nk jn hx ng b fi np nm l nn no">for column in column_names:<br/>    count = train_df[column].nunique()<br/>    if count==1:<br/>        del train_df[column]<br/>        unique_value_columns.append(column)</span></pre><p id="b9f1" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">在上面的代码片段中，我们检查每一列有多少唯一值。如果count为1，这意味着该特征在整个数据集中存在相同的值。所以这个特殊的特征对我们的任何预测都没有帮助。所以我们要删除这些列。</p><ul class=""><li id="9402" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated"><strong class="kg hy"> <em class="mq">缺失数据分析:</em> </strong></li></ul><figure class="mz na nb nc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nq"><img src="../Images/809e95f76ed4c80a016b2f3989e67293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mceRL_9RjhH-_XIEIvTlHw.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">缺失数据百分比的条形图</figcaption></figure><p id="2072" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">现在我们将分析每一个缺失的有价值的特征，不管它是否有用。如果有用，我们将分析如何估算缺失值。</p><p id="f685" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 8。探索性数据分析:</strong></p><p id="a58a" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> a)目标特征分析:</em> </strong></p><figure class="mz na nb nc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nr"><img src="../Images/674f1b0641083fae66be9b101c6ed0e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*fWVCL5XWT00rT4Xbo9BqhQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">交易收入分析</figcaption></figure><p id="9106" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">在上面的图中，x轴是用户指数，y轴是每个用户记录的交易收入值。</p><p id="e68f" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">正如我们已经讨论过的80/20法则。通过观察这个图表可以证明。大多数交易产生了零收入，但只有少数交易没有零收入。</p><p id="af32" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> b)趋势分析:</em> </strong></p><p id="4122" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">现在，我们将了解随着时间的推移，访问和交易的数量是如何变化的:</p><figure class="mz na nb nc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ns"><img src="../Images/27a5c4119e4b4c6e11ae34d9fd2daabb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vcaUiYZK7apqYPJqInxjUA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">访问和交易趋势分析</figcaption></figure><ul class=""><li id="d88e" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">如果我们观察2017年12月-2017年12月的上述图表，访问量和收入会大幅增加。</li><li id="b4a9" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">因此，这是对促销团队有用的见解之一。，这样他们就可以在12月的促销活动中投入更多的资金。</li></ul><p id="0505" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> c)渠道分组分析:</em> </strong></p><p id="5a1a" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">现在，我们将看到通过每个渠道发生的访问和交易数量:</p><div class="mz na nb nc fd ab cb"><figure class="nt hk nu nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/08697972870857ea5b3724fde70170fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*6TIwJiiNVWfKmCaHQ5fihQ.png"/></div></figure><figure class="nt hk nz nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/cc074f36f0b687559e79f126874fca9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*cpBDvZYQyIvMELpAHlIR7g.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx oa di ob oc translated">每个渠道的访问量和收入</figcaption></figure></div><ul class=""><li id="e156" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">最大的收入来自“有机搜索”、“直接搜索”、“推荐”..，但“直接”和“推荐”的访问次数非常少。</li><li id="2a33" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">因此，这里的结论是，分析团队可以在“直接”、“推荐”渠道上投入更少的资金(因为从这个渠道访问的用户更少)，并可以产生最多的收入。</li></ul><p id="50d6" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> d)网络浏览器分析:</em> </strong></p><p id="6937" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">现在，我们将看到通过每个网络浏览器进行的访问和交易数量:</p><div class="mz na nb nc fd ab cb"><figure class="nt hk od nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/ef6ea8158216ce3e9202a2594e8cd0ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*YKocQUSvCSNyHatCDLYZsA.png"/></div></figure><figure class="nt hk oe nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/ec7e3db191841aa58ebfa4b1b8e1b6a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*w08gBoa4FGjkqmqqM77wXg.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx of di og oc translated">通过网络浏览器的访问量和收入</figcaption></figure></div><ul class=""><li id="8205" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">与所有浏览器相比，chrome浏览器的访问量非常大。</li><li id="bab6" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">最大的收入来自“chrome”、“Firefox”、“safari”、“Internet explorer”、“edge”、“opera”、“Samsung internet”、“android web view”、“safari”、“amazon silk”、“Ya-browser”..,</li><li id="504e" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">因此，这里的结论是，分析团队可以在通过除chrome之外的浏览器(如safari、Firefox、opera、edge)访问商店的用户身上投入更少的资金，并可以产生最多的收入。</li></ul><p id="df97" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> e)操作系统分析:</em>T3】</strong></p><p id="4a34" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">现在，我们将看到通过每个操作系统发生的访问和交易数量:</p><div class="mz na nb nc fd ab cb"><figure class="nt hk oh nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/1fa0dcbd836473ab4516c4dc0ef07ba2.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*qADNYEGpUPm7Qxmkb9QoCg.png"/></div></figure><figure class="nt hk oi nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/d4fe75f3a28bd3a06bf15571dadc0b69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*BJ1SBVqUmTKfkZ6nGFCI_g.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx oj di ok oc translated">每个操作系统的访问量和收入</figcaption></figure></div><ul class=""><li id="e5f3" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">大多数用户都是通过windows、Macintosh来访问商店，而大部分收入都来自Windows和Macintosh。</li><li id="58b7" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">如果我们仔细观察，通过Linux和chrome OS访问的人非常少(不到10万)。，因此业务团队可以在这两个操作系统平台上投入很少的促销资金，并可以产生最多的收入。</li><li id="80cb" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">非常重要的是，不到2000人通过windows phone访问商品网站，但他们也产生了大量的收入。因此，分析团队可以在windows phone操作系统上投入更少的资金，并产生良好的收入。</li></ul><p id="a459" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> f)设备类别分析:</em> </strong></p><p id="5158" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">现在，我们将看到通过每个设备类别发生的访问和交易数量:</p><div class="mz na nb nc fd ab cb"><figure class="nt hk ol nv nw nx ny paragraph-image"><img src="../Images/d3b07e338d2b7b7d27551f6cc5360faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*6gQacinbjdhp2nAwx6sNOw.png"/></figure><figure class="nt hk om nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/fed1856cc674dc353b887a1f09604145.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*XdOau4mrqf-MSEPe6RCkkQ.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx on di oo oc translated">每台设备的访问量和收入</figcaption></figure></div><ul class=""><li id="6906" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">大多数用户是通过桌面访问的。</li><li id="54bc" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">这里非常重要的观察结果是，通过平板设备访问的人不到6.8万(与其他设备相比明显较少)，但他们产生的收入明显更高。</li><li id="85e4" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">因此，分析团队可以在通过“平板设备”访问商店的用户的促销活动上投入更少的资金，并可以产生显著更高的收入。</li></ul><p id="ef7e" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> g)移动vs非移动分析:</em> </strong></p><p id="28b1" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">现在，我们将看到通过移动和非移动设备进行的访问和交易数量:</p><div class="mz na nb nc fd ab cb"><figure class="nt hk op nv nw nx ny paragraph-image"><img src="../Images/1f92ef4ba518a2f740d37633c1ae70d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*qXX-NImqS1_ZwII99k6c3w.png"/></figure><figure class="nt hk oq nv nw nx ny paragraph-image"><img src="../Images/898d8d71ea332bc2aad5f02b46f0e00f.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*rfzFddSxubVyVyTQCKyKxw.png"/><figcaption class="hr hs et er es ht hu bd b be z dx or di os oc translated">移动与非移动的访问量和收入</figcaption></figure></div><ul class=""><li id="a391" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">如此多的用户通过非移动设备获得收入，而更多的收入来自非移动设备。</li><li id="e719" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">移动用户中的访客数量相对较少，但与非移动用户相比，他们也创造了可观的收入。</li></ul><p id="fe04" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> h)大陆分析:</em> </strong></p><p id="d898" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">现在，我们将看到各大洲发生的访问和交易数量:</p><div class="mz na nb nc fd ab cb"><figure class="nt hk ot nv nw nx ny paragraph-image"><img src="../Images/afd47fe735ebfc7a81e0e62f4e4cabf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*7W1_bpoobMT_juZMBNyp8g.png"/></figure><figure class="nt hk ou nv nw nx ny paragraph-image"><img src="../Images/4364e36e7623082d4d17324d1081fc87.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*yOWAAkWAhGfzan4HgLr_DA.png"/><figcaption class="hr hs et er es ht hu bd b be z dx ov di ow oc translated">各大洲的访问量和收入</figcaption></figure></div><ul class=""><li id="4c15" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">来自美国的游客数量明显多于其他大陆。</li><li id="f3f0" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">甚至来自“大洋洲”和“非洲”的访问数量也更少。但是这些大陆也产生了大量的收入。所以最好在这两个大陆投资。</li></ul><p id="664d" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 9。特征工程:</strong></p><p id="b46e" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> a)估算缺失值:</em> </strong></p><p id="84e6" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">这里，我们将对目标特征中缺失的值进行零插补。因为我们已经知道大约98%的交易没有产生任何金钱</p><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="94bc" class="nk jn hx ng b fi nl nm l nn no">train_df['totals.transactionRevenue'].fillna(0,inplace=True)</span></pre><p id="ca27" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> b)转换布尔特征:</em> </strong></p><p id="d49d" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">是一个布尔特性</p><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="d1be" class="nk jn hx ng b fi nl nm l nn no"># here we are converting the "device.isMobile" data type from string to boolean.</span><span id="c40f" class="nk jn hx ng b fi np nm l nn no">train_df['device.isMobile']=   train_df['device.isMobile'].astype(bool)</span><span id="7bca" class="nk jn hx ng b fi np nm l nn no">test_df['device.isMobile']  = test_df['device.isMobile'].astype(bool)</span></pre><p id="24ca" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> c)将数值特征转换为浮点数:</em> </strong></p><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="5c73" class="nk jn hx ng b fi nl nm l nn no"># here we defining list of all the numerical features and we are converting each numeric feature to float.</span><span id="4162" class="nk jn hx ng b fi np nm l nn no">numeric_features = [<br/>'visitNumber','visitStartTime','totals.hits','totals.pageviews',               'totals.timeOnSite','totals.transactions','totals.transactionRevenu']</span><span id="d632" class="nk jn hx ng b fi np nm l nn no">for col in numeric_feat:<br/>    train_df[col].fillna(0,inplace=True)<br/>    train_df[col] = train_df[col].astype('float')<br/>    <br/>    test_df[col].fillna(0,inplace=True)<br/>    test_df[col] = test_df[col].astype('float')</span></pre><p id="f8ab" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> <em class="mq"> d)分类特征的标签编码:</em> </strong></p><p id="b666" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">这里我们对分类特征执行<a class="ae mx" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kg hy">标签编码</strong> </a>。因为我们没有使用一次性编码，因为它会增加我们的数据维度。</p><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="71ab" class="nk jn hx ng b fi nl nm l nn no">categorical_feat = ['channelGrouping','device.browser','device.operatingSystem',<br/>'device.deviceCategory','geoNetwork.continent',<br/>'geoNetwork.subContinent','geoNetwork.country','geoNetwork.region','geoNetwork.metro','geoNetwork.city','geoNetwork.networkDomain',<br/>'totals.sessionQualityDim','trafficSource.campaign',<br/>'trafficSource.source','trafficSource.medium',<br/>'trafficSource.keyword','trafficSource.referralPath', 'trafficSource.adContent']</span><span id="f9f3" class="nk jn hx ng b fi np nm l nn no">for feature in categorical_feat:<br/>    <br/>    label_encoder = preprocessing.LabelEncoder() # initializing        label encoder object<br/>    <br/>    label_encoder.fit(list(train_df[feature].values.astype('str')) + list(test_df[feature].values.astype('str')))<br/>                                                             <br/># fit with list of variables in that feature<br/>    <br/>    train_df[feature] = label_encoder.transform(list(train_df[feature].values.astype('str'))) <br/># transforming that feature</span><span id="5180" class="nk jn hx ng b fi np nm l nn no">    test_df[feature]  = label_encoder.transform(list(test_df[feature].values.astype('str')))</span><span id="78fa" class="nk jn hx ng b fi np nm l nn no">    print("for this feature : {0} label-encoding was done succesfully".format(feature))</span></pre><p id="991a" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 10。时间序列特征:</strong></p><p id="94af" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">这个问题最重要的任务是时间序列特征化:</p><ul class=""><li id="2bdc" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">学分:"<a class="ae mx" href="https://www.kaggle.com/c/ga-customer-revenue-prediction/discussion/82614" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/ga-customer-revenue-prediction/discussion/82614</a>"</li><li id="1b30" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">因为这是一个回归问题，大多数值为零。，所以我们要用<a class="ae mx" href="https://seananderson.ca/2014/05/18/gamma-hurdle/" rel="noopener ugc nofollow" target="_blank"> <strong class="kg hy">跨栏模型</strong> </a>来解决这类问题。</li><li id="0397" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">在这里，我将讨论这个想法的整个方法论。</li><li id="c4fe" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">基本上kaggle给定:<br/> *列车数据时间段范围为:2016年8月1日至2018年4月30日= &gt;共638天。<br/> *测试数据时间段范围为:2018年5月1日至2018年10月15日= &gt;共168天。<br/> *预测数据时间段范围为:2018年12月1日至2019年1月31日= &gt;共62天。</li><li id="b319" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">所以这里我们需要用给我们的训练和测试数据来预测用户在2018年12月1日到2019年1月31日期间的收入。</li><li id="84b6" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">因此，我们拥有截至2018年10月15日的数据，预测数据开始日期为2018年12月1日。，所以中间的这段时间称为“<strong class="kg hy">冷却期</strong>，为46天。</li><li id="4928" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">因此，这里的想法是，首先我们需要预测在46天的“冷却期”(或测试期)后，用户是否会来商店。为此，我们将使用分类模型。</li><li id="50f1" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">假设他会来商店，那么我们将通过使用带有用户数据(特征)的回归模型来预测该用户的收入。</li><li id="fec1" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">因此，下一步是我们需要建立分类模型的数据，这样它将复制真实世界的场景。</li></ul><p id="3992" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy">真实世界场景？</strong> <br/>这意味着训练数据将由168天的数据组成，测试数据将由62天的数据组成，我们将保持训练数据结束日期和测试数据开始日期之间的间隔为46天。</p><blockquote class="mr ms mt"><p id="1e6c" class="lo lp mq kg b kh li iy lq kj lj jb lr mu ls lt lu mv lv lw lx mw ly lz ma kr hb bi translated">因此，通过使用这些训练数据，我们需要预测用户是否会存储我们准备的测试数据。<br/>例如:<br/>训练数据= 2016年8月1日至2017年1月15日(168天)<br/>测试数据= 2017年3月2日至2017年5月3日(62天)<br/>训练与测试数据之间的差距为46天。</p><p id="ef0c" class="lo lp mq kg b kh li iy lq kj lj jb lr mu ls lt lu mv lv lw lx mw ly lz ma kr hb bi translated">因此，通过使用我们拥有的数据，我们可以制作4组训练和测试帧。<br/> <br/> <strong class="kg hy">数据集-1:</strong><br/>*列车数据= 2016年8月1日至2017年1月15日(168天)<br/>*测试数据= 2017年3月2日至2017年5月3日(62天)<br/> <strong class="kg hy">数据集-2:</strong><br/>*列车数据= 2017年1月16日至2017年7月2日(168天)<br/>*测试数据= 2017年8月17日 <br/>*测试数据= 2018年2月1日至2018年4月4日(62天)<br/> <strong class="kg hy">数据集-4:</strong><br/>*训练数据= 2017年12月18日至2018年6月4日(168天)<br/>*测试数据= 2018年7月20日至2018年9月20日(62天)<br/> <br/> #因此从上述用户在训练和测试中常见的数据集(即冷却后返回 对于未返回的用户，我们将“is_returned”设置为0。</p><p id="06b8" class="lo lp mq kg b kh li iy lq kj lj jb lr mu ls lt lu mv lv lw lx mw ly lz ma kr hb bi translated">#我们将为“训练数据”中的每个用户创建一些新功能，最后我们将合并所有这些数据帧。</p></blockquote><ul class=""><li id="a9e3" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">所以现在我们的目标特性是“<strong class="kg hy"> is_returned </strong>”和“<strong class="kg hy"> revenue </strong>”。</li><li id="4038" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">其中“is_returned”将表示用户在测试期间是否会来商店。</li><li id="9d97" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">其中“收入”将表示由用户产生的收入。</li></ul><blockquote class="mr ms mt"><p id="7b96" class="lo lp mq kg b kh li iy lq kj lj jb lr mu ls lt lu mv lv lw lx mw ly lz ma kr hb bi translated">注:我第一次知道这很难理解。因此，在这里，我将用较少的几行给出时间序列特征的简要总结。</p><p id="8925" class="lo lp mq kg b kh li iy lq kj lj jb lr mu ls lt lu mv lv lw lx mw ly lz ma kr hb bi translated"><strong class="kg hy">我们决定建立分类模型和回归模型。这里分类模型的任务是预测用户是否会来商店。如果他不来商店，那么来自该用户的收入为零。直到这里我们都清楚了。</strong></p><p id="1f2d" class="lo lp mq kg b kh li iy lq kj lj jb lr mu ls lt lu mv lv lw lx mw ly lz ma kr hb bi translated">但是对于构建分类模型，我们没有任何带标签的数据。因此，我们试图为分类模型生成数据。因此，根据我们手头的数据，我们通过复制真实世界场景(冷却期间隙)将其分为训练框架和测试框架。如果用户同时出现在训练帧和测试帧中，则意味着他将前来存储，并且为该用户标记为“1”。如果他不在测试框中，那么我们将用“0”标记该用户。我希望现在你清楚了。</p></blockquote><figure class="mz na nb nc fd hk"><div class="bz dy l di"><div class="nd ne l"/></div></figure><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="f012" class="nk jn hx ng b fi nl nm l nn no">train_test_data = pd.concat([train_df, test_df], axis=0).reset_index()</span><span id="3fae" class="nk jn hx ng b fi np nm l nn no">%time train_frame_1 = get_time_series_features(train_test_data,1)<br/>train_frame_1.to_pickle('train_frame_1')</span><span id="d69c" class="nk jn hx ng b fi np nm l nn no">%time train_frame_2 = get_time_series_features(train_test_data,2)<br/>train_frame_2.to_pickle('train_frame_2')</span><span id="9d21" class="nk jn hx ng b fi np nm l nn no">%time train_frame_3 = get_time_series_features(train_test_data,3)<br/>train_frame_3.to_pickle('train_frame_3')</span><span id="0ad9" class="nk jn hx ng b fi np nm l nn no">%time train_frame_4 = get_time_series_features(train_test_data,4)<br/>train_frame_4.to_pickle('train_frame_4')</span><span id="9699" class="nk jn hx ng b fi np nm l nn no">#concatenating all our featurized frames:</span><span id="b6d3" class="nk jn hx ng b fi np nm l nn no">final_featurized_data = pd.concat([tr1, tr2, tr3, tr4], axis=0, sort=False).reset_index(drop=True)</span></pre><p id="928b" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 11。附加功能:</strong></p><p id="82b5" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">我们将计算每个数据点的特征。</p><p id="4989" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">我们将按访问者ID对数据点进行分组，然后我们将计算这个新特征。</p><ul class=""><li id="309d" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">网络域的最大值</li><li id="fee4" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">城市的最大价值</li><li id="c2b4" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">设备操作系统的最大值</li><li id="5898" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">Geo网络城域网的最大值</li><li id="6599" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">地理网络区域的最大值</li><li id="0202" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">频道分组的最大值</li><li id="bd13" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">推荐路径的最大值</li><li id="6711" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">国家的最大值</li><li id="e132" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">源的最大值</li><li id="32e4" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">介质的最大值</li><li id="cab9" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">关键字的最大值</li><li id="dc5d" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">浏览器的最大值</li><li id="ef78" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">设备类别的最大值</li><li id="0b4d" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">洲的最大值</li><li id="bc8a" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">现场时间总和</li><li id="cc11" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">现场时间的最小值</li><li id="f5bc" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">现场时间的最大值</li><li id="70af" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">现场时间的平均值</li><li id="1952" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">页面浏览量总和</li><li id="83c1" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">页面浏览量的最小值</li><li id="6531" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">页面访问量的最大值</li><li id="c10c" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">页面浏览量的平均值</li><li id="5375" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">命中总和</li><li id="5dca" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">点击的最小值</li><li id="5a38" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">命中的最大值</li><li id="42c1" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">命中的平均值</li><li id="cb5b" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">访问开始时间计数</li><li id="e2db" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">会话质量尺寸的最大值</li><li id="985d" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">isMobile的最大值</li><li id="0e71" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">最大访问次数</li><li id="2d88" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">所有交易金额的总和</li><li id="65c8" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">所有交易计数的总和</li><li id="608a" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">从期间开始日期起，客户第一次购物会话的天数</li><li id="a669" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">在期间开始日期之前，客户最后一次购物会话的天数</li><li id="0c19" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">间隔天数-当前框架中客户第一次和最后一次购物会话之间的差异</li><li id="15a6" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">客户访问的唯一日期数</li></ul><p id="55a8" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">同样，我们也将对测试数据进行特征化，我们将用(空)“np.nan”值填充目标特性“<strong class="kg hy"> is_returned </strong>”和“<strong class="kg hy"> revenue </strong>”。</p><p id="8fe3" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 12。准备训练和测试数据集:</strong></p><ul class=""><li id="d78a" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">我们将合并由“fullvisitorid”生成的所有数据。</li><li id="3126" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">现在，具有“is_returned”和“revenue”特征值的数据点为空，这些数据点是我们的测试数据点。(因为在特征化测试数据时，我们为目标特征附加了空值)</li></ul><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="8462" class="nk jn hx ng b fi nl nm l nn no"># for all our test records we already fill the 'revenue' column with 'null' values., <br/># so here we are separating our train and test records</span><span id="5d8b" class="nk jn hx ng b fi np nm l nn no">train_df = final_featurized_data[final_featurized_data['revenue'].notnull()]</span><span id="519d" class="nk jn hx ng b fi np nm l nn no">test_df  = final_featurized_data[final_featurized_data['revenue'].isnull()]</span></pre><p id="e6a1" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">13。机器学习模型:</p><p id="beec" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">这里，我们使用两个模型来构建预测收入的final</p><ul class=""><li id="88fc" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">预测客户是否会在测试窗口返回的分类模型。</li><li id="3022" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">预测交易金额的回归模型。</li></ul><p id="ee3b" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">所以最终值是:-</p><p id="e97a" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">预测收入=分类模型输出(概率)*回归模型输出(真实值)</p><p id="4d82" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy">注意:如果预测收入为负数，我们会将其视为零。因为收入不是负数。</strong></p><p id="fda1" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 14。分类模型的超参数调整:</strong></p><p id="61b3" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">在这里，我们采用Light-GBM作为分类任务的bse模型。因此，通过使用随机搜索，我们将找到超参数值。</p><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="ae7a" class="nk jn hx ng b fi nl nm l nn no"># initializing grid parameters:</span><span id="54ba" class="nk jn hx ng b fi np nm l nn no">gridParams = {<br/>    'learning_rate': [0.005,0.01,0.015],    <br/>    'n_estimators': [40,100,200],           <br/>    'num_leaves': [6,8,12,15,16],           <br/>    'boosting_type' : ['gbdt'],<br/>    'objective' : ['binary'],               <br/>    'metric' : ['binary_logloss'],          <br/>    'colsample_bytree' : [0.6, 0.8, 1],     <br/>    'subsample' : [0.7,0.9, 1],             <br/>    'reg_alpha' : [0,1],                    <br/>    'reg_lambda' : [0,1],                   <br/>    'max_leaves': [128,256,512],               <br/>    'min_child_samples' : [1,20]            <br/>              }</span><span id="3e5d" class="nk jn hx ng b fi np nm l nn no">#initializing the model object:<br/>model = lgb.LGBMClassifier()</span><span id="736c" class="nk jn hx ng b fi np nm l nn no">target_columns = ['is_returned', 'revenue', 'fullVisitorId']</span><span id="bffe" class="nk jn hx ng b fi np nm l nn no"># RandomizedSearchCV to tuning the parameters</span><span id="184d" class="nk jn hx ng b fi np nm l nn no">grid = RandomizedSearchCV(model, <br/>                          gridParams,<br/>                          cv=3)</span><span id="4ab3" class="nk jn hx ng b fi np nm l nn no"># Run the Randomsearch cv on the train dataset to find tuned hyper-parameters:</span><span id="4405" class="nk jn hx ng b fi np nm l nn no">%time grid.fit(train_df.drop(target_columns, axis=1) , train_df['is_returned'])</span></pre><p id="fdc0" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">在上面的代码片段执行之后，我们得到了下面的Light-GBM分类模型的最佳超参数。</p><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="6e63" class="nk jn hx ng b fi nl nm l nn no">{'subsample': 0.9, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'binary', 'num_leaves': 16, 'n_estimators': 200, 'min_child_samples': 20, 'metric': 'binary_logloss', 'max_leaves': 128, 'learning_rate': 0.015, 'colsample_bytree': 1, 'boosting_type': 'gbdt'}</span></pre><p id="d794" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 15。回归模型的超参数调整:</strong></p><p id="5642" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">这里，我们将Light-GBM作为回归任务的bse模型。因此，通过使用随机搜索，我们将找到超参数值。</p><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="cdb4" class="nk jn hx ng b fi nl nm l nn no">#defining grid parameters:</span><span id="b652" class="nk jn hx ng b fi np nm l nn no">gridParams = {<br/>    'learning_rate': [0.005,0.01,0.015],   <br/>    'n_estimators': [40,100,200],          <br/>    'num_leaves': [6,8,12,15,16],          <br/>    'boosting_type' : ['gbdt'],<br/>    'objective' : ['regression'],          <br/>    'metric' : ['rmse'],                   <br/>    'colsample_bytree' : [0.6, 0.8, 1],    <br/>    'subsample' : [0.7,0.9, 1],            <br/>    'reg_alpha' : [0,1],                   <br/>    'reg_lambda' : [0,1],                  <br/>    'max_leaves': [128,256,512],           <br/>    'min_child_samples' : [1,20]           <br/>            }</span><span id="d4a5" class="nk jn hx ng b fi np nm l nn no"># Define Light-GBM Regressor model</span><span id="cebc" class="nk jn hx ng b fi np nm l nn no">model = lgb.LGBMRegressor()</span><span id="171c" class="nk jn hx ng b fi np nm l nn no"># RandomizedSearchCV to tune the parameters</span><span id="72dc" class="nk jn hx ng b fi np nm l nn no">random_search = RandomizedSearchCV(model,<br/>                                   gridParams,<br/>                                   cv=3)</span><span id="155d" class="nk jn hx ng b fi np nm l nn no"># Run the Randomsearch cv on the train dataset to find tuned hyper -parameters</span><span id="8043" class="nk jn hx ng b fi np nm l nn no">%time random_search.fit(train_df.drop(target_columns, axis=1)[train_df['is_returned']==1], train_df['revenue'][train_df['is_returned']==1])</span></pre><p id="1aae" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">在上面的代码片段执行之后，我们得到了下面的Light-GBM分类模型的最佳超参数。</p><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="01e2" class="nk jn hx ng b fi nl nm l nn no">{'subsample': 0.9, 'reg_lambda': 0, 'reg_alpha': 1, 'objective': 'regression', 'num_leaves': 8, 'n_estimators': 100, 'min_child_samples': 20, 'metric': 'rmse', 'max_leaves': 128, 'learning_rate': 0.015, 'colsample_bytree': 1, 'boosting_type': 'gbdt'}</span></pre><p id="966b" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 16。最终型号:</strong></p><ul class=""><li id="29a7" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">将数据转换为LGB数据集对象以便于操作:</li></ul><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="c54c" class="nk jn hx ng b fi nl nm l nn no"># Define dataset for Classification model to determine whether customer would return during test time window.</span><span id="3e4f" class="nk jn hx ng b fi np nm l nn no">dtrain_returned = lgb.Dataset(train_df.drop(target_columns, axis=1), label = train_df['is_returned'])</span><span id="db5f" class="nk jn hx ng b fi np nm l nn no"># Define dataset for Regression model, picking only the customers who returned during test time window.</span><span id="1527" class="nk jn hx ng b fi np nm l nn no">dtrain_revenue = lgb.Dataset(train_df.drop(target_columns, axis=1)[train_df['is_returned']==1], <br/>                         label=train_df['revenue'][train_df['is_returned']==1])</span></pre><ul class=""><li id="a2a6" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">最终型号:</li><li id="1ccc" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">我们根据获得的最佳超参数值构建分类模型和回归模型，并运行多次(比如10次)，我们取每次迭代中生成的所有预测的平均值。</li></ul><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="32ff" class="nk jn hx ng b fi nl nm l nn no">#Running Light-GBM model for 10 iterations and took average of those.<br/>#Source :- <a class="ae mx" href="https://www.kaggle.com/kostoglot/winning-solution" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/kostoglot/winning-solution</a></span><span id="7228" class="nk jn hx ng b fi np nm l nn no">pr_lgb_sum = 0    #Variable to store predictions.</span><span id="7a66" class="nk jn hx ng b fi np nm l nn no">print('Training and predictions')</span><span id="fb96" class="nk jn hx ng b fi np nm l nn no">for i in range(10):     <br/>    print('Interation number ', i)<br/>    <br/>    #Classification model to predict whether customer will return in test window.<br/>    <br/>    classification_model = lgb.train(params_classification, dtrain_returned)</span><span id="fd0c" class="nk jn hx ng b fi np nm l nn no">pr_lgb     = classification_model.predict(test_df.drop(target_columns, axis=1))<br/>    classification_model.save_model('lgb_model1_itr_' + str(i) + '.txt' )<br/>    <br/>    <br/>    #Regression model to predict the transaction amount for the customers who returned in that time window.<br/>    <br/>    regression_model = lgb.train(params_lgb2, dtrain_revenue)</span><span id="7f0d" class="nk jn hx ng b fi np nm l nn no">    pr_lgb_ret = regression_model.predict(test_df.drop(target_columns, axis=1))</span><span id="d5d3" class="nk jn hx ng b fi np nm l nn no">    pr_lgb_ret.save_model('lgb_model2_itr_' + str(i) + '.txt' )<br/>    <br/>    #Calculating final prediction as product of above two amounts.<br/>    pr_lgb_sum = pr_lgb_sum + pr_lgb*pr_lgb_ret</span><span id="813e" class="nk jn hx ng b fi np nm l nn no">#Taking average value from above iterations the model was run.<br/>pr_final2 = pr_lgb_sum/10</span></pre><p id="9ffa" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">现在，我们将创建以“fullvisitorID”和“PredictedLogRevenue”为列的最终提交. csv文件。</p><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="cf58" class="nk jn hx ng b fi nl nm l nn no"># creating a data frame for predictions that we made for test data users:</span><span id="134a" class="nk jn hx ng b fi np nm l nn no">pred_df = pd.DataFrame({"fullVisitorId":test_df["fullVisitorId"].values})<br/>pred_df["PredictedLogRevenue"] = pr_final2<br/>pred_df.columns = ["fullVisitorId", "PredictedLogRevenue"]</span></pre><p id="228d" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 17。结果:</strong></p><p id="e4f0" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">上述模型在私人排行榜上的得分为0.8848，最终在排行榜上排名第5。</p><figure class="mz na nb nc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ox"><img src="../Images/9eb2f0c29a75c4ad6cb3ae8e60ea79c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jKBVpFXHdPJZ7B5Z4j6aIw.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">kaggle领导委员会提交</figcaption></figure><ul class=""><li id="6cbd" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">我们可以多重组合模型ex:逻辑回归+线性回归，随机森林(分类)+随机森林(回归)，XGB(分类)+XGB(回归)。</li></ul><p id="4bf3" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">18。特征重要性:</p><ul class=""><li id="7a8a" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">现在我们将做一些实验。我们先从<a class="ae mx" href="https://en.wikipedia.org/wiki/Feature_selection" rel="noopener ugc nofollow" target="_blank"> <strong class="kg hy">特征重要性</strong> </a>说起。</li><li id="8472" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">在这里我们将看到哪些功能是真正有用的。，所以我们将只使用那些特征，这样我们可以减少数据的维数和计算时间。</li><li id="02c0" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">所以对于这一点我们使用的是'<a class="ae mx" href="https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kg hy">【递归特征消除】'</strong> </a> <strong class="kg hy">。</strong></li></ul><p id="3aae" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><a class="ae mx" href="https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kg hy"> <em class="mq">递归特征消除</em></strong></a><strong class="kg hy"><em class="mq">:</em></strong></p><ul class=""><li id="7968" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">递归特征消除的思想类似于反向特征选择。</li><li id="0a41" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">首先，我们需要指定基本模型(这里基本模型必须返回特性的重要性)。因此算法首先在数据集的所有特征上训练模型。</li><li id="5a6a" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">现在它将考虑所有特征的特征重要性。现在，通过移除最不重要的特征，它将在新的特征集上重新训练模型。，因此该操作将针对不同的特征集迭代运行。</li><li id="d1f2" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">最后选择那些特征中准确率最高的特征集作为最终特征。</li></ul><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="13a1" class="nk jn hx ng b fi nl nm l nn no"># Define Light-GBM Regressor model as our base model:</span><span id="abbd" class="nk jn hx ng b fi np nm l nn no">estimator = lgb.LGBMRegressor(objective = "regression",metric= "rmse",max_leaves=128,num_leaves = 8,min_child_samples = 20 , learning_rate = 0.015,subsample = 0.9,colsample_bytree =1,bagging_frequency = 1,n_estimators = 100, reg_alpha = 1,reg_lambda = 0,boosting_type = "gbdt")</span><span id="d59e" class="nk jn hx ng b fi np nm l nn no">rfecv = RFECV(estimator, step=1) # here step denotes at a time how many features do you want to drop.</span><span id="439b" class="nk jn hx ng b fi np nm l nn no">%time rfecv.fit(train_df.drop(target_columns, axis=1)[train_df['is_returned']==1], train_df['revenue'][train_df['is_returned']==1])</span></pre><figure class="mz na nb nc fd hk er es paragraph-image"><div class="er es oy"><img src="../Images/88b3aba3750b1d0ed4b05b6163955f8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*HyYAQ8-8XoPUNosifx9kxg.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">特征重要性</figcaption></figure><pre class="mz na nb nc fd nf ng nh ni aw nj bi"><span id="577c" class="nk jn hx ng b fi nl nm l nn no">print('Optimal number of features: {}'.format(rfecv.n_features_))</span><span id="abb1" class="nk jn hx ng b fi np nm l nn no">Optimal number of features: 19</span></pre><figure class="mz na nb nc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es oz"><img src="../Images/277bcbb1c65ead4ab3a0f715f2492ff7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YfdtaQ2SaYe8D4HwPxR-LQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">特征重要性</figcaption></figure><ul class=""><li id="5fd2" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">现在，我们可以构建与之前构建的模型相同的模型。我试了一下，结果没有明显的改善，但是我观察到最终模型的性能有轻微的变化。</li></ul><p id="80a7" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">19。用bagging尝试集合模型:</p><ul class=""><li id="6dec" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated"><strong class="kg hy">集成学习</strong>通过组合几个模型<strong class="kg hy">帮助提高机器学习结果。集成</strong>方法是将几种机器学习技术结合到一个预测模型中以减少方差的元算法(<a class="ae mx" href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" rel="noopener ugc nofollow" target="_blank"> <strong class="kg hy"> Bagging </strong> </a>)</li><li id="10e2" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><strong class="kg hy">装袋:</strong>又称助推捆绑式聚集。在这里，我们将采取样品替换。在我们的集成架构中，我们将把数据的子集传递给每个模型，而不是把整个数据传递给每个模型。这里，通过从整个训练数据中抽取样本(替换)来形成子集。因此，通过使用这种技术，我们可以减少模型中的差异。</li><li id="1233" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">这是我的整体架构:</li></ul><figure class="mz na nb nc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es pa"><img src="../Images/8951ceb4a3d45360fd2c8840b1c39fa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eWmYZDAC32j3DryNt6mGyA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">集合模型</figcaption></figure><ul class=""><li id="0c64" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">这里我没有使用分类模型。我只用回归模型来预测用户的收入。</li></ul><p id="255b" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy">注意:这里我只使用了3个模型，但在现实世界中，人们会使用100个基础模型来改善结果。</strong></p><p id="09ec" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated">这是我用系综法得出的结果:</p><figure class="mz na nb nc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es pb"><img src="../Images/a8c8e3048624dc75d5b709dffcb3a481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8AQyRZbNGdFmxpN21Nth2w.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">集合模型结果</figcaption></figure><p id="d2d5" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 20。</strong> <strong class="kg hy">未来工作:</strong></p><p id="7aea" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><em class="mq">深度学习模型:</em></p><ul class=""><li id="6e17" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated">我们可以尝试具有conv1D层和max- pool层的各种cnn模型架构，并且我们可以尝试LSTM模型(因为给定的数据随时间变化，所以我们知道对于时间序列问题，LSTM模型将做得很好)。</li><li id="feae" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">在描述部分，你可以找到我的GitHub简介，在那里你可以找到整个项目和未来工作的代码。</li></ul><p id="0c38" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 21。简介:</strong></p><div class="hh hi ez fb hj mb"><a href="https://github.com/kireeti-kunam" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hy fi z dy mg ea eb mh ed ef hw bi translated">基里提-库纳姆-概述</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">在tcs工作了快2年。目前在寻找机器学习方面的机会。帮我接通…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">github.com</p></div></div><div class="mk l"><div class="pc l mm mn mo mk mp hp mb"/></div></div></a></div><div class="hh hi ez fb hj mb"><a href="https://www.linkedin.com/in/kireeti-kunam/" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hy fi z dy mg ea eb mh ed ef hw bi translated">印度特伦甘纳邦kireeti Kunam-Hyderabad |职业简介| LinkedIn</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">查看Kireeti Kunam在LinkedIn(全球最大的职业社区)上的个人资料。Kireeti有一个工作列在他们的…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">www.linkedin.com</p></div></div><div class="mk l"><div class="pd l mm mn mo mk mp hp mb"/></div></div></a></div><p id="d5f9" class="pw-post-body-paragraph lo lp hx kg b kh li iy lq kj lj jb lr kl ls lt lu kn lv lw lx kp ly lz ma kr hb bi translated"><strong class="kg hy"> 22。参考文献:</strong></p><ul class=""><li id="3753" class="ke kf hx kg b kh li kj lj kl lk kn ll kp lm kr ln kt ku kv bi translated"><a class="ae mx" href="https://www.kaggle.com/c/ga-customer-revenue-prediction/data" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/ga-customer-revenue-prediction/data</a></li><li id="fb03" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><a class="ae mx" href="https://support.google.com/analytics/answer/3437719?hl=en" rel="noopener ugc nofollow" target="_blank">https://support.google.com/analytics/answer/3437719?hl=en</a></li><li id="2125" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><a class="ae mx" href="https://seananderson.ca/2014/05/18/gamma-hurdle/" rel="noopener ugc nofollow" target="_blank">https://seananderson.ca/2014/05/18/gamma-hurdle/</a></li><li id="42ea" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><a class="ae mx" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . preprocessing . label encoder . html</a></li><li id="c8d7" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><a class="ae mx" href="https://www.kaggle.com/c/ga-customer-revenue-prediction/discussion/82614" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/ga-customer-revenue-prediction/discussion/82614</a></li><li id="e65a" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><a class="ae mx" href="https://www.kaggle.com/kostoglot/winning-solution" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/kostoglot/winning-solution</a></li><li id="adb7" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated"><a class="ae mx" href="https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html" rel="noopener ugc nofollow" target="_blank">https://www . sci kit-Yb . org/en/latest/API/model _ selection/RF ecv . html</a></li><li id="4359" class="ke kf hx kg b kh kw kj kx kl ky kn kz kp la kr ln kt ku kv bi translated">https://en.wikipedia.org/wiki/Bootstrap_aggregating<a class="ae mx" href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" rel="noopener ugc nofollow" target="_blank"/></li></ul></div></div>    
</body>
</html>