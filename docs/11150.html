<html>
<head>
<title>Support Vector Regression (SVR) Model: A Regression-Based Machine Learning Approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">支持向量回归模型:一种基于回归的机器学习方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/support-vector-regression-svr-model-a-regression-based-machine-learning-approach-f4641670c5bb?source=collection_archive---------6-----------------------#2020-11-20">https://medium.com/analytics-vidhya/support-vector-regression-svr-model-a-regression-based-machine-learning-approach-f4641670c5bb?source=collection_archive---------6-----------------------#2020-11-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="241b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将简要讨论 SVR 模型。我们将讨论三种类型的支持向量回归机，即 S-支持向量回归机(Scaling-SVR)、Z-支持向量回归机(Z-score-SVR)和 R-SVR (Range-SVR)。随后，我们将讨论它在预测无线传感器网络节点定位过程中的平均定位误差方面的应用。</p><p id="6bc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以<a class="ae jd" href="https://www.researchgate.net/publication/346008338_A_Machine_Learning_Approach_to_Predict_the_Average_Localisation_Error_with_Applications_to_Wireless_Sensor_Networks" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">下载</strong> </a>我们的论文了解更多详情。如果您有任何问题，可以写信给我(abhilash.singh@ieee.org)或访问<a class="ae jd" href="https://www.abhilashsingh.net?source=svr_medium" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">我的网页</strong> </a>了解更多更新。此外，查看本文末尾的推荐阅读部分，获取最新的研究文章。<a class="ae jd" href="https://www.youtube.com/channel/UC3YYrAOSNRXvG8Tud3XepYA" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">别忘了订阅我的 YouTube 频道。</strong>T11】</a></p><h2 id="ca2a" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">介绍</h2><p id="7a51" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">广义上，学习算法分为监督学习和非监督学习。此外，监督学习分为分类和回归学习，而无监督学习分为聚类和降维技术。</p><p id="6f34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基于回归的机器学习算法的关键目标是基于映射函数预测预测值。这个映射函数是通过输入一组称为训练数据集的特征和预测数据来建模的。SVR 被用于许多应用中，例如图像处理、遥感和区块链。它具有高超的概括能力和高精度。此外，计算复杂度与输入特征数据集无关。</p><p id="3b74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们在下一节看到 SVR 的控制方程；</p><h2 id="445a" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">支持向量回归</h2><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ke"><img src="../Images/155feb7d7ab710b4d8352752e3e8492f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bKI_PWOfdo9tTlMoGJIq_g.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图 1: SVR 结构<a class="ae jd" href="https://www.researchgate.net/publication/346008338_A_Machine_Learning_Approach_to_Predict_the_Average_Localization_Error_With_Applications_to_Wireless_Sensor_Networks" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jg"> (Singh et al. 2020，IEEE Access) </strong> </a></figcaption></figure><p id="f823" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVR 最初由 Drucker 等人提出，是一种基于 Vapnik 支持向量概念的监督学习技术。SVR 旨在通过确定超平面和最小化预测值和观察值之间的范围来减少误差。最小化下面给出的等式中的 w 值类似于定义为最大限度的值，如图 1 所示。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es ku"><img src="../Images/161ffed600e51fff36d47814853161e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*pKu88GFOvogfpbbEO_hq2w.png"/></div></figure><p id="bfda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中求和部分代表经验误差。因此，为了最小化这一误差，我们使用以下等式。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es kv"><img src="../Images/fecca746ef07942c1cb837d9a2756a18.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*Dukl2oYsc2OesLQGY3A6uw.png"/></div></figure><p id="f4dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中α项表示拉格朗日乘数，其值大于等于 1。<strong class="ih hj"> <em class="kw"> K </em> </strong>表示核函数，<strong class="ih hj"> <em class="kw"> B </em> </strong>表示偏差项。在这项研究中，我们使用了由下式给出的多项式内核:</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es kx"><img src="../Images/6769a79ce83cd37461d4432cb41afe57.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*uSE-iGbSev5aAqtxWScKPQ.png"/></div></figure><p id="9194" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中<strong class="ih hj"> <em class="kw"> d </em> </strong>为多项式次数，<strong class="ih hj"> <em class="kw"> γ </em> </strong>为多项式常数。</p><p id="13b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与线性回归、KNN 和弹性网络等其他算法相比，SVR 的预测性能更好，这是因为它针对大量变量改进了优化策略。此外，它还可以灵活地处理几何、传输、数据概括和内核的附加功能。这一附加功能通过考虑要素的质量来增强模型的预测能力。</p><p id="2829" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练样本影响 SVR 模型的拟合性能，因为 SVR 算法对训练数据中的干扰敏感。此外，支持向量回归机在解决高维特征回归问题时是有用的，并且在特征度量大于样本量的情况下表现良好。在本研究中，我们从改进的 CS 算法仿真中提取了四个特征，即锚比、传输范围、节点密度和迭代次数。</p><p id="1cd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">特征缩放对于 SVR 至关重要，因为当一个函数比其他函数具有更大的幅度时，其他特征将在测量距离时占主导地位。为了避免这种情况，我们使用了各种标准化方法。基于此，我们提出了三种方法，如图 2 所示。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ky"><img src="../Images/9eee0528de0407cb0294d878e5d9bd44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pjqa5Rr3rBOrQ8z11_atjA.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图 2:流程图<a class="ae jd" href="https://ieeexplore.ieee.org/document/9261408" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jg"> (Singh et al. 2020，IEEE Access) </strong> </a></figcaption></figure><p id="358a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">方法一是 S-SVR(缩放 SVR)。在这种方法中，我们首先使用下面给出的等式标准化特征；</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es kz"><img src="../Images/9decd36aadac50fb2d93f3ff0ab38c6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:206/format:webp/1*Cf8x5ZCfLzP2bOHeDyM53A.png"/></div></figure><p id="db23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中<strong class="ih hj"> x </strong>为特征向量，<strong class="ih hj"> xs </strong>为标准化数据，<strong class="ih hj"> σ </strong>为特征向量的标准差。方法二是 Z-SVR (Z-score SVR)。在这种方法中，我们已经使用下面给出的等式标准化了特征；</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es la"><img src="../Images/230eb6e598f1c1f812ae99cc59dd0f01.png" data-original-src="https://miro.medium.com/v2/resize:fit:196/format:webp/1*33pgybWDNmBLKkOUhES8IA.png"/></div></figure><p id="5e5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中 x 条是特征向量的平均值。方法三是 R-SVR(范围 SVR)。在这种方法中，我们已经使用下面给出的等式标准化了特征；</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es lb"><img src="../Images/1a10393c809758ca034a17d66c48f085.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*0Ua1twuGHa1F528oQL0wPQ.png"/></div></figure><p id="e13e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">之后，我们以 70:30 的比例训练和测试了 SVR 模型，如图 2 所示。在本研究中，特征向量的维数为 107 × 1。因此，我们使用了 75 个数据进行训练，剩下的 32 个用于测试。</p><h2 id="744b" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">SVR 预测 ALE 在无线传感器网络节点定位中的应用。</h2><p id="ad42" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">为了模拟 SVR 模型，我们通过网格搜索算法进行超参数调整。为此，我们将其中一个超参数(即<strong class="ih hj"><em class="kw">【ε】</em></strong>)固定在 0.01，并应用网格搜索算法找到另一个超参数(即<strong class="ih hj"><em class="kw">【C】</em></strong>)的值。我们为惩罚因子创建了一个 100 × 100 的网格，<strong class="ih hj"> <em class="kw"> C </em> </strong>。每个网格代表<strong class="ih hj"> <em class="kw"> C </em> </strong>的一个具体值。在模拟网格搜索算法时，它找到了与最小均方差对应的最优网格。下表给出了所有三种方法的最佳<strong class="ih hj"> <em class="kw"> C </em> </strong>的范围以及其他模拟参数值。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es lc"><img src="../Images/c4119800b8ac72f681470398221bb99d.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*_-D4WQJVK9Opvhi7SI_5hA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">表 SVR 的模拟参数</figcaption></figure><p id="170a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结果</strong></p><p id="f827" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本节中，我们在相应的小节中介绍了 ALE 预测方法 I、II 和 III 的结果。我们绘制了预测 ALE 和模拟 ALE 之间的线性回归曲线进行比较。</p><p id="ade4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">方法一的性能</strong></p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es ld"><img src="../Images/de08bce20eeda1136af332cf3ea0a388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*6uM_JquspETrdRpsaEphhg.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图 3:使用方法 I 的 ALE 预测结果</figcaption></figure><p id="ea19" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们比较了由方法 I 得到的 ALE 预测结果和改进的 CS 算法的模拟结果。我们发现，预测结果与模拟结果非常一致，并且沿着具有轻微散射的直线回归线聚集(图 3)。灰色阴影区域对应于回归线的 95%置信区间(CI ),表明预测结果与 R = 0.80 和 RMSE = 0.23m 有很强的正相关性</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es le"><img src="../Images/cc0b99f4b861448e3890cbc8dcb13e57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*cBm13IKnKQin6Q76AaJI2A.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图 4:使用方法 II 对 ALE 的预测结果。</figcaption></figure><p id="88b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们通过方法 II 计算了预测的 ALE，我们就用改进的 CS 算法的模拟结果来评估它的性能。在此过程中，我们发现 R = 0.81 和 RMSE = 0.20m 时两者吻合良好(图 4)。然而，由于 SVR 模型高估了 ALE 值，一些观察值位于回归线的置信区间之外。高估可能是由正偏差引起的。这种类型的误差属于系统误差，这主要是由于所使用的模型或方法。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es lf"><img src="../Images/048bde03f5987ecb8271fb49a4a9e771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*JeEQQhp65JQH_jj4QzvN1w.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图 5:使用方法 II 的 ALE 的预测结果。</figcaption></figure><p id="8877" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将方法 III 的预测 ALE 与通过改进的 CS 算法获得的模拟 ALE 进行了比较。在这种情况下，我们也发现变量之间有很强的相关性(图 5)。在这里，我们发现了 R = 0.82 与 RMSE = 0.15 米的实用相关性</p><p id="ee40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结论</strong></p><p id="a4e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们讨论和研究了三个基于支持向量回归机的 ALE 预测机器学习模型。这些方法是根据所使用的标准化方法定义的。在方法 I、II 和 III 中，我们分别使用了标度法、Z 分数法和范围标准化法。之后，我们使用标准化数据训练具有多项式核的 SVR 模型，并使用系数相关性和 RMSE 度量评估其性能。在这样做的过程中，我们发现特征的范围标准化(即方法 III)导致 ALE 预测中较低的 RMSE。此外，方法 III 中的相关系数最高。</p><p id="9f2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">视频(</strong>喜欢视频，订阅频道获取更多此类视频<strong class="ih hj"> ) </strong></p><figure class="kf kg kh ki fd kj"><div class="bz dy l di"><div class="lg lh l"/></div></figure><p id="ce59" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献</strong></p><ol class=""><li id="dff9" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated">辛格、阿比拉什、瓦伊巴夫·科蒂亚尔、桑迪普·夏尔马、贾普拉卡·纳加尔和程-李骥。"预测平均定位误差的机器学习方法及其在无线传感器网络中的应用."<em class="kw"> IEEE 访问</em>8(2020):208253–208263。</li><li id="2e05" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><a class="ae jd" href="https://www.researchgate.net/publication/348648168_A_Gaussian_Process_Regression_Approach_to_Predict_the_k-barrier_Coverage_Probability_for_Intrusion_Detection_in_Wireless_Sensor_Networks" rel="noopener ugc nofollow" target="_blank">辛格、阿比拉什、贾普拉卡什·纳加尔、桑迪普·夏尔马和瓦伊巴夫·科蒂亚尔。"预测无线传感器网络入侵检测 k-barrier 覆盖概率的高斯过程回归方法."专家系统及应用 172 (2021): 114603。</a></li></ol><p id="7254" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集可用性</strong></p><p id="d49b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets/Average+Localization+Error+%28ALE%29+in+sensor+node+localization+process+in+WSNs" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> UCI 机器学习库</strong> </a>下载数据集</p><p id="e6a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">建议阅读</strong></p><p id="d1bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://www.researchgate.net/publication/354751895_Machine_Learning_to_Estimate_Surface_Roughness_from_Satellite_Images" rel="noopener ugc nofollow" target="_blank">【1】。Singh Abhilash、Kumar Gaurav、Atul Kumar Rai 和 Zafar Beg“从卫星图像估计表面粗糙度的机器学习”，遥感，MDPI，13 (19)，2021，DOI: 10.3390/rs13193794。</a></p><p id="7aeb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://www.researchgate.net/publication/358201341_LT-FS-ID_Log-Transformed_Feature_Learning_and_Feature-Scaling-Based_Machine_Learning_Algorithms_to_Predict_the_k-Barriers_for_Intrusion_Detection_Using_Wireless_Sensor_Network" rel="noopener ugc nofollow" target="_blank">【2】。Singh，Abhilash，Amutha，j .，Nagar，Jaiprakash，Sharma，Sandeep 和 Lee，Cheng-Chi。“LT-FS-ID:基于对数变换的特征学习和特征缩放的机器学习算法，用于预测使用无线传感器网络进行入侵检测的 k 障碍<br/>,《传感器》，第 22 卷，第 3 期，第(2022)1070 页。DOI:10.3390/s22031070。</a></p><p id="b88b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://www.researchgate.net/publication/360974220_AutoML-ID_automated_machine_learning_model_for_intrusion_detection_using_wireless_sensor_network" rel="noopener ugc nofollow" target="_blank">【3】。辛格、阿比拉什、j .阿穆塔、贾普拉卡什·纳加尔、桑迪普·夏尔马和程-李骥。" AutoML-ID:用于无线传感器网络入侵检测的自动机器学习模型."<em class="kw">科学报告</em> 12，第 1 期(2022):1–14。</a></p></div></div>    
</body>
</html>