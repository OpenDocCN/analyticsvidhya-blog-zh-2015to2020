<html>
<head>
<title>Complete Guide about CNNs(Part-1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN全指南(上)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/complete-guide-about-cnns-part-1-65bdfee3cae3?source=collection_archive---------12-----------------------#2020-01-11">https://medium.com/analytics-vidhya/complete-guide-about-cnns-part-1-65bdfee3cae3?source=collection_archive---------12-----------------------#2020-01-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f130" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗨，学习者！美国有线电视新闻网(CNN ),在从各种来源对当前燃烧和强大的技术进行深入研究后，展示了一个详细的博客。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/f1e2241cf2fd7f21dd4025ccdfffa5cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ndF3a3o2tlbWzvyaQCJ7sA.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://www.pexels.com/search/concept/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="ddf0" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak"> <em class="ks">路线图</em> </strong></h1><p id="b836" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">1.简介<br/> 2。CNN怎么看一个图像<br/> 3。通用CNN架构<br/> 4。CNN层概念详解<br/> 5。CNN <br/> 6摘要。训练CNN模型<br/> 7。CNN <br/> 8中的超参数。推荐CNN架构规则<br/> 9。容易引起好奇心的“为什么”问题</p><p id="e016" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一部分:介绍CNN概要<br/>第二部分:<a class="ae jt" rel="noopener" href="/@shachikaul35/complete-guide-about-cnns-part-2-12c71b5d06bd">介绍从训练CNN模型到最后的为什么问题</a></p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="b799" class="ju jv hi bd jw jx lf jz ka kb lg kd ke kf lh kh ki kj li kl km kn lj kp kq kr bi translated">介绍</h1><p id="753c" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">卷积神经网络(ConvNets或CNN)是一种无监督的传统前馈深度学习技术，主要用于图像。<br/> CNN基本上对一个图像进行分类让我们假设一只狗或者猫。它不知道它是猫还是狗，但它刚刚接收到某些像素矩阵作为输入，并开始学习它的低级特征，如曲线、亮度或线条。随着越来越深入，它逐渐开始学习中级和高级特征，如耳朵和眼睛。最后，计算每个类别的概率(猫，狗..)的范围从0到1，使用最佳描述图像的特定激活函数(0.8用于猫，0.2用于狗等)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lk"><img src="../Images/28f5d4f2b6b96b5b9d135e64589dcb6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*p1nw7pe0gJLhHYaZctT5oA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://torres.ai/deeplearning/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="4394" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CNN的应用扩展到图像、视频、文本和音频分析。物体识别，计算机视觉和相关的应用程序，包括人脸识别应用程序。此外，它还被广泛用于非常先进的深度学习算法，称为<a class="ae jt" rel="noopener" href="/analytics-vidhya/gan-an-imaginative-tool-into-reality-d8fa46aa6bff">甘</a>。</p><blockquote class="ll lm ln"><p id="fb69" class="if ig lo ih b ii ij ik il im in io ip lp ir is it lq iv iw ix lr iz ja jb jc hb bi translated">ConvNet的作用是将图像简化为一种更容易处理的形式，而不会丢失对获得良好预测至关重要的特征。</p></blockquote><h1 id="53b3" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">CNN如何看待一幅图像</h1><p id="37f5" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">图像由排列成n维阵列的像素组成。这就是电脑看图像的方式。对它来说，图像是一个值的数组，每个值代表一个像素。每个像素表示该点的颜色强度，对于彩色和灰度图像，其范围分别为0–255和0–1。在CNN中，n-D数组形式的图像具有(长、宽、信道)的形状。这里，通道指的是图像的深度，指的是它是否是彩色图像。<br/>彩色图像有3个通道(R、G、B ),这是一个堆叠的三维矩阵，每个矩阵的值范围在0-255之间。另一个非彩色图像是具有1个通道的1-D阵列。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/6dc2afb0e1ceaf4dc985f26e5e978927.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*tp3rYJJaT586CA8YFZo14Q.png"/></div></figure><p id="2b32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">几个图像相关的术语:<br/> 1。<strong class="ih hj">分辨率:</strong>是指一幅图像中的ppi(每英寸像素)/ dpi(每英寸点数)，以高度和宽度的形式表示。低分辨率意味着每英寸像素更少，因此当大像素变得可见时，拉伸图像会使质量更差。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lt"><img src="../Images/86d98d8f5f87ca0238eaee356fd7b5e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*MOZ-iH4E_7mg3vev7WC9DA.png"/></div></figure><p id="9cf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">像素</strong>:图像元素，其值是指图像中该点的颜色强度。参考<a class="ae jt" href="https://www.whydomath.org/node/wavlets/imagebasics.html" rel="noopener ugc nofollow" target="_blank">这篇博客</a>了解更多信息。<br/> 3。<strong class="ih hj">尺寸</strong>:改变尺寸是指图像中像素数量的变化，即需要删除或添加一些像素。</p><p id="0717" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lo">关键事实:</em> </strong> <em class="lo">在图像处理中，图像缩放不会改变图像的大小，相反，如果分辨率不适合新的大小，像素会被拉伸或压缩。</em></p><h1 id="624e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">通用CNN架构</h1><p id="b262" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">CNN是另一种具有类似结构的神经网络，就像典型的神经网络一样。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lu"><img src="../Images/d9520607998db79584d4481f12787933.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*1KRzdZyQK4gZDc-N-VV9Hg.png"/></div></figure><p id="eba2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CNN只是通过添加一些层，如卷积、relu(又名激活)和池层来修改NN架构。基本上整个网络分为学习特征和分类。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/9e1c3b8d0d340602c4d853a4aabcc866.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*BO2DgZbcfQkekbMRHVjscw.png"/></div></figure><p id="7e5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">使用以下CNN层学习特征:</strong></p><p id="8452" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">卷积:</strong>输入图像首先进入该层，卷积核围绕整个图像进行卷积，以降低图像维数并生成一堆特征图。<br/> <strong class="ih hj"> ReLU </strong>(又名激活)<strong class="ih hj"> : </strong> ReLU激活函数将负值转换为0，<strong class="ih hj">激活某些高权重特征</strong>，这些特征被转发到下一层。因此被称为活化层。该层为模型带来了非线性，使其能够解决复杂的特征。</p><p id="993f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">汇集</strong>(也称为下采样)<strong class="ih hj"> : </strong>一个下采样层，它减少了训练参数，从而减少了计算成本和时间。简而言之，<strong class="ih hj">更快的计算</strong>。</p><p id="56f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">使用以下CNN层进行分类:</strong></p><p id="4e57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简化的矩阵现在被传递到分类层，在那里它被转换成一个长矢量(展平)。</p><p id="08b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">完全连接:</strong>矩阵被转换成密集层，该密集层被展平(特征向量)成一维数组。随后，这必须通过完全连接的层，并最终通过激活分类器(sigmoid/softmax)来相应地对图像进行分类。分类是通过获得输入图像的每个类别的概率来完成的。</p><h1 id="334d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">CNN分层概念详解</h1><h1 id="4923" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">1.卷积层</h1><p id="eb08" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">一般来说,“卷积”指的是将两个数字合成第三个数字的运算。这里，执行逐元素乘法，最后相加产生标量值。基本上，卷积是以特定的<strong class="ih hj">步长</strong>在图像上卷积(滑动)<strong class="ih hj">核</strong>的操作。输入图像中的当前操作区域(<em class="lo">比如说第一次滑过形状3*3的最左边矩阵)</em>与内核被称为<strong class="ih hj">感受野</strong>。</p><p id="48dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lo">我来说更简单的</em>。我是在研究其他博客时得到这个解释的。有一个闪光灯以一个步幅值在输入图像上闪烁。在这里，手电筒是一个核心，它照亮的区域是感受野。现在，当内核大小增加时，通过更多的层，感受野也增加，因此我们能够一次识别复杂层次的特征(对象)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lw"><img src="../Images/17d7e44e6afbcebbf1c713d18e944365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DmAwcMCcHqZdF62J0hNWlQ.png"/></div></div></figure><p id="32eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上所述，这一层有许多滤波器，它们分别与输入图像卷积，产生输出矩阵，称为<strong class="ih hj">特征图</strong>。查看<a class="ae jt" rel="noopener" href="/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8">这篇博客</a>了解更多细节。</p><blockquote class="lx"><p id="a097" class="ly lz hi bd ma mb mc md me mf mg jc dx translated">层目标通过反向传播学习核的参数(值)。</p></blockquote><p id="1f0d" class="pw-post-body-paragraph if ig hi ih b ii mh ik il im mi io ip iq mj is it iu mk iw ix iy ml ja jb jc hb bi translated"><strong class="ih hj">让我们进一步了解卷积中涉及的元素:</strong></p><p id="ccb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lo">滤镜:</em> </strong>(又名内核)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mm"><img src="../Images/3fd444d1863296841f8e46333988fcec.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*eeVgmSOhzruxtFC4XypDMw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://www.guru99.com/convnet-tensorflow-image-classification.html" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><ul class=""><li id="0010" class="mn mo hi ih b ii ij im in iq mp iu mq iy mr jc ms mt mu mv bi translated">过滤器是一个<strong class="ih hj">特征检测器</strong>(数组值)，它代表图像特征，如边缘、曲线、模糊或亮度检测器。</li><li id="cce5" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">内核的值被称为<strong class="ih hj">权重</strong>(/参数/强度值)，其中高权重表示该像素对于特定特征的重要性。值(1，-1，0)表示亮度(白色)、暗度(黑色)和0(灰色)的过滤。</li><li id="5d73" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">在跨越输入图像时，卷积期间执行以下两个操作:<br/> -逐元素乘法<br/> -求和</li><li id="f0dc" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">最初，滤波器被随机初始化，但随后被<em class="lo">反向传播更新。</em></li><li id="1f82" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">内核大小总是奇数。</li><li id="83c0" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">深度应始终与输入图像的深度<br/> ( <em class="lo">例如，输入尺寸(32*32*3)，其中“3”是深度。同样，内核的尺寸(7*7*3)具有相同的深度。)</em></li><li id="bc46" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated"><strong class="ih hj">多滤波器卷积的影响:</strong> <br/> 1。保留空间尺寸<br/> 2。特征图<br/> 3的深度(通道)越大。关于输入图像的更多信息</li><li id="85ed" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">内核最初检测低级特征，如曲线或边缘。深入网络，他们增加感受域，从图像更大部分获取信息。这允许检测一些复杂级别的特征或特定对象，如耳朵或眼睛。</li><li id="2209" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">如果内核不能很好地适应输入图像，该怎么办？ <br/> 1。<strong class="ih hj">放下</strong>未安装过滤器的部分<br/> 2。<strong class="ih hj">用0填充</strong>边界，使其适合内核</li></ul><p id="ce1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lo">特征图:</em> </strong> <em class="lo">(又名激活图，卷积特征)</em></p><ul class=""><li id="00ef" class="mn mo hi ih b ii ij im in iq mp iu mq iy mr jc ms mt mu mv bi translated">一组值(<em class="lo">或矩阵</em>)是卷积层在与特定滤波器执行卷积运算后的<strong class="ih hj">输出。</strong></li><li id="8e51" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">它被称为激活图，因为它显示了与内核相关的特定特性的激活区域。</li></ul><p id="afa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lo">跨步:</em> </strong></p><p id="0597" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步幅是指内核的<em class="lo">滑动，每次滑动一个特定的像素。<em class="lo">例如</em>，步幅为1将一次滑动一个像素的滤镜。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nb"><img src="../Images/3430d8a4eccea8609b4638ffa3250863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*6tXKORQ6ogCXMQj_0M4fGg.gif"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank">来源</a></figcaption></figure><p id="20a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大步行走时，某些细节会被忽略。因此，我们需要一个填充的概念。</p><p id="9916" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">填充:填充:</strong></p><ul class=""><li id="0b21" class="mn mo hi ih b ii ij im in iq mp iu mq iy mr jc ms mt mu mv bi translated">填充是<strong class="ih hj">沿着图像的边框</strong>添加值 <strong class="ih hj">的概念。</strong></li><li id="96f3" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">填充的类型:<br/> 1。<strong class="ih hj">有效</strong>:(无焊盘)导致输出尺寸&lt;输入尺寸<br/> 2。<strong class="ih hj">相同:</strong>(零填充)导致输出尺寸=输入尺寸</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nc"><img src="../Images/b0c1526e59a4f624af13744f9bd7653d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*p78KRoyTEUyR_6w77lBQwg.gif"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480" rel="noopener" target="_blank">来源</a></figcaption></figure><p id="8fe3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第一幅图像中，具有3*3内核的4*4输入(沿边界没有附加值)导致缩小的2*2特征图。这是'<strong class="ih hj">有效的</strong>填充。这对网络不好，因为我们会很快丢失很多细节。因此，第三个图像通过实现“<strong class="ih hj">相同的</strong>”填充来说明解决方案。<br/>具有2层填充(添加0)的3*3内核的5*5输入导致相同的维度，即相同的卷积，即作为输出的5*5特征图。</p><ul class=""><li id="e869" class="mn mo hi ih b ii ij im in iq mp iu mq iy mr jc ms mt mu mv bi translated"><strong class="ih hj">为什么需要填充？</strong> <br/> 1。执行卷积可能会影响数据的快速丢失。因此，额外的像素会减弱这种影响。<br/> 2。大步行走时，边缘的重量比中间的重量“接触”得少。因此，我们可能会丢失特定位置的某些细节。</li><li id="7d4d" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated"><strong class="ih hj">计算输出数据大小的公式</strong>其中滤波器大小(f)、步幅(s)、填充(p)和输入大小(n)为:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nd"><img src="../Images/2611f876f9d1c84905fd1bbef41c3063.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*4K9IPxWSC6q5cuBjWMrAKA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" rel="noopener" href="/machine-learning-bites/deeplearning-series-convolutional-neural-networks-a9c2f2ee1524">来源</a></figcaption></figure><h1 id="dc4e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">2.ReLU:(又名激活层)</h1><ul class=""><li id="9714" class="mn mo hi ih b ii kt im ku iq ne iu nf iy ng jc ms mt mu mv bi translated">CNN的激活层，在模型中引入非线性，能够解决复杂问题。</li><li id="03c3" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">没有ReLU模型，图像分类是一个线性问题，而实际上是一个非线性问题。</li><li id="6f7a" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">没有消失梯度问题</li><li id="34b7" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">输入中的负数转换为0。</li><li id="d713" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">ReLU函数在传递负数时输出为0，而为正数返回相同的值。因此，<strong class="ih hj"> f(x)=max(0，x) </strong></li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nh"><img src="../Images/96ee108cf971d64c3c214d1ef446d260.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*gVMfyUoq-ahdBmD7Gvv7pw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://ailephant.com/glossary/relu-function/" rel="noopener ugc nofollow" target="_blank">https://ailephant.com/glossary/relu-function/</a></figcaption></figure><h1 id="1768" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">3.合并:(又称为缩减采样)</h1><ul class=""><li id="fb7f" class="mn mo hi ih b ii kt im ku iq ne iu nf iy ng jc ms mt mu mv bi translated">应用线性和非线性变换后，对输出进行下采样，以获得足以描述整个图像的显著部分，而不是获取巨大的参数。</li><li id="e723" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">每个要素地图(conv图层的输出)都可以在保留重要信息的同时进行缩减。</li><li id="9672" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated">这是<strong class="ih hj">的一个特征，通过使用下面给出的两种方法中的任何一种来总结图像补丁中的重要特征</strong>。</li><li id="85d9" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ms mt mu mv bi translated"><strong class="ih hj">是怎么做到的？</strong></li></ul><ol class=""><li id="a4fd" class="mn mo hi ih b ii ij im in iq mp iu mq iy mr jc ni mt mu mv bi translated"><strong class="ih hj">平均:</strong>在每个特征图上由滤波器覆盖的感受野区域的平均计算。类似于该补丁中存在的平均特征。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nj"><img src="../Images/3ad362d95c0c684449f019c3e1fc7af0.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*_0mVH1SumYRnIu5ocNQUYA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源</figcaption></figure><p id="b44c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj"> Max: </strong>每张特征图上滤镜覆盖的感受野区域的每一片的最大值。类似于图像的该部分中存在的最重要的特征。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nk"><img src="../Images/80f4ae0519a4af14963bb64b0f716975.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*-zUMMU2Mf7UmpO3rtyQvxQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><ul class=""><li id="73a6" class="mn mo hi ih b ii ij im in iq mp iu mq iy mr jc ms mt mu mv bi translated"><strong class="ih hj">优点？</strong></li></ul><p id="2ea3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.减少要训练的重量数量，从而直接影响<strong class="ih hj">计算时间和成本</strong>。短时间内更快的计算。<br/> 2。在旋转、缩放或裁剪等<strong class="ih hj">变换</strong>场景中，使我们的训练更加<strong class="ih hj">健壮</strong>。<em class="lo">如何？</em>特征图的像素表示特定特征的精确位置。因此，模型对于检测特定特征变得如此精确。因此，当图像有一点点偏移时，建模可能不明智，因为这会导致不同特征图。</p><h1 id="06de" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">4.展平:</h1><p id="e0d2" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">汇集的图像矩阵被展平成单个向量，以便以某种方式在连续层中执行分类。</p><h1 id="cbe6" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">5.完全连接:(又名密集)</h1><p id="5100" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">顾名思义，这一层就像标准神经网络中的一层，其中展平的层连接到前一层中的所有激活。它就像隐藏层，唯一的区别是它是完全连接的。</p><h1 id="6cf8" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">6.Sigmoid/Softmax:</h1><p id="d37b" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">CNN的最后一层，在sigmoid或softmax激活函数的帮助下，基于二元或多类预测进行预测。这基本上是FC层之后的一个<strong class="ih hj">输出层，在这里我们根据概率</strong>得到预测的类别。</p><p id="c4c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比较输出和实际输出，并计算损耗，然后将其反向传播，用于下一个时期的进一步训练。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><h1 id="b731" class="ju jv hi bd jw jx lf jz ka kb lg kd ke kf lh kh ki kj li kl km kn lj kp kq kr bi translated">摘要</h1><ol class=""><li id="ac5f" class="mn mo hi ih b ii kt im ku iq ne iu nf iy ng jc ni mt mu mv bi translated">传递到网络的输入图像</li><li id="221b" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ni mt mu mv bi translated">选择步幅、过滤器尺寸和填充参数。执行卷积。</li><li id="4ba6" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ni mt mu mv bi translated">执行ReLU激活</li><li id="ab4c" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ni mt mu mv bi translated">根据你的需要，重复上面的步骤。</li><li id="8e24" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ni mt mu mv bi translated">将矩阵展平为单一矢量，作为全连接层</li><li id="8b36" class="mn mo hi ih b ii mw im mx iq my iu mz iy na jc ni mt mu mv bi translated">最后一层将根据不同的预测类别对图像进行分类</li></ol></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><p id="3183" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lo">值得浏览的有趣博客。</em></p><div class="nl nm ez fb nn no"><a rel="noopener follow" target="_blank" href="/machine-learning-bites/deeplearning-series-convolutional-neural-networks-a9c2f2ee1524"><div class="np ab dw"><div class="nq ab nr cl cj ns"><h2 class="bd hj fi z dy nt ea eb nu ed ef hh bi translated">深度学习系列:卷积神经网络</h2><div class="nv l"><h3 class="bd b fi z dy nt ea eb nu ed ef dx translated">在这篇博客中，我将解释卷积神经网络(CNN或ConvNets)的细节，它已被证明是…</h3></div><div class="nw l"><p class="bd b fp z dy nt ea eb nu ed ef dx translated">medium.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc jn no"/></div></div></a></div><p id="7152" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快乐阅读！</p><p id="820f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lo">可以通过</em></strong><a class="ae jt" href="https://www.linkedin.com/in/kaul-shachi" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="lo">LinkedIn</em></strong></a><strong class="ih hj"><em class="lo">与我联系。</em> </strong></p><p id="c04c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">欢迎在评论区分享你的观点或任何误导性的信息。:)</p></div></div>    
</body>
</html>