<html>
<head>
<title>An Intuitive Guide to Interpret a Random Forest Model using fastai library (Machine Learning for Programmers — Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用fastai库解释随机森林模型的直观指南(程序员的机器学习—第2部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/an-intuitive-guide-to-interpret-a-random-forest-model-using-fastai-library-machine-learning-for-f3b4513c366b?source=collection_archive---------2-----------------------#2018-10-29">https://medium.com/analytics-vidhya/an-intuitive-guide-to-interpret-a-random-forest-model-using-fastai-library-machine-learning-for-f3b4513c366b?source=collection_archive---------2-----------------------#2018-10-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="bd12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器学习是一个快速发展的领域——但有些东西会保持几年前的样子。其中之一就是<strong class="ih hj">解读和解释你的机器学习模型的能力</strong>。如果你建立了一个模型，却不能向你的业务用户解释它——它就不太可能出现。</p><p id="d6d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你能想象在不了解其工作原理的情况下将一个模型集成到你的产品中吗？或者哪些特性影响了您的最终结果？</p><p id="18c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">除了利益相关方的支持，作为数据科学家，我们还受益于对我们工作的解释和改进。这是一个双赢的局面！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/19ddb92975b860badb5eaf307d0c6907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*dlVHIYrrXpuRXPmG.jpg"/></div></figure><p id="8b1d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个fast.ai机器学习课程的<a class="ae jl" href="https://www.analyticsvidhya.com/blog/2018/10/comprehensive-overview-machine-learning-part-1/" rel="noopener ugc nofollow" target="_blank">第一篇文章在我们的社区看到了令人难以置信的反响。我很高兴分享本系列的第2部分，它主要讨论如何解释随机森林模型。我们将理解这个理论，并用Python实现它，以巩固我们对这个关键概念的理解。</a></p><p id="a30d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和往常一样，我鼓励您在阅读本文时在自己的机器上复制代码。对代码进行实验，看看您的结果与我在本文中介绍的结果有多大的不同。这将帮助你理解随机森林算法的不同方面以及可解释性的重要性。</p><h1 id="0f19" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">目录</h1><ol class=""><li id="4c95" class="kk kl hi ih b ii km im kn iq ko iu kp iy kq jc kr ks kt ku bi translated">第1部分概述(第1课和第2课)</li><li id="8c3c" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">机器学习介绍:第3课<br/> 2.1构建随机森林<br/> 2.2置信区间<br/> 2.3特征重要性</li><li id="141f" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">机器学习介绍:第4课<br/> 3.1一个热编码<br/> 3.2去除冗余特征<br/> 3.3部分依赖<br/> 3.4树解释器</li><li id="71de" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">机器学习介绍:第5课<br/> 4.1外推<br/> 4.2从零开始随机森林</li><li id="f676" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">其他主题</li></ol><h1 id="b67c" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">第1部分概述(第1课和第2课)</h1><p id="c0f3" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在我们开始本课程的下一课之前，让我们快速回顾一下前两节课所讲的内容。这将让你对未来有所了解。</p><ul class=""><li id="da88" class="kk kl hi ih b ii ij im in iq ld iu le iy lf jc lg ks kt ku bi translated"><strong class="ih hj">数据探索和预处理</strong>:探索推土机数据集(链接)，估算缺失值，并将分类变量转换成ml模型可接受的数字列。我们还使用fastai库中的<em class="lh"> date_part </em>函数从date列创建了多个特性。</li><li id="a94d" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><strong class="ih hj">构建随机森林模型并创建验证集</strong>:我们实现了一个随机森林，并计算了训练集的分数。为了确保模型不会过度拟合，创建了一个验证集。此外，我们调整了参数，以改善模型的性能。</li><li id="5a96" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><strong class="ih hj">装袋介绍</strong>:第二个视频介绍了装袋的概念。我们还可视化了一个单独的树，它提供了对随机森林如何工作的更好理解。</li></ul><p id="58c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将继续处理相同的数据集。我们将了解数据集中有哪些不同的变量，以及如何构建随机森林模型来做出有价值的解释。</p><p id="d8d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，是时候启动我们的Jupyter笔记本，开始学习第三课了！</p><h1 id="ff65" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">机器学习简介:第3课</h1><p id="903e" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">你可以在这里查阅本课<a class="ae jl" href="https://github.com/fastai/fastai/blob/master/courses/ml1/lesson2-rf_interpretation.ipynb" rel="noopener ugc nofollow" target="_blank">的笔记本。本笔记本将用于本视频中涵盖的所有三堂课。您可以观看以下视频中的整个课程(或者向下滚动，立即开始实施):</a></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="li lj l"/></div></figure><p id="e342" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">注意:正如我们在上一篇文章中看到的，杰瑞米·霍华德定期提供各种技巧，可以用来更有效地解决某个问题。这个视频的一部分是关于如何处理非常大的数据集。我在文章的最后一部分提到了这一点，这样我们可以先关注手头的主题。</em></p><p id="ce70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从第二课结束时停下的地方继续。我们已经使用日期列创建了新的特性，并且还处理了分类列。我们将加载经过处理的数据集，其中包括我们新设计的功能和<em class="lh">销售价格</em>变量的日志(因为评估指标是RMSLE):</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="d438" class="lp jn hi ll b fi lq lr l ls lt">#importing necessary libraries<br/>%load_ext autoreload<br/>%autoreload 2<br/>%matplotlib inline<br/><br/>from fastai.imports import *<br/>from fastai.structured import *<br/>from pandas_summary import DataFrameSummary<br/>from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier<br/>from IPython.display import display<br/>from sklearn import metrics<br/><br/>#loading preprocessed file<br/>PATH = "data/bulldozers/"<br/><br/>df_raw = pd.read_feather('tmp/bulldozers-raw')<br/>df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')</span></pre><p id="f787" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将定义在整个实现过程中经常使用的必要函数。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="e9ee" class="lp jn hi ll b fi lq lr l ls lt">#creating a validation set<br/><br/>def split_vals(a,n): return a[:n], a[n:]<br/>n_valid = 12000<br/>n_trn = len(df_trn)-n_valid<br/>X_train, X_valid = split_vals(df_trn, n_trn)<br/>y_train, y_valid = split_vals(y_trn, n_trn)<br/>raw_train, raw_valid = split_vals(df_raw, n_trn)<br/><br/>#define function to calculate rmse and print score<br/>def rmse(x,y): return math.sqrt(((x-y)**2).mean())<br/><br/>def print_score(m):<br/>   res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),<br/>               m.score(X_train, y_train), m.score(X_valid, y_valid)]<br/>   if hasattr(m, 'oob_score_'): res.append(m.oob_score_)<br/>   print(res)</span></pre><p id="83e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步将是实现一个随机森林模型，并解释结果，以更好地理解我们的数据集。到目前为止，我们已经了解到随机森林是由许多树组成的一组树，每棵树都在数据点和特征的不同子集上进行训练。每棵树都尽可能地不同，从数据集中捕捉唯一的关系。我们通过遍历每棵树的每一行并取叶节点值的平均值来进行预测。该平均值将作为该行的最终预测值。</p><p id="6dca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在解释结果时，该过程必须是交互式的，并且需要较少的运行时间。为了实现这一点，我们将在代码中做两处修改(与我们在上一篇文章中实现的相比):</p><ol class=""><li id="ef17" class="kk kl hi ih b ii ij im in iq ld iu le iy lf jc kr ks kt ku bi translated">取数据的子集:</li></ol><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="83d5" class="lp jn hi ll b fi lq lr l ls lt">set_rf_samples(50000)</span></pre><p id="447f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们只使用一个样本，因为处理整个数据需要很长时间。这里需要注意的一点是，样本不应该很小。这可能会导致不同的结果，对我们的整个项目不利。50，000的样本大小效果很好。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="ffbf" class="lp jn hi ll b fi lq lr l ls lt">#building a random forest model<br/><br/>m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)<br/>m.fit(X_train, y_train)<br/>print_score(m)</span></pre><p id="46b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2 .并行进行预测</p><p id="2f1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以前，我们使用每一棵树对每一行进行预测，然后计算结果的平均值和标准偏差。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="def3" class="lp jn hi ll b fi lq lr l ls lt">%time preds = np.stack([t.predict(X_valid) for t in m.estimators_])<br/>np.mean(preds[:,0]), np.std(preds[:,0])<br/><br/>CPU times: user 1.38 s, sys: 20 ms, total: 1.4 s<br/>Wall time: 1.4 s</span></pre><p id="91dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可能已经注意到这是以连续的方式工作的。相反，我们可以并行调用多个树上的预测函数！这可以通过使用fastai库中的<em class="lh"> parallel_trees </em>函数来实现。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="c86d" class="lp jn hi ll b fi lq lr l ls lt">def get_preds(t): return t.predict(X_valid)<br/>%time preds = np.stack(parallel_trees(m, get_preds))<br/>np.mean(preds[:,0]), np.std(preds[:,0])</span></pre><p id="0416" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里花的时间更少，结果完全一样！我们现在将创建数据的副本，这样我们所做的任何更改都不会影响原始数据集。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="c778" class="lp jn hi ll b fi lq lr l ls lt">x = raw_valid.copy()</span></pre><p id="a4dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们有了预测，我们就可以计算RMSLE来确定模型的表现如何。但是总体值并不能帮助我们确定某一行的预测值有多接近，也不能帮助我们确定预测值是否正确。在这种情况下，我们将查看各行的标准偏差。</p><p id="21c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果一行不同于训练集中存在的那些行，则每棵树将给出不同的值作为预测。这意味着标准偏差将会很高。另一方面，树将对与训练集t中存在的行非常相似的行做出几乎相似的预测，即，标准偏差将很低。因此，基于标准差的值，我们可以决定我们对预测有多有信心。</p><p id="f5e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们保存这些预测和标准差:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="b36d" class="lp jn hi ll b fi lq lr l ls lt">x['pred_std'] = np.std(preds, axis=0)<br/>x['pred'] = np.mean(preds, axis=0)</span></pre><h1 id="4539" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">置信区间</h1><p id="309d" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">现在，让我们从数据集中取出一个变量，并可视化它的分布，了解它实际代表什么。我们将从<em class="lh">外壳</em>变量开始。</p><ol class=""><li id="392a" class="kk kl hi ih b ii ij im in iq ld iu le iy lf jc kr ks kt ku bi translated">计算出变量<em class="lh">闭包:</em>中每个类别的值计数</li></ol><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="c38c" class="lp jn hi ll b fi lq lr l ls lt">x.Enclosure.value_counts().plot.barh()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lu"><img src="../Images/c28813deaa071dec662c201c65b0aeca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/0*ehtYj6yMXd3Ois8j.png"/></div></figure><p id="0540" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.对于每个类别，下面是<em class="lh">销售价格</em>的平均值、预测值和标准偏差。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="a11e" class="lp jn hi ll b fi lq lr l ls lt">flds = ['Enclosure', 'SalePrice', 'pred', 'pred_std']<br/>enc_summ = x[flds].groupby('Enclosure', as_index=False).mean()<br/>enc_summ</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/4629abe36120e58d9bfe505071129ae9.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/0*G6K6BSnIRSe5UzML.png"/></div></figure><p id="bb2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实际销售价格和预测值在三个类别中几乎相似—“EROPS”、“EROPS w AC”、“OROPS”(其余为空值)。由于这些空值列没有添加任何额外的信息，我们将删除它们，并可视化<em class="lh">销售价格</em>和预测的图表:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="e8c9" class="lp jn hi ll b fi lq lr l ls lt">enc_summ = enc_summ[~pd.isnull(enc_summ.SalePrice)]<br/>enc_summ.plot('Enclosure', 'pred', 'barh', xerr='pred_std', alpha=0.6, xlim=(0,11));</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lw"><img src="../Images/197f62542fe172345c12af9163575d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/0*-IJtvZh_XAbt3XW0.png"/></div></figure><p id="0bf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，黑色小条代表标准偏差。同样，让我们看看另一个变量— <em class="lh"> ProductSize </em>。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="09ba" class="lp jn hi ll b fi lq lr l ls lt">#the value count for each category raw_valid.ProductSize.value_counts().plot.barh();</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lx"><img src="../Images/f8e5342f5e1df58fc0b1cb993d1d238d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/0*urMMilZxfHNZR6Rv.png"/></div></figure><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="5577" class="lp jn hi ll b fi lq lr l ls lt">#category wise mean for sale price, prediction and standard deviation<br/>flds = ['ProductSize', 'SalePrice', 'pred', 'pred_std']<br/>summ = x[flds].groupby(flds[0]).mean()<br/>summ</span></pre><p id="4175" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将取标准偏差值和预测总和的比值，以便比较哪一个类别具有更高的偏差。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="ab4a" class="lp jn hi ll b fi lq lr l ls lt">(summ.pred_std/summ.pred).sort_values(ascending=False)</span><span id="6b35" class="lp jn hi ll b fi ly lr l ls lt">ProductSize<br/>Large             0.034871<br/>Compact           0.034297<br/>Small             0.030545<br/>Large / Medium    0.027799<br/>Medium            0.026928<br/>Mini              0.026247<br/>dtype: float64</span></pre><p id="ef9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“大”和“小”类别的标准差较高。你那是为什么？在继续阅读之前，花点时间思考一下答案。</p><p id="0cd4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看<em class="lh"> ProductSize中每个类别值的条形图。</em>找到原因了？这两个类别的行数较少。因此，该模型对这些变量的预测精度相对较低。</p><p id="16d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">利用这些信息，我们可以说，我们对迷你、中型和中型/大型产品尺寸的预测更有信心，而对小型、紧凑型和大型产品的预测信心较低。</p><h1 id="769d" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">特征重要性</h1><p id="15fd" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">特征重要性是机器学习模型的关键方面之一。理解哪个变量对模型的贡献最大对于解释结果至关重要。这就是数据科学家在构建需要向非技术利益相关者解释的模型时所努力追求的。</p><p id="9314" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的数据集有多个要素，通常很难理解哪个要素占主导地位。这就是随机森林的特征重要性函数如此有用的地方。让我们看看当前模型的10个最重要的特性(包括根据它们的重要性对它们进行可视化):</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="a718" class="lp jn hi ll b fi lq lr l ls lt">fi = rf_feat_importance(m, df_trn)<br/>fi[:10]</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/f29dc77c535b45f902f7679a5a2ede11.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/0*RPeGf29tshVRS508.png"/></div></figure><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="7161" class="lp jn hi ll b fi lq lr l ls lt">fi.plot('cols', 'imp', figsize=(10,6), legend=False);</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/a253bb2e0ed368394f6bea79d7aaa7f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/0*6hvDGmGjdn_TuCmG.png"/></div></figure><p id="7539" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个非常直观的情节。这是30大功能的柱状图可视化:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="3b60" class="lp jn hi ll b fi lq lr l ls lt">def plot_fi(fi):<br/>return fi.plot('cols','imp','barh', figsize=(12,7), legend=False)<br/>plot_fi(fi[:30]);</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mb"><img src="../Images/1ade8020d05f6de417319c52724dad98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aUYAg7grUYyaXkK7.png"/></div></div></figure><p id="dfeb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">显然<em class="lh">年制</em>是最重要的特征，其次是<em class="lh">车钩_系统。</em>大多数特征在最终模型中似乎都不太重要。让我们通过移除这些特征并检查这是否影响模型的性能来验证这种说法。</p><p id="d65d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们将仅使用要素重要性大于0.005的要素构建随机森林模型:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="e217" class="lp jn hi ll b fi lq lr l ls lt">to_keep = fi[fi.imp&gt;0.005].cols <br/>len(to_keep)</span><span id="7ca1" class="lp jn hi ll b fi ly lr l ls lt">24</span><span id="05db" class="lp jn hi ll b fi ly lr l ls lt">df_keep = df_trn[to_keep].copy()<br/>X_train, X_valid = split_vals(df_keep, n_trn)<br/><br/>m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5,<br/>n_jobs=-1, oob_score=True)<br/>m.fit(X_train, y_train)<br/>print_score(m)</span><span id="bb87" class="lp jn hi ll b fi ly lr l ls lt">[0.20685390156773095, 0.24454842802383558, 0.91015213846294174, 0.89319840835270514, 0.8942078920004991]</span></pre><p id="d06c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">仔细想想，删除冗余列应该不会降低模型分数，对吗？在这种情况下，模型性能略有提高。我们之前删除的一些特征可能与其他特征高度共线，因此删除它们不会对模型产生负面影响。让我们再次检查特性重要性，以验证我们的假设:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="b7f9" class="lp jn hi ll b fi lq lr l ls lt">fi = rf_feat_importance(m, df_keep)<br/>plot_fi(fi)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mg"><img src="../Images/0c312b5e74aa161019a1415fc6ff3cbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XFHfcd7uhcFTefie.png"/></div></div></figure><p id="af8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">年制</em>和C <em class="lh">输出系统</em>变量的特征重要性差异更显著。从移除的特征列表中，一些特征与<em class="lh"> YearMade、</em>高度共线，导致它们之间的特征重要性分布。</p><p id="b0ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">移除这些特征后，我们可以看到<em class="lh">年制</em>和<em class="lh">联轴器系统</em>的重要性之间的差异比之前的图有所增加。以下是如何计算特征重要性的详细说明:</p><ul class=""><li id="cc30" class="kk kl hi ih b ii ij im in iq ld iu le iy lf jc lg ks kt ku bi translated"><strong class="ih hj">考虑所有列，计算r平方:</strong>假设在这种情况下，r平方为0.89</li><li id="a313" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated">现在<strong class="ih hj">随机打乱任意一列</strong>的值，比如说<em class="lh"> YearMade。他的列与目标变量无关</em></li><li id="106c" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><strong class="ih hj">再算一下r平方:</strong>r平方已经降到0.8了。这表明<em class="lh"> YearMade </em>变量是一个重要的特性</li><li id="7716" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><strong class="ih hj">取另一个变量</strong>，说<em class="lh">圈地，</em>和<strong class="ih hj">随机洗牌</strong></li><li id="2380" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><strong class="ih hj">计算r平方:</strong>现在假设r平方即将为0.84。这表明该变量很重要，但相对来说不如<em class="lh">年制</em>变量重要</li></ul><p id="fef0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就完成了第3课的实施！我鼓励您尝试这些代码，并在您自己的机器上进行试验，以真正理解随机森林模型的每个方面是如何工作的。</p><h1 id="87d1" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">机器学习简介:第4课</h1><p id="b979" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在这一课中，杰瑞米·霍华德先对第三课进行了快速概述，然后介绍了一些重要的概念，如热编码、树状图和部分依赖。下面是该讲座的YouTube视频(或者您可以直接跳到下面的实现):</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="li lj l"/></div></figure><h1 id="9660" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">一键编码</h1><p id="3b54" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在本系列的第一篇文章中，我们了解到许多机器学习模型无法处理分类变量。使用<em class="lh"> proc_df </em>，我们将分类变量转换成数字列。例如，我们有一个变量<em class="lh"> UsageBand </em>，它有三个级别——“高”、“低”和“中”。我们用数字(0，1，2)代替了这些类别，以便于我们自己。</p><p id="6276" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">肯定有另一种方式来处理这件事，对我们来说要省力得多。有！</p><p id="9842" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以为每个类别创建单独的列，而不是将这些类别转换成数字。列<em class="lh"> UsageBand </em>可以替换为三列:</p><ul class=""><li id="e473" class="kk kl hi ih b ii ij im in iq ld iu le iy lf jc lg ks kt ku bi translated"><em class="lh"> UsageBand_low </em></li><li id="0dbe" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><em class="lh"> UsageBand_medium </em></li><li id="aa31" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><em class="lh"> UsageBand_high </em></li></ul><p id="e604" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个都有1和0作为值。这被称为一键编码。</p><p id="cec3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当类别远远超过3个时会发生什么？如果我们有超过10个呢？我们举个例子来理解这一点。</p><p id="7051" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们在数据集中有一个列'<em class="lh"> zip_code </em>'，它对每一行都有一个唯一的值。在这里使用一次性编码对模型没有好处，最终会增加运行时间(一个双输的场景)。</p><p id="6c77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用fastai中的<em class="lh"> proc_df </em>，我们可以通过传递一个参数<em class="lh"> max_n_cat </em>来执行一键编码。在这里，我们设置了<em class="lh"> max_n_cat=7 </em>，这意味着级别大于7的变量(如邮政编码)将不会被编码，而所有其他变量将被一次性编码。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="95df" class="lp jn hi ll b fi lq lr l ls lt">df_trn2, y_trn, nas = proc_df(df_raw, 'SalePrice', max_n_cat=7)<br/>X_train, X_valid = split_vals(df_trn2, n_trn)<br/>m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3,<br/>     max_features=0.6, n_jobs=-1, oob_score=<strong class="ll hj">True</strong>)<br/>m.fit(X_train, y_train)<br/>print_score(m)</span><span id="1a2d" class="lp jn hi ll b fi ly lr l ls lt">[0.2132925755978791, 0.25212838463780185, 0.90966193351324276, 0.88647501408921581, 0.89194147155121262]</span></pre><p id="5b4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这有助于确定特定列中的特定级别是否重要。由于我们已经将分类变量的每个级别分开，绘制特征重要性也将向我们展示它们之间的比较:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="c4a9" class="lp jn hi ll b fi lq lr l ls lt">fi = rf_feat_importance(m, df_trn2)<br/>fi[:25]</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mh"><img src="../Images/3d2e0f5593d4137763c8e4da45e66f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YHTNLATXBLYcYFU-.png"/></div></div></figure><p id="3f74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">早先，<em class="lh"> YearMade </em>是数据集中最重要的特征，但是<em class="lh"> EROPS w AC </em>在上图中具有更高的特征重要性。好奇这个变量是什么？别急，我们会在下一节讨论EROPS w AC实际代表的是什么。</p><h1 id="dfd5" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">移除冗余特征</h1><p id="4167" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">到目前为止，我们已经了解到，拥有大量的要素会影响模型的性能，并且还会使解释结果变得困难。在本节中，我们将了解如何识别冗余特征并将其从数据中移除。</p><p id="1240" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用聚类分析，更具体地说是等级聚类，来识别相似的变量。在这种技术中，我们观察每一个物体，并识别它们中哪些在特征方面最接近。然后这些变量被它们的中点所取代。为了更好地理解这一点，让我们看一下数据集的聚类图:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="43a1" class="lp jn hi ll b fi lq lr l ls lt">from scipy.cluster import hierarchy as hc<br/>corr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)<br/>corr_condensed = hc.distance.squareform(1-corr)<br/>z = hc.linkage(corr_condensed, method='average')<br/>fig = plt.figure(figsize=(16,10))<br/>dendrogram = hc.dendrogram(z, labels=df_keep.columns,<br/>    orientation='left', leaf_font_size=16)<br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mi"><img src="../Images/438d25db9b8504a39536fbb3df3e07f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PtizHe1HZsQ9NFD_.png"/></div></div></figure><p id="298c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的树状图中，我们可以看到变量<em class="lh">saleeyear</em>和<em class="lh">saleelast</em>彼此非常相似，并且倾向于表示同一事物。同样，<em class="lh">抓地齿_履带</em>、<em class="lh">液压_流量</em>和<em class="lh">连接器_系统</em>高度相关。<em class="lh">product group</em>&amp;<em class="lh">ProductGroupDesc</em>和<em class="lh">fibase model</em>&amp;<em class="lh">fiModelDesc</em>也是如此。我们将逐一删除这些功能，并看看它如何影响模型性能。</p><p id="adac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们定义一个函数来计算出袋(OOB)分数(以避免重复相同的代码行):</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="942c" class="lp jn hi ll b fi lq lr l ls lt">#define function to calculate oob score<br/>def get_oob(df):<br/>  m = RandomForestRegressor(n_estimators=30, min_samples_leaf=5, max_features=0.6, n_jobs=-1, oob_score=True)<br/>  x, _ = split_vals(df, n_trn)<br/>  m.fit(x, y_train)<br/>  return m.oob_score_</span></pre><p id="94cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了便于比较，以下是删除任何功能之前的原始OOB评分:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="2762" class="lp jn hi ll b fi lq lr l ls lt">get_oob(df_keep) <br/>0.89019425494301454</span></pre><p id="af18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在一次放下一个变量，然后计算分数:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="61e8" class="lp jn hi ll b fi lq lr l ls lt">for c in ('saleYear', 'saleElapsed', 'fiModelDesc', 'fiBaseModel', 'Grouser_Tracks', 'Coupler_System'):<br/>  print(c, get_oob(df_keep.drop(c, axis=1)))</span><span id="7e29" class="lp jn hi ll b fi ly lr l ls lt">saleYear 0.889037446375<br/>saleElapsed 0.886210803445<br/>fiModelDesc 0.888540591321<br/>fiBaseModel 0.88893958239<br/>Grouser_Tracks 0.890385236272<br/>Coupler_System 0.889601052658</span></pre><p id="67df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这并没有严重影响OOB的分数。现在让我们从每对变量中移除一个变量，并检查总得分:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="cc18" class="lp jn hi ll b fi lq lr l ls lt">to_drop = ['saleYear', 'fiBaseModel', 'Grouser_Tracks']<br/>get_oob(df_keep.drop(to_drop, axis=1))</span><span id="d27b" class="lp jn hi ll b fi ly lr l ls lt">0.88858458047200739</span></pre><p id="d066" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">分数从0.8901变成了0.8885。我们将在完整的数据集上使用这些选定的要素，并查看我们的模型如何执行:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="66ad" class="lp jn hi ll b fi lq lr l ls lt">df_keep.drop(to_drop, axis=1, inplace=True)<br/>X_train, X_valid = split_vals(df_keep, n_trn)<br/>reset_rf_samples()<br/><br/>m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)<br/>m.fit(X_train, y_train)<br/>print_score(m)</span><span id="29f5" class="lp jn hi ll b fi ly lr l ls lt">[0.12615142089579687, 0.22781819082173235, 0.96677727309424211, 0.90731173105384466, 0.9084359846323049]</span></pre><p id="95e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦这些变量从原始数据框架中移除，模型在验证集上的得分变成0.907。</p><h1 id="5d53" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">部分依赖</h1><p id="705b" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">我将在这里介绍另一种技术，它有可能帮助我们更好地理解数据。这种技术被称为部分依赖，它被用来找出特征是如何与目标变量相关的。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="530b" class="lp jn hi ll b fi lq lr l ls lt">from pdpbox import pdp<br/>from plotnine import *<br/><br/>set_rf_samples(50000)<br/><br/>df_trn2, y_trn, nas = proc_df(df_raw, 'SalePrice', max_n_cat=7)<br/>X_train, X_valid = split_vals(df_trn2, n_trn)<br/>m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.6, n_jobs=-1)<br/>m.fit(X_train, y_train);<br/><br/>plot_fi(rf_feat_importance(m, df_trn2)[:10]);</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mj"><img src="../Images/f0bc886d27b884eb04a4507d8df1610c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ua0Guo8uIeUl6T8o.png"/></div></div></figure><p id="1560" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们比较一下<em class="lh">年制</em>和<em class="lh">售价</em>。如果你为<em class="lh">年制造</em>和<em class="lh">年销售</em>创建一个散点图，你会注意到一些车辆是在1000年制造的，这实际上是不可能的。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="0c4c" class="lp jn hi ll b fi lq lr l ls lt">df_raw.plot('YearMade', 'saleElapsed', 'scatter', alpha=0.01, figsize=(10,8));</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mk"><img src="../Images/ee6d002f1e23a055e97b46435a94e7d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/0*CgDcpPkOBTx-AWUg.png"/></div></figure><p id="0e3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些可能是最初丢失的值，已被替换为1，000。为了保持实用性，我们将关注大于1930年的<em class="lh"> YearMade </em>变量的值，并使用流行的<em class="lh"> ggplot </em>包创建一个图。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="3eeb" class="lp jn hi ll b fi lq lr l ls lt">x_all = get_sample(df_raw[df_raw.YearMade&gt;1930], 500)<br/>ggplot(x_all, aes('YearMade', 'SalePrice'))+stat_smooth(se=True, method='loess')</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ml"><img src="../Images/78c135c709d9eeab026a273d9d150aaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/0*u7po3jVkj9B4UBoB.png"/></div></figure><p id="216d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该图表明，除了1991年至1997年间的一次下跌外，最近生产的汽车的销售价格较高。这种下降可能有多种原因——经济衰退、消费者更喜欢价格较低的汽车，或者其他一些外部因素。为了理解这一点，我们将创建一个图表来显示<em class="lh"> YearMade </em>和<em class="lh"> SalePrice </em>之间的关系，假设所有其他特征值都相同。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="f766" class="lp jn hi ll b fi lq lr l ls lt">x = get_sample(X_train[X_train.YearMade&gt;1930], 500)<br/><br/>def plot_pdp(feat, clusters=None, feat_name=None):<br/>   feat_name = feat_name or feat<br/>   p = pdp.pdp_isolate(m, x, feat)<br/>   return pdp.pdp_plot(p, feat_name, plot_lines=True, cluster=clusters is not None, n_cluster_centers=clusters)<br/><br/>plot_pdp('YearMade')</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mj"><img src="../Images/88372c8bd9a9884078e4b6a20852b6d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vHW1K6f-cNodosDJ.png"/></div></div></figure><p id="9ab6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过将每一行的<em class="lh">年份</em>固定为1960年，然后是1961年，以此类推，可以得到这个图。简单地说，我们取一组行，当<em class="lh"> YearMade </em>是1960年时，计算每行的<em class="lh">销售价格</em>。然后我们再次取整组，通过将<em class="lh">年制</em>设定为1962年来计算<em class="lh">销售价格</em>。我们重复多次，这导致了我们在上面的图中看到的多条蓝线。深黑线代表平均值。<strong class="ih hj">这证实了我们的假设，即最近生产的汽车销售价格会上升。</strong></p><p id="363e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，您可以检查其他功能，如<em class="lh">销售过去时间</em>，或<em class="lh">年制</em>和<em class="lh">销售过去时间</em>。对<em class="lh"> Enclosure </em>下的类别执行相同的步骤(因为<em class="lh"> Enclosure_EROPS w AC </em>被证明是最重要的特性之一)，结果图如下所示:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="fa40" class="lp jn hi ll b fi lq lr l ls lt">plot_pdp(['Enclosure_EROPS w AC', 'Enclosure_EROPS', 'Enclosure_OROPS'], 5, 'Enclosure')</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mj"><img src="../Images/cc08f8c93932e7027d96f79f82bc71a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CMSvajFIBSXiVZI-.png"/></div></div></figure><p id="0ec3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与其他两个变量(它们的值几乎相等)相比，Enclosure_EROPS w AC 似乎具有更高的销售价格。那么EROPS究竟是什么？这是一个封闭的翻车保护结构，可以有或没有空调。很明显，拥有AC的英雄会有更高的售价。</p><h1 id="4b46" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">树解释程序</h1><p id="0620" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">树解释器是另一种有趣的技术，它分析数据集中的每一行。到目前为止，我们已经了解了如何解释模型，以及每个特征(以及每个分类特征中的级别)如何影响模型预测。因此，我们现在将使用这个树解释器概念，并可视化特定行的预测。</p><p id="3ef3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们导入树解释器库，并评估验证集中第一行的结果。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="c59a" class="lp jn hi ll b fi lq lr l ls lt">from treeinterpreter import treeinterpreter as ti<br/>df_train, df_valid = split_vals(df_raw[df_keep.columns], n_trn)<br/>row = X_valid.values[None,0]<br/>row<br/></span><span id="9b48" class="lp jn hi ll b fi ly lr l ls lt">array([[4364751, 2300944, 665, 172, 1.0, 1999, 3726.0, 3, 3232, 1111, 0, 63, 0, 5, 17, 35, 4, 4, 0, 1, 0, 0,<br/>       0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 19, 29, 3, 2, 1, 0, 0, 0, 0, 0, 2010, 9, 37,<br/>       16, 3, 259, False, False, False, False, False, False, 7912, False, False]], dtype=object)</span></pre><p id="16c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是验证集中第一行(以及每一列)的原始值。使用树解释器，我们将使用随机森林模型进行预测。树解释器给出三个结果——预测、偏差和贡献。</p><ul class=""><li id="7852" class="kk kl hi ih b ii ij im in iq ld iu le iy lf jc lg ks kt ku bi translated">预测是由随机森林模型预测的值</li><li id="a7cb" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated">偏差是整个数据集的目标变量的平均值</li><li id="a931" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated">贡献是每一列改变预测值的量</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mm"><img src="../Images/c9f9c8ed2c5f434b82d884508525d7aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WwS-5O1MxRp4rsse.png"/></div></div></figure><p id="8e2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="lh">耦合器_系统</em> &lt; 0.5的值从10.189增加到10.345，小于0.2的外壳从10.345减少到9.955，以此类推。因此，贡献将代表预测值的这种变化。为了更好地理解这一点，请看下表:</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mn"><img src="../Images/e5caabf337bfdfabe52d6813e1515892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*k9FRI5d6S_u_iDbo.png"/></div></div></figure><p id="6516" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在此表中，我们存储了每个特征和分割点的值(从上图中验证)。变化是分割前后的值之差。这些是用Excel中的瀑布图绘制的。这里看到的变化是针对单个树的。随机森林中所有树的平均变化由树解释器中的<em class="lh">贡献</em>给出。</p><p id="9c41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">打印验证集中第一行的预测和偏差:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="7c5e" class="lp jn hi ll b fi lq lr l ls lt">prediction, bias, contributions = ti.predict(m, row)<br/>prediction[0], bias[0]</span><span id="747a" class="lp jn hi ll b fi ly lr l ls lt">(9.1909688098736275, 10.10606580677884)</span></pre><p id="d9fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一行数据集中每个要素的<em class="lh">贡献</em>值:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="436f" class="lp jn hi ll b fi lq lr l ls lt">idxs = np.argsort(contributions[0])<br/>[o for o in zip(df_keep.columns[idxs], df_valid.iloc[0][idxs], contributions[0][idxs])]</span><span id="11dc" class="lp jn hi ll b fi ly lr l ls lt">[('ProductSize', 'Mini', -0.54680742853695008),<br/>('age', 11, -0.12507089451852943),<br/>('fiProductClassDesc',<br/> 'Hydraulic Excavator, Track - 3.0 to 4.0 Metric Tons',<br/> -0.11143111128570773),<br/>('fiModelDesc', 'KX1212', -0.065155113754146801),<br/>('fiSecondaryDesc', nan, -0.055237427792181749),<br/>('Enclosure', 'EROPS', -0.050467175593900217),<br/>('fiModelDescriptor', nan, -0.042354676935508852),<br/>('saleElapsed', 7912, -0.019642242073500914),<br/>('saleDay', 16, -0.012812993479652724),<br/>('Tire_Size', nan, -0.0029687660942271598),<br/>('SalesID', 4364751, -0.0010443985823001434),<br/>('saleDayofyear', 259, -0.00086540581130196688),<br/>('Drive_System', nan, 0.0015385818526195915),<br/>('Hydraulics', 'Standard', 0.0022411701338458821),<br/>('state', 'Ohio', 0.0037587658190299409),<br/>('ProductGroupDesc', 'Track Excavators', 0.0067688906745931197),<br/>('ProductGroup', 'TEX', 0.014654732626326661),<br/>('MachineID', 2300944, 0.015578052196894499),<br/>('Hydraulics_Flow', nan, 0.028973749866174004),<br/>('ModelID', 665, 0.038307429579276284),<br/>('Coupler_System', nan, 0.052509808150765114),<br/>('YearMade', 1999, 0.071829996446492878)]</span></pre><p id="65d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">注意:如果您同时观看本文视频，数值可能会有所不同。这是因为最初这些值是根据索引排序的，而索引提供了不正确的信息。这一点在后面的视频和我们在整个课程中一直学习的笔记本中得到了纠正。</em></p><h1 id="ce19" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">机器学习导论:第5课</h1><p id="f23a" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在这个阶段，您应该对随机森林算法有了很好的理解。在第5课中，我们将重点讨论如何识别模型是否具有良好的泛化能力。杰瑞米·霍华德还谈到了树解释器、<em class="lh">贡献、</em>以及使用瀑布图理解树解释器(我们在上一课中已经介绍过了，所以不再赘述)。<strong class="ih hj">视频的主要重点是推断和理解我们如何从头开始构建随机森林算法。</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="li lj l"/></div></figure><h1 id="edd2" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">推断</h1><p id="2df5" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">如果一个模型建立在跨越四年的数据上，然后用于预测下一年的值，那么它可能表现不好。换句话说，该模型不进行外推。我们之前已经看到，训练分数和验证分数之间存在显著差异，这可能是因为我们的验证集由一组最近的数据点组成(并且模型使用时间相关变量进行预测)。</p><p id="9bd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，验证分数比OOB的<em class="lh">分数</em>差<em class="lh"> </em>这是不应该的，对吧？本系列的第一部分已经给出了关于<em class="lh"> OOB </em>分数的详细解释。解决这个问题的一个方法是直接解决它——处理与时间相关的变量。</p><p id="5b72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了找出哪些变量是时间相关的，我们将创建一个随机森林模型，试图预测某一行是否在验证集中。然后，我们将检查哪个变量对成功预测的贡献最大。</p><p id="8bae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">定义目标变量:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="bc7f" class="lp jn hi ll b fi lq lr l ls lt">df_ext = df_keep.copy()<br/>df_ext['is_valid'] = 1<br/>df_ext.is_valid[:n_trn] = 0<br/>x, y, nas = proc_df(df_ext, 'is_valid')<br/><br/>m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=<strong class="ll hj">True</strong>)<br/>m.fit(x, y);<br/>m.oob_score_</span><span id="7c7f" class="lp jn hi ll b fi ly lr l ls lt">0.99998753505765037</span></pre><p id="11e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型能够用r-square值0.99998分离训练集和验证集，最重要的特征是<em class="lh"> SaleID </em>、<em class="lh"> SaleElapsed </em>、<em class="lh"> MachineID。</em></p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="9846" class="lp jn hi ll b fi lq lr l ls lt">fi = rf_feat_importance(m, x)<br/>fi[:10]</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mo"><img src="../Images/d5102b1c9dba7d01b34c82c2852743b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/0*bW0igL-WJGi4X48k.png"/></div></figure><ul class=""><li id="cd9d" class="kk kl hi ih b ii ij im in iq ld iu le iy lf jc lg ks kt ku bi translated">SaleID当然不是一个随机的标识符，它应该是一个递增的顺序</li><li id="d31a" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated">看起来<em class="lh"> MachineID </em>有相同的趋势，并且能够分离训练集和验证集</li><li id="41b0" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><em class="lh"> SaleElapsed </em>是从数据集中的第一个日期算起的天数。由于我们的验证集具有来自完整数据的最新值，<em class="lh"> SaleElapsed </em>在这个数据集中会更高。为了证实假设，下面是训练和测试中三个变量的分布:</li></ul><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="d939" class="lp jn hi ll b fi lq lr l ls lt">feats=['SalesID', 'saleElapsed', 'MachineID']<br/>(X_train[feats]/1000).describe()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mp"><img src="../Images/3f53445ec8514c591b3534bdcc157e1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*829WLiYUk-X50kpT.png"/></div></figure><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="0902" class="lp jn hi ll b fi lq lr l ls lt">(X_valid[feats]/1000).describe()</span></pre><p id="ffdf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上表可以明显看出，这三个变量的平均值有很大不同。我们将删除这些变量，再次拟合随机森林并检查特征重要性:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="3cc4" class="lp jn hi ll b fi lq lr l ls lt">x.drop(feats, axis=1, inplace=True)<br/>m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)<br/>m.fit(x, y);<br/>m.oob_score_<br/></span><span id="14a0" class="lp jn hi ll b fi ly lr l ls lt">0.9789018385789966</span><span id="01e5" class="lp jn hi ll b fi ly lr l ls lt">fi = rf_feat_importance(m, x)<br/>fi[:10]</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/34e3c442cc651500de0161579ff314e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/0*4pQfWxfnXK10QDY6.png"/></div></figure><p id="9ba3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管这些变量明显与时间有关，但它们对预测也很重要。在我们放弃这些变量之前，我们需要检查它们如何影响<em class="lh"> OOB </em>分数。计算样本中的初始<em class="lh"> OOB </em>分数用于比较:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="413c" class="lp jn hi ll b fi lq lr l ls lt">set_rf_samples(50000)<br/>feats=['SalesID', 'saleElapsed', 'MachineID', 'age', 'YearMade', 'saleDayofyear']<br/>X_train, X_valid = split_vals(df_keep, n_trn)<br/>m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)<br/>m.fit(X_train, y_train)<br/>print_score(m)</span><span id="46f9" class="lp jn hi ll b fi ly lr l ls lt">[0.21136509778791376, 0.2493668921196425, 0.90909393040946562, 0.88894821098056087, 0.89255408392415925]</span></pre><p id="4f7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">逐一删除每个功能:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="7e66" class="lp jn hi ll b fi lq lr l ls lt">for f in feats:<br/><br/>  df_subs = df_keep.drop(f, axis=1)<br/>  X_train, X_valid = split_vals(df_subs, n_trn)<br/>  m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)<br/>  m.fit(X_train, y_train)<br/>  print(f)<br/>  print_score(m)</span><span id="bf22" class="lp jn hi ll b fi ly lr l ls lt">SalesID<br/>0.20918653475938534, 0.2459966629213187, 0.9053273181678706, 0.89192968797265737, 0.89245205174299469]<br/><br/>saleElapsed<br/>[0.2194124612957369, 0.2546442621643524, 0.90358104739129086, 0.8841980790762114, 0.88681881032219145]<br/><br/>MachineID<br/>[0.206612984511148, 0.24446409479358033, 0.90312476862123559, 0.89327205732490311, 0.89501553584754967]<br/><br/>age<br/>[0.21317740718919814, 0.2471719147150774, 0.90260198977488226, 0.89089460707372525, 0.89185129799503315]<br/><br/>YearMade<br/>[0.21305398932040326, 0.2534570148977216, 0.90555219348567462, 0.88527538596974953, 0.89158854973045432]<br/><br/>saleDayofyear<br/>[0.21320711524847227, 0.24629839782893828, 0.90881970943169987, 0.89166441133215968, 0.89272793857941679]</span></pre><p id="b5dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从结果来看，<em class="lh">年龄、MachineID </em>和<em class="lh"> SaleDayofYear </em>确实提高了分数，而其他人则没有。因此，我们将删除剩余的变量，并在完整的数据集上拟合随机森林。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="853e" class="lp jn hi ll b fi lq lr l ls lt">reset_rf_samples()<br/>df_subs = df_keep.drop(['SalesID', 'MachineID', 'saleDayofyear'],axis=1)<br/>X_train, X_valid = split_vals(df_subs, n_trn)<br/>m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=<strong class="ll hj">True</strong>)<br/>m.fit(X_train, y_train)<br/>print_score(m)</span><span id="899c" class="lp jn hi ll b fi ly lr l ls lt">[0.1418970082803121, 0.21779153679471935, 0.96040441863389681, 0.91529091848161925, 0.90918594039522138]</span></pre><p id="a336" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">去除时间相关变量后，验证分数(0.915)现在比<em class="lh"> OOB </em>分数(0.909)好。我们现在可以使用其他参数，如<em class="lh">n _ estimator</em>on<em class="lh">max _ features</em>。为了创建最终的模型，杰里米将树的数量增加到160棵，结果如下:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="e14c" class="lp jn hi ll b fi lq lr l ls lt">m = RandomForestRegressor(n_estimators=160, max_features=0.5, n_jobs=-1, oob_score=<strong class="ll hj">True</strong>)<br/>%time m.fit(X_train, y_train)<br/>print_score(m)</span><span id="a0bc" class="lp jn hi ll b fi ly lr l ls lt">CPU times: user 6min 3s, sys: 2.75 s, total: 6min 6s<br/>Wall time: 16.7 s<br/>[0.08104912951128229, 0.2109679613161783, 0.9865755186304942, 0.92051576728916762, 0.9143700001430598]</span></pre><p id="87e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">验证分数为0.92，而RMSE降至0.21。确实是一大进步！</p><h1 id="6c94" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">从零开始的随机森林</h1><p id="6b51" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">我们已经了解了随机森林模型实际上是如何工作的，如何选择特征以及如何最终做出预测。在本节中，我们将从头开始创建我们自己的随机森林模型。这是本节的笔记本:<a class="ae jl" href="https://github.com/fastai/fastai/blob/master/courses/ml1/lesson3-rf_foundations.ipynb" rel="noopener ugc nofollow" target="_blank">从零开始的随机森林</a>。</p><p id="d7f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将从导入基本库开始:</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="19aa" class="lp jn hi ll b fi lq lr l ls lt">%load_ext autoreload<br/>%autoreload 2<br/>%matplotlib inline<br/><br/>from fastai.imports import *<br/>from fastai.structured import *<br/>from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier<br/><br/>from IPython.display import display<br/>from sklearn import metrics</span></pre><p id="1783" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们先用两个变量。一旦我们确信模型能够很好地处理这些选定的变量，我们就可以使用完整的功能集了。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="e241" class="lp jn hi ll b fi lq lr l ls lt">PATH = "data/bulldozers/"<br/><br/>df_raw = pd.read_feather('tmp/bulldozers-raw')<br/>df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')<br/>def split_vals(a,n): return a[:n], a[n:]<br/><br/>n_valid = 12000<br/>n_trn = len(df_trn)-n_valid<br/><br/>X_train, X_valid = split_vals(df_trn, n_trn)<br/>y_train, y_valid = split_vals(y_trn, n_trn)<br/>raw_train, raw_valid = split_vals(df_raw, n_trn)<br/>x_sub = X_train[['YearMade', 'MachineHoursCurrentMeter']]</span></pre><p id="b1f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经加载了数据集，将它分为训练集和验证集，并选择了两个特征— <em class="lh"> YearMade </em>和<em class="lh"> MachineHoursCurrentMeter。从头开始构建任何模型时，首先要考虑的是——我们需要什么信息？因此，对于随机森林，我们需要:</em></p><ul class=""><li id="47c3" class="kk kl hi ih b ii ij im in iq ld iu le iy lf jc lg ks kt ku bi translated">一组特征— x</li><li id="9792" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated">目标变量— y</li><li id="65ca" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated">随机森林中的树的数量— n_trees</li><li id="bf67" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated">定义样本大小的变量— sample_sz</li><li id="4cae" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated">最小叶子大小的变量min _ leaf</li><li id="f351" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated">用于测试的随机种子</li></ul><p id="8c27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们用上面提到的输入定义一个类，并将随机种子设置为42。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="43a2" class="lp jn hi ll b fi lq lr l ls lt">class TreeEnsemble():<br/>   def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):<br/>       np.random.seed(42)<br/>       self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf<br/>       self.trees = [self.create_tree() for i in range(n_trees)]<br/><br/>   def create_tree(self):<br/>       rnd_idxs = np.random.permutation(len(self.y))[:self.sample_sz]<br/>       return DecisionTree(self.x.iloc[rnd_idxs], self.y[rnd_idxs], min_leaf=self.min_leaf)<br/>       <br/>   def predict(self, x):<br/>       return np.mean([t.predict(x) for t in self.trees], axis=0)</span></pre><p id="8868" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经创建了一个函数<em class="lh"> create_trees </em>，它将被调用n_trees的数量。函数<em class="lh"> create_trees </em>生成一组随机打乱的行(大小= <em class="lh"> sample_sz </em>)并返回<em class="lh">决策树。我们一会儿会看到决策树，但首先让我们弄清楚预测是如何创建和保存的。</em></p><p id="4485" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们之前了解到，在随机森林模型中，每棵树都对每一行进行预测，最后的预测是通过取所有预测的平均值来计算的。所以我们将创建一个预测函数，其中<em class="lh">。predict </em>用于每棵树来创建一个预测列表，这个列表的平均值被计算为我们的最终值。</p><p id="3bde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后一步是创建<em class="lh">决策树。</em>我们首先选择一个给出最小误差的特征和分割点。目前，此代码仅用于单个决策。如果代码运行成功，我们可以让它递归。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="b1d3" class="lp jn hi ll b fi lq lr l ls lt">class DecisionTree():<br/>   def __init__(self, x, y, idxs=None, min_leaf=5):<br/>       if idxs is None: idxs=np.arange(len(y))<br/>       self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf<br/>       self.n,self.c = len(idxs), x.shape[1]<br/>       self.val = np.mean(y[idxs])<br/>       self.score = float('inf')<br/>       self.find_varsplit()<br/>       <br/>   # This just does one decision; we'll make it recursive later<br/>   def find_varsplit(self):<br/>       for i in range(self.c): self.find_better_split(i)<br/>           <br/>   # We'll write this later!<br/>   def find_better_split(self, var_idx): pass<br/>   <br/>   @property<br/>   def split_name(self): return self.x.columns[self.var_idx]<br/>   <br/>   @property<br/>   def split_col(self): return self.x.values[self.idxs,self.var_idx]<br/><br/>   @property<br/>   def is_leaf(self): return self.score == float('inf')<br/>   <br/>   def __repr__(self):<br/>       s = f'n: {self.n}; val:{self.val}'<br/>       if not self.is_leaf:<br/>           s += f'; score:{self.score}; split:{self.split}; var:{self.split_name}'<br/>       return s</span></pre><p id="27ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh"> self.n </em>定义每棵树使用的行数，而<em class="lh"> self.c </em>是列数。<em class="lh"> self.val </em>计算每个指数的预测平均值。这段代码仍然不完整，将在下一课中继续。是的，第3部分即将推出！</p><h1 id="462d" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">其他主题</h1><ul class=""><li id="b3e4" class="kk kl hi ih b ii km im kn iq ko iu kp iy kq jc lg ks kt ku bi translated"><strong class="ih hj">在几秒钟内读取一个大型数据集:</strong>如果我们在读取文件本身的时候提供变量的数据类型，那么加载数据集的时间就会减少。使用这个拥有超过1亿行的数据集来看看这是怎么回事。</li></ul><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="5ff5" class="lp jn hi ll b fi lq lr l ls lt">types = {'id': 'int64',<br/>       'item_nbr': 'int32',<br/>       'store_nbr': 'int8',<br/>       'unit_sales': 'float32',<br/>       'onpromotion': 'object'}<br/>%%time<br/>df_test = pd.read_csv(f'{PATH}test.csv', parse_dates = ['date'], dtype=types, infer_datetime_format=True)</span><span id="a199" class="lp jn hi ll b fi ly lr l ls lt">CPU times: user 1min 41s, sys: 5.08s, total: 1min 46s <br/>Wall time: 1min 48s</span></pre><ul class=""><li id="fb8d" class="kk kl hi ih b ii ij im in iq ld iu le iy lf jc lg ks kt ku bi translated"><strong class="ih hj">基数:</strong>这是分类变量中的级别数。对于<em class="lh"> UsageBand </em>变量，我们有三个级别—高、低和中。因此基数是3。</li><li id="3652" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><strong class="ih hj">训练-验证-测试:</strong>在测试集上使用模型之前，有一个验证集来检查模型的性能是很重要的。经常发生的情况是，我们最终在验证集上过度拟合我们的模型。如果验证集不是测试集的真实代表，那么模型也会失败。<strong class="ih hj">因此，完整的数据应分为训练、验证和测试集，其中测试集应仅在结束时使用(而不是在参数调整期间)。</strong></li><li id="c991" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lg ks kt ku bi translated"><strong class="ih hj">交叉验证:</strong>交叉验证集创建多个验证集，并在每个验证集上测试模型。完整的数据被混洗并分成组，以5个为例。其中四组用于训练模型，一组用作验证集。在下一次迭代中，另外四个用于训练，一个用于验证。该步骤将重复五次，其中每组用作一次验证组。</li></ul><h1 id="3e01" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">结束注释</h1><p id="3b9a" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">我认为这是这个系列中最重要的文章之一。我怎么强调模型可解释性的重要性都不为过。在真实的行业场景中，您经常会面临必须向涉众(通常是非技术人员)解释模型结果的情况。</p><p id="d6bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你获得模型批准的机会将取决于你能够解释模型是如何以及为什么会这样。另外，用外行人能理解的方式向自己解释任何模型的性能总是一个好主意——这总是一个好习惯！</p><p id="1cb0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用下面的评论部分让我知道你的想法或者问你对这篇文章的任何问题。正如我提到的，第3部分即将推出，敬请期待！</p></div><div class="ab cl mr ms gp mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hb hc hd he hf"><p id="5e37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">原载于2018年10月29日</em><a class="ae jl" href="https://www.analyticsvidhya.com/blog/2018/10/interpret-random-forest-model-machine-learning-programmers/" rel="noopener ugc nofollow" target="_blank"><em class="lh">【www.analyticsvidhya.com</em></a><em class="lh">。</em></p></div></div>    
</body>
</html>