<html>
<head>
<title>Getting started with Apache Spark — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark入门—第1部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/getting-started-with-apache-spark-part-1-91b379204ae0?source=collection_archive---------12-----------------------#2020-07-10">https://medium.com/analytics-vidhya/getting-started-with-apache-spark-part-1-91b379204ae0?source=collection_archive---------12-----------------------#2020-07-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/97e6ced990d6fcb20cef0a1808ef54a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q7O2UbY_baJYVtNhVrHqtw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">资料来源:Udemy</figcaption></figure><p id="1c53" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在这个大数据时代，每分钟都在创造令人难以置信的大量数据，对企业来说，分析这些数据以获得快速洞察变得越来越重要。这就产生了对更快更有效的数据处理技术的需求。随着“大数据”和“数据科学”成为当今世界的流行语，难怪行业会落后于Apache Spark这样的大数据引擎。考虑到对Apache Spark开发人员的需求，我们可以肯定地说Spark是下一代大数据工具，也是您应该知道的最受欢迎的大数据技能之一。如果你期待在这个领域开始，那么这个博客有你想要的东西。</p><p id="ef1b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这篇博客是Apache Spark系列的第一篇<strong class="iw hj">、</strong>，在这篇<strong class="iw hj">、</strong>中，我们将看到什么是Apache Spark，为什么使用它，Spark的行业用例，以及它如何在无数行业中使用。我们还将了解Apache Spark生态系统及其组件。接下来，我们将看到为什么Spark是首选，它的哪些特性使它成为可取的，最后以Spark的内部架构及其工作方式结束。</p><h1 id="2f54" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">阿帕奇火花——是什么？</h1><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/5c565be000f61e5b60c9f46940565177.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*UUGMDuAP6c_brkuMM0Yk6g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">资料来源:PNGkey</figcaption></figure><p id="96d3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Apache Spark是一个数据处理框架，可以在非常短的时间内对非常大的数据集执行任务。Spark最初由加州大学伯克利分校开发，快速灵活，后来成为大数据领域最大的开源社区，被认为是世界上最好、最广泛使用的大数据处理框架之一。因此，它被各行各业的主要企业广泛采用。</p><p id="1a85" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Apache Spark是一个分布式数据处理框架，它可以通过将任务分布在多个节点上来快速处理大型数据。大规模部署Spark有助于在成千上万个节点的集群上高速处理甚至数Pb的数据！事实上，Spark进行大规模数据处理的速度比Hadoop快100倍。Spark可以执行批处理和流处理，这使它成为一个强大的引擎，可以以实时和批处理模式处理数据。凭借其易于使用的API，Spark使其用户更容易完成与分布式计算和大数据处理相关的工作。</p><p id="57a7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Spark建立在Scala之上，通过为Scala、Java、Python和最新的r提供API来支持多种语言。这是Spark的一个关键特性，使开发人员可以灵活地用他们方便的语言创建和运行应用程序。</p><h1 id="f9c5" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">Apache Spark用例</h1><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/0c65fcd7ce33167d273c6e3479ce910e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*o4kGqUZEGsXfzk7P.png"/></div></div></figure><p id="9545" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如今，几乎每个行业都在处理大数据。对于这些行业中的许多行业，考虑到Apache Spark惊人的特性和它提供的众多优势，Apache Spark是首选。Spark被几乎所有行业的许多公司广泛使用。它被大规模部署，在超过数千个节点的集群上共同处理数Pb的数据。以下是一些使用Spark处理大数据三个V的行业，即数量、速度和多样性。</p><ul class=""><li id="790f" class="kw kx hi iw b ix iy jb jc jf ky jj kz jn la jr lb lc ld le bi translated">今天，<strong class="iw hj">媒体和娱乐业</strong>作为发展最快的行业之一，正在向在线流媒体发展。像网飞这样的领先工业巨头使用Apache Spark进行实时流处理，每天处理数十亿个事件，以便向其客户提供个性化的在线推荐。此外，雅虎使用Spark进行机器学习，为其客户个性化网页和新闻文章。</li><li id="1234" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lb lc ld le bi translated"><strong class="iw hj">金融部门</strong>是实时处理发挥重要作用的另一个行业。Apache Spark用于分析和快速洞察客户细分、目标广告、信用风险评估、客户流失预测、交易欺诈检测等方面，以便在业务中做出正确的决策。它用于在分析大量事务日志时获得一流的结果。</li><li id="fa41" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lb lc ld le bi translated">Spark发挥重要作用的另一个领域是<strong class="iw hj">医疗保健行业</strong>，在该行业中，Spark用于分析大量患者健康记录和临床数据，以获得快速而有用的见解。</li><li id="f111" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lb lc ld le bi translated">来到<strong class="iw hj">旅游行业</strong>，像猫途鹰和OpenTable这样的领先旅游网站和应用程序使用Apache Spark来加速向用户提供定制化的推荐。</li><li id="50ff" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lb lc ld le bi translated">最后但同样重要的是，与数据分析和目标广告密不可分的一个行业是<strong class="iw hj">电子商务和零售部门</strong>。像阿里巴巴和易贝这样的电子商务领导者使用Spark来分析数Pb的数据。Spark的一些使用案例是定向广告、个性化推荐和优惠等。</li></ul><h1 id="350f" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">Spark生态系统及其组件</h1><p id="07b5" class="pw-post-body-paragraph iu iv hi iw b ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn lo jp jq jr hb bi translated">让我们简单了解一下Apache Spark生态系统及其组件。Spark整合了各种内置库和组件，即Spark core、Spark SQL、Spark Streaming、Spark MLlib和Spark GraphX。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/f11e17fad7569cc72c755faff7518730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZRKtlmT6gSkeli8mCsi0w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">星火生态系统</figcaption></figure><ol class=""><li id="d478" class="kw kx hi iw b ix iy jb jc jf ky jj kz jn la jr lq lc ld le bi translated"><strong class="iw hj"> Spark内核</strong>—Spark的基本功能建立在Spark内核之上。它整合了弹性分布式数据集(rdd ),这是Spark的主要抽象之一。Spark内核负责任务调度、故障恢复、内存计算和内存管理。它是处理大型数据集的基础。</li><li id="3afa" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lq lc ld le bi translated"><strong class="iw hj"> Spark SQL </strong> —它是Spark的一个模块，为Spark提供SQL接口，用于处理结构化和半结构化数据，并在这些数据上执行SQL查询。</li><li id="bb97" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lq lc ld le bi translated"><strong class="iw hj"> Spark Streaming </strong> —它是一个构建在Spark core之上的Spark组件，负责对从Apache Kafka、Apache Flume和Amazon Kinesis等数据流源获得的连续流动数据流进行高吞吐量、可扩展和容错的流处理。</li><li id="abc2" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lq lc ld le bi translated"><strong class="iw hj"> Spark MLlib </strong> —这是一个Spark库，有助于实现机器学习和深度学习算法，并使机器学习具有可扩展性。我们将在接下来的博客中详细讨论这个问题。</li><li id="f627" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lq lc ld le bi translated">Spark GraphX  —这是一个Spark API，用于操作和处理图形，并执行图形并行计算。</li></ol><h1 id="4a16" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">为什么是火花？</h1><p id="6a63" class="pw-post-body-paragraph iu iv hi iw b ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn lo jp jq jr hb bi translated">从数据收集开始，然后是数据清理和数据工程，再到高级分析，通过机器学习模型的培训、评估和验证来提供对数据的有意义的见解，像Apache Spark这样的统一框架将提供端到端的解决方案。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/d9d5b2ab845de3beab27de6fe0482774.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*c9hXC7Tftw0ntHiYtVY1YQ.png"/></div></figure><p id="837f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">该过程中涉及的主要步骤是收集数据、分析数据、清理数据、特征工程以及通过构建机器学习模型从数据中探索和生成见解。Spark在每一个步骤中都有自己的角色。这是Spark的优势，因为我们在这里讨论的数据类型是以TB和Pb为单位的，我们需要高度可扩展的管道。虽然像Pandas和NumPy这样的库在数据可以放入内存的单节点系统上工作得很好，但它们在处理大量数据时效率不高，我们需要一个统一的框架来更快地分发和处理数据。实时应用程序的实时分析处理大量实时生成的数据，如业务流程和交易。在这种情况下，Spark将成为首选解决方案，因为它能够支持高度可扩展的数据管道。</p><p id="3d3f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Spark支持批处理或实时数据。实时数据可以来自各种数据源，可以是Kafka消息或消息队列，也可以是来自物联网设备的实时数据，这些设备持续传输数百万笔交易，Spark可以使用其Spark流组件处理这些流数据。此外，Spark可以读取和写入各种系统，如MongoDB、Cassandra、HBase、谷歌云、亚马逊S3等。Spark与许多数据库系统和云基础设施的集成能力使其成为高度兼容和灵活的大数据框架。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/8c666e2073d8ccf5b458e06771fc1f9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/0*bdzHiY3-MUYUKixS.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">资料来源:Databricks</figcaption></figure><h1 id="5399" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">Spark如何工作</h1><p id="e18f" class="pw-post-body-paragraph iu iv hi iw b ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn lo jp jq jr hb bi translated">在Spark中，大量数据被分割成块，分布在多个系统中，以对数据执行任务，而不是依赖于单个节点(如下图所示)。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/4881f38f4e3d243ae8801d20b317d59a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*x9UgHo63dKQ6kxQ678ffNw.png"/></div></figure><p id="dda7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Spark应用程序的两个基本组件是驱动程序，它将应用程序代码转换成多个任务，这些任务分布在执行器上，执行器运行在工作节点上并执行分配给它们的任务。集群管理器充当这两个组件之间的中介。当客户端提交Spark应用程序代码时，驱动程序启动并初始化Spark上下文，它将转换和动作转换为逻辑有向无环图(DAG ),该图确定应该在每个节点上执行什么任务以及以什么顺序执行(我们将在接下来的博客中详细研究Spark上下文、转换和动作)。驱动程序还在DAG上执行优化，并在worker节点中的执行器之间分配和调度工作。然后，集群管理器启动工作节点中的执行器，并发送每个节点要执行的任务的详细信息。执行者执行工作并向驱动者报告。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/a452df483e149b2315636a89700f6795.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*DJ4t3razJClvW-SswybLKg.jpeg"/></div></figure></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="a1c3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">总而言之，我们从Spark是什么、为什么使用Spark、Spark的一些特性及其行业使用案例开始，然后是Apache Spark生态系统的组件，最后是它的内部工作和架构。</p><p id="1b9f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">祝贺您开始使用Apache Spark，您不再是Spark的新手了！但是记住还有很长的路要走。查看本系列中的其他文章，继续您的Spark之旅并了解更多信息。在下一篇博客中，我们将关注PySpark和更多。快乐学习！</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="d8d2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">查看本系列中的其他博客</p><p id="c258" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae mc" rel="noopener" href="/@anveshrithaas/introduction-to-pyspark-part-2-6d6113e31592"> <strong class="iw hj"> <em class="md">第二部分PySpark简介</em> </strong> </a></p><p id="b2b1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae mc" rel="noopener" href="/@anveshrithaas/understanding-spark-rdds-part-3-3b1b9331652a"> <strong class="iw hj"> <em class="md">第三部分—了解Spark RDDs </em> </strong> </a></p><p id="48ca" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae mc" rel="noopener" href="/@anveshrithaas/machine-learning-in-pyspark-part-4-5813e831922f"> <strong class="iw hj"> <em class="md">第四部分PySpark中的机器学习</em> </strong> </a></p><p id="9e9f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae mc" rel="noopener" href="/@anveshrithaas/end-to-end-machine-learning-pipeline-on-databricks-part-5-c10273e2cd88"> <strong class="iw hj"> <em class="md">第五部分——数据块上的端到端机器学习流水线</em> </strong> </a></p></div></div>    
</body>
</html>