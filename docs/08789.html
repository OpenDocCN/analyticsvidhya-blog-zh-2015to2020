<html>
<head>
<title>Building Support Vector Machines Algorithm from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始构建支持向量机算法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-support-vector-machines-from-algorithm-scratch-a4b19368a64b?source=collection_archive---------8-----------------------#2020-08-13">https://medium.com/analytics-vidhya/building-support-vector-machines-from-algorithm-scratch-a4b19368a64b?source=collection_archive---------8-----------------------#2020-08-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="679a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">支持向量机是一种监督学习模型，其算法用于分类和回归分析。它是非概率性的，这意味着数据中的点被分配到类别中。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/33f94dc3a456909797cb570b29c48e1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ie5sr9DNFkNRm0w3"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">照片由<a class="ae ju" href="https://unsplash.com/@cdr6934?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯里德</a>在<a class="ae ju" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="99d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">阿尔伯特·爱因斯坦曾经说过:</p><h1 id="cfbf" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">“如果你不能简单地解释它，你就不够了解它。”</h1></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="8f6d" class="jv jw hi bd jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko le kq kr ks bi translated"><strong class="ak">支持向量机算法是如何工作的？</strong></h1></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><p id="f09a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">也许你想知道，当我可以简单地用 Scikit-learn 实现支持向量机时，知道它如何工作真的很重要吗？</p><p id="e15f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">答案是肯定的，是。了解其工作原理将有助于您诊断和调整模型，以获得准确和精确的结果。</p><p id="05a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将一步一步地介绍 SVM 的算法。我们将使用一个名为“<strong class="ih hj"> Data.csv </strong>”的数据集。</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><p id="1079" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，您必须导入您的库(numpy、pandas、matplotlib 和 seaborn)。</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="838f" class="lk jw hi lg b fi ll lm l ln lo">import numpy as np</span><span id="03c1" class="lk jw hi lg b fi lp lm l ln lo">import pandas as pd</span><span id="ec0f" class="lk jw hi lg b fi lp lm l ln lo">import matplotlib.pyplot as plt</span><span id="9b29" class="lk jw hi lg b fi lp lm l ln lo">import seaborn as sns </span></pre><p id="f594" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另外，让我们使用以下代码片段加载数据集:</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="d6d9" class="lk jw hi lg b fi ll lm l ln lo">data = pd.read_csv(“Data.csv”)<br/>data. head() #displays the first few rows and columns of the data</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lq"><img src="../Images/8dd11768f99b48a931067ac26f95105c.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*a5VGn2_lcs4EUk0rI-1jUg.jpeg"/></div></figure><p id="a6a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，有 3 列，点被分组为“A”或“B”</p><p id="24b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，可以使用 Seaborn 中的 lmplot 函数可视化这些数据。</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="3c06" class="lk jw hi lg b fi ll lm l ln lo">sns.lmplot(’x1’, 'x2’, data = data, <br/>           hue = 'r’, palette = 'Set1’, fit_reg = False, scatter_kws = {"s" :50})<br/>plt.show() </span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/b48b8fc0567c91f2d0fe532b5b274c9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BTfb9sCd3df-muhIflAXug.jpeg"/></div></div></figure><p id="2ec9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，您可以使用 Scikit-learn svm 分类器来计算算法中所需的值。</p><p id="9244" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">超平面的公式是:</p><p id="f46b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">f(x) =W₀x + W₁y + b，其中 W₀和 W₁是向量的权重，b 是偏差。</p><p id="43a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">超平面是一个子空间，它的维数比其周围空间的维数小一。如果空间是三维的，那么它的超平面就是二维平面，而如果空间是二维的，那么它的超平面就是一维直线。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ls"><img src="../Images/05bb7d1b92d23881dd47f57f9511e5f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jv9OtUpb9Og5I43w"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">本·穆林斯在<a class="ae ju" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="c40e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用的内核是线性的。当使用线性核时，假设数据是线性可分的。</p><p id="bceb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVC 分类器被实例化为 clf。</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="88cf" class="lk jw hi lg b fi ll lm l ln lo">from sklearn import svm<br/>points = data[[‘x1’, ‘x2’]].values</span><span id="880a" class="lk jw hi lg b fi lp lm l ln lo">result = data[‘r’] <br/>clf = svm.SVC(kernel = ‘linear’) <br/>clf.fit(points,result)</span><span id="5de1" class="lk jw hi lg b fi lp lm l ln lo">print(f“Vector of weights (w) =  {clf.coef_[0]})<br/>print(f“b = {clf.intercept_[0]}”)<br/>print(f“Indices of support vectors = {clf.support_}”)<br/>print(f “Support vectors =  {clf.support_vectors_}”) <br/>print(f“Number of support vectors for each class = {clf.n_support_}”) <br/>print(f“Coefficients of the support vector in the decision function = {np.abs(clf.dual_coef_)}”) </span></pre><p id="597c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您将获得以下输出</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/e67ec121895e4df9653ddb7a904b1f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iFTECYs1Kh4sD7LIqTqyxA.jpeg"/></div></div></figure><p id="756d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要绘制超平面，您必须为向量的权重分配一个标识符，并找到超平面的斜率。超平面在(-b/W₀,0)处与 x 轴相交，在(0,-b/W₁).)处与 y 轴相交因此对于斜率，你将获得-(W₀/W₁).数学然后被翻译成代码，如下所示:</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="5135" class="lk jw hi lg b fi ll lm l ln lo">w = clf.coef_[0] #weight of vector<br/>slope = -w[0] / w[1]<br/>b = clf.intercept_[0]<br/></span></pre><p id="dd06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从 0 到 4 的值被用作 x 坐标，并找到相应的 y 值。</p><p id="fa61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:y = mx + c，其中 m 是你的斜率，所以对于 x 的每一个值，你都找到一个对应的 y 值。</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="e0eb" class="lk jw hi lg b fi ll lm l ln lo">#coordinates of the hyperplane <br/>xx = np.linspace(0, 4)<br/>yy = slope * xx - (b / w[1])</span></pre><p id="ea3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下代码片段是第一个支持向量的等式:</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="b0f3" class="lk jw hi lg b fi ll lm l ln lo">#plotting the margins<br/>s = clf.support_vectors_[0] <br/>yy_below = slope * xx + (s[1] - slope * s[0])</span></pre><p id="cd04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这也是第二个支持向量的等式:</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="1b38" class="lk jw hi lg b fi ll lm l ln lo"># last support vector<br/>s1 = clf.support_vectors_[-1]<br/>yy_above = slope * xx + (s1[1] - slope * s1[0])<br/></span></pre><p id="9bf0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据中的点也用以下代码绘制:</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="5916" class="lk jw hi lg b fi ll lm l ln lo">sns.lmplot(‘x1’,‘x2’, data = data, hue=‘r’, <br/>           palette = 'Set1’, <br/>           fit_reg = False, <br/>           scatter_kws={’s' : 70})</span></pre><p id="dd52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们画出超平面和两个边界或支持向量。</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="a5b3" class="lk jw hi lg b fi ll lm l ln lo"><br/>#plotting the hyperlane <br/>plt.plot(xx, yy, linewidth = 3, color = 'red’) <br/>#plotting the two margins <br/>plt.plot(xx, yy_below, 'k--’) <br/>plt.plot(xx, yy_above, 'k--’)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/129574ae98515e94ccd0458ca7eee89a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IgMRLsP90ODZztIH0kZ_oA.jpeg"/></div></div></figure><p id="0016" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">也可以使用 clf.predict()进行预测。</p><p id="69c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，基本上我们可以得出结论，支持向量机算法通过将数据点分组来对其进行分类。</p><p id="a295" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是我们的数据并不总是可以线性分离的。这样你就必须添加一个内核技巧。内核技巧是通过添加一个第三维空间来实现的，这样类之间的划分界限就很明显了。</p><p id="10a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要添加第三维，请使用以下公式</p><p id="c114" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">z = x + y</p><p id="750a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">整个代码片段:</p><pre class="jf jg jh ji fd lf lg lh li aw lj bi"><span id="e5b7" class="lk jw hi lg b fi ll lm l ln lo">import numpy as np <br/>import pandas as pd<br/>import matplotlib.pyplot as plt <br/>import seaborn as sns<br/>data = pd.read_csv (‘Data.csv’)<br/>sns.lmplot(‘x1’, ‘x2’,<br/>           data = data, <br/>           hue = ‘r’, <br/>          palette = ‘Set1’, <br/>           fit_reg = False, <br/>           scatter_kws = {"s" :50})<br/>plt.show() <br/>#importing svm<br/>from sklearn import svm<br/>#converting columns as matrices<br/>#formula for the hyperplane<br/>#g(x) =W⃗₀x+ W⃗₁y + b<br/>points = data[[’x1’,’x2’]].values<br/>result = data[‘r’] <br/>clf = svm.SVC(kernel = ‘linear’) <br/>clf.fit(points,result)<br/>print(f“Vector of weights (w) =  {clf.coef_[0]})<br/>print(f“b = {clf.intercept_[0]}”)<br/>print(f“Indices of support vectors = {clf.support_}”)<br/>print(f “Support vectors =  {clf.support_vectors_}”) <br/>print(f“Number of support vectors for each class = {clf.n_support_}”) <br/>print(f“Coefficients of the support vector in the decision function = {np.abs(clf.dual_coef_)}”) <br/>#plotting the hyperplane <br/>w = clf.coef_[0] #weight of vector<br/>slope = -w[0] / w[1]<br/>b = clf.intercept_[0]<br/>#coordinates of the hyperplane <br/>xx = np.linspace(0, 4)<br/>yy = slope * xx - (b / w[1]) <br/>#plotting the margins<br/>s = clf.support_vectors_[0] #first support vector <br/>yy_below = slope * xx + (s[1] - slope * s[0])<br/># last support vector<br/>s1 = clf.support_vectors_[-1]<br/>yy_above = slope * xx + (s1[1] - slope * s1[0])<br/>#plotting the points <br/>sns.lmplot(‘x1’, ‘x2’, data = data, hue=’r’, <br/>           palette = 'Set1’, <br/>           fit_reg = False, <br/>           scatter_kws={‘s' : 70})<br/>#plotting the hyperlane <br/>plt.plot(xx, yy, linewidth = 3, color = 'red’) <br/>#plotting the two margins <br/>plt.plot(xx, yy_below, ‘k--’) <br/>plt.plot(xx, yy_above, ‘k--’)</span></pre></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><p id="8b61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[1]https://en.m.wikipedia.org/wiki/Hyperplane</p><p id="4720" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2]李伟孟，Python 机器学习(2019)，威利在线图书</p><p id="ba71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我非常感谢迈克·夸布斯和 T2·里士满·阿切姆庞帮助我改正了这篇文章中的错误。</p></div></div>    
</body>
</html>