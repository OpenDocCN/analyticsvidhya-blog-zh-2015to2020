# 机器学习中的偏差-方差权衡

> 原文：<https://medium.com/analytics-vidhya/a-guide-to-bias-and-variance-in-machine-learning-6ce618590513?source=collection_archive---------9----------------------->

介绍偏差、方差、偏差-方差权衡及其对模型的影响。

你好，读者们，

作为机器学习的绝对初学者，一些概念可能看起来令人不知所措。偏见和差异是经常引起混淆的概念之一。理解这些基本而重要的概念非常重要。

![](img/fbcf5a6b20e26a374c7815b60d7be83b.png)

总预测误差=偏差+方差+不可约误差

## 偏移误差

“偏见”一词指的是对某事物先入为主的看法或强烈的倾向。同样，偏差误差是由模型中关于目标函数的假设(主要是不准确的)导致的误差。当对输入和输出数据之间的映射做出假设时，就会发生这种情况，由于这种假设，算法从训练集中学习的灵活性较小。偏差导致忽略数据集中的特征，因此不允许模型完全适应训练集。

**低偏差**:对目标函数的假设较少。KNN 和决策树可以被认为是低偏差的机器学习算法。

**高偏差**:对目标函数做了更多的假设。多元线性回归和逻辑回归可以被认为是具有高偏差的机器学习算法。

## 方差误差

从机器学习的角度来看，方差表示数据集之间拟合的差异。方差误差是当模型对训练数据非常敏感时出现的误差，即模型受到训练数据细节的强烈影响。当目标函数的许多参数强烈依赖于训练数据集时会出现这种误差，并且当模型被给予新的训练数据时，这进一步导致不同的估计。

**低方差:**当数据集的变化导致函数估计值的微小变化时，即不同数据集的拟合变化不大。线性回归可以被认为是一种低方差的机器学习算法。

**高方差:**当数据集的变化导致函数估计值的较大变化时，即数据集拟合之间的差异显著。通常，具有高复杂度的算法具有高方差，因为这种算法可以自由地从训练数据集学习任何函数形式。SVM 和决策树可以被认为是具有高方差的机器学习算法。

## 方差和偏差对模型的影响

基本上，偏差是预测与准确性的差距，方差是模型的不同实现之间预测变化的程度。

**低方差**算法趋于一致，结构简单，复杂度有限。这样的算法训练起来更快。
**低偏差**算法在高复杂度的结构中趋于精确和灵活。低偏差算法的训练速度较慢。
**高方差**算法从在模型中引入不一致性的训练集中学习随机噪声以及潜在模式。这往往会导致**过拟合**。
**高偏差**算法遗漏了特征和输出之间的重要关系，从而导致**欠拟合**。在这种情况下，预测远非正确。

![](img/1afbd00bea2ac0f148606fd0da163121.png)

基于方差和偏差水平的四种不同情况

对于一个好的模型，总的预测误差需要最小化。
总预测误差=偏差+方差+不可约误差
只有模型误差可以减少，因此偏差误差和方差误差需要最小化。

## 偏差-方差权衡

为什么会有取舍？为什么不能两全其美？
嗯，偏倚和方差的关系是没有办法回避的。同时最小化这两种误差是相当具有挑战性的。减少偏差将增加方差，减少方差将增加偏差。简单来说，准确度的提高会导致一致性的降低，反之亦然。

![](img/8d98318f3cc2cfcdadad9bbe8a3be5c2.png)

该模型需要努力在偏差和方差之间找到平衡。该模型需要处于复杂性的中间(下图中用虚线突出显示)，因为一个模型不能同时具有高复杂性(在低偏差的情况下)和有限复杂性(在低方差的情况下)。

![](img/9b85f20dbdd2e3892bd7f27f33b71587.png)

图片来源:[http://scott.fortmann-roe.com/](http://scott.fortmann-roe.com/)

找到偏差和方差的最佳平衡以避免过度拟合或欠拟合是很重要的。