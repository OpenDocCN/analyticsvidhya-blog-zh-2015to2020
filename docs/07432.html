<html>
<head>
<title>Linear Regression — Part IV — Chance of Admission Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归——第四部分——录取机会预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-part-iv-chance-of-admission-prediction-978540555c29?source=collection_archive---------17-----------------------#2020-06-25">https://medium.com/analytics-vidhya/linear-regression-part-iv-chance-of-admission-prediction-978540555c29?source=collection_archive---------17-----------------------#2020-06-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/65a8ea2e3965b4b46298ed5123cb946a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-IYcE6-YJTX_brw67C6aRA.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">照片由<a class="ae hv" href="https://unsplash.com/@almosbech?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">阿尔莫斯·贝托尔德</a>在<a class="ae hv" href="https://unsplash.com/s/photos/magic?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><div class=""/><p id="4787" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有没有想过变魔术或者预测未来？这是指南！</p><p id="db9b" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">lol！在本文中，让我们使用sklearn软件包进行编程，探索线性回归并学习如何使用线性回归进行预测。</p><p id="ac4e" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本系列之前的帖子中，我们已经看到了足够多的关于线性回归的理论。如果你想看一看，下面是详细内容。</p><ol class=""><li id="92b8" class="jt ju hy ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated"><a class="ae hv" href="https://devskrol.com/2020/07/18/linear-regression-part-i/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hz">线性回归—第一部分</strong> </a></li><li id="b99b" class="jt ju hy ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae hv" href="https://devskrol.com/2020/07/19/linear-regression-part-ii-gradient-descent/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hz">线性回归—第二部分—梯度下降</strong> </a></li><li id="9683" class="jt ju hy ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae hv" href="https://devskrol.com/2020/07/19/linear-regression-part-iii-r-squared/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hz">线性回归—第三部分— R平方</strong> </a></li><li id="c74c" class="jt ju hy ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae hv" href="https://devskrol.com/2020/07/16/what-is-regression-in-terms-of-ml/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hz">什么是ML方面的回归？</strong>T19】</a></li></ol><p id="a17b" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">导入必要的库来读取数据。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="b3f4" class="kq kr hy km b fi ks kt l ku kv"><strong class="km hz">import</strong> <strong class="km hz">pandas</strong> <strong class="km hz">as</strong> <strong class="km hz">pd</strong></span></pre><p id="2e96" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我已经从Kaggle下载了数据。多亏了Kaggle，他们为初学者提供了大量的数据来尝试和学习。<a class="ae hv" href="https://www.kaggle.com/search?q=tag%3A%22linear+regression%22+in%3Adatasets" rel="noopener ugc nofollow" target="_blank">链接到Kaggle获取数据进行线性回归。</a></p><p id="3ea0" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae hv" href="https://www.kaggle.com/search?q=tag%3A%22linear+regression%22+in%3Adatasets" rel="noopener ugc nofollow" target="_blank">我</a>取了一个录取预测数据集。让我们探索数据:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="4db5" class="kq kr hy km b fi ks kt l ku kv">df = pd.read_csv("Admission_Predict_Ver1_1.csv")<br/>df.head()</span></pre><figure class="kh ki kj kk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kw"><img src="../Images/22fdc5b4990a8e2e6447fc3d9c5df177.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C5npndRW6jjXsVLGUPuivw.png"/></div></div></figure><p id="6a2e" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的下一步是预处理数据，以获得更准确的结果。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="a22b" class="kq kr hy km b fi ks kt l ku kv">df.isnull().sum()</span></pre><figure class="kh ki kj kk fd hk er es paragraph-image"><div class="er es kx"><img src="../Images/59993a333b16d12bc4ba6b90ecab6f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*LzdUrlEPV0nhGT8446AOGQ.png"/></div></figure><p id="cd47" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但幸运的是，由于这是一个主要面向初学者的数据集，它没有空值，数据也很干净。所有值都是连续值，而不是分类值。</p><p id="52e9" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将在稍后的新帖中看到如何使用分类值。</p><p id="3da0" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们检查独立值和从属值之间的相关性。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="8643" class="kq kr hy km b fi ks kt l ku kv">df.corr()</span></pre><figure class="kh ki kj kk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ky"><img src="../Images/e5747236120f9023b19d1c2baeaffb6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f7LaN-vj8D-zQunidD0lwA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">相互关系</figcaption></figure><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="3091" class="kq kr hy km b fi ks kt l ku kv">df.columns</span><span id="8ebc" class="kq kr hy km b fi kz kt l ku kv">Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',<br/>       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],<br/>      dtype='object')</span></pre><p id="e3bb" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在所有栏目中，S.No与录取机会无关。所以我们可以移除它。要预测的值是“录取机会”。将这一列放在X中没有意义，因为这一列的变化与Y中的变化完全相等，Y是我们要预测值的同一列。</p><p id="de0d" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你还想知道，那就试一试吧，最终你会有100%的准确率。即r值将是1。很高兴看到但已经没用了。</p><p id="8538" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">开心一分钟，让我们回到现实吧！</p><p id="5ea2" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以后如果你马上得到100%的准确率，首先检查你是否在X中加了Y！lol！我已经做了足够多的次数来记住这个！</p><p id="5818" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里我去掉了‘连载’。X没有录取机会，y只有录取机会。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="c6c1" class="kq kr hy km b fi ks kt l ku kv">X = df.drop(['Serial No.','Chance of Admit '],axis = 1)<br/>y = df['Chance of Admit ']</span></pre><p id="98a6" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将整个数据框分割成X和Y参数。基本上，X参数是自变量，Y参数是我们需要预测的因变量。让我们看看X和Y变量。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="ff8a" class="kq kr hy km b fi ks kt l ku kv">X.head()</span></pre><figure class="kh ki kj kk fd hk er es paragraph-image"><div class="er es la"><img src="../Images/9ab27158ef572be785c6710768859ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*NlPoo1ORHuZxo-YIonAvJw.png"/></div></figure><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="2d9b" class="kq kr hy km b fi ks kt l ku kv">y.head()</span></pre><figure class="kh ki kj kk fd hk er es paragraph-image"><div class="er es lb"><img src="../Images/314110d0c71d07f441157640f32bbae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*EmP0TEHhkEc1b3NwxKr67Q.png"/></div></figure><p id="05cb" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们需要将数据分成训练集和测试集。我们用训练集训练模型，用测试集验证模型。</p><p id="3f04" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通常训练集应该高于测试集，这样我们可以得到更多的数据来学习。不同的分割精度也不同。</p><p id="008b" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">例如60-40，80-20，甚至73-27。</p><p id="1c2c" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">您可以只提及测试大小，这样训练集将自动成为剩余的。但是如何选择要测试的行呢？</p><p id="a8f7" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这种分割应该随机进行。</p><p id="8c75" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">sklearn有一个包train_test_split，它允许我们以随机的方式将数据分成训练和测试。您也可以使用参数<strong class="ix hz"> random_state </strong>来控制随机性。</p><p id="5304" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你和我对这个参数使用相同的int值，那么我们都将拥有相同数据集的相同测试和训练数据集。</p><p id="c4e1" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hz"> test_size </strong>参数取值&lt; = 1即0.33，0.4表示测试集数据的百分比。</p><p id="c42b" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">导入必要的包。需要的时候我会一一解释。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="e523" class="kq kr hy km b fi ks kt l ku kv"><strong class="km hz">from</strong> <strong class="km hz">sklearn.model_selection</strong> <strong class="km hz">import</strong> train_test_split <br/><strong class="km hz">from</strong> <strong class="km hz">sklearn.linear_model</strong> <strong class="km hz">import</strong> LinearRegression<br/><strong class="km hz">from</strong> <strong class="km hz">sklearn.metrics</strong> <strong class="km hz">import</strong> r2_score</span><span id="78a3" class="kq kr hy km b fi kz kt l ku kv">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)</span></pre><p id="f522" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们看看训练和测试数据集有多少行:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="99a0" class="kq kr hy km b fi ks kt l ku kv">X_train.shape</span></pre><p id="698c" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:(300，7)</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="112e" class="kq kr hy km b fi ks kt l ku kv">X_test.shape</span></pre><p id="59eb" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:(200，7)</p><p id="5d12" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们已经玩完了数据。让我们进入真正的游戏！让我们建立一个线性回归模型来预测一个新生的录取机会。</p><p id="66f1" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">sklearn为各种算法提供了大量的包。这里我们使用LinearRegression()为这个算法创建一个新对象。有了这个对象，我们可以拟合我们的数据，并使用这个对象来获得我们的模型的参数。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="e698" class="kq kr hy km b fi ks kt l ku kv">lr = LinearRegression()  <em class="lc">#Object Created</em><br/>lr.fit(X_train, y_train) <em class="lc">#Data given into the LinearReg. object</em></span></pre><h2 id="ec1b" class="kq kr hy bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">搞定了。恭喜你，你已经创建了你的第一个模型。</h2><p id="a93b" class="pw-post-body-paragraph iv iw hy ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">是啊！简单不是吗？让我们看看我们能从这个模型中得到什么！</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="6ec5" class="kq kr hy km b fi ks kt l ku kv">lr.coef_</span></pre><p id="505d" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="1513" class="kq kr hy km b fi ks kt l ku kv">array([0.00145221, 0.00302388, 0.00809642, 0.00672185, 0.01318406,<br/>       0.12002891, 0.02477235])</span></pre><ul class=""><li id="3cb4" class="jt ju hy ix b iy iz jc jd jg jv jk jw jo jx js mb jz ka kb bi translated">这些是X变量的系数(斜率)——GRE分数、TOEFL分数、大学评级、SOP、LOR、CGPA、研究。</li><li id="0834" class="jt ju hy ix b iy kc jc kd jg ke jk kf jo kg js mb jz ka kb bi translated">所以0.00174541<em class="lc">GRE+0.00280216</em>托福+ 0.00675831 <em class="lc">大学+0.0061299</em>SOP+0.01492133<em class="lc">LOR+0.11902878</em>CGPA+0.01943883 *研</li></ul><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="97e8" class="kq kr hy km b fi ks kt l ku kv">lr.intercept_</span></pre><p id="3334" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="fde6" class="kq kr hy km b fi ks kt l ku kv">-1.200250569689947</span></pre><p id="6556" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个值就是Y轴截距。所以我们的Y线方程变成了，</p><p id="39eb" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">chanceofadminit =-1.2567425309612157+0.00174541<em class="lc">GRE+0.00280216</em>托福+ 0.00675831 <em class="lc">大学+0.0061299</em>SOP+0.01492133<em class="lc">LOR+0.111902878</em>CGPA+0.00</p><p id="9547" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来呢？让我们测试我们的模型。</p><p id="1713" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用<strong class="ix hz"> <em class="lc"> lr </em> </strong>对象的predict方法，通过发送x_test值，我们可以预测y_test值。因为我们已经有了原始的y_test值，我们现在可以验证我们的模型。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="b434" class="kq kr hy km b fi ks kt l ku kv">predicted = lr.predict(X_test)</span><span id="cf4a" class="kq kr hy km b fi kz kt l ku kv">r2_score(y_test, predicted)</span></pre><p id="a7fe" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="37ed" class="kq kr hy km b fi ks kt l ku kv">0.8251757711467193</span></pre><p id="f272" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们已经预测了测试集的Y值，并使用sklearn.metrics包中的r1_score函数将其与真实值进行了比较。我们的模型的精确度为0.8257111467193这意味着我们的预测将有82%正确。</p><ul class=""><li id="659d" class="jt ju hy ix b iy iz jc jd jg jv jk jw jo jx js mb jz ka kb bi translated">让我们检查一下！</li></ul><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="0519" class="kq kr hy km b fi ks kt l ku kv">y_test.head(10)</span></pre><p id="d78e" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="f90c" class="kq kr hy km b fi ks kt l ku kv">18     0.63<br/>361    0.93<br/>104    0.74<br/>4      0.65<br/>156    0.70<br/>350    0.74<br/>32     0.91<br/>205    0.57<br/>81     0.96<br/>414    0.72<br/>Name: Chance of Admit , dtype: float64</span></pre><p id="0ec7" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">获取前10行的预测。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="025e" class="kq kr hy km b fi ks kt l ku kv">print(predicted[0:10])</span></pre><p id="7e03" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="be0a" class="kq kr hy km b fi ks kt l ku kv">[0.74116361 0.91082451 0.81024774 0.62183042 0.64643854 0.69311918<br/> 0.91233928 0.51828756 0.95333009 0.73419915]</span></pre><p id="eb50" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这里，我们预测了现有的测试数据。</p><p id="e357" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在你可以看到我们大部分的预测都非常接近。</p><p id="6c86" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们预测新的数据。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="6137" class="kq kr hy km b fi ks kt l ku kv">new_y = lr.predict([[347, 120, 4.5, 4.7, 4.7, 9.8, 1]])<br/>print(new_y)</span></pre><p id="4bcf" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="bf94" class="kq kr hy km b fi ks kt l ku kv">[0.99758071]</span></pre><p id="4355" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一个测试:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="0854" class="kq kr hy km b fi ks kt l ku kv">new_y = lr.predict([[250, 90, 2, 2.5, 4.7, 7, 1]])<br/>print(new_y)</span></pre><p id="136f" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="d697" class="kq kr hy km b fi ks kt l ku kv">[0.39488945]</span></pre><p id="de05" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在你有了你的模型，你可以预测任何分数的录取机会。</p><p id="f0a1" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们已经完成了线性回归模型的训练和测试，并预测了录取的机会。</p><h1 id="eff3" class="mc kr hy bd ld md me mf lh mg mh mi ll mj mk ml lo mm mn mo lr mp mq mr lu ms bi translated">您还希望:</h1><ol class=""><li id="17fa" class="jt ju hy ix b iy lw jc lx jg mt jk mu jo mv js jy jz ka kb bi translated"><a class="ae hv" href="https://devskrol.com/category/machine-learning/logistic-regression/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hz">逻辑回归</strong> </a></li><li id="fc74" class="jt ju hy ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae hv" href="https://devskrol.com/2020/07/25/decision-tree/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hz">决策树</strong> </a></li><li id="98ac" class="jt ju hy ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae hv" href="https://devskrol.com/2020/07/26/random-forest-how-random-forest-works/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hz">随机森林是如何运作的？—为什么我们需要随机森林？</strong>T15】</a></li><li id="d314" class="jt ju hy ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae hv" href="https://devskrol.com/2020/07/19/underfitted-generalized-overfitted/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hz">欠配—广义—过配</strong> </a></li><li id="ebd5" class="jt ju hy ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae hv" href="https://devskrol.com/2020/07/19/overfitting-bias-variance-regularization/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hz">过拟合—偏差—方差—正则化</strong> </a></li></ol><h1 id="e687" class="mc kr hy bd ld md me mf lh mg mh mi ll mj mk ml lo mm mn mo lr mp mq mr lu ms bi translated"><strong class="ak">结论:</strong></h1><p id="6da3" class="pw-post-body-paragraph iv iw hy ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">在这篇文章中我们学习了如何做线性回归模型和如何预测值。</p><p id="3e87" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我会在机器学习方面提出更多的研究和一些更有趣的事实，并在我的下一篇文章中看到你！</p><p id="495e" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">特别感谢Kaggle提供的数据集！</p><p id="dea5" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请用各种数据探索这个算法，用python试试。不要忘记在评论中留下你的想法。对我和所有读者都会有用！</p><p id="3cf9" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谢谢大家！</p><p id="44e9" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">喜欢支持？只要点击拍手图标就可以了。</p><p id="59b7" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">编程快乐！</p></div></div>    
</body>
</html>