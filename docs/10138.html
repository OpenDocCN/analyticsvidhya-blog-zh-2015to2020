<html>
<head>
<title>Data Mining and Machine Learning — Credibility of the trained model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据挖掘和机器学习——训练模型的可信度</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-mining-and-machine-learning-credibility-of-the-trained-model-47da29e53d49?source=collection_archive---------15-----------------------#2020-10-06">https://medium.com/analytics-vidhya/data-mining-and-machine-learning-credibility-of-the-trained-model-47da29e53d49?source=collection_archive---------15-----------------------#2020-10-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="cc4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们训练一个机器学习算法时，我们必须是可信的，并证明它比另一个模型更好。在这篇文章中，我们将看到这样做的技术。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/4fdd02c6ea3ca2b0d1220cb05f971449.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TOFM0EXsGZzYwo_WxE8wVA.png"/></div></div></figure><p id="7d85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如何分割数据集的数据，以便正确评估ML算法的性能？我们也会看到它的置信限。我们将看到如何评估两个分类器。因为一般来说没有比另一种更好的技术，所以你必须比较不同的方法。根据所研究的问题，我们有比其他方法更好的方法。一般来说，如果我们不使用统计测试，我们不能保证一种技术比其他技术更好。例如，如果我们有一个二元问题，我们的选择可能会落在二元分类器上。另一个重要的方面是，在许多情况下，并非所有的错误都以相同的方式衡量，例如在医学领域，说一个生病的病人很好意味着该错误比相反的错误具有更高的成本。我们最初假设每种错误的成本是不变的，这意味着不考虑成本。我们还将在我们的方案(模型)中看到对成本敏感的性能评估。也可以进行数值评估，例如，预测我们处理器的性能。虽然分类仅适用于标签或概率，但也可以评估数值。</p><p id="cb82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然理论上我可以这样做，但如果我根据训练集的错误来评估性能，我就犯了一个错误。对训练集误差的评估不是对未来数据的性能的良好指示。在这种假设中，k=1的分类器k-最近邻算法(k-NN)将是最佳的分类器，因为它将输入实例与最近的实例相关联，但是因为我放置的是训练集的样本，这些样本是它们本身，所以我永远不会出错，并且总是能够进行完美的分类。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/b462017e4677fd10424e9daa795d79ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tGFOVUNfVibfj2YkeUncsg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">1-神经网络</figcaption></figure><p id="a86e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">绿色圆圈是训练样本(每个圆圈应该属于不同的类别)，而红色圆圈是测试数据，虚线圆圈所勾勒的区域是分类区域。据推断，由于每个绿色圆圈是一个类别，因此分类将是完美的。你有一个1-NN。</p><p id="623a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我可以做的第一件事是，如果我有足够多的数据集，我们可以将数据集分为训练集和测试集，我们用训练集进行训练，并评估测试集的性能。但问题是数据量，即标记样本的数量是有限的，因此需要更复杂的技术来进行评估。我们将会看到，另一种试图对抗在某些情况下难以将大量数据标记为解决方案的方法是半监督方法。我可能很少有数据被标记的原因是因为可能很少有病人(医疗数据)来找我。在一个互联网网络的流量中，我可能会有问题，因为我有很多样本，但我很少做标记。</p><h2 id="a0a3" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">估价</h2><p id="46d9" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">要考虑的一个方面是与统计可靠性相关的方面。当我评估性能差异时，我必须使用称为统计显著性的测试来了解，即使我有几个分类器或不同的配置，如果我测量的性能不同，或者它只是取决于学习过程受误差影响的事实。这可以用置信区间技术来完成，然后用统计测试的方法来完成。作为绩效衡量的类型，我们有:</p><ul class=""><li id="fa5c" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">正确分类的数量；</li><li id="61f2" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">概率估计的准确性(在我们估计概率的情况下，我们越接近理想值越好)；</li><li id="aa55" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">数值预测误差(平均值、二次平均值、绝对值等)。</li></ul><h2 id="ddca" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">培训和测试</h2><p id="0e4e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">在分类的情况下，我们使用<strong class="ih hj">错误率</strong>,其中我们表示为:</p><ul class=""><li id="64e0" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">成功:实例的类被正确预测；</li><li id="4a3a" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">错误:实例的类预测不正确:</li><li id="162e" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">错误率:是错误在整个实例集中所占的比例。<br/>例如，如果我有100个实例和40个错误，从数字的角度来看，错误率百分比是40%或0.4。</li></ul><p id="bc62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你在训练数据上产生的误差通常被定义为<strong class="ih hj">重置误差</strong>，实际上是训练集上的误差率，这是一个非常乐观的估计。</p><p id="f50c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我考虑测试集，在训练过程中不使用独立实例，问题是什么？在某些情况下，在训练阶段，我不仅要训练分类器，还要调整参数。为了进行调整，我不能使用属于测试集的数据，但我也只能使用来自训练集的数据！赋予分类器泛化能力还包括在训练阶段正确设置参数。例如，假设我给他看A和B的样本，在测试中，我把A和B的样本放在训练中，很容易我是好的，但这并不意味着当他看到从未见过的样本时，我的分类器是非常通用的。因此，最好通过对一组样本进行训练来设置参数，然后对另一组样本进行测试，以便评估泛化能力。<br/>实际例子:有些情况下，我可以从不同的数据集中提取数据，例如，有一个分类器可以使用来自不同城市的客户的数据，我该怎么办？假设在两个城市有100个客户，我可以使用A的50个客户和B的50个客户作为训练集，做同样的测试，这样做，混合不同性质的样本我正在做一个乐观的估计，因为我对系统说:“我会给你所有可能的信息”，但如果有来自城市C的其他数据，其数据我从未见过，这些数据具有不同的特征，我可能会有更差的性能。如果我在A上训练，在B I上测试，会有一个更现实的估计。</p><h2 id="65b5" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">训练集、验证集和测试集</h2><p id="8637" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">一些学习系统分两个阶段运行:</p><ol class=""><li id="1695" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc lh kz la lb bi translated">基本结构的构建；</li><li id="ae7e" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc lh kz la lb bi translated">参数设置的优化。</li></ol><p id="6633" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">测试数据不应该用于参数优化，因为它在统计上是不正确的，并且因为我们正在用测试数据修改训练中固有的东西。建议使用三套:</p><ol class=""><li id="dc5d" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc lh kz la lb bi translated">训练集:构建基本模型；</li><li id="11cd" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc lh kz la lb bi translated">验证集:执行参数调整；</li><li id="5a2c" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc lh kz la lb bi translated">测试设备。仅用于评估性能一次。</li></ol><p id="05d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦评估完成，<em class="li">所有数据</em>可用于构建最终分类器。我们有两个独立的问题，因为一方面我们想建立最好的分类器，另一方面评估它的性能。因此，我们使用训练集、验证集和测试集(不连续的，只对评估性能有用)，但是只使用训练数据来训练分类器是愚蠢的，因为无论如何，它们是一个百分比，例如70%，我们还不如使用所有这些数据。<br/>在使用验证集设置参数之后，我们也知道了参数，所以为了进行最后的训练，我们使用了整个验证集，我进行了一次理论上更好的训练，因为我使用了比第一次训练更多的数据。<br/>如果在训练阶段我对干净的数据进行训练，然后在最后阶段我放入脏数据(标签有噪声的数据),最终结果可能会变得更糟，那么只在训练集上获得的结果会比使用所有数据进行训练获得的结果更高。但是总的来说，噪声分布在整个数据集上，因此我使用的数据越多越好。<br/>一般来说，我的训练集越大，我的错误率越低，但是为了进行估计，我希望有一个尽可能大的测试集，所以我有两个冲突的需求。一种可能性是使用维持过程，即将起始数据分为定型数据和集合数据(但理想情况下它们应该尽可能大)。另一种可能性是使用交叉验证技术来克服起始数据不够大的问题。</p><h1 id="0a24" class="lj ju hi bd jv lk ll lm jz ln lo lp kd lq lr ls kg lt lu lv kj lw lx ly km lz bi translated">预测性能</h1><p id="c7be" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">让我们考虑一个有10000个样本的数据集和一个有100个样本的数据集，我们马上意识到我们得到的错误率，即使在绝对相等的值上，从统计学的观点来看也不是。让我们假设有25%的错误率，实际上我们谈论的成功率比错误率高75%。现在，这只是一个估计。关于目标人群的真实成功率，我们能说些什么？当然，预计接近75%。但在5%或10%以内有多接近呢？这是一个<strong class="ih hj">统计问题</strong>！</p><blockquote class="ma mb mc"><p id="6337" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">在统计学中，一系列独立事件的成功或失败被称为伯努利过程。经典的例子是掷硬币。每次投掷都是独立的事件。假设我们总是预测正面。但不是“正面”或“反面”，每次投掷都被认为是“成功”或“失败”假设硬币是有偏向的，但是我们不知道正面的概率是多少。然后，如果我们实际上投掷硬币100次，其中75次是正面，我们的情况非常类似于刚才描述的分类器，在测试集上观察到75%的成功率。关于真正的成功概率，我们能说些什么？换句话说，假设有一个伯努利过程——一个有偏硬币——真实(但未知)成功率为p，假设N次试验中，S次是成功的；因此，观察到的成功率是f = S/N。问题是，这告诉你什么关于真正的成功率p？<br/>这个问题的答案通常表示为置信区间即p位于某个指定区间内，具有某个指定的置信度。例如，如果在N = 1000次试验中观察到S = 750次成功，这表明真正的成功率必须在75%左右。但是有多接近75%呢？结果发现，在80%的置信度下，真正的成功率p介于73.2%和76.7%之间。如果在N = 100次试验中观察到S = 75次成功，这也表明真正的成功率必须在75%左右。但是实验规模更小，因此p的80%置信区间更宽，从69.1%延伸到80.1%。</p></blockquote><p id="6dce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们用更简单的方式来谈谈置信区间。根据所考虑的集合，相同的性能(在现实中)具有不同的解释，例如:我有1000个元素，在750个元素上我有正确的分类，成功率(分类率)是75%，但是在n=100和s=75的情况下是相同的！从出错率的角度来看，结果总是一样的。但是通过置信区间(统计方法)，如果我说正确的真实分类的百分比在这个区间中的概率是80%，我是说有80%的概率真实的成功率发生在这个区间中。这两种情况的不同之处在于，如果我使用1000个样本，那么对于我所检查的值，区间会更窄。显然，分类器的高斯行为假设，对我来说最坏的情况是分类器可以下降到73%的性能，对我来说最好的情况是达到76%。如果我对少量样本进行估计，置信区间会变宽，我所做的估计会不那么稳健。<br/>我使用的实例越多，得到的估计就越好，因为我得到了一个更稳健的值。通常置信区间表示为90%或95%。我估计的数字越低，估计的稳健性(可靠性)就越低。<br/>如果我有80%的置信区间，这意味着5次中有1次我会在区间外结束，所以5次中有4次我在区间内，这就是为什么我们选择90%或95%的置信区间，也就是10次中有1次，从统计上来说，我会在区间外结束。</p><p id="03cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">给定单个伯努利过程，其平均值为p，而方差为p*(1-p)。如果从伯努利过程中进行N次试验，期望成功率<em class="li"> f = S/N </em>是一个具有相同均值p的随机变量；方差通过因子<em class="li"> N </em>减少到<em class="li">p(1p)/N</em>。<em class="li">对于大N，这个随机变量的分布趋近于</em> <strong class="ih hj"> <em class="li">正态分布</em> </strong>。后者是静态的事实，目前，为了简单起见，我们将不深入这一理论的优点。<br/>均值为零的随机变量<em class="li"> X </em>位于宽度<em class="li"> 2*z </em>的某个置信范围内的概率为概率<em class="li">P[z≤X≤z]= c</em>。正态分布的<strong class="ih hj"> <em class="li"> c </em> </strong>和<strong class="ih hj"> <em class="li"> z </em> </strong>值出现在表格中，其中的值已经计算过，例如<a class="ae mg" href="https://www.mathsisfun.com/data/standard-normal-distribution-table.html" rel="noopener ugc nofollow" target="_blank">标准正态分布【mathisfun】</a>。在链接的表格中，我们有<em class="li"> z </em>的值，事实上在许多情况下，这些表格给出了<em class="li"> X </em>超出范围的置信度。对于对称分布P[z≤X≤z]= 1 2×Pr[X≥z]，他们只能给出概率<em class="li"> P[X ≥ z] </em>，这被称为单尾概率，因为它仅指分布的上“尾”。正态分布是对称的，所以下尾<em class="li">P[X≤—z]</em>的概率是一样的。</p><h2 id="ec72" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">示例1</h2><p id="4ef0" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">求0到0.47之间的人口百分比。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mh"><img src="../Images/7f7272bba60c61f98982b380473ac209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*R9ygnDa06OWzu9YQ2P_ing.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">P[X <em class="mi"> ≥ z </em> ]</figcaption></figure><p id="91ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从0.4的行开始，一直读到0.07，现在我们有了0.47。我们找到的值是0.1808。所以总体的<strong class="ih hj"> 18.08% </strong>在均值的0到0.47个标准差之间。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mj"><img src="../Images/8a8a01fb6cc5e5bf6c78d8bc798fd3b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VNYAg-bUSq1UCW2yfppKeg.png"/></div></div></figure><h2 id="bd3d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">示例2</h2><p id="091b" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">请考虑下表:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="fd17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此表假设随机变量<em class="li"> X </em>的均值为<em class="li"> 0 </em>方差为<em class="li"> 1 </em>。X在标准差1.65之外的概率为5%，数学上<em class="li"> P[X ≥ 1.65] = 0.05 </em>，或<em class="li"> 5% </em>。所以一个值高于<em class="li"> 1.65 </em>的概率是<em class="li"> 5% </em>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mm"><img src="../Images/83530a212e04caa6f0ea903c64c2121b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zxbMDVydUMms5WuLTG-hRg.png"/></div></div></figure><p id="4058" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注:4.95%已近似为5%。</p><p id="bad7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于分布是对称的，X位于平均值1.65个标准偏差以上(高于或低于)的概率为<em class="li"> 10% </em>，或<br/><em class="li">P[1.65≤X≤1.65]= 90%</em>。</p><p id="3b2d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有公式以封闭的形式表示，一旦我知道了成功百分比(f)和N(训练集的样本数)的值，固定了我想要这样的概率，所以概率发生在那个置信区间，我可以直接去计算值。<br/>如果我想知道我的分类结果在80%的情况下结束的置信区间，我选择c = 80%(这意味着我将在右边10%的数据和左边10%的数据的区间之外)，从表中我推导出z=1.28。看到的数值加上我放进去的成功率和样本数(公式2.2)。在这个解决方案中，我希望置信度值为80%，分类结果在此范围内结束，请注意我要测量的百分比，并注意训练集中的样本数。</p><h2 id="da56" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">一些理论</h2><blockquote class="ma mb mc"><p id="3487" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">现在我们要把随机变量f = S/N渲染成<strong class="ih hj">零均值</strong>和<strong class="ih hj">单位方差</strong>。我们通过减去平均值<em class="hi"> p </em>并除以标准偏差来计算:</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mn"><img src="../Images/cdb44570b40d8908f4eed9021f9f8bad.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*fZyznaHIV7aQuAYiqoI92w.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">标准偏差公式(1.1)</figcaption></figure><blockquote class="ma mb mc"><p id="e81d" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">这导致:</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mo"><img src="../Images/059e23938c3635478938ebedab03f7b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*Yql17Cc4TKuOBL5xjbN2pw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">(公式2.2)</figcaption></figure><blockquote class="ma mb mc"><p id="1b69" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">下面是寻找置信限的步骤。给定一个特定的置信图c，查阅置信极限正态分布表以获得相应的z值。要使用该表，您必须首先从1中减去c，然后将结果减半，因此对于c = 90%,您将使用表中的条目5%。线性插值可用于中等置信水平。然后把前面表达式中的不等式写成等式，反过来求p的表达式<br/>最后一步是解一个二次方程。尽管这并不难做到，但它导致了令人不快的令人生畏的置信界限表达:</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mp"><img src="../Images/359ee6513b95c8a063af52f1d5809688.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*N3neKBGAvp-SMonUySqfzw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">(公式3.3)</figcaption></figure><blockquote class="ma mb mc"><p id="6d56" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">该表达式中的<strong class="ih hj"> </strong>给出了p的两个值，分别代表<strong class="ih hj">置信上限</strong>和<strong class="ih hj">置信下限</strong>。虽然这个公式看起来很复杂，但在特殊情况下不难算出。<br/>该结果可用于获取之前给出的数值示例中的值。</p><p id="c2ef" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">设置f = 75%，N = 1000，c = 80%(因此z = 1.28)得出p的区间[0.732，0.767]，N = 100得出相同置信度的[0.691，0.801]。注意，正态分布假设只对大N(比如N &gt; 100)有效。因此，f = 75%和N = 10导致置信限[0.549，0.881]，但这些应持保留态度。</p></blockquote><h2 id="7bea" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">坚持</h2><p id="562f" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">维持方法保留一定量用于测试，并将剩余部分用于训练，通常三分之一用于测试，其余部分用于训练。一个实际的问题是，我们将要做的集合之间的划分可能不能很好地代表各个类。例如，类可能在测试数据中丢失。</p><p id="35dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们建立训练集时，特别是当类之间存在不平衡时，我们使用<strong class="ih hj">分层</strong>方法。我们确保每个类(在训练、验证和测试集中)在每个子集中以大致相同的比例表示，比如说，与整个数据集相比，以相同的百分比表示。例如，如果我们有一个数据集，其中一个类由80%的样本表示，另一个由20%的样本表示，如果作为训练集，我使用数据集的60%，但我只在一个类的样本集中使用它，分类器将只在一个类上训练，这显然是错误的。</p><p id="5eb0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我使用维持方法(分为训练和测试)，如果我进行后续提取，我会有一个更健壮的估计。我提取了更多的样本，然后对结果进行平均(<strong class="ih hj">重复拒绝</strong>)。例如，如果我有1/3用于测试，2/3用于训练，我不是只提取一次，而是提取多次，然后对结果进行平均。但是不同的集合可能会重叠！因为如果我以1/3和2/3的随机方式提取样本，我不能保证下一个细分的样本不会重叠。</p><h2 id="b21d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">k倍交叉验证</h2><p id="61f4" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">一种可能性是使用交叉验证，根据定义，这可以避免重叠的测试集。它由以下步骤组成</p><ol class=""><li id="6928" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc lh kz la lb bi translated">将数据分成k个大小相等的子集(如果样本是奇数，我可能没有完美的划分，事实是大小相等应该这样理解)；</li><li id="8749" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc lh kz la lb bi translated">我进行k次训练，然后依次使用子集进行训练，一个子集用于迭代测试。例如，如果将数据集细分为5个集合，我将进行5次不同的训练，在每次训练中，我将4个集合用于训练，另一个集合用于测试。做5次，我有不同的训练和测试设置。不知何故，一方面我使用了一个测试集，这个测试集从整体上看尽可能的大，而且我也有一些不重叠的测试集。一般来说，将最初生成的集合分层是合适的。</li></ol><p id="6e21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">K=10是一个很好的值，用整个过程的平均值来估计误差(在这种情况下，我将10次测试的结果进行平均)。根据实际实验和理论论证，数值10已经足够好了。交叉验证我可以重复几次，并调节结果(因此有一个更健壮的结果)。</p><p id="0a1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:使用不同的学习技术对许多不同的数据集进行的大量测试表明，10次折叠大约是获得最佳误差估计的正确次数。分层减少了变异，但肯定不会完全消除变异。</p><p id="0294" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当寻求精确的误差估计时，标准程序是重复交叉验证过程10次，即10次10倍交叉验证，然后对结果取平均值。这涉及到在数据集上调用学习算法100次，数据集的大小都是原来的十分之九。获得良好的性能度量是一项计算密集型任务。</p><h2 id="1f0f" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">漏掉一个</h2><p id="31cd" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">交叉验证方法可以用留一法发挥到极致，在留一法中，我使用的折叠数等于训练实例的数量。例如，如果我有1000个样本，我可以进行1000次交叉验证，理论上我可以训练1000次分类器。优点是尽可能充分利用数据，没有数据重叠，因为选择是确定的，但从计算的角度来看，这是非常昂贵的。然而，留一法似乎提供了一个机会，从一个小的数据集中挤出最大值，并获得尽可能精确的估计。</p><p id="ae08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不能给出分层，我在属于一个类的测试集中只有一个样本，所以我不能有分层的测试集，这可能会导致我比正常情况下更高的错误，但一般来说，这种方法对于非常小的数据集是方便的，我们希望有稳健的结果。一个极端的情况是数据集被分成两个子集，每个类一个子集。例如，我们有一个类别的50个样本和另一个类别的49个样本，以及用于测试的1个样本。LOO技术将样本归属于多数类，这样我会犯100%的错误，因为它将样本归属于多数类，总是有50%的准确性。</p><h2 id="43d3" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">引导程序</h2><p id="e802" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">另一种可用于评估性能的技术是自举技术。与交叉验证不同，一旦我选择了一个样本，就没有“替换”了。在bootstrap的情况下，我做一个样本来确定我的训练是什么，但我有可能在训练集中插入更多次相同的样本，并有可能进行替换。然后，我对一个包含N个实例的数据集进行采样，并用替换进行N次，以形成一个包含N个实例的新数据集。因此，我的训练集将具有与原始数据集相同数量的实例，其中一些实例可以重复，而我没有放入训练集中的原始集的实例将成为测试集的一部分。例如，我有一个包含1000个样本的训练集，我随机提取样本，可以提取已经提取的样本，然后创建一个包含1000个元素的新集合，其中一些元素会出现不止一次。一些训练算法可能没有考虑到实例出现不止一次。重要的是要有一个未被采样的数据子集，因此不同于组成测试集的生成的训练集。注意:坚持数学的人会注意到，如果同一个对象可以出现不止一次，我们就根本不应该谈论“集合”。</p><p id="aabc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然训练集是由n个样本组成的，但它仍然只包含数据集实例的63%，这仍然低于考虑90%样本进行训练的10倍交叉验证。我对测试数据的估计将会非常悲观，在bootstrap的情况下，我们测量的误差是测试数据和训练数据的加权组合。为了弥补这一点，我们将测试集错误率与训练集中实例的替换错误相结合。正如我们之前所警告的，替代数据对真实误差给出了非常乐观的估计，当然不能单独用作误差数据。但是自举程序将它与测试错误率相结合，以给出如下的最终估计值e:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/a265fd85679d10f054a32000dcba7a13.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*KP12vnEAeRTzG61o4-Mcpw.png"/></div></figure><p id="0959" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在bootstrap的情况下，我们测量的误差是测试和训练的加权组合。误差= 0.632*误差_开_测试+0.368 *误差_开_训练。<br/>我可以多次重复这个过程，以便进行调解，得到更可靠的估计。这工作得很好，与只留下一个引导相比，我只做一次学习，但是调解十次我只做十次学习。一千个样本的遗漏让我学到了一千种知识！所以Bootstrap在计算复杂度方面也表现不错。这可能是评估非常小的数据集的性能的最佳方式。</p><blockquote class="ma mb mc"><p id="bd29" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">bootstrap过程可能是估计非常小的数据集的错误率的最佳方式。然而，像留一法交叉验证一样，它也有缺点，可以通过考虑一个特殊的人为情况来说明。事实上，我们上面考虑的数据集就可以了:一个完全随机的数据集，有两个大小相等的类。任何预测规则的真实误差率为50%。但记忆训练集的方案将给出100%的完美替代分数，因此训练实例= 0，0.632 bootstrap将把这与0.368的权重混合，从而给出仅31.6%的总错误率(0.632 × 50% + 0.368 × 0%)，这是误导性的乐观。</p></blockquote><h2 id="322d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">比较机器学习模型</h2><p id="096d" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">一种可能性是通过交叉验证来比较估计值，特别是十次交叉验证，这通常是一种合理的解决方案。因为训练数据的数量自然会影响性能，所以所有数据集的大小应该相同。事实上，可以用不同的尺寸重复实验，以获得学习曲线。</p><p id="0f5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器学习研究需要令人信服地证明一种特定的方法比另一种更有效！</p><p id="3afa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在某些情况下，如果我想证明方案A在某个领域优于方案B，我将不得不在我可以拥有的所有可能的训练集中进行，因此，实际上，我可以拥有的一种可能性是通过学生测试使用统计方法，以验证方案A的平均交叉验证是否优于方案B。<br/>该方法是统计方法，与之前看到的置信区间相似，即以相似的方式，使用略微不同的计算。我将计算两个结果的置信区间，如果它们重叠，这意味着它们彼此没有太大的不同，如果它们不重叠，这意味着它们彼此不同。我们已经看到，置信区间取决于我希望给予置信区间信任的概率，我必须将概率设置为90%或95%，也就是说，20次中有19次分类器的真实值将在该区间内。因此，如果我以这种方式计算分类器的置信区间，然后将它们与两个平均值相关联，并且我看到置信区间是不相连的，这意味着两个分类器的行为方式不同，也就是说两个方案在统计上是不同的，也就是说我要测量的差异在统计上是显著的，固定了某个概率值。如果区间重叠，可能会有很多情况，其中我要测量的差异只是虚构的，但事实上分类器是相似的或以相同的方式表现。</p><h2 id="e372" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">t检验- 10倍交叉验证</h2><p id="b372" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">假设你已经训练了两个ML算法，你想找出哪一个性能更好。我们在两个模型上执行10次十折交叉验证，小心地将我们输入的折叠与两个ML模型相匹配。ML算法“A”将给出输出x1，x2，…，xk，而算法“B”将给出y1，y2，…，yk。例如，在将数据集划分为10个子集后，为了获得x1和y1，我们将使用前9个子集进行训练，将第10个子集用于测试，将后9个子集用于训练，将第一个子集用于测试，以获得xk和yk。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/86f78c05b2aeb0bb646b4b27a27995ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VfBSRpaL0QoNu1ZA1lVssg.png"/></div></div></figure><p id="e46e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果有足够的样本，一组独立样本(x1，x2，…，xk)的“x标记”平均值具有正态分布，即高斯分布，而不考虑样本本身下面的分布。我们称μ mean的真实值为样本总体的平均值(我们将在另一篇文章中更详细地了解这些概念)。如果我们知道正态分布的方差，那么它可以被简化为具有零均值和单位方差，我们就可以在给定样本均值的情况下获得μ的置信限(“x标记”)。然而，方差是未知的，我们可以获得它的唯一方法是从样本集估计它。仅从我们的样本而不是从全球总体来估计方差的事实引入了不确定性。因为方差只是一个估计值，所以它不具有正态分布(即使对于大k值它变得正态)。我们得到的分布称为<strong class="ih hj">学生分布</strong>，具有<strong class="ih hj"> k -1个自由度</strong>，其中k是我们进行的十次交叉验证的次数。因此，我们不能再使用置信限正态分布表，而必须使用相对置信区间学生分布(置信限学生分布9自由度)表。如果我们在给定的置信度下比较这两个表，范围会稍微宽一些，这反映了需要估计方差所引起的额外的不确定性。不同的自由度需要不同的表格，如果自由度超过100，置信限就非常接近正态分布的置信限。在我们的例子中，我们有一个涉及9个自由度(k-1)的表格。与正态分布的表格一样，学生的分布指的是“单侧”置信区间。考虑“地= Xi-伊”的差异，确保观察值是成对的。这个差的均值就是两个均值的差，d = x-y，和均值本身一样，它有一个k-1个自由度的学生分布。如果平均值相同，差值将为0(这在统计学上称为<strong class="ih hj">零假设</strong>)。如果平均值显著不同，则差值将显著不同于零。因此，对于给定的置信水平，我们将检查实际差异是否超过置信界限。首先，将差异减少到零均值、单位方差变量，称为t统计量:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mr"><img src="../Images/184d8b3da3f78ff51f6a0c7dceee0d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:264/format:webp/1*mvtqhlcF8nWH06HKFM2_8g.png"/></div></figure><p id="e78b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中σd2是差异样本的方差。假设我们选择1%的置信区间。根据这个置信区间，如果k等于10，我就可以从表confidence _ limits _ student _ distribution _ 9 _ degrees _ of _ freedom得到z。双尾检验是合适的，因为我们事先不知道x的均值是否可能大于y的均值，反之亦然；因此，对于1%的测试，我们使用对应于0.5%的值。如果根据最后一个公式，t的值大于z，或小于–z，我们拒绝均值相同的零假设，并得出结论，对于该数据集大小，该域上的两种学习方法之间确实存在显著差异。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mk ml l"/></div></figure><h1 id="a7aa" class="lj ju hi bd jv lk ll lm jz ln lo lp kd lq lr ls kg lt lu lv kj lw lx ly km lz bi translated">预测概率</h1><p id="bb4e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">现在，我们使用成功率作为估计，也称为<strong class="ih hj">0–1损失函数</strong>。<br/>这是一个二元损失函数，也就是说，如果我说对了就是0，如果我说错了就是1。如果分类器给我一个概率估计，这个损失函数并不理想。<br/>注意:它被称为损失函数，但我们也可以将其视为增益函数，在这种意义上，如果我对增益进行了正确的分类，如果我对增益0进行了错误的分类，就会得分。<br/>很多分类器对一个元组进行分类，用概率告诉我们它们有多确定。如果分类器给了我一个概率度量，我就可以对更好的性能进行估计。一件事是当它告诉我们要有99%的把握时犯了错误，另一件事是当它告诉我们要有51%的把握时犯了错误。在这种情况下，当有99%的把握时犯错误，错误的数量更大。如果我有51%的把握，但我犯了一个错误，那么这个错误对分类的贡献将小于它犯了一个错误但有99%把握时的总贡献。</p><h2 id="a816" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">二次损失函数</h2><p id="ad06" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">让我们假设我们的“概率”分类器可以给出k个类别之间的一个结果，因为每个类别将用概率p1，…，pk表示，其中pi=P[class=i]。我们用向量a1，…，ac，…来表示。，ak，其对应于k个类别，并且其中只有ac=1，而其余的值等于0。我们可以将与这种情况相关联的惩罚表示为依赖于p向量和a向量的损失函数。经常用于评估概率预测的一个标准是<br/> <strong class="ih hj">二次损失函数</strong>:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ms"><img src="../Images/0b4572fa0792da7fd1839454f6cf5da7.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/1*FRzpFZdSWfJYyZE8PpC3ew.png"/></div></div></figure><p id="dd52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果用pi*=P[class=i]表示属于I类的<em class="li">真实概率</em>，可以考虑以下表达式:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mt"><img src="../Images/c6caf4d006cb98048c51df092e1e9b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*frhGPT0hAdY_XUl_HDgzVQ.png"/></div></figure><p id="9cbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终目标是最小化这个公式，最小化分类器产生的错误。这发生在pi=pi*时，也就是我们的分类器预测真实概率的时候。如果pi=pi*分类器，在我们的训练过程中，将努力实现相等。这是一组数据，其中包括了一个最小的分类:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mu"><img src="../Images/54ea2f20b2cd60b713b4171a363ec6c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:230/format:webp/1*vzN4_GwWOzEH6caHjcZumA.png"/></div></figure><p id="ce25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">换句话说，估计概率和真实概率之间的差异。例如，如果我们有3个类，对于某个元组，我们期望的第一个类是a=[1，0，0]，也许我们的分类器会给出p=[0.6，0.1，0.3]，为了最小化该公式，在下一次训练和评估时，他会给出p=[0.8，0.1，0.1]，因为他“理解”正确的分类是类1。因此可以理解，因为在返回概率的分类器的情况下，二次损失函数是最小化的度量。在目前的情况下，二次损失函数迫使预测者诚实地选择概率的最佳估计。所以让我们把它看作是0–1损失函数的演化。此外，二次损失函数有一些有用的理论性质，我们将不在这里深入研究。由于所有这些原因，它经常被用作概率预测情况下成功的标准。</p><h2 id="ba77" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">信息损失函数</h2><blockquote class="ma mb mc"><p id="df1a" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">用于评估概率预测的另一个流行标准是信息损失函数，</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/5bfc941847113ffc80dbb3950f244bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:214/format:webp/1*hrzyJpXfOwkDOkJiraJiew.png"/></div></figure><blockquote class="ma mb mc"><p id="7229" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">其中第I个预测是正确的。它表示相对于概率分布p1，p2，…，pk表达实际类别I所需的信息(以比特为单位)。换句话说，如果给你一个概率分布，有人必须告诉你哪个类是实际发生的，这是他们尽可能有效地编码信息所需的位数。</p><p id="fa51" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">如果真实概率为p1*、p2*、…、pk*，则信息损失函数的期望值为</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mw"><img src="../Images/e111fe921ff0a7d046a67fbd9b0d591c.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*qhLuBCwxwExkApP_oGLbEg.png"/></div></figure><blockquote class="ma mb mc"><p id="033f" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">像二次损失函数一样，该表达式通过选择pj = pj*来最小化，在这种情况下，该表达式成为真实分布的熵:</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mx"><img src="../Images/7c2cd7cac352a1cd1ec64b9d3e3abf80.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*Rbzyr6paWE1cEaZlF1beXg.png"/></div></figure><blockquote class="ma mb mc"><p id="7437" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">因此，信息损失函数也奖励知道真实概率的预测者的诚实，并鼓励不知道的预测者提出他们的最佳猜测。</p><p id="4ec9" class="if ig li ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">信息损失函数的一个问题是，如果你给一个实际发生的事件分配一个0的概率，函数值就是无穷大(零频率问题)。但是在信息损失函数下运作的谨慎预测者不会给任何结果分配零概率。</p></blockquote><h1 id="e7bd" class="lj ju hi bd jv lk ll lm jz ln lo lp kd lq lr ls kg lt lu lv kj lw lx ly km lz bi translated">分类成本</h1><p id="4bad" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我们在这里看到的是这样一个事实，不同类型的分类错误可以给出不同的成本。向不还钱的人发放贷款，可能比不向愿意还钱的人发放贷款更糟糕。所以，在实践中不同类型的分类错误<br/>通常会招致不同的成本。</p><h2 id="17fc" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">混淆矩阵</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es my"><img src="../Images/22921a6c6b1e0cf18e87dca74ddc83f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wFQH7XN7UKUAF2qoPt5EPA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">两类预测的不同结果(CM1)</figcaption></figure><p id="94d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不同的成本必须应用于分类错误。为了表示分类器产生的错误，可以使用混淆矩阵，其中实际类别在行上，预测类别在列上:</p><ul class=""><li id="b832" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">真正:样本类yes，归因于类yes(正确)；</li><li id="40ac" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">真否定:样本类别号，归因于类别号(正确)；</li><li id="c1aa" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">假阴性:样本被错误地归入类别号；</li><li id="c75b" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">假阳性:样本被错误地归入“是”类别。</li></ul><p id="8874" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从术语的角度来看，假阴性是“漏检”，而假阳性是“虚警”。在这四种情况之一中可以找到一个单一的预测。为了获得好的结果，必须在对角线上找到大多数或所有的样本，因此，一些甚至更好的零点在对角线之外。</p><p id="2f07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑一个3类问题的两个混淆矩阵，其中左边是实际预测值，右边是随机预测值:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mz"><img src="../Images/6f84a34599117f23298bc64b3ab03d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*1dKHc2FdYZA5n5UbgE9scg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">CM2</figcaption></figure><p id="cf1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在n个类别的情况下，正确分类的百分比由对角线上元素的总和给出，如果这些是绝对数字，则它们必须除以样本总数。例如，我们有(88+40+12)/200 = 0.7。当谈到成功率(f)时，已经提到了这一点。</p><h2 id="6902" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">卡帕统计量</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es na"><img src="../Images/8f8f34bc142f3c90f03dda54740141ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*m_HOw4GdJZhJ8WGx3vzy1Q.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">卡帕统计量(D =对角线)</figcaption></figure><p id="eaf6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kappa统计测量正确百分比和随机分类器生成的百分比之间的差异，随机分类器为每个类别提供相同数量的元素以考虑比例。它告诉我们真实的分类器与理想的随机分类器(正确地对所有样本进行分类)有多远的偏差。分类器告诉我们，120预测它们属于A类，60预测它们属于B类，20预测它们属于c类。右边的矩阵表示分类器的行为，从外部角度来看，该分类器的行为类似于我的分类器，因为每个类预测的样本数是相等的(最后一行矩阵)，但它是按照我的分类器的比例以随机方式进行的。Kappa统计是达到正确分类的另一个指标。让我们就之前看到的两个混淆矩阵(CM2)做一个数值例子:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nb"><img src="../Images/80a7b5c92b3ba9cc1b4b8029c55ba931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mt2d10OZiZCVmPJvnsnquw.png"/></div></div></figure><h2 id="f4c4" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">成本分类</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nc"><img src="../Images/cea4f213bc100d84582fe583e6969478.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*qSM5UWkdSaJcgHcjOag_Vg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">默认成本矩阵:(CM3)两级情况和(CM4)三级情况</figcaption></figure><p id="78da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有两类和三类矩阵，但一般来说，我们可以有N类混淆矩阵。到目前为止，我一直假设误差的权重总是1。在对角线上，我对实例进行了正确分类，成本等于0，所有错误的权重为1。在成本敏感分类中，我有对角线以外的值，这些值根据我考虑的类别而不同，我有一个与误差的“物理”意义相对应的真实成本矩阵，因此，除了0和1之外，我还可以有其他不同的值。实际上，我可以用多种方式操作:</p><ul class=""><li id="66d5" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">在分类过程中，我可以记住成本；</li><li id="d52e" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">以正常方式进行分类，然后在考虑成本的情况下评估性能。</li></ul><p id="6b42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第一种情况下，我可以考虑成本来尝试修改分类算法，在训练期间对成本进行适当的调整和/或修改样本的分布，使我的分类器以更高的成本给我更多次的样本。或者你可以只使用成本矩阵来评估性能(成本敏感性能评估)。</p><h2 id="dc64" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">成本敏感学习</h2><p id="b219" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我们用其他术语解释成本敏感学习。进行成本敏感学习的一个简单方法是根据成本对实例进行重采样，或者我可以有分类器，在其中我也可以对不同的实例进行加权。一些分类方案，如Baysian方案，我可以添加除先验概率之外的另一个因素，该因素可以是与特定类型的错误相关联的成本。如前所述，一种可能性是将成本直接插入学习算法中。事实上，已经有一些方案考虑到了这一点，我可以根据成本对实例进行重新采样。因此，如果一个错误比另一个错误代价更高，我会尝试强制系统不要在修改实例关系时犯这种错误。例如，如果我有50个和50个样本的两个类，我会对出错代价更高的类进行过采样。<br/>或者对不同的实例进行加权，如果我们使用的算法允许的话)。在朴素贝叶斯算法的情况下，我可以输入成本作为附加因素。</p><h2 id="43cc" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">电梯图表</h2><p id="6caf" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">实际成本往往是未知的，我们需要一个工具来考虑不同的可能场景，其中一个场景是不同的成本分配。例如:我有一家营销公司，我可能可以向一百万人(客户)发送电子邮件。</p><p id="7c86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我向我认识的每一个人(因为也许我以前做过研究)发送统计水平的答案，我将有0.1%的答案(1000个答案)，他们将已经有1000人。</p><p id="f5dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">无论如何，发送这些通信可能会产生成本，因此我的DM工具应该在所有可能的收件人中突出显示我，这些收件人最有可能对我的商业邀请做出响应。如果DM工具可以识别出最有希望的100000人，他们会以高出0.4%的百分比或者400人来响应。很明显，400人比1000人少，但我也减少了1/10的邮件，如果我支付这些邮件，就像节省了(1000000–100000 = 900000)等价的“邮票”。如果我找出400000个最有希望的人的子集，他们的回答比整体更好，我得到了<em class="li"> 0.2% </em>，比我给每个人发电子邮件时多两倍，这涉及到800个总答案。我们现在不仅将邮件数量减少了一半，而且有很多人回复了邮件，这与以前非常相似。<strong class="ih hj">提升图</strong>允许<em class="li">视觉比较</em>显示不同场景下的表现，允许你做出营销选择。在营销术语中，响应率的增加，在这种情况下是4倍，被称为学习工具产生的提升因子。如果你知道成本，你就可以确定一个特定升力系数所隐含的收益。术语“提升”来源于这样一个事实，即它度量“提升”，即当我选择一个子集时可以拥有的<em class="li">乘法因子</em>。</p><p id="3964" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">给定一个学习方案，该方案输出测试实例集合中每个成员的预测类的概率(就像朴素贝叶斯所做的那样)，您的工作是找到测试实例的子集，这些子集具有高比例的正实例，高于整个测试集中的正实例。要做到这一点，应该按照“是”的预测概率的降序对实例进行排序。然后，要找到一个给定大小的具有最大可能比例的阳性实例的样本，只需从列表中读取所需数量的实例，从顶部开始。因此，根据预测为正的概率对实例进行排序:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="184f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我可以从成功概率的角度来排序我的样本，我就可以构建提升图(提升图1)。做出选择总是取决于成本、收益和发送成本。例如，如果我假设发送的成本是零，那么我也可以把邮件发给每个人。提升图的优点是不必预先配置成本，相反，通过改变成本，我可以决定如何行动。它基于什么假设？它是基于这样一个事实，我可以根据请求是肯定的概率来排序请求。例如，如果贝叶斯分类器可用，我根据上述概率对实例进行排序，并且如果我知道样本的实际类别，我就可以构建此图表。随着人口的增加，我决定了正确答案的数量。在x轴上，我有所考虑的实例，在我们的例子中是百分比，而在y轴上，我们有真阳性，被正确分类为“是”类的样本的数量，因为在这个例子中，我考虑的是实际响应的人。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nd"><img src="../Images/eab73cb8974d4c86dc848cd07186c67a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z9nTkJAlSr_uxuTbKXTULg.png"/></div></div></figure><p id="1ac6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑图中的点A、B、C:</p><ul class=""><li id="0870" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">答:如果我正确地订购了我的客户，10%的成本(因为我只为10000个客户中的10%的样品支付运费),我们将得到((400/100000)*100)=总答案的0.4%，数量为400→<em class="li">lift = 4</em>；</li><li id="c837" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">b:我的样本中有40 %( 400000名顾客)他们对我的回应率为((800/400000)*100)= 0.2%,因此回应的人数为800→<em class="li">lift = 2</em>；</li><li id="d9da" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">c:如果我考虑我的样本的100%将回答1000人，我们有((1000/1000000)*100)=总答案的0.1%，正如我们在例子中所说的，这里我们可以用图形看到它。</li></ul><p id="d996" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">水平轴</em>显示样本量占可能邮寄总量的比例。<em class="li">纵轴</em>显示获得的响应数量。左下方和右上方的点对应于完全没有邮件输出，响应为0，以及完全邮件输出，响应为1000。如果你知道所涉及的不同成本，你就可以计算出每个样本量的成本，并选择最有利可图的。但是对各种可能性的图形化描述往往比给出一个单一的“最优”决策更能说明问题。对不同大小的样本重复这一操作，可以绘制出如图所示的提升图(列表图1)。对角线给出了不同大小随机样本的预期结果。</p><p id="7196" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基于成本进行评估这一事实非常重要。因为如果我发送信息的成本很高，那么最好把我自己放在10%的成本中。例如，如果我发现了一种更便宜的发送方式，那么我可能会将自己置于曲线的更右侧(例如40%)。如果我发现成本为0，我就把自己放在100%的样本量上。lift概念:在基本情况下，我们有0.1%的人回答((100000000/100)*0.1)=1000，而在第二种情况下，我的lift等于2(因为他们回答我的人数是我的两倍)，在第三种情况下，我的Lift等于4，因为他们回答我的人数是我的4倍。这张图表让我考虑到了提升，并让我知道如何通过考虑子集来提高。</p><p id="5983" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我的理想曲线是一个台阶:如果我能以所有分类都正确的方式排列所有样本，我将有一个<strong class="ih hj">理想系统</strong>，这对应于一条立即上升的曲线。实际上，由于我是根据第一个样本给我“是”的概率来排序第一个样本的，如果我遇到的前1000个样本都是“是”，那么我就有了一个理想的系统，它能带给我所有的好处，并对应于一条立即上升的曲线。实际上，曲线越靠近左上角越好！我的DM系统必须朝那个方向发展。<br/>平分线是在随机选择样本时得到的(<strong class="ih hj">随机系统</strong>)，这给了我一个公平的正负分布。在这种情况下，随着样本量的增加，我的概率是0.1%。事实上，如果我把自己放在40%，我有400，在60%，我有600，所以曲线代表一个完全随机的结果，这是当我把电子邮件发送给每个人。如果我生成的曲线非常接近平分线(随机选择),我的系统将不会为我提供太多服务。它基于什么假设？假设它们是正的，就能够对实例进行排序。除了评估一般的成本，我应该评估我的数据挖掘技术的成本，如果构建图表需要我付出不相称的成本，高于我的收益，理论上我可以/应该决定不采用它。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nb"><img src="../Images/91935aee6ec36675d629924877a18208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2dTvYk0VVQdjkKax_4kVRQ.png"/></div></div></figure><h2 id="d9d6" class="jt ju hi bd jv jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">ROC曲线</h2><p id="ea11" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">ROC曲线用于您试图选择具有高阳性百分比的测试实例样本的情况。它们与在市场营销中使用的提升图有关，在提升图中，我们试图最大化混淆矩阵中的真正积极因素。首字母缩略词代表接收器工作特性，这是信号检测中使用的一个术语，用于描述噪声信道中命中率和虚警率之间的权衡。ROC曲线不考虑类别分布，即一个类别的实例是否比另一个类别多，甚至不考虑错误成本，正如我们在“有成本的分类”一段中看到的。它们不同于电梯图，因为这里我们有:</p><ul class=""><li id="24b6" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated"><em class="li"> y轴</em>显示的是样本中真阳性的百分比(TP率)，而不是一个绝对数字(应答者的数量)；</li><li id="4b93" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated"><em class="li"> x轴</em>显示样本的假阳性百分比(FP率)，而不是显示样本大小。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ne"><img src="../Images/5e2986ae769726252f7215040159dd51.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*OF7uIawF6oIp9mUq7cIkQA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">(TP =真阳性，FN =假阴性)</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nf"><img src="../Images/a5597b4e185d5619b7f8668e3dc33773.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*hzEHd24gJeqKLs_s6gI-xQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">(FP =假阳性，TN =真阴性)</figcaption></figure><p id="ad02" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比较y轴和提升图，我们有几乎相同的东西，但用百分比表示。x轴非常不同，因为它考虑了假阳性(FP)，但如果在我们的问题中，真阳性(TP)的百分比非常低，例如0.1%，则样本的大小和数据集包含的阴性数之间的差异可以忽略不计。至于升降车，目标是在左上角。<br/>图“ROC曲线1”显示了一条锯齿状的线，该线是用表“data_for_lift_chart”中的数据构建的。向上两个正，然后水平一个负，然后5个正，以此类推。对于所有可用的测试集，我们都以这种方式进行，直到到达右上角。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ng"><img src="../Images/95a104d8b07657c37a89cff3cc2aff7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z5_wDrBVz9Gdd0pmlGlxRQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">ROC曲线1</figcaption></figure><p id="559e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从ROC曲线的构建方式来看，我们认识到锯齿状线取决于测试数据的样本。为了解决这个问题，我们可以应用交叉验证。使用交叉验证可以获得更平滑的ROC曲线(假设我的分类器根据概率给出了一个结果)，我将我的集合分成n个部分，然后按照概率的降序取结果，以便构建一个相当平滑的曲线。我甚至可以为每一次折叠生成一条ROC曲线，然后通过对ROC曲线求平均值得到一个总体结果。为此，我收集了每个测试实例的概率，并根据概率对它们进行排序。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nh"><img src="../Images/a7129c78fc2734b0d146eb51264682d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R2TNeYxt6P_YrHJpeQD8Wg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">ROC曲线2</figcaption></figure><p id="9614" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">记住提升图和ROC曲线之间的相似性，我们可以说，在图“ROC曲线2”中的示例中，如果您创建了一个小的聚焦样本，则“A”ML算法表现优异，如您在图的左侧所见，而如果您想要覆盖更多样本，则选择“B”ML算法。为了覆盖大约40%的TP，您应该选择A方法，它给出了5%的低百分比FP，而对于小样本，B方法给出了超过20%的假阳性。如前所述，B方法在大样本中表现出色，事实上我们覆盖了80%的TP和60%的FP。<br/>总是在凸包上移动是可能的，为此你可以采用这种组合方案，其中tA，fA真阳性率和假阳性率方案1；tB，fB真阳性率和假阳性率方案2，而q是我使用方案A来预测样本的次数的百分比，1-q是我使用方案B的百分比。概念是，给定两个可能的方案，我试图取两者之长，一部分使用方案A，一部分使用方案B，另一部分使用两者的组合(在我们的例子中是由箭头指示的中间部分)。使用这种组合就像在两条曲线的凸包上移动。<br/>注意:原则上，这两种方案也可以是具有不同参数的相同类型的分类器。</p><h1 id="eb03" class="lj ju hi bd jv lk ll lm jz ln lo lp kd lq lr ls kg lt lu lv kj lw lx ly km lz bi translated">综合测量</h1><p id="188c" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我们还有其他的度量，其中一些在信息检索中被广泛使用，比如精度和召回率。<strong class="ih hj">召回</strong>无非是真实阳性率:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ni"><img src="../Images/664601769a73288f57b09621a32c8d4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*5o_FnftkD0XRwjfrehVlAA.png"/></div></figure><p id="10c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">换句话说，它是真阳性/阳性组合(由真阳性和假阴性给出)，即检测到的真阳性的百分比。<br/>在信息检索的情况下，我必须找到与我的兴趣相关的文档，所以它是相关文档相对于属于该类别的所有文档的百分比。例如，它们是我找到的文档数与原始文档数的比较，所以如果我有100篇经济学文章，我找到了10篇，那么召回率是10%。<br/><strong class="ih hj">精度</strong>告诉我们从这组文档开始，在系统返回的所有文档中，有多少是相关的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nj"><img src="../Images/fbb45ed7d97b8a65823b595f12d17b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*BWKjB-97oqxmDELaXTuZzg.png"/></div></figure><p id="1dcd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，我想查找经济文档，我有100个文档，但我只找到了其中的20个，其中10个是经济文档，我的召回率= 10%，而精确度是10/20 = 50%，因为在找到的20个文档中，有10个实际上是正确的。我想最大限度地利用这两者。在文档示例的情况下，我们可以使用以下公式来查看召回率和精确度:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nk"><img src="../Images/878c6a839bb3721ff8c09bc7ee57c3c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IyCePXNebeM8N2RQ9_CYmQ.png"/></div></div></figure><p id="f9f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，一个合成的(唯一的)衡量标准可能是令人感兴趣的，例如<strong class="ih hj"> F-measure </strong>是一种介于召回率和精确度之间的调和平均值，而不是算术平均值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nl"><img src="../Images/a0e732f20452a38f7c3dd4744bd7f91d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yZrGiN11JK_TprV_2QDjOw.png"/></div></div></figure><p id="1e17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不同的领域使用不同的术语。例如，医生谈论诊断测试的敏感性和特异性。<strong class="ih hj">敏感度</strong>是指检测结果为阳性的患病人群的百分比，即tp。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nm"><img src="../Images/228ddd8eca62f11d6ac27f62446647be.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*k2M0JpwLYDkcPpOj9CW4uw.png"/></div></figure><p id="01bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">特异性</strong>是指未患病但检测结果为阴性的人的百分比，即1 — fp。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nn"><img src="../Images/ef8f572c0b74f0e2cb0dc6c914508a01.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*UdqF-ZleTwD99uq3JJFggw.png"/></div></figure><p id="4095" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有时，这些指标的乘积被用作总体衡量指标:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es no"><img src="../Images/f44ac8029e7c9b7c87f9b6c21e4ad5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DUvrNUlGT1-og2H1F0auwA.png"/></div></div></figure><p id="419c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，在TP、FP、TN、FN的所有尺寸组合中，我们有经典的成功率或<strong class="ih hj">精确度</strong>:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es np"><img src="../Images/582b9f521566aface934840bcd149548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iCTqr4gsoYNj43iqYC3oVA.png"/></div></div></figure><p id="b273" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用的另一种测量方法是ROC曲线下的面积(AUC ),通常表示为单位面积的分数。理想的ROC曲线是一个台阶，从0开始，它立即垂直上升，然后水平上升到100%，因此它将对着等于1的面积，因为我们有一个边长为1的正方形。曲线向平分线(随机值)挤压得越多，曲线下的面积就越小。这对于比较两条曲线并最终选择一个系统而不是另一个系统非常有用。这可能是有用的，因为ROC曲线没有预见到使用成本，而是提供了许多可能的情景。</p><h1 id="3970" class="lj ju hi bd jv lk ll lm jz ln lo lp kd lq lr ls kg lt lu lv kj lw lx ly km lz bi translated">参考</h1><p id="bb63" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">数据挖掘——实用的机器学习工具和技术，<a class="ae mg" href="https://www.cs.waikato.ac.nz/ml/weka/book.html" rel="noopener ugc nofollow" target="_blank">https://www.cs.waikato.ac.nz/ml/weka/book.html</a></p></div></div>    
</body>
</html>