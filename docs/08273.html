<html>
<head>
<title>Real-Time Sign Language Recognition System to Aid Specially Abled.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实时手语识别系统，以帮助特殊能力。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/real-time-indian-sign-language-recognition-system-to-aid-deaf-dumb-people-e10ac4880752?source=collection_archive---------11-----------------------#2020-07-23">https://medium.com/analytics-vidhya/real-time-indian-sign-language-recognition-system-to-aid-deaf-dumb-people-e10ac4880752?source=collection_archive---------11-----------------------#2020-07-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/935a8dd10a146e1c7c8bcdd7f9920cb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*cwukaTJPlp5GFd8twISZqQ.jpeg"/></div></figure><p id="0cc3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">手语是重听人——低能儿——交流的一种策略。基于手势的通信是重听残疾人通信的重要技术。由于通过手势进行的交流都是围绕着有组织的代码信号进行的，所以每个动作都有其特定的意义。</p><p id="b900" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">它可以通过连接基本组件来传达复杂的含义。在最近相当长的一段时间里，基于手势的通信确认领域的专家们对提出用于从人-人到人-PC合作的连接的方法越来越感兴趣。</p><p id="a9c0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">许多与手语相关的研究工作已经完成，如美国手语、英国手语、日本手语等。但到目前为止，在手语数字识别方面的研究还很少。不幸的是，受到挑战的个人依赖于通过签约调解人进行交流的沟通。</p><p id="ec41" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在任何情况下，寻找有经验和合格的调解人来处理他们一生中的日常事务都是一件麻烦的事情，而且费用高得不合理。随后，人机连接框架将成为这些人的可靠和稳定的答案。有一项全面的研究已经完成了二十多年。</p><p id="bc3e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">手语是一种结构良好的代码手势，手势具有赋予它的意义。每次找到一个有成就的合格的翻译是一件非常麻烦的任务，而且非常昂贵。此外，没有重听的人也不会试图熟悉基于手势的交流来与重听的人合作。</p><p id="f793" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这变成了重听人超然的理由。在任何情况下，如果PC可以被修改，使得它可以对文本组做出基于手势的通信的解释，则普通个体和听觉网络的困难之间的对比可以被限制。</p><p id="2e80" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在所提出的框架中，可以感知用于人机通信的不同数字(即，直到数字5)的手语数字，从而在任何可想象的时间给出逐渐精确的结果。这不仅仅是对印度几乎毫无意义的个人有利，还可以在创新领域的不同应用中加以利用。</p><p id="0ead" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">提议的系统如何运作？</p><ol class=""><li id="6d6a" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated"><em class="jt">从前置摄像头获取图像:</em></li></ol><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="b4d1" class="kd ke hi jz b fi kf kg l kh ki">a. Cap = cv2.VideoCapture(0)</span><span id="ce42" class="kd ke hi jz b fi kj kg l kh ki">b. Ret, IMG = cap.read()</span></pre><p id="3b4e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="jt"> 2。</em> <em class="jt">实时采集帧:</em></p><p id="de26" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有了上面的两条线a &amp; b，它会以帧为单位捕捉图像。下面的图1展示了如何捕获数字2。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kk"><img src="../Images/3bef49beacd370eace0de5c7fd338d78.png" data-original-src="https://miro.medium.com/v2/resize:fit:276/format:webp/1*ZaojFuEgbc2ahxHVXTaTNA.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">图一。实时获取帧</figcaption></figure><p id="b381" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="jt"> 3。</em> <em class="jt">图像预处理:</em></p><p id="7bd0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">使用<a class="ae kp" href="https://docs.opencv.org/master/d4/d13/tutorial_py_filtering.html" rel="noopener ugc nofollow" target="_blank">高斯模糊</a>处理从前置摄像头捕捉的图像，创建手的轮廓。然后处理手部轮廓的<a class="ae kp" href="https://docs.opencv.org/3.4/d7/d1d/tutorial_hull.html" rel="noopener ugc nofollow" target="_blank">凸包</a>，得到图像的<a class="ae kp" href="https://docs.opencv.org/master/d8/d1c/tutorial_js_contours_more_functions.html" rel="noopener ugc nofollow" target="_blank">凸缺陷</a>。图2显示了手部图像的转换。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/86ed458e60003c6eee944fd2d5f19a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*H5iobN-qpZYs6FcLXYO5LQ.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">图二。转换图像</figcaption></figure><p id="efbf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="jt"> 4。</em> <em class="jt">转换:</em></p><p id="6024" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">简而言之，凸度缺陷是从图像中分割出的对象(斑点、轮廓)中的空洞。这意味着一个区域不属于物体，但位于其外部边界-凸包内。下图，图3，比百万字更好的展示了它。在手轮廓的示意图中，手指之间的区域(都用箭头标记)是凸面缺陷。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/48307b575af631fb0ce7e1a0daab4124.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*M-c2Gp0EmlETXfBkcRgeCA.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">图3。手轮廓的凸包和凸起缺陷</figcaption></figure><p id="0079" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="jt"> 5。</em> <em class="jt">模糊:</em></p><p id="1b06" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图像模糊</strong>指使图像变得不清晰或不分明。这是在各种低通滤波器内核的帮助下完成的。</p><p id="a105" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">高斯模糊:</strong>高斯模糊是通过高斯函数模糊图像的结果。这是图形软件中广泛使用的效果，通常用于减少图像噪声和细节。它还被用作应用我们的机器学习或深度学习模型之前的预处理阶段。图4显示了通过高斯模糊提取最大轮廓。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/ae0fd6b76130e1bb8eea4b2dfa3b31a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*I1eFaWebTabVxDpieZetAg.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">图4。提取最大轮廓</figcaption></figure><p id="c888" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="jt"> 6。</em> <em class="jt">阈值:</em></p><p id="3694" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">对于每个像素，应用相似的边缘权重。如果像素权重小于极限，则设置为0，否则设置为最大值。容量cv.threshold用于应用阈值处理。主要的争论是源图片，它应该是灰度图片。随后的竞争是用于表征像素评价的边缘评价。第三个争论是最极端的价值，它被分配给超过边缘的像素，如图5所示。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es kt"><img src="../Images/54ac374fa213d495ffafedb7169e621b.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*Kc5ZvyNBn9xrZkmZREEKeQ.png"/></div></div><figcaption class="kl km et er es kn ko bd b be z dx translated">图5。具有精确匹配符号的轮廓形状匹配</figcaption></figure><blockquote class="ky kz la"><p id="9a00" class="im in jt io b ip iq ir is it iu iv iw lb iy iz ja lc jc jd je ld jg jh ji jj hb bi translated"><strong class="io hj">数字_印度手语识别的实现:</strong></p></blockquote><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="275a" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Imports<br/></em>import numpy as np<br/>import cv2<br/>import math</span><span id="060e" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Open Camera<br/></em>capture = cv2.VideoCapture(0)</span><span id="4d4b" class="kd ke hi jz b fi kj kg l kh ki">while capture.isOpened():</span><span id="8247" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Capture frames from the camera<br/>    </em>ret, frame = capture.read()</span><span id="6630" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Get hand data from the rectangle sub window<br/>    </em>cv2.rectangle(frame, (100, 100), (300, 300), (0, 255, 0), 0)<br/>    crop_image = frame[100:300, 100:300]</span><span id="865c" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Apply Gaussian blur<br/>    </em>blur = cv2.GaussianBlur(crop_image, (3, 3), 0)</span><span id="3788" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Change color-space from BGR -&gt; HSV<br/>    </em>hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)</span><span id="919a" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Create a binary image with where white will be skin colors and rest is black<br/>    </em>mask2 = cv2.inRange(hsv, np.array([2, 0, 0]), np.array([20, 255, 255]))</span><span id="d19f" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Kernel for morphological transformation<br/>    </em>kernel = np.ones((5, 5))</span><span id="d41f" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Apply morphological transformations to filter out the background noise<br/>    </em>dilation = cv2.dilate(mask2, kernel, iterations=1)<br/>    erosion = cv2.erode(dilation, kernel, iterations=1)</span><span id="32a6" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Apply Gaussian Blur and Threshold<br/>    </em>filtered = cv2.GaussianBlur(erosion, (3, 3), 0)<br/>    ret, thresh = cv2.threshold(filtered, 127, 255, 0)</span><span id="2f55" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Show threshold image<br/>    </em>cv2.imshow(<strong class="jz hj">"Thresholded"</strong>, thresh)</span><span id="ac6b" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Find contours<br/>    </em>contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><span id="4d25" class="kd ke hi jz b fi kj kg l kh ki">try:<br/>        <em class="jt"># Find contour with maximum area<br/>        </em>contour = max(contours, key=lambda x: cv2.contourArea(x))</span><span id="6628" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Create bounding rectangle around the contour<br/>        </em>x, y, w, h = cv2.boundingRect(contour)<br/>        cv2.rectangle(crop_image, (x, y), (x + w, y + h), (0, 0, 255), 0)</span><span id="8e37" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Find convex hull<br/>        </em>hull = cv2.convexHull(contour)</span><span id="61ca" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Draw contour<br/>        </em>drawing = np.zeros(crop_image.shape, np.uint8)<br/>        cv2.drawContours(drawing, [contour], -1, (0, 255, 0), 0)<br/>        cv2.drawContours(drawing, [hull], -1, (0, 0, 255), 0)</span><span id="ba75" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Find convexity defects<br/>        </em>hull = cv2.convexHull(contour, returnPoints=False)<br/>        defects = cv2.convexityDefects(contour, hull)</span><span id="3850" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Use cosine rule to find angle of the far point from the start and end point i.e. the convex points (the finger<br/>        # tips) for all defects<br/>        </em>count_defects = 0</span><span id="dd14" class="kd ke hi jz b fi kj kg l kh ki">for i in range(defects.shape[0]):<br/>            s, e, f, d = defects[i, 0]<br/>            start = tuple(contour[s][0])<br/>            end = tuple(contour[e][0])<br/>            far = tuple(contour[f][0])</span><span id="c232" class="kd ke hi jz b fi kj kg l kh ki">a = math.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)<br/>            b = math.sqrt((far[0] - start[0]) ** 2 + (far[1] - start[1]) ** 2)<br/>            c = math.sqrt((end[0] - far[0]) ** 2 + (end[1] - far[1]) ** 2)<br/>            angle = (math.acos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c)) * 180) / 3.14</span><span id="b4db" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># if angle &gt; 90 draw a circle at the far point<br/>            </em>if angle &lt;= 90:<br/>                count_defects += 1<br/>                cv2.circle(crop_image, far, 1, [0, 0, 255], -1)</span><span id="af6f" class="kd ke hi jz b fi kj kg l kh ki">cv2.line(crop_image, start, end, [0, 255, 0], 2)</span><span id="6d99" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Print number of fingers<br/>        </em>if count_defects == 0:<br/>            cv2.putText(frame, <strong class="jz hj">"ONE"</strong>, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255),2)<br/>        elif count_defects == 1:<br/>            cv2.putText(frame, <strong class="jz hj">"TWO"</strong>, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255), 2)<br/>        elif count_defects == 2:<br/>            cv2.putText(frame, <strong class="jz hj">"THREE"</strong>, (5, 50), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255), 2)<br/>        elif count_defects == 3:<br/>            cv2.putText(frame, <strong class="jz hj">"FOUR"</strong>, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255), 2)<br/>        elif count_defects == 4:<br/>            cv2.putText(frame, <strong class="jz hj">"FIVE"</strong>, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,0,255), 2)<br/>        else:<br/>            pass<br/>    except:<br/>        pass</span><span id="ffb6" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Show required images<br/>    </em>cv2.imshow(<strong class="jz hj">"Gesture"</strong>, frame)<br/>    all_image = np.hstack((drawing, crop_image))<br/>    cv2.imshow(<strong class="jz hj">'Contours'</strong>, all_image)</span><span id="6442" class="kd ke hi jz b fi kj kg l kh ki"><em class="jt"># Close the camera if 'q' is pressed<br/>    </em>if cv2.waitKey(1) == ord(<strong class="jz hj">'q'</strong>):<br/>        break</span><span id="bcb8" class="kd ke hi jz b fi kj kg l kh ki">capture.release()<br/>cv2.destroyAllWindows()</span></pre><h1 id="f407" class="le ke hi bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">结果:</h1><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mb"><img src="../Images/9e0d8d5cbfdecdcbf4eeb06cd70c9fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ZGf6IuL78csS0aHeVOfKvw.gif"/></div></div></figure><p id="e2f5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">利用图像处理技术为人机合作提出的通过手势确认框架的通信被有效地执行，其精度等同于正在进行的承诺。</p><p id="efae" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">希望这有所帮助:)</p><p id="40dc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果你喜欢我的帖子，请关注。</p><p id="6f9b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="jt">更多帮助，查看我的Github:-</em><a class="ae kp" href="https://github.com/Afaf-Athar/Hand_Gesture_Number" rel="noopener ugc nofollow" target="_blank"><em class="jt">【https://github.com/Afaf-Athar/Hand_Gesture_Number】</em>T5】</a></p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="c3a2" class="kd ke hi jz b fi kf kg l kh ki">More Refrences:<br/>1. <a class="ae kp" href="https://link.springer.com/article/10.1007/s11831-019-09384-2#:~:text=Sign%20language%20recognition%20is%20a,and%20to%20perceive%20their%20meaning." rel="noopener ugc nofollow" target="_blank">https://link.springer.com/article/10.1007/s11831-019-09384-2#:~:text=Sign%20language%20recognition%20is%20a,and%20to%20perceive%20their%20meaning.</a><br/>2. <a class="ae kp" href="https://link.springer.com/chapter/10.1007/978-3-319-38771-0_54" rel="noopener ugc nofollow" target="_blank">https://link.springer.com/chapter/10.1007/978-3-319-38771-0_54</a><br/>3. <a class="ae kp" href="https://ieeexplore.ieee.org/abstract/document/6470093" rel="noopener ugc nofollow" target="_blank">https://ieeexplore.ieee.org/abstract/document/6470093</a></span></pre></div></div>    
</body>
</html>