<html>
<head>
<title>Linear Regression Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归解释</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-explained-5a5e9027cd6d?source=collection_archive---------8-----------------------#2019-09-17">https://medium.com/analytics-vidhya/linear-regression-explained-5a5e9027cd6d?source=collection_archive---------8-----------------------#2019-09-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/ea58a9164ecaa678f7f777b954436e24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w64HM-ZiZfBrasI9yv9pdA.jpeg"/></div></div></figure><div class=""/><p id="412e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">线性回归是你开始学习机器学习时弹出的第一个算法。这是最简单的学习算法之一，很容易理解。点击这里查看如何在你的浏览器中运行ML程序。我们将思考它的工作原理，然后用Python实现它。我试着用很多图片和图形来解释，以帮助你理解这个概念。让我们看看它是如何工作的！</p><h1 id="bfb2" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是回归？</h1><p id="e139" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">回归是一种估计具有连续值域的变量之间关系的方法。相比之下，分类是将变量分成不同的类或组。比方说，我们必须模拟人的身高和体重之间的关系。所以，给定一个人的体重，我们必须预测他的身高。这里，身高和体重都有一个连续的取值范围。但是，在分类任务中，输出只能属于一组类或组。一个这样的例子是预测图像是“猫”还是“狗”。</p><p id="d677" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">关键是，当目标变量连续时，这是一个回归任务。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es ks"><img src="../Images/7889ade474e5f59b29fd6f06aa982a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*8KQh5n6gjpZWZtFYZ2JDDA.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">身高英寸，体重磅</strong></figcaption></figure><p id="d016" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的数据集中，我们可以使用两个变量中的任何一个来预测另一个。我用体重来预测身高。为了简单起见，我们将忽略表中的性别列。你看到“身高”和“体重”都有一个连续的数值范围吗？</p><h1 id="d503" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">线性回归简介</h1><p id="b97b" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">线性回归是使用线性预测模型来预测目标变量。我们用‘用体重预测身高’这个问题来详细了解一下。这里，权重作为输入或自变量。并且身高是使用输入体重预测的因变量。体重与身高的关系是用直线建立的。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lb"><img src="../Images/b37e6398097c016668c71b9fa0ed7c4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lCEhXyg83Bd1VMpSyP8Jnw.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">一条线的数学方程</strong></figcaption></figure><p id="5902" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们在数学上将线表示为Y = m*X+ C，其中X是输入要素，Y是目标变量。在上面的等式中，“m”和“C”是决定直线斜率和截距的参数。</p><p id="b2a5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">不能理解什么是“斜率”和“截距”？没问题，我掩护你。</p><h1 id="a2c0" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">斜率和截距。它们是什么？</h1><figure class="kt ku kv kw fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lc"><img src="../Images/262dba74fc031bdbc436dd071e586929.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kEiqTEOVnM5-6RZBqGneSA.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">直线方程</strong></figcaption></figure><p id="ff4d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">任何直线的斜率“m”决定了该直线相对于水平X轴的倾斜程度。在上图中，这条线的倾角为45度。因此，直线的斜率是正切(45)或tan(45)，即1。截距是直线与相应轴相交的地方。在我们的例子中，“C”是Y轴截距，其值为零。因此，线方程是Y=1*X + 0，即Y=X。</p><h1 id="4998" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">将线拟合到数据集</h1><p id="93ab" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">现在，让我们回到我们的“体重-身高”数据集，看看我们的数据是什么样子的。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es ld"><img src="../Images/564ae072598d455e00883e6d1e1c2800.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*8ixsXOlGFXb_SR4voV2zOw.jpeg"/></div></figure><p id="38be" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这个20个样本的散点图中，数据点以倾斜的方式分布。如果我们想用一条线来拟合这个数据，那也是一条斜线。但是，我们要使它倾斜到什么程度呢？我们把线放在哪里呢？还记得斜率和截距吗？通过调整它们的值，我们将能够定位线条以适应数据。但是我们如何知道我们的线性回归模型的斜率和截距的值应该是多少呢？训练部分来了。</p><p id="134f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在训练过程中，我们让我们的模型看到输入和输出数据(体重和身高)，并调整其参数，使线完美拟合。但是在我们开始训练之前，我们从‘m’和‘C’的随机值开始。因此，该模型预测给定输入集的随机输出值。然后，该模型通过使用损失函数将其输出与真实输出进行比较，来查看它预测的有多差。</p><h1 id="f7f8" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">线性回归模型的损失函数</h1><p id="51dc" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">为了了解我们的模型预测得有多糟糕，我们使用了一个叫做均方差(MSE)的指标。因为只有当我们看到误差有多大时，我们才能通过最小化误差来纠正它。MSE取整个训练数据集的实际高度值和预测高度值之差的平方和的平均值。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es le"><img src="../Images/03e021e14d0109550e53248c5cbf16bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ZZ9C629cdAidCWp-IQmDQ.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">均方误差成本函数</strong></figcaption></figure><p id="1072" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的等式中，“pred”是模型预测的值，而“true”是基本事实标签。但是，为什么是MSE呢？因为平方项会使大误差变大，非常小的误差变小。对整个数据集求和以计算误差。</p><h1 id="2cc6" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">最小化成本</h1><p id="c014" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们在上面看到的成本应该被最小化，以得到我们模型的最佳拟合。这是通过他们所谓的“梯度下降”来实现的。基本上，梯度下降调整“m”和“c”的值，使得总损失最小。它通过对‘m’和‘C’取成本函数的偏导数(使用链式法则)并更新它们的值来做到这一点。</p><h1 id="e6d9" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">梯度下降</h1><p id="caf2" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">成本函数在分别对‘m’和‘C’进行部分微分时，分别产生每个模型参数(m和C)的更新值。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es lf"><img src="../Images/3fd9be267361911a54b74129d9b2d087.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZiJ5Jby4ANad3I2yMZS73A.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">均方差的偏导数w.r.t 'm' </strong></figcaption></figure><p id="8c03" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，使用微积分的链式法则，我们区分成本函数元素。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/781d127bdd25bee2ddd4aa9a4f8698a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Malrqwt2aGsH6-wvzlkx3w.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">在偏导数外取常数1/n</strong></figcaption></figure><p id="47ff" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据标量乘规则，常数乘数可以移到导数之外。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es lf"><img src="../Images/b70a2453c078c004ede8a3b33ad44596.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nfO_rNT9d7tLsv59kDVhww.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">根据幂法则，平方项被微分</strong></figcaption></figure><p id="f96c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，常数‘2’也可以去掉，留下“(mX+C-ytrue)”项在里面。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lh"><img src="../Images/60c51f5ee6b4b9b6759dff788cd7a229.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aYJZC0yeNkHKRCDreOmgQQ.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">最终方程式</strong></figcaption></figure><p id="634d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“m*X+C-ytrue”相对于“m”的偏导数是X，因为所有其他项在偏导数中被视为常数。因此,“X”项与表达式的其余部分相乘。</p><p id="3da8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个过程对于C的导数也是一样的。它的结果方程将是这样的。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es lf"><img src="../Images/cc4b63a15ce1655527fd16dd457d5c59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NZyR0zwZzINv2uD4ywF6-Q.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">成本函数相对于‘C’的偏导数</strong></figcaption></figure><p id="2e30" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些导数用于使用梯度下降更新公式来更新‘m’和‘C’的现有值。我们使用参数‘alpha’来定义应该更新多少参数。alpha越高，更新越大。但是，α值应该被最佳地设置，以便不超过参数的最佳值。更新等式如下所示。</p><div class="kt ku kv kw fd ab cb"><figure class="li hk lj lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/f4d5960bfb13fb9585da790e468f46de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*wvcgOhor355xxH7VcREYEg.jpeg"/></div></figure><figure class="li hk lo lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/349ba9aa6a6370a7f2c32787ccdc423c.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*lC2NgEtwOAtSwlcA0W1q8Q.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx lp di lq lr translated"><strong class="bd jr">更新‘C’和‘m’</strong></figcaption></figure></div><p id="db7a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“t+1”是更新值，“t”是现值。</p><h1 id="8a4f" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">它看起来怎么样？</h1><div class="kt ku kv kw fd ab cb"><figure class="li hk ls lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/e9515c48ce67c977667b33a04a10fbdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*31Mn2N3kumAl6T3seGLYpA.jpeg"/></div></figure><figure class="li hk ls lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/82a7bfe8f95d161595f7ea49f8a4e9d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*kq9d0nhwWd27CBCaEHnp-A.jpeg"/></div></figure><figure class="li hk ls lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/c5b89c25ac42b8182fda764e09cf8577.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*uSkuQzWdvsvjh6KxgAP71g.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx lt di lu lr translated">1)随机适合2)完美适合3)不完美适合</figcaption></figure></div><p id="82a8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随着参数的更新，直线与数据集的拟合更加完美，最终的线性回归线是最佳拟合。</p><h1 id="6d5b" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">线性回归完成！</h1><p id="51a6" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我希望这篇文章能让你清楚地了解线性回归的工作原理。在下一篇文章中，我们将只使用Python从头开始编写一个线性回归模型。</p><p id="a9ca" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">直到那时，<a class="ae jo" href="https://hackerstreak.com" rel="noopener ugc nofollow" target="_blank">快乐黑客</a>！</p><p id="b740" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="lv">原载于</em><a class="ae jo" href="https://hackerstreak.com/" rel="noopener ugc nofollow" target="_blank"><em class="lv">https://hackerstreak.com</em></a></p></div></div>    
</body>
</html>