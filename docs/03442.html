<html>
<head>
<title>In a hurry! XGBoost: Six Easy Steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">赶时间！XGBoost:六个简单的步骤</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/in-a-hurry-xgboost-six-easy-steps-b410b56ef85b?source=collection_archive---------7-----------------------#2020-02-01">https://medium.com/analytics-vidhya/in-a-hurry-xgboost-six-easy-steps-b410b56ef85b?source=collection_archive---------7-----------------------#2020-02-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="09f8" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">极端梯度提升会发生什么——它如何提高性能</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/86cfe3ddc499e81a8c7efc76d2f52ff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GlMowOskgIm92P2x"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">贾斯汀·坎贝尔在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="8494" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">XGBoost是一个基于决策树的集成机器学习，它使用一个boosting框架。</p><p id="4b97" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们已经在文章中解释了决策树和CART技术。请阅读它以了解决策树如何识别分割特征的方法— <a class="ae jn" rel="noopener" href="/analytics-vidhya/in-a-hurry-classification-and-regression-tree-six-easy-steps-ec343c3f6b2f">点击此处</a></p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><p id="9d9b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">什么是助推？</p><ul class=""><li id="5ada" class="kr ks hi jq b jr js ju jv jx kt kb ku kf kv kj kw kx ky kz bi translated">在boosting中，每个模型都是建立在一个序列上的。</li><li id="7db9" class="kr ks hi jq b jr la ju lb jx lc kb ld kf le kj kw kx ky kz bi translated">基于训练数据集，两种技术都创建n个分类器(随机的新数据集)。</li><li id="196e" class="kr ks hi jq b jr la ju lb jx lc kb ld kf le kj kw kx ky kz bi translated">表示基于数据集1构建模型1。然后，模型2基于模型1构建(先前分类器成功-基于权重),但使用数据集2。这最大限度地减少了以前模型的误差，并增加了高性能模型的影响。</li><li id="8ff2" class="kr ks hi jq b jr la ju lb jx lc kb ld kf le kj kw kx ky kz bi translated">小心，这会增加过度拟合。</li><li id="ecae" class="kr ks hi jq b jr la ju lb jx lc kb ld kf le kj kw kx ky kz bi translated">提升使用某些权重到下一个分类阶段。</li></ul></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><p id="1d21" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">决策树的演变:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lf"><img src="../Images/9201a23c2c130747fcda1bcd0f1de93b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bFPXXMBkjNp8K6ZxbRzfaA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">从决策树进化出XGBoost算法</figcaption></figure><p id="9e45" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">XGBoost工作于并行处理，例如有两个循环，一个是内部循环，另一个是外部循环。现在，如果外部循环逐个创建叶节点。并且内部循环计算特征。现在，在内循环完成之前，不能启动外循环。因此，XGBoost中的并行化解决了这一限制，在XGBoost中，为了提高运行时间，循环的顺序是可以互换的。此开关提高了算法性能。</p><p id="417f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">与CART类似，我们也使用max_depth参数来设置修剪树的标准。</p><p id="0d4a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">XGBoost关注以下内置算法增强:</p><ul class=""><li id="dcda" class="kr ks hi jq b jr js ju jv jx kt kb ku kf kv kj kw kx ky kz bi translated">正规化，以克服过度拟合通过L1拉索斯和L2岭。</li><li id="ceb4" class="kr ks hi jq b jr la ju lb jx lc kb ld kf le kj kw kx ky kz bi translated">稀疏特征允许，比如，缺失值，零值，一键编码。</li><li id="7cb3" class="kr ks hi jq b jr la ju lb jx lc kb ld kf le kj kw kx ky kz bi translated">权重五分草图，以有效地在数据库中找到一个最佳分裂。</li><li id="9643" class="kr ks hi jq b jr la ju lb jx lc kb ld kf le kj kw kx ky kz bi translated">内置交叉验证</li></ul></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><p id="7903" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">在R中构建XGBoost模型的六个简单步骤:</strong></p><p id="e89b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">第一步:</strong>安装库，xgboost，margrittr，Matrix</p><p id="6722" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">步骤2: </strong>使用xgb为训练和测试数据集创建一个矩阵。DMatrix()函数</p><p id="f239" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">步骤3: </strong>为参数和观察列表设置参数</p><p id="5837" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">第四步:</strong>使用xgb.train()函数构建模型</p><p id="9868" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">第五步:</strong>使用xgb.importance()函数进行特征分析</p><p id="f386" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">第六步:</strong>使用predict()函数进行预测</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><p id="4b5d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">关于实际应用以及如何将XGBoost应用于“汽车司机接受/拒绝报价”预测案例研究— <a class="ae jn" href="https://github.com/RutvijBhutaiya/McKinsey-Big-Data-Hackathon" rel="noopener ugc nofollow" target="_blank">点击此处</a></p><div class="lg lh ez fb li lj"><a href="https://github.com/RutvijBhutaiya/McKinsey-Big-Data-Hackathon" rel="noopener  ugc nofollow" target="_blank"><div class="lk ab dw"><div class="ll ab lm cl cj ln"><h2 class="bd hj fi z dy lo ea eb lp ed ef hh bi translated">rutvijbhutaya/麦肯锡大数据黑客马拉松</h2><div class="lq l"><h3 class="bd b fi z dy lo ea eb lp ed ef dx translated">人群分析(CAX) -麦肯锡大数据黑客马拉松，预测要约被某个…</h3></div><div class="lr l"><p class="bd b fp z dy lo ea eb lp ed ef dx translated">github.com</p></div></div><div class="ls l"><div class="lt l lu lv lw ls lx jh lj"/></div></div></a></div></div></div>    
</body>
</html>