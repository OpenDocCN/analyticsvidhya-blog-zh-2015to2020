<html>
<head>
<title>Exploring Other Face Recognition Approaches (Part 2) — ArcFace</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">探索其他人脸识别方法(第 2 部分)ArcFace</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/exploring-other-face-recognition-approaches-part-2-arcface-88cda1fdfeb8?source=collection_archive---------4-----------------------#2020-08-28">https://medium.com/analytics-vidhya/exploring-other-face-recognition-approaches-part-2-arcface-88cda1fdfeb8?source=collection_archive---------4-----------------------#2020-08-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="37d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一系列的文章中，我们将探索不同于普通人脸的其他各种人脸识别方法。在上一篇文章<br/>(第一部分)中，我们讨论了关于<a class="ae jd" rel="noopener" href="/analytics-vidhya/exploring-other-face-recognition-approaches-part-1-cosface-4aed39afe7a8"> Cosface </a>。<br/>在这一部分，我们将讨论<em class="je"> Arcface:深度人脸识别的附加角度余量损失</em>。</p><p id="7596" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将讨论三种不同类型的人脸识别方法。<a class="ae jd" rel="noopener" href="/analytics-vidhya/exploring-other-face-recognition-approaches-part-1-cosface-4aed39afe7a8"> CosFace </a> <strong class="ih hj"> <br/> </strong> 2。<strong class="ih hj"> ArcFace </strong> <br/> 3。<a class="ae jd" rel="noopener" href="/analytics-vidhya/exploring-other-face-recognition-approaches-part-3-dream-a5627ced45be">梦:深度残差同变映射</a></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/1eb77f9a985572503bb9ccf088152f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*if3YDYycAl8grFlxScBsjA.jpeg"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated"><a class="ae jd" href="https://nrmedia.nyc3.cdn.digitaloceanspaces.com/2019/01/facial-recognition.jpg" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="76f4" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">介绍</h1><p id="5210" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">有两条主线研究训练 CNN 用于人脸识别，一条是使用 softmax 分类器训练多类分类器，另一条是学习嵌入，如三元组丢失。然而，两者都有其缺点:<br/>对于 softmax 损失，添加越多的不同身份进行识别，参数的数量将增加越多。对于三元组丢失，大规模数据集的面三元组数量出现组合爆炸，导致大量迭代。</p><p id="2864" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了进一步提高人脸识别模型的描述能力和稳定训练过程，arcface 提出了一个附加的角度裕度损失。反余弦函数用于计算当前特征和目标权重之间的角度。ArcFace 通过角度和弧在归一化超球[人脸特征所在]中的精确对应，直接优化了<a class="ae jd" href="https://dsp.stackexchange.com/questions/54826/what-is-different-between-euclidean-distance-and-the-geodesic-distance/54827" rel="noopener ugc nofollow" target="_blank">测地线距离</a>余量。</p><h1 id="3f3d" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">方法</h1><p id="ac7e" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">最广泛使用的分类损失，即 softmax 如下:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es ky"><img src="../Images/35c0b444775c6a683e3ff853a4c73c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*pIwx2O5H_tgWfCj7CYy1UA.png"/></div></figure><p id="2f45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中 x 表示第 I 个样本的特征向量，W 和 b 分别是权重和偏差。Softmax loss 没有显式地优化特征嵌入以加强类内样本的更高相似性和类间样本的多样性，这导致在大的类内外观变化(例如，姿势变化、年龄差距等)下深度人脸识别的性能差距。</p><p id="cc11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的 softmax 损耗中，为简单起见，我们将偏差固定为 0，然后将 logit 转换为:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es kz"><img src="../Images/fb88b48f3a3bcb526e2c1be69b87dc12.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*Ksu1Q59UJQT6j6v4VkDB4w.png"/></div></figure><p id="61fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中θ是权重 W 和特征 x 之间的角度。使用 L2 范数将权重归一化为 1。特征也进行 L2 归一化并重新缩放到 s。归一化步骤有助于仅根据特征和权重之间的角度θ进行预测。学习嵌入分布在半径为 s 的超球面上，如下所示:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es la"><img src="../Images/781b2b6fbf7448b66003ef6ec2f03697.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*RntJG4aplR-VoNm0hUTLWA.png"/></div></figure><p id="5dc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在权重和特征之间增加了附加的角度裕度损失 m，以增强类内紧密度和类间差异。由于提出的附加角裕度罚值等于归一化超球面中的测地距离裕度罚值，因此将其命名为 ArcFace。最终损失函数变为:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lb"><img src="../Images/eff2715b9c5b57a9b95d9d967bf22287.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*c1UeN8NADBMqazZ_C8d0qA.png"/></div></figure><h2 id="74f9" class="lc jw hi bd jx ld le lf kb lg lh li kf iq lj lk kj iu ll lm kn iy ln lo kr lp bi translated">体系结构</h2><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es lq"><img src="../Images/dcea547cef0ef7b8ee4ab5e66a4b9f4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ry8powQODa0tOt_qoxJJA.png"/></div></div></figure><p id="e962" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">训练过程</strong> : <br/> 1。在特征 x <em class="je"> i </em>和权重 W 归一化之后，我们得到每个类的 cos θ <em class="je"> j </em> (logit)为(W<em class="je">j)’</em>x<em class="je">I</em>。<br/> 2。我们计算 arccosθ <em class="je"> yi </em>并得到特征 x <em class="je"> i </em>和地面真实权重 W <em class="je"> yi 之间的角度。</em> <br/> 3。我们在目标(地面真实)角度θ <em class="je"> yi </em>上增加一个角度裕度罚分 m。<br/> 4。我们计算 cos(θ <em class="je"> yi </em> + m)并将所有 logits 乘以特征尺度 s<br/>5。然后，logits 通过 softmax 函数，并对交叉熵损失做出贡献。</p><p id="613e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">伪代码:</strong></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es lr"><img src="../Images/a8fa5b3f9b3e6e878d67d958b2e24de3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SxJpDceFQbtCV4RSwm45Pg.png"/></div></div></figure></div><div class="ab cl ls lt gp lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="hb hc hd he hf"><h1 id="294a" class="jv jw hi bd jx jy lz ka kb kc ma ke kf kg mb ki kj kk mc km kn ko md kq kr ks bi translated">几何差异 B/W 球面、共面和弧面</h1><p id="f413" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">附加角裕度具有更好的几何属性，因为角裕度与测地线距离具有精确的对应关系。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es me"><img src="../Images/a8afa9d837f3da96ba8a6ee4b3580509.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*UaCyImA1FXJq6IPmaI0Rjg.png"/></div></figure><p id="c467" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比较二分类情况下的分类边界。ArcFace 在整个区间内具有恒定的线性角裕度。相比之下，<a class="ae jd" href="https://arxiv.org/pdf/1704.08063.pdf" rel="noopener ugc nofollow" target="_blank">球面</a>和<a class="ae jd" href="https://arxiv.org/pdf/1801.09414.pdf" rel="noopener ugc nofollow" target="_blank">共面</a>只有非线性角裕度。</p></div><div class="ab cl ls lt gp lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="hb hc hd he hf"><p id="14e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注:</strong>本文还介绍了对各种其他人脸识别架构和损失函数进行的最广泛的实验评估，这不在本文讨论范围内。请参考论文，看看他们的实验。</p><h1 id="f764" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">结论</h1><p id="2763" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">我们了解了一种新的人脸识别损失函数，它在角度空间中工作，并帮助模型学习非常有区别的特征，给出线性角度余量。</p></div><div class="ab cl ls lt gp lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="hb hc hd he hf"><h1 id="7d73" class="jv jw hi bd jx jy lz ka kb kc ma ke kf kg mb ki kj kk mc km kn ko md kq kr ks bi translated">参考</h1><p id="0ca6" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">代号:<a class="ae jd" href="https://github.com/deepinsight/insightface" rel="noopener ugc nofollow" target="_blank">https://github.com/deepinsight/insightface</a></p><p id="b1a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">论文:<a class="ae jd" href="https://arxiv.org/pdf/1801.07698.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1801.07698.pdf</a></p></div></div>    
</body>
</html>