<html>
<head>
<title>A Beginner’s Guide to K Nearest Neighbor(KNN) Algorithm With Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带代码的K最近邻(KNN)算法初学者指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-beginners-guide-to-k-nearest-neighbor-knn-algorithm-with-code-5015ce8b227e?source=collection_archive---------0-----------------------#2019-09-21">https://medium.com/analytics-vidhya/a-beginners-guide-to-k-nearest-neighbor-knn-algorithm-with-code-5015ce8b227e?source=collection_archive---------0-----------------------#2019-09-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="49df" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">今天，让我们讨论机器学习中最简单的算法之一:K最近邻算法(KNN)。在本文中，我将解释KNN算法的基本概念，以及如何在Python中使用KNN实现一个机器学习模型。</p><p id="bfb6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">机器学习算法可以大致分为两类:</p><p id="108c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">1.监督学习</p><p id="4ac0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.无监督学习</p><p id="38c6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在<strong class="io hj">监督学习</strong>中，我们在一组带标签的数据上训练我们的模型，并要求它预测未标记点的标签。例如，一个癌症预测模型是根据许多被标记为阳性或阴性的临床测试结果来训练的。然后，经过训练的模型可以预测未标记的测试结果是阳性还是阴性。</p><p id="a899" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">另一方面，<strong class="io hj">无监督学习</strong>是在无标签数据集上完成的。</p><p id="3688" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">KNN属于监督学习。话虽如此，我们将在接下来的5分钟里把机器学习和KNN放在一边，让我们去镇上鲍勃新开的水果店。作为促销优惠，Bob设置了一个难题，并向解决该难题的人赠送免费水果。这个谜题解释如下。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jk"><img src="../Images/6948081e5273a00c64adf52564d98569.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0BFbnGz2OYv0zpWJITX3Mg.jpeg"/></div></div><figcaption class="jw jx et er es jy jz bd b be z dx translated">鲍勃的难题</figcaption></figure><p id="673a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">鲍勃排列了4种水果:苹果、橘子、草莓和葡萄，如上图所示。他用一块黑布盖住了一些水果，并给它们编号。谁能正确预测这些隐藏水果的名字，谁就可以免费领取！但是做一个错误的预测会让你失去你所拥有的一切。如果不确定，可以将其标记为不确定。现在暂停一下，试试看你能不能把它做好。</p><p id="56f1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一旦你做出了预测，让我们用下面的来核对一下:</p><p id="b201" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">1，2，3 →橙子</p><p id="9f06" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">4→不确定是橘子还是苹果</p><p id="4e46" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">5，6→苹果</p><p id="5e4d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">7→草莓</p><p id="fcb9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">8→不确定是葡萄还是草莓</p><p id="0076" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">9→葡萄</p><p id="7f9b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">10→不确定是苹果还是葡萄</p><p id="8013" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果你的预测与上面的相符，那么你已经知道什么是KNN，并且已经实现了！想知道怎么做？为了理解这一点，让我们仔细看看你是如何做出预测的。</p><p id="c59c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在图像中，我们观察到相似的水果排列在一起。对于1、2和3，我们可以很容易地将它们归类为橙子，因为它们被橙子单独密集地包围着，因此隐藏的橙子也很有可能是橙子。换句话说，隐藏的那些将大部分是与它们的大多数<strong class="io hj"> <em class="ka">邻居</em> </strong>相同的类型。同样的逻辑也适用于5、6、7和9。</p><p id="772c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">对于10，我们不确定它是苹果还是葡萄。这是因为，它被苹果和葡萄包围着。或者我们可以说，10的邻居属于苹果和葡萄。所以10可以是苹果也可以是葡萄。对于4和8也是如此。</p><p id="d3d6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">简而言之，KNN算法基于其邻居的标签来预测新点的标签。KNN依赖于相似数据点在空间坐标中更接近的假设。在上面的例子中，基于邻居的标签(苹果、橘子、草莓、葡萄)，我们可以预测新数据点的标签(隐藏的水果)。</p><h1 id="f627" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">最近邻居</strong></h1><p id="97b2" class="pw-post-body-paragraph im in hi io b ip kz ir is it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj hb bi translated">KNN中的k是我们在进行预测时考虑的最近邻的数量。我们根据一个点到考虑中的点的距离(例如:欧几里德距离、曼哈顿距离等)来确定该点的接近度。例如，如果K=5，我们考虑5个最近的点，并将这5个点中大多数的标签作为预测标签。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es le"><img src="../Images/ba9b0e8f1ec45485a25ded6e2dd4db78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uEsLUQ7GdAd1bKIQKG3QCQ.jpeg"/></div></div></figure><p id="bec6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们检查一下在前面的例子中是如何估计邻居的。考虑上图。我们的目标是预测标记为X的点的标签。如果K=3，在X的3个相邻点中，2个是草莓，1个是橙子。所以我们预测X的标签是草莓。如果K=5，在X的5个相邻点中，3个是橙子，2个是草莓。所以我们预测X的标签为橙色。</p><p id="03d5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从上面的例子，我们可以看到，随着K的变化，预测的标签不同。因此，K是KNN的超参数，其将被调整以找到最佳值。在标记的训练数据上，我们用不同的K值进行实验，并选择给出最佳结果的K值。一旦K值固定，该值可以在以后用于预测未标记的数据点。</p><h1 id="aa00" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">我们来编码吧……</strong></h1><p id="480a" class="pw-post-body-paragraph im in hi io b ip kz ir is it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj hb bi translated">我们将在iris数据集上实现KNN模型。Iris数据集包含3种鸢尾花的数据，即Setosa、Versicolour和Virginica。每个数据点有4个特征和一个与之相关的标签(物种)。特征是<br/>萼片长度、萼片宽度、花瓣长度、花瓣宽度。基于这些特征，我们需要预测输出标签，即花的种类。</p><p id="b87a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">您可以从以下链接下载虹膜数据集:<a class="ae lf" href="https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv" rel="noopener ugc nofollow" target="_blank"><em class="ka">https://raw . githubusercontent . com/uiuc-CSE/data-fa14/GH-pages/data/iris . CSV</em></a></p><p id="3115" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下载完成后，将数据集加载到Python代码中。我用过Jupyter笔记本做编码。</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="6dbd" class="ll kc hi lh b fi lm ln l lo lp">import pandas as pd<br/>import numpy as np<br/>iris=pd.read_csv('iris.csv')</span></pre><p id="a5ff" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下面是数据集的一个例子。</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="6f5a" class="ll kc hi lh b fi lm ln l lo lp">iris[20:25]</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es lq"><img src="../Images/f283d3e41c81ae8118ceeed6db4f93cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*SlI2maPy4gH62BRoSpUEnA.jpeg"/></div><figcaption class="jw jx et er es jy jz bd b be z dx translated">来自iris数据集的样本数据</figcaption></figure><p id="234a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们需要首先从数据集中分离出物种(标签)列。</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="9189" class="ll kc hi lh b fi lm ln l lo lp">X=iris.drop(columns=['species'])<br/>Y=iris['species']</span></pre><p id="0cbc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">x包含特征，Y包含物种。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lr"><img src="../Images/a0b8862be90ddb0763fe1f5b5e3d38c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vXF4s2Z5TgJ7A_TA7BZGYA.jpeg"/></div></div><figcaption class="jw jx et er es jy jz bd b be z dx translated">输入要素和输出标注</figcaption></figure><p id="f57c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在机器学习中，我们在训练数据上训练我们的模型，并使用交叉验证(CV)数据上的模型性能来调整超参数(KNN的K)。因此，让我们使用sklearn库中的train_test_split()函数将数据分成train和CV数据集。你可以从这个<a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank">链接</a>了解更多。</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="9d0a" class="ll kc hi lh b fi lm ln l lo lp">from sklearn.model_selection import train_test_split<br/>X_train,X_val,y_train,y_val=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=20)</span></pre><p id="c47d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">由于KNN是基于数据点之间的距离来工作的，因此在训练模型之前对数据进行标准化非常重要。标准化有助于避免规模带来的问题。我们使用sklearn的StandardScaler()函数进行数据标准化。你可以通过这个<a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">链接</a>了解更多信息。</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="a57d" class="ll kc hi lh b fi lm ln l lo lp">scaler = StandardScaler()<br/>scaler.fit_transform(X_train)<br/>scaler.transform(X_val)</span></pre><p id="c74d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在让我们用一个随机的K值来训练我们的KNN模型，比如K=10。这意味着我们考虑10个最近的邻居来进行预测。多亏了sklearn，我们只用3行代码就能训练出KNN模型！！！你可以从这个<a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" rel="noopener ugc nofollow" target="_blank">链接</a>中阅读更多关于sklearn中KNeighborsClassifier()函数的内容</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="8f88" class="ll kc hi lh b fi lm ln l lo lp">from sklearn import neighbors<br/>KNN_model=neighbors.KNeighborsClassifier(n_neighbors=best_k,n_jobs=-1)<br/>KNN_model.fit(X_train,y_train)</span></pre><p id="946f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们检查我们的训练模型在预测交叉验证数据的标签方面表现如何。</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="65b3" class="ll kc hi lh b fi lm ln l lo lp">pred=KNN_model.predict(X_val)<br/>print("Accuracy={}%".format((sum(y_val==pred)/y_val.shape[0])*100))</span></pre><p id="6049" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">输出:精确度=90.0%</p><p id="15ab" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这意味着该模型可以准确预测90%的数据点的标签。让我们检查一下是否可以通过将超参数K调整到最佳值来提高这种精度。</p><p id="29dc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在下面的代码片段中，对于每个K值，使用F1分数来评估模型性能。F1分数是用于评估模型的性能指标。F1分数的值在0-1的范围内。模型性能随着F1分数的增加而增加。你可以从这个<a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html" rel="noopener ugc nofollow" target="_blank">链接</a>中读到更多关于F1-Score的内容。</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="85d2" class="ll kc hi lh b fi lm ln l lo lp">from sklearn import neighbors <br/>from sklearn.metrics import f1_score,confusion_matrix,roc_auc_score<br/>f1_list=[]<br/>k_list=[]<br/>for k in range(1,10):<br/>    clf=neighbors.KNeighborsClassifier(n_neighbors=k,n_jobs=-1)<br/>    clf.fit(X_train,y_train)<br/>    pred=clf.predict(X_val)<br/>    f=f1_score(y_val,pred,average='macro')<br/>    f1_list.append(f)<br/>    k_list.append(k)</span></pre><p id="94bf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们绘制F1分数与K值的关系图。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es ls"><img src="../Images/322735f9dbb9ea7c41d2c31d5996ae92.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*eXJdoAFNHNssmaDgqDFLgQ.jpeg"/></div></figure><p id="e75b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们得到能给出最大F1分数的最佳K值</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="f3a6" class="ll kc hi lh b fi lm ln l lo lp">best_f1_score=max(f1_list)<br/>best_k=k_list[f1_list.index(best_f1_score)]        <br/>print("Optimum K value=",best_k," with F1-Score=",best_f1_score)</span></pre><p id="b813" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">输出:最佳K值= 3，F1得分= 1.0</p><p id="2a2d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，让我们使用最佳K值(即K=3)进行预测，并检查准确性</p><pre class="jl jm jn jo fd lg lh li lj aw lk bi"><span id="4aae" class="ll kc hi lh b fi lm ln l lo lp">KNN_model=neighbors.KNeighborsClassifier(n_neighbors=3,n_jobs=-1)<br/>KNN_model.fit(X_train,y_train)<br/>pred=KNN_model.predict(X_val)<br/>print("Accuracy={}%".format((sum(y_val==pred)/y_val.shape[0])*100))</span></pre><p id="c665" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">输出:精确度=100.0%</p><p id="8652" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，我们可以看到，通过使用最佳K值，我们获得了100%的精度。请注意，我们得到了100%的准确性，因为我们使用的数据集很简单。对于复杂得多的真实生活数据集，我们可能无法获得如此高的精确度。</p><h1 id="c963" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">KNN的优势</strong></h1><ul class=""><li id="5f7f" class="lt lu hi io b ip kz it la ix lv jb lw jf lx jj ly lz ma mb bi translated">不需要培训时间</li><li id="8b54" class="lt lu hi io b ip mc it md ix me jb mf jf mg jj ly lz ma mb bi translated">它简单且易于实现</li><li id="92a7" class="lt lu hi io b ip mc it md ix me jb mf jf mg jj ly lz ma mb bi translated">由于不需要模型训练，新的数据点可以随时添加到训练数据集中。</li></ul><h1 id="40ec" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">KNN的缺点</strong></h1><ul class=""><li id="9e5e" class="lt lu hi io b ip kz it la ix lv jb lw jf lx jj ly lz ma mb bi translated">需要特征缩放</li><li id="2be2" class="lt lu hi io b ip mc it md ix me jb mf jf mg jj ly lz ma mb bi translated">当维度较高时，效果不佳。</li><li id="9e29" class="lt lu hi io b ip mc it md ix me jb mf jf mg jj ly lz ma mb bi translated">对异常值敏感</li><li id="716d" class="lt lu hi io b ip mc it md ix me jb mf jf mg jj ly lz ma mb bi translated">预测在计算上是昂贵的，因为我们需要计算所考虑的点和所有其他点之间的距离。</li></ul></div></div>    
</body>
</html>