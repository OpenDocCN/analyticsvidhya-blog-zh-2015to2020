<html>
<head>
<title>Web Scraping using BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用BeautifulSoup进行网页抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-cricket-players-names-using-python-5e4318e94f9c?source=collection_archive---------7-----------------------#2020-05-08">https://medium.com/analytics-vidhya/web-scraping-cricket-players-names-using-python-5e4318e94f9c?source=collection_archive---------7-----------------------#2020-05-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ae93" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用request和BeautifulSoup库快速学习Web抓取。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/9105605fa2cccb82623012e96274c75e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iYMOKFTad55ZdkL6wutVTw.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">照片由费尔南多·埃尔南德斯拍摄，编辑为@Sarawritezz</figcaption></figure><p id="99f4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi kk translated"><span class="l kl km kn bm ko kp kq kr ks di"> W </span> eb搜集确实是数据科学中有趣的一部分。当我在开发的时候，我不得不从一个网站上收集蔬菜的价格，然后显示在一个web应用程序上。我在Ruby上做网页抓取。所以有时候开发者也需要了解/做网页抓取。事实上，我是在没有任何web抓取经验和知识的情况下开始这样做的。所以，做网络抓取是非常容易的。这里我们将使用一些库用python做一个简单的网络抓取。</p><h2 id="71cc" class="kt ku hi bd kv kw kx ky kz la lb lc ld jx le lf lg kb lh li lj kf lk ll lm ln bi translated">什么是数据抓取？</h2><p id="674f" class="pw-post-body-paragraph jo jp hi jq b jr lo ij jt ju lp im jw jx lq jz ka kb lr kd ke kf ls kh ki kj hb bi translated">你曾经从任何网站复制粘贴过任何东西吗？但是这样做是一件繁琐的工作，如果我们想从另一个来源得到的数据真的更多，对吗？所以，让我们用代码的形式让我们的机器来替我们做。这才是真正的网络抓取。很酷，对吧？(喘息！)</p><h2 id="ae72" class="kt ku hi bd kv kw kx ky kz la lb lc ld jx le lf lg kb lh li lj kf lk ll lm ln bi translated">先决条件</h2><p id="4119" class="pw-post-body-paragraph jo jp hi jq b jr lo ij jt ju lp im jw jx lq jz ka kb lr kd ke kf ls kh ki kj hb bi translated">先决条件非常简单，在您的机器上设置python环境。固定在任何IDE上根据您的选择进行编码。<em class="lt">美汤</em>和<em class="lt">请求</em>是这里做网页抓取需要的两个模块。我们将在后面的学习路径中看到这些模块的用途和安装过程。</p><h2 id="7f1c" class="kt ku hi bd kv kw kx ky kz la lb lc ld jx le lf lg kb lh li lj kf lk ll lm ln bi translated">我们要刮什么？</h2><p id="45e1" class="pw-post-body-paragraph jo jp hi jq b jr lo ij jt ju lp im jw jx lq jz ka kb lr kd ke kf ls kh ki kj hb bi translated">在这里，我们将从<a class="ae jn" href="https://en.wikipedia.org/wiki/List_of_India_ODI_cricketers" rel="noopener ugc nofollow" target="_blank">维基百科</a>中收集印度ODI板球运动员多年来为印度板球队效力的名字，并将名单以CSV格式保存在本地文件中。</p><h2 id="2cb4" class="kt ku hi bd kv kw kx ky kz la lb lc ld jx le lf lg kb lh li lj kf lk ll lm ln bi translated">我们可以开始了吗？</h2><p id="c674" class="pw-post-body-paragraph jo jp hi jq b jr lo ij jt ju lp im jw jx lq jz ka kb lr kd ke kf ls kh ki kj hb bi translated">在开始之前，我假设您对HTML有所了解。如果没有，<a class="ae jn" href="https://www.w3schools.com/html/" rel="noopener ugc nofollow" target="_blank">点击此处</a>至少学习一下基本标签。首先，我把完整的代码放在这里。接下来，我用可理解的方式一点一点地解释代码。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="bb4b" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">import requests<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</strong></span><span id="d071" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">page=requests.get("</strong><a class="ae jn" href="https://en.wikipedia.org/wiki/List_of_India_ODI_cricketers" rel="noopener ugc nofollow" target="_blank"><strong class="lv hj">https://en.wikipedia.org/wiki/List_of_India_ODI_cricketers</strong></a><strong class="lv hj">").text<br/>#page</strong></span><span id="216d" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">soup=BeautifulSoup(page,"lxml")</strong></span><span id="7019" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">print(soup.prettify())</strong></span><span id="0088" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">table=soup.find("table",{"class":"wikitable"})</strong></span><span id="c0ff" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">data_rows = table.findAll('tr')[2:]<br/>#type(data_rows)</strong></span><span id="aebd" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">player_names=[]</strong></span><span id="ff53" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">for i in data_rows:<br/>    names=i.findAll("a")<br/>    for x in names:<br/>        player_names.append(x.get("title"))</strong></span><span id="f5ef" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">#print(player_names)<br/>dataframe=pd.DataFrame()<br/>dataframe['Players']= player_names<br/>#dataframe.head()</strong></span><span id="6fba" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">dataframe.to_csv("Cricket_players.csv")</strong></span></pre><p id="342d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">简单代码！</p><p id="7f79" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们从安装依赖项开始。转到终端，并执行以下代码。(<em class="lt">如果已经安装了软件包，跳过</em>)</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="f1bb" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">pip install pandas</strong></span><span id="d595" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">pip install requests beautifulsoup4</strong></span></pre><p id="60c2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">好吧。您已经下载了所有需要的依赖项，现在这些模块占用了您RAM中的一些空间。好了，让我们开始将下载的模块导入到我们的工作文件中，并开始web抓取。等等，我们的工作文件在哪里？哦，我忘了创建一个工作文件。让我们先做那件事。我正在使用Atom IDE进行编码。为了方便起见，可以使用任何IDE。用<em class="lt">创建文件后。py </em>扩展(在我的例子中是<em class="lt">，Web_Scraping.py </em>)。您的文件已经准备好作为python代码文件。</p><p id="f347" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们使用下面的代码开始导入所有必要的模块。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="f472" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">import requests</strong></span><span id="0a1c" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">from bs4 import BeautifulSoup</strong></span><span id="65e9" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">import pandas as pd</strong></span></pre><p id="ba1a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我已经在这里导入了pandas模块，它将有助于将我们收集的数据转换成CSV文件，并保存在我们的本地路径中。正如我在前面的教程中已经说过的，模块就像仆人一样。如果你想让他们做你的工作，你应该每次都给他们打电话。这就是为什么我们一直在进口。好了，让我们进入真正的代码部分。准备好弄脏你的手。</p><p id="b745" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">首先，从口译模块开始。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="dfea" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">import requests</strong></span></pre><p id="9975" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> Requests </strong>模块用于对一个网页发出GET HTTP请求。GET请求通常用于从指定的资源中检索和请求数据。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="cf7e" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">from bs4 import BeautifulSoup</strong></span></pre><p id="95c7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> BeautifulSoup </strong>模块用于从HTML、XML和其他标记语言中获取数据。我们的源页面总是HTML格式。它通常充当一个解析器，帮助我们以一种简洁的方式提取我们想要的数据。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="79bd" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">import pandas as pd</strong></span></pre><p id="0b5e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> Pandas </strong>模块在这里被用来从我们收集的数据中创建一个数据帧，并以期望的格式保存在我们的本地机器中。</p><p id="b557" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">好了，我们导入了所有必要的模块。现在你的模块从RAM到rom为你工作。</p><p id="84cc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们开始刮削。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="ae8c" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">page=requests.get("</strong><a class="ae jn" href="https://en.wikipedia.org/wiki/List_of_India_ODI_cricketers" rel="noopener ugc nofollow" target="_blank"><strong class="lv hj">https://en.wikipedia.org/wiki/List_of_India_ODI_cricketers</strong></a><strong class="lv hj">")</strong></span></pre><p id="d3f8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在上面的例子中，我们从URL页面请求get请求，我们在GET函数中传递这个请求(<em class="lt"> get()是请求模块</em>的函数)。如果在终端中运行这段代码，输出将是，</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="010b" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">print(page)</strong></span><span id="be2a" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">OUTPUT: &lt;Response [200]&gt;</strong></span></pre><p id="472c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你得到这个响应代码200，<strong class="jq hj">成功</strong>。你现在可以从这个网页上抓取数据了。如果你想知道更多关于HTTP响应代码的信息，点击这里。简而言之，如果响应代码编号以数字<strong class="jq hj">开头，则2 </strong>表示成功。但是它只抛出响应代码。但是我们希望整个网页抓取数据，对吗？</p><p id="8386" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">加上<em class="lt">就行了。在上述代码的末尾添加文本</em>。然后<em class="lt">页面</em>将以文本格式存储所有网页内容。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="492f" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">page=requests.get("</strong><a class="ae jn" href="https://en.wikipedia.org/wiki/List_of_India_ODI_cricketers" rel="noopener ugc nofollow" target="_blank"><strong class="lv hj">https://en.wikipedia.org/wiki/List_of_India_ODI_cricketers</strong></a><strong class="lv hj">").text</strong></span></pre><p id="68ae" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们也可以通过下面的代码获取内容。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="1f06" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">page.content</strong></span></pre><p id="93bf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">但是上面的代码得到的是文本格式的页面，而且更可取。</p><p id="34fd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，让我们使用模块BeautifulSoup解析我们在变量“<em class="lt">page”</em>中收集的整个HTML源代码。我们这样做，是因为源代码的笨拙和沉重。我们想要漂亮的源代码，对吗？按照嵌入的代码来做。</p><blockquote class="me mf mg"><p id="c7ca" class="jo jp lt jq b jr js ij jt ju jv im jw mh jy jz ka mi kc kd ke mj kg kh ki kj hb bi translated">BeautifulSoup以tag soup命名。标签汤意味着一种结构不良的标记语言。BeautifulSoup通过解析来美化HTML代码。</p></blockquote><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="3fa0" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">soup=BeautifulSoup(page,"lxml")</strong></span><span id="7bbe" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">print(soup.prettify())</strong></span></pre><p id="8b45" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">第一个解析代码，下一个做美化部分。我们在这里使用“lxml”解析器来解析HTML代码。现在输出看起来比以前更漂亮。现在“soup”变量收集了我们的全部代码。</p><p id="4b52" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们有整个网页，但我们打算只把玩家的名字放在桌子上，对吗？要做到这一点，首先，我们应该有一张桌子。</p><p id="31ff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在做一些裁剪，使用类选择器选择页面上的特定表格。表的类名是“wikitable”，所以很容易在代码<em class="lt">(也可以根据需要使用CSS选择器)</em>中提到表的类名。我们开始吧。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="64fc" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">table=soup.find("table",{"class":"wikitable"})</strong></span></pre><h2 id="72f9" class="kt ku hi bd kv kw kx ky kz la lb lc ld jx le lf lg kb lh li lj kf lk ll lm ln bi translated">我怎么找到选择器的？</h2><p id="2a2b" class="pw-post-body-paragraph jo jp hi jq b jr lo ij jt ju lp im jw jx lq jz ka kb lr kd ke kf ls kh ki kj hb bi translated"><strong class="jq hj">第一步:</strong>转到你抓取的网页。在我们的例子中，<a class="ae jn" href="https://en.wikipedia.org/wiki/List_of_India_ODI_cricketers" rel="noopener ugc nofollow" target="_blank"> URL </a>。</p><p id="befe" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">第二步:</strong>按CTRL+Shift+I(或右键→检查元素)</p><p id="5cb1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">第三步:</strong>按CTRL+Shift+C(或选择上述选项中的第一个选项)</p><p id="d6ff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">第四步:</strong>将光标移到要刮的桌子上。</p><p id="f628" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后，您各自的表格代码会出现在右侧。看看下面。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mk"><img src="../Images/fd16b6344926517b288c303306facb53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SqSKFlXc9bqE8_CQB3FVKQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">网页的inspect元素的屏幕截图</figcaption></figure><p id="41f7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果您是开发人员(更确切地说是前端人员)，您可能更熟悉inspect元素。现在这些浏览器多有用啊，不是吗？</p><p id="c88e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">There <em class="lt"> find() </em>是一个函数，它有助于使用我们在内部使用的选择器来查找元素。<em class="lt">汤</em>有我们的源代码。现在我们从源代码中刮出我们想要的表，并存储在<em class="lt">表</em>变量中。</p><p id="4e6b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们有这张桌子，好的，但是现在仔细看这张桌子。我们需要前两行(<em class="lt">标题</em>)吗？把你的剪刀拿下来，我们来剪吧。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="a948" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">data_rows = table.findAll('tr')[2:]</strong></span></pre><p id="fca9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我解释一下上面的代码，我们已经在<em class="lt">表的</em>变量中收集了表数据。我们正在使用<em class="lt"> findAll() </em>函数查找表格行(<em class="lt"> tr </em>)，使用<em class="lt">表格</em>变量中的切片操作排除前两行。我们最终将不带表头的表格存储在<em class="lt"> data_rows </em>变量<em class="lt">中(现在不是二维的)。</em></p><p id="5be4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">看看下面，你可以看到表格的所有行都写在了<em class="lt"> tr </em>标签中。这是构建HTML代码的传统方式。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/da417aa260e74ed704a061375fd4f40f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c9qQkx27c-nPTIHsWe-Qhg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">检查网页源代码的元素</figcaption></figure><p id="31d1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">哦，多少次呱呱坠地！</p><p id="c169" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">尽管如此，我们还是没有得到数据…</p><p id="ff3a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">跑…跑…</p><p id="6be2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这个代码步骤之后，一件很棒的事情发生了。</p><p id="7a98" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们所有的行都被转换成一个列表。正如我已经说过的，当我们从表中删除标题时，它不是一个二维结构。它只是一系列的元素。我们如何在单个变量中存储一系列项目？以<strong class="jq hj">的形式列出</strong>，对吗？事情就是这么发生的(<em class="lt">机做</em>)。</p><p id="0303" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们用下面的代码检查一下。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="d171" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">type(data_rows)</strong></span><span id="a029" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">OUTPUT: &lt;class 'list'&gt;</strong></span></pre><p id="66a1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们做一些瑜伽，闭上你的眼睛…吸气…控制你的呼吸几秒钟…呼气…</p><p id="32d8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">回来学习。</p><p id="a032" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们快到目的地了，我们马上就要收集名字了。在这之前，有231个玩家名字，我们必须有一个容器来收集所有的名字。我们有吗？没有吗？让我们创建一个。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="210d" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">player_names=[]</strong></span></pre><p id="add4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们已经创建了一个列表来存储这些名字。这在收集姓名后将所有姓名存储在单个变量下时非常有用。如果你现在不明白，那就更进一步。现在不要和它搅在一起。</p><p id="ab34" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我们的<em class="lt"> data_rows </em>变量中，我们拥有表中的所有行。但是我们想要的不仅仅是这些，对吗？这一次，我们将使用循环来选择需要的内容，因为它是以列表的形式出现的。让我用下面的截图解释一下我们应该进一步做些什么。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mm"><img src="../Images/7eb715517a028dc28a7bd53064213ef4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*Qm8jw5jSv2PxM2FkImGHfw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">网页HTML代码的屏幕截图</figcaption></figure><p id="ae5f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们找到模式，如果你仔细观察，我们在锚标签下的所有名字(<em class="lt"> &lt; a &gt; &lt; /a &gt; </em>)都存储在<em class="lt"> title </em>变量中。所以，现在你知道我们应该做什么了。就像我们使用类选择器查找表一样，使用findAll函数(<em class="lt"> findAll() </em>)查找锚标记，使用<em class="lt"> get </em>函数(<em class="lt"> get() </em>)获取变量<em class="lt"> title </em>的值。我们开始吧。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="d37f" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">for i in data_rows:<br/>    names=i.findAll("a")<br/>    for x in names:<br/>        player_names.append(x.get("title"))</strong></span></pre><p id="5856" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在使用打印函数(<em class="lt"> print(player_names) </em>)检查player_name中的值。我希望这个简单的嵌套循环不言自明。我们使用append函数将<em class="lt">标题</em>的值追加到<em class="lt"> player_names </em>中。(<em class="lt"> append() </em>)。</p><p id="6df8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们收集了玩家的名字，并成功地将其存储在一个列表中。</p><p id="794e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">那么下一步是什么…？</p><p id="3d9b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">使用pandas函数将它以我们想要的格式保存在本地。让我们用下面的代码来做这件事。</p><pre class="iy iz ja jb fd lu lv lw lx aw ly bi"><span id="8431" class="kt ku hi lv b fi lz ma l mb mc"><strong class="lv hj">dataframe=pd.DataFrame()<br/>dataframe['Players']= player_names<br/>#dataframe.head()</strong></span><span id="9970" class="kt ku hi lv b fi md ma l mb mc"><strong class="lv hj">dataframe.to_csv("Cricket_players.csv")</strong></span></pre><p id="1c83" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你不熟悉熊猫的功能，<a class="ae jn" rel="noopener" href="/@sarawritezz/import-pandas-as-pd-26344cd7235e?source=friends_link&amp;sk=6938f9f48624571136e03ddfce733a18">点击这里</a>。其中我讲述了熊猫的基本知识。之后，转到“开始”,使用您为文件指定的名称开始搜索文件。现在你可以看到你的文件和你的抓取数据保存在一起。使用熊猫功能来操作你的文件。现在你完成了你的网页抓取，伙计！</p><blockquote class="me mf mg"><p id="15a5" class="jo jp lt jq b jr js ij jt ju jv im jw mh jy jz ka mi kc kd ke mj kg kh ki kj hb bi translated">有很多方法可以做网络抓取，但没有特定的方法。这完全是关于你的技能和你在编码方面的知识。我刚刚解释了做网页抓取的简单方法。多练习，探索网页抓取的所有功能和技术。在从任何随机网站抓取任何数据之前，确保其合法性。请张贴您的疑问/看法作为回应。</p></blockquote></div></div>    
</body>
</html>