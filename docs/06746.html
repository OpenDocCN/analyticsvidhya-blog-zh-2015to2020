<html>
<head>
<title>Interpretability of Machine Learning models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习模型的可解释性</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/interpretability-of-machine-learning-models-9787cf8a3789?source=collection_archive---------12-----------------------#2020-06-01">https://medium.com/analytics-vidhya/interpretability-of-machine-learning-models-9787cf8a3789?source=collection_archive---------12-----------------------#2020-06-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a8b81ed77dd11a3c585a611e4e9fa7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JTyGavQPr1N69n8B"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">安杰洛·摩尔勒在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="a068" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在机器学习决策过程中，人们常说越简单的模型越容易解释和理解。但是，我们知道在大多数情况下，较简单的模型表现不佳，为了实现更好的性能和准确性，有必要依赖复杂的模型，在向业务用户或决策者解释时，这些模型又被视为黑盒。所以，总的来说，简单模型和复杂模型之间有一个权衡。<br/> <br/>但是最近在机器学习模型的可解释性方面的突破(<strong class="ix hj">莱姆</strong>和<strong class="ix hj"> SHAP </strong>)提供了一个有用的指导，可以有效地用来解释模型的行为。这两个概念背后的基本原理简单明了。<strong class="ix hj"> LIME </strong>取局部特征的重要性，<strong class="ix hj"> SHAP </strong>处理集体或个人特征对目标变量的贡献。</p><p id="d7d5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以，如果我们能够清晰地解释这个模型，那么可解释性可能是一项伟大的技术</p><ul class=""><li id="e944" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">向业务用户解释模型。</li><li id="0767" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">帮助数据科学家从业务角度理解特性的重要性。</li><li id="484f" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">培养对已开发模型的信心和信任。</li><li id="21f2" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">以帮助模型的调试和验证。</li></ul><p id="77a0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇博客中，我将介绍流行的技术和它们的实现来解释模型。</p><h1 id="232d" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak"> SHAP(沙普利加法解释)</strong></h1><p id="0de3" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">SHAP是由Scott Lundberg和Su-In Lee在2017年提出的，原始论文可以在这里找到<a class="ae iu" href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"/></a><br/><br/>shap算法是一种模型不可知的算法，所提出的技术大大降低了附加特征归属方法的复杂性，从<strong class="ix hj"><em class="lk">【o(tld^m】</em></strong>到<strong class="ix hj"> <em class="lk"> O(TLD ) </em> </strong>其中<strong class="ix hj"><em class="lk"/></strong>和<strong class="ix hj">开源的SHAP库几乎可以与所有流行的集合模型很好地工作，比如XGBoost、LightGBM、CatBoost和sklearn树模型。</strong></p><p id="edc2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">SHAP算法受<a class="ae iu" href="https://en.wikipedia.org/wiki/Cooperative_game_theory" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">合作博弈论</strong> </a>的启发，用<a class="ae iu" href="https://en.wikipedia.org/wiki/Shapley_value" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> Shapley值</strong> </a>来解释特征对权重(系数)的贡献。</p><h2 id="62bb" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated"><strong class="ak">SHAP在机器学习中的用法</strong></h2><p id="7420" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">对于简单模型，很容易直观地解释特征的重要性和影响，例如，如何为预测计算关联权重，为什么为一个类形成特定的决策树，等等。然而，对于复杂的模型来说，这不是很直接，这里出现了<strong class="ix hj"> Shapely Value </strong>的概念来解释个人或一组特征如何影响预测的目标。</p><p id="3014" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一般来说，Shapley值是作为玩家联盟中每个玩家的边际贡献的平均值来计算的。对于<strong class="ix hj">“支付”，需要考虑玩家之间的公平分配。</strong></p><p id="6d18" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要了解数学和细节，请看看<a class="ae iu" href="https://www.rand.org/content/dam/rand/pubs/research_memoranda/2008/RM670.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">原文</strong> </a></p><p id="948c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对合作博弈论术语及其公理的基本理解是理解Shapely值计算的基础。<br/> <br/> <strong class="ix hj"> <em class="lk">合作博弈理论:</em> </strong>合作博弈(或联盟博弈)是一种博弈，由于合作行为的外部强制的可能性，参与者群体之间存在竞争。</p><p id="2768" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lk">玩家:</em> </strong>参与游戏的代理(玩家)。</p><p id="6756" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lk">联盟:</em> </strong>玩家之间为游戏出力的临时联盟。</p><p id="95f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lk">公平分配:</em> </strong>公平贡献如何在玩家之间分配？</p><h2 id="2b3d" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated"><strong class="ak">公理</strong></h2><p id="cf77" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated"><strong class="ix hj"> <em class="lk"> i)效率:</em> </strong>所有代理的Shapley值之和等于大联盟的值，使得所有的收益在代理之间分配。</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/49342338c6a633659a72d0aa725462b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*o3WagKAHqjov7f9FV1TF7g.png"/></div></figure><p id="ffca" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中N =代理总数，φ(v)=shapley值，v(N)=所有参与者的大联盟。</p><p id="a543" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lk"> ii)对称性:</em> </strong>所有玩家都有公平的机会加入游戏。这个属性也被称为<em class="lk">平等对待平等者。</em></p><p id="ecb7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果I和j是两个等价的参与者</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es me"><img src="../Images/c5d0880c2953f870c0f614a8f5636bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*QmfdDzHS6QSadTpzNFMrdw.png"/></div></figure><p id="6983" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于N中既不包含I也不包含j的每个子集S，则</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/38ae2148649e74532473f925402e8aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:238/format:webp/1*Vkk9bZN0gkeb-N3bTe7mLA.png"/></div></figure><p id="ee74" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lk"> iii)线性:</em> </strong>如果将增益函数v和w描述的两个联盟博弈组合起来，那么分配的增益应该对应于从v得到的增益和从w得到的增益</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/8cc583deb765f61be64fa5cdc08907bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*iLCDDlrg_jXt5Tc8tI8Rgg.png"/></div></figure><p id="8ccf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于n中的每个I。</p><p id="a56f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lk"> iv)空玩家或哑玩家:</em> </strong>一个游戏v中一个空玩家<strong class="ix hj"> <em class="lk"> i </em> </strong>的Shapley值为零。参与人I在v中为空，如果</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/b4622e15c9dd85060fbba1891a660dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/1*GjuzmxYgmJM8cgpeLVIs2w.png"/></div></figure><p id="13ab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于所有不包含的联盟，也就是说，如果玩家对联盟没有贡献，那么贡献将为零。</p><p id="f4c5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在现实生活中，一个<strong class="ix hj"> <em class="lk">游戏</em> </strong>可以被翻译成任何动作，例如共享出租车/食物、玩游戏、为协作动作而工作，或者通过使用可用特征来预测任何分类或回归模型的结果。</p><p id="ce9f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了更好地理解Shapley值的计算，我们来看一个简单的例子。</p><p id="1fb9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">三个朋友F1、F2和F3将共享出租车到达他们的家。如果他们单独去，那么每个人需要分别支付10美元、15美元和30美元。如果他们随团旅行，最高支付额是30美元。但问题是，除了一般平均工资贡献[(10+15+30)/3]，我们如何计算联盟的公平个人工资？</p><p id="49fb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">著名的沙普利救援值来了。</p><p id="9045" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">根据给定的细节，我们知道如果每个朋友将单独前往他们的家，那么他们将支付<br/><br/><em class="lk">F1-&gt;</em><em class="lk">10<br/>F2-&gt;</em><em class="lk">15<br/>F3-&gt;</em><em class="lk">30</em></p><p id="0db7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，如果他们要一起旅行，那么下面的组合就会形成</p><figure class="ma mb mc md fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/f4c3c8a4368a2c1084204a541852d863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z4AahgIpkr0kGYzHVsaN-A.png"/></div></div></figure><p id="9b75" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们创建一个可能的排列，如果他们在一个给定的联盟中旅行。</p><figure class="ma mb mc md fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/5b888eb70303bfb1649fac1e77659c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jql26dtYyLBjolWL6eOeUA.png"/></div></div></figure><p id="bb26" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们是如何计算置换集的？</p><p id="98ba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">{F1，F2，F3} = &gt; 如果F1 &amp; F2将组成联盟，那么他们将一起支付15美元。由于F1先下来，他将支付10美元，剩余的5美元将由F2支付，15美元将由F3支付(因为15美元已经支付)</p><p id="87f2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> {F1，F3，F2} = &gt; </strong>这一次，F1和F3将组成联盟。因此，F1将支付10美元，剩余金额将由F3支付，即30美元–10美元= 20美元。当F3和F2之间形成联盟时，F2将不必支付任何费用。</p><p id="407d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以同样的方式，计算其他排列集合和个体贡献。</p><p id="13a1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">计算出的平均值是T2沙普利值，如果一起旅行，个人会为所有的朋友付费。如果我们将排列集的所有朋友和联盟支付的平均值相加，那么它总是以30结束，这表明支付是公平分布的<strong class="ix hj">。</strong> <br/> <br/>同样的概念也适用于我们在预测目标变量时对特征的重要性及其权重进行可视化。我们可以把这些计算出的Shapley值看作是它们对某一类或某一值的预测的贡献。<br/> <br/>在机器学习中，我们可以这样联系上面的理解。</p><blockquote class="mk ml mm"><p id="1e89" class="iv iw lk ix b iy iz ja jb jc jd je jf mn jh ji jj mo jl jm jn mp jp jq jr js hb bi translated"><em class="hi">游戏- &gt;型号</em></p><p id="3311" class="iv iw lk ix b iy iz ja jb jc jd je jf mn jh ji jj mo jl jm jn mp jp jq jr js hb bi translated"><em class="hi">玩家- &gt;特性</em></p><p id="3d78" class="iv iw lk ix b iy iz ja jb jc jd je jf mn jh ji jj mo jl jm jn mp jp jq jr js hb bi translated"><em class="hi">玩家子集- &gt;特征子集</em></p><p id="2a6d" class="iv iw lk ix b iy iz ja jb jc jd je jf mn jh ji jj mo jl jm jn mp jp jq jr js hb bi translated"><em class="hi">特征的Shapley值- &gt;特征的贡献。</em></p></blockquote></div><div class="ab cl mq mr gp ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hb hc hd he hf"><h1 id="a30f" class="kh ki hi bd kj kk mx km kn ko my kq kr ks mz ku kv kw na ky kz la nb lc ld le bi translated"><strong class="ak"> LIME(局部可解释的模型不可知解释)</strong></h1><p id="da04" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">LIME也是由马尔科·图利奥、Sameer Singh和Carlos Guestrin提出的一种流行算法。我为什么要相信你</p><p id="8f9c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该算法使用局部解释来描述特征的重要性。可以通过用具有很少非零系数的简单线性模型来近似底层模型来产生解释。</p><p id="f010" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">石灰的数学表示是</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/d1a145c9e8543af9aa67839bd06bcd5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*zQTkYql6rX70uvYnHV9KZQ.png"/></div></figure><p id="a095" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，模型的解释通过保持模型复杂度低来测量解释与原始模型(f)的预测有多接近。</p><p id="bbd6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="lk">其中x =实例，L =位置感知损失函数，f=要解释的模型(原始模型)，g =线性模型，G=解释模型族，Pi -定义位置的实例x的邻近性度量，Omega(g) =模型复杂度。</em></p><p id="198d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了对酸橙有一个大致的了解，让我们来理解每个单词的意思。</p><blockquote class="mk ml mm"><p id="8447" class="iv iw lk ix b iy iz ja jb jc jd je jf mn jh ji jj mo jl jm jn mp jp jq jr js hb bi translated"><strong class="ix hj">局部:</strong>局部可靠的解释。这是LIME算法背后的关键直觉。</p><p id="5faf" class="iv iw lk ix b iy iz ja jb jc jd je jf mn jh ji jj mo jl jm jn mp jp jq jr js hb bi translated"><strong class="ix hj">可解释:</strong>可以处理和理解的信息。如果我们正在处理<strong class="ix hj">文本</strong>，那么它会显示<strong class="ix hj">存在/不存在单词，</strong>对于图像，它是<strong class="ix hj">存在/不存在超像素</strong>，对于表格数据，它是<strong class="ix hj">特征的加权组合</strong>(系数)。</p><p id="95d2" class="iv iw lk ix b iy iz ja jb jc jd je jf mn jh ji jj mo jl jm jn mp jp jq jr js hb bi translated"><strong class="ix hj">模型不可知:</strong>适用于任何类型的预测模型，也就是说，在提供解释时，它不应对模型做出任何假设。</p><p id="7b6a" class="iv iw lk ix b iy iz ja jb jc jd je jf mn jh ji jj mo jl jm jn mp jp jq jr js hb bi translated"><strong class="ix hj">说明:</strong>模型输入输出的关系和理解。</p></blockquote><h2 id="2539" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated"><strong class="ak">执行石灰的步骤</strong></h2><p id="dced" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">选择一个我们想要解释的观察。<br/> <br/> <strong class="ix hj"> ii) </strong>在观测周围，对每个数据点进行扰动，生成邻域。不考虑模型的复杂性，在局部水平上，可以线性地划分区域(局部线性回归)。在扰动中，在设置为1的所有特征(对于给定的数据点)中，随机采样特征的子集，并将它们的值设置为0。</p><p id="08a1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">参见原始论文中的下图</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/0578f51bd40b95ad9d6e0f0bbafda172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*5AKLkqzwrGxAOUII9jN0xg.png"/></div></figure><p id="f8f1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上图中，我们可以看到这些决策边界非常复杂，任何简单的模型都很难将其全局分离。然而，如果我们缩小范围并达到单个数据点，那么在局部上很容易用线性模型来分离决策边界。</p><p id="8875" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> iii) </strong>计算新点与观测值之间的距离(相似性的度量)。<br/> <br/> <strong class="ix hj"> iv) </strong>找到与我们的目标类关系最强的m个特征的子集。<br/> <br/> <strong class="ix hj"> v) </strong>在由相似性加权的<strong class="ix hj"> n- </strong>维的数据集上拟合线性模型或任何可解释模型。<br/> <br/> <strong class="ix hj"> vi) </strong>线性模型的权重被用来解释决策，我们知道简单模型是可以解释的。</p><h2 id="abf3" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated"><strong class="ak">弊端</strong></h2><p id="6dde" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">它依赖于新点的随机抽样，所以可能不稳定。</p><p id="5105" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> ii) </strong>拟合线性模型可能不准确。然而，LIME提供了R值，并且同样可以被检查以查看局部线性回归是否是良好的拟合。</p><p id="b16a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> iii) </strong>由于我们需要为每次观察生成一个样本数据集进行解释，这使得单次观察相对较慢，尤其是对于图像。</p></div><div class="ab cl mq mr gp ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hb hc hd he hf"><h1 id="f929" class="kh ki hi bd kj kk mx km kn ko my kq kr ks mz ku kv kw na ky kz la nb lc ld le bi translated"><strong class="ak">排列重要性或平均降低准确度(MDA) </strong></h1><p id="7c98" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">这也是用于模型可解释性的技术之一。它测量某项功能不可用时<strong class="ix hj">分数如何降低</strong>。这种方法的算法很简单——<em class="lk">去除特征，重新训练模型。检查R、F1值和模型的准确性。所以，这些值的任何变化都可以说明特性的重要性。</em></p><h2 id="4a2a" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated"><strong class="ak">弊端</strong></h2><ul class=""><li id="fb3b" class="jt ju hi ix b iy lf jc lg jg ne jk nf jo ng js jy jz ka kb bi translated">计算成本很高，因为它需要重新训练模型。但是，可以通过使用与原始特征值相同的分布为测试数据集中移除的列生成噪声数据来避免这种情况。这样做将有助于避免重新训练模型，但它需要仔细填充数据。</li></ul></div><div class="ab cl mq mr gp ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hb hc hd he hf"><h1 id="c548" class="kh ki hi bd kj kk mx km kn ko my kq kr ks mz ku kv kw na ky kz la nb lc ld le bi translated">部分相关图</h1><p id="6860" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">部分相关图是一种有用的技术，用所有其他独立变量的平均效应来表示<strong class="ix hj">独立变量(特征)对因变量(目标)的边际效应</strong>。一旦模型被训练，然后通过绘制PDP，我们可以可视化图形并关联特征与目标的交互。</p><h2 id="5c32" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated">缺点</h2><ul class=""><li id="7afd" class="jt ju hi ix b iy lf jc lg jg ne jk nf jo ng js jy jz ka kb bi translated">PDP假设为其创建图的特征与其他特征不相关。</li><li id="d993" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">有限的可视化技术(一个PDP图不能显示3个以上的特征。情节变得混乱和难以阅读)</li></ul></div><div class="ab cl mq mr gp ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hb hc hd he hf"><h1 id="a2c7" class="kh ki hi bd kj kk mx km kn ko my kq kr ks mz ku kv kw na ky kz la nb lc ld le bi translated">可用的Python包</h1><p id="ce77" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">下面是几个流行的python包，可以用来解释这些特性的重要性。</p><p id="a5d8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> shap，LIME，Skater，azureml-interpret，azureml-interpret-contrib，ELI5(像我5一样解释)→ </strong>提供MDA的实现<strong class="ix hj">。</strong></p><p id="4ffe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> sklearn.ensemble </strong>模块<strong class="ix hj"> </strong>提供<strong class="ix hj">partial _ dependency</strong>函数。</p></div><div class="ab cl mq mr gp ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hb hc hd he hf"><h1 id="72ff" class="kh ki hi bd kj kk mx km kn ko my kq kr ks mz ku kv kw na ky kz la nb lc ld le bi translated"><strong class="ak">让我们看看代码中的可解释性</strong></h1><p id="c7e7" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">以下代码片段的想法并不是建立一个好的模型，而是展示如何使用现有的最先进的技术以更好的方式理解预测。</p><p id="310c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">完整的笔记本可以在<a class="ae iu" href="https://github.com/saurabh2mishra/model-interpretation" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">这里找到</strong> </a></p><p id="ca42" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">必需库</strong> sklearn，numpy，matplotlib，shap，azureml，eli5</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="1ae7" class="ll ki hi ni b fi nm nn l no np"> from sklearn.model_selection import train_test_split<br/> from sklearn.ensemble import RandomForestClassifier<br/> from sklearn.metrics import classification_report<br/> import numpy as np<br/> import matplotlib.pyplot as plt<br/> import shap<br/> from interpret.ext.blackbox import TabularExplainer<br/> from interpret_community.widget import ExplanationDashboard<br/> shap.initjs()</span></pre><p id="2709" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我正在加载乳腺癌数据集，以展示如何在随机森林这样的复杂模型上解释模型的可解释性。</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="c7b0" class="ll ki hi ni b fi nm nn l no np">cancer_dataset = shap.datasets.sklearn.datasets.load_breast_cancer()<br/>feature_names = cancer_dataset.feature_names<br/>class_names = ["Malignant(0)", "Benign(1)"]<br/>X_train, X_test, Y_train, Y_test = train_test_split(cancer_dataset.data, cancer_dataset.target, test_size=0.25, random_state=23)<br/>rfc = RandomForestClassifier()<br/>rfc.fit(X_train, Y_train)</span></pre><p id="b901" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在使用可解释库之前，让我们看看哪些特性对forest tree很重要</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="c760" class="ll ki hi ni b fi nm nn l no np">def plot_imp_features(model, top_n):<br/>     try:<br/>         tree_feature_importances = rfc.feature_importances_<br/>     except Exception as e:<br/>         raise TypeError(f"Model must be a type of DecisionTree to use feature_importances_ Excpetion is {e}")<br/>     sorted_idx = tree_feature_importances.argsort()<br/>     select_n = sorted_idx[:top_n]<br/>     y_ticks = np.arange(0, len(select_n))<br/>     fig, ax = plt.subplots()<br/>     <br/>     ax.barh(y_ticks, tree_feature_importances[select_n])<br/>     ax.set_yticklabels(feature_names[select_n])<br/>     ax.set_yticks(y_ticks)<br/>     ax.set_title("Random Forest Feature Importances (MDI)")<br/>     fig.tight_layout()<br/>     plt.show()<br/>     </span><span id="a9be" class="ll ki hi ni b fi nq nn l no np">plot_imp_features(rfc, 15)</span></pre><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es nr"><img src="../Images/8583bda4ec93024e2bb4e86ee5bd9772.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*44kBfBXaNOx_MGwwh05ghw.png"/></div></figure><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="d598" class="ll ki hi ni b fi nm nn l no np">print(classification_report(Y_test, rfc.predict(X_test),  target_names=class_names))</span></pre><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es ns"><img src="../Images/0184c7f6c27ce9f8389959f4b4e8772d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*FS6qBVFMIsi5OaFLLO4Rcw.png"/></div></figure><p id="b632" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，使用<strong class="ix hj"> shap </strong> lib来看看我们如何解释这些特性对目标类的影响</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="222a" class="ll ki hi ni b fi nm nn l no np">explainer = shap.TreeExplainer(rfc, X_train, link="logit")<br/>shap_values = explainer.shap_values(X_test, check_additivity=False) </span></pre><p id="f632" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在下面的force_plot中，两个颜色代码用于绘制形状值和特征之间的关系。</p><p id="b3d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要理解这个图的意思，首先我们需要理解图中使用的颜色代码。</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/6c93062ef9e55e47d70299e597bbd159.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*5FyKSIT1bgZ4s1c-ZSI7lA.png"/></div></figure><p id="0dc4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有了这样的理解，让我们看看下面的特征是如何解释模型的结果的。</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="e9f8" class="ll ki hi ni b fi nm nn l no np">#first 10 classes for X_test dataset<br/>Y_test[:10] # (array([1, 1, 0, 1, 0, 0, 0, 1, 1, 0]),)</span><span id="3edf" class="ll ki hi ni b fi nq nn l no np">expected_index = 1 # indexes are 1,0<br/>test_data_index = 1 # test_data_index can range from 0 to #len(test_data_index)<br/>shap.force_plot(explainer.expected_value[expected_index], <br/>                 shap_values[expected_index][test_data_index,:], <br/>                 X_test[test_data_index,:],<br/>                 feature_names=feature_names)</span></pre><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es nu"><img src="../Images/350dd4aa194ebd1c659f7fe0ad7018b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*k0-VNjO66t0lPCVQsOn76g.png"/></div></figure><p id="3188" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">力图</strong>显示了各种特征及其值对模型输出的累积影响。上图中，预测值为0.60；平均凹点将预测值从0.5167推高到0.60</p><p id="ae1f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们遵循蓝色代码，那么我们可以看到其他特征正在最小化影响，并且将所有预测推向0，即恶性和最差周界导致更大的裕度。</p><p id="808b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们分析第二个数据点，在这里我们可以看到，最差周长、平均凹点、平均面积、最差半径等特征将预测推向0，即恶性</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="95cf" class="ll ki hi ni b fi nm nn l no np">expected_index, test_data_index = 1, 2 #test_data_index can range     #from 0 to len(test_data_index)<br/>shap.force_plot(explainer.expected_value[expected_index], <br/>                 shap_values[expected_index][test_data_index, :], <br/>                 X_test[test_data_index, :],<br/>                 feature_names=feature_names)</span></pre><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es nu"><img src="../Images/46bba7d08ebe4793b24bfb9091c62e3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*pYK87Zu3tqYepqDPLjqYZA.png"/></div></figure><p id="06a3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了获得整个数据集的解释，我们可以选择上面显示的许多解释，将它们旋转90度，然后水平堆叠。</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="79fa" class="ll ki hi ni b fi nm nn l no np">i=0 # class label. Can be change to 1 to see the behavior<br/>shap.force_plot(explainer.expected_value[i], shap_values[i], features=X_test, feature_names=feature_names)</span></pre><figure class="ma mb mc md fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nu"><img src="../Images/ce89c74682c767484ec4841b325a071a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*eJS83jgUwdPsYt7WjftjJg.png"/></div></div></figure><p id="bdef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">shap还提供了另一种类型的绘图，名为<strong class="ix hj">汇总绘图。</strong>在该图中，中间线表示shap值=0，与中线的偏差(+ve到-ve值)显示特定特征如何影响目标值的预测。</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="d410" class="ll ki hi ni b fi nm nn l no np">i=1<br/>shap.summary_plot(shap_values[i], features=X_test, <br/>                   feature_names=feature_names, <br/>                   class_names=class_names)</span></pre><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es nu"><img src="../Images/6e928f5830c5d50f7f3e66ff478b3115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*fmwaCO2XHekHzprp_E3AUQ.png"/></div></figure><p id="2557" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="lk">概要图通过保持X轴上的特征和Y轴上的SHAP值来绘制图表</em></p><p id="1ce3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">理解单个特征:</strong>该函数自动包含另一个与所选变量交互最多的变量。下图描绘了平均纹理和目标变量<strong class="ix hj">之间的负趋势，并且最差周长<strong class="ix hj">与平均纹理</strong>频繁交互。</strong></p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es nv"><img src="../Images/52e2d9909dcd1b4e45d85364c114ce04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*gl_A3W08y7E6Efau4gPhnA.png"/></div></figure><p id="06b3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这段代码可用于显示每个类和要素的SHAP值</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="f9a1" class="ll ki hi ni b fi nm nn l no np">for feature_name in range(len(feature_names)):<br/>     for target_label in range(len(cancer_dataset.target_names)):<br/>         shap.dependence_plot(feature_name, shap_values[target_label], features=X_test, feature_names=feature_names)</span></pre><p id="604b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> SHAP库</strong>还包含其他解释器，如<strong class="ix hj"> PermutationExplainer、GradientExplainer、KernelExplainer、LinearExplainer、DeepExplainer等。</strong>在API中我们可以看到关于这些解释器的详细信息</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="1c72" class="ll ki hi ni b fi nm nn l no np">dir(shap)</span><span id="e020" class="ll ki hi ni b fi nq nn l no np">['BruteForceExplainer', 'DeepExplainer', 'GradientExplainer', 'KernelExplainer', 'LinearExplainer', 'PartitionExplainer', 'PermutationExplainer', 'SamplingExplainer', 'Tree', 'TreeExplainer', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_cext', 'approximate_interactions', 'bar_plot', 'common', 'datasets', 'decision_plot', 'dependence_plot', 'embedding_plot', 'explainers', 'force_plot', 'have_matplotlib', 'hclust_ordering', 'image_plot', 'initjs', 'kmeans', 'matplotlib', 'monitoring_plot', 'multioutput_decision_plot', 'other', 'partial_dependence_plot', 'plots', 'sample', 'save_html', 'summary_plot', 'unsupported', 'warnings', 'waterfall_plot']</span></pre><h2 id="c622" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated"><strong class="ak"> LIME(局部可解释的模型不可知解释)</strong></h2><p id="3a52" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">石灰使用起来也很简单。首先，我们需要为数据集创建一个特定的解释器，然后我们可以调用解释器实例的<strong class="ix hj"> explain_instance </strong>方法来解释原始模型。</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="239e" class="ll ki hi ni b fi nm nn l no np">from lime.lime_tabular import LimeTabularExplainer<br/>np.random.seed(11)</span><span id="5a60" class="ll ki hi ni b fi nq nn l no np">tab_explainer=LimeTabularExplainer(X_train,feature_names=feature_nam   es,class_names=class_names, discretize_continuous=True,random_state=11)</span><span id="f52b" class="ll ki hi ni b fi nq nn l no np">def explain_model(model, test_data, index=0, num_features=1, top_labels=1): <br/>    if test_data.size ==0:<br/>        raise ValueError("Empty dataset is passed")<br/>    expl = tab_explainer.explain_instance(test_data[index], <br/>                                          model.predict_proba, <br/>                                          num_features=num_features, <br/>                                          top_labels=top_labels)<br/>    <br/>    expl.show_in_notebook(show_table=True,show_all=False)</span><span id="5f9c" class="ll ki hi ni b fi nq nn l no np"><br/>explain_model(rfc, X_test, index=0, num_features=10) # Y_test[1] = 1(Benign)</span></pre><figure class="ma mb mc md fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nw"><img src="../Images/84ffcff2954c7921b8ea67b82b8ed775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iEvzi8c1eUyMEjH2VgtBKA.png"/></div></div></figure><p id="cbe8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上图中，我们可以看到模型预测了良性类，突出显示的功能产生了更大的影响。在右侧，我们可以看到最差区域的值为517.88，低于其实际值564.20。我们可以从数据集中检查上述值。</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="96ba" class="ll ki hi ni b fi nm nn l no np">cancer_dataset.feature_names[-7] # worst area<br/>X_test[0][-7]</span><span id="0f2d" class="ll ki hi ni b fi nq nn l no np">Out[196]:<br/>564.2</span><span id="3e8f" class="ll ki hi ni b fi nq nn l no np">cancer_dataset.feature_names[-8] # worst perimeter<br/>X_test[0][-8]</span><span id="7bd4" class="ll ki hi ni b fi nq nn l no np">Out[197]:<br/>86.6</span></pre><h2 id="65d7" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated">部分相关图</h2><p id="c62f" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">scikit-learn提供了PDP的内置实现。partial _ dependence函数接受BaseGradientBoosting拟合模型作为参数来提供PDP。因此，出于这个原因，我在训练一个新的分类器。</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="213d" class="ll ki hi ni b fi nm nn l no np">from sklearn.ensemble import GradientBoostingClassifier<br/>from sklearn.ensemble import partial_dependence<br/>gbc = GradientBoostingClassifier()<br/>gbc.fit(X_train, Y_train)</span><span id="49c2" class="ll ki hi ni b fi nq nn l no np"># [20] is the index of columns of train data for PDP<br/>partial_dependence.plot_partial_dependence(gbc, X_train, [20], feature_names=feature_names)</span></pre><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es nx"><img src="../Images/bdf9295dabc29195944545bb1f65e864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*psehYGUyUGhFSr4nS9VxvA.png"/></div></figure><p id="f27a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该图显示了最差半径如何与目标相互作用(恶性和良性)。一旦最差半径的大小越过16的标记，预测就从良性急剧下降到恶性。</p><h2 id="3e05" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated">AzureML </h2><p id="a927" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">Azure还在其azuleml SDK下发布了一个开源库。该库可用于遵循scikit-learn方法惯例的所有类型的机器学习模型，即<strong class="ix hj"> fit()和transform() </strong></p><p id="fb79" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们正在使用任何自定义算法，那么我们可以简单地将我们的主模型包装在函数<strong class="ix hj"> fit() </strong>中，并将其传递给azureml来解释这些特性。</p><p id="1477" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面的可解释性图表有助于理解不同的解释者</p><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es ny"><img src="../Images/3fd8149ed4c0ff0bce25dea41adaede3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*aDeb_MFhYostqAIw5kdrRA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability" rel="noopener ugc nofollow" target="_blank">https://docs . Microsoft . com/en-us/azure/machine-learning/how-to-machine-learning-interprebility</a></figcaption></figure><p id="6b71" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，如果我们将同一个随机森林分类器作为一个参数传递给TabularExplainer，那么我们就可以得到模型的解释。</p><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="0b33" class="ll ki hi ni b fi nm nn l no np">tab_explainer = TabularExplainer(rfc, X_train, features=feature_names, classes=[0, 1])</span><span id="3b14" class="ll ki hi ni b fi nq nn l no np">global_explanation = tab_explainer.explain_global(X_test) # How globally all features set interpretate the outcome</span><span id="2827" class="ll ki hi ni b fi nq nn l no np">global_feature_rank_values = dict(zip(global_explanation.get_ranked_global_names(),<br/>                                       global_explanation.get_ranked_global_values()))<br/> global_feature_rank_values</span><span id="137a" class="ll ki hi ni b fi nq nn l no np">Out[23]:</span><span id="0ba0" class="ll ki hi ni b fi nq nn l no np">{'worst perimeter': 0.07595532987463141,<br/>  'worst concave points': 0.06780037332226518,<br/>  'worst radius': 0.06178580090500718,<br/>  'worst area': 0.061688813644569004,<br/>  'worst concavity': 0.051432037342211356,<br/>  'mean area': 0.02544095929461229,<br/>  'mean concavity': 0.022822935606762865,<br/>  'mean perimeter': 0.02230714237151857,<br/>  'mean concave points': 0.014994114385124891,<br/>  'mean texture': 0.01426150261834639,<br/>  'mean radius': 0.012523284263610842,<br/>  'worst texture': 0.012036364340557092,<br/>  'worst compactness': 0.011888211618859144,<br/>  'worst smoothness': 0.007687756633585173,<br/>  'mean compactness': 0.007227320108198555,<br/>  'perimeter error': 0.006870732294207836,<br/>  'area error': 0.006006945019138089,<br/>  'worst symmetry': 0.0059455597100683925,<br/>  'radius error': 0.00498892192057288,<br/>  'compactness error': 0.00440812326792559,<br/>  'mean fractal dimension': 0.004065060877333495,<br/>  'concavity error': 0.003417519253002984,<br/>  'texture error': 0.003318578728239531,<br/>  'worst fractal dimension': 0.0029870047227208156,<br/>  'symmetry error': 0.00259608337064409,<br/>  'mean smoothness': 0.0018153337349097675,<br/>  'concave points error': 0.0015773339816971782,<br/>  'fractal dimension error': 0.001495528819412792,<br/>  'smoothness error': 0.0007389462921350583,<br/>  'mean symmetry': 0.0005036257960195172}</span></pre><p id="727a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> Azureml </strong>还提供了<strong class="ix hj">解释仪表板</strong>，这是一个强大的仪表板服务。它为模型解释提供了4个基本图。</p><ol class=""><li id="888c" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js nz jz ka kb bi translated"><strong class="ix hj">数据浏览:</strong>在此选项卡中，我们可以选择X轴和Y轴的值来查看各自的目标分布。在右上角，我们可以看到目标类</li><li id="2b88" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js nz jz ka kb bi translated"><strong class="ix hj">全局重要性:</strong>全局重要性变量，我们可以选择前K个特征</li><li id="784d" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js nz jz ka kb bi translated"><strong class="ix hj">解释探究:</strong>该选项卡解释为什么某个特定特征对预测很重要。</li><li id="1df7" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js nz jz ka kb bi translated"><strong class="ix hj">汇总重要性:</strong>汇总所有特征及其与目标变量的关系。</li></ol><pre class="ma mb mc md fd nh ni nj nk aw nl bi"><span id="6d4d" class="ll ki hi ni b fi nm nn l no np">ExplanationDashboard(global_explanation, rfc , datasetX=X_test)</span></pre><figure class="ma mb mc md fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nu"><img src="../Images/9e91cb6bef88fe402f8b7a5b7947d1d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*lrRMBT-PL3O6OXsdCrhHOw.png"/></div></div></figure><h2 id="10ee" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated">结论</h2><p id="183c" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">总之，我们可以说，采用可解释性作为反馈循环可以增强对模型的信任。简单且符合逻辑的解释极大地增加了涉众的商业价值，并为模型提供了信心，使其能够如预期的那样明智地执行。因此，随着模型的各种度量(例如，准确性、交叉验证)，可解释性也应该在模型开发生命周期中获得自己的位置。</p><h2 id="ff3c" class="ll ki hi bd kj lm ln lo kn lp lq lr kr jg ls lt kv jk lu lv kz jo lw lx ld ly bi translated"><strong class="ak">参考文献</strong></h2><p id="ef68" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated"><a class="ae iu" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">https://christophm.github.io/interpretable-ml-book/</a></p><p id="e513" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://arxiv.org/abs/1705.07874" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1705.07874</a></p><p id="704b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">https://arxiv.org/abs/1602.04938——我为什么要相信你。</p><p id="6092" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability?WT.mc_id=azuremedium-blog-lazzeri" rel="noopener ugc nofollow" target="_blank">https://docs . Microsoft . com/en-us/azure/machine-learning/how-to-machine-learning-interpreability？wt . MC _ id = azure media-blog-lazzeri</a></p><p id="9001" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability" rel="noopener ugc nofollow" target="_blank">https://docs . Microsoft . com/en-us/azure/machine-learning/how-to-machine-learning-interprebility</a></p><p id="fcbe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://books.google.nl/books?id=wlexDwAAQBAJ&amp;pg=SA6-PA21&amp;lpg=SA6-PA21&amp;dq=azureml+Tabular+explainer&amp;source=bl&amp;ots=7_Stxdaw0l&amp;sig=ACfU3U12IPmJI0ImltJIitWY3VO1vdPGeg&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiDu56gtM3pAhVLwAIHHerQCa0Q6AEwBXoECAoQAQ#v=onepage&amp;q=azureml%20Tabular%20explainerTreeScoringExplainer&amp;f=false" rel="noopener ugc nofollow" target="_blank">https://books.google.nl/books?id=wlexDwAAQBAJ&amp;pg = SA6-PA21&amp;lpg = SA6-PA21&amp;dq = azure ml+Tabular+explainer&amp;source = bl&amp;ots = 7 _ stx daw0 l&amp;SIG = acfu 3 u 12 ipmji 0 imltjiitwy3 VO 1 vdp eg&amp;HL = en&amp;sa = X&amp;ved = 2 ahukewidu 56 GTM 3 pahvlaihherqca 0 q 6a</a></p><p id="24d9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">【https://www.youtube.com/watch?v=C80SQe16Rao】T2&amp;t = 2334s</p><p id="ae18" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://scikit-learn.org/stable/modules/partial_dependence.html" rel="noopener ugc nofollow" target="_blank">https://scikit-learn . org/stable/modules/partial _ dependency . html</a></p><p id="4fc5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html" rel="noopener ugc nofollow" target="_blank">https://eli5.readthedocs.io/en/latest/#</a></p><p id="b9af" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability" rel="noopener ugc nofollow" target="_blank">https://docs . Microsoft . com/en-us/azure/machine-learning/how-to-machine-learning-interprebility</a></p></div></div>    
</body>
</html>