<html>
<head>
<title>Time Series and Prediction (Part-2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时间序列与预测(下)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/time-series-and-prediction-part-2-84f674803c03?source=collection_archive---------29-----------------------#2020-07-16">https://medium.com/analytics-vidhya/time-series-and-prediction-part-2-84f674803c03?source=collection_archive---------29-----------------------#2020-07-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="1d78" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">有无深度学习算法的时间序列和预测综合研究。</h2></div><p id="9473" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">干杯！你终于来了。这是我关于时间序列和预测的第二篇文章。如果你没有读过第一篇，那么请阅读那篇文章<a class="ae jt" rel="noopener" href="/@tirth.stu/time-series-and-prediction-part-1-4a9b55c85276"> <strong class="iz hj"> <em class="ju">这里</em> </strong> </a>。在这一部分中，我们将对我们的时间序列应用一些深度学习算法。首先，我们必须将数据分为特征和标签。</p><h1 id="ed9e" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">准备要素和标签</h1><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es kn"><img src="../Images/96a5b870f9b3c299d49b5641ca0bdea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5yGVurgsif0HePpxdPVViw.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">功能和标签(来源— <a class="ae jt" href="https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction" rel="noopener ugc nofollow" target="_blank"> Coursera </a></figcaption></figure><p id="e1fe" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这种情况下，我们的特征实际上是系列中的几个值，我们的标签是下一个值。我们将把作为我们的特征的值的数量称为窗口大小，在这里我们获取数据的窗口，并训练ML模型来预测下一个值。例如，如果我们获取时间序列数据，比方说，一次30天，我们将使用30个值作为特征，下一个值是标签。然后，随着时间的推移，我们将训练一个神经网络，将30个特征与单个标签进行匹配。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">准备窗口数据集</figcaption></figure><p id="baf4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">例如，让我们使用<strong class="iz hj"> tf.data.Dataset </strong>类为我们创建一些数据，我们将创建10个值的范围。我们将使用<strong class="iz hj"> dataset.window </strong>通过窗口来扩展我们的数据集。它的参数是窗口的大小和我们每次想要移动的量。因此，我们将窗口大小设置为5，偏移量为1。我们可以在窗口上添加一个名为<strong class="iz hj"> drop_remainder </strong>的参数。如果我们将此设置为true，它将通过丢弃所有余数来截断数据。也就是说，这意味着它将只给我们五个项目的窗口。好消息是转换成NumPy数组非常容易，我们只需调用。<strong class="iz hj"> numpy </strong>方法对数据集中的每一项。好了，下一个任务是将数据分为要素和标注。对于列表中的每一项，将除最后一项之外的所有值作为特征是有意义的，然后最后一项可以作为标签。此外，你会在训练前打乱他们的数据。这可以通过使用<strong class="iz hj">随机播放方法</strong>来实现。最后，我们可以看看数据的批处理，这是通过<strong class="iz hj">批处理方法</strong>完成的。它需要一个大小参数，在这个例子中，是2。我们会看到这个输出。</p><pre class="ko kp kq kr fd lf lg lh li aw lj bi"><span id="40ca" class="lk jw hi lg b fi ll lm l ln lo">OUTPUT :<br/>x =  [[1 2 3 4]  [0 1 2 3]] y =  [[5]  [4]] <br/>x =  [[3 4 5 6]  [4 5 6 7]] y =  [[7]  [8]] <br/>x =  [[2 3 4 5]  [5 6 7 8]] y =  [[6]  [9]]</span></pre><p id="819c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">应用我的合成数据</strong>——第一步是使用<strong class="iz hj"> tf.data.dataset </strong>从系列中创建数据集。我们将使用它的<strong class="iz hj"> from_tensor_slices </strong>方法把这个序列传递给它。然后，我们将基于我们的<strong class="iz hj"> window_size </strong>使用数据集的<strong class="iz hj">窗口方法</strong>来将数据分割成适当的窗口。每一个移位一次。我们将通过将drop remainder设置为true来保持它们的大小不变。然后，我们将数据展平，使其更容易处理。一旦压平了，就很容易洗牌了。你调用一个shuffle并传递给它shuffle缓冲区。使用随机缓冲区可以加快速度。例如，如果您的数据集中有100，000项，但您将缓冲区设置为1000。它会用前一千个元素填充缓冲区，随机选择其中一个。然后它会用1000和第一个元素替换它，然后再随机选取，依此类推。这样，对于超大数据集，随机元素选择可以从较小的数字中选择，从而有效地加快速度。然后，经过混洗的数据集被分成'<strong class="iz hj"> x </strong>'，即除最后一个元素之外的所有元素，以及'<strong class="iz hj"> y' </strong>，即最后一个元素。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">从我们的合成数据生成window_datset的代码</figcaption></figure><h1 id="e814" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">预言；预测；预告</h1><p id="cf44" class="pw-post-body-paragraph ix iy hi iz b ja lp ij jc jd lq im jf jg lr ji jj jk ls jm jn jo lt jq jr js hb bi translated">我们创建一个空的预测列表，然后迭代序列，获取切片和窗口大小，预测它们，并将结果添加到预测列表中。我们将时间序列分成训练和测试数据，在某个时间之前获取所有数据，然后进行训练，剩下的就是验证。因此，我们将在分割时间后获取预测，并将其加载到NumPy数组中进行图表制作。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">预测下一个值的代码</figcaption></figure><ol class=""><li id="825f" class="lu lv hi iz b ja jb jd je jg lw jk lx jo ly js lz ma mb mc bi translated"><strong class="iz hj">使用单层神经网络— </strong>现在我们有了一个窗口数据集，我们可以开始用它来训练神经网络。让我们从一个非常简单的开始，它实际上是一个线性回归。我们将测量它的准确性，然后我们将在此基础上改进它。</li></ol><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">用<strong class="ak">单神经网络</strong> (window_size=20)训练我们的模型</figcaption></figure><pre class="ko kp kq kr fd lf lg lh li aw lj bi"><span id="8359" class="lk jw hi lg b fi ll lm l ln lo">Layer weights [array([[-0.05013938],        [-0.01954073],        <br/>[ 0.0709962 ],        [-0.04240771],        [ 0.04903989],        <br/>[ 0.0161289 ],        [ 0.01836954],        [ 0.04157093],        [-0.09568894],        [-0.01370953],        [ 0.0600764 ],        [-0.01854219],        [ 0.02502013],        [-0.03948223],        <br/>[ 0.0480251 ],        [-0.00747724],        [ 0.11437633],        <br/>[ 0.22616488],        [ 0.23641631],        [ 0.41190135]], dtype=float32), array([0.0148659], dtype=float32)]</span><span id="5b67" class="lk jw hi lg b fi md lm l ln lo">Model: "sequential_1" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= dense_1 (Dense)              (None, 1)                 21         ================================================================= Total params: 21 Trainable params: 21 Non-trainable params: 0 _________________________________________________________________ None</span></pre><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es me"><img src="../Images/bcc35d54c7e68da3965874bd929bcc7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ueU0NHDDpP5ZRqwRvCvyqA.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">预测<strong class="bd jx">使用单层神经网络</strong></figcaption></figure><p id="2b9c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后我们将定义模型，编译它，并使它适合我们生成的数据。完成后，它会打印出层的重量。您可以在此处看到图层权重，它为线性回归的x值提供了系数，以及回归的偏差值。我们通过调用层上的<strong class="iz hj">获取权重方法</strong>来实现这一点。我们现在可以为系列的验证拆分中的每个元素绘制预测，预测用橙色表示，实际值用蓝色表示。最后，我们可以测量有效数据和预测结果之间的平均绝对误差。我得到了平均绝对误差<strong class="iz hj"> 5.2505198 </strong>。</p><p id="7324" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 2。使用深度神经网络(DNN) </strong> —现在让我们用DNN进行下一步，看看我们是否可以提高我们的模型精度。和我们之前看到的线性回归模型没有太大区别。这是一个相对简单的深度神经网络，有三层。所以让我们一行一行地解开它。我用三层<strong class="iz hj"> 10、10和1个神经元</strong>保持了我的模型的简单。输入形状是窗口的大小，我们将使用relu函数激活每一层。然后，我们将像以前一样用<strong class="iz hj">均方误差损失函数</strong>和<strong class="iz hj">随机梯度下降优化器</strong>编译模型。最后，我们将在<strong class="iz hj"> 100个时期内拟合模型，</strong>经过几秒钟的训练后，我们将看到类似这样的结果。还是挺好的。当我们计算平均绝对误差时，即<strong class="iz hj"> 4.567452 </strong>，我们比之前更低，因此这是朝着正确方向迈出的一步。<br/>参考关于<a class="ae jt" href="https://towardsdatascience.com/a-laymans-guide-to-deep-neural-networks-ddcea24847fb" rel="noopener" target="_blank"> DNN </a>的更多探索。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">用具有3层的<strong class="ak">深度神经网络</strong>训练我们的模型</figcaption></figure><p id="5dcc" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是这也有点像瞎猜，特别是对于优化器函数。如果我们可以选择最佳的学习速度，而不是我们选择的速度，这不是很好吗？我们可能会更有效地学习，并建立一个更好的模型。现在让我们来看看使用回调的技术。我已经添加了一个<strong class="iz hj">回调</strong>来使用一个<strong class="iz hj">学习速率调度器</strong>调整学习速率。您可以在下面看到代码。这个函数将在每个时期结束时的回调中被调用。它要做的是根据纪元编号将学习速率更改为一个值。所以在<strong class="iz hj">纪元1 </strong>中，学习率为<strong class="iz hj"> 1e-8 * 10**(1/20) </strong>。而当我们到达<strong class="iz hj"> 100纪元</strong>的时候，就是<strong class="iz hj"> 1e-8 * 10**(100/20) </strong>。这将在每次回调时发生，因为我们在<strong class="iz hj"> model.fit </strong>的回调参数中设置了它。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">在每个时期后改变学习率的代码</figcaption></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mf"><img src="../Images/820537373703f8417c960377f62f91ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*d8uNqKdpZOL_HkOMqvf0oQ.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">每个时期的损失相对于每个时期的学习率</figcaption></figure><p id="ffd9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在完成训练后，我们可以使用下面的代码绘制每个时期的损失和每个时期的学习率，我们会看到这样的图表。y轴显示该时期的损失，x轴显示学习率。然后，我们可以尝试选择曲线的最低点，它仍然像这样相对稳定，就在<strong class="iz hj"> 7 * (10 **-6) </strong>附近。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">绘制不同学习率下的损失</figcaption></figure><p id="17f3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，让我们将它设定为我们的学习率，然后我们将重新培训。这是相同的神经网络代码，我们已经更新了学习率，所以我们也将训练它一段时间。我们来看看训练500个纪元后的结果。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es mg"><img src="../Images/4be6450834b2073c0a62c9463613116c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CPh3ONiUSHVZ5EHrsXV2pw.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">每个历元相对于历元数量的损失</figcaption></figure><p id="b258" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第一次检查看起来我们可能只是在浪费时间训练超过10个纪元，但是事实上早期的损失是如此之高。如果我们将它们切掉，并绘制10个时期后的时期损失，那么图表将告诉我们一个不同的故事。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es mh"><img src="../Images/e197c7cbfb89fd356c78238daaa28cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rRDulFAEUs8wV1oqaCjeCQ.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">缩放图像</figcaption></figure><p id="5f66" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到，即使在500个时代之后，损失仍在继续减少。这表明我们的网络确实学得很好。并且平均绝对误差即<strong class="iz hj"> 4.48277 </strong>明显低于先前。</p><p id="e26b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 3。使用递归神经网络(RNN) </strong> —一种递归神经网络，或RNN是一种包含递归层的神经网络。这些设计用于顺序处理输入序列。rnn非常灵活，能够处理各种序列，包括预测文本。这里我们将使用它们来处理时间序列。我们将构建一个包含两个循环图层和一个最终密集图层的RNN，作为输出。有了RNN，你可以成批地给它输入序列，它就会输出一批预测。一个区别是，当使用RNNs时，完整的输入形状是三维的。第一个维度是批量大小，第二个维度是时间戳，第三个维度是每个时间步的输入维度。想了解更多关于RNN的信息，请点击这里<a class="ae jt" href="https://www.coursera.org/learn/nlp-sequence-models/lecture/ftkzt/recurrent-neural-network-model" rel="noopener ugc nofollow" target="_blank"><em class="ju"/></a>。</p><p id="b801" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要了解更多参考这些文章:<a class="ae jt" href="https://towardsdatascience.com/understanding-rnn-and-lstm-f7cdf6dfc14e" rel="noopener" target="_blank"> <em class="ju"> Article1 </em> </a>，<a class="ae jt" href="https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/" rel="noopener ugc nofollow" target="_blank"> <em class="ju"> Article2 </em> </a>。<br/>参考这个<a class="ae jt" href="https://www.tensorflow.org/guide/keras/rnn" rel="noopener ugc nofollow" target="_blank"> <em class="ju">链接</em> </a>在TensorFlow中实现RNN。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es mi"><img src="../Images/7e80f489bd9fa3b690ad78f9110636f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4wv1sAKoi79hmIXaZiqF7A.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">RNN细胞(来源— <a class="ae jt" href="https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction" rel="noopener ugc nofollow" target="_blank"> Coursera </a>)</figcaption></figure><p id="5236" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">例如，如果我们有30个时间戳的窗口大小，我们将它们以4的大小进行批处理，形状将是4乘30乘1，每个时间戳，存储单元输入将是一个4乘1的矩阵，如上所示。该单元还将从上一步中获取状态矩阵的输入。当然在这种情况下，在第一步，这将是零。现在，在某些情况下，你可能想输入一个序列，但是你不想输出，你只是想为批处理中的每个实例获取一个向量。这通常被称为引导RNN 的<strong class="iz hj">序列。但实际上，你所做的就是忽略所有的输出，除了最后一个。在TensorFlow </strong>中使用<strong class="iz hj"> Keras时，这是默认行为。因此，如果您希望递归层输出一个序列，您必须在创建层时指定<strong class="iz hj">returns sequences equals true</strong>。当您将一个RNN图层叠加到另一个图层上时，您需要这样做。</strong></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es mj"><img src="../Images/5b19aad48ef85c14457937f3f883709d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L6Vs3QqJPcn3SUhY8JLdIg.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">来源— <a class="ae jt" href="https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction" rel="noopener ugc nofollow" target="_blank"> Coursera </a></figcaption></figure><p id="e350" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以在我的RNN中，有两个递归层，第一个设置了<strong class="iz hj"> return_sequences=True </strong>。它将输出一个序列，该序列被馈送到下一个循环层。下一个图层没有设置为True的return_sequence，因此该图层将向我们提供单个密集图层的输出。</p><p id="9fba" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，我想添加一些新的层，这些层使用了<strong class="iz hj">λ</strong>类型。因此，第一个λ层将用于帮助我们的维度。如果你记得RNN期望三维:<strong class="iz hj">批量大小，时间戳的数量，和序列维度。</strong>使用Lambda，我们只需将数组扩展一维。类似地，如果我们使用lambda函数将输出放大100倍，我们可以帮助训练。RNN层中的默认激活函数是<strong class="iz hj"> tanh() </strong>双曲正切激活。这会输出-1和1之间的值。由于时间序列值通常在10秒左右，如40秒、50秒、60秒和70秒，因此将输出放大到相同的范围可以帮助我们学习。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">使用<strong class="ak">递归神经网络(RNN) </strong>的训练模型</figcaption></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es me"><img src="../Images/d7fde08fe8ccd2dbeb1e6bc283b5b694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nHoAXkI_MFGv34jS9tQfuQ.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">预测<strong class="bd jx">使用递归神经网络(RNN) </strong></figcaption></figure><p id="a855" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是训练神经网络的代码。我已经设定了最佳的学习速度，并挑选了400个时期进行训练。一旦训练好了，我就可以用它来预测验证范围并绘制结果。在我所有的图中，我可以看到我的预测并不太坏，除了这个平台，这将对我的MAE产生不好的影响。但尽管如此，我的MAE只有大约<strong class="iz hj"> 6.41 </strong>，所以还不算太差。</p><p id="2bf4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 4。使用长短期记忆(LSTM)——</strong>lst ms是在训练的整个生命周期中保持状态的单元状态，以便状态从单元传递到单元，从时间戳传递到时间戳，并且可以更好地维护它。这意味着，与RNNs的情况相比，来自窗口早期的数据对整体预测具有更大的影响。状态也可以是双向的，以便状态可以向前和向后移动。要了解更多关于LSTMs的信息，请点击<a class="ae jt" href="https://www.coursera.org/lecture/nlp-sequence-models/long-short-term-memory-lstm-KXoay" rel="noopener ugc nofollow" target="_blank"> <em class="ju">此处</em> </a>。</p><p id="633b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">参考使用<a class="ae jt" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM" rel="noopener ugc nofollow" target="_blank"> <em class="ju">张量流</em> </a>实现LSTMs。<br/>参考这篇<a class="ae jt" rel="noopener" href="/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714"> <em class="ju">文章</em> </a>了解LSTMs的结构。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">使用<strong class="ak">长短期记忆(LSTM) </strong>训练模型的代码</figcaption></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es mk"><img src="../Images/ebab9bcee6ee232d1cced99b6a9ffca8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*386-mDvBirBjFeAlHB_UDw.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">预测<strong class="bd jx">利用长短期记忆(LSTM) </strong></figcaption></figure><p id="d6c5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先是<strong class="iz hj">TF . keras . back end . clear _ session</strong>，这个清除任何内部变量。这使得我们可以很容易地进行实验，而不会影响模型的后续版本。在为我们扩展维度的Lambda层之后，我添加了一个有32个单元格的<strong class="iz hj"> LSTM层。我还做了一个双向分析，来看看它对预测的影响。现在，我们将添加第二层，注意，我们必须在第一层上将返回序列设置为true，这样才能工作。我们在这方面进行了训练，现在我们可以看到图表。现在它跟踪得更好，更接近原始数据。也许跟不上急剧增长的速度，但至少接近了。它还给出了我们的平均误差<strong class="iz hj"> 5.28722 </strong>，这是一个很好的结果，表明我们正朝着正确的方向前进。</strong></p><p id="e2d3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 5。使用卷积— </strong>这是一种深度学习算法，可以接受输入图像，为图像中的各种对象/方面分配重要性，如可学习的权重和偏差，并能够区分它们。</p><p id="9820" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要深入卷积，请看这个<a class="ae jt" href="https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj"> <em class="ju">视频</em> </strong> </a>。</p><p id="a2b4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要不然参考这个<a class="ae jt" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53#:~:text=A%20Convolutional%20Neural%20Network%20(ConvNet,differentiate%20one%20from%20the%20other." rel="noopener" target="_blank"> <strong class="iz hj"> <em class="ju">条</em> </strong> </a>。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="ld le l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">使用<strong class="ak">卷积和lstm</strong>训练模型的代码</figcaption></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es ml"><img src="../Images/1bc1a91371c60846b0248f0bbc917c94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IUb8jJMk0y42jEcDVYzRJw.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">使用卷积的预测<strong class="bd jx"/></figcaption></figure><p id="e025" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个重要的注意事项是，我们摆脱了Lambda层，重塑了我们与LSTM的工作输入。所以我们在1D曲线上指定一个输入形状。这需要我们更新我们一直在使用的<strong class="iz hj"> windowed_datasetet </strong>助手函数。我们将简单地在助手函数中使用<strong class="iz hj"> tf.expand_ dims </strong>来扩展序列的维度，然后再对其进行处理。现在，在卷积层上添加两个双向LSTMs层，然后将输出序列传递到密集层，我们得到大约<strong class="iz hj"> 4.985901 </strong>的平均绝对误差。</p><p id="b64d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，为了进一步减少损失，一个建议是探究批量大小，并确保它适合您的数据。因此，在这种情况下，值得尝试不同的批量大小。因此，举例来说，用比原来的32个更大和更小的不同批量进行实验，你可以得到更好的结果。要了解更多关于合适批量的信息，请参考本<a class="ae jt" href="https://www.youtube.com/watch?v=4qJaSmvhxi8" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj"> <em class="ju">视频</em> </strong> </a>。</p><p id="59ae" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，通过结合CNN和LSTMs，我们已经能够建立我们迄今为止最好的模型，尽管有些粗糙的边缘可以改进。</p><h1 id="4469" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">使用真实数据(太阳黑子)</h1><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es mm"><img src="../Images/2f42e52e47403c9127c0b71cc767eb44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*65cxxVTLTLFUB9mbTRVmQQ.jpeg"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">来源— <a class="ae jt" href="https://www.cosmos.esa.int/web/cesar/rotation-period-and-sunspot-activity" rel="noopener ugc nofollow" target="_blank"> cosmos.esa </a></figcaption></figure><p id="4ba4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我已经借助Kaggle上的CSV数据预测了太阳黑子。在Github 上查看我的全部代码。</p><h1 id="9916" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">tirth Patel——Nirma大学计算机科学与工程专业学生。</h1><p id="0fc6" class="pw-post-body-paragraph ix iy hi iz b ja lp ij jc jd lq im jf jg lr ji jj jk ls jm jn jo lt jq jr js hb bi translated"><a class="ae jt" href="https://www.linkedin.com/in/tirth-patel-861303171/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>|<a class="ae jt" href="https://www.instagram.com/__txrth__/" rel="noopener ugc nofollow" target="_blank">insta gram</a>|<a class="ae jt" href="https://github.com/Tirth1306/" rel="noopener ugc nofollow" target="_blank">Github</a></p></div></div>    
</body>
</html>