<html>
<head>
<title>Implementing LightGBM to improve the accuracy of visibility variable from a meteorological model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实施LightGBM以改进来自气象模式的能见度变量的准确性</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/implementing-lightgbm-to-improve-the-accuracy-of-visibility-variable-from-a-meteorological-model-952e7418335?source=collection_archive---------9-----------------------#2019-10-02">https://medium.com/analytics-vidhya/implementing-lightgbm-to-improve-the-accuracy-of-visibility-variable-from-a-meteorological-model-952e7418335?source=collection_archive---------9-----------------------#2019-10-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="31d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的目标是提高气象模型的准确性。气象模型为我们提供了预测的变量。一些变量，如温度和压力，表现良好。您可以查看以下两个链接，了解更多信息:</p><p id="9d37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" rel="noopener" href="/@robinat539/improving-meteorological-and-ocean-models-with-machine-learning-part-0-set-up-a-data-frame-4abd3744ec75">利用机器学习改进气象和海洋模型(第0部分:建立数据框架)</a></p><p id="dfc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" rel="noopener" href="/@robinat539/improving-meteorological-and-ocean-models-with-machine-learning-part-1-assessing-the-4c309851a81e">利用机器学习改进气象和海洋模型(第1部分:评估气象模型)</a></p><p id="18b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本出版物中，我们将重点放在可见性变量上。首先，像往常一样，我们从我的Github存储库中获取数据帧:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="b0a9" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj">import pandas as pd<br/>#from Github link <br/>url=”</strong><a class="ae jd" href="https://raw.githubusercontent.com/granantuin/LEVX_class/master/maestro.csv" rel="noopener ugc nofollow" target="_blank"><strong class="jj hj">https://raw.githubusercontent.com/granantuin/LEVX_class/master/maestro.csv</strong></a><strong class="jj hj">"<br/>master=pd.read_csv(url,index_col=”datetime”,parse_dates=True)</strong></span><span id="eed7" class="jn jo hi jj b fi jt jq l jr js"><strong class="jj hj">#filter conditions<br/>master_f=master[[‘dir_p’, ‘lhflx_p’, ‘mod_p’, ‘prec_p’, ‘rh_p’, ‘visibility_p’,<br/> ‘mslp_p’, ‘temp_p’, ‘cape_p’, ‘cfl_p’, ‘cfm_p’, ‘cin_p’,<br/> ‘conv_prec_p’,”visibility_o”]]</strong></span></pre><p id="563a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们想解决一个分类二元问题。我们定义了一个阈值(1000米),并将能见度指定为阈值以下1，阈值以上0。代码应该是:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="5370" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj">#change label dependent variables<br/>threshold=1000<br/>X=master_f[[“dir_p”, ‘lhflx_p’, ‘mod_p’, ‘prec_p’, ‘rh_p’, ‘visibility_p’,<br/> ‘mslp_p’, ‘temp_p’, ‘cape_p’, ‘cfl_p’, ‘cfm_p’, ‘cin_p’,<br/> ‘conv_prec_p’]]<br/>y=pd.DataFrame({“datetime”:master_f.index,<br/> “visibility_o”:[1 if c&lt;=threshold else 0<br/> for c in master_f[“visibility_o”]]}).set_index(“datetime”)</strong></span></pre><p id="618f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上一篇文章(查看此<a class="ae jd" rel="noopener" href="/@robinat539/improving-meteorological-and-ocean-models-with-machine-learning-part-2-applying-deep-learning-to-239883b4815e">链接</a>)中，我们知道了可变能见度的模型预测。我们指定能见度小于1000米为1，否则为0。我们对比了气象站的真实能见度。结果是:</p><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es ju"><img src="../Images/8693a20a467d8a6ac88a3e5e512e1c9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zlNZlwyyEdjnoG50RLDy7w.jpeg"/></div></div></figure><p id="2e0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">f1分数0.23似乎不是一个很难打败的分数！</p><p id="96ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们必须将量表标准化，并将数据分为数据测试和数据训练。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="2417" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj"># Splitting the dataset into the Training set and Test set<br/>from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)<br/># Feature Scaling<br/>from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>x_train = sc.fit_transform(x_train)<br/>x_test = sc.transform(x_test)</strong></span></pre><p id="eb18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们定义LightGBM参数。我尝试了几种设置，最后，我找到了一组运行良好的设置。</p><p id="d8ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我阅读这篇<a class="ae jd" rel="noopener" href="/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc">文章</a>来帮助我找到最佳设置。参数是字典数据的代码是:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="129d" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj">import lightgbm as lgb<br/>d_train = lgb.Dataset(x_train, label=y_train)<br/>params = {}<br/>params[‘learning_rate’] = 0.001<br/>params[‘boosting_type’] = ‘gbdt’<br/>params[‘objective’] = ‘binary’<br/>params[‘metric’] = ‘binary_logloss’<br/>params[‘sub_feature’] = 0.5<br/>params[‘num_leaves’] = 1000<br/>params[‘min_data’] = 2000<br/>params[‘max_depth’] = 40<br/>clf = lgb.train(params, d_train, 10000)</strong></span></pre><p id="c2fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们得到分类器“clf”并测试它:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="5d65" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj">#Prediction dealing with skewed data<br/>y_pred=clf.predict(x_test)**(1/3)<br/>result=pd.DataFrame({“y_pred”:y_pred, “y_test”:y_test.values.reshape(1,-1)[0]})<br/>pd.DataFrame({“y_pred test==1”:result[“y_pred”][result.y_test==1],<br/> “y_pred test==0”:result[“y_pred”][result.y_test==0]}).plot(kind=”kde”,figsize=(15,15),grid=True)</strong></span></pre><p id="48a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果，这张漂亮的照片:</p><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kc"><img src="../Images/16cd960899e1873a079b9b43ba175fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PXHjzo6tXjT2AUf4AMFnxA.png"/></div></div></figure><p id="75a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">黄线是y_test为0时的密度曲线。蓝线是y_test为1时的密度曲线。我们的目标是找到一个低于它的阈值，LightGBM算法的结果将是0(能见度在1000米以上)，高于它，结果将是1(能见度小于1000米)。完美的结果将是当两个情节完全分开。也许另一个情节可以帮助我们:</p><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kd"><img src="../Images/e68a9b6ee491d97c54b622562bbaba15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pWEkUAxsxCVqzscvyQ7Vxw.png"/></div></div></figure><p id="a7d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要获得此图，请将上面代码中的“kde”替换为“box”。我找到一个阈值(0.6)，使能见度小于1000米时的参数f1最大化。代码是:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="ed69" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj">from sklearn.metrics import confusion_matrix ,classification_report <br/>#select threhold_nor<br/>threshold_nor=0.6<br/>y_pred_nor=[0 if c&lt;=threshold_nor else 1 for c in result.y_pred]<br/>target_names = [“&gt;”+str(threshold)+”m”,”&lt;=”+str(threshold)+”m” ]<br/>print(classification_report(y_test.values,y_pred_nor , target_names=target_names))<br/>print(“**** Confusion matrix ****”)<br/>print(confusion_matrix(y_test,y_pred_nor))</strong></span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es ke"><img src="../Images/6ce4a477c5d2a0b3aa6a737db6b4b7b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fnerOuecN94zF6jP92HXNA.jpeg"/></div></div></figure><p id="37bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以绘制ROC并计算AUC，以查看LightGBM算法的性能。代码可以是:</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="4a1c" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj">from sklearn.metrics import roc_curve, auc<br/>from sklearn import metrics<br/>#ROC model <br/>fpr, tpr, thresholds = metrics.roc_curve(y_test,y_pred)<br/>roc_auc = auc(fpr, tpr)<br/>plt.figure()<br/>lw = 2<br/>plt.plot(fpr, tpr, color=’darkorange’,<br/> lw=lw, label=’ROC curve (area = %0.2f)’ % roc_auc)<br/>plt.plot([0, 1], [0, 1], color=’navy’, lw=lw, linestyle=’ — ‘)<br/>plt.xlim([0.0, 1.0])<br/>plt.ylim([0.0, 1.05])<br/>plt.xlabel(‘False Positive Rate’)<br/>plt.ylabel(‘True Positive Rate’)<br/>plt.title(“ROC “)<br/>plt.legend(loc=”lower right”)<br/>plt.show()</strong></span></pre><p id="6110" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果是:</p><figure class="je jf jg jh fd jv er es paragraph-image"><div class="er es kf"><img src="../Images/f019f5c9cbe7cb8a97ff32cc79b0c712.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*8QCXGbTJsx1DIGoF4U868A.png"/></div></figure><p id="37e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结论和展望</p><p id="6936" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看来我们达到了我们的目标:获得比气象模型更好的结果。气象模型的f1值为0.23，LightGBM算法的f1值为0.41。应用交叉验证，不要只相信train_test_split库中的random_state=0，这将是一个很好的练习！在气象层面，我们可以尝试其他的能见度阈值。我鼓励其他读者将LightGBM应用于50、500、1000、5000米的阈值，并获得比气象模型更好的f1分数。来自气象模型的每个阈值的f1分数是:0、0.19、0.23(我们的情况)和0.25。点击<a class="ae jd" rel="noopener" href="/analytics-vidhya/improving-meteorological-and-ocean-models-with-machine-learning-part-2-applying-deep-learning-to-239883b4815e">此处</a>查看车型f1评分。</p><p id="0fcf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢大家！</p></div></div>    
</body>
</html>