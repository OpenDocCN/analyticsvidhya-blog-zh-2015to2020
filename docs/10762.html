<html>
<head>
<title>Linear Regression — Simple/Single — Multiple</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归—简单/单一—多重</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-simple-single-multiple-fb8a1a678168?source=collection_archive---------28-----------------------#2020-11-01">https://medium.com/analytics-vidhya/linear-regression-simple-single-multiple-fb8a1a678168?source=collection_archive---------28-----------------------#2020-11-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/54858801be16f761274651db69801118.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DJ7Ec6Ai3wyeWQIXJ5OK_Q.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">回归！</figcaption></figure><p id="faa4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当你开始学习机器学习时，你绝对会从线性回归算法开始，没有人会逃避或期待这一点，因为这一算法将是监督学习方法的第一个孩子。因为在这种情况下，数据集被标记，并且其中算法将明确地识别特征，并且通过找到最佳拟合或线从给定的数据集导出预测。</p><blockquote class="js jt ju"><p id="7c3f" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">让我们了解一下线性回归图的组成部分</p></blockquote><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es jz"><img src="../Images/1ca6e20fb1af635ae63a0c9589998cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*z_U4oyjKcUyD1HW_ry7kHg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">线性回归—组件</figcaption></figure><h2 id="6621" class="ke kf hi bd kg kh ki kj kk kl km kn ko jf kp kq kr jj ks kt ku jn kv kw kx ky bi translated">让我们从数学的角度来讨论线性回归。之前，如何使用机器学习模型。</h2><p id="4467" class="pw-post-body-paragraph iu iv hi iw b ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn ld jp jq jr hb bi translated">用简单的关系去类比<strong class="iw hj">距离-速度-时间</strong></p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es le"><img src="../Images/ddf1f137251042ce461db54a3e8e64ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*Po5JvFx95kcQcpN3O10-8A.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">时间、速度和距离的关系</figcaption></figure><p id="8a98" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">希望你能从下面的图片中很容易理解，什么是速度和距离之间的<strong class="iw hj">正关系</strong>和<strong class="iw hj">负关系</strong></p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/0cbc38895d54dea6465cf55a285488a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*6WM1VLq06gDQhsMRIchBtQ.png"/></div></figure><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/4b1c920a087e0ee536035f040d071eae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*alVDcGjKANCoMcmjpbjFeg.png"/></div></figure><p id="abd7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们来解决这个问题</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/6387c7a8c091acaa977ee2d69f0f3d00.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*6Ao-8O1AygdqPZXCEZTGwA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">已知资料</figcaption></figure><p id="981b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">找到斜率，然后截取？还记得你大学时代的数学<em class="jv">(工科数学 3) </em></p><p id="bf50" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">什么是从给定问题中得到的(<strong class="iw hj">斜率</strong>和 c ( <strong class="iw hj">截距)</strong></p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/785f78acbf14131a3621a468f0eefcf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/1*Y3mKyngFa9iiwPvaMfesTA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">斜率公式(米)</figcaption></figure><p id="3055" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">经过长时间的计算，我越来越不值钱了。</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es li"><img src="../Images/a1c89cc9ec72001c30afb8d726e3d39a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*nrxWmBBA5BJynAcBg8q-_A.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">计算</figcaption></figure><p id="1600" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果将您的值应用到斜率(m)的公式中。你会得到 m=0.4。因为我们已经应用了 m，x，Y 的值，那么我们可以计算出 c( <strong class="iw hj">截距)</strong></p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/93f332109aaebd3d18f7cc84bff8f7d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*Dhkzl4cbusFsaxNGIl99IA.png"/></div></figure><p id="1aaf" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，我们从上面的计算中知道了 m ( <strong class="iw hj">斜率</strong>)和 c ( <strong class="iw hj">截距)</strong>，接着我们得到了下面的方程，对于给定的 x 求解任意 Y</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/eb9280a097a7f488e37719be01ef026c.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*h6TpZ7jpNrooOiMg6JWqiA.png"/></div></figure><p id="02b3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">实际上，我们已经预测了值(Yp)</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/988d8cfb51705d0db322b5a60b07af60.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*gLBqiG8TwLGZgU8jpKznIA.png"/></div></figure><p id="5c49" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">y 预测值:通过应用导出值</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/951d5a7d02128e8ac1bfc32b9ef56e0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:260/format:webp/1*NCqebujeUAWljS5Ye6e9lQ.png"/></div></figure><p id="34bc" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们比较实际值和预测值</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/db10d2bf0dba8cba8f8ff660fe4b826b.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*ASQXOBSaJ2RiOXvAa7rMuQ.png"/></div></figure><p id="7831" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果你画这个图，你会得到下面的结果。</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/a5845bae5f28198289fdfc9d4c8b4258.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*mCUJMChYTDSo_bUw9Nk7pQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">实际值与预测值</figcaption></figure><p id="878e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下一个什么！😊。</p><p id="d9b4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">理解机器学习模型中线性回归的方法。</p><p id="47fc" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">线性回归是一种使用直线解释因变量(观察值或 Y 变量)和一个或多个解释变量(自变量或 Y 变量)之间关系的方法。</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/f07dc5be7fa9bd863165a9f2e2db96b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*5zcZ-b88aZ_SQ7OSkX5bNQ.png"/></div></figure><p id="056a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">同样，在线性回归下，我们有两种类型。</p><blockquote class="js jt ju"><p id="d878" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">1.单一/简单线性方程</p><p id="e4f6" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">2.多元线性回归</p></blockquote><p id="862a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">永远记住<strong class="iw hj"> <em class="jv">多元线性回归</em> </strong>模型在数据科学和加工学习空间中比简单模型更有发言权，因为预测分析总是依赖于多个因素。会讨论更多…..</p><blockquote class="js jt ju"><p id="76f9" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">让我们了解线性回归中的几个组成部分——图表</p></blockquote><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es li"><img src="../Images/1b13c2c884e44f724b4043745ab565f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*EUPxboFwHX_aCQkmtrWKkA.png"/></div></figure><p id="473f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">让我们从一元线性回归开始</strong></p><blockquote class="js jt ju"><p id="368b" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj"> 1。</strong> <strong class="iw hj">单/一元线性方程</strong></p><p id="a0f2" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">a.最常见的回归是简单/单一 LR，其中两个变量之间的线性关系</p><p id="e902" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj"><em class="hi"/></strong>因此称为<strong class="iw hj"> <em class="hi">预测变量</em> </strong>和<strong class="iw hj"> <em class="hi">响应变量。</em>T11】</strong></p><p id="9c05" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj"> <em class="hi"> c. </em> </strong>更进一步我们可以说两个变量之间的<strong class="iw hj"> <em class="hi">相关性。</em>T19】</strong></p><p id="4dba" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">d.涉及两(2)个变量，从属和独立范围各一个</p><p id="5d29" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">e.LR 模型是对因变量进行预测的最有价值和最常用的方法。</p><p id="af82" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">f.其中一个因变量被标记为 Y，另一个自变量被标记为 x，那么我们可以得到下面的方程，正如我们在学校和大学数学中所学的…</p><p id="6973" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated"><strong class="iw hj"> Y= mx + b(一元/简单线性方程)</strong></p></blockquote><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/a521361dcacaec9305edf967813538c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*mpzJp-59MwdIDoN8rfBEYg.png"/></div></figure><p id="2d1c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">样本代码</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/e595c3511cbf3f651956aad49d305733.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*fsmufrr8cXDTKObu724FhQ.png"/></div></figure><blockquote class="js jt ju"><p id="b433" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr hb bi translated">不浪费我们的时间…让我们跳到<strong class="iw hj"> <em class="hi">多元线性回归</em> </strong></p></blockquote><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/674550f84207911a9086ed199cc1f004.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*KV58flhU0qBF07vmJ2Fq4A.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd kg"> <em class="lt">多元线性回归</em> </strong></figcaption></figure><p id="049d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">其中因变量被标记为 Y，而另一组自变量被标记为 x1，x2…</p><p id="efc6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">y =β0+β1x1+β2 x2+βkxk+误差噪声</strong></p><p id="27ed" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如前所述，在现实世界的场景中，回归模型分析中有两个以上的变量。这就是所谓的<strong class="iw hj">、【多元线性回归】、</strong>或<strong class="iw hj">多元线性回归。</strong></p><p id="93b7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">区别是独立变量(x1，x2…)对预测变量(Y)的最高影响的评估。</p><p id="433d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">参考…葡萄酒质量数据集</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/e6f9493203a2eef956a4449d16a47af6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*9CtH82CHqqF5-OrL3SXqGw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">葡萄酒质量. csv</figcaption></figure><p id="2f6f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从给定数据集中选择特征</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/7d8ee457c878076a42b2f4462e891152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oJhuqxSb-SJRVgAcPZvEYA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">特征选择</figcaption></figure><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/611c645c2267a6f62c1c359f2c023727.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*GEL-PML5JKblEf5PvXTScg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">方程中的因变量和自变量是什么样的。</figcaption></figure><p id="c1bd" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在模型可以理解给定数据集中的 Y 和 X 引用是什么了。</p><p id="ba87" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因为 Y=mX+C 或者是单个或者是多个自变量。</p><p id="7f1c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Rest 是测试和训练分割，并在给定的微调数据集上应用算法。</p><p id="2032" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">记住一件事。以上计算由 Python 库负责。所以你不用担心！酷！:).但是在申请之前理解这些概念，对你解释和处理任何情况都会有很大的帮助。</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/45f2e4534f0693ea11cb13424198fd1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xWdKSZps5n9fUtXl6eTwmg.png"/></div></div></figure><p id="3fc7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="jv">将很快讨论更多关于因变量和自变量以及什么是</em>均方根误差<em class="jv">！</em></p><p id="fc0a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="jv">后会有期！感谢阅读。</em></p></div></div>    
</body>
</html>