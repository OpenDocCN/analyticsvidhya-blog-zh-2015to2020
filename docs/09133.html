<html>
<head>
<title>Ensemble Modelling- How to perform in python.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">整体建模-如何在 python 中执行？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ensemble-modelling-in-a-simple-way-386b6cbaf913?source=collection_archive---------11-----------------------#2020-08-26">https://medium.com/analytics-vidhya/ensemble-modelling-in-a-simple-way-386b6cbaf913?source=collection_archive---------11-----------------------#2020-08-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2b39d8625f9c504cde745290a4f3f562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IXx8X1_2V66Qodd4rJZ8WA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">集合模型-作者图片。</figcaption></figure><p id="1e99" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">嘿！这是 Shivani Parekh。我的这篇文章将讨论如何使用集成方法将不同的机器学习模型结合在一起，并提高模型的整体准确性。</p><p id="37d8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">什么是集合建模，我们为什么要使用它？</p><p id="bc19" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">集成建模是将两个或多个模型组合在一起，然后将结果合成为单个得分。单一模型可能会有偏差、高度可变性或不准确性，影响其分析结果的可靠性，因此集成模型可以用来改善所有这些。</p><p id="2151" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们将使用乳腺癌数据集，该数据集可在 https://www . ka ggle . com/merishna suwal/breast-cancer-prediction-dataset 找到</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jt"><img src="../Images/9d8d59d593250ae9e7eb73c5d8af3e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NvAFHvi-woHw10irL3nomw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">乳腺癌数据集概述</figcaption></figure><p id="61f6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">正如我们所看到的，在这个数据集中有 6 个特征，其中我们的目标特征是诊断。我们将预测女性是否患有乳腺癌。诊断有两个值，0 和 1。<br/> 0 表示没有乳腺癌，1 表示有乳腺癌。</p><p id="352d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，我们将从导入进行预测所需的重要库开始。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="a380" class="kd ke hi jz b fi kf kg l kh ki">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="d8a8" class="kd ke hi jz b fi kj kg l kh ki">from sklearn import model_selection</span><span id="2814" class="kd ke hi jz b fi kj kg l kh ki">from sklearn.linear_model import LogisticRegression<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.svm import SVC<br/>from sklearn.ensemble import VotingClassifier</span><span id="2d16" class="kd ke hi jz b fi kj kg l kh ki">from sklearn.metrics import classification_report , confusion_matrix ,accuracy_score</span></pre><p id="cb4a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">很好，我们正在使用 pandas(数据分析和操作工具)，numpy 来处理数组，matplotlib.pyplot 来绘制图形，sklearn(机器学习库-包含所有 ML 算法)，sklearn.metrics 模块包括得分函数、性能度量和成对度量以及距离计算。</p><p id="870d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，让我们使用 pandas 读取 csv 文件，并使用 pandas 的 head()方法显示文件的内容。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="a982" class="kd ke hi jz b fi kf kg l kh ki">dataset=pd.read_csv(“D:\\Breast_cancer_data.csv”)<br/>dataset.head()</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kk"><img src="../Images/1c9fbb55633aa1d4c281a3ca21156241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o5LMsck0OdRDdR6mM74OaA.png"/></div></div></figure><p id="4467" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，让我们通过使用 iloc 仅选择 X 中的前 5 列和可变目标中的目标(诊断),将目标特征从该数据帧中分离出来。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="f292" class="kd ke hi jz b fi kf kg l kh ki">X=dataset.iloc[:,0:5]<br/>print(X)<br/>target=dataset.iloc[:,5]<br/>print(target)</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kl"><img src="../Images/f8ade87fd53e18e57f39cd016257ffbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fR2YCGSrqSC9FsaFL7ElAA.png"/></div></div></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es km"><img src="../Images/b2ae716089a81c3903d77393f9dba7b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*5zoEFcagjsYrVldLUyrQHg.png"/></div></figure><p id="54e1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，使用 train_test_split()方法将数据集分成训练和测试。test_size 取分割值，这里是 20%，所以 80%是训练数据，20%是测试。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="5e81" class="kd ke hi jz b fi kf kg l kh ki">from sklearn.model_selection import train_test_split<br/>X_train, X_test, target_train, target_test = train_test_split(X, target, test_size = 0.20)</span></pre><p id="53b0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在我们将采用单个模型并预测其准确性。<br/>这里使用了 K-最近算法。n_neighbors 指定要使用的邻居数量。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="983e" class="kd ke hi jz b fi kf kg l kh ki">#creating empty lists<br/>estimators=[] #will store model names and its classifier instance.<br/>accuracys=[] #will store accuracy of each model.</span><span id="9257" class="kd ke hi jz b fi kj kg l kh ki">model1=KNeighborsClassifier(n_neighbors=3)</span><span id="0332" class="kd ke hi jz b fi kj kg l kh ki">#adding model1 to list, this step is performed for ensemble method.<br/>estimators.append((“KNN”,model1))</span><span id="7836" class="kd ke hi jz b fi kj kg l kh ki">model1.fit(X_train,target_train)</span><span id="fd9c" class="kd ke hi jz b fi kj kg l kh ki">target_pred1=model1.predict(X_test)</span><span id="34c3" class="kd ke hi jz b fi kj kg l kh ki">KNNacc=accuracy_score(target_test,target_pred1)<br/>print(“KNN acc:”,KNNacc)</span><span id="d5c7" class="kd ke hi jz b fi kj kg l kh ki">#adding accuracy of this model to list,this step is performed for data visualization.<br/>accuracys.append(KNNacc)</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/dc9807a0b9a747bf264ea5ca6ce30053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ullx-ziVhFiiowjn0X4TjQ.png"/></div></div></figure><p id="8697" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们可以看到，KNN 模型给出了 0.8508 的精度。</p><p id="d1a5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在 model1.fit(X_train，target_train)是做什么的？<br/>根据训练数据训练模型。<br/>model 1 . predict(X _ test)是做什么的？<br/>它对测试数据进行预测，这里是 X_test。</p><p id="a6ba" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">同样，我们将使用我们正在使用的其他两个模型，即 DecisionTreeClassifier()和 SVC()，对其他预测进行同样的操作。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="998a" class="kd ke hi jz b fi kf kg l kh ki">model2=DecisionTreeClassifier()<br/>estimators.append((“cart”,model2))<br/>model2.fit(X_train,target_train)<br/>target_pred2=model2.predict(X_test)<br/>Dtacc=accuracy_score(target_test,target_pred2)<br/>print(“Decision Tree acc:”,Dtacc)<br/>accuracys.append(Dtacc)</span><span id="4f45" class="kd ke hi jz b fi kj kg l kh ki">model3=SVC()<br/>estimators.append((“svm”,model3))<br/>model3.fit(X_train,target_train)<br/>target_pred3=model3.predict(X_test)<br/>SVMacc=accuracy_score(target_test,target_pred3)<br/>print(“SVM acc :”,SVMacc)<br/>accuracys.append(SVMacc)</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/96a63ded33ae32a0c6567b92e8eab17f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0usRyWEYPE-0A1Bxj41NzQ.png"/></div></div></figure><p id="188d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">决策树精度是. 8596，SVC 精度是. 8684。</p><p id="1f04" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，这是我们将在这里使用集成方法 VotingClassifier()的部分。这里将采用参数 estimators=estimators(因为列表名称相同)。让我们回想一下，估计器有 3 种模型，即 KNN，决策树，SVC。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="13d4" class="kd ke hi jz b fi kf kg l kh ki">ensemble=VotingClassifier(estimators)<br/>ec=ensemble.fit(X_train,target_train)<br/>target_pred=ec.predict(X_test)<br/>print(target_pred)</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/14f4f7abb88cff2251aee472929213ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aXg_iHZsaZhETv-3HDllow.png"/></div></div></figure><p id="e433" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在上面我们已经创建了一个单一的模型，该模型基于该类收到的最高多数的投票来预测输出类。</p><p id="43fa" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们以一种简单的方式看到预测值和实际值，这样我们就可以比较它。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="7dd0" class="kd ke hi jz b fi kf kg l kh ki">df=pd.DataFrame({‘Actual’:target_test, ‘Predicted’:target_pred})<br/>df.head(20)</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/feaf5074c5eb1bc1bae113609ac5749f.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*2MP4-kIXMTmsOZyu5Hq0Lg.png"/></div></figure><p id="3d4c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">使用 accuracy_score(target_test，target_pred)和混淆矩阵来检查集合的准确性，我们还可以使用分类报告来检查性能，该报告为我们提供了精确度、召回率、f1 分数和支持。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="c028" class="kd ke hi jz b fi kf kg l kh ki">ensem_acc=accuracy_score(target_test,target_pred)<br/>print(“Accuracy of ensemble model is :”,ensem_acc)<br/>print(confusion_matrix(target_test,target_pred))<br/>print(classification_report(target_test,target_pred))</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/f94128460ddb32c5111632685320d034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*GC1Apt1gk_ivGdfdgtTuIA.png"/></div></figure><p id="5f42" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以这里我们可以看到集合模型的精度是. 8771。明显比其他型号多。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="afe7" class="kd ke hi jz b fi kf kg l kh ki">print(“KNN acc:”,KNNacc)<br/>print(“Decision Tree acc:”,Dtacc)<br/>print(“SVM acc :”,SVMacc)<br/>print(“Ensemble acc:”,ensem_acc)</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/b6ea1578b1156210c67c1bbc1c074053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*QlPUS2qRBxsrZolwBjOmNg.png"/></div></figure><p id="e53b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这是完整的代码。</p><figure class="ju jv jw jx fd ij"><div class="bz dy l di"><div class="kt ku l"/></div></figure><p id="1c9c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以差不多就是这样了。在下一篇文章中，我将向您展示这个模型的可视化和准确性比较。</p><p id="3533" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我希望你喜欢我的文章😃。请欣赏我的努力，如果可能的话，请为我鼓掌👏👏。谢谢你。</p></div></div>    
</body>
</html>