<html>
<head>
<title>Let machine play some music</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让机器播放一些音乐</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/let-machine-play-some-music-1a86216df7a4?source=collection_archive---------32-----------------------#2020-05-03">https://medium.com/analytics-vidhya/let-machine-play-some-music-1a86216df7a4?source=collection_archive---------32-----------------------#2020-05-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e6ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着人工智能的进步，机器将能够播放音乐，这不是一个笑话。我不确定音乐会有情感和同情，而这可能很容易取代人类。无论如何，在这篇博客中，我将向你展示我们如何利用深度学习来创作音乐。当然，为了让它自己产生，你需要先教会它们。</p><p id="eda0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们需要对音乐的基本结构有所了解。如果我们以钢琴为例，即使是最业余的音乐家也会注意到的第一件事是一系列按键——一些黑色，一些白色——当敲击时会发出不同的声音或音符。这些音符的组合，被称为钢琴上的和弦，是至少三个音符一起演奏，有时在某些情况下会更多。歌曲是用调写的，也就是所谓的调号，这样你就可以从自己的根音开始。例如，c大调和弦是根音C(和弦的根音)，三度音程音E，五度音程音g。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/66d319047c46db4c326815568f5c22a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/0*xDP5PZwoPsKrR7dB.png"/></div></figure><p id="c9b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，为了教机器演奏音乐，我们需要将这些音符输入它的大脑。我们如何得到这些笔记？？？这是我们将要使用以MIDI格式下载的音乐的地方。MIDI是一种通信标准，允许数字音乐设备使用同一种语言。<strong class="ih hj"> MIDI </strong>是乐器数字接口的简称。这是一种允许计算机、乐器和其他硬件进行通信的协议。</p><p id="d7a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有一些我们将用于训练目的的钢琴曲的例子:【https://github.com/SciSharp/Keras.·T4】NET/tree/master/Examples/music generation/piano dataset</p><p id="0f02" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将把完整的代码分成3个部分:</p><ol class=""><li id="46ed" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated">数据准备</li><li id="5def" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc jr js jt ju bi translated">模特培训</li><li id="2f57" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc jr js jt ju bi translated">音乐一代</li></ol><p id="f94d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先在Visual Studio中创建一个新的控制台项目。将以下nuget包添加到您的项目中:</p><ol class=""><li id="d571" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated">喀拉斯。NET:<a class="ae jl" href="https://www.nuget.org/packages/Keras.NET" rel="noopener ugc nofollow" target="_blank">https://www.nuget.org/packages/Keras.NET</a></li><li id="c0ce" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc jr js jt ju bi translated">梅兰查尔。DryWetMidi:<a class="ae jl" href="https://www.nuget.org/packages/Melanchall.DryWetMidi" rel="noopener ugc nofollow" target="_blank">https://www.nuget.org/packages/Melanchall.DryWetMidi</a></li></ol><p id="b227" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Keras将用于建立深度学习模型，用于训练和预测下一个音符。而梅兰查尔。DryWetMidi用于数据准备和播放生成的音符。下载所有的midi文件并放在项目的PianoDataset文件夹中。创建一个新的C#类“WavenetMusicGeneration.cs”。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ka"><img src="../Images/231ad0fda4f66d5c26481ee94cdb0c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/0*d7I2zS7xDwyOTrtx.png"/></div></figure><h1 id="b0d7" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">数据准备</h1><p id="9d83" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">打开“WavenetMusicGeneration.cs”并添加以下字段。</p><pre class="je jf jg jh fd le lf lg lh aw li bi"><span id="f61f" class="lj kc hi lf b fi lk ll l lm ln">public class WavenetMusicGeneration<br/> {<br/>        static int no_of_timesteps = 32; //No. of notes to teach per step<br/>        static NDarray train_x = null; // Training notes set<br/>        static NDarray train_y = null; // Next note to play <br/>        static int output = 127; //Max number of notes a piano have<br/> }</span></pre><p id="0e30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要一个函数来读取MIDI文件并获取笔记列表。</p><pre class="je jf jg jh fd le lf lg lh aw li bi"><span id="7d4c" class="lj kc hi lf b fi lk ll l lm ln">private static Note[] ReadMidi(string file)<br/> {<br/>            Console.WriteLine("Loading music file: " + file);<br/>            var mf = MidiFile.Read(file);<br/>            return mf.GetNotes().ToArray();<br/>}</span></pre><p id="3b9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们要使用的下一个功能是读取这些下载的训练音乐文件并组合音符。现在这些音符是字符串格式的，所以我们将使用音符的数字版本，因为最后的机器理解数字。</p><pre class="je jf jg jh fd le lf lg lh aw li bi"><span id="e12e" class="lj kc hi lf b fi lk ll l lm ln">public static void PrepData()<br/>{<br/>            //notes array list declaration<br/>            List&lt;Note[]&gt; notes_array = new List&lt;Note[]&gt;();<br/><br/>            //Get all the file list<br/>            var files = Directory.GetFiles("./PianoDataset");<br/><br/>            //Loop through the files and read the notes, put them in the array<br/>            foreach (var file in files)<br/>            {<br/>                notes_array.Add(ReadMidi(file));<br/>            }<br/><br/>            //Show first 15 notes for the first music file<br/>             Console.WriteLine("Displaying first 15 notes of first music");<br/>            foreach (var n in notes_array[0].Take(15))<br/>            {<br/>                Console.Write(n.ToString() + " ");<br/>            }<br/><br/>            //Declare X and Y which will hold the training set<br/>            List&lt;float&gt; x = new List&lt;float&gt;();<br/>            List&lt;float&gt; y = new List&lt;float&gt;();<br/>           <br/>            //Loop through the notes and prepare X and Y set.<br/>            foreach (var notes in notes_array)<br/>            {<br/>                for (int i = 0; i &lt; notes.Length - no_of_timesteps; i++)<br/>                {<br/>                    var input = notes.Skip(i).Take(no_of_timesteps).Select(x =&gt; Convert.ToSingle(x.NoteNumber)).ToArray();<br/>                    var output = Convert.ToSingle(notes[i + no_of_timesteps].NoteNumber);<br/>                    x.AddRange(input);<br/>                    y.Add(output);<br/>                }<br/>            }<br/><br/>            // Finally convert them to numpy array format for neural network training.<br/>            train_x = np.array(x.ToArray(), dtype: np.float32).reshape(-1, 32);<br/>            train_y = np.array(y.ToArray(), dtype: np.float32);<br/>}</span></pre><p id="f4e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准备功能的输出:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/9e55deade8075488c0f360457f0e67eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/0*EZZd_GopdrschK53.png"/></div></figure><h1 id="1abb" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">教模特</h1><p id="5ca7" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">现在到了真正的部分，建立一个大脑的小部分，并教他们音乐。我们将使用WaveNet架构的变体(更简单的版本)。WaveNet是一个用于生成原始音频的深度神经网络。它是由伦敦人工智能公司DeepMind的研究人员创造的。我们要重用架构生成音乐:)。在继续下一步之前，你可以谷歌一下WaveNet的更多信息。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es lp"><img src="../Images/df2b010a913ee407698d057253def5d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2zY-FOwlvwTeqaoN.png"/></div></div></figure><p id="c2f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是构建模型并使用之前准备的数据集对其进行训练的代码。</p><pre class="je jf jg jh fd le lf lg lh aw li bi"><span id="1981" class="lj kc hi lf b fi lk ll l lm ln">public static void BuildAndTrain()<br/>{<br/>            //Model to hold the neural network architecture which in this case is WaveNet<br/>            var model = new Sequential();<br/>            // Starts with embedding layer<br/>            model.Add(new Embedding(output, 100, input_length: 32));<br/><br/>            model.Add(new Conv1D(64, 3, padding: "causal", activation: "tanh"));<br/>            model.Add(new Dropout(0.2));<br/>            model.Add(new MaxPooling1D(2));<br/><br/>            model.Add(new Conv1D(128, 3, activation: "relu", dilation_rate: 2, padding: "causal"));<br/>            model.Add(new Dropout(0.2));<br/>            model.Add(new MaxPooling1D(2));<br/><br/>            model.Add(new Conv1D(256, 3, activation: "relu", dilation_rate: 4, padding: "causal"));<br/>            model.Add(new Dropout(0.2));<br/>            model.Add(new MaxPooling1D(2));<br/><br/>            //model.Add(new Conv1D(256, 5, activation: "relu"));<br/>            model.Add(new GlobalMaxPooling1D());<br/><br/>            model.Add(new Dense(256, activation: "relu"));<br/>            model.Add(new Dense(output, activation: "softmax"));<br/><br/>            // Compile with Adam optimizer<br/>            model.Compile(loss: "sparse_categorical_crossentropy", optimizer: new Adam());<br/>            model.Summary();<br/><br/>            // Callback to store the best trained model<br/>            var mc = new ModelCheckpoint("best_model.h5", monitor: "val_loss", mode: "min", save_best_only: true, verbose: 1);<br/><br/>            //Method to actually train the model for 100 iteration<br/>            var history = model.Fit(train_x, train_y, batch_size: 32, epochs: 100, validation_split: 0.25f, verbose: 1, callbacks: new Callback[] { mc });<br/><br/>            // Save the final trained model which we are going to use for prediction<br/>            model.Save("last_epoch.h5");<br/>}</span></pre><p id="e2ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练过程有点耗时，但如果你给了GPU，那么它会快10倍。培训产出如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es lu"><img src="../Images/308cbee4607c507960a05297d4ebf439.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xoeF2aRgSnzqrKt-.png"/></div></div></figure><h1 id="1fca" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">创作新音乐</h1><p id="1778" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">现在有趣的部分来了，我们将使用这个模型生成音符。使用下面的功能生成新的音符</p><pre class="je jf jg jh fd le lf lg lh aw li bi"><span id="db19" class="lj kc hi lf b fi lk ll l lm ln">public static List&lt;int&gt; GenerateNewMusic(int n = 20)<br/>{<br/>            //Load the trained model<br/>            var model = Model.LoadModel("last_epoch.h5");<br/>            //Get a random 32 notes from the train set which we will use to get new notes<br/>            var ind = np.random.randint(0, train_x.shape[0]);<br/>            var random_music  = train_x[ind];<br/><br/>            //Build the prediction variable with sample 32 notes<br/>            List&lt;float&gt; predictions = new List&lt;float&gt;();<br/>            predictions.AddRange(random_music.GetData&lt;float&gt;());<br/><br/>            //Loop through N times which means N new notes, by default its 20<br/>            for (int i = 0; i &lt; n; i++)<br/>            {<br/>                // Reshape to model adaptaed shape<br/>                random_music = random_music.reshape(1, no_of_timesteps);<br/>                //Predict the next best note to be played<br/>                var prob = model.Predict(random_music)[0];<br/>                var y_pred = np.argmax(prob, axis: 0);<br/><br/>                //Add the prediction and pick the last 32 to predict the next music note<br/>                predictions.Add(y_pred.asscalar&lt;float&gt;());<br/>                random_music = np.array(predictions.Skip(i + 1).ToArray());<br/>            }<br/><br/>            //Finally skip the first 32 sample notes and return the rest N new predicted notes.<br/>            return predictions.Skip(no_of_timesteps - 1).Select(x=&gt;(int)x).ToList();<br/>}</span></pre><p id="a67c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">播放这些音符的功能。我们使用计算机上的默认播放设备，并发送将产生钢琴声音的MidiEvent。</p><pre class="je jf jg jh fd le lf lg lh aw li bi"><span id="534a" class="lj kc hi lf b fi lk ll l lm ln">private static void PlayNotes(List&lt;int&gt; notes)<br/>{<br/>            List&lt;List&lt;MidiEvent&gt;&gt; musicNotes = new List&lt;List&lt;MidiEvent&gt;&gt;();<br/>            var playbackDevice = OutputDevice.GetAll().FirstOrDefault();<br/>            foreach (var note in notes)<br/>            {<br/>                Note n = new Note(SevenBitNumber.Parse(note.ToString()));<br/>                Console.Write(n + " ");<br/>                playbackDevice.SendEvent(new NoteOffEvent(SevenBitNumber.Parse(note.ToString()), SevenBitNumber.MaxValue));<br/>            }<br/>}</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/cd64e562214bb74c8252ae7aae62ef81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*EJ_bQ-LEHmBH0UNW0YJzMw.png"/></div></figure><p id="678f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">调用上述所有函数的最终主函数:</p><pre class="je jf jg jh fd le lf lg lh aw li bi"><span id="85fe" class="lj kc hi lf b fi lk ll l lm ln">static void Main(string[] args)<br/>{<br/>            WavenetMusicGeneration.PrepData();<br/>            WavenetMusicGeneration.BuildAndTrain();<br/>            var notes = WavenetMusicGeneration.GenerateNewMusic(20);<br/>            Console.WriteLine("\n\nPlaying auto generated music....\n");<br/>            PlayNotes(notes);<br/>}</span></pre><p id="50bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">太棒了，对吧？但是你的学习不止于此。有很多方法可以进一步提高模型的性能:</p><ul class=""><li id="4f80" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc lw js jt ju bi translated">我们可以微调预先训练好的模型来构建一个健壮的系统</li><li id="2a07" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc lw js jt ju bi translated">尽可能多地收集训练数据，因为深度学习模型在较大的数据集上表现良好</li></ul><p id="bf88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">示例代码:<a class="ae jl" href="https://github.com/SciSharp/Keras.NET/tree/master/Examples/MusicGeneration" rel="noopener ugc nofollow" target="_blank">https://github.com/SciSharp/Keras.NET/tree/master/Examples/music generation</a></p></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><p id="cb4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="me">原载于2020年5月3日</em><a class="ae jl" href="https://www.tech-quantum.com/let-machine-play-some-music/" rel="noopener ugc nofollow" target="_blank"><em class="me">【https://www.tech-quantum.com】</em></a><em class="me">。</em></p></div></div>    
</body>
</html>