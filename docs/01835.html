<html>
<head>
<title>Semantic segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">语义分割</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/semantic-segmentation-420b9671f28b?source=collection_archive---------10-----------------------#2019-11-16">https://medium.com/analytics-vidhya/semantic-segmentation-420b9671f28b?source=collection_archive---------10-----------------------#2019-11-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="695f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">什么是语义切分？给图像中的每一个像素分配一个唯一的标签(或类别)的任务，这可以被认为是一个密集分类问题。</p><p id="b3f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">语义分割的应用:</p><p id="0358" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">-自动驾驶<br/> -医学影像分析</p><h1 id="d4a3" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">通用深度学习架构</h1><h2 id="6051" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">AlexNet</h2><blockquote class="kp kq kr"><p id="9d9f" class="if ig ks ih b ii ij ik il im in io ip kt ir is it ku iv iw ix kv iz ja jb jc hb bi translated">建筑的亮点</p></blockquote><ol class=""><li id="f5d3" class="kw kx hi ih b ii ij im in iq ky iu kz iy la jc lb lc ld le bi translated">用Relu代替Tanh因为ReLU对所有正值都是线性的(恒等式)，对所有负值都是零。这意味着:</li></ol><ul class=""><li id="0876" class="kw kx hi ih b ii ij im in iq ky iu kz iy la jc lf lc ld le bi translated">计算起来很便宜，因为没有复杂的数学。因此，该模型可以花费更少的时间来训练或运行。</li><li id="a5b5" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">它收敛得更快。线性意味着当<em class="ks"> x </em>变大时，斜率不会趋于平稳或“饱和”。它没有像sigmoid或tanh那样的其他激活函数所遭受的消失梯度问题。</li></ul><p id="629f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.用辍学生代替传统的规训者，如L1，L2</p><h2 id="35ae" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">建筑</h2><p id="aae5" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">它有5个回旋层和3个全连接层。Relu应用于每个卷积层和完全连接层之后。输入尺寸应为227*227</p><h2 id="d892" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">雷斯内特</h2><p id="ba87" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">ResNet的核心思想是引入所谓的“身份快捷连接”，跳过一层或多层，如下图所示:</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es lq"><img src="../Images/d3bdab3196349de1a84025cc4fe9ab69.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/0*ASzg_zrS4Mc_jVbh.png"/></div></div></figure><p id="b32a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如您所看到的，ResNet架构引入的新思想是允许来自先前步骤的信息的跳过连接，这与LSTMs在将先前状态信息添加到后面的层上的思想相同</p><h2 id="9c96" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">雷尼特</h2><p id="3ffc" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">网络背后的想法是使用4个RNN层，而不是卷积层+最大池层，这4个rnn最终将水平和垂直扫描输入图像，如图所示。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mc"><img src="../Images/539f3b0aefc2385525c6f1cfeeb78e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*c30t1zuP4I3JGxdTxnTUdw.png"/></div></figure><p id="3336" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我解释一下这种架构背后的直觉，我们将输入图像划分为不重叠的面片，例如Pi，j是第I行和第j列的面片，然后我们使用前两层RNNs，让一层从上到下获取展平的面片(列表),另一层从下到上获取，因此我们现在有两层的两个输出，我们将它们称为隐藏状态Vf和Vr，我们将它们连接起来，以获得第一个合成特征图。接下来，我们用来自垂直扫描的先前特征图的输入对水平扫描(左右)做同样的事情，产生我们的输入图像的输出特征图。</p><h2 id="24fa" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">深度图</h2><p id="97c1" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">深度图是一种图像，它包含从给定视点看物体表面之间距离的信息。深度图是从源图像创建的，并且通常是灰度级格式。</p><p id="5e76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当与源图像合并时，创建3D图像。看起来好像原始源图像有深度。</p><p id="29de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">遵循先前概念的数据集示例</strong></p><div class="md me ez fb mf mg"><a href="https://davischallenge.org/index.html" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">戴维斯:密集注释的视频分割</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">@article{Caelles_arXiv_2019，author = { Sergi Caelles and Jordi Pont-Tuset and Federico Perazzi and Alberto Montes and…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">davischallenge.org</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu ma mg"/></div></div></a></div><h2 id="bd1b" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">语义分割方法综述</h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mv"><img src="../Images/31801f88e329f94973cfda908d3fcda5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VZHDSi49jTkRtR6ZYvx88Q.png"/></div></div></figure><p id="c2f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大多数方法使用网络进行分类，例如VGG，并且只移除最终完全连接的层，并用卷积层替换它们，以输出低分辨率图像。问题在于学习解码或映射这些低分辨率图像到像素预测的分割。这部分称为解码器，通常是这类架构的分歧点。</p><h2 id="329c" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">SegNet</h2><p id="7a53" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">查看这个有趣的教程！</p><div class="md me ez fb mf mg"><a href="https://towardsdatascience.com/review-segnet-semantic-segmentation-e66f2e30fb96" rel="noopener follow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">复习:SegNet(语义分割)</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">编码器解码器架构使用最大池索引进行上采样，性能优于FCN、DeepLabv1和DeconvNet</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">towardsdatascience.com</p></div></div><div class="mp l"><div class="mw l mr ms mt mp mu ma mg"/></div></div></a></div><p id="f43c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SegNet执行的上采样与其他全卷积架构之间存在差异，我觉得在继续之前指出这一点很有意思。</p><p id="1d64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是SegNet如何通过用零填充空格来对特征图进行向上采样</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mx"><img src="../Images/ac9d9b1ed0c037ca14a42a7e4a9858e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/0*VgZ9_0ZQ8-PgmN9u.png"/></div></figure><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es my"><img src="../Images/81cf6ead26b28f92efa5a3321c01c6f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:24/0*PveQ8bKhV8Hvtrqo"/></div></figure><p id="8e49" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然其他完全卷积架构的上采样方式略有不同，但我发现本文可以准确地解释这一点。</p><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">转置卷积上采样</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">如果你听说过转置卷积，并对它的实际含义感到困惑，这篇文章是为…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="mz l mr ms mt mp mu ma mg"/></div></div></a></div><p id="c02e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想建造你自己的FCN，请跟随这个笔记本，</p><div class="md me ez fb mf mg"><a href="https://github.com/Mohamed209/Deep_Learning_Notes/blob/master/FCN/%20Fully%20Convolutional%20Networks%20for%20Semantic%20Segmentation%20in%20Keras.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">Mohamed 209/深度学习_笔记</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">github.com</p></div></div><div class="mp l"><div class="na l mr ms mt mp mu ma mg"/></div></div></a></div><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es nb"><img src="../Images/8273337e8efd6a2bbbcf0d4da8096ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:54/0*yTxJO8sRfRk1HTaA"/></div></figure><blockquote class="kp kq kr"><p id="fab7" class="if ig ks ih b ii ij ik il im in io ip kt ir is it ku iv iw ix kv iz ja jb jc hb bi translated">在达到最先进的模型之前的几个概念</p></blockquote><h1 id="969f" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">条件随机场</h1><p id="e392" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">生成模型与判别模型？</p><p id="1f65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">事实上，他们最终都预测了给定样本P(类别|特征)的某个类别，但在简单的英语生成模式中，为他们看到的每个类别创建一个分布，然后查看哪个分布与给定的新样本最匹配！到目前为止，判别模型是类之间的决策边界，说到概率，这两个模型的区别是生成模型学习联合概率p(x，y)让x是特征，y是类，因此我们在这里计算事件x和y一起发生的概率，其中x和y彼此独立。判别模型学习条件概率p(y/x ),其中这两个事件相互依赖，因此实际上我们是在已知事件x发生的情况下计算事件y的概率。</p><h1 id="7c64" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">在数学方面，</h1><p id="5112" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">‌Training分类器包括估计f: X -&gt; Y，或P(Y|X)</p><h1 id="87f4" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">生成分类器</h1><ul class=""><li id="d420" class="kw kx hi ih b ii ll im lm iq nc iu nd iy ne jc lf lc ld le bi translated">假设<strong class="ih hj"> P(Y)，P(X|Y) </strong>的某种函数形式</li><li id="fbbe" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">直接从训练数据估计<strong class="ih hj"> P(X|Y)，P(Y) </strong>的参数</li><li id="07dc" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">使用贝叶斯规则计算<strong class="ih hj"> P(Y |X) </strong></li></ul><h1 id="2e79" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">区别性分类器</h1><ul class=""><li id="0113" class="kw kx hi ih b ii ll im lm iq nc iu nd iy ne jc lf lc ld le bi translated">假设<strong class="ih hj"> P(Y|X) </strong>的某种函数形式</li><li id="e5a5" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">直接从训练数据估计<strong class="ih hj"> P(Y|X) </strong>的参数</li></ul><h1 id="9b56" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">示例:</h1><h1 id="f639" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">生成分类器</h1><ul class=""><li id="58eb" class="kw kx hi ih b ii ll im lm iq nc iu nd iy ne jc lf lc ld le bi translated">‌naïve·贝叶斯</li><li id="67bb" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">贝叶斯网络</li><li id="ae8f" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">马尔可夫随机场</li><li id="9173" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">‌Hidden马尔可夫模型(HMM)</li></ul><h1 id="735b" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">区别性分类器</h1><ul class=""><li id="a1b0" class="kw kx hi ih b ii ll im lm iq nc iu nd iy ne jc lf lc ld le bi translated">‌Logistic回归</li><li id="d73b" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">标量向量机</li><li id="f482" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">‌Traditional神经网络</li><li id="2232" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">‌Nearest邻居</li><li id="070d" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated">条件随机场</li></ul><p id="a39c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以回到我们的主模型<strong class="ih hj"> CRF。</strong></p><h2 id="9816" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">这是抽象的分布函数:</h2><blockquote class="kp kq kr"><p id="6e46" class="if ig ks ih b ii ij ik il im in io ip kt ir is it ku iv iw ix kv iz ja jb jc hb bi translated">crf = argmax(y) P(y/x)</p></blockquote><p id="68f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们深入这个等式背后的细节，x特征、y标签、λ是要被调整以实现x和y之间的最佳corr的权重。</p><p id="4a83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">p(x，y，lambda) = exp(对<strong class="ih hj"> i </strong>的求和(lambda * f(x，y(i-1)，y(i)))</p><p id="699d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在exp之后，我们需要通过Z(x)归一化值，其中</p><p id="6a87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">z(x) =对<strong class="ih hj"> y </strong>的求和(λ* f(x，y(i-1)，y(i))</p><p id="b974" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以最终分布会是p(x，y，lambda)/z(x)。</p><p id="6e75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更新lambda的函数会是这样的。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es nf"><img src="../Images/8c8ba92edcb86831f2b7faad9324062f.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/0*FYUNOMVbAqzYLgsP.gif"/></div></figure><h1 id="b3ff" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">扩张的回旋</h1><p id="1c53" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">膨胀卷积为卷积层引入了另一个参数，称为<strong class="ih hj">膨胀率</strong>。这定义了内核中值之间的间距。膨胀率为2的3×3内核将具有与5×5内核相同的视野，同时仅使用9个参数并用零填充其间的值。想象一下，取一个5x5的内核，每隔一行删除一列。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es ng"><img src="../Images/9854bc038537c869443812c4abeb7c5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/0*SeLwYtRTGkBK9pR0.gif"/></div></figure><p id="fc09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我们熟悉正常卷积右让点正常卷积和扩张卷积的函数之间的差异，</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es nh"><img src="../Images/771c45d5cc215e7ed95bd1794158ebcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/0*tF1lvg54ocuQyUS1.png"/></div><figcaption class="ni nj et er es nk nl bd b be z dx translated"><strong class="bd jf">标准卷积(左)，扩张卷积(右)</strong></figcaption></figure><p id="2e94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">f这里是框架，k代表核，l代表每个核值之间的距离。这种方法用于上采样以及前面讨论的方法，这种方法相对于其他方法的优势在于，它不改变内核中的值或其位置，它只是在内核的非零值之间放置零。</p><h1 id="78b5" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">DeepLab v1</h1><p id="681a" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">体系结构</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es nm"><img src="../Images/4468c8f5660cc6a683b2cf7fdcf41706.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/0*_V3TbZy2wvIEgPlb"/></div></figure><p id="6ac3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如图所示，它使用FCNs进行下采样，然后使用阿特鲁卷积(扩张卷积)进行上采样，然后进行双线性插值，这是一种使用四个最近像元中心的加权平均值的采样。输入像元中心越靠近输出像元中心，其值对输出像元值的影响就越大。这意味着输出值可能不同于最接近的输入值，但始终在与输入值相同的范围内，建议使用连续值。最后一步是通过完全连接的CRFs层对结果像素进行分类。</p><h2 id="d3ad" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">这种模式应对的挑战</h2><p id="1daf" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated"><strong class="ih hj"> <em class="ks">挑战1:降低特征分辨率</em> </strong></p><p id="2987" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于DCNN中的多重池化和下采样(“步长”)，空间分辨率显著降低。它们从DCNNs的最后几个最大池层中移除了下采样算子，而是在后续卷积层中对滤波器(atrous)进行上采样，从而以更高的采样率计算特征图。</p><p id="f8e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ks">挑战2:由于DCNN不变性导致定位精度降低</em> </strong></p><p id="a3dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以便通过采用全连通条件随机场(CRF)来捕捉精细细节。CRF势结合了平滑项，使相似像素之间的标签一致性最大化，并且可以集成更精细的项来模拟对象类之间的上下文关系。下图说明了在CRF的几次迭代后分割图的改进。</p><h1 id="4e25" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">关于我们</h1><p id="1157" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">我们是一个由4名精力充沛的机器学习工程师组成的研究团队，这项工作是我们4人的共同协作，你可以称我们为研究极客，瘸子？？哦，可能是因为是我选择了它(奥马尔)，无论如何，如果你发现这个博客有任何帮助，请按几次拍手按钮，:D，你也可以联系我们:</p><p id="3737" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">奥马尔/<a class="ae nn" href="https://www.linkedin.com/in/omar-ayman-6498529b/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/omar-ayman-6498529b/</a></p><p id="7abc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">米（meter的缩写））https://www.linkedin.com/in/mohamedmosad/莫萨德/ <a class="ae nn" href="https://www.linkedin.com/in/mohamedmosad/" rel="noopener ugc nofollow" target="_blank"/></p><p id="6a04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">A.https://www.linkedin.com/in/ahmed-gamal97/贾马尔/ <a class="ae nn" href="https://www.linkedin.com/in/ahmed-gamal97/" rel="noopener ugc nofollow" target="_blank"/></p><p id="7b3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">米（meter的缩写））https://www.linkedin.com/in/mostafa-elmenbawy/</p><h1 id="0ff9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">信用</h1><ul class=""><li id="96b1" class="kw kx hi ih b ii ll im lm iq nc iu nd iy ne jc lf lc ld le bi translated"><a class="ae nn" rel="noopener" href="/@mlengineer/generative-and-discriminative-models-af5637a66a3">https://medium . com/@ m engineer/generative-and-discriminal-models-af 5637 a66a 3</a></li><li id="77af" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated"><a class="ae nn" href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d" rel="noopener" target="_blank">https://towards data science . com/types-of-convolutions-in-deep-learning-717013397 f4d</a></li><li id="d4cf" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated"><a class="ae nn" rel="noopener" href="/ml2vec/overview-of-conditional-random-fields-68a2a20fa541">https://medium . com/ml 2 vec/overview-of-conditional-random-fields-68 a2a 20 fa 541</a></li><li id="c68b" class="kw kx hi ih b ii lg im lh iq li iu lj iy lk jc lf lc ld le bi translated"><a class="ae nn" href="https://towardsdatascience.com/the-evolution-of-deeplab-for-semantic-segmentation-95082b025571" rel="noopener" target="_blank">https://towards data science . com/the-evolution-of-deep lab-for-semantic-segmentation-95082 b 025571</a></li></ul></div></div>    
</body>
</html>