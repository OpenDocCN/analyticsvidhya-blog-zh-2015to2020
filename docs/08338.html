<html>
<head>
<title>Understanding Logistic Regression!!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解逻辑回归！！！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-logistic-regression-b3c672deac04?source=collection_archive---------1-----------------------#2020-07-26">https://medium.com/analytics-vidhya/understanding-logistic-regression-b3c672deac04?source=collection_archive---------1-----------------------#2020-07-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/6105a082cf1fe1fe4e5578f67ae7589c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*3FgpptTWzpd2RLgKbV-HvA.jpeg"/></div></div></figure><p id="e646" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi jo translated">在我之前的博客中，我试图解释线性回归及其工作原理。让我们看看为什么逻辑回归是需要理解的重要话题之一。<br/>这里是我之前关于线性回归的文章 的<a class="ae jx" rel="noopener" href="/analytics-vidhya/understanding-the-linear-regression-808c1f6941c0"> <strong class="is hj">链接，以防你错过。</strong></a></p><h1 id="7538" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">内容</h1><ol class=""><li id="fac5" class="kw kx hi is b it ky ix kz jb la jf lb jj lc jn ld le lf lg bi translated">什么是逻辑回归？</li><li id="b80f" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">逻辑回归的类型。</li><li id="3b62" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">逻辑回归的假设。</li><li id="f4f5" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">为什么不用线性回归进行分类？</li><li id="70ef" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">逻辑模型。</li><li id="56a8" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">系数的解释。</li><li id="75ea" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">优势比和对数</li><li id="645f" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">决策边界。</li><li id="7539" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">逻辑回归的成本函数。</li><li id="bf86" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">逻辑回归中的梯度下降。</li><li id="d67f" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">评估逻辑回归模型。</li></ol><blockquote class="lm"><p id="6be6" class="ln lo hi bd lp lq lr ls lt lu lv jn dx translated">我们开始吧</p></blockquote><figure class="lx ly lz ma mb ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/53af5eed8096e1a6d9c22fe541a06e60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i49JjiXdPmRNEL0g"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">照片由<a class="ae jx" href="https://unsplash.com/@dose?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">剂量介质</a>在<a class="ae jx" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="6834" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">什么是逻辑回归？</h1><ul class=""><li id="bc29" class="kw kx hi is b it ky ix kz jb la jf lb jj lc jn mg le lf lg bi translated">逻辑回归是一种监督统计技术，用于发现因变量(变量中存在的类别)的概率。</li><li id="73c7" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn mg le lf lg bi translated">逻辑回归使用名为<strong class="is hj"> <em class="mh"> logit函数</em> </strong> <em class="mh">的函数，通过预测发生的概率或机会，帮助</em>推导因变量和自变量之间的关系。</li><li id="8431" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn mg le lf lg bi translated">逻辑函数(也称为<em class="mh"> sigmoid函数</em>)将概率转换成可进一步用于预测的二进制值。</li></ul><h1 id="a7f5" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated"><strong class="ak">逻辑回归的类型:</strong></h1><ol class=""><li id="ce7d" class="kw kx hi is b it ky ix kz jb la jf lb jj lc jn ld le lf lg bi translated"><strong class="is hj">二元逻辑回归:</strong> <br/>因变量只有两2种可能的结果/类别。<br/>举例——男性或女性。</li><li id="6a5e" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj">多项Logistic回归:</strong> <br/>因变量只有两个3或更多可能的结果/类，没有排序。<br/>例:预测食品质量。(好的，伟大的，坏的)。</li><li id="fe7c" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj">有序逻辑回归:</strong> <br/>因变量只有两个3或更多可能的结果/类，具有有序性。示例:星级从1到5</li></ol><blockquote class="mi mj mk"><p id="60ea" class="iq ir mh is b it iu iv iw ix iy iz ja ml jc jd je mm jg jh ji mn jk jl jm jn hb bi translated">现在不同类型的逻辑回归已经清楚了，让我们来看看逻辑回归的假设。在构建模型时，应该记住这些假设。</p></blockquote><h1 id="dd02" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">逻辑回归的假设:</h1><p id="3e8a" class="pw-post-body-paragraph iq ir hi is b it ky iv iw ix kz iz ja jb mo jd je jf mp jh ji jj mq jl jm jn hb bi translated">尽管Logistic回归属于线性模型，但它并没有对线性回归模型做任何假设，比如:<br/> →它不要求因变量和自变量之间存在线性关系。<br/> →误差项不需要正态分布。<br/> →不需要同质性。</p><p id="78a8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，它几乎没有自己的假设:</p><ol class=""><li id="30de" class="kw kx hi is b it iu ix iy jb mr jf ms jj mt jn ld le lf lg bi translated">它假设自变量之间的多重共线性最小，或者没有多重共线性。<br/> 检查多重共线性的预见性的最佳方法是执行VIF(方差膨胀因子)。</li><li id="3bdd" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj">它假设自变量与赔率的对数线性相关。<br/> </strong>可用<strong class="is hj"> </strong>箱-台试验检查。</li><li id="f429" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj">为了更好的预测，它假设了一个大样本。</strong></li><li id="b4a6" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj">假设观测值相互独立。</strong></li><li id="4d34" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj">连续预测值(自变量)中没有影响值(异常值)。<br/></strong></li><li id="0ba2" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj">因变量为二元的两类逻辑回归，有序逻辑回归要求因变量有序。</strong></li></ol><blockquote class="mi mj mk"><p id="438a" class="iq ir mh is b it iu iv iw ix iy iz ja ml jc jd je mm jg jh ji mn jk jl jm jn hb bi translated"><strong class="is hj">可能还会出现一个问题，除了使用逻辑回归，我们为什么不能简单地使用线性回归来解决分类问题，下面让我们看看为什么我们不应该使用线性回归来解决分类问题。</strong></p></blockquote><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/27e6e0b550f8eb5788807ff36cdbc45b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*89mnJCb9tk3aD2jb"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">照片由<a class="ae jx" href="https://unsplash.com/@emilymorter?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">艾米丽·莫特</a>在<a class="ae jx" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="8203" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">为什么不用线性回归进行分类？</h1><p id="6c80" class="pw-post-body-paragraph iq ir hi is b it ky iv iw ix kz iz ja jb mo jd je jf mp jh ji jj mq jl jm jn hb bi translated">正如我们引入逻辑回归来解决分类问题无论是二分类还是多分类问题一样，<strong class="is hj"> <em class="mh">但是为什么我们不能使用线性回归呢？</em> </strong></p><ol class=""><li id="3e19" class="kw kx hi is b it iu ix iy jb mr jf ms jj mt jn ld le lf lg bi translated">线性回归预测连续变量，如房价，线性回归的输出范围可以从负无穷大到正无穷大。</li><li id="983f" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">由于预测值不是概率值，而是类别的连续值，因此很难找到有助于区分类别的正确阈值。</li><li id="a88d" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">让我们假设您很幸运地找到了阈值，并为二元类问题找到了正确的阈值，但是如果问题是多类的，它将不会给出理想的预测。</li><li id="7816" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">在一个多类问题中，不能有n个类，现在每个类将被标记为从0到n。然而，他们将被迫在从属特征和独立特征之间建立某种关系。</li><li id="ae7c" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated">此外，应变量将被视为连续数字，最佳拟合线将通过点的平均值，给出可能低于0且可能超过4的连续值。</li></ol><h1 id="01b4" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated"><strong class="ak">逻辑斯谛模型</strong></h1><p id="b92b" class="pw-post-body-paragraph iq ir hi is b it ky iv iw ix kz iz ja jb mo jd je jf mp jh ji jj mq jl jm jn hb bi translated">上述所有问题都可以通过逻辑回归来解决。<br/>逻辑回归代替拟合最佳拟合线，压缩0和1之间的线性函数的输出。</p><figure class="mv mw mx my fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/23056677762b23279762b6b8b4bd8418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*xTwaKZZsIRek8jzrNWRPzQ.png"/></div></figure><p id="7bc4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在逻辑斯谛模型的公式中，<br/>当<strong class="is hj"> b0+b1X == 0 </strong>时，那么p将为0.5，<br/>同理，<strong class="is hj"> b0+b1X &gt; 0 </strong>，那么p将趋向于1，<br/>T8】B0+b1X&lt;0，那么p将趋向于0。</p><h1 id="82b0" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">系数的解释</h1><ul class=""><li id="bb07" class="kw kx hi is b it ky ix kz jb la jf lb jj lc jn mg le lf lg bi translated">权重的解释不同于线性回归，因为逻辑回归的输出概率在0和1之间。</li><li id="de91" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn mg le lf lg bi translated">斜率系数(b)不是p随X变化的变化率，现在斜率系数被解释为“对数概率”随X变化的变化率。</li></ul><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/b551d563c07cfcee84d9dd0605573804.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aPgytc42C1btLtB3YbFTQA.jpeg"/></div></div></figure><p id="35c8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解更多信息，请参考此<a class="ae jx" href="https://christophm.github.io/interpretable-ml-book/logistic.html" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="38ce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，让我们了解什么是对数概率。</p><h1 id="314c" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">优势比和对数</h1><p id="1f7c" class="pw-post-body-paragraph iq ir hi is b it ky iv iw ix kz iz ja jb mo jd je jf mp jh ji jj mq jl jm jn hb bi translated">比值比定义为有<strong class="is hj"> B </strong>时的比值与无<strong class="is hj"> B </strong>时的<strong class="is hj"> A </strong>的比值，反之亦然。<br/>换句话说，<strong class="is hj"> <em class="mh">赔率是成功概率与失败概率的比值，Logit就是赔率的对数。<br/> </em> </strong>让我们用例子来理解这一点:</p><p id="5f09" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假设成功的概率是0.6。<br/>因此，失败的概率将是(1–0.6)= 0.4<br/>几率由概率和0到<strong class="is hj"> ∞ </strong>之间的范围决定。<strong class="is hj"> <em class="mh"> <br/> </em> </strong>所以，现在赔率(成功)= p/(1-p)或p/q = 0.6/0.4 = 1.5 <br/>还有，赔率(失败)= 0.4/0.6 = 0.66667</p><p id="a656" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">现在你对什么是优势比有了基本的了解，我推荐你去这个</strong> <a class="ae jx" href="https://www.unm.edu/~schrader/biostat/bio2/Spr06/lec11.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">的环节了解一下它是如何在逻辑回归中使用的，以及它背后的数学</strong> </a> <strong class="is hj">。</strong></p><blockquote class="lm"><p id="47a4" class="ln lo hi bd lp lq nb nc nd ne nf jn dx translated">赔率的公式是:</p></blockquote><figure class="lx ly lz ma mb ij er es paragraph-image"><div class="er es ng"><img src="../Images/21ffa99052b082bf8ca193a1fa74dc5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*8cqcGtfJ6TxBYaDJ4uzMpA.jpeg"/></div></figure><blockquote class="lm"><p id="021e" class="ln lo hi bd lp lq lr ls lt lu lv jn dx translated">如果我们想要二进制类之间的比值比，那么:</p></blockquote><figure class="lx ly lz ma mb ij er es paragraph-image"><div class="er es nh"><img src="../Images/bdb0c28d4b4b887f1d1054759fcc5211.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*_GqJPjnd86PTEiAFOrteFg.jpeg"/></div></figure><blockquote class="lm"><p id="94ae" class="ln lo hi bd lp lq lr ls lt lu lv jn dx translated">Logit函数就是概率的对数，公式是:</p></blockquote><figure class="lx ly lz ma mb ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ni"><img src="../Images/50992f0991590afb78d5e8202eee2e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_67G0GgIWISBFX9v36830Q.png"/></div></div></figure><p id="0b74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在逻辑回归中，我们可以计算类别之间的优势比:</p><figure class="mv mw mx my fd ij er es paragraph-image"><div class="er es nj"><img src="../Images/2139fdcaf0f184e9bebe5562f0200685.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/1*yJQWZPovSbmVl-Sxdu7trA.gif"/></div></figure><p id="d0d8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，你已经理解了什么是优势比，让我们看看什么是决策边界:</p><h1 id="f0ca" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">判别边界</h1><ul class=""><li id="88c9" class="kw kx hi is b it ky ix kz jb la jf lb jj lc jn mg le lf lg bi translated">决策边界是分隔类别的线或边界。</li><li id="b205" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn mg le lf lg bi translated">分类算法的全部内容是找到有助于完美或接近完美地区分类别的决策边界。</li><li id="107b" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn mg le lf lg bi translated">逻辑回归决定了一个合适的决策边界，以便我们能够预测新数据将对应于哪一类。</li></ul><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nk"><img src="../Images/8cf0262902d7ee198a48718a92354126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kmMho6PkiVbOXKEYvguMOQ.png"/></div></div></figure><p id="ce31" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">我强烈推荐通过这个</strong> <a class="ae jx" href="https://datascience.stackexchange.com/questions/49573/how-to-plot-logistic-regression-decision-boundary" rel="noopener ugc nofollow" target="_blank">链接</a> <strong class="is hj">来理解逻辑回归中如何选择决策边界背后的数学原理。</strong></p><p id="2511" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，您已经了解了什么是决策边界，以及如何找到它。让我们看看逻辑回归的成本函数。</p><h1 id="8d7f" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">逻辑回归的成本函数</h1><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/76242505dee9a906bc0ba461d35f3132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vk3si9-WokUdezcI"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated"><a class="ae jx" href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">布雷特·乔丹</a>在<a class="ae jx" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="349d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">成本函数</strong>是<strong class="is hj">针对给定数据衡量机器学习模型</strong>性能的函数。<br/>成本函数基本上是预测值和期望值之间的误差的计算，并且<strong class="is hj">以单个实数的形式呈现</strong>。<br/>很多人混淆了<strong class="is hj">成本函数</strong>和<strong class="is hj">损失函数</strong>，<br/>简单来说<strong class="is hj">成本函数</strong>是数据中n个样本误差的平均值<strong class="is hj">损失函数</strong>是单个数据点的误差。换句话说，<strong class="is hj">损失函数</strong>是针对一个训练示例的，<strong class="is hj">成本函数</strong>是针对整个训练集的。</p><p id="0395" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那么，当我们清楚成本函数是什么时，让我们继续。</p><p id="e049" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们知道逻辑函数是:</p><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nl"><img src="../Images/7bdce569e1b13c54917d9d3cf88931fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MMpmPO29QQ6rZte9lFoCjg.png"/></div></div></figure><p id="8039" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的主要任务是找到图像中存在的上述等式中的最佳参数(x ),以最小化误差。<br/>现在，如果你看过决策边界背后的数学，你会知道参数(x)不仅限于逻辑函数，它也有助于决策边界的等式。</p><p id="4d39" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它非常类似于线性回归，定义一个成本函数来找出误差，然后执行梯度下降，以便更新参数和最小化成本函数。</p><p id="b4b8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是，我们不能使用线性回归模型的成本函数。</p><h2 id="4a12" class="nm jz hi bd ka nn no np ke nq nr ns ki jb nt nu km jf nv nw kq jj nx ny ku nz bi translated">为什么我们不能使用线性回归的成本函数？</h2><p id="4a56" class="pw-post-body-paragraph iq ir hi is b it ky iv iw ix kz iz ja jb mo jd je jf mp jh ji jj mq jl jm jn hb bi translated">尝试使用使用均方误差的线性回归模型的成本函数将给出一个非凸函数，这将给出一个形状怪异的图形，如下所示。</p><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oa"><img src="../Images/34f91b0e4c2299f95b0af887b1dd3679.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sv5Y5btwr6fqhycQPmSGbQ.jpeg"/></div></div></figure><p id="e61c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该图具有许多局部最小值，这使得成本函数很难达到全局最小值并最小化误差。</p><figure class="mv mw mx my fd ij er es paragraph-image"><div class="er es ob"><img src="../Images/089994d9f7c9d601bc061122963d9072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*oNpLsrw76ZQCtRW30C7kFQ.png"/></div></figure><p id="01ba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是因为在逻辑回归中我们有非线性的sigmoid函数。</p><p id="65b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这就是为什么逻辑回归的成本函数是:</p><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oc"><img src="../Images/37845b1e9fa11b231c52c68f7b80e23f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SLrrR5PJc8kdcI04byw8qA.png"/></div></div></figure><figure class="mv mw mx my fd ij er es paragraph-image"><div class="er es od"><img src="../Images/da0f416b80e0217a6bdee5d1002077ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*rDcUoRniPnUAK9lO3UUTlA.png"/></div></figure><p id="dccb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果将上述两个方程合二为一，将得到一个凸函数，这个成本函数将帮助逻辑回归模型更快地收敛到全局最小值。</p><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oe"><img src="../Images/b296ece1b7f23f92484765cdace8f74e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dQ4S-QHAl6gZyRDjXAvhPQ.png"/></div></div></figure><blockquote class="lm"><p id="de2e" class="ln lo hi bd lp lq lr ls lt lu lv jn dx translated">你一定想知道为什么在成本函数中有一个负号，<br/>如果你看到，在日志中出现的值将是0和1之间的概率，所以，log1的值是0，log0的值是负(-)无穷大。<br/>因此，来自成本函数的值将始终为负值，这就是我们在它上面加上负号(-)的原因。</p></blockquote><p id="3fe6" class="pw-post-body-paragraph iq ir hi is b it of iv iw ix og iz ja jb oh jd je jf oi jh ji jj oj jl jm jn hb bi translated">现在我们知道了逻辑回归的成本函数，让我们来了解如何最小化误差以获得高性能模型</p><h1 id="21e4" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">逻辑回归中的梯度下降</h1><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ok"><img src="../Images/7ce2c13e77f4856f84107476a65298a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lxCnOb6Kv0qbemwl"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated"><a class="ae jx" href="https://unsplash.com/@ussamaazam?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乌萨马·阿扎姆</a>在<a class="ae jx" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="f799" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">梯度下降是一种优化算法，用于找到使成本函数(成本)最小化的函数的参数(系数)值。</p><blockquote class="mi mj mk"><p id="6e4f" class="iq ir mh is b it iu iv iw ix iy iz ja ml jc jd je mm jg jh ji mn jk jl jm jn hb bi translated">为了更好地了解渐变下降，我建议阅读杰森·布朗利的博客。</p></blockquote><p id="69e0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，你对梯度下降有了直觉，你可以理解为什么我们需要更新权重以达到全局最小值。</p><p id="f83e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">梯度下降后获得较低成本函数的步骤:</strong></p><p id="7bdc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们来看看逻辑(sigmoid)函数。</p><figure class="mv mw mx my fd ij er es paragraph-image"><div class="er es ol"><img src="../Images/29c50cb65f948e63552090e816307b11.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*Gp5E23P5d2PY5D5kOo8ePw.png"/></div></figure><blockquote class="lm"><p id="7a1d" class="ln lo hi bd lp lq lr ls lt lu lv jn dx translated">这里，x = mx+b或x = b0 + b1x</p></blockquote><p id="bd41" class="pw-post-body-paragraph iq ir hi is b it of iv iw ix og iz ja jb oh jd je jf oi jh ji jj oj jl jm jn hb bi translated">→最初，m和b的值将为0，学习率(α)将被引入函数。<br/>学习率(α)的取值很小，大约在0.01或0.0001之间。</p><blockquote class="mi mj mk"><p id="8dbb" class="iq ir mh is b it iu iv iw ix iy iz ja ml jc jd je mm jg jh ji mn jk jl jm jn hb bi translated"><em class="hi">学习率是优化算法中的调整参数，该优化算法确定每次迭代的步长，同时向成本函数的最小值移动。</em></p></blockquote><p id="9419" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">→然后计算成本函数的偏导数。计算后得到的方程将是。</p><figure class="mv mw mx my fd ij er es paragraph-image"><div class="er es om"><img src="../Images/2fd2559d0b1f44a4a6f47debb69ce4b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*Mc1KGXq2gDOgdbxoICt_9A.png"/></div></figure><blockquote class="mi mj mk"><p id="bf88" class="iq ir mh is b it iu iv iw ix iy iz ja ml jc jd je mm jg jh ji mn jk jl jm jn hb bi translated">熟悉微积分的人会理解这个方程是如何求导的。</p><p id="3f1c" class="iq ir mh is b it iu iv iw ix iy iz ja ml jc jd je mm jg jh ji mn jk jl jm jn hb bi translated"><em class="hi">如果你不知道微积分，不要担心，只要理解它是如何工作的就足够了，直观地思考幕后发生的事情和那些想知道推导过程的人</em> <strong class="is hj"> <em class="hi">看看这个</em> </strong> <a class="ae jx" href="https://towardsdatascience.com/gradient-descent-demystified-bc30b26e432a" rel="noopener" target="_blank"> <strong class="is hj"> <em class="hi">博客</em> </strong> </a> <strong class="is hj"> <em class="hi">，它显示了成本函数</em> </strong> <em class="hi">的推导。</em></p></blockquote><p id="0154" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">→计算导数后，借助以下等式更新权重。</p><figure class="mv mw mx my fd ij er es paragraph-image"><div class="er es on"><img src="../Images/080c3df8ad57f491cf57ed6df8c4f371.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*dw51PJIX1q_CniiH2yZ2cg.png"/></div></figure><p id="c953" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">也可以写成:</p><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oo"><img src="../Images/c22cfc210c6bdef25c643cf8fc37f893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pTWqGInm_-3j6-FN74gUlQ.png"/></div></div></figure><blockquote class="lm"><p id="1e6e" class="ln lo hi bd lp lq lr ls lt lu lv jn dx translated"><em class="op">如果你读过杰森·布朗利的博客</em> <a class="ae jx" href="https://machinelearningmastery.com/gradient-descent-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"> <em class="op">，你可能会理解梯度下降背后的直觉，以及它如何试图达到全局最小值(最低成本函数值)。</em></a></p></blockquote><blockquote class="mi mj mk"><p id="899e" class="iq ir mh is b it of iv iw ix og iz ja ml oh jd je mm oi jh ji mn oj jl jm jn hb bi translated"><strong class="is hj"> <em class="hi">为什么要用导数减去权重(m和b)？</em> </strong> <em class="hi"> <br/>梯度给我们损失函数的最陡上升方向，最陡下降方向与梯度相反，这就是为什么我们从权重(m和b)中减去梯度</em></p></blockquote><p id="986d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">→更新权重的过程将继续，直到成本函数达到理想值0或接近0。</p><p id="e6b1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，在你完成了最佳表演模式之后。让我们看看如何检查模型的质量。</p><h1 id="9191" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">评估逻辑回归模型</h1><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oq"><img src="../Images/aa1c2ac6c6f6d508c01282a4a173a10d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7Qr9Se0oJq3oo1ve"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated"><a class="ae jx" href="https://unsplash.com/@sctgrhm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯科特·格雷厄姆</a>在<a class="ae jx" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="173e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在建立模型之后，很明显，我们要检查我们的模型执行得有多好，它与我们的数据有多吻合。</p><p id="2eb6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">实现这一点的方法之一是，根据一组新的自变量来衡量你预测因变量的能力。</p><ol class=""><li id="74ac" class="kw kx hi is b it iu ix iy jb mr jf ms jj mt jn ld le lf lg bi translated"><strong class="is hj"> R2(R平方)值:</strong> <br/>为逻辑回归计算的R平方与为线性回归模型计算的R平方不同。<br/>这些伪R平方有助于衡量模型的预测能力。<br/>有许多不同的方法来计算逻辑回归的R平方值，然而，没有一种方法是公认的最佳方法。但是，在所有类型的R平方值中<strong class="is hj">麦克法登的R平方是更好的方法。<br/> </strong> <a class="ae jx" href="https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/#:~:text=A%20pseudo%20R%2Dsquared%20only,model%20better%20predicts%20the%20outcome." rel="noopener ugc nofollow" target="_blank">参考此链接浏览不同类型的R平方进行逻辑回归。</a></li><li id="9e08" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj"> AIC(赤池信息准则):</strong> <br/> * AIC是模型拟合优度的估计量。<br/> *每当我们创建一个模型时，我们都会丢失一些信息，没有人能够创建完美的模型。AIC估计了信息丢失的数量。<br/>* AIC值越小，意味着丢失的信息越少，意味着模型越好。<br/> *在模型中加入变量不会增加AIC的价值。<br/>* AIC的用途之一还在于它有助于选择型号。我们可以拟合整个数据来训练模型，并比较不同模型的AIC值，选择具有最佳AIC值的模型。<br/> AIC = -2/N * LL + 2*K/N <br/> <em class="mh">其中，</em> <strong class="is hj"> <em class="mh"> N </em> </strong> <em class="mh">为训练数据中的样本数，</em> <strong class="is hj"> <em class="mh"> LL </em> </strong> <em class="mh">为模型对训练数据的对数似然。而</em> <strong class="is hj"> <em class="mh"> K </em> </strong> <em class="mh">是数据中参数的个数。</em></li><li id="0b7f" class="kw kx hi is b it lh ix li jb lj jf lk jj ll jn ld le lf lg bi translated"><strong class="is hj">其他方法包括混淆矩阵、Roc-Auc曲线</strong>。<br/>你可以在我的博客<a class="ae jx" rel="noopener" href="/analytics-vidhya/calculating-accuracy-of-an-ml-model-8ae7894802e">中读到关于混淆矩阵和其他相关的指标计算一个ML模型的准确性</a>和理解<a class="ae jx" rel="noopener" href="/analytics-vidhya/understanding-the-auc-roc-curve-cdc754d7b58a"> AUC-ROC曲线</a>。</li></ol><p id="2474" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我希望这篇文章能让你对逻辑回归模型有一个大致的了解。逻辑回归中有更多的东西。然而，我们只是触及了它的表面。我推荐阅读关于逻辑回归的书籍，在谷歌上搜索，观看youtube视频，并尝试阅读发表在这方面的论文。</p><p id="0848" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">快乐学习！！！！！</strong></p></div><div class="ab cl or os gp ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="hb hc hd he hf"><p id="91f9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">喜欢我的文章？请为我鼓掌并分享它，因为这将增强我的信心。此外，我每周日都会发布新的文章，所以请保持联系，以获取关于数据科学和机器学习基础的未来文章。</p><p id="895b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另外，请务必通过LinkedIn 与我联系。</p><figure class="mv mw mx my fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oy"><img src="../Images/171495c0378e7ff1d01968bee0c5ce02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Jxl_dF4FzQ2ao3ek"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated"><a class="ae jx" href="https://unsplash.com/@alx_andru?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Alex </a>在<a class="ae jx" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure></div></div>    
</body>
</html>