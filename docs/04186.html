<html>
<head>
<title>Bangla Character Recognition System — The Deep Learning Way (3/n)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">孟加拉文字识别系统—深度学习方式(3/n)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/bangla-character-recognition-system-the-deep-learning-way-3-n-17cb1d140a5f?source=collection_archive---------21-----------------------#2020-03-08">https://medium.com/analytics-vidhya/bangla-character-recognition-system-the-deep-learning-way-3-n-17cb1d140a5f?source=collection_archive---------21-----------------------#2020-03-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="9633" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">用于手写孟加拉文字识别的卷积神经网络</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/1dbd5868843848116005d2e12a9b0acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gBo4CgVXdE3Xahz9jePWoQ.jpeg"/></div></div></figure><p id="09ba" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">你好，这是这个系列的倒数第二篇文章，也可能是我作为第一作者的最后一篇文章。这个系列始于我和Christina在布朗大学数据科学倡议的深度学习实践课上开展的期中项目的一部分。前两部分的链接如下:</p><ul class=""><li id="5cf5" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated"><a class="ae ko" rel="noopener" href="/@sayansamanta/bangla-character-recognition-system-the-deep-learning-way-1-n-8671a33a7860">孟加拉文字识别系统——深度学习方式(1/n) </a></li><li id="664d" class="kf kg hi jl b jm kp jp kq js kr jw ks ka kt ke kk kl km kn bi translated"><a class="ae ko" rel="noopener" href="/@sayansamanta/bangla-character-recognition-system-the-deep-learning-way-2-n-d5b16333d77b">孟加拉文字识别系统——深度学习方式(2/n) </a></li></ul><p id="701f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">手头的任务是<a class="ae ko" href="https://www.kaggle.com/c/bengaliai-cv19" rel="noopener ugc nofollow" target="_blank"> Kaggle竞赛</a>，该竞赛涉及将孟加拉手写字符分为3个目标类别——字素词根、元音变音符号和辅音变音符号。</p><p id="8f24" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在第一篇文章中，我们讨论了数据集，列举了不同的类和类平衡。我们还讨论了图像预处理步骤，如去噪，阈值和裁剪。我们还谈到了可能的数据增强管道。</p><p id="8099" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在第二篇文章中，我们讨论了卷积神经网络和DenseNet的一般概念，dense net是一种基于卷积网络的特定架构，其中每一层都将前一层的输出作为输入，但在一定程度上也将前几层的输入作为输入(准确地说，是特定密集块内的所有前几层卷积层)。</p><p id="1c8a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这篇文章中，我们将主要讨论我们的候选模型的微调(或者我称之为SayanNet v4，以激发我的被动自恋:P)。随后我们将展示最终结果。我们将谈一谈关于特定图像的不同卷积层的输出。作为结束语，我们建议对模型进行不同的升级，以挤出最后一点准确性。让我们开始吧。</p></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><h1 id="0a02" class="lb lc hi bd ld le lf lg lh li lj lk ll io lm ip ln ir lo is lp iu lq iv lr ls bi translated">超参数调谐</h1><p id="59a7" class="pw-post-body-paragraph jj jk hi jl b jm lt ij jo jp lu im jr js lv ju jv jw lw jy jz ka lx kc kd ke hb bi translated">我们选择使用TensorBoards HParams dashboard对一系列超参数进行全面搜索。由于项目交付期限和计算资源的限制，我们不得不保持搜索空间相当狭窄，但同时也有一些有趣的旋钮打开。</p><ol class=""><li id="c478" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke ly kl km kn bi translated">过滤器的数量——我们保持每个密集块中过滤器的数量不变，但对数量进行了试验。这决定了密集模块输出端的滤波器数量。我们搜索了8、12、24和32个过滤器。</li><li id="5393" class="kf kg hi jl b jm kp jp kq js kr jw ks ka kt ke ly kl km kn bi translated">生长率-我们还对生长率进行了搜索，确定了每个密集块中每个卷积层的过滤器数量。我们的搜索空间是4、6、12和16个过滤器。</li><li id="689d" class="kf kg hi jl b jm kp jp kq js kr jw ks ka kt ke ly kl km kn bi translated">块中的图层-该参数设置每个密集块中卷积图层的数量。在我们的例子中，我们在单个块中尝试了4层<strong class="jl hj">和6层</strong>。</li><li id="71d6" class="kf kg hi jl b jm kp jp kq js kr jw ks ka kt ke ly kl km kn bi translated">密集块大小—这是我们模型中的密集块数量。我们的搜索在大小为3和5的的<strong class="jl hj">块之间进行实验。</strong></li></ol><p id="279c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">使用HParams的主要原因之一是TensorBoard为分析提供了简洁的可视化。这是来自64个不同超参数组合的64个不同分数的结果。同样，由于计算和时间的限制，这些值用于完整的预处理数据集，但仅用于10个时期。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/437458116ef4139b13cb204ab19ecd6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rjrTnNmV59BP2oIPx_YFXw.png"/></div></div></figure><p id="dfac" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">绿线表示超参数的最佳组合。为了我们项目的目的，我们决定</p><ul class=""><li id="ed96" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated">过滤器— 12</li><li id="0bd3" class="kf kg hi jl b jm kp jp kq js kr jw ks ka kt ke kk kl km kn bi translated">增长率— 12</li><li id="8cb5" class="kf kg hi jl b jm kp jp kq js kr jw ks ka kt ke kk kl km kn bi translated">区块6中的图层</li><li id="8d55" class="kf kg hi jl b jm kp jp kq js kr jw ks ka kt ke kk kl km kn bi translated">密集块大小— 3(虽然6非常接近，但会涉及更多计算，因为它会增加6个卷积层)</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mb"><img src="../Images/baf8d6a66a8bd337021a0465499b96f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S6cZiduF4ab4VVAM4h5N2A.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">从左到右:分别训练和验证辅音、根音和元音准确度和损失。</figcaption></figure><p id="6d17" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在顶部，你可以看到新的训练曲线。您可以忽略大约第55个时间步长处的轻微缺口。Colab运行时重新启动，我们必须以更高的学习率恢复培训。</p></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><h1 id="1281" class="lb lc hi bd ld le lf lg lh li lj lk ll io lm ip ln ir lo is lp iu lq iv lr ls bi translated">Kaggle条目</h1><p id="1a5e" class="pw-post-body-paragraph jj jk hi jl b jm lt ij jo jp lu im jr js lv ju jv jw lw jy jz ka lx kc kd ke hb bi translated">这里是进入卡格尔的最后入口。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mg"><img src="../Images/4d1cdd3646a090d5ace87cbbaea3ca97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tg3q4CurE9XjJxwZ74jEXA.png"/></div></div></figure><p id="32fb" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">每个分数都与我们在这里描述的模型稍有不同。预测大致相同。</p><p id="a41f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果与竞赛排行榜相比，分数不是很令人鼓舞。然而，我们没有时间进行任何数据扩充。也许，像AlexNet所做的那样，局部标准化可以提高准确性。我们也从流行的模型如VGGnet、ResNet、InceptionNet等来推测迁移学习。冻结预训练层将是一个有趣的检查(在下一篇文章中会有更多的介绍)。我们的超参数搜索只浏览了定义我们模型的大规模参数空间的表面。另外，谁知道呢，也许更多的计算，也许多模型平均预测可能是有用的。调整的选择是巨大的。</p><h1 id="1c6c" class="lb lc hi bd ld le mh lg lh li mi lk ll io mj ip ln ir mk is lp iu ml iv lr ls bi translated">卷积网络解释</h1><p id="f138" class="pw-post-body-paragraph jj jk hi jl b jm lt ij jo jp lu im jr js lv ju jv jw lw jy jz ka lx kc kd ke hb bi translated">我们还绘制了从每个卷积层的不同过滤器看到的图像(স্ট্রী)的不同部分。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/766c5cf4c6fc4239a7e756347e4f0901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKyHaXIeNRtSAbU4OW8aDA.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">每个过滤器的图像卷积图。这表示第一个卷积块的滤波器</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/a971e3e44849e7e9144e800ec37b45c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zaSDTvGhJbZLBn2EPbze0Q.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">往下几层</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/ea6f50a0b5e13da6db9daceac8c971c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kwr8BjzJjHRlKfj5v90iLQ.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">再往下几层</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/c21d29f45be838aa41fcbcbc5008caa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BJuLvwTYyxsg8Z91ro7VXA.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">更深层</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/3570951133c5860c723f7361600e220d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ykkrtJFc9f-FeX6NDgv43g.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">接近结尾的层</figcaption></figure><p id="aa11" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">正如你从图像中看到的，顶部的几层在不同风格的轮廓周围很好地斜切了图像，更深的层在轮廓周围也发现了更好的差异。前几层中的一个共同线索是网络学习从背景画布中提取书写部分。随着我们越来越深入，由于这些层会出现更普遍的模式，所以解释起来就变得困难了。但毫无疑问，某种形式的层次特征映射正在进行。</p></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><h1 id="98af" class="lb lc hi bd ld le lf lg lh li lj lk ll io lm ip ln ir lo is lp iu lq iv lr ls bi translated">结尾注释</h1><p id="ac6a" class="pw-post-body-paragraph jj jk hi jl b jm lt ij jo jp lu im jr js lv ju jv jw lw jy jz ka lx kc kd ke hb bi translated">我们将在这里称之为这个项目的总结。虽然Christina会在她的博客上发布一个后记，我们将在那里讨论来自不同的更好的评分模型和前面提到的预训练网络的其他模型的性能。一旦完成，我会把链接贴在这里。</p><p id="0d92" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在成功的事情之间，有10件不同的事情没有成功，但最终的结果是所有这些尝试的高潮。学习曲线很陡(通过适当的调整:P)，而且非常有趣。感谢大家花时间阅读这份初出茅庐的尝试。向获奖者和排行榜上的每个人大声欢呼，这些人做得非常出色。下一个项目再见。</p><blockquote class="mn mo mp"><p id="7461" class="jj jk lz jl b jm jn ij jo jp jq im jr mq jt ju jv mr jx jy jz ms kb kc kd ke hb bi translated">আবারদেখাহবেএখনইশেষদেখানয়<br/>আবারদেখাহবেএখনইশেষকথানয়</p></blockquote><p id="d1e2" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi">চীয়ার্স!</p><p id="9026" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">সায়ন এবং ক্রিস্টিনা <br/> ( <a class="mt mu ge" href="https://medium.com/u/9e9e4910bc48?source=post_page-----17cb1d140a5f--------------------------------" rel="noopener" target="_blank">萨彦</a>和<a class="mt mu ge" href="https://medium.com/u/45dbeb02fb04?source=post_page-----17cb1d140a5f--------------------------------" rel="noopener" target="_blank">克里斯蒂娜</a>)</p></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><p id="26e7" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">项目的所有代码都可以在这个</strong><a class="ae ko" href="https://github.com/reach2sayan/Bengali-Grapheme_DATA2040" rel="noopener ugc nofollow" target="_blank"><strong class="jl hj">github</strong></a><strong class="jl hj">资源库中找到。</strong></p></div><div class="ab cl ku kv gp kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="hb hc hd he hf"><h1 id="2ff7" class="lb lc hi bd ld le lf lg lh li lj lk ll io lm ip ln ir lo is lp iu lq iv lr ls bi translated">参考</h1><ol class=""><li id="792d" class="kf kg hi jl b jm lt jp lu js mv jw mw ka mx ke ly kl km kn bi translated"><a class="ae ko" href="https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/tensor board/hyperparameter _ tuning _ with _ hparams</a></li></ol></div></div>    
</body>
</html>