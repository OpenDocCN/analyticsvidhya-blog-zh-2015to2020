<html>
<head>
<title>Natural Scenery Detection Using Deep Learning Model-Full Deployment With Django (Part-1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习模型的自然风景检测-使用Django的全面部署(第1部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/natural-scenery-detection-using-deep-learning-model-full-deployment-with-django-part-1-f0e4838c7198?source=collection_archive---------16-----------------------#2020-06-12">https://medium.com/analytics-vidhya/natural-scenery-detection-using-deep-learning-model-full-deployment-with-django-part-1-f0e4838c7198?source=collection_archive---------16-----------------------#2020-06-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/33c074f6fe7fcb5f39d43154bd0877c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*so429baKyZsWEbRPPOosHA.jpeg"/></div></div></figure><p id="1083" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了识别风景，我将使用Keras和Tensorflow。这只是一个初级水平的多标记图像识别方法。对于多标签图像，我们需要标记图像。有很多方法可以做到这一点，我只是通过CSV标记它们，这似乎是最简单的方法。我用colab来实现。首先，让我们进口所有必要的东西，</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="f539" class="jx jy hi jt b fi jz ka l kb kc"><strong class="jt hj">import</strong> <strong class="jt hj">keras</strong><br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.models</strong> <strong class="jt hj">import</strong> Sequential<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.layers</strong> <strong class="jt hj">import</strong> Dense, Dropout, Flatten<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.layers</strong> <strong class="jt hj">import</strong> Conv2D, MaxPooling2D<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.utils</strong> <strong class="jt hj">import</strong> to_categorical<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.preprocessing</strong> <strong class="jt hj">import</strong> image<br/><strong class="jt hj">import</strong> <strong class="jt hj">numpy</strong> <strong class="jt hj">as</strong> <strong class="jt hj">np</strong><br/><strong class="jt hj">import</strong> <strong class="jt hj">pandas</strong> <strong class="jt hj">as</strong> <strong class="jt hj">pd</strong><br/><strong class="jt hj">import</strong> <strong class="jt hj">matplotlib.pyplot</strong> <strong class="jt hj">as</strong> <strong class="jt hj">plt</strong><br/><strong class="jt hj">from</strong> <strong class="jt hj">sklearn.model_selection</strong> <strong class="jt hj">import</strong> train_test_split<br/><strong class="jt hj">from</strong> <strong class="jt hj">tqdm</strong> <strong class="jt hj">import</strong> tqdm<br/>%matplotlib inline<br/><strong class="jt hj">import</strong> <strong class="jt hj">keras_metrics</strong></span></pre><p id="c020" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可能对keras_metrics有问题，所以您应该通过“pip install Keras-metrics”来安装它。下一步是比较我们的CSV和我们现有的图像，我们必须让我们的模型识别图像，并将它们与我们标记的CSV文件进行比较。为此，我们必须将每个图像分别与CSV的每一行进行比较。为此，我们需要制作一个训练图像的空白列表，我们将在其中放置图像的数组，然后通过每行将其与CSV进行比较。让我们看看我们的CSV文件-</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="5a63" class="jx jy hi jt b fi jz ka l kb kc">train = pd.read_csv("/content/drive/My Drive/miml_dataset/miml_labels_1.csv")<br/>train_image = []<br/>train.head()</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kd"><img src="../Images/0ad7f88c50e2277e3ff98f3470333042.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*boxM_FAXQlyXhQu-cvFcBA.png"/></div></figure><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="1c13" class="jx jy hi jt b fi jz ka l kb kc"><strong class="jt hj">for</strong> i <strong class="jt hj">in</strong> tqdm(range(train.shape[0])):<br/>    img = image.load_img('/content/drive/My Drive/miml_dataset/images/'+train['Filenames'][i],target_size=(256,256,3))<br/>    img = image.img_to_array(img)<br/>    img = img/255<br/>    train_image.append(img)<br/>X = np.array(train_image)</span></pre><p id="4e8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，tqdm是一个进度条，用于笔记本中的嵌套循环。在我们使用CNN模型之前，我们最好删除文件名行。然后，我们将使用训练-测试拆分，将数据集拆分为90%用于训练数据集，10%用于验证数据集。</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="3ec4" class="jx jy hi jt b fi jz ka l kb kc">y = np.array(train.drop(['Filenames'],axis=1))<br/></span><span id="1e7c" class="jx jy hi jt b fi ke ka l kb kc">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)</span></pre><p id="859d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后我们再定义一个简单的CNN模型，层数和参数都比较少。并按照我们之前提供的方法改变输入形状。您也可以根据自己的需要添加层和参数。之后，我们使用fit运行模型，就像我们使用数组一样。</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="4b8a" class="jx jy hi jt b fi jz ka l kb kc">model = Sequential()<br/>model.add(Conv2D(filters=16, kernel_size=(5, 5), activation="relu", input_shape=(256,256,3)))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))<br/>model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))<br/>model.add(Conv2D(filters=64, kernel_size=(5, 5), activation="relu"))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))<br/>model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))<br/>model.add(Flatten())<br/>model.add(Dense(128, activation='relu'))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(64, activation='relu'))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(5, activation='sigmoid'))<br/>model.summary()<br/>model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',keras_metrics.precision(), keras_metrics.recall(),keras_metrics.f1_score()])</span><span id="a9e9" class="jx jy hi jt b fi ke ka l kb kc">hist=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), batch_size=64)</span></pre><p id="eac9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在第100个历元时，我们有一个相当好的精度，即96%的训练精度和验证精度较低，但仍然看起来不错。现在，我们将绘制准确性、丢失率、精确度、召回率和f1_score来进行可视化。</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="7a58" class="jx jy hi jt b fi jz ka l kb kc">plt.plot(hist.history['loss'])<br/>plt.plot(hist.history['val_loss'])<br/>plt.title('Model loss')<br/>plt.ylabel('Loss')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Validation'], loc='upper left')<br/><em class="kf">#fig.savefig("Model loss.png")</em><br/>plt.show()</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kg"><img src="../Images/8b17ffb0e35bf9c17cf613e6f486aa06.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*fQT7LCcYBf3VqOY-igm18g.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">训练损失和验证损失</figcaption></figure><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="615a" class="jx jy hi jt b fi jz ka l kb kc"><strong class="jt hj">import matplotlib.pyplot as plt</strong><br/>plt.plot(hist.history['accuracy'])<br/>plt.plot(hist.history['val_accuracy'])<br/>plt.title('Model accuracy')<br/>plt.ylabel('Accuracy')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Validation'], loc='upper left')<br/>plt.show()</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kl"><img src="../Images/023c3e0dca3fb260fc9d0a043da68202.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*tLBcmsAzXJii-NJsFC8lug.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">训练和测试准确性</figcaption></figure><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="c25e" class="jx jy hi jt b fi jz ka l kb kc">plt.plot(hist.history['precision'])<br/>plt.plot(hist.history['recall'])<br/>plt.plot(hist.history['f1_score'])<br/>plt.title('Model report')<br/>plt.ylabel('Report')<br/>plt.xlabel('Epoch')<br/>plt.legend(['precision', 'recall','f1_score'], loc='upper left')<br/>plt.show()</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kg"><img src="../Images/78a454c9d1ff0cabaae4dda51575c41d.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*sOaXK0qS6Ac4OqP4OLZh-Q.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">培训模型报告</figcaption></figure><p id="f795" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">之后，我们需要测试数据。为了测试，我们可以从谷歌上下载随机的风景图片。为了加载你的图像，你需要给出图像路径，并且你必须将目标尺寸改变为256的高度和256的宽度，否则，形状将会不匹配。然后把图像换成数组。就我而言，我已经从谷歌上随机下载了图片并进行测试。这里给出了一些例子。</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="4a75" class="jx jy hi jt b fi jz ka l kb kc">img = image.load_img('/content/image1.jpg',target_size=(256,256,3))                       <br/>img = image.img_to_array(img)                       <br/>img = img/255</span></pre><p id="c520" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们将使用model.predict来预测图像。在这里，我们选择了前3类进行预测。你可以自己改。</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="f695" class="jx jy hi jt b fi jz ka l kb kc">classes = np.array(train.columns[3:])<br/>proba = model.predict(img.reshape(1,256,256,3))<br/>top_3 = np.argsort(proba[0])[:-4:-1]<br/><strong class="jt hj">for</strong> i <strong class="jt hj">in</strong> range(3):<br/>    print("<strong class="jt hj">{}</strong>".format(classes[top_3[i]])+" (<strong class="jt hj">{:.3}</strong>)".format(proba[0][top_3[i]]))<br/>plt.imshow(img)</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es km"><img src="../Images/85ed171e8920b113aa714c5261162710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*ua6e59F1hSrdcD8-VNJ68A.jpeg"/></div></figure><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="b7a4" class="jx jy hi jt b fi jz ka l kb kc">img = image.load_img('/content/image2.jpg',target_size=(256,256,3))                       <br/>img = image.img_to_array(img)                       <br/>img = img/255</span><span id="d044" class="jx jy hi jt b fi ke ka l kb kc">classes = np.array(train.columns[3:])<br/>proba = model.predict(img.reshape(1,256,256,3))<br/>top_3 = np.argsort(proba[0])[:-4:-1]<br/><strong class="jt hj">for</strong> i <strong class="jt hj">in</strong> range(3):<br/>    print("<strong class="jt hj">{}</strong>".format(classes[top_3[i]])+" (<strong class="jt hj">{:.3}</strong>)".format(proba[0][top_3[i]]))<br/>plt.imshow(img)</span></pre><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/8cf191350db51c123cf310479d623ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*FvnwpcgqtSz2q0Mzx2TP2A.jpeg"/></div></figure><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="6281" class="jx jy hi jt b fi jz ka l kb kc">img = image.load_img('/content/image3.jpg',target_size=(256,256,3))                       <br/>img = image.img_to_array(img)                       <br/>img = img/255</span><span id="cb08" class="jx jy hi jt b fi ke ka l kb kc">classes = np.array(train.columns[3:])<br/>proba = model.predict(img.reshape(1,256,256,3))<br/>top_3 = np.argsort(proba[0])[:-5:-1]<br/><strong class="jt hj">for</strong> i <strong class="jt hj">in</strong> range(4):<br/>    print("<strong class="jt hj">{}</strong>".format(classes[top_3[i]])+" (<strong class="jt hj">{:.4}</strong>)".format(proba[0][top_3[i]]))<br/>plt.imshow(img)</span></pre><p id="f129" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里我选了4门课。有时模型在选择海洋或沙漠时可能是错误的。这是我面临的主要问题。除此之外，一切似乎都很好。</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es ko"><img src="../Images/05c20dfc531e73f8a7d7ef57cc35189c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*2-ng2FkK0h-9UVLs5bdW3A.jpeg"/></div></figure><p id="a3e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们将保存模型。模型可以通过多种方式保存。这些是-</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="bd27" class="jx jy hi jt b fi jz ka l kb kc"><strong class="jt hj">import</strong> <strong class="jt hj">pickle</strong><br/><strong class="jt hj">from</strong> <strong class="jt hj">sklearn.externals</strong> <strong class="jt hj">import</strong> joblib<br/>filename='Scene.pkl'<br/>joblib.dump(model, filename)<br/>model.save('scenery')<br/>model.save('scenery.h5')<br/>model.save_weights('scenery')<br/>model.save_weights('scenery.h5')</span></pre><p id="4acc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，我们可以加载模型并从模型中预测图像。下一部分，我们将使用保存的模型预测图像，然后在Django网站应用程序中进行。</p></div></div>    
</body>
</html>