<html>
<head>
<title>A Simple way to Scrape Images in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python抓取图像的简单方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-simple-way-to-scrape-images-in-python-4b543936c150?source=collection_archive---------3-----------------------#2019-10-10">https://medium.com/analytics-vidhya/a-simple-way-to-scrape-images-in-python-4b543936c150?source=collection_archive---------3-----------------------#2019-10-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b54c2375011d2a64ed3db47d107beaeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4_hBmRL9_SdJLFSfpaY0Gg.jpeg"/></div></div></figure><p id="d40e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本文中，我们将从同一个<em class="jo"> goibibo </em>网页中抓取所有图片。第一步是导航到目标网站并下载源代码。接下来，我们将找到所有使用<strong class="is hj"> &lt; img &gt; </strong>标签的图片:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="b366" class="jy jz hi ju b fi ka kb l kc kd"># importing required libraries<br/>import requests<br/>from bs4 import BeautifulSoup</span><span id="ac48" class="jy jz hi ju b fi ke kb l kc kd"># target URL<br/>url = "<a class="ae kf" href="https://www.goibibo.com/hotels/hotels-in-shimla-ct/" rel="noopener ugc nofollow" target="_blank">https://www.goibibo.com/hotels/hotels-in-shimla-ct/</a>"</span><span id="8377" class="jy jz hi ju b fi ke kb l kc kd">headers = {<br/>    'User-Agent': "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36"<br/>    }</span><span id="effc" class="jy jz hi ju b fi ke kb l kc kd">response = requests.request("GET", url, headers=headers)</span><span id="7103" class="jy jz hi ju b fi ke kb l kc kd">data = BeautifulSoup(response.text, 'html.parser')</span><span id="17eb" class="jy jz hi ju b fi ke kb l kc kd"># find all with the image tag<br/>images = data.find_all('img', src=True)</span><span id="adfb" class="jy jz hi ju b fi ke kb l kc kd">print('Number of Images: ', len(images))</span><span id="34ea" class="jy jz hi ju b fi ke kb l kc kd">for image in images:<br/>    print(image)</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kg"><img src="../Images/14453e1a002e009cf1afc2151ef0a336.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bWvH_GrXUSxfQTPC"/></div></div></figure><p id="efa2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从所有的图像标签中，只选择<strong class="is hj"> <em class="jo"> &lt; src &gt; </em> </strong>部分。另外，请注意，酒店图像可以使用<strong class="is hj"> <em class="jo"> jpg </em> </strong>格式。因此，我们将只选择那些:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="d587" class="jy jz hi ju b fi ka kb l kc kd"># select src tag<br/>image_src = [x['src'] for x in images]</span><span id="793f" class="jy jz hi ju b fi ke kb l kc kd"># select only jp format images<br/>image_src = [x for x in image_src if x.endswith('.jpg')]</span><span id="75e6" class="jy jz hi ju b fi ke kb l kc kd">for image in image_src:<br/>    print(image)</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kh"><img src="../Images/1970ba3470d54a95770b3ec49a2a0638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DQGpVR4Nvw-eTwZj"/></div></div></figure><p id="7a5d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们有了一个图像URL列表，我们所要做的就是请求图像内容并将其写入一个文件。确保你打开文件<strong class="is hj"><em class="jo">‘WB’(</em></strong>写二进制)格式:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="1c23" class="jy jz hi ju b fi ka kb l kc kd">image_count = 1<br/>for image in image_src:<br/>    with open('image_'+str(image_count)+'.jpg', 'wb') as f:<br/>        res = requests.get(image)<br/>        f.write(res.content)<br/>    image_count = image_count+1</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ki"><img src="../Images/fc4032d8e2e4e8775de260b931bf00bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Nol97Fqwf-xtzNQi"/></div></div></figure><p id="cfd3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您还可以通过页码更新初始页面URL，并反复请求它们收集大量数据。</p><p id="271d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图像<a class="ae kf" href="https://www.pymnts.com/news/security-and-risk/2019/sap-software-vulnerable-hack/" rel="noopener ugc nofollow" target="_blank">资源</a></p></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><p id="af78" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">原载于2019年10月10日https://www.analyticsvidhya.com</em><em class="jo">T21</em><a class="ae kf" href="https://www.analyticsvidhya.com/blog/2019/10/web-scraping-hands-on-introduction-python/" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>