<html>
<head>
<title>Step-By-Step Building A Neural Network From Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一步一步从头开始构建神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/step-by-step-building-a-neural-network-from-scratch-using-numpy-only-build-a-sentiment-b76393417291?source=collection_archive---------6-----------------------#2020-08-21">https://medium.com/analytics-vidhya/step-by-step-building-a-neural-network-from-scratch-using-numpy-only-build-a-sentiment-b76393417291?source=collection_archive---------6-----------------------#2020-08-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="cf18" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">关于如何用 python 实现一个神经网络的完整指南，只使用 NumPy。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/bd25e6152d3fc1d6e9f78226fda23a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ndLwRDTu7KdTeJBM"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">乔希·里默尔在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="b932" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我在<em class="kk"> Udacity 深度学习基金会 Nanodegree </em>中学到了这个教程，并想与你分享我在这个情感分类项目中的经验，并给出如何实现它的完整指导。</p><p id="dfaf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">您可以从 github 上的这个链接获得源代码和数据集。</p><blockquote class="kl km kn"><p id="8bf9" class="jo jp kk jq b jr js ij jt ju jv im jw ko jy jz ka kp kc kd ke kq kg kh ki kj hb bi translated"><a class="ae jn" href="https://github.com/udacity/deep-learning/tree/master/sentiment-network" rel="noopener ugc nofollow" target="_blank">https://github . com/uda city/deep-learning/tree/master/情操网</a></p></blockquote><p id="c18d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们将从零开始建立一个神经网络模型，而不使用<code class="du kr ks kt ku b">Tensorflow</code>或<code class="du kr ks kt ku b">py-torch</code>或任何机器学习平台。我们将使用<code class="du kr ks kt ku b">python</code>从头开始构建一切，这样我们就可以看到神经网络如何工作的幕后场景。</p><p id="7ee6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这个项目中，我们将实现一个多层感知器模型来将一个给定的文本分类为积极或消极。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kv"><img src="../Images/6f7fa6af1ae2b22aa12fbf9a4a5710e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ub-ifcgdi9xgryqvo0_GRA.png"/></div></div></figure><h2 id="0dc0" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">神经网络的组成部分:</h2><p id="304b" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">首先，让我们确定神经网络模型的组件:</p><ul class=""><li id="5ecb" class="lw lx hi jq b jr js ju jv jx ly kb lz kf ma kj mb mc md me bi translated">第 1 层→输入层</li><li id="e868" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">第 2 层→隐藏层</li><li id="e627" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">第 3 层→输出层</li><li id="b93f" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">激活函数(我们将选择一个 sigmoid 函数)</li><li id="4c36" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">学习率</li><li id="f2c9" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">数据集(评论文本)</li></ul><h2 id="97fe" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">要实现的功能:</h2><ul class=""><li id="65c3" class="lw lx hi jq b jr lr ju ls jx mk kb ml kf mm kj mb mc md me bi translated">预处理数据。</li><li id="64d6" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">标签转换为二进制(将输出标签正转换为“1”，负转换为“0”)。</li><li id="1ab3" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">乙状结肠函数。</li><li id="3850" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">Sigmoid 导数函数。</li><li id="134b" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">火车。</li><li id="7513" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">测试。</li><li id="55d6" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mb mc md me bi translated">快跑。</li></ul><h2 id="3f12" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">我们将经历的步骤:</h2><ol class=""><li id="dfd9" class="lw lx hi jq b jr lr ju ls jx mk kb ml kf mm kj mn mc md me bi translated">读取数据集</li><li id="cb25" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">导入 Numpy 库和计数器函数</li><li id="df4a" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">情感分类类</li><li id="fda3" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">创建预处理数据功能</li><li id="9768" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">初始化网络功能</li><li id="c921" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">标签到二进制</li><li id="e2a9" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">Sigmoid 函数及其导数</li><li id="f432" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">实施培训功能(向前传递)</li><li id="9484" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">偶数道次</li><li id="f400" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">运行和测试</li><li id="532e" class="lw lx hi jq b jr mf ju mg jx mh kb mi kf mj kj mn mc md me bi translated">让我们运行这个网络</li></ol><p id="5297" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们开始吧。</p><h2 id="df12" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 1:读取数据集</h2><p id="2685" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">使用<code class="du kr ks kt ku b">Open</code>功能读取文本文件，然后使用<code class="du kr ks kt ku b">map</code>映射整个文件，将其转换为评论列表，然后对标签文本文件重复上述操作。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="e067" class="kw kx hi ku b fi ms mt l mu mv">File = open('reviews.txt','r') # What we know!<br/>reviews = list(map(lambda x:x[:-1],File.readlines()))<br/>g.close()</span><span id="73e8" class="kw kx hi ku b fi mw mt l mu mv">File2 = open('labels.txt','r') # What we WANT to know!<br/>labels = list(map(lambda x:x[:-1].upper(),File2.readlines()))<br/>g.close()</span></pre><p id="c049" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这是列表中第一个评论的样子。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mx"><img src="../Images/2bde15da4ef3e35719d657cd9150c1ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ZaCQ98aL9craQEhYa6iOg.png"/></div></div></figure><h2 id="80d1" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 2:导入 Numpy 库和计数器函数</h2><p id="8221" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">我们将在我们的项目中使用一个名为 counter 的函数，我们稍后会用到它，但首先让我们导入它。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="bda3" class="kw kx hi ku b fi ms mt l mu mv">import numpy as np<br/>from collections import Counter</span></pre><h2 id="71f6" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 3:情感分类类</h2><p id="eecb" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">创建一个类，用我们将要使用的函数来保存整个网络，我们把它命名为“情感网络”。</p><p id="a4e3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们用这 4 个参数初始化它(评论数据，标签，隐藏节点，学习率)。</p><p id="3ce0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">接下来调用我们将在下一步实现的预处理数据函数，并调用初始化整个网络的 init network 函数，我们将在步骤 5 中实现该函数。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="108d" class="kw kx hi ku b fi ms mt l mu mv">class SentimentNetwork:<br/>    def __init__(self, reviews,labels,hidden_nodes=10,learning_rate = 0.1):</span><span id="1290" class="kw kx hi ku b fi mw mt l mu mv">self.pre_process_data(reviews, labels)<br/>        <br/>                self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)</span></pre><blockquote class="kl km kn"><p id="0933" class="jo jp kk jq b jr js ij jt ju jv im jw ko jy jz ka kp kc kd ke kq kg kh ki kj hb bi translated">注意:我们实现的函数的所有后续步骤都将在这些类下。</p></blockquote><h2 id="6324" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 4:创建预处理数据函数</h2><p id="481c" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">这个函数的目的是获取数据集中每个单词的 Id，这个 Id 将是数据集中每个单词的索引。</p><p id="4b68" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">预处理数据函数有两个参数:评论和标签，我们将创建一个<code class="du kr ks kt ku b">review_word</code>集合来存储评论中出现的所有单词，然后将这个集合转换成一个列表，以便于访问。</p><p id="32bf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这个 for 循环将遍历所有评论，对于每个评论，它将遍历其中的每个单词，并将其添加到一个集合中。使用<code class="du kr ks kt ku b">split(" ")</code>功能，每个评论将在每个空格后中断，以获得单个单词。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="6674" class="kw kx hi ku b fi ms mt l mu mv">class SentimentNetwork:<br/>    def pre_process_data(self, reviews, labels):<br/>        review_vocab = set()<br/>        <strong class="ku hj">for</strong> review <strong class="ku hj">in</strong> reviews:<br/>            <strong class="ku hj">for</strong> word <strong class="ku hj">in</strong> review.split(" "):<br/>                review_vocab.add(word)<br/>self.review_vocab = list(review_vocab)</span></pre><p id="d199" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">将对标签做同样的事情，但是这里我们不使用 split 函数，因为我们每行只有一个单词(积极的或消极的)。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="6347" class="kw kx hi ku b fi ms mt l mu mv">class SentimentNetwork:<br/>    def pre_process_data(self, reviews, labels):<br/>        review_word = set()<br/>        for review in reviews:<br/>            for word in review.split(" "):<br/>                review_word.add(word)<br/>        self.review_word = list(review_word)<br/>        <br/>        label_vocab = set()<br/>        <strong class="ku hj">for</strong> label <strong class="ku hj">in</strong> labels:<br/>            label_vocab.add(label)</span><span id="2856" class="kw kx hi ku b fi mw mt l mu mv">        self.label_vocab = list(label_vocab)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es my"><img src="../Images/7d8bb9c9f857ea79f130384901d2da60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*hwpHHELnxUZWWazFpLPA2Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">复习单词表</figcaption></figure><p id="2400" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后创建一个保存每个单词及其在列表中的位置的字典，这个循环将遍历每个单词，并使用它在列表中的索引将其转换为数字。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="36d2" class="kw kx hi ku b fi ms mt l mu mv">self.word2index = {}<br/>        <strong class="ku hj">for</strong> i, word <strong class="ku hj">in</strong> enumerate(self.review_vocab):<br/>            self.word2index[word] = i</span></pre><p id="aeee" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这就是<code class="du kr ks kt ku b">word_dictionary</code>的样子，一个单词和它的 id。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mz"><img src="../Images/f8c1d29cad52226291e9b6fa55fdf099.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*yQRJF5EMaYbCLSnQ0YtCuA.png"/></div></figure><p id="4134" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对标签做同样的事情。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="c571" class="kw kx hi ku b fi ms mt l mu mv">self.label2index = {}<br/>        <strong class="ku hj">for</strong> i, label <strong class="ku hj">in</strong> enumerate(self.label_vocab):<br/>            self.label2index[label] = i</span></pre><p id="f13f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这是类中函数的最终代码。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="14f7" class="kw kx hi ku b fi ms mt l mu mv">def pre_process_data(self, reviews, labels):<br/>        review_vocab = set()<br/>        <strong class="ku hj">for</strong> review <strong class="ku hj">in</strong> reviews:<br/>            <strong class="ku hj">for</strong> word <strong class="ku hj">in</strong> review.split(" "):<br/>                review_vocab.add(word)<br/><br/>        self.review_vocab = list(review_vocab)<br/>        <br/>        label_vocab = set()<br/>        <strong class="ku hj">for</strong> label <strong class="ku hj">in</strong> labels:<br/>            label_vocab.add(label)<br/>       <br/>        self.label_vocab = list(label_vocab)<br/>        <br/>       <br/>        self.word2index = {}<br/>        <strong class="ku hj">for</strong> i, word <strong class="ku hj">in</strong> enumerate(self.review_vocab):<br/>            self.word2index[word] = i<br/>        <br/>        self.label2index = {}<br/>        <strong class="ku hj">for</strong> i, label <strong class="ku hj">in</strong> enumerate(self.label_vocab):<br/>            self.label2index[label] = i</span></pre><h2 id="5383" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 5:初始化网络功能</h2><p id="7cd4" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">创建一个初始化网络中所有东西的函数，包括(输入节点、隐藏节点、输出节点、学习速率、第一层和权重)。</p><p id="f9b8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">下面我们初始化了输入、输出、隐藏节点和学习率，它们将被传递给类对象。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="2b48" class="kw kx hi ku b fi ms mt l mu mv">def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):<br/>       <br/>        self.input_nodes = input_nodes<br/>        self.hidden_nodes = hidden_nodes<br/>        self.output_nodes = output_nodes<br/>        <br/>        self.learning_rate = learning_rate</span></pre><p id="19ab" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">用 0 初始化输入和隐藏<code class="du kr ks kt ku b">self.weights_0_1</code>之间的权重，用随机值初始化隐藏和输出<code class="du kr ks kt ku b">self.weights_0_2</code>之间的权重。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="3c87" class="kw kx hi ku b fi ms mt l mu mv">self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))</span><span id="f143" class="kw kx hi ku b fi mw mt l mu mv">self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, <br/>                                                (self.hidden_nodes, self.output_nodes))</span></pre><p id="c9d4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">用零初始化连接到隐藏层的第一层。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="4db8" class="kw kx hi ku b fi ms mt l mu mv">self.layer_1 = np.zeros((1,hidden_nodes))</span></pre><p id="aeb4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这是初始化函数的完整代码。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="36dd" class="kw kx hi ku b fi ms mt l mu mv">def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):<br/>       <br/>        self.input_nodes = input_nodes<br/>        self.hidden_nodes = hidden_nodes<br/>        self.output_nodes = output_nodes<br/>        <br/>        self.learning_rate = learning_rate<br/>        <br/>        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))</span><span id="e8af" class="kw kx hi ku b fi mw mt l mu mv">self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, <br/>                                                (self.hidden_nodes, self.output_nodes))<br/>        <br/>        self.layer_1 = np.zeros((1,hidden_nodes))</span></pre><h2 id="6fd4" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 6:标记为二进制</h2><p id="6f77" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">一个小函数，它将正负标号转换成二进制数。正输出为 1，负输出为 0。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="1555" class="kw kx hi ku b fi ms mt l mu mv">def get_target_for_label(self,label):<br/>    if(label == 'POSITIVE'):<br/>        return 1<br/>    else:<br/>        return 0</span></pre><h2 id="a3c0" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 7: Sigmoid 函数及其导数</h2><p id="1ef8" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">在输出层，我们将使用一个 sigmoid 函数，我们可以使用下面的函数进行计算，我们还需要使用 sigmoid 计算导出输出的导数。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="b8eb" class="kw kx hi ku b fi ms mt l mu mv">def sigmoid(self,x):<br/>    return 1 / (1 + np.exp(-x))</span><span id="6660" class="kw kx hi ku b fi mw mt l mu mv">def sigmoid_output_2_derivative(self,output):<br/>        return output * (1 - output)</span></pre><h2 id="db17" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 8:实现培训功能(向前传递)</h2><p id="98a3" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">这是主函数，它将遍历所有数据集来更新权重和学习。</p><p id="466c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">当训练神经网络时，我们应该对数据进行两次传递(前向和后向传递),第一次传递是获得每个输入的输出，而后向传递是获得输出的误差，我们将使用该误差来更新权重。</p><p id="405a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这一步中，我们将向前传递，因此首先让我们定义函数并定义它的参数(训练数据检查和标签)。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="71d2" class="kw kx hi ku b fi ms mt l mu mv">def train(self, training_reviews_raw, training_labels):</span></pre><p id="b56e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，让我们为第一个列表创建一个列表列表，它将保存所有评论，在每个列表中，它将保存单个评论的所有单词。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="18ea" class="kw kx hi ku b fi ms mt l mu mv">training_reviews = list()<br/>    for review in training_reviews_raw:<br/>        indices = set()<br/>        for word in review.split(" "):<br/>            if(word in self.word_dictionary.keys()):<br/>                indices.add(self.word_dictionary[word])<br/>        training_reviews.append(list(indices))</span></pre><p id="cc2c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">初始化<code class="du kr ks kt ku b">correct_so_far = 0</code>以跟踪有多少输出是正确的，将在每次正确迭代后递增。</p><p id="7448" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，让我们循环查看所有训练数据，更新所有层的权重，并计算误差。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="1511" class="kw kx hi ku b fi ms mt l mu mv">for i in range(len(training_reviews)):<br/>    review = training_reviews[i]<br/>    label = training_labels[i]<br/>        <br/>    self.layer_1 *= 0<br/>    for index in review:<br/>       self.layer_1 += self.weights_0_1[index]</span><span id="1c94" class="kw kx hi ku b fi mw mt l mu mv">    layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))</span></pre><p id="69ce" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我解释一下上面的代码中发生了什么:</p><ul class=""><li id="63cb" class="lw lx hi jq b jr js ju jv jx ly kb lz kf ma kj mb mc md me bi translated">我们用零重置第一层节点。</li></ul><p id="16f1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><code class="du kr ks kt ku b">self.layer_1 *= 0</code></p><ul class=""><li id="0800" class="lw lx hi jq b jr js ju jv jx ly kb lz kf ma kj mb mc md me bi translated">现在，我们循环查看并获取每个单词的索引，这是它的 id，并用这些索引的权重更新第 1 层，这些权重来自第 0 层和隐藏层之间的权重，我们在第 4 步中初始化了这些权重。</li></ul><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="ef94" class="kw kx hi ku b fi ms mt l mu mv">for index in review:<br/> self.layer_1 += self.weights_0_1[index]</span></pre><ul class=""><li id="77a4" class="lw lx hi jq b jr js ju jv jx ly kb lz kf ma kj mb mc md me bi translated">现在，对于第 2 层的输出，我们使用 sigmoid 函数来计算它，我们在上面的步骤 6 中通过打点第 1 层和隐藏层与输出层之间的权重来实现该函数。</li></ul><p id="c9bb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><code class="du kr ks kt ku b">layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))</code></p><p id="15f2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">向前传球到此为止。</p><h2 id="2107" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">第九步:向后传球</h2><p id="d17e" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">在后向过程中，我们计算输出的误差，并更新<em class="kk">输入和隐藏层</em> <code class="du kr ks kt ku b">weights_0_1</code>之间的权重以及<em class="kk">隐藏和输出层</em> <code class="du kr ks kt ku b">weights_1_2</code>之间的权重。</p><ul class=""><li id="fb32" class="lw lx hi jq b jr js ju jv jx ly kb lz kf ma kj mb mc md me bi translated">首先:计算输出误差</li></ul><p id="4322" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">—输出错误是第 2 层的错误，我们通过从上一步<code class="du kr ks kt ku b">layer 2</code>得到的输出中减去输出的实际值(正或负)来计算，但我们不能用文本减去数值(正或负)，因此我们将使用我们在第 5 步中实现的函数，该函数将标签文本转换为二进制数。</p><p id="a1ea" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><code class="du kr ks kt ku b">layer_2_error = layer_2 — self.get_target_for_label(label)</code></p><p id="d566" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在将这些误差乘以层 2 的 sigmoid 的导数。</p><p id="3802" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><code class="du kr ks kt ku b">layer_2_delta = layer_2_error*self.sigmoid_output_2_derivative(layer_2)</code></p><ul class=""><li id="8cc4" class="lw lx hi jq b jr js ju jv jx ly kb lz kf ma kj mb mc md me bi translated">其次:计算隐含层误差</li></ul><p id="9689" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">—对于隐藏层，我们将使用从上一步获得的第 2 层增量，并将其与隐藏层和输出层之间的权重相乘。</p><p id="8761" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><code class="du kr ks kt ku b">layer_1_error = layer_2_delta.dot(self.weights_1_2.T)</code></p><p id="9dbf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因为我们没有在隐藏层中使用任何激活函数，所以层 1 增量将与错误相同。</p><p id="3808" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><code class="du kr ks kt ku b">layer_1_delta = layer_1_error</code></p><ul class=""><li id="06e4" class="lw lx hi jq b jr js ju jv jx ly kb lz kf ma kj mb mc md me bi translated">最后，让我们更新权重:</li></ul><p id="2aff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">—更新权重 _0_1:</p><p id="338e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">由于第 0 层对评论中的每个单词都有许多输入，因此我们将更新每个输入和隐藏神经元之间的权重。</p><p id="9552" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">所以让我们循环遍历每个单词，得到它的索引，用它来更新权重，然后乘以学习率。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="8fa2" class="kw kx hi ku b fi ms mt l mu mv">for index in review:<br/> self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate</span></pre><p id="a89b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">—更新权重 _1_2:</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="1b8e" class="kw kx hi ku b fi ms mt l mu mv">self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate</span></pre><p id="2465" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">—跟踪正确的输出:</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="e8d8" class="kw kx hi ku b fi ms mt l mu mv"><strong class="ku hj">if</strong>(layer_2 &gt;= 0.5 <strong class="ku hj">and</strong> label == 'POSITIVE'):<br/>                correct_so_far += 1<br/>            <strong class="ku hj">elif</strong>(layer_2 &lt; 0.5 <strong class="ku hj">and</strong> label == 'NEGATIVE'):<br/>                correct_so_far += 1</span></pre><p id="d0e6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们已经在每次迭代后更新了权重，训练在这里完成了。</p><h2 id="3651" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 10:运行和测试</h2><p id="c9c7" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">现在让我们实现一个函数<code class="du kr ks kt ku b">Run</code>，它接受输入<code class="du kr ks kt ku b">Review</code>并计算输出(在第 2 层)。</p><p id="0dca" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如我们在训练函数中所做的那样，我们获取评论并将其分成单词，然后获取每个单词的索引，并使用这些索引在第一层和隐藏层之间的权重中搜索其权重，以更新第一层。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="5d3c" class="kw kx hi ku b fi ms mt l mu mv"><strong class="ku hj">def</strong> run(self, review):<br/>self.layer_1 *= 0<br/>        unique_indices = set()<br/>        for word in review.lower().split(" "):<br/>            if word in self.word_index.keys():<br/>                unique_indices.add(self.word_index[word])<br/>        for index in unique_indices:<br/>            self.layer_1 += self.weights_0_1[index]</span></pre><p id="f3e4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，对于输出层，我们用隐藏层和输出层的权重点第 1 层，并将输出传递给 sigmoid 函数，我们得到输出。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="b0b1" class="kw kx hi ku b fi ms mt l mu mv">layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))</span></pre><p id="a4dd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">第二层应该根据类给我们 1 或 0，但肯定会有从 0 到 1 的误差，所以让我们说任何低于 0.5 的都是“0”，任何高于 0.5 的都是“1”。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="0d91" class="kw kx hi ku b fi ms mt l mu mv">if(layer_2[0] &gt;= 0.5):<br/>     return "POSITIVE"<br/>else:<br/>     return "NEGATIVE"</span></pre><p id="8d0d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于测试函数</p><h2 id="f94a" class="kw kx hi bd ky kz la lb lc ld le lf lg jx lh li lj kb lk ll lm kf ln lo lp lq bi translated">步骤 11:让我们运行这个网络</h2><p id="ae74" class="pw-post-body-paragraph jo jp hi jq b jr lr ij jt ju ls im jw jx lt jz ka kb lu kd ke kf lv kh ki kj hb bi translated">我们将从这个类创建一个对象，并传递这些参数(评论和标签、隐藏神经元的数量、学习速率)。</p><p id="1e2f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">并调用训练函数开始训练，通过点评和标签。</p><pre class="iy iz ja jb fd mo ku mp mq aw mr bi"><span id="52a7" class="kw kx hi ku b fi ms mt l mu mv">mlp = SentimentNetwork(reviews[:-1000],labels[:-1000],10,learning_rate=0.01)<br/>mlp.train(reviews[:-1000],labels[:-1000])</span></pre><p id="da4b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kk">我希望这篇博客能帮助你建立这个网络，并很好地理解神经网络是如何在幕后工作的。</em></p><p id="b360" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kk">让我知道你的反馈。感谢阅读！</em></p></div></div>    
</body>
</html>