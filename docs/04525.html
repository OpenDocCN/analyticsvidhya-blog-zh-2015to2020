<html>
<head>
<title>Integrating Scrapy with Flask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将刮刀与烧瓶整合</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/integrating-scrapy-with-flask-8611debc4579?source=collection_archive---------1-----------------------#2020-03-23">https://medium.com/analytics-vidhya/integrating-scrapy-with-flask-8611debc4579?source=collection_archive---------1-----------------------#2020-03-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/f48b3cf25b9c5927e69da9d1e3046645.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WbxX1oxa80l2yOLRbXiXeA.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">Pexels.com</figcaption></figure><div class=""/><blockquote class="iu iv iw"><p id="33db" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">Flask是Python的一个API，它允许我们构建web应用程序。Flask的框架比Django的框架更明确，也更容易学习，因为它实现一个简单的web应用程序的基础代码更少。</p></blockquote><p id="f98b" class="pw-post-body-paragraph ix iy hx ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv hb bi translated">在本文中，我们将看到如何将scrapy集成到FLASK中来抓取任何网站，并构建一个web表单，这样只需单击一个按钮，整个Scrapy代码就会启动并运行，并将抓取的数据返回给我们。</p><p id="7ad7" class="pw-post-body-paragraph ix iy hx ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv hb bi translated">这篇文章是我上一篇文章的续篇，在那篇文章中，我解释了如何使用产品URL抓取亚马逊评论，但如果你有自己的scrapy项目，并想学习如何将其与flask合并，那么你也很适合，因为基本结构几乎是相同的。</p><p id="9cb0" class="pw-post-body-paragraph ix iy hx ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv hb bi translated">最后给出了该项目的工作演示。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><blockquote class="iu iv iw"><p id="e601" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">步伐</p></blockquote><ol class=""><li id="6518" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv km kn ko kp bi translated"><em class="iz">制定项目结构。</em></li><li id="6865" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv km kn ko kp bi translated"><em class="iz">创建一个HTML表单。</em></li><li id="bdf2" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv km kn ko kp bi translated"><em class="iz">修改了之前</em> <a class="ae jz" rel="noopener" href="/analytics-vidhya/web-scraping-a-to-z-using-scrapy-6ece8b303793"> <em class="iz">条</em> </a> <em class="iz">中的刺儿头代码。</em></li><li id="c0d4" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv km kn ko kp bi translated"><em class="iz">用刮刀连接烧瓶。</em></li></ol><blockquote class="iu iv iw"><p id="d133" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">流程图</p></blockquote><figure class="kw kx ky kz fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kv"><img src="../Images/df308320d7a7d3bf826a2adc1478fe63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pJzQ3wKefuQahuhO8FUIFw.jpeg"/></div></div></figure><h1 id="ffcd" class="la lb hx bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">我们开始吧</h1><blockquote class="iu iv iw"><p id="c8ef" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">建立项目结构</p></blockquote><ul class=""><li id="a657" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv ly kn ko kp bi translated">让我们首先创建一个名为“Scraping”的项目文件夹，并在该文件夹中添加我们在<a class="ae jz" rel="noopener" href="/analytics-vidhya/web-scraping-a-to-z-using-scrapy-6ece8b303793">上一篇文章</a>中创建的教程文件夹(Scrapy项目文件夹)。</li><li id="3b32" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">现在在这个抓取文件夹中创建一个名为“main.py”的python文件，它将是我们的主FLASK文件。</li><li id="719f" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">现在，在同一个抓取文件夹中创建一个名为“templates”的文件夹，其中包含一个名为“index.html”的HTML文件</li><li id="f93a" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">完成这些步骤后，项目结构应该是这样的，</li></ul><figure class="kw kx ky kz fd hk er es paragraph-image"><div class="er es lz"><img src="../Images/4d79782e1df74fed385f59c2f2d4079d.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*eDs6IZFjgcs1kqWauEahpA.jpeg"/></div></figure><blockquote class="iu iv iw"><p id="8b0e" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">创建HTML表单</p></blockquote><ul class=""><li id="5010" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv ly kn ko kp bi translated">因此，在编写主要的FLASK代码之前，让我们先创建一个HTML表单，稍后我们将把它连接到FLASK。</li><li id="0e85" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">进入index.html文件，为我们的基本HTML表单添加以下代码。在后面的步骤中，我们将把这个表单连接到我们的主Flask代码。</li></ul><figure class="kw kx ky kz fd hk"><div class="bz dy l di"><div class="ma mb l"/></div></figure><blockquote class="iu iv iw"><p id="5f3e" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">更新Scrapy代码</p></blockquote><ul class=""><li id="0f84" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv ly kn ko kp bi translated">现在，我们将更新我在之前的<a class="ae jz" rel="noopener" href="/analytics-vidhya/web-scraping-a-to-z-using-scrapy-6ece8b303793">文章</a>中解释的Scrapy代码，以获取输入的URL并在其上进行抓取。</li><li id="8a95" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">对于有自己不同的scrapy项目的读者，你也应该参考这段代码，看看如何将URL作为输入，因为稍后我们会将URL从flask传入其中。</li><li id="51af" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">转到“amazon_scarping.py”文件(包含主碎片代码的文件)和类ReviewspiderSpider(主碎片类)中，并在parse函数前添加以下代码。</li></ul><figure class="kw kx ky kz fd hk"><div class="bz dy l di"><div class="ma mb l"/></div></figure><blockquote class="iu iv iw"><p id="8925" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">书写烧瓶代码</p></blockquote><ul class=""><li id="6c50" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv ly kn ko kp bi translated">现在进入main.py文件并导入以下库</li></ul><figure class="kw kx ky kz fd hk"><div class="bz dy l di"><div class="ma mb l"/></div></figure><ul class=""><li id="1cd7" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv ly kn ko kp bi translated">注意:如果您还没有安装这些库，那么您应该首先使用pip从您的终端安装这些库。</li><li id="7317" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">要安装所需的库，进入您的终端并运行，</li></ul><pre class="kw kx ky kz fd mc md me mf aw mg bi"><span id="d1f0" class="mh lb hx md b fi mi mj l mk ml">pip install crochet<br/>pip install flask<br/>pip install scrapy</span></pre><ul class=""><li id="87e6" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv ly kn ko kp bi translated">现在，我们将定义基本的Flask结构，从表单中获取链接，并将其存储在myBaseUrl变量中。</li><li id="9efa" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">获得链接后，我们将把它传递给下一步中提到的抓取函数，并将抓取的数据存储到output_data列表中，并返回jsonified输出。</li></ul><figure class="kw kx ky kz fd hk"><div class="bz dy l di"><div class="ma mb l"/></div></figure><ul class=""><li id="47b7" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv ly kn ko kp bi translated">现在我们将定义两个函数，其中的代码将迭代，直到整个抓取过程完成。</li><li id="4b72" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">首先，scrape_with_crochet函数将连接到dispatcher，这将有助于维护该循环。</li><li id="3df2" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">现在，代码将转到内置的scrapy crawl_runner函数，对于scrapy文件中的每个yield响应，控件将转到crawl_result函数，并将该项追加到output_data列表中。</li></ul><figure class="kw kx ky kz fd hk"><div class="bz dy l di"><div class="ma mb l"/></div></figure><p id="d19f" class="pw-post-body-paragraph ix iy hx ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv hb bi translated">就这样，我们结束了！</p><blockquote class="iu iv iw"><p id="e7b3" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">运行项目</p></blockquote><ul class=""><li id="bc82" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv ly kn ko kp bi translated">从您的终端，进入刮擦文件夹目录并运行，</li></ul><pre class="kw kx ky kz fd mc md me mf aw mg bi"><span id="1a2f" class="mh lb hx md b fi mi mj l mk ml">python main.py</span></pre><ul class=""><li id="6075" class="kh ki hx ja b jb jc jf jg jw kj jx kk jy kl jv ly kn ko kp bi translated">现在转到运行项目的本地主机地址，例如<a class="ae jz" href="http://127.0.0.1:5000/" rel="noopener ugc nofollow" target="_blank"> http://127.0.0.1:5000/ </a></li><li id="1270" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">在表单中输入任何亚马逊产品的URL，然后点击分析评论按钮，之后，您将在您的页面上看到抓取的数据。</li><li id="fb99" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">您的整个抓取的数据文件存储在教程文件夹中。</li></ul><blockquote class="iu iv iw"><p id="f9b6" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">完整代码</p></blockquote><figure class="kw kx ky kz fd hk"><div class="bz dy l di"><div class="ma mb l"/></div></figure><blockquote class="iu iv iw"><p id="d354" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">最终作品</p></blockquote><p id="68f1" class="pw-post-body-paragraph ix iy hx ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv hb bi translated">这是最终项目的运作方式，</p><figure class="kw kx ky kz fd hk er es paragraph-image"><div class="er es mm"><img src="../Images/caebae04c8a00948f5c07cbf5b7cc82e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*ICXlGcdeAGcjzuQ8IgUpaQ.gif"/></div></figure><h1 id="0f6d" class="la lb hx bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">结论</h1><ul class=""><li id="d7b8" class="kh ki hx ja b jb mn jf mo jw mp jx mq jy mr jv ly kn ko kp bi translated">因此，我们将整个Scrapy代码与Flask集成在一起，这样只需点击一个按钮，整个产品评论数据就会被抓取并存储在一个JSON文件中。</li><li id="4978" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">现在在这个项目中发生的是，每当你抓取一个链接时，它的数据被存储在一个列表中并显示出来，但当你用相同的链接重新运行代码时，它将再次执行整个抓取过程，这是非常低效的。</li><li id="8788" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">这就是为什么在<a class="ae jz" rel="noopener" href="/analytics-vidhya/connecting-scrapy-to-mysql-database-in-flask-256adc70b321">的下一篇文章</a>中，我解释了如何创建一个<strong class="ja hy">数据库</strong>并将我们抓取的数据存储在其中，当用户输入一个URL时，我们的代码将首先检查它是否已经被抓取，如果是，它将从数据库中获取数据，而不是再次抓取。</li><li id="284b" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">欢迎在评论区提出你对这篇文章的疑问。</li><li id="08ac" class="kh ki hx ja b jb kq jf kr jw ks jx kt jy ku jv ly kn ko kp bi translated">在<a class="ae jz" href="https://www.linkedin.com/in/rohan-goel-b0a6ab160/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上和我联系。</li></ul></div></div>    
</body>
</html>