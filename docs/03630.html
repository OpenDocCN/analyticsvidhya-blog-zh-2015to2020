<html>
<head>
<title>Auto Price Prediction from Scratch! Part 2: Data Collection and Cleaning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">汽车价格预测从零开始！第2部分:数据收集和清理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/auto-price-prediction-from-scratch-part-2-data-collection-and-cleaning-a147b6375b2f?source=collection_archive---------15-----------------------#2020-02-11">https://medium.com/analytics-vidhya/auto-price-prediction-from-scratch-part-2-data-collection-and-cleaning-a147b6375b2f?source=collection_archive---------15-----------------------#2020-02-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/f5c3bd266490da7f12a77a3ee5043fbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*srTC_yVMOsaINU3H-ZPI7A.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="1854" class="pw-subtitle-paragraph iq hs ht bd b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh dx translated">用Scrapy提取数据</h2></div><p id="6ba0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">我们想预测汽车价格。但是，我们没有数据。没什么。所以让我们建立自己的数据集吧！我们会用Scrapy提取网页数据。Scrapy是一个Python网页抓取工具，具有快速的性能。</p><p id="2527" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这是<a class="ae ke" rel="noopener" href="/analytics-vidhya/auto-price-prediction-from-scratch-part-1-overview-a4f331aaad00"> <strong class="jk hu">第一部分:概述</strong> </a>的延续。</p><h2 id="3d41" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">杂乱无章的新项目</h2><p id="2727" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated"><em class="lf">需求:</em>使用Scrapy 1 . 6 . 0版本，谷歌Chrome，VS代码。在VS代码中，我们可以在代码编辑器、终端和Python环境中的文件之间轻松切换。该项目应该在一个隔离的Python环境中完成，以避免软件版本冲突。阅读本文和查看代码时，最好使用两个屏幕。</p><p id="c110" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">Python环境中的Open VS代码。在终端中，导航到项目所需的文件夹位置。终端命令<code class="du lg lh li lj b">scrapy startproject craigslist_scrapy</code>将创建项目，包括文件夹和支持文件。我们在下面的资源管理器窗格中看到支持文件。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lk"><img src="../Images/279023f755023a9dd7f5525bcbad3c75.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*Pr9UCMJN9xhtTYMe6hyOPA.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">杂乱的项目文件。蜘蛛文件命名为clspider.py。</figcaption></figure><p id="866c" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">进入文件夹:<code class="du lg lh li lj b">cd craigslist_scrapy</code>。通过键入<code class="du lg lh li lj b">scrapy genspider clspider elpaso.craigslist.org</code>创建蜘蛛。这将使用classClspiderSpider()创建clspider.py，并将URL插入到类中。</p><p id="11f3" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">打开clspider.py，我们看到URL将蜘蛛指向该网站，并且仅指向该网站。</p><p id="ea71" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">将<strong class="jk hu"> start_url </strong>编辑为<code class="du lg lh li lj b"><a class="ae ke" href="https://elpaso.craigslist.org/search/cta?auto_make_model=ford" rel="noopener ugc nofollow" target="_blank">https://elpaso.craigslist.org/search/cta?auto_make_model=ford</a></code>。CraigsList最多返回3000个结果，不管有没有过滤器。我们将只查询福特，因此我们将获得每个福特型号的许多样品。</p><h2 id="2c0f" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">机器人和刮擦许可</h2><p id="c894" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">在抓取之前，请检查<em class="lf"> robots.txt </em>以确认允许抓取。该文件位于域名下方。在下面的example.com中，通配符意味着所有用户代理爬虫都是允许的。但是，某些文件夹禁止爬行。例如，<code class="du lg lh li lj b">www.example.com/reply</code>和回复子文件夹不能被抓取。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lt"><img src="../Images/37c580f8559b0d4d250696d36c26d472.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*dIESifupCeuxMtZ4dzrHMw.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">尊重robots.txt权限！</figcaption></figure><p id="9b48" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这里的刮擦是出于教育目的。获得书面许可来收集大量数据或为公司收集数据。</p><h2 id="0c67" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">蜘蛛代码</h2><p id="c723" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">下面是蜘蛛的完整代码:clspider.py。在与本文并排的新窗口中打开它。</p><figure class="ll lm ln lo fd hk"><div class="bz dy l di"><div class="lu lv l"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">在此要点的底部，右键单击clspider.py以在新窗口中打开要点。</figcaption></figure><p id="7306" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在谷歌浏览器中，查看<code class="du lg lh li lj b"><a class="ae ke" href="https://elpaso.craigslist.org/search/cta?auto_make_model=ford" rel="noopener ugc nofollow" target="_blank">https://elpaso.craigslist.org/search/cta?auto_make_model=ford</a></code>的搜索结果。我们在第一页上看到120个列表，然后在第二页上又看到120个，以此类推。如果你点击一个链接，这将把你带到汽车的详细广告，我们称之为“列表”或汽车网址。车辆URL包含我们想要提取的数据。</p><div class="ll lm ln lo fd ab cb"><figure class="lw hk lx ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/0431e2426c8f49da8eb2e9d0b37d6f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*GIdSMzDvNmDMvrnWw1R-UA.png"/></div></figure><figure class="lw hk mc ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/8c0b9f72a24625fb92995ca435313651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*XMKV3I46z45QLC2nU37cIQ.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx md di me mf translated">搜索结果第1和第2页。</figcaption></figure></div><p id="eac0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">现在我们对程序流程有了一个概念。我们需要第1页上的120个车辆网址，第2页上的120个车辆网址，等等。对于“all_vehicles”第1页中的每个URL，解析出数据。然后，请求第2页并重复。请求新页面，直到我们用完页面(上限为3000/120 = 25页)。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es mg"><img src="../Images/750a74ec76c9ee3c80514fc54b90b5a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*FYS-im7JvdqyktOEnjP5KQ.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">结果-行。第一行被展开，以显示蓝色框中的列表URL。</figcaption></figure><p id="d85e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">clspider.py实现了这个流。第15行将页面上120个结果的HTML保存到“all_vehicles”。</p><p id="32b7" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">查看“Result-rows”图片，查看URL的HTML格式。</p><p id="ac15" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">第17–18行遍历每个结果，只获取车辆URL。第18行中，<code class="du lg lh li lj b">vehicle.xpath(‘.//a/@href’)</code>是什么？</p><p id="fb09" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">对于刚接触蜘蛛的程序员来说——就像我一样——最具挑战性的部分是使用回调和XPath。</p></div><div class="ab cl mh mi gp mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="hb hc hd he hf"><h2 id="260b" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">复试</h2><p id="7b02" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">让我们回顾一下回调机制。在clspider.py的第19行，我们<strong class="jk hu">请求</strong>URL“vehicle _ URL”并下载HTML作为<strong class="jk hu">响应</strong>对象。请求和响应是内置的战斗能力。</p><p id="33db" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">下载响应对象后，调用回调函数parse_vehicle。回调函数获取响应作为第一个参数，然后函数运行。我们从响应对象的HTML中解析价格等特性。</p><h2 id="ef68" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">XPath</h2><p id="da77" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">XPath是一种用于在XML文档中选择节点的查询语言。以下是基本格式:</p><blockquote class="mo"><p id="1ae8" class="mp mq ht bd mr ms mt mu mv mw mx kd dx translated">element =//nodename[@ attribute = ' value ']</p></blockquote><ul class=""><li id="2d14" class="my mz ht jk b jl na jo nb jr nc jv nd jz ne kd nf ng nh ni bi translated"><code class="du lg lh li lj b">//</code>是节点的相对路径。与绝对路径相比，它对元素的完整现有路径中所做的更改具有弹性。</li><li id="b458" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><code class="du lg lh li lj b">nodename</code>是特定节点的标记名。示例包括:img、div或title。</li><li id="5084" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><code class="du lg lh li lj b">@</code>选择具有一定值的节点属性。例如，属性<em class="lf">类</em>有一个值<em class="lf">价格</em> : <code class="du lg lh li lj b">@class=”price”</code>。</li></ul><p id="fcc8" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">XPath查询语言还有很多功能。我们将使用这本入门书来实验在Chrome浏览器中选择网页节点。</p><h2 id="abf4" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">用XPath提取数据</h2><p id="9a00" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">通过找到有效的XPath并在scrapy中测试来查询价格。使用XPaths时使用Google Chrome浏览器。其他浏览器可能无法成功搜索XPath。</p><ol class=""><li id="e24c" class="my mz ht jk b jl jm jo jp jr no jv np jz nq kd nr ng nh ni bi translated">转到自动列表页面。点击Ctrl-Shift+C在“检查元素”模式下打开Chrome，鼠标悬停在价格上。在元素检查器中，我们应该看到<code class="du lg lh li lj b">&lt;span class="price"&gt;$5950&lt;/span&gt;</code>以蓝色着色。</li><li id="7258" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nr ng nh ni bi translated">按Ctrl-F在元素检查器中搜索HTML，并键入以下XPath: <code class="du lg lh li lj b">//span[@class=”price”]</code>按enter进行搜索。</li><li id="6419" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nr ng nh ni bi translated">找到价格节点——黄色阴影！再按几次enter键，验证它是我们匹配的唯一节点。</li></ol><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ns"><img src="../Images/ae732001d3db2eab4f3a909f2504ae54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M03g4lcQwAUoWIbHrzsiNg.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">XPath，<strong class="bd kh"> //span[@class="price"] </strong>，查询价格节点。</figcaption></figure><p id="d9ef" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">测试price XPath以确认它能与scrapy一起工作。在VS代码中用“+”打开一个新的终端，并输入<code class="du lg lh li lj b">scrapy shell "my_URL”</code>。将车辆URL放在双引号中。shell是一个交互式测试环境，包含URL的响应对象。</p><p id="ef2d" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">接下来，使用价格XPath选择价格数据节点:</p><p id="fef9" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lg lh li lj b"><strong class="jk hu">In[1]:</strong> response.xpath(‘//span[@class=”price”]’)</code></p><p id="c92b" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lg lh li lj b"><strong class="jk hu">Out[1]:</strong> [&lt;Selector xpath=’//span[@class=”price”]’ data=’&lt;span class=”price”&gt;$5950&lt;/span&gt;’&gt;]</code></p><p id="d5c8" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">上面，我们看到返回了xpath和HTML数据。但是，我们想要的只是价格文本“5950美元”。<strong class="jk hu"> text() </strong>返回文本并省略HTML，如下所示。</p><p id="26e5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lg lh li lj b"><strong class="jk hu">In[2]:</strong> response.xpath(‘//span[@class=”price”]/<strong class="jk hu">text()</strong>’)</code></p><p id="8c4f" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lg lh li lj b"><strong class="jk hu">Out[2]:</strong> [&lt;Selector xpath=’//span[@class=”price”]/text()’ data=’$5950'&gt;]</code></p><p id="58df" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">剩下的就是<code class="du lg lh li lj b">data=’$5950'</code>。Scrapy有内置的“选择器”来解析数据。选择器extract_first()或get()将返回第一个匹配项。</p><p id="1fa5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lg lh li lj b"><strong class="jk hu">In[3]:</strong> response.xpath(‘//span[@class=”price”]/text()’).extract_first()</code></p><p id="58a9" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lg lh li lj b"><strong class="jk hu">Out[3]:</strong> ‘$5950’</code></p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es nt"><img src="../Images/faa15cf1ad9d750f099b25b5944bac86.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*ng4IDKbdeqV4awdlCdktLg.jpeg"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">使用XPath技能我们还能做什么？</figcaption></figure><p id="5647" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">答对了。只返回“$5950”。我们现在有了从CraigsList汽车列表中查询价格的工作代码。</p><p id="784b" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">注意只有XPath <code class="du lg lh li lj b">//span[@class=”price”]</code>在Chrome搜索中有效。我们添加到XPath的函数text()和extract_first()在scrapy中工作。</p><h2 id="a1d8" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated"><strong class="ak">蜘蛛的数据提取代码</strong></h2><p id="6002" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">我们查看汽车列表，并决定提取以下原始特征:URL_Vehicle、Title、Price、SubLoc、Body、AttribDictionary和ImageDictionary。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nu"><img src="../Images/96a048bb0814bfe05600ef2342eb1fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2HmT0JOo2361XRujUexe0Q.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">福特野马GT的自动列表。</figcaption></figure><p id="7caf" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">要刮除的原始特征:</strong></p><ul class=""><li id="fbbf" class="my mz ht jk b jl jm jo jp jr no jv np jz nq kd nf ng nh ni bi translated"><strong class="jk hu"> URL_Vehicle </strong>是特定列表的网址。</li><li id="bc26" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><strong class="jk hu">标题</strong>是图片上方的大号粗体文本。</li><li id="0bbe" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><strong class="jk hu">价格</strong>嵌入<strong class="jk hu">标题</strong>。</li><li id="17e4" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><strong class="jk hu"> SubLoc </strong>是标题中价格后的任何文字，如“(埃尔帕索)”。</li><li id="e3a1" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><strong class="jk hu">正文</strong>是照片下方的无结构文字。</li><li id="797c" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><strong class="jk hu"> AttribDictionary </strong>包含某些车辆属性。</li><li id="45d5" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><strong class="jk hu"> ImageDictionary </strong>是图片URL(不下载图片)。</li></ul><p id="0ecb" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">clspider.py的第29–32行用适当的XPath获取我们的特性并保存到变量中。对于车辆属性，每个列表有许多属性。字典捕获属性(第34–39行)。此外，字典捕获图像URL。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es nv"><img src="../Images/977cb7586d983253485e78cfedc4bb5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*BgNs-4nW3Bx0T3b6KgfkOQ.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">AttribDictionary的属性。它们因上市而异。</figcaption></figure><p id="13f4" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">第40–48行将特性变量AttribDictionary和ImageDictionary插入到主字典中。</p><h2 id="c4d9" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">爬行蜘蛛</h2><p id="1e58" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">我们在clspider.py中有完整的蜘蛛代码，在原终端(不是scrapy shell terminal 2)中键入<code class="du lg lh li lj b">scrapy crawl clspider -o elpaso.json</code>运行蜘蛛。蜘蛛将运行许多秒，解析清单。主字典作为<code class="du lg lh li lj b">elpaso.json</code>写入磁盘。请在几秒钟后用Ctrl-C停止蜘蛛，改为在此下载数据<a class="ae ke" href="https://github.com/jkmackie/car_price_prediction/tree/master/json" rel="noopener ugc nofollow" target="_blank">。或者，克隆</a><a class="ae ke" href="https://github.com/jkmackie/car_price_prediction" rel="noopener ugc nofollow" target="_blank">回购</a>。</p><p id="6be6" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">下面显示了JSON文件。在VS代码编辑器中打开它，并点击<strong class="jk hu"> Shift-Alt-F </strong>以下面更易读的格式查看它。这可能需要几秒钟。回想一下<a class="ae ke" rel="noopener" href="/analytics-vidhya/auto-price-prediction-from-scratch-part-1-overview-a4f331aaad00"> <strong class="jk hu">第1部分</strong> </a>我们正在处理一个混乱的数据结构。例如，模型“野马”嵌入在标题中。没有人给我们交钥匙数据集-我们必须自己建立它！</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es nw"><img src="../Images/9b383374564bc604b8c38049b91fd33e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*wBE2LcQwwzCgTrNYyoz5sw.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">混乱的数据结构</figcaption></figure><p id="7082" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这将我们带到项目的下一个阶段——从JSON中提取有意义的特性。</p></div><div class="ab cl mh mi gp mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="hb hc hd he hf"><h1 id="437c" class="nx kg ht bd kh ny nz oa kl ob oc od kp iz oe ja ks jc of jd kv jf og jg ky oh bi translated">特征抽出</h1><p id="9381" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">概括一下，我们在CraigsList上搜索了待售的福特<strong class="jk hu">轿车+卡车。数据被保存为JSON格式。接下来，我们将从JSON中提取特性来预测价格。</strong></p><p id="2e08" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">建立准确和完整的特征需要反复试验。Jupyter笔记本是为快速代码原型设计的。我们将用它来提取数据。<strong class="jk hu">熊猫</strong>用于数据操作。</p><p id="b0d3" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">预处理亮点将在这里讨论。有关完整的预处理细节，请查看GitHub上的<a class="ae ke" href="https://github.com/jkmackie/car_price_prediction/tree/master/jupyter_notebooks" rel="noopener ugc nofollow" target="_blank"> car_preproc_final.ipynb </a>。</p><p id="ee95" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">Pandas包含了一个方便的方法<code class="du lg lh li lj b">read_json</code>，可以将我们的JSON导入到DataFrame中:</p><pre class="ll lm ln lo fd oi lj oj ok aw ol bi"><span id="e406" class="kf kg ht lj b fi om on l oo op">#Import JSON to Pandas DataFrame.</span><span id="63e7" class="kf kg ht lj b fi oq on l oo op">import pandas as pd<br/>vehicle = pd.read_json(‘elpaso.json’)</span></pre><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es or"><img src="../Images/50c0df9fcd00c54e707b909a645a876f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9RNQlDJee8dEFTW94ezyJQ.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">JSON数据加载到车辆数据帧中</figcaption></figure><p id="44bc" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">前面，我们看到模型“野马”是标题的一部分。它也嵌入在AttribDictionary中。无论哪种情况，我们都需要从字符串中提取一个字符串。幸运的是，正则表达式是完成这项任务的强大工具。正则表达式模式为可能匹配的字符串集指定规则。</p><p id="3887" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">函数<code class="du lg lh li lj b">match_regex_patt</code>从数据帧中的<code class="du lg lh li lj b">target_col</code>中提取正则表达式匹配。重要的是，匹配时忽略大小写。此外，成功的不区分大小写的匹配是小写的。为什么？该算法应该将“f-150”、“f150”、“F150”和“F-150”视为相同的汽车类别。同样，“150000”、“150K”、“150k”、“15万”都是一样的车里程。</p><p id="a016" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这种不一致性是真实世界特征提取挑战的一个缩影。房源是很多人写的；没有标准格式或保证某个特征(例如里程表)将被包括在内！</p><figure class="ll lm ln lo fd hk"><div class="bz dy l di"><div class="lu lv l"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">将正则表达式匹配作为Python列表返回</figcaption></figure><p id="87d6" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这是一个用正则表达式提取特征的基本例子。从<strong class="jk hu"> URL_Vehicle </strong>列提取车辆位置:</p><pre class="ll lm ln lo fd oi lj oj ok aw ol bi"><span id="dee8" class="kf kg ht lj b fi om on l oo op">#Get vehicle Location from URL location.craigslist.org</span><span id="4880" class="kf kg ht lj b fi oq on l oo op">vehLocList = match_regex_patt(df=vehicle, target_col='URL_Vehicle',\ regex_patt='<a class="ae ke" rel="noopener ugc nofollow" target="_blank" href="/(.+)/.craigslist',">https://(.+)\.craigslist',</a> no_match_value='None')</span><span id="89ac" class="kf kg ht lj b fi oq on l oo op">vehicle['Location'] = vehLocList</span></pre><p id="f304" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">让我们回顾一下正则表达式模式的含义:</p><p id="7428" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lg lh li lj b">‘<a class="ae ke" rel="noopener ugc nofollow" target="_blank" href="/(.+)/.craigslist',">https://(.+)\.craigslist'</a></code></p><p id="8fd2" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">捕获组是括号内的内容。输入字符串的这一部分被保存到一个可被引用的编号组中。捕获组中有一个句号和一个加号。句点表示除新行之外的任何字符。加号表示一个或多个。</p><p id="8496" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在捕获组之外，我们搜索字符串<code class="du lg lh li lj b">“https://”</code>和<code class="du lg lh li lj b">“.craigslist”</code>。<code class="du lg lh li lj b">“\.”</code>逃避了时期的特殊含义。我们想要匹配“city.craigslist”中的<em class="lf">文字句点</em>。</p><p id="d1f0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">正则表达式一开始看起来很奇怪。对于更高级的搜索需求，比如提取模型的模式(<code class="du lg lh li lj b">r’ford\s(\w+-{0,1}\S+)’</code>)，搜索答案通常是无效的。花在正则表达式教程或学习上的时间是值得的。相信我，这是我的经验之谈！</p><h1 id="03f4" class="nx kg ht bd kh ny os oa kl ob ot od kp iz ou ja ks jc ov jd kv jf ow jg ky oh bi translated">清洁</h1><h2 id="bd59" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">删除重复项</h2><p id="d9d3" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">在<a class="ae ke" rel="noopener" href="/analytics-vidhya/auto-price-prediction-from-scratch-part-1-overview-a4f331aaad00"> <strong class="jk hu">第一部分</strong> </a>中，阐述了重复数据对模型泛化的影响。假设我们在火车上装上复制品。接下来，我们在所谓的“看不见的”维持数据中预测<em class="lf">相同的副本</em>。在这种情况下，模型性能被夸大了。所以重复的必须被删除。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ox"><img src="../Images/84b1c50fb8284f8d28b4e60b33ecf2a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K21cC7Mv-DAJobrB2iFx-w.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">重复列表:不同URL上的相同VIN。</figcaption></figure><p id="12b3" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">以下是删除重复项的几种方法。为每辆车创造一个独特的特征。每辆车都有独特的识别码。因此，如果我们在不同的列表中看到相同的VIN，我们知道该汽车是重复的。当然，这只有在VIN可用的情况下才有效！</p><p id="7a1c" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">另一种技术是标记可疑的相似列表。如果它与另一个有相同的标题、里程表读数和价格，它很可能是一个复制品。</p><pre class="ll lm ln lo fd oi lj oj ok aw ol bi"><span id="8617" class="kf kg ht lj b fi om on l oo op">#Keep only the first in a set of duplicates.  Drop the rest.</span><span id="db77" class="kf kg ht lj b fi oq on l oo op">vehicle.drop_duplicates(subset=['Title', 'Odometer', 'Price'], inplace=True)</span></pre><h2 id="3503" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">放弃不好的观察</h2><p id="31f9" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">我们的真实世界数据相当混乱。甚至我们的目标变量价格也经常丢失。让我们去掉缺失的价格。</p><pre class="ll lm ln lo fd oi lj oj ok aw ol bi"><span id="ef25" class="kf kg ht lj b fi om on l oo op"><strong class="lj hu">#Price is missing, None, or blank.  Drop corresponding rows.</strong></span><span id="9b75" class="kf kg ht lj b fi oq on l oo op">filt = (vehicle['Price'].isna()) | (vehicle['Price'] == 'None') | (vehicle['Price'] == '')</span><span id="a950" class="kf kg ht lj b fi oq on l oo op">drop_indices = vehicle[filt].index<br/>print(f'Drop missing price rows:', drop_indices)<br/>vehicle.drop(index = drop_indices, inplace = True, errors = 'ignore')</span><span id="2a9e" class="kf kg ht lj b fi oq on l oo op"><strong class="lj hu">#Output:</strong><br/>Drop missing price rows: Int64Index([   12,    15,    33,    44,    45,    46,    63,    64,    81,   84,<br/>            ...<br/>20999, 21013, 21014, 21023, 21033, 21035, 21041, 21047, 21060, 21062], dtype='int64', length=2392)</span></pre><p id="d51f" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">缺失的价格被删除，而不是被估算。或者，缺失的价格可以用平均价格代替。因为可以收集更多的数据，而且这是我们的目标变量，所以丢失的价格被删除。</p><p id="7d10" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">可能是真正异常值的异常可以被丢弃。这改变了模型拟合，并可能影响最佳得分所需的正则化强度。小心地剔除真正的异常值可能会显著提高分数。以下是通常在VIN研究后发现的一些异常情况(粗体索引):</p><ul class=""><li id="d91d" class="my mz ht jk b jl jm jo jp jr no jv np jz nq kd nf ng nh ni bi translated">1997年的7504不是民用汽车，而是起重机。</li><li id="d74d" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><strong class="jk hu"> 7413 </strong>从2017年开始使用，但列在新的管理建议项目之上。</li><li id="aba9" class="my mz ht jk b jl nj jo nk jr nl jv nm jz nn kd nf ng nh ni bi translated"><strong class="jk hu"> 1991 </strong>因意外低价。同样适用于<strong class="jk hu"> 13843 </strong>。</li></ul><p id="ccde" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">前两个项目符号是离群值，可以删除。第三点中的价格异常是噪音的来源。我们怎样才能做得更好？事实证明，添加“残骸”特征改进了模型。残骸标志可以通过关键字搜索识别的受损汽车的子集。在下一篇文章中会有更多的介绍。</p><h1 id="ec4e" class="nx kg ht bd kh ny os oa kl ob ot od kp iz ou ja ks jc ov jd kv jf ow jg ky oh bi translated">结论</h1><p id="2660" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">我们已经走了很长的路！我们从CraigsList中提取JSON数据，创建整齐的特征，并为机器学习模型清理数据。这些是我们从零开始预测汽车价格的关键步骤。</p><p id="bc5f" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这个四部分系列的下一篇文章，<a class="ae ke" rel="noopener" href="/@jmackie_13883/auto-price-prediction-from-scratch-part-3-feature-engineering-a903e2509643"> <strong class="jk hu">第3部分:特性工程</strong> </a>，将涵盖被忽视的特性工程技术！</p></div><div class="ab cl mh mi gp mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="hb hc hd he hf"><p id="c837" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><em class="lf">我欢迎反馈！联系我的最好方式是发表评论。在LinkedIn上私信我:</em><a class="ae ke" href="http://www.linkedin.com/in/justinmackie" rel="noopener ugc nofollow" target="_blank">【http://www.linkedin.com/in/justinmackie】T21</a></p><h2 id="2cae" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated"><strong class="ak">尾注:</strong></h2><p id="e154" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">[1]确保您处于安装scrapy的隔离Python环境中。</p><p id="f749" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">[2] extract_first()在以前的scrapy版本中有效，包括1.6.0。</p></div></div>    
</body>
</html>