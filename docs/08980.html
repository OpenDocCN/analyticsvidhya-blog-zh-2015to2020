<html>
<head>
<title>Implementing CNN in PyTorch with Custom Dataset and Transfer Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用定制数据集和迁移学习在PyTorch中实现CNN</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc?source=collection_archive---------0-----------------------#2020-08-21">https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc?source=collection_archive---------0-----------------------#2020-08-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c0381c44ab6b749cd6c73a53083f93c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fbLvUsof93illP5qeLusLg.jpeg"/></div></div></figure><p id="72a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本文旨在指导在PyTorch中实现CNN算法，并假设您对CNN及其各种模型/架构有所了解，本文的重点将放在PyTorch的最佳编码实践的实现部分。在这个特殊的用例中使用了Inception，因为这些模块被设计来解决计算开销的问题，以及过度拟合等问题。</p><p id="a724" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">关键要点:</strong></p><ul class=""><li id="fd24" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">用python处理文件目录</strong></li><li id="56e0" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">使用数据集和数据加载器在PyTorch中创建自定义数据集</strong></li><li id="d95a" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">利用迁移学习进行猫狗图像分类</strong></li><li id="9788" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">如何将数据移动到GPU进行训练，创建高效的训练循环</strong></li></ul><p id="7a25" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数据集</strong>—<a class="ae kc" href="https://www.kaggle.com/c/dogs-vs-cats/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/dogs-vs-cats/data</a></p><p id="fe07" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据集由猫和狗的图像组成，我们的任务是将图像分类到它们各自的类别中。它由一个train和test文件夹以及一个示例提交文件组成(对于kaggle提交超出了本文的范围)。</p><h1 id="ccce" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">创建train_csv</h1><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="0c8b" class="lk ke hi lg b fi ll lm l ln lo">import pandas as pd<br/>import os<br/>import torch<br/><br/>device = (<strong class="lg hj">"cuda" </strong>if torch.cuda.is_available() else <strong class="lg hj">"cpu"</strong>)<br/><br/>train_df = pd.DataFrame(columns=[<strong class="lg hj">"img_name"</strong>,<strong class="lg hj">"label"</strong>])<br/>train_df[<strong class="lg hj">"img_name"</strong>] = os.listdir(<strong class="lg hj">"train/"</strong>)<br/>for idx, i in enumerate(os.listdir(<strong class="lg hj">"train/"</strong>)):<br/>    if <strong class="lg hj">"cat" </strong>in i:<br/>        train_df[<strong class="lg hj">"label"</strong>][idx] = 0<br/>    if <strong class="lg hj">"dog" </strong>in i:<br/>        train_df[<strong class="lg hj">"label"</strong>][idx] = 1<br/><br/>train_df.to_csv (<strong class="lg hj">r'train_csv.csv'</strong>, index = False, header=True)</span></pre><p id="4eac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在导入必要的库之后，我们将device设置为cuda，以便利用GPU资源进行训练。要检查是否正在使用GPU，可以使用print(device ),根据系统中GPU的可用性，输出将是“cuda”或“cpu”。对于那些试图利用GPU进行培训的人，必须安装pytorch和cudatoolkit版本—使用此<a class="ae kc" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank">链接</a>获取安装指南。</p><p id="cbb8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于第一部分，我们需要创建一个csv文件，其中包含train文件夹中的图像文件名及其相应的图像标签。因此，我们创建了一个熊猫数据框架，标题为“img_name”和“label”。然后我们使用os.listdir获取“train/”目录中所有文件名的列表。所有文件名都有“cat”或“dog”作为文件名的一部分，因此我们将此作为条件语句来创建0或1标签，并将其添加到数据帧中的标签列。最后，我们保存文件，这样我们就不必每次都重新运行代码来获取数据帧。</p><h1 id="5e5c" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">创建自定义数据集</h1><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="bcc6" class="lk ke hi lg b fi ll lm l ln lo">from torch.utils.data import Dataset<br/>import pandas as pd<br/>import os<br/>from PIL import Image<br/>import torch<br/><br/>class CatsAndDogsDataset(Dataset):<br/>    def __init__(self, root_dir, annotation_file, transform=None):<br/>        self.root_dir = root_dir<br/>        self.annotations = pd.read_csv(annotation_file)<br/>        self.transform = transform<br/><br/>    def __len__(self):<br/>        return len(self.annotations)<br/><br/>    def __getitem__(self, index):<br/>        img_id = self.annotations.iloc[index, 0]<br/>        img = Image.open(os.path.join(self.root_dir, img_id)).convert(<strong class="lg hj">"RGB"</strong>)<br/>        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))<br/><br/>        if self.transform is not None:<br/>            img = self.transform(img)<br/><br/>        return (img, y_label)</span></pre><p id="6464" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Dataset是一个pytorch工具，允许我们创建自定义数据集。PIL是一个流行的计算机视觉库，它允许我们加载python中的图像并将其转换为RGB格式。我们的目标是使用train文件夹中的图像以及train_csv文件中的图像文件名和标签来返回(img，label)元组，对于此任务，我们使用CatsAndDogsDataset类，它将root_dir(这是存储训练图像的位置)和annotation_file(train_csv)作为参数。Transform已被设置为None，稍后将被设置为对图像执行特定的一组转换，以匹配随后将用于CNN的inception模型的输入标准，因此如果您不理解这一点，请稍等！</p><p id="cd75" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">__init__是一个初始化器，它设置定义类的参数。__len__函数返回数据集的长度，在本例中，我们返回self.annoations数据帧的长度，因为它保存所有训练文件名，即train_csv文件中的条目数。__getitem__函数定义了(x，y)或(img，label)对以及如何提取它。请注意，索引是在pytorch内部使用的，用于跟踪数据点、创建批处理等。跟踪已经加载和尚未加载的批处理—它负责数据集的所有簿记工作，是pytorch自定义数据集的新特性之一。img_id设置为图像的文件名(来自train_csv，因此是[index，0]，其中0是img_name列)。os.path.join使用“/”符号将csv文件中的root _ dir(“train/”)和img_name(图像文件名)组合在一起，然后使用PIL加载图像并将其转换为RGB格式。最后，从train_csv文件中提取y标签([index，1]，其中1是标签列)。请注意，index是用于访问csv文件行的指针，0或1对应于csv文件的列。我们还将其包含在float和tensor中，以满足损失函数的要求，并且所有数据在馈送到CNN模型之前必须是张量形式。</p><h1 id="189a" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">创建模型</h1><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="8c56" class="lk ke hi lg b fi ll lm l ln lo">import torch.nn as nn<br/>import torchvision.models as models<br/><br/>class CNN(nn.Module):<br/>    def __init__(self, train_CNN=False, num_classes=1):<br/>        super(CNN, self).__init__()<br/>        self.train_CNN = train_CNN<br/>        self.inception = models.inception_v3(pretrained=True, aux_logits=False)<br/>        self.inception.fc = nn.Linear(self.inception.fc.in_features, num_classes)<br/>        self.relu = nn.ReLU()<br/>        self.dropout = nn.Dropout(0.5)<br/>        self.sigmoid = nn.Sigmoid()<br/><br/>    def forward(self, images):<br/>        features = self.inception(images)<br/>        return self.sigmoid(self.dropout(self.relu(features))).squeeze(1)</span></pre><p id="e908" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">火炬视觉模块有几个内置的CNN模型，如VGG16，LeNet，ResNet等。用于计算机视觉和其他任务。在我们的例子中，我们将使用inception_v3架构。对于那些不熟悉inception模型的人，我强烈建议在用代码实现它之前先阅读它。</p><p id="f806" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">迁移学习是一种强大的技术，其中我们使用预先训练的模型，其中权重已经在大型数据集(数百万张图像)上训练过，并且对所有开发人员开放源代码。这里唯一重要的是，最后几层必须根据开发者项目的需要进行修改(微调)。这里我们使用train_CNN变量，并将其设置为false，这将用作一个标志，将初始模型的参数设置为可训练或不可训练。对于我们的二进制分类问题，将使用CNN权重，并且完全连接的层将从最初的1000个类修改为2个类。</p><p id="ff9d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如上面的代码所示，self.inception.fc已被修改为线性层，它接受初始模型的原始fc层的数字输入特征，并将其映射到num_classes(二进制分类)。对于所有参数，pretrained设置为True，但是对于使用train_CNN的最后一个fc层，它将设置为False。aux_logits是inception模型的一个特性，通过在除最后一层之外的几个地方附加fc、softmax/sigmoid，从中间隐藏层返回rin输出(在线阅读更多信息)。在我们的例子中，它被设置为false。丢弃用于正则化，在fc层中丢弃权重的概率为0.5。</p><p id="0a49" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如，如果我们有一批32个图像，那么在分别应用inception、relu、dropout和sigmoid层后，我们将得到形状为[32，[1]]的输出。然而，为了在输出上应用二进制交叉熵损失函数，我们要求张量的大小为[N，*],这意味着我们必须得到[32，]作为输出大小。因此，对于这个任务，我们使用squeeze(1)来移除张量大小中位置1处的1维。</p><h1 id="ac3a" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">为训练循环导入库</h1><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="b9a9" class="lk ke hi lg b fi ll lm l ln lo">import torch<br/>import torch.nn as nn<br/>from torch.utils.data import DataLoader<br/>import torchvision.transforms as transforms<br/>from Model import CNN<br/>from Dataset import CatsAndDogsDataset<br/>from tqdm import tqdm</span><span id="12e6" class="lk ke hi lg b fi lp lm l ln lo">device = (<strong class="lg hj">"cuda" </strong>if torch.cuda.is_available() else <strong class="lg hj">"cpu"</strong>)</span></pre><h1 id="9961" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">转换</h1><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="35c3" class="lk ke hi lg b fi ll lm l ln lo">transform = transforms.Compose(<br/>        [<br/>            transforms.Resize((356, 356)),<br/>            transforms.RandomCrop((299, 299)),<br/>            transforms.ToTensor(),<br/>            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),<br/>        ]<br/>    )</span></pre><p id="50d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">torcvhvision.transforms库允许我们在训练期间对图像进行处理和数据扩充。然后，我们将从自定义数据集中加载的图像将按照上面定义的顺序进行这些转换。Resize确保所有批处理具有相同的图像尺寸，以便可以成批进行训练，并且还可以将图像调整到标准CNN模型的推荐输入。随机裁剪在随机位置裁剪图像。最后，我们将其转换为张量，并归一化图像。为了火炬。归一化第一个元组是每个通道所有批次的三个通道的平均值(RGB ),下一个元组是每个通道所有批次的三个通道的标准差(RGB)。然后，它使用以下公式来归一化图像，其中<strong class="is hj"> μ </strong>是平均值，<strong class="is hj"> σ </strong>是标准偏差。正常化对于加速训练是必不可少的。注意，inception对所有通道<strong class="is hj">的<strong class="is hj"> μ </strong>和<strong class="is hj"> σ </strong>使用值0.5。</strong></p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/8490db3b627c43313518553cfe629f06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*Ap_7t_-luGSaAVgc7kl7qA.png"/></div><figcaption class="lr ls et er es lt lu bd b be z dx translated"><strong class="bd kf">归一化公式</strong></figcaption></figure><h1 id="38dc" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">超参数</h1><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="3449" class="lk ke hi lg b fi ll lm l ln lo">num_epochs = 10<br/>learning_rate = 0.00001<br/>train_CNN = False<br/>batch_size = 32<br/>shuffle = True<br/>pin_memory = True<br/>num_workers = 1</span></pre><p id="b4da" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Pin_memory是一个非常重要的功能。由于我们创建的自定义数据集的所有操作都在CPU中运行，因此数据也被加载到CPU中。只有在训练期间，批量图像才会被移动到GPU。pin_memory确保数据的这种移动是高效和快速的。如果使用MNIST或CIFAR10等内置数据集，则不需要此参数，因为在这种情况下，数据会直接加载到GPU中。<strong class="is hj"> num_workers </strong>属性告诉数据加载器实例有多少子进程用于数据加载(主要是关于矢量化)。默认情况下，<strong class="is hj">的num_workers </strong>值被设置为零。</p><h1 id="7681" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">设置数据集和数据加载器</h1><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="a180" class="lk ke hi lg b fi ll lm l ln lo">dataset = CatsAndDogsDataset(<strong class="lg hj">"train"</strong>,<strong class="lg hj">"train_csv.csv"</strong>,transform=transform)<br/>train_set, validation_set = torch.utils.data.random_split(dataset,[20000,5000])<br/>train_loader = DataLoader(dataset=train_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)<br/>validation_loader = DataLoader(dataset=validation_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)</span></pre><p id="a5c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练数据被分为训练和验证两部分，以便我们能够在稍后使用早期停止来获取提供最佳验证准确性的模型。</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="3026" class="lk ke hi lg b fi ll lm l ln lo">model = CNN().to(device)<br/><br/>criterion = nn.BCELoss()<br/>optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)<br/><br/>for name, param in model.inception.named_parameters():<br/>    if <strong class="lg hj">"fc.weight" </strong>in name or <strong class="lg hj">"fc.bias" </strong>in name:<br/>        param.requires_grad = True<br/>    else:<br/>        param.requires_grad = train_CNN</span></pre><p id="1d2e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们之前设置的标志现在用于将fc层设置为可训练的，而将所有其他层设置为不可训练的，以避免通过这些层的反向传播。美国有线电视新闻网()。to(设备)将模型移动到GPU。注意:对于GPU培训，模型和数据都必须加载到GPU。有关BCELoss和Adam optimizer的输入格式，请参考torch文档。</p><h1 id="6349" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">准确性检查</h1><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="9afd" class="lk ke hi lg b fi ll lm l ln lo">def check_accuracy(loader, model):<br/>    if loader == train_loader:<br/>        print(<strong class="lg hj">"Checking accuracy on training data"</strong>)<br/>    else:<br/>        print(<strong class="lg hj">"Checking accuracy on validation data"</strong>)<br/><br/>    num_correct = 0<br/>    num_samples = 0<br/>    model.eval()<br/><br/>    with torch.no_grad():<br/>        for x, y in loader:<br/>            x = x.to(device=device)<br/>            y = y.to(device=device)<br/><br/>            scores = model(x)<br/>            predictions = torch.tensor([1.0 if i &gt;= 0.5 else 0.0 for i in scores]).to(device)<br/>            num_correct += (predictions == y).sum()<br/>            num_samples += predictions.size(0)<br/>    return <strong class="lg hj">f"</strong>{float(num_correct)/float(num_samples)*100:<strong class="lg hj">.2f</strong>}<strong class="lg hj">"<br/>        </strong>print(<br/>            <strong class="lg hj">f"Got </strong>{num_correct}<strong class="lg hj"> / </strong>{num_samples}<strong class="lg hj"> with accuracy </strong>{float(num_correct)/float(num_samples)*100:<strong class="lg hj">.2f</strong>}<strong class="lg hj">"<br/>        </strong>)<br/>    model.train()</span></pre><p id="1665" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们检查训练或验证加载程序，并相应地设置输出。torch.no_grad()确保模型不处于训练模式，而只是应用模型权重来获得预测，以计算训练/验证准确性。如上所示，图像和标签在从加载器加载后被移动到设备，然后通过将sigmoid层返回的最终值舍入为0或1(0 —猫，1 —狗)来设置预测张量，并移动到GPU。我们还跟踪样本的数量，方法是随着批次的加载，将num_samples递增batch_size。num_correct将预测与真实标签进行比较，并返回正确预测的总数。最后，该函数返回整个数据集的精度(训练/验证取决于我们输入到该函数的内容)。请注意，将模型置于评估模式(model.eval())非常重要，这样可以避免在精度计算过程中出现回推。还需要注意的是，在准确性检查之后，我们将继续训练以寻找更好的准确性，因此在最后，模型将再次设置为训练模式(model.train())。</p><h1 id="eb93" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">训练循环</h1><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="e8c4" class="lk ke hi lg b fi ll lm l ln lo">def train():<br/>    model.train()<br/>    for epoch in range(num_epochs):<br/>        loop = tqdm(train_loader, total = len(train_loader), leave = True)<br/>        if epoch % 2 == 0:<br/>            loop.set_postfix(val_acc = check_accuracy(validation_loader, model))<br/>        for imgs, labels in loop:<br/>            imgs = imgs.to(device)<br/>            labels = labels.to(device)<br/>            outputs = model(imgs)<br/>            loss = criterion(outputs, labels)<br/>            optimizer.zero_grad()<br/>            loss.backward()<br/>            optimizer.step()<br/>            loop.set_description(<strong class="lg hj">f"Epoch [</strong>{epoch}<strong class="lg hj">/</strong>{num_epochs}<strong class="lg hj">]"</strong>)<br/>            loop.set_postfix(loss = loss.item())<br/><br/>if __name__ == <strong class="lg hj">"__main__"</strong>:<br/>    train()</span></pre><p id="5216" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于每个时期，我们遍历训练加载器中所有批次的图像和标签，并将它们移动到GPU(分批)。然后，我们使用模型的输出，并使用BCELoss函数计算损失。在我们进行反向传播以计算梯度之前，我们必须执行optimizer.zero_grad()操作——这将清空前一批的梯度张量，以便重新计算新一批的梯度。现在，为了执行反向传播，我们使用loss.backward()，最后使用optimizer.step()用新计算的梯度更新权重参数。从上面的代码中可以看出，这里定义了一个循环变量——它使用tqdm库，在终端/控制台的训练过程中可以方便地创建一个进度条。leave = True确保较旧的进度条随着时期的进展而保持不变，或者将其设置为False将使先前时期的较旧进度条离开，并且仅显示当前时期的进度条。tqdm还增加了损失和准确性(每两个时期打印一次，以查看它在验证集上的表现)。最后一部分是必不可少的运行在笔记本的脚本代码，它不是必要的。</p><h1 id="80ef" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结论</h1><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/b1b506f231cdfbf94ba4d99b4627c5bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qwJeJX77npgC2i0Uw9md-g.jpeg"/></div></div></figure></div><div class="ab cl lw lx gp ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="hb hc hd he hf"><p id="7b49" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">链接到代码:<a class="ae kc" href="https://github.com/ajinkya98/PyTorchCNN" rel="noopener ugc nofollow" target="_blank">https://github.com/ajinkya98/PyTorchCNN</a></p></div></div>    
</body>
</html>