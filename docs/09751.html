<html>
<head>
<title>K-Means Clustering with Python — Beginner Tutorial</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 的 K-Means 聚类—初学者教程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/k-means-clustering-with-python-beginner-tutorial-45a44c34e7f?source=collection_archive---------2-----------------------#2020-09-19">https://medium.com/analytics-vidhya/k-means-clustering-with-python-beginner-tutorial-45a44c34e7f?source=collection_archive---------2-----------------------#2020-09-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0076c4a418fd7fbf16873e80a7920a6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZsI-R9t_O8USO4qS.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">各种颜色的气球作为未标记数据的例子。</figcaption></figure><p id="cbdb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">抱歉，不开门。我假设你已经知道什么是集群，以及这个东西的目的是什么，所以让我们直接跳到教程。</p><p id="1917" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="js">或者如果你还对数据分析中聚类的定义和目的感到困惑，可以查看这个链接:</em><a class="ae jt" href="https://developers.google.com/machine-learning/clustering/overview" rel="noopener ugc nofollow" target="_blank"><em class="js">https://developers . Google . com/machine-learning/clustering/overview</em></a></p><h2 id="2086" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jf kf kg kh jj ki kj kk jn kl km kn ko bi translated">导入库。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="62b3" class="ju jv hi ku b fi ky kz l la lb">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.cluster import KMeans<br/>from sklearn import datasets</span></pre><h2 id="0703" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jf kf kg kh jj ki kj kk jn kl km kn ko bi translated">加载数据集。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="acce" class="ju jv hi ku b fi ky kz l la lb">iris = pd.read_csv('iris.csv')</span></pre><p id="d5f1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">是的，我们将使用<a class="ae jt" href="https://www.kaggle.com/uciml/iris#" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a>。对于初学者学习机器学习来说，这是一个非常好的数据集。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/7bd71aea448d99321d534db8cbee2eb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*1bR2Yry8b2R_3DUj-a0nyA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">虹膜数据集</figcaption></figure><p id="5d77" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果你看一下“物种”一栏的数据，在物种名称前有某种额外的字符串(Iris-)。让我们删除多余的字符串，我们可以这样做:</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="34ed" class="ju jv hi ku b fi ky kz l la lb">iris['Species'] = iris.Species.str.replace('Iris-' , '')</span></pre><p id="a3b1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在我们得到了更干净的物种名称字符串。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/6172e7d0aa46ab6ab18dfc97b81be643.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*1TDGx_JUJULcRnFkPX40LQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">虹膜数据集</figcaption></figure><h2 id="235d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jf kf kg kh jj ki kj kk jn kl km kn ko bi translated"><strong class="ak">减去数值。</strong></h2><p id="4e27" class="pw-post-body-paragraph iu iv hi iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr hb bi translated">为了进行聚类，我们只需要表格中的四个特征(萼片长度、萼片宽度、花瓣长度和花瓣宽度)。所以我们可以把这些列减去，变成一个新的变量，叫做 x。</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="f728" class="ju jv hi ku b fi ky kz l la lb">x = iris.iloc[:, [1,2,3,4]]</span></pre><p id="78a8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">减去列之后，现在我们想使用 numpy 数组函数将值减去到一个数组表中。</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="d76f" class="ju jv hi ku b fi ky kz l la lb">x  = np.array(x)</span></pre><h2 id="d04b" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jf kf kg kh jj ki kj kk jn kl km kn ko bi translated"><strong class="ak">求最优聚类数。</strong></h2><p id="a97b" class="pw-post-body-paragraph iu iv hi iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr hb bi translated">因此，在我们实现 k-means 和分配数据中心之前，我们还可以使用 Elbow 方法进行快速分析，以找到最佳的聚类数(中心)。</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="96a5" class="ju jv hi ku b fi ky kz l la lb"># Collecting the distortions into list<br/>distortions = []<br/>K = range(1,10)<br/>for k in K:<br/> kmeanModel = KMeans(n_clusters=k)<br/> kmeanModel.fit(x)<br/> distortions.append(kmeanModel.inertia_)</span><span id="1a75" class="ju jv hi ku b fi lj kz l la lb"># Plotting the distortions<br/>plt.figure(figsize=(16,8))<br/>plt.plot(K, distortions, ‘bx-’)<br/>plt.xlabel(‘k’)<br/>plt.ylabel(‘Distortion’)<br/>plt.title(‘The Elbow Method showing the optimal clusters’)<br/>plt.show()</span></pre><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/c988227ee121cd454baf037bc37184aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-HzAyJ82EBieTLd6XE7bMQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">肘法</figcaption></figure><p id="f259" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从上面的折线图中，我们可以观察到“肘部”是数字 3，这是本例中的最佳集群(中心)。</p><p id="3679" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">实施 K 均值。</strong></p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="2bab" class="ju jv hi ku b fi ky kz l la lb"># Define the model<br/>kmeans_model = KMeans(n_clusters=3, n_jobs=3, random_state=32932)<br/># Fit into our dataset fit<br/>kmeans_predict = kmeans_model.fit_predict(x)</span></pre><p id="f5f7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在此步骤中，我们已经创建了集群，如下所示:</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/88c04f9309af18198a460eb968d749f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*z0r3MTdJ-5uk_mCeeuZqkA.png"/></div></figure><p id="0162" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">0、1 和 2 数字内的 3 个聚类。我们还可以将分类结果与原始数据表合并，如下所示:</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="fc2b" class="ju jv hi ku b fi ky kz l la lb">iris['Cluster'] = kmeans_predict</span></pre><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/ccc6aa03e056afe22423c618dda9fad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*mminLCAV8ywudQ-ddqpS8g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">具有聚类列的 Iris 数据集</figcaption></figure><p id="354a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后一步也是最必要的一步是可视化我们的集群，这样我们就可以实际看到集群的模型。</p><h2 id="4594" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jf kf kg kh jj ki kj kk jn kl km kn ko bi translated"><strong class="ak">可视化集群</strong>。</h2><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="836d" class="ju jv hi ku b fi ky kz l la lb"># Visualising the clusters<br/>plt.scatter(x[kmeans_predict == 0, 0], x[kmeans_predict == 0, 1], s = 100, c = ‘red’, label = ‘Setosa’)<br/>plt.scatter(x[kmeans_predict == 1, 0], x[kmeans_predict == 1, 1], s = 100, c = ‘blue’, label = ‘Versicolour’)<br/>plt.scatter(x[kmeans_predict == 2, 0], x[kmeans_predict == 2, 1], s = 100, c = ‘green’, label = ‘Virginica’)</span><span id="505d" class="ju jv hi ku b fi lj kz l la lb"># Plotting the centroids of the clusters<br/>plt.scatter(kmeans_model.cluster_centers_[:, 0], kmeans_model.cluster_centers_[:,1], s = 100, c = ‘yellow’, label = ‘Centroids’)</span><span id="5d8e" class="ju jv hi ku b fi lj kz l la lb">plt.legend()</span></pre><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/f0ec94a45afeed854bf74a4d5c9bbed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*ZQkh8ehwKwuoH_sA3DCS_g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">形象化</figcaption></figure><h1 id="e41f" class="lo jv hi bd jw lp lq lr ka ls lt lu ke lv lw lx kh ly lz ma kk mb mc md kn me bi translated">摘要</h1><ul class=""><li id="0065" class="mf mg hi iw b ix le jb lf jf mh jj mi jn mj jr mk ml mm mn bi translated">在最常见的无监督学习形式中，数据是无标记的，聚类涉及基于数据实例之间的相似性来分离数据。</li><li id="e693" class="mf mg hi iw b ix mo jb mp jf mq jj mr jn ms jr mk ml mm mn bi translated">K-means 是一种流行的聚类技术。它涉及一个迭代过程，以找到称为质心的聚类中心，并将数据点分配给其中一个质心。</li><li id="6790" class="mf mg hi iw b ix mo jb mp jf mq jj mr jn ms jr mk ml mm mn bi translated">K-means 聚类的步骤包括:<br/> 1 .识别组合 K <br/> 2 的编号。识别每个群集的质心<br/> 3。确定物体到质心的距离<br/> 4。基于最小距离对对象进行分组</li></ul><p id="041b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在这里可以找到笔记本<a class="ae jt" href="https://notebooks.gesis.org/binder/v2/gh/jerichosiahaya/my-notebooks/64131fa240144e991ce89b335649b1834b46ceb9?filepath=k-means%20clustering%20using%20iris%20dataset%2FClustering%20using%20Iris%20dataset.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>