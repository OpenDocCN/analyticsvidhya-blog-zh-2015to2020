<html>
<head>
<title>Deploy Machine Learning Models with Keras, FastAPI, Redis and Docker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Keras、FastAPI、Redis和Docker部署机器学习模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deploy-machine-learning-models-with-keras-fastapi-redis-and-docker-4940df614ece?source=collection_archive---------0-----------------------#2019-09-15">https://medium.com/analytics-vidhya/deploy-machine-learning-models-with-keras-fastapi-redis-and-docker-4940df614ece?source=collection_archive---------0-----------------------#2019-09-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/cdc96179417b3c74406e794cfc620704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V3Jy_hxwZYIXyMU_ZR5b1g.png"/></div></div></figure><p id="14dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本教程将向您展示如何使用FastAPI、Redis和Docker快速部署您的机器学习模型。</p><p id="4ba6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你想快进，伴随代码库的<a class="ae jo" href="https://github.com/shanesoh/deploy-ml-fastapi-redis-docker" rel="noopener ugc nofollow" target="_blank">将在几分钟内为你提供一个图像分类模型。</a></p><h1 id="e44a" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">概观</h1><p id="1c50" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">有很多很棒的“用Flask包装你的机器学习模型”教程。然而，当我看到<a class="ae jo" href="https://www.pyimagesearch.com/2018/02/05/deep-learning-production-keras-redis-flask-apache/" rel="noopener ugc nofollow" target="_blank">Adrian rose Brock的这个令人敬畏的系列帖子时，</a>我认为他的方法更适合生产，并且非常适合docker化。Docker化这种设置不仅可以让Docker Compose更容易地启动和运行，还可以更容易地扩展到生产中。</p><p id="0fa8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本教程结束时，您将能够:</p><p id="9e5b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.使用FastAPI(与Uvicorn一起)构建一个<strong class="is hj"> web服务器</strong>来服务我们的机器学习端点。</p><p id="a87d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.构建一个机器学习<strong class="is hj">模型服务器</strong>，服务于一个Keras图像分类模型(在ImageNet上训练的ResNet50)。</p><p id="5992" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.使用Redis作为<strong class="is hj">消息队列</strong>在<strong class="is hj"> web服务器</strong>和<strong class="is hj">模型服务器</strong>之间传递查询和响应。</p><p id="03c5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.使用Docker Compose将它们全部旋转起来！</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="d142" class="jp jq hi bd jr js kz ju jv jw la jy jz ka lb kc kd ke lc kg kh ki ld kk kl km bi translated">体系结构</h1><p id="e72b" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们将使用前面Adrian Rosebrock 的文章中的相同架构，但是替换web服务器框架(FastAPI+uvicon代替Flask + Apache ),更重要的是，将整个设置容器化以便于使用。我们还将使用Adrian的大部分代码，因为他在处理、序列化和解决一些小问题方面做得非常出色。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es le"><img src="../Images/cc3fd86f863661bf27ce79f1c01bda98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*TfV7PImGdWWeJMaZBkjNnw.png"/></div></figure><p id="9820" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> web服务器</strong>的主要功能是服务于一个<code class="du lj lk ll lm b">/predict</code>端点，其他应用程序将通过它调用我们的机器学习模型。当端点被调用时，web服务器将请求路由到Redis，Redis充当许多并发请求的内存中消息队列。<strong class="is hj">模型服务器</strong>简单地轮询Redis消息队列中的一批图像，对这批图像进行分类，然后将结果返回给Redis。web服务器获取结果并返回。</p><h1 id="6c8c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">代码库</h1><p id="92de" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">您可以在这里找到本教程中使用的所有代码:</p><div class="ln lo ez fb lp lq"><a href="https://github.com/shanesoh/deploy-ml-fastapi-redis-docker" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab dw"><div class="ls ab lt cl cj lu"><h2 class="bd hj fi z dy lv ea eb lw ed ef hh bi translated">Shane soh/deploy-ml-fastapi-redis-docker</h2><div class="lx l"><h3 class="bd b fi z dy lv ea eb lw ed ef dx translated">使用FastAPI、Redis和…服务于生产就绪和可扩展的基于Keras的深度学习模型图像分类</h3></div><div class="ly l"><p class="bd b fp z dy lv ea eb lw ed ef dx translated">github.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me io lq"/></div></div></a></div><h1 id="807c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">构建web服务器</h1><p id="d29d" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我选择使用<code class="du lj lk ll lm b">tiangolo/uvicorn-gunicorn-fastapi</code>作为web服务器。这个Docker映像提供了一个整洁的ASGI堆栈(Uvicorn由Gunicorn使用FastAPI框架管理),它承诺比更常见的基于WSGI的flask-uwsgi-nginx有显著的性能改进。</p><p id="3859" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个决定很大程度上是因为想要尝试ASGI堆栈，像tiangolo这样的高质量docker图像使实验变得更加容易。此外，正如您将在后面的代码中看到的，在FastAPI中编写简单的HTTP端点与我们在Flask中的做法没有太大的不同。</p><p id="0327" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lj lk ll lm b">webserver/Dockerfile</code>很简单。它获取上述映像，安装必要的Python需求，并将代码复制到容器中:</p><pre class="lf lg lh li fd mf lm mg mh aw mi bi"><span id="4b1b" class="mj jq hi lm b fi mk ml l mm mn">FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7<br/><br/>COPY requirements.txt /app/<br/><br/>RUN pip install -r /app/requirements.txt<br/><br/>COPY . /app</span></pre><p id="c3e3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lj lk ll lm b">webserver/main.py</code>文件运行FastAPI服务器，暴露<code class="du lj lk ll lm b">/predict</code>端点，该端点获取上传的图像，将其序列化，将其推送到Redis并轮询结果预测。</p><figure class="lf lg lh li fd ij"><div class="bz dy l di"><div class="mo mp l"/></div><figcaption class="mq mr et er es ms mt bd b be z dx translated">webserver/main.py</figcaption></figure><p id="d15a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">代码大部分保持原样，为Dockerized环境做一些内务处理，即分离web和模型服务器的助手函数和参数。此外，参数通过环境变量传递到Docker容器中(稍后将详细介绍)。</p><h1 id="1434" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">构建模型服务器</h1><p id="6f90" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">这个<code class="du lj lk ll lm b">modelserver/Dockerfile</code>也相当简单:</p><pre class="lf lg lh li fd mf lm mg mh aw mi bi"><span id="22e4" class="mj jq hi lm b fi mk ml l mm mn">FROM python:3.7-slim-buster<br/><br/>COPY requirements.txt /app/<br/><br/>RUN pip install -r /app/requirements.txt</span><span id="ab01" class="mj jq hi lm b fi mu ml l mm mn"># Download ResNet50 model and cache in image                       RUN python -c "from keras.applications import ResNet50; ResNet50(weights='imagenet')"</span><span id="901b" class="mj jq hi lm b fi mu ml l mm mn">COPY . /app<br/><br/>CMD ["python", "/app/main.py"]</span></pre><p id="be51" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我使用了<code class="du lj lk ll lm b">python:3.7-slim-buster</code>图像。<code class="du lj lk ll lm b">slim</code>变体将整体图像大小减少了大约700mb。<code class="du lj lk ll lm b">alpine</code>变体无法与tensorflow一起使用，所以我选择不使用它。</p><p id="02c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我还选择在Docker文件中下载机器学习模型，这样它将被缓存在Docker映像中。否则，将在运行模型服务器时下载模型。除了给复制过程增加几分钟的延迟之外，这并不是一个问题(因为每个启动的工作者需要首先下载模型)。</p><p id="1d21" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Dockerfile再次安装需求，然后运行<code class="du lj lk ll lm b">main.py</code>文件。</p><figure class="lf lg lh li fd ij"><div class="bz dy l di"><div class="mo mp l"/></div><figcaption class="mq mr et er es ms mt bd b be z dx translated">modelserver/main.py</figcaption></figure><p id="ebd0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">模型服务器向Redis轮询一批图像以进行预测。批量推理对于深度学习模型特别高效，尤其是在GPU上运行的时候。可以调整<code class="du lj lk ll lm b">BATCH_SIZE</code>参数以提供最低的延迟。</p><p id="2e08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们还必须使用redis-py的<code class="du lj lk ll lm b">pipeline</code>(这是一个误称，因为它在redis-py中默认是事务性的)来实现多个元素的原子左弹出(参见第45–48行)。当我们复制模型服务器时，这对于防止竞争情况变得很重要。</p><h1 id="093a" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">用Docker Compose把它们放在一起</h1><figure class="lf lg lh li fd ij"><div class="bz dy l di"><div class="mo mp l"/></div><figcaption class="mq mr et er es ms mt bd b be z dx translated">docker-compose.yml</figcaption></figure><p id="df3a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们创建了3个服务——Redis、模型服务器和web服务器——它们都在同一个Docker网络上。</p><p id="6b1f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“全局”参数在<code class="du lj lk ll lm b">app.env</code>文件中，而特定于服务的参数(如<code class="du lj lk ll lm b">SERVER_SLEEP</code>和<code class="du lj lk ll lm b">BATCH_SIZE</code>)作为环境变量传递给容器。</p><p id="2147" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lj lk ll lm b">deploy</code>参数仅用于Docker Swarm(在后面的帖子中会有更多介绍), Docker Compose会安全地忽略这些参数。</p><p id="1237" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以用<code class="du lj lk ll lm b">docker-compose up</code>来旋转一切，它将构建图像并启动各种服务。就是这样！</p><h1 id="e8f5" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">测试端点</h1><p id="4b93" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">现在通过卷曲端点来测试服务:</p><pre class="lf lg lh li fd mf lm mg mh aw mi bi"><span id="4f7d" class="mj jq hi lm b fi mk ml l mm mn">$ curl <a class="ae jo" href="http://localhost" rel="noopener ugc nofollow" target="_blank">http://localhost</a><br/>"Hello World!"</span><span id="c552" class="mj jq hi lm b fi mu ml l mm mn">$ curl -X POST -F img_file=@doge.jpg <a class="ae jo" href="http://localhost/predict" rel="noopener ugc nofollow" target="_blank">http://localhost/predict</a><br/>{"success":true,"predictions":[{"label":"dingo","probability":0.6836559772491455},{"label":"Pembroke","probability":0.17909787595272064},{"label":"basenji","probability":0.07694739103317261},{"label":"Eskimo_dog","probability":0.01792934536933899},{"label":"Chihuahua","probability":0.005690475460141897}]}</span></pre><p id="8b5a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">成功！ImageNet中可能没有“shiba inu”类，所以现在只能用“dingo”了。够近了。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mv"><img src="../Images/4121fbe53e2bea26517bcb8a3a496deb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*2BrZZJrl-_6sQESvEyTyAg.gif"/></div></div></figure><h1 id="5dfa" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">用蝗虫进行负载测试</h1><p id="c15d" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated"><a class="ae jo" href="https://locust.io" rel="noopener ugc nofollow" target="_blank"> Locust </a>是一款为负载测试网站设计的负载测试工具。它是为负载测试网站设计的，但也适用于像我们这样的简单HTTP端点。</p><p id="1ec3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它很容易启动和运行。首先用<code class="du lj lk ll lm b">pip install locustio</code>安装它，然后在项目目录下运行启动它:</p><pre class="lf lg lh li fd mf lm mg mh aw mi bi"><span id="38e8" class="mj jq hi lm b fi mk ml l mm mn">locust --host=http://localhost</span></pre><p id="f840" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这使用提供的<code class="du lj lk ll lm b">locustfile</code>来测试<code class="du lj lk ll lm b">/predict</code>端点。请注意，我们将主机指向<code class="du lj lk ll lm b">localhost</code> —我们正在测试我们的机器学习服务的响应时间，没有任何实际的网络延迟。</p><p id="9cf7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在将您的浏览器指向<code class="du lj lk ll lm b">http://localhost:8089</code>以访问locust web ui。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mw"><img src="../Images/f68bf0ea14674d6800972749f1ed5ca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LrUhZdjcqliOz1hvE9njpg.png"/></div></div><figcaption class="mq mr et er es ms mt bd b be z dx translated">蝗虫网络用户界面</figcaption></figure><p id="c34d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将模拟50个用户(他们都在开始时被孵化)。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mx"><img src="../Images/9ce064542009cd0c12672838328bc78b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3iLPc49llT-MWurVV24iYA.png"/></div></div><figcaption class="mq mr et er es ms mt bd b be z dx translated">绿色表示平均响应时间；黄色代表p95</figcaption></figure><p id="a8b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大约5000毫秒的p95响应时间意味着95%的请求应该在5秒内完成。根据您的使用情况和预期负载，这可能太慢了。</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="89e0" class="jp jq hi bd jr js kz ju jv jw la jy jz ka lb kc kd ke lc kg kh ki ld kk kl km bi translated">结论</h1><p id="27a6" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">在这篇文章中，我们看到了如何使用Keras、FastAPI和Redis构建Dockerized机器学习服务。我们还做了一个负载测试，看看性能可能不够好。</p><p id="3b2a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在下面这篇文章中，我将展示如何使用Docker Swarm轻松扩展我们的模型服务器以获得更好的性能:</p><div class="ln lo ez fb lp lq"><a rel="noopener follow" target="_blank" href="/@shane.soh/scaling-machine-learning-models-with-docker-swarm-39a1a875a692"><div class="lr ab dw"><div class="ls ab lt cl cj lu"><h2 class="bd hj fi z dy lv ea eb lw ed ef hh bi translated">用Docker Swarm扩展机器学习模型</h2><div class="lx l"><h3 class="bd b fi z dy lv ea eb lw ed ef dx translated">本教程展示了我们如何使用Docker Swarm在多台主机上轻松扩展机器学习服务。</h3></div><div class="ly l"><p class="bd b fp z dy lv ea eb lw ed ef dx translated">medium.com</p></div></div><div class="lz l"><div class="my l mb mc md lz me io lq"/></div></div></a></div></div></div>    
</body>
</html>