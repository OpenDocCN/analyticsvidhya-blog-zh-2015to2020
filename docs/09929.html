<html>
<head>
<title>Adult Census Income dataset: Using multiple machine learning models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">成人人口普查收入数据集:使用多种机器学习模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/adult-census-income-dataset-using-multiple-machine-learning-models-f289c960005d?source=collection_archive---------4-----------------------#2020-09-27">https://medium.com/analytics-vidhya/adult-census-income-dataset-using-multiple-machine-learning-models-f289c960005d?source=collection_archive---------4-----------------------#2020-09-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/3a1c870beb3a78dc1b2e2bcbdf49659d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rLxsR9uweBRF4q9s"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">亚历山大·密尔斯在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="7354" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们都听说过数据科学是“21世纪最性感的工作”。因此，同样令人惊讶的是，在数据充斥世界之前，<strong class="ix hj">神经网络的概念是在半个世纪前提出的。甚至在“机器学习”这个词被创造出来之前，唐纳德·赫布就在他1949年的著作《行为的组织》中创建了一个基于脑细胞互动的模型。本书介绍了Hebb关于神经元兴奋和神经元间通讯的理论。</strong></p><p id="2096" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">赫布写道，“当一个细胞反复协助另一个细胞放电时，第一个细胞的轴突在与第二个细胞的胞体接触时会形成突触旋钮(或扩大它们，如果它们已经存在的话)。”将Hebb的概念转化为人工神经网络和人工神经元，他的模型可以被描述为一种改变人工神经元(也称为节点)和单个神经元变化之间关系的方式。IBM的Arthur Samuel在1952年首次提出了“机器学习”这个词。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="dbfc" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">分析数据</h1><p id="9ff5" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">名为“成人人口普查收入”的数据集可在卡格尔和UCI资料库中找到。该数据由Ronny Kohavi和Barry Becker从1994年人口普查局数据库中提取。<strong class="ix hj">预测任务是确定一个人的年收入是否超过5万美元。</strong></p><p id="71f6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="ld">数据集:</em><a class="ae iu" href="https://www.kaggle.com/uciml/adult-census-income" rel="noopener ugc nofollow" target="_blank"><em class="ld">https://www.kaggle.com/uciml/adult-census-income</em>T17】</a></p><p id="ac7a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用python语言和几种可视化技术，我试图拟合4种机器学习模型，并找到描述数据的最佳模型。</p><p id="e0ac" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用数据有3个步骤——数据、发现和部署</p><h2 id="74e9" class="le kb hi bd kc lf lg lh kg li lj lk kk jg ll lm ko jk ln lo ks jo lp lq kw lr bi translated">数据</h2><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="812e" class="le kb hi lx b fi mb mc l md me">age workclass  fnlwgt     education  education.num marital.status  </span><span id="e879" class="le kb hi lx b fi mf mc l md me">0   90         ?   77053       HS-grad              9        Widowed   </span><span id="779d" class="le kb hi lx b fi mf mc l md me">1   82   Private  132870       HS-grad              9        Widowed   </span><span id="ca9b" class="le kb hi lx b fi mf mc l md me">2   66         ?  186061  Some-college             10        Widowed   </span><span id="2033" class="le kb hi lx b fi mf mc l md me">3   54   Private  140359       7th-8th              4       Divorced   </span><span id="ff0d" class="le kb hi lx b fi mf mc l md me">4   41   Private  264663  Some-college             10      Separated   </span><span id="eb9a" class="le kb hi lx b fi mf mc l md me">          occupation   relationship   race     sex  capital.gain  </span><span id="6945" class="le kb hi lx b fi mf mc l md me">0                  ?  Not-in-family  White  Female             0   </span><span id="f2d5" class="le kb hi lx b fi mf mc l md me">1    Exec-managerial  Not-in-family  White  Female             0   </span><span id="0b56" class="le kb hi lx b fi mf mc l md me">2                  ?      Unmarried  Black  Female             0   </span><span id="3c2d" class="le kb hi lx b fi mf mc l md me">3  Machine-op-inspct      Unmarried  White  Female             0   </span><span id="12de" class="le kb hi lx b fi mf mc l md me">4     Prof-specialty      Own-child  White  Female             0   </span><span id="6268" class="le kb hi lx b fi mf mc l md me">   capital.loss  hours.per.week native.country income  </span><span id="661d" class="le kb hi lx b fi mf mc l md me">0          4356              40  United-States  &lt;=50K  </span><span id="d6fc" class="le kb hi lx b fi mf mc l md me">1          4356              18  United-States  &lt;=50K  </span><span id="0e09" class="le kb hi lx b fi mf mc l md me">2          4356              40  United-States  &lt;=50K  </span><span id="60a8" class="le kb hi lx b fi mf mc l md me">3          3900              40  United-States  &lt;=50K  </span><span id="581f" class="le kb hi lx b fi mf mc l md me">4          3900              40  United-States  &lt;=50K</span></pre></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h2 id="fd58" class="le kb hi bd kc lf lg lh kg li lj lk kk jg ll lm ko jk ln lo ks jo lp lq kw lr bi translated">发现</h2><p id="5228" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">数据预处理</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/5c555280e3b2535b9958f854bf06f3f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*l1GP8i1mASf7Lhpf"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@isaacmsmith?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Isaac Smith </a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="4eb9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">发现阶段是我们试图理解数据的阶段。它可能需要清理、改造、整合。下面的代码片段突出了数据预处理步骤。</p><p id="23ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据集包含空值，包括数值和分类值。分类值既有名词性的，也有序数的。数据也有冗余的列。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="b2cf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为缺少的值用“？”表示，它们被替换为NAN值并在检测后被移除。要预测的从属列“收入”已被替换为0和1，因此将问题转换为二分法分类问题。有一个多余的列“education.num ”,它是“education”的序号表示，已在上面删除。</p><p id="8777" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">既然已经去除了不必要的数据点和冗余属性，就有必要选择真正有助于收入预测的属性集。</p><p id="00d5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了检查二元变量和连续变量之间的<strong class="ix hj">相关性，使用了<strong class="ix hj">点双列相关</strong>。在适当应用测试后，“fnlwgt”下降，显示负相关。</strong></p><p id="01d8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于功能选择，除了“fnlwgt”之外，所有数字列都被选择。对于分类变量，使用卡方估计。卡方估计用于衡量两个分类变量之间的相关性。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="fd38" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，对分类变量进行编码，或者说生成虚拟变量，并将数值进行<strong class="ix hj">归一化</strong>，使其在[0，1]之间。<strong class="ix hj">这只是一个在同一尺度上获取所有数据的简单例子:如果不同特征的尺度大相径庭，这可能会对你的学习能力产生连锁反应</strong>(取决于你使用什么方法来做这件事)。确保标准化的特征值隐含地在所有要素的表示中对其进行同等加权。</p><p id="bc4b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">包括数字变量在内共有103个属性。特征选择后，有65个属性。</p><p id="eea7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个数据集包含了一个<strong class="ix hj">典型的阶级不平衡的例子</strong>。如下图所示。</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/7e67312bfc5ed69d0e3b425f8abe9a08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*euUbaICC_HX4uKe3MtYC9g.png"/></div></figure><p id="a71a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">饼图清楚地表明超过50%的数据集被一种类型的观察所占据。使用<strong class="ix hj"> SMOTE(合成少数过采样技术)</strong>处理这个问题。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h2 id="f099" class="le kb hi bd kc lf lg lh kg li lj lk kk jg ll lm ko jk ln lo ks jo lp lq kw lr bi translated">部署</h2><p id="aef1" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">如上所述，下面显示了4个模型。逻辑和朴素贝叶斯的训练和测试分为80-20，而决策树和随机森林的训练和测试分为70-30。</p><p id="715c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">逻辑回归</strong></p><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/7dc640fd00e1e0cc49d6c460bca0eed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*qYbl7jNzDhlSFmavxIvXSA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">orange中的sigmoid函数</figcaption></figure><p id="27cd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">预测二元变量的最重要的模型是逻辑回归。<strong class="ix hj">逻辑函数是一个sigmoid函数，它接受任何实数输入t，并输出一个介于零和一之间的值</strong>。它给出了概率。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/fdbfdf16938682145c530b95e1ed60bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*N1S3Xg0ymbxyBJdHgKHqBg.png"/></div></figure><p id="6298" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">拟合模型后，我们发现模型的准确性。我生成了混淆矩阵，它做得还不错。最后我们会对所有的模型进行比较。</p><p id="66b7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">朴素贝叶斯</strong></p><p id="967b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">给定类变量，<strong class="ix hj">朴素贝叶斯分类器</strong>假设类的特定特征的存在(或不存在)与任何其他特征的存在(或不存在)无关。基本上，它是“<strong class="ix hj">天真的</strong>，因为它做出了<strong class="ix hj">的假设，这些假设可能是正确的，也可能不是。</strong></p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/9ed445dbdb7ba3fd5947cbddda326930.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*jjGdvGoPHOXGFCC0bSY8sg.png"/></div></figure><p id="be20" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">决策树</strong></p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/4126f957365b36be1a4837cae2f55d01.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*46UtnfsDpdGI6BBMo4Tl_w.png"/></div></div></figure><p id="dc1e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">决策树是一个分支流程图</strong>，显示了潜在决策和结果的多种途径。<strong class="ix hj">该树从所谓的决策节点</strong>开始，这意味着必须做出决策。从decision节点，为考虑中的每个替代选择创建一个分支。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/f0a89cc811b41077f9bb60237e415cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*dCYLEY1r5ggHu9F24sJukA.png"/></div></figure><p id="d483" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">随机森林</strong></p><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/834ed0b988b67e110a8e820ec6c1e068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Dul5qTpQtlNPB5btB2L77Q.png"/></div></figure><p id="738d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">随机森林是树预测值的组合，其中每棵树都依赖于随机向量的值，该随机向量对森林中的所有树以相同的分布进行独立采样。<strong class="ix hj">基本原理是一群“弱学习者”可以走到一起形成一个“强学习者”。</strong></p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/f3599991a1c15960d1b618c009a1d248.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*pgb7YWocVbU8Z_stZhVE4w.png"/></div></figure><p id="4ca0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我使用了一个模型精度度量来形成所有模型之间的比较研究。为了构建ROC曲线，下面的代码是这样的。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="d575" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了更好的决策，一起计算关于准确度、精确度、召回率、ROC分数的上述模型的比较研究。</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/8e26cacf3ee0c6ebcdbfa14d10a80883.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*RCqmeOu39HUnCtGNbcSubA.png"/></div></figure><p id="3454" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从上表可以看出，随机森林给出了最好的准确性和ROC得分。</p><p id="bd1b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所有的ROC曲线如下所示。</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/6c32a952e9c0ec4bb6c5a18438538dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*N9JHCvAoKvvjGALZzWiZSA.png"/></div></figure><p id="5c6a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">随机森林覆盖的面积最大，因此是更好的模型。</strong>我没有在这个问题上尝试过神经网络，因为只有30K以上的数据点，我觉得它会过度拟合数据。为了进一步改进，可以使用更复杂的集成方法。此外，根据奥卡姆剃刀理论，“最简单的解释很可能是正确的”。</p><p id="90d0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">关于这个项目的详细报告可以在我的kaggle笔记本上找到。</p><p id="8e65" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你喜欢这个，你可能会喜欢我的其他文章。一定要退房。</p><p id="4495" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果有什么地方我可以做得更好，请告诉我。</p><p id="14b4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">感谢阅读！！</strong></p><div class="mn mo ez fb mp mq"><a href="https://www.kaggle.com/coding16/classify-using-multiple-models" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hj fi z dy mv ea eb mw ed ef hh bi translated">使用多个模型进行分类</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自成人人口普查收入的数据</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">www.kaggle.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne io mq"/></div></div></a></div></div></div>    
</body>
</html>