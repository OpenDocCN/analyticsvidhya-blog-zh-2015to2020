<html>
<head>
<title>Understanding Customer’s Behaviour during Black Friday</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解顾客在黑色星期五的行为</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-customers-behaviour-during-black-friday-2cc2d644d7a?source=collection_archive---------8-----------------------#2020-06-28">https://medium.com/analytics-vidhya/understanding-customers-behaviour-during-black-friday-2cc2d644d7a?source=collection_archive---------8-----------------------#2020-06-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="c582" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用机器学习预测销售。</h2></div><p id="fc4f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated">在这个项目中，我们将使用年龄、性别、婚姻状况等各种特征来预测顾客在黑色星期五会花多少钱。我们将要使用的数据集是来自Kaggle的黑色星期五数据集，它包含大约550068行和12个特征，可以在这里<a class="ae kc" href="https://www.kaggle.com/sdolezel/black-friday" rel="noopener ugc nofollow" target="_blank">下载</a>。我们将遵循从数据收集到模型部署的数据科学生命周期的所有步骤。</p><blockquote class="kd ke kf"><p id="e5d9" class="ix iy kg iz b ja jb ij jc jd je im jf kh jh ji jj ki jl jm jn kj jp jq jr js hb bi translated">web app:【https://black-friday-sales-prediction.herokuapp.com/ T4】</p></blockquote><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es kk"><img src="../Images/0e8328d77140721b33f3ad8fa800b32b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2IkMtl3ovQwT1wnc"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">由<a class="ae kc" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h2 id="f850" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">动机</h2><p id="5033" class="pw-post-body-paragraph ix iy hi iz b ja lv ij jc jd lw im jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated">预测客户行为是机器学习在金融、销售、营销等各个领域最受欢迎的应用之一。通过构建这样的预测模型，我们可以预测所采取的决策对我们组织发展的影响。</p></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="ead5" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">理解问题</h2><p id="56e2" class="pw-post-body-paragraph ix iy hi iz b ja lv ij jc jd lw im jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated">在我们开始之前，重要的是我们理解这个问题，以便我们能够容易地选择可以应用于从数据集学习的算法类型。数据集包含我们必须预测哪个是从属特征“购买”的标签。此外，该特征的数据类型是连续的。所以我们的问题是一个<strong class="iz hj">监督回归</strong>类型。</p></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="8356" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">步骤0:导入库和数据集</h2><p id="a222" class="pw-post-body-paragraph ix iy hi iz b ja lv ij jc jd lw im jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated">所有的标准库，如numpy、pandas、matplotlib和seaborn都是在这一步导入的。我们使用numpy进行线性代数运算，pandas使用数据框，matplotlib和seaborn绘制图形。使用pandas命令<em class="kg"> read_csv() </em>导入数据集。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="be71" class="la lb hi mi b fi mm mn l mo mp"><em class="kg"># Import libraries</em><br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="86ae" class="la lb hi mi b fi mq mn l mo mp"><em class="kg"># Importing dataset</em><br/>train = pd.read_csv('train.csv')</span></pre></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="7894" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">步骤1:描述性分析</h2><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="edee" class="la lb hi mi b fi mm mn l mo mp"><em class="kg"># Preview dataset</em><br/>train.head()</span></pre><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mr"><img src="../Images/9de0c4b541ea54384bf944add0f58a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZIQmo8q7zhyHs1txv4OMDw.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">数据集预览</figcaption></figure><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="8195" class="la lb hi mi b fi mm mn l mo mp"><em class="kg"># Dataset dimensions - (rows, columns)</em><br/>print('Rows: {} Columns:{}'.format(train.shape[0],train.shape[1]))</span><span id="f605" class="la lb hi mi b fi mq mn l mo mp"><strong class="mi hj">Output:</strong><br/>Rows: 550068 Columns: 12</span><span id="0aa0" class="la lb hi mi b fi mq mn l mo mp"><em class="kg"># Features data-type</em><br/>train.info()</span><span id="3ed3" class="la lb hi mi b fi mq mn l mo mp"><strong class="mi hj">Output:<br/></strong>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 550068 entries, 0 to 550067<br/>Data columns (total 12 columns):<br/> #   Column                      Non-Null Count   Dtype  <br/>---  ------                      --------------   -----  <br/> 0   User_ID                     550068 non-null  int64  <br/> 1   Product_ID                  550068 non-null  object <br/> 2   Gender                      550068 non-null  object <br/> 3   Age                         550068 non-null  object <br/> 4   Occupation                  550068 non-null  int64  <br/> 5   City_Category               550068 non-null  object <br/> 6   Stay_In_Current_City_Years  550068 non-null  object <br/> 7   Marital_Status              550068 non-null  int64  <br/> 8   Product_Category_1          550068 non-null  int64  <br/> 9   Product_Category_2          376430 non-null  float64<br/> 10  Product_Category_3          166821 non-null  float64<br/> 11  Purchase                    550068 non-null  int64  <br/>dtypes: float64(2), int64(5), object(5)<br/>memory usage: 50.4+ MB</span><span id="be3c" class="la lb hi mi b fi mq mn l mo mp"><em class="kg"># Statistical summary</em><br/>train.describe().T</span></pre><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es ms"><img src="../Images/67ad8ba1e3e32f8d7b8f1839b4c4446a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0arwtHdRSoFy2VmIp2pmrA.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">数据集描述</figcaption></figure><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="4994" class="la lb hi mi b fi mm mn l mo mp"><em class="kg"># Checking for Null values</em><br/>round((train.isnull().sum()/train.shape[0])*100,2).astype(str)+ ' %'</span><span id="a539" class="la lb hi mi b fi mq mn l mo mp"><strong class="mi hj">Output:<br/></strong>User_ID                         0.0 %<br/>Product_ID                      0.0 %<br/>Gender                          0.0 %<br/>Age                             0.0 %<br/>Occupation                      0.0 %<br/>City_Category                   0.0 %<br/>Stay_In_Current_City_Years      0.0 %<br/>Marital_Status                  0.0 %<br/>Product_Category_1              0.0 %<br/>Product_Category_2            31.57 %<br/>Product_Category_3            69.67 %<br/>Purchase                        0.0 %<br/>dtype: object</span><span id="bf01" class="la lb hi mi b fi mq mn l mo mp"><em class="kg"># Checking the counts of unique values</em><br/>round((train['Age'].value_counts(normalize = True).mul(100)), 2).astype(str) + ' %'</span><span id="0cbe" class="la lb hi mi b fi mq mn l mo mp"><strong class="mi hj">Output:<br/></strong>26-35    39.92 %<br/>36-45     20.0 %<br/>18-25    18.12 %<br/>46-50     8.31 %<br/>51-55      7.0 %<br/>55+       3.91 %<br/>0-17      2.75 %<br/>Name: Age, dtype: object</span><span id="575c" class="la lb hi mi b fi mq mn l mo mp"><em class="kg"># Checking the counts of unique values</em><br/>round((train['Stay_In_Current_City_Years'].value_counts(normalize = True).mul(100)), 2).astype(str) + ' %'</span><span id="3b5f" class="la lb hi mi b fi mq mn l mo mp"><strong class="mi hj">Output:<br/></strong>1     35.24 %<br/>2     18.51 %<br/>3     17.32 %<br/>4+     15.4 %<br/>0     13.53 %<br/>Name: Stay_In_Current_City_Years, dtype: object</span></pre><blockquote class="kd ke kf"><p id="7ae8" class="ix iy kg iz b ja jb ij jc jd je im jf kh jh ji jj ki jl jm jn kj jp jq jr js hb bi translated"><strong class="iz hj">观察:</strong></p><p id="eac2" class="ix iy kg iz b ja jb ij jc jd je im jf kh jh ji jj ki jl jm jn kj jp jq jr js hb bi translated">1.特征‘Product _ Category _ 2’包含31.57%可以估算的空值，而‘Product _ Category _ 3’包含69.67%的空值，因此我们可以删除此特征。</p><p id="e236" class="ix iy kg iz b ja jb ij jc jd je im jf kh jh ji jj ki jl jm jn kj jp jq jr js hb bi translated">2.特征“年龄”和“停留在当前城市年数”包含一些值，这些值中包含需要替换的“+”。</p></blockquote></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="46cf" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">步骤2:探索性数据分析</h2><p id="6f75" class="pw-post-body-paragraph ix iy hi iz b ja lv ij jc jd lw im jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated"><strong class="iz hj"> <em class="kg"> 2.1单因素分析:</em> </strong></p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mt"><img src="../Images/65d4c00b08300f8a778ce0625ccc8676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R3qhsHzbj0UKzLr_L5T9VA.png"/></div></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mu"><img src="../Images/6f784290cd0de245700baea1e3048589.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*zip5j6coFdHEKCJDhxF0QQ.png"/></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mv"><img src="../Images/b86d3eb3f24c420ee4afb2c86419a4d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*nakK2Y0EiFdsv-XVKFvJ1g.png"/></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mw"><img src="../Images/14099e60eea6973ecca2e7b48253071d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WouxSy8_Nn6C4Pf3XGJtyQ.png"/></div></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mx"><img src="../Images/58b7db7209f47e4f2f6eb9fc64fd0575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*QsufWnvVyfWqZR0cIP4p7g.png"/></div></figure><p id="d1ac" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> <em class="kg"> 2.2双变量分析:</em> </strong></p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es my"><img src="../Images/593ce7d04a5cf95014bd48448fbde622.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*loH_pL7X-FVwViEi62Vfbg.png"/></div></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mz"><img src="../Images/935263d28055bba774f5c022b655533d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U13KQOwKKdizU7ogtNOo4w.png"/></div></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es my"><img src="../Images/4535842451cc1ca0518235f0d4d101e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yBLxjozFg6r58VzHSTUeew.png"/></div></div></figure><p id="88de" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> <em class="kg"> 2.3多元分析:</em> </strong></p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es na"><img src="../Images/46a79335a331d21ff11ed90169e6d4de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*uKaPYTwWQ8W2vczAnTad0A.png"/></div></figure><blockquote class="kd ke kf"><p id="11fe" class="ix iy kg iz b ja jb ij jc jd je im jf kh jh ji jj ki jl jm jn kj jp jq jr js hb bi translated"><strong class="iz hj">观察:</strong></p><p id="6356" class="ix iy kg iz b ja jb ij jc jd je im jf kh jh ji jj ki jl jm jn kj jp jq jr js hb bi translated">1.从性别分布图中可以观察到一个有趣的现象，在黑色星期五购物的女性人数少于男性。</p><p id="8c8a" class="ix iy kg iz b ja jb ij jc jd je im jf kh jh ji jj ki jl jm jn kj jp jq jr js hb bi translated">2.从关联热图中，我们可以观察到从属特征“购买”与“产品_类别_1”和“产品_类别_2”高度相关。</p></blockquote></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="cb7d" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">步骤3:数据预处理</h2><p id="303b" class="pw-post-body-paragraph ix iy hi iz b ja lv ij jc jd lw im jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated">“年龄”和“停留当前城市年数”中的“+”值需要固定，这可以通过使用<em class="kg">来完成。替换()</em>命令。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="2c8c" class="la lb hi mi b fi mm mn l mo mp">train['Age'] = train['Age'].apply(lambda x:str(x).replace('55+', '55'))</span><span id="cd88" class="la lb hi mi b fi mq mn l mo mp">train['Stay_In_Current_City_Years'] = train['Stay_In_Current_City_Years'].apply(lambda x : str(x).replace('4+', '4'))</span><span id="2582" class="la lb hi mi b fi mq mn l mo mp">train['Stay_In_Current_City_Years'] = train['Stay_In_Current_City_Years'].astype('int')</span></pre><p id="e686" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">功能“用户标识”和“产品标识”不相关，需要删除这些功能。功能“Product_Category_3”包含69.67 %的空值，因此也需要删除。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="ad0c" class="la lb hi mi b fi mm mn l mo mp">train.drop(['User_ID', 'Product_ID', 'Product_Category_3'], axis = 1, inplace = True)</span></pre><p id="1ea8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">“年龄”、“性别”和“城市类别”是我们数据集中的离散对象特征，需要对其进行编码以便进一步使用。这可以使用sklearn预处理库中的<strong class="iz hj">标签编码器</strong>来完成。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="5a48" class="la lb hi mi b fi mm mn l mo mp">from sklearn.preprocessing import LabelEncoder</span><span id="1855" class="la lb hi mi b fi mq mn l mo mp">label_encoder_gender = LabelEncoder()<br/>train['Gender'] = label_encoder_gender.fit_transform(train['Gender'])<br/><br/>label_encoder_age = LabelEncoder() <br/>train['Age'] = label_encoder_age.fit_transform(train['Age'])</span><span id="f0b1" class="la lb hi mi b fi mq mn l mo mp">label_encoder_city = LabelEncoder()<br/>train['City_Category'] = label_encoder_city.fit_transform(train['City_Category'])</span></pre><p id="5c6f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">功能“Product_Category_2”包含31.57%的空值，可以通过使用功能的中值填充它们来轻松修复。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="f88c" class="la lb hi mi b fi mm mn l mo mp">train['Product_Category_2'].fillna(train['Product_Category_2'].median(), inplace = True)</span></pre><p id="9021" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，数据集被分成包含所有独立功能的X和包含相关功能“购买”的Y。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="57be" class="la lb hi mi b fi mm mn l mo mp">X = train.drop("Purchase", axis = 1)<br/>Y = train["Purchase"]</span></pre><p id="7310" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以通过执行<strong class="iz hj">特征选择</strong>来处理多重共线性的诅咒。使用<em class="kg">提取树回归器</em>可以很容易地找到特征的重要性。它告诉我们，“性别”、“城市类别”和“婚姻状况”是数据集中被丢弃的最不重要的特征。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="a07b" class="la lb hi mi b fi mm mn l mo mp">from sklearn.ensemble import ExtraTreesRegressor <br/>selector = ExtraTreesRegressor()</span><span id="88bf" class="la lb hi mi b fi mq mn l mo mp">selector.fit(X, Y)<br/>feature_imp = selector.feature_importances_</span><span id="072e" class="la lb hi mi b fi mq mn l mo mp">for index, val in enumerate(feature_imp):<br/>    print(index, round((val * 100), 2))</span><span id="398a" class="la lb hi mi b fi mq mn l mo mp"><strong class="mi hj">Output:</strong></span><span id="52f5" class="la lb hi mi b fi mq mn l mo mp">0 0.54<br/>1 2.16<br/>2 5.03<br/>3 0.76<br/>4 2.7<br/>5 0.63<br/>6 75.79<br/>7 12.37</span><span id="d173" class="la lb hi mi b fi mq mn l mo mp">X.drop(['Gender', 'City_Category', 'Marital_Status'], axis = 1, inplace = True)</span></pre><p id="feb1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了有效地建立模型，我们可以使用<strong class="iz hj">特征缩放</strong>来标准化数据集。这可以用sklearn预处理库中的<em class="kg"> StandardScaler() </em>来完成。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="9847" class="la lb hi mi b fi mm mn l mo mp">from sklearn.preprocessing import StandardScaler<br/>scaler = StandardScaler()</span><span id="c88e" class="la lb hi mi b fi mq mn l mo mp">for col in X.columns:<br/>  X[col] = scaler.fit_transform(X[col].values.reshape(-1, 1))</span></pre><p id="71f7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用<em class="kg"> train_test_split() </em>命令将数据集分割成比例为80:20的训练数据和测试数据。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="3bc6" class="la lb hi mi b fi mm mn l mo mp">from sklearn.model_selection import train_test_split<br/>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)</span><span id="78f5" class="la lb hi mi b fi mq mn l mo mp">print("X_train shape:", X_train.shape)<br/>print("X_test shape:", X_test.shape)<br/>print("Y_train shape:", Y_train.shape)<br/>print("Y_test shape:", Y_test.shape)</span><span id="d566" class="la lb hi mi b fi mq mn l mo mp"><strong class="mi hj">Output:<br/></strong><br/>X_train shape: (440054, 5) <br/>X_test shape: (110014, 5) <br/>Y_train shape: (440054,) <br/>Y_test shape: (110014,)</span></pre></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="0a94" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">步骤4:数据建模</h2><p id="dc8d" class="pw-post-body-paragraph ix iy hi iz b ja lv ij jc jd lw im jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated">极端梯度推进回归器:</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="af04" class="la lb hi mi b fi mm mn l mo mp">from xgboost import XGBRegressor <br/>xgb = XGBRegressor(random_state = 42)<br/><br/>xgb.fit(X_train, Y_train)<br/>Y_pred_xgb = xgb.predict(X_test)</span></pre><blockquote class="nb"><p id="2b4d" class="nc nd hi bd ne nf ng nh ni nj nk js dx translated">理解算法:</p></blockquote><p id="35b2" class="pw-post-body-paragraph ix iy hi iz b ja nl ij jc jd nm im jf jg nn ji jj jk no jm jn jo np jq jr js hb bi translated">极端梯度推进或XGBoost回归器是一种集成学习技术，其中按顺序构建树，使得每棵树从其前任学习残差。XGBoost背后的基本思想是，我们构建一个模型，对参数和特性重要性进行假设。然后，我们利用这些结论建立一个更好的模型，从前人的错误中学习，并试图减少它。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es nq"><img src="../Images/ab7a22c6f2210f4a9da44375149afb0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DwvwMlOcT1T9hZwIJvMfng.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><a class="ae kc" rel="noopener" href="/ml-research-lab/boosting-ensemble-meta-algorithm-for-reducing-bias-5b8bfdce281">图像信用</a></figcaption></figure><p id="deba" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">XGBoost有许多可以在训练前设置的调优参数。最常见的有learning_rate、max_depth、subsample、colsample_bytree、n_estimators、objective和正则化参数，如gamma、alpha、lambda。学习率定义步长，max_depth确定允许每棵树生长多深，subsample是每棵树使用的样本的百分比，colsample_bytree定义特征的数量，n_estimators是树的数量，objective确定损失函数。Gamma控制给定节点是否会根据拆分后预期的损失减少量进行拆分。α控制L1正则化，λ控制L2正则化。</p><p id="dd51" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">XGBoost是一种流行的梯度提升方法，这是由于它的一些功能，如防止过度拟合的正则化、处理丢失值的稀疏数据、用于更快计算的并行学习以及用于优化硬件使用的缓存感知。由于其速度和出色的性能，它是竞赛和黑客马拉松中最受欢迎的建模算法之一。</p></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="1c14" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">第五步:模型评估</h2><p id="4834" class="pw-post-body-paragraph ix iy hi iz b ja lv ij jc jd lw im jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated">为了评估该模型，我们将使用两个指标，均方根误差(RMSE)和R平方得分(r2得分)。RMSE是误差方差的平方根。RMSE值越低，模型越好。R平方是数据与拟合回归线接近程度的统计度量。其值范围从0到1，值越高，模型越好。R2评分通常用于比较各种预测模型。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="9560" class="la lb hi mi b fi mm mn l mo mp">from sklearn.metrics import mean_squared_error<br/>from sklearn.metrics import r2_score</span><span id="ee18" class="la lb hi mi b fi mq mn l mo mp">print("XGB regression:")<br/>print("RMSE:",np.sqrt(mean_squared_error(Y_test, Y_pred_xgb)))<br/>print("R2 score:", r2_score(Y_test, Y_pred_xgb))</span><span id="531a" class="la lb hi mi b fi mq mn l mo mp"><strong class="mi hj">Output:</strong><br/>XGB regression:  <br/>RMSE: 3024.8703086442342 <br/>R2 score: 0.6358443502285505</span></pre></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="0e40" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">步骤6:超参数调整</h2><p id="06e6" class="pw-post-body-paragraph ix iy hi iz b ja lv ij jc jd lw im jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated">每个机器学习模型的核心都有一个数学模型，其中包含许多需要从数据中学习的参数。超参数是一种特殊的参数，它不能从数据中学习，并且在训练开始之前是固定的。在这一步中，我们将为我们的模型选择正确的超参数，这将为我们提供更好的预测。</p><p id="20fb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可以使用RandomizedSearchCV或GridSearchCV来调整超参数。我们将对这个数据集使用RandomizedSearchCV。RandomziedSearchCV通过随机搜索找到最佳超参数，避免不必要的计算。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="f0c2" class="la lb hi mi b fi mm mn l mo mp">from sklearn.model_selection import RandomizedSearchCV</span><span id="1ab2" class="la lb hi mi b fi mq mn l mo mp">max_depth = [int(x) for x in np.linspace(start = 5, stop = 20, num = 15)]<br/>learning_rate = ['0.01', '0.05', '0.1', '0.25', '0.5', '0.75', '1.0']<br/>min_child_weight = [int(x) for x in np.linspace(start = 45, stop = 70, num = 15)]</span><span id="3974" class="la lb hi mi b fi mq mn l mo mp">params = {<br/>"learning_rate"    : learning_rate,<br/>"max_depth"        : max_depth,<br/>"min_child_weight" : min_child_weight,<br/>"gamma"            : [0.0, 0.1, 0.2 , 0.3, 0.4],<br/>"colsample_bytree" : [0.3, 0.4, 0.5 , 0.7]<br/>}</span><span id="236a" class="la lb hi mi b fi mq mn l mo mp">xgb_tune = XGBRegressor(random_state = 42)</span><span id="b0ca" class="la lb hi mi b fi mq mn l mo mp">xgb_cv = RandomizedSearchCV(xgb_tune, param_distributions = params, cv = 5, verbose = 0, random_state = 42)</span><span id="2c69" class="la lb hi mi b fi mq mn l mo mp">xgb_cv.fit(X_train, Y_train)</span><span id="af6e" class="la lb hi mi b fi mq mn l mo mp">xgb_cv.best_score_<br/><strong class="mi hj">Output:</strong> 0.6512707227919969</span><span id="32a3" class="la lb hi mi b fi mq mn l mo mp">xgb_cv.best_params_<br/><strong class="mi hj">Output:</strong><br/>{'colsample_bytree': 0.7,  'gamma': 0.3,  'learning_rate': '1.0',  'max_depth': 11,  'min_child_weight': 66}</span></pre><p id="e148" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们使用RadomizedSearchCV来查找参数“learning_rate”、“max_depth”、“colsample_bytree”、“gamma”和“min_child_weight”的最佳值。</p><pre class="kl km kn ko fd mh mi mj mk aw ml bi"><span id="f853" class="la lb hi mi b fi mm mn l mo mp">xgb_best = XGBRegressor(colsample_bytree = 0.7, gamma = 0.3, learning_rate = 1.0, max_depth = 11, min_child_weight = 66, verbosity = 0, random_state = 42)</span><span id="9d26" class="la lb hi mi b fi mq mn l mo mp">xgb_best.fit(X_train, Y_train)</span><span id="c2dc" class="la lb hi mi b fi mq mn l mo mp">Y_pred_xgb_best = xgb_best.predict(X_test)</span><span id="a18d" class="la lb hi mi b fi mq mn l mo mp">print("XGB regression: ") print("RMSE:",np.sqrt(mean_squared_error(Y_test, Y_pred_xgb_best))) print("R2 score:", r2_score(Y_test, Y_pred_xgb_best))</span><span id="1721" class="la lb hi mi b fi mq mn l mo mp"><strong class="mi hj">Output:<br/></strong>XGB regression:  <br/>RMSE: 2985.7374358000807 <br/>R2 score: 0.6452055961121277</span></pre><p id="63d6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在超参数调整xgboost回归器后，我们发现最佳RMSE值为2985，R2分数为0.64。</p></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="add8" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">步骤7:模型部署</h2><p id="a996" class="pw-post-body-paragraph ix iy hi iz b ja lv ij jc jd lw im jf jg lx ji jj jk ly jm jn jo lz jq jr js hb bi translated">为了部署我们的模型，我们将首先使用<strong class="iz hj"> Flask </strong>微框架构建一个web应用程序。这个应用程序可以使用<strong class="iz hj"> Heroku </strong>部署到网络上。Heroku是一个平台即服务(PaaS ),使开发人员能够完全在云中构建、运行和操作应用程序。申请发现<a class="ae kc" href="https://black-friday-sales-prediction.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es nr"><img src="../Images/bd8fb2467c2f8a3c557a57a04c9e28d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*a8hzirIrAdB-qD1uAhcE_Q.gif"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">Heroku上部署的Flask WebApp</figcaption></figure></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><h2 id="d3dd" class="la lb hi bd lc ld le lf lg lh li lj lk jg ll lm ln jk lo lp lq jo lr ls lt lu bi translated">未来工作:</h2><ul class=""><li id="e8c6" class="ns nt hi iz b ja lv jd lw jg nu jk nv jo nw js nx ny nz oa bi translated">我们有一个足够大的数据集，所以我们可以使用人工神经网络等神经网络来建立一个可以产生更好性能的模型。</li></ul></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><p id="5d4f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> Github库:</strong></p><div class="ob oc ez fb od oe"><a href="https://github.com/Aditya-Mankar/Black-Friday-Sales-Prediction" rel="noopener  ugc nofollow" target="_blank"><div class="of ab dw"><div class="og ab oh cl cj oi"><h2 class="bd hj fi z dy oj ea eb ok ed ef hh bi translated">aditya-Mankar/黑色星期五-销售-预测</h2><div class="ol l"><h3 class="bd b fi z dy oj ea eb ok ed ef dx translated">在这个项目中，我们将建立一个回归模型来预测黑色星期五数据集</h3></div><div class="om l"><p class="bd b fp z dy oj ea eb ok ed ef dx translated">github.com</p></div></div><div class="on l"><div class="oo l op oq or on os ku oe"/></div></div></a></div></div></div>    
</body>
</html>