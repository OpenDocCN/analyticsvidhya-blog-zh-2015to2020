<html>
<head>
<title>Creating a CNN using Keras for GTSRB</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras for GTSRB创建CNN</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/creating-a-cnn-using-keras-for-gtsrb-c67e647fb9ca?source=collection_archive---------18-----------------------#2019-11-26">https://medium.com/analytics-vidhya/creating-a-cnn-using-keras-for-gtsrb-c67e647fb9ca?source=collection_archive---------18-----------------------#2019-11-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4e58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我创建了一个CNN模型GTRSB数据集，你可以在kaggle上查看一下这里:<a class="ae jd" href="https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/meowmeowmeowmeowm/gt SRB-german-traffic-sign</a>。</p><p id="318c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">上下文:</strong>gt SRB数据集是一个数据集，它是多类分类算法的众多基准之一。它由43个类别组成，每个类别都是一个不同的路标。CNN的目标是对这些图像进行高精度分类。</p><p id="ef2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我将描述我的方法、代码和数据集的结果。</p><h1 id="7057" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">我的方法</h1><ol class=""><li id="e38a" class="kc kd hi ih b ii ke im kf iq kg iu kh iy ki jc kj kk kl km bi translated"><strong class="ih hj">检查数据:</strong>看了20分钟的数据后，我发现不需要图像放大。这是因为每个类都有大量的数据来训练我的模型。此外，训练集在用于每个类别的图片类型方面有很好的差异(一些图片比其他图片有更多的模糊和噪声)。由于我的数据的性质，这里不需要数据扩充，所以我可以继续下一步。</li><li id="5957" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">创建我的训练和测试集:我使用给定的数据创建了我的训练和测试集。我的输出(Y)是图像的标签(它的类),我的输入(X)是图像的数组表示。通过检查数据，我发现在dataset文件夹中已经有了单独的训练集和测试集，因此我不需要将我的数据分成训练测试比。集合的顺序并不重要，因为当我们稍后将数据拟合到我们的模型时，我们会对数据进行洗牌。</li><li id="c70c" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated"><strong class="ih hj">定义模型的架构:</strong>我创建了CNN模型的架构。这种架构是定制的，因为我发现它在许多其他简单的图像任务中工作得很好，比如GTSRB。然而，这取决于你想要什么，因为有许多不同的架构，如VGG，AlexNet和YOLO。但是不管你用什么架构，最后一层一定是输出神经元数等于类数的密集层。</li><li id="25e7" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated"><strong class="ih hj">设置超参数后，将数据拟合到模型中，等待结果！</strong></li></ol><h1 id="19a2" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">创建训练集和测试集:</h1><p id="eff1" class="pw-post-body-paragraph if ig hi ih b ii ke ik il im kf io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated"><strong class="ih hj">第一步:导入</strong></p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="2ece" class="le jf hi la b fi lf lg l lh li">#import tensorflow as tf (This depends on how you want to configure your GPU<br/>from keras.models import Sequential, save_model<br/>from keras.layers import Conv2D, MaxPool2D, MaxPooling2D, Dense, Dropout, Activation, Flatten<br/>import keras.layers<br/>import cv2 as cv<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import pandas as pd<br/>import os</span></pre><p id="e7b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我在代码的开头导入了预处理和模型初始化所需的所有库。我知道TensorFlow为本地GPU提供了一些定制功能，因此如果您愿意，您可以导入并配置这些功能。</p><p id="08ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤2:创建训练和测试集</strong></p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="499b" class="le jf hi la b fi lf lg l lh li">train_X = []<br/>train_y = []</span><span id="1aa5" class="le jf hi la b fi lj lg l lh li">for i in range(0,43):<br/>    n = str(i)<br/>    train_Path = "gtsrb-german-traffic-sign/Train/" + n<br/>    label = [0 for i in range(0, 43)]<br/>    label[i] = 1<br/>    for filename in os.listdir(train_Path):<br/>        img = cv.imread(train_Path + "/" + filename)<br/>        img = cv.resize(img, (28,28))<br/>        print(filename)<br/>        train_X.append(img)<br/>        train_y.append(label)</span><span id="cd1e" class="le jf hi la b fi lj lg l lh li">train_X = np.asarray(train_X)<br/>train_X = train_X/255<br/>train_X = np.asarray(train_X, dtype = "float32")<br/>train_y = np.asarray(train_y, dtype= "float32")</span></pre><p id="abea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我遍历了所有的文件夹，并添加了(N，K，3)维图像的数组表示，其中N和K可以根据图像的大小而变化。此外，我创建了一个长度为43(有43个类)的零数组，并将对应于图像类的索引转换为1。因为数据集是零索引的，所以我可以简单地将相应的索引更新到图像的类。最后，我将数组从uint8转换为float32的dtype。我这样做是因为对于训练模型来说，这是一个相对安全的数据类型，但是，我事先将我的值缩放了255，以避免在类型转换期间搞砸我的图片。我还将我的图像大小调整为28x28，因为训练集中的所有图像都有不同的大小，但没有一个小于28x28。因此，为了最大限度地减少功能损失，这些是调整大小的最佳尺寸。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="44c8" class="le jf hi la b fi lf lg l lh li">counter = 0<br/>test_X = []<br/>test_y = []<br/>test_Path = "gtsrb-german-traffic-sign/Test"<br/>for filename in os.listdir(test_Path):<br/>        img = cv.imread(test_Path + "/" + filename)<br/>        img = cv.resize(img, (28,28))<br/>        label = [0 for i in range(0, 43)]<br/>        #6 is the column # within the .CSV file        label[df.loc[counter][6]] = 1<br/>        print(filename)<br/>        test_X.append(img)<br/>        test_y.append(label)<br/>        counter += 1</span><span id="5557" class="le jf hi la b fi lj lg l lh li">test_X = np.asarray(test_X)<br/>test_X = test_X/255<br/>test_X = np.asarray(test_X, dtype = "float32")<br/>test_y = np.asarray(test_y, dtype= "float32")</span></pre><p id="68c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用了与上面相同的逻辑来创建我的测试集，但是我必须使用一点pandas。loc方法)来遍历. CSV文件中代表每张图片的类别的一列，以创建我的标签。</p><p id="9d8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第三步:创建模型</strong></p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="e7c0" class="le jf hi la b fi lf lg l lh li">model = Sequential()<br/>model.add(Conv2D(32, (3, 3), padding='same',<br/>                 input_shape=train_X.shape[1:]))<br/>model.add(Activation('relu'))<br/>model.add(Conv2D(32, (3, 3)))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))</span><span id="79db" class="le jf hi la b fi lj lg l lh li">model.add(Conv2D(64, (3, 3), padding='same'))<br/>model.add(Activation('relu'))<br/>model.add(Conv2D(64, (3, 3)))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))</span><span id="85df" class="le jf hi la b fi lj lg l lh li">model.add(Flatten())<br/>model.add(Dense(392))<br/>model.add(Activation('relu'))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(43))<br/>model.add(Activation('softmax'))</span></pre><p id="4455" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我为这个任务创建了一个简单的CNN。我混合使用了卷积层和池层，以减少我需要插入到密集网络中的数据量，并减少了一些丢弃以防止过度拟合。我不会在这篇文章中详细介绍这是如何工作的，但如果你不明白发生了什么，那么这是一篇非常好的直觉文章:<a class="ae jd" href="https://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/" rel="noopener ugc nofollow" target="_blank">https://adventuresinmachinehlearning . com/keras-tutorial-CNN-11-lines/</a></p><p id="985b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第四步:初始化一些超参数，训练模型</strong></p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="dbd5" class="le jf hi la b fi lf lg l lh li">opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)<br/>model.compile(loss='categorical_crossentropy',<br/>              optimizer=opt,<br/>              metrics=['accuracy'])</span><span id="c2db" class="le jf hi la b fi lj lg l lh li">history = model.fit(train_X, train_y,<br/>              batch_size= 16,<br/>              epochs= 6,<br/>              validation_data= (test_X, test_y),<br/>              shuffle=True)</span></pre><p id="8129" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个任务，我使用RMSprop，学习率为0.0001，分类交叉熵表示我的损失。我想使用准确性作为衡量标准，因为它有助于我更好地理解我的模型的性能。</p><p id="5597" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结果</strong></p><p id="f484" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运行完模型后，我最后的准确率达到了94%，这就可以了。</p><figure class="kv kw kx ky fd ll er es paragraph-image"><div class="er es lk"><img src="../Images/76f767260398925f3932e3b55d35c31c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*s2Eu_DEDpdslPV79.png"/></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">随着时间的推移，使用matplotlib来提高我的准确性</figcaption></figure><figure class="kv kw kx ky fd ll er es paragraph-image"><div class="er es lk"><img src="../Images/55885106a6062586e0269ac8b0fc4e66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*5PnMVZt3ojfVGwWV.png"/></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">一个使用matplotlib的可视化工具来弥补我的损失</figcaption></figure><figure class="kv kw kx ky fd ll er es paragraph-image"><div class="er es ls"><img src="../Images/ddb9e796ca42c2db69e247dec4fb3a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/0*uznrTnaiOczAdzrF.png"/></div></figure><p id="1aa4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如你所见，我的模型收敛得很好，精度也很高。为了改进它，我可以尝试使用Adam optimizer而不是RMSprop，或者通过减少我的Conv图层并增加大小或添加更密集的图层来保留更多功能，从而使我的模型更深入。</p><p id="b3cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我从我的项目中学到了什么:</strong></p><ul class=""><li id="b3a5" class="kc kd hi ih b ii ij im in iq lt iu lu iy lv jc lw kk kl km bi translated">当我查看数据集时，我不认为我的CNN能够区分具有相同标志形状但标志上不同数字代表速度限制的图像。原来CNN比我想象的厉害多了！</li><li id="4c79" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc lw kk kl km bi translated">我还学习了如何使用<em class="lx"> OS </em>包遍历文件。我以前使用常规的字符串操作来遍历文件，但事实证明OS包使这项工作变得容易得多。</li></ul><p id="622c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢阅读我的文章！如果我在某个地方犯了错误，或者如果我在某些方面可以改进，请随时给我一些建议或批评。我只是一名高中生，所以我有很多成长和犯错的空间。如果您有任何问题或需要澄清，我邀请您在下面发表评论。</p></div></div>    
</body>
</html>