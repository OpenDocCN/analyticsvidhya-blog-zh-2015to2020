<html>
<head>
<title>Getting started with NLP: Tokenization, Document-Term Matrix, TF-IDF</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP入门:标记化、文档术语矩阵、TF-IDF</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/getting-started-with-nlp-tokenization-document-term-matrix-tf-idf-2ea7d01f1942?source=collection_archive---------7-----------------------#2020-08-03">https://medium.com/analytics-vidhya/getting-started-with-nlp-tokenization-document-term-matrix-tf-idf-2ea7d01f1942?source=collection_archive---------7-----------------------#2020-08-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="75c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应用基本的自然语言处理技术对推文进行文本分类:真的还是假的？</p><p id="df0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我们继续描述一些传统的方法来处理自然语言处理任务，文本分类。</p><p id="3ad5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个简单快速的文本分类器，基于传统的自然语言处理方法。接下来的步骤是:</p><ul class=""><li id="4d0e" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">描述标记化的过程</li><li id="87f7" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">如何建立一个术语文档矩阵(使用一些方法，如字数统计和TFIDF)作为数字化方法</li><li id="e730" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">然后应用机器学习分类器来预测或分类一条推文是真的还是假的。</li></ul><p id="3f47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">博文及代码可在</strong> <a class="ae jr" href="https://edumunozsala.github.io/BlogEms/jupyter/nlp/classification/python/2020/07/31/Intro_NLP_1_TFIDF_Text_Classification.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">我的fastai pages博客</strong> </a> <strong class="ih hj">上获取。</strong></p><h1 id="cf8a" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">问题描述</h1><p id="222a" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated"><em class="kv">推特已经成为紧急时刻的重要沟通渠道。智能手机的普及使人们能够实时宣布他们正在观察的紧急情况。正因为如此，越来越多的机构对有计划地监控Twitter感兴趣(如救灾组织和新闻机构)。但是，人们并不总是清楚一个人的话是否实际上是在宣布一场灾难。</em></p><p id="ee08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kv">在这个问题中，你面临的挑战是建立一个机器学习模型，预测哪些推文是关于真正的灾难，哪些不是。你将可以访问一个由10，000条推文组成的数据集，这些推文已经过人工分类。</em></p><p id="62c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是NLP入门的一场竞赛。</p><p id="b483" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练和测试集中的每个样本都有以下信息:</p><ul class=""><li id="a2cf" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">一条推文的文本</li><li id="e74c" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">那条推文中的一个关键词(虽然这可能是空白的！)</li><li id="fd3a" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">发送推文的位置(也可以是空白的)</li></ul><p id="ef0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你在预测一条推文是否是关于一场真正的灾难。如果是，预测一个1。如果没有，预测0。</p><p id="4297" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">代码在我的github账号</strong>  <strong class="ih hj">的一个</strong> <a class="ae jr" href="https://github.com/edumunozsala/Intro-NLP-Text-Classification/blob/master/Intro_NLP_1_TFIDF_Text_Classification.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">笔记本上。</strong></a></p><h1 id="659f" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">准备数据</h1><p id="eae0" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated"><strong class="ih hj">这篇文章不包括如何实现最好的预处理来清理我们的推文</strong>。因此，我们将按原样向我们的模型提供tweet，或者只删除字母数字字符。为了更好的结果，我们应该检查推文，并应用一些清除无用的单词，拼写错误的单词，表情符号，也许URIs，…</p><p id="b62f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将训练数据集分为训练和验证数据集，这样我们就可以评估结果并应用交叉验证等技巧。这项工作是在许多其他笔记本中使用sklearn完成的。</p><h1 id="cd1a" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">标记化</h1><p id="9c5b" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">标记化是自然语言处理中的一项常见任务。无论是在计数矢量器等传统方法中，还是在RNN或变形金刚等基于深度学习的架构中，这都是一个基本步骤。</p><blockquote class="kw kx ky"><p id="f453" class="if ig kv ih b ii ij ik il im in io ip kz ir is it la iv iw ix lb iz ja jb jc hb bi translated">给定一个字符序列和一个已定义的文档单元，标记化是将它分割成称为标记的片段的任务，可能同时丢弃某些字符，如标点符号。这里有一个标记化的例子:</p></blockquote><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es lc"><img src="../Images/17b72ae6b7a03c73ef20499c017f62a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*a9-NPYs-gBa2668C4WON3g.jpeg"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">单词标记化</figcaption></figure><blockquote class="kw kx ky"><p id="27f9" class="if ig kv ih b ii ij ik il im in io ip kz ir is it la iv iw ix lb iz ja jb jc hb bi translated">这些标记通常被笼统地称为术语或单词，但有时区分类型/标记是很重要的。令牌是某个特定文档中字符序列的实例，这些字符被组合在一起作为有用的语义单元进行处理。类型是包含相同字符序列的所有标记的类。术语是包含在IR系统字典中的(可能是规范化的)类型。该组索引项可以完全不同于令牌。</p><p id="f25a" class="if ig kv ih b ii ij ik il im in io ip kz ir is it la iv iw ix lb iz ja jb jc hb bi translated">[1]斯坦福大学NLP小组，<a class="ae jr" href="https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html" rel="noopener ugc nofollow" target="_blank">https://NLP . Stanford . edu/IR-book/html/html edition/token ization-1 . html</a></p></blockquote><p id="203e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kv">“标记化是文本数据建模的首要步骤。对语料库执行标记化以获得标记。然后，使用以下标记来准备词汇表。词汇指的是语料库中的唯一标记集。请记住，可以通过考虑语料库中的每个唯一标记或通过考虑前K个频繁出现的单词来构建词汇”。[2] </em>什么是NLP中的标记化？这里有你需要知道的一切由Aravind Pai，<a class="ae jr" href="https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2020/05/what-is-token ization-NLP/</a></p><p id="6462" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的示例中，标记化过程是在用于处理文本的函数内部完成的。sklearn库和它们的模块将标记文本，然后应用一种技术将这些标记转换成数字表示。</p></div><div class="ab cl lo lp gp lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hb hc hd he hf"><h1 id="2f77" class="js jt hi bd ju jv lv jx jy jz lw kb kc kd lx kf kg kh ly kj kk kl lz kn ko kp bi translated">创建特征或数字化文本:术语-文档矩阵</h1><p id="da2a" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated"><em class="kv">“文档-术语矩阵或术语-文档矩阵是描述术语在文档集合中出现的频率的数学矩阵。在文档-术语矩阵中，行对应于集合中的文档，列对应于术语。有各种方案来确定矩阵中每个条目应取的值。tf-idf就是这样一个方案。它们在自然语言处理领域很有用。”</em></p><p id="234f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以将<strong class="ih hj">文档术语矩阵(DTM) </strong>视为单词袋概念的实现。术语文档矩阵通过每个文档跟踪每个术语的术语频率。您从文档的单词包表示开始，然后对于每个文档，您跟踪一个术语存在的次数。根据语料库中的文档数量和每个文档中的术语数量，文档术语矩阵可以变成非常大的稀疏矩阵(0比值多很多)。</p><p id="77e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑到我们的数据是文本格式的tweets(文档)的集合，该过程将需要对文本进行标记以获得一组标记(我们词汇表中的项目)，在这个阶段，我们通常会减少标记的术语数量，删除那些似乎不相关的术语。如果我们的vocab包含太多的单词，其中许多是不相关的，我们将花费许多资源，并且我们的DTM可能对该过程无用。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es ma"><img src="../Images/953ab151930eae61e67dc6afb6786d9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*hKfC8g_7Ghv9Z36MeRj8GA.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">文档术语矩阵</figcaption></figure><h1 id="a673" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">计数矢量器</h1><p id="c512" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">现在是时候将一组文本文档(我们的推文)转换成一个令牌/字数矩阵(DTM)。如果您不提供先验词典，并且不使用进行某种特征选择的分析器，那么特征的数量将等于通过分析数据找到的词汇大小。</p><p id="edca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们简单地统计这个术语在文档中出现的次数，它将是cell (document，term)的值。</p><h1 id="fe54" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">TF-IDF</h1><p id="d55f" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">另一种制造DTM的技术是<strong class="ih hj"> TF-IDF </strong>。</p><blockquote class="kw kx ky"><p id="d44e" class="if ig kv ih b ii ij ik il im in io ip kz ir is it la iv iw ix lb iz ja jb jc hb bi translated">“在信息检索中，TF–IDF或TFIDF是<em class="hi">词频–逆文档频率</em>的缩写，是一种数字统计，旨在反映一个词对集合或语料库中的文档有多重要。在信息检索、文本挖掘和用户建模的搜索中，它经常被用作加权因子。TF–IDF值与某个单词在文档中出现的次数成比例增加，并被语料库中包含该单词的文档数抵消，这有助于调整某些单词通常出现频率更高的事实。TF–IDF是当今最受欢迎的术语加权方案之一。”—维基百科</p></blockquote><p id="8f8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">代码在我的github账号</strong>  <strong class="ih hj">的一个</strong> <a class="ae jr" href="https://github.com/edumunozsala/Intro-NLP-Text-Classification/blob/master/Intro_NLP_1_TFIDF_Text_Classification.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">笔记本上。</strong></a></p></div><div class="ab cl lo lp gp lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hb hc hd he hf"><h1 id="a6e0" class="js jt hi bd ju jv lv jx jy jz lw kb kc kd lx kf kg kh ly kj kk kl lz kn ko kp bi translated">朴素贝叶斯</h1><p id="aa8b" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">我们将使用文本分类中常用的传统分类器:使用多项式模型的朴素贝叶斯。</p><p id="6aa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kv">“多项式朴素贝叶斯分类器适用于具有离散特征的分类(例如，用于文本分类的字数)。多项式分布通常需要整数特征计数。但是，在实践中，分数计数(如tf-idf)也可能有效。”</em>，摘自Ritchie Ng的《<em class="kv">矢量化、多项式朴素贝叶斯分类器及评估</em>》。</p><p id="b858" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们不会详细描述这个算法是如何工作的，在以后的文章中我们会。此时此刻，我们可以确认它已经在多年的许多NLP任务中产生了巨大的成果。</p><p id="3b0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">只是为了比较，我们将为二元分类构建其他分类器，以检查我们的模型性能是否足够好，作为改进的初始解决方案。</p><h1 id="577b" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">支持向量机</h1><blockquote class="mb"><p id="cecb" class="mc md hi bd me mf mg mh mi mj mk jc dx translated"><em class="ml">“支持向量机算法的目标是在一个N维空间(N——特征的数量)中找到一个超平面，该超平面可以清楚地对数据点进行分类。”，</em></p><p id="b797" class="mc md hi bd me mf mg mh mi mj mk jc dx translated"><em class="ml">——</em>Rohith Gandhi的《机器学习算法的支持向量机介绍》。</p></blockquote><p id="a991" class="pw-post-body-paragraph if ig hi ih b ii mm ik il im mn io ip iq mo is it iu mp iw ix iy mq ja jb jc hb bi translated">我们可以使用SVM算法来预测一条推文是假还是真，这只是一个二元分类问题。</p><h1 id="de57" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">XGBoost分类器</h1><p id="089b" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">XGBoost是梯度增强决策树的一种实现，旨在提高速度和性能，是占主导地位的竞争机器学习。对于第一个XGBoost模型来说，这是一个很好的数据集，因为所有的输入变量都是数值型的，并且问题是一个简单的二元分类问题。</p><p id="186e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">代码在我的github账号</strong>  <strong class="ih hj">的一个</strong> <a class="ae jr" href="https://github.com/edumunozsala/Intro-NLP-Text-Classification/blob/master/Intro_NLP_1_TFIDF_Text_Classification.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">笔记本上。</strong></a></p><h1 id="0982" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">评估和指标</h1><p id="7a7e" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">我们的算法已经表现出类似的性能，正如我们之前所说的，我们并不是在寻找一个优化和调整的分类器，我们的目标是描述我们如何在几个步骤中轻松地对文本进行分类。投入时间和试验参数，我们会取得更好的结果。</p><p id="a93d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们的分类器在测试集上达到了81%的准确率和0.75的F1值。在下图中，我们绘制了ROC和混淆矩阵</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es mr"><img src="../Images/24a0b35aece28b3778254df7ec9234aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*DYYjyUFbKXV7nENUVpv_Qg.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">评估指标</figcaption></figure><p id="611a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们可以观察到，应用一些“旧的”和简单的技术而不进行“微调”,我们可以用几行代码和不超过一个小时的处理时间获得一个分类器。这个分类器可以以相对较高的可信度预测一条推文何时宣布一场虚假或真实的灾难。</p><p id="3395" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">代码在我的github账号</strong>  <strong class="ih hj">中的</strong> <a class="ae jr" href="https://github.com/edumunozsala/Intro-NLP-Text-Classification/blob/master/Intro_NLP_1_TFIDF_Text_Classification.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">笔记本上。</strong></a></p></div></div>    
</body>
</html>