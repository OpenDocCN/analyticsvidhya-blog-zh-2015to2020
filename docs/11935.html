<html>
<head>
<title>Quantization (post-training quantization) your (custom mobilenet_v2) models .h5 or .pb models using TensorFlow Lite 2.4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">量化(训练后量化)您的(自定义 mobilenet_v2)模型. h5 或。使用 TensorFlow Lite 2.4 的 pb 模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/quantization-your-custom-mobilenet-v2-models-h5-models-using-tensorflow-lite-2-4-5e7046fa860e?source=collection_archive---------4-----------------------#2020-12-24">https://medium.com/analytics-vidhya/quantization-your-custom-mobilenet-v2-models-h5-models-using-tensorflow-lite-2-4-5e7046fa860e?source=collection_archive---------4-----------------------#2020-12-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/dc45fd8379a169b99068f7aef1937c0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8z4lTcSfyEad87GGsf9IPw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用 TensorFlow Lite 量化你的模型. h5 或 tflite(图片，作者 GIF)<a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization/blob/main/1_8z4lTcSfyEad87GGsf9IPw.png" rel="noopener ugc nofollow" target="_blank">https://github . com/oleks andr-g-rock/Quantization/blob/main/1 _ 8 Z4 ltcsfyead 87 ggsf 9 ipw . png</a></figcaption></figure><h1 id="8515" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">简短摘要:</h1><p id="08b9" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">在本文中，我将解释什么是量化，目前存在哪些类型的量化，我将展示如何量化您的(自定义 mobilenet_v2)模型。pb 使用 TensorFlow Lite <strong class="jv hj">只针对 CPU 树莓 Pi 4 </strong>。</p><p id="9b41" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">这篇文章的代码可以在<a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><blockquote class="ld le lf"><p id="ab00" class="jt ju lg jv b jw kr jy jz ka ks kc kd lh kt kg kh li ku kk kl lj kv ko kp kq hb bi translated"><em class="hi">开始前请注意:</em></p></blockquote><figure class="lk ll lm ln fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="a0a2" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">所以，我们开始吧:)</h1><h1 id="875d" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">硬件准备:</h1><figure class="lk ll lm ln fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="60d5" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">软件准备:</h1><figure class="lk ll lm ln fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="c9df" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">1)张量流背景下的量子化模型是什么？</h1><p id="5402" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">这是一个和标准模型做的一样的模型，但是:更快，更小，具有相似的精度。比如下面的 gif:)</p><figure class="lk ll lm ln fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/fb5717c3c6ea5aa260cc542431175eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*-bmgkbQNGwVkDJJq64yVxQ.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用 TensorFlow Lite 量化你的模型. h5 或 tflite(图片，作者 GIF)<a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization/blob/main/1_-bmgkbQNGwVkDJJq64yVxQ.gif" rel="noopener ugc nofollow" target="_blank">https://github . com/oleks andr-g-rock/Quantization/blob/main/1 _-bmgkbqngwvkdjjjq 64 yvxq . GIF</a></figcaption></figure><p id="7615" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">或者这个:)</p><figure class="lk ll lm ln fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/dc45fd8379a169b99068f7aef1937c0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8z4lTcSfyEad87GGsf9IPw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用 TensorFlow Lite 量化你的模型. h5 或 tflite(图片，作者 GIF)<a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization/blob/main/1_8z4lTcSfyEad87GGsf9IPw.png" rel="noopener ugc nofollow" target="_blank">https://github . com/oleks andr-g-rock/Quantization/blob/main/1 _ 8 Z4 ltcsfyead 87 ggsf 9 ipw . png</a></figcaption></figure><p id="473e" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">大乌龟就是简单的 CNN (.h5 或者。pb)型号。<br/>小海龟是一个量化模型。<br/>:)</p><p id="b9d6" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj">简单来说</strong>，通常，我们使用具有下一个权重的模型(465.949494 等……)，这些权重通常是浮点数。<br/>在下面的截图中，你可以看到这些用于权重的浮点数— <strong class="jv hj">这只是一个例子。</strong></p><figure class="lk ll lm ln fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/bfbc34c1248053951b3bd0e5ceb2e705.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KvHwa5eUfyVTaNzEm3TJ8A.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用 TensorFlow Lite 量化你的模型. h5 或 tflite(图片，作者 GIF)<a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization/blob/main/1_KvHwa5eUfyVTaNzEm3TJ8A.png" rel="noopener ugc nofollow" target="_blank">https://github . com/oleks andr-g-rock/Quantization/blob/main/1 _ kvhwa 5 eufyvtanzem 3 TJ 8 a . png</a></figcaption></figure><p id="a6aa" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">但是量化之后，这些权重可以改成…</p><figure class="lk ll lm ln fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/1b40e204e18df8ecb8354d055eb0dc68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3bYW4pjMPEAN47aXLrDVvA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用 TensorFlow Lite 量化你的模型. h5 或 tflite(图片，作者 GIF)<a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization/blob/main/1_3bYW4pjMPEAN47aXLrDVvA.png" rel="noopener ugc nofollow" target="_blank">https://github . com/oleks andr-g-rock/Quantization/blob/main/1 _ 3 by 4 jmpean 47 axlrdvva . png</a></figcaption></figure><p id="269a" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">这是一个关于量子化的粗略例子。</p></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><h1 id="b6eb" class="iv iw hi bd ix iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js bi translated">2)那么量化模型和 simple (.h5 或者。pb 或 etc …)？</h1><h2 id="2258" class="lx iw hi bd ix ly lz ma jb mb mc md jf ke me mf jj ki mg mh jn km mi mj jr mk bi translated"><strong class="ak"> 1。正在减小模型尺寸</strong></h2><blockquote class="ld le lf"><p id="e2b1" class="jt ju lg jv b jw kr jy jz ka ks kc kd lh kt kg kh li ku kk kl lj kv ko kp kq hb bi translated"><strong class="jv hj">例如:</strong> <br/>我们有. h5 或 tflite 等…简单的 CNN 模型(用于图像分类)文件，大小为 11.59 MB。</p><p id="2ea1" class="jt ju lg jv b jw kr jy jz ka ks kc kd lh kt kg kh li ku kk kl lj kv ko kp kq hb bi translated"><strong class="jv hj">量化模型后他将得到下一个结果:</strong> <br/>模型将是 3.15 MB。</p></blockquote></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><h2 id="8651" class="lx iw hi bd ix ly lz ma jb mb mc md jf ke me mf jj ki mg mh jn km mi mj jr mk bi translated"><strong class="ak"> 2。识别一幅图像的延迟更少</strong></h2><blockquote class="ld le lf"><p id="1e2c" class="jt ju lg jv b jw kr jy jz ka ks kc kd lh kt kg kh li ku kk kl lj kv ko kp kq hb bi translated"><strong class="jv hj">例如:</strong> <br/>我们有. h5 或 tflite 简单 CNN 模型(用于图像分类)和在 CPU 上识别一幅图像 300 毫秒的延迟。</p><p id="bbc9" class="jt ju lg jv b jw kr jy jz ka ks kc kd lh kt kg kh li ku kk kl lj kv ko kp kq hb bi translated"><strong class="jv hj">量化模型后他将下一个结果:</strong><br/>CPU 上 170ms</p></blockquote></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><h2 id="a7a3" class="lx iw hi bd ix ly lz ma jb mb mc md jf ke me mf jj ki mg mh jn km mi mj jr mk bi translated"><strong class="ak"> 3。生产率损失高达 1%</strong></h2><blockquote class="ld le lf"><p id="f90b" class="jt ju lg jv b jw kr jy jz ka ks kc kd lh kt kg kh li ku kk kl lj kv ko kp kq hb bi translated"><strong class="jv hj">例如:</strong> <br/>我们有. h5 或 tflite 简单的 CNN 模型(用于图像分类),准确率为 99%</p><p id="2b19" class="jt ju lg jv b jw kr jy jz ka ks kc kd lh kt kg kh li ku kk kl lj kv ko kp kq hb bi translated"><strong class="jv hj">量化模型后他将下一个结果:</strong> <br/>准确率将达到 99%</p></blockquote></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><h1 id="dae0" class="iv iw hi bd ix iy ls ja jb jc lt je jf jg lu ji jj jk lv jm jn jo lw jq jr js bi translated">3)存在哪些类型的<strong class="ak">量化？</strong></h1><p id="a654" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">基本上存在两种类型的<a class="ae iu" href="https://www.tensorflow.org/lite/performance/model_optimization?hl=en" rel="noopener ugc nofollow" target="_blank">量化</a> <br/> - <a class="ae iu" href="http://www.tensorflow.org/model_optimization/guide/quantization/training" rel="noopener ugc nofollow" target="_blank">量化感知训练</a>；<br/> -采用 3 种不同方法的训练后量化(<a class="ae iu" href="https://www.tensorflow.org/lite/performance/post_training_quant" rel="noopener ugc nofollow" target="_blank">训练后动态范围量化</a>、<a class="ae iu" href="https://www.tensorflow.org/lite/performance/post_training_integer_quant" rel="noopener ugc nofollow" target="_blank">训练后整数量化</a>、<a class="ae iu" href="https://www.tensorflow.org/lite/performance/post_training_float16_quant" rel="noopener ugc nofollow" target="_blank">训练后浮点量化</a>)。</p><p id="aeb5" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在这篇文章中，我将解释第二种方法。</p><h1 id="d27a" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">4)我该如何做训练后的量化？</h1><p id="7237" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">笔记本上有这些例子<a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization/blob/main/quantization.ipynb" rel="noopener ugc nofollow" target="_blank">这里有</a>。</p><p id="f2a9" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">1 如何将. h5 转换为量化模型 tflite ( 8 位/浮点 8):</p><p id="bd1a" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">1.0 使用<strong class="jv hj">优化。默认</strong></p><pre class="lk ll lm ln fd ml mm mn mo aw mp bi"><span id="e684" class="lx iw hi mm b fi mq mr l ms mt">import tensorflow as tf</span><span id="eaae" class="lx iw hi mm b fi mu mr l ms mt">model = tf.keras.models.load_model("/content/test/mobilenetv2.h5")<br/>converter = tf.lite.TFLiteConverter.from_keras_model(model)<br/>converter.optimizations = [tf.lite.Optimize.DEFAULT]</span><span id="1ed8" class="lx iw hi mm b fi mu mr l ms mt">tflite_quant_model = converter.convert()</span><span id="c235" class="lx iw hi mm b fi mu mr l ms mt">#save converted quantization model to tflite format<br/>open("/content/test/quantization_DEFAULT_8bit_model_h5_to_tflite.tflite", "wb").write(tflite_quant_model)</span></pre><p id="10ab" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">1.1 使用<strong class="jv hj">优化。优化尺寸</strong></p><pre class="lk ll lm ln fd ml mm mn mo aw mp bi"><span id="0797" class="lx iw hi mm b fi mq mr l ms mt">import tensorflow as tf</span><span id="59e6" class="lx iw hi mm b fi mu mr l ms mt">model = tf.keras.models.load_model("/content/test/mobilenetv2.h5")<br/>converter = tf.lite.TFLiteConverter.from_keras_model(model)<br/>converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]</span><span id="dc30" class="lx iw hi mm b fi mu mr l ms mt">tflite_quant_model = converter.convert()</span><span id="797a" class="lx iw hi mm b fi mu mr l ms mt">#save converted quantization model to tflite format<br/>open("/content/test/quantization_OPTIMIZE_FOR_SIZE_8bit_model_h5_to_tflite.tflite", "wb").write(tflite_quant_model)</span></pre><p id="52f1" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">1.2 使用<strong class="jv hj">优化。优化延迟</strong></p><pre class="lk ll lm ln fd ml mm mn mo aw mp bi"><span id="06db" class="lx iw hi mm b fi mq mr l ms mt">import tensorflow as tf</span><span id="fdb2" class="lx iw hi mm b fi mu mr l ms mt">model = tf.keras.models.load_model("/content/test/mobilenetv2.h5")<br/>converter = tf.lite.TFLiteConverter.from_keras_model(model)<br/>converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]</span><span id="fb5b" class="lx iw hi mm b fi mu mr l ms mt">tflite_quant_model = converter.convert()</span><span id="6b46" class="lx iw hi mm b fi mu mr l ms mt">#save converted quantization model to tflite format<br/>open("/content/test/quantization_OPTIMIZE_FOR_LATENCY_8bit_model_h5_to_tflite.tflite", "wb").write(tflite_quant_model)</span></pre><p id="7713" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">2 如何将. h5 转换为量化模型 tflite ( 16 位/浮点 16):</p><p id="5f67" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">2.0 使用<strong class="jv hj">优化。默认</strong></p><pre class="lk ll lm ln fd ml mm mn mo aw mp bi"><span id="319b" class="lx iw hi mm b fi mq mr l ms mt">import tensorflow as tf</span><span id="4c28" class="lx iw hi mm b fi mu mr l ms mt">model = tf.keras.models.load_model("/content/test/mobilenetv2.h5")<br/>converter = tf.lite.TFLiteConverter.from_keras_model(model)<br/>converter.optimizations = [tf.lite.Optimize.DEFAULT]<br/>converter.target_spec.supported_types = [tf.float16]</span><span id="3a5a" class="lx iw hi mm b fi mu mr l ms mt">tflite_quant_model = converter.convert()</span><span id="6872" class="lx iw hi mm b fi mu mr l ms mt">#save converted quantization model to tflite format<br/>open("/content/test/quantization_DEFAULT_float16_model_h5_to_tflite.tflite", "wb").write(tflite_quant_model)</span></pre><p id="8724" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">2.1 使用<strong class="jv hj">优化。尺寸优化</strong></p><pre class="lk ll lm ln fd ml mm mn mo aw mp bi"><span id="6d73" class="lx iw hi mm b fi mq mr l ms mt">import tensorflow as tf</span><span id="1665" class="lx iw hi mm b fi mu mr l ms mt">model = tf.keras.models.load_model("/content/test/mobilenetv2.h5")<br/>converter = tf.lite.TFLiteConverter.from_keras_model(model)<br/>converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]<br/>converter.target_spec.supported_types = [tf.float16]</span><span id="9bb1" class="lx iw hi mm b fi mu mr l ms mt">tflite_quant_model = converter.convert()</span><span id="dab8" class="lx iw hi mm b fi mu mr l ms mt">#save converted quantization model to tflite format<br/>open("/content/test/quantization_OPTIMIZE_FOR_SIZE_float16_model_h5_to_tflite.tflite", "wb").write(tflite_quant_model)</span></pre><p id="b532" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">2.2 使用<strong class="jv hj">优化。优化延迟</strong></p><pre class="lk ll lm ln fd ml mm mn mo aw mp bi"><span id="6c50" class="lx iw hi mm b fi mq mr l ms mt">import tensorflow as tf</span><span id="61cb" class="lx iw hi mm b fi mu mr l ms mt">model = tf.keras.models.load_model("/content/test/mobilenetv2.h5")<br/>converter = tf.lite.TFLiteConverter.from_keras_model(model)<br/>converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]<br/>converter.target_spec.supported_types = [tf.float16]<br/>tflite_quant_model = converter.convert()</span><span id="fc5a" class="lx iw hi mm b fi mu mr l ms mt">#save converted quantization model to tflite format<br/>open("/content/test/quantization_OPTIMIZE_FOR_LATENCY_float16_model_h5_to_tflite.tflite", "wb").write(tflite_quant_model)</span></pre><h1 id="ff4b" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">5)后训练量化模型 mobilenet_V2 后会是什么结果？</h1><p id="3b12" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">我创建了 8 个 python 脚本来测试在 Raspberry Pi 4 上识别 100 张图片的速度。要运行这些测试，您可以运行下面的命令，但只能按顺序运行。</p><pre class="lk ll lm ln fd ml mm mn mo aw mp bi"><span id="973f" class="lx iw hi mm b fi mq mr l ms mt">#clone my repo<br/>git clone <a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization.git" rel="noopener ugc nofollow" target="_blank">https://github.com/oleksandr-g-rock/Quantization.git</a></span><span id="b000" class="lx iw hi mm b fi mu mr l ms mt">#go to directory<br/>cd Quantization</span><span id="c1ad" class="lx iw hi mm b fi mu mr l ms mt">#run tests</span><span id="f3fd" class="lx iw hi mm b fi mu mr l ms mt">python3 test_h5.py</span><span id="6abe" class="lx iw hi mm b fi mu mr l ms mt">python3 test_tflite.py</span><span id="c53a" class="lx iw hi mm b fi mu mr l ms mt">python3 OPTIMIZE_FOR_SIZE_float16.py</span><span id="ace5" class="lx iw hi mm b fi mu mr l ms mt">python3 DEFAULT_float16.py</span><span id="3d9a" class="lx iw hi mm b fi mu mr l ms mt">python3 OPTIMIZE_FOR_LATENCY_float16.py</span><span id="83c0" class="lx iw hi mm b fi mu mr l ms mt">python3 OPTIMIZE_FOR_SIZE_float8.py</span><span id="37fa" class="lx iw hi mm b fi mu mr l ms mt">python3 DEFAULT_float8.py</span><span id="5db2" class="lx iw hi mm b fi mu mr l ms mt">python3 OPTIMIZE_FOR_LATENCY_float8.py</span></pre><p id="f514" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">这 8 个脚本将测试下一个模型:</p><ul class=""><li id="72e4" class="mv mw hi jv b jw kr ka ks ke mx ki my km mz kq na nb nc nd bi translated">Tensorflow .h5</li><li id="0f2b" class="mv mw hi jv b jw ne ka nf ke ng ki nh km ni kq na nb nc nd bi translated">刚转换的 Tensorflow Lite。tflite</li><li id="4476" class="mv mw hi jv b jw ne ka nf ke ng ki nh km ni kq na nb nc nd bi translated">tensor flow Lite OPTIMIZE _ FOR _ SIZE/DEFAULT/OPTIMIZE _ FOR _ LATENCY 浮点 16 量化模型 tflite</li><li id="04be" class="mv mw hi jv b jw ne ka nf ke ng ki nh km ni kq na nb nc nd bi translated">tensor flow Lite OPTIMIZE _ FOR _ SIZE/DEFAULT/OPTIMIZE _ FOR _ LATENCY 浮点 8 量化模型 tflite</li></ul><p id="7863" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">下面是我测试后的结果，这里是:</p><figure class="lk ll lm ln fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nj"><img src="../Images/60e32012f404cdba595194b0a925ba91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6oEnzouLdQzcsDZW3SZnQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用 TensorFlow Lite 量化你的模型. h5 或 tflite(图片，作者 GIF)<a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization/blob/main/1_P6oEnzouLdQzcsDZW3SZnQ.png" rel="noopener ugc nofollow" target="_blank">https://github . com/oleks andr-g-rock/Quantization/blob/main/1 _ p6oenzouldqzcsdw 3 sznq . png</a></figcaption></figure><h1 id="b759" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">结果:</h1><p id="aa70" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated"><strong class="jv hj"> 1 个关于调整模型大小的结果:</strong></p><ul class=""><li id="5034" class="mv mw hi jv b jw kr ka ks ke mx ki my km mz kq na nb nc nd bi translated">将模型从. h5 转换为 tflite 后，模型大小从<strong class="jv hj"> 11.59 </strong> MB 变为<strong class="jv hj"> 10.96 </strong> MB</li><li id="9d4c" class="mv mw hi jv b jw ne ka nf ke ng ki nh km ni kq na nb nc nd bi translated">使用 tensor flow Lite OPTIMIZE _ FOR _ SIZE/DEFAULT/OPTIMIZE _ FOR _ LATENCY float 16 将模型从. h5 量化到 tflite 后，模型大小从<strong class="jv hj"> 10.96 </strong> MB 变为<strong class="jv hj"> 5.8 </strong> MB</li><li id="f47d" class="mv mw hi jv b jw ne ka nf ke ng ki nh km ni kq na nb nc nd bi translated">使用 tensor flow Lite OPTIMIZE _ FOR _ SIZE/DEFAULT/OPTIMIZE _ FOR _ LATENCY float 8 将模型从. h5 量化到 tflite 后，模型大小从<strong class="jv hj"> 5.8 </strong> MB 变为<strong class="jv hj"> 3.3 </strong> MB</li></ul><p id="2280" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj">所以我猜调整大小模型的结果是完美的。</strong></p><p id="3b98" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj"> 2 个关于识别速度的结果，结果没有我想象的那么好，但是速度识别对于 Raspberry Pi 是最优的(因为它 99%)。</strong></p><p id="b62e" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">这篇文章的代码可以在<a class="ae iu" href="https://github.com/oleksandr-g-rock/Quantization" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><figure class="lk ll lm ln fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure></div></div>    
</body>
</html>