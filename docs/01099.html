<html>
<head>
<title>Build an Image Classification Model using Convolutional Neural Networks in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用PyTorch中的卷积神经网络建立图像分类模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/build-an-image-classification-model-using-convolutional-neural-networks-in-pytorch-45c904791c7e?source=collection_archive---------4-----------------------#2019-10-01">https://medium.com/analytics-vidhya/build-an-image-classification-model-using-convolutional-neural-networks-in-pytorch-45c904791c7e?source=collection_archive---------4-----------------------#2019-10-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0cad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我被神经网络的力量和能力迷住了。几乎现在机器学习和深度学习领域发生的每一项突破都以神经网络模型为核心。</p><p id="4855" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这在<a class="ae jd" href="https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning-version2?utm_source=blog&amp;utm_medium=building-image-classification-models-cnn-pytorch" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>领域尤为普遍。神经网络开辟了处理图像数据的可能性——无论是简单的图像分类还是更高级的东西，如物体检测。简而言之，对于像我这样的数据科学家来说，这是一座金矿！</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/98f187a85922ec7a6fc9bf0f216c901c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vv3JrTSlMl-lfLkG"/></div></div></figure><p id="aee6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们使用深度学习解决图像分类问题时，简单的神经网络总是一个很好的起点。但是它们确实有局限性，并且在某一点之后，模型的性能无法提高。</p><p id="1529" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是卷积神经网络(CNN)改变游戏场的地方。它们在计算机视觉应用中无处不在。老实说，我觉得每个计算机视觉爱好者都应该很快学会这个概念。</p><p id="7e6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文是我的新系列的延续，在该系列中，我使用流行的PyTorch框架向您介绍新的深度学习概念。在本文中，我们将了解卷积神经网络如何有用，以及它们如何帮助我们提高模型的性能。我们还将研究CNN在PyTorch中的实现。</p><p id="4955" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jq">这是本系列的第二篇文章，我强烈建议在阅读本文之前先阅读第一部分:</em></p><ul class=""><li id="c4c9" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated"><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2019/09/introduction-to-pytorch-from-scratch/?utm_source=blog&amp;utm_medium=building-image-classification-models-cnn-pytorch" rel="noopener ugc nofollow" target="_blank"><em class="jq">py torch初学者友好指南以及它如何从头开始工作</em> </a></li></ul><h1 id="c26a" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">PyTorch、Tensors和NumPy概述</h1><p id="5686" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">让我们快速回顾一下我们在<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2019/09/introduction-to-pytorch-from-scratch/?utm_source=blog&amp;utm_medium=building-image-classification-models-cnn-pytorch" rel="noopener ugc nofollow" target="_blank">第一篇文章</a>中讲述的内容。我们讨论了PyTorch和张量的基础知识，还讨论了PyTorch与NumPy的相似之处。</p><p id="b268" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PyTorch是一个基于Python的库，它提供了如下功能:</p><ul class=""><li id="93c9" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated">用于创建可序列化和可优化模型的TorchScript</li><li id="7e80" class="jr js hi ih b ii ld im le iq lf iu lg iy lh jc jw jx jy jz bi translated">并行计算的分布式培训</li><li id="d105" class="jr js hi ih b ii ld im le iq lf iu lg iy lh jc jw jx jy jz bi translated">动态计算图，可以随时制作计算图，等等</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es li"><img src="../Images/4befe2d789c8fdc01ef4a7ad215ddead.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/0*Q-wLwiBpPhuxXis3"/></div></figure><p id="f40a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PyTorch中的张量类似于NumPy的n维数组，也可以用于GPU。在这些张量上执行操作几乎类似于在NumPy数组上执行操作。这使得PyTorch非常用户友好且易于学习。</p><p id="4eb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本系列的第1部分中，我们构建了一个简单的神经网络来解决一个案例研究。使用我们的简单模型，我们在测试集上获得了大约65%的基准准确率。现在，我们将尝试使用卷积神经网络来提高这个分数。</p><h1 id="b38c" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">为什么选择卷积神经网络(CNN)？</h1><p id="8f6e" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在我们进入实现部分之前，让我们快速地看看为什么我们首先需要CNN，以及它们是如何有帮助的。</p><blockquote class="lj lk ll"><p id="5758" class="if ig jq ih b ii ij ik il im in io ip lm ir is it ln iv iw ix lo iz ja jb jc hb bi translated"><em class="hi">我们可以将卷积神经网络(CNN)视为帮助从图像中提取特征的特征提取器。</em></p></blockquote><p id="25ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在一个简单的神经网络中，我们将三维图像转换为一维图像，对吗？让我们看一个例子来理解这一点:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lp"><img src="../Images/d5bf03746ed4b3865a8dd53537f9ed11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RqmtDaD6-9q3NW7k"/></div></div></figure><p id="802e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你能认出上面的图像吗？似乎没什么意义。现在，让我们看看下图:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lq"><img src="../Images/195a0f612663e1770c3a3e027d0d5c7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/0*5wrNOHWKpS83fsWJ"/></div></figure><p id="0f31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在可以很容易地说，这是一只狗的形象。如果我告诉你这两幅图像是一样的呢？相信我，他们是！唯一的区别是第一幅图像是一维表示，而第二幅图像是同一幅图像的二维表示。</p><h1 id="5177" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">空间定向</h1><p id="48b3" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">人工神经网络(ann)也会丢失图像的空间方向。让我们再举一个例子来理解它:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/b08fac3e7ffc2e5bdf829313da8f10e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*L_vA9mL_C-57gkcY"/></div></div></figure><p id="147a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你能辨别这两幅图像的不同之处吗？至少我不能。因为这是一维表示，所以很难识别差异。现在，让我们看看这些图像的二维表示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ls"><img src="../Images/da5f357c01e6d7d4c0d80b2589a68d17.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/0*MambMqURFGpUeQ2z"/></div></figure><p id="1835" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">难道你不喜欢通过简单地改变它的表现形式来改变同一个图像的不同外观吗？这里，图像的方向发生了变化，但是我们无法通过查看一维表示来识别它。</p><p id="027b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是人工神经网络的问题——它们失去了空间方向。</p><h1 id="47e9" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">大量参数</h1><p id="dc03" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">神经网络的另一个问题是大量的参数在起作用。假设我们的图像大小为28*28*3，那么这里的参数将是2，352。如果我们有一个224*224*3大小的图像会怎么样？这里的参数数量是150，528。</p><p id="cdb8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">并且这些参数只会随着我们增加隐藏层的数量而增加。所以，使用人工神经网络的两个主要缺点是:</p><ol class=""><li id="ec3f" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc lt jx jy jz bi translated">丢失图像的空间方向</li><li id="5f70" class="jr js hi ih b ii ld im le iq lf iu lg iy lh jc lt jx jy jz bi translated">参数的数量急剧增加</li></ol><p id="0136" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么我们如何处理这个问题呢？我们如何保持空间方向，同时减少可学习的参数？</p><p id="322d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是卷积神经网络真正有用的地方。<strong class="ih hj">细胞神经网络有助于从图像中提取特征，这些特征可能有助于对图像中的物体进行分类。</strong>首先从图像中提取低维特征(如边缘)，然后是一些高维特征，如形状。</p><blockquote class="lj lk ll"><p id="1962" class="if ig jq ih b ii ij ik il im in io ip lm ir is it ln iv iw ix lo iz ja jb jc hb bi translated">我们使用过滤器从图像中提取特征，并使用池技术来减少可学习参数的数量。</p></blockquote><p id="0b0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们不会深入探讨这些主题的细节。如果你希望了解过滤器如何帮助提取特征，以及池是如何工作的，我强烈建议你阅读<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/?utm_source=blog&amp;utm_medium=building-image-classification-models-cnn-pytorch" rel="noopener ugc nofollow" target="_blank">一个全面的教程，从头开始学习卷积神经网络</a>。</p><h1 id="e267" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">理解问题陈述:识别服装</h1><p id="a5ca" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">够了，让我们开始编码吧！我们将继续讨论我们在<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2019/09/introduction-to-pytorch-from-scratch/?utm_source=blog&amp;utm_medium=building-image-classification-models-cnn-pytorch" rel="noopener ugc nofollow" target="_blank">第一篇文章</a>中提到的同一问题陈述。这是因为我们可以直接将CNN模型的性能与我们在那里构建的简单神经网络进行比较。</p><p id="ac27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">你可以从</strong> <a class="ae jd" href="https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-apparels/?utm_source=blog&amp;utm_medium=building-image-classification-models-cnn-pytorch" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">这里</strong> </a> <strong class="ih hj">下载这个“识别”服装问题的数据集。</strong></p><p id="f6af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我快速总结一下问题陈述。我们的任务是通过查看各种服装图像来识别服装的类型。我们可以将服装图像分为10类:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lu"><img src="../Images/1279405f15dbb87fc9e193a36e16b2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*DKSf5JZn_ZjAgkr3gxJOdg.png"/></div></figure><p id="de7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该数据集总共包含70，000幅图像。这些图像中的60，000个属于训练集，剩余的10，000个在测试集中。所有图像都是大小为(28*28)的灰度图像。数据集包含两个文件夹，分别用于训练集和测试集。在每个文件夹中，都有一个包含图像的<em class="jq"> id </em>及其相应标签的. csv文件，以及一个包含该特定组图像的文件夹。</p><p id="b55f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准备开始了吗？我们将从导入所需的库开始:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="7c37" class="ma kb hi lw b fi mb mc l md me"># importing the libraries<br/>import pandas as pd<br/>import numpy as np</span><span id="b6df" class="ma kb hi lw b fi mf mc l md me"># for reading and displaying images<br/>from skimage.io import imread<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="701a" class="ma kb hi lw b fi mf mc l md me"># for creating validation set<br/>from sklearn.model_selection import train_test_split</span><span id="dcb4" class="ma kb hi lw b fi mf mc l md me"># for evaluating the model<br/>from sklearn.metrics import accuracy_score<br/>from tqdm import tqdm</span><span id="4f40" class="ma kb hi lw b fi mf mc l md me"># PyTorch libraries and modules<br/>import torch<br/>from torch.autograd import Variable<br/>from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout<br/>from torch.optim import Adam, SGD</span></pre><h1 id="fb1e" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">加载数据集</h1><p id="59af" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">现在，让我们加载数据集，包括训练、测试和样本提交文件:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="b360" class="ma kb hi lw b fi mb mc l md me"># loading dataset<br/>train = pd.read_csv('train_LbELtWX/train.csv')<br/>test = pd.read_csv('test_ScVgIM0/test.csv')</span><span id="990e" class="ma kb hi lw b fi mf mc l md me">sample_submission = pd.read_csv('sample_submission_I5njJSF.csv')</span><span id="d84b" class="ma kb hi lw b fi mf mc l md me">train.head()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mg"><img src="../Images/d9031ba0d3f842293d39fe7bce2d1d7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:192/0*nFchqggjBqFMUUxE"/></div></figure><ul class=""><li id="779f" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated">训练文件包含每个图像的id及其相应的标签</li><li id="eed0" class="jr js hi ih b ii ld im le iq lf iu lg iy lh jc jw jx jy jz bi translated"><strong class="ih hj">另一方面，测试文件只有id，我们必须预测它们对应的标签</strong></li><li id="d9ed" class="jr js hi ih b ii ld im le iq lf iu lg iy lh jc jw jx jy jz bi translated">样本提交文件将告诉我们提交预测的格式</li></ul><p id="40fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将一个接一个地读取所有的图像，并将它们一个接一个地堆叠在一个数组中。我们还将图像的像素除以255，使图像的像素值在范围[0，1]内。这一步有助于优化我们模型的性能。</p><p id="0d52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，让我们继续加载图像:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="c2af" class="ma kb hi lw b fi mb mc l md me"># loading training images<br/>train_img = []<br/>for img_name in tqdm(train['id']):<br/>    # defining the image path<br/>    image_path = 'train_LbELtWX/train/' + str(img_name) + '.png'<br/>    # reading the image<br/>    img = imread(image_path, as_gray=True)<br/>    # normalizing the pixel values<br/>    img /= 255.0<br/>    # converting the type of pixel to float 32<br/>    img = img.astype('float32')<br/>    # appending the image into the list<br/>    train_img.append(img)</span><span id="c707" class="ma kb hi lw b fi mf mc l md me"># converting the list to numpy array<br/>train_x = np.array(train_img)<br/># defining the target<br/>train_y = train['label'].values<br/>train_x.shape</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mh"><img src="../Images/cb578eb073bdacd4b27cc23e8538f2d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:252/0*curaic774PkBfucd"/></div></figure><p id="bfa5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如您所见，在训练集中，我们有60，000张图片，每张图片的大小为(28，28)。由于图像是灰度格式，我们只有一个单通道，因此形状(28，28)。</p><p id="0b24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们来研究这些数据并可视化一些图像:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="40df" class="ma kb hi lw b fi mb mc l md me"># visualizing images<br/>i = 0<br/>plt.figure(figsize=(10,10))<br/>plt.subplot(221), plt.imshow(train_x[i], cmap='gray')<br/>plt.subplot(222), plt.imshow(train_x[i+25], cmap='gray')<br/>plt.subplot(223), plt.imshow(train_x[i+50], cmap='gray')<br/>plt.subplot(224), plt.imshow(train_x[i+75], cmap='gray')</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mi"><img src="../Images/a14faa694cf8c80989f6b4155afec48d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/0*Ncn46sPw2HQKgFhn"/></div></figure><p id="b5e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是数据集中的几个例子。我鼓励你探索更多，想象其他的图像。接下来，我们将把我们的图像分成训练集和验证集。</p><h1 id="4c22" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">创建验证集并预处理图像</h1><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="94e1" class="ma kb hi lw b fi mb mc l md me"># create validation set<br/>train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.1)<br/>(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)<br/>view raw</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mj"><img src="../Images/9426a00a0d69d8874acedbadb1ac3e54.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/0*6L87t_rJla0_zJ2_"/></div></figure><p id="49b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将10%的数据保存在验证集中，其余的保存在训练集中。接下来，让我们将图像和目标转换为torch格式:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="7ee8" class="ma kb hi lw b fi mb mc l md me"># converting training images into torch format<br/>train_x = train_x.reshape(54000, 1, 28, 28)<br/>train_x  = torch.from_numpy(train_x)</span><span id="b962" class="ma kb hi lw b fi mf mc l md me"># converting the target into torch format<br/>train_y = train_y.astype(int);<br/>train_y = torch.from_numpy(train_y)</span><span id="f095" class="ma kb hi lw b fi mf mc l md me"># shape of training data<br/>train_x.shape, train_y.shape</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mk"><img src="../Images/3ba3f63b6ade2b4a16f8685c2e990c4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/0*9m6uOhSXBWoZUxbb"/></div></figure><p id="f5fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，我们将转换验证图像:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="9511" class="ma kb hi lw b fi mb mc l md me"># converting validation images into torch format<br/>val_x = val_x.reshape(6000, 1, 28, 28)<br/>val_x  = torch.from_numpy(val_x)</span><span id="048c" class="ma kb hi lw b fi mf mc l md me"># converting the target into torch format<br/>val_y = val_y.astype(int);<br/>val_y = torch.from_numpy(val_y)</span><span id="ece4" class="ma kb hi lw b fi mf mc l md me"># shape of validation data<br/>val_x.shape, val_y.shape</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ml"><img src="../Images/23710614a14e509a5134282b8e865c9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/0*H-FZUNH-WfQl85X8"/></div></div></figure><p id="8ed3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的数据现在准备好了。最后，是时候创建我们的CNN模型了！</p><h1 id="14ff" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">使用PyTorch实现CNN</h1><p id="fe0f" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">我们将使用一个非常简单的CNN架构，只有两个卷积层来从图像中提取特征。然后，我们将使用完全连接的密集图层将这些要素分类到各自的类别中。</p><p id="56c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来定义架构:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="4b43" class="ma kb hi lw b fi mb mc l md me">class Net(Module):   <br/>    def __init__(self):<br/>        super(Net, self).__init__()</span><span id="356d" class="ma kb hi lw b fi mf mc l md me">self.cnn_layers = Sequential(<br/>            # Defining a 2D convolution layer<br/>            Conv2d(1, 4, kernel_size=3, stride=1, padding=1),<br/>            BatchNorm2d(4),<br/>            ReLU(inplace=True),<br/>            MaxPool2d(kernel_size=2, stride=2),<br/>            # Defining another 2D convolution layer<br/>            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),<br/>            BatchNorm2d(4),<br/>            ReLU(inplace=True),<br/>            MaxPool2d(kernel_size=2, stride=2),<br/>        )</span><span id="ff83" class="ma kb hi lw b fi mf mc l md me">self.linear_layers = Sequential(<br/>            Linear(4 * 7 * 7, 10)<br/>        )</span><span id="4691" class="ma kb hi lw b fi mf mc l md me"># Defining the forward pass    <br/>    def forward(self, x):<br/>        x = self.cnn_layers(x)<br/>        x = x.view(x.size(0), -1)<br/>        x = self.linear_layers(x)<br/>        return x</span></pre><p id="ba95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们调用这个模型，并为模型定义优化器和损失函数:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="01e1" class="ma kb hi lw b fi mb mc l md me"># defining the model<br/>model = Net()<br/># defining the optimizer<br/>optimizer = Adam(model.parameters(), lr=0.07)<br/># defining the loss function<br/>criterion = CrossEntropyLoss()<br/># checking if GPU is available<br/>if torch.cuda.is_available():<br/>    model = model.cuda()<br/>    criterion = criterion.cuda()<br/>    <br/>print(model)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mm"><img src="../Images/469b4fce2cb6617e0ec53a35008e4336.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8mJgvdFT9pR__d-6"/></div></div></figure><p id="e7a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是模型的架构。我们有两个Conv2d层和一个线性层。接下来，我们将定义一个函数来训练模型:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="ef5a" class="ma kb hi lw b fi mb mc l md me">def train(epoch):<br/>    model.train()<br/>    tr_loss = 0<br/>    # getting the training set<br/>    x_train, y_train = Variable(train_x), Variable(train_y)<br/>    # getting the validation set<br/>    x_val, y_val = Variable(val_x), Variable(val_y)<br/>    # converting the data into GPU format<br/>    if torch.cuda.is_available():<br/>        x_train = x_train.cuda()<br/>        y_train = y_train.cuda()<br/>        x_val = x_val.cuda()<br/>        y_val = y_val.cuda()</span><span id="a452" class="ma kb hi lw b fi mf mc l md me"># clearing the Gradients of the model parameters<br/>    optimizer.zero_grad()<br/>    <br/>    # prediction for training and validation set<br/>    output_train = model(x_train)<br/>    output_val = model(x_val)</span><span id="d8e3" class="ma kb hi lw b fi mf mc l md me"># computing the training and validation loss<br/>    loss_train = criterion(output_train, y_train)<br/>    loss_val = criterion(output_val, y_val)<br/>    train_losses.append(loss_train)<br/>    val_losses.append(loss_val)</span><span id="ff63" class="ma kb hi lw b fi mf mc l md me"># computing the updated weights of all the model parameters<br/>    loss_train.backward()<br/>    optimizer.step()<br/>    tr_loss = loss_train.item()<br/>    if epoch%2 == 0:<br/>        # printing the validation loss<br/>        print('Epoch : ',epoch+1, '\t', 'loss :', loss_val)</span></pre><p id="37be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将训练25个时期的模型，并存储训练和验证损失:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="c797" class="ma kb hi lw b fi mb mc l md me"># defining the number of epochs<br/>n_epochs = 25<br/># empty list to store training losses<br/>train_losses = []<br/># empty list to store validation losses<br/>val_losses = []<br/># training the model<br/>for epoch in range(n_epochs):<br/>    train(epoch)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mj"><img src="../Images/a6971fc8b2241e20a614fc6f8f8038cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/0*f7-VEE-T_OaHwLkn"/></div></figure><p id="cc97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，随着时代的增加，验证损失在减少。让我们将培训和验证损失绘制成图，以示形象化:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="3f8b" class="ma kb hi lw b fi mb mc l md me"># plotting the training and validation loss<br/>plt.plot(train_losses, label='Training loss')<br/>plt.plot(val_losses, label='Validation loss')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mn"><img src="../Images/df157c4fa99e13c83967ec1a3802484f.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/0*31Eyh0qlW4prNJf0"/></div></figure><p id="12de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">啊，我喜欢视觉化的力量。我们可以清楚地看到，训练和验证损失是同步的。这是一个好迹象，因为模型在验证集上概括得很好。</p><p id="00dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们在训练和验证集上检查模型的准确性:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="c903" class="ma kb hi lw b fi mb mc l md me"># prediction for training set<br/>with torch.no_grad():<br/>    output = model(train_x.cuda())<br/>    <br/>softmax = torch.exp(output).cpu()<br/>prob = list(softmax.numpy())<br/>predictions = np.argmax(prob, axis=1)</span><span id="f582" class="ma kb hi lw b fi mf mc l md me"># accuracy on training set<br/>accuracy_score(train_y, predictions)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mo"><img src="../Images/c6a83615c7185d9dba2f416b1097d63a.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/0*odVb-R4u80EZeLNj"/></div></div></figure><p id="8a91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练集上大约72%的准确度是非常好的。让我们也检查一下验证集的准确性:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="a0ef" class="ma kb hi lw b fi mb mc l md me"># prediction for validation set<br/>with torch.no_grad():<br/>    output = model(val_x.cuda())</span><span id="6b30" class="ma kb hi lw b fi mf mc l md me">softmax = torch.exp(output).cpu()<br/>prob = list(softmax.numpy())<br/>predictions = np.argmax(prob, axis=1)</span><span id="e5f8" class="ma kb hi lw b fi mf mc l md me"># accuracy on validation set<br/>accuracy_score(val_y, predictions)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mp"><img src="../Images/aa83dd85b4b2da9cb128adfa5d336925.png" data-original-src="https://miro.medium.com/v2/resize:fit:116/0*hCJcUdL4ADUkM3rT"/></div></figure><p id="6fa9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们在损失中看到的，这里的准确性也是同步的——我们在验证集上也得到了大约72%。</p><h1 id="e3b0" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">为测试集生成预测</h1><p id="ec09" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">终于到了为测试集生成预测的时候了。我们将加载测试集中的所有图像，执行与训练集相同的预处理步骤，并最终生成预测。</p><p id="3479" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，让我们从加载测试图像开始:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="8c1e" class="ma kb hi lw b fi mb mc l md me"># loading test images<br/>test_img = []<br/>for img_name in tqdm(test['id']):<br/>    # defining the image path<br/>    image_path = 'test_ScVgIM0/test/' + str(img_name) + '.png'<br/>    # reading the image<br/>    img = imread(image_path, as_gray=True)<br/>    # normalizing the pixel values<br/>    img /= 255.0<br/>    # converting the type of pixel to float 32<br/>    img = img.astype('float32')<br/>    # appending the image into the list<br/>    test_img.append(img)</span><span id="e90c" class="ma kb hi lw b fi mf mc l md me"># converting the list to numpy array<br/>test_x = np.array(test_img)<br/>test_x.shape</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mq"><img src="../Images/a90a1bb804b2726ffce061043776ff7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/0*fqGH3mh0oxpDF6o4"/></div></figure><p id="f8e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将对这些图像执行预处理步骤，类似于之前对训练图像执行的步骤:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="7181" class="ma kb hi lw b fi mb mc l md me"># converting training images into torch format<br/>test_x = test_x.reshape(10000, 1, 28, 28)<br/>test_x  = torch.from_numpy(test_x)<br/>test_x.shape</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mr"><img src="../Images/524daee8b4b85b4dcb0197499cfb5b08.png" data-original-src="https://miro.medium.com/v2/resize:fit:498/0*SJd8yjzjh7am-3Cl"/></div></figure><p id="0396" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将为测试集生成预测:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="af1c" class="ma kb hi lw b fi mb mc l md me"># generating predictions for test set<br/>with torch.no_grad():<br/>    output = model(test_x.cuda())</span><span id="7d40" class="ma kb hi lw b fi mf mc l md me">softmax = torch.exp(output).cpu()<br/>prob = list(softmax.numpy())<br/>predictions = np.argmax(prob, axis=1)</span></pre><p id="3ae0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将样本提交文件中的标签替换为预测，最后保存文件并提交到排行榜:</p><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="79ec" class="ma kb hi lw b fi mb mc l md me"># replacing the label with prediction<br/>sample_submission['label'] = predictions<br/>sample_submission.head()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ms"><img src="../Images/de2b97ac3d0c921f3f1ee40ad0d4aef0.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/0*uDLnhKJeTonfeBS6"/></div></figure><pre class="jf jg jh ji fd lv lw lx ly aw lz bi"><span id="c269" class="ma kb hi lw b fi mb mc l md me"># saving the file<br/>sample_submission.to_csv('submission.csv', index=False)</span></pre><p id="52a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您将在当前目录中看到一个名为<em class="jq"> submission.csv </em>的文件。你只需要把它上传到问题页面的<a class="ae jd" href="https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-apparels/?utm_source=blog&amp;utm_medium=building-image-classification-models-cnn-pytorch" rel="noopener ugc nofollow" target="_blank">解决方案检查器上，它就会产生分数。</a></p><p id="be84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的CNN模型在测试集上给出了大约71%的准确率。与我们在上一篇文章中使用简单的神经网络获得的65%相比，这是一个相当大的进步。</p><h1 id="f2a1" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">结束注释</h1><p id="b821" class="pw-post-body-paragraph if ig hi ih b ii ky ik il im kz io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在本文中，我们研究了CNN如何用于从图像中提取特征。他们帮助我们将之前的神经网络模型的准确性从65%提高到71%，这是一个重大的提升。</p><p id="45a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以使用CNN模型的超参数，并尝试进一步提高精确度。要调整的一些超参数可以是卷积层数、每个卷积层中的滤波器数、时期数、密集层数、每个密集层中的隐藏单元数等。</p><p id="804a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本系列的下一篇文章中，我们将学习如何使用像VGG-16这样的预训练模型和PyTorch中的模型检查点步骤。和往常一样，如果你对这篇文章有任何疑问，欢迎在下面的评论区发表！</p></div><div class="ab cl mt mu gp mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="hb hc hd he hf"><p id="bb8e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jq">原载于2019年10月1日</em><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/" rel="noopener ugc nofollow" target="_blank"><em class="jq">【https://www.analyticsvidhya.com】</em></a><em class="jq">。</em></p></div></div>    
</body>
</html>