<html>
<head>
<title>Chapter 5: Machine learning basics(part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">第5章:机器学习基础(第1部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/chapter-5-machine-learning-basics-26c64412b42e?source=collection_archive---------18-----------------------#2019-12-28">https://medium.com/analytics-vidhya/chapter-5-machine-learning-basics-26c64412b42e?source=collection_archive---------18-----------------------#2019-12-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f2f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个故事是我从伊恩·古德菲勒、约舒阿·本吉奥和亚伦·库维尔的《深度学习》一书中总结出来的直觉</p><p id="d733" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你没有读过我之前的故事，请去查看一下<a class="ae jd" rel="noopener" href="/analytics-vidhya/deep-learning-book-in-plain-english-ch1-2f73e9b71acb">https://medium . com/analytics-vid hya/deep-learning-book-in-plain-English-ch1-2 f 73 e 9 b 71 ACB</a></p><p id="4e18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本章从解释线性回归开始，简单哈？我知道，但这本书确实超出了我们在许多教程中看到的简单线性方程，所以让我们从线性回归方程开始:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/efe36dd665c39b20dbf9c7cff6bf7d6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*AY4MI1jT5wfoogNOi9EQ-A.png"/></div></figure><p id="e453" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中，y-hat是我们需要预测的目标值，beta-one是斜率，也就是权重，X是我们从数据集获得的特征。权重得到调整，直到它给我们一个好的结果。那么我们如何衡量这个简单模型的好呢？你听说过交叉熵吗？震惊？是的，我也是。<strong class="ih hj">交叉熵</strong>就是模型和实际数据集之间的数据分布差异。默认情况下，模型的分布是高斯分布，所以想象一下，如果您有一个高斯分布，如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jm"><img src="../Images/b8fe0864435f57a45f966f797b49bf50.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*9g6ntnEXjM6W0itD2-fX2A.png"/></div></figure><p id="861e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">像这样的散点图，</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jn"><img src="../Images/c4701475988b9b7e97b05a78a184d557.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*Dnkx1-RqWufoaEbUcQVZtw.png"/></div></figure><p id="62fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型在训练期间所做的是，它试图尽可能地匹配这两张照片，而不模仿数据的确切分布，因此我们不会面临过度拟合。因此，这里的度量或交叉熵只是预测点和实际点之间的L2距离的均方根误差。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jo"><img src="../Images/364c9bfc5eec2a1b0a7e0f5c890f4803.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*U--UewTv_SjK8hviDAPLDA.png"/></div></figure><p id="01c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">顺便说一下，我们可以通过控制模型<strong class="ih hj">的容量来确定模型是否会过拟合或欠拟合。</strong></p><p id="8024" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">事实上，模型的能力就是模型拟合一个函数的能力。例如，我们可以增加这个线性回归模型的容量，以包括多项式，这增加了它的假设空间，从而增加了它的复杂性，如果给定的数据集很小，它可能会过度拟合</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jp"><img src="../Images/b5be53513df9aea6d01d0ed6660a5fa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*gZWhgbJz8oom_G9ToHjzPg.png"/></div></figure><p id="5ce3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图显示了给定数据集的最佳模型容量。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jq"><img src="../Images/3fdb7dda7a3f110e5f3b6a07bfa8d5cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*Bb2sIFvain_GciEZQYnzNw.png"/></div></figure><p id="c754" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，实际上什么度量模型度量模型容量呢？这里Vapnik-Chervonenkis维度或VC维度登场。分类器的VC维由Vapnik和Chervonenkis定义为分类算法可以粉碎的最大点集的基数(大小)。如果你感兴趣，这里有一篇更深入的文章</p><div class="jr js ez fb jt ju"><a href="https://towardsdatascience.com/measuring-the-power-of-a-classifier-c765a7446c1c" rel="noopener follow" target="_blank"><div class="jv ab dw"><div class="jw ab jx cl cj jy"><h2 class="bd hj fi z dy jz ea eb ka ed ef hh bi translated">用VC维度量分类器的能力</h2><div class="kb l"><h3 class="bd b fi z dy jz ea eb ka ed ef dx translated">用VC维度量算法的表达能力</h3></div><div class="kc l"><p class="bd b fp z dy jz ea eb ka ed ef dx translated">towardsdatascience.com</p></div></div><div class="kd l"><div class="ke l kf kg kh kd ki jk ju"/></div></div></a></div><p id="4546" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参数与非参数模型？</p><p id="582d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归、逻辑回归和支持向量机，其中模型的形式是预定义的— <strong class="ih hj">非参数学习器</strong>不具有先验指定的<em class="kj">模型结构。</em>在训练模型之前，我们不会推测我们试图学习的函数<em class="kj"> f </em>的形式，就像我们之前对线性回归所做的那样。相反，模型结构<em class="kj">完全由数据</em>决定。</p><p id="abb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">换句话说，线性回归中的参数即权重(β-one)被设置并独立于输入数据集，而例如在kNN中，它的机制是预测X-test的y，使得y等于与训练数据集中最近的Xtrain到Xtest相关联的y。这是数学公式，</p><p id="5804" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Y =Yi使得i = min(Xtrain，Xtest)所以这里它依赖于数据集，没有设置参数。</p><h1 id="05f9" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">偏置</strong></h1><p id="1958" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lk is it iu ll iw ix iy lm ja jb jc hb bi translated">偏差是我们估计出来的权重，偏差方程是</p><p id="200a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">偏差(θ)= E(θ)-θ。</p><p id="c6e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以某个参数θ的偏差是<strong class="ih hj">θ的<strong class="ih hj">估计减去实际θ</strong></strong></p><p id="c6b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以如果偏差为零，我们说这个参数是无偏的。我举个例子，把书上的事情说清楚。</p><p id="81aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑一组样本</p><p id="3167" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">{x(1)，。。。，x(m ),它们根据具有平均值θ的伯努利分布独立且相同地分布。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/4601048de50b40202c7314c9d9f6c597.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KoxQGqEyN6uGjKHOJ5xTuA.png"/></div></div></figure><h1 id="f0b0" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">差异</strong></h1><p id="571e" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lk is it iu ll iw ix iy lm ja jb jc hb bi translated">简单地说，就是数据集中的变化改变了我们的估计量(权重)多少，从而影响了我们的模型性能。当然，我们需要一个低偏差和低方差的估计量。</p><p id="1168" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，模型的均方差是给定估计量(权重)的偏差和方差之和，MSE =(E(θ)-θ)=偏差(θ)+var(θ)</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jq"><img src="../Images/3fdb7dda7a3f110e5f3b6a07bfa8d5cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*Bb2sIFvain_GciEZQYnzNw.png"/></div></figure><p id="37c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，偏差伴随着欠拟合，因为我们的参数是错误的，所以我们错过了数据中的重要信息，而方差伴随着过拟合，如果它增加，这意味着估计器捕捉到了数据中的每个信息，并且在泛化方面相对失败。</p><p id="bb5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一章将在另一个故事中完成，在那里我将谈论频率主义者和贝叶斯理论之间的差异，从内部监督和非监督算法！</p><p id="eaa0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢</p></div></div>    
</body>
</html>