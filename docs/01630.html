<html>
<head>
<title>peanuts.today | Cleaning and Pre-processing comic strip data set (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">peanuts.today |清理和预处理连环漫画数据集(第2部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/peanuts-today-cleaning-and-pre-processing-comic-strip-data-set-part-2-3b1215e9ecbf?source=collection_archive---------18-----------------------#2019-11-04">https://medium.com/analytics-vidhya/peanuts-today-cleaning-and-pre-processing-comic-strip-data-set-part-2-3b1215e9ecbf?source=collection_archive---------18-----------------------#2019-11-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9c7fbcbe632fb97608e9c523649bbcfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WzgbofWgoNO0oMJcOffLAQ.png"/></div></div></figure><p id="5439" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是我关于探索/使用花生漫画全集系列的第二篇文章。对于介绍帖，<a class="ae jo" rel="noopener" href="/@craig.burdulis/peanuts-today-exploring-the-peanuts-in-the-cloud-with-machine-learning-part-1-ea89f0899f23">点击这里</a>。</p><p id="c2f7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所有用来操作漫画图像的代码都可以在<a class="ae jo" href="https://github.com/icj217/peanuts-comic-preprocessing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="f715" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注意</strong>:我没有公布原始数据集，因为这是一个个人研究项目，我希望尊重可能适用于这些图像的任何版权/合理使用规则和条例。我制作了一些来自数据集的图片，1)在博客中展示我所面临的一些挑战，2)在<a class="ae jo" href="http://peanuts.today" rel="noopener ugc nofollow" target="_blank"> peanuts.today </a>上，这些图片只能以可控的方式访问，以防止图片抓取。</p><p id="6d9c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">说完了，让我们开始吧！</p><h1 id="36d9" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">原始数据</h1><p id="6f59" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">鉴于我的目标是1)提取图像本身的任何可用元数据，2)以适当的方式格式化图像以便在web上显示，处理图像带来了一些挑战。</p><p id="8862" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了给出图像可变性的一些背景，这里是来自数据集的3个不同的图像，它们说明了必须处理的差异。</p><p id="b877" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">图1 </strong>是一个周日带的例子。不同于典型的4个水平的连环画，周日连环画是“整版”的，多排连环画组成一幅漫画。我的处理脚本将需要能够识别和维护整个图像作为一个单一的漫画。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ks"><img src="../Images/92e5f540726161c2022fe6093b8430d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WPqmD7iCAi2HqTnr5fPyqA.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">图像1 </strong></figcaption></figure><p id="3c74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">图2 </strong>是我所说的工作日条带的一个例子，这意味着它们是典型的4面板行。我的处理脚本将需要认识到在这个图像中有3个单独的漫画/漫画，并适当地提取出来。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ks"><img src="../Images/8f206a01f531ca7d003882cfbffd691a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q3DJRFRjwyF01kgTXb67EA.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">图像2 </strong></figcaption></figure><p id="bbbb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">图3 </strong>也包含工作日条纹，但在图像底部也有一个粗黑的横幅。在尝试处理图像之前，我的处理脚本需要忽略/删除该条带。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ks"><img src="../Images/e53b332b4872e8fcbe3f44f395a46c6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*62sj7Dmz5ecCFGdBRW6veA.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated"><strong class="bd jr">图片3 </strong></figcaption></figure><p id="cf1f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据集中的所有图像还包括左下角/右下角的元数据。这包括页码(不太重要)以及出版的月份和年份(非常重要)</p><h1 id="4d60" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">挑战</h1><p id="982f" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">粗略看一下上面的数据，一些挑战变得很明显:</p><ul class=""><li id="edae" class="lb lc hi is b it iu ix iy jb ld jf le jj lf jn lg lh li lj bi translated">区分周日和周日的漫画</li><li id="3d0a" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">开发一种识别图像中单个条带的方法</li><li id="c5f5" class="lb lc hi is b it lk ix ll jb lm jf ln jj lo jn lg lh li lj bi translated">从图像中提取元数据(例如页码、月份/年份)</li></ul><h1 id="b2b1" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">解决方法</h1><p id="3f4c" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">谢天谢地，我能够找到相对简单的方法来解决上面列出的所有问题。</p><h2 id="4ab3" class="lp jq hi bd jr lq lr ls jv lt lu lv jz jb lw lx kd jf ly lz kh jj ma mb kl mc bi translated">漫画识别与提取</h2><p id="c7cd" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">周日和周日漫画的主要区别是面板行之间的空白量。通过比较图1和图2(见上图),你可以看到，周日漫画中的空白比平日漫画中的要少得多。</p><p id="322c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，我开发了一个<a class="ae jo" href="https://github.com/icj217/peanuts-comic-preprocessing/blob/851b3194905f2bc9883accf845facb138c886d09/src/utils/split.py#L23" rel="noopener ugc nofollow" target="_blank">函数</a> (`split_and_save_strips `)，它获取一个图像和一些调优参数，计算图像中找到的条带数，并为找到的每个条带创建一个新图像。</p><figure class="kt ku kv kw fd ij"><div class="bz dy l di"><div class="md me l"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">从图像中提取条带的功能</figcaption></figure><p id="bc21" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面的流程图说明了该功能的工作原理:</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/10eff2de4967dbe5290aa415e90da513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UyRygBX4Bgm2gvUBtwRo4w.png"/></div></div></figure><p id="14d1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了更好地形象化，这是原始图像被函数“标记”后的样子:</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ks"><img src="../Images/8a98599253b98b95d8934ecebb898d3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wPG9MF8Ob8md-8izq5B5FQ.jpeg"/></div></div></figure><h2 id="71de" class="lp jq hi bd jr lq lr ls jv lt lu lv jz jb lw lx kd jf ly lz kh jj ma mb kl mc bi translated">元数据提取</h2><p id="049a" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">从源图像中提取元数据被证明是相当简单的。由于文本是一致打印的，我认为某种OCR工具能够成功地解析文本，经过一些验证后，我可以将其加载到数据库表/CSV中。</p><p id="98d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我发现使用开源的<a class="ae jo" href="https://github.com/tesseract-ocr/tesseract" rel="noopener ugc nofollow" target="_blank"> Tesseract </a>项目正好满足了我的需求，而不是为任何基于云的OCR服务(例如AWS Textract/Rekognition或GCP的Vision API)付费。对图像进行一些清理是必要的，即确保我传递给Tesseract的图像中只有一部分是有内容的。包含任何无关的数据(例如，部分连环漫画或水印)会使Tesseract困惑，并阻止它返回有效文本。处理元数据解析/验证的功能可以在找到<a class="ae jo" href="https://github.com/icj217/peanuts-comic-preprocessing/blob/851b3194905f2bc9883accf845facb138c886d09/src/utils/metadata.py#L35" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="2f3f" class="lp jq hi bd jr lq lr ls jv lt lu lv jz jb lw lx kd jf ly lz kh jj ma mb kl mc bi translated">古怪的旁白</h2><p id="f5ac" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">除了上面讨论的与图像修改/提取相关的用例特定的解决方案之外，我还必须弄清楚如何针对数千个文件高效地运行这些脚本。<strong class="is hj">虽然我的内部AWS架构师希望将这些脚本捆绑到一些Lambda函数中，并使用S3事件通知触发器和可能的步进函数状态机来构建图像处理管道，但我发现在我的笔记本电脑上本地运行脚本更容易</strong>，因为1)这是一个一次性的清理过程，2)图像的不一致性可能会导致1–2%的错误率，这需要手动干预，如果文件/脚本不在本地运行，处理起来会更加困难。</p><p id="61fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最终，我能够使用Python的<code class="du mg mh mi mj b">threading</code>、<code class="du mg mh mi mj b">queue</code>和<code class="du mg mh mi mj b">concurrent.futures</code>模块开发一个高效的本地管道，您可以在<code class="du mg mh mi mj b">crop_images.py</code>脚本中查看这些模块。利用这一点，我能够利用多线程，并大大减少裁剪/分割图像的时间。没有一个剧本需要超过一两个小时才能完成。</p><h1 id="3aa5" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">总结&amp;下一步</strong></h1><p id="3721" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">在运行各种脚本从图像中裁剪、分割和提取元数据的最后，我现在有了一个干净的数据集，图像文件和漫画之间有一对一的关联。</p><p id="6434" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用这些数据的下一步是将它上传到某个存储库中，我可以用它来访问和搜索数据。这将在下一篇文章中讨论。感谢阅读！</p></div></div>    
</body>
</html>