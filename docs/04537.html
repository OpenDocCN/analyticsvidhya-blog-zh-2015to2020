<html>
<head>
<title>Eddie: Understanding User Queries &amp; Providing Natural Responses— Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Eddie:理解用户查询并提供自然的响应——第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/eddie-understanding-user-queries-providing-natural-responses-part-3-f2542ec3785d?source=collection_archive---------13-----------------------#2020-03-23">https://medium.com/analytics-vidhya/eddie-understanding-user-queries-providing-natural-responses-part-3-f2542ec3785d?source=collection_archive---------13-----------------------#2020-03-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d391" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本系列的第1部分中，我介绍了埃迪，并解释了埃迪如何回答一系列相互关联的问题。这篇文章解释了埃迪失败的情况。我们讨论了机器人在理解真实用户查询和以类似人类的方式回复时所面临的挑战。</p><h1 id="1f14" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">理解用户查询</h1><p id="376d" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">当用户与Google/Bing这样的搜索引擎交互时，他们通常会在多次查询中找到自己想要的答案。用户提出一个问题，然后通读一堆网页结果标题。如果他们对结果不满意，他们要么重新制定查询，要么向搜索引擎提供额外的上下文。这使得搜索引擎更容易带回相关的结果。由于语音助手没有显示多个结果的可视化界面，因此对他们来说，在第一次尝试中提供最佳答案本身就变得具有挑战性。此外，语音界面缺乏像自动完成和拼写纠正这样的机制，这些机制通常会引导用户在文本界面中进行搜索。为了克服这些问题，我们分析了不同类型的用户查询，并提出了一个可以处理每一种查询的系统。</p><h2 id="d2f8" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">寻找相同信息的不同方法</h2><p id="ce72" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">人类可以用多种方式问同一个问题。在每种情况下，用户查询在语法上是不同的，但是在语义上是相同的。我们发现，虽然Eddie中的文档阅读器模块理解查询的语义，但检索器模块却不能理解。由于检索器遵循简单的短语匹配或单词包模型，它不断返回不相关的结果，直到用户使用检索器的索引文档中存在的相同短语。</p><p id="5687" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们建议在向检索器发送查询之前添加一个<strong class="ih hj">查询重构引擎</strong>。该引擎将生成同一查询的多个公式。然后，Eddie可以返回多个答案，并从中选择最佳答案进行阅读。我们从论文<a class="ae jd" href="https://openreview.net/pdf?id=S1CChZ-CZ" rel="noopener ugc nofollow" target="_blank">主动问答</a>中得到灵感来实现这样一个引擎。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/3f040c7c8ba5883925df438990d2b529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ULuArBvXGGnmyKs3lSuxA.jpeg"/></div></div></figure><h2 id="cd1d" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">不明确的用户查询</h2><p id="729c" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">用户的查询通常简短、模糊且缺乏上下文。举个例子，</p><p id="4866" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">用户的查询</strong> — <em class="lh">“什么是增值税？”<br/> </em> <strong class="ih hj">埃迪的回复</strong>——“<em class="lh">梵蒂冈使徒图书馆()，俗称<br/>梵蒂冈图书馆或简称the Vat，是教廷的图书馆，<br/>位于梵蒂冈城内。</em></p><p id="aa7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用户的意思是询问印度的“增值税”。然而，埃迪把它和梵蒂冈使徒图书馆的增值税混淆了。因此，在印度的两个人之间的对话中非常明显的事情，对于一个与你的国籍无关的机器人来说，可能并不明显。理想情况下，Eddie应该向用户询问更多的上下文信息</p><p id="6aab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">“你指的是增值税库还是印度的税？”</em></p><h2 id="1107" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">多方面用户查询</h2><p id="bb35" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">用户有复杂的信息需求。他们无法在一个查询中明确表达他们的需求。像Eddie这样的系统即使在问题不完整或不清楚的情况下也会返回结果。在现实生活中，这样的系统应该向用户提出澄清性的问题，以便更好地理解他们的需求。例如，<br/>这是论文<a class="ae jd" href="https://arxiv.org/abs/1907.06554" rel="noopener ugc nofollow" target="_blank">中的一个例子，在开放领域信息搜寻对话中提出澄清性问题</a>。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es li"><img src="../Images/63da6b7305fb15b95e8033344b99ba2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ig5GsN36QNouxJmCD9LzNw.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">图片来源:<a class="ae jd" href="https://arxiv.org/abs/1907.06554" rel="noopener ugc nofollow" target="_blank">在公开领域的信息搜索对话中提出澄清性问题</a></figcaption></figure><p id="0d32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了处理模糊和多方面的查询，我们建议在任何信息搜索聊天机器人系统中增加一个<strong class="ih hj">澄清模块</strong>。澄清系统可以基于当前对话历史、主题和查询生成澄清问题。它还可以查阅关于该主题的现有问题的索引，并选择要问的最佳问题。澄清系统主要有两个部分——问题生成模块和问题选择模块。更多细节可以在这里找到<a class="ae jd" href="https://arxiv.org/abs/1907.06554" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="10dc" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">话题转移和话题回归问题</h2><p id="10a8" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">在与Eddie开始对话之前，用户通知Eddie对话的主题。在得到一个问题的答案时，Eddie使用该主题和历史中的所有问题(或最后n个问题)作为上下文。然而，在对话中，用户经常在不同的副主题之间切换，从而使部分对话与当前问题无关。换句话说，为了回答当前的问题，不能对所有的历史进行同等的加权。用户从一个子主题转移，过一段时间后又回到这个子主题。这个问题在<a class="ae jd" href="https://arxiv.org/pdf/1908.09456.pdf" rel="noopener ugc nofollow" target="_blank">对话式问答的注意历史选择</a>一文中有详细解释</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ln"><img src="../Images/079bdb5e456137367c2356fb2af3d905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sTERNqG_P8gkkURaqgLN5g.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">图片致谢:<a class="ae jd" href="https://arxiv.org/pdf/1908.09456.pdf" rel="noopener ugc nofollow" target="_blank">对话式问答的关注历史选择</a></figcaption></figure><p id="7eb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇论文之后，我们提出在文档阅读器神经模型中使用一种<strong class="ih hj">历史关注机制来对</strong>模型历史进行关注。过去的问题/答案可以基于它们与当前查询的相关性来加权，并且我们可以使用位置历史答案嵌入(PosHAE)来建模上下文。</p><h1 id="3ec0" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">提供自然反应</h1><p id="8ee2" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">在最近的过去，有一个强大的焦点，使机器人像人一样回答。<a class="ae jd" href="https://microsoft.github.io/msmarco/" rel="noopener ugc nofollow" target="_blank">的马尔科女士</a>运行了一个自然语言生成挑战，以一种智能扬声器可以读取的格式来设计问答任务答案，并且在没有任何额外上下文的情况下使其有意义。</p><p id="00fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了让Eddie能够对话，我们在管道中添加了一个<strong class="ih hj">自然语言生成组件</strong>。该组件使用Seq2Seq模型(P <a class="ae jd" href="https://arxiv.org/abs/1704.04368" rel="noopener ugc nofollow" target="_blank">指针生成器网络</a>)将读者基于跨度的答案转换成自由形式的答案。该模型将问题和答案跨度作为输入，并返回自由形式的答案作为输出。举个例子，</p><p id="14c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">问题</strong> : <em class="lh">他们拿到瓶子了吗？</em> <br/> <strong class="ih hj">回答跨度</strong> : <em class="lh">于是他们抓住了瓶子<br/> </em> <strong class="ih hj">自然回答:</strong>是的</p><p id="b580" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从例子中可以看出，对一个“是/否”问题回答“是/否”比阅读答案范围更具对话性。我们在<a class="ae jd" href="https://www.aclweb.org/anthology/Q19-1016/" rel="noopener ugc nofollow" target="_blank"> CoQA </a>数据集上训练PGNet模型，因为CoQA中的答案与QuAC不同，是自由形式的。</p><p id="e5eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们观察到，这种模型在重构是/否问题的答案方面非常好。然而，对于其他类型的问题，它们表现不佳。</p><h1 id="8b33" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">艾迪:理想的系统设计</h1><p id="3f99" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">不可否认，语音助手是互联网的未来。与语音助手互动比浏览一堆网页结果更像人类。然而，提供类似人类的体验仍然遥不可及。</p><p id="b65d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了实现这个目标，我们提出了一个新颖的端到端设计来开发这样一个多领域、多圈、上下文相关的智能QA代理。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lo"><img src="../Images/e7fe3f16866ddd55fb31dda6877a5c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ASOkVbYpDxIsCzyrHNFkpA.jpeg"/></div></div></figure><p id="fbe8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个设计的每一个组成部分都在我的3篇博文中讨论过。据我所知，这是第一个设计和实现端到端开放领域QA代理的开源项目。</p><h1 id="d4b7" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">展望未来</h1><p id="6470" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">用户问题是开放式的、模糊的、多方面的、无法回答的，或者在给定的上下文中通常是有意义的。处理如此复杂的信息需求使得开发Eddie具有挑战性。</p><p id="20cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们提出的设计非常适合构建这样一个系统所需的众多组件。然而，我们还没有对<strong class="ih hj">个性化组件</strong>建模。我们还计划改进我们的文档阅读器模型，以处理答案跨越多个段落的问题(<strong class="ih hj">多跳推理</strong>)。</p><p id="354a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想了解更多，请随时联系我(【https://miteshksingh.github.io/】T4)。</p></div></div>    
</body>
</html>