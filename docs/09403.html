<html>
<head>
<title>Prediction and Data Visualization of Breast Cancer using K-Nearest Neighbor (KNN)Classifier Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 K-最近邻(KNN)分类算法的乳腺癌预测及数据可视化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/prediction-and-data-visualization-of-breast-cancer-using-k-nearest-neighbor-knn-classifier-df7adadc4872?source=collection_archive---------1-----------------------#2020-09-05">https://medium.com/analytics-vidhya/prediction-and-data-visualization-of-breast-cancer-using-k-nearest-neighbor-knn-classifier-df7adadc4872?source=collection_archive---------1-----------------------#2020-09-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="a4ec" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">让我们使用机器学习来早期检测乳腺癌，以对抗乳腺癌。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/8aeacbdbefc547ff38f40b18cfe62aef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f8UToF4MLWqcrhZOatQURA.jpeg"/></div></div></figure><h1 id="4f71" class="jj jk hi bd jl jm jn jo jp jq jr js jt io ju ip jv ir jw is jx iu jy iv jz ka bi translated">问题陈述</h1><p id="0407" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">癌症是全球第二大死亡原因。在皮肤癌之后，乳腺癌是女性比男性更常见的癌症。</p><p id="9a16" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">乳腺癌是通常称为肿瘤的乳房组织中细胞异常生长的结果。肿瘤并不总是意味着癌症，但肿瘤可以是良性的(不是癌性的),这意味着细胞不会患癌症，也可以是恶性的(癌性的),这意味着细胞非常危险并且有毒，可能导致乳腺癌。</p><p id="8480" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">乳腺癌的原因是多因素的。如今，乳腺癌的几个风险因素已经为人所知。风险因素分为不可改变的风险因素，如年龄、性别、遗传因素(5-7%)、乳腺癌家族史、既往乳腺癌史和增生性乳腺疾病。可改变的危险因素是月经和生殖、辐射暴露、激素替代疗法、酒精和高脂肪饮食。导致乳腺癌的环境因素是有机氯暴露、电磁场和吸烟。<a class="ae lc" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5980871/#:~:text=Several%20risk%20factors%20for%20breast,cancer%20and%20proliferative%20breast%20disease." rel="noopener ugc nofollow" target="_blank">(克莱蒙斯和戈斯，2001；Nindrea 等人，2018) </a></p><p id="aa94" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">本文主要记录了<strong class="kd hj">实现 K-最近邻分类器机器学习算法</strong>的能力，以获取乳腺癌过去测量的数据集，<strong class="kd hj">通过探索性数据分析将数据可视化</strong>和<strong class="kd hj">评估构建 KNN 模型</strong>的结果，以了解哪些是最有能力的特征，可以使用数据集作为乳腺癌的风险发生。</p><p id="391e" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">所以，让我们把重点放在基本流程上。</p><p id="8b76" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld">数据采集</em> </strong></p><ul class=""><li id="b598" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated">资料组</li><li id="6bb8" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">属性描述</li></ul><p id="bec9" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld">实施前的数据预处理</em> </strong></p><ul class=""><li id="4e1b" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated">初始步骤</li><li id="e60a" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">数据预处理</li></ul><p id="3ed4" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld">探索性数据分析</em> </strong></p><ul class=""><li id="5ab8" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated">描述统计学</li><li id="ba04" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">使用计数图的数据可视化</li><li id="27bc" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">使用散点图的数据可视化</li><li id="5989" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">使用相关矩阵的数据可视化</li></ul><p id="7f9e" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"><em class="ld">K-最近邻算法</em> </strong></p><ul class=""><li id="3133" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated">K-NN 算法的基本概念</li><li id="4d8f" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">K-NN 算法的实现</li><li id="4c29" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">建立(KNN)的预测模型</li></ul><p id="9e5f" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld">成绩评估</em> </strong></p><ul class=""><li id="4fad" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated">分类报告</li><li id="050c" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">准确度分数</li><li id="a008" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">混淆矩阵</li></ul><p id="3862" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">通过<strong class="kd hj">将患者癌症阶段分为良性(B)和恶性(M)来预测未来患者被诊断为患病的可能性。</strong>因此，使用重要的测量，我们可以<strong class="kd hj">预测患者的未来</strong>是否他/她容易携带乳腺癌，并且<strong class="kd hj">基于具有所提供属性的数据集的预测</strong>和<strong class="kd hj">数据</strong> <strong class="kd hj">分析</strong>来测量乳腺癌风险的诊断准确性。</p><h1 id="7274" class="jj jk hi bd jl jm jn jo jp jq jr js jt io ju ip jv ir jw is jx iu jy iv jz ka bi translated">1.数据收集</h1><h2 id="002d" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">1.1 数据收集</h2><p id="9443" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">为了创建乳腺癌阶段的分类并使用预测乳腺癌的 KNN 算法训练模型，作为第一步，我们需要找到一个数据集。<strong class="kd hj"><em class="ld"/></strong><a class="ae lc" href="https://www.kaggle.com/uciml/breast-cancer-wisconsin-data" rel="noopener ugc nofollow" target="_blank"><strong class="kd hj"><em class="ld">乳腺癌威斯康星(诊断)数据集(第二版)</em></strong></a><strong class="kd hj"><em class="ld"/></strong>是本文中用于乳腺癌分期预测的数据库。</p><p id="8f86" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">该数据库使用 UCI 机器学习库发布在 Kaggle.com 网站上，并且该数据库是从威斯康星大学医院获得的。数据以逗号分隔值(CSV)文件的形式呈现。数据集的大小是 122KB。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mg"><img src="../Images/2ecbf7b482cc3b05f324c2206aa74cc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pecEnRcONk7uvOGmUlCi4g.jpeg"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">表 1:数据集的特征</figcaption></figure><h2 id="48e0" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">1.2 属性描述</h2><p id="ffe8" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">下表包含我们选择的数据集中使用的属性及其描述。这些属性描述是在获得的数据集中发布的标准描述。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/532e94208388fa8b3e5443c96f5d6115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-7Gwli-yhmHA7XNRmJwSRg.jpeg"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">表 2:数据集属性描述</figcaption></figure><p id="760f" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">当考虑数据集属性<strong class="kd hj"> <em class="ld">的描述时，“恶性(M)”和“良性(B)”</em></strong>是该数据集中用于预测乳腺癌的两个类别。替代特征代表乳腺癌风险的不同属性，其可用于对引起或不引起乳腺癌的给定情况进行分类。<strong class="kd hj"/>“诊断”是包含<strong class="kd hj">癌症阶段</strong>的特征，用于预测哪些阶段是<strong class="kd hj"> 0(B) </strong>和<strong class="kd hj"> 1(M) </strong>值，<strong class="kd hj"> <em class="ld"> 0 表示“非乳腺癌”，1 表示“乳腺癌”。</em> </strong></p></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><h1 id="b7f9" class="jj jk hi bd jl jm mt jo jp jq mu js jt io mv ip jv ir mw is jx iu mx iv jz ka bi translated">2.实施前的数据预处理</h1><h2 id="c0bd" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">2.1 初始步骤</h2><p id="96c2" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">找到合适的数据集后，在实现模型之前需要遵循一些初始步骤。</p><p id="b523" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">第一步是将所有必需的库导入到环境中。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es my"><img src="../Images/7f3bac1c616e10e7326f48b2d273e977.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uFyjmn7qE4a9IXrT6RaVwg.jpeg"/></div></div></figure><p id="eacb" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">在导入所有必需的库之后，数据集应该加载到环境中。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mz"><img src="../Images/0ef8dfbbb56dfc7cb6eee20af3001a5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s6rSCMyX7vgBnZ5PNRty_A.jpeg"/></div></div></figure><p id="787c" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">下一步应该读取数据集。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es na"><img src="../Images/739b48ce740c19522bfe2de3ec5d07ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*veFKDw-HB4IykBdhOJ1LcQ.jpeg"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nb"><img src="../Images/5338058c585355533093fa8bc656ebda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1FyCJmZ0BZo5v0vfI4Sj3Q.jpeg"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 1:预处理前的样本数据</figcaption></figure><h2 id="d7de" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">2.2 数据预处理</h2><p id="b6e9" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">数据预处理极其重要，因为它可以提高原始实验数据的质量。</p><p id="b8f6" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">因此，要获得预处理任务的最优解集，应用如下代码段。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nc"><img src="../Images/70c6c8fd50f4c45d0d097a6c6631f4fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*mnYsOhpWH5V_4pUJww3YgA.png"/></div></figure><p id="eecc" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">根据上面的代码段，预处理任务丢弃了不必要的列(id)，这些列称为未命名的<strong class="kd hj"><em class="ld">:32 个未使用的</em></strong><strong class="kd hj"><em class="ld">将目标数值改为 1 和 0 </em> </strong>以帮助统计。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/b9b78f07d9557237e6945c9857c6817c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*poAw85y0h8OZMcmASJDmSw.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 2:预处理后的样本数据</figcaption></figure><p id="aa8e" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">在大多数真实世界的数据集中，总有一些空值。然而，没有模型能够独自处理这些 NULL 或 NaN 值。因此，需要插入以下代码段。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ne"><img src="../Images/76f2c5302cd6003b2874603b23491d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-QgpNc1G_nEXUT4SnQPs2A.png"/></div></div></figure><p id="6bd6" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld">检测空值</em> </strong>的数据集及其数据类型信息如下图所示。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nf"><img src="../Images/81d87f513aa02b3718823764b28644ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*oojT8oRBMagvExPbtaVChw.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 3:检查数据集的空值</figcaption></figure><p id="35b1" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">从上图中可以看出，数据集只包含<strong class="kd hj"> <em class="ld"> 1 个分类列</em> </strong>作为诊断，除了诊断列(即 M =恶性或 B =良性)所有<strong class="kd hj"> <em class="ld">外，其他特征都是 float64 </em> </strong>类型，并且有<strong class="kd hj"> <em class="ld"> 0 个非空数字。</em> </strong></p></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><h1 id="e7ed" class="jj jk hi bd jl jm mt jo jp jq mu js jt io mv ip jv ir mw is jx iu mx iv jz ka bi translated">3.探索性数据分析</h1><h2 id="de30" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">3.1 描述性统计</h2><p id="c55c" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">此部分显示量化描述或汇总信息集合特征的汇总统计信息，这是将数据集的关键特征压缩为简单数字度量的过程。一些常用的指标是平均值、标准差和相关性。</p><p id="73bd" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">数据集的描述性统计可以通过下面的代码段获得。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ng"><img src="../Images/0eaf72c40b9326a64d51daf3c6c81d31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yC6ZwhS9jzt6U61Tji6aEQ.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nh"><img src="../Images/045f75aa71b365209df166bc56048c6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TSQKu6_n-ERP7HRqd2XISg.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 4:数据集的描述性统计输出</figcaption></figure><p id="5552" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">从图中中间值和平均值之间的差异来看，似乎有一些特征具有<strong class="kd hj"><em class="ld"/></strong>。</p><p id="32b2" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">基于诊断类别，数据集可以使用平均值分类如下。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ni"><img src="../Images/440f0cea667c651ea7800e9d6f3146f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vUVdpCRqhSEg6chvKGOjCw.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nj"><img src="../Images/6b1e90f8fe19350284ce1f2d8a98c320.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pUvcYtiL5lzzFVsYhf8bmA.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 5:基于诊断阶段的数据分类</figcaption></figure><h2 id="ccc6" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">3.2 使用计数图的数据可视化</h2><p id="c615" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">使用 seaborn 计数图生成乳腺癌分期的频率。它是基于乳腺癌的诊断类别生成的，如下所示。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/f69ac1ed8791b8e17c55150857a79986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XCttTHHxP3z6jfy1_9M4jg.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nl"><img src="../Images/90db5f2574b74279be506eeef3d6b222.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*Ngz5Rq0RVQlxSQtg-uc5Rw.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 6:计数图</figcaption></figure><p id="a5ff" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">从上面的计数曲线图可以清楚地看到，在数据集中有更多的良性(B)期 的肿瘤可以治愈。</p><h2 id="9126" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">3.3 使用散点图的数据可视化</h2><p id="0c7c" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">散点图通常用来描述变量之间的关系。</p><p id="f758" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">下面的代码段用于生成查看数据集中属性的相关性。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nm"><img src="../Images/0a653f8f5bf4a6839cfb89024ba67259.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*myNfii3tViuV4IU0OMyxCg.png"/></div></div></figure><p id="d0b4" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">散点图的输出，显示数据集中分布和关系的平均值。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nn"><img src="../Images/a303620715569a39078a99392ccd9b6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*02l-4ipAuuLzX7rwneHP0w.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 7:散点图矩阵</figcaption></figure><p id="57f7" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">观察上图，细胞半径、周长、面积、紧密度、凹度和凹点的平均值可用于乳腺癌的分类。<strong class="kd hj"> <em class="ld">这些参数的较大值往往显示出与恶性肿瘤的相关性。</em>T3】</strong></p><h2 id="776e" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">3.4 使用相关矩阵的数据可视化</h2><p id="c7a4" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">关联矩阵也称为热图，是观察数据集中所有关联的强大绘图方法。</p><p id="e3c2" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">以下代码段用于计算每对输入要素之间的相关系数。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es no"><img src="../Images/387f842af201ff0d4345f230a4c29f3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ZZJjurAXGydQrU04FJ_fw.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es np"><img src="../Images/66964a67674c4e31cfd25df08eb0a4c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mMWoEpsW0BOsL2woP5tlwA.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 8:关联矩阵(热图)</figcaption></figure><p id="9a35" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">如上图观察，组织细胞核的平均面积与半径和参数的平均值有一个<strong class="kd hj">和<em class="ld">强正相关。此外，一些参数适度正相关(r 在 0.5-0.75 之间)</em></strong></p></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><h1 id="eb86" class="jj jk hi bd jl jm mt jo jp jq mu js jt io mv ip jv ir mw is jx iu mx iv jz ka bi translated">4.k-最近邻算法</h1><h2 id="4b4d" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">4.1K-NN 算法的基本概念</h2><p id="546d" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">K-最近邻算法(K- Nearest Neighbors)也称为 K-NN，是监督机器学习算法家族中最简单也是最强的算法之一，它是指我们使用标记(目标变量)数据集来预测新数据点的类别。它主要用于分类问题以及回归问题。KNN 也称为非参数，懒惰学习算法。</p><p id="1d64" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">由于其易于解释和计算时间短而被广泛使用。算法的工作流程如下。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nq"><img src="../Images/a63943771a9bbc34d97168bdf69d791c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*2lB3OrXBdlG1PjMhICgsSw.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 9: K-NN 分类— <a class="ae lc" href="https://miro.medium.com/max/650/1*OyYyr9qY-w8RkaRh2TKo0w.png" rel="noopener">图像来源</a></figcaption></figure><p id="d810" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">KNN 算法中的“K”是我们希望进行投票的最近邻。</p><p id="8b71" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">图 9 描述了 KNN 算法是如何工作的，其中考虑了它的邻居。</p><p id="34b4" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">决定类的时候，考虑点属于哪里。此外，通过使用邻近度、距离或接近度，使用根据给定半径或“K”最接近一个点的点来建立该点的邻居。</p><p id="6adb" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">在图 9 中，将测试样本描绘为圆圈内的绿色圆圈。应该是第一类蓝色方块或者第二类红色三角形。</p><p id="ea71" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">考虑到<strong class="kd hj"> <em class="ld"> K 的最近邻值为 1，3 和 5 </em> </strong>训练样本识别的类选择如下。</p><ul class=""><li id="9507" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated"><strong class="kd hj"> <em class="ld"> K = 1 </em> </strong>表示在圆内，因为内圆内只有一个正方形，所以赋给一等。</li><li id="b9be" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated"><strong class="kd hj"> <em class="ld"> K = 3 </em> </strong>意为圆外，因为内圆内有两个三角形，只有一个正方形，所以划入第二类。</li><li id="0d21" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated"><strong class="kd hj"> <em class="ld"> K= 5 </em> </strong>被分配到第一类，因为它包括外圆外的 3 个正方形 vs 2 个三角形。</li></ul><p id="ecd5" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">一般来说，选择<strong class="kd hj"><em class="ld">【K】</em></strong>的较小值可以<em class="ld"/><em class="ld">会对结果有较高的影响。</em><strong class="kd hj"><em class="ld"/></strong>的“较大 K 值”将具有<em class="ld">更平滑的决策边界，这意味着较低的方差但增加了偏差</em>和<em class="ld">的计算开销。</em></p><p id="6579" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">选择 K 以获得更高准确度分数的最佳方法之一是通过<strong class="kd hj"> <em class="ld">交叉验证</em> </strong>。从训练数据集中选择交叉验证数据集的一种方式。从训练数据集中取出一小部分，称之为验证数据集，然后使用它来评估 K 的不同可能值。这样，我们将使用 K 等于 1、K 等于 2、K 等于 3 等来预测验证集中每个实例的标签。然后，我们看看 K 的什么值在验证集上给我们最好的性能，然后我们可以取那个值，并使用它作为我们算法的最终集，这样我们就可以最小化验证或错误分类错误。</p><p id="b922" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">因此，可以清楚地说，该算法的准确性和成功广泛地取决于“K”值的选择或邻居的数量。</p><p id="626d" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld">的一些优点使用</em></strong>KNN 分类器算法如下。</p><ul class=""><li id="381a" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated">简单实现</li><li id="64ec" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">灵活选择功能/距离</li><li id="5e42" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">自然处理多类案件</li><li id="2682" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">在实践中可以做得很好，有足够的代表性数据</li><li id="e43b" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">可用于分类和回归问题。</li></ul><h2 id="e048" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">4.2 最近邻算法的实现</h2><p id="e39b" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld"> 4.2.1 将数据集拆分为特征和标签</em> </strong></p><p id="c963" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">在实施 KNN 分类器之前，作为实施中的第一阶段，需要分离特征和标签。</p><ul class=""><li id="0112" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated"><strong class="kd hj"> <em class="ld">标签</em> </strong> —我们试图预测的东西(诊断)</li><li id="860f" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated"><strong class="kd hj"> <em class="ld">特性</em> </strong> —用于预测标签的属性。(良性— 0 或恶性— 1)</li></ul><p id="e2f8" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">以下代码段将数据集的分割显示为要素和标签。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nr"><img src="../Images/157f4e1ee07d750bae9404857223a4f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yojp-osoGkVPAJyFGen_vg.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ns"><img src="../Images/d83b5bffda19e21f048ebb5b3050b8c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*aXfvLvO0Fqf9pELrFxUtLQ.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 10:将数据集分成要素和标签</figcaption></figure><p id="5834" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld"> 4.2.2 将数据集拆分成测试集和训练集</em> </strong></p><p id="3c5f" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">下一步，我们需要将数据分成训练集和测试集。训练数据将用于创建 KNN 分类器模型，测试数据将用于测试分类器的准确性。因为<strong class="kd hj"> <em class="ld">将数据分成训练集和测试集将避免过拟合并优化 KNN 分类器模型。</em> </strong></p><p id="8765" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">下面的代码段显示了将数据集分成测试集和训练集的过程。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nr"><img src="../Images/ba36cc2b5a5fec04ba17ea25c2b9c8e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OaiLudk8TMaucXNIwVM-w.png"/></div></div></figure><p id="53fb" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">Sklearn 用于拆分数据。根据上述代码段，数据集的指定<strong class="kd hj"> <em class="ld">测试大小为 0.3 </em> </strong>。因此，<strong class="kd hj"> <em class="ld"> 30%的数据被拆分成测试</em> </strong>，剩余的<strong class="kd hj"><em class="ld">70%用于训练模型。</em>T11】</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nt"><img src="../Images/d678c4aab28fb3ce0d3ce18b9004dee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*zXrND8TlMlv5h0pMpbgvfg.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 11:带有特征和标签的分离数据集</figcaption></figure><p id="06f7" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld"> 4.2.3 通过实施 KNN 算法</em> </strong>建立预测模型</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nu"><img src="../Images/f0ab48c103c39febadeadc98d1b3cd63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KvdUSRu9NaSUlM2cjWHZDQ.png"/></div></div></figure><p id="57df" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">构建预测模型时，第一步是从<em class="ld"> "sklearn.neighbors" </em>库中导入<em class="ld"> "KNeighborsClassifier" </em>类。在第二行中，这个类用一个参数初始化，如<em class="ld">“n _ neigbours”</em>。</p><p id="d55f" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">这基本上是 K 的值。K 没有理想值，它是在测试和评估后选择的，但是，开始时，5 似乎是 KNN 算法最常用的值。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nv"><img src="../Images/e45c54c5849058ed53cc15b5bc79307e.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*2ldTYAqGusEllOHL114NKg.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 12:KNN 分类器的实现</figcaption></figure><p id="976e" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld"> 4.2.4 交叉验证</em> </strong></p><p id="a768" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">为了在乳腺癌-威斯康星数据集上为 KNN 选择最佳调整参数(超参数)并获得最佳概括数据，我们需要执行<strong class="kd hj"> <em class="ld"> 10 折交叉验证</em> </strong>，详细描述如下代码段。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nw"><img src="../Images/b8ac39161d8a2042f46c8ae67b426ee3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LxwrnldWHF0HdGv8bUhlGA.png"/></div></div></figure><p id="98de" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">在执行 10 倍交叉验证后，10 次迭代的准确度分数输出如下。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nx"><img src="../Images/ff81c06120202cae00d437612767cbe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*B5MipCcs4KtI6RVFhg8cfQ.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 13:10 次迭代的交叉验证准确性</figcaption></figure><p id="4790" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld"> 4.2.5 求 K 个邻居的最优个数</em> </strong></p><p id="9529" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">通过<strong class="kd hj"> <em class="ld">绘制 K 个邻居</em> </strong>的误分类误差，找到提供最高准确度分数的最佳 K 值的确定。这个过程是使用下面的代码段完成的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ny"><img src="../Images/c4b03b1815f60b9e7b27e88c852f48ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lxXu0OaX02S2n2PggIpVhw.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nz"><img src="../Images/7c97dd3288144224a9746f14f766f10b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9yUUTDmXHo9Fu7e7h2-6EQ.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 14:最佳 K 值的确定</figcaption></figure><p id="6da2" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">图 14 清楚地表明，当<strong class="kd hj"> <em class="ld"> K 的值在 13 和 17 之间时，<strong class="kd hj"><em class="ld"/></strong><strong class="kd hj"><em class="ld"/></strong>的平均误差为 0.88。</em>T49】</strong></p><p id="ce94" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld"> K= 13 </em> </strong>是误分类误差最小的最佳 K 值。</p></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><h1 id="b07a" class="jj jk hi bd jl jm mt jo jp jq mu js jt io mv ip jv ir mw is jx iu mx iv jz ka bi translated">5.结果评估</h1><h2 id="245b" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">5.1 分类报告</h2><p id="a919" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">分类报告显示了每个类别的主要分类指标的表示。它对分类器行为的整体准确性给出了更深层次的直觉，这可以掩盖一个多类问题中的一个类的功能弱点。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oa"><img src="../Images/85316a940323d444c7831c1f6f7276b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wzHn6M7h1xro3RhbXTvFgg.png"/></div></div></figure><p id="2b20" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">图 15 显示了分类报告的结果及其属性。</p><ul class=""><li id="2101" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated"><strong class="kd hj"> <em class="ld">精度— </em> </strong>分类器不将实际上为负的实例标记为正的能力。</li><li id="193a" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated"><strong class="kd hj"> <em class="ld">回忆— </em> </strong>分类器找到所有肯定实例的能力。</li><li id="ff46" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated"><strong class="kd hj"> <em class="ld"> F1-score — </em> </strong>精度和召回率的加权调和平均值，最好的分数是 1.0，最差的是 0.0。</li><li id="7297" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated"><strong class="kd hj"> <em class="ld">支持— </em> </strong>指定数据集中该类实际出现的次数。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ob"><img src="../Images/6bf22bc6daa23e6d469cf19a2bd13d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*PL96pOI8JOBy58BWWvqE0A.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 15:分类报告</figcaption></figure><p id="fa6b" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">对用于乳腺癌预测的预测模型的分类报告的观察如下。</p><ul class=""><li id="9f21" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated">分类器总共做出了<strong class="kd hj"><em class="ld">174 个预测。</em>T15】</strong></li><li id="155a" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">在这 174 个病例中，分类器预测癌症阶段<strong class="kd hj"> <em class="ld">“恶性”58 次，“良性”113 次。</em>T19】</strong></li><li id="1c59" class="le lf hi kd b ke ln kh lo kk lp ko lq ks lr kw lj lk ll lm bi translated">现实中，<strong class="kd hj"> <em class="ld">样本中有 63 名患者患有疾病</em></strong><strong class="kd hj"><em class="ld">【恶性】</em> </strong>，而<strong class="kd hj"> <em class="ld">中有 108 名患者没有</em> </strong>，因为他们被预测为<strong class="kd hj"> <em class="ld">【良性】癌期。</em> </strong></li></ul><h2 id="702c" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">5.2 准确度得分</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oc"><img src="../Images/006a7368bbe8acb5ad160c7d67949c65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Rx0cf_nQ5bWzS--3QgOaA.png"/></div></div></figure><p id="04eb" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">通过应用 KNN 分类器模型 “乳腺癌威斯康星(诊断)”数据集   <strong class="kd hj"> <em class="ld">的乳腺癌预测的总体准确度是 96.4912280，这意味着该模型在该场景中表现良好。</em></strong></p><h2 id="618e" class="ls jk hi bd jl lt lu lv jp lw lx ly jt kk lz ma jv ko mb mc jx ks md me jz mf bi translated">5.3 混淆矩阵</h2><p id="2253" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">混淆矩阵给出了实际标签和模型预测的清晰概述。它表示预测模型的准确性可视化。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ny"><img src="../Images/3f98f9d2b244c2017cf4cf413e8ef8e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ynh18KX23q8MovRALLCvHg.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es od"><img src="../Images/32e65730fd0269e28886a9f362e617f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*tm1IbsAx9eJb69FJFDx21w.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">图 16:混淆矩阵</figcaption></figure><p id="f04e" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">正如对图 16 中混淆矩阵的观察，</p><ul class=""><li id="faee" class="le lf hi kd b ke kx kh ky kk lg ko lh ks li kw lj lk ll lm bi translated">模型<strong class="kd hj"> <em class="ld">预测 112 个实例处于“良性(0)】</em></strong>阶段，而<em class="ld">只有 107 个，并且它预测 59 个实例</em>处于<strong class="kd hj"> <em class="ld">【恶性(1)】,而只有 58 个处于。</em>T55】</strong></li></ul></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><h1 id="29c9" class="jj jk hi bd jl jm mt jo jp jq mu js jt io mv ip jv ir mw is jx iu mx iv jz ka bi translated">夏天似的</h1><p id="eff3" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">在使用“K-最近邻分类器算法”实现和执行所创建的机器学习模型之后，可以清楚地发现,“乳腺癌威斯康星(诊断)数据集(版本 2)”的预测模型给出了最佳的<strong class="kd hj"> <em class="ld">准确度分数，为 96.44544%。36366.86867867667</em>T59】</strong></p><p id="ef7f" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">由于预测性<strong class="kd hj"> <em class="ld">模型是为分类问题</em> </strong>而创建的，所以这个准确度分数可以被认为是好的分数，并且它代表了模型的更好的性能。</p><p id="98e8" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">当应用 KNN 分类器时，当邻居数量变化时，它提供不同的准确度分数。当<strong class="kd hj"> <em class="ld">的最佳邻居数量为 13 </em> </strong>时，该模型给出了相当不错的准确度分数，其中该模型是用 1 到 50 范围内的值作为“K”的值或邻居的数量来测试的<strong class="kd hj"> <em class="ld">。</em> </strong></p><p id="ffb1" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="ld">为选择该模型中的最佳调整参数，应用 10 重交叉验证进行测试，每重包含 51 个实例。</em> </strong>从实验结果中，观察到<strong class="kd hj"> <em class="ld">将患者癌症阶段准确地分类为良性(B)和恶性(M)。</em>T15】</strong></p><p id="db81" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">此外，在数据探索部分，用<strong class="kd hj"> <em class="ld">对数据集进行描述性统计和可视化</em> </strong>任务揭示了预测前数据集的更好想法。</p><p id="a076" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">此外，评估部分中的<strong class="kd hj"> <em class="ld">分类报告和混淆矩阵</em> </strong>清楚地详细表示了预测模型的准确度分数和可视化。</p></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><p id="50d9" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">希望你喜欢这篇文章。😀</p><p id="4dfe" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">在这里，我与你分享我的<a class="ae lc" href="https://github.com/SasmithA18/Machine-Learning" rel="noopener ugc nofollow" target="_blank"> git 库</a>。🤗</p></div></div>    
</body>
</html>