<html>
<head>
<title>TensorFlow Lite Android Example [Beginners]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow Lite Android示例[初学者]</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorflow-lite-on-android-2f57267f7297?source=collection_archive---------0-----------------------#2020-07-10">https://medium.com/analytics-vidhya/tensorflow-lite-on-android-2f57267f7297?source=collection_archive---------0-----------------------#2020-07-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/11e37a9890707400da96aaad43c98033.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dHEaBzpso1Ytmklx"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae iu" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Franck V. </a>拍摄的照片</figcaption></figure><p id="a99c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://www.tensorflow.org/lite/guide/android" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> TensorFlow </strong> </a>是谷歌的开源机器学习框架，用于跨一系列任务的数据流编程。图中的节点表示数学运算，而图边表示它们之间通信的多维数据数组。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jt"><img src="../Images/9b4b571837ae3a6716b5b35b97978590.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*6qYUUYYQDRULXsc7s7XZIQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">张量流图</figcaption></figure><p id="f8e2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">张量只是多维数组，是二维表向更高维数据的扩展。TensorFlow有许多功能，这使它适合深度学习，它的核心开源库可以帮助您开发和训练ML模型。</p><h1 id="ca50" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">张量流的用例</h1><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/ed5e0362a3e74a9374325b8af9a37476.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*OTsRefoJujQR9fAlqra6ZQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">张量流用例</figcaption></figure><h1 id="db52" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">什么是图像分类？</h1><p id="4057" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">图像分类的目的是将数字图像中的所有像素归入几个土地覆盖类别或主题之一。然后，这种分类数据可用于制作图像中的土地覆盖专题地图。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/77add8a4c538a4e38be71edd36fa0a63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*GSZo4Wh57ErivLmxqj_ddg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">张量流图像分类</figcaption></figure><p id="a0ee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，不浪费任何时间，让我们进入张量流图像分类。</p><p id="4d8b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以通过5个步骤<strong class="ix hj">为android构建TensorFlow Lite模型</strong>，</p><ul class=""><li id="f6e9" class="ld le hi ix b iy iz jc jd jg lf jk lg jo lh js li lj lk ll bi translated">在Colab上安装TensorFlow 2.0 alpha</li><li id="9143" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">数据集准备</li><li id="9ec1" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">构建迁移学习模型</li><li id="6222" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">编译和训练模型</li><li id="1633" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">将Keras模型转换为TFLITE格式</li></ul><h1 id="5365" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">1.在Colab上安装TensorFlow 2.0 alpha</h1><p id="1328" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated"><a class="ae iu" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwip7oqGs67qAhX4zDgGHZVpAG8QFjAAegQIAxAC&amp;url=https%3A%2F%2Fcolab.research.google.com%2F&amp;usg=AOvVaw3A5aPK2kLFzKOzb6sOckVw" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">谷歌合作实验室</strong> </a>让在云中设置Python笔记本变得非常容易。由于每次可以免费访问GPU长达12小时，Colab很快成为我进行机器学习实验的首选平台。</p><p id="84a6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们通过pip在一台Colab笔记本上安装TensorFlow 2.0 alpha版本(GPU版)。</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="00ef" class="lw jz hi ls b fi lx ly l lz ma">!pip install tensorflow-gpu==2.0.0-alpha0</span></pre><p id="5684" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要验证其安装是否正确:</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="696b" class="lw jz hi ls b fi lx ly l lz ma">import tensorflow as tf <br/>print(tf.__version) <br/># Output: 2.0.0-alpha0</span></pre><h1 id="243a" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">2.数据集准备</h1><p id="2e3f" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">我们可以使用Keras ImageDataGenerator类和flow_from_directory() API逐步加载图像。这执行起来会比较慢，但是可以在更多的机器上运行。</p><p id="00fb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个API喜欢将数据划分到单独的train/和test/目录中，并且在每个目录下为每个类创建一个子目录。</p><p id="1f72" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后图像被组织在子目录下。</p><p id="9322" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们需要在Google Drive上上传训练和测试文件。将数据导入Google Colab环境还有其他方法(链接),但是，我们选择这种方法是因为它易于使用。现在让我们看看这是如何工作的。</p><p id="d63c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦您上传了训练和测试文件，第一步是将您的驱动器文件夹挂载到Colab环境中:</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="3354" class="lw jz hi ls b fi lx ly l lz ma">from google.colab import drive<br/>drive.mount('/content/drive')<br/>train_dir = '/content/drive/My Drive/tensorflow/document/Train'<br/>validation_dir = '/content/drive/My Drive/tensorflow/document/Test'<br/>image_size = 128<br/>batch_size = 32<br/>train_datagen = tf.keras.preprocessing.image.ImageDataGenerator()<br/>train_generator = train_datagen.flow_from_directory(directory=train_dir, target_size=(image_size, image_size), batch_size=batch_size)<br/>validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator()<br/>validation_generator = validation_datagen.flow_from_directory(directory=validation_dir, target_size=(image_size, image_size), batch_size=batch_size)</span></pre><h1 id="4ea2" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">3.构建迁移学习模型</h1><p id="b240" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">让我们使用TensorFlow 2.0的高级Keras API来快速构建我们的图像分类模型。对于迁移学习，我们可以使用预训练的MobileNetV2模型作为特征检测器。</p><p id="4574" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">MobileNetV2是Google发布的MobileNet的第二个迭代，目标是比ResNet和Inception等模型更小、更轻，以便在移动设备上运行。</p><p id="81df" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们加载在ImageNet上预训练的没有顶层的MobileNetV2模型，冻结其权重，并添加新的分类头。</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="29b8" class="lw jz hi ls b fi lx ly l lz ma">IMG_SHAPE = (image_size, image_size, 3)<br/>base_model = tf.keras.applications.MobileNet(input_shape=IMG_SHAPE, include_top=False)<br/>base_model.trainable = False<br/>model = tf.keras.Sequential([<br/> base_model,<br/> tf.keras.layers.GlobalAveragePooling2D(),<br/> tf.keras.layers.Dense(3, activation='softmax')<br/>])<br/>model.summary()</span></pre><h1 id="a286" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">4.编译和训练模型</h1><p id="01b2" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">一旦我们定义了神经网络架构，我们现在将编译它并训练模型，以检查它在验证集上的性能:</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="66cd" class="lw jz hi ls b fi lx ly l lz ma">model.compile(optimizer=tf.keras.optimizers.Adam(),<br/> loss='categorical_crossentropy',<br/> metrics=['accuracy'])<br/>epochs = 25<br/>steps_per_epoch = numpy.asarray(train_generator.n / batch_size)<br/>validation_steps = numpy.asarray(validation_generator.n / batch_size)<br/>history = model.fit_generator(generator=train_generator,<br/> steps_per_epoch=steps_per_epoch,<br/> epochs=epochs,<br/> validation_data=validation_generator,<br/> validation_steps=validation_steps)</span></pre><p id="8bcd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我鼓励你这样做:</p><ul class=""><li id="94d3" class="ld le hi ix b iy iz jc jd jg lf jk lg jo lh js li lj lk ll bi translated">不断增长的时代</li><li id="0836" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js li lj lk ll bi translated">使用更多层</li></ul><p id="f122" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这将帮助您在验证集上获得更好的分数。</p><h1 id="a38c" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">5.将Keras模型转换为TFLITE格式</h1><p id="79e9" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated"><strong class="ix hj">什么是TensorFlow Lite？</strong></p><p id="6451" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">TensorFlow Lite是专为移动平台和嵌入式设备设计的轻量级版本。它为移动设备提供低延迟和小二进制大小的机器学习解决方案。</p><p id="a483" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">TensorFlow Lite支持一组针对移动平台进行了调整的核心运营商。它还支持模型中的自定义操作。</p><p id="ce68" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">TensorFlow Lite基于FlatBuffers定义了一种新的文件格式，这是一个开源平台序列化库。它包括一个新的移动解释器，用于保持应用程序小而快。</p><p id="78f4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> TensorFlow Lite由两个主要组件组成:</strong></p><p id="7449" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> TensorFlow Lite解释器</strong>，它在许多不同的硬件类型上运行特别优化的模型，包括手机、嵌入式Linux设备和微控制器。</p><p id="7bba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> TensorFlow Lite转换器</strong>，它将TensorFlow模型转换为解释器使用的有效形式，并可以引入优化来提高二进制大小和性能。</p><p id="91b9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">磁盘上训练好的TensorFlow模型会转换成TensorFlow Lite文件格式(<strong class="ix hj">)。tflite </strong>)使用TensorFlow Lite转换器。然后，我们可以在移动应用程序中使用转换后的文件。</p><p id="e373" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">将Keras模型导出为TFLITE格式</strong></p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="70b4" class="lw jz hi ls b fi lx ly l lz ma">saved_model_dir = '/content/drive/My Drive/tensorflow/sample 3/TFLite/assets'<br/>tf.saved_model.save(model, saved_model_dir)<br/>converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)<br/>tflite_model = converter.convert()<br/>with open('model17.tflite', 'wb') as f:<br/> f.write(tflite_model)<br/>labels = '\n'.join(sorted(train_generator.class_indices.keys()))<br/>with open('labels17.txt', 'w') as f:<br/> f.write(labels)</span></pre><p id="e065" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们已经训练了自己的TensorFlow Lite模型。</p><h1 id="74c4" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">如何从tensorflow lite模型进行图像分类</h1><p id="d769" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">流程真的很简单。我们将位图图像从CameraX中的分析用例传递给TensorFlow解释器，后者使用MobileNet模型和标签类对图像进行推理。下面是CameraX和TensorFlow Lite如何相互交互的图示。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/b9a15d0830ce2401a6f2bb26ef1a7930.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*c_3U8EjpUyZ4XV9r5hyHDQ.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图像分类</figcaption></figure><p id="78c2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面的将详细解释这个流程。</p><h1 id="c069" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">android中使用tensorflow lite模型进行图像分类的7个步骤</h1><ol class=""><li id="dad5" class="ld le hi ix b iy kx jc ky jg mc jk md jo me js mf lj lk ll bi translated">设置android依赖项</li><li id="ca2b" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js mf lj lk ll bi translated">添加受过训练的。tflite和lables.txt文件</li><li id="74e8" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js mf lj lk ll bi translated">生成模型ByteBuffer。</li><li id="7033" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js mf lj lk ll bi translated">阅读label.txt</li><li id="8c06" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js mf lj lk ll bi translated">通过缓冲器生成捕获的图像。</li><li id="fa6d" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js mf lj lk ll bi translated">带翻译运行。</li><li id="85bf" class="ld le hi ix b iy lm jc ln jg lo jk lp jo lq js mf lj lk ll bi translated">解析结果。</li></ol><h1 id="e6b9" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">1.设置android依赖项</h1><p id="b416" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">启动一个新的Android Studio Kotlin项目，并在应用程序的<strong class="ix hj"> build.gradle </strong>文件中添加以下依赖项。</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="b07f" class="lw jz hi ls b fi lx ly l lz ma">implementation ‘org.tensorflow:tensorflow-lite:+’</span></pre><p id="b062" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，您需要通过在<strong class="ix hj"> build.gradle </strong>文件中设置以下选项来确保模型没有被压缩:</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="5aff" class="lw jz hi ls b fi lx ly l lz ma">android{<br/>aaptOptions {<br/>noCompress “tflite”<br/>noCompress “lite”<br/>}</span></pre><p id="7386" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在您的<strong class="ix hj"> AndroidManifest.xml </strong>文件中为摄像机添加必要的权限:</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="22cc" class="lw jz hi ls b fi lx ly l lz ma">&lt;uses-permission android:name=”android.permission.CAMERA” /&gt;</span></pre><h1 id="9585" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">2 .添加经过培训的。tflite和lables.txt文件</h1><p id="c17c" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">接下来，添加MVP文件、<strong class="ix hj">标签和。您的<strong class="ix hj">资产</strong>目录下的tflite模型文件</strong>。</p><h1 id="280e" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">3 .通过缓冲区生成模型</h1><p id="292b" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">让我们为模型使用<strong class="ix hj"> tf.lite.Interpreter </strong>接口。</p><p id="b4f2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以用很多方法设置一个解释器，TF网站上推荐的一个是利用MappedByteBuffer。</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="743c" class="lw jz hi ls b fi lx ly l lz ma">@Throws(IOException::class) <br/>private fun getModelByteBuffer(assetManager: AssetManager, modelPath: String): MappedByteBuffer { <br/> val fileDescriptor = assetManager.openFd(modelPath) <br/> val inputStream = FileInputStream(fileDescriptor.fileDescriptor) <br/> val fileChannel = inputStream.channel <br/> val startOffset = fileDescriptor.startOffset <br/> val declaredLength = fileDescriptor.declaredLength <br/> return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength) <br/>}</span></pre><h1 id="1f28" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">4.阅读label.txt</h1><p id="909c" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">下一步是读取带有标签的文件。您可以通过以下方式轻松获得它们:</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="c152" class="lw jz hi ls b fi lx ly l lz ma">@Throws(IOException::class) <br/>private fun getLabels(assetManager: AssetManager, labelPath: String): List&lt;String&gt; { <br/> val labels = ArrayList&lt;String&gt;() <br/> val reader = BufferedReader(InputStreamReader(assetManager.open(labelPath))) <br/> while (true) {<br/> val label = reader.readLine() ?: break<br/> labels.add(label)<br/> } <br/> reader.close() <br/> return labels <br/>}</span></pre><h1 id="9c2f" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">5 .通过缓冲器生成捕获的图像</h1><p id="1d88" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">最后一件事是创建一个方法，该方法将一个图像作为参数，并返回一个标签列表，这些标签具有分配给它们的概率。</p><p id="749b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为我们的模型期望精确的输入形状(128×128像素),所以我们需要重新缩放交付的位图以适应这些约束。</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="7c31" class="lw jz hi ls b fi lx ly l lz ma">fun recognize(bitmap: Bitmap): List&lt;Recognition&gt;{<br/> val scaledBitmap = Bitmap.createScaledBitmap(bitmap, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE, false)</span></pre><p id="e075" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们需要创建适当大小的byteBuffer，它将作为参数传递给模型。</p><p id="6daf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">并将图像数据作为浮点数加载到byteByffer中。为了解码位图中每个像素的颜色(忽略alpha ),我们需要屏蔽最低有效的8位及其倍数。</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="8593" class="lw jz hi ls b fi lx ly l lz ma">val pixelValues = IntArray(MODEL_INPUT_SIZE * MODEL_INPUT_SIZE) <br/> bitmap.getPixels(pixelValues, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height) <br/>  <br/> var pixel = 0<br/> for (i in 0 until MODEL_INPUT_SIZE) { <br/> for (j in 0 until MODEL_INPUT_SIZE) { <br/> val pixelValue = pixelValues[pixel++] <br/> byteBuffer.putFloat((pixelValue shr 16 and 0xFF) / 255f) <br/> byteBuffer.putFloat((pixelValue shr 8 and 0xFF) / 255f) <br/> byteBuffer.putFloat((pixelValue and 0xFF) / 255f) <br/> } <br/> }</span></pre><h1 id="ccaa" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">6.用解释器运行</h1><p id="7fbc" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">最后，我们可以将byteBuffer传递给模型。解释器期望结果的第二个参数容器，它是浮点数组的数组(每个图像的数组，每个图像将包含概率的浮点数组)。</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="a6fd" class="lw jz hi ls b fi lx ly l lz ma">val results = Array(BATCH_SIZE) { FloatArray(labels.size) }<br/> model.run(byteBuffer, results)<br/> return parseResults(results)<br/>}</span></pre><h1 id="c6f0" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">7.解析结果</h1><p id="e27d" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">最后一步是将概率与适当的类绑定。</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="48f3" class="lw jz hi ls b fi lx ly l lz ma">private fun parseResults(result: Array&lt;FloatArray&gt;): List&lt;Recognition&gt; { <br/> val recognitions = mutableListOf&lt;Recognition&gt;() <br/> labels.forEachIndexed { index, label -&gt; <br/> val probability = result[0][index] <br/> recognitions.add(Recognition(label, probability)) <br/> } <br/>  <br/> return recognitions.sortedByDescending { it.probability } <br/>}</span></pre><p id="8d1c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中识别是我们的结果数据类。</p><pre class="ju jv jw jx fd lr ls lt lu aw lv bi"><span id="0127" class="lw jz hi ls b fi lx ly l lz ma">data class Recognition( <br/> val name: String, <br/> val probability: Float <br/>) { <br/> override fun toString() = <br/> "$name : ${probability}%"<br/>}</span></pre><p id="0236" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">就是这样。我们构建了tensorflow lite模型，并部署在android应用程序中。</p><figure class="ju jv jw jx fd ij"><div class="bz dy l di"><div class="mg mh l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">Tensorflow lite android示例演示</figcaption></figure><p id="1c1a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从<a class="ae iu" href="https://github.com/velmurugan35/Android-Example/tree/master/tflite" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> github </strong> </a>中检查示例。</p><p id="7ed3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">结论</strong></p><p id="06e9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谢谢你的阅读。这是tensorflow lite的基本图像分类。您可以尝试不同的数据集和模型组合。</p><p id="caba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请在下面提供您的意见。</p></div></div>    
</body>
</html>