<html>
<head>
<title>Non Linear Model — Solve using combination of Linear Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">非线性模型-使用线性模型的组合求解</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/non-linear-model-1a9067d79dd3?source=collection_archive---------15-----------------------#2019-09-24">https://medium.com/analytics-vidhya/non-linear-model-1a9067d79dd3?source=collection_archive---------15-----------------------#2019-09-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/28bdd016f9f40ca2bd38d9889ebabf69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*sVnbCJb03Bh0PmiXQXObGA.png"/></div></figure><p id="795a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本文中，我们将看到模型如何学习复杂数据集的非线性边界。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div class="er es jk"><img src="../Images/2417bf239497907bf6fbd7df04597788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*vJXMtcOX9QeElvCsnxLCcA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">非线性数据分离的例子。资料来源:Udacity</figcaption></figure><p id="fdfd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">背景</strong></p><p id="be2b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">真实世界的数据集通常有一个问题，即数据不能仅由一条线分开。那么一行之后的下一个是什么呢？可能是一个圆，可能是两条线，也可能是一些曲线。这是神经网络可以展示其全部潜力的地方。</p><p id="4aa1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">我们开始吧..</strong></p><p id="dfae" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">简而言之，对于无法用直线分离的数据，我们将创建一个概率函数，其中蓝色区域中的点更可能是蓝色的，而红色区域中的点更可能是红色的。将它们分开的曲线是一组同样可能是蓝色或红色的点。</p><blockquote class="jt ju jv"><p id="9723" class="im in jw io b ip iq ir is it iu iv iw jx iy iz ja jy jc jd je jz jg jh ji jj hb bi translated"><strong class="io hj">组合</strong></p></blockquote><p id="aa60" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将使用一个非常简单的技巧，即将两个线性模型合并成一个非线性模型，如下图所示。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ka"><img src="../Images/eee06686e802a705b143ef4ffa56f754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IgCl8DDkv_WT5mAw"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">结合两个线性模型。资料来源:Udacity</figcaption></figure><p id="4f55" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在结合线性模型之前，让我们先来看看数学。我们所知的线性模型是一个完整的概率空间。这意味着对于每一个点，它给出了这个点是蓝色的概率。让我们选择任意一个点，并检查它在线性模型中为蓝色的概率。如下图所示，来自第一线性模型的点的概率是0.7，来自第二线性模型的点的概率是0.8。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div class="er es kf"><img src="../Images/ec7ef7d24804cd239a1372e24d3fdc30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*ghjUPlP-KN4zTPAk0O7M_Q.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">点的概率，两个线性模型。资料来源:Udacity</figcaption></figure><p id="fc8b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在的问题是，我们如何将这两者结合起来？嗯，组合两个数最简单的方法就是把它们相加，对吧？</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div class="er es kg"><img src="../Images/63a67f8ae847e706510961a9a105d980.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*4K4jNFhz5KsAUYbWBdtzBg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">两个线性模型合并后(概率总和)。资料来源:Udacity</figcaption></figure><blockquote class="jt ju jv"><p id="d714" class="im in jw io b ip iq ir is it iu iv iw jx iy iz ja jy jc jd je jz jg jh ji jj hb bi translated"><strong class="io hj">乙状结肠</strong></p></blockquote><p id="b6d2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">但是现在，这看起来不再像是一个概率，因为它大于1(1.5 &gt; 1)。概率需要介于0和1之间。那么我们能做什么呢？我们如何把这个大于1的数变成介于0和1之间的数呢？我们有一个很好的工具，可以将每个数字转换成0到1之间的数字。这只是一个sigmoid函数。我们将sigmoid函数应用于1.5，得到0.82，这就是这个点在结果概率空间中为蓝色的概率。</p><blockquote class="jt ju jv"><p id="5252" class="im in jw io b ip iq ir is it iu iv iw jx iy iz ja jy jc jd je jz jg jh ji jj hb bi translated"><strong class="io hj">组合加权</strong></p></blockquote><p id="0de6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，如果我们想对这个总数进行加权呢？比如说，我们希望左边的模型比右边的模型更能表达结果概率？我们可以增加重量。例如，我们可以说“左一的七倍加上右一的五倍。”当我们组合模型时，我们取第一个概率，乘以7，然后取第二个概率，乘以5，如果需要，我们甚至可以添加偏差。假设偏差是负6，然后我们把它加到整个方程中。</p><p id="7789" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">7 * 0.7+5 * 0.8–6 = 2.9，2.9以上的乙状结肠会给出0.95。</p><blockquote class="jt ju jv"><p id="641b" class="im in jw io b ip iq ir is it iu iv iw jx iy iz ja jy jc jd je jz jg jh ji jj hb bi translated"><strong class="io hj">通过神经网络获得权重</strong></p></blockquote><p id="4eb9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，让我们学习如何通过神经网络获得这些权重。比方说，左边的线性模型的线性方程是5x1-2x2+8。右边是7x1–3 x2–1。下图显示了两种线性模型的感知器表示。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kh"><img src="../Images/57079de5de7e5c12e0dee77e5fe57181.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Qjm-BYbP5wsE3JAb"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">两种线性模型的感知器。资料来源:Udacity。</figcaption></figure><p id="1399" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，让我们使用另一个感知器，通过线性方程将这两个模型结合起来，第一个模型的七倍加上第二个模型的五倍减去六倍。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ki"><img src="../Images/48a11323dc110eafdeae25d59cf4fc9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zJMBJvtHMM4GpsN1"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">用于组合线性模型的感知器。资料来源:Udacity</figcaption></figure><p id="b2c4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在把所有这些连接在一起，我们得到了一个神经网络。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kj"><img src="../Images/fd3e87a050710c6e1200835601e1a65f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FjQLi-p72no2bkv9iQNDxA.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">最终神经网络表示</figcaption></figure><p id="3b82" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">此外，我们在上面绘制的内容将偏差放在节点内部(左侧或中间一个)以及单独的节点上(最右侧)。为了避免混淆，中间的是最左边的清晰表示。</p><p id="5472" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，这里神经网络将学习两种类型的权重。一个用于每个线性模型(包括偏差),另一个用于组合线性模型。</p><p id="b11b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">不同的神经网络架构</strong></p><blockquote class="jt ju jv"><p id="78db" class="im in jw io b ip iq ir is it iu iv iw jx iy iz ja jy jc jd je jz jg jh ji jj hb bi translated"><strong class="io hj">案例1——较大的隐藏层</strong></p></blockquote><p id="2aea" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我们正在合并三个线性模型，即在隐藏层中再添加一个节点，以获得输出层中的三角形边界。看看<a class="ae kk" href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" rel="noopener ugc nofollow" target="_blank"> <em class="jw">通用逼近定理</em> </a>说一层神经网络可以解决几乎任何问题或者单个隐层神经网络可以以任何精度逼近x的任何连续函数。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kl"><img src="../Images/d0420471f3f9ae2bc921273db980bf02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1hWEQR1jCoEmk1yGpn1Uqw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">更多隐藏层。资料来源:Udacity</figcaption></figure><p id="af5e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> <em class="jw">情况2 —节点较多的输出层</em> </strong></p><p id="8250" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这只是意味着我们有更多的产出。在这种情况下，我们只有一个多类分类模型。因此，如果我们的模型告诉我们图像是猫、狗还是鸟，那么我们只需让输出层中的每个节点输出每个类别(狗、猫、鸟)的分数。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es km"><img src="../Images/98ea99e5a599453f632a0165b44b59d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Dz6wufdEVEZCBE6bnN8AQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">输出层中的更多节点。资料来源:Udacity</figcaption></figure><p id="0b5d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> <em class="jw">案例3 —多层</em> </strong></p><p id="083d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这仅仅意味着我们有深度神经网络。在这里，我们的线性模型结合起来创建非线性模型，然后这些模型结合起来创建更多的非线性模型。一般来说，我们可以这样做很多次，并获得具有许多隐藏层的高度复杂的模型。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kn"><img src="../Images/435bf09e5df72d69be98fe15a5c9d2f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kikb_zeXr0w2Y15mpubD0Q.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">更多隐藏层。资料来源:Udacity</figcaption></figure><p id="f766" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，每当你看到一个神经网络，想想它定义的非线性边界是什么。</p><p id="688e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">学分:Udacity课程。</p><p id="de44" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果这篇文章对你有帮助，请给出反馈，并与你的朋友分享。</p><p id="7406" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">谢谢！！</p></div></div>    
</body>
</html>