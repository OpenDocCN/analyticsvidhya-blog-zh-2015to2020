<html>
<head>
<title>Mining Twitter Data without API keys</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">挖掘没有API键的Twitter数据</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/twitter-data-mining-mining-twitter-data-without-api-keys-a2a2bd3f11c?source=collection_archive---------0-----------------------#2019-11-15">https://medium.com/analytics-vidhya/twitter-data-mining-mining-twitter-data-without-api-keys-a2a2bd3f11c?source=collection_archive---------0-----------------------#2019-11-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="5829" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用一行命令获取Twitter大数据进行分析。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/ed4ada04a139c7b7160b418fd7f07280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*OAqL1Yatoe0KxNXSYTffAw.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">社交媒体平台:文本大数据的大矿</figcaption></figure><p id="a909" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi kf translated">ata是新的石油，它无处不在。在过去十年中，超过90%的大数据是由生活在城市地区的人产生的。随着物联网的出现和互联网使用的增加，社交媒体已经成为人们日常生活中不可或缺的一部分。每秒钟有数百万的非结构化数据被发送到云端，提供几乎任何话语的免费和无偏见的信息。每秒钟，平均约有6000条推文在Twitter上发布，相当于每分钟发送超过35万条推文，每天5亿条推文，每年约2000亿条推文。看统计<a class="ae ko" href="https://www.internetlivestats.com/twitter-statistics/" rel="noopener ugc nofollow" target="_blank">这里</a>。</p></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="8a65" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">想象一下，在你的个人电脑上获取这些数据，而不必编写任何庞大的代码。只是来自命令行或终端的一堆命令。</p></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="6ab8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我最近有机会加入一个团队，致力于一个以社区弹性和学生化为中心的项目，我需要下载并分析大约<strong class="jl hj"> 10年</strong>以来的<strong class="jl hj">旧/回溯</strong> twitter数据，我天真地采用了非常标准的方法，首先用Twitter创建一个开发者帐户，然后使用Tweepy查询Twitter的RESTful API，以便下载用户推文以及一些其他元数据，如转发、喜欢、收藏、日期和时间、用户名等。</p><p id="940e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我很快发现，走这条路对我的任务没有太大帮助，我的任务是<strong class="jl hj">从</strong> <em class="kw">到</em> <strong class="jl hj"> </strong> <em class="kw">下载过去10年中某个特定话语的twitter数据，然后这些数据将被输入到我构建的几个管道中进行分析。这是因为Twitter的速率限制和时间限制；使用twitter的API，你不能挖掘超过7天的推文，同样，对于一个单一的搜索查询，twitter只给出100个当前周的结果。我得说这对我没多大帮助。</em></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kx"><img src="../Images/409c5aef017c9bc8e32b821458a662ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*V5UK6NIBA2uB9grMFPzD5A.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">谢谢计算器，但答案是<strong class="bd ky">没什么帮助。</strong> :-)</figcaption></figure><p id="aab1" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">所以我进入了默认的研究模式。我有一个问题需要解决，那就是以编程方式获取旧的tweets，然后我发现GetOldTweets-python工具最初是由python版本2.x中的<a class="ae ko" href="https://github.com/Jefferson-Henrique/GetOldTweets-python" rel="noopener ugc nofollow" target="_blank"><strong class="jl hj">Jefferson Henrique</strong></a>开发的，后来由Python版本3.x中的<a class="ae ko" href="https://github.com/Mottl/GetOldTweets3" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hj"> Dmitri Mottl </strong> </a>进行了修改。有意思！对我的任务很有帮助。</p><p id="3a6a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">该算法通过浏览器非常快速地查询twitter搜索，寻找您在命令中指定的搜索关键字、用户名或标签，直到您的搜索持续时间结束。基本上，当你进入Twitter时，一个滚动加载器开始启动，如果你向下滚动，你会得到越来越多的tweets，所有这些都是通过调用JSON提供者实现的。它可以搜索最深刻和最古老的推文。</p><p id="c326" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在我研究的那个阶段，我已经找到了我正在寻找的东西。本质上，在软件开发和工程中，你不会试图重新发明轮子。所以我欣然接受了它，但是发现很难为我自己的用例编写一个工作实现。我没有得到我想要的结果。另外，我发现很多人都和我一样，或者有一天也会和我一样，所以为什么不为开源做点贡献，让事情变得更容易，即使是那些没有很强的python/编程背景的人。</p><p id="bc9a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这导致了我自己的改进分叉，这是本文的关键。</p><p id="8159" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">所以我们才刚刚开始。</p><p id="1e9f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">TL；速度三角形定位法(dead reckoning)</p></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kx"><img src="../Images/cbb7281abebe6c4338c3a598da030693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*weenkO-G405x_MjszXUj1Q.png"/></div></figure><blockquote class="kz la lb"><p id="9c1b" class="jj jk kw jl b jm jn ij jo jp jq im jr lc jt ju jv ld jx jy jz le kb kc kd ke hb bi translated">代码的这一改进分支确保了下载数百万条可用于分析的回溯/旧推文变得相对更容易，在Windows、Ubuntu或Mac OS驱动的机器上以及从命令行都没有压力。基本上是一行命令。只需遵循我之前在Github  上列举的简单步骤，但为了实用起见，这里只展示这些步骤。</p></blockquote><p id="9b5d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">要求。</strong></p><p id="a7e6" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">第一个先决条件是在您的本地机器上安装任何python3.x版本，并且您应该已经设置了环境变量path，这样您就可以从命令提示符或终端交互地启动python，而不会出现任何错误。在Windows上，最简单的方法是再次运行python安装程序，并勾选高级选项下的“将Python添加到环境变量”复选框。<a class="ae ko" href="https://stackoverflow.com/posts/54934172/edit" rel="noopener ugc nofollow" target="_blank">stack overflow</a>上的这个回答更清楚地说明了这一点。在终端上，如果你使用的是Ubuntu发行版(我认为它在喜欢Linux操作系统的程序员中更受欢迎)，只需在你的终端上运行<code class="du lf lg lh li b">sudo apt-get install python3.6</code>，你应该能够在安装后通过输入“python”从终端启动python3。</p><p id="8e67" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">之后，下一个主要需求是安装pyQuery和Lxml来处理请求和xml/html文档类型。这可以很容易地通过运行终端或命令提示符来完成；<code class="du lf lg lh li b">pip install pyquery</code>和<code class="du lf lg lh li b">pip install lxml</code></p></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="feee" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在，一旦您完成了所有这些先决条件，请前往我的<a class="ae ko" href="https://github.com/marquisvictor/Modified-GetOldTweets3/blob/master/README.md" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hj"> Github这里</strong> </a>，派生和/或克隆Mottl的python3版本的改进派生，这也是Jefferson Henrique编写的原始包的改进派生。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lj"><img src="../Images/92b9dc21f93fc82a50b7ae1b5ecf8bde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*BQhEUTf2bSjvyy40KWGFcQ.gif"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">请给我来点尼日利亚Jollof和火鸡:-)</figcaption></figure><p id="5b10" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">有一个自述文件，其中包含了我的repo的实现和一些基本的例子，但我会给出一个简短的关于下载旧的/回溯的twitter数据的实践教程。</p><p id="c6b8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在，一旦您将回购克隆或下载到您的本地机器上，您就可以通过以下步骤开始下载您的旧/回溯twitter数据，用于任何类型的分析:</p><ol class=""><li id="28a2" class="lk ll hi jl b jm jn jp jq js lm jw ln ka lo ke lp lq lr ls bi translated">将repo克隆或下载到您的本地计算机上。</li><li id="e1c9" class="lk ll hi jl b jm lt jp lu js lv jw lw ka lx ke lp lq lr ls bi translated">拉开拉链。</li><li id="ce69" class="lk ll hi jl b jm lt jp lu js lv jw lw ka lx ke lp lq lr ls bi translated">导航到解压缩后的优化-修改-GetOldTweets3-OMGOT-master文件夹</li><li id="ac7b" class="lk ll hi jl b jm lt jp lu js lv jw lw ka lx ke lp lq lr ls bi translated">cd到解压缩后的Optimized-Modified-getoldtweets 3-om got-master文件夹中的getoldtweets 3–0 . 0 . 10文件夹，并在那里启动命令提示符或终端。</li><li id="b871" class="lk ll hi jl b jm lt jp lu js lv jw lw ka lx ke lp lq lr ls bi translated">好了，现在可以开始摆弄数据集了。</li></ol><p id="aa6c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">运行GitHub readme中的命令，开始下载您的twitter数据，这些数据将作为output.csv文件保存在您的计算机上。但是您可以通过传递一个“名称”来指定一个名称来保存您下载的数据集。“—输出”参数的csv。例如:<code class="du lf lg lh li b">--output dataset.csv</code>将下载的文件在你的工作目录下保存为dataset.csv。</p><p id="f530" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在，用更多的例子来弄脏我们的手。假设我们需要下载特定用户的推文。</p><p id="0274" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们只需执行上述步骤1–4，并输入从Github repo中摘录的以下命令</p><pre class="iy iz ja jb fd ly li lz ma aw mb bi"><span id="dc35" class="mc md hi li b fi me mf l mg mh">python GetOldTweets3.py --username "mo4president"  --maxtweets 50 --output dataset.csv</span></pre><p id="45ca" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">上面的命令将查询twitter的搜索引擎并下载@mo4president发出的所有推文，您还可以使用<code class="du lf lg lh li b">--maxtweets </code>参数指定您需要的推文数量，使用<code class="du lf lg lh li b">--output</code>参数指定输出名称。省略掉<code class="du lf lg lh li b">--maxtweets</code>这个参数，基本上用户下载了所有的推文。但是在这里我们指定了50，这意味着我们只能得到50行tweet信息。</p><p id="9236" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">此外，如果您需要下载从2014年至今的某个地理位置的特定关键字的推文，例如“<strong class="jl hj"> rent </strong>”，这是大约5年的旧推文，您可以在执行上述步骤1-4后使用这个命令，该命令也是从我的github repo中挑选出来的。</p><pre class="iy iz ja jb fd ly li lz ma aw mb bi"><span id="73dc" class="mc md hi li b fi me mf l mg mh">python GetOldTweets3.py --querysearch "rent" --near "6.52, 3.37" --within 40km --maxtweets 350 --output rent.csv --since 2014-01-01 --until 2019-08-31</span></pre><p id="ffaf" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">因此，上面的这个命令将为我们获取从2014年至今，在拉各斯州<em class="kw">(因为这是我们指定的)</em>的纬度和经度坐标的40公里半径范围内，包含单词或标签"<strong class="jl hj"> rent </strong>"的所有推文，并将结果存储在rent.csv文件中，该文件将保存在我们当前的工作目录中。这里的maxtweets参数将返回350条tweets，因为这是指定的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/ba0490f1c6b87cc4cf956404b0e83170.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*XUWCT46w4AnovrqGPIfs7Q.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">本质上是开始下载推文的一行命令</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kx"><img src="../Images/02111a85eb1a258ade139912402cd022.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*JLZInVS0rldePTBB7uEKeg.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">csv格式的输出</figcaption></figure><p id="268d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">运行同样的流程，我能够收集足够多的关于各种由关键词代表的话语的大数据，并相应地对其进行分析，以了解10年期间与社区弹性和学生化相关的趋势以及其他分析。</p><p id="5755" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如上所示，在下载了原始非结构化状态的twitter大数据后，您将需要使用python中的pandas库进行一些数据帧操作，以删除一些列，并可能进行一些基本的探索性数据分析。</p><p id="e771" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">值得注意的是，这个修改后的工具现在会自动清理所有的tweet文本并删除不需要的字符。</p><p id="e5ce" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">然后，您可能希望将推文文本传递到围绕<a class="ae ko" href="https://github.com/cjhutto/vaderSentiment" rel="noopener ugc nofollow" target="_blank"> vader </a>或<a class="ae ko" href="https://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank"> textblob </a>构建的情感分析管道中进行进一步分析，或者使用<a class="ae ko" href="https://pypi.org/project/gensim/" rel="noopener ugc nofollow" target="_blank"> Gensim的python库</a>和潜在的Dirichlet分配模型进行文档-主题-单词建模。但所有这些不同的分析都取决于你作为数据科学家或研究人员的熟练程度和项目方向。</p><p id="0902" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在接下来的几篇文章中，我将会看到几乎所有可以用tweet文本进行的分析，以获得更好的见解，以及如何处理数据集中的噪声。但是现在，我希望这篇文章对收集您的twitter“大”数据有所帮助。</p><p id="2097" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">代码贡献者:</p><p id="b361" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><a class="ae ko" href="https://www.linkedin.com/in/victor-e-irekponor/" rel="noopener ugc nofollow" target="_blank"><strong class="jl hj">Irekponor</strong></a><strong class="jl hj"/><a class="ae ko" href="https://github.com/marquisvictor" rel="noopener ugc nofollow" target="_blank"><strong class="jl hj">Victor</strong></a>，尼日利亚拉各斯大学。</p><p id="6b02" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><a class="ae ko" href="https://www.linkedin.com/in/aminu-israel-248ab3177/?originalSubdomain=ng" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hj">阿米努</strong> </a> <strong class="jl hj"> </strong> <a class="ae ko" href="https://github.com/AminuIsrael" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hj">以色列</strong> </a>，尼日利亚拉各斯州立大学。</p><p id="e0f9" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><a class="ae ko" href="https://www.linkedin.com/in/olahfemi/?originalSubdomain=ng" rel="noopener ugc nofollow" target="_blank"><strong class="jl hj">Olah</strong></a><strong class="jl hj"/><a class="ae ko" href="https://github.com/olahfemi" rel="noopener ugc nofollow" target="_blank"><strong class="jl hj">Femi</strong></a>，尼日利亚拉各斯大学。</p><h1 id="3d09" class="mi md hi bd ky mj mk ml mm mn mo mp mq io mr ip ms ir mt is mu iu mv iv mw mx bi translated">更新<strong class="ak">:</strong>13–10–2020。</h1><p id="56fa" class="pw-post-body-paragraph jj jk hi jl b jm my ij jo jp mz im jr js na ju jv jw nb jy jz ka nc kc kd ke hb bi translated">该工具(optimizedGetOldTweets)目前已损坏，因为twitter将其API端点从1.1版升级到1.2版，因此，该工具中使用的一些端点已被弃用<a class="ae ko" href="https://blog.twitter.com/developer/en_us/topics/tips/2020/understanding-the-new-tweet-payload.html" rel="noopener ugc nofollow" target="_blank">以下是关于其新API </a>的更多详细信息。事情进展得很快，我已经能够解决这个问题了。但是现在，如果你在这里，<a class="ae ko" href="https://github.com/marquisvictor/Optimized-Modified-GetOldTweets3-OMGOT/blob/master/README.md#update-12-10-20" rel="noopener ugc nofollow" target="_blank">看看我在Github自述文件中添加的这个</a>。</p><p id="bb5c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我相信这对你的twitter数据挖掘冒险有很大的帮助。😊。</p></div></div>    
</body>
</html>