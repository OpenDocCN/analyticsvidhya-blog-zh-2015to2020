# 基于深度学习和 AWS 的人脸表情分类

> 原文：<https://medium.com/analytics-vidhya/facial-expression-classification-using-deep-learning-aws-57621b41ad86?source=collection_archive---------6----------------------->

## AWS 中的全栈和深度学习

![](img/e06bfac20f219092783b34b11bf9693f.png)

摄影爱好在 [Unsplash](https://unsplash.com/s/photos/ai?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上

# **简介**

在这个项目中，我训练了一个算法来对面部表情进行分类。使用的算法是 AWS SageMaker 图像分类算法，这是一种监督学习算法。它将图像作为输入，并输出分配给该图像的一个或多个标签。它使用卷积神经网络(具有 ResNet 架构)，可以从头开始训练或使用迁移学习来训练。在通过训练创建模型之后，我通过创建一个 REST API 使它在外部可用。

这个项目是在完成由 AICamp 代表的为期 4 周的 8 节课课程“AWS 中的深度学习和全栈”后进行的学习和实践。

S3，SageMaker，Lambda，API Gateway 是 AWS 在这个项目中使用的工具。通过以下链接了解更多信息:

 [## 图像分类算法

### 亚马逊 SageMaker 图像分类算法是一种监督学习算法，支持多标签…

docs.aws.amazon.com](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html) [](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html) [## 亚马逊 SageMaker 是什么？

### 亚马逊 SageMaker 是一个完全托管的机器学习服务。有了 SageMaker，数据科学家和开发人员可以…

docs.aws.amazon.com](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html) 

# **项目任务和数据集**

所用的数据集来自 Kaggle，由 Pierre-Luc Carrier 和亚伦·库维尔准备。以下是链接:

[](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data) [## 表征学习的挑战:面部表情识别挑战

### 从图像中学习面部表情

www.kaggle.com](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data) 

我下载了“train.csv”文件，并将其用作我的数据集，其中约 20%用于验证，约 80%用于训练(随机)。来自链接的解释:

该数据由 48x48 像素的面部灰度图像组成。

面部已经被自动注册，使得面部居中并且在每个图像中占据大约相同的空间。

“train.csv”文件包含两列，“情感”和“像素”。

“情感”栏包含范围从 0 到 6(包括 0 和 6)的数字代码，用于表示图像中存在的情感。

“像素”列包含每个图像的引号中的字符串。该字符串的内容是以行主顺序分隔的像素值。

任务是根据面部表情将情绪分为七类(0 =愤怒，1 =厌恶，2 =恐惧，3 =快乐，4 =悲伤，5 =惊讶，6 =中性)。数据集的分布是:

愤怒:3995，厌恶:436，恐惧:4097，开心:7215，难过:4965

惊喜:4830，中立:3171

# **数据准备**

首先让我们看看使用 Pandas(用于数据分析的 python 库)的数据集:

![](img/61f23df4ca78a8d103ed003ab21d0035.png)

您可以观察图中 dataFrame 变量的类型和形状。使用 iterrows()以(Index，Series)对的形式迭代 dataFrame 行。让我们获取第一行的数据:

![](img/1966442f48bf7785270a9ae3158774bf.png)

使用 read_csv()函数，您可以将 csv 文件中的表格数据导入 pandas DataFrame。

我使用迁移学习进行训练，因此在配置 AWS 图像分类算法的超参数时，我将选项“使用预训练模型”的值设置为 1。在这种迁移学习方法中，用权重初始化网络(在这种情况下，在 ImageNet 上训练)，稍后可以针对不同数据集中的图像分类任务对其进行微调。

ImageNet 是一个大型数据集，包含超过 1100 万张图像，大约有 11，000 个类别。一旦用 ImageNet 数据训练了一个网络，通过简单的重新调整或微调，就可以用它来概括其他数据集。

预训练模型仅接受 3×224×224 图像作为输入(通道数=3，宽度=高度=224)，或者换句话说，RGB 224x224 图像。我把图像转换成三通道灰度图像。

在我的文件系统里，我创建了 l 一个名为“FacialExpressions”的文件夹，里面有七个子文件夹，分别名为“愤怒”、“厌恶”、“恐惧”、“快乐”、“悲伤”、“惊喜”和“中性”。

[我从 **PIL(Python 图像库)导入了**图像**模块。你可以点击这里**。](https://pillow.readthedocs.io/en/stable/reference/Image.html)我遍历 dataFrame 变量的每一行，将每个像素串转换成 48x48 的灰度图像，然后保存到它的 category 子文件夹中。代码起初看起来可能很难，但事实并非如此。

![](img/f906affef0309a4f31b632f28222aa3d.png)

现在，我们的数据集是 48x48 灰度图像，但如前所述，我们应该将它们转换为 3x244x224 图像。我没有直接转换它们，因为这样我就有了它们的原始格式，可以在其他情况下使用它们。

我将新图像保存在文件夹“FacialExpressions _ 224 by 224 _ 3 channel”中，并在我们的七个标签后再次命名七个子文件夹。

![](img/e65ad2f3647c6316d75f40fac38ff3c3.png)

在第二个 for 循环中，img 变量是一个 48 乘 48 的矩阵。之后，我在它的左、右、上、右添加了 88 个零。img_224 是一个 224 乘 224 的矩阵，img 的值在它的中间。然后，我们通过在深度方向(第三轴或维度)上重复 img_224 矩阵来创建 3×224×224 矩阵，使得三个相同的矩阵堆叠在彼此前面。img_224_3 是一个三维数组。然后从 img_224_3 创建一个图像，并将其保存在相应的子文件夹中。最终的图像是一个 RGB 224x224 的图像，但是由于我们创建 img_224_3 的方式，每个像素中的 RGB 值都是相同的，所以颜色不会改变。

# **元数据创建**

AWS SageMaker 使用。lst 文件来查找图像的路径，这样就知道什么标签与每个图像文件相关联。以下是来自 AWS 的解释:

. lst 文件是一个制表符分隔的文件，有三列，包含图像文件列表。第一列指定图像索引，第二列指定图像的类标签索引，第三列指定图像文件的相对路径。第一列中的图像索引在所有图像中必须是唯一的。类别标签索引集是连续编号的，编号应从 0 开始。例如，0 表示猫类，1 表示狗类，其他类以此类推。”

你可以通过这个链接了解更多关于这个话题和 ***输入数据*** :

 [## 图像分类算法

### 亚马逊 SageMaker 图像分类算法是一种监督学习算法，支持多标签…

docs.aws.amazon.com](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html#IC-inputoutput) 

随机选择 20%的数据集进行验证。我们将项目存储到培训和验证列表中。每个列表中的项目顺序是这样的，所有愤怒的图像首先出现，然后是所有厌恶的图像，依此类推，但这样训练准确度图会上下波动，因为算法首先处理所有愤怒的图像并调整其权重，所以准确度上升，但随后到达厌恶的图像，准确度下降，依此类推。为了避免这个问题，在将项目写入 f_train 和 f_validation 之前，我们打乱了 train 和 validation 列表。

我们可以开张了。记事本中的 lst 文件。以下是一些台词:

![](img/be88e789b2d1a50c23483ba74220dad9.png)

确认

![](img/ba22216fd47ebbe1cd55754bbccca246.png)

火车

# **保存到 S3**

我上传了数据集图像。lst 文件到我的 S3 桶中，并为模型创建了一个文件夹，以便在培训作业之外创建时保存。

![](img/b09dba80b011d515fb779725b2a6eeea.png)

s3 铲斗内

![](img/e7270ed8572c30d7aa74f4234767acb2.png)

文件

![](img/e78325d2b4b33ec279c58ee868733b45.png)

文件

自从。lst 文件和图像的其他文件夹在同一个目录中，所以现在我们使用的相对路径是有意义的。在培训作业配置中，我们指定了保存数据集的父文件夹，因此在创建上述两个文件时，我们只是提到了图像相对于这两个文件的相对路径。

# **培训工作和超参数**

在算法中选择了图像分类。对于 GPU 实例，选择了每个实例 40 GB 额外存储的(ml.p2.xlarge)。

在 AWS 文档中了解有关超参数的更多信息。

我设置了下面的超参数，其余的保持不变。

时代:30

image _ shape:3224224

学习率:0.0001

迷你 _ 批量 _ 大小:32

数量 _ 类别:7

层数:101

数量 _ 训练 _ 样本:22739

优化器:sgd(随机梯度下降)

use_pretrained_model: 1(表示真)

由于大规模的数据集，并把纪元 30，我不得不停止培训工作，以避免更多的费用，所以它在第 17 纪元后停止。

关于选择最佳层数，您可以从某个数字开始，然后增加它，直到训练精度不再增加，但无论如何，该数字最好是文档中建议列表中的某个数字。

关于选择最佳 learning_rate，您可以使用 lr_scheduler_factor 和 lr_scheduler_step 超参数来设置多个值，然后检查训练精度图以查看哪一个具有最佳结果，并为最终训练作业选择该值。

如果您不知道 epochs 和 mini_batch_size，请查看以下链接:

[](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/) [## 神经网络中批次和时期的区别-机器学习掌握

### 随机梯度下降是一种具有多个超参数的学习算法。两个超参数…

machinelearningmastery.com](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/) 

除了学习率和 mini_batch_size，SGD 的其他超参数有:

动量(左侧默认为 0.9)，权重 _ 衰减(左侧默认为 0.0001)

**指标**

为此类培训工作提供了 4 个衡量标准:

训练:准确性

验证:准确性

训练:精确度:纪元

验证:准确性:纪元

训练和验证精度分别达到约 0.96 和 0.55:

![](img/e70d686ef5ff888aa3c84baa02cd9b32.png)![](img/20e3a1927eef3c66585bca59801f64d6.png)

在“查看日志”中，您可以检查日志，并可以检查每个时期批次的准确性以及每个时期的“训练准确性”和“验证准确性”。

由于我停止了培训工作，我检查了第 17 个纪元(纪元[16])。“训练准确度”是 0.96，“验证准确度”是 0.55。

由于培训作业已停止，创建模型的选项处于非活动状态，因此我创建了另一个作业。

# **关于精度的一些注意事项**

由于我不得不停止训练工作，验证精度非常低，但我认为如果我们尝试将学习率设置为 0.00001 或将层数设置为 152，我们将获得更好的验证精度。

对于您的实验，将历元数设置为较低的值，如 5，在您计算出最佳超参数后，将其更改为某个固定值，用于您的最终训练工作。

我认为获得低验证准确性的重要原因是我们将单通道灰度图像转换为三通道灰度图像。虽然这可行，但不是最佳的，因为我们将模型外推至一个新的特征空间(ImageNet 不包含灰度图像)。

另一个重要注意事项是，我们通过添加零填充来放大图像，但这会影响性能和优化过程，因为 ImageNet 预训练模型是用 224x224 图像(无填充)训练的。

# **第二次培训工作**

完成以下更改后，我启动了另一项培训工作:

创造另一个。lst 文件寻址 10602 个样本

为输出模型创建新文件夹

将训练集的大小减少到 10602(通过执行第一步，大约是第一个大小的一半)

快乐的尺寸减少到第一个尺寸的 0.66

厌恶的大小没有改变，因为已经很小了

将层数增加到 152 层

将历元的数量减少到 5

历元的索引从 0 开始。我检查了日志，第五历元的训练精度是 0.61。前一个训练任务的第 5 个历元的训练精度是 0.67，**那么第二个任务中的这种降低是由于增加层数还是减少样本数？**

# **第三次培训工作**

这一次我将层数设置为 101，训练样本数设置为 10602，时期数设置为 15。

训练的准确度是 0.96，验证是 0.51。

![](img/8ccd2f47c993c94a16ad1c0c8446a06b.png)![](img/6c7ec88aecbfeca6c9b1c194d94d2071.png)

有了 30 个历元，我认为验证精度至少可以达到 0.60。

第一个作业的第 15 个历元的训练和验证精度为 0.95 和 0.54，因此我得出结论，将训练样本数量减少到 10602 不会对精度产生太大影响，这一事实有助于回答第二个作业后提出的问题。第二份工作的减少很可能是由于增加了层数。

在培训工作信息部分，有一个创建模型选项，在创建模型后，我可以在以下位置访问它:SageMaker->推论->模型

# **创建 SageMaker 端点**

为了访问和使用保存在 s3 的 output-2 文件夹中的模型，我们应该创建一个可以在 AWS 内部访问的 SageMaker 端点。有关创建端点的更多信息，请访问:

 [## 创建端点

### 使用请求中指定的终结点配置创建终结点。Amazon SageMaker 使用端点来…

docs.aws.amazon.com](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpoint.html) 

# **λ**

了解 AWS Lambda，请访问

[](https://aws.amazon.com/lambda/) [## AWS Lambda -无服务器计算-亚马逊网络服务

### 运行代码时不考虑服务器。只为您消耗的计算时间付费。AWS Lambda 让你运行代码…

aws.amazon.com](https://aws.amazon.com/lambda/) 

我们创建了一个 lambda 函数，这是我们编写业务逻辑的地方。我用的语言是 python。当 lambda 接收到 post 请求(人脸图像)时，它将请求发送到端点，由 model 处理，端点将结果作为 7 个概率的数组(列表)发送回来。索引 0 的值用于标签 0，依此类推。在 lambda 中，我们的代码(程序)选择列表中最大值的索引，然后使用字典找出该索引的情感，最后情感被发送到 API 网关，并从那里发送到客户端。

我用关键字‘ENDPOINT _ NAME’和值‘sep EHR-face-expressions-recognition’创建了一个环境变量，这是我的 SagMaker 端点的名称。

![](img/eab106915a60a1274445a61d6792f7db.png)

在上面的代码中，我们获取 base64 格式的图像，对其进行解码，用 bytearray()将其转换为字节数组，然后将其发送到端点以获得响应。

预测将采用大小为 7 的数组(列表)的形式，其中索引 0 处的值是标签 0(“愤怒”)的概率，依此类推。

# **创建测试事件**

我把下面这张愤怒的图像转换成 3x224x224 的图像进行测试。

![](img/cbbffb9677b45464e9e78e09bb8a4937.png)

愤怒的

![](img/8ff816dff76aaf8768c990003b4ade53.png)

像这样，我们可以将其转换为 base64 格式

在“配置测试事件”中，我用 JSON 格式的内容创建了一个测试事件，如{ " body ":"…" }，字符串是 base64 格式的输入图像。

![](img/f5d8c3f2ca5ee2431740ab5823e32a22.png)

反应

但是我们想要一个字符串作为 body 的结果，所以对代码做了如下修改，以找到列表中最大值(概率)的索引，并返回该数字的情感。

![](img/de3256639e88812bfcc76266c3926df2.png)

# **REST API**

为了能够连接到 lambda，我们应该创建一个 API。为此，我们使用 Amazon API 网关服务来创建 REST API。以下是了解更多信息的链接:

[](https://aws.amazon.com/api-gateway/) [## 亚马逊 API 网关| API 管理|亚马逊 Web 服务

### 创建、维护和保护任意规模的 API Amazon API Gateway 是一项完全托管的服务，它使您可以轻松地…

aws.amazon.com](https://aws.amazon.com/api-gateway/) 

AWS 文档中的这张图片有助于更好地理解:

此外，如果您想从总体上了解 word API Gateway，请查看这个有用的视频:

# **用邮递员发送邮件请求**

![](img/fcba8ad8faa7149f58d6325438f6b1b5.png)

以下是我们向 REST API 的 URL 发送 post 请求后的响应:

![](img/d1c0992a4e5d35a915cba62dedff97f5.png)

# **我的想法**

。愤怒和惊讶的脸可能会让算法感到困惑，因为愤怒有时可以表示为眉毛上扬。

。区分悲伤和厌恶可能很棘手。

对中性和悲伤进行分类对于算法来说是非常困难的，因为悲伤的脸可能具有与中性脸相似的特征，并且身体的姿势对于减少这个问题特别有用。

每次培训工作后，检查指标和日志以查看图表以及准确性如何从一个时期变化到另一个时期。

根据我的实验，打乱数据集是非常重要的。由于 SageMaker 使用(。lst)文件来查找图像，在写入文件之前，我通过打乱这些列表来打乱这些行。

我应该提醒一下，数据集中的图像只包含人脸。

人类也考虑其他因素，而不仅仅是面部表情来分类情绪。(天气、新闻、情况、姿势)

在这个项目中，身体的姿势没有被考虑，而这是非常重要的。

如果我们的原始图像是 RGB 224x224，并且我们不需要对它们进行变换，则可以获得更好的结果。

**像这样试验各种超参数会更系统化**:

1.  每个标签 1000 个训练样本(有些标签可能需要更多样本)
2.  每个标签 500 个验证样品
3.  将历元的数量固定在[5，10]的范围内(我更喜欢 6)
4.  现在尝试 50、101 和 152 层的学习率为 0.0001 和 0.00001
5.  在找到合适的学习速率和层数后，使用 30 个或更多的历元以及可能更大的数据集进行最终的训练工作。

# 我的 LinkedIn 网址

[www.linkedin.com/in/sepehr-vafaei-839ab3b0](http://www.linkedin.com/in/sepehr-vafaei-839ab3b0)