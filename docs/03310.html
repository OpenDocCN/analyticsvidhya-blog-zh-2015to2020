<html>
<head>
<title>RandomForestClassifier vs IsolationForest and LocalOutlierFactor for Credit Card Fraud Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RandomForestClassifier与IsolationForest和LocalOutlierFactor用于信用卡欺诈检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/randomforestclassifier-vs-isolationforest-and-localoutlierfactor-for-credit-card-fraud-detection-df43e6140915?source=collection_archive---------11-----------------------#2020-01-25">https://medium.com/analytics-vidhya/randomforestclassifier-vs-isolationforest-and-localoutlierfactor-for-credit-card-fraud-detection-df43e6140915?source=collection_archive---------11-----------------------#2020-01-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="d496" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在本文中，我将讨论如何使用IsolationForest和LocalOutlierFactor以及RandomForestClassifier来预测异常点。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/32ff67a59bac564586b5bd639df0e901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1V-Tyl7G0WEhETfso4zuvA.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片鸣谢:(https://dale-peterson.com)</figcaption></figure><h2 id="a315" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">隔离森林:</h2><p id="9e3e" class="pw-post-body-paragraph kl km hi kn b ko kp ij kq kr ks im kt jy ku kv kw kc kx ky kz kg la lb lc ld hb bi translated">该算法用于异常检测，它将数据集中出现的异常点与正常点隔离开来。它遵循递归分区，使用一种称为隔离树的树结构。</p><p id="d599" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated"><strong class="kn hj">localooutlierfactor:</strong></p><p id="b708" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">该算法也用于异常检测。它基于依赖于k近邻的局部密度，比较对象与其近邻的局部密度，并在此基础上检测离群点。</p><p id="2d6c" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">让我们应用这两种算法来检测欺诈信用卡交易。我将使用kaggle上的信用卡欺诈检测数据集。</p><p id="6c58" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">你可以从kaggle下载creditcard.csv数据集。(<a class="ae lj" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">这里是这个的链接。</a>)</p><p id="922a" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">本文中使用的代码可以在这个<a class="ae lj" href="https://github.com/pratikmishra356/ML-Credit_Card_fraud_detection" rel="noopener ugc nofollow" target="_blank"> github资源库</a>中找到。让我们首先导入必要的包。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="0ff0" class="jn jo hi ll b fi lp lq l lr ls"><strong class="ll hj">import</strong> <strong class="ll hj">numpy</strong> <strong class="ll hj">as</strong> <strong class="ll hj">np</strong><br/><strong class="ll hj">import</strong> <strong class="ll hj">pandas</strong> <strong class="ll hj">as</strong> <strong class="ll hj">pd</strong><br/><strong class="ll hj">import</strong> <strong class="ll hj">matplotlib.pyplot</strong> <strong class="ll hj">as</strong> <strong class="ll hj">plt</strong><br/><strong class="ll hj">import</strong> <strong class="ll hj">seaborn</strong> <strong class="ll hj">as</strong> <strong class="ll hj">sns</strong><br/><strong class="ll hj">from</strong> <strong class="ll hj">imblearn.over_sampling</strong> <strong class="ll hj">import</strong> SMOTE<br/><strong class="ll hj">from</strong> <strong class="ll hj">sklearn.ensemble</strong> <strong class="ll hj">import</strong> IsolationForest<br/><strong class="ll hj">from</strong> <strong class="ll hj">sklearn.neighbors</strong> <strong class="ll hj">import</strong> LocalOutlierFactor<br/><strong class="ll hj">from</strong> <strong class="ll hj">sklearn.ensemble</strong> <strong class="ll hj">import</strong> RandomForestClassifier<br/><strong class="ll hj">from</strong> <strong class="ll hj">sklearn.model_selection</strong> <strong class="ll hj">import</strong> train_test_split<br/><strong class="ll hj">from</strong> <strong class="ll hj">sklearn.metrics</strong> <strong class="ll hj">import</strong> classification_report,accuracy_score</span></pre><h2 id="c64c" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak"> <em class="lt">数据可视化:</em> </strong></h2><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="ccae" class="jn jo hi ll b fi lp lq l lr ls">print(data.shape)<br/>data.head(3)<br/>#this will show (28481, 31).</span></pre><p id="1137" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">它包含一个名为<strong class="kn hj"> Class </strong>的列，显示事务的类型。它基本上有两个等级“0”代表有效，而“1”代表欺诈交易。让我们看看这两个类在这个数据集中的分布。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lu"><img src="../Images/8c88c9d782e519ee51c2dd2339780be2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*_Tp_fYkcL9VTF1LEkG5tuw.png"/></div></figure><p id="f04f" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">如上图所示，欺诈交易的数量远低于有效交易的数量。</p><p id="a1d3" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">让我们定义一个分类器并实现这两个算法</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="16b7" class="jn jo hi ll b fi lp lq l lr ls">classifiers = {<br/>    "IsolationForest":IsolationForest(max_samples=len(X),<br/>                                     contamination = outlier_fraction,random_state=1),<br/>    "Local Outlier Factor":LocalOutlierFactor(<br/>    n_neighbors=20,<br/>    contamination = outlier_fraction)<br/>}</span><span id="0731" class="jn jo hi ll b fi lv lq l lr ls">n_outliers=len(Fraud)<br/><br/><strong class="ll hj">for</strong> i,(model_name,model) <strong class="ll hj">in</strong> enumerate(classifiers.items()):<br/>    <br/>    <strong class="ll hj">if</strong> model_name=="Local Outlier Factor":<br/>        y_pred = model.fit_predict(X)<br/>        scores_pred = model.negative_outlier_factor_<br/>    <strong class="ll hj">else</strong>:<br/>        model.fit(X)<br/>        scores_pred=model.decision_function(X)<br/>        y_pred=model.predict(X)<br/><em class="lw">#0 for valid and 1 for Fraud    </em><br/>    y_pred[y_pred==1]=0<br/>    y_pred[y_pred==-1]=1<br/>    <br/>    n_errors=(y_pred!=Y).sum()<br/>    <br/>    print("<strong class="ll hj">{}</strong>: <strong class="ll hj">{}</strong>".format(model_name,n_errors))<br/>    print(accuracy_score(Y,y_pred))<br/>    print(classification_report(Y,y_pred))</span></pre><p id="46ac" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">看看他们的预测准确度。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="0b58" class="jn jo hi ll b fi lp lq l lr ls">IsolationForest: 71<br/>0.99750711000316<br/>              precision    recall  f1-score   support<br/><br/>           0       1.00      1.00      1.00     28432<br/>           1       0.28      0.29      0.28        49<br/><br/>    accuracy                           1.00     28481<br/>   macro avg       0.64      0.64      0.64     28481<br/>weighted avg       1.00      1.00      1.00     28481<br/><br/>Local Outlier Factor: 97<br/>0.9965942207085425<br/>              precision    recall  f1-score   support<br/><br/>           0       1.00      1.00      1.00     28432<br/>           1       0.02      0.02      0.02        49<br/><br/>    accuracy                           1.00     28481<br/>   macro avg       0.51      0.51      0.51     28481<br/>weighted avg       1.00      1.00      1.00     28481</span></pre><p id="a40a" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">我们可以看到<strong class="kn hj">的精度是0.99 </strong>，但是我们知道，在这种异常检测数据集中，精度并不重要，我们必须考虑精度和召回率。我们可以看到，虽然IsolationForest的性能优于LocalOutlierFactor，但两者对于欺诈交易的精确度和召回率都<strong class="kn hj">非常低</strong>，这表明这两种算法无法将异常点与正常点隔离开来。</p><p id="aaf0" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">正如我们所知，这个数据集是高度不平衡的，它有0.001离群分数。因此，我们将使用SMOTE对此数据执行过采样。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="136c" class="jn jo hi ll b fi lp lq l lr ls">sm = SMOTE(sampling_strategy='minority', random_state=7)<br/>x_imbtrain,x_imbtest,y_imbtrain,y_imbtest = train_test_split(X,Y,test_size=0.2)<br/>oversampled_X, oversampled_Y = sm.fit_sample(x_imbtrain,y_imbtrain)</span></pre><p id="7e38" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">这里的'<strong class="kn hj"> imb' </strong>在名称上表示不平衡的数据，我已经将其分离出来用于进一步的预测。</p><p id="a8d9" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">让我们再次对这个过采样的数据应用IsolationForest和LocalOutlierFactor。这是对这两种算法的预测。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="5729" class="jn jo hi ll b fi lp lq l lr ls">IsolationForest: 22822<br/>0.4982632018643099<br/>              precision    recall  f1-score   support<br/><br/>           0       0.50      1.00      0.67     22743<br/>           1       0.00      0.00      0.00     22743<br/><br/>    accuracy                           0.50     45486<br/>   macro avg       0.25      0.50      0.33     45486<br/>weighted avg       0.25      0.50      0.33     45486<br/><br/>Local Outlier Factor: 22796<br/>0.4988348063140307<br/>              precision    recall  f1-score   support<br/><br/>           0       0.50      1.00      0.67     22743<br/>           1       0.16      0.00      0.00     22743<br/><br/>    accuracy                           0.50     45486<br/>   macro avg       0.33      0.50      0.33     45486<br/>weighted avg       0.33      0.50      0.33     45486</span></pre><p id="24fd" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">我们可以看到，不仅精度和召回率，而且准确性也非常低，这是显而易见的，因为这些算法用于异常检测，并且我们拥有的不平衡数据集包含相同数量的欺诈和有效交易。</p><p id="6f0b" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">现在，我们将对这个过采样平衡数据集应用RandomForestClassifier，并看看它在这个数据集上的表现如何。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="d63c" class="jn jo hi ll b fi lp lq l lr ls">x_train,x_test,y_train,y_test = train_test_split(oversampled_X,oversampled_Y,test_size=0.2)<br/><br/>rf = RandomForestClassifier(n_estimators=100,max_depth=10,random_state=1)<br/>rf.fit(x_train,y_train)<br/>y_predict = rf.predict(x_test)<br/><br/>print(accuracy_score(y_test,y_predict))<br/>print(classification_report(y_test,y_predict))</span><span id="6f6a" class="jn jo hi ll b fi lv lq l lr ls"><br/>#result</span><span id="d93d" class="jn jo hi ll b fi lv lq l lr ls">0.9996702571993845<br/>              precision    recall  f1-score   support<br/><br/>           0       1.00      1.00      1.00      4533<br/>           1       1.00      1.00      1.00      4565<br/><br/>    accuracy                           1.00      9098<br/>   macro avg       1.00      1.00      1.00      9098<br/>weighted avg       1.00      1.00      1.00      9098</span></pre><p id="5e42" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated"><strong class="kn hj">我们可以看到，RandomForestClassifier表现良好，对于两种类型的事务，</strong> <strong class="kn hj">的准确度为0.99，精确度和召回率为1.00。</strong></p><p id="c110" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">乍一看，它似乎过拟合，因此我们在为测试目的(x_imbtest，y_imbtest)而分离的不平衡数据集上进行预测。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="cf7e" class="jn jo hi ll b fi lp lq l lr ls">0.9992978760751272<br/>              precision    recall  f1-score   support<br/><br/>           0       1.00      1.00      1.00      5689<br/>           1       0.83      0.62      0.71         8<br/><br/>    accuracy                           1.00      5697<br/>   macro avg       0.92      0.81      0.86      5697<br/>weighted avg       1.00      1.00      1.00      5697</span></pre><p id="9681" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">我们可以看到，它以0.83的精度和0.62的召回率预测了8个欺诈交易中的7个。</p><blockquote class="lx ly lz"><p id="69fe" class="kl km lw kn b ko le ij kq kr lf im kt ma lg kv kw mb lh ky kz mc li lb lc ld hb bi translated"><strong class="kn hj">结论:</strong></p></blockquote><p id="f40a" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated"><em class="lw">虽然IsolationForest和LocalOutlierForest用于异常检测，但是我们可以通过过采样数据和使用RandomForestClassifier </em> <strong class="kn hj">来检测异常点。</strong></p><p id="3569" class="pw-post-body-paragraph kl km hi kn b ko le ij kq kr lf im kt jy lg kv kw kc lh ky kz kg li lb lc ld hb bi translated">有反馈给我吗？随意评论。可以在<a class="ae lj" href="https://www.linkedin.com/in/pratik-mishra-661005166/" rel="noopener ugc nofollow" target="_blank"> <strong class="kn hj"> LinkedIn联系我。</strong>T13】</a></p></div></div>    
</body>
</html>