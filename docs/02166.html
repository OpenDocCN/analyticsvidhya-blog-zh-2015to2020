<html>
<head>
<title>Big Data File Formats Explained Using Spark Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Spark解释大数据文件格式第1部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/big-data-formats-explained-using-spark-on-azure-gcp-part-1-a83d153c4e66?source=collection_archive---------0-----------------------#2019-12-04">https://medium.com/analytics-vidhya/big-data-formats-explained-using-spark-on-azure-gcp-part-1-a83d153c4e66?source=collection_archive---------0-----------------------#2019-12-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="6c9c" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">了解Avro、拼花地板和ORC的工作原理</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/68e6dcf8108451645e1e76b9ef4f4991.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6izWZ3bi4RRfrQrm5s2r-A.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="jn">图片来源:</em><a class="ae jo" href="https://www.ellicium.com/orc-parquet-avro/" rel="noopener ugc nofollow" target="_blank"><em class="jn">【https://www.ellicium.com/orc-parquet-avro/】</em></a></figcaption></figure><p id="a19b" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">在处理大型数据集时，使用传统的CSV或JSON格式存储数据在查询速度和存储成本方面效率极低。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/e1f9e3c9d0e861e6aebf16fac79f357f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wtSOywZqIE2UDKTJSX7Jow.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图1:显示了一个使用CSV、Parquet和ORC文件格式执行的简单sql查询。ORC大约比Parquet快10倍，比CSV快20倍！</figcaption></figure><p id="5fe1" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">图1展示了使用正确的文件格式来查询数据的强大功能。我们看到ORC格式比使用CSV快了将近20倍！这里使用的数据集是Kaggle的滑行轨迹数据集，大小刚刚超过1GB，包含大约170万条记录(数据集的完整详细信息可以在这里<a class="ae jo" href="https://www.kaggle.com/crailtap/taxi-trajectory" rel="noopener ugc nofollow" target="_blank">获得</a>)。</p><p id="34b9" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">希望这激起了您学习更多关于存储大数据的正确文件格式的兴趣。本文将讨论为存储大数据集而优化的3种主要文件格式，然后在出租车轨迹数据集上演示使用Spark的查询速度。这将在Azure(使用Databricks)和Google云平台(使用Dataproc)上完成，所以你可以在你选择的平台上尝试。</p><h2 id="b729" class="kl km hi bd kn ko kp kq kr ks kt ku kv jy kw kx ky kc kz la lb kg lc ld le lf bi translated"><strong class="ak">大数据格式</strong></h2><p id="1489" class="pw-post-body-paragraph jp jq hi jr b js lg ij ju jv lh im jx jy li ka kb kc lj ke kf kg lk ki kj kk hb bi translated">大数据世界主要有三种为存储大数据而优化的主要文件格式:<strong class="jr hj"> Avro </strong>、<strong class="jr hj"> Parquet </strong>和<strong class="jr hj">优化的</strong> <strong class="jr hj">行列</strong> (ORC)。下面提到的每种格式都有一些相似之处和不同之处。</p><p id="cf09" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><strong class="jr hj"> <em class="ll">相似之处</em> : </strong></p><p id="b906" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">所有这三种格式都以机器可读的二进制格式存储数据，这意味着它只能被机器理解，这与人类可读的CSV和JSON格式不同。</p><p id="4113" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">数据集也可以跨多个磁盘分割，从而实现大规模并行数据处理。这大大提高了处理速度</p><p id="ce33" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">它们是自描述的格式:一个parquet文件的副本可以很容易地转移到另一台机器上，而不会丧失可解释性。</p><p id="6865" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">它们是在线格式:可以轻松地在集群中的节点之间传递数据。</p><p id="bc40" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><strong class="jr hj"> <em class="ll">差异</em> : </strong></p><p id="176a" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">Parquet和ORC以<strong class="jr hj">列格式</strong>存储数据，这意味着数据是为快速检索而优化的。这非常适合读取量大的分析工作负载，即只使用几列进行分析的查询或具有复杂聚合的查询。</p><p id="6be0" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">Avro是一个基于<strong class="jr hj">行的</strong>数据存储，这意味着数据针对“写入密集型”工作负载进行了优化，即需要显示(写入)大部分或所有行数据的查询。</p><p id="6d9f" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">虽然不全面，但在决定哪种格式适合数据集时，有4个主要属性需要考虑:</p><ul class=""><li id="fe2a" class="lm ln hi jr b js jt jv jw jy lo kc lp kg lq kk lr ls lt lu bi translated">行或列存储(R)</li><li id="ab09" class="lm ln hi jr b js lv jv lw jy lx kc ly kg lz kk lr ls lt lu bi translated">压缩(摄氏度)</li><li id="8b21" class="lm ln hi jr b js lv jv lw jy lx kc ly kg lz kk lr ls lt lu bi translated">图式进化</li><li id="6138" class="lm ln hi jr b js lv jv lw jy lx kc ly kg lz kk lr ls lt lu bi translated">可分裂性</li></ul><p id="c492" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">帮助你记住它们的一个助记法是<strong class="jr hj">赛跑。</strong></p><h2 id="a023" class="kl km hi bd kn ko kp kq kr ks kt ku kv jy kw kx ky kc kz la lb kg lc ld le lf bi translated"><strong class="ak">行Vs列商店</strong></h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/669bbf907aa1b25e6d0a26cdeddbe814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*izjfS_xUpIj3qEyUXX7izA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="jn">表1:显示了截至2019年12月1日NBA所有时间点的前五名领先者。数据摘自</em><a class="ae jo" href="https://www.nba.com/" rel="noopener ugc nofollow" target="_blank"><em class="jn"/></a><em class="jn">。</em></figcaption></figure><p id="426b" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">行存储逐行存储数据。以表1中的数据集为例，基于行的存储如下所示:</p><p id="f516" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><em class="ll">卡里姆·阿布杜尔·贾巴尔1560，57446，38387，卡尔·马龙1476，54852，36928，科比1346，48643，33643，勒布朗1217，46895，33031，乔丹1072，41010，32292。</em></p><p id="5246" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">数据从左到右逐行存储。相比之下，基于列的数据存储如下所示:</p><p id="d1ee" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><em class="ll">卡里姆·阿布杜尔·贾巴尔，卡尔·马龙，科比，詹姆斯，乔丹，1560，1476，1346，1217，1072，57446，54852，48643，46895，41010，38387，36928，33643，33031，32292。</em></p><p id="1704" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">数据按从左到右的顺序逐列存储。该序列可以总结为如图2所示。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/9dd8a2c7cfce30a0742b329fae9fe811.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y-jTkztgl6sFlwgf7ozslg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="jn">图2:展示了基于行和基于列的存储格式如何存储数据。在基于行的格式中，数据从左到右逐行存储。列格式按从左到右的顺序逐列存储数据。</em></figcaption></figure><p id="adbd" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我们现在可以开始理解为什么基于列的存储对于分析目的是理想的，在这种情况下，查询往往只针对特定的列，而不是整个数据集，即读取量很大。这种列存储使得像Parquet和ORC这样的格式能够在每一列的末尾存储<strong class="jr hj">元数据</strong>(包含诸如模式、列最小值和最大值、空值等信息)，这对于基于行的存储是不可能的。使用这些信息，可以更快地跳到查询所需的相关列，因为元数据将通知查询相关数据是否出现在该列中。</p><p id="018f" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">例如，假设我们有一个产品表，并想找出哪个产品的收入最高，按产品ID分组。因此，您可能需要查询product表中的特定列(并对其执行聚合)来提取信息。将数据存储在Parquet或ORC中后，将执行<strong class="jr hj">数据跳过</strong>以仅扫描相关列(见图3)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mb"><img src="../Images/b74991719598e24498d249429884885b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W2IKBQ1pn7jBpubGwKnDqA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图3:数据跳过是如何工作的高级演示。</figcaption></figure><p id="6688" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">但是，如果查询需要返回数据集中的所有或大多数行，那么使用基于行的存储会更有效。</p><p id="d702" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">例如，假设您想预订第二天的航班。然后，您将希望看到与当天可用航班相对应的大部分/所有行数据，以及大部分/所有列，因为每列都添加了更多信息，以便您决定您将乘坐哪个确切的航班。在这种情况下，您可能希望使用基于行的格式，如为此优化的Avro。</p><h2 id="18c5" class="kl km hi bd kn ko kp kq kr ks kt ku kv jy kw kx ky kc kz la lb kg lc ld le lf bi translated"><strong class="ak">压缩</strong></h2><p id="481e" class="pw-post-body-paragraph jp jq hi jr b js lg ij ju jv lh im jx jy li ka kb kc lj ke kf kg lk ki kj kk hb bi translated">压缩数据减少了存储、查询和传输数据所需的信息量，从而节省了时间和金钱。</p><p id="7f33" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">以列格式存储的数据可以实现更好的压缩，因为相似类型的数据是相邻存储的。例如，以表1中的数据集为例，所有字符串值数据(来自第1列)都存储在一起，所有整数值数据(来自第2–4列)也存储在一起，因此与基于行的数据存储相比，数据压缩效率更高。这将降低存储成本。</p><h2 id="0efe" class="kl km hi bd kn ko kp kq kr ks kt ku kv jy kw kx ky kc kz la lb kg lc ld le lf bi translated"><strong class="ak">图式进化</strong></h2><p id="cb16" class="pw-post-body-paragraph jp jq hi jr b js lg ij ju jv lh im jx jy li ka kb kc lj ke kf kg lk ki kj kk hb bi translated">数据集上下文中的“架构”是指列标题和类型。随着项目的成熟，可能需要向数据集添加/改变(新的)列，从而改变其模式。讨论的所有3种格式都支持某种程度的模式进化支持，尽管Avro在这方面远远优于其他两种格式。</p><h2 id="8faa" class="kl km hi bd kn ko kp kq kr ks kt ku kv jy kw kx ky kc kz la lb kg lc ld le lf bi translated"><strong class="ak">分裂性</strong></h2><p id="96d1" class="pw-post-body-paragraph jp jq hi jr b js lg ij ju jv lh im jx jy li ka kb kc lj ke kf kg lk ki kj kk hb bi translated">“可分割性”指的是将大数据集分解成更小的独立数据块的容易程度，以便它们可以由集群中运行的多个节点处理。这使得大规模并行处理成为可能，因为一台机器将没有足够的计算能力来处理整个数据集。Avro、Parquet和ORC格式都经过优化，支持可分割性。</p><p id="1e3b" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">现在让我们更详细地研究这三种文件格式。</p><h1 id="7176" class="mc km hi bd kn md me mf kr mg mh mi kv io mj ip ky ir mk is lb iu ml iv le mm bi translated"><strong class="ak"> Avro </strong></h1><p id="660c" class="pw-post-body-paragraph jp jq hi jr b js lg ij ju jv lh im jx jy li ka kb kc lj ke kf kg lk ki kj kk hb bi translated">Avro是由Hadoop的一个团队在2009年开发的，是一种基于行的高度可拆分的存储格式。Avro的显著特点(如Nexla白皮书中所述)是它的模式<em class="ll">‘随数据一起移动’</em>。这是因为数据定义/模式是以人类可读的JSON格式存储的，而数据本身是以二进制格式存储的。这最大限度地提高了压缩和存储效率。此外，由于数据定义是以人类可读的格式存储的，这使得模式演化在修改列类型或添加新列类型方面变得非常容易。</p><h1 id="8a48" class="mc km hi bd kn md me mf kr mg mh mi kv io mj ip ky ir mk is lb iu ml iv le mm bi translated"><strong class="ak">拼花地板</strong></h1><p id="cb29" class="pw-post-body-paragraph jp jq hi jr b js lg ij ju jv lh im jx jy li ka kb kc lj ke kf kg lk ki kj kk hb bi translated">这种格式是由Twitter和Cloudera在2013年开发的，是一种基于分栏的格式。由于数据存储在列中(如前所述),因此很容易压缩。Parquet还在文件末尾存储元数据，其中包含有用的统计信息，如模式信息、列的最小值和最大值、压缩/编码方案等。这允许跳过数据，并允许在多台机器上分割数据。</p><h1 id="1efc" class="mc km hi bd kn md me mf kr mg mh mi kv io mj ip ky ir mk is lb iu ml iv le mm bi translated"><strong class="ak">优化的行列(ORC) </strong></h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/41f9f8c9c2f4ec7cead982e23271d8b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nqt-769cAHUogkKQkszlNw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="jn">图4:显示了如何使用“条带”将数据分组，然后在ORC中以列格式存储。条带页脚包含每个条带中用于数据跳过的列的元数据。来源:</em> <a class="ae jo" href="https://www.nexla.com/resource/introduction-big-data-formats-understanding-avro-parquet-orc/" rel="noopener ugc nofollow" target="_blank"> <em class="jn"> Nexla白皮书</em> </a></figcaption></figure><p id="a729" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">ORC由Hortonworks于2016年开发，以列格式存储行数据，这对压缩和存储来说效率极高。这种压缩是通过ORC的“索引”系统实现的，该系统将数据存储在大约10，000行的“<strong class="jr hj">条带</strong>中。每个条带将索引(列标题)、行数据和条带页脚(包含列统计信息、模式信息等)分组到不同的列中，如图4所示。这使得当查询跳转到相关条带进行分析时，数据跳转成为可能。条带也相互独立，这允许数据拆分，因为一个条带可以传输到另一个节点上，而不会损失可解释性。</p><p id="cbd3" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">图4总结了选择数据格式时需要考虑的四个主要属性，以及它们在Avro、Parquet和ORC中的适用性。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mo"><img src="../Images/525fded5adc177bc93a6f7b499cc5b7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_4bV1SP5Al6EYaAe-HuteQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><em class="jn">图5:总结了所讨论的大数据格式的4个核心属性，以及它们对不同平台的兼容性。来源:</em> <a class="ae jo" href="https://www.nexla.com/resource/introduction-big-data-formats-understanding-avro-parquet-orc/" rel="noopener ugc nofollow" target="_blank"> <em class="jn"> Nexla白皮书</em> </a> <em class="jn">。</em></figcaption></figure><p id="264f" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">点击<a class="ae jo" rel="noopener" href="/@aqeelahamed17/big-data-formats-explained-using-spark-on-azure-gcp-part-2-b93bf59118e7">此处</a>查看本文的<a class="ae jo" rel="noopener" href="/@aqeelahamed17/big-data-formats-explained-using-spark-on-azure-gcp-part-2-b93bf59118e7">第2部分</a>，该部分展示了在Azure &amp; GCP上使用这些高效的文件格式实现的查询速度。</p><h1 id="65cd" class="mc km hi bd kn md me mf kr mg mh mi kv io mj ip ky ir mk is lb iu ml iv le mm bi translated"><strong class="ak">参考文献</strong></h1><p id="da33" class="pw-post-body-paragraph jp jq hi jr b js lg ij ju jv lh im jx jy li ka kb kc lj ke kf kg lk ki kj kk hb bi translated">Nexla白皮书:<a class="ae jo" href="https://www.nexla.com/resource/introduction-big-data-formats-understanding-avro-parquet-orc/" rel="noopener ugc nofollow" target="_blank">大数据格式介绍</a>。</p><p id="966a" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">Datanami: <a class="ae jo" href="https://www.datanami.com/2018/05/16/big-data-file-formats-demystified/" rel="noopener ugc nofollow" target="_blank">大数据文件格式揭秘</a>。</p></div></div>    
</body>
</html>