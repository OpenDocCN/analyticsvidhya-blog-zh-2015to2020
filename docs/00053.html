<html>
<head>
<title>Neural Arithmetic Logic Units (NALU) — A new beginning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经算术逻辑单元(NALU)——一个新的开始？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/neural-arithmetic-logic-units-nalu-a-new-beginning-9b9b8a69eb32?source=collection_archive---------0-----------------------#2018-08-17">https://medium.com/analytics-vidhya/neural-arithmetic-logic-units-nalu-a-new-beginning-9b9b8a69eb32?source=collection_archive---------0-----------------------#2018-08-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9928" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我很小的时候，我的分数最多只能算一般。很多人过去比我得分高，特别是在需要段落/文章类型答案的考试中。</p><p id="5dd6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">为什么？</em></p><p id="be15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为，我以前都是先理解底层概念，然后自己去解释。由于英语不是我的第一语言，我只能勉强解释我想说的，因此最多只能得到一般的分数。假设这是A型学习。</p><p id="d6a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一方面，我班上有些学生习惯于学习老师在课堂上提供的答案，而不一定理解它们。假设这是B型学习。</p><p id="8337" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">值得庆幸的是，我没有屈服于以理解主题为代价获得更高分数的冲动。因为，当考试中出现看不见的问题时——我可以回答，而其他大多数人却不能</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="1d0e" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">这和<strong class="ak">神经网络</strong>有什么关系？</h1><p id="5853" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">嗯，目前训练神经网络的方法与上面提到的b型学习非常相似。他们需要大量的数据来学习和工作，只有当他们看到相同的东西。</p><p id="03e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个训练范围之外，他们不能很好地概括。</p><p id="84bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">安德鲁·特拉斯克(来自Deepmind) <em class="jd">等人</em>最近表明<a class="ae ko" href="https://arxiv.org/abs/1808.00508v1" rel="noopener ugc nofollow" target="_blank">神经网络甚至不能在它们的训练集之外学习标量恒等函数</a>。</p><p id="6fe3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们引入了两个新模型，神经累加器(NAC)和神经算术逻辑单元(NALU)。这两个模型的早期结果在附加到CNN和LSTMs时显示出更好的结果，即更多的A型学习。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="2b1e" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">什么是神经累加器(NAC)？</h1><p id="643b" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">简而言之，NAC是其输入的线性变换，其保持输入和输出向量的缩放一致。</p><p id="6816" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">NAC是线性(仿射)层的特例，其变换矩阵W仅由1、0和1组成；也就是说，它的输出是输入行的加法或减法。</p><p id="7b61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这可以防止图层在将输入映射到输出时更改数字表示的比例，这意味着无论有多少操作链接在一起，它们在整个模型中都是一致的</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es kp"><img src="../Images/1bc0a9fc1ef942b6cf4ebb09d6da6e17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*toQUKJdbT5ZYSZlyTyOxow.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">神经累加器(NAC)</figcaption></figure></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="2d5a" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">NALU模特怎么样？它们是如何工作的？</h1><p id="eabb" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">为了鼓励更系统的数值外推，作者提出了一种将数值表示为线性激活的体系结构，该线性激活使用原始算术运算符进行操作，由学习门控制。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lf"><img src="../Images/b7f9c02b4a440cc6a03a2146af3e499f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*enYojyC0tBLv9BIJWkYVRg.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">神经算术逻辑单元(NALU)</figcaption></figure><p id="af87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作者进一步称这个模块为神经算术逻辑单元(NALU)，类似于传统处理器中的算术逻辑单元(还记得ALU单元吗！).</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="4fcd" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">早期结果</h1><p id="f55d" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">论文中的实验进一步表明，NALU增强的神经网络可以学习跟踪时间，对数字图像执行算术，将数字语言翻译成实值标量，执行计算机代码，并对图像中的对象进行计数。</p><p id="b653" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与传统架构相比，作者在训练期间遇到的数值范围内外都获得了实质上更好的概括，通常外推超出训练的数值范围的数量级。</p><p id="bf2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更多细节可以在<a class="ae ko" href="https://arxiv.org/pdf/1808.00508v1.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1808.00508v1.pdf</a>的论文中找到</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="6af6" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">我的看法</h1><p id="e33a" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">这看起来是一个有趣的发展，可能会产生巨大的影响。几年后，当我们回顾当前训练神经网络的方法时，可能会觉得它们在本质上是非常初级的。</p><p id="acd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">至于NALU，只有时间和更详细的测试才能告诉我们他们是否真的属于A型学习——只有时间会告诉我们。</p><p id="f991" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望在接下来的几个月里看到更多这方面的行动。</p><p id="a34d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考:【https://arxiv.org/pdf/1808.00508v1.pdf T2】</p></div></div>    
</body>
</html>