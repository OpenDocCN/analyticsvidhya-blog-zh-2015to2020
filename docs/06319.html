<html>
<head>
<title>Reinforcement Learning: Temporal Difference Learning — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习:时间差异学习—第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/reinforcement-learning-temporal-difference-learning-part-1-339fef103850?source=collection_archive---------5-----------------------#2020-05-18">https://medium.com/analytics-vidhya/reinforcement-learning-temporal-difference-learning-part-1-339fef103850?source=collection_archive---------5-----------------------#2020-05-18</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><figure class="ev ex im in io ip er es paragraph-image"><div class="er es il"><img src="../Images/ce7c328f6f3a222c6dd88e528f65fc07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*YQlWynFiiYLDY4Cps7tLPA.jpeg"/></div></figure><p id="f73b" class="pw-post-body-paragraph is it ho iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hh bi translated">自从上一篇文章以来，我们越来越多地从理论走向实践。蒙特卡罗方法的<a class="ae jq" rel="noopener" href="/analytics-vidhya/monte-carlo-methods-in-reinforcement-learning-part-2-off-policy-methods-b9766d3e60d7?source=friends_link&amp;sk=80f053a8ab7f6d7a0fa47760c95f52c5">后两篇用于解决强化学习中的<strong class="iu hp">预测问题</strong>和<strong class="iu hp">控制问题</strong>。</a></p><p id="cd63" class="pw-post-body-paragraph is it ho iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hh bi translated">继蒙特卡罗方法之后，在本文中，我们将研究另一种叫做<strong class="iu hp">时间差异(TD)学习的方法。</strong></p></div></div>    
</body>
</html>