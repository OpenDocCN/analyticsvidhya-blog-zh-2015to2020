<html>
<head>
<title>A Beginners Guide to Unsupervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督学习初学者指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/beginners-guide-to-unsupervised-learning-76a575c4e942?source=collection_archive---------0-----------------------#2019-08-06">https://medium.com/analytics-vidhya/beginners-guide-to-unsupervised-learning-76a575c4e942?source=collection_archive---------0-----------------------#2019-08-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/41528dd51695373ce888422a7ae76ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*Iihw0V-r0raMMtcDTFGGQA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">PC: Quora</figcaption></figure><p id="f3e1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每当有人谈论机器学习时，他们总是会首先提到:监督学习、<strong class="is hj">非监督训练、</strong>强化训练是主要的大类。</p><p id="224b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是这种被称为无监督的技术背后真正的原因是什么呢？来，让我们用一些例子来看看。</p><p id="a776" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大多数时候，我们建立模型来预测或预报一些事情。这种特殊类型的技术是众所周知的监督训练。在这种情况下，我们知道数据中的标签和模式。</p><p id="d19b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是<em class="jo">无监督学习</em>与此有点不同，我们训练我们的模型<strong class="is hj">在数据中找到隐藏的模式，以基于学习标记未来看不见的项目。</strong>我们这样做</p><ol class=""><li id="d8d4" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">没有特定的预测任务，</li><li id="7af0" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">有时对大数据进行降维</li></ol><p id="1229" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我用一个“鱼测量”数据集给你演示一个例子。该数据集包括:</p><ul class=""><li id="4d72" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn kd jv jw jx bi translated">鱼的种类</li><li id="cf10" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">鱼的重量</li><li id="0f86" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">长度1(鱼从鼻子到尾巴起点的长度，以厘米为单位)</li><li id="ba04" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">长度2(鱼从鼻子到尾巴切口的长度，单位为厘米)</li><li id="3c6c" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">长度3(鱼从鼻子到尾巴末端的长度，以厘米为单位)</li><li id="93a1" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">鱼的最大高度，以厘米为单位</li><li id="7e1e" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">宽度鱼的最大宽度，以厘米为单位</li></ul><p id="c008" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里的任务是将鱼分成正确的种类。但不幸的是，我们不知道这些特征是如何相互关联的，所以给这些鱼贴上正确的物种类型标签是一项艰巨的任务。那么我们能做什么呢？</p><p id="8230" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这就是无监督学习派上用场的地方。有许多预定义的算法，如K-means聚类、层次聚类、DBSCAN，我们也可以根据需要使用神经网络构建自己的聚类模型。在本文中，我不打算解释那些算法，为了简单起见，我们将在我们的示例中使用<a class="ae ke" href="https://www.youtube.com/watch?v=f4jvifS41M4" rel="noopener ugc nofollow" target="_blank"><strong class="is hj">K-Means</strong></a><strong class="is hj"/>聚类。</p><h2 id="f32c" class="kf kg hi bd kh ki kj kk kl km kn ko kp jb kq kr ks jf kt ku kv jj kw kx ky kz bi translated">识别数据中可能的聚类数</h2><p id="06b9" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">在我们需要训练我们的模型之前，我们应该知道我们要标记多少不同类型的物种(集群)。那么怎么才能搞清楚呢？一种方法是我们可以简单地从用例中得到一个想法。例如，如果我们要根据一些属性对苹果和桔子进行分类，我们知道分类数是2。同样，我们可以从利益相关者那里得到一些想法。但理想的方法是使用<strong class="is hj">惯性。</strong>惯性是每个聚类的误差平方和。因此，惯性越小，集群越密集</p><p id="2a66" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们用不同的聚类数对数据进行聚类，并绘制聚类数与惯量的关系图。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="fbb1" class="kf kg hi lk b fi lo lp l lq lr">ks = range(1, 6)<br/>inertias = []</span><span id="8d1c" class="kf kg hi lk b fi ls lp l lq lr">for k in ks:<br/>    # Create a KMeans instance with k clusters: model<br/>    model = KMeans(n_clusters = k)</span><span id="701a" class="kf kg hi lk b fi ls lp l lq lr"># Fit model to samples<br/>    model.fit(samples)</span><span id="0b20" class="kf kg hi lk b fi ls lp l lq lr"># Append the inertia to the list of inertias<br/>    inertias.append(model.inertia_)</span><span id="1ad3" class="kf kg hi lk b fi ls lp l lq lr"># Plot ks vs inertias<br/>plt.plot(ks, inertias, '-o')<br/>plt.xlabel('number of clusters, k')<br/>plt.ylabel('inertia')<br/>plt.xticks(ks)<br/>plt.show()</span></pre><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/f7e76adae3184241809bbaf93b621ea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*FdQZSG50vUqiCoWEEZlP1A.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">惯性图</figcaption></figure><p id="8842" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们所见，随着集群数量的增加，惯性变得越来越低。那么最佳的集群数量是多少呢？</p><ul class=""><li id="c095" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn kd jv jw jx bi translated">一个好的集群应该有紧密的集群</li><li id="a483" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">但是不能有太多的集群</li><li id="df87" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">一个简单的经验法则是找到图形的拐点</li></ul><p id="02b7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，在我们的鱼类聚类案例中，有4个聚类，其中惯性的递减斜率较低。</p><h2 id="5c63" class="kf kg hi bd kh ki kj kk kl km kn ko kp jb kq kr ks jf kt ku kv jj kw kx ky kz bi translated">检查群集的质量</h2><p id="9d3b" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">既然我们知道了集群的数量，让我们建立一个模型并可视化结果。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="c022" class="kf kg hi lk b fi lo lp l lq lr">model = KMeans(n_clusters = 4)<br/>model.fit(samples)</span><span id="56d6" class="kf kg hi lk b fi ls lp l lq lr">labels = model.predict(samples)</span><span id="8d3f" class="kf kg hi lk b fi ls lp l lq lr">#lets see how the species are clustered based on the weight and height<br/>xs = samples.iloc[:,0] #weight column<br/>ys = samples.iloc[:,4] #height column</span><span id="fcd0" class="kf kg hi lk b fi ls lp l lq lr">plt.scatter(xs, ys, c = labels, alpha = 0.5)<br/>centroids = model.cluster_centers_<br/>centroids_x = centroids[:,0]<br/>centroids_y = centroids[:,4]</span><span id="1766" class="kf kg hi lk b fi ls lp l lq lr">plt.scatter(centroids_x, centroids_y, marker = 'D', s = 50)<br/>plt.show()</span></pre><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/624f9af3dc3932cc2a68474cf36476c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*eBT-d8BZVTIhMaH_FfIudg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">模型-1</figcaption></figure><p id="cc14" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">视觉上，它似乎完美地聚集在一起。菱形标记是每个聚类的中心点(平均值)。但是记住我们的眼睛会欺骗我们！</p><p id="a8cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们仔细检查我们的质量，通过计算物种是如何聚集成每个物种的。一个简单的方法是使用pandas交叉表方法。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="fb48" class="kf kg hi lk b fi lo lp l lq lr">#lets create a dataframe of predicted labels and species actually the were<br/>df = pd.DataFrame({'labels': labels, 'species': species})</span><span id="e973" class="kf kg hi lk b fi ls lp l lq lr">#lets do a crosstab evaluation to verify the quality of our clustering<br/>ct = pd.crosstab(df['labels'], df['species'])<br/>print(ct)</span></pre><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/00923bed27eecf82ed9fd8d391506e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*DPkCmtSmEt8I5Ww7VoYeFA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">标签和种类的交叉表视图</figcaption></figure><p id="dab7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们所看到的，聚类不够完美。一些来自鲷属物种的鱼聚集在标签0、1和2下。此外，其他物种也被错误地聚集成两个或多个不同的群(标签)。</p><p id="067a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那么这里的问题可能是什么呢？是的，你是正确的——我们拥有的特征在不同的度量中被缩放，因此<strong class="is hj">特征之间的均值和方差是不同的，这使得聚类不完美</strong>。那么如何解决这个问题，改进模型呢？</p><h2 id="c730" class="kf kg hi bd kh ki kj kk kl km kn ko kp jb kq kr ks jf kt ku kv jj kw kx ky kz bi translated">特征缩放和标准化</h2><p id="5749" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">这是用于解决上述问题的两种不同的技术。</p><p id="90d9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1 — <strong class="is hj">标准化</strong>是我们将特性的标准偏差和平均值降低到1和0，达到标准刻度的过程。</p><p id="26e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2 —另一方面，<strong class="is hj">归一化</strong>是我们降低0和1之间的所有特征值范围的过程。</p><p id="c98a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的示例中，我们将标准化数据并查看群集质量。Scikit中有许多技术可以用来做这件事。我们将使用<em class="jo">“standard scale</em>模块来实现我们的目标。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="992c" class="kf kg hi lk b fi lo lp l lq lr">scaler = StandardScaler()<br/>kmeans = KMeans(n_clusters= 4)</span><span id="4b34" class="kf kg hi lk b fi ls lp l lq lr">pipeline = Pipeline([('Scaler',scaler), ('KMeans',kmeans)])<br/>pipeline.fit(samples)</span><span id="78e7" class="kf kg hi lk b fi ls lp l lq lr">labels2 = pipeline.predict(samples)</span><span id="6d39" class="kf kg hi lk b fi ls lp l lq lr">df2 = pd.DataFrame({'labels': labels2, 'species': species})</span><span id="2f10" class="kf kg hi lk b fi ls lp l lq lr">ct2 = pd.crosstab(df2['labels'], df2['species'])</span><span id="f2e3" class="kf kg hi lk b fi ls lp l lq lr">print(ct2)</span></pre><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/a338f640836addbcad563a867e9629f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*hTOpe7gsZRylFQqxgRdPRw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">标准化后的交叉表视图</figcaption></figure><p id="7d86" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">万岁，现在的集群看起来比以前的好多了。我们仍然可以通过添加更多数据、调整KMeans的超参数以及使用特征缩放技术来改进这一点。这篇文章里我讲了很多东西。亲自动手尝试所有的概念。</p><p id="a77e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">哎呀，别忘了给<a class="ae ke" href="https://github.com/Mathanraj-Sharma/Python/blob/master/Beginners%20guide%20to%20Unsupervised%20Learning/cluster.ipynb" rel="noopener ugc nofollow" target="_blank"> Github回购</a>打个星。</p></div></div>    
</body>
</html>