<html>
<head>
<title>Detecting Outliers and its Treatment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">异常值的检测及其处理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/detecting-outliers-and-its-treatment-e22fe67819b0?source=collection_archive---------17-----------------------#2020-03-13">https://medium.com/analytics-vidhya/detecting-outliers-and-its-treatment-e22fe67819b0?source=collection_archive---------17-----------------------#2020-03-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ecc3" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">实验和观察</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/b9fa0642b9655a1b7da19ff979ac0097.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VrdKt9z_5cbksaQ3m2DxmQ.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://www.pexels.com/photo/photo-of-herd-of-sheep-on-grassland-3379771/" rel="noopener ugc nofollow" target="_blank">https://www . pexels . com/photo/photo-of-herd-of-of-sheep-on-grade-3379771/</a></figcaption></figure><h1 id="ed3d" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">介绍</h1><p id="df66" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">异常值是总体中不属于该总体的数据点。比如白羊群里的一只黑羊。</p><p id="c744" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">离群值会扭曲您的结果。或者我们可以说，它将数据的行为从被认为是真实的结果转变为不真实的结果。我们称这种偏移为<strong class="ki hj">误差</strong>。</p><p id="a5bc" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">误差是实际结果和预测结果之间的差异。如果存在不需要的数据，来自机器学习模型的预测结果会受到影响。为了确保机器学习模型做出正确的预测，我们必须确保适当地处理异常值。</p><p id="f87e" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">在本文中，我将尝试帮助您建立一种直觉，即如何在处理异常值的同时处理机器学习问题。</p><p id="63cc" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">为了理解这个问题，我将使用一个单变量数据集——它将有一个<strong class="ki hj">自变量</strong>和一个<strong class="ki hj">因变量</strong>。</p><blockquote class="lh li lj"><p id="9f54" class="kg kh lk ki b kj lc ij kl km ld im ko ll le kr ks lm lf kv kw ln lg kz la lb hb bi translated"><strong class="ki hj">注</strong>:代码在我的<a class="ae jn" href="https://github.com/Nielspace/MachineLearningBlogs" rel="noopener ugc nofollow" target="_blank"> <strong class="ki hj"> Github Repo </strong> </a>中有。请随意检查。另外重要的一点是，我并不试图探索ML模型本身，而是设计和构建一个模型<strong class="ki hj">来理解ML模型</strong>中异常值的影响，并观察哪个模型在自变量和因变量之间建立了最佳关系。</p></blockquote><h1 id="d135" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">寻找异常值</h1><p id="6367" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">离群值并不难发现。我们可以使用统计方法来寻找离群值的踪迹或离群值本身。我们将研究的工具是<strong class="ki hj">标准差、四分位间距和箱线图。</strong></p><p id="c4ff" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated"><strong class="ki hj">标准偏差</strong>是对平均值的方差(或数据分布)的测量，该平均值是标度的中心，也表示为“0”。大多数数据位于第一个和第二个标准差之间。除此之外，一切都被认为是离群值。</p><p id="a33e" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">一般来说，我们会尝试删除那些在第二个标准差之上或之外的数据点。</p><blockquote class="lh li lj"><p id="0e8e" class="kg kh lk ki b kj lc ij kl km ld im ko ll le kr ks lm lf kv kw ln lg kz la lb hb bi translated">注意:当我们谈论标准差时，我们同时考虑正负标准差。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lo"><img src="../Images/0b2aca219ff09708de50738d65291e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aos1eT6ocP3sKEln3R28jA.jpeg"/></div></div></figure><p id="93ff" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated"><strong class="ki hj">四分位距</strong> ( <strong class="ki hj"> IQR </strong>)是一种可变性的度量，基于将数据集分成四分位。四分位数将按等级排序的数据集分成四个相等的部分。划分每个部分的值称为第一、第二和第三四分位数；它们分别用Q1、Q2和Q3表示，即25、50和75个百分点。</p><p id="9a3a" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">一旦我们有了这些值，我们就可以设置一个阈值，超过和低于这个阈值就是异常值。</p><p id="7b38" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">下图是一个箱形图。“一个<strong class="ki hj">箱线图</strong>是一种通过四分位数图形化描述数字数据组的方法。箱形图也可能有从箱形图延伸的线(<em class="lk">须状图</em>)，表示上下四分位数之外的可变性，因此有术语<strong class="ki hj">箱形须状图</strong>和<strong class="ki hj">箱形须状图</strong>。离群值可能被标绘为单独的点”——维基百科。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lp"><img src="../Images/06173eb1322b050fb81a4c0cc83b1a89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aKQASMjH13uiKDEwZnjsbA.png"/></div></div></figure><p id="fc7f" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">一旦我们发现异常值，我们就可以相应地对待它们。</p><h1 id="e0af" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">处理异常值</h1><p id="7249" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">有几种方法可以处理异常值。但是在我们采取任何措施来处理异常值之前，我们应该记住某些要点。</p><ol class=""><li id="d5bb" class="lq lr hi ki b kj lc km ld kp ls kt lt kx lu lb lv lw lx ly bi translated">离群值有好有坏。我们面临的问题是主观的。有些问题需要异常值，例如异常检测，而其他问题则不需要，因为它会扭曲数据。</li><li id="62f0" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb lv lw lx ly bi translated">移除异常值还可以减少可能导致过度拟合的观察值的数量，过度拟合是指模型过于复杂，无法了解所提供数据的简单性。我们必须确保模型的参数和数据是正确平衡的。</li></ol><p id="7d66" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们将把重点放在第二点上，因为第一点超出了本文的范围。</p><p id="0eda" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">现在，有一些处理异常值的方法。</p><ol class=""><li id="1c44" class="lq lr hi ki b kj lc km ld kp ls kt lt kx lu lb lv lw lx ly bi translated">拆卸。</li><li id="5fee" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb lv lw lx ly bi translated">缩放。</li><li id="53b8" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb lv lw lx ly bi translated">使用非参数模型(如随机森林)来减少影响。</li><li id="c279" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb lv lw lx ly bi translated">使用深度神经网络。</li></ol><p id="2c44" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们将涵盖上述所有要点，看看上述哪一种方法会给我们带来好的结果。</p><h1 id="b9af" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">移除异常值</h1><p id="1d40" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">我们可以使用四分位间距来去除异常值。</p><pre class="iy iz ja jb fd me mf mg mh aw mi bi"><span id="7e12" class="mj jp hi mf b fi mk ml l mm mn">q25, q75 = np.percentile(data.carat, 25), np.percentile(data.carat, 75)<br/>iqr = q75 - q25; iqr<br/>cut_off = iqr * 2 <br/>lower, upper = q25 - cut_off, q75 + cut_off<br/>outliers = [x for x in data.carat if x &lt; lower or x &gt; upper]</span><span id="b995" class="mj jp hi mf b fi mo ml l mm mn">#removing the data from the dataset</span><span id="a9ed" class="mj jp hi mf b fi mo ml l mm mn">data = data.drop(data[(data.carat &gt; upper) | (data.carat&lt;lower)].index)</span></pre><blockquote class="lh li lj"><p id="e831" class="kg kh lk ki b kj lc ij kl km ld im ko ll le kr ks lm lf kv kw ln lg kz la lb hb bi translated">注:截止变量是平均值和标准差的乘积。</p></blockquote><p id="de09" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">以检查是否已经从数据中移除了不必要的数据点。我们将使用两个模型，一个是参数模型——随机梯度下降回归器——和一个非参数模型。</p><p id="db52" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我将使用我将要实现的所有模型的普通形式。目的是看预处理技术是否有效。</p><p id="be7a" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">在用不包含异常值<strong class="ki hj">的数据拟合模型后，我们得到了以下结果。</strong></p><pre class="iy iz ja jb fd me mf mg mh aw mi bi"><span id="ca43" class="mj jp hi mf b fi mk ml l mm mn">import <strong class="mf hj">math</strong></span><span id="d242" class="mj jp hi mf b fi mo ml l mm mn">def rmse(X,y): <em class="lk">return math.sqrt(((X-y)**2).mean())</em></span><span id="205c" class="mj jp hi mf b fi mo ml l mm mn">def print_score(model):<br/>    <em class="lk">return [rmse(model.predict(X_train), y_train),rmse(model.predict(X_test), y_test), <br/>     model.score(X_train, y_train), model.score(X_test, y_test)]</em></span><span id="1e6b" class="mj jp hi mf b fi mo ml l mm mn">print('The scores for Stochastic Gradient Descent are: ', <strong class="mf hj">print_score(SGD)</strong>)</span><span id="5b5d" class="mj jp hi mf b fi mo ml l mm mn">print('The scores for Random Forest are: ',<strong class="mf hj">print_score(rf)</strong>)</span><span id="8d57" class="mj jp hi mf b fi mo ml l mm mn">&gt;&gt;The scores for Stochastic Gradient Descent are: <strong class="mf hj">[0.33437466833442886, 0.33492309110522206, 0.8814293026043725, 0.8808833158341957]</strong></span><span id="4b7d" class="mj jp hi mf b fi mo ml l mm mn">&gt;&gt;The scores for Random Forest are:  <br/><strong class="mf hj">[0.2521855459326567, 0.25436238295812885, 0.93255480422885, 0.9312950253266471]</strong></span></pre><p id="fb1e" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">前两个指标分别告诉我们在训练和测试数据集上执行的模型的<strong class="ki hj">误差</strong>。同样，最后两个指标告诉我们在相同的上执行的模型的准确性。</p><p id="ccbb" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">因此，我们可以看到，没有过度拟合或拟合不足。这是一个好迹象。</p><h1 id="688d" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">缩放异常值</h1><p id="426a" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">缩放是一种技术，其中数据点被带到一个共同的值范围，分布的形状保持不变。</p><p id="9955" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">那么，为什么要缩放呢？</p><p id="d357" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">机器学习模型的主要任务是为每个特征找到一个值，这样它们可以更快地收敛，以达到唯一的解决方案。如果数字较大，那么对于机器学习模型来说，找到特定值就变得更加困难。因此，我们试图将它们带到一个范围内，以便更容易、更快地找到唯一的数字。</p><p id="6f58" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">当数字较大并且相同的群体中有很多差异时，缩放是最有效的。</p><pre class="iy iz ja jb fd me mf mg mh aw mi bi"><span id="2589" class="mj jp hi mf b fi mk ml l mm mn">from sklearn.model_selection import train_test_split</span><span id="7179" class="mj jp hi mf b fi mo ml l mm mn">X, y = data_raw.carat, np.log(data_raw.price)</span><span id="f7da" class="mj jp hi mf b fi mo ml l mm mn">from sklearn.preprocessing import RobustScaler</span><span id="d129" class="mj jp hi mf b fi mo ml l mm mn">scaling = RobustScaler()</span><span id="4def" class="mj jp hi mf b fi mo ml l mm mn">X = scaling.fit_transform(np.array(X).reshape(-1,1))</span><span id="cff5" class="mj jp hi mf b fi mo ml l mm mn">X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=23, test_size=0.3)</span><span id="7f69" class="mj jp hi mf b fi mo ml l mm mn">X_train = np.array(X_train).reshape(-1,1)<br/>X_test = np.array(X_test).reshape(-1,1)</span></pre><p id="fecc" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">因为数据集中存在异常值，所以我使用了健壮的标量。稳健标量减少了异常值的影响，因为它使用了四分位数范围。</p><p id="4bf7" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">在用缩放数据拟合模型后，我们得到了以下结果。</p><pre class="iy iz ja jb fd me mf mg mh aw mi bi"><span id="a00a" class="mj jp hi mf b fi mk ml l mm mn">print('The scores for Stochastic Gradient Descent are: ',print_score(SGD))</span><span id="d5e6" class="mj jp hi mf b fi mo ml l mm mn">print('*'*20)</span><span id="5771" class="mj jp hi mf b fi mo ml l mm mn">print('The scores for Random Forest are: ',print_score(rf))</span><span id="50f9" class="mj jp hi mf b fi mo ml l mm mn">&gt;&gt;The scores for Stochastic Gradient Descent are:  <strong class="mf hj">[0.3968648110452676, 0.3995578537520062, 0.8475738040346006, 0.8435787127417848]</strong><br/>********************<br/>&gt;&gt;The scores for Random Forest are:  <strong class="mf hj">[0.2505442962295736, 0.2532557461978344, 0.9392503939398784, 0.9371572577031487]</strong></span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/9cd7cd8b8a45ab1c89c64e523506bcaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WOlNPCbYNocemJGi4_m7AA.png"/></div></div></figure><p id="8ae0" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">虽然随机梯度下降随机森林的分数下降了，但是分数上升了一点。这可能是因为输入数据的方差不高。大多数输入数据都在0–2的范围内，因此缩放后没有太大意义。但我们可以肯定的是，缩放后的值停留在四分位数范围内。</p><h1 id="2f52" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">神经网络</h1><p id="ba89" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">神经网络是最先进的数学模型，受大脑功能的启发，可以制作预测模型并找到数据的底层结构。</p><p id="5544" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们将建立两个神经网络。两种深度学习模型在激活功能方面会有所不同。我们将比较他们彼此的表现。</p><p id="9110" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">同样，这里的目标是看看哪个模型对异常值是稳健的。我们将不再执行之前执行的任何预处理技术。</p><p id="dd2b" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">模型的轮廓非常简单。它将由300个神经元组成，这些神经元将具有s形激活功能。</p><pre class="iy iz ja jb fd me mf mg mh aw mi bi"><span id="67fd" class="mj jp hi mf b fi mk ml l mm mn">model = keras.models.Sequential([<br/>    keras.layers.Dense(300, activation="sigmoid", input_shape=X_train.shape[1:]),<br/>    keras.layers.Dense(1),<br/>])<br/>model.compile(loss="mean_squared_error", optimizer=keras.optimizers.SGD(lr=1e-3))<br/>history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))<br/>mse_test = model.evaluate(X_test, y_test)</span></pre><p id="6697" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">在20次迭代之后，具有sigmoid激活的普通神经网络表现得相当好。几乎没有过度拟合，可以忽略不计。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/fc8b560808f51cb48e95c4b8be39b9d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i48M1xu6CTwypGjRl3tkhQ.png"/></div></div></figure><p id="ed58" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">进入下一个具有LeakyRelu激活功能的深度学习模型，这是结果显示的。具有LeakyRelu激活功能的模型比具有Sigmoid功能激活的模型学习得更快，表现得更好。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mr"><img src="../Images/843309c839652c69f8db57d59d43a3dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lKVNnRh91UNn99YCSivShQ.png"/></div></div></figure><h1 id="ecb0" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">结论</h1><ul class=""><li id="9e65" class="lq lr hi ki b kj kk km kn kp ms kt mt kx mu lb mv lw lx ly bi translated">移除异常值会导致观察值减少，从而导致模型丢失重要的数据点，这些数据点对于建立自变量和因变量之间的关系至关重要。</li><li id="d7f5" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb mv lw lx ly bi translated">当谈到减少离群值的影响时，缩放是一个更好的选择。在这方面，我们也应该使用<strong class="ki hj">健壮标量</strong>,因为它在处理异常值时效果最好。</li><li id="82da" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb mv lw lx ly bi translated">其他缩放方法也是可用的，如标准标量、最小标量、归一化等等。阅读本文以了解更多关于缩放方法的信息。</li><li id="09ce" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb mv lw lx ly bi translated">我们还发现，当异常值被移除且未缩放时，参数模型工作得更好，这主要是因为大多数值聚集在0–2的范围内，使其对特征缩放不太有效。</li><li id="2ecb" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb mv lw lx ly bi translated">非参数模型显示了一些不同的结果，这可能是因为非参数模型更依赖于要素的修剪，而不是为要素分配权重。</li><li id="f154" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb mv lw lx ly bi translated">深度神经网络不容易出现异常值，特别是如果我们考虑激活函数的话。</li><li id="3594" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb mv lw lx ly bi translated">深度神经网络经历多次迭代，允许它们校正权重，然后应用它。当有许多节点，并且每个节点都有助于获得一个唯一的解决方案时，这将更加有效。这使得深度神经网络对异常值更加鲁棒。</li></ul><blockquote class="lh li lj"><p id="a7b7" class="kg kh lk ki b kj lc ij kl km ld im ko ll le kr ks lm lf kv kw ln lg kz la lb hb bi translated">注意:我们的目的不是设计一个复杂的模型，而是设计和构建一个模型<strong class="ki hj">，以了解去除异常值、缩放异常值、</strong>、T2的影响，以及观察哪些模型在自变量和因变量之间建立了最佳关系。</p></blockquote><h1 id="5c64" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">进一步阅读</h1><ul class=""><li id="1b16" class="lq lr hi ki b kj kk km kn kp ms kt mt kx mu lb mv lw lx ly bi translated"><a class="ae jn" href="https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02" rel="noopener" target="_blank">使用Scikit-Learn进行缩放、标准化或规范化</a></li><li id="6294" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb mv lw lx ly bi translated"><a class="ae jn" href="https://stackoverflow.com/questions/51841506/data-standardization-vs-normalization-vs-robust-scaler" rel="noopener ugc nofollow" target="_blank">数据标准化vs规范化vs健壮定标器</a></li><li id="4279" class="lq lr hi ki b kj lz km ma kp mb kt mc kx md lb mv lw lx ly bi translated"><a class="ae jn" href="https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-use-statistics-to-identify-outliers-in-data/</a></li></ul></div></div>    
</body>
</html>