<html>
<head>
<title>CNN — quick learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN——快速学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cnn-quick-learn-12dced578b01?source=collection_archive---------16-----------------------#2020-05-09">https://medium.com/analytics-vidhya/cnn-quick-learn-12dced578b01?source=collection_archive---------16-----------------------#2020-05-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="de62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快速简单地了解卷积神经网络的概念。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/e15d35b52ba3474942f11cd0643a28cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*clYVFdYDLdUcLqs5ZbfQXw.png"/></div></div></figure><h1 id="0d3f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">关于CNN你应该知道的一切</h1><ul class=""><li id="b1c3" class="kn ko hi ih b ii kp im kq iq kr iu ks iy kt jc ku kv kw kx bi translated"><em class="ky">CNN是什么？</em></li><li id="3097" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><em class="ky">为什么是CNN？</em></li><li id="5598" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><em class="ky">什么是卷积层？</em></li><li id="d8c7" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><em class="ky">什么是池层？</em></li><li id="3e74" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><em class="ky">什么是填充？</em></li><li id="5ecc" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><em class="ky">什么是跨步？</em></li><li id="b666" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><em class="ky">什么是展平层？</em></li><li id="fce5" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><em class="ky">什么是密层？</em></li></ul></div><div class="ab cl le lf gp lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="hb hc hd he hf"><h1 id="3c2f" class="jp jq hi bd jr js ll ju jv jw lm jy jz ka ln kc kd ke lo kg kh ki lp kk kl km bi translated">美国有线新闻网；卷积神经网络</h1><ul class=""><li id="e427" class="kn ko hi ih b ii kp im kq iq kr iu ks iy kt jc ku kv kw kx bi translated">&gt; CNN是一种深度学习算法，主要用于图像分类</li><li id="4801" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;它可以获取输入图像，为图像中的各个方面分配重要性(可学习的权重和偏差)，并能够区分它们。</li><li id="7a2f" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;与其他分类算法相比，ConvNet (CNN)中所需的预处理要低得多。虽然在原始方法中，过滤器是手工设计的，但是通过足够的训练，ConNet有能力学习这些过滤器或图像的特征</li></ul><h1 id="bd81" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">为什么是CNN？</h1><p id="46d7" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq lq is it iu lr iw ix iy ls ja jb jc hb bi translated">你可能会认为一个正常的机器学习分类器也可以做同样的事情，所以我们为什么需要这个CNN，嗯，这都是关于速度，计算和准确性。</p><ul class=""><li id="c25e" class="kn ko hi ih b ii ij im in iq lt iu lu iy lv jc ku kv kw kx bi translated">&gt;与ML分类器相比，CNN有许多主要优势，但是您想知道真正的原因，使用CNN的原因是它在处理器上的开销比ML分类器少，并且准确性更高。随着世界向云基础设施转变，云机器上的低处理模型是最合适的。</li><li id="05ef" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">如果你认为我们可以使用简单的神经网络。请听我说，在一个简单的神经网络中，一个3×3(像素分辨率)的图像矩阵被转换为一个9×1的矩阵，即所谓的向量，这样我们就可以将它输入到一个有9个起始节点的神经网络中。通常，不使用3x3图像，而是使用更大的图像，并且图像矩阵的维度也更多，这将导致非常大且宽的神经网络。</li><li id="2793" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;由于所涉及的参数数量减少，ConvNet对数据集的拟合更好。并且没有通过使用还原CNN不丢失图像的特征。</li></ul><h1 id="36d6" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">卷积层</h1><blockquote class="lw lx ly"><p id="cb1e" class="if ig ky ih b ii ij ik il im in io ip lz ir is it ma iv iw ix mb iz ja jb jc hb bi translated"><strong class="ih hj">卷积层不是神经网络的一部分，它只是在将图像发送到神经网络之前，对图像进行预处理并从图像中提取特征信息的一种技术。</strong></p></blockquote><ul class=""><li id="fe82" class="kn ko hi ih b ii ij im in iq lt iu lu iy lv jc ku kv kw kx bi translated">&gt; Filter =就在此下方，作为仅过滤图像特定信息的普通过滤器，例如，将返回图像中所有直线或图像中所有曲线的过滤器。</li><li id="0da9" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;如果您将这样的过滤器放在图像上，它会返回过滤后的信息。但是当然，整个图像不会仅仅由一条直线组成，这就是为什么我们选择一个小的过滤器，然后一次一个地应用到图像的一小部分，直到整个图像被覆盖。</li><li id="28e2" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;假设图像分辨率为5x5 px，我们选择大小为3x3 px的滤镜，这意味着图像矩阵为5x5矩阵，滤镜为3x3矩阵。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/1daa4a69b5dc1efeb6f92f9f27dd78f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*Z87z69ufkGnNolH6R_Ln_w.gif"/></div></figure><ul class=""><li id="36e6" class="kn ko hi ih b ii ij im in iq lt iu lu iy lv jc ku kv kw kx bi translated">&gt;首先，我们从图像中选择一个3x3的矩阵(这应该与我们的过滤器尺寸相同)。然后，图像的这个3x3子部分与我们的滤波器进行点积(矩阵乘法)，这将返回一个值，我们将这个值存储在一个新的矩阵中，称为卷积矩阵。</li><li id="c5fe" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;我们通过选择图像的不同部分重复这一过程，直到我们得到所有的值。具有滤波器的图像点积的特定部分将在我们的卷积矩阵中具有固定的位置</li><li id="84ff" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;例如:从一个5x5的图像中，我们可以选择一个3x3的矩阵，9个不同的时间。因此，我们的卷积矩阵等于我们的滤波器的维数。</li><li id="87ad" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;这个卷积矩阵现在是我们的新矩阵，以更高的直线检测精度来表示我们的图像。</li><li id="a030" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;现在您可以通过多个卷积层提取图像所需的所有信息。</li><li id="0b5a" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;真正的问题是，您不必选择哪个图层过滤哪个要素，也不必设置过滤器。这都是由算法本身完成的，你只需要给模型分配一个卷积层，权重会在训练时分配。</li></ul><h2 id="2ec7" class="md jq hi bd jr me mf mg jv mh mi mj jz iq mk ml kd iu mm mn kh iy mo mp kl mq bi translated">卷积运算的目的是从图像中提取高级特征，如边缘、线条、曲线、阴影等。</h2><h1 id="d759" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">汇集层</h1><ul class=""><li id="28df" class="kn ko hi ih b ii kp im kq iq kr iu ks iy kt jc ku kv kw kx bi translated">&gt;池层用于减少卷积特征的尺寸大小。</li><li id="c95c" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;这样做是为了通过降维来降低处理数据所需的计算能力</li><li id="7cdd" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;它有助于提取主要特征并减少噪声</li><li id="7c6b" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;用简单的语言来说，假设您在卷积层后得到的卷积矩阵是4x4，合并会将其简化为2x2矩阵。</li><li id="1c02" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;你可能会说，数据丢失或特征丢失，但事实并非如此，它更像是只降低了维度，但仍保留了特征，为此，我们可以使用不同的轮询技术。</li><li id="2072" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><strong class="ih hj"> MAX Pooling = </strong>我们从4x4矩阵中选择一个2x2子矩阵，从中取出最大值，并将其保存在新矩阵中。我们重复地取一个2x2矩阵(总共4次),直到我们完成我们的2x2简化矩阵。</li><li id="096e" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated"><strong class="ih hj">平均池</strong> =我们从4x4矩阵中选择一个2x2子矩阵，取所有4个值的平均值，并将其保存在我们的新矩阵中。我们重复地取一个2x2矩阵(总共4次),直到我们完成我们的2x2简化矩阵。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mr"><img src="../Images/61ea4c56437672ce32e750883ef198b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*qGjcCGjQnlPc5f7f5mUZCg.png"/></div></figure><p id="7291" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，“带滤波器+池的ConvNet”是一个卷积层。我们可以添加许多卷积层，这会给我们带来更好的结果。</p><h2 id="6676" class="md jq hi bd jr me mf mg jv mh mi mj jz iq mk ml kd iu mm mn kh iy mo mp kl mq bi translated">Conv层之后我们得到了什么结果</h2><p id="b634" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq lq is it iu lr iw ix iy ls ja jb jc hb bi translated">我们输入的原始图像有许多我们不需要的不必要的特征和数据，但我们仍然必须将它们作为矩阵中的一个像素输入，</p><p id="5eec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在卷积层之后，来自图像的所有噪声和不想要的数据被移除，并且我们有一个只包含主要特征的矩阵。</p><p id="4741" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑这个例子:你想训练模型，以便它可以预测照片是否是你的。你给训练的样本照片让你站在一些照片的中间，在边缘，远离相机，靠近相机，不同类型的背景等，所有这些图像将在卷积层预处理，只有那些具有一些主要特征的像素才会被发送。</p><ul class=""><li id="eba1" class="kn ko hi ih b ii ij im in iq lt iu lu iy lv jc ku kv kw kx bi translated">&gt;经过以上过程，我们已经成功地使模型理解了特征。</li><li id="173f" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">接下来，我们将展平convnet的最终输出，并将其输入常规神经网络进行分类</li></ul><h1 id="e7f5" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">填料</h1><ul class=""><li id="9535" class="kn ko hi ih b ii kp im kq iq kr iu ks iy kt jc ku kv kw kx bi translated">&gt;这是一个与convNet相关的术语，指的是CNN内核处理图像时添加到图像中的像素数量。</li><li id="36fe" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;每次我们使用滤镜时，图像的大小都会变小，如果我们不想这样，并且希望保留图像的原始大小，以提取我们使用填充的相同低级特征</li><li id="aefc" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;当我们在5x5图像上使用3x3滤镜时，我们会得到一个3x3卷积矩阵，如果我们不想发生这种情况，我们可以使用填充。</li><li id="696a" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;在使用3x3滤镜将5x5图像发送到Conv层之前，我们对图像进行像素填充，使其成为6x6图像，现在，如果我们将此6x6图像发送到Conv层，并对其应用3x3滤镜，我们将获得5x5分辨率的卷积矩阵。</li><li id="209a" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;这不会增加图像的大小，因为增加的新像素a的密度可能最低。(不作为功能)</li></ul><h1 id="0922" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">进展</h1><ul class=""><li id="362c" class="kn ko hi ih b ii kp im kq iq kr iu ks iy kt jc ku kv kw kx bi translated">&gt;它是在输入矩阵上移动的像素数。</li><li id="2330" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;记得在Conv层中，我们从原始图像矩阵(相同大小的过滤器)中选择一个子矩阵来与过滤器进行点积，Stride决定从哪里获取下一个子矩阵，下一个子矩阵应该离当前有多远。</li><li id="ad59" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;当Stride为1时，我们将子矩阵一次移动1个像素。</li></ul><h1 id="7863" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">变平</h1><p id="f19e" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq lq is it iu lr iw ix iy ls ja jb jc hb bi translated">它是将数据转换为一维数组以输入到神经网络中。</p><ul class=""><li id="3277" class="kn ko hi ih b ii ij im in iq lt iu lu iy lv jc ku kv kw kx bi translated">&gt;现在，在covn层之后，它缩小了图像的大小，并将其转换为功能包图像数组，然后我们将该数组输入到普通的神经网络中。</li><li id="72cd" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;正如我们所知，正常的神经网络采用图像的向量，简单来说，图像的每个像素都需要输入到神经网络的一个节点中。</li><li id="39d4" class="kn ko hi ih b ii kz im la iq lb iu lc iy ld jc ku kv kw kx bi translated">&gt;因此，我们将涉及的数组转换为一维数组，这个过程称为展平</li></ul><h1 id="e373" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">致密层</h1><p id="625e" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq lq is it iu lr iw ix iy ls ja jb jc hb bi translated">它只是神经网络中一层规则的神经元。每个神经元接收来自前一层的所有神经元的输入，这是一种密集连接。密集层是典型的全连接神经网络层:每个输入节点连接到每个输出节点。</p><p id="171c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一层给你模型的输出。</p><p id="3bb6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一层的节点数等于我们需要的输出数。</p></div></div>    
</body>
</html>