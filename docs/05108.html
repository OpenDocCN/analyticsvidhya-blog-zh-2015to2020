<html>
<head>
<title>Land Cover Classification Using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Keras的土地覆盖分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/land-cover-classification-using-keras-9f9036a07a3?source=collection_archive---------15-----------------------#2020-04-11">https://medium.com/analytics-vidhya/land-cover-classification-using-keras-9f9036a07a3?source=collection_archive---------15-----------------------#2020-04-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5a41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文将描述使用Keras库进行深度学习，构建用于识别卫星图像中土地覆盖的预测模型的过程。确定卫星图像中的土地覆盖范围是一项与行业相关的任务，这些行业依赖于从空间分析中获得的数据，包括环境工作、风险评估和规划。利用深度学习可以帮助自动化大型图像处理任务。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/fb4647ae455afaafea0eccdfd0ccfe1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*Qc6CS9HTaD3dXCqiPJwUTQ.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">版权所有:欧空局-皮埃尔·卡里尔</figcaption></figure></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="7c60" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">项目动机</h1><p id="9e1e" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">该项目侧重于为欧洲卫星图像数据集创建一个准确的图像分类模型，该数据集包含哨兵-2号卫星的27k、64x64p图像。在该数据集中，图像被组织成10个不同的土地覆盖类别。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kz"><img src="../Images/918d71e869d9585cf103b134dfa468d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*jbROexxCWMHRBmD2PK7kIA.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">欧洲卫星数据集的类别分布</figcaption></figure><p id="a866" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过使用<strong class="ih hj">迁移学习、</strong>将获得准确的模型，这涉及使用在一个领域中预先训练的模型作为相关应用的起点。在这个项目中，VGG16卷积神经网络是使用Keras下载的，当暴露于EUROSAT卫星图像时，它的层在训练中被冻结。通过VGG卷积层传递这些图像的输出被传递到一个新的分类器，不同于原始的VGG全连接层。</p><p id="4f9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">利用迁移学习，由于采用了已经训练好的模型的架构，训练精确的图像分类模型变得更加容易。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="85c5" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">预处理图像数据</h1><p id="5ac1" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">包含27，000幅图像的数据集被分成一个训练和测试目录。测试集大小占整个数据集的30%，并且在Scikit-Learn的StratifiedShuffleSplit的帮助下保持了班级大小的比例。</p><p id="76d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了将图像传递到Keras模型，可以打开文件并将其转换为numpy数组以进行拟合和预测。然而，对于27，000张图像的数据集来说，这并不完全理想。Keras支持以多种方式加载图像数据。ImageDataGenerator类支持图像数据批次的加载，能够应用实时图像增强。图像增强是一种提高模型概括数据能力的有用技术。它复制现有图像并应用变换，以增加数据集的可变性。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es la"><img src="../Images/eebdb4df6354836dc460b5b7b0fe1ce7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CqmN28osSX6Sr8Tx9FYO0g.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图二。创建用于加载批量图像张量的数据生成器</figcaption></figure><h1 id="2509" class="jw jx hi bd jy jz lf kb kc kd lg kf kg kh lh kj kk kl li kn ko kp lj kr ks kt bi translated">训练和微调一个Keras CNN</h1><p id="54b6" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">迁移学习可以包括冻结从原始预训练模型获得的现有卷积层的全部或一部分。本项目采用的方法是创建一个利用VGG16架构的新模型，训练该模型，并通过解冻一小组卷积层来微调该模型。</p><p id="6402" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了从VGG16的预训练权重创建新模型，使用Keras API下载该模型。对于模型架构中存在的每一层,“可训练”标志被设置为假，以指示模型的原始权重应该保持在它们的原始状态——即，不根据我们传递给它的新数据进行更新。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lk"><img src="../Images/9b03fe383be1685603fc532cb66744ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCyqq9uz-sXpuy-MIczjKg.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图三。通过微调编译模型</figcaption></figure><p id="7c9f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在代码片段中，您可以看到预训练模型是如何下载的，它的卷积基被设置为变量<em class="ll"> conv基</em>。该数据库的输出连接到根据EUROSAT数据集定义的密集输出层(即10个输出类，带有softmax激活功能)。全局平均池也被初始化，以确保卷积库的输出可以被聚集成可消化的格式。通过编译这个模型，我们已经成功地创建了一个利用VGG16架构的模型，但将能够在我们的自定义数据集上进行训练和预测。这个项目选择的优化器是Adagrad，学习率为0.01。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><p id="c23f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了评估模型的性能，考虑了加权F分数；精确率和召回率之间的加权调和平均值赋予召回率更大的权重<em class="ll">。</em>模型的初始训练取得了0.78的F值。早期停止阻止模型训练超过60个时期。</p><p id="1321" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个初始训练之后，用学习到的权重重新编译该模型，并且解冻卷积基中的层的子集。这第二次训练持续了所有100个时期，并获得了0.87的加权F值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lm"><img src="../Images/dc60c3ba209c309e1ef721a917e5f669.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*EGCsnNrUFHs4lssO03iSeg.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图4。微调前的模型训练精度和损失</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/1070ecc2375c75f633ce3d47e9b418ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*M6FAtgKGbDcXgovF3ppE1w.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图五。启用微调后的模型训练精度和损失</figcaption></figure><p id="e688" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，通过使用现有架构中的一些预训练层，微调可以让模型继续提高其预测能力。然后给模型提供预测的测试数据集。该模型还没有看到这些图像，因此这应该表明该模型对来自训练图像的信息的概括和保留有多好。</p><h1 id="9c1f" class="jw jx hi bd jy jz lf kb kc kd lg kf kg kh lh kj kk kl li kn ko kp lj kr ks kt bi translated">结果呢</h1><p id="4f91" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">该模型在大多数班级表现良好。信息检索需要在精确的结果之间稳定的导航，以及正确结果的最大化。精确度和召回率之间的平衡经常会导致一些艰难的决定。我发现，对模型进行微调，大大提高了最初训练时无法达到的模型精度。</p><p id="a6e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从该表中我们可以看到，该模型能够识别森林、海洋/湖泊和河流类别中的几乎所有图像，同时仍然保持较高的精确度。一个非常好的迹象。住宅类能够检索到所有885张照片，但牺牲了精确的结果。很可能，属于高速公路、植被或工业标签的图像最终出现在这里，因为它们的召回率很低。我们可以看到模型是如何对每个类标签进行推广的，使用这些结果可以提高性能。如果时间不是一个因素，我会继续尝试通过调整在微调期间解冻的层数来改进模型。在预测时，VGG16架构的前14层不可训练，而剩下的2层允许训练。我会考虑试验的另一个参数是所选择的优化器。也许从较低的学习率开始。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/ed7a0d926ec7e6973961067a0039d9c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*cLZme6lMQkHBc6Zg3Tsicw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图六。基于测试数据集的模型评估</figcaption></figure><p id="3346" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用Matplotlib，我们可以直观地看到模型的预测和它们的真实类:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lp"><img src="../Images/59d34c39e8a3086308ef7ec3f24ecc79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rq6pwjK86yMUotcksdz0Zg.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图7。预测图像，预测类下面的括号中包含真实类</figcaption></figure></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="595f" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">创建命令行应用程序</h1><p id="d586" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">如果性能令人满意，可以保存模型并为任何新的预测加载。编写了一个简单的命令行应用程序，允许输入图像路径，并返回带有预测类标签的图像。由于图像的低分辨率，输出不那么迷人。但是最后精度还算一致！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/1ca2e7e1742b9b43c50306837fd608af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*lD49qkpvqGHlVYWO0M-_kQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图8。命令行应用程序predict.py的输出</figcaption></figure><p id="428d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个项目的代码可以在<a class="ae lr" href="https://github.com/silent-j/DSND-CapstoneProject-SatelliteImageCNN" rel="noopener ugc nofollow" target="_blank">https://github . com/silent-j/DSND-capstone project-satellite image CNN</a>找到。</p></div></div>    
</body>
</html>