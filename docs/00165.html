<html>
<head>
<title>Choosing the Best K Value for K-means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为K-均值聚类选择最佳K值</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/choosing-the-best-k-value-for-k-means-clustering-d8b4616f8b86?source=collection_archive---------1-----------------------#2018-10-28">https://medium.com/analytics-vidhya/choosing-the-best-k-value-for-k-means-clustering-d8b4616f8b86?source=collection_archive---------1-----------------------#2018-10-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1554" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有许多用于不同应用的机器学习算法。有些叫“有监督的”，有些叫“无监督的”。今天，我们将讨论一种无监督算法，它被称为K-means聚类。</p><p id="d0e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可能，有很多关于K-means聚类如何工作或者如何用Python实现它的帖子。出于这个原因，我们将仅仅集中于选择最佳K值，以便获得更好的结果。我们所说的“更好的结果”显然是指尽可能有效地对数据点进行分组。</p><p id="551c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每次扫描一个范围内的K个值并将数据点聚类到K个不同的组中可能是一个聪明的想法。在每个聚类完成后，我们可以检查一些度量，以便决定我们是否应该选择当前的K或继续评估。</p><p id="1cd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中一个度量是总距离(在sklearn库中称为“惯性”)。惯性向我们展示了到每个星团中心的距离总和。如果总距离很大，这意味着这些点彼此之间距离很远，彼此之间可能不太相似。在这种情况下，我们可以选择继续评估更高的K值，以查看是否可以减少总距离。然而，我应该在这里强调一个非常重要的观点。缩短距离并不总是最明智的想法。假设我们有100个数据点。如果我们选择K为100，我们将得到一个等于0的距离值。但是，显然，这不是我们所希望的。我们希望有几个“好的”聚类，它们包含关于数据点的足够信息，并且没有任何噪声或异常值。</p><p id="c898" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗯，我们能感觉到自己还行的点叫做“肘点”。当您绘制总距离(惯性)与K值的关系图时，您会发现，在某一点之后，总距离开始发生变化，与之前的变化相比，变化不明显。此时，我们可以得出结论，数据点被充分地聚类，并且进一步的聚类不会为我们的系统贡献更多的信息。因此，我们可以选择停止在这里，并继续与肘点对应的K值。</p><p id="30bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们动手写一个Python代码，以便更好地理解如何找到最佳k。</p><p id="eca1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用一个非常著名的数据集Iris。虹膜数据集包含三种不同类型的花，每种花有4个特征。我们希望我们的K-means算法能够找到最佳的分组结构。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="a170" class="jm jn hi ji b fi jo jp l jq jr">#IMPORT LIBRARIES<br/>import numpy as np<br/>from sklearn.cluster import KMeans<br/>from sklearn import datasets<br/>import matplotlib.pyplot as plt</span><span id="c7b1" class="jm jn hi ji b fi js jp l jq jr">#LOAD IRIS DATASET<br/>iris=datasets.load_iris()<br/>x=iris.data<br/>target=iris.target</span><span id="68d0" class="jm jn hi ji b fi js jp l jq jr">#Create a function that calculates Inertia for n times<br/>#We will sweep through 1 to n to find the optimal cluster number</span><span id="96ae" class="jm jn hi ji b fi js jp l jq jr">def cluster_variance(n):<br/>    variances=[]<br/>    kmeans=[]<br/>    outputs=[]<br/>    K=[i for i in range(1,n+1)]</span><span id="52d2" class="jm jn hi ji b fi js jp l jq jr">    for i in range(1,n+1):<br/>        variance=0<br/>        model=KMeans(n_clusters=i,random_state=82,verbose=2).fit(x)<br/>        kmeans.append(model)<br/>        variances.append(model.inertia_)<br/>        <br/>    return variances,K,n</span><span id="2598" class="jm jn hi ji b fi js jp l jq jr">variances,K,n=cluster_variance(10)</span><span id="8443" class="jm jn hi ji b fi js jp l jq jr">plt.plot(K,variances)<br/>plt.ylabel("Inertia ( Total Distance )")<br/>plt.xlabel("K Value")<br/>plt.xticks([i for i in range(1,n+1)])<br/>plt.show()</span></pre><figure class="jd je jf jg fd ju er es paragraph-image"><div class="er es jt"><img src="../Images/b5df42a4cfcd89797d4c4d89dd9e6426.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*iDCdm9R92oBZ5iHjIlARDg.png"/></div></figure><p id="ee29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上图中可以看出，K=3后，总距离的减少变化更加缓慢，线的斜率显著降低。从这个图中，我们可以推断出，超过这个K值(3)不会对我们的聚类算法有太大的贡献，只会使我们的聚类更加复杂。最后，我想告诉你，这个结果与我们的预期相当一致。由于Iris数据集包含三种不同类型的花，因此得出3个聚类是这种情况下最有效的方法也就不足为奇了。</p></div></div>    
</body>
</html>