<html>
<head>
<title>Better set matrices to optimize the prediction of imbalanced user subscription</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优化不平衡用户订阅预测的更好集合矩阵</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-i-choose-metric-and-parameters-for-better-prediction-on-imbalanced-user-subscription-data-824369204cb3?source=collection_archive---------20-----------------------#2020-01-26">https://medium.com/analytics-vidhya/how-i-choose-metric-and-parameters-for-better-prediction-on-imbalanced-user-subscription-data-824369204cb3?source=collection_archive---------20-----------------------#2020-01-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e78a997e67118f02a8fbfd22299a9996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-hVGk59Nrftlcw7Z"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@tangcindy?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Cindy Tang </a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="61e9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们都知道在使用机器学习来解决问题时，获得正确的指标有多重要。适合这种情况的适当指标将有助于我们的机器学习模型在创造价值方面发挥最大作用。相反，糟糕的度量设置可能导致无用的模型，并失去创造更多价值的机会。</p><p id="4671" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本文中，我将通过一个例子来说明如何根据营销场景选择指标，并进一步实现根据指标选择参数的机器学习模型。此外，由于我们的样本数据非常不平衡，我还将演示一种在交叉验证过程中实现过采样的方法。</p><p id="f136" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们先快速浏览一下我们的数据。</p><p id="da25" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们使用的数据是来自UCI   <strong class="ix hj">的<a class="ae iu" href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">银行营销数据集。</strong>我们使用由<strong class="ix hj"/>#银行客户数据#其他属性#社会和经济背景属性组成的20个特征来预测用户订阅。(详细数据描述请点击链接。这里我们跳过这一部分来关注这个问题。)</a></strong></p><p id="6974" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据:41188个条目，21列，20个预测值(x)和1个因变量(y)</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jt"><img src="../Images/b6113d1c487947b691efe338a0543859.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*4_G50WYMZCVeklRHrfldSw.png"/></div></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jy"><img src="../Images/a1963e5ba1f11386a38a9cfd5ed7e3ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*rq2Tw78XRUGrOfhjgE4lCQ.png"/></div></figure><p id="bf63" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们所看到的，我们的数据在类别(y)标签上是高度不平衡的。当营销人员在线或线下开展营销活动时，与不响应的用户相比，只有很低比例的用户会订阅或成为买家，这是很常见的。</p><p id="effd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">常规设置是为了提高分类模型的度量“准确性”。然而，在我们的例子中，我们可能会遇到两个问题:</p><ol class=""><li id="3869" class="jz ka hi ix b iy iz jc jd jg kb jk kc jo kd js ke kf kg kh bi translated">误导性的高精度:对于主要由负值y组成的高度不平衡的数据，模型会倾向于将所有值预测为负值，从而误导性地提高精度。这时，过采样开始用于防止模型出现偏差。</li><li id="2aa4" class="jz ka hi ix b iy ki jc kj jg kk jk kl jo km js ke kf kg kh bi translated">我们衡量的指标可能不符合现实世界的情况:在用户订阅非常有价值而营销成本相对较低的情况下，我们主要关心的是如何找到尽可能多的用户订阅，而不是准确预测那些不会响应的用户。换句话说，我们希望降低误报率(我们无法识别的订阅用户)并提高召回率(TP/TP+FN ),这样我们就可以找到大多数愿意订阅的用户。</li></ol><p id="0b42" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们可以开始解决这些问题了。</p><p id="15b0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，当我们要在交叉验证过程中应用过采样时。我们应该只对训练数据进行过采样。对于验证和测试数据，我们想让它保持不平衡。(关于它的原因，请参考<a class="ae iu" href="https://beckernick.github.io/oversampling-modeling/" rel="noopener ugc nofollow" target="_blank">https://beckernick.github.io/oversampling-modeling/</a>)</p><p id="38ff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，我们不使用sci-kit learn中原来的交叉验证类，而是使用如下修改后的类。</p><pre class="ju jv jw jx fd kn ko kp kq aw kr bi"><span id="2361" class="ks kt hi ko b fi ku kv l kw kx">#modified cross validation that oversampled on training data (ref   <a class="ae iu" href="https://stackoverflow.com/questions/32615429/k-fold-stratified-cross-validation-with-imbalanced-classes" rel="noopener ugc nofollow" target="_blank">https://stackoverflow.com/questions/32615429/k-fold-stratified-cross-validation-with-imbalanced-classes</a>)</span><span id="32e0" class="ks kt hi ko b fi ky kv l kw kx">class UpsampleStratifiedKFold:<br/>    def __init__(self, n_splits=3):<br/>        self.n_splits = n_splits<br/>    def split(self, X, y, groups=None):<br/>        for rx, tx in StratifiedKFold(n_splits=self.n_splits).split(X,y):<br/>            nix = np.where(y[rx]==0)[0]<br/>            pix = np.where(y[rx]==1)[0]<br/>            pixu = np.random.choice(pix, size=nix.shape[0], replace=True)<br/>            ix = np.append(nix, pixu)<br/>            rxm = rx[ix]<br/>            yield rxm, tx<br/>    def get_n_splits(self, X, y, groups=None):<br/>        return self.n_splits</span></pre><p id="dcc0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们可以开始训练我们的模型。这里，我们使用决策树分类器，将我们的max_depth设置为[1，3，5，7，9]，并将cv设置为unsample_kf，我们刚刚定义了un sample _ KF，以便仅对训练数据进行过采样。对于测量的方式，而不是使用默认的“精度”度量来优化。我们输出以下度量[“准确性”、“f1”、“精确度”、“召回”]，并使用“召回”作为选择模型参数的度量。结果表明，将参数设置为tree-depth=5会给我们带来最高的验证数据平均召回率(0.92)。</p><pre class="ju jv jw jx fd kn ko kp kq aw kr bi"><span id="70c0" class="ks kt hi ko b fi ku kv l kw kx"># oversampling + choose parameters by recall<br/>clf = tree.DecisionTreeClassifier(random_state=0)<br/>unsample_kf=UpsampleStratifiedKFold(n_splits=5)<br/>gscv=GridSearchCV(estimator=clf, param_grid={"max_depth":[1,3,5,7,9]},cv=unsample_kf,scoring=["accuracy","f1","precision","recall"],refit=False)<br/>gscv.fit(X_train, y_train)<br/>recall_by_par=pd.DataFrame(gscv.cv_results_).loc[:,["params","mean_test_recall"]]<br/>print(recall_by_par)</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kz"><img src="../Images/6da1bd0223099bbfac194cd330a7fead.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*KTUTmVq2t2tzfbAkwJ_Kgg.png"/></div></figure><p id="70a1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，我们可以将我们的模型应用于测试数据。我们比较了原模型和新模型的测试结果。</p><ul class=""><li id="6360" class="jz ka hi ix b iy iz jc jd jg kb jk kc jo kd js la kf kg kh bi translated">原始模型(无过采样，使用精度作为测量值)</li></ul><pre class="ju jv jw jx fd kn ko kp kq aw kr bi"><span id="8aa2" class="ks kt hi ko b fi ku kv l kw kx">#The original model result without oversampling and choose parameters by accuracy<br/>clf = tree.DecisionTreeClassifier(random_state=0)<br/>gscv_ori=GridSearchCV(estimator=clf, param_grid={"max_depth":[1,3,5,7,9]},cv=5)<br/>gscv_ori.fit(X_train, y_train)<br/>print("Best parameters:",gscv_ori.best_params_)</span><span id="0737" class="ks kt hi ko b fi ky kv l kw kx">clf = tree.DecisionTreeClassifier(random_state=0,max_depth=5)<br/>clf_fit=clf.fit(X_train,y_train)<br/>y_pred=clf_fit.predict(X_test)<br/>print("Original Testing Accuracy:", accuracy_score(y_test,y_pred))<br/>print("Original Testing recall: ",recall_score(y_test,y_pred))<br/>print("confusion matrix:\n",confusion_matrix(y_test,y_pred))</span><span id="e798" class="ks kt hi ko b fi ky kv l kw kx">from sklearn.dummy import DummyClassifier<br/>dummy_clf =DummyClassifier(strategy="most_frequent")<br/>dummy_clf.fit(X_train,y_train)<br/>y_pred_dummy=dummy_clf.predict(X_test)<br/>print("Dummy Testing Accuracy:", accuracy_score(y_test,y_pred_dummy))<br/>print("Dummy Testing recall: ",recall_score(y_test,y_pred_dummy))<br/>print("Confusion matrix:\n",confusion_matrix(y_test,y_pred_dummy))</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lb"><img src="../Images/726f82ca9760bfd5118b4e89dbaef46e.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*8T4L68JYGGikZ3CMOrRChw.png"/></div></figure><p id="4b71" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们所看到的，原始模型的准确率相当高(92%)。但是召回率低(52%)。类似地，通过最频繁策略预测的虚拟分类器也具有高准确度(89%)但低召回率(0%)。</p><ul class=""><li id="e465" class="jz ka hi ix b iy iz jc jd jg kb jk kc jo kd js la kf kg kh bi translated">新模型(过采样并使用召回作为测量)</li></ul><pre class="ju jv jw jx fd kn ko kp kq aw kr bi"><span id="cba6" class="ks kt hi ko b fi ku kv l kw kx">#oversample the training data <br/>ind_0=np.where(y_train==0)[0]<br/>ind_1=np.where(y_train==1)[0]<br/>sample_cnt=len(ind_0)-len(ind_1)<br/>sample_to_add=np.random.choice(ind_1,size=sample_cnt)<br/>ind_ros=np.concatenate([ind_0,sample_to_add])<br/>X_train_ros=X_train.iloc[ind_ros,]<br/>y_train_ros=y_train[ind_ros]</span><span id="4d00" class="ks kt hi ko b fi ky kv l kw kx">#testing result <br/>clf_ros_new = tree.DecisionTreeClassifier(random_state=0,max_depth=5)<br/>clf_ros_new.fit(X_train_ros,y_train_ros)<br/>ros_new_y_pred=clf_ros_new.predict(X_test)<br/>print("confusion matrix:\n",confusion_matrix(y_test,ros_new_y_pred))<br/>print("Our new model's Testing recall: ",recall_score(y_test,ros_new_y_pred))<br/>print("Our new model's Testing accuracy: ",accuracy_score(y_test,ros_new_y_pred))</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/b5ea1be9d4a58fba448e184ecffc6e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*0rjG6QDTopyFSn-NEGbD_g.png"/></div></figure><p id="f27e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不错！我们的召回率从52%提高到了92%。我们的营销人员现在可以发现92%的用户会订阅，这与发现52%的用户会订阅相比是一个巨大的增长。我们可以看到准确性从92%下降到85%(这意味着将不订阅的用户归类为订阅者的用户增加了)。然而，在寻找用户如此重要，营销成本又相当低的情况下，新的模式会比原来的模式给公司带来更多的价值。</p><p id="be26" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">总之，在本文中，我们使用过采样来处理不平衡数据，并通过召回率而不是准确度来衡量我们的性能。我们修改了原始sci-kit学习包的交叉验证，以更好地预测我们的目标。为了进一步改进模型，您还可以尝试通过ROC曲线设置不同的阈值，以便模型可以帮助公司实现利润最大化。</p><p id="b87c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">就是这样。感谢您阅读文章！这个实现的python代码在<a class="ae iu" href="https://github.com/chenyuko/user-subscription-predict/blob/master/User_subscribe_prediction.ipynb" rel="noopener ugc nofollow" target="_blank">我的GitHub库</a>上。可以随意运用到自己的作品中，看看数据科学如何帮助你创造更多的价值！！</p></div></div>    
</body>
</html>