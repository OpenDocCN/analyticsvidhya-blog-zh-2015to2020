<html>
<head>
<title>Web Scraping Using Threading in Python Flask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python Flask中使用线程的Web抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-using-threading-in-python-flask-aad43edb44a8?source=collection_archive---------2-----------------------#2020-11-28">https://medium.com/analytics-vidhya/web-scraping-using-threading-in-python-flask-aad43edb44a8?source=collection_archive---------2-----------------------#2020-11-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/3d336e5916347d2eff7d1eef6cfeba2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4lf05yLLuu7ihAeo.jpg"/></div></figure><p id="c824" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你好！在这篇文章中，我将向您展示如何使用Python从文本中抓取和创建单词云。我将创建一个简单的Python Flask项目。</p><blockquote class="jk jl jm"><p id="d610" class="im in jn io b ip iq ir is it iu iv iw jo iy iz ja jp jc jd je jq jg jh ji jj hb bi translated">你可以在这里找到完整的代码:<a class="ae jr" href="https://github.com/minnela/WebScrapingAndThreading" rel="noopener ugc nofollow" target="_blank">https://github.com/minnela/WebScrapingAndThreading</a></p></blockquote><p id="027d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将去BBC新闻网站，删除该网站的所有新闻类别(体育，健康，艺术等。).然后，我们深入到每个类别，并获得它们的文本和内容。我们将所有类别的内容转换成文字云，并显示在我们的网页上。当你点击“云”这个词时，它会引导你进入该类别的网站。</p><p id="6177" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">词云:</strong> As <strong class="io hj"> </strong>谷歌称词云是“由特定文本或主题中使用的词组成的图像，其中每个词的大小表明其频率或重要性。”</p><h1 id="aa22" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">设置我们的环境</strong></h1><p id="5a9b" class="pw-post-body-paragraph im in hi io b ip kq ir is it kr iv iw ix ks iz ja jb kt jd je jf ku jh ji jj hb bi translated">我将在这个项目中使用Pycharm IDE。打开Pycharm并创建一个Flask项目:</p><p id="340e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">文件→新项目→烧瓶→创建</p><p id="a913" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">创建新的flask项目后，我们将导入<strong class="io hj"> request </strong>和<strong class="io hj"> BeautifulSoup </strong>库。<strong class="io hj">请求</strong>模块允许你使用Python发送HTTP请求。<strong class="io hj"> BeautifulSoup </strong>是用来从HTML文档中提取数据的库。</p><p id="83cd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">首先，我们将获得网站的html内容:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="d4a8" class="le jt hi la b fi lf lg l lh li">import requests<br/>from  bs4 import BeautifulSoup</span><span id="7aff" class="le jt hi la b fi lj lg l lh li">def getContentOfSite(url):<br/>    response = requests.get(url= url)<br/>    soup = BeautifulSoup(response.text, 'html.parser')<br/>    return soup</span></pre><p id="c793" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然后我们将在home()函数中使用BBC home网站创建categorySoup:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="1544" class="le jt hi la b fi lf lg l lh li">@app.route('/')<br/>def home():<br/>    i = 0<br/>    clouds=[]<br/>    categoriesSoup = getContentOfSite("https://www.bbc.com/")</span></pre><p id="0100" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们有了BBC新闻网站的内容。我们需要废弃所有类别，并创建一个类别链接列表和类别标题列表。要做到这一点，我们将去英国广播公司的网站，并做右键单击，检查网站。我们将在这里找到类别html部分。每个零件都有一个id。我们需要找到类别部分的id:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/dc26b8a72f5d9ad7d0201573f5b499b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*eQOiH2O5iw9ysG4Yn-crAg.png"/></div></div></figure><p id="a861" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">检查完HTML代码后，可以看到所有类别都定义在<strong class="io hj"> &lt;一个&gt; </strong>标签中。所以我们需要通过类别<strong class="io hj">&lt;&gt;</strong>id找到所有<strong class="io hj">&lt;&gt;</strong>元素。在找到所有<strong class="io hj"> &lt;一个&gt; </strong>元素后，我们需要提取类别url。为此，我们将所有<strong class="io hj">&lt;&gt;</strong>元素的<strong class="io hj"> href </strong>属性，并创建一个通用函数:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="3428" class="le jt hi la b fi lf lg l lh li">def getCategoryAndTitleList(categoriesSoup, id):<br/>    categoryList= []<br/>    categoryTitleList=[]<br/>    allCategories = categoriesSoup.find(id=id).find_all("a")<br/>    for category in allCategories:<br/>       categoryTitleList.append(category.string)<br/>       categoryList.append(category['href'])<br/>    return categoryList, categoryTitleList</span></pre><p id="e47f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们有了所有类别的url列表和它们的标题列表。我们需要去每个类别的网址，并获得他们的网站内容。为此，我们需要提取HTML内容中的<strong class="io hj"> &lt; p &gt; </strong>元素，然后将它们返回到文本中:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="b3d8" class="le jt hi la b fi lf lg l lh li">def parse_article(article_url):<br/>    print("Downloading {}".format(article_url))<br/>    soup= getContentOfSite(article_url)<br/>    ps=soup.find_all('p')<br/>    text= "\n".join(p.get_text() for p in ps)<br/>    return text</span></pre><p id="b164" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在得到所有类别的文本后，我们需要将文本转化为词云。为此，我们使用python的<strong class="io hj"> WordCloud </strong>库。要在访问者的浏览器中直接显示单词云图像，并作为HTML响应的一部分返回，我们可以使用<strong class="io hj"> base64 </strong>库。我们还将使用<strong class="io hj">字节数</strong>对象在内存中保存图像:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="68ab" class="le jt hi la b fi lf lg l lh li">from wordcloud import WordCloud<br/>import base64<br/>import io</span><span id="cfaa" class="le jt hi la b fi lj lg l lh li">def get_wordcloud(text):<br/>    pil_img = WordCloud()<br/>    wordCloud=pil_img.generate(text=text).to_image()<br/>    img= io.BytesIO()<br/>    wordCloud.save(img,"PNG")<br/>    img.seek(0)<br/>    img_b64=base64.b64encode(img.getvalue()).decode()<br/>    return img_b64</span></pre><p id="5888" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们有了一个通用的word cloud返回函数，我们可以完成我们的home函数，如下所示:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="d81c" class="le jt hi la b fi lf lg l lh li">@app.route('/')<br/>def home():<br/>    clouds=[]<br/>    categoriesSoup = getContentOfSite("https://www.bbc.com/")<br/>    categoryList, categoryTitleList = getCategoryAndTitleList(categoriesSoup,"orb-nav-links")<br/><br/>    for categoryLink in categoryList:<br/>        text = parse_article(categoryLink)<br/>        if(text != ''):<br/>           cloud = get_wordcloud(text)<br/>           clouds.append(cloud)</span><span id="ba20" class="le jt hi la b fi lj lg l lh li">    return render_template('home.html', clouds=clouds,<br/>categoryList=categoryList, categoryTitleList=categoryTitleList)</span></pre><p id="645b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们想返回一个HTML页面。我们将在我们的<strong class="io hj">home.html</strong>中使用<strong class="io hj"> Jinja </strong>模板来编写python代码。我们将展示类别标题、它们的文字云以及它们在文字云中的链接:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="5b45" class="le jt hi la b fi lf lg l lh li">&lt;p style="color:white;"&gt;Below you can see all the articles from BBC news. Just click a word cloud and start reading!&lt;/p&gt;<br/>   &lt;table&gt;<br/>   &lt;td&gt;<br/>{% set i = namespace(value=0) %}<br/>   {% for cloud in clouds %}<br/>       &lt;tr&gt;<br/>           &lt;th&gt; &lt;h1 style="color:white;"&gt;{{ categoryTitleList[i.value] }}&lt;/h1&gt;<br/>               &lt;/th&gt;<br/>           &lt;td&gt;<br/>       &lt;a href="{{categoryList[i.value]}}"&gt;&lt;img src="data:image/png;base64,{{cloud}}"&gt;&lt;/a&gt;<br/>        &lt;/td&gt;<br/>       &lt;/tr&gt;<br/>       {% set i.value = i.value + 1 %}<br/>    {% endfor %}<br/>   &lt;/td&gt;<br/>&lt;/table&gt;</span></pre><p id="57dc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我们准备运行我们的代码。但是当我们运行我们的代码时，我们会看到下载时间是如此之慢。提取网址并把它们变成图片需要一点时间。为了解决这个问题，我们将在python中使用<strong class="io hj">线程</strong>。</p><h1 id="1680" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">穿线</h1><p id="ab39" class="pw-post-body-paragraph im in hi io b ip kq ir is it kr iv iw ix ks iz ja jb kt jd je jf ku jh ji jj hb bi translated">线程化使多项工作能够在同一个处理环境中几乎同时完成。它是并行编程方法之一。线程通过缩短加载时间为我们提供了方便。</p><p id="c13e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">根据线程的工作逻辑，文字云和url链接可以混合定位。为了避免这种情况，我们将创建以下全局词典和列表。云词典会将每个云及其url保存在一起。类别字典将保留类别名称及其所属的url:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="58d9" class="le jt hi la b fi lf lg l lh li">categoryList= []<br/>categoryListInThreadOrder=[]<br/>categoryTitleListInThreadOrder=[]<br/>cloudListInThreadOrder=[]<br/>categorydict={}<br/>cloudDict ={}<br/>texts = []<br/>wordClouds = []</span></pre><p id="be31" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们将修改<strong class="io hj">getcategoryandtitllist()</strong>、<strong class="io hj"> parse_article() </strong>和<strong class="io hj"> get_wordcloud() </strong>函数，如下所示:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="ff12" class="le jt hi la b fi lf lg l lh li">def getCategoryAndTitleList(categoriesSoup, id):<br/>    allCategories = categoriesSoup.find(id=id).find_all("a")<br/>    for category in allCategories:<br/>            categoryTitleList.append(category.string)<br/>            categoryList.append(category['href'])<br/>            categorydict[category['href']]= category.string<br/>    return categoryList, categoryTitleList</span><span id="5751" class="le jt hi la b fi lj lg l lh li">def parse_article(url):<br/>    categoryListInThreadOrder.append(url)<br/>    print("Downloading {}".format(url))<br/>    soup= getContentOfSite(url)<br/>    ps=soup.find_all('p')<br/>    text= "\n".join(p.get_text() for p in ps)<br/>    texts.append(text)<br/>    get_wordcloud(text,url)</span><span id="633b" class="le jt hi la b fi lj lg l lh li">def get_wordcloud(text,url):<br/>      print(' Turning into word cloud')<br/>      pil_img = WordCloud()<br/>      wordCloud=pil_img.generate(text=text).to_image()<br/>      img= io.BytesIO()<br/>      wordCloud.save(img,"PNG")<br/>      img.seek(0)<br/>      img_b64=base64.b64encode(img.getvalue()).decode()<br/>      cloudDict[url] = img_b64<br/>      wordClouds.append(img_b64)</span></pre><p id="0167" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们将导入<strong class="io hj">线程</strong>库，转到<strong class="io hj"> home() </strong>函数并创建我们的线程:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="6dcc" class="le jt hi la b fi lf lg l lh li">import threading<br/>import time</span><span id="a259" class="le jt hi la b fi lj lg l lh li">@app.route('/')<br/>def home():<br/>    categoriesSoup = getContentOfSite("https://www.bbc.com/")<br/>    categoryList, categoryTitleList = getCategoryAndTitleList(categoriesSoup,"orb-nav-links")<br/><br/>    start = time.time()<br/>    threads = [threading.Thread(target=parse_article, args=(url,)) for url in categoryList]<br/>    for thread in threads:<br/>        thread.start()<br/>    for thread in threads:<br/>        thread.join()<br/>print("Elapsed Time: %s" % (time.time() - start))</span></pre><p id="6bc8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们为两个重要的函数创建了两个线程列表。我们把我们的目标函数，我们开始一个接一个的线程。</p><p id="9fbd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们进行最后一步，给我们的home.html打电话。我们需要给我们的云，网址和标题排序，所以我们在<strong class="io hj"> home() </strong>函数中填充我们的线程列表。我们将按主题顺序获取URL，然后从字典中提取URL的云和标题:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="440c" class="le jt hi la b fi lf lg l lh li">for categoryLink in categoryListInThreadOrder:<br/>  try:<br/>       categoryTitle = list(categorydict.values())[list(categorydict.keys()).index(categoryLink)]<br/>       cloud = list(cloudDict.values())[list(cloudDict.keys()).index(categoryLink)]<br/>       categoryTitleListInThreadOrder.append(categoryTitle)<br/>       cloudListInThreadOrder.append(cloud)<br/>  except:<br/>      print(categoryLink, " is not in List.")</span><span id="a38f" class="le jt hi la b fi lj lg l lh li">return render_template('home.html', clouds=cloudListInThreadOrder, categoryList=categoryListInThreadOrder, categoryTitleList=categoryTitleListInThreadOrder)</span></pre><p id="75cf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们的应用程序变得更快了。让我们运行代码:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lp"><img src="../Images/b27d31c1f12f4e877c11218f0efa8cc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Mgrspb0VfpvKu2pYdb4Kg.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/f0a4562d2521025b5982d5c82834cc27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K1BV8EiXSickxxGkSzcwUA.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lr"><img src="../Images/ef41c3267d1aac34c30c0d44133964f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mfYTkB1M54UeC281EziMag.png"/></div></div></figure><p id="47c2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">感谢阅读:)</strong></p></div></div>    
</body>
</html>