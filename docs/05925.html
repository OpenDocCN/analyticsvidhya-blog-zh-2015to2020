<html>
<head>
<title>Twitter Sentiment Analysis: Using PySpark to Cluster Members of Congress</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter情绪分析:使用PySpark对国会议员进行聚类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/congressional-tweets-using-sentiment-analysis-to-cluster-members-of-congress-in-pyspark-10afa4d1556e?source=collection_archive---------3-----------------------#2020-05-06">https://medium.com/analytics-vidhya/congressional-tweets-using-sentiment-analysis-to-cluster-members-of-congress-in-pyspark-10afa4d1556e?source=collection_archive---------3-----------------------#2020-05-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a109" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我之前的项目中使用了相当多的Python，我想处理一个大型数据集，这需要PySpark的并行计算能力。我在美国国会议员发的推特上发现了一个很大的数据集，看起来很有趣，我想到了一个主意…</p><p id="62da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我假设的客户:<br/> 我正在帮助游说者4America通过他们的推文更好地了解国会议员之间的关系:数据集由2008年至2017年间发送的推文组成。目的是利用这些情报帮助他们更好地瞄准客户在国会的游说活动。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/ec84b0cb88ab0bd6504c409508fc14bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sYZYkrtR1BlyNgmY_M2mYQ.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">这些国会议员中谁最像？</figcaption></figure><p id="2152" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">假设:<br/> </strong> 1。将会有一群志同道合的政治家，他们可以很大程度上按照党派划分。<br/> 2。在这些集群中会有客户可以瞄准的影响力中心(响亮/有影响力的声音)。<br/> 3。在这段时间里，一些主题会变得更加热门</p><p id="4c50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">做法:</strong> <br/> 1。导入数据并进行EDA。<br/> 2。主题提取:单词袋<br/> 3。实体识别:Spark-NLP <br/> 4。情感分析:使用文本块进行情感评分<br/> 5。Spark-ML聚集志同道合的成员。</p><h1 id="7ba9" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">第一步:导入数据，进行EDA。</strong></h1><p id="4664" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">导入Python库</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="8031" class="lb ju hi kx b fi lc ld l le lf">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><p id="0944" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">导入Spark函数和Spark-NLP，在构建SparkSession的过程中，确保Spark-NLP jars文件可以在我们的模块中找到(我发现我必须这样做，否则会出现没有找到模块的错误)</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="5d6f" class="lb ju hi kx b fi lc ld l le lf">import sparknlp<br/>from pyspark.sql import SparkSession<br/>spark = SparkSession.builder \<br/>    .master("local[4]")\<br/>    .config("spark.driver.memory","4G")\<br/>    .config("spark.driver.maxResultSize", "2G") \<br/>    .config("spark.jars.packages", "com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.5")\<br/>    .config("spark.kryoserializer.buffer.max", "1G")\<br/>    .getOrCreate()<br/>from sparknlp.pretrained import PretrainedPipeline<br/>from pyspark.sql.functions import from_unixtime, to_date, year, udf, explode, split, col, length, rank, dense_rank, avg, sum<br/>from pyspark.sql.window import Window</span></pre><p id="367b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark ML将在以后应用聚类时使用</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="4644" class="lb ju hi kx b fi lc ld l le lf">from pyspark.ml.linalg import Vectors<br/>from pyspark.ml.feature import VectorAssembler, StandardScaler<br/>from pyspark.ml.stat import Correlation<br/>from pyspark.ml.clustering import BisectingKMeans<br/>from pyspark.ml.evaluation import ClusteringEvaluator<br/>from pyspark.ml import Pipeline<br/>from pyspark.ml.tuning import CrossValidator, ParamGridBuilder</span></pre><p id="6ff0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将实现的NLP库:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="7245" class="lb ju hi kx b fi lc ld l le lf">import nltk<br/>from nltk.corpus import stopwords<br/>from collections import Counter<br/>from wordcloud import WordCloud</span><span id="0127" class="lb ju hi kx b fi lg ld l le lf">from textblob import TextBlob</span></pre><p id="b378" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">将数据导入Spark数据框:</strong></p><p id="4667" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将JSON文件作为Spark数据帧读取是相对简单的，尽管在处理数据帧时需要考虑一些因素以实现更高效的处理。<br/> 1。Spark数据帧应被分割成2-3倍于CPU或集群中可用线程数的分区。我的机器有4个逻辑核心，所以我选择了3x，即。12个分区，基于实验。<br/> 2。然后我缓存了这些表(‘persist’)，以提高以后的查询性能:您可以检查Spark GUI的Storage选项卡，每个文件确实缓存了12个分区。<br/> 3。Shuffle Read partitions参数默认为200，我们不希望这成为瓶颈，所以我们使用spark.sql.shuffle.partitions将它设置为等于数据中的分区。这将特别有助于稍后可能执行的广泛的Shuffle转换(例如GROUP BY或ORDER BY)。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="2b8b" class="lb ju hi kx b fi lc ld l le lf"># Tweets<br/>tweets = spark.read.json('../Lobbyists4America1/US_PoliticalTweets/tweets.json').repartition(12).persist()</span><span id="2f51" class="lb ju hi kx b fi lg ld l le lf"># Users<br/>users = spark.read.json('../Lobbyists4America1/US_PoliticalTweets/users.json').repartition(12).persist()</span></pre><p id="0f85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用Spark-SQL创建数据的不同部分，以便更好地理解它。与我的假设相关的一个观察结果是，很少有会员在Twitter上拥有大量追随者，这些追随者会是我客户政策的有力支持者</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lh"><img src="../Images/1d1491f268df5f9981a6db6ec14338e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KxfbkJG5edbMBnYkn6RX7Q.png"/></div></div></figure><p id="21b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">即…</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="39d3" class="lb ju hi kx b fi lc ld l le lf">+------------------+---------------+<br/>|              name|followers_count|<br/>+------------------+---------------+<br/>|   Donald J. Trump|       31712585|<br/>|   President Trump|       18545354|<br/>|    Bernie Sanders|        5072538|<br/>|       Cory Booker|        3094413|<br/>|       Marco Rubio|        2554822|<br/>|  Elizabeth Warren|        2412087|<br/>|       John McCain|        2274034|<br/>|      Nancy Pelosi|        1126205|<br/>|       Jerry Brown|        1119275|<br/>|  Senator Ted Cruz|         960413|<br/>| Governor Christie|         869256|<br/>|       John Kasich|         755475|<br/>|     Chuck Schumer|         591618|<br/>| Senator Tim Kaine|         553125|<br/>|        Trey Gowdy|         552930|<br/>|        John Lewis|         512433|<br/>|Kirsten Gillibrand|         396587|<br/>|     Maxine Waters|         379015|<br/>|          Mike Lee|         314821|<br/>|Rep. Keith Ellison|         313271|<br/>+------------------+---------------+<br/>only showing top 20 rows</span></pre><h1 id="3d4c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">第二步:主题提取:词汇袋</h1><p id="5cbd" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">在快速浏览了数据和一些描述性的统计数据之后，我想更深入一点，理解主题是什么。</p><ol class=""><li id="58df" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated">NLTK有一个停用词语料库，我下载了它来帮我从推文中删除它们。</li><li id="1799" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">Spark RDDs可以被操纵，这样我们就可以从一组文档/tweet中获得字数:使用flatMap、reduceByKey和sort。</li><li id="f5e5" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">然后，我把它输入到WordCloud中，以便在数据集中显示每年的情况</li></ol><p id="bf9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lw">注意:我关注的是2013年以后的数据，因为他们有足够大的样本量</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lx"><img src="../Images/e0d671812e6909836e967fdaa6d58bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*U6uVjyRMf7cfXbTUFoeTMg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lx"><img src="../Images/88820ad28d260350749407dba8d581d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*vBuEqD9wzYe5HIUg4Q9WSA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lx"><img src="../Images/60bb15addd3adc97c096ca09063e8854.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*k1Y2NydO1NuuKDWxD4QMeg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lx"><img src="../Images/1b94378cbcb6e80ccf66547b5cd5bebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*A974frtjB7t-NEM8SwPZTw.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lx"><img src="../Images/6c4b87f55ca6574cc1a5b4500cf1cf67.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*Sy6APeunpX3xV9j8LzvNWQ.png"/></div></div></figure><h1 id="07e7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">步骤3:实体识别:Spark-NLP</h1><p id="dd83" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">单词袋方法的问题是有许多单词不构成主题或主题，所以我将上面生成的语料库输入到Spark-NLP的预训练管道中，并从本质上询问它每个单词是否是一个实体。<br/>在这个清理过的语料库上重现文字云，可以更清晰地看到此时的热门话题:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/800aaa8dfae3524ccbb09a2722836597.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*8kqN5019YPbo9R8mAU1bVA.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/a43c0407fe30979e18e157dc05da810a.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*Cav5X0aVZEDx2l3j9Bhahg.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/59109c20c79f8d1fd5d82fa954f29676.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*kEkl5p_QdIh54MKk_dLNzA.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/693d1b5d9e8cb5cb21cb2ad574c80e7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*mT8ql3Dtyo2rbiHhxXmnuQ.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/4a9edc58654ce92c26c5e31e39223b6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*JiJE2AaohfbQB_bIQzBLow.png"/></div></figure><p id="a488" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一步让我对自己的旅行方向有了一些安慰:我将把医疗保健作为分析的主题…</p><h1 id="110a" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">步骤4:情感分析:使用TextBlob进行情感评分</h1><p id="81ff" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">使用TextBlob为每条推文分配情感分数非常简单，只需3行代码，不到一秒钟就可以运行整个数据集:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="a055" class="lb ju hi kx b fi lc ld l le lf">sentiment = udf(lambda x: TextBlob(x).sentiment[0])<br/>spark.udf.register(“sentiment”, sentiment)<br/>tweets = tweets.withColumn(‘sentiment’,sentiment(‘text’).cast(‘double’))</span></pre><p id="0730" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我观察了情绪和推文数量的总体趋势。使用90天的每日移动平均线，我们可以看到，从2013年起，Twitter作为国会议员沟通的媒介开始受到欢迎。有趣的是，在2016年底出现了非常大的增长:这可能与特朗普在推特上的高参与度有关，以及其他政客似乎对他的策略做出了回应，并增加了他们自己在推特上的存在。这种增长伴随着情绪的轻微下降，我们可以推断推文在语气上开始变得更具对抗性吗？</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/a2336cdce4aaf410a333deb49587d8a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*X-E3WeDWIdV5o1Eo5eUFfA.png"/></div></figure><p id="b88b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看包含“奥巴马医改”的推文，我们看到一个有趣的趋势:在2013年，这些推文的数量真的开始急剧上升，并在2014年急剧下降，这是一种故意的策略吗？有趣的是:在这一过程中，情绪下降到中性，看起来如果你在推特上谈论“奥巴马医改”而不是“ACA ”,那么你可能会对它持负面态度。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/71f5e7044d24634f6b77b69cdf8b5f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*5q7wASxjngGnRN3TVXz9Vw.png"/></div></figure><p id="3283" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看看那些倾向于使用“奥巴马医改”的议员就可以证明这一点:他们是共和党人。<br/>另一件有趣的事情是:“奥巴马医改”人气的下降也是这次整体人气下降的原因吗？<br/>按主题解释情绪的整体变化可能是一种有趣的方式，可以揭示整体趋势，或许可以在主题层面上创建某种加权情绪衡量指标:但那是另一个时间了(与我的假设无关)。</p><h1 id="fa0c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">步骤5: Spark-ML聚集志同道合的成员</h1><p id="8814" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">专注于医疗保健，我想得到一个更微妙的想法，志同道合和同样充满活力的国会议员。很容易将他们分为研究和开发，但如果你想知道哪些国会议员对这个话题持有最强烈的观点，以及他们中的哪些人也受到这个问题的激励而在Twitter上积极讨论这个问题，会怎么样呢？这对游说者来说是有价值的情报。因此，我使用Spark-ML的无监督学习模型(即平分K-Means)来创建这些集群，这些集群基于包含“ACA”或“奥巴马医改”的推文中的推文数量和成员表达的情绪</p><ol class=""><li id="68e7" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated">用于创建功能列的VectorAssembler</li><li id="dad3" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">将StandardScaler应用于所述特征列</li><li id="49ff" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">通过迭代不同的选项并使用剪影分数进行评估，在平分K-Means中优化K。</li><li id="873d" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">选择k=6，因为它的得分最高:0.502</li><li id="9c39" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">散点图…</li></ol><p id="2ace" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我选择在每一点上标注会员的名字，以及该会员基于关注者数量的排名。因此，根据追随者的数量，科里·布克似乎是他的团队中最有影响力的成员，他在Twitter上的追随者数量在所有国会议员中排名第四。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/68c273e1350744d087004ca4e16e36dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KsZB4vDjqF9guvkohRjT9w.png"/></div></div></figure><h1 id="aefc" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论</h1><ol class=""><li id="2c41" class="li lj hi ih b ii kr im ks iq mc iu md iy me jc ln lo lp lq bi translated">非常有趣的是，我们看到了基于医疗改革观点/观点力度的分类。这些聚类似乎有意义，给了我们一个比共和党和民主党更微妙的视角。</li><li id="99de" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">在这里，我们现在有6个志同道合(情绪)的成员集群，他们也受到手头问题的类似激励(num_tweets)。</li><li id="6c62" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">绿色集群似乎高度反对奥巴马医改，其中李政颖似乎拥有最多的追随者，在这个问题上也非常直言不讳。</li><li id="4459" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">红色群组的情绪更加消极，尽管他们发微博的次数比绿色群组的人少得多。这可能与样本规模有关:样本规模越小，越容易受到情绪极端化的影响，而样本规模越大，越倾向于中性。这是我在不同的数据切片中看到的:你越缩小，情绪就越中立。</li></ol><h1 id="21e0" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">假设:结论</h1><ol class=""><li id="dfba" class="li lj hi ih b ii kr im ks iq mc iu md iy me jc ln lo lp lq bi translated">将会有一群志同道合的政治家，他们可以很大程度上按照党派划分。<br/> 正确</li><li id="e251" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><strong class="ih hj">在这些集群中会有客户可以瞄准的影响力中心(响亮/有影响力的声音)。<br/> </strong>正确</li><li id="7818" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><strong class="ih hj">在这段时间里，一些主题会变得更加热门<br/> </strong>对吗</li></ol><h1 id="8729" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">潜在的后续步骤</h1><p id="c7a2" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我利用政治家们对两个不同主题的观点创建了这些集群:ACA和奥巴马医改，在外交政策、能源或税收改革问题上，有可能创建不同的集群。或者甚至是一组不同问题的集群:看看哪些成员在总体上是志同道合的，而不仅仅是在特定问题上…这可能导致我们推断…“如果政治家A在这个问题上和政治家B一样，那么他们也可能在这个问题上改变立场”</p><p id="5344" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢阅读，对于那些感兴趣的人…你可以在我的GitHub上找到代码，对这位崭露头角的数据科学家的任何反馈都将不胜感激！</p><div class="mf mg ez fb mh mi"><a href="https://github.com/noahberhe/Lobbyists4America" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hj fi z dy mn ea eb mo ed ef hh bi translated">Noah berhe/说客4America</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">使用Pyspark，Spark-NLP在JSON文件上发布情绪分析，帮助游说者4America了解关系…</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">github.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw jn mi"/></div></div></a></div></div></div>    
</body>
</html>