<html>
<head>
<title>Talented Mr. 1X1: Comprehensive look at 1X1 Convolution in Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">天才1X1先生:全面看深度学习中的1X1卷积</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578?source=collection_archive---------1-----------------------#2020-01-13">https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578?source=collection_archive---------1-----------------------#2020-01-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ih ii ij ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ig"><img src="../Images/8f36c0a2f88d490418b83da2b2e93fb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FwVCIY2gjUFONU4tTiu89g.png"/></div></div><figcaption class="ir is et er es it iu bd b be z dx translated">图片取自此<a class="ae iv" href="https://vimeo.com/274236414" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><p id="e8d7" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi ju translated"><span class="l jv jw jx bm jy jz ka kb kc di"> W </span>随着2012年AlexNet的惊人成功，卷积神经网络(CNN)革命已经开始！深度学习中基于CNN的框架，如GoogleNet、ResNet以及这些框架的几种变体，已经在计算机视觉中的对象检测和语义分割方面显示出惊人的结果。</p><p id="bdaf" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">当你开始查看大多数成功的现代CNN架构时，如GoogleNet、ResNet和SqueezeNet，你会发现1X1卷积层起着主要作用。乍一看，使用单个数字与输入图像进行卷积似乎没有意义(毕竟所有更宽的滤波器，如3X3、5X5，都可以处理图像的一部分，而不是这种情况下的单个像素)。然而，1X1卷积已被证明是非常有用的工具，如果使用正确，将有助于创建非常深刻的架构。</p><p id="1b9a" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">在本文中，我们将详细了解1X1卷积</p><p id="1f73" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">首先快速回顾一下深度学习中的卷积。有许多好的博客和文章直观地解释了什么是卷积以及卷积的不同类型(参考资料中很少列出)。虽然我们不会在本文中深入研究卷积，但理解几个关键点将使我们更容易理解1X1卷积在做什么，最重要的是它是如何做的以及为什么要做。</p><h2 id="6ceb" class="kd ke hi bd kf kg kh ki kj kk kl km kn jh ko kp kq jl kr ks kt jp ku kv kw kx bi translated"><strong class="ak"> <em class="if">快速回顾:深度学习中的卷积</em> </strong></h2><p id="8404" class="pw-post-body-paragraph iw ix hi iy b iz ky jb jc jd kz jf jg jh la jj jk jl lb jn jo jp lc jr js jt hb bi translated">如上所述，本文不会提供卷积的理论和实践的完整处理。然而，我们将重述深度学习中卷积的关键原理。当我们深入研究1X1卷积时，这将派上用场。</p><p id="a1e8" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">简而言之，卷积是输入和内核/滤波器元素的逐元素乘法和求和。现在要记住的数据点</p><p id="e4e5" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> 1。</strong> <em class="ld">输入矩阵可以并且在大多数情况下会有不止一个通道</em>。这有时被称为<strong class="iy hj"> <em class="ld">深度</em> </strong></p><p id="1070" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">a.<strong class="iy hj"> <em class="ld">示例</em> </strong>:图像的64X64像素RGB输入有3个通道，因此输入为64X64X3</p><p id="e9ab" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">2.<strong class="iy hj"> <em class="ld">过滤器与输入</em> </strong>具有相同的深度，除了一些特殊情况(例如3D卷积重建医学图像)。由于某些未知的原因，这一点在大多数文献中没有明确提及，导致了一些误解(特别是对于卷积、深度学习等的新手)</p><p id="7347" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">a.<strong class="iy hj"> <em class="ld">例如:</em></strong>3x 3的滤波器也有3个通道，因此滤波器应该表示为3X3X3</p><p id="3286" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ld"> 3。</em> </strong>第三个和临界点，<strong class="iy hj"> <em class="ld">卷积步长的输出深度等于我们选择的滤波器数量。</em> </strong></p><p id="7ff4" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">a.<strong class="iy hj"> <em class="ld">示例:</em></strong>3D输入(64X64X3)的卷积步骤的输出和我们选择的过滤器(3X3X3)的深度为1(因为我们只有一个过滤器)</p><p id="d24b" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">过滤器大小为3X3X3的3D输入64X64X3的卷积步骤将使过滤器沿着输入的宽度和高度“滑动”。</p><figure class="lf lg lh li fd ik er es paragraph-image"><div class="er es le"><img src="../Images/f1c0d4a4dd2bca7fee22a1b80bc30f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*R7zg6SANyYP45bW5f0QrBQ.png"/></div><figcaption class="ir is et er es it iu bd b be z dx translated">图片取自此<a class="ae iv" href="https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610" rel="noopener" target="_blank">链接</a></figcaption></figure><p id="7f1f" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">因此，当我们<em class="ld">用3D图像卷积</em>3D过滤器时，该操作在2个方向(沿着宽度和高度)上移动输入上的过滤器，并且我们在每个位置进行逐元素乘法和加法，以深度为1的输出结束。</p><figure class="lf lg lh li fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lj"><img src="../Images/94af0667e9c47087cf178a3a34b3eaab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ye4dZh0XdiuNhR7QsNUhzA.png"/></div></div><figcaption class="ir is et er es it iu bd b be z dx translated">图片取自此<a class="ae iv" href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215" rel="noopener" target="_blank">链接</a></figcaption></figure><p id="eaf4" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">有了这些，我们就可以开始1X1卷积了</p><h2 id="b6d7" class="kd ke hi bd kf kg kh ki kj kk kl km kn jh ko kp kq jl kr ks kt jp ku kv kw kx bi translated"><strong class="ak"> <em class="if"> 1X1卷积——是什么？</em> </strong></h2><p id="25ab" class="pw-post-body-paragraph iw ix hi iy b iz ky jb jc jd kz jf jg jh la jj jk jl lb jn jo jp lc jr js jt hb bi translated">在林敏等人的论文中首先介绍了在网络  中的<a class="ae iv" href="https://arxiv.org/pdf/1312.4400.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iy hj"> <em class="ld">网络，1X1卷积层用于“跨通道下采样”或跨通道汇集。换句话说，1X1 Conv用于减少通道数量，同时引入非线性。</em></strong></a></p><p id="907b" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">在1X1卷积中，简单地说就是滤波器的大小为1X1(是的，这意味着是一个单一的数字，而不是矩阵形式，比如3X3滤波器)。这个1X1滤波器将逐个像素地对整个输入图像进行卷积。</p><p id="125e" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">继续我们的示例输入64X64X3，如果我们选择1X1滤波器(即1X1X3)，那么输出将具有与输入相同的高度和重量，但只有一个通道，即64X64X1</p><p id="4fcd" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">现在考虑具有大量通道的输入，例如192个。如果我们想要减少深度，但保持特征图(感受野)的<em class="ld">高度X宽度</em>不变，那么我们可以选择1X1滤波器(记住滤波器数量=输出通道)来实现这种效果。这种跨通道下采样的效果被称为“降维”。</p><figure class="lf lg lh li fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lk"><img src="../Images/32277f7a11174fa06b2fe9a1899835ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dNaikOfrGzUaJ2EzRIl4tw.png"/></div></div><figcaption class="ir is et er es it iu bd b be z dx translated">图片取自此<a class="ae iv" href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215" rel="noopener" target="_blank">链接</a></figcaption></figure><p id="6ea5" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">为什么我们会想要这样的东西呢？为此，我们深入研究1X1卷积的用法</p><p id="01e1" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ld">用法1:降维/增维</em> </strong></p><p id="d3e4" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">ils vrc<em class="ld">(</em><a class="ae iv" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"><em class="ld">ImageNet大规模视觉识别竞赛</em> </a> ) 2014、<a class="ae iv" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank"><strong class="iy hj"><em class="ld">GoogleNet</em></strong></a><strong class="iy hj"><em class="ld">，使用</em> </strong> 1X1卷积层进行<strong class="iy hj"><em class="ld"/></strong>“计算昂贵的3×3和5×5卷积之前的缩减量”</p><p id="f223" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">让我们看一个例子来理解降维将如何减少计算量。假设我们需要用5×5×32个过滤器卷积28×28×192个输入特征图。<strong class="iy hj">这将导致<em class="ld">12042.2万次操作</em> </strong></p><figure class="lf lg lh li fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ll"><img src="../Images/dd52c6b0bb92c6fcc6630a438d02cc70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3kgQ1HJvVOGK_LWS_ANoBA.png"/></div></div></figure><p id="fb66" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">让我们用相同的输入要素地图做一些数学运算，但是在5 X 5 conv图层之前使用1X1 Conv图层</p><figure class="lf lg lh li fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lm"><img src="../Images/f4ff6c4d2616c92ed82cd8c50eb5414d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C2ei51Og0WMpoEesMFEvcA.png"/></div></div></figure><p id="8336" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><em class="ld">通过在5X5 Conv之前增加1X1 Conv图层，同时保持特征图的高度和宽度，我们将</em> <strong class="iy hj"> <em class="ld">的运算次数减少了10倍</em> </strong> <em class="ld">。这将减少计算需求，从而提高效率。</em> </p><p id="3afa" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">GoogleNet论文将该模块描述为“<strong class="iy hj"> <em class="ld">盗梦空间模块</em> </strong>”(明白了——电影《盗梦空间》中迪卡普里奥的《我们需要更深入》)</p><figure class="lf lg lh li fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ll"><img src="../Images/d6adf28fcd75076882c6b0be36d9aa52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O3wWIIX1WtiAGwquoL2kAw.png"/></div></div></figure><h2 id="298e" class="kd ke hi bd kf kg kh ki kj kk kl km kn jh ko kp kq jl kr ks kt jp ku kv kw kx bi translated"><strong class="ak"> <em class="if">用法二:构建更深层次的网络(“瓶颈”层)</em> </strong></h2><p id="fe22" class="pw-post-body-paragraph iw ix hi iy b iz ky jb jc jd kz jf jg jh la jj jk jl lb jn jo jp lc jr js jt hb bi translated">2015年ILSVRC分类冠军，<a class="ae iv" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="iy hj"><em class="ld">ResNet</em></strong></a><strong class="iy hj"><em class="ld">，</em> </strong>的错误率最低，并通过使用“残余连接”和“瓶颈层”的非常深的网络横扫对手。</p><p id="fef7" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">在他们的论文中，他等人解释了(第6页)瓶颈层如何使用3个卷积层的序列来设计<strong class="iy hj"> <em class="ld">，这些卷积层分别具有1X1、3X3和1X1大小的滤波器，以减少和恢复维度</em> </strong>。输入的下采样发生在1×1层，从而为3×3 conv汇集了更小的特征向量(减少了参数数量)。紧接着，1X1层恢复尺寸以匹配输入尺寸，因此可以直接使用标识快捷方式。关于身份快捷方式和跳过连接的细节，请看ResNet上的一些评论(或者可以等我以后的作品！)</p><figure class="lf lg lh li fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ln"><img src="../Images/d39748f894dce3bfbeca43334b911b5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Unx7sioMBJXPT6otlYY5ww.png"/></div></div><figcaption class="ir is et er es it iu bd b be z dx translated">图片取自此<a class="ae iv" href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><h2 id="b7be" class="kd ke hi bd kf kg kh ki kj kk kl km kn jh ko kp kq jl kr ks kt jp ku kv kw kx bi translated"><strong class="ak"> <em class="if">用法3:较小但精确的模型(“火模块”层)</em> </strong></h2><p id="b996" class="pw-post-body-paragraph iw ix hi iy b iz ky jb jc jd kz jf jg jh la jj jk jl lb jn jo jp lc jr js jt hb bi translated">虽然深度CNN模型具有很高的准确性，但它们需要处理数量惊人的参数，这增加了训练时间，最重要的是需要企业级的计算能力。Iandola等人都提出了一个名为<a class="ae iv" href="https://openreview.net/pdf?id=S1xh5sYgx" rel="noopener ugc nofollow" target="_blank"><strong class="iy hj"><em class="ld">SqueezeNet</em></strong></a><strong class="iy hj"><em class="ld"/></strong>的CNN模型，它保留了AlexNet级别的精度，而在参数方面却小了50倍。</p><p id="9809" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">较小的模型有许多优势，特别是在需要边缘计算能力的用例上，如自动驾驶。伊恩多拉等人通过堆叠一堆“<strong class="iy hj"> <em class="ld">”火模块</em> </strong>”实现了这一点，这些模块包括</p><p id="711c" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">1.<em class="ld">挤压层</em>只有1X1个Conv滤镜</p><p id="04bc" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">2.这为一个混合了1X1和3X3滤镜的<em class="ld">扩展层</em>提供了素材</p><p id="4742" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">3.挤压层中的滤镜数量设置为小于1X1滤镜数量+扩展层中的3X3滤镜数量</p><p id="051b" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">到目前为止，<em class="ld">挤压层</em>中的1X1 Conv滤波器的作用是显而易见的——它们通过在输入通道进入<em class="ld">扩展层之前对其进行“下采样”来减少参数数量。</em></p><p id="818c" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><em class="ld">扩展层</em>混合了1X1和3X3滤镜。如您所知，1X1滤镜执行交叉通道池，即合并通道，但无法检测空间结构(通过处理单个像素，而不是像较大的滤镜那样处理一片输入)。3×3卷积检测空间结构。<em class="ld">通过组合这两个不同大小的过滤器，模型在较小的参数下运行时变得更有表现力</em>。填充的适当使用使得1X1和3X3卷积的输出具有相同的大小，因此它们可以被堆叠。</p><figure class="lf lg lh li fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lo"><img src="../Images/0a7538bfa7cca6063e5b4febe6224a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a8En3QXSfOHznbYhFquwVw.png"/></div></div></figure><h2 id="ebbe" class="kd ke hi bd kf kg kh ki kj kk kl km kn jh ko kp kq jl kr ks kt jp ku kv kw kx bi translated"><strong class="ak"> <em class="if">结论</em> </strong></h2><p id="dbc1" class="pw-post-body-paragraph iw ix hi iy b iz ky jb jc jd kz jf jg jh la jj jk jl lb jn jo jp lc jr js jt hb bi translated">在本文中，我们回顾了高级卷积机制，并深入研究了1X1卷积，以了解其基础、有效用途和目的。</p><p id="57d4" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">概括地说，1X1卷积有效地用于</p><p id="ab51" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">1.维数减少/增加</p><p id="82aa" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">2.通过减少参数映射来减少计算量</p><p id="23af" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">3.向网络添加额外的<strong class="iy hj"> <em class="ld">非线性</em> </strong></p><p id="39e5" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">4.通过“瓶颈”层创建更深的网络</p><p id="ae03" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">5.创建更小的CNN网络，保持更高的精确度</p><h2 id="da8b" class="kd ke hi bd kf kg kh ki kj kk kl km kn jh ko kp kq jl kr ks kt jp ku kv kw kx bi translated"><strong class="ak"> <em class="if">参考文献</em> </strong></h2><p id="a39d" class="pw-post-body-paragraph iw ix hi iy b iz ky jb jc jd kz jf jg jh la jj jk jl lb jn jo jp lc jr js jt hb bi translated"><strong class="iy hj"> <em class="ld"> 1。</em> </strong> <strong class="iy hj"> <em class="ld">吴恩达的视频对1X1卷积</em> </strong></p><p id="4a65" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae iv" href="https://www.coursera.org/lecture/convolutional-neural-networks/networks-in-networks-and-1x1-convolutions-ZTb8x" rel="noopener ugc nofollow" target="_blank"><strong class="iy hj"><em class="ld">https://www . coursera . org/lecture/convolution-neural-networks/networks-in-networks-and-1x1-convolutions-ZTb8x</em></strong>T5】</a></p><p id="8802" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ld"> 2。</em> </strong> <a class="ae iv" href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215" rel="noopener" target="_blank"> <strong class="iy hj"> <em class="ld">全面介绍深度学习中不同类型的卷积</em> </strong> </a></p><p id="12e5" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ld"> 3。</em> </strong> <a class="ae iv" href="https://towardsdatascience.com/neural-network-architectures-156e5bad51ba" rel="noopener" target="_blank"> <strong class="iy hj"> <em class="ld">神经网络架构</em> </strong> </a></p><p id="371d" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ld"> 4。</em> </strong> <a class="ae iv" href="https://arxiv.org/pdf/1312.4400.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iy hj"> <em class="ld">网络中的网络</em> </strong> </a> <strong class="iy hj"> <em class="ld"> —林敏等人所有</em> </strong></p><p id="f666" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ld"> 5。</em></strong><a class="ae iv" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank"><strong class="iy hj"><em class="ld"/></strong></a><strong class="iy hj"><em class="ld">—克里斯蒂安·塞格迪等人</em> </strong></p><p id="9cf7" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj">6<em class="ld">。</em> </strong> <a class="ae iv" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iy hj"> <em class="ld">用于图像识别的深度残差学习</em> </strong> </a> <strong class="iy hj"> <em class="ld"> —何等人所有</em> </strong></p><p id="ab39" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ld"> 7。</em></strong><a class="ae iv" href="https://openreview.net/pdf?id=S1xh5sYgx" rel="noopener ugc nofollow" target="_blank"><strong class="iy hj"><em class="ld">SqueezeNet</em></strong></a><strong class="iy hj"><em class="ld">—林依安多拉等人所有</em> </strong></p><p id="e3e7" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ld"> 8。</em> </strong> <a class="ae iv" href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iy hj"> <em class="ld"> CNN架构—第九讲</em> </strong> </a> <strong class="iy hj"> <em class="ld">(斯坦福) :林等人所有</em> </strong></p><p id="cf2f" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae iv" href="https://arxiv.org/abs/1510.00149" rel="noopener ugc nofollow" target="_blank"> <strong class="iy hj"> <em class="ld"> 9。深度压缩:通过剪枝、训练量化和霍夫曼编码对深度神经网络进行压缩</em> </strong> </a> <strong class="iy hj"> <em class="ld">宋涵等所有</em> </strong></p></div></div>    
</body>
</html>