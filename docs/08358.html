<html>
<head>
<title>(Part 4)The goblet of Convolutional- Neural Network(CNN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">(第四部分)卷积神经网络(CNN)的酒杯</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/part-4-the-goblet-of-convolutional-neural-network-cnn-d640aa2c915d?source=collection_archive---------21-----------------------#2020-07-26">https://medium.com/analytics-vidhya/part-4-the-goblet-of-convolutional-neural-network-cnn-d640aa2c915d?source=collection_archive---------21-----------------------#2020-07-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7db7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们先玩一个小时候的游戏。</p><p id="0bda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑下面的两幅图像，并尝试将第一幅图像中的字符与第二幅图像中的字符进行匹配。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/d1028bc72fcfe77a3eee5ea2bd25853a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*psFhJaKAM8il12QbuTcT2g@2x.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片:<a class="ae jt" href="https://twitter.com/Igot7Linn" rel="noopener ugc nofollow" target="_blank"> Igot7Linn </a></figcaption></figure><p id="f04b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完成这个<em class="ju">分类</em>的练习后，你一定已经学会了每个角色的<em class="ju">特征</em>比如发型、眼睛颜色、眼睛形状等。使用你的<em class="ju">神经元</em>。事实证明，现代计算机以类似的方式对各种图像进行分类。而那背后的算法就是<strong class="ih hj"> <em class="ju">卷积神经网络</em> </strong> <em class="ju">，又名</em> <strong class="ih hj"> <em class="ju"> CNN </em> </strong>。</p><p id="95db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">想了解更多，跳上我的火车，你会在4号站下车:CNN 。[专家提示:在继续之前，修改第3部分的<a class="ae jt" rel="noopener" href="/analytics-vidhya/part-3-diving-into-neural-networks-52588b96cafa"/>。]如需协助，点击其中一个链接:<a class="ae jt" href="https://www.facebook.com/manika.miley" rel="noopener ugc nofollow" target="_blank">脸书</a>、<a class="ae jt" href="https://www.linkedin.com/in/manika-nagpal-808236154/" rel="noopener ugc nofollow" target="_blank">领英</a>、<a class="ae jt" href="https://www.instagram.com/manikanagpal/" rel="noopener ugc nofollow" target="_blank"> Instagram </a>、<a class="ae jt" href="https://www.quora.com/profile/Manika-Nagpal" rel="noopener ugc nofollow" target="_blank">、<em class="ju"> Quora </em>、<em class="ju">、</em>联系司机。旅途愉快！</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jv"><img src="../Images/800a26361c9058032d8654ed98cd617b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CKLjy9Jtwlc93qx5BUlwLw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片:<a class="ae jt" href="https://twitter.com/Igot7Linn" rel="noopener ugc nofollow" target="_blank"> Igot7Linn </a></figcaption></figure><p id="02ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CNN是一类特殊的神经网络，它接受图像作为输入，是<a class="ae jt" href="https://www.projectpro.io/article/deep-learning-for-image-classification-in-python-with-cnn/418" rel="noopener ugc nofollow" target="_blank"><em class="ju"/></a><em class="ju">和</em> <a class="ae jt" href="https://www.projectpro.io/project-use-case/real-time-fruit-detection-with-yolo" rel="noopener ugc nofollow" target="_blank"> <em class="ju">物体检测</em> </a>的基础。在数据科学世界中，神经网络有时被称为“完全连接的”<strong class="ih hj">神经网络或层</strong>，我将遵守相同的规则。</p><p id="7600" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们先从理解我附在已经学过的<a class="ae jt" rel="noopener" href="/analytics-vidhya/part-3-diving-into-neural-networks-52588b96cafa">神经网络</a>上的那个词的意思开始:‘卷积’。</p><h1 id="c627" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">盘旋</h1><p id="d2c1" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">数学上，卷积运算描述为:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/a8408e22ff3851760938371eaab74bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*262_j4XdpTUQTcU6BFGfaA@2x.png"/></div></div></figure><p id="6511" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中函数<em class="ju"> f </em>表示输入图像，<em class="ju"> w </em>表示<em class="ju">滤波器(</em>或<em class="ju">滤波器内核</em>或<em class="ju">T9】简称为<em class="ju">内核)。</em>我的<em class="ju">电子伙计们</em>很可能会问:</em></p><blockquote class="la lb lc"><p id="ee3e" class="if ig ju ih b ii ij ik il im in io ip ld ir is it le iv iw ix lf iz ja jb jc hb bi translated">“我们听说过低通/高通滤波器，这是同一种滤波器吗？”</p></blockquote><p id="440d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我的朋友们，答案是肯定的。事实上，可以将图像表示为不同频率的<a class="ae jt" href="https://david.li/filtering/" rel="noopener ugc nofollow" target="_blank">正弦波的总和，因此，某些频带可以与图像特征相关联。低频的正弦曲线通常表示图像中随强度缓慢变化的区域(例如图像中房间的墙壁)，而高频的正弦曲线描绘边缘和其他急剧的强度转变。因此，如果我们应用低通滤波器(不允许高频通过)，图像将会模糊。</a></p><p id="dbea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回到等式(1)，如果<em class="ju"> w </em>是<em class="ju">奇数</em>的尺寸1×m，那么<em class="ju"> a </em> = (m-1)/2。现在，让我举一个基本的例子来帮助你更好地理解这个等式。让我们为<em class="ju"> f </em>考虑一个一维像素阵列(参考<a class="ae jt" rel="noopener" href="/@manikanagpal1/fundamentals-of-digital-image-rgb-model-8bd01890ef23">第一部分</a>),为<em class="ju"> w </em>考虑一个维度为1x5的核，这样a=2。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/fb77129ac7fce5cba7a0e51139626724.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mSp_0QMzJxjf9dsN6hx5Ig@2x.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="9e21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，我们这里有一个问题。<em class="ju"> f </em>的每个元素都想让<em class="ju"> w </em>把它当做关注的中心。但是如果你试着计算卷积，你会意识到运算不能被执行，因为部分<em class="ju"> w </em>位于<em class="ju"> f </em>之外，所以求和不在那个区域中定义。别担心，我的친구(pron.<em class="ju"> chingu </em> = <em class="ju">朋友【韩语中的T41】)、<strong class="ih hj">T43】padding</strong></em>已经来救援了。我们<em class="ju">在函数<em class="ju"> f </em>的两边用<em class="ju">一个</em>数量的零填充</em>以便计算被调整。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/28df4934b208268688ff1fa74785b4f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VlxVhr_irgqr7pUv6kXLLg@2x.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="78a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你试着评价情商。(1)对于x = 0，你将得到:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lg"><img src="../Images/3c0969c750c39840007da31d13ac3972.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xfQnfQyvPucx3TFTCjfCAQ@2x.png"/></div></div></figure><p id="d5bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，如果我们将内核预旋转180°，然后计算乘积之和，也可以得到相同的结果。这与我们的数学直觉非常吻合，因为在等式(2) <em class="ju"> </em>中，内核<em class="ju"> w </em>已经相对于<em class="ju">f</em><em class="ju">w【T59(s)<em class="ju"/>和<em class="ju"> f </em> (-s) <em class="ju"> </em>在相反的方向<strong class="ih hj">被求值。</strong></em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/35c0dd945475e4d315f5f79ce18896ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-xWsX8Cw-bTkz1G8DXUKDg@2x.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="9090" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了计算<em class="ju"> x </em> =1的<em class="ju"> g </em>，我们应该计算<em class="ju"> f </em> (1-s)，这意味着将函数<em class="ju"> f </em>移动一个单位。但是，因为<a class="ae jt" href="https://ccrma.stanford.edu/~jos/mdft/Commutativity_Convolution.html" rel="noopener ugc nofollow" target="_blank">卷积是可交换的</a>，所以如果我们移动<em class="ju"> w </em>或<em class="ju"> f </em>几乎没有关系。由于移动较小的内核很容易，我也将遵守惯例。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/b14449840ffd42c53553f06e91c9262e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*umQpuoKxSmoyzR2oCv10hA@2x.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/a41a9c836a3aa223c6467481b838c68d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i-5TM23YxCtcz9uVbldf0w@2x.png"/></div></div></figure><p id="6874" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您对x的所有值(0到8)评估<em class="ju"> g </em>，您将获得以下结果:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lh"><img src="../Images/8a37527e77c5c580f403c09b9f824abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jk0zct2yyCIDX8T636tWsw@2x.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="b8e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意卷积后结果的大小是<strong class="ih hj"> <em class="ju"> M+(m-1) </em> </strong>其中<em class="ju"> M </em>是<em class="ju"> f </em>的长度。如果你注意到内核只需要<em class="ju"> M个</em>步骤就能覆盖整个<em class="ju"> f </em>和<em class="ju">卷积的两边都加了一个</em>数量的零，那么这个公式就很明显了。</p><p id="6aaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，同样的定义可以用于二维图像。大小为(MxN)的函数f(x，y)和大小为(m x n)的核w(x，y)的卷积公式变成:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/059eb1365b4f278b1c11e0dc09e68f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rZH3oi8r3--LZdmWcNmNbQ@2x.png"/></div></div></figure><p id="57f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中<em class="ju"> a </em> =(m-1)/2和<em class="ju"> b </em> =(n-1)/2。结果卷积的大小将是[<strong class="ih hj"><em class="ju">(M+M-1)</em>x<em class="ju">(N+N-1)</em></strong>]。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lj"><img src="../Images/371559022238e6e0df826f8468328a95.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/1*hW_qmy_LmVyS-5Rsn-J7uw.gif"/></div></figure><blockquote class="la lb lc"><p id="a68a" class="if ig ju ih b ii ij ik il im in io ip ld ir is it le iv iw ix lf iz ja jb jc hb bi translated">所以现在你知道为什么当你试图<strong class="ih hj">编辑</strong>你的seflie时，他们称它们为<strong class="ih hj">过滤器</strong>。</p></blockquote><p id="a7fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在进入CNN之前，你可以像这个可爱的男孩一样休息一下。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lk"><img src="../Images/32ebbad808db7d34bb856e8725a19345.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RBVZtUxX6UNw5srVy2Mm0g.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片:<a class="ae jt" href="https://twitter.com/Igot7Linn" rel="noopener ugc nofollow" target="_blank"> Igot7Linn </a></figcaption></figure><h1 id="0901" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">美国有线新闻网；卷积神经网络</h1><p id="f526" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">正如前一节已经暗示的，CNN的输入是图像，不像神经网络接收向量作为输入。CNN基本上试图通过将输入图像与某些<em class="ju">内核</em>进行卷积来提取输入图像的<em class="ju">特征</em>。卷积的结果连同一个<em class="ju">偏差</em>项然后通过<em class="ju">激活函数</em>，然后被线性化为一个向量，该向量然后被馈送到一个<em class="ju">完全连接的神经网络</em>。之后，完全连接的层给输入图像分配一个类。非零误差然后被传播回网络以学习正确的<em class="ju">内核</em>。</p><h2 id="14b2" class="ll jx hi bd jy lm ln lo kc lp lq lr kg iq ls lt kk iu lu lv ko iy lw lx ks ly bi translated">CNN是如何运作的？</h2><p id="7926" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">对于我的初学者친구，我将解释最简单和最早的CNN: Le-Net5。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lz"><img src="../Images/7ab203818fad90c5e48ce1a82d89474f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*79ROhAe2GWuxqrBtG4Voeg@2x.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图1 LeNet-5的体系结构</figcaption></figure><p id="727d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤1:输入图像的卷积</strong></p><p id="2396" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，当CNN接收到一个输入图像时，它不会立刻在整个图像上使用它的内核。更确切地说，它从图像中的某个像素区域开始，这个区域被称为<em class="ju">感受野，</em>具有相同大小的<em class="ju">核</em>。感受野然后以一定数量的步骤被拖过整个图像，这些步骤被称为<em class="ju">步幅</em>。在一维卷积(向上滚动)的情况下，我们的步距是1，但是为了减少数据，使用了大于1的步距。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/de241335fbe37785ed855a278011f57c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PwSaWkeTYwah3T4KwDi_Cg@2x.jpeg"/></div></div></figure><p id="5f6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤2:激活和功能映射</strong></p><p id="4213" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于从每个区域获得的卷积值，添加一个<em class="ju">偏差</em>项，然后总和通过一个<em class="ju">激活函数。</em>这导致一个名为<em class="ju">特征图的二维数组的形成，</em>然后成为下一层的输入。为了从图像中提取相同的特征，对感受野的所有位置使用相同的核和偏置。</p><p id="3c9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于LeNet-5(图1)，我们有一个32x32的输入图像，在该图像上应用了5x5内核，步幅=1。特征图的大小变成28×28。这是因为没有执行填充，因此图像两侧的a=2层的行为类似于填充零。因此，特征图的大小是M-(2*a)=M-(m-1)=28，其中M=32。</p><p id="ce97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第三步汇集/子采样</strong></p><p id="46b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢Hubel和Weisel，他们的哺乳动物视觉皮层模型是我们下一步工作的基础。</p><blockquote class="la lb lc"><p id="bed4" class="if ig ju ih b ii ij ik il im in io ip ld ir is it le iv iw ix lf iz ja jb jc hb bi translated">他们的论文表明，部分视觉皮层由简单和复杂的细胞组成。简单单元执行特征提取，而复杂单元将这些特征组合(聚合)成更有意义的整体。</p></blockquote><p id="1dbf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">汇集就是将特征地图压缩成更小维度的<em class="ju">汇集特征地图</em>的简单方法。它包括将一个要素地图细分为小部分，每个部分的大小为(比如)2x2，并汇集每4个值来生成一个值。假定池邻域彼此不重叠。有三种常见的方法来生成合并值:1)平均合并:计算4个值的平均值来生成结果。2) Max-Pooling:在4个值中，最大值。为输出选择值。3)L₂池:计算4个值的平方和的平方根。</p><p id="fe1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在LeNet-5(图1)中，选择2x2的感受野进行合并。这四个值简单地相加，然后乘以一个可训练系数，并加到一个可训练偏差上。结果通过一个s形函数传递。因此，汇集的特征地图的大小变为14x14。</p><p id="6f85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第4步添加另一个卷积层</strong></p><p id="6401" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在步骤2中，我们只对输入图像应用了一个内核。但是为了从输入图像中提取更多的特征，我们需要应用不同种类的内核。这导致了<em class="ju"> k </em>数量的特征地图<em class="ju">。</em>一组特征图统称为<em class="ju">卷积层。</em>下一步是汇集每个特征图<em class="ju">。</em></p><p id="89e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Le-Net5中，第一步是对输入图像应用6个不同的核。看下一层，人们可能想知道6个汇集的专题地图的值是如何输入到下一个卷积层的。答案很简单，将每个地图的每个位置的值相加，并提供给下一个图层。但是，需要注意的是，对于每个特征地图，过滤器和偏差的集合是不同的，因此对于图层C3，所需的核(和偏差)总数为6x16=96。</p><p id="2333" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第五步矢量化和分类</strong></p><p id="ef82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是<em class="ju">向量化</em>二维汇集的特征图，垂直连接它们，然后将它们馈送到完全连接的神经网络。如第3部分所述，神经网络的输出决定了输入的类别。</p><p id="bc15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤6错误反向传播</strong></p><p id="1de5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不打算深究反向传播方程。你可以在<a class="ae jt" href="https://www.amazon.com/Digital-Processing-Global-Richard-Gonzalez/dp/1292223049" rel="noopener ugc nofollow" target="_blank">书</a>里找到它们。然而，需要注意的一个关键问题是，当我们向后移动时，矢量化方法会反向生成输入向量。此外，每个汇集的要素地图都是未采样的，以匹配生成它的要素地图的大小。</p><p id="ac76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">仅此而已。你做到了！现在，有趣的部分开始了。</p><p id="2a6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了帮助你用Python编写LeNet-5的代码，我邀请了一位特殊的客人:BT21。请向他们问好。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/760a5a249674835a08ec2603526dbf5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/1*gfEbmjQwOSim6TjC1pKQyg.gif"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><em class="mb">图片:</em> <a class="ae jt" href="https://www.bt21.com/" rel="noopener ugc nofollow" target="_blank"> <em class="mb"> BT21 </em> </a></figcaption></figure><p id="aedf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">点击<a class="ae jt" href="https://github.com/ManikaNagpal/Waste_Segregation/blob/master/BT21.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a>了解你在其中的偏向名称。我的机器尽力学习BT21的特性。失败了就原谅吧！</p><p id="3c0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以参考这篇<a class="ae jt" rel="noopener" href="/analytics-vidhya/create-tensorflow-image-classification-model-with-your-own-dataset-in-google-colab-63e9d7853a3e">文章</a>来更好的了解google colab。</p><blockquote class="la lb lc"><p id="4922" class="if ig ju ih b ii ij ik il im in io ip ld ir is it le iv iw ix lf iz ja jb jc hb bi translated"><strong class="ih hj">游乐场时间！</strong></p><p id="dc98" class="if ig ju ih b ii ij ik il im in io ip ld ir is it le iv iw ix lf iz ja jb jc hb bi translated">你可以在这里访问<a class="ae jt" href="https://tensorspace.org/html/playground/lenet.html" rel="noopener ugc nofollow" target="_blank">，详细查看LeNet-5的所有图层。尽情享受吧！<em class="hi">😉</em></a></p></blockquote><p id="55c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">阅读更多:</strong><a class="ae jt" href="https://www.projectpro.io/article/rnn-vs-cnn-the-difference/491" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">CNN vs RNN——为你的项目选择合适的神经网络</strong> </a></p><p id="a50d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献</strong></p><p id="d66a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[1] <a class="ae jt" href="https://www.amazon.com/Digital-Processing-Global-Richard-Gonzalez/dp/1292223049" rel="noopener ugc nofollow" target="_blank"> Rafael C. Gonzalez和Richard E. Woods，数字图像处理，第四版，全球版(2018) </a></p><p id="12a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2] <a class="ae jt" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank"> Yann LeCun、Léeon Bottou、Yoshua Bengio和Patrick Haffner:基于梯度的学习应用于文档识别(1998)。</a></p><p id="d793" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想支持我，请点击按钮:</p><figure class="je jf jg jh fd ji er es paragraph-image"><a href="https://www.buymeacoffee.com/ManikaNagpal"><div class="er es mc"><img src="../Images/368cc3d5e7ab635359e3676c2e83893a.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/1*h4n_2kS4_aAoN6yMq8ZoKg.gif"/></div></a></figure></div></div>    
</body>
</html>