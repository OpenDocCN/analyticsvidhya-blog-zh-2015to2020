# 为什么特征预处理对健壮的 ML 模型很重要？

> 原文：<https://medium.com/analytics-vidhya/why-feature-preprocessing-is-important-for-a-robust-ml-model-edddd16a2bae?source=collection_archive---------5----------------------->

分析 Vidhya 继续发布由我们的客座作者撰写的高质量内容。在过去的两周里，我们的客座作者写了一些很棒的文章，探索了高度多样化的数据集、主题和很酷的技术，用在你的数据上，使你的预测更好。

![](img/070f89e5308cbf5f1c0c3d2de8335ac3.png)

## [数字数据的特征预处理——最重要的步骤](/analytics-vidhya/feature-preprocessing-for-numerical-data-the-most-important-step-e9ed76151298?source=friends_link&sk=519901aa94e9a6f02aa4459b8dccd2b1)

**按** [按**萨宾娜按**按](https://medium.com/u/7b40806ab7c7?source=post_page-----edddd16a2bae--------------------------------)

包含大量要素的数据集可能会让人不知所措，尤其是当数字要素表示不同的单位、测量值和实体时。Sabina 强调了在开始构建模型之前对要素进行预处理的重要性。本文也是对各种预处理技术以及如何实现它们的很好的指导。

## [使用 Pytorch 中的自动编码器对 MNIST 数据集进行维度操作](/analytics-vidhya/dimension-manipulation-using-autoencoder-in-pytorch-on-mnist-dataset-7454578b018?source=friends_link&sk=6e428d20fac0b5c3c6284d38179e3d4c)

**由** [**加里玛尼沙德**](https://medium.com/u/601d09175818?source=post_page-----edddd16a2bae--------------------------------)

将您的理论知识与自动编码器在流行的 MNIST 数据集上的实际应用联系起来。Garima 很好地解释了自动编码器背后的直觉，并提供了易于理解的代码。

## [实体链接:信息抽取的主要自然语言处理任务](/analytics-vidhya/entity-linking-a-primary-nlp-task-for-information-extraction-22f9d4b90aa8?source=friends_link&sk=7cc71db934a2145e988c18a31169797e)

**由** [**顺达诉**](https://medium.com/u/f123fdec163?source=post_page-----edddd16a2bae--------------------------------)

我们都熟悉命名实体识别(NER)，但您知道在信息提取过程中 NER 之后还有命名实体链接(NEL)吗？Sundar 详细解释了 NEL，从基础开始，一直到实现。