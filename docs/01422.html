<html>
<head>
<title>Learn Computer Vision Fundamentals with the famous MNIST data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用著名的MNIST数据学习计算机视觉基础</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/learn-computer-vision-fundamentals-with-the-famous-mnist-data-2bb63ec8e3f0?source=collection_archive---------10-----------------------#2019-10-21">https://medium.com/analytics-vidhya/learn-computer-vision-fundamentals-with-the-famous-mnist-data-2bb63ec8e3f0?source=collection_archive---------10-----------------------#2019-10-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="f83c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">本教程向您介绍Python中的深度学习:学习预处理您的数据，在著名的“MNIST”数据上建模、评估和优化神经网络。</p><p id="f8e0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">MNIST(“改进的国家标准和技术研究所”)自1999年发布以来，这个经典的手写图像数据集一直是基准分类算法的基础。随着新的机器学习技术的出现，MNIST仍然是研究人员和学习者的可靠资源。</p><p id="0eb0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本教程中，您将从成千上万的手写图像数据集中正确识别数字。我鼓励你尝试不同的算法，以直接了解什么效果好，技术如何比较。</p><p id="3fe1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">关于该数据集的更多细节，包括已经在其上尝试的算法及其成功程度，可以在http://yann.lecun.com/exdb/mnist/index.html的<a class="ae jk" href="http://yann.lecun.com/exdb/mnist/index.html" rel="noopener ugc nofollow" target="_blank">找到。该数据集是在知识共享署名共享3.0许可下提供的。</a></p><p id="737d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">或者，你也可以从https://www.kaggle.com/c/digit-recognizer的卡格尔<a class="ae jk" href="https://www.kaggle.com/c/digit-recognizer" rel="noopener ugc nofollow" target="_blank">下载数据集。使用下面的方法，我得到了0.99628的公开分数(kaggle的前10%)。</a></p><p id="3a91" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">深度学习</strong></p><p id="9e5f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你可能已经知道机器学习，它是数据科学和人工智能的一种应用，为系统提供自动学习和根据经验改进的能力，而无需显式编程。在本教程中，你将专注于深度学习，这是一种模拟大脑神经元网络的计算机软件。它是机器学习的一个子集，被称为深度学习，因为它利用了深度神经网络。</p><p id="6c8a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">深度学习算法是用连接的层构造的。</p><p id="5cf6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">-第一层称为输入层<br/> -最后一层称为输出层<br/> -中间的所有层称为隐藏层</p><p id="dfd8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">单词deep是指网络连接两层以上的神经元。</p><p id="0090" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数字识别器</strong></p><p id="c0a2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">本教程将向您介绍:</p><ul class=""><li id="af8e" class="jl jm hi io b ip iq it iu ix jn jb jo jf jp jj jq jr js jt bi translated">时尚MNIST数据集，包含10个类别的70，000幅灰度图像。这些图像以低分辨率(28×28像素)显示了单件衣服</li><li id="daff" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">如何使用Python及其库来理解、探索和可视化您的数据</li><li id="f78f" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">如何预处理您的数据</li><li id="fb87" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">如何使用Keras序列模型为分类任务建立多层感知器</li><li id="0e02" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">如何编译数据并使其适合这些模型</li><li id="8acf" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">如何使用您的模型来预测目标值，以及如何验证您已经建立的模型</li></ul><p id="3138" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">加载库</strong></p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="2faf" class="ki kj hi ke b fi kk kl l km kn">import pandas as pd<br/>import seaborn as sns<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import tensorflow as tf<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Activation, Flatten<br/>from keras.optimizers import Adam,RMSprop<br/>from keras.layers.normalization import BatchNormalization<br/>from keras.utils import np_utils,plot_model<br/>from keras.preprocessing.image import ImageDataGenerator<br/>from IPython.display import Image<br/>from keras.layers import Conv2D, MaxPooling2D<br/>from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import confusion_matrix,accuracy_score<br/>from keras.datasets import mnist</span></pre><p id="6aee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里，42，000幅图像用于训练网络，28，000幅图像用于最终测试，您将预测这28，000幅图像的类别。为了评估网络对这些图像进行分类的准确性，您还需要一个验证集。您可以直接从TensorFlow访问时尚MNIST。按照以下方式导入和加载时尚MNIST数据:</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="7023" class="ki kj hi ke b fi kk kl l km kn">train_mnist = pd.read_csv(‘../input/digit-recognizer/train.csv’)<br/>test_mnist = pd.read_csv(‘../input/digit-recognizer/test.csv’)</span></pre><p id="85dd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">查看下面的训练数据的形状，它包含42000个图像，每个图像表示为28 x 28像素。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="43a9" class="ki kj hi ke b fi kk kl l km kn">print(train_mnist.shape)<br/>print(train_mnist.head(1))</span><span id="d1b9" class="ki kj hi ke b fi ko kl l km kn">(42000, 785)<br/>   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \<br/>0      1       0       0       0       0       0       0       0       0   <br/><br/>   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \<br/>0       0    ...            0         0         0         0         0   <br/><br/>   pixel779  pixel780  pixel781  pixel782  pixel783  <br/>0         0         0         0         0         0  <br/><br/>[1 rows x 785 columns]</span></pre><p id="94db" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最后将数据和目标标签赋给变量X和y。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="c897" class="ki kj hi ke b fi kk kl l km kn">X = train_mnist.drop(“label”,axis=1)<br/>y = train_mnist[‘label’]<br/>X.shape<br/>(42000, 784)</span></pre><p id="4861" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">每个标签都是0到9之间的整数:</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="2917" class="ki kj hi ke b fi kk kl l km kn">np.unique(y)<br/>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)</span></pre><p id="6980" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据预处理</strong></p><p id="fb69" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在训练网络之前，必须对数据进行预处理:</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="fb20" class="ki kj hi ke b fi kk kl l km kn">plot_image = X.values.reshape(X.shape[0], 28, 28)</span><span id="e6ba" class="ki kj hi ke b fi ko kl l km kn">plt.figure()<br/>plt.imshow(plot_image[3])<br/>plt.colorbar()<br/>plt.grid(False)<br/>plt.show()</span></pre><figure class="jz ka kb kc fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es kp"><img src="../Images/4d293407958b63db2644642e4fea0fe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*5I-ldDkX8S3E18NKoVJfmQ.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">如果检查训练集中的图像，您会看到像素值在0到255的范围内</figcaption></figure><p id="86c9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在将这些值输入神经网络模型之前，将它们调整到0到1的范围内。为此，将这些值除以255。训练集和测试集必须以相同的方式进行预处理，这一点很重要:</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="86e3" class="ki kj hi ke b fi kk kl l km kn">X = X / 255.0<br/>test_mnist = test_mnist / 255.0</span></pre><p id="81d3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，从上面库部分的sklearn.model_selection导入train_test_split</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="4923" class="ki kj hi ke b fi kk kl l km kn">X = pd.DataFrame(X)<br/>y = pd.DataFrame(y)</span><span id="3665" class="ki kj hi ke b fi ko kl l km kn">X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.15,random_state=0)</span></pre><p id="2324" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了将图像输入卷积神经网络，你应该将数据帧转换成四维。这可以使用numpy reshape方法来完成。Keras希望在最后为渠道增加一个额外的维度。如果这是RGB图像，将有3个通道，但由于MNIST是灰度级，它只使用一个。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="72b2" class="ki kj hi ke b fi kk kl l km kn">X_train = X_train.values.reshape(X_train.shape[0],28,28,1)<br/>X_test = X_test.values.reshape(X_test.shape[0],28,28,1)<br/>test_mnist = test_mnist.values.reshape(test_mnist.shape[0],28,28,1)</span></pre><p id="0c04" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">训练模型</strong></p><p id="bd4c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Keras提供了两种不同的网络定义方式。在这里，我将定义顺序API，从输入开始，每次只添加一层。顺序API的问题是，它不允许模型有多个输入或输出，而这对于某些问题是需要的。要创建卷积神经网络，您只需创建一个顺序对象，并使用add函数添加层。<br/>第一层是Conv2D层。这些卷积层将处理我们的输入图像，这些图像被视为二维矩阵。</p><p id="1047" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">第一层中的64是层中的节点数。根据数据集的大小，这个数字可以调高或调低。在这种情况下，64工作得很好，所以我现在坚持使用它。</p><ul class=""><li id="c7d2" class="jl jm hi io b ip iq it iu ix jn jb jo jf jp jj jq jr js jt bi translated">核大小是我们卷积的滤波器矩阵的大小。因此，内核大小为3意味着您将拥有一个3×3的过滤器矩阵</li><li id="2abf" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">激活是层的激活功能。我将用于第一层的激活函数是ReLU，或整流线性激活。这种激活函数已被证明在神经网络中工作良好</li><li id="49e0" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">第一层也接受一个输入形状。这是每个输入图像的形状，28，28，1，如前所述，1表示图像是灰度的</li></ul><p id="91bd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">将像素添加到图像的边缘称为填充。</p><p id="41ee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在Keras中，这是通过Conv2D层上的“padding”参数指定的，该参数的默认值为“valid”(无填充)。这意味着过滤器仅应用于输入的有效途径。“相同”的“填充”值计算并添加输入图像(或特征映射)所需的填充，以确保输出与输入具有相同的形状。</p><p id="ddce" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Maxpooling:对于过滤器表示的每个区域，我们将获取该区域的最大值，并创建一个新的输出矩阵，其中每个元素都是原始输入中一个区域的最大值。</p><figure class="jz ka kb kc fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es lb"><img src="../Images/c33fc788f8846061e57f24bf284aabcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gaD6SJ6kQNVOclE_WkwLNQ.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">在中选择Maxpooling，以便它突出显示图像的边缘。</figcaption></figure><p id="6eef" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了提高神经网络的稳定性，批标准化通过减去批平均值并除以批标准偏差来标准化先前激活层的输出。</p><p id="37e2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">您可以在网络中添加更多层来查看模型的执行情况。下面增加了三层。在Conv2D层和密集层之间，有一个“展平”层。</p><p id="b86d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">展平用作卷积层和致密层之间的连接。<br/>“密集”是我们将在输出图层中使用的图层类型。密集是一种标准图层类型，在许多情况下用于神经网络。输出层应该有10个节点，每个节点对应一个可能的结果(0–9)。</p><figure class="jz ka kb kc fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es lc"><img src="../Images/adaea062de1a3f467d507fcabe45f26d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y_-y1-G4I4VrN92S5372Iw.png"/></div></div></figure><p id="6a6d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">术语“丢失”指的是在神经网络中丢失单元(隐藏的和可见的)。—辍学:防止神经网络过度拟合的简单方法。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="0e5c" class="ki kj hi ke b fi kk kl l km kn">model = Sequential()</span><span id="9af0" class="ki kj hi ke b fi ko kl l km kn">model.add(Conv2D(64, (3, 3), input_shape=(28,28,1),padding=”SAME”))<br/>model.add(BatchNormalization(axis=-1))<br/>model.add(Activation(‘relu’))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="146b" class="ki kj hi ke b fi ko kl l km kn">model.add(Conv2D(128,(3, 3),padding=”SAME”))<br/>model.add(BatchNormalization(axis=-1))<br/>model.add(Activation(‘relu’))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="3081" class="ki kj hi ke b fi ko kl l km kn">model.add(Conv2D(192,(3, 3),padding=”SAME”))<br/>model.add(Activation(‘relu’))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="51ee" class="ki kj hi ke b fi ko kl l km kn">model.add(Flatten())</span><span id="48df" class="ki kj hi ke b fi ko kl l km kn"># Fully connected layer<br/>model.add(Dense(256))<br/>model.add(BatchNormalization())<br/>model.add(Activation(‘relu’))<br/>model.add(Dropout(0.3))<br/>model.add(Dense(10))</span><span id="4367" class="ki kj hi ke b fi ko kl l km kn">model.add(Activation(‘softmax’))</span><span id="11cc" class="ki kj hi ke b fi ko kl l km kn">model.summary()</span></pre><p id="f76b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">查看下面的模型摘要:</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="f9b3" class="ki kj hi ke b fi kk kl l km kn">output_channels * (input_channels * window_size + 1) == number_parameters(param)</span><span id="0fee" class="ki kj hi ke b fi ko kl l km kn">64 * (1 * (3*3) + 1)  == 640<br/>True</span></pre><p id="e707" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">形状中的“无”表示它没有预定义的数字。例如，它可以是您在训练期间使用的批次大小，您希望通过不为其分配任何值来使其灵活，以便您可以更改您的批次大小。该模型将从层的上下文中推断形状。</p><p id="3f97" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在第一层中，我们有64个节点，每个输入层的形状为28×28。使用“max_pooling”后，形状缩小到14x14，因为我们使用了2x2的maxpooling。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="b120" class="ki kj hi ke b fi kk kl l km kn">Model: "sequential_1"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_1 (Conv2D)            (None, 28, 28, 64)        640       <br/>_________________________________________________________________<br/>batch_normalization_1 (Batch (None, 28, 28, 64)        256       <br/>_________________________________________________________________<br/>activation_1 (Activation)    (None, 28, 28, 64)        0         <br/>_________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 14, 14, 128)       73856     <br/>_________________________________________________________________<br/>batch_normalization_2 (Batch (None, 14, 14, 128)       512       <br/>_________________________________________________________________<br/>activation_2 (Activation)    (None, 14, 14, 128)       0         <br/>_________________________________________________________________<br/>max_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         <br/>_________________________________________________________________<br/>conv2d_3 (Conv2D)            (None, 7, 7, 192)         221376    <br/>_________________________________________________________________<br/>activation_3 (Activation)    (None, 7, 7, 192)         0         <br/>_________________________________________________________________<br/>max_pooling2d_3 (MaxPooling2 (None, 3, 3, 192)         0         <br/>_________________________________________________________________<br/>flatten_1 (Flatten)          (None, 1728)              0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 256)               442624    <br/>_________________________________________________________________<br/>batch_normalization_3 (Batch (None, 256)               1024      <br/>_________________________________________________________________<br/>activation_4 (Activation)    (None, 256)               0         <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 256)               0         <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 10)                2570      <br/>_________________________________________________________________<br/>activation_5 (Activation)    (None, 10)                0         <br/>=================================================================<br/>Total params: 742,858<br/>Trainable params: 741,962<br/>Non-trainable params: 896</span></pre><p id="8798" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">您还可以使用learning_rate_reduction、best_model和early_stopping来定义回调参数。在开始我的训练过程之前，我将在下面定义几个超参数。</p><ul class=""><li id="6cd5" class="jl jm hi io b ip iq it iu ix jn jb jo jf jp jj jq jr js jt bi translated">提前停止:用于在监控的数量停止改善时停止训练</li><li id="d556" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">监控:要监控的数量。在这种情况下，它是val_loss。如果损失停止改善，训练将自动停止。</li><li id="d89f" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">Min_delta:符合改善条件的监控量的最小变化，即小于min_delta的绝对变化将被视为无改善。</li><li id="1f99" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">耐心:产生监控数量但没有改善的时期数，在此之后训练将停止。</li><li id="ec01" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">restore_best_weights:是否从具有被监控量的最佳值的时期恢复模型权重。如果为False，则使用在最后一步训练中获得的模型权重。</li></ul><p id="a833" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">深度学习模型可能需要几个小时、几天甚至几周的时间来训练。如果运行意外停止，您可能会丢失大量工作。这是一种在系统出现故障时拍摄系统状态快照的方法。如果出了问题，也不是全部都没了。检查点可以直接使用，也可以作为新一轮运行的起点，从它停止的地方开始。<br/>训练深度学习模型时，检查点就是模型的权重。这些权重可以用于进行预测，或者用作正在进行的训练的基础。</p><p id="2267" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里的model_weights.h5是一个权重文件。</p><p id="5fc1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">learning_rate_reduction:一旦学习停滞，模型通常会受益于将学习速率降低2-10倍。这种回调监控一个数量，如果在“耐心”次数内没有看到改进，则学习率降低。</p><ul class=""><li id="db52" class="jl jm hi io b ip iq it iu ix jn jb jo jf jp jj jq jr js jt bi translated">因子:学习率降低的因子。new_lr = lr *因子</li><li id="04e7" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">min_lr:学习率的下限。</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="4d1b" class="ki kj hi ke b fi kk kl l km kn">early_stopping = EarlyStopping(monitor=’val_loss’, min_delta=1e-10, patience=10,restore_best_weights=True)</span><span id="4621" class="ki kj hi ke b fi ko kl l km kn">best_model = ModelCheckpoint(‘model_weights.h5’, monitor=’val_acc’, verbose=2, save_best_only=True, mode=’max’)</span><span id="7c4b" class="ki kj hi ke b fi ko kl l km kn">learning_rate_reduction = ReduceLROnPlateau(monitor=’val_acc’,patience=3, verbose=2,factor=0.5,min_lr=0.00001)</span></pre><p id="5885" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">编译模型</strong></p><p id="d44b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，您需要编译模型。编译模型需要三个参数:优化器、损失和指标。</p><ul class=""><li id="7244" class="jl jm hi io b ip iq it iu ix jn jb jo jf jp jj jq jr js jt bi translated">优化器控制学习速率。我们将使用“亚当”作为我们的优化器。在许多情况下，Adam通常是一个很好的优化器。adam优化器在整个训练过程中调整学习率</li><li id="8160" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">学习率决定了计算模型最佳权重的速度。较小的学习率可能导致更精确的权重(直到某一点)，但是计算权重所花费的时间将会更长</li><li id="9529" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">我将使用‘稀疏分类交叉熵’作为损失函数。这是最常见的分类选择。分数越低，表示模型的性能越好。</li></ul><p id="2c03" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当我们有一个单标签、多类分类问题时，标签对于每个数据是互斥的，这意味着每个数据条目只能属于一个类。然后我们可以用一键嵌入来表示y_true。<br/> <br/>例如，y_true有3个样本，分别属于类2、类0和类2。</p><p id="23e6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">y_true = [[0，0，1]，<br/> [1，0，0]，<br/> [0，0，1]]</p><p id="62fb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">会变成:</p><p id="bd56" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">y_true_one_hot = [2，0，2]</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="894c" class="ki kj hi ke b fi kk kl l km kn">model.compile(optimizer=’adam’,<br/>loss=’sparse_categorical_crossentropy’,<br/>metrics=[‘accuracy’])</span></pre><p id="a58b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图像数据生成器和数据扩充</strong></p><p id="bb4c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">数据扩充用于扩展训练数据集，以提高模型的性能和泛化能力。Keras深度学习库中通过ImageDataGenerator类支持图像数据增强。</p><p id="4ea6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Keras ImageDataGenerator类实际上通过以下方式工作:</p><ul class=""><li id="b8ca" class="jl jm hi io b ip iq it iu ix jn jb jo jf jp jj jq jr js jt bi translated">接受一批用于训练的图像</li><li id="e85f" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">取这一批并对这一批中的每个图像应用一系列随机变换(包括随机旋转、调整大小、剪切等。).</li><li id="86f1" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">用新的随机转换的批次替换原始批次。</li><li id="9e9e" class="jl jm hi io b ip ju it jv ix jw jb jx jf jy jj jq jr js jt bi translated">在这个随机转换的批次上训练CNN(即，原始数据本身不用于训练)</li></ul><p id="39c8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="ld"> ImageDataGenerator </em>接受原始数据，对其进行随机转换，并只返回新的转换后的数据。</p><p id="92f4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">数据扩充包括一系列技术，用于通过应用随机抖动和扰动(但同时确保数据的类别标签不变)从原始样本生成“新”训练样本。</p><p id="11eb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们应用数据扩充的目标是提高模型的概化能力。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="5311" class="ki kj hi ke b fi kk kl l km kn">gen = ImageDataGenerator(<br/> featurewise_center=False, <br/> samplewise_center=False, <br/> featurewise_std_normalization=False, <br/> samplewise_std_normalization=False, <br/> rotation_range=10, <br/> zoom_range = 0.1,<br/> width_shift_range=0.1, <br/> height_shift_range=0.1, <br/> horizontal_flip=False,<br/> vertical_flip=False)</span><span id="69e9" class="ki kj hi ke b fi ko kl l km kn">gen.fit(X_train)</span></pre><p id="341a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了估计模型在给定训练运行中的性能，您应该将训练集进一步拆分为训练和验证数据集。然后，可以绘制每次运行的训练和验证数据集的性能，以提供学习曲线和对模型学习问题的深入了解。</p><p id="7e08" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Keras API通过在训练模型时将“validation_data”参数指定给model.fit()函数来支持这一点，这将依次返回一个对象，该对象描述每个训练时期上所选损失和度量的模型性能。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="2a76" class="ki kj hi ke b fi kk kl l km kn">h = model.fit_generator(<br/> gen.flow(X_train, y_train, batch_size=64),<br/> validation_data=(X_test, y_test),<br/> steps_per_epoch=len(X_train) // 64,<br/> epochs=50, verbose=1,<br/> callbacks=[learning_rate_reduction,best_model,early_stopping]<br/> )</span><span id="741f" class="ki kj hi ke b fi ko kl l km kn">Epoch 1/50<br/>557/557 [==============================] - 23s 41ms/step - loss: 0.1681 - acc: 0.9500 - val_loss: 0.0710 - val_acc: 0.9792<br/><br/>Epoch 00001: val_acc improved from -inf to 0.97921, saving model to mnist_weights.h5<br/>Epoch 2/50<br/>557/557 [==============================] - 18s 32ms/step - loss: 0.0719 - acc: 0.9778 - val_loss: 0.0591 - val_acc: 0.9811<br/><br/>Epoch 00002: val_acc improved from 0.97921 to 0.98111, saving model to mnist_weights.h5<br/>Epoch 3/50<br/>557/557 [==============================] - 18s 33ms/step - loss: 0.0584 - acc: 0.9823 - val_loss: 0.0860 - val_acc: 0.9748<br/><br/>Epoch 00003: val_acc did not improve from 0.98111<br/>Epoch 4/50<br/>557/557 [==============================] - 18s 33ms/step - loss: 0.0475 - acc: 0.9852 - val_loss: 0.0507 - val_acc: 0.9856<br/><br/>Epoch 00004: val_acc improved from 0.98111 to 0.98556, saving model to mnist_weights.h5<br/>Epoch 5/50<br/>557/557 [==============================] - 18s 33ms/step - loss: 0.0455 - acc: 0.9859 - val_loss: 0.0507 - val_acc: 0.9848<br/><br/>Epoch 00005: val_acc did not improve from 0.98556<br/>Epoch 6/50<br/>557/557 [==============================] - 18s 33ms/step - loss: 0.0390 - acc: 0.9871 - val_loss: 0.0534 - val_acc: 0.9859<br/><br/>Epoch 00006: val_acc improved from 0.98556 to 0.98587, saving model to mnist_weights.h5<br/>Epoch 7/50<br/>557/557 [==============================] - 18s 32ms/step - loss: 0.0396 - acc: 0.9874 - val_loss: 0.0415 - val_acc: 0.9862<br/><br/>Epoch 00007: val_acc improved from 0.98587 to 0.98619, saving model to mnist_weights.h5<br/>Epoch 8/50<br/>557/557 [==============================] - 18s 32ms/step - loss: 0.0374 - acc: 0.9888 - val_loss: 0.0563 - val_acc: 0.9824<br/><br/>Epoch 00008: val_acc did not improve from 0.98619<br/>Epoch 9/50<br/>557/557 [==============================] - 18s 33ms/step - loss: 0.0328 - acc: 0.9896 - val_loss: 0.0315 - val_acc: 0.9908<br/><br/>Epoch 00009: val_acc improved from 0.98619 to 0.99079, saving model to mnist_weights.h5<br/>Epoch 10/50<br/>557/557 [==============================] - 18s 32ms/step - loss: 0.0350 - acc: 0.9886 - val_loss: 0.0267 - val_acc: 0.9916<br/><br/>Epoch 00010: val_acc improved from 0.99079 to 0.99159, saving model to mnist_weights.h5<br/>Epoch 11/50<br/>557/557 [==============================] - 19s 34ms/step - loss: 0.0295 - acc: 0.9903 - val_loss: 0.0271 - val_acc: 0.9933<br/><br/>Epoch 00011: val_acc improved from 0.99159 to 0.99333, saving model to mnist_weights.h5<br/>Epoch 12/50<br/>557/557 [==============================] - 18s 32ms/step - loss: 0.0276 - acc: 0.9912 - val_loss: 0.0310 - val_acc: 0.9910<br/><br/>Epoch 00012: val_acc did not improve from 0.99333<br/>Epoch 13/50<br/>557/557 [==============================] - 18s 31ms/step - loss: 0.0276 - acc: 0.9909 - val_loss: 0.0309 - val_acc: 0.9908<br/><br/>Epoch 00013: val_acc did not improve from 0.99333<br/>Epoch 14/50<br/>557/557 [==============================] - 17s 31ms/step - loss: 0.0264 - acc: 0.9919 - val_loss: 0.0337 - val_acc: 0.9898<br/><br/>Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.<br/><br/>Epoch 00014: val_acc did not improve from 0.99333<br/>Epoch 15/50<br/>557/557 [==============================] - 18s 31ms/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0201 - val_acc: 0.9948<br/><br/>Epoch 00015: val_acc improved from 0.99333 to 0.99476, saving model to mnist_weights.h5<br/>Epoch 16/50<br/>557/557 [==============================] - 18s 32ms/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0213 - val_acc: 0.9935<br/><br/>Epoch 00016: val_acc did not improve from 0.99476<br/>Epoch 17/50<br/>557/557 [==============================] - 18s 32ms/step - loss: 0.0167 - acc: 0.9948 - val_loss: 0.0220 - val_acc: 0.9935<br/><br/>Epoch 00017: val_acc did not improve from 0.99476<br/>Epoch 18/50<br/>557/557 [==============================] - 17s 31ms/step - loss: 0.0169 - acc: 0.9946 - val_loss: 0.0203 - val_acc: 0.9940<br/><br/>Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.<br/><br/>Epoch 00018: val_acc did not improve from 0.99476<br/>Epoch 19/50<br/>557/557 [==============================] - 17s 31ms/step - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0160 - val_acc: 0.9951<br/><br/>Epoch 00019: val_acc improved from 0.99476 to 0.99508, saving model to mnist_weights.h5<br/>Epoch 20/50<br/>557/557 [==============================] - 17s 31ms/step - loss: 0.0128 - acc: 0.9962 - val_loss: 0.0182 - val_acc: 0.9949<br/><br/>Epoch 00020: val_acc did not improve from 0.99508<br/>Epoch 21/50<br/>557/557 [==============================] - 17s 31ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0158 - val_acc: 0.9954<br/><br/>Epoch 00021: val_acc improved from 0.99508 to 0.99540, saving model to mnist_weights.h5<br/>Epoch 22/50<br/>211/557 [==========&gt;...................] - ETA: 10s - loss: 0.0112 - acc: 0.9964</span></pre><p id="aa98" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">预测函数将给出一个包含10个数字的数组。这些数字是输入图像代表每个数字(0-9)的概率。编号最高的数组索引表示模型预测。每个数组的总和等于1(因为每个数字都是一个概率)。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="14ff" class="ki kj hi ke b fi kk kl l km kn">y_pred = model.predict(X_test)<br/>y_pred = np.argmax(y_pred,axis = 1)</span><span id="9f2e" class="ki kj hi ke b fi ko kl l km kn">accuracy_score(y_test,y_pred)<br/>0.9961904761904762</span><span id="4612" class="ki kj hi ke b fi ko kl l km kn">pd.DataFrame(h.history).plot()</span></pre><figure class="jz ka kb kc fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es le"><img src="../Images/4a56b6dd8bdad197be02f1bd7b487ec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*CnsfgGAoUpAeTB_5PlI-ZQ.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">该图显示了每个历元的精度和损耗变化</figcaption></figure><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="0c75" class="ki kj hi ke b fi kk kl l km kn">conf_mat = confusion_matrix(y_test,y_pred)<br/>f,ax = plt.subplots(figsize=(7, 7))<br/>sns.heatmap(conf_mat, cmap=’Blues’,annot=True, linewidths=.5, fmt= ‘.1f’,ax=ax)</span></pre><figure class="jz ka kb kc fd kq er es paragraph-image"><div class="er es lf"><img src="../Images/c902d884e88eacfd45d27c394ea98036.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*iZy2Tg2JmzAaeC7jfNwDfA.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">混淆矩阵</figcaption></figure></div></div>    
</body>
</html>