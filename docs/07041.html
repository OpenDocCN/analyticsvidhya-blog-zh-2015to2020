<html>
<head>
<title>Data Acquisition Using Web Scraping, Web Crawlers and APIs (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用网络抓取、网络爬虫和API获取数据(第1部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-acquisition-using-web-scraping-web-crawlers-and-apis-part-1-93f63ffa5e24?source=collection_archive---------18-----------------------#2020-06-11">https://medium.com/analytics-vidhya/data-acquisition-using-web-scraping-web-crawlers-and-apis-part-1-93f63ffa5e24?source=collection_archive---------18-----------------------#2020-06-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="5b76" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">简介</strong></h1><p id="8026" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">本文将介绍使用不同方法从web上删除数据的基本技术，例如使用爬虫和库(如BeautifulSoup、urllib)以及以高效方式获取和解析数据的请求。</p><p id="3077" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">所有代码都在一个GitHub库中提供，请点击这里的<a class="ae kg" href="https://github.com/aryanchugh816/Data-Science/blob/master/01%20-%20Data%20Acquisition/01%20-%20Data%20Acquisition%20-%20Web%20Scrapping%20using%20BeautifulSoup.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="kh"/></a>查看代码。</p><h1 id="d376" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">使用BeautifulSoup进行网页抓取</strong></h1><p id="ba98" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Beautiful Soup是一个Python库，用于从HTML和XML文件中提取数据。它与您喜欢的解析器一起工作，提供导航、搜索和修改解析树的惯用方式。</p><p id="ee27" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在本练习中，我们将从页面中提取基于android版本历史的表格(第一个表格):<a class="ae kg" href="https://en.wikipedia.org/wiki/Android_version_history" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Android_version_history</a></p><p id="d2c2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">使用urllib获取HTML页面数据</strong></p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="847b" class="kr ig hi kn b fi ks kt l ku kv">from urllib.request import urlopen<br/>android_url = "<a class="ae kg" href="https://en.wikipedia.org/wiki/Android_version_history" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Android_version_history</a>"<br/>android_data = urlopen(android_url) <br/># android_data is an http response object</span><span id="94c5" class="kr ig hi kn b fi kw kt l ku kv">android_html = android_data.read()<br/># we can get the whole html of that page by using the read() method on the android_data (object)</span><span id="c664" class="kr ig hi kn b fi kw kt l ku kv">android_html = android_data.read()<br/>android_data.close()</span></pre><p id="1e5c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们使用<strong class="jf hj"> urlopen(url) </strong>向给定的url发送一个HTTP请求，并得到一个响应，我们使用这个响应对象通过<strong class="jf hj"> read() </strong>内置方法提取页面Html。记得在最后关闭连接。</p><p id="ee8b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">现在我们将使用<strong class="jf hj"> BeautifulSoup </strong>库来解析我们获得的Html代码。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="d53d" class="kr ig hi kn b fi ks kt l ku kv">from bs4 import BeautifulSoup as soup</span><span id="c143" class="kr ig hi kn b fi kw kt l ku kv">android_soup = soup(android_html, 'html.parser')<br/>tables = android_soup.findAll('table', {'class':'wikitable'})<br/>print("Number of Tables: {}".format(len(tables)))</span></pre><p id="4cc2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">输出:</strong></p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="d136" class="kr ig hi kn b fi ks kt l ku kv">Number of Tables: 31</span></pre><p id="c6e6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们首先必须使用创建一个soup类对象，并将解析器指定为“html.parser”。然后我们将使用<strong class="jf hj"> findall() </strong>方法来检测一个特定的元素，并以字典的形式给出任何进一步的搜索属性作为第二个参数，在我们的例子中，我们想要属于类“wikitable”的表。</p><p id="0f7e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们可以使用浏览器的内置inspect元素来查找元素标记和任何用于搜索的元素，如类名或特定id，并将其作为字典传递。</p><h1 id="7a2c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"><em class="kx">findall():</em></strong>的例子</h1><p id="ff5a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们将尝试查找带有“h1”标签的所有元素:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="7ea9" class="kr ig hi kn b fi ks kt l ku kv">a = android_soup.findAll('h1', {})<br/># it return a list of matching objects</span><span id="943f" class="kr ig hi kn b fi kw kt l ku kv">print(a)<br/>print(type(a))<br/>print(len(a))</span></pre><p id="ef76" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">输出:</strong></p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="6a09" class="kr ig hi kn b fi ks kt l ku kv">[&lt;h1 class="firstHeading" id="firstHeading" lang="en"&gt;Android version history&lt;/h1&gt;]<br/>&lt;class 'bs4.element.ResultSet'&gt;<br/>1</span></pre><p id="9b7f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们对ℎ1h1标签的搜索只得到1个输出，因为此网页只包含一个h1标签，它是页面的标题，如下所示:</p><figure class="ki kj kk kl fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ky"><img src="../Images/a7382c7a1d9e7f7d2215a02bffea2604.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o_2fbX6lHOp6OdwHEhQhyw.png"/></div></div></figure><h1 id="7043" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">在继续之前，我们将看一下我们试图刮擦的表</h1><figure class="ki kj kk kl fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lg"><img src="../Images/83ea79a5f0c22e8839af7baaf9d2d0c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jv_qCEtj_sGkMCh7grdi0Q.png"/></div></div></figure><p id="a5bf" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">正如我们所看到的，前两行不能使用，因为这些android版本没有代码名称。</p><p id="22f2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">类似地，最后一行是无用的，因为它包含丢失的值，我们也可以删除最后一列，<strong class="jf hj">引用</strong>列，因为它不包含任何信息。</p><p id="d4f4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们将选择第一个表数据，并从中提取列标题:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="0ce1" class="kr ig hi kn b fi ks kt l ku kv">android_table = tables[0]<br/>headers = android_table.findAll('th')</span><span id="f3e6" class="kr ig hi kn b fi kw kt l ku kv"># We will use these headers as columns names hence we have to store them in a variable<br/>column_titles = [ct.text for ct in headers]</span><span id="1f1c" class="kr ig hi kn b fi kw kt l ku kv"># slice out the carriage return (\n)<br/>column_titles = [ct.text[:-1] for ct in headers]</span><span id="21c2" class="kr ig hi kn b fi kw kt l ku kv"># We wont be using the last column('References') hence we will remove it from our column names:<br/>column_titles = column_titles[:-1]<br/>print(len(column_titles))<br/>print(column_titles)</span></pre><p id="a97b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">输出:</strong></p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="e864" class="kr ig hi kn b fi ks kt l ku kv">4<br/>['Name', 'Version number(s)', 'Initial release date', 'API level']</span></pre><p id="4973" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们现在将获取表中的行，并通过将所有内容存储在一个<strong class="jf hj"> table_rows </strong>变量中来完成对数据的排序和清理:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="3cfb" class="kr ig hi kn b fi ks kt l ku kv">rows_data = android_table.findAll('tr')[1:]<br/>print("Total number of rows: {}".format(len(rows_data)))</span><span id="3655" class="kr ig hi kn b fi kw kt l ku kv"># We will start with the third row as the first two rows have no name for the software versions<br/>rows_data = rows_data[2:]<br/>print("Number of rows we are going to display: {}".format(len(rows_data)))</span></pre><p id="dde5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">输出:</strong></p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="9e85" class="kr ig hi kn b fi ks kt l ku kv">Total number of rows: 18<br/>Number of rows we are going to display: 16</span></pre><p id="c527" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">整合所有内容的最终代码片段:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="f286" class="kr ig hi kn b fi ks kt l ku kv">table_rows = []<br/>for row_id, row in enumerate(rows_data):<br/>    <br/>    # We will skip the last row as it contains missing value<br/>    if row_id == 15:<br/>        continue<br/>    <br/>    current_row = []<br/>    row_data = row.findAll('td', {})<br/>    <br/>    for col_id, data in enumerate(row_data):<br/>        <br/>        # We will skip the last column(References) as it does not contain any major information<br/>        if col_id == 4:<br/>            continue<br/>            <br/>        # We will also replace any commas(',') present in the data as we have to store the data in a csv<br/>        # file<br/>        text = data.text<br/>        text = text.replace(",", "")[:-1] # We are slicing the data as all the elemnets contain a carriage<br/>        # return('\n') at the end<br/>        current_row.append(text)<br/>            <br/>    table_rows.append(current_row)</span></pre><p id="3236" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">变量<strong class="jf hj"> table_rows </strong>是一个嵌套列表，包含所有行的数据，我们可以将这些数据保存在一个CSV文件中，稍后将其显示为一个数据框(使用pandas):</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="ed64" class="kr ig hi kn b fi ks kt l ku kv">import pandas as pd<br/>pd.DataFrame(table_rows, columns=column_titles).to_csv("Data/android_version_history_pandas.csv", index=False)</span><span id="8d26" class="kr ig hi kn b fi kw kt l ku kv"># Reading CSV file and Displaying data<br/>data_1 = pd.read_csv("Data/android_version_history.csv")<br/>data_1.head(10)</span></pre><p id="ed20" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">最终结果如下所示:</p><figure class="ki kj kk kl fd kz er es paragraph-image"><div class="er es lh"><img src="../Images/aad99a46cf258dff886a4cabc243cbea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*N32sdlWYB6OGG5dfnayyww.png"/></div></figure><h1 id="5a2c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">结论</strong></h1><p id="b837" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">本文展示了使用beautiful soup作为Html解析器来清理和检索所需信息的基础知识。</p><p id="a38a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在本文的第二部分，我将讨论如何从API中检索数据:<a class="ae kg" rel="noopener" href="/@chugharyan816/data-acquisition-using-web-scraping-web-crawlers-and-apis-part-2-b85afddb5f9e"> <em class="kh">【使用Web抓取、网络爬虫和API的数据采集(第二部分)】</em> </a>。</p></div></div>    
</body>
</html>