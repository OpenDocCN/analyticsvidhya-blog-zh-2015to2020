<html>
<head>
<title>Classifying Asteroids Using ML : A beginner’s tale (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用最大似然法分类小行星:初学者的故事(第1部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classifying-asteroids-using-ml-a-beginners-tale-part-1-f4385458f13?source=collection_archive---------28-----------------------#2020-07-12">https://medium.com/analytics-vidhya/classifying-asteroids-using-ml-a-beginners-tale-part-1-f4385458f13?source=collection_archive---------28-----------------------#2020-07-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/682ec30e9b9a96f01006679b097bc676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*2RCUNfK2pwGFEAmnp67XDg.jpeg"/></div></figure><p id="57d1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">机器学习爱好者你好！这是关于机器学习的分类算法的两部分初级教程。所以，不要再拖延了，让我们直接投入进去吧。</p><h1 id="e45b" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">关于数据集</strong></h1><p id="2537" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">我们将在本教程中使用的数据是由NASA提供的关于小行星的原始数据。它有50列，其中一列对小行星是否危险进行分类。在这类教程中，解释数据的特征(列)是一种常见的做法，但我不会这样做，也不会要求你研究它。我希望你能利用手头的数据，发现其中可能包含的洞见。通过这种方式，你会亲自感受到数据分析的美妙之处。你可以在这里找到数据集<a class="ae kn" href="https://www.kaggle.com/shrutimehta/nasa-asteroids-classification" rel="noopener ugc nofollow" target="_blank"><strong class="io hj"/></a><strong class="io hj">。</strong></p><h1 id="efed" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">导入库并上传CSV </strong></h1><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es ko"><img src="../Images/8b25d66c104fe5dd59ad7513e1985833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dsfDoEQOjgRCs6dHGcxabg.png"/></div></div></figure><p id="3c6c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从上面的pic，你可以看到我已经导入了pandas，numpy，seaborn和matplotlib库。</p><p id="b405" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一旦完成了库的导入，下一步就是上传csv文件。这通常通过使用pandas的read_csv函数来完成，然后将上传的文件存储在一个变量(nasa_df)中。为了查看文件的内容，我们使用了nasa_df.head()来显示文件，最多显示5行。</p><h1 id="e584" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">探索性数据分析</strong></h1><p id="66b6" class="pw-post-body-paragraph im in hi io b ip ki ir is it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj hb bi translated">一旦我们完成了文件的上传，下一步就是执行探索性的数据分析。不要被这个花哨的术语吓到。它只是意味着，从数据中获得洞察力，如果需要的话，将它标准化，去掉那些对我们想要预测的变量没有太大贡献的项。</p><p id="23cd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">对于该数据集，我将涵盖以下分析主题:</p><ul class=""><li id="351c" class="kx ky hi io b ip iq it iu ix kz jb la jf lb jj lc ld le lf bi translated">标签编码</li><li id="9534" class="kx ky hi io b ip lg it lh ix li jb lj jf lk jj lc ld le lf bi translated">重采样</li><li id="02d2" class="kx ky hi io b ip lg it lh ix li jb lj jf lk jj lc ld le lf bi translated">删除某些功能</li><li id="0dbf" class="kx ky hi io b ip lg it lh ix li jb lj jf lk jj lc ld le lf bi translated">相关热图</li></ul><p id="6399" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">标签编码</strong></p><p id="bf9d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">通常执行标签编码以将标签转换成数字形式，使得它们容易被机器解释。在我们的数据集中，我们有危险列，标签为真和假。我们将使用相同的标签编码。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/9182236bb81d63ecf5f43d62a5d35cc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*MEyFGhPLMzxxJDhSHGyq4g.png"/></div></figure><p id="d1dd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">允许我们这样做的方法是sklearn的LabelEncoder。value_counts函数返回特定列中唯一值的计数。从返回的值中，我们可以看到数据非常不平衡，因为0的数量多于1。为此，我们将执行重采样。</p><p id="db86" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">重采样</strong></p><p id="755b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当我们有一个不平衡的数据集时，执行重采样。有很多方法可以做到这一点，但对于本教程，我使用的是我觉得最简单的一种方法，它适合处理手头的问题。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es lm"><img src="../Images/b4736f564dc84f1e5bd93331cd9cfebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t_qg2ImpmFzUkoDFmjETIw.png"/></div></div></figure><p id="04fe" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们简单地将对应于两个标签的所有特征分成两个不同的数据帧。然后，我们通过限制在标签为0的情况下放入的值的数量来连接这两个数据帧。此后，分布变得平衡。</p><p id="d457" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">删除某些功能</strong></p><p id="9345" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">除了对目标变量贡献不大的特性之外，还有许多原因可以使特性被删除。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es ln"><img src="../Images/f6f5818da6d5861b0172213fd955c436.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPm4J1hOZmEUdh6mAMtRCQ.png"/></div></div></figure><p id="9058" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从上面可以看出，我们删除了大部分值，因为它们是以不同形式存储的相同值。我们将使用千米作为度量单位。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es lo"><img src="../Images/6338e9d11ce1839145b435d33e1807a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sro55oczIKa80oRp3QOHFw.png"/></div></div></figure><p id="618f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，我们删除整个列中只有一个唯一值的特性。在这种情况下，特征是轨道体和春分点。</p><p id="1ea3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以类似的方式删除大部分值后，我们将执行的下一步是绘制关联热图。了解一下。</p><p id="3b39" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我将在第2部分讨论相关性热图、归一化值和实现机器学习算法。</p><p id="58ed" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">点击这里的  <strong class="io hj">，进入第二部分。</strong></p><p id="0e0b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">希望你读这篇文章的时候觉得有趣，并且学到了一些新的东西！！如果你愿意，留下一些掌声和评论。</p></div></div>    
</body>
</html>