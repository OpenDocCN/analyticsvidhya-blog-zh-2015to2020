<html>
<head>
<title>[Paper Breakdown] Modeling Relational Data with Graph Convolutional Networks (Schlichtkrull et al., 2018)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">【论文分解】用图卷积网络对关系数据建模(Schlichtkrull等人，2018)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/paper-series-2-modeling-relational-data-with-graph-convolutional-networks-schlichtkrull-et-al-b009ff48ab87?source=collection_archive---------7-----------------------#2020-03-09">https://medium.com/analytics-vidhya/paper-series-2-modeling-relational-data-with-graph-convolutional-networks-schlichtkrull-et-al-b009ff48ab87?source=collection_archive---------7-----------------------#2020-03-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="dd38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这几天真的迷上了几何深度学习。特别是，我对图形神经网络(GNN的)及其应用非常感兴趣。对于那些不熟悉这个话题的人，我强烈建议你们帮自己一个忙，好好读一读，因为那里有很多很好的资源。</p><p id="0a2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我今天要写的论文是一项建立在最近流行的图形卷积网络(GCN网络)之上的研究。本文的合著者Thomas Kipf是流行的GCN模型的作者，他也有一篇很棒的博文解释了这个话题。</p><h1 id="2bda" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">1.介绍</h1><p id="a417" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">作者首先介绍了一个被称为<a class="ae jd" href="https://en.wikipedia.org/wiki/Statistical_relational_learning" rel="noopener ugc nofollow" target="_blank">统计关系学习(SRL) </a>的主题。SRL在知识库环境中的任务非常重要，因为现代知识库太大太复杂，无法手工管理。也就是说，本文的作者试图通过将知识库视为多关系图来解决这个问题，实体是节点，关系是边。</p><p id="d0f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作者在本文中使用的两个任务是实体分类和链接预测。</p><h2 id="8d71" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">实体分类</h2><p id="7bcf" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">用于该任务的模型类似于在<em class="kv">使用图卷积网络的半监督分类(Kipf和Welling，2017) </em>中提出的GCN。在图上运行GCN后，对每个节点使用softmax分类器。本质上，你有两个模型:GCN +分类器。</p><h2 id="caab" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">链接预测</h2><p id="0cf3" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">这类似于实体分类任务，但是我们有一个额外的组件。用于该任务的模型类似于一个<a class="ae jd" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">自动编码器</a>。编码器部分将通过关系GCN (R-GCN)在执行卷积运算后基本上提供节点表示，解码器是一种张量分解方法，称为DistMult，来自<em class="kv">嵌入知识库中用于学习和推理的实体和关系(Yang et al .，2014) </em>。</p><p id="8745" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这两项任务的总体架构如下:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es kw"><img src="../Images/084fbd3720d85cd9f44ea00b183cbc7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*o6e82q0s0XwjYUjlcamSHg.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">论文中的图3。</figcaption></figure><h1 id="c599" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">2.神经关系建模</h1><p id="b545" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">本节将分析消息传递在GNN环境中是如何工作的。</p><h2 id="83eb" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">2.1关系图卷积网络</h2><p id="1e4c" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">这指的是本文中使用的R-GCN。它基本上是Kipf和Welling 2017年GCN的延伸。主要区别在于，<strong class="ih hj"> <em class="kv"> Kipf和Welling，2017是基于对本地邻域的操作，而R-GCN是针对大规模关系数据的。</em>T13】</strong></p><p id="caef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">R-GCN可以被认为是更一般的消息传递框架的一个特例:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es li"><img src="../Images/941cda105e538a6df4061954f801e3c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*PY3SNG9SzQJN2JlvAEjGzw.png"/></div></figure><p id="ee78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我一直在重复我自己，但是神经网络中消息传递的本质是，一个节点在一次消息传递后的表示基本上是其邻居的总和。这在上面的等式中很明显(注意sigma)。这里$g_m$可以是从神经网络到简单的权重乘法的任何东西(如Kipf和Welling，2017年的情况)。</p><p id="20c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个通用消息传递框架的基础上，作者扩展了这个等式以考虑多关系图:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lj"><img src="../Images/456dffc1469fc48e1c73afaa47d9b2de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*CeWWTks9qKkJdPvb3aB1jw.png"/></div></figure><p id="a0c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，$\mathcal{N}_i^r$指的是在关系$r$下的节点$i$的邻居集。例如，如果节点1有三个邻居，其中只有两个处于“is_friend_of”关系下，那么我们只将这两个节点纳入聚合。$c_{i，r}$是一个归一化常数，可以学习或简单地设置为$\mathcal{N}_i^r$.的长度注意第二项不包括在求和中。</p><p id="5b66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以看看图中的R-GCN是如何工作的:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lk"><img src="../Images/21c9801d4c824e0f9ea65efa8513060b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*r5aN5z3FvMILRpirjQoHxQ.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">论文中的图2。</figcaption></figure><p id="e99b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以看到，R-GCN消息传递框架同时考虑了传入和传出方向。</p><h2 id="822f" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">2.2正规化</h2><p id="3d74" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">可以想象，像R-GCN这样的模型的参数数量会随着图表的大小快速增长。为了解决这个问题，作者提出了两种正则化技术:基对角分解和块对角分解。</p><h2 id="d5b0" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">基对角分解</h2><p id="2ce6" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">回想前一等式中的权重矩阵，该分解方法实质上将该矩阵分解成基变换的线性组合:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es ll"><img src="../Images/8bc8fb9df0a94a3da0432eb2df233a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*EbrF1PhHCjleIDALmRZEKg.png"/></div></figure><p id="d9dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作者并没有真正说明如何获得基向量V，但他们确实说明了这可以被视为“不同关系类型之间有效的权重分配”的一种形式。</p><h2 id="21b2" class="kh jf hi bd jg ki kj kk jk kl km kn jo iq ko kp js iu kq kr jw iy ks kt ka ku bi translated">块对角分解</h2><p id="f9d0" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">块对角分解本质上是相同的，除了我们用矩阵代替向量。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lm"><img src="../Images/072820bf6b228bb4c32155f603dbe579.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*3l1kKv_c8AmaLnSsJw2Wuw.png"/></div></figure><p id="4d82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，对于我们从哪里得到这些问题，也没有一个明确的解释。如果我发现了什么，我会更新文章。</p><p id="9ab0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是本文的基本内容。如果你对R-GCN模型的实际表现很好奇，我强烈建议你看一看原文。</p><blockquote class="ln lo lp"><p id="5757" class="if ig kv ih b ii ij ik il im in io ip lq ir is it lr iv iw ix ls iz ja jb jc hb bi translated">我有意省略了本文的其他部分(即特定任务的实现、实验设置等。)因为我想更专注于直觉和方法。如果时间到了，我可以随时编辑这些细节，但现在这不是这个系列的主要焦点。</p></blockquote></div></div>    
</body>
</html>