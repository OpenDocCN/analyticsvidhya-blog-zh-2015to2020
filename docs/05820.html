<html>
<head>
<title>UDFs in Pyspark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pyspark中的UDF</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/udfs-in-pyspark-270bc7890786?source=collection_archive---------13-----------------------#2020-05-03">https://medium.com/analytics-vidhya/udfs-in-pyspark-270bc7890786?source=collection_archive---------13-----------------------#2020-05-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1b77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Pyspark sql库本身提供了多种应用于数据框的函数，但是我们可以在任何特殊需求的情况下定义自己的函数。这些被称为UDF或用户定义函数。我们将深入探讨在pyspark数据帧及其不同格式中应用UDF。</p><p id="b0c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">不同格式</strong></p><ol class=""><li id="b4a2" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">自定义项()</strong></li></ol><p id="8692" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这被认为是在pyspark上定义UDF最容易理解的方式。我们将采用学生姓名和分数的示例数据集，并在其上测试我们的功能。数据看起来像这样</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es jm"><img src="../Images/356ce8610de9034b13cb1dd7fce8b51f.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*TPi1AzPCw_iQjJopvfkKyg.png"/></div></figure><p id="9522" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们想要提取所有学生的名字，这可以通过udf来完成，如下所示</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ju"><img src="../Images/134faf93b4ee8134ed3835482b6cdb92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*7L9UO4AAUyoEF_oZg59QfQ.png"/></div></figure><p id="f43c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果是</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es jv"><img src="../Images/633704ce197f3ce02e56101d7bec07a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*0PB2cRtZxY0xF7H0-3zvEQ.png"/></div></figure><p id="0fb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其工作原理是，我们定义一个python函数，并将其传递给pyspark的udf()函数。</p><p id="24ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一种编写udf的混乱方式，尽管对于可解释性来说很好，但是当涉及到以这种格式编写代码的可维护性时，你有两个函数来管理python函数和pyspark udf。</p><p id="3fb7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。@udf decorator </strong></p><p id="646a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于上面的例子，定义udf的一种更干净的方式是通过UDF装饰器，如下所示</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es jw"><img src="../Images/83b0c6c439df247f9a268ade031e0437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*VvAQ-JoMYcq9Y0k0RIL8xA.png"/></div></div></figure><p id="255c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里您只需要定义一个函数和返回数据类型，但是如果您想将同一个函数用作python函数和pyspark udf呢？例如，假设我想先在一个较小的数据集上测试我的函数，然后在pyspark数据帧上使用它。</p><p id="18cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中一种方法是注释掉@udf decorator，这样函数就又变成了一个普通的python函数。</p><p id="5ce8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。@ py_or_udf </strong></p><p id="0e42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了能够使用与python和pyspark udf相同的函数，我们可以定义一个新的decorator @py_or_udf，如下所示</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es kb"><img src="../Images/5f9e489c9facc1c4ebddb1da24e0c24c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*EOcSQcH9WXG5LHSox3Q-ug.png"/></div></figure><p id="be95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是定义pyspark udfs的最干净的方法，因为它可以在部署和实验时有效地使用。</p><p id="b4d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">应用pyspark udfs行</strong></p><p id="cbd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了理解这一点，我们将举一个简单的例子，假设我们想要根据分数标准来标记学生在某一科目上是通过还是失败</p><p id="b83e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果科目是数学，分数超过50分，那么通过，</p><p id="30a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其他科目分数&gt; 40则及格</p><p id="1349" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如你所看到的，上面的问题涉及到要解决的2行数据帧，“考试名称”和“考试点”，将有一定的语法变化，以应用自定义项</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es kc"><img src="../Images/8344d3e74cd7a804abf117a36801e6a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4AIBh0ZgCvWt6n-w--y5yA.png"/></div></div></figure><p id="a20c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的例子中你可以看到，我们可以将dataframe作为一个结构来传递，并在其上应用udf。</p><p id="8983" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">对聚合数据应用UDF(udaf):</strong></p><p id="fe16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Pyspark不直接支持用户定义的聚合函数，但是有一种方法可以在pyspark中使用来实现它们。</p><p id="7db8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以做的是在一个组中使用F.collect_list()或F.collect_set()函数来分别收集列表或集合中的数据，并在列表顶部应用我们的udf。</p><p id="1390" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将以一个简单的问题为例，找出每个科目的平均分数，看看如何使用udf来实现，尽管已经有一些方法可以不用UDF来实现，但这只是一个简单的例子！</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es kd"><img src="../Images/4e45ecf942dd543fd1d1f0b9b6919b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_6BvkLMpWQ5SftUKFU2s-g.png"/></div></div></figure><p id="f810" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">collect_list语句返回一个带有单列标记列表的数据帧</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ke"><img src="../Images/322f4511759457c0b2c8c47ee0777f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*runxyz24oJucIfNDpvin9g.png"/></div></figure><p id="c66d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">获得get_avg_marks()后，将udf应用于数据帧，以获得每个科目的平均分数。</p><p id="341e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结论</strong></p><p id="09e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在pyspark数据帧上使用pandas udfs时，有一些更高级的主题可以派上用场，这本身就是一个详细的主题，需要单独的文章。</p><p id="31e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我正在撰写一系列文章来帮助理解数据科学和工程最基本的方面，即数据转换。如果您想了解pyspark中的windows函数，请参考下面列出的文章。</p><p id="b3f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢！！</p><div class="kf kg ez fb kh ki"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/intro-to-window-function-in-pyspark-with-examples-3a839b6e1cac"><div class="kj ab dw"><div class="kk ab kl cl cj km"><h2 class="bd hj fi z dy kn ea eb ko ed ef hh bi translated">pyspark中的窗口函数介绍及实例</h2><div class="kp l"><h3 class="bd b fi z dy kn ea eb ko ed ef dx translated">作为数据科学家/数据工程师，大数据转型是一个非常重要的方面。Spark框架是…</h3></div><div class="kq l"><p class="bd b fp z dy kn ea eb ko ed ef dx translated">medium.com</p></div></div><div class="kr l"><div class="ks l kt ku kv kr kw js ki"/></div></div></a></div></div></div>    
</body>
</html>