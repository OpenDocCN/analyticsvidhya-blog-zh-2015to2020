<html>
<head>
<title>Computer Vision- Predicting Image Samples By Extracting Features From Images And Transfer Learning.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉-通过从图像中提取特征和转移学习来预测图像样本。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/computer-vision-predicting-image-samples-by-extracting-features-from-images-and-transfer-learning-127da30e5fa6?source=collection_archive---------15-----------------------#2020-01-11">https://medium.com/analytics-vidhya/computer-vision-predicting-image-samples-by-extracting-features-from-images-and-transfer-learning-127da30e5fa6?source=collection_archive---------15-----------------------#2020-01-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="9f20" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">通过使用视觉几何组(一种深度卷积网络)进行基于机器的图像预测。</h2></div><p id="0ef3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过应用计算机视觉技术和自动化类似于人类视觉如何识别和预测模式的任务，可以解决空间、医学和虚拟现实中的各种未解之谜。</p><p id="2063" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">工艺流程图</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/1a80adda93012823a8b1f4f510c53b37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tBpAjgcr36VWdOCkYGn63w.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">预测图像的步骤</figcaption></figure><p id="feae" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">数据集</strong></p><p id="95d3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据集是由Alexander Mamaev提供的花图像。</p><p id="a2f1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该数据由4242幅花的图像组成。图像的像素分辨率为320x240像素。数据是从flickr、google和yandex的图片中搜集来的。</p><p id="e051" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据基于五类图像:雏菊、郁金香、玫瑰、向日葵和蒲公英。</p><p id="2f85" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">读取数据集</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es kj"><img src="../Images/d96841c9fbf1ae03b9ff9128fc59890d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*tPI54KVJzONWOzAdpQEW2g.png"/></div></figure><p id="5076" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">定义每类图像的路径并从VGG16中获取权重。</p><p id="1c8c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> VGG →视觉几何组</strong></p><p id="80ab" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每个输入图像大小保持一致。VGG有3个相连的层，前2层各有4096个频道，第3层有1000个频道→每类1个。</p><p id="b85c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">隐藏层使用优化的ReLu，与AlexNet等其他模型相比，VGG的训练时间要少得多。较小尺寸的卷积层和较大权重的层导致性能提高。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kk"><img src="../Images/a68edc0122415ff2c2a735920623baa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cN-fhmbxR5-TgPLheWPh2A.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kl"><img src="../Images/0f165c4ebe4b0a4f45c6b20ca5b3a828.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hvOlhOT0hMvlzM1b9icmKA.png"/></div></div></figure><p id="cd3f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">培训和测试</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es km"><img src="../Images/e8ff6c0e606237e27eeefc1395f002b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ezRALyw6EqNl7ejnbZ-v6Q.png"/></div></div></figure><p id="3934" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可视化数据</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kn"><img src="../Images/8043d486c8aa7567a54d233afd4a588a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZsFRCW_QsZzDsrlDV-0ZQ.png"/></div></div></figure><p id="2cf9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">标签编码</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es ko"><img src="../Images/dcce7d8ed622ca12bb46d5c7bdc4fbe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6dPODLRZxJ-6Otj1udpssw.png"/></div></div></figure><p id="a7c9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">构建CNN</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kp"><img src="../Images/d4966bfb517312e16b502c8b99a94802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DugSi5oocwu_MX4Nww5X0g.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kq"><img src="../Images/cfaf04a9cba31e95b03aef7df7bf71e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zk1cQ3mOPC4yc4AJRkc3dA.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es kr"><img src="../Images/0ef97c1ca26291ad9de814fd5d3fdd03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZUYqg7qcy9qAg07gb8imFQ.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es ks"><img src="../Images/240bc59a5efb7d2b1be676fa16a4c21d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rmNfZuxtfpG9CE8ceyjb2w.png"/></div></div></figure><p id="edb8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">预测结果</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es kt"><img src="../Images/50ef7457d95a4d7b2561a7eb67accf0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*rRBGvyhwHfwcq2Yh0HcEAg.png"/></div></figure><p id="0284" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">参考资料:</p><ol class=""><li id="dbe3" class="ku kv hi iz b ja jb jd je jg kw jk kx jo ky js kz la lb lc bi translated">用于大规模图像识别的极深度卷积网络:【https://arxiv.org/abs/1409.1556 T4】</li><li id="6e85" class="ku kv hi iz b ja le jd lf jg lg jk lh jo li js kz la lb lc bi translated">用于keras的VGG16预训练模型:kaggle数据集下载-d keras/vgg16</li></ol></div></div>    
</body>
</html>