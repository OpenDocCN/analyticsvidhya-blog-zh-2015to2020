<html>
<head>
<title>Sentiment Classification based on Financial News data for Portfolio/Asset Managers &amp; Credit Risk Officers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">投资组合/资产经理和信用风险官基于金融新闻数据的情绪分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sentiment-classification-based-on-financial-news-data-for-portfolio-asset-managers-credit-risk-2f6b54e5dd5e?source=collection_archive---------10-----------------------#2020-01-15">https://medium.com/analytics-vidhya/sentiment-classification-based-on-financial-news-data-for-portfolio-asset-managers-credit-risk-2f6b54e5dd5e?source=collection_archive---------10-----------------------#2020-01-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/faea13ac3be5446fbd9fa35b0396bd6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JSIbH49UPiqkFsRlFciEtQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来源:miro.medium.com</figcaption></figure><p id="8428" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">投资组合经理和信用风险管理人员的工作相当令人生畏。他们在任何时候都需要对当前的市场状况保持乐观。这些投资银行专业人士被认为是股票/工具/交易对手/发行人的技术和基本面分析专家，或者至少擅长使用各种COTS(商业现货)工具来生成数字/指标并识别市场模式，以帮助指导他们的投资决策。</p><p id="41d0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">有了这些数据，投资组合经理就可以决定在他们的投资组合中添加/删除工具，因为信贷员设定/调整交易限额或向他们的投资银行有兴趣与之交易的交易对手提供贷款。这是金融工作家族中最突出的工作之一，因为即使是一个错误的评估也很容易产生牵强的影响，导致投资者或银行损失大量投资者的资金——这对银行或金融机构来说是一场噩梦。</p><p id="e6e0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们为投资银行家的工具箱添加另一个工具——这个工具将帮助他们确定他们目前正在研究的股票/交易对手的市场情绪。</p></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><p id="34d3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在本文的其余部分，我们将专注于创建一个深度神经网络模型，该模型将接受一个文本体(预计是一篇金融新闻文章或Twitter讨论的摘录，甚至是一封包含金融内容的电子邮件！)并将其转化为市场情绪(而不需要手动逐字阅读文本)。</p><p id="f2bb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">该模型的编码将包括以下步骤:</p><p id="171a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">1.下载财经新闻情感数据；希望有人已经为我们收集了这些数据；</p><p id="25b8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">2.选择用于将文本数据转换成嵌入向量的单词嵌入；我们可以使用word2vec模型从头开始创建这个嵌入，但是我们将把这部分留给另一篇文章；现在我们将重用互联网上免费提供的一个嵌入。</p><p id="93e9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">3.预处理文本数据；在将输入输入到我们的模型之前，我们需要将文本转换成数字。</p><p id="8441" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">4.设计一个由输入层、隐层和输出层组成的定制神经网络；我们将在隐藏层中使用LSTM，因为文本数据是连续的，而LSTM层是处理连续数据的理想选择。GRU层是另一种选择，我们可以选择。你可以自由地尝试自己的GRU层。</p><p id="668f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">5.基于财经新闻情感数据训练网络。</p><p id="67c8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">6.预测我们选择的金融文本的情绪。</p><p id="ba5f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在下一节中，我将更详细地介绍上述步骤，并在需要的地方内嵌代码片段。该代码也可从以下Github链接获得:</p><p id="c613" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae jz" href="https://github.com/rohitar/myprojects/tree/master/counterparty-sentiment" rel="noopener ugc nofollow" target="_blank">https://github . com/rohitar/my projects/tree/master/counter party-情操</a></p><p id="9746" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">下载财经新闻舆情数据</strong></p><p id="2afd" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">与任何机器学习模型一样，我们需要数据来训练我们的模型。因为我们想衡量金融文本的极性，我们需要既包含金融文本又包含其相应极性的数据。幸运的是，这些数据已经存在(由Pekka Malo等人发表),您可以从这里免费下载:</p><p id="ebff" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae jz" href="https://www.researchgate.net/publication/251231364_FinancialPhraseBank-v10" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/publication/251231364 _ FinancialPhraseBank-v10</a></p><p id="520b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">选择文字嵌入</strong></p><p id="d29a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们可以选择从头开始构建整个单词嵌入，但是当有人已经在大量文本数据上运行严格的训练来生成嵌入时，我们不想重新发明轮子。</p><p id="d13b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">那些不理解嵌入的人——这是一个简单的映射，将词汇表中的所有单词映射到它们对应的向量表示(在n维向量空间中——在创建嵌入时可以定义维度)。通常，word2vec模型用于使用Skipgram方法或连续单词包(CBOW)方法来创建单词嵌入。这些单词嵌入捕获单词之间的语义关系，并且相似的单词将在向量空间中聚集在一起。</p><p id="b742" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">其中一个可以免费下载的预训练单词嵌入是基于包含300万个单词的谷歌新闻，并且已经从谷歌新闻档案中训练了大约1000亿个单词(你可以想象训练这些嵌入将是多么艰巨的任务)。另一个流行的单词嵌入选项是脸书训练的fastText。</p><p id="527a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们将在磁盘上下载Google新闻嵌入，并将使用Gensim库将这些嵌入加载到内存中(注意，这将消耗大约5 GB的内存，因此请确保您运行该模型的机器有足够的RAM！).以下代码行将下载嵌入内容并将其加载到内存中(由Douwe Osinga提供—深度学习食谱):</p><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="b8e3" class="kj kk hi kf b fi kl km l kn ko">MODEL = 'GoogleNews-vectors-negative300.bin'<br/>path = get_file(MODEL + '.gz', 'https://s3.amazonaws.com/dl4j-distribution/%s.gz' % MODEL)</span><span id="9f0d" class="kj kk hi kf b fi kp km l kn ko">if not os.path.isdir('generated'):<br/>    os.mkdir('generated')</span><span id="20ea" class="kj kk hi kf b fi kp km l kn ko">unzipped = os.path.join('generated', MODEL)<br/>if not os.path.isfile(unzipped):<br/>    with open(unzipped, 'wb') as fout:<br/>        zcat = subprocess.Popen(['zcat'],<br/>                          stdin=open(path),<br/>                          stdout=fout<br/>                         )<br/>        zcat.wait()</span><span id="4a48" class="kj kk hi kf b fi kp km l kn ko">from gensim.models import KeyedVectors<br/>word2vec = KeyedVectors.load_word2vec_format(unzipped, binary=True)</span></pre><p id="ef4d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果需要，您可以通过使用load_word2vec_format方法中的“limit”参数来减少加载到RAM中的单词向量的数量，但是这可能会对您构建的最终模型的准确性产生影响。</p><p id="a14e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">预处理文本数据</strong></p><p id="dff1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">注意，任何深度学习或机器学习模型都不理解文本数据；模型只理解数字。因此，我们需要将输入文本中的单词标记为数字形式。我们将使用Keras库适当地标记输入金融文本中的字符串；本质上，我们将把输入数据中的每个单词映射到一个唯一的数字标记，最后使用这个映射把输入文本转换成数字串。这方面的代码如下所示:</p><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="d1b2" class="kj kk hi kf b fi kl km l kn ko">from tensorflow.keras.preprocessing.text import Tokenizer<br/>from tensorflow.keras.preprocessing.sequence import pad_sequences</span><span id="b829" class="kj kk hi kf b fi kp km l kn ko">tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOK)<br/>tokenizer.fit_on_texts(sentences)<br/>word_index = tokenizer.word_index<br/>sequences = tokenizer.texts_to_sequences(sentences)</span><span id="714d" class="kj kk hi kf b fi kp km l kn ko">X = pad_sequences(sequences, maxlen=MAX_LENGTH, truncating=TRUNC_TYPE)<br/>y = to_categorical(labels)</span></pre><p id="3230" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，我们需要将分配给每个单词的标记转换成它们各自的嵌入向量。为此，我们需要在标记输入数据时，使用上面创建的单词索引来重新索引预训练的Gensim嵌入。下面给出了这样做的代码(由Antonio Gulli提供Keras的深度学习):</p><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="2644" class="kj kk hi kf b fi kl km l kn ko">embedding_weights = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))<br/>for word, index in word_index.items():<br/>  try:<br/>    embedding_weights[index,:] = word2vec[word]<br/>  except KeyError:<br/>    pass</span></pre><p id="dd2e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">设计神经网络</strong></p><p id="9b2b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在终于到了定义神经网络的时候了。我们将使用以下代码来定义我们的神经网络:</p><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="0132" class="kj kk hi kf b fi kl km l kn ko">from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Embedding, Dense, Bidirectional, LSTM</span><span id="0a3d" class="kj kk hi kf b fi kp km l kn ko">model = Sequential()<br/>model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LENGTH, weights=[embedding_weights]))<br/>model.add(Bidirectional(LSTM(64, return_sequences=True)))<br/>model.add(Bidirectional(LSTM(32)))<br/>model.add(Dense(64, activation="relu"))<br/>model.add(Dense(3, activation="softmax"))</span></pre><p id="ba74" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">请注意，上面的嵌入层使用了我们之前创建的变换后的嵌入权重。然后，矢量化输入将通过几个LSTM层和一个完全连接的密集层。</p><p id="0805" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在高层次上，LSTM层包括长期存储单元和短期存储单元。长期单元本质上捕捉文本主体中距离较远的单词的关联，而短期单元捕捉看起来距离较近的单词的关联。LSTM是一个复杂的话题，因此详细的讨论超出了本文的范围。</p><p id="ee16" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后，来自完全连接的密集层的数据被传递到3个类的“softmax”输出。这3个类将指定文本极性，即。积极、中立或消极。</p><p id="288e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">太好了！现在我们已经定义了神经网络，我们将跳到下一步。</p><p id="c907" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">训练网</strong></p><p id="6ec1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这一步将涉及使用我们在第一步中下载的金融新闻情绪数据来训练网络。然而，我们不想在整个数据上训练模型；我们希望保留一些数据，这些数据对模型来说是不可见的，以便以后可以用来评估我们训练好的模型。为此，我们将使用以下代码将数据分为训练和测试，测试规模为30%:</p><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="ef70" class="kj kk hi kf b fi kl km l kn ko">from sklearn.model_selection import train_test_split</span><span id="c6c8" class="kj kk hi kf b fi kp km l kn ko">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)</span></pre><p id="9c97" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，我们将编译模型，并随后根据测试数据对其进行拟合。为此，我们将使用以下代码:</p><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="6d99" class="kj kk hi kf b fi kl km l kn ko">model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])<br/>history = model.fit(X_train, y_train, batch_size=64, epochs=20, validation_data=(X_test, y_test))</span></pre><p id="6d49" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">请注意，我们选择了“亚当”优化器，因为众所周知，它最适合基于序列的模型，如LSTM。损失标准被定义为分类交叉熵，用于多类分类问题，如我们的问题。我建议在GPU机器上运行训练——因为训练的速度预计比在CPU上快10倍。如果您没有物理GPU，可以考虑使用Google Colab(基于云的GPU)。</p><p id="7950" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在运行20个时期的训练之后，您将获得大约99%的测试准确率&amp; 75%的验证准确率——这确实是一个非常好的开始。因此，你现在有了一个可靠的模型，可以根据输入的金融文本预测市场情绪。</p><p id="8b69" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我鼓励你尝试不同的模型参数/模型架构来进一步提高准确性。此外，由于训练和测试准确性之间的差距很大，该模型似乎有点过度拟合——我建议您尝试正则化技术，如辍学。</p><p id="b19b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">情绪预测</strong></p><p id="32cb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在是时候带着你的模型上路了。使用以下代码，通过输入您选择的金融文本来产生市场情绪。</p><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="f6e2" class="kj kk hi kf b fi kl km l kn ko">pred_sentences = ["&lt;input the financial text of your choice&gt;"]<br/>pred_sequences = tokenizer.texts_to_sequences(pred_sentences)<br/>X_pred = pad_sequences(pred_sequences, maxlen=MAX_LENGTH, truncating=TRUNC_TYPE)<br/>y_pred = model.predict(X_pred)<br/>y_pred</span></pre><p id="a137" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">你相信情绪预测的神圣性吗？如果是的话，现在是时候围绕我们刚刚开发的模型设计一个用户界面，并将其发送给你的信贷人员/投资组合经理，使他们能够使用该模型做出更好的投资决策。</p><p id="3afb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我真心希望你喜欢这篇文章——如果你能在下面留下评价/反馈，我将不胜感激。</p></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><p id="8870" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">学分:</p><ol class=""><li id="7c0c" class="kq kr hi iw b ix iy jb jc jf ks jj kt jn ku jr kv kw kx ky bi translated">由Anuj Kumar(【https://www.linkedin.com/in/anujchauhan/】T2)合著</li><li id="4102" class="kq kr hi iw b ix kz jb la jf lb jj lc jn ld jr kv kw kx ky bi translated">概念:Simarjit Singh Lamba和Rohit Arora</li><li id="e9d0" class="kq kr hi iw b ix kz jb la jf lb jj lc jn ld jr kv kw kx ky bi translated">佩卡·马洛等人发表的财经新闻情感数据集</li><li id="198b" class="kq kr hi iw b ix kz jb la jf lb jj lc jn ld jr kv kw kx ky bi translated">《深度学习食谱》</li><li id="6882" class="kq kr hi iw b ix kz jb la jf lb jj lc jn ld jr kv kw kx ky bi translated">Antonio Gulli——Keras深度学习</li><li id="1ad2" class="kq kr hi iw b ix kz jb la jf lb jj lc jn ld jr kv kw kx ky bi translated">霍布森·莱恩等——自然语言处理在行动</li><li id="7595" class="kq kr hi iw b ix kz jb la jf lb jj lc jn ld jr kv kw kx ky bi translated">图片-来源于miro.medium.com(<a class="ae jz" href="https://miro.medium.com/max/1196/1%2aLTpcCt2mYa2-edjdti8S4Q.jpeg" rel="noopener">https://miro . medium . com/max/1196/1% 2 altpcct 2 mya 2-edjdti 8s 4 q . JPEG</a>)</li></ol></div></div>    
</body>
</html>