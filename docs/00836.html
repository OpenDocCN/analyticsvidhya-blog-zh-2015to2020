<html>
<head>
<title>Get your hands dirty with Hadoop Map Reduce Job using Cloudera platform</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Hadoop Map简化工作使用Cloudera平台</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/get-your-hands-dirty-with-hadoop-map-reduce-job-using-cloud-era-platform-big-data-f929fe0f12b4?source=collection_archive---------3-----------------------#2019-09-12">https://medium.com/analytics-vidhya/get-your-hands-dirty-with-hadoop-map-reduce-job-using-cloud-era-platform-big-data-f929fe0f12b4?source=collection_archive---------3-----------------------#2019-09-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="c15e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">利用云时代平台分析连锁门店销售数据</strong></h1><h1 id="88e3" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">我们将通过这个博客实现什么！！</h1><blockquote class="jd je jf"><p id="29c7" class="jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jj hj">分析使用MapReduce的不同用例。</strong></p><p id="fb37" class="jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jj hj">实现基本的MapReduce概念。</strong></p><p id="5909" class="jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">运行一个MapReduce程序。</p><p id="ec1c" class="jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jj hj">了解MapReduce中的输入拆分概念。</strong></p><p id="b561" class="jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jj hj">·了解Map Reduce作业提交流程。</strong></p><p id="066a" class="jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jj hj">在MapReduce中实现作业跟踪器和作业追踪器。</strong></p></blockquote><h1 id="7c3e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">什么是MapReduce？</strong></h1><p id="7de5" class="pw-post-body-paragraph jg jh hi jj b jk kf jm jn jo kg jq jr kh ki ju jv kj kk jy jz kl km kc kd ke hb bi translated">作为云计算、虚拟化和大数据等技术的结果，MapReduce是用于处理大数据的新编程范式，称为大数据。MapReduce计算发生在与云相关的数千台计算机上。因此，它可以利用与云相关联的图形处理单元(GPU)的并行处理能力。现实世界的公司正在从传统计算转向云计算，从传统数据挖掘转向大数据分析。这背后的原因是数据的指数级增长。存储和处理这些数据需要一个与云计算相关的大型数据生态系统。在这种情况下，MapReduce编程模型受到分布式编程框架(如Hadoop)的支持。然而，很难保护MapReduce计算免受恶意攻击。</p><p id="4aca" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">文献中有很多云存储机制。然而，在Hadoop和大数据生态系统中保护MapReduce编程范式仍有待探索。在本文中，我们提出了一种差分隐私算法来保护大数据免受恶意软件映射器和Reducer的攻击。我们构建了一个应用程序原型来演示概念证明。结果表明了该方法的有效性。</p><p id="998d" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">最近，公司开始更加重视数据和数据分析，以进行战略决策。由于现实应用中的数据呈指数级增长，拥有一个良好的生态系统来存储和管理以数量、速度和多样性为特征的大数据变得至关重要。云计算的出现通过提供大量流行的共享计算资源，使得大数据的处理成为可能。同时出现了Hadoop分布式编程框架。该基础设施支持存储和处理大量数据，并利用数千台标准计算机进行并行处理。因为大数据处理需要计算能力和存储，云计算已经成为实现这一点的方式。借助云计算、虚拟化、大数据、Hadoop等大数据平台，在分布式环境中打造生态系统。MapReduce是用于大型数据处理的编程模型。这是一种新的编程方法，它包含了地图并减少了任务。这项工作是在许多标准计算机分布的环境中完成的。如上所述，Amazon提供了自己的MapReduce编程模型，称为基于Hadoop的弹性MapReduce。所以Hadoop是通过支持MapReduce编程来处理大数据的框架。然而，当映射器或齿轮箱受到损害时，就会出现安全问题。映射和作业缩减容易受到各种类型的攻击。在本文中，我们使用了mapper和reducer来计算美国每个商店的总销售额。</p><h1 id="11f4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"> <em class="kn">意念</em> </strong></h1><p id="f0db" class="pw-post-body-paragraph jg jh hi jj b jk kf jm jn jo kg jq jr kh ki ju jv kj kk jy jz kl km kc kd ke hb bi translated">分析和确定一个国家/地区不同商店的收入。</p><p id="496a" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">利用大数据Hadoop平台的核心概念HDFS和MapReduce来解决问题。</p><p id="267d" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">通过将工作分成一组独立的任务来并行处理大量数据。</p><p id="dce6" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">使用MapReduce进程文件将它分成块并并行处理。</p><h1 id="071f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">数据的初步概念</strong></h1><h1 id="ab60" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"> A .数据描述</strong></h1><p id="b256" class="pw-post-body-paragraph jg jh hi jj b jk kf jm jn jo kg jq jr kh ki ju jv kj kk jy jz kl km kc kd ke hb bi translated">数据集取自Udacity，一个提供广泛课程的在线学习平台。数据集包含关于沃尔玛每个商店在特定年份的销售数据的数据。这个数据集包含分类变量和数值变量。有6个属性和超过10，000，000个实例。</p><p id="cb79" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated"><strong class="jj hj">以下是必需的字段:</strong></p><p id="1136" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">日期</p><p id="50a6" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">时间</p><p id="0a9a" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">位置</p><p id="3c06" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">项目</p><p id="53ae" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">价格</p><p id="7f7c" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">卡片</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/671963fd549f0d168cb2302944e60506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*VWx1lXo6G7l87Hb-7Ylojw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih">图1商店销售数据集</strong></figcaption></figure><p id="aa77" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">数据集可从以下链接下载:</p><p id="2ce5" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated"><a class="ae la" href="https://drive.google.com/file/d/1Ar12GZISlf-JMQSj1FQsy0_XhSqMH4F9/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"><strong class="jj hj">https://drive . Google . com/file/d/1 ar 12 gzislf-jmqsj 1 fqsy 0 _ xhsqmh 4 f 9/view？usp =共享</strong> </a></p><h1 id="8c08" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"> B .方法论</strong></h1><p id="83a8" class="pw-post-body-paragraph jg jh hi jj b jk kf jm jn jo kg jq jr kh ki ju jv kj kk jy jz kl km kc kd ke hb bi translated"><strong class="jj hj"> Hadoop框架</strong></p><p id="e3fe" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">Hadoop是一个开源框架，可用于处理海量数据，即数据的大小可能以peta字节为单位。它是一个分布式计算框架。Hadoop的架构是主从架构，其中Hadoop的底层包括并行工作的其他机器。大量数据被分成在不同机器上运行的不同数据集。每台机器将执行任务。每台机器都有一个任务跟踪器和作业跟踪器。Hadoop框架的主要组件是HDFS (Hadoop分布式文件系统)和MapReduce概念。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lb"><img src="../Images/0b968de1ba8ea75a718696a8cad2de88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*9adeUEgPMpLrwraXSl3_tA.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih">图2 Hadoop框架的高层设计</strong></figcaption></figure><p id="a60c" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated"><strong class="jj hj"> MapReduce概念</strong></p><p id="1bea" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">MapReduce是一个编程模型。它通过并行拆分大量数据并将其发送到不同的机器来简化处理过程。它支持结构化和非结构化数据格式。使用的主要编程语言是Java，但也支持其他编程语言，如python、c、c++。R等其他数据分析编程工具也可以与Hadoop集成。</p><p id="6221" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated"><strong class="jj hj"> MapReduce编程有两个功能:</strong></p><p id="a9b2" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated"><strong class="jj hj"> a .映射器功能</strong></p><p id="f3d5" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">在这个函数中，大输入被分成子问题输入或任务。这些任务被分配给节点，这些节点还将子任务分成子子任务。一旦处理完成，它就映射成键值对格式。在映射被发送到reducer函数之前，它们会根据键进行混洗和排序。</p><p id="7911" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated"><strong class="jj hj"> b .减速器功能</strong></p><p id="e8c9" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">此函数用于处理，例如查找每个键的总计数或其他需要找出的分析。它产生一个或一组结果。</p><p id="2174" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated"><strong class="jj hj"> HDFS — Hadoop分布式文件系统</strong></p><p id="0b3e" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">在处理之前，本地磁盘中的大文件或实时数据存储在Hadoop的分布式文件系统中，称为HDFS。它有用于存储和计算的节点。可以在HDFS内创建、删除或管理文件。它还允许创建目录。它有数据节点和名称节点，用于存储和访问文件。</p><h1 id="4e87" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"> C. </strong> <strong class="ak">工艺设计</strong></h1><p id="a573" class="pw-post-body-paragraph jg jh hi jj b jk kf jm jn jo kg jq jr kh ki ju jv kj kk jy jz kl km kc kd ke hb bi translated">假设有一个销售数据的大文件，里面包含了沃尔玛各个门店在特定年份的销售数据。文件的行看起来像这样。我们需要找出2012年每个商店的总销售额。现在，由于该文件将包含数百万个项目，串行处理该文件是不可行的。Map Reduce帮助我们将文件分成更小的块，在集群中的不同机器上处理这些块，然后合并结果。</p><p id="cd02" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">我们将有一组称为映射器和减速器的机器来帮助并行运行这个过程，而不是一台机器来完成这项工作。制图者和简化者的工作是什么？该文件将被分成较小的区块，我们将为每个映射器分配一个区块。映射器的工作将是获取大块并分离每个商店的销售数据。例如，如果一个制图者得到上述记录，他将做三堆，即纽约、迈阿密和洛杉矶，并将每一堆的销售数据保存在特定的堆中。每个减速器将被分配一组存储。reducer将从其指定商店的映射器中收集数据，并对该商店的销售额求和。例如，如果第一个reducer被分配到NYC，他将从每个映射器收集NYC销售数据，并对这些值求和以获得NYC的总销售额。每个减速器按字母顺序通过他的桩。所以，第二个减速器将在迈阿密之前处理LA的销售。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/d76ac7d366b3d2fe7bab1745a92899fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*AZImlpDphmxbw8-p3U39nw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih">映射器-减速器</strong></figcaption></figure><p id="d5cc" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">所以，映射器只是程序，每个程序作用于文件的一小块。映射器产生一个中间键值对。在我们的例子中，它是商店名称和商品价格。一旦地图绘制者完成了他们的工作，一个被称为洗牌和排序的阶段就开始了。Shuffle是将记录从映射器移动到已经分配了这些记录的缩减器。排序是通过特定的缩减器对数据进行排序。reducers得到一个键和值的列表。在我们的例子中，商店名称和每个商店的销售数据。它遍历所有的值，最终产生每个商店的总销售额。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lc"><img src="../Images/8f9facccba48b169cff971eedd268786.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*r-cjBluhGTnTDb01fUygOg.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih">键值对</strong></figcaption></figure><h1 id="3b11" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">丁实施</strong></h1><p id="a541" class="pw-post-body-paragraph jg jh hi jj b jk kf jm jn jo kg jq jr kh ki ju jv kj kk jy jz kl km kc kd ke hb bi translated">现在是时候着手使用Hadoop Map Reduce了。在运行Map Reduce作业之前，您需要安装一些有助于在您的机器上设置Hadoop环境的东西。你可以从cloudera网站下载<a class="ae la" href="http://www.cloudera.com/content/support/en/downloads/download-components/download-products.html" rel="noopener ugc nofollow" target="_blank"> CDH </a>包，并尝试设置环境。或者，如果你像我一样懒，只需下载这个已经设置好环境的<a class="ae la" href="http://content.udacity-data.com/courses/ud617/Cloudera-Udacity-Training-VM-4.1.1.c.zip." rel="noopener ugc nofollow" target="_blank">虚拟机</a>，然后用Virtual Box运行它。我已经使用Oracle VM VirtualBox Manager安装了CloudEraDistribution。你也可以这样做，只要谷歌一下或者看一段youtube视频。</p><p id="a7d4" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">通常Map Reduce代码是用java编写的。但是有了一个叫做Hadoop Streaming的特性，你可以用任何语言编写你的映射器和缩减器。我们将使用python编写地图缩减作业。</p><p id="830b" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">我假设您已经安装了虚拟机。打开机器后，转到项目文件所在的目录。它将有一个映射器和减速器程序。它包含一个文件` ``<strong class="jj hj"> purchases.txt ``` </strong>,该文件包含一个虚拟商店的销售数据。首先，我们需要将这个输入添加到Hadoop集群中。要在Hadoop集群上运行任何命令，我们需要给它添加<strong class="jj hj"> Hadoop fs </strong>。</p><p id="bd2a" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">1.转到计算机中项目文件所在的文件夹。</p><p id="fc58" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">2.使用<em class="ji"/><strong class="jj hj"><em class="ji">hadoop fs-put purchases . txt</em></strong>将<strong class="jj hj"> purchases.txt </strong>文件放到Hadoop集群中</p><p id="2c92" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">3.使用<em class="ji"/><strong class="jj hj"><em class="ji">hadoop fs-ls</em></strong>检查文件是否在Hadoop集群中</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/2533a9a73185eb15f7ec40ce1fedce70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*mLl-1QQgRzyA7iM6iC_-Rw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih"> HDFS (CloudEra) </strong></figcaption></figure><p id="e80f" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">现在让我们看看映射器和缩减器代码。我们的purchases.txt数据如下所示。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/1007919ec420dcef61bb4455a90acd58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*cyL9hdSPaoG71wl4g17UWw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih"> purchases.txt示例</strong></figcaption></figure><p id="a324" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">项目文件夹包含<strong class="jj hj"> mapper.py </strong>和<strong class="jj hj"> reducer.py </strong>文件。</p><p id="6023" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated"><strong class="jj hj">映射器代码如下所示。</strong></p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ko"><img src="../Images/572a863b4cd9fcfd572e199702657f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*oSHoqqckekOkEfKIUB8xaw.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih">映射器代码(mapper.py) </strong></figcaption></figure><p id="9279" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">映射器读取文件的区块，并使用制表符分隔符拆分文件。然后，它只打印出商店位置和商品价格作为输出。</p><p id="f2bd" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated"><strong class="jj hj">减速器代码如图所示。</strong></p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/a2a24dc0f9dab811d011c8a54df96532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*eHBTRi7HoHbHKD2Itg6EXw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih">减速器代码(reducer.py) </strong></figcaption></figure><p id="abca" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">我们假设我们只有一个reducer，它将从mappers获得排序后的输入。reducer.py接受排序后的输入，并继续检查新键是否等于前一个键。当发生变化时，它打印商店名称和商店的总销售额。</p><p id="8c7e" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">编写完映射器和缩减器后，您可以使用以下命令启动映射缩减作业:</p><blockquote class="jd je jf"><p id="2b1c" class="jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jj hj">Hadoop jar/usr/lib/Hadoop-0.20-MapReduce/contrib/streaming/Hadoop-streaming-2 . 6 . 0-mr1-CD H5 . 12 . 0 . jar-mapper . py-reducer . py-file mapper . py-file reducer . py-input my input-output job output</strong></p></blockquote><p id="e4d1" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">运行这个程序后，需要一些时间来计算。您可以在输出终端中观察映射器和缩减器是如何运行的。终端将显示各种信息，如工作完成的百分比。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lh"><img src="../Images/2b3c548aa6053c5d3c3961f9a2ae0905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*JQwYtiXYVulbCvrL4DMxjw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih">输出端子-1 </strong></figcaption></figure><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lb"><img src="../Images/d9331db09d597231de70129cd69c11e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*dYieRCFIaVItfMMrZRAetQ.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih">输出端子-2 </strong></figcaption></figure><p id="b7fa" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">我们程序的输出保存在文件<strong class="jj hj"> joboutput/part-00000 </strong>中</p><p id="bb8b" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">您可以通过运行命令<strong class="jj hj"> hadoop fs -ls joboutput </strong>在同一个终端中查看输出</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es li"><img src="../Images/f41690778a65b8ae574a135666512d45.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*XLjCtY6j_SF0ghuqh4Db1Q.jpeg"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><strong class="bd ih">产出(每个商店产生的总收入)</strong></figcaption></figure><p id="98d5" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">您可以使用命令<strong class="jj hj">Hadoop fs-cat job output/part-00000 | less</strong>来查看一小部分输出，而不是查看整个输出</p><p id="fdf9" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">一旦您任务完成，现在您可以从我们的HDFS系统中删除joboutput文件。原因是，我们不能用相同的输出文件名生成不同的输出工作负载。这可以通过运行下面的命令<strong class="jj hj"> hadoop fs -rm -r -f joboutput </strong>来实现</p><p id="d18e" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">同时，您可以将数据导出到文本文件中，并将其保存在您的目录中以备将来使用。</p><h1 id="e937" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"> E .结论</strong></h1><p id="2621" class="pw-post-body-paragraph jg jh hi jj b jk kf jm jn jo kg jq jr kh ki ju jv kj kk jy jz kl km kc kd ke hb bi translated">为了分析和确定一个国家/地区不同商店的收入，我们使用了核心概念——来自大数据Hadoop平台的HDFS和MapReduce来解决这个问题。<strong class="jj hj">我们</strong>通过将工作分成一组独立的任务来并行处理大量数据。<strong class="jj hj">我们使用了MapReduce流程文件将数据分成块并并行处理，并且能够找出美国各个商店使用reducers获得的收入。</strong></p><p id="1403" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">这就是这篇文章的全部内容。我希望你真正理解HDFS和MapReduce框架背后的神话，以及如何实现它。</p><p id="6256" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">这个项目的代码可以在我的GitHub页面上找到:</p><p id="e720" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">` `<strong class="jj hj">https://github.com/MaajidKhan/HadoopMapReduce_BigData ` `</strong></p><p id="3d21" class="pw-post-body-paragraph jg jh hi jj b jk jl jm jn jo jp jq jr kh jt ju jv kj jx jy jz kl kb kc kd ke hb bi translated">如果你喜欢这篇文章，点击下面的拍手图标，将这篇文章分享给你的朋友和网络。谢了。</p></div></div>    
</body>
</html>