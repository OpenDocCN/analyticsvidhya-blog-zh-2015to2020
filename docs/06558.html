<html>
<head>
<title>Dealing with Imbalanced Dataset (UnderSampling)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理不平衡数据集(欠采样)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/dealing-with-imbalanced-dataset-undersampling-4e9b488a97c6?source=collection_archive---------4-----------------------#2020-05-26">https://medium.com/analytics-vidhya/dealing-with-imbalanced-dataset-undersampling-4e9b488a97c6?source=collection_archive---------4-----------------------#2020-05-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f242e3c380bad20aafb4611549436a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0tdvs_UVkGt86yWf"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">考尔·克里斯詹在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="e333" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了训练一个好的分类模型，我们需要每个类别有几乎相等数量的数据。数据点的数量越多，模型的学习效果就越好。在现实世界中，可能会出现一个类完全支配另一个类的情况。此外，如果我们试图训练，我们的模型可能会偏向一个阶级。因此，在不平衡数据集上训练模型时，我们必须遵循某些非常有用的技术。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="bba5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">不平衡分类— </strong>分类预测建模问题，其中样本在类别间的分布不相等。例如，如果我们有99%的非欺诈交易案例，只有1%的欺诈交易案例，并且只有这些案例构成我们的训练数据集。如果我们试图在这个数据集上训练一个模型，那么我们的模型将有利于具有最高百分比的类。这意味着，我们的模型看到的高级数据比低级数据多，因此它可以更好地学习高级数据的模式。这代表了不平衡分类问题的一个例子。</p><p id="b3fa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将进一步展示处理这种不平衡数据集的技巧和技术。我们考虑了来自信用卡欺诈检测挑战的数据集。详情<a class="ae iu" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</p><p id="40c8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">整个实现也可以在<a class="ae iu" href="https://www.kaggle.com/nvnvashisth/dealing-with-imbalanced-dataset" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="9685" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将继续前进，并遵循一定的步骤来实现我们的目标。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h2 id="36ff" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated"><strong class="ak"> 1。数据清理、探索和可视化</strong></h2><p id="faec" class="pw-post-body-paragraph iv iw hi ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">我们使用熊猫图书馆阅读了这些数据，并详细研究了这些数据。从这些数据中可以得出几个推论。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/640a4641a4d52a6b061ad0c2d28588ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKXG6iLbyFoywjMaNCmWPw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用熊猫图书馆读取信用卡. csv文件</figcaption></figure><p id="dfa4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lf">观察</em> </strong></p><p id="dbb3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">—为了保护用户的身份并生成匿名数据，数据提供商已经执行了PCA并给出了需要用于进一步分析的组成变量。</p><p id="f5cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">—查看数据后，未对“时间”和“金额”列进行缩放。因此，我们将通过某种缩放算法来缩放数据，使其与其他变量相似。</p><p id="9131" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">—类有两个值，即“0”→非欺诈交易和“1”→欺诈交易。</p><p id="144d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">—数据集中不存在空值。</p><p id="d614" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们在数据集中寻找可用的类，并计算它们的数量。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/ef127d8c04cb0bf25ed348c4bf6d3e2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kj4ueKbngHnKbaizFbNVXg.png"/></div></div></figure><p id="25e8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lf">观察</em> </strong></p><p id="786b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">—可以观察到，与欺诈交易相比，非欺诈交易的数量过多。</p><p id="5221" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">—如果我们试图应用机器学习来训练分类算法，那么它将偏向于非欺诈交易。</p><p id="4198" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，我们将探讨不同的过采样和欠采样技术。</p><p id="d933" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在将检查数据的偏斜度，这可能会导致整个数据集的缩放。我们可以看到“时间”和“数量”的分布图，看看它们在高斯曲线中是如何分布的。我们可以看到，图表是高度倾斜的。因此，缩放数据变得非常重要。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/b2b93456957e6e5213c5ecf1bdf981df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1e_fTGiRjeJKG0KQCnVoLQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">数量和时间的分布和偏斜度检查</figcaption></figure><p id="e7c1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">sklearn包中有各种类型的缩放技术。检查哪种缩放方法可以最好地缩放我们的变量将是有趣的，这将有助于我们的高斯曲线的数据中心。我们测试了各种缩放技术，如StandardScaler、MinMaxScaler和RobustScaler，并决定使用RobustScaler。鲁棒定标器不容易出现异常值。更多详情请访问此处页面— <a class="ae iu" href="https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html" rel="noopener ugc nofollow" target="_blank">其他缩放方法之间的比较。</a></p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/80b54f95b939ed9fb9f84d62f8931445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fnv5D7tr_8xfWJ6Y3aRwSA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">鲁棒定标技术</figcaption></figure><p id="fa63" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了查看我们的数据集，我们需要将维数减少到2。我们有三种选择:</p><ol class=""><li id="b082" class="li lj hi ix b iy iz jc jd jg lk jk ll jo lm js ln lo lp lq bi translated"><a class="ae iu" href="https://setosa.io/ev/principal-component-analysis/" rel="noopener ugc nofollow" target="_blank">主成分分析</a></li><li id="8425" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated"><a class="ae iu" href="https://towardsdatascience.com/svd-8c2f72e264f" rel="noopener" target="_blank">奇异值分解</a></li><li id="4401" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated"><a class="ae iu" href="https://mlexplained.com/2018/09/14/paper-dissected-visualizing-data-using-t-sne-explained/" rel="noopener ugc nofollow" target="_blank"> t分布随机邻居嵌入(t-SNE) </a></li></ol><p id="21a1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们观察到，tSNE显示准确，可以清楚地区分欺诈和非欺诈案件。</p><p id="3544" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，我们将执行欠采样，并进一步检查我们的模型如何在欠采样数据上执行。对于不同的<a class="ae iu" href="https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.under_sampling" rel="noopener ugc nofollow" target="_blank">欠采样</a>技术，有很大的库可以进一步探索。</p><p id="cd8a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的目标是从每个类中创建相等的采样数据，以消除数据集中的偏差。正如我们之前所理解的，我们只有492类非欺诈样本，那么我们必须只取492个欺诈样本。因此，对于imblearn库，我们将使用RandomUnderSampler。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/323e9df3e77fc52f9fac90ef5c6e9876.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QM3l7akVUc61YVDttk9efg.png"/></div></div></figure><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/3a8739961a9cf259da9ad21dc0387130.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W8yJi459kHN494ixsjDoCQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">欠采样数据的可视化</figcaption></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h2 id="f394" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated"><strong class="ak"> 2。数据优化</strong></h2><p id="365f" class="pw-post-body-paragraph iv iw hi ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">让我们画出不同特征的相关矩阵。我们绘制了欠采样数据和原始数据的相关矩阵。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/e5f073b4a55539785186f9725a7f2479.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FoIZgEyx80FVbYTLjgR-Lw.png"/></div></div></figure><div class="lb lc ld le fd ab cb"><figure class="lx ij ly lz ma mb mc paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/09c8dc79bf3ea19d979f97b9f4727fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*aPFrpR0dHruSL8mOpqTvIg.png"/></div></figure><figure class="lx ij ly lz ma mb mc paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/be6ff643904d953ca4f7209d8bbbd2b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*1phxJGNH-dsLIrV4ooQ1xQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx md di me mf translated"><strong class="bd kc">相关矩阵左</strong>:欠采样数据，<strong class="bd kc">右</strong>:原始数据</figcaption></figure></div><ol class=""><li id="0283" class="li lj hi ix b iy iz jc jd jg lk jk ll jo lm js ln lo lp lq bi translated">异常检查的负相关性— v3、v9、v10、v12、v14、v16、v17高度负相关。</li><li id="7cee" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">异常的正相关chcek — v2、v4、v11、v19高度正相关。</li></ol><p id="a7cc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将继续为上述特征创建箱线图，以寻找可用的异常值。一旦绘制了上述负特征和正特征的箱线图，我们观察到大量可用的异常值(也称为异常检测技术之一)。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/dc85760732c528f52d247d95117a44d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OFZwac2X78ZFh7XFVNGTfw.png"/></div></div></figure><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/b6ec7bf7937e329c5adc3be10509cbf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kj5QZhibHesh1ofLs756TQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">高度正相关特征的箱线图</figcaption></figure><p id="6487" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还绘制了特征的分布图，看它们偏离正态分布的程度。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/93eb60794f9f215dd8bbc2777c4387e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a_eI9N0vV3vRg-VNWL69xg.png"/></div></div></figure><p id="df94" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">离群点剔除</strong></p><p id="b1cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了去除足够数量异常值，我们尝试了Z值法和IQR法。</p><ol class=""><li id="e0ba" class="li lj hi ix b iy iz jc jd jg lk jk ll jo lm js ln lo lp lq bi translated">Z-score法:Z-Score背后的直觉是通过找到它们与该组数据点的标准差和均值的关系来描述任何一个数据点。Z-score是寻找平均值为0且标准差为1的数据分布，即正态分布。在大多数情况下，使用阈值3或-3，即如果Z分值分别大于或小于3或-3，</li><li id="ace6" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">IQR方法:IQR在寻找数据分布方面有点类似于Z-score，然后保留一些阈值来识别异常值。然后，我们乘以阈值(1.5)，并尝试只包括那些值。</li></ol><p id="1b46" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们观察到，IQR方法往往会删除太多的离群值，因此我们将继续使用Z-score方法。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/260c826c26a7d2be17a6e9d438e80e09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CJplj99lZRmtKXL9mZs_Xw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">剔除异常值后的欠采样数据</figcaption></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h2 id="5e56" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">3.建模和培训</h2><p id="2d22" class="pw-post-body-paragraph iv iw hi ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">我们用上述数据训练不同的模型，并进行交叉验证。我们观察到XGBoost分类器做得很好。这可能是因为它所遵循的基于随机森林的增强技术。关于模型选择和训练的细节，请访问这里。</p><pre class="lb lc ld le fd mk ml mm mn aw mo bi"><span id="6ac2" class="ka kb hi ml b fi mp mq l mr ms">from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.metrics import roc_curve, auc, classification_report<br/>from sklearn.naive_bayes import GaussianNB<br/>from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier<br/>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis<br/>from sklearn.gaussian_process import GaussianProcessClassifier<br/>import xgboost<br/>from sklearn import svm, tree<br/>from sklearn import metrics<br/><br/>classifiers = []<br/>nb_model = GaussianNB()<br/>classifiers.append(("Gausian Naive Bayes Classifier",nb_model))<br/>lr_model= LogisticRegression()<br/>classifiers.append(("Logistic Regression Classifier",lr_model))<br/># sv_model = svm.SVC()<br/># classifiers.append(sv_model)<br/>dt_model = tree.DecisionTreeClassifier()<br/>classifiers.append(("Decision Tree Classifier",dt_model))<br/>rf_model = RandomForestClassifier()<br/>classifiers.append(("Random Forest Classifier",rf_model))<br/>xgb_model = xgboost.XGBClassifier()<br/>classifiers.append(("XG Boost Classifier",xgb_model))<br/>lda_model = LinearDiscriminantAnalysis()<br/>classifiers.append(("Linear Discriminant Analysis", lda_model))<br/>gp_model =  GaussianProcessClassifier()<br/>classifiers.append(("Gaussian Process Classifier", gp_model))<br/>ab_model =  AdaBoostClassifier()<br/>classifiers.append(("AdaBoost Classifier", ab_model))<br/><br/>cv_scores = []<br/>names = []<br/>for name, clf <strong class="ml hj">in</strong> classifiers:<br/>    print(name)<br/>    clf.fit(X_train, y_train)<br/>    y_prob = clf.predict_proba(X_test)[:,1] # This will give you positive class prediction probabilities  <br/>    y_pred = np.where(y_prob &gt; 0.5, 1, 0) # This will threshold the probabilities to give class predictions.<br/>    print("Model Score : ",clf.score(X_test, y_pred))<br/>    print("Number of mislabeled points from <strong class="ml hj">%d</strong> points : <strong class="ml hj">%d</strong>"% (X_test.shape[0],(y_test!= y_pred).sum()))<br/>    scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')<br/>    cv_scores.append(scores)<br/>    names.append(name)<br/>    print("Cross validation scores : ",scores.mean())<br/>    confusion_matrix=metrics.confusion_matrix(y_test,y_pred)<br/>    print("Confusion Matrix <strong class="ml hj">\n</strong>",confusion_matrix)<br/>    classification_report = metrics.classification_report(y_test,y_pred)<br/>    print("Classification Report <strong class="ml hj">\n</strong>",classification_report)</span></pre><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/e89ce2df54a50f5d3a38d9bca8da848f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aEeq--QFjC-DBLSGTTFryw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">XGBoost分类器统计</figcaption></figure><p id="1204" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你喜欢这些技巧和技术，那么请鼓掌，分享和评论反馈。敬请关注更多博客！</p></div></div>    
</body>
</html>