<html>
<head>
<title>Paper Analysis 2 : Image Super Resolution using Residual Dense Network[CVPR 2018]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文分析2:利用残差密集网络的图像超分辨率[CVPR 2018]</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/paper-analysis-2-image-super-resolution-using-residual-dense-network-cvpr-2018-6d0d78de5666?source=collection_archive---------24-----------------------#2020-04-05">https://medium.com/analytics-vidhya/paper-analysis-2-image-super-resolution-using-residual-dense-network-cvpr-2018-6d0d78de5666?source=collection_archive---------24-----------------------#2020-04-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d71c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">原文:</em><a class="ae je" href="https://arxiv.org/pdf/1802.08797.pdf" rel="noopener ugc nofollow" target="_blank"><em class="jd"/></a></p><h1 id="7ea5" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">简介:</strong></h1><p id="a033" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">CNN已经在图像超分辨率(SR)方面取得了巨大的成功，但是它们的性能不是很有效，因为它们没有使用原始低分辨率(LR)图像的分层特征。</p><p id="99c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，剩余密集网络(RDN)被提出来解决SR中的这个问题，其中所有的层次特征都被用尽和利用。剩余密集块(RDB)是提取局部丰富特征的主要块。因此，RDB允许从以前的RDB块直接连接到当前RDB的所有层，导致连续内存(CM)。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ki"><img src="../Images/190768f2b1b44e9ba0f5f341f9317947.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*1eQLL8kF3eJbnW42Mg0SIA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图1:残余致密块</figcaption></figure><p id="aebb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后使用RDB的局部特征融合(LFF)从先前和当前局部特征中自适应地学习更有效的特征，并稳定更广泛网络的训练。</p><p id="681e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用术语“层次特征”是因为这些特征为图像的重建提供了更多的线索。在<a class="ae je" href="http://cvlab.cse.msu.edu/pdfs/Image_Restoration%20using_Persistent_Memory_Network.pdf" rel="noopener ugc nofollow" target="_blank"> MemNet研究论文</a>中有一个类似于RDN的方法，其中所有子网都连接到一个门单元，但是本地卷积层彼此之间没有直接访问。参考下图。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ku"><img src="../Images/62da99d9980c5bea39a2eb72e266aafc.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*nsldYnnACt1b6HOrjLMfiQ.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图2 : Memnet架构</figcaption></figure><p id="c6c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们谈论RDN，我们会看到从当前RDB块的卷积层以及从先前RDB块的输出中提取并连接特征，这通过利用所有分层特征来简化重构。这种网络克服了MemNet的缺点。</p><p id="90bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RDB由密集连接层和局部特征融合(LFF)以及局部剩余学习(LRL)组成。RDB还支持RBD之间的连续内存，即一个RDB的输出可以直接访问所有后续RDB，从而导致连续状态传递。RDB中的卷积层可以直接访问该RDB中的所有后续卷积层，即卷积层将其信息传递给RDB中的后续卷积层。</p><p id="bf03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LFF主要用于连接先前的RDB特征和当前RDB的输入通过所有卷积层之后的特征，其中输入不是别的，正是先前RDB的输出特征。简而言之，要融合过去和现在RDB的特点，LFF是适用的。</p><h1 id="464e" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">网络结构:</strong></h1><p id="e620" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">RDN由3个主要单元组成:</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es kv"><img src="../Images/ac975966edaa6b08dc3dd408eb36e2fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*rFeJX3mIvISzNIkL7pvDCA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图2:网络结构</figcaption></figure><ol class=""><li id="77ba" class="kw kx hi ih b ii ij im in iq ky iu kz iy la jc lb lc ld le bi translated"><em class="jd">浅层特征提取</em></li><li id="68ee" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated"><em class="jd">残余致密块(RDB氏)</em></li><li id="780d" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated"><em class="jd">密集特征融合(DFF) </em></li></ol><p id="8ecf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设Iʟʀ和Isʀ分别是RDN的输入和输出。</p><ol class=""><li id="d274" class="kw kx hi ih b ii ij im in iq ky iu kz iy la jc lb lc ld le bi translated"><strong class="ih hj">浅层特征提取</strong>:两个卷积层用于特征提取。</li></ol><p id="406f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于来自LR图像的第一卷积层，我们可以将其表示为:</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lk"><img src="../Images/3892824c4f0636c99e19142a4fa99697.png" data-original-src="https://miro.medium.com/v2/resize:fit:278/format:webp/1*pfQhmXbrngWoYnL4LbPXEQ.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">等式1:来自第一卷积层的特征</figcaption></figure><p id="9f57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中Hsғᴇ1:第一特征提取层的卷积运算</p><p id="f736" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，对于第二卷积层</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ll"><img src="../Images/8cf15812878ba3441acbf8a9aab3480e.png" data-original-src="https://miro.medium.com/v2/resize:fit:256/format:webp/1*iv4R5Ht8K6fwGxvekoi6YQ.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">等式2:来自第二卷积层的特征</figcaption></figure><p id="b964" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中Hsғᴇ2:第二特征提取层的卷积运算</p><p id="12a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于该论文已经提到只有2个卷积层将用于特征提取，所以2个操作用于特征提取。</p><p id="3ea7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">剩余密集块</strong> : RDB遵循连续存储机制，当前输出特征传递给后续层。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lm"><img src="../Images/5de2974038c5639a397d8ed85b8b061d.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*rwPoEBypsTl3o4ekhPlKgw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图3:RDB机制的示意图</figcaption></figure><p id="e075" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个卷积层的输出是先前层的特征与相应权重的乘积</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ln"><img src="../Images/818c69f073fa126ec1c37b6b727c3440.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*AvxQhPBTT6lUlls2Cvqwzg.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">等式3:DTH RDB中Cth卷积层操作的输出</figcaption></figure><p id="fb6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们知道在神经网络中<em class="jd">新层=激活函数(前一层*相应的权重)</em></p><p id="e53d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，等式3也遵循相同的原理，除了先前层是所有先前层和先前RDB的输出。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lo"><img src="../Images/6bd97197bcd515f5a3c4a136a80fbc07.png" data-original-src="https://miro.medium.com/v2/resize:fit:298/format:webp/1*GPVGC9-Xv_o4PXCHzfdDXw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">由d-1 RDB和卷积层产生的特征图的连接</figcaption></figure><p id="4e03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">局部特征融合:</em>这是从RDB所有卷积层生成特征图后的下一步。因此，先前RDB的特征地图被连接到当前RDB，然后1x1卷积层，以输出基本特征。</p><p id="f6a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以将它表示为以下形式的方程:</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lp"><img src="../Images/1cdc1fd6128ffe5c03d6cd4e1d63ac25.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*uhUs6qsB2Fsny87dF_kAyw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">等式4:局部特征融合</figcaption></figure><p id="3781" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中hʟғғ:1x1 conv层的功能</p><p id="1b46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一项表示先前RDB的输出以及当前RDB中C个卷积层的特征图的串联。</p><p id="7068" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">局部残差学习</em>:它是RDB的最终输出，其中我们计算的局部特征融合与先前RDB的输出相加。提高了网络表现能力。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lq"><img src="../Images/59d117eedeeda8271bbccd11994fb157.png" data-original-src="https://miro.medium.com/v2/resize:fit:266/format:webp/1*WDEe5BUEi1sLwJnDxncR7Q.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">等式5:局部剩余学习</figcaption></figure><p id="de0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.<strong class="ih hj">密集特征融合</strong>:进行LFF和LRL后，提取局部密集特征。类似地，在执行全局特征融合(GFF)和全局剩余学习(GRL)之后，执行密集特征融合(DFF)以产生全局密集特征。</p><p id="d7d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在连接所有RDB的输出特征之后，执行全局特征融合。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lr"><img src="../Images/5c148593223e2f372cd7b74247d33f9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*5U7mUHnuoCamWhtvWuVJeg.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">等式6:GFF之后的特征使用RDB的特征</figcaption></figure><p id="3e46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Hɢғғ:它是1x1卷积层和3x3卷积层的组合，其中:</p><p id="4b73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1×1卷积层用于融合不同级别的特征，3×3卷积层用于提取全局残差学习的特征。</p><p id="d331" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">全局残差学习就是GFF产生的特征和特征提取中第一卷积层之后的特征的总和。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ls"><img src="../Images/647726943a834f1c2c98247f4f438dec.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*XLzP3oABsCk3hC1LwVK69Q.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">等式7:执行GRL后的全局密集特征</figcaption></figure><p id="7829" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于<strong class="ih hj">上采样</strong>，我们使用了论文中的ESPCN:“<a class="ae je" href="https://arxiv.org/pdf/1609.05158.pdf" rel="noopener ugc nofollow" target="_blank">使用高效亚像素卷积神经网络</a>的实时单幅图像和视频超分辨率。</p><h1 id="011a" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">实验及结果:</strong></h1><p id="eee0" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">通过实验，作者发现了一些极端的结果</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lt"><img src="../Images/d5d0e491abacb3f688a5c702f1a76dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*olrgaX7gBoFyTctoCYWKpQ.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">结果1:平均值的比较。PSNR想出了其他方法</figcaption></figure><p id="0d87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是图片通过网络后的一些视觉效果</p><div class="kj kk kl km fd ab cb"><figure class="ly kn lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/837c161354be2850340545d4c05350dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*zXt7fPS9mt2fl-8d0zHC5g.png"/></div></figure><figure class="ly kn me ma mb mc md paragraph-image"><img src="../Images/fa37ef83dd75bc3f31def2863d828ad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*qUw_ti7VmZRl-Ks99g85GQ.png"/><figcaption class="kq kr et er es ks kt bd b be z dx mf di mg mh translated">结果2 : PSNR和SSIM执行超分辨率后的两张不同的图片</figcaption></figure></div><h1 id="fb87" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">结论:</strong></h1><p id="afe1" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">在浏览了网络体系结构及其性能之后，我们发现该模型的性能优于许多超分辨率体系结构，因为它有效地利用了网络的分层特征。</p><p id="f4ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在已经开发了很棒的超分辨率技术，但是这个模型对于2018年之前的超分辨率是最好的，没有任何复杂的架构或计算。</p><h1 id="5005" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">参考文献:</strong></h1><ol class=""><li id="b97a" class="kw kx hi ih b ii kd im ke iq mi iu mj iy mk jc lb lc ld le bi translated"><a class="ae je" href="http://cvlab.cse.msu.edu/pdfs/Image_Restoration%20using_Persistent_Memory_Network.pdf" rel="noopener ugc nofollow" target="_blank">http://cvlab . CSE . MSU . edu/pdf/Image _ restore % 20 using _ Persistent _ Memory _ network . pdf</a></li><li id="cbf9" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated"><a class="ae je" href="https://arxiv.org/pdf/1609.05158.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1609.05158.pdf</a></li><li id="0cee" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated"><a class="ae je" href="https://arxiv.org/pdf/1608.06993.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1608.06993.pdf</a></li><li id="4523" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated"><a class="ae je" href="https://github.com/yulunzhang/RDN" rel="noopener ugc nofollow" target="_blank">https://github.com/yulunzhang/RDN</a></li></ol></div></div>    
</body>
</html>