<html>
<head>
<title>Word Similarity|Word2vec|Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单词相似度| Word2vec |自然语言处理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/word-similarity-word2vec-natural-language-processing-fe085f9f03e7?source=collection_archive---------7-----------------------#2020-06-12">https://medium.com/analytics-vidhya/word-similarity-word2vec-natural-language-processing-fe085f9f03e7?source=collection_archive---------7-----------------------#2020-06-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b465" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">有了先进的技术，我们在计算机科学领域有了革命性的变化。在过去的十年里，在计算机科学领域，人们对人工智能进行了大量的研究。但是，由于机器不识别自然语言，所以我们要求把它转换成机器可读的语言。单词嵌入是一种文本呈现类型，它可以帮助我们找到任何相似的单词模式，并使其适合机器学习。虽然可以找到各种各样的单词嵌入模型，但我们将讨论由Google开发的word2vec模型，我喜欢Google的一切。本文将讨论word2vec架构以及实际实现，以理解嵌入技术。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jm"><img src="../Images/751bca9e50d23f5a5195db90406a9c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W6FRoId8E-OUPCgM7nuMNQ.png"/></div></div></figure><p id="1729" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jy">背景词2 vec</em>T5】</strong></p><blockquote class="jz ka kb"><p id="13cd" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">在学习任何新东西之前，先了解一下他的背景是有好处的。因为可以找到各种单词表示算法，例如单词包(BOW)、词频逆文档(TF-IDF)等等。这些算法之间的巨大差距是语义信息无法存储。这种算法(word2vec)比传统算法性能更好，因为它可以存储语义。Word2vec是由托马斯·米科洛夫于2013年在谷歌开发的。许多行业经常使用这种算法来分析客户的评论以及情感分析。另一个例子是我们通常在YouTube或其他地方看到的推荐系统。所以，可能你已经理解了为什么这个算法，以及在哪里可以利用这个算法。根据图1理解单词之间的关系。</p></blockquote><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es kf"><img src="../Images/7191833b5cbe0e9837248208b69d645e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cezjRtXBnWx8eqoT4UC9-w.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated"><strong class="bd kk">图1 .与文字相符。</strong></figcaption></figure><p id="63a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="jy">word 2 vec的层结构</em> </strong></p><blockquote class="jz ka kb"><p id="ce8f" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><em class="hi">这是一个简单的两层神经网络。浅层神经网络与输入和输出之间的深层连接，而深层神经网络包括输入和输出之间的多个私有层。由于神经网络的隐藏层对我们的单词表示进行编码，我们将这种自然语言处理应用程序主要留给神经网络。需要一些专门的框架来再次转换这两者。一个很好的框架是“Jensim”。真的是一个很棒的框架。但是，在开始的时候，‘词2 Vec’。意思是从单词到矢量。仔细看看图2，图中显示了浅层和深层网络。</em></p></blockquote><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es kl"><img src="../Images/2eb7bc8b4ca11143ee955383d27fdfda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9yZc60tBw5nn5N6fZsu2oA.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated"><a class="ae km" href="https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781785880360/1/ch01lvl1sec12/why-deep-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kk">图2 .浅层与深层</strong> </a></figcaption></figure><p id="e728" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jy">的建筑文字2vec </em> </strong></p><blockquote class="jz ka kb"><p id="0cb9" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">图3显示了word2vec的架构图。典型地，在word2vec中使用两种体系结构模型，例如，Skip-gram和连续单词包(CBOW)。每个人对于文字处理都有自己的特点。细节顺序如图3 所示</p></blockquote><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es kn"><img src="../Images/fdc16a842570f0403194a3eebf9cbb24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l6oLltRqioQcimN5Ik9W6Q.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated"><strong class="bd kk">图3:word 2 vec</strong>的架构</figcaption></figure><p id="7065" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jy">跳跃式架构</em> </strong></p><blockquote class="jz ka kb"><p id="841b" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><em class="hi">在不涉及太多复杂性的情况下，我可以说Word2vec以两种方式工作。一种我们称之为skip-gram，意思是通过预测句子的上下文来处理单词。当我们的skip-gram中的</em> <strong class="ih hj"> <em class="hi">目标</em> </strong> <em class="hi">词作为输入给出时——输出其周围的目标词。比如一个句子，“Analytics vidhya is great”，如果输入的单词是“vidhya”，那么它的输出将是“Analytics”“is”，以及“great”。我们这里的窗口大小是3。这里的输入和输出数据将在相同的维度，必须有'一个热编码'。这个网络有一个隐藏层，其尺寸等于“嵌入尺寸”——实际上小于输入和输出向量的尺寸。在输出层的末端，一个“softmax”激活函数将被应用于每个输出因子的元素，以便概率分布中的单词将接近这里的上下文。图4显示了跳格模型图。</em></p></blockquote><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ko"><img src="../Images/5d092b903542f4cb10a4291c7a580fa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*DMA3Ri3JlkpDyjZopWkKdg.jpeg"/></div><figcaption class="kg kh et er es ki kj bd b be z dx translated"><a class="ae km" href="https://www.researchgate.net/publication/322905432_Patent_Keyword_Extraction_Algorithm_Based_on_Distributed_Representation_for_Patent_Classification/figures?lo=1" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kk">图4: Skip-gram </strong> </a> <strong class="bd kk">模型:输入层到输出层</strong></figcaption></figure><p id="3a21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jy">连续包字(CBOW)架构</em> </strong></p><blockquote class="jz ka kb"><p id="a6e7" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">单词2vec的另一个概念是“连续单词包”，它类似于Skip-Gram，但它改变了输入和输出。问题是，我们将给出一个“上下文”,我们想知道哪个单词最有可能首先出现。这两个系统的最大区别是声音矢量的产生方式。“连续单词包”中目标单词的所有例子都被输入到网络中，网络实际上通过对它们进行平均来从隐藏层中提取它们。找出如何平均我们所有类型的句子不是一个大问题。让我们看一张图图5</p></blockquote><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es kp"><img src="../Images/1cc31a0bc59167b375ccd336e0257881.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*vPlSt2egrlc7-tTgreGwLg.jpeg"/></div><figcaption class="kg kh et er es ki kj bd b be z dx translated"><a class="ae km" href="https://subscription.packtpub.com/book/web_development/9781786465825/3/ch03lvl1sec34/continuous-bag-of-words-model" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kk">图5: CBOW模型:输入层到输出层</strong> </a></figcaption></figure><p id="b694" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">通过实际实现找出单词的相似度。</strong></p><p id="0c2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们做一些练习测试来理解Word2vec。按照下面的代码，我写了五个步骤，对初学者来说可能是一个更好的选择。更好的说法是，当一个理论被阅读时，如果你实际地去实现它，那会很棒。</p><blockquote class="jz ka kb"><p id="52ab" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><strong class="ih hj">步骤01:导入必要的库</strong></p><p id="854b" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><strong class="ih hj"> 1 .导入nltk </strong> (nltk库被导入，您可以从这里下载X语料库)</p><p id="c733" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><strong class="ih hj"> 2 .从gensim.models导入Word2Vec </strong> (Gensim是导入的。如果没有安装Gensim，请安装)<br/> <strong class="ih hj"> 3 .从nltk.corpus导入停用词</strong>(我们需要忽略一些不必要的词，比如“是”、“the”、“but”等等。</p><p id="8903" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">4 .导入re  (re mans:正则表达式。它要求在文本处理过程中。)</p><p id="490c" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><strong class="ih hj">步骤02:从数据集读取数据</strong></p><p id="d7f6" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">正如我试图解释的那样，我不会处理非常大的数据集，在这种情况下，我会用一些预定义的数据进行实验。</p><p id="4f0c" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">今天，我怀着沉重的心情来到你们面前。你们都知道我们有多努力。但令人悲伤的是，达卡、吉大港、库尔纳、朗布尔和拉杰夏希的街道上今天溅满了我兄弟的鲜血，我们听到的孟加拉人民的呼声是要求自由、生存和权利的呼声。是你们带来了人民联盟的胜利，所以你们可以看到一个宪法政府的恢复。人们希望当选的代表们能够""( T15)()这是孟加拉国国父的一句名言的一部分，我把它作为一个数据集。)</p><p id="2a43" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><strong class="ih hj">步骤03:处理数据</strong></p><p id="a266" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">text = re . sub(r ' \[[0–9]* \]'，' '，paragraph)//我们不需要特殊字符来查找单词中的相似性，因为它有时会使过程变慢。<br/>text = re sub(r ' \ s+'，' '，text)<br/>text = text . lower()<br/>text = re sub(r ' \ d '，' '，text)<br/>text = re sub(r ' \ s+'，' '，text)</p><p id="2608" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><strong class="ih hj">步骤03:准备数据集</strong></p><p id="c0a6" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">sentences = nltk . sent _ tokenize(text)</p><p id="2e08" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">sentences =[nltk . word _ tokenize(sentence)for sentences in sentences]</p><p id="f95f" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">for I in range(len(sentences)):<br/>sentences[I]=[word for word in sentences[I]if word not in stop words . words(' English ')]</p><p id="a2df" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><strong class="ih hj">步骤04:训练Word2Vec模型</strong></p><p id="3e25" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">model = Word2Vec(句子，min_count=1)</p><p id="69d3" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">words = model.wv.vocab</p><p id="b33f" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"><strong class="ih hj">步骤05:测试你的模型(寻找词向量或相似度)</strong></p><p id="0d05" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated"># Finding Word Vectors<br/>vector = model . wv['奴役']</p><p id="eb4d" class="if ig jy ih b ii ij ik il im in io ip kc ir is it kd iv iw ix ke iz ja jb jc hb bi translated">#最相似词<br/>相似= model.wv.most_similar('悲伤')</p></blockquote><p id="5f90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">输出</strong></p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es kq"><img src="../Images/eb2b633ea3c3e7de74fee1b1a9f81893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iHTn2MIwSZ3dB16ngtk_rg.png"/></div></div></figure><p id="6ce3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你看上面的图像，你会看到每个单独的部分都被创建了，例如，为“被奴役”创建了一个向量。word2vec就是这样工作的。</p><p id="02d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">综上所述，</strong>在本文中，已经讨论了单词嵌入模型。通常，可以找到几种嵌入技术，word2vec更可靠地找到单词中的相似性。其次，给出了word2vec的体系结构，最后，描述了word2vec模型的具体实现。</p><p id="244d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您希望看到我关于研究和创新的另一个更新，请关注我:</p><p id="9be9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">研究门:</strong>【https://www.researchgate.net/profile/Elias_Hossain7】T4</p><p id="e621" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">领英:</strong><a class="ae km" href="https://www.linkedin.com/in/elias-hossain-b70678160/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/elias-hossain-b70678160/</a></p></div></div>    
</body>
</html>