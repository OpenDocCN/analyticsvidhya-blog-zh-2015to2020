<html>
<head>
<title>Azure Synapse Analytics Run Clustering model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Azure Synapse分析运行聚类模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/azure-synapse-analytics-run-clustering-model-7bcd66e954d8?source=collection_archive---------29-----------------------#2020-01-05">https://medium.com/analytics-vidhya/azure-synapse-analytics-run-clustering-model-7bcd66e954d8?source=collection_archive---------29-----------------------#2020-01-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9d6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用出租车数据集运行K-means聚类无监督学习。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/3519a6ab0c2a077ec6a039765699b153.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dEFpsrPyjaRPKtuJ.JPG"/></div></div></figure><p id="50c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Synapse能够运行基于spark的代码，从而实现数据工程或特征工程以及机器学习。本文描述了如何在synapse中使用spark训练机器学习模型。</p><p id="dc2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将上述培训文件上传到blob存储或ADLS Gen2。或者您可以使用synapse orchestrate特性将数据移动到Blob中。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="8982" class="ju jv hi jq b fi jw jx l jy jz">For my testing i was able to move the blob storage train.csv into ADLS gen2 filesystem. I did that for just to show how to move data inside synapse analytics.</span><span id="3c15" class="ju jv hi jq b fi ka jx l jy jz">import org.apache.spark.mllib.clustering.{KMeans, KMeansModel}<br/>import org.apache.spark.mllib.linalg.Vectors<br/>import org.apache.spark.ml.clustering.KMeans<br/>import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}<br/>import org.apache.spark.sql.SQLContext<br/>import org.apache.spark.sql.SparkSession<br/>import org.apache.spark.sql.types.IntegerType<br/>import org.apache.spark.sql.functions.udf<br/>import org.apache.spark.sql.functions._<br/>import spark.implicits._<br/>import org.apache.spark.sql.functions._</span><span id="e8d9" class="ju jv hi jq b fi ka jx l jy jz">val yellowdf = spark.read.option("header","true").option("inferSchema","true").parquet("abfss://<a class="ae kb" href="mailto:opendataset@internalsandboxwe.dfs.core.windows.net" rel="noopener ugc nofollow" target="_blank">opendataset@internalsandboxwe.dfs.core.windows.net</a>/nyctlc/yellow/")</span></pre><p id="4f0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">验证数据集</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="bc60" class="ju jv hi jq b fi jw jx l jy jz">display(yellowdf)</span></pre><p id="a9ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看模式</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="8dde" class="ju jv hi jq b fi jw jx l jy jz">yellowdf.schema</span></pre><p id="44ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(最好是数值)</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="1297" class="ju jv hi jq b fi jw jx l jy jz">val df = yellowdf.select("passengerCount","tripDistance","fareAmount","tipAmount","totalAmount","puYear","puMonth")</span></pre><p id="4399" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">验证新数据集</p><p id="252f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">显示(df)</p><p id="8550" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">确保新数据集中只有选定的列</p><p id="7641" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">df .架构</p><p id="1dd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将数据帧转换成矢量格式，以便kmeans可以处理。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="5e8b" class="ju jv hi jq b fi jw jx l jy jz">val assembler = new VectorAssembler().setInputCols(Array("passengerCount","tripDistance","fareAmount","tipAmount","totalAmount","puYear","puMonth")).setOutputCol("features").setOutputCol("features")</span><span id="532e" class="ju jv hi jq b fi ka jx l jy jz">val training = assembler.transform(df.na.drop())</span><span id="b333" class="ju jv hi jq b fi ka jx l jy jz">// Cluster the data into two classes using KMeans<br/>val numClusters = 2<br/>val numIterations = 20<br/>// Trains a k-means model.<br/>val kmeans = new KMeans().setK(numClusters).setSeed(1L).setFeaturesCol("features").setPredictionCol("prediction")<br/>val model = kmeans.fit(training)</span><span id="0324" class="ju jv hi jq b fi ka jx l jy jz">// Evaluate clustering by computing Within Set Sum of Squared Errors.<br/>val WSSSE = model.computeCost(training)<br/>println(s"Within Set Sum of Squared Errors = $WSSSE")</span></pre><p id="502a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运行预测</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="b1c0" class="ju jv hi jq b fi jw jx l jy jz">val predicted = model.transform(training)<br/>predicted.show</span></pre><p id="5ece" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">显示结果:</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="4735" class="ju jv hi jq b fi jw jx l jy jz">// Shows the result<br/>println("Final Centers: ")<br/>model.clusterCenters.foreach(println)</span></pre></div><div class="ab cl kc kd gp ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="hb hc hd he hf"><p id="cd74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kj">最初发表于</em><a class="ae kb" href="https://github.com/balakreshnan/synapseAnalytics/blob/master/SparkClustering.md" rel="noopener ugc nofollow" target="_blank"><em class="kj">【https://github.com】</em></a><em class="kj">。</em></p></div></div>    
</body>
</html>