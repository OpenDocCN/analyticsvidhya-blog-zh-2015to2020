<html>
<head>
<title>Understanding Linear Regression and it’s python implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解线性回归及其python实现</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-linear-regression-and-its-python-implementation-9f004589e1b3?source=collection_archive---------27-----------------------#2020-01-05">https://medium.com/analytics-vidhya/understanding-linear-regression-and-its-python-implementation-9f004589e1b3?source=collection_archive---------27-----------------------#2020-01-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ec1edad31c9284c67714d6b103514605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cJ9ptStsS3nleW_6jL3NVQ.jpeg"/></div></div></figure><h1 id="33fb" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是线性回归？</h1><p id="bfb6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">线性回归是一种基本且常用的预测分析类型。它用于查找目标和一个或多个预测值之间的线性关系。回归的总体思想是检查两件事:</p><ol class=""><li id="8b50" class="km kn hi jq b jr ko jv kp jz kq kd kr kh ks kl kt ku kv kw bi translated">一组预测变量在预测一个结果(因变量)方面做得好吗？</li><li id="dca3" class="km kn hi jq b jr kx jv ky jz kz kd la kh lb kl kt ku kv kw bi translated">哪些变量是结果变量的重要预测因子，它们以何种方式影响结果变量？</li></ol><p id="4491" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">这些回归估计用于解释一个<em class="lf">因变量</em>和一个或多个<em class="lf">自变量</em>之间的关系。具有一个因变量和一个自变量的回归方程的最简单形式由以下公式定义</p><h2 id="8e74" class="lg ir hi bd is lh li lj iw lk ll lm ja jz ln lo je kd lp lq ji kh lr ls jm lt bi translated">y = b1*x + b0，</h2><blockquote class="lu"><p id="9434" class="lv lw hi bd lx ly lz ma mb mc md kl dx translated">在哪里</p><p id="a386" class="lv lw hi bd lx ly lz ma mb mc md kl dx translated"><strong class="ak"> y </strong> =估计的因变量，</p><p id="18c3" class="lv lw hi bd lx ly lz ma mb mc md kl dx translated">b0 =常数，</p><p id="df24" class="lv lw hi bd lx ly lz ma mb mc md kl dx translated"><strong class="ak"> b1 </strong> =回归系数，</p><p id="7944" class="lv lw hi bd lx ly lz ma mb mc md kl dx translated"><strong class="ak"> x </strong> =自变量。</p></blockquote><p id="688b" class="pw-post-body-paragraph jo jp hi jq b jr me jt ju jv mf jx jy jz mg kb kc kd mh kf kg kh mi kj kk kl hb bi translated">具有“p”个独立变量的多元线性回归的一般方程如下所示:</p><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/42a38b60f6008d96e60b83662e0a63fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/0*6vHomGLfFZd8u1ln.png"/></div></figure><blockquote class="mo mp mq"><p id="21ee" class="jo jp lf jq b jr ko jt ju jv kp jx jy mr lc kb kc ms ld kf kg mt le kj kk kl hb bi translated">有两种线性回归-</p></blockquote><ul class=""><li id="fbf6" class="km kn hi jq b jr ko jv kp jz kq kd kr kh ks kl mu ku kv kw bi translated"><strong class="jq hj">简单的</strong></li><li id="fcdb" class="km kn hi jq b jr kx jv ky jz kz kd la kh lb kl mu ku kv kw bi translated"><strong class="jq hj">多个</strong></li></ul><p id="5790" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">一元线性回归和多元线性回归的<strong class="jq hj">区别</strong>在于，多元线性回归有多个<em class="lf">自变量，而一元线性回归只有一个自变量。</em></p><h1 id="7f3c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">简单线性回归</h1><p id="8c77" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">简单线性回归用于寻找两个连续变量之间的关系。一个是预测器/自变量，另一个是响应/因变量。它寻找的是统计关系，而不是确定性关系(如果一个变量可以用另一个变量精确表达，那么两个变量之间的关系就是确定性的)。</p><blockquote class="mo mp mq"><p id="4324" class="jo jp lf jq b jr ko jt ju jv kp jx jy mr lc kb kc ms ld kf kg mt le kj kk kl hb bi translated">例如，使用摄氏温度可以准确预测华氏温度。统计关系在确定两个变量之间的关系时不准确。</p></blockquote><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/e8b96c053a2d5939ee174e2eb5a25b31.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/0*EIDbbNnjXE16tKLd.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx translated">例如身高和体重的关系。</figcaption></figure><p id="5414" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">核心思想是获得一条<strong class="jq hj">最适合</strong>数据的线，即总预测误差尽可能小。(误差=点到回归线的距离)。</p><blockquote class="mo mp mq"><p id="7f11" class="jo jp lf jq b jr ko jt ju jv kp jx jy mr lc kb kc ms ld kf kg mt le kj kk kl hb bi translated">现在，问题是“我们如何获得最佳拟合线？”</p></blockquote><p id="4d87" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">我们知道，<strong class="jq hj">Y</strong>(pred)= B0+B1 *<strong class="jq hj">x</strong></p><p id="9cd7" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">b0和b1值的选择必须使误差最小。如果将误差平方和作为评估模型的度量标准，那么我们的目标是获得一条最能减少误差的线。</p><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/edbcb47f0d9221d4ee9b92fcba731883.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rXhUlNJ4BQLBb495.png"/></div></div><figcaption class="mw mx et er es my mz bd b be z dx translated"><a class="ae nb" href="http://www.fairlynerdy.com/what-is-r-squared/" rel="noopener ugc nofollow" target="_blank">误差计算</a></figcaption></figure><blockquote class="mo mp mq"><p id="75f1" class="jo jp lf jq b jr ko jt ju jv kp jx jy mr lc kb kc ms ld kf kg mt le kj kk kl hb bi translated">如果我们不平方误差，那么正负点就会互相抵消。</p><p id="8b08" class="jo jp lf jq b jr ko jt ju jv kp jx jy mr lc kb kc ms ld kf kg mt le kj kk kl hb bi translated">对于具有一个预测器模型，</p></blockquote><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/f36b37766d0b1cf25b042405ffe4adeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/0*AH3PbSMGBQQLMC4Q.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx translated">计算截距</figcaption></figure><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/ff4cb3839ea84e7d894c545a08f5946c.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/0*vlH-4_0cJ8JkD7ra.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx translated">系数公式</figcaption></figure><ul class=""><li id="49b0" class="km kn hi jq b jr ko jv kp jz kq kd kr kh ks kl mu ku kv kw bi translated">如果b1 &gt; 0，那么x(预测值)和y(目标值)有一个正的关系(增加x会增加y)。</li><li id="6a62" class="km kn hi jq b jr kx jv ky jz kz kd la kh lb kl mu ku kv kw bi translated">如果B1&lt; 0, then x(predictor) and y(target) have a negative relationship (increase in x will decrease y).</li><li id="5929" class="km kn hi jq b jr kx jv ky jz kz kd la kh lb kl mu ku kv kw bi translated">If the model does not include x (i.e. x=0), then the prediction will become meaningless with only b0.</li><li id="f2a3" class="km kn hi jq b jr kx jv ky jz kz kd la kh lb kl mu ku kv kw bi translated">If there is no ‘b0’ term, then regression will be forced to pass over the origin. Both the regression co-efficient and prediction will be biased in this case.</li></ul><blockquote class="mo mp mq"><p id="42da" class="jo jp lf jq b jr ko jt ju jv kp jx jy mr lc kb kc ms ld kf kg mt le kj kk kl hb bi translated">E.g. Consider we have a dataset that relates height(x) and weight(y). Taking x=0(that is height as 0), the equation will have only b0 value which is completely meaningless as in real-time height and weight can never be zero. This resulted due to considering the model values beyond its scope.</p></blockquote><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es ne"><img src="../Images/f41ee3c36d15f19a73f697e8265a78b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/0*KtoB8AkvhyYQ6dSq.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx translated">Linear regression</figcaption></figure></div><div class="ab cl nf ng gp nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="hb hc hd he hf"><p id="f334" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">Randomness and unpredictability are the two main components of a regression model.</p><blockquote class="lu"><p id="2302" class="lv lw hi bd lx ly lz ma mb mc md kl dx translated">Prediction = Deterministic + Statistic</p></blockquote><p id="02b8" class="pw-post-body-paragraph jo jp hi jq b jr me jt ju jv mf jx jy jz mg kb kc kd mh kf kg kh mi kj kk kl hb bi nm translated"><span class="l nn no np bm nq nr ns nt nu di">D</span>e部长部分被模型中的预测变量覆盖。</p><p id="194e" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi nm translated"><span class="l nn no np bm nq nr ns nt nu di"> S </span>随机部分揭示了预期值和观测值不可预测的事实。</p><p id="437c" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">总会有一些信息被遗漏。这个信息可以从剩余信息中获得。</p><blockquote class="mo mp mq"><p id="cea8" class="jo jp lf jq b jr ko jt ju jv kp jx jy mr lc kb kc ms ld kf kg mt le kj kk kl hb bi translated">让我们通过一个例子来理解<strong class="jq hj"> <em class="hi">余数</em> </strong>的概念。考虑一下，当给定一个地方的温度时，我们有一个预测果汁销售的数据集。回归方程预测的值与实际值总会有一些差异。销售额不会与真正的产值完全相符。这个差值称为<strong class="jq hj">余项</strong>。</p></blockquote><p id="3874" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated"><strong class="jq hj">残基的特性:</strong></p><ul class=""><li id="e284" class="km kn hi jq b jr ko jv kp jz kq kd kr kh ks kl mu ku kv kw bi translated">残差不显示任何模式</li><li id="ed76" class="km kn hi jq b jr kx jv ky jz kz kd la kh lb kl mu ku kv kw bi translated">相邻残差不应相同，因为它们表明系统遗漏了一些信息。</li></ul><p id="48e5" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">残差图有助于使用残差值分析模型。它绘制在预测值和残差之间。他们的价值观是标准化的。该点与0的距离指定了该值的预测有多差。如果该值为正值，则预测值较低。如果该值为负，则预测值为高。<em class="lf"> 0值表示完全预测。</em>因此，检测残差模式可以改进模型。</p><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nv"><img src="../Images/4954a662bb2cbd7ae0253f34e899a965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XnE_PsemYTnFSqW3.png"/></div></div><figcaption class="mw mx et er es my mz bd b be z dx translated">残差分析</figcaption></figure><p id="d4c2" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">残差图的非随机模式表明该模型，</p><ul class=""><li id="6541" class="km kn hi jq b jr ko jv kp jz kq kd kr kh ks kl mu ku kv kw bi translated">缺少对模型目标有重要贡献的变量</li><li id="f3cd" class="km kn hi jq b jr kx jv ky jz kz kd la kh lb kl mu ku kv kw bi translated">缺少捕捉非线性(使用多项式项)</li><li id="4509" class="km kn hi jq b jr kx jv ky jz kz kd la kh lb kl mu ku kv kw bi translated">模型中的术语之间没有交互</li></ul><p id="5ece" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">应用:</p><ul class=""><li id="54f2" class="km kn hi jq b jr ko jv kp jz kq kd kr kh ks kl mu ku kv kw bi translated">在<a class="ae nb" href="https://en.wikipedia.org/wiki/Capital_asset_pricing_model" rel="noopener ugc nofollow" target="_blank">资本资产定价模型</a>中用于分析和量化投资的系统风险。</li><li id="b372" class="km kn hi jq b jr kx jv ky jz kz kd la kh lb kl mu ku kv kw bi translated">线性回归是经济学中主要的经验工具。</li></ul><blockquote class="mo mp mq"><p id="a4f6" class="jo jp lf jq b jr ko jt ju jv kp jx jy mr lc kb kc ms ld kf kg mt le kj kk kl hb bi translated">例如，它用于预测劳动力需求和劳动力供给。</p></blockquote><ul class=""><li id="a20d" class="km kn hi jq b jr ko jv kp jz kq kd kr kh ks kl mu ku kv kw bi translated">在加拿大，环境影响监测计划使用鱼类统计分析和<a class="ae nb" href="https://en.wikipedia.org/wiki/Benthic_zone" rel="noopener ugc nofollow" target="_blank">底栖生物</a>调查来衡量纸浆厂或金属矿废水对水生生态系统的影响。</li></ul><h1 id="d3d6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">Python实现</h1><p id="2108" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><strong class="jq hj">数据集:</strong><a class="ae nb" href="https://github.com/bhartendudubey/Supervised-Learning-Algorithms/blob/master/dataset.csv" rel="noopener ugc nofollow" target="_blank"><em class="lf">数据集</em> </a>包含关于在广告上花费的钱和它们产生的销售额的信息(在电视、广播和报纸广告上花费的钱)。</p><p id="d7ec" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">链接:<a class="ae nb" href="https://github.com/bhartendudubey/Supervised-Learning-Algorithms/blob/master/dataset.csv" rel="noopener ugc nofollow" target="_blank">https://github . com/bhartendudubey/Supervised-Learning-Algorithms/blob/master/dataset . CSV</a></p><p id="cd13" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated"><strong class="jq hj">目的:</strong>目标是使用线性回归来了解广告支出如何影响销售。</p><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nw"><img src="../Images/1aef52c5e1e98a7d7b7576439493766b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x10DBK2HyjICvBiN.jpg"/></div></div><figcaption class="mw mx et er es my mz bd b be z dx translated">图片提供:<a class="ae nb" href="http://shutterstock.com" rel="noopener ugc nofollow" target="_blank">shutterstock.com</a></figcaption></figure><p id="d79e" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">这里的<a class="ae nb" href="https://github.com/bhartendudubey/Supervised-Learning-Algorithms/blob/master/Linear_regression.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="lf"> Jupyter笔记本</em> </a>为线性回归的python实现。</p><p id="e126" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz lc kb kc kd ld kf kg kh le kj kk kl hb bi translated">链接:<a class="ae nb" href="https://github.com/bhartendudubey/Supervised-Learning-Algorithms/blob/master/Linear_regression.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/bhartendudubey/Supervised-Learning-Algorithms/blob/master/Linear _ regression . ipynb</a></p></div></div>    
</body>
</html>