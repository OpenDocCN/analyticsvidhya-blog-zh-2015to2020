<html>
<head>
<title>A Comprehensive Guide to Build your own Language Model in Python!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python构建自己的语言模型的全面指南！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-comprehensive-guide-to-build-your-own-language-model-in-python-5141b3917d6d?source=collection_archive---------0-----------------------#2019-08-08">https://medium.com/analytics-vidhya/a-comprehensive-guide-to-build-your-own-language-model-in-python-5141b3917d6d?source=collection_archive---------0-----------------------#2019-08-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if"><p id="d80f" class="ig ih hi bd ii ij ik il im in io ip dx translated">“我们倾向于只看语言，而没有意识到语言有多大的力量。”</p></blockquote><p id="5d74" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ip hb bi translated"><a class="ae jo" href="https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/" rel="noopener ugc nofollow" target="_blank">文本摘要</a>，生成全新的文本片段，预测下一个单词(谷歌的自动填充)，等等。你知道所有这些NLP任务的共同点是什么吗？</p><p id="b88c" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">都是以语言模型为动力的！老实说，这些语言模型是大多数高级NLP任务的关键的第一步。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ju"><img src="../Images/03edac4d8d12f91d726910236096d6de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UdxiQ1XCsI0XHQtT.png"/></div></div></figure><p id="17dc" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">在本文中，我们将涵盖语言模型的长度和宽度。</p><p id="9f87" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">所以，系紧你的安全带，提高你的语言技能——我们正在进入自然语言处理的奇妙世界！</p><h1 id="0944" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">什么是NLP中的语言模型？</h1><blockquote class="if"><p id="522c" class="ig ih hi bd ii ij le lf lg lh li ip dx translated">语言模型学习预测单词序列的概率。</p></blockquote><p id="d7f4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ip hb bi translated">但是为什么我们需要学习单词的概率呢？让我们用一个例子来理解这一点。</p><p id="adf6" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">在机器翻译中，你从一种语言中获取一堆单词，然后将这些单词转换成另一种语言。现在，系统可能会给出许多潜在的翻译，您需要计算每种翻译的概率，以了解哪种翻译最准确。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es lj"><img src="../Images/0a24ed28210a98ce356ac149ed2ba546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*S1AhIfgZOLDgmNBu.png"/></div></figure><p id="bb00" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">在上面的例子中，我们知道第一句的概率会大于第二句，对吗？这就是我们如何达到正确的翻译。</p><p id="1f58" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">这种将语言规则建模为概率的能力为NLP相关的任务提供了强大的能力。</p><h1 id="a1a6" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">语言模型的类型</h1><p id="1f4c" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">主要有两种类型的语言模型:</p><ol class=""><li id="34bd" class="lp lq hi it b iu jp iy jq jc lr jg ls jk lt ip lu lv lw lx bi translated"><strong class="it hj">统计语言模型:</strong>这些模型使用传统的统计技术，如N-gram、隐马尔可夫模型(HMM)和某些语言规则来学习单词的概率分布</li><li id="febb" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc ip lu lv lw lx bi translated">神经语言模型:这些是NLP镇的新玩家，他们使用不同种类的神经网络来模拟语言</li></ol><p id="25cc" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">既然您已经对语言模型有了一个相当好的想法，让我们开始构建一个吧！</p><h1 id="4535" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">构建N元语言模型</h1><blockquote class="if"><p id="c8bf" class="ig ih hi bd ii ij le lf lg lh li ip dx translated"><em class="iq">N-gram是N个记号(或单词)的序列。</em></p></blockquote><p id="5201" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ip hb bi translated">我们用一个例子来理解N-gram。考虑下面的句子:</p><p id="977f" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">"我喜欢阅读关于数据科学的博客."</p><p id="d09f" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">1-gram(或unigram)是一个单词序列。对于上面的句子，单字可以简单地是:“我”、“爱”、“阅读”、“博客”、“关于”、“数据”、“科学”、“分析”、“Vidhya”。</p><p id="36db" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">2-gram(或bigram)是两个单词的单词序列，如“我爱”，“爱阅读”，或“分析Vidhya”。</p><p id="7034" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">相当简单的东西！</p><h1 id="a451" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">N元语言模型是如何工作的？</h1><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es md"><img src="../Images/545f3daabcb3d4e97ce9a023889c945a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fcnyvZ1CTjrl7kFE.jpg"/></div></div></figure><p id="c6e3" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">N元语法语言模型预测语言中任意单词序列内给定N元语法的概率。</p><blockquote class="if"><p id="04ab" class="ig ih hi bd ii ij le lf lg lh li ip dx translated">如果我们有一个好的N-gram模型，我们可以预测p(w | h)——给定以前单词<em class="iq"> h </em>的历史，看到单词<em class="iq"> w </em>的概率是多少——其中历史包含n-1个单词。</p></blockquote><p id="27ed" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ip hb bi translated"><strong class="it hj">我们必须估计这个概率来构建一个N元模型。</strong></p><p id="5ce0" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">我们分两步计算这个概率:</p><ol class=""><li id="a412" class="lp lq hi it b iu jp iy jq jc lr jg ls jk lt ip lu lv lw lx bi translated">应用概率链规则</li><li id="8220" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc ip lu lv lw lx bi translated">然后，我们应用一个非常强的简化假设，使我们能够以一种简单的方式计算p(w1…ws)</li></ol><p id="7e9a" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">概率的链式法则是:</p><pre class="jv jw jx jy fd me mf mg mh aw mi bi"><span id="7668" class="mj kh hi mf b fi mk ml l mm mn">p(w1...ws) = p(w1) . p(w2 | w1) . p(w3 | w1 w2) . p(w4 | w1 w2 w3) ..... p(wn | w1...wn-1)</span></pre><p id="e00f" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">那么什么是链式法则呢？它告诉我们如何通过使用给定前一个单词的条件概率来计算序列的联合概率。</p><p id="6e6b" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">但是我们无法访问这些具有多达n-1个单词的复杂条件的条件概率。那么我们该如何进行呢？</p><p id="6c99" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">这就是我们引入简化假设的地方。对于所有情况，我们可以假设:</p><pre class="jv jw jx jy fd me mf mg mh aw mi bi"><span id="1b8a" class="mj kh hi mf b fi mk ml l mm mn">p(wk | w1...wk-1) = p(wk | wk-1)</span></pre><p id="5768" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">这里，我们<strong class="it hj">通过仅查看上下文的最后一个单词来近似</strong>单词<em class="mo"> wk </em>的历史(上下文)。这个假设被称为<strong class="it hj">马尔可夫假设</strong>。</p><h1 id="5ba2" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">构建基本语言模型</h1><p id="99f1" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">既然我们理解了什么是N-gram，那么让我们使用Reuters语料库的三元模型来构建一个基本的语言模型。</p><p id="04e9" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">路透社语料库是10，788篇新闻文档的集合，总计130万字。我们可以使用NLTK包用几行代码构建一个语言模型:</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="817e" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">上面的代码非常简单。我们首先在NLTK的帮助下将文本分割成三元模型，然后计算三元模型的每个组合在数据集中出现的频率。</p><p id="b814" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">然后，我们用它来计算一个单词的概率，给定前两个单词。这就是我们语言模型的本质！</p><p id="b81f" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">让我们用这个语言模型做一个简单的预测。我们将从两个简单的词开始——“今天”。我们希望我们的模型能告诉我们下一个单词是什么:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mr"><img src="../Images/8dfd862e978375f595335778e14fd72f.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/0*t1fSCI9lvYs38wMo.png"/></div></figure><p id="e44c" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">所以我们得到了所有可能出现的单词的预测，以及它们各自的概率。现在，如果我们拿起单词“price”并再次对单词“the”和“price”进行预测:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es ms"><img src="../Images/1b0f739c86a5f081d5f9fc16eb3901d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/0*Ruiuevys7R2-nOE5.png"/></div></figure><p id="ccdc" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">如果我们不断重复这个过程，我们很快就会有一个连贯的句子！下面是一个脚本，使用我们的n-gram模型生成一段随机的文本:</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="6184" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">这是我们的模型生成的一些文本:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mt"><img src="../Images/190db232a6c1a8ee1b9a2b39143d8097.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*U8q0U8KbKgL577o1.png"/></div></div></figure><p id="807e" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">相当令人印象深刻！尽管这些句子感觉有点不太对劲(可能因为路透社的数据集大多是新闻)，但它们非常连贯，因为我们刚刚用17行Python代码和一个非常小的数据集创建了一个模型。</p><p id="87de" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">这也是Google、Alexa和Apple等公司用于语言建模的基本原则。</p><h1 id="4171" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">N-gram语言建模方法的局限性</h1><p id="4c4a" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">基于n元语法的语言模型确实有一些缺点:</p><ol class=""><li id="f6cf" class="lp lq hi it b iu jp iy jq jc lr jg ls jk lt ip lu lv lw lx bi translated">N越高，模型通常越好。但是这导致了大量的计算开销，就RAM而言需要大量的计算能力</li><li id="8830" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc ip lu lv lw lx bi translated">n元语法是语言的一种稀疏表示。它将给所有不存在于训练语料库中的单词赋予零概率</li></ol><h1 id="3eec" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">构建神经语言模型</h1><p id="2dac" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">深度学习已经被证明在许多NLP任务上表现得非常好，如文本摘要、机器翻译等。由于这些任务本质上是建立在语言建模的基础上的，所以使用神经网络进行语言建模已经取得了巨大的研究成果。</p><blockquote class="if"><p id="2b38" class="ig ih hi bd ii ij le lf lg lh li ip dx translated">我们本质上可以建立两种神经语言模型——字符级和单词级。</p></blockquote><p id="3b3a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ip hb bi translated">甚至在每一个类别下，我们可以根据我们如何构建学习问题的简单事实，划分出许多子类别。我们将采用最简单的方法——构建一个字符级语言模型。</p><h1 id="3708" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">理解问题陈述</h1><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mu"><img src="../Images/a71818ccf9d7f5849ab2e69be9daa5bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/0*0z6F1msdhKU58pU8.jpg"/></div></figure><p id="e32a" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">上面的文字是不是看起来很熟悉？这是美国独立宣言！我们将使用的数据集是来自该声明的文本。</p><blockquote class="if"><p id="6039" class="ig ih hi bd ii ij le lf lg lh li ip dx translated"><em class="iq">问题陈述是在给定的文本上训练语言模型，然后在给定输入文本的情况下生成文本，其方式使得该文本看起来直接来自该文档，并且语法正确且易读。</em></p></blockquote><p id="1511" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn ip hb bi translated">你可以从<a class="ae jo" href="https://gist.github.com/mohdsanadzakirizvi/3a5a80ac8e32cdb15b86f9faea636cee" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据集。我们开始吧！</p><h1 id="783b" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">导入库</h1><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h1 id="0b1b" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">读取数据集</h1><p id="d9a7" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">在Python中，可以将数据集作为字符串直接读取:</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h1 id="a5b1" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">预处理文本数据</h1><p id="5e39" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">我们执行基本的文本预处理，因为该数据没有太多噪声。我们将所有单词小写以保持一致性，并删除长度小于3:</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="6ebf" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">一旦预处理完成，就该为模型创建训练序列了。</p><h1 id="1777" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">创建序列</h1><p id="086c" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">这个问题的建模方式是我们接受30个字符作为上下文，并要求模型预测下一个字符。</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="1573" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">让我们看看我们的训练序列是什么样的:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mv"><img src="../Images/63c855b9f3f245674add0fdd1b3fb070.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/0*K5yPmYK938W-6Fa-.png"/></div></figure><h1 id="0314" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">编码序列</h1><p id="2c8f" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">一旦序列生成，下一步就是对每个字符进行编码。这会给我们一系列的数字。</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="701d" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">所以现在，我们有这样的序列:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mw"><img src="../Images/6b5e1c2489caeff3d81678ecfc9340c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/0*B9kmhe1wzb4YRF_K.png"/></div></figure><h1 id="4f4a" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">创建培训和验证集</h1><p id="87fb" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">一旦我们准备好了序列，我们就将数据分成训练和验证两部分。这是因为在训练时，我想跟踪我的语言模型在处理看不见的数据时有多好。</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h1 id="54dc" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">模型结构</h1><p id="f121" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">是时候构建我们的语言模型了！</p><p id="feef" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">我已经使用Keras的嵌入层来学习每个字符的50维嵌入。这有助于模型理解角色之间的复杂关系。我还使用了一个GRU层作为基础模型，它有150个时间步长。最后，使用密集层和softmax激活进行预测。</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h1 id="f133" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">推理</h1><p id="fdc7" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">一旦模型完成训练，我们就可以使用下面的代码根据给定的输入序列从模型中生成文本:</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h1 id="1137" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结果</h1><p id="ffea" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">让我们来测试一下我们的模型。在下面的视频中，我给了模型不同的输入。让我们看看它的表现如何:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mx"><img src="../Images/354f4d4f69161c986c5a9be279bed977.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*WwYaXj3KlBSsqT-5TtKGFw.gif"/></div></figure><p id="33b5" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">请注意我们的语言模型对输入文本是多么敏感！像在“of”或“for”后面添加空格这样的小变化完全改变了下一个字符出现的概率，因为当我们写空格时，我们意味着一个新单词应该开始。</p><p id="e964" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">此外，请注意<strong class="it hj">在原始训练数据</strong>中，模型预测的组合几乎没有一个存在。因此，我们的模型实际上是根据它对英语规则的理解和它在训练中看到的词汇来构建单词。</p><h1 id="b909" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">使用OpenAI的GPT-2生成自然语言</h1><p id="b2de" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">领先的研究实验室在庞大的数据集上训练了复杂的语言模型，这导致了自然语言处理领域的一些最大突破。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es my"><img src="../Images/f3ec97fe03f9aceea3df45a7fe16d84f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3tIl4Oid3SWXSF_a.jpg"/></div></div></figure><p id="03eb" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">2019年2月，<strong class="it hj"> OpenAI </strong>发布了一款名为<strong class="it hj"> GPT-2的基于变形金刚的新语言模型，掀起了一场风暴。</strong> GPT-2是一个基于<a class="ae jo" href="https://www.analyticsvidhya.com/blog/2019/06/understanding-transformers-nlp-state-of-the-art-models/" rel="noopener ugc nofollow" target="_blank">转换器的</a>生成语言模型，在来自互联网的40GB精选文本上进行训练。</p><p id="2b31" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">你可以在这里阅读更多关于GPT-2的信息:</p><ul class=""><li id="b1af" class="lp lq hi it b iu jp iy jq jc lr jg ls jk lt ip mz lv lw lx bi translated"><a class="ae jo" href="https://www.analyticsvidhya.com/blog/2019/07/openai-gpt2-text-generator-python/" rel="noopener ugc nofollow" target="_blank"> OpenAI的GPT-2:用Python构建世界上最先进的文本生成器的简单指南</a></li></ul><p id="81c9" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">那么，让我们来看看GPT-2的行动吧！</p><h1 id="33b9" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">关于py torch-变形金刚</h1><p id="a78f" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">在我们开始使用GPT-2之前，让我们先了解一下<a class="ae jo" href="https://www.analyticsvidhya.com/blog/2019/07/pytorch-transformers-nlp-python/?utm_source=blog&amp;utm_medium=comprehensive-introduction-language-models-nlp-python" rel="noopener ugc nofollow" target="_blank"> PyTorch-Transformers </a>库。我们将使用这个库来加载预先训练好的模型。</p><blockquote class="if"><p id="2c19" class="ig ih hi bd ii ij le lf lg lh li ip dx translated">PyTorch-Transformers为自然语言处理(NLP)提供最先进的预训练模型。</p></blockquote><h1 id="2b7f" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr na kt ku kv nb kx ky kz nc lb lc ld bi translated">在机器上安装PyTorch-Transformers</h1><p id="b7fc" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">在Python中安装Pytorch-Transformers相当简单。您可以简单地使用pip安装:</p><pre class="jv jw jx jy fd me mf mg mh aw mi bi"><span id="f54c" class="mj kh hi mf b fi mk ml l mm mn">pip install pytorch-transformers</span></pre><p id="f849" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">或者，如果您正在使用Colab:</p><pre class="jv jw jx jy fd me mf mg mh aw mi bi"><span id="76da" class="mj kh hi mf b fi mk ml l mm mn">!pip install pytorch-transformers</span></pre><p id="df52" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">由于这些模型中的大多数都是GPU密集型的，我建议在本文的这一部分使用<a class="ae jo" href="https://colab.research.google.com/notebooks/welcome.ipynb#recent=true" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>。</p><h1 id="8e64" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">使用GPT-2完成句子</h1><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es nd"><img src="../Images/1a757551f11890cd3745d9886c27de1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/0*xFAyRkm5Us5SEVsw.png"/></div></figure><p id="75be" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated"><strong class="it hj">让我们使用GPT-2建立我们自己的句子完成模型。我们将试着预测句子中的下一个单词:</strong></p><blockquote class="ne nf ng"><p id="fd32" class="ir is mo it b iu jp iw ix iy jq ja jb nh jr je jf ni js ji jj nj jt jm jn ip hb bi translated">“_________中最快的汽车是什么？”</p></blockquote><p id="b465" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">我选择这个例子是因为这是Google的文本补全给出的第一个建议。下面是执行相同操作的代码:</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="7227" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">这里，我们将文本标记和索引为一个数字序列，并将其传递给<em class="mo"> GPT2LMHeadModel </em>。这是GPT2模型转换器，顶部有一个语言建模头(线性层，权重与输入嵌入相关)。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es nk"><img src="../Images/0596849f0af92e2e5982be3c769a9435.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_JWST_e7Lhb3djx2.png"/></div></div></figure><p id="1802" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">厉害！该模型成功预测下一个单词为<strong class="it hj">【世界】</strong>。这是相当惊人的，因为这是谷歌的建议。</p><h1 id="0bf2" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">使用GPT-2的条件文本生成</h1><p id="2263" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">到目前为止，我们已经预测了下一个单词和下一个字符。让我们通过从输入的一段文本生成一个完整的段落，将文本生成提升到一个新的层次！</p><p id="d8e0" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">让我们看看我们的模型为下面的输入文本生成了什么:</p><pre class="jv jw jx jy fd me mf mg mh aw mi bi"><span id="af5a" class="mj kh hi mf b fi mk ml l mm mn">Two roads diverged in a yellow wood,<br/>And sorry I could not travel both<br/>And be one traveler, long I stood<br/>And looked down one as far as I could<br/>To where it bent in the undergrowth;</span></pre><p id="6068" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">这是罗伯特·弗罗斯特的诗《未选择的路》的第一段。让我们让GPT-2开始工作，并生成这首诗的下一段。</p><p id="a817" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">我们将使用PyTorch-Transformers为此任务提供的现成脚本。让我们首先克隆他们的存储库:</p><pre class="jv jw jx jy fd me mf mg mh aw mi bi"><span id="fa23" class="mj kh hi mf b fi mk ml l mm mn">!git clone <a class="ae jo" href="https://github.com/huggingface/pytorch-transformers.git" rel="noopener ugc nofollow" target="_blank">https://github.com/huggingface/pytorch-transformers.git</a></span></pre><p id="2004" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">现在，我们只需要一个命令来启动模型！</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="a7ef" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">让我们看看我们的GPT-2模型对于输入文本给出了什么输出:</p><pre class="jv jw jx jy fd me mf mg mh aw mi bi"><span id="e488" class="mj kh hi mf b fi mk ml l mm mn">And with my little eyes full of hearth and perfumes, <br/>I saw the blue of Scotland, <br/>And this powerful lieeth close <br/>By wind's with profit and grief,<br/>And at this time came and passed by,<br/>At how often thro' places <br/>And always this path was fresh Through one winter down.<br/>And, stung by the wild storm,<br/>Appeared half-blind, yet in that gloomy castle.</span></pre><p id="04d1" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">这不是很疯狂吗？！输出几乎完全符合这首诗的上下文，看起来是这首诗第一段的良好延续。</p><h1 id="9ee2" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结束注释</h1><p id="a1a1" class="pw-post-body-paragraph ir is hi it b iu lk iw ix iy ll ja jb jc lm je jf jg ln ji jj jk lo jm jn ip hb bi translated">相当全面的旅程，不是吗？我们讨论了什么是语言模型，以及如何使用最新的NLP框架来使用它们。最终的结果是如此令人印象深刻！</p><p id="3c9e" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated">如果您对本文有任何疑问或反馈，请在下面的评论区告诉我。快乐学习！</p><p id="89cb" class="pw-post-body-paragraph ir is hi it b iu jp iw ix iy jq ja jb jc jr je jf jg js ji jj jk jt jm jn ip hb bi translated"><em class="mo">原载于2019年8月8日</em><a class="ae jo" href="https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/" rel="noopener ugc nofollow" target="_blank"><em class="mo">https://www.analyticsvidhya.com</em></a><em class="mo">。</em></p></div></div>    
</body>
</html>