<html>
<head>
<title>How are AutoML techniques changing the face of machine learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AutoML技术如何改变机器学习的面貌？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-are-automl-techniques-changing-the-face-of-machine-learning-621f1e5e3abb?source=collection_archive---------23-----------------------#2020-08-16">https://medium.com/analytics-vidhya/how-are-automl-techniques-changing-the-face-of-machine-learning-621f1e5e3abb?source=collection_archive---------23-----------------------#2020-08-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ebf715016b53fc84d4408ae01c99f64d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zYAOwcn1nciq2xcl2gMwmA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">AutoML</figcaption></figure><p id="e2c9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于所有便宜的计算机拥有者来说，NAS和AutoML就像梦想成真。就我个人而言，我拥有一台Macbook Pro 2017，作为一名预算有限的学生，让深度学习模型实际运行一直是一场噩梦。我的笔记本电脑已经连续几天甚至几周训练YOLOv4、YOLOv3、Inception和SSD模型。NAS改变了一切！随着围绕彩票假说的工作继续进行，我认为研究人员正在将人工智能带入下一个范式。对于所有的Kagglers来说，与在多GPU上运行复杂模型的参与者竞争肯定很艰难，具有讽刺意味的是，他们获胜的几率更高。</p><p id="a339" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在我深入探讨为什么我要谈论这个之前，让我们先谈谈什么。最近的一项研究证明，非常稀疏的神经网络(其权重已被初始化为极深网络的权重)可以实现相当水平的准确性，而没有低得多的计算要求，猜猜看，推理和训练时间更少？这是什么意思？我们CPU用户有机会。研究人员针对MNIST和CIFAR-10数据集测试了他们的假设，即现在通常所说的彩票假设，并令人惊讶地实现了同等水平的准确性，其网络是具有几个完全连接层的原始极其庞大的前馈神经网络的10-20%。他们的研究可以追溯到深度学习领域的许多参与者长期以来一直在谈论的问题，但他们能够证明这一点！我们都知道不相关的重量会增加我们模型的体积，对于CPU用户来说，一些关键的训练时间可能会挽救他们的笔记本电脑。研究人员提出的论点是，大部分工作是由我们庞大的深度网络的一部分完成的，其余的是多余的，因此我们可以复制具有极其稀疏特征的非常深度的网络的性能。可以肯定地说，这项研究具有真正的潜力，我们正在进入一个技术探索的时代，在这个时代，拥有越少越好！</p><p id="9901" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我今天想谈的另一件事是神经架构搜索(NAS)。创建神经网络的所有排列和组合是不可能的，但如果存在一种技术，其中一个网络可以使用人工智能中的另一个分支来最好地完成你的任务，这也可能使用神经架构搜索技术。为了给您一个高层次的概述，NAS使用强化学习和梯度优化技术，并调整其状态和奖励系统，以创建或选择最佳体系结构和适当的参数。现在，NAS的建立是为了将ML带给大众，并允许人们用有限的领域知识进行研究和利用这种复杂的技术。但是NAS压倒了一切吗？到目前为止，NAS或更广泛的领域自动化机器学习还有很长的路要走，它有自己的一系列缺点，还没有证明自己足以在任何地方使用。无论如何，NAS真的很酷，我相信这是一种未来的技术，肯定会让所有人都可以使用人工智能。</p><p id="4b57" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我想现在应该很清楚为什么我要反复强调这些概念了。这不仅是朝着“面向所有人的深度学习”迈出的一大步，也是更好地探索边缘和“精简”设备的一条途径。稀疏神经网络比那些转换的深度网络有更好的机会准确和更快地运行。所以想象一下，在短短的几年内，我们在带GPU的笔记本电脑上看到的一切，都可以在我们的手机上用指尖实现！</p><p id="6e24" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">NAS和AutoML对我即将开始的项目是一个巨大的推动。我和我的朋友决定为可持续消费者设计一个垃圾分类器。我们发现安全的垃圾处理，尤其是在印度，在可持续性方面是一个飞跃，但只有一个问题:信息。甚至我也不知道垃圾处理的规范，这个项目给我带来了很好的学习曲线。AutoML拯救了我们，而不是走从零开始或转移学习的相对混乱的网络路线。总的来说，我们使用CreateML、Teachable Machine和AutoKeras等软件来制作分类器。这次我们的模型只花了几个小时就达到了令人印象深刻的精确度。我们创建了模型，将垃圾分类到我们定义的类别中，并告知消费者他们要处理什么以及如何处理。在幕后，我们易于使用的NAS支持模型可以找出基本类别，如纸张、垃圾、金属、塑料等。而且更进一步告诉你是将其制成堆肥，回收还是丢弃。为了更好地衡量，我们甚至包括一个塑料分类器，它被广泛地分为7类塑料，每一类都有不同的处理方法。我们使用这些模型，并将它们转换成edge可用的格式，并发布了一款iOS应用。我们一直在寻找即兴创作的应用程序，所以去app store上搜索“Garbify”并发表评论吧！</p><p id="cef7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae js" href="https://apps.apple.com/in/app/garbify/id1522674990" rel="noopener ugc nofollow" target="_blank">https://apps.apple.com/in/app/garbify/id1522674990</a>—App链接。它是在另一个账户下发布的，因为我没有苹果账户:(</p><p id="5bf2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们的下一步是创建一个定制的分析后端，并在我们的模型中加入一个电子垃圾识别器。</p><p id="e2f1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我说的就是这些！让我知道你对这个应用程序的看法！</p><p id="6c3d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">彩票假说研究论文—【https://arxiv.org/abs/1803.03635 T2】</p><div class="jt ju jv jw fd ab cb"><figure class="jx ij jy jz ka kb kc paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/96cfa1ce308a3f4b421feab18822de3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*A9c6doMqjYWyCxwz6cBy6g.png"/></div></figure><figure class="jx ij jy jz ka kb kc paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/b20968208bb0d639b59c77b94d6e4625.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ZCx2btcS1usHOL02ErVlzA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx kd di ke kf translated">我们应用的快照</figcaption></figure></div><div class="ab cb"><figure class="jx ij jy jz ka kb kc paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/34cb1c20f42f502c29fa20298a30946e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Oa1oK2TZY7jmqeyc8PbfwA.png"/></div></figure><figure class="jx ij jy jz ka kb kc paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/8f6dbca6b881b8ed9d117912ebe2379a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*BAOZjt9F_Ke7TtbvTmbFXA.png"/></div></figure></div></div></div>    
</body>
</html>