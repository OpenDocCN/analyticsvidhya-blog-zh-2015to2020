<html>
<head>
<title>Finding Annual Income (Python- Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">寻找年收入(Python分类)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-classification-project-finding-annual-income-python-66eba44ade53?source=collection_archive---------13-----------------------#2020-05-11">https://medium.com/analytics-vidhya/machine-learning-classification-project-finding-annual-income-python-66eba44ade53?source=collection_archive---------13-----------------------#2020-05-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="c2f3" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">通过KNN、朴素贝叶斯、决策树、随机森林、GLM逻辑回归，建立了一个机器学习模型来准确预测个人收入高于或低于5万英镑。我用过的包有panda，numpy，matplotlib，sklearn。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/4e74f76eda100e6ac4e5055b1ecfddfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oja3YY5DZJEX_6daoLAa1w.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:互联网</figcaption></figure><p id="1c35" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在最近的冠状病毒爆发中，大量的人在失业后报名参加了美国1200美元的刺激计划。受助人的条件之一是年收入低于75，000美元，这些都可以通过他们的年度税务报告获得。(Singletary，2020)尽管如此，仍有数量惊人的人没有纳税。了解未申报税收个人的潜在年收入可以帮助政府采取战略性措施来照顾他们并确保他们的银行储备规模。因此，政府将从机器学习模型中受益匪浅，该模型可以根据个人的人口特征来预测个人的收入。</p><p id="38e3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这个项目中，我们将使用五种不同的监督算法(KNN，朴素贝叶斯，决策树和规则，随机森林，GLM和逻辑回归。)来自1994年美国人口普查的数据集。我们将在相互比较初步结果时选择最佳候选算法，并进一步优化所选算法，以最佳地模拟数据。我们这个项目的目标是最终提出一个模型，可以准确预测一个人的收入是高于还是低于50，000美元(分类-二元类)。根据Inflationcalcualtor.com，1994年的5万美元相当于2019年的8.7万美元。然后在这之后，未来的研究人员可以使用这个模型来申请当年的数据集。</p><p id="4bd0" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这个项目的数据集可以从UCI机器学习知识库或Kaggle网站获得。罗恩·科沙维和巴里·贝克尔在<em class="kj">“提高朴素贝叶斯分类器的准确性:一种决策树混合”</em>(科沙维，1996)发表了他们的发现，该数据集是在他们的帮助下捐赠的。请记住，我们在这里研究的数据是由对原始数据集的微小更改组成的，比如删除<code class="du kk kl km kn b">'fnlwgt'</code>特性以及缺少条目或条目格式不正确的记录。</p><h2 id="7775" class="ko kp hi bd kq kr ks kt ku kv kw kx ky jw kz la lb ka lc ld le ke lf lg lh li bi translated">数据</h2><p id="1318" class="pw-post-body-paragraph jn jo hi jp b jq lj ij js jt lk im jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated">该项目中更改后的人口普查数据集约有32，000个入口点，每个入口点有13个要素。</p><h2 id="bc66" class="ko kp hi bd kq kr ks kt ku kv kw kx ky jw kz la lb ka lc ld le ke lf lg lh li bi translated"><strong class="ak">特性</strong></h2><p id="7970" class="pw-post-body-paragraph jn jo hi jp b jq lj ij js jt lk im jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated"><code class="du kk kl km kn b">age</code>:年龄</p><p id="0dfc" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">workclass</code>:工人阶级(私营、自营企业、自营企业、联邦政府、地方政府、州政府、无薪、从未工作)</p><p id="bed5" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">education_level</code>:教育水平(学士、部分大学、11年级、HS-grad、Prof-school、Assoc-acdm、Assoc-voc、9年级、7-8年级、12年级、硕士、1-4年级、10年级、博士、5-6年级、学前班)</p><p id="688b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">education-num</code>:完成的教育年数</p><p id="2756" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">marital-status</code>:婚姻状况(已婚-同居-配偶、离婚、未婚、分居、丧偶、已婚-配偶不在、已婚-配偶)</p><p id="fb53" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">occupation</code>:工作职业(技术支持、工艺修理、其他服务、销售、行政管理、专业教授、搬运工人、清洁工、机器操作员、行政文员、农业-渔业、运输-搬家、私人服务、保安服务、武装部队)</p><p id="4e5b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">relationship</code>:关系状态(妻子、亲生子女、丈夫、非家庭成员、其他亲属、未婚)</p><p id="89c2" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">race</code>:种族(白人、亚洲太平洋岛民、美洲印第安爱斯基摩人、其他人、黑人)</p><p id="340d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">sex</code>:性别(女，男)</p><p id="4162" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">capital-gain</code>:货币资本收益</p><p id="67b4" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">capital-loss</code>:货币资金损失</p><p id="919e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">hours-per-week</code>:每周平均工作时间</p><p id="794f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du kk kl km kn b">native-country</code>:本土国家(美国、柬埔寨、英国、波多黎各、加拿大、德国、美国外围地区(关岛-USVI等)、印度、日本、希腊、中国、古巴、伊朗、洪都拉斯、菲律宾、意大利、波兰、牙买加、越南、墨西哥、葡萄牙、爱尔兰、法国、多米尼加共和国、老挝、厄瓜多尔、台湾、海地、哥伦比亚、匈牙利、危地马拉、尼加拉瓜、苏格兰、泰国、南斯拉夫、萨尔瓦多、特立尼达和多巴哥&amp;多巴哥、秘鲁、香港、荷兰)</p><h2 id="7c53" class="ko kp hi bd kq kr ks kt ku kv kw kx ky jw kz la lb ka lc ld le ke lf lg lh li bi translated"><strong class="ak">目标变量</strong></h2><p id="7f26" class="pw-post-body-paragraph jn jo hi jp b jq lj ij js jt lk im jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated"><code class="du kk kl km kn b">income</code>:收入阶层(&lt; =50K，&gt; 50K)</p><h2 id="3ab8" class="ko kp hi bd kq kr ks kt ku kv kw kx ky jw kz la lb ka lc ld le ke lf lg lh li bi translated">导入库并加载数据</h2><p id="229b" class="pw-post-body-paragraph jn jo hi jp b jq lj ij js jt lk im jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated">我们将首先导入数据集以及对我们的分析有用的必要Python库，如numpy、pandas、IPython、matplolib、seaborn、visuals file。数据集的最后一列是最终的“收入”二元结果，其余的是特征</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lo"><img src="../Images/e2f0b17da7498f7047609d8c198a76e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ekOGeFZDzsEi7UI7e00HXQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><h1 id="74b5" class="lp kp hi bd kq lq lr ls ku lt lu lv ky io lw ip lb ir lx is le iu ly iv lh lz bi translated"><strong class="ak"> I/探索性数据分析(EDA)和数据准备</strong></h1><p id="c72e" class="pw-post-body-paragraph jn jo hi jp b jq lj ij js jt lk im jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated">我们稍微研究了一下我们的数据集，看看每个群体中有多少人，以及年收入超过50，000美元的公民的百分比。我们还可以通过seasborn.pairplot()函数获得数据集的可视化视图，以了解每个因素是如何相互影响的</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ma"><img src="../Images/469d716d885f15ee7e136028c4f64648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*A5kK_-e6m5EQDfBsgSvmjQ.png"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mb"><img src="../Images/a66f47a2f1d6211850839790815c38da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qMGqcPzC3qxo_SfYDgeh9w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="eb5f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">为了在机器学习算法中被接受，必须准备数据。否则，模型将做出不正确的预测。该过程包括数据的清理、格式化和要素缩放。</p><p id="2b89" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">1/第一步是变换倾斜的连续特征。这是因为，如果范围未被归一化，则要素值的偏斜分布会使算法表现不佳。我们将数据分为要素和目标标签。然后我们可视化原始数据的偏斜连续。收入数据集具有两个偏态分布的特征:</p><ul class=""><li id="e390" class="mc md hi jp b jq jr jt ju jw me ka mf ke mg ki mh mi mj mk bi translated">资本收益</li><li id="200d" class="mc md hi jp b jq ml jt mm jw mn ka mo ke mp ki mh mi mj mk bi translated">资本损失</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/79763bd9db0f265293ff137931d43704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*002lZ7JCIW06Lz314wr4-g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="653b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">特征的分布向右倾斜。因此，我们对数据应用对数变换，以防止异常值对机器学习模型产生负面影响。然而，在处理o值时必须小心，因为log(o)是不确定的。我们可以将这些值转换成大于o的小数值，以便很好地应用对数。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mr"><img src="../Images/e021ef2a6c5c704ada206f7cb47d8793.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5zxQQUkCFzXfJwH3I1jMlQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="fa6a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">2第二步是通过数据换算使数字特征正常化。这种缩放最终不会改变特征分布的形状，但它确保了在应用五种模型时对每一个特征的平等处理。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ms"><img src="../Images/e9fe6b6ddcd612c4cc08905aea2ed05f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UDlZ4PLt6P4H6SL9tNlaKw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="4ff2" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">3/ <strong class="jp hj"> </strong>第三步是使用一键编码功能将“职业”或“种族”等分类因素转化为数字因素。通过这样做，算法将为与数字特征相似的分类特征的每个可能类别创建“虚拟”变量。但是，单热编码器不适合目标，因为这是一个复杂的过程，因此我们将手动将'&lt; =50k '指定为0，将'&gt; 50k '指定为1，以避免最终出现意外结果。由于one-hot编码功能，数据集从13个独特的特征调整为总共103个特征。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mt"><img src="../Images/2da1d3d55219f002a1f6b55d57c0bf6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FMMh_1SMjmNmYYg9Bdp5QQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mu"><img src="../Images/6a8456bd9714db5b1c631fa68a3c94eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sae_wZBsq5qWQRxvV1HPpg.png"/></div></div></figure><p id="eb14" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">4/ <strong class="jp hj"> </strong>第四步是将数据集以80-20的比例进行洗牌和拆分，分别用于训练测试</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/e02891a67245b16a8bc203ba104f6683.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*QDeJ1p-6cT9eycGAfJjHbw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><h1 id="b143" class="lp kp hi bd kq lq lr ls ku lt lu lv ky io lw ip lb ir lx is le iu ly iv lh lz bi translated"><strong class="ak">二/建立预测模型</strong></h1><p id="b0f1" class="pw-post-body-paragraph jn jo hi jp b jq lj ij js jt lk im jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated">考虑到我们数据的形状(30162个数据点和103个独特的因素)，我们足够幸运，我们选择的所有模型都可以适当地处理大量的因素。为了正确访问每个模型，我们将比较每个模型的优点和缺点</p><blockquote class="mw mx my"><p id="6b54" class="jn jo kj jp b jq jr ij js jt ju im jv mz jx jy jz na kb kc kd nb kf kg kh ki hb bi translated"><strong class="jp hj">a)K-最近邻算法</strong></p></blockquote><p id="469b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">优点</strong>:简单无训练期(被称为懒学)。研究人员可以无缝地添加新数据，而不会影响算法的准确性</p><p id="31ec" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">缺点</strong> : KNN与大型或高维数据集不兼容。该模型还需要特征缩放，并且对噪声数据、缺失值以及异常值高度敏感。(库马尔，2019年)</p><p id="d698" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">潜在应用:</strong>搜索“相似”物品的应用</p><blockquote class="mw mx my"><p id="9228" class="jn jo kj jp b jq jr ij js jt ju im jv mz jx jy jz na kb kc kd nb kf kg kh ki hb bi translated"><strong class="jp hj"> b)高斯朴素贝叶斯</strong></p></blockquote><p id="faf6" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">优势</strong>:最简单、最快的分类器之一，几乎不需要调整模型的超参数就能提供良好的结果。此外，它不需要大量的数据来进行有效的训练。</p><p id="dba4" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">弱点</strong>:该模型对数据分布的形状做了非常强的假设。它还受到数据稀缺和持续问题的困扰，这些问题会导致整个预测不准确。一般建议不要用它来解决分类问题</p><p id="789f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">潜在应用:</strong>自然语言处理(文本学习)</p><blockquote class="mw mx my"><p id="4216" class="jn jo kj jp b jq jr ij js jt ju im jv mz jx jy jz na kb kc kd nb kf kg kh ki hb bi translated"><strong class="jp hj"> c)决策树</strong></p></blockquote><p id="1f75" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">优点</strong>:流程有可理解的规则，不需要太多计算就可以进行分类。它可以处理连续变量和分类变量，并为研究人员提供了一个明确的指示，哪些特征是重要的。(Geeksforgeeks，2019年)</p><p id="a746" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">缺点</strong>:连续属性可能不是最适合模型的。对于许多类和相对少量的训练示例，它容易出错，并且训练成本相当高。</p><p id="4b1f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">潜在应用:</strong>动物图像分类</p><blockquote class="mw mx my"><p id="6319" class="jn jo kj jp b jq jr ij js jt ju im jv mz jx jy jz na kb kc kd nb kf kg kh ki hb bi translated"><strong class="jp hj"> d)随机森林</strong></p></blockquote><p id="71f1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">长处</strong>:非常适合分类问题，因为它是决策树的集合体。随机森林也适用于高维空间和大量训练样本</p><p id="2c2c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">缺点</strong>:在处理噪声数据时可能会过拟合</p><p id="0f8c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">潜在应用:</strong>股票市场价格预测</p><blockquote class="mw mx my"><p id="8971" class="jn jo kj jp b jq jr ij js jt ju im jv mz jx jy jz na kb kc kd nb kf kg kh ki hb bi translated">GLM和逻辑回归</p></blockquote><p id="d74a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">优势</strong>:响应变量可以有任何形式的指数分布类型，GLM可以处理分类因素。解释结果相对容易，并且不容易过度拟合</p><p id="009b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">缺点:它需要一个相当大的数据集。预测因子越多，样本量越大。GLM对局外人很敏感</p><p id="276a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">潜在应用:</strong>预测医疗费用</p><h1 id="b329" class="lp kp hi bd kq lq lr ls ku lt lu lv ky io lw ip lb ir lx is le iu ly iv lh lz bi translated"><strong class="ak"> III/预测模型对比和模型优化</strong></h1><blockquote class="mw mx my"><p id="cfec" class="jn jo kj jp b jq jr ij js jt ju im jv mz jx jy jz na kb kc kd nb kf kg kh ki hb bi translated"><strong class="jp hj"> a)型号对比</strong></p></blockquote><p id="814e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在了解了五种模型的所有优点和缺点之后，我们继续比较结果并选择模型的优化过程。在对事件进行预测时，我们可以得到四种类型的结果:真阳性(TP)、<em class="kj"> </em>【真阴性(TN)、假阳性(FP-第一类错误)和假阴性(FN-第二类错误)<em class="kj"> </em>一般来说，基于上述类型的结果，有四种度量来判断模型的性能:</p><p id="9c83" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">准确性:</strong>衡量预测与实际结果相比有多准确。</p><p id="6bc0" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> Precision: </strong>告知我们被正确分类为某一类的事件的百分比。</p><p id="0f5c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">回忆(敏感度):</strong>告知我们实际上属于某一类别的事件被我们归类为该类别的百分比。</p><p id="4f03" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> F1得分:</strong>表示精度和召回率得分的加权平均值，即精度和召回率得分的加权平均值(调和平均值)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nc"><img src="../Images/e2cae6d87b26e49b04f7da2160042cfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*H0fPFLaJpKTbvrcUcPW4nQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:维基百科</figcaption></figure><p id="176b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">由于我们的数据集是一个分类问题，在因子中有一些偏态分布，准确性本身不是一个合适的度量。相反，我们会寻找精确和回忆的数字。此外，由于我们搜索的是应该得到刺激支票救济的个人，因此模型精确预测收入超过5万美元的个人的能力比模型回忆起这些个人的能力更重要</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nd"><img src="../Images/0445061d6f1c598b3435655fd513c9d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*XBTWwSnrQ4LVAB_xHDHDDw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ne"><img src="../Images/77f67c2877e5da1963f6ab2778c6d4a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p5CALdIhgbU1OhYO3yAh8Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="22ca" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">根据上面的表格和图表，随机森林和逻辑回归具有最高的精确度和召回分数。尽管具有更高的精度分数，随机森林的性能几乎类似于逻辑回归的性能。对我们来说，在做出最终决定之前，改进模型并再次比较会好得多。另一方面，我们对朴素贝叶斯模型评分较低的原因之一是，该模型存在零频率问题，如果分类变量具有在训练数据集中未观察到的类别，则该模型将分配0(零)概率，并且不进行预测。朴素贝叶斯的另一个问题是独立预测者的假设。因此，我们最终得到了朴素贝叶斯的糟糕结果。下面是决策树的图示</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nf"><img src="../Images/47d17b5949d45814cff58c1e872f996c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gdi1OknbXabzpYTQnHGPbQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="9786" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们将尝试了解特征选择如何影响这两个模型的性能，并应用具有不同参数的K-fold交叉验证和网格搜索来找到具有最佳参数的最佳模型。</p><blockquote class="mw mx my"><p id="fa4e" class="jn jo kj jp b jq jr ij js jt ju im jv mz jx jy jz na kb kc kd nb kf kg kh ki hb bi translated"><strong class="jp hj"> b)车型优化</strong></p></blockquote><p id="7c2a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">功能选择</strong></p><p id="995e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在像这样的数据集上执行监督学习时，一项重要任务是调查这些因素对最终预测性能的影响程度。通过提取仅在几个关键特征和目标变量之间的关系，我们可以随后消除噪声。原始数据集中有13个可用的要素，我们希望将它们减少一半。凭直觉，我们会选择年龄、教育程度、祖国、职业和每周工作时间等因素，因为它们通常是个人财务状况的最佳指标。然后，我们通过使用AdaBoostClassifier分类器绘制下图来检查我们的逻辑的准确性</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ng"><img src="../Images/838d814d7bf261932cc900b8de32b4dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*hO712UffAJ_U0TehLUX-Zw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="9f62" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们的直觉是部分准确的，因为年龄；每周工作时间和教育对一个工作者的经济状况有很大的影响。令人惊讶的是，我们未能确定“资本收益”和“资本损失”的重要性。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nh"><img src="../Images/8b89fadc1415b63996137cdfe25f93ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8-Oj4tqU6PCRcO_qTPUQWg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="2319" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在重新执行随机森林和逻辑回归后，我们见证了在两个预测模型中，与原始数据集相比，精简数据的准确性和F值都有所下降。考虑到在缩减数据集上对原始模型进行评估时获得的指标，最佳选择是继续使用原始数据集版本，因为它们产生了准确性和F分数的良好组合。</p><p id="0848" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> K倍交叉验证和网格搜索</strong></p><p id="c2de" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这一步中，我们使用交叉验证(旋转估计)方法来验证模型的技术，方法是将数据集分割成许多折叠，并对其结果进行交叉测试。(Brownlee，2019)‘estimator’参数表示您用来拟合模型的对象(随机森林和逻辑回归的分类器)，而‘cv’验证您想要将训练集分成多少个折叠(通常为10)。然后，我们基于10个小数据集样本计算10个不同准确度的均值和标准差，并相互比较。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ni"><img src="../Images/1e617e03396d25c460a377f01765bd3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*KefUCvdJjQckD63PXZH-4g.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ni"><img src="../Images/57517c3f04a6bf8b3385b3e374d57ff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*sn5G5cJ0Nv7OxWp25qosgg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="312d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">交叉验证后，这两个模型的均值和标准差是相同的。可以肯定地说，我们在这两个模型中选择哪一个都不会有太大的差别。因此，我们可以只在随机森林模型上执行网格搜索，以选择能够产生最高可能精度的最佳参数。“n_estimators”有10、30、100、300之间的选项，而“criterion”有“熵”和“基尼”模型之间的选项</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nj"><img src="../Images/192359e179df0bb1e25985b1e0656dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eK_aTUSIlJC0YfgSmQ9Msg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">作者图片</figcaption></figure><p id="f46b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">最后，可以产生0.844准确度分数的最佳模型是‘准则’=‘熵’，‘n _估计量’=‘300’的随机森林</p><h1 id="02ad" class="lp kp hi bd kq lq lr ls ku lt lu lv ky io lw ip lb ir lx is le iu ly iv lh lz bi translated"><strong class="ak">四/结论</strong></h1><p id="b9c0" class="pw-post-body-paragraph jn jo hi jp b jq lj ij js jt lk im jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated">这个项目让我们不仅可以准确预测每个人的年收入，还可以了解每个模型在分类时的优势和劣势。建议未来的研究人员进一步改进模型，并根据问题的需要进行相应的调整</p><p id="62c6" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">Github:</strong><a class="ae nk" href="https://github.com/Lukastuong123/Python-Projects/tree/master/Project-%20Finding%20Annual%20Income%20(Python-%20Classification)" rel="noopener ugc nofollow" target="_blank">https://Github . com/lukastuong 123/Python-Projects/tree/master/Project-% 20 finding % 20 annual % 20 income % 20(Python-% 20 classification)</a></p><h1 id="97bb" class="lp kp hi bd kq lq lr ls ku lt lu lv ky io lw ip lb ir lx is le iu ly iv lh lz bi translated"><strong class="ak">参考&amp;来源:</strong></h1><p id="a8a9" class="pw-post-body-paragraph jn jo hi jp b jq lj ij js jt lk im jv jw ll jy jz ka lm kc kd ke ln kg kh ki hb bi translated">布朗利，J.  (2019)。k-fold交叉验证的简单介绍。从https://machinelearningmastery.com/k-fold-cross-validation/<a class="ae nk" href="https://machinelearningmastery.com/k-fold-cross-validation/" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="3d39" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">极客forgeeks。</strong> (2019年4月17日)。决策树。从https://www.geeksforgeeks.org/decision-tree/<a class="ae nk" href="https://www.geeksforgeeks.org/decision-tree/" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="42da" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">科哈维，R. </strong> (1996)。提高朴素贝叶斯分类器的精度:决策树混合。<em class="kj"> KDD'96:第二届知识发现与数据挖掘国际会议论文集</em>，<em class="kj"> 8 </em>，202–207。从https://www.aaai.org/Papers/KDD/1996/KDD96-033.pd<a class="ae nk" href="https://www.aaai.org/Papers/KDD/1996/KDD96-033.pd" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="837a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">库马尔，N. </strong> (2019)。机器学习中KNN算法的优缺点。检索自<a class="ae nk" href="http://theprofessionalspoint.blogspot.com/2019/02/advantages-and-disadvantages-of-knn.html" rel="noopener ugc nofollow" target="_blank">http://the professionals point . blogspot . com/2019/02/benefits-and-missions-of-KNN . html</a></p><p id="bffd" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> Singletary，M. </strong> (2020)。还在等你的刺激支票吗？你必须在周三晚上12点之前把你的银行信息交给国税局。从<a class="ae nk" href="https://www.washingtonpost.com/gdpr-consent/?next_url=https%3a%2f%2fwww.washingtonpost.com%2fbusiness%2f2020%2f05%2f11%2fstill-waiting-your-stimulus-check-you-have-until-12-pm-wednesday-give-irs-your-bank-information%2f" rel="noopener ugc nofollow" target="_blank">https://www.washingtonpost.com/gdpr-consent/?取回next _ URL = https % 3a % 2f % 2fwww . Washington post . com % 2f business % 2f 2020% 2f 05% 2f 11% 2f等待你的刺激计划-检查你所拥有的直到下午12点-星期三-给国税局你的银行信息%2f </a></p><p id="6eb3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">https://archive.ics.uci.edu/ml/datasets/Census+Income<a class="ae nk" href="https://archive.ics.uci.edu/ml/datasets/Census+Income" rel="noopener ugc nofollow" target="_blank">UCI</a></strong>机器学习资源库</p></div></div>    
</body>
</html>