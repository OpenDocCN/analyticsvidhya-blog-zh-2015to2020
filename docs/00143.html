<html>
<head>
<title>A Step-by-Step Introduction to the Basic Object Detection Algorithms (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基本对象检测算法的逐步介绍(第1部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1-c61bebaf1038?source=collection_archive---------1-----------------------#2018-10-11">https://medium.com/analytics-vidhya/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1-c61bebaf1038?source=collection_archive---------1-----------------------#2018-10-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="54b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你花了多少时间在一个又脏又乱的房子里寻找丢失的房间钥匙？它发生在我们最优秀的人身上，至今仍是一种令人难以置信的沮丧经历。但是如果一个简单的计算机算法可以在几毫秒内定位你的钥匙呢？</p><p id="cb7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是物体检测算法的威力。虽然这是一个简单的例子，但物体检测的应用跨越多个不同的行业，从全天候监控到智能城市中的实时车辆检测。简而言之，这些都是强大的深度学习算法。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/a71bb2392acea2f4de98fe86b9af6c6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*LEah2NqnDsdBtsWl.jpg"/></div></figure><p id="5738" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我们将更深入地研究各种可用于物体检测的算法。我们将从属于RCNN家族的算法开始，即RCNN、快速RCNN和更快RCNN。在本系列即将发布的文章中，我们将讨论更高级的算法，如YOLO、SSD等。</p><p id="748f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jl">我鼓励你仔细阅读这篇关于物体检测的</em> <a class="ae jm" href="https://www.analyticsvidhya.com/blog/2018/06/understanding-building-object-detection-model-python/" rel="noopener ugc nofollow" target="_blank"> <em class="jl">的前一篇文章</em> </a> <em class="jl">，在这篇文章中，我们介绍了这一奇妙技术的基础知识，并向你展示了使用OpenAI库在Python中的实现。</em></p><p id="e842" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们开始吧！</p><h1 id="de45" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">目录</h1><ol class=""><li id="9776" class="kl km hi ih b ii kn im ko iq kp iu kq iy kr jc ks kt ku kv bi translated">解决对象检测任务的简单方法(使用深度学习)</li><li id="5c5e" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">了解基于区域的卷积神经网络<br/> 1。RCNN <br/> 2的直觉。RCNN的问题</li><li id="100a" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">了解快速RCNN <br/> 1。快速RCNN <br/> 2的直觉。快速RCNN的问题</li><li id="16aa" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">了解更快的RCNN <br/> 1。直觉更快RCNN <br/> 2。快速RCNN的问题</li><li id="a0b8" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">涵盖的算法概述</li></ol><h1 id="b71d" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">1.解决对象检测任务的简单方法(使用深度学习)</h1><p id="7160" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">下图是一个常见的例子，说明了对象检测算法是如何工作的。图像中的每一个物体，从一个人到一只风筝，都被精确定位和识别。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es le"><img src="../Images/9c969c43fd400baf965bd11ad517387b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XMA6JND3CR0oGWBs.png"/></div></div></figure><p id="a5d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从最简单的深度学习方法开始，这是一种广泛使用的方法，用于检测图像中的对象——卷积神经网络或CNN。如果你对CNN的了解有点生疏，我推荐你先通读一下<a class="ae jm" href="https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><p id="397a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是我将简要地为你总结一个CNN的内部运作。请看下图:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lj"><img src="../Images/500c8849612156bb5f4f68a56e980429.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PoXHrsc2OzmBrWTk.png"/></div></div></figure><p id="7032" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将图像传递到网络，然后通过各种卷积和池层发送。最后，我们以对象的类的形式得到输出。相当简单，不是吗？</p><p id="c025" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每个输入图像，我们得到一个相应的类作为输出。我们可以使用这种技术来检测图像中的各种对象吗？是的，我们可以！让我们看看如何使用CNN解决一般的对象检测问题。</p><p id="211f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.首先，我们将一幅图像作为输入:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lk"><img src="../Images/fe03de0e6e5d144f17779a053a44a54e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rWXg0P5X5cPA-uZu.png"/></div></div></figure><p id="36a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.然后我们把图像分成不同的区域:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es ll"><img src="../Images/d393933086513896e3585ba15dbfd844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CY765xRHC09QVjRO.png"/></div></div></figure><p id="43a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.然后，我们将每个区域视为一个单独的图像。</p><p id="3a54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.把这些区域(图像)全部传给CNN，分门别类。</p><p id="0e7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.一旦我们将每个区域划分到其相应的类中，我们就可以组合所有这些区域以获得具有检测到的对象的原始图像:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lk"><img src="../Images/48a1ef1dde88a94b77338559847058b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uG9u20fbAJRq8BZd.png"/></div></div></figure><p id="ca14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用这种方法的问题是图像中的对象可能具有不同的纵横比和空间位置。例如，在某些情况下，对象可能覆盖图像的大部分，而在其他情况下，对象可能仅覆盖图像的一小部分。对象的形状也可能不同(这在现实生活中经常发生)。</p><p id="aac2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于这些因素，我们将需要非常大量的区域，导致大量的计算时间。因此，为了解决这个问题并减少区域的数量，我们可以使用基于区域的CNN，它使用一种提议方法来选择区域。让我们来了解一下这个以地区为基础的CNN能为我们做些什么。</p><h1 id="9690" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">2.理解基于区域的卷积神经网络</h1><h1 id="2ee1" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">2.1 RCNN的直觉</h1><p id="ea4a" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">RCNN算法不是在大量区域上工作，而是在图像中提出一堆盒子，并检查这些盒子中是否包含任何对象。RCNN <strong class="ih hj">使用选择性搜索从图像中提取这些框(这些框称为区域)。</strong></p><p id="13bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们首先了解什么是选择性搜索，以及它如何识别不同的区域。基本上有四个区域形成一个物体:不同的比例，颜色，纹理和外壳。选择性搜索识别图像中的这些模式，并基于此提出各种区域。以下是选择性搜索工作原理的简要概述:</p><ul class=""><li id="6587" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">它首先接受一幅图像作为输入:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/f06f816019a0255bd78f6de46cbd31f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/0*OurZzhlxQ8NNV7vQ.png"/></div></figure><ul class=""><li id="90ac" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">然后，它生成初始子分割，以便我们从该图像中获得多个区域:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lr"><img src="../Images/48449afef30bdfa37c7b8994c536606b.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/0*VAiWTAXVVdNwgvw-.png"/></div></figure><ul class=""><li id="6688" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">该技术然后组合相似的区域以形成更大的区域(基于颜色相似性、纹理相似性、尺寸相似性和形状兼容性):</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/931797a89b2ed5f110b9616e316dd832.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/0*E56c2FrelmESz-5C.png"/></div></figure><ul class=""><li id="291f" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">最后，这些区域然后产生最终的对象位置(感兴趣区域)。</li></ul><p id="8ff6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是RCNN检测对象所遵循的步骤的简要总结:</p><ol class=""><li id="7437" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc ks kt ku kv bi translated">我们首先采用一个预先训练好的卷积神经网络。</li><li id="3e64" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">然后，这个模型被重新训练。我们根据需要检测的类别数量来训练网络的最后一层。</li><li id="153a" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">第三步是获取每幅图像的感兴趣区域。然后，我们对所有这些区域进行整形，使它们能够匹配CNN的输入大小。</li><li id="594e" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">在得到区域后，我们训练SVM对物体和背景进行分类。每堂课，我们训练一个二进制SVM。</li><li id="2944" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">最后，我们训练一个线性回归模型来为图像中每个识别的对象生成更紧密的边界框。</li></ol><p id="1eb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可能会通过一个视觉示例<em class="jl">对以上步骤有更好的理解(下面所示示例的图像摘自</em> <a class="ae jm" href="http://www.robots.ox.ac.uk/~tvg/publications/talks/fast-rcnn-slides.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="jl">本文</em> </a> <em class="jl">)。</em>那我们就来一个吧！</p><ul class=""><li id="2fa3" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">首先，将一幅图像作为输入:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lt"><img src="../Images/d83639146872313defedd9fe19524afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/0*4wiGFK68mk8k-8FC.png"/></div></figure><ul class=""><li id="b266" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">然后，我们使用某种提议方法(例如，如上所示的选择性搜索)来获得感兴趣区域(ROI):</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lu"><img src="../Images/a3f8b6d6c0cdbf62f6c0e46117e6ed0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sYc2VDeYYpuiptq-.png"/></div></div></figure><ul class=""><li id="a2eb" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">然后，所有这些区域都按照CNN的输入进行整形，并且每个区域都被传递到ConvNet:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lv"><img src="../Images/22037df9851879b57ad8f722e8c35ded.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f2RectzkPK_ZSwOU.png"/></div></div></figure><ul class=""><li id="6397" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">CNN然后提取每个区域的特征，并且使用支持向量机将这些区域分成不同的类别:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lw"><img src="../Images/98a260f7106496ca1d6fe969707502eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*p7tvu6z9zk30f_Sl.png"/></div></div></figure><ul class=""><li id="e44d" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">最后，使用边界框回归(<em class="jl"> Bbox reg </em>)来预测每个识别区域的边界框:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lx"><img src="../Images/12428f3d214eb66964e8d4d0c7b0500f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/0*1lkPrJ0wmuKDDWt8.png"/></div></figure><p id="b7e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简而言之，这就是RCNN如何帮助我们检测物体。</p><h1 id="343b" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">2.2 RCNN的问题</h1><p id="f30a" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">到目前为止，我们已经看到了RCNN如何有助于对象检测。但是这种技术有其自身的局限性。由于以下步骤，训练RCNN模型既昂贵又缓慢:</p><ul class=""><li id="58a1" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">基于选择性搜索为每幅图像提取2000个区域</li><li id="a392" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc lp kt ku kv bi translated">使用CNN提取每个图像区域的特征。假设我们有N个图像，那么CNN特征的数量将是N * 2,000</li><li id="bbdb" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc lp kt ku kv bi translated">使用RCNN的目标检测的整个过程有三个模型:<br/> 1 .CNN进行特征提取<br/> 2。用于识别物体的线性SVM分类器<br/> 3。收紧包围盒的回归模型。</li></ul><p id="b1f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所有这些过程结合起来使得RCNN非常慢。对每个新图像进行预测大约需要40-50秒，这基本上使得模型变得繁琐，并且在面对巨大数据集时几乎不可能构建。</p><p id="f601" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有一个好消息，我们有另一种对象检测技术，它修复了我们在RCNN中看到的大多数限制。</p><h1 id="be59" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">3.了解快速RCNN</h1><h1 id="7368" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">3.1快速RCNN的直觉</h1><p id="c713" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们还能做什么来减少RCNN算法通常需要的计算时间？我们可以对每幅图像只运行一次CNN，而不是对每幅图像运行2000次，并获得所有感兴趣的区域(包含一些对象的区域)。</p><p id="a92e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RCNN的作者Ross Girshick提出了这样一个想法，即每幅图像只运行一次CNN，然后找到一种方法在2000个区域之间共享计算。在快速RCNN中，我们将输入图像馈送到CNN，CNN进而生成卷积特征图。使用这些图，提取提案的区域。然后，我们使用RoI pooling层将所有建议的区域重新调整为固定的大小，以便将其输入到完全连接的网络中。</p><p id="a139" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们将它分解成几个步骤来简化概念:</p><ol class=""><li id="381d" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc ks kt ku kv bi translated">与前两种技术一样，我们将图像作为输入。</li><li id="afec" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">该图像被传递到ConvNet，conv net进而生成感兴趣的区域。</li><li id="2bed" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">RoI pooling层应用于所有这些区域，以根据ConvNet的输入对它们进行整形。然后，每个区域被传递给一个完全连接的网络。</li><li id="e494" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">在全连接网络的顶部使用softmax层来输出类。除了softmax图层之外，线性回归图层也被并行用于输出预测类的边界框坐标。</li></ol><p id="46bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，快速RCNN使用单个模型，而不是使用三个不同的模型(如RCNN ),该模型从区域中提取特征，将它们分成不同的类，并同时返回已识别类的边界框。</p><p id="1cce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了进一步分解，我将把每一步都形象化，为解释增加一个实用的角度。</p><ul class=""><li id="806f" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">我们遵循现在众所周知的将图像作为输入的步骤:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lt"><img src="../Images/57745503290ee123ebecef941634e9af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/0*eUT5vX4Qk7R-oC3P.png"/></div></figure><ul class=""><li id="ac79" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">该图像被传递给ConvNet，conv net相应地返回感兴趣的区域:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es ly"><img src="../Images/ba71aecaa76d266b893c41b349c20224.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8Z-Sk4z5p1Zj0fYF.png"/></div></div></figure><ul class=""><li id="2c3e" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">然后，我们对提取的感兴趣区域应用RoI pooling层，以确保所有区域的大小相同:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lz"><img src="../Images/54b33c7d0760f0cd4158744c57039cba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dConP3GVT1HSNtHv.png"/></div></div></figure><ul class=""><li id="4d18" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">最后，这些区域被传递到一个完全连接的网络，该网络对它们进行分类，并同时使用softmax和线性回归图层返回边界框:</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es ma"><img src="../Images/c1be499af5d03cd5e73469dc1bbc4ad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*59EyI_ud8767w20l.png"/></div></div></figure><p id="ba6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是RCNN解决RCNN的两个主要问题的速度，即，将每个图像的一个而不是2，000个区域传递到ConvNet，以及使用一个而不是三个不同的模型来提取特征、分类和生成边界框。</p><h1 id="cc14" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">3.2快速RCNN的问题</h1><p id="2c2f" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">但是即使快速RCNN也有某些问题区域。它还使用选择性搜索作为查找感兴趣区域的建议方法，这是一个缓慢且耗时的过程。每幅图像大约需要2秒来检测对象，这比RCNN好得多。但是当我们考虑大型真实数据集时，即使快速的RCNN看起来也不再那么快了。</p><p id="f14e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是还有另一种物体检测算法胜过快速RCNN。我觉得你不会对它的名字感到惊讶。</p><h1 id="8209" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">4.了解更快的RCNN</h1><h1 id="58ac" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">4.1.更快RCNN的直觉</h1><p id="ca34" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">快速RCNN是快速RCNN的修改版本。它们之间的主要区别是，快速RCNN使用选择性搜索来生成感兴趣的区域，而快速RCNN使用“区域提议网络”，也称为RPN。RPN将图像特征图作为输入，并生成一组对象提议，每个提议都有一个对象性分数作为输出。</p><p id="04d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在更快的RCNN方法中，通常遵循以下步骤:</p><ol class=""><li id="71db" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc ks kt ku kv bi translated">我们将一幅图像作为输入，并将其传递给ConvNet，后者返回该图像的特征图。</li><li id="7911" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">在这些特征图上应用区域建议网络。这将返回对象建议及其客观性分数。</li><li id="b671" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">投资回报池层应用于这些建议，将所有建议缩小到相同的大小。</li><li id="6090" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">最后，建议被传递到一个完全连接的层，该层在其顶部具有一个softmax层和一个线性回归层，以分类和输出对象的边界框。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mb"><img src="../Images/4233c0197cdb37cd6de1401500c97003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/0*8VyYLAOJu-4svgje.png"/></div></figure><p id="1b84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我简单解释一下这个区域提案网络(RPN)实际上是如何工作的。</p><p id="bd42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，快速RCNN从CNN获取特征地图，并将它们传递给区域提议网络。RPN在这些特征图上使用滑动窗口，并且在每个窗口，它生成不同形状和大小的<em class="jl"> k </em>锚框:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mc"><img src="../Images/c4d8b922fab8a0e9a7b97a0652194789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*B6bR3oFkwt4odqb5.png"/></div></div></figure><p id="c1cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">锚定框是固定大小的边界框，放置在整个图像中，具有不同的形状和大小。对于每个主播，RPN预测两件事:</p><ul class=""><li id="b203" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">第一个是锚是对象的概率(它不考虑对象属于哪个类)</li><li id="d8c0" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc lp kt ku kv bi translated">第二个是边界框回归器，用于调整锚点以更好地适应对象</li></ul><p id="8f47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在有不同形状和大小的边界框，它们被传递到RoI合并层。现在，在RPN步骤之后，有可能存在没有被分配类别的提议。我们可以对每个提议进行裁剪，使每个提议都包含一个对象。这就是RoI pooling层的作用。它为每个锚点提取固定大小的特征图:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es md"><img src="../Images/389cc5b09bf7854c5c620b85e6cb3ce7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bHAIsI5aZwxvykIj.png"/></div></div></figure><p id="8d25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，这些特征地图被传递到具有softmax和线性回归层的全连接层。它最终对对象进行分类，并预测所识别对象的边界框。</p><h1 id="ecae" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">4.2更快RCNN的问题</h1><p id="787a" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">到目前为止，我们讨论的所有对象检测算法都使用区域来识别对象。该网络不会一次查看完整的图像，而是依次关注图像的各个部分。这造成了两个问题:</p><ul class=""><li id="b494" class="kl km hi ih b ii ij im in iq lm iu ln iy lo jc lp kt ku kv bi translated">该算法需要多次通过单个图像来提取所有对象</li><li id="c5ed" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc lp kt ku kv bi translated">由于不同的系统一个接一个地工作，未来系统的性能取决于先前系统的性能</li></ul><h1 id="617d" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">5.涵盖的算法概述</h1><p id="0d48" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">下表很好地总结了我们在本文中涉及的所有算法。我建议下次你在进行物体探测挑战的时候把它放在手边！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es me"><img src="../Images/04bbf393beffc97b37fa0761b27656df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*VJLL7CMhCzpF3bqObL7j0g.png"/></div></figure><h1 id="7e72" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结束注释</h1><p id="3d09" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">物体检测是一个迷人的领域，在商业和研究应用中有着巨大的吸引力。由于现代硬件和计算资源的进步，这一领域的突破一直是快速和突破性的。</p><p id="8b40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章只是我们的目标检测之旅的开始。在本系列的下一篇文章中，我们将会遇到现代的物体检测算法，比如YOLO和RetinaNet。敬请关注！</p><p id="073d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我总是很感谢对我的文章的任何反馈或建议，所以请随时在下面的评论部分与我联系。</p></div><div class="ab cl mf mg gp mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="hb hc hd he hf"><p id="5ed0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jl">原载于2018年10月11日</em><a class="ae jm" href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/" rel="noopener ugc nofollow" target="_blank"><em class="jl">【www.analyticsvidhya.com】</em></a><em class="jl">。</em></p></div></div>    
</body>
</html>