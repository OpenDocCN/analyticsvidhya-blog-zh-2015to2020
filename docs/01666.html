<html>
<head>
<title>Object Detection with YOLO</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO物体检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/object-detection-with-yolo-d7f3fa788e0a?source=collection_archive---------6-----------------------#2019-11-07">https://medium.com/analytics-vidhya/object-detection-with-yolo-d7f3fa788e0a?source=collection_archive---------6-----------------------#2019-11-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/97a5eb217335778c992c927ba85f48fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V3tRoQlmKLVDeN3uItXbUA.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">黄金视觉</figcaption></figure><div class=""/><p id="14cc" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae js" href="https://en.wikipedia.org/wiki/Object_detection" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hy">物体检测</strong> </a>是与<a class="ae js" href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>和<a class="ae js" href="https://en.wikipedia.org/wiki/Image_processing" rel="noopener ugc nofollow" target="_blank">图像处理</a>相关的计算机技术，处理在数字图像和视频中检测某一类语义物体(如人、建筑物或汽车)的实例。</p><p id="14bd" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">速度、识别和完美</strong>是检测和处理图像、视频或直播流的主要标准。在任何时候，所有这些标准都不能满足。最多，两个可能的标准可以给出最大的好处。</p><p id="1452" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">约洛夫3等:</strong></p><ul class=""><li id="cbf7" class="jt ju hx iw b ix iy jb jc jf jv jj jw jn jx jr jy jz ka kb bi translated">R- CNN、快速R-CNN和更快R-CNN</li><li id="c1d7" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">单触发检测器(SSDs)</li></ul><p id="074f" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">r-CNN是首批基于深度学习的对象检测器之一，具有准确的对象检测和语义分割等功能。然而，R-CNN是精确的并且非常慢(每秒5帧)，因此不能用于实时或接近实时的物体检测。</p><p id="23c3" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">快速R-CNN通过外部区域提议算法提高了处理的准确性和时间。</p><p id="9177" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">快速R-CNN实现的区域提议网络。这完全是CNN和对象边界/锚盒的概念是用分数和类标签实现的。狗周围的黄线和人周围的粉线是边界框。边界框顶部的标签是定义图像标签或对象名称的类别标签。</p><figure class="ki kj kk kl fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kh"><img src="../Images/e89acf4ff735f3cf6091e70d51b70ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xecUJeVcx9q3QXEt2G2bBA.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">享受汽车之旅的狗狗。</figcaption></figure><p id="9b55" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">Yolo是什么？为什么是Yolo？</strong></p><p id="41b4" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">YOLO是一种基于卷积神经网络的快速目标检测算法。</p><p id="633d" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了提高对象检测器的速度，单次检测器(SSDs)和YOLO都使用一级检测器策略，其中所有东西都在一次通过中。该算法基于回归，算法同时学习包围盒坐标和相应的类别标签概率。</p><p id="592f" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">单次检测器没有委托区域建议网络，并且在一次通过中直接从特征地图预测边界框和类。</p><p id="5d34" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">Yolo如何工作:</strong></p><p id="d6a4" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">YOLO将图像分成13×13的网格(左图)。每个单元能够预测5个边界框，并且每个单元还预测一个类别。</p><p id="5766" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，总共13 * 13 * 5 = 845个边界框(中上图)。</p><p id="fff2" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">每个边界框都有一个置信度得分，它表示边界框的确定性。置信度得分表明盒子的形状是好是坏(中上/下图)。</p><p id="236f" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">置信度得分和类别预测被合并以导出最终得分，该最终得分告诉包含特定类型的对象的边界框相对于标记和训练的权重被测量的概率。例如，左边的蓝框是75%，它确认对象是“狗”:</p><figure class="ki kj kk kl fd hk er es paragraph-image"><div class="er es km"><img src="../Images/22d3bc337ba4e4d13d986d0204f5917f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*CYTDLg54ol-NpBOnrhFo2A.jpeg"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">https://arxiv.org/pdf/1506.02640.pdf YOLO赛段的图示</figcaption></figure><p id="3f31" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">图像的高分区域被认为是检测到的(阈值大于30%)</p><p id="cdcd" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下图描绘了YOLO V3的整体<strong class="iw hy">架构</strong>:</p><figure class="ki kj kk kl fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kn"><img src="../Images/e8dd1330ea9b43acd427ce7c7e656ffc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WUmwgLWUqMDflME0yJxrjg.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">YOLO网络架构</figcaption></figure><figure class="ki kj kk kl fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ko"><img src="../Images/4553e6790cb521fc51c8023c4e78d4f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-5Vs_BQb0nORCoE_61YBAw.jpeg"/></div></div></figure><p id="84cb" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在该示例中，神经网络仅使用标准层类型:具有3×3内核的卷积和具有2×2内核的最大池。</p><p id="d3a9" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后一个卷积层具有1×1内核，用于将数据简化为13×13×125的形状。</p><p id="18f6" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，我们发现每个网格单元有125个通道。这125个通道包含用于边界框和类别预测的数据。每个网格单元预测5个边界框，一个边界框由25个数据元素描述:</p><ul class=""><li id="5ab8" class="jt ju hx iw b ix iy jb jc jf jv jj jw jn jx jr jy jz ka kb bi translated">边界框矩形的x，y，宽度，高度</li><li id="ba30" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">置信度得分</li><li id="ce0e" class="jt ju hx iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">类别的概率分布</li></ul><p id="b88d" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">输入图像(416×416像素)以单输入方式被馈送到卷积网络。</p><p id="ec3f" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">输出从另一端以13×13×125张量的形式输出，描述网格单元的边界框。30%以下的分数全部去掉。</p><p id="0b38" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy"> YOLO积木:</strong></p><p id="4f76" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">darknet——用C和CUDA编写的开源框架</p><p id="8f5e" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy"> YOLO实现:</strong></p><p id="8994" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下面的代码从命令行调用YOLO:</p><p id="7269" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">shiv @ shiv-VirtualBox:~/darknet $。/darknet detect CFG/yolov 3 . CFG yolov 3 . weights data/dog auto 2 . jpg</p><p id="2b88" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下面是自信的输出:</p><p id="9799" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从yolov3.weights加载砝码…完成！<br/>data/dog auto 2 . jpg:26.626181秒预测。<br/>狗:99% <br/>狗:80% <br/>人:98 <a class="ae js" href="https://www.facebook.com/jayeeta.it" rel="noopener ugc nofollow" target="_blank"> % </a></p><figure class="ki kj kk kl fd hk er es paragraph-image"><div class="er es kp"><img src="../Images/f994e06cb6ba8308ba68835e54e12ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*H_rKPppGzHzNeg0hHUgtrw.jpeg"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated"><a class="ae js" href="https://www.facebook.com/jayeeta.it" rel="noopener ugc nofollow" target="_blank">集体合影</a></figcaption></figure><figure class="ki kj kk kl fd hk er es paragraph-image"><div class="er es kq"><img src="../Images/f52b0dbaeafe57f7b3e28d837e12751e.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*pl--pj4Lf5TNIr-W7TLbig.jpeg"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">单人形象</figcaption></figure><p id="1e54" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">稍后，随着CUDA和OpenCV的实施，这将升级为成熟的代码。这将有助于处理视频以及直播流。</p><p id="51f5" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">重要统计:</strong></p><p id="7f28" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="kr"> YOLOv1 </em>在GPU上进行<strong class="iw hy"> 45 FPS </strong>的实时物体检测。</p><p id="778c" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="kr">快YOLO号称在一个GPU上实现</em><strong class="iw hy"><em class="kr"/></strong><em class="kr">155 FPS。</em></p><p id="e6a5" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae js" href="https://arxiv.org/abs/1612.08242" rel="noopener ugc nofollow" target="_blank"> <em class="kr"> YOLO9000: </em> </a>(即YOLOv2)能够以16%的平均精度检测超过9000个物体检测器，并在156个标签上训练。</p><p id="e0b3" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">YOLOv3在包含80个标签的COCO数据集上进行训练</p><p id="fb51" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">限制:</strong></p><p id="5096" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">它并不总是能很好地处理小物体。</p><p id="12bf" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">参考资料:</p><p id="9e5d" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">原始研究论文:</p><div class="hh hi ez fb hj ks"><a href="https://arxiv.org/abs/1506.02640" rel="noopener  ugc nofollow" target="_blank"><div class="kt ab dw"><div class="ku ab kv cl cj kw"><h2 class="bd hy fi z dy kx ea eb ky ed ef hw bi translated">你只看一次:统一的，实时的对象检测</h2><div class="kz l"><h3 class="bd b fi z dy kx ea eb ky ed ef dx translated">我们提出了YOLO，一种新的目标检测方法。先前关于目标检测的工作将分类器重新用于执行…</h3></div><div class="la l"><p class="bd b fp z dy kx ea eb ky ed ef dx translated">arxiv.org</p></div></div></div></a></div><div class="hh hi ez fb hj ks"><a href="https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/" rel="noopener  ugc nofollow" target="_blank"><div class="kt ab dw"><div class="ku ab kv cl cj kw"><h2 class="bd hy fi z dy kx ea eb ky ed ef hw bi translated">基于OpenCV - PyImageSearch的YOLO目标检测</h2><div class="kz l"><h3 class="bd b fi z dy kx ea eb ky ed ef dx translated">在本教程中，您将学习如何使用YOLO对象检测器来检测图像和视频流中的对象…</h3></div><div class="la l"><p class="bd b fp z dy kx ea eb ky ed ef dx translated">www.pyimagesearch.com</p></div></div><div class="lb l"><div class="lc l ld le lf lb lg hp ks"/></div></div></a></div></div></div>    
</body>
</html>