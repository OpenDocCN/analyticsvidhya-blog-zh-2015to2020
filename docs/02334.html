<html>
<head>
<title>Neural Nets on Drugs*</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">药物神经网络*</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/neural-nets-on-drugs-7cef2ac16726?source=collection_archive---------19-----------------------#2019-12-11">https://medium.com/analytics-vidhya/neural-nets-on-drugs-7cef2ac16726?source=collection_archive---------19-----------------------#2019-12-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c06e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">*自我报告的吸毒经历</p><p id="b2a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">加勒特·考夫曼和维克多·科莱蒙</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="3ec3" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated"><strong class="ak">简介</strong></h1><p id="4b80" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在我们默认的意识模式下，人类思维的能力远远超过我们在任何给定时刻所意识到的。尽管在过去的几十年里，关于迷幻物质及其引发的意识扩展状态的研究一直在争论不休。对于我们的项目，我们想探索一个神经网络系统是否可以为扩展物质的精神现象学提供新的见解。我们希望<strong class="ih hj">使用从用户体验中训练出来的顺序神经网络模型</strong>生成文本，以便为一些经典迷幻剂创造一种‘通用’版本的体验。我们希望从这些文本中找到每种物质独特的语音模式，以及生成的文本是否能捕捉到用户体验的一般化版本。</p><p id="ae0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是我们从哪里获得数据来使用呢？自20世纪50年代以来，研究人员一直在收集少量物质的trip账户，包括但不限于LSD、MDMA、裸盖菇素和大麻。这些经历数量很少，也很少被数字化。我们找不到一个简洁的数据集来组织这些经验，以便数据科学家轻松访问。虽然这令人失望，但我们找到了一个看起来很有希望的来源。</p><h1 id="97e4" class="jl jm hi bd jn jo ko jq jr js kp ju jv jw kq jy jz ka kr kc kd ke ks kg kh ki bi translated"><strong class="ak">数据:Erowid </strong></h1><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es kt"><img src="../Images/7af537d61ba643c40713667198ab3209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ssYjSstQGWum5cJ8doPSAA.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">Erowid数据库的主页</figcaption></figure><p id="f5d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Erowid数据库包含了几乎所有人类曾经摄入的化学物质的信息。这个网站(<a class="ae lj" href="http://www.erowid.org/" rel="noopener ugc nofollow" target="_blank">www.erowid.org</a>)上有丰富的信息，从1985年到现在不断更新，我们兴奋地发现，对于数据库中列出的每种药物，都有一个页面，人们可以匿名地自我报告他们的药物经历。然后我们决定，我们的第一步将是构建一个scraper，它可以将药物的名称作为输入，并返回给我们来自每个没有混合药物的用户的文本。然后，我们将我们的数据组织到一些经典精神药物的物质特定目录中:<strong class="ih hj">大麻、裸盖菇素(蘑菇)、摇头丸和迷幻药</strong>。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lk"><img src="../Images/4e760fef528f484e1d5b7c8c36d06a69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NnPzyLCTpxMRlTE_vjWLIQ.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">Erowid上的“体验”页面示例</figcaption></figure><h1 id="fc76" class="jl jm hi bd jn jo ko jq jr js kp ju jv jw kq jy jz ka kr kc kd ke ks kg kh ki bi translated"><strong class="ak">模型行程安排:文本生成</strong></h1><p id="5bac" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">我们的下一步是为我们想要研究的每种药物创建一个文本生成器模型。为了做到这一点，我们训练了一个单层，<strong class="ih hj"> 128节点LSTM </strong>，为每个模型的<strong class="ih hj"> 50个时期使用一键字符编码。我们的训练集包含<strong class="ih hj">4000–20000个字符</strong>。我们认为应该从一个相对简单的模型开始，因为我们使用的四个模型中的每一个都需要两个小时以上的培训。我们获得了平均损失为1.2的<strong class="ih hj">和大约60%的精度</strong>。虽然我们的模型不需要学习大量的文本格式，但每个神经网络都开发了一个独特的词汇，用于Erowid药物体验。文本输出既深刻又有趣(见下文)。现在我们有了输出文本，我们必须决定如何处理新数据。虽然数据可能在语法上不美观，但我们认为分类器模型可以量化文本生成性能。<em class="jd">如果分类器可以根据文本描述的药物准确地对文本进行分类，那么我们的文本模型学习的语言将是该药物独有的，因此表明我们的模型已经学习了通用特征</em>。</strong></p><pre class="ku kv kw kx fd ll lm ln lo aw lp bi"><span id="5955" class="lq jm hi lm b fi lr ls l lt lu">model = Sequential()<br/>model.add(LSTM(128, input_shape=(seqlen, len(chars)),      <br/>    return_sequences=True))<br/>model.add(Dense(len(chars), activation='softmax'))</span><span id="ca8a" class="lq jm hi lm b fi lv ls l lt lu">#################################################################<br/>#step from training</span><span id="c64b" class="lq jm hi lm b fi lv ls l lt lu">----- Generating text after Epoch: 25<br/>----- diversity: 0.5<br/>----- Generating with seed: "ad in a long time. This feeling lasted f"<br/>ad in a long time. This feeling lasted for the fact that I was all the people was a strong started to see the morning I was taken so continued and we started to get up and some of the concept and constant I was about to see the trees and the woods of the trip, that was a small or so fully and the similar mind perhaps that was so straight that seemed to a parents was still so decided to do the shrooms that was only a small briefly seeing<br/>Epoch 27/50<br/>62585/62585 [==============================] - 97s 2ms/step - loss: 1.2711 - categorical_crossentropy: 1.2711 - accuracy: 0.6151</span></pre><h1 id="fd12" class="jl jm hi bd jn jo ko jq jr js kp ju jv jw kq jy jz ka kr kc kd ke ks kg kh ki bi translated">生成模型性能</h1><p id="e67d" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">这里是我们的四个模型在50个时期后的性能统计。</p><h2 id="c2ae" class="lq jm hi bd jn lw lx ly jr lz ma mb jv iq mc md jz iu me mf kd iy mg mh kh mi bi translated">蘑菇</h2><p id="99d4" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated"><strong class="ih hj">损失:</strong> 1.2581 <strong class="ih hj">，分类交叉熵:</strong> 1.2581 <strong class="ih hj">，准确率:</strong> 61.84%</p><h2 id="db90" class="lq jm hi bd jn lw lx ly jr lz ma mb jv iq mc md jz iu me mf kd iy mg mh kh mi bi translated">亚甲基双氧甲基苯丙胺</h2><p id="47fb" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated"><strong class="ih hj">损失:</strong> 1.2435，<strong class="ih hj">分类交叉熵:</strong> 1.2435 <strong class="ih hj">，准确率:</strong> 62.55%</p><h2 id="aec6" class="lq jm hi bd jn lw lx ly jr lz ma mb jv iq mc md jz iu me mf kd iy mg mh kh mi bi translated">二乙基麦角酰胺</h2><p id="5428" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated"><strong class="ih hj">损失:</strong> 1.2760，<strong class="ih hj">分类交叉熵:</strong> 1.2760 <strong class="ih hj">，准确率:</strong> 61.33%</p><h2 id="60ee" class="lq jm hi bd jn lw lx ly jr lz ma mb jv iq mc md jz iu me mf kd iy mg mh kh mi bi translated">大麻</h2><p id="46d8" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated"><strong class="ih hj">损失:</strong> 1.2318，<strong class="ih hj">分类交叉熵:</strong> 1.2318 <strong class="ih hj">，准确率:</strong> 62.78%</p><h1 id="b5cf" class="jl jm hi bd jn jo ko jq jr js kp ju jv jw kq jy jz ka kr kc kd ke ks kg kh ki bi translated"><strong class="ak">使用BERT进行NLP分类</strong></h1><p id="cd36" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">鉴于这种文本分类需要大量的自然语言处理，我们很高兴能够利用BERT迁移学习模型。我们想利用BERT根据上下文标记文本数据的能力。这个模型是由谷歌的研究人员开发的，在“下一句话预测”和“问答”等任务中显示出了令人难以置信的结果。我们认为，使用这样一个强大的模型来分类我们的药物体验数据可能会产生一些有趣的结果。我们期望训练好的模型能够很好地预测原始经历是写在哪种药物上的，但是在LSTM生成的药物账户上表现不佳。</p><p id="ea5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用了<a class="ae lj" href="https://mc.ai/a-guide-to-simple-text-classification-with-bert/" rel="noopener ugc nofollow" target="_blank">这篇</a>关于多类文本分类的文章，以BERT为指导。在下载预训练模型之前，我们必须将数据格式化，使其对BERT更加友好。为此，我们使用了<em class="jd">熊猫</em>图书馆。所有的记录都被读入并写入一个<em class="jd">。tsv </em>逐行。<em class="jd"> train.tsv </em>需要有<strong class="ih hj"> 4列:索引、类、杂项和行</strong>。测试tsv只需要列<strong class="ih hj"> 1和4 </strong>。我们将80%的数据写入<em class="jd"> train.tsv </em>文件，而剩余的20%被平均分配到<em class="jd"> test.tsv </em>和<em class="jd"> dev.tsv </em>中进行验证。现在我们准备好实现BERT了。</p><h1 id="9624" class="jl jm hi bd jn jo ko jq jr js kp ju jv jw kq jy jz ka kr kc kd ke ks kg kh ki bi translated">BERT故障排除</h1><p id="c274" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">我们决定使用“只有”1.1亿个参数的装箱基础版本。在克隆了存储库并下载了模型之后，我们的麻烦就开始了。我们花了接下来的两天时间来密切熟悉BERT存储库中的文件，以便修复我们的错误(不幸的是没有错误消息的截图)。我们遇到的一个问题是bert_config文件上的<em class="jd">没有这样的文件或目录</em>错误。有趣的是，所有使用的文件都在同一个目录中，脚本在抛出错误之前能够访问其他文件，所以我们很困惑。最终，这个错误通过<strong class="ih hj">给BERT_BASE_DIR分配一个相对路径而不是绝对路径</strong>得以解决。弹出的另一个错误抱怨了我们的数据所包含的类的数量。问题在于BERT只配置了2个类，而我们的数据只有4个。为了解决这个问题，我们修改了<em class="jd"> run_classifier.py </em>中的<em class="jd"> get_labels() </em>方法，增加了两个额外的类。另一个神秘的错误声称找不到Tensorflow。原来BERT需要的是<em class="jd"> Tensorflow 1.15 </em>，不会和<em class="jd"> 2.0* </em>一起用。不幸的是，关于伯特错误的问题，尤其是解决方案在互联网上很少见，这使得它们更难克服。</p><pre class="ku kv kw kx fd ll lm ln lo aw lp bi"><span id="1b1a" class="lq jm hi lm b fi lr ls l lt lu"><strong class="lm hj">def</strong> get_labels(self):</span><span id="89ee" class="lq jm hi lm b fi lv ls l lt lu">"""See base class."""</span><span id="f745" class="lq jm hi lm b fi lv ls l lt lu"><strong class="lm hj">    return</strong> ["0", "1", "2", "3"]. &lt;-- one digit for each class</span></pre><ul class=""><li id="b868" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated">上面:包含BERT类的方法。对于二进制分类，默认返回值为“['0 '，' 1']”。</li></ul><h1 id="ebeb" class="jl jm hi bd jn jo ko jq jr js kp ju jv jw kq jy jz ka kr kc kd ke ks kg kh ki bi translated">训练伯特</h1><p id="ecf1" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">最后，伯特开始训练。一路上它没有提供太多信息，只有<em class="jd">全局_步/秒</em>和<em class="jd">示例/秒</em>。这让我们了解了训练的进度，但没有进展的迹象。通过粗略的计算，我们估计了5个小时的培训时间，虽然很多，但还是可以管理的。<strong class="ih hj">伯特最终训练了20个小时</strong>，这是意料之外的。更令人意想不到的是，它在我们的测试数据中的评价是如此之差。损耗在<strong class="ih hj"> 5.0 </strong>以上，精度为<strong class="ih hj"> ~10% </strong>。此时，我们既失望又沮丧。我们是否在开始训练前做错了什么，或者我们的数据如此“不可分类”？即使后者是真的，我们也应该得到50%左右的准确率。我们怀疑伯特出了什么问题。</p><pre class="ku kv kw kx fd ll lm ln lo aw lp bi"><span id="086b" class="lq jm hi lm b fi lr ls l lt lu">#eval_results.txt</span><span id="e5db" class="lq jm hi lm b fi lv ls l lt lu">eval_accuracy = 0.14463277<br/>eval_loss = 5.6167216<br/>global_step = 1994  #number of batches<br/>loss = 5.61461</span></pre><h1 id="9557" class="jl jm hi bd jn jo ko jq jr js kp ju jv jw kq jy jz ka kr kc kd ke ks kg kh ki bi translated">戴上手套，真的…</h1><p id="c674" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">和伯特的失败之后，我们必须决定下一步的行动。一种选择是诊断出了什么问题，并重新训练模型的最后一层。我们很快放弃了这个选项，因为在我们的机器(Macbook 8GB RAM)上20小时的培训时间使得在这个项目的时间框架内做这件事不可行。相反，我们选择利用一个(弱得多的)分类模型:1D卷积神经网络。我们将在这个模型中添加一个在<strong class="ih hj"> 100维</strong> <a class="ae lj" href="https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">手套</strong> </a> <strong class="ih hj">嵌入</strong>上预处理的嵌入层。这允许我们的分类器通过在<strong class="ih hj"> 100维‘嵌入空间’</strong>中的位置来识别每个单词。在嵌入空间中，具有较高程度的上下文相似性的单词被彼此紧密地分配。例如，“king”和“queen”之间的距离将小于“scoot”和“apple”。同样，使用上下文驱动嵌入的目的是希望获得更丰富的分类方案。我们训练这个模型的数据被分成多个文件，每个文件有两行长。这是为了增加我们可以分类的样本数量，从而有望改善结果。</p><pre class="ku kv kw kx fd ll lm ln lo aw lp bi"><span id="68be" class="lq jm hi lm b fi lr ls l lt lu">sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')<br/>embedded_sequences = embedding_layer(sequence_input)<br/>x = Conv1D(128, 5, activation='relu')(embedded_sequences)<br/>x = MaxPooling1D(5)(x)<br/>x = Conv1D(128, 5, activation='relu')(x)<br/>x = MaxPooling1D(5)(x)<br/>x = Conv1D(128, 5, activation='relu')(x)<br/>x = GlobalMaxPooling1D()(x)<br/>x = Dense(128, activation='relu')(x)<br/>preds = Dense(len(labels_index), activation='softmax')(x)</span><span id="715e" class="lq jm hi lm b fi lv ls l lt lu">model = Model(sequence_input, preds)<br/>model.compile(loss='categorical_crossentropy',<br/>              optimizer='rmsprop',<br/>              metrics=['acc'])</span></pre><p id="ef64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">经过训练，我们获得了相对较高的准确性和较低的损失，但验证分数仍然很低。</p><pre class="ku kv kw kx fd ll lm ln lo aw lp bi"><span id="0381" class="lq jm hi lm b fi lr ls l lt lu">Epoch 10/10<br/>11856/11856 [==============================] - 476s 40ms/sample - loss: 0.4500 - acc: 0.8249 - val_loss: 1.4107 - val_acc: 0.5386</span></pre><p id="0ed1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们发现，我们的简单分类器在上下文丰富的环境中运行良好，但它没有足够大的文本样本来生成有意义的结果。对于大量一致的文本数据的问题，这是一个简单的解决方案:我们只需找到更多的数据和格式，这样我们就可以在更大的文本文件上训练更长的时间。然而，考虑到我们有限的数据集，增加文本文件的丰富性(使训练文件更长)意味着将我们的初始数据集分割成更大的子文件。这反过来减少了可用于培训的文件数量。</p><p id="66ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，我们将训练好的分类器应用于模型生成的文本，得到了更令人印象深刻的结果:25%的分类准确率。</p><p id="1cc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管在分类上的结果不太引人注目，但我们认为这个项目是成功的。我们在Erowid上发现的数据非常适合简单分析，但是报告的<strong class="ih hj">风格不一致</strong>。一些叙述比其他叙述更具描述性，它们经常包含错别字(它们毕竟是来自吸毒经历的自我报告)，并且在讨论的主题中存在不一致。尽管如此，我们简单的文本生成器生成的文本具有不错的语调和词汇意识，这表明每个模型都学习了特定物质的书面描述的半独特特征。在提炼这些结果后，我们可以将我们的分类器应用于每种物质特有的改进的生成文本。这表明自我报告中使用的语言存在明显的差异。相信我们的方法，就有可能将这些分析技术应用于更大、更一致的药物报告数据集。通过基于药物描述的概括产生文本，我们希望巩固我们对这些神秘和强大物质的现象学的理解。如果我们能够用低维语言描绘出一幅清晰的画面，说明一种药物如何让一个人产生感觉，那么我们就能够更好地传达这些效果，以便更安全地使用，并让公众更好地理解精神药物及其诱导的扩张状态。</p><p id="aed4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，请尽情欣赏我们的文本生成器编写的这些诗歌片段:</p><p id="f788" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“<em class="jd">我带他去看了一条小径，接下来似乎有了感知的特定概念，并准备尝试预防这种声音，我开始了解所有情况，并开始循环楼上的对话，还在生活道路的整个喘息之前，给了我和我们更多的重复时间…</em>——迷幻药</p><p id="f7f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">”<em class="jd">我花了几分钟时间，思考着我的朋友们和我说过的话，我的身体几乎完全和床融为一体了。</em>——蘑菇</p><p id="892e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">”<em class="jd">像袜子一样僵硬的香肠充满了世界的一部分——用它们在任何一条有洼地的街道上为一些人遮挡阳光。我被保证不会有过去的效果。在意志开始降临到最好的朋友身上的时候。没有很长的时间，有很多真正的精神上的大排档，几分钟对我来说是一个怪胎。</em>-摇头丸</p><p id="29e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">“有几盏最亮的灯似乎一直照着我，我们可以看到我正在开始睡觉，接近令人担忧，有点现实，只是说，‘我不能说我们都有感情’”——</em>蘑菇</p><p id="561b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“<em class="jd">因为这是一个真实的人的压力，一切都变得越来越多，我太多的购物和沟通的事实，我的朋友们感觉</em>——大麻</p><p id="87db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“<em class="jd">我</em> <em class="jd">做不到我的头上，她想去最喜欢的地方，我全程带我去了</em>——MDMA</p><p id="0298" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">"<em class="jd">我的朋友走进了我的嘴里，当我感到非常模糊时，我就消失在摇头丸中，我享受着思考口香糖的乐趣，我不得不去听音乐，感觉几乎要发生了，我是我朋友的冲浪手，完美对一个满意的同伴来说完全是一粒药丸，音乐是音乐的整体，比一些人有快感，他们在几个聚会和整个道琼斯指数中更有把握。</em>-摇头丸</p><p id="d392" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">”<em class="jd">这是世界我的浴室，我以为他们是一个令人难以置信的权利旁边，我过去控制她的背部之一，并认为太阳将是其中的课程，然后我开始思考浴室和有方式有开始的音乐会。</em>-迷幻药</p><p id="b73b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">”<em class="jd">我曾牵过它的手，当时我正和我的朋友一起卷着一个惊喜的感觉，想说一说，出了一个惊喜的背影，此时我感到散漫……</em>”——MDMA</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><p id="9800" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">*截至2019年16月12日的修订版，提供了一个使用tensorflow 2.0构建的BERT实施。</em></p><p id="aea7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">这个项目是为我们的人工神经网络和深度学习课程做的。在GitHub上找到我们的代码</em> <a class="ae lj" href="https://github.com/gtdlk20/NN_final" rel="noopener ugc nofollow" target="_blank"> <em class="jd">这里</em> </a> <em class="jd">。</em></p></div></div>    
</body>
</html>