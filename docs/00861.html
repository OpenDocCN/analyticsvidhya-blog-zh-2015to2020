<html>
<head>
<title>Fallacy of using AUC as a model selection criteria</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用AUC作为模型选择标准的谬误</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fallacy-of-using-auc-as-a-model-selection-criteria-d6bf50f4de0d?source=collection_archive---------4-----------------------#2019-09-14">https://medium.com/analytics-vidhya/fallacy-of-using-auc-as-a-model-selection-criteria-d6bf50f4de0d?source=collection_archive---------4-----------------------#2019-09-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6baa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在模型选择的背景下，大多数数据科学家依靠各种各样的拟合优度标准来决定哪个模型对应于维持/验证数据集的最佳性能。这些拟合优度标准通常也称为'<strong class="ih hj">度量'</strong>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/3a34811680fda4cc72eaaf78f34ba498.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*o9zTy1FuqWmDBePQeUkgKg.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">混淆矩阵:表格ML模型的大多数度量标准都是从混淆矩阵中得到的</figcaption></figure><blockquote class="jp jq jr"><p id="ce6c" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">注意，“<strong class="ih hj">度量”</strong>可以是与“<strong class="ih hj">损失函数</strong>完全不同的<strong class="ih hj">，在大多数情况下，损失函数对应于将成本惩罚映射到任何给定预测的函数，使得如果预测更接近目标，则成本更低，反之亦然。</strong></p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jw"><img src="../Images/c433d42f4a1ac95aeaa26e30b7105d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*gw2Hw_WFJ6MMnZ1AUdT8jQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated"><strong class="bd jx">三维欧氏空间中的损失函数</strong></figcaption></figure><blockquote class="jp jq jr"><p id="fdfe" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj">损失函数被约束:</strong></p></blockquote><p id="1f26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损失函数的一个约束条件是，在大多数情况下，要求它们至少是一阶可微的，在一些高级算法中，甚至是二阶可微的(<a class="ae jy" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> LightGBM </a>，<a class="ae jy" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>等)</p><h2 id="69d6" class="jz ka hi bd jx kb kc kd ke kf kg kh ki iq kj kk kl iu km kn ko iy kp kq kr ks bi translated"><strong class="ak">损失函数和度量的例子:</strong></h2><p id="41dc" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated"><strong class="ih hj">损失函数</strong>:对数损失、似然损失、均方误差等。</p><p id="61ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">指标</strong>:准确度、精确度、召回率、f-Beta评分、RMSE、MSE、MAPE、MAD等。</p><p id="b58e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你会注意到一个<strong class="ih hj"> <em class="js">损失函数绝对可以作为一个度量</em> </strong>，但是<strong class="ih hj"> <em class="js">反过来不一定是真的</em> </strong>。例如，可以使用<a class="ae jy" href="http://wiki.fast.ai/index.php/Log_Loss" rel="noopener ugc nofollow" target="_blank"> logloss </a>作为损失函数和度量。然而，诸如<a class="ae jy" href="https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/" rel="noopener ugc nofollow" target="_blank">准确度、精确度、召回率</a>等指标不能用作损失函数。</p><p id="c2af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们使用上述度量，则违反了至少要定义有效梯度或甚至Hessian矩阵(对于提升树模型)的约束。</p><p id="619d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="js">解析梯度公式:</em></strong><em class="js">f(x0+⇼x)= f(x0)+A(x0)⇼x+o(⇼x)</em></p><p id="0a3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注</strong>:尽量说服自己，梯度可以看成是一个指向函数曲面上最陡上升方向的向量。</p><p id="7587" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">黑森</strong>定义为二阶微分，数学上可以写成:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ky"><img src="../Images/97b99c92caf5407b7dbfef56c53f88cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/1*lCt4fAmnDVQ0m9ScucM_lQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated"><strong class="bd jx">黑森公式</strong></figcaption></figure><p id="68f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> AUC-ROC指标</strong></p><p id="492d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们关注分类问题中非常常见的一个特定指标——AUC或ROC(受试者操作特征)曲线下面积。</p><p id="86f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑二进制分类的情况，其中我们训练模型X并检索维持集上的预测概率。我们还假设阳性类的特定截止阈值为0.4(概率&gt; 0.4 = +ve类)。</p><blockquote class="jp jq jr"><p id="da44" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">参考下表的Y实际(目标)、预测概率(+ve类)和基于阈值的预测类标签。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kz"><img src="../Images/f349bd75a314c929c96c528f0690d70d.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*a_V2ypqp55wsUtL_cMS-jg.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">实际问题与预测问题</figcaption></figure><p id="7d4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们不会深入讨论如何计算AUC的细节，但在高层次上，AUC对应于:</p><p id="09aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.首先基于多个截止阈值计算<strong class="ih hj"> TPR(真阳性率)</strong>和<strong class="ih hj"> FPR(假阳性率)</strong></p><p id="bb18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.将这些绘制在图上，并计算曲线下的面积。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es la"><img src="../Images/0188a2b30fc0fe2a2b8944f662c8bb6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/0*eh9IL6ex4GeFBcHo.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">AUC-ROC曲线(<a class="ae jy" href="https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5" rel="noopener" target="_blank">来源</a>)</figcaption></figure><p id="6c64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如需了解详细信息，请点击<a class="ae jy" href="https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5" rel="noopener" target="_blank">查看</a>。</p><blockquote class="jp jq jr"><p id="e29f" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">现在，我们将从<strong class="ih hj">创建一个随机数据集</strong>开始。具体来说，我们生成三样东西:</p></blockquote><ol class=""><li id="b2c5" class="lb lc hi ih b ii ij im in iq ld iu le iy lf jc lg lh li lj bi translated">y实际矢量:10 X 1</li><li id="a132" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated">Y Pred矢量:10 X 1</li><li id="fb85" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated">基于阈值的预测类别:10 X 1</li></ol><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><blockquote class="jp jq jr"><p id="3543" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">接下来，我们将基于实际的目标标签和预测的概率值来计算AUC</p></blockquote><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="1157" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">乍一看，<strong class="ih hj"> AUC似乎直接取决于概率</strong>。在上面的代码中，我们可以看到，我们仅使用实际目标和预测概率来计算AUC。虽然使用了概率，但人们可能会惊讶地发现<strong class="ih hj">根本没有使用量值</strong>。我用代码解释一下。</p><blockquote class="jp jq jr"><p id="99fe" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">我们不使用原始概率，而是对概率进行等级平均，然后将等级平均结果输入AUC公式。让我们看看当我们这样做时会发生什么:</p></blockquote><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><blockquote class="jp jq jr"><p id="89f5" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">瞧啊。当我们使用概率向量的等级平均值时，AUC值<strong class="ih hj">不变</strong>。</p></blockquote><p id="ad6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这对我们的分析意味着什么？</p><p id="dc81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简而言之，这意味着在AUC的计算中没有使用原始概率值，因此，我们不能说我们的模型在进行预测方面有多大的信心。</p><p id="a488" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了进一步分析，我们将准备另一组预测概率(<strong class="ih hj">模型B </strong>)，它是模型A概率的等级平均值，缩小了100倍。</p><p id="f9d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，在新生成的概率中，<strong class="ih hj"><em class="js"/></strong><em class="js"/>的排序仍然保持不变。与原始模型(模型A)的输出 相比，概率的<strong class="ih hj"> <em class="js">幅度很可能会减小。</em></strong></p><p id="4451" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们检查两个不同模型的预测概率输出的概率分布曲线，如下所示:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lr"><img src="../Images/5884a132b3fec52feaf62e6a088cbf63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YO3bZ0n2l_MrOr6xKB7udg.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">来自两个不同模型(具有相同AUC)的预测先证者的KDE图</figcaption></figure><blockquote class="jp jq jr"><p id="6941" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj">模型A的AUC:0.875<br/>模型B的AUC:0.875</strong></p><p id="27cf" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">因此，两个分类器的AUC分数相同，但预测的概率分布非常不同。这是什么意思？</p></blockquote><p id="5afe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这意味着我们的模型在预测的可信度方面表现得非常不同。我们知道，我们既不想要一个过于自信的模型，也不想要一个不够自信的模型。</p><p id="3b21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将不得不看一系列的数字来理解两个模型中哪一个过于自信/不够自信/刚刚好。</p><p id="19b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个帖子下周会有后续，届时我会贴出进一步的分析，介绍概率校准分析的概念。</p><p id="0339" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢阅读。</p><p id="937f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="js">参考文献</em>:</p><p id="a99a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="js"> 1。</em><a class="ae jy" href="https://blog.algorithmia.com/introduction-to-loss-functions/" rel="noopener ugc nofollow" target="_blank"><em class="js">https://blog . algorithm ia . com/introduction-to-loss-functions/</em></a></p><p id="d3dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="js"> 2。</em><a class="ae jy" href="https://courses.cs.ut.ee/MTAT.03.227/2016_spring/uploads/Main/lecture-4-extra-materials.pdf" rel="noopener ugc nofollow" target="_blank"><em class="js">https://courses . cs . ut . ee/mtat . 03.227/2016 _ spring/uploads/Main/lecture-4-extra-materials . pdf</em></a></p></div></div>    
</body>
</html>