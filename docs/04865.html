<html>
<head>
<title>Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的特征缩放:理解标准化与规范化的区别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/feature-scaling-for-machine-learning-normalization-vs-standardization-34daa2d4f707?source=collection_archive---------13-----------------------#2020-04-03">https://medium.com/analytics-vidhya/feature-scaling-for-machine-learning-normalization-vs-standardization-34daa2d4f707?source=collection_archive---------13-----------------------#2020-04-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="82cc" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">特征缩放简介</h1><p id="c532" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我最近在处理一个数据集，该数据集包含多个要素，这些要素的大小、范围和单位各不相同。这是一个重大障碍，因为一些机器学习算法对这些特征非常敏感。</p><p id="0103" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我敢肯定，你们大多数人在项目或学习过程中肯定都面临过这个问题。例如，一个特征完全以千克为单位，而另一个以克为单位，另一个以升为单位，等等。当这些功能在呈现内容上有如此大的差异时，我们该如何使用它们呢？</p><blockquote class="kg"><p id="3134" class="kh ki hi bd kj kk kl km kn ko kp ka dx translated">这就是我转向特征缩放概念的地方。这是数据预处理阶段的一个关键部分，但我看到许多初学者忽略了它(这对他们的机器学习模型不利)。</p></blockquote><figure class="ks kt ku kv kw kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es kr"><img src="../Images/ec04400f91d70204ffe5999c466dc9f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iFGswHtfVCuUEJgE.png"/></div></div></figure><p id="6405" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">关于特征缩放，有一件奇怪的事情——它(显著)提高了一些机器学习算法的性能，但对其他算法根本不起作用。这种怪癖背后的原因可能是什么？</p><p id="284b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">还有，规范化和标准化有什么区别？这是机器学习中最常用的两种特征缩放技术，但在它们的理解中存在一定程度的模糊性。什么时候应该使用哪种技术？</p><p id="8033" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我将在这篇关于特性扩展的文章中回答这些问题以及更多问题。我们还将在Python中实现特性缩放，让您实际了解它如何适用于不同的机器学习算法。</p><p id="3b7c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="le">注:我假设你熟悉Python和核心机器学习算法。如果你是新手，我建议你参加以下课程:</em></p><ul class=""><li id="5a6b" class="lf lg hi jf b jg kb jk kc jo lh js li jw lj ka lk ll lm ln bi translated"><a class="ae lo" href="https://courses.analyticsvidhya.com/courses/introduction-to-data-science?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> <em class="le">用于数据科学的Python</em></a></li><li id="94f9" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lk ll lm ln bi translated"><a class="ae lo" href="https://courses.analyticsvidhya.com/collections?category=free" rel="noopener ugc nofollow" target="_blank"> <em class="le">所有免费机器学习课程由Analytics Vidhya </em> </a></li><li id="ffe9" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lk ll lm ln bi translated"><a class="ae lo" href="https://courses.analyticsvidhya.com/courses/applied-machine-learning-beginner-to-professional?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> <em class="le">应用机器学习</em> </a></li></ul><h1 id="1f57" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">目录</h1><ol class=""><li id="8782" class="lf lg hi jf b jg jh jk jl jo lu js lv jw lw ka lx ll lm ln bi translated">为什么要使用特征缩放？</li><li id="ee3c" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lx ll lm ln bi translated">什么是正常化？</li><li id="6230" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lx ll lm ln bi translated">什么是标准化？</li><li id="0133" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lx ll lm ln bi translated">最大的问题是——正常化还是标准化？</li><li id="f7e0" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lx ll lm ln bi translated">在Python中实现要素缩放</li></ol><ul class=""><li id="4106" class="lf lg hi jf b jg kb jk kc jo lh js li jw lj ka lk ll lm ln bi translated">使用Sklearn进行规范化</li><li id="e4a2" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lk ll lm ln bi translated">使用Sklearn实现标准化</li></ul><p id="5793" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">6.将特征缩放应用于机器学习算法</p><ul class=""><li id="9e80" class="lf lg hi jf b jg kb jk kc jo lh js li jw lj ka lk ll lm ln bi translated">k-最近邻(KNN)</li><li id="718d" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lk ll lm ln bi translated">支持向量回归机</li><li id="7141" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lk ll lm ln bi translated">决策图表</li></ul><h1 id="5fa8" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">为什么要使用特征缩放？</h1><p id="db00" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们需要解决的第一个问题是——为什么我们需要调整数据集中的变量？一些机器学习算法对特征缩放很敏感，而其他算法对特征缩放几乎不变。让我更详细地解释一下。</p><h1 id="28bb" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">基于梯度下降的算法</h1><p id="4295" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj">机器学习算法像</strong> <a class="ae lo" href="https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj">线性回归</strong></a><strong class="jf hj"/><a class="ae lo" href="https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"><strong class="jf hj">逻辑回归</strong></a><strong class="jf hj"/><a class="ae lo" href="https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"><strong class="jf hj">神经网络</strong> </a> <strong class="jf hj">等。使用梯度下降作为优化技术需要对数据进行缩放。</strong>看看下面的梯度下降公式:</p><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es ly"><img src="../Images/de8311cd735c737f0401d43fbe4403d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*FUIjyVaNf99iB9Kc.png"/></div></figure><p id="6d97" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">公式中特征值X的存在将影响梯度下降的步长。特征范围的差异将导致每个特征的不同步长。为了确保梯度下降平滑地向最小值移动，并确保梯度下降的步长以相同的速率更新所有要素，我们在将数据输入模型之前对其进行了缩放。</p><blockquote class="kg"><p id="461f" class="kh ki hi bd kj kk kl km kn ko kp ka dx translated">具有相似尺度的特征可以帮助梯度下降更快地向最小值收敛。</p></blockquote><h1 id="9f7c" class="if ig hi bd ih ii ij ik il im in io ip iq md is it iu me iw ix iy mf ja jb jc bi translated">基于距离的算法</h1><p id="ff8a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">像<a class="ae lo" href="https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> KNN </a>、<a class="ae lo" href="https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> K-means </a>和<a class="ae lo" href="https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> SVM </a>这样的距离算法受特征范围的影响最大。这是因为在幕后，他们使用数据点之间的距离来确定它们的相似性。</p><p id="36a6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">例如，假设我们有包含学生高中CGPA分数(从0到5)和他们未来收入(以千卢比计)的数据:</p><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es mg"><img src="../Images/1a79258d13dcd5b1cdcfa31fc90a5731.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/0*6ElAOCgJUfBkPpF4.png"/></div></figure><p id="c37c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">由于这两个要素的比例不同，因此可能会对具有较高幅度的要素赋予较高的权重。这将影响机器学习算法的性能，显然，我们不希望我们的算法偏向一个特征。</p><blockquote class="kg"><p id="d68b" class="kh ki hi bd kj kk kl km kn ko kp ka dx translated"><em class="kq">因此，在采用基于距离的算法之前，我们对数据进行了缩放，以便所有特征对结果的贡献相等。</em></p></blockquote><figure class="ks kt ku kv kw kx er es paragraph-image"><div class="er es mh"><img src="../Images/7119287a7b075025ebada787f325ae48.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/0*ki3CfQSngJ-ECiic.png"/></div></figure><p id="b5d4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">当我们比较学生A和B的数据点之间以及B和C的数据点之间在缩放前后的欧几里德距离时，缩放的效果是明显的，如下所示:</p><ul class=""><li id="b5cd" class="lf lg hi jf b jg kb jk kc jo lh js li jw lj ka lk ll lm ln bi translated">缩放前的距离AB:</li></ul><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es mi"><img src="../Images/f6d675088c2cb3ea53960bcc267684be.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*7Lp14s6eMU-ar8Ow0On2gw.png"/></div></figure><ul class=""><li id="400a" class="lf lg hi jf b jg kb jk kc jo lh js li jw lj ka lk ll lm ln bi translated">缩放前的距离BC:</li></ul><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es mj"><img src="../Images/f9b9d7dbe2b8f457854c2e00716e2d82.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/1*3_JVNYY2QVN-1qrRprMU2A.png"/></div></figure><ul class=""><li id="c925" class="lf lg hi jf b jg kb jk kc jo lh js li jw lj ka lk ll lm ln bi translated">缩放后的距离AB:</li></ul><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es mk"><img src="../Images/64b871a715d3318e9c1ce96bb4686b63.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*IfPWPTNTy7Spk4s-Y9KBRA.png"/></div></figure><ul class=""><li id="984d" class="lf lg hi jf b jg kb jk kc jo lh js li jw lj ka lk ll lm ln bi translated">缩放后的距离BC:</li></ul><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es ml"><img src="../Images/8ca649ecacd108308d145f1e2b3ad05c.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*L-rm4iEYEdveMLQOa8t6QQ.png"/></div></figure><p id="52a2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">缩放将两个特征都带入了画面，距离现在比应用缩放之前更具可比性。</p><h1 id="82f1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">基于树的算法</h1><p id="f7e4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae lo" href="https://www.analyticsvidhya.com/blog/2016/04/tree-based-algorithms-complete-tutorial-scratch-in-python/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank">另一方面，基于树的算法</a>对特征的规模相当不敏感。想一想，决策树只是基于单一特征拆分一个节点。决策树在增加节点同质性的特征上分割节点。特征上的这种分割不受其他特征的影响。</p><p id="e718" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">因此，实际上剩余特征对分割没有影响。这就是为什么它们对特征的比例不变！</p><h1 id="07dc" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">什么是正常化？</h1><p id="8d46" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj">标准化是一种缩放技术，其中值被移动和重新缩放，以使它们最终在0和1之间变化。这也称为最小-最大缩放。</strong></p><p id="11bc" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这是归一化的公式:</p><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es mm"><img src="../Images/86e5525bbbe3235eae2bc020e7e0fcb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/1*Vri8Qo74-7R8c_wogcgxoQ.png"/></div></figure><p id="a2c1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这里，Xmax和Xmin分别是特征的最大值和最小值。</p><ul class=""><li id="2c65" class="lf lg hi jf b jg kb jk kc jo lh js li jw lj ka lk ll lm ln bi translated">当X的值是列中的最小值时，分子将是0，因此X '是0</li><li id="4c6d" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lk ll lm ln bi translated">另一方面，当X的值是列中的最大值时，分子等于分母，因此X’的值是1</li><li id="278c" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lk ll lm ln bi translated">如果X的值在最小值和最大值之间，那么X’的值在0和1之间</li></ul><h1 id="f541" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">什么是标准化？</h1><p id="3748" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj">标准化是另一种标度技术，其中数值以平均值为中心，具有单位标准偏差。这意味着属性的平均值变为零，结果分布有一个单位标准偏差。</strong></p><p id="7fcd" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这是标准化的公式:</p><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es mn"><img src="../Images/a6e31a7164ba2635b3ada98a479d7a33.png" data-original-src="https://miro.medium.com/v2/resize:fit:220/format:webp/1*-xkYdBNFzjY7i-6mHnixWA.png"/></div></figure><p id="bacd" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">注意，在这种情况下，这些值不限于特定的范围。</p><p id="4bb1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">现在，你心中的大问题一定是什么时候应该使用规范化，什么时候应该使用标准化？让我们来了解一下！</p><h1 id="2823" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">最大的问题是——正常化还是标准化？</h1><p id="7c73" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">规范化vs .标准化是机器学习新人中永恒的问题。让我在这一节详细阐述一下答案。</p><ul class=""><li id="f984" class="lf lg hi jf b jg kb jk kc jo lh js li jw lj ka lk ll lm ln bi translated"><strong class="jf hj">当您知道数据的分布不符合高斯分布时，可以使用归一化</strong>。这在不假设任何数据分布的算法中很有用，例如K-最近邻和神经网络。</li><li id="e62a" class="lf lg hi jf b jg lp jk lq jo lr js ls jw lt ka lk ll lm ln bi translated"><strong class="jf hj">另一方面，标准化</strong>在数据遵循高斯分布的情况下会很有帮助。然而，这并不一定是真的。此外，与标准化不同，标准化没有边界范围。因此，即使您的数据中有异常值，它们也不会受到标准化的影响。</li></ul><p id="7021" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">然而，最终，选择使用规范化还是标准化将取决于您的问题和您使用的机器学习算法。没有硬性的规则告诉你什么时候规范化或标准化你的数据。<strong class="jf hj">您总是可以从将您的模型与原始的、标准化的和标准化的数据进行拟合开始，并比较性能以获得最佳结果。</strong></p><p id="4609" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="le">在训练数据上安装定标器，然后用它来转换测试数据，这是一个很好的做法。这将避免模型测试过程中的任何数据泄漏。此外，通常不需要目标值的缩放。</em></p><h1 id="81f1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">在Python中实现要素缩放</h1><p id="b42c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在有趣的部分来了——把我们学到的东西付诸实践。我将在<a class="ae lo" href="https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank">大市场数据集</a>上对一些机器学习算法应用特征缩放，我已经采用了<a class="ae lo" href="https://datahack.analyticsvidhya.com/contest/all/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> DataHack </a>平台。</p><p id="3efa" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我将跳过预处理步骤，因为它们超出了本教程的范围。但是你可以在这篇<a class="ae lo" href="https://www.analyticsvidhya.com/blog/2016/02/bigmart-sales-solution-top-20/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank">文章</a>中找到它们的清晰解释。这些步骤将使您能够进入hackathon排行榜的前20%，因此值得一试！</p><p id="6312" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">因此，让我们首先将数据分成训练集和测试集:</p><figure class="lz ma mb mc fd kx"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="ca07" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在进入特性缩放部分之前，我们先来看一下使用<strong class="jf hj"> pd.describe() </strong>方法得到的数据细节:</p><figure class="lz ma mb mc fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mq"><img src="../Images/3732d974e9b4de5218540f195d86592f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*598Mm9jIwiPOOzdD.png"/></div></div></figure><p id="87fc" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们可以看到，在我们的数字特征中存在着一个巨大的值范围差异:<strong class="jf hj"> Item_Visibility </strong>、<strong class="jf hj"> Item_Weight、</strong>Item _ MRP、<strong class="jf hj">Outlet _ Establishment _ Year</strong>。让我们尝试使用功能缩放来解决这个问题！</p><p id="4186" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="le">注意:您将注意到Item_Visibility特性中的负值，因为我已经采用了对数变换来处理该特性中的偏斜度。</em></p><h1 id="db4e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">使用sklearn进行规范化</h1><p id="8d3f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了规范化您的数据，您需要从<a class="ae lo" href="https://courses.analyticsvidhya.com/courses/get-started-with-scikit-learn-sklearn?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> sklearn </a>库中导入<em class="le"> MinMaxScalar </em>并将其应用到我们的数据集。所以，让我们这样做吧！</p><figure class="lz ma mb mc fd kx"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="1b92" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">让我们看看标准化是如何影响我们的数据集的:</p><figure class="lz ma mb mc fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mr"><img src="../Images/ecb62766c8f556989a8f8cd34181d01b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_gEUdAi_31KMJQ-4.png"/></div></div></figure><p id="4fe2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">现在，所有特征的最小值为0，最大值为1。完美！</p><p id="bdf0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">接下来，让我们尝试标准化我们的数据。</p><h1 id="5248" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">使用sklearn实现标准化</h1><p id="6aef" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了标准化您的数据，您需要从sklearn库中导入<em class="le"> StandardScalar </em>，并将其应用到我们的数据集。你可以这样做:</p><figure class="lz ma mb mc fd kx"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="5bdd" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">您可能已经注意到，我只对我的数字列应用了标准化，而没有对其他的<a class="ae lo" href="https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank">一键编码</a>特性应用标准化。标准化独热编码特征意味着给分类特征分配一个分布。你不会想那么做的！</p><p id="1521" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">但是为什么我没有在标准化数据时做同样的事情呢？因为独热编码特征已经在0到1的范围内。因此，规范化不会影响它们的值。</p><p id="7167" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">好的，让我们看看标准化是如何改变我们的数据的:</p><figure class="lz ma mb mc fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es ms"><img src="../Images/94c04d09696caacaa7154e8bf6d20e3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LlpBuofy4Rxub4WB.png"/></div></div></figure><p id="cd5a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">数字特征现在以平均值为中心，具有单位标准偏差。厉害！</p><h1 id="35ef" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">比较未缩放、规范化和标准化的数据</h1><p id="b41c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">可视化您的数据以了解当前的分布总是很棒的。我们可以使用箱线图来比较未缩放数据和缩放数据。</p><p id="38d1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="le">您可以在这里 <em class="le">了解更多关于数据可视化</em> <a class="ae lo" href="https://www.analyticsvidhya.com/blog/tag/data-visualization/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank">。</a></em></p><figure class="lz ma mb mc fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mt"><img src="../Images/e13cdc7d88436867d4312991958a2c07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*o21-O_BtfyZb_VtB.png"/></div></div></figure><p id="b453" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">您可以注意到缩放要素是如何让一切变得清晰可见的。这些功能现在更具可比性，并将对学习模型产生类似的影响。</p><h1 id="2b79" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">将缩放应用于机器学习算法</h1><p id="4e73" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在是时候在我们的数据上训练一些机器学习算法，以比较不同缩放技术对算法性能的影响。我想看看缩放对三种算法的影响:K近邻、支持向量回归机和决策树。</p><p id="70cf" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">K-最近邻</strong></p><p id="357b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">正如我们之前看到的，KNN是一种基于距离的算法，它受要素范围的影响。让我们看看它在扩展前后对我们的数据的表现如何:</p><figure class="lz ma mb mc fd kx"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es mu"><img src="../Images/961e36df02c290604bef3b1b7b8d2aa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:378/format:webp/0*SwHDhN5gWcXR5Kuk.png"/></div></figure><p id="fb11" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">你可以看到缩放特征降低了我们的KNN模型的RMSE分数。具体来说，标准化数据的性能比标准化数据好一点。</p><p id="749b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="le">注意:我在这里测量RMSE，因为这个比赛评估的是RMSE。</em></p><p id="2aaa" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">支持向量回归机</strong></p><p id="63bd" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae lo" href="https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> SVR </a>是另一种基于距离的算法。因此，让我们来看看规范化和标准化哪个效果更好:</p><figure class="lz ma mb mc fd kx"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es mv"><img src="../Images/2dd5478be9fde22b9a95c1a4304e3b75.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/0*aWpvzctGQMcr1j5E.png"/></div></figure><p id="1cec" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们可以看到，缩放功能确实降低了RMSE分数。并且标准化数据比标准化数据表现得更好。你觉得为什么会这样？</p><p id="779f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">sklearn文档指出，使用RBF核的SVM假设所有特征都以零为中心，方差也是相同的数量级。这是因为方差大于其他特征的特征会阻止估计器从所有特征中学习。太好了！</p><p id="2a66" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">决策树</strong></p><p id="a086" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们已经知道决策树对于特征缩放是不变的。但我想展示一个它如何处理数据的实际例子:</p><figure class="lz ma mb mc fd kx"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="lz ma mb mc fd kx er es paragraph-image"><div class="er es mw"><img src="../Images/9e556da78367f7a4dc2837bd41800b5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/0*ndYDK6Kt4efUKLcr.png"/></div></figure><p id="d500" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">你可以看到RMSE分数在缩放特征上没有移动一英寸。因此，当您对数据使用基于树的算法时，请放心！</p><h1 id="1207" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结束注释</h1><p id="57f1" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">本教程讲述了对数据使用要素缩放的相关性，以及规范化和标准化如何对机器学习算法的工作产生不同的影响</p><p id="fa2a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">请记住，对于何时使用规范化而非标准化，没有正确的答案，反之亦然。这完全取决于你的数据和你使用的算法。</p><p id="fec7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">下一步，我鼓励你尝试用其他算法进行特征缩放，并找出哪种算法效果最好——规范化还是标准化？我建议你使用<a class="ae lo" href="https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization" rel="noopener ugc nofollow" target="_blank"> BigMart的销售数据</a>来保持这篇文章的连续性。别忘了在下面的评论区分享你的见解！</p><h1 id="c347" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">你也可以在分析Vidhya的Android应用上阅读这篇文章</h1><figure class="lz ma mb mc fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mx"><img src="../Images/f9c0317a3ec7db6f12fbfb5a6c3dbb8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/0*rOAhaBJhgObsLxsh.png"/></div></div></figure></div><div class="ab cl my mz gp na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="hb hc hd he hf"><p id="e8e2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="le">原载于2020年4月3日https://www.analyticsvidhya.com</em><em class="le"/><a class="ae lo" href="https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/" rel="noopener ugc nofollow" target="_blank"><em class="le">。</em></a></p></div></div>    
</body>
</html>