<html>
<head>
<title>Convolutional Neural Networks using Numpy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Numpy的卷积神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/convolutional-neural-networks-using-numpy-part-1-f4f8ab26cccb?source=collection_archive---------5-----------------------#2019-10-29">https://medium.com/analytics-vidhya/convolutional-neural-networks-using-numpy-part-1-f4f8ab26cccb?source=collection_archive---------5-----------------------#2019-10-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="206e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">第1部分:在两类时尚MNIST图像分类任务上使用单层卷积滤波器和单个密集层</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/747283f81b1f312d6f9ac129a47cea16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pydxZjZYXCW7IqU2"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae jn" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Franck V. </a>拍摄的照片</figcaption></figure><p id="5bf0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">有许多强大的工具，如Keras和Tensorflow，可以用来制作卷积神经网络(CNN)。然而，除非我已经打开了引擎盖，偷看了里面，我并不真正满意我知道一些事情。如果您和我一样，请继续阅读，看看如何使用Numpy(和Scipy)从头构建CNN。</p><p id="f812" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kk">这个帖子的代码在我的</em> <a class="ae jn" href="https://github.com/borundev/DNN_Lectures" rel="noopener ugc nofollow" target="_blank"> <em class="kk">资源库</em> </a> <em class="kk">里有。</em></p><p id="4b8f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我将这篇文章分成多个部分。到目前为止，我已经计划了两个部分。首先，我将只做一个关于时尚MNIST的两类分类问题，仅限于两类。图像是单色的，CNN将只有一个卷积滤波器，后面是一个致密层。这种简单性将使我们能够专注于卷积的细节，而不必担心附带的复杂性。在第二篇文章中，我将处理完整的时尚MNIST数据集(10类)和多重卷积滤波器。我还将查看CIFAR-10数据集，该数据集包含10类彩色图像。我可能会在第三篇文章中强调一些关于卷积的其他方面。</p><p id="38e3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这是一个技术性的职位，并且假定你对代数和微积分有一定的了解。虽然我知道一个不懂高等数学的人可以用tensorflow做很多事情，但我不明白没有tensor flow怎么可能在引擎盖下偷看。代数在前向传递中是必不可少的，并且代数和微积分对于计算损失函数相对于网络权重的导数是有用的，这是我以封闭形式导出的。这些用于更新权重，通常称为反向传播。不愿意经历推导过程但能够理解最终表达式的读者仍然可以通过理解最终结果并在numpy中实现(或遵循我的实现)而受益。</p><h1 id="9be9" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">盘旋</h1><p id="c1d8" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">在本节中，我们将讨论图像处理中卷积的确切含义，以及它与scipy中实现的关系。这很有用，因为scipy实现比简单的numpy实现快得多。最后，我们将考虑一个手动计算卷积的例子，并使用scipy作为健全性检查。为简单起见，本节我们将在1维中工作，但论点可以简单地扩展到任何维数。</p><p id="1832" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">数学上，函数f与函数g的卷积被定义为</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es li"><img src="../Images/0194eec2caa7e4f778ab1cd08c581e52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*hxOL3tKq4QO2KGwtJ-iTHA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">物理学中的卷积</figcaption></figure><p id="5d38" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这个定义在物理学和信号处理中是有用的。例如，在电磁学中，g可以是电荷密度，f(在这种情况下称为格林函数)将帮助我们计算由于所述电荷分布而产生的电势。(详见杰克逊等电磁学书籍或佩斯金、施罗德等粒子物理学书籍)。</p><p id="d78d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在图像处理中，这个定义有点落后，因为对于长度为<em class="kk"> 𝐾、</em>的卷积窗g，我们希望在<em class="kk"> 𝑥 </em>的卷积是<em class="kk"> 𝑓 </em>的加权平均值，使得在<em class="kk">𝑥</em>-<em class="kk">𝐾</em>/2+<em class="kk">𝑦</em>的值被<em class="kk"> 𝑔 </em> ( <em class="kk"> 𝑦 </em>)加权。因此，为了图像处理的目的，正确的定义是</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lj"><img src="../Images/a96902a933d034892a52d898df11d8dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HZ0LbLI5lqlSBMZOKrj65Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图像处理卷积</figcaption></figure><p id="7c28" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kk">请注意，这将需要f(x)的值作为x的负值，如果按原样放入，则numpy会将负数解释为从数组末尾开始的索引。因此，在numpy中实现这一点时，我们需要确保原始数组嵌入到一个更大的0填充数组中，并且正确理解负索引。</em></p><p id="fdc3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我们的CNN实现中，我们将使用scipy.convolve，因为它将比numpy中的简单实现更快。因此，了解scipy.convolve与我们想要的东西之间的联系是很有用的。Scipy的卷积用于信号处理，因此它类似于传统的物理定义，但由于数组位置从0开始的numpy约定，g的窗口中心不在0处，而是在K/2处。所以scipy.convolve使用了这个定义</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lk"><img src="../Images/a9f5a65c99540fc24a7514ac1c245744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*2MFaNy3oLSyMei8_c1W4ow.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">scipy .旋花</figcaption></figure><p id="2d52" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，如果我们反转这个卷积窗，我们得到y -&gt;K-y，这就是积分</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ll"><img src="../Images/42e750ced7b5d5463c2f5f7c2baad1d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AWgADtNAaQ-g1cvSi_r5ZQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">在将卷积滤波器数组交给scipy.convolve之前对其进行反转的结果</figcaption></figure><p id="1ee3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此<strong class="jq hj">我们将通过把卷积窗口的反转数组交给scipy.convolve来得到我们想要的结果。</strong></p><p id="92be" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">例如，考虑下面给出的信号和滤波器。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lm"><img src="../Images/38c44a487b7aa85caa81e15976a16b3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OyqZA06izWEaEXbT26yEag.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">信号和与之卷积的滤波器</figcaption></figure><p id="a790" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后，我们手动实现卷积，并在下面的命令中使用scipy</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="8486" class="ls km hi lo b fi lt lu l lv lw">convolve(sig,win[::-1],'same')</span></pre><p id="7912" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">结果绘制如下。建议读者通过目测图表或自己实施这两种方法来说服自己结果是相同的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/4164bef00765f68bad46f89f5c0fcbd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_jdeNo0TDHC_1IJ08yr7uw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">手动和手动卷积的结果。</figcaption></figure><p id="270a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们现在准备使用numpy实现CNN。</p><h1 id="68d8" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">两级分类</h1><p id="7464" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">作为我们的第一个例子，我们使用numpy实现了两个类的分类。我会详细讨论这一点，对于后面帖子中的其他示例，我希望读者已经详细理解了这个示例，并且理解得更快一些。</p><p id="6380" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于数据，我们将使用时尚MNIST。我们从Keras那里得到这个，因为它很容易得到，但是请注意这是Keras在这篇文章中的唯一用途。</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="d270" class="ls km hi lo b fi lt lu l lv lw">(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()</span></pre><p id="f2fa" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后我们将数据集限制在第1类和第3类。</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="633f" class="ls km hi lo b fi lt lu l lv lw">cond=np.any([y_train_full==1,y_train_full==3],0)</span><span id="c911" class="ls km hi lo b fi ly lu l lv lw">X_train_full=X_train_full[cond]<br/>y_train_full=y_train_full[cond]<br/>X_test=X_test[np.any([y_test==1,y_test==3],0)]<br/>y_test=y_test[np.any([y_test==1,y_test==3],0)]</span><span id="cb06" class="ls km hi lo b fi ly lu l lv lw">y_train_full=(y_train_full==3).astype(int)<br/>y_test=(y_test==3).astype(int)</span></pre><p id="468d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后，我们将训练集分成训练集和验证集</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="e5d4" class="ls km hi lo b fi lt lu l lv lw">X_train, X_valid = X_train_full[:-1000], X_train_full[-1000:]<br/>y_train, y_valid = y_train_full[:-1000], y_train_full[-1000:]</span></pre><p id="d510" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">最后，我们将数据标准化，因为神经网络最适合处理平均值和单位标准偏差为零的数据。</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="ea63" class="ls km hi lo b fi lt lu l lv lw">X_mean = X_train.mean(axis=0, keepdims=True)<br/>X_std = X_train.std(axis=0, keepdims=True) + 1e-7<br/>X_train = (X_train - X_mean) / X_std<br/>X_valid = (X_valid - X_mean) / X_std<br/>X_test = (X_test - X_mean) / X_std</span></pre><p id="501e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们的数据是单色图像，以L×L(这里L=28)的矩阵形式出现。为了简单起见，我们只有一个卷积层(我们将在后面的文章中放宽这一限制)，它是一个大小为K×K(在我们的例子中我们取K=3)的矩阵，其权重可以学习。此外，我们还有一个密集层，它是一个大小为(L*L) x 1的矩阵。注意，我们没有保留偏见术语，一旦读者理解了这个例子，就可以把它们作为练习。</p><p id="279e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们现在详细描述正向传递、误差和反向传播。</p><h2 id="0bc5" class="ls km hi bd kn lz ma mb kr mc md me kv jx mf mg kx kb mh mi kz kf mj mk lb ml bi translated">前进传球</h2><ul class=""><li id="9702" class="mm mn hi jq b jr ld ju le jx mo kb mp kf mq kj mr ms mt mu bi translated">我们得到的图像，并将其作为第0层𝑙</li><li id="cfac" class="mm mn hi jq b jr mv ju mw jx mx kb my kf mz kj mr ms mt mu bi translated">我们将居中的图像嵌入到大小为(<em class="kk"> 𝐿 </em> + <em class="kk"> 𝐾 </em>，<em class="kk"> 𝐿 </em> + <em class="kk"> 𝐾 </em>)的图像中，并填充零</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es na"><img src="../Images/18a1898d52bee9954aa9834f78f57d4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*oxBxJWo-D_6YNZA11riGOw.png"/></div></figure><ul class=""><li id="e494" class="mm mn hi jq b jr js ju jv jx nb kb nc kf nd kj mr ms mt mu bi translated">然后，我们将它通过一个卷积层和一个激活函数f1(我们将把它称为Relu)。这是第一层l1。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ne"><img src="../Images/81f583609adc75be772d0db79fe66398.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*mRj5FieFxeD28Gzwf5_oTw.png"/></div></figure><ul class=""><li id="6618" class="mm mn hi jq b jr js ju jv jx nb kb nc kf nd kj mr ms mt mu bi translated">最后，我们制作一个包裹在函数f2中的稠密层(在这种情况下，我们认为它是一个sigmoid函数)。这是第二层l2。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nf"><img src="../Images/a9d556009ba4b5d4ff238dd1c4bff263.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*lc-pgOlNukhSuzer9UGWtA.png"/></div></figure><p id="08f4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kk">请注意，尽管权重W2是针对密集层的，但我们在此处写入的指数没有进行展平，因为它有一个直观的解释，即它取卷积图像的每个像素并进行加权求和。然而，将两者拉平并做一个数字点会更有性能，这就是我们在下面的代码中所做的。</em></p><h2 id="401a" class="ls km hi bd kn lz ma mb kr mc md me kv jx mf mg kx kb mh mi kz kf mj mk lb ml bi translated">损失函数</h2><p id="a45d" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">对于损失函数，我们采用通常的对数损失</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ng"><img src="../Images/b1a160eee45233ac8f062baeb393c8f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EVql7jAxPeu267Ep5kZH2Q.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">损失函数</figcaption></figure><p id="f4c7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">其中y是真实结果。</p><h2 id="bd24" class="ls km hi bd kn lz ma mb kr mc md me kv jx mf mg kx kb mh mi kz kf mj mk lb ml bi translated">反向传播</h2><p id="ce30" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">反向传播只是一个花哨的词，用来表示所有可学习的权重都通过损失函数相对于正在学习的权重的梯度来校正。使用链式法则来区分关于W1和W2的损失函数是很简单的。</p><ul class=""><li id="ff44" class="mm mn hi jq b jr js ju jv jx nb kb nc kf nd kj mr ms mt mu bi translated">损失函数相对于层2的导数为</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nh"><img src="../Images/12c026073412835c90f1d6d379113642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*p57tYr7JHZ3ayI2R2V3DZQ.png"/></div></figure><ul class=""><li id="9c26" class="mm mn hi jq b jr js ju jv jx nb kb nc kf nd kj mr ms mt mu bi translated">损失函数相对于密集层权重的<strong class="jq hj">导数为</strong></li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ni"><img src="../Images/932295a8567db7cd3a997033bb0695dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*9NCbbNHn-2rNEjnOegqRKA.png"/></div></figure><p id="d389" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">其中我们使用了l2是sigmoid函数s(x)的输出以及s'(x)=s(x)(1-s(x))的事实。</p><ul class=""><li id="5efb" class="mm mn hi jq b jr js ju jv jx nb kb nc kf nd kj mr ms mt mu bi translated">类似地，损失函数相对于层1的导数为</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nj"><img src="../Images/8bca4c9ff0d708c2951f05c96342b99a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*LWmhdTSgvxCpXwhG2BP7XA.png"/></div></figure><ul class=""><li id="67d1" class="mm mn hi jq b jr js ju jv jx nb kb nc kf nd kj mr ms mt mu bi translated">损失函数相对于卷积滤波器的<strong class="jq hj">导数为</strong></li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nk"><img src="../Images/8eb733eaa5018211bf128a8d00a1a98a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*w_qmCQGLk_QNdk2hOwM8uw.png"/></div></figure><p id="63be" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，我们已经有了损失函数的导数相对于卷积滤波器的权重以及最终密集矩阵的封闭形式的表达式，因此我们可以将权重(具有学习速率的超参数)更新为</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nl"><img src="../Images/dcb27d2f0ce2aff35361a4997514aa88.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*ygBoi1cKIqy-DAG-D0n7gg.png"/></div></figure><p id="2713" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">就这样。</strong></p><p id="6223" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这就是编写CNN实现所需的全部内容。在此之前，我们首先注意初始随机权重的损失函数和准确性，以便有一个基准。</p><h2 id="bafc" class="ls km hi bd kn lz ma mb kr mc md me kv jx mf mg kx kb mh mi kz kf mj mk lb ml bi translated">训练前的损失和准确性</h2><p id="4e43" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">在训练开始之前，平均损失可以从损失的表达式中分析获得，并且是1。精度为0.5。我们将在五个时期内运行我们的代码，并在测试和验证集上查看损失和准确性。</p><h2 id="3c01" class="ls km hi bd kn lz ma mb kr mc md me kv jx mf mg kx kb mh mi kz kf mj mk lb ml bi translated">代码</h2><p id="6edc" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">首先，我们为Relu、它的导数和sigmoid函数编写一些自定义函数，这是主代码和一个函数所需要的，该函数只进行前向传递，并在验证集上计算损失和精度</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="dec2" class="ls km hi lo b fi lt lu l lv lw">def relu(x):<br/>    return np.where(x&gt;0,x,0)<br/>    <br/>def relu_prime(x):<br/>    return np.where(x&gt;0,1,0)</span><span id="5e9a" class="ls km hi lo b fi ly lu l lv lw">def sigmoid(x):<br/>    return 1./(1.+np.exp(-x))</span><span id="5d11" class="ls km hi lo b fi ly lu l lv lw">def forward_pass(W1,W2,X,y):<br/>    l0=X<br/>    l0_conv=convolve(l0,W1[::-1,::-1],'same','direct')</span><span id="3413" class="ls km hi lo b fi ly lu l lv lw">    l1=relu(l0_conv)</span><span id="a308" class="ls km hi lo b fi ly lu l lv lw">    l2=sigmoid(np.dot(l1.reshape(-1,),W2))<br/>    l2=l2.clip(10**-16,1-10**-16)</span><span id="3461" class="ls km hi lo b fi ly lu l lv lw">    loss=-(y*np.log(l2)+(1-y)*np.log(1-l2))<br/>    accuracy=int(y==np.where(l2&gt;0.5,1,0))</span><span id="ca27" class="ls km hi lo b fi ly lu l lv lw">    return accuracy,loss</span></pre><p id="0b6c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们编写代码的主要部分</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="ad4e" class="ls km hi lo b fi lt lu l lv lw"># learning rate<br/>eta=.001</span><span id="e5a4" class="ls km hi lo b fi ly lu l lv lw">for epoch in range(5):</span><span id="c187" class="ls km hi lo b fi ly lu l lv lw">    # custom code to keep track of quantities to <br/>    # keep a running average. it is not shown for clarity. <br/>    # the reader can implement her own or ask me in the comments.</span><span id="baed" class="ls km hi lo b fi ly lu l lv lw">    train_loss, train accuracy=averager(), averager()<br/>    <br/>    for i in range(len(y_train)):<br/>        <br/>        # Take a random sample from train set<br/>        k=np.random.randint(len(y_train))<br/>        X=X_train[k]<br/>        y=y_train[k]<br/><br/>        ##### FORWARD PASS ######</span><span id="ec96" class="ls km hi lo b fi ly lu l lv lw">        # First layer is just the input<br/>        l0=X<br/>        <br/>        # Embed the image in a bigger image. <br/>        # It would be useful in computing corrections <br/>        # to the convolution filter</span><span id="ebe2" class="ls km hi lo b fi ly lu l lv lw">        lt0=np.zeros((l0.shape[0]+K-1,l0.shape[1]+K-1))<br/>        lt0[K//2:-K//2+1,K//2:-K//2+1]=l0<br/>        <br/>        # convolve with the filter<br/>        # Layer one is Relu applied on the convolution        </span><span id="038d" class="ls km hi lo b fi ly lu l lv lw">        l0_conv=convolve(l0,W1[::-1,::-1],'same','direct')<br/>        l1=relu(l0_conv)</span><span id="3bf1" class="ls km hi lo b fi ly lu l lv lw">        # Compute layer 2<br/>        l2=sigmoid(np.dot(l1.reshape(-1,),W2))<br/>        l2=l2.clip(10**-16,1-10**-16)<br/>        <br/>        ####### LOSS AND ACCURACY #######<br/>        loss=-(y*np.log(l2)+(1-y)*np.log(1-l2))<br/>        accuracy=int(y==np.where(l2&gt;0.5,1,0))<br/>        <br/>        # Save the loss and accuracy to a running averager<br/>        train_loss.send(loss)<br/>        train_accuracy.send(accuracy)</span><span id="9c50" class="ls km hi lo b fi ly lu l lv lw">        ##### BACKPROPAGATION #######<br/>        <br/>        # Derivative of loss wrt the dense layer<br/>        dW2=(((1-y)*l2-y*(1-l2))*l1).reshape(-1,)<br/>        <br/>        # Derivative of loss wrt the output of the first layer<br/>        dl1=(((1-y)*l2-y*(1-l2))*W2).reshape(28,28)<br/>        <br/>        # Derivative of the loss wrt the convolution filter</span><span id="0eb0" class="ls km hi lo b fi ly lu l lv lw">        f1p=relu_prime(l0_conv)<br/>        dl1_f1p=dl1*f1p<br/>        dW1=np.array([[<br/>           (lt0[alpha:+alpha+image_size,beta:beta+image_size]\<br/>           *dl1_f1p).sum() for beta in range(K)<br/>        ]for alpha in range(K)])</span><span id="97be" class="ls km hi lo b fi ly lu l lv lw">        W2+=-eta*dW2<br/>        W1+=-eta*dW1</span><span id="b50b" class="ls km hi lo b fi ly lu l lv lw">    loss_averager_valid=averager()<br/>    accuracy_averager_valid=averager()   <br/>    <br/>    for X,y in zip(X_valid,y_valid):<br/>        accuracy,loss=forward_pass(W1,W2,X,y)<br/>        loss_averager_valid.send(loss)<br/>        accuracy_averager_valid.send(accuracy)<br/>    <br/>    train_loss,train_accuracy,valid_loss,valid_accuracy\<br/>            =map(extract_averager_value,[train_loss,train_accuracy,<br/>                 loss_averager_valid,accuracy_averager_valid])<br/>    <br/>    # code to print losses and accuracies suppressed for clarity</span></pre><p id="076b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我的试运行中，我得到了以下结果。你的应该差不多</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nm"><img src="../Images/35dee857ab08ba32ef83ec1a8f22c1cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HRXfBl8EbFg1do-vN-3ZZw.png"/></div></div></figure><p id="1ce0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们可以看到，即使这个简单的模型也将损失从大约1减少到0.1，并将准确度从0.5增加到大约0.96(在验证集上)。</p><p id="dd24" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们可以通过绘制一些(标准化的)图像以及它们与原始随机滤波器和最终训练的滤波器的卷积来可视化卷积。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nn"><img src="../Images/d02c7f80a73b34b7155b695027744f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*DFFP7YGMY2tRp6SQcNCC9Q.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">使用初始随机滤波器和最终学习滤波器的图像1的卷积</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nn"><img src="../Images/8e9ab4f383a8b282427c50e2842ab710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*2NNIXD0eVkPU5bbpfPBvPQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">使用初始随机滤波器和最终学习滤波器的图像2的卷积</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nn"><img src="../Images/1a5ad32ecf688ca5b27241e349fe4613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*pVhNyMXLN5SMY56cDVnjKA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">使用初始随机滤波器和最终学习滤波器的图像3的卷积</figcaption></figure><p id="1154" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们看到卷积滤波器似乎已经学会了识别右边缘。当我们训练多个过滤器时应该更好，但是我们通过只有一个过滤器来保持事情简单。(这个选择本身就是一个超参数)。在结束这篇文章的第一部分之前，我们还可以做一件事。我们可以制作另外两个模型:1)我们冻结卷积层权重，2)我们冻结密集层权重。这将有助于我们了解这些层是否有助于该过程。这很容易。对于前者，我们注释掉W1的更新行</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="e04d" class="ls km hi lo b fi lt lu l lv lw">W2+=-eta*dW2<br/># W1+=-eta*dW1</span></pre><p id="d411" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于后者，我们注释掉W2的更新行</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="84c3" class="ls km hi lo b fi lt lu l lv lw"># W2+=-eta*dW2<br/>W1+=-eta*dW1</span></pre><p id="2cd6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">由此产生的损耗和精度为</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es no"><img src="../Images/8cc22a0243a3716de12291222efc7c38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5L89EPXdnM1ww7wGwNewxA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">冻结卷积层的性能</figcaption></figure><p id="90ec" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">和</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es np"><img src="../Images/c2b2f588758a08e249466bc68f7c126e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Bx3uizLD3OCnPsytVyPeA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">冻结致密层的性能</figcaption></figure><p id="0629" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">分别是。很明显，大部分工作是由密集层完成的，但我们仍然可以通过卷积层获得0.5的损失和0.8的精度。据推测，随着过滤器数量的增加，这种性能将会提高。我们将在以后的文章中探讨这个问题。</p></div></div>    
</body>
</html>