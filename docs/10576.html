<html>
<head>
<title>Decision Trees: Explained in Simple Steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树:用简单的步骤解释</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/decision-trees-explained-in-simple-steps-39ee1a6b00a2?source=collection_archive---------2-----------------------#2020-10-25">https://medium.com/analytics-vidhya/decision-trees-explained-in-simple-steps-39ee1a6b00a2?source=collection_archive---------2-----------------------#2020-10-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/4ad2b7d08de932c65ec18fd39832dc5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/0*KQUBhmPmWeP8mHQz.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">看不懂这个模因？阅读文章:)</figcaption></figure><h1 id="f42c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">1.介绍</h1><p id="fe7f" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">与上面的迷因不同，当涉及到现实世界的场景时，基于树的算法非常漂亮。决策树是一种<strong class="jq hj">监督的</strong>(标记数据)机器学习算法，可用于<strong class="jq hj">分类和回归问题</strong>。</p><p id="8261" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">它类似于树数据结构，树数据结构有一个根和多个其他类型的节点(父节点、子节点和叶节点)。</p><blockquote class="kr ks kt"><p id="7b87" class="jo jp ku jq b jr km jt ju jv kn jx jy kv ko kb kc kw kp kf kg kx kq kj kk kl hb bi translated"><em class="hi">在下面的例子中，我们必须根据这个人的年龄、工资和孩子的数量来批准贷款。我们在每个节点问一个条件问题，并相应地进行拆分，直到我们在叶节点做出决定(即获得贷款/不获得贷款)。</em></p></blockquote><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ky"><img src="../Images/15a54118b370d86a554942a38d4d8f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4QE-0kavxXfzF_bR.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">简单的决策树</figcaption></figure></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="4261" class="iq ir hi bd is it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn bi translated">2.为什么要用决策树？</h1><h2 id="30c7" class="lt ir hi bd is lu lv lw iw lx ly lz ja jz ma mb je kd mc md ji kh me mf jm mg bi translated">优势</h2><ul class=""><li id="8e70" class="mh mi hi jq b jr js jv jw jz mj kd mk kh ml kl mm mn mo mp bi translated">它们有很高的可解释性，这使得它们成为现实世界商业应用的首选算法。它们可以解释为一系列问题/ if-else 语句<strong class="jq hj">。</strong></li><li id="db91" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated">进行预测所需的<strong class="jq hj">时间非常少</strong>。它只是对给定数据点的一组特定条件的评估。</li><li id="1cfc" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><strong class="jq hj">不需要缺失值插补</strong>，因为算法会相应调整。</li></ul><h2 id="3a31" class="lt ir hi bd is lu lv lw iw lx ly lz ja jz ma mb je kd mc md ji kh me mf jm mg bi translated">不足之处</h2><ul class=""><li id="333e" class="mh mi hi jq b jr js jv jw jz mj kd mk kh ml kl mm mn mo mp bi translated">他们不稳定。数据中的一个小变化会导致一个非常不同的决策树。</li><li id="5065" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated">它们通常相对不准确，并且<strong class="jq hj">容易过度配合</strong>。这可以通过用<strong class="jq hj">决策树的随机森林</strong>替换单个决策树来纠正。</li></ul></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="0568" class="iq ir hi bd is it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn bi translated">3.基本直觉</h1><p id="e251" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">让我们试着用一个例子来建立直觉。我们将采用一个非常受欢迎的方法，根据给定的<strong class="jq hj">天气条件(预测因素)</strong>，我们必须决定是否可以在某一天<strong class="jq hj">打高尔夫球(目标)</strong>。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/fbefd101a06a7f0d4547c839c8e58ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/0*vYQrshQ9cOLPUHzI.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">高尔夫和天气示例</figcaption></figure><p id="668b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在这个例子中，给定的预测值本质上是明确的，目标也是如此。构建决策树的步骤如下-</p><ul class=""><li id="da5c" class="mh mi hi jq b jr km jv kn jz mw kd mx kh my kl mm mn mo mp bi translated">首先，我们选择了<strong class="jq hj"> Outlook </strong>特性作为我们的节点，并为它的每个值创建了拆分。对于<strong class="jq hj">阴天</strong>类别，玩高尔夫(目标)变量的每个结果都是“是”,这基本上意味着无论何时前景阴天，我们都可以玩高尔夫。我们做了一个最终的<strong class="jq hj">决定</strong>，所以我们把它做成一个<strong class="jq hj">叶节点</strong>。</li><li id="60da" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated">对于其余的类别，结果并不像阴云一样明朗，因为它由是和否的混合组成。我们根据其他列，如风或湿度，进一步划分这些节点，直到我们能够做出决定(例如，我们是否可以打高尔夫球)。</li></ul><h2 id="20b1" class="lt ir hi bd is lu lv lw iw lx ly lz ja jz ma mb je kd mc md ji kh me mf jm mg bi translated">看了上面的例子后，可能会出现以下问题:</h2><ul class=""><li id="2713" class="mh mi hi jq b jr js jv jw jz mj kd mk kh ml kl mm mn mo mp bi translated">我们应该先选择哪个<strong class="jq hj">特性</strong>？</li><li id="353b" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated">分裂的<strong class="jq hj">顺序应该是怎样的？</strong></li><li id="be24" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated">我们如何决定子节点的<strong class="jq hj">数量？</strong></li><li id="12e2" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated">我们如何<strong class="jq hj">比较两个特性</strong> w.r.t 哪个更适合拆分？</li><li id="2639" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated">我们如何决定<strong class="jq hj">分割标准</strong>？</li></ul><p id="2993" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这些问题将在下一节中得到回答，在这一节中，我们将看到一个名为<strong class="jq hj"> C4.5 </strong>的算法，它使用了熵和信息增益的概念。</p></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="9846" class="iq ir hi bd is it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn bi translated">4.算法</h1><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es mz"><img src="../Images/78a6248f352853f407bc40da69d5e662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*isIjqcykpG8iiZPk"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">由<a class="ae na" href="https://unsplash.com/@itfeelslikefilm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">🇸🇮·扬科·菲利</a>在<a class="ae na" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="c0ff" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">有<strong class="jq hj">多种算法</strong>(名字很长，很吓人)用于构建决策树。其中一些是:</p><ul class=""><li id="63f3" class="mh mi hi jq b jr km jv kn jz mw kd mx kh my kl mm mn mo mp bi translated"><a class="ae na" href="https://en.wikipedia.org/wiki/ID3_algorithm" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj">ID3</strong></a><strong class="jq hj"/>(迭代二分法 3)</li><li id="2723" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><a class="ae na" href="https://en.wikipedia.org/wiki/C4.5_algorithm" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"/></a><strong class="jq hj"/>(ID3 的继承者)</li><li id="7f21" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><a class="ae na" href="https://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees_.28CART.29" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"/></a>(分类和回归树)</li><li id="af08" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><a class="ae na" href="https://en.wikipedia.org/wiki/Chi-square_automatic_interaction_detection" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj">卡方自动交互检测</strong> </a> (CHAID)。计算分类树时执行多级拆分。</li><li id="c495" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><a class="ae na" href="https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj"> MARS </strong> </a>:扩展决策树，更好地处理数值数据。</li></ul><p id="11c6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们现在将重点放在<strong class="jq hj"> C4.5 </strong>上，因为它很流行，能够处理分类和数字特征。在我们深入算法之前，我们需要知道某些术语的<strong class="jq hj">含义:</strong></p><ul class=""><li id="e9ec" class="mh mi hi jq b jr km jv kn jz mw kd mx kh my kl mm mn mo mp bi translated"><strong class="jq hj"> <em class="ku">根节点</em> </strong>:树中最顶端的节点。</li><li id="6aaa" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><strong class="jq hj"> <em class="ku">叶子/终端节点</em> </strong>:不分裂的节点称为叶子或终端节点</li><li id="5e0c" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><strong class="jq hj"> <em class="ku">拆分</em> </strong>:是将一个节点分成两个或两个以上子节点的过程。</li><li id="a296" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><strong class="jq hj"> <em class="ku">父子节点</em> </strong>:一个节点被划分为子节点，称为子节点的父节点<strong class="jq hj"> </strong>，子节点是父节点的子节点。</li><li id="2748" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><strong class="jq hj"> <em class="ku">决策节点</em> </strong>:当一个子节点分裂成更多的子节点时，则称之为决策节点。</li></ul><h2 id="36f9" class="lt ir hi bd is lu lv lw iw lx ly lz ja jz ma mb je kd mc md ji kh me mf jm mg bi translated">C4.5 算法特有的一些更重要的术语</h2><h1 id="7c61" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">熵</h1><p id="6d30" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">物理学中的熵只是一种度量系统无序或随机程度的尺度。</p><blockquote class="kr ks kt"><p id="2900" class="jo jp ku jq b jr km jt ju jv kn jx jy kv ko kb kc kw kp kf kg kx kq kj kk kl hb bi translated"><em class="hi">在决策树的上下文中，它可以被认为是预测目标的无序或不确定性的度量。让我们以盒子里的红色、蓝色和绿色的球为例。一个有 6 个蓝色球的盒子将具有非常低(零)的熵，而一个有 2 个蓝色球、2 个绿色球和 2 个红色球的盒子将具有相对高的熵。</em></p></blockquote><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/365c38d463b0ae9c535a1e56b05c52b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/0*UcggVi79TaIHfprO.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">计算具有 C 个类的数据集的信息熵的公式:</figcaption></figure><p id="7fd7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">其中<strong class="jq hj"> pᵢ </strong>是随机选取类<strong class="jq hj"> i </strong>元素的概率(即由类 I 组成的数据集的比例)。</p><p id="4d0c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">让我们举个例子来更好地理解这一点。考虑一个有 1 个蓝色球、2 个绿色球和 3 个红色球的数据集，然后:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/f1c0aa809da95f9c9f699ab51e394754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/0*2Rj4osVD1Bvrc48V.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">扩展了原始公式以显示数据集中的三个类</figcaption></figure><p id="0c2f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们知道<strong class="jq hj"> pb </strong> = 1/6(蓝色)，因为数据集的 1/6 是蓝色的。同样，<strong class="jq hj"> pg </strong> = 2/6(绿色)，而<strong class="jq hj"> pr </strong> = 3/6(红色)。因此，</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/c74152f28b932291df90422aa664db0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/0*cUVcKfKXPMnZ8MZF.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">1 个蓝色球、2 个绿色球和 3 个红色球的熵</figcaption></figure><p id="d4d5" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">然而，对于只包含蓝色球的数据集，熵将是:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es ne"><img src="../Images/9329738fd469d3a8cca17ef5dea84346.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/0*D7CRZyDKnaAi3_EH.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">只有蓝色球的熵</figcaption></figure><h1 id="e396" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">信息增益</h1><p id="a41f" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">信息增益是一种度量，它帮助我们确定给定的一组训练特征向量中的哪个属性对于区分目标类最有用。我们用它来决定属性在决策树节点中的排序。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es nf"><img src="../Images/1bc5fcf7bef6ab1104cc7eb3b36669f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PJv_wGvRdC6c5F02.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">信息增益的公式</figcaption></figure><p id="d454" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这个获取信息的公式非常直观。我们来看看父母和孩子的熵之间的差异。熵的大幅减少是好事，因为我们能够更好地区分目标类别。这仅仅意味着我们选择具有最高信息增益的特征。</p><h1 id="022e" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">C4.5 算法的步骤</h1><p id="cf22" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">C4.5 是一种递归算法，因为它递归地选取给出最大信息增益的特征，并使用它来进一步分割树。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ng"><img src="../Images/c8b10aa55fa6020edcfb2939b490c994.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jZyKO7PbFmrjX5lL.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">解释算法步骤的简单流程图</figcaption></figure><ol class=""><li id="6b60" class="mh mi hi jq b jr km jv kn jz mw kd mx kh my kl nh mn mo mp bi translated">选择定义了<strong class="jq hj">特征和目标属性</strong>的初始数据集。</li><li id="b941" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl nh mn mo mp bi translated"><strong class="jq hj">计算每个属性的信息增益和熵</strong>。</li><li id="442e" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl nh mn mo mp bi translated"><strong class="jq hj">挑选信息增益最高的属性</strong>，作为决策根节点。</li><li id="0ac5" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl nh mn mo mp bi translated">计算剩余属性的<strong class="jq hj">信息增益。</strong></li><li id="1f1c" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl nh mn mo mp bi translated">通过在决策节点开始拆分来创建<strong class="jq hj">循环子节点</strong>(即，对于决策节点的各种值，创建单独的子节点)。</li><li id="3033" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl nh mn mo mp bi translated"><strong class="jq hj">重复这个过程</strong>，直到覆盖所有属性。</li><li id="2021" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl nh mn mo mp bi translated"><strong class="jq hj">修剪圣诞树</strong>以防止过度修剪。</li></ol><p id="ea0c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这就是 C4.5 算法。</p><p id="e8ae" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这篇文章的内容是互联网上各种来源的信息的混合体，结合了我对它们的理解。</p><p id="4a68" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">参考资料:</p><ul class=""><li id="0314" class="mh mi hi jq b jr km jv kn jz mw kd mx kh my kl mm mn mo mp bi translated"><a class="ae na" href="https://en.wikipedia.org/wiki/C4.5_algorithm" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/C4.5_algorithm</a></li><li id="e5ed" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><a class="ae na" href="https://saiconference.com/Downloads/SpecialIssueNo10/Paper_3-A_comparative_study_of_decision_tree_ID3_and_C4.5.pdf" rel="noopener ugc nofollow" target="_blank">https://saiconference . com/Downloads/specialissueno 10/Paper _ 3-A _ comparative _ study _ of _ decision _ tree _ ID3 _ and _ c 4.5 . pdf</a></li><li id="99db" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><a class="ae na" href="https://uh.edu/~smiertsc/4397cis/C4.5_Decision_Tree_Algorithm.pdf" rel="noopener ugc nofollow" target="_blank">https://uh . edu/~ smiertsc/4397 cis/c 4.5 _ Decision _ Tree _ algorithm . pdf</a></li><li id="912b" class="mh mi hi jq b jr mq jv mr jz ms kd mt kh mu kl mm mn mo mp bi translated"><a class="ae na" href="https://towardsdatascience.com/what-is-the-c4-5-algorithm-and-how-does-it-work-2b971a9e7db0" rel="noopener" target="_blank">https://towards data science . com/what-the-C4-5-algorithm-and-how-it-work-2b 971 a9 e 7 db 0</a></li></ul><p id="2779" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果你喜欢这篇文章，请给它鼓掌，并确保在评论中留下任何反馈/建议/问题:)</p><p id="4921" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">长寿兴旺</strong></p></div></div>    
</body>
</html>