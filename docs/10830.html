<html>
<head>
<title>Natural Language Processing (NLP) Project Example for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向初学者的自然语言处理(NLP)项目示例</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/natural-language-processing-nlp-project-example-for-beginners-616549300c54?source=collection_archive---------3-----------------------#2020-11-04">https://medium.com/analytics-vidhya/natural-language-processing-nlp-project-example-for-beginners-616549300c54?source=collection_archive---------3-----------------------#2020-11-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/316d3eaf1c6e780394d369009c4ef3c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cSGyGYA2BiB2jqznbNWRQg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">鸣谢:埃琳娜·莱西——盖蒂图片社</figcaption></figure><h1 id="1683" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">指令</h1><p id="d3cf" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">当感兴趣的领域变成机器学习时，它就采取步骤进行各种研究。这些调查可能需要很长时间。但是如果你继续不放弃，过一段时间，就会有你没有注意到的步骤和你思考的细节。</p><p id="fb24" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">作为一个已经采取了其中一些步骤的人，我想分享一个我已经完成的简单但有指导意义的机器学习项目，特别是对初学者来说。</p><p id="f1e7" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">这个示例应用程序是 Kaggle 上发布的竞赛。简单解释一下:它在 Twitter 上发布各种推文。这些是关于严肃的问题、笑话、批评、侮辱、灾难等等。</p><p id="b48a" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">Kaggle 提供的数据集包括许多推文。在为测试准备的数据集中有 3243 个唯一数据，在训练数据集中有 7503 个唯一数据。在训练和测试数据集中有 id、关键字、位置、文本(tweeted)列。我们将进行各种开发，以改进对列车数据集的预测。因此，有一个目标列将有利于我们作为一个加号。测试数据集中还没有目标列，我们将创建这个列，看看我们能猜得多好。</p><p id="951d" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">训练数据集中有目标列 1 和 0 数据。因此，我们有一个目标列，其中的分类变量包含离散值。如果 Target = 1，则同一列中的推文是灾难推文。如果 Target = 0，则同一列中的推文不是灾难推文。</p><p id="271d" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">这个问题是一个 NLP 问题，我们需要预测的数据只有 1 或 0，这意味着我们可以使用分类算法作为解决方案。更多信息在步骤 8 中。</p><p id="42f9" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated"><em class="kv">竞争在这里:</em> <a class="ae kw" href="https://www.kaggle.com/c/nlp-getting-started" rel="noopener ugc nofollow" target="_blank"> <em class="kv">真实与否？NLP 与灾难推文</em> </a></p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/e2a30a74d5c70a9266ba598419b28274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ixAAGTu3oChj8dfAsv1tZg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">鸣谢:Getty Images</figcaption></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="44ac" class="iu iv hi bd iw ix lj iz ja jb lk jd je jf ll jh ji jj lm jl jm jn ln jp jq jr bi translated">步骤 1:连接数据集以使其可用</h1><p id="1104" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">训练集和测试集是分开的，但是在训练期间对单个数据集进行操作更准确和有效。因此，作为第一步，我们必须合并数据集。这样做时，目标列已被删除，但稍后会被添加回去。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="2857" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">步骤 2:可视化数据</h1><p id="6b70" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">直观地表达数据有助于更好地理解所处理的主题。</p><p id="8d34" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">Python 中有很多模块和方法可用于数据可视化。我选择了一个简单的方法，字云。使用单词云可以突出显示重要的单词。在这种方法中，单词的大小根据使用频率而变大或变小。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/516b9f8e3bf0cfe1054ccac3c45a236d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jtAkq18OKP0QRikpUsmerw.png"/></div></div></figure><h1 id="a692" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">第三步:清理正文</h1><p id="5f3f" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">在有文字的交易中，要突出能触及具体问题的文字。删除不必要的、无意义的或无意义的对猜测没有帮助的词，让我们更容易对推文进行分类。</p><p id="68d3" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">其中最重要的是<strong class="ju hj"> <em class="kv">停用词</em> </strong>。停用词是一种语言中的一组常用词，因为无效而从搜索引擎查询中删除。Python 中有一个<strong class="ju hj"> <em class="kv"> NLTK </em> </strong>模块列出了停用词。</p><p id="5c7f" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">Twitter 平台上有太多非字母数字的有意义或无意义的字符，这是人们可以立即写下想法的预期情况。以及这些字符、邮件地址、共享链接等。结构也是可用的。<em class="kv">摆脱这些结构会提高我们的效率和表现，对吗？那么我们该怎么办呢？</em>我们编写了<strong class="ju hj"> <em class="kv">正则表达式</em> </strong>的等价物，并在 replace 函数中使用它来查找和删除这些不必要或无意义的结构。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="1c70" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">第四步:删除无用的列</strong></h1><p id="88bc" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">数据集中的位置和 id 列对我们的预测没有帮助。因此，删除了位置和 id 列。</p><p id="a4b7" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">Keyword 是一个专栏，其中的推文根据其包含的主题进行标记。因此，对它进行编码会更有效，这样它就可以通过分类过程，而不是删除它。让我们首先看看关键字列中唯一数据的数量，并相应地选择一种编码解决方案；</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><p id="31ff" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">我们得到结果<strong class="ju hj"> <em class="kv"> (221，)</em> </strong>。换句话说，关键字列中有 221 个唯一数据。</p><p id="bd15" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">打印关键字列中的标签/类别；</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/f39afa9ee6d53e60ea679234ce62a905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*lL9YB4iX7JE73bvc-oe4xw.png"/></div></figure><p id="05d3" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">让我们回顾一下我们可以做些什么:</p><ol class=""><li id="9e58" class="ls lt hi ju b jv kq jz kr kd lu kh lv kl lw kp lx ly lz ma bi translated"><strong class="ju hj"> <em class="kv">标签编码器</em> </strong>可能是该问题的合适解决方案，但是标签编码器通常在基于树的算法上工作良好，我们将不使用基于树的算法。</li><li id="c4be" class="ls lt hi ju b jv mb jz mc kd md kh me kl mf kp lx ly lz ma bi translated"><strong class="ju hj"> <em class="kv">一键编码</em> </strong>占用大量内存，因为这意味着为每个数据添加列</li><li id="781a" class="ls lt hi ju b jv mb jz mc kd md kh me kl mf kp lx ly lz ma bi translated">就目前而言，最好的解决方案看起来像是<strong class="ju hj"> <em class="kv">二进制编码</em> </strong>。当有很多类别时，二进制编码非常有效。这是一种更有效的内存使用方法，因为它使用的功能比一键编码少。</li></ol><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/4e7eaad1d8fa5cccafb5635deedb488a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oc2K-q7NlfcXsp68iXmViw.png"/></div></div></figure><h1 id="3d88" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">步骤 5: <strong class="ak">分析单词</strong>和文档频率</h1><p id="4f57" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">在数据挖掘和 NLP 问题中，有一些统计方法用于测量称为文档的文本组。这种计算权重因子的方法名字叫做<strong class="ju hj"> <em class="kv"> TF-IDF(词频—逆文档频)。</em> </strong></p><p id="70e6" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated"><strong class="ju hj"> TF(术语频率):</strong>测量术语在文档中出现的频率。这个计算实际上是一个归一化的过程。因为每个文档的长度不同，一个术语可能在长文档中出现得更频繁，一个术语可能在长文档中出现得更频繁。如果我们查看所有文档中的所有术语，归一化对于计算术语频率变得至关重要。因此，术语在文档中出现的次数除以文档中的术语总数。</p><blockquote class="mh mi mj"><p id="69fc" class="js jt kv ju b jv kq jx jy jz kr kb kc mk ks kf kg ml kt kj kk mm ku kn ko kp hb bi translated">TF =(术语在文档中出现的次数)/(文档中的总术语数)</p></blockquote><p id="18a7" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated"><strong class="ju hj"> IDF(逆文档频率):</strong>简而言之，衡量术语的重要性。根据这种计算，几乎所有文档中的单词以及大多数充当连词的单词都不重要。很少使用或独特的单词很重要，并且具有很高的 IDF 值。</p><blockquote class="mh mi mj"><p id="7605" class="js jt kv ju b jv kq jx jy jz kr kb kc mk ks kf kg ml kt kj kk mm ku kn ko kp hb bi translated">IDF = log_e(文档总数/包含术语的文档数)</p></blockquote><p id="86ca" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">我们来想一个例句，命名为‘猫’。包含术语“cat”的文档数量越多，TF-IDF 值越低。此外，cat 术语在自己的文档中出现得越多，TF-IDF 值就越高。</p><p id="b971" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">在 Python 中，<strong class="ju hj"> <em class="kv">计数矢量器</em> </strong>用于 TF-IDF 操作；</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="d265" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">第六步:不平衡数据集控制</strong></h1><p id="9e2a" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">需要开发具有不平衡类别的数据集的预测模型。不平衡数据集会对基于分类的预测模型的结果产生不利影响。虽然该模型可以很好地预测较大的类，但它会对构成少数的数据类做出不好的预测，它会忽略少数类。</p><p id="98e3" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">如果我们看看我们的模型，它没有一个极度不平衡的阶级。但是仍然存在影响预测模型的不平衡；</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/6e01e475c2206ed9bc3f187b6eec0524.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*tfOYxmi9pNz7IYYk9Pl4Wg.png"/></div></div></figure><p id="6fe8" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">解决这个问题最常见的方法是称为<strong class="ju hj"> <em class="kv">重采样</em> </strong>的方法。这是一种快速而简单的技术。重采样技术分为两种；通过向少数类添加样本或从多数类中移除样本，使数据集达到更平衡的水平。</p><ul class=""><li id="f11c" class="ls lt hi ju b jv kq jz kr kd lu kh lv kl lw kp mo ly lz ma bi translated"><strong class="ju hj">过采样:</strong>该方法将样本的副本添加到被视为少数的类中，从而产生一个平衡的数据集。</li><li id="405e" class="ls lt hi ju b jv mb jz mc kd md kh me kl mf kp mo ly lz ma bi translated"><strong class="ju hj">欠采样:</strong>该方法通过使用各种方法删除大部分样本来提供平衡的数据集。</li></ul><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/07aeb8d61f17d9769fc2ad5701a1f905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7WmV_lWzRIMfg9GfnW6l6g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">欠采样和过采样</figcaption></figure><p id="0bfe" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">通过对分类模型进行过采样，我们可以得到一个更加平衡的数据集。Python 的名为<em class="kv">不平衡学习(imblearn) </em>的包可以用于过采样。使用了 imblearn 包中的 SMOTE 方法。</p><p id="e6e5" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated"><strong class="ju hj"> <em class="kv"> SMOTE(合成少数过采样技术):</em> </strong>通过少数类中已经存在的样本的邻域来复制附近的样本。SMOTE 查找少数类中每个样本的 K 个最近邻。然后，在连接原始样本和检测到的相邻样本的线上添加新的数据点。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/6a53bdf99079d9e47dc6f4955637b2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P1puq36Ccl0wApPiFdJbhA.png"/></div></div></figure><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/6fdc4bf0605c159e5c289e7619c24db8.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*2gkVN-3GvddWt6H20GPIEg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">SMOTE 的输出。</figcaption></figure><h1 id="85aa" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">第七步:<strong class="ak">拆分</strong>数据</h1><p id="b938" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">通过各种过程传递数据，如删除、编码。这为分类提供了更有效的环境。这对于良好的预测性能是必要的。</p><p id="5f82" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">在所有这些操作的最开始，我们组合了训练和测试数据集，并创建了 all_data 数据帧。现在是时候再次获取训练和测试数据集了。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="096f" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">第八步:<strong class="ak">型号选择</strong></h1><p id="a4ec" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">如果有必要从一个很基本的问题开始，<em class="kv">学习模型的目的是什么？</em>我们试图用各种数学学习算法为我们拥有的数据找到最佳模式。有了我们的训练集，它可以帮助我们找到需要的模式。当我们找到最接近的模式，即学习模型时，我们就在测试集中获得了成功的结果。</p><p id="b340" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">在文章的开头，我们说明了使用分类算法(一种监督学习方法)来解决这个问题是合适的。</p><p id="138f" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">选择模型时，有时尝试几个模型是很好的。因此，可以观察到哪个模型给出更好的结果。我已经用朴素贝叶斯、随机森林和 SVM 测试了我的模型的性能。结果，我用<strong class="ju hj"> <em class="kv">【支持向量机】</em> </strong>得到了最好的预测数据。我建议你也做这些试验。除了达到最好的结果，我们还获得了经验。随着经验的积累，机器学习领域变得更容易理解，就像在许多其他领域一样。随着你的实验，你的头脑中可以有更多不同的和实际的想法。</p><p id="27b7" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated"><strong class="ju hj"> SVM(支持向量机):</strong>表示不能线性分离的数据集。一条曲线可以将这两个类别分开，但不是直线。像大多数真实世界的数据集一样，它代表一个线性不可分的数据集。我们可以把这些数据导出到一个更高维的空间，比如映射到一个三维空间。转换后，桥可以定义两个类别之间的边界。由于我们现在是在三维空间中，我们把它表示为一个分离的平面。</p><p id="3ad0" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">该平面可用于分类新的或未知的目标数据。因此，SVM 算法生成一个分类新样本的最佳超平面。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ms"><img src="../Images/302898ce06600d7a73397d8fbc2a8e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Xc-CeinxpV078Ozt3R-lQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">SVM 算法</figcaption></figure><p id="33b3" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">该视频将有助于更好的视觉理解:</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="mt lp l"/></div></figure><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="be4b" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">步骤 9:计算模型的准确性</h1><p id="88d5" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">在训练了我们的模型之后，我们在测试集中进行了目标预测。那么，这些预测有多少是正确的呢？在我们计算准确度之后，如果我们获得不期望的低结果，它将被返回以处理数据并被审查。数据被尝试优化用于预测模型，或者我们改变模型。在 Python 中，精确度分数是通过 sklearn 库中的 accuracy_score 度量来计算的。准确度分数取 1 到 0 之间的值。准确度分数在 1 时达到最佳值，在 0 时达到最差值。我们将用百分比来表示准确度分数。</p><p id="b2f4" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">它可以用于混淆矩阵，作为获得分类器精度的方法之一。该矩阵显示了与真实标签相比的正确和不正确的估计。每个混淆矩阵行显示测试集中的正确标签，列显示分类器估计的标签。这种方法叫做<strong class="ju hj"><em class="kv">F1——得分</em> </strong>。我们可以更清楚地看到哪个类有多少实例预测正确，有多少实例预测错误。</p><p id="2745" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">如果我们需要重新安排我们的数据集或选择另一个模型，我们将在这一步理解。因此，如果我们在这一步不能得到我们想要的结果，很可能我们将重复前面所有的步骤。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lo lp l"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es mu"><img src="../Images/a4ba4739f4f4daacdd2c29c354762928.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*K7_1bFNmeM381CRHzhPmzw.png"/></div></figure><p id="7c8a" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">预测结果出来了 99.15%。这是一个好结果。</p><p id="e0a8" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated"><strong class="ju hj">表格解读:</strong>根据 F1 评分表，目标值为 1 的样本中有 10 个样本被估算为 0，991 为 1。换句话说，在 10 条推特上出现了错误的猜测。目标值为 0 的样本中有 7 个被估计为 1，992 个被估计为 0。换句话说，超过 7 条推文做出了错误的猜测。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/379eb5c38f641a0b686e7411c9ac159c.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/1*mTJDoMU6LGQl3PiVWu6cRw.gif"/></div></figure><h1 id="c6ee" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">结论</h1><p id="ac64" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">以下是我们从取得成功的结论中得出的总结:</p><ul class=""><li id="7226" class="ls lt hi ju b jv kq jz kr kd lu kh lv kl lw kp mo ly lz ma bi translated">当你遇到一个需要解决的问题时，先复习资料，试着了解问题的大概轮廓。通过这种方式，您将了解可以使用哪些模型。</li><li id="9a20" class="ls lt hi ju b jv mb jz mc kd md kh me kl mf kp mo ly lz ma bi translated">不要害怕将你拥有的数据形象化，这会让你更好地理解这些数据。</li><li id="6e29" class="ls lt hi ju b jv mb jz mc kd md kh me kl mf kp mo ly lz ma bi translated">如果你正在处理文本(就像我们正在处理的这个例子)。思考在猜测阶段对你有帮助的单词，并努力突出那些对你将得到的结果有发言权的单词或词组。我们可以简称其为<em class="kv">清理正文</em>。</li><li id="19c2" class="ls lt hi ju b jv mb jz mc kd md kh me kl mf kp mo ly lz ma bi translated">如果可以对数据进行分类，请检查数据集是平衡的还是不平衡的。它会成为一个严重影响结果的问题。</li><li id="f1bb" class="ls lt hi ju b jv mb jz mc kd md kh me kl mf kp mo ly lz ma bi translated">在为模型准备数据或选择模型时，不要犹豫尝试。如果你添加的一个步骤严重影响了结果，那就删除它，然后考虑另一个选择。如果你真的有耐心，机器学习是一个你可以前进的领域。</li></ul><p id="060e" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated"><strong class="ju hj">感谢您的阅读！！</strong></p></div></div>    
</body>
</html>