<html>
<head>
<title>Machine Learning: Simple Linear Regression Using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习:使用Python的简单线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-simple-linear-regression-using-python-7d13e8ac8300?source=collection_archive---------13-----------------------#2020-09-30">https://medium.com/analytics-vidhya/machine-learning-simple-linear-regression-using-python-7d13e8ac8300?source=collection_archive---------13-----------------------#2020-09-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ea51f2310021edb7447eff71989a60a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lv496Bftwqj-548Z.jpg"/></div></div></figure><p id="3fd1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随着经验和年龄的增长，我们人类会变得更好。想知道机器如何在数据科学领域变得更好吗？数据建模使用机器学习算法，其中机器从历史数据中学习，以开发一个模型来预测新数据。</p><p id="bf8b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">机器学习模型分为两类:</p><ol class=""><li id="05b1" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">监督学习法</strong>:这种方法有带标签的历史数据。回归和分类算法属于这一类。</li><li id="6cef" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">无监督学习方法</strong>:没有给历史数据分配预定义的标签。聚类算法属于这一类。</li></ol><p id="6854" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当函数f从输入变量X映射到输出变量Y时:</p><p id="20eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="kc">分类算法</em>的任务是预测离散的类别标签。<br/>例如，电子邮件或文本可以被分类为属于两类之一:“垃圾邮件”和“非垃圾邮件”是一个分类问题。</p><p id="7e91" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="kc">回归算法</em>是预测一个连续量的任务。<br/>例如，根据历史数据预测一家公司在收入方面的表现就是一个回归问题。</p><p id="22bd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解更多关于机器学习中模型的分类，你可以点击我的文章<a class="ae kd" rel="noopener" href="/analytics-vidhya/parametric-and-nonparametric-models-in-machine-learning-a9f63999e233">这里</a>。</p><h2 id="7301" class="ke kf hi bd kg kh ki kj kk kl km kn ko jb kp kq kr jf ks kt ku jj kv kw kx ky bi translated">什么是回归分析，什么时候可以用？</h2><p id="89c5" class="pw-post-body-paragraph iq ir hi is b it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj ld jl jm jn hb bi translated">回归分析是一种预测建模方法，它探索了因变量(目标变量)和预测变量之间的关系。这种方法用于预测、建模时间序列以及寻找变量之间的因果关系。换句话说，回归就是把变量之间的点连接起来。</p><p id="a8a7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如，如果一家公司必须雇用一名员工并协商工资，那么它会考虑<strong class="is hj">的特征</strong>，如经验、教育水平、角色、他们工作的城市等等。在一个回归问题案例中，我们将公司的每个员工相关数据视为一个<strong class="is hj">观察值。</strong></p><blockquote class="le lf lg"><p id="93ac" class="iq ir kc is b it iu iv iw ix iy iz ja lh jc jd je li jg jh ji lj jk jl jm jn hb bi translated">为了更容易理解，我们可以把它理解为<strong class="is hj"> : </strong></p><p id="192b" class="iq ir kc is b it iu iv iw ix iy iz ja lh jc jd je li jg jh ji lj jk jl jm jn hb bi translated">在回归分析中，我们通常会考虑一些感兴趣的现象并有一些观察值。每个观察值有两个或多个特征。遵循(至少)一个特征依赖于其他特征的假设，我们试图在它们之间建立一种关系。</p></blockquote><p id="c121" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">包括我自己在内的人们在学习数据科学算法时，可能经常会觉得线性和逻辑回归是唯一的回归形式，但重要的是要知道在预测建模领域有几种类型的技术:</p><ol class=""><li id="3ba8" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">简单和多元线性回归</li><li id="6079" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">多项式回归</li><li id="39fa" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">岭回归和套索回归(线性回归的升级)</li><li id="c6d5" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">决策树回归</li><li id="7eca" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">支持向量机(SVM)</li></ol><p id="a5dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇文章中，让我们把我们的学习限制在对简单线性回归的透彻理解上，这是一种重要且常用的回归技术。</p><p id="a9d3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了在变量之间的线性关系的粒度级别上获得我们的基础知识，最好加入像“<em class="kc">这样的词，展示两个相关量</em>成正比的变化。</p><p id="51ee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注:基于维度的线性回归模型:<br/>在二维是一条<em class="kc">直线</em> <br/>在三维是一个<em class="kc">平面；</em> <br/>在三维以上，一个<em class="kc">超平面</em>。</p><h1 id="7c58" class="lk kf hi bd kg ll lm ln kk lo lp lq ko lr ls lt kr lu lv lw ku lx ly lz kx ma bi translated">Y=a+bx</h1><p id="76e0" class="pw-post-body-paragraph iq ir hi is b it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj ld jl jm jn hb bi translated"><strong class="is hj">线性函数</strong>有一个自变量和一个因变量。自变量为<strong class="is hj"> <em class="kc"> x </em> </strong>，因变量为<strong class="is hj"> <em class="kc"> y </em> </strong>。</p><ul class=""><li id="da7c" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn mb ju jv jw bi translated"><strong class="is hj"> <em class="kc"> a </em> </strong>是常数项或y截距。是<strong class="is hj"> <em class="kc"> x </em> </strong> = 0时因变量的值。</li><li id="cd9d" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn mb ju jv jw bi translated"><strong class="is hj"> <em class="kc"> b </em> </strong>是自变量的系数。它也被称为斜率，给出了因变量的变化率。</li></ul><p id="ef34" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们用工资预测数据集来建立线性回归模型。<br/>这里有一个到<a class="ae kd" href="https://www.kaggle.com/karthickveerakumar/salary-data-simple-linear-regression" rel="noopener ugc nofollow" target="_blank">数据集</a>的链接供参考。</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="8bc6" class="ke kf hi mh b fi ml mm l mn mo">#importing the libraries</span><span id="42b5" class="ke kf hi mh b fi mp mm l mn mo">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="4378" class="ke kf hi mh b fi mp mm l mn mo">dataset.describe()</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mq"><img src="../Images/e71c587064098aceb7b674a4bf884e0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*1Ff5doxzJhYEHsyBuOGoOg.png"/></div></figure><p id="0aad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将事实形象化总比盲目地将等式记在脑子里要好，对吧！我们可以用散点图来看两个变量是如何分布的吗？让我们将数据点绘制在二维图上，以查看我们的数据集，并看看我们是否能发现值之间的任何关系。</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="8f96" class="ke kf hi mh b fi ml mm l mn mo">dataset.plot(x=’YearsExperience’, y=’Salary’, style=’o’)<br/>plt.title(‘Work Experience vs Salary’)<br/>plt.xlabel(‘Experience’)<br/>plt.ylabel(‘Salary’)<br/>plt.show()</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/2919004793b7dce126e70ff8d5ebd5dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*DPg1Lb7PJ930x5lbJVH2bg.png"/></div></figure><p id="1b4f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">人们很容易引用“工资随着工作经验年限的增加而增加”这句话。但是从上面的图表来看，情况并非如此，我们可以注意到，3年经验的人比5年经验的人挣得多！！。这就是我们的失望之处，所有的观察都不在一条线上。也就是说，我们找不到计算(y)值的方程式。:(</p><p id="4b20" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">哦，等等，没我们想的那么糟，所以别担心。现在，再次仔细观察散点图。你看到什么模式了吗？所有点不在一条直线上，但它们在一条直线上！ <strong class="is hj"> <em class="kc">这是线性的！</em>T44】</strong></p><p id="2f7b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们还可以检查工资值在给定数据集中是如何分布的。</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="99c4" class="ke kf hi mh b fi ml mm l mn mo">sns.set_style("whitegrid")<br/>plt.figure(figsize=(20,8))<br/>plt.subplot(1,2,1)<br/>plt.title('Salary Distribution Plot')<br/>sns.distplot(dataset.Salary)<br/>plt.show()</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/ae84b396c58f763fc311c88dc24bc73c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*__E_reEl5hZCkvfFYh3rGw.png"/></div></figure><p id="cf08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面的情节，我们可以推断出工资分布在40000到125000之间。</p><h2 id="f240" class="ke kf hi bd kg kh ki kj kk kl km kn ko jb kp kq kr jf ks kt ku jj kv kw kx ky bi translated">Python代码:</h2><ul class=""><li id="46a7" class="jo jp hi is b it kz ix la jb mt jf mu jj mv jn mb ju jv jw bi translated"><code class="du mw mx my mh b">X</code>:包含年经验数组的第一列</li><li id="cf88" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn mb ju jv jw bi translated"><code class="du mw mx my mh b">y</code>:包含薪资数组的最后一列</li></ul><p id="5daf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们使用下面的代码将80%的数据分割成训练集，而将20%的数据分割成测试集。<br/>test _ size变量是我们实际指定测试集比例的地方。</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="864e" class="ke kf hi mh b fi ml mm l mn mo">X = dataset[‘YearsExperience’].values.reshape(-1,1)<br/>y = dataset[‘Salary’].values.reshape(-1,1)</span></pre><ul class=""><li id="62e5" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn mb ju jv jw bi translated"><code class="du mw mx my mh b">regressor = LinearRegression()</code>:我们的训练模型，将实现线性回归。</li><li id="60f1" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn mb ju jv jw bi translated"><code class="du mw mx my mh b">regressor.fit</code>:在这一行中，我们通过包含<strong class="is hj">年资</strong>的值的<code class="du mw mx my mh b">X_train</code>和包含<strong class="is hj">具体薪资</strong>的值的<code class="du mw mx my mh b">y_train</code>来组成模型。这是训练过程。</li></ul><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="190c" class="ke kf hi mh b fi ml mm l mn mo">from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LinearRegression</span><span id="e5ca" class="ke kf hi mh b fi mp mm l mn mo">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)</span><span id="e5ba" class="ke kf hi mh b fi mp mm l mn mo">regressor = LinearRegression()<br/>regressor.fit(X_train, y_train) #training the algorithm</span></pre><p id="b446" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">耶，我们已经建立了我们的模型，现在我们可以用它来计算(预测)<em class="kc">X的任何值取决于y </em>或<em class="kc">y的任何值取决于X </em>。我们是这样做的:</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="f1ad" class="ke kf hi mh b fi ml mm l mn mo">y_pred = regressor.predict(X_test)</span></pre><p id="4a34" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们还可以比较模型给出的实际值和预测值，以确定模型的效果如何。</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="c2aa" class="ke kf hi mh b fi ml mm l mn mo">df = pd.DataFrame({‘Actual’: y_test.flatten(), ‘Predicted’: y_pred.flatten()})</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/9a915fb4826484f67bf5a4d91f7489bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*h7dNhK84N10sAwbzvGW6rg.png"/></div></figure><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="ed7a" class="ke kf hi mh b fi ml mm l mn mo">df1 = df.head(25)<br/>df1.plot(kind=’bar’,figsize=(10,10))<br/>plt.grid(which=’major’, linestyle=’-’, linewidth=’0.5', color=’green’)<br/>plt.grid(which=’minor’, linestyle=’:’, linewidth=’0.5', color=’black’)<br/>plt.show()</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/f37d82f5c9245c40e0cf816d5968c89d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*olU-pG3l975dNgc72Q6Wug.png"/></div></div></figure><p id="9f95" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，任务是在上面的散点图中找到最符合的<strong class="is hj">线，这样我们就可以预测任何新特征值的响应。(即数据集中不存在的x值)。这条线叫做<strong class="is hj">回归线</strong>。</strong></p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="9b58" class="ke kf hi mh b fi ml mm l mn mo">plt.scatter(X_test, y_test, color=’gray’)<br/>plt.plot(X_test, y_pred, color=’red’, linewidth=2)<br/>plt.show()</span></pre><figure class="mc md me mf fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/c57a60ee471ad3378c7793aa8138fe23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*gVbu06-niERr0wMQcnY5Aw.png"/></div></figure><p id="cbd1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面的结果来看，我们可以自信地说我们的模型很好用。</p><blockquote class="le lf lg"><p id="ea23" class="iq ir kc is b it iu iv iw ix iy iz ja lh jc jd je li jg jh ji lj jk jl jm jn hb bi translated">我们可以控制的值是截距和斜率。根据截距和斜率的值，可以有多条直线。基本上，线性回归算法所做的是拟合数据点上的多条线，并返回导致最小误差的线。</p></blockquote><p id="a846" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们找到斜率和截距的值，以形成回归线。</p><pre class="mc md me mf fd mg mh mi mj aw mk bi"><span id="cf18" class="ke kf hi mh b fi ml mm l mn mo">#To retrieve the intercept:<br/>print(regressor.intercept_)</span><span id="bbb7" class="ke kf hi mh b fi mp mm l mn mo">#For retrieving the slope:<br/>print(regressor.coef_)</span><span id="d297" class="ke kf hi mh b fi mp mm l mn mo">Intercept of the model: 25202.887786154883<br/>Coefficient of the line: [9731.20383825]</span></pre><p id="6721" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们打电话说函数是，<strong class="is hj">y = 9731.2<em class="kc">x</em>+25202.88<br/></strong>如果我们要查看5年经验的工资，那么从上面的函数我们得到y = 73,858.8..预测不错！！！</p></div></div>    
</body>
</html>