<html>
<head>
<title>Step-by-Step Text Classification using different models and compare them.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用不同模型的逐步文本分类并比较它们。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/step-by-step-text-classification-using-different-models-and-compare-them-8a34204c34f8?source=collection_archive---------7-----------------------#2020-03-17">https://medium.com/analytics-vidhya/step-by-step-text-classification-using-different-models-and-compare-them-8a34204c34f8?source=collection_archive---------7-----------------------#2020-03-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/8b05305c3b15c29ecd3c325569745f1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*gprvof7lKc3w8oFuaLCmGA.jpeg"/></div></figure><p id="9913" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">索引:</p><ol class=""><li id="cd89" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated"><strong class="io hj">数据集信息</strong></li><li id="9177" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><strong class="io hj">探索性数据分析</strong></li><li id="ad94" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><strong class="io hj">特色工程</strong></li><li id="6beb" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><strong class="io hj">机器学习模型</strong></li><li id="f14c" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><strong class="io hj">使用LSTM和CONV1D进行文本分类</strong></li><li id="32ad" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><strong class="io hj">伯特详细介绍</strong></li><li id="7b12" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><strong class="io hj">未来工作</strong></li><li id="910d" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><strong class="io hj">参考</strong></li></ol><p id="4bc3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据集信息</strong></p><p id="601a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">该数据集包含由网络聚合器在2014年3月10日至2014年8月10日期间收集的422，937条新闻故事的标题、URL和类别。</p><p id="02c5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">该数据集中包含的新闻类别包括商业；科学技术；娱乐；和健康。涉及同一新闻条目的不同新闻文章(例如，关于最近发布的就业统计的几篇文章)也被分类在一起。</p><p id="1cdf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">422937个新闻页面，分为:</p><p id="1653" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">152746商业类新闻<br/> 108465科技类新闻<br/> 115920商业类新闻<br/> 45615健康类新闻</p><p id="f369" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你可以在这里从<a class="ae jy" href="https://archive.ics.uci.edu/ml/datasets/News+Aggregator" rel="noopener ugc nofollow" target="_blank">下载数据集。</a></p><h1 id="ab32" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">什么是文本分类</h1><p id="5db3" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">简单地说，文本分类是根据内容对原始文本进行分类或标记的过程。文本分类几乎可以用在任何事情上，从新闻话题标注到用户评论的情感分析。</p><p id="091d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">例如:</p><p id="87d5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">“电话太可怕了。超级慢。有一些严重的膨胀软件和弹出广告不像其他人。我不会向任何人推荐这款手机”</p><p id="3da5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从上面的文字中，我们的分类模型可以决定与我们的需求相关的特定类别或标签，在这种情况下，就是负面评论。</p><p id="cb69" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">基于机器学习的文本分类</strong></p><p id="d214" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">随着机器学习的发展，现在使用机器学习创建模型、向模型提供数据并等待模型完成变得更加容易。有了机器学习模型，从输入文本中进行分类就容易得多，也快得多。使用机器学习的一个重要步骤是特征提取。我们用向量的形式将文本转换为数字表示，一种方法是使用单词包，或者基本上，我们统计文本中的每个单词，或者使用tfidf(术语频率逆文档频率)等。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lc"><img src="../Images/d3f8be534eaa51ea77f8f06b13356d23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nUkApJ-FSJsf8G7Z.png"/></div></div></figure><p id="de25" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">上图是使用机器学习进行文本分类的简单流程。在第一阶段，我们使用文本输入作为训练数据。然后我们需要做特征提取，把文本转换成数字表示，因为大部分机器学习算法只理解数字特征。在获得我们想要的特征后，我们将这些特征与预定义的标签/类别一起输入机器学习算法。当它完成训练后，我们就有了我们的分类模型。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ll"><img src="../Images/dbdf54fe3d7f05d755201be49d0089b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*I5_tj51ikS5cVmpd.png"/></div></div></figure><p id="f983" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有了分类模型后，我们可以输入想要预测的数据，使用相同的流程，进行特征提取，然后将其输入到我们的模型中。当它完成时，我们将得到我们预测的类。</p><p id="5587" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">使用机器学习使文本分类变得更容易、更快，准确率也更高。</p><p id="7064" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">任务</strong></p><p id="d3bb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">根据标题对新闻进行分类</p><p id="0594" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">第一步:“将csv数据加载到我们的数据框架中”</strong></p><blockquote class="lm ln lo"><p id="c81e" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated"><em class="hi">导入熊猫为PD<br/>df = PD . read _ CSV(' UCI-news-aggregator . CSV ')<br/>df . head()</em></p></blockquote><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lt"><img src="../Images/28c220c2dab8f82c1c757976cd9a7be6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*u4hCiY5VQ5Wq6UoY.png"/></div></div></figure><p id="b549" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">“标题”是输入,“类别”是我们想要预测的类别输出</p><p id="bf19" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">第二步:探索性数据分析。(EDA) </strong></p><p id="26e5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有时候甚至我们肉眼看到的东西也不是“赤裸裸”的真相。追寻真相需要时间、信念和确定性。EDA——探索性数据分析——为机器学习爱好者做这件事。这是一种可视化、总结和解释隐藏在行列格式中的信息的方式。EDA是数据科学中至关重要的一步，它使我们能够获得对业务连续性、股东和数据科学家至关重要的某些见解和统计方法。它执行定义和细化我们的重要特征变量选择，这将在我们的模型中使用。</p><p id="48e0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">对于我们的数据集，下面是我为数据集做的EDA。EDA有100多种技术，这取决于我们选择哪种技术。最常见的是条形图、字云、散点图等。</p><p id="00d3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">月分析。</strong></p><p id="408f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们有2014年3月10日至2014年8月28日的数据，从3月到8月大约6个月。</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/c78d3632a158223ae8a141b52b757f77.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*fiT_hK6-9CJUImnZFHRULw.jpeg"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">月份分析</figcaption></figure><p id="8d8e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">类别分析</strong></p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/dff93ac0b2aa353b9e15947f36bf3102.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*gxrdUG8BpXu__bnCzlaBWQ.jpeg"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">类别分析</figcaption></figure><p id="a658" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">字云</strong></p><p id="5f59" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一个<strong class="io hj">字云</strong>(也称为<strong class="io hj">标签云</strong>或文字<strong class="io hj">云</strong>)是<strong class="io hj">字</strong>频率和值的直观表示。它用于突出显示特定术语或类别在数据源中出现的频率。一个关键词在数据集中出现的次数越多，这个关键词就显得越大越粗。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mc"><img src="../Images/c851f2eae8132fe72751b7cfff3f8fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sVHbqjaSdMwEyvUMiV1avA.jpeg"/></div></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es md"><img src="../Images/937d354e294f447d38c189f5bfbe8017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b5YMArlcXsq6YxaYumPhrQ.jpeg"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx translated"><strong class="bd kb">不同类别的词云</strong></figcaption></figure><p id="0b84" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">第三步:数据清理和数据预处理</strong></p><p id="849a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">将数据转换成计算机可以理解的东西的过程被称为<strong class="io hj">预处理。</strong>预处理的主要形式之一是过滤掉无用的数据。在自然语言处理中，无用的词(数据)被称为停用词。</p><p id="b3fb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">停用词:</strong>停用词是搜索引擎已经被编程忽略的常用词(例如“the”、“A”、“an”、“in”)，无论是在索引用于搜索的条目时还是在作为搜索查询的结果检索它们时。</p><p id="70c4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">特色工程:</strong></p><p id="e86f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jy" href="https://en.wikipedia.org/wiki/Feature_engineering" rel="noopener ugc nofollow" target="_blank">特征工程</a>，也称为特征创建，是从现有数据中构建新特征来训练机器学习模型的过程。这一步可能比实际使用的模型更重要，因为机器学习算法只从我们给它的数据中学习，创建与任务相关的特征绝对至关重要(参见优秀论文<a class="ae jy" href="https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf" rel="noopener ugc nofollow" target="_blank">“关于机器学习要知道的一些有用的事情”</a>)。</p><p id="2583" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在大多数情况下，特征工程帮助我们获得比简单模型更高的精度。</p><p id="6bda" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如你所知，通过阅读帖子的上半部分，我们的数据是文本格式的，所以我在下面添加了这个功能。</p><p id="13b6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">位置标记</strong></p><p id="5576" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">词性标注的主要目标是识别给定单词的语法组。无论是名词、代词、形容词、动词、副词等。根据上下文。词性标注寻找句子中的关系，并为单词分配相应的标签。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es me"><img src="../Images/8cd8eaa5627a496fd20576e6b032b943.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RGDTqbmdtBGKfMXUm3xGOg.jpeg"/></div></div></figure><p id="e6d0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当你的数据是文本时，你可以从<a class="ae jy" href="https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk" rel="noopener ugc nofollow" target="_blank">这里</a>找到如何添加更多的特性。</p><p id="e824" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们去分类脸。</p><p id="83ad" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">第四步:分类:</strong></p><p id="b163" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">机器学习模型不能直接处理原始文本！这个问题现在提出了另一个难题——我们如何将文本转换成有意义的数字或向量，以便它们对ML管道有用？简单地将原始文本转换成例如二进制、十进制或十六进制表示，肯定不会给我们单词的函数表示，因为这些值不能捕获关于单词(例如“国王”和“王后”或“猫”和“狗”)之间的含义、上下文和相关性的信息。应用将一组文档表示为公共向量空间中的向量的模型可以解决这个问题。</p><p id="7102" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有多种方法可以将word转换成vector，但我在这里使用了以下方法。</p><ol class=""><li id="21c9" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">一袋单词</li><li id="564a" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">TFIDF</li><li id="3606" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">AVG w2v</li><li id="2e07" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">TFIDF w2v</li></ol><p id="9ef2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你可以在这里学习如何将文本转换成矢量<a class="ae jy" href="https://towardsdatascience.com/different-techniques-to-represent-words-as-vectors-word-embeddings-3e4b9ab7ceb4" rel="noopener" target="_blank">。</a></p><p id="4958" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">机器学习模型:</strong></p><ol class=""><li id="3be5" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">朴素贝叶斯</li><li id="2be1" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">逻辑回归</li></ol><p id="bda8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">为什么是朴素贝叶斯？</strong></p><ol class=""><li id="e6c6" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">用于大数据集分类的最好和最古老的方法之一。</li><li id="fc1f" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">更少的培训时间</li><li id="96e9" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">可解释性</li></ol><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="35d7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">alpha是朴素贝叶斯中的超参数，因此我们必须使用GridSearchCV找到最佳超参数。</p><p id="4b4c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">什么是网格搜索？</strong></p><p id="1549" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">网格搜索是执行超参数调整的过程，以确定给定模型的最佳值。这一点非常重要，因为整个模型的性能取决于指定的超参数值</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/f35a9195db33da055fb05f545d04997f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*0bwB71EVt-5eROEj6St3Jg.jpeg"/></div></figure><p id="1637" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">拟合模型后，我绘制混淆矩阵并计算精度。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/db9f674f8308f5141ab236e2c0669a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*4tkex35J5W237IPzpL6aDw.jpeg"/></div></figure><p id="daaf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从上面的图片你可以看到我的大部分分类标签都是正确的。</p><p id="e493" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">正如我上面提到的，使用朴素贝叶斯是因为特征的可解释性</p><p id="2736" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们打印重要的特征。</p><p id="33a4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们可以使用sklearn的MultinomialNB函数中的feature_log_prob 通过<a class="ae jy" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html" rel="noopener ugc nofollow" target="_blank">来实现这一点。</a></p><p id="48f7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">argsort()将以log-prob的升序提供索引，因此对于最高imp特性，我们必须以逆序获取特性名称。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/1de42064209845279196a6aa916e5630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*444yZhRweXtHPgJC-oZkfQ.jpeg"/></div></figure><p id="61c4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">参见健康新闻分类，我的前10个词是埃博拉、研究、健康等，同样，对于技术，我的前10个词是谷歌、苹果、新闻、三星等。</p><h1 id="b26f" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">逻辑回归:</h1><p id="e3ca" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">就其本身而言，逻辑回归只是二元分类器，这意味着它们不能处理超过两个类别的目标向量。然而，有一些逻辑回归的巧妙扩展可以做到这一点。在一对其余的逻辑回归(OVR)中，为每个类别训练一个单独的模型，预测一个观察值是否是该类别(因此使其成为一个二元分类问题)。它假设每个分类问题(例如0类或不0类)是独立的。您可以通过设置multiclass = 'ovr '来实现这一点，这意味着one vs rest。</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="bc94" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">应用网格搜索后，我们可以检查哪个参数最适合我们的模型</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mi"><img src="../Images/a53ee1e82ed9764a4298978b542636cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a8weCBH2hI0R4z9mZwIhPg.jpeg"/></div></div></figure><p id="aca2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当我们得到模型的最佳参数时，我们训练模型并测试它。</p><p id="ff7b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">训练后，让我们检查模型的性能和绘图混淆矩阵。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mj"><img src="../Images/d7563de6b5d6100b2f9589e40979053e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mtj17RofiE_H1h0kayTCxw.jpeg"/></div></div></figure><p id="4779" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">混淆矩阵</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mk"><img src="../Images/d59b9c3f8b8c597275ba4d1d657bb17a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-NWAg2vnVdIRGOEoJRVaew.jpeg"/></div></div></figure><h2 id="479b" class="ml ka hi bd kb mm mn mo kf mp mq mr kj ix ms mt kn jb mu mv kr jf mw mx kv my bi translated">功能重要性:</h2><p id="8e8f" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated"><strong class="io hj">业务:</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/e32bb8905a4e4bf50a2397f5e85783ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*ggK0AGLbJfnQy7kC-NIzlw.jpeg"/></div></figure><p id="6dd8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">娱乐:</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es na"><img src="../Images/821f77f9606628c0de72db375f3e8051.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*b2dBdpUm4EftkpSdNkMeyA.jpeg"/></div></figure><p id="e18a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">医疗:</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/f0b947c968d014f935e6f2b559d04e02.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*C8hTOQ7pKD9yWCMPXb1XNA.jpeg"/></div></figure><p id="d671" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">技术:</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/46f6cf21ddb7ce373f58ec11f6269c96.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*lYsUeAtLvzOeCanudzioZA.jpeg"/></div></figure><p id="beb7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我在逻辑回归中使用coef属性来绘制特征重要性。</p><p id="4ea2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">决策函数中特征的系数。</p><p id="e9a6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们可以使用深度学习模型来提高准确性，所以我也使用了谷歌伯特和LSTM进行分类。</p><h1 id="84ee" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">LSTM:</h1><p id="235d" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">为了了解LSTM，你应该有RNN的基本知识，你可以从<a class="ae jy" href="https://towardsdatascience.com/understanding-rnn-and-lstm-f7cdf6dfc14e" rel="noopener" target="_blank">这里</a>阅读。</p><p id="ff3b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们的文本预处理将包括以下步骤:</p><ul class=""><li id="8065" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj nd jq jr js bi translated">将所有文本转换为小写。</li><li id="6f0b" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">在文本中用空格替换REPLACE_BY_SPACE_RE符号。</li><li id="33f9" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">从文本中删除BAD_SYMBOLS_RE中的符号。</li><li id="f402" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">删除文本中的“x”。</li><li id="eb45" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">删除停用词。</li></ul><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><h1 id="47c9" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">LSTM造型</h1><ul class=""><li id="4c6f" class="jk jl hi io b ip kx it ky ix ne jb nf jf ng jj nd jq jr js bi translated">通过将每个文本转换成整数序列或向量，对标题文本进行矢量化。</li><li id="ff31" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">将数据集限制在50000字以内。</li><li id="ec60" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">将每个投诉的最大字数设置为250。</li></ul><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="93ec" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">找到47422个唯一令牌。</p><ul class=""><li id="90ca" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj nd jq jr js bi translated">截断并填充输入序列，使它们在建模时长度相同。</li></ul><pre class="ld le lf lg fd nh ni nj nk aw nl bi"><span id="6067" class="ml ka hi ni b fi nm nn l no np">X = tokenizer.texts_to_sequences(data['clean_titles'].values)</span><span id="1399" class="ml ka hi ni b fi nq nn l no np">X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)</span><span id="e98c" class="ml ka hi ni b fi nq nn l no np">print('Shape of data tensor:', X.shape)</span></pre><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es nr"><img src="../Images/3b7e9d835aee608cf8244084c0a51591.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*XvmkWI5jafkvdxn-vLj91g.jpeg"/></div></figure><ul class=""><li id="0c72" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj nd jq jr js bi translated">将分类标签转换为数字。你可以认为这是标签编码器分配给每个类别的唯一编号。</li></ul><pre class="ld le lf lg fd nh ni nj nk aw nl bi"><span id="274d" class="ml ka hi ni b fi nm nn l no np">Y = pd.get_dummies(df['Product']).values<br/>print('Shape of label tensor:', Y.shape)</span></pre><ul class=""><li id="b0cb" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj nd jq jr js bi translated">列车测试分离。</li></ul><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><ul class=""><li id="96c9" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj nd jq jr js bi translated">第一层是嵌入层，使用100个长度向量来表示每个单词。</li><li id="3840" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">下一层是具有100个存储单元的LSTM层。</li><li id="d7fb" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">输出层必须创建4个输出值，每个类一个。</li><li id="53cd" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">激活功能是softmax用于多类分类。</li><li id="67f2" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">因为这是一个多类分类问题，所以使用categorical _ crossentropy作为损失函数。</li></ul><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/310f2c653507665566e33b53879948de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*HXMbbx8p-LVagHpV9oKb_A.jpeg"/></div></figure><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ns"><img src="../Images/e5027a74a6434bee66eec9c807f1b7a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pXRX44s0dfx4Jtz9OfiJaw.jpeg"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">训练了5个时代</figcaption></figure><p id="9976" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">训练后让我们绘制损失和准确度图。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/f9d0670a3b4689c55572095da4776fce.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*xMtVhyyJ1MIDbnH8boG8AQ.jpeg"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es nu"><img src="../Images/522e26365b40efa1db43a03e9295fc89.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*4KikUBG7be8dmI9H70sRsQ.jpeg"/></div></figure><p id="30a8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">LSTM给出了更高的准确性和可解释性，但训练时间高于朴素贝叶斯和逻辑回归。</p><p id="ecc0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们测试我们的模型。</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="927d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">上述函数预测传递给该函数的任何标题的类别。</p><pre class="ld le lf lg fd nh ni nj nk aw nl bi"><span id="0094" class="ml ka hi ni b fi nm nn l no np">title=['Private hospitals threaten to stop CGHS, ECHS cashless services']</span><span id="6c67" class="ml ka hi ni b fi nq nn l no np">check(title)</span></pre><p id="8518" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">输出:</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es nv"><img src="../Images/22a4143f093199d3eaad9fd2caa818be.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*FgDElCi5CzwhCv4plCzcag.jpeg"/></div></figure><h2 id="9100" class="ml ka hi bd kb mm mn mo kf mp mq mr kj ix ms mt kn jb mu mv kr jf mw mx kv my bi translated">CONV1D:</h2><p id="803c" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">CONV1D如何用于文本分类<a class="ae jy" href="https://stackoverflow.com/questions/52352522/how-does-keras-1d-convolution-layer-work-with-word-embeddings-text-classificat" rel="noopener ugc nofollow" target="_blank">这里</a>是最好的解释。</p><p id="66c7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这个模型中，我使用了预训练手套。</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="19f3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">首先加载手套文件</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="d4fd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">将给定单词的向量保存在矩阵中。</p><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="cda0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">训练完模型后，我的图形看起来像这样。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nw"><img src="../Images/81214e6d2b3eb67f868432fa1ade5894.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SuDVrMyv-1n3Cl4U0qZK3g.jpeg"/></div></div></figure><h1 id="f586" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak"> BERT( </strong>变压器的双向编码器表示)<strong class="ak"> : </strong></h1><p id="e5e4" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">如果你在过去的一年里一直关注自然语言处理，你可能听说过BERT:Transformers的双向编码器表示。这是一个由谷歌研究人员设计的神经网络架构，它完全改变了NLP任务的艺术状态，如文本分类，翻译，摘要和问题回答。</p><p id="b3c1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">既然BERT已经作为可加载模块添加到了<a class="ae jy" href="https://www.tensorflow.org/hub" rel="noopener ugc nofollow" target="_blank"> TF Hub </a>中，那么添加到现有的Tensorflow文本管道中就很容易了。在现有的管道中，BERT可以取代像ELMO和GloVE这样的文本嵌入层。或者，<a class="ae jy" href="http://wiki.fast.ai/index.php/Fine_tuning" rel="noopener ugc nofollow" target="_blank">微调</a> BERT在许多情况下可以提高精确度和缩短训练时间。</p><p id="61ea" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我们将在Tensorflow和tf hub中使用BERT训练一个模型来预测新闻的类别。一些代码改编自这个<a class="ae jy" rel="noopener" href="/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d"> colab </a>笔记本。我们开始吧！</p><p id="2480" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据预处理</strong></p><p id="72f8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">BERT模型仅接受特定类型的输入，数据集通常具有以下四个特征:</p><p id="29f0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">-&gt; guid:代表观察的唯一id。</p><p id="dde6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">-&gt; text_a:我们需要分类到给定类别的文本</p><p id="18c1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">-&gt; text_b:它在我们训练模型以理解句子之间的<br/>关系时使用，它不适用于分类问题。</p><p id="dab4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">-&gt;标签:它由给定文本所属的标签或类或类别组成。</p><ul class=""><li id="2c4c" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj nd jq jr js bi translated">&gt;在我们的数据集中，有text_a和label。下面的代码块将使用BERT库中提供的InputExample类为我们数据集中的所有记录<br/>的上述每个特性创建对象。</li></ul><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mk"><img src="../Images/437d17eba88cae1d270b7eb20083a2dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XdMblaqhTgJkb8_cYXQ6lA.jpeg"/></div></div></figure><p id="0af4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们现在要开始讨论训练前的伯特。在这个例子中，我们将使用bert_uncased_L-12_H-768_A-12/1模型。点击<a class="ae jy" href="https://tfhub.dev/s?network-architecture=transformer&amp;publisher=google" rel="noopener ugc nofollow" target="_blank">查看所有可用版本。</a></p><p id="61b9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将在模型中使用vocab.txt文件来将数据集中的单词映射到索引。此外，加载的BERT模型是在未大写/小写数据上训练的，因此我们输入来训练模型的数据也应该是小写的。(所以我们提前对数据进行预处理)。</p><p id="5643" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们有了BERT模型的适当格式，可以开始预处理数据了。</p><p id="263a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将执行以下操作:</p><ul class=""><li id="52ef" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj nd jq jr js bi translated">通过将所有空白字符转换为空格并根据所使用的模型类型(大写或小写)区分字母大小写来规范化文本。</li><li id="a11d" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">对文本进行分词或将句子拆分成单词，并将所有标点符号从文本中拆分出来。</li><li id="7290" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">添加CLS和SEP标记来区分句子的开头和结尾。</li><li id="07f2" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">根据相似性将单词拆分成单词块(即“呼叫”-&gt; [“呼叫”、" ##ing"])</li><li id="682d" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">使用保存在BERT的vocab.txt文件中的BERT自己的词汇将文本中的单词映射到索引。</li></ul><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es nx"><img src="../Images/a9c016c4a43d0584877ddad6ef34635b.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*Zc3gxyRfgkTOvtFcZCtMhA.jpeg"/></div></figure><p id="e8a8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将把InputExample转换成BERT能够理解的特性。该特征将由类InputFeatures表示。</p><ul class=""><li id="cc86" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj nd jq jr js bi translated">input_ids:标记文本的数字id列表</li><li id="f8d4" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">input_mask:对于实数标记将被设置为1，对于填充标记将被设置为0</li><li id="8961" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">segment_ids:在我们的例子中，这将被设置为一个列表</li><li id="2dab" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj nd jq jr js bi translated">label_ids:文本的一次性编码标签。</li></ul><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="37f6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们使用准确性作为衡量标准。</p><blockquote class="lm ln lo"><p id="4c70" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">#为训练创建一个输入函数。对于使用TPU，drop_remainder = True。</p><p id="aef8" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">train _ input _ fn = Bert . run _ classifier . input _ fn _ builder(</p><p id="0016" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">特征=训练_特征，</p><p id="7a55" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">序列长度=最大seq长度，</p><p id="2c94" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">is_training=True，</p><p id="3c54" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">drop_remainder=False)</p><p id="1caa" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">#创建用于验证的输入函数。对于使用TPU，drop_remainder = True。</p><p id="1d9c" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">val _ input _ fn = run _ classifier . input _ fn _ builder(</p><p id="0de5" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">功能=val_features，</p><p id="e01a" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">序列长度=最大seq长度，</p><p id="d562" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">is_training=False，</p><p id="772f" class="im in lp io b ip iq ir is it iu iv iw lq iy iz ja lr jc jd je ls jg jh ji jj hb bi translated">drop_remainder=False)</p></blockquote><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es ny"><img src="../Images/0e11e2938554964ff3ced64406a3b505.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*hitbPNTwI338W3TutR0tfw.jpeg"/></div></figure><p id="1c39" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">训练结束后，我们开始预测</strong></p><pre class="ld le lf lg fd nh ni nj nk aw nl bi"><span id="0b85" class="ml ka hi ni b fi nm nn l no np">“””Entertainment: e<br/>Medical : m<br/>Buisness: b<br/>Technology: t”””</span></pre><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><figure class="ld le lf lg fd ij"><div class="bz dy l di"><div class="lu lv l"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nz"><img src="../Images/5902e40f7f0268c8a48ce6094405ad01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OO-nrJZVcnJSdGLV9kqXmg.jpeg"/></div></div></figure><p id="5ce0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">比较所有型号:</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es oa"><img src="../Images/3f1cb0dcd844f16998731f89064609e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kO6eQwcz2lNdjVlYO8dd7A.jpeg"/></div></div></figure><h2 id="bb74" class="ml ka hi bd kb mm mn mo kf mp mq mr kj ix ms mt kn jb mu mv kr jf mw mx kv my bi translated">未来工作:</h2><p id="b093" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">对于深度学习模型，可以通过超参数调整来提高精度，对于深度学习模型的超参数调整也是如此。</p><p id="c903" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">会尝试装袋和助推技术。</p><h2 id="90dc" class="ml ka hi bd kb mm mn mo kf mp mq mr kj ix ms mt kn jb mu mv kr jf mw mx kv my bi translated">谢谢</h2><p id="e2c3" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">GIthub回购<a class="ae jy" href="https://github.com/amanv1906/News-Classification-using-Bert-and-other-techniques" rel="noopener ugc nofollow" target="_blank">这里</a></p><h2 id="a393" class="ml ka hi bd kb mm mn mo kf mp mq mr kj ix ms mt kn jb mu mv kr jf mw mx kv my bi translated">参考:</h2><p id="36bf" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated"><a class="ae jy" href="https://www.appliedaicourse.com/course/11/Applied-Machine-learning-course" rel="noopener ugc nofollow" target="_blank">应用人工智能</a></p><p id="7233" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jy" href="https://www.analyticsvidhya.com/myfeed/?utm-source=blog&amp;utm-medium=top-icon/" rel="noopener ugc nofollow" target="_blank">分析Vidhya </a></p><p id="20bc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jy" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank">伯特研究论文</a></p><p id="9dca" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jy" href="https://machinelearningmastery.com/" rel="noopener ugc nofollow" target="_blank">机器学习掌握度</a></p><div class="ob oc ez fb od oe"><a href="https://www.linkedin.com/in/aman-varyani-885725181/" rel="noopener  ugc nofollow" target="_blank"><div class="of ab dw"><div class="og ab oh cl cj oi"><h2 class="bd hj fi z dy oj ea eb ok ed ef hh bi translated">aman varyani -作家-分析Vidhya | LinkedIn</h2><div class="ol l"><h3 class="bd b fi z dy oj ea eb ok ed ef dx translated">我学东西很快，总是想找到一种方法去做一些有创意的事情。我寻找机会建立一个…</h3></div><div class="om l"><p class="bd b fp z dy oj ea eb ok ed ef dx translated">www.linkedin.com</p></div></div><div class="on l"><div class="oo l op oq or on os ik oe"/></div></div></a></div></div></div>    
</body>
</html>