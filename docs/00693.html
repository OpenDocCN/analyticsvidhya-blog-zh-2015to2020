<html>
<head>
<title>Super fast GPU based T-SNE-CUDA on Kaggle</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kaggle上基于超高速GPU的T-SNE-CUDA</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/super-fast-tsne-cuda-on-kaggle-b66dcdc4a5a4?source=collection_archive---------2-----------------------#2019-08-27">https://medium.com/analytics-vidhya/super-fast-tsne-cuda-on-kaggle-b66dcdc4a5a4?source=collection_archive---------2-----------------------#2019-08-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="beeb" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">学习降维可能会让你接触到t-SNE(t-分布式随机邻居嵌入)。许多实现提供了t-SNE，但是由于计算的复杂性，一些实现非常慢。在本文中，让我们看看如何在Kaggle内核上安装和使用基于GPU的t-SNE-CUDA的实现，并可视化MNIST数据</p></blockquote><figure class="jj jk jl jm fd jn er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es ji"><img src="../Images/33e4d0ed71a67291c69be0cd00b4b894.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Z38ZQwZDH7V5maDivc4GA.jpeg"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">照片由<a class="ae jh" href="https://unsplash.com/@adityachinchure?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Aditya Chinchure </a>在<a class="ae jh" href="https://unsplash.com/search/photos/dimensions?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="70eb" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated"><strong class="ak">目的</strong></h1><p id="abf4" class="pw-post-body-paragraph ii ij hi il b im kw io ip iq kx is it ky kz iw ix la lb ja jb lc ld je jf jg hb bi translated">在讨论如何让Kaggle为tsnecuda做好准备之前，让我们先了解一下什么是降维，以及有哪些可用的解决方案。</p><p id="b0d6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated">ML工程师总是探索数据集，以找到最能解释结果(Y)的特征(X)。在一些数据集中，会有很多特征，然而，一个好的ML工程师应该总是通过仔细选择最重要的特征，以简单的模型为目标。</p><h1 id="f817" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">降维</h1><figure class="jj jk jl jm fd jn er es paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="er es le"><img src="../Images/a7c361591f6b5b4cbba6ddeec24a400a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-TQAz7RVuD0K5MTy9UC7Kg.png"/></div></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">图片来源- <a class="ae jh" href="http://blog.kaggle.com/2017/04/10/exploring-the-structure-of-high-dimensional-data-with-hypertools-in-kaggle-kernels/" rel="noopener ugc nofollow" target="_blank"> Kaggle博客</a> |描绘从3D到2D的维度缩减</figcaption></figure><p id="95e3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated">简而言之，减少特征的数量以简化ML模型被称为降维。有许多方法可以做到这一点</p><ol class=""><li id="07ee" class="lf lg hi il b im in iq ir ky lh la li lc lj jg lk ll lm ln bi translated"><strong class="il hj">主成分分析</strong>:降维的常用方法之一。这个想法是找到覆盖大部分点的最佳主轴。通过正交投影该轴上的所有点，将产生维数减少的新数据集。即使信息由于数据预测而丢失，它也将概括和简化问题。</li><li id="d90c" class="lf lg hi il b im lo iq lp ky lq la lr lc ls jg lk ll lm ln bi translated"><strong class="il hj">特征消除:</strong>每个特征都被移除和/或添加到模型中，并检查错误结果。具有最小正面影响或最大负面影响的特征从特征集中被消除。</li><li id="1b67" class="lf lg hi il b im lo iq lp ky lq la lr lc ls jg lk ll lm ln bi translated"><strong class="il hj">因子分析:</strong>检查特征本身之间的相关性。如果高度相关，我们可以保留重要的特征，其余的可以剔除</li><li id="5611" class="lf lg hi il b im lo iq lp ky lq la lr lc ls jg lk ll lm ln bi translated"><strong class="il hj"> t分布式随机邻域嵌入(t-SNE) </strong>:这是最先进的最新技术，通过保持局部拓扑结构而不考虑全局配置，将数据点嵌入到低维图上。参考:<a class="ae jh" href="https://arxiv.org/abs/1807.11824" rel="noopener ugc nofollow" target="_blank">论文1 </a> <a class="ae jh" href="https://dl.acm.org/citation.cfm?id=2627435.2697068" rel="noopener ugc nofollow" target="_blank">论文2 </a> <a class="ae jh" href="https://github.com/CannyLab/tsne-cuda" rel="noopener ugc nofollow" target="_blank">实现</a></li></ol><h1 id="8572" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated"><strong class="ak">比较不同的实现方式</strong></h1><figure class="jj jk jl jm fd jn er es paragraph-image"><div class="er es lt"><img src="../Images/edd324d8dcaee775d6b3db148e22e97c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*Hwziz7RX48fCr0s0XDQQiw.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">坎尼拉布·茨内库达| t-SNE-库达胜过其他人</figcaption></figure><p id="1846" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated">包括Sklearn在内的许多流行库都附带了t-SNE实现，但它们并没有有效地使用GPU。tsnecuda的实现使性能达到了顶级水平，如图所示。(<em class="ik">比Sklearn实现</em>快650倍)</p></div><div class="ab cl lu lv gp lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="hb hc hd he hf"><h1 id="ba71" class="jy jz hi bd ka kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv bi translated">装置</h1><p id="79c4" class="pw-post-body-paragraph ii ij hi il b im kw io ip iq kx is it ky kz iw ix la lb ja jb lc ld je jf jg hb bi translated"><strong class="il hj">在Kaggle </strong> <br/>上安装<em class="ik"> tsnecuda </em>流行的在线python环境，如<a class="ae jh" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>和<a class="ae jh" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Colab </a>没有安装tsnecuda库。让我们看看如何在Kaggle上安装tsnecuda及其先决条件。我的<a class="ae jh" href="https://www.kaggle.com/karthikcs1/digit-recognizer-using-t-sne-cuda-using-gpu" rel="noopener ugc nofollow" target="_blank"> Kaggle内核</a>中描述了所遵循的步骤</p><p id="ee45" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated"><strong class="il hj">第一步:</strong>首先，启用GPU，因为这个库是专门为充分利用GPU处理能力而设计的。在Kaggle中，在右侧边栏→设置菜单下→启用GPU <br/>您可以通过执行以下命令来确认GPU的存在</p><pre class="jj jk jl jm fd mg mh mi mj aw mk bi"><span id="8588" class="ml jz hi mh b fi mm mn l mo mp">!nvidia-smi</span></pre><p id="7433" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated"><strong class="il hj">第二步:</strong>检查CUDA的版本。在我的例子中，它是版本10.0.130</p><pre class="jj jk jl jm fd mg mh mi mj aw mk bi"><span id="1f77" class="ml jz hi mh b fi mm mn l mo mp">!cat /usr/local/cuda/version.txt</span></pre><p id="1d30" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated"><strong class="il hj">步骤3(先决条件):</strong>通过执行以下命令安装faiss-gpu。请为各自的CUDA版本安装faiss</p><pre class="jj jk jl jm fd mg mh mi mj aw mk bi"><span id="7ff4" class="ml jz hi mh b fi mm mn l mo mp">!yes Y | conda install faiss-gpu cudatoolkit=10.0 -c pytorch</span></pre><p id="f713" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated"><strong class="il hj">步骤4(先决条件):</strong>安装openblas</p><pre class="jj jk jl jm fd mg mh mi mj aw mk bi"><span id="fa5c" class="ml jz hi mh b fi mm mn l mo mp">!apt search openblas<br/>!yes Y | apt install libopenblas-dev</span></pre><p id="3f86" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated"><strong class="il hj">第5步:</strong>从源代码安装tsnecuda。当我们安装conda libfaiss.so时，它丢失了。所以我们下载并复制文件到lib64目录</p><pre class="jj jk jl jm fd mg mh mi mj aw mk bi"><span id="584e" class="ml jz hi mh b fi mm mn l mo mp">!wget <a class="ae jh" href="https://anaconda.org/CannyLab/tsnecuda/2.1.0/download/linux-64/tsnecuda-2.1.0-cuda100.tar.bz2" rel="noopener ugc nofollow" target="_blank">https://anaconda.org/CannyLab/tsnecuda/2.1.0/download/linux-64/tsnecuda-2.1.0-cuda100.tar.bz2</a></span><span id="23bf" class="ml jz hi mh b fi mq mn l mo mp">!tar xvjf tsnecuda-2.1.0-cuda100.tar.bz2 — wildcards ‘lib/*’<br/>!tar xvjf tsnecuda-2.1.0-cuda100.tar.bz2 — wildcards ‘site-packages/*’<br/>!cp -r site-packages/* /opt/conda/lib/python3.6/site-packages/<br/># !export LD_LIBRARY_PATH=”/kaggle/working/lib/” <br/>!cp /kaggle/working/lib/libfaiss.so /usr/local/cuda/lib64/</span></pre></div><div class="ab cl lu lv gp lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="hb hc hd he hf"><p id="7467" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated">我们都设置了安装，并准备使用t-SNE-CUDA</p><h1 id="634c" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">MNIST数据集上的T-SNE</h1><p id="5256" class="pw-post-body-paragraph ii ij hi il b im kw io ip iq kx is it ky kz iw ix la lb ja jb lc ld je jf jg hb bi translated">让我们使用TSNE图书馆的MNIST数据。MNIST数据包含60，000个手写数字样本。每个数字有28x28个像素。每个像素被认为是一个特征，因此它的维数为784。为了可视化和分类目的，我们的目标是减少到2维。</p><pre class="jj jk jl jm fd mg mh mi mj aw mk bi"><span id="b5a0" class="ml jz hi mh b fi mm mn l mo mp">from tsnecuda import TSNE<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><p id="1d5c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated">加载数据</p><pre class="jj jk jl jm fd mg mh mi mj aw mk bi"><span id="fcd2" class="ml jz hi mh b fi mm mn l mo mp">df_train = pd.read_csv(‘../input/digit-recognizer/train.csv’)<br/>Y = df_train[[‘label’]]<br/>X = df_train.drop(‘label’, axis=1)</span></pre><p id="dc2f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated">T-SNE模型:我们有两个重要的超参数需要调整。</p><ul class=""><li id="4653" class="lf lg hi il b im in iq ir ky lh la li lc lj jg mr ll lm ln bi translated"><em class="ik">困惑</em>:告知高维度中有多少个点被认为是邻居。</li><li id="a6f0" class="lf lg hi il b im lo iq lp ky lq la lr lc ls jg mr ll lm ln bi translated"><em class="ik">迭代次数</em>:由于T-SNE是一种迭代算法，它告诉我们应该进行多少次迭代。</li><li id="50d8" class="lf lg hi il b im lo iq lp ky lq la lr lc ls jg mr ll lm ln bi translated"><em class="ik">部件号:</em>输出尺寸</li></ul><pre class="jj jk jl jm fd mg mh mi mj aw mk bi"><span id="8dda" class="ml jz hi mh b fi mm mn l mo mp">tsne_model = TSNE(n_components=2, perplexity=30.0, n_iter=1000).fit_transform(X)</span></pre><p id="1891" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated">上述模型提供了二维数据阵列，可以很容易地绘制在2D图上来表示数字。</p><pre class="jj jk jl jm fd mg mh mi mj aw mk bi"><span id="3d6f" class="ml jz hi mh b fi mm mn l mo mp">tsne_df = pd.DataFrame(tsne_model)<br/>tsne_df = pd.concat([tsne_df,Y], axis=1)<br/>sns.FacetGrid(tsne_df, hue="label" , size=6).map(plt.scatter, 0, 1).add_legend()<br/>plt.show()</span></pre><figure class="jj jk jl jm fd jn er es paragraph-image"><div class="er es ms"><img src="../Images/34fec9e131273defadaa41b9b382806d.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*GLUbkrODZsiJL_usMro5nQ.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">降维后的MNIST数据可以显示在2D图上</figcaption></figure></div><div class="ab cl lu lv gp lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="hb hc hd he hf"><h1 id="e8f1" class="jy jz hi bd ka kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv bi translated">结论</h1><p id="e116" class="pw-post-body-paragraph ii ij hi il b im kw io ip iq kx is it ky kz iw ix la lb ja jb lc ld je jf jg hb bi translated">在本文中，我们看到了以下内容</p><ul class=""><li id="3711" class="lf lg hi il b im in iq ir ky lh la li lc lj jg mr ll lm ln bi translated">降维的重要性</li><li id="4eba" class="lf lg hi il b im lo iq lp ky lq la lr lc ls jg mr ll lm ln bi translated">不同的解决方案</li><li id="4e48" class="lf lg hi il b im lo iq lp ky lq la lr lc ls jg mr ll lm ln bi translated">t-SNE-CUDA的性能</li><li id="ca15" class="lf lg hi il b im lo iq lp ky lq la lr lc ls jg mr ll lm ln bi translated">存储库安装指南</li><li id="e11f" class="lf lg hi il b im lo iq lp ky lq la lr lc ls jg mr ll lm ln bi translated">在MNIST使用t-SNE-CUDA的例子</li></ul><p id="cc53" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ky iv iw ix la iz ja jb lc jd je jf jg hb bi translated">注意:同样的方法也可以在Google Colab上尝试。我没有尝试过，如果有人尝试，请让我知道..</p></div><div class="ab cl lu lv gp lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="hb hc hd he hf"><h1 id="1dad" class="jy jz hi bd ka kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv bi translated">参考</h1><p id="8f93" class="pw-post-body-paragraph ii ij hi il b im kw io ip iq kx is it ky kz iw ix la lb ja jb lc ld je jf jg hb bi translated">[1] Karthik Sunil (2019)，<a class="ae jh" href="https://www.kaggle.com/karthikcs1/digit-recognizer-using-t-sne-cuda-using-gpu" rel="noopener ugc nofollow" target="_blank">使用t-SNE CUDA的数字识别器—使用GPU</a><br/>【2】Canny labs，<a class="ae jh" href="https://github.com/CannyLab/tsne-cuda" rel="noopener ugc nofollow" target="_blank">t-SNE-CUDA Github</a><br/>【3】<a class="ae jh" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chan%2C+D+M" rel="noopener ugc nofollow" target="_blank">David m . Chan</a>，<a class="ae jh" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rao%2C+R" rel="noopener ugc nofollow" target="_blank"> Roshan Rao </a>，<a class="ae jh" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+F" rel="noopener ugc nofollow" target="_blank"> Forrest Huang </a>，<a class="ae jh" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Canny%2C+J+F" rel="noopener ugc nofollow" target="_blank"> John F. Canny </a>，【2018】，<a class="ae jh" href="https://arxiv.org/abs/1807.11824" rel="noopener ugc nofollow" target="_blank">t-t</a></p></div></div>    
</body>
</html>