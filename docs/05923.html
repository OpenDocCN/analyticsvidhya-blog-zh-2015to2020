<html>
<head>
<title>Count people in webcam using pre-trained YOLOv3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用预先训练的YOLOv3计算网络摄像头中的人数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/count-people-in-webcam-using-yolov3-tensorflow-f407679967d5?source=collection_archive---------1-----------------------#2020-05-06">https://medium.com/analytics-vidhya/count-people-in-webcam-using-yolov3-tensorflow-f407679967d5?source=collection_archive---------1-----------------------#2020-05-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="dc1a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">了解如何使用实例分段(YOLOv3)通过python中的TensorFlow和OpenCV使用其预训练的权重来统计人数。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/dda6c533c8139832353c04ede43c33e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*odeev6UHyMgig0ru"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">丁满·斯图德勒在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="4f6d" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">目录</h1><ul class=""><li id="7130" class="kg kh hi ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ki hj">要求</strong></li><li id="8336" class="kg kh hi ki b kj ky kl kz kn la kp lb kr lc kt ku kv kw kx bi translated"><strong class="ki hj">简介</strong></li></ul><ol class=""><li id="04bb" class="kg kh hi ki b kj ld kl le kn lf kp lg kr lh kt li kv kw kx bi translated"><em class="lj">实例切分vs语义切分</em></li><li id="1002" class="kg kh hi ki b kj ky kl kz kn la kp lb kr lc kt li kv kw kx bi translated"><em class="lj"> YOLOv3 vs更快的RCNN vs SSD </em></li><li id="6044" class="kg kh hi ki b kj ky kl kz kn la kp lb kr lc kt li kv kw kx bi translated"><em class="lj">约洛夫3 </em></li><li id="f222" class="kg kh hi ki b kj ky kl kz kn la kp lb kr lc kt li kv kw kx bi translated"><em class="lj">锚箱</em></li><li id="3dd4" class="kg kh hi ki b kj ky kl kz kn la kp lb kr lc kt li kv kw kx bi translated"><em class="lj">非最大抑制</em></li></ol><ul class=""><li id="2d6c" class="kg kh hi ki b kj ld kl le kn lf kp lg kr lh kt ku kv kw kx bi translated"><strong class="ki hj">代码</strong></li></ul></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h1 id="aae3" class="jo jp hi bd jq jr lr jt ju jv ls jx jy io lt ip ka ir lu is kc iu lv iv ke kf bi translated">要求</h1><p id="6999" class="pw-post-body-paragraph lw lx hi ki b kj kk ij ly kl km im lz kn ma mb mc kp md me mf kr mg mh mi kt hb bi translated">对于这个项目，我们需要Tensorflow、OpenCV和wget-python(来下载YOLOv3权重。您也可以手动下载它们。)</p><p id="34c6" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">使用画中画:</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="d17c" class="mr jp hi mn b fi ms mt l mu mv">pip install tensorflow-gpu # this is the gpu version<br/>pip install tensorflow # if you don't have gpu like me 😥<br/>pip install opencv-python<br/>pip install wget</span></pre><p id="7c44" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">如果您使用anaconda，那么使用conda:</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="38a3" class="mr jp hi mn b fi ms mt l mu mv">conda install -c anaconda tensorflow-gpu # this is the gpu version<br/>conda install -c conda-forge tensorflow # if you don't have gpu version<br/>conda install -c conda-forge opencv<br/>conda install -c conda-forge python-wget</span></pre></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h1 id="c408" class="jo jp hi bd jq jr lr jt ju jv ls jx jy io lt ip ka ir lu is kc iu lv iv ke kf bi translated">介绍</h1><p id="c894" class="pw-post-body-paragraph lw lx hi ki b kj kk ij ly kl km im lz kn ma mb mc kp md me mf kr mg mh mi kt hb bi translated">在这里，我将简要讨论与YOLOv3和实例分割相关的基本术语，并提供额外的阅读资源。如果您了解它们，并想跳过它们，请随意进入下一部分。</p><h2 id="d4a8" class="mr jp hi bd jq mw mx my ju mz na nb jy kn nc nd ka kp ne nf kc kr ng nh ke ni bi translated">实例分割与语义分割</h2><p id="0c0b" class="pw-post-body-paragraph lw lx hi ki b kj kk ij ly kl km im lz kn ma mb mc kp md me mf kr mg mh mi kt hb bi translated">在语义分割中，基于各种标签(如人、狗、猫等)对图像进行分割，但是没有办法区分两个人物。这个缺点在实例分割中得到解决，其中除了区分不同的标签之外，我们还能够区分该标签的多个对象。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nj"><img src="../Images/a655235f1ec7bfa63a0f74de38740d9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_zPIxfnlJNy_svJ1Vo9xPg.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">语义分段(左)与实例分段(右)如果按边数分段。</figcaption></figure><h2 id="d1b4" class="mr jp hi bd jq mw mx my ju mz na nb jy kn nc nd ka kp ne nf kc kr ng nh ke ni bi translated">YOLOv3与更快的RCNN和SSD</h2><p id="2d6b" class="pw-post-body-paragraph lw lx hi ki b kj kk ij ly kl km im lz kn ma mb mc kp md me mf kr mg mh mi kt hb bi translated">选择哪一个，为什么？</p><p id="589b" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">想要最好的精确度？更快的RCNN</p><p id="e94e" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">想要最快的速度？YOLOv3</p><p id="7e2d" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">想要在两者之间进行权衡吗？（同solid-statedisk）固态（磁）盘</p><p id="2f42" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">我试图通过CPU (LOL)上的网络摄像头进行实时实现，所以我选择了YOLOv3。我也尝试过微小的YOLO，但它的预测不准确，所以我放弃了它。你可以选择最适合你的。</p><p id="9b87" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated"><em class="lj">深入了解这些模型的补充阅读</em></p><p id="ac55" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">fast RCNN—<a class="ae jn" href="https://towardsdatascience.com/faster-r-cnn-for-object-detection-a-technical-summary-474c5b857b46" rel="noopener" target="_blank">https://towardsdatascience . com/fast-r-CNN-for-object-detection-a-technical-summary-474 C5 b 857 b 46</a></p><p id="b1c1" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">SSD—<a class="ae jn" href="https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab" rel="noopener" target="_blank">https://towards data science . com/understanding-SSD-multi box-real-time-object-detection-in-deep-learning-495 ef 744 fab</a></p><p id="9368" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">他们之间的比较—<a class="ae jn" rel="noopener" href="/@jonathan_hui/object-detection-speed-and-accuracy-comparison-faster-r-cnn-r-fcn-ssd-and-yolo-5425656ae359">https://medium . com/@ Jonathan _ hui/object-detection-speed-and-accuracy-comparison-fast-r-CNN-r-fcn-SSD-and-yolo-5425656 AE 359</a></p><h2 id="18e2" class="mr jp hi bd jq mw mx my ju mz na nb jy kn nc nd ka kp ne nf kc kr ng nh ke ni bi translated">YOLOv3</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/8e1fa824da2b78f982cc8acd24f39c6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ro3fspog1fXfs5SGJwGaTw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片取自<a class="ae jn" href="https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b" rel="noopener" target="_blank">这里</a>。</figcaption></figure><p id="1f08" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">YOLOv3预训练模型可用于分类80个对象，速度超快，几乎与SSD一样准确。它有53个卷积层，每个卷积层后面都有一个批量归一化层和一个泄漏RELU激活。为了下采样，他们在卷积层中使用了步长2，而不是使用池。它的输入格式是图像应该是RGB格式(所以如果使用OpenCV记得转换)，输入类型是float32，尺寸可以是320x320或416x416或608x608。</p><p id="0747" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">补充阅读:<a class="ae jn" href="https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b" rel="noopener" target="_blank">https://towards data science . com/yolo-v3-object-detection-53 FB 7d 3 bfe 6 b</a></p><h2 id="8137" class="mr jp hi bd jq mw mx my ju mz na nb jy kn nc nd ka kp ne nf kc kr ng nh ke ni bi translated">锚箱</h2><p id="5582" class="pw-post-body-paragraph lw lx hi ki b kj kk ij ly kl km im lz kn ma mb mc kp md me mf kr mg mh mi kt hb bi translated">锚盒有助于模型更好地专门化。举一个站着的人和汽车的例子。人需要一个高箱子，而汽车需要一个胖箱子。我们的模型如何知道这些？这是通过不同尺寸的锚箱实现的。这意味着所有对象都有不止一个边界框。为了决定保留哪个边界框，使用了非最大抑制。当不同对象的中心在同一位置时，锚定框也有助于预测这两个对象。</p><p id="e612" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">补充阅读:<a class="ae jn" rel="noopener" href="/@andersasac/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9">https://medium . com/@ anderssac/anchor-boxes-the-key-to-quality-object-detection-ddf9d 612 D4 f 9</a></p><h2 id="8eef" class="mr jp hi bd jq mw mx my ju mz na nb jy kn nc nd ka kp ne nf kc kr ng nh ke ni bi translated">非最大抑制</h2><p id="f7a6" class="pw-post-body-paragraph lw lx hi ki b kj kk ij ly kl km im lz kn ma mb mc kp md me mf kr mg mh mi kt hb bi translated">非最大抑制或NMS使用IOU工作。交集超过并集(IOU)顾名思义就是两个盒子的交集和并集之比。选择具有最高检测概率的盒子。然后，与该框具有高IOU的所有框被移除。</p><p id="4b7a" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">补充阅读:<a class="ae jn" rel="noopener" href="/@sarangzambare/object-detection-using-non-max-supression-over-yolov2-382a90212b51">https://medium . com/@ sarangzambare/object-detection-using-non-max-suppression-over-yolov 2-382 a 90212 b 51</a></p><h1 id="2ada" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">密码</h1><p id="ba1c" class="pw-post-body-paragraph lw lx hi ki b kj kk ij ly kl km im lz kn ma mb mc kp md me mf kr mg mh mi kt hb bi translated">第一个任务是下载预训练的权重，这可以通过使用wget来完成。</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="8549" class="mr jp hi mn b fi ms mt l mu mv">import wget</span><span id="61b5" class="mr jp hi mn b fi nl mt l mu mv">url = '<a class="ae jn" href="https://pjreddie.com/media/files/yolov3.weights'" rel="noopener ugc nofollow" target="_blank">https://pjreddie.com/media/files/yolov3.weights'</a><br/>yolov3 = wget.download(url, out='yolov3.weights')</span></pre><p id="b237" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">在您的工作目录中运行这段代码将会在那里保存权重。</p><p id="7402" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">现在，在展示和解释代码之前，我要感谢Tensorflow 2中YOLO实现的这个<a class="ae jn" href="https://github.com/zzh8829/yolov3-tf2/" rel="noopener ugc nofollow" target="_blank"> Github </a>库，因为我大部分都是从这里复制的。</p><p id="1776" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">进行必要的进口</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="869b" class="mr jp hi mn b fi ms mt l mu mv">import tensorflow as tf<br/>import numpy as np<br/>import cv2<br/>from tensorflow.keras import Model<br/>from tensorflow.keras.layers import (<br/>    Add,<br/>    Concatenate,<br/>    Conv2D,<br/>    Input,<br/>    Lambda,<br/>    LeakyReLU,<br/>    UpSampling2D,<br/>    ZeroPadding2D,<br/>    BatchNormalization<br/>)<br/>from tensorflow.keras.regularizers import l2</span></pre><p id="6948" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">加载暗网权重，并将这些权重分配给模型的层。创建一个函数来定义卷积层以及是否对其应用批量归一化。</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="0677" class="mr jp hi mn b fi ms mt l mu mv">def load_darknet_weights(model, weights_file):<br/>    '''<br/>    Helper function used to load darknet weights.<br/>    <br/>    :param model: Object of the Yolo v3 model<br/>    :param weights_file: Path to the file with Yolo V3 weights<br/>    '''<br/>    <br/>    #Open the weights file<br/>    wf = open(weights_file, 'rb')<br/>    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)</span><span id="194f" class="mr jp hi mn b fi nl mt l mu mv">#Define names of the Yolo layers (just for a reference)    <br/>    layers = ['yolo_darknet',<br/>            'yolo_conv_0',<br/>            'yolo_output_0',<br/>            'yolo_conv_1',<br/>            'yolo_output_1',<br/>            'yolo_conv_2',<br/>            'yolo_output_2']</span><span id="466d" class="mr jp hi mn b fi nl mt l mu mv">for layer_name in layers:<br/>        sub_model = model.get_layer(layer_name)<br/>        for i, layer in enumerate(sub_model.layers):<br/>          <br/>            <br/>            if not layer.name.startswith('conv2d'):<br/>                continue<br/>                <br/>            #Handles the special, custom Batch normalization layer<br/>            batch_norm = None<br/>            if i + 1 &lt; len(sub_model.layers) and \<br/>                    sub_model.layers[i + 1].name.startswith('batch_norm'):<br/>                batch_norm = sub_model.layers[i + 1]</span><span id="3659" class="mr jp hi mn b fi nl mt l mu mv">filters = layer.filters<br/>            size = layer.kernel_size[0]<br/>            in_dim = layer.input_shape[-1]</span><span id="97c0" class="mr jp hi mn b fi nl mt l mu mv">if batch_norm is None:<br/>                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)<br/>            else:<br/>                # darknet [beta, gamma, mean, variance]<br/>                bn_weights = np.fromfile(<br/>                    wf, dtype=np.float32, count=4 * filters)<br/>                # tf [gamma, beta, mean, variance]<br/>                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]</span><span id="5936" class="mr jp hi mn b fi nl mt l mu mv"># darknet shape (out_dim, in_dim, height, width)<br/>            conv_shape = (filters, in_dim, size, size)<br/>            conv_weights = np.fromfile(<br/>                wf, dtype=np.float32, count=np.product(conv_shape))<br/>            # tf shape (height, width, in_dim, out_dim)<br/>            conv_weights = conv_weights.reshape(<br/>                conv_shape).transpose([2, 3, 1, 0])</span><span id="81de" class="mr jp hi mn b fi nl mt l mu mv">if batch_norm is None:<br/>                layer.set_weights([conv_weights, conv_bias])<br/>            else:<br/>                layer.set_weights([conv_weights])<br/>                batch_norm.set_weights(bn_weights)</span><span id="0a63" class="mr jp hi mn b fi nl mt l mu mv">assert len(wf.read()) == 0, 'failed to read all data'<br/>    wf.close()</span><span id="3857" class="mr jp hi mn b fi nl mt l mu mv">def DarknetConv(x, filters, kernel_size, strides=1, batch_norm=True):<br/>    '''<br/>    Call this function to define a single Darknet convolutional layer<br/>    <br/>    :param x: inputs<br/>    :param filters: number of filters in the convolutional layer<br/>    :param kernel_size: Size of kernel in the Conv layer<br/>    :param strides: Conv layer strides<br/>    :param batch_norm: Whether or not to use the custom batch norm layer.<br/>    '''<br/>    #Image padding<br/>    if strides == 1:<br/>        padding = 'same'<br/>    else:<br/>        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding<br/>        padding = 'valid'<br/>        <br/>    #Defining the Conv layer<br/>    x = Conv2D(filters=filters, kernel_size=kernel_size,<br/>               strides=strides, padding=padding,<br/>               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)<br/>    <br/>    if batch_norm:<br/>        x = BatchNormalization()(x)<br/>        x = LeakyReLU(alpha=0.1)(x)<br/>    return x</span></pre><p id="b5f5" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">创建函数来定义暗网残差层和暗网块，它们将你上面创建的卷积层，然后是一个函数来使用它们并创建整个暗网模型。</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="882a" class="mr jp hi mn b fi ms mt l mu mv">def DarknetResidual(x, filters):<br/>    '''<br/>    Call this function to define a single DarkNet Residual layer<br/>    <br/>    :param x: inputs<br/>    :param filters: number of filters in each Conv layer.<br/>    '''<br/>    prev = x<br/>    x = DarknetConv(x, filters // 2, 1)<br/>    x = DarknetConv(x, filters, 3)<br/>    x = Add()([prev, x])<br/>    return x<br/>  <br/>  <br/>def DarknetBlock(x, filters, blocks):<br/>    '''<br/>    Call this function to define a single DarkNet Block (made of multiple Residual layers)<br/>    <br/>    :param x: inputs<br/>    :param filters: number of filters in each Residual layer<br/>    :param blocks: number of Residual layers in the block<br/>    '''<br/>    x = DarknetConv(x, filters, 3, strides=2)<br/>    for _ in range(blocks):<br/>        x = DarknetResidual(x, filters)<br/>    return x</span><span id="49d2" class="mr jp hi mn b fi nl mt l mu mv">def Darknet(name=None):<br/>    '''<br/>    The main function that creates the whole DarkNet.<br/>    '''<br/>    x = inputs = Input([None, None, 3])<br/>    x = DarknetConv(x, 32, 3)<br/>    x = DarknetBlock(x, 64, 1)<br/>    x = DarknetBlock(x, 128, 2)  # skip connection<br/>    x = x_36 = DarknetBlock(x, 256, 8)  # skip connection<br/>    x = x_61 = DarknetBlock(x, 512, 8)<br/>    x = DarknetBlock(x, 1024, 4)<br/>    return tf.keras.Model(inputs, (x_36, x_61, x), name=name)</span></pre><p id="e731" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">现在，我们需要为YOLOv3模型创建辅助函数，以定义YOLOv3卷积层、YOLO模型的输出、绘制输出、根据预测创建边界框以及非最大抑制函数。我们还需要定义我们的锚盒，并最终创建一个函数来组合所有的锚盒，以生成我们的模型。</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="2f52" class="mr jp hi mn b fi ms mt l mu mv">def draw_outputs(img, outputs, class_names):<br/>    '''<br/>    Helper, util, function that draws predictons on the image.<br/>    <br/>    :param img: Loaded image<br/>    :param outputs: YoloV3 predictions<br/>    :param class_names: list of all class names found in the dataset<br/>    '''<br/>    boxes, objectness, classes, nums = outputs<br/>    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]<br/>    wh = np.flip(img.shape[0:2])<br/>    for i in range(nums):<br/>        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))<br/>        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))<br/>        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)<br/>        img = cv2.putText(img, '{} {:.4f}'.format(<br/>            class_names[int(classes[i])], objectness[i]),<br/>            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)<br/>    return img</span><span id="e0f8" class="mr jp hi mn b fi nl mt l mu mv">yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),<br/>                         (59, 119), (116, 90), (156, 198), (373, 326)],<br/>                        np.float32) / 416</span><span id="3b76" class="mr jp hi mn b fi nl mt l mu mv">yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])<br/>def YoloConv(filters, name=None):<br/>    '''<br/>    Call this function to define the Yolo Conv layer.<br/>    <br/>    :param flters: number of filters for the conv layer<br/>    :param name: name of the layer<br/>    '''<br/>    def yolo_conv(x_in):<br/>        if isinstance(x_in, tuple):<br/>            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])<br/>            x, x_skip = inputs</span><span id="e50c" class="mr jp hi mn b fi nl mt l mu mv"># concat with skip connection<br/>            x = DarknetConv(x, filters, 1)<br/>            x = UpSampling2D(2)(x)<br/>            x = Concatenate()([x, x_skip])<br/>        else:<br/>            x = inputs = Input(x_in.shape[1:])</span><span id="334a" class="mr jp hi mn b fi nl mt l mu mv">x = DarknetConv(x, filters, 1)<br/>        x = DarknetConv(x, filters * 2, 3)<br/>        x = DarknetConv(x, filters, 1)<br/>        x = DarknetConv(x, filters * 2, 3)<br/>        x = DarknetConv(x, filters, 1)<br/>        return Model(inputs, x, name=name)(x_in)<br/>    return yolo_conv</span><span id="545c" class="mr jp hi mn b fi nl mt l mu mv">def YoloOutput(filters, anchors, classes, name=None):<br/>    '''<br/>    This function defines outputs for the Yolo V3. (Creates output projections)<br/>     <br/>    :param filters: number of filters for the conv layer<br/>    :param anchors: anchors<br/>    :param classes: list of classes in a dataset<br/>    :param name: name of the layer<br/>    '''<br/>    def yolo_output(x_in):<br/>        x = inputs = Input(x_in.shape[1:])<br/>        x = DarknetConv(x, filters * 2, 3)<br/>        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)<br/>        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],<br/>                                            anchors, classes + 5)))(x)<br/>        return tf.keras.Model(inputs, x, name=name)(x_in)<br/>    return yolo_output</span><span id="11d5" class="mr jp hi mn b fi nl mt l mu mv">def yolo_boxes(pred, anchors, classes):<br/>    '''<br/>    Call this function to get bounding boxes from network predictions<br/>    <br/>    :param pred: Yolo predictions<br/>    :param anchors: anchors<br/>    :param classes: List of classes from the dataset<br/>    '''<br/>    <br/>    # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))<br/>    grid_size = tf.shape(pred)[1]<br/>    #Extract box coortinates from prediction vectors<br/>    box_xy, box_wh, objectness, class_probs = tf.split(<br/>        pred, (2, 2, 1, classes), axis=-1)</span><span id="e28c" class="mr jp hi mn b fi nl mt l mu mv">#Normalize coortinates<br/>    box_xy = tf.sigmoid(box_xy)<br/>    objectness = tf.sigmoid(objectness)<br/>    class_probs = tf.sigmoid(class_probs)<br/>    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss</span><span id="8673" class="mr jp hi mn b fi nl mt l mu mv"># !!! grid[x][y] == (y, x)<br/>    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))<br/>    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]</span><span id="438d" class="mr jp hi mn b fi nl mt l mu mv">box_xy = (box_xy + tf.cast(grid, tf.float32)) / \<br/>        tf.cast(grid_size, tf.float32)<br/>    box_wh = tf.exp(box_wh) * anchors</span><span id="4aef" class="mr jp hi mn b fi nl mt l mu mv">box_x1y1 = box_xy - box_wh / 2<br/>    box_x2y2 = box_xy + box_wh / 2<br/>    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)</span><span id="3c9c" class="mr jp hi mn b fi nl mt l mu mv">return bbox, objectness, class_probs, pred_box</span><span id="20a0" class="mr jp hi mn b fi nl mt l mu mv">def yolo_nms(outputs, anchors, masks, classes):<br/>    # boxes, conf, type<br/>    b, c, t = [], [], []</span><span id="e81c" class="mr jp hi mn b fi nl mt l mu mv">for o in outputs:<br/>        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))<br/>        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))<br/>        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))</span><span id="423e" class="mr jp hi mn b fi nl mt l mu mv">bbox = tf.concat(b, axis=1)<br/>    confidence = tf.concat(c, axis=1)<br/>    class_probs = tf.concat(t, axis=1)</span><span id="31db" class="mr jp hi mn b fi nl mt l mu mv">scores = confidence * class_probs<br/>    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(<br/>        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),<br/>        scores=tf.reshape(<br/>        scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),<br/>        max_output_size_per_class=100,<br/>        max_total_size=100,<br/>        iou_threshold=0.5,<br/>        score_threshold=0.6<br/>    )</span><span id="10f0" class="mr jp hi mn b fi nl mt l mu mv">return boxes, scores, classes, valid_detections</span><span id="4403" class="mr jp hi mn b fi nl mt l mu mv">def YoloV3(size=None, channels=3, anchors=yolo_anchors,<br/>           masks=yolo_anchor_masks, classes=80):<br/>  <br/>    x = inputs = Input([size, size, channels], name='input')</span><span id="4c11" class="mr jp hi mn b fi nl mt l mu mv">x_36, x_61, x = Darknet(name='yolo_darknet')(x)</span><span id="3164" class="mr jp hi mn b fi nl mt l mu mv">x = YoloConv(512, name='yolo_conv_0')(x)<br/>    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)</span><span id="baa0" class="mr jp hi mn b fi nl mt l mu mv">x = YoloConv(256, name='yolo_conv_1')((x, x_61))<br/>    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)</span><span id="01eb" class="mr jp hi mn b fi nl mt l mu mv">x = YoloConv(128, name='yolo_conv_2')((x, x_36))<br/>    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)</span><span id="a4ce" class="mr jp hi mn b fi nl mt l mu mv">boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),<br/>                     name='yolo_boxes_0')(output_0)<br/>    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),<br/>                     name='yolo_boxes_1')(output_1)<br/>    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),<br/>                     name='yolo_boxes_2')(output_2)</span><span id="a988" class="mr jp hi mn b fi nl mt l mu mv">outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),<br/>                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))</span><span id="041b" class="mr jp hi mn b fi nl mt l mu mv">return Model(inputs, outputs, name='yolov3')</span></pre><p id="bc26" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">现在所有的函数都定义好了，是时候创建一个YOLOv3模型了，可以使用:</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="8e8a" class="mr jp hi mn b fi ms mt l mu mv">yolo = YoloV3()<br/>load_darknet_weights(yolo, 'yolov3.weights')</span></pre><p id="f346" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">启动网络摄像头，让每一帧都为预测做好准备。当我们使用OpenCV时，我们需要将我们的图像转换为RGB，将它们的大小调整为320x320或416x416或608x608，将它们的数据类型转换为float32，将它们扩展为四维并除以255。</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="32a2" class="mr jp hi mn b fi ms mt l mu mv">cap = cv2.VideoCapture(0)<br/>while(True):<br/>    ret, image = cap.read()<br/>    if ret==True:<br/>        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/>        img = cv2.resize(img, (320, 320))<br/>        img = img.astype(np.float32)<br/>        img = np.expand_dims(img, 0)<br/>        img = img / 255</span></pre><p id="181b" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">使用yolo获得图像上的预测。加载类名文件，其中包含为其训练模型的所有对象名。这里可以找到<a class="ae jn" href="https://github.com/vardanagarwal/Proctoring-AI/blob/master/models/classes.TXT" rel="noopener ugc nofollow" target="_blank">。您可以绘制输出来检查模型是否工作。</a></p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="dde9" class="mr jp hi mn b fi ms mt l mu mv">boxes, scores, classes, nums = yolo(img)<br/>class_names = [c.strip() for c in open("classes.txt").readlines()]<br/>image = draw_outputs(image, (boxes, scores, classes, nums), class_names)<br/>cv2.imshow('Prediction', image)<br/>if cv2.waitKey(1) &amp; 0xFF == ord('q'):<br/>    break</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nm"><img src="../Images/f2e0cf2fca48b3f135133ba57d003322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*o8RhIA1GTu7knHIWSF8Lfg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">使用YOLOv3进行预测</figcaption></figure><p id="2c6e" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">现在，为了统计classes.txt中的人员或任何内容，我们需要知道它在其中的索引。person的索引是0，所以我们需要检查预测的类是否是0，然后我们增加一个计数器。</p><pre class="iy iz ja jb fd mm mn mo mp aw mq bi"><span id="0924" class="mr jp hi mn b fi ms mt l mu mv">count=0<br/>for i in range(nums[0]):<br/>    if int(classes[0][i] == 0):<br/>        count +=1</span><span id="9126" class="mr jp hi mn b fi nl mt l mu mv">print('Number of people:', count)</span></pre><p id="3602" class="pw-post-body-paragraph lw lx hi ki b kj ld ij ly kl le im lz kn mj mb mc kp mk me mf kr ml mh mi kt hb bi translated">你可以在我的<a class="ae jn" href="https://github.com/vardanagarwal/Proctoring-AI" rel="noopener ugc nofollow" target="_blank"> Github repo </a>上找到完整的代码。</p></div></div>    
</body>
</html>