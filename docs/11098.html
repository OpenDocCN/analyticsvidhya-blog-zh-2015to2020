<html>
<head>
<title>TensorFlow 2 — Common Functions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流 2-常见函数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorflow-2-common-functions-4f538fd9b995?source=collection_archive---------15-----------------------#2020-11-17">https://medium.com/analytics-vidhya/tensorflow-2-common-functions-4f538fd9b995?source=collection_archive---------15-----------------------#2020-11-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8cb253964a94e3e78453a9e035f1e64a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7k5Or4PutNMzkQGBOGECrw.jpeg"/></div></div></figure><p id="5598" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">注意:所有代码文件将在</em><a class="ae jp" href="https://github.com/ashwinhprasad/Tensorflow-2.0" rel="noopener ugc nofollow" target="_blank"><em class="jo">【https://github.com/ashwinhprasad/Tensorflow-2.0】</em></a><em class="jo"><br/></em>提供。这篇博文将涵盖 tensorflow 2 中会重复使用的一些基本函数。</p><h1 id="989f" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">随意</h1><p id="c42f" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">random.normal 生成给定形状的随机值，这些值遵循正态分布<br/>，random.uniform 生成随机值的方式使得从随机束中选择任意数字的概率几乎是一致的</p><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="ed2f" class="lc jr hi ky b fi ld le l lf lg">#normal distribution<br/>x1 = tf.random.normal(shape=(5,5),mean=0,stddev=1) <br/>#normal distribution<br/>print(x1)</span><span id="062a" class="lc jr hi ky b fi lh le l lf lg"><strong class="ky hj">output: </strong></span><span id="c407" class="lc jr hi ky b fi lh le l lf lg">tf.Tensor(<br/>[[-1.1473149e+00  5.1616412e-01 -2.8656033e-01 -1.4161720e-03<br/>  -6.7782238e-02]<br/> [ 1.5549400e-01 -1.8609362e+00  7.8299832e-01 -7.3712116e-01<br/>  -3.0330741e-01]<br/> [ 5.6524660e-02  1.0138390e-01  1.2218195e+00  1.2505690e+00<br/>   3.0457941e-01]<br/> [ 3.6436683e-01 -8.6699528e-01  1.5152076e+00  7.8330201e-01<br/>  -1.4127023e+00]<br/> [-1.2999429e+00  1.3505920e+00  1.0376108e+00 -1.5029492e+00<br/>   9.7778231e-01]], shape=(5, 5), dtype=float32)<br/></span><span id="e0e2" class="lc jr hi ky b fi lh le l lf lg">#visualize normal distribution<br/>x1 = tf.random.normal(shape=(500,))<br/>sns.displot(x1)</span></pre><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es li"><img src="../Images/d34f3ecf9d318561df2cb41ce39d4548.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*2kwCzUj-4p-hp3gj03dfmw.png"/></div></figure><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="7b5f" class="lc jr hi ky b fi ld le l lf lg">#uniform distribution<br/>x2 = tf.random.uniform(shape=(5,4))<br/>print(x2)</span><span id="a451" class="lc jr hi ky b fi lh le l lf lg"><strong class="ky hj">output : </strong></span><span id="4e19" class="lc jr hi ky b fi lh le l lf lg">tf.Tensor(<br/>[[0.65285194 0.42846894 0.12264287 0.10860097]<br/> [0.93370414 0.5431448  0.68363917 0.649168  ]<br/> [0.03916836 0.13292682 0.83300996 0.78246915]<br/> [0.82530236 0.58112395 0.5084605  0.7217077 ]<br/> [0.6427095  0.8807986  0.2582872  0.00343001]], shape=(5, 4), dtype=float32)<br/></span><span id="18ab" class="lc jr hi ky b fi lh le l lf lg">#visualize uniform distribution<br/>x2 = tf.random.uniform(shape=(500,))<br/>sns.displot(x2)</span></pre><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es li"><img src="../Images/6bf5feb22b62cdc659eedd1cdb40cda2.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*Y36CmRLMYxTMRLOXRlNiRA.png"/></div></figure><h1 id="8e7e" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">整形、堆叠、连接和 Argsort</h1><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/d063c4e157f6d5e3aa1e2cab0853c634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*debAUNxcVZZ5DdfVgBSCLA.jpeg"/></div></figure><ul class=""><li id="6a3e" class="lk ll hi is b it iu ix iy jb lm jf ln jj lo jn lp lq lr ls bi translated">整形顾名思义，是用来整形张量的。</li><li id="78c0" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn lp lq lr ls bi translated">concatenate 基本上将第二个张量附加在第一个张量的底部。</li><li id="6be4" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn lp lq lr ls bi translated">stack 类似于 concatenate，但是它用一个张量堆叠另一个张量，就像添加一个额外的列。</li><li id="1c0c" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn lp lq lr ls bi translated">argsort 按升序对张量进行排序，并返回索引</li></ul><pre class="kt ku kv kw fd kx ky kz la aw lb bi"><span id="9abe" class="lc jr hi ky b fi ld le l lf lg">#reshape<br/>x3 = tf.random.normal(shape=(64,))<br/>print(x3)</span><span id="86d3" class="lc jr hi ky b fi lh le l lf lg"><strong class="ky hj">output:</strong></span><span id="3221" class="lc jr hi ky b fi lh le l lf lg">tf.Tensor(<br/>[ 0.42399088 -0.80428976  0.04625189  0.12766832 -1.1452513  -1.132444<br/> -1.5954331  -0.7658271   0.23830678  0.87359303 -1.1955462   0.60085934<br/> -0.16850014  0.23895513 -0.79428434  0.5901934   0.7201891  -0.88731915<br/>  0.416003    0.36231613 -0.9967045   0.25209612  0.7464547  -0.5838859<br/>  0.81082785  1.1345944  -0.13218845 -1.1947349  -0.15193698 -0.15605085<br/> -0.22355284  0.22670309 -0.09245801 -0.47463486 -0.0844338   0.395378<br/>  1.7628212   1.1505485   0.4349458  -1.070593    0.9156709  -0.09126403<br/> -1.127492   -0.7092636  -1.0289346  -0.06610456  1.199735   -0.07397708<br/> -0.19952694 -0.10441776 -0.99892586 -0.3821481   0.34758636  0.53041816<br/> -0.53391504 -1.2965931   1.4620845  -0.02443436  0.14388773  0.2543015<br/> -0.7513509  -0.18593496  1.0581148   0.18503264], shape=(64,), dtype=float32)</span><span id="f1a6" class="lc jr hi ky b fi lh le l lf lg">#reshaping to a 32x2 tensor<br/>tf.reshape(x3,shape=(32,2))</span><span id="f431" class="lc jr hi ky b fi lh le l lf lg"><strong class="ky hj">output:</strong> </span><span id="11a4" class="lc jr hi ky b fi lh le l lf lg">&lt;tf.Tensor: shape=(32, 2), dtype=float32, numpy=<br/>array([[ 0.42399088, -0.80428976],<br/>       [ 0.04625189,  0.12766832],<br/>       [-1.1452513 , -1.132444  ],<br/>       [-1.5954331 , -0.7658271 ],<br/>       [ 0.23830678,  0.87359303],<br/>       [-1.1955462 ,  0.60085934],<br/>       [-0.16850014,  0.23895513],<br/>       [-0.79428434,  0.5901934 ],<br/>       [ 0.7201891 , -0.88731915],<br/>       [ 0.416003  ,  0.36231613],<br/>       [-0.9967045 ,  0.25209612],<br/>       [ 0.7464547 , -0.5838859 ],<br/>       [ 0.81082785,  1.1345944 ],<br/>       [-0.13218845, -1.1947349 ],<br/>       [-0.15193698, -0.15605085],<br/>       [-0.22355284,  0.22670309],<br/>       [-0.09245801, -0.47463486],<br/>       [-0.0844338 ,  0.395378  ],<br/>       [ 1.7628212 ,  1.1505485 ],<br/>       [ 0.4349458 , -1.070593  ],<br/>       [ 0.9156709 , -0.09126403],<br/>       [-1.127492  , -0.7092636 ],<br/>       [-1.0289346 , -0.06610456],<br/>       [ 1.199735  , -0.07397708],<br/>       [-0.19952694, -0.10441776],<br/>       [-0.99892586, -0.3821481 ],<br/>       [ 0.34758636,  0.53041816],<br/>       [-0.53391504, -1.2965931 ],<br/>       [ 1.4620845 , -0.02443436],<br/>       [ 0.14388773,  0.2543015 ],<br/>       [-0.7513509 , -0.18593496],<br/>       [ 1.0581148 ,  0.18503264]], dtype=float32)&gt;</span><span id="3fdc" class="lc jr hi ky b fi lh le l lf lg"># reshaping into 16 x 4 tensor<br/>tf.reshape(x3,shape=(-1,4))</span><span id="5bc1" class="lc jr hi ky b fi lh le l lf lg"><strong class="ky hj">output:</strong> <br/>&lt;tf.Tensor: shape=(16, 4), dtype=float32, numpy=<br/>array([[ 0.42399088, -0.80428976,  0.04625189,  0.12766832],<br/>       [-1.1452513 , -1.132444  , -1.5954331 , -0.7658271 ],<br/>       [ 0.23830678,  0.87359303, -1.1955462 ,  0.60085934],<br/>       [-0.16850014,  0.23895513, -0.79428434,  0.5901934 ],<br/>       [ 0.7201891 , -0.88731915,  0.416003  ,  0.36231613],<br/>       [-0.9967045 ,  0.25209612,  0.7464547 , -0.5838859 ],<br/>       [ 0.81082785,  1.1345944 , -0.13218845, -1.1947349 ],<br/>       [-0.15193698, -0.15605085, -0.22355284,  0.22670309],<br/>       [-0.09245801, -0.47463486, -0.0844338 ,  0.395378  ],<br/>       [ 1.7628212 ,  1.1505485 ,  0.4349458 , -1.070593  ],<br/>       [ 0.9156709 , -0.09126403, -1.127492  , -0.7092636 ],<br/>       [-1.0289346 , -0.06610456,  1.199735  , -0.07397708],<br/>       [-0.19952694, -0.10441776, -0.99892586, -0.3821481 ],<br/>       [ 0.34758636,  0.53041816, -0.53391504, -1.2965931 ],<br/>       [ 1.4620845 , -0.02443436,  0.14388773,  0.2543015 ],<br/>       [-0.7513509 , -0.18593496,  1.0581148 ,  0.18503264]],<br/>      dtype=float32)&gt;</span><span id="5317" class="lc jr hi ky b fi lh le l lf lg">#argsort<br/>arr1 = tf.constant([2,41,1,2,5,82,12,32])<br/>tf.argsort(arr1,direction="ASCENDING")</span><span id="d405" class="lc jr hi ky b fi lh le l lf lg"><strong class="ky hj">output: </strong><br/>&lt;tf.Tensor: shape=(8,), dtype=int32, numpy=array([2, 0, 3, 4, 6, 7, 1, 5], dtype=int32)&gt;</span><span id="6c9d" class="lc jr hi ky b fi lh le l lf lg">#concatenate and shape<br/>x4 = tf.random.normal(shape=(5,))<br/>x5 = tf.random.normal(shape=(6,))<br/>x6 = tf.concat([x4,x5],axis=0)</span><span id="9489" class="lc jr hi ky b fi lh le l lf lg">print("Tensor 1: ",x4.numpy(),"\nTensor 2: ",x5.numpy(),"\nTensor 3: ",x6.numpy())<br/>print("Shape of Tensor 3: ",x6.shape)</span><span id="edbc" class="lc jr hi ky b fi lh le l lf lg"><strong class="ky hj">output:</strong></span><span id="0ad7" class="lc jr hi ky b fi lh le l lf lg">Tensor 1:  [ 0.8083252  -0.33577648 -0.08235504  0.54277456  0.14716475] <br/>Tensor 2:  [ 1.0126716  1.2005072  1.4773481  1.1552964 -1.7687838 -0.5394377] <br/>Tensor 3:  [ 0.8083252  -0.33577648 -0.08235504  0.54277456  0.14716475  1.0126716<br/>  1.2005072   1.4773481   1.1552964  -1.7687838  -0.5394377 ]<br/>Shape of Tensor 3:  (11,)</span></pre><h1 id="3a9a" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="7f26" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">tensorflow 中经常使用一些重要的函数，如 Random、Reshape、Argsort、Stack 和 Concatenate。<br/> Github 回购:<a class="ae jp" href="https://github.com/ashwinhprasad/Tensorflow-2.0" rel="noopener ugc nofollow" target="_blank">T12】https://github.com/ashwinhprasad/Tensorflow-2.0T14】</a></p><h1 id="ac90" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">谢谢你</h1></div></div>    
</body>
</html>