<html>
<head>
<title>G2D: Generate to Detect Anomaly</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">G2D:生成以检测异常</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/g2d-generate-to-detect-anomaly-a06d127b6c77?source=collection_archive---------21-----------------------#2020-11-16">https://medium.com/analytics-vidhya/g2d-generate-to-detect-anomaly-a06d127b6c77?source=collection_archive---------21-----------------------#2020-11-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/fec757167c27d8956831a886026f4cc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*sdTE0-2GkKoMq_twMv3KrA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">在不同时期的训练期间，由在正常(目标类)样本(红色)上训练的 GAN 生成的实例(蓝色)。我们使用 T-SNE 来表示二维样本。正如在更早的时代可以看到的，GAN 的发生器产生与正常样品完全不同的样品。但是随着学习过程的继续，随着时代的增加，两种类型的样本逐渐彼此接近。</figcaption></figure></div><div class="ab cl iq ir gp is" role="separator"><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv"/></div><div class="hb hc hd he hf"><p id="1e50" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi jv translated"><span class="l jw jx jy bm jz ka kb kc kd di"> O </span> ne-Class 分类(OCC)的任务是检测不可见或超出目标分布的样本。换句话说，OCC 方法寻找异常，即在训练数据中不(或很少)发生的意外行为或事件。受深度学习解决方案，特别是生成式对抗网络(GANs)的成功启发，已经提出了一些用于离群点检测的方法。简而言之，这种方法对立地学习两个深度神经网络，一个用于生成虚假数据，另一个用于区分正常样本和异常值。虽然他们已经取得了有希望的结果，但与所有其他基于 GAN 的方法一样，学习找到最佳参数是一个麻烦的过程。此外，对于 OCC 任务，在没有任何离群类验证样本的情况下，找到停止学习过程的适当时间以实现最佳性能是非常具有挑战性的，并且需要反复试验。</p><p id="c560" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">为了应对上述挑战，我们提出了一种非常简单而有效的方法来检测异常样本。类似于前面的方法，我们利用了对抗性学习，但是以完全不同的方式使用它。以前提出的方法集中于对立地学习正态数据的分布，并将所有与参考模型有重大偏离的实例视为异常值。与这些解决方案相反，我们提出了一种简单直接的方法来生成不符合正态数据分布的不规则样本。生成的不规则体旁边有可用的正常实例，可以简单地用于训练一个二元分类器。</p><p id="2ee3" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">不规则性检测的任务是找到不存在或存在低可能性的样本。异常或不规则样本可以是与预期和通常行为的任何偏差，或者是与目标类数据不相似的任何情况。因此，它们是非常多样的，研究人员更喜欢学习训练数据中的共享概念，即规则实例。在这种情况下，具有不同概念的样本被认为是不规则的。在<a class="ae ke" href="https://arxiv.org/pdf/2006.11629.pdf" rel="noopener ugc nofollow" target="_blank">这篇论文中，</a>我们跟进了一种新的不规则检测方法。尽管对离群样本建模很困难，但生成它们却很简单。由于不规则性的高度多样性，随机生成的样本可以被认为是关于目标类的异常实例，具有高概率。我们使用二元分类法来检测(G2D)异常。我们的方法，即 G2D，由三个主要模块组成:(1)不规则发生器网络(<strong class="iz hj"> <em class="kf"> I </em> </strong>)，(2) <strong class="iz hj"> <em class="kf"> C </em> </strong> ritic 网络，以及(3)检测器网络(<strong class="iz hj"> <em class="kf"> D </em> </strong>)。</p><p id="1143" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj"> <em class="kf"> I </em> </strong>作为不规则发生器，完全不知道有这样的样本。关键思想是在正常样本上训练 GAN，并在完全收敛之前利用其生成器。事实上，生成的不规则数据应该与正常情况有一些偏差。由<strong class="iz hj"> <em class="kf"> I </em> </strong>连同可用的正常样本一起生成的不规则性，形成用于优化卷积神经网络(CNN)的参数的信息训练集，如<strong class="iz hj"> <em class="kf"> D </em> </strong>以区分正常和异常样本。我们提出的方法的草图如下所示。<strong class="iz hj"> <em class="kf"> I </em> </strong>、<strong class="iz hj"> <em class="kf"> C </em> </strong>和<strong class="iz hj"> <em class="kf"> D </em> </strong>的详细信息在以下章节中描述。</p><figure class="kh ki kj kk fd ij er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kg"><img src="../Images/ec2727c3fd834b1b85e60b0e9a447fb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wnJb3TCSNYCKBpzOK7agow.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">我们提出的方法的概要。(左:)不规则发生器，(右:)不规则检测器。<strong class="bd kp"> I </strong> + <strong class="bd kp"> C </strong>网络在正态类数据上联合对抗训练。在训练期间，几个模型(<strong class="bd kp"> I </strong>具有不同的权重)被认为是异常检测器。作为二元分类器的<strong class="bd kp"> D </strong>网络在所有可用的正常样本上进行训练，并通过<strong class="bd kp"> I </strong> 1:k 生成不规则样本。在训练过程之后，<strong class="bd kp"> D </strong>充当不规则检测器。</figcaption></figure><p id="cde3" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj"> <em class="kf"> I </em> </strong>是为从看不见的类数据中生成样本而定制的。这个网络接收一个从高斯分布采样的随机噪声向量，即 Z∈ N(μ1，σ1)作为输入，然后将其映射到一幅图像上。这种网络可以容易地产生不遵循目标类别分布的样本，即使不需要训练过程并且仅基于随机初始化的参数。<strong class="iz hj"> <em class="kf"> I </em> </strong>网络逐渐得知目标阶层的分布。<strong class="iz hj"> <em class="kf"> I </em> </strong>网络逐渐学习目标阶层的分布。</p><p id="9194" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj"> <em class="kf"> D </em> </strong>网络是用于区分正常样本和模拟异常的分类器。在训练过程之后，有足够的可用数据来训练二元分类器。</p><h1 id="b839" class="kq kr hi bd kp ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak">训练:<em class="ln"> I </em> + <em class="ln"> C </em>和<em class="ln">D</em>T23】</strong></h1><p id="6f1b" class="pw-post-body-paragraph ix iy hi iz b ja lo jc jd je lp jg jh ji lq jk jl jm lr jo jp jq ls js jt ju hb bi translated">为了避免传统氮化镓的缺点对我们的工作造成负面影响，我们使用了 Wasserstein 氮化镓(WGAN)。歧视 WGANs 人的人通常被称为批评家。<strong class="iz hj"><em class="kf">C</em></strong>WGAN 的网络类似于 GAN 的 G 网络，但取消了 sigmoid 功能。在 WGAN 中，<strong class="iz hj"> <em class="kf"> C </em> </strong>网络输出的是标量分数而不是概率。这个分数可以解释为输入图像的真实程度。换句话说，它衡量一个状态(输入)有多好。在训练期间，<strong class="iz hj"> <em class="kf"> I </em> </strong>模型已经被保存用于每个时期。因此，在 n 个时期之后，我们有 n 个不同的模型。选择 n 个保存的模型的 k 个网络作为不规则生成器可以以两种方式完成:(1)使用包括正常和异常数据的验证集，以及(2)通过分析<em class="kf"> I </em>网络损耗。事实上，没有任何样本来自离群类。因此，使用验证样本是不可行的，也就是说，这种方法完全违背了我们的主要假设。为了遵循第二种解决方案，不规则网络选择如下</p><figure class="kh ki kj kk fd ij er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lt"><img src="../Images/2625f903c0fc59891c964fee054e846d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6uZRTyinyUcP1bcqEiWfdQ.png"/></div></div></figure><figure class="kh ki kj kk fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/4b27c002068b1ad010f90bb0312c9686.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*_lKOQUX1vlOH8KvyapOimg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">损失函数值与网络行为的关系。</figcaption></figure><p id="acea" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">我们的目标是提出一个端到端的神经网络来检测不规则样本。因此，如前所述，仅<strong class="iz hj"> <em class="kf"> D </em> </strong>网络在视频中起到异常检测器的作用，在图像中起到异常检测器的作用。二进制分类问题，在我们的情况下是 OCC 任务的转换版本，可以简单地公式化为:</p><figure class="kh ki kj kk fd ij er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lv"><img src="../Images/0e778729e1c8a83f499121da0da21110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*98j0aO-md-zbXd4BmxkXLg.png"/></div></div></figure><p id="f8c3" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">其中α是预定的阈值(在我们的例子中，α等于 0.5)。</p><figure class="kh ki kj kk fd ij er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lw"><img src="../Images/fde94cd785bf161c243ee0500a79c960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B-8Sm1NB34ncoFwH0SxArA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">Caltech-256 数据集上的结果。从一、三或五个选择的类别中随机抽取内联者。此外，不规则性是从类别 257-杂波中随机选择的。前两行:内标物来自一类图像，50%是外标物；两个第二行:内标物来自三类图像，50%为外标物；最后两行:内含物来自五类图像，而离群值占样本的 50%</figcaption></figure><p id="0998" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">要了解更多信息，你可以在这里找到我们的论文。G2D 是#WACV2021 上被接受的论文之一。你可以在<a class="ae ke" href="https://github.com/masoudpz/G2D_generate_to_detect_anomaly" rel="noopener ugc nofollow" target="_blank"> Github </a>找到源代码。请随意询问关于纸张和代码问题。</p></div></div>    
</body>
</html>