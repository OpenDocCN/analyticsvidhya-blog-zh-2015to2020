<html>
<head>
<title>Image Segmentation Task using Fastai v1.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Fastai v1.0的图像分割任务</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-segmentation-task-using-fastai-d8fbf9b5b75a?source=collection_archive---------20-----------------------#2019-11-24">https://medium.com/analytics-vidhya/image-segmentation-task-using-fastai-d8fbf9b5b75a?source=collection_archive---------20-----------------------#2019-11-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c33a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图像分割是将图像的每个像素分类到一个类别中的任务。例如，给定一个骑自行车的人的图像，组成骑自行车的人的每个像素应该被分类到骑自行车的人类别中(下图中的青色)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/54e3e46ff7c3a4060684f8ef33d3f6b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XG9J-9Xmw7I1g4rU_NG6IA.png"/></div></div></figure><p id="ba63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Fastai(一个在线机器学习课程)通过用这个<a class="ae jp" href="https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>中的<a class="ae jp" href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/" rel="noopener ugc nofollow" target="_blank"> CamVid数据集</a>训练一个<a class="ae jp" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> U-Net </a>来研究图像分割任务。</p><p id="8a36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个已经训练好的U-Net也可以在这个<a class="ae jp" href="https://colab.research.google.com/gist/feiwu77777/5c87836e5f319f71a3150018c042fdf8/image_segmentation.ipynb#scrollTo=J_xaleEeS-6f" rel="noopener ugc nofollow" target="_blank"> colab笔记本</a>上测试。</p><h2 id="cdc9" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">数据</h2><p id="599f" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">图像分割数据被组织成成对的图像和遮罩。图像由形状张量(h，w，c)表示，其中<em class="kq"> h </em>、<em class="kq"> w </em>和<em class="kq"> c </em>是图像的高度、宽度和通道号。掩模由形状张量(h，w，N)表示。如果总共有<em class="kq"> N </em>个类(类别)要分类，则遮罩的每个像素是长度为<em class="kq"> N </em>的向量，其中0在各处，1在索引<em class="kq"> i </em>处(对应类的标签)。</p><p id="5a16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将加载和预处理图像及其各自的用于训练和验证步骤的掩码的加载器由以下代码行定义:</p><pre class="je jf jg jh fd kr ks kt ku aw kv bi"><span id="7d9a" class="jq jr hi ks b fi kw kx l ky kz">src = (SegmentationItemList.from_folder(path_of_dataset)<br/>       .split_by_fname_file('../valid.txt')<br/>       .label_from_func(get_y_fn, classes=codes))</span><span id="2a99" class="jq jr hi ks b fi la kx l ky kz">data = (src.transform(get_transforms(), size=size, tfm_y=True)<br/>        .databunch(bs=bs)<br/>        .normalize(imagenet_stats))</span></pre><h2 id="874f" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">模型</h2><p id="8292" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">用于将图像映射到其相应遮罩的模型是一个<a class="ae jp" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> U-Net </a>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lb"><img src="../Images/6b2dffc03519c01466bf05dfafab842d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VPwlGWr7Xe1nSW6uQDl8nQ.png"/></div></div></figure><p id="0cfc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jp" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> U-Net </a>(下采样路径)的第一部分是一个标准的卷积网络(fastai的<a class="ae jp" href="https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>中的resnet)，它逐渐减小图像的大小，增加其通道数。</p><p id="25e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jp" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> U-Net的第二部分</a>(上采样路径)相反，逐渐增加图像张量的大小并减少其通道数。每次对图像张量进行上采样时，它都与下采样路径中相应的图像张量连接(灰色箭头)。通过这样做，该模型可以更好地定位输入图像的特定区域中最深层的信息。</p><p id="4f4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">带有特定数据集的U-Net可以用一行创建。</p><pre class="je jf jg jh fd kr ks kt ku aw kv bi"><span id="0e34" class="jq jr hi ks b fi kw kx l ky kz">learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd)</span></pre><h2 id="035b" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">培养</h2><p id="4c2d" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">为了训练U-Net，fastai使用具有默认参数的Adam优化器，权重衰减为1e-2，并选择以下每次迭代的学习速率(1个时期具有大约70次迭代/批次)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lc"><img src="../Images/5def46adbfddc363e4b81cfc755d7ab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u50SmQrLmwQhrN6H1ReQYA.png"/></div></div></figure><p id="8f71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">学习率的这种形状可以训练更一般化的模型，因为学习率的稳定提升可以允许优化过程逃脱局部最小值。</p><p id="764c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损失函数是softmax损失的平均值(nn。PyTorch中的CrossEntropyLoss)应用于每个像素。U-Net的下采样路径是用ImageNet预训练的。它首先被冻结，并且在开始时只训练上采样路径。然后通过解冻下采样路径来训练整个U-Net。</p><pre class="je jf jg jh fd kr ks kt ku aw kv bi"><span id="e710" class="jq jr hi ks b fi kw kx l ky kz">learn.fit_one_cycle(10, slice(lr), pct_start=0.9)<br/>learn.unfreeze()<br/>learn.fit_one_cycle(10, slice(lr/400,lr/4), pct_start=0.8)</span></pre><p id="04d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Fastai然后建议增加输入图像的大小，以进一步训练模型。其目的是减少过拟合，并作为迁移学习步骤。该模型用较小版本的图像进行“预训练”,然后用较大版本的图像进行训练。</p><pre class="je jf jg jh fd kr ks kt ku aw kv bi"><span id="2213" class="jq jr hi ks b fi kw kx l ky kz">learn.destroy()<br/>data = (src.transform(get_transforms(), size=size*2, tfm_y=True)<br/>        .databunch(bs=bs)<br/>        .normalize(imagenet_stats))<br/>learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd)</span><span id="477b" class="jq jr hi ks b fi la kx l ky kz">learn.fit_one_cycle(10, slice(lr), pct_start=0.8)<br/>learn.unfreeze()<br/>learn.fit_one_cycle(10, lrs)</span></pre><h2 id="548d" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">结果</h2><p id="f520" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">经过40代的训练，这里是一些图像分割结果的例子。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ld"><img src="../Images/d8cbea6aa8aca2c91e882ce911d7533a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CPMmG8kZ44qossS0Vp1_rQ.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">基本事实/预测</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/47316b5acd4d472192162e0e3a219c8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*agtQHu75ZDzqpyiyp0FIxQ.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">基本事实/预测</figcaption></figure></div></div>    
</body>
</html>