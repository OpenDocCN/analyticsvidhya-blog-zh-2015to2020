<html>
<head>
<title>Setting up Isolated Virtual Environments in SparkR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在SparkR中设置隔离的虚拟环境</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/setting-up-isolated-virtual-environments-in-sparkr-ff4795db8cfc?source=collection_archive---------13-----------------------#2020-12-05">https://medium.com/analytics-vidhya/setting-up-isolated-virtual-environments-in-sparkr-ff4795db8cfc?source=collection_archive---------13-----------------------#2020-12-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/09903775dbd987cf79b2c92b159e0bd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ihh9Q13yOW-WB723IHGKg.png"/></div></div></figure><h1 id="0502" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">动机</h1><p id="d4fc" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">随着Spark越来越多地被用于扩展ML管道，如果我们想使用UDF，安装和部署我们自己的R库变得尤为重要。在我的<a class="ae km" href="https://shbhmrzd.medium.com/stl-and-holt-from-r-to-sparkr-1815bacfe1cc" rel="noopener">上一篇文章</a>中，我谈到了使用SparkR UDFs在R中缩放ML管道。<br/>今天，我将讨论为我们的SparkR运行设置一个虚拟环境，确保运行时依赖项和库安装在集群上。</p><h1 id="c21b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">限制</h1><p id="e485" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">对于任何Spark集群，我们都可以在集群中的所有节点上安装R和所需的库，或者根据需要创建虚拟环境。<br/>在我的例子中，我们有一个Cloudbreak集群，它只能访问边缘节点来提交Spark作业。所有其他群集节点都不可访问。<br/>由于这些限制，我无法在边缘节点或集群上安装R和任何依赖项。</p><h1 id="7db9" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">创造环境</h1><p id="f35c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">因为我们目前在R中运行ML算法，所以我们有一个带有R的docker映像，所有的ML库都安装在它上面。我创建了一个新的映像，在其上安装了Spark (v2.3.0，与Cloudbreak cluster相同)。</p><p id="7c0b" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">在这个容器上成功执行ML算法的SparkR实现[使用较小的数据集]确保了我可以使用这个R安装目录在CloudBreak集群上设置虚拟环境。由于权限限制，我们不能直接在Cloudbreak集群上安装R，所以我打算将R安装目录从容器转移到边缘节点。</p><p id="c6ac" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj"> install_spark.sh </strong>:安装spark的Shell脚本。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="cecd" class="lb ir hi kx b fi lc ld l le lf">yum -y install wget</span><span id="017d" class="lb ir hi kx b fi lg ld l le lf">wget — no-check-certificate <a class="ae km" href="https://www.scala-lang.org/files/archive/scala-2.11.8.tgz" rel="noopener ugc nofollow" target="_blank">https://www.scala-lang.org/files/archive/scala-2.11.8.tgz</a></span><span id="7384" class="lb ir hi kx b fi lg ld l le lf">tar xvf scala-2.11.8.tgz<br/>mv scala-2.11.8 /usr/lib<br/>ln -sf /usr/lib/scala-2.11.8 /usr/lib/scala<br/>export PATH=$PATH:/usr/lib/scala/bin</span><span id="2a3c" class="lb ir hi kx b fi lg ld l le lf">wget — no-check-certificate <a class="ae km" href="https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz" rel="noopener ugc nofollow" target="_blank">https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz</a></span><span id="8496" class="lb ir hi kx b fi lg ld l le lf">tar xvf spark-2.3.0-bin-hadoop2.7.tgz<br/>mkdir /usr/local/spark<br/>cp -r spark-2.3.0-bin-hadoop2.7/* /usr/local/spark</span><span id="1964" class="lb ir hi kx b fi lg ld l le lf">export SPARK_EXAMPLES_JAR=/usr/local/spark/examples/jars/spark-examples_2.11–2.3.0.jar</span><span id="e0d0" class="lb ir hi kx b fi lg ld l le lf">ln -sf /usr/bin/python3 /usr/bin/python<br/>export PATH=$PATH:/usr/local/spark/bin</span><span id="2343" class="lb ir hi kx b fi lg ld l le lf">#Installation directory of R on container : /usr/lib64/R </span></pre><p id="bcbf" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated"><strong class="jq hj"> Dockerfile </strong> : Dockerfile，用于基于安装了R和ML库的现有镜像创建安装了Spark的新镜像。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="814f" class="lb ir hi kx b fi lc ld l le lf">FROM &lt;image_with_R_and_ML_libs_installed&gt;:latest<br/>COPY install_spark.sh ./<br/>RUN bash install_spark.sh<br/>ENV SPARK_EXAMPLES_JAR=”/usr/local/spark/examples/jars/spark-examples_2.11–2.3.0.jar”</span></pre><h1 id="16d3" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">引导环境</h1><h2 id="7bfc" class="lb ir hi bd is lh li lj iw lk ll lm ja jz ln lo je kd lp lq ji kh lr ls jm lt bi translated">火花在本地模式下运行</h2><p id="bde2" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我在edge节点主目录中创建了一个文件夹<em class="lu"> sparkr_packages </em>，并将R安装目录和包从容器中复制到这里。</p><p id="abbd" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">我们还需要设置一些必需的环境变量。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="cd27" class="lb ir hi kx b fi lc ld l le lf">export PATH=$HOME/sparkr_packages/R/bin:$PATH<br/>export R_LIBS=$HOME/sparkr_packages/R/library<br/>export RHOME=$HOME/sparkr_packages/R<br/>export R_HOME=$HOME/sparkr_packages/R</span></pre><p id="545e" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">R安装需要某些编译时依赖项，安装后就不需要了。因为我们已经成功地在容器上安装了R并通过了验证，所以我们不需要边缘节点上的这些依赖项。</p><p id="91dd" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">我们仍然需要在RScript执行期间所需的运行时依赖项。如果没有这些库，启动R控制台将会失败，并显示如下错误</p><blockquote class="lv lw lx"><p id="1ec0" class="jo jp lu jq b jr kn jt ju jv ko jx jy ly kp kb kc lz kq kf kg ma kr kj kk kl hb bi translated">$ HOME/sparkr _ packages/R/bin/exec/R:加载共享库时出错:libtre.so.5:无法打开共享对象文件:没有这样的文件或目录</p></blockquote><p id="325b" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">在我的例子中，我需要边缘节点上的<em class="lu"> libtre.so.5 </em>和<em class="lu">libpcre 2–8 . so . 0</em>。</p><p id="36bd" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">这些库也存在于容器中的<em class="lu"> /usr/lib64/ </em>。就像R安装目录一样，我也将它们复制到位于<em class="lu"> sparkr_packages </em>的边缘节点。<br/>我们需要设置LD_LIBRARY_PATH指向这个位置，以便R运行时访问这些库。我们还可以将这些库添加到R/libs中，使它们在R运行时可用。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="5386" class="lb ir hi kx b fi lc ld l le lf">export LD_LIBRARY_PATH=$HOME/sparkr_packages:$LD_LIBRARY_PATH</span></pre><p id="0ea4" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">我们现在可以在本地模式下启动SparkR控制台，并运行UDF来验证边缘节点上的安装。</p><h2 id="9550" class="lb ir hi bd is lh li lj iw lk ll lm ja jz ln lo je kd lp lq ji kh lr ls jm lt bi translated">火花发生器以集群模式运行</h2><p id="886a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">对于在集群模式下运行的SparkR使用UDF，R安装目录和运行时依赖项必须存在于所有执行器上。我们还需要在每个执行器上设置相应的环境变量。</p><p id="00c7" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">我们可以使用spark-submit运行时参数<em class="lu">存档</em>将压缩的sparkr _ packages目录发送给所有的执行器。</p><blockquote class="lv lw lx"><p id="820f" class="jo jp lu jq b jr kn jt ju jv ko jx jy ly kp kb kc lz kq kf kg ma kr kj kk kl hb bi translated">- archive:接受一个逗号分隔的归档列表，该列表将被提取到每个执行器的工作目录中。</p></blockquote><p id="4816" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">在spark-submit过程中，我们可以通过使用config<em class="lu">spark . executorenv .&lt;property _ name&gt;=&lt;property _ value&gt;</em>为每个执行器设置R_HOME、LD_LIBRARY_PATH、PATH等环境变量。</p><p id="e1ce" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">最后，启动SparkR会话</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="2747" class="lb ir hi kx b fi lc ld l le lf">sparkR —-master yarn —-conf spark.executorEnv.RHOME=./environment/sparkr_packages/R —-conf spark.executorEnv.R_HOME_DIR=./environment/sparkr_packages/R —-conf spark.executorEnv.PATH=./environment/sparkr_packages/R/bin:$PATH —-conf spark.executorEnv.LD_LIBRARY_PATH=./environment/sparkr_packages:$LD_LIBRARY_PATH —-num-executors 10 —-executor-cores 3 —-executor-memory 10g —-archives sparkr_packages.zip#environment</span></pre><h1 id="e6b4" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论</h1><p id="0912" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">像这样设置虚拟环境有点麻烦，因为我们必须手动维护R可执行文件和模块。<br/>尽管如此，这种方法对我们非常有用，让我们能够在不访问集群节点的情况下建立虚拟环境。</p></div></div>    
</body>
</html>