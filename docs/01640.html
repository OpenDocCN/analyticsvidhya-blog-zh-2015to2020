<html>
<head>
<title>Types of Activation Functions in Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络中激活函数的类型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/https-medium-com-types-of-activation-functions-in-neural-network-504ddba28e35?source=collection_archive---------8-----------------------#2019-11-05">https://medium.com/analytics-vidhya/https-medium-com-types-of-activation-functions-in-neural-network-504ddba28e35?source=collection_archive---------8-----------------------#2019-11-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9be00b42606bce860731cbe06a7a4835.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pVAK4JVYrft7yRjd1K9XIg.png"/></div></div></figure><p id="3ec9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">什么是激活函数？</p><p id="87fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">激活函数</strong>通常是代表细胞内动作电位发放速率的抽象概念。在最简单的形式下，这个函数是二元的——也就是说，要么神经元在放电，要么不放电。</p><p id="40b0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">激活函数在神经网络中的作用是什么？</p><p id="15d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">激活函数的目标是将非线性引入神经元的输出。</p><p id="1ff1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为什么我们需要非线性激活函数？</p><p id="b5f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你使用线性激活函数(身份激活函数，例如:y=ax)，那么神经网络只是输出输入的线性函数。换句话说，无论网络有多少层，它的行为就像一个单层感知器，因为将这些层相加只会给你另一个线性函数。</p><p id="54c0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">激活功能的类型:</p><p id="3130" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有许多类型的激活功能。在本文中，我们将看到我在项目中使用的函数以及每个函数的python实现。</p><ol class=""><li id="4cea" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">乙状结肠的</li><li id="ae21" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">双曲正切</li><li id="5676" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">热卢</li><li id="4996" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">卢瑟</li><li id="8ad7" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">Softplus</li><li id="a53a" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">软设计</li></ol><p id="92a2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">乙状结肠功能:</strong></p><p id="0661" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们熟悉这个函数，因为我们在逻辑回归中使用过它。</p><p id="2455" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数学方程式:f(x)= </strong> 1/(1+e^(-x)</p><p id="9fa0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">值的范围是从0到1。</p><p id="e647" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Python实现:请参考<strong class="is hj">Github link "</strong><a class="ae kc" href="https://github.com/vivekpandian08/activation-function" rel="noopener ugc nofollow" target="_blank">https://github.com/vivekpandian08/activation-function</a></p><p id="2822" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">双曲正切函数:</strong></p><p id="294d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正切双曲函数。它比使用s形函数给出更好的结果，但不是最好的。</p><p id="b360" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数学方程:f(x)= </strong> (2/(1 + e-2x))-1</p><p id="d7db" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">值的范围是从-1到1。</p><p id="3bf0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> Relu功能:</strong></p><p id="68ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">整流线性单元。由于它的非线性性质，它是隐藏单元中最常用的激活函数。</p><p id="84e2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数学方程:f(x)= </strong> max(0，x)</p><p id="dba2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当x为正时，它给出x的值，否则给出0。</p><p id="05a1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">值的范围是从0到无穷大。</p><p id="f14e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">卢瑟功能:</strong></p><p id="2ee1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">比例指数线性单位。它支持深度神经网络，因为没有消失梯度的问题。</p><p id="1128" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数学等式:f(x) = </strong> λ*x对于所有x &gt; 0，λ*αe(x)α否则。</p><p id="644b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">值的范围是从-无穷大到无穷大。</p><p id="aee2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">软加功能:</strong></p><p id="ab8d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">郑等人(2015)的研究论文“使用softplus单元改进深度神经网络”表明，softplus比ReLU函数为深度神经网络提供了更多的稳定性和性能。</p><p id="fd33" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数学方程式:f(x) = </strong> log(exp(x)+1)</p><p id="1cbd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">值的范围是从-无穷大到无穷大。</p><p id="855c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">软标记功能:</strong></p><p id="c855" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Softsign是神经网络双曲正切激活函数的替代方案。尽管tanh和softsign函数密切相关，但重要的区别是tanh以指数方式收敛，而softsign以多项式方式收敛。</p><p id="2aad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数学方程式:f(x)=x/abs(x)+1 </strong></p><p id="af5b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">值的范围是从-1到+1。</p><p id="c2ec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在下一篇文章中，我们将介绍其他重要的高级激活函数，如reaky relu、parametric relu等。</p><p id="2d09" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Git hub链接:【https://github.com/vivekpandian08/activation-function T2】</p><p id="31ec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感谢阅读。</p></div></div>    
</body>
</html>