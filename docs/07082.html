<html>
<head>
<title>End-to-End Object Detection with Transformers(DETR)-by Facebook AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用变压器的端到端对象检测(DETR)-脸书·艾</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/end-to-end-object-detection-with-transformers-detr-by-facebook-ai-833f4086280a?source=collection_archive---------8-----------------------#2020-06-13">https://medium.com/analytics-vidhya/end-to-end-object-detection-with-transformers-detr-by-facebook-ai-833f4086280a?source=collection_archive---------8-----------------------#2020-06-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/31967c1e8b2d76093d790fd5527c162b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CWVq7FIjq0sVSynnHaezyA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://arxiv.org/pdf/2005.12872.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2005.12872.pdf</a></figcaption></figure><h1 id="97a8" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated"><strong class="ak">物体探测一目了然</strong></h1><p id="6258" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">在计算机视觉中，目标检测是一项任务，我们希望我们的模型能够区分前景目标和背景，并预测图像中目标的位置和类别。</p><p id="9ea0" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">有许多用于物体检测的框架，但脸书人工智能的研究人员提出了DETR，这是一种创新而有效的方法来解决物体检测问题。</p><h1 id="1cd2" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">介绍</h1><p id="360e" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">借助于基于变换器的编码器-解码器架构，DETR将对象检测问题视为直接集预测问题。我说的集合是指边界框的集合。变形金刚是深度学习模型的新品种，在NLP领域表现突出。这是第一次有人用变形金刚进行物体检测。</p><p id="3fc1" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">本文的作者在最受欢迎的对象检测数据集之一COCO上评估了DETR，对比了非常有竞争力的更快的R-CNN基线。</p><p id="299f" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在结果中，DETR取得了类似的表现。更准确地说，DETR在大型对象上表现出明显更好的性能。然而，它在小对象上的表现并不好。</p><h1 id="8d81" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">DETR模式</h1><p id="02e0" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">大多数现代对象检测方法相对于一些初始猜测进行预测。两级检测器(R-CNN系列)预测盒w.r.t .建议，而单级方法(YOLO)预测w.r.t .锚或可能的对象中心网格。最近的工作表明，这些系统的最终性能很大程度上取决于这些初始猜测的确切设置方式。在我们的模型(DETR)中，我们能够去除这种手工制作的过程，并通过使用绝对盒预测对输入图像而不是锚直接预测检测集来简化检测过程。</p><p id="b966" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">对于检测中的直接集合预测来说，两件事是必不可少的:</p><ol class=""><li id="7997" class="kw kx hi jv b jw kr ka ks ke ky ki kz km la kq lb lc ld le bi translated">一组预测损失，强制在预测框和实际框之间进行唯一匹配</li><li id="b76d" class="kw kx hi jv b jw lf ka lg ke lh ki li km lj kq lb lc ld le bi translated">一种预测(在一次传递中)一组对象并对它们的关系建模的体系结构</li></ol><p id="1237" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">脸书人工智能的研究人员在预测和基础事实对象之间使用了二分匹配，这确保了预测和基础事实对象/边界框之间的一对一映射。</p><p id="1c6b" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">DETR在单次通过解码器的过程中推断出一组固定大小的N个预测，其中N被设置为明显大于图像中对象的典型数量。这N个用户必须根据他们的需要来决定。假设在一个图像中最多有5个对象，因此我们可以定义(N=7，8，..).假设N=7，那么DETR推断出一组7个预测。在这7个预测中，5个预测将用于对象，2个预测用于∅(no对象)意味着它们将分配给背景。每个预测是一种包含类和包围盒(c，b)的元组。</p><h1 id="5c05" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">DETR建筑</h1><p id="f14b" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">DETR的整体架构很容易理解。它包含三个主要组件:</p><ol class=""><li id="a904" class="kw kx hi jv b jw kr ka ks ke ky ki kz km la kq lb lc ld le bi translated">CNN主干网</li><li id="a241" class="kw kx hi jv b jw lf ka lg ke lh ki li km lj kq lb lc ld le bi translated">编码器-解码器变压器</li><li id="0fbe" class="kw kx hi jv b jw lf ka lg ke lh ki li km lj kq lb lc ld le bi translated">简单前馈网络</li></ol><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/300cd1fb3bc30db789e31d0ec9b37ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_BU_YRIRTzqAXzSQuRgQMQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://arxiv.org/pdf/2005.12872.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2005.12872.pdf</a></figcaption></figure><p id="d421" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">DETR使用传统的CNN骨干来学习输入图像的2D表示。该模型将其展平，并在将其传递到transformer编码器之前用位置编码对其进行补充。然后，变换器解码器将固定数量(N)的学习位置嵌入作为输入，我们称之为对象查询，并另外关注编码器输出。我们将解码器的每个输出嵌入传递到共享前馈网络(FFN ),该网络预测检测(类和边界框)或∅(no对象(类)。</p><p id="0db7" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">解码器遵循转换器的标准架构，使用多头自和编码器-解码器注意机制转换大小为d的N个嵌入。与原始转换器的不同之处在于，我们的模型在每个解码器层并行解码N个对象，而原始转换器使用自回归模型，一次预测一个元素的输出序列。</p><p id="f99c" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">解码器将N个对象查询转换成输出嵌入。然后通过前馈网络将它们独立解码成盒坐标和类别标签，从而产生N个最终预测。使用自身和编码器-解码器对这些嵌入的关注，该模型使用所有对象之间的成对关系来整体推理所有对象，同时能够使用整个图像作为上下文。</p><p id="dea4" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">最终预测由一个具有ReLU激活函数和隐藏维数d的3层感知器和一个线性投影层计算。FFN根据输入影像预测盒子的归一化中心坐标、高度和宽度，线性图层使用softmax函数预测分类标注。因为我们预测一组固定大小的n个边界框，其中n通常大于图像中感兴趣对象的实际数量，所以使用额外的特殊类别标签∅来表示在一个槽内没有检测到对象。这个类在标准对象检测方法中扮演类似于“背景”类的角色。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/7d2d3ca0411c09a69bd0881b58eb42c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C76AsJX6FoOdcnxvpN3_lw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://arxiv.org/pdf/2005.12872.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2005.12872.pdf</a></figcaption></figure><p id="5eb4" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在上面的图像中，我们可以看到我们的DETR推断出6个预测，但6个预测中只有2个预测被分配给对象，其余的预测属于∅(no对象类别。</p><h1 id="c886" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">结论</h1><p id="f2d9" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">脸书人工智能的研究人员提出了一种简单的物体检测方法。这是第一次有人用变形金刚来探测物体。在自然语言处理领域，我们看到变形金刚表现突出，这似乎是自然语言处理领域的一个重大突破。</p><p id="09a7" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">DETR不需要任何后处理步骤，如我们在YOLO或SSD中使用的非最大值抑制，因为二分匹配确保了预测和地面真相框之间的一对一映射。</p><p id="97c2" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj">参考文献</strong></p><p id="99b4" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">【https://arxiv.org/pdf/2005.12872.pdf T4】</p></div></div>    
</body>
</html>