<html>
<head>
<title>Understanding Residual Network (ResNet)Architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解剩余网络(ResNet)架构</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-resnet-architecture-869915cc2a98?source=collection_archive---------4-----------------------#2020-09-09">https://medium.com/analytics-vidhya/understanding-resnet-architecture-869915cc2a98?source=collection_archive---------4-----------------------#2020-09-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="12b1" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">PyTorch中的实现</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/3851a85f2a29f9569ca70417a7707e0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gbnZ6oCsteAexIi2s9jb1A.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">仿佛跳绳只限于人类！！</figcaption></figure><p id="7e23" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">非常深的网络通常导致梯度消失，因为梯度被反向传播到更早的层，重复乘法可以使梯度无限小。ResNet使用包含快捷跳过连接的剩余块的概念来跳过一些层。</p><p id="f05d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">ResNet论文的作者提供的证据表明，残差网络更容易优化，并且可以通过将层重构为参考层输入的学习残差函数，从显著增加的深度中获得准确性。</p><p id="e7c5" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">再详细了解一下吧！！</p><h2 id="77f7" class="kk kl hi bd km kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">残余块</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lf"><img src="../Images/4a33735bb05efd49d01d9a11a98b53c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3wubYL0XmePeU1KH7cMAXQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">残余块</figcaption></figure><p id="ba23" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">具有剩余块的网络背后的直觉是<em class="lg"> </em>每一层被馈送到网络的下一层，并且还直接到下一层，在中间的几层之间跳过。残余块允许你训练更深层次的神经网络。该连接(灰色箭头)被称为<strong class="jp hj">跳过连接或快捷连接</strong>，因为它绕过了中间的一个或多个层。它也被称为<strong class="jp hj">恒等式连接</strong>，因为我们可以从中学习一个恒等式函数。</p><blockquote class="lh li lj"><p id="8fa9" class="jn jo lg jp b jq jr ij js jt ju im jv lk jx jy jz ll kb kc kd lm kf kg kh ki hb bi translated">快捷连接只是执行身份映射，它们的输出会添加到堆叠层的输出中。恒等式快捷连接既不增加额外的参数，也不增加计算复杂度。整个网络仍然可以通过具有反向传播的SGD进行端到端的训练，并且可以在不修改解算器的情况下使用公共库容易地实现。</p></blockquote><p id="5645" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><a class="ae kj" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lg">来源:——用于图像识别的深度残差学习</em> </a></p><h1 id="a6d9" class="ln kl hi bd km lo lp lq kq lr ls lt ku io lu ip kx ir lv is la iu lw iv ld lx bi translated">ResNet架构</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ly"><img src="../Images/b92f3960e863b309946f65ffedb2b0da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1CSCPAEhvtBPcjNA9bll0A.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">ResNet34架构</figcaption></figure><p id="4bb2" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">让我们深入研究ResNet34架构:-</p><ul class=""><li id="cce0" class="lz ma hi jp b jq jr jt ju jw mb ka mc ke md ki me mf mg mh bi translated">它从一个7x7大小的内核(64)的卷积层开始，步长为2，随后是一个最大池操作。</li><li id="030e" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated">它由四个剩余块组成(分别为配置:- 3、4、6和3)</li><li id="9902" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated">每个块的通道是恒定的，分别为64、128、256、512。</li><li id="1a95" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated">这些模块中只使用了3x3内核。</li><li id="2e4c" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated">除了第一个块，每个块都以步幅为2的3x3内核开始。</li><li id="c89e" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated">虚线为<strong class="jp hj">跳过连接</strong>。</li></ul><p id="8e6c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">当输入和输出具有相同的维数，但是维数不同时(即，输入大于剩余输出)，可以直接添加虚线或单位快捷方式，默认的解决方法是使用步长为2的1x1卷积。</p><p id="f328" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">对于ResNet34，我们有四个配置为3，4，6，3的剩余块。类似地，对于ResNet18模型，我们有配置为2，2，2，2的四个残差块。除了这些，其他版本还有ResNet瓶颈(R50、R101、R152)、ResNet V3、ResNeXt。</p></div><div class="ab cl mn mo gp mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="hb hc hd he hf"><h1 id="da10" class="ln kl hi bd km lo mu lq kq lr mv lt ku io mw ip kx ir mx is la iu my iv ld lx bi translated">在CIFAR-10数据集上训练ResNet模型</h1><h2 id="5dc4" class="kk kl hi bd km kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated"><strong class="ak">使用的数据集</strong></h2><p id="f894" class="pw-post-body-paragraph jn jo hi jp b jq mz ij js jt na im jv jw nb jy jz ka nc kc kd ke nd kg kh ki hb bi translated">CIFAR-10数据集(加拿大高级研究所)是一个图像集合，通常用于训练深度学习算法。</p><ul class=""><li id="b0bb" class="lz ma hi jp b jq jr jt ju jw mb ka mc ke md ki me mf mg mh bi translated">它包含<strong class="jp hj">60000张</strong>大小为<strong class="jp hj">32×32</strong>的彩色图像，适用于<strong class="jp hj"> 10种不同的等级</strong>。</li><li id="eb56" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated">10个不同的类别是:飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。每个类有6000张图片。</li></ul><h2 id="a63e" class="kk kl hi bd km kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated"><strong class="ak">实施</strong></h2><p id="8359" class="pw-post-body-paragraph jn jo hi jp b jq mz ij js jt na im jv jw nb jy jz ka nc kc kd ke nd kg kh ki hb bi translated">我已经使用了来自<a class="ae kj" href="https://github.com/kuangliu/pytorch-cifar" rel="noopener ugc nofollow" target="_blank">这个</a> Github repo的ResNet实现。我使用了ResNet18模型架构，并在CIFAR-10数据集上对其进行了10个时期的训练。</p><p id="e4f9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">你可以在PyTorch <a class="ae kj" href="https://github.com/poojamahajan0712/medium_blog/tree/master/CIFAR_Resnet" rel="noopener ugc nofollow" target="_blank">中找到相应的实现代码。</a></p></div><div class="ab cl mn mo gp mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="hb hc hd he hf"><h2 id="fa02" class="kk kl hi bd km kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">参考</h2><ul class=""><li id="5b2a" class="lz ma hi jp b jq mz jt na jw ne ka nf ke ng ki me mf mg mh bi translated"><a class="ae kj" href="https://learning.oreilly.com/library/view/deep-learning-with/9781789534092/f61e9609-c07b-46d6-a54b-096c2714a632.xhtml" rel="noopener ugc nofollow" target="_blank">https://learning . oreilly . com/library/view/deep-learning-with/9781789534092/f61e 9609-c07b-46d 6-a54b-096 c 2714 a632 . XHTML</a></li><li id="c6f3" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated"><a class="ae kj" href="https://arxiv.org/pdf/1611.05431v2.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1611.05431v2.pdf</a></li><li id="154a" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated"><a class="ae kj" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1512.03385.pdf</a></li><li id="a2e1" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated"><a class="ae kj" href="https://www.youtube.com/watch?v=ZILIbUvp5lk" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=ZILIbUvp5lk</a></li><li id="a733" class="lz ma hi jp b jq mi jt mj jw mk ka ml ke mm ki me mf mg mh bi translated"><a class="ae kj" href="https://www.youtube.com/watch?v=RYth6EbBUqM" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=RYth6EbBUqM</a></li></ul></div></div>    
</body>
</html>