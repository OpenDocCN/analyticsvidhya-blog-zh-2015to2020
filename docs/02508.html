<html>
<head>
<title>Use Pytorch to create an image captioning model with pretrained Resnet50 and LSTM and train on google Colab GPU (seq2seq modeling).</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Pytorch创建一个带有预训练Resnet50和LSTM的图像字幕模型，并在google Colab GPU上进行训练(seq2seq建模)。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/use-pytorch-to-create-an-image-captioning-model-with-cnn-and-seq2seq-lstm-and-train-on-google-e6563cb9f511?source=collection_archive---------5-----------------------#2019-12-20">https://medium.com/analytics-vidhya/use-pytorch-to-create-an-image-captioning-model-with-cnn-and-seq2seq-lstm-and-train-on-google-e6563cb9f511?source=collection_archive---------5-----------------------#2019-12-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0fc8144488ee087b74c191d62a8ef8ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QfC2FMb2wZjV4j58"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">萨法尔·萨法罗夫在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="c17a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">点击这里查看完整步骤和详情:<a class="ae iu" href="https://github.com/rammyram/image_captioning/blob/master/Image_Captioning.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/rammyram/Image _ captioning/blob/master/Image _ captioning . ipynb</a></p><p id="d03a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">使用的训练数据集:</strong></p><p id="f887" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用COCO 2014数据集。欢迎您使用最新数据以获得更好的结果。</p><p id="dd97" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以跟着官方的github repo学习如何使用COCO API。输入注释文件的路径，然后我们可以从数据集可视化图像。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jt"><img src="../Images/8629010018ff0f2f689956e81b83d66a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*szYdgUBdiArjCZ8bxyoxjQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">加载注释</figcaption></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jy"><img src="../Images/e9df6cc6a47bb346fc595639b3cae521.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*7FU5sAm6sTaPx3TCvRWqcg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">选择一个随机的注释id，并可视化相应的图像和标题</figcaption></figure><p id="0f07" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">预处理步骤:</strong></p><p id="3606" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我已经应用了通常的预处理步骤，如调整大小，随机裁剪，图像正常化。</p><p id="ee9b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用NLKT对字幕进行标记化，并通过出现次数过滤了对我们的训练没有太大帮助的罕见单词。我们添加了开始和结束标记来标识标题的开始和结束，这些标题对应于idx2word字典中的索引0和1。例如，一个原始文本句子“我很棒”将被标记为[，'我'，' am '，'很棒'，]，并最终变成[0，23，8，14，1]。</p><p id="f318" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">图像上标题的长度是可变的，但我们的模型要求每批输入固定的长度。通常我们会使用pytorch中的填充函数来填充或截断它们，使它们在mini batch中具有相同的长度。或者我们可以使用pytorch中的SubsetRandomSampler从给定的索引列表中随机抽取元素。我们首先生成一个随机数≤字幕的最大长度，例如13。然后，我们使用np.where获取长度=13的标题的所有索引。</p><p id="9f7c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了节省时间，我们应用了预先训练的resnet50。记得删除最后的FC层，因为我们不做图像分类，我们只需要提取特征和连接特征向量与LSTM在解码器中。记住冻结resnet50的参数，否则会损坏训练重量。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jz"><img src="../Images/5e2e1257aa1ff1158a24a36371bc5997.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/0*DWJVDeDT7fm1UTsF.PNG"/></div></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/41c58da9e76bc18b37b2b30efa552ddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/0*AY3Y0Ms8NMNf9Ioz.PNG"/></div></figure><p id="45d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">解码器中的正向功能:</strong></p><p id="380b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们已经将文本句子转换为整数标记，现在我们添加一个单词嵌入层来增加模型的表示能力。不要忘记连接特征向量(图像)和我们的嵌入矩阵(标题),以传递到LSTM</p><p id="3c31" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">测试用样本函数:</strong></p><p id="75e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不要忘记对测试图像集应用相同的图像预处理步骤。测试图像将经过相同的预处理步骤，并输入到模型中以输出一个令牌，然后我们将整数令牌与word2idx字典进行映射以获得文本令牌。这个记号也成为我们的模型的输入，以预测下一个记号。它一直循环，直到我们的模型读取了令牌。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kb"><img src="../Images/72736234ede1bb97aabd3391f0d35a77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*2puOWnUqBXD3d4WkyTMptQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">DecoderRNN中定义的预测函数，用于预测样本测试数据的标题</figcaption></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kc"><img src="../Images/cdbc0ff4bb8fc6bf6ef3d7213be35dcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w20LneKfxyCuzGlw.PNG"/></div></div></figure></div><div class="ab cl kd ke gp kf" role="separator"><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki"/></div><div class="hb hc hd he hf"><p id="bece" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kk">最初发表于</em><a class="ae iu" href="https://github.com/rammyram/image_captioning" rel="noopener ugc nofollow" target="_blank"><em class="kk">【https://github.com】</em></a><em class="kk">。</em></p></div></div>    
</body>
</html>