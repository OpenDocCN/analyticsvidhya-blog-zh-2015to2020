<html>
<head>
<title>Tutorial on How to Run Inference with OpenVino in 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2021年如何用OpenVino运行推理的教程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tutorial-on-how-to-run-inference-with-openvino-in-2021-a96e5e7c99f8?source=collection_archive---------2-----------------------#2020-11-01">https://medium.com/analytics-vidhya/tutorial-on-how-to-run-inference-with-openvino-in-2021-a96e5e7c99f8?source=collection_archive---------2-----------------------#2020-11-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6f24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文旨在提供关于如何使用OpenVino推理引擎的Python API通过对象检测器运行推理的见解。在我寻求了解OpenVino以及如何使用它的过程中，我在网上找到了一些有用的代码示例和教程。然而，我发现的大部分代码使用了不推荐的方法，我努力寻找最新的和最少的推理例子。这就是本文的目的，使用最新的OpenVino包为读者提供最少的代码</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="c425" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文分为以下几个部分，您可以随意跳过:</p><ul class=""><li id="369d" class="jk jl hi ih b ii ij im in iq jm iu jn iy jo jc jp jq jr js bi translated">OpenVino简介</li><li id="af16" class="jk jl hi ih b ii jt im ju iq jv iu jw iy jx jc jp jq jr js bi translated">Linux的安装说明</li><li id="4e0f" class="jk jl hi ih b ii jt im ju iq jv iu jw iy jx jc jp jq jr js bi translated">运行推理的教程代码</li></ul></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="494a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">open vino概述</strong></p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es jy"><img src="../Images/db454d9e3b138fc2c9cacf681b1ca8c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yEsXOwTcfI4O-ZWM.jpg"/></div></div><figcaption class="kk kl et er es km kn bd b be z dx translated">英特尔OpenVino工具包概述|图片鸣谢:英特尔</figcaption></figure><p id="dbc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">OpenVino是英特尔为英特尔硬件开发的工具包。该工具包最初是作为视觉推理和神经优化(VINO)的API解决方案开发的，但是，它已经发展到包括对用于NLP任务的BERT等模型的支持。该工具包的目标是通过应用各种<a class="ae ko" href="https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_Model_Optimization_Techniques.html" rel="noopener ugc nofollow" target="_blank">优化技术</a>充当推理加速器，并充当推理机接口。英特尔提供的API解决方案可分为两个主要部分:</p><ol class=""><li id="0891" class="jk jl hi ih b ii ij im in iq jm iu jn iy jo jc kp jq jr js bi translated">模型优化器</li><li id="dfbd" class="jk jl hi ih b ii jt im ju iq jv iu jw iy jx jc kp jq jr js bi translated">推理机</li></ol><p id="0bf6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ko" href="https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html" rel="noopener ugc nofollow" target="_blank">模型优化器</a>是运行推理的第一步。它包括从您的原生训练框架(TensorFlow、PyTorch、MXNet、ONNX)转换一组模型权重和模型图，并将其转换为描述网络拓扑的. xml文件和存储网络权重的. bin文件。</p><p id="ec5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ko" href="https://docs.openvinotoolkit.org/latest/openvino_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html" rel="noopener ugc nofollow" target="_blank">推理引擎</a>是运行推理的第二步，也是最后一步。它是一个高度可用的接口。xml和。模型优化器创建的bin文件，并对您的数据进行推理。推理机正是本文所要讨论的。如果您正在寻找关于模型优化器的信息，请查看超链接或留意该帐户的更多内容。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="6dcf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">【Linux的安装说明</p><p id="604d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用2020年10月14日发布的OpenVino的最新版本。这就是2021年V1一揽子计划。这个版本的特别之处在于它可以通过pip安装！以前的版本需要注册并从源代码安装，这会给最初的学习曲线增加不必要的负担。安装需要一个pip命令:</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="cb4c" class="kv kw hi kr b fi kx ky l kz la">pip install openvino-python</span></pre><p id="d2f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于操作系统兼容性的细节，这里的<a class="ae ko" href="https://pypi.org/project/openvino-python/" rel="noopener ugc nofollow" target="_blank">是pip项目的链接。</a></p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="1d86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">运行推理教程代码</strong></p><p id="dac2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先我们必须下载一个例子。xml和。bin文件。如果你有自己的。xml和。bin文件可以跳过这一步。如果没有，让我们从英特尔下载一个<a class="ae ko" href="https://docs.openvinotoolkit.org/latest/omz_models_intel_faster_rcnn_resnet101_coco_sparse_60_0001_description_faster_rcnn_resnet101_coco_sparse_60_0001.html" rel="noopener ugc nofollow" target="_blank">预训练的对象检测模型</a>。我们可以使用wget来做到这一点</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="d61c" class="kv kw hi kr b fi kx ky l kz la">wget <a class="ae ko" href="https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/1/faster-rcnn-resnet101-coco-sparse-60-0001/FP32/faster-rcnn-resnet101-coco-sparse-60-0001.xml" rel="noopener ugc nofollow" target="_blank">https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/1/faster-rcnn-resnet101-coco-sparse-60-0001/FP32/faster-rcnn-resnet101-coco-sparse-60-0001.xml</a></span><span id="c2b7" class="kv kw hi kr b fi lb ky l kz la">wget <a class="ae ko" href="https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/1/faster-rcnn-resnet101-coco-sparse-60-0001/FP32/faster-rcnn-resnet101-coco-sparse-60-0001.bin" rel="noopener ugc nofollow" target="_blank">https://download.01.org/opencv/2021/openvinotoolkit/2021.1/open_model_zoo/models_bin/1/faster-rcnn-resnet101-coco-sparse-60-0001/FP32/faster-rcnn-resnet101-coco-sparse-60-0001.bin</a></span></pre><p id="9f74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在你应该下载了两个文件。的。xml文件是网络结构或拓扑。的。bin文件是模型权重，这就是为什么下载时间明显较长的原因。下载了模型结构和权重之后，我们就可以开始运行推理了。</p><p id="1a55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先让我们导入我们将使用的库。</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="ad55" class="kv kw hi kr b fi kx ky l kz la">from openvino.inference_engine import IECore, Blob, TensorDesc<br/>import numpy as np</span></pre><p id="987c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">IECore是处理所有重要后端功能的类。Blob是用于保存输入和输出数据的类。TensorDesc用于描述输入数据特征，如位精度和张量形状。</p><p id="e019" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们设置一些文件路径。</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="99cf" class="kv kw hi kr b fi kx ky l kz la">XML_PATH = "PATH_TO_XML_FILE"<br/>BIN_PATH = "PATH_TO_BIN_FILE"</span></pre><p id="f0c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据您的xml和bin文件路径调整它们的值。这些以后会用到。接下来是加载IECore类。</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="dc16" class="kv kw hi kr b fi kx ky l kz la">ie_core_handler = IECore()</span></pre><p id="fd28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">IECore负责处理所有后端功能。点击查看Python API <a class="ae ko" href="https://docs.openvinotoolkit.org/2021.1/ie_python_api/classie__api_1_1IECore.html" rel="noopener ugc nofollow" target="_blank">。现在，让我们加载网络。</a></p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="780a" class="kv kw hi kr b fi kx ky l kz la">network = ie_core_handler.read_network(model=XML_PATH, weights=BIN_PATH)</span></pre><p id="1fe4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">read_network加载模型结构(。xml文件)和模型权重(.bin文件)到网络变量中。加载模型信息后，我们可以构建可执行的网络。</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="32a4" class="kv kw hi kr b fi kx ky l kz la">executable_network = ie_core_handler.load_network(network, device_name='CPU', num_requests=1)</span></pre><p id="c2ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">load_network接收网络信息，在指定的设备(在本例中是CPU)上构建一个可执行的网络，并返回一组推理请求。为了简单起见，我们将num_requests设置为1，并使用同步执行。请留意未来关于在异步执行中使用多个推理请求的文章。</p><p id="5648" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着executable_network的建立，我们可以访问推理请求。因为我们将num_requests设置为1，所以我们引用索引0并从可执行网络中获取推理请求。</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="36ac" class="kv kw hi kr b fi kx ky l kz la">inference_request = executable_network.requests[0]</span></pre><p id="113e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里查看Python API的推理请求<a class="ae ko" href="https://docs.openvinotoolkit.org/2021.1/ie_python_api/classie__api_1_1InferRequest.html" rel="noopener ugc nofollow" target="_blank"/>。现在，我们可以构建一些虚拟输入数据，并为网络输入做准备。</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="e0fc" class="kv kw hi kr b fi kx ky l kz la">random_input_data = np.random.randn(1, 3, 800, 1280).astype(np.float32)</span><span id="0db7" class="kv kw hi kr b fi lb ky l kz la">tensor_description = TensorDesc(precision="FP32", dims=(1, 3, 800, 1280), layout='NCHW')</span><span id="94b1" class="kv kw hi kr b fi lb ky l kz la">input_blob = Blob(tensor_description, random_input_data)</span></pre><p id="eb75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这三行中，我们将random_input_data设置为随机数据，它将被用作推理请求的输入数据。这可以替换为一个实际的图像，但是，一定要调整到适当的输入大小！我在这里使用为模型<a class="ae ko" href="https://docs.openvinotoolkit.org/latest/omz_models_intel_faster_rcnn_resnet101_coco_sparse_60_0001_description_faster_rcnn_resnet101_coco_sparse_60_0001.html" rel="noopener ugc nofollow" target="_blank">定义的输入大小</a>。然后，我们设置tensor_description，它指定位精度、维度和通道布局。<a class="ae ko" href="https://docs.openvinotoolkit.org/2021.1/ie_python_api/classie__api_1_1TensorDesc.html" rel="noopener ugc nofollow" target="_blank">这个</a>是对TensorDesc类的Python API。最后，我们从blob类构建一个input_blob。Blob类是OpenVino使用的输入层和输出层数据类型。<a class="ae ko" href="https://docs.openvinotoolkit.org/2021.1/ie_python_api/classie__api_1_1Blob.html" rel="noopener ugc nofollow" target="_blank">这里的</a>是Blob类的Python API。</p><p id="4dba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们需要将input_blob放在推理请求的input_layer中。为此，我们使用inference_request.set_blob()方法。但是，我们首先需要input_layer的名称。为了找到名称，我们可以打印所有输入层的名称。</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="8334" class="kv kw hi kr b fi kx ky l kz la">print(inference_request.input_blobs)</span></pre><p id="f7bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">input _ blobs是一个将输入层名称映射到相应blob的字典。我们可以通过获取input _ blobs中的第一个键来捕获输入层名称，而不是打印字典，如下所示:</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="d998" class="kv kw hi kr b fi kx ky l kz la">input_blob_name = next(iter(input_blobs))</span></pre><p id="df0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有了可用的推理请求和相应的输入blob名称，我们可以在推理请求中设置输入blob。</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="d14c" class="kv kw hi kr b fi kx ky l kz la">inference_request.set_blob(blob_name=input_blob_name, blob=input_blob)</span></pre><p id="d82e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有了input_blob集合，我们终于可以运行推理了！</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="7ccb" class="kv kw hi kr b fi kx ky l kz la">inference_request.infer()</span></pre><p id="08cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了在运行推理后获得output_blob，我们还需要output_blob的名称。让我们用上面同样的方法得到它:</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="d277" class="kv kw hi kr b fi kx ky l kz la">output_blob_name = next(iter(inference_request.output_blobs))</span></pre><p id="f580" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有了output_blob_name，我们就可以从inference_request中获得输出。</p><pre class="jz ka kb kc fd kq kr ks kt aw ku bi"><span id="1b3f" class="kv kw hi kr b fi kx ky l kz la">output = inference_request.output_blobs[output_blob_name].buffer</span></pre><p id="54ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">的。buffer属性是output_blob_name为的output_blob中的数据。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="93f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用OpenVino v2021运行推理的教程到此结束。期待看到更多来自这个帐户的相关内容，所以如果你觉得有趣，请关注！</p></div></div>    
</body>
</html>