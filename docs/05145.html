<html>
<head>
<title>Classification of COVID-19 X-ray images with Keras and its potential problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Keras的新冠肺炎X射线图像分类及其潜在问题</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classification-of-covid-19-x-ray-images-with-keras-and-its-potential-problem-e31b3ff16f24?source=collection_archive---------16-----------------------#2020-04-12">https://medium.com/analytics-vidhya/classification-of-covid-19-x-ray-images-with-keras-and-its-potential-problem-e31b3ff16f24?source=collection_archive---------16-----------------------#2020-04-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f8faf1885cccaf3cd39ffeb6cc0f54a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PX3R2zLQJwPdmLoQ"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">罗伯特·祖尼科夫在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="3bb3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">免责声明:</em> </strong> <em class="jt">本帖探讨的方法和技术是为了教育和分享的目的。这不是一项科学研究，也不会发表在期刊上。</em></p><p id="5704" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个项目最初是受Adrian Rosebrock的一个帖子的启发，使用X射线图像来建立一个检测器来对新冠肺炎患者进行分类。正如世卫组织总干事所强调的，所有国家都要做检测，因为我们需要确定感染者，以减少传播。所以我想，如果有可能对它们进行高准确度的分类，数据科学界可以为那些难以获得检测试剂盒的国家建立一个权宜之计。</p><blockquote class="ju jv jw"><p id="aeb0" class="iv iw jt ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">一月下旬，一个中国小组发表了一篇论文，详细描述了新冠肺炎临床和临床前特征。他们报告说，利用患者胸部CT扫描来分类新冠肺炎、流感或健康患者。他们的深度学习模型能够达到86.7 %的准确率。</p></blockquote><figure class="ka kb kc kd fd ij"><div class="bz dy l di"><div class="ke kf l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">世卫组织强调所有国家检测新冠肺炎</figcaption></figure><h1 id="9972" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">总结</strong></h1><p id="0dad" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated">以下是常用图像分类中使用的步骤。</p><ol class=""><li id="3623" class="lj lk hi ix b iy iz jc jd jg ll jk lm jo ln js lo lp lq lr bi translated">数据集的收集</li><li id="8186" class="lj lk hi ix b iy ls jc lt jg lu jk lv jo lw js lo lp lq lr bi translated">创建图像生成器</li><li id="a18c" class="lj lk hi ix b iy ls jc lt jg lu jk lv jo lw js lo lp lq lr bi translated">定义我们的模型</li><li id="a74c" class="lj lk hi ix b iy ls jc lt jg lu jk lv jo lw js lo lp lq lr bi translated">训练我们的模型</li><li id="5397" class="lj lk hi ix b iy ls jc lt jg lu jk lv jo lw js lo lp lq lr bi translated">我们模型的评估</li></ol><h1 id="24da" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">1.数据集的收集</h1><p id="f8f4" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated">在这个项目中，我使用了来自<a class="ae iu" href="https://github.com/ieee8023/covid-chestxray-dataset?fbclid=IwAR3yCPo_e55khIvhhqDdPhCI6OMCLXjZKEziNnUzZWC9_h3NkyhqdjTqD5c" rel="noopener ugc nofollow" target="_blank"><em class="jt">covid-chestx ray-dataset</em></a>的数据集，并且只提取了<strong class="ix hj">新冠肺炎</strong>的x光图像。此外，我使用来自Kaggle的<a class="ae iu" href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia" rel="noopener ugc nofollow" target="_blank"> <em class="jt">胸部x光图像</em> </a>的数据集，提取<strong class="ix hj">正常</strong>和<strong class="ix hj">细菌</strong>图像</p><p id="2e57" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我选择3个不同类别的原因是，只有新冠肺炎图像，我担心模型会通过计算白色阴影像素来学习。因为这些被感染的病例肺部会有白色斑块。但是对于3个类别，该模型将被迫学习细菌和病毒病例之间的模式。<em class="jt"> </em>另外，请注意，我已经通过为每个类选择相同数量的图像来平衡数据集。这对于确保我们的模型不会偏向任何一个职业非常重要。<em class="jt">*新冠肺炎是一种病毒感染。</em></p><p id="6379" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据集由以下图像组成:</p><pre class="ka kb kc kd fd lx ly lz ma aw mb bi"><span id="f08c" class="mc kh hi ly b fi md me l mf mg">Total covid_images: 179<br/>Total normal_images: 179<br/>Total bacteria_images: 179</span></pre><h1 id="b604" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">2.创建图像生成器</h1><p id="6a88" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated"><strong class="ix hj">增强</strong></p><p id="c087" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于数据集中的图像数量有限，我在训练时使用了增强来增加模型的变化。我想强调的一个增强是使用伽马对比度来改变图像中白色像素的强度和图像的随机裁剪。这些方法用于防止模型仅学习计算白色阴影像素。此外，我们的扩充不应盲目进行，而是有选择地解决我们面临的某个问题。我为这个项目使用了下面的<a class="ae iu" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank"> <em class="jt"> imgaug </em> </a>包。</p><p id="8670" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我想分享的是，在我们开始训练我们的模型之前，我们应该总是从生成器生成一些图像以供查看。这是为了确保我们的生成器产生预期的增强结果。因为当我们的模型不工作时，它将节省我们的宝贵时间，并且我们确信我们的发电机不是问题的一部分。</p><p id="a253" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">从小处着手，快速迭代</strong></p><p id="332b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一个建议是，在开始时，我们应该尽量保持我们的训练图像尽可能小。是的，这可能会影响我们从高分辨率图像中学习的建模能力。但是更小的图像将允许我们通过不同的模型和超参数更快地迭代实验。找到这些参数后，我们就可以放大图像进行进一步的训练。这样我们可以在探索过程中节省时间。</p><p id="a3b1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面是我们的生成器的一些例子。</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/dc3d0baf37a6ad6b48470d934089dd63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HWjTS9BTRQ11FJkDQVuLIQ.png"/></div></div></figure><h1 id="15ec" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak"> 3。定义我们的模型</strong></h1><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/4ed4212ed6b0843dee9c0dabe31481c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*ssvPeVcsuP1qh3iNShUcyQ.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">对<a class="ae iu" href="https://www.researchgate.net/figure/TOP-LEVEL-DIAGRAM-OF-TRANSFER-LEARNING-FROM-A-PRE-TRAINED-CNN-MODEL_fig4_333882146" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/figure/TOP-LEVEL-DIAGRAM-OF-TRANSFER-LEARNING-FROM-A-PRE-TRAINED-CNN-MODEL _ fig 4 _ 333882146</a></figcaption></figure><p id="a61e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">迁移学习</strong></p><p id="e7e3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">迁移学习是一种利用现有模型的知识来学习另一项任务的方法。这个模型中的知识将作为我们新任务的初始化权重。使用迁移学习的好处是，与从头开始训练相比，该模型能够用更少的数据获得更高的精度，并且收敛速度更快。</p><p id="a0fe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">微调模型</strong></p><p id="5d4c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一种称为微调的常见做法是冻结预训练网络的前几层的权重，只训练最后几层。这是因为前几层捕捉到了对分类问题有用的曲线和边等一般特征。通常，我们会保留这些一般特征，并将培训集中在我们问题的更具体的特征上。(例如骨骼、肺的形状)</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/8ed7af91a4478098ce710e9387f8d1a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*0wSuve35SxbL0TAr-h5MxA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">项目建议书网络，VGG16微调</figcaption></figure><p id="5145" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是对于这个项目，人们发现微调前几层会产生更好的结果。我对此的猜测是，ImageNet预训练网络没有捕捉到太多的X射线曲线和边缘。因为x光图像被认为是私人信息，所以ImageNet建立在公共领域的图像之上。此外，ImageNet是在彩色图像上训练的，我们的数据集是灰度的。你可能会问，ImageNet权重对于X射线图像分类没有用，但我认为使用ImageNet比使用随机权重更好。</p><p id="6e2e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面是创建分类模型的代码。</p><pre class="ka kb kc kd fd lx ly lz ma aw mb bi"><span id="a840" class="mc kh hi ly b fi md me l mf mg"># VGG16 transfer learning<br/>def create_model(input_shape, n_out):<br/> model = Sequential() <br/> model.name = “VGG16_Model”<br/> pretrain_model = VGG16(include_top=False, weights=’imagenet’, input_tensor=Input(shape=input_shape)) <br/> <br/> # Set all layers to be trainable<br/> for layer in pretrain_model.layers: <br/>   layer.trainable = True<br/> for layer in pretrain_model.layers[-4:]: # last 4 layer freeze<br/>   layer.trainable = False</span><span id="f17e" class="mc kh hi ly b fi mk me l mf mg"> x = pretrain_model.output<br/> x = AveragePooling2D(pool_size=(3,3))(x)<br/> x = Flatten()(x)<br/> x = Dense(64, activation=’relu’)(x)<br/> x = Dropout(0.5)(x)<br/> x = Dense(n_out, activation=”softmax”)(x)</span><span id="57e0" class="mc kh hi ly b fi mk me l mf mg"> model = Model(pretrain_model.input, x) <br/> return model</span><span id="d109" class="mc kh hi ly b fi mk me l mf mg">Total params: 14,747,715<br/>Trainable params: 7,668,291<br/>Non-trainable params: 7,079,424</span></pre><h1 id="6a7f" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak"> 4。训练我们的模型</strong></h1><p id="252d" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated">为了训练我们的模型，使用“Adam”优化器并将“分类_交叉熵”作为损失函数。我还会在平稳状态下降低学习速度，并提前停止以防止过度适应。有关培训的详细信息，请参考提供的<a class="ae iu" href="https://github.com/Niellai/ObjectDetection/blob/master/6_COVID19%20ClassifierV2.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>。</p><p id="8e95" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我会推荐使用FastAI实现寻找学习率和适合一个周期的策略来训练模型，但这将是另一个时间的另一篇文章。以下链接很好地解释了“适合一个周期”政策。</p><div class="ml mm ez fb mn mo"><a href="https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6" rel="noopener follow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">找到好的学习率和一个周期的政策。</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">介绍</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc io mo"/></div></div></a></div><h1 id="b858" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">5.我们模型的评估</h1><p id="3abd" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated">为了衡量我们模型的性能，我们可以查看每个班级的f1分数。我们可以看到，我们的模型能够区分病毒和细菌感染，我们的准确率为97%，即使我们的图像分辨率为100x100。</p><pre class="ka kb kc kd fd lx ly lz ma aw mb bi"><span id="7175" class="mc kh hi ly b fi md me l mf mg">               precision    recall  f1-score   support<br/><br/>      Normal       0.97      0.95      0.96        60<br/>    COVID-19       0.98      0.98      0.98        60<br/>    Bacteria       0.95      0.97      0.96        60<br/><br/>    accuracy                           0.97       180<br/>   macro avg       0.97      0.97      0.97       180<br/>weighted avg       0.97      0.97      0.97       180</span></pre><p id="0fb3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">梯度加权类激活映射(Grad-CAM) </strong></p><p id="3cea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是理解模型性能还不够好，我们需要知道模型已经学习了什么以及模型实际看到了什么来确定分类。这是当<a class="ae iu" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"/></a><strong class="ix hj"/>进入画面时。Grad-CAM是一种为基于CNN的模型的决策提供“视觉解释”的技术，使模型变得透明。它使用流经决策层最后一个卷积层的梯度信息。我使用<a class="ae iu" href="https://github.com/raghakot/keras-vis" rel="noopener ugc nofollow" target="_blank"> Keras-Vis </a>包来实现这个项目的Grad-CAM。</p><p id="8165" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在实现Grad-CAM的时候一定要注意，你需要将你的最终图层激活改为线性。如果不是，你将不会从梯度中得到任何结果。</p><pre class="ka kb kc kd fd lx ly lz ma aw mb bi"><span id="3f0f" class="mc kh hi ly b fi md me l mf mg">layer_idx = utils.find_layer_idx(model, model.layers[-1].name)<br/>model.layers[layer_idx].activation = <strong class="ly hj">linear</strong><br/>model = utils.apply_modifications(model)</span></pre><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/40930ebc39637e1ce1bf82989c0179fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*g_MpYafgQ72qvL-_LmqxUQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">肺解剖学</figcaption></figure><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es ne"><img src="../Images/dcacea45b0179f16415c5aa75f74eab7.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*7XOdHeed3JafJe8RyE5szg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ki">样本1，</strong> Grad-CAM新冠肺炎</figcaption></figure><blockquote class="ju jv jw"><p id="d166" class="iv iw jt ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated"><strong class="ix hj">免责声明:</strong>下面的解释很明显是在看Grad-CAM给出的内容和一些关于肺炎感染的谷歌搜索。我不是医生，也无法验证模型是否正确。</p></blockquote><p id="817c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从上面的示例1中，我们可以看到我们的模型正在拾取“气管(windpipe)”区域来对新冠肺炎进行分类。我们知道新冠肺炎是一种呼吸道病毒，也许这就是为什么该模型将重点放在肺和气管的上部进行分类。</p><figure class="ka kb kc kd fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nf"><img src="../Images/074bf27961c1299e8556e10183cc4c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B6vBpsSIaqr4VgAUTS1xsw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">样本2，Grad-CAM随机样本</figcaption></figure><p id="9fc8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从样本2中，我们可以看到病灶的细菌感染区域是不同的。模型集中在肺的中心部分，虽然细菌感染可以通过空气传播，但也有其他途径被感染。传染源可能来自身体的其他部位，如肾脏。细菌可以从任何来源进入血液，并沉积在肺部。</p><div class="ml mm ez fb mn mo"><a href="https://www.emedicinehealth.com/bacterial_pneumonia/article_em.htm#what_causes_bacterial_pneumonia" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">细菌性肺炎传染期、治疗和症状</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">细菌性肺炎定义肺炎是肺部的真菌、病毒或细菌感染。肺炎是一种…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.emedicinehealth.com</p></div></div><div class="mx l"><div class="ng l mz na nb mx nc io mo"/></div></div></a></div><h1 id="7900" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">附加注释</h1><figure class="ka kb kc kd fd ij er es paragraph-image"><div class="er es nh"><img src="../Images/6b3cfb575a10bdc39293fce3d08e0bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/0*_BMz7ioQR-VA7qnc.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">我不是医生，但我知道我在做什么。相信我=D</figcaption></figure><p id="77a1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在所有的实验和阅读之后，在我看来，我认为x光图像很可能不足以识别受感染的病人和阻止新冠肺炎病毒的传播。原因是我收集的这些X射线图像很可能是在病人入院时拍摄的，并且一开始就有呼吸困难。该模型将不能识别无症状的人。我们仍然需要依靠检测试剂盒来鉴别这些病例。目前，我们最好的选择是呆在家里，以防止任何方式的传播。所以，如果你真的需要外出，回家后马上洗手，请戴上口罩。注意安全。</p></div><div class="ab cl ni nj gp nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="hb hc hd he hf"><p id="de23" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">参考</strong></p><div class="ml mm ez fb mn mo"><a href="https://github.com/Niellai/ObjectDetection/blob/master/6_COVID19%20ClassifierV2.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">niel lai/对象检测</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">github.com</p></div></div><div class="mx l"><div class="np l mz na nb mx nc io mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/how-to-train-siamese-network-on-covid-19-x-ray-images-639a993b35a3"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">如何在新冠肺炎X射线图像上训练暹罗网络</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">您可能对另一种X射线图像分类方法感兴趣。在这篇文章中，我不解决任何与新冠肺炎相关的问题，而是探索暹罗网的概念和实现…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">medium.com</p></div></div><div class="mx l"><div class="nq l mz na nb mx nc io mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">使用Keras、TensorFlow和深度学习- PyImageSearch检测X射线图像中的新冠肺炎</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">在本教程中，您将学习如何使用自动检测手动创建的X射线图像数据集中的新冠肺炎</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.pyimagesearch.com</p></div></div><div class="mx l"><div class="nr l mz na nb mx nc io mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">胸部x光图像(肺炎)</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">5，863张图片，2个类别</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.kaggle.com</p></div></div><div class="mx l"><div class="ns l mz na nb mx nc io mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://github.com/ieee8023/covid-chestxray-dataset?fbclid=IwAR3yCPo_e55khIvhhqDdPhCI6OMCLXjZKEziNnUzZWC9_h3NkyhqdjTqD5c" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">IEEE 8023/covid-chest Xray-dataset</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">我们正在用胸部x光或CT图像建立一个新冠肺炎病例数据库。我们也在寻找新冠肺炎病例…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">github.com</p></div></div><div class="mx l"><div class="nt l mz na nb mx nc io mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://github.com/aleju/imgaug" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">aleju/imgaug</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">这个python库可以帮助您为您的机器学习项目增加图像。它转换一组输入…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">github.com</p></div></div><div class="mx l"><div class="nu l mz na nb mx nc io mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://towardsdatascience.com/does-imagenet-pretraining-work-for-chest-radiography-images-covid-19-2e2d9f5f0875" rel="noopener follow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">Imagenet预处理对胸部放射摄影图像有效吗(新冠肺炎)？</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">Imagenet训练模型在新冠肺炎x射线上的性能</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="nv l mz na nb mx nc io mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://fairyonice.github.io/Grad-CAM-with-keras-vis.html" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">带有keras-vis的Grad-CAM</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">设$a^k \在\mathbb{R}^{u\textrm{ x } v}$是最后一个卷积图层的第$ K$个要素地图($k=1，\cdots，k $)</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">仙妮莎. github.io</p></div></div><div class="mx l"><div class="nw l mz na nb mx nc io mo"/></div></div></a></div></div></div>    
</body>
</html>