<html>
<head>
<title>Twitter Sentimental Analysis Using Naive Bayes Classifier(Process Explanation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用朴素贝叶斯分类器的Twitter情感分析(过程解释)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/twitter-sentimental-analysis-using-naive-bayes-classifier-process-explanation-f532b96b30b8?source=collection_archive---------2-----------------------#2020-07-07">https://medium.com/analytics-vidhya/twitter-sentimental-analysis-using-naive-bayes-classifier-process-explanation-f532b96b30b8?source=collection_archive---------2-----------------------#2020-07-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/4782346b6ed05d46e07e24391f2f674f.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*2bha4fcoi_ghvC5wvWjlcA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">来源:https://www . social bakers . com/blog/social-media-sensation-analysis</figcaption></figure><p id="586b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">情感分析主要是对文本中的情感和观点进行分析。一种用于文本分析的情感评估系统结合了自然语言处理(NLP)和笔记本电脑控制方法，以将加权的情感分数分配给句子或短语内的实体、主题、问题和类别。它试图找到并证明人对给定内容源的情感。我正在从包含推文的数据集提出一个高度准确的情感分析模型，在分类器如朴素贝叶斯的帮助下，该应用程序可以正确地将给定数据集的推文分类为正面和负面，以给出每个推文的情感。自从社交媒体出现以来，人类就利用媒体来表达他们的需求、偏好和情感。以及Twitter、脸书等社交网络的发展，收集了大量关于用户偏好的信息。</p><blockquote class="jo jp jq"><p id="d07d" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated">通过这篇文章，我试图实现一个系统，试图了解一个给定主题的意见。本文基于解决两个子问题:</p><p id="7773" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj"> <em class="hi"> 1。将一个句子分类为主观或客观，称为主观性分类。</em>T3】</strong></p><p id="e4e1" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><strong class="is hj">2<em class="hi">。把一个句子分类为表达肯定、否定的称为极性分类。</em> </strong></p></blockquote></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h1 id="8cb5" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">解决方案</strong></h1><p id="9897" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">Binary致力于二元情感分析，使用具有多项分布的朴素贝叶斯分类器以及伯努利分类器对给定句子的正面和负面推文进行分类。为了开发，从Kaggle中提取了包含tweet的数据集。首先，将进行预处理。在这个阶段，白色单词、重复单词、情绪以及#标签都将被删除。然后tweets使用训练数据的机器学习技术将被分类。将使用几种方法从源文本中提取特征。特征提取将分两个阶段进行:1 .twitter相关数据的抽取，2。添加到特征向量的其他数据提取。在特征被添加到特征向量之后，训练数据中的每个tweet都与类别标签相关联，并被传递到不同的分类器，分类器被训练。最后，将对模型进行测试，并在这些训练好的分类器的帮助下进行分类。最后，我们将推文分为正面和负面。</p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h1 id="4ae6" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">开发过程说明</h1><p id="59a1" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated"><strong class="is hj"> A .加载情感数据</strong></p><p id="9717" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个项目的数据集是从Kaggle中提取的。这个数据集包含了这个项目中用于分析情绪的100多万条推文。这些文件包含正面标签和负面标签的推文。首先，数据集被加载到程序中。包含以下6个字段:1。pnn:推文的极性(0 =负，1 =正)</p><p id="d679" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.身份证:身份证号码</p><p id="5c1d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.日期:推文的日期</p><p id="7070" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.query:查询如果没有查询，那么这个值就是NO_QUERY。</p><p id="c0f6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.Tweeter_id:推文的id</p><p id="a321" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.tweets:tweet的文本</p><h2 id="523d" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">B.预处理数据</h2><p id="2cab" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">加载数据后，会进行预处理。为了准备消息，在该程序中使用了文本预处理技术，例如用关键字替换URL和用户名、去除标点符号以及转换成小写字母。它们描述如下:</p><ul class=""><li id="44b8" class="lt lu hi is b it iu ix iy jb lv jf lw jj lx jn ly lz ma mb bi translated"><strong class="is hj">解码数据:</strong>这是将信息从复杂的符号转化为简单易懂的字符的过程。文本数据可能会受到不同形式的解码，如“拉丁”、“UTF8”等。UTF-8编码是被广泛接受的编码格式，推荐使用。</li><li id="8a26" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn ly lz ma mb bi translated"><strong class="is hj">停用词的去除:</strong>常用词(停用词)应该被去除。它们包括像' am '，' an '，' the '等词。通过将该参数值设置为English，Count Vectorizer将自动忽略在scikit-learn的内置英文停用词列表中找到的所有单词(来自我们的输入文本)。</li><li id="bba2" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn ly lz ma mb bi translated"><strong class="is hj">去除标点:</strong>所有的标点符号都要按照轻重缓急来处理。比如:“”, ",","?"是重要的标点符号，应该保留，而其他需要删除。</li><li id="a80c" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn ly lz ma mb bi translated">移除URL:应该移除文本数据中的URL和超链接，如评论、评论和推文。</li></ul><h2 id="a8e3" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">C.训练朴素贝叶斯分类器</h2><p id="af67" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">朴素贝叶斯方法是一组基于应用贝叶斯定理的监督学习算法，其“朴素”假设是在给定类变量的值的情况下，每对要素之间的条件独立性。</p><p id="24d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">管道类用于使矢量器= &gt;转换器= &gt;分类器更容易使用。诸如IDF使用、使用网格搜索的TF-IDF标准化类型的超参数。所选超参数的性能是在模型训练步骤中未使用的测试集上测量的。数据集被分成训练和测试子集。使用了两个朴素贝叶斯分类器。它们列举如下:—</p><ul class=""><li id="7049" class="lt lu hi is b it iu ix iy jb lv jf lw jj lx jn ly lz ma mb bi translated"><strong class="is hj">伯努利朴素贝叶斯:</strong>它假设我们所有的特征都是二元的，因此它们只取两个值。表示0可以表示“文档中没有出现单词”，1表示“文档中出现了单词”。</li><li id="1600" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn ly lz ma mb bi translated"><strong class="is hj">多项式朴素贝叶斯:</strong>当我们有离散数据时使用(例如，tweets评级范围为1到5，因为每个评级都有一定的频率来表示)。在文本分类中，我们有每个单词的计数来预测类别或标签。如果单词可以用它们的出现次数(频率计数)来表示，那么就使用多项式事件模型。如果我们只关心一个单词在文档中的存在与否，那么使用伯努利事件模型。</li></ul><h2 id="97c8" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">D.计数矢量器和TFI-DF矢量器的实现</h2><p id="668d" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">计数矢量器只计算词频。它将字符串标记化(将字符串分隔成单个单词)，并为每个标记提供一个整数ID。它计算这些标记的出现次数。计数矢量器方法会自动将所有标记化的单词转换为小写形式，这样就不会对“he”和“He”这样的单词进行不同的处理。它使用默认设置为True的小写参数来实现这一点。它还会忽略所有标点符号，以便单词后跟一个标点符号。</p><p id="19bb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Tfidf矢量器将CountVectorizer和TfidfTransformer的所有选项组合在一个模型中。TfidfTransformer用于统计一个词在语料库中出现的次数(仅指词频，而非词频倒数)。TfidfVectorizer对其结果进行归一化，即其输出中的每个向量的范数为1。</p><h2 id="1327" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">E.评估指标的实施</h2><p id="f071" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">最后，对于数据的评价使用了混淆矩阵。混淆矩阵是一种总结分类算法性能的技术。计算混淆矩阵可以让我们更好地了解我们的分类模型是正确的，以及它会产生什么类型的错误。正确和不正确预测的数量通过计数值进行汇总，并按每个类别进行细分。</p><p id="7544" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">混淆度量中有4个重要术语:</p><ol class=""><li id="8ea8" class="lt lu hi is b it iu ix iy jb lv jf lw jj lx jn mh lz ma mb bi translated">真阳性:我们预测的结果是肯定的，而实际结果也是肯定的。</li><li id="5bb9" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn mh lz ma mb bi translated">真正的否定:我们预测没有，而实际结果是没有的情况。</li><li id="bce2" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn mh lz ma mb bi translated">假阳性:我们预测结果是肯定的，而实际结果是否定的。</li><li id="207f" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn mh lz ma mb bi translated">假阴性:我们预测结果是否定的，而实际结果是肯定的。</li></ol></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h1 id="732c" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">使用的库</h1><ol class=""><li id="a26a" class="lt lu hi is b it la ix lb jb mi jf mj jj mk jn mh lz ma mb bi translated">Wordcloud:单词云(也称为标签云)是一种数据可视化技术，它突出了大型文本语料库中的重要文本数据点</li><li id="eee1" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn mh lz ma mb bi translated">NumPy:它是使用Python进行科学计算的基础包，可以用作通用数据的高效多维容器。它是一个Python库，提供了一个多维数组对象，各种派生对象(比如掩码数组和矩阵)，</li><li id="cdb5" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn mh lz ma mb bi translated">熊猫:它获取数据(如CSV或TSV文件，或SQL数据库)并创建一个包含行和列的Python对象，称为数据框，它看起来非常类似于统计软件中的表格。</li><li id="2a5c" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn mh lz ma mb bi translated">Matplotlib: Matplotlib是一个Python 2D绘图库，它以各种硬拷贝格式和跨平台的交互环境生成出版物质量数字。</li><li id="c6b1" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn mh lz ma mb bi translated">Scikit learn: Scikit-learn是Python中的一个库，它提供了许多非监督和监督学习算法。</li><li id="cfc3" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn mh lz ma mb bi translated">Nltk:自然语言工具包(NLTK)是一个平台，用于构建Python程序，这些程序处理人类语言数据，以应用于统计自然语言处理(NLP)。它包含用于标记化、解析、分类、词干、标记和语义推理的文本处理库。</li></ol></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h1 id="a3d9" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">解决方案的伪代码</strong></h1><p id="64b3" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">开始</p><ol class=""><li id="c147" class="lt lu hi is b it iu ix iy jb lv jf lw jj lx jn mh lz ma mb bi translated">输入:数据集D和训练数据T</li><li id="3143" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn mh lz ma mb bi translated">对于每个:TW TW在数据集D中</li></ol><p id="abb2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a.摘录:在推特上发布来自数据集D的Tw</p><p id="5342" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">b.初始化:将C切到推特Tw的根目录</p><p id="fa2b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">c.获取:特征向量F</p><p id="f936" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">d.提取:从特征向量F到提取的特征E的特征Fe</p><p id="7c15" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.对于每个:数据集D中提取的特征E</p><p id="8250" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a.比较:使用朴素贝叶斯算法将提取的特征E与训练数据T进行比较，并将极性存储在P中</p><p id="d6a6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.如果极性P是正的</p><p id="9224" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a.显示:阳性结果</p><p id="3164" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.否则，如果极性p为负</p><p id="6b86" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a.显示:阴性结果</p><p id="7970" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.其他</p><p id="918a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a.显示:中性结果</p><p id="1f6a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">停止</p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h1 id="6dad" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">结果</strong></h1><h2 id="d70a" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">A.从数据集加载数据</h2><figure class="mm mn mo mp fd ij er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es ml"><img src="../Images/f9b67830c2db7b1f38a3b9211fe7459d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K-mmdqcCaAbwPkD8hhSLjg.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">正在加载数据集</figcaption></figure><p id="5ba4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了进一步处理，数据集已使用ISO8859-1编码的panda库加载到程序中。上图显示了成功加载的数据集。</p><h2 id="e9d9" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">B.清洗数据集</h2><figure class="mm mn mo mp fd ij er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mu"><img src="../Images/ecc93553161aed3699358d7da035eef1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*414ZqTQtb94DKo7Baof31Q.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">清洗数据集</figcaption></figure><p id="3866" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在数据集被加载后，我清理了数据集，得到了上面的结果。数据集已成功清理，以供进一步演示。数据集分布如下图所示。</p><figure class="mm mn mo mp fd ij er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mv"><img src="../Images/3af1bfb60e3765c86e4803f001b0c685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YES2J-UNQhpsneNvCnQEow.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">数据集标签分布</figcaption></figure><h2 id="983a" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">C.词云生成</h2><p id="fb98" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">在“pnn”字段值的帮助下，在清理的数据集的帮助下，生成单词云。它分为正面词云和负面词云两种类型，如下图所示:</p><figure class="mm mn mo mp fd ij er es paragraph-image"><div class="er es mw"><img src="../Images/f2b618e8bc39d8cd88b84984fccd850c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*qctOHkUYx_Rff78S4HfbrQ.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">负词云生成</figcaption></figure><figure class="mm mn mo mp fd ij er es paragraph-image"><div class="er es mx"><img src="../Images/273bedc066961f68ef44113161b4ef70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*CUEAvmwYhqVoU2ovxvCA-g.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">积极的词云生成</figcaption></figure><h2 id="f14b" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">D.混淆矩阵</h2><figure class="mm mn mo mp fd ij er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es my"><img src="../Images/27bf23e8a6a0dbe4400c41a5a43eeaa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EFl1lFapqEWfir5Y2y5Ttw.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">混淆矩阵</figcaption></figure><p id="7483" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上图展示了我们程序的混淆矩阵。有4个重要术语:</p><ul class=""><li id="a9c3" class="lt lu hi is b it iu ix iy jb lv jf lw jj lx jn ly lz ma mb bi translated">真阳性:我们预测的结果是肯定的，而实际结果也是肯定的。</li><li id="7e60" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn ly lz ma mb bi translated">真正的否定:我们预测没有，而实际结果是没有的情况。</li><li id="a10c" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn ly lz ma mb bi translated">假阳性:我们预测结果是肯定的，而实际结果是否定的。</li><li id="5846" class="lt lu hi is b it mc ix md jb me jf mf jj mg jn ly lz ma mb bi translated">假阴性:我们预测结果是否定的，而实际结果是肯定的。</li></ul><h2 id="b239" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">E.多项式与伯努利分类器结果的讨论</h2><p id="8c36" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">多项式朴素贝叶斯在某种意义上更复杂，因此，伯努利模型可以使用较少的数据进行训练，并且不容易过拟合。</p><p id="a0f8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多项式NB将基于它发现的多个关键词的计数来分类文档；而Bernoulli NB只能关注单个关键字，但也会计算该关键字在文档中没有出现的次数。所以，他们确实模拟了稍微不同的东西。如果我们有离散的多个特征要考虑，我们必须使用多项式NB。但是，如果我们只需要担心一个单一的特性，那么我们可以根据上面的内容进行建模选择。</p><figure class="mm mn mo mp fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/b6e14dbf9786af16bfb1abf63bb39350.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*ueTsEILqGC97LzT4LiK50Q.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">培训和测试分数</figcaption></figure><p id="eb31" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jr">准确度结果:</em> </strong></p><p id="eaa5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">多项式朴素贝叶斯具有以下属性:</strong></p><p id="9c64" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多项式朴素贝叶斯模型的训练精度为:0.7969994993205064多项式朴素贝叶斯模型的检验精度为:0.7969996996</p><p id="4f2a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">伯努利分类器具有以下属性:</strong></p><p id="3f37" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">伯努利分类器模型的训练精度为:0.8096178146532198伯努利分类器模型的测试精度为:0.809676867</p><h2 id="48d9" class="lf kd hi bd ke lg lh li ki lj lk ll km jb lm ln kq jf lo lp ku jj lq lr ky ls bi translated">F.传递一些随机值来分析情绪</h2><figure class="mm mn mo mp fd ij er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es na"><img src="../Images/0d35e83c6aa4b3bc0552f6f7ad10eafc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1rWR5EXrbKhf48E4yYltFw.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">分析情绪</figcaption></figure><p id="aa39" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了进一步演示，使用了名为predict()的方法，并传递了一些值，以检验程序是否正常工作，结果是否如我所料。以上结果是针对各种输入值获得的，程序运行成功。</p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h1 id="0d3d" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">结论</h1><p id="9118" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">尽管情感分析有其局限性，但它可以在现实世界中推断出许多好处。这对于公开意见起关键作用的组织来说是有价值的。此外，来自情感分析可以通过使他们获得将他们放在twitter中的讨论和对话来提供帮助交易发展，并且提供帮助他们以类似的方式快速响应。政府可以制定法律，大学可以发现学生的失望，商业可以利用假设检验以类似的方式进行展示查询等等。因此，意见调查的领域非常广泛，可以在任何组织中实施，以确定自己的利益。</p></div></div>    
</body>
</html>