<html>
<head>
<title>Decoding object from neurons activity in the mouse brain</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从老鼠大脑中的神经元活动解码物体</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/mouse-brain-responses-demystified-81f4c979a96d?source=collection_archive---------16-----------------------#2019-12-18">https://medium.com/analytics-vidhya/mouse-brain-responses-demystified-81f4c979a96d?source=collection_archive---------16-----------------------#2019-12-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="7c84" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="dbb8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">人脑是人体最复杂的部分。我们仍然没有真正理解大脑是如何工作的，并且很难在人身上做实验。通过探索动物的大脑，我们可以发现大脑中的规律。我们可以找出不同的行为模式，或者在人类身上应用技术，找出相似或不同之处。这片土地尚未被发现，有待开发。</p><h1 id="cf04" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">背景</h1><p id="1dc0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">2018年<em class="kb">，Carsen Stringer，Marius Pachitariu，Nicholas斯坦梅茨，Matteo Carandini，Kenneth D. Harris </em>制作了一个数据集，其中包含小鼠大脑中10 000个神经元对视觉刺激的反应记录。每种视觉刺激都呈现在老鼠周围的三个屏幕上，平均每秒一幅图像。</p><p id="a6ac" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">视觉刺激意味着显示图像，例如，著名的ImageNet数据集中的猫、鸟、蛇。用老鼠大脑内部的<a class="ae kh" href="https://www.nature.com/articles/nature24636" rel="noopener ugc nofollow" target="_blank">神经像素电极阵列</a>来测量反应。</p><p id="0c9c" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在对数据集的描述中，他们说回答非常稀少。只有一小部分细胞被任何特定的刺激驱动超过其基线放电率两个标准偏差以上。这意味着大多数神经元对刺激的反应并不特别，但我们可以假设我们可以找到特定的模式。</p><p id="e23a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">不同的设置总共有32个记录:</p><ul class=""><li id="e45e" class="ki kj hi jf b jg kc jk kd jo kk js kl jw km ka kn ko kp kq bi translated">小鼠(6只小鼠)</li><li id="28f4" class="ki kj hi jf b jg kr jk ks jo kt js ku jw kv ka kn ko kp kq bi translated">方向</li><li id="f384" class="ki kj hi jf b jg kr jk ks jo kt js ku jw kv ka kn ko kp kq bi translated">图像增强(白化、填充零非感受野)</li><li id="6bce" class="ki kj hi jf b jg kr jk ks jo kt js ku jw kv ka kn ko kp kq bi translated">测量设备的数量</li><li id="b1f0" class="ki kj hi jf b jg kr jk ks jo kt js ku jw kv ka kn ko kp kq bi translated">测量设备的放置</li><li id="7176" class="ki kj hi jf b jg kr jk ks jo kt js ku jw kv ka kn ko kp kq bi translated">长度、显示的图像数量</li></ul><p id="d7f6" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将只使用未经处理的自然图像记录。每个记录代表2，800个连续重复的图像刺激序列(至少两次)。</p><h2 id="cff7" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">数据</h2><p id="45df" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于每一幅图像，我们都有<em class="kb"> XYZ </em>神经元的坐标和它们的值。我们应该把它形象化，看看它是什么样子。</p><div class="lk ll lm ln fd ab cb"><figure class="lo lp lq lr ls lt lu paragraph-image"><img src="../Images/8b7e975f6e2b8f083bed232d50dcb0f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*hiw-Usx9qIOXaZSLT5Yo6w.jpeg"/></figure><figure class="lo lp lq lr ls lt lu paragraph-image"><img src="../Images/c1f6f9f17461a6ab7ac0aeea97c54084.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*W-LOyTumJAFTkzSK3sATqg.jpeg"/><figcaption class="lx ly et er es lz ma bd b be z dx mb di mc md translated">带有神经元反应(左)和反转颜色(右)的热图</figcaption></figure></div><p id="644e" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">播放并旋转一会儿后，我们可以立即看到电极被放置在特定的平面上。</p><figure class="lk ll lm ln fd lp er es paragraph-image"><div class="er es me"><img src="../Images/4a2f78fde675643e9089a656c7befbe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Zj0Of2gfMebfNmzVW-B7bA.png"/></div></figure><p id="be77" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们可以在这个<em class="kb"> z </em>坐标上看到切片，稍后会用到。此外，我们可以再次看到，数据是稀疏的，在常规热图上只有几个红色响应。</p><p id="b11b" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们试图通过数据集提供商提供的有用代码来消除噪声，其中spont是大脑活动的自发记录:</p><pre class="lk ll lm ln fd mf mg mh mi aw mj bi"><span id="162a" class="kw ig hi mg b fi mk ml l mm mn">mu = spont.mean(axis=0) # get rid of spontaneous noise<br/>sd = spont.std(axis=0) + 1e-6<br/>responses = (responses - mu) / sd<br/>spont = (spont - mu) / sd<br/>sv,u = eigsh(spont.T @ spont, k=32)<br/>responses = responses - (responses @ u) @ u.T<br/># mean center each neuron<br/>responses -= responses.mean(axis=0)</span></pre><p id="c383" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">现在是时候可视化各个类的平均响应，看看是否已经有明显的差异。</p><div class="lk ll lm ln fd ab cb"><figure class="lo lp mo lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><img src="../Images/d17e57c7def229e61cab3d63bfdb4b7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*riseepAj-q46dSNBlG3HCQ.jpeg"/></div></figure><figure class="lo lp mo lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><img src="../Images/0051f33cd08e2696813ac93c5f1b8f85.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*dckVWRVKNEXWVhfrRiPt8g.jpeg"/></div></figure><figure class="lo lp mo lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><img src="../Images/b6d1edeffc7305d7ba0726412b9656bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*M2T2sgQE0zVytQ8pmbZ6hA.jpeg"/></div><figcaption class="lx ly et er es lz ma bd b be z dx mt di mu md translated">每类3、4、9的平均回答</figcaption></figure></div><p id="bde4" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">看到这个之后，我们有了一个计算均方差的想法，不幸的是，这个方法并不成功。它仍然有随机的性能。</p><h1 id="970e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">方法</h1><p id="d262" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们尝试了多种方法，其中一些完全失败了，我们花了太多时间试图让它们奏效。其他的不那么成功，我们早就放弃了。</p><h2 id="f81d" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">表格学习</h2><p id="9356" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">没有充分的理由，我们试图完全忽略空间信息。从众多可用选项中，我们选择了这些分类器:AdaBoostClassifier、RandomForestClassifier和XGBoostClassifier。我们还尝试了一个fast.ai深度学习框架(批量归一化和辍学的ANN架构)。</p><p id="ef02" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们的数据看起来像这样:</p><figure class="lk ll lm ln fd lp"><div class="bz dy l di"><div class="mv mw l"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">没有空间信息的数据结构</figcaption></figure><p id="cce4" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">通过五次交叉验证计算准确度。我们能得到的最佳精度结果和虚拟模型一样好。</p><pre class="lk ll lm ln fd mf mg mh mi aw mj bi"><span id="fcc7" class="kw ig hi mg b fi mk ml l mm mn">AdaBoost: 0.17% <br/>Random Forest: 0.19%<br/>XGBoost: 0.174%</span><span id="e085" class="kw ig hi mg b fi mx ml l mm mn">Most frequent (dummy) predictor: 0.16%</span></pre><h2 id="9e47" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">表格平均法</h2><p id="0e11" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了克服第一种方法的过度拟合等问题，我们尝试以类似网格的方式对大脑的平均区域进行处理，但随后再次丢弃空间信息，并将其放入一个表格中:</p><figure class="lk ll lm ln fd lp"><div class="bz dy l di"><div class="mv mw l"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">无空间信息的分割数据结构</figcaption></figure><p id="2a76" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">然而，这也无济于事。任何分类器的分数都没有提高。</p><h2 id="8e04" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">空间数据呢？</h2><p id="3f4f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们可能会想到将数据放入一些网格中，制作体素(3D像素)。</p><figure class="lk ll lm ln fd lp er es paragraph-image"><div class="er es my"><img src="../Images/129580e07a24cd1ed835d5895dd40771.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*6JIi8jjNFbphi2PzIJKz-w.jpeg"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">3D体素网格</figcaption></figure><p id="70ee" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">虽然他们只测到了小鼠大脑中的10 000个神经元，但它们所分配的体积大约是<strong class="jf hj"> <em class="kb"> 1000 </em> </strong> <em class="kb">(宽度)</em> <strong class="jf hj"> <em class="kb"> x 1000 </em> </strong> <em class="kb">(深度)</em><strong class="jf hj"><em class="kb">×13</em></strong><em class="kb">(高度)</em> <strong class="jf hj"> </strong>个单位。这给出了13密耳的体素，但其中只有10 000个被占用。这将是浪费和低效的。我们在单次试验中有大约5000个样本，所以这是巨大的数据膨胀。再者，大部分是零。我们可以使用稀疏矩阵，但是它很难处理，而且一些算法不能处理稀疏矩阵。</p><p id="ddef" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">另一个想法是再次使用分而治之的方法。我们可以像以前一样将3D空间划分成一些块/子空间，然后使用卷积神经网络来保存空间信息并提取已知模式。</p><p id="09fa" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在预处理之后，我们使用了两种可能的可视化。在右边，我们可以看到该区域是如何划分的，但内部体素没有显示，因为它们的脸被覆盖。在左边，我们可以看到每个区域，但我们看不到每个点覆盖哪个区域。</p><div class="lk ll lm ln fd ab cb"><figure class="lo lp lq lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><img src="../Images/d4e6fe64289db8c8cc2a129aaad0ac43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*U2toxNgjAKHsfR1lDCMMWg.jpeg"/></div></figure><figure class="lo lp lq lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><img src="../Images/e73f23357f8fa898e1dac5fe0d1dbcb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*jlfbZ-oiosrOZFNFhhajqw.jpeg"/></div><figcaption class="lx ly et er es lz ma bd b be z dx mb di mc md translated">左侧为散点图，右侧为体素网格</figcaption></figure></div><p id="4caa" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">区域的粒度是一个关键的选择。区域应该足够大以避免维数灾难，但也应该足够小以代表空间中大脑的小区域。</p><p id="5484" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">下一个重要的选择是模型的架构。对于那些不确定卷积是什么的人，我们建议查看这个<a class="ae kh" href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215" rel="noopener" target="_blank">链接</a>。简而言之，卷积是对特征的提取，例如，在单通道版本中:</p><figure class="lk ll lm ln fd lp er es paragraph-image"><div class="er es mz"><img src="../Images/f671713c2c09d2ef6aae2723c8aaec57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/1*h-czrVhg0x3kOLiKs8IHqA.gif"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">单通道卷积</figcaption></figure><p id="9558" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">然而，我们的数据集是由3D数据棱柱构成的，所以我们应该使用3D版本的卷积。它仍然有过滤器，在这种情况下是3D的，通过体素的补丁以滑动窗口的方式应用，提取最重要的特征。</p><figure class="lk ll lm ln fd lp er es paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="er es na"><img src="../Images/7de57bb4eabb40d74a4b42ebd77174fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fnkPPcqdWOtgg0ewoEfr9g.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx translated"><em class="nb">在3D卷积中，3D滤镜可以在所有3个方向上移动(高度、宽度、图像的通道)</em>。在每个位置，逐元素的乘法和加法提供一个数。由于过滤器在三维空间中滑动，<em class="nb">输出数字也在三维空间中排列。然后输出3D数据。</em></figcaption></figure><p id="c86a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们选择了下述第一种架构:</p><pre class="lk ll lm ln fd mf mg mh mi aw mj bi"><span id="ded7" class="kw ig hi mg b fi mk ml l mm mn">MouseNet<br/>====================================================================<br/>Layer (type)         Output Shape         Param #    Trainable <br/>====================================================================<br/>Conv3d               [16, 11, 6, 6]       432        True      <br/>____________________________________________________________________<br/>BatchNorm3d          [16, 11, 6, 6]       32         True      <br/>____________________________________________________________________<br/>ReLU                 [16, 11, 6, 6]       0          False     <br/>____________________________________________________________________<br/>Conv3d               [32, 6, 3, 3]        13,824     True      <br/>____________________________________________________________________<br/>BatchNorm3d          [32, 6, 3, 3]        64         True      <br/>____________________________________________________________________<br/>ReLU                 [32, 6, 3, 3]        0          False     <br/>____________________________________________________________________<br/>Conv3d               [32, 6, 3, 3]        27,648     True      <br/>____________________________________________________________________<br/>BatchNorm3d          [32, 6, 3, 3]        64         True      <br/>____________________________________________________________________<br/>ReLU                 [32, 6, 3, 3]        0          False     <br/>____________________________________________________________________<br/>MaxPool3d            [32, 2, 1, 1]        0          False     <br/>____________________________________________________________________<br/>Flatten              [64]                 0          False     <br/>____________________________________________________________________<br/>Linear               [13]                 845        True      <br/>____________________________________________________________________<br/>Total params: 42,909<br/>Total trainable params: 42,909<br/>Total non-trainable params: 0<br/>Optimized with 'torch.optim.adam.Adam', betas=(0.9, 0.99)<br/>Using true weight decay as discussed in <a class="ae kh" href="https://www.fast.ai/2018/07/02/adam-weight-decay/" rel="noopener ugc nofollow" target="_blank">https://www.fast.ai/2018/07/02/adam-weight-decay/ </a><br/>Loss function : CrossEntropyLoss</span></pre><p id="f5ed" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">它是卷积层的重复，<a class="ae kh" href="https://arxiv.org/pdf/1502.03167.pdf" rel="noopener ugc nofollow" target="_blank">批量归一化</a>和<a class="ae kh" href="https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6" rel="noopener" target="_blank"> ReLU </a>激活函数。以下是二维图像上<em class="kb">步幅=2 </em>和<em class="kb">填充=1 </em>的卷积示例:</p><figure class="lk ll lm ln fd lp er es paragraph-image"><div class="er es nc"><img src="../Images/8d0c8d79ca7ffa7b613f2c4923420c69.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/1*1VJDP6qDY9-ExTuQVEOlVg.gif"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">填充=1，步幅=2卷积</figcaption></figure><p id="7f67" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们使用<a class="ae kh" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> pytorch </a>库和<a class="ae kh" href="https://www.fast.ai" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>模块来创建这个网络。</p><h1 id="863c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结果</h1><p id="7913" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们无法得到一些像样的结果。我们所有的尝试都以随机行为告终。一些可能的问题是不好的空间划分，也许一些更聪明的方法会挑选更重要的领域。在某些空间中，具有某种相关性的聚类是可能的。</p><h1 id="9d17" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结论</h1><p id="0129" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们没有发现小鼠大脑的不同部分对图像刺激有某种相关性。然而，我们并没有说它不存在。我试过的方法都不成功，很难说出到底是什么问题。</p><h2 id="12a4" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">未来的工作</h2><p id="d385" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">有一些神经网络将点云作为它们的输入，但我没有发现任何一个还会结合点的强度，而不仅仅是空间信息。我自己创建这样一个网络并不是一件简单的事情，我也没有成功地让它运转起来。如果这样的网络存在，它将完美地满足我们的目的，因为点云是存储神经元数据的最有效的方式。</p><p id="8c00" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">关于小鼠大脑区域的专家知识不仅有助于可视化，也有助于分类。我们可能对老鼠大脑的某些部分有较高的分辨率，而对其他部分分辨率较低。</p><p id="b353" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们应该考虑神经元和它们的低级特征提取。从低级特征构建图像上的对象的语义的任务可能非常困难，几乎是不可能的。更小的步骤，如解码特定图像，而不是图像的语义可能更有帮助。</p><p id="2e1b" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">神经元归一化是神经科学界的重要技术。如果我们在刺激前后都有反应，我们可以更好地去噪反应。即使使用我们的数据，考虑从数据中去除自发反应的噪声对于能够识别自发反应和对刺激的反应之间的差异是至关重要的。</p><p id="0f04" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我所有的代码都可以在<a class="ae kh" href="https://github.com/xbankov/Neuroscience" rel="noopener ugc nofollow" target="_blank"> GitHub </a>找到。</p><h1 id="f594" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">参考</h1><p id="3e3b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">博文中的一切都是Mikulábanko VI做的。借助其他一些博客文章和学术论文。我的大部分想法来自塔尔图大学的计算神经科学导论课，老师是Raul Vicente Zafra。我要感谢的讲师和学生的问题和建议。</p><p id="a206" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><a class="ae kh" href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215" rel="noopener" target="_blank">深度学习中不同类型卷积的全面介绍</a></p><p id="d32e" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><a class="ae kh" href="https://docs.fast.ai/index.html" rel="noopener ugc nofollow" target="_blank"> Fast.ai框架</a></p><p id="4ce1" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><a class="ae kh" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> Pytorch </a></p><p id="c43e" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">谢尔盖·约菲，克里斯蒂安·塞格迪；批量标准化:通过减少内部协变量转移加速深度网络训练:CoRRABS/1502.03167；2015;<a class="ae kh" href="http://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank">网址</a>；arXiv2018年8月13日星期一；<a class="ae kh" href="https://dblp.org/rec/bib/journals/corr/IoffeS15" rel="noopener ugc nofollow" target="_blank"> biburl </a></p><p id="fdeb" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">Brosch，t .，Tang，L. Y .，Yoo，y .，Li d . k .，Traboulsee，a .，&amp; Tam，R. (2016年)。应用于多发性硬化病变分割的具有多尺度特征整合捷径的深度3D卷积编码器网络。IEEE医学成像汇刊，35(5)，1229–1239。</p><p id="94d9" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">哈韦伊，m .，戴维，a .，沃德-法利，d .，比亚尔，a .，库维尔，a .，本吉奥，y .，… &amp;拉罗歇尔，H. (2017)。基于深度神经网络的脑肿瘤分割。<em class="kb">医学图像分析</em>，<em class="kb"> 35 </em>，18–31。</p><p id="d488" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">Kamnitsas，k .，Ledig，c .，Newcombe，V. F .，Simpson，J. P .，Kane，A. D .，Menon，D. K .，… &amp; Glocker，B. (2017)。高效的多尺度3D CNN与完全连接的CRF一起用于精确的脑部病变分割。<em class="kb">医学图像分析</em>，<em class="kb"> 36 </em>，61–78。</p></div></div>    
</body>
</html>