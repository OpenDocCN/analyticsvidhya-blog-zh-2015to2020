<html>
<head>
<title>Web-Scraping using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行Web抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-using-python-981c75b9672e?source=collection_archive---------11-----------------------#2020-07-07">https://medium.com/analytics-vidhya/web-scraping-using-python-981c75b9672e?source=collection_archive---------11-----------------------#2020-07-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/263fdcde8e34523d47512c3d3b21d09b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iw9QNqYay_kTWlyYPvYO1w.png"/></div></div></figure><div class=""/><p id="bba6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有没有想过从一些网站获取一些数据，或者想为一些数据科学问题或训练机器学习模型等创建一个结构化数据集…..如果是，那么这就是我为你准备的解决方案…</p><p id="6738" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">解决方案是<strong class="is hu">网页抓取</strong>也称为<strong class="is hu">网页采集</strong>或<strong class="is hu">网页数据提取</strong>是从网站中提取数据的工具。我们从网络抓取中获得的数据是一种<strong class="is hu">结构化的</strong>数据格式。</p><p id="3995" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> web scraping </strong>是一种工具，用于将<strong class="is hu"> web </strong>上的非结构化<strong class="is hu">数据</strong>转换为机器可读的结构化<strong class="is hu">数据</strong>，以备分析。</p><p id="0a63" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">网络爬虫</strong>与<strong class="is hu">网络刮刀</strong>的区别:</p><p id="7073" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">网络爬虫:网络爬虫，我们一般称之为“蜘蛛”，是一种人工智能，它通过跟随链接和探索来浏览互联网以索引和搜索内容，就像一个有太多时间的人。</p><p id="3e12" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">web scraper:web scraper是一个专门的工具，用于准确快速地从网页中提取数据。根据项目的不同，Web scrapers在设计和复杂性上有很大的不同。</p><p id="eba5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有时在一些网站上，<strong class="is hu">数据保护</strong>是存在的，使用正常的方式你将无法从网站上获取数据，所以我将给出解决这个问题的方法</p><p id="affa" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如，让我向您展示我第一次使用的程序，我得到了预期的响应，但是第二次当我试图使用相同的代码从相同的网站提取更多的数据时，我得到了以下错误</p><figure class="jp jq jr js fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es jo"><img src="../Images/307a2c0f09818447e53ae8940f5748c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oO52sGSWulfqZWJzuoVohw.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">数据保护问题</figcaption></figure><p id="b3b4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我为此编写的程序如下:</p><p id="2a06" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">导入库</p><pre class="jp jq jr js fd jx jy jz ka aw kb bi"><span id="cbec" class="kc kd ht jy b fi ke kf l kg kh">from urllib.request import urlopen<br/>from bs4 import BeautifulSoup</span></pre><p id="48c3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Beautifulsoup4: Beautiful Soup是一个库，可以很容易地从网页中抓取信息。它位于HTML或XML解析器之上，为迭代、搜索和修改解析树提供了Pythonic习惯用法。</p><p id="75d0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">urllib . request:<a class="ae ki" href="https://docs.python.org/3/library/urllib.request.html#module-urllib.request" rel="noopener ugc nofollow" target="_blank">urllib . request</a>模块定义了一些函数和类，这些函数和类有助于在复杂的世界中打开URL(主要是HTTP)——基本和摘要认证、重定向、cookies等等。</p><p id="f7b2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要做网页抓取，打开你想执行抓取的网站，进入开发者选项，你会看到HTML代码</p><figure class="jp jq jr js fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kj"><img src="../Images/a6feb1eaa4569fc80ecb8158564a1e4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IaVxw0XDxYgY25gCPQq5pA.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">网页开发者选项</figcaption></figure><pre class="jp jq jr js fd jx jy jz ka aw kb bi"><span id="0f2e" class="kc kd ht jy b fi ke kf l kg kh">url = "<a class="ae ki" href="https://www.yellowpages.com.au/search/listings?clue=Real+estate+agents&amp;locationClue=&amp;lat=&amp;lon=&amp;selectedViewMode=list" rel="noopener ugc nofollow" target="_blank">https://www.yellowpages.com.au/search/listings?clue=Real+estate+agents&amp;locationClue=&amp;lat=&amp;lon=&amp;selectedViewMode=list</a>"<br/>html = urlopen(url)<br/>soup = BeautifulSoup(html, 'lxml')<br/>type(soup)<br/>title = soup.title<br/>print(title)<br/># Print out the text<br/>text = soup.get_text()<br/>print(soup.text)<br/>all_links = soup.find_all(“a”)<br/>for link in all_links:<br/> if (link.get(“data-email”) == None):<br/> continue<br/> print(link.get(“data-email”))</span></pre><p id="7735" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当我们执行上面的代码时，标题会打印在控制台中，第一次点击代码时，我们会得到预期的响应，但同样，当我们尝试执行第二次以获取更多数据时，我会得到数据保护消息</p><p id="b944" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在假设，你得到了这个错误，你仍然想获取数据。你怎么能这样做</p><p id="b75f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里是使用selenium工具从网站获取电子邮件地址的python代码。我使用过与上面相同的网站</p><p id="2f45" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Selenium Python 绑定提供了一个简单的API来使用Selenium WebDriver编写功能/验收测试。通过Selenium Python API，您可以以直观的方式访问Selenium WebDriver的所有功能。</p><p id="4a09" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Selenium Python绑定提供了一个方便的API来访问Selenium WebDrivers，如Firefox、Ie、Chrome、Remote等。目前支持的Python版本为2.7、3.5及以上版本。</p><p id="2d23" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这个程序中，我使用了chrome网络驱动程序</p><figure class="jp jq jr js fd hk"><div class="bz dy l di"><div class="kk kl l"/></div></figure><p id="0629" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此代码的输出:</p><figure class="jp jq jr js fd hk er es paragraph-image"><div class="er es km"><img src="../Images/aa522e998b74dea65ce4b0e97f2bb366.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*as5u6O0xb4NZ3ZxHXN-2mA.png"/></div></figure><p id="92a7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我展示一些从Flipkart网站获取数据的更复杂的例子。为此，请打开Flipkart网页，并打开开发者工具。检查您想要获取的div参数，并相应地在代码中定义它。</p><figure class="jp jq jr js fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kn"><img src="../Images/326e16a4bcafe6530581dfd38a420227.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fiI2CInfIMomW08jGDutpg.png"/></div></div></figure><p id="0950" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">查看代码以提取excel文件中的名称、价格和规格</p><p id="1b6f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">导入库</p><pre class="jp jq jr js fd jx jy jz ka aw kb bi"><span id="e8d3" class="kc kd ht jy b fi ke kf l kg kh">from selenium import webdriver<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</span></pre><p id="22a7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> pandas </strong>是一个快速、强大、灵活且易于使用的开源数据分析和操作工具，构建在<a class="ae ki" href="https://www.python.org/" rel="noopener ugc nofollow" target="_blank"> Python </a>编程语言之上。</p><pre class="jp jq jr js fd jx jy jz ka aw kb bi"><span id="8a80" class="kc kd ht jy b fi ke kf l kg kh">driver = webdriver.Chrome(“C:\chromedriver_win32/chromedriver”)<br/>products=[] #List to store name of the product<br/>prices=[] #List to store price of the product<br/>ratings=[] #List to store rating of the product<br/>specs=[]#List to get the specs<br/>driver.get(“<a class="ae ki" href="https://www.flipkart.com/laptops/pr?sid=6bo%2Fb5g&amp;p%5B%5D=facets.offer_type%255B%255D%3DExchange%2BOffer&amp;wid=12.productCard.PMU_V2_8" rel="noopener ugc nofollow" target="_blank">https://www.flipkart.com/laptops/pr?sid=6bo%2Fb5g&amp;p%5B%5D=facets.offer_type%255B%255D%3DExchange%2BOffer&amp;wid=12.productCard.PMU_V2_8</a>")<br/>content = driver.page_source<br/>soup = BeautifulSoup(content)<br/>for a in soup.findAll(‘a’,href=True, attrs={‘class’:’_31qSD5'}):<br/> name=a.find(‘div’, attrs={‘class’:’_3wU53n’})<br/> price=a.find(‘div’, attrs={‘class’:’_1vC4OE _2rQ-NK’})<br/> rating=a.find(‘div’, attrs={‘class’:’hGSR34'})<br/> spec = a.find(‘div’, attrs={‘class’:’_3ULzGw’})<br/> products.append(name.text)<br/> prices.append(price.text)<br/> ratings.append(rating) <br/> specs.append(spec.text)</span></pre><p id="3008" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要以excel格式保存数据，请参见下面的代码片段</p><pre class="jp jq jr js fd jx jy jz ka aw kb bi"><span id="c79c" class="kc kd ht jy b fi ke kf l kg kh">df = pd.DataFrame({‘Product Name’:products,’Price’:prices,’Specification’:specs}) <br/>df.to_csv(‘products1.csv’, index=False, encoding=’utf-8')</span></pre><p id="9f8a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">运行代码后，会生成一个包含所需信息的excel表</p><figure class="jp jq jr js fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ko"><img src="../Images/57294fad91603bb6dd8549ab4626d563.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MESWJKT7JLhIijJYqMkE4A.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">上面代码的输出</figcaption></figure><p id="5b1b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">还有更多的操作可以使用web抓取来执行，例如从网站上的一些表格中获取信息，然后绘制这些信息，以图形表示的方式将其可视化</p><p id="3483" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我希望这篇文章能给你一些关于网络抓取的小提示</p></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="d976" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我仅出于学习目的使用了上述网站。</p></div></div>    
</body>
</html>