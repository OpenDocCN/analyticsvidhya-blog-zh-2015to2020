<html>
<head>
<title>Web Scraping using BeautifulSoup- COVID-19 Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用BeautifulSoup-新冠肺炎数据的网络抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-using-beautifulsoup-covid-19-data-44da0c702a62?source=collection_archive---------10-----------------------#2020-06-12">https://medium.com/analytics-vidhya/web-scraping-using-beautifulsoup-covid-19-data-44da0c702a62?source=collection_archive---------10-----------------------#2020-06-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/57e8f2f519de42c2b4af44f11e330f49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K3_bpuAEquEhGbPN"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">马丁·桑切斯在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="d88d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">网络抓取是从网站中提取大量的非结构化数据，并以结构化的格式存储在所需的文件/数据库中。我们将在这篇博客中看到它是如何实现的。</em></p><p id="b0f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">那么你如何从网上搜集数据呢？</p><p id="4ec0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你有没有从网站上复制粘贴过信息？如果是的话，我会说你在某种程度上已经完成了网络搜集。但是你不能复制粘贴大约100次甚至更多，你能吗？</p><p id="86af" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，让我们看看Python如何借助它的一个包—<strong class="ix hj"><em class="jt">beautiful soup</em></strong>来帮助我们做同样的事情。</p><ul class=""><li id="290b" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><strong class="ix hj">第1步-找到包含您所需信息的网站。</strong></li></ul><p id="b947" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一些网站，如Twitter和脸书，提供了API以方便连接和访问他们的数据。但是有些没有，所以你必须写一个代码来导航和提取它的内容。</p><p id="3714" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请记住，并不是每个网站都对你抓取他们的内容不感兴趣。所以确保你了解网站的条款和条件。</p><blockquote class="kd ke kf"><p id="ec68" class="iv iw jt ix b iy iz ja jb jc jd je jf kg jh ji jj kh jl jm jn ki jp jq jr js hb bi translated">你可以通过在网址后面加上“/robots.txt”来查看网站的权限。<br/> <strong class="ix hj"> robots.txt </strong>文件被称为robots排除协议。</p></blockquote><blockquote class="kj"><p id="dbfc" class="kk kl hi bd km kn ko kp kq kr ks js dx translated">我们先刮- <br/> <em class="kt">各个国家的新冠肺炎病例数- <br/> </em>从https://en.wikipedia.org/wiki/COVID-19_pandemic<a class="ae iu" href="https://en.wikipedia.org/wiki/COVID-19_pandemic" rel="noopener ugc nofollow" target="_blank"><strong class="ak">到<em class="kt"/></strong></a><em class="kt">。</em></p></blockquote><ul class=""><li id="7d0e" class="ju jv hi ix b iy ku jc kv jg kw jk kx jo ky js jz ka kb kc bi translated">第二步——检查网站。</li></ul><p id="f4d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">了解网站的结构以提取你感兴趣的信息是很重要的。找出需要抓取的数据所在的html标签。<br/>右击网站，然后点击检查。</p><blockquote class="kd ke kf"><p id="e149" class="iv iw jt ix b iy iz ja jb jc jd je jf kg jh ji jj kh jl jm jn ki jp jq jr js hb bi translated">为了理解和检查内容，您需要知道一些常用的HTML标签。<br/> &lt;标题&gt;标题| &lt; p &gt;段落<br/> &lt; a &gt;超链接| &lt; div &gt;页面上的分部<br/> &lt;表格&gt;表格| &lt; th &gt;表格标题<br/> &lt; tr &gt;表格行| &lt; tr &gt;表格单元格<br/>这些标签还可以有class、id、src、title等属性。</p></blockquote><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/7c640196dd4b9e70fc2900c0c801fb33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dhRJqna2_yer2vV7joyzTg@2x.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">检查前面提到的网站，用粉色突出显示的是我们将从中提取数据的标签。</figcaption></figure><ul class=""><li id="70c9" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated">第三步——在你的Python脚本中获取网站的HTML代码。</li></ul><p id="eafd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用<strong class="ix hj"> <em class="jt">请求</em> </strong>库向网站发送一个HTTP请求。服务器将以页面的HTML内容作为响应。</p><pre class="la lb lc ld fd lf lg lh li aw lj bi"><span id="4d60" class="lk ll hi lg b fi lm ln l lo lp">import requests <em class="jt"><br/></em>response = requests.get("<a class="ae iu" href="https://en.wikipedia.org/wiki/COVID-19_pandemic" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/COVID-19_pandemic</a>")</span></pre><p id="2618" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们检查请求是否成功。</p><pre class="la lb lc ld fd lf lg lh li aw lj bi"><span id="5af8" class="lk ll hi lg b fi lm ln l lo lp">response.status_code</span></pre><blockquote class="kd ke kf"><p id="ddd4" class="iv iw jt ix b iy iz ja jb jc jd je jf kg jh ji jj kh jl jm jn ki jp jq jr js hb bi translated"><strong class="ix hj">输出- </strong> 200</p></blockquote><p id="3461" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以2开头的状态代码通常表示成功，以4或5开头的代码表示错误。</p><pre class="la lb lc ld fd lf lg lh li aw lj bi"><span id="03d7" class="lk ll hi lg b fi lm ln l lo lp">response.content</span></pre><p id="4988" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">获得的响应将类似于您检查的HTML内容。</p><ul class=""><li id="c8ee" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><strong class="ix hj">第四步——用BeautifulSoup解析HTML数据</strong></li></ul><p id="4add" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于嵌套标签和多个属性，HTML内容看起来复杂而混乱。我们现在需要美丽的声音来简化我们的任务。<br/> BeautifulSoup是一个解析HTML和XML文档的python包。它创建解析树并使提取数据变得容易。</p><p id="0879" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们首先导入BeautifulSoup包并创建它的对象‘soup’。</p><pre class="la lb lc ld fd lf lg lh li aw lj bi"><span id="b97d" class="lk ll hi lg b fi lm ln l lo lp">from bs4 import BeautifulSoup<br/>soup = BeautifulSoup(response.content, 'html.parser')<br/>soup.prettify()</span></pre><p id="f7f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"><em class="jt">【pretify()</em></strong><em class="jt"/>函数帮助我们查看标签嵌套的方式。</p><ul class=""><li id="d83a" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><strong class="ix hj">步骤5-使用soup过滤出所需的数据。</strong></li></ul><pre class="la lb lc ld fd lf lg lh li aw lj bi"><span id="b792" class="lk ll hi lg b fi lm ln l lo lp">print(soup.title.text)</span></pre><blockquote class="kd ke kf"><p id="9730" class="iv iw jt ix b iy iz ja jb jc jd je jf kg jh ji jj kh jl jm jn ki jp jq jr js hb bi translated"><strong class="ix hj">输出- </strong>新冠肺炎·疫情-维基百科</p></blockquote><p id="111f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在将提取国家的名称和病例数，死亡人数和康复人数。</p><pre class="la lb lc ld fd lf lg lh li aw lj bi"><span id="1f11" class="lk ll hi lg b fi lm ln l lo lp">table= soup.find('table', attrs={"class" : "wikitable"})</span><span id="62dd" class="lk ll hi lg b fi lq ln l lo lp">Country = []<br/>Cases = []<br/>Deaths = []<br/>Recoveries = []</span><span id="329f" class="lk ll hi lg b fi lq ln l lo lp">trs = table.select("tbody tr")[2:230]</span><span id="f8a0" class="lk ll hi lg b fi lq ln l lo lp">for tr in trs:<br/>    Country.append(tr.find_all("th", attrs = {'scope' : 'row'})[1].find('a').text) <br/>    <br/>    tds = tr.find_all("td")<br/>    Cases.append(tds[0].text.replace("\n", "").strip())<br/>    Deaths.append(tds[1].text.replace("\n", "").strip())<br/>    Recoveries.append(tds[2].text.replace("\n", "").strip())</span></pre><p id="68c9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面代码中使用的一些BeautifulSoup函数:<br/><strong class="ix hj"><em class="jt">select()</em></strong>帮助导航嵌套的HTML标签，并最终找到所需标签的出现。</p><p id="2bb1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> find() </em> </strong>从网页响应中返回第一次出现的被传递标签<em class="jt">。</em><strong class="ix hj"><em class="jt"><br/>【find _ all()</em></strong>返回我们作为参数传递的标签的所有出现次数。<strong class="ix hj"><em class="jt"><br/></em></strong>find()和find_all()都接受特定的属性作为它们的第二个参数。</p><p id="6cda" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"><em class="jt">text</em></strong>attribute<strong class="ix hj"><em class="jt"/></strong>帮助我们从上述任一函数返回的标签中获取内容。</p><ul class=""><li id="95c5" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><strong class="ix hj">步骤6-存储提取的数据。</strong></li></ul><p id="9625" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们将这些数据存储在一个<a class="ae iu" href="https://link.medium.com/sRvo73oMh7" rel="noopener"><strong class="ix hj"><em class="jt">pandas</em></strong></a>data frame中，以便于进一步的分析。</p><pre class="la lb lc ld fd lf lg lh li aw lj bi"><span id="7711" class="lk ll hi lg b fi lm ln l lo lp">import pandas as pd<br/>data = list(zip(Country, Cases, Deaths, Recoveries))<br/>COVID_data = pd.DataFrame(data, columns=['Country', 'Cases', 'Deaths', 'Recoveries'])<br/>COVID_data.head(10)</span></pre><blockquote class="kd ke kf"><p id="72ec" class="iv iw jt ix b iy iz ja jb jc jd je jf kg jh ji jj kh jl jm jn ki jp jq jr js hb bi translated"><strong class="ix hj">输出- </strong></p></blockquote><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/b928f719cc677df1b8317634ce1aac94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DOFfDwiBLOXMzHCybBO6cw@2x.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd le">病例数最多的前10个国家。</strong></figcaption></figure><p id="8104" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">注意-该数据由网站持续更新。所以当你读的时候，这些值会不一样。</em></p><p id="ec2c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">感谢阅读！你自己去试试！</em> </strong></p><p id="5bee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">代码:</strong><a class="ae iu" href="https://github.com/akshada30/COVID-19-Data/blob/master/COVID-19%20Data%20Scraping.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="jt">https://github . com/aksha da 30/新冠肺炎-数据/blob/master/新冠肺炎% 20 Data % 20 scraping . ipynb</em></a></p><p id="1880" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">领英:</strong><a class="ae iu" href="https://www.linkedin.com/in/akshada-gaonkar-9b8886189/" rel="noopener ugc nofollow" target="_blank"><em class="jt">https://www.linkedin.com/in/akshada-gaonkar-9b8886189/</em></a></p></div></div>    
</body>
</html>