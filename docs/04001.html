<html>
<head>
<title>Building Neural Network Framework in C using Backpropagation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用反向传播法在C语言中构建神经网络框架</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-neural-network-framework-in-c-using-backpropagation-8ad589a0752d?source=collection_archive---------0-----------------------#2020-03-01">https://medium.com/analytics-vidhya/building-neural-network-framework-in-c-using-backpropagation-8ad589a0752d?source=collection_archive---------0-----------------------#2020-03-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="c7a6" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">神经网络框架的C语言基本实现</h2></div><p id="d6c0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本文中，我们将用C语言从头开始实现一个基本的神经网络框架。之所以用C来做，是因为大多数库和其他高级语言(如Python)都抽象出了实现细节。用C语言实现反向传播实际上会给我们提供详细的见解，让我们了解改变权重和偏差是如何改变网络的整体行为的。</p><p id="eb92" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">注意:</strong>本文假设你知道反向传播算法背后的数学原理。如果你不熟悉，那么请参考<a class="ae jt" href="http://neuralnetworksanddeeplearning.com/chap2.html" rel="noopener ugc nofollow" target="_blank">这个</a>。</p><p id="4ccf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的目标是建立一个通用框架，其中层和神经元的数量将由用户根据他的要求指定。因此，我们将从用户处获得以下输入，用于定义我们的神经网络框架:</p><p id="316f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1.层数</p><p id="b027" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.每层神经元的数量</p><p id="eedf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.学习率</p><p id="5185" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4.培训示例</p><p id="2ca4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">5.输出标签</p><h2 id="d87d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated"><strong class="ak">定义层和神经元结构:</strong></h2><p id="fd01" class="pw-post-body-paragraph ix iy hi iz b ja kp ij jc jd kq im jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">一旦我们有了层数和每层神经元的数量，我们就可以创建神经网络的架构。但首先我们必须定义神经元和层的结构。</p><p id="5e2f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">神经元结构将包含以下参数:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="018d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">层结构将具有该层中的多个神经元和neuron_t结构的指针。</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><h2 id="5505" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated"><strong class="ak">创建架构:</strong></h2><p id="ef18" class="pw-post-body-paragraph ix iy hi iz b ja kp ij jc jd kq im jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">现在，让我们使用create_architecture()函数创建神经网络的架构。</p><p id="13ab" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在下面给出的代码片段中，外部for循环创建层，内部For循环向该层添加指定数量的神经元。我们还在0和1之间随机初始化神经元的权重。</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><h2 id="bdf7" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated"><strong class="ak">获取培训示例:</strong></h2><p id="b8a3" class="pw-post-body-paragraph ix iy hi iz b ja kp ij jc jd kq im jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">我们将使用get_inputs()函数存储训练示例:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><h2 id="6393" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated"><strong class="ak">获取输出标签:</strong></h2><p id="acc6" class="pw-post-body-paragraph ix iy hi iz b ja kp ij jc jd kq im jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">我们将使用get_desired_outputs()函数存储输出标签:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><h2 id="6312" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated"><strong class="ak">向前传球:</strong></h2><p id="f8ec" class="pw-post-body-paragraph ix iy hi iz b ja kp ij jc jd kq im jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">第I层中第j个神经元的激活与第(I-1)层中的激活相关联，公式如下:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lb"><img src="../Images/5feede198dfebfb45f888c2cc95e476d.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*xQcIWQTq4hI0__W_USVQJg.png"/></div></figure><p id="2619" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注:σ为激活函数。这里，我们将对输出层使用sigmoid激活函数，对隐藏层使用Relu激活函数。</p><p id="182c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">乙状结肠:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es le"><img src="../Images/1130c051f9f7a20ddfb9e6af450e9f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*HcLR-903h2QqDEGRY9QxAw.png"/></div></figure><p id="9637" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Relu:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lf"><img src="../Images/06c8e0c56537858aeeb0cbdd0afb19af.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*5sqPrt9gfpZstV4lGtVnIg.png"/></div></figure><p id="a074" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们实现forward_prop()函数:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><h2 id="65f2" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated"><strong class="ak">向后传球:</strong></h2><p id="5a70" class="pw-post-body-paragraph ix iy hi iz b ja kp ij jc jd kq im jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">反向传播的目标是反向传播误差并更新权重以最小化误差。这里，我们将使用均方误差函数来计算误差。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lg"><img src="../Images/b83839814599c37bcf83fa225789921c.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*a3WF7_uTb4PB1RMH_JI8nA.png"/></div></figure><p id="61cb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用成本函数c相对于网络中的权重和偏差的偏导数(∂C/∂weights和∂C/∂bias)来计算权重(dw)和偏差(d bias)的变化。</p><p id="1aa5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">乙状结肠的导数:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lh"><img src="../Images/fffe755034afb736c26222a7a4f97381.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*AMDygJ9lCxZFIubDYzN6Aw.png"/></div></figure><p id="43a5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Relu的导数:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es li"><img src="../Images/80c66a8ed2d88a19392f7d72222b6f8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*dgK26nFs37JJWChCoxchag.png"/></div></figure><p id="1522" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">反向传播背后的四个基本方程:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lj"><img src="../Images/1560c25419497f1c54f1dd7dadb07b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*K4D8qfb-BU1fn1yET1Njag.png"/></div></figure><p id="926f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们在back_prop()函数中实现这些公式:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><h2 id="93f4" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated"><strong class="ak">更新权重:</strong></h2><p id="8a0e" class="pw-post-body-paragraph ix iy hi iz b ja kp ij jc jd kq im jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">在每个时期，我们将使用update_weights()函数更新网络权重和偏差:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><h2 id="6dec" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">测试框架</h2><p id="b4fe" class="pw-post-body-paragraph ix iy hi iz b ja kp ij jc jd kq im jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">现在我们已经准备好了所有的部分，我们将验证我们的框架的工作。因此，让我们创建一个4层神经网络，其中输入层有2个神经元，第一隐藏层有4个神经元，第二隐藏层有4个神经元，输出层有1个神经元。此外，隐藏和输出神经元会有偏差。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lk"><img src="../Images/7c113e3c7f138f30d0b7d5991d558f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*Z7AqsskpE4ECLfJyZIDbLg.png"/></div></figure><p id="0add" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们可以为不同的逻辑门训练这个神经网络，例如Xor、OR和etc。在下面的例子中，我们将实现异或门。</p><p id="e64a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，提供所需的层数和每层神经元数:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="c0e4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将根据给定的规范创建神经网络架构:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="ac55" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所有权重将在0和1之间随机初始化。</p><p id="01e6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，提供学习率和输入训练示例。以下是XOR逻辑门的真值表。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es ll"><img src="../Images/49dd927c042a32e6c6dfd039a96beb72.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*Hz9lagcZ0y2vRTHZcCueKA.png"/></div></figure><p id="d926" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将给出上述4个输入作为神经网络的训练示例。</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="13bf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">给出输出标签:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="41ef" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的神经网络将在这4个训练样本上训练20000个时期。</p><p id="9ccf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，测试训练好的神经网络:</p><figure class="ku kv kw kx fd ky"><div class="bz dy l di"><div class="kz la l"/></div></figure><h2 id="54a7" class="ju jv hi bd jw jx jy jz ka kb kc kd ke jg kf kg kh jk ki kj kk jo kl km kn ko bi translated">结论:</h2><p id="54eb" class="pw-post-body-paragraph ix iy hi iz b ja kp ij jc jd kq im jf jg kr ji jj jk ks jm jn jo kt jq jr js hb bi translated">这是一个神经网络框架的基本实现，目的是理解神经网络和反向传播算法的基础。通过实现各种损失函数和提供权重的保存/加载，可以随意增强代码。</p><p id="4d3c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以在这里找到完整的代码<a class="ae jt" href="https://github.com/mayurbhole/Neural-Network-framework-using-Backpropogation-in-C" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>