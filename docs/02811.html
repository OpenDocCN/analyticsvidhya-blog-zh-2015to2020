<html>
<head>
<title>It’s The Same Hamburger!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">是同一个汉堡！！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/its-the-same-hamburger-1262ce67892a?source=collection_archive---------30-----------------------#2020-01-02">https://medium.com/analytics-vidhya/its-the-same-hamburger-1262ce67892a?source=collection_archive---------30-----------------------#2020-01-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="39c4" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">自然语言处理(下)</p><p id="a63b" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">以下是NLP系列文章的一部分。(查 <a class="ae jh" rel="noopener" href="/@azabou.sofiene/its-the-same-hamburger-983a7966acd8"> <em class="hi">第一部分</em> </a> <em class="hi"> &amp; </em> <a class="ae jh" rel="noopener" href="/@azabou.sofiene/how-do-they-read-your-mind-c145d1b3de74"> <em class="hi">第三部分</em> </a> <em class="hi"> ) </em></p></blockquote><p id="6946" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi jl translated"><span class="l jm jn jo bm jp jq jr js jt di">正如我们在上一篇文章中看到的，NLP提供了有趣的功能，这些功能正在改变当今的许多行业。电脑能做那么多事情，这很酷，但是它是怎么做到的呢？哦，是的，你猜对了，我们要去一些严肃的地方..东西！</span></p><h1 id="9cca" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">NLP框架</h1><p id="bb05" class="pw-post-body-paragraph ii ij hi il b im ks io ip iq kt is it ji ku iw ix jj kv ja jb jk kw je jf jg hb bi translated">我们将逐步构建一个自然语言处理框架，在本“教程”结束时，您将能够构建自己的NLP模型。我们开始吧！</p><figure class="ky kz la lb fd lc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es kx"><img src="../Images/7031f194cf76380ba1e0eb96a2747440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*togkH_MMvEEboa9tMGX0aw.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">NLP框架</figcaption></figure><p id="be24" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">首先，我们来看这段文字。这是比尔·盖茨的一句名言，也是我最喜欢的一句。如果我的电脑能读懂这句话，尤其是能“理解”它，那就太棒了，不是吗？要实现这一点，我们需要采取几个步骤。</p><figure class="ky kz la lb fd lc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ln"><img src="../Images/c32aac6010175057d19c8eb2114b156e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2SFEOEsaBiRNTik8cisa4g.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">比尔·盖茨——微软创始人兼董事长</figcaption></figure><h1 id="6e5c" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">数据预处理</h1><p id="1ca9" class="pw-post-body-paragraph ii ij hi il b im ks io ip iq kt is it ji ku iw ix jj kv ja jb jk kw je jf jg hb bi translated">数据预处理被认为是这项工作中最烦人的部分，因为它在技术上没有吸引力，而且相对费力，但仍然很重要。数据科学家中有一句名言:“垃圾进，垃圾出”。这意味着，如果你给你的机器学习模型输入肮脏的数据，它会直接把它扔回到你面前(抱歉😊)..换句话说，它会给你无意义的结果。够公平吧？这就是为什么这部分工作要严谨的做。<br/>通常，在处理结构化数据时，数据预处理往往涉及到删除重复数据、空值和错误。当涉及到文本数据时，有许多常见的数据预处理技术，也称为文本清洗技术。<br/>为了应用预处理技术，我们将使用一个非常强大的Python库:<a class="ae jh" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="il hj"> NLTK:自然语言工具包</strong> </a>。NLTK提供了一套文本处理库，用于分类、标记化、词干提取、标记等。坚持住，我们将在几分钟后看到所有这些功能。敬请期待！</p><h2 id="0c6f" class="lo jv hi bd jw lp lq lr ka ls lt lu ke ji lv lw ki jj lx ly km jk lz ma kq mb bi translated">句子分割</h2><p id="f80b" class="pw-post-body-paragraph ii ij hi il b im ks io ip iq kt is it ji ku iw ix jj kv ja jb jk kw je jf jg hb bi translated">基本上，它是把我们的文本分成单独的句子的行为。在我们的例子中，我们将以这个结束:</p><p id="ac37" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">1.“我能理解想要拥有数百万美元，随之而来的是某种自由，有意义的自由。”2<br/>2。“但是一旦你吃得太多，我不得不告诉你，这还是同一个汉堡。” <br/> 3。<em class="ik">“比尔·盖茨——董事长&amp;微软创始人”</em></p><p id="ec9f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">在这种情况下，我们可以假设每个句子代表一个独立的想法。因此，开发一个理解单个句子而不是整个段落的算法要容易得多。</p><h2 id="c1f3" class="lo jv hi bd jw lp lq lr ka ls lt lu ke ji lv lw ki jj lx ly km jk lz ma kq mb bi translated">符号化</h2><p id="b8c5" class="pw-post-body-paragraph ii ij hi il b im ks io ip iq kt is it ji ku iw ix jj kv ja jb jk kw je jf jg hb bi translated">现在我们把文本分成句子，让我们做得更好，把它分成单词，或者更准确地说是“记号”。例如，让我们从引用的第一句话开始:</p><p id="6375" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">“我能理解想要拥有数百万美元，随之而来的是某种自由，有意义的自由。”</p><p id="e2c8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">应用标记化后，结果如下:</p><p id="d00a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated"><em class="ik">"我"、"能"、"懂"、"想"、"有"、"百万"、"美元"、"有"、"有"、"某"、"自由"、"有意义"、"自由"、"那个"、"那个"、"来了"、"有了"、"那个"、"那个"。"</em></p><pre class="ky kz la lb fd mc md me mf aw mg bi"><span id="b8a0" class="lo jv hi md b fi mh mi l mj mk">text = '''<em class="ik">I can understand wanting to have millions of dollars, there’s a certain freedom, meaningful freedom, that comes with that</em>. <em class="ik">But once you get much beyond that, I have to tell you, it’s the same hamburger. Bill Gates — Chairman &amp; Founder of Microsoft'''</em></span><span id="1c87" class="lo jv hi md b fi ml mi l mj mk">#Import NLTK Library<br/>import nltk</span><span id="b530" class="lo jv hi md b fi ml mi l mj mk">#Segmentation<br/>nltk.tokenize.sent_tokenize(text)</span><span id="9f69" class="lo jv hi md b fi ml mi l mj mk">#Tokenization<br/>nltk.tokenize.word_tokenize(text)</span></pre><h2 id="6ec1" class="lo jv hi bd jw lp lq lr ka ls lt lu ke ji lv lw ki jj lx ly km jk lz ma kq mb bi translated">文本剥离</h2><p id="ee05" class="pw-post-body-paragraph ii ij hi il b im ks io ip iq kt is it ji ku iw ix jj kv ja jb jk kw je jf jg hb bi translated">如果你和我想的一样，那你就错了..但是我们还是会脱下一些东西。<br/><strong class="il hj">使文本小写:</strong>这是一种标准化检查点，以避免我们要处理的字符数。<br/><strong class="il hj">扩展缩写:</strong>非正式英语充满了应该被替换的缩写，总是试图尽可能地使我们的文本正常化。<br/>例如，在我们的引用中，“there's”将被替换为“there is”。</p><p id="bdf3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">我在<a class="ae jh" href="https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python" rel="noopener ugc nofollow" target="_blank"> StackOverFlow </a>上找到了下面使用的<strong class="il hj"> cList </strong>。</p><pre class="ky kz la lb fd mc md me mf aw mg bi"><span id="2d86" class="lo jv hi md b fi mh mi l mj mk">###Make text lowercase &amp; Expand contractions</span><span id="1287" class="lo jv hi md b fi ml mi l mj mk">#Load English contracted/expanded words list from a .py file<br/>from contractions import cList</span><span id="6631" class="lo jv hi md b fi ml mi l mj mk"># Compile a regular expression pattern for matching <br/>import re<br/>c_re = re.compile('(%s)' % '|'.join(cList.keys()))</span><span id="8f05" class="lo jv hi md b fi ml mi l mj mk">#Create a function to look for contractions and replace them with their full form<br/>#Put text in lowercase to make sure all words are included<br/>def expandContractions(text, c_re=c_re):<br/>    def replace(match):<br/>        return cList[match.group(0)]<br/>    return c_re.sub(replace, text.lower())</span><span id="113c" class="lo jv hi md b fi ml mi l mj mk">#Notice it's a bit grammatically incorrect, but it doesn't matter since we gonna remove the stopwords later<br/>expanded_text = expandContractions(text)</span></pre><p id="2dbc" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">注意这有点语法错误，但是没关系，因为我们稍后会删除停用词😉</p><p id="6915" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated"><strong class="il hj">删除标点符号:</strong>标点符号代表不需要的字符，让我们去掉它们。</p><pre class="ky kz la lb fd mc md me mf aw mg bi"><span id="9240" class="lo jv hi md b fi mh mi l mj mk">###Remove punctuations</span><span id="11c1" class="lo jv hi md b fi ml mi l mj mk">#Import string library<br/>import string</span><span id="d8f8" class="lo jv hi md b fi ml mi l mj mk">#Create a function to remove punctuation / special characters '!"#$%&amp;\'()*+,-./:;&lt;=&gt;?#@[\\]^_`{|}~'<br/>def clean_text(text):<br/>    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)<br/>    return text</span></pre><p id="3ab6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated"><strong class="il hj">拼写纠正:</strong>想法很简单；我们将使用一个大语料库作为参考来纠正我们文本中的单词拼写。<br/><strong class="il hj">删除停用词:</strong>停用词是被过度使用的词，对每篇文章所传达的信息没有额外的重要信息。大多数常见的停用词是限定词(如the，a，an)，介词(如above，cross，before)和一些形容词(如good，nice)。让我们把他们赶出去！</p><p id="1346" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated"><em class="ik">我能</em> <strong class="il hj">理解想要</strong> <em class="ik">拥有</em> <strong class="il hj">百万</strong><em class="ik"/><strong class="il hj"><em class="ik"/>美元</strong> <em class="ik">，有一种</em> <strong class="il hj">确定的自由</strong> <em class="ik">，</em> <strong class="il hj">有意义的自由</strong> <em class="ik">，那种</em> <strong class="il hj">伴随着那种而来</strong> <em class="ik">。<br/> <em class="ik">但是一旦你</em> <strong class="il hj">得到远远超出</strong> <em class="ik">的那一点，我就不得不</em> <strong class="il hj">告诉</strong> <em class="ik">你，这是一样的</em> <strong class="il hj">汉堡</strong> <em class="ik">。</em> <br/> <strong class="il hj">比尔盖茨</strong><em class="ik">——</em><strong class="il hj">董事长</strong> <em class="ik"> &amp; </em> <strong class="il hj">创始人</strong><em class="ik"/><strong class="il hj">微软</strong></em></p><pre class="ky kz la lb fd mc md me mf aw mg bi"><span id="06b7" class="lo jv hi md b fi mh mi l mj mk">###Remove stopwords</span><span id="1765" class="lo jv hi md b fi ml mi l mj mk">#nltk.download('stopwords')<br/>from nltk.corpus import stopwords</span><span id="a4f0" class="lo jv hi md b fi ml mi l mj mk">#Create a function to remove stopwords<br/>def remove_stopwords (sentence = None):<br/>    words = sentence.split()<br/>    stopwords_list = stopwords.words("english")<br/>    clean_words = []<br/>    for word in words:<br/>        if word not in stopwords_list:<br/>            clean_words.append(word)<br/>    return ' '.join(clean_words);</span></pre><figure class="ky kz la lb fd lc er es paragraph-image"><div class="er es mm"><img src="../Images/cb58f73ca6fa12d6745a0633389b79be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*7hNuTDwAY6Wh-gzgLqvXGQ.png"/></div></figure><p id="8c3a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated"><strong class="il hj">词性过滤:</strong>目的是通过给每个单词添加标签来识别其词汇类别:动词、形容词、名词、副词、代词、介词……</p><pre class="ky kz la lb fd mc md me mf aw mg bi"><span id="5198" class="lo jv hi md b fi mh mi l mj mk">###Part of Speech Tagger</span><span id="ed92" class="lo jv hi md b fi ml mi l mj mk">#nltk.download('averaged_perceptron_tagger')<br/>import nltk<br/>from nltk import pos_tag, word_tokenize</span><span id="df38" class="lo jv hi md b fi ml mi l mj mk">#Create a function to pull out nouns &amp; adjectives from text<br/>def nouns_adj(text):<br/>    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'<br/>    tokenized = word_tokenize(text)<br/>    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if <br/>    is_noun_adj(pos)] <br/>    return ' '.join(nouns_adj)</span><span id="2667" class="lo jv hi md b fi ml mi l mj mk">#Return list of tuple [word; PoS]<br/>tokens = word_tokenize(clean_text_sw)<br/>tuple_list = nltk.pos_tag(tokens)</span></pre><figure class="ky kz la lb fd lc er es paragraph-image"><div class="er es mn"><img src="../Images/3fdfa5c4f3168647fa8123124bcdef82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*TbUIsNls4wWHDK1SQusxhw.jpeg"/></div></figure><p id="00fc" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">在大多数语言中，单词可以以不同的形式出现。将每个单词替换成它的基本形式会很有趣，这样我们的计算机就可以理解不同的句子可能在谈论同一个概念。所以，让我们来引用我们的话吧！</p><p id="1eaa" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">就我们而言，“我可以理解想要拥有数百万美元的愿望”</p><p id="e94b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated">变成“我可以理解为<strong class="il hj">【想要】</strong>有<strong class="il hj">【百万】</strong><strong class="il hj">【美元】</strong>”</p><pre class="ky kz la lb fd mc md me mf aw mg bi"><span id="f6d7" class="lo jv hi md b fi mh mi l mj mk">###Lemmatization</span><span id="f4a3" class="lo jv hi md b fi ml mi l mj mk">#nltk.download('wordnet')</span><span id="1960" class="lo jv hi md b fi ml mi l mj mk">#Lemmatize text with appropriate POS tag<br/>from nltk.stem import WordNetLemmatizer<br/>from nltk.corpus import wordnet</span><span id="aa4f" class="lo jv hi md b fi ml mi l mj mk">#Create a function to map NLTK's POS tags to the format wordnet lemmatizer would accept<br/>def get_wordnet_pos(word):<br/>    tag = nltk.pos_tag([word])[0][1][0].upper()<br/>    tag_dict = {"J": wordnet.ADJ,<br/>                "N": wordnet.NOUN,<br/>                "V": wordnet.VERB,<br/>                "R": wordnet.ADV}<br/>    return tag_dict.get(tag, wordnet.NOUN)</span><span id="f4ab" class="lo jv hi md b fi ml mi l mj mk">#Create an instance of the WordNetLemmatizer()<br/>lemmatizer = WordNetLemmatizer()</span><span id="7a66" class="lo jv hi md b fi ml mi l mj mk">#Create a function to return text after lemmatization<br/>def lemmatize_text(text):<br/>    lemm_text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(clean_text_sw)]<br/>    return ' '.join(lemm_text)</span></pre><p id="2f97" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ji iv iw ix jj iz ja jb jk jd je jf jg hb bi translated"><strong class="il hj">命名实体识别:</strong>是一个算法以一串文本(句子或段落)作为输入，识别相关名词(人、地点、组织等)的过程..)在那串中提到的。</p><pre class="ky kz la lb fd mc md me mf aw mg bi"><span id="c4d0" class="lo jv hi md b fi mh mi l mj mk">###Named Entity recognition</span><span id="550a" class="lo jv hi md b fi ml mi l mj mk">#nltk.download('maxent_ne_chunker')<br/>#nltk.download('words')<br/>from nltk import ne_chunk</span><span id="1d25" class="lo jv hi md b fi ml mi l mj mk">#Create a function to tokenize and PoS your text<br/>def NER(text):<br/>    text = nltk.tokenize(text)<br/>    text = nltk.pos_tag(text)<br/>    return text</span><span id="ae9e" class="lo jv hi md b fi ml mi l mj mk">text_NER = NER(text)</span><span id="515c" class="lo jv hi md b fi ml mi l mj mk">pos_list = ne_chunck(text_NER)</span></pre><figure class="ky kz la lb fd lc er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es mo"><img src="../Images/1853e97477652ca212141caaefa064a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yNmIndN1hUrZNTx3NUCBlw.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">来看看吧！</figcaption></figure></div></div>    
</body>
</html>