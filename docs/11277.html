<html>
<head>
<title>Evaluation Metrics for Regression Algorithms (Along with their implementation in Python)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归算法的评估指标(以及它们在Python中的实现)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/evaluation-metrics-for-regression-algorithms-along-with-their-implementation-in-python-9ec502729dad?source=collection_archive---------4-----------------------#2020-11-27">https://medium.com/analytics-vidhya/evaluation-metrics-for-regression-algorithms-along-with-their-implementation-in-python-9ec502729dad?source=collection_archive---------4-----------------------#2020-11-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3675" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">本文主要关注用于评估回归算法的评估指标及其在Python中的实现。在本文结束时，您将熟悉回归算法的评估指标以及它们在python中的实现。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/cee96007357be006be98c909976f77c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gnd2H_j4UyEDTR4o18tMgg.jpeg"/></div></div></figure><p id="03c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型的评估是建立有效的机器学习模型的最重要的部分。在进入正题之前，我们先了解一下什么是回归算法。</p><h2 id="02e3" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">什么是回归算法？</h2><p id="ca66" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">回归算法属于监督机器学习算法。回归算法基于输入要素预测连续值。例如:基于房屋特征(卧室数量、房屋大小、位置、房龄、装修年份)的房价预测。</p><h2 id="aad7" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">什么是评估指标？</h2><p id="2748" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">评估指标用于衡量机器学习算法的质量。不同类型的算法有许多评估指标。我们将讨论回归的评估标准。</p><h2 id="2265" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">机器学习回归算法的评估标准；</h2><ol class=""><li id="f751" class="kq kr hi ih b ii kl im km iq ks iu kt iy ku jc kv kw kx ky bi translated">绝对平均误差</li><li id="6648" class="kq kr hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">均方误差</li><li id="57d5" class="kq kr hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">均方根误差</li><li id="de0c" class="kq kr hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">r分数</li><li id="43d5" class="kq kr hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">调整后的R分数</li></ol><h1 id="726e" class="le jr hi bd js lf lg lh jw li lj lk ka ll lm ln kd lo lp lq kg lr ls lt kj lu bi translated">平均绝对误差</h1><p id="0de2" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated"><strong class="ih hj">平均绝对误差</strong>是实际值和预测值的绝对差之和的平均值。平均绝对误差对异常值不敏感。当您在解决回归问题并且不希望异常值在预测中扮演重要角色时，应该使用MAE。如果您知道数据的分布是<a class="ae lv" href="https://en.wikipedia.org/wiki/Multimodal_distribution#:~:text=In%20statistics%2C%20a%20Multimodal%20distribution,in%20Figures%201%20and%202." rel="noopener ugc nofollow" target="_blank">多峰</a>的，这可能会很有用。</p><p id="fc77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看平均绝对误差的公式:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lw"><img src="../Images/690dbe4240676599a7bc2790aa611370.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*fYNhlncTwLYqUl-_H6YElA.png"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">平均绝对误差公式</figcaption></figure><p id="f910" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们分解这个公式:</p><p id="e026" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">yᵢ =预测值</p><p id="35c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">yᵢ帽=实际价值</p><p id="a7b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里(yᵢ - yᵢhat)是误差值，误差的绝对值被用来去除任何负号。</p><p id="f28a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看使用python实现平均绝对误差的部分。设X_train，y_train为训练数据，X_test，y_test为评估我们模型的测试数据。</p><p id="39a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">MAE值较小的模型比MAE值较大的模型性能更好。</p><pre class="jf jg jh ji fd mb mc md me aw mf bi"><span id="777d" class="jq jr hi mc b fi mg mh l mi mj"># Importing all necessary libraries<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import mean_absolute_error</span><span id="a1b6" class="jq jr hi mc b fi mk mh l mi mj"># Initializing the model and fitting the model with train data<br/>model = LinearRegression()<br/>model.fit(X_train,y_train)</span><span id="7a06" class="jq jr hi mc b fi mk mh l mi mj"># Generating predictions over test data<br/>predictions = model.predict(X_test)</span><span id="ebcc" class="jq jr hi mc b fi mk mh l mi mj"># Evaluating the model using MAE Evaluation Metric<br/>print(mean_absolute_error(y_test, predictions))</span></pre><h1 id="bf02" class="le jr hi bd js lf lg lh jw li lj lk ka ll lm ln kd lo lp lq kg lr ls lt kj lu bi translated">均方误差</h1><p id="ad1d" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated"><strong class="ih hj">均方差</strong>是实际值和预测值之差的平方和的平均值。</p><p id="4a55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当数据集包含异常值或意外值(过高或过低的值)时，MSE最有用。因此，应该考虑到，如果我们的模型做出一个非常糟糕的预测，MSE会放大误差。</p><p id="4564" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当单个错误的预测会破坏整个模型的预测能力时，即当数据集包含大量噪声时，MSE是最没有用的。</p><p id="b54a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">MSE的单位是垂直轴或y轴上绘制的任何东西的平方。因为函数中取了误差的平方。</p><p id="2839" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大的MSE值意味着数据值广泛分散在数据的平均值周围，而小的MSE值意味着数据值紧密分散在平均值周围。即具有小MSE值的模型具有更好的性能。</p><p id="52b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看均方差的公式:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ml"><img src="../Images/4a908272c8bb5700ff1cd541c6f0c5f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WDKhO-z7rti70ZTv59yJ9A.jpeg"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">均方误差公式</figcaption></figure><p id="4ca0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">误差的平方(yᵢ-yᵢhat)对于消除任何负号是必要的，并且也给予大的差异更多的权重。</p><p id="eaf3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看使用python实现均方误差的部分。设X_train，y_train为训练数据，X_test，y_test为评估我们模型的测试数据。</p><pre class="jf jg jh ji fd mb mc md me aw mf bi"><span id="b03a" class="jq jr hi mc b fi mg mh l mi mj"># Importing all necessary libraries<br/>import numpy as np<br/>from sklearn.ensemble import RandomForestRegressor<br/>from sklearn.metrics import mean_squared_error</span><span id="9529" class="jq jr hi mc b fi mk mh l mi mj"># Defining our own MSE function<br/>def own_mean_squared_error(actual, predictions):<br/>    return <!-- -->((predictions - actual) ** 2).mean()</span><span id="b8fa" class="jq jr hi mc b fi mk mh l mi mj"># Initializing the model and fitting the model with train data<br/>model = RandomForestRegressor(<br/>               n_estimators = 100,<br/>               criterion = 'mse'<br/>        )<br/>model.fit(X_train,y_train)</span><span id="fb8e" class="jq jr hi mc b fi mk mh l mi mj"># Generating predictions over test data<br/>predictions = model.predict(X_test)</span><span id="d87b" class="jq jr hi mc b fi mk mh l mi mj"># Evaluating the model using MSE Evaluation Metric<br/>print(mean_squared_error(y_test, predictions))<br/>print(own_mean_squared_error(y_test, predictions))</span></pre><h1 id="3e9e" class="le jr hi bd js lf lg lh jw li lj lk ka ll lm ln kd lo lp lq kg lr ls lt kj lu bi translated">均方根误差(RMSE)</h1><p id="c2cb" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated"><strong class="ih hj">均方根误差</strong>与均方误差相同，但在评估模型时考虑了MSE的根。RMSE对虚假数据(即异常值)的存在更为敏感。当存在较大误差时，RMSE最有用，这些误差会显著影响模型性能。从那以后，RMSE对较大的误差赋予较高的权重。</p><p id="4070" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RMSE是评估模型的常用评估指标。与MSE不同，均方根误差在纵轴或y轴上绘制了相同的数量单位。因为MSE值的平方根在RMSE。</p><p id="ac92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看均方根误差的公式:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mm"><img src="../Images/fe0d90e6da0357b15fe6d9d2616141e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*st1zZN7rHX8KYy_BZWYETg.png"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">均方根误差公式</figcaption></figure><p id="03a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">没有可用于计算均方根误差的内置函数。让我们通过定义自己的函数来研究均方根误差的实现部分。设X_train，y_train为训练数据，X_test，y_test为评估我们模型的测试数据。</p><pre class="jf jg jh ji fd mb mc md me aw mf bi"><span id="7929" class="jq jr hi mc b fi mg mh l mi mj"># Importing all necessary libraries<br/>import numpy as np<br/>from sklearn.ensemble import RandomForestRegressor<br/>from sklearn.metrics import mean_squared_error</span><span id="44dd" class="jq jr hi mc b fi mk mh l mi mj"># Defining RMSE function<br/>def root_mean_squared_error(actual, predictions):<br/>    return np.sqrt(mean_squared_error(actual, predictions))</span><span id="a578" class="jq jr hi mc b fi mk mh l mi mj"># Initializing the model and fitting the model with train data<br/>model = RandomForestRegressor(<br/>               n_estimators = 100,<br/>               criterion = 'mse'<br/>        )<br/>model.fit(X_train,y_train)</span><span id="ff0d" class="jq jr hi mc b fi mk mh l mi mj"># Generating predictions over test data<br/>predictions = model.predict(X_test)</span><span id="7dee" class="jq jr hi mc b fi mk mh l mi mj"># Evaluating the model using RMSE Evaluation Metric<br/>print(root_mean_squared_error(y_test, predictions))</span></pre><p id="2097" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注:</strong>对于sklearn版本≥ 0.22.0，sklearn.metrics有一个平方为kwarg的mean_squared_error函数(默认值为True)。将平方值设置为False将返回RMSE值。</p><pre class="jf jg jh ji fd mb mc md me aw mf bi"><span id="d127" class="jq jr hi mc b fi mg mh l mi mj"># For sklearn versions &gt;= 0.22.0<br/>print(mean_squared_error(y_test, predictions, squared = False))</span></pre><h1 id="3f6c" class="le jr hi bd js lf lg lh jw li lj lk ka ll lm ln kd lo lp lq kg lr ls lt kj lu bi translated">r分数</h1><p id="ed71" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">r得分也称为决定系数，用于衡量模型与给定数据集的拟合程度。它表示预测值与实际值的接近程度。</p><p id="fbbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看这个公式，以便更好地理解:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mn"><img src="../Images/5e4618164308791b0faffe3891b56031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JwEiZQSkL4I710994WaY4w.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">r公式</figcaption></figure><p id="bfe0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们分解这个公式，看看每一项:</p><p id="48b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SSᵣₑₛ =残差平方和</p><p id="8f27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SSₜₒₜ =总平方和</p><p id="1de8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">R值的范围从-∞到1。R值为负的模型表示最佳拟合线的表现比平均拟合线差。</p><p id="bc42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看R评估指标的实现:</p><pre class="jf jg jh ji fd mb mc md me aw mf bi"><span id="0497" class="jq jr hi mc b fi mg mh l mi mj"># Importing all necessary libraries<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import r2_score</span><span id="e98d" class="jq jr hi mc b fi mk mh l mi mj"># Initializing the model and fitting the model with train data<br/>model = LinearRegression()<br/>model.fit(X_train,y_train)</span><span id="4c43" class="jq jr hi mc b fi mk mh l mi mj"># Generating predictions over test data<br/>predictions = model.predict(X_test)</span><span id="76ee" class="jq jr hi mc b fi mk mh l mi mj"># Evaluating the model using R² Evaluation Metric<br/>print(r2_score(y_test, predictions))</span></pre><p id="6f3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">R指标的主要缺点是，随着模型输入特征数量的增加，R值也会增加，而与增加的特征相对于输出变量的重要性无关。即，即使添加的特征与输出变量没有相关性，R值也会增加。</em></p><h1 id="bd2a" class="le jr hi bd js lf lg lh jw li lj lk ka ll lm ln kd lo lp lq kg lr ls lt kj lu bi translated">调整后的R分数</h1><p id="6dce" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq kn is it iu ko iw ix iy kp ja jb jc hb bi translated">调整后的R是R的修改形式，其惩罚新的独立变量或预测值的增加，并且仅在新的独立变量或预测值增强模型性能时增加。</p><p id="776d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看调整后的R的公式:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mo"><img src="../Images/9e25f1114433be6c851205ed1aed71e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*Cedh3rw7NzaHJDEdpullSg.png"/></div><figcaption class="lx ly et er es lz ma bd b be z dx translated">调整后的R公式</figcaption></figure><p id="1127" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们分解这个公式，看看它的每一项:</p><p id="cd03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">R:这是R分数</p><p id="07bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">n:数据集中的样本数量</p><p id="bd24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">k:预测值的数量</p><p id="7024" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">没有仅计算调整后R的内置函数。让我们来看看调整后R的实现部分:</p><pre class="jf jg jh ji fd mb mc md me aw mf bi"><span id="8b53" class="jq jr hi mc b fi mg mh l mi mj"># Importing all necessary libraries<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import r2_score</span><span id="c1a3" class="jq jr hi mc b fi mk mh l mi mj"># Defining the adjusted R² function<br/>def adjusted_r2_score(actual, predictions, num_pred, num_samples):<br/>    n = num_samples<br/>    k = num_pred<br/>    r2 = r2_score(actual, predictions)<br/>    adjusted_r2 = 1 - ((1-r2) * ((n-1)/(n-k-1)))<br/>    return adjusted_r2</span><span id="74a5" class="jq jr hi mc b fi mk mh l mi mj"># Initializing the model and fitting the model with train data<br/>model = LinearRegression()<br/>model.fit(X_train,y_train)</span><span id="00ad" class="jq jr hi mc b fi mk mh l mi mj"># Generating predictions over test data<br/>predictions = model.predict(X_test)</span><span id="f926" class="jq jr hi mc b fi mk mh l mi mj"># Evaluating the model using Adjusted R² Evaluation Metric<br/>num_samples = X_test.shape[0]<br/>num_predictors = X_test.shape[1]<br/>adjusted_r2_score(y_test, predictions, num_predictors, num_samples)</span></pre><p id="2dd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注:</strong>调整后的R将始终小于或等于R得分。</p><p id="c3ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述评估指标是评估回归算法最常用的5种评估指标。</p><blockquote class="mp mq mr"><p id="c9bc" class="if ig jd ih b ii ij ik il im in io ip ms ir is it mt iv iw ix mu iz ja jb jc hb bi translated">如果你喜欢这篇文章，请跟我来。如果您发现公式、代码或内容中有任何错误，请告诉我。</p><p id="f88b" class="if ig jd ih b ii ij ik il im in io ip ms ir is it mt iv iw ix mu iz ja jb jc hb bi translated">你可以在<a class="ae lv" href="https://www.linkedin.com/in/venugopalkadamba" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae lv" href="https://github.com/venugopalkadamba" rel="noopener ugc nofollow" target="_blank"> GitHub </a>找到我</p></blockquote><div class="mv mw ez fb mx my"><a href="https://github.com/venugopalkadamba" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hj fi z dy nd ea eb ne ed ef hh bi translated">韦努·戈帕尔·卡丹巴</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">学生👨‍🎓和Python程序员。venugopalkadamba有22个可用的存储库。在GitHub上关注他们的代码。</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">github.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm jo my"/></div></div></a></div><div class="mv mw ez fb mx my"><a href="https://www.linkedin.com/in/venugopalkadamba" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hj fi z dy nd ea eb ne ed ef hh bi translated">韦努·戈帕尔·卡丹巴</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">在世界上最大的职业社区LinkedIn上查看Venu Gopal Kadamba的个人资料。</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">www.linkedin.com</p></div></div><div class="nh l"><div class="nn l nj nk nl nh nm jo my"/></div></div></a></div><h1 id="43d4" class="le jr hi bd js lf lg lh jw li lj lk ka ll lm ln kd lo lp lq kg lr ls lt kj lu bi translated">谢谢大家！</h1></div></div>    
</body>
</html>