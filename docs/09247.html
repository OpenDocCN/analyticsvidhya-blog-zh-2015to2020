<html>
<head>
<title>Build face movement detection with Machine Learning using ML Kit Firebase</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用ML Kit Firebase通过机器学习构建人脸运动检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/build-face-movement-detection-with-machine-learning-using-ml-kit-firebase-a4f1ea69ae04?source=collection_archive---------4-----------------------#2020-08-30">https://medium.com/analytics-vidhya/build-face-movement-detection-with-machine-learning-using-ml-kit-firebase-a4f1ea69ae04?source=collection_archive---------4-----------------------#2020-08-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/37692842996b9bae4f94915569fbc57a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YjHtJcQ6rdVFlpo6SH3CQw.png"/></div></div></figure><p id="937c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ML Kit firebase是firebase magic之一，可以在您的移动应用程序中进行机器学习，通过导入Firebase为我们准备的库和AI模型，您可以轻松实现机器学习功能，现在有一些模型可供我们使用，您可以在Firebase控制台中查看所有可用的模型，如下所示。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jo"><img src="../Images/17678ea1a0dadc1067b914dad0b6604f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mjVfbFTk9vW5Fy3q9sezkg.png"/></div></div></figure><p id="61c0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了表示这种面部运动检测的用例，我们将使用一个名为<strong class="is hj">活跃度检测的用例，</strong>它是一个功能特性，用于检测和验证用户是否真的是真实用户，为了验证它，有一些方法可以这样做:</p><ol class=""><li id="d92b" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn jy jz ka kb bi translated">将捕获的视频上传到服务器</li><li id="9c9d" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn jy jz ka kb bi translated">用户和管理员之间的视频通话</li><li id="659e" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn jy jz ka kb bi translated">使用人工智能来验证和自动化活性检测</li></ol><p id="0e9f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以为了解决这个问题，在这里我们将使用来自Firebase的ML工具包。</p><h1 id="d37f" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">我们将使用的技术</h1><blockquote class="lf lg lh"><p id="9c13" class="iq ir li is b it iu iv iw ix iy iz ja lj jc jd je lk jg jh ji ll jk jl jm jn hb bi translated">ML Vision—Firebase的ML套件</p></blockquote><h1 id="8fd4" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">我们将使用的人工智能模型</h1><blockquote class="lf lg lh"><p id="7086" class="iq ir li is b it iu iv iw ix iy iz ja lj jc jd je lk jg jh ji ll jk jl jm jn hb bi translated">ML视觉—人脸模型</p></blockquote><h1 id="9bf2" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">Firebase设置</h1><p id="f39a" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">为了得到这些人工智能模型中的一个，我们需要在https://firebase.google.com/<a class="ae lr" href="https://firebase.google.com/" rel="noopener ugc nofollow" target="_blank">创建一个Firebase项目。<br/>登录后，您需要创建一个Firebase项目，如下所示。</a></p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/136d2dd6c7257d9a3eb499002ce9b611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JyH5PqXAHfNf3hP5Td3IKQ.png"/></div></div></figure><p id="3e74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，单击左边的机器学习部分，因为我们将在这里进行活性检测，所以我们将使用一个名为<strong class="is hj">人脸检测</strong>的模型。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/206e09f1b474862bc27fe64884cfb8fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h7NSJRXu1aitxHh8oKt77w.png"/></div></div></figure><p id="862f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦我们选择了模型，填充一些关于我们项目的信息并下载我们的<strong class="is hj"> google-services.json </strong>。我们可以跳转到Android Studio来构建我们的应用程序。</p><p id="d98f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以在继续之前，我们先来了解一下MLKit Firebase的基础知识——人脸检测。</p><h1 id="5042" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">基础知识</h1><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/5411b799ee8357334d30ac1a7731eeac.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*oHB_oSAfxi8R09BB9_CU2A.png"/></div></figure><ol class=""><li id="989c" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn jy jz ka kb bi translated">将SDK <br/> Import MLKit依赖项集成到项目中</li><li id="8cad" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn jy jz ka kb bi translated">提供输入数据<br/>输入数据将是从摄像机拍摄的图像帧，并在设备中本地独立处理。(设备上处理)</li><li id="c30c" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn jy jz ka kb bi translated">将ML应用于数据<br/>从设备摄像头拍摄的数据将由AI机器学习模型进行处理，该模型在我们构建应用时已经嵌入到应用中。</li></ol><p id="e328" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此MLKit(机器学习套件)中还有一些其他功能，包括:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/d885a9372bdfeeab2dbd1da331d0838b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8yOZzc69DxfxINeG0QiVlA.png"/></div></div></figure><p id="f009" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们可以看到的，我们现在将用于活体检测的<strong class="is hj">人脸检测</strong>是一个<strong class="is hj">设备上的</strong>功能，这意味着一切都将在用户的设备内处理。</p><h1 id="da6e" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">面向方向</h1><p id="3207" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">以下术语描述了面相对于相机的角度:</p><ul class=""><li id="4173" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated"><strong class="is hj">欧拉X </strong>:欧拉X角为正的面朝上。</li><li id="86f7" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated"><strong class="is hj">欧拉Y </strong>:欧拉Y角为正的脸看向镜头右边，为负的脸看向左边。</li><li id="6efb" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated"><strong class="is hj">欧拉Z </strong>:欧拉Z角为正的面相对于相机逆时针旋转。</li></ul><p id="8c26" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在以下情况下，ML套件不会报告检测到的面的欧拉X、欧拉Y或欧拉Z角度:</p><blockquote class="lf lg lh"><p id="bfd5" class="iq ir li is b it iu iv iw ix iy iz ja lj jc jd je lk jg jh ji ll jk jl jm jn hb bi translated">地标_模式_无</p><p id="805f" class="iq ir li is b it iu iv iw ix iy iz ja lj jc jd je lk jg jh ji ll jk jl jm jn hb bi translated">轮廓_模式_全部</p><p id="55f5" class="iq ir li is b it iu iv iw ix iy iz ja lj jc jd je lk jg jh ji ll jk jl jm jn hb bi translated">分类_模式_无</p><p id="77b9" class="iq ir li is b it iu iv iw ix iy iz ja lj jc jd je lk jg jh ji ll jk jl jm jn hb bi translated">性能模式快速</p></blockquote><p id="04d1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">被设置在一起。</p><p id="97ff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，让我们开始Android Studio，所以在继续之前，请确保您已经创建了您的Android Studio项目，并将您的<strong class="is hj"> google-services.json </strong>放在项目的根目录中。</p><h1 id="8ba3" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">预设置</h1><p id="85a6" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">MLKit要求minSdk 16，适用于:</p><ul class=""><li id="bf08" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated">ML试剂盒普通版本19.0.0</li><li id="c7e6" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">ML套件视觉版本20.0.0</li><li id="7682" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">ML套件对象检测和跟踪模型版本16.0.0</li><li id="04e1" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">ML工具包自然语言版本19.0.0</li><li id="a0f9" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">ML试剂盒语言识别模型版本19.0.0</li><li id="d3b1" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">ML套件智能回复模型版本19.0.0</li><li id="c679" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">ML套件翻译模型版本19.0.0</li><li id="a16d" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">ML套件模型解释器版本19.0.0</li><li id="2209" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">ML套件Vision AutoML版本16.0.0</li></ul><p id="b466" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，将MLKit库导入到项目中，并添加一个人脸模型作为从属模型。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/55f686fe46748baf555a34bebd7a6e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YT_93aNX_8l8GAbwppdbJA.png"/></div></div></figure><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/be117fd9337ba96502e2dc74452b848c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jWQ7aQ7VmzaNEI2UOpFUPg.png"/></div></div></figure><h1 id="c47c" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">1.配置面部检测器</h1><p id="5dca" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">在将人脸检测应用于图像或扫描仪之前，如果我们想要更改人脸检测器的任何默认设置，请使用firebasevisionfaceteditoroptions对象指定这些设置。我们可以通过以下设置进行更改:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/c2e738d4a5c337f76343f1463d7eda0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_YuzMv4u_pUjGR16olTpIA.png"/></div></div></figure><p id="66c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，在这里我们将配置如下:</p><ul class=""><li id="a60a" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated"><strong class="is hj">性能模式</strong>变得<strong class="is hj">快</strong> <br/>我们使用性能模式变得<strong class="is hj">快</strong>而不是<strong class="is hj">准</strong>因为用户的设备并不是真正的高端设备，所以处理和运行AI模型的能力并不是真的很好或足够快。</li><li id="9aa8" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated"><strong class="is hj">地标模式</strong>为<strong class="is hj">所有地标</strong> <br/>使用此选项，我们将获得人工智能模型检测到的人脸上的所有地标，如鼻子、右耳、左耳等。</li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/4ef91fd8031e1ffc0599f737154c491a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oWJ9-lPSQLDoDkH-XCahiA.png"/></div></div></figure><h1 id="71ee" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">2.准备数据源</h1><p id="fd4e" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">为了检测图像中的人脸，我们可以从图像、视频或实时相机渲染中创建一个InputImage对象。然后，将InputImage对象传递给FaceDetector的process方法。</p><ul class=""><li id="7b50" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated"><strong class="is hj">基于捕获图像的输入图像</strong></li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/4d7b3d3b5694c3ab5edae8e717dcfad6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FtIpzgmfyhuxGFagqK-9nA.png"/></div></div></figure><p id="97ea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">位图对象是从相机意图中获取并创建的，所述对象将被传递给人脸检测函数以进行进一步处理。</p><ul class=""><li id="be0b" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated"><strong class="is hj">基于实时渲染输入视频</strong></li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/0c2dad0693e8ff97418ff7d214c31da8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qGrkoCfJKbdLK6ATpnNzrA.png"/></div></div></figure><p id="51d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们不是创建一个Image对象，而是创建一个FaceDetectionProcessor对象来附加到一个摄像机源。这样，我们将能够立即处理渲染数据，并近乎实时地检测所述对象的活性(性能取决于所用设备的规格)。</p><h1 id="4885" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">3.从FaceDetector实例启动检测器</h1><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/2489adcb47d549403a5172a76caa43f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_mKvEwrILn7c7S6B6M3InA.png"/></div></div></figure><p id="fd0e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">检测器用于启动任何检测，我们将从Firebase Vision实例中获得这些检测。</p><h1 id="69b7" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">4.处理数据源</h1><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/aeb73084a4cdcc77e390a608cbe6983c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xjQp3lHyFSr4YLdFOTGoSQ.png"/></div></div></figure><p id="3b95" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在检测器启动后，接下来我们将把图像传递给检测图像函数，以便所述检测器能够从传递的图像中提取FireBaseVisionFaces对象。处理本身将由FireBase库处理，并自动将其输出传递给监听器函数。</p><h1 id="3fa1" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">5.从检测结果中获取信息</h1><p id="113d" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">一旦我们从MLKit的嵌入式AI模型中获得检测结果，监听器将被FirebaseVisionFaces的对象触发，其中将包含每个已检测到的人脸的检测结果，因为现在原型只能正常工作，如果检测到2个以上的人脸，将会有一些不期望的结果。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/0ad18171f53a0dbba880538bc3b60c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r1EDEWfXzaYJQExTk95E4g.png"/></div></div></figure><p id="ba99" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当在传递的图像中检测到FireBaseVisionFaces对象时，addOnSuccessListener将在其参数内运行lambda函数。在这种情况下，提取的人脸对象将被传递给FaceDetection对象，以进行进一步处理。例如，这里的face对象将被传递给isLookingRightSide函数。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/db40d0e08ed26eb8c618e3cb16eb9649.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uCYNwEomQq-rmdfgPrWGow.png"/></div></div></figure><p id="7f27" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在将FireBaseVisionFaces对象传递给isLookingRightSide函数后，该函数将提取在配置步骤中已配置的地标的位置。</p><p id="c720" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们将提取面部中间到右侧的标志。那就是:</p><ul class=""><li id="a35c" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated">右脸颊</li><li id="49cb" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">向右张嘴</li><li id="350a" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">鼻基</li><li id="0827" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn lw jz ka kb bi translated">嘴底部</li></ul><p id="45c6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些职位将被进一步处理，所以我们可以根据我们的需要来计算它。</p><h1 id="358c" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">6.根据需要用我们的计算处理信息</h1><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/b42d492c725a9e9cb5a86e9bf146fe24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2rN7lz9MnA4qCm_YLE0TJQ.png"/></div></div></figure><p id="e7d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从提取的位置，我们可以使用isNearby和isHigher函数计算2个点的差异，以确定两点之间的“接近度”或Y位置比较。这些函数将被用作对结果进行分类的参数。</p><h1 id="1064" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">7.根据需要对过程结果进行分类</h1><p id="3f74" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">计算后，结果将被归入4个不同的分类，即:</p><ul class=""><li id="f20b" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated">抬头看；查阅</li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/d29a49a0d5b127a7634b86da10e5df32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tq5Oe-vjxbOBexO2BIE_YQ.png"/></div></div></figure><ul class=""><li id="1739" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated">向下看</li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/a6d833afe4b6f30e75645ebf3f94e582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WSi-UfpKlIJ2xoBTnGHEww.png"/></div></div></figure><ul class=""><li id="ce22" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated">向左看</li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/2ace99042aa9de1a916d593d91d90bb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ekew18eUbAFspancCc9UaA.png"/></div></div></figure><ul class=""><li id="687d" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn lw jz ka kb bi translated">向右看</li></ul><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/2873d960558c2738b8bc3966cc74d2ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M8foYPMi16w_tcUaoBtTNw.png"/></div></div></figure><p id="dc98" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在isLookingRight功能的情况下，当<strong class="is hj">右脸颊位置</strong>接近<strong class="is hj">鼻梁位置</strong>并且<strong class="is hj">嘴部右位置</strong>接近<strong class="is hj">嘴部下位置</strong>时，所述面部将被分类为向右看，这同样适用于另一种检测，因此基本上每次检测我们将基于AI模型实时给出的数据使用不同的算法和数学计算。</p><p id="5147" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">误差容限</strong></p><p id="d570" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种计算也取决于在某些函数中应用的<strong class="is hj">误差容限</strong>，这个<strong class="is hj">误差容限</strong>是一个特定检测被视为有效检测的值范围，<strong class="is hj">误差容限</strong>越大，检测的准确性就越低，因此给出一个适当且平衡的<strong class="is hj">误差容限</strong>值是非常重要和关键的，但是这个<strong class="is hj">误差容限</strong>从何而来呢？该值来自于我们开发函数时的值测试，并猜测特定检测的<strong class="is hj">误差容差</strong>的理想值。</p><p id="46f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，一旦一切都设置妥当，瞧，这就是结果！</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/56a8bbf206fa9ebb64d7e937b03016ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*4qnu0lpDjT-zgU7ztJg4hg.gif"/></div></figure><p id="309c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">希望有帮助！如果你们有任何问题，请随时问我，如果你们喜欢，不要忘记给一些掌声！:D</p></div></div>    
</body>
</html>