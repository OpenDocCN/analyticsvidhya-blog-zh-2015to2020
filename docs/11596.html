<html>
<head>
<title>Autonomous Vehicle Object Detector with YOLOv4 and Darknet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有YOLOv4和Darknet的自主车辆物体检测器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/autonomous-vehicle-object-detector-with-yolov4-and-darknet-277c645b70c1?source=collection_archive---------5-----------------------#2020-12-10">https://medium.com/analytics-vidhya/autonomous-vehicle-object-detector-with-yolov4-and-darknet-277c645b70c1?source=collection_archive---------5-----------------------#2020-12-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii"><div class="bz dy l di"><div class="ij ik l"/></div><figcaption class="il im et er es in io bd b be z dx translated">以防你更喜欢看视觉效果…</figcaption></figure><p id="d8b6" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">随着自动驾驶汽车在过去几年中的兴起，我想探索一个对于创建良好的自动驾驶汽车系统来说很有必要的方面，即物体检测。那到底是什么呢？形容它的最佳方式是“汽车的眼睛”。正如你在下面看到的，车辆的摄像头正在向自主系统反馈它看到的物体。在这种情况下，它是一个人，宠物和其他车辆。自治系统然后使用该信息来做出左转、直行等决定。让我们看看是否可以使用Darknet和YOLOv4复制这个对象检测器，以检测交通标志、交通灯和其他车辆。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es jn"><img src="../Images/831d3909d8c9e5a36a4fd1e1141620f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*dQZ2skdOOhlJrbNY.gif"/></div></figure><h1 id="f126" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">过程</h1><p id="4867" class="pw-post-body-paragraph ip iq hi ir b is ks iu iv iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm hb bi translated">首先，我想了解如何着手这个项目。人工智能专家向我推荐了一个开源的Google Colab笔记本，并用它来帮助我开始建模。为了创建这个模型，我将使用Darknet开源神经网络和YOLO物体探测器。为了解释YOLO的力量，让我们首先把它与利用滑动窗口的传统物体跟踪器进行比较。</p><h1 id="6008" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">传统目标检测</h1><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es kx"><img src="../Images/14d1a7d06f72cffb14baae044dff1911.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/0*DXTDTU0mw5_DKlcq.gif"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:https://towardsdatascience . com/how-do-自驾汽车-see-13054aee2503</figcaption></figure><p id="4b4d" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">正如您所观察到的，窗口遍历图像的每个部分，直到它检测到实际的对象，在本例中是汽车。有两个框:一个是地面真实框，在建模之前手动放置在图片中，另一个是预测框，即模型预测对象的位置。这两个框用于计算并集的交集(IoU ),该交集用于计算平均精度(mAP ),这是我们将在本文后面触及的内容。总的来说，这个过程是非常计算机密集型的，并且对于对象检测来说是低效的。就自动驾驶汽车而言，你不会希望你的汽车在15秒钟后没有识别出“停车标志”，然后突然停下来。它必须是即时的。</p><h1 id="e7c8" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">YOLO</h1><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es ky"><img src="../Images/28c80b997ebeb22a8a62849350528885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/0*uu9FYYf54gHQo35k.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:<a class="ae kz" href="https://towardsdatascience.com/how-do-self-driving-cars-see-13054aee2503" rel="noopener" target="_blank">https://towards data science . com/how-do-self-driving-cars-see-13054 aee 2503</a></figcaption></figure><p id="c1df" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">现在介绍你只看一次或简称YOLO。约瑟夫·雷德蒙是一名计算机奇才，他在2015年创造了YOLO，他还维护着暗网神经网络(<em class="la">查看他的ted演讲</em> <a class="ae kz" href="https://www.youtube.com/watch?v=XS2UWYuh5u0" rel="noopener ugc nofollow" target="_blank"> <em class="la">这里</em> </a>)。在YOLO发生的与上述不同的是这三个步骤:网格分割、分类和图像定位。在这种方法中，模型需要检查一次图像/视频帧。网格分割将图像分割成大小均匀的网格块，因此图像的每个部分都被考虑在内。然后，模型将识别图像的不同类别，在这种情况下，是狗、自行车和卡车。最后，如上所述，使用边界框来定位对象，边界框定位对象在图像中的位置，因此称为图像定位。将所有这些放在一起，您的模型已经成功地识别了一只狗、一辆自行车和一辆卡车，以及它们在图像中的位置。</p><h1 id="cf0d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">图像收集和预先训练的权重</h1><p id="783c" class="pw-post-body-paragraph ip iq hi ir b is ks iu iv iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm hb bi translated">在我们开始构建模型之前，我们需要收集一些图像。我从Google Open Images收集了我所有的汽车、交通灯、交通标志和停车标志的图像。在创建模型之前，我下载了YOLOv4预训练权重，这些权重是在微软的80个类的COCO数据集上训练的。在这80节课中，你会看到汽车、交通灯和停车标志。所以利用它来增加地图(平均精度)是明智的。不幸的是，交通标志没有预先训练的权重，因此预测其地图得分将低于其他得分。</p><h1 id="fd2e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">模型创建和测试</h1><p id="3675" class="pw-post-body-paragraph ip iq hi ir b is ks iu iv iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm hb bi translated">现在模型创建好了，我用它运行我的视频，瞧！</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es jn"><img src="../Images/8dd26de27279caa19e4841588fb16534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*Tq45eGUpGtkdwWOH.gif"/></div></figure><p id="d79d" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">如你所见，它能识别所有的交通灯、汽车，最重要的是交通标志！很好，模型的第一次迭代！</p><h1 id="10cb" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">结果:平均准确度精密度</h1><p id="d9be" class="pw-post-body-paragraph ip iq hi ir b is ks iu iv iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm hb bi translated">如果您还记得上文，我提到过并集的交集(IoU)以及它将如何影响我们的平均精度(mAP)。要再次分解借据，请观察下面这只可爱小猫的照片。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es lb"><img src="../Images/c98ca33165175d3c2da1cbac6940060b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/0*Zt9kI02YM_sGtZa7.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:<a class="ae kz" href="https://blog.paperspace.com/mean-average-precision/" rel="noopener ugc nofollow" target="_blank">https://blog.paperspace.com/mean-average-precision/</a></figcaption></figure><p id="e67f" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">正如你所观察到的，有一个真实边界框和预测框。在构建模型之前，手动绘制地面真实边界框，以准确指示对象在图片中的位置。预测框是决定它“认为”对象在哪里的模型。两个边界框之间的交集越大，平均精度(AP)分数就越大。为每个图像中的每个对象类计算AP，然后对所有分数进行平均以确定贴图分数，这最终决定了模型的表现。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es lc"><img src="../Images/ea9a7c82398036e86b5b76417d5e359a.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/0*vsdWis9O_51rtGSp.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:https://blog.paperspace.com/mean-average-precision/</figcaption></figure><p id="fbd7" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">请参见下文，获得更直观的展示。正如你所看到的黄色框,“预测框”与地面实况框有90%的重叠。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es ld"><img src="../Images/9501d3024eb3595cec3fee79e37f808b.png" data-original-src="https://miro.medium.com/v2/resize:fit:210/format:webp/0*OtMys5tghl9BPYLT.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:https://blog.paperspace.com/mean-average-precision/<a class="ae kz" href="https://blog.paperspace.com/mean-average-precision/" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="a9f0" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">最后，请参见下面模型的单个类别映射和整体映射。</p><ul class=""><li id="f4f1" class="le lf hi ir b is it iw ix ja lg je lh ji li jm lj lk ll lm bi translated">汽车:80.70%</li><li id="ddf7" class="le lf hi ir b is ln iw lo ja lp je lq ji lr jm lj lk ll lm bi translated">停车标志:98.20%</li><li id="c2d4" class="le lf hi ir b is ln iw lo ja lp je lq ji lr jm lj lk ll lm bi translated">交通灯:75.06%</li><li id="31b5" class="le lf hi ir b is ln iw lo ja lp je lq ji lr jm lj lk ll lm bi translated">交通标志:42.49%</li><li id="b18c" class="le lf hi ir b is ln iw lo ja lp je lq ji lr jm lj lk ll lm bi translated">整体地图:74.11%</li></ul><p id="b8b5" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated">正如所料，交通标志具有最低的地图，因为它没有任何预先训练的权重来训练。我希望在未来的迭代中提高这个分数，因为没有人想进入一辆自动驾驶汽车，它只能每两次预测一次它是否是交通标志。不过整体图74.11%，目前还不错。</p><h1 id="0c43" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">未来的工作</h1><p id="5303" class="pw-post-body-paragraph ip iq hi ir b is ks iu iv iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm hb bi translated">理想情况下，我希望将这种模式作为dashcam应用程序部署在移动应用程序上。有一个我用Android Studio从这个<a class="ae kz" href="https://github.com/hunglc007/tensorflow-yolov4-tflite" rel="noopener ugc nofollow" target="_blank">开源回购</a>部署的Android文件夹。它与YOLOv4预训练的重量一起部署，如下所示，它可以实时检测汽车，卡车和交通灯。我将应用程序的名称定制为“DashKam ”,并更改了布局，除此之外，所有代码都保持不变。理想情况下，我想用TensorFlow Lite格式的我自己的YOLOv4定制模型部署这个移动应用程序。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es jn"><img src="../Images/4b1161240ea5c449d2abd60f3afb672b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*DiGbnLfie6H2u4Ju.gif"/></div></div></figure><h1 id="4672" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">道德困境</h1><p id="d3d7" class="pw-post-body-paragraph ip iq hi ir b is ks iu iv iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm hb bi translated">Joseph Redmon创造了YOLO来推动物体探测的发展。有了他的模型，我们能够瞬间探测到物体。然而，一名军事人员找到了他，告诉他他们使用他的模型来跟踪车辆和人员，最终可以导致无人机袭击。Redmon听到这个消息非常震惊，以至于在2020年初，他宣布他将不再从事计算机视觉(物体检测)方面的工作。他创造的东西是如此美丽和宏伟，但它表明，如果它落入坏人之手，可能会导致毁灭性的后果。为此，我坚信我们需要坚持这样一个理念:为了社会，我们数据科学界有责任在工作中遵守道德规范。</p><h1 id="8b89" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">其他工作</h1><p id="96c6" class="pw-post-body-paragraph ip iq hi ir b is ks iu iv iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm hb bi translated">请访问我的网站、Github repository和LinkedIn来查看我的所有项目。让我知道我下一步应该做什么！</p><p id="32ec" class="pw-post-body-paragraph ip iq hi ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm hb bi translated"><a class="ae kz" href="https://ridwanalam.com/" rel="noopener ugc nofollow" target="_blank">RidwanAlam.com</a></p><div class="lw lx ez fb ly lz"><a href="https://github.com/ridwan102" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab dw"><div class="mb ab mc cl cj md"><h2 class="bd hj fi z dy me ea eb mf ed ef hh bi translated">ridwan102 -概述</h2><div class="mg l"><h3 class="bd b fi z dy me ea eb mf ed ef dx translated">钻研软件工程世界，继续推动人类创新北极代码库贡献者…</h3></div><div class="mh l"><p class="bd b fp z dy me ea eb mf ed ef dx translated">github.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn js lz"/></div></div></a></div><div class="lw lx ez fb ly lz"><a href="https://www.linkedin.com/in/ridwanalam/" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab dw"><div class="mb ab mc cl cj md"><h2 class="bd hj fi z dy me ea eb mf ed ef hh bi translated">Ridwan Alam -数据科学家- Metis | LinkedIn</h2><div class="mg l"><h3 class="bd b fi z dy me ea eb mf ed ef dx translated">顶尖技能:Python，回归建模，分类，无监督学习，主题建模，情感分析…</h3></div><div class="mh l"><p class="bd b fp z dy me ea eb mf ed ef dx translated">www.linkedin.co</p></div></div><div class="mi l"><div class="mo l mk ml mm mi mn js lz"/></div></div></a></div><h1 id="dcff" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">特别感谢</h1><ul class=""><li id="5a84" class="le lf hi ir b is ks iw kt ja mp je mq ji mr jm lj lk ll lm bi translated"><a class="ae kz" href="https://github.com/theAIGuysCode/YOLOv4-Cloud-Tutorial" rel="noopener ugc nofollow" target="_blank">那个人工智能的家伙</a></li><li id="3d2d" class="le lf hi ir b is ln iw lo ja lp je lq ji lr jm lj lk ll lm bi translated"><a class="ae kz" href="https://github.com/hunglc007/tensorflow-yolov4-tflite" rel="noopener ugc nofollow" target="_blank">饥饿007 </a></li></ul></div></div>    
</body>
</html>