<html>
<head>
<title>Training a Neural Network to identify Pneumonia in X-rays</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练神经网络以识别X射线中的肺炎</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-a-neural-network-to-identify-pneumonia-in-x-rays-e05a27982443?source=collection_archive---------2-----------------------#2020-11-14">https://medium.com/analytics-vidhya/training-a-neural-network-to-identify-pneumonia-in-x-rays-e05a27982443?source=collection_archive---------2-----------------------#2020-11-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class="if ig ez fb ih ii"><a href="https://github.com/roydipta/xray_pneumonia" rel="noopener  ugc nofollow" target="_blank"><div class="ij ab dw"><div class="ik ab il cl cj im"><h2 class="bd hj fi z dy in ea eb io ed ef hh bi translated">罗伊迪普塔/x射线肺炎</h2><div class="ip l"><h3 class="bd b fi z dy in ea eb io ed ef dx translated">熨斗模块3项目迪普塔罗伊和阿维丹伯曼。肺炎是一种感染，会使一个或多个器官的气囊发炎。</h3></div><div class="iq l"><p class="bd b fp z dy in ea eb io ed ef dx translated">github.com</p></div></div><div class="ir l"><div class="is l it iu iv ir iw ix ii"/></div></div></a></div><p id="520e" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">在COVID时代，特别是在疫情的初期，没有广泛的测试来判断一个人是否有病毒。医生能够猜测一个人是否患有COVID的一种方法是通过肺部的x射线，并查看这个人是否有肺炎的迹象。</p><p id="9c28" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">什么是肺炎？</strong></p><p id="5796" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">肺炎是一种感染，使一个或两个肺部的气囊发炎。气囊可能会充满液体或脓，这可能会导致咳嗽、发烧、发冷和呼吸困难。包括细菌、病毒和真菌在内的有机体会导致肺炎。</p><figure class="jx jy jz ka fd kb er es paragraph-image"><div class="er es jw"><img src="../Images/eaa61113db31b2c879f90cffeb44e22e.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*7O9_S7R4XcSC8-MxojYvIQ.png"/></div></figure><p id="5cba" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">潜在肺炎迹象:</strong></p><p id="0ca6" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">下图显示了正常肺和肺炎肺在x线上的区别。通常肺部充满空气，不吸收X射线，所以它看起来是黑色的，这在正常图像中可以看到。骨头吸收x光，呈现白色。液体或组织显示为灰色。</p><figure class="jx jy jz ka fd kb er es paragraph-image"><div class="er es kd"><img src="../Images/1da31f1cab6158ffe284bfd0c5a609bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*umKEOpeQJb6Ss8oHPZm4Fg.png"/></div></figure><p id="b19c" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">导入库和下载数据:</strong></p><p id="7ebf" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">让我们从kaggle下载数据:<a class="ae ke" href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/paultimothymooney/chest-x-ray-pneumonia</a></p><p id="fb0b" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">然后，我们需要导入项目将使用的所有必要的库！我们将使用keras来完成神经网络的实质性工作。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="8679" class="kk kl hi kg b fi km kn l ko kp"><strong class="kg hj">import</strong> <strong class="kg hj">matplotlib.pyplot</strong> <strong class="kg hj">as</strong> <strong class="kg hj">plt</strong><br/><strong class="kg hj">import</strong> <strong class="kg hj">seaborn</strong> <strong class="kg hj">as</strong> <strong class="kg hj">sns</strong><br/><strong class="kg hj">import</strong> <strong class="kg hj">keras</strong><br/><strong class="kg hj">from</strong> <strong class="kg hj">keras.models</strong> <strong class="kg hj">import</strong> Sequential<br/><strong class="kg hj">from</strong> <strong class="kg hj">keras.layers</strong> <strong class="kg hj">import</strong> Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization<br/><strong class="kg hj">from</strong> <strong class="kg hj">keras.preprocessing.image</strong> <strong class="kg hj">import</strong> ImageDataGenerator<br/><strong class="kg hj">from</strong> <strong class="kg hj">sklearn.model_selection</strong> <strong class="kg hj">import</strong> train_test_split<br/><strong class="kg hj">from</strong> <strong class="kg hj">sklearn.metrics</strong> <strong class="kg hj">import</strong> classification_report,confusion_matrix<br/><strong class="kg hj">from</strong> <strong class="kg hj">keras.callbacks</strong> <strong class="kg hj">import</strong> ReduceLROnPlateau<br/><strong class="kg hj">import</strong> <strong class="kg hj">os</strong><br/><strong class="kg hj">import</strong> <strong class="kg hj">numpy</strong> <strong class="kg hj">as</strong> <strong class="kg hj">np</strong> <em class="kq"># linear algebra</em><br/><strong class="kg hj">import</strong> <strong class="kg hj">pandas</strong> <strong class="kg hj">as</strong> <strong class="kg hj">pd</strong> <em class="kq"># data processing, CSV file I/O (e.g. pd.read_csv)</em><br/><strong class="kg hj">import</strong> <strong class="kg hj">cv2</strong></span></pre><p id="c389" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">对于这个项目，我使用谷歌collab，因为它有更快的训练时间。与我电脑上每个纪元2分钟相比，collab可以做到每个纪元12秒。</p><p id="aebf" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">因此，我们需要创建一个助手函数来实际获取数据。为此，我们将使用CV2。我们还会把图像放大到150 x 150。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="6727" class="kk kl hi kg b fi km kn l ko kp">labels = ['PNEUMONIA', 'NORMAL']<br/>img_size = 150<br/><strong class="kg hj">def</strong> get_data(data_dir):<br/>    data = [] <br/>    <strong class="kg hj">for</strong> label <strong class="kg hj">in</strong> labels: <br/>        path = os.path.join(data_dir, label)<br/>        class_num = labels.index(label)<br/>        <strong class="kg hj">for</strong> img <strong class="kg hj">in</strong> os.listdir(path):<br/>            <strong class="kg hj">try</strong>:<br/>                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)<br/>                resized_arr = cv2.resize(img_arr, (img_size, img_size)) <em class="kq"># Reshaping images to preferred size</em><br/>                data.append([resized_arr, class_num])<br/>            <strong class="kg hj">except</strong> <strong class="kg hj">Exception</strong> <strong class="kg hj">as</strong> e:<br/>                print(e)<br/>    <strong class="kg hj">return</strong> np.array(data)</span><span id="e7dc" class="kk kl hi kg b fi kr kn l ko kp">train = get_data('/content/drive/My Drive/chest_xray/train')<br/>test = get_data('/content/drive/My Drive/chest_xray/test')<br/>val = get_data('/content/drive/My Drive/chest_xray/val')</span></pre><p id="12e2" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated"><strong class="ja hj">准备数据:</strong></p><p id="f7f2" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">在图像分类中，我们将图像放入一组数字中。这些数字代表像素强度，它是一个介于0和255之间的数字，255表示白色，0表示黑色。</p><p id="9527" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">在我们实际准备数据之前，有几个关键点:</p><ul class=""><li id="0e33" class="ks kt hi ja b jb jc jf jg jj ku jn kv jr kw jv kx ky kz la bi translated">我们需要将图像的数组与它们的标签配对(不管是不是肺炎)</li><li id="ef61" class="ks kt hi ja b jb lb jf lc jj ld jn le jr lf jv kx ky kz la bi translated">在神经网络中，后端会发生大量的数学运算。如果我们使用像255这样的数字，计算机将被迫处理非常大的数字，这可能会增加计算能力，同时也会减慢运算时间。为了纠正这一点，我们可以将每个像素除以255，这样我们就得到0和1之间的数字，1是白色，0是黑色。</li><li id="6826" class="ks kt hi ja b jb lb jf lc jj ld jn le jr lf jv kx ky kz la bi translated">最后，当我们将图像输入keras时，我们需要重塑我们的维度。所以我们将使用x _ train . shape(-1，image_size，image_size，1)。这些数字表示[批量大小、高度、宽度、通道]。-1意味着维度中的长度是推断出来的，所以我们不必指定它。1是因为我们使用的是黑白图片，所以我们只有一层图像。</li></ul><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="22c2" class="kk kl hi kg b fi km kn l ko kp">x_train = []<br/>y_train = []<br/><br/>x_val = []<br/>y_val = []<br/><br/>x_test = []<br/>y_test = []<br/><br/><strong class="kg hj">for</strong> feature, label <strong class="kg hj">in</strong> train1:<br/>    x_train.append(feature)<br/>    y_train.append(label)<br/><br/><strong class="kg hj">for</strong> feature, label <strong class="kg hj">in</strong> test:<br/>    x_test.append(feature)<br/>    y_test.append(label)<br/>    <br/><strong class="kg hj">for</strong> feature, label <strong class="kg hj">in</strong> val:<br/>    x_val.append(feature)<br/>    y_val.append(label)</span><span id="3026" class="kk kl hi kg b fi kr kn l ko kp"><em class="kq"># Normalize the data</em><br/>x_train = np.array(x_train) / 255<br/>x_val = np.array(x_val) / 255<br/>x_test = np.array(x_test) / 255</span><span id="1884" class="kk kl hi kg b fi kr kn l ko kp"><em class="kq"># resize data for deep learning </em><br/>x_train = x_train.reshape(-1, img_size, img_size, 1)<br/>y_train = np.array(y_train)<br/><br/>x_val = x_val.reshape(-1, img_size, img_size, 1)<br/>y_val = np.array(y_val)<br/><br/>x_test = x_test.reshape(-1, img_size, img_size, 1)<br/>y_test = np.array(y_test)</span></pre><p id="149f" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">我们也有很大的数据不平衡，所以我们将使用数据增强来解决这个问题。这是什么意思？基本上，我们将采取的图片，我们现在和创造他们的副本做某些改变的图像，可以包括裁剪，旋转，翻转。让我们把它安装到我们的x列车上。请注意，我们不会翻转图像，因为我们如何向计算机显示图像确实很重要，而且右肺总是在左侧。电脑可能会搞混=\</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="e220" class="kk kl hi kg b fi km kn l ko kp">datagen = ImageDataGenerator(<br/>        featurewise_center=<strong class="kg hj">False</strong>,  <em class="kq"># set input mean to 0 over the dataset</em><br/>        samplewise_center=<strong class="kg hj">False</strong>,  <em class="kq"># set each sample mean to 0</em><br/>        featurewise_std_normalization=<strong class="kg hj">False</strong>,  <em class="kq"># divide inputs by std of the dataset</em><br/>        samplewise_std_normalization=<strong class="kg hj">False</strong>,  <em class="kq"># divide each input by its std</em><br/>        zca_whitening=<strong class="kg hj">False</strong>,  <em class="kq"># apply ZCA whitening</em><br/>        rotation_range = 30,  <em class="kq"># randomly rotate images in the range (degrees, 0 to 180)</em><br/>        zoom_range = 0.2, <em class="kq"># Randomly zoom image </em><br/>        width_shift_range=0.1,  <em class="kq"># randomly shift images horizontally (fraction of total width)</em><br/>        height_shift_range=0.1,  <em class="kq"># randomly shift images vertically (fraction of total height)</em><br/>        horizontal_flip = <strong class="kg hj">False</strong>,  <em class="kq"># randomly flip images</em><br/>        vertical_flip=<strong class="kg hj">False</strong>)  <em class="kq"># randomly flip images</em><br/><br/><br/>datagen.fit(x_train)</span></pre><p id="0efd" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">我们准备好出发了！</p><p id="626c" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">所以一切都准备好了。我们可以通过基线卷积，尝试不同的东西，但我会节省你的麻烦。玩了一些参数后，最好的结果是6个卷积层。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="196c" class="kk kl hi kg b fi km kn l ko kp">model = Sequential()<br/>model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))<br/><em class="kq"># model.add(BatchNormalization())</em><br/>model.add(MaxPool2D((2,2)))<br/><br/>model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))<br/>model.add(Dropout(0.2))<br/><em class="kq"># model.add(BatchNormalization())</em><br/>model.add(MaxPool2D((2,2)))<br/><br/>model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))<br/><em class="kq"># model.add(Dropout(0.3))</em><br/><em class="kq"># model.add(BatchNormalization())</em><br/>model.add(MaxPool2D((2,2)))<br/><br/>model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))<br/>model.add(Dropout(0.3))<br/><em class="kq"># model.add(BatchNormalization())</em><br/>model.add(MaxPool2D((2,2)))<br/><br/>model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))<br/>model.add(Dropout(0.3))<br/><em class="kq"># model.add(BatchNormalization())</em><br/>model.add(MaxPool2D((2,2)))<br/><br/>model.add(Conv2D(512 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))<br/>model.add(Dropout(0.3))<br/><br/>model.add(Flatten())<br/>model.add(Dense(units = 128 , activation = 'relu'))<br/>model.add(Dropout(0.3))<br/><em class="kq"># model.add(Dense(units = 128 , activation = 'relu'))</em><br/><em class="kq"># model.add(Dropout(0.3))</em><br/>model.add(Dense(units = 1 , activation = 'sigmoid'))<br/>model.compile(optimizer = "rmsprop" , loss = 'binary_crossentropy' , metrics = ['accuracy'])<br/>model.summary()</span></pre><p id="0a54" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">这就是我们的模型设置，现在我们必须使用model.fit()方法实际运行它。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="3135" class="kk kl hi kg b fi km kn l ko kp">history = model.fit(datagen.flow(x_train,y_train, batch_size=100),epochs = 12 , validation_data = datagen.flow(x_val, y_val)</span><span id="31b3" class="kk kl hi kg b fi kr kn l ko kp">predictions = model.predict_classes(x_test)<br/>predictions = predictions.reshape(1,-1)[0]<br/>cm= confusion_matrix(y_test,predictions)<br/><br/>print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))</span></pre><figure class="jx jy jz ka fd kb er es paragraph-image"><div class="er es lg"><img src="../Images/c2a7f96e3bd6d830eddd1ca3166f6ff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*sZ0aEyeplLSGLvx28yDjYw.png"/></div></figure><p id="66ba" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">我们的F1成绩非常好！准确率高达92%。但是在我们的模型调试过程中，我对召回更感兴趣。回忆意味着我们能够预测所有阳性病例中的96%。太棒了。！但是看看正常情况，我们做得很好，但是没有85%好。但这没关系，因为我们宁愿告诉人们他们患有肺炎，并立即开始治疗，而不是错误分类，告诉他们他们没有肺炎，而延长治疗可能会使病情恶化。</p><p id="d359" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">最后，我们可以可视化我们的卷积层在后端做什么。</p><pre class="jx jy jz ka fd kf kg kh ki aw kj bi"><span id="0406" class="kk kl hi kg b fi km kn l ko kp"><strong class="kg hj">from</strong> <strong class="kg hj">keras.preprocessing</strong> <strong class="kg hj">import</strong> image<br/><strong class="kg hj">from</strong> <strong class="kg hj">keras.models</strong> <strong class="kg hj">import</strong> Model</span><span id="52bc" class="kk kl hi kg b fi kr kn l ko kp">layer_outputs = [layer.output <strong class="kg hj">for</strong> layer <strong class="kg hj">in</strong> model.layers[:50]]<br/>test_image = '/content/drive/My Drive/chest_xray/test_image.jpeg'<br/><br/>img = image.load_img(test_image, target_size=(img_size, img_size))<br/>img_tensor = image.img_to_array(img)<br/>img_tensor = img_tensor.reshape(-1, img_size, img_size, 1)<br/><em class="kq"># img_tensor = np.expand_dims(img_tensor, axis=0)</em><br/>img_tensor /= 255.<br/><br/>activation_model = Model(inputs=model.input, outputs=layer_outputs)<br/>activations = activation_model.predict(img_tensor)<br/><br/>layer_names = ['conv2d_1', 'activation_1', 'conv2d_2', 'activation_2', 'conv2d_5', 'activation_5']<br/>activ_list = [activations[1], activations[3], activations[11], activations[13]]<br/><br/>images_per_row = 16<br/><br/><strong class="kg hj">for</strong> layer_name, layer_activation <strong class="kg hj">in</strong> zip(layer_names, activ_list):<br/>    n_features = layer_activation.shape[-1]<br/>    size = layer_activation.shape[1]<br/>    n_cols = n_features // images_per_row<br/>    display_grid = np.zeros((size * n_cols, images_per_row * size))<br/>    <br/>    <strong class="kg hj">for</strong> col <strong class="kg hj">in</strong> range(n_cols):<br/>        <strong class="kg hj">for</strong> row <strong class="kg hj">in</strong> range(images_per_row):<br/>            channel_image = layer_activation[0, :, :, col * images_per_row + row]<br/>            channel_image -= channel_image.mean()<br/>            channel_image /= channel_image.std()<br/>            channel_image *= 64<br/>            channel_image += 128<br/>            channel_image = np.clip(channel_image, 0, 255).astype('uint8')<br/>            display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image<br/><br/>    scale = 1. / size<br/>    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))<br/>    plt.title(layer_name)<br/>    plt.grid(<strong class="kg hj">False</strong>)<br/>    plt.imshow(display_grid, aspect='auto', cmap='plasma')<br/>    plt.savefig(layer_name+"_grid.jpg", bbox_inches='tight')</span></pre><figure class="jx jy jz ka fd kb er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lh"><img src="../Images/a165acee3b13b245c53b9fdcf51df0e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NWevdtNqctm_WBmrr9APqQ.png"/></div></div></figure><p id="475b" class="pw-post-body-paragraph iy iz hi ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hb bi translated">这并不是卷积分解的最佳表现。但是我们可以看出他们在关注什么。</p></div></div>    
</body>
</html>