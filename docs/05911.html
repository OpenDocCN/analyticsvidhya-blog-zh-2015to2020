<html>
<head>
<title>An Introduction To Spark and Its Behavior.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火花及其行为介绍。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/an-introduction-to-spark-and-its-behavior-ac247889922f?source=collection_archive---------20-----------------------#2020-05-05">https://medium.com/analytics-vidhya/an-introduction-to-spark-and-its-behavior-ac247889922f?source=collection_archive---------20-----------------------#2020-05-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/cee7491d32792823539fb90189877f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eZB_IrK1Q952iiO5"/></div></div></figure><h1 id="a316" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">清单如下:</h1><ol class=""><li id="ef12" class="jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">Mapreduce，Hadoop和Spark。</li><li id="23ae" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">火花建筑。</li><li id="2ecd" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">集群中的火花。</li><li id="217b" class="jo jp hi jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">谓词下推、广播和累加器。</li></ol><h1 id="9d45" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 1。Mapreduce、</strong> Hadoop和<strong class="ak"> Spark </strong></h1><p id="022e" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">对于此部分，让下表代表存储在S3的待处理数据。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es la"><img src="../Images/adb8d818c96008656c8a5ee177ba38e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*GNwFj2SDGhB_d5v0pJ6jnw.png"/></div><figcaption class="lf lg et er es lh li bd b be z dx translated"><strong class="bd is">贷款支付表</strong></figcaption></figure><p id="040b" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">下表分别用绿色和蓝色表示地图和洗牌+减少。如下所示，数据不会被读入驱动程序。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/c4328ef8d312b774a128a25c1e36539c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-5IP306azHK7yjvxgDgRxQ.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated"><strong class="bd is">Hadoop集群中的Map Reduce。</strong></figcaption></figure><p id="6fb2" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">作为第<strong class="jq hj">0</strong>步的一部分，从源读取输入数据。在<strong class="jq hj">的第一个</strong>步骤中，数据被加载到集群的各个节点中。<strong class="jq hj">其次</strong>，数据根据所需列映射到键值对。<strong class="jq hj">第三</strong>，键值对在节点间混洗，计算最终计数。<strong class="jq hj">第四</strong>，键值对减少到总计数。<strong class="jq hj">最后，</strong>计数被加载到驱动程序中。</p><p id="5e70" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">上述并行处理数据的技术被称为<strong class="jq hj"> MapReduce </strong>。技术算法可以用任何语言编写。Hadoop已经实现了这种Map和Reduce技术以及逻辑来<strong class="jq hj">管理集群</strong>进行数据存储。</p><p id="0855" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">在Map、Shuffle和Reduce过程中，MapReduce算法将每个中间步骤的结果写入<strong class="jq hj">磁盘</strong>。为每个中间步骤写入磁盘是一个昂贵的解决方案，Spark为所有中间步骤数据存储将数据保留在<strong class="jq hj"> RAM </strong>中。与RAM一起，Spark使用了<strong class="jq hj">血统</strong>、<strong class="jq hj"> RDD </strong>、<strong class="jq hj">转化</strong>和<strong class="jq hj">动作的概念。</strong></p><h1 id="ca2b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2.火花建筑</h1><p id="1275" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">以下是Spark架构的几个基本组件。</p><blockquote class="lp lq lr"><p id="39d9" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated"><strong class="jq hj"> a .集群和集群管理器</strong> —如上图所示，每个集群都有一个主/驱动节点和工作节点。在操作过程中，主机和工作机之间的所有协调都由一个名为集群管理器的应用程序负责。Spark有自己的集群管理器，也可以与YARN、Mesos和Kubernates集成。在AWS EMR中，Spark集群由YARN管理。</p><p id="124b" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated"><strong class="jq hj"> b .驱动程序和执行器— </strong>每个spark应用程序都与一个驱动程序和多个执行器程序相关联。驱动程序是主控制器，与集群管理器一起管理数据处理执行器之间的任务分配。驱动程序可以在<strong class="jq hj">主节点</strong>或<strong class="jq hj">工作节点</strong>上执行，由参数<strong class="jq hj">部署模式</strong>控制。在多用户环境下，建议以集群模式提交spark应用，以避免驱动节点过载。与驱动程序和执行器相关联的CPU内核和内存的数量由<strong class="jq hj"><em class="hi">spark . driver . cores</em></strong>，<strong class="jq hj"><em class="hi">spark . driver . memory</em></strong>，<strong class="jq hj"><em class="hi">spark . executor . cores</em></strong><em class="hi">和</em><strong class="jq hj"><em class="hi">spark . executor . memory</em></strong>等参数控制。更多详情请访问<a class="ae lw" rel="noopener" href="/analytics-vidhya/an-introduction-to-spark-with-aws-425e6ccdff52"><strong class="jq hj"><em class="hi">AWS</em></strong></a><strong class="jq hj">中带Spark的数据流水线简介。</strong></p></blockquote><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/376f51b9e790ec979375bf092e43b187.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n6yUvHtz-FfZLM7XizHbBg.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated"><strong class="bd is">spark session vs spark context</strong></figcaption></figure><blockquote class="lp lq lr"><p id="ba36" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated">c. SparkSession和SparkContext <em class="hi"> — </em> 如上所示，SparkSession和SparkContext都是spark cluster的入口点。<strong class="jq hj"> SparkContext </strong>是2.0之前进入Spark JVM的切入点。SparkSession是在2.0之后引入的，封装了spark、hive和sql上下文。使用参数<em class="hi">spark . driver . allowmultiplecontexts，</em>可以在同一个JVM中执行多个SparkContext，但是这使得JVM更加不稳定。一个SparkContext的崩溃可能会导致其他spark context的崩溃。2.0之后，<strong class="jq hj"> SparkSession </strong>是JVM的入口点。可以启动多个SparkSession，它们各自的配置、表和视图可以独立工作。如上图所示，所有Spark会话都有一个<strong class="jq hj"> single </strong> SparkContext，后跟集群管理器，用于管理和分配执行程序给各个会话。</p><p id="aca4" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated"><strong class="jq hj"> d .转化与行动— </strong> Spark遵循懒惰框架。对于所有称为转换的计算或映射，spark会创建称为DAG的数据流计划。只有在调用某个操作(显示、收集、写入、缓存)时，才会根据创建的DAG或计划触发和执行数据流。对于任何故障，DAG都会被跟踪以检索丢失的数据。对于MapReduce部分解释的例子，下面是Spark代码。</p></blockquote><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/905a68948a0affa7542adaa30f327c25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rdR-JNzSerQg-S780-wh6Q.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated"><strong class="bd is">群发火花</strong></figcaption></figure><blockquote class="lp lq lr"><p id="41e6" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated">一旦执行了上述代码，Spark仅创建计划或数据沿袭，并可通过如下所示的<strong class="jq hj"> explain </strong>参数获得。</p></blockquote><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/32cdd2686b13565989baef811b35d454.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FMYWFEiNJWWAFcrt1ezwwA.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated"><strong class="bd is">数据血统</strong></figcaption></figure><blockquote class="lp lq lr"><p id="a2c6" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated">一旦执行了任何操作(如show ),就会执行数据计划并进行数据移动，生成DAG图并输出如下。</p></blockquote><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/e147f98d09ceda34cdf0ca15f085653f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Q9h-wywqDI6kktQ7LPHqQ.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated"><strong class="bd is"> DAG表示</strong></figcaption></figure><blockquote class="lp lq lr"><p id="ba86" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated">如上所述，为最终查询创建了总共5个不同的中间RDD。5个不同的RDD可以与Hadoop集群中的<strong class="jq hj"> Map Reduce中所示的5个不同步骤进行比较。MapReduce在计算最终答案时将所有中间结果写入磁盘，而Spark在RDD上工作，并将数据保留在RAM中，直到计算出最终结果。</strong></p></blockquote><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/4a749689dd8878692e4259547613b0d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yovL5tCMv-NJnIgqrTqf9w.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated"><strong class="bd is">火花输出on动作。</strong></figcaption></figure><h1 id="1e17" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">3.星团中的火花</h1><p id="9a80" class="pw-post-body-paragraph kl km hi jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">可以使用<strong class="jq hj"> Spark-submit </strong>向集群提交spark应用程序。与spark应用程序一起，spark-submit接受在集群中使用<strong class="jq hj"> conf </strong>参数成功执行应用程序所需的各种Spark配置参数。一旦spark-submit触发了一个应用程序，SparkSession在SparkContext和集群管理器的帮助下创建RDD，执行转换并管理集群以执行应用程序。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/06c79ce8445a0a97cd1fe4b36fb5aae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2uae49RojGJq1oi576ftXQ.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated"><strong class="bd is">提交的Spark申请中的转换+动作</strong></figcaption></figure><p id="c880" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">每个提交的申请都由许多职务组成。触发的<strong class="jq hj"> <em class="ls">作业数=提交的申请中存在的</em> </strong>动作数。每个作业(一组转换)又被进一步划分为几个阶段。<strong class="jq hj"> <em class="ls">跨集群节点的数据的每次洗牌</em> </strong>都会产生一个<strong class="jq hj"> <em class="ls">新阶段</em> </strong>。每个<strong class="jq hj">阶段由<strong class="jq hj">任务</strong>组成。<strong class="jq hj"> <em class="ls">任务数= </em> </strong> <em class="ls"> </em> <strong class="jq hj"> <em class="ls">分区数</em> </strong>将RDD分为while操作。</strong></p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/25523327471672e1978ef74d9c45f0fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yDN4dlId3NPltTz202qwcw.png"/></div></div></figure><p id="f785" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">从上面的例子来看，<strong class="jq hj"> <em class="ls">作业数= 1 =动作数</em> </strong>。虽然计划了5项工作，但只执行了一项，其余的都被跳过了。<strong class="jq hj"> <em class="ls">洗牌次数= 2 =级数</em> </strong>。一个用于从输入文件映射RDD，另一个在分组时使用。<strong class="jq hj"> <em class="ls">任务数= 1 =分区数</em> </strong>。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/bb6f0ca847a523483fe335068cca5d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FimvS5rMdZg0OQYEJiWkNg.png"/></div></div></figure><h1 id="5166" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">4.谓词下推、广播、累加器</h1><blockquote class="lp lq lr"><p id="7385" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated"><strong class="jq hj"> a .谓词下推</strong> —每当对数据应用任何过滤器时，过滤器逻辑在读取时被下推到数据源，而不是提取所有数据并应用过滤器。将过滤器下推到数据源的概念称为谓词下推。</p></blockquote><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/518df8aa30bd6cfa028d5879641d061a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kf7uzvDGoT_AVtrdQqKmxw.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">谓词下推</figcaption></figure><p id="b41b" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">对于并行处理，spark使用共享变量。当驱动程序向执行器发送任务时，共享变量的副本会被发送到每个节点，以便用于执行任务。Spark使用两种共享变量，如下所示</p><blockquote class="lp lq lr"><p id="94e4" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated"><strong class="jq hj"> b. Broadcast变量</strong> — Broadcast变量用于在每个节点保存一份数据副本，避免数据洗牌，提高效率。在执行小文件和大文件之间的连接时，可以将小文件广播到每个节点，以避免集群节点之间的数据洗牌。广播变量是一个只读变量。</p></blockquote><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/3c6ddeaea008003a73e234bd91bdd413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OZfx-1nG2IW0sreB3s1Vgg.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">广播变量。</figcaption></figure><blockquote class="lp lq lr"><p id="da40" class="kl km ls jq b jr lj kn ko jt lk kp kq lt ll ks kt lu lm kv kw lv ln ky kz kb hb bi translated"><strong class="jq hj"> c .累加器</strong> —累加器是用于累加运算的共享变量。每个工人节点向累加器增值，而只有司机可以访问全局变量。工人只能将值添加到累加器中，而不能读取它。每次触发任何任务时，驱动程序都会将累加器变量发送到工作节点。</p></blockquote><p id="7685" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">感谢阅读。欢迎提问和建议。</p><p id="4e7d" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">问候</p><p id="63fb" class="pw-post-body-paragraph kl km hi jq b jr lj kn ko jt lk kp kq jv ll ks kt jx lm kv kw jz ln ky kz kb hb bi translated">阿比。</p></div></div>    
</body>
</html>