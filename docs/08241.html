<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-proceed-from-simple-to-multiple-and-polynomial-regression-in-r-84b77f5673c5?source=collection_archive---------5-----------------------#2020-07-22">https://medium.com/analytics-vidhya/how-to-proceed-from-simple-to-multiple-and-polynomial-regression-in-r-84b77f5673c5?source=collection_archive---------5-----------------------#2020-07-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="4691" class="hg hh hi bd hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie bi translated">如何从<strong class="ak">简单回归到R </strong>中的多元和多项式回归</h2><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es if"><img src="../Images/a43907dc9460192ead2b7b44055e5363.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LIFTcaAiITblpi1U6ZP26w.png"/></div></div></figure><h1 id="33a8" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">简介-</h1><p id="e031" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">这篇文章是我的<a class="ae kd" rel="noopener" href="/विज्ञानं-ब्रह्म/step-by-step-procedure-to-perform-simple-linear-regression-with-statistical-analysis-in-r-340ef0a392d6"> <strong class="jk ke">第一篇文章</strong> </a>的延续，在这篇文章中，我详细展示了执行简单线性回归的完整过程。现在，在本文中，我将采用一个稍微复杂一点的数据集(<a class="ae kd" href="https://www.kaggle.com/ashydv/advertising-dataset" rel="noopener ugc nofollow" target="_blank"> <strong class="jk ke">广告数据集</strong> </a>)，并向您展示<strong class="jk ke">如何准备多元线性回归，以及如何使用从其诊断图中获得的信息，我们如何进行正交多项式回归，并获得该数据集的更好模型。</strong></p><p id="ad3f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">本文由以下部分组成-</p><ol class=""><li id="0820" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">加载所需的库</li><li id="1dea" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">加载数据集</li><li id="4914" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">探索数据集</li><li id="2236" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">分割数据集</li><li id="e510" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">拟合简单线性回归模型</li><li id="4a3f" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">用诊断图和统计检验拟合多元线性回归模型</li><li id="1faf" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">用诊断图和统计检验拟合正交多项式线性回归模型</li><li id="9e99" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">做预测</li><li id="cc7b" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">重复10重交叉验证</li><li id="b6a6" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">结论</li><li id="6d30" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">任务给你(如果感兴趣)</li><li id="e41a" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">关于下一篇文章的信息</li></ol><p id="d941" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">我将使用kaggle online R-Notebook进行分析工作。您可以使用任何软件，如R-studio或R-cran版本脱机工作。</p><h1 id="9396" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">1.加载所需的库</h1><p id="789c" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">一开始并不强制加载库，但我这样做是为了简单。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="873f" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Loading required libraries</strong><br/>library(tidyverse)     <strong class="kz ke">#</strong> Pipe operator (<strong class="kz ke">%&gt;%</strong>) and other commands<br/>library(caret)         <strong class="kz ke">#</strong> Random split of data/cross validation<br/>library(olsrr)         <strong class="kz ke">#</strong> Heteroscedasticity Testing (<strong class="kz ke">ols_test_score</strong>)<br/>library(car)           <strong class="kz ke">#</strong> Muticolinearity detection (<strong class="kz ke">vif</strong>)<br/>library(broom)         <strong class="kz ke"># </strong>Diagnostic Metric Table (<strong class="kz ke">augment</strong>)</span></pre><h1 id="9d70" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">2.加载数据集</h1><p id="465c" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">首先，在您的R-Session中加载数据集。<a class="ae kd" href="https://www.kaggle.com/ashydv/advertising-dataset/download" rel="noopener ugc nofollow" target="_blank"> <strong class="jk ke">链接</strong> </a>下载数据集。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="5a11" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Loading Data set</strong><br/>data = read.csv("../input/advertising-dataset/advertising.csv" , header = T)</span></pre><p id="cb33" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">广告数据集已成功加载到R-object“数据”中。</strong></p><h1 id="9303" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">3.探索数据集</h1><p id="be8d" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">对给定的数据集做如下理解-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="28ad" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Inspection of top 5-rows of data</strong><br/>head(data)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lh"><img src="../Images/b7fb00d2fadc0ad57a4eb7471e74f838.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LjGv--Z0zcPDYhUafi3QPw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 1 </strong></figcaption></figure><p id="5169" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">上面的输出显示了给定数据集的前5行。在这个阶段，只需看到数据并作出一些理解即可— <strong class="jk ke">数据集中有四个变量(电视、广播、报纸、销售)，并且都是数字变量</strong>。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="3fb8" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Inspection of 5-bottom rows of data</strong><br/>tail(data)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lm"><img src="../Images/3a942bbf06312858a249f49b0bf2e242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MekiZ-5eD-N_dMeTMtTMHg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 2 </strong></figcaption></figure><p id="7cad" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">从上面的输出可以清楚地看到，数据集中有<strong class="jk ke"> 200行</strong>，更重要的一点是<strong class="jk ke">没有包含类似于“总计”</strong>的信息的行。在您的数据集中，可能有最后一行包含每列的<strong class="jk ke">总计信息。这样的行在进一步的分析或模型准备过程中没有用。因此，如果存在这样的行，就从数据中删除它。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="d4e7" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Getting Structure of whole data set</strong><br/>str(data)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ln"><img src="../Images/d9e46e236568b4df20bd58cc21c7780f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f7E1tAh252RwB1Lo55Fhow.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 3 </strong></figcaption></figure><p id="3e4d" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">以上输出给出的信息为- </strong></p><ol class=""><li id="b32f" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">有200行和4个变量。</li><li id="834f" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">变量有:电视、广播、报纸、销售</li><li id="6e5c" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">所有都是数字变量。</li></ol><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="f3aa" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Checking Outliers</strong><br/>boxplot(data)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lo"><img src="../Images/243f3247aae6afa58cad6784766ac95f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lW0m6M9BhDlqq4a2-rF6vw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 4 </strong></figcaption></figure><p id="af60" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">上图显示变量“报纸”</strong>中存在两个异常值。只需通过以下命令删除这些异常值-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="f7bf" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Removing Outliers</strong><br/>data &lt;- data[-which(data$Newspaper %in%    boxplot.stats(data$Newspaper)$out), ]</span></pre><p id="11a3" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">再一次，看箱线图-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="1aa6" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Again Checking Outliers</strong><br/>boxplot(data)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lp"><img src="../Images/dffedf640a1349d2cf008d56aa79bb8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qeAsuvry2A4VAg2cHUFQeA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 5 </strong></figcaption></figure><p id="f305" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">现在，离群点已经被剔除。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="1423" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Checking Missing Values</strong><br/>table(is.na(data))</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ln"><img src="../Images/944b1c0928ad1c1cf0478065f3ff7139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tEIGCTJB5UTaGQp9aH2XEw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 6 </strong></figcaption></figure><p id="184f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">上面的输出显示给定的数据集中没有缺失值。</strong></p><p id="b6e5" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">决定目标和预测因素</strong> —我们总是知道哪些变量必须作为目标，哪些作为预测因素。这取决于你想预测什么问题。我在这里把<strong class="jk ke">销售</strong>作为<strong class="jk ke">目标</strong>，把<strong class="jk ke">剩余变量</strong>作为<strong class="jk ke">预测值</strong>。</p><p id="271b" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">我们有四个数值变量。看一下这些变量的散点图，如下所示</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="fcfd" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Creating scatter plot matrix </strong><br/>pairs(data , upper.panel = NULL)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lp"><img src="../Images/d43785afccd662f2b6b0a13dde2495b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GyY3TGZxrO5AE1lh7l4peg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 7 </strong></figcaption></figure><p id="f759" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">此输出显示- </strong></p><ol class=""><li id="375c" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">电视和无线电变量之间没有线性关系或线性关系很低。</li><li id="41e7" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">●电视和报纸变量之间的线性关系。</li><li id="b87f" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">广播和报纸变量之间的适度线性关系。</li><li id="fadf" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">电视与销售、广播与销售、报纸与销售之间的高度线性关系。</li><li id="e73b" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">电视和销售以及广播和销售之间也存在一个小的曲线关系。</li></ol><p id="2052" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">让我们通过绘制单独的散点图来获得更近的视角，对现有关系更有信心-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="cc68" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Scatter Plot between TV and Sales</strong><br/>plot(data$TV , data$Sales)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lq"><img src="../Images/7f9ed2150bba92e2f935915a8a20b75b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zaP2j03NFFQlOQhPZYCQWg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 8 </strong></figcaption></figure><p id="8b13" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">注意，电视和销量之间有一个小的曲线关系。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="dc3f" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Scatter Plot between Radio and Sales</strong><br/>plot(data$Radio , data$Sales)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ln"><img src="../Images/1f59d3f32ab42ac89c5005363a07e276.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eqPMaJlis0QNkyvktwP3-g.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 9 </strong></figcaption></figure><p id="c374" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">注意，广播和销售之间有一个曲线关系。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="2ea1" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Scatter Plot between Newspaper and Sales</strong><br/>plot(data$Newspaper , data$Sales)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lr"><img src="../Images/d289fa9a880806846b6aeea3b62e818c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1zCSdBHNm7yKP4G_LY4p3Q.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 10 </strong></figcaption></figure><p id="f428" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">报纸和销售变量之间的低线性关系。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="f129" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Scatter Plot between TV and Radio</strong><br/>plot(data$TV , data$Radio)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ls"><img src="../Images/5821c36307a86817935eb29ca593225c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OPXdoD3RvlfOKE4bpX7JqA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 11 </strong></figcaption></figure><p id="50bf" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">电视和收音机变量之间没有线性关系。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="cfbb" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Scatter Plot between Newspaper and TV</strong><br/>plot(data$TV , data$Newspaper)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lt"><img src="../Images/89f6229c17209b45d0ff9bf2d0e27b8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JTD8g7eKgznZzHILrTno_A.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 12 </strong></figcaption></figure><p id="7416" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">电视和报纸变量之间没有线性关系。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="42f0" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Scatter Plot between Newspaper and Radio</strong><br/>plot(data$Radio , data$Newspaper)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lu"><img src="../Images/f085ae296ffb8b2d7f99ec8fa67030ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y8yhkKD7gi7UPbpvi7IGLA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 13 </strong></figcaption></figure><p id="dfaa" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">广播和报纸变量之间的适度线性关系。</strong></p><p id="9293" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">记住这些要点，这将有助于你准备更好的模型。</strong></p><h1 id="1bb8" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">4.分割数据集</h1><p id="1f55" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">现在，我将把整个数据集分成两部分。一部分称为<strong class="jk ke">训练数据集</strong>，另一部分称为<strong class="jk ke">测试数据集</strong>。我们这样做是因为首先我们使用训练数据集来训练/拟合模型，然后使用测试数据集来检查所获得的模型在训练期间没有使用的新数据集上的性能。拆分由以下代码完成-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="ef9a" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Randomly Split the data into training and test set</strong><br/>set.seed(123)<br/>training.samples &lt;- data$Sales %&gt;%<br/>  createDataPartition(p = 0.75, list = FALSE)<br/>train.data  &lt;- data[training.samples, ]<br/>test.data &lt;- data[-training.samples, ]</span></pre><p id="9874" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">训练数据集</strong>和<strong class="jk ke">测试数据集</strong>已经<strong class="jk ke">分别存储在</strong>R-object<strong class="jk ke">Train . data</strong>和<strong class="jk ke"> test.data </strong>中。请注意:</p><ol class=""><li id="1144" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">我们将使用<strong class="jk ke"> train.data </strong>中的可用数据来<strong class="jk ke">装配/训练模型</strong>。</li><li id="56a4" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">我们将使用<strong class="jk ke">测试数据</strong>中的可用数据来检查型号的<strong class="jk ke">性能。</strong></li></ol><h1 id="6ae0" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">5.拟合简单线性回归</h1><p id="1935" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">由于我们只有三个预测值，我们可以拟合三个独立的简单线性回归模型，每个预测值一个，即:</p><ol class=""><li id="ad19" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">销售~电视</li><li id="d012" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">销售~电台</li><li id="4488" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">销售~报纸</li></ol><p id="55d2" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">拟合这三个模型，试着找出这些模型解释的百分比方差。这是通过<strong class="jk ke">调整R </strong>并在R中使用<strong class="jk ke"> summary() </strong>功能实现的。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="d311" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Fitting Sales ~ TV</strong><br/>sm1 &lt;- lm(Sales ~ TV , data = train.data)<br/><br/><strong class="kz ke"># Take a look on summary of the model</strong><br/>summary(sm1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lv"><img src="../Images/58732b04dc28fb39644bab71719b5b64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I9jrIZE6F96MI-WGwqTrIw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 14 </strong></figcaption></figure><p id="f61a" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">从上面的输出中，你一定注意到了——</strong></p><ol class=""><li id="4965" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">由于目标(销售)的p值&lt;&lt;&lt; 0.05 (see in the last line of output)</li><li id="2eaa" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">From the coefficients section, it is clear that both coefficients (slope and intercept) are statistically significant since p-value &lt;&lt;&lt; 0.05</li><li id="bc22" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">This model with TV as predictor explains approximately <strong class="jk ke"> 81% </strong>可变性，创建的模型具有统计显著性。</li><li id="00b7" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated"><strong class="jk ke">模型的残差标准误差</strong>为<strong class="jk ke"> 2.29 </strong></li></ol><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="4718" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Fitting Sales ~ Radio</strong><br/>sm2 &lt;- lm(Sales ~ Radio , data = train.data)<br/><br/><strong class="kz ke"># Take a look on summary of the model</strong><br/>summary(sm2)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lw"><img src="../Images/a6a791bda054cfc12eed3a7414786a91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0W3Ni-gfcbRP07KUCClouA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 15 </strong></figcaption></figure><p id="73be" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">从上面的输出中，你一定注意到了——</strong></p><ol class=""><li id="9254" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">由于目标(销售)的p值&lt;&lt; 0.05 (see in the last line of output)</li><li id="f67c" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">From the coefficients section, it is clear that both coefficients (slope and intercept) are statistically significant since p-value &lt;&lt; 0.05</li><li id="b95c" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">This model with TV as predictor explains approximately <strong class="jk ke"> 13% </strong>可变性，创建的模型具有统计显著性。</li><li id="05d6" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated"><strong class="jk ke">该模型的剩余标准误差</strong>为<strong class="jk ke"> 4.917 </strong></li></ol><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="8914" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Fitting Sales ~ Newspaper</strong><br/>sm3 &lt;- lm(Sales ~ Newspaper , data = train.data)<br/><br/><strong class="kz ke"># Take a look on summary of the model</strong><br/>summary(sm3)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lr"><img src="../Images/5fb9f36212d82df87533a25f7b35f0ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L42lrBrzCjymTIx5RzYNLw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 16 </strong></figcaption></figure><p id="76a5" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">从上面的输出中，你一定注意到了——</strong></p><ol class=""><li id="ae9d" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">由于目标(销售)的p值&lt; 0.05 (see in the last line of output)</li><li id="4a34" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">From the coefficients section, it is clear that both coefficients (slope and intercept) are statistically significant since p-value &lt; 0.05</li><li id="8b6a" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">This model with TV as predictor explains approximately <strong class="jk ke"> 2% </strong>可变性，创建的模型具有统计显著性。</li><li id="c9db" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated"><strong class="jk ke">模型的剩余标准差</strong>为<strong class="jk ke"> 5.21 </strong></li></ol><p id="ecdf" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">到目前为止，我们已经得出，以电视作为预测因子的简单线性回归模型解释了目标(销售)的更多可变性。</strong></p><p id="382f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">只需<strong class="jk ke">绘制电视和销售</strong>之间的散点图，并且<strong class="jk ke">在图</strong>中绘制简单的线性回归线，如下所示-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="25fc" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Scatter plot with Simple Linear Regression Line</strong><br/>plot(train.data$TV , train.data$Sales)<br/><br/><strong class="kz ke"># Adding Regression Line</strong><br/>abline(lm(train.data$Sales ~ train.data$TV) , col = "blue")</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lx"><img src="../Images/7f292463dbf309b37b7a086a07998a29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tjVldhMVw0I64ABmATlawg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 17 </strong></figcaption></figure><p id="943a" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">这里出现了一个问题:</strong>上图表明，由于销售的可变性更大，仅基于单一预测因素来预测销售是不可行的。此外，如果我们使用单一预测因素，那么我们完全忽略了其余两个预测因素对销售的影响，实际情况可能并非如此。<strong class="jk ke">那么，为什么不扩展这个模型呢？</strong></p><h1 id="aca9" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">6.用诊断图拟合多元线性回归</h1><p id="3483" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">扩展上述简单线性回归模型的方法有很多，如<strong class="jk ke">正向选择法</strong>、<strong class="jk ke">反向选择法</strong>、<strong class="jk ke">混合选择法</strong>等等。在这篇文章中，<strong class="jk ke">我想用向前选择的方法去探索一些更多的概念</strong>。</p><p id="b33f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">使用正向选择方法扩展简单线性回归模型- </strong></p><p id="2e52" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">在这种背景下，<strong class="jk ke">我会怎么做？</strong></p><p id="4116" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">我就简单的<strong class="jk ke">把预测电台</strong>包含在简单线性回归模型<strong class="jk ke">销售~电视</strong>(为什么在这个模型里？:<strong class="jk ke">由于解释了销售变化的很大一部分</strong>。</p><p id="25ab" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">为什么我们在这个阶段包括无线电？</strong></p><p id="acb2" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">因为<strong class="jk ke">比<strong class="jk ke">报纸(2%)</strong><strong class="jk ke">电视(81%) </strong>更能解释销售的可变性(13%) </strong>。—{此处使用简单线性回归的结果。}</p><p id="e160" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">因此，用<strong class="jk ke">两个预测因子TV和Radio </strong>拟合一个<strong class="jk ke">多元线性回归模型</strong>，得到模型总结如下-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="8f91" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Fitting MLR model with predictors TV and Radio</strong><em class="ly"> </em><br/>mm1 &lt;- lm(Sales ~ TV + Radio , data = train.data)<br/><br/><strong class="kz ke"># Take a look on summary of the model</strong><br/>summary(mm1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lw"><img src="../Images/32f342819fa127014b7508a16f2b1a48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2upUerzInMFmYPPmwJJk_Q.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 18 </strong></figcaption></figure><p id="b93c" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">好吧，从上面的输出中，注意——</strong></p><ol class=""><li id="8e73" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">由于p值&lt; &lt; &lt; 0.05，创建的模型具有统计学意义(参见输出的最后一行)</li><li id="4100" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">从系数部分可以清楚地看出，由于p值&lt; &lt; &lt; 0.05，所以两个系数(斜率和截距)都具有统计学意义</li><li id="3b5f" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">这种将电视和广播作为预测因素的模型解释了大约89% 的目标(销售)可变性，相对于仅将电视作为预测因素的模型，这是一个更好的指示。</li><li id="aaa5" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">模型的<strong class="jk ke">残差标准误差</strong>为<strong class="jk ke"> 1.715 </strong></li></ol><p id="b4a5" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">但是<strong class="jk ke">我们必须测试，调整后的R平方的改善在统计上是否显著？</strong></p><p id="3758" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">也就是说，我们想要检验零假设— <strong class="jk ke"> H0:调整后的R平方的改善在统计上并不显著。</strong>对比替代假设— <strong class="jk ke"> H1:调整后的R平方的改善具有统计学意义。</strong></p><p id="8d1f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">对于该测试，我们使用<strong class="jk ke"> ANOVA(方差分析)技术</strong>，其代码如下-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="8c62" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Performing ANOVA to test the above stated null hypothesis</strong><br/>anova(sm1 , mm1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lz"><img src="../Images/20fb1ca35e7bb1710a1b8aae72b4ad60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xru6ZFaBs567NGRDdkddCQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 19 </strong></figcaption></figure><p id="4087" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">在上面的输出中，<strong class="jk ke">注意第二行最后一列的值</strong>。该值(<strong class="jk ke"> 2.051808e-20 </strong>)表示检验零假设的<strong class="jk ke"> p值</strong>。由于该值远小于0.05，因此我们有足够的数据证据来拒绝零假设并接受替代方案。</p><p id="b415" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">这就是为什么调整后的R平方的改善具有统计学意义。</strong></p><p id="a1b0" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">因此，<strong class="jk ke">采用</strong>的型号<strong class="jk ke">现阶段销量约为0.05462台电视机+ 0.10239台收音机</strong>。</p><p id="0200" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">为什么不进一步扩展这种模式？</p><p id="7768" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">即<strong class="jk ke">把第三个预测报也纳入你的多元线性回归模型，看看会发生什么。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="3bbc" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Extending further the MLR including the predictor Newspaper</strong><br/>mm2 &lt;- lm(Sales ~ TV + Radio + Newspaper , data = train.data)<br/><br/><strong class="kz ke"># Take a look on summary of the model</strong><br/>summary(mm2)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ma"><img src="../Images/8c63d171218a2e67d52151e86333f20c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VmsNDQKkE2IHSvlE11_3ww.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 20 </strong></figcaption></figure><p id="c121" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">根据上述输出，并使用先前拟合模型的信息，注意- </strong></p><ol class=""><li id="d684" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">从上述输出的系数部分可以清楚地看出，由于p值(0.69) &gt; 0.05，报纸预测值对于模型来说没有统计学意义</li><li id="a9bb" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">调整后的R平方从89.41降至89.35</li><li id="ca6f" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">剩余标准误差从1.715增加到1.72</li><li id="578f" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">虽然，由于p值&lt;&lt;&lt; 0.05 (see in the last line of output)</li></ol><p id="8171" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">So, we have sufficient evidence from the data for <strong class="jk ke">没有将报纸作为预测因子</strong>包含在模型中，因此创建的模型在统计上是显著的。</p><p id="cb39" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">因此，将其从模型中移除，我们得到之前拟合的模型<strong class="jk ke">多元线性回归模型</strong>已经存储在R-object <strong class="jk ke"> mm1 </strong>中</p><p id="eb41" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">即<strong class="jk ke">销售额~ 0.05462电视+ 0.10239收音机</strong></p><p id="5184" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">我们将进一步讨论这一模型。</p><h1 id="05b5" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">诊断图-</h1><p id="75b3" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">为了检查是否满足多元线性回归的所有假设，我们使用不同的诊断图。</p><p id="a175" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查线性假设- </strong></p><p id="18ec" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">残差图</strong>用于检查第一个假设，即目标和预测值(电视、广播的联合)之间的<strong class="jk ke">线性</strong>假设如下-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="c544" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Residual Plot</strong><br/>plot(mm1 , 1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mb"><img src="../Images/57671b1e10b6bb110e5e8c8a93fec78c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dsL4csAH_x7bEU3e7wECmg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 21 </strong></figcaption></figure><p id="6309" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">从上图预告- </strong></p><ol class=""><li id="c293" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">红线近似水平且呈线性，这表明<strong class="jk ke">线性假设适用于</strong>。</li><li id="ebef" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">残差在残差= -4到+4之间的范围内以随机方式波动，这表明拟合模型在某种程度上有利于预测。<strong class="jk ke">为什么在某种程度上？</strong></li><li id="4f1e" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">因为点<strong class="jk ke"> 131 </strong>和<strong class="jk ke"> 151 </strong>可能是潜在的<strong class="jk ke">异常值</strong>，因为它们离其他点非常远。但是我们知道<strong class="jk ke">大的残差(如在我们的例子中有131和151个数据点)也可能表明方差不是常数(异方差)或者目标和预测之间的真实关系是非线性的</strong>。因此，在将这些点视为异常值之前，应该调查这些可能性。</li></ol><p id="9b06" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查同方差假设- </strong></p><p id="8964" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">我将使用<strong class="jk ke">分数测试</strong>，但你也可以应用其他测试，如布勒许帕甘测试、巴特利特测试等。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="c2a8" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Score Test for Heteroscedasticity</strong><br/>ols_test_score(mm1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mc"><img src="../Images/d4cc2edb82589b1e4633c158e2b29deb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*79Vb7WwaZjzZcD1Zhpo71w.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 22 </strong></figcaption></figure><p id="5f6c" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">从上面输出的最后一行，很明显p值大于显著性水平0.05。因此，我们可以接受零假设，并得出方差是齐次的结论。即同质性</em></p><p id="3ac7" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查自相关假设- </strong></p><p id="1a53" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">Durbin Watson测试用于检测自相关的影响，如下所示</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="076d" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Checking effect of</strong> <strong class="kz ke">Auto-correlation</strong><br/>durbinWatsonTest(mm1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es md"><img src="../Images/b8146903b6d9137a600160ca63b415e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-y3aWMfSqEKuFR5iNvWHg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 23 </strong></figcaption></figure><p id="aa1f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">从上面的输出可以清楚地看出，p值(0.166) &gt; 0.05，因此，我们可以接受零假设并得出错误之间没有自相关的结论。即误差是不相关的。</em></p><p id="e8e1" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查多重共线- </strong></p><p id="b425" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">通常，方差膨胀因子用于检测多重共线性。根据经验，VIF大于5或10代表多重共线性。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="7dec" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Detecting</strong> <strong class="kz ke">Multicolinearity</strong><br/>vif(mm1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es me"><img src="../Images/9d10210876ef96a1b948e1e7dfa2508e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dd_jz5BvY8V15l7uI6SEAQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 24 </strong></figcaption></figure><p id="c572" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">请注意，两个预测值的方差膨胀因子均小于5(根据经验法则)，因此预测值之间不存在多重共线性。</em></p><p id="ac95" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检验正态假设- </strong></p><p id="3309" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">夏皮罗维尔克检验通常用于检验正态性假设。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="d28b" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Checking Normality of Errors</strong><br/>shapiro.test(mm1$residuals)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lu"><img src="../Images/5e9581ca764014992940a9694d5c76d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VMIKl0SsyC1t4OIa1HIusQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 25 </strong></figcaption></figure><p id="a63f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">常态不成立，因为p值&lt;为0.05 </em></p><p id="9242" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">只要画出残差的直方图，就能了解分布的模式</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="7cb8" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Plotting Histogram for Residuals</strong><br/>hist(mm1$residuals)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lu"><img src="../Images/bb6f455522793d06c2d49c5d352cc977.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hg0g1y3V-KylLljOJJn4jg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 26 </strong></figcaption></figure><p id="e1df" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">我们发现左尾巴有些问题。这可能是由于前面指出的数据点131和151。</p><p id="d20e" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">现在，最终我们得到的是方差是恒定的，最后一种可能性是在将数据点131和151视为异常值之前检查目标和预测值之间是否存在任何非线性关系</strong>。</p><p id="c2ae" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">同样从之前绘制的目标和不同预测值之间的散点图中，我们注意到存在某种类型的曲线关系</strong>。处理曲线关系的算法有很多，但我将采用一种非常基本的算法来处理现有的曲线关系，这就是多项式回归。(通常，<strong class="jk ke">我们使用正交多项式来避免多重共线性问题</strong></p><p id="c2fb" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">所以，所有这些事实直接向我们表明<strong class="jk ke">为什么不使用正交多项式回归？</strong></p><p id="0e13" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">现在，我们开始拟合<strong class="jk ke">销售额与预测电视和广播</strong>之间的正交多项式回归。</p><p id="c839" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">为什么只有这两个预测值？</strong></p><p id="fff1" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">因为我们已经看到，当我们拟合多元线性回归时，<strong class="jk ke">报纸变量在统计上并不显著。</strong></p><h1 id="e2d1" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">7.用诊断图拟合正交多项式回归</h1><p id="e942" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">现在，我将拟合两个变量的二阶正交多项式。用于拟合电视和收音机两个变量中二阶正交多项式模型的r代码如下</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="f545" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Fitting second order orthogonal polynomial model in two variables to avoid multicollinearity</strong><br/>pm1 &lt;- lm(Sales ~ poly(TV , 2) + poly(Radio , 2) + TV:Radio  , data = train.data)<br/><br/><strong class="kz ke"># Take a look on summary of the model</strong><br/>summary(pm1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mf"><img src="../Images/d3b812a0c3aaefebfa68e499e2e82b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IansgfdPHliTDgp0WuhwLQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 27 </strong></figcaption></figure><p id="9100" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">从上面的输出中，请注意- </strong></p><ol class=""><li id="b52f" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">所创建的模型具有统计显著性，因为目标(销售额)的p值&lt;&lt;&lt; 0.05 (see in the last line of output)</li><li id="16fa" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">From the coefficients section, it is clear that all coefficients are statistically significant since p-value &lt;&lt;&lt; 0.05</li><li id="57b8" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">This second order orthogonal polynomial model explains <strong class="jk ke"> 92.58% </strong>可变性相对于以电视和广播作为预测因子的多元线性回归模型而言是一个更好的指示。</li><li id="ed94" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated"><strong class="jk ke">模型的残差标准误差</strong>为<strong class="jk ke"> 1.436 </strong></li></ol><p id="1ceb" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查调整后的R平方的改善是否具有统计显著性- </strong></p><p id="73a8" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">也就是说，我们想要测试零假设— <strong class="jk ke"> H0:调整后的R平方的改善在统计上并不显著。</strong></p><p id="eedd" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">对比另一个假设— <strong class="jk ke"> H1:调整后的R平方的改善具有统计学意义。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="bbec" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Performing ANOVA to test the above stated null hypothesis</strong><br/>anova(mm1 , pm1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mg"><img src="../Images/258e10b6808b2a348b2f103c4b472003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rQSOJzueucVlJF-gkKhHhg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 28 </strong></figcaption></figure><p id="b626" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">在上面的输出中，<strong class="jk ke">注意第二行最后一列的值</strong>。该值(<strong class="jk ke"> 9.441734e-12 </strong>)表示检验零假设的<strong class="jk ke"> p值</strong>。由于该值远小于0.05，因此我们有足够的数据证据来拒绝零假设并接受替代方案。</p><p id="1195" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">这就是调整后的R平方的改善具有统计学意义的原因。</strong></p><p id="22a8" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">因此，<strong class="jk ke">在此阶段采用二阶正交多项式模型。</strong></p><p id="2fed" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">为什么不在两个变量中使用三阶(正交)多项式回归？</strong></p><p id="ea79" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">年以来，我们注意到调整后的R平方从</em><strong class="jk ke"><em class="ly">89%</em></strong><em class="ly">到</em><strong class="jk ke"><em class="ly">92.58%</em></strong><em class="ly">有了很大程度的提高。因此，转向拟合两个变量的三阶正交多项式回归，看看会发生什么。</em></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="3f90" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Fitting third order (orthogonal) polynomial model in two variables to avoid multicollinearity</strong><br/>pm2 &lt;- lm(Sales ~ poly(TV , 3) + poly(Radio , 3) + TV:Radio  , data = train.data)<br/><br/><strong class="kz ke"># Take a look on summary of the model</strong><br/>summary(pm2)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mh"><img src="../Images/0d194bfce6bc4c0eaef7fa38d4029889.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mIih_WLV8lgwwdMBsZys4g.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 29 </strong></figcaption></figure><p id="e7dd" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">从上述输出的系数部分可以清楚地看出，<strong class="jk ke">三阶TV预测值在统计上并不显著(p值&gt; 0.05)。因此，不要在模型中包括这个术语。</strong></p><p id="a634" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">因此，将模型拟合如下-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="ff54" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Fitting third order (orthogonal) polynomial model in two variables to avoid multicolinearity but after removing third order of TV predictor</strong><br/>pm3 &lt;- lm(Sales ~ poly(TV , 2) + poly(Radio , 3) + TV:Radio  , data = train.data)<br/><br/><strong class="kz ke"># Take a look on summary of the model</strong><br/>summary(pm3)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lu"><img src="../Images/e0fe800312741f6ba7ceb99c8242201a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mW_n5KNnKS0MVOW-gVIpng.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 30 </strong></figcaption></figure><p id="9ddb" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">根据上述输出，并使用存储在R对象pm2中的二阶正交多项式模型的信息，注意- </strong></p><ol class=""><li id="d25c" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">由于目标(销售)的p值&lt;&lt;&lt; 0.05 (see in the last line of output)</li><li id="ea32" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">From the coefficients section, it is clear that all coefficients are statistically significant since p-value &lt;&lt;&lt; 0.05</li><li id="81dd" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">This third order orthogonal polynomial model in two variables after removing third order of TV predictor explains <strong class="jk ke"> 92.93% </strong>可变性相对于二阶正交多项式回归模型是一个更好的指示，因此所创建的模型具有统计显著性。</li><li id="b798" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated"><strong class="jk ke">模型的剩余标准误差</strong>为<strong class="jk ke"> 1.401 </strong></li></ol><p id="b813" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">再次检查调整后的R平方的改善是否具有统计显著性- </strong></p><p id="6087" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">也就是说，我们想要测试零假设— <strong class="jk ke"> H0:调整后的R平方的改善在统计上并不显著。</strong></p><p id="04f8" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">对比另一个假设— <strong class="jk ke"> H1:调整后的R平方的改善具有统计学意义。</strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="60c8" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Performing ANOVA to test the above stated null hypothesis</strong><br/>anova(pm1 , pm3)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lh"><img src="../Images/4c64c99927e9fa6f07426b31ad870d17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PGS__2xLkgSNf1sB_uFvOA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 31 </strong></figcaption></figure><p id="c9a9" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">在上面的输出中，<strong class="jk ke">注意第二行最后一列的值</strong>。该值(<strong class="jk ke"> 0.004968654 </strong>)表示检验零假设的<strong class="jk ke"> p值</strong>。由于该值远小于0.05，因此我们有足够的数据证据来拒绝零假设并接受替代方案。</p><p id="0316" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">这就是调整后的R平方的改善具有统计学意义的原因。</strong></p><p id="d2fe" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">因此，<strong class="jk ke">现阶段采用三阶正交多项式模型，无三阶TV预测器。</strong></p><p id="02ff" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">我们将进一步讨论这一模型。</strong></p><blockquote class="mi mj mk"><p id="b3b8" class="ji jj ly jk b jl kf jn jo jp kg jr js ml kh ju jv mm ki jx jy mn kj ka kb kc hb bi translated"><strong class="jk ke">因此，你必须删除它和 <strong class="jk ke"> <em class="hi">去与二阶电视和三阶收音机只</em> </strong> <em class="hi">。之后你不能再增加订单了。</em></strong></p></blockquote><h1 id="c8fd" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">诊断图-</h1><p id="61cb" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">现在，再次检查线性回归的所有假设是否得到满足。</p><p id="6418" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查线性假设- </strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="fb59" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Residual Plot</strong><br/>plot(pm3 , 1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mo"><img src="../Images/7e6ae2d40b608733c0a15b2935eac90b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pQ5vEFEHcIA7Q9Vj3hNBVA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 32 </strong></figcaption></figure><p id="fbb1" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">以上剧情预告- </strong></p><ol class=""><li id="c941" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">红线近似水平，在残差= 0时是线性的，这表明<strong class="jk ke">线性假设在</strong>中成立。</li><li id="e9ad" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">残差在残差= -4到+4之间的范围内以随机方式波动，这表明拟合模型在某种程度上有利于预测。<strong class="jk ke">为什么在某种程度上？</strong></li><li id="1f4e" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">因为我们再次看到点<strong class="jk ke"> 131 </strong>(注意:151现在与其他点在一起)可能是潜在的<strong class="jk ke">异常值</strong>，因为它离其他点非常远。</li></ol><p id="436f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查同质性假设- </strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="eadc" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Score Test for Heteroscedasticity</strong><br/>ols_test_score(pm3)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mp"><img src="../Images/24fe29170419902d5fa11e581c8338d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jeTDKgS6GADHqOmSYUvdzA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 33 </strong></figcaption></figure><p id="7ddd" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">误差具有恒定方差，p值&gt; 0.05 </em></p><p id="93e7" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查自相关假设- </strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="4f10" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Checking effect of Auto-correlation</strong><br/>durbinWatsonTest(pm3)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lz"><img src="../Images/1d90840ed9030f6be6ed560f3bc07332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*83fO4YuhNrfODCOSg4xKFg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 34 </strong></figcaption></figure><p id="0cbc" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">误差是不相关的。</p><p id="b243" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查正态假设- </strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="151d" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Checking Normality of Errors</strong><br/>shapiro.test(pm3$residuals)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mq"><img src="../Images/ead8d3560c1524b44d26ed6daf09d3c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FmbxLBNAXHY01pAdG2FADw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 35 </strong></figcaption></figure><p id="7796" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">误差正态分布。</em></p><p id="3a48" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">检查多重共线性- </strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="3c04" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Detecting Multicolinearity</strong><br/>vif(pm3)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mb"><img src="../Images/02a9530ea4673f861b3447738540a766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yr0BBkaSfBXdGZFuF3RiYA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 36 </strong></figcaption></figure><p id="aaa2" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">请注意，上述输出的最后一列中的所有值都小于5(根据经验法则)，因此不存在多重共线性。</em></p><p id="6f9b" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">从列车数据集中删除131号观察值- </strong></p><p id="3510" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">现在，我们只有一个选择，即从训练数据集中删除观测值131，因为它具有较大的残差(参见:pm3对象的残差图),并检查调整后的R平方是否显著提高。如果是，则删除它，否则也包括观察编号131。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="b74f" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Creating Diagnostic metrics Table for model pm3</strong><br/>dm = augment(pm3)<br/><br/><strong class="kz ke"># See the Table</strong><br/>head(dm)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mr"><img src="../Images/4666c46644f54f6644991dcc5fcac9a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wlhuzd2GGjGK73ykHgBRqA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 37 </strong></figcaption></figure><p id="a93c" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">从上面的输出中注意到- </strong></p><ol class=""><li id="d627" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">该表包含不同诊断指标的信息，如残差(列9)、库克距离(列12)和学生化残差(列13)等。</li><li id="5580" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">我将使用上表的最后一列删除131号观察值。</li></ol><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="a1ac" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Checking minimum value of last column (Studentized Residual)</strong><br/>min(dm$.std.resid)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ms"><img src="../Images/54284f7e31fe1bbccb9e76cf5693d524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rskvI88WQ4D0r_AsBxJTIQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 38 </strong></figcaption></figure><p id="2f46" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">学生化残差的上述值小于-3(经验法则)，因此表示异常值。</strong>因此，只需移除如下观察值-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="f679" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Checking the index of that observation in train data</strong><br/>which(dm$.std.resid  %in% "-3.4452042988145")</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div class="er es mt"><img src="../Images/939e81cacd4ae3d48b26613dafb7a2fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*amicu8c4Ybz8mLyWBMZHfQ.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 39 </strong></figcaption></figure><p id="5dd2" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">上述输出表明异常值位于训练数据集中的索引98处。</strong>只需检查该行的完整信息，如下所示-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="e504" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Info. about 98th row of train data set</strong><br/>train.data[98,]</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mg"><img src="../Images/10f36f3f37b50dbae7cca0ca9bab0f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-HBuSkoc6n310ws_UBXWkg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 40 </strong></figcaption></figure><p id="a5af" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">这是我们的目标。我们必须把它从我们的训练数据集中删除。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="f532" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Removing 98th row of outlier</strong><br/>train.data1 = train.data %&gt;% filter(train.data$Sales !=  1.6)<br/><br/><strong class="kz ke"># Checking number of rows in old train data set</strong><br/>nrow(train.data)<br/><br/><strong class="kz ke"># Checking number of rows in new train data set (train.data1)</strong><br/>nrow(train.data1)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mu"><img src="../Images/18ec3e17e7cb4794c577434402602427.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dbk7qsdWxfvgwHeQdvj2uw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 41 </strong></figcaption></figure><p id="5be7" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">已成功移除一个观察。</strong></p><p id="48e0" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">现在，再次拟合存储在pm3中的相同多项式模型，但使用存储在R-object <strong class="jk ke"> train.data1 - </strong>中的数据</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="547a" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"><em class="ly"># Fitting third order (orthogonal) polynomial model in two variables to avoid multicolinearity but after removing third order of TV predictor using train.data1</em></strong><br/>pm4 &lt;- lm(Sales ~ poly(TV , 2) + poly(Radio , 3) + TV:Radio  , data = train.data1)<br/><br/><strong class="kz ke"># Take a look on summary of the model</strong><br/>summary(pm4)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es md"><img src="../Images/1e7f552026f3bcc514d0082824c1c8ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_PWF1xMbsz0sfIsCD_iXVw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 42 </strong></figcaption></figure><p id="544c" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">根据上述输出，并使用存储在R对象pm3中的二阶正交多项式模型的信息，注意- </strong></p><ol class=""><li id="f6b6" class="kk kl hi jk b jl kf jp kg hs km hw kn ia ko kc kp kq kr ks bi translated">由于目标(销售)的p值&lt;&lt;&lt; 0.05 (see in the last line of output)</li><li id="dd9e" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">From the coefficients section, it is clear that all coefficients are statistically significant since p-value &lt;&lt;&lt; 0.05</li><li id="35bd" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated">This polynomial model after removing the outlier explains <strong class="jk ke"> 93.21% </strong>可变性相对于存储在R-object pm3中的多项式回归模型是一个更好的指示，因此创建的模型pm4具有统计显著性。</li><li id="c9fd" class="kk kl hi jk b jl kt jp ku hs kv hw kw ia kx kc kp kq kr ks bi translated"><strong class="jk ke">模型的残差标准误差</strong>为<strong class="jk ke"> 1.347 </strong></li></ol><blockquote class="mi mj mk"><p id="d681" class="ji jj ly jk b jl kf jn jo jp kg jr js ml kh ju jv mm ki jx jy mn kj ka kb kc hb bi translated"><strong class="jk ke">在这种情况下。由于我们注意到调整后的R平方增加了，剩余标准误差减少了，因此我们可以采用存储在pm4中的模型。</strong></p></blockquote><p id="7021" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">现在，快速检查所有其他假设- </strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="e856" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Linearity Assumption</strong><br/>plot(pm4 ,1)<br/><br/><strong class="kz ke"># Homoscedasticity Assumption </strong><br/>ols_test_score(pm4)<br/><br/><strong class="kz ke"># Autocorrelation Assumption</strong><em class="ly"> </em><br/>durbinWatsonTest(pm4)<br/><br/><strong class="kz ke"># Normality Assumption</strong><br/>shapiro.test(pm4$residuals)<br/><br/><strong class="kz ke"># Multicolinearity Assumption</strong><br/>vif(pm4)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mp"><img src="../Images/be69bef1f6d34111efc3c0fd1c48abb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xMus_BGmRIGPQ8yTaWnyYA.png"/></div></div></figure><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mv"><img src="../Images/14df070031620bde9dc1de0c0cbdf1f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HXX0a4SGjGxsCCRUUnJPXQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 43 </strong></figcaption></figure><p id="13b3" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">现在所有的假设都得到了满足。</em></p><p id="cdb0" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">通过为模型pm4创建诊断度量表再次检查异常值- </strong></p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="585d" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Creating Diagnostic metric table for model pm4</strong><br/>dm1 = augment(pm4)<br/><br/><strong class="kz ke"># Checking minimum and maximum value of studentized residual</strong><br/>min(dm1$.std.resid)<br/>max(dm1$.std.resid)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mb"><img src="../Images/caf5085661be1acbd7895680df6f8c78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U6O5MlSJVNhWMoTYlxo96g.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 44 </strong></figcaption></figure><p id="3870" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><em class="ly">以上输出表明，学生化残差的绝对值不大于3(经验法则)。因此，不存在潜在的异常值。</em></p><p id="6d6f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated"><strong class="jk ke">最后，采用这个模型(存储在R-object pm4中)进行预测。</strong></p><h1 id="b487" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">8.做预测-</h1><p id="fbb7" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">现在，是时候对测试数据集(看不见的数据)进行预测，并检查模型的性能，如下所示-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="f850" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Making Predictions</strong><br/>prediction = pm4 %&gt;% predict(test.data)<br/><br/><strong class="kz ke"># Checking performance by calculating R2 , RMSE and MAE</strong><br/>data.frame( R2 = R2(prediction, test.data$Sales),<br/>            RMSE = RMSE(prediction, test.data$Sales),<br/>            MAE = MAE(prediction, test.data$Sales))</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mw"><img src="../Images/3235f05413024be7c714a72daa62fee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f_diUU-84dshxmNUaTk9xQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated"><strong class="bd hj">输出— 45 </strong></figcaption></figure><p id="d18c" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">我们得到:R = 0.9526385，这表示最佳拟合。</p><p id="bde5" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">因为，这个结果仅仅基于一个测试数据集。因此，我们不能确定该模型对所有未知数据都有更好的表现。为了在这方面更加自信，我们将使用重复K-fold交叉验证的方法在不同的测试数据集上测试模型的性能。</p><p id="a7ed" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">这将按如下方式进行</p><h1 id="5e26" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">9.重复10重交叉验证</h1><p id="214d" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">在执行交叉验证之前，只需删除被标识为异常值的观察值，即包含Sales = 1.6的行</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="0eef" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Removing outlier, i.e., the row that contains Sales = 1.6</strong><br/>data &lt;- data %&gt;% filter(Sales != 1.6)</span></pre><p id="effa" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">现在，执行如下交叉验证-</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="7d64" class="hg hh hi kz b fi ld le l lf lg"><strong class="kz ke"># Define training control</strong><br/>set.seed(123)<br/>train.control &lt;- trainControl(method = "repeatedcv", <br/>                              number = 10, repeats = 3)<br/><strong class="kz ke"># Train the model</strong><br/>model_cv &lt;- train(Sales ~ poly(TV , 2) + poly(Radio , 3) + TV:Radio , data = data, method="lm",<br/>                  trControl = train.control)<br/><br/><strong class="kz ke"># Summarize the results</strong><br/>print(model_cv)</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es mx"><img src="../Images/ec450ebdfd5814e6f65c94c2942271b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PnR6D_oeHMx9H6uqjoqcVQ.png"/></div></div></figure><h1 id="1a38" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">伟大的结果！</h1><p id="c9ca" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated"><strong class="jk ke">平均而言，该正交多项式回归模型(存储在R-object pm4中)捕获了目标(销售)中93.69%的可变性。也就是说，销售中93.69%的可变性是由于预测器“电视”和“收音机”。休息可变性是由于随机原因或可能是由于一些其他原因。</strong></p><h1 id="822d" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">10.结论-</h1><p id="fd3f" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">最后，我想在这里总结一下。<strong class="jk ke">我从简单线性回归的拟合开始，然后向您展示该模型会出现什么问题，然后为了消除该问题，您必须如何进行多元线性回归模型。在那之后，我已经向你展示了你将如何了解如何进行正交多项式回归。我还包括了不同的统计测试、诊断图、诊断指标，以准备一个更好的基本模型，根据给定的电视、广播和报纸广告预算来预测销售。</strong></p><p id="8e8b" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">更进一步，<strong class="jk ke">我想在这里提一下，这并不是结束。这只是一个开始，这就是为什么我之前说我已经为给定的数据集准备了一个更好的基本模型。有一些先进的算法，如样条拟合(参数算法)和许多非参数算法，如决策树，随机森林，支持向量机等..其可以处理曲线关系并可以给出更精确的结果。所以你必须进一步学习和尝试这些先进的算法，以提高和获得更多的准确性以及该领域的知识</strong>。</p><p id="a66f" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">为了更好的理解，你自己做一次就好了！</p><h1 id="9fb5" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated"><strong class="ak"> 11。给你的任务(如果感兴趣)- </strong></h1><p id="f249" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">如果你想做更多的练习，我推荐你做这个<a class="ae kd" href="https://www.kaggle.com/pranjalpandey12/advertising-tricky-data-set/download" rel="noopener ugc nofollow" target="_blank"> <strong class="jk ke">广告数据集</strong> </a>。该数据集需要更多与残差图相关的分析工作。在处理该数据集之前，请阅读<a class="ae kd" href="http://home.iitk.ac.in/~shalab/regression/Chapter4-Regression-ModelAdequacyChecking.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jk ke">中的残差分析概念，此处</strong> </a> <strong class="jk ke"> </strong>(第18至20页)，然后应用简单、多元和多项式回归并分析诊断图。</p><h1 id="522e" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">12.关于下一篇文章的信息-</h1><p id="be99" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">只需保存在执行交叉验证时获得的完全无异常值的数据，并保存存储在<strong class="jk ke"> train.data1 </strong>和<strong class="jk ke"> test.data </strong>中的分割数据，即可阅读我的下一篇文章，名为<strong class="jk ke">multicolines/Ridge/Lasso/Elastic-Net Regression using R</strong>。我将在下一篇文章中使用相同的离群自由数据集来理解更多的概念。</p><pre class="ig ih ii ij fd ky kz la lb aw lc bi"><span id="4846" class="hg hh hi kz b fi ld le l lf lg"><em class="ly"># Saving outlier free data set stored in R-object data</em><br/>write.csv(data , "Outlier Free Data Set.csv" , row.names = F)<br/><br/><em class="ly"># Saving outlier free train data set stored in R-object train.data1</em><br/>write.csv(data , "Outlier Free Data Set.csv" , row.names = F)<br/><br/><em class="ly"># Saving test data set stored in R-object test.data</em><br/>write.csv(data , "Outlier Free Data Set.csv" , row.names = F)</span></pre><h1 id="ca71" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">感谢阅读我的文章。</h1><p id="c8e1" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">我的kaggle笔记本— <a class="ae kd" href="https://www.kaggle.com/pranjalpandey12/simple-to-multiple-and-polynomial-regression-in-r" rel="noopener ugc nofollow" target="_blank"> <strong class="jk ke">点击</strong> </a></p><p id="4c18" class="pw-post-body-paragraph ji jj hi jk b jl kf jn jo jp kg jr js hs kh ju jv hw ki jx jy ia kj ka kb kc hb bi translated">如果你发现任何错误，请告诉我。</p></div></div>    
</body>
</html>