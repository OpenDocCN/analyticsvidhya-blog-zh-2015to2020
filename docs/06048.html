<html>
<head>
<title>ML Model Interpretability — LIME</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML模型可解释性—石灰</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/model-interpretability-lime-part-2-53c0f5e76b6a?source=collection_archive---------5-----------------------#2020-05-10">https://medium.com/analytics-vidhya/model-interpretability-lime-part-2-53c0f5e76b6a?source=collection_archive---------5-----------------------#2020-05-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ec58bbfda17a48c5ca7fda006efb3550.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WlXZX91Y4UBQ3y0E"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">格伦·卡丽在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</figcaption></figure><h1 id="b712" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">介绍</h1><p id="2396" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">在我早先的<a class="ae iu" rel="noopener" href="/@sand.mayur/why-should-i-trust-your-model-bdda6be94c6f">文章</a>中，我描述了为什么更需要理解机器学习模型以及其中的一些技术。我还详细解释了如何使用ELI5来更深入地了解模型。</p><p id="ad87" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在本文中，我将详细讨论另一种技术— <a class="ae iu" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">石灰</a></p><h1 id="0552" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">LIME(局部可解释的模型不可知解释)</h1><p id="b42d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">莱姆被提议作为论文“我为什么要相信你？”:解释任何分类器的预测”发表于2016年8月，作者:<em class="kw">马尔科·图利奥·里贝罗、萨米尔·辛格、卡洛斯·盖斯特林。它有两个Python的库。</em></p><h2 id="5fcb" class="kx iw hi bd ix ky kz la jb lb lc ld jf ke le lf jj ki lg lh jn km li lj jr lk bi translated">直觉</h2><blockquote class="ll lm ln"><p id="a256" class="jt ju kw jv b jw kr jy jz ka ks kc kd lo kt kg kh lp ku kk kl lq kv ko kp kq hb bi translated">局部:解释为什么单个数据点被分类为特定的类</p><p id="0ee8" class="jt ju kw jv b jw kr jy jz ka ks kc kd lo kt kg kh lp ku kk kl lq kv ko kp kq hb bi translated">模型不可知:将模型视为黑盒。不需要知道它是如何预测的</p></blockquote><p id="1bb6" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">所有处理大数据的深度学习模型都需要处理大量特征才能准确预测。深度学习模型生成的n维曲线非常复杂，难以理解和解释。</p><p id="7b54" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">LIME建议专注于局部解释，而不是提供全局模型解释。我们可以放大模型中的数据点，然后可以详细地找到哪些特征影响了模型，从而得出某些结论。</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/b81de5cebfe3811a335def7bd6d0f17b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*PdzQboG2-jFMTGFWmBoGOQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">LIME是模型不可知的</figcaption></figure><p id="c147" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">LIME不关心你正在使用的ML模型(现在或将来)。它会将其视为黑盒，并专注于解释本地结果。</p><h2 id="7ca8" class="kx iw hi bd ix ky kz la jb lb lc ld jf ke le lf jj ki lg lh jn km li lj jr lk bi translated">石灰是如何工作的</h2><p id="fcb9" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">对于给定的观察值<strong class="jv hj"> </strong>:</p><ol class=""><li id="b631" class="lw lx hi jv b jw kr ka ks ke ly ki lz km ma kq mb mc md me bi translated">置换数据-通过从在训练数据上学习的分布中取样，在观察值周围创建新的数据集<strong class="jv hj"> </strong>(在扰动的数据集中，基于分布挑选数字特征&amp;基于出现的分类值)</li><li id="b874" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mb mc md me bi translated">计算排列和原始观察值之间的距离</li><li id="888b" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mb mc md me bi translated">用模型预测新点上的概率<strong class="jv hj"> </strong>，那就是我们新的<strong class="jv hj"> y </strong></li><li id="6af3" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mb mc md me bi translated">从置换数据中挑选最能描述复杂模型结果的m个特征</li><li id="77f2" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mb mc md me bi translated">对通过相似性加权的m个维度中的数据拟合线性模型</li><li id="dc73" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mb mc md me bi translated">线性模型的权重<strong class="jv hj"> </strong>用于解释决策</li></ol><p id="e53f" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj">如何在python中使用这个库</strong></p><p id="cd7a" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们将使用银行营销数据集— <a class="ae iu" href="https://archive.ics.uci.edu/ml/datasets/bank+marketing" rel="noopener ugc nofollow" target="_blank">链接</a>。所有数据分析步骤都在<a class="ae iu" rel="noopener" href="/@sand.mayur/why-should-i-trust-your-model-bdda6be94c6f">前一篇文章</a>中提到。使用这个数据集，我们将为线性回归、决策树、随机森林&amp; Light GBM建立模型(参考<a class="ae iu" href="https://github.com/mayur29/Machine-Learning-Model-Interpretation" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的代码)。</p><p id="c228" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在创建了我们的模型之后，我们将通过使用<code class="du mk ml mm mn b">LimeTabularExplainer</code>实例化一个新的<code class="du mk ml mm mn b">explainer</code>来开始使用LIME。这些论点是</p><ul class=""><li id="0316" class="lw lx hi jv b jw kr ka ks ke ly ki lz km ma kq mo mc md me bi translated">将带有分类值的训练数据转换为LIME格式</li><li id="7200" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mo mc md me bi translated">指定一个<code class="du mk ml mm mn b">mode</code>回归或分类</li><li id="9b46" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mo mc md me bi translated"><code class="du mk ml mm mn b">feature_names</code>:您的列的名称列表</li><li id="3af6" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mo mc md me bi translated"><code class="du mk ml mm mn b">categorical_names</code>:我们的字典将分类特征映射到它们可能的值</li><li id="3608" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mo mc md me bi translated"><code class="du mk ml mm mn b">categorical_features</code>:分类特征索引列表</li></ul><pre class="ls lt lu lv fd mp mn mq mr aw ms bi"><span id="1c45" class="kx iw hi mn b fi mt mu l mv mw">explainer = LimeTabularExplainer(<br/>convert_to_lime_format(X_train,categorical_names).values,<br/>                   mode="classification",<br/>                   feature_names=X_train.columns,<br/>                   categorical_names=categorical_names,<br/>                   categorical_features=categorical_names.keys(),<br/>                   random_state=42)</span></pre><p id="8af4" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们将选择一行来解释结果</p><pre class="ls lt lu lv fd mp mn mq mr aw ms bi"><span id="943a" class="kx iw hi mn b fi mt mu l mv mw">i = 4<br/>print(X_test.iloc[i])</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es mx"><img src="../Images/4680f4dcebcee20d9bc57e10496db46c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*Nib6hCLs6_aXMoG7cEZR3A.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">为本地解释选择的行</figcaption></figure><p id="b55d" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">现在，我们将在这一行上为我们的4个模型中的每一个运行解释</p><pre class="ls lt lu lv fd mp mn mq mr aw ms bi"><span id="b753" class="kx iw hi mn b fi mt mu l mv mw">explanation = explainer.explain_instance(observation, lr_predict_proba, num_features=5)</span><span id="787a" class="kx iw hi mn b fi my mu l mv mw">explanation.show_in_notebook(show_table=True, show_all=False)</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mz"><img src="../Images/03368aaea5cc989046ed9dcfe69db9b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j0uZUrhkBgIod8HAv3PvSQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">逻辑回归因素的解释</figcaption></figure><p id="b4af" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">中心图显示了与线性模型的权重相对应的顶部特征对预测的贡献。因此，对于这位客户来说，subscribed的值是真实的，因为他是在6月份通过电话联系的。事实上，他在这次竞选中接触了3次以上，这可能是一个负面因素。</p><p id="30c9" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">LIME正在对本地数据集拟合线性模型。通过调用以下函数，可以找到线性模型的系数、截距和R平方</p><pre class="ls lt lu lv fd mp mn mq mr aw ms bi"><span id="f68c" class="kx iw hi mn b fi mt mu l mv mw">print(explanation.local_exp)<br/>print(explanation.intercept)<br/>#R2 score<br/>print(explanation.score)</span></pre><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/7b3fa6d7a5880f0416ce73143c768ecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nccc870w15JvUwFQkOKSMg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">线性模型信息</figcaption></figure><p id="00bc" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">人们可以注意到上图中描述的权重是local_exp的值。线性回归模型的R2分数相当糟糕。</p><p id="9c90" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们还尝试了LightGBM模型，下面是结果</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nb"><img src="../Images/bc01d8943d1fe261d711326e3990a145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NOUrbOFYiiFH5owJuaEt_w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">LightGBM结果</figcaption></figure><h2 id="2700" class="kx iw hi bd ix ky kz la jb lb lc ld jf ke le lf jj ki lg lh jn km li lj jr lk bi translated">石灰的缺点</h2><ol class=""><li id="ecd9" class="lw lx hi jv b jw jx ka kb ke nc ki nd km ne kq mb mc md me bi translated"><strong class="jv hj">依赖于随机抽样的</strong>新点，所以它可能不稳定</li><li id="3343" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mb mc md me bi translated">线性模型拟合可能不准确</li><li id="e5ea" class="lw lx hi jv b jw mf ka mg ke mh ki mi km mj kq mb mc md me bi translated">图像处理速度很慢</li></ol><h1 id="27ff" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">结论</h1><p id="1000" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">LIME是理解黑盒模型的好工具。人们不需要花费太多精力来寻找影响模型决策的特征的细节。它独立于现在或将来使用的模型运行。你可以在我的<a class="ae iu" href="https://github.com/mayur29/Machine-Learning-Model-Interpretation" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到代码</p><p id="ee93" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">如果你有任何关于酸橙的问题，让我知道乐意帮忙。如果你想收到我博客上的更新，请在<a class="ae iu" rel="noopener" href="/@sand.mayur"> Medium </a>或<a class="ae iu" href="https://www.linkedin.com/in/mayursand/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我！</p></div></div>    
</body>
</html>