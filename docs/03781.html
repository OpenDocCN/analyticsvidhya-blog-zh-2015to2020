<html>
<head>
<title>Understanding Machine Learning Algorithms — Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解机器学习算法—逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-machine-learning-algorithms-logistic-regression-362fa68e5284?source=collection_archive---------18-----------------------#2020-02-18">https://medium.com/analytics-vidhya/understanding-machine-learning-algorithms-logistic-regression-362fa68e5284?source=collection_archive---------18-----------------------#2020-02-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/91d386b159259dca5a8344cd932e9145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qQpsqRwiGFalarSrCOt6ig.png"/></div></div></figure><p id="cb58" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">逻辑回归是一种分类算法。不要被它的名字弄糊涂了。逻辑回归有多种解释</p><ol class=""><li id="0959" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">概率解释</strong></li><li id="2ba4" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">几何解释</strong></li><li id="a9c9" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">损失函数解释</strong></li></ol><h1 id="5c1b" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">你会学到什么？</h1><p id="88bf" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">在这个博客中，我们将重点放在几何解释，我们从第一原理推导逻辑回归</p><ol class=""><li id="b8d3" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">几何直觉</strong></li><li id="a459" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">理解逻辑回归背后的数学原理</strong></li><li id="0377" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">时间和空间复杂度</strong></li><li id="a8dc" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">调整、过拟合和欠拟合</strong></li><li id="debb" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">当我们有异常值时它是如何工作的</strong></li><li id="9959" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">特征重要性、可解释性和多重共线性</strong></li></ol></div><div class="ab cl lf lg gp lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hb hc hd he hf"><h2 id="a400" class="lm kd hi bd ke ln lo lp ki lq lr ls km jb lt lu kq jf lv lw ku jj lx ly ky lz bi translated">1.几何直觉</h2><p id="c621" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated"><strong class="is hj">如果我们的数据线性可分或几乎线性可分，那么我们可以应用逻辑回归，否则我们不能应用逻辑回归</strong></p><p id="c48f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">作为数据集的一个例子，我在这里举了一些评论(产品评论)，我们都知道有正面评论和负面评论，它们都是混淆的。在2D，如果有任何一条线将它们分成负面或正面评论，我们称之为3D线和面。</p><figure class="mb mc md me fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/abad6d30482171ae29f38ba6ba1776e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*kgjzBXfXYvpD7nIpokyS9Q.png"/></div></figure><p id="4510" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们所见，上述数据可以线性分离(除了对我们来说没问题的少数数据点，我们都知道2D的线是<strong class="is hj"> <em class="mf"> y = mx+c </em> </strong>(其中<em class="mf"> c是截距，m是斜率</em>)。在逻辑回归中，分隔正点或负点的线称为<strong class="is hj">决策边界</strong></p><p id="584a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">3D中的直线只不过是超平面，其中b是截距项，w垂直于平面</strong></p><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/6d98a65d073f810097c28b00ccadf11e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zRMKPu3vDtBX8j1qDmnU4Q.png"/></div></div></figure><blockquote class="mh mi mj"><p id="f614" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">如果平面(pi)通过原点b=0 </strong>，那么我们就简单了</p></blockquote><figure class="mb mc md me fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/e2bb8bf98739fb0c73deeee5ed6a510a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*0RSb1UrSAozTScNl-xlPRQ.png"/></div></figure><blockquote class="mh mi mj"><p id="1ada" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">任务:</strong>逻辑回归中的任务是找到已经给定的<strong class="is hj"> w </strong>和<strong class="is hj">b</strong><strong class="is hj">x</strong>(x是正或负的数据点)找到对应于平面的<strong class="is hj"> w </strong> &amp; <strong class="is hj"> b </strong>使得该平面将正的点与负的点分开</p></blockquote><h2 id="999c" class="lm kd hi bd ke ln lo lp ki lq lr ls km jb lt lu kq jf lv lw ku jj lx ly ky lz bi translated"><strong class="ak"> 2。理解逻辑回归背后的数学原理</strong></h2><p id="1bb8" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">现在，我们了解了逻辑回归中的任务，我们必须为每个数据点找到<strong class="is hj"> w和b </strong>来分隔正负数据点</p><blockquote class="mh mi mj"><p id="b177" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated">我们将+1视为正数据点，将-1视为负数据点，并且我们正在计算每个数据点离平面的距离(d)</p></blockquote><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/4febf774ff5f434a255548938da39842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iQBmSd0_MBrfF0R8AkwlPg.jpeg"/></div></div></figure><figure class="mb mc md me fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/a4eea1b2f4cc61aa834c108548370090.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*93zGiFGkgmXZPss1iCV0KQ.png"/></div></figure><blockquote class="mq"><p id="febf" class="mr ms hi bd mt mu mv mw mx my mz jn dx translated"><strong class="ak">如果W转置x大于零，那么它是一个正点y=1 </strong></p></blockquote><figure class="nb nc nd ne nf ij er es paragraph-image"><div class="er es na"><img src="../Images/5ffa869c3cc20b10f9b1f04d0b63b1c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*qJCXQft_I2Ru6seO5-OgrA.png"/></div></figure><blockquote class="mq"><p id="cea2" class="mr ms hi bd mt mu mv mw mx my mz jn dx translated">如果W转置x小于零，那么它是一个负点y=-1</p><p id="0564" class="mr ms hi bd mt mu ng nh ni nj nk jn dx translated">请注意，平面经过原点，这就是为什么我们没有在这里加b</p></blockquote><h2 id="9cec" class="lm kd hi bd ke ln nl lp ki lq nm ls km jb nn lu kq jf no lw ku jj np ly ky lz bi translated">问:我们如何知道数据点被正确分类？</h2><figure class="mb mc md me fd ij er es paragraph-image"><div class="er es nq"><img src="../Images/197676eceed481099677acc573f03b00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*6ZTkMTDjI4I0Lu2MWIASVQ.png"/></div></figure><h2 id="b240" class="lm kd hi bd ke ln lo lp ki lq lr ls km jb lt lu kq jf lv lw ku jj lx ly ky lz bi translated">问:但是失败在哪里？</h2><p id="b9ee" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">当我们的数据集中有异常值时，我们在这里计算距离。如果我们计算的距离是异常值和错误分类的数据点，那么我们的整个平面都会受到影响。请看下面的例子</p><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nr"><img src="../Images/e7f5689186a51b430ede841e0687623f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xe9vJPRYi2eF5Aripxipiw.jpeg"/></div></div></figure><p id="e871" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里一个离群点影响整个平面本身，它改变了超平面或模型。</p><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ns"><img src="../Images/432ea0d9efff106f1679c0e6d785683b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F3OMiJk5KLH-I3_7AHRRZg.jpeg"/></div></div></figure><p id="5e08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们要摆脱谁呢？每个数据集或每个现实世界的问题中总会有一些异常值，我们必须以某种方式修改这个公式，它也适用于异常值</p><blockquote class="mq"><p id="80e4" class="mr ms hi bd mt mu ng nh ni nj nk jn dx translated"><strong class="ak"> Sigmoid函数:-</strong>Sigmoid函数的思想是，如果距离很小，不使用相同的距离，而是使用相同的距离，如果距离很大，则将距离变小并使用它。</p></blockquote><figure class="nb nc nd ne nf ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nt"><img src="../Images/4877d89ce21f50bf767a650b85d658ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-T9ykgInQzpk7SmqdtZu4g.png"/></div></div></figure><p id="245c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 1。最小值为0 </strong></p><p id="7ff2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2。x最大值的Sigmoid为1 </strong></p><p id="76ce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3。当距离为零时，sigmoid函数值为0.5 </strong></p><p id="5d21" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">我们如何让距离变小？</strong> <br/>这里我们对每个点使用Sigmoid函数，它使上图中的每个数据点都有一些小值，这些数据点称为z，但这里我认为是x</p><figure class="mb mc md me fd ij er es paragraph-image"><div class="er es nu"><img src="../Images/621923802c740f107bd414bbf14a90c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*nhbQ6NqmqiDj2AXy3G7HAg.png"/></div></figure><p id="d83c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">其中-x是数据点，对于每个数据点，我们将应用Sigmoid函数</strong></p><p id="0ac8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">问:为什么只使用Sigmoid函数，不使用其他函数？</strong></p><p id="a178" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种性质的函数有很多，但我们使用Sigmoid函数是因为</p><ol class=""><li id="6c84" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">它有一个概率解释</strong></li><li id="64dc" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">很容易可微</strong></li></ol><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nv"><img src="../Images/1df4622c123afe4ada418cfa8e5f050a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YsqmCqn-sO1QVACxK2eH1w.png"/></div></div></figure><p id="9a72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们正在计算由Sigmoid函数转换的点的距离，Sigmoid函数的整体思想是去除异常值。</p><p id="3aa4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了简化，我们采用<strong class="is hj"> Log </strong>，因为它是一个单调函数。单调函数以直观的方式如果x增加g(x)也增加</p><p id="c6e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">问:为什么我们应该只使用日志功能，而不使用其他功能？</strong></p><p id="6bd5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过使用log()，我们将使用几何方法获得的目标函数转换为与使用概率和损失最小化方法获得的逻辑回归相同的格式</p><p id="995f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">log()用于使目标函数凸起，以便于优化</strong></p><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nw"><img src="../Images/ad41cd926aa1d586c3340b6dbb1496a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MUAPYoioZ1yd-JwZdXYejw.png"/></div></div></figure><p id="6b0f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">这是我们最后的优化问题</strong></p><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nx"><img src="../Images/ac0cec6d903fbcb62255279e0f560b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tAhPMXcZd7brFDwI2db1jg.png"/></div></div></figure><h2 id="dc6a" class="lm kd hi bd ke ln lo lp ki lq lr ls km jb lt lu kq jf lv lw ku jj lx ly ky lz bi translated">3.时间和空间复杂性</h2><p id="467f" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">当我们在生产中使用机器学习项目时，训练、运行时间和时间复杂性很重要</p><blockquote class="mh mi mj"><p id="b7d6" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">训练逻辑回归:- </strong>训练逻辑回归无非是解决优化问题，确切地说是找到最佳的W。它大约是O(nd ),其中n是d-train中的点数，d是数据的维数</p><p id="b713" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">运行时间:- </strong>运行时间复杂性更重要，因为在现实世界中，当任何新数据点出现时，我们必须对其进行分类，无论它是正的还是负的。从逻辑回归的训练中，我们仅获得向量W=[w1，w2，w3，w4…..wn]它是d维的，我们把新的数据点乘以W</p></blockquote><figure class="mb mc md me fd ij er es paragraph-image"><div class="er es ny"><img src="../Images/ec21ded907d4e1c42a7a7f233eeae93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*fYDhAv20FhpTNm3LbcRgdQ.png"/></div></figure><p id="25cc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">时间复杂度也是O(d)我们必须用维向量W来计算</strong></p><blockquote class="mh mi mj"><p id="4434" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">当维度很小时？</strong></p><p id="2280" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated">当我们的维数很小时，逻辑回归工作得相当好，但它太快了。当维数很小时，它是低延迟应用程序的最佳算法</p><p id="f244" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">维度大的时候？</strong></p><p id="282c" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated">当我们的维数是大的逻辑回归时，它必须乘以更多的值，这需要更多的时间，但是，如果我们使用L1正则化，那么大多数无用的特征将为零，因为它产生了稀疏性，所以，我们可以使用L1正则化当维数是大的时，我们必须找到正确的λ</p></blockquote><h2 id="fee0" class="lm kd hi bd ke ln lo lp ki lq lr ls km jb lt lu kq jf lv lw ku jj lx ly ky lz bi translated">4.正则化、过拟合和欠拟合</h2><p id="23c8" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated"><strong class="is hj"> L2正则化:- </strong></p><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nz"><img src="../Images/90238cc7e2f448a869cb5f2888e420e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*La9Hk2tkpCWN8V_h_XDcmg.png"/></div></div></figure><p id="42cd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">现在，让我们看看exp(-z)图将如何</strong></p><figure class="mb mc md me fd ij er es paragraph-image"><div class="er es oa"><img src="../Images/e3821668c5672f399df0f5bc516f3aa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*a7Ui7-ZHsP7j8Ymb7Hp3vg.png"/></div></figure><p id="10d1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我们的目标是找到exp(-z)的最小值，当最小值出现时，当我们的向量z趋于无穷大时，我们将得到最小值</p><ol class=""><li id="f30b" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">给定任何新的查询点，Zi为正，则它将被正确分类</strong></li><li id="13a9" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">当Zi趋于无穷大时，我们得到最小值，这意味着零</strong></li></ol><blockquote class="mh mi mj"><p id="2406" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">对于每个数据点，我们应用上面那些导致过度拟合且趋向于-无穷大或+无穷大的数据点，因此，为了避免这个问题，我们添加了一个称为正则化项的项</strong></p></blockquote><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ob"><img src="../Images/b7b1da1b0df536469c123a924d401421.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OW3BxhpKOYohaUK1cH7hEg.png"/></div></div></figure><p id="4afa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> L1正则化:- </strong></p><figure class="mb mc md me fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oc"><img src="../Images/82540fbcbe6540f093598fa97a8c030c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q2VltpuQSD66QAd2fG5Lng.png"/></div></div></figure><p id="c1f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">L1正则化在向量W中产生稀疏性，这意味着大多数不太重要的特征将为零</p><h2 id="81d7" class="lm kd hi bd ke ln lo lp ki lq lr ls km jb lt lu kq jf lv lw ku jj lx ly ky lz bi translated">5.当我们有异常值时它是如何工作的</h2><p id="ed1b" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">在逻辑回归中，当我们的数据中有异常值时，Sigmoid函数会处理，所以我们可以说它不容易出现异常值。</p><h2 id="2ec3" class="lm kd hi bd ke ln lo lp ki lq lr ls km jb lt lu kq jf lv lw ku jj lx ly ky lz bi translated">6.<strong class="ak">特征重要性、可解释性和多重共线性</strong></h2><p id="2a57" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated"><strong class="is hj">特征重要性:- </strong>选择正确的特征更为重要，因为一旦我们找到正确的特征，模型构建只需将所有正确的特征输入模型并找到超参数。</p><blockquote class="mh mi mj"><p id="a443" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">通过查看权重向量(W ),我们可以知道哪些特征比其他特征更重要。我们如何发现让我们看看？</strong></p><p id="fae8" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated">假设权重向量<strong class="is hj"> Wj </strong>在权重向量<strong class="is hj">中，一些值是正的并且是大的值，那么得到正的概率会更大</strong>，因为我们将权重向量值与对应的数据点相乘</p><p id="74a4" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated">假设我们的权重向量<strong class="is hj"> Wj </strong>在权重向量<strong class="is hj">中，有些值是负值，如果值很大，那么得到负值的概率会更大</strong>，因为我们将权重向量值与对应的数据点相乘</p></blockquote><p id="6067" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">无论是正还是负，无论权重向量值多大，这都是一个更重要的特征，这就是为什么我们采用绝对值权重向量</strong></p><p id="b706" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">| | Wj | | = Fj(特征)对应的权重绝对值</strong></p><blockquote class="mh mi mj"><p id="1ca3" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">如果我们的特征是独立的，那么只有我们可以使用权重向量的绝对值，否则我们不能使用</strong></p><p id="9470" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">模型可解释性:- </strong>通过查看值较大的权重向量值，我们可以说这就是相应数据点为负或为正的原因。我们可以给出为什么它是负的或正的推理，并且模型的可解释性在医学应用中更重要。</p></blockquote><p id="e4c6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">多重共线性:- </strong>直觉上，共线性是指如果我们有一个要素，那么我们通过将第一个要素乘以某个常数值并添加某个值来获得第二个要素，然后我们获得第二个要素，这就是共线性。如果我们的所有要素都是这样，那么它会导致多重共线性</p><p id="24a1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">多重共线性问题:- </strong></p><p id="9c8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.当数据集中存在多重共线性时，我们的权重向量会任意变化，因为要素不再相互独立，因此我们不能使用权重向量作为要素重要性向量</p><blockquote class="mh mi mj"><p id="dd34" class="iq ir mf is b it iu iv iw ix iy iz ja mk jc jd je ml jg jh ji mm jk jl jm jn hb bi translated"><strong class="is hj">要确定我们的特征是否多重共线，有一种方法可以检查扰动技术</strong></p></blockquote><p id="7757" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mf">感谢阅读！</em></p></div></div>    
</body>
</html>