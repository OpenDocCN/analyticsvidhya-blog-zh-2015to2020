<html>
<head>
<title>Functioning of CNN with custom dataset.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN与自定义数据集的功能。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cnn-with-custom-dataset-8cdd153f5c9e?source=collection_archive---------4-----------------------#2020-01-03">https://medium.com/analytics-vidhya/cnn-with-custom-dataset-8cdd153f5c9e?source=collection_archive---------4-----------------------#2020-01-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="5318" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你会在Youtube上找到许多关于CNN运作的文章和视频。写这篇文章背后的想法是改变常规，在现有信息的基础上分享一些额外的信息。<br/>因此，在这个尝试中，解释了卷积神经网络在定制数据集上的功能。文章以问答的形式撰写，涵盖了所有相关的话题以及关于这个话题的常见问题。</p><p id="7651" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你可以使用任何语言Python或R，也可以使用任何库，如Tensorflow、TFlearn或keras等..只要你清楚这个概念，这其实并不重要。</p><p id="d445" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">这篇文章的目的是教你如何使用TFlearn创建自己的数据并将CNN应用于这些数据，我在Google Colab上运行了这段代码。</strong></p><p id="4e3a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">根据定义:<strong class="io hj"> <em class="jk"> TFlearn是构建在Tensorflow之上的模块化、透明的深度学习库。它旨在为TensorFlow提供一个更高级别的API，以促进和加速实验，同时保持完全透明并与之兼容。</em> </strong></p><p id="44fc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> <em class="jk">问:为什么选择CNN？</em>T11】</strong></p><p id="c8ee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> A. </strong> CNN是卷积神经网络，通常用于图像识别。实际好处是，参数越少，学习时间就越短，训练模型所需的数据量也就越少。CNN不是一个由每个像素的权重组成的完全连接的网络，它只有足够的权重来查看一小块图像。</p><p id="79e9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">问:但是为什么要去定制数据呢？ </p><p id="0c70" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">答:</strong>MNIST数据集中会有成千上万篇文章，但在这些预处理过的数据集中，你实际上不知道如何提取新图像并自己创建数据集，调整图像大小，对图像排序并给它们加标签。<br/>安装google_images_download将自定义图片下载到我们的选择中。将此输入cmd。</p><p id="892d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><code class="du jl jm jn jo b">! pip install google_images_download</code></p><h1 id="ca36" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">卷积神经网络</h1><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es kn"><img src="../Images/44b3a5a843c0609c906b7c8354797de1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mLMSAlWugrpSU54-KUJmMQ.png"/></div></div></figure><h1 id="cdb7" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">CNN层</h1><p id="4901" class="pw-post-body-paragraph im in hi io b ip kz ir is it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj hb bi translated">这一层帮助我们检测图像中的特征。如第一幅图像所示，有一个2*2的过滤器以1的步幅移动。该滤波器与输入图像相乘以获得输出图像。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es le"><img src="../Images/c1ec46cc3e6c1ea3781523850e701346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*noYcUAa_P8nRilg3Lt_nuA.png"/></div></figure><p id="8faa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">问:但是这些过滤器能做什么呢？<br/>答:现在，每个过滤器实际上都是一个特征检测器。例如，在下图中，您可以看到每个过滤器检测不同的特征。为了更好地理解这一点，如果你的图像是一只“猫”，那么也许一个特征检测过滤器检测眼睛，另一个检测鼻子和耳朵等等…<strong class="io hj"> <br/> </strong>同样在下图中每个滤镜搜索并检测一个特征，我们得到一个特征图。最后，在使用不同的过滤器后，我们得到了一组特征图，这就是我们的卷积层。<br/>至于如何理解特征检测过程，<a class="ae lf" href="https://www.coursera.org/lecture/convolutional-neural-networks/edge-detection-example-4Trod" rel="noopener ugc nofollow" target="_blank">吴恩达的这个</a>视频是你能找到的最好的。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es lg"><img src="../Images/3e495fcfc35d8169df913e146a8baf65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aIF_TvfDSC0ZVlDKiVGYyg.png"/></div></div></figure><p id="b1fa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">问:为什么把ReLU作为激活函数？答:我们选择ReLU in作为激活函数来增加非线性度。那么为什么是非线性的问题就出现了。<br/> Well ReLU为整流线性单元，定义为<em class="jk"> y = max(0，x) </em>其中<em class="jk"> x </em>为神经元的输入。</strong></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es lh"><img src="../Images/d351baef0d00871c8b5fedc7c1204727.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ACHo09NFhKvYCsOFHxWVbA.png"/></div></div></figure><p id="e83c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">图像本身是高度线性的，但是在卷积之后，线性降低了，为了增加图像的线性，我们使用ReLU。你说的非线性是什么意思？当从一个像素过渡到另一个像素时，由于颜色、形状、边界和不同的元素，存在非线性。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es li"><img src="../Images/39fba11775a8ab036ac97ad505e37478.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LNNFW_77lxPC3bca8PTEjw.png"/></div></div></figure><p id="4658" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里我们有一个来自一个过滤器的特征图，它是黑白的，现在在应用ReLU后，我们只有非负值，即所有的黑色都被去除了。现在，从黑色区域到白色区域的特征图中的像素过渡是线性的，即首先是黑色，然后是深灰色，然后是灰色，然后是白色。但是在应用ReLU时，我们在颜色上有明显的对比，因此增加了非线性。</p><h1 id="5ba6" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">汇集层</h1><p id="c58e" class="pw-post-body-paragraph im in hi io b ip kz ir is it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj hb bi translated">池层用于查找矩阵中的最大值。通常采用的步幅是2，通常的滤波器大小是2。</p><p id="706b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">问:但是这个最大池有什么作用呢？<br/> A. </strong>最大池化是为了在a池中获得最大值。现在这一步是在卷积层之后完成的，在卷积层中我们检测特征。因此，让我们举一个例子来更好地理解。如果图像是猫的，那么卷积层检测到的特征之一可能是眼睛，现在这些眼睛可以位于图像中的任何位置，一些图像可能只有猫的脸，一些可能有整个身体，一些可能是侧视图等等…但我们的CNN应该识别所有的“CATS”。因此，汇集所做的是，它有助于识别特征，即使它们略有失真。通过2*2滤波器，我们将尺寸和参数减少了75%。因此，这防止了过度拟合。</p><p id="9efd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">问:它是如何达到处理特征失真的目的的？<br/> A. 当滤镜以2*2的尺寸和2的步幅移动时。它扫描并从2*2的组中获取最大值，从而确保获取所有组的主要特征，并因此处理空间失真。只是一个直观的例子，数字9向我们展示了一只猫的耳朵，它位于第2行第1列，现在如果图像被扭曲，而9碰巧向上或向右移动，那么在合并后，我们仍然可以使用最大合并来恢复该特征。不要把这当作字面上的解释，而是作为一个直观的例子来理解池的概念。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es lj"><img src="../Images/45f76d1d100c5e53786bec6196a6687a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6u3QK9M9ZJws58P4SAr2AQ.png"/></div></div></figure><p id="eb5f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">对于好奇的人来说…<br/> 问:一个有趣的疑问是，为什么只采用最大池，而不采用任何其他类型的池，如平均池？答:请参考张秀坤·舍雷尔、安德烈亚斯·穆勒和斯文·本克的研究论文。它只是一篇10页的研究论文，深入解释了这个主题。<br/>也可以访问<a class="ae lf" href="https://cs.ryerson.ca/~aharley/vis/conv/flat.html" rel="noopener ugc nofollow" target="_blank">这个</a>网站，体验CNN功能的乐趣。</p><p id="2464" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">代码:</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="57f3" class="lo jq hi jo b fi lp lq l lr ls"><strong class="jo hj">import</strong> <strong class="jo hj">tflearn<br/>from</strong> <strong class="jo hj">tflearn.layers.core</strong> <strong class="jo hj">import</strong> input_data, fully_connected, dropout <strong class="jo hj">from</strong> <strong class="jo hj">tflearn.layers.conv</strong> <strong class="jo hj">import</strong> conv_2d,max_pool_2d <strong class="jo hj">from</strong> <strong class="jo hj">tflearn.layers.estimator</strong> <strong class="jo hj">import</strong> regression <strong class="jo hj">import</strong> <strong class="jo hj">numpy</strong> <strong class="jo hj">as</strong> <strong class="jo hj">np</strong> <strong class="jo hj">import</strong> <strong class="jo hj">matplotlib.pyplot</strong> <strong class="jo hj">as</strong> <strong class="jo hj">plt</strong> <br/><strong class="jo hj">import</strong> <strong class="jo hj">cv2</strong> <br/><strong class="jo hj">import</strong> <strong class="jo hj">os</strong> <br/><strong class="jo hj">from</strong> <strong class="jo hj">random</strong> <strong class="jo hj">import</strong> shuffle <br/><strong class="jo hj"><em class="jk">from google_images_download import</em></strong><em class="jk"> google_images_download</em> <br/><strong class="jo hj">from</strong> <strong class="jo hj">PIL</strong> <strong class="jo hj">import</strong> Image</span></pre><p id="d157" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">此处:</strong> <br/> <strong class="io hj">关键词:</strong>需要下载图片的对象名称。<br/> <strong class="io hj">限制:</strong>您想一次下载的图片数量。<br/><strong class="io hj">:Print _ URLs:</strong>打印所有正在下载的图片的网址。</p><p id="ee72" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里的限制是100，我们得到了94个图像，因为有些图像会被破坏。参考<a class="ae lf" href="https://google-images-download.readthedocs.io/en/latest/examples.html#" rel="noopener ugc nofollow" target="_blank">本页</a>以更好地了解各种参数和示例。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="317a" class="lo jq hi jo b fi lp lq l lr ls"><em class="jk"># getting random images of </em>Forest Fire<em class="jk"> and </em>Natural Vegetation<em class="jk"> in</em><br/>response  = google_images_download.googleimagesdownload()<br/>arguments = {"keywords":"Forest Fire,Natural Vegetation","limit":100,"print_urls":<strong class="jo hj">False</strong>}<br/><br/>path = response.download(arguments)<br/>print(path)<br/><br/><em class="jk"># got 94 images of forest_fire and 94 images of natural vegetation</em></span></pre><p id="c3c7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">上述代码确保下载的图像不会被破坏。如果没有这一点，以后在调整图像大小和转换图像时会产生很多问题。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="280c" class="lo jq hi jo b fi lp lq l lr ls"><em class="jk"># removing corrupted images</em><br/><br/>FOREST_FIRE_DIR = '/content/downloads/Forest Fire'<br/>NATURAL_VEG_DIR = '/content/downloads/Natural Vegetation'<br/><br/>url_list = [FOREST_FIRE_DIR,NATURAL_VEG_DIR]<br/><strong class="jo hj">for</strong> i <strong class="jo hj">in</strong> url_list :<br/>    <br/>  <strong class="jo hj">for</strong> image <strong class="jo hj">in</strong> os.listdir(i):<br/><br/>    <strong class="jo hj">try</strong>:<br/>      <strong class="jo hj">with</strong> Image.open(i+"/"+image) <strong class="jo hj">as</strong> im :<br/>        <strong class="jo hj">pass</strong><br/><br/>    <strong class="jo hj">except</strong>:<br/>      print(i+"/"+image)<br/>      os.remove(i+"/"+image)</span></pre><p id="4858" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我们重命名现有的图像。这样做是为了给两组图像添加标签，我们将使用CNN对这两组图像进行分类。稍后将解释标签部分。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="f722" class="lo jq hi jo b fi lp lq l lr ls"><em class="jk"># renaming the files</em><br/><strong class="jo hj">for</strong> i <strong class="jo hj">in</strong> url_list:<br/>    <br/>  <strong class="jo hj">for</strong> num , image <strong class="jo hj">in</strong> enumerate(os.listdir(i)):<br/><br/>    <strong class="jo hj">if</strong> i == '/content/downloads/Forest Fire':<br/>      os.rename(i+"/"+image,i+"/"+"forest_fire."+str(num)+".jpg")<br/>    <strong class="jo hj">else</strong>:<br/>      os.rename(i+"/"+image,i+"/"+"natural_veg."+str(num)+".jpg")</span></pre><p id="9054" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果你没有使用Google Colab，你可以跳过这几行代码。Google colab创建的检查点经常会带来问题，通过这段代码，问题得到了解决。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="8f06" class="lo jq hi jo b fi lp lq l lr ls"><em class="jk"># removing corrupted images</em>  <br/>FOREST_FIRE_DIR = '/content/downloads/Forest Fire' <br/>NATURAL_VEG_DIR = '/content/downloads/Natural Vegetation'  </span><span id="3818" class="lo jq hi jo b fi lt lq l lr ls">url_list = [FOREST_FIRE_DIR,NATURAL_VEG_DIR]<br/><strong class="jo hj">for</strong> i <strong class="jo hj">in</strong> url_list :<br/>    <br/>  <strong class="jo hj">for</strong> image <strong class="jo hj">in</strong> os.listdir(i):<br/><br/>    <strong class="jo hj">try</strong>:<br/>      <strong class="jo hj">with</strong> Image.open(i+"/"+image) <strong class="jo hj">as</strong> im :<br/>        <em class="jk"># print(i+"/"+image)</em><br/>        <strong class="jo hj">pass</strong><br/><br/>    <strong class="jo hj">except</strong>:<br/>      print(i+"/"+image)<br/>      <strong class="jo hj">if</strong> image == '.ipynb_checkpoints':<br/>        <strong class="jo hj">pass</strong><br/>      <strong class="jo hj">else</strong>:<br/>        os.remove(i+"/"+image)</span><span id="092f" class="lo jq hi jo b fi lt lq l lr ls"><em class="jk"># getting the count of the no of images available under each category </em><br/><br/>print("forest fire image count: "+ str(len([x <strong class="jo hj">for</strong> x <strong class="jo hj">in</strong> os.listdir(FOREST_FIRE_DIR)])))<br/><br/>print("natural vegetation image count: "+ str(len([x <strong class="jo hj">for</strong> x <strong class="jo hj">in</strong> os.listdir(NATURAL_VEG_DIR)])))</span></pre><p id="a322" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果图像的名称以forest_fire else [0，1]开头，则将图像标记为[1，0]。在这里，图像的早期重命名很有帮助。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="eacc" class="lo jq hi jo b fi lp lq l lr ls"><strong class="jo hj">from</strong> <strong class="jo hj">tqdm</strong> <strong class="jo hj">import</strong> tqdm<br/><br/><strong class="jo hj">def</strong> label_img(img):<br/><br/>  word_label = img.split('.')[0]<br/>  <strong class="jo hj">if</strong> word_label == "forest_fire":<br/>    <strong class="jo hj">return</strong> [1,0]<br/><br/>  <strong class="jo hj">else</strong>:<br/>    <strong class="jo hj">return</strong> [0,1]</span></pre><p id="50d8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们现在需要一个训练集，并从现有的数据集中进行测试。我将分析这几行代码中发生了什么。<br/>两组步骤相同。</p><p id="585b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">1.从文件中读取图像:</p><blockquote class="lu lv lw"><p id="4125" class="im in jk io b ip iq ir is it iu iv iw lx iy iz ja ly jc jd je lz jg jh ji jj hb bi translated">train_url = [TRAIN_DIR_Fire，TRAIN _ DIR _ Nature]<br/><strong class="io hj">for</strong>I<strong class="io hj">in</strong>TRAIN _ URL:<br/><strong class="io hj">for</strong>image<strong class="io hj">in</strong>tqdm(OS . listdir(I)):<br/>label = label _ img(image)<br/>path = OS . path . join(I，image)</p></blockquote><p id="7f8b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.在这里，我们读取图像并将其调整到图像大小，这个图像大小将在以后定义。<br/> 3。然后图像和标签都被一个接一个地添加到numpy数组中<br/> 4。你的数据被打乱以改变图像的顺序</p><blockquote class="lu lv lw"><p id="fd8b" class="im in jk io b ip iq ir is it iu iv iw lx iy iz ja ly jc jd je lz jg jh ji jj hb bi translated"><strong class="io hj">else</strong>:<br/>image = cv2 . resize(cv2 . im read(path)，(IMG_SIZE，IMG _ SIZE))<br/>training_data . append([NP . array(image)，NP . array(label)])<br/>shuffle(training _ data)<br/>NP . save(' training _ data . npy '，training _ data)</p></blockquote><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="e08a" class="lo jq hi jo b fi lp lq l lr ls"><strong class="jo hj">'''TRAIN SET '''<br/>def</strong> create_train_set(): <br/>  training_data = []<br/>  TRAIN_DIR_Fire = '/content/downloads/Forest Fire'<br/>  TRAIN_DIR_Nature = '/content/downloads/Natural Vegetation'<br/><br/>  train_url = [TRAIN_DIR_Fire,TRAIN_DIR_Nature]<br/>  <strong class="jo hj">for</strong> i <strong class="jo hj">in</strong> train_url:<br/>    <strong class="jo hj">for</strong> image <strong class="jo hj">in</strong> tqdm(os.listdir(i)):<br/>      label = label_img(image)<br/>      path  = os.path.join(i,image)<br/>      <strong class="jo hj">if</strong> path <strong class="jo hj">in</strong> ["/content/downloads_img/ForestFire/.ipynb_checkpoints"]:      <br/>        <strong class="jo hj">pass</strong></span><span id="1506" class="lo jq hi jo b fi lt lq l lr ls">      <strong class="jo hj">else</strong>:<br/>          <br/>        image = cv2.resize(cv2.imread(path),(IMG_SIZE,IMG_SIZE))<br/>        <br/>        training_data.append([ np.array(image),np.array(label)])<br/><br/>  shuffle(training_data)<br/>  np.save('training_data.npy',training_data)<br/>  <strong class="jo hj">return</strong> training_data</span><span id="e5ae" class="lo jq hi jo b fi lt lq l lr ls"><strong class="jo hj">'''TEST SET'''</strong></span><span id="6d25" class="lo jq hi jo b fi lt lq l lr ls"><strong class="jo hj">def</strong> create_test_set():<br/>  testing_data = []<br/>  TEST_DIR_Fire = '/content/test/Forest_Fire'<br/>  TEST_DIR_Nature = '/content/test/Natural_Vegetation'<br/>  test_url = [TEST_DIR_Fire,TEST_DIR_Nature]<br/>  <strong class="jo hj">for</strong> i <strong class="jo hj">in</strong> test_url:<br/>      <br/>    <strong class="jo hj">for</strong> image <strong class="jo hj">in</strong> tqdm(os.listdir(i)):<br/>      label = label_img(image)<br/>      path  = os.path.join(i,image)<br/>      <strong class="jo hj">if</strong> path <strong class="jo hj">in</strong> ["/content/downloads_img/Forest Fire/.ipynb_checkpoints"]:<br/>        <br/>        <strong class="jo hj">pass</strong><br/>      <strong class="jo hj">else</strong>:<br/>          <br/>        image = cv2.resize(cv2.imread(path),(IMG_SIZE,IMG_SIZE))<br/>        testing_data.append([ np.array(image),np.array(label)])<br/><br/>  np.save('testing_data.npy',testing_data)<br/>  <strong class="jo hj">return</strong> testing_data</span></pre><p id="dbbf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我们声明图像的大小，学习速度和纪元的数量，请随意试验。我们现在创建训练和测试集。</p><p id="940b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">本文之所以关注自定义数据集，是因为在大多数例子中，CNN是在MNIST或时尚MNIST数据集上完成的。问题在于，我们到目前为止所做的所有上述预处理都已经完成并为我们准备好了，我们没有任何知识来处理现实生活中的项目。在现实生活项目中，我们需要:提取自定义数据<br/> 2。清理图像，并将不同的图像分离到文件夹中。<br/> 3。然后调整大小并重命名<br/> 4。标记图像<br/> 5。将图像转换为Numpy数组的。</p><p id="707f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所有这些步骤都是在现有的数据集中完成的。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="c776" class="lo jq hi jo b fi lp lq l lr ls">IMG_SIZE = 50<br/>learning_rate = 1e-3<br/>N_EPOCH = 5<br/><br/>MODEL_NAME = "fireVSnature-<strong class="jo hj">{}</strong>-<strong class="jo hj">{}</strong>-<strong class="jo hj">{}</strong>.model".format(learning_rate,'6-conv-basic',N_EPOCH)</span><span id="5bc9" class="lo jq hi jo b fi lt lq l lr ls"><em class="jk">train_data = create_train_set()<br/>test_data = create_test_set()</em></span></pre><p id="4494" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这段代码中，我们使用tflearn构建了CNN。我们有2个卷积和最大池层，其中2个是全连接层，使用的优化器是“adam”，分类的度量是“准确性”。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="905f" class="lo jq hi jo b fi lp lq l lr ls">convnet = input_data([<strong class="jo hj">None</strong>,IMG_SIZE,IMG_SIZE,3],name='inputs')<br/><br/>convnet = conv_2d(convnet,64,3,activation='relu')<br/>convent = max_pool_2d(convnet,2)<br/><br/>convnet = conv_2d(convnet,32,3,activation='relu')<br/>convent = max_pool_2d(convnet,2)<br/><br/>convnet = fully_connected(convnet,512,activation='relu')<br/><br/>convnet = fully_connected(convnet,2,activation='sigmoid')<br/>convnet = regression(convnet,optimizer='adam',name='targets',learning_rate=learning_rate,loss='binary_crossentropy',metric = 'accuracy')</span><span id="0cbf" class="lo jq hi jo b fi lt lq l lr ls">model = tflearn.DNN(convnet,tensorboard_dir='log')</span></pre><p id="e7be" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从测试和训练数据中获取图像和标签。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="bece" class="lo jq hi jo b fi lp lq l lr ls"><em class="jk">X = np.array( [ i[0] for i in train_data ])</em><br/><em class="jk">y = np.array([i[1] for i in train_data])</em><br/><br/><em class="jk">test_X = np.array( [ i[0] for i in test_data ])</em><br/><em class="jk">test_y = np.array([i[1] for i in test_data])</em></span></pre><p id="39b5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">拟合模型。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="5569" class="lo jq hi jo b fi lp lq l lr ls">model.fit({'inputs':X},{'targets':y},n_epoch=3,validation_set=({'inputs':test_X},'targets':test_y}),show_metric=<strong class="jo hj">True</strong>,snapshot_step=10,run_id=MODEL_NAME,batch_size=10)<br/>model.save(MODEL_NAME)</span></pre><p id="5c4c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">预测分类和可视化结果。如果你有像我一样少的图片数(少于100张)，那么你的准确度不会很高。</p><pre class="ko kp kq kr fd lk jo ll lm aw ln bi"><span id="f2d7" class="lo jq hi jo b fi lp lq l lr ls">%matplotlib inline<br/>fig = plt.figure(figsize=(10,6))<br/><strong class="jo hj">import</strong> <strong class="jo hj">matplotlib.image</strong> <strong class="jo hj">as</strong> <strong class="jo hj">mpimg</strong></span><span id="9f79" class="lo jq hi jo b fi lt lq l lr ls"><strong class="jo hj">for</strong> num, image <strong class="jo hj">in</strong> enumerate(test_data):<br/>  <em class="jk"># image = mpimg.imread(image)</em><br/>  y_plot = fig.add_subplot(3,6,num+1)<br/>  model_out = model.predict([image[0]])[0][0]<br/>  <em class="jk"># print(model_out)</em></span><span id="950c" class="lo jq hi jo b fi lt lq l lr ls">  <strong class="jo hj">if</strong>  model_out == 1:<br/>    label = "FOREST_FIRE"<br/>  <strong class="jo hj">else</strong>:<br/>    label="NATURAL_VEG"</span><span id="6a38" class="lo jq hi jo b fi lt lq l lr ls">  y_plot.imshow(image[0])<br/>  plt.title(label)<br/>  y_plot.axis('off')</span><span id="3bb3" class="lo jq hi jo b fi lt lq l lr ls">plt.show()</span></pre><p id="3387" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">用于检查完整的代码。参见<a class="ae lf" href="https://github.com/AjayJohnAlex/ANN/blob/master/tf_learn_custom_images_CNN.ipynb" rel="noopener ugc nofollow" target="_blank">这</a>页。</p><p id="a9a4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果对这篇文章有任何疑问，请在评论区添加。我很乐意尽快回答他们。我也会相应地对文章进行充分的修改。</p></div></div>    
</body>
</html>