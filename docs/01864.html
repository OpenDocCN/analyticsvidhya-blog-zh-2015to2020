<html>
<head>
<title>Intro to Deep Neural Networks — Is it really that hard?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度神经网络介绍——真的那么难吗？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/intro-to-deep-neural-networks-is-it-really-that-hard-94b74e6da790?source=collection_archive---------12-----------------------#2019-11-18">https://medium.com/analytics-vidhya/intro-to-deep-neural-networks-is-it-really-that-hard-94b74e6da790?source=collection_archive---------12-----------------------#2019-11-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/efa9879a9233845f2a567b0fc7df843e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vyKvzmdnR4UCU_Lh-lZwNQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">神经网络的概念受到我们大脑学习、理解和保留信息的方式的启发。</figcaption></figure><p id="0f79" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在技术领域，“机器学习”(ML)、“人工智能”(AI)和“深度学习”(DL)已经成为吸引雇主、投资者和技术极客的完美流行语！虽然这些概念最初很难理解，但是有了正确的指导和可靠的文档，它会变得更容易！</p><p id="1be5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">也就是说，巩固深度神经网络的基础很重要(DNN)。这包括定义、某些算法、概念和各种类型的模型。同样重要的是能够应用各种技术来训练和增强所选择的数据。在这篇文章中，我们将做到这一点，完善的基础！</p><p id="5f3f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">内容的灵感来自伊恩·古德菲勒、约舒阿·本吉奥和亚伦·库维尔在麻省理工学院出版社出版的关于深度学习<a class="ae js" href="https://www.deeplearningbook.org/" rel="noopener ugc nofollow" target="_blank"><em class="jt"/></a>的书。</p><h1 id="78f5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">1.定义</h1><p id="4321" class="pw-post-body-paragraph iu iv hi iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr hb bi translated"><strong class="iw hj">什么是深度学习？</strong></p><p id="e79e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">深度学习是机器学习领域下的一项研究，它侧重于向计算机模型教授任务的技术；人类天生的任务。DL方法的一些流行应用包括图像识别、语音搜索和声控智能助理、地震预测和用于脑癌检测的神经网络等等。</p><p id="a122" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这些算法是由我们大脑的功能激发的，准确地说是被称为<em class="jt">人工神经网络</em>。具体来说，神经网络的结构非常类似于我们的神经系统的结构，其中复杂的系统由数百万个<strong class="iw hj">神经元</strong>组成，每个神经元相互之间来回通信，以学习、识别和理解各种任务。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/6d39b83085d926fc5af43d94b3342fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c9x9cqqbCkmGMM4YQOc4Xg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图一。幻灯片由<a class="ae js" href="https://www.slideshare.net/ExtractConf" rel="noopener ugc nofollow" target="_blank"> <em class="lc">吴恩达</em> </a>制作，版权所有。</figcaption></figure><p id="44c6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最初，可能不清楚为什么具有一堆层和数百(如果不是数千)个神经元的这种复杂网络更好。然而，将它们与旧算法进行比较有助于理解为什么。如图<em class="jt">图1 </em>所示，随着要处理的数据量的增加，旧模型开始接近饱和点并停止改进，而深度学习模型则开始处理更大的数据集。</p><p id="0d87" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">拆分数据</strong></p><p id="fe8a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在机器学习中，你所拥有的全部数据被分成3类，分别是训练集、验证集和测试集。这种分割是为了避免ML的根本问题，即过度拟合和欠拟合——将在本文后面讨论。顾名思义，训练集用于训练算法，该算法在可用的总数据中占最大部分。而一旦模型被完全训练，测试数据被用于使用一些性能度量来评估模型的性能。重要的是，训练集和测试集是互斥的，以避免记忆而不是泛化。最后，验证集用于调整称为<em class="jt">超参数</em>的变量，这些变量控制模型如何学习。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/4658c966955a6691197d36971f52dea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XN4_CEijMdAImpHdh8PTBw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图二。3个类别之间的分裂可视化，<a class="ae js" href="https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7" rel="noopener" target="_blank">塔朗沙阿</a>，版权所有。</figcaption></figure><h1 id="fbef" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak"> 2。然而，我们真正在“学习”什么呢？</strong></h1><p id="da9a" class="pw-post-body-paragraph iu iv hi iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr hb bi translated">“一个计算机程序被称为从关于某类任务<em class="jt"> T </em>和性能测量<em class="jt"> P </em>的经验<em class="jt"> E </em>中学习，如果它在<em class="jt"> T </em>中的任务的性能，如<em class="jt"> P </em>所测量的，随着经验<em class="jt"> E的增加而提高。</em></p><p id="0381" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">一)<strong class="iw hj">任务，<em class="jt">T</em>T21】</strong></p><p id="31f5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">ML任务通常根据ML系统应该如何处理示例来描述，其中示例是从我们希望系统处理的一些对象或事件中定量测量的特征的集合。一些最常见的ML任务包括:</p><ul class=""><li id="59eb" class="le lf hi iw b ix iy jb jc jf lg jj lh jn li jr lj lk ll lm bi translated">有/无缺失输入的分类</li><li id="f91e" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">回归</li><li id="1187" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">抄本</li><li id="f0f0" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">异常检测</li><li id="23ea" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">合成和取样</li><li id="eb4f" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">去噪</li><li id="1ded" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">密度估计或概率质量函数估计</li></ul><p id="1e12" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">b) <strong class="iw hj">绩效衡量，<em class="jt"> P </em> </strong></p><p id="8e9c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了评估最大似然算法的能力，我们必须设计其性能的定量测量。我们可以评估两个主要因素:</p><ul class=""><li id="454b" class="le lf hi iw b ix iy jb jc jf lg jj lh jn li jr lj lk ll lm bi translated">准确(性)</li><li id="9871" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">出错率</li></ul><p id="04e7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">实际上，我们通常想知道我们的算法在以前没有见过的数据上的表现如何，因此评估我们在数据的<em class="jt">测试集</em>(独立于<em class="jt">训练集</em>)上的表现是正确的方法。</p><p id="5487" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">c) <strong class="iw hj">经验，<em class="jt"> E </em> </strong></p><p id="68b7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">根据在学习过程中允许的经验种类，机器学习算法可以大致分为<em class="jt">无监督的</em>或<em class="jt">有监督的</em>。这是一个重要的话题，值得另写一篇文章。</p><h1 id="a078" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak"> 3。过拟合和欠拟合模型</strong></h1><p id="0bf3" class="pw-post-body-paragraph iu iv hi iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr hb bi translated">有两个关键因素决定了ML算法的性能。也就是说，它能够:</p><ul class=""><li id="fe3a" class="le lf hi iw b ix iy jb jc jf lg jj lh jn li jr lj lk ll lm bi translated">使训练误差变小</li><li id="acab" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">使训练和测试误差之间的差距变小</li></ul><p id="c816" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然而，机器学习算法的一个反复出现的问题是:</p><p id="ea4c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">a)过度拟合</p><p id="005c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当模型捕捉到数据的噪声时，就会出现这种(频繁的)问题。换句话说，当模型“太好地”符合训练数据，或者只学习数据中特定于模式的模式，并且“记住”其输出，以至于影响模型在新的、看不见的数据上的性能时，就会发生这种情况。简单来说就是训练误差和测试误差差距过大的时候。</p><p id="6b3a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">解决这个问题的一个常见方法是简化模型，特别是通过删除或减少隐藏层中的元素数量来减少网络容量。另一种可能的解决方案是添加权重正则化层，从而为大权重的损失函数增加成本，并通过迫使模型仅学习训练集中的相关模式来简化模型。例如，看看多伦多大学的研究人员发表的这篇文章，这篇文章解释了如何使用T2辍学来防止神经网络中的过度拟合。</p><p id="8a0e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">b)装配不足</p><p id="3a5a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当模型无法捕获基本的、潜在的训练数据模式时，就会出现这种问题。与过度拟合相反，当模型不能很好地拟合训练数据时，就会发生这种情况，从而导致对测试集或验证集的预测不佳。换句话说，就是模型不能在训练集上获得足够低的误差值。</p><p id="2d03" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">解决这个问题的一个简单方法是简单地获取更多的训练数据，并让它学习更多的数据。</p><p id="9dc3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">显然，对于这两种情况，一些共同的改变可能会产生更好的解决方案。比如:</p><ul class=""><li id="cf86" class="le lf hi iw b ix iy jb jc jf lg jj lh jn li jr lj lk ll lm bi translated">改变初始权重/偏差</li><li id="d4cc" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">使用不同的激活功能</li><li id="c808" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">切换层的顺序(架构)</li><li id="a14f" class="le lf hi iw b ix ln jb lo jf lp jj lq jn lr jr lj lk ll lm bi translated">交叉验证</li></ul><h1 id="1873" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">4.它实际上是如何工作的？一个简单的CNN例子。</h1><p id="876a" class="pw-post-body-paragraph iu iv hi iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr hb bi translated">深度学习模型有很多种。例如，举几个例子，递归神经网络、递归神经网络和残差神经网络(ResNet)。然而，对于ML从业者来说，最常见的一种是卷积神经网络(CNN)。</p><p id="7b3b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们将通过一个简单的CNN架构示例，使用图表和Python代码来理解其功能。</p><p id="d5a3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">建筑概述</strong></p><p id="c3d8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">CNN是一种专门的神经网络，用于处理具有已知网格状拓扑的数据，例如时间序列数据和图像数据。本质上，它们接受输入，为网络的各个部分分配权重/偏差，最后根据定义的类别对图像进行分类。当然，我们跳过了中间发生的许多有趣的事情。</p><p id="9226" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">CNN中使用了一些基本层。尽管它们的排列顺序不同，但它们的核心功能和重要性不会改变。我们将讨论以下几层:卷积层、池层和全连接层。</p><p id="831b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">附注:我将使用这篇文章中的图片和GIF，因为它很好地展示了这些层是如何工作的。</p><p id="c8e5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">卷积层</strong></p><p id="5a17" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在数学上，卷积是两个函数(<em class="jt"> f </em>和<em class="jt"> g </em>产生第三个函数(<em class="jt"> h </em>)的运算，其中<em class="jt"> h </em>表示<em class="jt"> f </em>和<em class="jt"> g </em>之间的关系以及它们如何相互影响。类似地，在CNN中，卷积层基于滤波器/内核大小遍历整个输入，并且对于每个遍历的矩阵，它在每个空间位置计算与滤波器矩阵的点积，从而在输出矩阵上产生1个单元。(看<em class="jt">图4。)</em></p><p id="0c46" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">以下是不同类型的可能特征的示例，这些特征用于检测和提取低级模式，如边、圆和其他多边形，具体取决于特征图。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/f56d4e5482776bcf2354586a020f4ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*UgVpTJah0syV2l3fLvXhsQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图三。特征地图的例子。</figcaption></figure><p id="2dde" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下面的GIF示例展示了卷积图层如何遍历输入图像，并基于具有特定特征的点积生成输出。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/f707125b9ec4b5e8aa7c8ba64ea86e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*kZCeqOU6kGxWlA_fbiLIjg.gif"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图4。特征/内核大小为3x3，输入为6x6，生成4x4矩阵，<a class="ae js" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank"> Sumit Saha </a>，版权所有。</figcaption></figure><p id="14fe" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">与输入相比，得到的矩阵可以在维度上减少(如上所示),或者维度可以增加或保持不变(应用填充)。</p><p id="32f4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">汇集层</strong></p><p id="752b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">池层是CNN中另一个经常使用的层，其主要目的是减少大小以降低进一步处理所需的计算能力。不仅如此，它在提取给定输入中的主要特征时非常有用。</p><p id="0a87" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最常用的池类型是<em class="jt"> max-pooling </em>，其中给定步长<em class="jt"> s，</em>它滑过特征尺寸为<em class="jt"> n </em>的输入，并将当前n <em class="jt"> x n </em>输入矩阵中的最大值写入输出矩阵，如下所示。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/7edf84c2e226c84996f25b3f723d6288.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/1*UWkC4pEPYu2R5FOR1UD7GA.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图五。输入大小5x5矩阵，最大3x3池，<a class="ae js" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank"> Sumit Saha </a>，版权所有。</figcaption></figure><p id="b458" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">全连接/分类层</strong></p><p id="9551" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后，在应用了卷积层和池层的组合之后，网络通常以完全连接的层结束，在那里它们捕获网络中的高级推理。它是一个层，其中一层中的每个神经元都与另一层中的每个神经元相连。通常，展平的矩阵经过完全连接的层来分类图像。</p><p id="a236" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下图显示了卷积网络的典型架构。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/41c885ac6ff440fbdde6ee8af2f2fbdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4OUonEDfZwCfR4Y-G-h1fw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图六。CNN有两个组成层，两个池层和一个全连接层来帮助分类图像，<a class="ae js" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank"> Sumit Saha </a>。保留所有权利。</figcaption></figure><h1 id="e9e9" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak"> 5。我们来玩Python吧！</strong></h1><p id="1c50" class="pw-post-body-paragraph iu iv hi iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr hb bi translated">到目前为止，你可能只是想“是的，是的，我得到了所有这些理论上的东西，但是我们如何编码呢？”。</p><p id="462b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们将使用Tensorflow和Keras API来运行一个非常基本的CNN网络，该网络具有顺序模型，ReLU作为激活函数，Adam作为反向传播优化器。</p><p id="ed8d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">首先，需要导入某些库。为了让生活更简单，我在Anaconda3 Naviagtor上运行Jupyter。</p><p id="f30e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我已经使用<a class="ae js" href="https://www.youtube.com/user/sentdex" rel="noopener ugc nofollow" target="_blank">send ex</a>Youtube频道开始使用。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/312781301dfda4d614b6ccd290f676cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7NLhkJH1HTQRJhivFDTtew.png"/></div></div></figure><p id="48f5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于这个例子，我使用的是猫狗64 x 2 CNN数据集，可以从<a class="ae js" href="https://www.kaggle.com/c/dogs-vs-cats" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/ecf2173c4f0d007fd12d60528536b639.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BMaMOS6sRLE7ZyOSTxd7vQ.png"/></div></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/5a4b1416b2e58e42af51176e0509e755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pZrJg44Z2pnO7xgUg1e5gw.png"/></div></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/8d38e6e86ecd8d2f8a216e535c61b7b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3cuFYG8FFLvCqiEoUFMUIQ.png"/></div></div></figure></div></div>    
</body>
</html>