<html>
<head>
<title>Set up a Hadoop Cluster using Ansible</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Ansible设置Hadoop集群</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/set-up-a-hadoop-cluster-using-ansible-b218bf4ce602?source=collection_archive---------6-----------------------#2020-12-29">https://medium.com/analytics-vidhya/set-up-a-hadoop-cluster-using-ansible-b218bf4ce602?source=collection_archive---------6-----------------------#2020-12-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/55e4239b7f3bb3e112e3a3860c40bdcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*hREI1MjmsK8wMaF6nznnEA.jpeg"/></div></figure><h2 id="daa5" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">介绍</h2><p id="e3d2" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt iw ju jv jw ja jx jy jz je ka kb kc kd ha bi translated">我们使用Ansible通过简单地编写行动手册来自动化云供应、配置管理、部署和其他IT操作。它是一个开源工具，可以大规模提高我们的生产力，当我们需要在多个节点上执行配置管理时，可以节省我们很多时间和麻烦。</p><p id="7a09" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">在本文中，我们将在Ansible的帮助下自动化Hadoop集群设置。为了简单起见，我们的集群包含一个虚拟机作为Ansible的控制节点，两个虚拟机作为受管节点，它们将作为Hadoop集群中的名称节点和数据节点。</p></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><h2 id="3017" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">设置Ansible</h2><p id="8025" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt iw ju jv jw ja jx jy jz je ka kb kc kd ha bi translated"><em class="kq">如果您已经设置了Ansible，您可以跳过这一部分。</em></p><p id="d8d8" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">首先，运行<code class="du kr ks kt ku b"><strong class="jl hi">ansible --version</strong></code>命令检查您安装了什么版本的Ansible。如果这个命令不运行，那么可以使用pip安装Ansible(需要为Ansible安装Python)。要用pip安装Ansible，可以运行<code class="du kr ks kt ku b"><strong class="jl hi">pip3 install ansible</strong></code>。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es kv"><img src="../Images/76ae38a29c5f192082666391a8edc026.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ePJXjLRSjfzYotQlq6Jenw.png"/></div></div></figure><p id="a233" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">接下来，我们需要创建一个清单文件，其中包含所有托管节点的IP地址。因此，在任何位置(例如<code class="du kr ks kt ku b"><strong class="jl hi">vi /root/ipINV.txt</strong></code>)创建一个清单文件，最好是在某个目录下，这样你以后也可以保存你的ansible配置文件。</p><p id="6bc7" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">在清单中，以以下格式添加您的受管节点信息:</p><pre class="kw kx ky kz fd le ku lf lg aw lh bi"><span id="5d5f" class="il im hh ku b fi li lj l lk ll">[namenode]<br/><em class="kq">&lt;IP address of namenode&gt;</em> ansible_user=root ansible_ssh_pass=<em class="kq">&lt;password&gt;</em> ansible_connection=ssh<br/>[datanode]<br/><em class="kq">&lt;IP address of datanode&gt;</em> ansible_user=root ansible_ssh_pass=<em class="kq">&lt;password&gt;</em> ansible_connection=ssh</span></pre><p id="7cfb" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated"><code class="du kr ks kt ku b">[namenode]</code>和<code class="du kr ks kt ku b">[datanode]</code>是我们在写剧本时可以使用的标签。你可以随意命名你的标签。</p><p id="33dc" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">接下来，为ansible配置文件创建一个目录，</p><p id="e462" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated"><code class="du kr ks kt ku b">[root@localhost ~]# mkdir /etc/ansible</code></p><p id="9d1a" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">在这个目录下，创建一个配置文件，<code class="du kr ks kt ku b">vim ansible.cfg </code>并添加以下内容，</p><pre class="kw kx ky kz fd le ku lf lg aw lh bi"><span id="bca0" class="il im hh ku b fi li lj l lk ll">[defaults]<br/>inventory = &lt;path to inventory file&gt;<br/>host_key_checking = False</span></pre><p id="05c6" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">通过<strong class="jl hi"> ssh </strong>连接依赖于另一个名为<strong class="jl hi"> sshpass </strong>的软件。要在Red Hat 8上安装，输入<code class="du kr ks kt ku b">dnf install sshpass</code>(这个包可以在<strong class="jl hi"> epel-release </strong> repo中找到，所以要确保yum配置了epel-release存储库)。</p><p id="61ab" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">至此，我们完成了ansible的设置。我们现在可以开始编写剧本来配置Hadoop了。</p></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><h1 id="8b91" class="lm im hh bd in ln lo lp ir lq lr ls iv lt lu lv iz lw lx ly jd lz ma mb jh mc bi translated">创建行动手册</h1><p id="5d6d" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt iw ju jv jw ja jx jy jz je ka kb kc kd ha bi translated">创建一个目录作为您的工作区，例如<code class="du kr ks kt ku b">mkdir /hadoopws <br/></code>在这个工作区内，创建一个剧本(扩展名<strong class="jl hi">)。yml </strong>)，比如<code class="du kr ks kt ku b"> <br/>vim hadoop.yml </code>。</p><p id="d102" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">我们的第一行将有<strong class="jl hi"> hosts </strong>关键字，它带有您希望在其上执行上述任务的主机组的标签。让我们从在名称节点和数据节点上安装JDK和Hadoop安装文件开始。</p><ul class=""><li id="4c4f" class="md me hh jl b jm ke jq kf iw mf ja mg je mh kd mi mj mk ml bi translated"><strong class="jl hi">复制JDK和Hadoop的安装文件</strong></li></ul><p id="bc9c" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">在我的例子中，我将保存在我的控制器节点上的JDK和Hadoop安装文件复制到受管节点中，但是您也可以使用其他的ansible模块，比如<strong class="jl hi"> get_url </strong>来直接从给定的url下载文件。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es mm"><img src="../Images/b5a8f939bb3882518be99cf4cc95cf13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*fgnkqs6Xehc3DjJBswQHWQ.png"/></div></figure><p id="e4a7" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">这里我使用<strong class="jl hi">循环</strong>和内置变量<strong class="jl hi">项</strong>来复制多个文件。<br/>确保您下载了您安装的Hadoop版本支持的JDK。参考此处的<a class="ae mn" href="https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions" rel="noopener ugc nofollow" target="_blank">和</a>来检查哪些版本是兼容的。</p><p id="5735" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">您可以使用<code class="du kr ks kt ku b">ansible-playbook &lt;playbook name&gt;</code>运行您的剧本，看看是否一切正常。如果正确，您的数据节点和名称节点应该将这两个文件保存在您给定的目标中。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es kv"><img src="../Images/e03ee3c0d3d81acd6f81630e70d272ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZXoIDxuvNcooTNGgKN4jsw.png"/></div></div></figure><ul class=""><li id="1df6" class="md me hh jl b jm ke jq kf iw mf ja mg je mh kd mi mj mk ml bi translated"><strong class="jl hi">安装Java和Hadoop并停止防火墙</strong></li></ul><p id="fbbd" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">我们可以使用<strong class="jl hi"> yum </strong>模块安装一个以path为名称属性的包，但是我们需要为Hadoop安装输入<strong class="jl hi"> - force </strong>选项，这就是为什么我们可以只使用<strong class="jl hi">命令</strong>模块。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es mo"><img src="../Images/ea54bea67b6fadf59183271bd3d42bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*wAfVrnL258EFvfbR-hqIGg.png"/></div></figure><p id="6a79" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">我们还将停止两个节点上的防火墙服务，以便当我们启动namenode和datanode时，它们可以相互连接。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es mp"><img src="../Images/ab3194c38bb22085495e55d8217de5d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*4a8fflDHqiJ7J9E6Gp8yzA.png"/></div></figure><ul class=""><li id="3178" class="md me hh jl b jm ke jq kf iw mf ja mg je mh kd mi mj mk ml bi translated"><strong class="jl hi">配置名称节点</strong></li></ul><p id="6121" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">在name节点中，我们使用<strong class="jl hi"> vars_prompt </strong>模块输入我们的目录名。我们的任务包括，<br/> - <strong class="jl hi"> file </strong>模块创建目录<br/> - <strong class="jl hi"> lineinfile </strong>模块输入<em class="kq"> hdfs-site.xml </em>和<em class="kq"> core-site.xml </em>文件中的配置行，位置为<strong class="jl hi"> /etc/hadoop/ </strong>。我们使用<strong class="jl hi"> groups['namenode'][0] </strong>变量从清单文件中获取namenode的IP。这是可能的，因为我们将我们的名称节点IP标记为“name node”。<strong class="jl hi"><br/></strong>——我们最后使用<strong class="jl hi">命令</strong>模块和命令<code class="du kr ks kt ku b">hadoop namenode -format -force</code>和<code class="du kr ks kt ku b">hadoop-daemon.sh start namenode</code>格式化并启动名称节点。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es mq"><img src="../Images/45e81859abf5ae7ef92fba4d1e98985c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mXwKa-_DxuU_xgQXsQiQUw.jpeg"/></div></div></figure><ul class=""><li id="02a3" class="md me hh jl b jm ke jq kf iw mf ja mg je mh kd mi mj mk ml bi translated"><strong class="jl hi">配置数据节点</strong></li></ul><p id="43b3" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">我们在数据节点上执行与名称节点相同的操作，除了我们对目录使用不同的变量名，并且我们的<em class="kq"> hdfs-site.xml </em>也有一点变化。之后，我们可以直接启动datanode。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es mr"><img src="../Images/9bc8d007784e253a5c8030a142825857.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MRnT2XANsORzJfTmXKex0Q.jpeg"/></div></div></figure></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><h1 id="e352" class="lm im hh bd in ln lo lp ir lq lr ls iv lt lu lv iz lw lx ly jd lz ma mb jh mc bi translated"><strong class="ak">完整剧本</strong></h1><pre class="kw kx ky kz fd le ku lf lg aw lh bi"><span id="da07" class="il im hh ku b fi li lj l lk ll">- hosts: namenode, datanode<br/>  tasks:<br/>       - name: "Copying Installation Files"<br/>         copy:<br/>             src: "{{ item }}"<br/>             dest: "/root/Downloads/"<br/>         loop:<br/>             - /root/Downloads/jdk-8u171-linux-x64.rpm<br/>             - /root/Downloads/hadoop-1.2.1-1.x86_64.rpm</span><span id="b7cb" class="il im hh ku b fi ms lj l lk ll">- name: "Installing Java and Hadoop"<br/>         ignore_errors: yes<br/>         command: "rpm -i {{ item }}"<br/>         loop:<br/>             - /root/Downloads/jdk-8u171-linux-x64.rpm<br/>             - /root/Downloads/hadoop-1.2.1-1.x86_64.rpm --force</span><span id="02f2" class="il im hh ku b fi ms lj l lk ll">- name: "Stopping firewalld service"<br/>         ignore_errors: yes<br/>         command: "systemctl stop firewalld"</span><span id="fd3c" class="il im hh ku b fi ms lj l lk ll">- hosts: namenode<br/>  vars_prompt:<br/>       - name: nndir<br/>         private: no<br/>         prompt: "Enter location directory path and name for Name Node"</span><span id="0c0a" class="il im hh ku b fi ms lj l lk ll">tasks:<br/>       - name: "Creating Name Node Directory"<br/>         file:<br/>             state: directory<br/>             path: "{{ nndir }}"</span><span id="b9fd" class="il im hh ku b fi ms lj l lk ll">- name: "Configuring hdfs-site.xml in Name Node"<br/>         lineinfile:<br/>                 path: "/etc/hadoop/hdfs-site.xml"<br/>                 insertafter: "&lt;configuration&gt;"<br/>                 line: "&lt;property&gt;<br/>                   \n\t &lt;name&gt;dfs.name.dir&lt;/name&gt;<br/>                   \n\t &lt;value&gt;{{ nndir }}&lt;/value&gt;<br/>                     \n &lt;/property&gt;"</span><span id="fe2e" class="il im hh ku b fi ms lj l lk ll">- name: "Configuring core-site.xml in Name Node"<br/>         lineinfile:<br/>                 path: "/etc/hadoop/core-site.xml"<br/>                 insertafter: "&lt;configuration&gt;"<br/>                 line: "&lt;property&gt;<br/>                   \n\t &lt;name&gt;fs.default.name&lt;/name&gt;<br/>                   \n\t &lt;value&gt;hdfs://{{ groups['namenode'][0] }}:9001&lt;/value&gt;<br/>                     \n &lt;/property&gt;"</span><span id="01bc" class="il im hh ku b fi ms lj l lk ll">- name: "Formatting Name Node Directory"<br/>         ignore_errors: yes<br/>         command: "hadoop namenode -format -force"<br/>       - name: "Starting Name Node daemon"<br/>         ignore_errors: yes<br/>         command: "hadoop-daemon.sh start namenode"</span><span id="c4af" class="il im hh ku b fi ms lj l lk ll">- hosts: datanode<br/>  vars_prompt:<br/>       - name: dndir<br/>         private: no<br/>         prompt: "Enter location directory path and name for Data Node"</span><span id="73f7" class="il im hh ku b fi ms lj l lk ll">tasks:<br/>       - name: "Creating Data Node Directory"<br/>         file:<br/>             state: directory<br/>             path: "{{ dndir }}"</span><span id="74b9" class="il im hh ku b fi ms lj l lk ll">- name: "Configuring hdfs-site.xml in Data Node"<br/>         lineinfile:<br/>                 path: "/etc/hadoop/hdfs-site.xml"<br/>                 insertafter: "&lt;configuration&gt;"<br/>                 line: "&lt;property&gt;<br/>                   \n\t &lt;name&gt;dfs.data.dir&lt;/name&gt;<br/>                   \n\t &lt;value&gt;{{ dndir }}&lt;/value&gt;<br/>                     \n &lt;/property&gt;"</span><span id="fddd" class="il im hh ku b fi ms lj l lk ll">- name: "Configuring core-site.xml in Data Node"<br/>         lineinfile:<br/>                 path: "/etc/hadoop/core-site.xml"<br/>                 insertafter: "&lt;configuration&gt;"<br/>                 line: "&lt;property&gt;<br/>                   \n\t &lt;name&gt;fs.default.name&lt;/name&gt;<br/>                   \n\t &lt;value&gt;hdfs://{{ groups['namenode'][0] }}:9001&lt;/value&gt;<br/>                     \n &lt;/property&gt;"</span><span id="7aeb" class="il im hh ku b fi ms lj l lk ll">- name: "Starting Data Node daemon"<br/>         ignore_errors: yes<br/>         command: "hadoop-daemon.sh start datanode"</span></pre></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><h2 id="f874" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">运行剧本，</h2><p id="3a42" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt iw ju jv jw ja jx jy jz je ka kb kc kd ha bi translated">使用命令<code class="du kr ks kt ku b">ansible-playbook &lt;playbook-name&gt;<br/></code>,您可以通过在name node或data node上运行<code class="du kr ks kt ku b">hadoop dfsadmin -report </code>来确保您的数据节点正在共享存储。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/8acb4da4fc3a09c52d95b390e47603c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*6zx_FWUS5lSoaRGQSjH34Q.png"/></div></figure></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><blockquote class="mu mv mw"><p id="ad2f" class="jj jk kq jl b jm ke jo jp jq kf js jt mx kg jv jw my kh jy jz mz ki kb kc kd ha bi translated">只需将数据节点的IP地址添加到数据节点标签下的清单文件中，就可以添加更多的数据节点。</p><p id="289c" class="jj jk kq jl b jm ke jo jp jq kf js jt mx kg jv jw my kh jy jz mz ki kb kc kd ha bi translated">请记住，如果系统中保存了hadoop的任何缓存文件，重复运行本行动手册可能不起作用。因此，要为新集群重新运行行动手册，请确保您删除了<strong class="jl hi"> /etc/hadoop/ </strong>目录(如果您在运行行动手册时给出了与之前相同的目录名称，那么namenode和datanode目录，即<strong class="jl hi"> /nn </strong>和<strong class="jl hi"> /dn </strong>、<strong class="jl hi"> </strong>也应该被删除)。</p></blockquote><p id="ec6e" class="pw-post-body-paragraph jj jk hh jl b jm ke jo jp jq kf js jt iw kg jv jw ja kh jy jz je ki kb kc kd ha bi translated">希望这有所帮助:)</p></div></div>    
</body>
</html>