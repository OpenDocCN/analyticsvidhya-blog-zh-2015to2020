<html>
<head>
<title>Random Forests Interpretation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">随机森林解释</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/rf-interpretation-season-2-ce74a4c32ab4?source=collection_archive---------2-----------------------#2019-08-04">https://medium.com/analytics-vidhya/rf-interpretation-season-2-ce74a4c32ab4?source=collection_archive---------2-----------------------#2019-08-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="7d8f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">第2部分:编码技术和树状图</h2></div><p id="135f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇博文中，我将讨论剩余的随机森林解释技术，以改进使用随机森林的预测。我也推荐读者们去看看我的 <a class="ae ju" rel="noopener" href="/@machine_tyro/rf-interpretation-season-1-e4bdbd10e0fe"> <em class="jt">上一篇文章</em> </a> <em class="jt">来更好地理解下面的文章。</em></p><h1 id="fb04" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">One Hot编码到底是什么？</h1><p id="22d2" class="pw-post-body-paragraph ix iy hi iz b ja kn ij jc jd ko im jf jg kp ji jj jk kq jm jn jo kr jq jr js hb bi translated">让我们用一个例子来理解这个可怕的术语。请容忍我。<br/>考虑一个列名为WeekDay(分类变量)的数据集，它告诉我们一周中的某一天，即，是星期天、星期一还是其他任何一天。现在，数据集中还有其他列，但在整个数据集中最重要的是，这一天是不是星期天，因为让我们假设星期天是国定假日，它通过流形影响数据集。</p><p id="b310" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，训练模型的代码是以这样的方式编写的，如果那天是第n个分裂中的星期天。到那时，Sunday参数变得很重要，一半的数据集已经被分割，因此，重要的东西根本不重要。这可能导致非常错误和非常不可接受的结果，让任何著名的组织承担巨大的损失。但是有一种方法可以解决这个问题。现在，这些都是一次性编码突然出现的情况。</p><blockquote class="ks kt ku"><p id="d7e9" class="ix iy jt iz b ja jb ij jc jd je im jf kv jh ji jj kw jl jm jn kx jp jq jr js hb bi translated"><strong class="iz hj">幕后<br/> </strong>这个特性的作用是创建类别数作为单独的列，并删除父列。它分配二进制值，即0或1，这取决于它是否满足条件，否则它分配s 1和0。让我们用上面同样的例子来理解它。One-hot-encoding会将WeekDay分类变量分成以下类别:<br/> 1。工作日_周日<br/> 2。工作日_星期二<br/> 3。工作日_周三<br/> 4。工作日_周四<br/> 5。工作日_星期五<br/> 6。WeekDay_saturday <br/>它将销毁父变量WeekDay。</p></blockquote><p id="02a4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，估计者可以自由地考虑任何列，一些估计者将足够幸运地抓住要点。现在，如果您将特征工程应用于您的模型，我们可能会处理不同的结果，一组不同的参数可能比其他参数更重要。</p><p id="4fba" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个热编码并不总是能改善结果？可能会有这样的情况，它恶化了模型的性能，可能是因为维数灾难。至少在那些场景中，我们会知道一些其他的基本特性。</p><p id="17a7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以我们可以足够快地进行一次热编码，我们这样做的方法是传递一个额外的参数，这个参数就是类别的最大数量。因此，如果我们说它是7，那么任何少于7级的都将被转换为一个热编码的列束。您可以如下设置该参数。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es ky"><img src="../Images/993fd1e0b754df72d88225eda7f11973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*LCGODAkQ9hd_Ki02JS7oEw.png"/></div></figure><h1 id="2066" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">冗余是重复，去掉重复</h1><p id="0952" class="pw-post-body-paragraph ix iy hi iz b ja kn ij jc jd ko im jf jg kp ji jj jk kq jm jn jo kr jq jr js hb bi translated">有时在我们的数据集中，我们有非常相似的特征，并且可能没有什么额外的我们可以通过拥有冗余的特征来实现。所以还是去掉不必要的特性比较好。现在问题来了，</p><blockquote class="ks kt ku"><p id="66a4" class="ix iy jt iz b ja jb ij jc jd je im jf kv jh ji jj kw jl jm jn kx jp jq jr js hb bi translated"><strong class="iz hj"> <em class="hi">如何了解冗余功能？</em> </strong></p></blockquote><p id="c244" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">聚类分析</strong>:与把相似的东西聚类成一个有关，一般是两个东西的平均值。有一种聚类技术现在没有广泛使用，但在寻找冗余特征时非常有用。它被称为层次聚类或聚集聚类。</p><p id="b955" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在层次聚类中，我们采用自下而上的类比。我们考虑每一个物体，并与其他物体进行比较。我们把相似的物体组合起来，进行同样的过程。与k-means中比较没有标签的行不同，这里我们比较完整的对象，或者更清楚地说，我们完全比较两个特征。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es lg"><img src="../Images/51fe5ddb15bd385d447c5d4288bddcf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*oE4IazBs3Gyv8flYn0x84A.png"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">分层聚类</figcaption></figure><p id="a7df" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以通过上面的图片来确认我们的理解。</p><p id="f74b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们使用树状图来绘制层次聚类。下面是绘图的代码。</p><pre class="kz la lb lc fd ll lm ln lo aw lp bi"><span id="308a" class="lq jw hi lm b fi lr ls l lt lu">from scipy.cluster import hierarchy as hc</span><span id="3389" class="lq jw hi lm b fi lv ls l lt lu">corr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)</span><span id="a367" class="lq jw hi lm b fi lv ls l lt lu">corr_condensed = hc.distance.squareform(1-corr)<br/>z = hc.linkage(corr_condensed, method='average')<br/>fig = plt.figure(figsize=(16,10))<br/>dendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)</span><span id="8b72" class="lq jw hi lm b fi lv ls l lt lu">plt.show()</span></pre><p id="3c6a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的代码中，在绘制树状图之前，我们正在计算spearman的相关系数。</p><p id="ef59" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">有什么关联？<br/> </strong>相关性类似于R，但它是在两个对象之间而不是在实际值和预测值之间。</p><p id="6993" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们计算秩相关是因为对于单调非减函数一般是一条直线。这只是一个程序。<br/>现在，如果你运行上面的代码，一个非常连贯的情节就会出现，如下所示。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es lw"><img src="../Images/07c8cb5960d8d3bf7d2ced3fcdc9b8ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*PvGL2AqONrf1NMYsvx7O1w.png"/></div></figure><p id="f8af" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，您知道哪些功能是多余的，哪些不是。此外，您可能会看到移除oob_score上的冗余要素的效果，并推断哪些要素可能会从数据集中删除。你可以遵循以下策略。</p><pre class="kz la lb lc fd ll lm ln lo aw lp bi"><span id="742e" class="lq jw hi lm b fi lr ls l lt lu">def calc_oob_score(df):<br/>    m = RandomForestRegressor(n_estimators=30, min_samples_leaf=5, max_features=0.6, n_jobs=-1, oob_score=True)<br/>    m.fit(independent_dataset_values, dependent_dataset_values)<br/>    return m.oob_score_</span><span id="25dd" class="lq jw hi lm b fi lv ls l lt lu">for col in ('A', 'B', 'E', 'F'):<br/>    print(col, get_oob(independent_dataset_values.drop(col, axis=1)))</span></pre><p id="4a4b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，我们在没有任何冗余变量的情况下训练了我们的模型。</p><h1 id="1451" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">什么是树解释器？</h1><p id="cfbf" class="pw-post-body-paragraph ix iy hi iz b ja kn ij jc jd ko im jf jg kp ji jj jk kq jm jn jo kr jq jr js hb bi translated">这是一个非常酷的技术，它告诉你通往你的预测的道路。假设你做了一个预测，现在你的客户想知道预测背后的原因，那么你可以使用树解释器显示你的预测的完整详细的路径。</p><pre class="kz la lb lc fd ll lm ln lo aw lp bi"><span id="b93c" class="lq jw hi lm b fi lr ls l lt lu">pip install treeinterpreter</span><span id="219f" class="lq jw hi lm b fi lv ls l lt lu"><strong class="lm hj">from</strong> <strong class="lm hj">treeinterpreter</strong> <strong class="lm hj">import</strong> treeinterpreter <strong class="lm hj">as</strong> ti<br/>prediction, bias, contributions = ti.predict(m, row)</span></pre><p id="2a55" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><code class="du lx ly lz lm b">ti.predict</code>函数获取随机的森林和行(您想要在其上探索预测结果)。它会给我三样东西:</p><ul class=""><li id="93f7" class="ma mb hi iz b ja jb jd je jg mc jk md jo me js mf mg mh mi bi translated"><code class="du lx ly lz lm b">prediction</code>:来自随机森林的预测</li><li id="6744" class="ma mb hi iz b ja mj jd mk jg ml jk mm jo mn js mf mg mh mi bi translated"><code class="du lx ly lz lm b">bias</code>:整个原始数据集中因变量的平均值，即任何分割前的初始值。</li><li id="94d9" class="ma mb hi iz b ja mj jd mk jg ml jk mm jo mn js mf mg mh mi bi translated"><code class="du lx ly lz lm b">contributions</code>:一列和要分割的值(即预测值)，以及它对预测值的改变程度。</li></ul><p id="2b62" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以，现在你不仅对你的预测有把握，而且你还可以展示你的预测的完整路径。</p><p id="c56c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，这些是广泛使用的随机森林解释方法。我建议读者多了解他们。</p></div></div>    
</body>
</html>