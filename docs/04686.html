<html>
<head>
<title>One more gem to your Data Science Crown!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">您的数据科学王冠上又多了一颗宝石！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/one-more-gem-to-your-data-science-crown-12cac0b1c627?source=collection_archive---------23-----------------------#2020-03-28">https://medium.com/analytics-vidhya/one-more-gem-to-your-data-science-crown-12cac0b1c627?source=collection_archive---------23-----------------------#2020-03-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2d5cabeebe002172f9f01f9d95cb723c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eivq2Y4BeAoWhSXr"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@vidarnm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">维达尔·诺德里-马西森</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="795f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated">数据科学是本世纪最受欢迎的领域之一。如果你在谷歌上搜索成为一名数据科学家所需的技能，有很多网站列出了根据你目前的技能和经验成为一名数据科学家所需掌握的“n”种技能。数据科学是一个如此广阔的领域，它本身包含了如此多的不同领域。当你阅读这篇文章的时候，这个领域每天都在发展，所以没有一套预先定义的技能可以让你成为一名数据科学家。这篇文章讲的是一项技能，它不是<em class="kc">必须具备的技能，</em>而是<em class="kc">必须具备的技能。</em></p><p id="2979" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们想象一下这样一种情况，你在谷歌上为你的下一个项目寻找一些有趣的数据集，然后你偶然发现一个网站有你正在寻找的数据类型。你只希望这些数据是可下载的格式。如果有一种方法可以不用手工复制粘贴就可以获得web数据，那会怎么样？嗯，有。完成这项工作的方法或过程称为爬行或Web爬行。</p><h2 id="ab04" class="kd ke hi bd kf kg kh ki kj kk kl km kn jg ko kp kq jk kr ks kt jo ku kv kw kx bi translated">什么是网络爬行？</h2><p id="906f" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">Web爬行是一种浏览Web内容的机械化能力，通过开发爬行器或机器人或蜘蛛来遍历页面最深处的不断变化的密集内容。虽然大多数人把网络爬行和网络抓取混为一谈，但是<a class="ae iu" href="https://en.wikipedia.org/wiki/Web_scraping" rel="noopener ugc nofollow" target="_blank">网络抓取</a>也被称为网络数据提取、网络收获等。只是使用自动化工具或软件提取数据，这些工具或软件可以来自任何地方— web、数据库、电子表格、本地机器等。</p><p id="199a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意:这篇文章是对爬行的固执己见。</p><h2 id="40fa" class="kd ke hi bd kf kg kh ki kj kk kl km kn jg ko kp kq jk kr ks kt jo ku kv kw kx bi translated">为什么要抓取网页？</h2><p id="6fdb" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">虽然有些人认为web抓取已经足够了，因为爬行可能需要一些复杂的技能，但我仍然建议您学习如何构建一个爬虫，而不仅仅是通过抓取来提取数据。爬行并不像许多人认为的那样需要专业的编程技能。让我用一个例子来支持我的观点。</p><p id="cbd2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我参与了一个机器学习项目，该项目根据市值分析了《经济时报》500强公司的不同部门。经济时报<a class="ae iu" href="https://economictimes.indiatimes.com/et500" rel="noopener ugc nofollow" target="_blank">在这里</a>公开了这个项目所需的数据。如果您访问该页面，您将看到一个项目表，其中仅包含前25家公司，您必须再次单击下一个箭头，一次又一次地查看其余数据，从技术上讲，它们是不同的页面。好吧，那是乏味的。此外，您只能从这组链接中获取2019年的数据。如果我想对比2018年的数据和2010年的数据呢？在这种情况下，爬虫可以减轻你的痛苦。除非您另外指定，否则它会通过链接浏览大量页面。有很多爬行框架，比如用Python写的<a class="ae iu" href="https://scrapy.org/" rel="noopener ugc nofollow" target="_blank"> scrapy </a>，你可以学习一些基础教程。</p><h2 id="5e70" class="kd ke hi bd kf kg kh ki kj kk kl km kn jg ko kp kq jk kr ks kt jo ku kv kw kx bi translated">作为一名数据科学家，爬行对您有什么好处？</h2><blockquote class="ld le lf"><p id="6cdb" class="iv iw kc ix b iy iz ja jb jc jd je jf lg jh ji jj lh jl jm jn li jp jq jr js hb bi translated">数据越多，数据科学家越开心。</p></blockquote><p id="b23e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据是推动整个数据科学生态系统的燃料。在数据科学项目中，总是有空间容纳更多的数据。web上有超过10亿个页面，它包含的数据量超过100万兆兆字节。网络上的潜在数据可以提供令人信服的见解，但并非所有这些数据都可以获得和使用，因为它们是非结构化的。爬行可以将非结构化(人类可读)内容转换为结构化(机器可读)数据。</p><p id="4761" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">机器学习就是训练模型，在训练数据中寻找模式。评估机器学习模型的最佳方式是为它提供测试数据，看看它的表现如何。你可以抓取更多的数据，这可能会改变你的机器学习模式。更多的数据可以提高机器学习模型的性能和效率。</p><p id="0bb4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于在线社交网络(OSNs)的研究和分析，将需要大量的数据，这些数据可以从各种社交媒体网站获得。网络抓取可以用来抓取金融新闻网站的内容，监控市场趋势和预测股票指数的情绪。爬行在预测建模、自然语言处理、推荐引擎、实时数据分析、分类、聚类等方面也有应用。</p><h2 id="93ba" class="kd ke hi bd kf kg kh ki kj kk kl km kn jg ko kp kq jk kr ks kt jo ku kv kw kx bi translated">哪个字段可以利用爬网数据？</h2><p id="c318" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">研究和调查性新闻、股票市场、旅游和酒店、零售企业、保险行业、医疗保健公司、餐馆、房地产等等。</p><h2 id="2c59" class="kd ke hi bd kf kg kh ki kj kk kl km kn jg ko kp kq jk kr ks kt jo ku kv kw kx bi translated">Python中的一些爬行库可以帮助您入门</h2><ul class=""><li id="f003" class="lj lk hi ix b iy ky jc kz jg ll jk lm jo ln js lo lp lq lr bi translated"><a class="ae iu" href="https://scrapy.org/" rel="noopener ugc nofollow" target="_blank">刺儿头</a></li><li id="fb08" class="lj lk hi ix b iy ls jc lt jg lu jk lv jo lw js lo lp lq lr bi translated"><a class="ae iu" href="http://docs.pyspider.org/en/latest/" rel="noopener ugc nofollow" target="_blank"> PySpider </a></li><li id="ff2f" class="lj lk hi ix b iy ls jc lt jg lu jk lv jo lw js lo lp lq lr bi translated"><a class="ae iu" href="https://mechanicalsoup.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank">机械汤</a></li><li id="263a" class="lj lk hi ix b iy ls jc lt jg lu jk lv jo lw js lo lp lq lr bi translated"><a class="ae iu" href="https://selenium-python.readthedocs.io/" rel="noopener ugc nofollow" target="_blank">硒</a></li><li id="5d1d" class="lj lk hi ix b iy ls jc lt jg lu jk lv jo lw js lo lp lq lr bi translated"><a class="ae iu" href="https://pypi.org/project/requests-crawler/" rel="noopener ugc nofollow" target="_blank">请求</a></li><li id="24a1" class="lj lk hi ix b iy ls jc lt jg lu jk lv jo lw js lo lp lq lr bi translated"><a class="ae iu" href="https://docs.python.org/3.4/howto/urllib2.html" rel="noopener ugc nofollow" target="_blank"> Urllib </a></li></ul><p id="5831" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽管有些人认为抓取网页是非法的，但只要它遵守服务条款，它就不是非法的。这完全取决于你如何做，以及你如何处理获得的数据。这种技能可以让你脱颖而出，如果你倾向于在跨职能部门工作，它可以证明自己是一项宝贵的资产。</p><p id="f4cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">爬行愉快！</p><p id="1604" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">感谢你一路阅读到这里。如果有任何关注/反馈/批评请在评论区告诉我。祝你愉快，:D</p></div></div>    
</body>
</html>