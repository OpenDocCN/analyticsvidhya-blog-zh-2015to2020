<html>
<head>
<title>Transformer vs RNN and CNN for Translation Task</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">变压器vs RNN和CNN的翻译任务</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/transformer-vs-rnn-and-cnn-18eeefa3602b?source=collection_archive---------0-----------------------#2019-08-13">https://medium.com/analytics-vidhya/transformer-vs-rnn-and-cnn-18eeefa3602b?source=collection_archive---------0-----------------------#2019-08-13</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><figure class="ev ex im in io ip er es paragraph-image"><div role="button" tabindex="0" class="iq ir di is bf it"><div class="er es il"><img src="../Images/a6677bb056b6b0ab0cfd6cfdc3e04b2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TUdU__KY3uBHyfi17g-jiw.jpeg"/></div></div><figcaption class="iw ix et er es iy iz bd b be z dx translated">图示:<a class="ae ja" href="http://www.ebisss.com/translation-interpretation-services-kuala-lumpur-kl.html" rel="noopener ugc nofollow" target="_blank">http://www . ebisss . com/translation-interpretation-services-Kuala-Lumpur-KL . html</a></figcaption></figure><h1 id="cd1b" class="jb jc ho bd jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy bi translated">先决条件</h1><p id="ffea" class="pw-post-body-paragraph jz ka ho kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw hh bi translated">对于具有深度学习的自动翻译，使用序列对序列模型(Seq2Seq)，具有诸如RNN和CNN的架构，并通过添加注意力机制。以下是理解这篇文章的一些参考:</p></div></div>    
</body>
</html>