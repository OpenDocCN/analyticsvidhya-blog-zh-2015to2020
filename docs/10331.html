<html>
<head>
<title>Damage Detection using CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 CNN 的损伤检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/damage-detection-using-cnn-b72c931d23c8?source=collection_archive---------11-----------------------#2020-10-14">https://medium.com/analytics-vidhya/damage-detection-using-cnn-b72c931d23c8?source=collection_archive---------11-----------------------#2020-10-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3edd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">阿育王大学</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/c9edfb17aa91b30c0245c8b37561e176.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/1*3ecOai7S4ah73bBY7Jp4EA.gif"/></div></figure><h1 id="7f59" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">摘要</h1><p id="7332" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">计算机视觉的最新进展已经产生了高度精确的图像分类算法，例如卷积神经网络(CNN)架构。在本研究中，我们在 Keras 深度学习框架中测试并实现了一个基于 CNN 的算法，Keras 深度学习框架是 Tensorflow 之上的一个高级 API。Keras 最近变得非常出名，因为它能够轻松地构建复杂的模型并快速迭代。</p><p id="0fc6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用深度学习方法，使用 CNN 来演示如何建立一个神经网络，将区域分类为<em class="jd">“受损”</em>和<em class="jd">“未受损”</em>，这更通常被称为二进制图像分类问题。这两个类别包括基于自然灾害发生的图像，即:洪水、地震和火灾。遥感光学图像是一个巨大的信息源，可用于时间紧迫的任务，如损害检测和评估，以便立即提供救济援助。我们提出的模型为损伤检测提供了良好的准确性；我们还观察到显著的执行速度。我们没有使用玩具数据集来构建我们的模型，而是编译了我们自己的多类图像分类数据集来区分受损区域和未受损区域。</p><h1 id="3616" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">CNN 理论</h1><p id="7290" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">卷积神经网络(CNN)是多层全连接神经网络。它们由一个输入层、多个隐藏层和一个输出层组成。我们通过增加隐藏层的数量使网络更深。CNN 接收输入图像，执行数学运算(使用非线性激活函数，如 ReLU、sigmoid ),并预测输出的类别或标签概率。它们将输入图像的原始像素亮度作为展平向量。例如，[30x30]彩色图像将作为三维矩阵传递到 CNN 的输入层。</p><p id="5d29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积神经网络(CNN)具有如下三种类型的层:</p><h2 id="bb93" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">1.卷积层(CONV)</h2><p id="7745" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">这是 CNN 通过移动小过滤器从输入图像中学习特征的层。CONV 层包含过滤器(例如[3x3]或[5x5])，这些过滤器与输入矩阵进行卷积，并在给定的空间位置学习要素。对于过滤器的每个位置，计算过滤器和过滤器下的图像像素之间的点积，这在输出图像中产生单个像素。因此，在整个图像中移动滤波器会产生新的图像，卷积层中的每个滤波器对应一个图像。</p><p id="1d62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CONV 层有 3 个关键参数:<br/><strong class="ih hj"/>—用于卷积运算的滤波器数量。<br/><strong class="ih hj"/>—过滤矩阵覆盖输入矩阵的像素数。<br/> <strong class="ih hj">填充</strong> —如果需要，用于在输入体积的边界周围添加零。</p><h2 id="6f6d" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">2.汇集层(池)</h2><p id="3d7a" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">该层用作网络中的中间层，在该层中，它沿空间维度对传入的体积进行下采样或压缩，以减少网络中的过拟合，但保留最重要的信息。例如，如果输入体积为[64x64x12]，则其缩减取样体积将为[32x32x12]。</p><h2 id="ea8a" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated"><strong class="ak"> 3。全连接层(FC) </strong></h2><p id="f793" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">在全连接层中，每个节点都与前一层中的所有其他节点相连。这一 FC 层通常作为 CNN 的最后一层，其激活函数为<strong class="ih hj"> <em class="jd"> SIGMOID </em> </strong>用于多类分类问题。FC 层负责预测输入图像的最终类别或标签。因此，它的输出维数为[1x1xN],其中 N 表示考虑用于分类的类或标签的数量。</p><p id="955d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">层中的给定节点取其输入的加权和，并将其通过非线性激活函数。这是节点的输出，然后成为下一层中另一个节点的输入。信号从左向右流动，通过对所有节点执行该过程来计算最终输出。训练这个深度神经网络意味着学习与所有边相关联的权重。注意 TensorFlow 中的计算实际上是对一批图像而不是单张图像进行的，这样计算效率更高。</p><h1 id="8e59" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">方法学</h1><p id="2d60" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">该模型从头开始构建，以更好地匹配与手动整理的详尽数据集相关的参数，该数据集由三种自然灾害的图像组成:洪水、地震和火灾。为了确保模型的稳健性，我们在每一类自然灾害中加入了全球不同时期发生的大量事件的图片。图像也被下采样至 200x200，因此图像分辨率在整个数据集中是一致的。</p><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="c063" class="kp jn hi le b fi li lj l lk ll"><strong class="le hj">#Importing Libraries<br/></strong>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import os<br/>import cv2<br/>import tensorflow as tf<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from tensorflow.keras.models import Sequential <br/>from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D<br/>from tensorflow.keras.callbacks import TensorBoard<br/>import time</span></pre><h2 id="2603" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">加载数据集</h2><p id="1981" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">该数据集包括 1，505 个图像，其中 750 个标签用于受损类别，755 个标签用于未受损类别。这些数据被用来训练我们的模型。您可以在这里访问数据集<a class="ae lm" href="https://github.com/AakritiJain98/Damage_detection_using_CNN" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="3e67" class="kp jn hi le b fi li lj l lk ll">DATADIR= "...file path..."<br/>CATEGORIES=["Damaged","Undamaged"]</span><span id="2a88" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Iterate through the two categories<br/></strong>for category in CATEGORIES:<br/>    path= os.path.join(DATADIR,category)<br/>    for img in os.listdir(path):<br/>        img_array= cv2.imread(os.path.join(path,img)) <br/>        plt.imshow(img_array)<br/>        plt.show()<br/>        break<br/>    break</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lo"><img src="../Images/37308aebc97a6f0faced2171b8cd989e.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*_sp8LP3ShSSxMtCrYTdr0Q.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">PS:运行这段代码时，任何随机图像都可能出现在我们的数据集中</figcaption></figure><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="b854" class="kp jn hi le b fi li lj l lk ll">IMG_SIZE= 200</span><span id="9801" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Resizing all images to one size <br/></strong>training_data=[]<br/>def create_training_data():<br/>    for category in CATEGORIES:<br/>        path= os.path.join(DATADIR,category) <br/>        class_num = CATEGORIES.index(category)<br/>        for img in os.listdir(path):<br/>            try:<br/>                img_array= cv2.imread(os.path.join(path,img))<br/>                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))<br/>                training_data.append([new_array,class_num])<br/>            except Exception as e:<br/>                pass</span><span id="82ea" class="kp jn hi le b fi ln lj l lk ll">create_training_data()</span><span id="1dc0" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Checking the new image size <br/></strong>new_array.shape</span></pre><h2 id="4e0f" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">训练模型</h2><p id="67b4" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">批次标准化用于训练非常深的神经网络，该神经网络将每个批次的输入标准化到一个层。这稳定了学习过程，并显著减少了训练时期的数量，从而加速了深度学习神经网络的训练。</p><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="6b6c" class="kp jn hi le b fi li lj l lk ll"><strong class="le hj">#Creating features and labels for the images in our dataset<br/></strong>X_calamity=[]#features<br/>y_calamity=[]#labels</span><span id="6dd0" class="kp jn hi le b fi ln lj l lk ll">for features, label in training_data:<br/>    X_calamity.append(features)<br/>    y_calamity.append(label)</span><span id="3d1b" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Converting image input to array <br/></strong>X_calamity= np.array(X_calamity).reshape(-3,IMG_SIZE,IMG_SIZE,3)</span><span id="37ec" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Normalising the image input array<br/></strong>X_calamity=X_calamity/255.0</span></pre><h1 id="a3f6" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">制定模型</h1><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lt"><img src="../Images/2862a58c82bc8976b8ffd3129dee44b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bWsIyoHRjWOR2Sbe7Jh6AA.png"/></div></div></figure><p id="e351" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们添加了六个卷积层，每个卷积层都包含一个 ReLU 激活函数，每个卷积层后面都有一个大小为 2x2 的最大池层。</p><p id="dd96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用滤波器权重在第一卷积层中处理输入图像。这导致 32 个新图像，卷积层中的每个滤波器一个图像(内核大小= 3 意味着卷积滤波器是 3x3 像素，我们已经采用了 32 个这样的滤波器)。</p><p id="861d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后在第二卷积层中处理这 32 个较小的图像。在第二个卷积层，我们有 64 个新的过滤器(每个卷积过滤器是 3x3 像素)。</p><p id="ffd6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">保持每个滤镜的内核大小不变(3x3 像素)，我们在后续的 conv3 层中进一步将滤镜数量增加到 128 个。此后，我们逐渐将滤波器数量减少到 conv4 中的 64 个、conv5 中的 32 个以及 conv6 中的 16 个。</p><p id="64d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些然后被展平为单个向量，该向量被用作具有 32 个神经元(或元素)的全连接层的输入。这馈入另一个具有 2 个神经元的全连接层，每个神经元用于{0，1}中的每个类别，这确定图像属于受损(类别=0)还是未受损(类别=1)类别。</p><p id="76e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Sigmoid 激活函数应用于输出层。使用二进制交叉熵测量损失。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es ly"><img src="../Images/11ed3a8a5ab7de7c99b01561c7fca691.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KgwT6L6tpoxZXx1nRE3Zhg.jpeg"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">来源:https://images.app.goo.gl/X5dk5G58bdcjykyw7</figcaption></figure><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="bf6f" class="kp jn hi le b fi li lj l lk ll">model = Sequential()</span><span id="7324" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Second Convolutional layer</strong><br/>model.add(Conv2D(kernel_size=3, strides=1, filters=64, padding='same', activation='relu', name='layer_conv2'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="ca8d" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Third Convolutional layer<br/></strong>model.add(Conv2D(kernel_size=3, strides=1, filters=128, padding='same', activation='relu', name='layer_conv3'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="8b66" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Drop-out layer <br/></strong>model.add(Dropout(0.25))<br/>model.add(MaxPooling2D(pool_size=2, strides=2))</span><span id="3faa" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Fourth Convolutional layer<br/></strong>model.add(Conv2D(kernel_size=3, strides=1, filters=64, padding='same', activation='relu', name='layer_conv4'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="fa27" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Fifth Convolutional layer<br/></strong>model.add(Conv2D(kernel_size=3, strides=1, filters=32, padding='same', activation='relu', name='layer_conv5'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="cd80" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Sixth Convolutional layer<br/></strong>model.add(Conv2D(kernel_size=3, strides=1, filters=16, padding='same', activation='relu', name='layer_conv6'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="e75d" class="kp jn hi le b fi ln lj l lk ll">model.add(Flatten())<br/>model.add(Dense(32)) #Fully Connected Layer<br/>model.add(Activation("relu"))</span><span id="1bfc" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Output layer <br/></strong>model.add(Dense(1))<br/>model.add(Activation('sigmoid'))</span><span id="bc94" class="kp jn hi le b fi ln lj l lk ll">model.compile(loss="binary_crossentropy",<br/>             optimizer="adam", metrics=['accuracy'])</span><span id="8c37" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Displaying model summary statistics<br/></strong>model.summary()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lz"><img src="../Images/bad2b0c96d9d42789908af96d33af006.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*GivBkD-gwQJ2Q75o-7p2-g.png"/></div></figure><p id="de5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积滤波器最初是随机选择的，因此分类也是随机进行的。输入图像的预测类别和真实类别之间的误差被测量为所谓的交叉熵。然后，优化器使用微分链规则通过卷积网络自动传播该误差，并更新滤波器权重，以改善分类误差。这被重复多次，直到分类误差足够低。</p><h2 id="8f00" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">结果</h2><p id="a280" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">所有参数都设置为通过最小化执行时间来提供最佳精度。65 个样本用于训练，其中任意 10%的图像用于验证。我们能够在仅仅 20 个时期内获得几乎 90%的准确度，其中运行单个时期所花费的时间最多为 3 秒。</p><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="271d" class="kp jn hi le b fi li lj l lk ll">model.fit(X_calamity, y_calamity, batch_size=65, epochs=20, validation_split=0.1)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es ma"><img src="../Images/4b73e40718f461ab52a5542e97a5ee1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nySuncDbn2tDsAnGzY7nJA.jpeg"/></div></div></figure><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="0e4d" class="kp jn hi le b fi li lj l lk ll"><strong class="le hj">#Evaluating the model<br/></strong>result = model.evaluate(x=X_calamity, y=y_calamity)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mb"><img src="../Images/0450fc6694b2c13b0923fd1a24b5f94f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*_DH6IjO2BBI_Z3216aZXaQ.png"/></div></figure><h1 id="d414" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">可视化结果</h1><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="1254" class="kp jn hi le b fi li lj l lk ll"><strong class="le hj">#Helper Function to plot images <br/></strong>def plot_images(images, cls_true, cls_pred=None):<br/>    assert len(images) == len(cls_true) == 9<br/>    <br/><strong class="le hj">    # Create figure with 3x3 sub-plots<br/></strong>    fig, axes = plt.subplots(3, 3)<br/>    fig.subplots_adjust(hspace=0.3, wspace=0.3)</span><span id="1dec" class="kp jn hi le b fi ln lj l lk ll">for i, ax in enumerate(axes.flat):<br/><strong class="le hj">        # Plot image<br/></strong>        ax.imshow(images[i].reshape(image_shape), cmap='binary')</span><span id="e519" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Show true and predicted classes<br/></strong>        if cls_pred is None:<br/>            xlabel = "True: {0}".format(cls_true[i])<br/>        else:<br/>            xlabel = "True: {0}, Pred: {1}".format(cls_true[i], cls_pred[i])</span><span id="033f" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Show the classes as the label on the x-axis<br/></strong>        ax.set_xlabel(xlabel)<br/>        <br/>        # Remove ticks from the plot<br/>        ax.set_xticks([])<br/>        ax.set_yticks([])</span><span id="111b" class="kp jn hi le b fi ln lj l lk ll">    plt.show()</span></pre><h2 id="8b56" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">打印图像和标签</h2><p id="4214" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">我们从输入矩阵中选择前 9 个图像，并显示它们的真实和预测类别标签。</p><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="7f42" class="kp jn hi le b fi li lj l lk ll"><strong class="le hj">#Defining parameters<br/></strong>images = X_calamity[0:9]<br/>cls_true =y_calamity[0:9]<br/>y_pred = model.predict(x=images)<br/>cls_pred = np.argmax(y_pred, axis=1)</span><span id="8b34" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Plotting images<br/></strong>plot_images(images=images, cls_true=cls_true, cls_pred=cls_pred)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mc"><img src="../Images/2c0f084c65b7ae19e9cd98de6dcee565.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*4CA_il0akVmhr3fGh7ji1w.png"/></div></figure><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="64ea" class="kp jn hi le b fi li lj l lk ll"><strong class="le hj">#Helper Function to plot incorrect images</strong><br/>def plot_example_errors(cls_pred): </span><span id="572e" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#cls_pred is an array of the predicted class-number for all images in the test-set</strong></span><span id="337c" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj"># Boolean array whether the predicted class is incorrect.<br/></strong>    incorrect = (cls_pred != y_calamity)</span><span id="bb05" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj"># Get the images from the test-set that have been incorrectly classified<br/></strong>    images = X_calamity[incorrect]<br/>    <br/><strong class="le hj">    #Get the predicted classes for those images<br/></strong>    cls_pred = cls_pred[incorrect]</span><span id="59dc" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Get the true classes for those images<br/></strong>    cls_true = y_calamity[incorrect]<br/>    <br/><strong class="le hj">    #Plot the first 9 images<br/></strong>    plot_images(images=images[0:9], cls_true=cls_true[0:9], cls_pred=cls_pred[0:9])</span></pre><p id="df86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在绘制前 9 张错误分类的图像:</p><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="4691" class="kp jn hi le b fi li lj l lk ll"><strong class="le hj">#Defining parameters</strong><br/>y_pred = model.predict(x=X_calamity)<br/>cls_pred = np.argmax(y_pred, axis=1)</span><span id="3d1e" class="kp jn hi le b fi ln lj l lk ll"><strong class="le hj">#Plotting images</strong><br/>plot_example_errors(cls_pred)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es md"><img src="../Images/084ec97b9307e518d21156f075cb10f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*ZcuZi4wp3Jhjtkmr65o2yw.png"/></div></figure><h1 id="fec3" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">结束语</h1><p id="1a8e" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">我们设计了一个高性能的深度学习分类模型，并将其应用于我们编制的一个灾难数据集上进行损伤检测。它提供了总体 90%的准确率，并显著减少了执行时间。</p><p id="bcaa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经发现，在运行给定 Adam 优化器的参数的多个排列和组合之后，结果是最佳的。结果可能会随着参数值的变化而变化。</p><p id="1405" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过使用卫星图像可以使该模型更适用于损伤检测，并且可以在 GPU K80 高性能计算(HPC)平台上观察到显著的执行速度。</p><h1 id="6ceb" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">参考</h1><p id="08bd" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">Bhangale，u .，Durbha，s .，Potnis，a .，&amp; Shinde，R. (2019，7 月)。基于深度学习的 VHR 遥感图像震害快速检测。在 IGARSS 2019–2019 IEEE 国际地球科学与遥感研讨会(第 2654–2657 页)。IEEE。</p><p id="1b29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Gogul，I. &amp; Kumar，Sathiesh。(2017).基于卷积神经网络和迁移学习的花卉品种识别系统。1–6.</p><p id="5426" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">h .实验室(2016 年 6 月)。从 Github 检索:<a class="ae lm" href="https://github.com/Hvass-Labs/TensorFlow-Tutorials" rel="noopener ugc nofollow" target="_blank">https://github.com/Hvass-Labs/TensorFlow-Tutorials</a></p><p id="07b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Ng，A. (2017，11 月)。<em class="jd"> Deeplearning.ai </em>。从 Youtube 检索:【https://www.youtube.com/playlist? T4】list = plk da E6 sczn 6 GL 29 AOE 31 wdvwsg-KnDzF</p><p id="5245" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">v . Sharma(2018 年 10 月 15 日)。Vinod Sharma 的博客。检索自<a class="ae lm" href="https://vinodsblog.com/2018/10/15/everything-you-need-to-know-about-convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://vinodsblog . com/2018/10/15/everything-you-neural-networks/</a></p></div></div>    
</body>
</html>