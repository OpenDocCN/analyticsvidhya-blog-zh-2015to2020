<html>
<head>
<title>Text Summarization in Python using Extractive method (including end-to-end implementation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用提取方法的 Python 文本摘要(包括端到端实现)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/text-summarization-in-python-using-extractive-method-including-end-to-end-implementation-2688b3fd1c8c?source=collection_archive---------3-----------------------#2020-08-29">https://medium.com/analytics-vidhya/text-summarization-in-python-using-extractive-method-including-end-to-end-implementation-2688b3fd1c8c?source=collection_archive---------3-----------------------#2020-08-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/df944ce03f7633dce4c89e5ec73f66f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Go9S_MFGh_ZHQZ7o"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://unsplash.com/@sincerelymedia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">真诚媒体</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="53b8" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated"><strong class="ak">什么是文本摘要</strong></h2><p id="89eb" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">文本摘要是创建原始文本的简明版本同时保留关键信息的过程。人类天生是很好的总结者，因为我们有能力通过阅读理解文本的整体意思。但是机器如何做到这一点呢？这就是我们在这篇文章中要讨论的内容。</p><p id="2c20" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">自动文本摘要有许多应用，包括如下:</p><ol class=""><li id="fc35" class="kt ku hi jv b jw ko ka kp jg kv jk kw jo kx kn ky kz la lb bi translated">阅读冗长的客户评论，并将其转换成更小、更有意义的版本，用于采取必要的行动。</li><li id="9dff" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn ky kz la lb bi translated">将新闻文章转换成简短的摘要。手机应用程序<strong class="jv hj"> inshorts </strong>就是一个例子。</li><li id="f813" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn ky kz la lb bi translated">根据商务会议记录创建简明摘要报告。</li></ol><p id="98e4" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">如果这足以让你对 NLP 的惊人应用有更多的了解，那么让我们一起深入了解细节。</p><h2 id="1ad8" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated"><strong class="ak">工作原理</strong></h2><p id="e49d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">文本摘要有两种方法:</p><ol class=""><li id="d734" class="kt ku hi jv b jw ko ka kp jg kv jk kw jo kx kn ky kz la lb bi translated"><strong class="jv hj">摘录摘要:</strong>这种方法通过从原始文本中选择最重要的句子子集来概括文本。顾名思义，它从文本中提取最重要的信息。这种方法本身没有生成文本的能力，因此输出总是包含原始文本的某个部分。</li><li id="0ee2" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn ky kz la lb bi translated"><strong class="jv hj">抽象概括:</strong>这种方法背后的思想是理解原文的核心语境，并基于这种理解产生新的文本。它可以比作人类以自己的方式阅读和总结文本的方式。抽象概要的输出可以具有原始文本中不存在的元素。</li></ol><p id="882a" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">虽然抽象摘要听起来更有前途，因为它具有更深层次的理解和文本生成的能力，但是摘录摘要也有其自身的优势，例如:</p><ul class=""><li id="d80a" class="kt ku hi jv b jw ko ka kp jg kv jk kw jo kx kn lh kz la lb bi translated">比抽象更容易实现，因为不需要语言生成能力。</li><li id="b7ac" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn lh kz la lb bi translated">使用无监督的方法实现起来更快，不需要任何事先培训。</li></ul><p id="b9d6" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">我们将更详细地讨论提取总结。</p><h2 id="24ae" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated"><strong class="ak">摘录摘要</strong></h2><p id="6b35" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">这种方法背后的核心思想是找到所有句子之间的相似性，并返回具有最大相似性得分的句子。我们使用<strong class="jv hj">余弦相似度</strong>作为相似度矩阵，使用<strong class="jv hj"> TextRank </strong>算法根据句子的重要性进行排序。</p><p id="edfb" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">在了解 TextRank 算法之前，有必要简单说一下 PageRank 算法，TextRank 背后的影响。PageRank 是 Google 使用的一种基于图形的算法，用于根据搜索结果对网页进行排序。PageRank 首先创建一个图，以页面为顶点，页面之间的链接为边。对每个页面计算 PageRank 得分，基本上就是用户访问那个页面的概率。<a class="ae iu" href="https://web.stanford.edu/class/cs54n/handouts/24-GooglePageRankAlgorithm.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>是一篇很好的解释 PageRank 算法的论文。</p><h2 id="3cff" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated"><strong class="ak"> TextRank(文本摘要背后的魔力)</strong></h2><p id="2ff0" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">TextRank 与 PageRank 的相似性可以用以下几点来强调:</p><ol class=""><li id="e439" class="kt ku hi jv b jw ko ka kp jg kv jk kw jo kx kn ky kz la lb bi translated">文本单元(句子)被用来代替页面作为图形中的顶点。</li><li id="3a94" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn ky kz la lb bi translated">句子之间的相似度被用作边缘而不是链接。</li><li id="d7e6" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn ky kz la lb bi translated">代替页面访问概率，句子相似度被用来计算排名。</li></ol><p id="b73e" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">TextRank 算法从自然语言文本生成图。任何基于图的算法的基本思想都是基于“投票”或“推荐”。当一个顶点链接到另一个顶点时，它基本上是在为那个顶点投票。一个顶点的票数越高，该顶点的重要性就越高。顶点得分取决于两个因素:</p><ul class=""><li id="548f" class="kt ku hi jv b jw ko ka kp jg kv jk kw jo kx kn lh kz la lb bi translated">投票数。</li><li id="4bd0" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn lh kz la lb bi translated">为它投票的顶点的分数(重要性)。</li></ul><p id="01c0" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated"><strong class="jv hj">text rank 中要遵循的步骤</strong></p><ol class=""><li id="5d7b" class="kt ku hi jv b jw ko ka kp jg kv jk kw jo kx kn ky kz la lb bi translated">从原文中提取所有句子。</li><li id="b673" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn ky kz la lb bi translated">根据句子中存在的标记(单词)为所有句子创建向量。</li><li id="cc63" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn ky kz la lb bi translated">计算每个句子对之间的余弦相似度。创建一个 n×n 相似度矩阵，其中 n 是句子的数量。</li><li id="45c7" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn ky kz la lb bi translated">使用相似性矩阵创建一个图，其中每个顶点代表一个句子，两个顶点之间的边代表相似性。</li><li id="2f55" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn ky kz la lb bi translated">根据相似性得分对句子进行排序，并返回要包含在摘要版本中的前 N 个句子。</li></ol><blockquote class="li lj lk"><p id="62a1" class="jt ju ll jv b jw ko jy jz ka kp kc kd lm kq kf kg ln kr ki kj lo ks kl km kn hb bi translated"><strong class="jv hj">注意:</strong>余弦相似性的一个简短说明在这里会有帮助。多维空间中任意两个向量之间的余弦距离是使用它们之间角度的余弦来计算的。向量 Va 和 Vb 之间的余弦距离公式可以写成:</p><p id="48af" class="jt ju ll jv b jw ko jy jz ka kp kc kd lm kq kf kg ln kr ki kj lo ks kl km kn hb bi translated"><strong class="jv hj">余弦距离(Va，Vb) = 1-余弦(Va，Vb 之间的角度)</strong></p><p id="673e" class="jt ju ll jv b jw ko jy jz ka kp kc kd lm kq kf kg ln kr ki kj lo ks kl km kn hb bi translated">我们可以说，对于相似的向量，余弦距离将是低的，余弦相似度将是高的。</p></blockquote><p id="142d" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">今天的理论到此为止。让我们直接进入有趣的部分，那就是实现。:)</p><h2 id="9c25" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated"><strong class="ak">用 Python 实现</strong></h2><p id="dd12" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">让我们从导入所需的库开始。</p><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="40a9" class="iv iw hi lu b fi ly lz l ma mb">import nltk<br/>from nltk.corpus import stopwords<br/>from nltk.cluster.util import cosine_distance<br/>from nltk.tokenize import sent_tokenize<br/>import numpy as np<br/>import networkx as nx<br/>import re</span></pre><p id="cf86" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">第一个函数用于读取文本并将其转换成句子。我们也将做基本的文本清理，以消除所有的特殊字符。</p><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="0a32" class="iv iw hi lu b fi ly lz l ma mb">def read_article(text):        <br/>  sentences =[]        <br/>  sentences = sent_tokenize(text)    <br/>  for sentence in sentences:        <br/>    sentence.replace("[^a-zA-Z0-9]"," ")     <br/>return sentences</span></pre><p id="cbc9" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">接下来，我们将从句子中创建向量，并计算这些向量之间的余弦相似度。</p><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="73a2" class="iv iw hi lu b fi ly lz l ma mb">def sentence_similarity(sent1,sent2,stopwords=None):    <br/>  if stopwords is None:        <br/>    stopwords = []        <br/>  sent1 = [w.lower() for w in sent1]    <br/>  sent2 = [w.lower() for w in sent2]<br/>        <br/>  all_words = list(set(sent1 + sent2))   <br/>     <br/>  vector1 = [0] * len(all_words)    <br/>  vector2 = [0] * len(all_words)        <br/>  #build the vector for the first sentence    <br/>  for w in sent1:        <br/>    if not w in stopwords:<br/>      vector1[all_words.index[w]+=1                                                             <br/>  #build the vector for the second sentence    <br/>  for w in sent2:        <br/>    if not w in stopwords:            <br/>      vector2[all_words.index(w)]+=1 <br/>               <br/>return 1-cosine_distance(vector1,vector2)</span></pre><p id="dd19" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">接下来我们创建一个 n×n 维的相似性矩阵来存储相似性值。</p><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="18ac" class="iv iw hi lu b fi ly lz l ma mb">def build_similarity_matrix(sentences,stop_words):<br/>  #create an empty similarity matrix<br/>  similarity_matrix = np.zeros((len(sentences),len(sentences)))</span><span id="4870" class="iv iw hi lu b fi mc lz l ma mb">for idx1 in range(len(sentences)):<br/>    for idx2 in range(len(sentences)):<br/>      if idx1!=idx2:<br/>        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1],sentences[idx2],stop_words)</span><span id="9d84" class="iv iw hi lu b fi mc lz l ma mb">return similarity_matrix</span></pre><p id="27d2" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">最后 main 函数调用管道中的所有上述函数。</p><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="ca3c" class="iv iw hi lu b fi ly lz l ma mb">def generate_summary(text,top_n):<br/>  nltk.download('stopwords')    <br/>  nltk.download('punkt')</span><span id="67d8" class="iv iw hi lu b fi mc lz l ma mb">  stop_words = stopwords.words('english')    <br/>  summarize_text = []</span><span id="5c03" class="iv iw hi lu b fi mc lz l ma mb">  # Step1: read text and tokenize    <br/>  sentences = read_article(text)</span><span id="08c8" class="iv iw hi lu b fi mc lz l ma mb">  # Step2: generate similarity matrix            <br/>  sentence_similarity_matrix = build_similarity_matrix(sentences,stop_words)</span><span id="183c" class="iv iw hi lu b fi mc lz l ma mb">  # Step3: Rank sentences in similarity matrix<br/>   sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)<br/>   scores = nx.pagerank(sentence_similarity_graph)</span><span id="34dc" class="iv iw hi lu b fi mc lz l ma mb">  # Step4: sort the rank and place top sentences<br/>  ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)),reverse=True)<br/>  <br/>  # Step5: get the top n number of sentences based on rank<br/>  for i in range(top_n):<br/>    summarize_text.append(ranked_sentences[i][1])</span><span id="20c1" class="iv iw hi lu b fi mc lz l ma mb">  # Step6 : output the summarized version<br/>  return " ".join(summarize_text),len(sentences)</span></pre><p id="3857" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">详细解释请参考这里的完整代码<a class="ae iu" href="https://github.com/sawansaxena/Extractive-Text-Summarization" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="c57e" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated"><strong class="jv hj">让我们看看结果</strong></p><p id="6629" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">以下是我作为输入给出的原文。</p><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="0524" class="iv iw hi lu b fi ly lz l ma mb">WASHINGTON - The Trump administration has ordered the military to start withdrawing roughly 7,000 troops from Afghanistan in the coming months, two defense officials said Thursday, an abrupt shift in the 17-year-old war there and a decision that stunned Afghan officials, who said they had not been briefed on the plans.<br/>President Trump made the decision to pull the troops - about half the number the United States has in Afghanistan now - at the same time he decided to pull American forces out of Syria, one official said.<br/>The announcement came hours after Jim Mattis, the secretary of defense, said that he would resign from his position at the end of February after disagreeing with the president over his approach to policy in the Middle East.<br/>The whirlwind of troop withdrawals and the resignation of Mr. Mattis leave a murky picture for what is next in the United States’ longest war, and they come as Afghanistan has been troubled by spasms of violence afflicting the capital, Kabul, and other important areas. <br/>The United States has also been conducting talks with representatives of the Taliban, in what officials have described as discussions that could lead to formal talks to end the conflict.<br/>Senior Afghan officials and Western diplomats in Kabul woke up to the shock of the news on Friday morning, and many of them braced for chaos ahead. <br/>Several Afghan officials, often in the loop on security planning and decision-making, said they had received no indication in recent days that the Americans would pull troops out. <br/>The fear that Mr. Trump might take impulsive actions, however, often loomed in the background of discussions with the United States, they said.<br/>They saw the abrupt decision as a further sign that voices from the ground were lacking in the debate over the war and that with Mr. Mattis’s resignation, Afghanistan had lost one of the last influential voices in Washington who channeled the reality of the conflict into the White House’s deliberations.<br/>The president long campaigned on bringing troops home, but in 2017, at the request of Mr. Mattis, he begrudgingly pledged an additional 4,000 troops to the Afghan campaign to try to hasten an end to the conflict.<br/>Though Pentagon officials have said the influx of forces - coupled with a more aggressive air campaign - was helping the war effort, Afghan forces continued to take nearly unsustainable levels of casualties and lose ground to the Taliban.<br/>The renewed American effort in 2017 was the first step in ensuring Afghan forces could become more independent without a set timeline for a withdrawal. <br/>But with plans to quickly reduce the number of American troops in the country, it is unclear if the Afghans can hold their own against an increasingly aggressive Taliban.<br/>Currently, American airstrikes are at levels not seen since the height of the war, when tens of thousands of American troops were spread throughout the country. <br/>That air support, officials say, consists mostly of propping up Afghan troops while they try to hold territory from a resurgent Taliban.</span></pre><p id="0fb2" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">来源:https://www.nytimes.com<a class="ae iu" href="https://www.nytimes.com/" rel="noopener ugc nofollow" target="_blank"/></p><p id="42ca" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">下面是三行输出的总结版本。</p><pre class="lp lq lr ls fd lt lu lv lw aw lx bi"><span id="e23f" class="iv iw hi lu b fi ly lz l ma mb">The whirlwind of troop withdrawals and the resignation of Mr. Mattis leave a murky picture for what is next in the United States’ longest war, and they come as Afghanistan has been troubled by spasms of violence afflicting the capital, Kabul, and other important areas. <br/>They saw the abrupt decision as a further sign that voices from the ground were lacking in the debate over the war and that with Mr. Mattis’s resignation, Afghanistan had lost one of the last influential voices in Washington who channeled the reality of the conflict into the White House’s deliberations. <br/>Though Pentagon officials have said the influx of forces - coupled with a more aggressive air campaign - was helping the war effort, Afghan forces continued to take nearly unsustainable levels of casualties and lose ground to the Taliban.</span></pre><p id="f477" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">输出显示了具有最大相似性得分的前 3 个句子。您可以根据需要更改汇总版本中的行数。</p><p id="42a0" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">在生成文本摘要的核心 python 代码之上，我使用 Flask API 将其与 web 应用程序集成，并将其部署在云上。这使得从用户处获取输入文本并显示生成的摘要作为结果变得容易。</p><p id="2603" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated"><strong class="jv hj">重要链接</strong></p><ul class=""><li id="11d8" class="kt ku hi jv b jw ko ka kp jg kv jk kw jo kx kn lh kz la lb bi translated">这个项目的代码可以在我的 Github 库的这里找到。</li><li id="3215" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn lh kz la lb bi translated"><a class="ae iu" href="https://nlp-extractive-summary.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">这里的</a>是我部署在云上的 web 应用程序的链接。</li><li id="aa1a" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn lh kz la lb bi translated"><a class="ae iu" href="https://www.linkedin.com/in/sawan-saxena-640a4475/" rel="noopener ugc nofollow" target="_blank">这个</a>是我喜欢的丁简介。</li></ul><p id="c96c" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated"><strong class="jv hj">参考文献</strong></p><ul class=""><li id="6f00" class="kt ku hi jv b jw ko ka kp jg kv jk kw jo kx kn lh kz la lb bi translated">将秩序带入文本:<a class="ae iu" href="https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/sawan-saxena-640a4475/</a></li><li id="4774" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn lh kz la lb bi translated">了解文本摘要并使用 python 创建自己的摘要器:<a class="ae iu" href="https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70" rel="noopener" target="_blank">https://towards data science . com/understand-Text-summary-and-create-your-own-summary zer-in-python-b 26 a9 f 09 fc 70</a></li><li id="b350" class="kt ku hi jv b jw lc ka ld jg le jk lf jo lg kn lh kz la lb bi translated">使用 TextRank 算法的文本摘要介绍:<a class="ae iu" href="https://www.analyticsvidhya.com/blog/2018/11/introduction-text-summarization-textrank-python/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2018/11/Introduction-Text-summary-Text rank-python/</a></li></ul><p id="9fc0" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">在下一篇文章中，我将讨论文本摘要的抽象方法。请在评论中告诉我你的反馈。</p><p id="5180" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">感谢阅读。:)</p></div></div>    
</body>
</html>