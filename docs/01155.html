<html>
<head>
<title>Transfer Learning using Inception-v3 for Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用Inception-v3进行图像分类的迁移学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/transfer-learning-using-inception-v3-for-image-classification-86700411251b?source=collection_archive---------0-----------------------#2019-10-05">https://medium.com/analytics-vidhya/transfer-learning-using-inception-v3-for-image-classification-86700411251b?source=collection_archive---------0-----------------------#2019-10-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7184070dcae50ecb90d67b22a69d28a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wdMSQUIwn_ZGeFDpaguyXQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">皮查拜在<a class="ae iu" href="https://www.pexels.com/photo/girls-on-desk-looking-at-notebook-159823/" rel="noopener ugc nofollow" target="_blank">pexels.com</a>拍摄的照片</figcaption></figure><p id="0282" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我的<a class="ae iu" rel="noopener" href="/analytics-vidhya/end-to-end-image-classification-project-using-tensorflow-46e78298fa2f"> <strong class="ix hj">上一篇</strong> </a>中，我对原始的狗与猫<a class="ae iu" href="http://www.kaggle.com/c/dogs-vs-cats/data" rel="noopener ugc nofollow" target="_blank">数据集</a>(从25000张图像的原始数据集采样的3000张图像)的子集进行了工作，以建立一个能够以<strong class="ix hj"> 82% </strong>的准确度对狗和猫的图像进行分类的图像分类器。</p><p id="11a6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个项目是上一个项目的延续，在那个项目中我们试图提高我们的性能，并且基于tensor flow in Practice<a class="ae iu" href="https://www.coursera.org/specializations/tensorflow-in-practice?" rel="noopener ugc nofollow" target="_blank">Specialization</a>。</p><p id="c551" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们有一个相对较小的数据集时，一个超级有效的技术是使用<strong class="ix hj">迁移学习</strong>，其中我们使用一个预训练的模型。这个模型已经在一个非常大的数据集上进行了训练，我们将能够转移在多个高性能GPU上通过数百个小时的训练学习到的权重。</p><p id="882d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">许多这样的模型都是开源的，比如VGG 19和Inception-v3。他们接受了数百万张图像的训练，这些图像具有极高的计算能力，从零开始实现可能非常昂贵。</p><p id="4b9d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们在项目中使用<strong class="ix hj"> Inception-v3 </strong>模型。</p><p id="c1ed" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">迁移学习已经变得非常流行，因为它大大减少了训练时间，并且需要更少的数据来提高性能。</p><p id="529c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们开始吧。</p><p id="0503" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">获取数据</strong>(共3000张图像)</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jt"><img src="../Images/bd8aa50c4d750b0b4ffbd8f981504b4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lltT_OgCu2k1YW7s8Swtow.png"/></div></div></figure><p id="7c20" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">导入Inception-v3模型</strong></p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jy"><img src="../Images/1f8051d99dea685ccd59dbc68bb4e5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*xrcn9CUdGvC5eaEoZBGYTA.png"/></div></figure><p id="ba9f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用模型中的所有层，除了最后一个完全连接的层，因为它特定于<a class="ae iu" href="https://http//image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>竞赛。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jz"><img src="../Images/daf8b386c1cad1883f98a6f4cf18ae8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m7rtEnpG1kKCygoi027XUw.png"/></div></div></figure><p id="3443" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使所有层不可训练(我们可以重新训练一些较低的层来提高性能。请记住，这可能会导致过度拟合)</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/5dea3ae1f8fd9f7c7abdf02ae21f1c72.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*r7ZnbFeXu2sfD4Bq4G3nmA.png"/></div></figure><p id="169e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们使用二元交叉熵作为损失度量，因为我们有两个目标类(这是一个二元分类问题)</p><p id="11d1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的优化器是<strong class="ix hj"> RMSprop </strong>，学习率为<strong class="ix hj"> 0.0001 </strong>(我们可以对此进行实验；Adam和Adagrad优化器也能很好地工作)</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kb"><img src="../Images/e89eb2ef5c218cfbdef8d055f0bfa5d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aM4S3-3kce_mIvXvRk5KBg.png"/></div></div></figure><p id="134b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在重新缩放图像并使用图像增强后，我们使用train_datagen和test_datagen以20个为一批对它们进行流动。详情可以在我的<a class="ae iu" rel="noopener" href="/analytics-vidhya/end-to-end-image-classification-project-using-tensorflow-46e78298fa2f">上一篇</a>中找到。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kc"><img src="../Images/0581313d4c1691c152d215639cee16c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tDQI9rJV3oIxJExGDDB7FA.png"/></div></div></figure><p id="833f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们有<strong class="ix hj"> 2000 </strong>训练图像和<strong class="ix hj"> 1000 </strong>用于验证。</p><p id="d379" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">让我们训练</strong></p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kd"><img src="../Images/b651018fcff0d99e2b1332e9c49c7a6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*G-C9rmvpXUTOW9LeLhjReQ.png"/></div></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ke"><img src="../Images/bbd348357d65d165b9d749885ebabd5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cE3028uZfAcQ0hHS__vUAw.png"/></div></div></figure><p id="f37c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">大约35分钟后，我们能够达到94%的准确率。在我们达到一定的准确度后，回调可以很容易地实现。</p><p id="cb7e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是我们希望使用<strong class="ix hj">迁移学习</strong>得到的结果；建立在预训练模型的基础上，并将其用于我们的定制应用程序，该应用程序仅在2000张图像上进行训练后就能够实现出色的性能。</p><p id="e203" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">解决这个问题的另一种方法是不使用Inception-v3的所有层。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kf"><img src="../Images/781c9daa7611d49310ef28b566b48326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TmTWz7bEXTk1r8n2qiL_jA.png"/></div></div></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kg"><img src="../Images/c28854dc8e84daa1dedbd48b9b3aa57e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*IQHPLIT4bavCDc5U0xVh5g.png"/></div></figure><p id="1f09" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这里，我们能够使用回调达到96%的准确率。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/167cd67a476c7228e28b375c11078da6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*z4PtWSDpFL0QNbz0kLK7uw.png"/></div></figure><p id="ca33" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如你所见，<strong class="ix hj">迁移学习</strong>在计算机视觉中有很大的应用。</p><p id="feb8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">除了访问数百万张图像来为他们的定制用例构建高性能的CNN模型，不是每个人都能够负担得起数周的培训，这就是迁移学习的用武之地。您获得了使用合理数量的资源重新培训一些较低层(根据您的目标类)的能力和灵活性。<a class="ae iu" rel="noopener" href="/datadriveninvestor/image-classifier-using-create-ml-core-ml-and-vision-framework-in-swift-345557960786">这是一篇旨在通过IOS应用部署此类模型的文章。</a></p><p id="ac03" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在<a class="ae iu" href="http://www.linkedin.com/in/tejan-irla" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系。你可以在这里找到完整的代码。</p><p id="1bc3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">干杯！！</p></div></div>    
</body>
</html>