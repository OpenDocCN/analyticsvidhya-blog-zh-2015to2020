<html>
<head>
<title>SHAP Part 2: Kernel SHAP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SHAP第2部分:内核SHAP</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/shap-part-2-kernel-shap-3c11e7a971b1?source=collection_archive---------2-----------------------#2020-03-30">https://medium.com/analytics-vidhya/shap-part-2-kernel-shap-3c11e7a971b1?source=collection_archive---------2-----------------------#2020-03-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="05d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">核SHAP是一种模型不可知的方法，它使用来自LIME和Shapley值的思想来近似SHAP值。这是我第二篇关于SHAP的文章。参考我之前的文章<a class="ae jd" rel="noopener" href="/@rakesh.melezhath/shap-part-1-an-introduction-to-shap-58aa087a460c">这里</a>是对SHAP的理论介绍。</p><h2 id="5c38" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">什么是石灰？</h2><p id="f551" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">局部可解释模型不可知解释(LIME)是一种通过建立许多可解释的局部代理模型(如线性回归)来解释黑盒机器学习模型的预测的技术。代理模型基于底层黑盒模型的预测进行训练。训练本地代理模型的方法是:</p><ul class=""><li id="8301" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc kj kk kl km bi translated">选择您想要了解其黑盒模型预测的相关xᵢ实例。</li><li id="949c" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">通过扰动xᵢ.的特征值生成新数据集对于替代模型，我们不使用xᵢ的实际特征值，但是简化的二进制版本(zᵢ)被构造如下:如果x∈Rᴾ是xᵢ的原始表示，则简化的二进制版本(称为可解释表示)是1}ᴾ.的zᵢ∈{0例如，如果xᵢ = (x₁，x₂，x₃)，相应的可解释表示zᵢ由zᵢ = (z₁，z₂，z \u\u\u给出，其中z \u\u，z \u\u\u和z \u\u\u可取值0或1。</li><li id="16d9" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">注意黑盒模型对每个扰动样本zᵢ.的预测通过将zᵢ映射回原始表示Rᴾ来获得预测，如下所示:zᵢ中的‘1’被映射到实际特征值，而‘0’根据数据集的类型被映射到适当的非信息值。参考<a class="ae jd" href="https://towardsdatascience.com/understanding-how-lime-explains-predictions-d404e5d1829c" rel="noopener" target="_blank"> <em class="ks">了解石灰如何解释预测</em> </a> &amp; <a class="ae jd" href="https://cran.r-project.org/web/packages/lime/vignettes/Understanding_lime.html" rel="noopener ugc nofollow" target="_blank"> <em class="ks">了解石灰</em> </a>了解表格、文本和图像数据集的处理。SHAP KernelExplainer()函数(如下所述)将简化表示zᵢ中的“0”替换为给定背景数据集中相应要素的随机样本值。因此，局部替代模型的独立变量是一串1和0，因变量是获得的预测。然而，这种计算特征贡献的过程对特征独立性和模型线性度做出了额外的假设，至少在xᵢ.附近是局部的</li><li id="fc7b" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">根据新样本与感兴趣实例的接近程度对其进行加权(xᵢ).</li><li id="5d31" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">训练一个可解释的模型(如线性回归、套索、决策树等。)在这个新的数据集上。</li><li id="9547" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">通过解释局部模型(也称为解释模型)来解释黑盒模型的预测。</li></ul><p id="966f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LIME要求用户选择局部代理模型的复杂性和合适的核函数来为生成的数据集中的样本分配权重。下图展示了石灰背后的直觉。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es kt"><img src="../Images/88a6914b9393357a7ff750e06d11802c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*02osEZEsHs2KTQ3oLnoHbw.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">石灰背后的直觉:黑盒模型决策功能由蓝色/粉色背景表示。加粗的红叉是正在解释的例子。灰色虚线表示建立的解释模型。</figcaption></figure><h2 id="f4db" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">内核SHAP:线性石灰+沙普利值</h2><p id="b3a7" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">在SHAP的论文中，作者表明，使用加权线性回归模型作为局部代理模型和适当的加权核，石灰代理模型的回归系数估计SHAP值。恢复SHAP值的沙普利核由下式给出:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lj"><img src="../Images/0aa49fe5e382b9c6f6bdd0bc54cad945.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*YV87878GGpUJllRqMRAR7w.png"/></div></figure><p id="a2bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中M是特征的数量&amp; |z'|是简化输入z '中非零特征的数量。</p><p id="88b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将通过iris数据集上的一个例子来理解KernelExplainer的工作原理。我们将使用google Colab来运行我们的代码。代码文件上传到这里:<a class="ae jd" href="https://github.com/Rakeshsuku/Medium-Blog" rel="noopener ugc nofollow" target="_blank"> Kernel_SHAP.ipynb </a></p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lk"><img src="../Images/bc49b33938d7b937f61f884202c24d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TEgvO3ecOQGham2sMhjKpA.png"/></div></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ll"><img src="../Images/dd409a7db39d098e0bfc5a7884b7efac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pRByWhBN2Hf2BjNuM7lRwg.png"/></div></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lm"><img src="../Images/46573c66569028497b5af6a445f8eca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C2qZHEJy0AjjRfbkk7FrKA.png"/></div></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ln"><img src="../Images/fbfcb3ef30b1694dc3e750b5523e807b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MOE0bK-_tk0johkIrkLN5g.png"/></div></div></figure><p id="47ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用SHAP·克纳解释SVM模型。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lo"><img src="../Images/a01a44eaf67c5a962e4d1bff9c847101.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uAGS-G-k3Qu6nLpF5owP_Q.png"/></div></div></figure><p id="77cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">KernelExplainer()函数的参数:</p><ul class=""><li id="7fd2" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc kj kk kl km bi translated">模型:要解释的模型。模型的输出可以是大小为n_samples的向量或大小为[n_samples x n_output]的矩阵(对于分类模型)。</li><li id="0cf5" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">数据:背景数据集，用于生成训练替代模型所需的扰动数据集。我们通过用背景数据集中的值替换特征来模拟“丢失”(在zᵢ为“0”)。因此，如果背景数据集是全零的简单样本，那么我们将通过将其设置为零来近似缺失的特征。对于小问题，此背景数据集可以是整个训练集，但是对于大问题，可以考虑使用单个参考值或使用kmeans函数来汇总数据集。</li><li id="ff33" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">link:将特征贡献值连接到模型输出的函数。对于分类模型，我们通常将预测概率的logit解释为特征贡献的总和。因此，如果“模型”(第一个参数)的输出是一个概率，我们设置link = "logit "以获得logit形式的特性贡献。</li></ul><p id="d8ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们计算SHAP值如下:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lp"><img src="../Images/6e2ea6a86d3a0077232b34ec469bb7ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YSlmvupce-ZnFhPFcHBtTg.png"/></div></div></figure><p id="8e4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">explainer.shap_values()函数的参数:</p><ul class=""><li id="e185" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc kj kk kl km bi translated">x:解释模型输出的数据集。</li><li id="5bc2" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">nsamples:为建立解释每个预测的代理模型而抽取的样本数。</li><li id="a919" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">l1_reg:用于选择要素以解释模型预测的l1正则化。可能的值为:" num _ features(<int>)"-选择固定数量的特征来解释模型预测；“AIC”/“BIC”-使用AIC/BIC规则进行调整；<float>-设置sklearn.linear_model.lasso的alpha参数；“自动”-当枚举少于20%的可能样本空间时使用AIC，否则不使用正则化。</float></int></li></ul><p id="0374" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于分类问题，explainer.shap_values()返回一个大小为n_classes(类的数量)的列表。对于二元分类模型，n_classes=2(负类和正类)。该列表中的每个对象都是一个大小为[n_samples，n_features]的数组，并且对应于各个类的SHAP值。对于回归模型，我们得到大小为[n_samples，n_features]的单组shap值。这里，我们有一个3类分类问题，因此我们得到一个长度为3的列表。</p><p id="73a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">解释单个预测</strong></p><p id="4064" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们解释一下测试集中第一项的预测。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lq"><img src="../Images/92296ebdaa105e4c48ec4fbec3f7d396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OsuUOhl3AKBzR-lG02Ft0Q.png"/></div></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lp"><img src="../Images/1db14b48caba75b6e41a94cc492a402f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hF4FD7-cY4Y3-ZvTYOsrKw.png"/></div></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lr"><img src="../Images/e6d1beb31783f7f36d74c113fd5b84e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rPT56QQ-Vae_ffSId_RLpw.png"/></div></div></figure><p id="f0e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">link="logit "参数将logit值转换为概率。每个图显示了训练数据集中各个类的基本概率值。蓝色表示特征降低了概率，红色表示特征值增加了概率<em class="ks">。</em></p><p id="fe69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">解释一个以上样本的预测</strong></p><p id="918d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们为每个样本的任何一个类别绘制上述图，将它们旋转90度并并排堆叠，我们可以在单个图中解释多个样本的预测(请注意，样本是按相似性排序的):</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ls"><img src="../Images/56ef003059604bb580502565bb07e42f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hxSWFwenjHhoQ_T8bg669Q.png"/></div></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lt"><img src="../Images/043a6bb8e9bc11678da86668b30113e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FXGW_Atc7m2g7SmHXUKWrA.png"/></div></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lp"><img src="../Images/ff4007a845110a1833eea56e2148e349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qIOy13hgQSUD4dBUIm2FlA.png"/></div></div></figure><p id="a5ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> SHAP汇总图</strong> <br/> SHAP.summary_plot()可以绘制每个类的平均shap值，前提是提供一个shap值列表(分类问题的explainer.shap_values()的输出)，如下所示:</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ls"><img src="../Images/52c08722cf2ba91679994d1107dc4bba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6T1Z6I74rgZfyTXXXmWxdg.png"/></div></div></figure><p id="65d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上图表明<em class="ks">花瓣长度(cm) </em>对所有3类的预测影响最大，其次是<em class="ks">花瓣宽度(cm)。</em></p><p id="b9d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果提供了一组shap值(分类问题中单个类的shap值或回归问题的shap值)，shap.summary_plot()将为每个要素创建SHAP值的密度散点图，以确定每个要素对模型输出的影响程度。要素按所有样本的SHAP量值总和排序。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lu"><img src="../Images/86c2a717fb81ab2612679484cf16fb6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0-n0VQUlwfntjGO3lb-Krg.png"/></div></div></figure><p id="ba77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于Setosa输出，我们看到<em class="ks">花瓣长度(cm) </em>(由蓝色圆点表示)的低值增加了样本被分类为Setosa的概率(高shap值)。</p><p id="3356" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> SHAP依赖图</strong></p><p id="60ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SHAP依赖图揭示了交互作用效应。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ln"><img src="../Images/865ec8d431e301b443ce6ca897ba101d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_10e-wjeTOhoONnN-bjTLw.png"/></div></div></figure><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lp"><img src="../Images/7abb8b2067905a93ab34566bec9afe78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WnezRxzUZTrQeiO0faa7sA.png"/></div></div></figure><p id="5faf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Versicolor输出描述了<em class="ks">花瓣长度(cm) </em>和<em class="ks">花瓣宽度(cm) </em>之间的相互作用。</p><p id="9e27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">找到这里上传的代码文件:<a class="ae jd" href="https://github.com/Rakeshsuku/Medium-Blog" rel="noopener ugc nofollow" target="_blank"> Kernel_SHAP.ipynb </a>。</p><p id="30fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">链接到本系列的其他文章:</strong></p><p id="f525" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SHAP第一部:SHAP简介</p><p id="b545" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" rel="noopener" href="/@rakesh.melezhath/shap-part-3-tree-shap-3af9bcd7cd9b"> SHAP第三部:树SHAP </a></p><p id="632d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献:</strong></p><ol class=""><li id="4b74" class="ke kf hi ih b ii ij im in iq kg iu kh iy ki jc lv kk kl km bi translated"><a class="ae jd" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">可解释的机器学习——让黑盒模型变得可解释的指南。</a></li><li id="ca07" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc lv kk kl km bi translated">“我为什么要相信你？”:解释任何分类器的预测。arXiv:1602.04938</li><li id="2caa" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc lv kk kl km bi translated">SHAP:解释模式预测的统一方法。arXiv:1705.07874</li><li id="15bb" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc lv kk kl km bi translated"><a class="ae jd" href="https://towardsdatascience.com/understanding-how-lime-explains-predictions-d404e5d1829c" rel="noopener" target="_blank">https://towards data science . com/understanding-how-lime-explains-predictions-d 404 e 5d 1829 c</a></li><li id="cb71" class="ke kf hi ih b ii kn im ko iq kp iu kq iy kr jc lv kk kl km bi translated"><a class="ae jd" href="https://cran.r-project.org/web/packages/lime/vignettes/Understanding_lime.html" rel="noopener ugc nofollow" target="_blank">https://cran . r-project . org/web/packages/lime/vignettes/Understanding _ lime . html</a></li></ol></div></div>    
</body>
</html>