<html>
<head>
<title>Build your own WhatsApp Text Generator (and learn all about language models)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建你自己的WhatsApp文本生成器(并学习所有关于语言模型的知识)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/build-your-own-whatsapp-text-generator-and-learn-all-about-language-models-a1d6d96cd32e?source=collection_archive---------4-----------------------#2019-10-14">https://medium.com/analytics-vidhya/build-your-own-whatsapp-text-generator-and-learn-all-about-language-models-a1d6d96cd32e?source=collection_archive---------4-----------------------#2019-10-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="b10b" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">一个实用的端到端深度学习NLP例子</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/5ccb2e2a891f56ec33b4a5fcdbb6aa01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hfrb7wIY4jymRrpQGXs0vA.png"/></div></div></figure><p id="16fc" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">WhatsApp上的正常对话，但一切并不像看上去的那样。人民是真实的；聊天是假的。它是由一个基于真实对话历史训练的语言模型生成的。在这篇文章中，我将带你通过使用<em class="kf">循环神经网络</em>和<em class="kf">转移学习</em>的力量来构建你自己的版本。</p><h2 id="d182" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">要求</h2><p id="42d6" class="pw-post-body-paragraph jj jk hi jl b jm lb ij jo jp lc im jr js ld ju jv jw le jy jz ka lf kc kd ke hb bi translated">我使用了谷歌免费数据科学研究工具<a class="ae lg" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Colab </a>中的<a class="ae lg" href="https://docs.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fastai库</a>。这意味着很少的时间(也没有钱)来设置。要构建自己的模型，你只需要这篇文章中列出的代码(这里也是<a class="ae lg" href="https://colab.research.google.com/drive/1UcX4p1Icw0quNrhuA2B912DRTwcIDEQA" rel="noopener ugc nofollow" target="_blank">和下面的代码:</a></p><ul class=""><li id="595b" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lm ln lo lp bi translated">访问互联网的设备</li><li id="d1dc" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated">一个谷歌账户</li><li id="7aab" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated">WhatsApp聊天记录</li></ul><p id="9730" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我讨论了一些理论并深入研究了一些源代码，但是更多的细节有各种学术论文和文档的链接。如果你想了解更多，我强烈建议你去看看优秀的fastai课程。</p><h2 id="6700" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">驱动器和Colab初始设置</h2><p id="14b6" class="pw-post-body-paragraph jj jk hi jl b jm lb ij jo jp lc im jr js ld ju jv jw le jy jz ka lf kc kd ke hb bi translated">首先，我们将在<a class="ae lg" href="http://drive.google.com" rel="noopener ugc nofollow" target="_blank"> Google Drive </a>上为您的笔记本电脑创建一个空间。点击“新建”，给文件夹起个名字(我用的是“whatsapp”)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lv"><img src="../Images/c7f55e937564c159d9f3f8bb685f34b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gHqT4bjPGHrtCmkkfLdBXA.png"/></div></div></figure><p id="4b1a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">然后进入你的新文件夹，再次点击“新建”，打开一个Colab笔记本，给它一个合适的名字。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lw"><img src="../Images/19a2d9ae1d6ec224b0ace079f61065c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*JpzNpzv-_JkYvA_uLAc77Q.png"/></div></figure><p id="0b32" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">最后，我们希望为笔记本电脑启用GPU。这将大大加快训练和文本生成过程(对于矩阵乘法，即神经网络中的主要计算，GPU比CPU更有效)。</p><p id="e7c4" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">单击顶部菜单中的“运行时”，然后单击“更改运行时类型”，并为硬件加速器选择“GPU”。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/58498366f5d99fba1eaac3d15821e731.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8eZDBSp5r7acnwkYx7FnPg.png"/></div></div></figure><h2 id="51cb" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">WhatsApp数据</h2><p id="7d01" class="pw-post-body-paragraph jj jk hi jl b jm lb ij jo jp lc im jr js ld ju jv jw le jy jz ka lf kc kd ke hb bi translated">现在我们来获取一些数据。越多越好，所以你会想选择一个有相当长历史的聊天。此外，向参与谈话的其他人解释你正在做什么，并首先获得他们的许可。</p><p id="e6d7" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">要下载聊天，请单击选项(右上角的三个垂直点)，选择“更多”，然后选择“导出聊天”，“不带媒体”，如果您的移动设备上安装了驱动器，您应该可以选择保存到新创建的文件夹中(否则，保存文件并手动添加到驱动器中)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ly"><img src="../Images/cce2fa363630de73a73154b4c9f3f656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gLjtcke30xn5_lzQ798hnw.png"/></div></div></figure><h2 id="1361" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">数据准备</h2><p id="3ce3" class="pw-post-body-paragraph jj jk hi jl b jm lb ij jo jp lc im jr js ld ju jv jw le jy jz ka lf kc kd ke hb bi translated">回到笔记本。让我们从更新fastai库开始。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="4c22" class="kg kh hi ma b fi me mf l mg mh">!curl -s <a class="ae lg" href="https://course.fast.ai/setup/colab" rel="noopener ugc nofollow" target="_blank">https://course.fast.ai/setup/colab</a> | bash</span></pre><p id="a8d2" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">然后是一些标准的魔法命令，我们引入了三个库:fastai.text(用于模型)、pandas(用于数据准备)和re(用于正则表达式)。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="4c9a" class="kg kh hi ma b fi me mf l mg mh">## magic commands<br/>%reload_ext autoreload<br/>%autoreload 2<br/>%matplotlib inline</span><span id="05a9" class="kg kh hi ma b fi mi mf l mg mh">## import required packages<br/>from fastai.text import *<br/>import pandas as pd<br/>import re</span></pre><p id="44cc" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们希望将这个笔记本链接到Google Drive，以便使用我们刚刚从WhatsApp导出的数据，并保存我们创建的任何模型。为此，运行以下代码，转到提供的链接，选择您的google帐户，并将授权代码复制回您的笔记本。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="e426" class="kg kh hi ma b fi me mf l mg mh">## Colab google drive stuff<br/>from google.colab import drive<br/>drive.mount('/content/gdrive', force_remount=True)<br/>root_dir = "/content/gdrive/My Drive/"<br/>base_dir = root_dir + 'whatsapp/'</span></pre><p id="31c7" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们有一些清理工作要做，但数据目前还在。txt格式。不理想。这里有一个函数，它将文本文件转换成pandas数据帧，每个聊天条目占一行，并带有时间戳和发送者的姓名。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="d404" class="kg kh hi ma b fi me mf l mg mh">## function to parse the whatsapp extract file<br/>def parse_file(text_file):<br/>    '''Convert WhatsApp chat log text file to a Pandas dataframe.'''<br/>    <br/>    # some regex to account for messages taking up multiple lines<br/>    pat = re.compile(r'^(\d\d\/\d\d\/\d\d\d\d.*?)(?=^^\d\d\/\d\d\/\d\d\d\d|\Z)',<br/>                     re.S | re.M)<br/>    with open(text_file) as f:<br/>        data = [m.group(1).strip().replace('\n', ' ') <br/>                for m in pat.finditer(f.read())]</span><span id="c572" class="kg kh hi ma b fi mi mf l mg mh">    sender = []; message = []; datetime = []<br/>    for row in data:<br/>        <br/>        # timestamp is before the first dash<br/>        datetime.append(row.split(' - ')[0])</span><span id="a278" class="kg kh hi ma b fi mi mf l mg mh">        # sender is between am/pm, dash and colon<br/>        try:<br/>            s = re.search(' - (.*?):', row).group(1)<br/>            sender.append(s)<br/>        except:<br/>            sender.append('')<br/>            <br/>        # message content is after the first colon<br/>        try:<br/>            message.append(row.split(': ', 1)[1])<br/>        except:<br/>            message.append('')<br/>    <br/>    df = pd.DataFrame(zip(datetime, sender, message), <br/>                      columns=['timestamp',<br/>                               'sender',<br/>                               'text'])    <br/>    <br/>    # exclude any rows where format does not match <br/>    # proper timestamp format<br/>    df = df[df['timestamp'].str.len() == 17]<br/>    df['timestamp'] = pd.to_datetime(df.timestamp, <br/>                                     format='%d/%m/%Y, %H:%M')</span><span id="04a0" class="kg kh hi ma b fi mi mf l mg mh">    # remove events not associated with a sender<br/>    df = df[df.sender != ''].reset_index(drop=True)<br/>    <br/>    return df</span></pre><p id="c6a8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们看看它是如何工作的。创建数据的路径，将该函数应用于聊天导出，并查看生成的数据帧。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="d378" class="kg kh hi ma b fi me mf l mg mh">## path to directory with your file<br/>path = Path(base_dir)</span><span id="d918" class="kg kh hi ma b fi mi mf l mg mh">## parse whatsapp extract, replace chat.txt with your <br/>## extract filename<br/>df = parse_file(path/'chat.txt')</span><span id="a001" class="kg kh hi ma b fi mi mf l mg mh">## take a look at the result<br/>df[205:210]</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mj"><img src="../Images/422321a4cd3acf330afac2436e020a92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ehaebVJ-amIbpL_dg3_O1A.png"/></div></div></figure><p id="eb8c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">完美！这是我和我可爱的妻子之间的一小段对话。这种格式的一个优点是，我可以很容易地用小写字母创建一个参与者姓名列表，用下划线代替任何空格。这个以后会有帮助的。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="0e6c" class="kg kh hi ma b fi me mf l mg mh">## list of conversation participants<br/>participants = list(df['sender'].str.lower().<br/>                    str.replace(' ', '_').unique())<br/>participants</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mk"><img src="../Images/23253e26d1c774276eaf305cfa0cefa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FWvcfQ0DNYIvmSJGrRjNPw.png"/></div></div></figure><p id="6c22" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这种情况下，只有两个名字，但它将与任何数量的参与者。</p><p id="b950" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">最后，我们需要考虑如何将文本输入到我们的模型网络中。通常，我们会有多个独立的文本片段(例如维基百科文章或IMDB评论)，但我们这里只有一个正在进行的文本流。一次连续的谈话。这就是我们创造的。一个长字符串，包括发件人姓名。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="dff9" class="kg kh hi ma b fi me mf l mg mh">## concatenate names and text into one string<br/>text = [(df['sender'].str.replace(' ', '_') + ' ' + df['text']).str.cat(sep = ' ')]</span><span id="319d" class="kg kh hi ma b fi mi mf l mg mh">## show part of string<br/>text[0][8070:8150]</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/33c6195e14422b18a76a1a58e8a2ba2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k4nAiPT_4BG4A5GNeNYlow.png"/></div></div></figure><p id="d72d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">看起来不错。我们已经准备好让学生学习这个了。</p><h2 id="b32d" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">学习者创造</h2><p id="4ba3" class="pw-post-body-paragraph jj jk hi jl b jm lb ij jo jp lc im jr js ld ju jv jw le jy jz ka lf kc kd ke hb bi translated">为了使用fastai API，我们现在需要创建一个<a class="ae lg" href="https://docs.fast.ai/data_block.html#The-data-block-API" rel="noopener ugc nofollow" target="_blank"> DataBunch </a>。这是一个可以在学习者内部用来训练模型的对象。在这种情况下，它有三个关键输入:数据(分为训练集和验证集)、数据标签和批量。</p><p id="e1ff" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><em class="kf">数据</em></p><p id="78c5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为了将培训和验证分开，让我们在我们的长对话字符串中间选择一个点。我把前90%用于培训，后10%用于验证。然后我们可以创建几个<a class="ae lg" href="https://docs.fast.ai/text.data.html#TextList" rel="noopener ugc nofollow" target="_blank">文本列表</a>对象，并快速检查它们看起来和以前一样。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="9cc1" class="kg kh hi ma b fi me mf l mg mh">## find the index for 90% through the long string<br/>split = int(len(text[0])*0.9)</span><span id="2a86" class="kg kh hi ma b fi mi mf l mg mh">## create TextLists for train/valid<br/>train = TextList([text[0][:split]])<br/>valid = TextList([text[0][split:]])</span><span id="e184" class="kg kh hi ma b fi mi mf l mg mh">## quick look at the text<br/>train[0][8070:8150]</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/33c6195e14422b18a76a1a58e8a2ba2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k4nAiPT_4BG4A5GNeNYlow.png"/></div></div></figure><p id="3ebf" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这个文本列表值得更深入一点。</p><p id="8cdf" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">它或多或少是一个文本列表(在本例中只有一个元素)，但是让我们快速查看一下源代码，看看还有什么。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/a9ffa1a065177b48966f597908f60c18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xb7UkdrJtaSxcLA0iYDtMQ.png"/></div></div></figure><p id="7d37" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">好了，TextList是一个有一堆方法的类(函数，上面任何以“def”开头的，都最小化)。它继承自一个<a class="ae lg" href="https://docs.fast.ai/data_block.html#ItemList" rel="noopener ugc nofollow" target="_blank">项目列表</a>，换句话说，它是一种项目列表。尽一切办法去查找一个项目列表，但我最感兴趣的是“_处理器”变量。处理器是一个带有TokenizeProcessor和NumericalizeProcessor的列表。这些在NLP环境中听起来很熟悉:</p><p id="add0" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><em class="kf">标记化</em> —处理文本并将其分解成单个单词</p><p id="336f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><em class="kf">数字化</em> —用与单词在词汇库中的位置相对应的数字来替换这些标记</p><p id="37d3" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为什么我要强调这一点？当然，理解用于处理文本的规则是有帮助的，深入研究这部分源代码和文档将有助于你做到这一点。但是，具体来说，我想添加我自己的新规则。我觉得我们应该表明文本中的发送者姓名在某些方面是相似的。理想情况下，我希望在每个发送者姓名前有一个标记，告诉模型“这是一个发送者姓名”。</p><p id="6031" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们如何做到这一点？这就是_processor派上用场的地方。文档告诉我们，我们可以用它来传入一个定制的记号赋予器。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/ecab18f3f0b8807f6aa7659ccfafeaa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eCAGsfSWAreAdTXdRm5wzg.png"/></div></div></figure><p id="ca54" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">因此，我们可以创建自己的规则，并用定制的处理器将它传入。我仍然希望保留以前的默认值，所以我需要做的就是将新函数添加到现有的默认规则列表中，并将这个新列表添加到我们的自定义处理器中。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="9800" class="kg kh hi ma b fi me mf l mg mh">## new rule<br/>def add_spk(x:Collection[str]) -&gt; Collection[str]:<br/>  res = []<br/>  for t in x:<br/>        if t in participants: res.append('xxspk'); res.append(t)<br/>        else: res.append(t)<br/>  return res</span><span id="e203" class="kg kh hi ma b fi mi mf l mg mh">## add new rule to defaults and pass in customer processor<br/>custom_post_rules = defaults.text_post_rules + [add_spk]<br/>tokenizer = Tokenizer(post_rules = custom_post_rules)</span><span id="917c" class="kg kh hi ma b fi mi mf l mg mh">processor = [TokenizeProcessor(tokenizer=tokenizer), <br/>             NumericalizeProcessor(max_vocab=30000)]</span></pre><p id="ef17" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">该函数在每个名称前添加标记“xxspk”。</p><p id="c113" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">加工前:</strong>“……鸡蛋，牛奶保罗_所罗门好……”</p><p id="3417" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">加工后:</strong>“…鸡蛋，牛奶xxspk保罗_所罗门xxmaj ok…”</p><p id="346d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">请注意，我已经应用了其他一些默认规则，即识别大写单词(在大写单词前添加“xxmaj”)和分隔标点符号。</p><p id="29ee" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><em class="kf">标签</em></p><p id="25fa" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们将创建一个叫做<em class="kf">语言模型</em>的东西。这是什么？很简单，这是一个预测单词序列中的下一个单词的模型。为了准确地做到这一点，模型需要理解语言规则和上下文。在某些方面，它需要<em class="kf">学习语言。</em></p><p id="7809" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">那么标签是什么呢？简单，是下一个词。更具体地说，在我们使用的模型架构中，对于一个单词序列，我们可以通过获取相同的标记序列并将其向右移动一个单词来创建一个目标序列。在输入序列中的任何一点，我们都可以查看目标序列中的同一点，并找到要预测的正确单词(即标签)。</p><p id="19eb" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">输入顺序:</strong>“…鸡蛋，牛奶spkxx paul_solomon xxmaj …”</p><p id="90aa" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">标签/下一个单词:</strong>“ok”</p><p id="bfad" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">目标序列:</strong>“…，牛奶spkxx保罗_所罗门xxmaj ok …”</p><p id="9d70" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们通过使用label_for_lm方法(上面的TextList类中的函数之一)来实现这一点。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="1b1a" class="kg kh hi ma b fi me mf l mg mh">## take train and valid and label for language model<br/>src = ItemLists(path=path, train=train, valid=valid).label_for_lm()</span></pre><p id="d1e9" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><em class="kf">批量</em></p><p id="418c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">神经网络是通过并行传递成批数据来训练的，因此databunch的最终输入是我们的batchsize。我们使用48，这意味着一次有48个文本序列通过网络。默认情况下，这些文本序列的长度都是70个标记。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="005b" class="kg kh hi ma b fi me mf l mg mh">## create databunch with batch size of 48<br/>bs = 48<br/>data = src.databunch(bs=bs)</span></pre><p id="6896" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们现在有数据了！让我们创建学习者。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="f93e" class="kg kh hi ma b fi me mf l mg mh">## create learner<br/>learn = language_model_learner(data, AWD_LSTM, drop_mult=0.3)</span></pre><p id="987c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">Fastai给了我们一个快速创建<a class="ae lg" href="https://docs.fast.ai/text.learner.html#language_model_learner" rel="noopener ugc nofollow" target="_blank">语言模型学习者</a>的选项。我们需要的只是我们的数据(我们已经有了)和一个现有的模型。默认情况下，此对象的参数“pretrained”设置为“True”。这意味着我们将采用一个<em class="kf">预先训练的</em>语言模型，然后<em class="kf">根据我们的数据对其进行微调</em>。</p><p id="fcc5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这叫<em class="kf">迁移学习</em>，我很喜欢。语言模型需要大量的数据才能很好地工作，但在这种情况下我们没有足够的数据。为了解决这个问题，我们可以采用现有的模型，根据大量数据进行训练，并根据我们的文本对其进行微调。</p><p id="1d7e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这种情况下，我们使用一个<a class="ae lg" href="https://arxiv.org/abs/1708.02182" rel="noopener ugc nofollow" target="_blank"> AWD_LSTM </a>模型，它已经在<a class="ae lg" href="https://arxiv.org/abs/1609.07843" rel="noopener ugc nofollow" target="_blank"> WikiText-103 </a>数据集上进行了预训练。AWD·LSTM是一种语言模型，它使用一种叫做递归神经网络的结构。它是在文本上训练的，在这种情况下，它是在维基百科的全部数据上训练的。我们可以查一下。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/c57f41b13ba4818aaffb616bcf0217aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L2oZ7TkQlyT7UaMbbUZkjw.png"/></div></div></figure><p id="7939" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">该模型已经在超过<em class="kf">100亿</em>个来自<em class="kf"> 28k </em>维基百科文章的令牌上进行了训练，具有最先进的性能。听起来像是我们的一个很好的起点！</p><p id="588f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们快速了解一下模型架构。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="523e" class="kg kh hi ma b fi me mf l mg mh">learn.model</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mo"><img src="../Images/291784d997f4ec71035d35297b2517cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*ntSn-DnLwWbtJPi_T_Zkyg.png"/></div></figure><p id="bf3a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我来分解一下。</p><ol class=""><li id="827c" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke mp ln lo lp bi translated"><strong class="jl hj">编码器</strong> —我们文本的词汇库将包含任何使用两次以上的单词。在这种情况下，有2，864个单词(您的会有所不同)。这些单词中的每一个都使用长度为2，864的向量来表示，在适当的位置使用1，在其他位置使用全0。编码采用该向量，并将其乘以权重矩阵，以将其压缩成长度为400的<em class="kf">字嵌入</em>。</li><li id="2e33" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke mp ln lo lp bi translated"><strong class="jl hj"> LSTM细胞</strong>——长度为400字的嵌入物然后被送入LSTM细胞。我不会深入到单元格的细节，你只需要知道一个长度为400的向量进入第一个单元格，然后一个长度为1152的向量出来。另外两件值得注意的事情:这个细胞有一个<em class="kf">记忆</em>(它正在记住前面的单词)并且细胞的输出被反馈回自身并与下一个单词结合(这是循环部分)，以及被推入下一层。一排有三个这样的单元。</li><li id="27d5" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke mp ln lo lp bi translated"><strong class="jl hj">解码器</strong> —第三个LSTM单元的输出是一个长度为400的向量，它被再次扩展成一个与你的vocab长度相同的向量(在我的例子中是2，864)。这给了我们对下一个单词的预测，并可以与实际的下一个单词进行比较，以计算我们的损失和准确性。</li></ol><p id="178a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">请记住，这是一个<em class="kf">预训练的</em>模型，因此只要有可能，权重就与使用WikiText数据训练的完全一样。这将是LSTM单元的情况，以及两个词汇库中的任何单词的情况。任何新单词都是通过所有嵌入的平均值来初始化的。</p><p id="315b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在让我们用我们自己的数据对它进行微调，使它生成的文本听起来像我们的WhatsApp聊天，而不是维基百科的文章。</p><h2 id="089d" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">培养</h2><p id="4e4f" class="pw-post-body-paragraph jj jk hi jl b jm lb ij jo jp lc im jr js ld ju jv jw le jy jz ka lf kc kd ke hb bi translated">首先，我们要做一些<em class="kf">冷冻</em>训练。这意味着我们只更新模型的某些部分。具体来说，我们只训练<em class="kf">最后一层组</em>。上面我们可以看到最后一层组是“(1): LinearDecoder”，解码器。在训练过程中，所有的单词嵌入和LSTM单元将保持不变，只是在最后的解码阶段会被更新。</p><p id="1ad0" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">最重要的超参数之一是学习率。Fastai给了我们一个有用的小工具，可以快速找到一个好的值。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="feb5" class="kg kh hi ma b fi me mf l mg mh">## run lr finder<br/>learn.lr_find()</span><span id="5291" class="kg kh hi ma b fi mi mf l mg mh">## plot lr finder<br/>learn.recorder.plot(skip_end=15)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mq"><img src="../Images/8e52f1b754aac7b28e7be92c822f91c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*XZ7VY98pcCknAcZWZhqg9g.png"/></div></figure><p id="870a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">经验法则是找到曲线最陡的部分(即最快学习的点)。1.3e-2看起来就在这里。</p><p id="4810" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们继续进行一个时期的训练(一次通过所有的训练数据)。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="60f3" class="kg kh hi ma b fi me mf l mg mh">## train for one epoch frozen<br/>learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mr"><img src="../Images/ad5f273151fbad0674c63ce95a5aa352.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*BeEwKnDYnmJCAj04vgllhg.png"/></div></figure><p id="9746" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在纪元结束时，我们可以看到训练集和验证集的损失，以及验证集的准确性。我们正确预测了验证集中41%的下一个单词。还不错。</p><p id="f6a0" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">冻结训练是从迁移学习开始的一个很好的方式，但是现在我们可以通过<em class="kf">解冻</em>来打开整个模型。这意味着编码器和LSTM细胞现在将包括在我们的培训更新。也意味着模型会更灵敏，所以我们把学习速率降低到1e-3。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="d82a" class="kg kh hi ma b fi me mf l mg mh">## train for four further cycles unfrozen<br/>learn.fit_one_cycle(4, 1e-3, moms=(0.8,0.7))</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ms"><img src="../Images/62b276d58d84cc4a39d7b881fa49e08b.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*69MhEMMXFMlhQ21gRD1n4Q.png"/></div></figure><p id="8f25" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">准确率高达44.4%。注意，现在训练损失低于验证，这是我们希望看到的，验证损失已经见底。</p><p id="7bbe" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">请注意，您几乎肯定会发现您的损失和准确性与上述不同(有些对话比其他对话更容易预测)，因此我建议您调整参数(学习率、培训协议等。)尝试从您的模型中获得最佳性能。</p><h2 id="c522" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">文本生成</h2><p id="20e0" class="pw-post-body-paragraph jj jk hi jl b jm lb ij jo jp lc im jr js ld ju jv jw le jy jz ka lf kc kd ke hb bi translated">我们现在有了一个语言模型，针对你的WhatsApp对话进行了微调。要生成文本，我们需要做的就是让它运行，只要你要求，它就会开始一遍又一遍地预测下一个单词。</p><p id="4bb1" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">Fastai为我们提供了一个有用的predict方法来实现这一点，我们需要做的就是给它一些文本来启动它，并告诉它要运行多长时间。输出仍然是标记化的格式，所以我写了一个函数来清理文本并在笔记本中很好地打印出来。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="35be" class="kg kh hi ma b fi me mf l mg mh">## function to generate text<br/>def generate_chat(start_text, n_words):<br/>  text = learn.predict(start_text, n_words, temperature=0.75)<br/>  text = text.replace(" xxspk ", <br/>                      "\n").replace(" \'", <br/>                                    "\'").replace(" n\'t", <br/>                                                  "n\'t")<br/>  text = re.sub(r'\s([?.!"](?:\s|$))', r'\1', text)<br/>  <br/>  for participant in participants:<br/>    text = text.replace(participant, participant + ":")<br/>  <br/>  print(text)</span></pre><p id="9607" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们开始吧。</p><pre class="iy iz ja jb fd lz ma mb mc aw md bi"><span id="d674" class="kg kh hi ma b fi me mf l mg mh">## generate some text of length 200 words<br/>generate_chat(participants[0] + " are you ok ?", 200)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mt"><img src="../Images/3d0d0812dabc12958b53c981707742b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*j6mC3t3bt5uMGeqneKKPzw.png"/></div></figure><p id="d9fd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">不错！它读起来肯定很像我的一段对话(主要集中在每天下班回家的路上)，上下文是持续的(这是LSTM记忆在起作用)，文本甚至看起来是为每个参与者量身定制的。</p><h2 id="4d57" class="kg kh hi bd ki kj kk kl km kn ko kp kq js kr ks kt jw ku kv kw ka kx ky kz la bi translated">最后的想法</h2><p id="16fd" class="pw-post-body-paragraph jj jk hi jl b jm lb ij jo jp lc im jr js ld ju jv jw le jy jz ka lf kc kd ke hb bi translated">我将以一句警告结束我的发言。与许多其他人工智能应用一样，虚假文本生成可以大规模用于不道德的目的(例如在互联网上传播旨在伤害的消息)。我在这里使用它来提供一种有趣的和动手的方式来学习语言模型，但是我鼓励您考虑如何将上述方法用于其他目的(例如，作为文本分类系统的输入)或其他类型的类似序列的数据(例如，音乐创作)。</p><p id="5c37" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这是一个令人兴奋的快速发展的领域，有潜力构建创造价值和造福社会的强大工具。我希望这篇文章告诉你<em class="kf">任何人</em>都可以参与其中。</p></div></div>    
</body>
</html>