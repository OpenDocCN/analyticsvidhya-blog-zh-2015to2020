<html>
<head>
<title>How to train Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何训练神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-train-neural-networks-3ec2208ae953?source=collection_archive---------16-----------------------#2020-10-05">https://medium.com/analytics-vidhya/how-to-train-neural-networks-3ec2208ae953?source=collection_archive---------16-----------------------#2020-10-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="382d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我将讲述任何深度学习模型都要遵循的通用蓝图。在这里，我不会深入到深度学习的概念，但这是开发神经网络的基本步骤。根据要求，可以在下面的列表中添加或删除一些步骤。</p><p id="1586" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1。数据预处理</strong></p><p id="bbc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们获得的用于建模的数据大部分时间都是非结构化的和原始的，其中我们有很多我们的案例不需要的数据。所以我们需要保留必要的数据，而忽略其他的</p><p id="a6f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。重量初始化</strong></p><p id="4b75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">神经网络建模的第一步是权重初始化，这是一个非常重要的步骤，因为如果权重初始化不正确，就不可能收敛到最小值，但如果方法正确，就可以在最短的时间内实现优化。有几种技术，如零初始化，随机初始化，HE 初始化，glorant 初始化，Xavier 等。</p><p id="5fc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。选择正确的激活功能</strong></p><p id="4dee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">激活函数被认为是一个门，可以简单地开或关，也可以转换神经元的输入并给出输出。根据使用情况，您可以选择几种类型的激活功能。一些激活函数大致分为线性和非线性。线性激活函数的问题是不能应用反向传播。如果一个线性变换有多层，它仍然相当于一层，因为线性的函数仍然是线性函数。我们有非线性激活，如 Sigmoid，tanh，ReLu，它解决了线性激活函数的问题。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/667a92848f782378c09834016dd7b679.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*7uUCVwLEynpFQ9ltvEUmHw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">图片提供:<a class="ae jp" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwp.wwu.edu%2Fmachinelearning%2F2017%2F02%2F12%2Fdeep-neural-networks%2F&amp;psig=AOvVaw1KUT6UrNsKH9O6rN6THk75&amp;ust=1601991340554000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCJDJp__InewCFQAAAAAdAAAAABAD" rel="noopener ugc nofollow" target="_blank">https://www.google.com/url?sa=i&amp;URL = https % 3A % 2F % 2fwp . wwu . edu % 2f machine learning % 2f 2017% 2f 02% 2f 12% 2f 深度神经网络% 2F&amp;psig = aovvaw 1 Kut 6 urns KH 9 o 6 rn 6 thk 75&amp;ust = 1601991340554000&amp;source = images&amp;CD = vfe&amp;ved = ved</a></figcaption></figure><p id="17d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。批量标准化</strong></p><p id="fa3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">归一化是将所有要素放在一个单一的范围内，例如，可能有值为 1-100 的要素，也可能有值为 0-1 的要素。我们需要将数据标准化为 0–1，这样学习速度会更快。如果输入层可以从归一化中受益，为什么隐藏层不能受益，所以我们也对隐藏层添加批量归一化，特别是对于更接近深度神经网络中的输出层的后面的层，以便收敛变得更容易。标准化使非活化变得更高。</p><p id="a734" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 5。如有需要，添加脱落层</strong></p><p id="1cb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基本上，添加漏失层是为了避免过度拟合，如果您怀疑模型过度拟合，可以使用该层。丢弃只是在特定层中随机丢弃一些神经元。虽然如果我们加上了丢失，它需要更长的时间来收敛，但是每个时期将需要更短的时间。</p><p id="a094" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 6。选择一个好的优化器</strong></p><p id="1502" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">优化器是改变神经网络属性的方法。例如权重和学习率，以便减少损失。有很多优化器可以选择。例如梯度下降、随机梯度下降、小批量梯度下降、动量、Adagrad、AdaDelta、Adam。Adam 优化器是最近出现的，是迄今为止最好的优化器，它花费的时间更少，对训练任何神经网络都更有效。</p><p id="f2a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 7。超参数调谐</strong></p><p id="791e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">超参数是<em class="jq"> </em>所有的训练变量在开始训练前都用预先设定的值手动设定。</p><p id="7b1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一些常见的超参数如下:</p><ul class=""><li id="f538" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated">学习率</li><li id="dd28" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">动力</li><li id="b660" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">亚当超参数</li><li id="ce82" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">隐藏层数</li><li id="1e17" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">不同层的隐藏单元数量</li><li id="7aa5" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">学习率衰减</li><li id="d866" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">小批量</li></ul><p id="418b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在所有的超参数中，学习率/sep 大小是最重要的超参数，它告诉我们在梯度中移动多远。如果学习率小，我们会有更多的可靠性，但是收敛需要很多时间。有几种方法来找到学习率，其中一些是，试错法，网格搜索，随机搜索，贝叶斯优化。</p><p id="adce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 8。损失函数</strong></p><p id="5f13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终，ML 或深度学习模型中重要的是减少损失函数。所以在分类任务中，我们需要减少，在回归任务中，我们需要将损失最小化。在分类任务的情况下，我们通常减少日志损失，在多类分类中是多类日志损失。在回归任务的情况下，这将是一个均方损失。</p><p id="fcd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 9。监控梯度</strong></p><p id="c40a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于梯度有两种问题，一种是爆炸梯度和消失梯度下降。该模型是不稳定的，导致每次更新的损失变化很大。我们可以说它受到了爆炸梯度的影响。消失梯度问题是，在某些情况下，梯度会变得非常小，从而有效地防止权重改变其值。在最坏的情况下，这可能会完全停止神经网络的进一步训练。我们需要通过使用像梯度裁剪这样的技术来监控梯度。</p><p id="cd0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10 可视化</strong></p><p id="648b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">曲线图很好地展示了模型的性能。很容易理解从模型中流出的数据，并对需要对影响模型的参数或超参数进行的更改做出明智的决策。</p><p id="0136" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文不应被视为构建深度学习模型的指南，而是本文只是如何构建深度学习模型的一种方式。</p><p id="f3f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快乐学习</p></div></div>    
</body>
</html>