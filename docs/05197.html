<html>
<head>
<title>Dog-Breed Classifier using Convolution Neural Networks(CNN’s)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用卷积神经网络(CNN)的狗品种分类器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/dog-breed-classifier-using-convolution-neural-networks-cnns-507d126a9185?source=collection_archive---------36-----------------------#2020-04-13">https://medium.com/analytics-vidhya/dog-breed-classifier-using-convolution-neural-networks-cnns-507d126a9185?source=collection_archive---------36-----------------------#2020-04-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ih ii ij ik er es paragraph-image"><div class="er es ig"><img src="../Images/5a9d25c1a162aa1995774784d5716e50.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*p9GDQcWycm4rrA9je7NI1Q.png"/></div></figure><p id="ca36" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">概述:</strong></p><p id="3299" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">对现实世界中物体的分类通常是为了使它们作为一个组的一部分更有意义。我们在日常生活中做的一个非常常见的分类是，当我们看着一个人时，立即将他们归类为男性或女性。在这个应用程序中，有一个<a class="ae jl" href="https://brilliant.org/wiki/classification/" rel="noopener ugc nofollow" target="_blank">分类问题</a>被解决，但是在另一个不同的问题<strong class="ip hj">上，根据一张图片将一只狗分类到它可能的品种。</strong></p><p id="5a17" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">在本文中，我们将按照我所遵循的步骤来实现解决方案和结果。我们还将研究模型预测的准确性以及进一步改进它们的方法。</p><p id="6c20" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">问题陈述:</strong></p><p id="dfc8" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">在这一节中，我们将研究实际的问题陈述。</p><p id="dec7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">犬种分类器问题是分类问题中的一个常见问题。这里的目标是从作为机器学习模型的输入而提供的图像中获得狗的正确品种。为了让应用程序更具挑战性，如果人类图像通过，模型必须<strong class="ip hj">返回相似的品种</strong>。例如，看看顶部的图像。该模型还必须拒绝没有狗的图像。</p><p id="820b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">数据探索:</strong></p><p id="74d7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">这个项目的数据由<strong class="ip hj"> Udacity </strong>提供，作为他们<a class="ae jl" href="https://www.udacity.com/course/ud025-preview" rel="noopener ugc nofollow" target="_blank">数据科学家纳米学位项目</a>的一部分。请使用以下链接获取数据。请注意，两个链接中的数据总计约2 GB！</p><ul class=""><li id="0688" class="jm jn hi ip b iq ir iu iv iy jo jc jp jg jq jk jr js jt ju bi translated"><a class="ae jl" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip" rel="noopener ugc nofollow" target="_blank">狗图像数据集</a>:用于训练模型。内容和结构解释如下。</li><li id="0fce" class="jm jn hi ip b iq jv iu jw iy jx jc jy jg jz jk jr js jt ju bi translated"><a class="ae jl" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip" rel="noopener ugc nofollow" target="_blank">人脸数据集</a>:用于检测/预测。</li></ul><p id="44a0" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">狗图像数据集总共有<strong class="ip hj"> 8351张图像</strong>。这分为<strong class="ip hj">训练</strong> ( <strong class="ip hj"> 6680张图像</strong>)、<strong class="ip hj">测试(836张图像)、验证(835张图像)目录。</strong>这些目录中的每一个都有<strong class="ip hj"> 133个子目录</strong>对应133种不同品种的狗。不同的品种有不同数量的图像。有些品种有多达8种不同的图像，而有些只有4种。所以数据是不平衡的。下面是示例图像</p><figure class="kb kc kd ke fd ik er es paragraph-image"><div class="er es ka"><img src="../Images/e3155fbe0b7736e3e2942bd32b4341db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*F_JDlollHhR-fKcXp9RwmA.png"/></div></figure><p id="c468" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">人体图像数据集</strong>在5750个文件夹下总共有<strong class="ip hj">13233张图像。所有图像的尺寸都是(<strong class="ip hj"> 250 X 250 </strong>)。在狗的数据集中，数据是不平衡的，有些人只有一个图像，而有些人有多个图像。样本人类图像，</strong></p><figure class="kb kc kd ke fd ik er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es kf"><img src="../Images/a47206b2c7fe6b8c69788340cdc1fa65.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*PKBYMc0-KuiToMylnyTEEg.png"/></div></div></figure><p id="a33b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">作为图像预处理数据的一部分，所有图像的尺寸都调整为<strong class="ip hj"> 240 X 240。</strong>然后将<a class="ae jl" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022860" rel="noopener ugc nofollow" target="_blank"> <strong class="ip hj">归一化</strong> </a>应用于所有数据集(训练、测试、验证)。</p><p id="7e27" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">现在数据的最重要部分——图像的预处理，<a class="ae jl" href="https://towardsdatascience.com/image-augmentation-using-python-numpy-opencv-and-skimage-ef027e9898da?gi=a750faef656" rel="noopener" target="_blank"> <strong class="ip hj">图像增强</strong> </a> <strong class="ip hj"> </strong>是对训练数据进行的。随机旋转图像，并应用水平翻转。需要图像增强来<strong class="ip hj">防止模型的过度拟合</strong>。最后，图像被转换成张量并输入到模型中。</p><p id="176c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">指标:</strong></p><p id="20d3" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">整个数据被分成训练、测试和验证数据集。通过测试数据集的标准精度测试来评估该模型。</p><pre class="kb kc kd ke fd kk kl km kn aw ko bi"><span id="7375" class="kp kq hi kl b fi kr ks l kt ku">accuracy = correct_predictions/total_number_of_inputs</span></pre><p id="6a46" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">对于狗品种分类器来说，准确度是足够的度量，因为所有品种都具有几乎相似数量的图像。</p><p id="4e4d" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">从零开始创建的模型必须具有至少10%的精度。当模型的训练完成并且绘制了损失时，获得了下面的图。</p><figure class="kb kc kd ke fd ik er es paragraph-image"><div class="er es kv"><img src="../Images/e37c7785ad40fa6ec70581b9fd86d9cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*VCcYwyKt-gVOonG7G1c1yA.png"/></div></figure><p id="3b06" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">使用迁移学习创建的模型预期具有至少60%的准确度。获得的准确率为72%,训练和测试损失较低</p><figure class="kb kc kd ke fd ik er es paragraph-image"><div class="er es kw"><img src="../Images/be89e92f48ba8428933c42b03d76cdd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*9IvFTi3EvmByZWFae0I-kg.png"/></div></figure><figure class="kb kc kd ke fd ik er es paragraph-image"><div class="er es kx"><img src="../Images/9f83cbdc51c3665bf31d0354b11351e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*7jEXiCTP727-oxS1kTx4EA.png"/></div></figure><p id="82e7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">实施:</strong></p><p id="8507" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">本节简要说明了实施过程:</p><ul class=""><li id="994f" class="jm jn hi ip b iq ir iu iv iy jo jc jp jg jq jk jr js jt ju bi translated">与所有数据科学和机器学习项目一样，这个项目也是从数据预处理开始的。</li><li id="a7e5" class="jm jn hi ip b iq jv iu jw iy jx jc jy jg jz jk jr js jt ju bi translated">数据被分成训练、测试和验证数据集。下面的代码执行这项任务。</li></ul><pre class="kb kc kd ke fd kk kl km kn aw ko bi"><span id="07dc" class="kp kq hi kl b fi kr ks l kt ku">train_data = datasets.ImageFolder(train_dir, transform=data_transforms['train'])<br/>valid_data = datasets.ImageFolder(valid_dir, transform=data_transforms['valid'])<br/>test_data = datasets.ImageFolder(test_dir, transform=data_transforms['test'])</span><span id="c64c" class="kp kq hi kl b fi ky ks l kt ku">training_loader = torch.utils.data.DataLoader(train_data,<br/>                                           batch_size=batch_size, <br/>                                           num_workers=num_workers,<br/>                                           shuffle=True)<br/>validation_loader = torch.utils.data.DataLoader(valid_data,<br/>                                           batch_size=batch_size, <br/>                                           num_workers=num_workers,<br/>                                           shuffle=False)<br/>testing_loader = torch.utils.data.DataLoader(test_data,<br/>                                           batch_size=batch_size, <br/>                                           num_workers=num_workers,<br/>                                           shuffle=False)</span></pre><ul class=""><li id="480e" class="jm jn hi ip b iq ir iu iv iy jo jc jp jg jq jk jr js jt ju bi translated">然后是主要的过程，图像增强。这样做是为了得到图像的变化。这有助于预测图像中的狗相对于帧处于不同角度的情况。简而言之，为了防止过度拟合</li></ul><p id="ea08" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">图像增强在下面的代码片段中执行。</p><pre class="kb kc kd ke fd kk kl km kn aw ko bi"><span id="d504" class="kp kq hi kl b fi kr ks l kt ku"><br/>'train': transforms.Compose([transforms.RandomResizedCrop(224),<br/>                    transforms.RandomHorizontalFlip(),<br/>                    transforms.ToTensor(),<br/>                    transforms.Normalize(mean=[0.485, 0.456, 0.406],<br/>                                      std=[0.229, 0.224, 0.225])]),<br/>'valid': transforms.Compose([transforms.Resize(256),<br/>                            transforms.CenterCrop(224),<br/>                            transforms.ToTensor(),<br/>                   transforms.Normalize(mean=[0.485, 0.456, 0.406],<br/>                                       std=[0.229, 0.224, 0.225])]),<br/>'test': transforms.Compose([transforms.Resize(size=(224,224)), <br/>                            transforms.CenterCrop(224),<br/>                            transforms.ToTensor(),<br/>                    transforms.Normalize(mean=[0.485, 0.456, 0.406],<br/>                                       std=[0.229, 0.224, 0.225])])</span></pre><ul class=""><li id="db80" class="jm jn hi ip b iq ir iu iv iy jo jc jp jg jq jk jr js jt ju bi translated">使用分类器的OpenCV实现检测人脸。</li><li id="7523" class="jm jn hi ip b iq jv iu jw iy jx jc jy jg jz jk jr js jt ju bi translated">VGG16模型用于创建狗检测器。</li></ul><p id="61e5" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">下面是VGG16模型的代码片段</p><pre class="kb kc kd ke fd kk kl km kn aw ko bi"><span id="bfda" class="kp kq hi kl b fi kr ks l kt ku">import torch<br/>import torchvision.models as models</span><span id="a80e" class="kp kq hi kl b fi ky ks l kt ku"># define VGG16 model<br/>VGG16 = models.vgg16(pretrained=True)</span></pre><ul class=""><li id="b4b2" class="jm jn hi ip b iq ir iu iv iy jo jc jp jg jq jk jr js jt ju bi translated">CNN模型是从零开始创建的。这包括模型的训练、测试和验证。这里有3个卷积层，每层的核大小为3，步长为1。</li><li id="fd6f" class="jm jn hi ip b iq jv iu jw iy jx jc jy jg jz jk jr js jt ju bi translated">下面是从头开始创建的模型的架构</li></ul><pre class="kb kc kd ke fd kk kl km kn aw ko bi"><span id="c13e" class="kp kq hi kl b fi kr ks l kt ku">----------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv2d-1         [-1, 32, 112, 112]             896<br/>         MaxPool2d-2           [-1, 32, 56, 56]               0<br/>            Conv2d-3           [-1, 64, 28, 28]          18,496<br/>         MaxPool2d-4           [-1, 64, 14, 14]               0<br/>            Conv2d-5          [-1, 128, 14, 14]          73,856<br/>         MaxPool2d-6            [-1, 128, 7, 7]               0<br/>           Dropout-7                 [-1, 6272]               0<br/>            Linear-8                  [-1, 500]       3,136,500<br/>           Dropout-9                  [-1, 500]               0<br/>           Linear-10                  [-1, 133]          66,633<br/>================================================================<br/>Total params: 3,296,381<br/>Trainable params: 3,296,381<br/>Non-trainable params: 0<br/>----------------------------------------------------------------<br/>Input size (MB): 0.57<br/>Forward/backward pass size (MB): 4.60<br/>Params size (MB): 12.57<br/>Estimated Total Size (MB): 17.75<br/>----------------------------------------------------------------</span></pre><ul class=""><li id="cdfc" class="jm jn hi ip b iq ir iu iv iy jo jc jp jg jq jk jr js jt ju bi translated">具有Resnet101架构的CNN模型用于使用迁移学习过程来创建模型。</li></ul><p id="bd47" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">这是迁移学习模型的模型架构:</p><pre class="kb kc kd ke fd kk kl km kn aw ko bi"><span id="0354" class="kp kq hi kl b fi kr ks l kt ku">---------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv2d-1         [-1, 64, 112, 112]           9,408<br/>       BatchNorm2d-2         [-1, 64, 112, 112]             128<br/>              ReLU-3         [-1, 64, 112, 112]               0<br/>         MaxPool2d-4           [-1, 64, 56, 56]               0<br/>            Conv2d-5           [-1, 64, 56, 56]           4,096<br/>       BatchNorm2d-6           [-1, 64, 56, 56]             128<br/>              ReLU-7           [-1, 64, 56, 56]               0<br/>            Conv2d-8           [-1, 64, 56, 56]          36,864<br/>       BatchNorm2d-9           [-1, 64, 56, 56]             128<br/>             ReLU-10           [-1, 64, 56, 56]               0<br/>           Conv2d-11          [-1, 256, 56, 56]          16,384<br/>      BatchNorm2d-12          [-1, 256, 56, 56]             512<br/>           Conv2d-13          [-1, 256, 56, 56]          16,384<br/>      BatchNorm2d-14          [-1, 256, 56, 56]             512<br/>             ReLU-15          [-1, 256, 56, 56]               0<br/>       Bottleneck-16          [-1, 256, 56, 56]               0<br/>           Conv2d-17           [-1, 64, 56, 56]          16,384<br/>      BatchNorm2d-18           [-1, 64, 56, 56]             128<br/>             ReLU-19           [-1, 64, 56, 56]               0<br/>           Conv2d-20           [-1, 64, 56, 56]          36,864<br/>      BatchNorm2d-21           [-1, 64, 56, 56]             128<br/>             ReLU-22           [-1, 64, 56, 56]               0<br/>           Conv2d-23          [-1, 256, 56, 56]          16,384<br/>      BatchNorm2d-24          [-1, 256, 56, 56]             512<br/>             ReLU-25          [-1, 256, 56, 56]               0<br/>       Bottleneck-26          [-1, 256, 56, 56]               0<br/>           Conv2d-27           [-1, 64, 56, 56]          16,384<br/>      BatchNorm2d-28           [-1, 64, 56, 56]             128<br/>             ReLU-29           [-1, 64, 56, 56]               0<br/>           Conv2d-30           [-1, 64, 56, 56]          36,864<br/>      BatchNorm2d-31           [-1, 64, 56, 56]             128<br/>             ReLU-32           [-1, 64, 56, 56]               0<br/>           Conv2d-33          [-1, 256, 56, 56]          16,384<br/>      BatchNorm2d-34          [-1, 256, 56, 56]             512<br/>             ReLU-35          [-1, 256, 56, 56]               0<br/>       Bottleneck-36          [-1, 256, 56, 56]               0<br/>           Conv2d-37          [-1, 128, 56, 56]          32,768<br/>      BatchNorm2d-38          [-1, 128, 56, 56]             256<br/>             ReLU-39          [-1, 128, 56, 56]               0<br/>           Conv2d-40          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-41          [-1, 128, 28, 28]             256<br/>             ReLU-42          [-1, 128, 28, 28]               0<br/>           Conv2d-43          [-1, 512, 28, 28]          65,536<br/>      BatchNorm2d-44          [-1, 512, 28, 28]           1,024<br/>           Conv2d-45          [-1, 512, 28, 28]         131,072<br/>      BatchNorm2d-46          [-1, 512, 28, 28]           1,024<br/>             ReLU-47          [-1, 512, 28, 28]               0<br/>       Bottleneck-48          [-1, 512, 28, 28]               0<br/>           Conv2d-49          [-1, 128, 28, 28]          65,536<br/>      BatchNorm2d-50          [-1, 128, 28, 28]             256<br/>             ReLU-51          [-1, 128, 28, 28]               0<br/>           Conv2d-52          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-53          [-1, 128, 28, 28]             256<br/>             ReLU-54          [-1, 128, 28, 28]               0<br/>           Conv2d-55          [-1, 512, 28, 28]          65,536<br/>      BatchNorm2d-56          [-1, 512, 28, 28]           1,024<br/>             ReLU-57          [-1, 512, 28, 28]               0<br/>       Bottleneck-58          [-1, 512, 28, 28]               0<br/>           Conv2d-59          [-1, 128, 28, 28]          65,536<br/>      BatchNorm2d-60          [-1, 128, 28, 28]             256<br/>             ReLU-61          [-1, 128, 28, 28]               0<br/>           Conv2d-62          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-63          [-1, 128, 28, 28]             256<br/>             ReLU-64          [-1, 128, 28, 28]               0<br/>           Conv2d-65          [-1, 512, 28, 28]          65,536<br/>      BatchNorm2d-66          [-1, 512, 28, 28]           1,024<br/>             ReLU-67          [-1, 512, 28, 28]               0<br/>       Bottleneck-68          [-1, 512, 28, 28]               0<br/>           Conv2d-69          [-1, 128, 28, 28]          65,536<br/>      BatchNorm2d-70          [-1, 128, 28, 28]             256<br/>             ReLU-71          [-1, 128, 28, 28]               0<br/>           Conv2d-72          [-1, 128, 28, 28]         147,456<br/>      BatchNorm2d-73          [-1, 128, 28, 28]             256<br/>             ReLU-74          [-1, 128, 28, 28]               0<br/>           Conv2d-75          [-1, 512, 28, 28]          65,536<br/>      BatchNorm2d-76          [-1, 512, 28, 28]           1,024<br/>             ReLU-77          [-1, 512, 28, 28]               0<br/>       Bottleneck-78          [-1, 512, 28, 28]               0<br/>           Conv2d-79          [-1, 256, 28, 28]         131,072<br/>      BatchNorm2d-80          [-1, 256, 28, 28]             512<br/>             ReLU-81          [-1, 256, 28, 28]               0<br/>           Conv2d-82          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-83          [-1, 256, 14, 14]             512<br/>             ReLU-84          [-1, 256, 14, 14]               0<br/>           Conv2d-85         [-1, 1024, 14, 14]         262,144<br/>      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048<br/>           Conv2d-87         [-1, 1024, 14, 14]         524,288<br/>      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048<br/>             ReLU-89         [-1, 1024, 14, 14]               0<br/>       Bottleneck-90         [-1, 1024, 14, 14]               0<br/>           Conv2d-91          [-1, 256, 14, 14]         262,144<br/>      BatchNorm2d-92          [-1, 256, 14, 14]             512<br/>             ReLU-93          [-1, 256, 14, 14]               0<br/>           Conv2d-94          [-1, 256, 14, 14]         589,824<br/>      BatchNorm2d-95          [-1, 256, 14, 14]             512<br/>             ReLU-96          [-1, 256, 14, 14]               0<br/>           Conv2d-97         [-1, 1024, 14, 14]         262,144<br/>      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048<br/>             ReLU-99         [-1, 1024, 14, 14]               0<br/>      Bottleneck-100         [-1, 1024, 14, 14]               0<br/>          Conv2d-101          [-1, 256, 14, 14]         262,144<br/>     BatchNorm2d-102          [-1, 256, 14, 14]             512<br/>            ReLU-103          [-1, 256, 14, 14]               0<br/>          Conv2d-104          [-1, 256, 14, 14]         589,824<br/>     BatchNorm2d-105          [-1, 256, 14, 14]             512<br/>            ReLU-106          [-1, 256, 14, 14]               0<br/>          Conv2d-107         [-1, 1024, 14, 14]         262,144<br/>     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048<br/>            ReLU-109         [-1, 1024, 14, 14]               0<br/>      Bottleneck-110         [-1, 1024, 14, 14]               0<br/>          Conv2d-111          [-1, 256, 14, 14]         262,144<br/>     BatchNorm2d-112          [-1, 256, 14, 14]             512<br/>            ReLU-113          [-1, 256, 14, 14]               0<br/>          Conv2d-114          [-1, 256, 14, 14]         589,824<br/>     BatchNorm2d-115          [-1, 256, 14, 14]             512<br/>            ReLU-116          [-1, 256, 14, 14]               0<br/>          Conv2d-117         [-1, 1024, 14, 14]         262,144<br/>     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048<br/>            ReLU-119         [-1, 1024, 14, 14]               0<br/>      Bottleneck-120         [-1, 1024, 14, 14]               0<br/>          Conv2d-121          [-1, 256, 14, 14]         262,144<br/>     BatchNorm2d-122          [-1, 256, 14, 14]             512<br/>            ReLU-123          [-1, 256, 14, 14]               0<br/>          Conv2d-124          [-1, 256, 14, 14]         589,824<br/>     BatchNorm2d-125          [-1, 256, 14, 14]             512<br/>            ReLU-126          [-1, 256, 14, 14]               0<br/>          Conv2d-127         [-1, 1024, 14, 14]         262,144<br/>     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048<br/>            ReLU-129         [-1, 1024, 14, 14]               0<br/>      Bottleneck-130         [-1, 1024, 14, 14]               0<br/>          Conv2d-131          [-1, 256, 14, 14]         262,144<br/>     BatchNorm2d-132          [-1, 256, 14, 14]             512<br/>            ReLU-133          [-1, 256, 14, 14]               0<br/>          Conv2d-134          [-1, 256, 14, 14]         589,824<br/>     BatchNorm2d-135          [-1, 256, 14, 14]             512<br/>            ReLU-136          [-1, 256, 14, 14]               0<br/>          Conv2d-137         [-1, 1024, 14, 14]         262,144<br/>     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048<br/>            ReLU-139         [-1, 1024, 14, 14]               0<br/>      Bottleneck-140         [-1, 1024, 14, 14]               0<br/>          Conv2d-141          [-1, 512, 14, 14]         524,288<br/>     BatchNorm2d-142          [-1, 512, 14, 14]           1,024<br/>            ReLU-143          [-1, 512, 14, 14]               0<br/>          Conv2d-144            [-1, 512, 7, 7]       2,359,296<br/>     BatchNorm2d-145            [-1, 512, 7, 7]           1,024<br/>            ReLU-146            [-1, 512, 7, 7]               0<br/>          Conv2d-147           [-1, 2048, 7, 7]       1,048,576<br/>     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096<br/>          Conv2d-149           [-1, 2048, 7, 7]       2,097,152<br/>     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096<br/>            ReLU-151           [-1, 2048, 7, 7]               0<br/>      Bottleneck-152           [-1, 2048, 7, 7]               0<br/>          Conv2d-153            [-1, 512, 7, 7]       1,048,576<br/>     BatchNorm2d-154            [-1, 512, 7, 7]           1,024<br/>            ReLU-155            [-1, 512, 7, 7]               0<br/>          Conv2d-156            [-1, 512, 7, 7]       2,359,296<br/>     BatchNorm2d-157            [-1, 512, 7, 7]           1,024<br/>            ReLU-158            [-1, 512, 7, 7]               0<br/>          Conv2d-159           [-1, 2048, 7, 7]       1,048,576<br/>     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096<br/>            ReLU-161           [-1, 2048, 7, 7]               0<br/>      Bottleneck-162           [-1, 2048, 7, 7]               0<br/>          Conv2d-163            [-1, 512, 7, 7]       1,048,576<br/>     BatchNorm2d-164            [-1, 512, 7, 7]           1,024<br/>            ReLU-165            [-1, 512, 7, 7]               0<br/>          Conv2d-166            [-1, 512, 7, 7]       2,359,296<br/>     BatchNorm2d-167            [-1, 512, 7, 7]           1,024<br/>            ReLU-168            [-1, 512, 7, 7]               0<br/>          Conv2d-169           [-1, 2048, 7, 7]       1,048,576<br/>     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096<br/>            ReLU-171           [-1, 2048, 7, 7]               0<br/>      Bottleneck-172           [-1, 2048, 7, 7]               0<br/>       AvgPool2d-173           [-1, 2048, 1, 1]               0<br/>          Linear-174                  [-1, 133]         272,517<br/>================================================================<br/>Total params: 23,780,549<br/>Trainable params: 272,517<br/>Non-trainable params: 23,508,032<br/>----------------------------------------------------------------<br/>Input size (MB): 0.57<br/>Forward/backward pass size (MB): 286.55<br/>Params size (MB): 90.72<br/>Estimated Total Size (MB): 377.84<br/>----------------------------------------------------------------</span></pre><ul class=""><li id="ba49" class="jm jn hi ip b iq ir iu iv iy jo jc jp jg jq jk jr js jt ju bi translated">最后，编写这个app的主要代码。这里把狗检测器和人检测器结合起来，处理下面的情况。</li><li id="53e6" class="jm jn hi ip b iq jv iu jw iy jx jc jy jg jz jk jr js jt ju bi translated">如果检测到狗，则输出该品种。</li><li id="712a" class="jm jn hi ip b iq jv iu jw iy jx jc jy jg jz jk jr js jt ju bi translated">如果人类被检测到，则输出与人类相似的品种，以及人类被检测到的消息。</li><li id="a9a7" class="jm jn hi ip b iq jv iu jw iy jx jc jy jg jz jk jr js jt ju bi translated">如果两者都不是，则输出指示相同的适当消息。</li></ul><p id="ebae" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">模型评估和验证:</strong></p><p id="552a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><a class="ae jl" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>(CNN)用于创建模型。最初<strong class="ip hj">车型是从零开始创造的</strong>。这个模型的目标是至少有10 %的精确度。设定这个目标的原因是为了确保模型比随机猜测做得更好(<strong class="ip hj"> 1%的准确性</strong>)。</p><p id="a50b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">现在使用<a class="ae jl" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank"> <strong class="ip hj">迁移学习</strong> </a> <strong class="ip hj"> </strong>创建了一个新的CNN模型，目标是准确率超过<strong class="ip hj"> 60%。该模型被训练20个时期。应用中的模型超过预期，准确率为72%。在总共836幅图像中，它正确预测了619幅。</strong></p><p id="c814" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">测试准确率:72% (610/836) </strong></p><p id="6a61" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">输出:</strong></p><p id="2751" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">下图描述了我的应用程序的输出。</p><figure class="kb kc kd ke fd ik er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es kz"><img src="../Images/8fa7803acff323a21b46d0a509abf1c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rBpqs0slkhpBavZ7mtcC5Q.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">所有情况下的应用程序输出示例(狗图像、人图像、无)</figcaption></figure><p id="6c0d" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">总结</strong>:</p><p id="205f" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">与从零开始创建的模型(10%的准确率)相比，使用迁移学习创建的模型要好得多(74%的准确率)。因此，我们通过选择迁移学习做得更好。这为迁移学习解决这类问题开辟了广阔的空间。</p><p id="d05b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">改进:</strong></p><p id="3b28" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">下面的步骤可能会产生一个更好的模型，在精度上有很大的提高。</p><ul class=""><li id="ab20" class="jm jn hi ip b iq ir iu iv iy jo jc jp jg jq jk jr js jt ju bi translated">我们可以使用除<strong class="ip hj"> ResNet101 </strong>之外的架构，这可能会提高性能。</li><li id="dffa" class="jm jn hi ip b iq jv iu jw iy jx jc jy jg jz jk jr js jt ju bi translated">可以增加图像放大以防止更多的<strong class="ip hj">过度拟合</strong>并提高精确度。</li><li id="b664" class="jm jn hi ip b iq jv iu jw iy jx jc jy jg jz jk jr js jt ju bi translated">每种狗的更多图像导致更好的预测。</li></ul><p id="f5e2" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">项目链接:</strong></p><p id="ee14" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">如果你已经做到这一步，那么我很高兴分享我的项目代码。下面是我的项目目录的github链接。根目录下的<strong class="ip hj"> Readme.md </strong>文件中给出了项目的使用说明。</p><p id="81d9" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">链接:<a class="ae jl" href="https://github.com/KIRANVASISHTA/Dog-Breed-Classifier" rel="noopener ugc nofollow" target="_blank">https://github.com/KIRANVASISHTA/Dog-Breed-Classifier</a></p><p id="6d99" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">参考文献:</strong></p><p id="9ec4" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">除了上面提到的链接，下面的链接对我完成这个项目帮助很大。</p><p id="c634" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">1.Udacity犬种分类器<a class="ae jl" href="https://github.com/udacity/deep-learning-v2-pytorch/tree/master/project-dog-classification" rel="noopener ugc nofollow" target="_blank">https://github . com/uda city/deep-learning-v2-py torch/tree/master/project-dog-classification</a></p><p id="3841" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.来自卡格尔的resnet 101:<a class="ae jl" href="https://www.kaggle.com/pytorch/resnet101" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/pytorch/resnet101</a></p><p id="9462" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">3.Pytorch教程:<a class="ae jl" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/</a></p><p id="4ef5" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">4.jupyter项目文件中给出了更多的参考资料。</p><p id="3cf6" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">除此之外，我还要感谢Udacity为我提供了这个学习和完成这个项目的机会。</p></div></div>    
</body>
</html>