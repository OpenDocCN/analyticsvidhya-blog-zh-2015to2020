<html>
<head>
<title>SIIM-ACR Pneumothorax Segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SIIM-阿克尔气胸分割法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/siim-acr-pneumothorax-segmentation-d92af3086b51?source=collection_archive---------6-----------------------#2020-12-08">https://medium.com/analytics-vidhya/siim-acr-pneumothorax-segmentation-d92af3086b51?source=collection_archive---------6-----------------------#2020-12-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="8e50" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated"><code class="du ix iy iz ja b">Can Artificial Intelligence recognize pneumothoraces(Collapsed Lung) from Chest X-ray and save lives?</code></h2></div><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es jb"><img src="../Images/71994a5159fb063ec63c300330399b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IHzf11afYwRieoJbJgBH-g.jpeg"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">图片提供:<a class="ae jr" href="https://www.medimaging.net/industry-news/articles/294778410/acr-releases-second-research-road-map-on-medical-imaging-ai.html" rel="noopener ugc nofollow" target="_blank">https://www . medi maging . net/industry-news/articles/294778410/ACR-releases-second-research-road-map-on-medical-imaging-ai . html</a></figcaption></figure><p id="a260" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi ko translated"><span class="l kp kq kr bm ks kt ku kv kw di">一个</span>人工智能已经接管了各种行业，信不信由你，你在手机中使用的每个应用程序都在使用<strong class="ju hj"> AI </strong>在某种程度上，有如此多的医疗正在使用<strong class="ju hj"> AI </strong>来诊断各种疾病。事实上，医疗保健行业中的数字成像领域是一种非常受欢迎的诊断重大疾病的方法，如今<strong class="ju hj">人工</strong>智能通过分析X射线、ct扫描等的数字成像为这种诊断提供了很大帮助。在这篇博客中，我将展示我在案例研究“<strong class="ju hj"> <em class="kx"> SIIM-ACR气胸分割</em> </strong>”中的工作，其中包括使用胸部X射线识别肺部疾病。</p><p id="fbfa" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">所以让我们来看看博客的轮廓，</p><ol class=""><li id="0b40" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn ld le lf lg bi translated"><em class="kx">业务问题</em></li><li id="7103" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">将业务问题映射为深度学习问题</em></li><li id="9bc8" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">现有方法</em></li><li id="e24e" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">我的第一次切入方式</em></li><li id="025e" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">探索性数据分析</em></li><li id="5d8c" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">数据预处理</em></li><li id="4e9a" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">深度学习模型</em></li><li id="e58d" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">最终管线</em></li><li id="864c" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">部署</em></li><li id="21bd" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">未来扩展</em></li><li id="42fd" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated"><em class="kx">参考文献</em></li></ol><p id="9a27" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">现在让我们开始人工智能的故事，</p><p id="f8b8" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">注:这将是一个很长的故事，但相信我，它真的很有趣。着急的可以直接去本博客的 <strong class="ju hj"> <em class="kx">部署</em> </strong> <em class="kx">版块看一个工作的web应用演示。</em></p><h1 id="0375" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated"><strong class="ak"> 1。商务问题:</strong></h1><p id="6dfa" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated"><strong class="ju hj"> 1.1说明:</strong></p><p id="1958" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">首先，我们要了解什么是气胸，对吗？</p><p id="26ae" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">所以，</p><ul class=""><li id="0136" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated"><strong class="ju hj">气胸</strong>基本上就是两个字Pneumo(空气)和Thorax(胸腔)的组合。气胸又称肺萎陷。气胸是由壁层胸膜和内脏胸膜(即肺和胸壁之间的胸膜空间)之间的空气异常聚集引起的。气胸是一种相对常见的呼吸系统疾病，可发生在各种患者和各种临床环境中。下图是一个正常的和气胸影响的肺，可以让你对它的实际情况有一点了解。</li></ul><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es mk"><img src="../Images/e6b5aa35dc31fb5ee01ba0898698636b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*IOoIC69UK2jmhuOsGoMq3Q.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated"><code class="du ix iy iz ja b">Image Credit: <a class="ae jr" href="https://www.firstaidforfree.com/what-is-a-spontaneous-pneumothorax/" rel="noopener ugc nofollow" target="_blank">https://www.firstaidforfree.com/what-is-a-spontaneous-pneumothorax/</a></code></figcaption></figure><ul class=""><li id="cced" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated"><strong class="ju hj">气胸的症状</strong>包括突然发作的剧烈、单侧胸痛和气短。气胸可能由胸部钝伤、潜在肺部疾病的损伤引起，或者最可怕的是——它可能没有任何明显的原因。在某些情况下，肺萎陷可能会危及生命。仅通过体格检查诊断气胸可能是困难的，尤其是在较小的气胸中。通常，胸部x光、CT(计算机断层扫描)扫描或超声波用于检测或确认气胸的存在。小气胸通常无需治疗即可解决，只需监测即可。这种方法可能适用于没有潜在疾病的人。在较大的气胸或呼吸急促的情况下，可以通过连接到单向阀系统的注射器或胸管排出空气。偶尔，如果引流管引流不成功，可能需要手术。每年每100，000人中大约发生17-23例气胸。男性比女性更常见。</li><li id="77fb" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated"><strong class="ju hj">对有经验的医生或放射科医生来说，在胸部放射摄影图像中诊断气胸并不困难，但在某些情况下，它很容易被遗漏。通常，它是由放射科医生在胸部x光片上诊断的，如上所述，有时很难确诊。一个精确的人工智能算法来检测气胸将在许多临床场景中有用。人工智能可以用于优先解释胸片，或者为非放射科医生提供更有信心的诊断。换句话说，需要根据胸部X射线图像的基于机器学习的气胸诊断技术来辅助医生诊断气胸。</strong></li></ul><p id="f957" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj">来源:</strong>此问题属于Kaggle上举办的比赛之一，可在以下链接找到:</p><div class="ml mm ez fb mn mo"><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">SIIM-阿克尔气胸分割法</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">在胸片中识别气胸疾病</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.kaggle.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc jl mo"/></div></div></a></div><p id="2731" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 1.2业务目标:</strong></p><ul class=""><li id="91f1" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">我们必须预测气胸，并根据x光图像进行分割</li><li id="e490" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">预测所需的时间应该从几秒到几分钟。</li></ul><h1 id="82e1" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">2.深度学习问题:</h1><p id="9b90" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated">在上面的部分中，我们已经看到了什么是气胸以及如何得到诊断，因此下一步是将该问题公式化为深度学习问题。首先，我们将检查我们有什么样的数据。</p><p id="c281" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 2.1数据:</strong></p><p id="554a" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">我们有两个CSV文件，一个用于训练集，一个用于测试集。训练CSV文件包含图像(X射线)id及其相应的RLE遮罩，而测试CSV文件仅包含图像(X射线)id。</p><p id="82b0" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">数据由DICOM格式的图像和图像id形式的注释以及游程编码(RLE)掩码组成。一些图像包含气胸(肺萎陷)的实例，这由注释中的编码二进制掩码指示。一些训练图像具有多个注释。</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es nd"><img src="../Images/40284f637fd9b09bcb3231ee1b999ca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A9EYEB6O2mE3IKxib3sUBA.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">x射线ID及其相应的RLE编码掩模</figcaption></figure><p id="4323" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">没有气胸的图像的遮罩值为-1。这意味着一个空白的面具。</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es ne"><img src="../Images/db43333c923244882c68a34bc10f49d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0rFVcuAqVxVL_bvPPyA8BA.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">x射线ID及其相应的RLE编码掩模</figcaption></figure><p id="8aa9" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">该数据集可在以下位置找到:</p><div class="ml mm ez fb mn mo"><a href="https://www.kaggle.com/seesee/siim-train-test" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">SIIM _火车_测试</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">Kaggle是世界上最大的数据科学社区，拥有强大的工具和资源来帮助您实现您的数据…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.kaggle.com</p></div></div><div class="mx l"><div class="nf l mz na nb mx nc jl mo"/></div></div></a></div><p id="f81f" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 2.2将真实世界问题映射到深度学习问题:</strong></p><p id="b45f" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 2.2.1深度学习问题类型:</strong></p><p id="ff50" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">正如我们在数据集部分看到的，我们有一个图像形式的数据集，我们的任务是预测X射线图像中气胸的掩蔽。这个问题属于<strong class="ju hj">语义图像分割</strong>问题。该模型将帮助医生诊断<strong class="ju hj">气胸</strong>。</p><p id="e783" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">为了解决这个问题，我们必须使用深度学习技术，这些技术用于音频和视频文件、图像等非结构化数据。在这种特殊情况下，我们有X射线图像形式的数据，这是非结构化数据之一。</p><p id="ac71" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">我将简单介绍一下图像分割，</p><p id="54a6" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">基本上，图像分割是一项任务，其中我们对属于特定对象类的图像的像素值进行分类。因此，基于对这些像素进行分类的方式，大致有两种类型的分割，语义分割和实例分割。考虑下面的图片:</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es ng"><img src="../Images/6a51cfcc8c64163fc8b1f90fcf9ff207.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eUG84jvG3NZ4ZCa4maZT4g.png"/></div></div></figure><ul class=""><li id="eb5d" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated"><strong class="ju hj">语义分割:</strong></li></ul><p id="d163" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在这种技术中，所有相似类型的像素用相同的颜色分割，正如我们在上面的图像中看到的。它检测到有粉红色阴影的人和黑色背景的人。</p><ul class=""><li id="7d2e" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated"><strong class="ju hj">实例分割:</strong></li></ul><p id="3b0c" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">这种技术用不同的颜色分割所有相似的物体或像素，我们可以看到在上面的图像中每个人都用不同的颜色表示。</p><p id="03ea" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">如前所述，我们的问题属于语义分割范畴，我们必须将像素标记为遮罩或非遮罩(背景)。</p><p id="9b65" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 2.2.2评价指标:</strong></p><p id="a71e" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">现在我们知道这个问题是一个语义分割问题。我们必须定义一个衡量标准来评估我们的深度学习模型。对于分割模型的评估，有一个更常用和更好的度量，称为Dice系数。</p><ul class=""><li id="d57b" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated"><strong class="ju hj">骰子系数:</strong></li></ul><p id="6fb3" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">骰子系数源于<a class="ae jr" href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient" rel="noopener ugc nofollow" target="_blank">索伦森–骰子系数</a>，是20世纪40年代开发的一种统计方法，用于衡量两个样本之间的相似性。2016年由Milletari等人带到计算机视觉社区，用于3D医学图像分割。骰子损失也称为F1得分指标。简单地说，Dice系数是2 *重叠面积除以两幅图像中的总像素数。骰子损失范围从0到1，1表示预测和真实之间的最大相似性。</p><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es nh"><img src="../Images/c5b60e77a3474eb613486ed36cf0a090.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*3JvrlheTNjY2fj9AGGxYsA.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated"><code class="du ix iy iz ja b"><a class="ae jr" href="https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2" rel="noopener" target="_blank">Dice Coefficient</a> = (2 * Area of Overlap)/(total pixels combined)</code></figcaption></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es ni"><img src="../Images/624c488681dc24bc2e4f252f6069cf77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vsSo2OU2vY9e9Gr0KTkZZw.png"/></div></div></figure><ul class=""><li id="75b5" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated"><strong class="ju hj">损失度量:</strong></li></ul><p id="c098" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">每当我们解决机器学习问题或深度学习问题时，我们都需要一个很好的可信损失函数来检查我们的模型是否表现得更好。损失函数基本上是根据数据集的类型和我们所解决的问题来选择的。我们的问题是图像分割，对于分割模型的评估，研究人员发现二进制交叉熵和骰子损失是我们可以使用的最佳组合损失函数。这个<a class="ae jr" href="https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch#BCE-Dice-Loss" rel="noopener ugc nofollow" target="_blank">组合损失</a>对于不平衡数据集的问题非常有帮助。因此，在整个案例研究中，我将使用这个组合损失作为损失指标。将这两种方法结合起来考虑到了损耗的多样性，同时受益于BCE的稳定性。</p><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es nj"><img src="../Images/4d70b6c6280c5964492d1469f416b3c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*q3GKe44gZvYmlwSD8zz1Iw.png"/></div></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es nk"><img src="../Images/9624a939d389a9a6744e2218b62c7880.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hl7utZSYYZpm9pmIHC3Zug.png"/></div></div></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es nl"><img src="../Images/47304c8288042b450ff92366dfd04a8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*GhtjUEdqT5eBGQiF7hd0hw.png"/></div></figure><h1 id="ee39" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">3.现有方法:</h1><p id="24e3" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated"><strong class="ju hj"> 3.1第四名解法:</strong></p><p id="f453" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><a class="ae jr" href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/siim-ACR-气胸-分割/讨论</a> /108397</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es nm"><img src="../Images/585f727e6a74beb9343b5d2522a04049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YT0ypQdbvu6Obzi4HxUBKw.png"/></div></div></figure><p id="0e87" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">这是本次比赛的第四名解决方案。这是基于具有用于空掩码分类的深度监督分支的U-Net。他使用U-Net模型和ResNet34作为具有冻结批量标准化的主干网络。他使用了一些增强技术，如albumentations库中的ShiftScaleRotate、RandomBrightnessContrast、ElasticTransform、HorizontalFlip。使用的优化器是Adam，批量大小为8。对于快速收敛，非空样本的比例根据时期从0.8线性下降到0.22。他最后的合奏是平均4个最好的检查点超过8倍。</p><p id="8420" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 3.2用于气胸分割的Unet exception Keras:</strong></p><p id="f450" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><a class="ae jr" href="https://www.kaggle.com/meaninglesslives/unet-xception-keras-for-pneumo" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/meaninglesslives/unet-xception-keras-for-pneumonia</a>胸部分割</p><p id="93af" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">这个内核是由<a class="ae jr" href="https://www.kaggle.com/meaninglesslives" rel="noopener ugc nofollow" target="_blank">悉达多</a>共享的。这是基于带有ResNet解码器的预先训练的imagenet异常模型。他使用余弦退火和随机加权平均来收敛到一个更好的最优值。他在这个内核中说，模型的性能肯定可以通过使用其他一些技巧来提高，一个显而易见的方法是使用KFold交叉验证。在这个内核中使用的增强是弹性变形，网格变形。使用的图像尺寸为256x256。他使用了带有Xception的U-Net架构作为主干网络，他称之为Uxception模型。</p><h1 id="7ec0" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">4.我的第一个切割方法:</h1><p id="4544" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated">我将使用以下步骤开始案例研究:</p><ol class=""><li id="d42b" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn ld le lf lg bi translated"><em class="kx">数据采集</em>:</li></ol><p id="8787" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">对于任何问题，我们想要使用机器学习或深度学习算法来解决，我们需要足够多的数据。我们有时可能会在从各种来源收集数据时遇到困难，或者有时这并不是一项乏味的任务。谢天谢地，比赛组织者为我们提供了数据，我们只需下载并开始工作。因此，我将使用wget chrome扩展收集数据，以便从这里快速下载:</p><div class="ml mm ez fb mn mo"><a href="https://www.kaggle.com/seesee/full-dataset/data" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">完整数据集</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自多个数据源的数据</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.kaggle.com</p></div></div><div class="mx l"><div class="nn l mz na nb mx nc jl mo"/></div></div></a></div><p id="acf4" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">注意:我们也可以使用Kaggle API下载数据集。<a class="ae jr" href="https://www.youtube.com/watch?v=tGw-ZACouik&amp;t=120s" rel="noopener ugc nofollow" target="_blank">点击此处</a>了解诀窍。</p><p id="1dc6" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">2.<em class="kx">预处理</em>:</p><p id="a0b2" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">因为我们被提供了数据。dcm格式，这是一种DICOM图像格式，我将不得不提取的图像。dcm格式，并使数据适合训练深度学习模型。在这一步中，我还将为所有可用的训练数据创建分段掩码。掩码数据是以游程编码的形式给出的，所以我必须使用这种编码来生成掩码。为此，组织者提供了功能，所以我将使用它。</p><p id="79c1" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">3.<em class="kx"> EDA(探索性数据分析)</em>:</p><p id="2a4b" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">实际上，我们有图像数据，所以我们不能像处理其他有很多特征要比较的问题那样做太多的EDA。但好的一面是我们有Dicom文件，其中有一些关于图像的元数据。在训练模型时，这些元数据可能不完全有用，但我们可以从中获得一些见解，以便理解数据。我将尝试对可用的元数据以及我们可用的掩码信息执行EDA。</p><p id="f693" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">4.<em class="kx">模型开发</em>:</p><p id="7958" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">现在，我将从预处理步骤中生成的数据和掩码中获得一些见解。在这里，我将使用深度学习技术来解决这个问题。这是一个图像分割问题，有许多深度学习算法可用于执行分割任务。我将使用最流行的普通UNet架构作为这项任务的基线模型。基于这个模型的结果，我将尝试不同的架构，以实现可靠的模型性能。</p><h1 id="875a" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">5.探索性数据分析:</h1><h2 id="3e1d" class="no ln hi bd lo np nq nr ls ns nt nu lw kb nv nw ly kf nx ny ma kj nz oa mc ob bi translated">5.1让我们分析提供给我们的培训数据，</h2><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="c042" class="no ln hi ja b fi og oh l oi oj">train_data = pd.read_csv('siim/train-rle.csv', delimiter=',')<br/>train_data.head()</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es ok"><img src="../Images/c6ef69f2caf38baf6a3f311b84f48db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YgIDwBUU-r5bFvtin6DDOA.png"/></div></div></figure><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="7bca" class="no ln hi ja b fi og oh l oi oj">train_data.info()</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es ol"><img src="../Images/68bb2bbde087d1d3382a8c77a5fcb0d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Qc8b083eMTyIleRGf0leA.png"/></div></div></figure><ul class=""><li id="c31c" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">在上面的信息中，我可以看到我们总共有12954个X射线文件作为训练数据</li></ul><p id="9556" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">数据集中有两列:</p><ul class=""><li id="4fa2" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">ImageId =每位被检查患者的X射线Id</li><li id="2e6b" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">EncodedPixels =每个X射线图像的游程长度编码像素数据</li></ul><p id="9392" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">让我们检查数据集中是否有重复的ImageId。</p><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="1a82" class="no ln hi ja b fi og oh l oi oj"><em class="kx"># add column if the file is duplicate or not</em><br/>train_data['isDuplicate'] = train_data['ImageId'].duplicated()<br/>train_data.head()</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es om"><img src="../Images/cc70b7b4f82253158c91555cac9eaab3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKJxJjfoAaNwpOtD5di8lA.png"/></div></div></figure><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="f7d7" class="no ln hi ja b fi og oh l oi oj"><em class="kx"># check where the files are duplicate</em><br/>dupImages = train_data.index[train_data['isDuplicate']==<strong class="ja hj">True</strong>]<br/>print(f"We have total <strong class="ja hj">{</strong>len(dupImages)<strong class="ja hj">}</strong> duplicate image ids")</span><span id="75b3" class="no ln hi ja b fi on oh l oi oj">Output:</span><span id="e44b" class="no ln hi ja b fi on oh l oi oj">We have total <strong class="ja hj">907 duplicate</strong> image ids</span></pre><p id="fbc9" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">我们应该总是丢弃重复的文件，</p><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="7b24" class="no ln hi ja b fi og oh l oi oj">print(f"With duplicates we have total <strong class="ja hj">{</strong>len(train_data)<strong class="ja hj">}</strong> files.")<br/>train_data = train_data.drop(list(dupImages))<br/>print(f"Without duplicates we have total <strong class="ja hj">{</strong>len(train_data)<strong class="ja hj">}</strong> files.")</span><span id="437c" class="no ln hi ja b fi on oh l oi oj">Output:</span><span id="6e7c" class="no ln hi ja b fi on oh l oi oj"><strong class="ja hj">With duplicates</strong> we have total <strong class="ja hj">12954</strong> files.<br/><strong class="ja hj">Without duplicates</strong> we have total <strong class="ja hj">12047</strong> files.</span></pre><p id="c289" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">现在我已经删除了重复的图像Id，现在我必须为每个图像Id添加一个路径，以便进一步处理X射线图像，</p><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="6f0b" class="no ln hi ja b fi og oh l oi oj">train_data = train_data.drop('isDuplicate', axis=1)<br/>train_data['ImagePath'] = 'siim/train_dicom/'+ train_data['ImageId']+'.dcm'<br/><em class="kx"># save the .csv file for further use</em><br/>train_data.to_csv('train_images_dicom.csv', index=<strong class="ja hj">False</strong>)<br/>train_data.head()</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es oo"><img src="../Images/a6eb01cd5ce711f69b500449d7379af2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zw1N6QBb4zPEqAkuHHghhg.png"/></div></div></figure><h2 id="ffc1" class="no ln hi bd lo np nq nr ls ns nt nu lw kb nv nw ly kf nx ny ma kj nz oa mc ob bi translated">5.2让我们分析提供给我们的测试数据，</h2><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="2142" class="no ln hi ja b fi og oh l oi oj">test_data = pd.read_csv('siim/stage_2_sample_submission.csv', delimiter=',')<br/>test_data = test_data.drop('EncodedPixels', axis=1)<br/>test_data['ImagePath'] = 'siim/test_dicom/'+ test_data['ImageId']+'.dcm'<br/><em class="kx"># save the .csv file for further use</em><br/>test_data.to_csv('test_images_dicom.csv', index=<strong class="ja hj">False</strong>)<br/>test_data.head()</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es op"><img src="../Images/3153709471dffab23fd5581edc4daf59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bCXFJcb3DhPg9BThNsHIkQ.png"/></div></div></figure><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="44da" class="no ln hi ja b fi og oh l oi oj">test_data.info()</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es oq"><img src="../Images/6891bf6323bead50648010fceb95057f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wfm4Jr-BHypbAXUOPcZelQ.png"/></div></div></figure><ul class=""><li id="7632" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">在上面的信息中，我可以看到我们总共有3205个x光文件作为测试数据</li><li id="fc3e" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">我们在数据集中有一列:</li><li id="399e" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">ImageId =每位被检查患者的X射线Id</li></ul><p id="fbba" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">图像路径的第二列是我添加的。</p><h2 id="5003" class="no ln hi bd lo np nq nr ls ns nt nu lw kb nv nw ly kf nx ny ma kj nz oa mc ob bi translated">5.3元数据的分析，</h2><p id="5ab3" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated">正如在本博客前面部分所讨论的，我们有DICOM文件格式的图像。那么什么是DICOM呢？</p><p id="049a" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">DICOM<strong class="ju hj">(</strong><em class="kx"/><strong class="ju hj">)</strong>只不过是另一种存储图像的格式，就像<strong class="ju hj"> <em class="kx">一样。png </em> </strong>和<strong class="ju hj"> <em class="kx">。jpeg </em> </strong>，唯一不同的是与<strong class="ju hj"> <em class="kx">。dcm </em> </strong>格式我们可以把图像的元数据和图像一起存储到这个里面。这种格式通常用于医学成像领域。现在，几乎所有形式的医学成像都已数字化，放射学领域不仅包括数字射线照片，还包括CT扫描、核磁共振成像、超声波和核成像。DICOM是用于存储图像的文件格式，这些图像可以是X射线扫描、CT扫描等。以及元数据。</p><p id="ef0e" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">让我们开始分析DICOM文件，我们有一个很棒的python库来处理DICOM文件，即<strong class="ju hj">‘pydicom’</strong></p><p id="43d8" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">我们可以使用下面一行代码来安装<strong class="ju hj">‘pydicom’</strong>库，</p><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="2cd6" class="no ln hi ja b fi og oh l oi oj">pip install pydicom</span></pre><p id="5db6" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">给定图像的可用元数据太大，包含大量信息。并非所有信息都对我们有用，因此我们将分析文件中的一些重要数据，如患者年龄、性别等。</p><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="c1f1" class="no ln hi ja b fi og oh l oi oj"><em class="kx"># Check the total no. of males and females in the dataset</em><br/>mens = len(meta_data[meta_data["Gender"] == "M"])<br/>women = meta_data.shape[0] - mens<br/>print(f"We have total <strong class="ja hj">{</strong>mens<strong class="ja hj">}</strong> Males, and total <strong class="ja hj">{</strong>women<strong class="ja hj">}</strong> Females in the DataSet.")</span><span id="809e" class="no ln hi ja b fi on oh l oi oj">Output:</span><span id="2b66" class="no ln hi ja b fi on oh l oi oj"><strong class="ja hj">We have total 6626 Males, and total 5421 Females in the DataSet.</strong></span><span id="670e" class="no ln hi ja b fi on oh l oi oj"><em class="kx">#Check the number of pneumothorax affected people and healthy</em><br/>healthy = len(meta_data[meta_data["Affection"] == "No"])<br/>ill = len(meta_data) - healthy<br/>print(f"We have total <strong class="ja hj">{</strong>healthy<strong class="ja hj">}</strong> healthy patients, and <strong class="ja hj">{</strong>ill<strong class="ja hj">}</strong> pneumothorax affected patients")</span><span id="031d" class="no ln hi ja b fi on oh l oi oj">Output:</span><span id="914d" class="no ln hi ja b fi on oh l oi oj"><strong class="ja hj">We have total 9378 healthy patients, and 2669 pneumothorax affected patients</strong></span></pre><p id="29a2" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">让我们以饼状图的形式将上述信息可视化，</p><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es or"><img src="../Images/8295a9d9e25fb0d7c66ad83c29d1d9e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*RYz-Ijj2rFT7Q86kvs9CNg.png"/></div></figure><ul class=""><li id="12f5" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">从上面的饼状图中，我可以看到55%的患者是男性，45%是女性。</li></ul><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es os"><img src="../Images/b45633cd61dbb75da7ad41bb14dcfea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*ccjdGeZ5I_bB5COF8PAh5w.png"/></div></figure><ul class=""><li id="71eb" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">Piec图表显示78%的患者是安全的，他们没有气胸，只有22%的人受到气胸的影响。</li></ul><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es ot"><img src="../Images/b2528bfd00f242dbbbb3651229b79df7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mAXqM0WZZEQspFXQEio45g.png"/></div></div></figure><ul class=""><li id="4cc4" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">以上是气胸患者性别分布的饼状图，我们可以看到男性和女性的分布几乎相同。</li><li id="a377" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">77.5%的男性健康，22.5%的男性患有气胸。</li><li id="5b7c" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">78.2%的女性是健康的，21.8%的女性患有气胸。</li></ul><p id="d5e5" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">从上图可以明显看出，男性和女性受影响的百分比几乎相同，所以现在只需绘制年龄直方图，以检查患者的年龄分布</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es ou"><img src="../Images/f59d960ad4186f614c37a88afd838aea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rLOHWik28LPGJZb35CdrOQ.png"/></div></div></figure><p id="80a6" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">观察结果:</p><ul class=""><li id="78fe" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">首先，年龄的总体分布看起来几乎是正态分布，但并不精确。</li><li id="9e11" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">在这个数据集中，0-6岁的婴儿不会受到气胸的影响。</li><li id="3cc9" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">从7岁到85岁，至少有一名患者受到影响。</li><li id="2edb" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">大多数受影响的患者年龄为51岁。</li><li id="4b5a" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">但是我们不能说特定的年龄组受到影响，因为我们有很大的差异，即几乎所有年龄在6岁以上的患者都受到影响。</li></ul><h1 id="9459" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">6.数据预处理:</h1><p id="aa31" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated">我们有<strong class="ju hj">形式的文件。dcm </strong>文件，我们不能直接使用它们来训练模型。所以我们必须把它们转换成<strong class="ju hj">。png </strong>格式。此外，我必须为各个图像创建遮罩，这也将在<strong class="ju hj">。png </strong>格式。</p><p id="006d" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">所以让我们开始吧，</p><p id="f561" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 6.1 DCM到PNG的转换:</strong></p><p id="9c2a" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">通过使用下面的函数，我们可以将。dcm文件转换成. png。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="ov ow l"/></div></figure><p id="fbad" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 6.2遮罩创建:</strong></p><p id="cc6f" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">我们有掩码为游程长度编码的数据，我们必须了解这实际上是什么，所以上面的视频给出了一个关于RLE的清晰概念。游程编码(RLE)是无损数据压缩的一种形式，在这种形式中，数据游程(相同数据值出现在许多连续数据元素中的序列)被存储为单个数据值和计数，而不是原始游程。这对于包含许多此类运行的数据非常有用。例如，考虑简单的图形图像，如图标、线条画、康威的生活游戏和动画。它对运行次数不多的文件没有用，因为它会大大增加文件的大小。</p><p id="505a" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">RLE : a4b3c3</p><p id="7f54" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">例如</p><p id="2613" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">输入:aaaabbbccc</p><p id="64be" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">RLE : a4b3c3</p><p id="2761" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">现在我把所有的文件都放在<strong class="ju hj">里了。png </strong>格式，下一步是为训练数据集中的每个图像创建地面真实遮罩。我们有行程长度编码像素形式的掩码数据，所以我们必须将它们转换成<strong class="ju hj">。png </strong>图片。组织者提供了一个使用RLE创建蒙版的函数，如下面的代码片段所示。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="ov ow l"/></div></figure><p id="69e5" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">下面是一个样本X射线，它是我用上面的函数创建的相应的遮罩，</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es ox"><img src="../Images/6fef9fcef6f734e2596b8a8fd43bff43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fyag2c6J9xb6Z-hadQjorg.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">从所提供的数据中选取带有屏蔽的X射线样本</figcaption></figure><ul class=""><li id="3544" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">上面是一个样本X射线和相应的面具</li><li id="c8b9" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">在最初的x光片中，很难识别是否有气胸。</li><li id="b864" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">但是事实摆在我们面前，我打印了x光片的蒙版图像，我用一个红色的补丁展示，这个补丁是气胸的存在。</li><li id="6e51" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">第三张图片是一张带面具的x光片，我可以看到面具在x光片上的准确位置。</li></ul><h1 id="17ec" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">7.深度学习模型:</h1><p id="c069" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated"><em class="kx">注意:本研究的主要目标不是实现很高的准确性或胜过任何模型，而是探索模型如何表现并执行输出分析，以便了解模型的行为。</em></p><p id="1efd" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 7.1香草U-Net: </strong></p><p id="ae0d" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">作为第一种方法，我使用了一个普通的U-网结构，在本文<a class="ae jr" href="https://arxiv.org/abs/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank"><em class="kx">【U-网:生物医学图像分割的卷积网络】</em> </a>中有所描述</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es oy"><img src="../Images/342f2c88bc2f14bea027a44026df8a50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvXoKMHoPJMKpKK7keZMEA.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">U-Net架构</figcaption></figure><p id="ab91" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">用于这个普通U-Net模型的代码很长，所以我在这里不包括它，你可以在我提供链接的Github库中找到完整的代码。</p><p id="9f81" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">以下是使用普通U-Net模型的结果，</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es oz"><img src="../Images/499a1a52d456b59b6bae4a3080fbd5f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T3AnYf-uQZ6c4QuTSY7fOQ.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">骰子系数和损失图U-网</figcaption></figure><ul class=""><li id="00c3" class="ky kz hi ju b jv jw jy jz kb la kf lb kj lc kn mj le lf lg bi translated">从上面的图表中，我可以说训练和测试集的模型工作良好，但在0.36014之后它没有提高分数。</li><li id="6858" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn mj le lf lg bi translated">这可能是由于U-Net网络架构是香草，我应该尝试一些不同于香草的结构</li></ul><p id="804b" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><strong class="ju hj"> 7.2双U形网:</strong></p><p id="dc2d" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">顾名思义，这只是两个U-Net模型的组合。该架构来自论文<a class="ae jr" href="https://arxiv.org/pdf/2006.00414" rel="noopener ugc nofollow" target="_blank"><em class="kx">【DC-UNet:反思U-Net架构与双通道高效CNN用于医学图像分割】</em> </a></p><p id="cc7e" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">作者对建筑的简短解释:</p><p id="d911" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><em class="kx"> DoubleU-Net以VGG19作为编码器子网开始，其后是解码器子网。在网络中，输入图像被馈送到修改的UNet(UNet1)，该UNet生成预测的掩模(即，输出1)。然后，我们将输入图像与生成的掩码(即，输出1)相乘，该掩码作为第二个修改的U-Net(UNet2)的输入，该U-Net生成另一个生成的掩码(输出2)。最后，我们连接两个掩码(输出1和输出2)以获得最终的预测掩码(输出)。</em></p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es pa"><img src="../Images/82524698ab0862a2fc42855eed7d98d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iVi5typWa2Q2rv92oI9mQQ.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">独创的双U网架构</figcaption></figure><p id="8439" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">作者提供的上述架构很好，但正如我们所看到的，有多个编码器和解码器模块，这意味着大量的训练参数，因此由于没有强大的资源来训练，我想通过使用2个模块而不是4个模块来稍微改变一下架构，如下图所示。</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es pa"><img src="../Images/da13b1719914396f106dcdad0faf9b92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*epIkzGfTstyAkxwAWwLnLw.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">改进的双U网结构</figcaption></figure><p id="8087" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">不仅删除块，而且我已经将图像数据格式改为“通道优先”格式，这是专家提供的提示，通道优先数据格式比通道最后数据格式效果更好。该架构的代码可以在我的GitHub存储库中找到。</p><p id="4e2f" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">通过使用上述架构，我得到了以下结果:</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es pb"><img src="../Images/409e6a76f04f80e2647b8e711240c377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ek8qSvHD8zsTzqq62I8Qbg.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">骰子系数和损失图双U网</figcaption></figure><p id="07df" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">30个周期后，模型给出的骰子系数为0.25491，当然，这不是很好，但正如前面讨论的，我正在进行实验。我保存了骰子系数为0.25491的最佳模型。</p><p id="a320" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在这之后，我做了一些分析，哪些类型的图像模型给出了高分，哪些类型的图像模型给出了低分。我计算了数据集中每个图像的骰子得分，发现具有大量背景像素的图像是模型给出高分的图像，这意味着低分图像是具有少量前景像素的图像。这是一个典型的不平衡数据集，因为我们有一个数据集，其中约80%的患者是健康的，20%是受影响的患者。</p><p id="99e2" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">因此，为了解决数据不平衡的问题，我使用了类加权方法，并为前景像素提供了更多的权重(这是我们正确预测的兴趣所在)，而为大多数背景像素提供了更少的权重。通过使用这一加权指标，我对之前的模型进一步训练了3个时期，但没有发现任何改进。以下是两个模型做出的预测:</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es pc"><img src="../Images/019813b6923a0bbfc427bc57e85cd5d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3iGzllBiluoOAjlXaoKEhw.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">没有加权指标的模型的预测</figcaption></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es pd"><img src="../Images/4475054d8f677f2decaa7bb59d703399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G_4yloi9zRoyuKwhktWzug.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">通过具有加权度量的模型进行预测</figcaption></figure><p id="c21c" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">这些图像图显示结果或多或少彼此相似。除了类加权方法，还有许多其他方法来处理数据不平衡问题，不幸的是，由于一些时间限制，我只训练了30个时期的模型，也没有尝试其他方法来处理数据不平衡。但是分数肯定可以通过训练300-1000个时期的模型以及一些其他方法来提高，如对少数类数据进行过采样，增强技术也将有助于提高分数。</p><h1 id="a476" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">8.最终管道:</h1><p id="208c" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated">因此，现在我正在使用保存的模型，并创建一个我们可以考虑部署的最终管道。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="ov ow l"/></div></figure><pre class="jc jd je jf fd oc ja od oe aw of bi"><span id="e6a5" class="no ln hi ja b fi og oh l oi oj"># load the saved model model.load_weights('/content/drive/MyDrive/27_Case_study_2/best_Double_Unet.hdf5')</span></pre><p id="b2fd" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">我们可以用上面的函数如下预测气胸、</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="jh ji di jj bf jk"><div class="er es pe"><img src="../Images/fd6d28a01be04b003531f8719f7a2d54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qvyos40jnwdtdjGsBukFdA.png"/></div></div></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es pf"><img src="../Images/e7acf423f53a680decc71da0ddd89add.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*z-lZJzkNIM7GAv8errPZjw.png"/></div></figure><h1 id="fe40" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">9.部署:</h1><p id="39d6" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated">我已经使用Flask API部署了上面解释的模型，下面是部署的web应用程序如何工作的演示视频，</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="pg ow l"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">气胸探测器演示网络应用程序</figcaption></figure><h1 id="4551" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">10.未来扩展:</h1><ol class=""><li id="7ee4" class="ky kz hi ju b jv me jy mf kb ph kf pi kj pj kn ld le lf lg bi translated">我们可以使用不同的方法来处理数据不平衡，更好的增强技术等。</li><li id="c354" class="ky kz hi ju b jv lh jy li kb lj kf lk kj ll kn ld le lf lg bi translated">Unet++架构可以用来解决这个深度学习问题。</li></ol><h1 id="85fe" class="lm ln hi bd lo lp lq lr ls lt lu lv lw io lx ip ly ir lz is ma iu mb iv mc md bi translated">11.参考资料:</h1><p id="ee26" class="pw-post-body-paragraph js jt hi ju b jv me ij jx jy mf im ka kb mg kd ke kf mh kh ki kj mi kl km kn hb bi translated">[1]<a class="ae jr" href="https://www.firstaidforfree.com/what-is-a-spontaneous-pneumothorax/" rel="noopener ugc nofollow" target="_blank">https://www . first aidforfree . com/什么是自发性气胸/ </a></p><p id="23fa" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[2] Drbeen解释气胸:<a class="ae jr" href="https://www.youtube.com/watch?v=uRMcgLvKeIE" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=uRMcgLvKeIE</a></p><p id="d80f" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">【3】气胸动画:【https://youtu.be/DgU1HE_6ueI T2】</p><p id="d2a7" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[4]<a class="ae jr" href="https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2" rel="noopener" target="_blank">https://towards data science . com/metrics-to-evaluate-your-semantic-segmentation-model-6 BCB 99639 aa 2</a></p><p id="2ad4" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[5]<a class="ae jr" href="https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/jesperdramsch/intro-chest-Xray-DICOM-viz-u-nets-full-data</a></p><p id="6db7" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[6]<a class="ae jr" href="https://www.kaggle.com/retyidoro/eda-of-pneumothorax-dataset#Exploratory-Data-Analysis-of-Pneumothorax-dataset" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/retyidoro/EDA-of-气胸-数据集#气胸的探索性数据分析-数据集</a></p><p id="0263" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[7]<a class="ae jr" href="https://www.kaggle.com/schlerp/getting-to-know-dicom-and-the-data/notebook" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/sch lerp/getting-to-know-DICOM-and-the-data/notebook</a></p><p id="1c1e" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[8]<a class="ae jr" href="https://www.postdicom.com/en/blog/handling-dicom-medical-imaging-data" rel="noopener ugc nofollow" target="_blank">https://www . post DICOM . com/en/blog/handling-DICOM-medical-imaging-data</a></p><p id="0eb9" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><a class="ae jr" href="https://www.geeksforgeeks.org/run-length-encoding/" rel="noopener ugc nofollow" target="_blank">https://www.geeksforgeeks.org/run-length-encoding/</a></p><p id="db92" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[10]优网:<a class="ae jr" href="https://arxiv.org/abs/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1505.04597.pdf</a></p><p id="a9d0" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[11]双U网:<a class="ae jr" href="https://arxiv.org/pdf/2006.04868.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2006.04868.pdf</a></p><p id="5fdd" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated"><a class="ae jr" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com/</a></p><p id="e521" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">【13】<a class="ae jr" href="https://www.youtube.com/watch?v=h6skw_h7Wg8" rel="noopener ugc nofollow" target="_blank">如何在Google Colab中运行Flask</a></p><p id="4497" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[14] <a class="ae jr" href="https://towardsdatascience.com/building-a-web-application-to-deploy-machine-learning-models-e224269c1331" rel="noopener" target="_blank">构建一个Web应用程序来部署机器学习模型|作者李宗德·韦恩|走向数据科学</a></p><p id="c11f" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">[15] <a class="ae jr" href="https://blog.usejournal.com/host-static-images-for-your-apps-or-website-on-google-drive-hotlink-to-gdrive-images-358d6fcf8ef7" rel="noopener ugc nofollow" target="_blank">在Google Drive上为您的应用程序或网站托管静态图像。(GDrive图片的热链接)|作者Pius Aboyi |值得注意的是——日志博客</a></p><p id="0e98" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">感谢您阅读我的博客，在此，我要感谢我在整个案例研究中的导师以及整个应用课程团队。</p><p id="65f4" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">所有代码的完整工作可以在我的Github个人资料中找到:</p><div class="ml mm ez fb mn mo"><a href="https://github.com/harsh-jadhav/SIIM-Pneumothorax-Case-Study2/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">哈什-贾达夫/SIIM-气胸-案例研究2</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">github.com</p></div></div><div class="mx l"><div class="pk l mz na nb mx nc jl mo"/></div></div></a></div><p id="71e2" class="pw-post-body-paragraph js jt hi ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在LinkedIn上联系我:</p><div class="ml mm ez fb mn mo"><a href="https://www.linkedin.com/in/harshwardhan-jadhav-a4a18682" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">印度马哈拉施特拉邦harshwardhan jad hav-Pune |职业简介| LinkedIn</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">查看Harshwardhan Jadhav在世界上最大的职业社区LinkedIn上的个人资料。Harshwardhan有一份工作…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.linkedin.com</p></div></div><div class="mx l"><div class="pl l mz na nb mx nc jl mo"/></div></div></a></div></div></div>    
</body>
</html>