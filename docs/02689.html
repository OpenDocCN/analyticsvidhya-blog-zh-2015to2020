<html>
<head>
<title>Machine Learning Dataset Tour (2): Boston Housing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习数据集之旅(2):波士顿住房</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-dataset-tour-2-boston-housing-d006834815c3?source=collection_archive---------23-----------------------#2019-12-28">https://medium.com/analytics-vidhya/machine-learning-dataset-tour-2-boston-housing-d006834815c3?source=collection_archive---------23-----------------------#2019-12-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/22f718b1551a008964e2fbbed6905275.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Hl1-s4FU0Z2KXczr"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">斯科特·韦伯在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="4b2c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇文章中，我将简要介绍波士顿住房数据集，并分享我的解决方案和一些解释。</p><blockquote class="jt ju jv"><p id="d41a" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">被困在付费墙后面？点击<a class="ae iu" rel="noopener" href="/analytics-vidhya/machine-learning-dataset-tour-2-boston-housing-d006834815c3?source=friends_link&amp;sk=1063ddeeeb5a1383e92a3cf782751067">此</a>即可通过！</p><p id="ba69" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated"><em class="hi">TL；DR:你可以在我的</em><a class="ae iu" href="https://github.com/Cuda-Chen/machine-learning-note/blob/master/boston-housing/boston_xgboost.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="hi">GitHub</em></a><em class="hi">上查看我的作品。</em></p></blockquote><h1 id="80ff" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">波士顿住房是什么？</h1><p id="7518" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">该数据集由美国人口普查局收集的马萨诸塞州波士顿地区的住房信息组成。</p><p id="2246" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面显示了数据集中每个变量(列)的含义:</p><figure class="le lf lg lh fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/ba3bc9e7f9a5f160a2104544fc538db5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WYEyESZ7_B3W7uetbGVIDQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">每个变量的描述</figcaption></figure><p id="c5e2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">更多详情可以访问这个<a class="ae iu" href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html" rel="noopener ugc nofollow" target="_blank">网站</a>。</p><h1 id="b647" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">目标和评估指标</h1><h2 id="a88b" class="li kb hi bd kc lj lk ll kg lm ln lo kk jg lp lq ko jk lr ls ks jo lt lu kw lv bi translated">目标</h2><ul class=""><li id="8b72" class="lw lx hi ix b iy ky jc kz jg ly jk lz jo ma js mb mc md me bi translated">预测<code class="du mf mg mh mi b">MEDV</code>的值</li></ul><h2 id="9f18" class="li kb hi bd kc lj lk ll kg lm ln lo kk jg lp lq ko jk lr ls ks jo lt lu kw lv bi translated">评估指标</h2><ul class=""><li id="30be" class="lw lx hi ix b iy ky jc kz jg ly jk lz jo ma js mb mc md me bi translated">RMSE，即</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/813e474f27191d5ad5ed37a8e5adf0f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*ayUi8JogLtoDx0YAEStKCQ.png"/></div></figure><h1 id="5815" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">我的解决方案</h1><ul class=""><li id="7c5b" class="lw lx hi ix b iy ky jc kz jg ly jk lz jo ma js mb mc md me bi translated">虽然基于决策树的模型在表格数据上表现出色，但我会选择线性回归模型进行实践。具体我根据sklearn的<a class="ae iu" href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" rel="noopener ugc nofollow" target="_blank">小抄</a>选择套索回归。</li><li id="9058" class="lw lx hi ix b iy mk jc ml jg mm jk mn jo mo js mb mc md me bi translated">我会在以后的日子里尝试线性回归，敬请期待！在以后的日子里，我还将演示如何使用更少的特性来产生类似的结果。</li><li id="060e" class="lw lx hi ix b iy mk jc ml jg mm jk mn jo mo js mb mc md me bi translated">因为没有任何空值，所以我们不需要填充或删除缺少的值。</li><li id="b6ae" class="lw lx hi ix b iy mk jc ml jg mm jk mn jo mo js mb mc md me bi translated">由于测试数据不包含基本事实，我们将使用交叉验证来训练模型。</li></ul><h1 id="98e5" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">逐步解释</h1><h2 id="f5a7" class="li kb hi bd kc lj lk ll kg lm ln lo kk jg lp lq ko jk lr ls ks jo lt lu kw lv bi translated">1.准备数据并做一些解释</h2><p id="4bbc" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">使用pandas的<code class="du mf mg mh mi b">info()</code>方法，我们发现所有的特征都是数字，所以不需要一键编码。</p><p id="8cd2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用熊猫的<code class="du mf mg mh mi b">isnull()</code>方法，我们认识到不存在任何空值，所以不需要填充空值。</p><h2 id="0c01" class="li kb hi bd kc lj lk ll kg lm ln lo kk jg lp lq ko jk lr ls ks jo lt lu kw lv bi translated">2.形象化</h2><p id="ae24" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我想找出每个特性和价格之间的关系，所以我画了一些图来形象化这种关系。</p><p id="b313" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为有很多情节，你可以在这里看到<a class="ae iu" href="https://github.com/Cuda-Chen/machine-learning-note/blob/master/boston-housing/boston_xgboost.ipynb" rel="noopener ugc nofollow" target="_blank">以清楚地查看结果。</a></p><h2 id="4506" class="li kb hi bd kc lj lk ll kg lm ln lo kk jg lp lq ko jk lr ls ks jo lt lu kw lv bi translated">3.检查特征重要性</h2><p id="6306" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">也许我们不需要把每个特性都放入模型，所以我用XGBoost来寻找特性重要性。<br/>许多基于决策树的模型具有发现特征重要性的能力，因为它们通过计算信息增益或基尼系数来分割数据。<br/>运行XGBoost回归器后，我们得到以下结果:</p><pre class="le lf lg lh fd mp mi mq mr aw ms bi"><span id="98ca" class="li kb hi mi b fi mt mu l mv mw">xgbr<strong class="mi hj">.</strong>get_booster()<strong class="mi hj">.</strong>get_score(importance_type<strong class="mi hj">=</strong>'gain')<br/><br/><em class="jw"># Out:<br/></em>{'LSTAT': 1170.5912806284505,<br/> 'RM': 407.86173977156585,<br/> 'NOX': 114.57274366695417,<br/> 'CRIM': 48.06237422548619,<br/> 'DIS': 65.78717631524752,<br/> 'PTRATIO': 109.93901440305558,<br/> 'AGE': 26.895764984946428,<br/> 'TAX': 56.70414882315789,<br/> 'B': 30.702484215217385,<br/> 'INDUS': 15.392935187827584,<br/> 'CHAS': 45.74311416166666,<br/> 'RAD': 18.774944386363632,<br/> 'ZN': 9.174343283333334}</span></pre><p id="8025" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以认识到最重要的三个特征:<code class="du mf mg mh mi b">LSTAT</code>、<code class="du mf mg mh mi b">RM</code>和<code class="du mf mg mh mi b">PTRATIO</code>。</p><h1 id="a548" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">4.建立模型</h1><p id="98c9" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">让我们用套索回归建立我们的模型！<br/>我用参数<code class="du mf mg mh mi b">alpha=0.1</code>创建模型对象:</p><pre class="le lf lg lh fd mp mi mq mr aw ms bi"><span id="d2e1" class="li kb hi mi b fi mt mu l mv mw">lasso <strong class="mi hj">=</strong> Lasso(alpha<strong class="mi hj">=</strong>0.1)</span></pre><p id="71c9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我还做了一个训练测试分割来训练模型，并使用分割的测试数据来产生预测。<br/>然后我们获得<code class="du mf mg mh mi b">RMSE</code>值的<code class="du mf mg mh mi b">4.48</code>。让我们试试交叉验证是否能提高性能。</p><p id="8473" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Scikit-learn提供了名为<code class="du mf mg mh mi b">LassoCV()</code>的Lasso回归和交叉验证。经过训练，我们得到<code class="du mf mg mh mi b">RMSE</code>值的<code class="du mf mg mh mi b">4.37</code>。嗯，价值降低了。</p><h2 id="1d38" class="li kb hi bd kc lj lk ll kg lm ln lo kk jg lp lq ko jk lr ls ks jo lt lu kw lv bi translated">5.产生竞争的结果</h2><p id="b150" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">让我们将结果更新到Kaggle，我们获得了<code class="du mf mg mh mi b">5.16976</code>的分数，在排行榜上排名第4。这里可以看到排行榜<a class="ae iu" href="https://www.kaggle.com/c/boston-housing-dataset/leaderboard" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="8b24" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">结论</h1><p id="cbc2" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">在这篇文章中，我简要介绍了著名的波士顿住房数据集，并演示了我的解决方案的步骤。此外，我展示了我们可以使用带交叉验证的Lasso回归，但是性能没有提升。<br/>下次巡演再见！</p><blockquote class="jt ju jv"><p id="03c3" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated"><em class="hi">您可以在我的</em><a class="ae iu" href="https://github.com/Cuda-Chen/machine-learning-note/blob/master/boston-housing/boston_xgboost.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="hi">GitHub</em></a><em class="hi">上查看我的作品。</em></p></blockquote></div><div class="ab cl mx my gp mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="hb hc hd he hf"><p id="33a5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">原载于2019年12月28日</em><a class="ae iu" href="https://cuda-chen.github.io/machine%20learning/2019/12/28/machine-learning-dataset-tour-2-boston-housing.html" rel="noopener ugc nofollow" target="_blank"><em class="jw">https://cuda-Chen . github . io</em></a><em class="jw">。</em></p></div><div class="ab cl mx my gp mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="hb hc hd he hf"><blockquote class="jt ju jv"><p id="da5e" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">如果你有任何想法和问题要分享，请联系我<a class="ae iu" href="http://clh960524@gmail.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj">clh 960524【at】Gmail . com</strong></a>。另外，你可以查看我的<a class="ae iu" href="https://github.com/Cuda-Chen" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中的其他作品。如果你和我一样对机器学习、图像处理和并行计算充满热情，欢迎在LinkedIn上加我。</p></blockquote></div></div>    
</body>
</html>