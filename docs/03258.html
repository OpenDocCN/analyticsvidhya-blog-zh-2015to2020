<html>
<head>
<title>Image Classification with Deep Learning: A theoretical introduction to machine learning and deep learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有深度学习的图像分类:机器学习和深度学习的理论介绍</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-classification-with-deep-learning-a-theoretical-introduction-to-machine-learning-and-deep-d118905c6d3a?source=collection_archive---------8-----------------------#2020-01-22">https://medium.com/analytics-vidhya/image-classification-with-deep-learning-a-theoretical-introduction-to-machine-learning-and-deep-d118905c6d3a?source=collection_archive---------8-----------------------#2020-01-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b69079024db7dfecf76ed4c5667a9133.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cqca3eXUpPxKL5CGkoIqXw.jpeg"/></div></div></figure><p id="7515" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">关于识别图像，人类通常能够容易地识别物体中的大量细节。多年来，我们训练我们的大脑来解释我们所看到的，从而下意识地形成我们的现实。</p><p id="d341" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">随着先进技术成为我们生活中不可替代的元素，人工智能等突破性技术的出现为不同的领域和用例提供了巨大的潜力。</strong></p><p id="0545" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">特别是，卷积神经网络(CNN)，一种深度神经网络被应用于分析图像。让计算机视觉成为可能，或者换句话说，增强机器像人类一样看待世界，不再是未来的愿景。</strong></p><p id="1884" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">在这篇文章中，你将获得机器学习和深度学习的简短理论介绍，并更好地理解利用深度学习对图像进行分类。</strong></p></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><h1 id="a26b" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">内容</strong></h1><p id="d41b" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">1.AI、机器学习和深度学习的区别<br/> 2。机器学习理论介绍<br/> 2.1关键术语<br/> 2.2基本概念<br/> 3。深度学习:神经网络<br/> 3.1感知器<br/> 3.2 Sigmoid神经元<br/> 3.3神经网络的架构<br/> 4 .深度学习:用卷积神经网络进行图像分类</p></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><p id="d874" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 1。AI、机器学习和深度学习的区别</strong></p><p id="3949" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了理解深度学习的概念，将它置于人工智能和机器学习的背景中是至关重要的。在计算机科学中，人工智能(AI)是一个广义的术语，用于描述机器显示的智能。这种描绘的特点是模仿自然的人类智能，如学习或解决问题(Russell and Norvig，2003)。机器学习是计算机直接从数据中“学习”的能力，就像人类和动物从现实生活经验中学习一样。一个重要的方面是，所使用的算法不依赖于预定的方程，而是自适应地发展其性能(MathWorks Inc .，2016)。而且，深度学习是机器学习和所谓的神经网络训练的结合，这将在后续章节中解释(Burkov，2019)。事先，必须解释相关的机器学习术语和概念。</p><p id="050a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2。机器学习理论介绍</strong></p><p id="28ce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2。1关键术语</strong></p><p id="de20" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">简而言之，构建的机器学习系统学习如何组合输入因素，以根据之前未见过的数据生成预测。当系统或模型被训练时，标签被提供。标签是要预测的变量y。从案例模型的角度来看，电子邮件被分为垃圾邮件和非垃圾邮件。这里“垃圾邮件”和“非垃圾邮件”代表标签。</p><p id="2619" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">考虑到这一点，特征是描述数据的输入变量，例如电子邮件中的单词、电子邮件地址和任何类型的其他相关信息。一个例子是作为电子邮件的一段数据。这可能是用于训练模型的已标记示例，也可能是用于对新数据进行预测的未标记示例。</p><p id="36b8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，强调回归和分类之间的区别是很重要的。回归模型预测连续值，如某事物的值或概率。然而，分类模型预测离散值，并将解释图像中是否有猫、狗或仓鼠(谷歌开发者，框架:关键ML术语，2019年)</p><p id="fff5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3。2基本概念</strong></p><p id="bc65" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">线性回归</p><p id="cf57" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如前所述，回归可以预测给定输入集下的输出概率。这是通过猜测变量之间的线性关系实现的。下表显示了以平方米为单位的海洋面积以及每片海洋中相应的鱼类数量。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/97f9e3faec4d33d760bc0395678e16a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6katV1QBMJXAOkUSQEMOCw.png"/></div></div></figure><p id="e6c0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据可以通过绘制图表来检查。这种简单的线性关系可以通过给定数据拟合一条线来显示。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/ff5469d396d939a94bdac6700a7ebe84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NxCbMVgNt1v7DY2MTXUTOw.png"/></div></div></figure><p id="2a44" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种关系由以下等式描述(麻省理工学院-麻省理工学院，n. D .):</p><p id="2094" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">y = b + mx</p><p id="4562" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这种情况下，</p><ul class=""><li id="c86e" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">y是因变量，它是我们试图预测的值(鱼的数量)，</li><li id="0ec8" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">x是独立变量，它是我们输入特征的值(海洋的大小)，</li><li id="918f" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">m是斜率，并且</li><li id="b671" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">线的截距(麻省理工学院-麻省理工学院，未注明)。</li></ul><p id="2b70" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">训练和损失</strong></p><p id="80f3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是如何知道创造出来的线可以被认为是“好”还是“坏”？在这种背景下，就涉及到了损失的概念。损失表明模型在预测结果方面做得有多好。损耗可以定义为示例中预测值和真实值之间的差异。在一个完美的预测中，损失的数量等于零。单次观测的等式称为平方损失或L2损失:</p><p id="5156" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">标注和预测之间的差值的平方=(观察值-预测值(x))</p><p id="6583" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">=(y—y’)</p><p id="de2e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了将这个概念扩展到整个数据集，使用了所谓的均方误差(MSE)方程:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/8a9c62640a26c659d291a54f74a17ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wXYKxA4qnlErSog6cJT7VQ.png"/></div></div></figure><p id="e6d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，所有平方损失的总和除以示例的数量。</p><p id="f4e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，这也是培训变得相关的地方。训练描述了使用训练数据逐步提高模型预测结果的能力的过程。在实践中，机器学习算法通过检查几个带标签的例子来建立一个系统，以找到一个使损失最小化的模型(Google Developers，Descending into ML:Training and Loss，2019)。</p><p id="457a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">逻辑回归</strong></p><p id="fc05" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果人们感兴趣的不是预测海洋中的鱼的数量，而是预测水体是淡水还是咸水，会怎么样？对于分类问题类型，逻辑回归开始起作用。这种分类学习算法可以是二进制的，也可以是多类的。不是预测一个值，而是预测一个发生的概率。为此，有必要从可能在负无穷大和正无穷大之间的输出转换到0和1之间的输出。在这种情况下，模型为输入x返回的更接近0的值将被指定为负值，而更接近1的值将被指定为正值(Burkov，2019，S. 32)。符合这一确切目的的函数是sigmoid函数:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/48f0f6e2b00d3be7da23e00ead7cfb7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZWxVaz1Ubet1Kb-eTgIlbw.png"/></div></div></figure><p id="2c94" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 4。深度学习:神经网络</strong></p><p id="d84f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随着复杂性的增加以及从线性问题向非线性问题的转变，以前的概念很快就遇到了它们的极限。深度学习，一类神经网络优化提供了一个解决方案。</p><p id="865c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 4。1感知器</strong></p><p id="60af" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了理解神经网络背后的概念，从感知器开始是至关重要的。</p><p id="9eb2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个人工神经元保存几个输入(xj)并产生一个二进制输出。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/25867704a5b19652cd1b7c00b3e379cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nU02Rp4imwvPF1AMkSwsHw.png"/></div></div></figure><p id="16f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">向输入提供权重(wj ),并且确定0或1的输出是权重之和大于还是小于阈值。</p><p id="5568" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将许多感知器组合成一个网络，使得更微妙的决策成为可能。第一层感知器基于加权做出三个基本决策，而第二层感知器根据第一层的结果做出决策。网络的层数越多，可以做出的选择就越复杂。尽管如此，还是只有一个输出。</p><p id="ff1a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于从单个感知器到整个网络的转变，数学描述也从两个方面发生了变化。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/16e086782f27d4d9f5de04b33af786e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aHpczZapx8mQaZHi09HobQ.png"/></div></div></figure><p id="541d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，∑j wjxj成为以w和x为向量，以权重和输入为元素的乘积w * x。而且，阈值移动到不等式的另一边，成为所谓的感知机偏差b≦-阈值。偏差可以理解为感知机获得输出1的难易程度的值(Nielsen，2018，s . 2–4)。</p><p id="2b31" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 4。2个乙状结肠神经元</strong></p><p id="2bff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这一点上，人工神经元网络仅仅是作为实现布尔函数的逻辑门运行，而没有任何学习视角。在这种情况下，学习将等于对权重或偏差进行最小的修改，以获得输出中最小的相应变化，直到设计的模型完全按照预期的方式运行。一个特别的困难是感知器的特性，它通过最小的调整就能使整个网络发生根本的变化。这个问题是由所谓的sigmoid神经元来解决的，它的行为类似于感知器。乙状结肠神经元的优势在于，权重和偏差的变化仅引起输出的微小变化。</p><p id="855c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">sigmoid神经元的输入值能够具有0和1之间的每个值，这是由于已经熟悉的sigmoid函数的特征(Nielsen，2018，s . 7–8)。</p><p id="da78" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 4。3神经网络的架构</strong></p><p id="d4a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下图显示了神经网络体系结构的标准描述。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/43d97141d824cd3b0cadc1c88a6645c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wR77ePpzOYtK-oFAAXsskA.png"/></div></div></figure><p id="4e3a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最左边的层称为输入层及其输入神经元。最右边是输出层，仍然包含单个输出神经元。一个新的元素是隐藏层，它在数量上是可变的。隐藏层简单定义为“不是输入也不是输出”。它的任务是将输入转换成输出层可用的形式。</p><p id="8727" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">神经网络的方法可以用一个例子来说明。如果神经网络应该确定手写图像是否是数字“9 ”,那么每个图像像素的亮度起着主要作用。在一个64乘64的灰度图像中，4 096个输入神经元将灰度强度保持在0和1之间。最后，神经网络的输出值表明，如果该值低于0.5，则输入图像不是9；如果该值高于0.5，则输入图像是9(Nielsen，2018，s . 10–12)。</p><p id="026d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 5。深度学习:卷积神经网络</strong></p><p id="82c0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在图像分类的背景下，依赖于经典的神经网络结构是无益的。这是因为它们没有考虑到图像的空间结构。因此，离得远和离得近的输入像素被视为相同。这就是为什么使用一种利用空间结构的架构:卷积神经网络(CNN) (Nielsen，2018，S. 169)。</p><p id="2573" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">CNN用于逐步提取输入图像的更高级表示。它获得每一层的抽象特征。例如，物体的边缘可能首先被识别，然后是更基本的形状，最后是更高级的特征，如面部(Albawi，Mohammed &amp; Alzawi，2017)。</p><p id="6dae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该模型不再对给定的数据进行预处理以生成形状和纹理等特征。相反，CNN处理图像的像素数据，并学习推导这些特征(谷歌开发者，ML Practicum:图像分类，2019)。</p><p id="2cc7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">虽然神经网络的输入层显示为神经元的垂直线，但卷积神经网络的输入是神经元的正方形:输入特征图。和以前一样，输入像素连接到一个隐藏层。这次实现了输入图像的小局部区域的连接。</p><p id="cec4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">CNN提取输入特征地图的分块，并对其应用过滤器以生成新特征，从而产生输出特征地图。</p><p id="74ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在卷积过程中，过滤器滑过输入特征地图以提取相应的图块。在本例中，有一个输入要素地图和一个具有给定值的卷积过滤器。过滤器被应用于输入要素地图，这导致过滤器的值与输入要素的值相乘。然后，将结果求和为输出特征图的单个值。(尼尔森，2018，S. 170谷歌开发者，ML实习:图像分类，2019)。</p><p id="5bf7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae lx" href="https://www.youtube.com/watch?v=YRhxdVk_sIs&amp;t=339s" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=YRhxdVk_sIs&amp;t = 339s</a></p><p id="c798" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面的例子说明了这种方法。左边的对象是7的图像表示，以及将通过具有单个过滤器的卷积层运行的输入特征地图。这个矩阵的值是图像中的单个像素。中间的物体是带有随机数的过滤器。过滤器从左上角开始，落在输入的第一个3×3像素块上。这两个元素的点积将针对输入要素地图的每个3乘3块进行存储，以将其存储在输出要素地图的相应站点上(deeplizard，2017)。可以在YouTube上随意观看deeplizard的“<a class="ae lx" href="https://www.youtube.com/watch?v=YRhxdVk_sIs&amp;t=339s" rel="noopener ugc nofollow" target="_blank">卷积神经网络(CNN)解释的</a>视频:<a class="ae lx" href="https://www.youtube.com/watch?v=YRhxdVk_sIs&amp;t=339s" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=YRhxdVk_sIs&amp;t = 339s</a></p><p id="39c4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">虽然这仍然是一个基本的例子，但CNN能够很容易地以高达90 %的准确率对物体、动物、人类、植物或截图的图像进行分类。CNN用例的突出例子是脸书的照片标签系统，虚拟助手，如Siri、聊天机器人和物体识别相机(Mhalagi，n. D .)。</p></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><p id="a46b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">参考文献</strong></p><p id="114e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">阿尔巴维，s .，穆罕默德，t .，阿尔扎维，S. (2017)。<em class="ly">对卷积神经网络的理解。</em>迪亚拉/基尔库克:迪亚拉大学/基尔库克大学。DOI:10.1109/icengtechnol . 17863863867</p><p id="e3b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">布尔科夫，A. (2019)。<em class="ly">机器学习的合页书。</em>可在:<a class="ae lx" href="https://file.ai100.com.cn/files/file-code/original/cd136ebe-0e34-4e43-966b-224acff83005/100MLBOOK/The+Hundred-Page+Machine+Learning+Book.pdf" rel="noopener ugc nofollow" target="_blank">https://file . ai 100 . com . cn/files/file-code/original/CD 136 ebe-0e 34-4e 43-966 b-224 acff 83005/100 mlbook/The+bai百页+Machine+Learning+book . pdf</a>(28 . 09 . 2019)。</p><p id="88f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">深海蜥蜴。(2017年12月9日)。<em class="ly">卷积神经网络(CNN)解释。</em>可在:<a class="ae lx" href="https://www.youtube.com/watch?v=YRhxdVk_sIs" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=YRhxdVk_sIs</a>(05 . 10 . 2019)。</p><p id="2d92" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">德拉科斯，G. (2018)。<em class="ly">如何为机器学习模型选择正确的评估指标:第1部分回归指标。</em>可从以下网址获得:<a class="ae lx" href="https://towardsdatascience.com/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-1-regrression-metrics-3606e25beae0" rel="noopener" target="_blank">https://towards data science . com/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-1-regr regression-metrics-3606 e 25 beae 0</a>(01 . 10 . 2019)。</p><p id="ee1b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谷歌开发者。(2019).<em class="ly">降入ML:训练与损耗|机器学习速成班。</em>可在:<a class="ae lx" href="https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/crash-course/descending-into-ml/training-and-loss</a>(01 . 10 . 2019)。</p><p id="e27e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谷歌开发者。(2019).<em class="ly">框架:关键ML术语|机器学习速成班</em>。可在:<a class="ae lx" href="https://developers.google.com/machine-learning/crash-course/framing/ml-terminology" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/crash-course/framing/ml-terminals</a>(31 . 09 . 2019)查阅。</p><p id="1c83" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谷歌开发者。(2019).<em class="ly"> ML实习:图像分类。</em>可从以下网址获得:<a class="ae lx" href="https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/practica/image-class ification/convolutionary-neural-networks</a>(03 . 10 . 2019)。</p><p id="9592" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">MathWorks Inc. (2016)。<em class="ly">引入机器学习。</em>可在:<a class="ae lx" href="https://www.mathworks.com/content/dam/mathworks/tag-team/Objects/i/88174_92991v00_machine_learning_section1_ebook.pdf" rel="noopener ugc nofollow" target="_blank">https://www . mathworks . com/content/dam/mathworks/tag-team/Objects/I/88174 _ 92991 v00 _ machine _ learning _ section 1 _ ebook . pdf</a>(25 . 09 . 2019)。</p><p id="2b3f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Mhalagi，s .(未注明)<em class="ly">对CNN模型更高精确度的探索。</em>可在:<a class="ae lx" href="https://towardsdatascience.com/the-quest-of-higher-accuracy-for-cnn-models-42df5d731faf" rel="noopener" target="_blank">https://towardsdatascience . com/the-quest-of-higher-accuracy-for-CNN-models-42 df5d 731 faf</a>(06 . 10 . 2019)。</p><p id="51dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">麻省理工学院。(未注明)。<em class="ly">第3章—线性回归</em>。可在:<a class="ae lx" href="http://www.mit.edu/~6.s085/notes/lecture3.pdf" rel="noopener ugc nofollow" target="_blank">www.mit.edu/~6.s085/notes/lecture3.pdf</a>(01 . 10 . 2019)。</p><p id="3800" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">尼尔森，M. (2018)。<em class="ly">神经网络和深度学习。</em>可在:<a class="ae lx" href="http://static.latexstudio.net/article/2018/0912/neuralnetworksanddeeplearning.pdf" rel="noopener ugc nofollow" target="_blank">http://static . latex studio . net/article/2018/0912/neuralnetworksanddeeplearning . pdf</a>(03 . 10 . 2019)。</p><p id="b9f1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Russell s .和nor vig p .(2003年)。<em class="ly">人工智能</em>(第二版。).新耶尔西:普伦蒂斯霍尔。</p></div></div>    
</body>
</html>