<html>
<head>
<title>Data Streams and Online Machine Learning in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Data Streams and Online Machine Learning in Python</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-streams-and-online-machine-learning-in-python-a382e9e8d06a?source=collection_archive---------0-----------------------#2019-01-19">https://medium.com/analytics-vidhya/data-streams-and-online-machine-learning-in-python-a382e9e8d06a?source=collection_archive---------0-----------------------#2019-01-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9f57720d84f6d0b1633e8e2d62285752.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1LI9TzwDU1l6IyJFBRcULw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Photo by <a class="ae iu" href="https://unsplash.com/photos/1K6IQsQbizI?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Franki Chamaki</a> on <a class="ae iu" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f986" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated"><span class="l ju jv jw bm jx jy jz ka kb di">D</span>ata has become more than a set of binary digits in everyone’s day-to-day decision-making processes.</p><p id="b529" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">The power of data and the insights derived from it was once limited to large business corporations. <strong class="ix hj">Now, the power of data is available to anyone who is willing to trade their data for a piece of information</strong> (example: one has to turn on the location sensor in the mobile phone to share his/her location data to find the minimal traffic route to a destination).</p><p id="cfbb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Data generation has seen exponential growth in the last decade along with the growth in infrastructure to handle it. Every application in our smartphone generates tons of data.</p><p id="f150" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">IoT (Internet of things) generates data every second about a state of a mechanical device, Server and application logs along with actual user interaction events like clicks and transaction data only grows over time as the user base grows for the application.</p><blockquote class="kc kd ke"><p id="02da" class="iv iw kf ix b iy iz ja jb jc jd je jf kg jh ji jj kh jl jm jn ki jp jq jr js hb bi translated"><strong class="ix hj">In 2018 for a single minute in a day</strong> — YouTube users watched 4.3 million videos, Amazon shipped 1,111 packages, Twitter had close to half a million tweets, Instagram inducted 50 thousand photos, Google performed 3.8 million searches, and Reddit received 1,944 user comments. An estimate quotes that by 2020 for every person on earth, 1.7 MB of data will be generated for every second.</p></blockquote><p id="19c9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">It was in 2005, Roger Mougalas from O’Reilly Media coined Big Data as a term.</strong> It was used to denote the large amount of data which cannot be managed by the traditional business intelligence tools or data processing applications (mainstream relational). It was in the same year Yahoo! built Hadoop on top of Google’s MapReduce with an objective of indexing the entire world wide web. The core concept of distributed computing and the key-value pair data representation (instead of the tabular data representation) has been adopted by most of the new age data integration and business intelligence tools over time.</p><p id="c625" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Any organization which has to deal with massive amount of data (structured, semi-structured, and unstructured) for their business development must have crossed path with one of the tools which had its roots in Hadoop core concepts.</p><p id="fed0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Big Data is an evolving term. It currently describes the large volume of structured or unstructured data that has the potential to be analyzed by various machine learning algorithms for patterns/insights. <br/>Big Data is characterized by</p><ul class=""><li id="6ac2" class="kj kk hi ix b iy iz jc jd jg kl jk km jo kn js ko kp kq kr bi translated"><strong class="ix hj">卷</strong>(数据的大小)</li><li id="9a39" class="kj kk hi ix b iy ks jc kt jg ku jk kv jo kw js ko kp kq kr bi translated"><strong class="ix hj">速度</strong>(数据通过数据管道生成或共享的速度。即气候或交通相关数据必须是实时的，没有延迟)</li><li id="0f07" class="kj kk hi ix b iy ks jc kt jg ku jk kv jo kw js ko kp kq kr bi translated"><strong class="ix hj">品种</strong>(数据不符合a表示布局。即，关系数据库期望所述布局中的数据输入，但是不能与具有变化的布局结构的输入数据文件一起工作)</li></ul><p id="9e1d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">无限量的云存储可用于应对海量数据，自然语言处理和自然语言理解的结合使得与NoSQL数据库一起应对数据变化并存储数据成为可能。<strong class="ix hj">在本文中，我们将重点关注大数据的速度属性——如何在python中处理数据流，以及如何使用python中的在线学习技术来训练机器学习模型，以适应传入的数据流。</strong></p><p id="f95e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">传统的机器学习过程将从静态输入数据文件开始。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/49984fd41fc65ca7c8fd8ce58424f0f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*93o11f72wcYoTLmlHCE_Mg.png"/></div></div></figure><p id="e18a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们来看一个有监督的学习过程。<strong class="ix hj">该流程从接收一个带有标签的静态数据文件作为输入文件</strong>开始，执行探索性数据分析，缩放并执行特征工程，将数据记录分成训练、测试和验证集。使用训练数据记录来训练模型，使用测试数据记录来微调模型参数，并且基于验证数据记录上的性能度量来执行模型选择。然后将训练有素的模型部署到生产中，对未知数据记录进行预测/分类。<strong class="ix hj">模型局限于在静态输入文件中观察到的模式，不能适应实时的行为变化。</strong>每次有新的训练数据可用时，训练模型的整个过程都要从头开始。训练一个完整的模型可能是一个耗费资源和时间的过程，这是业务应用程序所不能承受的。</p><p id="e756" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在线学习可以在更大程度上解决这个问题。训练数据越多，新记录集的模型性能越好</p><blockquote class="kc kd ke"><p id="6d1b" class="iv iw kf ix b iy iz ja jb jc jd je jf kg jh ji jj kh jl jm jn ki jp jq jr js hb bi translated"><strong class="ix hj">“不是谁的算法最好谁就赢；而是谁拥有的数据最多。”</strong>作者吴恩达。</p></blockquote><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/4e33b0fad1208a7c0f71234e78c6daac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eSSU6uX7NR5kPK7ZbfnnVw.png"/></div></div></figure><p id="85b3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">增量/在线学习算法是基于给定的训练数据流<em class="kf"> t0，T1，t2，…生成模型的算法。，tn </em>一系列模型<em class="kf"> f0，f1，…，fn </em>增量训练。ti被标记为训练数据<em class="kf"> ti = (xi，易)</em>和<strong class="ix hj"> <em class="kf"> fi </em>是依赖于来自<em class="kf"> f(i-1) </em>的参数和来自数据段ti的最近参数更新的模型。</strong></p><p id="6720" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">换句话说，在线训练算法可以获取新的输入数据记录，并从中无缝学习，而无需从头开始经历整个训练过程。在线培训在以下情况下很有帮助。</p><p id="7118" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1.其中模型训练和适应必须在设备上发生，并且训练数据太敏感(由于数据隐私)以至于不能移动到离线环境。即像智能手表和应用程序这样的健康设备。没有一个单一的通用模型可以处理所有可能的用户行为</p><p id="5176" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.其中由于网络流量/障碍，新的训练数据不能转移到离线过程环境，或者设备必须完全在离线模式下工作。也就是说，引导海上运输船只的导航系统可能没有稳定的网络连接来将数据从其物联网设备加载到家庭办公室</p><p id="2d95" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.庞大的训练数据集，在给定的时间点无法放入单台机器的内存中</p><p id="bc9e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4.在所有设备上重新培训和分发新型号可能是一项昂贵的工作</p><p id="8e07" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们稍微转移一下话题来理解什么是数据流，看看卡夫卡的简要概述。</p><p id="3141" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据流是指当事件发生时，数据立即可用的地方。可以是实时，也可以是近实时。不是收集和存储来自事件的数据，然后将文件发送给应用程序，而是当事件发生时，数据可供应用程序使用。也就是说，信用卡交易必须是即时的——可用信用必须在交易后立即更新。它不能等待隔夜批次重新运行，因为向消费者显示的可用信用可能不准确，并由于交易重复而导致许多混乱。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/0287bf00601abb5de7cc21c19aa1fb94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OeQDd5-tLEqnYoLGXyUm0A.png"/></div></div></figure><p id="874f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> Kafka是一个分布式发布-订阅消息系统</strong>(在Linkedin孵化)。它用于处理高吞吐量的消息传递应用程序，如网页点击、日志聚合和流处理。卡夫卡中的三个重要关键词将是生产者(出版商)、消费者(订户)和主题。<strong class="ix hj">这个系统相当于一个无限长的磁带卷轴。一个应用程序可以在事件发生时实时写入Kafka(将消息发布到流)，另一个应用程序可以从给定的偏移量读取磁带(使用流中的消息)。</strong></p><p id="91d7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">多个数据流可以共存于Kafka消息传递环境中，它们通过各自的主题名称相互区分。即Youtube将是最好的例子。观众可以订阅一个频道(主题)。频道所有者(制作者)可以向频道推送新内容(事件)。订户(消费者)接收新内容的通知。频道所有者可以运行多个频道。一个频道可以有很多订户。订户可以订阅各种频道。</p><p id="4c65" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">RabbitMQ、谷歌PubSub、亚马逊Kinesis Stream、Wallaroo和Redis Streams是卡夫卡的几个替代品。在任何分布式系统中，都必须有一个进程负责任务协调、状态管理和配置管理，Kafka依靠zookeeper来执行这些必要的任务。从https://kafka.apache.org/downloads<a class="ae iu" href="https://kafka.apache.org/downloads" rel="noopener ugc nofollow" target="_blank">下载Kafka tgz文件并解压到一个文件夹中。</a></p><p id="ce3d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">移动到提取的Kafka文件夹后，运行以下两个命令(在两个单独的命令窗口或终端中运行)</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="ca1a" class="lh li hi ld b fi lj lk l ll lm">bin/zookeeper-server-start.sh config/zookeeper.properties<br/>bin/kafka-server-start.sh config/server.properties</span></pre><p id="6641" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在zookeeper和Kafka服务器都已启动并运行，我们需要一种通过python连接Kafka服务器的方法。我们将使用Kafka-python包。运行以下命令来安装该软件包</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="94f4" class="lh li hi ld b fi lj lk l ll lm">pip install kafka-python</span></pre><p id="2bed" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">软件包安装完成后，从Github下载代码</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="d41c" class="lh li hi ld b fi lj lk l ll lm">01.Blog_04_KafkaProducer_Code_V1.0.py<br/>01.Blog_04_KafkaConsumer_Code_V2.0.py</span></pre><p id="e49f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">生产者代码是生成点击流分类数据(十个因变量和一个目标变量)并将数据段发布到消息代理中的特定主题的代码。</p><p id="11dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在代码中，确保更新Kafka文件夹路径变量并安装像sklearn这样的依赖项。</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="d3b8" class="lh li hi ld b fi lj lk l ll lm">def create_topic(logger=None, kafka_path=None, topic=None):</span><span id="f9b2" class="lh li hi ld b fi ln lk l ll lm">     ‘’’ Routine will create a new topic; assuming delete_all_topics<br/>         will run before this routine ‘’’;<br/>     <br/>     cmd_string = f’{kafka_path}bin/kafka-topics.sh — create —  <br/>                    zookeeper localhost:2181 — replication-factor 1 <br/>                    — partitions 1 — topic {topic.lower()}’;</span><span id="e63a" class="lh li hi ld b fi ln lk l ll lm">     cmd_status = subprocess.check_output(cmd_string, <br/>                   stderr=subprocess.STDOUT, shell=True);</span><span id="be14" class="lh li hi ld b fi ln lk l ll lm">     cmd_output = cmd_status.decode(‘utf-8’).split(‘\n’)[0];<br/>     <br/>     logger.info(f’’);<br/>     logger.info(f’{cmd_output}’);<br/>     logger.info(f’’);</span><span id="f25e" class="lh li hi ld b fi ln lk l ll lm">return None;</span></pre><p id="05de" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的函数将kafka_path和topic_name作为输入，并在kafka系统中创建一个主题。子流程模块用于在命令行中提交命令并返回响应。代码还会在创建主题之前检查活动的zookeeper进程是否可用。</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="06c2" class="lh li hi ld b fi lj lk l ll lm">def run_producer(logger=None, topic=None):</span><span id="4944" class="lh li hi ld b fi ln lk l ll lm">    ''' Run a producer to put messages into a topic ''';</span><span id="f910" class="lh li hi ld b fi ln lk l ll lm">    # The function simulates the clickstream data with pass through<br/>    # X0 - X9   : (Dependent) Numerical features which detail the<br/>                   attributes of an advertisement<br/>    # y         : (Target) Whether the advertisement resulted in a<br/>                   user click or not<br/>    # for every instance a random choice is made to generate the<br/>                   number of records</span><span id="8fab" class="lh li hi ld b fi ln lk l ll lm">    producer = KafkaProducer(bootstrap_servers=['localhost:9092'], <br/>               value_serializer=lambda x: dumps(x).encode('utf-8'));</span><span id="b1d6" class="lh li hi ld b fi ln lk l ll lm">    logger.info(f'Publishing messages to the topic : {topic}');</span><span id="70c4" class="lh li hi ld b fi ln lk l ll lm">    random_choice_seq = [ i for i in range(100,110) ];</span><span id="e856" class="lh li hi ld b fi ln lk l ll lm">    record_count = 0;</span><span id="3edd" class="lh li hi ld b fi ln lk l ll lm">    for i in range(10000):<br/>        number_of_records = random.choice(random_choice_seq);<br/>        record_count += number_of_records;<br/>        X, y = generate_sample(logger=logger, <br/>                number_of_records=number_of_records);</span><span id="39b2" class="lh li hi ld b fi ln lk l ll lm">        if i == 0 :<br/>            X_scalar = MinMaxScaler();<br/>            X_scalar.fit(X);<br/>            X = X_scalar.transform(X);<br/>        else:<br/>            X = X_scalar.transform(X);</span><span id="15e5" class="lh li hi ld b fi ln lk l ll lm">        data = {'X' : X.tolist(), 'y' : y.tolist()};<br/><br/>        producer.send(f'{topic}', value=data);<br/>        <br/>        sleep(0.05);<br/>     <br/>    logger.info(f'Closing producer process; <br/>                  Total records generated is <br/>                  {format(record_count, "09,")}');</span><span id="0140" class="lh li hi ld b fi ln lk l ll lm">    return None;</span></pre><p id="11d9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">KafkaProducer函数用于连接运行在端口号9092上的Kafka服务器，并向特定主题发布消息。在上面的函数中，我们使用scikit-learn toy数据生成模块为分类问题生成数据样本。我们将发布近1万条消息，每条消息中有100到110条数据记录。在过程代码的末尾，流将有大约1M的数据记录和10，000条消息。</p><p id="deec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">查看下面的博文，了解更多关于scikit-learn模块和用于构建基本机器学习流程管道的一系列函数的信息</p><div class="lo lp ez fb lq lr"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/scikit-learn-a-silver-bullet-for-basic-machine-learning-13c7d8b248ee"><div class="ls ab dw"><div class="lt ab lu cl cj lv"><h2 class="bd hj fi z dy lw ea eb lx ed ef hh bi translated">Scikit-Learn:基础机器学习的银弹</h2><div class="ly l"><h3 class="bd b fi z dy lw ea eb lx ed ef dx translated">Scikit-Learn是python的核心机器学习包，拥有大多数必要的模块来支持基本的…</h3></div><div class="lz l"><p class="bd b fp z dy lw ea eb lx ed ef dx translated">medium.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf io lr"/></div></div></a></div><p id="0c45" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">等待生产者代码完成，因为消费者代码使用消息偏移量来关闭训练循环。</p><p id="2a27" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">消费者代码包含从主题开始直到最后一条发布的消息消费消息的模块。</strong>(在提交消费者代码之前，必须执行并完成生产者代码，否则消费者将无法阅读整个主题。它可能仅读取部分消息集)以及在线模型训练</p><p id="80c4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">回到在线学习，我们需要一种学习算法，它可以获取一组新的数据记录，并更新已训练的模型参数，以提高模型性能指标。</p><p id="9002" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1.Scikit-learn包含几个具有parital_fit方法的分类器模型。parital_fit允许将训练模型拟合到新数据的较小子集，而不是整个训练数据集</p><p id="a1fe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.热启动一个神经网络。对于新的训练迭代，权重可以来自先前训练的模型。TensorFlow有检查点来处理这种情况</p><p id="9a90" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.贝叶斯方法将非常适合在线学习，因为关于参数分布的信念随着新的训练数据记录的出现而更新</p><p id="f93a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">我们将使用Scikit-learn SGD class ifier进行部分拟合。</strong></p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/dcaa9eda3f9a16500e8cbe6f635b6cfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jOFTZw6e3AmkyVMzEPO7iA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd mg">红色条带线为批量学习，蓝色条带线为随机梯度下降；SGD可能会左右摇摆，但最终会达到全局最小值</strong></figcaption></figure><p id="e3fa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于SGD的成本函数是凸的，因此可以使用梯度来达到全局最小值。与较小的输入数据记录集相比，完整的批量训练可能平滑地达到全局最小值，而较小的输入数据记录集将错开并最终收敛到全局最小值。</p><p id="b21a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">基于来自新的训练数据集的梯度以及控制学习速率的α(来自新的训练集的多少信息应该用于影响训练的模型参数)来更新模型参数</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="a78e" class="lh li hi ld b fi lj lk l ll lm">def initial_model(logger=None):<br/>    <br/>        ''' Simulation of the initial model setup in a traditional <br/>            ML training ''';</span><span id="28e5" class="lh li hi ld b fi ln lk l ll lm">        clf = SGDClassifier(<br/>   <br/>              loss='log', <br/>              # log as a loss gives the logistic regression<br/>              penalty='none', <br/>              # l2 as a default for the linear SVM;<br/>              fit_intercept=True, <br/>              shuffle=True, <br/>              # shuffle after each epoch<br/>              eta0=0.001,<br/>              learning_rate='constant',<br/>              average=False, <br/>              # computes the averaged SGD weights <br/>              random_state=1623,<br/>              verbose=0,<br/>              max_iter=1000,<br/>              warm_start=False<br/>            );</span><span id="1895" class="lh li hi ld b fi ln lk l ll lm">        return clf;</span></pre><p id="fe0f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">消费者代码将使用KafkaConsumer连接到一个活动的Kafka服务器，并从主题管道的开头开始消费消息。</strong>numpy数据元素是不可序列化的，所以它在生产者代码中被转换成python列表，并被转储到JSON中。消费者将颠倒该过程来取回numpy数组。scikit-learn parital_fit方法可以很好地处理numpy数组/pandas数据对象。</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="1602" class="lh li hi ld b fi lj lk l ll lm">consumer = KafkaConsumer(<br/>               topic_name,<br/>               bootstrap_servers=['localhost:9092'],<br/>               auto_offset_reset='earliest',<br/>               enable_auto_commit=True,<br/>               value_deserializer=lambda x: loads(x.decode('utf-8'))<br/>               );</span></pre><p id="c25b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于第一次迭代，模型使用来自消息的全部数据记录进行训练和测试。从第二次迭代开始，只有当模型性能提高时，我们才会进行拟合。</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="6cae" class="lh li hi ld b fi lj lk l ll lm">if counter == 1:</span><span id="10b4" class="lh li hi ld b fi ln lk l ll lm">            clf.partial_fit(X_train, y_train, classes=[0,1]);<br/>            y_test_predict = clf.predict(X_test);</span><span id="14f3" class="lh li hi ld b fi ln lk l ll lm">            clf_log_loss = log_loss(y_test, y_test_predict, <br/>                           labels=[0,1]);<br/>            clf_acc_score = accuracy_score(y_test, y_test_predict);<br/>            clf_f1_score = f1_score(y_test, y_test_predict);</span><span id="ade8" class="lh li hi ld b fi ln lk l ll lm">            row_list.append(selected_models);<br/>            ll_list.append(clf_log_loss);<br/>            accuracy_list.append(clf_acc_score);<br/>            f1_list.append(clf_f1_score);</span><span id="fec1" class="lh li hi ld b fi ln lk l ll lm">else:</span><span id="7e53" class="lh li hi ld b fi ln lk l ll lm">            clf_temp = clf;</span><span id="b916" class="lh li hi ld b fi ln lk l ll lm">            clf_temp.partial_fit(X_train, y_train, classes=[0,1]);<br/>            y_test_predict = clf_temp.predict(X_test);</span><span id="0d70" class="lh li hi ld b fi ln lk l ll lm">            clf_log_loss = log_loss(y_test, y_test_predict, <br/>                           labels=[0,1]);<br/>            clf_acc_score = accuracy_score(y_test, y_test_predict);<br/>            clf_f1_score = f1_score(y_test, y_test_predict);</span><span id="c8d1" class="lh li hi ld b fi ln lk l ll lm">            if clf_f1_score &gt; (np.mean(f1_list) * 0.95) :</span><span id="ffff" class="lh li hi ld b fi ln lk l ll lm">                clf = clf_temp;<br/>                selected_models += 1;</span><span id="b7e8" class="lh li hi ld b fi ln lk l ll lm">                row_list.append(selected_models);<br/>                ll_list.append(clf_log_loss);<br/>                accuracy_list.append(clf_acc_score);<br/>                f1_list.append(clf_f1_score);</span><span id="2162" class="lh li hi ld b fi ln lk l ll lm">counter += 1;</span><span id="d841" class="lh li hi ld b fi ln lk l ll lm">if counter == topic_offset:<br/>             break;</span></pre><p id="3983" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">性能指标是一段时间内的平均值，所以曲线看起来很平滑。</p><p id="c8f7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">模型评估和结果</strong></p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/f9c7636a5aff15fc76598971c70ffccc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vUcPWUMZncbADilcnZ31kA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd mg">分类任务的F1分数；随着通过</strong>的数据样本数量的增加，该指标也会提高</figcaption></figure><p id="c8a0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们假设数据是稳定的，而不稳定的数据将需要改变学习速率、模型参数平均以及我们使模型适合学习任务的方式。</p><h2 id="e4f7" class="lh li hi bd mg mi mj mk ml mm mn mo mp jg mq mr ms jk mt mu mv jo mw mx my mz bi translated">快乐编码，坚持学习</h2><blockquote class="kc kd ke"><p id="6709" class="iv iw kf ix b iy iz ja jb jc jd je jf kg jh ji jj kh jl jm jn ki jp jq jr js hb bi translated">如果你喜欢这篇文章，请鼓掌，如果有任何疑问或建议，你可以通过manikandan@datazymes.com联系我</p></blockquote><p id="dbed" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">链接到<em class="kf">代码</em>回购</p><div class="lo lp ez fb lq lr"><a href="https://github.com/manikandanj2207/dataibreathe" rel="noopener  ugc nofollow" target="_blank"><div class="ls ab dw"><div class="lt ab lu cl cj lv"><h2 class="bd hj fi z dy lw ea eb lx ed ef hh bi translated">manikandanj2207/dataibreathe</h2><div class="ly l"><h3 class="bd b fi z dy lw ea eb lx ed ef dx translated">支持媒体博客的代码库。为manikandanj 2207/dataibreat的发展作出贡献</h3></div><div class="lz l"><p class="bd b fp z dy lw ea eb lx ed ef dx translated">github.com</p></div></div><div class="ma l"><div class="na l mc md me ma mf io lr"/></div></div></a></div></div></div>    
</body>
</html>