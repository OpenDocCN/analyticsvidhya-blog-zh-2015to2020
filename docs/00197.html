<html>
<head>
<title>Hadoop Performance Benchmark Results Comparing On-Premise S3 vs. HDFS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">本地S3与HDFS的Hadoop性能指标评测结果比较</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hadoop-performance-benchmark-results-comparing-on-premise-s3-vs-hdfs-cf7a9ea3baa3?source=collection_archive---------0-----------------------#2018-11-28">https://medium.com/analytics-vidhya/hadoop-performance-benchmark-results-comparing-on-premise-s3-vs-hdfs-cf7a9ea3baa3?source=collection_archive---------0-----------------------#2018-11-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="92f9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="af5a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Hadoop部署面临的一个挑战是与计算需求同步扩展存储，因为存储和计算位于相同的硬件节点上。一种更加灵活且经济高效的解决方案是，通过将存储节点与计算节点分开，独立于计算来扩展存储。使用S3存储软件(在本例中为<a class="ae kb" href="https://cloudian.com" rel="noopener ugc nofollow" target="_blank"> Cloudian HyperStore </a>软件)实施存储层，并使用S3连接器代替HDFS，我们可以实现存储层和计算层的分离。但是在网络中使用S3而不是HDFS会对性能产生什么影响呢？</p><p id="0035" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">由Tatsuya Kawano(<a class="ae kb" href="https://twitter.com/tatsuya6502" rel="noopener ugc nofollow" target="_blank">@ Tatsuya 6502</a>)完成的这项工作旨在通过检查查询类型和存储类型的不同组合的性能来回答这个问题:</p><ol class=""><li id="a77d" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka km kn ko kp bi translated">蜂巢+HDFS</li><li id="f123" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">蜂巢+S3 (Cloudian HyperStore)</li><li id="f41c" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">普雷斯托+HDFS</li><li id="5eb4" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">普雷斯托+S3(云端超级商店)</li></ol><p id="7b42" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们使用了<a class="ae kb" href="https://github.com/intel-hadoop/HiBench" rel="noopener ugc nofollow" target="_blank"> HiBench的</a> SQL (Hive-QL)工作负载，记录约1100万条(约1.8GB)，以及<a class="ae kb" href="http://www.tpc.org/tpch/" rel="noopener ugc nofollow" target="_blank"> TPC-H </a>基准测试，记录约8.66亿条(约100GB)。</p><p id="16a4" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">CD H5(<a class="ae kb" href="https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html" rel="noopener ugc nofollow" target="_blank">cloud era Distribution Hadoop v 5 . 14 . 4</a>)用于Hadoop和HDFS实现。</p><p id="2bb0" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">对于S3存储，我们使用了<a class="ae kb" href="https://cloudian.com" rel="noopener ugc nofollow" target="_blank"> Cloudian HyperStore v7.1 </a>，它在一个可以部署在Linux上的软件包中实现了<a class="ae kb" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank">亚马逊S3 API </a>。</p><p id="5362" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">根据基准测试结果的汇总，从最好到最差的相对性能是</p><ol class=""><li id="dbb6" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka km kn ko kp bi translated">转眼间+HDFS ( <em class="kv">最佳</em>)</li><li id="7d3d" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">普雷斯托+S3</li><li id="f550" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">蜂巢+HDFS</li><li id="2d98" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">蜂巢+S3 ( <em class="kv">最差</em>)</li></ol><p id="ca70" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">两种Presto配置都大大优于两种蜂巢配置(大约10倍)。普雷斯托+S3组合显示出与最佳普雷斯托+HDFS组合非常相似的性能结果。</p><h1 id="3558" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">基础设施设置</h1><p id="9b0e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们在Amazon EC2上创建了单独的CDH5和HyperStore 7.1集群。我们将它们部署在同一个亚马逊VPC子网中。</p><h2 id="fdc2" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">CDH5集群(6 + 1节点)</h2><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es lk"><img src="../Images/d08663c40013b75833a465d5e3259962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8C57rVq7Ppl9sjj2"/></div></div></figure><ul class=""><li id="a701" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka lw kn ko kp bi translated">CDH 5.14.4在中央7号。Hadoop 2.6.0+cdh5.14.4和Hive 1.1.0+cdh5.14.4</li><li id="9d83" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">6个工作节点和1个协调节点</li><li id="a6d5" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">每个t 3.2x大型EC2实例具有8个vCPUs、32GB RAM和5千兆位/秒的网络性能。</li><li id="eb2c" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">每个节点使用一个150GB的EBS卷作为根文件系统。卷类型调配了iops SSD (io1 ),具有500 IOPs/秒的中等性能。所有数据(操作系统和Hadoop)都存储在该卷中。</li><li id="f8c6" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">每个节点上的HAProxy作为HyperStore S3服务器的负载平衡器</li></ul><p id="0f24" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们还在同一个CDH5集群上部署了<a class="ae kb" href="https://prestodb.io/" rel="noopener ugc nofollow" target="_blank"> Presto 0.212 </a>(最新版本)。</p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es lk"><img src="../Images/1306e71742f0d4f8d1f9134a2fbd49fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*29laovifQFP0-HQZ"/></div></div></figure><h2 id="99fd" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated"><strong class="ak"> HyperStore集群(6个节点)</strong></h2><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es lk"><img src="../Images/42c1b78d815bb5b372283a48134da6c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7vj9mdXrOooFpjSL"/></div></div></figure><ul class=""><li id="ec16" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka lw kn ko kp bi translated">CentOS 7上的Cloudian HyperStore 7.1</li><li id="a048" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">6个节点</li><li id="60dc" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">每个t 3.2x大型EC2实例具有8个vCPUs、32GB RAM和5千兆位/秒的网络性能。</li><li id="0d0a" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">每个节点使用一个150GB的EBS卷作为根文件系统。卷类型调配了iops SSD (io1 ),具有500 IOPs/秒的中等性能。所有数据(操作系统和超级存储)都存储在该卷中。</li></ul><h2 id="7353" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">HDFS构型</h2><p id="6baf" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们使用Cloudera Manager通过以下服务创建了CDH5集群:Hadoop YARN with MapReduce 2、HDFS、Hive、Spark和ZooKeeper。</p><p id="4728" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们没有更改HDFS设置的默认值，即3个副本和128MB的数据块大小</p><h2 id="9c61" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">蜂巢配置</h2><p id="060b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们更改了以下配置单元设置以提高配置单元+S3的性能。</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="7a3c" class="kw ig hi ly b fi mc md l me mf">hive.warehouse.subdir.inherit.perms = false<br/>hive.metastore.pre.event.listeners = (empty)<br/>hive.mv.files.thread = 45<br/>hive.exec.dynamic.partition.mode = nonstrict</span></pre><h2 id="eb37" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">S3A文件系统配置</h2><p id="6189" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们使用Cloudera Manager添加了S3A文件系统。为了获得更好的性能，我们禁用了SSL (HTTPS)连接。</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="7d5c" class="kw ig hi ly b fi mc md l me mf">fs.s3a.connection.ssl.enabled = false</span></pre><p id="42d0" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们还调整了以下S3A设置，以提高Hive+S3的性能。</p><p id="db7c" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">启用S3A快速上传功能:</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="dfb4" class="kw ig hi ly b fi mc md l me mf">fs.s3a.fast.upload = true<br/>fs.s3a.fast.buffer.size = 1048576<br/>fs.s3a.fast.upload.buffer = array</span></pre><p id="3b49" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">减少多部分上传的部分大小以获得更多的并行性。</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="9694" class="kw ig hi ly b fi mc md l me mf">fs.s3a.multipart.size = 10M<br/>fs.s3a.multipart.threshold = 10M<br/>fs.s3a.fast.upload.active.blocks = 8</span></pre><p id="df1b" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">增加连接/线程数量。</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="9f0b" class="kw ig hi ly b fi mc md l me mf">fs.s3a.threads.max = 50<br/>fs.s3a.max.total.tasks = 30</span></pre><h2 id="fbe6" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">Presto配置</h2><p id="d798" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们在CDH5节点上手动部署了最新版本的Presto。我们将节点0上的Presto服务器配置为协调器，将节点1到6上的其他6个Presto服务器配置为工作器。</p><p id="3521" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">内存设置</strong></p><p id="7d41" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">Presto对查询中每个任务可以存储的最大内存量有限制。我们没有启用“溢出到磁盘”特性，该特性将中间任务结果卸载到磁盘，因为这会降低性能。所以在我们的环境中，如果一个查询需要大量的内存，这个查询就会失败。</p><p id="7911" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">经过一些实验，我们发现以下内存设置可以处理针对100GB数据集的TPC-H查询。(我们一次运行一个查询)</p><p id="4a55" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">etc/配置.属性</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="fbac" class="kw ig hi ly b fi mc md l me mf">query.max-memory = 100GB<br/>query.max-memory-per-node = 12GB<br/>query.max-total-memory-per-node = 12GB</span></pre><p id="8566" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">etc/jvm.config</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="c02c" class="kw ig hi ly b fi mc md l me mf">-server<br/>-Xmx18G<br/>-XX:+UseG1GC</span></pre><p id="047d" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">蜂箱连接器</strong></p><p id="4275" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将Hive连接器配置为启用S3访问，这样Presto就可以访问存储在HDFS和S3的Hive表。</p><p id="6c9f" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">etc/目录/hive.properties</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="cb30" class="kw ig hi ly b fi mc md l me mf">connector.name = hive-hadoop2<br/>hive.metastore.uri = thrift://cdh-node0:9083<br/>hive.non-managed-table-writes-enabled = true<br/>hive.config.resources =<br/> /etc/hadoop/conf/core-site.xml, /etc/hadoop/conf/hdfs-site.xml<br/>hive.s3.ssl.enabled = false<br/>hive.s3.max-connections = 500<br/>hive.s3.multipart.min-file-size = 20 MB<br/>hive.s3.multipart.min-part-size = 10 MB</span></pre><p id="fe4c" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">注意，Presto不使用Hadoop S3A文件系统来访问S3，因为它有自己的<a class="ae kb" href="https://prestodb.io/docs/current/connector/hive.html#amazon-s3-configuration" rel="noopener ugc nofollow" target="_blank"> S3连接器</a>实现。</p><p id="368b" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> TPC-H连接器</strong></p><p id="4cf0" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们还配置了TPC-H连接器，可用于生成TPC-H数据集。</p><p id="192a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">etc/目录/tpch.properties</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="78a2" class="kw ig hi ly b fi mc md l me mf">connector.name = hive-hadoop2<br/>hive.metastore.uri = thrift://cdh-node0:9083<br/>hive.non-managed-table-writes-enabled = true<br/>hive.config.resources =<br/> /etc/hadoop/conf/core-site.xml, /etc/hadoop/conf/hdfs-site.xml<br/>hive.s3.ssl.enabled = false<br/>hive.s3.max-connections = 500<br/>hive.s3.multipart.min-file-size = 20 MB<br/>hive.s3.multipart.min-part-size = 10 MB</span></pre><h2 id="eca8" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">超级商店配置</h2><p id="c907" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们没有更改HyperStore设置的默认值。我们创建了一个具有擦除编码存储策略的S3存储桶(4+2)。我们在那个桶上放了蜂箱桌。</p><h2 id="f206" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">羟基构型</h2><p id="6e16" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们在每个CDH5节点上安装了HAProxy，以便在HyperStore节点上平均分配S3请求。我们使用循环负载平衡算法。</p><h1 id="be05" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">基本数据流</h1><h2 id="a4a4" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">案例一:蜂巢+HDFS</h2><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es mg"><img src="../Images/4e58ccbdecd0307c550ac475d720394c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sV-zHTeQ8DYMi1ZP"/></div></div></figure><ol class=""><li id="e612" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka km kn ko kp bi translated">输入和输出配置单元表存储在HDFS上。(此时输出表应该是空的)</li><li id="2a08" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">HiBench或TPC-H查询从节点0上的Hive客户端提交到同一节点上的HiveServer2。</li><li id="8e38" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Hive从其Metastore中定位表，并为查询安排一系列MapReduce (M/R)作业。(Hive将每个作业称为“阶段”)</li><li id="da4a" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Hadoop YARN(图中未显示)运行M/R作业中的任务。每个任务都有一个嵌入式HDFS客户端，并在HDFS上读/写数据。中间结果存储在HDFS上。</li><li id="ab8b" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">当所有阶段完成后，Hive将查询结果返回给客户端。</li></ol><h2 id="a03d" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated"><strong class="ak">案例二:蜂巢+S3 </strong></h2><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es mg"><img src="../Images/bba65206d952c57467eb94740561c46f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*C4vL84BeSdcbJRJ5"/></div></div></figure><ol class=""><li id="e529" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka km kn ko kp bi translated">输入和输出配置单元表存储在S3上。(此时输出表应该是空的)</li><li id="7d40" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">HiBench或TPC-H查询已从节点0上的配置单元客户端提交到同一节点上的HiveServer2。</li><li id="1ec3" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Hive从其Metastore中定位表，并为查询安排一系列M/R作业。</li><li id="d1c5" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Hadoop YARN运行M/R作业中的任务。每个任务都嵌入了S3A文件系统客户端，并在HyperStore S3上读取/写入数据。HAProxy作为一个循环负载平衡器，将S3请求转发到不同的S3服务器。中间结果存储在默认的分布式文件系统实例中，在我们的例子中是HDFS。</li><li id="8de0" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">当所有阶段完成后，Hive将查询结果返回给客户端。</li></ol><h2 id="fd53" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">案例3:普雷斯托+HDFS</h2><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es mg"><img src="../Images/8279ddf2e18a897b6259ce6cb85db022.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lHrPVtZzXIiMnG9y"/></div></div></figure><ol class=""><li id="b4bb" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka km kn ko kp bi translated">输入和输出配置单元表存储在HDFS上。(此时输出表应该是空的)</li><li id="a607" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">HiBench或TPC-H查询从节点0上的Presto客户端提交到同一节点上的Presto协调器。</li><li id="9de1" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Presto协调器查询配置单元Metastore以定位配置单元表。</li><li id="6d97" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Presto Coordinator为查询安排一系列任务。</li><li id="2a31" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Presto工作人员使用其嵌入式HDFS客户端执行任务，在HDFS上读取/写入数据。中间结果保存在内存中，并在Presto工人之间传输。</li><li id="851e" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">当所有任务完成后，Presto Coordinator将查询结果返回给客户机。</li></ol><h2 id="266a" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated"><strong class="ak">案例四:急变+S3 </strong></h2><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es mg"><img src="../Images/2d1af04df9679e815688abcc44d394e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o4oir7NSFqtwz3HA"/></div></div></figure><ol class=""><li id="0f95" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka km kn ko kp bi translated">输入和输出配置单元表存储在S3上。(此时输出表应该是空的)</li><li id="9a4f" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">HiBench或TPC-H查询从节点0上的Presto客户机提交到同一节点上的Presto协调器。</li><li id="201d" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Presto协调器查询配置单元Metastore以定位配置单元表。</li><li id="c6ca" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Presto Coordinator为查询安排一系列任务。</li><li id="e4bc" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Presto工作人员使用其嵌入式S3客户端执行这些任务，在HyperStore S3上读取/写入数据。中间结果保存在内存中，并在Presto工人之间传输。</li><li id="f3ad" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">当所有任务完成后，Presto Coordinator将查询结果返回给客户机。</li></ol><h1 id="dcda" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">衡量绩效</h1><p id="597f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了在Hive和Presto上生成负载，我们使用了以下基准:</p><ul class=""><li id="426e" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka lw kn ko kp bi translated"><strong class="jf hj">希本斯</strong>，【https://github.com/intel-hadoop/HiBench】T2</li><li id="3d65" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">http://www.tpc.org/tpch、<a class="ae kb" href="http://www.tpc.org/tpch" rel="noopener ugc nofollow" target="_blank">T4</a></li></ul><p id="da3f" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">英特尔HiBench是一款大数据性能指标评测套件，可帮助评估不同大数据产品的速度。它有三个Hive工作负载，是基于SIGMOD 09论文“大规模数据分析方法的比较”开发的。</p><p id="b78b" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">TPC-H是一种OLAP(在线分析处理)工作负载，用于测量数据仓库环境中的分析查询性能。Presto可以运行未经修改的TPC-H查询(这是ANSI SQL兼容)，它有TPC-H连接器，可以生成TPC-H数据集。Hive不能直接运行TPC-H查询，但是我们在GitHub上找到了几个TPC-H的Hive-QL实现，我们使用了其中的一个。</p><p id="a226" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">HiBench工作负载提供非常简单的写密集型和读密集型查询。它们将帮助我们了解这两种产品在基本读/写性能方面的差异。</p><p id="6df7" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">TPC-H提供复杂的大量读取的查询。这些查询将让我们对真实世界的性能差异有更多的了解。</p><h2 id="94f9" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">HiBench配置单元工作负载</h2><p id="76ae" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">HiBench数据集是使用HiBench的数据生成器创建的，并以SequenceFile格式存储。我们将hibench.scale.profile设置为large，将hi bench . default . map . parallelism设置为48，得到的输入数据量如下:</p><ul class=""><li id="a24e" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka lw kn ko kp bi translated">所有两个表总共约有1100万条记录</li><li id="8cea" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">所有48个存储文件总计约1.8 GB(每个约37MB)</li></ul><p id="5df2" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将Hive-QL移植到了Presto可以执行的SQL中。Presto通过配置单元连接器访问配置单元表。</p><p id="813d" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们通过手动执行每个查询来测量性能，并以毫秒为单位记录查询时间。结果如下:</p><p id="415e" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> HiBench查询时间</strong></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mh"><img src="../Images/1d2e9df661c727b224921d33ce695329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/0*EwT4h8YuN3Cs6A7N"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mi"><img src="../Images/3ec4db90d1c8d501a91a1b15ec4df378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*z4_hmuEzP5ESF9XAUDt5GQ.png"/></div></figure><p id="6fce" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">备注</strong></p><p id="f9b0" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">不管名称如何，“扫描”查询不仅从输入表中读取所有记录，还将它们复制到输出表中。所以写得很重。</p><pre class="ll lm ln lo fd lx ly lz ma aw mb bi"><span id="78b6" class="kw ig hi ly b fi mc md l me mf">insert overwrite table uservisits_copy select * from uservisits;</span></pre><p id="86eb" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">hi bench结果汇总:</strong></p><ul class=""><li id="0e14" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka lw kn ko kp bi translated">输入数据大小约1100万条记录(约1.8GB)，以顺序文件格式存储</li><li id="7c2d" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">HiBench适合测量基本读/写性能。</li><li id="70ec" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">对于写繁重的查询，Presto+S3比Hive+HDFS快<strong class="jf hj"><em class="kv"/></strong>4.2倍。</li><li id="8088" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">对于阅读量大的查询，Presto+S3比Hive+HDFS平均快15.1倍。</li></ul><h2 id="1af4" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated">TPC-H基准</h2><p id="1b2f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">TPC-H数据集是使用Presto的<a class="ae kb" href="https://prestodb.io/docs/current/connector/tpch.html" rel="noopener ugc nofollow" target="_blank"> TPC-H连接器</a>创建的，并使用ZLIB压缩以ORC(优化行列)格式存储。ORC类似于拼花地板，广泛用于蜂巢。我们无法使用Parquet，因为Hive 1.1不支持Parquet文件中的“日期”列类型。</p><p id="6fc3" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们选择TPC-H比例因子= 100来生成100GB的数据集。我们得到了以下数量的输入数据，所有8个表总共有8 . 66亿条记录</p><p id="58a9" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">Presto能够运行未经修改的TPC-H查询。它通过配置单元连接器访问存储TPC-H数据集的配置单元表。</p><p id="0c1e" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">对于Hive，我们在GitHub上找到了以下Hive-QL查询实现。</p><ol class=""><li id="c58d" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka km kn ko kp bi translated">【https://github.com/rxin/TPC-H-Hive】，包含贾云涛2011年的作品(<a class="ae kb" href="https://issues.apache.org/jira/browse/hive-600" rel="noopener ugc nofollow" target="_blank"/>)</li><li id="c595" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><a class="ae kb" href="https://github.com/hortonworks/hive-testbench" rel="noopener ugc nofollow" target="_blank">https://github.com/hortonworks/hive-testbench</a>，包含霍顿作品近几年的作品。</li></ol><p id="1bae" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">#2包含比#1更复杂的查询，但似乎#2针对的是比CDH 5 (Hive 1.1)更新的Hive版本(1.3+)。在我们的环境中，一些#2查询在一个较小的1GB数据集上返回了不正确的结果，其中许多查询在100GB数据集上停滞不前。所以这里我们只给出第一个查询结果:</p><p id="87ea" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> TPC-H查询时间</strong></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mj"><img src="../Images/c517b76a917caf8c4ec2eb32cecf6dbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*rubso4JV04BB9j8x"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mk"><img src="../Images/5d9ef620fe3490434469e937d740a7fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*huOe8ZyVHJkdUYojE6ZdYA.png"/></div></figure><p id="657d" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">备注</strong></p><ul class=""><li id="319b" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka lw kn ko kp bi translated">所有TPC-H的查询都是大量读取的。</li><li id="173c" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">我们没有测量Hive+S3的性能，因为从HiBench结果来看，我们预计它会比所有其他组合慢，我们可能对结果不感兴趣。</li><li id="cbe8" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">我们没有在100GB数据集上运行查询“q19 ”,因为Hive和Presto在1GB数据集上返回了不同的查询结果。</li><li id="96d4" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">我们跳过了查询“q22 ”,因为它在100GB数据集的Hive上失败。</li><li id="b660" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">如前所述，我们将Presto coordinator/worker的query.max-memory-per-node设置为12GB，以便在内存中处理查询。大多数查询在每个节点8GB内存内完成，但是“q09”和“q21”分别需要每个节点10GB和12GB内存。</li></ul><p id="96a7" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">TPC-H结果汇总:</strong></p><ul class=""><li id="0441" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka lw kn ko kp bi translated">输入数据大小:约8.66亿条记录(约100GB)，以ORC格式存储，ZLIB压缩</li><li id="1ae0" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">TPC-H很适合测量分析查询的真实性能。</li><li id="b335" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">Presto+S3在<strong class="jf hj"> <em class="kv">上平均比Hive+HDFS的</em> </strong>快11.8倍</li></ul><h1 id="4aa7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">为什么Presto在基准测试中比Hive快</h1><ul class=""><li id="30eb" class="kh ki hi jf b jg jh jk jl jo ml js mm jw mn ka lw kn ko kp bi translated">Presto是一个内存查询引擎，所以它不会将中间结果写入存储(S3)。Presto发出的S3请求比Hive少得多。</li><li id="d6aa" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">与Hive M/R作业不同，Presto在写入后不执行重命名文件操作。重命名在S3存储系统中是非常昂贵的操作，因为它是通过复制和删除文件操作来实现的。</li><li id="1d06" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka lw kn ko kp bi translated">Hive必须在阶段之间等待(M/R作业)。很难持续利用所有的CPU和磁盘资源。</li></ul><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es mo"><img src="../Images/f337506e9216a359b4cad51abacf8598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*74-ZUK6kaMUnPP8F"/></div></div><figcaption class="mp mq et er es mr ms bd b be z dx translated">图片来源:<a class="ae kb" href="https://blog.treasuredata.com/blog/2015/03/20/presto-versus-hive/" rel="noopener ugc nofollow" target="_blank">https://blog . treasured data . com/blog/2015/03/20/presto-vs-hive/</a></figcaption></figure><h1 id="dcd4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结论</h1><p id="0524" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">根据基准测试结果的汇总，从最好到最差的相对性能是</p><ol class=""><li id="92a6" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka km kn ko kp bi translated">转眼间+HDFS ( <em class="kv">最佳</em></li><li id="d136" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">普雷斯托+S3</li><li id="f66c" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">蜂巢+HDFS</li><li id="68de" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">蜂巢+S3 ( <em class="kv">最差</em>)</li></ol><p id="a5b7" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">两种Presto配置都大大优于两种蜂巢配置(大约10倍)。普雷斯托+S3组合显示出与最佳普雷斯托+HDFS组合非常相似的性能结果，并且明显优于蜂巢+HDFS组合。这些Presto+S3结果证明了在Hadoop集群中分离计算层和存储层的可行性。</p></div></div>    
</body>
</html>