<html>
<head>
<title>K-Means Clustering using Python from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-意味着从头开始使用Python进行聚类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/k-means-clustering-using-python-from-scratch-7ccdace7789?source=collection_archive---------13-----------------------#2019-11-11">https://medium.com/analytics-vidhya/k-means-clustering-using-python-from-scratch-7ccdace7789?source=collection_archive---------13-----------------------#2019-11-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2afcf3f8518f4a7aa59607d6271a6df2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mEjVgvRumu52lVgh"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">玛利亚·沙妮娜在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="dc2d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">K-means聚类是一种无监督学习算法，旨在将n个观察值划分为k个聚类，其中每个观察值属于质心最近的聚类。该算法旨在最小化观测值与其所属聚类质心之间的平方欧氏距离。</p><p id="db3e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在深入研究代码之前，我们先来看看分步方法:-</p><p id="476f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第一步</strong> :-首先我们需要决定集群的数量。在某些情况下，如市场细分，在问题陈述中定义了“k”(聚类数)的值。在其他情况下，我们必须决定“k”的最佳值。肘法通过用一系列“k”值拟合模型来帮助选择“k”的最佳值。我们将在另一篇文章中讨论它。这里我们假设“k”的值是3。</p><p id="ab98" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第二步 :-然后我们从给定的数据点中随机初始化‘k’个质心。</p><p id="7556" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤3 </strong> :-我们计算质心和数据点之间的欧几里德距离的平方。如果数据点和第k个聚类的质心之间的欧几里德距离的平方最小，则将该数据点分配给第k个聚类。</p><p id="77d1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤4 </strong> :-现在我们知道了每个聚类中的数据点，计算每个聚类的质心。</p><p id="290a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤5 </strong> :-我们计算“ε”,其定义为数据点与其各自质心之间欧几里得距离的平方和。</p><p id="36ef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤6 </strong> :-我们重复整个过程，直到‘Epsilon’的值没有显著变化，表明集群形成没有显著变化。</p><p id="a156" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们来理解将2维数据K-means聚类成3个聚类的python代码。</p><figure class="jt ju jv jw fd ij"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="ae2a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们得到下面的散点图。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jz"><img src="../Images/bff1caf4752e4d0d8f2b522a976ccba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dvaphmfi2kz_DcqrsO5aew.png"/></div></div></figure><p id="d661" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们观察到，在第3次迭代后，聚类形成没有显著变化，因为第3、第4和第5散点图彼此非常相似。</p><p id="321c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们绘制“迭代次数对ε的平方根”的图表。</p><pre class="jt ju jv jw fd ka kb kc kd aw ke bi"><span id="2d8f" class="kf kg hi kb b fi kh ki l kj kk"><strong class="kb hj">a = list(range(1,21)) </strong>#Number of iterations = 20<strong class="kb hj"><br/>plt.plot(a, [x**0.5 for x in epsilon], ‘go — ‘, linewidth=1.5, markersize=4)<br/>plt.xlabel(‘Iteration number’) <br/>plt.ylabel(‘Square root of epsilon’)</strong></span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es kl"><img src="../Images/d9917efb1ff67d8b31d3be1b354d2748.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*7S8O9UIXq4ZAC9qro6mSHA.png"/></div></figure><p id="6a49" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从上图中，我们再次观察到，在第三次迭代之后，ε的平方根值没有显著变化。因此，我们可以在3-4次迭代后停止。</p></div></div>    
</body>
</html>