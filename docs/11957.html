<html>
<head>
<title>Akira’s ML News #Week52, 2020</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2020 年第 52 周</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/akiras-ml-news-week52-2020-845556ee3a45?source=collection_archive---------11-----------------------#2020-12-25">https://medium.com/analytics-vidhya/akiras-ml-news-week52-2020-845556ee3a45?source=collection_archive---------11-----------------------#2020-12-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="35e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是我在 2020 年第 52 周(12 月 20 日~)读到的一些我觉得特别有意思的论文和文章。我已经尽量介绍最近的了，但是论文提交的日期可能和星期不一样。</p><h1 id="a553" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">主题</h1><ol class=""><li id="5c4d" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc ki kj kk kl bi translated">机器学习论文</li><li id="187d" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">技术文章</li><li id="c4d2" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">机器学习用例的例子</li></ol><h1 id="c3c2" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">—每周编辑精选</h1><ul class=""><li id="0a4f" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc kr kj kk kl bi translated"><a class="ae ks" href="https://www.biorxiv.org/content/10.1101/2020.06.16.154542v1" rel="noopener ugc nofollow" target="_blank">使用灵长类视觉皮层提高对抗攻击的能力</a></li><li id="c2ab" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc kr kj kk kl bi translated"><a class="ae ks" href="https://arxiv.org/abs/2012.07421" rel="noopener ugc nofollow" target="_blank">用于测量真实世界数据分布变化稳健性的数据集</a></li><li id="e199" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc kr kj kk kl bi translated"><a class="ae ks" href="https://analytics.dkv.global/deep-pharma/AI-for-Drug-Discovery-2020.pdf" rel="noopener ugc nofollow" target="_blank">人工智能用于药物发现</a></li></ul><p id="c38c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">— — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="01fb" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">1.机器学习论文</h1><p id="0a1b" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi">— —</p><h1 id="7819" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">使用智能手机上的图像创建 10 微米级别精度的高度地图</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kw"><img src="../Images/dde4368219ca1040173de8062e970f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yA1I9BU-Nfd7zkYm.png"/></div></div></figure><p id="3970" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">使用不稳定手机摄像头的介观摄影测量</em><br/><a class="ae ks" href="https://arxiv.org/abs/2012.06044" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2012.06044</a></p><p id="910e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">研究从智能手机拍摄的多幅图像中创建 10μm 级别的高度图。它学习使 CNN 计算出的高度图与它和摄像头信息重建的地图保持一致。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="9bf5" class="jd je hi bd jf jg lq ji jj jk lr jm jn jo ls jq jr js lt ju jv jw lu jy jz ka bi translated">用于测量对真实世界数据分布变化的稳健性的数据集</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/055dc3dd0be9fc1a9de21935c29bc3a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1yPc5XkRWe_AzQbb.png"/></div></div></figure><p id="f0de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">野生:野生分布移位的基准</em><br/><a class="ae ks" href="https://arxiv.org/abs/2012.07421" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2012.07421</a></p><p id="a544" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在现实世界中，数据分布(由不同的摄像机、一天中的时间、区域捕获)会发生许多变化，并导致模型性能下降。该项目提供了卫生图像、医学图像和文档等数据集，以评估这些分布变化的鲁棒性。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="cb6e" class="jd je hi bd jf jg lq ji jj jk lr jm jn jo ls jq jr js lt ju jv jw lu jy jz ka bi translated">复制和粘贴可以是一种强大的数据扩充。</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lw"><img src="../Images/54b53499d7ae00b84c8306f2b779b142.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4VNzl3hbbDDHdsPq.png"/></div></div></figure><p id="2c61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">简单的复制粘贴是一种强大的数据扩充方法，例如分段</em><br/><a class="ae ks" href="https://arxiv.org/abs/2012.07177" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2012.07177</a></p><p id="0717" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一项研究表明，结合图像缩放和复制粘贴的数据扩充在实例分割和对象检测中非常强大。这种效果在许多网络中得到证实。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="9ff8" class="jd je hi bd jf jg lq ji jj jk lr jm jn jo ls jq jr js lt ju jv jw lu jy jz ka bi translated">在不使用 JFT300M 的情况下超越 ViT 的性能</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lx"><img src="../Images/a2942191fcf8feed5bdc4e5c26b111fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*elP5ZAL9PKxroNeg.png"/></div></div></figure><p id="d56f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">https://arxiv.org/abs/2012.12877<br/><a class="ae ks" href="https://arxiv.org/abs/2012.12877" rel="noopener ugc nofollow" target="_blank">训练数据高效的图像变形金刚&amp;通过注意力蒸馏</a></p><p id="a4ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们提出了 DeiT(数据高效图像转换器),在仅转换器的机制中使用基于令牌的提取，这超过了 ViT 的准确性，ViT 是没有 CNN 的 SotA 模型，而 EfficientNet 仅使用 ImageNet 进行训练。背景是 ViT 论文中说“Transformer 在 ImageNet 这样的中型数据集上不准确，因为它的感性偏差很小，需要 JFT300M 这样的大型数据集。然而，它需要使用 RegNet (CNN)作为教师以及正则化和数据扩充等进行提炼。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="06ed" class="jd je hi bd jf jg lq ji jj jk lr jm jn jo ls jq jr js lt ju jv jw lu jy jz ka bi translated">一种通过关注单个正确答案来消除 NMS 的对象检测模型</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es ly"><img src="../Images/aeff200d182e5e6aec5667fe9f999cac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hWOSI5yN3QeE5I2r.png"/></div></div></figure><p id="79af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li"> OneNet:面向端到端的一阶段目标检测</em><br/><a class="ae ks" href="https://arxiv.org/abs/2012.05780" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2012.05780</a></p><p id="1c22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在目标检测中，在传统的盒分配系统 YOLO 和点分配系统 CenterNet 中，对于一个目标有多个正确的标签。OneNet 通过将正确答案分配给每个候选对象成本最低的点，将正确锚点的数量缩小到一个。虽然这是一个简单的方法，但它可以消除 NMS，建立一个完整的 E2E 网络。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="a9f4" class="jd je hi bd jf jg lq ji jj jk lr jm jn jo ls jq jr js lt ju jv jw lu jy jz ka bi translated">通过在每个块中保留图像的表示，成功地将超分辨率提高了 30 倍</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lz"><img src="../Images/6034ac3c65bb3c38154822548dee6053.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/0*QV7ge4R57fiPNwbP.png"/></div></figure><p id="269c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">用局部隐式图像函数学习连续图像表征</em><br/><a class="ae ks" href="https://arxiv.org/abs/2012.09161" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2012.09161</a></p><p id="9608" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们提出了一种局部隐式图像函数(LIIF ),它将图像表示为一组向量，而不是单个向量，并对它们进行积分以实现更高的分辨率。与许多使用特定放大倍数进行学习的研究不同，LIIF 可以在任何放大倍数下进行训练，即使在推断 30 倍高分辨率时也能获得良好的结果。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="b53c" class="jd je hi bd jf jg lq ji jj jk lr jm jn jo ls jq jr js lt ju jv jw lu jy jz ka bi translated">这是一篇关于套索及其变体的综合论文</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es ma"><img src="../Images/2a54b389c27505615f0ba5190f5971e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1rm0KjHdxw0ejRPH.png"/></div></div></figure><p id="b1b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">LASSO 及其衍生工具在协变量依赖下的变量选择</em><br/><a class="ae ks" href="https://arxiv.org/abs/2012.11470" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2012.11470</a></p><p id="9b4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一篇关于套索及其在变量选择中经常使用的变体的综合论文。当添加有噪声的虚拟特征或特征相关时，LASSO 不能很好地工作，本文展示了它们在这种情况下如何表现的许多实验。(自适应套索好像挺好的)</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="fbfd" class="jd je hi bd jf jg lq ji jj jk lr jm jn jo ls jq jr js lt ju jv jw lu jy jz ka bi translated">使用灵长类动物视觉皮层可以提高对抗攻击的能力</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mb"><img src="../Images/0c034210b29fd6af69fb64729cd606a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_cI4ktUZz1nphQte.png"/></div></div></figure><p id="8242" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">模拟中枢神经系统前部的初级视觉皮层提高了对图像扰动的鲁棒性</em><br/><a class="ae ks" href="https://www.biorxiv.org/content/10.1101/2020.06.16.154542v1" rel="noopener ugc nofollow" target="_blank">https://www.biorxiv.org/content/10.1101/2020.06.16.154542v1</a></p><p id="3090" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们发现了灵长类初级视觉皮层(V1)和对抗攻击的抵抗力之间的相关性，通过添加一层重现 V1 的层，他们可以提高对抗攻击的抵抗力。</p><h1 id="02a8" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">用轻量计算获得光流运动特征</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mc"><img src="../Images/fb42c59d68ad4b98d98319a1fefd32a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IVRfUw2ze_TgF19n.png"/></div></div></figure><p id="432c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">运动挤压:用于视频理解的神经运动特征学习</em><br/><a class="ae ks" href="https://arxiv.org/abs/2007.09933" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2007.09933</a></p><p id="b49e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过计算相邻帧的点积来计算相邻像素的相似性，他们可以像轻量计算中的 OpticalFlow 一样计算动作的特征。结果是一个轻量级的网络，具有动作识别的高精度。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="8447" class="jd je hi bd jf jg lq ji jj jk lr jm jn jo ls jq jr js lt ju jv jw lu jy jz ka bi translated">处理来自特殊相机的数据的缺乏</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es md"><img src="../Images/0b657049d8cfbd5ee66d414cfd6d9bf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kNsdyFjndt01BzMB.png"/></div></div></figure><p id="d1fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">通过使用嫁接网络</em><br/><a class="ae ks" href="https://arxiv.org/abs/2003.10959" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2003.10959</a>学习利用多种视觉模态</p><p id="5eca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">来自热感相机等特殊相机的数据少于来自正常图像数据集的数据。因此，他们提出了一种类似蒸馏的学习机制，该机制使用在正常图像上训练的学习模型，并应用约束，使得除了特殊相机侧的输入层之外的层的表示匹配。这比从特殊的摄像机图像中从头开始学习更准确。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="8e8f" class="jd je hi bd jf jg lq ji jj jk lr jm jn jo ls jq jr js lt ju jv jw lu jy jz ka bi translated">通过将数据分配到一个额外的类来识别标签错误的数据。</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es me"><img src="../Images/b634e1b684f8b4040368ad3996e783af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*d47ZlIgzkfRUB4G_.png"/></div></div></figure><p id="746f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="li">使用边距等级</em><br/><a class="ae ks" href="https://arxiv.org/abs/2001.10528" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2001.10528</a>下的区域识别误贴标签的数据</p><p id="d13b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过将样本随机分配到附加的额外类别，并将其置信水平与最大置信水平进行比较来识别错误标记数据的研究。错误标记的数据可以被识别，因为最大置信度大于实际值。</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><p id="9f88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">— — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="8857" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">2.技术文章</h1><p id="64e6" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi">— —</p><h1 id="352f" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">NeRF 及其相关研究解释</h1><div class="mf mg ez fb mh mi"><a href="https://dellaert.github.io/NeRF/" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hj fi z dy mn ea eb mo ed ef hh bi translated">NeRF 爆炸 2020</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">除了新冠肺炎疫情和美国的政治动荡，2020 年也是神经体绘制…</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">dellaert.github.io</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw lg mi"/></div></div></a></div><p id="a95a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一篇简要介绍 NeRF 及其相关研究的文章。文章首先介绍了导致 NeRF 的相关研究，因此很容易理解 NeRF 如何使用这些研究。</p><p id="49ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">— — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="953e" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">3.机器学习用例的例子</h1><p id="fbb1" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi">— —</p><h1 id="9597" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">用于药物发现的人工智能</h1><p id="0f59" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><a class="ae ks" href="https://analytics.dkv.global/deep-pharma/AI-for-Drug-Discovery-2020.pdf" rel="noopener ugc nofollow" target="_blank">https://analytics . dkv . global/deep-pharma/AI-for-Drug-Discovery-2020 . pdf</a></p><p id="1fca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一份关于人工智能用于新药开发的报告，描述了领先的公司，人工智能如何在每个公司中使用，以及市场。每个公司如何使用人工智能的部分是必看的。例如，报告描述了阿斯利康如何使用知识图表来分析相关信息。</p><p id="cefd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">— — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="281f" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">—过去的文章</h1><p id="a6af" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><a class="ae ks" rel="noopener" href="/analytics-vidhya/akiras-ml-news-week51-2020-6fb82b15642d"> 2020 第 51 周</a> ⇦ 2020 第 52 周(本帖)⇨ <a class="ae ks" rel="noopener" href="/analytics-vidhya/akiras-ml-news-week2-2021-c9374ac86d3e"> 2021 第 1 周&amp; 2 </a></p><p id="73a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ks" rel="noopener" href="/analytics-vidhya/akiras-ml-news-november-2020-a48a3cb75285">2020 年 11 月汇总</a><a class="ae ks" rel="noopener" href="/analytics-vidhya/akiras-ml-news-october-2020-c7b5b4281d36"><br/>2020 年 10 月汇总</a><br/><a class="ae ks" rel="noopener" href="/analytics-vidhya/akiras-ml-news-september-2020-80ed65bd7ea4">2020 年 9 月汇总</a> <br/> <a class="ae ks" href="https://towardsdatascience.com/machine-learning-2020-summary-84-interesting-papers-articles-45bd45c0d35b" rel="noopener" target="_blank"> 2020 年汇总</a></p><p id="0bb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">— — — — — — — — — — — — — — — — — — — — — — — — — —</p><h1 id="81dd" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">推特，我贴一句纸评论。</h1><p id="226e" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><a class="ae ks" href="https://twitter.com/AkiraTOSEI" rel="noopener ugc nofollow" target="_blank">https://twitter.com/AkiraTOSEI</a></p></div></div>    
</body>
</html>