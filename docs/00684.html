<html>
<head>
<title>An Intro to NLP and Sentiment Analysis using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行自然语言处理和情感分析的介绍</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/exploring-twitter-data-using-python-af1287ee65f1?source=collection_archive---------1-----------------------#2019-08-26">https://medium.com/analytics-vidhya/exploring-twitter-data-using-python-af1287ee65f1?source=collection_archive---------1-----------------------#2019-08-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7a2fa3336a32f1e44ef3b26498681ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_7BKNWpPcwiB8gpu"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">萨拉·库菲在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="a22d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本系列的<a class="ae iu" rel="noopener" href="/@cnstlungu/exploring-twitter-data-using-python-part-i-setting-up-and-getting-the-data-e1cc2d13b7f4">第一部分中，我们已经了解了接入Twitter APIs所需的设置，如何搜索关于某个主题的推文(鉴于铺天盖地的媒体报道，我们选择了英国退出欧盟)以及如何预处理数据以获得表格形式。</a></p><p id="d5fb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇文章中，我们将在这项工作的基础上做进一步的数据处理和特征提取。我们还将介绍自然语言处理的概念，并展示情感分析工具的概念证明。</p><p id="43a8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样，如果您希望继续学习，请参考Github资源库，其中包含本系列的完整的<a class="ae iu" href="https://github.com/cnstlungu/incubator/tree/master/Python/Exploring%20Twitter%20Data%20using%20Python" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本。</a></p><h2 id="7b11" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">处理数据</h2><p id="6e24" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">首先，让我们看一下上一部分我们停止的地方。也就是说，让我们仔细看看我们的文本。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/27188b94205c8ad719656de98a890832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*s_7U5NJhKHWOKVhQUvPYHA.png"/></div></div></figure><p id="a008" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为我们正在查看推文，推文的<em class="ky">文本</em>属性——推文的实际信息——是我们数据集中最重要的属性之一。我们现在可以发现数据中的几个问题:</p><ul class=""><li id="1670" class="kz la hi ix b iy iz jc jd jg lb jk lc jo ld js le lf lg lh bi translated">不能保证我们看到的是独特的推文(关于它们的<em class="ky">文本</em>)。病毒消息可能会被转发几十次。</li><li id="1786" class="kz la hi ix b iy li jc lj jg lk jk ll jo lm js le lf lg lh bi translated">对推文的意义没有增加价值的元素:标点符号和特殊字符、超链接、twitter句柄、<em class="ky">停用词</em>、元数据(比如“RT”代表转发)</li></ul><p id="62a7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们首先删除重复的。我们将它们视为与其他推文相同的推文，例如同一条原始推文的多次转发。</p><pre class="ku kv kw kx fd ln lo lp lq aw lr bi"><span id="eade" class="jt ju hi lo b fi ls lt l lu lv">df.drop_duplicates(subset='text',inplace=True)</span></pre><p id="7280" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们通过删除重复项来检查我们删除了多少行。因此，从随机构建的18000条推文中，我们得到了6389条独特的推文。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/4f2f72067466f6916630eafdbc3fa987.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*WuezKD7MB_enCjlXRnAwFg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">以前</figcaption></figure><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/f9448746b99101d6007924cd51436ded.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*GgBf5faC86J8mh33JF38Jw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">在...之后</figcaption></figure><p id="17a9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们继续处理文本。我们将逐一应用以下步骤:</p><ul class=""><li id="b45e" class="kz la hi ix b iy iz jc jd jg lb jk lc jo ld js le lf lg lh bi translated">将tweet文本转换成小写</li><li id="8f53" class="kz la hi ix b iy li jc lj jg lk jk ll jo lm js le lf lg lh bi translated">移除twitter句柄</li><li id="b833" class="kz la hi ix b iy li jc lj jg lk jk ll jo lm js le lf lg lh bi translated">删除超链接</li><li id="eced" class="kz la hi ix b iy li jc lj jg lk jk ll jo lm js le lf lg lh bi translated">删除非字母数字字符，如标点符号</li><li id="5773" class="kz la hi ix b iy li jc lj jg lk jk ll jo lm js le lf lg lh bi translated">删除空白</li></ul><p id="c94c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一步是删除停用词——可以忽略的助词。我们将使用一个预定义的停用词列表和一些作品，比如retweet(“rt”)。</p><pre class="ku kv kw kx fd ln lo lp lq aw lr bi"><span id="f155" class="jt ju hi lo b fi ls lt l lu lv">from nltk.corpus import stopwords<br/>additional  = ['rt','rts','retweet']<br/>swords = set().union(stopwords.words('english'),additional)</span></pre><p id="a5ed" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下是我们排除的单词的预览:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/7d40365c15e0174cb01444eeb22fa592.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*9xDhFhfJzXu_VqObkWmurw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">一共182个字</figcaption></figure><pre class="ku kv kw kx fd ln lo lp lq aw lr bi"><span id="214d" class="jt ju hi lo b fi ls lt l lu lv">df['processed_text'] = df['text'].str.lower()\<br/>          .str.replace('(@[a-z0-9]+)\w+',' ')\<br/>          .str.replace('(http\S+)', ' ')\<br/>          .str.replace('([^0-9a-z \t])',' ')\<br/>          .str.replace(' +',' ')\<br/>          .apply(lambda x: [i for i in x.split() if not i in swords])</span></pre><p id="ae32" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们应用下面的转换从处理过的文本中删除停用词。</p><p id="039e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一个转变可能是词干。想想'玩'，'玩过'，'玩'，'玩'。既然都代表同一个想法，那就把它们简化成同一个概念，一起算就好了。</p><pre class="ku kv kw kx fd ln lo lp lq aw lr bi"><span id="42f7" class="jt ju hi lo b fi ls lt l lu lv">from nltk.stem import PorterStemmer<br/>ps = PorterStemmer()<br/>df['stemmed'] = df['processed_text'].apply(lambda x: [ps.stem(i) for i in x if i != ''])</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/afec8fd6faff77ae2bd4a8c27d500aa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*9iail_h7B3VhnQ8AHb3OCQ.png"/></div></figure><p id="3a58" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们通过原始推文文本转换及其词干分析获得的列将允许我们分析所使用的词汇，查看重复出现的主题，并确定最常用的单词。</p><p id="c508" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在将简要地分析这些推文的情绪。</p><h2 id="7480" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">情感分析</h2><p id="157e" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">显然，考虑到大量的推文，人们不可能通读它们来了解公众的普遍感受。因此，我们需要一种更自动化的方式来判断一条给定的推文是正面还是负面地谈论我们感兴趣的话题。一个简单的分析器可能如下所示:</p><ul class=""><li id="2564" class="kz la hi ix b iy iz jc jd jg lb jk lc jo ld js le lf lg lh bi translated">创建一个单词字典，表示各种情绪或观点</li><li id="ae5f" class="kz la hi ix b iy li jc lj jg lk jk ll jo lm js le lf lg lh bi translated">相应地给他们打分:消极的给消极的，积极的给积极的。说<em class="ky">可怕的</em>是-5，<em class="ky">可怕的</em>是-3，<em class="ky">坏的</em>是-1而<em class="ky">好的</em>是+1，<em class="ky">伟大的</em> +3和<em class="ky">杰出的</em> + 5。</li><li id="d987" class="kz la hi ix b iy li jc lj jg lk jk ll jo lm js le lf lg lh bi translated">对于一个给定的短语，把分数加起来，看看你得到了多少分。</li></ul><p id="c941" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是一个基本的情感分析器。幸运的是，这些工具已经存在于Python生态系统中，我们可以用它们来为我们做这件事。也就是说，我们将使用维德情绪强度分析仪。</p><pre class="ku kv kw kx fd ln lo lp lq aw lr bi"><span id="66ed" class="jt ju hi lo b fi ls lt l lu lv">import nltk.sentiment.vader as vd<br/>from nltk import download<br/>download('vader_lexicon')<br/>sia = vd.SentimentIntensityAnalyzer()</span></pre><p id="dacc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还将使用一个单词分词器，它将把我们的单词一个接一个地输入情感分析器。</p><pre class="ku kv kw kx fd ln lo lp lq aw lr bi"><span id="09e0" class="jt ju hi lo b fi ls lt l lu lv">from nltk.tokenize import word_tokenize<br/>df['sentiment_score'] = df['processed_text'].apply(lambda x: sum([ sia.polarity_scores(i)['compound'] for i in word_tokenize( ' '.join(x) )]) )</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es kt"><img src="../Images/1eb2d04414d17c971a8b5d93dc4aace3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*WyKCBD-V_A5w2ixnGoL29w.png"/></div></figure><p id="37d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当然，我们应该详细检查数据，看看我们是否对极性评分为我们的推文分配情感的方式感到满意。</p><p id="5ab4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们将尝试可视化归因情绪之间的分裂。正如我们所看到的，这个词是相当矛盾的，负面情绪略有优势。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/8b639bd898e698489ddcb9af7b7278d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*dX4csy3GuHDfUtD_u30CiA.png"/></div></figure><p id="7f3d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不幸的是，一些更负面的意见(</p><h2 id="0f83" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">A closer look at our features</h2><p id="f73f" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">So by now we know some of the transformations we can apply to our text and how to get a feel on what the sentiment of the texts are. But we could still mine more data from any of the 320+ attributes we have apart the tweet text itself.</p><p id="ca68" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">For example, from the <strong class="ix hj">user . followers _ count</strong>table)我们可以了解我们的哪些推文属于拥有低、中或高twitter受众的用户。我们将用户分为三类:少于300个追随者，300到10.000个追随者和超过10.000个追随者。有了更大的样本量，这也可以让我们了解信息到达的受众的规模。</p><pre class="ku kv kw kx fd ln lo lp lq aw lr bi"><span id="f31a" class="jt ju hi lo b fi ls lt l lu lv">df['user_audience_category'] = pd.cut(df['user.followers_count'],[0,300,10000,999999999],include_lowest=True,labels=['small','medium','wide'])</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/3919f57d35a69694e0a450c077738812.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*OVCAMj-hlIR4_JtJGaVgWw.png"/></div></figure><h2 id="4ea1" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">结论</h2><p id="5997" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">本系列的这一部分介绍了我们如何转换从Twitter上检索到的文本，执行基本的情感分析，以及根据我们已经拥有的数据构建新的简单功能。</p><p id="6a4e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本系列的<a class="ae iu" rel="noopener" href="/@cnstlungu/exploring-twitter-data-using-python-part-iii-analyzing-the-data-e883aa340dff?sk=2958fbb608e2b76f71694d081606ca74">后续部分，我们将探讨分析这些数据并向感兴趣的群体展示的方法。感谢您的阅读，敬请关注下一篇文章。</a></p><p id="2ba2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" rel="noopener" href="/@cnstlungu/exploring-twitter-data-using-python-part-iii-analyzing-the-data-e883aa340dff?source=friends_link&amp;sk=2958fbb608e2b76f71694d081606ca74">在这里继续阅读第三部</a></p></div></div>    
</body>
</html>