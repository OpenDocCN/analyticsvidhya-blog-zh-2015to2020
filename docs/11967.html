<html>
<head>
<title>Eye Tracking using OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用OpenCV进行眼睛跟踪</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/eye-tracking-using-opencv-2f40cc09183c?source=collection_archive---------8-----------------------#2020-12-26">https://medium.com/analytics-vidhya/eye-tracking-using-opencv-2f40cc09183c?source=collection_archive---------8-----------------------#2020-12-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="62cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我2000年初的时候，我父亲经常开车带我去我的家乡度假。从我住的地方出发大概需要8个小时。在我们的旅程中，我的主要角色是坐在他身边，每当他的眼睛闭上时叫醒他。如果我不在他身边呢？是不是很恐怖？是啊。在阅读了OpenCV的这个案例研究后，我们可以使用一个小相机来跟踪你的眼睛，感到很高兴，并想象它将有助于避免高速公路上的许多事故。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><h1 id="96e3" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">追踪眼睛的步骤</h1><ol class=""><li id="5faa" class="ki kj hi ih b ii kk im kl iq km iu kn iy ko jc kp kq kr ks bi translated">检测你的脸</li><li id="f2de" class="ki kj hi ih b ii kt im ku iq kv iu kw iy kx jc kp kq kr ks bi translated">裁剪人脸区域并检测人脸区域中的眼睛</li><li id="bc9e" class="ki kj hi ih b ii kt im ku iq kv iu kw iy kx jc kp kq kr ks bi translated">继续追踪眼睛区域</li></ol></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><h1 id="9ca8" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">代码片段</h1><p id="6f67" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">如果你在自己的视频中尝试，我们需要调整比例因子和最小邻居来获得更好的结果。</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="0979" class="lk jl hi lg b fi ll lm l ln lo"># import the necessary packages<br/>import cv2</span><span id="e944" class="lk jl hi lg b fi lp lm l ln lo">class EyeTracker:<br/>   def __init__(self, faceCascadePath, eyeCascadePath):<br/>       # load the face and eye detector<br/>       self.faceCascade = cv2.CascadeClassifier(faceCascadePath)<br/>       self.eyeCascade = cv2.CascadeClassifier(eyeCascadePath)</span><span id="464f" class="lk jl hi lg b fi lp lm l ln lo">  def track(self, image):<br/>       # detect faces in the image and initialize the list of<br/>       # rectangles containing the faces and eyes<br/>       faceRects = self.faceCascade.detectMultiScale(image,<br/>         scaleFactor = 1.1, minNeighbors = 5, minSize = (30,30),<br/>         flags = cv2.CASCADE_SCALE_IMAGE)<br/>       rects = []</span><span id="368a" class="lk jl hi lg b fi lp lm l ln lo">       # loop over the face bounding boxes<br/>       for (fX, fY, fW, fH) in faceRects:<br/>          # extract the face ROI and update the list of<br/>          # bounding boxes<br/>          faceROI = image[fY:fY + fH, fX:fX + fW]<br/>          rects.append((fX, fY, fX + fW, fY + fH))<br/> <br/>          # detect eyes in the face ROI<br/>          eyeRects = self.eyeCascade.detectMultiScale(faceROI,<br/>          scaleFactor = 1.1, minNeighbors = 10, minSize = (20, 20),<br/>          flags = cv2.CASCADE_SCALE_IMAGE)</span><span id="0be8" class="lk jl hi lg b fi lp lm l ln lo">          # loop over the eye bounding boxes<br/>          for (eX, eY, eW, eH) in eyeRects:<br/>          # update the list of boounding boxes<br/>          rects.append(<br/>             (fX + eX, fY + eY, fX + eX + eW, fY + eY + eH))</span><span id="a6b6" class="lk jl hi lg b fi lp lm l ln lo">       # return the rectangles representing bounding<br/>       # boxes around the faces and eyes<br/>       return rects</span></pre><p id="7268" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以现在我们创建了一个类，它可以从视频中检测人脸和眼睛。但是如果我们发送不同大小的视频，参数需要经常改变。为了克服这一点，我们可以对输入图像进行预处理，这样在转换成某种格式后将调用眼球跟踪器类。</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="3436" class="lk jl hi lg b fi ll lm l ln lo"># USAGE<br/># python eyetracking.py — face cascades/haarcascade_frontalface_default.xml — eye cascades/haarcascade_eye.xml — video video/adrian_eyes.mov<br/># python eyetracking.py — face cascades/haarcascade_frontalface_default.xml — eye cascades/haarcascade_eye.xml</span><span id="bff2" class="lk jl hi lg b fi lp lm l ln lo"># import the necessary packages<br/>from pyimagesearch.eyetracker import EyeTracker<br/>from pyimagesearch import imutils<br/>import argparse<br/>import cv2</span><span id="93d6" class="lk jl hi lg b fi lp lm l ln lo"># construct the argument parse and parse the arguments<br/>ap = argparse.ArgumentParser()<br/>ap.add_argument(“-f”, “ — face”, required = True,<br/> help = “path to where the face cascade resides”)<br/>ap.add_argument(“-e”, “ — eye”, required = True,<br/> help = “path to where the eye cascade resides”)<br/>ap.add_argument(“-v”, “ — video”,<br/> help = “path to the (optional) video file”)<br/>args = vars(ap.parse_args())</span><span id="a5b4" class="lk jl hi lg b fi lp lm l ln lo"># construct the eye tracker<br/>et = EyeTracker(args[“face”], args[“eye”])</span><span id="5088" class="lk jl hi lg b fi lp lm l ln lo"># if a video path was not supplied, grab the reference<br/># to the gray<br/>if not args.get(“video”, False):<br/>   camera = cv2.VideoCapture(0)</span><span id="ca3e" class="lk jl hi lg b fi lp lm l ln lo"># otherwise, load the video<br/>else:<br/>   camera = cv2.VideoCapture(args[“video”])</span><span id="55e8" class="lk jl hi lg b fi lp lm l ln lo"># keep looping<br/>while True:<br/>   # grab the current frame<br/>   (grabbed, frame) = camera.read()</span><span id="3a67" class="lk jl hi lg b fi lp lm l ln lo">   # if we are viewing a video and we did not grab a<br/>   # frame, then we have reached the end of the video<br/>   if args.get(“video”) and not grabbed:<br/>      break</span><span id="6631" class="lk jl hi lg b fi lp lm l ln lo">   # resize the frame and convert it to grayscale<br/>   frame = imutils.resize(frame, width = 300)<br/>   gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><span id="aadf" class="lk jl hi lg b fi lp lm l ln lo">   # detect faces and eyes in the image<br/>   rects = et.track(gray)</span><span id="d4d3" class="lk jl hi lg b fi lp lm l ln lo">   # loop over the face bounding boxes and draw them<br/>   for rect in rects:<br/>      cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]),    (0, 255, 0), 2)</span><span id="e380" class="lk jl hi lg b fi lp lm l ln lo">   # show the tracked eyes and face<br/>   cv2.imshow(“Tracking”, frame)</span><span id="69b2" class="lk jl hi lg b fi lp lm l ln lo">   # if the ‘q’ key is pressed, stop the loop<br/>   if cv2.waitKey(1) &amp; 0xFF == ord(“q”):<br/>     break</span><span id="acbe" class="lk jl hi lg b fi lp lm l ln lo"># cleanup the camera and close any open windows<br/>camera.release()<br/>cv2.destroyAllWindows(</span></pre><p id="9107" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考:</strong></p><p id="acc2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Adrian的OpenCV-基础包</p><p id="f782" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">链接代码:【https://github.com/RamjiB/Eye-Tracking T2】</p></div></div>    
</body>
</html>