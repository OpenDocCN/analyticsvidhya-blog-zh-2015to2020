<html>
<head>
<title>The kernel trick and infinite dimensions.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">内核技巧和无限维。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/the-kernel-trick-and-infinite-dimensions-7ecd91cee6ef?source=collection_archive---------3-----------------------#2020-12-27">https://medium.com/analytics-vidhya/the-kernel-trick-and-infinite-dimensions-7ecd91cee6ef?source=collection_archive---------3-----------------------#2020-12-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/35734d1adb847d6f06822d4ae17ce1ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Z5VT8hOVeddipBRAiHr_WA.png"/></div></figure><p id="1fca" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果你曾经接触过机器学习理论，你可能会遇到术语<em class="jj">内核方法</em>，以及它们如何将原始输入空间转换到更高维度的空间(有时是<em class="jj">无限</em>)，以便使用被称为<em class="jj">内核技巧</em>的东西来执行回归/分类任务。这似乎有点“神奇”，让我困惑了很长时间。然而，我最终认为我已经理解了这一点，这就是为什么我想分享我的观点。</p><p id="bc90" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">一种常见的线性参数模型被称为<em class="jj">线性回归</em>，其中一些输出作为某个输入向量<strong class="in hi"> x </strong>和一些参数<strong class="in hi"> w </strong>的某种线性组合的函数给出。我们通常将初始数据划分为训练集和测试集，并在训练集上调整回归参数<strong class="in hi"> w </strong>，直到我们对结果满意为止。然后，我们扔掉训练集，使用测试集来评估其总体性能，并使用<strong class="in hi"> w </strong>来预测新的、新鲜的未见过的数据。</p><p id="d985" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们以岭回归为例:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es jk"><img src="../Images/4dd40f5b5eacebdd5a5b2dc6a47be7ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*jWlmk10T5eY4cCJzlQUygA.png"/></div></figure><p id="0d60" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这是我们试图最小化的损失函数，用参数<strong class="in hi"> w </strong>表示。如果我们取这个函数相对于<strong class="in hi"> w </strong>的梯度，我们得到如下结果:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es jp"><img src="../Images/39111469014e9581c7da53cf6e9de8f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*8TL95PvDBixm-B0a-FYqIQ.png"/></div></figure><p id="3d0d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">注意我们如何将 w 重写为 a 的函数。如果我们将其代入原始损失函数，我们得到以下结果:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es jq"><img src="../Images/b5cdfa552e0c40124997b8be5c8ac4c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*hyg2I4Wy_TX1Qozj-UCxGA.png"/></div></figure><p id="1968" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">注意 phi 的重复模式。矩阵<strong class="in hi">φ</strong>是映射到某个扩展特征空间的每个初始数据点<strong class="in hi"> x </strong>。自身被转置的<strong class="in hi"> phi </strong>的乘积表示每个数据点与其自身和所有其他数据点的点积(在各个变换 phi(x)下)。这个乘积也被称为<em class="jj">克</em>矩阵<strong class="in hi"> K. </strong>我们继续根据<strong class="in hi"> K </strong>重写损失函数:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es jr"><img src="../Images/00888a7630626fd618b0c6a3026a7bd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*XRPcuE7kmRgYSiQiVv-7qQ.png"/></div></figure><p id="0432" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果我们计算这个函数相对于<strong class="in hi"> a </strong>的梯度，并将其设置为零，我们得到:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es js"><img src="../Images/7161d8f3bd4ca231a4e4478ed838db4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*AyS6KgdrQkfZB0-TBLztIg.png"/></div></figure><p id="2549" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果我们重新排列并求解<strong class="in hi"> a </strong>，我们最终得到<strong class="in hi"> : </strong></p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es jt"><img src="../Images/4b5296e560924579a26f7d9fb2b38885.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*CGtz9DEi3XM7PfoTqqZEiQ.png"/></div></figure><p id="bb77" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们设法用<strong class="in hi"> a </strong>来重新表述这个问题，这样我们可以看到解决方案只能用<strong class="in hi"> K </strong>和<strong class="in hi">y</strong>来表示。这是<em class="jj">对偶</em>表示，但是为什么这是一件好事呢？<em class="jj">*鼓声* </em>进入<em class="jj">内核绝招</em>。</p><p id="edd3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在简单的情况下，φ(<strong class="in hi">x</strong>)表示恒等式变换φ(<strong class="in hi">x</strong>)=<strong class="in hi">x</strong>。这意味着<strong class="in hi"> K </strong>的每个条目只是训练集中每个数据点的点积。由于<strong class="in hi"> K </strong>是 n 乘 n 矩阵，这似乎只会使事情变得更糟(因为当使用高斯-乔丹算法<em class="jj"> ) </em>时，对 n 乘 n 矩阵求逆的计算复杂度是<em class="jj">o(n^3</em>，然而，当训练集的维数 d 远大于样本数量(<em class="jj"> D &gt; &gt; N </em>)时，我们可以看到，解决对偶问题比原始问题更有效。</p><p id="8d37" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">但是什么是<em class="jj">绝招</em>？</p><p id="d7f6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果我们将点积视为相似性的度量，我们可以想象,<strong class="in hi"> K </strong>中的每个条目给我们一个度量，即每个向量对<strong class="in hi"> x </strong>和<strong class="in hi"> z </strong>在原始 D 维空间中有多相似。但是如果我们要扩展到更高维度的空间呢？</p><p id="216c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">存在一些流行的核，例如多项式核:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es ju"><img src="../Images/e7c03596da992a6bc40559cd312134e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*oohmfSnwRXOSmPlLSYrFsg.png"/></div></figure><p id="0b54" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为简单起见，我们设置 b = 1 和 d = 2，这样内核中的每个条目都变成:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es jv"><img src="../Images/91c63b798a353ceee1adef22a4654127.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*Awp9p3vB-hCk1YRYeNYFcQ.png"/></div></figure><p id="696f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们看到每一项都是点积和加法的平方。然而，如果我们根据点积重写每个条目，我们可以看到它实际上代表了更高维空间中的比较:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es jw"><img src="../Images/0580b923ce045fecca2f8b3490fc67db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s2VTXwZnea7EjOGC5U0WBA.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">更正:我在这里漏掉了 sqrt(2)*(交叉项)的总和</figcaption></figure><p id="73ca" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这是内核的伎俩！我们发现一些映射<strong class="in hi"> K </strong>允许我们在更高维度中比较原始数据集<strong class="in hi">，而不需要在扩展的特征空间中实际计算点积的额外工作。</strong></p><p id="3f28" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">无限维的核呢？</p><p id="80cd" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">还有一个非常流行的内核叫做 RBF(径向基函数),看起来像这样:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es kf"><img src="../Images/1ac5f0106c4871a6b6bfc77b0f998e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*e2tMbkQj367dfhyR5iLXlw.png"/></div></figure><p id="865b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们从扩展正方形开始:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es kg"><img src="../Images/42400aab1ed8dd6a4975b281cd7d7da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*ZGuVgbNvPvK6jFXAHdn6QA.png"/></div></figure><p id="0824" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果你还记得微积分，你知道我们可以用泰勒展开式来近似一个函数:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es kh"><img src="../Images/eb1abd6af1b052bf563693622a2af4d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*Dda-xq20hO1AVuoLNT0ElQ.png"/></div></div></figure><p id="d22e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">幸运的是，当 f(x)是指数函数时，展开很容易:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es ki"><img src="../Images/a7c4eb0876c4aab83bdcff9d94a25fe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*riR3RyGX71JGjp8QTWEoFQ.png"/></div></figure><p id="4463" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果我们简化上面的表达式，我们得到:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es kj"><img src="../Images/095989cc1d35abd75c11168bd49511a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*9LPwz_wQto3kJdQgbgqw_g.png"/></div></figure><p id="92a6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们用这个展开式代替最后一个 exp(xy)项，这样初始公式就变成:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es kk"><img src="../Images/8c400a9006dfbf916b105285382c379c.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*6xWD8Sn6LCBqoNi7OS4PZA.png"/></div></figure><p id="b3d2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在像这样替换表达式的左手因子:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es kl"><img src="../Images/a7dcfab317679cc9eb93293c4d2f1579.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*PrBzGh25pggXhLEwkAPF-w.png"/></div></figure><figure class="jl jm jn jo fd ii er es paragraph-image"><div class="er es km"><img src="../Images/7076644908c9afde876aca93ed28a3b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*hwITUJ4Is8F02MPboMSbNQ.png"/></div></figure><p id="df6b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">正如多项式核可以重写为点积一样，RBF 也可以:</p><figure class="jl jm jn jo fd ii er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es kn"><img src="../Images/f5e22460f0e177963bb8106358aecf7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TkkCuuwVUf47Ha3dmHuj1Q.png"/></div></div></figure><p id="3fc2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这意味着 RBF 将每一对数据点映射到一个无限的核中，更重要的是，我们不必实际计算这些(无限)点积。</p><p id="54cd" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">注意，不是所有的函数都是有效的内核函数，有一些条件必须适用，如果你感兴趣，我可以推荐 M. Bishop 的“模式识别和 ML”的第 6.2 章。</p><p id="8e10" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">感谢阅读！</p></div></div>    
</body>
</html>