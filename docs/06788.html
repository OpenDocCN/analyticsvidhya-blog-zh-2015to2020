<html>
<head>
<title>Understanding Callbacks In Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解Keras中的回调</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-callbacks-in-keras-98c935095219?source=collection_archive---------18-----------------------#2020-06-02">https://medium.com/analytics-vidhya/understanding-callbacks-in-keras-98c935095219?source=collection_archive---------18-----------------------#2020-06-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es im"><img src="../Images/c8106112a2f08c566ea6447c05954ed9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JYKzEh9A_lffbeAz"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">照片由Maria Casteli在Unsplash上拍摄</figcaption></figure><p id="3246" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">训练深度学习模型是一个非常复杂的过程。在训练模型时，几乎不可能预测模型的这么多参数。例如，事先决定历元的数量是一项单调乏味的任务。在这篇文章中，我们将研究一些使用回调来控制模型训练的方法。</p><h1 id="8c74" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">什么是回拨:</h1><p id="8ee2" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">keras中的回调有助于我们对模型进行适当的训练。从框架的角度来看，它是一个对象，我们可以在使用fit方法时将其传递给模型，并可以在训练的不同点调用它。下面我们可以看到在模型训练中可以使用的不同类型的回调。</p><h2 id="cfd4" class="ld kb hi bd kc le lf lg kg lh li lj kk jn lk ll ko jr lm ln ks jv lo lp kw lq bi translated">提前停止:</h2><p id="4f3a" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">当验证损失不再改善时，我们可以使用<em class="lr">提前停止</em>来中断训练过程。我们还可以确保在训练期间存储最佳模型。下面的代码片段显示了应用提前停止的方法。</p><pre class="in io ip iq fd ls lt lu lv aw lw bi"><span id="f3ae" class="ld kb hi lt b fi lx ly l lz ma">keras.callbacks.EarlyStopping(monitor='val_loss',<br/>                              min_delta=0,<br/>                              patience=0,<br/>                              mode='auto')</span></pre><p id="6baf" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">让我们逐个检查参数。</p><p id="f877" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj"> <em class="lr">监视器</em></strong>——这个参数告诉我们应该被监视的性能指标。</p><p id="0c2b" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj"> <em class="lr"> min_delta </em> </strong> -该参数表示监控值的下限(<em class="lr">此处为val_loss </em>)，我们可以将其视为改进。</p><p id="8c70" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj"> <em class="lr">耐心- </em> </strong>该参数表示当我们的val_loss没有改善时，在停止训练过程之前我们可以等待的次数。</p><p id="bd96" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj"> <em class="lr">模式- </em> </strong>它表示我们应该检查监控数量的方向(可能增加或减少)。</p><h2 id="4ef0" class="ld kb hi bd kc le lf lg kg lh li lj kk jn lk ll ko jr lm ln ks jv lo lp kw lq bi translated">模型检查点:</h2><p id="15c6" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">它帮助我们在训练过程中的不同点保存模型的当前重量。下面的代码片段显示了实现的方法。</p><pre class="in io ip iq fd ls lt lu lv aw lw bi"><span id="4292" class="ld kb hi lt b fi lx ly l lz ma">from keras.callbacks import ModelCheckpoint<br/>checkpoint = ModelCheckpoint(filepath, monitor=’val_accuracy’, save_best_only=True)</span></pre><p id="adc1" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj"> <em class="lr"> filepath </em> </strong> -在每一个历元之后，将模型的权重保存在这个路径中。</p><p id="3994" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj"> <em class="lr">监控和保存_最佳- </em> </strong>这两个参数确保保存最佳模型，除非模型没有根据监控值进行改进，否则我们不会保存结果。</p><h2 id="58fb" class="ld kb hi bd kc le lf lg kg lh li lj kk jn lk ll ko jr lm ln ks jv lo lp kw lq bi translated"><strong class="ak">高原减少:</strong></h2><p id="54ce" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">当验证损失停止改善时，我们可以使用这种回调来降低学习率。这对于在训练中走出局部极小点真的很有帮助。下面的代码片段显示了执行它的方法。</p><pre class="in io ip iq fd ls lt lu lv aw lw bi"><span id="789f" class="ld kb hi lt b fi lx ly l lz ma">from keras.callbacks import ReduceLROnPlateau</span><span id="4453" class="ld kb hi lt b fi mb ly l lz ma">reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,<br/>                              patience=5)</span></pre><p id="3bbb" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">上面的代码片段说，如果val_loss在5个时期内没有改善，那么它会将学习率更改为其1/5的值。</p><p id="4a44" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">为了将这些回调应用到我们的模型中，我们可以使用fit方法并传递回调列表。下面的代码片段显示了同样的情况。</p><pre class="in io ip iq fd ls lt lu lv aw lw bi"><span id="9407" class="ld kb hi lt b fi lx ly l lz ma">model.fit(x,y,epochs=5,callbacks=callbacks_list,validation_data=(x_val,y_val)</span></pre><p id="3b2a" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这里callback_list可以是上面我们讨论过的任何一个回调。</p><p id="1729" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这是一个在keras中训练模型的非常有效的机制的简要概述。</p></div></div>    
</body>
</html>