<html>
<head>
<title>The Absolute Basics of Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习的绝对基础</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/the-absolute-basics-of-reinforcement-learning-97402c444be1?source=collection_archive---------8-----------------------#2020-11-23">https://medium.com/analytics-vidhya/the-absolute-basics-of-reinforcement-learning-97402c444be1?source=collection_archive---------8-----------------------#2020-11-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="6b03" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">强化学习</h1><p id="fde1" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">强化学习。它是什么，有什么作用？在本文中，您将对强化学习有一个基本的了解。</p><p id="6c6f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">首先，我们从一个基本定义开始:</strong></p><p id="2fce" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">强化学习是机器学习的一个领域。</p><p id="1e0b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">它包括软件代理学习在不确定的环境中导航，以获得最大回报。它从互动体验中学习，并利用来自其行动的反馈。基本上，机器人会因为它的动作而得到分数。它可以加分也可以减分。代理通过 RL 学习的方式和我们人类学习的方式是一样的。</p><p id="e21b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">把它想象成一个电子游戏，你会因为你的行为而得到惩罚或奖励。在大多数电子游戏中，你可以通过获得更多分数或进入下一关来获得奖励，而你会受到失去一条生命或死亡的惩罚。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/6d4123f35d2cbec1ad38901da0c413c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o4zsnopV8r8TunULNXO9lQ.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">在 RL 算法内部</figcaption></figure><h2 id="fac8" class="kw ig hi bd ih kx ky kz il la lb lc ip jo ld le it js lf lg ix jw lh li jb lj bi translated"><strong class="ak">我们想让代理自己学习。</strong></h2><p id="55bc" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">强化学习算法有三个基本要素:</p><p id="4f84" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">首先，我们得到了代理所处的<strong class="jf hj">环境</strong>。环境向代理提供反馈，告诉它所做的是对还是错。换句话说，环境告诉代理人它所采取的行动是否导致了奖励或惩罚。</p><p id="c693" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">接下来，我们有了<strong class="jf hj">代理</strong>代理是选择它所采取的动作的人。</p><p id="509c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">最后，我们得到了<strong class="jf hj">奖励</strong>。报酬是代理人的目标。代理人的激励。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lk"><img src="../Images/fbbdeee7a3db851a3d1a4b9cc0c7de9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*THi0KZcRwWm-za4atP24kQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">RL 算法如何学习</figcaption></figure><p id="fc8f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">现在，如果我们回到视频游戏的例子，环境将是你看到的游戏屏幕，代理人将是你，因为你是做决定和玩游戏的人，奖励将是更多的分数或进入下一个级别。</p><p id="2894" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">那么它与其他机器学习技术相比如何:</strong></p><p id="2ee5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">有 3 种基本的机器学习技术；监督学习，非监督学习，当然还有强化学习。</p><p id="d35c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这些技术的主要区别在于目标。</p><p id="f6bb" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">无监督学习的目标是发现数据点之间的异同，而监督学习的目标是根据给定的标签对数据进行排序。当然，正如我们所知，强化学习的目标是获得最大的回报。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ll"><img src="../Images/d5f94286cce8065d3bb95025d4a07a8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*nomoPirEmlbXg11TN-WtMA.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">RL 与其他 ML 技术</figcaption></figure><p id="0412" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">RL 在哪里最有用？</strong></p><p id="d274" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">强化学习技术特别有用，因为它们不需要大量预先存在的知识或数据来提供有用的解决方案，或者在有许多未知的地方。</p><p id="ae14" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">今天用在哪里？</strong></p><p id="ab8e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">目前，RL 正被用于机器人、空中交通管制、数据处理、创建培训系统等领域！RL 上的应用是无止境的，几乎可以在任何地方使用。谷歌的 Deep Mind 团队已经使用 RL 让一个代理学习和识别数字，并独自玩游戏 Atari！</p><p id="dd03" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这是谷歌 Deepmind 算法玩雅达利的视频。<a class="ae lm" href="https://www.youtube.com/watch?v=V1eYniJ0Rnk" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=V1eYniJ0Rnk</a></p><p id="deef" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">RL 的挑战</strong></p><p id="0db2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">任何新技术都会带来挑战，对 RL 来说也不例外。RL 最大的问题之一是试图大规模使用它。学习任务需要大量的训练时间和大量的迭代。RL 学习的方式是通过反复试验。在现实世界中做到这一点几乎是不可能的。让我们以一个代理试图在一个环境中导航以避开人群为例。然后，代理将尝试不同的操作，然后选择最适合该环境的操作。在环境不断频繁变化的现实世界中，这变得很难做到。</p></div><div class="ab cl ln lo gp lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="hb hc hd he hf"><p id="310e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae lm" href="https://towardsdatascience.com/the-ultimate-beginners-guide-to-reinforcement-learning-588c071af1ec" rel="noopener" target="_blank">https://towards data science . com/the-ultimate-beginners-guide-to-reinforcement-learning-588 c 071 a f1 EC</a></p><p id="d172" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae lm" href="https://www.kdnuggets.com/2018/03/5-things-reinforcement-learning.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2018/03/5-things-reinforcement-learning . html</a></p><p id="6d14" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae lm" rel="noopener" href="/@BonsaiAI/why-reinforcement-learning-might-be-the-best-ai-technique-for-complex-industrial-systems-fde8b0ebd5fb">https://medium . com/@ BonsaiAI/why-reinforcement-learning-may-be-best-ai-technique-for-complex-industrial-systems-FD E8 b 0 EBD 5 FB</a></p><p id="2a7a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae lm" href="https://towardsdatascience.com/applications-of-reinforcement-learning-in-real-world-1a94955bcd12" rel="noopener" target="_blank">https://towards data science . com/applications-of-enforcement-learning-in-real-world-1a 94955 BCD 12</a></p><p id="0a5a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae lm" href="https://www.guru99.com/reinforcement-learning-tutorial.html" rel="noopener ugc nofollow" target="_blank">https://www.guru99.com/reinforcement-learning-tutorial.html</a></p><p id="fb69" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae lm" href="https://www.futurithmic.com/2019/04/12/why-you-should-study-ai-machine-learning-how-did-it/" rel="noopener ugc nofollow" target="_blank">https://www . futurithmic . com/2019/04/12/why-you-should-study-ai-machine-learning-how-do-it/</a></p><div class="lu lv ez fb lw lx"><a href="https://towardsdatascience.com/reinforcement-learning-its-necessity-and-challenges-febef1470e9a" rel="noopener follow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">强化学习:必要性和挑战</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">简介:</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">towardsdatascience.com</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml kq lx"/></div></div></a></div><p id="5c69" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae lm" href="https://towardsdatascience.com/an-introduction-to-reinforcement-learning-1e7825c60bbe" rel="noopener" target="_blank">https://towards data science . com/an-introduction-to-reinforcement-learning-1e 7825 c 60 bbe</a></p></div></div>    
</body>
</html>