<html>
<head>
<title>Auto Price Prediction from Scratch! Part 4: Algorithms and Experiments</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">汽车价格预测从零开始！第4部分:算法和实验</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/auto-price-prediction-from-scratch-part-4-algorithms-and-experiments-e78aa2bf864f?source=collection_archive---------19-----------------------#2020-02-25">https://medium.com/analytics-vidhya/auto-price-prediction-from-scratch-part-4-algorithms-and-experiments-e78aa2bf864f?source=collection_archive---------19-----------------------#2020-02-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/03a5b0f5b750c7453184b8581632e517.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lq4vhtep4uLBS7LOH3IY4g.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="4f6d" class="pw-subtitle-paragraph iq hs ht bd b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh dx translated"><strong class="ak">为我们来之不易的数据建模</strong></h2></div><p id="8493" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">我们想预测汽车价格。从一无所有开始，我们自己搜集和准备数据。在这里，我们找到有前途的算法，实验，并评估结果。</p><p id="2527" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这是本系列文章<a class="ae ke" rel="noopener" href="/analytics-vidhya/auto-price-prediction-from-scratch-part-3-feature-engineering-a903e2509643"> <strong class="jk hu">第3部分:特性工程</strong> </a>的延续。请看<a class="ae ke" rel="noopener" href="/analytics-vidhya/auto-price-prediction-from-scratch-part-1-overview-a4f331aaad00"> <strong class="jk hu"> Part1:概述</strong> </a>了解大图。</p></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><h2 id="f53d" class="km kn ht bd ko kp kq kr ks kt ku kv kw jr kx ky kz jv la lb lc jz ld le lf lg bi translated">寻找有前途的算法和评分</h2><p id="e3de" class="pw-post-body-paragraph ji jj ht jk b jl lh iu jn jo li ix jq jr lj jt ju jv lk jx jy jz ll kb kc kd hb bi translated">在项目的早期，花很多时间调整预测算法可能很有诱惑力。当有很多转盘要转的时候，尤其如此。例如，决策树提升算法LightGBM有许多超参数。</p><p id="2ec5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">不要玩弄所有用户指定的参数，而是用标准超参数训练许多快速、普通的模型。模型应该是不同的类型，例如线性、随机森林、神经网络和最近邻。将模型缩小到有希望的模型，避免不停地修改参数！</p><p id="b51a" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">选择一个与您的问题相关的误差指标。我选择平均绝对误差(MAE ),因为它是直观的，我们希望最小化预测价格和真实价格之间的美元差异。让我们称这个度量为“分数”。</p><p id="55fe" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在拟合模型和根据测试数据进行预测时，您可以使用不同的评分方法。为什么？一个原因是某些评分方法对异常值更敏感。例如，均方误差(MSE)比MAE对大误差更敏感，因此模型拟合将会改变。</p><p id="94f8" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">选择与目标一致的评分标准。例如，如果标记所有欺诈性信用卡交易(容忍一些“假警报”)至关重要，那么召回就是一个很好的指标。召回的定义是:</p><p id="8bda" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lm ln lo lp b">Recall = (True Positives)/ (True Positives + False Negatives)</code></p><p id="4ba6" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">它是正确的欺诈预测与所有欺诈的比率。越大越好，最大值不超过1。在回忆=1时，我们预测100%的欺诈。</p><p id="f756" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">也许测试数据度量被转换为准确性，预测的子集匹配地面真相。</p><p id="d90e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lm ln lo lp b">Accuracy = correct predictions / total predictions</code></p><p id="5b09" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">您可以为测试数据计算多个指标，包括召回率和准确度，以便更好地理解二进制分类结果。</p><p id="8413" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在训练期间，调整模型性能和稳定性的普遍方法是k倍<a class="ae ke" href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation" rel="noopener ugc nofollow" target="_blank">交叉验证</a>。k倍的平均分数反映了平均模型性能。k倍的分数标准差反映了模型的变化。当然，稳定的模型变化较小。</p><h2 id="a101" class="km kn ht bd ko kp kq kr ks kt ku kv kw jr kx ky kz jv la lb lc jz ld le lf lg bi translated">分析和改进算法</h2><p id="4043" class="pw-post-body-paragraph ji jj ht jk b jl lh iu jn jo li ix jq jr lj jt ju jv lk jx jy jz ll kb kc kd hb bi translated">最有前途的算法是LightGBM、KNN和MLPRegressor。普通的最小二乘回归，线性回归，是我们的基线算法。(这里省略了KNN和MLPRegressor。)</p><p id="f4e6" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">要问关键问题是:</p><ul class=""><li id="b857" class="lq lr ht jk b jl jm jo jp jr ls jv lt jz lu kd lv lw lx ly bi translated">哪些特性很重要？</li><li id="6f20" class="lq lr ht jk b jl lz jo ma jr mb jv mc jz md kd lv lw lx ly bi translated">我们如何修复算法错误？</li></ul><p id="90e9" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">排列重要性是量化特征重要性的直观方式。它提出了以下问题:如果一个特性不可用，模型的得分会差多少？但是，如果我们简单地放弃这个特征，模型必须重新调整。排列重要性回避了这个问题。该特征不是被重新训练，而是被混洗以将其转换成噪声。</p><p id="e2ae" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">排列重要性返回权重。权重越大，特征对模型得分的影响越大。下面我们看到<strong class="jk hu">是Year^2 </strong>最重要的特征。</p><pre class="me mf mg mh fd mi lp mj mk aw ml bi"><span id="4ec6" class="km kn ht lp b fi mm mn l mo mp">#Get feature importances using eli5.</span><span id="7d85" class="km kn ht lp b fi mq mn l mo mp">perm = PermutationImportance(lgb_model, n_iter=20).fit(testX, testY)</span><span id="240c" class="km kn ht lp b fi mq mn l mo mp">display(eli5.show_weights(perm, feature_names = testX.columns.tolist()))</span></pre><figure class="me mf mg mh fd hk er es paragraph-image"><div class="er es mr"><img src="../Images/c58e375ba750204baa350c3801b7c714.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*C4aJqol9bf6bat4a-GZXlQ.png"/></div><figcaption class="ms mt et er es mu mv bd b be z dx translated">排列重要性—权重越高越重要。</figcaption></figure><p id="034e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">当心在高度相关的特征上使用排列重要性。该子集的重要性可能较低。如果使用重要性阈值自动丢弃特征，则相关的特征可能会被一次性丢弃，而不管它们是否有用。以上，displacement和CombMPG共线，那些重要的不要信！</p></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><p id="4070" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">残差有助于我们理解发生了什么样的建模误差。使用自动化工具快速获得剩余数据点背后的细节。以编程方式构建一个按量值排序的残差列表。残差应与原始要素和原始数据的全部细节相关联。如果索引在整个代码中保持不变，这很容易做到。</p><p id="37d5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><code class="du lm ln lo lp b">Residual error = Absolute_Value(Actual Value-Predicted Value)</code></p><p id="5237" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">通过绘制残差来可视化它们。残差图对于查看是否有任何东西看起来有趣(如异方差形状)至关重要。残差代码请看GitHub上的<a class="ae ke" href="https://github.com/jkmackie/car_price_prediction/tree/master/jupyter_notebooks" rel="noopener ugc nofollow" target="_blank"> algo </a>笔记本。</p><figure class="me mf mg mh fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mw"><img src="../Images/07629b91f70858639f17f537deb80d7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WsSM8cBweA_kRq8irYfK8A.png"/></div></div><figcaption class="ms mt et er es mu mv bd b be z dx translated">用Seaborn绘制的残差图。橙色线标记了平均值的三个标准偏差。红色数字是熊猫的观察指数。</figcaption></figure><h2 id="4fe0" class="km kn ht bd ko kp kq kr ks kt ku kv kw jr kx ky kz jv la lb lc jz ld le lf lg bi translated">残差案例研究</h2><p id="2226" class="pw-post-body-paragraph ji jj ht jk b jl lh iu jn jo li ix jq jr lj jt ju jv lk jx jy jz ll kb kc kd hb bi translated">一些最差的残差具有看似精确的特征和非常高的预测值。价格检查显示，与第三方网站上出售的汽车相比，这一预测是合理的。发生了什么事？CraigsList的车被撞毁了！这就是实际价格低的原因。于是“残骸”这个功能就产生了。它搜索与沉船相关的关键词。</p><figure class="me mf mg mh fd hk er es paragraph-image"><div class="er es mx"><img src="../Images/4806f434383d59fb6bc4edd6ec679032.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/format:webp/1*KudMUhfEcirfQl6b0B0BIg.png"/></div><figcaption class="ms mt et er es mu mv bd b be z dx translated">残骸特征。左边的数字是熊猫指数。</figcaption></figure><p id="55e9" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">当然，如果缺少相关关键字，就无法捕获沉船状态。在这种情况下，残骸状态为“无”。这是模型预测中噪音/异常值的来源。</p><p id="58b2" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">噪音的第二个来源是首付被列为价格。我们在模拟全价，而不是付款。如果我们以1000美元的价格安装一辆12000美元的汽车，我们如何建立一个成功的模型？权宜之计是:删除价格低于5001美元、包含“下跌”一词的列表。</p><p id="c482" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">逻辑一定要写仔细。我们不想把“down*”车和“市区”车搞混。正则表达式必须考虑这种情况。这种逻辑是脆弱的。例如，根据当前的逻辑，如果汽车列表低于5001美元，并且具有单词“楼下”，则列表可能会被错误地丢弃。</p></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><p id="fc92" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">模型预测中的另一个噪音来源是环境保护局的规范。EPA组合和排量数据是模型级的— <strong class="jk hu">不是</strong>修整级的。这意味着一辆普通的2011款野马和一辆2011款野马GT拥有相同的(中值)发动机排量。一个trim级别的规格数据库将会改善结果。</p><blockquote class="my"><p id="d03f" class="mz na ht bd nb nc nd ne nf ng nh kd dx translated">处理异常的更安全的方法是逐个检查，使用专家判断来确定它是否是真正的异常值。</p></blockquote><p id="3015" class="pw-post-body-paragraph ji jj ht jk b jl ni iu jn jo nj ix jq jr nk jt ju jv nl jx jy jz nm kb kc kd hb bi translated">超过平均值的三个标准偏差阈值的训练数据残差被丢弃。这个做过一次。相对于逐个调查每个异常，这是一种权宜之计。这可能会引起一些人的争议(我们<em class="nn">可能会</em>删除非常重要的数据)，这也是一个旋转木马。丢弃最差的会改变误差分布，因此新的误差可能会落在阈值之外！我的建议是进行实验，看看什么可以改善训练数据的交叉验证结果。忽略异常也可能带来好的结果！</p><p id="f221" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">处理异常的更安全的方法是逐个检查，使用专家判断来确定它是否是真正的异常值。数据集中的一辆卡车实际上是一辆起重机，因此可以安全地放下。</p><p id="7583" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在测试数据中，只有看起来像真正离群值的异常可能会被丢弃。不要通过简单地从测试数据中丢弃不好的预测来扭曲模型的泛化性能。</p><p id="51db" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">为了加强项目纪律，<strong class="jk hu">没有从测试数据</strong>中删除异常值。下图中异常值的长尾包括改装车辆。例如，第三和第五大LightGBM异常值是Chip Foose改装和Roush增压车辆。如果我们能捕捉到从卡车升降机到增压器的售后改装，我们的模型将会改进。</p><h2 id="f019" class="km kn ht bd ko kp kq kr ks kt ku kv kw jr kx ky kz jv la lb lc jz ld le lf lg bi translated">修剪特征实验</h2><p id="d277" class="pw-post-body-paragraph ji jj ht jk b jl lh iu jn jo li ix jq jr lj jt ju jv lk jx jy jz ll kb kc kd hb bi translated">排列重要性表明模型修剪是最重要的特征之一。我们能把功能做得更好吗？</p><p id="c238" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这里有两个想法。我们看到一辆叫做野马GT跑车的车。我们是否应该有最多<strong class="jk hu">两个</strong>饰件，“GT”和“Coupe”(野马_GTCoupe)而不是最多一个？这是一个最大值，因为可能会发现一个或“没有”微调。</p><p id="79ae" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">我们是否应该按字母顺序排列Trim，以便将Mustang_GTCoupe和Mustang_CoupeGT组合在一起？</p><pre class="me mf mg mh fd mi lp mj mk aw ml bi"><span id="a0e8" class="km kn ht lp b fi mm mn l mo mp">maxi_trims_used = 1 or 2</span><span id="b12d" class="km kn ht lp b fi mq mn l mo mp">alphabetize = True or False</span></pre><p id="26e9" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">原来改变修剪顺序会丢弃信息。模型性能变差。</p><p id="6558" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">如果<code class="du lm ln lo lp b">maxi_trims_used</code>变为2，则产生新的残差分布和新的可疑异常值。五分之一的数据被丢弃。发生丢弃是因为较少的修剪满足40个Model_Trim示例的最小样本阈值。</p><p id="4c38" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">当在交叉验证中测量时，最大两个调整模型的美元MAE可变性稍小。相比之下，one Trim模型保留更多的数据，并预测更多的微调。最终的模型坚持一个修剪。</p><h2 id="46d1" class="km kn ht bd ko kp kq kr ks kt ku kv kw jr kx ky kz jv la lb lc jz ld le lf lg bi translated">模型噪音和限制</h2><p id="6235" class="pw-post-body-paragraph ji jj ht jk b jl lh iu jn jo li ix jq jr lj jt ju jv lk jx jy jz ll kb kc kd hb bi translated">到目前为止，我们确定了两个噪声源:(1)具有干净标题的受损汽车和(2)在不同修整水平上固定的里程和位移特征。另外三个来源是(1)售后改装未被捕获。一辆950马力的野马；(2)坏数据；以及(3)缺少修剪。</p><p id="8365" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">售后改装很难捕捉到特征。车辆“抬”的是怪物卡车吗？或者，它是一个举升门或轮椅升降机？与库存版本相比，怪物升降机价格大幅上涨。标记“怪物电梯”的电梯功能在最终模型中被省略了，因为它很难有效地实现。</p><p id="4f35" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">有些数据看起来很糟糕，但无法证明是错误的。比如有一辆1998年的福特F-150，只有22500英里。没有车辆识别号来验证里程。这是测试数据残差图中的一个异常。</p><p id="11d7" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">最后，缺失会降低算法性能。某些卖家忽略了修剪，因此修剪值为“无”。在美国，同型号汽车的装饰价格相差几千美元。这是材料差价。</p><h2 id="a847" class="km kn ht bd ko kp kq kr ks kt ku kv kw jr kx ky kz jv la lb lc jz ld le lf lg bi translated">哪款比较好？</h2><p id="c7fe" class="pw-post-body-paragraph ji jj ht jk b jl lh iu jn jo li ix jq jr lj jt ju jv lk jx jy jz ll kb kc kd hb bi translated">如果LightGBM误差低于线性回归误差，那么LightGBM就是更好的独立模型，对吗？没那么快。</p><p id="6464" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">LightGBM中的<strong class="jk hu">平均</strong>误差更低。但是，这个汇总统计并没有说明模型误差的<strong class="jk hu">离差</strong>。也许预测接近75%的时间，误差被大的异常值抬高了？数据重叠的误差箱线图说明了预测的准确性。请参见下面的箱线图。</p><p id="81a3" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">蓝框包含25–75%的百分位数范围，称为四分位数范围(IQR)。将蓝框一分为二的垂直线是中值误差。蓝框两侧的两条垂直线是“胡须”,表示以下内容:</p><ul class=""><li id="f1d1" class="lq lr ht jk b jl jm jo jp jr ls jv lt jz lu kd lv lw lx ly bi translated">最大值=四分位数3 + 1.5*IQR</li><li id="d58b" class="lq lr ht jk b jl lz jo ma jr mb jv mc jz md kd lv lw lx ly bi translated">最小值=四分位数1-1.5*IQR</li></ul><figure class="me mf mg mh fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es no"><img src="../Images/35f190534be590f9183593fe57ba1817.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MqaKgiXYpKQH1Ul-TE49mw.png"/></div></div><figcaption class="ms mt et er es mu mv bd b be z dx translated">测试误差箱线图</figcaption></figure><p id="c815" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">最大值和最小值之外的数据点是可疑的异常值。</p><p id="b23a" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">对于这两个模型，我们看到一半的测试预测，那些低于中位数的，是体面的。它们在两千美元以内。但是，超过最大晶须的预测是不好的！对于线性模型，最高约为7800美元。箱线图显示LightGBM是更好的模型。</p><h2 id="0b35" class="km kn ht bd ko kp kq kr ks kt ku kv kw jr kx ky kz jv la lb lc jz ld le lf lg bi translated">异常残差和特征工程</h2><p id="fa6b" class="pw-post-body-paragraph ji jj ht jk b jl lh iu jn jo li ix jq jr lj jt ju jv lk jx jy jz ll kb kc kd hb bi translated">LightGBM模型做出了许多很好的预测，但是超过第三个四分位数(75%)的预测(误差超过2400美元)在商业环境中没有用。</p><p id="ab23" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">此外，还存在可疑异常值的长尾。十个最大的LightGBM异常中有七个是F-150卡车。F-150卡车有许多配置选项和售后改装。如前所述，有Foose改进的F-150和Roush增压野马。请记住，测试数据中没有离群值。</p><p id="a744" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">前两个异常的标题暗示有些不对劲:“2018款福特F-150 F150 F 150 XLT——中西部排名第一的二手车经销商！!"<strong class="jk hu">子位置</strong>栏写着“明尼苏达州卡车总部”。虽然卡车在houston.craigslist.org上市，这两个上市是明尼苏达州！这证明我们需要一个更好的位置特征，比如卖家的纬度和经度。</p><p id="c1d0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">对于非结构化数据和售后改装，正确的特征工程是很困难的。</p><p id="d9a0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">尽管测试数据异常，LightGBM MAE在+/-1900美元以内。</p><h2 id="f70e" class="km kn ht bd ko kp kq kr ks kt ku kv kw jr kx ky kz jv la lb lc jz ld le lf lg bi translated">结论</h2><p id="db28" class="pw-post-body-paragraph ji jj ht jk b jl lh iu jn jo li ix jq jr lj jt ju jv lk jx jy jz ll kb kc kd hb bi translated">准确完整的数据对于高质量的预测至关重要。它回避了我们遇到的一些建模问题。勤奋的特征工程可以改进模型。但是，这些特征可能很难提取。</p><p id="3e79" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这些文章为读者提供了收集、准备和评估数据的真实感受。数据有许多问题:遗漏，重复，错误的数据，以及更小粒度的位移和MPG数据。好消息是真实世界的数据很有启发性！习惯于玩具数据的读者可以一窥真实世界的建模挑战。</p></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><p id="5ff0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><em class="nn">我欢迎反馈！联系我的最好方式是发表评论。在LinkedIn上私信我:</em><a class="ae ke" href="http://www.linkedin.com/in/justinmackie" rel="noopener ugc nofollow" target="_blank"><em class="nn">http://www.linkedin.com/in/justinmackie</em></a></p><h2 id="b675" class="km kn ht bd ko kp kq kr ks kt ku kv kw jr kx ky kz jv la lb lc jz ld le lf lg bi translated"><strong class="ak">尾注:</strong></h2><p id="e154" class="pw-post-body-paragraph ji jj ht jk b jl lh iu jn jo li ix jq jr lj jt ju jv lk jx jy jz ll kb kc kd hb bi translated">[1]机器学习专家Aurélien Géron在<em class="nn">用Scikit-Learn动手进行机器学习中的建议，Keras &amp; TensorFlow </em>，第758页。这本易懂的书是一个极好的资源。</p><p id="e554" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">[2]所有欺诈的计数为(真阳性+假阴性)。相比之下，真阴性和假阳性都是合法交易！当然，真正的肯定是正确的欺诈预测。</p><p id="6166" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">[3]残差来自LightGBM。对于最佳的线性回归预测，回归残差应单独分析，并单独丢弃。无论如何，回归都将是最糟糕的模型。跳过了独立的回归管道，因此视觉效果使用一致的数据！</p></div></div>    
</body>
</html>