<html>
<head>
<title>Gaussian Mixture Models with TensorFlow Probability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有张量流概率的高斯混合模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/gaussian-mixture-models-with-tensorflow-probability-125315891c22?source=collection_archive---------1-----------------------#2020-06-27">https://medium.com/analytics-vidhya/gaussian-mixture-models-with-tensorflow-probability-125315891c22?source=collection_archive---------1-----------------------#2020-06-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="c188" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">关于张量流概率高斯混合模型的注记。</h2></div><blockquote class="ix iy iz"><p id="dd67" class="ja jb jc jd b je jf ij jg jh ji im jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">在<a class="ae jx" href="https://en.wikipedia.org/wiki/Probability_theory" rel="noopener ugc nofollow" target="_blank">概率论</a>中，一个<strong class="jd hj">正态</strong>(或<strong class="jd hj">高斯</strong>或<strong class="jd hj">高斯</strong>或<strong class="jd hj">拉普拉斯–高斯</strong> ) <strong class="jd hj">分布</strong>是一个<a class="ae jx" href="https://en.wikipedia.org/wiki/Real_number" rel="noopener ugc nofollow" target="_blank">实值</a> <a class="ae jx" href="https://en.wikipedia.org/wiki/Random_variable" rel="noopener ugc nofollow" target="_blank">随机变量</a>的一种<a class="ae jx" href="https://en.wikipedia.org/wiki/Continuous_probability_distribution" rel="noopener ugc nofollow" target="_blank">连续概率分布</a>。—维基百科</p></blockquote><h1 id="1cb7" class="jy jz hi bd ka kb kc kd ke kf kg kh ki io kj ip kk ir kl is km iu kn iv ko kp bi translated">内容</h1><ol class=""><li id="d23d" class="kq kr hi jd b je ks jh kt ku kv kw kx ky kz jw la lb lc ld bi translated">统计数字</li><li id="3156" class="kq kr hi jd b je le jh lf ku lg kw lh ky li jw la lb lc ld bi translated">高斯的</li><li id="907b" class="kq kr hi jd b je le jh lf ku lg kw lh ky li jw la lb lc ld bi translated">多元高斯</li><li id="03f6" class="kq kr hi jd b je le jh lf ku lg kw lh ky li jw la lb lc ld bi translated">高斯混合模型</li><li id="1fd1" class="kq kr hi jd b je le jh lf ku lg kw lh ky li jw la lb lc ld bi translated">多元高斯混合模型</li><li id="56f2" class="kq kr hi jd b je le jh lf ku lg kw lh ky li jw la lb lc ld bi translated">条件高斯混合模型</li></ol><h1 id="90de" class="jy jz hi bd ka kb kc kd ke kf kg kh ki io kj ip kk ir kl is km iu kn iv ko kp bi translated">属国</h1><p id="dfe6" class="pw-post-body-paragraph ja jb hi jd b je ks ij jg jh kt im jj ku lj jm jn kw lk jq jr ky ll ju jv jw hb bi translated">所需的依赖项是Python 3.8、Numpy、Pandas、Matplotlib、TensorFlow和Tensorflow-Probability。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="e5ef" class="lv jz hi lr b fi lw lx l ly lz">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from mpl_toolkits import mplot3d<br/>import scipy<br/>import tensorflow as tf<br/>import tensorflow_probability as tfp<br/>tfd = tfp.distributions</span></pre><h1 id="a4a7" class="jy jz hi bd ka kb kc kd ke kf kg kh ki io kj ip kk ir kl is km iu kn iv ko kp bi translated">统计数字</h1><p id="3e9a" class="pw-post-body-paragraph ja jb hi jd b je ks ij jg jh kt im jj ku lj jm jn kw lk jq jr ky ll ju jv jw hb bi translated">所需的统计数据有:平均值、协方差、对角线和标准偏差。我们首先生成X，一个2D数组，然后使用Numpy方法将统计数据与所使用的参数进行比较。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="eefc" class="lv jz hi lr b fi lw lx l ly lz">np.random.seed(0)  # random seed</span><span id="d265" class="lv jz hi lr b fi ma lx l ly lz">mu = [0,1]<br/>cov = [[2,0],<br/>       [0,2]]<br/>X = np.random.multivariate_normal(mu, cov, size=100)</span><span id="23eb" class="lv jz hi lr b fi ma lx l ly lz">X_mean = np.mean(X, axis=0)<br/>X_cov = np.cov(X, rowvar=0)<br/>X_diag = np.diag(X_cov)<br/>X_stddev = np.sqrt(X_diag)</span><span id="bb4c" class="lv jz hi lr b fi ma lx l ly lz"># X_mean<br/>[-9.57681805e-04  1.14277867e+00]</span><span id="7695" class="lv jz hi lr b fi ma lx l ly lz"># X_cov<br/>[[ 1.05494742 -0.02517201]<br/> [-0.02517201  1.04230397]]</span><span id="a1b0" class="lv jz hi lr b fi ma lx l ly lz"># X_diag<br/>[1.05494742 1.04230397]</span><span id="9ec3" class="lv jz hi lr b fi ma lx l ly lz"># X_stddev<br/>[1.02710633 1.02093289]</span></pre><p id="87d5" class="pw-post-body-paragraph ja jb hi jd b je jf ij jg jh ji im jj ku jl jm jn kw jp jq jr ky jt ju jv jw hb bi translated">请注意，从X计算出的平均值和协方差的值与指定用于生成X的参数相当。<code class="du mb mc md lr b">np.cov</code>使用参数<code class="du mb mc md lr b">rowvar=0</code>将样本行转换为变量行，以计算协方差矩阵。<code class="du mb mc md lr b">np.diag</code>获得对角线，即协方差矩阵的方差。<code class="du mb mc md lr b">np.sqrt</code>将获得对角线的标准差。</p><h1 id="b121" class="jy jz hi bd ka kb kc kd ke kf kg kh ki io kj ip kk ir kl is km iu kn iv ko kp bi translated">高斯的</h1><p id="85f9" class="pw-post-body-paragraph ja jb hi jd b je ks ij jg jh kt im jj ku lj jm jn kw lk jq jr ky ll ju jv jw hb bi translated">高斯分布由其概率密度函数定义:</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="3883" class="lv jz hi lr b fi lw lx l ly lz">p(x) = 1/(sigma*sqrt(2*pi))*e^(-1/2*((x-mu)/sigma)²)</span></pre><div class="lm ln lo lp fd ab cb"><figure class="me mf mg mh mi mj mk paragraph-image"><img src="../Images/b5bd14b91c7fbdebbbe6ea9a0ffe26a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/0*1iCAS11CaTEy8eSH.png"/></figure><figure class="me mf mg mh mi mj mk paragraph-image"><img src="../Images/8433f0bc7bd992c57212b86c04b5ec98.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/0*xupxPFmWJEWdXpG1.png"/><figcaption class="mn mo et er es mp mq bd b be z dx mr di ms mt translated">高斯分布:概率密度函数(左)和累积分布函数(右)</figcaption></figure></div><h1 id="c4f9" class="jy jz hi bd ka kb kc kd ke kf kg kh ki io kj ip kk ir kl is km iu kn iv ko kp bi translated">多元高斯</h1><p id="383c" class="pw-post-body-paragraph ja jb hi jd b je ks ij jg jh kt im jj ku lj jm jn kw lk jq jr ky ll ju jv jw hb bi translated">多变量高斯可以使用<code class="du mb mc md lr b">tfd.MultivariateNormalFullCovariance</code>建模，通过<code class="du mb mc md lr b">loc</code>和<code class="du mb mc md lr b">covariance_matrix</code>参数化。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="e0bd" class="lv jz hi lr b fi lw lx l ly lz">mvn = tfd.MultivariateNormalFullCovariance(<br/> loc=X_mean,<br/> covariance_matrix=X_cov)</span><span id="cbbf" class="lv jz hi lr b fi ma lx l ly lz">mvn_mean = mvn.mean().numpy()<br/>mvn_cov = mvn.covariance().numpy()<br/>mvn_stddev = mvn.stddev().numpy()</span><span id="6397" class="lv jz hi lr b fi ma lx l ly lz"># mvn_mean<br/>[-0.00135437  1.20191953]</span><span id="e839" class="lv jz hi lr b fi ma lx l ly lz"># mvn_cov<br/>[[ 2.10989483 -0.05034403]<br/> [-0.05034403  2.08460795]]</span><span id="3403" class="lv jz hi lr b fi ma lx l ly lz"># mvn_stddev<br/>[1.4525477  1.44381714]</span></pre><p id="5c1a" class="pw-post-body-paragraph ja jb hi jd b je jf ij jg jh ji im jj ku jl jm jn kw jp jq jr ky jt ju jv jw hb bi translated">但是，<code class="du mb mc md lr b">tfd.MultivariateNormalFullCovariance</code>将被弃用，应使用<code class="du mb mc md lr b">MultivariateNormalTril(loc=loc, scale_tril=tf.linalg.cholesky(covariance_matrix))</code>来代替。正定矩阵(如协方差矩阵)的乔莱斯基分解可以解释为正定矩阵[ <a class="ae jx" href="http://www.seas.ucla.edu/~vandenbe/133A/lectures/chol.pdf" rel="noopener ugc nofollow" target="_blank"> 1 </a> ][ <a class="ae jx" href="http://ais.informatik.uni-freiburg.de/teaching/ws12/mapping/pdf/slam05-ukf.pdf" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]的“平方根”。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="4425" class="lv jz hi lr b fi lw lx l ly lz"># Due to deprecated MultivariateNormalFullCovariance<br/>mvn = tfd.MultivariateNormalTriL(<br/> loc=X_mean,<br/> scale_tril=tf.linalg.cholesky(X_cov))</span><span id="a4be" class="lv jz hi lr b fi ma lx l ly lz">mvn_mean = mvn.mean().numpy()<br/>mvn_cov = mvn.covariance().numpy()<br/>mvn_stddev = mvn.stddev().numpy()</span><span id="78e3" class="lv jz hi lr b fi ma lx l ly lz"># mvn_mean<br/>[-0.00135437  1.20191953]</span><span id="60ef" class="lv jz hi lr b fi ma lx l ly lz"># mvn_cov<br/>[[ 2.10989483 -0.05034403]<br/> [-0.05034403  2.08460795]]</span><span id="bdb3" class="lv jz hi lr b fi ma lx l ly lz"># mvn_stddev<br/>[1.4525477  1.44381714]</span></pre><p id="8dcb" class="pw-post-body-paragraph ja jb hi jd b je jf ij jg jh ji im jj ku jl jm jn kw jp jq jr ky jt ju jv jw hb bi translated">可以为<code class="du mb mc md lr b">tfd.MultivariateNormalDiag</code>指定标准偏差，而不是指定协方差矩阵。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="863d" class="lv jz hi lr b fi lw lx l ly lz">mvn = tfd.MultivariateNormalDiag(<br/> loc=X_mean,<br/> scale_diag=X_stddev)</span><span id="40c8" class="lv jz hi lr b fi ma lx l ly lz">mvn_mean = mvn.mean().numpy()<br/>mvn_cov = mvn.covariance().numpy()<br/>mvn_stddev = mvn.stddev().numpy()</span><span id="c920" class="lv jz hi lr b fi ma lx l ly lz"># mvn_mean<br/>[-0.00135437  1.20191953]</span><span id="3bf5" class="lv jz hi lr b fi ma lx l ly lz"># mvn_cov<br/>[[2.10989483 0.        ]<br/> [0.         2.08460795]]</span><span id="2835" class="lv jz hi lr b fi ma lx l ly lz"># mvn_stddev<br/>[1.4525477  1.44381714]</span></pre><p id="01ac" class="pw-post-body-paragraph ja jb hi jd b je jf ij jg jh ji im jj ku jl jm jn kw jp jq jr ky jt ju jv jw hb bi translated">为了显示多元高斯的概率密度函数，可以使用<code class="du mb mc md lr b">plt.contour</code>。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="710f" class="lv jz hi lr b fi lw lx l ly lz">x1, x2 = np.meshgrid(X[:,0], X[:,1])</span><span id="d3fc" class="lv jz hi lr b fi ma lx l ly lz">data = np.stack((x1.flatten(), x2.flatten()), axis=1)<br/>prob = mvn.prob(data).numpy()</span><span id="8504" class="lv jz hi lr b fi ma lx l ly lz">ax = plt.axes(projection='3d')<br/>ax.plot_surface(x1, x2, prob.reshape(x1.shape), cmap='viridis')<br/>plt.show()</span></pre><figure class="lm ln lo lp fd mf er es paragraph-image"><div class="er es mu"><img src="../Images/6fda469336507b9e63c585331928cb8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*WHEK0OAoUSVaCDV3duJlbw.png"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated">多元高斯的概率密度函数</figcaption></figure><h1 id="2bc7" class="jy jz hi bd ka kb kc kd ke kf kg kh ki io kj ip kk ir kl is km iu kn iv ko kp bi translated">高斯混合模型</h1><p id="3fad" class="pw-post-body-paragraph ja jb hi jd b je ks ij jg jh kt im jj ku lj jm jn kw lk jq jr ky ll ju jv jw hb bi translated">高斯混合模型(GMM)是高斯混合模型，每个高斯模型由μ_ k和σ_ k参数化，并与每个分量权重θ_ k线性组合，总和为1。GMM可以通过其概率密度函数来定义:</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="0901" class="lv jz hi lr b fi lw lx l ly lz">p(x)=sum(theta*N(x|mu,sigma))</span></pre><p id="b18a" class="pw-post-body-paragraph ja jb hi jd b je jf ij jg jh ji im jj ku jl jm jn kw jp jq jr ky jt ju jv jw hb bi translated">取由<code class="du mb mc md lr b">pi=[0.2,0.3,0.5]</code>、<code class="du mb mc md lr b">mu=[10,20,30]</code>和<code class="du mb mc md lr b">sigma=[1,2,3]</code>参数化的高斯混合。分类分布<code class="du mb mc md lr b">tfd.Categorical(probs=pi)</code>是一种离散概率分布，它模拟一个随机变量，该变量取K个可能类别中的一个。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="2d4d" class="lv jz hi lr b fi lw lx l ly lz">pi = np.array([0.2, 0.3, 0.5], dtype=np.float32)<br/>mu = np.array([10, 20, 30], dtype=np.float32)<br/>sigma = np.array([1, 2, 3], dtype=np.float32)</span><span id="acf6" class="lv jz hi lr b fi ma lx l ly lz">gmm = tfd.Mixture(<br/>    cat=tfd.Categorical(probs=pi),<br/>    components=[tfd.Normal(loc=m, scale=s) for m, s in zip(mu, sigma)]<br/>)</span><span id="6c1e" class="lv jz hi lr b fi ma lx l ly lz">x = np.linspace(0, 40, 100)<br/>plt.plot(x, gmm.prob(x).numpy());</span><span id="f2a7" class="lv jz hi lr b fi ma lx l ly lz">print(gmm.mean().numpy())  # 23.0</span></pre><figure class="lm ln lo lp fd mf er es paragraph-image"><div class="er es mv"><img src="../Images/ca36877d54e453d7fb114b54c019c9b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*231-_w492HBEiz-XmQptZQ.png"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated">混合高斯分布的概率密度函数</figcaption></figure><p id="d61e" class="pw-post-body-paragraph ja jb hi jd b je jf ij jg jh ji im jj ku jl jm jn kw jp jq jr ky jt ju jv jw hb bi translated"><code class="du mb mc md lr b">tfd.MixtureSameFamily</code>允许定义相同系列分布的混合模型，无需for循环。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="d965" class="lv jz hi lr b fi lw lx l ly lz">gmm = tfd.MixtureSameFamily(<br/>    mixture_distribution=tfd.Categorical(probs=pi),<br/>    components_distribution=tfd.Normal(loc=mu, scale=sigma)<br/>)</span><span id="1a1c" class="lv jz hi lr b fi ma lx l ly lz">gmm.mean().numpy()  # 23.0</span></pre><h1 id="a5f0" class="jy jz hi bd ka kb kc kd ke kf kg kh ki io kj ip kk ir kl is km iu kn iv ko kp bi translated">多元高斯混合模型</h1><p id="b9c3" class="pw-post-body-paragraph ja jb hi jd b je ks ij jg jh kt im jj ku lj jm jn kw lk jq jr ky ll ju jv jw hb bi translated">通过将<code class="du mb mc md lr b">tfd.MixtureSameFamily</code>与<code class="du mb mc md lr b">tfd.MultivariateNormalDiag</code>结合使用张量流概率，可以实现多元高斯混合模型。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="77b8" class="lv jz hi lr b fi lw lx l ly lz">pi = np.array([0.2, 0.3, 0.5], dtype=np.float32)<br/>mu = np.array([[10, 10],<br/>               [20, 20],<br/>               [30, 30]], dtype=np.float32)<br/>sigma = np.array([[1, 1],<br/>                  [2, 2],<br/>                  [3, 3]], dtype=np.float32)</span><span id="47c6" class="lv jz hi lr b fi ma lx l ly lz">mvgmm = tfd.MixtureSameFamily(<br/>    mixture_distribution=tfd.Categorical(probs=pi),<br/>    components_distribution=tfd.MultivariateNormalDiag(<br/>        loc=mu,<br/>        scale_diag=sigma)<br/>)</span><span id="2805" class="lv jz hi lr b fi ma lx l ly lz">x = np.linspace(5, 35, 100)<br/>y = np.linspace(5, 35, 100)<br/>x, y = np.meshgrid(x, y)</span><span id="b4bc" class="lv jz hi lr b fi ma lx l ly lz">data = np.stack((x.flatten(), y.flatten()), axis=1)<br/>prob = mvgmm.prob(data).numpy()</span><span id="65cf" class="lv jz hi lr b fi ma lx l ly lz">ax = plt.axes(projection='3d')<br/>plt.contour(x, y, prob.reshape((100, 100)));<br/>ax.plot_surface(x, y, prob.reshape((100,100)), cmap='viridis');</span></pre><figure class="lm ln lo lp fd mf er es paragraph-image"><div class="er es mu"><img src="../Images/6f4bd0cb7aa76083a18e438cf8dded52.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*a2bUPjzOPeIvhnQoaETVDA.png"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated">多元高斯混合的概率密度函数</figcaption></figure><h1 id="680b" class="jy jz hi bd ka kb kc kd ke kf kg kh ki io kj ip kk ir kl is km iu kn iv ko kp bi translated">条件多元高斯</h1><p id="b00f" class="pw-post-body-paragraph ja jb hi jd b je ks ij jg jh kt im jj ku lj jm jn kw lk jq jr ky ll ju jv jw hb bi translated">不幸的是，TensorFlow-Probability不支持在给定x的选定特征的情况下获得条件分布和边际分布。我们可以通过扩展<code class="du mb mc md lr b">tfd.MultivariateNormalTriL</code>自己实现这一点。</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="8120" class="lv jz hi lr b fi lw lx l ly lz">def invert_indices(n_features, indices):<br/>    inv = np.ones(n_features, dtype=np.bool)<br/>    inv[indices] = False<br/>    inv, = np.where(inv)<br/>    return inv</span><span id="d9f2" class="lv jz hi lr b fi ma lx l ly lz">class ConditionalMultivariateNormal(tfd.MultivariateNormalTriL):<br/>    def parameters(self):<br/>        covariances = self.covariance()<br/>        means = self.loc<br/>        return means, covariances<br/>    <br/>    def condition(self, i2, x):<br/>        mu, cov = self.loc, self.covariance()<br/>        i1 = invert_indices(mu.shape[0], indices)<br/>        <br/>        cov_12 = tf.gather(tf.gather(cov, i1, axis=0), i2, axis=1)<br/>        cov_11 = tf.gather(tf.gather(cov, i1, axis=0), i1, axis=1)<br/>        cov_22 = tf.gather(tf.gather(cov, i2, axis=0), i2, axis=1)<br/>        <br/>        prec_22 = tf.linalg.pinv(cov_22)<br/>        regression_coeffs = tf.tensordot(cov_12, prec_22, axes=1)<br/>        <br/>        mean = tf.gather(mu, i1, axis=0)<br/>        diff = tf.transpose(x - tf.gather(mu, i2, axis=0))<br/>        mean += tf.transpose(tf.tensordot(regression_coeffs, diff, axes=1))<br/>        <br/>        covariance = cov_11 - tf.tensordot(regression_coeffs, tf.transpose(cov_12), axes=0)<br/>        return ConditionalMultivariateNormal(loc=mean, scale_tril=tf.linalg.cholesky(covariance))</span><span id="ad82" class="lv jz hi lr b fi ma lx l ly lz">    def marginalize(self, indices):<br/>        mu, cov = self.loc, self.covariance()<br/>        return ConditionalMultivariateNormal(loc=mu.numpy()[indices], scale_tril=tf.linalg.cholesky(cov.numpy()[np.ix_(indices, indices)]))<br/></span><span id="6a62" class="lv jz hi lr b fi ma lx l ly lz"># Conditional Distribution P(X1|X0)<br/>mvn = ConditionalMultivariateNormal(<br/>    loc=X_mean,<br/>    scale_tril=tf.linalg.cholesky(X_cov))</span><span id="a8c4" class="lv jz hi lr b fi ma lx l ly lz">x = np.array([2])<br/>indices = np.array([1])</span><span id="08f5" class="lv jz hi lr b fi ma lx l ly lz">conditional_mvn = mvn.condition(indices, x)<br/>marginal_mvn = mvn.marginalize(indices)</span><span id="f39b" class="lv jz hi lr b fi ma lx l ly lz">print(conditional_mvn.sample().numpy())<br/>print(marginal_mvn.sample().numpy())</span><span id="60dd" class="lv jz hi lr b fi ma lx l ly lz"># Conditional MVN sample<br/>[[[[1.60346902]]]<br/> [[[0.70901248]]]<br/> [[[0.68173244]]]]</span><span id="5cba" class="lv jz hi lr b fi ma lx l ly lz"># Marginal MVN sample<br/>[[-0.22300554]<br/> [ 2.69431439]<br/> [-0.52467359]]</span></pre></div></div>    
</body>
</html>