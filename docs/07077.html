<html>
<head>
<title>Getting Started Spark 3.0.0 in Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Google Colab中开始使用Spark 3.0.0</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/getting-started-spark3-0-0-with-google-colab-9796d350d78?source=collection_archive---------3-----------------------#2020-06-13">https://medium.com/analytics-vidhya/getting-started-spark3-0-0-with-google-colab-9796d350d78?source=collection_archive---------3-----------------------#2020-06-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/5a0f8a89558855a9b5297cf75cb02721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*IobDaguistYWWuGwrlmbhA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">由马拉扎设计，使用了www.canva.com的<a class="ae iq" href="http://www.canva.com" rel="noopener ugc nofollow" target="_blank">和谷歌图片中的图片</a></figcaption></figure><p id="e5fd" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi jp translated"><span class="l jq jr js bm jt ju jv jw jx di"> A </span> pache Spark是一个闪电般快速的集群计算系统，解决了以前最受欢迎的Map Reduce系统对大型数据集的限制。它是数据科学家和机器学习工程师处理大数据问题的首选框架。Spark engine是用Scala编写的，Scala被认为是可伸缩计算的首选语言。然而，Apache Spark提供了Java、Scala、Python和r的高级API。作为一名数据科学家<code class="du jy jz ka kb b">pyspark</code>是我利用Spark并行和分布式处理的首选API。这可能是一种偏见，但是你可以选择适合你的应用程序的API。</p><p id="43a4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">根据<a class="ae iq" href="https://www.kdnuggets.com/2018/10/apache-spark-introduction-beginners.html" rel="noopener ugc nofollow" target="_blank"> Apache Spark新手入门</a></p><blockquote class="kc kd ke"><p id="0398" class="ir is kf it b iu iv iw ix iy iz ja jb kg jd je jf kh jh ji jj ki jl jm jn jo hb bi translated">Spark是Hadoop的子项目之一，由Matei Zaharia于2009年在加州大学伯克利分校的AMPLab创建。它于2010年在BSD许可下开源。它在2013年被交给了Apache programming establishment，现在Apache Spark已经从2014年2月变成了最好的Apache venture。现在结果非常好。</p></blockquote><p id="26c3" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">今年，spark将庆祝作为一个开源项目的10周年纪念。在过去10年中，spark成为利用并行和分布式计算框架进行大数据处理的事实上的选择。</p><p id="e249" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在2020年6月10日通过投票后，Spark 3.0.0于2020年6月18日发布。不过，Spark 3.0.0的预览版是在2019年末发布的。</p><p id="34dc" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj"> <em class="kf"> Spark 3.0大概比Spark 2.4快两倍。</em>T11】</strong></p><p id="9f92" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">对于数据科学家和机器学习工程师来说，<code class="du jy jz ka kb b">pyspark and MLlib</code>是Apache Spark附带的两个最重要的模块。spark 3.0.0中有大量与上述两个模块相关的新特性。阅读下面发布的说明，了解更多信息。</p><p id="cf57" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><a class="ae iq" href="https://spark.apache.org/releases/spark-release-3-0-0.html" rel="noopener ugc nofollow" target="_blank">基于发布的注释</a></p><blockquote class="kc kd ke"><p id="0b1a" class="ir is kf it b iu iv iw ix iy iz ja jb kg jd je jf kh jh ji jj ki jl jm jn jo hb bi translated">Python现在是Spark上使用最广泛的语言。PySpark在Python包索引PyPI上的月下载量超过500万次。这个版本改进了它的功能和可用性，包括熊猫UDF API重新设计的Python类型提示，新的熊猫UDF类型，以及更多的Python错误处理。</p></blockquote><p id="bb52" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">对于对JVM操作系统了解有限的研究人员来说，设置spark通常被认为是一个复杂而耗时的步骤。在本文中，我将带您快速了解如何在google colab上安装Apache Spark 3.0.0。</p><h2 id="cb9f" class="kj kk hi bd kl km kn ko kp kq kr ks kt jc ku kv kw jg kx ky kz jk la lb lc ld bi translated">安装Apache Spark 3.0.0</h2><p id="85ae" class="pw-post-body-paragraph ir is hi it b iu le iw ix iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo hb bi translated">打开google colab笔记本，使用以下命令安装Java 8，下载并解压<a class="ae iq" href="http://apache.osuosl.org/spark/spark-3.0.0/" rel="noopener ugc nofollow" target="_blank"> Apache Spark 3.0.0 </a>并安装<code class="du jy jz ka kb b">findpyspark</code>。根据您的连接速度，不会超过几分钟。</p><pre class="lj lk ll lm fd ln kb lo lp aw lq bi"><span id="11f6" class="kj kk hi kb b fi lr ls l lt lu"># Run below commands in google colab</span><span id="c011" class="kj kk hi kb b fi lv ls l lt lu"># install Java8<br/>!apt-get install openjdk-8-jdk-headless -qq &gt; /dev/null</span><span id="930d" class="kj kk hi kb b fi lv ls l lt lu"># download spark3.0.0<br/>!wget -q http://apache.osuosl.org/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz</span><span id="d2ce" class="kj kk hi kb b fi lv ls l lt lu"># unzip it<br/>!tar xf spark-3.0.0-bin-hadoop3.2.tgz</span><span id="77bd" class="kj kk hi kb b fi lv ls l lt lu"># install findspark <br/>!pip install -q findspark</span></pre><h2 id="dc6b" class="kj kk hi bd kl km kn ko kp kq kr ks kt jc ku kv kw jg kx ky kz jk la lb lc ld bi translated">设置环境变量</h2><p id="0e11" class="pw-post-body-paragraph ir is hi it b iu le iw ix iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo hb bi translated">一旦执行了上面的命令，就该向环境添加相关的路径了。通过环境变量指向正确的版本，可以管理spark的多个版本。运行下面的命令集，指向之前下载的Apache Spark 3.0.0版本。</p><pre class="lj lk ll lm fd ln kb lo lp aw lq bi"><span id="38e6" class="kj kk hi kb b fi lr ls l lt lu">import os<br/>os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"<br/>os.environ["SPARK_HOME"] = "/content/spark-3.0.0-bin-hadoop3.2"</span></pre><h2 id="cc16" class="kj kk hi bd kl km kn ko kp kq kr ks kt jc ku kv kw jg kx ky kz jk la lb lc ld bi translated">快速安装测试</h2><p id="221b" class="pw-post-body-paragraph ir is hi it b iu le iw ix iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo hb bi translated">现在是时候测试我们的spark安装及其版本了。我们应该可以使用Spark 3.0.0版本和带有3.0.0版本的<code class="du jy jz ka kb b">pyspark </code>。</p><pre class="lj lk ll lm fd ln kb lo lp aw lq bi"><span id="156c" class="kj kk hi kb b fi lr ls l lt lu">import findspark<br/>findspark.init()</span><span id="5fdb" class="kj kk hi kb b fi lv ls l lt lu">from pyspark.sql import SparkSession<br/>spark = SparkSession.builder.master("local[*]").getOrCreate()<br/># Test the spark<br/>df = spark.createDataFrame([{"hello": "world"} for x in range(1000)])<br/>df.show(3, False)</span></pre><p id="1f41" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">要检查<code class="du jy jz ka kb b">pyspark</code>版本，使用下面的一组命令。强烈建议在运行应用程序时始终记录版本。</p><pre class="lj lk ll lm fd ln kb lo lp aw lq bi"><span id="075b" class="kj kk hi kb b fi lr ls l lt lu"># Check the pyspark version<br/>import pyspark<br/>print(pyspark.__version__)</span></pre><h2 id="6ae8" class="kj kk hi bd kl km kn ko kp kq kr ks kt jc ku kv kw jg kx ky kz jk la lb lc ld bi translated">工作Google Colab</h2><p id="b1cf" class="pw-post-body-paragraph ir is hi it b iu le iw ix iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo hb bi translated">我还创建了一个工作谷歌colab，可以在下面找到。</p><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="lw lx l"/></div><figcaption class="im in et er es io ip bd b be z dx translated">作者:M.A .拉扎</figcaption></figure><h2 id="4eed" class="kj kk hi bd kl km kn ko kp kq kr ks kt jc ku kv kw jg kx ky kz jk la lb lc ld bi translated">结论</h2><p id="045e" class="pw-post-body-paragraph ir is hi it b iu le iw ix iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo hb bi translated">在这篇简短的文章中，我们学习了如何在不到两分钟的时间内设置Spark 3.0.0。</p><h2 id="f7c7" class="kj kk hi bd kl km kn ko kp kq kr ks kt jc ku kv kw jg kx ky kz jk la lb lc ld bi translated">参考资料/阅读/链接</h2><ol class=""><li id="5622" class="ly lz hi it b iu le iy lf jc ma jg mb jk mc jo md me mf mg bi translated"><a class="ae iq" href="http://apache.osuosl.org/spark/spark-3.0.0-preview2/" rel="noopener ugc nofollow" target="_blank">http://apache.osuosl.org/spark/spark-3.0.0-preview2/</a></li><li id="24e2" class="ly lz hi it b iu mh iy mi jc mj jg mk jk ml jo md me mf mg bi translated"><a class="ae iq" rel="noopener" href="/@sushantgautam_930/apache-spark-in-google-collaboratory-in-3-steps-e0acbba654e6">https://medium . com/@ sushantgautam _ 930/Apache-spark-in-Google-collaboratory-in-3-steps-E0 acbba 654 e 6</a></li><li id="510b" class="ly lz hi it b iu mh iy mi jc mj jg mk jk ml jo md me mf mg bi translated"><a class="ae iq" href="https://notebooks.gesis.org/binder/jupyter/user/databricks-koalas-kuv5qckt/notebooks/docs/source/getting_started/10min.ipynb" rel="noopener ugc nofollow" target="_blank">https://notebooks . gesis . org/binder/jupyter/user/data bricks-koalas-kuv5 qckt/notebooks/docs/source/getting _ started/10min . ipynb</a></li><li id="a483" class="ly lz hi it b iu mh iy mi jc mj jg mk jk ml jo md me mf mg bi translated"><a class="ae iq" rel="noopener" href="/@sushantgautam_930/apache-spark-in-google-collaboratory-in-3-steps-e0acbba654e6">https://medium . com/@ sushantgautam _ 930/Apache-spark-in-Google-collaboratory-in-3-steps-E0 acbba 654 e 6</a></li><li id="b0e3" class="ly lz hi it b iu mh iy mi jc mj jg mk jk ml jo md me mf mg bi translated">1<a class="ae iq" href="https://towardsdatascience.com/introduction-to-apache-spark-207a479c3001" rel="noopener" target="_blank">https://towards data science . com/introduction-to-Apache-spark-207 a 479 c 3001</a></li><li id="1ac3" class="ly lz hi it b iu mh iy mi jc mj jg mk jk ml jo md me mf mg bi translated"><a class="ae iq" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/</a></li><li id="e74d" class="ly lz hi it b iu mh iy mi jc mj jg mk jk ml jo md me mf mg bi translated"><a class="ae iq" rel="noopener" href="/@amjadraza24/spark-ifying-pandas-databricks-koalas-with-google-colab-93028890db5">https://medium . com/@ amjadraza 24/spark-ifying-pandas-data bricks-koala-with-Google-colab-93028890 db5</a></li></ol></div></div>    
</body>
</html>