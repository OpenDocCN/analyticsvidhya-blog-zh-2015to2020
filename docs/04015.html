<html>
<head>
<title>Learning Generative Adversarial Networks (GANs)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习生成对抗网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/learning-generative-adversarial-networks-gans-6036a612a370?source=collection_archive---------14-----------------------#2020-03-01">https://medium.com/analytics-vidhya/learning-generative-adversarial-networks-gans-6036a612a370?source=collection_archive---------14-----------------------#2020-03-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5573" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2014年，蒙特利尔大学的Ian Goodfellow和其他研究人员在一篇论文中介绍了gan。</p><h1 id="2012" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">甘是什么？</h1><p id="8bff" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">生成对抗网络(GAN)是神经网络中的一种模型，它在机器学习领域提供了很多潜力。在GAN中有两个神经网络:第一个是生成网络，第二个是鉴别网络。所以这个项目背后的主要概念是生成性对抗网络。甘是关于创造的东西，这是很难比较的其他深度学习领域。GAN的主要重点是从零开始生成数据。正如我们所见，早期的GAN由两个网络组成，即发生器和鉴别器。</p><p id="31be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">生成对抗网络(GANs)是由两个网络组成的深度神经网络架构，两个网络相互对抗。</strong></p><p id="92e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">脸书人工智能研究主任Yann LeCun称对抗性训练是“过去10年中最有趣的想法”</strong></p><p id="150e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GANs的潜力非常巨大，因为他们可以学习模仿任何数据。因此，使用GAN，我们可以在任何领域创造与我们相似的世界:图像、动漫、新闻主播、演讲。</p><h1 id="00ad" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">生成算法与判别算法</h1><p id="5778" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">为了理解GANs，我们需要知道生成算法是如何工作的，以及判别算法是如何简洁的，因此判别算法的工作是尝试对数据进行分类。<br/>这种情况的一个标准例子是电子邮件，给定电子邮件中的所有单词，鉴别器所做的是预测该消息是否是垃圾邮件。在这个例子中，垃圾邮件是标签之一，电子邮件的单词是组成输入数据的特征。如果我们把这个问题表述为数学问题，那么标签称为y，特征称为x。公式p (y|x)用于表示“给定x时y的概率”。</p><p id="b258" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成算法试图回答的主要问题是:它们假设这封电子邮件是垃圾邮件，而判别模型关心特征(x)和标签(y)之间的关系。<br/>因此，如果我们考虑生成算法，它们与鉴别器相反。他们不是预测标签，而是预测给定某个标签的特征。<br/>区分生意经和辨别力的最佳方式如下:</p><ul class=""><li id="a2de" class="kg kh hi ih b ii ij im in iq ki iu kj iy kk jc kl km kn ko bi translated">判别模型学习类别之间的范围</li><li id="07a2" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">生成模型对各个类的分布进行建模</li></ul><h1 id="fc09" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">GANs如何工作</h1><p id="fb18" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我们知道这些算法属于无监督学习领域<br/>生成式对抗网络由两个模型组成:</p><p id="f8a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一个模型称为生成器，其目标是生成与真实数据相似的新数据。生成器可以创建数据，鉴别器检查数据是真是假。</p><p id="049b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二个模型叫做鉴别器。该模型的目标是识别输入数据是真的还是假的-属于原始数据集-或者是由生成器生成的假数据。因此，歧视者就像一个警察，试图检测工作是真是假。</p><p id="f2d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当训练开始时，生成器产生假数据，鉴别器很快学会辨别这是假的。</p><p id="3842" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练后，生成模型可用于按需创建新的可信样本。</p><p id="6b20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">gan有非常具体的用例，开始时可能很难理解这些用例。</p><h1 id="ea63" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">这些模型是如何相互作用的？</h1><p id="3b7b" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">在提出这个框架的原始论文中，可以认为生成器有一个对手，即鉴别器。因此，这意味着生成器需要学习如何操作以及如何创建数据，以使鉴别器不再能够区分真假或假的。这两个模型之间的竞争提高了他们的知识，直到生成器创建真实的数据</p><h1 id="a379" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">训练GAN的基本步骤</h1><p id="01f1" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">I .采样噪声集数据和真实数据集。每个尺寸为m。</p><p id="279b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">二。根据这些数据训练鉴别器。</p><p id="7448" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">三。采样大小为m的不同噪声子集</p><p id="043f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">四。根据这些数据训练发电机。</p><p id="d4ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">动词 （verb的缩写）从步骤1开始重复。</p><p id="a431" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">以下是甘采取的步骤:</strong></p><ul class=""><li id="33aa" class="kg kh hi ih b ii ij im in iq ki iu kj iy kk jc kl km kn ko bi translated"><strong class="ih hj">所以生成器接收随机数并返回图像。</strong></li><li id="5719" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated"><strong class="ih hj">生成的图像与实际数据集进行比较，并输入鉴别器。</strong></li><li id="1413" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated"><strong class="ih hj">然后鉴别器获取真实和虚假图像，并像逻辑回归一样返回0和1之间的概率和数字。1代表真，0代表假。</strong></li></ul><p id="6822" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我们有两个反馈回路:</p><ul class=""><li id="2db8" class="kg kh hi ih b ii ij im in iq ki iu kj iy kk jc kl km kn ko bi translated">鉴别器与图像的基本事实处于反馈回路中。</li><li id="be0d" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">发生器与鉴别器在一个反馈回路中。</li></ul><p id="152c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是整个系统的图片:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/5e1d4a2e81a46401dabbf5155998808e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cxnqsjXYP-lx-3afYsuxXQ.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">生成性对抗网络基本图(来源:“Pathmind”)</figcaption></figure><p id="ade0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所见，两者都是动态的。鉴别器网络是一个标准的卷积网络，可以对馈送给它的图像进行分类，生成器是逆卷积网络。</p><p id="40a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">目标函数</strong></p><p id="4350" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GAN被定义为一个极小极大对策，其目标函数如下。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lk"><img src="../Images/10cf364c426f3c4f3dd5b5f9d72a3371.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*pE444QTQTQlmYs9aNPACZQ.jpeg"/></div></figure><h1 id="e838" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">GAN问题</h1><p id="6437" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">许多GAN模型面临一个巨大的问题:</p><p id="2ba2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I .有时模型不能结合非收敛性。<br/>二。发电机崩溃，这就是为什么产生有限的样本数据三的真实性。鉴别器和发生器之间的不平衡导致数据过拟合。对超参数选择高度敏感。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es ll"><img src="../Images/da10d8817749aed5436fea1de038c506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*Q7sZcfRj2M64GDD1ncvoCA.jpeg"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">鉴别器和生成器(来源:“Pathmind”)</figcaption></figure><h1 id="e45d" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">氮化镓的应用</h1><ul class=""><li id="ac13" class="kg kh hi ih b ii kb im kc iq lm iu ln iy lo jc kl km kn ko bi translated">生成人脸照片(Tero Karras等人在其2017年题为“<a class="ae lp" href="https://arxiv.org/abs/1710.10196" rel="noopener ugc nofollow" target="_blank">GANs的渐进增长以提高质量、稳定性和变化</a>”的论文中演示了人脸的可信现实照片的生成。)</li><li id="a37b" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">生成逼真的照片(Andrew Brock等人在其2018年题为“<a class="ae lp" href="https://arxiv.org/abs/1809.11096" rel="noopener ugc nofollow" target="_blank">高保真自然图像合成的大规模GAN训练</a>”的论文中，展示了使用他们的技术BigGAN生成的合成照片，这些照片实际上与真实照片无法区分。)</li><li id="574b" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">生成卡通人物(Jin等人在其2017年题为“<a class="ae lp" href="https://arxiv.org/abs/1708.05509" rel="noopener ugc nofollow" target="_blank">利用生成对抗网络实现自动动漫人物创建</a>”的论文中演示了训练和使用GAN来生成动漫人物(即日本漫画人物)的面部。)</li><li id="b221" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">图像到图像的翻译(Phillip Isola等人在其2016年题为“<a class="ae lp" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank">使用条件对抗网络进行图像到图像的翻译</a>”的论文中演示了GANs，特别是他们用于许多图像到图像翻译任务的pix2pix方法。)<strong class="ih hj">最有趣的论文</strong>——(朱俊彦在他们2017年题为“<a class="ae lp" href="https://arxiv.org/abs/1703.10593" rel="noopener ugc nofollow" target="_blank">使用循环一致的对抗网络进行不成对的图像到图像翻译</a>”的论文中介绍了他们著名的<a class="ae lp" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank">循环根</a>和一系列令人印象深刻的图像到图像翻译示例。)</li></ul><p id="401b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下示例演示了四种图像转换情况:</p><ul class=""><li id="63c3" class="kg kh hi ih b ii ij im in iq ki iu kj iy kk jc kl km kn ko bi translated">从照片到艺术绘画风格的转换。</li><li id="d2ae" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">马到斑马的翻译。</li><li id="65d9" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">照片从夏天到冬天的翻译。</li><li id="0561" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">将卫星照片翻译成谷歌地图视图。</li></ul><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lq"><img src="../Images/5c8074c4bcc8960b63e01736d981b3d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*S5pVSwBh7W-oR1zWyNysBQ.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">2017年使用CycleGANTaken从不配对的图像到图像的翻译执行的四个图像到图像的翻译的例子。(来源:机器学习掌握)</figcaption></figure><ul class=""><li id="4568" class="kg kh hi ih b ii ij im in iq ki iu kj iy kk jc kl km kn ko bi translated">文本到图像的翻译(张寒等人在他们2016年题为“<a class="ae lp" href="https://arxiv.org/abs/1612.03242" rel="noopener ugc nofollow" target="_blank"> StackGAN:利用堆叠生成对抗网络进行文本到照片的逼真图像合成</a>”的论文中演示了GAN的使用，特别是他们的StackGAN从简单对象(如鸟和花)的文本描述中生成逼真的照片。)</li><li id="84cc" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">语义图像到照片的翻译(廷-王春等人在其2017年题为“H <a class="ae lp" href="https://arxiv.org/abs/1711.11585" rel="noopener ugc nofollow" target="_blank">高分辨率图像合成和使用条件甘的语义操作</a>”的论文中，演示了在给定语义图像或草图作为输入的情况下，使用条件甘来生成照片真实感图像。)</li><li id="211d" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">照片到表情符号(Yaniv Taigman等人在2016年发表的题为“<a class="ae lp" href="https://arxiv.org/abs/1611.02200" rel="noopener ugc nofollow" target="_blank">无监督跨域图像生成</a>”的论文中，使用GAN将图像从一个域翻译到另一个域，包括从街道号码到MNIST手写数字，从名人的照片到他们所谓的表情符号或小卡通脸。)</li><li id="6ae3" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">超分辨率(Christian Ledig等人在其2016年题为“<a class="ae lp" href="https://arxiv.org/abs/1609.04802" rel="noopener ugc nofollow" target="_blank">使用生成式对抗网络的照片级单图像超分辨率</a>”的论文中，演示了使用GAN，特别是他们的SRGAN模型，来生成像素分辨率更高，有时高得多的输出图像。)</li><li id="b041" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">视频预测(Carl Vondrick等人在其2016年题为“<a class="ae lp" href="https://arxiv.org/abs/1609.02612" rel="noopener ugc nofollow" target="_blank">生成具有场景动态的视频</a>”的论文中描述了使用GANs进行视频预测，特别是成功预测高达一秒的视频帧，主要针对场景的静态元素。)</li></ul><h1 id="e726" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">摘要</h1><p id="99b6" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">在这篇文章中，你发现了一个温和的介绍生成敌对网络。比如什么是GAN，生成和判别算法，GAN如何工作，模型交互，基本步骤，GAN问题和应用</p><p id="e5a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我的下一篇文章中，我将简要描述定义GAN的数学方法以及提高图像到图像翻译的对抗网络的模型效率和循环一致性的一些步骤。</p><h2 id="0d4d" class="lr je hi bd jf ls lt lu jj lv lw lx jn iq ly lz jr iu ma mb jv iy mc md jz me bi translated">感谢阅读！</h2><p id="6d38" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">随时给我发信息。</p><p id="465a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Twitter:aamirjarda<br/>LinkedIn:aamirjarda<br/>insta gram:aamirjarda</p><p id="e9e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢Sarfaraz Jarda帮助审阅这篇文章！</p><p id="e1cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你有什么问题吗？<br/>在下面的评论里提出你的问题，我会尽力回答。</p></div></div>    
</body>
</html>