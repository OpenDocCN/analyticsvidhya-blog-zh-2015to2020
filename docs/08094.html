<html>
<head>
<title>Image Classification in Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch中的图像分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-classification-in-pytorch-fbaa4f36bf47?source=collection_archive---------7-----------------------#2020-07-17">https://medium.com/analytics-vidhya/image-classification-in-pytorch-fbaa4f36bf47?source=collection_archive---------7-----------------------#2020-07-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c8c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在当今世界，随着海量数据和计算能力的可用性，机器学习获得了比以前更大的动力。数据有多种形式，其中最重要的数据形式之一是图像。</p><p id="82d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">分类是一种ML问题，其中我们有一组数据点，我们将每个点分类或标记到各自的类别中。这样，特定的数据点可以与相邻的点区分开。同样，在图像分类的情况下，我们也将特定的图像分类到其所属的相应类别中。</p><p id="4c95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我们将尝试看看Pytorch中图像分类器的实现。</p><h1 id="db3e" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">Pytorch是什么？</h1><p id="004b" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">PyTorch是一个基于Torch库的开源机器学习库，用于计算机视觉和自然语言处理等应用，主要由脸书的人工智能研究实验室开发。</p><h1 id="3bfb" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">什么是CIFAR10数据集？</h1><p id="2d10" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">它是用于物体识别的已建立的计算机视觉数据集。它是<a class="ae kg" href="http://groups.csail.mit.edu/vision/TinyImages/" rel="noopener ugc nofollow" target="_blank">8000万微小图像数据集</a>的子集，由60，000张32x32彩色图像组成，包含10个对象类中的一个，每个类6000张图像。它由亚历克斯·克里热夫斯基、维诺德·奈尔和杰弗里·辛顿收藏。</p><h1 id="1c5a" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">代码的结构:</h1><ul class=""><li id="e687" class="kh ki hi ih b ii kb im kc iq kj iu kk iy kl jc km kn ko kp bi translated">加载数据集</li><li id="5dd0" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">图像预处理</li><li id="5f2c" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">构建Pytorch模型</li><li id="5c08" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">训练模型</li><li id="d063" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">预测和结果</li></ul><h1 id="1893" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">1.加载数据集</h1><p id="74f0" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">CIFAR-10数据集已经与Pytorch中已经提供的数据集一起提供。要使用数据集，我们需要使用Pytorch导入和加载数据集，如下所示:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="5d09" class="le je hi la b fi lf lg l lh li">#Get the CIFAR10 Dataset</span><span id="774b" class="le je hi la b fi lj lg l lh li">transform = transforms.Compose( [transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</span><span id="3a74" class="le je hi la b fi lj lg l lh li">trainset = torchvision.datasets.CIFAR10(root=’./data’, train=True,download=True, transform=transform)</span><span id="4e47" class="le je hi la b fi lj lg l lh li">trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)<br/>testset = torchvision.datasets.CIFAR10(root=’./data’, train=False,download=True, transform=transform)</span><span id="00b3" class="le je hi la b fi lj lg l lh li">testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False, num_workers=2)</span><span id="a65e" class="le je hi la b fi lj lg l lh li">classes = (‘plane’, ‘car’, ‘bird’, ‘cat’,‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’)</span></pre><h1 id="fb73" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">2.图像预处理</h1><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="6bdf" class="le je hi la b fi lf lg l lh li">import matplotlib.pyplot as plt<br/>import numpy as np</span><span id="c597" class="le je hi la b fi lj lg l lh li"># functions to show an image<br/>def imshow(img):<br/>    img = img / 2 + 0.5 # unnormalize<br/>    npimg = img.numpy()<br/>    plt.imshow(np.transpose(npimg, (1, 2, 0)))<br/>    plt.show()</span><span id="a0e6" class="le je hi la b fi lj lg l lh li"># get some random training images<br/>dataiter = iter(trainloader)<br/>images, labels = dataiter.next()</span><span id="187e" class="le je hi la b fi lj lg l lh li"># show images<br/>imshow(torchvision.utils.make_grid(images))</span><span id="55ec" class="le je hi la b fi lj lg l lh li"># print labels<br/>print(‘ ‘.join(‘%5s’ % classes[labels[j]] for j in range(4)))</span></pre><figure class="kv kw kx ky fd ll er es paragraph-image"><div class="er es lk"><img src="../Images/8efbbbe00728ba7eeb181b45fd9d47b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*HVW9P-p-e2qE5dsaZDV3Lg.png"/></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">数据集的图像</figcaption></figure><h1 id="558e" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">3.构建Pytorch模型</h1><p id="3c35" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">使用Pytorch，我们将尝试建立一个模型，可以对这10类图像进行分类(即飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车)。图像分类模型分为两部分:特征学习和分类器。</p><p id="96c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">特征学习:</strong></p><p id="e85b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型的这一部分处理学习图像的不同特征和特性，以将图像与其他图像区分开来。为了学习这些特性，我们将利用CNN(卷积神经网络)。Pytorch附带卷积2D图层，可通过“torch.nn.conv2d”使用。</p><p id="075e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过卷积层和池层的组合来完成特征学习。一幅图像可以被看作是一个像素矩阵，每个像素都有一个数值来存储该像素内的颜色信息。卷积层利用了一个核心，该核心突出了特定图像中的突出特征/像素。通过只保留那些包含重要信息的像素并拒绝其余的像素，池被用于对该图像进行下采样(即降低尺寸)。池有两种方式:全局平均池和最大池。在这个用例中，我们将利用最大池。</p><figure class="kv kw kx ky fd ll er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/eda06db579717a271d40b1e3e94462c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gkucqChMR9bHesn03WxfZQ.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">卷积层和池层的表示</figcaption></figure><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="6bc5" class="le je hi la b fi lf lg l lh li">self.conv1 = nn.Conv2d(3, 6, 5)</span></pre><p id="c311" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2D卷积层可以用下面的方式来声明。第一个参数表示输入通道的数量，在本例中为3 (R、G和B)。第二个参数表示输出通道的数量，第三个参数表示内核大小，在本例中为5x5。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="45d4" class="le je hi la b fi lf lg l lh li">self.pool = nn.MaxPool2d(2, 2)</span></pre><p id="7467" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">池层定义如下。第一个参数定义了用于选择重要特性的内核大小。</p><p id="7168" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">分类头:</strong></p><p id="197f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">学习到的特征或来自卷积层的输出被传递到展平层，使其成为1D。这然后被馈送到由激活功能ReLU(整流线性单元)激活的线性层。最后一层包含10个节点，因为在这个例子中类的数量是10。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="4162" class="le je hi la b fi lf lg l lh li">self.fc1 = nn.Linear(16 * 5 * 5, 120)</span></pre><p id="43e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性层定义如下，第一个参数表示输入通道的数量，该数量应该等于前一卷积层的输出数量。第二个参数是输出通道的数量。</p><p id="6619" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是用于构建模型的重要层。让我们看一下构建模型的完整代码:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="cf0a" class="le je hi la b fi lf lg l lh li">import torch.nn as nn<br/>import torch.nn.functional as F</span><span id="8a89" class="le je hi la b fi lj lg l lh li">class Net(nn.Module):</span><span id="fdd8" class="le je hi la b fi lj lg l lh li">def __init__(self):<br/>    super(Net, self).__init__()<br/>    self.conv1 = nn.Conv2d(3, 6, 5)<br/>    self.pool = nn.MaxPool2d(2, 2)<br/>    self.conv2 = nn.Conv2d(6, 16, 5)<br/>    self.fc1 = nn.Linear(16 * 5 * 5, 120)<br/>    self.fc2 = nn.Linear(120, 84)<br/>    self.fc3 = nn.Linear(84, 10)</span></pre><p id="8975" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用类网来建立模型。__init__方法用于定义层。创建层定义后，下一步是定义在网络中执行正向传递时，数据如何流经这些层:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="7fc0" class="le je hi la b fi lf lg l lh li">def forward(self, x):<br/>    x = self.pool(F.relu(self.conv1(x)))<br/>    x = self.pool(F.relu(self.conv2(x)))<br/>    x = x.view(-1, 16 * 5 * 5)<br/>    x = F.relu(self.fc1(x))<br/>    x = F.relu(self.fc2(x))<br/>    x = self.fc3(x)<br/>    return x</span></pre><p id="8ed1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型的第一层或输入层是conv1，输出层是fc3。此函数定义了数据在网络中的流动方式—来自输入层conv1的数据由ReLU激活函数(F.relu())激活，然后被传递到定义为pool的池层。第一层的输出存储在变量x中，然后被发送到下一层。在将其发送到分类器之前，最后一个回旋层的输出对于线性层是平坦的。由ReLU激活功能激活的前两个线性层(fc1和fc2)然后将输出发送到最后一个层fc3。</p><h1 id="7360" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak"> 4。训练模型</strong></h1><p id="d121" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">模型的架构现在已经可以使用了，在开始训练过程之前，我们将创建一个Net()类的实例，并设置优化器和损失函数。在这个特殊的问题中，我们将使用学习率为0.001的SGD优化器。学习率定义了模型的好坏或模型拟合的速度。因此，为了防止模型过度拟合，我们将尽量保持较低的值。使用的损失函数是交叉熵，因为这是一个多标签分类问题。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="10dc" class="le je hi la b fi lf lg l lh li">#Define Loss Function and optimizer<br/>import torch.optim as optim<br/>net = Net()<br/>criterion = nn.CrossEntropyLoss()<br/>optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)</span></pre><p id="572e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是训练前编译模型的代码。</p><p id="0bb1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，使用此函数将模型训练到所需的历元数。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="2f04" class="le je hi la b fi lf lg l lh li">def train_the_classifier(net,trainloader,optimizer, criterion, epochs):<br/>     #Training the Classifier<br/>     for epoch in range(epochs): # loop over the dataset multiple times<br/>          running_loss = 0.0<br/>          for i, data in enumerate(trainloader, 0):</span><span id="b9db" class="le je hi la b fi lj lg l lh li">              # get the inputs; data is a list of [inputs, labels]<br/>              inputs, labels = data<br/>                  <br/>              # zero the parameter gradients<br/>              optimizer.zero_grad()</span><span id="89ce" class="le je hi la b fi lj lg l lh li">              # forward + backward + optimize<br/>              outputs = net(inputs)</span><span id="3ae7" class="le je hi la b fi lj lg l lh li">              loss = criterion(outputs, labels)<br/>              loss.backward()<br/>              optimizer.step()</span><span id="1a97" class="le je hi la b fi lj lg l lh li">              # print statistics<br/>              running_loss += loss.item() <br/>              if i % 2000 == 1999: # print every 2000 mini-batches<br/>                       print(‘[%d, %5d] loss: %.3f’ %<br/>                        (epoch + 1, i + 1, running_loss / 2000))<br/>                       running_loss = 0.0</span><span id="fce5" class="le je hi la b fi lj lg l lh li">    print(‘Finished Training’)</span></pre><p id="4291" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过传递模型、损失函数、优化器和时期数来调用该函数。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="2f51" class="le je hi la b fi lf lg l lh li">#train the classifier<br/>train_the_classifier(net,trainloader,optimizer, criterion, 5)</span></pre><p id="ca3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">培训日志如下:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="f698" class="le je hi la b fi lf lg l lh li">[1, 2000] loss: 2.217 <br/>[1, 4000] loss: 1.835 <br/>[1, 6000] loss: 1.697 <br/>[1, 8000] loss: 1.638 <br/>[1, 10000] loss: 1.565 <br/>[1, 12000] loss: 1.545 </span><span id="3dbf" class="le je hi la b fi lj lg l lh li">[2, 2000] loss: 1.467 <br/>[2, 4000] loss: 1.389 <br/>[2, 6000] loss: 1.395 <br/>[2, 8000] loss: 1.346 <br/>[2, 10000] loss: 1.325 <br/>[2, 12000] loss: 1.297 </span><span id="4cc6" class="le je hi la b fi lj lg l lh li">[3, 2000] loss: 1.239 <br/>[3, 4000] loss: 1.224 <br/>[3, 6000] loss: 1.238 <br/>[3, 8000] loss: 1.227 <br/>[3, 10000] loss: 1.201 <br/>[3, 12000] loss: 1.193 </span><span id="45d2" class="le je hi la b fi lj lg l lh li">[4, 4000] loss: 1.133 <br/>[4, 6000] loss: 1.125 <br/>[4, 8000] loss: 1.135 <br/>[4, 10000] loss: 1.112 <br/>[4, 12000] loss: 1.123 </span><span id="5eaa" class="le je hi la b fi lj lg l lh li">[5, 2000] loss: 1.025 <br/>[5, 4000] loss: 1.063 <br/>[5, 6000] loss: 1.058 <br/>[5, 8000] loss: 1.049 <br/>[5, 10000] loss: 1.052 <br/>[5, 12000] loss: 1.066 <br/>Finished Training</span></pre><p id="0aac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终得到的损耗是1.066。让我们看看模型在测试数据集上的表现。该模型现在已保存，以供测试。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="e578" class="le je hi la b fi lf lg l lh li">#Save the Model<br/>PATH = ‘./cifar_net.pth’<br/>torch.save(net.state_dict(), PATH)</span></pre><h1 id="160c" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">5.测试和结果</h1><p id="a066" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">在测试模型之前，我们将重新加载模型和权重。这样做是为了避免训练好的模型在运行时断开连接的情况下丢失。这是通过以下代码行完成的:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="f1de" class="le je hi la b fi lf lg l lh li">#load the model<br/>net = Net()<br/>net.load_state_dict(torch.load(PATH))</span></pre><blockquote class="lx ly lz"><p id="5c2e" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">这一步的输出将是:</p><p id="6fd5" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated"><all keys="" matched="" successfully=""/></p></blockquote><p id="8b87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，让我们在第一批图像上测试图像。我们首先打印前4张图片和标签。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="d57a" class="le je hi la b fi lf lg l lh li">#Test the Network<br/>dataiter = iter(testloader)<br/>images, labels = dataiter.next()</span><span id="1035" class="le je hi la b fi lj lg l lh li"># print images<br/>imshow(torchvision.utils.make_grid(images))<br/>print(‘GroundTruth: ‘, ‘ ‘.join(‘%5s’ % classes[labels[j]] for j in range(BATCH_SIZE)))</span></pre><figure class="kv kw kx ky fd ll er es paragraph-image"><div class="er es me"><img src="../Images/d4d8f1990c928db6d970438df6a6652b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*hwnkzuOPsxGM4_de-mqlDg.png"/></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">带有原始标签的第一批图像</figcaption></figure><p id="0b05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些图像现在被输入到模型中，以获得预测的输出。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="3cf2" class="le je hi la b fi lf lg l lh li">outputs = net(images)</span><span id="9c18" class="le je hi la b fi lj lg l lh li">_, predicted = torch.max(outputs, 1)<br/>print(‘Predicted: ‘, ‘ ‘.join(‘%5s’ % classes[predicted[j]]<br/>         for j in range(BATCH_SIZE)))</span></pre><blockquote class="lx ly lz"><p id="b2eb" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">预测的标签有:</p><p id="ed7f" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">预言:猫船汽车飞机</p></blockquote><p id="c5a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，该模型成功预测了3幅图像，但未能正确预测第3幅图像。继续讨论这个结果，让我们预测10000个图像测试集，并计算总体准确性。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="03e0" class="le je hi la b fi lf lg l lh li">correct = 0<br/>total = 0</span><span id="d57e" class="le je hi la b fi lj lg l lh li">with torch.no_grad():<br/>    for data in testloader:<br/>            images, labels = data<br/>            outputs = net(images)<br/>            _, predicted = torch.max(outputs.data, 1)<br/>            total += labels.size(0)<br/>            correct += (predicted == labels).sum().item()<br/>            print(‘Accuracy of the network on the 10000 test images: %d %%’ % (100 * correct / total))</span></pre><blockquote class="lx ly lz"><p id="3513" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">总体精度为:</p><p id="7333" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">网络对10000张测试图像的准确率:60 %</p></blockquote><p id="a4da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在多类分类的情况下，总体精度并不总是正确的度量。因此，我们计算每个类的准确度。这是通过计算被正确预测的图像的百分比来完成的。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="b5dc" class="le je hi la b fi lf lg l lh li">class_correct = list(0. for i in range(10))<br/>class_total = list(0. for i in range(10))</span><span id="7531" class="le je hi la b fi lj lg l lh li">with torch.no_grad():<br/>     for data in testloader:<br/>         images, labels = data<br/>         outputs = net(images)<br/>         _, predicted = torch.max(outputs, 1)<br/>         c = (predicted == labels).squeeze()</span><span id="71d8" class="le je hi la b fi lj lg l lh li">         for i in range(4):<br/>              label = labels[i]<br/>              class_correct[label] += c[i].item()<br/>              class_total[label] += 1</span><span id="af72" class="le je hi la b fi lj lg l lh li">for i in range(10):<br/>     print(‘Accuracy of %5s : %2d %%’ % (<br/>            classes[i], 100 * class_correct[i] / class_total[i]))</span></pre><blockquote class="lx ly lz"><p id="d599" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">每类的精度为:</p><p id="bb80" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">飞机精度:67 % <br/>汽车精度:71 % <br/>鸟精度:55 % <br/>猫精度:48 % <br/>鹿精度:51 % <br/>狗精度:47 % <br/>青蛙精度:57 % <br/>马精度:60 % <br/>船精度:74 % <br/>卡车精度:69 %</p></blockquote><p id="2625" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基线模型的结果相当可观。这可以使用各种技术进一步改进。</p><h1 id="54a9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">提高准确性</h1><p id="b510" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">基线模型的准确率为60%，我们将努力提高整体准确率和每个类别的准确率。为此，我们进行了三项更改:</p><ul class=""><li id="1cfe" class="kh ki hi ih b ii ij im in iq mf iu mg iy mh jc km kn ko kp bi translated">添加批量标准化图层</li><li id="c64b" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">将优化器更改为Adam</li><li id="827c" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">为更多的时代训练它</li></ul><p id="4cfe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">型号:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="3afe" class="le je hi la b fi lf lg l lh li">import torch.nn as nn<br/>import torch.nn.functional as F</span><span id="66d6" class="le je hi la b fi lj lg l lh li">class ConvNet(nn.Module):<br/>       def __init__(self):<br/>            super(ConvNet, self).__init__()<br/>            self.conv1 = nn.Conv2d(3, 16, 5)<br/>            self.pool = nn.MaxPool2d(2, 2)<br/>            self.bn1 = nn.BatchNorm2d(16)<br/>            self.conv2 = nn.Conv2d(16, 32, 5)<br/>            self.bn2 = nn.BatchNorm2d(32)<br/>            <br/>            self.fc1 = nn.Linear(32 * 5 * 5, 120)<br/>            self.fc2 = nn.Linear(120, 84)<br/>            self.fc3 = nn.Linear(84, 10)</span><span id="de67" class="le je hi la b fi lj lg l lh li">       def forward(self, x):<br/>            x = self.pool(F.relu(self.conv1(x)))<br/>            x = self.bn1(x)<br/>            x = self.pool(F.relu(self.conv2(x)))<br/>            x = self.bn2(x)<br/>            x = torch.flatten(x, 1)<br/>            x = F.relu(self.fc1(x))<br/>            x = F.relu(self.fc2(x))<br/>            x = self.fc3(x)</span><span id="7b60" class="le je hi la b fi lj lg l lh li">       return x</span><span id="d7d5" class="le je hi la b fi lj lg l lh li">#Define Loss Function and optimizer</span><span id="0a04" class="le je hi la b fi lj lg l lh li">import torch.optim as optim<br/>net = ConvNet()<br/>criterion = nn.CrossEntropyLoss()<br/>optimizer = optim.Adam(net.parameters(), lr=0.001)</span></pre><p id="2e3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如前所述训练模型，但这次直到10个时期，最后五个时期的训练日志如下所示。</p><p id="8ac0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">培训日志:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="bb5b" class="le je hi la b fi lf lg l lh li">[1, 2000] loss: 1.860 <br/>[1, 4000] loss: 1.537 <br/>[1, 6000] loss: 1.407 </span><span id="ca0e" class="le je hi la b fi lj lg l lh li">....<br/>[5, 2000] loss: 0.753 <br/>[5, 4000] loss: 0.771 <br/>[5, 6000] loss: 0.792 <br/>[5, 8000] loss: 0.773 <br/>[5, 10000] loss: 0.795 <br/>[5, 12000] loss: 0.801 <br/>[6, 2000] loss: 0.706 <br/>[6, 4000] loss: 0.693 <br/>[6, 6000] loss: 0.715 <br/>[6, 8000] loss: 0.730 <br/>[6, 10000] loss: 0.720 <br/>[6, 12000] loss: 0.756 <br/>[7, 2000] loss: 0.626 <br/>[7, 4000] loss: 0.651 <br/>[7, 6000] loss: 0.682 <br/>[7, 8000] loss: 0.680 <br/>[7, 10000] loss: 0.687 <br/>[7, 12000] loss: 0.678 <br/>[8, 2000] loss: 0.573 <br/>[8, 4000] loss: 0.612 <br/>[8, 6000] loss: 0.626 <br/>[8, 8000] loss: 0.637 <br/>[8, 10000] loss: 0.636 <br/>[8, 12000] loss: 0.634 <br/>[9, 2000] loss: 0.551 <br/>[9, 4000] loss: 0.542 <br/>[9, 6000] loss: 0.575 <br/>[9, 8000] loss: 0.572 <br/>[9, 10000] loss: 0.593 <br/>[9, 12000] loss: 0.623 <br/>[10, 2000] loss: 0.516 <br/>[10, 4000] loss: 0.521 <br/>[10, 6000] loss: 0.555 <br/>[10, 8000] loss: 0.537 <br/>[10, 10000] loss: 0.592 <br/>[10, 12000] loss: 0.586 <br/>Finished Training</span></pre><p id="19b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">10个时期结束时的训练损失急剧减少到0.586。</p><blockquote class="lx ly lz"><p id="045d" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">整体精度:</p><p id="f5e5" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">网络对10000张测试图像的准确率:67 %</p></blockquote><p id="7461" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，整体精度也有所提高。因为整体的准确性不是合适的衡量标准，我们将看看每个职业的准确性。</p><blockquote class="lx ly lz"><p id="b204" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">每类精度:</p><p id="4f8e" class="if ig ma ih b ii ij ik il im in io ip mb ir is it mc iv iw ix md iz ja jb jc hb bi translated">飞机精度:77 % <br/>汽车精度:79 % <br/>鸟精度:52 % <br/>猫精度:50 % <br/>鹿精度:64 % <br/>狗精度:54 % <br/>青蛙精度:71 % <br/>马精度:74 % <br/>船精度:73 % <br/>卡车精度:76 %</p></blockquote><p id="64f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，每类的准确率也有所提高。然而，通过添加更多层、构建更深层次的模型以及添加数据扩充，可以实现更高的准确性。这篇文章是关于如何在Pytorch中处理图像分类问题的指南。</p><p id="3c2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完整的代码和数据集可以在这个<a class="ae kg" href="https://colab.research.google.com/drive/1TlxCy_A6ITFnHm3tIzqKwRlFYxXRpNqc?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>中找到。请随意调整参数，并尝试提高精确度。</p><p id="1f87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢大家！</p><h1 id="6157" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">参考资料:</h1><p id="7d1c" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">[1]<a class="ae kg" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/初学者/blitz/cifar 10 _ tutorial . html</a></p><p id="ccab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2]<a class="ae kg" href="https://analyticsindiamag.com/how-to-implement-cnn-model-using-pytorch-with-tpu/" rel="noopener ugc nofollow" target="_blank">https://analyticsindiamag . com/how-to-implementation-CNN-model-using-py torch-with-TPU/</a></p></div></div>    
</body>
</html>