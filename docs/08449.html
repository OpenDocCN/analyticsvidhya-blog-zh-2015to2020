<html>
<head>
<title>AlexNet Architecture Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AlexNet架构解释道</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/alexnet-architecture-explained-5d19e3dca2bb?source=collection_archive---------6-----------------------#2020-07-30">https://medium.com/analytics-vidhya/alexnet-architecture-explained-5d19e3dca2bb?source=collection_archive---------6-----------------------#2020-07-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5439" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AlexNet在2012年ImageNet LSVRC-2012比赛中以较大优势获胜(15.3%对26.2%(第二名)的错误率)。这是原始<a class="ae jd" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>的链接。</p><p id="ebca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">文件的主要重点</p><ol class=""><li id="65f7" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">使用ReLU代替tanh来增加非线性。</li><li id="e2aa" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">使用退出而不是调整来处理过度拟合。</li><li id="1ed2" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">重叠池用于缩小网络规模。</li><li id="0544" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated"><strong class="ih hj">输入</strong></li></ol><p id="a49a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AlexNet使用ImageNet数据集的子集解决了图像分类的问题，该数据集大约有120万张训练图像、50，000张验证图像和150，000张测试图像。输入是1000个不同类别之一的图像，输出是1000个数字的向量。</p><p id="bce5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AlexNet的输入是大小为256*256的RGB图像。这意味着训练集和测试图像中的所有图像的大小都是256*256。如果输入图像不是256*256，则图像被重新缩放，使得较短的尺寸为长度256，并从结果图像中裁剪出中心256*256的小块。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es js"><img src="../Images/7ba4145592112717c5a9d3c4e19d0e43.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*lrk2d4HqJFgfgR4A.jpg"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated"><a class="ae jd" href="https://www.learnopencv.com/wp-content/uploads/2018/05/AlexNet-Resize-Crop-Input.jpg" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="e4b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用像素的原始RGB值训练图像。因此，如果输入图像是灰度图像，它将被转换为RGB图像。大小为257*257的图像是通过随机裁剪从256*256的图像中生成的，它被馈送到AlexNet的第一层。</p><p id="8742" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。AlexNet架构</strong></p><p id="e823" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AlexNet包含五个卷积层和三个全连接层，总共八层。AlexNet架构如下图所示:</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es js"><img src="../Images/6e50c28a710a2badf949009bf8eb6bc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*EwqoP4xjej68ZeeR.png"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated"><a class="ae jd" href="https://www.learnopencv.com/wp-content/uploads/2018/05/AlexNet-1.png" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="a9d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于前两个卷积层，每个卷积层之后是重叠的最大池层。第三、第四和第五卷积层彼此直接相连。第五卷积层之后是重叠的最大池层，然后连接到完全连接的层。全连接层各有4096个神经元，第二个全连接层被送入具有1000个类的softmax分类器。</p><p id="08e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ke"> 2.1) ReLU非线性:</em> </strong></p><p id="2eee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">引入非线性的标准方法是使用tanh: f(x) = tanh(x)，其中f是输入x的函数，或者使用f(x) = (1+e^-x)^-1.</p><p id="1b63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就梯度下降的训练时间而言，这些是比非饱和非线性f(x) = max(0，x)慢得多的饱和非线性。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es kf"><img src="../Images/a5c18cccdbf59abf9827761b5e8046fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/0*as8hH-98uRG7yxtB.png"/></div></figure><p id="3fa4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图(此处虚线代表tanh，实线代表ReLU)</p><p id="0a6d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">饱和非线性:这些函数具有紧凑的范围，这意味着它们将神经响应压缩到实数的有界子集。对数将输入压缩为0至1之间的输出，TAN H在-1至1之间。这些函数在边界显示限制行为。</p><p id="b394" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">具有非饱和非线性的训练网络比具有饱和非线性的训练网络更快。</p><p id="4609" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ke"> 2.2)重叠合并:</em> </strong></p><p id="f9ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最大池层有助于对输入表示(图像、隐藏层输出矩阵等)进行下采样。)，减少其维数，并允许对包含在被装仓的子区域中的特征进行假设。最大池有助于减少过度拟合。基本上，它使用一个最大值操作来集合特性，留给我们更少的特性。除了计算最大值的相邻窗口彼此重叠之外，最大池化和重叠是相同的。</p><blockquote class="kg kh ki"><p id="9113" class="if ig ke ih b ii ij ik il im in io ip kj ir is it kk iv iw ix kl iz ja jb jc hb bi translated">汇集层可以被认为是由间隔s个像素的汇集单元的网格组成，每个汇集单元概括了以汇集单元的位置为中心的大小为z*z的邻域。如果我们设置s=z，我们得到传统的本地池。如果我们设置s &lt; z, we obtain overlapping pooling.</p><p id="a323" class="if ig ke ih b ii ij ik il im in io ip kj ir is it kk iv iw ix kl iz ja jb jc hb bi translated">AlexNet Paper (2012)</p></blockquote><p id="6d7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">The overlapping pooling reduces the top-1 and top-5 error rates by 0.4% and 0.3% compared to non-overlapping pooling, thus finding it very difficult to overfit.</p><p id="dcf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.3)减少过拟合</strong></p><p id="816e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">应用各种技术来减少重叠</p><p id="909b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据扩充</p><p id="2878" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">减少图像数据过度拟合的最常见方法是数据扩充。这是一种在不收集新数据的情况下显著增加可用于训练模型的数据多样性的策略。数据增强包括诸如位置增强(裁剪、填充、旋转、平移、仿射变换)、颜色增强(亮度、对比度饱和度、色调)和许多其他技术。AlexNet采用两种不同形式数据扩充。</p><p id="aaf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据扩充的第一种形式是转换图像和水平反射。这是通过从256*256图像中提取随机的224*224小块并在这些小块上训练网络来实现的。数据扩充的第二种形式包括改变训练图像中RGB通道的强度。</p><p id="5a9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">拒绝传统社会的人</p><p id="9e09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Dropout是一种正则化技术，用于减少过拟合并提高深度神经网络的泛化能力。“丢失”是指在神经网络中丢失单元(隐藏的和可见的)。我们可以将dropout解释为训练一层中给定节点的概率，其中1.0表示没有丢失，0.5表示50%的隐藏神经元被忽略。</p><figure class="jt ju jv jw fd jx er es paragraph-image"><div class="er es js"><img src="../Images/c79f70dc251a2959de9ef4b15d77b0a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*0usrnE6xFgzARWeI.png"/></div><figcaption class="ka kb et er es kc kd bd b be z dx translated"><a class="ae jd" href="http://jmlr.org/papers/v15/srivastava14a.html" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="df55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">原贴<a class="ae jd" href="https://prabinnepal.com/alexnet-architecture-explained/" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="f935" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考资料:</p><ol class=""><li id="53e2" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">Alex Krizhevsky、Ilya Sutskever和Geoffrey E. Hinton于2012年发表的《使用深度卷积神经网络进行ImageNet分类》</li><li id="83e2" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">https://www.learnopencv.com/understanding-alexnet/<a class="ae jd" href="https://www.learnopencv.com/understanding-alexnet/" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>