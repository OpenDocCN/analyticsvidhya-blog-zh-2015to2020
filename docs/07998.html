<html>
<head>
<title>Web Scraping with Python using BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python和BeautifulSoup进行网页抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-with-python-using-beautifulsoup-69b8bc07ff43?source=collection_archive---------6-----------------------#2020-07-14">https://medium.com/analytics-vidhya/web-scraping-with-python-using-beautifulsoup-69b8bc07ff43?source=collection_archive---------6-----------------------#2020-07-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/792f8752c6d43a2838597703f9b47492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gvXC-aVn5-eAzBe1bZhIdA.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">照片由<a class="ae hv" href="https://unsplash.com/@clemhlrdt" rel="noopener ugc nofollow" target="_blank"> Clément H </a>在<a class="ae hv" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><div class=""/><div class=""><h2 id="d5d8" class="pw-subtitle-paragraph iv hx hy bd b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm dx translated">如何用简单的步骤从HTML文档中解析和提取数据</h2></div><p id="f808" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">当开始一个新项目时，我们主要关心的问题之一是如何获得我们将要处理的数据。例如，像Airbnb和Twitter这样的公司通过提供API来简化这项任务，这样我们就可以有组织地汇编信息。在其他情况下，我们可以下载已经清理好并准备使用的结构化数据集，如在一些Kaggle比赛中。然而，我们需要探索网络来找到并提取我们想要的数据，这种情况并不少见。</p><p id="43b5" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这时<strong class="jp hz">网页抓取</strong>就派上用场了。这个想法是从一个网站中提取信息，并将其转换为实际分析。虽然有几个工具可用于此目的，但在本文中，我们将使用<a class="ae hv" href="https://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>，这是一个<strong class="jp hz"> Python </strong>库，旨在轻松地从HTML和XML文件中提取数据。</p><p id="8b6d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这里，我们将访问这个<a class="ae hv" href="https://en.wikipedia.org/wiki/List_of_best-selling_books" rel="noopener ugc nofollow" target="_blank">维基百科页面</a>，其中包含几个畅销书列表，并提取第二个表格，其中包含销量在5000万到1亿册之间的书籍。</p><h1 id="f5b0" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">所需的库</h1><p id="7bf2" class="pw-post-body-paragraph jn jo hy jp b jq lb iz js jt lc jc jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">我们只需要2个包来处理HTML文件。我们还将使用<strong class="jp hz">熊猫</strong>从提取的数据中创建一个数据框:</p><ul class=""><li id="da95" class="lg lh hy jp b jq jr jt ju jw li ka lj ke lk ki ll lm ln lo bi translated"><code class="du lp lq lr ls b">requests</code> -允许我们发送HTTP请求并从网页下载HTML代码；</li><li id="fc83" class="lg lh hy jp b jq lt jt lu jw lv ka lw ke lx ki ll lm ln lo bi translated"><code class="du lp lq lr ls b">beautifulsoup</code> -用于从原始HTML文件中提取数据；</li><li id="5dba" class="lg lh hy jp b jq lt jt lu jw lv ka lw ke lx ki ll lm ln lo bi translated"><code class="du lp lq lr ls b">pandas</code> -用于数据操作的Python库。我们将使用它来创建数据框。</li></ul><figure class="ly lz ma mb fd hk"><div class="bz dy l di"><div class="mc md l"/></div></figure><h1 id="4621" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">提取HTML文件</h1><p id="2dbc" class="pw-post-body-paragraph jn jo hy jp b jq lb iz js jt lc jc jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">要提取原始HTML文件，我们只需将网站URL传递给<code class="du lp lq lr ls b">request.get()</code>函数。</p><figure class="ly lz ma mb fd hk"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="be72" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们现在有一个非结构化的文本文件，包含从我们传递的URL路径中提取的HTML代码。</p><p id="b232" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">让我们来看看:</p><figure class="ly lz ma mb fd hk er es paragraph-image"><div class="er es me"><img src="../Images/846d7f7e47391e3f7f334ee75032c0c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*GP72TihabYtBjzQ95g-thQ.jpeg"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">从网页中提取的HTML代码</figcaption></figure><p id="4b8d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><code class="du lp lq lr ls b">requests</code>交付HTML代码输出的方式对于分析来说相当混乱。这时我们可以从BeautifulSoup那里得到帮助。</p><h1 id="74fc" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">创建一个BeautifulSoup对象</h1><p id="2e3e" class="pw-post-body-paragraph jn jo hy jp b jq lb iz js jt lc jc jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">现在，我们可以开始使用BeautifulSoup了。让我们生成一个名为<code class="du lp lq lr ls b">soup</code>的BeautifulSoup对象，传递上面创建的<code class="du lp lq lr ls b">html_text</code>文件。</p><p id="585c" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来，我们可以使用一个名为<code class="du lp lq lr ls b">prettify()</code>的函数以结构化的格式来塑造对象。</p><figure class="ly lz ma mb fd hk"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="a99c" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">请注意，与我们第一次生成原始的<code class="du lp lq lr ls b">html_text</code>文件时相比，格式化后的文件更容易阅读和操作。</p><figure class="ly lz ma mb fd hk er es paragraph-image"><div class="er es mf"><img src="../Images/de17b8cc2353755df79f3ef7f5bf636d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*y5FZhRlnvCy6MNx3pQKz0A.jpeg"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">结构化美丽组对象</figcaption></figure><h1 id="4c9f" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">检查维基百科页面</h1><p id="faa8" class="pw-post-body-paragraph jn jo hy jp b jq lb iz js jt lc jc jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">在<a class="ae hv" href="https://en.wikipedia.org/wiki/List_of_best-selling_books" rel="noopener ugc nofollow" target="_blank">维基百科页面</a>上，我们来考察一下网页的元素。(在Windows中，按<strong class="jp hz"> Ctrl + Shift + I </strong>。在Mac中，按下<strong class="jp hz"> Cmd + Opt + I </strong></p><figure class="ly lz ma mb fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mg"><img src="../Images/08b89ef7ea631dbf64623294b8a45d11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o0Ooub1DIiK3rV_2Mh50uw.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">检查网页的元素</figcaption></figure><p id="739d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">注意，所有的表都有一个类<code class="du lp lq lr ls b">wikitable sortable</code>。我们可以利用这一点来选择HTML文件中的所有表格。</p><h1 id="fd94" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">提取表格</h1><p id="2573" class="pw-post-body-paragraph jn jo hy jp b jq lb iz js jt lc jc jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">我们将表格保存在一个名为<code class="du lp lq lr ls b">wiki_tables</code>的变量中，使用方法<code class="du lp lq lr ls b">find_all()</code>来搜索所有的HTML <code class="du lp lq lr ls b">table</code>标签，使用一个类<code class="du lp lq lr ls b">wikitable sortable</code>。</p><p id="4a2f" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">因为我们想要页面上的第二个表(5000万到1亿份)，所以让我们将搜索范围缩小到第二个<code class="du lp lq lr ls b">wiki_tables</code>元素。让我们提取表中的每一行<code class="du lp lq lr ls b">tr</code>。</p><figure class="ly lz ma mb fd hk"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="82c5" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">现在，我们将创建一个名为<code class="du lp lq lr ls b">table_list</code>的空列表，并将每个表格单元格<code class="du lp lq lr ls b">td</code>的元素追加到<code class="du lp lq lr ls b">table_list</code>中。</p><figure class="ly lz ma mb fd hk"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="ccb2" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们已经成功地将网站上的第二个表提取到一个列表中，我们已经准备好开始分析数据了。</p><h1 id="5560" class="kj kk hy bd kl km kn ko kp kq kr ks kt je ku jf kv jh kw ji kx jk ky jl kz la bi translated">创建熊猫数据框架</h1><p id="9c9b" class="pw-post-body-paragraph jn jo hy jp b jq lb iz js jt lc jc jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">最后，我们可以简单地将列表转换成一个<strong class="jp hz"> Pandas DataFrame </strong>来可视化我们从维基百科中提取的数据。</p><figure class="ly lz ma mb fd hk"><div class="bz dy l di"><div class="mc md l"/></div></figure><figure class="ly lz ma mb fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mh"><img src="../Images/b689cf74247365f7cd5b3f23945f8335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ubsa6y8R2fSjc7i1WMjLPg.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">根据维基百科表格创建的熊猫数据框架</figcaption></figure><p id="a9ff" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">就是这样！通过几个步骤和几行代码，我们现在有了一个从HTML表中提取的数据框，可以进行分析了。嗯，仍然可以做一些调整，比如删除<code class="du lp lq lr ls b">approximate sales</code>列中的方括号引用，但是网页抓取已经完成了！</p><p id="9b2f" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">完整代码请参考<a class="ae hv" href="https://github.com/rmpbastos/data_science/blob/master/Web_Scraping_with_Python_using_BeautifulSoup.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>。</p></div></div>    
</body>
</html>