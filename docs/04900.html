<html>
<head>
<title>Classification in Decision Tree — A Step by Step CART (Classification And Regression Tree)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树中的分类—一步一步的推车(分类和回归树)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classification-in-decision-tree-a-step-by-step-cart-classification-and-regression-tree-8e5f5228b11e?source=collection_archive---------1-----------------------#2020-04-05">https://medium.com/analytics-vidhya/classification-in-decision-tree-a-step-by-step-cart-classification-and-regression-tree-8e5f5228b11e?source=collection_archive---------1-----------------------#2020-04-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f5fc" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">决策树算法—第二部分</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/c578dc8675cfc37eef3ca788241419da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WUGM6HSqRRlZGmXeuFi3rA.jpeg"/></div></div></figure><h1 id="5aa2" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">1.介绍</h1><p id="65de" class="pw-post-body-paragraph ig ih hi ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hb bi translated">CART(分类和回归树)是决策树算法的变体，在上一篇文章— <a class="ae kt" rel="noopener" href="/@arifromadhan19/the-basics-of-decision-trees-e5837cc2aba7">决策树的基础知识</a>中。决策树是非参数监督学习方法。CART可以应用于回归和分类问题[ <a class="ae kt" rel="noopener" href="/@arifromadhan19/the-basics-of-decision-trees-e5837cc2aba7"> 1 </a> ]。</p><p id="7f42" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">正如我们所知，数据科学家经常使用决策树来解决回归和分类问题，他们大多数人在决策树实施中使用scikit-learn。基于<a class="ae kt" href="https://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart" rel="noopener ugc nofollow" target="_blank">文档</a>，scikit-learn使用了优化版本的CART算法</p><h1 id="4f35" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">2.CART如何在分类中工作</h1><p id="0676" class="pw-post-body-paragraph ig ih hi ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hb bi translated"><a class="ae kt" rel="noopener" href="/@arifromadhan19/the-basics-of-decision-trees-e5837cc2aba7">在上一篇文章</a>中，我们解释了CART在将数据集分割成决策树的过程中使用了Gini杂质。</p><p id="36b1" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">数学上，我们可以把基尼系数写成如下</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ku"><img src="../Images/b5538c42ce80910cdb3d2a9ed937c646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vpx5zX45s8mTMOLSH6qOVA.png"/></div></div></figure><h2 id="408c" class="kv jr hi bd js kw kx ky jw kz la lb ka ir lc ld ke iv le lf ki iz lg lh km li bi translated">CART如何处理数据集的分割</h2><p id="2318" class="pw-post-body-paragraph ig ih hi ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hb bi translated">这个模拟使用一个有303行的心脏病数据集，有13个属性。目标包括138个值0和165个值1</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lj"><img src="../Images/6fdda72246625dd9bcf2d42aa4551855.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/0*0zo8Ipx3coTzFIGA"/></div></figure><p id="2310" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在此模拟中，仅使用性别、Fbs(空腹血糖)、Exang(运动诱发的心绞痛)和目标属性。</p><h2 id="d600" class="kv jr hi bd js kw kx ky jw kz la lb ka ir lc ld ke iv le lf ki iz lg lh km li bi translated">分类</h2><p id="2119" class="pw-post-body-paragraph ig ih hi ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hb bi translated"><strong class="ii hj">测量基尼系数在性别上的杂质</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lk"><img src="../Images/d341efe1ae14435ecdbfebe2b1544bac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*GOdkYC7ahc7OvXoGS4PBBw.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ll"><img src="../Images/213f0416000184ebc89e3818e6149d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*weJz1ySCM1zCdUXXhnDnfQ.png"/></div></div></figure><p id="e7ae" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">测量Fbs(空腹血糖)中的基尼系数杂质</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lk"><img src="../Images/6da96877205d3065b0e40b65c0940ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*maoBf7OGfIdz-M_6tocROw.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lm"><img src="../Images/487de7060e6d475fe4c10262f934beed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uitcZpl9-DCOAdcI5kzQDw.png"/></div></div></figure><p id="472d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">测量Exang(运动诱发的心绞痛)中的Gini杂质</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lk"><img src="../Images/9fa776cf6d04cabbc561bde8f0676b6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*uv5yAlR-7zjpCdj3d1iNjA.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ln"><img src="../Images/0b4e53e064574e5ec3ecc98a609d1e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ErP1iQA29UeKEYtqGY_5dA.png"/></div></div></figure><p id="2b6a" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj"> Fbs(空腹血糖)的基尼杂质最低，所以我们要在根节点使用它</strong></p><p id="c434" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">正如我们所知，我们将Fbs作为根节点，当我们使用Fbs(空腹血糖)划分所有患者时，我们最终会得到“不纯”的叶节点。每片叶子都包含有无心脏病。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lo"><img src="../Images/1afcb104e251f0595f56da7475667cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/0*WG30IbLeSBfqfo2H"/></div></figure><p id="7cf4" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">我们需要弄清楚性别和Exang在Fbs左侧淋巴结中如何区分这些患者</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lp"><img src="../Images/984f6004f4167e4942dc36d9fb9be6d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qhDveP9TvqqCn_Uy"/></div></div></figure><p id="c69b" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj"> Exang(运动诱发心绞痛)基尼杂质最低，我们在这个节点用它来区分患者。</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lq"><img src="../Images/aee8ab7ad65e50ef62ce5eb031a9ee1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/0*4j3X8XYg7gdY50Ld"/></div></figure><p id="4862" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在Exang(运动诱发的心绞痛)的左侧结中，它如何很好地分离这49个患者(24个患有心脏病，25个没有心脏病。因为只剩下属性sex，所以我们将sex属性放在Exang的左侧节点中</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/3fffaed86f76914f01ab2b5173798451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CqUhQD6zzZgBg1bS"/></div></div></figure><p id="e4dc" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">正如我们所看到的，我们在这个分支上有最终的叶节点，但是为什么叶节点被圈起来，包括最终的节点？</p><p id="b187" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">注:带圈的叶节点，89%没有心脏病</p><p id="4c90" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">这些新的叶子比我们以前的更好的分离病人吗？</p><p id="61de" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">为了回答这些问题，我们必须在使用属性性别区分病人之前，比较使用属性性别的基尼系数和基尼系数。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ls"><img src="../Images/e9145be30160bbca6dece59367ef98fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0Fut-9j0qxgXShRa"/></div></div></figure><p id="fef2" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">用性别来分离患者之前的基尼杂质是最低的，所以我们不用性别来分离这个节点。树的这个分支的最后一个叶节点</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lt"><img src="../Images/ba28c27e6d6575d8d522a149b7c6373c.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/0*ttXZLxx9OC75BAc8"/></div></figure><p id="28cc" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在右边的树枝上做同样的事情，所以这种情况下树的最终结果是</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lu"><img src="../Images/dcc0d04a8e9df1ed6c2049f5f10840b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HPE2L-ik2iHKsoNJ"/></div></div></figure><p id="ba4a" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">处理数据集拆分时的要点</strong></p><blockquote class="lv lw lx"><p id="f0f5" class="ig ih ly ii b ij ik il im in io ip iq lz is it iu ma iw ix iy mb ja jb jc jd hb bi translated">1.计算所有的基尼系数</p><p id="16ce" class="ig ih ly ii b ij ik il im in io ip iq lz is it iu ma iw ix iy mb ja jb jc jd hb bi translated">2.比较基尼杂质分数，在使用新属性分离数据之前的n之后。如果节点本身得分最低，那么就没有必要分离数据</p><p id="c21f" class="ig ih ly ii b ij ik il im in io ip iq lz is it iu ma iw ix iy mb ja jb jc jd hb bi translated">3.如果分离数据导致改善，则选择杂质分数最低的分离</p></blockquote><h1 id="93e4" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">奖金</h1><h2 id="e1ed" class="kv jr hi bd js kw kx ky jw kz la lb ka ir lc ld ke iv le lf ki iz lg lh km li bi translated"><strong class="ak">如何计算连续数据中的基尼杂质？</strong></h2><p id="75d6" class="pw-post-body-paragraph ig ih hi ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hb bi translated">比如体重，体重是决定心脏病的属性之一，比如我们有体重属性</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mc"><img src="../Images/298c234c3e394f4331f07409745edc57.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/0*zG_vM-YBOzP_Fcm6"/></div></figure><p id="6183" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">第一步:数据升序排序</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es md"><img src="../Images/35e50db4a67fd1d786389014c38c6348.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/0*cUK8HXBDgD0TovYN"/></div></figure><p id="e4f0" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">第二步:计算平均重量</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es me"><img src="../Images/df5075658e370cd159a421eaabf7d25d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/0*UDVMwgSRWS4gwl7q"/></div></figure><p id="d341" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">步骤3:计算每个平均体重的基尼系数杂质值</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mf"><img src="../Images/d193e42e856dbd05a1fbc5a3e044fed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9n29hkwLQyOeg9OT"/></div></div></figure><p id="77bf" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">最低的基尼系数杂质是<strong class="ii hj">权重&lt; 205，</strong>这是我们与另一个属性比较时使用的临界值和杂质值</p><h2 id="7757" class="kv jr hi bd js kw kx ky jw kz la lb ka ir lc ld ke iv le lf ki iz lg lh km li bi translated"><strong class="ak">如何计算分类数据中的基尼杂质？</strong></h2><p id="76c1" class="pw-post-body-paragraph ig ih hi ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hb bi translated">我们有一个最喜欢的颜色属性来确定一个人的性别</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mg"><img src="../Images/0c477fdf5126c48485a15b2e0871c265.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*EiA4It23nkFcq-aS"/></div></figure><p id="fdda" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">为了了解基尼系数杂质这一属性，计算每一个以及每一个可能的组合的杂质分数</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mh"><img src="../Images/de76b3a3df5c6b80e31261b619165557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cPRnFd7prTjoyafxmsLyyw.jpeg"/></div></div></figure><h1 id="c66a" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">继续学习CART在回归中是如何工作的</h1><p id="e90f" class="pw-post-body-paragraph ig ih hi ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hb bi translated"><a class="ae kt" rel="noopener" href="/@arifromadhan19/regrssion-in-decision-tree-a-step-by-step-cart-classification-and-regression-tree-196c6ac9711e">决策树中的回归——一步一步的CART(分类和回归树)——第三部分)</a></p><h2 id="4aae" class="kv jr hi bd js kw kx ky jw kz la lb ka ir lc ld ke iv le lf ki iz lg lh km li bi translated">关于我</h2><p id="bb34" class="pw-post-body-paragraph ig ih hi ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hb bi translated">我是一名数据科学家，专注于机器学习和深度学习。你可以通过<a class="ae kt" rel="noopener" href="/@arifromadhan19">媒体</a>和<a class="ae kt" href="https://www.linkedin.com/in/arif-romadhan-292116138/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>联系我</p><p id="290f" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">我的网站:【https://komuternak.com/】<a class="ae kt" href="https://komuternak.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ii hj"/></a></strong></p><h2 id="c83b" class="kv jr hi bd js kw kx ky jw kz la lb ka ir lc ld ke iv le lf ki iz lg lh km li bi translated">参考</h2><ol class=""><li id="6b46" class="mi mj hi ii b ij ko in kp ir mk iv ml iz mm jd mn mo mp mq bi translated"><a class="ae kt" rel="noopener" href="/@arifromadhan19/the-basics-of-decision-trees-e5837cc2aba7">https://medium . com/@ arifromadhan 19/the-basics-of-decision-trees-e 5837 cc 2 ABA 7</a></li><li id="4646" class="mi mj hi ii b ij mr in ms ir mt iv mu iz mv jd mn mo mp mq bi translated"><a class="ae kt" href="http://faculty.marshall.usc.edu/gareth-james/ISL/" rel="noopener ugc nofollow" target="_blank">统计学习简介</a></li><li id="c284" class="mi mj hi ii b ij mr in ms ir mt iv mu iz mv jd mn mo mp mq bi translated">拉什卡，塞巴斯蒂安。Python机器学习</li><li id="5412" class="mi mj hi ii b ij mr in ms ir mt iv mu iz mv jd mn mo mp mq bi translated"><a class="ae kt" href="https://en.wikipedia.org/wiki/Decision_tree_learning" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Decision_tree_learning</a></li><li id="4b2c" class="mi mj hi ii b ij mr in ms ir mt iv mu iz mv jd mn mo mp mq bi translated">博纳科索朱塞佩。机器学习算法</li><li id="dd95" class="mi mj hi ii b ij mr in ms ir mt iv mu iz mv jd mn mo mp mq bi translated"><em class="ly">改编自YouTube频道的《</em><a class="ae kt" href="https://www.youtube.com/watch?v=7VeUPuFGJHk&amp;t=911s" rel="noopener ugc nofollow" target="_blank"><em class="ly">stat quest with Josh Stamer</em></a><em class="ly"/></li></ol></div></div>    
</body>
</html>