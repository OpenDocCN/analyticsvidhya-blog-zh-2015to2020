<html>
<head>
<title>Eddie: A Knowledge Backed Question Answering Agent — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">埃迪:知识支持的问题回答代理——第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/eddie-a-knowledge-backed-question-answering-agent-part-1-b93f68dab5c1?source=collection_archive---------7-----------------------#2020-02-23">https://medium.com/analytics-vidhya/eddie-a-knowledge-backed-question-answering-agent-part-1-b93f68dab5c1?source=collection_archive---------7-----------------------#2020-02-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="17c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最近，我从石溪大学获得了计算机科学硕士学位。我在<a class="ae jd" href="https://compas.cs.stonybrook.edu/" rel="noopener ugc nofollow" target="_blank"> COMPAS </a>实验室工作，由<a class="ae jd" href="https://compas.cs.stonybrook.edu/~mferdman/" rel="noopener ugc nofollow" target="_blank">教授Mike Ferdman </a>指导。我花了两个美丽的学期研究开发“埃迪:知识支持的问答代理”。这篇文章揭示了我在那段旅程中的一些学习。</p><p id="eba1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章是一系列文章的第一部分(<a class="ae jd" rel="noopener" href="/@miteshkumarsingh/eddie-understanding-user-queries-providing-natural-responses-part-3-f2542ec3785d">第二部分</a>)。它面向所有对自然语言处理感兴趣的人，尤其是了解开放领域问答系统内部的人。这样的系统往往会形成像Siri、Cortana、Alexa等个人助理的核心组件。</p><h1 id="3663" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">目标是什么？</h1><blockquote class="kc kd ke"><p id="6b0a" class="if ig kf ih b ii ij ik il im in io ip kg ir is it kh iv iw ix ki iz ja jb jc hb bi translated">开发一个智能问答代理，它可以通过适合每个用户的交互式和知识支持的对话来解决用户的复杂信息需求。我们称这个系统为“埃迪”。</p></blockquote><p id="8350" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们设想对话代理更像人类，主要针对以下目标。</p><h2 id="59d7" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated">主要目标</h2><ol class=""><li id="415c" class="kx ky hi ih b ii kz im la iq lb iu lc iy ld jc le lf lg lh bi translated"><strong class="ih hj">提供准确的答案</strong> <br/>我们希望代理扫描整个web，并为用户的查询提供准确的答案，而不是转储一组搜索结果。</li><li id="e4b0" class="kx ky hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><strong class="ih hj">回答上下文相关/相互关联的问题</strong> <br/>这样的代理应该能够理解对话上下文，并与用户进行一系列相互关联的问答对话。比如用户问— <br/>一、<em class="kf">加州的人口是多少？</em> <br/> <em class="kf">二世。那里的天气怎么样？<br/> </em>代理应该足够聪明，能够理解前面问题中的‘there’指的是‘California’这个词。</li></ol><figure class="ln lo lp lq fd lr"><div class="bz dy l di"><div class="ls lt l"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">Eddie演示:基于主题的开放领域对话式问答</figcaption></figure><h2 id="4b30" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated">次要目标</h2><ol class=""><li id="e72e" class="kx ky hi ih b ii kz im la iq lb iu lc iy ld jc le lf lg lh bi translated"><strong class="ih hj">理解多样的用户查询<br/> </strong>自然语言是模棱两可的。用户查询通常很短并且缺乏上下文。此外，可以用多种方式询问同一个查询。Eddie应该能够重新制定用户查询，或者在有疑问时询问更多的上下文。</li><li id="314f" class="kx ky hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><strong class="ih hj">用有意义的句子作答</strong> <br/>代理应该用有意义的句子作答，而不是用单个单词或阅读互联网文档中的短语。</li><li id="00c5" class="kx ky hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><strong class="ih hj">提供个性化响应<br/> </strong>这样的对话界面产生的响应应该是个性化的。在回复之前，它应该考虑用户的个性特征，如年龄、性别、兴趣和过去的查询。于是，一个代理人对问题“<em class="kf">什么是癌症？</em>“对于一个对星座感兴趣的5岁孩子来说，应该和给医生的回复不一样。</li></ol><p id="dc80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">值得注意的是，每个目标都是由研究人员/公司在某种程度上独立实现的。然而，还没有一个成功的系统具有Eddie的所有主要特征。每个子问题都是一个独立的研究课题，我们将在随后的文章中简要介绍它们。</p><h1 id="cd31" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">Eddie和现有的聊天机器人有什么不同？</h1><h2 id="8bd2" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated">现有聊天机器人</h2><p id="dbb2" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">现有的基于语音的聊天机器人大致分为两类</p><p id="b67d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">像Alexa、Siri或Cortana这样的个人数字助理主要是面向任务的机器人。它们是封闭域机器人，即它们响应执行特定的任务。例如，他们可以轻松地预约餐馆，播放视频或预订优步。他们可以通过给你讲一个笑话或有意识地回答几个问题来进行有限的社交聊天。他们还可以通过从互联网上识别相关文档并通读它们来回答一些寻求信息的问题。在内部，这些助理将社交聊天和信息搜索建模为成千上万个其他任务中的两个独立任务。当提出问题时，助手首先将话语分类到任务类别之一。这被划分为<a class="ae jd" href="http://nlpprogress.com/english/intent_detection_slot_filling.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">意图分类和槽填充</strong> </a>问题，并且通常使用神经网络来解决。一旦任务被识别，与该任务相关联的相关API执行该工作。</p><p id="5e9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">社交聊天机器人<br/> </strong>这种机器人是开放域机器人，即它们可以讨论任何话题。它们或者是基于检索的，或者是生成的。给定用户的一句话和一段对话，基于检索的机器人要么从知识库或知识图中检索下一个响应。生殖机器人使用深度神经网络(在现有的社交聊天中训练)来生成用户查询的答案。聊天机器人的常见例子有— <a class="ae jd" href="https://www.msxiaobing.com/" rel="noopener ugc nofollow" target="_blank"> XiaoIce </a>、<a class="ae jd" href="https://arxiv.org/pdf/2001.09977.pdf" rel="noopener ugc nofollow" target="_blank"> Meena </a>、<a class="ae jd" href="https://www.cleverbot.com/" rel="noopener ugc nofollow" target="_blank"> Cleverbot </a></p><h2 id="1705" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated"><strong class="ak">艾迪</strong></h2><p id="8e16" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">埃迪的目标是改进面向任务的机器人的单一任务——在开放领域寻找信息的任务。旨在回答用户的开放领域、多回合、情境化问题。</p><p id="4327" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现有的语音助手经常最终对许多问题提供固定的回答，即它们的准确性非常低。即使他们找到了答案，他们的反应也是基于跨度的。因为他们只是阅读维基百科的文档，所以他们的回答不是会话式的。我们希望埃迪用有意义的人类句子来回应。此外，现有的助手不能对对话中的上下文问题做出反应。我们希望Eddie至少保留到最后一个问题答案对的上下文。</p><p id="42a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在一个非常受约束的环境中建造埃迪。例如，现有的助手/搜索引擎具有丰富的上下文，如—</p><p id="e9fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.与这个问题相关的最常见的问题有哪些？<br/> 2。当给定一组链接时，用户点击了哪个链接？<br/> 3。什么是用户个性，种族，位置？</p><p id="c2d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们使用这些问题的答案，同时找出用户问题的答案。由于这些助手的数据集不公开，Eddie没有所有这些信息。此外，助理使用基于<strong class="ih hj">知识图的问答和基于神经RC模型的问答</strong>来回答问题。我们的研究只集中在基于神经RC模型的问答系统上。</p><h1 id="de99" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">目标1 —提供一个准确的答案</h1><p id="82d5" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">我们目标的最重要方面是让Eddie能够回答寻找信息的问题。这可以通过建立一个开放领域问答系统来实现。我们使用一个流行的QA系统<a class="ae jd" href="https://github.com/facebookresearch/DrQA" rel="noopener ugc nofollow" target="_blank"> DrQA </a>的设计作为基础。<strong class="ih hj">我们首先建立一个管道，仅处理与上下文无关的问题。我们的系统主要由3部分组成。</strong></p><figure class="ln lo lp lq fd lr er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mb"><img src="../Images/1fb03dd26f292956e83c2ee091bb8189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qIttWvRtiWakTidiPKCDUw.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">基于<a class="ae jd" href="https://github.com/facebookresearch/DrQA" rel="noopener ugc nofollow" target="_blank"> DrQA </a>的非对话式开放领域问答系统的总体架构</figcaption></figure><p id="206a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，为了清楚起见，我们将答案排名器显示为一个单独的模块。答案排序器的逻辑位于文档阅读器本身内部。</p><h2 id="2cf5" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated"><strong class="ak">文件检索器</strong></h2><p id="9611" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">我们使用DrQA的维基百科索引作为我们的知识库。</p><blockquote class="kc kd ke"><p id="6062" class="if ig kf ih b ii ij ik il im in io ip kg ir is it kh iv iw ix ki iz ja jb jc hb bi translated">给定一个问题Q和一组文档{d1，d2，…dn}，找出可能包含问题Q答案的前K个文档。</p></blockquote><p id="4f13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用TFIDF模型为每个文档生成一个分数。分数表示用户问题和文档之间的相似性。根据分数，我们检索一组可能包含答案的前5个文档。</p><h2 id="5a8f" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated"><strong class="ak">文件阅读器</strong></h2><p id="c929" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">在检索文档时，我们将每个文档分成段落，比如总共X个段落。对于每一段，我们现在已经将我们的问题简化为NLP中的标准阅读理解问题。</p><blockquote class="kc kd ke"><p id="562a" class="if ig kf ih b ii ij ik il im in io ip kg ir is it kh iv iw ix ki iz ja jb jc hb bi translated">给定一个段落P和一个问题Q，找出段落中最有可能成为答案的跨度。</p></blockquote><p id="c105" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">段落中的跨度由段落中的两个标记确定，开始标记和结束标记。我们使用<a class="ae jd" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank"> SQuAD </a> v1.1(基于跨度的阅读理解)数据集来训练神经模型，以找到开始和结束标记。</p><p id="4494" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">具体来说，我们使用手套嵌入对问题Q和段落P标记进行编码。我们通过一个<strong class="ih hj"> 3层堆叠的biLSTM模型传递问题和段落表示，并使用问题和段落之间的注意力</strong> <em class="kf"> ( </em> <strong class="ih hj">斯坦福注意力读者模型)</strong> <em class="kf"> </em>来确定每个标记成为开始/结束标记的概率。</p><figure class="ln lo lp lq fd lr er es paragraph-image"><div class="er es mi"><img src="../Images/a68e9502b09069551e10bfb82bf06aba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*0vMasrV6R9WxFMorh_IYiA.png"/></div></figure><p id="c67b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在推理过程中，该模型将具有最高起始和结束标记联合概率的段落跨度作为答案跨度。</p><p id="3cf2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要详细查看我们的神经模型的架构，请阅读此处的<a class="ae jd" href="https://github.com/miteshksingh/Eddie/blob/master/StanfordAttentiveReader-ParameterAnalysis.pdf" rel="noopener ugc nofollow" target="_blank"/>。并不是说COMPAS实验室的同学致力于建造LSTM加速器。他们使用我的斯坦福专心读者(SAR)代码来测试他们的加速器。为了帮助他们开发，我对SAR模型进行了详细的参数分析，其细节也可以在上面的链接中找到。</p><h2 id="7fdc" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated"><strong class="ak">答案排名</strong></h2><p id="3f2d" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">在X个段落上运行神经阅读器后，我们获得了一组X个答案。现有的DrQA模型为每个答案提供分数。</p><p id="8486" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">答案得分= max (Pr(开始令牌)x Pr(结束令牌))<br/> DrQA使用得分最高的区间作为最佳区间。</p><p id="90d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kf">然而，我们发现这些答案分数是跨段落不可比的。</em>在开放领域设定中，大部分段落不包含答案。现有的DrQA模型是在不包含无法回答的问题的SQuAD v1.1上训练的。因此，该模型没有被训练来为不包含答案的段落产生低置信度分数。为了解决这个问题，我们使用了<a class="ae jd" href="https://arxiv.org/abs/1710.10723" rel="noopener ugc nofollow" target="_blank"> Clark等人</a>在开发<a class="ae jd" href="https://github.com/allenai/document-qa" rel="noopener ugc nofollow" target="_blank">文档QA </a>时采用的方法。<strong class="ih hj">我们修改了现有的DrQA，在培训目标中使用共享标准化。这在所有段落中产生了精确的分数。</strong></p><p id="5580" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于我们的非上下文管道，我们使用SQuAD 2.0来训练和评估模型，因为它也包含无法回答的段落。</p><h1 id="0e27" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">目标2 —回答上下文相关的问题</h1><p id="85b1" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">我们的下一个目标是让Eddie能够与用户进行有吸引力的对话。它应该理解对话的上下文，并能够回答一系列相互关联的问题。例如，考虑下表第二列中的查询。</p><figure class="ln lo lp lq fd lr er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mj"><img src="../Images/85066044a6544b342a2e1dc8070145dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pgjLZtI8UJ1A3yII.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">学分— <a class="ae jd" href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/www_published_rpsr1234-renA.pdf" rel="noopener ugc nofollow" target="_blank">使用序列对序列建模的对话查询理解</a></figcaption></figure><p id="30b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了正确回答这样的问题，Eddie必须保持过去对话的上下文，并通过它们进行推理。因此，我们建议在管道的检索器和读取器组件中都包含上下文。</p><h1 id="e4c4" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤1 —定义上下文</h1><p id="65fe" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">在基于阅读理解的会话式问答中，给出一个固定的段落。问题的答案要么存在于给定的段落中，要么问题无法回答。基于RC的会话式问答数据集的流行示例是QuAC和CoQA。</p><blockquote class="kc kd ke"><p id="bfca" class="if ig kf ih b ii ij ik il im in io ip kg ir is it kh iv iw ix ki iz ja jb jc hb bi translated">给定一个段落P和一个对话历史(Q1、A1、Q2、A2……)，一个<strong class="ih hj"> RC对话QA </strong>的目标是使用<strong class="ih hj">整个对话历史作为上下文</strong>来回答第n个问题Qn。然而，在<strong class="ih hj">开放领域对话式问答</strong>中，用户可以在主题之间切换。每个问题可以来自完全不同的领域(比如从政治到体育)，从而使整个对话历史变得无关紧要。</p></blockquote><p id="26ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果Eddie有一个“<strong class="ih hj">会话标识符/主题检测器</strong>”模块，就可以解决上述问题。该模块可以检测话题变化。然后，它可以计算与当前问题的主题相关的先前问答配对的回合数。然而，由于时间限制，我们在研究中跳过了会话标识符模块。我们缩小我们的研究范围，建立一个基于主题的开放领域问答系统，也就是说，我们强迫用户总是通过预先声明主题来声明一个新的对话正在开始。</p><p id="bbc6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们的方法——基于主题的开放领域QA </strong></p><p id="e9c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在开始对话之前，Eddie和用户就讨论的主题达成一致。每当用户希望讨论新的话题时，它可以与Eddie开始新的会话。因此，当前会话中的所有问题/答案都充当Eddie的上下文。用户只能问与约定主题相关的问题。如果用户向Eddie提出不同主题的问题，Eddie可能会返回垃圾答案，因为当前问题和上下文不再匹配。</p><h1 id="ebe2" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤2 —选择对话数据集</h1><p id="fd23" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">为了训练和测试我们的管道，我们需要一个数据集来满足我们的主要目标和次要目标。我们调查了大量数据集，寻找以下特征—</p><h2 id="86e2" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated"><strong class="ak">主要特征</strong></h2><ol class=""><li id="fd0c" class="kx ky hi ih b ii kz im la iq lb iu lc iy ld jc le lf lg lh bi translated"><strong class="ih hj">信息搜寻— </strong>阅读理解数据集默认为信息搜寻。</li><li id="46c1" class="kx ky hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><strong class="ih hj">主题可用性— </strong>为了在推理过程中评估Eddie，我们需要将主题作为上下文传递给检索者和读者。因此，数据集必须有可用的每个对话的主题。</li><li id="d3f1" class="kx ky hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><strong class="ih hj">对话式— </strong>数据集应该有一系列相互关联的问题。</li><li id="734f" class="kx ky hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><strong class="ih hj">段落无关查询— </strong>在大多数数据集中，问题都是基于给定的段落。然而，在现实世界中，提问者并没有一个段落。因此，数据集应该有真实的用户向搜索引擎和QA机器提出的问题，独立于任何段落。这种查询通常是不明确的和开放式的。我们还希望避免数据集在看到文章后有注释者创建的问题。</li></ol><h2 id="8450" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated"><strong class="ak">次要特征</strong></h2><ol class=""><li id="1d09" class="kx ky hi ih b ii kz im la iq lb iu lc iy ld jc le lf lg lh bi translated"><strong class="ih hj">自由形式答案— </strong>数据集应该有自然语言的答案。它不应基于跨度。比如<br/> <strong class="ih hj">段</strong>:公羊去市场了。他买了牛奶。<br/> <strong class="ih hj">问题</strong>:拉姆买牛奶了吗？<br/>Span答案:他买了牛奶。<br/> <strong class="ih hj">自然回答</strong>:是<br/>用‘是’回答比用span回答更像人类。</li><li id="cfce" class="kx ky hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><strong class="ih hj">个性化的答案— </strong>如果答案也基于个性背景，那就更好了。</li></ol><h2 id="0ccb" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated"><strong class="ak">数据集调查结果</strong></h2><p id="c024" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">2.0小队和马尔科女士不搭话。MARCO女士有一个优势，那就是它包含了真实的Bing用户查询，并且其中的答案是自由形式的。然而，他们提出了一个额外的挑战，即跨越多个段落的答案(多跳推理)，这超出了我们的研究范围。CoQA和QuAC是对话式的，但它们不是基于真实的用户查询。没有一个数据集包含用户回答时的个性。我们意识到没有这样的数据集能满足我们所有的需求。因此，我们缩小了研究范围，专注于解决埃迪的主要目标。</p><figure class="ln lo lp lq fd lr er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mk"><img src="../Images/53ef28c18512a31d64d271d1b1e9a9e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N2j6RXeKyNvD_qTwKV7dWA.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">Eddie数据集调查</figcaption></figure><p id="8695" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在简化设置中，QuAC是唯一满足4个主要要求中的3个的数据集。它不满足“段落独立查询”标准。为了解决这个问题，我们使用QuAC数据集的训练集来训练我们的文档阅读器。但是我们通过删除所有段落来修改QuAC验证集。在推理过程中，我们在维基百科索引中索引了所有的QuAC验证段落，并只向Eddie(检索者+读者)提出没有段落的问题。我们把这个修改后的数据集称为<strong class="ih hj">开域QuAC </strong>，类似于<a class="ae jd" href="https://github.com/facebookresearch/DrQA" rel="noopener ugc nofollow" target="_blank">开域小队</a>。</p><figure class="ln lo lp lq fd lr er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ml"><img src="../Images/2c99ffbc0a335daa52d63272b5573058.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fe0gLKHgQ2aP7u1s.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">QuAC数据集</figcaption></figure><h2 id="c9d1" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated"><strong class="ak">使用CoQA的简短实验</strong></h2><p id="4ad6" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">我们通过构建一个管道并始终将过去的两个查询视为上下文，对CoQA数据集进行了简单的实验。我们观察到，在推断过程中，CoQA性能非常低，主要原因如下</p><ol class=""><li id="a1f2" class="kx ky hi ih b ii ij im in iq mm iu mn iy mo jc le lf lg lh bi translated">CoQA中的问题往往太短(什么？，哪里？什么时候？)以便检索器返回有意义的结果。QuAC中的平均问题长度为6.5个标记，而CoQA中的平均问题长度仅为5.5个标记。</li><li id="d743" class="kx ky hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">CoQA中的问题不是仿真的，当独立地向寻回者提出时，通常没有任何意义。这可能是因为CoQA中的提问者可以看到该段落，然后提问。另一方面，QuAC包含维基百科段落。因此，它的问题更加真实，非常类似于用户在与语音助手/网络交互时寻求信息的本性。</li></ol><figure class="ln lo lp lq fd lr er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mp"><img src="../Images/e78950f4b74231ea660a51a837c388cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nIqn1JhWTAxFlNuZ.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">CoQA</figcaption></figure><p id="37bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.其准确性低的另一个原因隐藏在我们创造环境的方式中。在实验中，我们使用前两个问题作为背景，一个接一个地问所有的问题。例如，考虑只有两个段落的数据集P1(两个问题Q1和Q2)和P2(两个问题Q3和Q4)。如果我们删除这些段落，并向Eddie提出问题(Q1、Q2、第3季度、第4季度)，我们将最终使用Q1和Q2作为第3季度的背景。因此，我们最终向埃迪·里查德和里德提供了错误的背景，因为Q1和Q2完全基于不同的段落，也许是不同的主题。</p><h1 id="2506" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤3——融入背景</h1><p id="733f" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">我们使用与上面提到的相同的非上下文管道，只是改变提供给检索器和阅读器的输入。</p><h2 id="6eae" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated">向检索器添加上下文</h2><p id="1bce" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">我们的文档检索器不是基于机器学习的组件。因此它不需要被训练。我们在维基百科索引中索引了QuAC训练和验证数据集中的所有段落。构建维基百科索引需要一个120GB内存的系统。我们通过将主题和QA对作为上下文传递给检索器，在检索器上执行了几个实验。</p><figure class="ln lo lp lq fd lr er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mq"><img src="../Images/b0eb2b2802eed231c21a1b1ebc7d605b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HXjX69Y74PliOa2KvQzlMg.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">Eddie文档检索器在QuAC验证数据集上的评估结果</figcaption></figure><p id="2247" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们观察到，通过这个话题，检索者的准确率从11.37%大幅提高到64.44%。</strong>类似地，将所有之前的问答对与主题一起作为上下文传递，将检索器的准确率从11.37%提高到66.24%。我们还测量检索器返回验证集所有问题的结果所花费的时间。当我们只是把主题作为上下文传递时，花费的时间最少。</p><h2 id="b6cd" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated">向读者添加上下文</h2><blockquote class="kc kd ke"><p id="0eaf" class="if ig kf ih b ii ij ik il im in io ip kg ir is it kh iv iw ix ki iz ja jb jc hb bi translated"><em class="hi">给定一个问题Q，段落P，题目T，以及一段对话历史{Q1，A1，Q2，A2，… }，我们的目标是找到答案A. </em></p></blockquote><p id="775e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了实现这个目标，我们通过传递一个上下文相关的问题来修改QuAC上Stanford attention Reader(SAR)模型的输入。上下文问题是原始问题和上下文(主题和之前的问答对)的串联。它有以下结构— <br/> &lt;话题&gt;&lt;Q1&gt;&lt;A1&gt;&lt;Q2&gt;&lt;A2&gt;……&lt;Q&gt;</p><p id="a5f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在K40 GPU上用新的输入重新训练SAR模型26小时。【DrQA适配QuAC的细节可以看<a class="ae jd" href="https://github.com/miteshksingh/Eddie/blob/master/Adapting_DrQA_on%20QuAC.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="9b28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">在QuAC验证数据集</strong> <br/>上的评测结果精确匹配准确率— 29.61 <br/> F1准确率— 45.87</p><h2 id="c5d0" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated">重述—埃迪·皮莱恩</h2><figure class="ln lo lp lq fd lr er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mr"><img src="../Images/d1aded5d1f10135f637ca5d235e1e8ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZUYeAo649LiMD2YG.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">埃迪管道公司</figcaption></figure><h2 id="00b2" class="kj jf hi bd jg kk kl km jk kn ko kp jo iq kq kr js iu ks kt jw iy ku kv ka kw bi translated">管道评估</h2><p id="3be0" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">在评估期间，我们使用QuAC的修改验证集。我们将不带原始段落的上下文问题作为查询传递给检索器。检索器从索引中检索可能包含也可能不包含正确段落的文档列表。读者从检索到的段落中获得多个答案跨度。排序器然后提供具有最高分数的区间。我们通过比较Eddie的答案跨度和黄金跨度来计算精确的匹配评估度量。</p><p id="2434" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在开放域对话设置中，Eddie具有3.03%的精确匹配准确度。<a class="ae jd" href="https://github.com/facebookresearch/DrQA" rel="noopener ugc nofollow" target="_blank"> DrQA </a>在开域班整体精确匹配准确率30%。然而，DrQA不能处理相互关联的问题，即它不是对话式的。虽然我们的管道精度较低，但我们相信它可以作为构建开放域对话系统的基线。</p><h1 id="d4dd" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">简而言之…</h1><p id="e002" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">据我们所知，Eddie是第一个尝试在开放对话环境中回答问题的人。我们建立了一个端到端的管道，可以为一系列相互关联的用户问题提供准确的答案。我们还提出了一个修改的数据集——开放域QuAC，并对我们的管道进行了评估。我们在本系列的第2部分的<a class="ae jd" rel="noopener" href="/@miteshkumarsingh/eddie-understanding-user-queries-providing-natural-responses-part-3-f2542ec3785d">中分析了我们的流水线精度低的原因。</a></p></div></div>    
</body>
</html>