<html>
<head>
<title>Web Scraping a Wikipedia Table into a Dataframe</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将维基百科表格抓取到数据帧中</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-a-wikipedia-table-into-a-dataframe-c52617e1f451?source=collection_archive---------0-----------------------#2020-08-03">https://medium.com/analytics-vidhya/web-scraping-a-wikipedia-table-into-a-dataframe-c52617e1f451?source=collection_archive---------0-----------------------#2020-08-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="1c75" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">如何将维基百科表格转换成 Python 数据帧？T3】</h2></div><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es iy"><img src="../Images/547d5a0e6584237ef8d5bdbbc93ce111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VkgykPl2Cvj1GMuK"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">来源:<a class="ae jo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><h2 id="e1c4" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">"没有数据就进行理论化是一个严重的错误。"—夏洛克·福尔摩斯</h2><p id="f739" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv ka kw kx ky ke kz la lb ki lc ld le lf hb bi translated">你们中的许多数据科学爱好者正在考虑开始一个新项目，无论是为了提高技能还是一个公司级别的项目，都需要使用<strong class="kp hj"> "data" </strong>。感谢互联网，今天我们有数百个可用的数据源。你可以很容易找到数据的地方之一是维基百科。下面是一个数据源的例子:<a class="ae jo" href="https://en.wikipedia.org/wiki/List_of_cities_in_India_by_population" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/List _ of _ cities _ in _ India _ by _ population</a></p><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es lg"><img src="../Images/5225c838c5bd463f8d2082333cbc8841.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*24s2PClv_SED4JQOhBZkUg.jpeg"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">印度城市及其人口表</figcaption></figure><p id="c568" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">我们有需要处理的数据。假设我需要印度城市的名称、它们的州和人口。现在有很多方法可以提取这些数据，比如将内容复制并粘贴到新的 excel 表格中，或者使用维基百科 API。但是，如果我告诉您，这个表可以直接转换成 Python 数据帧，以便更容易进行进一步的分析和处理，那会怎么样呢？很有趣，不是吗？</p><p id="846c" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">从网站提取数据的任务被称为<strong class="kp hj">网络搜集</strong>。这是与 API 一起从互联网上收集数据的最流行的方法之一。一些网站不提供 API 来收集他们的数据，所以我们使用数据抓取技术。一些最好的编程语言是 Node.js、C、C++、PHP 和 Python。</p><p id="fbbe" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">我们使用 Python 来完成这个特殊的任务。但是<strong class="kp hj">为什么是 Python </strong>？</p><ul class=""><li id="dbd6" class="lm ln hi kp b kq lh kt li ka lo ke lp ki lq lf lr ls lt lu bi translated">它是最流行的网络抓取语言。</li><li id="fdd3" class="lm ln hi kp b kq lv kt lw ka lx ke ly ki lz lf lr ls lt lu bi translated"><strong class="kp hj"> BeautifulSoup </strong>是基于 Python 的广泛使用的框架之一，它使得使用这种语言进行抓取变得如此容易。</li><li id="e819" class="lm ln hi kp b kq lv kt lw ka lx ke ly ki lz lf lr ls lt lu bi translated">这些高度发展的 web 抓取库使得 Python 成为 web 抓取的最佳语言。</li></ul><p id="e297" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">你需要有一些<a class="ae jo" href="https://www.w3schools.com/html/" rel="noopener ugc nofollow" target="_blank"> <strong class="kp hj"> HTML </strong> </a>页面的基础知识才能理解网页抓取。我们还需要一些像<a class="ae jo" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"><strong class="kp hj">beautiful soup</strong></a><a class="ae jo" href="https://requests.readthedocs.io/en/v0.8.2/" rel="noopener ugc nofollow" target="_blank"><strong class="kp hj">Requests</strong></a><a class="ae jo" href="https://pandas.pydata.org/pandas-docs/version/0.25.3/" rel="noopener ugc nofollow" target="_blank"><strong class="kp hj">Pandas</strong></a>这样的 python 库。</p><p id="e881" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">以下是抓取维基百科表格并将其转换为 Python 数据帧的步骤。</p><ol class=""><li id="8d42" class="lm ln hi kp b kq lh kt li ka lo ke lp ki lq lf ma ls lt lu bi translated"><strong class="kp hj">安装 BeautifulSoup </strong> : pip 安装 beautifulsoup4(到终端使用这个 pip 命令安装)</li><li id="081c" class="lm ln hi kp b kq lv kt lw ka lx ke ly ki lz lf ma ls lt lu bi translated"><strong class="kp hj">导入需要的库</strong>:请求，熊猫，美瞳。</li></ol><blockquote class="mb mc md"><p id="f596" class="kn ko me kp b kq lh ij ks kt li im kv mf lj kx ky mg lk la lb mh ll ld le lf hb bi translated"><strong class="kp hj">请求</strong> <em class="hi">是一个 Python 模块，可以用来发送各种 HTTP 请求。这是一个易于使用的库，具有许多功能，从在 URL 中传递参数到发送自定义头和 SSL 验证。</em></p><p id="fca8" class="kn ko me kp b kq lh ij ks kt li im kv mf lj kx ky mg lk la lb mh ll ld le lf hb bi translated"><strong class="kp hj"> Pandas </strong> <em class="hi">是 python 编程语言的数据分析工具。我们使用 Pandas Dataframe，它是一个带有潜在不同类型列的二维标签数据结构。你可以把它想象成一个电子表格或 SQL 表，或者一系列对象的字典。它一般是最常用的熊猫</em> <strong class="kp hj"> <em class="hi"> </em> </strong> <em class="hi">对象。</em></p></blockquote><pre class="iz ja jb jc fd mi mj mk ml aw mm bi"><span id="8737" class="jp jq hi mj b fi mn mo l mp mq">import pandas as pd # library for data analysis<br/>import requests # library to handle requests<br/>from bs4 import BeautifulSoup # library to parse HTML documents</span></pre><p id="5140" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">3.<strong class="kp hj">使用 URL 请求 HTML 响应</strong>:我们向 Wikipedia URL 发送一个 GET 请求，该 URL 的表需要被抓取，并将 HTML 响应存储在一个变量中。抓取任何网站都是不合法的，所以我们检查状态码。200 显示你可以继续下载。</p><pre class="iz ja jb jc fd mi mj mk ml aw mm bi"><span id="0dee" class="jp jq hi mj b fi mn mo l mp mq"># get the response in the form of html<br/>wikiurl="<a class="ae jo" href="https://en.wikipedia.org/wiki/List_of_cities_in_India_by_population" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/List_of_cities_in_India_by_population</a>"<br/>table_class="wikitable sortable jquery-tablesorter"<br/>response=requests.get(wikiurl)<br/>print(response.status_code)</span></pre><p id="9284" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">4.<strong class="kp hj">检查页面</strong>:为了从网站上抓取数据，我们把光标放在数据上，点击右键，进行检查。这为我们提供了 HTML 内容，通过它我们可以找到存储数据的标签。很明显，HTML 中的&lt;表&gt;标签中存储了一个表。</p><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es mr"><img src="../Images/16863a300bce6d74a1fdff9121f38e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ChMRG59gazTzZoXDhhT5Cw.jpeg"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">在 Chrome 中使用 Inspect</figcaption></figure><p id="21af" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">5.<strong class="kp hj">解析来自 HTML </strong>的数据:接下来我们创建一个 BeautifulSoup 对象，并使用 find()方法提取相关信息，在我们的例子中是&lt;表&gt;标签。在一个 Wikipedia 页面中可以有许多表，所以为了指定表，我们还传递了“class”或&lt;表&gt;标签的“id”属性。</p><pre class="iz ja jb jc fd mi mj mk ml aw mm bi"><span id="9d09" class="jp jq hi mj b fi mn mo l mp mq"># parse data from the html into a beautifulsoup object<br/>soup = BeautifulSoup(response.text, 'html.parser')<br/>indiatable=soup.find('table',{'class':"wikitable"})</span></pre><p id="2c47" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated"><em class="me">输出:</em></p><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es ms"><img src="../Images/12b81ea665fc8af857a15dad10e74e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*Fo_r6ednw6RLjtVbc3R9og.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">从维基百科页面抓取 HTML 代码</figcaption></figure><p id="1adf" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">6.<strong class="kp hj">将 Wikipedia 表转换成 Python Dataframe </strong>:我们使用 read_html()将 HTML 表读入 Dataframe 对象列表。这将返回一个列表。接下来，我们将列表转换成数据帧。</p><pre class="iz ja jb jc fd mi mj mk ml aw mm bi"><span id="c5b3" class="jp jq hi mj b fi mn mo l mp mq">df=pd.read_html(str(indiatable))<br/># convert list to dataframe<br/>df=pd.DataFrame(df[0])<br/>print(df.head())</span></pre><p id="1f34" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated"><em class="me">输出:</em></p><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mt"><img src="../Images/88b968f8dad6b98f2cf5540b2d9354c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*D0u8uJn96g7XorB9zgKXlg.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">维基百科表格到 Python 数据帧</figcaption></figure><p id="71fc" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">7.<strong class="kp hj">清理数据</strong>:我们只需要这个数据框架中的城市名称、州和人口(2011)。因此，为了更好地理解，我们从数据帧中删除了其他列，并对这些列进行了重命名。</p><pre class="iz ja jb jc fd mi mj mk ml aw mm bi"><span id="a6aa" class="jp jq hi mj b fi mn mo l mp mq"># drop the unwanted columns<br/>data = df.drop(["Rank", "Population(2001)"], axis=1)<br/># rename columns for ease<br/>data = data.rename(columns={"State or union territory": "State","Population(2011)[3]": "Population"})<br/>print(data.head())</span></pre><p id="440f" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated"><em class="me">输出:</em></p><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mu"><img src="../Images/d3f152eac42ff4408ed7c0aef0bdad92.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*OzpePqCiT71oXaDUWmoS1Q.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">干净的数据</figcaption></figure><p id="0e18" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">就是这样！！</p><p id="1f80" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">你已经将维基百科表格转换成数据帧，现在可以用于进一步的数据分析和机器学习任务。这就是使用 Python 进行 web 抓取的好处。只需几行代码，您就可以立即获得数据。</p><figure class="iz ja jb jc fd jd er es paragraph-image"><a href="https://www.buymeacoffee.com/nakullakhotia"><div class="er es mv"><img src="../Images/ddf83bcb485f106561fc652826105be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VqLYs481X9kw_CTosgqlcg.png"/></div></a><figcaption class="jk jl et er es jm jn bd b be z dx translated">如果你喜欢读这篇文章，请支持我。点击上图。谢谢你</figcaption></figure><p id="330d" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">参考我的<a class="ae jo" href="https://github.com/NakulLakhotia/Coursera_Capstone/blob/master/Wikipedia_table.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="kp hj"> GitHub 代号</strong> </a></p><p id="0f84" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated"><strong class="kp hj"> <em class="me">注</em> </strong> <em class="me">:本文中已经提到了你开始工作所需的所有资源及其链接。希望你好好利用:)</em></p></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><p id="ae3b" class="pw-post-body-paragraph kn ko hi kp b kq lh ij ks kt li im kv ka lj kx ky ke lk la lb ki ll ld le lf hb bi translated">我希望这篇文章能让你对尝试像网络抓取这样的新事物感兴趣，并帮助你增加知识。如果你喜欢读这篇文章，不要忘记点击下面的“拍手”图标。谢谢你的时间。</p></div></div>    
</body>
</html>