<html>
<head>
<title>My ML Glossary: Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我的ML词汇表:第1部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/my-ml-glossary-part-1-47d6347388a8?source=collection_archive---------20-----------------------#2020-06-22">https://medium.com/analytics-vidhya/my-ml-glossary-part-1-47d6347388a8?source=collection_archive---------20-----------------------#2020-06-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4f03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我熟悉机器学习技术时，我会记下我遇到的概念。像我这样的人可能会从中受益。词汇表的第一部分开始了。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="d48a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">混淆矩阵:</strong>分类模型的混淆矩阵是可视化性能的布局。它显示算法能够正确预测的次数。横轴显示实际标签，纵轴显示预测。例如，假设我们有一个过滤垃圾邮件的模型。可能有4种结果:</p><ol class=""><li id="5ecb" class="jk jl hi ih b ii ij im in iq jm iu jn iy jo jc jp jq jr js bi translated">当一封电子邮件实际上是垃圾邮件，并且模型也识别为垃圾邮件时，则该情况为真阳性(TP)。</li><li id="5762" class="jk jl hi ih b ii jt im ju iq jv iu jw iy jx jc jp jq jr js bi translated">当该模型将合法的电子邮件标记为垃圾邮件时，则该案例为假阳性(FP)。</li><li id="bfa2" class="jk jl hi ih b ii jt im ju iq jv iu jw iy jx jc jp jq jr js bi translated">当一个模型将一封真实的垃圾邮件标记为非垃圾邮件时，那么这个案例就是假阴性的。</li><li id="ef75" class="jk jl hi ih b ii jt im ju iq jv iu jw iy jx jc jp jq jr js bi translated">当一个模型正确地将一个非垃圾邮件消息标记为非垃圾邮件时，则该情况为真否定。</li></ol><p id="6ec2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图描述了这些情况。模型性能的这种表示被称为混淆矩阵。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es jy"><img src="../Images/df7e7ab457ed373bd3503264f2f5d20f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0A_VgFeFCor1K2k_Lt0kMw.png"/></div></div><figcaption class="kk kl et er es km kn bd b be z dx translated">混淆矩阵</figcaption></figure><p id="e49c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">1型错误:</strong>假阳性错误称为1型错误。</p><p id="6106" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">二类错误:</strong>假阴性错误称为二类错误。</p><p id="af8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">精度:</strong>是评价一个分类模型的度量。这是模型预测正确的部分。所以，<em class="ko">准确率=正确预测总数/预测总数。</em></p><p id="7f94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准确率为95%的模型意味着它能够在100次中正确分类95次。</p><p id="6deb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">精确度的公式为:</p><blockquote class="kp kq kr"><p id="ab58" class="if ig ko ih b ii ij ik il im in io ip ks ir is it kt iv iw ix ku iz ja jb jc hb bi translated">准确度= (TP+TN)/(TP+FP+TN+FN)</p></blockquote><h2 id="f528" class="kv kw hi bd kx ky kz la lb lc ld le lf iq lg lh li iu lj lk ll iy lm ln lo lp bi translated">精确度和召回率:</h2><p id="4510" class="pw-post-body-paragraph if ig hi ih b ii lq ik il im lr io ip iq ls is it iu lt iw ix iy lu ja jb jc hb bi translated">我将这两个概念放在同一个标签下，因为它们放在一起更容易理解，而且作为衡量标准，它们是成反比的。</p><p id="9523" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">精度:</strong>这是一个度量，它告诉我们，在所有具有正标签(TP和FP)的分类器中，有多少部分是正确的。这个的数学公式是:</p><blockquote class="kp kq kr"><p id="6d9c" class="if ig ko ih b ii ij ik il im in io ip ks ir is it kt iv iw ix ku iz ja jb jc hb bi translated">精度= TP/(TP+FP)</p></blockquote><p id="0ec2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回忆:它是告诉我们，在所有真实的样本中，有多少被模型识别的度量。这个的数学公式是:</p><blockquote class="kp kq kr"><p id="32dd" class="if ig ko ih b ii ij ik il im in io ip ks ir is it kt iv iw ix ku iz ja jb jc hb bi translated">召回= TP/(TP+FN)</p></blockquote><p id="8ba5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将用一个垃圾邮件过滤器的例子来解释这两者。假设我们有一个需要识别垃圾邮件的模型。现在，该模型的<strong class="ih hj"> Precision </strong>将告诉我们，被该模型标记为垃圾邮件的电子邮件中，有多少是真正的垃圾邮件。<strong class="ih hj">回忆</strong>将告诉我们，实际垃圾邮件中有多少部分被模型正确标记为垃圾邮件。</p><p id="4985" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> F1-score </strong>:精度和召回率的调和平均值。这个的数学公式是:</p><p id="1439" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">F = 2 *(精度*召回)/(精度+召回)</p><p id="9a97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们希望我们的模型有一个高的F1分数。</p><p id="d187" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">F1分数来自于F-beta指标。公式是:</p><p id="593c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">f-beta = 1/(beta *(1/精度)+(1-beta)*(1/召回))</p><p id="ae24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">β值越高，精度就越重要。例如，癌症分类模型需要高精度，因此β值会很高。</p><p id="9bef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">F1分数是当beta = 0.5时的分数，因此精确度和召回率同等重要，F-beta方程推导出F1分数的公式。</p><p id="7ade" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">灵敏度:</strong>这个指标告诉我们，在所有真实的样本中，有多少被模型识别出来。这是真正的阳性率(TPR)。这听起来熟悉吗？没错，其实是<strong class="ih hj">召回的另一种说法。</strong>不出所料，这个的数学公式是:</p><blockquote class="kp kq kr"><p id="a9d2" class="if ig ko ih b ii ij ik il im in io ip ks ir is it kt iv iw ix ku iz ja jb jc hb bi translated">灵敏度= TP/(TP+FN)</p></blockquote><p id="f948" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1 —特异性:特异性</strong>是一个度量标准，它告诉我们，在所有阴性样本(假阳性和真阴性)中，有多少是实际正确的预测(真阴性)。所以公式是:</p><blockquote class="kp kq kr"><p id="389b" class="if ig ko ih b ii ij ik il im in io ip ks ir is it kt iv iw ix ku iz ja jb jc hb bi translated">特异性= TN/(FP+TN)</p></blockquote><p id="0d75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由此我们可以推断出<code class="du lv lw lx ly b">1-Specificity</code>将会是什么。</p><blockquote class="kp kq kr"><p id="8586" class="if ig ko ih b ii ij ik il im in io ip ks ir is it kt iv iw ix ku iz ja jb jc hb bi translated">1 —特异性= FP/(FP+TN)</p></blockquote><p id="8ab4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du lv lw lx ly b">1-Specificity</code>是假阳性率(FPR)。</p><p id="ec99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">欠采样</strong>:我们的数据集经常是不平衡的。例如，在二进制分类模型中，我们的训练数据有一个名为<code class="du lv lw lx ly b">class</code>的目标标签，值为1和0。现在，如果我们在<code class="du lv lw lx ly b">class=1</code>(标为1)处的数据比<code class="du lv lw lx ly b">class=0</code>(标为0)多，那么我们的模型将倾向于<code class="du lv lw lx ly b">class-1</code>。欠采样就是用来解决这类问题的一种方法。在欠采样中，我们将随机选择一些标签为1的行，并缩小行数，使其与标签为0的行数相同或成比例。</p><p id="d497" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">过采样:</strong>过采样在不平衡类中创建平衡的另一种方法。在上面欠采样的定义中，很明显，当我们减少行数时，一些数据丢失了。为了克服这种数据丢失，需要使用过采样。过采样与欠采样正好相反。在这种方法中，少数类中的样本数量增加，使其等于多数类中的样本数量。有两种方法可以实现过采样:随机过采样和SMOTE过采样。</p><p id="3e97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">随机过采样:</strong>迭代复制少数类中的随机样本，直到两个类的大小变得相似。</p><p id="29e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> SMOTE过采样:SMOTE </strong>代表合成少数过采样技术。SMOTE的工作方式是，对于少数类的特征，它找到k个最近的邻居并将它们相互连接。例如，对于k=3，将连接特征的3个样本。然后，将通过选择位于连接路径上的点来生成合成样本。对于未完全填充的数据集，合成少数过采样技术(SMOTE)通过向少数类添加合成数据点来添加新信息。</p><p id="0ce2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">损失函数</strong>:ML模型的工作是预测估计的目标值。当它预测的值与实际目标值不相等时，它会招致惩罚。损失函数将这种损失量化为单个值。</p><p id="4f21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优化技术</strong>:优化技术寻求最小化损失。随机梯度下降(SGD)是一种优化技术。SGD对训练数据进行连续遍历，并且在每次遍历期间，一次更新一个示例的特征权重，目的是接近使损失最小化的最佳权重。</p><p id="cde8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ko">亚马逊ML使用以下学习算法:</em></p><ul class=""><li id="ff70" class="jk jl hi ih b ii ij im in iq jm iu jn iy jo jc lz jq jr js bi translated"><em class="ko">对于二元分类，亚马逊ML使用的是logistic回归(logistic loss function + SGD)。</em></li><li id="005a" class="jk jl hi ih b ii jt im ju iq jv iu jw iy jx jc lz jq jr js bi translated"><em class="ko">对于多类分类，亚马逊ML使用多项式逻辑回归(多项式逻辑损失+ SGD)。</em></li><li id="8a38" class="jk jl hi ih b ii jt im ju iq jv iu jw iy jx jc lz jq jr js bi translated"><em class="ko">对于回归，亚马逊ML使用线性回归(平方损失函数+ SGD)。</em></li></ul><p id="e9ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">超参数</strong>:训练参数用于提高模型性能。每个ML算法都有不同的超参数集。</p><p id="712e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">学习率:</strong>学习率是一个常数，用于随机梯度下降(SGD)算法中。在SGD算法中，学习速率决定了它多快达到或收敛到最优权重。线性模型权重会针对它获得的每个数据示例进行更新。更新量由学习率值决定。如果该值太大，则权重可能达不到最优解。如果该值太低，则该算法可能需要多次通过才能达到最佳权重。</p><p id="3801" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型大小:</strong>模型大小由输入特征的数量决定。如果有太多的特征，那么数据中也会有太多的模式。这将增加模型的大小。随着模型大小的增加，训练和使用模型进行预测所需的RAM大小也会增加。为了减少模型大小，我们可以使用L1正则化或设置最大大小。如果我们把模型缩小太多，可能会降低它的性能。</p><p id="4eeb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">过度拟合</strong>:当模型记忆模式而不是推广模式时。</p><p id="dc86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">欠拟合</strong>:当模型没有很好地学习模式时。</p><p id="e63e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">正则化</strong>:惩罚极端权重特征以减少过度拟合的过程。L1正则化将值较小的要素的权重降低为零。这导致稀疏的数据和更少的噪声。L2正则化降低了特征的总权重值，并稳定了具有高相关性的特征的权重。可以使用<code class="du lv lw lx ly b">Regularization Type</code>和<code class="du lv lw lx ly b">Regularization amount</code>参数设置规则化的类型和数量。大量将导致所有特征的权重为零，并且模型不会学习任何模式。</p><p id="599b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">文本特征工程</strong>:特征工程是从数据中提取有用信息的过程。文本数据的特征工程过程是文本特征工程。例如，如果我们有这样一行文本<code class="du lv lw lx ly b">45 Collins st, VIC 3000, Australia</code>，它可能对算法没有任何意义。但是当我们用分隔符(如空格、逗号)分隔文本时，我们会发现重要的信息，如街道名称、街道编号、州、邮政编码、国家等。单词袋、N-gram、Tf-idf等是一些文本特征工程方法。</p><p id="15ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">单词包</strong>:用空格将句子分割成单个单词。</p><p id="5bc9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> N-gram </strong>:是单词包的扩展。n元语法是来自给定文本或语音样本的n个项目的连续序列。</p><p id="35d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Tf-idf: </strong> Tf-idf代表<em class="ko">词频-逆文档频</em>。这是一种统计度量，用于评估一个术语对集合或语料库中的文档有多重要。</p><p id="58fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">词频</strong>:衡量一个词在文档中出现的频率，因为文档长度可以变化，所以通过除以文档长度来归一化。</p><p id="879f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TF(t) =(术语t在文档中出现的次数)/(文档中的总术语数)。</p><p id="24b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">逆文档频率</strong>:衡量一个术语的重要程度。当我们计算TF时，所有的项都是同等重要的。然而，我们知道像<code class="du lv lw lx ly b">the, of, is</code>这样的词可能会频繁出现，但对找到相关文档没有什么价值。因此，我们需要降低常用术语的权重，增加稀有术语的权重。</p><p id="d8fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">IDF = log_e(文档总数/包含该术语的文档数。)</p><p id="2297" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">归一化</strong>:最大值为1，最小值为0。其余值使用以下公式计算:</p><p id="9bf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">x` = (x-min(x))/(max(x)-min(x))</p><p id="0426" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">离群值会干扰规范化。</p><p id="9767" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">标准化</strong>:将平均值设置为零，并使用z-score计算值。Z-score使用平均值和标准偏差来计算值。</p><p id="4c30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">z = (x均值)/sd</p><p id="48a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，mean = x值的平均值，sd =值的标准偏差</p><p id="2e55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">未完待续…</p></div></div>    
</body>
</html>