<html>
<head>
<title>Benchmarking data: Parallel Distributed Training of Deep Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基准数据:深度学习模型的并行分布式训练</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/benchmarking-data-parallel-distributed-training-of-deep-learning-models-in-pytorch-and-tensorflow-99613f00987d?source=collection_archive---------12-----------------------#2019-12-24">https://medium.com/analytics-vidhya/benchmarking-data-parallel-distributed-training-of-deep-learning-models-in-pytorch-and-tensorflow-99613f00987d?source=collection_archive---------12-----------------------#2019-12-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="8ae2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">TL；博士；医生</h1><p id="cb91" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我使用PyTorch DataParallel和TensorFlow MirroredStrategy来改变数据集大小、模型大小、批处理大小以及GPU和train的数量。我注意到TensorFlow具有更高的处理速率和更大的规模，但我认为TensorFlow MirroredStrategy和PyTorch DistributedDataParallel之间的比较更公平。</p><p id="1eef" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">代号:<a class="ae kg" href="https://github.com/r-o-s-h-a-n/data_parallel_benchmark" rel="noopener ugc nofollow" target="_blank">https://github.com/r-o-s-h-a-n/data_parallel_benchmark</a></p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kh"><img src="../Images/dbe2b10059b57e42854988ee439d1892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*GBikug4eMTrN5g_t.jpg"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">服务器的嗡嗡声帮助我疏导我的编码能量。图为:不是我。</figcaption></figure><h1 id="6004" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">简介</strong></h1><p id="acb5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">近年来，深度学习模型已经成为从不断增加的数据量和复杂性中进行学习的最先进的模型。深度学习模型需要大量的数据来提取有用的特征。这个过程可能需要大量的时间来训练——大约几周。由于某些计算的重复性，分布式计算在这个领域有了价值。分布式深度学习可以分为两个潜在重叠的子类别:模型并行和数据并行。</p><h2 id="e65f" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">模型并行性</h2><p id="99ca" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在模型并行中，模型的各个部分位于不同的处理器上。只有具有跨越分区边界的边的节点才需要在机器之间传输它们的状态。如果一个模型太大而无法在单个GPU上运行，那么训练几乎肯定需要某种形式的模型并行性。数据并行的一个突出的早期成功例子是Google的DistBelief模型[1]。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lh"><img src="../Images/7a7e71484fb5dc71dba69327ada54395.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/0*wc2vyDN6X6Z3fcDI"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图一。dist faith模型跨多台机器进行划分。粗体的边要求跨机器传输。[1]</figcaption></figure><h2 id="5095" class="kt ig hi bd ih ku kv kw il kx ky kz ip jo la lb it js lc ld ix jw le lf jb lg bi translated">数据并行性</h2><p id="8c25" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在数据并行中，训练数据被划分到不同的处理器上，并且每个模型被复制到不同的机器上。每台机器根据本地包含的数据训练其复制品，并且共享参数更新。共享权重更新的方法是研究的主题。这些方法可以同步或异步执行，每种方法都有自己的挑战。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lh"><img src="../Images/5bba98ef47b920102643b6084cf34f8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/0*cf1kNcjUWY64FFmF"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图二。数据并行的参数服务器方法。[2]</figcaption></figure><p id="bdb0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在参数服务器方法中，每个处理器与参数服务器共享其权重更新。参数服务器负责存储模型的当前全局状态。处理器在训练后将权重更新写入参数服务器，并在训练前读取最新的权重。这个方法遇到了读写参数服务器的瓶颈问题。</p><p id="be7c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">更有效的方法是环全归约。这是由优步Horovod软件[3]推广的，但现在已经在包括TensorFlow在内的其他包中实现了。在这种方法中，没有中央参数服务器，但是机器形成一个环，并且每台机器仅从一台其他机器监听，并且向一台其他机器发送基于元素的更新。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es li"><img src="../Images/d6a9e4bd38b030f260e339339cb1fff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CDJkPdkVta6mSDNo"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图3。来自优步·霍罗沃德论文的环形全图。在状态传输阶段，更新状态的元素在环形结构中一次共享一个。[3]</figcaption></figure><h1 id="8ec6" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">评估系统</h1><p id="bb90" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">执行数据并行分布式深度学习的软件包有很多。其中最突出的两个是TensorFlow [4]和PyTorch [2]，本文将对它们进行评估。</p><p id="0766" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">TensorFlow distributed [4]提供了多种分发策略。我评估了Keras API上的同步镜像策略。在MirroredStrategy中，每个GPU接收一部分训练数据以及模型的副本。每个GPU都在本地进行训练，然后使用高效的all-reduce算法传递变量更新。</p><p id="1b46" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">PyTorch提供DataParallel，用于在具有多个内核的单台机器上进行数据并行训练。它的工作方式类似于TensorFlow MirroredStrategy，其中每个核心都包含模型的副本。然而，我观察到了两个关键的区别。在TensorFlow MirroredStrategy中，每个GPU都在静态数据分片上训练，而在PyTorch DataParallel中，每个GPU在每次批量迭代中都接受一批数据，这可能会导致通信成本增加。此外，PyTorch使用参数服务器策略，并且没有给出改变通信策略的选项。[5]在以前的工作中已经看到全归约策略比参数服务器更有效。[3]</p><p id="c4e6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在运行我的实验之后，我后来发现PyTorch确实有一个被称为DistributedDataParallel的框架，预计比DataParallel快。一个优化是，它在训练时间之前对数据进行分片，而不是在每次批量迭代时。在未来的研究中，将它的性能与TensorFlow MirroredStrategy进行比较是合适的。</p><h1 id="f28f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">方法</h1><p id="8135" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于我的实验，我在MNIST数字数据集上进行训练。我改变了GPU的数量、批量大小、数据集大小和模型大小。我记录了训练第一个纪元和第二个纪元的时间。在第一个时期，模型可能会产生一次性启动成本，例如数据分片。因为同步数据并行训练的操作是确定性的:正向传递、计算损失、反向传播误差、梯度步长，许多资源在各时期之间变得空闲，所以该模型在第二时期和所有未来时期期间将可能具有相似的运行时间。为此，我只记录第一和第二个纪元的火车时间。</p><p id="81c3" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">MNIST数据集包含60k训练集图像和10k测试集图像。当我改变训练集大小时，我简单地将MNIST数据集连接到其自身的副本。我在1x MNIST、4x MNIST和8x MNIST上运行实验，它们对应于60k、240k和480k的图像。</p><p id="fc8c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我在每批128、256和512张图像之间改变批量大小。我使用两种尺寸的模型:具有402，442个可训练参数的较小模型，以及具有2，636，554个可训练参数的较大模型。都使用交叉熵损失和adam优化器，参数:学习率=0.001，beta =(0.9，0.999)，eps=1e-07，weight_decay=0，amsgrad=False。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es ln"><img src="../Images/d7e6bedcdc5b085390480db84c13fd2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/0*fsEYAaWE7h7Ti1l-"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图4。用于图像分类的小型和大型模型结构。小模型包含402，442个可训练参数，大模型包含2，636，554个可训练参数。</figcaption></figure><p id="6508" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">GPU的数量在1、2和4之间变化。所有实验都是在谷歌云平台上由n1-highmem-2 (2个vCPUs，13 GB内存)和数量可变的NVIDIA Tesla K80 GPUs组成的机器上运行的。TensorFlow实验在使用谷歌、英特尔优化的深度学习图像的实例上运行:TensorFlow 2.0.0。PyTorch实验是在Google的实例上运行的，深度学习图片:PyTorch 1.2.0。</p><h1 id="3c8b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结果</h1><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lo"><img src="../Images/914130386677b79694e931deb6fc3dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8gu2njIbZY_umHAmxYwqmQ.png"/></div></div></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lp"><img src="../Images/247b41e3139d50be95ce4e0922dbc490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B8DW9E7AEsSVwmoY2sYuVw.png"/></div></div></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lq"><img src="../Images/2b766d376ec9ad471d9b67dbf3df6865.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oal8sSDqYskFQEsTbUTQqQ.png"/></div></div></figure><p id="4c87" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在图5a中，对于采用1x MNIST数据集的小型模型上的TensorFlow，秒历元处理速率会随着GPU数量的增加而非直觉地降低。在PyTorch上，我们看到第二个纪元的处理速度随着GPU的增加而增加。结果表明，对于TensorFlow，数据集大小或模型大小都很小，并行化带来的开销超过了并行化带来的速度提升。</p><p id="4f14" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们在图5c中看到，总的第二历元训练时间随着GPU的增加而减少，并且当我们使用更大的数据集时，这种影响更加明显。然而，我们在图5e中看到，当我们只改变数据集大小时，处理速度保持不变。这与图5a的结果形成对比，图5a显示，当我们增加模型大小时，处理速率随着GPU的增加而增加。这种效果似乎变成抛物线，在2 GPUs时具有最佳性能。也许这个实验中使用的大约260万个参数的大型模型仍然不够大，不足以利用4 GPUs的数据并行性。</p><p id="ce59" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">此外，我们在图5b中看到，对于给定数量的GPU，增加的批量会提高处理速度，但这种影响随着GPU数量的增加而更加明显。当批处理大小最大化每个设备上的可用内存时，数据并行效果最佳。(批量大小是一个学习参数，在没有调整学习速率的情况下不应调整。)总的来说，我们注意到TensorFlow MirroredStrategy优于PyTorch DataParallel，并且不同的策略对处理速度有显著的影响，特别是当比较第一和第二时段训练处理速度时(图5d)，其中TensorFlow在第一时段中似乎较慢，这可能是由于数据分片。</p><h1 id="4287" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结论</h1><p id="81fc" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">就易用性而言，在PyTorch中实现数据并行比在TensorFlow中更简单。然而，我们观察到TensorFlow MirroredStrategy比PyTorch DataParallel具有更快的处理速度和规模。这可能部分是由于其最初的缓慢时期，在此期间它将数据分段。然而，这可能不是苹果对苹果的比较，未来的研究应该将TensorFlow MirroredStrategy与PyTorch DistributedDataParallel进行比较。</p><h1 id="c083" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">引用的作品</h1><p id="0453" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">[1]迪恩，杰弗里，等，“大规模分布式深度网络”<em class="lr">神经信息处理系统的进展</em>。2012.</p><p id="845a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">[2] PyTorch (2019)版本1.2.0。Github仓库。https://github.com/pytorch/pytorch<a class="ae kg" href="https://github.com/pytorch/pytorch" rel="noopener ugc nofollow" target="_blank"/></p><p id="0356" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">[5]拉什卡、塞巴斯蒂安和埃里克·关。"皮托尔奇如何与拉什卡、塞巴斯蒂安和埃里克·关相提并论. "PyTorch的并行方法和分布式方法是如何工作的？"<em class="lr"> PyTorch </em>，2018年11月，discuse . py torch . org/t/how-pytorchs-parallel-method-and-distributed-method-works/30349/16。</p><p id="6451" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">[3]谢尔盖耶夫、亚历山大和迈克·德尔·巴尔索。" horo VOD:tensor flow中快速简单的分布式深度学习."<em class="lr"> arXiv预印本arXiv:1802.05799 </em> (2018)。</p><p id="d8c2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">[4]tensor flow(2019)2 . 0 . 0版本。Github仓库。代号:<a class="ae kg" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/tensorflow</a>文件:<a class="ae kg" href="https://www.tensorflow.org/guide/distributed_training" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/distributed_training</a></p></div></div>    
</body>
</html>