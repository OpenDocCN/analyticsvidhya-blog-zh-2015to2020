<html>
<head>
<title>NLP Representations Techniques Part2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP表示技术第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/nlp-representations-techniques-part2-86b2fd4e04b9?source=collection_archive---------21-----------------------#2020-06-10">https://medium.com/analytics-vidhya/nlp-representations-techniques-part2-86b2fd4e04b9?source=collection_archive---------21-----------------------#2020-06-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0fc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在之前的博客中，我们已经看到了如何使用一包单词和TF-IDF将NLP数据转换为向量，然后在此基础上开始运行一些算法。如果你想了解他们，点击<a class="ae jd" rel="noopener" href="/@shivambatra76/nlp-representations-techniques-e6d69096d4ad"> <strong class="ih hj">这里</strong> </a>。在这篇文章中。我将解释像单词嵌入这样的嵌入技术，这些嵌入是如何生成的，以及如何使用单词嵌入来生成句子嵌入。</p><h1 id="5087" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">TFIDF问题</h1><p id="35d5" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">首先，我想告诉大家TFIDF的一些问题，以及为什么我们可能不想在工业规模的应用中使用它。<br/> TFIDF和单词包从你的数据集中生成向量，所以你的数据集中的每个单词都将被视为一个特征，从而产生非常大的向量表示。假设你有一个10K单词或更多的单词，这很常见。那么为每个句子生成的每个向量将具有10K或更大的大小。</p><p id="7bd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比如:<br/>我讨厌电影→【1，0，0，0.3，…。bunch zeroessss](1 * 10K大小或更大)<br/>假设你有一个5万句的数据集，你想在这个数据集上训练你的模型。然后，转换后的训练集将是一个形状为50000*10000的矩阵，这可能不适合您的内存，而且这是一个非常大的稀疏矩阵(它有很多零，或者不包含那么多信息)。此外，这些向量没有我将在本文后面解释的语义信息。</p><p id="1821" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为你已经从训练集中生成了向量，假设你在测试期间得到了一个新单词，而这个单词不在你的词汇表中，你将得到一个零分，这是不好的，因为这个单词可能接近训练集中的某个单词，但你仍然得到一个零分。这也适用于拼写错误和其他因素，如大写单词或词干技术，但可以通过编写脚本或监控预处理阶段来解决。<br/>但是我们如何解决这种类似的文字问题呢？<br/>这可以通过使用预训练模型(如手套)或一些最新的基于变压器的模型(如BERT或XLNET)中的单词嵌入来解决。</p><h1 id="6883" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">单词嵌入</h1><p id="cf77" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">词嵌入是一种特殊的向量，它可以表示文本，同时保持文本之间的语义相似性。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kh"><img src="../Images/d86e85463180151d664bd901b97cee4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RW-6qy-fEojYCbTQdS9MpA.png"/></div></div></figure><p id="61e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词嵌入背后的直觉是生成向量，使得彼此相似的单词在特征空间中彼此靠近。这只是一张图片，显示了风扇、灯、led和灯泡等词相互靠近，冰箱、微波炉和烤箱等词相互靠近。但是我们如何生成这些嵌入或向量呢？<br/>想法是你创建一个神经网络，给它一个任务来预测序列中的下一个单词，通过这样做，模型将学习单词和它们的上下文之间的差异。</p><h2 id="2d5a" class="kt jf hi bd jg ku kv kw jk kx ky kz jo iq la lb js iu lc ld jw iy le lf ka lg bi translated">生成单词嵌入的过程。</h2><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lh"><img src="../Images/c8432e56ecf1a31d0ce4378117a8e8d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0TUtOl9cFJGXpD78oOJ8_Q.png"/></div></div></figure><p id="84b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们希望建立一个神经网络，它可以将单词作为输入，并生成一个新单词作为输出，通过这样做，模型将学习单词之间的映射。</p><p id="93a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将拥有:</p><ol class=""><li id="420f" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated">输入层</li><li id="5b5d" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">隐蔽层</li><li id="7f03" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">输出层</li></ol><p id="1fb8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们首先对vocab中的每个单词使用一个热编码向量表示。</p><blockquote class="lw lx ly"><p id="a847" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">例如，你有一个这样的词汇</p><p id="2aec" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">vocab →{喜欢:1，电影:2，无聊:3，讨厌:4}</p></blockquote><p id="af71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi md translated">对于热向量，我们将创建一个与vocab大小相同的向量，用零填充，然后在单词索引所在的位置标记1。</p><p id="5688" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后一个热点矢量表示会是这样的</p><blockquote class="lw lx ly"><p id="6cd1" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">爱过→[1，0，0，0](vocab的大小= vocab的大小)<br/>电影→[0，1，0，0] <br/>无聊→[0，0，1，0] <br/>讨厌→[0，0，0，1]</p></blockquote><p id="c528" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在给定一个单词序列，你可以传递一个单词序列作为输入，一个单词作为输出<br/>你必须决定你将给出多少个单词作为输入，然后这将创建一个输入向量，看起来像</p><blockquote class="lw lx ly"><p id="26f4" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">[第一个字热编码矢量，第二个字热编码矢量，…等等]</p><p id="2eee" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">输入向量的大小=要考虑的字数*一键向量表示的大小(或vocab的大小)</em> </strong></p></blockquote><p id="5352" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以你会有<br/> 1)one-hot encode输入向量(姑且称之为I) <br/> 2)一些矩阵(W)这是我们要在整个过程中学习的隐藏层的权重。<br/> 3)输出向量(G →地面真实值)</p><p id="435d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们可以在输出层使用softmax函数来训练这一切，以最大化地面真实的可能性，并使用梯度下降来最小化损失。<br/>现在您可以计算:</p><blockquote class="lw lx ly"><p id="7726" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">使得损失最小</p></blockquote><p id="c2a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，一旦你训练了你的模型，你就可以使用这个隐藏层为你的输入提供单词嵌入。所以你将删除最后一层并在输入中传递一个新的测试数据，最后隐藏的输出被当作单词嵌入。<br/>一般来说，这些网络要深得多，也就是说，它包含更多的层，并在更大的vocab大小上进行训练，如400K甚至更大。<br/>该任务的培训方法和架构有多种变化</p><h2 id="bc83" class="kt jf hi bd jg ku kv kw jk kx ky kz jo iq la lb js iu lc ld jw iy le lf ka lg bi translated">单词嵌入生成方法</h2><p id="2c47" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">1)你可以只看一个单词，试着在上下文中为接下来的单词训练它。你将给出一个单词输入，并产生一个单词序列。这类似于Word2Vec使用的Skip-gram方法。</p><p id="e623" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2)您可以查看序列，即输入中的单词序列和输出中的一个单词。这类似于用于训练单词嵌入的连续单词包方法。你可以在这里阅读更多<a class="ae jd" href="https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a></p><p id="7cab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3)还有一种方法，其中我们使用一个特殊的令牌跳过其中一个单词，并在作为输入的单词序列上训练网络，模型试图预测被跳过的单词。这用于训练一些最新的基于变压器的模型，如BERT。</p><p id="9655" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">幸运的是，我们不必从头开始训练这些网络，我们可以使用这些开源的预训练模型。其中有Glove、Bert和多语言Bert。在下一部分，我将向您展示如何在您的项目中使用它们中的每一个。但是首先，看看Word2Vec。</p><h1 id="c765" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">Word2Vec</h1><p id="a035" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">Word2Vec是Google提出的第一个单词嵌入模型。它可以用于根据您的训练集专门为您的领域创建嵌入。</p><p id="13d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我有一个不同领域的新闻文章数据集，如体育、娱乐和政治，所以我只是将它们添加到一个文件中，并将其作为模型的输入来学习单词嵌入。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es mm"><img src="../Images/73746a3bc98e1bd451247e0342c28b56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u6yWvEe2SUXwhsitp4xIwg.png"/></div></div></figure><p id="9c88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是我的模型在这个过程中学到的单词嵌入，因为你可以看到单词利润，提升，巨大，公司紧密地躺在一起，远离像月和年这样的单词。</p><blockquote class="lw lx ly"><p id="e13b" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated"><strong class="ih hj">如果想用Word2Vec训练自己的单词嵌入。去我的</strong> <a class="ae jd" href="https://github.com/shivambatra76/WORD-EMBEDDINGS" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> GITHUB </strong> </a> <strong class="ih hj">随便用。</strong></p></blockquote><h2 id="ad00" class="kt jf hi bd jg ku kv kw jk kx ky kz jo iq la lb js iu lc ld jw iy le lf ka lg bi translated">如何使用单词嵌入</h2><p id="f6c3" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">现在我们已经看到了如何创建和生成单词embedding。</p><p id="181c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是单词嵌入，而不是像我们在单词包方法和TFIDF中使用的句子嵌入。</p><blockquote class="lw lx ly"><p id="5bd2" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">句子嵌入是为每个句子ie生成的固定大小的向量。</p><p id="edb8" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">[一些数字…](向量的大小等于vocab的大小)</p><p id="c985" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">但是单词嵌入是每个单词的固定大小的向量</p><p id="c30e" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">[一些数字…..](尺寸取决于型号)</p></blockquote><p id="0689" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们通常有可变长度的句子，那么我们如何使用单词嵌入来生成固定长度的向量，以便我们可以对它应用一些机器学习或深度学习算法。</p><p id="762a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我已经探索并尝试了这些方法，你也可以使用它们。</p><h2 id="3f8a" class="kt jf hi bd jg ku kv kw jk kx ky kz jo iq la lb js iu lc ld jw iy le lf ka lg bi translated">平均法</h2><p id="412e" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">这是一个非常基本的方法，但是效果相当好。</p><p id="94d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们有一个长度为4的句子。</p><blockquote class="lw lx ly"><p id="5b9b" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">单词1 →单词1的嵌入</p><p id="d485" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">单词2→单词2的嵌入</p><p id="0601" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">单词3→单词3的嵌入</p><p id="36fd" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">单词4→单词4的嵌入</p></blockquote><p id="78bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为所有的嵌入都来自同一个模型，所以它们将是大小相等的向量。我们可以计算包含所有单词信息的所有向量的平均值，然后将该平均向量视为句子嵌入。</p><blockquote class="lw lx ly"><p id="7c5c" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">例如:</p><p id="432a" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">向量1 →[1，3，5]</p><p id="c0ac" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">向量2 →[3，5，1]</p><p id="bdfa" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">平均向量→[2，4，3]每个维度的平均值</p></blockquote><h2 id="e624" class="kt jf hi bd jg ku kv kw jk kx ky kz jo iq la lb js iu lc ld jw iy le lf ka lg bi translated">串联方法</h2><p id="0003" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">在这种方法中，我们可以设置一个固定长度的句子，然后将嵌入的单词水平堆叠，得到一个句子向量。</p><p id="b841" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如:</p><p id="caf4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词1 →单词1的嵌入</p><p id="cde6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词2→单词2的嵌入</p><p id="bd56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词3→单词3的嵌入</p><p id="1cda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词4→单词4的嵌入</p><p id="2f20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们假设你的句子长度是4</p><blockquote class="lw lx ly"><p id="9e90" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated"><strong class="ih hj">句子嵌入:</strong></p><p id="b35e" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">[单词1嵌入、单词2嵌入、单词3嵌入、单词4嵌入]</p><p id="e39d" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">(句子嵌入的大小=句子长度*单词嵌入)</p></blockquote><p id="3b82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在实践中，我们有一个更长的句子长度，我们用零填充缺失的单词嵌入。</p><p id="1428" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以如果你在一个句子中有3个单词，但是你的句子嵌入长度是4。那么，在这种情况下，我们将使用填充技术，简单地在缺少的值中添加零，这样我们就保持了特定的长度。</p><blockquote class="lw lx ly"><p id="c248" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated"><strong class="ih hj">句子嵌入:</strong></p><p id="4771" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">[word1嵌入，word1嵌入，word1嵌入，[0，..一串零](单词嵌入的大小)]</p><p id="28e9" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">(句子嵌入的大小=句子长度*单词嵌入)</p></blockquote><blockquote class="mn"><p id="6c22" class="mo mp hi bd mq mr ms mt mu mv mw jc dx translated">有时候我们也会出现这种情况，你的句子长度设置为4，但是你输入的句子超过了4。在这种情况下，我们必须将句子删减到所需的句子长度。这可以从开始或结束时进行</p></blockquote><p id="fe18" class="pw-post-body-paragraph if ig hi ih b ii mx ik il im my io ip iq mz is it iu na iw ix iy nb ja jb jc hb bi translated">这是我们用来训练基本神经网络的东西。</p><h2 id="521d" class="kt jf hi bd jg ku kv kw jk kx ky kz jo iq la lb js iu lc ld jw iy le lf ka lg bi translated">生成嵌入矩阵方法</h2><p id="f173" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">这种方法用于训练一些先进的神经网络，如LSTMS，RNNS和GRU</p><p id="86e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，你有一个这样的词汇。</p><blockquote class="lw lx ly"><p id="144a" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">vocab →{喜欢:1，电影:2，无聊:3，讨厌:4}</p></blockquote><p id="7c65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将把我们的句子和词汇分配给每个单词。</p><blockquote class="lw lx ly"><p id="6c81" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">注意:我们不会给1分或TFDIF分。</p></blockquote><p id="582f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">示例:</p><p id="ce20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我喜欢这部电影</p><p id="9b09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">喜爱的电影→[1，2，0，0，0](1用于vocab中分配的令牌，2用于相同的令牌，0用于填充)(向量长度=句子长度)</p><p id="1f37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种方法中，我们采用我们的vocab，并为vocab中的每个单词生成嵌入，从而创建一个嵌入矩阵。</p><blockquote class="lw lx ly"><p id="e913" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">嵌入矩阵看起来会像这样:</p><p id="a696" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi">[</p><p id="6c3b" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">word1，word1嵌入]，</p><p id="0c64" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">word2，word2嵌入]</p><p id="975a" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi">…</p><p id="f714" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi translated">单词n [单词n嵌入]</p><p id="71c1" class="if ig lz ih b ii ij ik il im in io ip ma ir is it mb iv iw ix mc iz ja jb jc hb bi">]</p></blockquote><p id="b3cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，标记1的单词嵌入将在嵌入矩阵的第一行，同样标记2的单词嵌入在嵌入矩阵的第二行。</p><p id="039d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在将把这些符号化的句子输入馈送到模型，并提供这个嵌入矩阵作为嵌入层的权重。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es nc"><img src="../Images/ce9ed6a2d5d360bb512d44d26069f785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NKhwsOYNUT5xU7Pyf6Znhg.png"/></div></div></figure><p id="2a93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是神经网络中使用的展开的RNN细胞的图像。我不会深入RNN的细节，因为这不是本文的范围，但我会给你一些想法。</p><p id="d7a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个想法不是一次性处理整个句子。这些RNN细胞处理一个单词作为输入，并产生一个隐藏状态，这是一段编码信息。然后，这个隐藏状态与作为输入的下一个单词一起被反馈到RNN单元，这个过程被重复，直到整个序列被处理，然后最终的隐藏包含关于作为输入给出的所有单词的信息。现在，这个最终的隐藏状态被认为是句子嵌入，这些句子嵌入被馈送到神经网络，该神经网络将在分类或一些其他任务上被训练。</p><p id="aaeb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望你看完这篇文章后有所收获，如果你需要任何帮助，请联系<a class="ae jd" href="https://www.linkedin.com/in/shivam-batra-34b63a17a/" rel="noopener ugc nofollow" target="_blank"> me </a>。</p><p id="9f70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我在第3部分讨论了Glove、BERT嵌入和多语言嵌入。你也可以在这里查看<a class="ae jd" rel="noopener" href="/analytics-vidhya/nlp-representation-techniques-part-3-18383b037e15"><strong class="ih hj"/></a><strong class="ih hj">。</strong></p><p id="cc83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">领英:<a class="ae jd" href="https://www.linkedin.com/in/shivam-batra-34b63a17a/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/shivam-batra-34b63a17a/</a></p><p id="4142" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">https://github.com/shivambatra76</p></div></div>    
</body>
</html>