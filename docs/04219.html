<html>
<head>
<title>Natural Language Processing (NLP) Workflow/Tutorial for Binary Classification in Sci-kit Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Sci-kit Learn中二进制分类的自然语言处理(NLP)工作流/教程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/natural-language-processing-nlp-workflow-tutorial-for-binary-classification-in-sci-kit-learn-b9f94c6aaf14?source=collection_archive---------7-----------------------#2020-03-10">https://medium.com/analytics-vidhya/natural-language-processing-nlp-workflow-tutorial-for-binary-classification-in-sci-kit-learn-b9f94c6aaf14?source=collection_archive---------7-----------------------#2020-03-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/0ebd46f8ce6142600f35eb0706c82b9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bqdc4Ma8AE-xXbw_1xZOPg.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">图片来自:<a class="ae hv" href="https://www.xoriant.com/blog/machine-learning/natural-language-processing-the-next-disruptive-technology-under-ai-part-i.html" rel="noopener ugc nofollow" target="_blank">https://www . xoriant . com/blog/machine-learning/natural-language-processing-the-next-disruptive-technology-under-ai-part-I . html</a></figcaption></figure><div class=""/><p id="1226" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">本文将概述和描述我构建二元分类器的工作流，该分类器可以通过自然语言处理(NLP)技术，根据帖子中的内容成功预测帖子来自哪个子编辑。使用的主要编程语言是Python，一些导入的库是:nltk、regex、pandas、wordcloud、sklearn和beautiful soup。这篇文章中包含了一些代码，但大部分是NLP专有的，不会包含太多基本的Python、Pandas、Webscraping等。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h2 id="a6b6" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">网页抓取和数据框架</h2><p id="07a3" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">我能够使用Beautiful Soup和<a class="ae hv" href="https://github.com/pushshift/api" rel="noopener ugc nofollow" target="_blank"> PushShift API </a>提取6000个帖子:3000个来自r/NeutralPolitics，3000个来自r/PoliticalDiscussion。然后我创建了两个熊猫数据框，包含了每个子编辑的所有帖子。现在我已经组织好了我的文本数据。接下来，我必须对它进行预处理，然后才能适合模特。这需要多个步骤:</p><h2 id="3cf0" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">符号化</h2><p id="a001" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">虽然标记化可以在我稍后将使用的矢量器中自动完成，但我希望在整个NLP过程中获得经验和理解。使用nltk中的Regexp标记器，我标记了我的每一列。</p><figure class="lb lc ld le fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es la"><img src="../Images/ce96d02defa3d231bb1b377f5b7d6c27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dY7Indtdn0eyqfC1vYgLIg.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">正则表达式标记器的实例化，然后在我的文本数据上应用它。向Rachel Koenig致敬，她的代码和有影响力的NLP文章在这里找到:<a class="ae hv" href="https://towardsdatascience.com/nlp-for-beginners-cleaning-preprocessing-text-data-ae8e306bef0f" rel="noopener" target="_blank">https://towards data science . com/NLP-for-初学者-清理-预处理-文本-数据-ae8e306bef0f </a></figcaption></figure><h2 id="edc0" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">停止言语</h2><p id="a6fd" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">接下来，我决定手动删除文本中的停用词。同样，这可以是矢量器中的一个过程，但我选择手动执行。我用nltk.corpus停用词集作为我的初始停用词集。在我的项目中稍后运行测试之后，我会回到这个问题，用nltk.corpus中没有包括但与我的目标相关的附加停用词来更新它。其中大部分是互联网相关词汇，如“www”、“org”、“http”等。</p><figure class="lb lc ld le fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lf"><img src="../Images/604937addad81678f5a7a44aaefe4351.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pzk6RzujlJIoWz_WsbE-cg.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">创建停用词集并在函数中实现它们</figcaption></figure><h2 id="2b0a" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">词汇化</h2><p id="08a8" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">与标记化和添加停用词不同，这个过程不是用矢量器自动完成的，所以我必须手动完成。尽管对NLP来说，lemmatizing并不总是必要的，但它可以提高模型的性能，我就是这样做的。我使用了WordNetLemmatizer，它也来自nltk库。首先，我使用Rachel Koenig的方法创建了一个将文本进行lemmatize的函数，然后在我的列上的lambda函数中调用它。</p><figure class="lb lc ld le fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lf"><img src="../Images/d6aeade19e63d6a8f79ff0ebc2773752.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hV7RXMtTGthb0qvDq3mFmA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">实例化Lemmatizer，在函数中使用它，并在lambda函数中实现该函数</figcaption></figure><h2 id="f0a7" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">堵塞物</h2><p id="cb5b" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">我使用同样来自nltk库的PorterStemmer遵循了上面相同的协议。我建议为您的项目尝试每种工具。我尝试在不进行词汇化的情况下对数据进行词干化，反之亦然，两者都用。对于这个项目，在我的文本数据上使用这两种方法后，我得到了最好的结果。</p><figure class="lb lc ld le fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lf"><img src="../Images/55248814fabfecc9613de3ca64fb2a17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mzriyBe4Wp5zc8jcZr5EIg.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">实例化斯特梅尔，在函数中使用它，并在lambda函数中实现该函数</figcaption></figure><p id="44d4" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意:如果您使用词干分析器和词汇分析器，请确保使用. join或与您最后使用的工具等效的工具，以便您的文本可以在一个大字符串中保持连接，但用逗号分隔。</p><h2 id="66dc" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">模型准备</h2><p id="253a" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">文本数据几乎都是为了建模而设置的！只剩下最后几个步骤了。在这一点上，每个子编辑仍然在单独的数据帧中进行预处理，所以现在是时候将它们组合起来了。这里我使用了pandas concat函数。我还在同一列中添加了提交的标题文本和自我文本，这样我就可以在模型中包含尽可能多的文本。这个新的组合列将是我在预测它所来自的subreddit的名称时唯一的X特征，这是我的y。然后，我使用train test split将我的数据分成多组训练和测试数据。</p><figure class="lb lc ld le fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lf"><img src="../Images/9be01221d476b3fe29051f5ccffd1200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3KRn3s2xB5TuQXhgLIh5hA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">使用Pandas concat函数</figcaption></figure><figure class="lb lc ld le fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/761dc5c5a4de10f842480ff9cf97ebba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UC6g125ByOJ5xCl-ymdklQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">因为每一列都是由字符串组成的，所以我只是将它们加在一起。向我的同事Amit Marwaha致敬，感谢他对我的项目做出的贡献</figcaption></figure><h2 id="1f75" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">矢量化</h2><p id="890d" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">让我们的文本数据为建模做好准备的最后一步是将其矢量化！也就是说，我们使用Count和Tfidf矢量器将文本转换成数字数据。为了方便和实验，我为我的X训练和测试数据创建了count和tfidf矢量化变量。通过这种方式，我可以在所有不同的模型上快速、轻松地试验每个版本的矢量化数据，看看哪个矢量化工具对每个模型的性能更好。这些矢量器可以用不同的参数修改。我建议尝试许多不同的选项，尤其是ngram系列。</p><figure class="lb lc ld le fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lf"><img src="../Images/41c7c501d9bd42df4fef92386f5d086e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uJ8vAsqgLtRbmWsSYK0jaw.png"/></div></div></figure><h2 id="3829" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">建模</h2><p id="7d46" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">说到建模，我有太多的选择。这里有足够的自由和实验空间。如果你有时间和计算资源，我建议你运行多个管道，尝试调整模型和矢量器的许多不同的超参数。我试验了一些不同的模型，包括逻辑回归、支持向量机和多项式朴素贝叶斯。</p><h2 id="4014" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">估价</h2><p id="60e9" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">基于Tfidf矢量化数据的支持向量机最终表现最佳，达到96.8%的准确率，相比之下，计数矢量化版本的准确率为86.6%。该分数表示该模型根据标题和自我文本预测帖子来自2个子编辑中的哪一个的准确度。</p><h2 id="aebc" class="ka kb hy bd kc kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku bi translated">数据可视化</h2><p id="e73f" class="pw-post-body-paragraph iv iw hy ix b iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo kz jq jr js hb bi translated">在创建了我的模型之后，我回去直观地探索数据。这包括创建单词云来以一种美观的方式表现最流行的单词，并创建条形图来做同样的事情。</p><figure class="lb lc ld le fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lf"><img src="../Images/a0d2629f5126f308d4405a22d8782bd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E0Uf3PZQJUqS_sAt1pOEWA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">下面是单词云的代码</figcaption></figure><figure class="lb lc ld le fd hk er es paragraph-image"><div class="er es lh"><img src="../Images/a8b1607746c1c331cf2114795f6f360c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*JOhEVdwEidhjy-DJR0J3BQ.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">帖子标题和两个子编辑的自文本中最流行的词的词云</figcaption></figure><figure class="lb lc ld le fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lf"><img src="../Images/c7e8703de963981ebef38fbff46cdb2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sJlEy1XQdsr0upUqDaiCag.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">每个子主题中最流行的词及其频率</figcaption></figure><p id="04ed" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我希望你喜欢这篇文章，它能帮助你在你的NLP项目中找到你的心流！如果您对我的代码或流程有任何反馈、批评或建议，请联系我们！我们互相帮助学习得越多，我们的社区就会变得越好越聪明！</p></div></div>    
</body>
</html>