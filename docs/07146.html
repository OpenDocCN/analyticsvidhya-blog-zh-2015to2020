<html>
<head>
<title>Beginner to Advance — Web Scraping Guide in Python: Automated Lyrics Scraper.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从初学者到高级Python中的网络抓取指南:自动歌词抓取器。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/beginner-to-advance-web-scraping-guide-in-python-automated-lyrics-scraper-809163f279a1?source=collection_archive---------8-----------------------#2020-06-15">https://medium.com/analytics-vidhya/beginner-to-advance-web-scraping-guide-in-python-automated-lyrics-scraper-809163f279a1?source=collection_archive---------8-----------------------#2020-06-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/ace7aa4845a61e4f5594d84062de7cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O5ngnJfi1EEi2GmX4-N53A.jpeg"/></div></div></figure><div class=""/><p id="31e5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在之前的教程中，我们学习了网页抓取、旋转请求和使用异步编程的基础知识。现在，我们将使用这些技巧从AZLyrics网站上删除歌词，并将删除的歌词保存为JSON格式。</p><h1 id="27ac" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">工作流程</h1><figure class="kn ko kp kq fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es km"><img src="../Images/278dce7ad041efe09a9ee80182fcdd76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HZBrDaUHqEWDzapXO4Q89g.png"/></div></div></figure><p id="8051" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将使自动化的过程，接受歌手的网址，并保存那里的歌曲和专辑列表，并开始在那里的网页上收集所有的歌曲。以下是歌手样本页面的样子。</p><figure class="kn ko kp kq fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kr"><img src="../Images/a4d89d0a3633dc3b437be8c8036d73a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*esOKPmIKvDtuor8otGtj8g.png"/></div></div></figure><p id="e8a4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于我们已经在<em class="ks">bin/Proxy . py</em>中开发了2个类，我们将在<em class="ks"> bin/main.py </em>中创建一个新的主类，名为<em class="ks"> AZLyrics </em>，并继承之前的类<em class="ks"> Proxy_Checker </em>。</p><h2 id="d416" class="kt jp ht bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">第1部分—解析主页面并从插入的URL中收集歌曲URL。</h2><p id="fae0" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">这是我们新班级的样子:</p><figure class="kn ko kp kq fd hk"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="d7c7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我们定义了函数<em class="ks"> az_load_data(self) </em>来加载az_data和az_lyrics里面的json数据。我们将使用这些变量来追加数据，并保存这些变量来备份我们的数据。<br/>函数<em class="ks"> az_logger(self) </em>将允许我们创建日志文件来检查我们在脚本中的进度。<br/>现在，我们将为请求URL定义新的函数，但由于我们的大多数请求都将失败，我们将使用新的代理和标头进行请求，直到我们成功地从站点获取数据。此外，如果被识别为机器人网站将发送警告页面，我们也需要处理它，因为它看起来像一个正常的页面，状态代码为200，但对我们没有用，因为它没有任何实际数据。所以这个函数看起来像这样:</p><figure class="kn ko kp kq fd hk"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="d512" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用这个函数，我们将从服务器请求页面，但我们仍然需要解析请求和过滤我们需要的数据。为此，我们将创建其他函数<em class="ks"> az_songs_by_list(self) </em>来解析请求并保存页面中的所有URL。</p><figure class="kn ko kp kq fd hk"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="d4cb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">函数<em class="ks"> az_songs_by_list </em>将数据保存在字典中，并将URL保存在<em class="ks"> az_data['simple_urls'] </em>数组中。使用<em class="ks"> add_urls() </em>，我们可以接受并保存艺术家的URL。</p><p id="25d8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果一切都正确，要运行我们到目前为止创建的脚本，我们将使用命令。</p><figure class="kn ko kp kq fd hk"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="4611" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果一切正确，您应该可以开始废弃该站点，并在<em class="ks">JSON _ data/data _ to _ scrap . JSON</em>中检查进度，日志将在<em class="ks"> log_data/main.log中更新。</em></p><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es lo"><img src="../Images/794bad996d4d9ab4a56627901fe779f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*mfT9e9_DEtVJghkKs_6uDg.png"/></div></figure><p id="fc8f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">更新后，您的<em class="ks">JSON _ data/data _ to _ scrap . JSON文件</em>将看起来类似。<br/>正如你看到的，通过抓取3位歌手，我们可以抓取1686首歌曲的网址。现在我们将使用这些网址从网站上删除歌词。</p><h2 id="3c62" class="kt jp ht bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">第2部分—通过Asyncio编程抓取URL和收集歌词。</h2><p id="4bd5" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">根据之前教程的经验，我们将使用Asyncio概念来删除歌词。</p><ul class=""><li id="f3f9" class="lp lq ht is b it iu ix iy jb lr jf ls jj lt jn lu lv lw lx bi translated"><strong class="is hu"> lyrics_from_link() — </strong>函数，接受解析后的网站并创建包含歌词的歌曲详细信息字典。</li><li id="4fe9" class="lp lq ht is b it ly ix lz jb ma jf mb jj mc jn lu lv lw lx bi translated"><strong class="is hu"> get_batch_lyrics() </strong> —函数创建线程，并发运行<strong class="is hu"> lyrics_from_link() </strong>函数。</li></ul><blockquote class="md me mf"><p id="e6aa" class="iq ir ks is b it iu iv iw ix iy iz ja mg jc jd je mh jg jh ji mi jk jl jm jn hb bi translated">注意—您应该不时地废弃代理，因为它们会在几个小时内更新并需要刷新。</p></blockquote><p id="a14d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">完整的脚本将是:</p><figure class="kn ko kp kq fd hk"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="2c51" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，既然我们已经完成了我们的代码，我们将创建一个<em class="ks"> main.py </em>文件来轻松访问我们所有的代码<em class="ks">。</em>如果正确，运行下面的代码将开始抓取URL，您可以在日志中检查进度。一旦完成，您将在<em class="ks">JSON _ data/data _ lyrics . JSON</em>文件中看到更新。</p><pre class="kn ko kp kq fd mj mk ml mm aw mn bi"><span id="8bb0" class="kt jp ht mk b fi mo mp l mq mr">import json<br/>from bin.azlyrics import *</span><span id="7ee9" class="kt jp ht mk b fi ms mp l mq mr">if __name__ == “__main__”:<br/> azlyrics = AZLyrics()<br/> azlyrics.start_scrapping()</span></pre><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es mt"><img src="../Images/048a12d38aca552415e8be9b2eff7485.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*lr4UtCntTl43x675newjrw.png"/></div></figure><p id="1181" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有了这个脚本，我可以在两个小时内删除大约16k首歌曲的歌词。<br/>我使用的max_workers值设置为100，但您也可以根据您的系统和带宽增加该值。</p><p id="8a57" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你也可以在Github的<a class="ae mu" href="https://github.com/terminate9298/azlyrics_scraper" rel="noopener ugc nofollow" target="_blank">链接上找到完整的代码。</a></p></div><div class="ab cl mv mw gp mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="hb hc hd he hf"><div class="kn ko kp kq fd nc"><a href="https://github.com/terminate9298/azlyrics_scraper" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hu fi z dy nh ea eb ni ed ef hs bi translated">终结9298/azlyrics_scraper</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">Python Webscraper使用漂亮的组和并发编程和请求的概念来清除AZLyrics.com…</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">github.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq hp nc"/></div></div></a></div><blockquote class="md me mf"><p id="0da4" class="iq ir ks is b it iu iv iw ix iy iz ja mg jc jd je mh jg jh ji mi jk jl jm jn hb bi translated"><strong class="is hu">你已经成功编写了代码，可以在不被阻塞的情况下删除AZLyrics。做得好…！！！</strong></p></blockquote><h1 id="a968" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">从这里继续前进。</h1><h2 id="ae23" class="kt jp ht bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">教程1 —简介</h2><p id="067e" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">在<a class="ae mu" rel="noopener" href="/@kaus.pathak_30409/beginner-to-advance-web-scraping-guide-in-python-799ffd367067">之前的教程</a>中，我们了解了网络抓取的基本概念，并创建了简单的函数来使用请求和美丽组从页面中提取歌词。</p><h2 id="4d89" class="kt jp ht bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">教程2 —使用Python中的头池和代理循环请求。</h2><p id="6801" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">为了创建一个更大的项目，可以从互联网上删除成千上万的页面，你需要一个更清晰的工作环境，使用面向对象和继承的概念。你还需要有更详细的关于头文件池和代理池的知识来保持对服务器的匿名，我们已经在本教程的第二部分中讨论过了。</p><h2 id="b1d0" class="kt jp ht bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">教程3 —工作环境和异步I/O编程</h2><p id="4b2a" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">我们将做异步I/O编程来提高你的报废速度，这将在本教程的第三部分中介绍。</p><h2 id="6165" class="kt jp ht bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">教程4 —自动化站点抓取</h2><p id="311e" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">有了之前教程中学习的所有概念，我们将在本教程的第四部分中创建实际的自动抓取器来下载和保存网页上的歌词。</p><h2 id="8ae6" class="kt jp ht bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">教程5 — API访问</h2><p id="b662" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">为了方便地从互联网上访问歌词，我们将创建Flask API和前端来访问我们在本教程第五部分中废弃的歌词。</p><h2 id="dae1" class="kt jp ht bd jq ku kv kw ju kx ky kz jy jb la lb kc jf lc ld kg jj le lf kk lg bi translated">教程6 —在Heroku上托管我们的Flask服务器</h2><p id="4642" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">为了提供容易的歌词访问，我们将在本教程的第六部分<a class="ae mu" rel="noopener" href="/@kaus.pathak_30409/beginner-to-advance-web-scraping-guide-in-python-deploy-a-python-web-app-using-flask-and-a0e3cc8ce9f6">的Heroku上托管我们的Flask服务器。</a></p><figure class="kn ko kp kq fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nr"><img src="../Images/4e108e76b35fe29a6a34f74ce4c91dc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*q9SySkNwsu0Y5uBQ"/></div></div></figure><h1 id="6596" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">最后的话</h1><p id="25e7" class="pw-post-body-paragraph iq ir ht is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">感谢您阅读这篇文章，我们希望听到您的反馈。请随意评论任何问题。<br/>如果你喜欢，请给我们鼓掌。关注我们，获取我们的最新文章。</p></div></div>    
</body>
</html>