<html>
<head>
<title>End-to-end Machine learning pipeline on Databricks — Part 5</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据砖块上的端到端机器学习管道—第5部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/end-to-end-machine-learning-pipeline-on-databricks-part-5-c10273e2cd88?source=collection_archive---------10-----------------------#2020-07-12">https://medium.com/analytics-vidhya/end-to-end-machine-learning-pipeline-on-databricks-part-5-c10273e2cd88?source=collection_archive---------10-----------------------#2020-07-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/59e9dca05401a67c3aab73dad14ef618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LbN4hy3OppJz2tYd.PNG"/></div></div></figure><p id="d502" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在<a class="ae jo" rel="noopener" href="/@anveshrithaas/machine-learning-in-pyspark-part-4-5813e831922f">之前的博客</a>中，我们从PySpark中的机器学习开始，通过使用Spark的机器学习库实现一个线性回归模型来预测房价。</p><p id="ed4e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇博客中，我们将创建一个端到端的机器学习管道。与前一篇博客中的示例不同，我们将围绕Apache Spark- Databricks构建一个基于云的统一数据分析平台，体验使用Apache Spark进行大规模数据处理、分析和机器学习的体验，就像数据科学家和工程师如何大规模应用高级分析技术和机器学习模型来解决现实世界的问题一样。Databricks使我们能够在很短的时间内轻松构建、扩展和部署机器学习模型。它提供了全面管理的Spark集群、用于数据探索和可视化的交互式工作空间、生产流水线调度程序和一个促进基于Spark的应用的平台。</p><p id="8f74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了更好地理解这是如何工作的，让我们通过在Databricks平台上用PySpark创建一个端到端的机器学习管道来动手操作。首先将数据加载到数据帧中，并执行探索性数据分析，然后继续创建统一的管道，该管道由统称为管道阶段的<strong class="is hj">转换器</strong>和<strong class="is hj">估算器</strong>组合而成，最后是机器学习模型的评估。转换器是一种将一个数据帧转换成另一个数据帧的算法。它包括特征转换器和学习模型。估计器是一种算法，它通过在数据帧上实现fit()方法来拟合或训练数据，从而生成一个作为转换器的模型。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es jp"><img src="../Images/1c158f31c38bf695cc64c6af1ab5875f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*ZxJqKzA4v_qB8XP3riugKQ.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">来源:AIEngineering</figcaption></figure><p id="94f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇博客中，我们将在PySpark中为一个银行营销用例构建一个机器学习管道。该数据集包含一家银行为说服客户订阅定期存款而开展的基于电话营销活动的信息，我们的任务是对其进行分析，并确定有助于我们得出结论的模式，以便制定未来策略让客户订阅定期存款。基本上，这将是一个二元分类问题，目标是预测客户是否会订阅(是或否)。我们将为此使用的数据集可以在<a class="ae jo" href="https://www.kaggle.com/janiobachmann/bank-marketing-dataset" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><h2 id="8498" class="jy jz hi bd ka kb kc kd ke kf kg kh ki jb kj kk kl jf km kn ko jj kp kq kr ks bi translated">设置数据块环境</h2><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es kt"><img src="../Images/af7190b3d3ca16b4271c60e74a4ab295.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/0*hZDHkwfxzDXEh40_"/></div></figure><p id="979b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们开始构建管道之前，我们必须首先设置我们的数据块环境。Databricks提供了一个免费的社区版，其中包含了处理大规模数据集的功能，这对于我们在这篇博客中将要做的事情来说已经足够了。</p><ul class=""><li id="0d8f" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">先去<a class="ae jo" href="https://databricks.com/try-databricks" rel="noopener ugc nofollow" target="_blank">官方databricks网站</a>。一旦你到达那里，填写你的详细资料注册并开始。</li><li id="e8cc" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">您需要在databricks平台免费试用版和社区版之间选择一个平台。虽然在AWS或Azure云平台上提供的databricks platform免费试用版提供了一些高级功能，如协作环境、无限集群、作业调度器、与ML框架的本机集成等，这些都是面向企业的，但community edition提供了对免费微集群(6GB，无工作节点)以及集群管理器和笔记本环境的访问，非常适合开始使用Spark。对于本教程，社区版应该足够了。</li><li id="c361" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">一旦电子邮件验证完成，我们就可以开始了。在欢迎页面中，您会看到创建新笔记本、表格、集群等的选项。让我们从创建一个集群开始。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/569a3e538b8834ffab7c14ccb26c596b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d-dyBnOjm7wC6LDhJ40yKw.png"/></div></div></figure><ul class=""><li id="296c" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">要创建新的集群，请为集群命名，选择一个databricks运行时版本，然后单击create cluster。</li></ul><p id="4476" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lj">注意:</em> </strong> <em class="lj">在社区版中，集群会在两个小时的空闲期后自动终止。</em></p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/489a70ce47724438bfedc898c0f21ba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fRlP7pDBMOP5KNuiKJE2-g.png"/></div></div></figure><p id="1cd0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建集群需要一些时间。当群集状态从“挂起”变为“正在运行”时，这意味着群集已创建并且当前正在运行。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/a159b485f790549d3607806e2ecc6562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jKbPDmlijSiRR6tXzXsVgg.png"/></div></div></figure><p id="18fa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当您单击您的集群时，您可以在顶部看到多个选项卡。当你点击库标签，会有一个选项'安装新的'，让你安装各种软件包和库，你会需要的。“笔记本”选项卡显示与群集一起运行的笔记本。您还可以在“事件日志”和“驱动程序日志”选项卡中查看日志信息。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/7e987175f0f67574a78fadb7bf9bb47c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gfwKu1Ogwv5L62aPIjLVw.png"/></div></div></figure><p id="47cf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建集群后，让我们转到显示已经可用的数据的数据部分。如果我们想使用新数据，那么点击“添加数据”来加载数据。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/a1c5ec86eb2bb96571b4e4d2e9b914e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9T01Du24CeH19XOIOkNSNw.png"/></div></div></figure><p id="67bd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">点击“添加数据”后，您会看到各种添加数据的选项。您可以添加数据，只需从您的本地文件系统上传，或连接到亚马逊S3桶，或将数据上传到Databricks文件系统(DBFS)，或添加来自其他来源的数据，如亚马逊Kinesis，Cassandra，Kafka，JDBC等。通过单击在笔记本中创建表格，它将打开一个新的笔记本，并在其中加载数据。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/f7f066151646249bbdbea1446957af5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*pf9x8LGetwVyluufKNDh6A.png"/></div></figure><p id="523c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">获取数据的一种方式是连接AWS环境，并通过给予必要的权限将数据获取到Databricks Spark环境，从S3存储桶中提取数据。亚马逊S3只不过是AWS提供的一种存储服务，具有高度的可扩展性、安全性和性能，可以为各种各样的用例存储任意数量的数据。包括各行各业领先企业在内的多家公司都使用它来存储大量数据，并随时随地在网上检索这些数据。</p><h2 id="1aa7" class="jy jz hi bd ka kb kc kd ke kf kg kh ki jb kj kk kl jf km kn ko jj kp kq kr ks bi translated">AWS入门</h2><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/2d3c895fd51ffd89d672f4ff5da7fb01.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*lo2Q78gYSGnqLk_d"/></div></div></figure><p id="bad4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于我们将要创建的机器学习管道，让我们尝试从亚马逊S3桶中提取数据，以便了解数据科学家和数据工程师如何使用真实世界用例的云存储来处理大量数据。为此，我们必须创建一个S3桶，将数据上传到其中，将Databricks环境与AWS连接起来，并将数据从S3桶拉入我们的Spark环境。</p><p id="50ea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">设置AWS账户</strong></p><p id="e361" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，首先我们需要有一个AWS帐户。如果您没有，可以注册一个AWS免费层帐户(包括12个月的免费层访问)。</p><ul class=""><li id="66e9" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">访问<a class="ae jo" href="https://aws.amazon.com" rel="noopener ugc nofollow" target="_blank"> AWS网站</a></li><li id="4337" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">点击“创建AWS帐户”,输入您的详细信息，然后点击“继续”。</li><li id="028e" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">接下来，选择帐户类型—专业或个人，开始填写您的联系信息，并通过单击“创建帐户并继续”进行下一步。</li><li id="24db" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">一旦这一步完成，它会问你支付卡的细节。即使是免费等级帐户也需要您输入这些详细信息。但是，除非您的使用超过AWS免费层限制，否则不会向您收费。</li><li id="f729" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">完成后，您将被要求通过电话号码验证来确认您的身份。输入您的电话号码，然后点击“发送短信”以接收该手机号码的验证码。</li><li id="94a2" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">输入验证码以成功验证您的身份。</li><li id="1539" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">最后，从列出的三个计划中，选择自由层的基本计划。</li></ul><p id="9ab9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">就是这样。您的AWS免费层帐户已成功创建，现在您可以使用您的凭据登录AWS控制台并开始使用AWS服务。AWS免费层帐户在亚马逊S3提供高达5 GB的存储空间。为了简单起见，我们将用于机器学习管道的数据是一个小数据集。但在现实世界中，数据科学家和分析师处理的数据甚至可能高达万亿字节。</p><p id="5a2e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">创建S3桶并存储数据</strong></p><p id="a352" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们已经设置了AWS帐户，让我们开始上传已经下载到亚马逊S3桶中的数据集。在此之前，我们必须创建一个S3桶。为此，</p><ul class=""><li id="9b30" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">登录到您的AWS帐户，在AWS管理控制台中，在AWS服务下搜索S3并点击它。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/3451b56436c156dce6fc9cf71bc8e8ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oa-lMjkY70VZBoa9ZR-IWg.png"/></div></div></figure><ul class=""><li id="0774" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">进入S3窗口后，单击“create bucket”创建一个新的存储桶，我们将在其中存储数据。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/4c6620e19bd48db444e4cbd839dd2362.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SW5ODKT2FLL7Ssr-tW8L2A.png"/></div></div></figure><ul class=""><li id="0ede" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">为存储桶指定一个唯一的名称，并选择离您的数据块集群区域最近的区域，以最大限度地减少延迟。完成后，单击创建。您不需要担心配置选项或设置权限，在为集群命名并选择区域后，您可以直接创建集群。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/bd3cffe17455c96c97ea3bc76552cbab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NN_i38gMvZV1LRtNtSsfpg.png"/></div></div></figure><ul class=""><li id="3137" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">现在，你会看到新创建的S3桶。点击桶。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/b0f07e79bdb0c5b0715134e324122330.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_P9W_RldJIYdeQGgVOgWbg.png"/></div></div></figure><ul class=""><li id="63f9" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">在这里，点击上传按钮上传我们的数据集在这个S3桶。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/9117c451cb725a6d9a1414d937de2939.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhk4HrV3BBQ6GOesfp51pA.png"/></div></div></figure><ul class=""><li id="5d14" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">单击“添加文件”以添加数据集。选择您必须从本地文件系统上传的数据集。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/1706f786e4540162bcd1cbad2f1595a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3IvizH84x9P3wmPNcWo2ig.png"/></div></div></figure><ul class=""><li id="805e" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">现在，您要上传的选定文件将出现在列表中。验证并上传以将其存储在S3存储桶中。上传需要一些时间。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/9e30fda33bd8a3df024ee6e31eed1759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q-vmcv0-I1pdS2D3jHjR2g.png"/></div></div></figure><p id="b7e1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦上传成功，你会看到它出现在屏幕上。现在，我们已经将数据存储在S3存储桶中。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/00125626c3628ff742b235ec64be38f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AaBaz2GVCeIxH4RR0tUKMQ.png"/></div></div></figure><p id="aced" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们如何在S3之外获取这些数据？我们如何将它放入我们的Databricks Spark环境？一种方法是将S3存储桶权限设置为对所有人可见，这样任何人都可以访问它。更安全的方法是获得一个访问密钥ID和一个秘密的访问密钥，并在我们的Spark环境中使用它从bucket中提取数据。这就是我们在这里要做的。</p><ul class=""><li id="9bc4" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">要获取访问ID和密钥，请转到服务，搜索IAM并单击它。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/38e00de5535a8fde2ddedc20f0bf4ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5bYfqLRhyPDXBF0Zndh__g.png"/></div></div></figure><ul class=""><li id="2a62" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">到达后，在窗口左侧的菜单中点击“访问管理”下的“用户”选项。然后点击“添加用户”选项。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/8b3788dc2ff681861a7d085b0658f550.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*50_1aOMpSPc0D_hQYD_J9g.png"/></div></div></figure><ul class=""><li id="54b6" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">通过提供用户名来设置用户详细信息。然后选择访问类型为编程访问，以便获得访问密钥ID和密钥，它们可以在我们的Spark程序中用来访问来自S3存储桶的数据。然后点击“下一个权限”。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/16168d8e0ba26fac6a728780dc867b59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nak-s13mKp-SDx1nunMjpw.png"/></div></div></figure><ul class=""><li id="e2bc" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">在这里，选择“直接附加现有保单”并搜索S3。从显示的列表中，选择“AmazonS3FullAccess”选项以授予读写权限。对于只读权限，请选择“AmazonS3ReadOnlyAccess”选项。选择后，点击“下一个标签”。</li><li id="c88f" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">跳过可选的“添加标签”步骤并继续。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/b945820a2b6f858e30ab39a28352e48b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Otnx8r7XnvqQVnC8KDQkIw.png"/></div></div></figure><ul class=""><li id="94a3" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">查看一次，然后单击Create user以获取访问ID和密钥。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/5121bcca49643726af62b33e4d5ea933.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gz0_s90c89kM3c3_T5qKKg.png"/></div></div></figure><p id="acff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，您可以找到S3桶的访问密钥ID和秘密访问密钥，我们可以在PySpark程序中使用它们来访问数据。请注意，不应该共享秘密访问密钥，因为拥有秘密密钥的任何人都可以完全访问您的S3存储桶，并可以对其进行更改。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/b2bd2cd1140d43972940a2b4fd4d060f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5JfTngOXcOvTpf_cbpe9ZA.png"/></div></div></figure><p id="5aae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">虽然这只是为我们的管道获取数据的一种方式，但您没有必要这样做。如果您无法设置亚马逊S3存储桶，您完全可以将数据直接上传到Databricks环境，这是一种简单得多的方法。</p><h2 id="8bbf" class="jy jz hi bd ka kb kc kd ke kf kg kh ki jb kj kk kl jf km kn ko jj kp kq kr ks bi translated"><strong class="ak">将数据直接上传至databricks环境，无需AWS(替代方法)</strong></h2><ul class=""><li id="edcf" class="ku kv hi is b it lx ix ly jb lz jf ma jj mb jn kz la lb lc bi translated">正如我们已经看到的，在数据部分，当您单击“添加数据”时，您可以选择上传文件。选择该文件并浏览本地文件系统中要上传的文件。</li><li id="2a09" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">上传后，单击Create table with UI。然后选择要将数据附加到的群集。我将使用我们在开始时已经创建的集群。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/c61b056163693312c91374981731bb01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*GvEmKP5KBb7LNgkx2xAEUg.png"/></div></figure><ul class=""><li id="0cf4" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">向下滚动，在“指定表属性”下，给出表名、文件类型、列分隔符(CSV文件中为逗号)，选择“首行作为标题”、“推断模式”和“多行”，然后单击“创建表”。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/1230d661f5a7f9f13d315803787f5283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LCCKEDgn58QzF0E98DCjhw.png"/></div></div></figure><p id="1216" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将显示该表的模式。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/b54468e9db59a6d9bcbe6c278f3063be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GPjf0SP6CjlphpRpaWliXg.png"/></div></div></figure><h2 id="abcf" class="jy jz hi bd ka kb kc kd ke kf kg kh ki jb kj kk kl jf km kn ko jj kp kq kr ks bi translated">在databricks中创建新笔记本</h2><p id="fbe9" class="pw-post-body-paragraph iq ir hi is b it lx iv iw ix ly iz ja jb me jd je jf mf jh ji jj mg jl jm jn hb bi translated">现在让我们创建一个新的笔记本(类似于Jupyter Notebbok ),以我们构建机器学习管道的Spark计划开始。</p><ul class=""><li id="ca8c" class="ku kv hi is b it iu ix iy jb kw jf kx jj ky jn kz la lb lc bi translated">转到Databricks的主窗口，单击“新建笔记本”选项创建一个新笔记本。</li><li id="22a2" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">为笔记本指定一个名称，选择语言(我们将使用python ),然后选择要将笔记本连接到的集群。完成后，点击“创建”打开一个新笔记本。现在我们可以走了。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/c0e860a35aed8de108c34addc0c1be13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*NvV5Zf-L0b6_F-jZysyxbw.png"/></div></figure><h2 id="7be8" class="jy jz hi bd ka kb kc kd ke kf kg kh ki jb kj kk kl jf km kn ko jj kp kq kr ks bi translated">为ML管道编写我们的Spark程序</h2><p id="c78c" class="pw-post-body-paragraph iq ir hi is b it lx iv iw ix ly iz ja jb me jd je jf mf jh ji jj mg jl jm jn hb bi translated">让我们开始编写我们的Spark程序。首先，让我们开始使用访问密钥ID和秘密访问密钥从S3存储桶导入数据。如果您已经在Databricks环境中直接上传了数据，而不是使用亚马逊S3，那么跳过下面的代码片段，直接通过指定文件位置开始(参见下一个代码片段)。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><p id="4cbd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当您运行该单元时，您将获得以下输出。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/187d732fad523c277cf23e54bf4f9ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*9404s1UzHoECNhtl2fqHRg.png"/></div></figure><p id="510a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lj">注意:</em> </strong> <em class="lj">使用Databricks notebook时，不需要显式创建SparkContext或SparkSession。请改为对SparkContext使用已定义的变量“sc”，对SparkSession使用“spark”，对SQLContext使用“sqlContext”。</em></p><p id="6b34" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，指定数据集位置和文件类型，并配置CSV选项，例如将数据集的第一行设置为标题、列分隔符、推断模式等。最后显示数据集。如果您已经在databricks环境中直接上传了数据集，那么首先将文件位置指定为“/file store/tables/bank marketing . CSV”</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><p id="22e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据框被创建并显示，如图所示。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ca"><img src="../Images/eef038c0944ffe677f63341454732017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N2WxZ4CvLBlype0ZFXFBNA.png"/></div></div></figure><p id="c0e7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，使用<em class="lj"> printSchema() </em>打印dataframe的模式。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><p id="a441" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我们可以看到数据集有17个属性，并且显示了每个属性的数据类型。这里的'<em class="lj">存款</em>'是目标变量，有两个类别标签(是和否)，其余属性是自变量。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/b339d5c7f607462858675d49b086a1bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*RP3zqTHsrb0jFzI0Kt-7GQ.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">数据帧的模式(输出)</figcaption></figure><p id="069e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，使用<em class="lj"> groupBy() </em>和<em class="lj"> count() </em>显示数据集中每个类标签的计数(Yes和No)，检查数据集是否平衡。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><p id="2915" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这给出了数据集中每个类标签下的示例数。我们可以看到，该数据集非常均衡，每个类标签中的实例数量几乎相等，5873个实例的类标签为“否”，5289个实例的类标签为“是”。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/93c254257333107d0163226f1570e846.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*aXl946nCOvOzt_w85JK_Yg.png"/></div></figure><p id="4d80" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们在模式中已经看到的，该数据包含字符串和数字类型(整数)的变量。让我们使用<em class="lj"> dtypes()获取所有类型为integer的列。</em></p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><p id="b32f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下变量在数据帧中有数值。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/78b18ff0fe38ff27eec8a0b346850707.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*cJLZJW9l2bqwsueMMPxl0g.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">数字类型的列(输出)</figcaption></figure><p id="6f43" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lj">注:</em> </strong> <em class="lj">我们也可以使用to Pandas()将Spark数据帧转换为Pandas数据帧。我们可以使用Pandas dataframe获得更好的数据表格视图。</em></p><p id="aeeb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="lj">举例:</em></p><pre class="jq jr js jt fd mo mp mq mr aw ms bi"><span id="85cd" class="jy jz hi mp b fi mt mu l mv mw">df.select(numeric_features).toPandas().head(5)</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es mx"><img src="../Images/402ba154378df5bcd7bba4299adffd70.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*ZjkPXaNMfsvFagEdhzSmOQ.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">熊猫数据框的表格视图</figcaption></figure><p id="6d28" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">除了数字类型列之外，其余的列都是分类变量。为了使它们适合模型学习，我们必须通过一键编码将分类变量转换为二进制表示。我们将首先使用<em class="lj"> StringIndexer </em>将分类列转换为索引，然后将这些索引类别转换为一键编码变量。目标变量(标签)也使用<em class="lj"> StringIndexer </em>编码成一个列向量。我们将分类变量的字符串索引器和一键编码器以及标签的字符串索引器附加到流水线阶段。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><p id="50d7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们将使用<em class="lj"> VectorAssembler </em>将一系列列组合成一个单独的向量列，将所有的独立变量转换成一个单独的特征向量。这将把自变量(特征)与目标变量(标签)分开。一个<em class="lj"> VectorAssembler </em>接受数字、布尔和向量类型的输入列。这里，所有的独立变量(数字列+分类列)都被转换成一个称为features的向量。然后，这个向量汇编器被附加为流水线阶段。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><p id="cc2c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦我们添加了管道的所有阶段，就该创建管道了。这里，我们用这些阶段创建管道，然后使管道适合数据帧并对其进行转换。我们将选择<em class="lj">‘标签’</em>(目标变量)和<em class="lj">‘特征’</em>(所有自变量的向量)作为数据帧的列。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es my"><img src="../Images/be6b9c81118b98c10a6c250e71e511e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*z0e9SFPZKMNZUzO21MrwKA.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">数据帧的模式(输出)</figcaption></figure><p id="7f96" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，模型的数据已经准备好了。让我们将其分为训练集和测试集，用于训练模型，然后在看不见的数据上测试模型。这里，我们以80:20的训练/测试分割比率分割数据。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><p id="1551" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在是时候创建一个二元分类器，我们将选择逻辑回归模型进行分类。首先，我们将初始化模型，然后使其适合训练数据。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><p id="c4e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦在训练集上创建并拟合了模型，让我们通过绘制真阳性率对假阳性率来绘制该二元分类器的ROC曲线。我们通过把它转换成熊猫，然后进行绘图来做到这一点。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/e7ee14395ebb442cdc9cbfbfc7b9d467.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*TKuWZ7rF0eAKH3CtLvTMXw.png"/></div></figure><p id="c33e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们将使用两个性能指标，即准确性和ROC曲线下面积，来评估模型在训练数据上的性能。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es na"><img src="../Images/933f1d1f201eff0191045c110d781b8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*h13NfsD-yADhXrP_pQKmmA.png"/></div></figure><p id="2ea1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">模型的训练精度为0.8257，而ROC曲线下面积为0.9033。但是根据训练数据评估模型性能并不是一个好主意。因此，我们将使用测试集进行预测，并在此基础上评估模型。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/19f571a14c23fbcf4bf108071b501614.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*mawmF3jYh91y_g-HPYsLUg.png"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">模型的预测(输出)</figcaption></figure><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/315020fbc9fc52ec59af416c5c877ce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*o3Kr9DEL9zSiQPc3L9i-sg.png"/></div></figure><p id="ad68" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当对以前未见过的数据进行测试时，该模型的准确性证明为大约82.4%，ROC曲线下的面积为0.9047。我们看到，模型在训练和测试数据上的性能没有太大差异。</p><p id="5bb7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">超参数调谐</strong></p><p id="c1bf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在构建逻辑回归模型时，我们为模型分配了默认的超参数。调整这些参数以找到最佳超参数可以极大地提高模型性能。为此，我们可以使用<em class="lj"> ParamGridBuilder </em>和<em class="lj"> CrossValidator </em>来执行网格搜索，这相当于Sklearn的<em class="lj"> GridSearchCV </em>。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="mi mj l"/></div></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/3ed1318a2733fea4cf2be9a8360cb1f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*E284WfvBGB0lXLcWxSf9Yg.png"/></div></figure><p id="7523" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是从指定超参数值的各种组合创建的最佳可能分类模型的ROC曲线下的面积。</p><p id="2aeb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该模型的性能还有改进的余地。您可以尝试通过执行更多的数据预处理步骤来改进模型，如缺失值插补、特征选择等。并将它们作为阶段添加到管道中。您可以在此访问此笔记本<a class="ae jo" href="https://github.com/Anveshrithaa/PySpark-ML-Pipeline" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="0d23" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇博客中，我们学习了如何为我们的Spark应用程序使用基于云的统一分析平台，如何在亚马逊S3桶中存储数据并从Spark环境中访问数据，以及如何在Spark中构建端到端的机器学习管道。不仅仅是阅读，动手操作和摆弄它会让你有更好的理解。确保尝试为您选择的任何机器学习用例构建自己的管道。对数据进行探索性分析，对数据进行分析并做必要的数据预处理，最后建立并训练模型。最后，努力提高模型的性能。编码快乐！</p></div><div class="ab cl ne nf gp ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="hb hc hd he hf"><p id="93b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">查看本系列中的其他博客</p><p id="cb9e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@anveshrithaas/getting-started-with-apache-spark-part-1-91b379204ae0"> <strong class="is hj"> <em class="lj">第1部分Apache Spark入门</em> </strong> </a></p><p id="c258" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@anveshrithaas/introduction-to-pyspark-part-2-6d6113e31592"> <strong class="is hj"> <em class="lj">第二部分PySpark简介</em> </strong> </a></p><p id="b2b1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@anveshrithaas/understanding-spark-rdds-part-3-3b1b9331652a"> <strong class="is hj"> <em class="lj">第三部分—了解火花RDDs </em> </strong> </a></p><p id="48ca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@anveshrithaas/machine-learning-in-pyspark-part-4-5813e831922f"> <strong class="is hj"> <em class="lj">第四部分—用PySpark进行机器学习</em> </strong> </a></p></div></div>    
</body>
</html>