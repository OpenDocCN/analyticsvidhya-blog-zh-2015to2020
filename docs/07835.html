<html>
<head>
<title>Human Pose Estimation using OpenCV in Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习中基于OpenCV的人体姿态估计</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/human-pose-estimation-using-deep-learning-using-opencv-9d8edd5e8879?source=collection_archive---------10-----------------------#2020-07-09">https://medium.com/analytics-vidhya/human-pose-estimation-using-deep-learning-using-opencv-9d8edd5e8879?source=collection_archive---------10-----------------------#2020-07-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a4a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个帖子里，我讨论了我是如何使用OpenCV和Tensorflow开发人体姿态估计的。我试图用最简单的方式解释这个过程以及必要的实现部分。</p><p id="b3e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从输出的样子开始，也许这样你就能对我们试图理解的东西有一个整体的概念。这是实时估算的结果:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/e50ac5b7191b6f2abba12df64d3ee455.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/1*m2rpt3R_51y9SLbSIComxw.gif"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jl"><img src="../Images/b709019d505de8d1ebb60d364f938941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*2_qBv3iqiwBpmmrmq_lDSw.jpeg"/></div></figure><p id="2d2d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先:<strong class="ih hj">什么是姿态估计？</strong>姿态估计是计算机视觉中的一个普遍问题，在这里我们检测物体的位置和方向。这通常意味着检测描述对象的关键点位置。</p><p id="177c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该概念背后的基本思想是在图像中找到<strong class="ih hj"> <em class="jm">【身体上的标志】</em> </strong>，即:身体的主要部分/关节(例如，肩、踝、膝、腕等。).</p><p id="5986" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如何开始建造它？项目的第一步，也可能是最重要的一步是找到合适的数据集。幸运的是，对于姿势估计，有几个很好的数据集可用:</p><ol class=""><li id="7658" class="jn jo hi ih b ii ij im in iq jp iu jq iy jr jc js jt ju jv bi translated"><a class="ae jw" href="http://cocodataset.org/#keypoints-2018" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">可可要点挑战</strong> </a></li><li id="2556" class="jn jo hi ih b ii jx im jy iq jz iu ka iy kb jc js jt ju jv bi translated"><a class="ae jw" href="http://human-pose.mpi-inf.mpg.de/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> MPII人体姿态数据集</strong> </a></li><li id="6331" class="jn jo hi ih b ii jx im jy iq jz iu ka iy kb jc js jt ju jv bi translated"><a class="ae jw" href="http://www.robots.ox.ac.uk/~vgg/data/pose_evaluation/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> VGG姿态数据集</strong> </a></li></ol><p id="2a2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可可模型产生18分，而MPII模型输出15分。下图显示了一个人的输出。这些点是在通过卷积神经网络(CNN)对数据集进行处理和彻底训练时生成的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es kc"><img src="../Images/3b01d7382ffda64155a81cb42587e82b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*10Lsy16fVeAVQKe8wRVE4A.png"/></div></div></figure><p id="8224" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们知道了关键点的检测，让我们进入项目的核心:实现</p><h1 id="1466" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">实施:</strong></h1><p id="4c1c" class="pw-post-body-paragraph if ig hi ih b ii lf ik il im lg io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">第一个也是最重要的部分将包括生成和处理包含神经网络中正向传递的随机权重的权重文件和包含关于神经网络层的信息的原型文件。然后我们把文件加载到网络上</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="c868" class="lp ki hi ll b fi lq lr l ls lt"># Specify the paths for the 2 files<br/>protoFile = "pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt"<br/>weightsFile = "pose/mpi/pose_iter_160000.caffemodel"<br/><br/># Read the network into Memory<br/>net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)</span></pre><p id="f835" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在对于检测部分，为了识别关键点，我们必须首先将帧转换成一个<strong class="ih hj"> <em class="jm">斑点</em> </strong>(斑点是一种可以存储二进制数据的数据类型。这不同于数据库中使用的大多数其他数据类型，如存储字母和数字的整数、浮点数、字符和字符串。因为blobs可以存储二进制数据，所以它们可以用于存储图像或其他多媒体文件)</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="0933" class="lp ki hi ll b fi lq lr l ls lt"># Prepare the frame to be fed to the network<br/>inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)<br/><br/># Set the prepared object as the input blob of the network<br/>net.setInput(inpBlob)</span></pre><p id="53d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们都设置了先决条件，现在我们移动到训练模型和预测部分:一旦图像被传递到模型，就可以使用一行代码进行预测。OpenCV中DNN类的<strong class="ih hj"> forward </strong>方法通过网络进行前向传递，换句话说就是进行预测。</p><pre class="je jf jg jh fd lk ll lm ln aw lo bi"><span id="9edb" class="lp ki hi ll b fi lq lr l ls lt">output = net.forward()</span></pre><p id="2270" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出是4D矩阵:</p><ol class=""><li id="5ce6" class="jn jo hi ih b ii ij im in iq jp iu jq iy jr jc js jt ju jv bi translated">第一维是图像ID(如果您向网络传递多个图像)。</li><li id="fb13" class="jn jo hi ih b ii jx im jy iq jz iu ka iy kb jc js jt ju jv bi translated">第二维表示关键点的索引。该模型产生置信度图和零件相似性图，它们都被连接起来。对于COCO模型，它由57个部分组成——18个关键点置信度图+ 1个背景+ 19*2个部分相似性图。同样，对于MPI，它产生44个点。我们将只使用与关键点相对应的前几个点。</li><li id="eb55" class="jn jo hi ih b ii jx im jy iq jz iu ka iy kb jc js jt ju jv bi translated">第三个维度是输出地图的高度。</li><li id="7b8f" class="jn jo hi ih b ii jx im jy iq jz iu ka iy kb jc js jt ju jv bi translated">第四维是输出地图的宽度。</li></ol><p id="8e33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在反向传递完成后，系统有<strong class="ih hj"> 2D置信度图或亲和度图</strong>，其中包含目标身体部位图像中预测的<strong class="ih hj">全局最大值</strong>。置信图看起来像这样:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lu"><img src="../Images/21d2886dde8b3a0137884dcb21c79660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*ULgSJ_zpwdWLK1vO8MakUQ.png"/></div></figure><p id="5bde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们有了这些点的位置，我们只需要将它们绘制到图像上。所以剩下要做的就是<strong class="ih hj">绘制姿态预测的骨架</strong>。我已经预定义了身体部位对，这样就可以更容易地连接身体部位之间的线条。</p><p id="4174" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我还加了一个功能<strong class="ih hj">显示身体四肢之间的角度</strong>。这样做的目的是，这些分析可能对那些试图在运动或跑马拉松时改善姿势的运动员有用</p><p id="ea61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是模型完全训练后输入图像的最终输出:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/c01c1095708ca8d886abd60550748678.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P740Db3ABvVyMS3hdzX2KQ.jpeg"/></div></figure><p id="afd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以在我的<strong class="ih hj"> GitHub资源库链接</strong>中找到完整的源代码供你参考:</p><p id="5256" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jw" href="https://github.com/kunjshah2511/Human-Pose-Estimation" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="jm">https://github.com/kunjshah2511/Human-Pose-Estimation</em></strong></a></p><p id="8238" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望你已经发现这个指南是有用的，并且现在你已经对姿态估计模型的内部工作有了更深的了解。</p></div></div>    
</body>
</html>