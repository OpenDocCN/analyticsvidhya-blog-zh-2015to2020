<html>
<head>
<title>Applying Faster R-CNN for Object Detection on Malaria Cells</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">应用快速R-CNN进行疟疾细胞目标检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/applying-faster-r-cnn-for-object-detection-on-malaria-cells-723c11a45448?source=collection_archive---------8-----------------------#2020-01-18">https://medium.com/analytics-vidhya/applying-faster-r-cnn-for-object-detection-on-malaria-cells-723c11a45448?source=collection_archive---------8-----------------------#2020-01-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1f5f4ddbee0082e5422ad84730d84d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OsNfJhnCn0MlmC_-EEV_xg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">疟疾细胞</figcaption></figure><h1 id="12ce" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">内容:</h1><ol class=""><li id="49be" class="js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">语境</li><li id="5e0b" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">关于图像和目标</li><li id="56a7" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">评估指标</li><li id="61bf" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">培训和测试数据</li><li id="f5c4" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">使用的库</li><li id="e66b" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">映象分析</li><li id="4162" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">应用更快的R-CNN</li><li id="9071" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">测试数据评估</li><li id="00fa" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">参考</li></ol></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><h1 id="8d9c" class="iu iv hi bd iw ix kw iz ja jb kx jd je jf ky jh ji jj kz jl jm jn la jp jq jr bi translated">1.语境</h1><p id="07f4" class="pw-post-body-paragraph lb lc hi ju b jv jw ld le jx jy lf lg jz lh li lj kb lk ll lm kd ln lo lp kf hb bi translated">疟疾是一种由疟原虫寄生虫引起的疾病，它仍然是全球健康的主要威胁，每年影响2亿人，导致40万人死亡。影响人类的主要疟疾种类是恶性疟原虫和间日疟原虫。</p><p id="7718" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">对于疟疾和其他微生物感染，由训练有素的显微镜专家人工检查厚血涂片和薄血涂片仍然是寄生虫检测和阶段确定的金标准，因为其试剂和仪器成本低且灵活性高。尽管手动检查的处理量极低并且容易受到人为偏差的影响，但由于明视野显微镜图像的变化范围很大，自动计数软件仍然很大程度上未被使用。然而，一个强大的自动计数和细胞分类解决方案将提供巨大的好处，因为更快和更准确的定量结果，没有人为的可变性；研究人员和医疗专业人员可以更好地表征特定阶段的药物靶标，并更好地量化患者对药物的反应。</p><p id="20af" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">部分由于复制、比较和扩展的困难，以前将疟疾的识别和量化过程自动化的尝试没有获得主要的关注。作者也很少让他们的图像集可用，这排除了结果的复制和潜在改进的评估。缺乏一套标准的图像，也没有一套用于报告结果的标准指标，这阻碍了这一领域的发展。</p><h1 id="51c1" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">2.关于图像和目标</h1><p id="66c9" class="pw-post-body-paragraph lb lc hi ju b jv jw ld le jx jy lf lg jz lh li lj kb lk ll lm kd ln lo lp kf hb bi translated"><strong class="ju hj">图像</strong>已输入。png或者。jpg格式。共有3组图像，由1364幅图像(约80，000个细胞)组成，每组图像由不同的研究人员准备:来自巴西(斯蒂芬妮·洛佩斯)、来自东南亚(Benoit Malleret)和时间进程(Gabriel Rangel)。血液涂片用吉姆萨试剂染色。</p><p id="dda7" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated"><strong class="ju hj">标签:</strong>数据由两类未感染细胞(红细胞和白细胞)和四类感染细胞(配子体、环、滋养体和裂殖体)组成。注释者被允许将一些单元格标记为困难的，如果在某个单元格类中不清楚的话。数据显示未感染的红细胞与未感染的白细胞和感染的细胞之间存在严重的不平衡，后者占所有细胞的95%以上。</p><p id="23d4" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">给每个单元一个类标签和一组边界框坐标。对于所有的数据集，海托尔·维埃拉·多拉多热带医学基金会医院的疟疾研究员斯蒂芬妮·洛佩斯给受感染的细胞贴上了类别标签，表明发育阶段或标记为困难。</p><p id="6146" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated"><strong class="ju hj">目标:</strong>这个项目的目标是训练一种<strong class="ju hj">更快的R-CNN目标检测技术</strong>对疟疾细胞进行检测，并使用【https://arxiv.org/abs/1804.09548】的研究论文中的思想，以最大可能的精度将每幅图像中的目标分类到上述细胞类别中。</p><h1 id="5014" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">3.评估指标</h1><p id="4852" class="pw-post-body-paragraph lb lc hi ju b jv jw ld le jx jy lf lg jz lh li lj kb lk ll lm kd ln lo lp kf hb bi translated">平均精度(Mean Average Precision):这是一个衡量物体检测技术准确性的流行指标，比如更快的R-CNN，SSD..等等。当一个对象被错误分类或者没有被检测到时，MAP会扣分。</p><h1 id="e253" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">4.培训和测试数据</h1><ol class=""><li id="e4d0" class="js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">培训和测试数据的图像在中提供。jpg和。图像文件夹中的png格式。</li><li id="f78f" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">JSON文件是为训练和测试图像提供的，由以下几列组成。</li></ol><p id="0abf" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated"><strong class="ju hj">训练和测试中的列</strong></p><p id="517f" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">a.校验和— ID</p><p id="220c" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">b.路径名—图像的路径</p><p id="1aa5" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">c.整形器—图像的整形器</p><p id="91ba" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">d.ShapeC —图像的ShapeC</p><p id="71b3" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">e.通道—图像的通道</p><p id="5898" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">f.bbminR边界框坐标minR</p><p id="a556" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">g.bbminC边界框坐标minC</p><p id="682e" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">h.bbmaxR边界框坐标maxR</p><p id="77eb" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">i. bbmaxC包围盒坐标maxC</p><p id="70b1" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">j.类别—图像中对象的类别</p><h1 id="839b" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">5.使用的库</h1><ol class=""><li id="7ca3" class="js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ju hj"> Pandas </strong> : Pandas是一个python语言的软件库，用于数据编程和分析。使用pandas库，我们将训练和测试csv文件读入pandas数据帧和任何数据操作。</li><li id="2a6c" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated"><strong class="ju hj">JSON</strong>:JSON库可以从字符串或者文件中解析JSON。该库将JSON解析成Python字典或列表。它还可以将Python字典或列表转换成JSON字符串。在这个项目中，训练和测试文件是JSON格式的。使用JSON库，JSON文件被转换成csv文件。</li><li id="0dad" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated"><strong class="ju hj"> Imagesize </strong>:解析图像文件头，返回图像大小。使用Imagesize库，我们可以读取图像来检索图像的高度和宽度。</li><li id="998c" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">Keras是一个用Python编写的开源神经网络库。它能够在TensorFlow上运行。Keras包含许多常用神经网络构建块的实现，如层、<a class="ae lv" href="https://en.wikipedia.org/wiki/Objective_function" rel="noopener ugc nofollow" target="_blank">目标</a>、<a class="ae lv" href="https://en.wikipedia.org/wiki/Activation_function" rel="noopener ugc nofollow" target="_blank">激活函数</a>、<a class="ae lv" href="https://en.wikipedia.org/wiki/Mathematical_optimization" rel="noopener ugc nofollow" target="_blank">优化器</a>，以及许多工具，使处理图像和文本数据更容易，以简化编写深度神经网络代码所需的编码。</li><li id="5cb4" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated"><strong class="ju hj"> Pickle </strong> : Python pickle模块用于序列化和反序列化Python对象结构。Python中的任何对象都可以被腌制，以便保存在磁盘上。在这个项目中，我们使用pickle保存训练好的模型。</li></ol><h1 id="e1c4" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">6.映象分析</h1><ol class=""><li id="32b6" class="js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">JSON格式的图像的训练和测试数据应该被写入csv文件以供进一步分析。使用下面的代码可以读取并保存为csv文件。</li></ol><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/cc7b82ac7426e9da879cb7e2b7c0c65d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d4ZmCctmJzrsK7ort35NBw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">JSON到CSV</figcaption></figure><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/5351156f601e5af13253d38086ffc67f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aEjNZxyUMp5WZ_fGsvnuyA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">列车CSV</figcaption></figure><p id="703c" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">2.训练数据有7个标签，测试数据有6个标签。数据高度不平衡。在训练和测试图像中，红细胞的数量都非常高。</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/7271ca309cbd4a9152fc17330b234b40.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*dAcxLSTpwQSihkJqsfjoOw.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">标签计数</figcaption></figure><p id="e5bf" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">3.为所有图像中的每个对象提供边界框坐标及其标签。通过这些边界框，我们可以看到一个训练和测试图像是什么样子的。</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div class="er es md"><img src="../Images/48de5355dafec40101d3c045d6090d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*xCu2zWOASPI3wFuYfDy9nQ.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">列车图像</figcaption></figure><figure class="lx ly lz ma fd ij er es paragraph-image"><div class="er es me"><img src="../Images/db682f0766c7d94603e4dd700885aeec.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*HohHG7g8cJFaaYRQ4wT2lA.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">测试图像</figcaption></figure><p id="04c8" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">4.用于训练更快的R-CNN技术的输入格式将是注释文本文件，该文件将具有图像文件名、边界框坐标及其类别值。可以使用下面的代码创建训练和测试注释文本文件。</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/acb84605f20f850786c31e1086e485fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uvD1w5LPVpHde5A6-tZWIA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">csv到文本文件</figcaption></figure><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/464ef13900b7ff7f421dde3f46241ba9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ErLhGDiwVjsHPn0X-rw2TA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">注释文件</figcaption></figure><p id="0bff" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">5.我们现在可以着手建立更快的R-CNN模型，并在疟疾图像上进行训练。</p><h1 id="3a63" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">7.应用更快的R-CNN</h1><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/518b2f1e7ddf116009099dac032e3a02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GYri4SV0kS0h1mRGJs7MRA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">更快的R-CNN</figcaption></figure><ol class=""><li id="eb8f" class="js jt hi ju b jv lq jx lr jz mi kb mj kd mk kf kg kh ki kj bi translated"><strong class="ju hj">基本型号:</strong>更快的R-CNN使用VGG-16、ResNet之类的基本CNN型号..以提取图像的特征。在这个项目中，在ImageNet数据集上训练的VGG-16模型被用作提取特征的基础模型。由于更快的R-CNN使用单独的分类层来对带有标签的对象进行分类，因此中间卷积层的输出被用于将其传递到下一层。</li></ol><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/146286df4bc5c0d377ea962fbf09fe62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Lg1i7wv1pLpzp2F4MLrvw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">VGG-16</figcaption></figure><p id="87c9" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">2.<strong class="ju hj">锚点:</strong>这些是固定的边界框，它们以不同的大小和长宽比放置在整个图像中，在首次预测对象位置时将用作参考。由于每个疟疾图像中的对象都非常小，锚定框比例是一个超参数，可以调整它以通过图像创建锚定框。用于这些图像的锚定框比例为[8，16，32]。</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/37eb3aa8c4a0dc295b16157335c16126.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*JZewcyXx1IjsiWzen2JeXQ.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">正面锚</figcaption></figure><p id="b5d3" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">3.<strong class="ju hj">区域建议网:</strong> RPN把所有的参考框(主播)放入两个不同的类别。那些与具有大于0.5的并集  (IoU)上的<a class="ae lv" href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hj">交集的地面实况对象重叠的对象被认为是“前景”，而那些不与任何地面实况对象重叠或者具有小于0.1 IoU的地面实况对象的对象被认为是“背景”，并且输出一组良好的对象提议。</strong></a></p><p id="42bc" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">RPN以完全卷积的方式有效地实现，使用由基础网络返回的卷积特征图作为输入。首先，我们使用一个具有512个信道和3x3内核大小的卷积层，然后我们有两个使用1x11 <em class="mn"> x </em> 1内核的并行卷积层，其信道数量取决于每个点的锚数量。对于分类层，我们输出每个锚点的两个预测:它是背景(不是对象)的得分和它是前景(实际对象)的得分。</p><p id="f7d7" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">对于回归或边界框调整层，我们输出4个预测:deltas \Delta_{x_{center}} 、\Delta_{y_{center}} 、\Delta_{width} 、\ Delta _ { height }δ<em class="mn">x</em><em class="mn">中心</em>、δ<em class="mn">y</em><em class="mn">中心</em>、δ<em class="mn">宽度</em>、δ<em class="mn">高度</em>，我们将这些预测应用于锚点以获得最终提议。</p><p id="dd5e" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">使用最终的提议坐标和它们的“对象性”分数，我们就有了一组好的对象提议。</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/412c4f8ad53ee8a88fc99cc88273b702.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-_5AXEw7icZ3gwnrreWxSQ.png"/></div></div></figure><p id="4aff" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">4.<strong class="ju hj">非最大抑制:</strong>由于锚点通常会重叠，所以提议最终也会重叠在同一个对象上。为了解决重复建议的问题，我们使用一种简单的算法方法，称为非最大抑制(NMS)。NMS获取按分数排序的提案列表，并遍历排序后的列表，丢弃那些IoU大于阈值0.9的提案，而使用具有更高分数的提案。应用NMS后，考虑前300个建议。</p><p id="bff6" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">5.<strong class="ju hj">兴趣池区域:</strong>现在我们有一堆没有分配给它们的类的对象提议。在这一步中，我们获取每一个建议，对其进行裁剪，然后将其传递到最终的分类R-CNN层，以标记这些建议。</p><p id="5fca" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">一种更简单的方法，被对象检测实现广泛使用，包括Luminoth的更快的R-CNN，是使用每个建议裁剪卷积特征地图，然后使用插值(通常是双线性的)将每个裁剪调整为固定大小的14×14× <em class="mn"> convdepth </em>。裁剪后，使用2x2内核的max pooling为每个建议获得最终的7×7× <em class="mn"> convdepth </em>特征图。</p><p id="c9e2" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">选择这些精确形状的原因与下一个块如何使用它有关(R-CNN)。重要的是要明白，这些是可定制的，取决于第二阶段的使用。</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/de3a71d75bdc673a7a48d4081e7f88a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cBXXqZy2P4PqEMYvS8-ZTg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">投资收益率</figcaption></figure><p id="5bc9" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">6.<strong class="ju hj">基于区域的卷积神经网络:</strong>基于区域的卷积神经网络</p><p id="7b3e" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">基于区域的卷积神经网络(R-CNN)是更快的R-CNN管道中的最后一步。从图像中获得卷积特征图后，使用它来获得具有RPN的对象提议，并最终为这些提议中的每一个提取特征(通过RoI Pooling)，我们最终需要使用这些特征进行分类。R-CNN试图模仿分类CNN的最后阶段，其中全连接层用于输出每个可能的对象类的分数。</p><p id="7be4" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">R-CNN有两个不同的目标:</p><ol class=""><li id="7be1" class="js jt hi ju b jv lq jx lr jz mi kb mj kd mk kf kg kh ki kj bi translated">将提案分类为一个类别，加上一个背景类别(用于删除不良提案)。</li><li id="8fc5" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">更好地根据预测的类别调整提议的边界框。</li></ol><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/1f11c5eb0c93df590a1276fc48ee3548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*178FsEdjhpWhzIaWEtOFiA.jpeg"/></div></div></figure><p id="ceab" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">7.<strong class="ju hj">训练:</strong>一旦模型准备好了，我们通过传递train_annotation.txt文件开始训练，初始化基本模型权重并将类的数量传递给模型。准确性是训练模型时使用的度量标准。训练了100个时期，其中每个时期花费大约2小时，并且实现了93%的准确度。记录了4种不同的损耗，RPN层两种，R-CNN层两种。使用随机梯度下降来训练该模型，这导致</p><pre class="lx ly lz ma fd mr ms mt mu aw mv bi"><span id="a31c" class="mw iv hi ms b fi mx my l mz na">Classifier accuracy for bounding boxes from RPN: 0.934<br/>Loss RPN classifier: 0.08543467678808205<br/>Loss RPN regression: 0.02398829758935608<br/>Loss Detector classifier: 0.1817812535882481<br/>Loss Detector regression: 0.03701828640169697<br/>Total loss: 0.3282225143673832</span></pre><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nb"><img src="../Images/8a045ea4a150479dc0e58fdb57f7c2d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P3YHFreq-HxEaNWYYCW_zw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">准确(性)</figcaption></figure><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nc"><img src="../Images/c2e68496137e817bd299a11655325295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_YbXUf0NKsBdok0JTU_AMQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">损耗</figcaption></figure><h1 id="2d25" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak"> 8。测试数据评估</strong></h1><p id="1e79" class="pw-post-body-paragraph lb lc hi ju b jv jw ld le jx jy lf lg jz lh li lj kb lk ll lm kd ln lo lp kf hb bi translated">评估是在特定IoU阈值为0.7时使用标准平均精度(mAP)完成的。使用在上一步骤中保存的训练模型，通过传递测试注释文件及其类标签来预测测试图像的边界框。</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/d6e3f96e324a3e07734fff68f33d16fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*lIZI_4IjtcDiwwN3qd_Rbw.jpeg"/></div></figure><p id="77ed" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">计算所有120幅测试图像的精度，以查看每幅图像中疟疾细胞的预测。</p><pre class="lx ly lz ma fd mr ms mt mu aw mv bi"><span id="8398" class="mw iv hi ms b fi mx my l mz na">Elapsed time = 3.3739821910858154<br/>red blood cell AP: 0.9098086551867395<br/>gametocyte AP: 0.7333333333333333<br/>trophozoite AP: 0.7837234722362358<br/>ring AP: 0.7036900726267535<br/>schizont AP: 0.44<br/>difficult AP: 0.056179775280898875<br/>mAP = 0.6044558847773268<br/>112/120<br/>Elapsed time = 3.3699944019317627<br/>red blood cell AP: 0.9095687056598919<br/>gametocyte AP: 0.7333333333333333<br/>trophozoite AP: 0.7884311726729429<br/>ring AP: 0.7036900726267535<br/>schizont AP: 0.4230769230769231<br/>difficult AP: 0.053763440860215055<br/>mAP = 0.60197727470501<br/>113/120<br/>Elapsed time = 3.3679988384246826<br/>red blood cell AP: 0.9098503831773301<br/>gametocyte AP: 0.7333333333333333<br/>trophozoite AP: 0.7884311726729429<br/>ring AP: 0.7068164731280739<br/>schizont AP: 0.4230769230769231<br/>difficult AP: 0.053763440860215055<br/>mAP = 0.6025452877081364<br/>114/120<br/>Elapsed time = 3.742985725402832<br/>red blood cell AP: 0.9101059579135993<br/>gametocyte AP: 0.7333333333333333<br/>trophozoite AP: 0.7884311726729429<br/>ring AP: 0.7135207354597167<br/>schizont AP: 0.4230769230769231<br/>difficult AP: 0.053763440860215055<br/>mAP = 0.6037052605527884<br/>115/120<br/>Elapsed time = 3.854698419570923<br/>red blood cell AP: 0.9101823806717539<br/>gametocyte AP: 0.7333333333333333<br/>trophozoite AP: 0.7884311726729429<br/>ring AP: 0.7146642333156751<br/>schizont AP: 0.4230769230769231<br/>difficult AP: 0.053763440860215055<br/>mAP = 0.6039085806551406<br/>116/120<br/>Elapsed time = 3.3181307315826416<br/>red blood cell AP: 0.9095249366698459<br/>gametocyte AP: 0.75<br/>trophozoite AP: 0.7899554367201427<br/>ring AP: 0.7146642333156751<br/>schizont AP: 0.4230769230769231<br/>difficult AP: 0.05319148936170213<br/>mAP = 0.6067355031907148<br/>117/120<br/>Elapsed time = 3.3460564613342285<br/>red blood cell AP: 0.9097258074309477<br/>gametocyte AP: 0.7058823529411765<br/>trophozoite AP: 0.7914580101784912<br/>ring AP: 0.7169115123945246<br/>schizont AP: 0.4230769230769231<br/>difficult AP: 0.05319148936170213<br/>mAP = 0.6000410158972942<br/>118/120<br/>Elapsed time = 3.3121471405029297<br/>red blood cell AP: 0.9099155549306795<br/>gametocyte AP: 0.7058823529411765<br/>trophozoite AP: 0.7914580101784912<br/>ring AP: 0.7186625010102929<br/>schizont AP: 0.4230769230769231<br/>difficult AP: 0.05263157894736842<br/>mAP = 0.6002711535141553<br/>119/120<br/>Elapsed time = 3.4268405437469482<br/>red blood cell AP: 0.9094612324851495<br/>gametocyte AP: 0.7058823529411765<br/>trophozoite AP: 0.7858513244702504<br/>ring AP: 0.7220951977234226<br/>schizont AP: 0.4230769230769231<br/>difficult AP: 0.05263157894736842<br/>mAP = 0.5998331016073818</span></pre><p id="7e79" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">对于使用训练模型的所有测试图像，实现的平均精度约为60%。</p><h1 id="760b" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">9.参考</h1><ol class=""><li id="8a1c" class="js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">GitHub代码库:<a class="ae lv" href="https://github.com/sriluk9/MalariaCells-ObjectDetection-Using-FasterRCNN" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/Sri luk 9/malaria cells-object detection-Using-fasterr CNN</a></li><li id="6abd" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated">参考链接:<a class="ae lv" href="https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/" rel="noopener ugc nofollow" target="_blank">https://tryo labs . com/blog/2018/01/18/faster-r-CNN-down-the-rabbit-hole-of-modern-object-detection/</a></li><li id="6f36" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated"><a class="ae lv" href="https://towardsdatascience.com/faster-r-cnn-object-detection-implemented-by-keras-for-custom-data-from-googles-open-images-125f62b9141a" rel="noopener" target="_blank">https://towards data science . com/faster-r-CNN-object-detection-implemented-by-keras-for-custom-data-from-Google-open-images-125 f62b 9141 a</a></li><li id="b034" class="js jt hi ju b jv kk jx kl jz km kb kn kd ko kf kg kh ki kj bi translated"><a class="ae lv" href="https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2018/11/implementation-faster-r-CNN-python-object-detection/</a></li></ol><p id="5408" class="pw-post-body-paragraph lb lc hi ju b jv lq ld le jx lr lf lg jz ls li lj kb lt ll lm kd lu lo lp kf hb bi translated">谢谢你</p></div></div>    
</body>
</html>