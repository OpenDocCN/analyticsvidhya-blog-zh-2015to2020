<html>
<head>
<title>Convolutional Neural Networks-Demystified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络——去神秘化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/convolutional-neural-networks-demystified-80f72c1ea31b?source=collection_archive---------17-----------------------#2020-09-23">https://medium.com/analytics-vidhya/convolutional-neural-networks-demystified-80f72c1ea31b?source=collection_archive---------17-----------------------#2020-09-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2b83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人工智能在过去十年里变得非常先进。它甚至在一些任务中表现出接近人类水平的准确性，如图像分类和物体检测。</p><p id="81bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2012 年，当 Alex Krizhevsky 和他的队友赢得 ImageNet 比赛时，计算机视觉领域出现了突破。他们建立了一个卷积神经网络架构来解决图像分类问题。</p><p id="e3e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是计算机视觉新时代的开始，到目前为止，我们已经即兴构建了几个架构，如 VGG16、VGG19、ResNet50、ResNet150，这些架构几乎以人类水平的精度解决了计算机视觉问题。卷积神经网络是所有这些架构的基础。</p><p id="8c10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是这个卷积神经网络是什么，它是如何工作的。我将在本文中一步一步地解释它，但首先，我们需要有一些基础知识，比如什么是神经网络，它与卷积神经网络有什么不同(<strong class="ih hj"> <em class="jd"> CNN </em> </strong>)</p><h1 id="b916" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">什么是神经网络？</h1><p id="52cb" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">在非常高的层次上，神经网络是一种能够学习输入和输出之间关系的神经元架构。输入可以是图像的像素，输出可以是图像属于哪一类，像狗还是猫。如果你想了解更多关于神经网络的内容，你可以在这里  <strong class="ih hj">查看我之前关于神经网络的博客<a class="ae kh" rel="noopener" href="/swlh/introduction-to-neural-networks-d0ff7e9a647b"> <strong class="ih hj">。</strong></a></strong></p><h1 id="af4b" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">为什么卷积神经网络优于传统方法？</h1><p id="709c" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">有一些传统的方法来解决图像问题，如使用模板匹配和酉图像变换等特征工程的机器学习算法。它们是图像相关问题的解决方案，如人脸检测、人脸识别、图像分类或物体检测。但所有这些方法都是基于手工编码的特征，当你将这些特征输入到机器学习算法中时，它们不会将其推广到更广泛的数据集。因此，它们在现实世界中是行不通的。</p><h1 id="b4f6" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">卷积神经网络如何优于传统方法？</h1><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ki"><img src="../Images/9c70ea0b416431525b59e1673acecc22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VMYAQF9SCqJDlRnUI4RZWQ.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">高级卷积神经网络</figcaption></figure><p id="bce6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CNN 网络将输入视为图像，并尝试从中提取特征，而不是手动编码的特征，因此它在学习特征方面具有更大的灵活性。</p><p id="d9fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人工神经网络(<strong class="ih hj"> <em class="jd"> ANN </em> </strong>)将输入作为所有特征，并试图学习所有输入特征和输出之间的函数。</p><p id="d647" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，我们的输入特征是图像原始像素，可能与输出没有良好的关系，因此，如果我们直接使用<strong class="ih hj"> ANN </strong>来完成图像分类等任务，它会将所有像素视为特征，并遇到一个称为维数灾难的问题。</p><p id="02b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是如果我们使用 CNN，它将首先尝试使用称为<strong class="ih hj">滤波器</strong>的权重矩阵从图像中提取特征，然后创建一个通常被称为<strong class="ih hj">特征图</strong>的特征图。然后，该特征图将被传递到人工神经网络或网络的密集层上，以进行预测。</p><p id="9711" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">特征地图是在训练过程中学习的，因此我们可以给出任何类型的图像，网络将尝试提取和学习它生成的特征。</p><h1 id="24cf" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">这些地图是如何创建的，过滤器在这个过程中有什么帮助？</h1><p id="bdaf" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">使用称为<strong class="ih hj">过滤器</strong>或<strong class="ih hj">内核</strong>的权重矩阵来创建特征图。最初，这些权重是随机分配的，就像网络中的其他权重一样，但它们是在训练过程中学习的。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ky"><img src="../Images/e8457adf507b4db0afa7686bb1e02fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z3tVpwY2ULg3UlwXwAGQwg.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">使用滤波器的特征提取</figcaption></figure><p id="e113" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个例子中，图像输入为 6*6，我们有一个 3*3 的滤波器来提取特征。首先，我们从 6*6 的图像中提取 3*3 的一部分，然后我们计算过滤器和图像的这一部分之间的点积，最终生成一个数字。在本例中，我们生成了 31 个。</p><p id="57c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实际上，我们有 RGB 通道的图像，这意味着在这种情况下图像将是 6*6*3，部分将是 3*3*3，过滤器也是如此。想象一下，只需将 3*3*3 的向量展平为 1*27，然后在内核和图像部分之间取点积。</p><p id="edd8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们对整个图像重复这一过程，通过在整个图像上移动过滤器，最终生成二维<strong class="ih hj">图</strong>或矩阵。我们把这个图叫做<strong class="ih hj">特征图</strong>。在实践中，我们使用不止一个滤波器来从图像中提取更多的特征。通常使用的过滤器数量通常是 2 的倍数，如 32、64、128 或 256。</p><p id="e4ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们采用了<strong class="ih hj"> n </strong>个滤波器，那么我们从卷积层输出的大小将是<em class="jd">某个数字*某个数字*</em><strong class="ih hj"><em class="jd">n</em></strong><em class="jd">。</em></p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es kz"><img src="../Images/29155ace3a4067e095bca8625924a00f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*4Dx_dPbsCQlcL0kcT5766Q.jpeg"/></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">填料</figcaption></figure><p id="07f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有时在实践中，我们希望使用图像的每个部分提取更多的特征，所以我们使用填充。填充只是在图像的角上加零，这有助于我们创建一个更大的图像，这样我们就可以提取更多的特征。也是一种生成一定大小的特征地图的技术。</p><p id="de2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还在卷积层中使用 stride，这是您在生成特征地图时希望在图像上采取的步骤。我们可以使用此公式来计算将要创建的要素地图的大小:</p><blockquote class="la lb lc"><p id="5bd5" class="if ig jd ih b ii ij ik il im in io ip ld ir is it le iv iw ix lf iz ja jb jc hb bi translated"><strong class="ih hj">n-2 * p+f/s→某数</strong></p></blockquote><p id="af72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">n 是图像的输入尺寸。<em class="jd">(如果图像是 100*100，那么 n 就是 100) </em></p><p id="4b0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">p 是填充<em class="jd">(某数)</em></p><p id="7a22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">f 是过滤器尺寸<em class="jd">(如果过滤器尺寸是 3*3，则 f 是 3) </em></p><p id="503d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">s 是步幅<em class="jd">(某数)。</em></p><p id="3c78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经了解了要素地图和卷积图层。我们使用一些额外的技术来改进结果。CNN 架构中还有两个常见组件。这些是<strong class="ih hj">池层</strong>和<strong class="ih hj"> Relu </strong>激活功能</p><h1 id="33de" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">汇集层</h1><p id="9657" class="pw-post-body-paragraph if ig hi ih b ii kc ik il im kd io ip iq ke is it iu kf iw ix iy kg ja jb jc hb bi translated">一个<strong class="ih hj">池层</strong>是一个<strong class="ih hj"> CNN </strong>的另一个积木。它的功能是逐渐减小表示的空间大小，以减少网络中的参数和计算的数量。汇集<strong class="ih hj">层</strong>在每个特征地图上独立操作。</p><p id="c20d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">整体思路是缩小要素地图的大小，仅保留网络中的重要要素。</p><h2 id="d729" class="lg jf hi bd jg lh li lj jk lk ll lm jo iq ln lo js iu lp lq jw iy lr ls ka lt bi translated">共用的常见方式</h2><ol class=""><li id="b792" class="lu lv hi ih b ii kc im kd iq lw iu lx iy ly jc lz ma mb mc bi translated">最大池化</li><li id="8dcf" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">最小池</li><li id="36c6" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">平均池</li></ol><p id="f631" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在了解每种类型的池之前，让我们先了解池是如何工作的。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es mi"><img src="../Images/59478a9c01e3da65c26e66f1e6752c22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*zygzpA-Ub68EFjvChReVnA.jpeg"/></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">CNN 中的池层</figcaption></figure><p id="3b7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上图中，假设我们已经创建了一个<strong class="ih hj"> 4*4 </strong>的特征图，现在我们想缩小这个特征图的尺寸。我们可以使用池层和池大小。</p><p id="cf7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">池大小就是在缩小规模的每个步骤中使用的特征图的大小。这里我们用了 2*2。这将从特征地图中裁剪出 2*2 的地图，然后从中提取最大数量。(<strong class="ih hj"> <em class="jd">最大汇集</em> </strong>)</p><p id="ddde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将对每个特征地图独立地重复该过程。我们可以使用最大池来获取最大数量。我们可以使用 Min Pooling 获取最小数量，也可以使用 Average pooling 获取该区域所有数量的平均值。最常见的是最大和平均池。</p><p id="c908" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">既然我们已经使用了池层来缩小特征地图，我们可以使用 Relu 激活功能来优化特征地图。</p><h1 id="99f8" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">Relu 激活功能</h1><blockquote class="la lb lc"><p id="fd94" class="if ig jd ih b ii ij ik il im in io ip ld ir is it le iv iw ix lf iz ja jb jc hb bi translated">给定一个输入或一组输入，节点的<strong class="ih hj">激活函数</strong>定义该节点的输出。激活函数决定哪些信息应该在网络中前进，哪些信息应该被忽略。</p></blockquote><p id="1bef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">神经网络中使用了不同的激活函数，如 sigmoid、Relu、Tanh、leaky Relu，但 CNN 的<strong class="ih hj"> Relu </strong>是使用最多的激活函数。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mj"><img src="../Images/daf6b0d6d97baf0065f7f278f3330b8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ys5QBaq8qej_mZWxtrvz6w.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">Relu 激活功能- CNN</figcaption></figure><p id="3d00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Relu( <em class="jd">整流线性单元</em>)就是给定输入正 x 的正 x，以及负 x 的零。这有助于改进特征，并且计算梯度也变得更快，因为对于所有负 x，它将是 0。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mk"><img src="../Images/3fbc91ef310f77073e6bd8c9d0c15570.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z-2oEe3RhNoiLtoHHtSwAg.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">Relu 对特征地图的影响</figcaption></figure><p id="6965" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用 Relu 激活函数细化特征映射中的值。所有负值变为零，所有正值保持不变。这有助于我们确定要素的重要性以及该要素在网络中的位置。</p><p id="6cc5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有时我们在池层之后使用 Relu，有时在池层之前使用它。它是实践者和问题陈述的完整架构选择。</p><p id="67af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个过程可以重复几层，如 Vgg16、Vgg19，但卷积神经网络的基本组件保持不变。</p><p id="5916" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们提炼了这些特征，我们就使用人工神经网络或密集层，最终学习输入和输出之间的函数。</p><p id="92f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们假设我们最终有一个 30*30*20 的特征图，然后我们可以将该特征图展平并将其传递给人工神经网络。在这种情况下，输入将是 1*18000。这是一个非常大的向量，处理起来会很昂贵。</p><p id="615f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是我们使用池层和激活函数的原因，这样我们可以减少最终向量的大小，并且只保留手头问题陈述所需的信息。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mj"><img src="../Images/a8150e44ef20d38e38f8a083eb7d0735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ysUVjIIZiHVIkdtZqsGFXQ.png"/></div></div></figure><p id="fa06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们提取了所有的特征并提炼出来。我们可以使用神经网络来完成这项任务。我们可以使用这种神经网络来完成各种任务，如图像分类、目标定位、图像分割。架构将根据问题陈述而变化，但核心思想将保持不变。</p><p id="162a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望你从这篇文章中学到了一些东西。我会写更多关于循环神经网络的文章。</p></div></div>    
</body>
</html>