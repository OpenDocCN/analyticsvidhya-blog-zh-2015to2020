<html>
<head>
<title>Physics-Based Machine Learning: Combining Scientific Computing and Machine Learning for Inverse Problems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于物理学的机器学习:结合科学计算和机器学习解决逆问题</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/physics-based-machine-learning-combining-scientific-computing-and-machine-learning-for-inverse-ddb897eaf2ec?source=collection_archive---------9-----------------------#2019-12-25">https://medium.com/analytics-vidhya/physics-based-machine-learning-combining-scientific-computing-and-machine-learning-for-inverse-ddb897eaf2ec?source=collection_archive---------9-----------------------#2019-12-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2544" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文改编自基于物理学的机器学习库ADCME文档</p><div class="jd je ez fb jf jg"><a href="https://github.com/kailaix/ADCME.jl" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hj fi z dy jl ea eb jm ed ef hh bi translated">kailaix/ADCME.jl</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">ADCME图书馆(计算和数学工程的自动微分图书馆)的目标是一般的…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">github.com</p></div></div><div class="jp l"><div class="jq l jr js jt jp ju jv jg"/></div></div></a></div><h1 id="b662" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">什么是逆向建模？</h1><p id="6276" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">逆建模问题在数学上可以表述为在给定正模型的输入X和输出u的情况下寻找未知参数X</p><p id="eef1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">u= <em class="kz"> F </em> ( <em class="kz"> θ，</em> X)</p><p id="1b5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里X和u可以是随机过程的样本。可以用ADCME处理的逆问题的范围是</p><ol class=""><li id="e0e7" class="la lb hi ih b ii ij im in iq lc iu ld iy le jc lf lg lh li bi translated">正向模型必须<em class="kz">可微</em>，即∂ <em class="kz"> F/ </em> ∂ <em class="kz"> X </em>和∂ <em class="kz"> F/ </em> ∂ <em class="kz"> θ </em>存在。然而，我们并不要求那些渐变由用户来实现；它们可以用ADCME中的自动微分来计算。</li><li id="a018" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc lf lg lh li bi translated">前向模型必须是一个<em class="kz">白盒</em>并通过ADCME实现。ADCME不用于黑盒模型的逆建模。</li></ol><figure class="lp lq lr ls fd lt er es paragraph-image"><div class="er es lo"><img src="../Images/32822196514d4d00b9bc9cfb57f3b446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/0*pHOaYLoZFfe6roZt.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">逆向建模的范例</figcaption></figure><p id="9226" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">估计x的一个迭代过程如下:我们从初始猜测X=X⁰开始，假设它是正确的，并且用在ADCME中实现的正向建模代码计算预测的输出u⁰。然后，我们测量预测的输出u⁰和实际的u之间的差异，并应用常规的基于梯度的优化方法来找到最小化该差异的最佳x。梯度用自动微分法、伴随状态法或两者都用来计算。</p><p id="2612" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种概念上简单的方法可以解决各种类型的反问题:X，u是随机的或确定的，未知的X可以是值、函数、泛函甚至随机变量。例如，假设正演模型是具有适当边界条件的泊松方程(可视为输入数据<em class="kz"> θ </em>)，</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div class="er es lz"><img src="../Images/d89156ff8a6db07d71547c07c3f732b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*OYKeIzTD5oZN04D7bSz48Q.png"/></div></figure><p id="656e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">u(x)是输出，下表列出了可以用ADCME解决的四类潜在问题</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ma"><img src="../Images/a8c02104a7466bc73e1d65fda6de8d29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VkYoKcWMyAucGzaDWbDXaw.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">(*)f<em class="mf">f</em>的自变量独立于u<em class="mf">u</em>(*)f<em class="mf">f</em>的自变量中至少有一个依赖于u</figcaption></figure><h1 id="3b6d" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">利用ADCME进行逆建模</h1><h2 id="b195" class="mg jx hi bd jy mh mi mj kc mk ml mm kg iq mn mo kk iu mp mq ko iy mr ms ks mt bi translated">参数逆建模</h2><p id="fbcb" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">当<em class="kz"> X </em>只是一个标量/向量时，我们称这类问题为<strong class="ih hj">参数反问题</strong>。我们考虑一个人为的解决方案:精确的<em class="kz"> X </em>是1，而<em class="kz">u</em>(<em class="kz">X</em>)=<em class="kz">X</em>(1-<em class="kz">X</em>)，所以我们有</p><p id="e952" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kz"> φ </em> ( <em class="kz"> x </em> )=2</p><p id="00d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们可以观察到<em class="kz"> u </em> (0.5)=0.25，最初的猜测为<em class="kz"> X </em> 0 =10。我们使用有限差分法对偏微分方程进行离散，区间[0，1]被均匀划分为0 =<em class="kz">x(</em>0)&lt;<em class="kz">x(</em>1)&lt;…&lt;<em class="kz">x(n)</em>= 1，其中<em class="kz"> n </em> =100，<em class="kz">x(I</em>+1)—<em class="kz">x(I)</em>=<em class="kz">h【T17</em></p><p id="8f04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以用下面的代码片段解决这个问题</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mu"><img src="../Images/df54dabbb32c4b890160b9ef46ceb208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KzgtwL31ZeZgjfF3qxdOfQ.png"/></div></div></figure><p id="44a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在大约7次迭代之后，估计的<em class="kz"> X </em> 0收敛到1.0000000016917243。</p><h2 id="63af" class="mg jx hi bd jy mh mi mj kc mk ml mm kg iq mn mo kk iu mp mq ko iy mr ms ks mt bi translated">函数逆问题</h2><p id="e981" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">当<em class="kz"> X </em>是不依赖于<em class="kz"> u </em>的函数，即位置<em class="kz"> x </em>的函数时，我们称这类问题<strong class="ih hj">函数反问题</strong>。解决这类问题的一种常见方法是用参数化形式来逼近未知函数<em class="kz"> X </em>，例如分段线性函数、径向基函数或切比雪夫多项式；有时我们也可以将<em class="kz"> X </em>离散化，并用离散网格节点上的值的向量来代替<em class="kz"> X </em>。</p><p id="d985" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本教程不是针对不同方法的比较。相反，我们展示了如何使用神经网络来表示<em class="kz"> X </em>，并通过将其与数值方案相结合来训练神经网络。用传统的伴随状态法计算梯度是很费力的，但用自动微分法却很简单。</p><p id="3bf3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们假设真实的<em class="kz"> X </em>具有以下形式</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div class="er es mv"><img src="../Images/5c6aa8a592210a4130df54f5f65dff15.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*SqgbCgl7ynMtwuoVoyrEaQ.png"/></div></figure><p id="50c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">精确的<em class="kz"> φ </em>由下式给出</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div class="er es mw"><img src="../Images/f3afa268d425859ab3f71728e76ca185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*a0NBk5Pn6MvGmCJ8AyHezQ.png"/></div></figure><p id="cd37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">想法是使用一个神经网络N(<em class="kz">x</em>；带有权重和偏差的<em class="kz">w</em>w<em class="kz">w</em>，其将位置<em class="kz"> x </em> ∈R映射到标量值，使得</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div class="er es mx"><img src="../Images/4549992d69d4c2cc26ee933a945cff28.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*6Rb7Dea8MzV1DNXUFX7V3A.png"/></div></figure><p id="8c40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了找到可选的<em class="kz"> w </em>，我们用<em class="kz">X</em>(<em class="kz">X</em>)= N(<em class="kz">X</em>)解泊松方程；<em class="kz"> w </em>)，其中数值方案为</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es my"><img src="../Images/0afac7a75df6d30c59a6a8a9b20b3f73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kzjc01WP0nhVf_svFK1D0Q.png"/></div></div></figure><p id="10c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里<em class="kz">Xi</em>= N(<em class="kz">Xi</em>；<em class="kz"> w </em>)。</p><p id="8ce6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们可以观测到全解<em class="kz"> u </em> ( <em class="kz"> x </em>)，我们可以将其与解<em class="kz"> u </em> ( <em class="kz"> x </em>)进行比较；<em class="kz"> w </em>)，以及最小化损失功能</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div class="er es mz"><img src="../Images/e07c009eb650ffabc2a1b16eed57d204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*VWmOKnaGmg4UpVlt9-hILA.png"/></div></figure><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es na"><img src="../Images/a58c45dbce2a49cb0820fb4a2e2b60b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PaFh88yICi-Pw6EU6GiFnw.png"/></div></div></figure><p id="d2dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在下面的图中显示了精确的<em class="kz"> X </em> ( <em class="kz"> x </em>)和逐点误差</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div class="er es nb"><img src="../Images/cf81e9044faaeff61209c5c7796c2b9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*ohrXM0eSCDF7YusKKbfX1w.png"/></div></figure><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nc"><img src="../Images/d1f27d573460807362fa7d78388fdf6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TFQpbpT827S92owIAjhQHg.png"/></div></div></figure><h2 id="b39d" class="mg jx hi bd jy mh mi mj kc mk ml mm kg iq mn mo kk iu mp mq ko iy mr ms ks mt bi translated">泛函反问题</h2><p id="bb0b" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">在<strong class="ih hj">泛函逆问题</strong>中，<em class="kz"> X </em>是<em class="kz">依赖</em>于<em class="kz"> u </em>(或者两者都是<em class="kz"> x </em>和<em class="kz"> u </em>)的函数；它不能与泛函反问题相混淆，而且更难解决(因为方程是非线性的)。例如，我们可能有</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div class="er es nd"><img src="../Images/9ed75cb17816404415d344365ad3b641.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*FGKZ6wOPNdAT3yquEKvmcQ.png"/></div></figure><p id="5495" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对应的<em class="kz"> φ </em>是</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ne"><img src="../Images/763e2393c69635ad352b153d02fde90f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JdDMXBNvaUpj48_nd9rnqg.png"/></div></div></figure><p id="769d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了求解泊松方程，我们使用标准的牛顿-拉夫森格式，在这种情况下，我们需要计算残差</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nf"><img src="../Images/2c8ee729f8ea44d887c071914ad82de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LxGD1B-ODNHP44fFFgNcZQ.png"/></div></div></figure><p id="c398" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和相应的雅可比矩阵</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ng"><img src="../Images/ffd71ec42f996cee5fc8fc005380b90e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s_jCqQtpynnG4eydF9W0aQ.png"/></div></div></figure><p id="e935" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就像函数反问题一样，我们也是用一个神经网络来逼近<em class="kz">X</em>(<em class="kz">u</em>)；不同的是神经网络的输入是<em class="kz"> u </em>而不是<em class="kz"> x </em>。自动微分便于计算<em class="kz">X</em>'(<em class="kz">u</em>)。如果我们使用分段线性函数，就只能计算弱意义上的梯度；但这对于神经网络来说不是问题，只要我们使用“tanh”之类的平滑激活函数。</p><p id="b21e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ADCME还为您准备了内置的牛顿-拉夫森求解器<code class="du nh ni nj nk b"><a class="ae nl" href="https://kailaix.github.io/ADCME.jl/dev/newton_raphson/#ADCME.newton_raphson" rel="noopener ugc nofollow" target="_blank">newton_raphson</a></code>。要使用这个函数，你只需要提供残差和雅可比</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nm"><img src="../Images/31d979cd2b518743b4a8c82b355ed416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QTU6YZ3ObuPD09GzL3Gp4A.png"/></div></div></figure><p id="e753" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我们可以用来解泊松方程</p><pre class="lp lq lr ls fd nn nk no np aw nq bi"><span id="6108" class="mg jx hi nk b fi nr ns l nt nu">newton_raphson(residual_and_jacobian, u0, θ)</span></pre><p id="4fa4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里需要注意的是，牛顿-拉夫森算子是一种<a class="ae nl" href="https://kailaix.github.io/ADCME.jl/dev/inverse_modeling/#Forward-Operator-Types-1" rel="noopener ugc nofollow" target="_blank">非线性隐式算子</a>，它不属于自动微分应用的算子类型。幸运的是，ADCME提供了一个API来抽象这个技术难题，用户可以直接调用<code class="du nh ni nj nk b"><a class="ae nl" href="https://kailaix.github.io/ADCME.jl/dev/api/#ADCME.NonlinearConstrainedProblem-Union{Tuple{T},%20Tuple{Function,Function,Union{Array{Float64,1},%20PyObject},Union{PyObject,%20Array{Float64,N}%20where%20N}}}%20where%20T%3C:Real" rel="noopener ugc nofollow" target="_blank">NonlinearConstrainedProblem</a></code>来提取梯度。</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nv"><img src="../Images/ad33010a865e15d497589a8175da9375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wVW-2RTGxNshqHCr6qh9Rg.png"/></div></div></figure><p id="a59e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，在这种情况下，我们只有一组观测值，逆问题可能是不适定的，即解不是唯一的。因此，我们所能期望的最好结果是，我们能找到N( <em class="kz"> x </em>)的解之一；能够重现我们观察到的现象。这确实是我们在这个例子中遇到的情况:重现的解与观测值几乎相同，但我们发现了一个完全不同的N(<em class="kz">x</em>；<em class="kz"> w </em>对比<em class="kz"> X </em> ( <em class="kz"> u </em>)。</p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nw"><img src="../Images/a1a451112c8938e0f6670bf353d23fd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MmI2fPXuTte3IpMUiDS1cQ.png"/></div></div></figure><h2 id="d64d" class="mg jx hi bd jy mh mi mj kc mk ml mm kg iq mn mo kk iu mp mq ko iy mr ms ks mt bi translated">随机反问题</h2><p id="be6a" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">最后一类反问题叫做<strong class="ih hj">随机反问题</strong>。在这个问题中，<em class="kz"> X </em>是一个分布未知的随机变量。因此，解<em class="kz"> u </em>也将是一个随机变量。例如，我们在实践中可能有以下设置</p><ul class=""><li id="1ebe" class="la lb hi ih b ii ij im in iq lc iu ld iy le jc nx lg lh li bi translated"><em class="kz"> u </em> (0.5)的测量可能不准确。我们可以假设<em class="kz">u</em>(0.5)∞N(<em class="kz">u0</em>(0.5)，<em class="kz"> σ </em> 2)其中<em class="kz"> u0 </em> (0.5)是一个观察值，<em class="kz"> σ </em>是测量值的规定标准偏差。因此，我们想要估计<em class="kz"> X </em>的分布，这将产生与<em class="kz"> u </em> (0.5)相同的分布。这类问题属于<strong class="ih hj">不确定性量化</strong>的范畴。</li><li id="bb8b" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc nx lg lh li bi translated">数量<em class="kz"> X </em>本身在本质上是随机的，但是它的分布可能是正/负偏斜的(例如，股票价格回报)。我们可以测量几个<em class="kz"> u </em> (0.5)的样本，想根据样本估计<em class="kz"> X </em>的分布。这个问题也被称为<strong class="ih hj">概率逆问题</strong>。</li></ul><p id="e265" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们不能像往常一样简单地最小化<em class="kz"> u </em> (0.5)和<code class="du nh ni nj nk b">u</code>(为随机变量)之间的距离；相反，我们需要一个度量来衡量两个分布之间的差异——<code class="du nh ni nj nk b">u</code>和<em class="kz"> u </em> (0.5)。可观测量<em class="kz"> u </em> (0.5)可以以多种形式给出</p><ul class=""><li id="73ff" class="la lb hi ih b ii ij im in iq lc iu ld iy le jc nx lg lh li bi translated">概率密度函数。</li><li id="613e" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc nx lg lh li bi translated">非标准化对数似然函数。</li><li id="c3f3" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc nx lg lh li bi translated">离散样本。</li></ul><p id="69e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本教程中，我们考虑第三种类型。其思想是用神经网络为<em class="kz"> X </em>构建一个采样器，并通过最小化实际观察到的样本和产生的样本之间的差异来找到最佳权重和偏差。我们是这样训练神经网络的:</p><p id="ff09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们首先提出一个候选神经网络，它将来自N(0，<em class="kz"> I </em>的样本转换为来自<em class="kz"> X </em>的样本。然后我们从N(0，<em class="kz"> I </em>)中随机生成<em class="kz"> K </em>个样本{ <em class="kz"> z(i) </em> }，<em class="kz"> i </em> =1，…，<em class="kz"> K </em>并转换为{<em class="kz">X(I)</em>；<em class="kz"> w </em> }，<em class="kz"> i </em> =1，… , <em class="kz"> K </em>。我们求解泊松方程K <em class="kz"> K </em>次得到{<em class="kz">u</em>(0.5；<em class="kz"> z(i) </em>，<em class="kz"> w </em> )}，<em class="kz"> i </em> =1，…, <em class="kz"> K </em>。同时，我们从观测值中抽样<em class="kz"> K </em>项(例如，用bootstrap方法){ <em class="kz"> ui </em> (0.5)}，<em class="kz"> i </em> =1，…, <em class="kz"> K </em>。我们可以使用概率度量<em class="kz"> D </em>来度量{<em class="kz">u</em>(0.5；<em class="kz"> z(i) </em>，<em class="kz"> w </em> )}和{ <em class="kz"> ui </em> (0.5)}，<em class="kz"> i </em> =1，…, <em class="kz"> K </em>。<em class="kz"> D </em>有很多选择，比如(方法可能会重叠)</p><ul class=""><li id="0fa4" class="la lb hi ih b ii ij im in iq lc iu ld iy le jc nx lg lh li bi translated">瓦瑟斯坦距离(从最优运输)</li><li id="8e86" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc nx lg lh li bi translated">KL-divergence，JS-divergence等。</li><li id="ef72" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc nx lg lh li bi translated">鉴别器神经网络(来自生成对抗网络)</li></ul><p id="d48f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，我们可以考虑第一种方法，并调用ADCME提供的<code class="du nh ni nj nk b"><a class="ae nl" href="https://kailaix.github.io/ADCME.jl/dev/inverse_impl/@ref" rel="noopener ugc nofollow" target="_blank">sinkhorn</a></code></p><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ny"><img src="../Images/ea2671389b9910def6fc62feca3aabda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouj0p1YIj6I-ZU8oWrl3Ew.png"/></div></div></figure><figure class="lp lq lr ls fd lt er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es nz"><img src="../Images/1d78b1a7e0067e4da0531df37803cd46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RqWp-zeBLy-oSjmkTfHTLQ.png"/></div></div></figure><h1 id="20d0" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">结论</h1><p id="a789" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">我们介绍了四种类型的逆向建模问题，其中机器学习和科学计算的结合可能是有益的。将这两个领域的精华结合起来，有望解决科学和工程中许多长期存在的挑战性问题</p><ul class=""><li id="cf07" class="la lb hi ih b ii ij im in iq lc iu ld iy le jc nx lg lh li bi translated">科学计算界在过去几十年中开发的数值格式，用于模拟由偏微分方程描述的物理过程，具有收敛、稳定和高效等特点。</li><li id="8ce4" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc nx lg lh li bi translated">机器学习擅长从数据中“学习”，特别是神经网络是一个非常强大的通用逼近器。</li></ul><p id="56d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想了解更多基于物理的机器学习背后的技术工具，下面的页面是一个很好的起点</p><div class="jd je ez fb jf jg"><a href="https://kailaix.github.io/ADCME.jl/dev/inverse_modeling/" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hj fi z dy jl ea eb jm ed ef hh bi translated">逆向建模</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">逆向建模(IM)确定了一组参数或函数，利用这些参数或函数，正演模型的输出…</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">kailaix.github.io</p></div></div><div class="jp l"><div class="oa l jr js jt jp ju jv jg"/></div></div></a></div><p id="bab9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，如果你对基于物理的机器学习在现实世界问题中的应用感兴趣，这里的<a class="ae nl" href="https://github.com/kailaix/ADCME.jl#research-work" rel="noopener ugc nofollow" target="_blank"/>是可能应用的列表。</p></div></div>    
</body>
</html>