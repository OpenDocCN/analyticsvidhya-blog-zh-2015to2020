<html>
<head>
<title>Apache Spark — Fast and Furious.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阿帕奇火花——速度与激情。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/apache-spark-fast-and-furious-2f9e34f4601b?source=collection_archive---------12-----------------------#2020-06-24">https://medium.com/analytics-vidhya/apache-spark-fast-and-furious-2f9e34f4601b?source=collection_archive---------12-----------------------#2020-06-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="268d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jk" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>是一个数据处理框架，可以在非常大的数据集上快速执行处理任务，也可以将数据处理任务分布在多台计算机上，既可以单独使用，也可以与其他分布式计算工具协同使用。这两个品质是大数据和机器学习世界的关键，这需要汇集巨大的计算能力来处理大型数据存储。Spark还通过一个易于使用的API减轻了开发人员的编程负担，该API抽象出了分布式计算和大数据处理的大量繁重工作。</p><p id="09f1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">要以最大功率运行spark作业，正确配置和调优它们非常重要。单一的公共配置或风格可能不适合所有的用例，所以首先理解一个用例，然后基于这个用例配置spark作业是非常重要的。</p><p id="e952" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">本文将关注Apache spark推荐的常见配置，以及有助于决定这些配置的因素。我们还将介绍如何以更有效的方式编写/编码spark作业，以提高速度并优化内存利用率。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="7f0d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当您编写Apache Spark代码并浏览公共API时，您会遇到像<em class="jl">转换</em>、<em class="jl">动作</em>和<em class="jl"> RDD </em>这样的词。在这个层面上理解Spark对于编写Spark程序至关重要。类似地，当事情开始失败时，或者当你冒险进入web UI试图理解为什么你的应用程序需要这么长时间时，你会遇到一个新的词汇，比如<em class="jl"> job </em>、<em class="jl"> stage </em>和<em class="jl"> task </em>。在这个层次上理解Spark对于编写好的Spark程序是至关重要的，当然这里所说的好，我指的是快。要编写一个能够高效执行的Spark程序，理解Spark的底层执行模型是非常非常有帮助的。</p><p id="ac26" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在我们开始之前，让我们了解一些重要的spark术语</p><ol class=""><li id="822b" class="jm jn hi io b ip iq it iu ix jo jb jp jf jq jj jr js jt ju bi translated">SPARK CONTEXT  : SparkContext是spark core的主要入口。它允许我们访问spark的更多功能。这有助于建立到spark执行环境的连接。它提供了对spark集群的访问，甚至可以使用资源管理器。Sparkcontext充当spark应用程序的主人。它提供了各种功能，如:获取spark应用程序的当前状态、取消作业、取消阶段、同步运行作业、异步运行作业等。</li><li id="2df3" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated"><strong class="io hj"> SPARK应用程序</strong>:即使没有作业运行，SPARK应用程序也可以代表它运行进程。它是一个独立的计算，运行用户提供的代码来计算结果。</li><li id="4232" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated"><strong class="io hj"> TASK </strong>:是一个工作单元，我们发送给执行者。每个阶段都有一些任务，每个分区一个任务。</li><li id="481e" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated">任务:并行处理由多个任务组成的计算。</li><li id="c229" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated"><strong class="io hj">阶段</strong>:每项工作都被划分成小的任务集，这些任务集被称为阶段。</li><li id="a870" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated"><strong class="io hj">动作</strong>:动作用于将结果保存到某个位置或显示结果。</li><li id="f849" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated"><strong class="io hj"> RDD </strong>:弹性分布式数据集(RDD)是Spark的基础数据结构。它是一个不可变的分布式对象集合。</li></ol><blockquote class="ka kb kc"><p id="341f" class="im in jl io b ip iq ir is it iu iv iw kd iy iz ja ke jc jd je kf jg jh ji jj hb bi translated">RDD(<strong class="io hj"><em class="hi"/></strong>)是不可变的分布式对象集合。<strong class="io hj"><em class="hi">【RDD】</em></strong><em class="hi">是一个</em> <code class="du kg kh ki kj b"><em class="hi">dataset</em></code> <em class="hi">的逻辑引用，它跨集群中的多个服务器机器进行分区。</em><strong class="io hj"><em class="hi"/></strong><em class="hi">RDD是不可变的，并且在失败的情况下可以自我恢复。RDD可以来自任何数据源，例如文本文件、通过JDBC的数据库等。</em></p><p id="02f7" class="im in jl io b ip iq ir is it iu iv iw kd iy iz ja ke jc jd je kf jg jh ji jj hb bi translated"><strong class="io hj">分区</strong> : RDD是各种数据的集合，如果它不能放入单个节点，它应该被分区到各个节点。也就是说，分区数量越多，并行性越强。RDD的这些分区分布在网络中的所有节点上。</p><p id="f330" class="im in jl io b ip iq ir is it iu iv iw kd iy iz ja ke jc jd je kf jg jh ji jj hb bi translated"><strong class="io hj">转换</strong>:转换是在RDD上创建一个或多个新rdd的懒惰操作，例如<code class="du kg kh ki kj b">map</code>、<code class="du kg kh ki kj b">filter</code>、<code class="du kg kh ki kj b">reduceByKey</code>、<code class="du kg kh ki kj b">join</code>、<code class="du kg kh ki kj b">cogroup</code>、<code class="du kg kh ki kj b">randomSplit</code></p><p id="08f7" class="im in jl io b ip iq ir is it iu iv iw kd iy iz ja ke jc jd je kf jg jh ji jj hb bi translated">在高层次上，有两种变换可以应用于RDDs，即<strong class="io hj">窄变换和宽变换</strong>。宽变换基本上导致阶段边界。</p></blockquote><p id="662f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">窄转换</strong> —不需要数据在分区间混洗。例如，地图、过滤器等..</p><p id="b3bc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">宽转换</strong> —要求数据被混洗，例如，reduceByKey等..</p><p id="316a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">通过应用转换，您可以用最终RDD的所有父RDD逐步构建一个<a class="ae jk" href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-lineage.html" rel="noopener ugc nofollow" target="_blank"> RDD谱系</a>。转换是惰性的，即不会立即执行。只有在调用一个动作后，才会执行转换。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="de64" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">了解用户提交spark作业时会发生什么</h1><p id="a6b1" class="pw-post-body-paragraph im in hi io b ip li ir is it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj hb bi translated">当作业进入时，驱动程序将代码转换成逻辑有向无环图(DAG)。之后，驱动程序执行某些优化，如流水线转换。此外，它将DAG转换成具有一组阶段的物理执行计划。同时，它在每个阶段下创建称为任务的小执行单元。然后，它收集所有任务并将其发送到集群。</p><p id="db94" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">驱动程序与集群管理器对话并协商资源。在此之后，集群管理器代表驱动程序启动执行器。此时，基于数据，放置驱动器将任务发送到集群管理器。执行者在开始执行之前向驱动程序注册自己。这样司机就能看到所有执行者的全貌。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div class="er es ln"><img src="../Images/2fb7f2a4e539003060c449a0efee8c4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*mJvex41LvRFIZ1Y7cGLtpQ.jpeg"/></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">Spark作业执行的内部机制</figcaption></figure><p id="23a8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，Executors执行驱动程序分配的所有任务。同时，应用程序正在运行，驱动程序监控运行的执行器。在spark体系结构中，驱动程序计划未来的任务。通过基于数据放置跟踪缓存数据的位置来完成所有任务。当它调用sparkcontext的stop方法时，它终止所有的执行器。之后，它从集群管理器中释放资源。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="aa45" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">调整和调试Spark应用程序</h1><p id="6b48" class="pw-post-body-paragraph im in hi io b ip li ir is it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj hb bi translated">Spark的设计使得默认设置在许多情况下“开箱即用”;但是，仍有一些配置用户可能想要修改。配置对于调整应用程序的性能也很有用。Spark的用户界面、工具和日志机制在您进行性能调优或故障排除时也很有用。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div class="er es lz"><img src="../Images/32d6bb6aa8c91ec5660b056f25b5efa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*UE94_HBU_2FIumYoqgUbQg.jpeg"/></div></figure></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="dcd8" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">执行的组成部分:工作、任务和阶段</h1><p id="c2ce" class="pw-post-body-paragraph im in hi io b ip li ir is it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj hb bi translated">作为调优和调试Spark的基础步骤，有必要更深入地了解系统的内部设计。通过将多个操作合并到任务中，Spark在执行时将逻辑表示转化为物理执行计划。虽然理解Spark执行的每个方面超出了本文的范围，但是理解相关的术语和更深入地理解所涉及的步骤在调优和调试作业时是很有帮助的。</p><p id="9921" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了演示Spark的执行阶段，我们将遍历一个示例应用程序，看看用户代码如何编译到一个较低级别的执行计划。我们将考虑的应用程序是Spark shell中的一个简单的日志分析。对于输入数据，我们将使用一个文本文件，其中包含不同严重程度的日志消息，以及一些穿插的空行。</p><p id="3b25" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">基于Spark的执行，我们将举例说明一个示例应用程序，其中用户代码组装到一个较低级别的执行计划。这里我们以Spark shell中一个简单的日志分析应用为例。一个由严重程度不确定的日志消息组成的文本文件，以及一些交错的空行将被视为输入数据。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div class="er es ma"><img src="../Images/f10abbad1029d4c55c5345cc0523e360.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*WcbcqZwmNPtQ4Pz8PUivxA.jpeg"/></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">示例输入文件— input.txt</figcaption></figure><p id="36c5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">需要在Spark shell中打开该文件，并计算每个严重级别出现多少条日志消息。让我们创造几个RDD来更好地回答这个问题。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mb"><img src="../Images/514cd646d43370265635e89f13edd709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aBLYGqBUlAXBTYQOu8ANIA.jpeg"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">火花应用代码</figcaption></figure><p id="f04a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">RDD是一系列命令和计数的结果，包括每个严重级别的日志条目数量。在shell中执行这些行后，程序不会导致任何动作。它间接定义了RDD对象的有向无环图(DAG)。一旦动作发生，这将在以后使用。</p><p id="e116" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">维护指向一个或多个父节点的指针以及定义它们之间关系的元数据是RDD的特征。以这个例子为例，当您在RDD上调用<strong class="io hj"> val b = a.map() </strong>时，RDD b会保留一个对其父节点a的引用。这些指针对于RDD追溯到其祖先是必不可少的。</p><blockquote class="ka kb kc"><p id="55e8" class="im in jl io b ip iq ir is it iu iv iw kd iy iz ja ke jc jd je kf jg jh ji jj hb bi translated">为了显示RDD的血统，Spark提供了一个toDebugString()方法。</p></blockquote><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mg"><img src="../Images/b59c2e49fe5c739533a56bfe8a66fac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OlUJJQtrEBRcAzalJhoWLg.jpeg"/></div></div></figure><p id="1a33" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在第一张图中，我们可以看到输入RDD。这个RDD是通过调用sc.textFile()创建的。ancestory让我们了解了sc.textFile()的基本功能，因为它揭示了哪些rdd是在textFile()函数中创建的。它创建一个HadoopRDD，然后对其执行映射以创建返回的RDD。伯爵的祖先故事更加扭曲。这个特殊的RDD有几个祖先，因为在输入RDD之上执行了其他操作，如附加地图、过滤和简化。</p><p id="c4fb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">此处显示的计数谱系也以图形方式显示在下图的左侧。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mh"><img src="../Images/6ce680eca7a69fef57b4648fd5e16a2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VRnj5Zs2H865ug60lxZruA.jpeg"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">图— 1</figcaption></figure><p id="fb08" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在执行一个动作之前，这些rdd只存储将帮助我们以后计算它们的元数据。在计数RDD上调用一个动作并收集()它到驱动程序激活计算。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mi"><img src="../Images/552342d8f049ea18662d606a8bedc9f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b8kDOO_xIh0WuHU650vNKA.jpeg"/></div></div></figure><p id="a164" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Spark的调度程序创建一个物理执行计划，以确定执行动作所需的rdd。在这部分中，当我们在RDD上调用collect()时，RDD的每一个分部都必须生成，然后转移到驱动程序中。调度器从最终确定的RDD开始(在这种情况下，计数)，并向后工作以找到它必须计算的内容。它调用RDD的父母，其父母的父母，并继续，循环地形成计算所有祖先rdd所需的物理计划。在简单的情况下，调度器为该图中的每个RDD输出一个计算阶段，其中该阶段为该RDD中的每个分部具有特定的任务。然后，反向执行这些阶段，以计算最终所需的RDD。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="d1ab" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">流水线操作和谱系截断</h1><p id="1faa" class="pw-post-body-paragraph im in hi io b ip li ir is it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj hb bi translated">在复杂的情况下，阶段的物理集合与RDD图不是严格的1:1对应关系。<strong class="io hj">流水线</strong>，或者由调度器执行的将多个rdd折叠成单个阶段是造成这种情况的原因。</p><blockquote class="ka kb kc"><p id="ff6a" class="im in jl io b ip iq ir is it iu iv iw kd iy iz ja ke jc jd je kf jg jh ji jj hb bi translated">当rdd可以在不移动数据的情况下从其父级计算出来时，就会出现流水线操作。</p></blockquote><p id="e1ff" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在物理执行的时候，RDD现有的与他们的父辈处于同一水平的腔将被流水线化。让我们考虑这个例子——在计算计数时，尽管有大量的父rdd，但只显示了两个级别的缩进。这表明物理执行将只需要两个阶段。这种情况下的流水线操作是因为顺序有几个过滤和映射操作。上面图-1的右半部分显示了计算RDD计数所需的两个执行阶段。</p><p id="7f22" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果一个现有的RDD已经保存在集群内存或磁盘上，Spark的内部调度程序可能会随流水线一起截断祖先史。在这种情况下，Spark可以“短路”,并基于持久的RDD开始计算。在另一种情况下，当RDD作为早期洗牌的副作用已经形成时，即使它没有被显式地持续，截断也可能发生。这是一种底层优化，它利用了Spark shuffle输出被写入磁盘的事实，并利用了RDD图的许多部分被重新计算的事实。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mj"><img src="../Images/148d7e80d22cfc5f5b5af3926efee443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEShTeBRcCc8BLwzXO8PHg.jpeg"/></div></div></figure><p id="a135" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一项工作可以被定义为一个特定的行动产生的一组阶段。一个工作的创建是由一个或多个阶段组成的，每次我们非法的行动，如计数。一旦设置并定义了阶段图，任务就会形成并发送到内部时间表，该时间表会根据使用的部署模式而变化。它们将按照特定的顺序执行，因为根据RDD的历史，物理计划中的各个阶段相互依赖。例如，输出混洗数据的阶段必须出现在依赖于该数据存在的阶段之前。物理阶段将启动任务，每个任务做相同的事情，但针对特定的数据部分。每个任务在内部执行相同的步骤:1 .从数据存储(如果RDD是输入RDD)、现有的RDD(如果舞台基于已缓存的数据)或随机输出中获取其输入。2.执行计算它所代表的RDD所必需的操作。例如，对输入数据执行filter()或map()函数，或者执行分组或归约。3.将输出写入shuffle、外部存储或写回驱动程序(如果它是count()等操作的最终RDD)。</p><p id="3471" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Spark中的大多数日志记录和插装都是用阶段、任务和洗牌来表示的。理解用户代码如何编译成物理执行是一个高级的概念，但它将极大地帮助您调优和调试应用程序。</p><p id="18ce" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">总而言之，在火花执行期间发生以下阶段:</p><p id="1b1d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">1.用户代码定义了rdd的DAG(有向无环图)。对rdd的操作创建了新的rdd，这些rdd引用回它们的父rdd，从而创建了图。</p><p id="b064" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.操作强制将DAG转换为执行计划。当您在RDD上调用操作时，必须对其进行计算。这也需要计算它的父rdd。Spark的调度程序提交一个任务来计算所有需要的rdd。该作业将有一个或多个阶段，这些阶段是由任务组成的并行计算波。每个阶段将对应于DAG中的一个或多个rdd。由于流水线操作，单个阶段可以对应于多个rdd。</p><p id="2961" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">3.任务在群集上调度和执行，阶段按顺序处理，单个任务启动以计算RDD的各个部分。一旦工作的最后一个阶段完成，动作就完成了。在给定的Spark应用程序中，随着新rdd的创建，整个步骤序列可能会以连续的方式发生多次。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="c4a0" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">从Spark UI中获得洞察力</h1><p id="ed7f" class="pw-post-body-paragraph im in hi io b ip li ir is it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj hb bi translated">Spark的内置web UI是了解Spark应用程序的本质、行为和性能的基础。默认情况下，在端口4040上运行驱动程序的机器上，这是可用的。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mk"><img src="../Images/68153dd6b7517195bdc75f3e720a3925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f9I8CdhPtbpYV86Be2sEjQ.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">Spark UI</figcaption></figure><p id="84fb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">此页面通常用于评估职务的绩效。查看构成一个作业的各个阶段，并确定在同一作业的多次运行中，这些阶段的响应时间是否很慢或波动很大。要了解该阶段与什么用户代码相关联，您可以点击进入，特别是如果您有一个昂贵的阶段。一旦感兴趣的阶段被缩小，如图2所示，它可以帮助隔离或突出性能问题。Spark是性能问题的一个常见来源，它在数据并行系统中是不对称的，当任务比其他任务花费更长时间时就会发生。要识别不对称，stage页面可以通过查看不同指标在所有任务上的分布来提供帮助。任务的运行时间——如果一些任务比其他任务长，这是一个好的开始。找出少数任务是否比其他任务读取或写入更多的数据，或者在某些节点上运行的任务是否非常慢——这些可以被认为是调试作业的有用的第一步。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es ml"><img src="../Images/d9aaf6f8e845afa6bc31e33deaf635a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uyxy2MOMN8k2fGuyyqqJww.jpeg"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">图2</figcaption></figure><p id="495d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">除了查看任务偏差之外，确定任务在任务生命周期的各个阶段投入的时间是很有帮助的，例如阅读、计算和写作。如果任务花费很少的时间来读取或写入数据，用户代码可能被认为是昂贵的，但是它总体上花费了很长时间。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="78ba" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">最佳性能的关键考虑因素</h1><p id="ea2a" class="pw-post-body-paragraph im in hi io b ip li ir is it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj hb bi translated">为了提高性能以及优化Spark运行的集群和环境，您可以进行代码级的更改。</p><p id="16d4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">并行级别(代码级)</strong>:一个RDD在逻辑上由一个对象集合表示。它为存储在一个部门中的数据创建一个任务，默认情况下，当spark调度或运行任务时，该任务将需要一个内核来执行。Spark将根据自己的想法推断出rdd的良好并行度，对于大多数用例来说，这已经足够了。基于底层存储系统，输入rdd通常选择并行性。考虑这个例子，HDFS输入rdd对于底层HDFS文件的每个部分都有一个分部。rdd中的并行度设置基于父rdd的大小(当它们是通过洗牌其他rdd得到的时)。并行性的数量可能会从两个方面影响性能。如果并行性太强，资源可能会闲置。如果您为一个应用分配了1，000个内核，并且正在运行30个任务，那么通过利用更多内核，您可能能够提高并行度。如果有太多的并行性，与每个部门相关的小开销会累积起来，变得很大。当您的任务在几毫秒内完成，或者它们既不读也不写数据时，就表明了这一点。</p><p id="017f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Spark提供了两种方法来调整操作的并行度。首先，在混洗数据的操作过程中，您可以始终将生成的RDD的并行度作为参数给出。第二，任何现存的RDD都可以被重新分配成更多或更少的分区。</p><blockquote class="ka kb kc"><p id="7941" class="im in jl io b ip iq ir is it iu iv iw kd iy iz ja ke jc jd je kf jg jh ji jj hb bi translated"><strong class="io hj">coalesce()vs re partition()<br/></strong>re partition()操作符会将一个RDD随机洗牌到所需数量的分区中。如果知道正在收缩RDD，可以使用coalesce()运算符；这比repartition()更有效，因为它避免了洗牌操作。</p></blockquote><p id="7db1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">序列化格式(代码级)</strong>:当使用Spark在网络上传输数据或将数据溢出到磁盘时，需要将对象按顺序合并成二进制格式。这种情况发生在随机操作期间，此时会传输大量数据。Spark将默认使用Java的内置序列化器。它还支持使用Kyro，这是一个第三方序列化库，改进了Java的序列化，提供了更快的序列化时间，具有更机敏和更紧凑的二进制表示，但它不能序列化“开箱即用”的对象。Kyro方便了所有转移到它的应用程序进行序列化。如果您计划序列化，则需要向Kyro注册类。它允许Kyro避免为单个对象编写完整的类名，这是一种空间节省，可以增加数千或数百万的序列化记录。如果想强制这种类型的注册，可以将<strong class="io hj">spark . kryo . registration required</strong>设置为<strong class="io hj"> true </strong>，Kryo遇到未注册的类就会抛出错误。</p><blockquote class="ka kb kc"><p id="95f7" class="im in jl io b ip iq ir is it iu iv iw kd iy iz ja ke jc jd je kf jg jh ji jj hb bi translated">无论是使用Kryo还是Java的序列化程序，如果您的代码引用的类没有扩展Java的可序列化接口，您可能会遇到NotSerializableException。在这种情况下，很难找出是哪个类导致了这个问题，因为可以从用户代码中引用许多不同的类。许多JVM支持一个特殊的选项来帮助调试这种情况:“<strong class="io hj">-dsun . io . serialization . extended debug info = true</strong>”。您可以使用<strong class="io hj"> — driver-java-options </strong>和<strong class="io hj"> — executor-java-options </strong>标志来启用此选项</p></blockquote><p id="fc86" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">内存管理(代码级)</strong>:内存被Spark以不同的方式使用，所以如果你想优化你的应用，理解和调整Spark的内存使用是很重要的。在每个执行器内部，内存用于不同的目的，即RDD存储。当您在RDD上调用persist或cache时，它的分部将存储在内存缓冲区中。当缓存到JVM总堆的一定数量时，Spark storage memory Fraction 将限制使用的内存量。当超过此限制时，旧的分部将从内存中删除。<strong class="io hj">混洗和聚合缓冲器- </strong>在执行混洗操作时，Spark将在创建输出混洗数据时创建即时缓冲器。聚合的中间结果与将作为混洗的一部分直接输出的缓冲数据一起存储在这些缓冲区中。在混洗相关缓冲器中使用的存储器总量将受到火花到火花混洗存储器部分的限制。任何用户代码都是由用户代码Spark执行的，所以用户函数本身就需要大量的内存。例如，如果用户应用程序分配了大型数组或其他对象，这些对象将会争用全部内存。</p><blockquote class="ka kb kc"><p id="5ae3" class="im in jl io b ip iq ir is it iu iv iw kd iy iz ja ke jc jd je kf jg jh ji jj hb bi translated">默认情况下，Spark将为RDD存储器留出<strong class="io hj"> 60%的空间，为随机存储器</strong>留出<strong class="io hj"> 20%的空间，为用户程序</strong>留出<strong class="io hj">剩余的20%空间。在某些情况下，用户可以调整这些选项以获得更好的性能。如果您的用户代码正在分配非常大的对象，那么减少存储和洗牌区域以避免耗尽内存可能是有意义的。</strong></p></blockquote><p id="1641" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">动态资源分配(硬件级)</strong> : Spark提供了一种机制，可以根据工作负载动态调整应用程序占用的资源。这意味着您的应用程序可以将不再使用的资源归还给集群，并在以后需要时再次请求它们。</p><p id="0356" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了支持动态分配，必须将群集配置为具有外部随机播放服务。这是必要的，以便在删除执行器时保留洗牌信息。Spark使用的所有集群管理器都支持外部洗牌机。</p><p id="c7a4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了在Spark standalone上配置外部洗牌机，将键<code class="du kg kh ki kj b">spark.shuffle.service.enabled</code>设置为<code class="du kg kh ki kj b">true</code>启动工作机。</p><p id="4152" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">此外，必须将<code class="du kg kh ki kj b">spark.dynamicAllocation.enabled</code>键设置为<code class="du kg kh ki kj b">true.</code>来启动火花应用程序</p><p id="bd6b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">附加配置</strong></p><ol class=""><li id="51f2" class="jm jn hi io b ip iq it iu ix jo jb jp jf jq jj jr js jt ju bi translated"><strong class="io hj">限制资源</strong>:每个应用程序可以设置集群应该分配的最小和最大资源。这是通过设置最小和最大数量的执行者。控制这些数字的配置键是<code class="du kg kh ki kj b">spark.dynamicAllocation.minExecutors</code>(默认值:零)和<code class="du kg kh ki kj b">spark.dynamicAllocation.maxExecutors</code>(默认值:无穷大)。</li><li id="eff3" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated"><strong class="io hj">资源移除</strong>:当没有任务要执行时，执行器空闲。默认情况下，60秒的空闲执行器将被删除。该值可以通过<code class="du kg kh ki kj b">spark.dynamicAllocation.executorIdleTimeout</code>键控制。</li></ol><p id="81bf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">集群设置的配置清单</strong>:关于配置spark集群配置的好读物在此—<a class="ae jk" href="https://c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/#:~:text=If%20your%20local%20machine%20has,out%20the%20OS%20Reserved%20settings." rel="noopener ugc nofollow" target="_blank">https://c2fo . io/c2fo/spark/AWS/EMR/2016/07/06/Apache-spark-config-cheat sheet/#:~:text = If % 20 your % 20 local % 20 machine % 20 has，out % 20 the % 20OS % 20 reserved % 20 settings。</a></p><p id="33ee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">总之你可以下载这个excel文件<a class="ae jk" href="https://c2fo.io/img/apache-spark-config-cheatsheet/C2FO-Spark-Config-Cheatsheet.xlsx" rel="noopener ugc nofollow" target="_blank"> config-cheatsheet.xlsx </a>。在excel中，只需更改以绿色突出显示的字段，rest就会自动计算出来。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="9cd7" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">参考文献</strong></h1><ol class=""><li id="01c4" class="jm jn hi io b ip li it lj ix mm jb mn jf mo jj jr js jt ju bi translated"><a class="ae jk" href="https://spark.apache.org/docs/latest/tuning.html" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/docs/latest/tuning.html</a></li><li id="6f9a" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated">学习火花:奥雷利的闪电般的大数据分析</li><li id="eb24" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated"><a class="ae jk" href="https://c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/#:~:text=If%20your%20local%20machine%20has,out%20the%20OS%20Reserved%20settings." rel="noopener ugc nofollow" target="_blank">https://c2fo . io/c2fo/spark/AWS/EMR/2016/07/06/Apache-spark-config-cheat sheet/#:~:text = If % 20 your % 20 local % 20 machine % 20 has，20the % 20OS % 20Reserved % 20settings。</a></li><li id="5ddc" class="jm jn hi io b ip jv it jw ix jx jb jy jf jz jj jr js jt ju bi translated"><a class="ae jk" href="https://towardsdatascience.com/how-does-facebook-tune-apache-spark-for-large-scale-workloads-3238ddda0830" rel="noopener" target="_blank">https://towards data science . com/how-does-Facebook-tune-Apache-spark-for-large-scale-workloads-3238 ddda 0830</a></li></ol></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="4451" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这些是我在阅读其他媒体文章、技术博客和我自己的工作经验时发现的一些事实。</p><p id="32b0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">希望你们觉得有帮助。</p><p id="3688" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">谢了。</p></div></div>    
</body>
</html>