<html>
<head>
<title>Cross-Validation — Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">交叉验证—简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cross-validation-introduction-faa394f229f4?source=collection_archive---------12-----------------------#2020-06-10">https://medium.com/analytics-vidhya/cross-validation-introduction-faa394f229f4?source=collection_archive---------12-----------------------#2020-06-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="4ee2" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">python中不同的验证方法及其性能比较。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/4bf60f826e590a838aabce81b5685676.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*MariDzIsZv3VYWDdk4V79w.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">约翰·麦克唐纳在<a class="ae jj" href="https://unsplash.com/s/photos/train-test?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="e0ae" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">在本文中，我们将回顾一些在机器学习模型中广泛使用的验证方法及其优缺点。我们将使用Python中的真实数据集来看它们的实际应用。</p><h2 id="243b" class="kg kh hi bd ki kj kk kl km kn ko kp kq jt kr ks kt jx ku kv kw kb kx ky kz la bi translated">一般理论</h2><p id="7829" class="pw-post-body-paragraph jk jl hi jm b jn lb ij jp jq lc im js jt ld jv jw jx le jz ka kb lf kd ke kf hb bi translated">我们为什么要分割数据集？最简单的答案是评估模型的性能，即确定模型的预测能力。</p><p id="e5ab" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">数据集通常被分成2或3部分——分别是训练/测试，或训练/有效/测试集。</p><p id="2771" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">分成三部分有两种风格:</p><p id="be2b" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">1)训练/有效/测试分割</p><p id="c7f3" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">2)使用维持集的交叉验证</p><p id="4650" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">额外的验证集有利于超参数调优。</p><p id="e396" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">在训练/测试/分割方法中，训练集用于调整超参数。我们使用训练数据在超参数值的所有组合中拟合模型。然后，使用拟合的模型，我们可以预测验证集，并使用超参数值的所有组合来评估性能。选择产生最佳结果的超参数组合。最佳性能模型取决于我们选择的评估指标——准确度、精确度和召回率。我们使用通过验证集过程获得的超参数组合来预测测试集。测试集是不可见的，并且不用于拟合模型，因此它有助于不带任何偏见地评估模型性能。</p><p id="5e6c" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">训练/有效/测试分离方法的缺点是只有一个验证集来调整参数。这种拆分方法存在很高的“几率”或“运气”风险。为了克服这个缺点，我们可以利用<strong class="jm hj">交叉验证。</strong>该方法与训练/有效/测试分割方法类似，但我们会多次重复分割步骤。有不同类型的交叉验证类型- k-fold CV，留一法(LOO)，嵌套CV等。我们来看看k倍CV。</p><h2 id="4b12" class="kg kh hi bd ki kj kk kl km kn ko kp kq jt kr ks kt jx ku kv kw kb kx ky kz la bi translated">具有维持设置的k倍CV</h2><p id="eb79" class="pw-post-body-paragraph jk jl hi jm b jn lb ij jp jq lc im js jt ld jv jw jx le jz ka kb lf kd ke kf hb bi translated">这是交叉验证的最简单形式。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lg"><img src="../Images/181cd2f426d17829c376bb88da425645.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*eseCXbkzwPJSNf-Jg5E7Ng.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">图片来源<a class="ae jj" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank">此处</a></figcaption></figure><p id="06af" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">这就是K折叠CV的工作原理</p><ul class=""><li id="7a94" class="lh li hi jm b jn jo jq jr jt lj jx lk kb ll kf lm ln lo lp bi translated">一个测试集被放在一边以供最终评估</li><li id="dff6" class="lh li hi jm b jn lq jq lr jt ls jx lt kb lu kf lm ln lo lp bi translated">对于剩余的数据，数据被分成k个折叠。然后，使用褶皱的k-1(训练数据)来训练该模型。然后，使用第k个集合(验证集合)，使用不同的超参数值执行预测，并选择给出最佳验证分数的超参数。</li><li id="3a2c" class="lh li hi jm b jn lq jq lr jt ls jx lt kb lu kf lm ln lo lp bi translated">最后，通过使用最佳超参数的测试集来评估模型。</li></ul><h1 id="890a" class="lv kh hi bd ki lw lx ly km lz ma mb kq io mc ip kt ir md is kw iu me iv kz mf bi translated">Python中的比较</h1><p id="b4bf" class="pw-post-body-paragraph jk jl hi jm b jn lb ij jp jq lc im js jt ld jv jw jx le jz ka kb lf kd ke kf hb bi translated">我们将使用来自UCI知识库的数据集。这是来自不同社区的犯罪率数据。有101个预测变量，如家庭规模、警察人数、人口等。目标是预测每100，000人的非违法犯罪总数(答案)。</p><p id="d529" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">代码和数据集可以在找到<a class="ae jj" href="https://github.com/divyar2630/Validation-methods" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="562c" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">我们将使用Lasso回归作为我们的预测模型。由于有许多变量，套索是一个伟大的工具，过滤掉不必要的功能。在所有其他因素都相同的情况下，我们将实施不同的验证方法来确定每个因素的最佳超参数。</p><p id="4eec" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">数据集中的要素:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mg"><img src="../Images/5d8bc9c4af773702d60ba564cce52958.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*DbyfXxFIYZYqnRbjsC6XIw.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">变量名的快照</figcaption></figure><p id="c792" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">我们将测试的验证方法如下:</p><p id="4f0c" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">1.训练/验证/测试分割。</p><p id="32ef" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">2.五重交叉验证。</p><p id="927e" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">3.10重交叉验证</p><p id="4d7e" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated"><strong class="jm hj">数据集分割</strong></p><p id="9c09" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">让我们做一个70%-30%的训练测试分割，并进一步将训练集分成两个相等的部分，分别用于训练集和有效集。</p><pre class="iy iz ja jb fd mh mi mj mk aw ml bi"><span id="0537" class="kg kh hi mi b fi mm mn l mo mp">X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)<br/>X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.2857, random_state = 1)</span></pre><p id="fcc3" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated"><strong class="jm hj">超参数选择</strong></p><p id="376f" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">让我们在这个练习中使用三个超参数，Alpha，最大迭代次数，容差</p><pre class="iy iz ja jb fd mh mi mj mk aw ml bi"><span id="2658" class="kg kh hi mi b fi mm mn l mo mp">alphas = np.logspace(-10,10,21) <br/>max_iters = np.arange(50,75,5) <br/>tols = np.linspace(0.0001,0.1,5)</span></pre><h2 id="92cc" class="kg kh hi bd ki kj kk kl km kn ko kp kq jt kr ks kt jx ku kv kw kb kx ky kz la bi translated">1.训练/验证/测试分割。</h2><p id="8768" class="pw-post-body-paragraph jk jl hi jm b jn lb ij jp jq lc im js jt ld jv jw jx le jz ka kb lf kd ke kf hb bi translated">我们将一步一步地查看python中发生了什么。</p><p id="2eb2" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">使用<code class="du mq mr ms mi b">itertools.product(alphas,max_iters,tols)</code>创建超参数三元组。我们已经创建了525个3个超参数的独特组合。接下来，我们将对数据进行标准化。将Lasso回归的数据标准化至关重要，这样我们就可以为所有变量提供公平的竞争环境。为此，我们使用一个<code class="du mq mr ms mi b">StandardScaler()</code>。参考sklearn <a class="ae jj" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多关于在<code class="du mq mr ms mi b">sklearn.preprocessing.</code>可用的标准定标器的详细信息。使用for循环，我们使用所有525超参数组合拟合训练数据。然后，我们预测验证集的犯罪率(y)。我们选择的评估指标是<em class="mt">均方误差。</em>我们的超参数三重奏获胜者是产生误差最少的那个。然后，我们缩放(拟合)训练+有效数据，并将缩放应用于测试数据。使用从验证集获得的最佳结果，我们拟合训练+有效数据并预测测试集的犯罪率(y)。整个过程的python代码如下:</p><pre class="iy iz ja jb fd mh mi mj mk aw ml bi"><span id="4f97" class="kg kh hi mi b fi mm mn l mo mp">hyperparameter_trio=list(itertools.product(alphas,max_iters,tols)) <br/>print("The number of trios in total: {}".format(len(hyperparameter_trio)))<br/>#scaling the data<br/>scaler=StandardScaler() # Instantiate<br/>scaler.fit(X_train)<br/>X_train=pd.DataFrame(scaler.transform(X_train))<br/>X_valid=pd.DataFrame(scaler.transform(X_valid))<br/>Validation_Scores=[]</span><span id="f44a" class="kg kh hi mi b fi mu mn l mo mp">start = datetime.now()<br/>for a in hyperparameter_trio:<br/>    lm_trainlasso=linear_model.Lasso<br/>    (alpha=a[0],max_iter=a[1],tol=a[2])<br/>    lm_trainlasso.fit(X_train,y_train)<br/>    Validation_Scores.append(metrics.mean_squared_error                                                             <br/>    (lm_trainlasso.predict( X_valid),y_valid))<br/>end = datetime.now() <br/>M1 = end - start<br/>minerror_M1 = min(Validation_Scores) <br/>besttrio_M1 = hyperparameter_trio[np.argmin(Validation_Scores)]</span><span id="6d85" class="kg kh hi mi b fi mu mn l mo mp">scaler = StandardScaler()<br/>scaler.fit(X_train_valid)<br/>X_train_valid = pd.DataFrame(scaler.transform(X_train_valid))<br/>X_test = pd.DataFrame(scaler.transform(X_test))<br/>M1_terror = metrics.mean_squared_error(lm1.predict(X_test),y_test)<br/>print("The prediction error for the test set is : {}".format(M1_terror))</span></pre><h2 id="42f7" class="kg kh hi bd ki kj kk kl km kn ko kp kq jt kr ks kt jx ku kv kw kb kx ky kz la bi translated">2.五重交叉验证。</h2><p id="88cc" class="pw-post-body-paragraph jk jl hi jm b jn lb ij jp jq lc im js jt ld jv jw jx le jz ka kb lf kd ke kf hb bi translated">我们将使用sklearn库中可用的<strong class="jm hj"> GridSearchCV </strong>包进行交叉验证。GridSearchCV将调整我们的超参数值的所有组合(搜索网格中指定的参数)。GridSearchCV执行一个<strong class="jm hj"> K折叠交叉验证</strong>，默认情况下，它执行5次折叠。估计器参数对训练数据执行<em class="mt">拟合</em>功能，对每个网格点的有效数据执行<em class="mt">变换</em>功能。我们在估计器中包含了转换，其中转换是按顺序执行的，并且每个转换都应该准备好接受<em class="mt">拟合</em>和<em class="mt">转换</em>方法。<code class="du mq mr ms mi b">param_grid</code>参数允许您指定超参数值，GridSearchCV迭代该网格中的所有值。此过程的python代码如下:</p><pre class="iy iz ja jb fd mh mi mj mk aw ml bi"><span id="81f8" class="kg kh hi mi b fi mm mn l mo mp">start = datetime.now()<br/>estimator = Pipeline([(‘scale’, StandardScaler()), (‘lasso’,Lasso())]) <br/>parameters = {‘lasso__alpha’:alphas, ‘lasso__max_iter’:max_iters, ‘lasso__tol’:tols}<br/>lm2 = GridSearchCV(estimator = estimator, param_grid = parameters, cv = 5, scoring = ‘neg_mean_squared_error’, n_jobs = -1) <br/>lm2.fit(X_train_valid, y_train_valid) <br/>end = datetime.now()<br/>M2 = end — start</span></pre><h2 id="5251" class="kg kh hi bd ki kj kk kl km kn ko kp kq jt kr ks kt jx ku kv kw kb kx ky kz la bi translated">3.10重交叉验证</h2><p id="4fef" class="pw-post-body-paragraph jk jl hi jm b jn lb ij jp jq lc im js jt ld jv jw jx le jz ka kb lf kd ke kf hb bi translated">就python实现而言，10折交叉验证方法类似于5折方法。在<code class="du mq mr ms mi b">GridSearchCV</code>中，我们将CV参数设置为10。</p><h2 id="6e1f" class="kg kh hi bd ki kj kk kl km kn ko kp kq jt kr ks kt jx ku kv kw kb kx ky kz la bi translated">根据3种不同的标准比较上述三种验证方法</h2><ol class=""><li id="b3d3" class="lh li hi jm b jn lb jq lc jt mv jx mw kb mx kf my ln lo lp bi translated">基于代码运行所花费的时间进行比较</li><li id="5247" class="lh li hi jm b jn lq jq lr jt ls jx lt kb lu kf my ln lo lp bi translated">比较超参数值</li><li id="da5e" class="lh li hi jm b jn lq jq lr jt ls jx lt kb lu kf my ln lo lp bi translated">比较选择的系数</li><li id="24eb" class="lh li hi jm b jn lq jq lr jt ls jx lt kb lu kf my ln lo lp bi translated">比较预测结果。</li></ol><p id="2983" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">获得的结果如下</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mz"><img src="../Images/ffbcddae7f1dfd9bfa91e447b12c4d29.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*GKESMW3338BZMwIgZcHW0Q.png"/></div></figure><p id="fe71" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">模型1-训练/有效/测试分割方法花费的时间最少。随着折叠次数的增加，模型花费的时间也越来越多。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es na"><img src="../Images/7fd2f2acda169d014784186a0419f5dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*QZfFzjg6s0tqXCkDotzhWA.png"/></div></figure><p id="2ad0" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">模型收敛所需的最大迭代次数是第三个模型的最大迭代次数(10倍CV)。5倍CV和10倍CV的alpha值相同</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nb"><img src="../Images/3caae6ec1a1942b963561237263f9f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*SZV72Jn21h_ikMdG0VHMkw.png"/></div></figure><p id="615e" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">10倍CV在测试集上产生的误差最小。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nc"><img src="../Images/6c0d2479e6fdb9e284ba8d2750452f4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*0K_9Ad2QsyfogXKOrLSyNA.png"/></div></figure><p id="1be1" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">上面描述了以降序排列的系数的绝对值。这些是每种认证方法的前5个系数。三个模型中的大部分系数是相似的。<code class="du mq mr ms mi b">PctForeignBorn</code>、<code class="du mq mr ms mi b">PersPerOccupHous</code>和<code class="du mq mr ms mi b">MalePctNevMarr </code>是所有三个模型的预测值的前几名。</p><p id="8ffb" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">训练/有效/测试方法缩减了一个系数。然而，CV模型缩小了以下系数。</p><pre class="iy iz ja jb fd mh mi mj mk aw ml bi"><span id="b72c" class="kg kh hi mi b fi mm mn l mo mp">Index(['population', 'racePctWhite', 'racePctAsian', 'racePctHisp',<br/>'agePct65up', 'numbUrban', 'medIncome', 'pctWWage', 'perCapInc','NumUnderPov', 'PctOccupManu', 'PersPerFam', 'PctYoungKids2Par','PctTeen2Par', 'PctWorkMomYoungKids', 'NumImmig', 'PctImmigRec8',PctRecImmig5', 'PctRecImmig10','PctNotSpeakEnglWell',<br/>'PctLargHouseFam', 'PctHousLess3BR', 'PctHousOwnOcc',       'PctVacantBoarded', 'OwnOccHiQuart', 'OwnOccQrange', 'RentMedian',<br/>'MedRent', 'NumStreet', 'PctSameHouse85'],dtype='object', name='Vars')</span><span id="1db1" class="kg kh hi mi b fi mu mn l mo mp">Total features shrinked to zero by M1: 1<br/>Total features shrinked to zero by M2: 30<br/>Total features shrinked to zero by M3: 32</span></pre><p id="3404" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">在101个预测值中，训练/有效/测试方法仅将一个特征缩减为零。5折CV模型提供了比训练/有效/测试方法更好的结果，因为它将30个特征缩减到零。最后，10折CV方法执行得甚至更好，因为它将32个无用特征缩减为零。</p></div><div class="ab cl nd ne gp nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="hb hc hd he hf"><h2 id="010a" class="kg kh hi bd ki kj kk kl km kn ko kp kq jt kr ks kt jx ku kv kw kb kx ky kz la bi translated">最后的想法</h2><p id="5910" class="pw-post-body-paragraph jk jl hi jm b jn lb ij jp jq lc im js jt ld jv jw jx le jz ka kb lf kd ke kf hb bi translated">选择哪种交叉验证方法取决于业务问题。在时间和评估指标之间经常有一个权衡。</p><p id="cdd9" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">交叉验证是一个巨大的话题。这篇文章是高水平的。概念概述</p><p id="07fc" class="pw-post-body-paragraph jk jl hi jm b jn jo ij jp jq jr im js jt ju jv jw jx jy jz ka kb kc kd ke kf hb bi translated">感谢您的阅读。我很想听听你对我的文章的想法和反馈。请在下面的评论区留下它们。</p></div></div>    
</body>
</html>