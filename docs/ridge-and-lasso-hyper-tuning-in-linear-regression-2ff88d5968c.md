# 山脊和套索:线性回归中的超参数调整

> 原文：<https://medium.com/analytics-vidhya/ridge-and-lasso-hyper-tuning-in-linear-regression-2ff88d5968c?source=collection_archive---------9----------------------->

在线性回归中，如果训练数据集完全符合模型，形成一条直线(如 y=mx ),并且形成的回归线覆盖所有点，但在测试时，预测值和实际值有很大差异。这是训练数据在线性回归模型上过度拟合的情况。

怎么才能解决呢？

这可以通过使用岭回归或套索回归来解决。

1.岭回归:

线性回归的损失函数如下所示:

![](img/6ab1b32dd9862107c1bb9579623b0f67.png)

线性回归的成本函数

其中 L 是损耗，Y-hat 是预测值，Y 是实际输出值。

这里我们想让损失函数值收敛到 0，即斜率最大。

这是模型可能面临过度拟合的时候。在岭回归中，损失函数是通过增加一个简单的方程加法来调整的，它可以降低斜率曲线的陡度。该公式如下所示:

![](img/44e2e6b6bb7facaded01055c53bbf279.png)

岭回归的成本函数

现在我们将使损失函数/成本函数的这个值收敛到 0。

这将降低斜率曲线的陡度，从而避免过度拟合的情况。

λ保持为 0 到任何正整数。让我们将 lambda 的值设为 1，并查看值或线如何变化的示例:

在线性回归中，L = 0。假设斜率值为 1.3，则山脊中的 L 将变为 L= 0 + (1.3) = 1.69。现在在线性回归中，当值收敛到 0 时，我们停止，但现在在岭中，如果值不收敛，它将继续前进，并选择不同的线，直到它收敛到 0。

对于 m1、m2 和 m3 等多个特性，方程将变成:

![](img/18cb1b6903adfb7f25d39657335e1c18.png)

多特征岭回归的代价函数

这将惩罚曲线，并选择 L 的方程最小的最佳拟合线。

2.套索回归:

Lasso 回归的损失函数/成本函数方程如下:

![](img/3364cd54acbecd6c57b85835c423bf8a.png)

Lasso 回归的成本函数

这里我们没有使用斜率的平方，而是使用斜率的大小。

它不仅用于克服线性回归的过拟合值，还用于通过以下方式进行特征选择:

假设有三个特征 m1、m2 和 m3。等式将是这样的:

![](img/07b037facab5708822afbdce27b05dc8.png)

多要素 Lasso 回归的成本函数

当我们趋向于收敛到 0 时，一些值变得非常小，这将被忽略，这意味着特征不重要，并且在输出值的预测中不太重要。

因此，通过惩罚曲线，它也有助于特征选择。

在交叉验证的帮助下，可以通过多个值来选择λ值。调整该值将有助于选择合适的 lambda 值来预测最佳拟合线。