<html>
<head>
<title>How to make a movie recommender: creating a recommender engine using Keras and TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何制作电影推荐器:使用Keras和TensorFlow创建推荐器引擎</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-make-a-movie-recommender-creating-a-recommender-engine-using-keras-and-tensorflow-a8e34c9ce48e?source=collection_archive---------5-----------------------#2020-12-12">https://medium.com/analytics-vidhya/how-to-make-a-movie-recommender-creating-a-recommender-engine-using-keras-and-tensorflow-a8e34c9ce48e?source=collection_archive---------5-----------------------#2020-12-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="eb06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将要创建的推荐引擎类型是一个协作过滤器。我们将用于模型的数据是MovieLens数据集，这是一个公共数据集，包含观众和电影的信息。这个模型的代码基于Keras的教程。这个教程的代码可以在<a class="ae jd" href="https://github.com/jdortuzar5/movie-recommender/tree/master/ai-model" rel="noopener ugc nofollow" target="_blank">这里</a>找到，整个项目的代码可以在<a class="ae jd" href="https://github.com/jdortuzar5/movie-recommender" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/dd1e81fc6c7d63781fe49b272b26a7f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*Xptsde5aIA1yN4DMtf9KTA.jpeg"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><a class="ae jd" href="https://www.kaggle.com/rounakbanik/movie-recommender-systems" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/rounakbanik/movie-recommender-systems</a></figcaption></figure><h1 id="8bfe" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">协同过滤是如何工作的</h1><p id="faf8" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">协同过滤模型背后的思想是使用来自两个来源的数据，在这种情况下是用户评论和用户观看历史，来找到具有相似品味的用户。这使用了观看相同电影的人具有相同品味的假设。</p><p id="599b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了达到这个结果，我们必须创建表示用户和电影之间关系的嵌入。一维示例的结果是一个矩阵，其中用户是行，列是电影。所以看下面这个例子，最后一排的用户应该喜欢电影《怪物史莱克》吧？</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kt"><img src="../Images/ce86db92bd2d08875ebaa71641b90d91.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*aytfH14yYRr9SHXD0Y406Q.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><a class="ae jd" href="https://developers.google.com/machine-learning/recommendation/collaborative/basics" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/recommendation/collaborative/basics</a></figcaption></figure><p id="0f58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以说，她可能不喜欢史莱克，这是基于她过去的电影历史(《黑暗骑士》和《纪念品》)，如果我们看看和我们当前的用户观看过相同电影的用户，我们会发现两个例子。也看过《黑暗骑士》的用户也看过《怪物史莱克》,所以投票推荐《怪物史莱克》,但是没有看过《怪物史莱克》的用户投票反对推荐《怪物史莱克》。这给我们留下了一个“结”，我们可以查看观看过《怪物史莱克》的用户，看看我们是否能找到与该用户的一些相似之处。因为我们不容易找到相关性，我们应该<strong class="ih hj">而不是</strong>向我们的用户推荐《怪物史莱克》。</p><p id="5765" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这或多或少是我们的机器学习模型要学习的东西，要找到用户和电影的异同。为了更深入地理解这一模式，以下是一些资料来源:</p><ul class=""><li id="fbef" class="ku kv hi ih b ii ij im in iq kw iu kx iy ky jc kz la lb lc bi translated"><a class="ae jd" href="https://developers.google.com/machine-learning/recommendation/collaborative/basics" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/recommendation/collaborative/basics</a></li><li id="02ae" class="ku kv hi ih b ii ld im le iq lf iu lg iy lh jc kz la lb lc bi translated"><a class="ae jd" href="https://www.researchgate.net/publication/200121027_Collaborative_Filtering_Recommender_Systems" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/publication/20012 10 27 _ Collaborative _ Filtering _ Recommender _ Systems</a></li><li id="b638" class="ku kv hi ih b ii ld im le iq lf iu lg iy lh jc kz la lb lc bi translated">【https://en.wikipedia.org/wiki/Collaborative_filtering T4】</li></ul><h1 id="ef9b" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">如何用TensorFlow和Keras进行协同过滤</h1><p id="ff8e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><a class="ae jd" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>是一个用于计算数学和机器学习的开源库。<a class="ae jd" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>是一个深度学习API，属于TensorFlow内部，使得定义和编写神经网络更加容易。这些库将帮助我们定义、训练和保存我们的推荐器模型。</p><p id="8b36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还将使用Pandas、Numpy和Matplolib等库进行数据转换和数据可视化。</p><p id="568d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从使用virtualenv创建一个虚拟环境开始(查看这个<a class="ae jd" href="https://help.dreamhost.com/hc/en-us/articles/115000695551-Installing-and-using-virtualenv-with-Python-3" rel="noopener ugc nofollow" target="_blank">教程</a>关于什么是以及如何使用python中的虚拟环境)。以下是该脚本的依赖项:</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="5143" class="ln jr hi lj b fi lo lp l lq lr">tensorflow<br/>pandas<br/>matplotlib</span></pre><p id="df91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">安装完依赖项后，让我们将数据加载到系统中。由于数据集是Keras API的一部分，我们可以使用以下命令直接下载。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="9b36" class="ln jr hi lj b fi lo lp l lq lr">import pandas as pd<br/>import numpy as np<br/>from zipfile import ZipFile<br/>import tensorflow as tf<br/>from tensorflow import keras<br/>from tensorflow.keras import layers<br/>from pathlib import Path<br/>import matplotlib.pyplot as plt<br/>import os<br/>import tempfile<br/>LOCAL_DIR = os.getcwd()</span><span id="49f5" class="ln jr hi lj b fi ls lp l lq lr">os.environ['CUDA_VISIBLE_DEVICES'] = '-1'<br/>movielens_data_file_url = (<br/>    "&lt;http://files.grouplens.org/datasets/movielens/ml-latest-small.zip&gt;"<br/>)<br/>movielens_zipped_file = keras.utils.get_file(<br/>    "ml-latest-small.zip", movielens_data_file_url, extract=False<br/>)<br/>keras_datasets_path = Path(movielens_zipped_file).parents[0]<br/>movielens_dir = keras_datasets_path / "ml-latest-small"<br/># Only extract the data the first time the script is run.<br/>if not movielens_dir.exists():<br/>    with ZipFile(movielens_zipped_file, "r") as zip:<br/>        # Extract files<br/>        print("Extracting all the files now...")<br/>        zip.extractall(path=keras_datasets_path)<br/>        print("Done!")</span></pre><p id="af24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这段代码会将数据集下载到您的计算机上，并将文件提取到一个目录中。现在，我们必须加载数据并进行一些更改，以生成数据集来训练模型。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="05d8" class="ln jr hi lj b fi lo lp l lq lr">ratings_file = movielens_dir / "ratings.csv"<br/>df = pd.read_csv(ratings_file)</span><span id="b9f0" class="ln jr hi lj b fi ls lp l lq lr">user_ids = df["userId"].unique().tolist()<br/>user2user_encoded = {x: i for i, x in enumerate(user_ids)}<br/>userencoded2user = {i: x for i, x in enumerate(user_ids)}<br/>movie_ids = df["movieId"].unique().tolist()<br/>movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}<br/>movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}<br/>df["user"] = df["userId"].map(user2user_encoded)<br/>df["movie"] = df["movieId"].map(movie2movie_encoded)</span><span id="4281" class="ln jr hi lj b fi ls lp l lq lr">num_users = len(user2user_encoded)<br/>num_movies = len(movie_encoded2movie)<br/>df["rating"] = df["rating"].values.astype(np.float32)<br/># min and max ratings will be used to normalize the ratings later<br/>min_rating = min(df["rating"])<br/>max_rating = max(df["rating"])</span><span id="714a" class="ln jr hi lj b fi ls lp l lq lr">print(<br/>    "Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}".format(<br/>        num_users, num_movies, min_rating, max_rating<br/>    )<br/>)</span><span id="dbf0" class="ln jr hi lj b fi ls lp l lq lr">df = df.sample(frac=1, random_state=42)</span></pre><p id="0480" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用Pandas将评级数据作为数据帧加载到计算机中。这里我们必须找到所有唯一的<code class="du lt lu lv lj b">userId</code>并给它们一个编码值。这个值将告诉我们推荐矩阵的哪一行是每个用户。然后冲洗并重复<code class="du lt lu lv lj b">movieId</code>的操作。最后，我们将取最高和最低评级，以便稍后对它们进行标准化，并打乱我们的数据。</p><p id="c58a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们创建我们的培训和评估集。我们将使用90%的可用数据进行训练，10%用于评估我们的模型。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="41e5" class="ln jr hi lj b fi lo lp l lq lr">x = df[["user", "movie"]].values<br/># Normalize the targets between 0 and 1. Makes it easy to train.<br/>y = df["rating"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values<br/># Assuming training on 90% of the data and validating on 10%.<br/>train_indices = int(0.9 * df.shape[0])<br/>x_train, x_val, y_train, y_val = (<br/>    x[:train_indices],<br/>    x[train_indices:],<br/>    y[:train_indices],<br/>    y[train_indices:],<br/>)</span></pre><p id="0330" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">处理完数据后，我们就可以用Keras创建模型了。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="be16" class="ln jr hi lj b fi lo lp l lq lr">EMBEDDING_SIZE = 32</span><span id="02d1" class="ln jr hi lj b fi ls lp l lq lr">class RecommenderNet(keras.Model):<br/>    def __init__(self, num_users, num_movies, embedding_size, **kwargs):<br/>        super(RecommenderNet, self).__init__(**kwargs)<br/>        self.num_users = num_users<br/>        self.num_movies = num_movies<br/>        self.embedding_size = embedding_size<br/>        self.user_embedding = layers.Embedding(<br/>            num_users,<br/>            embedding_size,<br/>            embeddings_initializer="he_normal",<br/>            embeddings_regularizer=keras.regularizers.l2(1e-6),<br/>            mask_zero=True<br/>        )<br/>        self.user_bias = layers.Embedding(num_users, 1)<br/>        self.movie_embedding = layers.Embedding(<br/>            num_movies,<br/>            embedding_size,<br/>            embeddings_initializer="he_normal",<br/>            embeddings_regularizer=keras.regularizers.l2(1e-6),<br/>            mask_zero=True<br/>        )<br/>        self.movie_bias = layers.Embedding(num_movies, 1)</span><span id="f6e5" class="ln jr hi lj b fi ls lp l lq lr">    def call(self, inputs):<br/>        user_vector = self.user_embedding(inputs[:, 0])<br/>        user_bias = self.user_bias(inputs[:, 0])<br/>        movie_vector = self.movie_embedding(inputs[:, 1])<br/>        movie_bias = self.movie_bias(inputs[:, 1])<br/>        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)<br/>        # Add all the components (including bias)<br/>        x = dot_user_movie + user_bias + movie_bias<br/>        # The sigmoid activation forces the rating to between 0 and 1<br/>        return tf.nn.sigmoid(x)</span></pre><p id="6fad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型由两个嵌入层定义，一个用于用户，一个用于电影。然后我们将使用用户嵌入层和电影嵌入层之间的点积。为了得到这个结果，我们添加了一个用户偏见嵌入层和一个电影偏见嵌入层。最后，我们对结果运行一个sigmoid函数，得到一个介于0和1之间的向量。</p><p id="60a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们训练和测试我们的模型。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="92d4" class="ln jr hi lj b fi lo lp l lq lr">model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)<br/>model.compile(<br/>    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)<br/>)</span><span id="bc9e" class="ln jr hi lj b fi ls lp l lq lr">history = model.fit(<br/>    x=x_train,<br/>    y=y_train,<br/>    batch_size=64,<br/>    epochs=5,<br/>    verbose=1,<br/>    validation_data=(x_val, y_val),<br/>)</span><span id="4dac" class="ln jr hi lj b fi ls lp l lq lr">model.summary()<br/>test_loss = model.evaluate(x_val, y_val)<br/>print('\\nTest Loss: {}'.format(test_loss))</span><span id="efaa" class="ln jr hi lj b fi ls lp l lq lr">print("Testing Model with 1 user")<br/>movie_df = pd.read_csv(movielens_dir / "movies.csv")<br/>user_id = "new_user"<br/>movies_watched_by_user = df.sample(5)<br/>movies_not_watched = movie_df[<br/>    ~movie_df["movieId"].isin(movies_watched_by_user.movieId.values)<br/>]["movieId"]<br/>movies_not_watched = list(<br/>    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))<br/>)<br/>movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]</span><span id="fede" class="ln jr hi lj b fi ls lp l lq lr">user_movie_array = np.hstack(<br/>    ([[0]] * len(movies_not_watched), movies_not_watched)<br/>)<br/>ratings = model.predict(user_movie_array).flatten()<br/>top_ratings_indices = ratings.argsort()[-10:][::-1]<br/>recommended_movie_ids = [<br/>    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices<br/>]</span><span id="6759" class="ln jr hi lj b fi ls lp l lq lr">print("Showing recommendations for user: {}".format(user_id))<br/>print("====" * 9)<br/>print("Movies with high ratings from user")<br/>print("----" * 8)<br/>top_movies_user = (<br/>    movies_watched_by_user.sort_values(by="rating", ascending=False)<br/>    .head(5)<br/>    .movieId.values<br/>)<br/>movie_df_rows = movie_df[movie_df["movieId"].isin(top_movies_user)]<br/>for row in movie_df_rows.itertuples():<br/>    print(row.title, ":", row.genres)</span><span id="fd7a" class="ln jr hi lj b fi ls lp l lq lr">print("----" * 8)<br/>print("Top 10 movie recommendations")<br/>print("----" * 8)<br/>recommended_movies = movie_df[movie_df["movieId"].isin(recommended_movie_ids)]<br/>for row in recommended_movies.itertuples():<br/>    print(row.title, ":", row.genres)</span><span id="8733" class="ln jr hi lj b fi ls lp l lq lr">print("==="* 9)<br/>print("Saving Model")<br/>print("==="* 9)</span></pre><p id="370d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们对我们的模型满意，我们可以保存它，这样我们就可以在我们的web应用程序中使用它。</p><h1 id="f346" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">如何保存你的TensorFlow模型</h1><p id="798c" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">由于我们使用Keras来描述我们的模型，我们只需要将它保存在我们计算机的一个文件夹中。有一件事要记住，随着更多的数据可用，我们将需要重新训练我们的模型，或者如果我们想试验新的参数。为了跟踪所有这些，我们将使用版本控制。由于我们将使用Tensorflow服务来调用我们的模型，Tensorflow服务将自动更新到最新版本。</p><pre class="jf jg jh ji fd li lj lk ll aw lm bi"><span id="dd91" class="ln jr hi lj b fi lo lp l lq lr">MODEL_DIR = tempfile.gettempdir()<br/>version = 1<br/>export_path = os.path.join(LOCAL_DIR, f"ai-model/model/{version}")</span><span id="201f" class="ln jr hi lj b fi ls lp l lq lr">print('export_path = {}\\n'.format(export_path))</span><span id="8cb1" class="ln jr hi lj b fi ls lp l lq lr">tf.keras.models.save_model(<br/>    model,<br/>    export_path,<br/>    overwrite=True,<br/>    include_optimizer=True,<br/>    save_format=None,<br/>    signatures=None,<br/>    options=None<br/>)</span></pre><h1 id="a573" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">如何让TensorFlow模型适用于web应用程序</h1><p id="b04a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">为了从我们的应用程序中提出建议，我们需要提供模型。为此，我们将使用Tensorflow服务。这是Tensorflow的扩展，允许使用HTTP请求运行我们的模型。这是使用Tensorflow服务的Docker图像完成的，我们将在教程的Docker部分对此进行讨论。</p></div></div>    
</body>
</html>