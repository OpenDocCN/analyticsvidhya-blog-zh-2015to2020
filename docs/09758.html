<html>
<head>
<title>Facial Emotion Recognition using Convolutional Bidirectional LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于卷积双向LSTM的人脸情感识别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/facial-emotion-recognition-using-convolutional-bidirectional-lstm-49d4199024f?source=collection_archive---------9-----------------------#2020-09-19">https://medium.com/analytics-vidhya/facial-emotion-recognition-using-convolutional-bidirectional-lstm-49d4199024f?source=collection_archive---------9-----------------------#2020-09-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="321b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是<a class="ae jd" rel="noopener" href="/analytics-vidhya/facial-emotion-recognition-fer-using-keras-763df7946a64">面部情感识别</a>系列中的第二部，建议先看完第一部再跳到这里。</p><p id="5eef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个故事将带你了解如何在Tensorflow-Keras中使用<strong class="ih hj">时间分布卷积</strong>和<strong class="ih hj">双向LSTM </strong>创建一个FER模型。我已经在第一部分讨论了这个主题的介绍和应用。</p><p id="3ddf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个故事分为以下几个部分:</p><ul class=""><li id="d78e" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">为什么我们需要这种方法</li><li id="859b" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">检查和操作数据</li><li id="8665" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">从头开始创建我们自己的定制FER模型</li></ul></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="0a16" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">为什么我们需要这种方法？</h1><p id="3989" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">因此，如果您已经完成了第一部分，那么您可能会问这种新方法的需求是什么？答案非常简单和直观，正如我在第1部分的结尾告诉你的那样，要将简单的基于CNN的模型应用于视频，我必须逐帧馈送视频<strong class="ih hj"/>，即<em class="lc">一次馈送一帧，并预测该帧</em>上的情绪，并对每一帧持续这样做(可能会在中间跳过4-5帧，因为这样会增加fps，但性能几乎保持不变)。</p><p id="3600" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，<em class="lc">有没有什么方法可以让我们播放一小段2-3秒的视频(一个30fps的视频60-90帧)？</em>是的，我们可以，通过<em class="lc">时间分配CNN</em>。但是，我们可以做得更多，因为就像一个句子的单词彼此共享上下文一样，视频的帧也与相邻的帧共享上下文。因此，我们的模型也可以从这些上下文中学习，为此我们可以使用<em class="lc">双向lstm</em>。</p><blockquote class="ld le lf"><p id="d712" class="if ig lc ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong>为了充分理解这个故事，你应该对python和神经网络(特别是CNN和LSTM)有一些基本的了解。</p></blockquote></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><h1 id="d093" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">检查和操作数据</h1><p id="161f" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">众所周知<em class="lc">给机器增加智能更多的是让它们通过某种算法从数据中学习，</em>，当然为此我们需要<strong class="ih hj">数据</strong>。数据是任何机器学习/深度学习项目中最重要的部分，因为毕竟我们训练的模型是它训练所依据的数据的产物。我的意思是，我们的数据越能代表真实世界，我们的模型就越能像真实世界一样，在真实世界中表现得越好。记住一件事<strong class="ih hj">“垃圾输入，垃圾输出”</strong>，如果我们训练包含大量垃圾的数据，那么在生产中我们的模型也会抛出垃圾。因此，数据是任何ML/DL任务最重要的组成部分。</p><p id="2227" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，我们也需要FER任务的数据。我们将在此基础上训练我们的模型，然后在保留的数据和实时视频流中测试它的性能。注意，这是一个<strong class="ih hj">监督学习</strong>问题，即学习的模型y是数据x的函数</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es lj"><img src="../Images/be9ded983809ef199c0a0fbfec358119.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/0*CiIFX-Bqbjd9j9vL.png"/></div></figure><p id="5d2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个任务，我将使用一个在<a class="ae jd" href="https://www.kaggle.com" rel="noopener ugc nofollow" target="_blank"> kaggle </a>非常流行的数据，称为<a class="ae jd" href="https://www.kaggle.com/gauravsharma99/ck48-5-emotions" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">【CK+48</strong></a><strong class="ih hj"/><strong class="ih hj">数据集，每个图像都是灰度的，分辨率为48x48。</strong>您也可以使用其他数据集，公开可用的数据集很少，或者您可以创建自己的数据集。</p><blockquote class="ld le lf"><p id="68dc" class="if ig lc ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">随着我们的继续，我们将获得更多关于这些数据的见解，敬请关注…</p></blockquote><p id="d70b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将尝试一些真正的python代码。首先导入所有需要的库，</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="9fb1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们检查数据，我们将检查我们拥有的情感类别的数量以及每个类别中的图像数量。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="58da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与其他类别相比，<code class="du lt lu lv lw b">sadness</code>和<code class="du lt lu lv lw b">fear</code>的图像数量非常少。</p><pre class="lk ll lm ln fd lx lw ly lz aw ma bi"><span id="7ae1" class="mb ka hi lw b fi mc md l me mf">TOP_EMOTIONS = ["happy", "surprise", "anger", "sadness", "fear"]</span></pre><p id="9a57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与第一部分中使用的数据集不同，这个<em class="lc"> CK+48数据集包含图像目录，这些目录以它们包含的情感命名。在每个目录中，我们都有特定情感类别的图像。</em></p><p id="da1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于这些数据有趣的一点是<em class="lc">原始数据包含视频剪辑</em>。但是我们使用的数据集包含了每个视频剪辑的最后3帧。因为在即将到来的模型中，我们将不会提供图像(如第1部分)，而是微小的视频剪辑，即帧的集合。因此，<em class="lc">我们需要将与每个视频剪辑相关的这3帧捆绑成一个短的3帧视频剪辑</em>(尽管这个剪辑非常短，以毫秒计，因为在一个30fps的视频中，一秒钟包含30帧)。然后，我们将这3帧视频输入到我们的模型中。</p><p id="d336" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是代码片段，它将使数据与我们即将推出的模型兼容。我将逐一解释。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="39d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们创建了一个名为<strong class="ih hj"> data </strong>的默认字典，它的关键字是情感名称，值是字典本身。这个嵌套字典的关键字是<em class="lc">视频id </em>，我们已经从中提取了最后三帧，这个嵌套字典的值是一个包含最后三帧名称的列表。看看下面的图片，你会更清楚。</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="er es mg"><img src="../Images/4c11e8c40c853e8444ecaecf021b2baa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-rWILEseIiVaNb_jOUesOQ.png"/></div></div></figure><p id="20d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还需要一些助手功能来完成工作。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="e3ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们首先迭代字典<code class="du lt lu lv lw b">data</code>的关键字，然后在每个情感类中，我们堆叠与每个视频剪辑相关的3帧。这将为我们提供如下内容:</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es ml"><img src="../Images/8ede15f336c1eb584eecab720623f443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*Ib1aGKcCYlDfLp2s2GcPcA.png"/></div></figure><p id="db0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们差不多完成了，我们需要一些堆叠和整形，如下图所示。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="43db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将数据分为训练集和验证集。我们将根据训练数据进行训练，并根据验证数据验证我们的模型。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="3911" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du lt lu lv lw b">label_emotion_mapper</code>，是原始类别标签到情感名称的映射。</p><p id="7ff0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们想象一下每一种情绪的图像。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="ab fe cl mm"><img src="../Images/153b8c116875f68e2c7daaadc6e0ef6c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*CNpMnS9tqBDG56HfJDcifQ.png"/></div></figure><h1 id="1086" class="jz ka hi bd kb kc mn ke kf kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw bi translated">创建我们自己的定制FER模型</h1><p id="70cc" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">我们首先需要归一化图像阵列，这样做是因为神经网络对非归一化数据高度敏感。我们将使用<strong class="ih hj">最小-最大归一化。</strong></p><p id="f1b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这些灰度图像，最小值=0，最大值=255，因此我们将阵列除以<strong class="ih hj"> 255 </strong>，因为，</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es ms"><img src="../Images/2e303166f881281fedbc6b7862e0a76b.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*gDY0d2CRitVOU9o1.png"/></div></figure><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="c718" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是一个<em class="lc">卷积神经网络(CNN)，我用了以下设置:</em></p><ul class=""><li id="8ec5" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated">出于通用目的，定期使用<strong class="ih hj"> <em class="lc">辍学</em> </strong>。</li><li id="07a4" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated"><strong class="ih hj"> <em class="lc"> ELU </em> </strong>被用作激活函数，因为首先它避免了<em class="lc">死亡relu问题</em>但是与LeakyRelu相比它也表现得很好，至少在这种情况下。</li><li id="860f" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated">he_normal 被用作内核初始化器，因为它适合ELU。</li><li id="d6c0" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated"><strong class="ih hj">批量归一化</strong>也用于更好的结果。</li></ul><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="1a58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将上述CNN模型进行时间分布，然后堆叠几个双向LSTMs，最后堆叠几个密集层。下面是它的功能，</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="843b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与第一部分不同，这里我只使用了一个名为<strong class="ih hj"> ReduceLROnPlateau </strong>的回调函数，用于在验证精度达到稳定状态时降低学习速度。使用32的批量大小并训练100个时期。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="3fe2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在你会看到输入形状的不同，与4维数组(在第1部分)不同，我们现在有5维数组(第5维是图像的批次)。然后我们编译这个模型。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="89b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们训练模型并记录训练表现。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="5e97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们绘制培训和验证指标，</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="ab fe cl mm"><img src="../Images/65abaf9011a46b22384eb0e64962fc0f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*CRlaEtVpAw-cbc6_FVkoNQ.png"/></div></figure><p id="9b63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">epoch的历史表明，准确率逐渐增加，在训练集和验证集上都达到了+86%的准确率。此外，每当精度达到稳定状态时，就会调用ReduceLROnPlateau。</p><blockquote class="ld le lf"><p id="f687" class="if ig lc ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong>历元指标的波动是由于我们对于如此复杂的任务只有非常少的数据。</p></blockquote><p id="4309" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在将可视化我们称之为<strong class="ih hj">的混淆矩阵</strong>，它是用于多类分类的最广泛使用的评估器之一。它让我们清楚地看到模特在所有课程上的表现。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="ab fe cl mm"><img src="../Images/78f2609742a06f051446c1564ff2d9ee.png" data-original-src="https://miro.medium.com/v2/format:webp/1*7VWOQzSVulbXVA4oLm-gMA.png"/></div></figure><blockquote class="ld le lf"><p id="73dc" class="if ig lc ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">如果我们有更多的数据来训练，那么我们将得到更好和更通用的模型。</p></blockquote><p id="d4df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们想象一些预测。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="lr ls l"/></div></figure><blockquote class="ld le lf"><p id="01aa" class="if ig lc ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated"><strong class="ih hj">注</strong>:此处<strong class="ih hj"> t </strong>为真实标签，<strong class="ih hj"> p </strong>为预测标签</p></blockquote><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="ab fe cl mm"><img src="../Images/56ee830918411f995978613f23ad973d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*2uRAoynQ1jl-sACvd3g8Sw.png"/></div></figure></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><p id="6aa0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来呢？我们应该就此打住吗？不，一点也不。任何模型的目的不仅仅是训练和验证它，而是在现实世界中测试/使用它。通过尝试许多不同的模型和更多的情感课程，我在这个项目上前进了很长时间。最后，我将我的模型与OpenCV整合在一起，并在视频上进行测试。</p><p id="eb22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个2分钟的演示视频，展示了我们模型的威力，在这个视频中，我使用了许多情感，也做了很酷的注释。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="mt ls l"/></div></figure><p id="b7d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://github.com/greatsharma/Facial_Emotion_Recognition" rel="noopener ugc nofollow" target="_blank">这里的</a>是托管在Github上的完整项目。</p></div><div class="ab cl js jt gp ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="hb hc hd he hf"><blockquote class="ld le lf"><p id="be78" class="if ig lc ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">你可以从<a class="ae jd" href="https://www.kaggle.com/gauravsharma99/fer-using-convolutional-bidrectional-lstm" rel="noopener ugc nofollow" target="_blank">这里</a>获得这个故事的<strong class="ih hj">整个jupyter笔记本</strong>，你只需要叉一下。同样，如果你喜欢这个笔记本，那么<strong class="ih hj">投票支持</strong>，它会激励我创造更多高质量的内容。</p></blockquote><p id="d585" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你喜欢这个故事，请鼓掌并与他人分享。</p><p id="bda1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，请阅读我的其他故事，其中包括各种主题，</p><ul class=""><li id="ae90" class="je jf hi ih b ii ij im in iq jg iu jh iy ji jc jj jk jl jm bi translated"><a class="ae jd" rel="noopener" href="/@greatsharma04/statistical-analysis-using-python-e83f10ca3c82"><strong class="ih hj">python中的统计分析</strong> </a></li><li id="1bdf" class="je jf hi ih b ii jn im jo iq jp iu jq iy jr jc jj jk jl jm bi translated"><a class="ae jd" rel="noopener" href="/analytics-vidhya/effect-of-multicollinearity-on-linear-regression-1cf7cfc5e8eb"> <strong class="ih hj">线性回归中的多重共线性</strong> </a></li></ul><p id="5fc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有<a class="ae jd" rel="noopener" href="/@greatsharma04">好多好多</a>。</p><p id="f7a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">再次感谢你阅读我的故事，我的朋友:)</p></div></div>    
</body>
</html>