# 深度神经网络的构建模块:Sigmoid 神经元

> 原文：<https://medium.com/analytics-vidhya/building-block-of-deep-neural-network-sigmoid-neuron-5fbd388757ff?source=collection_archive---------8----------------------->

在我进入这个特殊的乙状结肠神经元之前，让我们先熟悉一下神经网络，也就是说，一般来说。就把它想象成一个函数，它把输入作为各种特征，然后产生输出。所以它基本上是一个神经元网络。现在我们要集中的只是一个巨大神经元网络中的一个神经元。

我将给出第一个基本模型的概述直觉，它是 MP 神经元-麦卡洛克-皮茨神经元

![](img/c453b28952e1ad0f994cfbcdd9234bc9.png)

图:MP 神经元

从这个图中，你可以看出它只是一个接受输入(x1，x2，…)的函数。)并产生布尔输出。为了给出更多信息，请参见“f”作为一行中所有输入特征总和的函数(仅限 tnc 布尔值)以及“g”应用于“f”以基于某个阈值产生输出{0，1}。

现在感知器模型也是一种类似的模型，它只是将权重添加到输入特征中，以便完美地适应数据。

![](img/d50075ecd337ae1b064d194c8c75c2d1.png)

图:感知器模型

那为什么是重量？？？

每个参数对输出都有不同的影响，有的多，有的少，有的成正比，有的成反比。因此权重决定了哪个特征在决定输出时更有力量。从现在开始，投入是真正有价值的。所以让我们来了解一下 sigmoid 神经元，并给你一个为什么它比感知器模型更合适的场景。

# **乙状结肠神经元:-**

它也是单神经元模型，以输入为特征，不仅产生{0，1}输出，而且产生回归{ 0–1 }。So 可用于回归和分类问题(如果我们只是调整输入中的 lil)。

它是神经网络的构建模块，因为它提供了比感知器模型更平滑的曲线。sigmoid 函数提供了更平滑的 s 形曲线，而不是阶梯线。函数定义为 y = 1/(1+exp(-(σI w I x I+b))，其中 i = 1 至 n

![](img/783e40236030a5b6e7f25d40c32a48c0.png)

图:Sigmoid vs 感知器

这就是平滑曲线的样子。从曲线上我们可以看到感知器曲线有多粗糙，粗糙到某一点是“0 ”,在很小的变化下直接是“1 ”,这不是解决真实世界数据问题的方法。那么，你为什么认为阶梯线或沙罗边界不合适或没有多大用处呢？？

让我们来看看这个场景——

![](img/14fa46710fc59d512f2b70c1d3945b0b.png)

图:感知器 _ 视点

从上面的数据中我们知道一个收入 50k 的人不能买车，而收入 50k 的人可以买车，奇怪吗？？对！！这就是阶梯线的意义。

现在让我们得到更平滑的曲线。注意:Sigmoid 是一个函数族，这里我们使用的是一个逻辑函数(S 形曲线)。

![](img/783e40236030a5b6e7f25d40c32a48c0.png)

图:乙状结肠

红色曲线从“0”到“1”开始，因此对于 50k，他可能有 50%(0.5 的概率)购买汽车，而对于 50.1k，可能稍高一些(52%)。不仅仅是像感知器/MP 那样的真或假。

我会给你看三维曲线的对比，从那时起就很清楚了。

![](img/93478348bf1716438c76765787727206.png)![](img/99905c7436e35473cff2e6e8aa16580a.png)

图 3:三维可视化(Sigmoid 和感知器)

左图您可以看到不同的彩色条带，它给出了可能性的概率值，标记的点在 sigmoid 中有所不同，但在右图中，标记的点是相同的，这就是我引用的示例(50k 和 50.1k)。然而，sigmoid 也不能解决非线性问题。(单个乙状结肠不能解决它并不意味着乙状结肠的网络也不能？)

![](img/fbaa848c0d8f3b37f6419a4737f8bd0d.png)

图 5:实现 alg 的完整结构.

这是三种型号的对比表

![](img/893957526f021dca50f05b17fc8f7a2a.png)

图:对比

现在我们知道了这个模型，损失函数也是我们的平方误差(真实的——预测的)。现在，我们要采用的学习算法是梯度下降法，这意味着在数据集的每次迭代中，您需要做些什么才能使损失函数在一些迭代后减少或保持不变。我们必须改变的参数是‘w’和‘b’。

那么那些“w”和“b”是什么？它将如何影响我们的模型？

简而言之，我会给你一个想法--看“W”权重只不过是一个特定输入的力量，它决定或参与的决策比其他的多，好吧！。实际上,“w”将拟合曲线，或者使曲线的形状完美地拟合空间上的(x，y)点。“b”是一个偏差术语，假设您更改“w ”,找到了完全符合数据集的完美曲线，现在形状被确定为没有放在点上，因此“b”有助于向右/向左移动曲线，以便精确地符合点，这样损失要么是 nill，要么是一个小的 epslon(E)值。使用“b”是为了使曲线不会欠拟合或过拟合。

现在怎么选择‘w’和‘b’呢？？

这是这个模型的主要或核心..！实际上，让我们看看我们的设计方式。假设你将 w 和 b 初始化为某个值。然后，您迭代您的数据集并计算损失(现在您观察到的损失有点高)，因此您想要更改“w”和“b ”,以便计算出的新损失小于旧损失。现在你决定随机选择这些值。让我们用图表来看看它是如何变化的。

![](img/4584499c063ab3efc24abd06fd3db795.png)

图:猜猜看

![](img/1e0ffaf2e04b8a816fd0c7b63d7e8070.png)

图:继续

从上图可以看出，随着我们逐渐增加“w ”,曲线开始平滑拟合，同时损耗也开始下降，但当 w=3 时，你可以看到损耗逐渐增加，但这并不好。所以现在我们开始增加 b 的-ve 值，使曲线完美地移动并适合输入给定点。但在 b = -9 时，损失又略有增加，所以我们又减少了“w ”,继续下去，直到损失为“0”或停滞。好的，最后一条曲线给出了损失=0，那么为什么不继续进行猜测呢？？

我们可以看到损失的很多变化，有时会减少，有时会增加，这不是我们的动机。我们需要一些原则性的方法，这就是梯度下降的概念。

![](img/ffc8099cbd38d3c0c102e73da5899005.png)

图:损失可视化

蓝点是相对于输入黑点的损耗变化。显然，损失没有适当的变化。因此，我们使用梯度下降算法，以尽量减少损失。我们采取梯度步骤并测量损失，然后再次继续，直到我们获得参数‘w’和‘b’的最佳值。

![](img/12b401055925c19ff0b6f81b0abcad77.png)

图:完整的算法

所以你可以在上面看到完整的算法，其中“w”和“b”在每次迭代中更新，直到满意为止。无论我有什么概念，它都是由 GUVI 平台上的四分之一实验室激发的。米特什先生和普拉托什先生是老师。

[***https://padhai . one fourth labs . in***](https://padhai.onefourthlabs.in/)

这是我从一句谚语中获得动力后的第一篇文章，“如果你不能向别人解释它，那么你可能真的不知道它”。此外，我会尝试获得更多的直觉，并尝试把它贴在这里，以提高我对我设定的目标的认识。

谢谢(:__spreadlove__(:

[](https://padhai.onefourthlabs.in/) [## PadhAI，四分之一实验室的可负担得起的人工智能课程

### 一所负担得起的印度特定人工智能课程的在线学校为 2019 年 8 月第一批第四实验室留下了最后几个名额…

padhai.onefourthlabs.in](https://padhai.onefourthlabs.in/) 

#深度学习#机器学习