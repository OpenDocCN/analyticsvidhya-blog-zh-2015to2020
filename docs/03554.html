<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-augmentation-what-why-and-how-ae8e7161c542?source=collection_archive---------8-----------------------#2020-02-07">https://medium.com/analytics-vidhya/data-augmentation-what-why-and-how-ae8e7161c542?source=collection_archive---------8-----------------------#2020-02-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="79b6" class="hg hh hi bd hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie bi translated">数据增强:什么、为什么以及如何……？？？？？？</h2><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es if"><img src="../Images/44c725b1746326a5871737fc2e6bc988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Of5IHG3sKlnAHq0W_oOB-A.png"/></div></div></figure><h1 id="bc25" class="ir hh hi bd hj is it iu hn iv iw ix hr iy iz ja hv jb jc jd hz je jf jg id jh bi translated">什么是增强，我们为什么需要它，它有什么帮助？</h1><p id="b368" class="pw-post-body-paragraph ji jj hi jk b jl jm jn jo jp jq jr js hs jt ju jv hw jw jx jy ia jz ka kb kc hb bi translated">众所周知，<strong class="jk kd">深度神经网络</strong>在数据集的规模和种类都很大的情况下工作得最好。</p><p id="7e7f" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated"><strong class="jk kd">数据增强</strong>是一种正则化技术，像套索、铰链、L1和L2正则化，它也在任何机器学习模型训练过程中提供了很大的帮助。</p><p id="1452" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">一般来说，需要扩充来实现更大的变化深度和数据规模。在数据量不足或缺乏变化的地方，这种方法被大量使用。</p><p id="b870" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">增强计算机视觉似乎是一个急需的步骤。Kaggle上每10个计算机视觉相关内核中就有8个将此作为满足预测的步骤之一。</p><p id="1f28" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">尽管在<strong class="jk kd">自然语言处理</strong>和<strong class="jk kd">自然语言理解</strong>中，增强仍然试图赢得信任。</p><p id="05a4" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">这里有一篇来自<strong class="jk kd"> neptune.ai，</strong>的最好的文章，如果你想在自然语言处理中做同样的事情，请看看。<br/> <a class="ae kj" href="https://neptune.ai/blog/data-augmentation-nlp" rel="noopener ugc nofollow" target="_blank"> <strong class="jk kd">数据-增强-NLP </strong> </a> <strong class="jk kd">。</strong></p><p id="6dac" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">在这个故事中，我们将涵盖图像数据的数据增强方面。重点将是如何实现<strong class="jk kd">数据增强</strong>和<strong class="jk kd"> </strong>对其后果的分析。</p><p id="01f2" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">我们将使用<strong class="jk kd"> Tensorflow </strong>和<strong class="jk kd"> Keras </strong>来实现，这将帮助我们理解这个主题的各个方面。</p><p id="487b" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">更常见的情况是，当数据较少或没有多样性时，包括<strong class="jk kd">数据预处理</strong>步骤中的<strong class="jk kd">数据扩充</strong>，有助于产生大量具有良好多样性的数据。</p><p id="7d3e" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">让我们卷起袖子，打开Jupyter笔记本。</p><pre class="ig ih ii ij fd kk kl km kn aw ko bi"><span id="7efa" class="hg hh hi kl b fi kp kq l kr ks">## Bare minimum library requirement<br/>import tensorflow as tf<br/>import keras</span><span id="b8b5" class="hg hh hi kl b fi kt kq l kr ks">#Keras provide API for Augmentation helps in generation<br/>from tensorflow.keras.optimizers import RMSprop</span></pre><blockquote class="ku kv kw"><p id="5157" class="ji jj kx jk b jl ke jn jo jp kf jr js ky kg ju jv kz kh jx jy la ki ka kb kc hb bi translated">边做边学是我发现的最好的方法。因此，为了了解数据扩充，让我们处理一些真实的数据，而不是合成的数据。</p></blockquote><p id="4ec2" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi lb translated">你可以打开你的终端并粘贴下面的命令，它会在/tmp位置为你下载压缩格式。</p><p id="7448" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated"># #来自微软<br/>的猫狗数据！wget—no-check-certificate "<a class="ae kj" href="https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip" rel="noopener ugc nofollow" target="_blank">https://download . Microsoft . com/download/3/E/1/3 E1 c3f 21-ECDB-4869-8368-6 deba 77 b 919 f/kagglecatsanddogs _ 3367 a . zip</a>" \-O "/tmp/cats-and-dogs . zip "</p><p id="357d" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">成功下载数据集后，我们需要解压缩它。并将相应的数据放入训练和测试位置。我们需要以这种方式放置它，因为有了<em class="kx">Keras</em><strong class="jk kd">image generator</strong>API。</p><pre class="ig ih ii ij fd kk kl km kn aw ko bi"><span id="6e58" class="hg hh hi kl b fi kp kq l kr ks">import os<br/>import zipfile</span><span id="216c" class="hg hh hi kl b fi kt kq l kr ks">from os import path, getcwd, chdir</span><span id="8c99" class="hg hh hi kl b fi kt kq l kr ks">local_zip = "/tmp/cats-and-dogs.zip"<br/>zip_ref = zipfile.ZipFile(local_zip, 'r')<br/>zip_ref.extractall("/tmp/")<br/>zip_ref.close()</span><span id="30f0" class="hg hh hi kl b fi kt kq l kr ks">#Creating corresponding directories.<br/>try:<br/>    os.mkdir('/tmp/cats-v-dogs')<br/>    os.mkdir('/tmp/cats-v-dogs/training')<br/>    os.mkdir('/tmp/cats-v-dogs/testing')<br/>    os.mkdir('/tmp/cats-v-dogs/training/cats')<br/>    os.mkdir('/tmp/cats-v-dogs/training/dogs')<br/>    os.mkdir('/tmp/cats-v-dogs/testing/cats')<br/>    os.mkdir('/tmp/cats-v-dogs/testing/dogs')<br/>except OSError:<br/>    pass</span></pre><p id="137a" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">想象一下，我们必须给任何给定的图像分配一个类别，它是一只<strong class="jk kd">猫</strong>还是<strong class="jk kd">狗？在我们的样本数据集中，我们得到了猫和狗的图像(尽管数据并不多)。</strong></p><p id="92da" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">现在，在把这些图像交给模型进行训练之前，我们如何在飞行中玩这些图像呢？更好的<strong class="jk kd">在飞行中增强</strong>它们，生产一批张量。</p><p id="5013" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">让我们试着挑选一些图片来验证和概括它们。</p><pre class="ig ih ii ij fd kk kl km kn aw ko bi"><span id="f584" class="hg hh hi kl b fi kp kq l kr ks">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/>from matplotlib.pyplot import imread, imshow, subplots, show<br/>CAT_TRAINING_DIR = "/tmp/cats-v-dogs/training/cats/"<br/>DOG_TRAINING_DIR = "/tmp/cats-v-dogs/training/dogs/"</span><span id="cd90" class="hg hh hi kl b fi kt kq l kr ks"># Parameters for our graph; we'll output images in a 4x4 configuration<br/>nrows = 4<br/>ncols = 4</span><span id="96ce" class="hg hh hi kl b fi kt kq l kr ks"># Index for iterating over images<br/>pic_index = 0</span></pre><p id="339f" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">让我们试着画出它的网格。</p><pre class="ig ih ii ij fd kk kl km kn aw ko bi"><span id="aa8c" class="hg hh hi kl b fi kp kq l kr ks"># Set up matplotlib fig, and size it to fit 4x4 pics<br/>fig = plt.gcf()<br/>fig.set_size_inches(ncols * 4, nrows * 4)<br/>pic_index += 8</span><span id="58f5" class="hg hh hi kl b fi kt kq l kr ks">next_cat_pix = [os.path.join(CAT_TRAINING_DIR, fname) for fname in os.listdir(‘/tmp/PetImages/Cat/’)[pic_index — 8:pic_index]]<br/>next_dog_pix = [os.path.join(DOG_TRAINING_DIR, fname) for fname in os.listdir(‘/tmp/PetImages/Dog/’)[pic_index — 8:pic_index]]</span><span id="73f2" class="hg hh hi kl b fi kt kq l kr ks">for i, img_path in enumerate(next_cat_pix + next_dog_pix):<br/> # Set up subplot; subplot indices start at 1<br/> sp = plt.subplot(nrows, ncols, i + 1)<br/> sp.axis(‘Off’) # Don’t show axes (or gridlines)<br/> img = mpimg.imread(img_path)<br/> plt.imshow(img)</span><span id="60e7" class="hg hh hi kl b fi kt kq l kr ks">plt.show()</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lk"><img src="../Images/ead95bb6e15b0e181aa71f940765194f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NnqMzQrIRTYTjl1TyzVv4Q.png"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">来自训练图像群体的样本</figcaption></figure><p id="8f32" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">使用<strong class="jk kd"> Keras </strong>进行扩充给了我们另一个优势，它不会修改或影响原始数据源。</p><p id="9689" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">让我们从训练集中绘制一幅图像，然后我们将它传递到增强阶段。</p><pre class="ig ih ii ij fd kk kl km kn aw ko bi"><span id="a6c4" class="hg hh hi kl b fi kp kq l kr ks">pic_index += 8<br/>next_cat_pix = [<br/>    os.path.join(CAT_TRAINING_DIR, fname)<br/>    for fname in os.listdir('/tmp/PetImages/Cat/')[pic_index - 8:pic_index]<br/>]</span><span id="5c97" class="hg hh hi kl b fi kt kq l kr ks">image = plt.imread(next_cat_pix[0])</span><span id="0c9f" class="hg hh hi kl b fi kt kq l kr ks"># Creating a dataset which contains just one image.<br/>images = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))<br/>imshow(images[0])<br/>show()</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div class="er es lp"><img src="../Images/3dc4ee075238edaeb82f57f530c8f432.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*rub73ea5YUiAGeLX-7TzwA.png"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">来自训练图像集的随机样本图像</figcaption></figure><p id="f82c" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">是时候对该图像应用增强，并查看它如何改变空间排列，以便模型可以对同一图像具有不同的视角，并可以在接受训练的同时学习更好的特征。</p><p id="7646" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated"><strong class="jk kd">让我们生成一个UDF，这将有助于从源图像绘制各种增强图像。</strong></p><pre class="ig ih ii ij fd kk kl km kn aw ko bi"><span id="0ac1" class="hg hh hi kl b fi kp kq l kr ks">%matplotlib inline<br/><strong class="kl kd">from</strong> <strong class="kl kd">tensorflow.keras.preprocessing.image</strong> <strong class="kl kd">import</strong> ImageDataGenerator<br/><br/><strong class="kl kd">def</strong> plot(data_generator):<br/>    <em class="kx">"""</em><br/><em class="kx">    Plots 4 images generated by an object of the ImageDataGenerator     class.</em><br/><em class="kx">    """</em><br/>    data_generator.fit(images)<br/>    image_iterator = data_generator.flow(images)<br/>    <br/>    <em class="kx">#Plot the images given by the iterator</em><br/>    fig, rows = subplots(nrows=1, ncols=4, figsize=(18, 18))<br/>    <strong class="kl kd">for</strong> row <strong class="kl kd">in</strong> rows:<br/>        row.imshow(image_iterator.next()[0].astype('int'))<br/>        row.axis('off')<br/>    show()</span></pre><p id="28a7" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">现在我们所要做的就是调整一些参数，并将其输入到ImageGenerator中，然后绘制出结果。</p><pre class="ig ih ii ij fd kk kl km kn aw ko bi"><span id="24bd" class="hg hh hi kl b fi kp kq l kr ks"><strong class="kl kd">def</strong> imageAugmentor():<br/>    data_generator = ImageDataGenerator(rotation_range=180)<br/>    plot(data_generator)<br/><br/>    data_generator = ImageDataGenerator(featurewise_center=<strong class="kl kd">False</strong>,<br/>                                        width_shift_range=0.65)<br/>    plot(data_generator)<br/><br/>    data_generator = ImageDataGenerator(featurewise_center=<strong class="kl kd">False</strong>,<br/>                                        width_shift_range=0.65)<br/>    plot(data_generator)<br/><br/>    data_generator = ImageDataGenerator(vertical_flip=<strong class="kl kd">True</strong>,<br/>                                        zoom_range=[0.2, 0.9],<br/>                                        width_shift_range=0.2)<br/>    plot(data_generator)<br/><br/>    data_generator = ImageDataGenerator(horizontal_flip=<strong class="kl kd">True</strong>,<br/>                                        zoom_range=[1, 1.5],<br/>                                        width_shift_range=0.2)<br/>    plot(data_generator)<br/><br/>    data_generator = ImageDataGenerator(width_shift_range=[0.1, 0.5])<br/>    plot(data_generator)<br/><br/>    data_generator = ImageDataGenerator(zoom_range=[1, 2], rotation_range=260)<br/>    plot(data_generator)<br/></span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lq"><img src="../Images/ff2e2e6f35bc82aafb3243a1739eef90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-n5ea-d8YcVaHVacF-1xww.png"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">在同一图像上应用各种增强。</figcaption></figure><pre class="ig ih ii ij fd kk kl km kn aw ko bi"><span id="aae1" class="hg hh hi kl b fi kp kq l kr ks"><strong class="kl kd">class</strong> <strong class="kl kd">NeuralNet</strong>:<br/>    <em class="kx">'''</em><br/><em class="kx">    Responsible for Neural net skeleton</em><br/><em class="kx">    '''</em><br/>    <em class="kx">'''</em><br/><em class="kx">    Sequential design of layering to interconnect various layers.</em><br/><em class="kx">    Hawk eye view would be</em><br/><em class="kx">     _____________________________________________________</em><br/><em class="kx">    |conv--&gt;pool--&gt;--------------&gt;flatten--&gt;dense--&gt;dense|</em><br/><em class="kx">     -----------------------------------------------------</em><br/><em class="kx">    </em><br/><em class="kx">    #Basic parameters to be passed on call </em><br/><em class="kx">    #1.training_data_path</em><br/><em class="kx">    #2.validation_data_path</em><br/><em class="kx">    #3.callback</em><br/><em class="kx">    #4.epochs</em><br/><em class="kx">    #5.batch_size</em><br/><em class="kx">    #6.learning_rate</em><br/><em class="kx">    '''</em><br/>    <br/>    <strong class="kl kd">def</strong> neuralModeling(self, training_data_path, validation_data_path,<br/>                       callback, epochs, batch_size, learning_rate):<br/>        model = tf.keras.models.Sequential([<br/>            tf.keras.layers.Conv2D(16, (3, 3),<br/>                                   activation='relu',<br/>                                   input_shape=(150, 150, 3)),<br/>            tf.keras.layers.MaxPooling2D(2, 2),<br/>            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),<br/>            tf.keras.layers.MaxPooling2D(2, 2),<br/>            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),<br/>            tf.keras.layers.MaxPooling2D(2, 2),<br/>            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),<br/>            tf.keras.layers.MaxPooling2D(2, 2),<br/>            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),<br/>            tf.keras.layers.MaxPooling2D(2, 2),<br/>            tf.keras.layers.Flatten(),<br/>            tf.keras.layers.Dense(512, activation='relu'),<br/>            tf.keras.layers.Dense(1, activation='sigmoid')<br/>        ])<br/><br/>        <em class="kx">#Model compilation</em><br/>        model.compile(<br/>            optimizer=RMSprop(lr=0.001),<br/>            loss='binary_crossentropy',<br/>            metrics=['accuracy']<br/>        )<br/><br/>        <em class="kx">#model summary</em><br/>        model.summary()<br/><br/>        <em class="kx">#Make datagen for Train generator</em><br/>        train_datagen = ImageDataGenerator(rescale=1. / 255,<br/>                                          vertical_flip=True,<br/>                                        zoom_range=[0.2, 0.9],<br/>                                       width_shift_range=[0.1, 0.5],</span><span id="c69d" class="hg hh hi kl b fi kt kq l kr ks">                                            rotation_range=260)<br/><br/>        <em class="kx">#Train generator</em><br/>        train_generator = train_datagen.flow_from_directory(<br/>            training_data_path,<br/>            target_size=(150, 150),<br/>            batch_size=batch_size,<br/>            class_mode='binary')<br/>        <br/>        <em class="kx">#Make datagen for validation generator</em><br/>        validation_datagen = ImageDataGenerator(rescale=1. / 255)<br/><br/>        <em class="kx">#validation generator</em><br/>        validation_generator = validation_datagen.flow_from_directory(<br/>            validation_data_path,<br/>            target_size=(150, 150),<br/>            batch_size=batch_size,<br/>            class_mode='binary')<br/><br/>        history = model.fit(train_generator,<br/>                            validation_data=validation_generator,<br/>                            epochs=epochs,<br/>                            verbose=1<br/>                            )<br/><br/>                            <em class="kx">#callbacks=[callback]</em><br/><br/>        <strong class="kl kd">return</strong> history, model<br/><br/>    <em class="kx">'''</em><br/><em class="kx">    Constructor of the class    </em><br/><em class="kx">    '''</em><br/>    <br/>    <strong class="kl kd">def</strong> __init__(self):<br/>        print("Object getting created")</span><span id="4460" class="hg hh hi kl b fi kt kq l kr ks">net = NeuralNet()<br/>history, model = net.neuralModeling(training_data_path, validation_data_path,callback, 20, 5, 0.01)</span><span id="76bb" class="hg hh hi kl b fi kt kq l kr ks">Object getting created<br/>Model: "sequential_3"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_9 (Conv2D)            (None, 148, 148, 16)      448       <br/>_________________________________________________________________<br/>max_pooling2d_9 (MaxPooling2 (None, 74, 74, 16)        0         <br/>_________________________________________________________________<br/>conv2d_10 (Conv2D)           (None, 72, 72, 32)        4640      <br/>_________________________________________________________________<br/>max_pooling2d_10 (MaxPooling (None, 36, 36, 32)        0         <br/>_________________________________________________________________<br/>conv2d_11 (Conv2D)           (None, 34, 34, 32)        9248      <br/>_________________________________________________________________<br/>max_pooling2d_11 (MaxPooling (None, 17, 17, 32)        0         <br/>_________________________________________________________________<br/>conv2d_12 (Conv2D)           (None, 15, 15, 32)        9248      <br/>_________________________________________________________________<br/>max_pooling2d_12 (MaxPooling (None, 7, 7, 32)          0         <br/>_________________________________________________________________<br/>conv2d_13 (Conv2D)           (None, 5, 5, 32)          9248      <br/>_________________________________________________________________<br/>max_pooling2d_13 (MaxPooling (None, 2, 2, 32)          0         <br/>_________________________________________________________________<br/>flatten_3 (Flatten)          (None, 128)               0         <br/>_________________________________________________________________<br/>dense_6 (Dense)              (None, 512)               66048     <br/>_________________________________________________________________<br/>dense_7 (Dense)              (None, 1)                 513       <br/>=================================================================<br/>Total params: 99,393<br/>Trainable params: 99,393<br/>Non-trainable params: 0<br/>_________________________________________________________________<br/>Found 22499 images belonging to 2 classes.<br/>Found 2499 images belonging to 2 classes.<br/>Epoch 1/20<br/>3432/4500 [=====================&gt;........] - ETA: 18s - loss: 0.6406 - acc: 0.6213<br/>4496/4500 [============================&gt;.] - ETA: 0s - loss: 0.6241 - acc: 0.6432Epoch 1/20<br/>4500/4500 [==============================] - 85s 19ms/step - loss: 0.6239 - acc: 0.6433 - val_loss: 0.6024 - val_acc: 0.6999<br/>Epoch 2/20<br/>4499/4500 [============================&gt;.] - ETA: 0s - loss: 0.5389 - acc: 0.7474Epoch 1/20<br/>4500/4500 [==============================] - 85s 19ms/step - loss: 0.5389 - acc: 0.7475 - val_loss: 0.5006 - val_acc: 0.7735<br/>Epoch 3/20<br/>4498/4500 [============================&gt;.] - ETA: 0s - loss: 0.5226 - acc: 0.7658Epoch 1/20<br/>4500/4500 [==============================] - 84s 19ms/step - loss: 0.5228 - acc: 0.7657 - val_loss: 0.5139 - val_acc: 0.7403<br/>Epoch 4/20<br/>4499/4500 [============================&gt;.] - ETA: 0s - loss: 0.5205 - acc: 0.7711Epoch 1/20<br/>4500/4500 [==============================] - 84s 19ms/step - loss: 0.5204 - acc: 0.7711 - val_loss: 0.4538 - val_acc: 0.8067<br/>Epoch 5/20<br/>4496/4500 [============================&gt;.] - ETA: 0s - loss: 0.5139 - acc: 0.7779Epoch 1/20<br/>4500/4500 [==============================] - 85s 19ms/step - loss: 0.5139 - acc: 0.7780 - val_loss: 0.5352 - val_acc: 0.7867<br/>Epoch 6/20<br/>4497/4500 [============================&gt;.] - ETA: 0s - loss: 0.5263 - acc: 0.7843Epoch 1/20<br/>4500/4500 [==============================] - 84s 19ms/step - loss: 0.5262 - acc: 0.7844 - val_loss: 0.4560 - val_acc: 0.7915<br/>Epoch 7/20<br/>4497/4500 [============================&gt;.] - ETA: 0s - loss: 0.5337 - acc: 0.7814Epoch 1/20<br/>4500/4500 [==============================] - 84s 19ms/step - loss: 0.5337 - acc: 0.7814 - val_loss: 0.4116 - val_acc: 0.8183<br/>Epoch 8/20<br/>4497/4500 [============================&gt;.] - ETA: 0s - loss: 0.5165 - acc: 0.7843Epoch 1/20<br/>4500/4500 [==============================] - 83s 19ms/step - loss: 0.5164 - acc: 0.7844 - val_loss: 0.4559 - val_acc: 0.7959</span></pre><p id="aaab" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">根据当前的超参数和网络架构，经过多达<strong class="jk kd"> 20个历元</strong>的训练，在<strong class="jk kd"> Google Colab </strong>上的<strong class="jk kd">准确率已经达到了88.43% </strong>。</p><p id="93ec" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">如果我们尝试深入了解训练历史，我们可以了解模型训练和验证准确性，这将清楚地告诉我们每个时期的模型拟合行为。</p><pre class="ig ih ii ij fd kk kl km kn aw ko bi"><span id="9400" class="hg hh hi kl b fi kp kq l kr ks">import matplotlib.pyplot as plt<br/>acc = history.history['accuracy']<br/>val_acc = history.history['val_accuracy']</span><span id="3011" class="hg hh hi kl b fi kt kq l kr ks">epochs = range(len(acc))<br/>plt.figure(figsize=(17, 10))<br/>plt.plot(epochs, acc, 'r', label='Training accuracy')<br/>plt.plot(epochs, val_acc, 'b', label='Validation accuracy')<br/>plt.title('Training and validation accuracy')<br/>plt.xlabel('Epochs')<br/>plt.ylabel('Accuracy')<br/>plt.legend(loc=0)<br/>plt.show()</span></pre><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es lr"><img src="../Images/b806c9ed9e23ab9151202f9b803acbb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KrBw2vITAlrxTTZiGQFTIw.png"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">每个历元的训练和验证精度</figcaption></figure><p id="40e5" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">从上面的图表中，可以看出在第11和第15纪元期间发生了一些事情。大概在第11世纪，增强图像的巴赫完全来自现实。请注意，在slog时代，验证准确性显然超过了训练准确性。</p><p id="cfe8" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">让我们来看看培训和验证的损失。</p><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es ls"><img src="../Images/baa7b39bc689dbfaec88b28f90440290.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s23i5xQz9mqoJO6_8Sd-7Q.png"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">每个时期的训练和验证损失</figcaption></figure><p id="ee1f" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">查看上面的损失图，如果尝试将准确度与损失相关联，可以看到，在第11和第15个时期，损失急剧增加，在最后一个时期，验证损失高于训练损失，这清楚地表明模型倾向于过度拟合。</p><p id="8ded" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">正则化是通过惩罚权重来处理过度拟合，而增强是完全开箱即用的机制，它向数据添加了如此多的增强和噪声，以至于有时很难找到和学习精细的分级特征。</p><p id="2199" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">尽管超参数和网络定义的调整是实验性的。因此，为了提高精度并防止模型过度拟合，我们可以对超参数区域进行一些小的调整。</p><p id="f56d" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">虽然这是一个直观的方法来实现这个美丽的技术，但我希望它能为你现有的军械库增加价值。</p><p id="fd0a" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">你可以用我为这篇文章做的<a class="ae kj" href="https://github.com/sachin032/Tensorflow/blob/master/TF-Data-Augumentation.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>作为参考。</p><p id="527b" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">感谢阅读。</p><p id="a83c" class="pw-post-body-paragraph ji jj hi jk b jl ke jn jo jp kf jr js hs kg ju jv hw kh jx jy ia ki ka kb kc hb bi translated">萨钦。</p></div></div>    
</body>
</html>