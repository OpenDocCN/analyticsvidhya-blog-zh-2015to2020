<html>
<head>
<title>Building a Speaker Identification System from Scratch with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用深度学习从零开始构建说话人识别系统</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-speaker-identification-system-from-scratch-with-deep-learning-f4c4aa558a56?source=collection_archive---------0-----------------------#2018-10-02">https://medium.com/analytics-vidhya/building-a-speaker-identification-system-from-scratch-with-deep-learning-f4c4aa558a56?source=collection_archive---------0-----------------------#2018-10-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/c6c7c4079c5fb892be2541f16316359e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*BXdiezd11ERvLHTQiTxvWQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">资料来源:freepik.com</figcaption></figure><p id="9b2e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在许多分类问题中，神经网络是最先进的，特别是在图像、视频和音频等感知数据上。一个这样的分类问题是从说话者声音的音频样本中确定说话者的身份。一个能很好地实现这一点的模型有着广泛的应用，从生物认证到增强带有说话者身份的文本到语音字幕。<strong class="is hj"> </strong> <em class="jo">在这篇文章中，我将概述我如何使用在公共源原始音频数据上训练的卷积神经网络来制作概念验证的说话人识别系统。</em></p><p id="8e4c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这篇博文分为以下几个部分:</p><ul class=""><li id="4dde" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">引言:我提出了少量多次学习的问题以及为什么它对说话人识别系统是必要的，并介绍了暹罗网络，一种设计用于少量多次学习的架构。</li><li id="05fd" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">方法:关于数据集的细节，训练制度和一些调整实验。</li><li id="f99d" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">结果:最终模型的性能和它所学习的嵌入空间的可视化。</li></ul><h1 id="33b5" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h1><p id="4653" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">传统观点认为，神经网络需要大量训练数据才能达到高性能。事实上，当从零开始训练网络时，最先进的图像识别模型通常在<a class="ae lg" href="http://image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>上训练，这是一个由120万张图像组成的数据集，被精心标记为1000个类别。如果在数据收集上花费足够的努力，为许多常见的对象训练一个图像分类器肯定是可能的，但是为对象的每一个可能的变化获得1000个图像显然是不可能的。说话人识别系统也存在同样的问题——我们无法从世界上的每个人那里收集大量带标签的音频。</p><p id="1212" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">与神经网络不同，人类显然能够从很少的例子中快速学习。看过一次新动物后，你能再次认出它吗？与新同事交谈几分钟后，第二天你能辨别出他们的声音吗？与人类相比，神经网络的采样效率较低，即它们需要大量数据来实现良好的性能。开发提高学习算法的样本效率的方法是一个活跃的研究领域，已经有一些有前途的方法，包括<a class="ae lg" href="http://cs231n.github.io/transfer-learning/" rel="noopener ugc nofollow" target="_blank">迁移学习</a>和<strong class="is hj"> </strong> <a class="ae lg" rel="noopener" href="/huggingface/from-zero-to-research-an-introduction-to-meta-learning-8e16e677f78a">元学习</a> <strong class="is hj"> </strong>等等。</p><p id="6da0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些方法基于直觉，即一旦我们已经学会执行许多先前的任务/分类问题，学习新的任务/分类问题应该更容易，因为我们可以利用先前的知识。事实上，只有未经训练的神经网络具有如此荒谬的低采样效率，因为需要大量数据才能将未经训练的神经网络(它只是充满随机数的数组的集合)塑造成有用的东西。</p><p id="451f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在训练过程中，图像分类器学习有用特征的层次结构:首先是边缘和颜色检测器，然后是更复杂的形状和纹理。最后，网络深处的神经元可能与相当高级的视觉概念有对应关系(有大量的工作在探索这一点，包括<a class="ae lg" href="https://distill.pub/2017/feature-visualization/" rel="noopener ugc nofollow" target="_blank">这本</a>出色的出版物)。由于已经训练过的神经网络已经能够生成有用的、有区别的特征，因此有理由认为人们应该能够利用这一点来快速适应以前看不见的类别。</p><h2 id="3959" class="lh ke hi bd kf li lj lk kj ll lm ln kn jb lo lp kr jf lq lr kv jj ls lt kz lu bi translated">暹罗网络</h2><p id="e73c" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">这个项目依赖于连体神经网络的使用。与最常见的神经网络架构不同，这些网络采用两个独立的样本作为输入，而不是一个样本。这两个样本中的每一个都通过编码器网络从高维输入空间映射到低维空间。“暹罗”命名法来自于两个编码器网络是“双胞胎”的事实，因为它们共享相同的权重并学习相同的功能。</p><figure class="lw lx ly lz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es lv"><img src="../Images/0d5f80235e4eb134e385a9d78179ad00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V6kstNiDGG3knzsZ-DcFyw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">暹罗网络示意图。样本从高维空间映射到低维空间，即n &gt;&gt; d，然后计算它们之间的距离度量。</figcaption></figure><p id="fdf2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，这两个网络在顶部通过计算嵌入空间中两个样本之间的距离度量(例如欧几里德距离)的层连接。训练网络，使相似样本的距离小，不相似样本的距离大。我在这里对相似和不相似的定义保持开放，但通常这是基于样本是否来自标记数据集中的同一类。</p><p id="600a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，当我们训练暹罗网络时，它正在学习将样本从输入空间(在这种情况下是原始音频)映射到更容易处理的低维嵌入空间。通过包括这个距离层，我们试图直接优化嵌入的属性，而不是优化分类精度。</p><p id="9a91" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Siamese网络于1994年由Bromley等人(包括LeCun)引入，用于验证手写签名之间的匹配。然而，它们在2015年被<a class="ae lg" href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" rel="noopener ugc nofollow" target="_blank"> Koch等人</a>重新用于一次性学习，正是这篇论文启发了我的工作。</p><h2 id="eae2" class="lh ke hi bd kf li lj lk kj ll lm ln kn jb lo lp kr jf lq lr kv jj ls lt kz lu bi translated">n次学习</h2><p id="a8c9" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">快速归纳到以前未见过的类的能力通常被框定为执行<strong class="is hj"> n次学习</strong>的能力，即在只看过<em class="jo"> n次</em>(其中<em class="jo"> n </em>较小)示例后识别以前未见过的类的能力。使用<em class="jo"> n </em> -shot、<em class="jo"> k </em> -way分类任务来测量模型在少镜头学习中的性能，这些任务运行如下:</p><ol class=""><li id="9927" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn me jv jw jx bi translated">给一个模型一个属于一个新的、看不见的类的查询样本</li><li id="6dc4" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn me jv jw jx bi translated">还给出了由来自不同的不可见类的n个例子组成的支持集</li><li id="8469" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn me jv jw jx bi translated">然后，模型必须识别支持中的哪个(些)样本属于查询样本的类别</li></ol><p id="a60e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我个人认为，将这称为一个<em class="jo"> n </em>镜头分类任务有些误导，因为与分类不同，该模型不必区分所有新的和以前学习过的类别。相反，这更像是一个以前看不见的类的匹配问题。</p><figure class="lw lx ly lz fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/a42329c7c83cd297b72db78d728ea8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*yXw5D5oNs3JZ1-SUzsoxfg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">Omniglot数据集上的20路1次分类。这20个符号中的每一个都是模型看到的该类的第一个实例。转载自<a class="ae lg" href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" rel="noopener ugc nofollow" target="_blank">科赫等人</a></figcaption></figure><h2 id="a317" class="lh ke hi bd kf li lj lk kj ll lm ln kn jb lo lp kr jf lq lr kv jj ls lt kz lu bi translated">n-shot学习的连体网络</h2><p id="6c1e" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">我希望在您的脑海中形成一个想法，即如何使用嵌入空间和连体网络的成对相似性度量来执行一次性分类。该过程是通过将查询样本和所有支持集样本作为输入馈送到siamese网络来计算它们之间的成对相似性度量。然后选择具有最大相似性的支持集样本——简单！</p><figure class="lw lx ly lz fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/cddcce4624584b764afa513f53e30dfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*cGMVhv0dNZTM6gPua4uzAA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">1-镜头分类。模型的预测是与查询样本的距离(<strong class="bd kf"> d </strong> _1、<strong class="bd kf"> d </strong> _2、<strong class="bd kf"> d </strong> _3)最小的样本的类别。</figcaption></figure><p id="875c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将此扩展到<em class="jo">n</em>shot任务的一种方式是将查询样本和所有支持集样本转换成它们在嵌入空间中的表示，然后执行最近邻分类。我选择了稍微不同的方法(遵循<a class="ae lg" href="https://arxiv.org/pdf/1703.05175.pdf" rel="noopener ugc nofollow" target="_blank"> Snell等人</a>)，首先计算属于每个类的嵌入的平均位置，然后将最接近查询样本嵌入的平均嵌入作为最佳类。</p><figure class="lw lx ly lz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es mh"><img src="../Images/58baed5362997cd684379cec53b6b4e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yzq0c8tEruvTEf1UlVezSA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated"><em class="mi">n</em>-<em class="mi">n</em>= 4的镜头分类。模型的预测是其均值嵌入到查询样本的距离最小(<strong class="bd kf"> d </strong> _1，<strong class="bd kf"> d </strong> _2，<strong class="bd kf"> d </strong> _3)的类。</figcaption></figure><p id="f0cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">n-shot学习的另一种方法是使用传统分类器的倒数第二个“瓶颈”层作为嵌入空间。然而，假设是暹罗网络更适合推广到以前看不见的类。这是因为编码器子网络被训练来最小化相同类别的样本之间的距离，并且最大化嵌入空间中不同类别的样本之间的距离。</p><p id="0812" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其思想是，当我们明确地学习区分不同的、任意的类的样本，而不是识别特定的类时，学习的嵌入函数将比典型分类器的瓶颈层更好地分离先前未见过的类。稍后我会检验这个假设。</p><h1 id="f9ca" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">履行</h1><h2 id="3e5e" class="lh ke hi bd kf li lj lk kj ll lm ln kn jb lo lp kr jf lq lr kv jj ls lt kz lu bi translated">资料组</h2><p id="3de8" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">我使用<a class="ae lg" href="http://www.openslr.org/12/" rel="noopener ugc nofollow" target="_blank"> LibriSpeech </a>有声读物数据语料库来训练和评估模型。我使用<code class="du mj mk ml mm b">train-clean-100</code>和<code class="du mj mk ml mm b">train-clean-360</code>子集(~460小时，&gt; 1000名演讲者)进行培训，使用<code class="du mj mk ml mm b">dev-clean</code>子集(~10小时，40名演讲者)进行验证。此数据包含来自受控环境的音频，没有外部噪声，只有麦克风嗡嗡声等录音假象。LibriSpeech语料库是免费提供的。</p><p id="1084" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在所有实验中，我将音频从16 KHz下采样到4 KHz，以加快实验速度并减少计算量。</p><h2 id="1f96" class="lh ke hi bd kf li lj lk kj ll lm ln kn jb lo lp kr jf lq lr kv jj ls lt kz lu bi translated">模型</h2><p id="7021" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在整个工作中，我使用了一个简单的4层卷积编码器网络。架构如下</p><ul class=""><li id="a5dd" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">用大(尺寸32)过滤器进行1D卷积，然后用尺寸4和步幅4进行批量标准化和最大汇集</li><li id="c906" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">大小为3的3倍1D卷积，随后进行批量标准化和大小为2、步幅为2的最大汇集</li><li id="775e" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">全局最大池和产生嵌入的密集层</li><li id="a133" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">暹罗网络是上述网络中的两个(权重共享)通过欧氏距离图层连接在一起</li><li id="5ac2" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">最后一层是具有s形活化的致密层</li></ul><p id="4295" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">除了最后一层，我在任何地方都使用ReLu激活。我选择在第一层执行相当激进的最大池，因为样本的初始大小相当大。</p><figure class="lw lx ly lz fd ij"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="4b8a" class="lh ke hi bd kf li lj lk kj ll lm ln kn jb lo lp kr jf lq lr kv jj ls lt kz lu bi translated">培养</h2><p id="966c" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在每个实验中，我在50个“时期”(每个时期是1000个批次)中，在32个相似和32个不相似对的批次上训练一个连体网络。每对标签对于相似的对是0，对于不相似的对是1，即来自相同和不同说话者的对。</p><p id="8b0b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我使用Adam优化器，学习率为0.001。对之前未见过的说话者的持续验证集的单次分类准确度被用于确定学习率时间表——当该度量稳定了10个时期时，学习率下降了10倍。</p><p id="1d14" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">音频片段长度调谐</strong></p><p id="d93e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一个关键参数是作为模型输入的音频长度。直觉上，随着输入数据越来越丰富，人们期望模型的准确性会提高，但是代价是训练时间和内存需求的增加。</p><figure class="lw lx ly lz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es mp"><img src="../Images/1ad49935bcae77db6d78e0344f5333a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1QyCOKtbXheLnyV-V-dN9A.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">音频片段长度与验证集指标</figcaption></figure><p id="c2d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">可以看出，验证单次准确性和验证准确性都随着音频片段长度而不断增加。我选择了3秒的长度，因为在这一点之后，回报似乎在减少。</p><p id="e42e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">超参数网格搜索</strong></p><p id="db38" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我对以下超参数空间进行了网格搜索:卷积滤波器的初始数量(16，32，64，128)，嵌入维数(32，64，128，256，512)和丢弃分数(0，0.1)。使用128个滤波器，嵌入维数为64并且没有丢失，获得了最好的结果。</p><h1 id="2433" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结果</h1><p id="3a37" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">以下是最佳连体网络对<em class="jo"> 2 ≤ k ≤ 20 </em>的1发、k路和5发、k路分类任务的结果。我还在同一数据集上训练了一个分类器网络，使用与单个编码器“双胞胎”相同的架构和超参数，并在瓶颈层和分类交叉熵损失之后添加了1172路softmax。</p><figure class="lw lx ly lz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es mq"><img src="../Images/66049f208dba336fc3b2d4d7491ad83e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JgjxI-diuhpGhL1Lra6xGg.png"/></div></div></figure><p id="0a84" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有两个结果需要注意:</p><ol class=""><li id="7cd3" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn me jv jw jx bi translated">暹罗网络确实(稍微)超过了期望的一次分类中的分类器瓶颈嵌入</li><li id="17e7" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn me jv jw jx bi translated">出乎意料地，分类器瓶颈嵌入在5次分类中比具有相同超参数的暹罗网络执行得更好</li></ol><p id="01d9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意，对于更高的<em class="jo"> k </em>，分类器瓶颈嵌入和连体网络嵌入之间的5次分类性能差距更大。潜在地，这可能是因为分类器学习了更好的嵌入，用于根据它在训练时使用的标签的性质来区分许多类别。考虑当使用独热分类标签时，正确说话人的softmax分数被上推，而所有其他说话人的softmax分数被下推。</p><p id="f4c1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将这与验证任务进行比较，在验证任务中，训练将不同说话人的样本之间的嵌入距离推开，但是仅针对该批中存在的不同说话人。特别是，我预计暹罗网络将很快学会区分男性和女性的声音，而喂养异性对在以后的时代几乎不会提供任何学习，因为它们“太容易了”。解决这个问题的一种方法是执行硬负挖掘，以创建更困难的验证任务。</p><h2 id="64cf" class="lh ke hi bd kf li lj lk kj ll lm ln kn jb lo lp kr jf lq lr kv jj ls lt kz lu bi translated">嵌入空间可视化</h2><figure class="lw lx ly lz fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/d6a96dff233529fd8604eff0cf411515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*8yRlNrZTG08XvTH5PZFHTA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">圆形=男性，三角形=女性。每种颜色对应不同的说话人身份。</figcaption></figure><p id="23e0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面显示的是暹罗网络学习的嵌入空间的可视化。我从训练集中随机选择了20个说话者，并为每个人随机选择了10个音频样本。然后，我使用<a class="ae lg" href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" rel="noopener ugc nofollow" target="_blank"> tSNE </a>将代表音频样本的64维点嵌入到一个2维空间中进行绘制。请注意，说话者身份有很好的聚类(用颜色表示)，男性和女性说话者通常是分开的(用圆形或三角形标记表示)。</p><h1 id="36b8" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结束注释</h1><p id="c1e1" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在这篇文章中，我展示了利用少量学习的最新进展，建立一个概念验证的说话人识别模型是可能的。我还发现，在Librispeech数据集上的少量说话人识别中，暹罗网络并不普遍优于常规分类器。虽然我还没有达到一流的性能指标(验证集上92%的验证准确率)，但最好的模型仍然足以在低安全性应用程序中使用。在以后的文章中，我打算研究性能的改进，最终目标是生成一个可安装pip的纯python的说话人识别包。</p></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><p id="5c37" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">我的Github上有代码</em></p><p id="e5c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">【https://github.com/oscarknagg/voicemap T4】</p></div></div>    
</body>
</html>