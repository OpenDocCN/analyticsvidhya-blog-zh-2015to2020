<html>
<head>
<title>Urdu News Clustering Using Headlines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用标题的乌尔都语新闻聚类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/urdu-news-clustering-using-headlines-c45bc2b8362f?source=collection_archive---------32-----------------------#2020-04-19">https://medium.com/analytics-vidhya/urdu-news-clustering-using-headlines-c45bc2b8362f?source=collection_archive---------32-----------------------#2020-04-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/6ff9457a3e468506c37d5232ce176aa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yqiYybWOw1gszGy1"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">蒂姆·莫斯霍尔德在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="f9c6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">乌尔都语</em> </strong> <em class="jt">全世界有超过1.04亿人使用。他们中的大多数人对阅读他们感兴趣的特定新闻更感兴趣。现在，基于同样的新闻，不同的媒体呈现不同的观点。因此，将来自不同来源的类似新闻聚集在一起将会给出更好的图景。</em></p><p id="42ef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本文中，我将讨论数据处理技术和用于对来自不同来源的类似乌尔都语新闻进行聚类的<a class="ae iu" href="http://www.cle.org.pk/clt16/Presentations/Clustering%20Urdu%20News%20Using%20Headlines.pdf" rel="noopener ugc nofollow" target="_blank">方法。用于该任务的算法基于不同新闻之间的相似性分数和阈值，以将其视为聚类的一部分。该算法分两部分工作。首先，它计算相似性得分，然后将该得分与阈值进行比较</a></p><p id="81cf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以在<a class="ae iu" href="https://github.com/asadmohammad/UrduNewsClustering" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上看到最终代码。</p><h1 id="02ce" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">数据</h1><p id="7ed4" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">我使用的数据是BBC和VOA每天大约3000篇不同类别的新闻文章，如娱乐、政治、体育和杂文。</p><h1 id="273a" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">数据处理</h1><p id="5de5" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">为了给聚类算法准备标题，数据需要是干净的。处理步骤如下:</p><p id="bcc9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1.记号化:给定一个字符序列和一个已定义的文档单元，记号化就是将它分割成小块的任务，称为<strong class="ix hj">记号。</strong></p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="fa2a" class="lg jv hi lc b fi lh li l lj lk">“Word Split”<br/>def Tokenize(headline):<br/> words = []<br/> splitHeadLine = []<br/> for headline in headlines: <br/>   words = re.split(‘\W+’,headline)<br/>   splitHeadLine.append(words)<br/>   words = [“”]<br/> <br/> return splitHeadLine</span></pre><p id="6f5c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.去除停用词:<strong class="ix hj">停用词</strong>是任何语言中的一组常用词。在乌尔都语中，使用最多的词是آ、آئی、آئیں、آئے,یہ、یہاں等等。我用过的一长串停用词可以在这里找到<a class="ae iu" href="https://github.com/urduhack/urdu-stopwords" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="60a1" class="lg jv hi lc b fi lh li l lj lk">“Stop Word Removal”<br/>def removeStopwords(jumla): <br/>   emp = ‘’<br/>   WordsWithoutStopWords = []<br/>   for alfaz in jumla:<br/>      wordsWithoutoStopWords = []<br/>      for lafz in alfaz:<br/>        if lafz in stop_words or lafz == emp:<br/>          continue<br/>      wordsWithoutoStopWords.append(lafz)<br/> <br/>      WordsWithoutStopWords.append(wordsWithoutoStopWords)<br/>      del wordsWithoutoStopWords<br/> <br/> return WordsWithoutStopWords</span></pre><p id="191b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.单词规范化:文本规范化是将文本转换成规范(标准)形式的过程。比如'<em class="jt">美国'</em>到'<em class="jt">美国</em>'。为了规范化乌尔都语单词，使用了UrduHack库来执行这项任务。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="1671" class="lg jv hi lc b fi lh li l lj lk">“Normalize Words”</span><span id="00e9" class="lg jv hi lc b fi ll li l lj lk">from urduhack import normalize<br/>def NormalizeWords(word):<br/>    NormalizedWord = normalize(word)<br/>    return NormalizedWord</span></pre><p id="cd70" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们已经清理了数据。是时候实现算法了。</p><h1 id="f7bd" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">算法</h1><p id="8847" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">用于该任务的算法基于不同新闻之间的相似性分数和阈值，以将其视为聚类的一部分。该算法分两部分工作。首先，它计算相似性得分，然后将该得分与阈值进行比较。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/fd8723eccd8f450b568caccfc759ce23.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*mfj_d9PXil-kmYVFqDAcmw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">算法1.0</figcaption></figure><p id="61b5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个算法的详细解释可以看<a class="ae iu" href="http://www.cle.org.pk/clt16/Presentations/Clustering%20Urdu%20News%20Using%20Headlines.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="b491" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面代码片段的实现如下:</p><p id="d338" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该算法返回类似于给定新闻“n”的新闻列表。</p><ol class=""><li id="492c" class="ln lo hi ix b iy iz jc jd jg lp jk lq jo lr js ls lt lu lv bi translated">相关新闻功能:</li></ol><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="7849" class="lg jv hi lc b fi lh li l lj lk">“Related NEWS Function”<br/>def relatedNews(dataSet,inputNews):<br/>    relatedNewsList = []<br/>    t = 0.5<br/>    dataSetList = dataSet<br/>    ni = inputNews<br/>    sizeofDataSetList = len(dataSetList)<br/>    for j in range(0,sizeofDataSetList):<br/>        nj = dataSetList[j]<br/>        Sij = getSimilarityScore(ni,nj)<br/>        if Sij &gt;= t:<br/>            relatedNewsList.append(nj)<br/>        <br/>    return relatedNewsList</span></pre><p id="957c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.相似性得分:这个函数将计算我们上面处理过的两个标题之间的相似性。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="bd65" class="lg jv hi lc b fi lh li l lj lk">"Similarity between input document(ith) and the jth document(document in the corpus)"<br/>def getSimilarityScore(ni,nj):<br/>    tli = getTokensList(ni)<br/>    tlj = getTokensList(nj)<br/>    sti = len(tli)<br/>    stj = len(tlj)<br/>    Sij = 0<br/>    mij = 0<br/>    for x in range(0,sti):<br/>        for y in range(0,stj):<br/>            if tli[x] == tlj[y]:<br/>                mij = mij + 1<br/>    if mij &gt; 0:<br/>        avg = (sti + stj)/2<br/>        Sij = mij / avg<br/>    <br/>    return Sij</span></pre><h1 id="1254" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">聚类结果:</h1><p id="46d9" class="pw-post-body-paragraph iv iw hi ix b iy ks ja jb jc kt je jf jg ku ji jj jk kv jm jn jo kw jq jr js hb bi translated">以下是由该算法生成的聚类示例:</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/ff88cde6e3f8ea96587302f39bed03d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*7-YIKfOwSZWz3nnq3sr65Q.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">相似新闻的群集</figcaption></figure><p id="9da7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们输入news，看看这个算法生成的新闻列表。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/f4dce62fac2ce7bacc30dabb0edb740a.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*VA1qBESb28SWSRLR7ddDBg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">与输入的新闻相似的新闻列表</figcaption></figure><p id="8397" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">国家类别的精度最高，为0.84。微观平均精度为0.45，而宏观平均精度为0.48。</p><p id="726f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">展望未来</strong>我正在将它整合到我们的项目<em class="jt"> AKHBAR中，</em>这是一个乌尔都语新闻个性化门户，将通过仅使用标题和新闻内容对新闻进行聚类来显示来自所有其他乌尔都语新闻机构的新闻。</p><p id="d7e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对进一步推进这个项目有什么建议吗？我很想收到你的来信！随时和我联系<a class="ae iu" href="https://www.linkedin.com/asad-muhammad/" rel="noopener ugc nofollow" target="_blank"><em class="jt">LinkedIn</em></a><em class="jt">。</em></p><p id="70eb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">干杯。</p></div></div>    
</body>
</html>