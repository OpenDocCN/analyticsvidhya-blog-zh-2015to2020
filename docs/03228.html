<html>
<head>
<title>KNN(K_Nearest Neighbors)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">KNN(K _最近邻)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/knn-k-nearest-neighbors-1add1b5d6eb2?source=collection_archive---------10-----------------------#2020-01-21">https://medium.com/analytics-vidhya/knn-k-nearest-neighbors-1add1b5d6eb2?source=collection_archive---------10-----------------------#2020-01-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="52fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">KNN是一种受监督的机器学习算法(已标记的数据集),用于二元以及多类分类问题，尤其是在经济预测、数据压缩和遗传学领域。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/54f926c20865dd71bf21caf1ff4dce71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/0*lZuWPURwIsT_36qm.jpg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">KNN的简单类比</figcaption></figure><h2 id="be6a" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">目录:</h2><ol class=""><li id="4304" class="kk kl hi ih b ii km im kn iq ko iu kp iy kq jc kr ks kt ku bi translated">KNN的先决条件</li><li id="350f" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">直觉</li><li id="8cd1" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">KNN分类器如何工作？</li><li id="16c7" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">加权KNN</li><li id="7acd" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">偏差—方差权衡</li><li id="907b" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">时间和空间复杂性</li><li id="11c4" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">KNN概述</li></ol><h2 id="9f90" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">1.KNN的先决条件:</h2><p id="5243" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">由于KNN算法是在已知邻居的情况下完美工作的算法，因此它借助于距离矩阵(欧几里德距离、曼哈顿距离)或相似性矩阵(余弦相似性)。</p><p id="7612" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了深入和完善地了解它的工作，我们应该知道上面提到的距离或相似性矩阵是如何计算的。</p><h2 id="964a" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">2.直觉:</h2><p id="55fa" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">假设我们想要预测查询点的类别标签(下图中显示的红色星号)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ld"><img src="../Images/cafa8b9de913fa63f491ae1dc10bca63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/0*x5mnVrHr-ETrYwkf"/></div></figure><p id="5eb9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">案例一:</strong></p><p id="f9dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们认为KNN的k值是3，如上面的圆圈所示，则查询点属于B类，因为B类数据点更多地位于k(3)个邻居中</p><p id="d81a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">案例二:</strong></p><p id="45c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以与上述相同的方式，如果k的值是6(6个邻居),则认为查询点属于A类，因为k个邻居中的大多数属于A类</p><h2 id="c23f" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">3.KNN分类器如何工作？</h2><p id="58a5" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">KNN中的查询点根据所选K值(最近邻)中的多数投票被分类到其所属的类别。如前所述，从使用的距离矩阵中已知邻居，主要使用欧几里得距离，也称为L2范数。因此，尽管没有给出数据点，而是给出了相似性矩阵或距离矩阵，但我们可以使KNN工作。</p><p id="583f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">现在有趣的问题来了，我们如何选择K的正确值？？？</strong></p><p id="375c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了使KNN完美地工作，这是需要知道的最重要的事情，也就是说，如果我们直观地观察上述情况，我们可以观察到当k=3时查询点属于B类，当k=6时属于A类。那么我们怎么能说它属于一个特定的类主要取决于正确的K值。现在让我们看看如何确定k的正确值。</p><p id="2357" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基本上，我们会将数据集分为训练数据集和测试数据集，但为了确定K的正确值，我们会将数据集分为训练数据集、交叉验证数据集和测试数据集(最好分别为60%、20%、20%)。在使用训练数据集训练模型之后，我们将使用交叉验证数据集，以便使用不同的K值来测试模型，并且针对每个K值获得交叉验证准确性，并且正确的K值是具有最高准确性的值。</p><p id="af24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">KNN算法中要遵循的步骤有:</strong></p><p id="234e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1)将数据集分成训练、交叉验证和测试数据集。</p><p id="fda7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2)选择要使用的距离度量。</p><p id="e6ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3)使用训练数据集建立模型</p><p id="24ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4)使用交叉验证数据集准确性来确定K的正确值。</p><p id="1eb6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5)对于给定的查询点，计算距所有数据点的距离，并按升序对它们进行排序，并应用所获得的K值，即K个最近邻。</p><p id="d927" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6)基于其k个邻居的多数投票将查询点分配给该类。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/ae3a4ec504e6f1dad92edc00cbef5342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/0*oq9T_Rg75IF4bIW_.png"/></div></figure><h2 id="d075" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">4.加权KNN:</h2><p id="6ddc" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">这只是对我们上面讨论的KNN算法的一点更新。</p><p id="1f26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面讨论的算法中，我们基于k个最近邻居中的多数投票来标记查询点，这在某些情况下存在一个小问题。我们举个例子，了解一下问题是什么。假设k=5，并且在5个最近的邻居中，有2个A类点非常靠近查询点，比如分别相距0.1和0.2，以及3个B类点，相距0.5、0.9、1.2。</p><p id="6423" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，根据上面解释的KNN算法，查询点属于B类，因为大多数(5个中的3个)点属于B类。但是根据加权KNN，查询点属于a类。让我们深入研究它的主题，看看它是如何说查询点属于a类的</p><p id="5514" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于我们知道所有k个邻居与查询点的距离，现在我们计算权重，以便使用我们所拥有的距离来说明它属于哪个类。属于A类的权重为((1/0.1)+(1/0.2))=15，属于B类的权重为((1/0.5)+(1/0.9)+(1/1.2))=3.944。通过分别取A类和B类的距离的倒数之和来获得权重。当A类权重大于B类时，根据加权KNN，查询点属于A类。</p><p id="0af8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当K的值是偶数并且两个类数据点在最近邻中相等时，主要使用加权KNN，即，如果K=6并且A类点是3，B类点是3，则在这里使用两个类中的任何一个加权KNN而不是标记查询点，这有利于决定它所属的类。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lf"><img src="../Images/dc61ca14b156225890fc75c12f21f07a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9HWif3vbwZ6MFE-h.jpg"/></div></div></figure><h2 id="13d8" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">5.偏差—方差权衡:</h2><p id="2130" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated"><strong class="ih hj">情况一:</strong>如果K值很低。</p><p id="e946" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于K的值非常低，它可以将查询点标记为靠近它的点，只考虑小的点，因此有可能出现高方差(也称为过拟合)，在高方差中，训练误差较低，但是测试误差相对较高。</p><p id="2787" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">情况2: </strong>如果K值非常高，实际上几乎等于数据点的数量。</p><p id="9307" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于K的值非常高，它可以将查询点大部分标记为在给定数据集中占多数的类别标签。因此存在高偏差(也称为欠拟合)的可能性，在高偏差中，训练误差和测试误差都非常高。</p><p id="e3f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">案例3: </strong>如果K值不高也不低，并且使用交叉验证数据准确性正确获得，那么它是一个没有高偏差和方差的良好平衡。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lk"><img src="../Images/3ca28ee2bdf1fa796e1f58d445245c94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yCzUCs7hQL3UtB-E.png"/></div></div></figure><h2 id="54ea" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">6.时间和空间复杂性:</h2><p id="9915" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated"><strong class="ih hj">训练阶段:</strong>在训练阶段，因为我们需要存储所有的数据点。</p><p id="2f91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">空间复杂度将是O(n*d ),其中n表示数据点的数量，d表示确定每个数据点的特征的数量。</p><p id="e0d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算具有d个特征的n个数据点所需的时间将是O(n*d)。</p><p id="3854" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">测试阶段:</strong>测试阶段或运行时间复杂度为O(n*k*d)，其中k代表需要考虑的最近邻的数量。</p><h2 id="12cf" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">7.KNN概述:</h2><p id="d9c7" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">今天我们学习了KNN模型，它主要有三个步骤</p><ol class=""><li id="115a" class="kk kl hi ih b ii ij im in iq ll iu lm iy ln jc kr ks kt ku bi translated">计算距离(例如欧几里德距离、汉明距离等。)</li><li id="c617" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">查找k个最近的邻居</li><li id="ea33" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">为标签投票或计算平均值(在回归的情况下)</li></ol><p id="424b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很少有人支持和反对KNN。</p><p id="f3fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优点:</strong></p><ul class=""><li id="7746" class="kk kl hi ih b ii ij im in iq ll iu lm iy ln jc lo ks kt ku bi translated">没有关于数据分布的假设，在实际应用中有用</li><li id="d830" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lo ks kt ku bi translated">简单的算法来解释和理解</li><li id="aa35" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lo ks kt ku bi translated">它可以用于分类和回归</li></ul><p id="b2f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">缺点:</strong></p><ul class=""><li id="e162" class="kk kl hi ih b ii ij im in iq ll iu lm iy ln jc lo ks kt ku bi translated">计算量很大，因为该算法存储了所有的训练数据</li><li id="97e8" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lo ks kt ku bi translated">高内存需求，同样，它存储所有的训练数据</li><li id="3211" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc lo ks kt ku bi translated">预测阶段可能较慢(N较大)。</li></ul><p id="8651" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong>为了降低KNN的时间复杂度，做了一些小的修改，其中一些是LSH(位置敏感散列)、K '-折叠交叉验证、Kd树算法，只是为了更深入的理解而检查它们。</p><p id="fbac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">恭喜你！我们已经学习了第一个分类模型。我希望这篇文章能帮助你理解什么是K-最近邻算法，以及我们如何基于交叉验证的准确性来选择K。一如既往，我欢迎问题，笔记，建议等。享受旅程，继续学习！</p></div></div>    
</body>
</html>