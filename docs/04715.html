<html>
<head>
<title>Image-Image Translation using Pix2Pix/Conditional GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用pix 2 pix/条件GANs的图像-图像翻译</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-image-translation-using-pix2pix-conditional-gans-a23e0d78ac32?source=collection_archive---------28-----------------------#2020-03-29">https://medium.com/analytics-vidhya/image-image-translation-using-pix2pix-conditional-gans-a23e0d78ac32?source=collection_archive---------28-----------------------#2020-03-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="6ac1" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">图像-图像翻译</h1><p id="259a" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">图像-图像转换将图像转换为不同类型的图像，保持图像的所有基本细节相似。这是使用嵌入来完成的，因为来自较高维度图像的所有数据都被嵌入到仅包含图像的基本信息的较低维度空间中，之后，从该较低维度空间中重构图像，但是这一次，较高维度的基本事实发生了变化，从而产生了相似但不同风格的图像。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ki"><img src="../Images/7ed42a7d5888cb6dd4936acc4479ba18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*iXereqyzv58IcxQLJvOIFg.jpeg"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">使用pix2pix架构的图像-图像转换示例，使用facades数据集</figcaption></figure></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="5025" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">Pix2Pix的架构</h1><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ku"><img src="../Images/2297ac1a2c57348da7c28613c100b662.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*-cOl_8EgQBI64WM8tHq-UQ.jpeg"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">常见的编码器-解码器结构与Pix2Pix中使用的结构，来源:<a class="ae kv" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank">图像-图像翻译论文</a></figcaption></figure><p id="4032" class="pw-post-body-paragraph jk jl hi jm b jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh hb bi translated">Pix2Pix使用一个生成器和一个鉴别器，前者生成图像，后者识别图像是由生成器生成的还是实际数据集的一部分。鉴别器被用作发生器的损失函数，这让我们对我们的发生器有一个动态损失函数，关于GANs的更多信息，请参考<a class="ae kv" href="http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="noopener ugc nofollow" target="_blank">的原始论文</a>。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lb"><img src="../Images/ae3e9cbe551ccdbca83fa1398bd102f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*Km8nrJ99ywIjHhwVE2bJYw.jpeg"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">发生器和鉴别器如何工作，来源:<a class="ae kv" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank">图像-图像翻译论文</a></figcaption></figure></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="9597" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">如何创建自己的图像-图像翻译</h1><p id="e7f2" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">现在，我们对Pix2Pix网络中发生的事情有了一个狭隘的理解，让我们看看如何在短时间内创建我们自己的图像-图像翻译器。在这种情况下，我们将创建一个将人脸草图转换成照片的网络。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lc"><img src="../Images/56331b912935d25ba8cda00df15fcaf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*RCN2lQ8F_Ct2soy3kqHDrQ.jpeg"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">左图:人脸草图(来源:<a class="ae kv" href="http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html" rel="noopener ugc nofollow" target="_blank"> CUHK数据集</a>)，右图:从人脸生成的图像</figcaption></figure><p id="180f" class="pw-post-body-paragraph jk jl hi jm b jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh hb bi translated">创建您自己的图像翻译器的整个过程将分为三个阶段:</p><ol class=""><li id="d431" class="ld le hi jm b jn kw jr kx jv lf jz lg kd lh kh li lj lk ll bi translated">收集数据集</li><li id="3eff" class="ld le hi jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">预处理数据集</li><li id="1aed" class="ld le hi jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated">训练模型</li></ol></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="6d72" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">收集数据集</strong></h1><p id="8571" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在这种情况下，我们将需要一个包含草图和与这些草图对应的照片的数据库。有一个预先存在的数据集，其中有草图和相应的人脸图像，称为<a class="ae kv" href="http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html" rel="noopener ugc nofollow" target="_blank"> CUHK数据集</a>。我们将使用这个数据集来训练我们的网络。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="c5b2" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">预处理数据集</strong></h1><p id="2220" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">作者方便地提供的<a class="ae kv" href="https://phillipi.github.io/pix2pix/" rel="noopener ugc nofollow" target="_blank"> Pix2Pix </a>模型以照片|草图的形式接收训练输入，如下图所示。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lr"><img src="../Images/82288b756792612aaa6897a49284448f.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*IxGmxC0hwnrh-umqOZSXEg.jpeg"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">左:照片，右:草图，模型如何在Pix2Pix中获取输入。</figcaption></figure><p id="4db8" class="pw-post-body-paragraph jk jl hi jm b jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh hb bi translated">由于CUHK数据集在单独的文件夹中包含图像和草图，我们将把它们组合起来以创建我们想要的训练数据。我们将使用python中的PIL库来完成这项工作。</p><pre class="kj kk kl km fd ls lt lu lv aw lw bi"><span id="d58a" class="lx in hi lt b fi ly lz l ma mb">#Sample preprocessing of images for the CUHK Dataset. <br/>import sys<br/>from PIL import Image<br/>for i in range(100,102):<br/> if (i&lt;10):<br/> s=’0'+str(i)<br/> else:<br/> s=str(i)<br/> images = [Image.open(x) for x in [‘./photos1/m-’+s+’-01.jpg’, ‘./sketches1/m-’+s+’-01-sz1.jpg’]]<br/> widths, heights = zip(*(i.size for i in images))</span><span id="d85c" class="lx in hi lt b fi mc lz l ma mb">total_width = sum(widths)<br/> max_height = max(heights)</span><span id="b611" class="lx in hi lt b fi mc lz l ma mb">new_im = Image.new(‘RGB’, (total_width, max_height))</span><span id="ed43" class="lx in hi lt b fi mc lz l ma mb">x_offset = 0<br/> for im in images:<br/> new_im.paste(im, (x_offset,0))<br/> x_offset += im.size[0]</span><span id="45ea" class="lx in hi lt b fi mc lz l ma mb">new_im.save(‘mfmm’+s+’.jpg’)</span></pre><p id="677a" class="pw-post-body-paragraph jk jl hi jm b jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh hb bi translated">上面的代码根据训练Pix2Pix模型的需要对图像进行预处理，对于数据集中的每个图片和草图对，它将它们组合起来，并从中生成一个新图像。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="cbad" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">训练模型</h1><p id="38de" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在PyTorch上运行的<a class="ae kv" href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上有一个模型的原始实现。通过使用<a class="ae kv" href="https://colab.research.google.com/github/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab </a>上的实现，使用你自己的数据集训练模型是非常容易的。在Colab上打开笔记本后，创建datasets/sketch/train文件夹，并将预处理后的数据上传到该文件夹中。最后，在代码的训练部分，引用文件夹，而不是facades，你应该准备好了。</p><pre class="kj kk kl km fd ls lt lu lv aw lw bi"><span id="04c1" class="lx in hi lt b fi ly lz l ma mb">!python train.py — dataroot ./datasets/sketches — name sketches_pix2pix — model pix2pix — direction BtoA</span></pre><p id="6fbf" class="pw-post-body-paragraph jk jl hi jm b jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh hb bi translated">现在您已经成功实现了模型，您可以使用该模型将自己的草图转换为栩栩如生的图像！干得好！</p><p id="feb7" class="pw-post-body-paragraph jk jl hi jm b jn kw jp jq jr kx jt ju jv ky jx jy jz kz kb kc kd la kf kg kh hb bi translated">使用相同的方法，您可以为许多不同类型的图像-图像翻译训练模型。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="3193" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">参考</h1><ol class=""><li id="c83f" class="ld le hi jm b jn jo jr js jv md jz me kd mf kh li lj lk ll bi translated">基于条件对抗网络的图像-图像翻译。艾尔。</li><li id="cd5a" class="ld le hi jm b jn lm jr ln jv lo jz lp kd lq kh li lj lk ll bi translated"><a class="ae kv" href="http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html" rel="noopener ugc nofollow" target="_blank"> CUHK数据集</a></li></ol></div></div>    
</body>
</html>