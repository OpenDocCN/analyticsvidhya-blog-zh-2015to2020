<html>
<head>
<title>How to train TensorFlow models using Docker ( without CUDA ) on Linux</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Linux上使用Docker(不带CUDA)训练TensorFlow模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-train-tensorflow-models-using-docker-without-cuda-on-linux-a327323a6d81?source=collection_archive---------6-----------------------#2020-09-13">https://medium.com/analytics-vidhya/how-to-train-tensorflow-models-using-docker-without-cuda-on-linux-a327323a6d81?source=collection_archive---------6-----------------------#2020-09-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/475a5be917d2fdba1b7b8c6a8611120c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jOPOvl9CG12vXr-EVClt7g.png"/></div></div></figure><div class=""/><p id="3524" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当你开始使用GPU进行机器学习和训练神经网络时，你(和任何ML工程师)的第一个障碍是让CUDA工作并让TensorFlow识别你的GPU。</p><h1 id="2401" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">简介</strong></h1><blockquote class="km kn ko"><p id="8a1a" class="iq ir kp is b it iu iv iw ix iy iz ja kq jc jd je kr jg jh ji ks jk jl jm jn hb bi translated">CUDA是NVIDIA开发的并行计算平台和编程模型，用于图形处理单元(GPU)上的一般计算。</p><p id="49cf" class="iq ir kp is b it iu iv iw ix iy iz ja kq jc jd je kr jg jh ji ks jk jl jm jn hb bi">…</p><p id="ea13" class="iq ir kp is b it iu iv iw ix iy iz ja kq jc jd je kr jg jh ji ks jk jl jm jn hb bi translated">NVIDIA的CUDA工具包提供了开发GPU加速应用程序所需的一切。CUDA工具包包括GPU加速库、编译器、开发工具和CUDA运行时。</p><p id="b075" class="iq ir kp is b it iu iv iw ix iy iz ja kq jc jd je kr jg jh ji ks jk jl jm jn hb bi translated">(来源)【https://developer.nvidia.com/cuda-zone T2】</p></blockquote><p id="24e3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通常情况下，安装任何依赖项都需要获得最新版本，这样一切都可以正常工作。但是经验告诉我，事实从来都不是这样。</p><p id="0846" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你看，安装CUDA本身是一项棘手的任务，即使有人设法安装它，让它工作本身就是一种痛苦。至于我的情况，即使在经历了几十个GPU驱动程序版本、CUDA版本、cuDNN版本之后，我仍然无法让Tensorflow检测到我有一个GPU，而是不断地在我的CPU上训练。我花了将近一个月的时间才最终让它工作起来。所以，如果你也面临着类似的问题，或者你不想在未来遵循我的领导。你应该只需要花费大约<strong class="is hu">15-20分钟</strong>的时间来运行CUDA和你的GPU，而不是花几天时间在Nvidia论坛上。</p><h1 id="56dc" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">依赖关系</strong></h1><ul class=""><li id="6868" class="ku kv ht is b it kw ix kx jb ky jf kz jj la jn lb lc ld le bi translated">码头工人</li><li id="46a1" class="ku kv ht is b it lf ix lg jb lh jf li jj lj jn lb lc ld le bi translated">Nvidia GPU驱动程序</li><li id="9781" class="ku kv ht is b it lf ix lg jb lh jf li jj lj jn lb lc ld le bi translated">就是这样…</li></ul><p id="a425" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我知道这看起来很混乱，但是Docker和一个互联网连接是你不需要安装CUDA就能运行CUDA的全部。如果你没有docker，不要担心，我会教你如何安装</p><h1 id="68fe" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">安装依赖关系</strong></h1><p id="08b8" class="pw-post-body-paragraph iq ir ht is b it kw iv iw ix kx iz ja jb lk jd je jf ll jh ji jj lm jl jm jn hb bi translated">所以让我们继续吧。</p><p id="9cef" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">安装最新的Nvidia GPU驱动程序</strong></p><p id="98df" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我已经从这篇非常好的<a class="ae kt" rel="noopener" href="/better-programming/how-to-install-nvidia-drivers-and-cuda-10-0-for-rtx-2080-ti-gpu-on-ubuntu-16-04-18-04-ce32e4edf1c0">中型文章</a>中获得了安装GPU驱动程序的步骤。你需要从<a class="ae kt" href="https://www.nvidia.com/Download/index.aspx?lang=en-us" rel="noopener ugc nofollow" target="_blank">这里</a>下载最新的NVIDIA GPU驱动。这将比使用Ubuntu或Nvidia GeForce体验应用程序中的软件和更新更好、更可靠。</p><ol class=""><li id="f9b8" class="ku kv ht is b it iu ix iy jb ln jf lo jj lp jn lq lc ld le bi translated">转到提到的<a class="ae kt" href="https://www.nvidia.com/Download/index.aspx?lang=en-us" rel="noopener ugc nofollow" target="_blank">网址</a>。</li></ol><figure class="ls lt lu lv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lr"><img src="../Images/1dcb1a4060a18f31aa66e4f84db1cd90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lVCdemwP8xhTgeMuHl1FxA.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图一。英伟达的司机网站</figcaption></figure><p id="0afe" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.输入您的GPU的详细信息，您应该会看到适合您的配置的最佳驱动程序。</p><p id="0fe9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.请将它下载到您的本地。</p><p id="02cc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.使用<code class="du ma mb mc md b">CTRL+ALT+ T</code>打开您的终端</p><p id="ee43" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.转到下载驱动程序的目录(在我的例子中是下载)<code class="du ma mb mc md b"> cd ~/Dowloads</code></p><p id="4a32" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.授予执行的权限。运行你下载的文件，<code class="du ma mb mc md b">chmod +x NVIDIA-Linux-x86_64–450.66.run</code></p><p id="631e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">7.运行。运行文件<code class="du ma mb mc md b">sudo ./NVIDIA-Linux-x86_64–450.66.run --no-x-check</code></p><p id="14d1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果在这个阶段后你得到一个错误，这可能意味着有一些Nvidia驱动程序已经安装。你可以通过使用<code class="du ma mb mc md b">sudo nvidia uninstall</code>然后<code class="du ma mb mc md b">reboot</code>你的机器来删除任何现有的驱动程序。重启后，重复从<strong class="is hu">开始的第3步</strong></p><p id="9670" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">8.将会出现Nvidia GUI提示，选择<strong class="is hu">继续安装</strong></p><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es me"><img src="../Images/9da63dea33535a9dfd18d131896d507e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*KNG_Ac35k3Kz4m6sZnwf1Q.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">选择继续安装:<a class="ae kt" rel="noopener" href="/better-programming/how-to-install-nvidia-drivers-and-cuda-10-0-for-rtx-2080-ti-gpu-on-ubuntu-16-04-18-04-ce32e4edf1c0">https://medium . com/better-programming/how-to-install-NVIDIA-drivers-and-cuda-10-0-for-RTX-2080-ti-GPU-on-Ubuntu-16-04-18-04-ce 32 e 4 EDF 1c 0</a></figcaption></figure><p id="9f29" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">9.当询问您是否要自动更新X配置时，选择<strong class="is hu">否</strong>。</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="b771" class="mj jp ht md b fi mk ml l mm mn">$ sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit</span><span id="e7d7" class="mj jp ht md b fi mo ml l mm mn">$ sudo systemctl restart docker</span></pre><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es mp"><img src="../Images/2b2c44dcb530cd05f38a9b7ef114455e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*HlQCMxjQwpQeNGEHl46Ywg.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">选择否:<a class="ae kt" rel="noopener" href="/better-programming/how-to-install-nvidia-drivers-and-cuda-10-0-for-rtx-2080-ti-gpu-on-ubuntu-16-04-18-04-ce32e4edf1c0">https://medium . com/better-programming/how-to-install-NVIDIA-drivers-and-cuda-10-0-for-RTX-2080-ti-GPU-on-Ubuntu-16-04-18-04-ce 32 e 4 EDF 1c 0</a></figcaption></figure><p id="d12f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">10.重启你的机器。</p><p id="d05d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">11.搞定了。您已经安装了最新的Nvidia驱动程序。但是，您如何确保您正确地遵循了这些步骤呢？</p><p id="0084" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了验证您是否正确安装，您可以在您的终端上运行<code class="du ma mb mc md b">nvidia-settings</code>,您将获得一个NVIDIA应用程序，这意味着您安装正确。</p><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es mq"><img src="../Images/79a6b090d9f7361368f537a600991de9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*E1NXXByl0vkJ8zxD3zeQuA.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">Nvidia X服务器设置。</figcaption></figure><p id="8636" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您也可以从终端运行<code class="du ma mb mc md b">nvidia-smi</code>,您将得到如下响应</p><figure class="ls lt lu lv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mr"><img src="../Images/022b9d53d1374a302ff9f9b0a4d18752.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K7Sfp_g2VK1CibaOqtkEJw.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">nvidia-smi命令的响应。</figcaption></figure><p id="299e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">注意:</strong>在Docker上使用Tensorflow不需要CUDA，但是如果你需要它来完成任何其他任务，请查看我上面提到的<a class="ae kt" rel="noopener" href="/better-programming/how-to-install-nvidia-drivers-and-cuda-10-0-for-rtx-2080-ti-gpu-on-ubuntu-16-04-18-04-ce32e4edf1c0">中型文章</a>的其余部分。</p><p id="b3a1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">安装对接器</strong></p><ol class=""><li id="9dd8" class="ku kv ht is b it iu ix iy jb ln jf lo jj lp jn lq lc ld le bi translated">使用以下命令卸载机器中旧版本的docker(如果有)</li></ol><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="f556" class="mj jp ht md b fi mk ml l mm mn"> $ sudo apt-get remove docker docker-engine docker.io containerd runc</span></pre><p id="c10f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.接下来我们需要设置Docker存储库</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="7909" class="mj jp ht md b fi mk ml l mm mn">$ sudo apt-get update<br/><br/>$ sudo apt-get install \<br/>    apt-transport-https \<br/>    ca-certificates \<br/>    curl \<br/>    gnupg-agent \<br/>    software-properties-common</span></pre><p id="f637" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.添加码头工人的官方GPG键</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="5f10" class="mj jp ht md b fi mk ml l mm mn">$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span></pre><p id="837b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.现在我们需要设置稳定的存储库</p><p id="27ba" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">供<strong class="is hu"> x86_64 / amd64 </strong>使用，</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="7987" class="mj jp ht md b fi mk ml l mm mn">$ sudo add-apt-repository \<br/>   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \<br/>   $(lsb_release -cs) \<br/>   stable"</span></pre><p id="cfa8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">供<strong class="is hu"> armhf </strong>使用，</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="3322" class="mj jp ht md b fi mk ml l mm mn">$ sudo add-apt-repository \<br/>   "deb [arch=armhf] https://download.docker.com/linux/ubuntu \<br/>   $(lsb_release -cs) \<br/>   stable"</span></pre><p id="795d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">供<strong class="is hu">臂64 </strong>使用，</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="3d6d" class="mj jp ht md b fi mk ml l mm mn">$ sudo add-apt-repository \<br/>   "deb [arch=arm64] https://download.docker.com/linux/ubuntu \<br/>   $(lsb_release -cs) \<br/>   stable"</span></pre><p id="a6c8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.安装Docker引擎</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="9539" class="mj jp ht md b fi mk ml l mm mn">$ sudo apt-get update<br/>$ sudo apt-get install docker-ce docker-ce-cli containerd.io</span></pre><p id="390e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.通过运行<code class="du ma mb mc md b">hello-world</code>映像，验证Docker引擎是否已正确安装。</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="5fb3" class="mj jp ht md b fi mk ml l mm mn">$ sudo docker run hello-world</span></pre><p id="a905" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="kp">该命令下载一个测试映像，并在容器中运行它。当容器运行时，它打印一条信息性消息并退出。</em></p><p id="392b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">安装NVIDIA-Docker </strong></p><p id="c271" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要安装NVIDIA-Docker来连接我们的Docker系统和我们的GPU。为此，我们将使用<a class="ae kt" href="https://github.com/NVIDIA/nvidia-docker" rel="noopener ugc nofollow" target="_blank"> Nvidia-docker GitHub库</a>。</p><p id="3af9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我将下载Ubuntu 16.04/18.04/20.04，Debian Jessie /Stretch /Buster，如果你使用另一个操作系统，请检查上面提到的GitHub repo。</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="d940" class="mj jp ht md b fi mk ml l mm mn"># Add the package repositories<br/>$ distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</span><span id="b32a" class="mj jp ht md b fi mo ml l mm mn">$ curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -</span><span id="0b09" class="mj jp ht md b fi mo ml l mm mn">$ curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list<br/><br/>$ sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit</span><span id="8d56" class="mj jp ht md b fi mo ml l mm mn">$ sudo systemctl restart docker</span></pre><h1 id="09f0" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">通过TensorFlow使用Docker</h1><p id="daf3" class="pw-post-body-paragraph iq ir ht is b it kw iv iw ix kx iz ja jb lk jd je jf ll jh ji jj lm jl jm jn hb bi translated">最后，我们已经安装了所有的依赖项，但是我们还不能启动我们的神经网络！我知道工作量很大，但是相信我，这是值得的；)</p><ol class=""><li id="f724" class="ku kv ht is b it iu ix iy jb ln jf lo jj lp jn lq lc ld le bi translated">转到您的终端，调出与我们希望使用的TensorFlow版本相当的docker图像。</li></ol><p id="c99f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所有TensorFlow版本的所有不同docker图像均可在此处找到<a class="ae kt" href="https://hub.docker.com/r/tensorflow/tensorflow/tags/" rel="noopener ugc nofollow" target="_blank"/>。我正在使用TensorFlow 1.14与GPU和Python，所以我会运行</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="0179" class="mj jp ht md b fi mk ml l mm mn">$ sudo docker pull tensorflow/tensorflow:1.14.0-gpu-py3 </span></pre><p id="1b0d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以使用任何配置的TF版本。</p><p id="13e0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.我们将使用<code class="du ma mb mc md b">sudo docker login</code>登录docker(这一步不是强制性的)</p><p id="4e1c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.我们可以运行<code class="du ma mb mc md b">lspci | grep -i nvidia</code>来列出所有可用的GPU，你应该会看到你的GPU。</p><p id="c6f6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.我们可以通过运行来验证到目前为止所做的一切</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="78f8" class="mj jp ht md b fi mk ml l mm mn">$ sudo docker run --gpus all --rm nvidia/cuda nvidia-smi</span></pre><p id="4209" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.我们终于跑了</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="2c74" class="mj jp ht md b fi mk ml l mm mn">$ sudo docker run --gpus all -it tensorflow/tensorflow:1.14.0-gpu-py3 bash</span></pre><p id="de58" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们有了一个包含TensorFlow和CUDA的docker容器。这将作为一种类似虚拟机运行在你的电脑终端上。</p><p id="bb7c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你打开另一个终端并运行<code class="du ma mb mc md b">sudo docker ps</code>，你会看到你的docker容器正在运行。您的新docker容器将像一个新系统一样运行，并且将只包含基本组件，因此您需要首先安装您需要的所有库。</p><p id="7e43" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">注意#1 </strong>:您可以使用以下方式将文件从主机传输到docker机器</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="4a78" class="mj jp ht md b fi mk ml l mm mn"><em class="kp">$ sudo docker cp .\host/file/path\ &lt;container_ID&gt;:/destination/path</em></span></pre><p id="1e88" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">注意#2 </strong>:你可以从<code class="du ma mb mc md b">sudo docker ps</code>命令中看到你的容器ID。</p><p id="e779" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">注意#3 </strong>:如果您从docker正在运行的终端退出，您将停止容器，这将有点难以取回数据。</p><figure class="ls lt lu lv fd hk er es paragraph-image"><div class="er es ms"><img src="../Images/4500cf268cec114fc34834ccccf5bba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/0*qpDyTHmizwOzXh1p.png"/></div></figure><h1 id="c011" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">使用TensorFlow训练模型</h1><p id="101d" class="pw-post-body-paragraph iq ir ht is b it kw iv iw ix kx iz ja jb lk jd je jf ll jh ji jj lm jl jm jn hb bi translated">难的部分终于完成了。现在，我们有一台机器在您的本地运行，它可以利用GPU，您甚至不必担心CUDA。现在让我们通过在MNIST数据集上训练一个简单的神经网络来使用我们的GPU推出新的Docker。</p><p id="a5ff" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以在这里找到笔记本<a class="ae kt" href="https://github.com/tensorflow/datasets/blob/master/docs/keras_example.ipynb" rel="noopener ugc nofollow" target="_blank">的GitHub链接，在这里</a>找到Collab链接<a class="ae kt" href="https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/keras_example.ipynb" rel="noopener ugc nofollow" target="_blank"/></p><p id="d5c6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">导入库</strong></p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="0dbf" class="mj jp ht md b fi mk ml l mm mn"><strong class="md hu">import</strong> <strong class="md hu">tensorflow.compat.v2</strong> <strong class="md hu">as</strong> <strong class="md hu">tf</strong><br/><strong class="md hu">import</strong> <strong class="md hu">tensorflow_datasets</strong> <strong class="md hu">as</strong> <strong class="md hu">tfds</strong><br/><br/>tfds.disable_progress_bar()<br/>tf.enable_v2_behavior()</span></pre><p id="2c78" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">加载数据集</strong></p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="a166" class="mj jp ht md b fi mk ml l mm mn">(ds_train, ds_test), ds_info = tfds.load(<br/>    'mnist',<br/>    split=['train', 'test'],<br/>    shuffle_files=<strong class="md hu">True</strong>,<br/>    as_supervised=<strong class="md hu">True</strong>,<br/>    with_info=<strong class="md hu">True</strong>,<br/>)</span></pre><p id="900f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">建立培训渠道</strong></p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="0f27" class="mj jp ht md b fi mk ml l mm mn"><strong class="md hu">def</strong> normalize_img(image, label):<br/>  <em class="kp">"""Normalizes images: `uint8` -&gt; `float32`."""</em><br/>  <strong class="md hu">return</strong> tf.cast(image, tf.float32) / 255., label<br/><br/>ds_train = ds_train.map(<br/>    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)<br/>ds_train = ds_train.cache()<br/>ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)<br/>ds_train = ds_train.batch(128)<br/>ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)</span></pre><p id="172d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">建立评估管道</strong></p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="5427" class="mj jp ht md b fi mk ml l mm mn">ds_test = ds_test.map(<br/>    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)<br/>ds_test = ds_test.batch(128)<br/>ds_test = ds_test.cache()<br/>ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)</span></pre><p id="510c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">训练我们的模型</strong></p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="214a" class="mj jp ht md b fi mk ml l mm mn">model = tf.keras.models.Sequential([<br/>  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),<br/>  tf.keras.layers.Dense(128,activation='relu'),<br/>  tf.keras.layers.Dense(10, activation='softmax')<br/>])<br/>model.compile(<br/>    loss='sparse_categorical_crossentropy',<br/>    optimizer=tf.keras.optimizers.Adam(0.001),<br/>    metrics=['accuracy'],<br/>)<br/><br/>model.fit(<br/>    ds_train,<br/>    epochs=6,<br/>    validation_data=ds_test,<br/>)</span></pre><p id="0003" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">仅此而已。</p><h1 id="7af4" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">在Docker上设置TensorBoard</h1><p id="82da" class="pw-post-body-paragraph iq ir ht is b it kw iv iw ix kx iz ja jb lk jd je jf ll jh ji jj lm jl jm jn hb bi translated">因为我们用的是docker，它会有自己的IP地址，而且它会作为一台没有GUI的独立机器，因此不可能那么容易地设置TensorBoard。</p><p id="97ce" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了实现这一壮举，我们将使用我们的TensorBoard的特定端口进行端口转发。</p><ol class=""><li id="b0c7" class="ku kv ht is b it iu ix iy jb ln jf lo jj lp jn lq lc ld le bi translated">我们将使用一个单独的命令来启动docker机器，而不是我们上面提到的命令。</li></ol><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="ccf5" class="mj jp ht md b fi mk ml l mm mn"><em class="kp">$ sudo docker run -p 0.0.0.0:6006:6006 — gpus all -it tensorflow/tensorflow:1.14.0-gpu-py3 bash</em></span></pre><p id="744e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.这将与我们之前的命令一样，让我们登录到docker机器，但是对于端口，我们指定了ie。, 6006.</p><p id="1c0f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.我们将开始在这个终端中运行我们的训练脚本，然后使用命令<code class="du ma mb mc md b">docker exec -it &lt;container&gt; bash</code>启动一个新的终端</p><p id="5bcb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.现在，我们将使用两个不同的终端访问同一台docker机器，第一个终端用于运行我们的脚本，第二个终端用于运行TensorBoard。</p><p id="855e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.我们将在第二个终端中运行以下命令</p><pre class="ls lt lu lv fd mf md mg mh aw mi bi"><span id="31ee" class="mj jp ht md b fi mk ml l mm mn"><em class="kp">$ tensorboard --logdir=/home/faceopen/Desktop/NN_training/facenet/files_for_training/logs — port 6006</em></span></pre><p id="6385" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">希望这将帮助你快速训练深度学习模型，而没有设置CUDA的初始麻烦。</p><p id="92e9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你有任何进一步的疑问，请与我在anandhakrishnanh1998@gmail.com联系</p><h1 id="d7a1" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">参考</h1><ol class=""><li id="5adb" class="ku kv ht is b it kw ix kx jb ky jf kz jj la jn lq lc ld le bi translated"><a class="ae kt" href="https://www.nvidia.com/Download/index.aspx?lang=en-us" rel="noopener ugc nofollow" target="_blank">https://www.nvidia.com/Download/index.aspx?lang=en-us</a></li><li id="b93b" class="ku kv ht is b it lf ix lg jb lh jf li jj lj jn lq lc ld le bi translated"><a class="ae kt" rel="noopener" href="/better-programming/how-to-install-nvidia-drivers-and-cuda-10-0-for-rtx-2080-ti-gpu-on-ubuntu-16-04-18-04-ce32e4edf1c0">https://medium . com/better-programming/how-to-install-NVIDIA-drivers-and-cuda-10-0-for-RTX-2080-ti-GPU-on-Ubuntu-16-04-18-04-ce 32 e 4 EDF 1c 0</a></li><li id="4f93" class="ku kv ht is b it lf ix lg jb lh jf li jj lj jn lq lc ld le bi translated"><a class="ae kt" href="https://www.tensorflow.org/install/docker" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/install/docker</a></li><li id="b0c2" class="ku kv ht is b it lf ix lg jb lh jf li jj lj jn lq lc ld le bi translated">【https://github.com/NVIDIA/nvidia-docker】</li><li id="c257" class="ku kv ht is b it lf ix lg jb lh jf li jj lj jn lq lc ld le bi translated"><a class="ae kt" href="https://hub.docker.com/r/tensorflow/tensorflow/tags/" rel="noopener ugc nofollow" target="_blank">https://hub.docker.com/r/tensorflow/tensorflow/tags/</a></li><li id="8b5f" class="ku kv ht is b it lf ix lg jb lh jf li jj lj jn lq lc ld le bi translated"><a class="ae kt" href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" rel="noopener ugc nofollow" target="_blank">https://docs.docker.com/install/linux/docker-ce/ubuntu/</a></li><li id="4b08" class="ku kv ht is b it lf ix lg jb lh jf li jj lj jn lq lc ld le bi translated"><a class="ae kt" rel="noopener" href="/@teavanist/image-classification-using-tensorflow-on-docker-windows-bd7824b05fee">https://medium . com/@ teavanist/image-class ification-using-tensor flow-on-docker-windows-BD 7824 b 05 fee</a></li><li id="c688" class="ku kv ht is b it lf ix lg jb lh jf li jj lj jn lq lc ld le bi translated"><a class="ae kt" href="https://briancaffey.github.io/2017/11/20/using-tensorflow-and-tensor-board-with-docker.html" rel="noopener ugc nofollow" target="_blank">https://briancaffey . github . io/2017/11/20/using-tensor flow-and-tensor-board-with-docker . html</a></li></ol></div></div>    
</body>
</html>