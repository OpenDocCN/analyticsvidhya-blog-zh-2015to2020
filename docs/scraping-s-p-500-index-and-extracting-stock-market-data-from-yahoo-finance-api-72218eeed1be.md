# 从雅虎财经 API 中抓取和提取标准普尔 500 指数数据的 7 个简单步骤

> 原文：<https://medium.com/analytics-vidhya/scraping-s-p-500-index-and-extracting-stock-market-data-from-yahoo-finance-api-72218eeed1be?source=collection_archive---------8----------------------->

![](img/76f4b49dee707ad81437c0c564748680.png)

由 Freepik 设计的

# 概观

股票交易是世界上最复杂的过程之一。人们越来越努力地学习股票交易系统，希望能预测股票价格的走势。

如果能够获得股票价格的历史数据，就可以更好地预测股票价格。这可以通过两种方式实现:通过数据服务提供商或通过简单的 web 抓取器。我们可以刮给我们这项工作的股票价格数据的网站。股票数据可以在很多网站上找到，包括最受欢迎的网站之一雅虎财经。

在本文中，我们将重点关注通过抓取维基百科从标准普尔 500 获取公司列表，然后从雅虎提取股票相关数据。我们将一步一步地展示网页抓取的实现，这样你就能很容易地掌握它。

# 目标

1.  通过抓取维基百科获得标准普尔 500 的公司名单
2.  从雅虎提取标准普尔 500 公司的股票相关数据

# 规范

标准普尔 500 由代表所有经济部门的 500 家公司组成。该指数仅涵盖在美国市场上市的大型公司，包括纽约证券交易所或纳斯达克。因为标准普尔 500 代表了美国最大的上市公司，它被认为是最广泛引用的股票市场指数之一。标准普尔 500 的这些公司占美国所有股票的四分之三。

# 里程碑

> **网页抓取**

首先，我们需要导入所需的库。我们用漂亮的汤擦掉了维基百科上包含公司代码或符号的表格。我们使用请求从维基百科中检索源代码，然后事后使用 Pickle 保存。

在提取列表之前，我们需要看一下源代码。你可以在你的浏览器中右击某处，选择 *inspect element (* 按*F12*on*Windows*)*。可以在 *<表格>* 标签下查看 *html* 编码。*

*然后，它被转换成一个 BeautifulSoup 对象，可以像 Python 对象一样进行操作。更具体地说，该脚本发出一个 *http* 请求，然后用漂亮的 Soup 解析 Wiki 页面。Beautiful Soup 允许我们以类似解析树的格式从 HTML 中提取数据。*

*接下来，我们遍历整个表。美汤中的 *Findall* 方法将从 *html* 表中提取文本。表格的每一行都由 *html* 代码中的 *< tr >* 标签表示。需要从表格中删除的标题行(即*【1:】*)。我们创建一个空列表，并在其中添加代码。每行包括 ticker，即表数据 *< td >。*注意，在从维基百科提取数据的过程中，它会在每个字符串的末尾生成“ *\n* ”。因此，在将其纳入清单之前，应将其删除。*

*在这个阶段，我们可以使用 Pickle 保存列表。或者，我们可以将其转换为数据帧，但我们使用前者。*

> ***获取股票价格数据***

*在这一节中，我们将获得我们在上一节中收集的标准普尔 500 公司的财务信息。我们将在 Pandas 的帮助下使用雅虎财经数据，Pandas 是最好的 Python 包之一。*

*我们增加了几个库，包括指定日期的 *datatime* ，创建和检查目录的 *os* 。*

*我们需要访问之前保存的 Pickle 文件。然后，我会将每只股票的信息存储在单独的目录中。它是可选的，你可以将 500 家公司的所有数据保存在一个文件中，也可以将数据分割成单独的文件。*

*这和之前的过程是一样的，所以我们遍历股票代码列表并获取雅虎数据。偶尔，维基百科可能会使用不同的代码来代表同一家公司，如伯克希尔哈撒韦公司(BRK-B)，然而，在雅虎的缩写似乎是“BRK”。b "所以我们需要在遇到任何错误之前替换这些特殊字符。*

*我们需要的所有信息都唾手可得，所以是时候开动脑筋，开始对股票数据进行一些有用而令人兴奋的分析了。*