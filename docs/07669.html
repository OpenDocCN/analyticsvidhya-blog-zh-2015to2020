<html>
<head>
<title>Social Distancing Detector using Deep Learning and Depth Perception</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习和深度感知的社交距离检测器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/social-distancing-detector-using-deep-learning-and-depth-perception-b8d94fc7b02?source=collection_archive---------12-----------------------#2020-07-03">https://medium.com/analytics-vidhya/social-distancing-detector-using-deep-learning-and-depth-perception-b8d94fc7b02?source=collection_archive---------12-----------------------#2020-07-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b8ea8967b38b131db742ab507c44eee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2vxItm74Tt25KjPJ9X6xw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">输出图像以红色突出显示违反世卫组织建议的安全距离的人员</figcaption></figure><h2 id="5a5b" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">摘要</h2><p id="c004" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">由于高传染性的新冠肺炎疫情病毒，世界正在经历一段艰难的时期。尽管这是冠状病毒家族的一个新变种，但迄今为止还没有疫苗，最大的解决方案超越了任何药物疫苗——以数百年来社会距离的形式。因为这种病毒可以通过呼出空气传播，这使得与受感染者密切接触的每个人都非常容易被感染。因此，在公共场所与每个人保持安全距离是确保安全抵御病毒的最简单方法。</p><p id="3429" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">该软件旨在监控给定帧中每个人之间的距离，并计算和突出显示未保持世界卫生组织建议的安全距离的人数。这可以部署到任何公共区域，如道路、街道、市场、办公室、商场和清真寺，以确保严格遵循预防措施，使生活恢复正常。</p><p id="6bae" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">有一种普遍的误解，认为这场战争的士兵只是卫生工作者，人工智能社区也可以从前线战斗，并且有无数的例子表明，人工智能已经通过预测模型，通过使用强化学习来帮助寻找药物开发的最佳蛋白质结构，以及通过基于计算机视觉的诊断系统来提高认识。提出的软件旨在使一个基于视觉的监控系统工作在现场摄像机饲料，并显示违规行为的实时状态。</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h2 id="8b26" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">介绍</h2><p id="0927" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">社会距离的需要从来没有像今天这样重要，这种做法不仅会影响到观察它的个人，还会通过这个小小的行为引起的一系列连锁反应影响到整个世界。几个世纪以来，这种古老的疗法在许多病毒大流行中被观察到。由于全球化程度较低，症状更明显，这种传播在当时相对容易控制，然而，在今天这个全球化的时代，没有一个地方是安全的。然而，它也有积极的一面，那就是技术方面，人民和政府以前从来没有依靠技术来执行这些措施，这正是这个项目的目的。</p><p id="2e8d" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">这种基于计算机视觉的检测系统将允许我们在给定的视频中突出显示违反世界卫生组织建议的安全距离的人数。除了告知总体状况，例如遵守或违反准则的人数，它还在屏幕上突出显示个人，以便当局采取行动。这可以在部署数据的地方记录数据，例如一个商场，然后管理层和当局可以基于该数据做出决策，该数据可以进一步用于任何其他分析项目。这个项目是一个概念的证明，没有一些硬件校准是不可能达到准确的距离，答案将携带一些小误差，可以忽略不计。</p><p id="51ea" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">违反社交距离和其他预防措施可能是致命的，但在几乎所有的公共场所都很常见，尽管情况严重，但很少有人求助于技术来解决这一问题。目前还没有商用的基于计算机视觉的系统来监控和实施社交距离。这个问题并不困难，这里使用的管道对计算机视觉社区来说也不陌生。然而，由于它是一种相对年轻的疾病，没有多少与其相关的工作可以发表，文献的缺乏使得很难假设目前许多计算机视觉科学家在解决该问题时所面临的问题。这个项目旨在以一种原型的形式回馈社区，这种原型可以被未来的研究人员进一步改进。</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h2 id="433f" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">方法学</h2><p id="313b" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated"><strong class="ju hj">目标检测算法</strong>将用于检测图像帧中的局部人。更快的R-CNN、SSD(单次检测)和YOLO(你只看一次)是对象检测问题的三种最常见的架构。尽管各有各的优势，但在这个项目中使用的是<strong class="ju hj"> SSD </strong>(单次检测)，它的计算成本较低，可以在最快的时间内处理。SSD是唯一一个几乎实时地在CPU上完美流畅地工作的。在CNN的众多架构中，这里使用的是谷歌开发的<strong class="ju hj"> MobileNet </strong>版本，它以非常轻便和快速而著称。</p><p id="d4bb" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated"><strong class="ju hj"> COCO数据集</strong>是一个公开可用的数据集，有超过80个类，MobileNet SSD是在COCO数据集上训练的。因为我们只需要那个数据集中的一个类，即‘person’类，所以所有其他的类都被过滤掉了。使用COCO数据集上预先训练的MobileNet，而不是从头开始训练，权重和架构通过<strong class="ju hj">迁移学习</strong>导入。由于Python易于使用诸如Tensorflow、Keras、OpenCV等库，所以在Python上实现</p><p id="ab9b" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">一旦在帧中检测到人，一个人与所有其他人的距离将通过<strong class="ju hj">欧几里德距离</strong>计算，将设置一个阈值，所有距离小于该阈值的人将通过红色边界框高亮显示。违规者的总数将显示在屏幕上。根据世卫组织的建议，门槛或最小距离为1米。</p><p id="30f4" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">虽然获得距离的最佳方法是将视觉部分与深度传感器(如激光雷达、雷达或声纳)结合起来，但由于这是一个纯粹基于软件的项目，因此该选项是不可接受的。部署时需要进行摄像机校准，校准会因摄像机而异。对于深度，使用针孔相机模型和类似的三角形方法来估计人离相机的深度，这样做导致人之间更精确的距离计算。</p><figure class="la lb lc ld fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/44c8f6669913ad712e7fcdb1ee253443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OkVKBCsJd-vyVZ0qJgCnBA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图2:使用相机的深度</figcaption></figure><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es le"><img src="../Images/98b3f64eba81607c2290fc71e0fe1e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*L-cCH7BCgp7lR3e30O_bfQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图3:焦距、深度和高度的方程式</figcaption></figure><p id="74a5" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">图2显示了类似三角形方法的基础图，图3提到了我们用来从摄像机中找到每个人的<strong class="ju hj">深度的等式。在其中，我们必须假设一件事，那就是焦距，只是因为物理校准是不可能的，因为所使用的视频没有提到相机规格和一些外部值，但如果我们在自己的环境中应用它，我们可以采用一些值来进行校准。人的深度用于获得每个人的三维坐标，并且这些三维坐标的欧几里德距离导致图像中每个检测到的人之间的距离。这一新增功能大大提高了深度，从而使人与人之间的距离更加精确。</strong></p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h2 id="8097" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">结果</h2><p id="17f8" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">下图显示了检测和查找距离后的最终结果。那些有红色边框的人违反了世卫组织制定的社交距离准则，而那些有绿色边框的人则相互保持安全距离。其余没有包围盒的人没有被检测到。状态显示在屏幕的左上角。</p><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/92f9620b6650944d2655775e197f4217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*xye7DP06UtflVcCcQo9nxA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><em class="lg">图4:图像结果</em></figcaption></figure><p id="f6a5" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">所有检测的总结，包括每个检测到的人的中点、人的深度和社交距离的总体状态，都打印在最后。图5显示了打印的输出状态，这可以进一步用于为不同种类的分析构建另一个数据集。</p><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/1bd4433e21430cd2d80c69b12f4d9e53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*IhBO1_B9ptEMPnUG4zvGjA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><em class="lg">图5:打印所有结果的状态</em></figcaption></figure><p id="1f87" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">然后通过视频进行检测，在速度或FPS(每秒帧数)和检测精度之间进行权衡。下图展示了更高的精度如何导致更低的FPS，反之亦然。这取决于进入网络的输入图层，输入影像的大小越大，输入图层和复杂性就越大，从而导致更高的精度-但代价是速度。</p><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es li"><img src="../Images/23c776065687366884839dffa6d9cf25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*RBWMagUGLp1XsAmBjhhBsQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><em class="lg">图6:具有更多输入层(更大输入维度)的视频输出</em></figcaption></figure><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/0e4f829fa2cd5a24a5c3b45fa53a2336.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*VRdktjJJHXXdvkXD0Hpr9A.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><em class="lg">图7:具有更多输入层的输出视频的每秒帧数</em></figcaption></figure><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/a262acca140a03b46beb42bb6990db66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*Gan7BXgN3OKQRsNcWYhhxQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><em class="lg">图8:具有较少输入层(较小输入尺寸)的视频输出</em></figcaption></figure><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/592be592b0d5eb1c784dc018343e6260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*FBxqomN3cIcuLWb-11GciQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><em class="lg">图9:输入尺寸较小的视频每秒帧数</em></figcaption></figure><p id="ade7" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">对于视频，每一帧都被单独处理，屏幕上打印的状态是每一帧的，因为每一帧的检测结果都不同。至于距离，由于视错觉存在一些误差，虽然试图将其最小化，但不能完全消除误差。</p><p id="e542" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">带有详细解释的完整代码将很快出现在我的GitHub上。这里附上资源库的链接<a class="ae lm" href="https://github.com/osama-AI/Social-Distancing-AI" rel="noopener ugc nofollow" target="_blank">https://github.com/osama-AI/Social-Distancing-AI</a></p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h2 id="9c2a" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><span class="l ln lo lp bm lq lr ls lt lu di"> C </span>结论和未来改进</h2><p id="6f80" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">这个项目是一个概念验证，没有一些初始校准，这将取决于外部参数，它不会没有误差，但尽管使用了新的方法，结果是接近准确的。有一些限制，由于一些额外的功能没有添加到这个项目，可以提高性能。尽管缺乏参数，但这显示了巨大的成果，有可能成为今后所有此类工作的框架。</p><p id="5dc2" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated">以下是一些针对未来的<strong class="ju hj">建议</strong>,可以使这一点更加准确</p><p id="3972" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated"><strong class="ju hj"> 1。</strong>使用<strong class="ju hj">更精密复杂的模型</strong>进行物体检测，例如更快的R-CNN，甚至YOLO。这里使用的CNN架构是MobileNet，但VGG或Inception有数百万层，足够复杂，可以从中提取更多功能。它们没有被使用的唯一原因是因为那些复杂版本所需的<strong class="ju hj">计算处理</strong>意味着不可能在CPU上实时运行它们。</p><p id="6db7" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated"><strong class="ju hj"> 2。</strong>为了获得从相机到人的精确深度，理想的技术是将<strong class="ju hj">深度传感器</strong>如激光雷达和雷达与视觉部分融合。这些传感器是从相机中找到深度的最精确和最简单的方法。</p><p id="eb8f" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated"><strong class="ju hj"> 3。</strong>为了避免由于相机视角不同而导致深度估计不准确的视错觉，应用了<strong class="ju hj">透视变换</strong>将其转换为鸟瞰图。这将防止视错觉，并且通过俯视图检测到的所有人都将从相机的几乎相同的高度。这样做的问题是，虽然它可以使计算距离更准确，但它导致了更不准确的检测。</p><p id="ecca" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated"><strong class="ju hj"> 4。</strong>用于检测和跟踪的深度排序算法可以使得在视频上检测更容易，而不是在每一帧中检测一个新的人，这可以给被检测的人一个唯一的ID，该ID将在所有帧中与该特定的人在一起。这是专门用于跟踪应用程序的。</p><p id="74e0" class="pw-post-body-paragraph js jt hi ju b jv kn jx jy jz ko kb kc jf kp ke kf jj kq kh ki jn kr kk kl km hb bi translated"><strong class="ju hj"> 5。</strong>深度估计的方法需要一些外部值，根据该值，其余的距离将被校准。由于外部值不可用，因此对焦距值进行了假设，如果实际部署在某处，则建议实际计算相机的焦距，这对于所有相机来说是不同的。这个假设是为了继续这个项目，它不仅仅是一个精确的结果，而是一个概念证明，如果在使用前进行校准，它可以给出更准确的结果。利用视差匹配，可以使用立体相机来获得更精确的深度。</p></div></div>    
</body>
</html>