<html>
<head>
<title>Face Recognition using Transfer Learning on MobileNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于MobileNet的迁移学习人脸识别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-recognition-using-transfer-learning-on-mobilenet-cf632e25353e?source=collection_archive---------7-----------------------#2020-05-19">https://medium.com/analytics-vidhya/face-recognition-using-transfer-learning-on-mobilenet-cf632e25353e?source=collection_archive---------7-----------------------#2020-05-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/e03ecace20ba430029388a35d7c32d3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g_OTuQVoP31kUunrywfzfw.jpeg"/></div></div></figure><div class=""/><p id="805c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">今天，我将使用迁移学习的概念来演示迁移学习如何在预先训练的模型上完成(这里，我使用MobileNet)以节省我们的计算能力和资源。</p><ol class=""><li id="340e" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">创建数据集。</li></ol><p id="9945" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因为，我必须做我的面部识别，所以手动做所有的裁剪和重新签名部分，然后将其存储到一个文件夹中，使用一个脚本，在一个单一的去创建尽可能多的图像，你想要的，也根据各自的大小。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="5147" class="kg kh ht kc b fi ki kj l kk kl">import cv2<br/>import numpy as np</span><span id="0d0c" class="kg kh ht kc b fi km kj l kk kl"># Load HAAR face classifier<br/>face_classifier = cv2.CascadeClassifier(‘haarcascade_frontalface_default.xml’)</span><span id="eb93" class="kg kh ht kc b fi km kj l kk kl"># Load functions<br/>def face_extractor(img):<br/> # Function detects faces and returns the cropped face<br/> # If no face detected, it returns the input image<br/> <br/> gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)<br/> faces = face_classifier.detectMultiScale(gray, 1.3, 5)<br/> <br/> if faces is ():<br/> return None<br/> <br/> # Crop all faces found<br/> for (x,y,w,h) in faces:<br/> cropped_face = img[y:y+h, x:x+w]</span><span id="5d9f" class="kg kh ht kc b fi km kj l kk kl">return cropped_face</span><span id="8286" class="kg kh ht kc b fi km kj l kk kl"># Initialize Webcam<br/>cap = cv2.VideoCapture(0)<br/>count = 0</span><span id="5673" class="kg kh ht kc b fi km kj l kk kl"># Collect 100 samples of your face from webcam input<br/>while True:</span><span id="ec9f" class="kg kh ht kc b fi km kj l kk kl">ret, frame = cap.read()<br/> if face_extractor(frame) is not None:<br/> count += 1<br/> face = cv2.resize(face_extractor(frame), (300, 300))</span><span id="7aea" class="kg kh ht kc b fi km kj l kk kl"># Save file in specified directory with unique name<br/> file_name_path = r”C:\Users\Shinchan\Music\Akashdeep” + str(count) + ‘.jpg’<br/> cv2.imwrite(file_name_path, face)</span><span id="5f7f" class="kg kh ht kc b fi km kj l kk kl"># Put count on images and display live count<br/> cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)<br/> cv2.imshow(‘Face Cropper’, face)<br/> <br/> else:<br/> print(“Face not found”)<br/> pass</span><span id="07d4" class="kg kh ht kc b fi km kj l kk kl">if cv2.waitKey(1) == 27 or count == 100: #27 is the Esc Key<br/> break<br/> <br/>cap.release()<br/>cv2.destroyAllWindows() <br/>print(“Samples Taken”)</span></pre><p id="99d3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我创建了100个大小为300x300的样本进行测试，并在GitHub库中上传了一些不同民族的数据集，链接在文章的末尾。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="f63f" class="kg kh ht kc b fi ki kj l kk kl">Here  ”C:\Users\Shinchan\Music\Akashdeep” is the path where the samples will be stored. You can use your own location.</span></pre><p id="16ea" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.现在，我们将在MobileNet模型上使用迁移学习的概念。</p><p id="4043" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将加载预先训练好的模型，您可以在本地下载，也可以从互联网上自动下载。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kn"><img src="../Images/ce3ebe091ea6a4dbb86f13157b94d2bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M6c3d7oGF9sOpNeNmv-34g.png"/></div></div></figure><p id="233b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些是默认情况下在该模型中使用的预训练层的列表。正如你所看到的，所有预先训练的层都被设置为真，这意味着它们准备好再次被训练。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kn"><img src="../Images/3a4f112baf78571b8d60e126c6ad53d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kLMJgywRx0uN3mDNcDvAyA.png"/></div></div></figure><p id="ac58" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们将把所有预先训练好的层设置为False，这样它们就不能再被训练了。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kn"><img src="../Images/1eb4f707472b4bdea9d80d2a775277c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wn1miCr9uy0rmze51aSVWw.png"/></div></div></figure><p id="2776" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.现在，我们将为我们想要训练的输入添加层。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kn"><img src="../Images/04addffed220cc6dcf4743b007bb9f60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0OAupAyZMfN9-FuuahbL-Q.png"/></div></div></figure><p id="14d7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.将所有层添加到模型中，并打印模型摘要。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kn"><img src="../Images/61b37c5ef2cfc4e0f293085587e17f76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1L9ELPlvoMYdtTKZTOBn6Q.png"/></div></div></figure><p id="1be7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.现在，检查我们提供给模型的测试和验证数据集，并对它们进行修改。</p><figure class="jx jy jz ka fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kn"><img src="../Images/ec3e7b5ed4e7155fc475e7416b07babf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1WxaRF2BVoaN8EwKeGp1IQ.png"/></div></div></figure><p id="85e6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们使用ImageDataGenerator模块来完成所有的事情。</p><p id="6d20" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ImageDataGenerator接受一批输入的<strong class="is hu">图像</strong>，随机转换该批图像，然后返回原始批图像和修改后的数据</p><p id="b974" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.现在，我们将训练are模型并将该模型保存到特定文件扩展名“. h5”中。</p><div class="jx jy jz ka fd ab cb"><figure class="ko hk kp kq kr ks kt paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/e14ea00422eccc0cc4f222d6621529d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*OlcVRbvqHHIZtO29ooikwQ.png"/></div></figure><figure class="ko hk ku kq kr ks kt paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/d8f2c5a996e086559ca08a0b6cc9ef72.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*BlnZMHFRfE3C9iu-cC7h3Q.png"/></div></figure></div><p id="9d89" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我使用名称“face _ recognet . H5”来保存模型。您可以使用任何名称，但以前只能使用分机。</p><p id="98b8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以看到模型的准确性几乎是91%,因为只有这么少的历元和使用更少的计算能力。</p><p id="8114" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.现在，加载面部识别的模型和模型预测。</p><div class="jx jy jz ka fd ab cb"><figure class="ko hk kv kq kr ks kt paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/d50bef3ae25c412cb7979a806b1c41e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*CQMCK4jc96At220Vp53eyw.png"/></div></figure><figure class="ko hk kw kq kr ks kt paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/89064ee7b879a124665dc086a0cd4505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*AW9Zb7oQ4Hn_a7ClhJUZaw.png"/></div></figure></div><p id="1b54" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">7.显示预测。</p><div class="jx jy jz ka fd ab cb"><figure class="ko hk kx kq kr ks kt paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/5db5bc670af202ada45089a3e0be04e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*Tdu7f1cXJNBfe8TIR9DabA.png"/></div></figure><figure class="ko hk ky kq kr ks kt paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/d445ceaee55227a386cf64b7009b2f73.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*00fAwHRwflJ2VKUjbvflhQ.png"/></div></figure><figure class="ko hk kz kq kr ks kt paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/6d58963484315d6d96ea756bc51238ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*NEGnpXwVs-xbD-i9T5gJVQ.png"/></div></figure></div><p id="9ade" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此任务的数据集和所有文件的GitHub链接…</p><div class="hh hi ez fb hj la"><a href="https://github.com/Akashdeep-47/Facial-Recognition.git" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hu fi z dy lf ea eb lg ed ef hs bi translated">akashdeep-47/面部识别</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">在MobileNet-Akashdeep-47/face-Recognition上使用迁移学习进行人脸识别</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="lk l ll lm ln lj lo hp la"/></div></div></a></div></div></div>    
</body>
</html>