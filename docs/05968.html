<html>
<head>
<title>Scale Spacy document/text similarity(NLP) on Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark上的缩放空间文档/文本相似性(NLP)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/scale-spacy-text-similarity-nlp-on-apache-spark-cce95bda686c?source=collection_archive---------15-----------------------#2020-05-07">https://medium.com/analytics-vidhya/scale-spacy-text-similarity-nlp-on-apache-spark-cce95bda686c?source=collection_archive---------15-----------------------#2020-05-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/08129a9c92091eb42eb7f3edcbb92874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GunfqPVVSUQx3Gas"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">安妮·斯普拉特在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="9131" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本文中，我们将了解什么是<a class="ae iu" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank">空间</a>，以及我们如何利用Apache Spark来大规模运行空间。</p><p id="c965" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">随着日常业务对机器学习用例的需求不断增长，不同领域对不同类型的机器学习算法的需求也随着数据的不断增长而增长。</p><h2 id="c72d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">什么是空间</h2><p id="6ce0" class="pw-post-body-paragraph iv iw hi ix b iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo ks jq jr js hb bi translated">Spacy是工业级自然语言处理库，用于处理机器学习的文本数据，提供了大量的预处理、标记化、词干化、命名实体解析、预训练的词向量<strong class="ix hj"> </strong>和为深度学习准备文本等选项。Spacy还提供了一些构建向量，例如用于<a class="ae iu" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> word2vec </a>。你可以在这里找到更多关于各种语言的模型的细节</p><p id="7bdf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://en.wikipedia.org/wiki/Apache_Spark" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> Apache Spark </strong> </a>是一个开源的分布式通用集群计算框架。Spark提供了一个接口，通过隐式数据并行和容错对整个集群进行编程。</p><p id="4b6e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">如何在spacy上运行相似度:</strong></p><p id="1dc6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kt">注:您可以在这里</em>  <em class="kt">找到关于安装空间</em> <a class="ae iu" href="https://spacy.io/usage" rel="noopener ugc nofollow" target="_blank"> <em class="kt">的详细说明。(我用的是spacy的2.1.8版本)</em></a></p><p id="fa82" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我将探索基于余弦相似性的空间相似性度量。它是通过比较<strong class="ix hj">单词向量</strong>或“单词嵌入”，一个单词的多维意义表示来确定的。</p><p id="ae1d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们看看来自空间的相似性api。</p><p id="f590" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我在这篇文章中使用的是<strong class="ix hj"> en_core_web_lg </strong>模型，它是在普通爬行中训练的手套向量，有685k个键，685k个唯一向量(300个维度)</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="7afe" class="jt ju hi kz b fi ld le l lf lg">import spacy<br/>import en_core_web_lg<br/>nlp = en_core_web_lg.load()<br/>doc1 = nlp("i love my pet dog")<br/>doc2 = nlp("Maggie is my lovable pet dog !")<br/>print("output:" , doc1.similarity(doc2))</span></pre><p id="91dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:0.9822815156578484</p><p id="3f1c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这意味着以上两个文档/句子文本98.22 %相似。</p><p id="0c60" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在的挑战是如何以分布式方式在spark上执行，其中每个执行器节点都在计算分布式数据切片的相似性。</p><p id="8f54" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里的想法是在多个执行器上并行运行similarity()作为spark UDF(用户定义的函数)。以下是需要配置的一些重要因素，以便在spacy on spark上运行和扩展:</p><p id="0f0d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我的所有代码都打包在MySpacyClassObject类中。为了避免每次计算相似度都要反复下载en_core_web_lg，我将en_core_web_lg存储在每个执行器上的全局变量中。这将加快计算速度，因为en_core_web_lg (~789 MB)已经加载到executor内存中</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="9b8a" class="jt ju hi kz b fi ld le l lf lg">@staticmethod<br/><em class="kt">def </em>get_spacy():<br/><br/>    <em class="kt">if </em>"nlp" <em class="kt">not in </em>globals():<br/>        globals()["nlp"] = en_core_web_lg.load()<br/><br/>    <em class="kt">return </em>globals()["nlp"]</span></pre><p id="f319" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">创造火花UDF: </strong></p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="a2dd" class="jt ju hi kz b fi ld le l lf lg"><em class="kt">def </em>text_similarity(dsc1, <em class="kt">dsc2</em>):<br/>    '''<br/>    Load spacy and calculate similarity measure<br/>    '''<br/>    <em class="kt">if </em>(dsc1 <em class="kt">is None or dsc2 is None</em>):<br/>        <em class="kt">return </em>float(-1)<br/>    <em class="kt">if </em>((len(str(dsc1)) &lt; 1 <em class="kt">or </em>str(dsc1) == "") <em class="kt">or </em>(len(str(<em class="kt">dsc2</em>)) &lt; 1 <em class="kt">or </em>str(<em class="kt">dsc2</em>) == "")):<br/>        <em class="kt">return </em>float(-1)<br/><br/>    nlp_glob = MySpacyClassObject.get_spacy()<br/><br/>    <em class="kt">return </em>float(nlp_glob(dsc1).similarity(nlp_glob(<em class="kt">dsc2</em>)))</span><span id="aa76" class="jt ju hi kz b fi lh le l lf lg">#define your udf <br/>text_similarity_UDF = udf(<em class="kt">lambda arr</em>: MySpacyClassObject.text_similarity(arr[0], arr[1]), FloatType())</span></pre><p id="7edd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如何使用UDF:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="fd90" class="jt ju hi kz b fi ld le l lf lg">#You can read data from any data source per your need to create #spark data frame to use UDF. I am reading table from hive which #already has two columns with textual data for similarity</span><span id="e3fc" class="jt ju hi kz b fi lh le l lf lg">text_similarity_DF = spark.read.table(<br/>    "your_schema.table_name").repartition(500)<br/>text_similarity_with_measure = text_similarity_UDF \<br/>    .withColumn("similarity",<br/>                text_similarity_UDF(array(text_similarity_DF['text1'],<br/>                                   text_similarity_DF['text2']))) \<br/>    .select(text_similarity_DF['text1']<br/>            , "similarity"<br/>            , text_similarity_DF['text2'])</span><span id="652c" class="jt ju hi kz b fi lh le l lf lg">#Persist dataframe text_similarity_with_measure back in hive<br/>text_similarity_with_measure.write.mode('overwrite').saveAsTable(your_output_tabble_name)</span></pre><p id="b843" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">提高性能的重要考虑因素和挑战:</strong></p><p id="e44b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kt">①</em><strong class="ix hj"><em class="kt">。</em> </strong> <em class="kt">连载</em> : Spacy 2。*版本支持序列化。确保您使用的是版本&gt; 2。</p><p id="99bf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.确保<strong class="ix hj"> en_core_web_lg </strong>(或者您正在使用的其他模型)在每个执行器上都可用，以便您可以读取和加载模型以获得更好的性能。另一种方法是你仍然可以让你的spark程序只下载一次，然后继续重用它(请看上面的get_spacy()静态方法)。</p><p id="90d5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.确保每个执行器都安装了空间并可供使用。</p></div></div>    
</body>
</html>