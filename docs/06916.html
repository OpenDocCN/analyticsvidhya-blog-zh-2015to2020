<html>
<head>
<title>Autoencoders: Unsupervised Artificial Neural Networks(ANN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动编码器:无监督人工神经网络(ANN)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/autoencoders-unsupervised-artificial-neural-networks-ann-a276089f0053?source=collection_archive---------10-----------------------#2020-06-07">https://medium.com/analytics-vidhya/autoencoders-unsupervised-artificial-neural-networks-ann-a276089f0053?source=collection_archive---------10-----------------------#2020-06-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/5f543782bb06ac7522baf10f472e2eb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjljTyveOl0kWbsYgIDzEA.png"/></div></div></figure><div class=""/><blockquote class="iq ir is"><p id="f71e" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">欢迎来到这个关于自动编码器的博客。在这篇博客中，你将会找到关于什么是自动编码器，它是如何工作的解释，并看到自动编码器在<strong class="iw hu"> TensorFlow </strong>中的实现。</p></blockquote><h1 id="be3b" class="js jt ht bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">目录</h1><ol class=""><li id="42d3" class="kq kr ht iw b ix ks jb kt ku kv kw kx ky kz jr la lb lc ld bi translated">介绍</li><li id="5e67" class="kq kr ht iw b ix le jb lf ku lg kw lh ky li jr la lb lc ld bi translated">特征提取和降维</li><li id="cea3" class="kq kr ht iw b ix le jb lf ku lg kw lh ky li jr la lb lc ld bi translated">自动编码器结构</li><li id="0958" class="kq kr ht iw b ix le jb lf ku lg kw lh ky li jr la lb lc ld bi translated">表演</li><li id="adc2" class="kq kr ht iw b ix le jb lf ku lg kw lh ky li jr la lb lc ld bi translated">密码</li></ol><h1 id="b61b" class="js jt ht bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">1.介绍</h1><p id="96d4" class="pw-post-body-paragraph it iu ht iw b ix ks iz ja jb kt jd je ku lj jh ji kw lk jl jm ky ll jp jq jr hb bi lm translated"><span class="l ln lo lp bm lq lr ls lt lu di">一个</span>自动编码器，也被称为<strong class="iw hu">自动联想器</strong>或<strong class="iw hu">空竹网络</strong>，是一个<strong class="iw hu">人工神经网络</strong>，用于重建给定的输入。它获取一组<strong class="iw hu">未标记的</strong>输入，对它们进行编码，然后试图从中提取最有价值的信息。用于<strong class="iw hu">特征提取</strong>，<strong class="iw hu">数据学习生成模型</strong>，<strong class="iw hu">降维</strong>，可用于<strong class="iw hu">压缩</strong>。</p><p id="b4d4" class="pw-post-body-paragraph it iu ht iw b ix iy iz ja jb jc jd je ku jg jh ji kw jk jl jm ky jo jp jq jr hb bi translated">G. E. Hinton和R. R. Salakhutdinov 在2006年发表了一篇名为<a class="ae lv" href="https://www.cs.toronto.edu/~hinton/science.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hu">用神经网络</strong> </a> <strong class="iw hu">减少数据维度的论文，显示出比多年来改进其他类型的网络更好的结果，是在<strong class="iw hu">神经网络</strong>领域的突破。</strong></p><blockquote class="lw"><p id="64a8" class="lx ly ht bd lz ma mb mc md me mf jr dx translated">“基于<strong class="ak">受限玻尔兹曼机器</strong>的自动编码器被用于一些最大的深度学习应用中。他们是<strong class="ak">深度信念网络(DBN) </strong>的组成部分</p></blockquote><figure class="mh mi mj mk ml hk er es paragraph-image"><div class="er es mg"><img src="../Images/7d7758505bdd23ce035ccba42ecf3d42.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*Kan9IUnMNaooGjdeGDpA6Q.png"/></div><figcaption class="mm mn et er es mo mp bd b be z dx translated">自动编码器</figcaption></figure><h1 id="cf3d" class="js jt ht bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak"> 2。特征提取和降维</strong></h1><p id="78c9" class="pw-post-body-paragraph it iu ht iw b ix ks iz ja jb kt jd je ku lj jh ji kw lk jl jm ky ll jp jq jr hb bi translated"><strong class="iw hu"> Nikhil Buduma </strong>在<a class="ae lv" href="http://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hu"> KdNuggets </strong> </a>中给出了一个例子，很好的解释了这种<strong class="iw hu">神经网络</strong>的效用。</p><p id="fba0" class="pw-post-body-paragraph it iu ht iw b ix iy iz ja jb jc jd je ku jg jh ji kw jk jl jm ky jo jp jq jr hb bi translated">比如说你想提取摄影中的人的情绪。以下面这张256x256像素的灰度图片为例:</p><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es mq"><img src="../Images/4f9c9e3c963222c593567c5179de6baa.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*jmgPplLw1hCqlENLTrLlAg.png"/></div></figure><p id="99f9" class="pw-post-body-paragraph it iu ht iw b ix iy iz ja jb jc jd je ku jg jh ji kw jk jl jm ky jo jp jq jr hb bi translated">但是当使用这张图片时，我们开始遇到一个瓶颈！因为这个尺寸为<strong class="iw hu"> 256x256像素</strong>的图像对应于一个尺寸为<strong class="iw hu"> 65536的输入向量！</strong>如果我们使用传统手机相机生成的图像，即生成<strong class="iw hu"> 4000 x 3000 </strong>像素的图像，我们将有<strong class="iw hu">1200万</strong> <strong class="iw hu">个维度来分析。</strong>:</p><blockquote class="iq ir is"><p id="8172" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">正如<!-- -->所见，<strong class="iw hu">它呈指数级增长！</strong>回到我们的例子，<strong class="iw hu">我们不需要使用所有的65，536个维度来对情绪进行分类</strong>。人类根据一些特定的面部表情、一些关键特征来识别情绪，比如嘴的形状、眉毛的形状。</p></blockquote><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es mv"><img src="../Images/cc14a7d7095d253225c7b71dbd4872a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*2KGEYD5V4J0z-ItTwStkAQ.png"/></div></figure></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><h1 id="59b9" class="js jt ht bd ju jv nd jx jy jz ne kb kc kd nf kf kg kh ng kj kk kl nh kn ko kp bi translated">3.自动编码器结构</h1><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es ni"><img src="../Images/26b99af87d74b726dc5883e4a645ef25.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*_wBvbOPF3EhMxLNTrfskyQ.png"/></div><figcaption class="mm mn et er es mo mp bd b be z dx translated">自动编码器结构</figcaption></figure><blockquote class="iq ir is"><p id="f517" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hu">一个<em class="ht">自动编码器</em>可以分为两部分:</strong></p><p id="372c" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hu"> <em class="ht"> 1。编码器:</em></strong><em class="ht"/><strong class="iw hu"><em class="ht">编码器</em>需要压缩输入</strong>的表示。在这种情况下，我们将<strong class="iw hu">将演员面部的尺寸</strong>、<strong class="iw hu">从2000个尺寸减少到只有30个尺寸</strong>，通过我们的编码器的层运行数据。</p><p id="4bf4" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hu">2<em class="ht">。解码器:</em></strong><em class="ht"/><strong class="iw hu"><em class="ht">解码器</em>的工作原理与编码器网络</strong>相反。<strong class="iw hu">尽可能接近</strong>地重新创建 <strong class="iw hu">输入</strong>、<strong class="iw hu">。这在训练中起着重要的作用，因为它迫使自动编码器在<strong class="iw hu">压缩的</strong>表示中选择最重要的特征。</strong></p></blockquote><h1 id="92ab" class="js jt ht bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">4.表演</h1><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nj"><img src="../Images/0ce16b1d09dd9f9de01790dc9baad667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IFWeX6iKlpm8H95Mba4Fxg.png"/></div></div><figcaption class="mm mn et er es mo mp bd b be z dx translated"><strong class="bd ju">左:主成分分析</strong>和<strong class="bd ju">右:自动编码器</strong></figcaption></figure><p id="4a3b" class="pw-post-body-paragraph it iu ht iw b ix iy iz ja jb jc jd je ku jg jh ji kw jk jl jm ky jo jp jq jr hb bi translated">该图像摘自G. E. Hinton和R. R. Salakhutdinovcomparing的<a class="ae lv" href="https://www.cs.toronto.edu/~hinton/science.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>，关于500位MNIST的二维简化，左边是PCA，右边是autoencoder。我们可以看到，自动编码器为我们提供了更好的数据分离。</p><h1 id="62dd" class="js jt ht bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">5.密码</h1><pre class="mr ms mt mu fd nk nl nm nn aw no bi"><span id="1d7b" class="np jt ht nl b fi nq nr l ns nt">#from __future__ import division, print_function, absolute_import</span><span id="198b" class="np jt ht nl b fi nu nr l ns nt"><strong class="nl hu">import tensorflow as tf<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</strong></span><span id="8634" class="np jt ht nl b fi nu nr l ns nt"># Import MINST data<br/><strong class="nl hu">from tensorflow.examples.tutorials.mnist import input_data<br/>mnist = input_data.read_data_sets(“/tmp/data/”, one_hot=True)</strong></span></pre><blockquote class="iq ir is"><p id="29e5" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，让我们给出神经网络将要使用的参数。</p></blockquote><pre class="mr ms mt mu fd nk nl nm nn aw no bi"><span id="3216" class="np jt ht nl b fi nq nr l ns nt"><strong class="nl hu">learning_rate = 0.01<br/>training_epochs = 20<br/>batch_size = 256<br/>display_step = 1<br/>examples_to_show = 10</strong></span><span id="fbd5" class="np jt ht nl b fi nu nr l ns nt"># Network Parameters<br/><strong class="nl hu">n_hidden_1 = 256 # 1st layer num features<br/>n_hidden_2 = 128 # 2nd layer num features<br/>n_input = 784 # MNIST data input (img shape: 28*28)</strong></span><span id="cc66" class="np jt ht nl b fi nu nr l ns nt"># tf Graph input (only pictures)<br/><strong class="nl hu">X = tf.placeholder(“float”, [None, n_input])</strong></span><span id="3c48" class="np jt ht nl b fi nu nr l ns nt"><strong class="nl hu">weights = {<br/> ‘encoder_h1’: tf.Variable(tf.random_normal([n_input, n_hidden_1])),<br/> ‘encoder_h2’: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),<br/> ‘decoder_h1’: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),<br/> ‘decoder_h2’: tf.Variable(tf.random_normal([n_hidden_1, n_input])),<br/>}<br/>biases = {<br/> ‘encoder_b1’: tf.Variable(tf.random_normal([n_hidden_1])),<br/> ‘encoder_b2’: tf.Variable(tf.random_normal([n_hidden_2])),<br/> ‘decoder_b1’: tf.Variable(tf.random_normal([n_hidden_1])),<br/> ‘decoder_b2’: tf.Variable(tf.random_normal([n_input])),<br/>}</strong></span></pre><blockquote class="iq ir is"><p id="7557" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在我们需要创建我们的编码器。为此，我们将使用s形函数。s形函数通过这种类型的网络提供了很好的结果。这是因为具有非常适合反向传播的良好导数。我们可以使用sigmoidal函数创建编码器，如下所示:</p></blockquote><pre class="mr ms mt mu fd nk nl nm nn aw no bi"><span id="0344" class="np jt ht nl b fi nq nr l ns nt"># Building the Encoder<br/><strong class="nl hu">def encoder(x):<br/></strong>    # Encoder first layer with sigmoid activation #1<br/><strong class="nl hu">    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))</strong></span><span id="cb39" class="np jt ht nl b fi nu nr l ns nt">    # Encoder second layer with sigmoid activation #2<br/><strong class="nl hu">    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1,  weights['encoder_h2']), biases['encoder_b2']))<br/>    return layer_2</strong></span></pre><blockquote class="iq ir is"><p id="38c0" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">而解码器:你可以看到编码器中的layer_1就是解码器中的layer_2，反之亦然。</p></blockquote><pre class="mr ms mt mu fd nk nl nm nn aw no bi"><span id="cef3" class="np jt ht nl b fi nq nr l ns nt"># Building the decoder<br/><strong class="nl hu">def decoder(x):<br/></strong>    # Decoder first layer with sigmoid activation #1<br/><strong class="nl hu">    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),biases['decoder_b1']))</strong></span><span id="6404" class="np jt ht nl b fi nu nr l ns nt">    # Decoder second layer with sigmoid activation #2<br/><strong class="nl hu">    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))<br/>    return layer_2</strong></span></pre><blockquote class="iq ir is"><p id="7dd3" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们构建我们的模型。在变量<code class="du nv nw nx nl b"><strong class="iw hu">cost</strong></code> <strong class="iw hu"> </strong>中，我们有损失函数，在变量<code class="du nv nw nx nl b"><strong class="iw hu">optimizer</strong></code> <strong class="iw hu"> </strong>中，我们有用于反向传播的梯度。</p></blockquote><pre class="mr ms mt mu fd nk nl nm nn aw no bi"><span id="995e" class="np jt ht nl b fi nq nr l ns nt"># Launch the graph<br/># Using InteractiveSession (more convenient while using Notebooks)<br/><strong class="nl hu">sess = tf.InteractiveSession()<br/>sess.run(init)</strong></span><span id="1043" class="np jt ht nl b fi nu nr l ns nt"><strong class="nl hu">total_batch = int(mnist.train.num_examples / batch_size)<br/></strong># Training cycle<br/><strong class="nl hu">for epoch in range(training_epochs):<br/></strong> # Loop over all batches<br/><strong class="nl hu"> for i in range(total_batch):<br/> batch_xs, batch_ys = mnist.train.next_batch(batch_size)<br/></strong> # Run optimization op (backprop) and cost op (to get loss value)<br/><strong class="nl hu"> _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})<br/></strong> # Display logs per epoch step<br/><strong class="nl hu"> if epoch % display_step == 0:<br/> print(“Epoch:”, ‘%04d’ % (epoch+1),<br/> “cost=”, “{:.9f}”.format(c))</strong></span><span id="c925" class="np jt ht nl b fi nu nr l ns nt"><strong class="nl hu">print(“Optimization Finished!”)</strong></span></pre><p id="dd08" class="pw-post-body-paragraph it iu ht iw b ix iy iz ja jb jc jd je ku jg jh ji kw jk jl jm ky jo jp jq jr hb bi translated">输出:</p><pre class="mr ms mt mu fd nk nl nm nn aw no bi"><span id="ccec" class="np jt ht nl b fi nq nr l ns nt"><strong class="nl hu">Epoch: 0001 cost= 0.182728916<br/>Epoch: 0002 cost= 0.150434598<br/>Epoch: 0003 cost= 0.130958572<br/>Epoch: 0004 cost= 0.125098571<br/>Epoch: 0005 cost= 0.119374141<br/>Epoch: 0006 cost= 0.116029739<br/>Epoch: 0007 cost= 0.114480294<br/>Epoch: 0008 cost= 0.110542893<br/>Epoch: 0009 cost= 0.107315414<br/>Epoch: 0010 cost= 0.103023507<br/>Epoch: 0011 cost= 0.101529025<br/>Epoch: 0012 cost= 0.097410828<br/>Epoch: 0013 cost= 0.093311585<br/>Epoch: 0014 cost= 0.093811013<br/>Epoch: 0015 cost= 0.090760238<br/>Epoch: 0016 cost= 0.089178301<br/>Epoch: 0017 cost= 0.087290406<br/>Epoch: 0018 cost= 0.085913278<br/>Epoch: 0019 cost= 0.086014777<br/>Epoch: 0020 cost= 0.084903874<br/>Optimization Finished!</strong></span></pre><blockquote class="iq ir is"><p id="0082" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">上面我们已经用了20个纪元。</p><p id="250f" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，让我们为我们的<strong class="iw hu">测试</strong>应用<strong class="iw hu">编码器</strong>和<strong class="iw hu">解码器</strong>。</p></blockquote><pre class="mr ms mt mu fd nk nl nm nn aw no bi"><span id="4ae5" class="np jt ht nl b fi nq nr l ns nt"># Applying encode and decode over test set<br/><strong class="nl hu">encode_decode = sess.run(<br/> y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})</strong></span><span id="b2f6" class="np jt ht nl b fi nu nr l ns nt"># Lets Let’s simply visualize our graphs!</span><span id="07f9" class="np jt ht nl b fi nu nr l ns nt"># Compare original images with their reconstructions<br/><strong class="nl hu">f, a = plt.subplots(2, 10, figsize=(10, 2))<br/>for i in range(examples_to_show):<br/> a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))<br/> a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))</strong></span></pre><h2 id="de20" class="np jt ht bd ju ny nz oa jy ob oc od kc ku oe of kg kw og oh kk ky oi oj ko ok bi translated">最终输出:</h2><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es ol"><img src="../Images/d91ea90bd6e1e13cb4c3db46a4e7dbdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*KaYjkWDEEjbUbTrI21eWxQ.png"/></div></figure><h2 id="6971" class="np jt ht bd ju ny nz oa jy ob oc od kc ku oe of kg kw og oh kk ky oi oj ko ok bi translated">如你所见，重建是成功的。可以看出，图像中添加了一些噪声。</h2></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><h1 id="1004" class="js jt ht bd ju jv nd jx jy jz ne kb kc kd nf kf kg kh ng kj kk kl nh kn ko kp bi translated">感谢您的阅读</h1><p id="bce8" class="pw-post-body-paragraph it iu ht iw b ix ks iz ja jb kt jd je ku lj jh ji kw lk jl jm ky ll jp jq jr hb bi translated">更多深度学习和神经网络相关的此类内容和知识<a class="ae lv" rel="noopener" href="/@kalamanoj989"> <strong class="iw hu"> <em class="iv">点击此处</em> </strong> </a></p></div></div>    
</body>
</html>