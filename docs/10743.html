<html>
<head>
<title>Chest X-Ray Medical Report Generation Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习生成胸部X射线医学报告</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/chest-x-ray-medical-report-generation-using-deep-learning-bf39cc487b88?source=collection_archive---------9-----------------------#2020-11-01">https://medium.com/analytics-vidhya/chest-x-ray-medical-report-generation-using-deep-learning-bf39cc487b88?source=collection_archive---------9-----------------------#2020-11-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="0136" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">目录:</h1><ol class=""><li id="835d" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated"><em class="jv">业务问题</em></li><li id="bff1" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated"><em class="jv">机器学习问题</em></li><li id="2ce4" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated"><em class="jv">探索性数据分析</em></li><li id="f15d" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated"><em class="jv">机器学习模型</em></li><li id="f7bd" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated"><em class="jv">未来工作</em></li><li id="267b" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">参考</li></ol><h1 id="fda6" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">1.商业问题</h1><h1 id="9937" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">1.1描述</h1><p id="373f" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">如果你因胸痛、胸部受伤或呼吸急促去看医生，你通常会接受胸部x光检查。胸部x光是最常要求的放射学检查。该图像有助于医生确定你是否有心脏问题、肺萎陷、肺炎、肋骨骨折、肺气肿、癌症或任何其他疾病。胸部x光检查也有助于诊断肺部的新冠肺炎感染，因为新冠肺炎主要攻击我们的肺部。一旦你做了x光检查，你的医生会用他的知识解释并进一步指导你。因此，我们的目标是通过生成描述放射科医师在x射线中看到和观察到的内容的报告，使这些x射线易于阅读。</p><p id="b8ee" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">问题陈述</strong></p><p id="1ca0" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">构建深度学习模型，从给定的x光图像生成医疗报告。</p><p id="da89" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">数据来源:</strong></p><p id="e7ab" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">PNG图片:<a class="ae kv" href="http://academictorrents.com/details/5a3a439df24931f410fac269b87b050203d9467d" rel="noopener ugc nofollow" target="_blank">http://academic torrents . com/details/5a 3a 439 df 24931 f 410 fac 269 b 87b 050203d 9467d</a></p><p id="1674" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">XML报告:<a class="ae kv" href="http://academictorrents.com/details/66450ba52ba3f83fbf82ef9c91f2bde0e845ab" rel="noopener ugc nofollow" target="_blank">http://academic torrents . com/details/66450 ba 52 ba 3 f 83 fbf 82 ef 9 c 91 F2 bde 0 e 845 ab</a></p><h1 id="c69e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">1.2现实世界/业务目标和约束</h1><ol class=""><li id="3a4e" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">错误分类的代价可能非常高。</li><li id="415c" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">没有严格的延迟问题。</li><li id="e23b" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">可解释性是部分重要的。</li></ol><h1 id="91f2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">2.机器学习问题</h1><h1 id="7afa" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">2.1数据</h1><h1 id="9ff5" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">数据概述</h1><ul class=""><li id="dff2" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq kw js jt ju bi translated"><strong class="jf hj">数据将在2个TAR文件中扩展:</strong></li></ul><ol class=""><li id="81cf" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">一个文件夹将包含PNG图像，这将是x射线。</li><li id="4fdd" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">另一个有XML报告(一个报告可以关联多个图像)</li></ol><ul class=""><li id="8e5e" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">Posts.xml的大小—14.6 GB XML报告文件夹中的文件数= 3955</li><li id="1106" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">XML报告文件夹中的文件数= 3955</li><li id="2359" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">我们使用的数据框架有5栏:“图像”、“比较”、“指示”、“发现”、“印象”</li></ul><p id="bc7b" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">数据字段解释</strong></p><ul class=""><li id="1b4a" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">数据集包含3955行。表中的列有:</li></ul><ol class=""><li id="4542" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">图像—包含与报告相关的所有图像的路径(输入变量)</li><li id="6598" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">比较—包含关于报告的不同图像的注释</li><li id="cfa1" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">指示—包含建议使用x射线的原因描述。</li><li id="b68f" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">发现——x射线图像的初步发现。</li><li id="7595" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">印象—关于x射线的详细信息(目标变量)</li></ol><ul class=""><li id="cef3" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated"><strong class="jf hj">数据点数= 3955 </strong></li></ul><h1 id="4df3" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">2.2将现实世界的问题映射到机器学习问题</h1><h1 id="ca9d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">2.2.1机器学习问题的类型</h1><ol class=""><li id="3fea" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">这个案例研究基本上是基于给定一个输入图像生成一个文本。具体来说，我们希望生成一份给定胸部x射线图像的医疗报告。</li><li id="1ce0" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">这属于视觉语言任务，是计算机视觉领域和自然语言处理领域的混合。</li></ol><h1 id="d89e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">性能指标</h1><p id="7c8d" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">我们将在此评估中使用的指标是BLEU分数。</p><p id="e5bf" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">Bleu是机器翻译最常用的度量标准。它使用一种叫做修正精度的东西来计算分数，这个分数介于0-1之间，1表示完全相同或完美，0表示没有共同点。</p><p id="daf7" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">顾名思义，修改后的精度用于克服正常的<br/>精度，计算如下</p><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es la"><img src="../Images/f68d32699e807edafc9a2321520d5079.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/0*OfJfglDsFUCvq2wk.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">精确</figcaption></figure><p id="088d" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">候选翻译是我们模型的输出/预测，参考<br/>翻译是我们拥有的输入句子。<br/>让我们举个例子，计算一下候选<br/>翻译的精度</p><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es lm"><img src="../Images/f2eea088443a136f69b25f9ba4e32bac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/0*Ug4_6FG1SSEFUbUN.png"/></div></figure><p id="5474" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">候选项1的精度是2/7 (28.5%) <br/>候选项2的精度是1(100%)。<br/>但我们知道这些结果并不充分。<br/>所以我们修改如下:</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/5a6608537e3f130479e0569963c51d97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mBzLgWsCme2kyNUlhX7X-w.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">修正精度</figcaption></figure><p id="5287" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这里，n-gram是在n通常被取为4时要考虑的单词长度。1克将为每个窗口考虑1个字，2克将取<br/> 2个字，以此类推。<br/>计数夹是:</p><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es ls"><img src="../Images/7970ea1330bf09a29001d21b71130f47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*EyqLpvBj4Gi73Q1laUjn_g.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">计数剪辑</figcaption></figure><p id="84f0" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们首先使用以下步骤计算任何n元文法的计数剪辑:-</p><ul class=""><li id="f015" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">步骤1:统计候选n元语法<br/>在任何单个引用翻译中出现的最大次数；这被称为计数。</li><li id="fee0" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">第二步:对于每个参考句子，统计一个<br/>候选n元语法出现的次数。由于我们有三个参考翻译，我们<br/>计算Ref 1计数、Ref2计数和Ref 3计数。</li><li id="cd8b" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">步骤3:在任何<br/>引用计数中取n元文法出现的最大数量。也称为最大引用计数。</li><li id="bd5e" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">步骤4:取最小的计数和最大的引用计数。也称为计数剪辑，因为它通过最大引用计数剪辑每个候选字的总计数</li><li id="f70d" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">第五步:将所有这些剪辑计数相加。</li></ul><p id="2809" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">现在只需输入值，您将获得修改后的精度，但是如果<br/>翻译太长或太短怎么办？？<br/>过长的翻译在默认情况下通过使用计数剪辑由修改的精度分数<br/>处理。对于太短的翻译，我们引入简洁惩罚。<br/>当候选翻译长度与任何参考翻译长度的<br/>相同时，简洁罚分(BP)将为1.0。最接近的参考句子<br/>长度是“最佳匹配长度”</p><p id="25c9" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">BP是指数衰减，计算如下</p><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es lt"><img src="../Images/15f1e717337d9b5771b213aa97e58340.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*_x1MqVefYYqh81W0iP7rpA.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">简短惩罚</figcaption></figure><p id="efd0" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">参考译文中的r-字数<br/>候选译文中的c-字数</p><p id="e9f7" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">注意:</strong>无论是简洁惩罚还是修正的n-gram精度长度<br/>都没有直接考虑源长度；相反，他们只考虑目标语言的<br/>参考翻译长度的范围。</p><p id="021c" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">最后，我们计算BLEU</p><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es lu"><img src="../Images/a6aecdb79c2a8db976ac9477544be07f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*7IbLiFDkisprINiXtA6yrg.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">最终BLEU分数</figcaption></figure><p id="3cd8" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">BP-bristy penalty<br/>N:N-gram的数量，我们通常使用单gram、双gram、3-gram、4-gram <br/> Wn:每个修正精度的权重，默认情况下N是4，Wn是1/4=0.25 <br/> Pn:修正精度</p><p id="7c97" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">参考博客:</strong><a class="ae kv" href="https://towardsdatascience.com/bleu-bilingual-evaluation-understudy-2b4eab9bcfd1" rel="noopener" target="_blank">https://towards data science . com/bleu-双语-评测-替角-2b4eab9bcfd1 </a></p><p id="d851" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">BLEU评分是由Kishore Papineni等人在其2002年的论文《BLEU:一种自动评估机器翻译的方法》中提出的。</p><p id="52c7" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">研究论文链接:</strong><a class="ae kv" href="https://www.researchgate.net/publication/2588204_BLEU_a_Method_for_Automatic_Evaluation_of_Machine_Translation" rel="noopener ugc nofollow" target="_blank">https://www . Research gate . net/publication/2588204 _ BLEU _ a _ Method _ for _ Automatic _ Evaluation _ of _ Machine _ Translation</a></p><p id="070b" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">我们将使用nltk库来计算BLEU分数。</strong></p><h1 id="47b1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.探索性数据分析</h1><h1 id="c99e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.1数据加载</h1><h1 id="b85c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.1.1下载数据并提取TAR文件</h1><p id="b247" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">数据以Torrent的形式提供，因此我们将使用Google Colab将Torrent下载到Google Drive。</p><p id="c134" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们可以用命令行使用<a class="ae kv" href="https://transmissionbt.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj">传输</strong> </a>客户端下载torrent文件。它支持<strong class="jf hj">命令行界面</strong>，我们所要做的就是安装它，它会下载我们的种子文件。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">传输-cli</figcaption></figure><p id="1efe" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这样就会下载安装<a class="ae kv" href="https://transmissionbt.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj">传输</strong> </a> <strong class="jf hj"> </strong> BitTorrent客户端。</p><p id="5a40" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">然后我们将复制torrent文件链接使用transmission-cli下载torrent。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">传输cli</figcaption></figure><p id="bd6a" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">以上代码将从给定的种子文件链接下载种子文件到我的Google Drive。</p><p id="9a8f" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">现在我们有了文件，我们必须提取它，所以我们将使用<a class="ae kv" href="https://pypi.org/project/patool/" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj"> patoo </strong> l </a>库来提取。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">数据摘录</figcaption></figure><h1 id="9bc2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.1.2解析xml文件</h1><p id="cb9c" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">我们的报告是xml文件，我们必须从中提取信息。XML是一种固有的分层数据格式，用树来表示它是最自然的方式。为此，它有两个类——Element tree将整个XML文档表示为一棵树，Element表示这棵树中的一个节点。与整个文档的交互(读写文件)通常在ElementTree级别完成。与单个XML元素及其子元素的交互是在元素级别完成的。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">提取列</figcaption></figure><p id="4b36" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">在上面这段代码中，我们遍历了目录中的每个文件，并提取了ID、比较、指示、发现、图像名称字段。</p><p id="f42d" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">现在我们将从这些提取的列中制作数据帧，我们的初始数据帧有<strong class="jf hj"> 3955个数据点。</strong></p><h1 id="4b9f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">每列3.2 EDA</h1><h2 id="91ac" class="lx ig hi bd ih ly lz ma il mb mc md ip jk me mf it jm mg mh ix jo mi mj jb mk bi translated">3.2.1列图像:</h2><p id="2d72" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">图像列包含与每个报告关联的图像名称，多个图像可以与单个报告关联。</p><p id="3a1a" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">每份报告图像数量的平均值为:1.8887484197218711 <br/>每份报告图像数量的中位数为:2.0 <br/>每份报告图像数量的最大值为:5 <br/>每份报告图像数量的最小值为:0</p><p id="5849" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">从上面的评估中，我们发现我们最多有5个图像与单个报告相关联，并且我们的数据中没有任何图像与某些报告相关联。平均值更接近于2，中位数也是2。</p><p id="9c5e" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">因此，让我们看看与每个报告相关的图像数量。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ml"><img src="../Images/0d88d6dcd2aa4dd32d20e8f0c4fb73b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*feQSq56JqEB0xrkuz5_khw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">字数</figcaption></figure><ul class=""><li id="cd8d" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">宽度和高度的EDA</li></ul><p id="15e0" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">平均高度:531.6648922357829 <br/>平均高度:512.0 <br/>平均宽度:512 <br/>平均宽度:512.0</p><h2 id="006e" class="lx ig hi bd ih ly lz ma il mb mc md ip jk me mf it jm mg mh ix jo mi mj jb mk bi translated">3.2.2列比较:</h2><p id="46fa" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">在我们的印象栏中有2389个无值或垃圾值。所以它没有给我们提供足够的信息。所以我们会放弃这个。</p><h2 id="6034" class="lx ig hi bd ih ly lz ma il mb mc md ip jk me mf it jm mg mh ix jo mi mj jb mk bi translated">3.2.3列指示:</h2><pre class="lb lc ld le fd mm mn mo mp aw mq bi"><span id="70a9" class="lx ig hi mn b fi mr ms l mt mu">Chest pain                               129<br/>XXXX                                     114<br/>Chest pain.                               88<br/>NaN                                       86<br/>chest pain                                62<br/>XXXX.                                     58<br/>XXXX-year-old female with chest pain.     39<br/>XXXX-year-old male with chest pain.       38<br/>Dyspnea                                   37<br/>Shortness of breath                       31<br/>dyspnea                                   29<br/>Shortness of breath.                      23<br/>XXXX-year-old female with chest pain      19<br/>XXXX-year-old woman with chest pain.      19<br/>XXXX-year-old female with XXXX.           19<br/>Name: INDICATION, dtype: int64</span></pre><p id="e67c" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这些是指示栏中出现的前10个值，我认为这些也不会证明有任何价值，所以我放弃了它。</p><h2 id="fea7" class="lx ig hi bd ih ly lz ma il mb mc md ip jk me mf it jm mg mh ix jo mi mj jb mk bi translated">3.2.4列结果:</h2><p id="0d24" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">发现列有514个Nan列，所以如果我删除这些列，将会有更少的数据点来构建我的模型。所以也放弃这个专栏。</p><h2 id="8cb1" class="lx ig hi bd ih ly lz ma il mb mc md ip jk me mf it jm mg mh ix jo mi mj jb mk bi translated">3.2.5列印象(目标):</h2><p id="5451" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">策划20大印象。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mv"><img src="../Images/9393960be5b9a7ba21845f924626e620.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*29pweYFPb4aN92oqusu5sQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">前20个印象</figcaption></figure><p id="2501" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">从上面的图中我们可以看到，印象栏中的Nan非常少，因此我们不会删除它们，而是用“无印象”字符串来替换它们。</p><p id="f000" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">单印象中的平均字数为:<strong class="jf hj"> 10.493378343287457 </strong> <br/>单印象中的平均字数为:<strong class="jf hj"> 5.0 </strong> <br/>单印象中的最大字数为:<strong class="jf hj"> 130 </strong> <br/>单印象中的最小字数为:<strong class="jf hj"> 1 </strong></p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mw"><img src="../Images/10df56e7e0f3b733a196a8e8f60c6b01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p1CdO56KPFze98U3gyWFDA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">每句话的字数</figcaption></figure><p id="cf40" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">因此，从上面我们可以观察到，每个印象中的单词数在2-30之间，因此我们可以从我们的模型中期待短句。</p><h1 id="9e7b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">EDA的发现:</h1><ol class=""><li id="4371" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">我想我将只保留印象和图像列，其他人有许多空值。</li><li id="dca6" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">大多数报告是正常的，只有一些是不正常的，所以数据偏差是存在的。</li><li id="7f09" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">主要是每个报告有2个图像，所以我只会通过2个图像，如果少于这一点，然后我会重复第一个图像本身两次。有3个和4个图像的每张图片出现较少，我会保留前两个和丢弃其余的。只有一个包含5幅图像的报告，因此将执行与2–4幅图像相同的操作。,</li></ol><h1 id="20ac" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.3数据清理</h1><p id="61a5" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">删除列，因为它有许多空值。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">删除列</figcaption></figure><h1 id="ed70" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.3.3最常用的单词</h1><p id="0743" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">我们将绘制一个单词云，它将显示出现最多的单词，字体大小与该单词的出现次数成正比。</p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mx"><img src="../Images/cff37765275572bddc6bec37e9a7978c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*el3si3cj8zM4HT_rPO9ZRA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">词云</figcaption></figure><h1 id="4ffe" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.4数据预处理</h1><p id="0af3" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">在此，我们将以下列方式预处理输入文本:</p><ol class=""><li id="adb5" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">我们将替换“XXXX”字符串，它出现在许多印象中，没有任何意义。</li><li id="fba3" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将删除所有其他小型和大写字母。</li><li id="b37e" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">解收缩文本:基本上是从收缩状态展开单词，例如:不会→不会，不能→不能等。</li></ol><p id="8a27" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">4.将制表符和多余的空格转换成一个简单的空格。</p><h1 id="302b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.4.2预处理图像列</h1><ol class=""><li id="61dd" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">每个数据点仅保留前两幅图像。</li></ol><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">每个数据点2幅图像</figcaption></figure><p id="77be" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">在上面这段代码中，我们对图像列的每个数据点进行切片，这是一个图像名称的列表，长度为2，然后将此操作应用于整个列</p><p id="8d27" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">2.对于每个数据点只有一个图像的行，我们复制该图像两次。</p><h1 id="e761" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.4.3在IMPRESSION列中添加特殊字符串</h1><p id="d8c3" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">在impression列中插入起始'<start>'和'<end>'字符串，让模型知道什么是标记的开始和结束，这将有助于生成字幕/印象。</end></start></p><p id="5339" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们将制作3个新列表，如下所示:</p><p id="8b55" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">原始_序列:</strong> &lt;开始&gt;无急性肺部发现&lt;结束&gt;<br/>T5】输入_序列: &lt;开始&gt;无急性肺部发现<br/> <strong class="jf hj">输出_序列:</strong>无急性肺部发现&lt;结束&gt;</p><p id="2e0d" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我将在构建模型时展示它的用途。</p><h1 id="75ad" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">3.4.4标记化。</h1><p id="b2e2" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">当处理文本时，我们必须做的第一件事是在将文本输入模型之前，想出一个策略将字符串转换成数字(或“矢量化”文本)，这就是Tokenizer发挥作用的时候了。</p><p id="3b62" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">标记化是将单词转换成整数的过程，其中每个单词对应于语料库中的唯一单词。Tensorflow内置了tokenizer，我们只需初始化该函数，它将为我们标记输入。</p><p id="1a00" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">在我们对输入句子进行标记后，我们必须使所有输入的大小相同，为此我们将填充序列，填充可以通过两种方式完成:预填充(在序列开始处填充零)或后填充(在原始序列结束后填充零)</p><p id="fc1d" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">最初，我将填充的最大序列长度限制为单词长度的99%，即语料库中所有单词的53%，最后我使用了100%，即123，因此每个序列的长度为123，填充类型为后填充。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">标记化</figcaption></figure><p id="08c7" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">标记化后的示例。</p><pre class="lb lc ld le fd mm mn mo mp aw mq bi"><span id="3395" class="lx ig hi mn b fi mr ms l mt mu">sample input sequence [ 1 12 18 88  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]</span><span id="1d7b" class="lx ig hi mn b fi my ms l mt mu">sample output sequence [12 18 88  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0<br/>0  0  0]</span></pre><h1 id="7dc7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.机器学习模型</h1><h1 id="8afe" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.1将数据分为训练、验证和测试。</h1><p id="14f9" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">我们要做的第一件事是将数据分为训练集、验证集和测试集。我们将使用'<strong class="jf hj">sk learn</strong>' train _ test _ split来拆分我们的数据。</p><p id="c0c6" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们将把我们的数据集分成总数据的训练(90%)、验证(9%)、测试(1%)和洗牌。</p><p id="a767" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">Sklearn的train_test_split将数据分成两部分(训练和测试)，但我们也希望验证，所以我们首先将数据分成90%(训练):10%(初始测试)，并将初始测试子集的10%分成99.98%(验证)和0.019%(最终测试)数据集。</p><p id="388f" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我将测试规模保持得很小，因为我们只需要显示几个例子作为输出，但是更多的验证数据将有助于训练模型(当然是间接的)。</p><h1 id="9e1a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.3数据扩充</h1><p id="0fce" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">数据扩充是生成略有不同的训练数据副本的过程，以使模型的性能在验证和测试集上保持稳定。</p><p id="848c" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们增加输入图像也是因为我们没有太多的数据来训练。</p><p id="5470" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">因此，下一个问题是，我们如何在训练时将增强应用于图像？？答案很简单，在将图像传递给模型之前，我们将应用下面提到的任意一个随机增强。通过这样做，模型将在每次获取数据点时看到增强的/不同的图像，因此这将帮助他减少过拟合，并且可以很好地推广。</p><p id="2c66" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们正在使用的增强功能有:</p><ol class=""><li id="fd4d" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">翻转:从左向右或水平翻转图像。</li><li id="4470" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">上下或垂直翻转图像</li><li id="3a0c" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">浮雕图像，并用原始图像覆盖结果。</li><li id="cda2" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">检测具有特定方向的边缘，并在黑白图像中标记它们，然后用原始图像覆盖结果。</li><li id="149c" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">锐化图像</li></ol><p id="1da6" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">为了对图像执行上述增强，我们将使用<a class="ae kv" href="https://imgaug.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj"> imgaug </strong> </a> <strong class="jf hj"> </strong>库，如下所示:</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">增加</figcaption></figure><h1 id="d641" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.4加载和预处理图像</h1><p id="3541" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">为了加载和预处理图像，我们将使用名为<a class="ae kv" href="https://pypi.org/project/opencv-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj"> opencv </strong> </a> <strong class="jf hj">的计算机视觉库。</strong></p><p id="57dc" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们将定义一个函数，该函数将在调用时加载预处理和增强图像，并返回最终的图像数组。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">预处理图像</figcaption></figure><p id="a01a" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">在上面的代码中，我们遵循以下步骤。</p><ol class=""><li id="8f59" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">我们正在使用<code class="du mz na nb mn b">cv2.imread</code>方法加载图像</li><li id="2c1e" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们正在使用<code class="du mz na nb mn b">cv2.resize</code>根据模型的需要调整图像的大小。</li><li id="39de" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">然后，我们在0-1之间选择一个随机数，并相应地应用任何一个增量。</li><li id="b512" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">最后我们对图像进行归一化处理，使用<code class="du mz na nb mn b">cv2.normalize</code>对图像的像素值进行压缩/归一化，范围从0–255到0–1，使计算更简单，计算更快。</li></ol><h1 id="3e10" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.5数据加载器功能:</h1><p id="3cb0" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">顾名思义，我们正在创建一个将继承<code class="du mz na nb mn b"><a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence" rel="noopener ugc nofollow" target="_blank">tf.keras.utils.Sequence</a></code>功能的函数，这是一种更安全的多处理方式。这种结构保证了网络在每个时期的每个样本上只训练一次，这与发电机的情况不同。</p><p id="ac85" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">每个<code class="du mz na nb mn b">Sequence</code>都必须实现<code class="du mz na nb mn b">__getitem__</code>和<code class="du mz na nb mn b">__len__</code>方法。如果你想在不同时期之间修改你的数据集，你可以实现<code class="du mz na nb mn b">on_epoch_end</code>。方法<code class="du mz na nb mn b">__getitem__</code>应该返回一个完整的批处理。</p><p id="65ab" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">让我们深入研究一下<strong class="jf hj">数据加载器</strong>类的每个函数。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="d23a" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">该函数将定义数据加载器的长度。</p><p id="f292" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">注意:</strong>当您调用<code class="du mz na nb mn b">len(dataloader)</code>时，它将返回dataloader的长度，而不是您在其中传递的训练样本的长度。例如:假设你有256个数据点，你的批量大小是8，那么这个函数将返回256//8，也就是32注256。</p><p id="d9cf" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi">2.</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="08e4" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">在这个函数中，我们定义了我们想要在一个时期结束时做什么，这个函数将在一个时期结束后被调用。我们只是在每个时期后改变数据点的索引，以便模型在每个时期后看到不同的组合数据点。</p><p id="0075" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi">3.</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="a057" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这个函数将加载增强的、标准化的图像，我们调用load_image1函数，它与我之前解释的<code class="du mz na nb mn b">preprocess_img</code>函数相同。</p><p id="963a" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi">4.</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">获取批量项目</figcaption></figure><p id="166c" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这是批量加载图像、输入和输出张量并返回(input，target)元组的函数。</p><p id="2e9f" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">它将开始索引作为输入，并从该索引返回批量输出，例如:如果函数中的“I”为4，批量大小为16，则开始索引将为4*16，直到(4+1)*16，因此它将从64–80获取数据点，这是一个16的批量。把它们堆起来，然后归还。</p><h1 id="09b6" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.6制作模型架构。</h1><p id="db81" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">我们要遵循的模型架构称为<strong class="jf hj">带注意机制的编码器-解码器</strong>模型。</p><p id="19bb" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">编码器-解码器模型最初是为机器翻译开发的，其中编码器和解码器都包含递归神经网络(LSTM，GRU)。编码器部分对输入序列进行编码，然后使用其内部状态将处理后的信息传递给模型的解码器部分，解码器然后处理输入并生成转换后的输出。</p><p id="cc1f" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这些模型的问题在于，编码器输出除了最后一个lstm隐藏和输出状态之外什么也不是，不能捕捉要翻译的整个输入句子的关键。为了解决这个问题，研究人员引入了一种有效地将信息从编码器传递到解码器的方法。那种机制叫做'<strong class="jf hj">注意</strong>机制。这个想法是在2015年通过联合学习对齐和翻译论文的<a class="ae kv" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank">神经机器翻译中引入的。在下一节中，我们将详细介绍该模型的所有部分。</a></p><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nc"><img src="../Images/5ca8242cbee941de575c6994cc6eda92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PPTZFFcLniUYVU4mHWenPg.jpeg"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">注意的编码器-解码器模型</figcaption></figure><p id="b244" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">上图描述了编码器-解码器模型的工作原理，注意机制位于其上。</p><p id="3269" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们正在修改编码器部分，并将其替换为预训练的DenseNet121模型，该模型是一个卷积神经网络，而不是递归神经网络，它将图像作为输入，提取感兴趣的特征或区域，并将其进一步传递给注意机制。</p><p id="34a4" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">现在让我们深入模型的各个部分。</p><h1 id="bcf9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.6.1加载预训练Chex-Net模型。</h1><p id="b1f5" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">这个模型是在<a class="ae kv" href="https://arxiv.org/abs/1711.05225" rel="noopener ugc nofollow" target="_blank"> CheXNet:利用深度学习对胸部X射线进行放射科医生级别的肺炎检测</a>中介绍的</p><p id="6bbc" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">在这个实验中，他们采用了densenet121，这是一个121层的卷积神经网络，并用imagenet权重对其进行初始化，并在<a class="ae kv" href="https://arxiv.org/abs/1705.02315" rel="noopener ugc nofollow" target="_blank"> ChestX-ray14数据集</a>上对其进行训练。他们试图根据输入图像将图像分为14类或14种疾病，因此这是一个多标签分类问题。他们使用的度量标准是f1-score，并将模型在测试数据上的性能与4名放射科医生进行了比较，这4名放射科医生手动标记疾病，模型的表现优于他们。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">chexnet</figcaption></figure><p id="4866" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们使用densenet121并添加Chex-Net模型的预训练权重。我们必须定义类=14，因为该模型是在14类多标签分类任务上训练的。我们获取的图像高度和宽度是<strong class="jf hj"> (224，224，3) </strong>，这与densenet默认的输入形状相同。</p><p id="2dc4" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">权重_链接</strong>:<a class="ae kv" href="https://github.com/brucechou1983/CheXNet-Keras" rel="noopener ugc nofollow" target="_blank">https://github.com/brucechou1983/CheXNet-Keras</a></p><p id="614e" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">加载权重后，我们将从预训练模型中移除最后完全连接的层和全局平均池层。这使得最后卷积块的输出在级联或残差块之后，并应用批量归一化和relu激活作为我们的最终输出。该模型的输出将作为我们图像的特征向量。</p><h1 id="e1fd" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">CNN _编码器</h1><p id="8ad8" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">这是我们模型中的编码器模块，在这一层中，我们将调用我们的图像特征提取模型(chexnet ),并对其输出进行整形，使其看起来像序列编码器/LSTM (batch_size，hidden_state_size，units)的输出。</p><p id="b378" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">例如:我们的图像提取模型的输出是来自较低卷积层的形状(batch_size，7，7，1024)。我们将这个输入压缩为(batch_size，49，1024)作为编码器的输出。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">编码器</figcaption></figure><h1 id="029c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">注意事项:</h1><p id="cead" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">这部分将告诉lstm哪个单词从图像的哪个区域产生，这就是为什么它被命名为注意机制。</p><p id="f064" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">有两种类型的注意机制。</p><ul class=""><li id="242f" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated"><strong class="jf hj"> Bahdanau注意</strong></li></ul><p id="a448" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这种注意力机制是在论文《通过联合学习对齐和翻译的<a class="ae kv" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank">神经机器翻译》中介绍的。它是为序列到序列的机器翻译而引入的。让我们假设我们有一个将英语句子翻译成法语的任务。因此，现在我们对输入和输出文本进行了标记化和填充，以备将来使用。</a></p><ol class=""><li id="2993" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">我们的英语句子将一个字一个字地进入编码器部分，如图所示'<em class="jv">注意编码器-解码器模型'</em>。以上这些步骤被称为时间步骤。之后，我们将传递来自嵌入层的输入，我们将通过反向传播来学习。此后，每个输入进入lstm单元，并且该lstm的隐藏和输出状态将改变/更新。这个过程将对每个单词持续进行。因此，当我们的输入语句结束时，我们将最终的LSTM隐藏和输出状态作为编码器的输出。</li><li id="1bbf" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">接下来是注意部分，现在我们有lstm输出状态、隐藏状态和单元状态作为编码器输出。</li><li id="3013" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将使用隐藏的编码器和单元状态初始化解码器模型的lstm。</li><li id="04fd" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">首先，注意力将把编码器输出状态和解码器隐藏状态作为输入。然后它将计算它们之间的相似性。通过应用下面所示的操作，这些隐藏和输出状态将生成一个相似性得分。</li></ol><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">相似性</figcaption></figure><p id="2d42" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">5.然后，我们从softmax函数传递这个分数，该函数将把这个分数从0-1之间的范围转换。这种相似性的形状将等于编码器的隐藏大小，我们将称之为注意力权重，因为它将告诉我们在生成该输出时，它对每个编码器隐藏状态给予了多少注意力。比方说，隐藏大小为49，第31个索引处的值为<strong class="jf hj"> 0.88 </strong>，因此我们知道这在生成结果时贡献更多，因为由于softmax函数，通过将所有输出相加，最终概率将为1。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">注意力权重</figcaption></figure><p id="7027" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">6.然后，我们将该注意力权重与编码器输出状态相乘，并将它们相加以生成上下文向量，以将其传递给解码器lstm。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">上下文向量</figcaption></figure><ul class=""><li id="e414" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated"><strong class="jf hj"> Luong注意</strong></li></ul><p id="65dd" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">Luong的注意力和Bahdanau的注意力没有太大的不同。过程是一样的。主要区别是:</p><ol class=""><li id="5340" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">Luong介绍了3种计算相似性得分的技术，而bahdanau只有一种方法。这些方法如下图所示。</li></ol><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es nd"><img src="../Images/cec25097394a1fb8e0e43708be98bbc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*kyxYIgqjdZLCUPObIzR_ww.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">注意类型</figcaption></figure><p id="09d3" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这里得分指的是相似度，h_t是目标隐藏状态，h_s是源输出状态，Wa和Va是权重矩阵。</p><p id="ce94" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">2.我们在案例研究中使用了Luongs串联注意力方法，该方法与Bahndanus注意力相似度计算方法相同。</p><p id="364c" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">3.在计算相似性分数之后，计算注意力权重和上下文向量与bahndanau注意力相同。</p><p id="d0a6" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">4.在计算注意力时，Bahndanus使用lstm的输出，该输出是在先前的时间步中生成的，其中Luong的注意力将使用当前的时间步隐藏状态。</p><h1 id="b591" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">解码器</h1><p id="0555" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">解码器是模型中发生转换的部分，在我们的例子中，解码器包含嵌入、LSTM和末尾的密集层(没有任何激活)。</p><p id="f89a" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">解码器会在每一步中提取当前单词并生成下一个单词。让我们一步一步地看看解码器是如何工作的。</p><p id="c291" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">请记住，在我们的标记化中，我们对input_sequence和output_sequence做了不同的处理，它们将在这里使用，让我们通过一个例子来理解这一点。</p><p id="ec48" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">原_序</strong> : &lt;开始&gt;无急性肺部发现&lt;结束&gt;</p><p id="27b1" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">输入_序列</strong> : &lt;开始&gt;无急性肺部发现</p><p id="cd5c" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj">输出_序列</strong>:无急性肺部发现&lt;结束&gt;</p><p id="a5ef" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">因为我们知道解码器会一个字一个字地接受输入，所以我们使用教师强制来决定解码器的下一个输入。</p><p id="7ac4" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">教师强制是将目标单词作为下一个输入传递给解码器的技术。</p><p id="1698" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">因此，特殊标记'<start>'将从INPUT_SEQUENCE进入解码器，我们期望' No '作为解码器的输出，这也是第一时间步OUTPUT_SEQUENCE中的第一个字。此后，输入序列的第二个字“否”将作为解码器的输入，我们期望输出序列的第二个字“急性”作为输出。</start></p><p id="fd34" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">对于每个输入序列，我们将解码器的隐藏和单元状态初始化为来自正态分布的随机数，因为输入在图像之间是不相关的。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">解码器的一步</figcaption></figure><p id="2fb9" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这是名为“one_step decoder”的解码器类中的一个函数，它将为每个时间步长运行123次，这是我们在填充输入时决定的max_sequence长度，并按如下步骤执行操作。</p><ol class=""><li id="15e9" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">它将从INPUT_SEQUENCE中取出第一个字，并将其传递给嵌入层。在我们的例子中是256。</li><li id="1f1b" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">然后，来自先前时间步长的解码器隐藏状态连同编码器输出状态将被传递到我们在上面解释过的注意类，并且它将返回给我们context_vector和注意权重(<strong class="jf hj">注意:</strong>我们将不使用注意权重，而训练仅使用上下文向量)。</li><li id="86e0" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">现在，我们将上下文向量与嵌入的输出连接起来，并将其传递给lstm，我们将用先前隐藏的时间步长和单元状态来初始化lstm。并生成当前时间步长输出、隐藏和单元格状态。</li><li id="283b" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将传递来自全连接密集层的lstm输出，其单位与vocab_size相同。稍后我们将从这个密集层的输出中提取预测的单词。</li><li id="a6c6" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将从该函数返回当前步骤lstm输出、其隐藏状态、其单元格状态和注意力权重。</li><li id="aad0" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">对于下一步，所接收的输出将被用作lstm的输入，作为先前状态隐藏和单元状态。这样，序列信息保留在解码器的lstm单元中。</li></ol><p id="4eb7" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">对于每个时间步长，我们将堆栈从one_step_decoder函数接收的输出，并将其作为最终的编码器输出返回。</p><h1 id="11c7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.7损失函数和优化器</h1><p id="9c6a" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">我们使用<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy" rel="noopener ugc nofollow" target="_blank">稀疏分类交叉熵</a>，因为我们已经编码出真正的标签。</p><p id="6ce5" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">在正常的分类交叉熵中，这些标签将是一个热编码，这不是我们已经标记化标签的使用情况。</p><p id="67f4" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">例如:</p><p id="a233" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">y_true: [[1，0，0，0]，[0，1，0，0]，[0，0，0，1]] —因为我们真正的标签是单标签，并且我们有多类分类问题，我们也可以这样写。</p><p id="80c7" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">y_true: [0，1，3] —它只是真实标签的索引。通过编码成这种类型，我们在计算损失时节省了大量的存储器，当数量类很大时，因为最终唯一的一个值将对损失项rest有贡献，将变成零。</p><p id="ca41" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">如果你看到我们使用记号化器，我们也把我们的句子编码成记号，就像这样。</p><p id="7cbe" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这些整数中的每一个都可以被认为是index，其中特定的值是one in one hot setting，并且该特定数组的大小将等于词汇表的大小。</p><p id="8c32" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">正如你所看到的，我们通过添加零来填充序列。这些零不应该干扰损失值，因此我们必须找到一种方法来克服这个问题。为此，我们将使用SparseCategoricalCrossentropy的sample_weight参数，该参数让我们定义每个令牌的样本权重，因此首先我们将发现令牌/标签是否为零，如果它不为零，那么我们将把它的权重指定为1，否则样本权重将为零，因此这些值不会干扰我们的损失计算。</p><p id="384d" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">我们正在使用的优化器是<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj">亚当</strong> </a>，学习率为<strong class="jf hj"> 0.00001。</strong></p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">优化器和损失函数</figcaption></figure><h1 id="799e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.9定制培训</h1><p id="9832" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">我们已经编写了自己的自定义循环，如下所示。</p><ul class=""><li id="8d24" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">我们将运行n个时期的循环。</li><li id="d39a" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">在循环中，我们将使用枚举再次迭代我们训练数据加载器，我们将接收batch_number、inputs、target。</li><li id="dbc2" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">我们将输入和目标传递到train_step函数中，该函数将运行我们的模型1批次/步骤，计算损失并应用梯度更新。</li></ul><p id="9d15" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">train_step函数执行以下操作:</p><ol class=""><li id="a5f3" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">首先，它将重置解码器的隐藏单元状态。</li><li id="d5bf" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">它将从我们的编码器部分传递图像1和图像2数组，这将为我们提供特征向量。</li><li id="41a5" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">然后，我们连接这些特征向量，并添加丢失以减少过拟合。</li><li id="c784" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将input_sequence、连接的特征和解码器隐藏的、我们初始化的单元状态传递到解码器中。</li><li id="e1a7" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">解码器将在内部为每个时间步长运行，并使用image_features和input_sequence预测下一个单词，然后将该批次的最终预测结果返回给我们。</li><li id="6c6a" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将把解码器输出和真实输出传递到损失函数中。</li><li id="1ce2" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们必须计算每个标记的损失，因为当我们计算梯度时，我们需要每个标记的损失。我们单独添加每个令牌的损失</li><li id="2875" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将计算的损失除以时间步长，得到该批次的最终损失。</li><li id="fae0" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">然后，我们将计算梯度，并将这些梯度和可训练变量一起应用于优化器。</li><li id="b4b0" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">最后，我们将总损失作为输出返回。</li></ol><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">训练步骤</figcaption></figure><ul class=""><li id="20e3" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">我们得到该批次的损失，然后将该损失加到模型的总损失中。</li><li id="0123" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">当我们计算通过验证数据进入validation_Step。validation_step与train_step函数相同，只是在此步骤中我们不更新模型权重，我们只是预测输出并报告验证损失以用于模型评估。</li><li id="eadb" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq kw js jt ju bi translated">在时段完成后，我们通过将增加的损失除以总时间步长来保存损失，并且我们将使用该类内的on_epoch_end函数来混洗列车数据加载器的索引。</li></ul><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div></figure><ul class=""><li id="a6f6" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">然后，我们将使用自定义学习率降低器，如果验证损失在最后3个时期没有变化，则降低学习率</li></ul><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">降低lr</figcaption></figure><ul class=""><li id="24fb" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">我们将实施定制的提前停止回调，它将检查6个时期的验证损失是否没有变化，这将停止训练。</li></ul><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">提前停止</figcaption></figure><h1 id="63d2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.10绘制损失图</h1><figure class="lb lc ld le fd lf er es paragraph-image"><div class="er es ne"><img src="../Images/76d92f46e15b20260cf3181ecf8f97ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*ErccyH2IWNAVLexXy1O7RQ.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">损耗图</figcaption></figure><h1 id="9be2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">我们的模型运行了<strong class="ak"> 34 </strong>个周期，其训练损失:<strong class="ak"> 0.433114 </strong>和val_Loss : <strong class="ak"> 0.387015 </strong></h1><h1 id="7104" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.11模型评估</h1><p id="03c2" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">Evaluate step与我们的train_step没有太大的不同，只是我们在这里没有使用教师强制。</p><ol class=""><li id="4017" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">我们首先将输入图像传入编码器，并连接输出特征。</li><li id="a495" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">然后，我们初始化解码器lstm的隐藏状态和单元状态。</li><li id="11df" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">然后，我们将令牌<start>传递给解码器，这是我们的特殊令牌，类似于预测的开始。</start></li><li id="423a" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将为max_sequence_length运行for循环。</li><li id="9017" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">在for循环中，我们调用decoder类的one_step_decoder函数。通过传递开始令牌作为解码器输入、隐藏和单元状态以及编码器输出。</li><li id="ca47" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">从该函数返回，我们将接收预测、新更新的隐藏的解码器lstm的单元状态。</li><li id="898f" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将作为解码器输入隐藏的所有三个预测字和作为先前时间步长输出的单元状态再次传递给one_step_decoder函数，以生成下一个字，这将持续到max_seq_length的范围。</li><li id="fe45" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将保存注意力权重用于绘制注意力，并使用预测的<strong class="jf hj"> argmax </strong>来找到预测的单词。</li><li id="bd98" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">如果从我们的模型中预测到特殊记号<end>，我们将在中间停止训练。</end></li><li id="c2e1" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">此函数将返回图像的最终印象和注意力图的注意力权重。</li></ol><h1 id="7cf4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.12模型预测</h1><p id="42cd" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">在我们看到模型预测之前，让我们先来看看两个函数</p><ol class=""><li id="825b" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">Bleu_score:这个函数将给出1，2，3，4克的Bleu分数。我们使用nltk的bleu分数作为我们的用例。</li></ol><ul class=""><li id="d931" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">计算BLEU分数的方法不正确:</li></ul><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="b070" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">在上述代码中，引用指的是正确的翻译或基本事实，而翻译指的是模型、预测输出。当你按原样传递引用和翻译时，这个函数不会抛出错误，而是会给你好的结果，这就是发生在我身上的事情，我得到了整个数据的总bleu分数，0.80是非常好的，但我认为这个分数有些可疑，所以我在他们的函数实现中查找它。</p><p id="1b35" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">当你按原样传递这个函数时，它会将你的句子分解成字母而不是单词，我们的词汇量有限，只有26个字母，这个单词很有可能出现在翻译的句子中。这就是为什么它给了我这么好的分数。后来我改正了。</p><ul class=""><li id="728e" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq kw js jt ju bi translated">计算BLEU分数的正确方法。</li></ul><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">蓝色分数正确</figcaption></figure><p id="4c23" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">看看错误的和正确的之间的区别，这一个采取参考/基本事实的列表，因为可以有一个以上的参考句子，并且每个参考/基本事实也被分成单词列表，并且对于翻译，它采取翻译句子的单词列表。</p><p id="c534" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">2.剧情_注意:</p><p id="5445" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">Phis函数将图像、预测句子和注意力权重作为输入，并绘制注意力。</p><figure class="lb lc ld le fd lf"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">剧情关注</figcaption></figure><p id="9043" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">这里len_result是预测字符串的长度。我们正在迭代它。</p><ol class=""><li id="dc5e" class="jd je hi jf b jg kq ji kr jk kx jm ky jo kz jq jr js jt ju bi translated">首先，我们打开图像，然后使用函数get_concat_h将它们并排粘贴。</li><li id="7d7b" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">然后我们迭代结果的长度。</li><li id="e628" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们首先将注意力图数组调整为7，7数组，因为这是CHeXnet模型7，7，1024的最后一层的输出，然后我们将数组调整为49，1024，然后我们将产生49，2048的特征连接起来。所以现在我们再次分离它。</li><li id="e69e" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">当我们添加支线剧情时，要注意每个单词。</li><li id="dbe0" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我们将预测的单词设置为子情节的标题。</li><li id="0aa9" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">然后我们显示图像，然后在图像上画出我们的注意力，它将显示为灰色。</li></ol><h2 id="6d88" class="lx ig hi bd ih ly lz ma il mb mc md ip jk me mf it jm mg mh ix jo mi mj jb mk bi translated"><strong class="ak">部分结果:</strong></h2><ol class=""><li id="fdf0" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated"><strong class="jf hj">结果1 </strong></li></ol><pre class="lb lc ld le fd mm mn mo mp aw mq bi"><span id="0c20" class="lx ig hi mn b fi mr ms l mt mu">Real Caption: no acute cardiopulmonary findings chronic changes of emphysema and left basilar scarring<br/>Prediction Caption: no hypoinflation minimal acute recommended lungs a left are identified no cannot &lt;end&gt;<br/>BLEU score: 0.7071067811865476<br/>Cumulative 1-gram: 0.250000<br/>Cumulative 2-gram: 0.500000<br/>Cumulative 3-gram: 0.632878<br/>Cumulative 4-gram: 0.707107</span></pre><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mw"><img src="../Images/c3ab7941e9499026cbfb7e50cda09193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CyAY54P4wuR9Mp_hciH0gg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">注意力图1</figcaption></figure><p id="cf50" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj"> 2。结果2 </strong></p><pre class="lb lc ld le fd mm mn mo mp aw mq bi"><span id="ca10" class="lx ig hi mn b fi mr ms l mt mu">Real Caption: no acute findings<br/>Prediction Caption: no evidence have right nodules of chest &lt;end&gt;<br/>BLEU score: 0.6147881529512643<br/>Cumulative 1-gram: 0.142857<br/>Cumulative 2-gram: 0.377964<br/>Cumulative 3-gram: 0.526160<br/>Cumulative 4-gram: 0.614788</span></pre><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nf"><img src="../Images/450d6d92490fce3909792a73c3a7bbfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BU51u5zQNnW-0kkYenQYjw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">注意情节2</figcaption></figure><p id="41c6" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated"><strong class="jf hj"> 3。结果3 </strong></p><pre class="lb lc ld le fd mm mn mo mp aw mq bi"><span id="488f" class="lx ig hi mn b fi mr ms l mt mu">Real Caption: bilateral opacities most prominent in the lower lobes representing airspace disease or edema<br/>Prediction Caption: retained volumes curvature normal lung prominent normal volumes fractures disease disease &lt;end&gt;<br/>BLEU score: 0.5444358245099123<br/>Cumulative 1-gram: 0.151591<br/>Cumulative 2-gram: 0.355513<br/>Cumulative 3-gram: 0.475026<br/>Cumulative 4-gram: 0.544436</span></pre><figure class="lb lc ld le fd lf er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mw"><img src="../Images/b4c39552294e83ba6d49d65a41bdcaa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gR2wrEw7UD9BF6DIfQgYZg.png"/></div></div></figure><h1 id="12a2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">4.13整个语料库的最终BLEU分数。</h1><p id="6fc9" class="pw-post-body-paragraph kb kc hi jf b jg jh kd ke ji jj kf kg jk kh ki kj jm kk kl km jo kn ko kp jq hb bi translated">我们已经计算了我们拥有的整个语料库的bleu分数，下面是结果。</p><blockquote class="ng nh ni"><p id="abab" class="kb kc jv jf b jg kq kd ke ji kr kf kg nj ks ki kj nk kt kl km nl ku ko kp jq hb bi translated"><strong class="jf hj"><em class="hi">Final _ bleau 1 _ score 0.11377335230141303</em></strong></p><p id="9e80" class="kb kc jv jf b jg kq kd ke ji kr kf kg nj ks ki kj nk kt kl km nl ku ko kp jq hb bi translated"><strong class="jf hj"><em class="hi">Final _ bleau 2 _ score 0.20860306243858598</em></strong></p><p id="e9bf" class="kb kc jv jf b jg kq kd ke ji kr kf kg nj ks ki kj nk kt kl km nl ku ko kp jq hb bi translated"><strong class="jf hj">T17】Final _ bleau 3 _ score 0.27927417083079303T19】</strong></p><p id="8893" class="kb kc jv jf b jg kq kd ke ji kr kf kg nj ks ki kj nk kt kl km nl ku ko kp jq hb bi translated"><strong class="jf hj"><em class="hi">Final _ bleau 4 _ score 0.3235168641768014</em></strong></p></blockquote><p id="97fb" class="pw-post-body-paragraph kb kc hi jf b jg kq kd ke ji kr kf kg jk ks ki kj jm kt kl km jo ku ko kp jq hb bi translated">最终结果是好的:)</p><h1 id="7460" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">5.未来工作:</h1><ol class=""><li id="0b31" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">我想试试<a class="ae kv" href="https://arxiv.org/abs/1908.03557" rel="noopener ugc nofollow" target="_blank"> VisualBERT:一个简单的视觉和语言基准</a>和<a class="ae kv" href="https://arxiv.org/abs/2001.07966" rel="noopener ugc nofollow" target="_blank"> ImageBERT:使用大规模弱监督图像文本数据的跨模态预训练</a></li><li id="f8bf" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我想在模型的预测上尝试波束搜索，看看结果是否有所改善。</li><li id="1293" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated">我想尝试不同型号的编码器部分，如yolov3，更快的R-CNN等。</li></ol><h1 id="fb39" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">6。参考文献:- </h1><ol class=""><li id="4266" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated"><a class="ae kv" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">www.appliedaicourse.com</a></li><li id="0b33" class="jd je hi jf b jg jw ji jx jk jy jm jz jo ka jq jr js jt ju bi translated"><a class="ae kv" href="https://www.tensorflow.org/tutorials/text/image_captioning" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tutorials/text/image_captioning</a></li></ol><h1 id="935f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">—这个博客的源代码。</h1><div class="nm nn ez fb no np"><a href="https://github.com/sezazqureshi/chest-xray-medical-report-generation" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab dw"><div class="nr ab ns cl cj nt"><h2 class="bd hj fi z dy nu ea eb nv ed ef hh bi translated">sezazqureshi/胸部x光-医疗-报告-生成</h2><div class="nw l"><h3 class="bd b fi z dy nu ea eb nv ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nx l"><p class="bd b fp z dy nu ea eb nv ed ef dx translated">github.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od lg np"/></div></div></a></div><h2 id="244f" class="lx ig hi bd ih ly lz ma il mb mc md ip jk me mf it jm mg mh ix jo mi mj jb mk bi translated">也看看我的另一个案例研究。我做了一个基于StackOverflow问题的搜索引擎，并把它部署在AWS上。它会根据你的问题向你提出类似的问题。</h2><div class="nm nn ez fb no np"><a href="https://sezazqureshi.medium.com/search-engine-based-on-stackoverflow-questions-2151307c283f" rel="noopener follow" target="_blank"><div class="nq ab dw"><div class="nr ab ns cl cj nt"><h2 class="bd hj fi z dy nu ea eb nv ed ef hh bi translated">基于StackOverflow问题的搜索引擎</h2><div class="nw l"><h3 class="bd b fi z dy nu ea eb nv ed ef dx translated">目录:</h3></div><div class="nx l"><p class="bd b fp z dy nu ea eb nv ed ef dx translated">sezazqureshi.medium.com</p></div></div><div class="ny l"><div class="oe l oa ob oc ny od lg np"/></div></div></a></div><h1 id="292c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">喜欢并评论你的观点。</h1><h1 id="12b2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">感谢您的阅读…</h1></div></div>    
</body>
</html>