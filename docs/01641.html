<html>
<head>
<title>End-to-End ML in Tensorflow and Tensorflow Extended — 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow和tensor flow Extended-3中的端到端ML</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/end-to-end-ml-in-tensorflow-and-tensorflow-extended-3-d2de4354c816?source=collection_archive---------9-----------------------#2019-11-05">https://medium.com/analytics-vidhya/end-to-end-ml-in-tensorflow-and-tensorflow-extended-3-d2de4354c816?source=collection_archive---------9-----------------------#2019-11-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2d50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一部分将与之前的<a class="ae jd" rel="noopener" href="/@jagesh.maharjan007/end-to-end-ml-in-tensorflow-and-tensorflow-extended-2-ac20276ebef0?source=friends_link&amp;sk=29fa0ab2ff933a01d4470d46dd7e7533">部分</a>类似，然而，这一部分更侧重于张量流变换和阿帕奇波束。我碰巧使用了TensorFlow Transform Github存储库中的census_example示例，在那里我发布了一些问题并设法解决了这些问题。因此你可以参考<a class="ae jd" href="https://github.com/tensorflow/transform/blob/master/examples/census_example.py" rel="noopener ugc nofollow" target="_blank">这个</a>例子了解更多细节。因此，我不会张贴所有的代码，由一些，我们将需要知道和推理。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="3f2f" class="jn jo hi jj b fi jp jq l jr js">CATEGORICAL_FEATURE_KEYS = [<br/>  <strong class="jj hj">'workclass'</strong>,<br/>  <strong class="jj hj">'education'</strong>,<br/>  <strong class="jj hj">'marital-status'</strong>,<br/>  <strong class="jj hj">'occupation'</strong>,<br/>  <strong class="jj hj">'relationship'</strong>,<br/>  <strong class="jj hj">'race'</strong>,<br/>  <strong class="jj hj">'sex'</strong>,<br/>  <strong class="jj hj">'native-country'</strong>,<br/>]<br/><br/>NUMERIC_FEATURE_KEYS = [<br/>   <strong class="jj hj">'age'</strong>,<br/>   <strong class="jj hj">'capital-gain'</strong>,<br/>   <strong class="jj hj">'capital-loss'</strong>,<br/>   <strong class="jj hj">'hours-per-week'</strong>,<br/>]<br/><br/>OPTIONAL_NUMERIC_FEATURE_KEYS = [<br/>   <strong class="jj hj">'education-num'</strong>,<br/>]<br/>LABEL_KEY = <strong class="jj hj">'label'</strong></span></pre><p id="4527" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此示例使用人口普查数据来预测给定要素的收入是大于等于50k还是小于50k。输入要素分为分类要素键、数字要素键、可选数字要素键。我们需要知道这一点，因为我们需要在张量流变换中将数据转换为各自的数据类型。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="735c" class="jn jo hi jj b fi jp jq l jr js">RAW_DATA_FEATURE_SPEC = dict([(name, tf.io.FixedLenFeature([], tf.string)) <strong class="jj hj">for </strong>name <strong class="jj hj">in </strong>CATEGORICAL_FEATURE_KEYS] +<br/>                             [(name, tf.io.FixedLenFeature([], tf.float32)) <strong class="jj hj">for </strong>name <strong class="jj hj">in </strong>NUMERIC_FEATURE_KEYS] +<br/>                             [(name, tf.io.VarLenFeature(tf.float32)) <strong class="jj hj">for </strong>name <strong class="jj hj">in </strong>OPTIONAL_NUMERIC_FEATURE_KEYS] +<br/>                             [(LABEL_KEY, tf.io.FixedLenFeature([], tf.string))])</span><span id="da42" class="jn jo hi jj b fi jt jq l jr js">RAW_DATA_METADATA = dataset_metadata.DatasetMetadata(<br/>    schema_utils.schema_from_feature_spec(RAW_DATA_FEATURE_SPEC))</span></pre><p id="a416" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要素数据类型被转换为RAW_DATA_FEATURE_SPEC，它是Tensorflow的一部分，而基于要素规范，tensorflow_transform的tf_metadata函数创建输入要素类型的方案。功能规范和模式如下所示</p><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es ju"><img src="../Images/876df58ed35fbce94b354ec860234254.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gMtTgebLAhV5VPCNhwVUrA.png"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">图:功能规格</figcaption></figure><figure class="je jf jg jh fd jv er es paragraph-image"><div class="er es kg"><img src="../Images/4b6265968e64bc667c7c713333a1091c.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*1fPWrLMZzo9HNJ82mmLtfQ.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">图:数据模式</figcaption></figure><p id="9468" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在使用这些数据训练模型之前，最关键的部分是数据转换，或者我们称之为预处理函数，我们将在训练过程中将其作为包装函数传递。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="c1a9" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj">def </strong>preprocessing_fn(inputs):<br/>    outputs = inputs.copy()<br/>    <strong class="jj hj">for </strong>key <strong class="jj hj">in </strong>NUMERIC_FEATURE_KEYS:<br/>        outputs[key] = tft.scale_to_0_1(outputs[key])<br/><br/>    <strong class="jj hj">for </strong>key <strong class="jj hj">in </strong>OPTIONAL_NUMERIC_FEATURE_KEYS:<br/>        dense = tf.compat.v1.sparse_to_dense(<br/>            outputs[key].indices, [outputs[key].dense_shape[0], 1],<br/>            outputs[key].values,<br/>            default_value=0.)<br/>        dense = tf.squeeze(dense, axis=1)<br/>        outputs[key] = tft.scale_to_0_1(dense)<br/><br/>    <strong class="jj hj">for </strong>key <strong class="jj hj">in </strong>CATEGORICAL_FEATURE_KEYS:<br/>        tft.vocabulary(inputs[key], vocab_filename=key)<br/><br/>    table_keys = [<strong class="jj hj">'&gt;50K'</strong>, <strong class="jj hj">'&lt;=50K'</strong>]<br/>    initializer = tf.lookup.KeyValueTensorInitializer(<br/>        keys=table_keys,<br/>        values=tf.cast(tf.range(len(table_keys)), tf.int64),<br/>        key_dtype=tf.string,<br/>        value_dtype=tf.int64)<br/>    table = tf.lookup.StaticHashTable(initializer, default_value=-1)<br/>    outputs[LABEL_KEY] = table.lookup(outputs[LABEL_KEY])<br/>    <strong class="jj hj">return </strong>outputs</span></pre><p id="297c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将使用apache beam管道将我们的训练数据或评估数据转换为TFRecord。apache beam是为处理批量数据和流数据而构建的高级API，用于快速处理(这里不做详细介绍，留待下一节课讨论)。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="3886" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj">with </strong>beam.Pipeline() <strong class="jj hj">as </strong>pipeline:<br/>    <strong class="jj hj">with </strong>tft_beam.Context(temp_dir=tempfile.mktemp()):<br/>        ordered_columns = [<strong class="jj hj">'age'</strong>, <strong class="jj hj">'workclass'</strong>, <strong class="jj hj">'fnlwgt'</strong>,<strong class="jj hj">'education'</strong>, <strong class="jj hj">'education-num'</strong>,<strong class="jj hj">'marital-status'</strong>, <strong class="jj hj">'occupation'</strong>, <strong class="jj hj">'relationship'</strong>, <strong class="jj hj">'race'</strong>, <strong class="jj hj">'sex'</strong>,<strong class="jj hj">'capital-gain'</strong>, <strong class="jj hj">'capital-loss'</strong>, <strong class="jj hj">'hours-per-week'</strong>, <strong class="jj hj">'native-country'</strong>,<strong class="jj hj">'label'</strong>]<br/>        converter = tft.coders.CsvCoder(ordered_columns, RAW_DATA_METADATA.schema)<br/><br/>        raw_data = (<br/>            pipeline<br/>            | <strong class="jj hj">"ReadTrainData" </strong>&gt;&gt; beam.io.ReadFromText(train_data_file)<br/>            | <strong class="jj hj">"FixCommasTrainData" </strong>&gt;&gt; beam.Map(<strong class="jj hj">lambda </strong>line: line.replace(<strong class="jj hj">', '</strong>, <strong class="jj hj">','</strong>))<br/>            | <strong class="jj hj">"DecodeTrainData" </strong>&gt;&gt; MapAndFilterErrors(converter.decode)<br/>        )<br/><br/>        raw_dataset = (raw_data, RAW_DATA_METADATA)<br/>        transformed_dataset , transform_fn = (raw_dataset | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))<br/>        transformed_data, transformed_metadata = transformed_dataset<br/><br/>        transformed_data_coder = tft.coders.ExampleProtoCoder(transformed_metadata.schema)<br/><br/>        _ = (<br/>            transformed_data<br/>            | <strong class="jj hj">"EncodeTrainData" </strong>&gt;&gt; beam.Map(transformed_data_coder.encode)<br/>            | <strong class="jj hj">"WriteTrainData" </strong>&gt;&gt; beam.io.WriteToTFRecord(os.path.join(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE))<br/>             )</span></pre><p id="3913" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">apache beam pipeline的函数<em class="kh"> ReadFromText </em>将读取文本文件，并在每一行(一条记录)中固定逗号，然后使用MapAndFilterErrors类解码CSV编码数据。然后简单地用原始数据和模式创建原始数据集，如上所示。然后用我们的预处理函数作为包装器，使用AnalyzeAndTransformDataset进行转换。最后，将转换后的数据作为TFRecord数据类型文件写入磁盘。我们对评估数据集进行同样的操作。</p><p id="d063" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们创建一个训练包装器，将转换后的数据集作为其输入参数。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="c824" class="jn jo hi jj b fi jp jq l jr js"><strong class="jj hj">def </strong>_make_training_input_fn(tf_transform_output, transformed_examples, batch_size):<br/>    <strong class="jj hj">def </strong>input_fn():<br/>        dataset = tf.data.experimental.make_batched_features_dataset(<br/>            file_pattern=transformed_examples,<br/>            batch_size=batch_size,<br/>            features=tf_transform_output.transformed_feature_spec(),<br/>            reader=tf.data.TFRecordDataset,<br/>            shuffle=<strong class="jj hj">True<br/>        </strong>)<br/>        transformed_features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()<br/>        transformed_labels = transformed_features.pop(LABEL_KEY)<br/>        <strong class="jj hj">return </strong>transformed_features, transformed_labels<br/>    <strong class="jj hj">return </strong>input_fn</span></pre><p id="f78a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，我们为一个服务函数创建了一个包装器，可以在评估过程中使用，也可以在以后的服务过程中使用。只是我们不需要标签功能，这违背了培训的目的。</p><p id="99a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用estimator API进行训练，并将使用LinearClassifier，但也可以随意使用任何其他API，如DNNClassifier。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="fd6e" class="jn jo hi jj b fi jp jq l jr js">estimator = tf.estimator.LinearClassifier(<br/>    feature_columns=get_feature_columns(tf_transformed_output),<br/>    config=run_config,<br/>    loss_reduction=tf.losses.Reduction.SUM<br/>)<br/><br/>train_input_fn = _make_training_input_fn(<br/>    tf_transformed_output,<br/>    os.path.join(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE + <strong class="jj hj">'*'</strong>),<br/>    batch_size=TRAIN_BATCH_SIZE<br/>)<br/>estimator.train(input_fn=train_input_fn, max_steps=TRAIN_NUM_EPOCHS * num_train_instances / TRAIN_BATCH_SIZE)</span></pre><p id="622d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦训练完成，我们将把输出模型保存在working_dir中。</p><figure class="je jf jg jh fd jv er es paragraph-image"><div class="er es ki"><img src="../Images/593aa9d7a59bb99c0e268221683b3907.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*gCxSUaRMFwnc8koULNVd0A.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">图:保存的模型</figcaption></figure><p id="936f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练完成后，我们可以使用TensorFlow的saved_model_cli检查我们保存的模型的签名定义。</p><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kj"><img src="../Images/7b678b16619e95a1731abacbf1ebc732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o2P_Exv56ldDu_nKZQ9Oxw.png"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">图:保存模型的签名定义</figcaption></figure><p id="2317" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经准备好使用TensorFlow服务来服务从人口普查数据集中训练的模型。</p><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kk"><img src="../Images/fb4b95c0b4bada5a93bc74da9bd0c6ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dj8hgzdWD155Fkgg4YYKhA.png"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx translated">图:使用Tensorflow模型服务来服务模型</figcaption></figure><p id="f404" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，是时候为推理创建一个客户机了。然而，在前面的小节中，我使用python创建了一个用于推理的客户机。我们可以用旋度来做推论，这也是最简单的方法。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="f919" class="jn jo hi jj b fi jp jq l jr js">$ curl -d ‘{“examples”: [{“age”:30.0, “workclass”:”Self-emp-not-inc”, “education”:”Bachelors”, “education-num”:17.0, “marital-status”:”Married-civ-spouse”, “occupation”:”Exec-managerial”, “relationship”:”Husband”, “race”:”White”, “sex”:”Male”, “capital-gain”:0.0, “capital-loss”:0.0, “hours-per-week”:40.0, “native-country”:”United-States”}]}’ -X POST <a class="ae jd" href="http://localhost:8501/v1/models/census:classify" rel="noopener ugc nofollow" target="_blank">http://localhost:8501/v1/models/census:classify</a><br/>{<br/> “results”: [[[“0”, 0.498906225], [“1”, 0.501093805]]<br/> ]</span></pre></div></div>    
</body>
</html>