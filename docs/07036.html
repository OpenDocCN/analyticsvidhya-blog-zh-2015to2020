<html>
<head>
<title>Web Scraping in Python For Novice.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向新手的Python网页抓取。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-in-python-for-novice-58856d82e749?source=collection_archive---------13-----------------------#2020-06-11">https://medium.com/analytics-vidhya/web-scraping-in-python-for-novice-58856d82e749?source=collection_archive---------13-----------------------#2020-06-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/fbf304df7395f6b71d392cf64197bd00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1x7ew4VtuN19s4l2z1QT6g.jpeg"/></div></div></figure><p id="9295" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你是第一次做网络抓取，那你就来对地方了。我把我第一次做网络抓取时遇到问题的每一部分放在一起。如果你是第一次使用Python，不确定语法，不要担心——冷静，不知道库——冷静。只要和我在一起，我们会一件一件地探索事物，让水果变得美味。</p><p id="718a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇文章中，我们将使用Jupyter笔记本。如果你没有笔记本，你可以通过在命令行输入下面的代码很容易地得到。确保您的系统中安装了python如果没有，您可以点击<a class="ae jo" href="https://www.python.org/downloads/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">这里</strong> </a>下载</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es jp"><img src="../Images/1051e8d4f7c691a0138d5397e54f2afb.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*6PBQDUSnYwi2uHfif6bnbw.png"/></div></figure><p id="6b06" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以上命令将安装Jupiter笔记本，现在您可以在Jupyter笔记本中编写代码了。要打开笔记本，请在命令提示符下键入以下命令。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ju"><img src="../Images/1c8d83f0dbdef3f896daa43b84b211dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*l4yuyflnfRBR4yiWG5Nzew.png"/></div></figure><p id="f55b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">之后，你会在浏览器中看到一个打开的笔记本，如下图所示。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jv"><img src="../Images/9ed3a6278656d6f72902f15f3356a59d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8FU_5EsCgaQHFdwHWEoRw.png"/></div></div></figure><p id="38b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以在这里创建新的笔记本或打开以前的工作簿。现在，我们将按照以下步骤打开一个新笔记本。</p><p id="6ffb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">点击右边的新建图标-&gt;选择Python3笔记本就这样，新的工作簿准备好了，我们可以开始编码了。</p><p id="b3d8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将从导入web抓取所需的库开始。我们需要请求，美女们。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jw"><img src="../Images/6170e19bdd0d4a5d884658551cbab94d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z1nrbjLi0x_iqb8mSdenkQ.png"/></div></div></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jx"><img src="../Images/a49d018f906a96b671dd0e282af4ffbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c5TynOM1Px4xI8u69MrMSg.png"/></div></div></figure><p id="55b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，时候到了。选择你要废弃的网站，并准备好网址。在这里，我选择<strong class="is hj"> CBC </strong> URL来提取最新的政治新闻文章，并提取文章的标题和描述。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jy"><img src="../Images/e853f54ffb311feaaefbbd3e5fdbbd7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iaD2BGSibH7UdeMlo6huTQ.png"/></div></div></figure><p id="c059" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">requests.get将获取页面源，我们将输出存储在页面变量中。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jw"><img src="../Images/a6d3520301e1eb88ee2908266397a066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F6p_PWALwvbUy1HbejTGow.png"/></div></div></figure><p id="5ddb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们将页面的HTML内容存储在Soup对象中。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jz"><img src="../Images/f87b71f16f4a879b4b934c9fcb7d2fcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3vyt7KYs2LjEK4Tnbe6GPA.png"/></div></div></figure><p id="0c22" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们将通过下面一行代码获取网页上的所有锚标签。使用“a”是因为锚标签用于源页面中的链接。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ka"><img src="../Images/6d8c270e940db7c4ad82a2ce2fc1e53d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*--nREFOpaCsL-7oEqMROLw.png"/></div></div></figure><p id="001e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们获取链接，并存储在一个名为listofLinks的列表中。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kb"><img src="../Images/e4690dee33d57d220f568f042afddf6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lcMgZfHT28om18f1kXFS7Q.png"/></div></div></figure><p id="0041" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我们只关心提取政治新闻，所以我们过滤上面的结果，只提取与“政治”相关的链接，并再次存储在另一个名为linksrequired的列表中。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jw"><img src="../Images/5c9fd738960a0fe9a7b27c3cfb779e66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ezCOYAhrGSBzbpVzx55mpw.png"/></div></div></figure><p id="0f4d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在放松，我们擅长链接，我们需要从每个URL提取标题和描述。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kc"><img src="../Images/cb226db350f1ec399d08951d33ff1973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ObIIYNkV81pd3ArHKAvg3A.png"/></div></div></figure><p id="b72e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">成功提取数据后，下一步是将数据加载到DataFrame中，为此我们使用了<strong class="is hj"> pandas </strong>库<strong class="is hj">。</strong></p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kd"><img src="../Images/e0e85f15e7ae660e28f70e5e54ab0f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gn98J-ndYd_7StlQPjBwEg.png"/></div></div></figure><p id="9a0b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，我们成功地完成了我们的任务，我们刮网站，提取标题，新闻文章的描述，并存储在熊猫数据帧。</p><p id="1956" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">到目前为止，我们很好，假设我们有一个场景，比如当我们抓取网站时，我们需要点击一些按钮，我们会怎么做？对于上面的例子，我们讨论了如果我们需要点击下面的LOAD MORE按钮来加载更多的文章。</p><p id="863b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我的下一篇文章中，我将讨论web驱动程序，这样我们就可以点击网页上的按钮。</p><p id="af83" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我希望你们都喜欢阅读这篇文章。如果有任何错误/疑问，请分享或评论。</p><p id="10c8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谢谢你。</p><p id="45ae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"># Python # web scraping # learning Python</strong></p></div></div>    
</body>
</html>