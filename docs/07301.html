<html>
<head>
<title>Overfitting — Bias — Variance — Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">过度拟合—偏差—方差—正则化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/overfitting-bias-variance-regularization-fd929ff54218?source=collection_archive---------14-----------------------#2020-06-20">https://medium.com/analytics-vidhya/overfitting-bias-variance-regularization-fd929ff54218?source=collection_archive---------14-----------------------#2020-06-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2179" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当线性回归模型对训练数据很有效，但对测试数据或未知的新数据无效时，这意味着模型过度拟合。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/bd16332490fcbcb4710d9ac926bc1070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*axQoMUmYmNZXyaOiP49w0g.png"/></div></div></figure><blockquote class="jp jq jr"><p id="e44a" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj">当我们为训练数据的模型增加更多复杂性时，就会出现过度拟合。当复杂性增加时，模型对数据中的噪声做出反应。</strong></p></blockquote><p id="07d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">这里的噪声指的是与数据点没有真正的关系，而只是随机选择的数据点。</strong></p><p id="9693" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，在多项式回归中，我们增加了太多的次数以适应训练数据，但这将无法明智地处理测试数据。这个场景是用一个花哨的词<strong class="ih hj">过拟合</strong>提到的。</p><p id="2c52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了理解过度拟合，让我们以下面的线性回归模型为例。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jw"><img src="../Images/a07b30629eafb8a4db80eae4c3afb20d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*0q9nJI0KB9Bocq8T0dkfsw.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">过度拟合</figcaption></figure><p id="04a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，这条回归线非常符合上述数据。</p><p id="954a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看当我们绘制测试和训练数据时会发生什么，这样我们就可以比较这两条最佳拟合线。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kb"><img src="../Images/335d4cf3c4d7a04b46cf337b69ac92ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*t3MzudZ4qdpRRqWSuR6gnw.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">过度拟合—测试</figcaption></figure><p id="583e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，您可以看到测试数据(橙色点)具有不同于训练数据的最佳拟合线。</p><p id="dee8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这意味着，对于训练数据的最佳拟合线，不同数据集的误差值之和变化很大。</p><p id="12a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">变化很大？是啊！这就是所谓的高方差。</p><blockquote class="jp jq jr"><p id="476f" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj">数据集之间误差总和的差异(训练&amp;测试)称为方差。</strong></p><p id="65a3" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">如果一个模型在训练中产生的误差(SSE)很小，而测试误差(SSE)很大，那么称之为高方差模型。</em>T13】</strong></p><p id="58e2" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">如果该模型产生的测试数据误差非常接近训练中得到的误差，则称之为低方差模型。</em> </strong></p></blockquote><p id="5e06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第一个“过度拟合”图中，如果我们稍微调整了训练数据的回归线，以便它可以推广到测试数据以及不同的数据集，会怎么样？</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kc"><img src="../Images/b5338956f3fc93a8a8887bfb3e277853.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*DHjAQJfDlBUqwuP6R5C2aw.png"/></div></figure><p id="9949" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些调整可以通过向SSE值添加罚值来降低系数来完成。</p><p id="d82b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当惩罚太低时，比如说0，那么它就是我们的原始线性回归，我们发现它是过度拟合的模型。</p><p id="ebba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设SSE值仍然保持较低，通过逐渐增加惩罚，系数开始逐渐减小，最佳拟合线一点一点地移动，从而模型将被一般化。</p><p id="c769" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在一个点上，通过增加罚值，直线会移出广义点，不再是最佳拟合直线。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kd"><img src="../Images/60f25f8ce28a386b1d4969fc0e6f2051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*FPagxn8zYN3oaupkBoh0gQ.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">带惩罚的线性回归</figcaption></figure><p id="b2a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上图中，我们绘制了具有不同惩罚的一般化线条。</p><p id="1a08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当惩罚稍微增加时，我们得到绿线，这样它可以推广模型。(只是为了演示，我已经手绘好了)</p><p id="e58f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当进一步增加时，线移出数据。黄色、粉色和红色的线甚至没有靠近数据，这不是一个好的迹象。因此，当增加惩罚时，模型的适合度开始变得不适合(不适合任何数据集)。</p><p id="5585" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种向线性回归成本函数添加惩罚的方式称为正则化。</p><h1 id="dce8" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated"><strong class="ak">收缩/正则化方法:</strong></h1><ol class=""><li id="b78f" class="lc ld hi ih b ii le im lf iq lg iu lh iy li jc lj lk ll lm bi translated">拉索-L1正则化</li><li id="8af8" class="lc ld hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">岭-L2正则化-了解我们的模型有多灵活。正则化程度越高，我们的模型就越不容易过度拟合。</li></ol><p id="e6fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">拉索还是L1正规化:</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/5dbc3d492761423df1c72dd5a710b4df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*fHUYYl_QjsbqqzvdnWA4kA.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">来源<a class="ae lt" href="https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11" rel="noopener" target="_blank">https://towards data science . com/optimization-loss-function-under-the-hood-part-ii-d20a 239 CDE 11</a></figcaption></figure><p id="9f90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">岭或L2正则化:</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lu"><img src="../Images/068e4564bd64f1618ceb4e193d04bda4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*R68jVyUaDTPcTgIaXoUe9Q.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">来源<a class="ae lt" href="https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11" rel="noopener" target="_blank">https://towards data science . com/optimization-loss-function-under-the-hood-part-ii-d20a 239 CDE 11</a></figcaption></figure><p id="4717" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们已经看到了过度拟合和高方差在其中的作用。</p><p id="aca1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看偏差是如何与方差相关联的。</p><p id="9c44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在下图中，只有3个数据点。</p><h1 id="aaa8" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated"><strong class="ak">什么是偏见？</strong></h1><p id="708d" class="pw-post-body-paragraph if ig hi ih b ii le ik il im lf io ip iq lv is it iu lw iw ix iy lx ja jb jc hb bi translated">考虑下面的线性回归模型:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/a9796fb1eae54c2979ac0f4561051a2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*_NyKYfbJJXddBD7so2ghkg.png"/></div></figure><p id="f08d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在该图中，数据点非常适合多项式回归。但不是线性回归。因此，该模型在训练和测试数据集上都产生很高的误差。这种情况称为高偏差。</p><blockquote class="jp jq jr"><p id="2b9d" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj">机器学习模型无法找到真实关系的现象称为偏差。</strong></p><p id="c5ee" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj"> Foreman的文章对此进行了总结:<br/>“偏差是算法通过不考虑数据中的所有信息(欠拟合)而持续学习错误东西的倾向。”</strong></p></blockquote><p id="0314" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归可以很好地拟合训练数据，而很差地拟合测试数据。这被称为<strong class="ih hj">过拟合</strong>数据(低偏差和高方差)。</p><p id="9ca3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型可能非常不适合训练和测试数据(高偏差和低方差)。这被称为<strong class="ih hj">欠拟合</strong>数据。</p><p id="562c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个理想的模型是同样适合训练和测试数据集。</p><blockquote class="jp jq jr"><p id="c75c" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj">高偏差发生在:<br/> 1。我们的数据量非常少，无法找到数据中的真实关系。<br/> 2。当使用与数据的基本模式不匹配的模型时。例如:当我们试图为非线性数据建立线性模型时。</strong></p></blockquote><p id="7f97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">克服过拟合:</strong></p><ol class=""><li id="f58a" class="lc ld hi ih b ii ij im in iq lz iu ma iy mb jc lj lk ll lm bi translated">使用正则化(即套索、脊、弹性网)。</li><li id="b65a" class="lc ld hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">移除实际上没有关系的要素。</li><li id="ed89" class="lc ld hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">添加更多数据点。</li></ol><p id="99a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">克服拟合不足:</strong></p><ol class=""><li id="5016" class="lc ld hi ih b ii ij im in iq lz iu ma iy mb jc lj lk ll lm bi translated">欠拟合意味着你的模型太简单。增加模型的复杂性，例如使用要素的多项式。(即增加多项式回归的次数。)</li><li id="63f5" class="lc ld hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">合并更多的特征或计算特征的相互作用。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/47d83929bae9ab03fdb267ce786e590e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*gkY45qP4r2eJG2WDQjthIg.png"/></div></figure><p id="2f42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi mc translated"><span class="l md me mf bm mg mh mi mj mk di"> C </span> <strong class="ih hj">结束语:</strong></p><ol class=""><li id="8c5c" class="lc ld hi ih b ii ij im in iq lz iu ma iy mb jc lj lk ll lm bi translated">线性回归可以很好地拟合训练数据，而很差地拟合测试数据。这被称为过度拟合数据(低偏差和高方差)。</li><li id="11ee" class="lc ld hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">类似地，它可能非常不适合训练和测试数据(高偏差和低方差)。这就是所谓的数据欠拟合。</li><li id="078b" class="lc ld hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">一个理想的模型是同样适合训练和测试数据集。</li><li id="5928" class="lc ld hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">我们仍然可以通过使用正则化或添加模式特征或添加更多的数据点来克服这些问题。</li></ol></div></div>    
</body>
</html>