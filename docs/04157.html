<html>
<head>
<title>Simple Neural Network Explanation: From Logistic Regression to Neural Network — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单的神经网络解释:从逻辑回归到神经网络—第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/simple-explanation-from-logistic-regression-to-neural-network-part-2-9b74718544c8?source=collection_archive---------9-----------------------#2020-03-07">https://medium.com/analytics-vidhya/simple-explanation-from-logistic-regression-to-neural-network-part-2-9b74718544c8?source=collection_archive---------9-----------------------#2020-03-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="79b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的<a class="ae jd" rel="noopener" href="/@esraa.sabry.mohamed/simple-explanation-from-logistic-regression-to-neural-network-part-1-8c018b04a824">上一篇文章</a>中，我们概述了监督机器学习和逻辑回归模型。让我们从重温逻辑回归模型术语开始，然后开始画一个神经网络模型。</p><h1 id="5dd8" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">索引:</h1><ol class=""><li id="32b4" class="kc kd hi ih b ii ke im kf iq kg iu kh iy ki jc kj kk kl km bi translated">建立一个简单的神经网络</li><li id="6921" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">神经网络组件</li><li id="8528" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">为什么叫神经网络？我们为什么要用它？</li><li id="8203" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">激活功能类型</li></ol><p id="e341" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在之前的逻辑回归算法中，我们在下面的公司数据集上应用了线性回归概念，以对给定员工是否会离开公司进行分类。我们通过为训练数据集找到最合适的<strong class="ih hj">线/分隔符/决策边界</strong>来完成这一任务。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es ks"><img src="../Images/d2f98d54392865576c4203b9e39ce316.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*LkJOPaO7lCJLQ1ymvZ3bYA.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图1:训练数据集</figcaption></figure><p id="df2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">拟合线的一般方程为:</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es le"><img src="../Images/fbce07b1871c3c9ce544fabb998a3967.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*lFRRugxrLe0agMbRthzrVA.png"/></div></figure><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lf"><img src="../Images/23f638095d39e4c72e4bc59e6633221d.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*KCl4anCjLY68Zv6wZRUE_A.png"/></div></figure><p id="6f0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Z </strong>值代表员工属于另一个阶层<strong class="ih hj">{离开，不离开} </strong>的概率。</p></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="81c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">现在，让我们将逻辑回归模型描绘成一个图形/网络，如下所示:</strong></p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es ln"><img src="../Images/9af551fddd8ee8b806146422dfd52b67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*0rYIVrMh8bXv8buEVt_i6w.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图2:作为网络的逻辑回归</figcaption></figure><p id="4466" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上图显示了一个简单的神经网络结构。本质上，我们可以将逻辑回归视为一个单层神经网络。</p><h1 id="bddf" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">神经网络</h1><p id="a459" class="pw-post-body-paragraph if ig hi ih b ii ke ik il im kf io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">我们可以将神经网络描述为<strong class="ih hj">一种处理给定输入以计算期望输出的功能。</strong></p><h1 id="078b" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">神经网络组件</h1><p id="5cad" class="pw-post-body-paragraph if ig hi ih b ii ke ik il im kf io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">神经网络由以下五个主要组件组成:</p><ol class=""><li id="6468" class="kc kd hi ih b ii ij im in iq lr iu ls iy lt jc kj kk kl km bi translated"><strong class="ih hj">神经元:</strong>是神经网络的基本单元。</li></ol><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lu"><img src="../Images/d606de6feb09027a7ec0a669347abcce.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*qKrV4W4NvlrTlgQzHuzNBg.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图3:神经元</figcaption></figure><p id="1b82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">神经元是一个数学函数，它接收<strong class="ih hj">多个输入</strong>并返回一个<strong class="ih hj">单个</strong> <strong class="ih hj">输出</strong>作为对输入的一些计算的结果。例如，上面的黄色神经元将X1(年龄)和X2(休假天数)作为输入，然后计算Y预测函数:</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es le"><img src="../Images/fbce07b1871c3c9ce544fabb998a3967.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*lFRRugxrLe0agMbRthzrVA.png"/></div></figure><p id="448b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在计算预测的Y值后，它对预测的Y应用sigmoid函数以获得Z值。最后，<strong class="ih hj"> Z </strong>就是这个神经元的输出。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lf"><img src="../Images/23f638095d39e4c72e4bc59e6633221d.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*KCl4anCjLY68Zv6wZRUE_A.png"/></div></figure><p id="d81b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。权重:</strong>任何对神经元的<strong class="ih hj"> </strong>输入都有一个相关的值叫做权重(<em class="lv"> w </em>)。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lu"><img src="../Images/39fbc3edbd85b4c901ecbb9658d431ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*2IShuVrMGsUhBMItUXLVSQ.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图4:重量</figcaption></figure><p id="2906" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上所述，黄色神经元将X1和X2作为输入，并将<strong class="ih hj"> a </strong>和<strong class="ih hj"> b </strong>作为它们的关联权重。因此，每个单个神经元基于其<strong class="ih hj">输入乘以其相关权重值</strong>来计算其输出。因此，对于我们的输入，<strong class="ih hj"> X1 </strong>将乘以其相关权重<strong class="ih hj"> a </strong>并且<strong class="ih hj"> X2 </strong>乘以其权重<strong class="ih hj"> b </strong>。</p><p id="e9ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。输入层:</strong>是神经网络的第一层神经元。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es lw"><img src="../Images/e21d615f21284ae3204ce906aba3c3bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dCKDUR0DP4uY8v8lwT3FzA.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图5:输入层</figcaption></figure><p id="c559" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入层告诉我们关于训练数据集及其外观，输入层中的每个神经元代表训练数据集中的一个<strong class="ih hj">特征(列)</strong>。例如，年龄列有一个神经元<strong class="ih hj"> (X1) </strong>，假期列有另一个神经元<strong class="ih hj"> (X2) </strong>。它由被动神经元组成，这些神经元不接受来自前几层的信息，因为它们是网络的第一层。这一层的目标是向神经网络提供输入数据。本质上，它是逐行获取训练数据，并将行的值分布在输入层的神经元上，然后将这些值传递给下一层。</p><p id="91d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="lv">* *注意</em> </strong> <em class="lv">在NN中统计层数时我们不统计输入层数。</em></p><p id="e7d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。输出层:</strong>这一层是神经网络的最后一层神经元。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es mb"><img src="../Images/5177e56612996ca6df239a6c52392d97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*z3FNxn45ZQUi9mkiFE-ULQ.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图6:输出层</figcaption></figure><p id="d533" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该层接收来自前几层的输入，<strong class="ih hj">返回代表模型预测的输出</strong>。这一层的神经元数量取决于预测的类型<em class="lv">。当它解决一个回归问题时，输出层只包含一个神经元。另一方面，当网络解决一个分类问题时，它包含的神经元数量等于类别(类)的数量。</em></p><p id="d6c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 5。隐层:</strong>输入层和输出层之间的所有层神经元都是隐层。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lu"><img src="../Images/8609c0017eed21eaefe171b28d2a5168.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*zfLTyRkSHRmHgwCY7Tt0qQ.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图7:隐藏层</figcaption></figure><p id="2ec0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上图中，有一个隐藏层，但神经网络通常有多个隐藏层。这些图层被称为“隐藏的”，因为它们在网络输出中不可见。隐藏层中的所有这些神经元都有一个计算过程。<br/>隐藏层通常是完全连接的层(每个神经元接收来自所有前一层神经元的输入，并将其输出发送给下一层中的每个神经元)。</p><p id="aebd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我们对神经网络有了一个基本的了解，我们经历了一个可以构建的基本结构。神经网络可以通过具有两个或更多隐藏层(在这种情况下，它被称为深度神经网络)而具有更复杂的结构，或者根据问题的复杂性在任何层中具有更多神经元。</p><h1 id="9a52" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">为什么叫神经网络？我们为什么要用它？</h1><p id="459c" class="pw-post-body-paragraph if ig hi ih b ii ke ik il im kf io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">开发神经网络架构是为了让计算机模仿大脑，方法是让这些节点以类似于人脑中神经元和突触的方式学习和行为。这就是为什么它被称为神经网络。</p><p id="a3ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在将逻辑回归模型转换为神经网络模型并简要介绍了其主要组件之后，如果神经网络模型与逻辑回归模型实现了相同的计算并给出了相同的结果，而不管它们是如何实现的，那么我们为什么要使用神经网络模型而不是逻辑回归模型呢？有什么区别？</p><ol class=""><li id="7e98" class="kc kd hi ih b ii ij im in iq lr iu ls iy lt jc kj kk kl km bi translated">我们可以将神经网络模型用于回归和分类问题，这与仅用于分类的逻辑回归不同。</li><li id="8d74" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">神经网络具有高维数(具有大量特征/列的训练数据),非常方便。</li><li id="50ad" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated"><strong class="ih hj">神经网络为模型</strong>引入了非线性(这是神经网络的重要部分)。</li></ol><p id="c0b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从我们以前的帖子中，我们知道逻辑回归是一个线性模型，这意味着它试图找到最佳的决策边界(线)，可以分离可能的类别(组)，所以它不能捕捉更复杂的非线性关系。在神经网络的情况下，它试图生成更复杂的决策边界(非线性分隔符),可以对特征之间的高度复杂的关系进行建模。神经网络(简称NN)可以使用一个<strong class="ih hj">激活函数</strong>来完成，它通常是一个传递函数，接受输入，然后将结果值映射到不同的范围。我们之前确实使用了相同的概念，对吗？🤔在sigmoid函数中，将预测值映射到代表类概率的(0–1)范围。sigmoid函数是各种激活函数中的一种，我们将在这篇文章中讨论其中的一些。</p><p id="50f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在人们越来越清楚地认识到，没有激活函数的神经网络本质上只是一个线性逻辑回归模型。激活函数将非线性变换应用于输入，使神经网络能够学习和执行更复杂的任务，并找到非线性决策边界。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es mc"><img src="../Images/6704d601a741bfc0b8cd6f4b921a3dbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*1EJvCaUB4b2Yi8bccaOPfQ.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图8:非线性决策边界</figcaption></figure><p id="6a7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回到我们将逻辑回归转换为神经网络时所做的事情，我们仍然看不到神经网络在哪里执行这种非线性转换(应用激活函数)，因为它实现了与线性逻辑回归相同的数学函数！让我们在更大的神经网络中解释更多。</p><p id="78b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们考虑图1中使用的相同训练数据，并通过训练两个线性逻辑回归模型来尝试找到这两个类之间的最佳分隔符。每个模型必须正确地对大多数训练点进行分类，并生成所需决策边界的一部分，直到完成为止。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es md"><img src="../Images/b45c37014ebdc70371a7f6ddc018ff05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*S9gclsCVgyXcFGTnmsddIw.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图9:逻辑回归模型</figcaption></figure><p id="db70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个模型都可以用它自己的方程来表示，这是我们在训练数据集上训练该模型之后获得的。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es me"><img src="../Images/712a7969a793412877cf213e4afef533.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*4_3lJLRWWIGcxYogZiF6tQ.png"/></div></figure><p id="1dc2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">两个模型都试图将点分成两个给定的类，但是每次它们都将一些点分类错误。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es mf"><img src="../Images/ffdbafbfcd6eb08cceeac8b2ba170dd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6nQnsWtde4OmOEDiGgJKpw.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图10:错误分类的点</figcaption></figure><p id="93fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于模型1，它错误分类了1个红点，模型2错误分类了2个红点。因此，我们可以说绿色模型的精度比蓝色模型好。</p><p id="ba8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，我们不会依赖这两个模型中的任何一个作为我们的最终模型。最终模型将是两条线(模型)的组合乘以代表每个模型有多好的因子。该因子可以是总点数中正确分类的点数。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es mg"><img src="../Images/676da7ec7466dbbb4a2fedc934f52a45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V4X5Gi2C3lClFAg0XfNwqA.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图11:最终的(组合的)模型</figcaption></figure><p id="6463" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，这个组合模型将比早期的两个单独的模型具有更好的准确性。</p><p id="be25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从数学上追溯我们是如何计算最终模型的:</p><p id="5d1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">型号1 /绿线/ Y1: </strong></p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es mh"><img src="../Images/028976bd90f41455c5447f0aa272853a.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*XzKXk0Y2osuveRa3WKayMQ.png"/></div></figure><p id="931a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型2 /蓝线/ Y2: </strong></p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es mh"><img src="../Images/5bf9338635a8153b8bc301eb24670162.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*a6K-AiDpe4Bk8D2npcChjg.png"/></div></figure><p id="dc6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">最终型号/双线/ Yc: </strong></p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es mi"><img src="../Images/e6f673e016e6e64cfa0d61b4c251d78a.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*Z3Kuv6KKkr7X5bTvkZjLgw.png"/></div></figure><p id="5be9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这从数学上总结了最终的模型方程。通过这样做，我们仍然得到线性模型中使用的相同的线性方程。此外，上图没有显示我们在图8中看到的弯曲的决策边界。那么接下来我们需要做什么来证明这一点呢？🙄答案是<strong class="ih hj"> </strong>到<strong class="ih hj">应用激活功能。</strong></p><p id="c6cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们把这些逻辑回归模型转换成神经网络结构，看看应用激活函数在数学上是什么样子。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es mj"><img src="../Images/adc4872ada37abc9b12af78d00908bd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XHEC9Z0rVna7lGeMxzq4Gw.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图12:神经网络模型</figcaption></figure><p id="535f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这可以用数学方法写成如下:</p><p id="5a1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型1输出Z(Y1): </strong></p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es mk"><img src="../Images/439206efe962b43584ceb3c9025b5936.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TVN20k_vIFMx8uoCSXeSgw.png"/></div></div></figure><p id="0ce4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型2输出Z(Y2): </strong></p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es mk"><img src="../Images/eb133bee7eef8d17904ac84019cae63d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S-o0b_2-angqY0irdoJb1A.png"/></div></div></figure><p id="8947" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">最终模型输出Zf(Y): </strong></p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es ml"><img src="../Images/ecd64759fdd7e1e56b05814d975603a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dxOFArQzCzGu9AhzrmyBlw.png"/></div></div></figure><p id="8ea8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很明显，每个模型的输出都不是线性的。请记住，神经元执行某种计算(在我们的情况下是线性回归)，然后它应用一个激活函数将线性输出转换为非线性输出，如上面的等式所示。每个模型在其输出上应用sigmoid函数来打破模型的线性。</p><p id="906b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">在上述NN中，我们在神经元[Z(Y1)，Z(Y2)，Zf(Y)]中的每次计算后使用相同的激活函数3次，但它们执行的不是相同的工作！</strong></p><p id="a5a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，我们在NN中使用激活函数来完成两个不同的任务，具体取决于我们使用它的层:</p><ul class=""><li id="22c6" class="kc kd hi ih b ii ij im in iq lr iu ls iy lt jc mm kk kl km bi translated">如果我们在隐藏层中使用一个激活函数(例如Z(Y1)，Z(Y2))，那么它被用来打破神经网络的线性，就像我们上面所做的那样。</li><li id="a1ff" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc mm kk kl km bi translated">如果我们在输出层使用它(例如Zf(Y))，那么它将用于返回表示模型预测的输出。例如，在二进制分类问题中，我们需要通过对其应用sigmoid函数来计算作为模型输出的类的概率。不像如果我们有一个回归问题，那么我们将在输出层有一个神经元，不需要应用任何类型的激活函数。因此，在输出图层中应用激活函数是可选的，并且取决于问题类型，但是当到达使NN成为任何正常线性模型的隐藏图层时，它不是可选的。</li><li id="c96d" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc mm kk kl km bi translated">输入层没有激活功能。</li></ul><p id="2c06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简单来说，应用非线性激活函数和使用多个隐藏层，使得NN可以检测数据集中更复杂的模式。</p><h1 id="e118" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">激活功能类型:</h1><p id="c91a" class="pw-post-body-paragraph if ig hi ih b ii ke ik il im kf io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">前面我们提到过，<strong class="ih hj">激活函数是一个传递函数，用来确定一定范围内的输出。</strong></p><p id="2d86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当在神经网络的几个隐藏层中使用激活函数时，我们可以在每个隐藏层中使用不同类型的激活函数。实践中使用了几种激活函数:</p><ol class=""><li id="2c65" class="kc kd hi ih b ii ij im in iq lr iu ls iy lt jc kj kk kl km bi translated"><strong class="ih hj"> Sigmoid </strong>:它接受输入并将输出映射到范围[0，1]。</li></ol><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es mn"><img src="../Images/3c86fe92909577a5be8608fcf0030d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/1*DecGcOcLDaeSwJYA65hRqg.png"/></div></figure><p id="709a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。Tanh(正切双曲函数):</strong>它接受输入并将输出映射到范围[-1，1]。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es mo"><img src="../Images/a8eeab552e13dde126b8764a4e3dc430.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*h2kF_L9AUNiFQ9SrG6ZdGQ.png"/></div></figure><p id="d17a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。ReLU(整流线性单元):</strong>是使用最广泛的激活功能。它将输出映射到范围[0，无穷大]。当x为正时，其值等于x，否则为0。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es mp"><img src="../Images/587be7e70a70960c3570308e744c8bbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/1*8uSgn143l1z2S4xkWcRPhg.png"/></div></figure><p id="1490" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。Softmax </strong>:类似于sigmoid函数，它将输出映射到范围[0，1]中，但在我们有多个类时使用。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es mq"><img src="../Images/6178e5884c80e9059fe0de06c1d557c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/format:webp/1*SM2SFuYuRKirwF9mNlR0gg.png"/></div></figure></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="bcb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我们已经介绍了基本的神经网络结构，以及它如何帮助构建非线性决策边界。此外，我们回顾了一些常见的激活功能，我们可以使用它们。在下一篇文章中，我们将开始使用数据训练我们的神经网络。</p><h2 id="fd4b" class="mr jf hi bd jg ms mt mu jk mv mw mx jo iq my mz js iu na nb jw iy nc nd ka ne bi translated">接下来:<a class="ae jd" rel="noopener" href="/analytics-vidhya/simple-explanation-from-logistic-regression-to-neural-network-part-3-284baee5db13">第三部分——如何训练神经网络模型。</a></h2></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="8e81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您有任何建议、想法、意见或问题，请在下面留言</p></div></div>    
</body>
</html>