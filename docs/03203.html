<html>
<head>
<title>All about YOLOs — Part3 — The Better, Faster and Stronger YOLOv2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于YOLOs的一切——第三部分——更好、更快、更强的YOLOv2</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/all-about-yolos-part3-the-better-faster-and-stronger-yolov2-9c0cf9de9758?source=collection_archive---------8-----------------------#2020-01-20">https://medium.com/analytics-vidhya/all-about-yolos-part3-the-better-faster-and-stronger-yolov2-9c0cf9de9758?source=collection_archive---------8-----------------------#2020-01-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/d3622f08e4e2574fcb14e07bc812d1c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MKQ84cP2dmXbfQRG.jpg"/></div></div></figure><div class=""/><p id="a349" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">YOLOv2项目开始让YOLO在准确性方面更好，在速度方面更快，在能够分类更多类别方面更强。</p><p id="ec81" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个5部分的系列旨在解释YOLO的一切，它的历史，它是如何版本化的，它的架构，它的基准，它的代码，以及如何让它为自定义对象工作。</p><p id="0732" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是该系列的链接。</p><p id="ea9b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@rehan_ahmad/all-about-yolos-part1-a-bit-of-history-a995bad5ac57"> <strong class="is hu">关于YOLOs的一切— Part1 —一点历史</strong> </a></p><p id="3103" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@rehan_ahmad/all-about-yolos-part2-the-first-yolo-2b5db7d78411"> <strong class="is hu">关于YOLOs — Part2 —第一个YOLO </strong> </a></p><p id="99e3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">关于YOLOs的一切——第三部分——更好、更快、更强YOLOv2 </strong></p><p id="cc3b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@rehan_ahmad/all-about-yolos-part4-yolov3-an-incremental-improvement-36b1eee463a2"> <strong class="is hu">关于YOLOs — Part4 — YOLOv3，一个增量改进</strong> </a></p><p id="356c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" rel="noopener" href="/@rehan_ahmad/all-about-yolos-part5-how-to-code-it-up-937f05cc9ae9"> <strong class="is hu">关于YOLOs —第5部分—启动并运行</strong> </a></p><h1 id="c9ef" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">丰富</h1><p id="b83c" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">在精确度方面，这里有一些渐进的改进。</p><ol class=""><li id="767f" class="ks kt ht is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la bi translated"><strong class="is hu">微调448*448分类器</strong>:执行大量图像检测任务的标准方式是在ImageNet上预先训练网络，通常是224*224图像大小，并在我们打算做的任务上进行微调。为了检测，我们通常将网络的大小调整得相当大，以便能够检测场景中较小的对象。这种方法的问题是，算法在较小图像上学习的特征可能无法很好地在较大图像上操作。因此，在YOLOv2中，他们添加了一个额外的层，以便在调整大小之后，在微调之前，他们在ImageNet的更大图像上训练网络。这使得精确度提高了+3.5倍。</li></ol><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lb"><img src="../Images/7eb88f91c69effe7618117cee1f92c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p-jdalY4R1I39hb3A1H-uw.png"/></div></div></figure><p id="fa19" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.<strong class="is hu">锚盒</strong>:在YOLO的原始版本中，它通过末端回归直接预测X，Y坐标以及宽度和高度。但其他系统，如更快的R-CNN和SSD，采用具有3种不同比例和3种不同纵横比的锚框概念，并计算这些预先给定的锚框的偏移，以预测对象的框。这使得算法只学习偏移和选择盒子的大小比自己学习这些信息更容易。YOLOv2采用了锚框的想法，但它不是预定义锚框，而是查看训练数据的边界框，并在这些框上运行k-means聚类，基本上得出一组更符合现实的维度聚类。这使得训练从一个真正好的地方开始。一种初始化技术。使用这些维度聚类获得了高达+5mAP的精度。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/e5768e8c954f5b0d04733c61ae430f91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LDTARkC1xffe8vcko2aBbg.png"/></div></div></figure><p id="0ca3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.<strong class="is hu">多尺度训练</strong>:一般来说，在训练检测器的时候，会考虑一个单一的长宽比，通常是448*448，推理图像会被调整大小以匹配这个长宽比。在YOLOv2中，网络将在整个训练过程中以32的倍数随机调整大小。每次调整层的大小时，它的后续层也会调整大小。这似乎大大提高了性能。作为一个副产品，我们可以在测试时改变图像的大小，并且在不改变权重的情况下获得检测结果。这使我们能够在不改变网络的情况下获得不同尺度的检测。这提供了+1.5mAP的改进</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lh"><img src="../Images/1d6a25871cd469b05e94297de0a70874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DhRcafTx-wXBbAho5j_PPg.png"/></div></div></figure><p id="78b2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在速度方面，这里有一些渐进的改进。</p><h2 id="3e47" class="li jq ht bd jr lj lk ll jv lm ln lo jz jb lp lq kd jf lr ls kh jj lt lu kl lv bi translated"><strong class="ak">黑暗19 </strong></h2><p id="c34f" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">与大多数人认为的相反，速度不仅仅是FLOPS(浮点运算)。VGG-16有更多的卷积层和更多的触发器，使得延迟很高，这对实时性不利。在YOLOv1中，使用了一种称为提取网络的新网络，减少了FLOPS，将GPU速度提高到200 FPS，并超过了VGG-16的分类精度。对于YOLO的第二个版本(YOLOv2 ),使用了称为Darknet19的新分类网络，它比YOLOv1更好，具有更高的精度和更少的FLOPS，而处理时间一样快。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lw"><img src="../Images/166608e692b4b461d5190626141f849c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pPloqPfbn20QMv4_qLmpcQ.png"/></div></div></figure><p id="a5c1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在新类方面，这里是一些增量改进。</p><h2 id="a297" class="li jq ht bd jr lj lk ll jv lm ln lo jz jb lp lq kd jf lr ls kh jj lt lu kl lv bi translated">单词树</h2><p id="6174" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">典型的数据集分为两类。检测数据集如COCO有80个类，分类数据集如ImageNet有22k个类，每个图像有一个标签，没有边界框。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lx"><img src="../Images/1446014782121a2048ca2bc6b45698e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T7iUlDyK60V83MLwxwuZWA.png"/></div></div></figure><p id="8eae" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对新类别进行训练的一个选项是收集一组图像，用类别和边界框坐标对其进行标记，并传递到模型权重的训练循环中，以更新到合并的新类别。</p><p id="7cf2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">YOLOv2试图将这两种数据集结合在一起，其中单个网络应该能够从检测数据集了解什么是对象以及对象在场景中的位置，并从分类数据集了解一些更细粒度的类别。这使得YOLOv2摆脱了80类的限制，能够从单个神经网络中检测数千类。</p><p id="cfdf" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通常，通过在末端层对所有类别应用SoftMax来预测类别概率。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ly"><img src="../Images/d77a75ac4e17f3fd2bfed2771de49a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tIYqD5GzC6TmiogU9JKxTg.png"/></div></div></figure><p id="9986" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了将这两个数据集组合在一起，用类似wordnet的层次结构实现了一个树形结构，以构建一个单词树。现在不是让一个单一的SoftMax来决定哪个类，而是进入一个更精细的类来说明对象是什么。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lz"><img src="../Images/ebfa40a585a55e7d13ab37bc61e5b2ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4mkezWMdSCMQpboCdaqYog.png"/></div></div></figure><p id="77e6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于训练部分，来自COCO和ImageNet的图像都被传递到网络中，并且每当网络看到具有标签和边界框坐标的图像时，检测和分类误差都被反向传播，并且当它只看到没有边界框的图像和标签时，它只反向传播分类误差。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ma"><img src="../Images/dcd0f98269ef7b32f605f87607672a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ah6dvgXZH8THRryO8oj5oA.png"/></div></div></figure><p id="adb7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种联合训练检测和分类数据集的聪明方法产生了惊人的结果。突然之间，YOLOv2能够检测和分类成千上万的物体。</p><figure class="lc ld le lf fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mb"><img src="../Images/9d10043cb20c047986d0f0bd0f757f25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2tba5u7bmz5NJ_3hLBVObg.png"/></div></div></figure><p id="93f4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些总结了YOLOv2中的改进。在下一篇文章中，我们来谈谈所有YOLOs中的明星——yolov 3</p><p id="88e4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">资源:</strong></p><p id="23dc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">https://arxiv.org/pdf/1506.02640.pdf<a class="ae jo" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">YOLO</a></p><p id="21a1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">YOLOv2和yolo 9000:<a class="ae jo" href="https://arxiv.org/pdf/1612.08242.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1612.08242.pdf</a></p><p id="ca5e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">约洛夫3:<a class="ae jo" href="https://arxiv.org/pdf/1804.02767.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1804.02767.pdf</a></p><blockquote class="mc md me"><p id="123c" class="iq ir mf is b it iu iv iw ix iy iz ja mg jc jd je mh jg jh ji mi jk jl jm jn hb bi translated"><em class="ht">关于我</em></p></blockquote><p id="f8ff" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我是<a class="ae jo" href="https://wavelabs.ai/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> Wavelabs.ai </a>的资深AI专家。我们Wavelabs帮助您利用人工智能(AI)来彻底改变用户体验并降低成本。我们使用人工智能独特地增强您的产品，以达到您的全部市场潜力。我们试图将尖端研究引入您的应用中。</p><p id="6668" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">欢迎访问<a class="ae jo" href="https://wavelabs.ai/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> Wavelabs.ai </a>了解更多信息。</p></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><p id="2ad5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">嗯，这都是在这个职位。感谢阅读:)</p><p id="fe26" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">保持好奇！</p><p id="a954" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以通过<a class="ae jo" href="https://www.linkedin.com/in/rehan-a-18675296?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p></div></div>    
</body>
</html>