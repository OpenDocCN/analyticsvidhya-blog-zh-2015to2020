<html>
<head>
<title>Spark: Web Server Logs Analysis with Scala</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark:使用Scala进行Web服务器日志分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spark-web-server-logs-analysis-with-scala-74e0ece40a4e?source=collection_archive---------3-----------------------#2019-11-24">https://medium.com/analytics-vidhya/spark-web-server-logs-analysis-with-scala-74e0ece40a4e?source=collection_archive---------3-----------------------#2019-11-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/fb83a2e7fd777f22324f3126e37c879d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pVjshxfwCmhRUEo8gEkDqg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Web服务器日志分析</figcaption></figure><p id="f2de" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi js translated">欢迎来到Spark cookbook系列，在上一篇文章中，我们制作了一个ETL(提取、转换和加载)示例，在该示例中，我们从CSV文件中加载数据，清理数据，对其进行一些转换，最后我们将其加载到postgreSQL数据库中，并将其导出为JSON文件。</p><p id="13fc" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在本文中，我们将向您展示解析web服务器日志文件并对其进行一些分析是多么简单。</p><p id="16c4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">一般来说，<strong class="iw hj">服务器日志</strong>是一个由服务器自动创建和维护的日志文件(或几个文件),由它执行的活动列表组成。例如，web服务器日志维护页面请求的历史。<a class="ae kb" href="https://en.wikipedia.org/wiki/World_Wide_Web_Consortium" rel="noopener ugc nofollow" target="_blank"> W3C </a>为web服务器日志文件维护了一种标准格式(<a class="ae kb" href="https://en.wikipedia.org/wiki/Common_Log_Format" rel="noopener ugc nofollow" target="_blank">通用日志格式</a>)。</p><p id="fef8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于这个实验，我们将使用来自<a class="ae kb" href="https://www.kaggle.com/shawon10/web-log-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>网站的随机数据集，它包含一年的所有HTTP请求。</p><h2 id="1c66" class="kc kd hi bd ke kf kg kh ki kj kk kl km jf kn ko kp jj kq kr ks jn kt ku kv kw bi translated">通用日志文件格式:</h2><p id="d428" class="pw-post-body-paragraph iu iv hi iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr hb bi translated">常见的日志文件格式如下:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="a200" class="kc kd hi lh b fi ll lm l ln lo"><em class="lp">remotehost rfc931 authuser [date] "request" status bytes</em></span></pre><ul class=""><li id="c661" class="lq lr hi iw b ix iy jb jc jf ls jj lt jn lu jr lv lw lx ly bi translated"><strong class="iw hj"> remotehost </strong>:远程主机名(或者IP号，如果DNS主机名不可用，或者DNSLookup关闭。</li><li id="563b" class="lq lr hi iw b ix lz jb ma jf mb jj mc jn md jr lv lw lx ly bi translated"><strong class="iw hj"> rfc931 </strong>:用户的远程日志名。</li><li id="f5a5" class="lq lr hi iw b ix lz jb ma jf mb jj mc jn md jr lv lw lx ly bi translated"><strong class="iw hj"> authuser </strong>:用户认证自己的用户名</li><li id="b4c8" class="lq lr hi iw b ix lz jb ma jf mb jj mc jn md jr lv lw lx ly bi translated"><strong class="iw hj">【日期】</strong>:请求的日期和时间。</li><li id="9414" class="lq lr hi iw b ix lz jb ma jf mb jj mc jn md jr lv lw lx ly bi translated"><strong class="iw hj">“请求”</strong>:来自客户端的请求行。</li><li id="24a4" class="lq lr hi iw b ix lz jb ma jf mb jj mc jn md jr lv lw lx ly bi translated"><strong class="iw hj">状态</strong>:返回给客户端的HTTP状态码。</li><li id="7660" class="lq lr hi iw b ix lz jb ma jf mb jj mc jn md jr lv lw lx ly bi translated"><strong class="iw hj">字节</strong>:传输文件的内容长度。</li></ul><h1 id="1e65" class="me kd hi bd ke mf mg mh ki mi mj mk km ml mm mn kp mo mp mq ks mr ms mt kv mu bi translated">我们开始吧:)</h1></div><div class="ab cl mv mw gp mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="hb hc hd he hf"><h1 id="f212" class="me kd hi bd ke mf nc mh ki mi nd mk km ml ne mn kp mo nf mq ks mr ng mt kv mu bi translated">先决条件:</h1><p id="327c" class="pw-post-body-paragraph iu iv hi iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr hb bi translated">这个示例是使用IntelliJ IDEA制作的，为了使用spark，请确保将其库添加到build.sbt文件中，如下所示:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="dc3e" class="kc kd hi lh b fi ll lm l ln lo"><em class="lp">name </em>:= "SparkLabs"<br/><br/><em class="lp">version </em>:= "0.1"<br/><br/><em class="lp">scalaVersion </em>:= "2.11.0"<br/><br/>// https://mvnrepository.com/artifact/org.apache.spark/spark-core<br/><em class="lp">libraryDependencies </em>+= "org.apache.spark" %% "spark-core" % "2.4.3"<br/><br/>// https://mvnrepository.com/artifact/org.apache.spark/spark-sql<br/><em class="lp">libraryDependencies </em>+= "org.apache.spark" %% "spark-sql" % "2.4.3"<br/><br/>// https://mvnrepository.com/artifact/org.postgresql/postgresql<br/><em class="lp">libraryDependencies </em>+= "org.postgresql" % "postgresql" % "42.2.8"</span></pre><h1 id="b66b" class="me kd hi bd ke mf mg mh ki mi mj mk km ml mm mn kp mo mp mq ks mr ms mt kv mu bi translated">I)加载日志文件:</h1><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nh"><img src="../Images/74072e743ac39cf26f47832c7f14b8cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kHL0xIuni7Pg_MZGrhrVFA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据加载</figcaption></figure><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="31b0" class="kc kd hi lh b fi ll lm l ln lo">Result : <br/>root<br/> |-- value: string (nullable = true)</span><span id="05c6" class="kc kd hi lh b fi ni lm l ln lo">+---------------------------------------------------------------+<br/>|value                                                          |<br/>+---------------------------------------------------------------+<br/>|IP,Time,URL,Staus                                              |<br/>|10.128.2.1,[29/Nov/2017:06:58:55,GET /login.php HTTP/1.1,200   |<br/>|10.128.2.1,[29/Nov/2017:06:59:02,POST /process.php HTTP/1.1,302|<br/>+---------------------------------------------------------------+<br/>only showing top 3 rows</span></pre><p id="b81d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">正如您在第12行中看到的，因为我们的数据是非结构化的，所以我们使用了text函数来读取文件，这产生了一个dataframe，其中只有一个名为“value”的列。</p><p id="abf1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，我们必须将数据解析到各个列中，为此我们将使用特殊函数<a class="ae kb" href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$" rel="noopener ugc nofollow" target="_blank"><strong class="iw hj"><em class="lp">regexp _ extract</em></strong></a><strong class="iw hj"><em class="lp">()</em></strong>，它们分别将要解析的列作为参数，要捕获的组的正则表达式和索引如下:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="3463" class="kc kd hi lh b fi ll lm l ln lo">def regexp_extract(e: Column, exp: String, groupIdx: Int): Column</span><span id="096d" class="kc kd hi lh b fi ni lm l ln lo">Extract a specific group matched by a Java regex, from the specified string column. If the regex did not match, or the specified group did not match, an empty string is returned.</span><span id="abf7" class="kc kd hi lh b fi ni lm l ln lo">Since<br/>1.5.0</span></pre><p id="b332" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果你不熟悉正则表达式，我建议你查看下面的网站。</p><div class="nj nk ez fb nl nm"><a href="https://regexone.com/lesson/introduction_abcs" rel="noopener  ugc nofollow" target="_blank"><div class="nn ab dw"><div class="no ab np cl cj nq"><h2 class="bd hj fi z dy nr ea eb ns ed ef hh bi translated">正则表达式-学习正则表达式-第1课:介绍，和ABC</h2><div class="nt l"><h3 class="bd b fi z dy nr ea eb ns ed ef dx translated">正则表达式在从文本中提取信息时非常有用，比如代码、日志文件、电子表格或…</h3></div><div class="nu l"><p class="bd b fp z dy nr ea eb ns ed ef dx translated">regexone.com</p></div></div></div></a></div><p id="5c2e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我想你已经注意到我们的日志文件只包含4个字段:</p><ul class=""><li id="aeb8" class="lq lr hi iw b ix iy jb jc jf ls jj lt jn lu jr lv lw lx ly bi translated">远程主机:10.128.2.1</li><li id="b19c" class="lq lr hi iw b ix lz jb ma jf mb jj mc jn md jr lv lw lx ly bi translated">日期:[29/11/2017:06:58:55</li><li id="86b7" class="lq lr hi iw b ix lz jb ma jf mb jj mc jn md jr lv lw lx ly bi translated">请求:GET /login.php HTTP/1.1</li><li id="9d3e" class="lq lr hi iw b ix lz jb ma jf mb jj mc jn md jr lv lw lx ly bi translated">状态:200</li></ul><h1 id="4805" class="me kd hi bd ke mf mg mh ki mi mj mk km ml mm mn kp mo mp mq ks mr ms mt kv mu bi translated">II)解析日志文件:</h1><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nh"><img src="../Images/27d6f840461a969a2c2a3c2dc7b2fc70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yLrqNuFkNuwZq0i6hQSTwg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">解析web服务器日志文件</figcaption></figure><p id="c51c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，现在我们将单列“值”分成四个单独的列:主机、时间戳、路径和状态，为了提供正则表达式，我们使用三重引号语法，这样我们就可以使用特殊的正则表达式字符' \d，\s …'，而不会转义反斜杠。^([^(\s|,)]+)意味着我们从行'^'的开头开始解析，然后我们捕获每个不是空格或逗号的字符'[^(\s|,)]'，通常s指的是任何空格字符，这就是为什么我们在方括号和'^'.中使用它</p><p id="ebbe" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们解析的结果如下:</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="a50e" class="kc kd hi lh b fi ll lm l ln lo">+----------+--------------------+------------------------+------+<br/>|host      |timestamp           |path                    |status|<br/>+----------+--------------------+------------------------+------+<br/>|IP        |                    |                        |null  |<br/>|10.128.2.1|29/Nov/2017:06:58:55|/login.php              |200   |<br/>|10.128.2.1|29/Nov/2017:06:59:02|/process.php            |302   |<br/>|10.128.2.1|29/Nov/2017:06:59:03|/home.php               |200   |<br/>|10.131.2.1|29/Nov/2017:06:59:04|/js/vendor/moment.min.js|200   |<br/>+----------+--------------------+------------------------+------+<br/>only showing top 5 rows</span><span id="2794" class="kc kd hi lh b fi ni lm l ln lo">root<br/> |-- host: string (nullable = true)<br/> |-- timestamp: string (nullable = true)<br/> |-- path: string (nullable = true)<br/> |-- status: integer (nullable = true)</span></pre><h1 id="69c1" class="me kd hi bd ke mf mg mh ki mi mj mk km ml mm mn kp mo mp mq ks mr ms mt kv mu bi translated">III)数据清理:</h1><h2 id="b1c9" class="kc kd hi bd ke kf kg kh ki kj kk kl km jf kn ko kp jj kq kr ks jn kt ku kv kw bi translated">I)零检查</h2><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nv"><img src="../Images/91fcdc4cce396006df759d3d124e7ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qlsluZdN69jBJtGzRX9LAw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据清理</figcaption></figure><p id="c7c2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这里，我们检查了初始数据集是否包含任何空值，然后检查了解析的每一列。我们发现解析的数据集包含<strong class="iw hj"> 219 </strong>个坏行。</p><p id="f167" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了统计每一列中空值的数量，我们创建了一个函数'<strong class="iw hj"> <em class="lp"> count_null </em> </strong>'，该函数将一列作为参数，然后过滤空值并将其转换为1，之后我们将所有的1值相加得到空值的总数</p><p id="9c67" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">结果:</strong></p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="6599" class="kc kd hi lh b fi ll lm l ln lo">Number of bad row in the initial dataset : 0<br/>Number of bad rows : 219<br/>+----+---------+----+------+<br/>|host|timestamp|path|status|<br/>+----+---------+----+------+<br/>|   0|        0|   0|   219|<br/>+----+---------+----+------+</span><span id="5550" class="kc kd hi lh b fi ni lm l ln lo">Number of bad rows : 219<br/>+--------------------+<br/>|          bad_status|<br/>+--------------------+<br/>|   IP,Time,URL,Staus|<br/>|chmod:,cannot,'a....|<br/>|chmod:,cannot,'er...|<br/>|rm:,cannot,'*.o':,No|<br/>|rm:,cannot,'a.out...|<br/>+--------------------+</span></pre><h2 id="3013" class="kc kd hi bd ke kf kg kh ki kj kk kl km jf kn ko kp jj kq kr ks jn kt ku kv kw bi translated">ii)修复具有空状态的行:</h2><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nw"><img src="../Images/373edef0f13d96ab3e2372aec507657c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HAWgH4nYPZSC9RfUhXCHfA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用na包删除具有空值的行</figcaption></figure><p id="9376" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这里我们选择删除所有空值的行。</p><p id="c023" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">结果:</strong></p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="b3a6" class="kc kd hi lh b fi ll lm l ln lo">The count of null value : 0<br/>Before : 16008 | After : 15789</span></pre><h2 id="a699" class="kc kd hi bd ke kf kg kh ki kj kk kl km jf kn ko kp jj kq kr ks jn kt ku kv kw bi translated">iii)解析时间戳:</h2><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nh"><img src="../Images/7348c909d1d5e6f1a0fa4bbfc372e06b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1nWqwODw1FG7AE48sQc0Sw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">将字符串解析为时间戳</figcaption></figure><p id="c853" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">结果:</strong></p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="38b7" class="kc kd hi lh b fi ll lm l ln lo">+--------------------+<br/>|to_date(`timestamp`)|<br/>+--------------------+<br/>|                null|<br/>|                null|<br/>+--------------------+<br/>only showing top 2 rows</span><span id="dbee" class="kc kd hi lh b fi ni lm l ln lo">root<br/> |-- host: string (nullable = true)<br/> |-- path: string (nullable = true)<br/> |-- status: integer (nullable = true)<br/> |-- time: timestamp (nullable = true)</span><span id="93b2" class="kc kd hi lh b fi ni lm l ln lo">+----------+------------+------+-------------------+<br/>|      host|        path|status|               time|<br/>+----------+------------+------+-------------------+<br/>|10.128.2.1|  /login.php|   200|2017-11-29 06:58:55|<br/>|10.128.2.1|/process.php|   302|2017-11-29 06:59:02|<br/>+----------+------------+------+-------------------+<br/>only showing top 2 rows</span></pre><h1 id="cc72" class="me kd hi bd ke mf mg mh ki mi mj mk km ml mm mn kp mo mp mq ks mr ms mt kv mu bi translated">IV)分析走查:</h1><h2 id="0710" class="kc kd hi bd ke kf kg kh ki kj kk kl km jf kn ko kp jj kq kr ks jn kt ku kv kw bi translated">I)我们的数据集的分布:</h2><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nx"><img src="../Images/4e88762caf8ef0d1548ceb22ea8adeaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1aijy7Lv8E5z8ys8mOQJog.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据分布</figcaption></figure><p id="066e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">结果:</strong></p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="dcbe" class="kc kd hi lh b fi ll lm l ln lo">status column statistics :<br/>+-------+------------------+<br/>|summary|            status|<br/>+-------+------------------+<br/>|  count|             15789|<br/>|   mean|230.19469250744189|<br/>| stddev| 50.05853522906924|<br/>|    min|               200|<br/>|    max|               404|<br/>+-------+------------------+</span><span id="0b38" class="kc kd hi lh b fi ni lm l ln lo">HTTP status analysis :<br/>+------+-----+<br/>|status|count|<br/>+------+-----+<br/>|   200|11330|<br/>|   206|   52|<br/>|   302| 3498|<br/>|   304|  658|<br/>|   404|  251|<br/>+------+-----+</span><span id="2dbf" class="kc kd hi lh b fi ni lm l ln lo">Frequent Hosts :<br/>+----------+-----+<br/>|      host|count|<br/>+----------+-----+<br/>|10.131.2.1| 1626|<br/>|10.128.2.1| 4257|<br/>|10.130.2.1| 4056|<br/>|10.131.0.1| 4198|<br/>|10.129.2.1| 1652|<br/>+----------+-----+</span><span id="ab3c" class="kc kd hi lh b fi ni lm l ln lo"><br/>+--------------------+-----+<br/>|                path|count|<br/>+--------------------+-----+<br/>|          /login.php| 3298|<br/>|           /home.php| 2653|<br/>|/js/vendor/modern...| 1417|<br/>|                   /|  862|<br/>|/contestproblem.p...|  467|<br/>|  /css/normalize.css|  408|<br/>|/css/bootstrap.mi...|  404|<br/>|/css/font-awesome...|  399|<br/>|      /css/style.css|  395|<br/>|       /css/main.css|  394|<br/>|/js/vendor/jquery...|  387|<br/>|/bootstrap-3.3.7/...|  382|<br/>|        /process.php|  317|<br/>|        /contest.php|  249|<br/>|        /archive.php|  246|<br/>|/fonts/fontawesom...|  245|<br/>|         /robots.txt|  224|<br/>|       /img/ruet.png|  213|<br/>|/bootstrap-3.3.7/...|  191|<br/>|/js/vendor/moment...|  173|<br/>+--------------------+-----+<br/>only showing top 20 rows</span><span id="7932" class="kc kd hi lh b fi ni lm l ln lo">Top Paths :<br/>+--------------------+-----+<br/>|                path|count|<br/>+--------------------+-----+<br/>|          /login.php| 3298|<br/>|           /home.php| 2653|<br/>|/js/vendor/modern...| 1417|<br/>|                   /|  862|<br/>|/contestproblem.p...|  467|<br/>|  /css/normalize.css|  408|<br/>|/css/bootstrap.mi...|  404|<br/>|/css/font-awesome...|  399|<br/>|      /css/style.css|  395|<br/>|       /css/main.css|  394|<br/>+--------------------+-----+<br/>only showing top 10 rows</span></pre><h2 id="5e64" class="kc kd hi bd ke kf kg kh ki kj kk kl km jf kn ko kp jj kq kr ks jn kt ku kv kw bi translated">ii)分析Web服务器日志文件:</h2><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ny"><img src="../Images/4b025d4f56657a3a17fb60762e8e1827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cgO-tTeUs7d9AIXYr6V2_w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据探索</figcaption></figure><p id="e8f0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">结果:</strong></p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="9484" class="kc kd hi lh b fi ll lm l ln lo">Top Ten Error Paths :<br/>+--------------------+-----+<br/>|                path|count|<br/>+--------------------+-----+<br/>|           /home.php| 2167|<br/>|                   /|  741|<br/>|        /process.php|  317|<br/>|         /robots.txt|  224|<br/>|         /action.php|   83|<br/>|/contestproblem.p...|   74|<br/>|/js/vendor/jquery...|   73|<br/>|/js/vendor/modern...|   72|<br/>|/css/bootstrap.mi...|   72|<br/>|       /css/main.css|   68|<br/>+--------------------+-----+<br/>only showing top 10 rows</span><span id="5123" class="kc kd hi lh b fi ni lm l ln lo">Unique hosts : 5</span><span id="3c8e" class="kc kd hi lh b fi ni lm l ln lo">Number of Unique Daily Hosts :<br/>+---+----+-----+<br/>|day|year|count|<br/>+---+----+-----+<br/>|311|2017|    1|<br/>|312|2017|    5|<br/>|313|2017|    5|<br/>|314|2017|    5|<br/>|315|2017|    5|<br/>+---+----+-----+<br/>only showing top 5 rows</span><span id="b1c3" class="kc kd hi lh b fi ni lm l ln lo">Average Number of Daily Requests per Host :<br/>+---+----+------------------------+<br/>|day|year|avg_req_per_host_per_day|<br/>+---+----+------------------------+<br/>|335|2017|                    93.6|<br/>|327|2017|                    76.0|<br/>| 60|2018|      10.333333333333334|<br/>|350|2017|      51.666666666666664|<br/>| 46|2018|       6.666666666666667|<br/>+---+----+------------------------+<br/>only showing top 5 rows</span></pre><h2 id="7db6" class="kc kd hi bd ke kf kg kh ki kj kk kl km jf kn ko kp jj kq kr ks jn kt ku kv kw bi translated">iii)探索404状态代码:</h2><p id="0f1a" class="pw-post-body-paragraph iu iv hi iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr hb bi translated">让我们深入研究错误404状态记录，我们都见过那些“404未找到”的网页。当服务器找不到浏览器客户端请求的资源(页面或对象)时，返回404错误。</p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nw"><img src="../Images/b57e9cc4caf5c30962b7e30ac2b361d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oGU8-wXkTSrcOcglK6OX-w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">404状态代码分析</figcaption></figure><p id="48af" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">结果:</strong></p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="a030" class="kc kd hi lh b fi ll lm l ln lo">Counting 404 Response Codes :<br/>found 251 404 Urls</span><span id="34e8" class="kc kd hi lh b fi ni lm l ln lo">Listing 404 Status Code Records :<br/>+---------------------------------------+<br/>|path                                   |<br/>+---------------------------------------+<br/>|/css/bootstrap.min.css.map             |<br/>|/robots.txt                            |<br/>|/djs/vendor/bootstrap-datetimepicker.js|<br/>|/favicon.ico                           |<br/>+---------------------------------------+</span><span id="c6f5" class="kc kd hi lh b fi ni lm l ln lo">Listing The Top Twenty 404 Response Code Paths :<br/>+---------------------------------------+-----+<br/>|path                                   |count|<br/>+---------------------------------------+-----+<br/>|/css/bootstrap.min.css.map             |1    |<br/>|/djs/vendor/bootstrap-datetimepicker.js|7    |<br/>|/favicon.ico                           |19   |<br/>|/robots.txt                            |224  |<br/>+---------------------------------------+-----+</span><span id="c3fa" class="kc kd hi lh b fi ni lm l ln lo">+--------------------+--------------------+-------------+<br/>|                path|  collect_list(host)|count(status)|<br/>+--------------------+--------------------+-------------+<br/>|/css/bootstrap.mi...|        [10.130.2.1]|            1|<br/>|/djs/vendor/boots...|[10.131.0.1, 10.1...|            7|<br/>|        /favicon.ico|[10.128.2.1, 10.1...|           19|<br/>|         /robots.txt|[10.131.0.1, 10.1...|          224|<br/>+--------------------+--------------------+-------------+</span><span id="b342" class="kc kd hi lh b fi ni lm l ln lo">+--------------------+--------------------+-------------+<br/>|                path|   collect_set(host)|count(status)|<br/>+--------------------+--------------------+-------------+<br/>|/css/bootstrap.mi...|        [10.130.2.1]|            1|<br/>|/djs/vendor/boots...|[10.130.2.1, 10.1...|            7|<br/>|        /favicon.ico|[10.130.2.1, 10.1...|           19|<br/>|         /robots.txt|[10.130.2.1, 10.1...|          224|<br/>+--------------------+--------------------+-------------+</span><span id="762b" class="kc kd hi lh b fi ni lm l ln lo">Listing the Top Twenty-five 404 Response Code Hosts :<br/>+----------+-----+<br/>|host      |count|<br/>+----------+-----+<br/>|10.128.2.1|67   |<br/>|10.131.0.1|61   |<br/>|10.130.2.1|52   |<br/>|10.129.2.1|41   |<br/>|10.131.2.1|30   |<br/>+----------+-----+</span><span id="33d0" class="kc kd hi lh b fi ni lm l ln lo"> Listing 404 Errors per Day :<br/>+---+----+-----+<br/>|day|year|count|<br/>+---+----+-----+<br/>|312|2017|    8|<br/>|313|2017|   10|<br/>|314|2017|    6|<br/>|315|2017|   12|<br/>|316|2017|    6|<br/>|317|2017|   10|<br/>|318|2017|   18|<br/>|319|2017|    8|<br/>|320|2017|   10|<br/>|321|2017|    5|<br/>+---+----+-----+<br/>only showing top 10 rows</span></pre><h2 id="cbfa" class="kc kd hi bd ke kf kg kh ki kj kk kl km jf kn ko kp jj kq kr ks jn kt ku kv kw bi translated">总结:</h2><p id="28ce" class="pw-post-body-paragraph iu iv hi iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr hb bi translated">在本实验中，我们学习了如何使用regexp_extract函数加载和解析数据，然后在na包的帮助下清理数据，然后使用UDF将日期列转换为有效的时间戳，最后我们浏览了数据并对其进行了一些分析。</p><h1 id="72f3" class="me kd hi bd ke mf mg mh ki mi mj mk km ml mm mn kp mo mp mq ks mr ms mt kv mu bi translated">附录:</h1><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="c024" class="kc kd hi lh b fi ll lm l ln lo">import org.apache.log4j.{Level, Logger}<br/>import org.apache.spark.sql.{Column, SparkSession}<br/>import org.apache.spark.sql.functions.{<em class="lp">regexp_extract</em>,sum,<em class="lp">col</em>,to_date,udf,to_timestamp,<em class="lp">desc</em>,<em class="lp">dayofyear</em>,<em class="lp">year</em>}<br/><br/><br/>object WebLog extends App {<br/><br/>  Logger.<em class="lp">getLogger</em>("org").setLevel(Level.<em class="lp">OFF</em>)<br/>  val <em class="lp">spark </em>= SparkSession.<em class="lp">builder</em>().appName("WebLog").master("local[*]").getOrCreate()<br/>  import <em class="lp">spark</em>.implicits._<br/>  //this will produce a dataframe with a single column called value<br/>  val <em class="lp">base_df </em>= <em class="lp">spark</em>.read.text("/home/achraf/Desktop/labo/SparkLab/datasets/weblog.csv")<br/>  <em class="lp">base_df</em>.printSchema()<br/><br/>  //let's look at some of the data<br/>  <em class="lp">base_df</em>.show(3,false)<br/><br/>  /* So our data is organized as follows<br/>  |remote host  : 10.128.2.1<br/>  | date        : [29/Nov/2017:06:58:55<br/>  | request     : GET /login.php HTTP/1.1<br/>  | status      : 200<br/>   */<br/><br/>  /*<br/>      Parsing the log file<br/>   */<br/>  val <em class="lp">parsed_df </em>= <em class="lp">base_df</em>.select(<em class="lp">regexp_extract</em>($"value","""^([^(\s|,)]+)""",1).alias("host"),<br/>    <em class="lp">regexp_extract</em>($"value","""^.*\[(\d\d/\w{3}/\d{4}:\d{2}:\d{2}:\d{2})""",1).as("timestamp"),<br/>    <em class="lp">regexp_extract</em>($"value","""^.*\w+\s+([^\s]+)\s+HTTP.*""",1).as("path"),<br/>    <em class="lp">regexp_extract</em>($"value","""^.*,([^\s]+)$""",1).cast("int").alias("status"))<br/>  <em class="lp">parsed_df</em>.show(5,false)<br/>  <em class="lp">parsed_df</em>.printSchema()<br/><br/>  /*<br/>     Data cleaning<br/>   */<br/>  // check if the initial dataset contain any null values<br/>  <em class="lp">println</em>("Number of bad row in the initial dataset : " + <em class="lp">base_df</em>.filter($"value".isNull).count())<br/><br/>  // lets see our parsed dataset<br/>  val <em class="lp">bad_rows_df </em>= <em class="lp">parsed_df</em>.filter($"host".isNull || $"timestamp".isNull || $"path".isNull || $"status".isNull)<br/>  <em class="lp">println</em>("Number of bad rows : " + <em class="lp">bad_rows_df</em>.count())<br/>  // same result as the previous statement but with different syntax<br/>  //val bad_rows_df = parsed_df.filter($"host".isNull.or($"timestamp".isNull).or($"path".isNull)<br/>  // .or($"status".isNull)).count<br/><br/>  // lets count number of null values in each column<br/>  // we create a function that convert null value to one and then we count the number of one value<br/>  def count_null(col_name: Column): Column = <em class="lp">sum</em>(col_name.isNull.cast("int")).alias(col_name.toString())<br/>  val <em class="lp">t </em>= <em class="lp">parsed_df</em>.columns.map(col_name =&gt; <em class="lp">count_null</em>(<em class="lp">col</em>(col_name)))<br/>  <em class="lp">parsed_df</em>.select(<em class="lp">t</em>: _*).show()<br/><br/>  // So all the null values are in status column, let's check what does it contain<br/>  val <em class="lp">bad_status_df </em>= <em class="lp">base_df</em>.select(<em class="lp">regexp_extract</em>($"value","""([^\d]+)$""",1).as("bad_status"))<br/>    .filter($"bad_status".notEqual(""))<br/>  <em class="lp">println</em>("Number of bad rows : " + <em class="lp">bad_status_df</em>.count())<br/>  // So the bad content correspond to error result, in our case this is just polluting our logs and our results<br/>  <em class="lp">bad_status_df</em>.show(5)<br/><br/><br/>  /*<br/>       Fix the rows with null status<br/>   */<br/><br/>  // we have two option, replace the null value by some other meaningful value, or delete the whole line<br/>  // we will go with the other option since those lines are with no value for us<br/>  // we will use the na subpackage on a dataframe<br/>  val <em class="lp">cleaned_df </em>= <em class="lp">parsed_df</em>.na.drop()<br/><br/>  // let's check that we don't have any null value<br/>  <em class="lp">println</em>("The count of null value : " + <em class="lp">cleaned_df</em>.filter($"host".isNull || $"timestamp".isNull || $"path".isNull<br/>    || $"status".isNull).count())<br/>  // count before and after<br/>  <em class="lp">println</em>("Before : " + <em class="lp">parsed_df</em>.count() + " | After : " + <em class="lp">cleaned_df</em>.count())<br/><br/>  /*<br/>       Parsing the timestamp<br/>   */<br/>  // let's try to cast the timestamp column to date<br/>  // surprised ! we got null value, that's because when spark is not able to convert a date value<br/>  // it just return null<br/>  <em class="lp">cleaned_df</em>.select(<em class="lp">to_date</em>($"timestamp")).show(2)<br/><br/>  // Let's fix this by converting the timestamp column to the format spark knows<br/>  val <em class="lp">month_map </em>= <em class="lp">Map</em>("Jan" -&gt; 1, "Feb" -&gt; 2, "Mar" -&gt; 3, "Apr" -&gt; 4, "May" -&gt; 5, "Jun" -&gt; 6, "Jul" -&gt; 7, "Aug" -&gt; 8<br/>    , "Sep" -&gt; 9, "Oct" -&gt; 10, "Nov" -&gt; 11, "Dec" -&gt; 12)<br/>  def parse_clf_time(s: String) ={<br/>    "%3$s-%2$s-%1$s %4$s:%5$s:%6$s".format(s.substring(0,2),<em class="lp">month_map</em>(s.substring(3,6)),s.substring(7,11)<br/>      ,s.substring(12,14),s.substring(15,17),s.substring(18))<br/>  }<br/><br/>  val <em class="lp">toTimestamp </em>= <em class="lp">udf</em>[String, String](<em class="lp">parse_clf_time</em>(_))<br/>  val <em class="lp">logs_df </em>= <em class="lp">cleaned_df</em>.select($"*",<em class="lp">to_timestamp</em>(<em class="lp">toTimestamp</em>($"timestamp")).alias("time"))<br/>    .drop("timestamp")<br/>  <em class="lp">logs_df</em>.printSchema()<br/>  <em class="lp">logs_df</em>.show(2)<br/>  // We cache the dataset so the next action would be faster<br/>  <em class="lp">logs_df</em>.cache()<br/><br/>  //       ====&lt;  Analysis walk-trough  &gt;====<br/><br/>  /*<br/>       status column statistics<br/>   */<br/>  <em class="lp">logs_df</em>.describe("status").show()<br/>  /*<br/>       HTTP status analysis<br/>   */<br/>  <em class="lp">logs_df</em>.groupBy("status").count().sort("status").show()<br/><br/>  /*<br/>       Frequent Hosts<br/>   */<br/>  <em class="lp">logs_df</em>.groupBy("host").count().filter($"count" &gt; 10).show()<br/>  /*<br/>       Visualizing Paths<br/>   */<br/>  <em class="lp">logs_df</em>.groupBy("path").count().sort(<em class="lp">desc</em>("count")).show()<br/>  /*<br/>       Top Paths<br/>   */<br/>  <em class="lp">logs_df</em>.groupBy("path").count().sort(<em class="lp">desc</em>("count")).show(10)<br/><br/>  //       ====&lt; Analyzing Web Server Log File &gt;====<br/><br/>  /*<br/>       Top Ten Error Paths<br/>   */<br/>  <em class="lp">logs_df</em>.filter($"status" =!= 200).groupBy("path").count().sort(<em class="lp">desc</em>("count"))<br/>    .show(10)<br/>  /*<br/>       Number of unique Hosts<br/>   */<br/>  val <em class="lp">unique_host_count </em>= <em class="lp">logs_df</em>.select("host").distinct().count()<br/>  <em class="lp">println</em>("Unique hosts : %d".format(<em class="lp">unique_host_count</em>))<br/>  /*<br/>       Number of Unique Daily Hosts :<br/>   */<br/>  val <em class="lp">daily_hosts_df </em>= <em class="lp">logs_df</em>.withColumn("day",<em class="lp">dayofyear</em>($"time")).withColumn("year",<em class="lp">year</em>($"time"))<br/>    .select("host","day","year").distinct().groupBy("day","year")<br/>    .count().sort("year","day").cache()<br/>  <em class="lp">daily_hosts_df</em>.show(5)<br/>  /*<br/>       Average Number of Daily Requests per Host<br/>   */<br/>  val <em class="lp">total_req_per_day_df </em>= <em class="lp">logs_df</em>.withColumn("day", <em class="lp">dayofyear</em>($"time"))<br/>    .withColumn("year", <em class="lp">year</em>($"time"))<br/>    .groupBy("day", "year").count()<br/>  val <em class="lp">avg_daily_request_per_host_df </em>= <em class="lp">total_req_per_day_df</em>.join(<em class="lp">daily_hosts_df</em>,<br/>    <em class="lp">total_req_per_day_df</em>("day") === <em class="lp">daily_hosts_df</em>("day")<br/>    &amp;&amp; <em class="lp">total_req_per_day_df</em>("year") === <em class="lp">daily_hosts_df</em>("year"))<br/>    .select(<em class="lp">daily_hosts_df</em>("day"), <em class="lp">daily_hosts_df</em>("year"),<br/>      (<em class="lp">total_req_per_day_df</em>("count") / <em class="lp">daily_hosts_df</em>("count")).alias("avg_req_per_host_per_day")).cache()<br/>  <em class="lp">avg_daily_request_per_host_df</em>.show(5)<br/><br/>  //      ====&lt; Exploring 404 status codes &gt;====<br/>  /*<br/>      Let's drill down and explore the error 404 status records, We've all seen those "404 Not Found" web pages.<br/>      404 errors are returned when the server cannot find the resource (page or object) the browser client requested.<br/>   */<br/><br/>    //   Counting 404 Response Codes<br/>  val <em class="lp">not_found_df </em>= <em class="lp">logs_df</em>.where($"status" === 404).cache()<br/>  <em class="lp">println</em>("found %d 404 Urls".format(<em class="lp">not_found_df</em>.count()))<br/><br/>    //   Listing 404 Status Code Records<br/>  <em class="lp">not_found_df</em>.select("path").distinct().show(40,false)<br/><br/>    //   Listing The Top Twenty 404 Response Code Paths :<br/>  <em class="lp">not_found_df</em>.groupBy("path").count().sort("count").show(20,false)<br/>  <em class="lp">not_found_df</em>.groupBy("path").agg("host" -&gt; "collect_list","status" -&gt; "count")<br/>    .sort("count(status)").show(20)<br/>  <em class="lp">not_found_df</em>.groupBy("path").agg("host" -&gt; "collect_set","status" -&gt; "count")<br/>    .sort("count(status)").show(20)<br/><br/>    //   Listing the Top Twenty-five 404 Response Code Hosts<br/>  <em class="lp">not_found_df</em>.groupBy("host").count().sort(<em class="lp">desc</em>("count")).show(truncate = false)<br/><br/>    //   Listing 404 Errors per Day<br/>  val <em class="lp">errors_by_date_pair_df </em>= <em class="lp">not_found_df</em>.withColumn("day", <em class="lp">dayofyear</em>($"time"))<br/>    .withColumn("year", <em class="lp">year</em>($"time")).groupBy("day","year").count()<br/>  <em class="lp">not_found_df</em>.withColumn("day", <em class="lp">dayofyear</em>($"time")).withColumn("year", <em class="lp">year</em>($"time"))<br/>    .groupBy("day","year").count().sort($"year",$"day").show(10)<br/><br/>}</span></pre></div></div>    
</body>
</html>