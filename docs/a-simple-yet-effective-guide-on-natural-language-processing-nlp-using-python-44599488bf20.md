# 关于使用 Python 进行自然语言处理(NLP)的简单而有效的指南

> 原文：<https://medium.com/analytics-vidhya/a-simple-yet-effective-guide-on-natural-language-processing-nlp-using-python-44599488bf20?source=collection_archive---------10----------------------->

![](img/b9e41075792884f0d1c74c2068811919.png)

自然语言处理(NLP)！虽然这个术语看起来很新，但我敢打赌，你一生中肯定至少用过一次。

*   有没有想过，当你在 Gmail 上输入邮件时，它是如何提示你一个完整的句子的？
*   很多时候，邮件会自动进入你的垃圾邮件文件夹。这是怎么发生的？
*   Alexa，Siri 等怎么样？能够理解你？

这样的例子不胜枚举。

在本教程中，我们将通过一步一步的指导，帮助您开始自然语言处理(NLP)。

## 在我们开始之前，NLP 可以用于各种目的，但不限于:

*   **文本分类**

这是一个通过分析和给文本分配标签来帮助我们根据其内容对文本进行分类的过程。

*   **情绪分析**

情绪是情感的同义词。使用情感分析，我们可以识别从博客、评论到社交媒体等各种来源的观点。

*   **话题造型**

主题建模帮助你发现出现在文档集合中的主题。

*   **位置标记**

词性标注是将文本中的单词标记为特定词性的过程。POS 是 lemmatizers 的基本构件之一，我们将在本文中继续讨论它。

尽管 NLP 还可以应用于更多领域，但在本文 中，我们将特别关注 ***文本分类。***

正如我们所知，在建立任何机器学习模型时，第一步是清理和转换数据，然后这些数据可以被机器学习算法识别，并有助于训练整个模型。

使用 NLP 时最重要的库是 ***自然语言工具包 wiz NLTK。*** 由众多内置函数组成，如**标记化、词条化、词干化**等。这形成了在我们训练机器学习算法之前清理和转换文本数据的整体部分。

1.  **删除空值行**

虽然，我们在这种情况下考虑的是一个句子，但是当你在处理真实世界的数据集时，你是在同时处理数百万条记录。所以第一步是检查当前句子是否为空。如果它是一个空值，我们需要丢弃它并遍历下一行。这是一个重要的步骤，因为在数据集中处理空值是很常见的，甚至当您从任何网站提取数据时也是如此。

2.**数据的符号化**

标记化帮助我们把句子分成单词，因为我们的大脑逐字分析句子，机器也是如此。这有助于我们一个一个地处理单词。

3.**停用词的移除**

这些是在每个句子中出现的最常见的单词，但是不会增加文档含义的价值，因此对于分析数据是不必要的。停用词包括诸如“a”、“the”、“an”、“this”以及许多其他需要在进一步处理之前删除的词。

4.**删除非字母文本**

现在我们的输入文本没有了停用词，但仍然由数字和特殊字符组成。非字母文本不能被机器学习算法处理，并且不会因其在数据中的存在而受到影响。

5.**分词词干**

词干提取是从给定单词中检索词根的过程。例如，像 dance，dancer 这样的词是 dance 这个词的不同形式。如果我们不阻止这些单词，或者不转换成它们的词根，我们将最终为它们中的每一个生成向量，并最终在算法上投入额外的工作。“nltk.stem”包为我们提供了词干分析器，可以用来将一个单词转换成它们的词根。

6.**组词造句**

在执行了上述过程之后，在被转换成矢量化格式之前，需要将标记化的单词再次组合成句子。

为了说明(兴奋😜我从电影《哈利·波特与密室》中摘录了如下对话

“决定我们成为什么样的人的不是我们的能力，而是我们的选择。”

虽然听起来很好，但我们现在已经将这句话转换为适当的形式，然后再输入到我们的机器学习算法中。

这是这样的:-

![](img/98336d64cbcf05d6a6a9592eb866181d.png)

让我们进入下一步。

# 文本矢量化

文本矢量化有助于将文本数据转换为一系列数字因子，以便进一步处理。我们可以通过各种技术来实现这一点。其中一些描述如下。

1.  **计数矢量器**

计数矢量器通过查看文本是否出现在单词列表(BOW)中来帮助我们将文本转换成矢量格式。单词包是一种文本表示，它基于限制因素描述单词在文档中的出现，限制因素可以是单字母(单个单词)、双字母(两个单词)以及 N 字母(N 个单词)。

2.**词频-逆文档频率(TF-IDF)**

**词频(TF)** 定义为单词在文档或语料库中出现的频率。因为每个句子的长度不同，所以一个单词在长句中出现的次数可能比在短句中多。**逆文档频率(IDF)** 是用于找出最重要的单词的概念。 **TF-IDF** 帮助减少在不同文档中使用的常用单词的值。

3. **Word2vec**

Word2vec 使用神经网络来确定它们之间的关联，这是使用 google 预先训练的数据集来完成的。

在本教程中，我们使用计数矢量器对数据进行矢量化，但可以很容易地被前者所取代。

现在我们已经熟悉了自然语言处理(NLP)的工作流，让我们来看一下代码。

上面的代码是我们前面讨论的步骤的实现。在对数据进行预处理和矢量化之后，我们将它扔给机器学习算法来训练数据。通过生成分类报告，可以进一步验证结果的准确性。您可以使用额外的度量标准(比如混淆矩阵)来进一步测试模型。

> **在上述代码中输入的数据集将包括两列，第一列是需要训练的文本/句子，随后是需要预测的类别标签。在按下 run 按钮之前，请务必更新第 24 行和第 45 行的列名。**

感谢您阅读本文。在你最喜欢的数据集上试试上面的代码，我相信你会很兴奋地看到结果。您可以随意地进一步操作代码，以提高模型的整体性能。

如果你喜欢这篇文章，请与你的朋友和同事分享。如果你有任何问题，请在下面的评论区随意发表。