<html>
<head>
<title>Transfer Learning — Face recognition &amp; Image classification .</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">迁移学习-人脸识别和图像分类。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/transfer-learning-face-recognition-image-classification-55920098f5b7?source=collection_archive---------15-----------------------#2020-07-22">https://medium.com/analytics-vidhya/transfer-learning-face-recognition-image-classification-55920098f5b7?source=collection_archive---------15-----------------------#2020-07-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/e1d28c16bdb42920b8a4e4e2bea6924b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*sBJrriHxm-rJbwKf.jpg"/></div></figure><h1 id="4132" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">❗Problem statement❗:</h1><p id="b0b5" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">使用迁移学习创建一个项目，解决各种问题，如人脸识别、图像分类，使用现有的深度学习模型，如VGG16、VGG19、ResNet、MobileNet等。</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="ebb9" class="im in hi bd io ip kp ir is it kq iv iw ix kr iz ja jb ks jd je jf kt jh ji jj bi translated"><strong class="ak">基本信息:</strong></h1><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es ku"><img src="../Images/76d961f3aab98c5fe3327965373d89fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*tKFU-wW4qMfDiv8wf_6uMw.jpeg"/></div></figure><h2 id="6f70" class="kz in hi bd io la lb lc is ld le lf iw jv lg lh ja jz li lj je kd lk ll ji lm bi translated">📌迁移学习:</h2><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/e30e70fb158abe0c3d100a4f5c3e53f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/0*_fJlsmVmFk1PEGIE.png"/></div></figure><p id="168f" class="pw-post-body-paragraph jk jl hi jm b jn lo jp jq jr lp jt ju jv lq jx jy jz lr kb kc kd ls kf kg kh hb bi translated">迁移学习通常指的是这样一个过程，即在一个问题上训练的模型以某种方式用于另一个相关的问题。</p><p id="a554" class="pw-post-body-paragraph jk jl hi jm b jn lo jp jq jr lp jt ju jv lq jx jy jz lr kb kc kd ls kf kg kh hb bi translated">在深度学习中，迁移学习是一种技术，通过这种技术，神经网络模型首先针对与正在解决的问题类似的问题进行训练。然后，来自训练模型的一个或多个层被用在针对感兴趣的问题训练的新模型中。</p><p id="8b8d" class="pw-post-body-paragraph jk jl hi jm b jn lo jp jq jr lp jt ju jv lq jx jy jz lr kb kc kd ls kf kg kh hb bi translated">迁移学习具有减少神经网络模型的训练时间的优点，并且可以导致更低的泛化误差。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es lt"><img src="../Images/a192193dcebbb9d0fa851fb616b041dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UV0kHZtFi-7aSedu.png"/></div></div></figure><h2 id="1a7c" class="kz in hi bd io la lb lc is ld le lf iw jv lg lh ja jz li lj je kd lk ll ji lm bi translated">📌预训练模型:</h2><p id="e966" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">一个<strong class="jm hj">前</strong> - <strong class="jm hj">训练过的模型</strong>是一个<strong class="jm hj">模型</strong>由其他人创建来解决类似的问题。不是从零开始建立一个<strong class="jm hj">模型</strong>来解决一个类似的问题，<strong class="jm hj">你</strong>使用<strong class="jm hj">模型训练</strong>解决其他问题作为起点。</p><p id="4c53" class="pw-post-body-paragraph jk jl hi jm b jn lo jp jq jr lp jt ju jv lq jx jy jz lr kb kc kd ls kf kg kh hb bi translated">为什么我们使用预训练模型:</p><ul class=""><li id="8e86" class="ly lz hi jm b jn lo jr lp jv ma jz mb kd mc kh md me mf mg bi translated">如果你从头开始构建模型，那么你必须花大量的时间来训练你的模型。你将不得不做大量的计算和实验来建立一个合适的CNN架构。</li><li id="ec4f" class="ly lz hi jm b jn mh jr mi jv mj jz mk kd ml kh md me mf mg bi translated">你可能没有足够大的数据集来使你的模型能够足够好地概括，你也可能没有足够的计算资源。</li><li id="7985" class="ly lz hi jm b jn mh jr mi jv mj jz mk kd ml kh md me mf mg bi translated">请记住，ImageNet有1000个类，因此预先训练的模型已经被训练为处理许多不同的事情。</li></ul><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/6969e6bdefee379b7cfef9f47ecd8ce2.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*I_9x9WewATNcnhzu.jpg"/></div></figure><h2 id="45ec" class="kz in hi bd io la lb lc is ld le lf iw jv lg lh ja jz li lj je kd lk ll ji lm bi translated">📌MobileNet:</h2><p id="5147" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">MobileNets是Tensorflow的一系列<em class="mn">移动优先</em>计算机视觉模型，旨在有效地最大化准确性，同时注意设备或嵌入式应用的有限资源。它是一种有效的卷积神经网络，在目标检测中具有显著的效果。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/d338638b055d8977d95122e703f7ca42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/0*1XpWSL9d0WPD_RIY.png"/></div></figure></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="075b" class="pw-post-body-paragraph jk jl hi jm b jn lo jp jq jr lp jt ju jv lq jx jy jz lr kb kc kd ls kf kg kh hb bi translated"><strong class="jm hj">环境中需要的模块:</strong></p><ul class=""><li id="bc92" class="ly lz hi jm b jn lo jr lp jv ma jz mb kd mc kh md me mf mg bi translated">喀拉斯**</li><li id="ade0" class="ly lz hi jm b jn mh jr mi jv mj jz mk kd ml kh md me mf mg bi translated">张量流**</li><li id="059f" class="ly lz hi jm b jn mh jr mi jv mj jz mk kd ml kh md me mf mg bi translated">opencv(用于cv2) **</li><li id="6e64" class="ly lz hi jm b jn mh jr mi jv mj jz mk kd ml kh md me mf mg bi translated">枕头</li><li id="1a5d" class="ly lz hi jm b jn mh jr mi jv mj jz mk kd ml kh md me mf mg bi translated">Numpy</li></ul></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="2397" class="im in hi bd io ip kp ir is it kq iv iw ix kr iz ja jb ks jd je jf kt jh ji jj bi translated">🎭面部识别:</h1><p id="1a11" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">人脸识别在迁移学习中工作得非常好。在一个要点中，你采用在庞大的数据集上训练的权重，例如LFW(在野外标记的人脸)，然后你自己训练模型。</p><p id="2b35" class="pw-post-body-paragraph jk jl hi jm b jn lo jp jq jr lp jt ju jv lq jx jy jz lr kb kc kd ls kf kg kh hb bi translated">为了用作现有的深度学习模型，我使用了<strong class="jm hj"> MobileNet。</strong></p><p id="41ca" class="pw-post-body-paragraph jk jl hi jm b jn lo jp jq jr lp jt ju jv lq jx jy jz lr kb kc kd ls kf kg kh hb bi translated">通过网络摄像头在给定路径位置的文件夹中收集50–100个图像样本，并创建两个单独的文件夹“训练”和“验证”,这两个文件夹称为“类”,将样本图像文件夹放入“训练”文件夹，同样，将“验证”文件夹放入与样本文件夹同名的文件夹。并且验证文件夹将包含被检查以预测准确性的图像。</p><div class="kv kw kx ky fd ab cb"><figure class="mp ij mq mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/c9edc6ed7ae88fd5b7a261eb65ca0b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*2l4o8R2YSZI_VohH8wzTqw.png"/></div></figure><figure class="mp ij mv mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/e30caf941dd6fb418490ab59d9751d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*fHkwdtYTwhQWSwXsyGRKYQ.png"/></div></figure></div><pre class="kv kw kx ky fd mw mx my mz aw na bi"><span id="0cc0" class="kz in hi mx b fi nb nc l nd ne">import cv2<br/>face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')<br/>def face_extractor(img):<br/>    # Function detects faces and returns the cropped face<br/>    # If no face detected, it returns the input image<br/>    <br/>    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)<br/>    faces = face_classifier.detectMultiScale(gray, 1.3, 5)<br/>    <br/>    if faces is ():<br/>        return None<br/>    #To crop all the faces found.<br/>    for (x,y,w,h) in faces:<br/>        cropped_face = img[y:y+h, x:x+w]</span><span id="e30e" class="kz in hi mx b fi nf nc l nd ne">return cropped_face</span><span id="c112" class="kz in hi mx b fi nf nc l nd ne"># Initialize Webcam<br/>cap = cv2.VideoCapture(0)<br/>count = 0</span><span id="f956" class="kz in hi mx b fi nf nc l nd ne"># Collect 100 samples of your face from webcam input<br/>while True:</span><span id="5fcf" class="kz in hi mx b fi nf nc l nd ne">ret, frame = cap.read()<br/>    if face_extractor(frame) is not None:<br/>        count += 1<br/>        face = cv2.resize(face_extractor(frame), (224, 224))<br/>        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)</span><span id="3e27" class="kz in hi mx b fi nf nc l nd ne"># Save file in specified directory with unique name<br/>        file_name_path = 'C://Users//Dell//Desktop//mloops//Images//rani//' + str(count) + '.jpg'<br/>        cv2.imwrite(file_name_path, face)</span><span id="9e6b" class="kz in hi mx b fi nf nc l nd ne"># Put count on images and display live count<br/>        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)<br/>        cv2.imshow('Face Cropper', face)<br/>        <br/>    else:<br/>        print("Face not found")<br/>        pass</span><span id="347d" class="kz in hi mx b fi nf nc l nd ne">if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key<br/>        break<br/>        <br/>cv2.destroyAllWindows()   <br/>cap.release()<br/>print("sample Collection  Completed")</span></pre><div class="kv kw kx ky fd ab cb"><figure class="mp ij ng mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/3709c4e0827803b92b50e3df99f3bcee.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*5mtxSV7KHIX0f_lX3x5sWw.png"/></div></figure><figure class="mp ij nh mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/faa7721dfcc749bce668dd9f64488f78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*ST03HIcoApUGSp3gSAnGcQ.png"/></div></figure></div><p id="fdd3" class="pw-post-body-paragraph jk jl hi jm b jn lo jp jq jr lp jt ju jv lq jx jy jz lr kb kc kd ls kf kg kh hb bi translated">人脸识别模型:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es ni"><img src="../Images/ef31a4721a540f65476fa6c02e9d3149.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B3-sVlt-D9uuIAUravN6Rw.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nj"><img src="../Images/3b0f61b91b306c500aa025ba84dda6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-sVHFsWZsAMgvWEUwfvHzg.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es ni"><img src="../Images/bae17ef2e2007c5c514f8f0842fe3775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Izc0lhTW7wr8fDZd9UetQ.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nk"><img src="../Images/6ba2c318f0448b0365f43f799815fdaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*juU-azvTyQj8ZydjcZWssA.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nl"><img src="../Images/c58406865929de05641b83164c7a3c03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GxEdlvnASF3BemWh29Xo8w.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nm"><img src="../Images/e5d6494f9d8184b1daa0be70c069c197.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kOk6z0ngzxfzN21RQ48VUg.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nn"><img src="../Images/6cdcc40104b209d6818ff0897d86b3da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wz3YWOBoyEEuILLtBiAKhQ.png"/></div></div></figure><h1 id="a04e" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">*输出*:</h1><div class="kv kw kx ky fd ab cb"><figure class="mp ij no mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/0178149a984688385c1a329415016fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*vdxFSHB_dzldEpVxf_Ee_w.png"/></div></figure><figure class="mp ij np mr ms mt mu paragraph-image"><img src="../Images/59ebf2ab952d4b8b3dd6e2cd33dd2a43.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*_bXUTR60JIeUZJmzjqNGkA.png"/></figure></div></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="4b47" class="im in hi bd io ip kp ir is it kq iv iw ix kr iz ja jb ks jd je jf kt jh ji jj bi translated">🖼Image分类:</h1><p id="e286" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在这里，我使用MobileNet现有的深度学习模型对猴子的品种进行分类，该模型可以预测猴子的品种。同上，我们将创建两个不同的文件夹，即培训和验证。</p><h2 id="df6e" class="kz in hi bd io la lb lc is ld le lf iw jv lg lh ja jz li lj je kd lk ll ji lm bi translated">✔加载MobileNet模型:</h2><p id="61aa" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">冻结除顶部4层以外的所有层，因为我们将训练顶部4层。在这里，MobileNet被设计为处理224 x 224像素的输入图像，默认情况下图层被设置为可训练的真值。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nq"><img src="../Images/2022a783e9e16980c210a000878a6834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ytE5J9uNvkvGMDvT84Qxng.png"/></div></div><figcaption class="nr ns et er es nt nu bd b be z dx">………………………….</figcaption></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nv"><img src="../Images/6d8a00053e04e4956bf5c701b4a165c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dzLehXI_fidlGYPub8Ig3g.png"/></div></div></figure><h2 id="0821" class="kz in hi bd io la lb lc is ld le lf iw jv lg lh ja jz li lj je kd lk ll ji lm bi translated">✔让我们做一个函数，返回我们完全连接的头部:</h2><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nw"><img src="../Images/0e0d432561e699c0df207f3ff3ae4974.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eB2bP5VB3cD8RRWMqPGy2w.png"/></div></div></figure><h2 id="c0e3" class="kz in hi bd io la lb lc is ld le lf iw jv lg lh ja jz li lj je kd lk ll ji lm bi translated">✔在MobileNet上添加全连接头:</h2><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nx"><img src="../Images/3889f3b963180e2978a7ece8c4f2d097.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pBJgP9Zelkek6MVcq_T6ng.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es ny"><img src="../Images/b56104c100e7cda43aa30cf4fb3e0c5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WAHmf3zJ_7m4R7HnOBnmcw.png"/></div></div></figure><h2 id="cbc6" class="kz in hi bd io la lb lc is ld le lf iw jv lg lh ja jz li lj je kd lk ll ji lm bi translated">✔加载猴子品种数据集:</h2><p id="62a3" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">通常，大多数中间层系统的批量大小为16 - 32</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es nz"><img src="../Images/0082f499e43c8a24f2f48c9b36528ea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BaYiSb0iXiHbdMNxbpRfcA.png"/></div></div></figure><h2 id="202e" class="kz in hi bd io la lb lc is ld le lf iw jv lg lh ja jz li lj je kd lk ll ji lm bi translated">✔火车模型:</h2><p id="11c1" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在这里，我们使用检查点和提前停止。使用回调，我们把回调放到一个列表中。并且以非常小的学习率即0.001进行训练</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es oa"><img src="../Images/ef858e9fe594bc67d5dbbd544fa3743b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O1ymsamNGBciOLc2rJb7TA.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es ob"><img src="../Images/7720612f8f09dad7e989cc82bca97951.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rvUXNRGqjJtV5KV0zl713Q.png"/></div></div></figure><h2 id="8263" class="kz in hi bd io la lb lc is ld le lf iw jv lg lh ja jz li lj je kd lk ll ji lm bi translated">✔在测试图像上测试分类器:</h2><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es oc"><img src="../Images/c87b70e2ab8d37bf98d45db41900e4b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h7K3b1GXxNh1P_tYweT8XA.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es od"><img src="../Images/87a7e7792fed42c03318ce9b7a608b65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3oq2VI6_NpnutGEsPQjDGA.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="er es oe"><img src="../Images/269fcddb3cd7fb81a8fbce5976fb362f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_N8ooEAlkEtyU2MdXoS93A.png"/></div></div></figure><h1 id="82df" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">*输出*:</h1><div class="kv kw kx ky fd ab cb"><figure class="mp ij of mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/e1d4311ebde64556797e0322c73dea28.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*2lSyLe-c-lA9WAz5_6i3hQ.png"/></div></figure><figure class="mp ij og mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/90169e7db2470609a967da9ee7a3bcee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*2XejqbUbG5PemOZILY5fMw.png"/></div></figure></div><div class="ab cb"><figure class="mp ij oh mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/169aa2b0d08077cef9822f8dcd32422a.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*0j3uhBaK91RDFFCWUgc6IQ.png"/></div></figure><figure class="mp ij oi mr ms mt mu paragraph-image"><img src="../Images/05f5ac739c0688ba109faaa25caa935f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*g_N63V9N4yxz_SHStnO4Lw.png"/></figure></div><div class="ab cb"><figure class="mp ij oj mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/bb8d9d24007a2e0200a1779e765346a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*giBtTBt5EudONSVUCzYIZw.png"/></div></figure><figure class="mp ij ok mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/654559798d7b26784b9a28ad47c5212c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*yue-jE2_abJDegNY3iY6Ww.png"/></div></figure></div><div class="ab cb"><figure class="mp ij ol mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/8c41ac4a914e38ba0362d4a838b91512.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*cyAZcPRbb_-KGeGybMPusA.png"/></div></figure><figure class="mp ij om mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/07af60aa5b560bdd09d0408cb4bdb7e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*X5RlNk45PUlUYVHxPjfB7g.png"/></div></figure></div><p id="50d1" class="pw-post-body-paragraph jk jl hi jm b jn lo jp jq jr lp jt ju jv lq jx jy jz lr kb kc kd ls kf kg kh hb bi translated"><strong class="jm hj">联系方式:</strong></p><blockquote class="on oo op"><p id="d058" class="jk jl mn jm b jn lo jp jq jr lp jt ju oq lq jx jy or lr kb kc os ls kf kg kh hb bi translated"><strong class="jm hj">Github:</strong>【https://github.com/rani-gupta/ML_FaceRecognition-Model.git】T4</p><p id="be7e" class="jk jl mn jm b jn lo jp jq jr lp jt ju oq lq jx jy or lr kb kc os ls kf kg kh hb bi translated"><strong class="jm hj">电子邮件:</strong>raniagrawal2001@gmail.com</p><p id="a842" class="jk jl mn jm b jn lo jp jq jr lp jt ju oq lq jx jy or lr kb kc os ls kf kg kh hb bi translated"><strong class="jm hj">领英:</strong><a class="ae ot" href="https://www.linkedin.com/in/rani-gupta-07a828180" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/rani-gupta-07a828180</a></p></blockquote><h1 id="077e" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">🎉谢谢大家！！</h1></div></div>    
</body>
</html>