<html>
<head>
<title>Mercedes-Benz Greener Manufacturing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">梅赛德斯-奔驰绿色制造</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/mercedes-benz-greener-manufacturing-74a932ae0693?source=collection_archive---------2-----------------------#2020-04-20">https://medium.com/analytics-vidhya/mercedes-benz-greener-manufacturing-74a932ae0693?source=collection_archive---------2-----------------------#2020-04-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="011a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> <em class="jl">(能不能削减一辆奔驰在测试台上的时间？)</em> </strong></p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es jm"><img src="../Images/41c050465ced83cf33d228714bfb6129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xUbIhKoRt09iFLVjAJ9WJg.png"/></div></figure><p id="a4e8" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">业务问题:</strong></p><p id="cd8a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">自1886年第一辆汽车——奔驰专利汽车问世以来，梅赛德斯-奔驰一直代表着重要的汽车创新。例如，这包括带有防撞缓冲区的乘客安全单元、安全气囊和智能辅助系统。梅赛德斯-奔驰每年申请近2000项专利，使该品牌成为欧洲高档汽车制造商中的佼佼者。戴姆勒的梅赛德斯-奔驰汽车是高档汽车行业的领导者。凭借丰富的功能和选项，客户可以选择他们梦想中的定制梅赛德斯-奔驰。</p><p id="25f4" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">为了确保每一个独特的汽车配置在上路前的安全性和可靠性，戴姆勒的工程师们开发了一个强大的测试系统。但是，如果没有强大的算法方法，为如此多可能的功能组合优化测试系统的速度是复杂和耗时的。作为世界上最大的高档汽车制造商之一，安全和效率是戴姆勒生产线的重中之重。</p><p id="34b4" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">在这场比赛中，戴姆勒正在挑战卡格勒，以解决维度的诅咒，并减少汽车在测试台上花费的时间。竞争对手将使用代表梅赛德斯-奔驰汽车功能不同排列的数据集来预测通过测试所需的时间。获胜的算法将有助于加快测试速度，从而在不降低戴姆勒标准的情况下降低二氧化碳排放。</p><p id="6300" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">问题陈述:</strong></p><p id="1677" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">预测汽车通过测试所需的目标变量“y”的时间(秒)。</p><p id="8521" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">现实世界/业务目标和约束:</strong></p><ol class=""><li id="1035" class="ju jv hi ip b iq ir iu iv iy jw jc jx jg jy jk jz ka kb kc bi translated">用高R值(决定系数)以秒为单位预测时间。</li><li id="7398" class="ju jv hi ip b iq kd iu ke iy kf jc kg jg kh jk jz ka kb kc bi translated">没有严格的延迟限制。</li></ol><p id="852b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">数据来源:</strong></p><p id="c69c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">您可以使用以下链接从Kaggle下载数据:</p><div class="ki kj ez fb kk kl"><a href="https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/data" rel="noopener  ugc nofollow" target="_blank"><div class="km ab dw"><div class="kn ab ko cl cj kp"><h2 class="bd hj fi z dy kq ea eb kr ed ef hh bi translated">梅赛德斯-奔驰绿色制造</h2><div class="ks l"><h3 class="bd b fi z dy kq ea eb kr ed ef dx translated">你能减少一辆奔驰花在测试台上的时间吗？</h3></div><div class="kt l"><p class="bd b fp z dy kq ea eb kr ed ef dx translated">www.kaggle.com</p></div></div><div class="ku l"><div class="kv l kw kx ky ku kz js kl"/></div></div></a></div><p id="f86f" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">文件描述:</strong></p><p id="ccec" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">带字母的变量是分类变量。带有0/1的变量是二进制值。</p><p id="af4c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">1.<strong class="ip hj"> train.csv </strong> —训练集</p><p id="a665" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.<strong class="ip hj"> test.csv </strong> —测试集，您必须预测该文件中“ID”的“y”变量</p><p id="e065" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">3.<strong class="ip hj">sample _ submission . CSV</strong>—格式正确的样本提交文件</p><p id="79e0" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">机器学习问题公式化:</strong></p><p id="0d4e" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">该数据集包含一组匿名的变量，每个变量代表一辆奔驰汽车的定制功能。例如，变量可以是4WD、附加空气悬架或平视显示器。</p><p id="afac" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">地面实况标记为“y ”,代表汽车通过每个变量测试的时间(秒)。</p><p id="1229" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">由于“y”是一个连续变量，因此我们可以把这个问题表述为一个回归问题。</p><p id="dbfa" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">这里使用的性能指标是:</strong></p><p id="9a06" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> R2(决定系数):</strong>是从自变量中可预测的因变量中方差的比例。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es la"><img src="../Images/67a0fe19072366bea3da8763d9a12136.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ro1lX9h9As3FgGBi9BEJA.png"/></div></div></figure><p id="c1eb" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">现有方法:</strong></p><p id="95f6" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">您可以查看以下链接，了解一些类似的解决方案:</p><div class="ki kj ez fb kk kl"><a rel="noopener follow" target="_blank" href="/@williamkoehrsen/capstone-project-mercedes-benz-greener-manufacturing-competition-4798153e2476"><div class="km ab dw"><div class="kn ab ko cl cj kp"><h2 class="bd hj fi z dy kq ea eb kr ed ef hh bi translated">顶点项目:梅赛德斯-奔驰绿色制造竞赛</h2><div class="ks l"><h3 class="bd b fi z dy kq ea eb kr ed ef dx translated">Udacity机器学习工程师纳米学位</h3></div><div class="kt l"><p class="bd b fp z dy kq ea eb kr ed ef dx translated">medium.com</p></div></div><div class="ku l"><div class="lf l kw kx ky ku kz js kl"/></div></div></a></div><p id="eb06" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">描述:</strong></p><p id="f8c5" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">以上博客由Will Koehrsen撰写，其项目工作流程如下:</p><p id="a60c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">1.数据探索和准备</p><p id="c367" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.数据预处理</p><p id="2a95" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">3.型号选择</p><p id="b1b4" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">4.模型优化</p><p id="4155" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">5.模型测试和评估</p><p id="0409" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">6.结果报告</p><p id="e883" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">他使用线性回归作为他的基准模型。</p><p id="5232" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">最终模型是以下模型的加权平均值:</p><p id="b9de" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">使用许多决策树的极端梯度提升</p><p id="7ee9" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">具有弹性网的线性回归和具有多个决策树的额外树的堆叠模型</p><p id="c24f" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">这个模型帮助他用一个简单的回归器设计一个强大的回归器。</p><p id="af77" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><a class="ae lg" href="https://blog.goodaudience.com/stacking-ml-algorithm-for-mercedes-benz-greener-manufacturing-competition-5600762186ae" rel="noopener ugc nofollow" target="_blank"><strong class="ip hj">https://blog . good audience . com/stacking-ml-algorithm-for-Mercedes-benz-greener-manufacturing-competition-5600762186 AE</strong></a></p><p id="5654" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">描述:</strong></p><p id="370b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">上面的博客是叶达鑫·拉德写的，他漂亮地展示了解决给定问题的方法。</p><p id="0203" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">他处理这个问题的方法如下:</p><p id="346a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">1.解释问题陈述</p><p id="4668" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.描述数据</p><p id="72d1" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">3.数据分析</p><p id="5daf" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">4.数据预处理</p><p id="61b6" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">5.降维</p><p id="ff96" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">6.特征化</p><p id="664c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">7.ML建模</p><p id="2e91" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">8.XGBoost回归模型</p><p id="a2ce" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">9.深度学习MLP模型</p><p id="3f3a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">10.堆叠回归模型</p><p id="2a39" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">堆叠模型为数据集提供了最佳性能。</p><p id="d91b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">请访问他们的博客了解详细的方法。</p><p id="0c7a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj">我的解决方案(首次切割方法):</strong></p><p id="b534" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">由于‘y’是一个连续变量，所以它是一个回归问题。最初，我可以将线性回归方法视为我的基准模型，因为它是我们拥有的最简单的回归算法。因此，我最初的方法如下:</p><p id="5d26" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 1。</strong> <strong class="ip hj">导入基本库</strong></p><p id="bc4f" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 2。</strong> <strong class="ip hj">执行EDA以理解数据集和特征分析</strong></p><p id="b58e" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 3。正如Mercedes在Kaggle上告诉我们的那样，我们必须执行降维技术，我们必须处理维数灾难。通过分析数据，我们可以更好地理解。</strong></p><p id="db12" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 4。</strong> <strong class="ip hj">列车数据的标准化和特色化</strong></p><p id="0799" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 5。</strong> <strong class="ip hj">准备测试数据</strong></p><p id="627e" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 6。</strong> <strong class="ip hj">训练基线模型</strong></p><p id="2001" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 7。</strong> <strong class="ip hj">根据R2分数评估结果</strong></p><p id="0d9b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 8。</strong> <strong class="ip hj">基于基线模型的结果，尝试更复杂的模型进行进一步改进。</strong></p><ol class=""><li id="afe9" class="ju jv hi ip b iq ir iu iv iy jw jc jx jg jy jk jz ka kb kc bi translated"><strong class="ip hj">导入、可视化和理解数据:</strong></li></ol><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lh li l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lj"><img src="../Images/74b434e1af3631ac16ed78205daf37e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xbTaNX21RdX3JJq4X8kEHg.png"/></div></div></figure><p id="e17c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们使用Pandas来导入csv文件。我们在训练数据集中有4209个数据点和378个特征。</p><p id="f04a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们可以清楚地看到训练数据的稀疏性。这意味着与分类特征相比，有更多的二元特征。</p><p id="2ec2" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">让我们进一步分析这些特性，以便更深入地了解它。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lh li l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lk"><img src="../Images/70b44a1a6b27930ecf1dbef2c821a409.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*DboAT4KmJ_MVOB-KdtJ8qQ.png"/></div></figure><p id="874a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">在分析了特征的数据类型之后，我们可以说有369个二元特征，其中8个特征的数据类型=<strong class="ip hj">‘object’</strong>很可能是分类特征，剩下的一个特征是我们的目标变量，即<strong class="ip hj">‘y’。</strong></p><p id="151c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 2。分类特征分析:</strong></p><p id="1646" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">让我们对分类特征进行单变量分析，从中获得洞察力。为此，我将使用箱线图。每个特征的对应图如下:</p><div class="jn jo jp jq fd ab cb"><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/fe53d9f410a648645b103a46a4f67c00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*sw07wiEsgI7Pjg8x8ANKdg.png"/></div></figure><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/9b154525a0c78fb46450d868639304ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*NeZzsCMuTlrGZVmSaBUJug.png"/></div></figure></div><div class="ab cb"><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/0eef63dd33d95eb0ebbbda5d00881647.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qllRy-u8ILS5aUuLMLX6yg.png"/></div></figure><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/126ab5d1367737e2cf9748a46a77c85e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*vPsB-e8W_dFTtCz86pQ9EA.png"/></div></figure></div><div class="ab cb"><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/6ccd6e1606de45bd24ff76104b28172c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*iT6TbrzB86uP6WXrWELfCg.png"/></div></figure><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/78f0f7b6f76ff0014c05df2fa677cb92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ff_-M1QVK77CFhUmdSH10w.png"/></div></figure></div><div class="ab cb"><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/5d564893d8845ca4cac987ebfbde4f9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*XPceoVqbst4yqguBku4rKw.png"/></div></figure><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/ba3ef466d4e4241f7a309350f6a1f557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ELGkX9NUVeRAuAu-u3TkSQ.png"/></div></figure></div><p id="9df7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们观察到，<strong class="ip hj">‘X4’</strong>与其他分类特征相比具有非常低的方差。因此，我们可以从数据集中移除该特征。</p><p id="059a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 3。二进制特征分析:</strong></p><p id="8b30" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们的第一步是检查二元特征中值的数量。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lr"><img src="../Images/9fac6e6943787242dfa1c5a3dfb3ab79.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*IbHbXppJXDvR79NfTETOqA.png"/></div></figure><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lh li l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ls"><img src="../Images/a5dfb27666e19b45a10cfa787c506525.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fb0-1mn6yqHzG0iRU6DA5w.png"/></div></div></figure><p id="85c0" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">由此，我们观察到有13个特征在所有数据点上具有恒定值。因此，根据我的假设，这些特性不会对建模有所贡献。</p><p id="851f" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们将从数据集中移除这些要素。</p><p id="b5cb" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 4。目标变量(' y'): </strong></p><p id="a77c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">为了分析目标变量，我们将使用散点图和箱线图。</p><div class="jn jo jp jq fd ab cb"><figure class="ll jr lt ln lo lp lq paragraph-image"><img src="../Images/7fb66a71f4b848f31062da4c5758cf7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*Axk-NzLRqiQSAHBGwmt9hg.png"/></figure><figure class="ll jr lu ln lo lp lq paragraph-image"><img src="../Images/0be16d0912a544a00a0cbf9ecd5268e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*fa-M5iRvXDbv6LKhzkT0Kw.png"/></figure></div><p id="dcc7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">正如我们所观察到的，目标变量的阈值位于150左右，超过该值可被视为异常值。</p><p id="0300" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 5。检查重复特征:</strong></p><p id="27ee" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们观察到有许多特征是重复的。我们将删除这些功能，只保留一个。</p><p id="0a11" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 6。EDA结论:</strong></p><p id="f4df" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">1.数据集中有13列包含常量值。</p><p id="ac43" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.X4具有非常低的方差</p><p id="0871" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">3.我们也将尝试移除异常值</p><p id="7cba" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 7。数据准备:</strong></p><p id="2ad6" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">1.在这里，我们将删除所有不变的功能</p><p id="fd70" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.我们将删除X4功能</p><p id="1565" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">3.我们将移除异常值，并将目标变量的阈值保持为150</p><p id="ff72" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">在数据准备之后，我们得到了378个特征中剩余的319个特征。因此，我们能够从378个特征中移除59个特征。</p><p id="99b0" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们将按照相同的步骤准备测试数据集。</p><p id="626d" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 8。特征化:</strong></p><p id="d030" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">在数据准备之后，我们留下了7个分类变量。我们将使用标签编码对它们进行编码。</p><p id="4798" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">对于二进制特征，我们将对数据进行标准化，然后使用PCA作为一个新的特征，其中组件的数量为6。</p><p id="8c02" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">除此之外，我们将使用双向和三向交互特征工程。</p><p id="f2c2" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">特征化后，我们有4个特色数据集，我们可以在上面尝试我们的模型。这些措施如下:</p><p id="560d" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">1.标签编码功能</p><p id="7960" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.标签编码+ PCA组件特性</p><p id="63a8" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">3.标签编码+交互功能</p><p id="84d3" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">4.标签编码+ PCA +交互特征</p><p id="2054" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 9。实施模式:</strong></p><p id="a341" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">实现模型背后的想法是在所有4个特征数据集上尝试基线模型，然后尝试使用复杂模型来改善结果。</p><p id="546e" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 9.1线性回归:</strong></p><p id="d252" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们将使用线性回归作为基线模型，因为它是最简单的回归模型。因为我们有300多个特性，所以线性回归会给我们一个不错的基线分数，以供进一步参考和改进。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="3ee2" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">线性回归模型的结果如下:</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lv"><img src="../Images/504ecaabe0830599b007ee1db799b7c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nPnluKgibgEywgwH5f1MIw.png"/></div></div></figure><p id="bf10" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们可以看到，我们在Kaggle上得到的最低私分是<strong class="ip hj"> 0.50994 </strong>。</p><p id="44c7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们将这个分数作为我们的基线分数。</p><p id="80cd" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 9.2随机森林回归量:</strong></p><p id="a3fb" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">随机森林基于被称为Bagging的集成技术，以基本学习者作为决策树。与线性回归相比，随机森林的优势在于它将特征空间划分为轴平行的矩形或超平面，并且还处理过拟合情况。这就是为什么它是一个比线性回归更复杂的模型。此外，它是高度可解释的，所以我们可以很容易地得到数据的特征重要性。对于超参数调优，我们将使用RandomSearchCV，因为它将比GridSearchCV花费更少的时间。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lh li l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lw"><img src="../Images/5664f32edd72864e772f32127aa04cef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cZo98-TtI6ORbb7PzapT1w.png"/></div></div></figure><p id="5473" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">随机森林回归模型的结果如下:</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lx"><img src="../Images/5832c536ca94b3f46c43d297842a3e28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KZQYxgKmOCCHtx8nsG-ycQ.png"/></div></div></figure><p id="c2bc" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">正如我们可以观察到的，随机森林回归器使Kaggle的私人得分急剧增加。我们得到的最高分是<strong class="ip hj"> 0.55148 </strong>。</p><p id="9f97" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们还可以观察特征的重要性，因为这将有助于我们未来的探索。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ly"><img src="../Images/c4d7c4ac5ebf8c5e63705b1459325a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4YtKfDBQHYTphyGRp2iKfg.png"/></div></div></figure><p id="1356" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 9.3 XGB回归器:</strong></p><p id="2328" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">XGBoost基于集成技术Boosting，将基础学习器作为决策树。boosting算法在训练模型的下一次迭代时，会考虑前一次迭代的残差。由于随机森林回归器在数据集上表现良好，因此值得尝试XGBoost回归器来提高性能。该算法是Kaggle竞赛中最常用的算法之一。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lh li l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lz"><img src="../Images/f87f8b1cffaf2c68e4e76e7e8ae07512.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i5d77jtqz07rDl607FYhfw.png"/></div></div></figure><p id="43ee" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">XGBoost回归模型的结果如下:</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ma"><img src="../Images/c70c149e98aa9dc5f3986fc77d286270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0vKp5oZwXENIGacv51yynw.png"/></div></div></figure><p id="9d5c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">XGBoost回归模型的最佳得分为<strong class="ip hj"> 0.54654 </strong>，仍然无法超越随机森林回归模型。我们最好的分数仍然是随机森林回归模型，分数为0.55148。</p><p id="038c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 9.4额外的树回归量:</strong></p><p id="3e5e" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">额外树回归也称为极度随机化树。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lh li l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mb"><img src="../Images/3d44746d14b2aec3f2b4298c0f364bbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EqshekoVFYEr3slAA4StnA.png"/></div></div></figure><p id="ee9c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">额外树回归的结果如下:</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mc"><img src="../Images/97d19934c9b7684cdfc9891b4d765e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lEnme4fSXPZo7dxhd23CXQ.png"/></div></div></figure><p id="bcea" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们从额外的树回归器得到的最好分数是<strong class="ip hj"> 0.55045 </strong>，这比XGB回归器好，但仍然比我们从随机森林回归器得到的分数低。</p><p id="5170" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 9.5叠加回归量:</strong></p><p id="5610" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">到目前为止，我们尝试了三种基于树的模型。现在让我们尝试堆叠模型，它将所有基于树的模型与作为元回归变量的“山脊”结合起来。</p><figure class="jn jo jp jq fd jr"><div class="bz dy l di"><div class="lh li l"/></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es md"><img src="../Images/53a4cc50e0226de897496e6f30d89517.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q3Ak1sA_xX2cCRJAOa58Bg.png"/></div></div></figure><p id="a33e" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">叠加回归的结果如下:</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es me"><img src="../Images/16ca3d932305c8fa64495233a558743d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6TdqSuUMpYJQoJzMi9MQQg.png"/></div></div></figure><p id="65b7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们从堆叠回归元<strong class="ip hj"> 0.55227 </strong>得到的最好分数超过了我们的随机森林回归元结果。</p><p id="d6e2" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 9.6车型对比:</strong></p><p id="56e7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">模型总结如下:</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mf"><img src="../Images/50d545c93e2c2e3113e3eef5cf54fb7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZAuK9SbtjiOrmcwFt-CWdg.png"/></div></div></figure><p id="a9a1" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">根据Kaggle私人排行榜，以<strong class="ip hj"> 0.55227 </strong>的分数，站在第<strong class="ip hj">156位——第</strong>190位，排名前<strong class="ip hj"> 5% </strong>。</p><p id="d039" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">让我们选出最好的两个模型进行进一步的尝试，这可能会提高我们的分数。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mg"><img src="../Images/ac06f40ff11b8fcb45280573baeef333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6HhmgV4P1Fdt4qTSrvtLmQ.png"/></div></div></figure><p id="4cdf" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 10。尝试另一种方法:</strong></p><p id="436a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">在浏览Kaggle的讨论部分时，我得到了一个美丽的讨论，它的作者名叫David。讨论的环节如下:</p><div class="ki kj ez fb kk kl"><a href="https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34949" rel="noopener  ugc nofollow" target="_blank"><div class="km ab dw"><div class="kn ab ko cl cj kp"><h2 class="bd hj fi z dy kq ea eb kr ed ef hh bi translated">梅赛德斯-奔驰绿色制造</h2><div class="ks l"><h3 class="bd b fi z dy kq ea eb kr ed ef dx translated">你能减少一辆奔驰花在测试台上的时间吗？</h3></div><div class="kt l"><p class="bd b fp z dy kq ea eb kr ed ef dx translated">www.kaggle.com</p></div></div><div class="ku l"><div class="mh l kw kx ky ku kz js kl"/></div></div></a></div><p id="e1cf" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">根据他的观点，分类特征是由其他特征改造而来的。我正在尝试使用他的假设，看看这种方法是否能提高我们的分数。</p><p id="db69" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">此外，如果我从以前的基于树的模型中看到特征重要性，分类特征的重要性与其他特征相比非常低。所以，这支持了大卫关于分类特征的假设。</p><p id="da07" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 11。实施模式:</strong></p><p id="744d" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">当我们绘制“X5”与“ID”特征时，有一个非常有趣的发现:</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mi"><img src="../Images/ef7832d6a76b5dbe45a9cf01ce440b7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTJSItZyIy6q2zz_8_JVjw.png"/></div></div></figure><p id="5e05" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">我们可以清楚地看到，X5不过是数据集的一组ID。</p><p id="276a" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">x4’特征也具有非常低的方差。</p><p id="363b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">因此，我们去除了所有的分类特征，并训练了我们的模型。</p><p id="e656" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">随机森林回归和堆积回归的结果如下:</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mj"><img src="../Images/336c00a06ba4d157f04ce4d77a42c07c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aL_g1NFjM1QKTYFXXHBfmA.png"/></div></div></figure><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mk"><img src="../Images/c3daf7bdc344f9c2544971bdf191fdc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L5Tct80LRKx4KoXc1qj0Kw.png"/></div></div></figure><p id="d457" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 12。对比模型及结论:</strong></p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ml"><img src="../Images/02c627a9843a6f0146a752201967f293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bCEjF5UGw3LGjbx4XZSsWw.png"/></div></div></figure><p id="96f7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">正如我们可以看到的，如果我们从数据集中删除分类特征，我们在Kaggle上的得分就会下降。这证明了我们的假设是错误的。所以，结论如下:</p><p id="91db" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">1.根据Kaggle排行榜，最佳解决方案是一个<strong class="ip hj">“堆叠模型”</strong>，除了交互功能之外，还具有标签编码器、PCA的功能工程，这使我在排行榜上处于<strong class="ip hj">第156位</strong>到<strong class="ip hj">第190位</strong>之间。</p><p id="63a7" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.移除低方差特征有助于提高模型性能。</p><p id="9517" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">3.超参数调整防止模型过度拟合。</p><p id="6519" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">4.添加PCA特征有助于模型的降维，这有助于增加得分。</p><p id="f54c" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">交互功能极大地改善了解决方案。</p><blockquote class="mm mn mo"><p id="6975" class="in io jl ip b iq ir is it iu iv iw ix mp iz ja jb mq jd je jf mr jh ji jj jk hb bi translated">T <strong class="ip hj">最好的模型是(堆叠+标签编码+ PCA +交互特征)，私有分0.55227。</strong></p></blockquote><p id="4b6b" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 13。Kaggle私人排行榜分数和排名:</strong></p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ms"><img src="../Images/44293d81a29235f161f4f4349a79f685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z6XXJUDDmETR2EvDjkV7ug.png"/></div></div></figure><p id="cad9" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 14。Kaggle排行榜:</strong></p><div class="jn jo jp jq fd ab cb"><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/a3d7ed618ad1750ebbcd2c36c80be69a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*MKpfZ1FrQlQHS0eQKAc8xg.png"/></div></figure><figure class="ll jr lm ln lo lp lq paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><img src="../Images/0ee6a5f9b0871a364bd01f8625ef2dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*DM5tcKDiTXPrPiU5JExtMQ.png"/></div></figure></div><p id="10f8" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">15。未来工作:</p><p id="3cb9" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">1.在我的特征工程中，我使用了PCA。我们可以进一步使用TSVD，ICA，GRP进行特征工程。</p><p id="8e70" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.我们可以使用深度学习技术。</p><p id="40a2" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> 16。参考:</strong></p><ol class=""><li id="acb9" class="ju jv hi ip b iq ir iu iv iy jw jc jx jg jy jk jz ka kb kc bi translated"><a class="ae lg" href="https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/37700" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/Mercedes-benz-greener-manufacturing/discussion/37700</a></li></ol><p id="11a4" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">2.<a class="ae lg" href="https://blog.goodaudience.com/stacking-ml-algorithm-for-mercedes-benz-greener-manufacturing-competition-5600762186ae" rel="noopener ugc nofollow" target="_blank">https://blog . good audience . com/stacking-ml-algorithm-for-Mercedes-benz-greener-manufacturing-competition-5600762186 AE</a></p><p id="8a54" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">3.<a class="ae lg" href="https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/overview" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/梅赛德斯-奔驰-更环保-制造/概述</a></p><p id="7b39" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">4.<a class="ae lg" href="https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/34949" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/Mercedes-benz-greener-manufacturing/discussion/34949</a></p><p id="37d8" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated">5.<a class="ae lg" href="https://www.appliedaicourse.com" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com</a></p></div><div class="ab cl mt mu gp mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="hb hc hd he hf"><p id="3a9e" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> Github链接:</strong></p><div class="ki kj ez fb kk kl"><a href="https://github.com/aditya2029/Mercedes-Benz-Greener-Manufacturer" rel="noopener  ugc nofollow" target="_blank"><div class="km ab dw"><div class="kn ab ko cl cj kp"><h2 class="bd hj fi z dy kq ea eb kr ed ef hh bi translated">aditya 2029/梅赛德斯-奔驰-更环保-制造商</h2><div class="ks l"><h3 class="bd b fi z dy kq ea eb kr ed ef dx translated">通过在GitHub上创建一个帐户，为aditya 2029/梅赛德斯-奔驰-绿色制造商的发展做出贡献。</h3></div><div class="kt l"><p class="bd b fp z dy kq ea eb kr ed ef dx translated">github.com</p></div></div><div class="ku l"><div class="na l kw kx ky ku kz js kl"/></div></div></a></div><p id="f60e" class="pw-post-body-paragraph in io hi ip b iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk hb bi translated"><strong class="ip hj"> LinkedIn个人资料:</strong></p><div class="ki kj ez fb kk kl"><a href="https://www.linkedin.com/in/aditya-pandey-b9bb968b/" rel="noopener  ugc nofollow" target="_blank"><div class="km ab dw"><div class="kn ab ko cl cj kp"><h2 class="bd hj fi z dy kq ea eb kr ed ef hh bi translated">aditya Pandey-Vogo Automotive PVT . ltd .数据分析师| LinkedIn</h2></div><div class="ku l"><div class="nb l kw kx ky ku kz js kl"/></div></div></a></div></div></div>    
</body>
</html>