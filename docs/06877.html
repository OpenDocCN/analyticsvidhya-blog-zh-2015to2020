<html>
<head>
<title>Support Vector Regression for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的支持向量回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/support-vector-regression-for-machine-learning-843978ba6279?source=collection_archive---------19-----------------------#2020-06-05">https://medium.com/analytics-vidhya/support-vector-regression-for-machine-learning-843978ba6279?source=collection_archive---------19-----------------------#2020-06-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1ed0aa17c80539be7410fa46018c009e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M57OgznesBrXu2WcpfpTGA.jpeg"/></div></div></figure><p id="fd82" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">SVR(支持向量回归)实际上是SVM(支持向量机)的一部分，支持向量机是一种有监督的机器学习算法，它在解决分类和回归问题上都是有用的。</p><blockquote class="jo jp jq"><p id="b50a" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated">SVM的目标是训练一个模型，将新的看不见的物体分配到一个特定的类别中。它通过将特征空间线性划分为两类来实现这一点。基于新的看不见的物体的特征，它将物体放置在分离平面之上或之下，导致分类。</p></blockquote><h1 id="7c45" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">线性支持向量回归</h1><p id="bf2a" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">支持向量回归机利用SVM原理建立回归模型。在SVR中，有一条<strong class="is hj"><em class="jr"/></strong>而不是一条直线或一个<strong class="is hj">超平面</strong>，并且我们在<em class="jr"/><strong class="is hj"><em class="jr">-</em></strong><em class="jr">管</em>中间有一条回归线。</p><p id="f1d7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个管的宽度为<strong class="is hj">ε</strong>，垂直测量的宽度是沿着轴，不是垂直于管而是垂直的，这个管本身被称为<strong class="is hj">ɛ-insensitive</strong>，这意味着数据集中落在管内的任何点我们将忽略它们的误差。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/a11bf576eec6a4a98829fd9a253b3e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*fOjJBkRUuJ6d5LVW7hJ-Mg.png"/></div></figure><p id="dd4e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以基本上这个ɛ-tube认为它是一个误差范围，这意味着我们允许我们的模型有那些点，而不关心它里面的任何误差。所以点和回归线或者超平面之间的任何差异，或者任何相似的距离，我们不关心面积，因为它落在ɛ-insensitive管上。</p><p id="eb2d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于位于ɛ-insensitive管外部的点，我们将考虑它们，并通过测量该点和管本身之间的距离来处理它们，这些值/点被称为松弛变量。</p><p id="e8ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">测量距离/面积的公式为:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/62d4e8c5f2a59cdd3bca219d37a8425b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*pwgzEGupLhuGD7jiXHT1Cg.png"/></div></figure><h1 id="4bf4" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">支持向量</h1><p id="a3fd" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">位于ɛ-insensitive管外部的点决定了管的外观以及管的位置。这些点在管外，它们被称为支持向量，帮助形成ɛ-insensitive管。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es le"><img src="../Images/4b92662ab12cfbcbcfdfad76c5ceefe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*aCAoQSOS0tCE76KXR2Vd4g.png"/></div></div></figure><p id="04ec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种方法称为支持向量回归，因为实际上所有的点都可以表示为二维空间中的一个向量，如果数据集中有更多的特征，则可以表示为多维空间中的一个向量。</p><h1 id="7432" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">非线性支持向量回归</h1><p id="0483" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">在非线性支持向量回归中，数据不能用直线或回归线来分离。因此，为了解决这个问题，我们将高维空间，使数据线性分离。</p><p id="d525" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们将数据的维度空间从2D空间增加到3D空间，现在我们可以清楚地看到，现在我们可以轻松地分离数据。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/9cf7a805ff8881501bd9144b60a09455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pqpWeS0jQnkuTNnKaefekg.png"/></div></div></figure><p id="9cdf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我们使用了一个映射函数(一个将低维数据点映射到高维空间的函数)，它将我们的数据点提升到一个高维空间，在那里它们可以线性分离。我们找到一个超平面，它将数据点分成两个不同的类别。</p><p id="8c00" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在支持向量回归中，我们通过使用核技巧来增加数据的维数空间。有不同类型的内核。一些最常用的核是高斯RBF核、多项式核、Sigmoid核等。</p><p id="23fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我们选择高斯径向基函数内核</p><h1 id="0cf9" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">内核</strong></h1><p id="9e1e" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">我们可以假设内核是一个相似性函数，其中<strong class="is hj">隐含地</strong>将数据映射到一个无限维平面，然后在该平面中找到支持向量，并将向量映射回原始维。</p><p id="b63f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">核参数选择用于分离数据的超平面的类型。使用“线性”将使用线性超平面(在2D数据的情况下是一条线)。“rbf”和“poly”使用非线性超平面。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/10698139b35fec61ec3167fa70a06111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cwih4la0aR7nYv0FG7fCMQ.png"/></div></div></figure><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/6e87754834fd72a9a9181a17043fce10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KDfShUSJPVgeYOXT.png"/></div></div></figure><p id="f98e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">SVR机器学习算法到此为止。敬请关注更多博客。</p><p id="c729" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jr">谢谢</em></p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><p id="ab70" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">SVR算法在工资数据集上的实现</p><blockquote class="jo jp jq"><p id="e0fc" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated"><em class="hi">数据集:</em> <a class="ae lp" href="https://github.com/InternityFoundation/MachineLearning_Navu4/blob/master/Day%209%20:%20SVR/Salary_Data.csv" rel="noopener ugc nofollow" target="_blank"> <em class="hi">薪资</em> </a> <em class="hi">数据集</em></p></blockquote><p id="8286" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">链接:<a class="ae lp" href="https://github.com/InternityFoundation/MachineLearning_Navu4/blob/master/Day%209%20:%20SVR/SVR_on_salary_dataset.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/internity foundation/machine learning _ navu 4/blob/master/Day % 209% 20:% 20 SVR/SVR _ on _ salary _ dataset . ipynb</a></p></div></div>    
</body>
</html>