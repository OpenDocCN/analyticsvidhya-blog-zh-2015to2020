<html>
<head>
<title>GPU On Keras and Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras和Tensorflow上的GPU</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/gpu-on-keras-and-tensorflow-357d629fb7e2?source=collection_archive---------8-----------------------#2019-12-16">https://medium.com/analytics-vidhya/gpu-on-keras-and-tensorflow-357d629fb7e2?source=collection_archive---------8-----------------------#2019-12-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7c66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好奇的人们，你们好！</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/83e7ced0ae4eb8b83d5fbe7d11f28f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dfd5SckwchXAlGHw"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">由<a class="ae ju" href="https://unsplash.com/@latorware?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">大卫·拉托雷·罗梅罗</a>在<a class="ae ju" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="7a7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jv translated">发表这篇关于如何在Keras和Tensorflow上使用GPU的博客。如果你不太喜欢GPU，我建议你快速检查一下GPU的症结所在。</p><p id="bec9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗯，早期用于游戏的GPU现在已经用于机器学习和深度学习。Tensorflow或Keras上的神经网络必须使用GPU。此外，令人惊讶的是，这些技术在初始化时使用整个GPU。因此，这可能给多用户环境设置带来问题。完全不用担心！这个博客有它的解决方案。<br/>但在开始之前，让我们先了解一下如何在Tensorflow和Keras上使用。</p><h1 id="6309" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">GPU上的张量流</h1><p id="09b0" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">Tensorflow在启动时会自动分配整个GPU。这可能会导致各种问题。</p><p id="ff54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">问题</strong>:我们不会去了解实际的GPU使用情况。多用户环境设置有点令人担忧，当多用户同时访问1个GPU时会出现警报情况。</p><p id="ccb8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">解决方案一:</strong></p><p id="7055" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这适用于多用户环境。无法指定所需的确切GPU内存量，因此<strong class="ih hj"><em class="jd">allow _ growth</em></strong><em class="jd">进入画面</em>。它允许运行时分配内存。将它设置为true意味着它开始时分配很少的内存，然后根据进程需求逐渐分配更多的区域。</p><blockquote class="lh li lj"><p id="c392" class="if ig jd ih b ii ij ik il im in io ip lk ir is it ll iv iw ix lm iz ja jb jc hb bi translated">config = tf。config proto()<br/>config . GPU _ options . allow _ growth = True<br/>sess = TF。会话(配置=配置)</p></blockquote><p id="0454" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运筹学</p><blockquote class="lh li lj"><p id="8fbd" class="if ig jd ih b ii ij ik il im in io ip lk ir is it ll iv iw ix lm iz ja jb jc hb bi translated">config = tf。config proto()<br/>TF . config . GPU . set _ per _ process _ memory _ growth = True<br/>sess = TF。会话(配置=配置)</p></blockquote><p id="fcd6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">方案二:</strong></p><p id="3773" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当您确定进程的内存消耗时，可以应用这个解决方案。固定的内存分配可以通过使用<strong class="ih hj">set _ per _ process _ memory _ growth</strong>指定所需的内存部分来完成，而不是动态的GPU分配。</p><blockquote class="lh li lj"><p id="1205" class="if ig jd ih b ii ij ik il im in io ip lk ir is it ll iv iw ix lm iz ja jb jc hb bi translated">config = tf。config proto()<br/>config . GPU _ options . set _ per _ process _ memory _ growth = 0.4<br/>sess = TF。会话(配置=配置)</p></blockquote><p id="fb84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面分配了每个GPU的固定百分比内存。例如，上面的40%分配在每个GPU上。</p><h1 id="3308" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated"><strong class="ak">GPU上的Keras</strong></h1><p id="c15a" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">在Keras中，对于后端Tensorflow或CNTK，如果检测到任何GPU，则代码将自动在GPU上运行，而后端则需要一个定制的函数。Keras文档是一个非常棒和读者友好的。有关更多详细信息，请访问以下文档的常见问题。</p><p id="98ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://keras.io/getting-started/faq/#how-can-i-run-a-keras-model-on-multiple-gpus" rel="noopener ugc nofollow" target="_blank">https://keras . io/getting-started/FAQ/# how-can-I-run-a-keras-model-on-multi-GPU</a></p></div><div class="ab cl ln lo gp lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="hb hc hd he hf"><h1 id="124f" class="ke kf hi bd kg kh lu kj kk kl lv kn ko kp lw kr ks kt lx kv kw kx ly kz la lb bi translated">常见问题解答</h1><p id="3720" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated"><strong class="ih hj">问:如何检查每个进程正在使用的所有GPU或GPU利用率？</strong></p><p id="e721" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">有NVIDIA管理和监控命令行实用工具“nvidia-smi”。访问</em> <a class="ae ju" rel="noopener" href="/@shachikaul35/explained-output-of-nvidia-smi-utility-fc4fbee3b124"> <em class="jd">了解nvidia-smi实用程序</em> </a> <em class="jd">的输出详情。</em></p><p id="6ce5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">问:如何检查你的系统中是否存在GPU？</strong></p><blockquote class="lh li lj"><p id="8fb4" class="if ig jd ih b ii ij ik il im in io ip lk ir is it ll iv iw ix lm iz ja jb jc hb bi translated">tf.test.is_gpu_available()</p></blockquote><p id="adac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">问:如何列出tensorflow可用的所有物理设备？</strong></p><blockquote class="lh li lj"><p id="d459" class="if ig jd ih b ii ij ik il im in io ip lk ir is it ll iv iw ix lm iz ja jb jc hb bi translated">从tensorflow.python.client导入设备库<br/> print(设备库.列表本地设备())</p></blockquote><p id="1503" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">问:如何向tensorflow列出所有可用的GPU？</strong></p><blockquote class="lh li lj"><p id="9c99" class="if ig jd ih b ii ij ik il im in io ip lk ir is it ll iv iw ix lm iz ja jb jc hb bi translated">all _ GPU = TF . config . experimental . list _ physical _ devices(" GPU ")<br/>for GPU in all _ GPU:<br/>print(" Name:"，gpu.name，" Type:"，gpu.device_type)</p></blockquote><p id="80aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运筹学</p><blockquote class="lh li lj"><p id="1580" class="if ig jd ih b ii ij ik il im in io ip lk ir is it ll iv iw ix lm iz ja jb jc hb bi translated">if TF . test . gpu _ Device _ name():<br/>print('默认GPU设备:{} '。format(tf . test . gpu _ device _ name())<br/>else:<br/>print("请安装TF的GPU版本")</p></blockquote><p id="1509" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">问:如何验证Keras是否有GPU？</strong></p><blockquote class="lh li lj"><p id="853a" class="if ig jd ih b ii ij ik il im in io ip lk ir is it ll iv iw ix lm iz ja jb jc hb bi translated">从keras导入后端为K <br/> K.tensorflow_backend。_ get _ available _ gpus()</p></blockquote><p id="a380" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢，</p><p id="f4e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快乐阅读！</p><p id="e2ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">可以通过</em></strong><a class="ae ju" href="https://www.linkedin.com/in/kaul-shachi" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="jd">LinkedIn</em></strong></a><strong class="ih hj"><em class="jd">取得联系。</em> </strong></p></div></div>    
</body>
</html>