<html>
<head>
<title>Automated Essay Scoring — Kaggle Competition End to End Project Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动化论文评分— Kaggle竞赛端到端项目实施</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/automated-essay-scoring-kaggle-competition-end-to-end-project-implementation-part-2-a9fb4c31aed8?source=collection_archive---------7-----------------------#2019-11-10">https://medium.com/analytics-vidhya/automated-essay-scoring-kaggle-competition-end-to-end-project-implementation-part-2-a9fb4c31aed8?source=collection_archive---------7-----------------------#2019-11-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="1927" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">第二部分:数据预处理和LSTM训练</h2></div><p id="58bf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请通过<a class="ae jt" rel="noopener" href="/@mayurmorin/automated-essay-scoring-kaggle-competition-end-to-end-project-implementation-part-1-b75a043903c4">第一部分</a>、<a class="ae jt" rel="noopener" href="/@mayurmorin/automated-essay-scoring-kaggle-competition-end-to-end-project-implementation-part-2-a9fb4c31aed8">第二部分</a>和<a class="ae jt" rel="noopener" href="/@mayurmorin/automated-essay-scoring-kaggle-competition-end-to-end-project-implementation-part-3-ccd8ae110fd4">第三部分</a>完整理解和项目执行，并给出<a class="ae jt" href="https://github.com/mayurmorin/Automated-Essay--Scoring" rel="noopener ugc nofollow" target="_blank"> Github </a>。</p><ol class=""><li id="85c9" class="ju jv hi iz b ja jb jd je jg jw jk jx jo jy js jz ka kb kc bi translated"><strong class="iz hj">训练LSTM模型，ipynb </strong>用于训练和保存模型。</li></ol><h1 id="5fa7" class="kd ke hi bd kf kg kh ki kj kk kl km kn io ko ip kp ir kq is kr iu ks iv kt ku bi translated"><strong class="ak">导入数据</strong></h1><ul class=""><li id="1d71" class="ju jv hi iz b ja kv jd kw jg kx jk ky jo kz js la ka kb kc bi translated">增加了Gensim、NLTK、Django库。</li><li id="4f2f" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js la ka kb kc bi translated">在DATASET_DIR、GLOVE_DIR和SAVE_DIR路径中添加了常量。</li><li id="ef5c" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js la ka kb kc bi translated">使用pandas库从training_set_rel3.tsv加载数据。</li><li id="9822" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js la ka kb kc bi translated">删除不必要的列，如domain_score和raters_domain。</li><li id="f58b" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js la ka kb kc bi translated">定义我们将在预测实际分数时使用的最低和最高分数。</li></ul><figure class="lg lh li lj fd lk"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h1 id="b657" class="kd ke hi bd kf kg kh ki kj kk kl km kn io ko ip kp ir kq is kr iu ks iv kt ku bi translated">预处理数据</h1><p id="0533" class="pw-post-body-paragraph ix iy hi iz b ja kv ij jc jd kw im jf jg ln ji jj jk lo jm jn jo lp jq jr js hb bi translated">我们将对所有文章进行预处理，并将其转换为特征向量，以便输入RNN。</p><p id="15f1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这些都是用来清理论文的辅助函数。</p><figure class="lg lh li lj fd lk"><div class="bz dy l di"><div class="ll lm l"/></div></figure><ul class=""><li id="9e5a" class="ju jv hi iz b ja jb jd je jg jw jk jx jo jy js la ka kb kc bi translated">定义了4个函数:</li></ul><ol class=""><li id="0da5" class="ju jv hi iz b ja jb jd je jg jw jk jx jo jy js jz ka kb kc bi translated"><strong class="iz hj"> getAvgFeatureVecs </strong>:该函数接受3个参数:文章、模型、数量_特征。它内部调用<strong class="iz hj"> makeFeatureVec </strong>函数将短文转换成FeatureVector。</li><li id="ca80" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js jz ka kb kc bi translated"><strong class="iz hj"> makeFeatureVec: </strong>该函数接受3个参数:单词、模型、num_features。使用Word2Vec index2word函数和np.divide最终给出所传递模型的平均特征向量。</li><li id="b48f" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js jz ka kb kc bi translated"><strong class="iz hj">essay _ to _ sentence</strong>:该函数接受两个参数:essay_v，remove_stopwords。它在内部调用essay_to_wordlist，将短文转换成句子。</li><li id="b968" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js jz ka kb kc bi translated"><strong class="iz hj"> essay_to_wordlist </strong>:这个函数接受两个参数:essay_v，remove_stopwords。它删除停用词并返回单词。</li></ol><ul class=""><li id="5eff" class="ju jv hi iz b ja jb jd je jg jw jk jx jo jy js la ka kb kc bi translated">每当你处理NLP机器学习和深度学习任务时，上面提到的步骤几乎是必要的，因为机器理解数字，或者我们可以说计算非常容易，当我们在这里使用数字时，我们指的是向量。</li><li id="b5c0" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js la ka kb kc bi translated">我们正试图将短文或语料库转换成句子，然后转换成单词，单词也可以称为标记，然后将它们转换成向量。</li></ul><blockquote class="lq"><p id="3143" class="lr ls hi bd lt lu lv lw lx ly lz js dx translated">我强烈建议浏览一些自然语言处理的术语和概念，如分词器、词干、限定、停用词，以及将单词转换成向量的不同方法，如BOW、TF-IDF、n-gram。这些是在馈送到任何机器学习算法或深度学习算法之前的NLP数据预处理技术。</p></blockquote><h1 id="f358" class="kd ke hi bd kf kg kh ki kj kk kl km kn io ma ip kp ir mb is kr iu mc iv kt ku bi translated">定义模型</h1><p id="8341" class="pw-post-body-paragraph ix iy hi iz b ja kv ij jc jd kw im jf jg ln ji jj jk lo jm jn jo lp jq jr js hb bi translated">这里我们定义一个两层LSTM模型。</p><p id="7a8d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请注意，我们将使用Relu，而不是在输出层使用sigmoid激活，因为我们没有标准化训练标签。</p><figure class="lg lh li lj fd lk"><div class="bz dy l di"><div class="ll lm l"/></div></figure><ul class=""><li id="0259" class="ju jv hi iz b ja jb jd je jg jw jk jx jo jy js la ka kb kc bi translated">/models文件夹包含6个不同的模型，您应该尝试并检查其准确性。</li><li id="9106" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js la ka kb kc bi translated">作为培训的一部分，你只需要用那些模型文件代码替换上面的代码</li></ul><h1 id="e8d2" class="kd ke hi bd kf kg kh ki kj kk kl km kn io ko ip kp ir kq is kr iu ks iv kt ku bi translated">培训阶段</h1><p id="1e26" class="pw-post-body-paragraph ix iy hi iz b ja kv ij jc jd kw im jf jg ln ji jj jk lo jm jn jo lp jq jr js hb bi translated">现在我们在数据集上训练模型。</p><p id="f506" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用5重交叉验证，并测量每一重的二次加权Kappa。然后我们将计算所有折叠的平均Kappa。</p><figure class="lg lh li lj fd lk"><div class="bz dy l di"><div class="ll lm l"/></div></figure><ul class=""><li id="2cbd" class="ju jv hi iz b ja jb jd je jg jw jk jx jo jy js la ka kb kc bi translated">我们首先使用gensim库中可用的Word2Vec模型训练文章。稍后，我们将保存到word2vecmodel.bin文件中，我们将在预测分数时使用该文件。</li></ul><pre class="lg lh li lj fd md me mf mg aw mh bi"><span id="6cd4" class="mi ke hi me b fi mj mk l ml mm">print("Training Word2Vec Model...")<br/>    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)<br/><br/>    model.init_sims(replace=<strong class="me hj">True</strong>)<br/>    model.wv.save_word2vec_format('word2vecmodel.bin', binary=<strong class="me hj">True</strong>)</span></pre><ul class=""><li id="1a09" class="ju jv hi iz b ja jb jd je jg jw jk jx jo jy js la ka kb kc bi translated">现在，我们使用之前定义的函数将短文转换为向量表示。</li><li id="8d4c" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js la ka kb kc bi translated">我们还将这个向量传递到LSTM模型中，并将模型保存在final_lstm.h5文件中。</li><li id="557f" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js la ka kb kc bi translated">作为结果的一部分，我们使用KFold交叉验证用二次加权计算cohen kapp分数5次，然后取平均值。如你所见，结果将会是</li></ul><pre class="lg lh li lj fd md me mf mg aw mh bi"><span id="c1fb" class="mi ke hi me b fi mj mk l ml mm">print("Average Kappa score after a 5-fold cross validation: ",np.around(np.array(results).mean(),decimals=4))<br/><strong class="me hj">Average Kappa score after a 5-fold cross validation:  0.9615</strong></span></pre><h1 id="dee2" class="kd ke hi bd kf kg kh ki kj kk kl km kn io ko ip kp ir kq is kr iu ks iv kt ku bi translated">参考</h1><ol class=""><li id="ae78" class="ju jv hi iz b ja kv jd kw jg kx jk ky jo kz js jz ka kb kc bi translated"><a class="ae jt" href="http://aclweb.org/anthology/D/D16/D16-1193.pdf" rel="noopener ugc nofollow" target="_blank">自动论文评分的神经方法</a></li><li id="c1f2" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js jz ka kb kc bi translated"><a class="ae jt" href="https://arxiv.org/pdf/1606.04289.pdf" rel="noopener ugc nofollow" target="_blank">使用神经网络的自动文本评分</a></li></ol><figure class="lg lh li lj fd lk er es paragraph-image"><div class="er es mn"><img src="../Images/d6a15d5343d85df88f8af0dbdf200446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*mfiehGJhPa-lOtzPZpXgeA.png"/></div><figcaption class="mq mr et er es ms mt bd b be z dx translated"><strong class="bd kf">研究论文</strong></figcaption></figure><p id="cc01" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上述研究论文清楚地解释了使用Cohen kappa评分的重要性，以及他们在研究中尝试的不同模型，以及哪个模型给出了最好的结果。</p><p id="1146" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">重要提示:在实际项目实施中，您必须尝试不同的模型以获得最大的准确性，这一点也非常重要，然后该模型将被保存并作为生产的一部分使用。</strong></p><p id="2637" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们将浏览Web应用程序代码，从中我们将看到保存的模型实际上是如何预测第3部分中的分数的。</p><h1 id="096c" class="kd ke hi bd kf kg kh ki kj kk kl km kn io ko ip kp ir kq is kr iu ks iv kt ku bi translated">参考资料:</h1><ol class=""><li id="f0d3" class="ju jv hi iz b ja kv jd kw jg kx jk ky jo kz js jz ka kb kc bi translated">特别感谢Ronit Mankad的Github回购，我已经分叉，并得到了对这个项目的理解。</li><li id="b606" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js jz ka kb kc bi translated">引用自维基百科和其他网站。</li><li id="c239" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js jz ka kb kc bi translated"><a class="ae jt" href="http://aclweb.org/anthology/D/D16/D16-1193.pdf" rel="noopener ugc nofollow" target="_blank">自动论文评分的神经方法</a></li><li id="4f23" class="ju jv hi iz b ja lb jd lc jg ld jk le jo lf js jz ka kb kc bi translated"><a class="ae jt" href="https://arxiv.org/pdf/1606.04289.pdf" rel="noopener ugc nofollow" target="_blank">使用神经网络的自动文本评分</a></li></ol><p id="6103" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">如果你真的喜欢这个文章系列，请鼓掌，跟我来，就像下面的小喽啰一样享受人工智能的极致力量。</strong></p><figure class="lg lh li lj fd lk er es paragraph-image"><div class="er es mu"><img src="../Images/f9d4a63df6e2b8651ebc2567fa8d8aa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*lz_twaj-e9SFYuXc.gif"/></div></figure></div></div>    
</body>
</html>