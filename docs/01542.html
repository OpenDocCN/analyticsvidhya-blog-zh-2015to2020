<html>
<head>
<title>Experimenting with XGBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用XGBoost进行实验</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/experimenting-with-xgboost-997401f54aa1?source=collection_archive---------18-----------------------#2019-10-29">https://medium.com/analytics-vidhya/experimenting-with-xgboost-997401f54aa1?source=collection_archive---------18-----------------------#2019-10-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/cfd8bec7e39ac5af28a8c39a3c69c9ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Kkyt018_ZK_EsWC7"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">萨法尔·萨法罗夫在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="1d25" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">介绍</h1><p id="0dab" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">这是一篇旨在通过一些机器学习的简单例子来了解XGBoost API的文章。我将调整一些超级参数，并使用其内置的交叉验证。</p><h1 id="fb56" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">数据集</h1><p id="7841" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">我们将使用我从Kaggle 获得的<a class="ae iu" href="https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data" rel="noopener ugc nofollow" target="_blank"> NYC Air Bnb数据集。</a></p><h1 id="beae" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">数据集的基本步骤</h1><p id="3b4a" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">我们不会在这里深入探讨EDA，因为我们的目标是熟悉XGBoost的API。但是，我们需要做一些数据处理，因为我们的数据集混合了分类数据和数值数据。首先，让我们导入必要的库。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="c9b1" class="la iw hi kw b fi lb lc l ld le">import xgboost as xgb</span><span id="3389" class="la iw hi kw b fi lf lc l ld le">import pandas as pd</span><span id="4e21" class="la iw hi kw b fi lf lc l ld le">import numpy as np</span><span id="eec6" class="la iw hi kw b fi lf lc l ld le">from sklearn.model_selection import train_test_split</span><span id="8171" class="la iw hi kw b fi lf lc l ld le">from sklearn.metrics import mean_absolute_error</span><span id="8a2f" class="la iw hi kw b fi lf lc l ld le">from sklearn.pipeline import Pipeline</span><span id="06f4" class="la iw hi kw b fi lf lc l ld le">from sklearn.preprocessing import StandardScaler</span><span id="c7fe" class="la iw hi kw b fi lf lc l ld le">from sklearn.pipeline import FeatureUnion</span><span id="3b6e" class="la iw hi kw b fi lf lc l ld le">from sklearn.base import BaseEstimator, TransformerMixin</span><span id="e61b" class="la iw hi kw b fi lf lc l ld le">from sklearn.preprocessing import Imputer</span><span id="eacc" class="la iw hi kw b fi lf lc l ld le">from sklearn.preprocessing import LabelEncoder</span><span id="685f" class="la iw hi kw b fi lf lc l ld le">from sklearn.pipeline import FeatureUnion</span><span id="de88" class="la iw hi kw b fi lf lc l ld le">from sklearn.model_selection import GridSearchCV</span></pre><p id="a31d" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">通过简单地使用一些基本的Pandas功能，我们可以清楚地看到有许多缺失的功能，特别是在“last_review”和“reviews_per_month”列中。我们会放弃他们。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="9da6" class="la iw hi kw b fi lb lc l ld le">airbnb.isnull().sum()</span><span id="dfd0" class="la iw hi kw b fi lf lc l ld le">id                                    0<br/>name                                 16<br/>host_id                               0<br/>host_name                            21<br/>neighbourhood_group                   0<br/>neighbourhood                         0<br/>latitude                              0<br/>longitude                             0<br/>room_type                             0<br/>price                                 0<br/>minimum_nights                        0<br/>number_of_reviews                     0<br/>last_review                       10052<br/>reviews_per_month                 10052<br/>calculated_host_listings_count        0<br/>availability_365                      0<br/>dtype: int64</span></pre><p id="368e" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">之后，我们使用<strong class="jv hj"> info() </strong>函数告诉我们每一列的类型。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="ef61" class="la iw hi kw b fi lb lc l ld le">airbnb.info()</span><span id="940f" class="la iw hi kw b fi lf lc l ld le">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 48895 entries, 0 to 48894<br/>Data columns (total 14 columns):<br/>id                                48895 non-null int64<br/>name                              48879 non-null object<br/>host_id                           48895 non-null int64<br/>host_name                         48874 non-null object<br/>neighbourhood_group               48895 non-null object<br/>neighbourhood                     48895 non-null object<br/>latitude                          48895 non-null float64<br/>longitude                         48895 non-null float64<br/>room_type                         48895 non-null object<br/>price                             48895 non-null int64<br/>minimum_nights                    48895 non-null int64<br/>number_of_reviews                 48895 non-null int64<br/>calculated_host_listings_count    48895 non-null int64<br/>availability_365                  48895 non-null int64<br/>dtypes: float64(2), int64(7), object(5)<br/>memory usage: 5.2+ MB</span></pre><p id="4802" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">由于我们有几个分类列，我们将使用熊猫。分类函数并返回数字列，每个数字代表列中不同的值。</p><h1 id="2165" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">XGBoost API</h1><p id="4627" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">经过这几个简单的步骤，我们可以说我们已经准备好应用XGBoost及其API了。此外，我们将通过谷歌的Collab内置结构来比较它的速度和性能，以及GPU和常规CPU。</p><p id="dc05" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">首先，我们需要将表格数据转换成数据矩阵。</p><p id="ee41" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">DMatrix是XGBoost开发人员创建的一种数据结构，这也是XGBoost速度超快的原因之一。也就是说，它实现是特定的，且是为这个特定算法精心设计的。</p><p id="9033" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">之后，我们需要确定一些需要传递给模型的参数。XGBoost有很多参数，但我们将重点关注几个简单但仍然重要的参数。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="ebfc" class="la iw hi kw b fi lb lc l ld le"># The model's individual parameters</span><span id="904f" class="la iw hi kw b fi lf lc l ld le">general_params = {"verbosity": 1,</span><span id="90e0" class="la iw hi kw b fi lf lc l ld le">"booster": "gbtree"} #just to get familiar with the notations</span><span id="c831" class="la iw hi kw b fi lf lc l ld le">tree_params = {"eta": 0.1,</span><span id="18ac" class="la iw hi kw b fi lf lc l ld le">"max_depth": 8,</span><span id="4403" class="la iw hi kw b fi lf lc l ld le">"min_child_weight": 1,</span><span id="d53d" class="la iw hi kw b fi lf lc l ld le">"tree_method": "gpu_hist"</span><span id="3982" class="la iw hi kw b fi lf lc l ld le">}</span><span id="4ed5" class="la iw hi kw b fi lf lc l ld le">learning_task_parameters = {"objective": "reg:squarederror",</span><span id="0e28" class="la iw hi kw b fi lf lc l ld le">"eval_metric" : "rmse"}</span><span id="9168" class="la iw hi kw b fi lf lc l ld le">model_params = {**general_params, **tree_params, **learning_task_parameters}</span></pre><p id="35e7" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">第一个字典<em class="ll"> general_params </em>由已经设置为这些值的默认参数组成。</p><p id="a36f" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">第二个参数tree_params更重要。在其中，我们定义了算法的学习率，is max_depth，它的min_child_weight(所有这些定义了模型的学习和它的最终结果，比如过拟合或欠拟合)以及“tree_method”。这一点很重要，因为在本文中，我们将XGBoost的性能与GPU和常规CPU进行比较。此参数可以留空，它将使用其“自动”默认值。</p><p id="3096" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">因此，接下来我们需要做的就是实例化一个与这个模型完全相同的模型，但是没有“tree_method”参数。</p><p id="93ab" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">现在，我们只需要测试两者的性能。</p><h1 id="b52b" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">使用GPU</h1><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="5231" class="la iw hi kw b fi lb lc l ld le">model = xgb.train(model_params, d_train, num_boost_round= num_boost_round, evals = [(d_test, "test")], early_stopping_rounds = 10)</span><span id="605e" class="la iw hi kw b fi lf lc l ld le">0]	test-rmse:260.538<br/>Will train until test-rmse hasn't improved in 10 rounds.<br/>[1]	test-rmse:252.566<br/>[2]	test-rmse:246.073<br/>[3]	test-rmse:240.912<br/>[4]	test-rmse:236.7<br/>[5]	test-rmse:232.965<br/>[6]	test-rmse:230.032<br/>[7]	test-rmse:227.433<br/>[8]	test-rmse:225.417<br/>[9]	test-rmse:223.836<br/>[10]	test-rmse:222.405<br/>[11]	test-rmse:221.197<br/>[12]	test-rmse:220.515<br/>[13]	test-rmse:219.941<br/>[14]	test-rmse:219.523<br/>[15]	test-rmse:219.903<br/>[16]	test-rmse:219.719<br/>[17]	test-rmse:219.644<br/>[18]	test-rmse:219.46<br/>[19]	test-rmse:219.341<br/>[20]	test-rmse:219.396<br/>[21]	test-rmse:219.492<br/>[22]	test-rmse:219.109<br/>[23]	test-rmse:219.02<br/>[24]	test-rmse:219.108<br/>[25]	test-rmse:218.846<br/>[26]	test-rmse:218.614<br/>[27]	test-rmse:218.538<br/>[28]	test-rmse:218.545<br/>[29]	test-rmse:218.546<br/>[30]	test-rmse:218.606<br/>[31]	test-rmse:218.779<br/>[32]	test-rmse:218.611<br/>[33]	test-rmse:218.729<br/>[34]	test-rmse:218.807<br/>[35]	test-rmse:218.746<br/>[36]	test-rmse:218.826<br/>[37]	test-rmse:219.02<br/>Stopping. Best iteration:<br/>[27]	test-rmse:218.538<br/><br/>CPU times: user 1.17 s, sys: 747 ms, total: 1.92 s<br/>Wall time: 1.95 s</span></pre><p id="e950" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">现在我们将使用XGBoost的CV内置函数，并计算它的性能。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="90e6" class="la iw hi kw b fi lb lc l ld le">%%time</span><span id="fb53" class="la iw hi kw b fi lf lc l ld le">cv_results = xgb.cv(model_params, d_train, num_boost_round = num_boost_round, seed = 41, nfold = 10, metrics = {"rmse"}, early_stopping_rounds = 10)</span><span id="5796" class="la iw hi kw b fi lf lc l ld le">CPU times: user 10.3 s, sys: 6.07 s, total: 16.4 s<br/>Wall time: 16.4 s</span></pre><h1 id="42b7" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">不带GPU</h1><p id="3dbf" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">我们将执行与之前相同的步骤。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="dbd9" class="la iw hi kw b fi lb lc l ld le">%%time</span><span id="26fa" class="la iw hi kw b fi lf lc l ld le">model = xgb.train(model_params, d_train, num_boost_round= num_boost_round, evals = [(d_test, "test")], early_stopping_rounds = 10)</span><span id="f9d2" class="la iw hi kw b fi lf lc l ld le">0]	test-rmse:260.663<br/>Will train until test-rmse hasn't improved in 10 rounds.<br/>[1]	test-rmse:252.803<br/>[2]	test-rmse:246.229<br/>[3]	test-rmse:241.064<br/>[4]	test-rmse:236.891<br/>[5]	test-rmse:233.325<br/>[6]	test-rmse:230.704<br/>[7]	test-rmse:228.544<br/>[8]	test-rmse:226.999<br/>[9]	test-rmse:225.487<br/>[10]	test-rmse:224.685<br/>[11]	test-rmse:224.073<br/>[12]	test-rmse:223.353<br/>[13]	test-rmse:222.934<br/>[14]	test-rmse:222.601<br/>[15]	test-rmse:222.435<br/>[16]	test-rmse:222.544<br/>[17]	test-rmse:222.532<br/>[18]	test-rmse:222.712<br/>[19]	test-rmse:222.187<br/>[20]	test-rmse:222.263<br/>[21]	test-rmse:221.973<br/>[22]	test-rmse:221.898<br/>[23]	test-rmse:221.9<br/>[24]	test-rmse:221.668<br/>[25]	test-rmse:221.591<br/>[26]	test-rmse:221.584<br/>[27]	test-rmse:221.649<br/>[28]	test-rmse:221.907<br/>[29]	test-rmse:221.829<br/>[30]	test-rmse:222.147<br/>[31]	test-rmse:221.988<br/>[32]	test-rmse:221.957<br/>[33]	test-rmse:221.249<br/>[34]	test-rmse:221.144<br/>[35]	test-rmse:221.161<br/>[36]	test-rmse:221.081<br/>[37]	test-rmse:221.175<br/>[38]	test-rmse:221.169<br/>[39]	test-rmse:221.251<br/>[40]	test-rmse:221.247<br/>[41]	test-rmse:221.255<br/>[42]	test-rmse:221.246<br/>[43]	test-rmse:221.293<br/>[44]	test-rmse:221.149<br/>[45]	test-rmse:220.766<br/>[46]	test-rmse:220.965<br/>[47]	test-rmse:221.119<br/>[48]	test-rmse:221.181<br/>[49]	test-rmse:221.177<br/>[50]	test-rmse:221.272<br/>[51]	test-rmse:221.318<br/>[52]	test-rmse:221.366<br/>[53]	test-rmse:220.959<br/>[54]	test-rmse:220.975<br/>[55]	test-rmse:220.934<br/>Stopping. Best iteration:<br/>[45]	test-rmse:220.766<br/><br/>CPU times: user 6.14 s, sys: 124 ms, total: 6.26 s<br/>Wall time: 3.46 s</span></pre><p id="8669" class="pw-post-body-paragraph jt ju hi jv b jw lg jy jz ka lh kc kd ke li kg kh ki lj kk kl km lk ko kp kq hb bi translated">现在，通过交叉验证。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="8bd5" class="la iw hi kw b fi lb lc l ld le">%%time</span><span id="af04" class="la iw hi kw b fi lf lc l ld le">cv_results = xgb.cv(model_params, d_train, num_boost_round = num_boost_round, seed = 41, nfold = 10, metrics = {"rmse"}, early_stopping_rounds = 10)</span><span id="595c" class="la iw hi kw b fi lf lc l ld le">CPU times: user 50.1 s, sys: 126 ms, total: 50.3 s<br/>Wall time: 25.7 s</span></pre></div></div>    
</body>
</html>