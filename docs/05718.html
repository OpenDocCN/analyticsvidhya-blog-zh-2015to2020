<html>
<head>
<title>Snowflake with Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带火花的雪花</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/snowflake-with-spark-2f3691af322d?source=collection_archive---------13-----------------------#2020-04-30">https://medium.com/analytics-vidhya/snowflake-with-spark-2f3691af322d?source=collection_archive---------13-----------------------#2020-04-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/7950542b51c9803f3e10b4f201305373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aUpM55gTsJf1TkPTYQBElw.png"/></div></div></figure><div class=""/><p id="b13f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Snowflake是一个基于云的SQL数据仓库，专注于高性能、零调优、数据源多样性和安全性。</p><p id="36e4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark的雪花连接器支持使用雪花作为Apache Spark数据源，类似于其他数据源(PostgreSQL、HDFS、S3等)。).雪花支持三个版本的Spark: Spark 2.2、Spark 2.3和Spark 2.4。每个版本的Spark都有一个单独版本的雪花Spark连接器。针对您的Spark版本使用正确版本的连接器。</p><p id="dad9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本主题中，我们将使用Spark 2.4，并了解如何向雪花数据库读写数据帧。</p><p id="7114" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">确保您在这里遵循关于创建雪花数据库<a class="ae jo" rel="noopener" href="/@keitamouhamad/snowflake-in-5minutes-9c6e4c22bb4">的主题。</a></p><h2 id="6784" class="jp jq ht bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">SBT属地</h2><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="4e01" class="jp jq ht kp b fi kt ku l kv kw"><em class="kx">libraryDependencies </em>++= <em class="kx">Seq</em>(<br/>  "net.snowflake" %% "spark-snowflake" % "2.7.0-spark_2.4"<br/>)</span></pre><h2 id="97a5" class="jp jq ht bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">创建雪花表格</h2><p id="a223" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hb bi translated">要在雪花中创建数据库，请参考主题<a class="ae jo" href="http://mk" rel="noopener ugc nofollow" target="_blank">snow SQL上的SQL </a>。要访问雪花数据库，我们必须创建一个新表。我们可以使用下面的程序来创建一个表格。</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="a948" class="jp jq ht kp b fi kt ku l kv kw"><em class="kx">package </em>com.sparkSnowFlake<br/><br/><em class="kx">import </em>java.sql.<em class="kx">DriverManager<br/><br/>object CreateSnowflakeTable extends App </em>{<br/><br/>  <em class="kx">val properties </em>= <em class="kx">new </em>java.util.Properties()<br/>  <em class="kx">properties</em>.put("user", "mouhamadkeita92")<br/>  <em class="kx">properties</em>.put("password", "*********")<br/>  <em class="kx">properties</em>.put("account", "re54891")<br/>  <em class="kx">properties</em>.put("warehouse", "COMPUTE_WH")<br/>  <em class="kx">properties</em>.put("db", "PEOPLE")<br/>  <em class="kx">properties</em>.put("schema", "public")<br/>  <em class="kx">properties</em>.put("role", "SYSADMIN")<br/><br/>  <em class="kx">val jdbcUrl </em>= "jdbc:snowflake://re54891.east-us-2.azure.snowflakecomputing.com/"<br/><br/>  <em class="kx">println</em>("Created connection")<br/>  <em class="kx">val connection </em>= <em class="kx">DriverManager</em>.<em class="kx">getConnection</em>(<em class="kx">jdbcUrl</em>, <em class="kx">properties</em>)<br/>  <em class="kx">val statement </em>= <em class="kx">connection</em>.createStatement<br/>  <em class="kx">println</em>("Done creating connection")<br/><br/>  <em class="kx">println</em>("Creating table PEOPLE")<br/>  <em class="kx">statement</em>.executeUpdate("create or replace table PEOPLE(name VARCHAR, age INT, job VARCHAR)")<br/>  <em class="kx">statement</em>.close()<br/>  <em class="kx">println</em>("Done creating PEOPLE table")<br/><br/>  <em class="kx">connection</em>.close()<br/>}</span></pre><p id="868c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这段代码中，我们用Spark创建了一个数据库“PEOPLE”。我们也可以用SnowSQL CLI或Snowflake GUI创建数据库。</p><h2 id="1887" class="jp jq ht bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">将火花数据帧写入雪花</h2><p id="57dd" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hb bi translated">为了将数据从雪花读入Spark数据帧，我们使用了<code class="du ld le lf kp b">DataFrame</code>的<code class="du ld le lf kp b">write()</code>方法来构造一个<code class="du ld le lf kp b">DataFrameWriter</code>。</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="f747" class="jp jq ht kp b fi kt ku l kv kw"><em class="kx">package </em>com.sparkSnowFlake<br/><br/><em class="kx">import </em>org.apache.spark.sql.{<em class="kx">SaveMode</em>, SparkSession}<br/><br/><em class="kx">object WriteDataToSnowflake extends App </em>{<br/><br/>  <em class="kx">val spark </em>= <em class="kx">SparkSession</em>.<em class="kx">builder</em>()<br/>    .master("local[*]")<br/>    .appName("SparkSnowflakeWrite")<br/>    .getOrCreate()<br/>  <em class="kx">spark</em>.<em class="kx">sparkContext</em>.setLogLevel("ERROR")<br/>  <em class="kx">import spark</em>.<em class="kx">implicits</em>._<br/>  <em class="kx">var sfParameters </em>= <em class="kx">Map</em>(<br/>    "sfURL" -&gt; "https://re54891.east-us-2.azure.snowflakecomputing.com/",<br/>    "sfAccount" -&gt; "re54891",<br/>    "sfUser" -&gt; "mouhamadkeita92",<br/>    "sfPassword" -&gt; "Ousmane92.",<br/>    "sfDatabase" -&gt; "PEOPLE",<br/>    "sfSchema" -&gt; "PUBLIC",<br/>    "sfRole" -&gt; "ACCOUNTADMIN"<br/>  )<br/><br/>  <em class="kx">val data </em>= <em class="kx">Seq</em>(("Jorge",23,"Developer"),<br/>    ("Bob",28,"Developer"),<br/>    ("Bill",31,"Admin"),<br/>    ("John",40,"Project Manager")<br/>  )<br/>  <em class="kx">val peopleDF </em>= <em class="kx">data</em>.toDF("name","age","job")<br/><br/>  <em class="kx">peopleDF</em>.write<br/>    .format("snowflake")<br/>    .options(<em class="kx">sfParameters</em>)<br/>    .option("dbtable", "PEOPLE")<br/>    .mode(<em class="kx">SaveMode</em>.<em class="kx">Overwrite</em>)<br/>    .save()<br/>}</span></pre><p id="d947" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这段代码中，我们将数据插入数据库PEOPLE中的表PEOPLE。在下一节中，我们将把保存在PEOPLE表中的数据读入Dataframe。</p><h2 id="c628" class="jp jq ht bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">将雪花表读入火花数据帧</h2><p id="68fc" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hb bi translated">为了将数据从雪花读入Spark数据帧，我们使用了<code class="du ld le lf kp b">SqlContext</code>对象的<code class="du ld le lf kp b">read()</code>方法来构造一个<code class="du ld le lf kp b">DataFrameReader</code>。</p><blockquote class="lg lh li"><p id="12c2" class="iq ir kx is b it iu iv iw ix iy iz ja lj jc jd je lk jg jh ji ll jk jl jm jn hb bi translated">使用DataFrames时，雪花连接器仅支持SELECT查询。</p></blockquote><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="118e" class="jp jq ht kp b fi kt ku l kv kw"><em class="kx">package </em>com.sparkSnowFlake<br/><br/><em class="kx">import </em>org.apache.spark.sql.{<em class="kx">DataFrame</em>, SparkSession}<br/><br/><em class="kx">object ReadDataFromSnowflake extends App </em>{<br/><br/>  <em class="kx">val spark </em>= <em class="kx">SparkSession</em>.<em class="kx">builder</em>()<br/>    .master("local[*]")<br/>    .appName("SparkByExamples.com")<br/>    .getOrCreate()<br/>  <em class="kx">var sfParameters </em>= <em class="kx">Map</em>(<br/>    "sfURL" -&gt; "https://re54891.east-us-2.azure.snowflakecomputing.com/",<br/>    "sfAccount" -&gt; "re54891",<br/>    "sfUser" -&gt; "mouhamadkeita92",<br/>    "sfPassword" -&gt; "********",<br/>    "sfDatabase" -&gt; "PEOPLE",<br/>    "sfSchema" -&gt; "PUBLIC",<br/>    "sfRole" -&gt; "ACCOUNTADMIN"<br/>  )<br/><br/>  <em class="kx">val df</em>: <em class="kx">DataFrame </em>= <em class="kx">spark</em>.read<br/>    .format("snowflake")<br/>    .options(<em class="kx">sfParameters</em>)<br/>    .option("dbtable", "PEOPLE")<br/>    .load()<br/>  <em class="kx">df</em>.show(<em class="kx">false</em>)<br/>}</span></pre><p id="758e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出</p><figure class="kk kl km kn fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lm"><img src="../Images/c7a3a6a8d103949a38bdee172909ef3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5PAAobT_esK9QiPLrr-1ZA.png"/></div></div></figure><h2 id="c808" class="jp jq ht bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">使用查询读取雪花表</h2><p id="4e31" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hb bi translated">上面带Spark的雪花示例演示了使用<code class="du ld le lf kp b">dbtable</code>选项从雪花表中读取整个表并创建Spark数据帧，下面的示例使用<code class="du ld le lf kp b">query</code>选项执行过滤SQL查询。</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="fcda" class="jp jq ht kp b fi kt ku l kv kw">  <em class="kx">val df</em>: <em class="kx">DataFrame </em>= <em class="kx">spark</em>.read<br/>    .format("snowflake")<br/>    .options(<em class="kx">sfParameters</em>)<br/>    .option("query", "SELECT * FROM PEOPLE WHERE job = 'Developer'")<br/>    .load()<br/>  <em class="kx">df</em>.show(<em class="kx">false</em>)</span></pre><p id="72cc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出</p><figure class="kk kl km kn fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lm"><img src="../Images/3fec9f296fb900a46b20b96868b37d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rEL4UUCC2LXfR4ID3JuuCQ.png"/></div></div></figure><h2 id="8952" class="jp jq ht bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">通过SnowSQL CLI检查数据</h2><p id="3a46" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hb bi translated">我们可以从SnowSQL中读取数据，以确保一切正常。</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="1b69" class="jp jq ht kp b fi kt ku l kv kw">❯ snowsql<br/>* SnowSQL * v1.2.5<br/>Type SQL statements or !help<br/>mouhamadkeita92#COMPUTE_WH@PEOPLE.PUBLIC&gt;SELECT * FROM "PEOPLE"."PUBLIC"."PEOPLE"<br/>                                         ;<br/>+-------+-----+-----------------+<br/>| NAME  | AGE | JOB             |<br/>|-------+-----+-----------------|<br/>| Jorge |  23 | Developer       |<br/>| Bob   |  28 | Developer       |<br/>| Bill  |  31 | Admin           |<br/>| John  |  40 | Project Manager |<br/>+-------+-----+-----------------+<br/>4 Row(s) produced. Time Elapsed: 1.795s<br/>mouhamadkeita92#COMPUTE_WH@PEOPLE.PUBLIC&gt;</span></pre><p id="6af8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> <em class="kx">参考文献:</em> </strong></p><ul class=""><li id="3c47" class="ln lo ht is b it iu ix iy jb lp jf lq jj lr jn ls lt lu lv bi translated"><a class="ae jo" href="https://docs.snowflake.com/en/user-guide-getting-started.html" rel="noopener ugc nofollow" target="_blank">https://docs . snow flake . com/en/user-guide-getting-started . html</a></li><li id="154b" class="ln lo ht is b it lw ix lx jb ly jf lz jj ma jn ls lt lu lv bi translated"><a class="ae jo" href="https://www.snowflake.com/" rel="noopener ugc nofollow" target="_blank">https://www.snowflake.com/</a></li><li id="72c9" class="ln lo ht is b it lw ix lx jb ly jf lz jj ma jn ls lt lu lv bi translated"><a class="ae jo" href="https://github.com/mkprime92/sparksnowflake" rel="noopener ugc nofollow" target="_blank">https://github.com/mkprime92/sparksnowflake</a></li></ul></div></div>    
</body>
</html>