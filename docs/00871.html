<html>
<head>
<title>[Tensorflow 2.0]Save and Restore Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[tensor flow 2.0]保存和恢复模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorflow-2-0-save-and-restore-models-4708ed3f0d8?source=collection_archive---------2-----------------------#2019-09-15">https://medium.com/analytics-vidhya/tensorflow-2-0-save-and-restore-models-4708ed3f0d8?source=collection_archive---------2-----------------------#2019-09-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7c68" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了更好地理解，将会对某些部分进行修改和阐述，但是，我在此承认以下帖子是基于中提供的TensorFlow教程:</p><div class="jd je ez fb jf jg"><a href="https://www.tensorflow.org/beta/tutorials/keras/save_and_restore_models" rel="noopener  ugc nofollow" target="_blank"><div class="jh ab dw"><div class="ji ab jj cl cj jk"><h2 class="bd hj fi z dy jl ea eb jm ed ef hh bi translated">保存和恢复模型| TensorFlow核心</h2><div class="jn l"><h3 class="bd b fi z dy jl ea eb jm ed ef dx translated">您看到了如何将权重加载到模型中。手动保存它们与模型一样简单</h3></div><div class="jo l"><p class="bd b fp z dy jl ea eb jm ed ef dx translated">www.tensorflow.org</p></div></div></div></a></div><p id="31f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有关代码和数据集的更详细的解释和背景知识，您可以随时查阅链接。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="69c0" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">一.导言</h1><h2 id="4da9" class="ku jx hi bd jy kv kw kx kc ky kz la kg iq lb lc kk iu ld le ko iy lf lg ks lh bi translated">我们为什么要保存模型？</h2><p id="4240" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lk is it iu ll iw ix iy lm ja jb jc hb bi translated">我们需要一些动机来开始这样一个保存和恢复模型的漫长过程，那么我们到底为什么要做这样一个负担呢？</p><p id="e20b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">目的很简单，为什么我们要保存一个简单的word文件或在两个小时的讲座中做的笔记？然而，我们保存一个模型所能达到的效率是保存几页长的word文件所不能比拟的。</p><p id="8f6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建的模型可以在训练过程中和训练后保存。即使这个中等的草稿也能保存每秒发生的任何变化，为什么不是张量流模型呢？这个过程是通过<em class="ln">在训练期间保存检查点来完成的。</em>在检查点和回调<strong class="ih hj">的帮助下，你可以在训练期间和结束时持续保存模型。</strong>当medium自动保存您的草稿或您的帖子在Instagram上“临时保存”时，我们感到安全，TensorFlow检查点也是如此；你现在不会受到工作中可能出现的任何干扰。</p><h2 id="6f9f" class="ku jx hi bd jy kv kw kx kc ky kz la kg iq lb lc kk iu ld le ko iy lf lg ks lh bi translated">我们想拯救什么？</h2><p id="3405" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lk is it iu ll iw ix iy lm ja jb jc hb bi translated">我们可以只保存权重来恢复它们或整个模型，这样您就不必重新进行整个训练。保存的最大好处是，您可以将您的模型共享给其他人，以便他们可以参考您的代码，或者在您的模型的训练结果的基础上，以更高的准确性和效率创建他们的模型。</p><h2 id="3ee7" class="ku jx hi bd jy kv kw kx kc ky kz la kg iq lb lc kk iu ld le ko iy lf lg ks lh bi translated">我们如何“恢复”保存的模型？</h2><p id="ae48" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lk is it iu ll iw ix iy lm ja jb jc hb bi translated">一旦你保存了你的微软Word文件，你只需要双击它或者你喜欢的任何方式打开它。此外，我们经常打开一个下载的文件，并从那里开始你的工作，或者只是参考你的参考文件。同样的事情也发生在模型上，但是比双击桌面上的文件名稍微复杂一些。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="3026" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">二。设置</h1><p id="e7c2" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lk is it iu ll iw ix iy lm ja jb jc hb bi translated"><strong class="ih hj"> 1 —安装或导入Tensorflow </strong></p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="c778" class="ku jx hi lt b fi lx ly l lz ma">try:<br/>  # %tensorflow_version only exists in Colab.<br/>  %tensorflow_version 2.x<br/>except Exception:<br/>  pass</span><span id="f563" class="ku jx hi lt b fi mb ly l lz ma">!pip install -q pyyaml h5py  # Required to save models in HDF5 format</span><span id="9d3b" class="ku jx hi lt b fi mb ly l lz ma">from __future__ import absolute_import, division, print_function, unicode_literals</span><span id="86d6" class="ku jx hi lt b fi mb ly l lz ma">import os</span><span id="8042" class="ku jx hi lt b fi mb ly l lz ma">import tensorflow as tf<br/>from tensorflow import keras</span><span id="c232" class="ku jx hi lt b fi mb ly l lz ma">print(tf.version.VERSION)</span></pre><p id="0886" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">**正如带有hashtag的代码中所说，您应该在Colab中练习代码**</p><p id="33fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae mc" href="https://colab.research.google.com/notebooks/welcome.ipynb#recent=true" rel="noopener ugc nofollow" target="_blank">https://colab.research.google.com</a></p><blockquote class="md me mf"><p id="9424" class="if ig ln ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">(边注)我刚不小心按了command+w回来！！对于Mac用户，你会看到刚刚发生在我身上的事情，但是自动保存确实救了我！我还需要30分钟来重写这一切，或者花3个小时来写一个tensorflow代码！所以，请学习如何保存你的模型。；)</p></blockquote><p id="1b78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2 —导入数据集</strong></p><ul class=""><li id="7e7d" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated">在本练习中，我们使用MNIST数据集和前1000个示例。</li></ul><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="a141" class="ku jx hi lt b fi lx ly l lz ma">(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()</span><span id="edc1" class="ku jx hi lt b fi mb ly l lz ma">train_labels = train_labels[:1000]<br/>test_labels = test_labels[:1000]</span><span id="4b28" class="ku jx hi lt b fi mb ly l lz ma">train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0<br/>test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0</span></pre><p id="80e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3 —定义模型</strong></p><ul class=""><li id="d372" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated">我们将建立一个简单的序列模型。</li></ul><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="76d3" class="ku jx hi lt b fi lx ly l lz ma"># Define a simple sequential model<br/>def create_model():<br/>  model = tf.keras.models.Sequential([<br/>    keras.layers.Dense(512, activation='relu', input_shape=(784,)),<br/>    keras.layers.Dropout(0.2),<br/>    keras.layers.Dense(10, activation='softmax')<br/>  ])</span><span id="d3d6" class="ku jx hi lt b fi mb ly l lz ma">model.compile(optimizer='adam',<br/>                loss='sparse_categorical_crossentropy',<br/>                metrics=['accuracy'])</span><span id="2449" class="ku jx hi lt b fi mb ly l lz ma">return model</span></pre><ul class=""><li id="5540" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated">这里定义的create_model()'函数将不断地被用来使代码更简单。</li><li id="9f77" class="mj mk hi ih b ii ms im mt iq mu iu mv iy mw jc mo mp mq mr bi translated">所以用' model=create_model()'，我们就完成了模型的构建。</li></ul><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="3852" class="ku jx hi lt b fi lx ly l lz ma"># Create a basic model instance<br/>model = create_model()</span><span id="901e" class="ku jx hi lt b fi mb ly l lz ma"># Display the model's architecture<br/>model.summary()</span></pre><ul class=""><li id="5881" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated"><strong class="ih hj"> model.summary( ) </strong>的结果如下:</li></ul><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="f0ce" class="ku jx hi lt b fi lx ly l lz ma">Model: "sequential"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>dense (Dense)                (None, 512)               401920    <br/>_________________________________________________________________<br/>dropout (Dropout)            (None, 512)               0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 10)                5130      <br/>=================================================================<br/>Total params: 407,050<br/>Trainable params: 407,050<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="77b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我被教导说，我不应该认为数字是理所当然的。现在，我想把这个习惯传递给可能在网上的读者。</p><ul class=""><li id="4664" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated"><strong class="ih hj"> input_shape=(784，)</strong>来自<strong class="ih hj"> reshape(-1，28*28): <br/> </strong>在建模之前，我们将28*28的二维图像文件整形为长度为28*28=784的1D矢量</li><li id="3fe9" class="mj mk hi ih b ii ms im mt iq mu iu mv iy mw jc mo mp mq mr bi translated"><strong class="ih hj">第一个密集层的参数# 401920 </strong>:该层有(784+1)*512个参数。<br/><strong class="ih hj"><em class="ln">keras . layers . dense(512，activation='relu '，input_shape=(784，)</em> </strong> <br/> 512是第一个密集层的节点数(⁹).<br/> 784是对应于该层作为输入的1D向量的权重数。<br/> 1是将要添加的偏差数。<br/>所以每个节点都以W1*X1+…+W784*X784 + B1作为输入！</li><li id="6ad4" class="mj mk hi ih b ii ms im mt iq mu iu mv iy mw jc mo mp mq mr bi translated"><strong class="ih hj">keras . layers . dropout(0.2)</strong>通过将输入单元的某个分数(0.2)随机设置为零，来防止通过历元的过度拟合。我把它理解为放松身体肌肉，深呼吸以做出更好的瑜伽姿势。通过将负担(数据)保持在您可以放心管理的水平，我们有时可以实现更多。</li><li id="25a1" class="mj mk hi ih b ii ms im mt iq mu iu mv iy mw jc mo mp mq mr bi translated"><strong class="ih hj">参数#5130 </strong>来自第二密集层:在这一层中，有(512+1)*10个参数。<strong class="ih hj"><br/><em class="ln">keras . layers . dense(10，activation = ' soft max ')</em></strong><br/>10是第二密集层的节点数。<br/> 512是对应于输入长度或第一层节点数的权重数。<br/> 1是偏置数。</li></ul><blockquote class="md me mf"><p id="e1cd" class="if ig ln ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">旁注)参考以下教程以了解有关MNIST数据集或建模过程的更多信息<a class="ae mc" href="https://www.tensorflow.org/beta/tutorials/keras/basic_classification" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/beta/tutorials/keras/basic _ classification</a></p></blockquote></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="e666" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">三。在训练期间保存检查点，并将其恢复到新的未训练模型</h1><p id="8d1b" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lk is it iu ll iw ix iy lm ja jb jc hb bi translated">通过保存检查点，如果建模由于任何可能的动机而中断，人们可以使用经过训练的模型，而无需重做整个过程或从中间重新开始。</p><p id="c74b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1。仅在训练期间保存重量</strong></p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="7619" class="ku jx hi lt b fi lx ly l lz ma">checkpoint_path = "training_1/cp.ckpt"<br/>checkpoint_dir = os.path.dirname(checkpoint_path)</span><span id="9a5f" class="ku jx hi lt b fi mb ly l lz ma"><strong class="lt hj"># Create a callback that saves the model's weights<br/></strong>cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,<br/>                                   <strong class="lt hj">save_weights_only=True</strong>,<br/>                                   verbose=1)</span><span id="34cb" class="ku jx hi lt b fi mb ly l lz ma"><strong class="lt hj"># Train the model with the new callback<br/></strong>model.fit(train_images, <br/>          train_labels,  <br/>          epochs=10,<br/>          validation_data=(test_images,test_labels),<br/>          callbacks=[cp_callback])  # Pass callback to training</span><span id="cd14" class="ku jx hi lt b fi mb ly l lz ma"><strong class="lt hj"># This may generate warnings related to saving the state of the optimizer.<br/># These warnings (and similar warnings throughout this notebook)<br/># are in place to discourage outdated usage, and can be ignored.</strong></span></pre><p id="df70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该过程将留下在每个时期结束时更新的Tensorflow检查点文件的单一集合。</p><p id="a5f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以通过以下方式看到这一点:</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="6a2c" class="ku jx hi lt b fi lx ly l lz ma">!ls {checkpoint_dir}</span></pre><p id="6268" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其结果是:</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="6cb8" class="ku jx hi lt b fi lx ly l lz ma">checkpoint           cp.ckpt.data-00001-of-00002<br/>cp.ckpt.data-00000-of-00002  cp.ckpt.index</span></pre><p id="0ad8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。从纯权重模型中恢复一个模型，并将其应用于一个新的未经训练的模型</strong></p><p id="32f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不幸的是，与word文件或中型草稿不同，检查点<strong class="ih hj">不会</strong>保存模型的所有内容。其实更多的是你看完长篇论文后做的旁注。所以，现在您想打开保存的便笺并创建您的另一张便笺。</p><p id="aa92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当从权重恢复一个模型时，你总是需要一个与原始模型结构完全相同的模型。<strong class="ih hj"> <em class="ln">一旦你有了相同的模型架构，你就可以共享权重，尽管它是一个模型的不同实例。</em> </strong></p><p id="d6ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你不能用专门为Galaxy Note 10设计的充电器给你的全新iPhone 11充电。然而，尽管手机的功能不同，你仍然可以用你用来给iPhone XR充电的充电器给iPhone 11充电。(除非他们改变了标准)</p><ul class=""><li id="257c" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated">现在，重新构建一个新的未训练模型，然后在测试集上对其进行评估。</li></ul><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="5cb4" class="ku jx hi lt b fi lx ly l lz ma"># Create a basic model instance<br/>model = create_model()</span><span id="f583" class="ku jx hi lt b fi mb ly l lz ma"># Evaluate the model<br/>loss, acc = model.evaluate(test_images, test_labels)<br/>print("Untrained model, accuracy: {:5.2f}%".format(100*acc))</span></pre><p id="d085" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将导致相当令人沮丧的精度水平。(很明显，您没有接受过培训——如果模型正确地将图像文件与正确的标签相匹配，这仅仅是一种运气)</p><ul class=""><li id="c261" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated">现在，加载我们之前在checkpoint中保存的重量，并重新评估模型。</li></ul><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="0c49" class="ku jx hi lt b fi lx ly l lz ma"># Loads the weights<br/>model.load_weights(checkpoint_path)</span><span id="c60c" class="ku jx hi lt b fi mb ly l lz ma"># Re-evaluate the model<br/>loss,acc = model.evaluate(test_images, test_labels)<br/>print("Restored model, accuracy: {:5.2f}%".format(100*acc))</span></pre><p id="df35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将精度与我们在原始模型中得到的精度进行比较。</p><p id="6921" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面，将其与以下模型拟合之前获得的结果进行比较:</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="460d" class="ku jx hi lt b fi lx ly l lz ma">model.fit(train_images, <br/>          train_labels,  <br/>          epochs=10,<br/>          validation_data=(test_images,test_labels),<br/>          callbacks=[cp_callback])</span></pre><p id="32d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。检查点回调选项</strong></p><p id="80ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如您可能已经预料到的那样，总是有修改一些关于检查点的选项的空间。</p><p id="059e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比如看论文或者备考的时候有必要一行一行做笔记吗？对于一篇极其庞大的论文来说，主题或概念在整篇论文中不会改变，为了提高效率，你可能需要跳过一些页面。同样，回调提供了一个选项，以便您可以在每个特定时期保存一次检查点。</p><p id="b1db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，为了方便起见，您可以为检查点命名。</p><p id="d315" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们训练一个新模型，每五个历元保存一次不同名称的检查点。</p><p id="3545" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3.1。定义检查点路径和检查点目录</strong></p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="abef" class="ku jx hi lt b fi lx ly l lz ma"># Include the epoch in the file name (uses `str.format`)<br/>checkpoint_path = <strong class="lt hj">"training_2/cp-{epoch:04d}.ckpt"<br/></strong>checkpoint_dir = os.path.dirname(checkpoint_path)</span><span id="950c" class="ku jx hi lt b fi mb ly l lz ma"><strong class="lt hj">#previoulsy, checkpoint_path = "training_1/cp.ckpt"</strong></span></pre><p id="4b7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3.2。创建一个保存模型权重的回调</strong></p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="5097" class="ku jx hi lt b fi lx ly l lz ma"># Create a callback that saves the model's weights every 5 epochs<br/>cp_callback = tf.keras.callbacks.ModelCheckpoint(<br/>    filepath=checkpoint_path, <br/>    verbose=1, <br/>    save_weights_only=True,<br/>    <strong class="lt hj">period=5</strong>)</span><span id="ac25" class="ku jx hi lt b fi mb ly l lz ma"><strong class="lt hj"># previously, there was no period defined </strong></span></pre><p id="ff32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">在第3.3和3.4部分中，我们将在保存时进行训练，然后创建一个新模型并重新加载保存的权重。与我们对基本检查点所做的过程完全相同(不带选项的版本)</strong></p><p id="c7b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3.3用新的回调(训练)创建新的模型和模型拟合</strong></p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="b700" class="ku jx hi lt b fi lx ly l lz ma"># Create a new model instance<br/>model = create_model()<br/><br/># Save the weights using the `checkpoint_path` format<br/><strong class="lt hj">model.save_weights(checkpoint_path.format(epoch=0))<br/></strong><br/># Train the model with the new callback<br/>model.fit(train_images, <br/>          train_labels,<br/>         <strong class="lt hj"> epochs=50</strong>, <br/>          callbacks=[cp_callback],<br/>          validation_data=(test_images,test_labels),<br/>          verbose=0)</span></pre><p id="6035" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们希望查看生成的检查点列表，然后检查最新的检查点，并将其命名为“latest”</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="58a5" class="ku jx hi lt b fi lx ly l lz ma">! ls {checkpoint_dir}</span><span id="72bc" class="ku jx hi lt b fi mb ly l lz ma">latest = tf.train.latest_checkpoint(checkpoint_dir)<br/>latest</span></pre><p id="61f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将导致</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="34f9" class="ku jx hi lt b fi lx ly l lz ma">'training_2/cp-0050.ckpt'</span></pre><p id="2af4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3.4。重新创建一个模型并重新加载最新的检查点</strong></p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="3b73" class="ku jx hi lt b fi lx ly l lz ma"># Create a new model instance<br/>model = create_model()<br/><br/># Load the previously saved weights<br/>model.load_weights(latest)<br/><br/># Re-evaluate the model<br/>loss, acc = model.evaluate(test_images, test_labels)<br/>print("Restored model, accuracy: {:5.2f}%".format(100*acc))</span></pre><p id="91fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准确度的结果如何不同或相似？</p><p id="ab23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。手动保存重量</strong></p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="3423" class="ku jx hi lt b fi lx ly l lz ma"># Save the weights<br/>model.save_weights(<strong class="lt hj">'./checkpoints/my_checkpoint'</strong>)<br/><strong class="lt hj">#previously, <em class="ln">model.save_weights(checkpoint_path.format(epoch=0))</em></strong></span><span id="ce1e" class="ku jx hi lt b fi mb ly l lz ma"><br/># Create a new model instance<br/>model = create_model()<br/><br/># Restore the weights<br/>model.load_weights(<strong class="lt hj">'./checkpoints/my_checkpoint'</strong>)<br/><strong class="lt hj"><em class="ln">#previously, model.load_weights(checkpoint_path) </em></strong></span><span id="210e" class="ku jx hi lt b fi mb ly l lz ma"># Evaluate the model<br/>loss,acc = model.evaluate(test_images, test_labels)<br/>print("Restored model, accuracy: {:5.2f}%".format(100*acc))</span></pre><h1 id="66cc" class="jw jx hi bd jy jz mx kb kc kd my kf kg kh mz kj kk kl na kn ko kp nb kr ks kt bi translated"><strong class="ak">四。保存整个模型</strong></h1><p id="c5b5" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lk is it iu ll iw ix iy lm ja jb jc hb bi translated">如果要整体保存模型呢？检查点方法只保存权重，但是通过将整个模型保存到一个文件中，我们可以共享一个模型并重新加载它，而无需重新定义一个应该与之前完全相同的模型。</p><p id="2a3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的例子中，我们定义了<em class="ln"> 'create_model()' </em>，所以我们确信任何新创建的带有<em class="ln"> 'model= create_model()' </em>的模型实例都将具有完全相同的模型架构。但是，如果你想重新加载在网上下载的模型呢？如果你没有下载代码的完整信息，可能会有些困难。</p><p id="f25d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，通过保存一个完整的模型是非常有用的，从某种意义上说，你总是可以从保存的模型完成其过程的部分开始，并运行你自己的代码或模型。</p><ol class=""><li id="d2f8" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc nc mp mq mr bi translated"><strong class="ih hj">将模型保存为HDF5文件</strong></li></ol><ul class=""><li id="b641" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated">将模型保存到HDF5文件中相当简单；<strong class="ih hj"><em class="ln">' model . save(' name . H5 ')'</em></strong></li></ul><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="25ef" class="ku jx hi lt b fi lx ly l lz ma"># Create a new model instance<br/>model = create_model()<br/><br/># Train the model<br/>model.fit(train_images, train_labels, epochs=5)<br/><br/># Save the entire model to a HDF5 file<br/>model.save('my_model.h5')</span></pre><p id="6b58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。从文件</strong>重新创建模型</p><ul class=""><li id="ca00" class="mj mk hi ih b ii ij im in iq ml iu mm iy mn jc mo mp mq mr bi translated">更多的是从您或其他作者离开的部分重新加载模型。</li></ul><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="600f" class="ku jx hi lt b fi lx ly l lz ma"># Recreate the exact same model, including its weights and the optimizer<br/>new_model = keras.models.load_model('my_model.h5')<br/><br/># Show the model architecture<br/>new_model.summary()</span></pre><p id="2fb5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果和以前完全一样；(检查二。设置，第3点。)</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="625c" class="ku jx hi lt b fi lx ly l lz ma">Model: "sequential_5"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>dense_10 (Dense)             (None, 512)               401920    <br/>_________________________________________________________________<br/>dropout_5 (Dropout)          (None, 512)               0         <br/>_________________________________________________________________<br/>dense_11 (Dense)             (None, 10)                5130      <br/>=================================================================<br/>Total params: 407,050<br/>Trainable params: 407,050<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="8299" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以重新评估模型的准确性；</p><pre class="lo lp lq lr fd ls lt lu lv aw lw bi"><span id="0fa2" class="ku jx hi lt b fi lx ly l lz ma">loss, acc = new_model.evaluate(test_images, test_labels)<br/>print("Restored model, accuracy: {:5.2f}%".format(100*acc))</span></pre><p id="f62b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，通过保存模型，可以保存权重、模型架构和优化器。</p><p id="67d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望这篇文章对你理解保存和重新加载tensorflow模型有所帮助。我试图根据自己的类比来总结和解释这些概念，但我希望这不会让人们更加困惑。</p><p id="8d0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里没有人是专家，所以可能会有一些错误。因此，任何抬头是完全欢迎的，我将很荣幸有人问我问题！</p><p id="ef78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">祝你有愉快的一天！</p></div></div>    
</body>
</html>