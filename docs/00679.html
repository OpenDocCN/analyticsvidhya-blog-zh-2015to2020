<html>
<head>
<title>Prepare a corpus in Sinhala language by crawling the web</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过搜索网络准备僧伽罗语语料库</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/prepare-a-corpus-in-sinhala-language-by-crawling-the-web-28f34a0a3713?source=collection_archive---------11-----------------------#2019-08-25">https://medium.com/analytics-vidhya/prepare-a-corpus-in-sinhala-language-by-crawling-the-web-28f34a0a3713?source=collection_archive---------11-----------------------#2019-08-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/4a6240bae72ec98a79a7f5a5d8054ace.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*5LqNNpWQZTsUIVAYnIklnA.jpeg"/></div></figure><p id="bfd3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果你想建立一个信息检索系统，你需要做的第一件事就是收集一组文档(语料库)。在收集一套文件的过程中，你要面对几个问题。</p><ol class=""><li id="5345" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">确定文档的单元，例如:整个电子邮件线程/仅该线程的第一封电子邮件/带或不带附件的电子邮件等</li><li id="7960" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">语言—例如:英语/僧伽罗语/泰米尔语/日语等</li><li id="a0c9" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">格式—例如:PDF/HTML/JSON等</li></ol><p id="0779" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然而，通过克服这个挑战，假设我们想要收集一组JSON格式的僧伽罗语歌曲。我发现这个网站<a class="ae jy" href="http://lyricslk.com/" rel="noopener ugc nofollow" target="_blank">http://lyricslk.com/</a>包含大约800首僧伽罗语歌词。让我们抓取这个网站来提取我们需要的信息。</p><p id="0e95" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="jz">注意:以下步骤可以应用于任何其他有网站地图的网站，语言无关紧要。</em></p><p id="264f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将使用名为<a class="ae jy" href="https://docs.scrapy.org/en/latest/" rel="noopener ugc nofollow" target="_blank"> Scrapy </a>的工具来抓取网页。这是一个用python编写的框架应用程序，用于抓取网站并提取结构化数据，这些数据可用于各种有用的应用程序。</p><ol class=""><li id="6d55" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated"><a class="ae jy" href="https://docs.scrapy.org/en/latest/intro/install.html#installing-scrapy" rel="noopener ugc nofollow" target="_blank"> <strong class="io hj">安装刺儿头</strong> </a></li></ol><p id="ec4d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">作为先决条件，您需要安装python2.7或更高版本的pip/anaconda软件包管理器</p><p id="23c3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">要使用conda安装Scrapy:</p><p id="e849" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><code class="du ka kb kc kd b">conda install -c conda-forge scrapy</code></p><p id="4d8c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">使用pip安装Scrapy:</p><p id="5d66" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><code class="du ka kb kc kd b">pip install Scrapy</code></p><p id="82ee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 2。创建一个新的Scrapy项目</strong></p><p id="2460" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">导航到您想要创建项目的位置，打开终端并发出</p><p id="a8dd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><code class="du ka kb kc kd b">scrapy startproject lyrics</code></p><p id="cd04" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里“歌词”是项目名称。</p><p id="67be" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这个命令创建一个新的名为“歌词”的Scrapy项目，它包含一个名为“歌词”的文件夹和一个名为“scrapy.cfg”的文件。</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es ke"><img src="../Images/50d2b0a37dab312b6390f7e3180f9a3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wxlMX4C7eA1dNind4ymIGg.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">内部歌词文件夹中的文件夹和文件</figcaption></figure><p id="9667" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 3。写一个蜘蛛抓取网页并提取数据</strong></p><p id="a704" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Scrapy的蜘蛛类定义了一个站点或一组站点将如何被抓取。一些通用的蜘蛛是CrawlSpider、XMLFeedSpider、CSVSpider和SitemapSpider。你可以从<a class="ae jy" href="https://docs.scrapy.org/en/latest/topics/spiders.html" rel="noopener ugc nofollow" target="_blank">这里</a>阅读更多细节。</p><p id="28e1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这篇文章中，我使用了一个<a class="ae jy" href="https://docs.scrapy.org/en/latest/topics/spiders.html#sitemapspider" rel="noopener ugc nofollow" target="_blank"> SitemapSpider </a>。SitemapSpider允许我们通过使用sitemap.xml发现URL来爬行站点。</p><p id="2ab8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">点击此链接，访问lyricslk.com网站的sitemap.xml。【http://lyricslk.com/sitemap.xml T4】</p><p id="7f5b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">导航到lyrics/lyrics/spider，用以下内容创建一个文件“lyrics_spider.py”。</p><figure class="kf kg kh ki fd ij"><div class="bz dy l di"><div class="kr ks l"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">歌词_spider.py</figcaption></figure><p id="8559" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><code class="du ka kb kc kd b">sitemap_rules = [(‘^(?!.*artist).*$’, ‘parse’)]</code></p><p id="cadd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这个sitemap_rule描述了，任何包含单词“artist”的URL都被忽略。考虑所有其他URL。</p><p id="d573" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><code class="du ka kb kc kd b">response.xpath</code>用于从各个站点提取所需信息。由于与从sitemap中提取的URL相关的所有页面都是一致的，我们可以使用一组常量xpaths来提取信息，如<strong class="io hj">歌曲</strong>、<strong class="io hj">歌手</strong>和<strong class="io hj">标题</strong>。</p><p id="aa0d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 4。</strong> <strong class="io hj">运行创建好的蜘蛛</strong></p><p id="a21a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">导航到项目的顶级目录并运行:</p><p id="141a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><code class="du ka kb kc kd b">scrapy crawl lyrics -o output.json</code></p><p id="e489" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里“歌词”是蜘蛛类使用的名称。</p><pre class="kf kg kh ki fd kt kd ku kv aw kw bi"><span id="868f" class="kx ky hi kd b fi kz la l lb lc">class LyricsSpider(SitemapSpider):<br/>      name = “lyrics”</span></pre><p id="f979" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">提取的数据将被写入“output.json”文件。</p><pre class="kf kg kh ki fd kt kd ku kv aw kw bi"><span id="36a1" class="kx ky hi kd b fi kz la l lb lc">[<br/>{"song": " \u0d9a\u0db3\u0dd4\u0dc5\u0dd4 \u0d9a\u0dd2\u0dbb\u0dd2 \u0db4\u0ddc\u0dc0\u0dcf \u0dad\u0dd4\u0dbb\u0dd4\u0dbd\u0dda \u0dc3\u0dd9\u0db1\u0dd9\u0dc4\u0dc3\u0dd2\u0db1\u0dca \u0dc4\u0daf\u0dcf \u0d9a\u0db3\u0dd4\u0dc5\u0dd4 \u0dc0\u0dd2\u0dbd \u0daf\u0dd2\u0d9c\u0dda \u0db1\u0ddc\u0db4\u0dd9\u0db1\u0dd3 \u0d9c\u0dd2\u0dba\u0dcf\u0daf\u0ddd \u0d85\u0db8\u0dca\u0db8\u0dcf  \u0dc3\u0dad\u0dca \u0db4\u0dd2\u0dba\u0dd4\u0db8\u0dca \u0dc0\u0dd2\u0dbd\u0dda \u0dc0\u0dd2\u0dbd \u0db8\u0dd0\u0daf \u0dba\u0dc5\u0dd2 \u0db4\u0dd2\u0db4\u0dd3 \u0daf\u0dd2\u0dbd\u0dda \u0daf\u0dd4\u0da7\u0dd4 \u0dc3\u0db3 \u0daf\u0dbb\u0dd4\u0dc0\u0db1\u0dca \u0dc0\u0dd9\u0dad \u0db8\u0dc0\u0d9a\u0d9c\u0dda \u0dc3\u0dd9\u0db1\u0dda \u0db8\u0dd2\u0dc4\u0dd2\u0d9a\u0dad \u0dc0\u0dd4\u0dc0 \u0dc4\u0dac\u0dcf \u0dc0\u0dd0\u0da7\u0dda  \u0db1\u0dd2\u0dc0\u0db1\u0dca \u0db8\u0db1\u0dca \u0db4\u0dd9\u0dad\u0dda \u0d94\u0db6  \u0d9c\u0dd2\u0dba \u0db8\u0db1\u0dca \u0dbd\u0d9a\u0dd4\u0dab\u0dd4 \u0db4\u0dd9\u0db1\u0dda \u0dc0\u0da9\u0dd2\u0db1\u0dcf \u0daf\u0dcf \u0db1\u0dd2\u0dc0\u0db1\u0dca \u0db4\u0dd4\u0dad\u0dd4 \u0dc3\u0dd9\u0db1\u0dda \u0dc0\u0da9\u0dcf \u0db8\u0dcf \u0daf\u0dd9\u0dc3 \u0db6\u0dbd\u0db1\u0dd4 \u0db8\u0da7 \u0daf\u0dd0\u0db1\u0dda ", "title": "\u0d9a\u0db3\u0dd4\u0dc5\u0dd4 \u0d9a\u0dd2\u0dbb\u0dd2 \u0db4\u0ddc\u0dc0\u0dcf", "singer": "\u0d85\u0db8\u0dbb\u0daf\u0dda\u0dc0 W.D."},<br/>{"song": " \u0d89\u0dbb \u0dc4\u0db3 \u0db4\u0dcf\u0dba\u0db1 \u0dbd\u0ddd\u0d9a\u0dda \u0d86\u0dbd\u0ddd\u0d9a\u0dba \u0d85\u0dad\u0dbb\u0dda \u0dc3\u0dd0\u0db4 \u0daf\u0dd4\u0d9a \u0dc3\u0db8\u0db6\u0dbb \u0dc0\u0dda \u0db8\u0dda \u0da2\u0dd3\u0dc0\u0db1 \u0d9a\u0dad\u0dbb\u0dda // \u0dc3\u0dd0\u0db4 \u0daf\u0dd4\u0d9a \u0dc3\u0db8\u0db6\u0dbb \u0dc0\u0dda  \u0d8b\u0d9a\u0dd4\u0dbd\u0dda \u0dc5\u0db8\u0dd0\u0daf\u0dda \u0dc3\u0db8\u0db6\u0dbb \u0d8b\u0dc3\u0dd4\u0dbd\u0db1 \u0d9c\u0dd0\u0db8\u0dd2 \u0dbd\u0dd2\u0dba \u0dba\u0db1 \u0d9c\u0db8\u0db1\u0dda \u0db8\u0dd4\u0daf\u0dd4 \u0db6\u0db3 \u0db1\u0dd0\u0dc5\u0dc0\u0dd9\u0db1 \u0dc3\u0dda \u0d9a\u0db3\u0dd4\u0dc0\u0dd0\u0da7\u0dd2 \u0d9c\u0d82\u0d9c\u0dcf \u0dc3\u0dcf\u0d9c\u0dbb \u0d91\u0d9a\u0dc3\u0dda \u0db4\u0ddc\u0dc5\u0ddc\u0dc0\u0da7 \u0dc3\u0db8\u0db6\u0dbb \u0dc0\u0dda \u0db8\u0dda \u0da2\u0dd3\u0dc0\u0db1 \u0d9a\u0dad\u0dbb\u0dda // \u0dc3\u0dd0\u0db4 \u0daf\u0dd4\u0d9a \u0dc3\u0db8\u0db6\u0dbb \u0dc0\u0dda  \u0dc0\u0dd0\u0da9\u0dd2\u0dc0\u0db1 \u0d86\u0dc1\u0dcf \u0db8\u0dd0\u0dac\u0dbd\u0db1 \u0dc0\u0dda\u0d9c\u0dda \u0da2\u0dd3\u0dc0\u0db1 \u0db8\u0d9f \u0d9a\u0dd0\u0dc5\u0db8\u0dda \u0d92\u0d9a\u0db8 \u0dbb\u0dc3\u0db8\u0dd4\u0dc3\u0dd4 \u0dc0\u0dda \u0db8\u0dc4 \u0dc0\u0db1 \u0dc0\u0daf\u0dd4\u0dbd\u0dda \u0dc0\u0db1 \u0dc0\u0dd2\u0dbd\u0dca \u0db8\u0dad\u0dd4\u0dc0\u0dda \u0db4\u0dd2\u0dba\u0dd4\u0db8\u0dca \u0db4\u0dd2\u0db4\u0dd3 \u0db1\u0dd0\u0da7\u0dc0\u0dda \u0db8\u0dda \u0da2\u0dd3\u0dc0\u0db1 \u0d9a\u0dad\u0dbb\u0dda // \u0dc3\u0dd0\u0db4 \u0daf\u0dd4\u0d9a \u0dc3\u0db8\u0db6\u0dbb \u0dc0\u0dda", "title": "\u0d89\u0dbb \u0dc4\u0db3 \u0db4\u0dcf\u0dba\u0db1 \u0dbd\u0ddd\u0d9a\u0dda", "singer": "\u0d85\u0db8\u0dbb\u0daf\u0dda\u0dc0 W.D."}, ....</span></pre><p id="7093" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在您可以在output.json文件中看到类似的内容。</p><p id="7feb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 5。将unicode转换成僧伽罗文字符</strong></p><p id="c828" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">导航到“output.json”文件所在的文件夹。</p><p id="47c9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">编写一个python脚本，将unicodes转换为僧伽罗语字符，并将输出写入一个单独的文件。</p><figure class="kf kg kh ki fd ij"><div class="bz dy l di"><div class="kr ks l"/></div></figure><p id="d28c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">通过在终端上运行<code class="du ka kb kc kd b">python -m unicode_converter</code>命令来执行脚本。</p><p id="290c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在您有了“song_lyrics.json”文件，其内容类似于下面的内容。</p><pre class="kf kg kh ki fd kt kd ku kv aw kw bi"><span id="977e" class="kx ky hi kd b fi kz la l lb lc">[{"song": " කඳුළු කිරි පොවා තුරුලේ සෙනෙහසින් හදා කඳුළු විල දිගේ නොපෙනී ගියාදෝ අම්මා  සත් පියුම් විලේ විල මැද යළි පිපී දිලේ දුටු සඳ දරුවන් වෙත මවකගේ සෙනේ මිහිකත වුව හඬා වැටේ  නිවන් මන් පෙතේ ඔබ  ගිය මන් ලකුණු පෙනේ වඩිනා දා නිවන් පුතු සෙනේ වඩා මා දෙස බලනු මට දැනේ ", "singer": "අමරදේව W.D.", "title": "කඳුළු කිරි පොවා"}, {"song": " ඉර හඳ පායන ලෝකේ ආලෝකය අතරේ සැප දුක සමබර වේ මේ ජීවන කතරේ // සැප දුක සමබර වේ  උකුලේ ළමැදේ සමබර උසුලන ගැමි ලිය යන ගමනේ මුදු බඳ නැළවෙන සේ කඳුවැටි ගංගා සාගර එකසේ පොළොවට සමබර වේ මේ ජීවන කතරේ // සැප දුක සමබර වේ  වැඩිවන ආශා මැඬලන වේගේ ජීවන මඟ කැළමේ ඒකම රසමුසු වේ මහ වන වදුලේ වන විල් මතුවේ පියුම් පිපී නැටවේ මේ ජීවන කතරේ // සැප දුක සමබර වේ", "singer": "අමරදේව W.D.", "title": "ඉර හඳ පායන ලෝකේ"}, ....</span></pre><p id="453d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">凉爽的😎。现在您有了一个丰富的语料库来构建您的信息检索系统。</p></div></div>    
</body>
</html>