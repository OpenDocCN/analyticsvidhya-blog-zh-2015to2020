<html>
<head>
<title>Prediction of the Output Power of a Combined Cycle Power Plant using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于机器学习的联合循环电厂输出功率预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/prediction-of-the-output-power-of-a-combined-cycle-power-plant-using-machine-learning-a2ca01848eea?source=collection_archive---------4-----------------------#2020-07-06">https://medium.com/analytics-vidhya/prediction-of-the-output-power-of-a-combined-cycle-power-plant-using-machine-learning-a2ca01848eea?source=collection_archive---------4-----------------------#2020-07-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1d41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">多元回归的简单介绍</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/bff95b848fa77aba7afec966acaac0c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*U57e7v9P2-QzvPC7"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">杰森·黑眼在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="f1ec" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">背景</h1><p id="53bd" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">单循环燃气轮机发电厂使用天然气和压缩空气发电。空气从周围环境中抽出，压缩，并送入燃气轮机的燃烧室。在这里，天然气被注入，与压缩空气混合并被点燃。燃烧产生的高压热气流流过涡轮，使其旋转(速度极快)。因此，这带动了与涡轮机相连的发电机旋转，从而产生电能。</p><p id="789f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于单循环燃气轮机，大部分能量作为热废气被浪费掉，最多只能达到35%的能量转换效率。联合循环发电厂利用这种低效率，通过使用热回收蒸汽发生器(HRSG)捕获废热，以产生更多的电力。</p><p id="406f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">联合循环发电厂是同时使用燃气轮机和蒸汽轮机发电的发电厂。燃气轮机产生的废热被用于产生蒸汽，该蒸汽被供给蒸汽轮机以产生更多的电力。这增加了同样数量的燃料产生的功率(高达50%以上),以及将工厂的效率提高到约60%。</p><p id="7efc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">联合循环发电厂(CCPP)的输出功率取决于几个参数，即大气压力、排汽压力、环境温度和相对湿度。能够预测满负荷电功率输出对于发电厂的高效和经济运行是重要的。在本文中，我们将使用机器学习来开发一个预测模型，以预测CCPP的满载输出功率。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kx"><img src="../Images/7eb482ce2ee0c0a3ddee3c1be4db7492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vVjcd8BFY0ETPaN6L9T3KA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">联合循环发电厂(来自Planete能源公司，总计)</figcaption></figure><h1 id="d049" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">目标</h1><ol class=""><li id="3ecd" class="ky kz hi ih b ii ks im kt iq la iu lb iy lc jc ld le lf lg bi translated">开发一个预测模型来预测满载功率输出。</li><li id="c2d7" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">评估模型的性能</li></ol><p id="a6ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">提示</strong> : <em class="lm">既然目标是基于一些参数来预测输出功率，这就是一个</em> <strong class="ih hj"> <em class="lm">回归问题。</em> </strong> <em class="lm">回归旨在建立预测因子(帮助我们做出预测的变量)和目标(我们想要预测的值)之间的关系。</em></p><h1 id="274f" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">资料组</h1><p id="d607" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">对于本文，我们将使用Pinar Tufekci提供的数据集，该数据集可在UCI机器学习知识库中获得。该数据集是在六年的时间内收集的，由电厂满负荷运行时收集的9568个数据点组成。</p><p id="ffb5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jt" href="https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant?ref=datanews.io" rel="noopener ugc nofollow" target="_blank">https://archive . ics . UCI . edu/ml/datasets/Combined+Cycle+Power+Plant？ref=datanews.io </a></p><h1 id="2dfb" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">多次回归</h1><p id="3192" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">多元回归是简单线性回归的延伸。它是一种使用多个预测因子或独立变量来预测一个目标变量或结果的建模方法。</p><p id="c876" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">多元回归的一般形式</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/f44a599d4c3eed172b3c40930dabea38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*jP-rylycMlzyCuDGJJJoeQ.png"/></div></figure><h1 id="5c38" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">我们的工作流程</h1><ol class=""><li id="bdb5" class="ky kz hi ih b ii ks im kt iq la iu lb iy lc jc ld le lf lg bi translated">探索性数据分析</li><li id="4ba1" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">开发模型</li><li id="0892" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">评估模型</li><li id="a2dc" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc ld le lf lg bi translated">选择最佳型号</li></ol></div><div class="ab cl lo lp gp lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hb hc hd he hf"><h1 id="4593" class="ju jv hi bd jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr bi translated">1.探索性数据分析</h1><p id="8f7d" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">首先，我们将在导入我们需要的所有python库之后加载数据。</p><blockquote class="ma mb mc"><p id="2121" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">导入熊猫为pd，numpy为np，matplotlib.pyplot为PLT<br/>data = PD . read _ CSV(' CCPP . CSV ')</p><p id="c9c3" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">df = pd。数据帧(数据)</p></blockquote><p id="3ed1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们研究这些数据来感受一下。</p><blockquote class="ma mb mc"><p id="54fc" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">df.info()</p></blockquote><pre class="je jf jg jh fd mg mh mi mj aw mk bi"><span id="9732" class="ml jv hi mh b fi mm mn l mo mp">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 9568 entries, 0 to 9567<br/>Data columns (total 5 columns):<br/>AT    9568 non-null float64<br/>V     9568 non-null float64<br/>AP    9568 non-null float64<br/>RH    9568 non-null float64<br/>PE    9568 non-null float64<br/>dtypes: float64(5)<br/>memory usage: 373.9 K</span></pre><p id="9146" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，这个数据集包含5个数值变量(float64)。所有变量都没有缺失值(9568非空)，数据类型(<em class="lm"> dtypes </em>)是一个浮点数。这当然是个好消息，因为我们有一个干净的数据集。</p><p id="dad1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们看看数据集的分布</p><blockquote class="ma mb mc"><p id="d1fc" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">df.describe()</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/8768a80f8f2a28b53865ebe6d9985a68.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*aSM587ytHvaGS6eAxCxxgw.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">显示平均值、最小值、最大值和标准值的统计细节</figcaption></figure><p id="15a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集由4个小时平均变量或特征以及输出功率(PE)目标变量组成</p><ul class=""><li id="427b" class="ky kz hi ih b ii ij im in iq mr iu ms iy mt jc mu le lf lg bi translated">环境温度(AT)在1.81℃和37.11℃之间，</li><li id="a5ee" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc mu le lf lg bi translated">环境压力(AP)在992.89-1033.30毫巴范围内，</li><li id="1ada" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc mu le lf lg bi translated">相对湿度(RH)在25.56%至100.16%的范围内</li><li id="963c" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc mu le lf lg bi translated">排气真空(V)在25.36–81.56厘米汞柱的范围内</li><li id="c671" class="ky kz hi ih b ii lh im li iq lj iu lk iy ll jc mu le lf lg bi translated">每小时净电能输出(PE)420.26–495.76兆瓦</li></ul><p id="c313" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们已经对数据集有所了解，我们需要确定哪些特征将有助于我们预测输出功率。因为回归的目标是从特征中创建一个数学模型来预测目标变量(PE)，所以我们需要确保我们选择的特征与目标有很强的相关性(高预测能力)。相关矩阵将有助于做到这一点。</p><p id="ba6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">相关矩阵</strong>是一种结构化方法，用于对预测值或输入变量(对输出<em class="lm">影响最大的输入变量)的重要性进行排序。</em>为此，我们使用Seaborn绘制了相关矩阵的热图。</p><blockquote class="ma mb mc"><p id="5a7f" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">将seaborn导入为SNS<br/>PLT . fig(figsize =(7，5)) <br/> sns.heatmap(df.corr()，annot = True)</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/da9b8b8cc31b3914a412aaf950767fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*eKLwD6tx24DMtcPBPE5mQg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">相关矩阵的热图</figcaption></figure><p id="d0db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">提示</strong>:C<em class="lm">or关系在-1到1的范围内测量。-1表示完全负相关，1表示完全正相关。0表示完全没有相关性。</em></p><p id="42af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从相关矩阵中，我们可以看到at和V与目标变量(PE)具有很强的负相关性，因为它们的相关系数分别为-0.95和-0.87。AP和RH与PE呈弱正相关，相关系数分别为0.52和0.39。</p><p id="980b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以将数据集的二元分布可视化(它显示了每个特征如何相互关联以及如何与PE关联)</p><blockquote class="ma mb mc"><p id="38b3" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">SNS . set(style = " ticks ")<br/>SNS . pair plot(df，diag_kind = 'hist ')</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mw"><img src="../Images/6430341c7336544d0c0bde754789e36d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j3LEjd04R3y3LqQrG9ic-Q.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">数据集的二元分布</figcaption></figure><p id="2ae4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当可视化时，我们可以容易地看到在at和V上看到的与PE相关的独特模式(负相关)。</p><p id="f180" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong>你会注意到at和V彼此高度相关。这通常不是一件好事，因为我们的特性应该是相互独立的。这个问题叫做<strong class="ih hj"> <em class="lm">多重共线性。</em> </strong> <em class="lm">解决这个问题的一种方法是选择与我们的目标变量(PE)更密切相关的特征。在这种情况下，将为(-0.95)。在某些情况下，我们可以选择忍受这个问题，并像那样使用我们的功能。</em></p></div><div class="ab cl lo lp gp lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hb hc hd he hf"><h1 id="9336" class="ju jv hi bd jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr bi translated">2.开发模型</h1><p id="222d" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们在这里要做的是使用不同的机器学习算法和不同的特征组合来开发几个回归模型。我决定对这个数据集使用线性回归、决策树回归和随机森林回归算法。</p><h2 id="7c21" class="ml jv hi bd jw mx my mz ka na nb nc ke iq nd ne ki iu nf ng km iy nh ni kq nj bi translated"><strong class="ak">功能选择</strong></h2><p id="ab95" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">机器学习项目成功的一个关键部分是提出一组好的特征或预测器来进行训练。特征选择包括在现有特征中选择最有用的特征进行训练</p><p id="4974" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，让我们创建4种不同的特征组合，并用3种回归算法训练我们的模型</p><p id="18a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型1:我们仅选择处的<strong class="ih hj">作为预测器(因为它与目标变量(PE)具有最强的相关性)</strong></p><blockquote class="ma mb mc"><p id="812c" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">df_1 = df['AT']</p></blockquote><p id="1ca7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型2:我们选择处的<strong class="ih hj">和<strong class="ih hj"> V </strong>作为预测器</strong></p><blockquote class="ma mb mc"><p id="1030" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">df_2 = df[['AT '，' V']]</p></blockquote><p id="fad3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型3:我们选择处的<strong class="ih hj">、<strong class="ih hj"> V </strong>和<strong class="ih hj"> RH </strong>作为预测器</strong></p><blockquote class="ma mb mc"><p id="cfa2" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">df_3 = df[['AT '，' V '，' RH']]</p></blockquote><p id="4e5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型4:我们选择处的<strong class="ih hj">、<strong class="ih hj"> V </strong>、<strong class="ih hj"> AP </strong>和<strong class="ih hj"> RH </strong>作为预测器</strong></p><blockquote class="ma mb mc"><p id="c93b" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">df_4 = df[['AT '，' V '，' AP '，' RH']]</p><p id="f5bb" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated"><strong class="ih hj">备选项</strong> : df_4 = df.drop(['PE']，axis =1)</p></blockquote><p id="8381" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们的目标变量(PE)是y </strong></p><blockquote class="ma mb mc"><p id="b443" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">y = df['PE']</p></blockquote><p id="0f8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经完成了特征选择，是时候训练我们的ML模型了</p><h2 id="33f3" class="ml jv hi bd jw mx my mz ka na nb nc ke iq nd ne ki iu nf ng km iy nh ni kq nj bi translated"><strong class="ak">训练模型</strong></h2><p id="4d4f" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在我们实际训练我们的机器学习模型之前，我们需要首先将我们的数据分成训练和测试集。训练集将用于创建特征和目标变量之间关系的数学模型。测试集将用于验证模型。为此，我们将使用sci-kit学习库并导入<em class="lm"> train_test_split </em>模块。</p><p id="bf19" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将把数据集分成80%的训练集和20%的测试集(<em class="lm">使用帕累托法则</em>)。</p><blockquote class="ma mb mc"><p id="66e3" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">从sklearn.model_selection导入train_test_split <br/> X_train，X_test，y_train，y _ test = train _ test _ split(<strong class="ih hj">df _ 1</strong>，y，test_size = 0.2，random_state = 0)</p></blockquote><p id="6ff5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过用相应的特征数组替换<strong class="ih hj"> <em class="lm"> df_1 </em> </strong>，将对所有其他模型的数据集重复该步骤。比如带<strong class="ih hj"> df_4 </strong>的4型。</p><p id="e4e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们到了激动人心的部分，我们实现了一个回归算法，并开发了我们的预测模型。为此，我们将使用OLS回归、决策树回归和随机森林回归。首先，我们从sci-kit学习库中导入LinearRegression并训练模型。</p><h2 id="663c" class="ml jv hi bd jw mx my mz ka na nb nc ke iq nd ne ki iu nf ng km iy nh ni kq nj bi translated">对于线性回归</h2><blockquote class="ma mb mc"><p id="b552" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">从sklearn.linear_model导入线性回归<br/>regressor = linear regression()<br/>regressor . fit(X _ train，y_train)</p></blockquote><p id="650b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">既然我们已经在我们的训练集上训练了我们的模型，我们准备在我们的测试集上进行预测(我们的模型以前从未见过这个集)</p><blockquote class="ma mb mc"><p id="1dc3" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">y _ pred = regressor . predict(X _ test)</p></blockquote><p id="2ff5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树回归和随机森林回归的代码实现如下所示:</p><h2 id="97c2" class="ml jv hi bd jw mx my mz ka na nb nc ke iq nd ne ki iu nf ng km iy nh ni kq nj bi translated">对于决策树回归</h2><blockquote class="ma mb mc"><p id="5963" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">从sklearn.tree导入决策树回归器<br/>dt _ regressor = DecisionTreeRegressor()<br/>dt _ regressor . fit(X _ train，y_train)</p></blockquote><p id="aab9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了预测</p><blockquote class="ma mb mc"><p id="b401" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">y _ pred = dt _ regressor . predict(X _ test)</p></blockquote><h2 id="26c1" class="ml jv hi bd jw mx my mz ka na nb nc ke iq nd ne ki iu nf ng km iy nh ni kq nj bi translated">对于随机森林回归</h2><blockquote class="ma mb mc"><p id="d3ed" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">从sklearn.ensemble导入RandomForestRegressor<br/>RF _ regressor = RandomForestRegressor()<br/>RF _ regressor . fit(X _ train，y_train)</p></blockquote><p id="9d36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了预测</p><blockquote class="ma mb mc"><p id="1231" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">y _ pred = RF _ regressor . predict(X _ test)</p></blockquote><p id="db1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lm">随机森林是一种集成算法，它在数据集的各种子样本上拟合许多决策树。通过平均每个决策树的预测来进行预测。这提高了预测精度并控制了过度拟合。</em></p><p id="061c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">太棒了。现在，我们已经创建了一个预测模型，并使用它进行预测。是时候评估我们的模型表现如何了</p><h1 id="8e43" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">3.性能赋值</h1><p id="033a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">每当开发机器学习模型时，评估其性能以确保它产生有用的输出而不是过度拟合是很重要的。对于回归问题，有<strong class="ih hj"> 3个关键性能指标</strong>用于评估你的模型表现如何。有</p><ol class=""><li id="9d1a" class="ky kz hi ih b ii ij im in iq mr iu ms iy mt jc ld le lf lg bi translated"><strong class="ih hj">均方根误差(RMSE): </strong>测量模型在预测观察结果时的平均误差。</li></ol><p id="08a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lm">提示:</em></strong><em class="lm">RMSE分数越低越好</em></p><blockquote class="ma mb mc"><p id="6d82" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">从sklearn.metrics导入均方误差<br/> mse =均方误差(y_test，y _ pred)<br/>RMSE = NP . sqrt(MSE)<br/>RMSE</p></blockquote><p id="0a87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。r平方</strong>:它表示目标变量中有多少变化可以用训练模型时使用的一组特征来解释。</p><p id="1366" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lm">提示:</em></strong><em class="lm">R平方分数越高越好</em></p><blockquote class="ma mb mc"><p id="356b" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">从sklearn.metrics导入R2 _ score<br/>r _ squared = R2 _ score(y _ test，y_pred) <br/> r_squared</p></blockquote><p id="c0d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。平均绝对误差</strong>:测量预测值与实际值的差距。</p><p id="bb85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">提示:</strong>MAE值越低越好</p><blockquote class="ma mb mc"><p id="ad27" class="if ig lm ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">从sklearn.metrics导入mean _ absolute _ error<br/>Mae = mean _ absolute _ error(y _ test，y_pred) <br/> mae</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nk"><img src="../Images/ce8cefe04042bac3dce168f61c24758b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AwNF61HwIcZVCw_VVguGQQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">显示学习算法评估指标的表格</figcaption></figure><p id="84ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经评估了所有模型，我们可以看到模型4(所有特征)的随机森林回归算法为我们提供了最佳性能。R平方为0.9644(这意味着目标变量PE的96.44%的变化可以由模型解释)。</p><p id="117b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，它产生的最低RMSE为3.1891。</p><p id="f011" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从我们的结果可以得出结论，应该选择随机森林回归模型4</p><h1 id="7da4" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">尾注</h1><p id="f807" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在本文的开头，我们根据所提供的数据集开发了一个满负载输出功率(PE)的预测模型。我们研究了数据集，以找出我们是否有缺失值或其他问题，然后在3种不同的机器学习回归算法上进行4个特征子集选择。我们能够发现，对随机森林回归算法使用一组完整的参数或特征会产生最佳结果。我们得到了0的R平方。9644和RMSE的3.1891。</p><p id="7234" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望这对你有用。万事如意！</p></div></div>    
</body>
</html>