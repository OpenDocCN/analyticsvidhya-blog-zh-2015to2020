<html>
<head>
<title>Complete Guide to build an AutoEncoder in Pytorch and Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">åœ¨Pytorchå’ŒKerasä¸­æ„å»ºè‡ªåŠ¨ç¼–ç å™¨çš„å®Œæ•´æŒ‡å—</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/analytics-vidhya/complete-guide-to-build-an-autoencoder-in-pytorch-and-keras-94555dce395d?source=collection_archive---------8-----------------------#2020-07-06">https://medium.com/analytics-vidhya/complete-guide-to-build-an-autoencoder-in-pytorch-and-keras-94555dce395d?source=collection_archive---------8-----------------------#2020-07-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="5d83" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘ä¹‹å‰çš„<a class="ae jk" rel="noopener" href="/analytics-vidhya/complete-guide-to-build-cnn-in-pytorch-and-keras-abc9ed8b8160">æ–‡ç« </a>çš„å»¶ç»­ï¼Œè¿™ç¯‡æ–‡ç« æ˜¯ä½¿ç”¨pytorchå’Œkerasæ„å»ºCNNçš„å®Œæ•´æŒ‡å—ã€‚</p><p id="1982" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">ä»æ ‡å‡†æ•°æ®é›†æˆ–è‡ªå®šä¹‰æ•°æ®é›†è·å–è¾“å…¥å·²ç»åœ¨<a class="ae jk" rel="noopener" href="/analytics-vidhya/complete-guide-to-build-cnn-in-pytorch-and-keras-abc9ed8b8160">ä½¿ç”¨pytorchå’Œkerasçš„CNNå®Œå…¨æŒ‡å—</a>ä¸­æåˆ°ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä»å¯¹è‡ªåŠ¨ç¼–ç å™¨çš„å¿…è¦ä»‹ç»å¼€å§‹ï¼Œç„¶åå®ç°ä¸€ä¸ªã€‚</p><h2 id="2799" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">è‡ªåŠ¨ç¼–ç å™¨</h2><p id="ddc1" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">è‡ªåŠ¨ç¼–ç å™¨æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œï¼Œå®ƒå­¦ä¹ ä»¥æœ€å°çš„ä¿¡æ¯æŸå¤±å¯¹æ•°æ®è¿›è¡Œç¼–ç ã€‚</p><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es kl"><img src="../Images/4c06d6623ca8552a7d249af453aa4b4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cFvChxqTd39zvZYb_VDeuQ.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">è‡ªåŠ¨ç¼–ç å™¨</figcaption></figure><p id="0218" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">ä¸Šè¿°ç½‘ç»œæœ‰è®¸å¤šå˜ä½“ã€‚å…¶ä¸­ä¸€äº›æ˜¯:</p><h2 id="5d4a" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨</h2><p id="7072" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">è¿™ç§è‡ªåŠ¨ç¼–ç å™¨é€šè¿‡æ­£åˆ™åŒ–æ¿€æ´»å‡½æ•°éšè—èŠ‚ç‚¹æ¥å‡å°‘è¿‡æ‹Ÿåˆã€‚</p><h2 id="7785" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">é™å™ªè‡ªåŠ¨ç¼–ç å™¨</h2><p id="cdce" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">è¿™ä¸ªè‡ªåŠ¨ç¼–ç å™¨æ˜¯é€šè¿‡åœ¨è¾“å…¥ä¸­åŠ å…¥å™ªå£°æ¥è®­ç»ƒçš„ã€‚è¿™å°†æ¶ˆé™¤è¯„ä¼°æ—¶è¾“å…¥çš„å™ªå£°ã€‚</p><h2 id="cd6d" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">å˜ä½“è‡ªåŠ¨ç¼–ç å™¨</h2><p id="6f34" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">è¿™æ˜¯ä¸€ç§æ·±åº¦ç”Ÿæˆç¥ç»ç½‘ç»œã€‚è‡ªåŠ¨ç¼–ç å™¨çš„ä¸»è¦æŒ‘æˆ˜æ˜¯å®ƒä»¬æ€»æ˜¯è¯•å›¾æœ€å°åŒ–é‡å»ºè¯¯å·®ï¼Œå¹¶ä¸”ä»ä¸å…³å¿ƒæ½œåœ¨çš„è¡¨ç¤ºã€‚</p><p id="7b20" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">ä¸€ä¸ªå¥½çš„æ½œåœ¨è¡¨ç¤ºåº”è¯¥æ€»æ˜¯æœ‰æ„ä¹‰çš„ï¼Œä»¥ä¾¿å®ƒå¯ä»¥ç”¨äºåƒGANè¿™æ ·çš„ç”Ÿæˆç¥ç»ç½‘ç»œã€‚æœ‰æ„ä¹‰æ˜¯æŒ‡å®‰æ’ã€‚æ¥è‡ªåŒä¸€ç±»çš„æ•°æ®ç‚¹åˆ†ç»„æ›´è¿‘ï¼Œæ¥è‡ªä¸åŒç±»çš„æ•°æ®ç‚¹åˆ†ç»„ç¨è¿œã€‚</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es lb"><img src="../Images/160b20692089a71a9a579caadfc3c187.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*nNULTP48_LQgKSYLB-wV6Q.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">ã€https://blog.keras.io/building-autoencoders-in-keras.html T4ã€‘</figcaption></figure><p id="cc99" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">è¿™ç§æ½œåœ¨è¡¨ç¤ºå¯ä»¥é€šè¿‡å¦‚ä¸‹æ”¹å˜ç¥ç»ç½‘ç»œçš„ç»“æ„æ¥å®ç°:</p><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es lc"><img src="../Images/cad657f3565d83359a697b16776f3037.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*drAHNZvlSr-bB4V5XAhzzw.png"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">VAE</figcaption></figure><p id="b9d7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">ä¸å…¶ä»–è‡ªåŠ¨ç¼–ç å™¨ä¸åŒï¼Œæˆ‘ä»¬æ­£åœ¨ç”Ÿæˆä¸€ä¸ªå…·æœ‰å‡å€¼å’Œæ ‡å‡†å·®çš„æ½œåœ¨åˆ†å¸ƒï¼Œè€Œä¸æ˜¯å•ä¸€çš„æ½œåœ¨å‘é‡ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ä»æ½œåœ¨åˆ†å¸ƒä¸­å–æ ·ä»¥é‡å»ºè¾“å…¥ã€‚</p><p id="a7c1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">å…³äºå˜ä½“è‡ªåŠ¨ç¼–ç å™¨çš„ä¸¤ä»¶é‡è¦äº‹æƒ…æ˜¯:</p><p id="9154" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">åœ¨é‡‡æ ·æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨é‡æ–°å‚æ•°åŒ–æŠ€å·§æ¥å¤„ç†èŠ‚ç‚¹çš„éšæœºæ€§ï¼Œå› ä¸ºèŠ‚ç‚¹çš„éšæœºæ€§å¯èƒ½ä¼šåœæ­¢åå‘ä¼ æ’­ã€‚</p><blockquote class="ld le lf"><p id="55ce" class="im in lg io b ip iq ir is it iu iv iw lh iy iz ja li jc jd je lj jg jh ji jj hb bi translated">Î¼,ğ›”â‰ˆÎ¼+ğ›”*n(0,1)</p></blockquote><p id="0ca9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">è¿™ç§é‡æ–°å‚æ•°åŒ–çš„æŠ€å·§ä¸ä¼šæ”¹å˜åˆ†å¸ƒã€‚ä½†æ˜¯å®ƒå°†è°ƒæ•´å‚æ•°ä»¥å…è®¸åå‘ä¼ æ’­ã€‚</p><p id="2afe" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">å˜åŒ–è‡ªåŠ¨ç¼–ç å™¨ä½¿ç”¨ä¸‹é¢çš„ç­‰å¼æ­£åˆ™åŒ–æˆæœ¬å‡½æ•°ã€‚</p><blockquote class="ld le lf"><p id="d00e" class="im in lg io b ip iq ir is it iu iv iw lh iy iz ja li jc jd je lj jg jh ji jj hb bi translated">æ­£åˆ™åŒ–æˆæœ¬å‡½æ•°= Loss+KL(N(Î¼,ğ›”),N(0,1))</p></blockquote><p id="ccad" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">è¿™å°†å¼ºåˆ¶æ½œåœ¨åˆ†å¸ƒéµå¾ªæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œä»è€Œæ‰©å±•å…¶åœ¨æ·±åº¦ç”Ÿæˆæ¨¡å‹ä¸­çš„ä½¿ç”¨ã€‚</p><p id="594b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">ä½ å¯ä»¥åœ¨è¿™ç¯‡<a class="ae jk" href="https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73" rel="noopener" target="_blank">æ–‡ç« </a>ä¸­è¯»åˆ°æ›´å¤šå…³äºVAEçš„ä¿¡æ¯ï¼Œåœ¨è¿™é‡Œä½ å¯ä»¥è¯»åˆ°æ›´å¤šå…³äºå„ç§ç±»å‹çš„è‡ªåŠ¨ç¼–ç å™¨çš„ä¿¡æ¯ã€‚æˆ‘ä»¬å°†åœ¨æœ¬æ–‡ä¸­å®ç°VAEã€‚</p><h1 id="ced4" class="lk jm hi bd jn ll lm ln jr lo lp lq jv lr ls lt jy lu lv lw kb lx ly lz ke ma bi translated">å±¥è¡Œ</h1><p id="e53d" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">ä»»ä½•è‡ªåŠ¨ç¼–ç å™¨éƒ½åŒ…æ‹¬ä¸¤ä¸ªç½‘ç»œç¼–ç å™¨å’Œè§£ç å™¨ã€‚å¦‚å‰æ‰€è¿°ï¼ŒVAEä¹Ÿä½¿ç”¨è§„åˆ™åŒ–æˆæœ¬å‡½æ•°ã€‚</p><h2 id="4236" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">ç¼–ç å™¨</h2><p id="db29" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">ç¼–ç å™¨æ¥å—è¾“å…¥å¹¶è¿”å›æ½œåœ¨åˆ†å¸ƒçš„å¹³å‡å€¼å’Œæ ‡å‡†åå·®ã€‚</p><pre class="km kn ko kp fd mb mc md me aw mf bi"><span id="e96e" class="jl jm hi mc b fi mg mh l mi mj">#<strong class="mc hj">Pytorch</strong></span><span id="a7e1" class="jl jm hi mc b fi mk mh l mi mj"><strong class="mc hj">class</strong> <strong class="mc hj">VAE</strong>(nn.Module):<br/>    <strong class="mc hj">def</strong> __init__(self, x, h1, h2, z):<br/>        super(VAE, self).__init__()<br/>        <br/>        <br/>        self.fc1 = nn.Linear(x, h)<br/>        self.fc2 = nn.Linear(h1, h2)<br/>        self.fc_mean = nn.Linear(h2, z)<br/>        self.fc_sd = nn.Linear(h2, z)<br/>        <br/>      <br/>        <br/>    <strong class="mc hj">def</strong> encoder(self, x):<br/>        h1 = F.relu(self.fc1(x))<br/>        h2 = F.relu(self.fc2(h1))<br/>        <strong class="mc hj">return</strong> self.fc_mean(h2), self.fc_sd(h2) <em class="lg"># mu, log_var</em></span><span id="39f9" class="jl jm hi mc b fi mk mh l mi mj">#<strong class="mc hj">Keras</strong></span><span id="7da1" class="jl jm hi mc b fi mk mh l mi mj">x = Input(batch_shape=(batch_size, original_dim))<br/>h = Dense(intermediate_dim, activation='relu')(x)<br/>z_mean = Dense(latent_dim)(h)<br/>z_log_sigma = Dense(latent_dim)(h)<br/></span></pre><h2 id="5a19" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">æŠ½æ ·</h2><p id="09e5" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">æ ¹æ®ä»ç¼–ç å™¨è·å¾—çš„å¹³å‡å€¼å’Œæ ‡å‡†åå·®ï¼Œæˆ‘ä»¬å°†é€šè¿‡é‡‡æ ·ç”Ÿæˆè§£ç å™¨çš„è¾“å…¥ã€‚ä¸Šé¢æåˆ°çš„é‡æ–°å‚æ•°åŒ–æŠ€å·§å‡ºç°åœ¨è¿™é‡Œã€‚</p><pre class="km kn ko kp fd mb mc md me aw mf bi"><span id="0681" class="jl jm hi mc b fi mg mh l mi mj"><strong class="mc hj">#Pytorch</strong></span><span id="be2a" class="jl jm hi mc b fi mk mh l mi mj">def sampling(self, mu, log_var):<br/>        std = torch.exp(0.5*log_var)<br/>        eps = torch.randn_like(std)<br/>        <strong class="mc hj">return</strong> eps.mul(std).add_(mu)</span><span id="7939" class="jl jm hi mc b fi mk mh l mi mj"><br/>#<strong class="mc hj">Keras</strong></span><span id="e115" class="jl jm hi mc b fi mk mh l mi mj">def sampling(args):<br/>    z_mean, z_log_sigma = args<br/>    epsilon = K.random_normal(shape=(batch_size, latent_dim),<br/>                              mean=0., std=epsilon_std)<br/>    return z_mean + K.exp(z_log_sigma) * epsilon</span></pre><h2 id="6240" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">è§£ç å™¨</h2><p id="2cd1" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">è§£ç å™¨è·å–é‡‡æ ·å‡½æ•°çš„è¾“å‡ºï¼Œå¹¶å°è¯•é‡å»ºåŸå§‹è¾“å…¥ã€‚</p><pre class="km kn ko kp fd mb mc md me aw mf bi"><span id="3dfd" class="jl jm hi mc b fi mg mh l mi mj"><strong class="mc hj">#Pytorch</strong></span><span id="7199" class="jl jm hi mc b fi mk mh l mi mj"><strong class="mc hj">class</strong> <strong class="mc hj">VAE</strong>(nn.Module):<br/>    <strong class="mc hj">def</strong> __init__(self, x, h1, h2, z):<br/>        super(VAE, self).__init__()<br/>        self.fc1 = nn.Linear(x, h1)<br/>        self.fc2 = nn.Linear(h1, h2)<br/>        self.fc_mean = nn.Linear(h2, z)<br/>        self.fc_sd = nn.Linear(h2, z)<br/>        <em class="lg"># decoder </em><br/>        self.fc4 = nn.Linear(z, h2)<br/>        self.fc5 = nn.Linear(h2, h1)<br/>        self.fc6 = nn.Linear(h1, x)<br/>    <br/>    <strong class="mc hj">def</strong> decoder(self, z):<br/>        h1 = F.relu(self.fc4(z))<br/>        h2 = F.relu(self.fc5(h1))<br/>        <strong class="mc hj">return</strong> F.sigmoid(self.fc6(h2))</span><span id="7c5c" class="jl jm hi mc b fi mk mh l mi mj">#<strong class="mc hj">Keras</strong></span><span id="d231" class="jl jm hi mc b fi mk mh l mi mj">decoder_h = Dense(intermediate_dim, activation='relu')<br/>decoder_mean = Dense(original_dim, activation='sigmoid')<br/>h_decoded = decoder_h(z)<br/>x_decoded_mean = decoder_mean(h_decoded)</span></pre><h2 id="03ae" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">æŸå¤±å‡½æ•°</h2><p id="958a" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">å¦‚å‰æ‰€è¿°ï¼ŒVAEä½¿ç”¨æ­£åˆ™åŒ–æŸå¤±å‡½æ•°ï¼Œ</p><p id="177b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">å…·æœ‰å‡å€¼Î¼iå’Œæ ‡å‡†åå·®ğ›”içš„åˆ†å¸ƒçš„KLæ•£åº¦å…·æœ‰æ ‡å‡†æ­£æ€åˆ†å¸ƒ(KL(N(Î¼i,ğœI),N(0,1))æ˜¯</p><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es ml"><img src="../Images/2f9c6fad3459b31d22e7397213724b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*JzhXZdyuChm_jOCtSNv5gQ.png"/></div></figure><pre class="km kn ko kp fd mb mc md me aw mf bi"><span id="7f06" class="jl jm hi mc b fi mg mh l mi mj"><strong class="mc hj">#Pytorch</strong></span><span id="0f1a" class="jl jm hi mc b fi mk mh l mi mj"><strong class="mc hj">def</strong> loss_function(reconstructed_x, x, mu, log_var):<br/>    loss = F.binary_cross_entropy(reconstructed_x, x.view(-1, 784),      <br/>                       reduction='sum')<br/>    regularized_term = -0.5 * torch.sum(1 + log_var - mu.pow(2) -   <br/>                      log_var.exp())<br/>    <br/>    <strong class="mc hj">return</strong> loss + regularized_term</span><span id="70e5" class="jl jm hi mc b fi mk mh l mi mj"><strong class="mc hj">#Keras</strong></span><span id="7e54" class="jl jm hi mc b fi mk mh l mi mj">def vae_loss(x, x_decoded_mean):<br/>    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)<br/>    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - <br/>                 K.exp(z_log_sigma), axis=-1)<br/>    return xent_loss + kl_loss</span></pre><h2 id="fec8" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">æ•°æ®æµåŠ¨</h2><p id="5880" class="pw-post-body-paragraph im in hi io b ip kg ir is it kh iv iw ix ki iz ja jb kj jd je jf kk jh ji jj hb bi translated">æ•°æ®ä»ç¼–ç å™¨ã€é‡‡æ ·å¼€å§‹ï¼Œç„¶åæ˜¯è§£ç å™¨ã€‚</p><pre class="km kn ko kp fd mb mc md me aw mf bi"><span id="7a56" class="jl jm hi mc b fi mg mh l mi mj"><strong class="mc hj">#Pytorch</strong></span><span id="a48b" class="jl jm hi mc b fi mk mh l mi mj">def forward(self, x):<br/>        mu, log_var = self.encoder(x.view(-1, 784))<br/>        z = self.sampling(mu, log_var)<br/>        <strong class="mc hj">return</strong> self.decoder(z), mu, log_var</span></pre><p id="da66" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">åœ¨kerasä¸­ï¼Œä¸éœ€è¦è½¬å‘å‡½æ•°ã€‚æ•°æ®å°†æŒ‰ç…§ä½ å»ºç«‹ç½‘ç»œæ¨¡å‹çš„é¡ºåºæµåŠ¨ã€‚</p><p id="4276" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">ç”¨æŸå¤±å‡½æ•°ç¼–åˆ¶ç½‘ç»œã€‚</p><pre class="km kn ko kp fd mb mc md me aw mf bi"><span id="81f8" class="jl jm hi mc b fi mg mh l mi mj">#<strong class="mc hj">Pytorch</strong></span><span id="3f6b" class="jl jm hi mc b fi mk mh l mi mj">vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)<br/>latent, mu, log_var = vae(data)<br/>loss = loss_function(latent, data, mu, log_var)<br/>        <br/>loss.backward()<br/> <br/>optimizer.step()</span><span id="f8de" class="jl jm hi mc b fi mk mh l mi mj"><strong class="mc hj">#Keras</strong></span><span id="7d62" class="jl jm hi mc b fi mk mh l mi mj">vae = Model(x, x_decoded_mean)</span><span id="8fc0" class="jl jm hi mc b fi mk mh l mi mj">vae.compile(optimizer='rmsprop', loss=vae_loss)</span></pre><p id="d557" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">æˆ‘ä»¬è¿˜å°†åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­æ‰“åŒ…pytorchå’Œkerasä¸­GANçš„å®ç°ã€‚</p><p id="4071" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">æ„Ÿè°¢é˜…è¯»:)</p><h2 id="40a7" class="jl jm hi bd jn jo jp jq jr js jt ju jv ix jw jx jy jb jz ka kb jf kc kd ke kf bi translated">å‚è€ƒ</h2><div class="mm mn ez fb mo mp"><a href="https://blog.keras.io/building-autoencoders-in-keras.html" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab dw"><div class="mr ab ms cl cj mt"><h2 class="bd hj fi z dy mu ea eb mv ed ef hh bi translated">åœ¨Kerasä¸­æ„å»ºè‡ªåŠ¨ç¼–ç å™¨</h2><div class="mw l"><h3 class="bd b fi z dy mu ea eb mv ed ef dx translated">åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å›ç­”ä¸€äº›å…³äºè‡ªåŠ¨ç¼–ç å™¨çš„å¸¸è§é—®é¢˜ï¼Œæˆ‘ä»¬å°†æ¶µç›–ä»£ç çš„ä¾‹å­â€¦</h3></div><div class="mx l"><p class="bd b fp z dy mu ea eb mv ed ef dx translated">blog.keras.io</p></div></div><div class="my l"><div class="mz l na nb nc my nd kv mp"/></div></div></a></div></div></div>    
</body>
</html>