<html>
<head>
<title>The Concept of Error Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">误差分析的概念</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-the-concept-of-error-analysis-7e8ec3fee398?source=collection_archive---------4-----------------------#2020-02-19">https://medium.com/analytics-vidhya/understanding-the-concept-of-error-analysis-7e8ec3fee398?source=collection_archive---------4-----------------------#2020-02-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8b2b0b9ea30b9eb999d85d37fe4a0e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F46qrBSaCDXDLSd1io4ypw.jpeg"/></div></div></figure><p id="8f5c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您正开始处理机器学习问题或构建机器学习应用程序，从一个可以快速实现并使用验证数据集测试的简单算法开始总是被认为是最佳实践</p><p id="94f0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">绘制学习曲线、错误分析，即手动查看错误(验证数据集中简单算法无法正常工作的示例)以获得更多见解。</p><p id="0f77" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在错误分析的帮助下，你可以尝试不同的想法，并交叉检查它们是否在改进你的应用程序。</p><p id="026d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果数据集由倾斜的类组成，那么仅使用分类精度很难得出任何具体的结论</p><p id="6495" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">即使我们有非常倾斜的类，通过使用精度和召回，我们将更好地了解学习算法是如何做的。与仅使用分类准确度相比，精确度和召回率通常是对学习算法性能的更好的评估</p><p id="4293" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们考虑一个包含两个类的数据集</p><ul class=""><li id="8d5a" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">甲级</li><li id="fa8e" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">B级</li></ul><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es kc"><img src="../Images/026166e7524d102c724dbb6884767503.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*ZkAGFpioGX2NSG8ZLOxTiQ.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">验证数据集由验证数据集的10个样本混淆矩阵组成</figcaption></figure><p id="274f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，将类A视为正类:</p><p id="8208" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">真阳性</strong>:样本的预测结果为阳性类别，样本的实际类别也为阳性类别</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es kl"><img src="../Images/11a1adc073dd978254b20f67c5fedde5.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*VLyO4UqAUTcf8FaomJ_b1w.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">相对于A级的真阳性</figcaption></figure><p id="a886" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">真阴性</strong>:样本的预测结果为阴性类别，样本的实际类别也为阴性类别</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es km"><img src="../Images/a61eeb68a0f84fe326d9734aa26be8a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*M-bSUFcE4WNpzZ7x_6LVpA.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">相对于A级的真底片</figcaption></figure><p id="5a0a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阳性</strong>:样本的预测结果为正类，样本的实际类为负类</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/f32d1ca47b266bf773d6303e2cc005e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*97MOKBaHaezF_BEIFYa_9w.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">与A级相关的误报</figcaption></figure><p id="48b0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阴性</strong>:样本的预测结果为阴性类别，样本的实际类别为阳性类别</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es ko"><img src="../Images/a6dfcad6a107ca57aa47873eefa67dd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*o--362jdanBzcMZpz3Xpew.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">与A级相关的假阴性</figcaption></figure><h1 id="176b" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">什么是精准？</h1><p id="f72c" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">在我们预测它们属于特定类别(y_pred=A)的所有验证记录中，我们通过我们的学习算法预测属于类别A的验证记录的百分比是属于类别A的</p><p id="97b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">换句话说，精度是模型预测的所有阳性中真正阳性的比例</p><p id="66ec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">属于类别A的预测样本数量= 6 =学习算法预测的阳性数量</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/b55f01da7b2ab53549a9eddf070c608f.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*qDjpyqUiZK-gNCmN3_9jxA.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">A级全部阳性</figcaption></figure><p id="5f6d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">属于类别A的预测样本的数量属于类别A = 2 =类别A的真阳性</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/fb343098dc1e5dae9d6947336975521d.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*eyWswMIejLRt6ux3136PhQ.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">A级真阳性</figcaption></figure><blockquote class="lu lv lw"><p id="ce16" class="iq ir lx is b it iu iv iw ix iy iz ja ly jc jd je lz jg jh ji ma jk jl jm jn hb bi translated">精确度=真阳性/所有阳性</p><p id="de25" class="iq ir lx is b it iu iv iw ix iy iz ja ly jc jd je lz jg jh ji ma jk jl jm jn hb bi translated">所有阳性=真阳性+假阳性</p><p id="d9a5" class="iq ir lx is b it iu iv iw ix iy iz ja ly jc jd je lz jg jh ji ma jk jl jm jn hb bi translated">精度= TP/(TP + FP)</p></blockquote><blockquote class="mb"><p id="19e0" class="mc md hi bd me mf mg mh mi mj mk jn dx translated">精度= 2 / (2+4) = 2/6 = 0.33</p></blockquote><h1 id="6364" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la ml lc ld le mm lg lh li mn lk ll lm bi translated">什么是召回？</h1><p id="d79b" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">在属于特定类别(y_true = A)的所有验证记录中，我们的学习算法正确预测了属于类别A的验证记录的比例。</p><p id="c093" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">换句话说，回忆是所有实际值中真正肯定的部分</p><p id="9df4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">属于A类的验证样本数量= 3</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/d950b3a8f488d201539bb505195e462e.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*ZH01ywicgwQiwqOT0UgzQg.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">A类的实际值</figcaption></figure><p id="851a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">属于A类的预测结果的数量= 2 =类的真阳性</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/fb343098dc1e5dae9d6947336975521d.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*eyWswMIejLRt6ux3136PhQ.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">A级真阳性</figcaption></figure><blockquote class="lu lv lw"><p id="c4e5" class="iq ir lx is b it iu iv iw ix iy iz ja ly jc jd je lz jg jh ji ma jk jl jm jn hb bi translated">回忆=真阳性/所有实际值</p><p id="c0d6" class="iq ir lx is b it iu iv iw ix iy iz ja ly jc jd je lz jg jh ji ma jk jl jm jn hb bi translated">所有实际值=真阳性+假阴性</p><p id="3c43" class="iq ir lx is b it iu iv iw ix iy iz ja ly jc jd je lz jg jh ji ma jk jl jm jn hb bi translated">召回= TP/(TP+FN)</p></blockquote><blockquote class="mb"><p id="373e" class="mc md hi bd me mf mg mh mi mj mk jn dx translated">回忆= 2/(2+1) = 2/3 = 0.66</p></blockquote><h1 id="db21" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la ml lc ld le mm lg lh li mn lk ll lm bi translated">f1-得分(权衡精确度和召回率)</h1><p id="8144" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">想象一下，我们有5种不同的学习算法，每种学习算法都给出精度和召回数量</p><p id="5fb2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">比较不同的学习算法并使用单个实数评估度量找到最佳算法要容易和有效得多。</p><p id="479c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">F1-Score是一个单一的实数评估指标，通过权衡精确度和召回率来生成。</p><blockquote class="lu lv lw"><p id="bd61" class="iq ir lx is b it iu iv iw ix iy iz ja ly jc jd je lz jg jh ji ma jk jl jm jn hb bi translated"><strong class="is hj">F1-得分=(2 *精度*召回)/(精度+召回)</strong></p></blockquote><p id="ded4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们数据集的F1分数由A类和B类组成</p><blockquote class="mb"><p id="e38c" class="mc md hi bd me mf mp mq mr ms mt jn dx translated">f1-得分=(2 * 0.33 * 0.66)/(0.33+0.66)= 0.455</p></blockquote><p id="eefa" class="pw-post-body-paragraph iq ir hi is b it mu iv iw ix mv iz ja jb mw jd je jf mx jh ji jj my jl jm jn hb bi translated">现在我们用一个例子来探究我们讨论过的所有概念。</p><p id="4210" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将使用UCI机器学习库中的垃圾短信收集数据集</p><p id="9ef5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将使用两种不同的机器学习算法，逻辑回归和决策树，并在精确度和召回率的帮助下找出哪种效果更好</p><p id="31b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据集中的样本数</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mz"><img src="../Images/650c7dcbb90532496c93913704a77718.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*ms-fic4l4AV4ZCc9JS6Jcw.png"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">数据集大小</figcaption></figure><p id="2b44" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练数据集和测试数据集中的样本数</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es na"><img src="../Images/e968402628c6c8066fa231673c77b86c.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*_8Ki3WMVb1WzIf5CUX8KDw.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">训练集和测试集</figcaption></figure><p id="bf2b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">学习算法1:简单逻辑回归</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/699026f7ae105909786bb476301570e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*XaaQvkO1F7dctxzxHBS8AQ.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">逻辑回归</figcaption></figure><p id="3434" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">学习算法2:简单决策树</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/60145fd36f907f207201e9a5fcf6beea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*iW79m9KlrfP59Tc4X9g55g.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">决策图表</figcaption></figure><p id="6074" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">基于逻辑回归预测结果的混淆矩阵</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/be6dc8c42858cdfdcc77a915e74723d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:250/format:webp/1*P1UWper2be1Sx0JhKMMQZA.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">使用逻辑回归的验证集混淆矩阵</figcaption></figure><p id="0e67" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">基于决策树预测结果的混淆矩阵</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es ne"><img src="../Images/e6d248b8e975242985bd36efdb3d9e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*JwB6521KLO6YCTQ6Av33Ng.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">决策树验证集的混淆矩阵</figcaption></figure><p id="8389" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">分类报告，包括使用逻辑回归学习算法对数据集中存在的每个类的精确召回</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es nf"><img src="../Images/3559a56d7df1786c6b8e571e229e054d.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*xb1Rt03UMsEJV88bk6QM5Q.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">使用逻辑回归的验证集的分类报告</figcaption></figure><p id="cb3f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">分类报告，包括使用决策树学习算法对数据集中存在的每个类的精确召回</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es ng"><img src="../Images/a6030d5ba0b9adb54aa0dd13ca7af8f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*q0pX1DEvbXBOnyRM4IVT0A.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">使用决策树的验证集分类报告</figcaption></figure><p id="8095" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因为数据是偏斜的(类0由1206个样本组成，类1由187个样本组成)</p><p id="282e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">逻辑回归学习算法的宏观平均f1分数优于决策树。</p><p id="f3e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在宏观平均f1分数的帮助下，我们可以得出结论，在数据集上，逻辑回归比决策树表现得更好。</p><h1 id="546f" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">宏观平均和加权平均有什么区别？</h1><p id="2dae" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">考虑决策树分类器分类报告的精度</p><h2 id="7fb8" class="nh kq hi bd kr ni nj nk kv nl nm nn kz jb no np ld jf nq nr lh jj ns nt ll nu bi translated">计算宏观平均值</h2><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es nv"><img src="../Images/f3b52a03c6e2a6b621b9629f50633065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*YCpYhbtlsoQ_8aX_nKFoUQ.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">决策树分类报告的精度</figcaption></figure><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es nw"><img src="../Images/b854062b9828eb145c6cf0cd6bce9d06.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*zWKxvY_WrDAw-49cpE8c1g.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">宏观平均计算</figcaption></figure><h2 id="8caa" class="nh kq hi bd kr ni nj nk kv nl nm nn kz jb no np ld jf nq nr lh jj ns nt ll nu bi translated">计算加权平均值</h2><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nx"><img src="../Images/39120f805969f52eab0376f0f6164482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3tnsVgfc5bEmVcjsDZ0vyw.png"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">决策树分类报告的精度</figcaption></figure><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es ny"><img src="../Images/1ed823caf6c5c83d35617a22b5aa8806.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*6FWAanNjmA4Hdix6cX0LVA.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">加权精度</figcaption></figure><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es nz"><img src="../Images/744c82fe16e32cd05344c7d741e4d3bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*jr8ZKtzDMkJVqDMO7bIlpg.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">加权平均值</figcaption></figure><h1 id="d5fa" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">结论</h1><p id="7406" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">在本文中，我们讨论了精度、召回以及它们的行为方式。我们讨论了混淆矩阵、加权平均和宏观平均。</p><p id="d8c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="lx">你会在</em> <a class="ae oa" href="https://github.com/ambatiashok60/Deep-Learning/tree/master/Error%20Analysis" rel="noopener ugc nofollow" target="_blank"> <em class="lx"> GitHub </em> </a>找到与我们讨论相关的完整代码和数据文件</p><p id="a25d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">关于错误分析的更多参考和例子，请查看<a class="ae oa" href="https://neptune.ai/blog/deep-dive-into-error-analysis-and-model-debugging-in-machine-learning-and-deep-learning" rel="noopener ugc nofollow" target="_blank"> <em class="lx">错误分析和模型调试</em> </a></p><h1 id="ddc1" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">资源</h1><p id="888c" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated"><a class="ae oa" href="https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection</a>本次讨论中使用的数据集</p></div></div>    
</body>
</html>