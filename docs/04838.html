<html>
<head>
<title>How to edit the image stream for video chat, teams, zoom. Part 3 Convert to Anime</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何编辑视频聊天，团队，缩放的图像流。第三部分转化为动漫</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-edit-the-image-stream-for-video-chat-teams-zoom-part-3-convert-to-anime-84a6788819d2?source=collection_archive---------10-----------------------#2020-04-02">https://medium.com/analytics-vidhya/how-to-edit-the-image-stream-for-video-chat-teams-zoom-part-3-convert-to-anime-84a6788819d2?source=collection_archive---------10-----------------------#2020-04-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="14a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章也可以在这里找到。(日文)<br/><a class="ae jd" href="https://cloud.flect.co.jp/entry/2020/04/02/114756#f-459f23dc" rel="noopener ugc nofollow" target="_blank">https://cloud . flext . co . jp/entry/2020/04/02/114756 # f-459 f23 DC</a></p><p id="a1f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我以前的文章中，我向你展示了如何处理你的团队和变焦相机图像。在这些帖子中，我们向您展示了一个检测微笑和情绪(面部表情)并显示笑脸符号的演示。</p><div class="je jf ez fb jg jh"><a rel="noopener follow" target="_blank" href="/@dannadori/how-to-edit-the-image-stream-for-video-chat-teams-zoom-part-2-emotion-analysis-by-tensorflow-819563f17dfe"><div class="ji ab dw"><div class="jj ab jk cl cj jl"><h2 class="bd hj fi z dy jm ea eb jn ed ef hh bi translated">如何编辑视频聊天，团队，缩放的图像流。第二部分Tensorflow情感分析</h2><div class="jo l"><h3 class="bd b fi z dy jm ea eb jn ed ef dx translated">这篇文章也可以在这里找到。(日语)https://cloud.flect.co.jp/entry/2020/04/01/201158</h3></div><div class="jp l"><p class="bd b fp z dy jm ea eb jn ed ef dx translated">medium.com</p></div></div><div class="jq l"><div class="jr l js jt ju jq jv jw jh"/></div></div></a></div><div class="je jf ez fb jg jh"><a rel="noopener follow" target="_blank" href="/@dannadori/how-to-edit-the-image-stream-for-video-chat-teams-zoom-3acb58669f26"><div class="ji ab dw"><div class="jj ab jk cl cj jl"><h2 class="bd hj fi z dy jm ea eb jn ed ef hh bi translated">如何编辑视频聊天、团队、缩放的图像流</h2><div class="jo l"><h3 class="bd b fi z dy jm ea eb jn ed ef dx translated">这篇原创文章也可以在这里找到。https://cloud.flect.co.jp/entry/2020/03/31/162537</h3></div><div class="jp l"><p class="bd b fp z dy jm ea eb jn ed ef dx translated">medium.com</p></div></div><div class="jq l"><div class="jx l js jt ju jq jv jw jh"/></div></div></a></div><p id="2f71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一次，我将它扩展了一点，并尝试将一个图像转换成动画风格的显示，这就是它。首先，我要给你一个剧透，我认为由于滞后，很难使用CPU实时转换成动漫风格的图像。(我没有在GPU上试过，看是不是更好。)</p><p id="02a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">-&gt;我试过GPU！https://www.youtube.com/watch?v=Rw2DcUk4k-Y<br/>T4&amp;feature = youtu . be</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es jy"><img src="../Images/18c6de0a06b4c976a21eb411376fd457.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/1*Zv_LnMG0d_zvqMT_sOHK0g.gif"/></div></figure><ul class=""><li id="a7d4" class="kf kg hi ih b ii ij im in iq kh iu ki iy kj jc kk kl km kn bi translated">左上角:CPU英特尔4770</li><li id="c5d4" class="kf kg hi ih b ii ko im kp iq kq iu kr iy ks jc kk kl km kn bi translated">右上:CPU英特尔9900KF</li><li id="77f6" class="kf kg hi ih b ii ko im kp iq kq iu kr iy ks jc kk kl km kn bi translated">左下方:采用GPU 2080ti的英特尔9900 KF CPU</li><li id="9c4e" class="kf kg hi ih b ii ko im kp iq kq iu kr iy ks jc kk kl km kn bi translated">右下角:CPU英特尔9900KF，GPU 2080ti，skip_frame=3</li></ul><p id="46f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们快速浏览一下。</p><h1 id="1c65" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">动漫风格图像转换</h1><p id="ea9c" class="pw-post-body-paragraph if ig hi ih b ii lr ik il im ls io ip iq lt is it iu lu iw ix iy lv ja jb jc hb bi translated">我相信你们中的许多人可能听说过它，因为它是大约半年前由新闻媒体报道的。一种将照片转换成动漫风格的方法可以在下面的页面找到。</p><p id="a233" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://github.com/taki0112/UGATIT:embed:cite" rel="noopener ugc nofollow" target="_blank">https://github.com/taki0112/UGATIT</a></p><p id="4a48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与简单的image2image风格转换不同，这款UGATIT基于使用生成器和鉴别器的所谓GAN技术，并通过添加原始的AdaLIN功能，似乎能够应对形状的变化。</p><p id="be2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lw">在我们的工作中，我们提出了一种自适应层实例归一化(AdaLIN)函数，以自适应地选择In和LN之间的适当比率。通过AdaLIN，我们的注意力引导模型可以灵活地控制形状和纹理的变化量。</em></p><p id="d4b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有关更多信息，请参见本文(<a class="ae jd" href="https://arxiv.org/abs/1907.10830" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1907.10830</a>)和评论文章。</p><p id="b020" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你使用上一页的训练好的模型，你可以看到它在实际转换中的样子。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es lx"><img src="../Images/2ac411adb9c26eac25d87cc4cb08af91.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/0*wHyXxX0ZkRFCGAD_.png"/></div></figure><p id="bf23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果被摄对象比较远，好像转换的不太好。此外，一个上了年纪的男人似乎不能很好地处理这件事。训练中使用的数据集也公布在上面的页面中，但似乎偏向于年轻女性，所以可能是这个原因。(我还没那么老…这样说是不是很过分…？)</p><h1 id="535c" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">实施概述</h1><p id="a264" class="pw-post-body-paragraph if ig hi ih b ii lr ik il im ls io ip iq lt is it iu lu iw ix iy lv ja jb jc hb bi translated">如上所述，看起来图像应该靠近主体(人的脸)(≒the的脸占据了屏幕的大部分)。这一次，我尝试使用我在以前的文章中介绍的人脸检测功能来识别人脸的位置，然后我剪切出人脸的位置，并应用UGATIT进行转换。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es ly"><img src="../Images/5c6a3bac6b1403c8f2817d5e13d01183.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*T4xtTDIwkZGMhFwE.png"/></div></div></figure><p id="00b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有关实现的更多信息，请参考下面提到的存储库。</p><h1 id="b40f" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">环境建设</h1><p id="343a" class="pw-post-body-paragraph if ig hi ih b ii lr ik il im ls io ip iq lt is it iu lu iw ix iy lv ja jb jc hb bi translated">看一下<a class="ae jd" href="https://cloud.flect.co.jp/entry/2020/03/31/162537" rel="noopener ugc nofollow" target="_blank">之前的文章</a>准备一个v4l2loopback，一个面部识别的模型等等。</p><p id="adcf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另外，和以前一样，请从下面的存储库中克隆脚本并安装必要的模块。</p><pre class="jz ka kb kc fd md me mf mg aw mh bi"><span id="9ebb" class="mi ku hi me b fi mj mk l ml mm">$ git clone <a class="ae jd" href="https://github.com/dannadori/WebCamHooker.git" rel="noopener ugc nofollow" target="_blank">https://github.com/dannadori/WebCamHooker.git</a><br/>$ cd WebCamHooker/<br/>$ pip3 install -r requirements.txt</span></pre><h1 id="20aa" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">部署UGATIT训练模型</h1><p id="6aa2" class="pw-post-body-paragraph if ig hi ih b ii lr ik il im ls io ip iq lt is it iu lu iw ix iy lv ja jb jc hb bi translated">UGATIT官方提供了Tensorflow和PyTorch版本的源代码，但唯一经过训练的模型似乎是Tensorflow版本。请得到这个并且扩展它。</p><p id="e8a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，正常的Windows和Linux zip解压工具似乎都失败了，并且在问题中有一个报告说7zip在使用Windows时工作良好。此外，它似乎不会在Mac上引起任何问题。对于Linux，解决方案是未知的…(截止到2020年4月2日)</p><p id="514f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里是正常运行的模型的哈希值(md5sum)。(大概是因为这是最大的绊脚石吧。)</p><pre class="jz ka kb kc fd md me mf mg aw mh bi"><span id="1dc2" class="mi ku hi me b fi mj mk l ml mm">$ find . -type f |xargs -I{} md5sum {}<br/>43a47eb34ad056427457b1f8452e3f79 . /UGATIT.model-1000000.data-00000-of-00001<br/>388e18fe2d6cedab8b1dbaefdddab4da . /UGATIT.model-1000000.meta<br/>a0835353525ecf78c4b6b33b0b2ab2b75c . /UGATIT.model-1000000.index<br/>f8c38782b22e3c4c61d4937316cd3493 . /checkpoint<br/></span></pre><p id="47b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些文件存储在从上述git克隆的文件夹中的‘uga tit/check point’中。如果是这样的话，还可以。</p><pre class="jz ka kb kc fd md me mf mg aw mh bi"><span id="9348" class="mi ku hi me b fi mj mk l ml mm">$ ls UGATIT/checkpoint/ -1<br/>UGATIT.model-1000000.data-00000-of-00001<br/>UGATIT.model-1000000.index<br/>UGATIT.model-1000000.meta<br/>checkpoint<br/></span></pre><h1 id="2c4a" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">我们开个视频会议吧！</h1><p id="0edb" class="pw-post-body-paragraph if ig hi ih b ii lr ik il im ls io ip iq lt is it iu lu iw ix iy lv ja jb jc hb bi translated">执行过程如下。增加了一个选项。</p><p id="2e05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">input _ video _ num应该是实际的网络摄像机设备号。对于/dev/video0，输入一个尾随的0。<br/>-output _ video _ dev必须是虚拟网络摄像机设备的设备文件。<br/> - anime_mode应该是真的。</p><p id="9c4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另外，请使用ctrl+c终止。</p><pre class="jz ka kb kc fd md me mf mg aw mh bi"><span id="f905" class="mi ku hi me b fi mj mk l ml mm">$ python3 webcamhooker.py --input_video_num 0 --output_video_dev /dev/video2 --anime_mode True</span></pre><p id="5c13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当执行上述命令时，ffmpeg开始运行，视频被传送到虚拟摄像机设备。</p><p id="dbd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和之前一样，当你开视频会议的时候，你应该会在视频设备列表中看到一个叫“dummy~~”的东西，所以选择它。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es mn"><img src="../Images/e41b4058a9bfb170ae8eff97acd6dc2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*ULJNYeVKhNuOIaTOdc33jw.gif"/></div></figure><p id="3438" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个团队的例子。原始图像也显示在屏幕右上方的划像区。它被转换成比我想象中更动漫的风格。但是，它很重，当它是一台有点旧的PC时，它是每秒1帧这样的水平(Intel(R)Core(TM)i7–4770 CPU @ 3.40 GHz，32G RAM)。可能很难正常操作。我想最终在GPU上尝试一下。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><a href="https://www.buymeacoffee.com/wokad"><div class="er es mo"><img src="../Images/6d60b235fcc46a4bd696b90e886419ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*Dpw8-hNGI2fDmosV4E8DVQ.png"/></div></a><figcaption class="mp mq et er es mr ms bd b be z dx translated">我很渴！！</figcaption></figure><h1 id="f6cb" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">最后。</h1><p id="8614" class="pw-post-body-paragraph if ig hi ih b ii lr ik il im ls io ip iq lt is it iu lu iw ix iy lv ja jb jc hb bi translated">长时间在家办公，可能很难随便交流，但我觉得把这种趣味性带到视频会议上来活跃一下谈话气氛是个不错的主意。我相信你可以做得更多，所以请尝试一下。</p></div></div>    
</body>
</html>