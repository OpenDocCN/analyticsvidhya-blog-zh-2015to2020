<html>
<head>
<title>Personalized Cancer Diagnosis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">个性化癌症诊断</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/personalized-cancer-diagnosis-823aeb28aaff?source=collection_archive---------17-----------------------#2020-06-11">https://medium.com/analytics-vidhya/personalized-cancer-diagnosis-823aeb28aaff?source=collection_archive---------17-----------------------#2020-06-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2559f440e85a68fc95009b4426df59f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MO--amY4WaRMZuW4ZfTxYg.png"/></div></div></figure><p id="f2f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“一旦被测序，一个癌症肿瘤可以有数千种基因突变。但挑战在于区分导致肿瘤生长的突变(驱动者)和中性突变(过客)。</p><p id="4ddb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">目前这种基因突变的解释是手工完成的。这是一项非常耗时的任务，临床病理学家必须根据基于文本的临床文献中的证据，对每一个基因突变进行人工审查和分类。我们需要你的帮助来开发一个机器学习算法，使用这个知识库作为基线，自动对基因变异进行分类。”</em></p><p id="3eeb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">~~Kaggle</p><p id="9741" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">【https://www.kaggle.com/c/msk-redefining-cancer-treatment/】来源:<a class="ae jp" href="https://www.kaggle.com/c/msk-redefining-cancer-treatment/" rel="noopener ugc nofollow" target="_blank"/></p><p id="fa39" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">具体实施请点击链接:</em><a class="ae jp" href="https://github.com/vedanshsharma/Personalized-Cancer-Diagnosis" rel="noopener ugc nofollow" target="_blank">https://github . com/vedanshharma/Personalized-Cancer-Diagnosis</a></p><h1 id="f1b5" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">介绍</h1><p id="1505" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">识别基因变异类型的任务通常分为三个步骤。我们的任务是使用一个模型来自动化第三步，这是分子病理学家最耗时的步骤。这包括分析与每个变化相关的证据，以便对它们进行分类。更正式的问题陈述是-</p><p id="28f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">根据基于文本的临床文献的证据，对给定的遗传变异/突变进行分类。</strong></p><p id="e183" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">来源</strong>:<a class="ae jp" href="https://www.kaggle.com/c/msk-redefining-cancer-treatment/discussion/35336#198462" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/MSK-重新定义-癌症-治疗/讨论/35336#198462 </a></p><h2 id="21ef" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">业务目标和约束。</h2><ul class=""><li id="7485" class="lh li hi is b it ko ix kp jb lj jf lk jj ll jn lm ln lo lp bi translated"><strong class="is hj">无低延迟要求</strong>。由于我们没有严格的延迟要求，我们可以训练复杂的模型，只要我们的模型花费合理的时间。</li><li id="4c8e" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">可解释性很重要。医生可能想要交叉检查结果，为此他可能需要算法来解释自己。为此，可解释性应该很高。</li><li id="9a11" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">错误可能代价高昂。既然这是生死攸关的事情，我们需要一个精确度很高的模型。</li><li id="babe" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated"><strong class="is hj">需要数据点属于每个类别的概率</strong>。这将让医生最终决定变异属于哪一类。在等概率类的情况下，医生将能够通过执行测试来决定，而不是模型返回单个类。</li></ul></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><h1 id="a270" class="jq jr hi bd js jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn bi translated">机器学习问题公式</h1><h2 id="b8dc" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">数据</h2><ul class=""><li id="13cc" class="lh li hi is b it ko ix kp jb lj jf lk jj ll jn lm ln lo lp bi translated">我们有两个数据文件:一个包含关于基因突变的信息，另一个包含人类专家/病理学家用来分类基因突变的临床证据(文本)。</li><li id="b8ac" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">这两个数据文件都有一个名为ID的公共列</li><li id="6f7d" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">数据文件的信息:</li></ul><ol class=""><li id="0935" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn mk ln lo lp bi translated">训练_变体(ID，基因，变体，类别)</li><li id="3e64" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn mk ln lo lp bi translated">培训_文本(ID，文本)</li></ol><div class="ml mm mn mo fd ab cb"><figure class="mp ij mq mr ms mt mu paragraph-image"><img src="../Images/7992ac68ad047866e07f70c19ed7af25.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*O0hHCpWv7EHJmxipJmgLCQ.png"/></figure><figure class="mp ij mv mr ms mt mu paragraph-image"><img src="../Images/2291ac78dd1785b9c280c8f570139bde.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*wm3rSelzHk3yRZtJ9fzpbg.png"/></figure></div><h2 id="464d" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">将现实世界的问题映射到ML问题</h2><p id="04db" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">遗传变异/突变可以分为九个不同的类别。这意味着我们的问题是一个多类分类问题。我们将使用的性能指标是-</p><ul class=""><li id="6982" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">多类对数损失，因为我们想要输出给定变量x_i属于1-9类的概率。</li><li id="b9ff" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">混淆矩阵</li></ul><p id="0b52" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">来源</strong>:<a class="ae jp" href="https://www.kaggle.com/c/msk-redefining-cancer-treatment#evaluation" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/MSK-重新定义-癌症-治疗#评测</a></p><p id="56ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">所以我们的最终目标是- </strong></p><p id="5853" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">目的:预测每个数据点属于这九个类别的概率。</p><p id="5fd7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们最后的限制是-</p><ul class=""><li id="c0b6" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">可解释性:像朴素贝叶斯、线性svm或DTs这样的模型可以训练，因为它们具有很高的可解释性。我们可能应该避免使用RBF svm这样的模型。</li><li id="2376" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">需要类别概率。</li><li id="4b20" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">惩罚类概率中的错误= &gt;度量是对数损失。</li><li id="e17a" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">没有延迟限制。</li></ul><h2 id="6d5f" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">训练、CV和测试数据集</h2><p id="f42e" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">我们的数据在本质上不是时间性的，也就是说，它不会随时间而改变。因此，我们将我们的数据集随机分为训练Cv和测试集，大小分别为64% (80的80 %)、16%(80的20%)和20%。我们将以保持类别标签分布不变的方式分割数据。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><h1 id="7178" class="jq jr hi bd js jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn bi translated">探索性数据分析</h1><h2 id="71fc" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">文本预处理</h2><p id="5e5f" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">我们将做一些基本的文本预处理，包括-</p><ul class=""><li id="d15f" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">删除停用词。</li><li id="330e" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">用空格替换每个特殊字符。</li><li id="726e" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">用单个空格替换多个空格。</li><li id="7775" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">将所有字符转换成小写字母。</li></ul><p id="82b5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">文本中很少有空值。</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es mw"><img src="../Images/612e1adcd5508a870bac32093e8ec583.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*jjRSAlUKjeMEhd4a2Lh8og.png"/></div></figure><p id="57fa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这种情况下，我们将简单地用基因名称和各行的变异来替换它们，如下所示</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es mx"><img src="../Images/11fb4ef4be6345ea0a89e3638abb01fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*U0B6RI0BkdLVuNNamh0yjA.png"/></div></figure><h2 id="5b17" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">分类标签的分布</h2><div class="ml mm mn mo fd ab cb"><figure class="mp ij my mr ms mt mu paragraph-image"><img src="../Images/e08a1b3088cbc09c4f1f66de730665eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*TSnZm1vr3e5OiviXSFEYig.png"/></figure><figure class="mp ij mz mr ms mt mu paragraph-image"><img src="../Images/d0de5791f9b3518b041679a18d5660ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*BTn_1yj5IIgATJL80Ny8_w.png"/></figure></div><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es na"><img src="../Images/d0de5791f9b3518b041679a18d5660ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*BTn_1yj5IIgATJL80Ny8_w.png"/></div></figure><ul class=""><li id="b68b" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">数据不平衡。</li><li id="0ee3" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">训练、测试和Cv数据的分类标签分布大致相似。</li></ul><h2 id="4633" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">训练随机模型</h2><p id="2c77" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">我们的关键性能指标“对数损失”是一个范围为<em class="jo">【0，</em> ∞) <em class="jo">的函数。</em>因此，我们需要一个随机模型来获得指标的上限。随机模型是这样一种模型，当给定x_i时，它将随机产生从1到9的任何标号，其中所有标号都是等概率的。</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/72030c41b35890228f6d2a73e56ae00d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*w6N9SuNUlGRr5aj1dxU1jA.png"/></div></figure><p id="1776" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.5是我们随机模型的对数损失值。对于我们的问题来说,“体面”的模型将具有远小于2.5的对数损失值。</p><h2 id="3281" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">单变量分析</h2><p id="c3b3" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated"><strong class="is hj">基因- </strong></p><ul class=""><li id="a2c9" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">基因是一个分类变量</li><li id="4734" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">在训练集中有232个独特的基因。</li></ul><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/96d6ab045cdbc40908c67a607fcc59a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*6hQlsWViR6dKsd7AeRB38Q.png"/></div></figure><ul class=""><li id="fca9" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">基因的分布是高度倾斜的</li></ul><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/835a8674bf4b4de2c356ee9fd5e87f2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*uU0rvSS1X_UiQBl3QgixWA.png"/></div></figure><ul class=""><li id="1fb0" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">前50个基因贡献了大约75%的总数据。</li></ul><p id="02fc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了对基因变量进行分类，我们将使用两种方法-</p><ul class=""><li id="e698" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">一个热编码</li><li id="61e4" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">响应编码。<a class="ae jp" rel="noopener" href="/@thewingedwolf.winterfell/response-coding-for-categorical-data-7bb8916c6dc1">https://medium . com/@ thewingdwolf . winterfell/response-coding-for-categorical-data-7bb 8916 c6dc 1</a></li></ul><p id="fe1e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将根据我们使用的ML模型选择适当的特征。对于具有类别特征的多类分类问题，一键编码更适合逻辑回归，而响应编码更适合随机森林。</p><p id="9e10" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要做的下一件事是检查特征基因是否对分类有一定的重要性。为此，我们将在一个热编码上训练多类逻辑回归，看看我们是否能够获得比随机模型更好的对数损失。</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ne"><img src="../Images/530a0a93d739b7906fc479479ba9ae4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*CAqZyTCSj0PLWOMHM87ZOQ.png"/></div></div></figure><p id="c84a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">特征基因能够极大地减少所有数据集上的日志损失。因此，它对分类具有重要意义。此外，基因特征也是一个稳定的特征，因为在训练、测试和Cv集的对数损失之间有很大的差异。</p><p id="372b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">变异</strong></p><ul class=""><li id="cbe8" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">变异也是一个分类变量。</li><li id="77f5" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">在训练数据集中有1926个独特的变化</li><li id="7f9e" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">大多数变异只出现一次。</li></ul><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nf"><img src="../Images/cad25f0f80a784d1c6d0d15b11e37069.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*Y1jpLZ2Hq6Elc8bdmJmsqg.png"/></div></figure><ul class=""><li id="97a3" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">1500个变异只占数据的80%。</li></ul><p id="85fa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了对基因变量进行分类，我们将使用两种方法-</p><ul class=""><li id="d0b7" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">一个热编码</li><li id="ad87" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">响应编码</li></ul><p id="c027" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">类似于我们对基因特征所做的，我们将在一个热编码上训练一个多类逻辑回归，看看我们是否能够得到比随机模型更好的对数损失。</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es ng"><img src="../Images/ae11a5079186a3c6063827e3564e3b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*l5YSWesBcp8BWPfuHi0kew.png"/></div></figure><p id="7aeb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">看起来我们得到了一个更好的日志损失，原来特征变化是不稳定的。但是我们仍然保留这个特性，因为它能够极大地减少所有数据集的日志丢失</p><p id="7644" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">对文本特征的单变量分析</strong></p><ul class=""><li id="8fc7" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">在训练文本中存在53619个唯一单词。</li><li id="b683" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">最频繁出现的单词出现了404次。</li></ul><p id="bdac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了对基因变量进行分类，我们将使用两种方法-</p><ul class=""><li id="01b1" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">一个热编码(在文本数据的情况下是一袋单词)</li><li id="0058" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">响应编码(文本数据的响应编码有点类似于朴素贝叶斯方法，其中对于给定的类I，我们有<em class="jo"> y=P(class=i|text_j) </em>)</li></ul><p id="36ff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们已经使用逻辑回归(像以前一样)来确定文本特征的重要性。</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nh"><img src="../Images/3a0a88fa3bd3f280764bf06dc8a63ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*0rEBBj9UJirCsMLhRDZX0A.png"/></div></figure><p id="361f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该功能似乎很稳定。现在我们可以断定<strong class="is hj">基因&gt;文字&gt;变异</strong>在稳定性方面。</p><h2 id="5f4a" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">机器学习模型</h2><p id="6331" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated"><strong class="is hj">朴素贝叶斯</strong></p><p id="eb36" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们将训练一个带有超参数调整的基线朴素贝叶斯模型。朴素贝叶斯是一个相对简单的模型。我们将对朴素贝叶斯使用一次性编码特征化。</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es ni"><img src="../Images/d9319083c0917792fbbf1a5936287977.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*-ZcUpdJ-iHNx7LO1GbQS1Q.png"/></div></figure><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nj"><img src="../Images/ac52906c0fc6f63d44a0230dc2986c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*j64JDb9V2H7N48gw2QY1Fg.png"/></div></figure><ul class=""><li id="b15b" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">测试数据的对数损失为1.28。</li><li id="7db5" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">我们错过了44.36%的分类数据点。</li></ul><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nk"><img src="../Images/e91c8189510812c64fdd99a57c6de6a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wzYIYN6X-_c706tK6B3ZZg.png"/></div></div></figure><ul class=""><li id="5b07" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">许多4级点被误归类为1级。许多7类点被归类为2类。</li></ul><p id="4b08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> K-NN </strong></p><p id="6438" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的第二个模型是KNN。由于 <a class="ae jp" href="https://towardsdatascience.com/k-nearest-neighbors-and-the-curse-of-dimensionality-e39d10a6105d" rel="noopener" target="_blank"> <strong class="is hj">维度的诅咒</strong> </a>，KNN不能很好地处理高维数据<strong class="is hj">。因此，对于KNN，我们将使用响应编码数据来训练我们的模型。KNN的另一个重要方面是它是不可解释的。我们能做的最好的事情就是查看给定查询点的邻居。</strong></p><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nl"><img src="../Images/9a291cd9ea084bfdba4bcf8a2b68ebbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*gxzuc6k0wwXdR_TkZtn36A.png"/></div></div></figure><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nm"><img src="../Images/9a4ddef0af2a1219b47d1ed29369ce33.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*RYnPwxMxwLnsk9cy6RSSyA.png"/></div></figure><ul class=""><li id="22e7" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">我们的测试数据的对数损失为1.08，这是一个改进。</li><li id="f624" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">我们的失误分类误差降低了8%(大约)。</li></ul><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nn"><img src="../Images/071f5d71f45776395538da2dd13b5ed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2EMfEMZG5UuZ0i-5uZBPBg.png"/></div></div></figure><ul class=""><li id="f20c" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">1-4级和2-7级的问题仍然存在。</li><li id="f88d" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">尽管类别9在数据中所占的比例很小，但它被很好地分类了。</li></ul><p id="6137" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">逻辑回归(带类别平衡)</strong></p><p id="2541" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">逻辑回归在处理高维数据时效果相当好。首先，我们将训练一个具有类平衡的逻辑回归模型。类别平衡类似于过采样，过采样主要通过不平衡的数据集来完成，以便在训练数据中具有所有类别的<strong class="is hj">相等表示。</strong></p><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es no"><img src="../Images/72d804670e5e6d7f2ef0f3c6ce4502a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*roCnBxHJ_EZibAG2K8NIjQ.png"/></div></div></figure><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es np"><img src="../Images/98dd7d9eba0a205ec10e4ef4b96abe94.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*-4XUR0gMWlrGy6mWiXERTQ.png"/></div></figure><ul class=""><li id="6269" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">测试数据的对数损失为1.13。</li><li id="f9ad" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">未命中分类误差没有太大改善。</li></ul><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nq"><img src="../Images/14e122a9e5f2396748d9df7865b24c24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AELt1twNdCpGFf0q-l53Zw.png"/></div></div></figure><ul class=""><li id="9a87" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">尽管八班是一个少数民族班级，但它被很好地分类了。</li><li id="b318" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">对角线值相对较大，这是一个健康的迹象。</li></ul><p id="6554" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">逻辑回归(无类别平衡)</strong></p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nr"><img src="../Images/522919366f76be0ba96d21956ad5282f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*ko5HcAUZiRetnnywA7vFCA.png"/></div></figure><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es mw"><img src="../Images/e6077f33a1a86bab11faf30af2e5c3c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*B8bTsw5TSARzHxz6e4Nhsg.png"/></div></figure><ul class=""><li id="94dd" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">我们在测试数据上获得了1.14的对数损失。</li><li id="be3f" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">没有类平衡的模型比有平衡的模型性能差。</li></ul><p id="257a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">线性SVM(带类别平衡)</strong></p><p id="d84e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">线性支持向量机类似于逻辑回归。因此，对于高维数据，它也能很好地工作。此外，它具有高度的可解释性。</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es ns"><img src="../Images/4650efadf28ddb25ce7901ff3fe667f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*-Y9f2ZyZi9GNkrZQUcOsbQ.png"/></div></figure><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/93d2e0f64d24caee6a39329cb94aa5e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*CIqWcpaUDg6kK-d0I0CqQQ.png"/></div></figure><ul class=""><li id="88b9" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">根据测试数据，对数损失为1.19。</li><li id="e8ba" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">未命中分类误差约为37.69%。</li></ul><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nu"><img src="../Images/e7d843c6fbda422d8c89a3735f779e20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M33X6q6Pd04_8vlxT-RT1g.png"/></div></div></figure><ul class=""><li id="d2bf" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">结果类似于具有类别平衡的逻辑回归。</li></ul><p id="e9e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">随机森林(带一个热编码)</strong></p><p id="0bd7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随机森林最适合低维数据</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nv"><img src="../Images/e5a842384ea742a00dab6f671946ae3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*OE8K9KjmW_Un6n-WOG_JQA.png"/></div></figure><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/655d46f41e1bcea0424908c55df4fd51.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*dOImy1KwTtOQzbSkwTtSuw.png"/></div></figure><ul class=""><li id="2056" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">测试数据的对数损失为1.19。</li><li id="d82f" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">未命中分类误差约为40.97 %。</li></ul><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nw"><img src="../Images/8c8c0a8b2641437cd409e15fa9676c6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xHAMvMQEckmaDOnET9-PUg.png"/></div></div></figure><p id="6840" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">随机森林(带响应编码)</strong></p><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es nx"><img src="../Images/08bb8dcddd1de4a77404dda822d6f5bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*1oYzN0DJDz9ozKEWE2PV9Q.png"/></div></figure><figure class="ml mm mn mo fd ij er es paragraph-image"><div class="er es ny"><img src="../Images/a6f14073cc31e4be9b5078844b9bea9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*MXhTTVvmonIbu4-89pAVTA.png"/></div></figure><ul class=""><li id="cff6" class="lh li hi is b it iu ix iy jb mh jf mi jj mj jn lm ln lo lp bi translated">对数损失为1.34。</li><li id="a5d5" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">即使在超参数调整后，该模型仍然过度拟合。这可能是因为响应编码是一种比热编码更弱的特征化形式。</li><li id="8742" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">未命中分类误差接近50%，这是一个危险信号。这意味着每一秒钟都被遗漏了</li></ul><p id="ed98" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们还尝试了堆叠模型，但即使这样也没有提高性能。下一个选择是尝试使用其他功能。</p><h2 id="d31d" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">Tf-Idf</h2><p id="a4c5" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">我们没有使用单词包，而是尝试了tfidf特性。</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nz"><img src="../Images/36ae561b1f66ce50a1d524703cee9f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gwfKnpP9VSitdB8OKWUFgg.png"/></div></div></figure><p id="43bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用逻辑回归，我们能够将所有数据集的对数损失降低到1.0以下。即使我们的失误分类错误只有33.27 %，这是非常令人印象深刻的。</p><h2 id="dd28" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">二元模型和二元模型</h2><p id="1442" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">这种特征化将导致维度激增。因此，我们只训练线性模型</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oa"><img src="../Images/8008b24380fd88a433cc7741d881fb13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dUea-8Cb_tFaqIK4-4pTxw.png"/></div></div></figure><p id="522e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于这两个模型，测井曲线损失增加甚至超过1.0。</p><h2 id="a6c5" class="kt jr hi bd js ku kv kw jw kx ky kz ka jb la lb ke jf lc ld ki jj le lf km lg bi translated">Tf-Idf，包含单字和双字</h2><p id="5361" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">我们将尝试使用unigrams和bigrams的if-idf，但我们将只取前4000个idf值。这将为我们提供文本数据的维度上限。</p><figure class="ml mm mn mo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ob"><img src="../Images/b6477ba414793e729f3c2853fc43db35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tu7AfeS5ZDBTs8yr-3Z6Wg.png"/></div></div></figure><p id="1107" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">再次使用逻辑回归，我们的对数损失下降到1.0以下，但最大的优点是它的错过分类误差仅为30.07 %。<strong class="is hj">这比我们使用简单的tf idf特性获得的结果少3%。</strong></p><h1 id="2b2d" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="60d4" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">对于此数据集，使用tf-idf和unigram和bigram进行逻辑回归，同时仅使用前4000个idf值的特征，是建模的最佳方法，因为它具有最小的未命中分类错误，同时所有对数损失都低于1.0</p></div></div>    
</body>
</html>