<html>
<head>
<title>Convolutional Neural Network: Conceptual view.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络:概念观点。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/convolutional-neural-network-conceptual-view-e2f42bf93b70?source=collection_archive---------19-----------------------#2019-11-18">https://medium.com/analytics-vidhya/convolutional-neural-network-conceptual-view-e2f42bf93b70?source=collection_archive---------19-----------------------#2019-11-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ea88a80277c3618f113231eaaefdf288.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kc-Ou2P5I-7tq3zcbjxPSQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">信用:<a class="ae iu" href="https://cogniinsight.com/research/" rel="noopener ugc nofollow" target="_blank">https://cogniinsight.com/research/</a></figcaption></figure><p id="bf5e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">卷积神经网络(ConvNet / CNN)是一种主要用于图像分类和图像识别的神经网络。ConvNet的架构灵感来自视觉皮层的组织。</p><p id="d675" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">ConvNet由具有权重的神经元组成，可以从数据中学习。一个神经网络在三个维度上排列它的神经元:宽度、高度和深度。每个神经元接收输入并执行点积。这个输入通过隐藏层。每个隐藏层由一组神经元组成，其中每个神经元都与前一层中的所有其他神经元完全连接。在同一层内，每个神经元都是独立的，不共享任何连接。最后一个完全连接的层被称为<strong class="ix hj">输出层。</strong></p><p id="1f76" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">ConvNet有四个功能</p><p id="179d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1.卷积的</p><p id="5dbf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.热卢</p><p id="da14" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.联营</p><p id="cd87" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4.全连接层。</p><p id="fc64" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">卷积运算:</strong></p><p id="4c7f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该操作的主要目的是从输入图像中提取特征。执行这个操作所涉及的元素被称为<strong class="ix hj">内核或过滤器。</strong>该过滤器以某个值在整个矩阵上移动，直到完成。滤波器移动的这个特定值被称为<strong class="ix hj">步幅值</strong>。卷积运算后产生的输出矩阵称为<strong class="ix hj">特征图</strong>。例如:</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jt"><img src="../Images/19e57e6225299d61ad8d3c47490bc5ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Bz4EVmjtt-df3l2Vm-0j0A.gif"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">信用:<a class="ae iu" rel="noopener" href="/@phidaouss/convolutional-neural-networks-cnn-or-convnets-d7c688b0a207"> F D博客</a></figcaption></figure><p id="9a8a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> ReLU : </strong></p><p id="b7d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">ReLU代表校正线性单位。像任何其他神经网络一样，CNN也需要保持非线性。如果输入为负，ReLU单元的输出为0，否则，它将与输入相同。卷积运算的输出之后是ReLU激活函数，用于从矩阵中移除所有负值。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jy"><img src="../Images/e0dcea57e2c64ff9afb64d600df3a7a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*EZOOhgjvH0ayFc88jyT3pg.png"/></div></figure><p id="82c7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">汇集:</strong></p><p id="5460" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在ReLU激活函数之后，我们执行下一个被称为池化的操作。这种操作有助于降低图像的维数，从而减少过拟合的可能性。</p><p id="3286" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最常见的池化方法是最大池化，它选取定义窗口的最大值。类似于卷积，我们决定最大池的窗口和步幅。它减小了特征图的大小，但同时保留了重要的信息。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es jz"><img src="../Images/e1f3ea120f16c5ce23b8f3d2b03c153e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*WSgjXfa7mv-upuD8hX-K5g.png"/></div></figure><p id="3eae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">全连接层:</strong></p><p id="ff1c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，池化步骤的输出传递给完全连接的层。该全连接层神经元与所有先前的神经元连接，并接收输入和执行分类。这些完全连接的图层只接受1D的数据。因此，我们需要将数据从三维平面展开到1D矢量。</p><p id="4d04" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">性能优化/超参数调整:</strong></p><p id="322a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在卷积神经网络中，我们有4个超参数</p><p id="43a2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1.过滤器尺寸</p><p id="34e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.进展</p><p id="afd2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.使用的过滤器数量。</p><p id="2604" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4.填料</p><p id="c220" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">5.图像增强</p><p id="a485" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">滤镜尺寸</strong>:滤镜尺寸作为取决于图像的超参数非常重要。我们主要考虑3x3，但其他也用于根据图像大小。通常，我们不考虑过滤器尺寸中的深度，因为它总是与输入深度相同。</p><p id="5493" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">使用的滤镜数量</strong>:滤镜数量通常由开发者决定，开发者大多是2的幂。基本上，我们应该从小数量开始，然后相应地增加。</p><p id="ff3a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步幅</strong>:正如我们上面讨论的，步幅是过滤器在图像矩阵上移动的步数。</p><p id="5cb0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">填充</strong>:在原始图像上应用滤镜后，特征图的尺寸总是会减小。因此，为了保持特征图的相同尺寸，我们使用填充。向特征地图中添加了一个额外的零列，以便它不会收缩并保持空间大小不变。这提高了性能。</p><p id="b14b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">图像增强</strong>:为了使模型尺寸更大，我们添加了不同角度的不同尺寸的图像。这是防止过度拟合的一种方法。</p><p id="34b3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的博客帮助你理解卷积神经网络的基本概念。在下一篇博客中，我们将通过代码解释上述所有步骤，并在Keras的帮助下编写一个模型。</p></div></div>    
</body>
</html>