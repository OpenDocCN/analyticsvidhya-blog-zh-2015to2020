<html>
<head>
<title>Image forgery localization(IFL) using UNET architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用UNET建筑的图像伪造定位(IFL)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-forgery-localization-ifl-using-unet-architecture-772ba1b15a2d?source=collection_archive---------5-----------------------#2020-05-13">https://medium.com/analytics-vidhya/image-forgery-localization-ifl-using-unet-architecture-772ba1b15a2d?source=collection_archive---------5-----------------------#2020-05-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="d28f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">图像伪造定位是检测伪造或篡改区域的技术之一，目前已有一些图像伪造检测算法。但这种方法与典型的伪造检测器略有不同，伪造检测器可以对给定图像是否被操纵进行分类，而伪造定位通过将图像分割成不同的区域来确定被操纵的区域。在这篇博客中，我们将使用UNET架构实现IFL。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/e5fd17b74278925702cd1b8472515acd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2d2t4qfl_7uJhG2P.jpg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">封面图片(<a class="ae jn" href="https://www.thairath.co.th/news/business/1348497" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><h1 id="7646" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">理解问题</h1><p id="d204" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi lj translated"><span class="l lk ll lm bm ln lo lp lq lr di"> T </span>数字取证部门正在积极开展研究，以确保给定的数字内容是经过认证的，但为什么研究人员非常关注数字取证呢？看看下面的图片，你注意到了什么？看起来非常自然，没有什么可疑的权利，但它实际上是操纵。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ls"><img src="../Images/709a58b9f1284aa5c8d9690587c6fd0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*WwGAZGvqim3FwNV_AihO4A.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图1:一个看起来真实的数字内容的例子(<a class="ae jn" href="http://web.archive.org/web/20171013200331/http:/ifc.recod.ic.unicamp.br/fc.website/index.py?sec=5" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="c0b7" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">如今，我们不能信任任何数字内容，因为由于数字篡改工具(如Photoshop、Adobe After effects，甚至一些人工智能算法)的可用性更高，这些内容被攻击的可能性非常高。</p><p id="54bd" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">下图(图2)显示了图1中被篡改的区域，这意味着黑色突出显示的区域表示特定区域已经被篡改。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ly"><img src="../Images/0c569c201fe5c64efebc09e2493c035e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*IYkM3j20tyCuNeKnDZWdXQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图2:一个被操作图像的蒙版图像的例子(<a class="ae jn" href="http://web.archive.org/web/20171013200331/http:/ifc.recod.ic.unicamp.br/fc.website/index.py?sec=5" rel="noopener ugc nofollow" target="_blank">源</a></figcaption></figure><p id="cb18" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">对于人类来说，几乎不可能每次都确定数字内容是原始的还是被操纵的。基本上最常见的图像篡改方法有<strong class="kp hj">复制移动</strong>、<strong class="kp hj">图像拼接</strong>、<strong class="kp hj">图像绘画</strong>。<strong class="kp hj">复制-移动</strong>是一种将图像的一小部分复制粘贴到同一图像的其他区域的攻击。<strong class="kp hj">图像修复</strong>是去除图像中的一些细节，并在被去除的区域用其相邻的颜色和属性进行平滑，从而使人无法识别图像受到了攻击。最后，<strong class="kp hj">图像拼接</strong>是选择一幅特定图像中的某个区域，并将该区域粘贴到另一幅合适的图像中。</p><p id="b4ea" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">应该有一个合适的算法系统来检测被攻击的图像。已经说过，检测图像是否被操纵是不够的，并且它不能给出完整的解决方案，因此算法应该定位给定图像中被操纵的区域。</p><p id="454a" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">在理解了上述问题之后，这里的<strong class="kp hj"> <em class="lz">我们的目标是建立一个模型，使得对于给定的图像，它应该能够定位被篡改的区域。</em>T3】</strong></p><h1 id="bcc3" class="jv jw hi bd jx jy ma ka kb kc mb ke kf io mc ip kh ir md is kj iu me iv kl km bi translated">为什么只和AI？</h1><p id="ac44" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">对于被篡改区域的图像，统计参数会发生突变，特别是对于图像拼接类攻击。虽然说篡改可以通过统计参数的变化来检测，但是我们是否可以只用传统的图像处理技术来解决这个问题呢？是的，我们可以，但这可能需要大量的人工努力，大量的研究和数年的时间，让我来详细解释一下。</p><p id="01d2" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">例如，如果我的目标是检测并消除给定图像中的高频。是的，这是一个非常简单的目标，对吗？我们可以通过使用具有一些均值和标准差的高斯滤波器来衰减其中的较高频率，以某种方式实现这一点。注意，对于这个目标，我们有一个非常合适的滤波器，但是对于我们的主要目标(即定位篡改区域),没有<strong class="kp hj">预定义的滤波器函数</strong>,并且基于目标确定完美的滤波器可能需要多次尝试，这显然需要多年的研究和时间。</p><p id="c7a0" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">同样在上面的例子中，对于所有类型的图像，滤波器的传递函数是相同的，因此滤波器的权重不会按照我们的要求改变。每当我们有一个复杂的目标，并且不知道使用哪个过滤器/过滤器的组合时，工程师或研究人员就会选择深度学习技术。</p><p id="1ab5" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">使用像CNN这样的DL技术可以自动学习我们目标所需的滤波器传递函数。而在训练阶段，CNN随着获得的结果到实际结果的变化，不断更新和学习滤波器权重，这是任何人工智能算法的主要核心部分。</p><h1 id="8944" class="jv jw hi bd jx jy ma ka kb kc mb ke kf io mc ip kh ir md is kj iu me iv kl km bi translated">数据和EDA</h1><p id="a15b" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">在进入深度学习架构的进一步细节之前，我们需要获得适合我们目标的数据。这里，我考虑的是IEEE IFS-TC图像取证挑战[1]数据，其中包含原始图像数据和经过处理的图像数据。数据中经过处理的图像是使用我在上面讨论的所有三种处理方法创建的。让我们通过一些探索性的数据分析来快速掌握数据。</p><p id="e0f4" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">有两类图像<strong class="kp hj">原始图像</strong>和<strong class="kp hj">伪图像</strong>，其中伪图像具有其对应的灰色遮罩，其中遮罩中的深色表示被操纵的区域。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mf"><img src="../Images/3e852a2407f40d04855948872551dcea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*1Xz-0YceDMyODc6o8xR9_A.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图3:柱状图显示了数据中的类及其数量</figcaption></figure><p id="d454" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">在数据中，有1050个原始图像和450个伪图像，正如我们在下图中看到的，这450个伪图像将有其相应的遮罩。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mg"><img src="../Images/2f9c3edc0dd023677bfaf6142703534f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pjnW5am4VOqi4xiaoc4enA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图4:假图像及其灰度蒙版的样本。</figcaption></figure><p id="04ef" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">图5和图6中的曲线分别显示了赝品和原始品的图像宽度和高度的分布。使用这个PDF图，我们可以快速掌握什么可能是典型的大小及其在未来发生的可能性。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mh"><img src="../Images/10a678630ad803d60602122c0baba8a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cZrLBErNQLTnTp7GM-e9PQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图5:两个类中图像的宽度的PDF</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mi"><img src="../Images/c65d850864ed902c48e145cc0a416139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u_ggp1iW9NqqjOSbSPPFCQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图6:两个级别图像的<strong class="bd jx">高度</strong>的PDF</figcaption></figure><p id="2885" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">正如我们在图4中看到的，蒙版图像看起来是灰度的，这意味着它只有一个颜色通道。然而，对于一些掩模图像，有3个通道，甚至4个通道，图7描述了具有1个通道、3个通道、4个通道的掩模图像数量的柱状图。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mj"><img src="../Images/31e2f2abe3b023b05d30406b0d32ae57.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*jtBuVi-IO1o7cp9bXXJwxw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图7:柱状图显示了屏蔽图像中通道的数量。</figcaption></figure><p id="ae1a" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">在第一个轴之后的多通道遮罩图像通道中，它只是增加了冗余，并没有增加任何进一步的信息，因此我只考虑了每个遮罩图像中的单个通道。对于一些面具，几乎没有噪音。为了减弱这一点，我添加了一个简单的高斯模糊来帮助平滑，最后我认为这是二进制蒙版。请看图8</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mk"><img src="../Images/2d08f12513d89399f32124b84b416170.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hHDF5CuBiQQp7SQhdcRHYw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图8:图像显示了给定蒙版和平滑二进制蒙版之间的差异</figcaption></figure><p id="447b" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">在这450个伪图像和它们的450个对应的掩模中，可能存在有缺陷的掩模，有缺陷的意思是，如果伪图像和它的对应掩模的尺寸不相同，那么就不会使用伪图像和它的掩模，因此避免了这样的图像和它的掩模。在检查上述条件时，我们只得到8个有缺陷的蒙版，因此删除了这些蒙版及其相应的图像。</p><h2 id="0cfa" class="ml jw hi bd jx mm mn mo kb mp mq mr kf kw ms mt kh la mu mv kj le mw mx kl my bi translated"><strong class="ak">对数据执行EDA后，快速得出的结论是:</strong></h2><p id="ad13" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">–我们的数据量非常少，只有1050个原始图像和442个伪图像(经过数据清理)，原始图像和伪图像之间的数据不平衡。我们需要扩大数据规模以获得更好的结果。</p><p id="55f8" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">–从我们观察到的pdf图来看，假类的图像大小范围略高于原始类</p><p id="9680" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">–一些掩码具有多通道信息。意识到这一点，我们只考虑了第一通道，并将每个掩码转换为二进制。</p><h1 id="2a84" class="jv jw hi bd jx jy ma ka kb kc mb ke kf io mc ip kh ir md is kj iu me iv kl km bi translated">解决我们问题的一些现有方法</h1><p id="84da" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">在考虑我们的基本模型之前，让我们了解一些现有的方法来实现我们的目标。有一些基于照片响应非均匀性(PRNU) [2][3]的方法，它对于每个相机都是非常独特的，这意味着特定相机拍摄的照片会受到相机内置图像传感器的固定噪声模式的影响。</p><p id="bb32" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">如果我们考虑并计算PRNU作为预处理步骤，这无疑为模型增加了很大的优势，使得模型可以区分用两个不同的相机捕获的两个图像。利用这一特性，有许多好的方法来检测被操纵的区域，但是它需要相机的信息，并且它对于图像拼接类型的攻击相当有效，因为在图像拼接的大多数情况下，拼接的区域和目标图像来自用不同相机捕获的不同来源，但是我们不能保证在复制-移动类型中。因为我们的数据中没有任何关于相机的信息，所以我们不能利用PRNU。</p><p id="6c35" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">有一些定义明确的体系结构，如BusterNet[4]，专门为图像伪造定位类任务而设计，总之BusterNet仅设计用于复制-移动类攻击，但在我们的数据中，总共有三种类型的攻击，并且在实时中可能不止这些，因此我们应该得到一个模型，该模型应该能够处理所有类型的攻击。</p><h1 id="b393" class="jv jw hi bd jx jy ma ka kb kc mb ke kf io mc ip kh ir md is kj iu me iv kl km bi translated">UNET作为基础模型</h1><p id="3b31" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">如前所述，我们期望的模型应该预测给定图像的遮罩，因此我们的模型应该包含编码器和解码器类型的架构，因为我们试图突出给定图像中的篡改区域，所以模型需要将图像分为两类，一类是篡改区域(深色)，另一类是未篡改区域(浅色)。</p><p id="0d1c" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">在这里，我考虑将<strong class="kp hj">UNET</strong>【5】<strong class="kp hj"/>作为基础模型，因为它已经在类似的图像分割中取得了证明的结果，并且它也满足上述要求。第一次UNET是为生物医学图像分割开发的，该体系结构包含两条路径，一条是包含一些卷积堆栈、最大池层的编码器路径，另一条是与编码器路径对称的解码器路径。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mz"><img src="../Images/41869e584b0f03c54b46158ef5d92e89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tOBli5WktHvNwP53w8o_YQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图9: UNET建筑(<a class="ae jn" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="3229" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">从EDA中，我们意识到数据非常有限，因为我们知道深度学习模型非常渴望数据，用这种少量的数据我们无法建立一个合理的模型。为了增加数据的影响，我用另外一个叫做<strong class="kp hj">albuminations</strong>【6】的库来扩充数据。但为什么我使用一些特殊的库来增加数据，因为图像增加应该发生在图像和它的遮罩上，例如作为数据增加的一部分，如果我的图像旋转90度，那么它相应的遮罩也应该以同样的方式旋转，为此我发现这个库非常有用。</p><p id="158d" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">另外，请注意，作为预处理步骤的一部分，图像的大小被调整为512 X 512，并且所有像素值都除以255</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es na"><img src="../Images/6c77a369c18a353ac8294be5e323c492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*VgOcQYI13s2QEgG2uJh5fQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图10:使用<strong class="bd jx">白蛋白</strong>库的数据扩充</figcaption></figure><p id="53b7" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">为了避免数据泄露，我将数据分为训练集、验证集和测试集，分割后，我分别为这三个集增加了数据。注意，对于伪图像，我们有遮罩，但是对于原始图像，我们没有任何遮罩，因此对于所有原始图像，将<strong class="kp hj">default.mask.png</strong>视为默认遮罩，其中它仅包含白色像素，并且对于所有原始图像都是相同的。</p><p id="2986" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">在分割和扩充之后，该数据被训练用于使用adam对UNET架构进行优化，以减少二进制交叉熵和测量精度，在运行10个时期之后，我们获得了大约96.17%的良好的数字精度，并且大大减少了对数损失，但是该模型可以做出适当的预测，并且预测的掩模图像远离地面真实掩模，您可以看到下面的图像。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nb"><img src="../Images/c55210c2ee7d2fd26a10f7f7eb52aeaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IMmyD0nYnOoozNyJwoLBXg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图11:基础模型的预测掩码和地面真实掩码之间的比较</figcaption></figure><h2 id="29bd" class="ml jw hi bd jx mm mn mo kb mp mq mr kf kw ms mt kh la mu mv kj le mw mx kl my bi translated">让我们理解为什么会发生这种情况:</h2><p id="50c0" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">–众所周知，当我们有不平衡的数据时，准确性可能会有欺骗性，但我们在扩充时平衡了我们的数据，但请注意，我们平衡了原始类和伪类之间的数据。</p><p id="1be7" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">–根据我们的目标，模型需要预测图像中的每个像素，无论它是真实的还是被操纵的，对于每个被操纵的像素，结果应该是0，对于未被触摸的像素，结果应该是1。</p><p id="ed5b" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">–如果我们需要平衡数据，我们应该在暗像素和亮像素之间进行平衡，其中暗像素表示被处理的区域，亮像素表示未被处理的区域。</p><p id="990f" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">–另一种说法是，与未受影响的区域相比，受影响区域的所有图像面积非常小，因为白色像素变得非常重要，因此这造成了不平衡的类别，我们的模型无法正确学习。</p><p id="2a6e" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">–因此，我们的基本模型显示出很高的精度，但没有我们预期的那么高效。</p><p id="58c8" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">为了在学习区分暗像素和白像素的同时对模型产生相同的影响，数据应该是平衡的，但是在我们的情况下，要么我们不能增加被操纵的像素，要么不应该减少被操纵的像素，唯一的方法是减少或避免白像素。</p><p id="2584" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">为了向下采样白色像素，这一次我完全避免了原始的类图像，因为它只包含蒙版中的白色像素。</p><h2 id="9b1c" class="ml jw hi bd jx mm mn mo kb mp mq mr kf kw ms mt kh la mu mv kj le mw mx kl my bi translated">只用假图像训练UNET</h2><p id="f412" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">在我们的下一个UNET模型中，我们只考虑假图像来训练，以避免所有原始图像，并且使用与我们对基本模型所做的相同的设置来训练。这一次，在10个时期后，我们获得了大约93.34%的准确度，但是该模型再次不能如预期的那样做出正确的预测，然而这些预测比第一个模型稍微好一些。</p><p id="fb60" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">因此，这说明即使我们避免了完整的原始类，但假图像中的白色像素仍然占主导地位。数据必须进一步平衡。</p><h2 id="a85f" class="ml jw hi bd jx mm mn mo kb mp mq mr kf kw ms mt kh la mu mv kj le mw mx kl my bi translated">用从假图像中提取的补丁训练UNET</h2><p id="1fdb" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">在进入下一个模型之前，由于我们的is数据受到不平衡类的影响，这次我将每个假图像分割成大小为128×128像素、步幅为32的小块，并考虑到这些小块仅包含至少25%的操纵像素和未操纵像素，并忽略其余的小块。这样我们就不会得到完整的白色区域。</p><p id="3d89" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">正如你在下面的图11中看到的是一个样本假图像和它的蒙版图像，现在在图12中是使用stride 32提取的128X128补丁。注意，我们为一幅图像得到了许多这样的补丁，但是由于空间的限制，我只展示了很少的几个。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nc"><img src="../Images/70e1ef220250729c6c56a5fe6f2e9155.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ubClK4usLjLLY2TtTuBeDw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图12:假图像及其灰度蒙版的样本。</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/98cda007e3ed5342ef34a27d131dd49a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aTn7ags_seeEIkARWe7yvQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图13:从图11所示的样本中提取的几个<strong class="bd jx"> </strong>补丁<strong class="bd jx"> (128X128) </strong></figcaption></figure><p id="9d05" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">经过10个时期的训练后，我获得了近50%的准确性，现在我们获得了模型的原始行为，当然，我们可以使用修补后的数据进一步提高准确性，对不同的模型进行实验，但要获得最终结果，我们需要将所有预测的补丁合并为一个。</p><p id="6ccd" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated"><strong class="kp hj">由于我们已经从图像中消除了大部分的补片，也就是说我们只考虑了具有被操纵和被认证的像素的补片，从这些预测的补片构建最终的掩模一点也不容易。</strong></p><h2 id="0a73" class="ml jw hi bd jx mm mn mo kb mp mq mr kf kw ms mt kh la mu mv kj le mw mx kl my bi translated"><strong class="ak">经过以上三种方法的实验，我们了解到:</strong></h2><p id="8844" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">–在我们的数据中，由于操纵区域的比例较小，我们的基础模型无法正确学习。</p><p id="2d49" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">–在预测的遮罩(图11)中，我们可以看到网格状的方框，这是因为没有一个模型能够检测到物体本身。</p><p id="9637" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">–即使我们提取了补丁以平衡类别，但仍然很难从预测的补丁中构建最终的遮罩，因此我们不会进一步使用这些补丁方法。</p><p id="fabd" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">–由于我们几乎没有数据，如果我们有任何已经根据类似数据预先训练过的模型，这可能是有益的，这样我们就可以根据我们的数据微调权重，这可能会奏效</p><h2 id="89db" class="ml jw hi bd jx mm mn mo kb mp mq mr kf kw ms mt kh la mu mv kj le mw mx kl my bi translated">VGG16+UNET</h2><p id="dc5e" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">在理解以上所有要点的基础上，为了选择下一个模型，我们将考虑这样的想法，假设模型可以理解其中的不同对象，然后作为下一步，如果模型可以分割这些对象，无论它们是否被操纵。</p><p id="bad6" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">为了采用这个想法，我们应该使用一个对象检测网络，并且对于下一个任务，我们可以附加一些UNET，它将像分割网络一样工作。</p><p id="c3a2" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">现在，我将尝试使用<strong class="kp hj"> VGG16 </strong>作为主干，它在imagenet数据上进行预训练，并在将输入图像发送到分割网络之前对其进行编码。在我们的情况下，它是UNET架构，因此我们可以在组合架构上进行训练，以保持vgg16 imagenet权重不变。</p><p id="5c6a" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">在这里，我使用"<strong class="kp hj"> segmentation_models </strong> "[7]包，以便它将为我们提供所需的实用程序，从这个包中，我们可以选择vgg16或类似的imagenet权重作为主干，并可以与UNET等细分模型相结合。利用这一优势，我在VGG16(用imagenet权重固定)+UNET上训练了数据，这一次，由于我们的数据不平衡，我正在测量<strong class="kp hj"> f1得分</strong>，并用<strong class="kp hj">亚当</strong>进行优化，减少<strong class="kp hj">二进制交叉熵</strong>，并运行10个时期。</p><p id="53a0" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">最后，它在测试数据上给出了一个非常好的f1值，大约为0.9746，并且我们的最终模型很好地定位了伪造品。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ne"><img src="../Images/cd568a9d2a125c1d06e2386853e382a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*wlANnZDVHYwP-t-BiU4EpA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图14:来自<strong class="bd jx"> VGG16+UNET </strong>模型的预测掩码与地面真实掩码的比较</figcaption></figure><p id="922a" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">正如我们在图14中看到的，我们的最终模型，即VGG16+UNET，比之前的两个模型更有效地定位了被操纵的区域。请注意，如果我们在数据语料库中有大量的虚假图像，那么将有更高的机会进行更好的学习。即使我们用很少的数据进行训练，这个模型确实在定位伪造品方面做得不错。</p><h1 id="3285" class="jv jw hi bd jx jy ma ka kb kc mb ke kf io mc ip kh ir md is kj iu me iv kl km bi translated">未来范围</h1><p id="342d" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">到目前为止，我们在数据中看到的经过处理的图像质量稍高，要检查低质量图像是否受到攻击，我们的方法可能效率不高。我们可以扩展这种方法，在将它发送到我们的最终模型之前，再包含一个被学习来将低质量转换为高质量的模型。</p><p id="739c" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">到目前为止，我们只看到了三种类型的攻击，但在未来，我们不确定是否会有大量的操纵技术可能由人类或使用人工智能本身进化而来。因此我们未来的模型应该对任何类型的攻击都是不可知的。</p></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><p id="b180" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">本博客中提到的所有步骤的代码(在tensorflow+keras中可用)都发布在我的Github个人资料中，请随意访问代码，如果您愿意，您可以使用/修改以供个人使用。</p><div class="nf ng ez fb nh ni"><a href="https://github.com/pothabattulasantosh/Image-forgery-localization-IFL-using-UNET-architecture" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hj fi z dy nn ea eb no ed ef hh bi translated">pothabattulasantosh/图像-伪造-本地化-IFL-使用-UNET-建筑</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">这是使用深度学习技术和架构实现的图像伪造定位的解决方案之一…</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">github.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw jh ni"/></div></div></a></div><h1 id="fc39" class="jv jw hi bd jx jy ma ka kb kc mb ke kf io mc ip kh ir md is kj iu me iv kl km bi translated">参考</h1><p id="fe24" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">[1]<a class="ae jn" href="http://ifc.recod.ic.unicamp.br/fc.website/index.py?sec=5" rel="noopener ugc nofollow" target="_blank">http://ifc.recod.ic.unicamp.br/fc.website/index.py?sec=5</a></p><p id="c7e0" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">[2]<a class="ae jn" href="https://www.baslerweb.com/en/sales-support/knowledge-base/frequently-asked-questions/what-is-prnu/14988/" rel="noopener ugc nofollow" target="_blank">https://www . basler web . com/en/sales-support/知识库/常见问题/what-is-prnu/14988/ </a></p><p id="75ec" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">[3]<a class="ae jn" href="https://www.researchgate.net/publication/231596743_PRNU-based_detection_of_small_size_image_forgeries" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/publication/231596743 _ PRNU _ detection _ of _ small _ size _ image _ forgeries</a></p><p id="0662" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">[4]<a class="ae jn" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Rex_Yue_Wu_BusterNet_Detecting_Copy-Move_ECCV_2018_paper.pdf" rel="noopener ugc nofollow" target="_blank">http://open access . the CVF . com/content _ ECCV _ 2018/papers/Rex _岳_吴_ BusterNet _ Detecting _ Copy-Move _ ECCV _ 2018 _ paper . pdf</a></p><p id="6f0a" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">[5]https://arxiv.org/pdf/1505.04597.pdf<a class="ae jn" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank"/></p><p id="ad7f" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">[6]<a class="ae jn" href="https://albumentations.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://albumentations.readthedocs.io/en/latest/</a></p><p id="ebf9" class="pw-post-body-paragraph kn ko hi kp b kq lt ij ks kt lu im kv kw lv ky kz la lw lc ld le lx lg lh li hb bi translated">[7]<a class="ae jn" href="https://segmentation-models.readthedocs.io/en/latest/tutorial.html" rel="noopener ugc nofollow" target="_blank">https://segmentation-models . readthedocs . io/en/latest/tutorial . html</a></p></div></div>    
</body>
</html>