<html>
<head>
<title>Text Generation with OpenAI’s GPT-2 in Production</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在生产中使用OpenAI的GPT-2生成文本</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/text-generation-with-openais-gpt-2-in-production-1379e0df103d?source=collection_archive---------4-----------------------#2019-11-15">https://medium.com/analytics-vidhya/text-generation-with-openais-gpt-2-in-production-1379e0df103d?source=collection_archive---------4-----------------------#2019-11-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1e065467e2fa656168d6f548f037334c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6CQ4ajkVZU8aV5w7C0OSGg.jpeg"/></div></div></figure><p id="80ca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Open AI最近刚刚发布了最大版本的GPT-2，其中有1.5亿个参数，而9个月前它发布了最小版本，其中有1.24亿个参数。回到2019年2月，埃隆·马斯克(Elon Musk)的OpenAI发布声明称，OpenAI的GPT-2在生成文本方面如此出色，以至于发布它是危险的。这就是最大型号推迟发布的原因。它现在就在这里，它是否危险，只有时间能证明。研究是伟大的，但是把它投入生产并在生产系统中使用才是真正的不同。</p><p id="0593" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇博客中，我将与你分享将开放的AIs GPT 2投入生产的技巧、诀窍和工具，并免费给你一个工作的<strong class="is hj"> Docker容器映像</strong>，你可以<strong class="is hj">将它部署到你的生产环境</strong>。在我们深入技术实现之前，让我们看看什么是文本生成，以及开放的人工智能GPT 2模型如何促进它。</p><p id="c94f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">什么是OpenAI？</strong></p><p id="e70c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">OpenAI是一家位于美国旧金山的人工智能研究公司。OpenAI的使命是确保人工通用智能(AGI)造福全人类。我们所说的AGI指的是在大多数有经济价值的工作中胜过人类的高度自治的系统。</p><p id="9ec0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">什么是GPT新协议模式？</strong></p><p id="1ff5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">GPT-2是一个大型的基于转换器的语言模型，具有15亿个参数，在800万个网页的数据集上进行训练。GPT-2训练有一个简单的目标:预测下一个单词，给定一些文本中的所有以前的单词。数据集的多样性导致这个简单的目标包含跨不同领域的许多任务的自然发生的演示。GPT-2是GPT的直接放大版，参数超过10倍，数据量超过10倍。由OpenAI开发的GPT-2是一个预先训练好的语言模型。</p><p id="05c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">“GPT-2在各种特定领域的语言建模任务上取得了一流的成绩。我们的模型没有针对这些任务的任何特定数据进行训练，只是作为最终测试对其进行评估；这就是所谓的“零射击”设置。在特定领域数据集(如维基百科、新闻、书籍)上进行评估时，GPT-2的表现优于在这些数据集上训练的模型。”—开放AI团队。</em></p><p id="06e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有关该模型的架构和工作的更多信息，请阅读OpenAI发表的<a class="ae jp" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>。</p><p id="b1d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在实践层面上，它可以完成各种自然语言处理任务，例如:</p><ul class=""><li id="c8b5" class="jq jr hi is b it iu ix iy jb js jf jt jj ju jn jv jw jx jy bi translated">文本生成</li><li id="7bd4" class="jq jr hi is b it jz ix ka jb kb jf kc jj kd jn jv jw jx jy bi translated">语言翻译</li><li id="f0b6" class="jq jr hi is b it jz ix ka jb kb jf kc jj kd jn jv jw jx jy bi translated">阅读理解</li><li id="d670" class="jq jr hi is b it jz ix ka jb kb jf kc jj kd jn jv jw jx jy bi translated">构建问答系统</li><li id="4ce3" class="jq jr hi is b it jz ix ka jb kb jf kc jj kd jn jv jw jx jy bi translated">写作辅助</li><li id="9b6d" class="jq jr hi is b it jz ix ka jb kb jf kc jj kd jn jv jw jx jy bi translated">创造性写作和艺术</li><li id="275c" class="jq jr hi is b it jz ix ka jb kb jf kc jj kd jn jv jw jx jy bi translated">娱乐:创造游戏、聊天机器人和娱乐一代。</li></ul><p id="275f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里有一个例子，说明模型如何在给出一个短句后生成一个故事或文本。</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ke"><img src="../Images/38346d5b33f1f38fd4506c32e6554bdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p-EjkyYABi1yqomkrlOtCA.png"/></div></div></figure><p id="00bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了快速获得感觉，你可以在这里试验这个模型:<a class="ae jp" href="https://talktotransformer.com/" rel="noopener ugc nofollow" target="_blank">https://talktotransformer.com/</a></p><h1 id="f0d6" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">现在让我们将它部署到生产环境中。</h1><figure class="kf kg kh ki fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/e0218b84dd858124ebfe4fb8bcde39ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtyIsDcTOTz3Wu04FmO0hw.png"/></div></div></figure><p id="e193" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将使用python进行应用和部署。我们使用Flask应用程序在Apache web服务器(适用于生产，可以处理大量请求)上推断GPT-2模型，Docker将其封装并部署在Kubernetes集群上，该集群处理服务编排和扩展。为了开始，</p><p id="63c7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">克隆这个库:【https://github.com/emmanuelraj7/opengpt2.git T2】</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="e4bb" class="ln kk hi lj b fi lo lp l lq lr">git clone https://github.com/emmanuelraj7/opengpt2.git</span></pre><p id="302d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">关键文件…</p><p id="19aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a)download _ models . py-下载所需的模型工件。</p><p id="0bec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">b)<a class="ae jp" href="https://github.com/emmanuelraj7/opengpt2/blob/master/flask_demo/flask_predict_api.py" rel="noopener ugc nofollow" target="_blank">flask _ predict _ API . py</a>—基于Flask的web应用，以REST API的形式提供GPT-2模型即服务</p><h1 id="9796" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">要在本地运行它…</h1><p id="c5a6" class="pw-post-body-paragraph iq ir hi is b it ls iv iw ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn hb bi translated">所有步骤都可以使用virtualenv或conda等工具在虚拟环境中完成。拥有python 3.6版本(不是3.7)。安装tensorflow 1.12(有GPU支持，如果你有GPU，希望一切运行得更快)</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="d911" class="ln kk hi lj b fi lo lp l lq lr">pip3 install tensorflow==1.12.0</span></pre><p id="c60b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">或者</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="efb7" class="ln kk hi lj b fi lo lp l lq lr">pip3 install tensorflow-gpu==1.12.0</span></pre><p id="3cb2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">安装其他需要的python包</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="41d7" class="ln kk hi lj b fi lo lp l lq lr">cd flask_demo<br/>pip3 install -r requirements.txt</span></pre><p id="8354" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下载模型数据:下载具有124，355，774百万和15亿个参数的模型</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="40f9" class="ln kk hi lj b fi lo lp l lq lr">python3 download_model.py 124M<br/>python3 download_model.py 355M<br/>python3 download_model.py 774M<br/>python3 download_model.py 1558M</span></pre><p id="4c31" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">运行推理-API</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="2ae6" class="ln kk hi lj b fi lo lp l lq lr">python flask_predict_api.py</span></pre><h1 id="4fc0" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">在生产中运行它…</h1><h1 id="53a3" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">1.建立码头工人形象</h1><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="db00" class="ln kk hi lj b fi lo lp l lq lr">FROM continuumio/anaconda3:4.4.0<br/>MAINTAINER Emmanuel Raj, AI Engineer<br/>EXPOSE 8000<br/>RUN apt-get update &amp;&amp; apt-get install -y apache2 \<br/>	    apache2-dev \   <br/>	    vim \<br/>	 &amp;&amp; apt-get clean \<br/>	 &amp;&amp; apt-get autoremove \<br/>	 &amp;&amp; rm -rf /var/lib/apt/lists/*<br/>WORKDIR /var/www/flask_predict_api/<br/>COPY ./flask_predict_api.wsgi /var/www/flask_predict_api/flask_predict_api.wsgi<br/>COPY ./flask_demo /var/www/flask_predict_api/<br/>RUN pip install -r requirements.txt<br/>RUN python3 download_model.py 124M<br/>RUN python3 download_model.py 355M<br/>RUN python3 download_model.py 774M<br/>RUN python3 download_model.py 1558M<br/>RUN /opt/conda/bin/mod_wsgi-express install-module<br/>RUN mod_wsgi-express setup-server flask_predict_api.wsgi --port=8000 \<br/>	    --user www-data --group www-data \<br/>	    --server-root=/etc/mod_wsgi-express-80<br/>	<br/>CMD /etc/mod_wsgi-express-80/apachectl start -D FOREGROUND</span></pre><p id="3e53" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面的docker文件，我们建立一个docker映像来部署。首先，我们使用来自Docker hub的预制容器映像continuumio/anaconda3:4.4.0，我们公开Apache server将在其中运行服务器的端口8000，然后安装Apache，为Docker容器创建一个工作目录，从repo复制所有需要的文件，并从requirements.txt安装所有需要的依赖项。</p><p id="b75c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们通过使用文件download_model.py下载所需的工件——模型文件。我们通过文件——flask _ predict _ API . WSGI创建web服务器网关接口(WSGI ),使用apache服务器托管我们的web应用程序，因为flask开发服务器不适合生产。然后，我们用Apache服务器将flask应用程序封装到docker容器中，并在端口8000运行它。</p><p id="9738" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要运行构建此docker映像:</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="f685" class="ln kk hi lj b fi lo lp l lq lr">docker build --tag openai-gpt2 .</span></pre><p id="eff9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将此docker映像推送到Docker hub或您需要的Docker注册表。从那里，它应该准备好部署到Kubernetes集群。</p><p id="41c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要在本地运行它:</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="5876" class="ln kk hi lj b fi lo lp l lq lr">docker run -d -p 8000:8000 containerid</span></pre><p id="6523" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个应用程序有Swagger UI，通过它您可以在:<a class="ae jp" href="http://localhost:8000/apidocs/" rel="noopener ugc nofollow" target="_blank">http://localhost:8000/API docs/</a>上使用和测试服务</p><p id="3a74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">或者简单地用“input_text”和“model_name”参数向端点“get_text_generate”发出get请求。例如:</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="a519" class="ln kk hi lj b fi lo lp l lq lr"><a class="ae jp" href="http://localhost:8000/text-generate?input_text=where%20is%20finland%3F&amp;model_name=124M" rel="noopener ugc nofollow" target="_blank">http://localhost:8000/text-generate?input_text=where%20is%20finland%3F&amp;model_name=124M</a></span></pre><p id="8954" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将docker映像上传到集线器/注册表:</p><pre class="kf kg kh ki fd li lj lk ll aw lm bi"><span id="7e64" class="ln kk hi lj b fi lo lp l lq lr">docker push openai-gpt2:latest</span></pre><h1 id="3a82" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">2.将Docker容器映像部署到Kubernetes集群</h1><p id="a307" class="pw-post-body-paragraph iq ir hi is b it ls iv iw ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn hb bi translated">Kubernetes是一个开源的容器编排系统，用于自动化应用程序部署、伸缩和管理。您可以使用您选择的理想工具来部署它，例如:Kubectl、Helm或Kompose。</p><p id="cc24" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是我的Kubernetes集群的仪表板视图，我在其中部署了服务(使用Helm ),该服务可以自动伸缩，并准备好一次处理多个大量的请求。</p><figure class="kf kg kh ki fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/1110e450769f36112b34cede0e859603.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*127J9A5NKv5-OzZB6tr9Mg.png"/></div></div></figure><p id="917f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感谢阅读。这是我很高兴与你分享把开放人工智能的GPT-2模型投入生产。我很乐意帮助你将最先进的人工智能模型应用到生产中。如果有任何问题，请随时联系我。</p></div></div>    
</body>
</html>