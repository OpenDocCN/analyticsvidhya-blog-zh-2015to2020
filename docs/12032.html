<html>
<head>
<title>Text Classification — From Bag-of-Words to BERT — Part 1 (BagOfWords)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本分类—从词袋到BERT —第1部分(词袋)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/text-classification-from-bag-of-words-to-bert-1e628a2dd4c9?source=collection_archive---------3-----------------------#2020-12-29">https://medium.com/analytics-vidhya/text-classification-from-bag-of-words-to-bert-1e628a2dd4c9?source=collection_archive---------3-----------------------#2020-12-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><figure class="im in io ip fd iq er es paragraph-image"><div role="button" tabindex="0" class="ir is di it bf iu"><div class="er es il"><img src="../Images/87c8de222f647b8c3fa7818795ea3c42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yTqRTDlvepfXMP0F"/></div></div><figcaption class="ix iy et er es iz ja bd b be z dx translated">爱德华·乔佩蒂亚在<a class="ae jb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="fa12" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">什么是文本分类？</p><blockquote class="ka kb kc"><p id="5501" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz ha bi translated"><a class="ae jb" href="https://monkeylearn.com/text-classification/" rel="noopener ugc nofollow" target="_blank">文本分类</a>也称为<em class="hh">文本标记</em>或<em class="hh">文本分类</em>是将文本分类成有组织的组的过程。通过使用自然语言处理(NLP)，文本分类器可以自动分析文本，然后根据其内容分配一组预定义的标签或类别。</p></blockquote><p id="a42d" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">少数应用:</p><ol class=""><li id="7b36" class="kh ki hh je b jf jg jj jk jn kj jr kk jv kl jz km kn ko kp bi translated">电子商务、新闻机构、内容管理者、博客、目录等平台可以使用自动化技术对内容和产品进行分类和标记。</li><li id="b508" class="kh ki hh je b jf kq jj kr jn ks jr kt jv ku jz km kn ko kp bi translated">通过对社交媒体上的恐慌对话进行分类，可以建立更快的应急响应系统。</li><li id="2372" class="kh ki hh je b jf kq jj kr jn ks jr kt jv ku jz km kn ko kp bi translated">营销人员可以根据用户在线谈论产品或品牌的方式对他们进行监控和分类。</li></ol><p id="d5a2" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">还有更多</p><p id="ea70" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">问题陈述:</strong>为了练习，我们将使用Kaggle竞赛命名为“<a class="ae jb" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge" rel="noopener ugc nofollow" target="_blank"> <em class="kd">【有毒评论分类挑战】</em> </a> <em class="kd"> </em>【由Jigsaw(字母表的附属)<strong class="je hi"> <em class="kd">。</em> </strong>在这场比赛中，我们面临的挑战是建立一个多头模型，能够检测不同类型的毒性，如<em class="kd">威胁、淫秽、侮辱和基于身份的仇恨。</em>该数据集包含来自维基百科谈话页面编辑的<em class="kd"> </em>评论。(因此，除了文本分类，我们还将学习如何实现多输出/多标签分类)</p><p id="878a" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> <em class="kd">免责声明:本次比赛的数据集包含可能被视为亵渎、粗俗或冒犯的文本。我不鼓励这样的话，这只是为了实验的目的。</em>T29】</strong></p><p id="f7cb" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">评估:</strong>根据平均列方式<a class="ae jb" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html" rel="noopener ugc nofollow" target="_blank"> ROC AUC </a>评估提交。换句话说，分数是每个预测列的单个AUC的平均值。</p><p id="cf6b" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">模型:</strong>模型按照复杂程度递增的顺序被提及</p><ol class=""><li id="376e" class="kh ki hh je b jf jg jj jk jn kj jr kk jv kl jz km kn ko kp bi translated">一袋单词</li><li id="2f58" class="kh ki hh je b jf kq jj kr jn ks jr kt jv ku jz km kn ko kp bi translated"><a class="ae jb" rel="noopener" href="/analytics-vidhya/text-classification-from-bag-of-words-to-bert-part-2-word2vec-35c8c3b34ee3"> Word2Vec嵌入</a></li><li id="db08" class="kh ki hh je b jf kq jj kr jn ks jr kt jv ku jz km kn ko kp bi translated"><a class="ae jb" rel="noopener" href="/analytics-vidhya/text-classification-from-bag-of-words-to-bert-part-3-fasttext-8313e7a14fce">快速文本嵌入</a></li><li id="7d25" class="kh ki hh je b jf kq jj kr jn ks jr kt jv ku jz km kn ko kp bi translated"><a class="ae jb" href="https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-part-4-convolutional-neural-network-53aa63941ade" rel="noopener">卷积神经网络</a></li><li id="1fe6" class="kh ki hh je b jf kq jj kr jn ks jr kt jv ku jz km kn ko kp bi translated"><a class="ae jb" rel="noopener" href="/analytics-vidhya/text-classification-from-bag-of-words-to-bert-part-5-recurrent-neural-network-b825ffc8cb26">长短期记忆(LSTM) </a></li><li id="72d3" class="kh ki hh je b jf kq jj kr jn ks jr kt jv ku jz km kn ko kp bi translated"><a class="ae jb" rel="noopener" href="/analytics-vidhya/text-classification-from-bag-of-words-to-bert-part-6-bert-2c3a5821ed16">变压器的双向编码器表示(BERT) </a></li></ol><p id="cf46" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">那么，让我们开始吧😁</p><blockquote class="ka kb kc"><p id="14b3" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz ha bi translated"><strong class="je hi"> 1。一袋字</strong></p></blockquote><p id="1753" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">单词袋模型是最常用的文本分类方法，其中每个单词的出现频率被用作训练分类器的特征。</p><p id="db9a" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">直觉:</strong></p><figure class="im in io ip fd iq er es paragraph-image"><div role="button" tabindex="0" class="ir is di it bf iu"><div class="er es kv"><img src="../Images/cce5f01cb67c22b94eee29b3ca4f582e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gUt1ghyEMqn2ARQyLAOnCw.png"/></div></div></figure><p id="9630" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">当然，除此之外还有预处理。但是图表给出了一个基本的理解。让我们深入研究一下实现</p><p id="f1b1" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">实施:</strong></p><p id="464b" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我们将使用CountVectorizer(单词包的sklearn实现)模型将文本转换为数字数据集，然后可以根据输出变量<strong class="je hi"> toxic、severe_toxic、淫秽、威胁、侮辱、identity_hate、</strong>进行映射，并且可以使用任何模型来学习输出变量的依赖性，即在这种情况下毒性类型对单词出现的依赖性。目前，我们将在CountVectorizer创建的数据集上使用<strong class="je hi">朴素贝叶斯和逻辑回归</strong>，并选择在验证数据集上给出最佳结果的一个来预测测试数据集。我们将使用sklearn的<strong class="je hi">多输出分类器</strong>包装器为所有6个输出变量创建模型。对于对完整代码感兴趣的人，你可以在这里找到它。</p><ol class=""><li id="432a" class="kh ki hh je b jf jg jj jk jn kj jr kk jv kl jz km kn ko kp bi translated"><strong class="je hi">读取数据集</strong></li></ol><figure class="im in io ip fd iq er es paragraph-image"><div role="button" tabindex="0" class="ir is di it bf iu"><div class="er es kw"><img src="../Images/0543de08e345f6b77adbe68a2a0922ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1oEsT7kJsaTm2saQmCu36g.png"/></div></div><figcaption class="ix iy et er es iz ja bd b be z dx translated">训练数据集</figcaption></figure><p id="848f" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我们有大约16万份训练文本和15.3万份测试文本</p><p id="35ce" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> 2。基本预处理</strong></p><p id="98df" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">像任何其他ML任务一样，预处理是NLP中至关重要的步骤之一。在NLP中，通过将所有字符转换为小写、删除标点符号以及删除停用词和错别字，它有助于去除数据中无用的部分，或<em class="kd">噪音</em>。在这种情况下，标点符号和数字与停用词(如In、the、of)一起被删除，以便这些词可以从文本中删除，因为这些词无助于确定类别(一个句子是否有毒)</p><pre class="im in io ip fd kx ky kz la aw lb bi"><span id="3000" class="lc ld hh ky b fi le lf l lg lh">stop_words = stop_words.ENGLISH_STOP_WORDS</span><span id="5463" class="lc ld hh ky b fi li lf l lg lh"><em class="kd">#Function for basic cleaning/preprocessing texts<br/></em>def clean(doc):<br/>    <em class="kd"># Removal of punctuation marks (.,/\][{} etc) and numbers</em><br/>    doc = "".join([char for char <strong class="ky hi">in</strong> doc if char <strong class="ky hi">not</strong> <strong class="ky hi">in</strong> string.punctuation <strong class="ky hi">and</strong> <strong class="ky hi">not</strong> char.isdigit()])<br/>    <em class="kd"># Removal of stopwords</em><br/>    doc = " ".join([token for token <strong class="ky hi">in</strong> doc.split() if token <strong class="ky hi">not</strong> <strong class="ky hi">in</strong> stop_words])<br/>    return doc.lower()</span></pre><p id="cd87" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> 3。创建一个单词包向量</strong></p><p id="9065" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">创建一个最多包含5000个最常用单词的单词包模型(因为包含所有单词会使数据集变得稀疏，只会增加噪声)。此外，在使用一包单词创建数据集时，清理数据集</p><pre class="im in io ip fd kx ky kz la aw lb bi"><span id="7b91" class="lc ld hh ky b fi le lf l lg lh">vect = CountVectorizer(max_features= 5000, preprocessor=clean)<br/>X_train_dtm = vect.fit_transform(X_train)<br/>X_val_dtm = vect.transform(X_val)<br/><br/>print(X_train_dtm.shape, X_val_dtm.shape)<br/>#(119678, 5000) (39893, 5000)</span></pre><figure class="im in io ip fd iq er es paragraph-image"><div role="button" tabindex="0" class="ir is di it bf iu"><div class="er es lj"><img src="../Images/5abeb3df629a77d417e62e94f582be14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6lnlFxJlNzQ4irLM9UuVQ.png"/></div></div><figcaption class="ix iy et er es iz ja bd b be z dx translated">词汇袋向量</figcaption></figure><p id="c291" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">以上，我们可以看到单词袋。例如，abide在第一句中出现了0次。这个单词包非常稀疏(如果需要，我们可以进一步减少max_features)。这将是机器学习分类器的输入</p><p id="3913" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> 4。创建多输出分类器</strong></p><p id="7df2" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">由于我们需要将每个句子分类为有毒与否、严重有毒与否、猥亵与否、威胁与否、侮辱与否以及身份仇恨与否，因此我们需要针对6个输出变量对句子进行分类(这称为多标签分类，不同于多类别分类，多类别分类中目标变量有2个以上的选项，例如句子可以是正面的、负面的和中性的)</p><p id="c720" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">同样，我们将使用sklearn的MultiOutputClassifier，正如前面提到的，它是一个包装器。该策略包括为每个目标安装一个分类器。注意:我也尝试过使用支持向量分类器，但是那花费了很多时间来训练，却没有给出最好的结果</p><pre class="im in io ip fd kx ky kz la aw lb bi"><span id="d70f" class="lc ld hh ky b fi le lf l lg lh"><em class="kd">#Initializing and fitting models on Training Data</em><br/><em class="kd">#Naive Bayes Model</em><br/>nb = MultiOutputClassifier(MultinomialNB()).fit(X_train_dtm, y_train)<br/><em class="kd">#Logistic Regression Model (As we have unbalanced dataset, we use class_weight which will use inverse of counts of that class. It penalizes mistakes in samples of class[i] with class_weight[i] instead of 1)</em><br/>lr = MultiOutputClassifier(LogisticRegression(class_weight='balanced', max_iter=3000)) \<br/>                    .fit(X_train_dtm, y_train)</span></pre><p id="6102" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> 5。测量验证数据集的性能</strong></p><p id="3b35" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">由于竞争对手使用ROC-AUC作为评估指标，我们将在笔记本中使用相同的指标。我们将比较我们训练的所有3个模型的平均ROC-AUC。我们将使用模型的<em class="kd"> predict_proba </em>函数，而不是<em class="kd"> predict </em>函数，后者根据阈值0.5给出概率得分，而不是预测值，因为roc_auc_measure使用它。</p><pre class="im in io ip fd kx ky kz la aw lb bi"><span id="2ea7" class="lc ld hh ky b fi le lf l lg lh"><em class="kd">#Function for calculating roc auc with given actual binary values across target variables and the probability score made by the model</em><br/>def calculate_roc_auc(y_test, y_pred):<br/>    aucs = []<br/>    <em class="kd">#Calculate the ROC-AUC for each of the target column</em><br/>    for col <strong class="ky hi">in</strong> range(y_test.shape[1]):<br/>        aucs.append(roc_auc_score(y_test[:,col],y_pred[:,col]))<br/>    return aucs</span></pre><p id="3218" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">给定性能指标，让我们在验证数据集上运行模型</p><pre class="im in io ip fd kx ky kz la aw lb bi"><span id="0d29" class="lc ld hh ky b fi le lf l lg lh"><em class="kd">#Creating an empty list of results</em><br/>results = []<br/><em class="kd">#Making predictions from all the trained models and measure performance for each</em><br/>for model <strong class="ky hi">in</strong> [nb,lr]:<br/>    <em class="kd">#Extracting name of the model</em><br/>    est = type(model.estimator).__name__<br/>    <em class="kd">#Actual output variables</em><br/>    y_vals = y_val.to_numpy()<br/>    <em class="kd">#Model Probabilities for class 1 of each of the target variables</em><br/>    y_preds = np.transpose(np.array(model.predict_proba(X_val_dtm))[:,:,1])<br/>    <em class="kd">#Calculate Mean of the ROC-AUC</em><br/>    mean_auc = mean(calculate_roc_auc(y_vals,y_preds))<br/>    <em class="kd">#Append the name of the model and the mean_roc_auc into the results list</em><br/>    results.append([est, mean_auc])</span></pre><figure class="im in io ip fd iq er es paragraph-image"><div class="er es lk"><img src="../Images/53596383675bd2998f3e246c47a17849.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*7QeOlPziXUZFRPLGhN1SWA.png"/></div><figcaption class="ix iy et er es iz ja bd b be z dx translated">验证结果</figcaption></figure><p id="87cf" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">正如我们所看到的，两种型号的表现都很好，LR的表现稍好一些。因此，我们将使用它作为最终模型来提交测试数据的预测。此外，这些简单的模型给出了相当好的结果，没有太多的麻烦或技术知识，这就是为什么他们仍然被广泛使用。</p><p id="5e2d" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">上一点<strong class="je hi">逻辑回归</strong>是没有坏处的。</p><p id="3bac" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><em class="kd">逻辑模型</em>(或logit模型)用于模拟某个类别或事件存在的概率，如通过/失败、赢/输、活着/死了、健康/生病。这可以扩展到建模几类事件，如确定图像是否包含猫、狗、狮子等。图像中检测到的每个对象将被分配0到1之间的概率，总和为1。</p><p id="b739" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">下图是逻辑回归最常用的图像</p><figure class="im in io ip fd iq er es paragraph-image"><div class="er es ll"><img src="../Images/23056677762b23279762b6b8b4bd8418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*xTwaKZZsIRek8jzrNWRPzQ.png"/></div><figcaption class="ix iy et er es iz ja bd b be z dx translated">逻辑模型</figcaption></figure><p id="e6e5" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">通过简单的变换，逻辑回归方程可以写成优势比。</p><figure class="im in io ip fd iq er es paragraph-image"><div class="er es lm"><img src="../Images/2fd434f451ca4a444993cc6ef1bae094.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/format:webp/1*S3YNoErM0h58rHhdW0_fww.png"/></div></figure><p id="b52a" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">最后，取两边的自然对数，我们可以用log-odds (logit)来写方程，它是预测值的线性函数。</p><figure class="im in io ip fd iq er es paragraph-image"><div class="er es ln"><img src="../Images/5f010b6d73a92972d9f7b1a83cfd70e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*Ol1r2AsRWiC0pm7dlzmyLw.png"/></div></figure><p id="6192" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">系数(b1)是x中一个单位变化时logit(对数优势)的变化量。</p><p id="be11" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">例如，如果等式是1+2x，即b0 = 1，b1 = 2。x增加1，对数优势增加2，Y=1的优势增加10倍。注意Y=1的概率也增加了，但是没有几率增加的多。</p><p id="d323" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">这是关于逻辑功能的。</p><p id="b0f2" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">现在，为了找到最佳分割线(换句话说，减少损失函数)，逻辑回归也使用梯度下降，但具有不同的损失函数(线性回归使用均方误差)。逻辑回归使用对数损失/最大似然估计(MLE)函数</p><figure class="im in io ip fd iq er es paragraph-image"><div role="button" tabindex="0" class="ir is di it bf iu"><div class="er es lo"><img src="../Images/dcc517bbb49b712dc288ea9127ac1610.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JWvYunYNRvkTz7ROGR43_w.png"/></div></div><figcaption class="ix iy et er es iz ja bd b be z dx translated">逻辑回归的成本函数</figcaption></figure><p id="4aaf" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">其中m是样本数(取平均值)，y是实际值，h(x)是模型的输出</p><p id="d265" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> 6。模型解读</strong></p><p id="1ca2" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">至少对我来说，这是最激动人心的部分。由于我们只是使用一个简单的逻辑回归模型，我们可以直接使用模型的系数值来了解所做的预测。通过这样做，我们可以知道哪个特征是重要的，或者哪个单词使一个句子变得有毒。如果我们使用复杂的模型，我们可以选择SHAP或莱姆。此外，由于我们有6个输出变量，我们将有6个特征重要性，这将是有趣的。我们将根据模型来看决定句子是否有毒的前5个单词。</p><pre class="im in io ip fd kx ky kz la aw lb bi"><span id="7869" class="lc ld hh ky b fi le lf l lg lh"><em class="kd">#Assigning the feature names to an empty list<br/></em>feat_impts = [vect.get_feature_names()]<br/><em class="kd">#For all the models save the feature importances in the #list.estimators_ would give the internal models used by the #multioutput regressor</em><br/>for clf <strong class="ky hi">in</strong> lr.estimators_:<br/>    feat_impts.append(clf.coef_.flatten())<br/><em class="kd">#Saving the coefficients in a dataframe</em><br/>df_feats_impts = pd.DataFrame(np.transpose(np.array(feat_impts)), columns = ["word","toxic","severe_toxic","obscene","threat","insult","identity_hate"])</span><span id="66e4" class="lc ld hh ky b fi li lf l lg lh"><em class="kd">#Creating Individual Feature Importance table by sorting on specific toxic-type column and selecting top 5 words</em><br/>toxic_fi = df_feats_impts[["word","toxic"]].sort_values(by = "toxic", ascending = False).head()</span></pre><p id="2946" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在上面代码的最后一次，我们已经为有毒输出变量创建了一个前5名特征重要性列表。类似地，我们可以为所有其他5种有毒类型创建一个数据框，根据各自模型的系数选择前5个单词。</p><figure class="im in io ip fd iq er es paragraph-image"><div role="button" tabindex="0" class="ir is di it bf iu"><div class="er es lp"><img src="../Images/a9da649927352cb1ea24002f01208a62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gQopsgbYWu3iikOxM0SH2w.png"/></div></div></figure><p id="7632" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我们可以看到，模型非常正确地选择了最重要的功能，这是完全有意义的。例如，对于威胁——像杀死、射杀、摧毁等词是最重要的。对于身份仇恨——如黑鬼，黑鬼，同性恋，同性恋。毒性的最重要的词没有重度毒性的最重要的词那么极端。</p><p id="935e" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> 7。改进的结果和范围</strong></p><figure class="im in io ip fd iq er es paragraph-image"><div class="er es lq"><img src="../Images/b3a017fb4ac94598cd71981aae593c42.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*wbCqk_kDFJuSK10tjLuHvw.png"/></div><figcaption class="ix iy et er es iz ja bd b be z dx translated">Kaggle排行榜上的结果</figcaption></figure><p id="fd1b" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><em class="kd"> TODOs: </em> <br/> 1。尝试用TF-IDF代替CountVectorizer <br/>在某些情况下，TF-IDF的性能往往优于count vectorizer<br/>2。尝试集合模型而不是普通的ML模型<br/>在大多数情况下，装袋和助推模型比经典的ML技术给出更好的结果<br/> 3。更好的文本预处理<br/>可以进行错别字纠正、词汇化等，以进一步改进模型</p><p id="ded5" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">这是关于单词袋的，下一个，将是关于Word2Vec的。在那之前保持安全。同样，整个代码都存在(这里的<a class="ae jb" href="https://www.kaggle.com/anirbansen3027/jtcc-bag-of-words" rel="noopener ugc nofollow" target="_blank">是</a>)。请以回答和鼓掌的形式提供您的反馈:)</p></div></div>    
</body>
</html>