<html>
<head>
<title>Face Recognition with VGG-Face in Keras.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Face Recognition with VGG-Face in Keras.</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-recognition-with-vgg-face-in-keras-96e6bc1951d5?source=collection_archive---------0-----------------------#2019-10-16">https://medium.com/analytics-vidhya/face-recognition-with-vgg-face-in-keras-96e6bc1951d5?source=collection_archive---------0-----------------------#2019-10-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e5e23d3129674207cda97ef1a759e410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j-sma006c-c8NPPbt3LSSA.jpeg"/></div></div></figure><h1 id="6b9b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">1. Get dataset/images of persons.</h1><p id="eba6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">I have collected images of top 5 most powerful leaders in the world Donald Trump, Vladimir Putin, Xi Jinping, Angela Merkel, Narendara Modi. Train dataset contains 10 images of each person and also to check model working also included my images. Name this folder as “Images” .</p><h1 id="4802" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2.Detect faces in image.</h1><p id="76e2" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">To get better predictions we first detect faces in image and use only faces for recognition. To do so we first detect faces in an image,for this we use ‘mmod_human_face_detector’ a cnn_face_detector which identifies faces in image and returns position of each face in image with finding rectangle bounding box as (left,top,right,bottom) positions. ‘dlib’ in python uses these weights and detect images,but dlib doesn’t provide this detector as in-built. We must download and provide to ‘dlib’ classes for extracting face. Download mmod_human_face_detector from here</p><blockquote class="km kn ko"><p id="7ec7" class="jo jp kp jq b jr kq jt ju jv kr jx jy ks kt kb kc ku kv kf kg kw kx kj kk kl hb bi translated"><a class="ae ky" href="http://dlib.net/files/mmod_human_face_detector.dat.bz2" rel="noopener ugc nofollow" target="_blank">‘http://dlib.net/files/mmod_human_face_detector.dat.bz2'</a></p></blockquote><p id="5094" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">As it is .bz2 file,extract it</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="7b03" class="li ir hi le b fi lj lk l ll lm">$ wget <a class="ae ky" href="http://dlib.net/files/mmod_human_face_detector.dat.bz2" rel="noopener ugc nofollow" target="_blank">http://dlib.net/files/mmod_human_face_detector.dat.bz2</a> <br/>$ bzip2 -dk mmod_human_face_detector.dat.bz2 </span></pre><h1 id="fc8c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">3. Extract faces from images.</h1><p id="d12d" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">Extract face from images,crop face and store as image in separate folder with image name as person name.</p><p id="c240" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">We use images with only one face</p><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="3e80" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">Above snippet shows how to extract face from image and save them for recognition. Do the same for all images in train dataset and test dataset saving with person names as image names. Store each person cropped image in a separate folder like Ex: All ‘modi_*.jpg’ images are saved in ‘modi’ folder.</p><p id="20fd" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">After extracting faces directory structures looks like:</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="4f08" class="li ir hi le b fi lj lk l ll lm">Directory structure :<br/>|Images /<br/>|  |-- (60 images)<br/>|Images_crop /<br/>|  |--angelamerkel (10 images)<br/>|  |--jinping / (10 images)<br/>|  |--lakshminarayana / (10 images)<br/>|  |--modi / (10 images)<br/>|  |--putin / (10 images) <br/>|  |--trump / (10 images)<br/>|Images_test / <br/>|  |-- .. / (18 images)<br/>|Images_test_crop / <br/>|  |--angelamerkel / (3 images)<br/>|  |--jinping / (3 images)<br/>|  |--lakshminarayana / (3 imgaes)<br/>|  |--modi / (3 images)<br/>|  |--putin / (3 images) <br/>|Face_Recognition.ipynb<br/>|mmod_human_face_detector.dat</span></pre><h1 id="9c97" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">4.Use VGG-face model to create embeddings for faces.</h1><p id="3b79" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">We create embeddings for each face/person which defines the person in numeric data. Pre-trained networks like DeepFace,OpenFace provides embeddings in less than 5 lines of code. But we use VGG_Face_net which trained on millions of images to recognize labelled faces in the wild (LFW). The original model takes an image in WildFace dataset on which VGG_face_net trained and classifies/recognize person in image. It ouputs 2622 embeddings for an image,we take this 2622 embeddings for each cropped_image for later classification of image. VGG_face_net weights are not available for tensorflow or keras models in official <a class="ae ky" href="https://www.robots.ox.ac.uk/~vgg/software/vgg_face/" rel="noopener ugc nofollow" target="_blank">site</a>, in this <a class="ae ky" href="https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/" rel="noopener ugc nofollow" target="_blank">blog</a> .mat weights are converted to .h5 file weights.<br/>Donwnload .h5 weights file for VGG_Face_net here</p><blockquote class="km kn ko"><p id="a024" class="jo jp kp jq b jr kq jt ju jv kr jx jy ks kt kb kc ku kv kf kg kw kx kj kk kl hb bi translated"><a class="ae ky" href="https://drive.google.com/uc?id=1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo" rel="noopener ugc nofollow" target="_blank">‘https://drive.google.com/uc?id=1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo’</a></p></blockquote><p id="6d24" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">因为它存储在google drive中，所以我们可以用python 'gdown '包下载到我们的本地存储中。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="6925" class="li ir hi le b fi lj lk l ll lm">$ gdown https://drive.google.com/ucid=1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo </span></pre><p id="009f" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">我们现在有了. h5的vgg_face_net权重，用它在keras/tensorflow中建立vgg_face_net模型。</p><h1 id="f9ec" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">5.构建vgg_face_architecture并获得faces的嵌入。</h1><p id="37a8" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">为了给模型分配权重，我们必须定义模型架构。keras中的VGG _人脸模型</p><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="be56" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">在输出层中，他们使用softmax层来识别WildFaces数据集中的图像。我们只需要倒数第二层输出的嵌入，即。展平()图层。所以我们的模型需要最后一个Flatten()层。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="f287" class="li ir hi le b fi lj lk l ll lm"># Remove last Softmax layer and get model upto last flatten layer #with outputs 2622 units </span><span id="8cca" class="li ir hi le b fi lp lk l ll lm">vgg_face=Model(inputs=model.layers[0].input,outputs=model.layers[-2].output) </span></pre><p id="bfed" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">在上面的行中，我们定义了模型直到Flatten()层。现在，我们可以输入任何图像来获得嵌入，这些嵌入将用于训练我们自己的分类器/识别器。</p><h1 id="9c3a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">6.准备训练数据和测试数据</h1><p id="75ad" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">准备训练数据和测试数据，这些数据包含作为每张脸的行的嵌入和作为人名的标签。</p><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="5953" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">之前，我们将每个裁剪的人脸图像存储在相应的个人文件夹中，遍历每个文件夹，并在每个文件夹中为每个图像从keras内置函数load_img()加载图像，该函数是具有<br/> <strong class="jq hj"> target_size=(224，224) </strong>的PIL图像，因为VGG_face_net期望图像形状为(224，224)格式。对于每个加载的图像，它被预处理成[ <strong class="jq hj"> -1，1]【T4]的尺度，并被馈送到vgg_face()模型，该模型输出<strong class="jq hj"> (1，2262) </strong>维张量，它被转换成列表并附加到训练和测试数据。此外，对于每个人，我们用数字标记该人，如</strong></p><blockquote class="km kn ko"><p id="f602" class="jo jp kp jq b jr kq jt ju jv kr jx jy ks kt kb kc ku kv kf kg kw kx kj kk kl hb bi translated">例如:{ 0:'莫迪'，1:'川普'，2:'安格拉马克尔'，3:'金平'，…。….}</p></blockquote><p id="9d7c" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">我们得到了(x_train，y_train)和(x_test，y_test)列表，为了在keras模型中使用，我们首先将它们转换成numpy数组。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="fc66" class="li ir hi le b fi lj lk l ll lm">x_train=np.array(x_train) <br/>y_train=np.array(y_train)<br/>x_test=np.array(x_test) <br/>y_test=np.array(y_test) </span></pre><h1 id="9dfe" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">7.训练softmax分类器。</h1><p id="ee60" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们最终得到的是训练数据和测试数据，其中人脸嵌入和标签作为人的编码。现在，我们训练简单的softmax分类器并保存模型，以获得对数据集中看不见的图像面部的预测。</p><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="f91e" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">我们训练softmax分类器对图像进行分类，它以人脸嵌入作为输入，输出对应的图像编号，图像编号编码为人名。</p><div class="lq lr ez fb ls lt"><a href="https://github.com/santhalakshminarayana/face-recognition" rel="noopener  ugc nofollow" target="_blank"><div class="lu ab dw"><div class="lv ab lw cl cj lx"><h2 class="bd hj fi z dy ly ea eb lz ed ef hh bi translated">santhalakshminarayana/面部识别</h2><div class="ma l"><p class="bd b fp z dy ly ea eb lz ed ef dx translated">在keras中用Vgg人脸网和dlib opencv人脸detection…github.com进行人脸识别</p></div></div><div class="mb l"><div class="mc l md me mf mb mg io lt"/></div></div></a></div><h1 id="cf07" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">8.识别面孔。</h1><p id="13cd" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在，我们可以识别图像中的任何人脸，如果我们在vgg_face模型的帮助下获得人脸的嵌入，并输入到分类器中，然后获得人名。用opencv在人脸周围画一个矩形框，并在图像中写下每个人脸的名字。</p><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="c449" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">在上面的代码片段中，它获取图像路径，并输出图像中识别的人脸，在人脸和人名周围有一个矩形框。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/dd487b36078cb7bd0fcda67165863b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OXK5dLfFmeMzlgsNIPV9Ow.png"/></div></div></figure><p id="5381" class="pw-post-body-paragraph jo jp hi jq b jr kq jt ju jv kr jx jy jz kt kb kc kd kv kf kg kh kx kj kk kl hb bi translated">我的形象</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/244426031c70d46d0e8d72b6a5f4a512.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*6AZZIP_cFtkTOjrLODxjdg.png"/></div></div></figure></div></div>    
</body>
</html>