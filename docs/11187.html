<html>
<head>
<title>MNIST classification using different activation functions and optimizers with implementation— Accuracy Comparison</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用不同激活函数和优化器的MNIST分类及其实现——精度比较</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/mnist-classification-using-different-activation-functions-and-optimizers-with-implementation-dc1ed7abc341?source=collection_archive---------3-----------------------#2020-11-22">https://medium.com/analytics-vidhya/mnist-classification-using-different-activation-functions-and-optimizers-with-implementation-dc1ed7abc341?source=collection_archive---------3-----------------------#2020-11-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="796a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我尝试使用keras版本2.4.0在Tensorflow版本2.3.1中创建一个模型，该模型是在MNIST数据集上训练的。这个数据集包含60000个手写数字的图像，从0到9，每个大小为28x28。</p><p id="d883" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我在最后一层(输出层)使用了3个不同的激活函数，即softmax、sigmoid和tanh。</p><blockquote class="jd je jf"><p id="06af" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">model 1 = TF . keras . models . sequential([<br/>TF . keras . layers . flatten(input _ shape =[28，28])，<br/> tf.keras.layers.Dense(300，activation="relu ")，<br/> tf.keras.layers.Dense(100，activation="relu ")，<br/> tf.keras.layers.Dense(10，activation = " soft max ")<br/>)</strong></p></blockquote><p id="fc03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的代码来看，最后一层的激活函数是softmax(推荐用于多类分类)</p><blockquote class="jd je jf"><p id="75ff" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">model 2 = TF . keras . models . sequential([<br/>TF . keras . layers . flatten(input _ shape =[28，28])，<br/> tf.keras.layers.Dense(300，activation="relu ")，<br/> tf.keras.layers.Dense(100，activation="relu ")，<br/> tf.keras.layers.Dense(10，activation = " sigmoid ")<br/>])【T13</strong></p></blockquote><p id="f102" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的代码来看，最后一层的激活函数是sigmoid(推荐用于二进制分类)</p><blockquote class="jd je jf"><p id="6917" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">model 3 = TF . keras . models . sequential([<br/>TF . keras . layers . flatten(input _ shape =[28，28])，<br/> tf.keras.layers.Dense(300，activation="relu ")，<br/> tf.keras.layers.Dense(100，activation="relu ")，<br/> tf.keras.layers.Dense(10，activation = " tanh))<br/>)【t23</strong></p></blockquote><p id="d66a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据上面的代码，最后一层的激活函数是tanh(推荐用于二进制分类)</p><p id="8805" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于以上创建的所有模型，使用相同的“稀疏分类交叉熵”损失函数和“SGD”(随机梯度下降)优化器。</p><blockquote class="jd je jf"><p id="ef8f" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">LOSS _ FUNCTION = " sparse _ category _ cross entropy "<br/>OPTIMIZER = " SGD "<br/>METRICS =[" accuracy "]<br/>model 1 . compile(LOSS = LOSS _ FUNCTION，<br/> optimizer=OPTIMIZER，<br/> metrics=METRICS) </strong></p></blockquote><p id="0390" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以上代码保持不变，只有'<strong class="ih hj"> model1.compile </strong>'会变成'<strong class="ih hj"> model2.compile </strong>'等等。</p><p id="9572" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这样做之后，该模型被训练30个时期</p><blockquote class="jd je jf"><p id="8336" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">EPOCHS = 30<br/>VALIDATION _ SET =(X _ valid，y _ valid)<br/>history = model 1 . fit(X _ train，y_train，epochs=EPOCHS，<br/>VALIDATION _ data = VALIDATION _ SET)</strong></p></blockquote><p id="bcdc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样'<strong class="ih hj"> model1.fit </strong>'也会改变</p><p id="7dbf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">30个纪元后</p><blockquote class="jd je jf"><p id="fca9" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">模型1-损耗:0.0278-精度:0.9936-val _损耗:0.0706-val _精度:0.9800 </strong></p><p id="6664" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">model 2-loss:0.0317-accuracy:0.9926-val _ loss:0.0712-val _ accuracy:0.9796</strong></p><p id="1500" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">model 3-loss:3.8495-精度:0.0990-val _ loss:3.7865-val _精度:0.0958 </strong></p></blockquote><p id="4b9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这表明softmax和sigmoid(令人惊讶地)表现良好，但tanh的精度为0.0990，这意味着模型几乎没有学到任何东西。当模型在'<strong class="ih hj"> X_test </strong>和'<strong class="ih hj"> y_test </strong>数据上进行测试时。只有<strong class="ih hj">模型3 </strong> ( <strong class="ih hj"> tanh </strong>)给出了错误的预测，而<strong class="ih hj"> sigmoid </strong>给出了低概率，例如</p><pre class="jk jl jm jn fd jo jp jq jr aw js bi"><span id="7870" class="jt ju hi jp b fi jv jw l jx jy">array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.47, 0.  , 0.  ],<br/>       [0.  , 0.  , 0.73, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],<br/>       [0.  , 0.26, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],<br/>      dtype=float32)</span><span id="464b" class="jt ju hi jp b fi jz jw l jx jy"><br/>#Here the array has 3 arrays inside it and each array shows the prediction, so the model says that the input data is 47 percent digit 7(based on the position) and so on</span></pre><figure class="jk jl jm jn fd kb er es paragraph-image"><div class="er es ka"><img src="../Images/d6c01c63c5d2fe534fa7ea2390bb1373.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*cpIUalA9RWCVNi8C6A2rzg.png"/></div></figure><p id="2d2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">而<strong class="ih hj"> softmax </strong>给出了高概率。</p><pre class="jk jl jm jn fd jo jp jq jr aw js bi"><span id="74b5" class="jt ju hi jp b fi jv jw l jx jy">array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],<br/>       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],<br/>       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)</span></pre><figure class="jk jl jm jn fd kb er es paragraph-image"><div class="er es ke"><img src="../Images/14abcc6a4b75923de3c1ebf16dd00688.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*PXOAXtW9jvOfKra_S_70GA.png"/></div></figure><p id="0774" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于tahn来说，概率是</p><pre class="jk jl jm jn fd jo jp jq jr aw js bi"><span id="0979" class="jt ju hi jp b fi jv jw l jx jy">array([[ 1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.],<br/>       [ 1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.],<br/>       [ 1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32)</span></pre><figure class="jk jl jm jn fd kb er es paragraph-image"><div class="er es kf"><img src="../Images/25de67d0d7c8196381921915d24a93e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*5N9MZrdNN_LlLZi_vWOC8Q.png"/></div></figure><p id="bf6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如你所看到的，model3在测试阶段表现不佳，它错误地预测了所有的数字0。</p><p id="22c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">再次进行相同的操作，但是使用的优化器是'<strong class="ih hj"> Adam </strong>'，softmax给出了相同的概率(预测)，但是sigmoid给出了比以前的sigmoid模型更好的概率，tanh没有显示出改进</p><p id="609f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于<strong class="ih hj">乙状结肠</strong></p><pre class="jk jl jm jn fd jo jp jq jr aw js bi"><span id="c407" class="jt ju hi jp b fi jv jw l jx jy">X_new = X_test[:3]<br/>y_proba = model2.predict(X_new)#where model2 uses sigmoid<br/>y_proba.round(2)</span></pre><p id="f757" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Out[67]:</p><pre class="jk jl jm jn fd jo jp jq jr aw js bi"><span id="7eaf" class="jt ju hi jp b fi jv jw l jx jy">array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],<br/>       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],<br/>       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)</span></pre><p id="41db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于<strong class="ih hj"> softmax </strong></p><pre class="jk jl jm jn fd jo jp jq jr aw js bi"><span id="08ab" class="jt ju hi jp b fi jv jw l jx jy">X_new = X_test[:3]<br/>y_proba = model1.predict(X_new) # where model uses sofmax<br/>y_proba.round(2)</span></pre><p id="8961" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Out[66]:</p><pre class="jk jl jm jn fd jo jp jq jr aw js bi"><span id="b878" class="jt ju hi jp b fi jv jw l jx jy">array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],<br/>       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],<br/>       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)</span></pre><p id="7858" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">而对于<strong class="ih hj">谭</strong></p><pre class="jk jl jm jn fd jo jp jq jr aw js bi"><span id="1a20" class="jt ju hi jp b fi jv jw l jx jy">X_new = X_test[:3]<br/>y_proba = model3.predict(X_new)#where model3 uses tanh<br/>y_proba.round(2)</span></pre><p id="932d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Out[68]:</p><pre class="jk jl jm jn fd jo jp jq jr aw js bi"><span id="02d1" class="jt ju hi jp b fi jv jw l jx jy">array([[ 1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.],<br/>       [ 1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.],<br/>       [ 1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32)</span></pre><p id="686e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">理解:<br/>当我们在多类分类的情况下使用softmax时，我们获得了非常好的准确性，但是当使用tanh时，我们获得了较差的准确性，sigmoid和tanh都主要在面临二分类问题时使用。在这种情况下，当<strong class="ih hj">乙状结肠</strong>与<strong class="ih hj"> SGD </strong>一起使用时，概率较低，但仍然可以分类，当<strong class="ih hj">乙状结肠</strong>与<strong class="ih hj"> Adam </strong>一起使用时，概率较高。(不知道这种情况下乙状结肠是怎么工作的)</p><p id="4e08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终点数<br/> 1。多级分类时使用soft max<br/>2。在二元分类的情况下，使用sigmoid或tanh</p></div></div>    
</body>
</html>