<html>
<head>
<title>MOST COMMON DATA SCIENCE QUESTION?(PART 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最常见的数据科学问题？(第一部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/most-common-data-science-question-part-1-e049e338af4f?source=collection_archive---------25-----------------------#2020-09-06">https://medium.com/analytics-vidhya/most-common-data-science-question-part-1-e049e338af4f?source=collection_archive---------25-----------------------#2020-09-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="bd51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与L2正则化相比，为什么L1正则化会产生稀疏性？</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/119cce91ce3c89c2cc52cc26478de4f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*O474eW71YETYnAywUZnxaw.png"/></div></figure><p id="8261" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以在机器学习中，我们有两种类型的正则化。L1(拉索)和L2(岭)正则化，所以在这篇文章中，我们要看看以下几点。</p><ol class=""><li id="ba97" class="jl jm hi ih b ii ij im in iq jn iu jo iy jp jc jq jr js jt bi translated"><strong class="ih hj"> <em class="ju">什么是SPARCITY？</em> </strong></li><li id="07a8" class="jl jm hi ih b ii jv im jw iq jx iu jy iy jz jc jq jr js jt bi translated"><strong class="ih hj"><em class="ju">L1和L2正规化有什么区别？</em>T9】</strong></li><li id="b9fd" class="jl jm hi ih b ii jv im jw iq jx iu jy iy jz jc jq jr js jt bi translated"><strong class="ih hj"><em class="ju">L1为什么创造了斯巴达，斯巴达的用处在哪里？</em>T13】</strong></li></ol><p id="97cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我假设你知道什么是正则化，如果你不知道什么是正则化，那么就把它理解为优化问题中的一个额外项，这有助于减少过度拟合。</p><p id="1baf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是逻辑回归优化问题中的L2正则化的图片，我已经在那里清楚地标记了正则化项。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ka"><img src="../Images/c720e9c3db2197d3f7c8f887075c7c81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C7kdJLs8fUOUuMzpnCKgxg.jpeg"/></div></div></figure><h2 id="85ac" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">什么是节俭？？</h2><p id="3e18" class="pw-post-body-paragraph if ig hi ih b ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc hb bi translated">Sparcity或sparce matrix是其中大部分值为“0”的矩阵，这样理解，你想求logistic回归中的权向量(w*)，那么它会是这样的</p><p id="a719" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">w*= <w1>如果有d维。</w1></p><p id="b9a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在这样理解，d维意味着d个特征，所以我们有一个问题，其中有d个特征，现在w1可以理解为特征1的权重，w2可以理解为特征2的权重，等等。</p><p id="9b4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们知道一些特征不太重要，并且对目标(y)没有贡献，如果我使用L2正则化，那么这些特征的权重值将会更小，如果我使用L1正则化，那么这些特征的权重值将会是0，这仅仅意味着L1正则化给出了一个权重向量w*，其中大部分值为“0”(我们假设d特征中只有少数特征是重要的，这就是为什么L1将它们设为0)</p><p id="1f47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我认为很明显L1正则化产生了稀疏矩阵(意味着矩阵中的大部分权重值将为0)</p><h2 id="82d4" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">L1正规化和L2正规化有什么区别？</h2><p id="7398" class="pw-post-body-paragraph if ig hi ih b ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc hb bi translated">我将首先用一个非常简单的方法进行L2正则化，我希望最后你会自动给出为什么L1正则化给出稀疏矩阵的答案。</p><p id="ba9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们知道最优化问题通常是什么样子，</p><p id="310b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">(有一些损失函数+有一些正则项)。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es lf"><img src="../Images/2663b42b9226955fb9d5452181bbcb78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dwohZsTpGRccS-R4LbivKw.jpeg"/></div></div></figure><p id="83e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了简化计算，假设只有一个权重w1，如图1所示，如果我们可以检查w1，它将应用于所有的d维权重。所以我们现在只取w。</p><p id="5138" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们有一个问题，其中我们有一个函数f(x)=w1，我们想找到w1的值，它给出了f(x)的最小值，让我们绘制f(x)对w1，它形成了一个y=x图，如图1图像1所示</p><p id="edd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经知道，要得到最小值或最大值，我们需要找到导数，并放入梯度下降更新函数。让我们求f(x)对w1的导数，结果是2w1。</p><p id="e606" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们画出导数，</p><p id="955d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考图片1图片2</p><p id="3f4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们把导数代入梯度函数，</p><p id="400d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">(w1)j+1 =(w1)j-r(df(x)/d(w1))</strong></p><p id="9472" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在输入导数值后，</p><p id="c9ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> (w1)j+1=(w1)j-r(2w1)，这里r是步长，假设取步长为0.01，假设取(w1)(0)=0.05，((w1)(0)是随机选择的第一个值，其中j=0) </strong></p><p id="f766" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以<strong class="ih hj">(w1)1 =(0.05)(0)-0.01 *(2 * 0.05)(0)，她的(0)就是j=0。</strong></p><p id="d435" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> (w1)1=0.049，我们可以看到从w1(0)到w1(1)有一个微小的变化，w1(0)为0.05。</strong></p><p id="d52e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你看到导数图，我们可以看到斜率持续减小，当你在L2迭代时，很快我们会注意到，L2正则化不会从一次迭代到另一次迭代改变w1的值，这是因为同样的原因(斜率在L2正则化中持续减小)。</p><p id="167d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着迭代次数的增加，w1(j)减小，并且随着越来越接近w*，导数变得越来越小。这就是w1=0的机会较少的原因。与L1相比，L2的功能更少，甚至为零。</p><h2 id="4a9c" class="kf kg hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">L1正则化</h2><p id="a788" class="pw-post-body-paragraph if ig hi ih b ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc hb bi translated">现在让我们看看L1正则化中发生了什么，为什么它给出稀疏矩阵，所以相同的损失函数，所以我们不用担心损失函数，所以在L2正则化项中没有平方项，所以当我们对它求导时，我们得到一个常数，如图1、图3和图4所示。</p><p id="4d92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，在导数项中没有“w”项，这意味着当我们像图2那样应用梯度下降时，w1(j+1)与w1(j)相比会有很大变化，因为差异部分非常小。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es lg"><img src="../Images/066e1bf063acf3ad62210397e90d552c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MDHXM_7ejGpKYZK_XiHdCg.jpeg"/></div></div></figure><p id="9115" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里迭代次数增加，可微项是常数，正为1，负为-1。并且l1正则化继续不断地将w1向“0”减小。</p><p id="1260" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以基本上斜率是恒定的，很有可能在几次迭代中得到w=0。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es lh"><img src="../Images/ad74e0570affcae8df739a144c89b7fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-yA-ivNjCVhufq57WWv1ug.jpeg"/></div></div></figure><p id="340d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">本文到此为止，感谢阅读。</strong></p></div></div>    
</body>
</html>