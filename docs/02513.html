<html>
<head>
<title>Quality Assessment of Generative Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成对抗网络的质量评估</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/quality-assessment-of-generative-adversarial-networks-369444a0259c?source=collection_archive---------10-----------------------#2019-12-20">https://medium.com/analytics-vidhya/quality-assessment-of-generative-adversarial-networks-369444a0259c?source=collection_archive---------10-----------------------#2019-12-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="9aad" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">目标</h1><p id="4781" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">目标是使用无参考图像质量评估度量(NR-IQA)找到性能最佳的GAN。该项目的主要部分需要</p><p id="c5d6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">(一)审查现有的基本原则并进行分类；</p><p id="c8df" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">(ii)选择用于生成假图像的最佳GANs</p><p id="3895" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">(iii)使用IQA测量生成图像的质量；最后</p><p id="eb82" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">(iv)比较各种IQA以找到性能最佳的GAN。</p><p id="49f6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">该报告的结果评估了哪种GAN使用NR-IQ产生更好的图像</p><h1 id="9859" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="7d37" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">近年来，生成性对抗网络(GANs)呈指数级增长。除了提供令人惊讶的似是而非的假图像之外，它们还在例如半监督学习、图像到图像的翻译和模拟图像细化等方面进行了创新。不管有多少GAN模型可用，为了找到更好的GAN，我们需要评估生成的图像。然而，它们的评估仍然主要是主观的，并且经常反映了对生成图像的视觉保真度的人工检查</p><p id="34ae" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">图像质量是评估视频和图像处理方案效率的关键指标。因此，图像质量的评价非常重要。对图像进行评估的最简单的方法是向熟练的人类观察者展示它。然而，对于每个人，人类的感知可能不同。这个问题可以通过从不同的人那里获取不同的意见并对结果进行统计处理来解决；这叫做<em class="kg">主观质量评估</em>。然而，这是一个漫长且不准确的质量评估过程。以同样的方式选择参与者，他们所有的信息，技能，可及性，偏见，解释都是主观的和定性的。由于主观评估的内在约束，GANs的发展需要适当的量化措施来规范更好模型的结构。</p><p id="d59e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">与参考图像和重建图像都可用的许多图像分析任务(例如图像压缩)相反，由GANs生成的图像可能没有任何参考图像。因此，为了找到更好的GAN，需要一种用于对GAN图像进行无参考定量评估的自动化系统。这个问题因此可以表示为<em class="kg">对甘</em>的客观质量评价。</p><h1 id="6f8b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">1.科学总结</h1><p id="2ecc" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">由于该项目的目标是找到能够生成最佳伪图像的GAN，这是通过NR-IQA度量对这些图像进行质量评估来完成的。在该项目中，6个gan使用6个数据库来生成图像，然后使用3个无参考图像质量评估指标来评估图像，如图1所示。</p><p id="4912" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">6数据库包括:6数据库包括-</p><ul class=""><li id="334d" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka km kn ko kp bi translated">MNIST:一个数字数据库，包括60，000个样本的训练集和10，000个样本的测试集。</li><li id="0a2d" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">CelebA:超过20万张著名图片的大规模面部数据收集，每张图片有40个特征。</li><li id="7a77" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Stl10:具有10个类别和10000个未标记图像的图像识别数据集。10类包括飞机、鸟、汽车、猫、鹿、狗、马、猴子、船和卡车。</li><li id="c62c" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Lsun:它包含了10个场景类别和20个物体类别的大约100万张标记图像。该数据集包含自行车、鸟、卧室、公共汽车、椅子、汽车、桌子图像等等。</li><li id="9e14" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">地图:由卫星和普通视图中的1000幅土地图像组成的数据集。</li><li id="c3ab" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">立面:它包括来自不同来源的606个立面校正图像的立面图像数据集。</li></ul><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es kv"><img src="../Images/3fbd698251311e863760f4a5ebf05636.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*tE68dZ0-goh3WnuHhT2hfg.png"/></div></figure><p id="bda2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">使用这些数据集的六个gan是(更多细节将在第2.2节提供) :</p><ul class=""><li id="e9cc" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka km kn ko kp bi translated">DcGAN —顾名思义，深度卷积GAN使用卷积层代替全连接和最大池层。</li><li id="f6e3" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">WGAN — Wasserstein GAN [23]使用Wasserstein距离来估计模型和目标分布之间的方差。</li><li id="18e7" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">BigGAN -[27]它使用具有非常大批量和大量模型参数的深度神经网络来产生高分辨率图像。</li><li id="b8b3" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">SrGAN —超分辨率GAN使用深度网络结合对手网络来生成超分辨率图像。</li><li id="8839" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">DiscoGAN -Discovery GAN使用深度卷积网络执行跨域图像到图像的转换。</li><li id="4c74" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">CycleGAN-CycleconsistentGAN使用循环一致的对抗网络执行不成对的图像到图像翻译。</li></ul><p id="6b1f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">IQA的应用范围很广，可以分为三类:全参考IQA (FR-IQA) (FR-IQA)[，无参考IQA (NR- IQA)和简化参考IQA (RR-IQA)此外，本研究中使用的三种无参考图像质量评估指标是:</p><ul class=""><li id="a0bf" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka km kn ko kp bi translated">PIQE——基于感知的图像质量评估器(PIQE) [29]是一种不知道观点且不受监督的指标。PIQE测量可感知的失真块的局部可变性，并评估块失真。</li><li id="b16b" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">NIQE —自然图像质量评估器(NIQE) [28]模型已经在原始图像数据库上进行了训练，用于测量具有渐变失真的图像质量。</li><li id="ad07" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">bris que-Blind/ReferencelessImageSpatialQualityEvaluator(bris que)[30]在具有明显失真的图像数据库上运行，测量具有相同失真类型的图像质量。</li></ul><h1 id="c0da" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">2.方法学</h1><h2 id="7211" class="ld ig hi bd ih le lf lg il lh li lj ip jo lk ll it js lm ln ix jw lo lp jb lq bi translated">2.1 —理论</h2><blockquote class="lr ls lt"><p id="04b0" class="jd je kg jf b jg kb ji jj jk kc jm jn lu kd jq jr lv ke ju jv lw kf jy jz ka hb bi translated">氮化镓</p></blockquote><p id="4917" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">深度学习用于发现丰富的渐进模型，这些模型显示了自然语言处理、波形形式的语音和主要在人工智能中体验的自然图像等数据的概率分布。2014年，Ian Goodfellow和他的同事提出了一个基于深度学习的生成模型。生成建模是机器学习中的一项无监督学习任务，涉及对输入数据的规律性或模式的自动检测和学习，以便可以生成或产生新的示例，这些新示例可以从原始数据集中获取。</p><p id="d1e7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">GANs是一种训练生成模型的智能方法，通过将问题分成两个子模型作为监督学习问题:我们训练以产生新示例的生成器模型，以及尝试将实例分类为真实(来自领域)或虚假(生成)的鉴别器模型。</p><p id="3702" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">首先，GAN中的生成模型与一个敌人对抗:一个判别模型，它决定一个实例是来自数据样本还是模型。GANs的基本思想是在两个玩家之间建立游戏。一个叫做发电机。生成器生成旨在与训练数据进行比较的样本。歧视者是另一个玩家。鉴别者检查测试以确定它们是真的还是假的。鉴别者希望使用传统的受控学习方法，将贡献分成两类(真的或假的)。生成器愿意欺骗鉴别器。</p><p id="11c2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">生成模型可以被认为是像一群伪造者，试图提供和使用未经识别的伪造资金，而辨别模型几乎像警察，寻求识别伪造的现金。在这场比赛中，竞争导致两组都加强他们的策略，直到假货与认证数据无法区分。</p><ul class=""><li id="15ee" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka km kn ko kp bi translated">生成器——生成器本质上是一个可微分函数<em class="kg"> G </em>,由带参数<em class="kg"> g </em>的多层感知器表示。首先，输入噪声<em class="kg"> z </em>根据一些基本的先验分布进行测试，<em class="kg"> G(z) </em>产生输出<em class="kg"> x </em>。深度神经网络的第一层的输入不需要与函数<em class="kg"> G </em>的输入相同。</li><li id="0ab0" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">鉴别器——还有第二个多层感知器<em class="kg"> D </em>提供单一标量输出。<em class="kg"> D(x) </em>表示x来自生成器或数据的概率。</li><li id="66d7" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">训练过程——在训练中，鉴别者<em class="kg"> D </em>和生成者<em class="kg"> G </em>都用价值函数<em class="kg"> V(G，D) </em>在双人游戏中进行极大极小游戏。为了最大化对从<em class="kg"> G </em>和训练样本生成的样本的准确标记，我们训练<em class="kg"> D </em>，同时训练<em class="kg"> G </em>以减少<em class="kg"> log(1-D(G(z))) </em>。</li></ul><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es lx"><img src="../Images/93695ea3643dd993e6327233b8772271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mny02kEselPSgQyMgQ9ruw.png"/></div></div></figure><p id="b995" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在学习阶段开始时，<em class="kg"> G </em>很差，因此<em class="kg"> D </em>非常确定要剔除样本</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mc"><img src="../Images/c08ce08e10293cf0a851a4353d048ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uti0RCgseX0ft7Mdz-SP8g.png"/></div></div></figure><p id="364f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">因为它们显然不如训练数据好。所以我们可以因为训练位置G处的<em class="kg"> log(1-D(G(z)) </em>而增加<em class="kg"> logD(G(z) </em>，以减少<em class="kg"> log(1-D(G(z))) </em>。该功能提供了与<em class="kg"> G </em>和<em class="kg"> D </em>动力学相同的设定目标，但使学习的开始变得更加有力。</p><p id="c963" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">其中<em class="kg"> D </em>为鉴频器，<em class="kg"> G </em>为发电机，<em class="kg"> z </em>为输入噪声，<em class="kg"> x </em>为发电机输出。尽管GANs在真实图像生成方面取得了一些成绩，但这种训练是不稳定和缓慢的。许多GAN模型存在以下主要问题:</p><ol class=""><li id="836b" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka md kn ko kp bi translated">纳什均衡——甘是非合作零和博弈。一个模型试图赢得我最大化自己的行动，另一个模型的行动是减少他们。在博弈论中，当鉴别器和生成器达到纳什均衡时，GAN模型收敛。纳什均衡是一个模型不会改变，不管另一个模型做什么。</li><li id="43a1" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka md kn ko kp bi translated">消失渐变—如果鉴别器行为不好，则发生器没有精确的反馈或真实性，损失函数无法表示它。如果鉴别器操作令人钦佩，损失函数率下降到接近于零，学习太温和，甚至卡住。</li><li id="d52f" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka md kn ko kp bi translated">模式崩溃——在训练期间，发生器可能会陷入某个位置，在该位置，它通常会产生相同的输出。对于一般被称为模式崩溃的GANs来说，这是一个典型的失望情况。尽管生成器很可能误导相关的鉴别器，但是它不理解来自真实地球仪的复杂信息是如何被表示的，因为它们位于具有非常低变化的小区域中。</li><li id="9dc9" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka md kn ko kp bi translated">没有合适的评估标准——没有合适的评估标准，就像是默默无闻地工作。甘没有提供好的标志，建议什么时候停下来，什么时候看各种车型的表现。</li></ol><p id="ed8b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">随着gan的改进，gan的数量呈指数级增长，可分为4大类-</p><ol class=""><li id="13dc" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka md kn ko kp bi translated">单/多类生成-它们是生成性对抗网络的类型，在单个或多个域中接收噪声并从中生成图像</li><li id="5019" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka md kn ko kp bi translated">域内—在域内翻译图像的GANs类型。</li><li id="81d6" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka md kn ko kp bi translated">域间-将图像从一个域转换到另一个域的GANs类型。</li><li id="2c22" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka md kn ko kp bi translated">超分辨率——有一些gan可以实现超分辨率。</li></ol><blockquote class="lr ls lt"><p id="176f" class="jd je kg jf b jg kb ji jj jk kc jm jn lu kd jq jr lv ke ju jv lw kf jy jz ka hb bi translated">2.1.2无参考图像质量指标</p></blockquote><p id="09e4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">图像噪声含量的估计及其随后的去除是一个非常重要的研究领域。这些年来，人类的智能一直被认为是唯一能够感知信号图像噪声的工具。评估图像质量的最简单方法是将图像展示给专业的人类观察者。但是，对于每个人，人类的理解可能是截然不同的。</p><p id="334f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这个问题可以通过采纳不同的意见并对不同人的结果进行统计处理来解决。这被称为图像质量的主观评价。然而，这是一个漫长而不准确的质量评估方法。事实上，一切都是主观的，从参与者的选择，他们的知识，专长，可达性，严重性偏见，解释质量。因此，需要一种自动化系统来进行定量图像评估。</p><p id="2b05" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">可以使用简化且有效的客观评估方案，根据主观人类质量评估给出图像的质量等级。客观图像质量评估(IQA)是指自动预测变形图像的感知质量的挑战性任务。客观图像质量评估可以通过三种方式完成-</p><ol class=""><li id="5889" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka md kn ko kp bi translated">完全参考图像质量评估(FR-IQA) —这是通过将失真图像的质量与被认为未失真的初始图像版本进行比较来评估图像。通过测量失真图像与参考图像的差异，计算失真量。测量图像质量最简单的方法是计算峰值信噪比(PSNR)，但PSNR并不总是与人类视觉感知和图像质量相关[31]。为解决PSNR度量的限制，提出了附加参数。结构相似性指数(SSIM) [32]，视觉保真度(VIF) [39]，快速SSIM (FSIM) [33]，多尺度结构相似性(M-SSIM)，加权四分量结构相似性[35]是与人类感知密切相关的参数。这些参数给出了失真图像与参考图像的偏差程度。对质量评估参考图像的要求限制了以下用于质量评估的参数和算法的使用。</li><li id="e242" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka md kn ko kp bi translated">简化的参考图像质量评估(RR-IQA)-在RR-IQA中，算法仅使用参考图像的受限特征来评估质量，而不是完整图像。FR-IQA的限制保留在RR-IQA，这意味着需要使用从参考图像获得的特征进行质量评估。尽管有RR-IQA技术的种种限制，卫星和遥感图像质量评估仍被普遍使用。</li><li id="1aa0" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka md kn ko kp bi translated">无参考图像质量评估(NR-IQA)-这些算法在不需要参考或其特征的情况下给出图像质量，这是使用NR-IQA评估GANs生成的图像的主要原因。NR-IQA问题比上面提到的两个问题更严重。由于缺少参考图像，有必要对参考图像统计、人类视觉系统的性质以及未监控图像统计中失真的影响进行建模。在缺少参考图像的情况下，对具有某种失真图像的质量测量的有效性也很难评估。无参考算法使用输入图像的统计特征来评估图像质量。因为对于由GANs产生的伪图像没有参考图像，所以无参考质量度量是唯一可用的选项。这些无参考算法包括:</li></ol><ul class=""><li id="f557" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka km kn ko kp bi translated">盲/无参考图像空间质量评估器(BRISQUE)</li><li id="c08c" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">自然图像质量评估器(NIQE)</li><li id="f1c2" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">基于感知的图像质量评价器(PIQE)</li></ul><div class="me mf ez fb mg mh"><a rel="noopener follow" target="_blank" href="/@gaganjotsingh_30429/quality-assessment-of-generative-adversarial-networks-part-ii-6f8eea050e57"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hj fi z dy mm ea eb mn ed ef hh bi translated">生成对抗网络的质量评估(下)</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">方法</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">medium.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv lb mh"/></div></div></a></div></div></div>    
</body>
</html>