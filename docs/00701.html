<html>
<head>
<title>Training your own Sentiment Analyzer with spaCy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用spaCy训练你自己的情感分析器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-your-own-sentiment-analyzer-with-spacy-9b924df1514c?source=collection_archive---------1-----------------------#2019-08-29">https://medium.com/analytics-vidhya/training-your-own-sentiment-analyzer-with-spacy-9b924df1514c?source=collection_archive---------1-----------------------#2019-08-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/db1970cf4bc7efa268931035f767692e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o762lDI2AR9hWlH_RKZc7g.png"/></div></div></figure></div><div class="ab cl iq ir gp is" role="separator"><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv iw"/><span class="it bw bk iu iv"/></div><div class="hb hc hd he hf"><p id="a9c8" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">嗨伙计们！！！在这篇博客中，我将讨论在spaCy的帮助下训练一个基于LSTM的情感分析器。最近我在做twitter情绪分析，为此我花了很长时间探索已经可用的预训练模型。我碰到过的python库有<a class="ae jv" href="https://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj"> TextBlob </strong> </a> <strong class="iz hj">，</strong><a class="ae jv" href="https://www.nltk.org/_modules/nltk/sentiment/vader.html" rel="noopener ugc nofollow" target="_blank"><strong class="iz hj">vadersentimental analyser</strong></a><strong class="iz hj">，</strong><a class="ae jv" href="https://github.com/zalandoresearch/flair" rel="noopener ugc nofollow" target="_blank"><strong class="iz hj">Flair</strong></a><strong class="iz hj"/>等<strong class="iz hj">。虽然这些库工作得很好，但是我们不能根据我们的需要调整它们。我在寻找与我的用例相关的东西。我需要一个模型，这将与我自己的数据集训练。与此同时，我不想担心诸如单词嵌入、网络架构等实质性的细节。斯帕西来救援了。他们提供了一个大纲来训练一个lstm模型。我们所需要做的就是用最少的代码修改正确地传递数据。我们开始吧。</strong></p><p id="d5a2" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">首先，我们必须从github链接下面获取spaCy提供的python脚本并存储该文件。</p><blockquote class="jw jx jy"><p id="b215" class="ix iy jz iz b ja jb jc jd je jf jg jh ka jj jk jl kb jn jo jp kc jr js jt ju hb bi translated"><a class="ae jv" href="https://github.com/explosion/spaCy/blob/master/examples/deep_learning_keras.py" rel="noopener ugc nofollow" target="_blank">https://github . com/explosion/spaCy/blob/master/examples/deep _ learning _ keras . py</a></p></blockquote><p id="623a" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj">先决条件:</strong></p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="b342" class="km kn hi ki b fi ko kp l kq kr"><em class="jz">pip install spacy</em></span><span id="7464" class="km kn hi ki b fi ks kp l kq kr"><em class="jz">spacy download en_vectors_web_lg <br/>## en_vectors_web_lg is the pre trained Word Vector Model spaCy is providing</em></span><span id="13c4" class="km kn hi ki b fi ks kp l kq kr"><em class="jz">pip install keras==2.0.9</em></span><span id="3659" class="km kn hi ki b fi ks kp l kq kr"><em class="jz">Compatible with: spaCy v2.0.0+</em></span></pre><p id="9e49" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj">数据准备</strong></p><p id="fcfe" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">如果我们运行deep_learning_keras.py文件而不提供任何数据，它将默认下载imdb reviews数据集，并使用该数据集训练模型。因为我们想用自定义数据进行训练，所以我们需要处理数据并维护一个特定的文件结构。</p><p id="aff7" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">假设我们的数据是以下格式。其中1表示积极情绪，0表示消极情绪。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/a85001ede8f84614b953c8a8ddeb253e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M71cz_xZC7_cIhQo2jk1wA.png"/></div></div></figure><p id="ef60" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">在执行一些基本的预处理(如删除标点符号、特殊字符、URL)后，我们需要将数据分成两部分(训练测试分割)，两部分的名称相同(例如Tweet _情操. csv)，一部分位于<strong class="iz hj">训练</strong>文件夹，另一部分位于<strong class="iz hj">测试</strong>文件夹。我们还必须创建一个文件夹来存储最终的模型权重(这里是<strong class="iz hj"> model_lstm)。</strong></p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/61fc7e2e923180acb90a81d73d57bbe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DV2u3gNyGTuSsPg87NTfxQ.png"/></div></div></figure><p id="bfb6" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">一旦创建了这个文件夹结构，我们必须对deep_learning_keras.py文件进行一些更改。</p><p id="6c86" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj">改变read_data()函数</strong></p><p id="4dad" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">因为我们将csv文件作为训练和测试文件传递，所以我们需要对read_data格式进行一些更改。我们更新后的代码如下所示</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="95b0" class="km kn hi ki b fi ko kp l kq kr">def  read_data(data_dir, limit=0):</span><span id="3f75" class="km kn hi ki b fi ks kp l kq kr">    dataset=pd.read_csv(data_dir / 'Tweet_Sentiments.csv')</span><span id="4ac2" class="km kn hi ki b fi ks kp l kq kr">    tweets = dataset['Tweet']</span><span id="489a" class="km kn hi ki b fi ks kp l kq kr">    sentiments = dataset['Sentiment']</span><span id="5f5f" class="km kn hi ki b fi ks kp l kq kr">    example=zip(tweets,sentiments)</span><span id="63b5" class="km kn hi ki b fi ks kp l kq kr">    example=list(example)</span><span id="6cd4" class="km kn hi ki b fi ks kp l kq kr">    if limit &gt;= 1:</span><span id="f1de" class="km kn hi ki b fi ks kp l kq kr">        example = example[:limit]</span><span id="c29e" class="km kn hi ki b fi ks kp l kq kr">    return zip(*example) ## This would unzip into two lists</span></pre><p id="bb9f" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj">设置一些变量</strong></p><p id="016a" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">在运行脚本之前，我们需要在main函数中设置一些变量。那些是<strong class="iz hj">列车_方向</strong>、<strong class="iz hj">开发_方向</strong>、<strong class="iz hj">模型_方向</strong></p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/aeaeb59c4c5bf912b9b9e0a531b19e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*rXwH43OY9ezqbYX5jwCZGA.png"/></div></div></figure><p id="c0d4" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj">导入熊猫:</strong>由于我们在这里处理数据帧，我们应该在python文件的开头添加“导入熊猫”。</p><p id="184a" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj">运行脚本:</strong></p><p id="8218" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">现在我们已经准备好训练lstm模型了。我们需要做的就是运行下面的命令。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="df94" class="km kn hi ki b fi ko kp l kq kr">python deep_learning_keras.py</span></pre><p id="a5ea" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">这可能需要一段时间，具体取决于数据集的大小。一旦训练完成，我们将在model_lstm目录中有两个文件，命名为“config.json”和“model”。“config.json”包含了spaCy在脚本中提供的lstm架构。“模型”是一个pickle文件，其中包含最终lstm模型的权重。现在我们需要使用这些文件来预测情绪。</p><p id="8fe9" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj">情绪预测</strong></p><p id="d926" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">有了“config.json”和“model ”,我们必须使用下面的python脚本来预测情绪。(模型将给出极性得分，根据得分，我们可以将文本分为积极或消极情绪)</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="8aa1" class="km kn hi ki b fi ko kp l kq kr">import plac<br/>import random<br/>import pathlib<br/>import cytoolz<br/>import numpy<br/>from keras.models import Sequential, model_from_json<br/>from keras.layers import LSTM, Dense, Embedding, Bidirectional<br/>from keras.layers import TimeDistributed<br/>from keras.optimizers import Adam<br/>from spacy.compat import pickle<br/>import spacy</span><span id="70dc" class="km kn hi ki b fi ks kp l kq kr">class SentimentAnalyser(object):<br/>    <a class="ae jv" href="http://twitter.com/classmethod" rel="noopener ugc nofollow" target="_blank">@classmethod</a><br/>    def load(cls, path, nlp, max_length=100):<br/>#         with ("config").open() as file_:<br/>        model = model_from_json(config)<br/>        with open("model",'rb') as file_:<br/>            lstm_weights = pickle.load(file_)<br/>        embeddings = get_embeddings(nlp.vocab)<br/>        model.set_weights([embeddings] + lstm_weights)<br/>        return cls(model, max_length=max_length)</span><span id="dc5b" class="km kn hi ki b fi ks kp l kq kr">def __init__(self, model, max_length=100):<br/>        self._model = model<br/>        self.max_length = max_length</span><span id="029d" class="km kn hi ki b fi ks kp l kq kr">def __call__(self, doc):<br/>        X = get_features([doc], self.max_length)<br/>        y = self._model.predict(X)<br/>        self.set_sentiment(doc, y)</span><span id="45a6" class="km kn hi ki b fi ks kp l kq kr">def pipe(self, docs, batch_size=1000):<br/>        for minibatch in cytoolz.partition_all(batch_size, docs):<br/>            minibatch = list(minibatch)<br/>            sentences = []<br/>            for doc in minibatch:<br/>                sentences.extend(doc.sents)<br/>            Xs = get_features(sentences, self.max_length)<br/>            ys = self._model.predict(Xs)<br/>            for sent, label in zip(sentences, ys):<br/>                sent.doc.sentiment += label - 0.5<br/>            for doc in minibatch:<br/>                yield doc</span><span id="a03f" class="km kn hi ki b fi ks kp l kq kr">def set_sentiment(self, doc, y):<br/>        doc.sentiment = float(y[0])<br/>        # Sentiment has a native slot for a single float.<br/>        # For arbitrary data storage, there's:<br/>        # doc.user_data['my_data'] = y<br/>        <br/>def get_labelled_sentences(docs, doc_labels):<br/>    labels = []<br/>    sentences = []<br/>    for doc, y in zip(docs, doc_labels):<br/>        for sent in doc.sents:<br/>            sentences.append(sent)<br/>            labels.append(y)<br/>    return sentences, numpy.asarray(labels, dtype="int32")</span><span id="b01a" class="km kn hi ki b fi ks kp l kq kr">def get_features(docs, max_length):<br/>    docs = list(docs)<br/>    Xs = numpy.zeros((len(docs), max_length), dtype="int32")<br/>    for i, doc in enumerate(docs):<br/>        j = 0<br/>        for token in doc:<br/>            vector_id = token.vocab.vectors.find(key=token.orth)<br/>            if vector_id &gt;= 0:<br/>                Xs[i, j] = vector_id<br/>            else:<br/>                Xs[i, j] = 0<br/>            j += 1<br/>            if j &gt;= max_length:<br/>                break<br/>    return Xs</span><span id="9dc4" class="km kn hi ki b fi ks kp l kq kr">def compile_lstm(embeddings, shape, settings):<br/>    model = Sequential()<br/>    model.add(<br/>        Embedding(<br/>            embeddings.shape[0],<br/>            embeddings.shape[1],<br/>            input_length=shape["max_length"],<br/>            trainable=False,<br/>            weights=[embeddings],<br/>            mask_zero=True,<br/>        )<br/>    )<br/>    model.add(TimeDistributed(Dense(shape["nr_hidden"], use_bias=False)))<br/>    model.add(<br/>        Bidirectional(<br/>            LSTM(<br/>                shape["nr_hidden"],<br/>                recurrent_dropout=settings["dropout"],<br/>                dropout=settings["dropout"],<br/>            )<br/>        )<br/>    )<br/>    model.add(Dense(shape["nr_class"], activation="sigmoid"))<br/>    model.compile(<br/>        optimizer=Adam(lr=settings["lr"]),<br/>        loss="binary_crossentropy",<br/>        metrics=["accuracy"],<br/>    )<br/>    return model</span><span id="5208" class="km kn hi ki b fi ks kp l kq kr">def get_embeddings(vocab):<br/>    return vocab.vectors.data</span><span id="1eea" class="km kn hi ki b fi ks kp l kq kr">#### Creating nlp pipeline<br/>nlp = spacy.load("en_vectors_web_lg")<br/>nlp.add_pipe(nlp.create_pipe("sentencizer"))</span><span id="5bef" class="km kn hi ki b fi ks kp l kq kr"><br/>#### Loading Model and Config.json</span><span id="244a" class="km kn hi ki b fi ks kp l kq kr">with open('model','rb') as f:<br/>    model=pickle.load(f)</span><span id="f0fd" class="km kn hi ki b fi ks kp l kq kr">with open('config.json','r') as f:<br/>    config=f.read()</span><span id="dc48" class="km kn hi ki b fi ks kp l kq kr">##### Applying Sentiment Analyser<br/>nlp.add_pipe(SentimentAnalyser.load(model, nlp, max_length=100))</span><span id="16e9" class="km kn hi ki b fi ks kp l kq kr">##### Getting the Polarity Score<br/># "docs" is a list which contains sentences we want to classify</span><span id="cd55" class="km kn hi ki b fi ks kp l kq kr">for doc in nlp.pipe(docs):<br/>    print(doc.sentiment)</span></pre><p id="138d" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated"><strong class="iz hj">最终输出</strong></p><p id="8098" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">例如，我选择了一些句子，并用训练好的模型进行了测试。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/c3c6c7bac5de89181de5bd484c705ac1.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*foxl3eYHGsRuuyUg0vKnug.png"/></div></figure><p id="abdf" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">我们可以观察到，我们训练的模型表现得很好。当我们有大量数据要训练并且我们想要合理地控制训练过程，但是我们不想深入研究LSTM网络体系结构或单词嵌入时，这种训练模型的方法将是有用的。我们可以尝试改变参数，如退学率，学习率等，以获得更好的结果。</p><p id="ead2" class="pw-post-body-paragraph ix iy hi iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju hb bi translated">这就是今天博客里的所有人。快乐学习。干杯！！</p></div></div>    
</body>
</html>