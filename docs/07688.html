<html>
<head>
<title>Retail Store Item Detection using YOLOv5</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用YOLOv5检测零售店商品</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/retail-store-item-detection-using-yolov5-7ba3ddd71b0c?source=collection_archive---------2-----------------------#2020-07-04">https://medium.com/analytics-vidhya/retail-store-item-detection-using-yolov5-7ba3ddd71b0c?source=collection_archive---------2-----------------------#2020-07-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9777" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我介绍了流行的深度学习算法YOLO的最新版本(即YOLOv5)的应用程序，以检测零售店货架上的商品。这个应用程序可以简单地使用货架上物品的图像来跟踪物品的库存。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/ebc25dc3d2bfc4e9f790c6adee000243.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QsiP9Yjx8KNHLq2BSkykYg.png"/></div></div></figure><h1 id="c135" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">简介</strong></h1><p id="5110" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">目标检测是一项计算机视觉任务，需要对目标进行检测、定位和分类。在这项任务中，首先我们需要我们的机器学习模型来判断图像中是否存在任何感兴趣的对象。如果存在，则围绕图像中存在的对象绘制一个边界框。最后，模型必须对由边界框表示的对象进行分类。这项任务需要快速的目标检测，以便能够实时实现。其主要应用之一是用于自动驾驶车辆中的实时物体检测。</p><p id="dd35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Joseph Redmon等人最初设计了执行实时对象检测的YOLOv1、v2和v3模型。YOLO“你只看一次”是一种最先进的实时深度学习算法，用于图像和视频中的对象检测、定位和分类。这种算法非常快速、准确，是基于对象检测的项目的前沿。</p><p id="c197" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个版本的YOLO都在准确性和性能上不断改进。然后是另一个团队开发的YOLOv4，进一步提高了模型的性能，最后是Glenn Jocher在2020年6月推出的YOLOv5模型。这个模型大大减小了模型的大小(Darknet上的YOLOv4有244MB大小，而YOLOv5最小的模型只有27MB)。YOLOv5还声称比YOLOv4更快的精度和每秒更多的帧数，如下图所示，摘自<strong class="ih hj"> Roboflow.ai的</strong>网站。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ks"><img src="../Images/edf203f56aad4072cf42bd3538bb3438.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vh2in4Pw58sMbrJO.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">图1.1: YOLOv5比EfficientDet模型更快</figcaption></figure><p id="2825" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于YOLO如何工作的更多细节可以在互联网上找到。在本文中，我将只关注YOLOv5在零售商品检测中的应用。</p><h1 id="b2ad" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">目标</h1><p id="5080" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">使用YOLOv5在使用SKU110k数据集的图片中的零售产品上绘制边界框。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/ebc25dc3d2bfc4e9f790c6adee000243.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QsiP9Yjx8KNHLq2BSkykYg.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">图1.2:商店货架图像(左图)与在对象上绘制边界框的期望输出(右图)</figcaption></figure><h1 id="62e6" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">资料组</h1><p id="df7d" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">为了完成这项任务，首先我从以下链接下载了SKU110k图像数据集:</p><p id="a5f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae kx" href="http://trax-geometry.s3.amazonaws.com/cvpr_challenge/SKU110K_fixed.tar.gz" rel="noopener ugc nofollow" target="_blank">http://trax-geometry . S3 . Amazon AWS . com/cvpr _ challenge/SKU 110k _ fixed . tar . gz</a></p><p id="82d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SKU110k数据集基于密集包装环境中零售物品的图像。它提供了训练、验证和测试集图像以及相应的。包含这些图像中所有对象的边界框位置信息的csv文件。的。csv文件将对象边界框信息写入以下各列:</p><p id="ffa3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ky">图像名称，x1，y1，x2，y2，类别，图像宽度，图像高度</em></p><p id="ffbb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中x1，y1是边界框的左上坐标，x2，y2是边界框的右下坐标，其余参数不言自明。一个边界框的train_0.jpg图像的参数示例如下所示。每个图像有几个边界框，每个对象一个框。</p><p id="222b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ky"> train_0.jpg，208，537，422，814，object，3024，3024 </em></p><p id="eae6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在SKU110k数据集中，测试集中有2940幅图像，训练集中有8232幅图像，验证集中有587幅图像。每个图像可以具有不同数量的对象，因此具有不同数量的边界框。</p><h1 id="d753" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">方法学</h1><p id="dea8" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">从数据集中，我只从训练集中提取了998幅图像，并访问了Roboflow.ai网站，该网站提供不同格式的在线图像注释服务，包括YOLOv5支持的格式。仅从训练集中挑选998幅图像的原因是，Roboflow.ai的<strong class="ih hj"> </strong>图像注释服务仅对前1000幅图像免费。</p><p id="77c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">预处理</strong></p><p id="35f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图像的预处理包括将图像大小调整为416x416x3。这是在<strong class="ih hj"> Roboflow的</strong>平台上完成的。下图显示了一幅经过标注和调整大小的图像:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kz"><img src="../Images/5ed585f1f50f05d4526d5b8af0673d0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*AnPrhjG5vRS3BvAhv69dOw.jpeg"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">图1.3:由Roboflow注释的图像</figcaption></figure><p id="9a72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">自动标注</strong></p><p id="be41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Roboflow.ai网站上，边框标注。csv文件和来自训练集的图像被上传，Roboflow.ai的<strong class="ih hj"> </strong>注释服务使用。csv文件如上图所示。</p><p id="fd32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据生成</strong></p><p id="c873" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Roboflow还提供了基于用户定义的分割生成数据集的选项。我使用70–20–10训练-验证-测试集分割。在Roboflow上生成数据后，我们在每个图像的单独文本文件中获得原始图像以及所有带注释对象的所有边界框位置，这很方便。</p><p id="c689" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们得到一个链接来下载带有标签文件的生成数据。此链接包含一个仅限您的帐户使用的密钥，不应共享。</p><h1 id="f6fd" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">使用的硬件</strong></h1><p id="92c5" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">该模型在配有特斯拉P100 16GB显卡的Google Colab Pro笔记本上进行训练。它的价格是9.99美元，可以使用一个月。谷歌Colab笔记本也可以免费使用，但使用会话时间有限。</p><h1 id="384b" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">密码</h1><p id="caac" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我推荐使用Roboflow.ai在<br/><a class="ae kx" href="https://models.roboflow.ai/object-detection/yolov5" rel="noopener ugc nofollow" target="_blank">www.models.roboflow.ai/object-detection/yolov5</a><br/>提供的Google Colab笔记本，它最初是为COCO数据集训练的，但可以为定制任务进行调整，这就是我所做的。我从克隆YOLOv5并安装requirements.txt文件中提到的依赖项开始。此外，该模型是为Pytorch构建的，所以我将其导入。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="7a99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我下载我在Roboflow.ai创建的数据集。它还创建了一个. yaml文件，该文件包含训练和验证集的路径以及数据中存在的类。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="520a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该文件告诉模型训练集和验证集图像的位置路径，以及类的数量和类的名称。对于这个任务，类的数量是“<strong class="ih hj"> 1 </strong>”，类的名称是“<strong class="ih hj">对象</strong>”，因为我们只希望预测边界框。data.yaml文件如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lc"><img src="../Images/1db87c3661a377f8dd5c1f319f497255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6rO5D-7wp-XIJUeVAwB0Gg.jpeg"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">图1.4:data . YAML文件的视图</figcaption></figure><p id="908d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">网络架构</strong></p><p id="09b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来让我们定义YOLOv5的网络架构。这与作者Glenn Jocher在COCO数据集上进行训练时使用的架构相同。我没有改变网络中的任何东西。然而，需要一些调整来改变边界框的大小，颜色，并删除标签，否则标签会因为太多的框而使图像混乱。这些调整是在detect.py和utils.py文件中进行的。网络保存为custom_yolov5.yaml文件。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="0d1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">训练</strong></p><p id="8858" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我开始训练过程。我将图像大小(img)定义为416x416，批次大小为32，模型运行300个时期。如果我们不定义权重，它们会被随机初始化。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="7594" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在谷歌Colab Pro提供的特斯拉P100 16GB GPU上完成训练花了4小时37分钟。训练完成后，模型的权重将作为last_yolov5_results.pt保存在Google drive中</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="la lb l"/></div></figure><h1 id="3af3" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">观察</h1><p id="64e4" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在使用以下代码对模型进行训练之后，我们可以可视化重要的评估指标:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="f0e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下3个参数通常用于对象检测任务:</p><p id="802e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GIoU 是并集上的广义交集，它告诉我们的边界框有多接近真实情况。</p><p id="770a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">物体性</strong>表示物体存在于图像中的概率。这里它被用作损失函数。</p><p id="139e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> mAP </strong>是平均精度，表示我们的边界框预测平均有多准确。它是精确召回曲线的曲线下面积。</p><p id="39c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以看出，对于训练和验证，广义交集(GIoU)损失和目标损失都减少了。然而，对于0.5的边界框IoU阈值，平均精度(mAP)为0.7。召回率为0.8，如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ld"><img src="../Images/ecdd64e6e5dded49f10d26234fa02670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*40Q8cbTIzEqjRgco4_huWQ.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">图1.5:yolo V5模型训练中观察到的不同评估参数</figcaption></figure><p id="e17e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们使用以下代码来检查我们的模型在测试集图像上的表现:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="la lb l"/></div></figure><h1 id="8f1d" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结果</h1><p id="3ce7" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">下图显示了我们的YOLOv5算法在物体上绘制边界框的结果。结果相当不错。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es le"><img src="../Images/243841d5b6f227b1dd8a4df028097c87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8LG8dnQoYiqR9w0CXXKoow.jpeg"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">图1.6:原始测试集图像(左图)和YOLOv5绘制的边界框图像(右图)</figcaption></figure><p id="17eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">推断时间只有0.009秒，权重文件只有13.9MB</p><h1 id="b3f0" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">链接到存储库</h1><p id="9bed" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">以下链接包含项目的存储库。请确保您在Google Colab中复制了jupyter notebook中的代码，因为它最初是在那里编写的。</p><p id="c750" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae kx" href="https://github.com/shayanalibhatti/Retail-Store-Item-Detection-using-YOLOv5" rel="noopener ugc nofollow" target="_blank">https://github . com/shayanalibhatti/Retail-Store-Item-Detection-using-yolov 5</a></p><p id="c413" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对存储库中的utils.py和detect.py文件进行了调整，删除了对象标签并创建了绿色的薄边界框。</p><h1 id="e1b5" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论</h1><p id="a5c3" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">撇开命名争议不谈，YOLOv5表现很好，可以根据我们的需要进行定制。然而，训练该模型可能需要大量的GPU能力和时间。建议至少使用配有16GB GPU的Google Colab，或者最好使用TPU来加速大型数据集的训练过程。</p><p id="9c90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个零售对象检测器应用程序可以用来跟踪商店货架库存，或者用于智能商店概念，人们可以挑选商品并自动收费。YOLOv5的小重量尺寸和良好的帧速率将为其成为基于嵌入式系统的实时对象检测任务的首选铺平道路。</p></div></div>    
</body>
</html>