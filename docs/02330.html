<html>
<head>
<title>Minimize your errors by learning Gradient Boosting Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过学习梯度推进回归来最小化你的错误</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/minimize-your-errors-by-learning-gradient-boosting-regression-2c002c65a064?source=collection_archive---------15-----------------------#2019-12-11">https://medium.com/analytics-vidhya/minimize-your-errors-by-learning-gradient-boosting-regression-2c002c65a064?source=collection_archive---------15-----------------------#2019-12-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7f50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">梯度推进是一种推进算法，主要用于回归以及机器学习中的分类问题。</p><p id="94e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我们将了解梯度推进回归算法如何为数据集生成连续值。但是在我们开始我们的模型工作之前，我们必须知道如何建立一个决策树。所以，如果你不熟悉决策树，你可以<a class="ae jd" rel="noopener" href="/analytics-vidhya/a-deep-dive-to-decision-trees-6575e016d656?source=friends_link&amp;sk=82fb99bb05d07712858d642c840ae29a"> <strong class="ih hj">点击这里</strong> </a>来了解<strong class="ih hj">决策树是如何构建的</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/db5c6c930368bd5608e9a4e727f499db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4jivCpH2LdFbyCgrDKjcNw.png"/></div></div></figure><h2 id="b5d3" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">关于梯度推进算法的一些要点是→</h2><ol class=""><li id="4681" class="kl km hi ih b ii kn im ko iq kp iu kq iy kr jc ks kt ku kv bi translated">梯度增强基于单个<a class="ae jd" href="https://drive.google.com/open?id=1UGUsRLbXBvGdCsM4Nc60fd5fW5SUBfsX" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">叶</strong> </a>，并且该叶代表所有样本的初始猜测</li><li id="8bc0" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">我们首先猜测的是平均值。然后梯度推进建立树。</li><li id="d012" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc ks kt ku kv bi translated">梯度提升是基于前一个决策树产生的错误。</li></ol><h2 id="0318" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">模型是如何工作的？</h2><p id="ddb6" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">为了探索梯度推进模型的工作原理，我们将使用“TIPS”数据集，其中我们需要预测数据集中的“tip”列。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es le"><img src="../Images/554641ce24b73eca2b19157739444e41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*ayRH4Whrc9p8V-pVJnbQQw.png"/></div></figure><p id="db60" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lf">第一步</em> </strong>:首先我们将计算‘tip’列的平均值。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lg"><img src="../Images/6e797cb74fd519d38c5f9a21b34a76c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*D2cSHri50VC58SBsbURv2Q.png"/></div></figure><p id="baac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"/></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lh"><img src="../Images/29ce588a7b6cc69f349cdf75f6f95b06.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*la_kPpxleMszLGBGH5FxuQ.png"/></div></div></figure><p id="339e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lf">第三步</em> </strong>:现在，我们必须使用这个新的数据集来构建决策树。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es li"><img src="../Images/e11d03ed2b5bcf336b8c0e8ceb6cfc5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*26i6077vqOD7_OwXLhtO6w.png"/></div></figure><p id="809b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">分析完成后，建立的回归树是:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lj"><img src="../Images/eb253bbfd9bd5401c41df6c994530270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-tDsHPNRx0SdXoMSGxMUhQ.png"/></div></div></figure><p id="a9ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">* * IMP * *</strong>→要了解这个回归树是如何构建的，你可以通过<a class="ae jd" rel="noopener" href="/@soumo.villa7/how-regression-with-decision-trees-works-ba8b523097cf?source=friends_link&amp;sk=5f4153c5e50da3bebf58a7a798aab5de"> <strong class="ih hj">点击这里</strong> </a>来检验这个博客。</p><p id="46d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> IMP NOTE </strong> →如果最后有一个以上的残差值落在一个叶类别中，那么我们必须对这些值进行平均，例如，如果1.15、0.18和0.16在一个叶节点中，那么(1.15 + 0.18 + 0.16)/3 = 0.4966将是叶节点的值。</p><p id="8bb6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lf">第四步</em> </strong>:之后，第一次训练过程完成。在下一个训练过程中，首先我们将使用<strong class="ih hj"> Average tip +(学习率*来自新测试功能树的剩余结果)</strong>计算我们对此数据集的预测。在这里，学习率是一个超参数，因此我们可以根据我们的数据集调整或更改它，以获得最佳结果。</p><p id="a8e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lf">示例</em> →对于我们数据集中的第一行，预测值为:2.16 + 0.1 * 1.15 = 2.275</p><p id="5975" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lf">第五步</em> </strong>:现在，我们将通过对数据集使用新的预测来形成新的数据集。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lk"><img src="../Images/09356862bd7784fe6c8ae18692db9fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RRarnI9fyVzEYRN7sdazDA.png"/></div></div></figure><p id="ab71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤6:在此之后，我们将再次计算我们的新预测的平均小费，即</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ll"><img src="../Images/0aa4f9a83e440921ef6c98a4105902e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*6zPD8yQo3-SshkVqo7Jt-g.png"/></div></figure><p id="d37b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在此之后，我们将<strong class="ih hj">再次计算残差，并为预测</strong>制作新的回归树。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lm"><img src="../Images/f25f71f8726d1b847ad6b8c8d8a46443.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*Nx_0L4AVHbnrmoZcnZYAig.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ln"><img src="../Images/f7565333d3becfec7bc27ac72b78c6ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sDlVgmwnKX2eUwmPi-qseg.png"/></div></div></figure><p id="bcfe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注</strong> →来自该数据集的新回归树的结构可能与先前的不同。</p><ul class=""><li id="3de1" class="kl km hi ih b ii ij im in iq lo iu lp iy lq jc lr kt ku kv bi translated"><em class="lf">* *</em><strong class="ih hj">IMP</strong><em class="lf">* *</em>→这里不打算构造回归树。只是要注意，第二训练过程的tip预测将=第一平均tip +(学习率*来自第一回归树的残值)+(学习率*来自第二回归树的残值)</li><li id="ce90" class="kl km hi ih b ii kw im kx iq ky iu kz iy la jc lr kt ku kv bi translated">因此，当我们继续训练我们的数据集N次时，对于一组新的特征，如果我们想要预测输出，那么它将等于:<strong class="ih hj">第一平均tip +(学习率*来自第一回归树的残值)+(学习率*来自第二回归树的残值)+(学习率*来自第三回归树的残值)+………………..(学习率*第n棵回归树的残值)</strong></li></ul><p id="7e82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们刚刚意识到梯度推进算法如何在机器学习中工作，并可以实现各种回归问题。希望你已经掌握了梯度推进的关键概念。如果你对这个话题有任何疑问，请在评论中告诉我，在此之前，请享受学习的乐趣。</p></div></div>    
</body>
</html>