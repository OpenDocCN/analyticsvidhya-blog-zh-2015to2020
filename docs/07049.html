<html>
<head>
<title>Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/logistic-regression-bb2087fbd588?source=collection_archive---------26-----------------------#2020-06-11">https://medium.com/analytics-vidhya/logistic-regression-bb2087fbd588?source=collection_archive---------26-----------------------#2020-06-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/57883ac393d091bceb61a1fb2d385120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KtnzJpY81gDWNVnOVNZoQQ.jpeg"/></div></div></figure><p id="023e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">逻辑回归</strong>是一种用于解决分类问题的数学算法。此模型背后的基本工作类似于线性回归，但逻辑回归不是预测值，而是用于估计实例属于特定类的概率。</p><h1 id="c4da" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">估计概率</h1><p id="8244" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在逻辑回归中，我们计算独立变量的加权和。但是我们不是预测值，而是计算加权和的<em class="kr">逻辑</em>。这是通过在输出上应用<em class="kr">逻辑函数</em>来完成的。</p><p id="7a55" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">g(x) = θ₀*X₀ + θ₁*X₁ + θ₂*X₂ + θ₃*X₃ + …+θₙ*xₙ</p><p id="1fe1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="kr"> g(x) = X*θ </em> </strong></p><p id="8fd4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">逻辑函数是<strong class="is hj"> <em class="kr"> sigmoid函数</em> </strong>，输出一个介于“0”和“1”之间的数字。</p><p id="e0df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"><em class="kr">p = h(X)=σ(g(X))=σ(X *θ)</em></strong></p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/6062f8634124f71d923b1aa4ac2f3973.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*a2e-ozEcNCm_s0trFzf-DA.jpeg"/></div></figure><h1 id="747f" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">做预测</h1><p id="d64b" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">一旦我们的逻辑模型估计了实例的概率，我们就可以通过对分类器输出应用阈值来预测每个实例属于哪个类。如果概率≥ 0.5，则为<strong class="is hj"> <em class="kr">类1 </em> </strong>否则为<strong class="is hj"> <em class="kr">类0 </em> </strong>。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/ef06044a920caa0f4018a4ffae6f0840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nbFK3cqvfp_W3nph-Cc70A.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">(图片来源:dorianbrown.dev)</figcaption></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/c62b9a150ff99fba4cb58a85d765b1e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*LWr2RLw8USjX_WBjfm0ycQ.png"/></div></figure><p id="e8ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所用阈值的默认值为0.5。但是在许多分类问题中，两类的实例是不平衡的。因此，我们应该根据数据集中的类不平衡来调整它，以获得更好的性能。</p><h1 id="aa96" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">训练我们的分类器</h1><p id="ccd9" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在线性回归中，我们最小化实例与其预测值之间的均方距离，但我们不能在逻辑回归中使用均方函数，因为它可能包含许多局部最小值，这将使梯度下降难以收敛。</p><p id="6141" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，代替使用均方误差函数，我们将使用<strong class="is hj"> <em class="kr">交叉熵</em> </strong>函数作为我们的成本函数。成本函数如下所示:</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/a997ab1c04b1fbf0d65bd15b7e8d180a.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*lftvF96lwYCntZ9IkWBMDQ.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">(图片来源:<a class="ae le" href="https://ml-cheatsheet.readthedocs.io/" rel="noopener ugc nofollow" target="_blank">https://ml-cheatsheet.readthedocs.io/</a>)</figcaption></figure><p id="27b8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果我们看一下对数函数的曲线图，我们会清楚地了解为什么选择这个函数。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/9910ffdd18d5c4b68b21c23de94bab68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZR__jLeoLnAMk3gBSsJXQ.jpeg"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">(图片来源:gigadom.in/2013/11/15/)</figcaption></figure><p id="d4eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于<strong class="is hj"> y = 1 </strong>，如果我们的预测值也是1，那么成本函数中的“log”将是0，并且权重不会发生变化。但是如果预测值是0，那么“log”将给出一个高值，并且权重将被更新。</p><p id="4cc3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于<strong class="is hj"> y = 0 </strong>，如果我们的预测值也是0，那么‘log’将是0，并且权重不会发生变化。但是如果预测值是1，那么“log”将给出一个高值，并且权重将被更新。</p><p id="5add" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将使用<strong class="is hj">梯度下降</strong>算法来最小化我们的成本函数。为此，我们需要计算成本函数的偏导数。并且迭代地更新权重。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/f9f8a31e7d7d29f5da97a9ac56d977d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y9Z-UAEKit_p5ljzsuze5w.jpeg"/></div></div></figure><h1 id="5c26" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">例子</h1><p id="d279" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">让我们看一个例子，看看我们的算法是如何工作的。我随机取了一些数据。你可以选择任何数据集。数据集在可视化上看起来是这样的。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/62cd9d6f9c9a7fab4d7a73de7923085c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*Fc_Qm4_aG2X93fYkTSMozw.png"/></div></figure><p id="c3fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练完我们的模型后，我们可以画出两个类的分界线。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/5d70ef4423eeb7f7b4288ea0d624a83e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*nBU8L7lmXJFXS_UFaSCPVA.png"/></div></div></figure><p id="a687" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">可以参考Github上的完整代码— <a class="ae le" href="https://github.com/ShubhAgarwal/Logistic-Regression" rel="noopener ugc nofollow" target="_blank">这里</a></p><p id="805a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以借助Scikit学习库直接实现逻辑回归。它有一个名为LogisticRegression的类，直接为我们训练模型，我们可以根据自己的要求调整超参数。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/0da7b08283f9d7bcc17be065f68770f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QbTRvhJXioSYwfm5n_YTjQ.png"/></div></div></figure><h1 id="ba44" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">结论</h1><p id="a83c" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">我们学习了逻辑回归、它的成本函数以及如何使用梯度下降算法训练我们的模型。</p><p id="1e49" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们还看到了如何使用Scikit学习库在不同数据集上实现逻辑回归算法。</p><p id="2bc0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我希望你发现通过我的博客很容易理解逻辑回归的概念。</p></div></div>    
</body>
</html>