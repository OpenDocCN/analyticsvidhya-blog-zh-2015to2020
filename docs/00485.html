<html>
<head>
<title>A Week of Machine Learning: Day 5</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习一周:第五天</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-week-of-machine-learning-5th-day-e0795edfd35c?source=collection_archive---------6-----------------------#2019-07-06">https://medium.com/analytics-vidhya/a-week-of-machine-learning-5th-day-e0795edfd35c?source=collection_archive---------6-----------------------#2019-07-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/aecd541f7ce3fc5fe4336b163eeb836c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ggdRglL5G8G06CbYG8jZg.png"/></div></div></figure><p id="8f04" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是7天机器学习系列的第5天。</p><h1 id="4001" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">无监督学习</h1><p id="d337" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">当我们没有数据的标签时，我们使用无监督学习算法。这些算法寻找数据中的模式，通过这些模式可以将数据分成不同的组。主要我们看到PCA(主成分分析)和聚类。</p><h1 id="9ced" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">使聚集</h1><p id="2ef8" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">我们把数据分成不同的组。存在于同一组中的数据样本具有一些相似性或者它们遵循相同的模式。这些组被称为集群。这个过程叫做聚类。有不同的算法用于聚类，例如K-means。</p><h1 id="0443" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">k均值</h1><p id="a5bf" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">这是一个著名的聚类算法。这遵循相当简单的步骤来形成数据的聚类。这里“K”表示我们需要多少个集群。它遵循以下步骤</p><ul class=""><li id="c897" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated">用随机平均值初始化K个变量。</li><li id="c864" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">将平均值分配给最接近平均值的数据样本。</li><li id="5f11" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">更新K意味着</li><li id="f4de" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">迭代几次</li></ul><p id="dc8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了分类，我们只需找到所有聚类的平均距离，并预测最接近的聚类。</p><p id="25c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们玩小代码吧。正如我之前所说，我们将遵循自上而下的方法。我们不会从零开始实现这个算法，虽然我们可以做到，但它很简单。但是我们的目标是，现在，让我们自己介绍这些算法，只做有趣的部分。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/386e92cd2e00130db02e9b7e1d37c2a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C2fyL_9eMVSBWDW3B996Ew.png"/></div></div></figure><p id="14d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正在导入所需的库。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/1e56081f45f4de19618555f4dd66504d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35-DNWcXF3lbxG5OjVzHjg.png"/></div></div></figure><p id="19f1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们正在创建自己的简单数据。这里创建了具有两个不同组的数据。这是一个相当简单的数据。在现实世界中，数据更加复杂，我们也不知道它所包含的不同组的确切数量。Numpy的normal函数用于创建正态分布的随机值。“concatenate”函数用于组合两个Numpy数组。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/46fec2750b8744a9b6ecf5192c8f94dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*enZbYsksVHVLlxsjgMFBoA.png"/></div></div></figure><p id="dff2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们将数据可视化。我们可以观察到两个不同的星团。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/caf3ce5945ca2685c83f2e1ea12c5017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*k9pcyNiyhKlcLXTlzg_46w.png"/></div></figure><p id="0cd3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是我们创造的数据。现在，我们必须检查K-Means算法如何处理这些数据。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/8c4aedd5923779524f405ce8843e9586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vxrn82N7cHDMeEheGNofQg.png"/></div></div></figure><p id="ad6b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用创建的数据拟合模型。我们在这里传递了n_clusters = 2，但是在现实世界中，我们并不确定会有多少个集群。有一些技术可以使这个值正确。现在，让我们保持简单。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/66211d456d3899493d09bd0fef1447e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6OnyLAqrWcxf3H3oYybWjg.png"/></div></div></figure><p id="f639" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">看看数据是如何被K-Means分成两类的。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/d223b24705d83e29ca6867e54736b4c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*EJp1uCvThLpXffvE37slMQ.png"/></div></figure><p id="053e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一个非常好的结果。</p><figure class="lg lh li lj fd ij"><div class="bz dy l di"><div class="lq lr l"/></div></figure><p id="719e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请记住，这是相当简单的数据。随着数据维数的增加，k-means的计算时间也增加。希望你理解了k-means算法背后的思想。</p><p id="e730" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是完整的代码</p><figure class="lg lh li lj fd ij"><div class="bz dy l di"><div class="ls lr l"/></div></figure><p id="e5e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">还有其他方法属于无监督学习。它在各个领域都有应用。作为初学者，你应该试着理清你的概念。不要被互联网上的内容淹没。本文的目的是让您熟悉无监督学习和k-means聚类。</p><ul class=""><li id="8720" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated">一周的机器学习:第一天</li><li id="a9fe" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">一周的机器学习:第二天</li><li id="4f59" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated"><a class="ae lt" rel="noopener" href="/analytics-vidhya/a-week-of-machine-learning-3rd-day-13843fda63c3">一周的机器学习:第三天</a></li><li id="121a" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated"><a class="ae lt" rel="noopener" href="/analytics-vidhya/a-week-of-machine-learning-4th-day-599e53032c97">为期一周的机器学习:第四天</a></li></ul><h2 id="763d" class="lu jp hi bd jq lv lw lx ju ly lz ma jy jb mb mc kc jf md me kg jj mf mg kk mh bi translated">感谢阅读。快乐学习！！</h2></div></div>    
</body>
</html>