<html>
<head>
<title>AI in Healthcare: Chest X-ray classification using Transfer learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">医疗保健中的人工智能:使用迁移学习的胸部 X 射线分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ai-in-healthcare-chest-x-ray-classification-using-transfer-learning-45934929509b?source=collection_archive---------11-----------------------#2020-11-05">https://medium.com/analytics-vidhya/ai-in-healthcare-chest-x-ray-classification-using-transfer-learning-45934929509b?source=collection_archive---------11-----------------------#2020-11-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="06ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">深度学习</strong>:在深度学习模型中，迁移学习对于取得更好的结果可以起到至关重要的作用。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/4d7c2436034d082586c27b436ae1ca83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O8oyxTwlM3yMSyzuO7SbnA.jpeg"/></div></div></figure><p id="1c42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">医学图像对于临床诊断和决策具有重要价值。图像模态是一个重要的基本步骤，因为它能够帮助临床医生在检索系统中访问所需的医学图像。传统的模态分类方法依赖于手工制作的特征的选择，并且要求对先前的领域知识有清楚的认识。特征学习方法可以有效地检测不同模态的视觉特征，但它受限于训练数据集的数量。为了克服标记数据的缺失，一方面，我们在 ImageNet 上预先训练不同深度的深度卷积神经网络(VGGNet，ResNet)，固定大部分早期层以保留自然图像的通用特征，在 ImageCLEF 上只训练其较高层部分以学习医学人物的领域特定特征。</p><h1 id="c7d7" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是迁移学习？</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kn"><img src="../Images/4c5d6704b059656db37273187a98585c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XmcqqVxzzsTO3rkKa666XQ.png"/></div></div></figure><p id="f072" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在迁移学习中，已经训练好的深度学习模型的知识被应用于不同但相关的问题。例如，如果您训练一个简单的分类器来预测图像中是否包含一只猫，您可以使用模型在训练过程中获得的知识来识别其他动物。</p><p id="0ad9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用迁移学习，我们基本上试图利用在一个任务中学到的知识来提高另一个任务的概括能力。我们将网络在“任务 A”中学习到的权重转移到新的“任务 b”</p><h1 id="55d5" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">迁移学习和传统的机器学习有什么不同？</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ko"><img src="../Images/2928c29d38068ba2f8962df1fa7f3c58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IPtOaobgDpV-FBcf1w_eog.png"/></div></div></figure><h1 id="9891" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">迁移学习的方法</h1><h2 id="ebc5" class="kp jq hi bd jr kq kr ks jv kt ku kv jz iq kw kx kd iu ky kz kh iy la lb kl lc bi translated">1.训练模型以重用它</h2><p id="387c" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">想象一下，你想解决任务 A，但没有足够的数据来训练一个深度神经网络。解决这个问题的一种方法是找到一个有大量数据的相关任务 B。在任务 B 中训练深度神经网络，并使用该模型作为解决任务 a 的起点。您是需要使用整个模型还是只使用几个层，这在很大程度上取决于您要解决的问题。</p><p id="78ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您在两个任务中有相同的输入，那么可以重用模型并为您的新输入进行预测。或者，改变和重新训练不同的任务特定层和输出层是一种探索的方法。</p><h2 id="5518" class="kp jq hi bd jr kq kr ks jv kt ku kv jz iq kw kx kd iu ky kz kh iy la lb kl lc bi translated">2.使用预先训练的模型</h2><p id="8353" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">第二种方法是使用已经预先训练好的模型。有很多这样的模型，所以一定要做一些研究。重用多少层，重新训练多少层取决于问题。</p><p id="fb79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，Keras 提供了九个预训练模型，可用于迁移学习、预测、特征提取和微调。你可以在这里找到这些模型，以及一些关于如何使用它们的简短教程。也有很多研究机构发布训练好的模型。</p><p id="c52c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种类型的迁移学习在整个深度学习中最常用。</p><h2 id="35ea" class="kp jq hi bd jr kq kr ks jv kt ku kv jz iq kw kx kd iu ky kz kh iy la lb kl lc bi translated">3.特征抽出</h2><p id="8f5a" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">另一种方法是使用深度学习来发现你的问题的最佳表示，这意味着找到最重要的特征。这种方法也被称为表征学习，通常可以获得比手工设计的表征更好的表现。</p><h1 id="cfa5" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">项目:借助迁移学习预测肺炎</h1><p id="2e54" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated"><strong class="ih hj">数据集来源:</strong><a class="ae li" href="https://drive.google.com/drive/folders/1Vz7QDBwASNCUgE8dzCWPLjiGOpEg1mS5?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://drive . Google . com/drive/folders/1 vz 7 qdbwasncuge 8 dzcwpljigope 1g ms5？usp =分享</a></p><p id="0d2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考的研究论文:</strong></p><ol class=""><li id="2e96" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated"><a class="ae li" href="https://arxiv.org/abs/1403.6382" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1403.6382</a></li><li id="c98f" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated"><a class="ae li" href="https://arxiv.org/abs/1411.1792" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1411.1792</a></li></ol></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><h2 id="0b3d" class="kp jq hi bd jr kq kr ks jv kt ku kv jz iq kw kx kd iu ky kz kh iy la lb kl lc bi translated">代码和方法</h2><blockquote class="me mf mg"><p id="1238" class="if ig mh ih b ii ij ik il im in io ip mi ir is it mj iv iw ix mk iz ja jb jc hb bi translated"><strong class="ih hj">导入必要的库</strong></p></blockquote><pre class="je jf jg jh fd ml mm mn mo aw mp bi"><span id="ad9e" class="kp jq hi mm b fi mq mr l ms mt">import torch<br/>import torch.nn as nn<br/>import torch.optim as optim<br/>from torch.optim import lr_scheduler<br/>import numpy as np<br/>import torchvision<br/>from torchvision import datasets, models, transforms<br/>import matplotlib.pyplot as plt<br/>import time<br/>import os<br/>import copy</span></pre><blockquote class="me mf mg"><p id="bed9" class="if ig mh ih b ii ij ik il im in io ip mi ir is it mj iv iw ix mk iz ja jb jc hb bi translated"><strong class="ih hj">用于训练和验证的数据扩充和标准化</strong></p></blockquote><pre class="je jf jg jh fd ml mm mn mo aw mp bi"><span id="55ee" class="kp jq hi mm b fi mq mr l ms mt">mean = np.array([0.5, 0.5, 0.5])<br/>std = np.array([0.25, 0.25, 0.25])</span><span id="6cba" class="kp jq hi mm b fi mu mr l ms mt">data_transforms = {<br/>    'train': transforms.Compose([<br/>        transforms.RandomResizedCrop(224),<br/>        transforms.RandomHorizontalFlip(),<br/>        transforms.ToTensor(),<br/>        transforms.Normalize(mean, std)<br/>    ]),<br/>    'val': transforms.Compose([<br/>        transforms.Resize(256),<br/>        transforms.CenterCrop(224),<br/>        transforms.ToTensor(),<br/>        transforms.Normalize(mean, std)<br/>    ]),<br/>}</span></pre><blockquote class="me mf mg"><p id="9944" class="if ig mh ih b ii ij ik il im in io ip mi ir is it mj iv iw ix mk iz ja jb jc hb bi translated"><strong class="ih hj">加载数据:我们将使用 torchvision 和 torch.utils.data 包来加载数据。</strong></p></blockquote><pre class="je jf jg jh fd ml mm mn mo aw mp bi"><span id="3ebf" class="kp jq hi mm b fi mq mr l ms mt">data_dir = r'D:\Assign\X_ray\chest_xray\chest_xray'<br/>image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),<br/>                                          data_transforms[x])<br/>                  for x in ['train', 'val']}<br/>dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,<br/>                                             shuffle=True, num_workers=0)<br/>              for x in ['train', 'val']}<br/>dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}<br/>class_names = image_datasets['train'].classes</span><span id="8241" class="kp jq hi mm b fi mu mr l ms mt">device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")<br/>print(class_names)</span></pre><blockquote class="me mf mg"><p id="77ae" class="if ig mh ih b ii ij ik il im in io ip mi ir is it mj iv iw ix mk iz ja jb jc hb bi translated"><strong class="ih hj">可视化一些图像</strong></p></blockquote><pre class="je jf jg jh fd ml mm mn mo aw mp bi"><span id="db99" class="kp jq hi mm b fi mq mr l ms mt">def imshow(inp, title):<br/>    """Imshow for Tensor."""<br/>    inp = inp.numpy().transpose((1, 2, 0))<br/>    inp = std * inp + mean<br/>    inp = np.clip(inp, 0, 1)<br/>    plt.imshow(inp)<br/>    plt.title(title)<br/>    plt.show()</span><span id="9c34" class="kp jq hi mm b fi mu mr l ms mt"># Get a batch of training data<br/>inputs, classes = next(iter(dataloaders['train']))</span><span id="0896" class="kp jq hi mm b fi mu mr l ms mt"># Make a grid from batch<br/>out = torchvision.utils.make_grid(inputs)</span><span id="24fd" class="kp jq hi mm b fi mu mr l ms mt">imshow(out, title=[class_names[x] for x in classes])</span></pre><p id="cfe7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">训练模特</strong></p><ol class=""><li id="df1f" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated">计划学习率</li><li id="e93f" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">保存最佳模型</li></ol><pre class="je jf jg jh fd ml mm mn mo aw mp bi"><span id="020d" class="kp jq hi mm b fi mq mr l ms mt">def train_model(model, criterion, optimizer, scheduler, num_epochs=25):<br/>    since = time.time()</span><span id="daef" class="kp jq hi mm b fi mu mr l ms mt">best_model_wts = copy.deepcopy(model.state_dict())<br/>    best_acc = 0.0</span><span id="fbc0" class="kp jq hi mm b fi mu mr l ms mt">for epoch in range(num_epochs):<br/>        print('Epoch {}/{}'.format(epoch, num_epochs - 1))<br/>        print('-' * 10)</span><span id="05fd" class="kp jq hi mm b fi mu mr l ms mt"># Each epoch has a training and validation phase<br/>        for phase in ['train', 'val']:<br/>            if phase == 'train':<br/>                model.train()  # Set model to training mode<br/>            else:<br/>                model.eval()   # Set model to evaluate mode</span><span id="b8e1" class="kp jq hi mm b fi mu mr l ms mt">running_loss = 0.0<br/>            running_corrects = 0</span><span id="6fcb" class="kp jq hi mm b fi mu mr l ms mt"># Iterate over data.<br/>            for inputs, labels in dataloaders[phase]:<br/>                inputs = inputs.to(device)<br/>                labels = labels.to(device)</span><span id="a043" class="kp jq hi mm b fi mu mr l ms mt"># forward<br/>                # track history if only in train<br/>                with torch.set_grad_enabled(phase == 'train'):<br/>                    outputs = model(inputs)<br/>                    _, preds = torch.max(outputs, 1)<br/>                    loss = criterion(outputs, labels)</span><span id="f35e" class="kp jq hi mm b fi mu mr l ms mt"># backward + optimize only if in training phase<br/>                    if phase == 'train':<br/>                        optimizer.zero_grad()<br/>                        loss.backward()<br/>                        optimizer.step()</span><span id="15aa" class="kp jq hi mm b fi mu mr l ms mt"># statistics<br/>                running_loss += loss.item() * inputs.size(0)<br/>                running_corrects += torch.sum(preds == labels.data)</span><span id="2f5e" class="kp jq hi mm b fi mu mr l ms mt">if phase == 'train':<br/>                scheduler.step()</span><span id="b664" class="kp jq hi mm b fi mu mr l ms mt">epoch_loss = running_loss / dataset_sizes[phase]<br/>            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><span id="4437" class="kp jq hi mm b fi mu mr l ms mt">print('{} Loss: {:.4f} Acc: {:.4f}'.format(<br/>                phase, epoch_loss, epoch_acc))</span><span id="c3ad" class="kp jq hi mm b fi mu mr l ms mt"># deep copy the model<br/>            if phase == 'val' and epoch_acc &gt; best_acc:<br/>                best_acc = epoch_acc<br/>                best_model_wts = copy.deepcopy(model.state_dict())</span><span id="09a1" class="kp jq hi mm b fi mu mr l ms mt">print()</span><span id="28db" class="kp jq hi mm b fi mu mr l ms mt">time_elapsed = time.time() - since<br/>    print('Training complete in {:.0f}m {:.0f}s'.format(<br/>        time_elapsed // 60, time_elapsed % 60))<br/>    print('Best val Acc: {:4f}'.format(best_acc))</span><span id="70b9" class="kp jq hi mm b fi mu mr l ms mt"># load best model weights<br/>    model.load_state_dict(best_model_wts)<br/>    return model</span></pre><blockquote class="me mf mg"><p id="9c2f" class="if ig mh ih b ii ij ik il im in io ip mi ir is it mj iv iw ix mk iz ja jb jc hb bi translated"><strong class="ih hj">微调 Convnet，加载预训练模型，重置最终全连接层。</strong></p></blockquote><pre class="je jf jg jh fd ml mm mn mo aw mp bi"><span id="cb28" class="kp jq hi mm b fi mq mr l ms mt">model = models.resnet18(pretrained=True)<br/>num_ftrs = model.fc.in_features</span><span id="ad53" class="kp jq hi mm b fi mu mr l ms mt"><strong class="mm hj"># Here the size of each output sample is set to 2.<br/># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</strong></span><span id="60cd" class="kp jq hi mm b fi mu mr l ms mt">model.fc = nn.Linear(num_ftrs, 2)</span><span id="53c1" class="kp jq hi mm b fi mu mr l ms mt">model = model.to(device)</span><span id="e286" class="kp jq hi mm b fi mu mr l ms mt">criterion = nn.CrossEntropyLoss()</span></pre><ol class=""><li id="de3b" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated">StepLR 在每个 step_size 时期通过伽玛衰减每个参数组的学习率</li><li id="1fd3" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">每 7 个时期以 0.1 的因子衰减 LR</li><li id="a53b" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">学习率调度应该在优化器更新后应用，例如，您应该这样编写代码:<br/># for epoch in range(100):<br/># train(…)<br/># validate(…)<br/># scheduler . step()</li></ol><pre class="je jf jg jh fd ml mm mn mo aw mp bi"><span id="5b0b" class="kp jq hi mm b fi mq mr l ms mt">step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)</span><span id="6259" class="kp jq hi mm b fi mu mr l ms mt">model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=10)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mv"><img src="../Images/7477ef61c4f4a28b494709f4c971ab1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Zr39s6CS9bbNcewxYfv5g.png"/></div></div><figcaption class="mw mx et er es my mz bd b be z dx translated"><strong class="bd jr">历元上的训练模型= 8 </strong></figcaption></figure><blockquote class="me mf mg"><p id="b960" class="if ig mh ih b ii ij ik il im in io ip mi ir is it mj iv iw ix mk iz ja jb jc hb bi translated"><strong class="ih hj">现在将训练好的模型应用于我们的问题陈述</strong></p></blockquote><pre class="je jf jg jh fd ml mm mn mo aw mp bi"><span id="b49d" class="kp jq hi mm b fi mq mr l ms mt">model_conv = torchvision.models.resnet18(pretrained=True)<br/>for param in model_conv.parameters():<br/>    param.requires_grad = False</span><span id="6c5a" class="kp jq hi mm b fi mu mr l ms mt"><strong class="mm hj"># Parameters of newly constructed modules have requires_grad=True by default</strong></span><span id="a6cf" class="kp jq hi mm b fi mu mr l ms mt">num_ftrs = model_conv.fc.in_features<br/>model_conv.fc = nn.Linear(num_ftrs, 2)</span><span id="5069" class="kp jq hi mm b fi mu mr l ms mt">model_conv = model_conv.to(device)</span><span id="be16" class="kp jq hi mm b fi mu mr l ms mt">criterion = nn.CrossEntropyLoss()</span><span id="e6d3" class="kp jq hi mm b fi mu mr l ms mt"><strong class="mm hj"># Observe that only parameters of final layer are being optimized as<br/># opposed to before.</strong><br/>optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)</span><span id="dd99" class="kp jq hi mm b fi mu mr l ms mt"><strong class="mm hj"># Decay LR by a factor of 0.1 every 6epochs</strong><br/>exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)</span><span id="28ae" class="kp jq hi mm b fi mu mr l ms mt">model_conv = train_model(model_conv, criterion, optimizer_conv,<br/>                         exp_lr_scheduler, num_epochs=6)</span></pre><h1 id="6230" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">在测试图像上显示结果</h1><pre class="je jf jg jh fd ml mm mn mo aw mp bi"><span id="4d09" class="kp jq hi mm b fi mq mr l ms mt">def visualize_model(model, num_images=2):<br/>    was_training = model.training<br/>    model.eval()<br/>    images_so_far = 0<br/>    fig = plt.figure()</span><span id="8b22" class="kp jq hi mm b fi mu mr l ms mt">with torch.no_grad():<br/>        for i, (inputs, labels) in enumerate(dataloaders['val']):<br/>            inputs = inputs.to(device)<br/>            labels = labels.to(device)</span><span id="17a7" class="kp jq hi mm b fi mu mr l ms mt">outputs = model(inputs)<br/>            _, preds = torch.max(outputs, 1)</span><span id="fa55" class="kp jq hi mm b fi mu mr l ms mt">for j in range(inputs.size()[0]):<br/>                images_so_far += 1<br/>                ax = plt.subplot(num_images//2, 2, images_so_far)<br/>                ax.axis('off')<br/>                ax.set_title('predicted: {}'.format(class_names[preds[j]]))<br/>                imshow(inputs.cpu().data[j])</span><span id="2e1e" class="kp jq hi mm b fi mu mr l ms mt">if images_so_far == num_images:<br/>                    model.train(mode=was_training)<br/>                    return<br/>        model.train(mode=was_training)</span></pre></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><pre class="ml mm mn mo aw mp bi"><span id="c92a" class="kp jq hi mm b fi na nb nc nd ne mr l ms mt">visualize_model(model,num_images=4)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nf"><img src="../Images/f43bd524ad280711c28bdf87179b0433.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*HFRUUbw_hR7bNk6r9moVRQ.png"/></div></figure></div></div>    
</body>
</html>