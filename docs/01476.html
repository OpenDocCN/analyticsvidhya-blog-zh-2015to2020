<html>
<head>
<title>Generating Keras like model summary in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在PyTorch中生成类似模型摘要的Keras</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/generating-keras-like-model-summary-in-pytorch-110cb37c2cc1?source=collection_archive---------4-----------------------#2019-10-25">https://medium.com/analytics-vidhya/generating-keras-like-model-summary-in-pytorch-110cb37c2cc1?source=collection_archive---------4-----------------------#2019-10-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/6f7eb3d83be506403771583581fda694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ddbrRRMUIt2OI8ro"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://unsplash.com/@webaroo?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Webaroo.com.au</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="369b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你是一个热情的keras用户，并且最近正在迁移到PyTorch，我敢肯定你会错过很多Keras的功能。向<a class="ae iu" href="https://www.google.com/search?safe=strict&amp;client=ubuntu&amp;hs=eGg&amp;channel=fs&amp;sxsrf=ACYBGNSBLhLecE1T_PCvNeejWDadspbuow:1572002688856&amp;q=Fran%C3%A7ois+Chollet&amp;stick=H4sIAAAAAAAAAONgVuLVT9c3NMwwSk_Lys4oXMQq6FaUmHd4eX5msYJzRn5OTmoJAEyaoxIlAAAA&amp;sa=X&amp;ved=2ahUKEwjCo-uuprflAhUNUI8KHV6bCVgQmxMoATAkegQIDRAL" rel="noopener ugc nofollow" target="_blank">致敬</a>为<a class="ae iu" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank">干杯</a>。</p><p id="ba40" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中一个令人惊奇的特性是使用Keras model.summary()快速获得模型摘要，并立即理解您开发的架构</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="6548" class="kc kd hi jy b fi ke kf l kg kh">from keras.datasets import mnist<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten<br/>from keras.layers import Conv2D, MaxPooling2D</span><span id="f92e" class="kc kd hi jy b fi ki kf l kg kh">model = Sequential()<br/>model.add(Conv2D(32, kernel_size=(3, 3),<br/>                 activation='relu',<br/>                 input_shape=input_shape))<br/>model.add(Conv2D(64, (3, 3), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))<br/>model.add(Flatten())<br/>model.add(Dense(128, activation='relu'))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(num_classes,activation='softmax'))</span><span id="c162" class="kc kd hi jy b fi ki kf l kg kh">model.summary()</span><span id="2009" class="kc kd hi jy b fi ki kf l kg kh">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_4 (Conv2D)            (None, 222, 222, 32)      896       <br/>_________________________________________________________________<br/>conv2d_5 (Conv2D)            (None, 220, 220, 64)      18496     <br/>_________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2 (None, 110, 110, 64)      0         <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 110, 110, 64)      0         <br/>_________________________________________________________________<br/>flatten_1 (Flatten)          (None, 774400)            0         <br/>_________________________________________________________________<br/>dense_10 (Dense)             (None, 128)               99123328  <br/>_________________________________________________________________<br/>dropout_2 (Dropout)          (None, 128)               0         <br/>_________________________________________________________________<br/>dense_11 (Dense)             (None, 10)                1290      <br/>=================================================================<br/>Total params: 99,144,010<br/>Trainable params: 99,144,010<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="7680" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的片段来自Keras，我们可以看到我们可以多么容易地看到输出形状和参数数量的整个模型摘要。</p><p id="810b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">PyTorch中有类似的功能吗？？？是的。！！</p><p id="f55b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是第八届火炬节图书馆</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kj"><img src="../Images/478ab667a3cdff4cac21133c02fda3d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AoS83em16SEbTQDPvIPYGQ.png"/></div></div></figure><p id="bcc9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">安装</strong></p><p id="62f9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">安装非常简单</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="5fba" class="kc kd hi jy b fi ke kf l kg kh">pip install torchsummary</span></pre><p id="d8f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">使用火炬摘要</strong></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="55af" class="kc kd hi jy b fi ke kf l kg kh">summary(model,input_shape)</span></pre><p id="f58c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我通过一个例子来说明，为了进行说明，我将导入一个在<a class="ae iu" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据集上训练的预训练<a class="ae iu" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank"> Alexnet </a>模型</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="0cd4" class="kc kd hi jy b fi ke kf l kg kh">from torchvision import models<br/>from torchsummary import summary</span><span id="a9cb" class="kc kd hi jy b fi ki kf l kg kh"># import the pretrained alexnet<br/>model = models.alexnet(pretrained=True)<br/>summary(model,(3,224,224))</span><span id="ff95" class="kc kd hi jy b fi ki kf l kg kh"># And you should see something like this<br/>----------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv2d-1           [-1, 64, 55, 55]          23,296<br/>              ReLU-2           [-1, 64, 55, 55]               0<br/>         MaxPool2d-3           [-1, 64, 27, 27]               0<br/>            Conv2d-4          [-1, 192, 27, 27]         307,392<br/>              ReLU-5          [-1, 192, 27, 27]               0<br/>         MaxPool2d-6          [-1, 192, 13, 13]               0<br/>            Conv2d-7          [-1, 384, 13, 13]         663,936<br/>              ReLU-8          [-1, 384, 13, 13]               0<br/>            Conv2d-9          [-1, 256, 13, 13]         884,992<br/>             ReLU-10          [-1, 256, 13, 13]               0<br/>           Conv2d-11          [-1, 256, 13, 13]         590,080<br/>             ReLU-12          [-1, 256, 13, 13]               0<br/>        MaxPool2d-13            [-1, 256, 6, 6]               0<br/>          Dropout-14                 [-1, 9216]               0<br/>           Linear-15                 [-1, 4096]      37,752,832<br/>             ReLU-16                 [-1, 4096]               0<br/>          Dropout-17                 [-1, 4096]               0<br/>           Linear-18                 [-1, 4096]      16,781,312<br/>             ReLU-19                 [-1, 4096]               0<br/>           Linear-20                 [-1, 1000]       4,097,000<br/>================================================================<br/>Total params: 61,100,840<br/>Trainable params: 61,100,840<br/>Non-trainable params: 0<br/>----------------------------------------------------------------<br/>Input size (MB): 0.57<br/>Forward/backward pass size (MB): 8.31<br/>Params size (MB): 233.08<br/>Estimated Total Size (MB): 241.96<br/>----------------------------------------------------------------</span></pre><p id="98f1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">带Cuda </strong></p><p id="023b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果您有cuda，您可能需要将您的模型导出到cuda，如果您得到如下所示的运行时错误</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="8d51" class="kc kd hi jy b fi ke kf l kg kh">model = models.alexnet(pretrained=True)<br/>summary(model,(3,224,224))</span><span id="b6ec" class="kc kd hi jy b fi ki kf l kg kh">RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same</span><span id="61cb" class="kc kd hi jy b fi ki kf l kg kh">#instead do this</span><span id="3048" class="kc kd hi jy b fi ki kf l kg kh">model = models.alexnet(pretrained=True)<br/>model.cuda()<br/>summary(model,(3,224,224))</span><span id="7376" class="kc kd hi jy b fi ki kf l kg kh">----------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv2d-1           [-1, 64, 55, 55]          23,296<br/>              ReLU-2           [-1, 64, 55, 55]               0<br/>         MaxPool2d-3           [-1, 64, 27, 27]               0<br/>            Conv2d-4          [-1, 192, 27, 27]         307,392<br/>              ReLU-5          [-1, 192, 27, 27]               0<br/>         MaxPool2d-6          [-1, 192, 13, 13]               0<br/>            Conv2d-7          [-1, 384, 13, 13]         663,936<br/>              ReLU-8          [-1, 384, 13, 13]               0<br/>            Conv2d-9          [-1, 256, 13, 13]         884,992<br/>             ReLU-10          [-1, 256, 13, 13]               0<br/>           Conv2d-11          [-1, 256, 13, 13]         590,080<br/>             ReLU-12          [-1, 256, 13, 13]               0<br/>        MaxPool2d-13            [-1, 256, 6, 6]               0<br/>AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0<br/>          Dropout-15                 [-1, 9216]               0<br/>           Linear-16                 [-1, 4096]      37,752,832<br/>             ReLU-17                 [-1, 4096]               0<br/>          Dropout-18                 [-1, 4096]               0<br/>           Linear-19                 [-1, 4096]      16,781,312<br/>             ReLU-20                 [-1, 4096]               0<br/>           Linear-21                 [-1, 1000]       4,097,000<br/>================================================================<br/>Total params: 61,100,840<br/>Trainable params: 61,100,840<br/>Non-trainable params: 0<br/>----------------------------------------------------------------<br/>Input size (MB): 0.57<br/>Forward/backward pass size (MB): 8.38<br/>Params size (MB): 233.08<br/>Estimated Total Size (MB): 242.03<br/>----------------------------------------------------------------</span></pre><p id="f415" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">一个3DCNN模型的概要</strong></p><p id="06a6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里，输入形状将具有帧数的额外维度。我正在使用来自Kensho Hara-<a class="ae iu" href="https://github.com/kenshohara/video-classification-3d-cnn-pytorch" rel="noopener ugc nofollow" target="_blank">https://github . com/kenshohara/video-class ification-3D-CNN-py torch</a>的3D CNN ResNet进行视频分类</p><p id="4836" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它是一个3D ResNet-18架构，输入形状为(3，16，112，112)</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="ee76" class="kc kd hi jy b fi ke kf l kg kh">model = generate_model(opt)<br/>summary(model,(3,16,112,112))</span><span id="5276" class="kc kd hi jy b fi ki kf l kg kh">----------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv3d-1       [-1, 64, 16, 56, 56]          65,856<br/>       BatchNorm3d-2       [-1, 64, 16, 56, 56]             128<br/>              ReLU-3       [-1, 64, 16, 56, 56]               0<br/>         MaxPool3d-4        [-1, 64, 8, 28, 28]               0<br/>            Conv3d-5        [-1, 64, 8, 28, 28]         110,592<br/>       BatchNorm3d-6        [-1, 64, 8, 28, 28]             128<br/>              ReLU-7        [-1, 64, 8, 28, 28]               0<br/>            Conv3d-8        [-1, 64, 8, 28, 28]         110,592<br/>       BatchNorm3d-9        [-1, 64, 8, 28, 28]             128<br/>             ReLU-10        [-1, 64, 8, 28, 28]               0<br/>       BasicBlock-11        [-1, 64, 8, 28, 28]               0<br/>           Conv3d-12        [-1, 64, 8, 28, 28]         110,592<br/>      BatchNorm3d-13        [-1, 64, 8, 28, 28]             128<br/>             ReLU-14        [-1, 64, 8, 28, 28]               0<br/>           Conv3d-15        [-1, 64, 8, 28, 28]         110,592<br/>      BatchNorm3d-16        [-1, 64, 8, 28, 28]             128<br/>             ReLU-17        [-1, 64, 8, 28, 28]               0<br/>       BasicBlock-18        [-1, 64, 8, 28, 28]               0<br/>           Conv3d-19       [-1, 128, 4, 14, 14]         221,184<br/>      BatchNorm3d-20       [-1, 128, 4, 14, 14]             256<br/>             ReLU-21       [-1, 128, 4, 14, 14]               0<br/>           Conv3d-22       [-1, 128, 4, 14, 14]         442,368<br/>      BatchNorm3d-23       [-1, 128, 4, 14, 14]             256<br/>             ReLU-24       [-1, 128, 4, 14, 14]               0<br/>       BasicBlock-25       [-1, 128, 4, 14, 14]               0<br/>           Conv3d-26       [-1, 128, 4, 14, 14]         442,368<br/>      BatchNorm3d-27       [-1, 128, 4, 14, 14]             256<br/>             ReLU-28       [-1, 128, 4, 14, 14]               0<br/>           Conv3d-29       [-1, 128, 4, 14, 14]         442,368<br/>      BatchNorm3d-30       [-1, 128, 4, 14, 14]             256<br/>             ReLU-31       [-1, 128, 4, 14, 14]               0<br/>       BasicBlock-32       [-1, 128, 4, 14, 14]               0<br/>           Conv3d-33         [-1, 256, 2, 7, 7]         884,736<br/>      BatchNorm3d-34         [-1, 256, 2, 7, 7]             512<br/>             ReLU-35         [-1, 256, 2, 7, 7]               0<br/>           Conv3d-36         [-1, 256, 2, 7, 7]       1,769,472<br/>      BatchNorm3d-37         [-1, 256, 2, 7, 7]             512<br/>             ReLU-38         [-1, 256, 2, 7, 7]               0<br/>       BasicBlock-39         [-1, 256, 2, 7, 7]               0<br/>           Conv3d-40         [-1, 256, 2, 7, 7]       1,769,472<br/>      BatchNorm3d-41         [-1, 256, 2, 7, 7]             512<br/>             ReLU-42         [-1, 256, 2, 7, 7]               0<br/>           Conv3d-43         [-1, 256, 2, 7, 7]       1,769,472<br/>      BatchNorm3d-44         [-1, 256, 2, 7, 7]             512<br/>             ReLU-45         [-1, 256, 2, 7, 7]               0<br/>       BasicBlock-46         [-1, 256, 2, 7, 7]               0<br/>           Conv3d-47         [-1, 512, 1, 4, 4]       3,538,944<br/>      BatchNorm3d-48         [-1, 512, 1, 4, 4]           1,024<br/>             ReLU-49         [-1, 512, 1, 4, 4]               0<br/>           Conv3d-50         [-1, 512, 1, 4, 4]       7,077,888<br/>      BatchNorm3d-51         [-1, 512, 1, 4, 4]           1,024<br/>             ReLU-52         [-1, 512, 1, 4, 4]               0<br/>       BasicBlock-53         [-1, 512, 1, 4, 4]               0<br/>           Conv3d-54         [-1, 512, 1, 4, 4]       7,077,888<br/>      BatchNorm3d-55         [-1, 512, 1, 4, 4]           1,024<br/>             ReLU-56         [-1, 512, 1, 4, 4]               0<br/>           Conv3d-57         [-1, 512, 1, 4, 4]       7,077,888<br/>      BatchNorm3d-58         [-1, 512, 1, 4, 4]           1,024<br/>             ReLU-59         [-1, 512, 1, 4, 4]               0<br/>       BasicBlock-60         [-1, 512, 1, 4, 4]               0<br/>        AvgPool3d-61         [-1, 512, 1, 1, 1]               0<br/>           Linear-62                  [-1, 400]         205,200<br/>           ResNet-63                  [-1, 400]               0<br/>================================================================<br/>Total params: 33,235,280<br/>Trainable params: 33,235,280<br/>Non-trainable params: 0<br/>----------------------------------------------------------------<br/>Input size (MB): 2.30<br/>Forward/backward pass size (MB): 133.72<br/>Params size (MB): 126.78<br/>Estimated Total Size (MB): 262.80<br/>----------------------------------------------------------------</span></pre><p id="5567" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我希望这篇文章有用！！</p><p id="9447" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在那之前，继续学习！继续探索神经元！</p></div></div>    
</body>
</html>