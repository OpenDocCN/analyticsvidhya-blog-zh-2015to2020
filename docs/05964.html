<html>
<head>
<title>Auto Encoders and Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动编码器和风格转换</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/lets-discuss-encoders-and-style-transfer-c0494aca6090?source=collection_archive---------11-----------------------#2020-05-07">https://medium.com/analytics-vidhya/lets-discuss-encoders-and-style-transfer-c0494aca6090?source=collection_archive---------11-----------------------#2020-05-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7774" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自动编码器和风格转移小指南。</p><p id="2294" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">欢迎大家！这是我在一个月内完成<em class="jd">深度学习纳米学位</em>的旅程中的第八篇文字！我已经完成了该学位总共六个模块中第三个模块的73%。今天的话题包括<em class="jd">自动编码器</em>，他们做什么和什么是<em class="jd">风格转移。</em></p><h2 id="df48" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated"><strong class="ak">第10天</strong></h2><p id="c341" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">今天第一课的名字是<em class="jd">自动编码器</em>。我希望在明天之前完成整个模块。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es ke"><img src="../Images/f8191b15f387e3da0622872e1dae336d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*tvwYybdIwvoOs0DuUEJJTg.png"/></div></figure><h1 id="88a3" class="km jf hi bd jg kn ko kp jk kq kr ks jo kt ku kv jr kw kx ky ju kz la lb jx lc bi translated">自动编码器</h1><p id="ba1d" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">编码器本质上是为完成特定工作而设计和训练的神经网络。现在，在进入真正的内容之前，让我告诉你有两种类型的编码器，编码器&amp;解码器。</p><blockquote class="ld le lf"><p id="cab6" class="if ig jd ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">不同的是，这些编码器学习新的算法来有效地完成工作，而不是由人类编码。</p><p id="9754" class="if ig jd ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">通常，整个模型是通过减少/最小化输入和输出之间的差异来构建的。这样，中间层将是输入数据的压缩表示。</p></blockquote><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lj"><img src="../Images/928f5e00273d72dc9b3454be5520696c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*blDYt-BnN-5BUKqy0FsrCA.png"/></div></div></figure><h2 id="0aed" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">编码器</h2><p id="41b5" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">这是自动编码器的第一部分。它的作用是，基本上缩短了图像的数据。它获取图像，将其传递到一组卷积层和最大池层。卷积层用于识别模式并将权重保存在新矩阵中。然后，对其应用最大池以缩短其大小，并重复该过程，直到我们有了一个包含识别图像所需信息的小矩阵。</p><blockquote class="ld le lf"><p id="81cb" class="if ig jd ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">使用编码器的关键是，它能够以保持重要特征的方式压缩图像。然后这些可以用来在他们所学的知识上建立新的信息。</p></blockquote><h2 id="5dd3" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">解码器</h2><p id="3e36" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">这是自动编码器的第二部分。这和编码器的工作完全相反。它接收一个图像并对其进行一些操作以增加其大小/尺寸。</p><p id="ea4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们知道这些是什么，我们可以谈得更深入一点。</p><h2 id="a97a" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">MLP自动编码器</h2><p id="1ba8" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">编码器的基本工作是将图片压缩成矢量。<strong class="ih hj">为什么有用？</strong>让我们举一个例子。让我们假设你需要送一个朋友这个模型。现在，发送一个已经训练好的带有权重的模型可能会造成混乱，但是当你从编码器传递图像时，图片的大小会减小，但它仍然具有那些重要的特征。然后，您可以轻松地发送它们。上传到云时也是如此。我们可以通过使用这个来大幅减小图像的大小。由于这些缩短的图像包含了所有的特征，它们可以通过将信息传递给解码器而被重新创建。</p><blockquote class="ld le lf"><p id="1d5f" class="if ig jd ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">我们只需要最小化测试损失，而不是验证损失。所有层都是ReLU，最后一层是Sigmoid，用于将它们转换成概率。</p></blockquote><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lo"><img src="../Images/19a7e02118787cb94e070873b6cbca0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*_JLyYpyrNt9B4neY9gtrKw.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">MLP自动编码器</figcaption></figure><h2 id="2706" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">卷积层自动编码器</h2><p id="fb3a" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">这里，在这种方法中，我们在编码和解码部分使用卷积层。这比使用标准MLP要好，因为我们知道CNN通常比MLP更擅长处理图片。</p><p id="09bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，编码器的过程很简单。当我们在解码过程中到达池层时，主要部分就出现了。现在，我们基本上要扭转这里的MaxPool效应，姑且称之为<strong class="ih hj"> <em class="jd"> UnPooling </em> </strong>。有许多技术可以执行这一步，下面我们来谈谈<strong class="ih hj"> <em class="jd">最近邻</em> </strong>算法如何帮助我们。在这种情况下，我们只需复制一个单元格的值，并将其粘贴到未缓冲层的相应单元格中。这是可以的，但是在现实世界中，数据是相当混乱的，简单地复制这些值无法得到令人满意的模型。因此，我们可以<em class="jd">学习</em>如何取消图层。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lt"><img src="../Images/7824b05667afb21cf9e82f7105316dea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QYWNa1YpxHLZW0ZRv9rOeg.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">CNN自动编码器</figcaption></figure><h2 id="6d80" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">转置卷积层</h2><p id="11e0" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">这些也被称为<strong class="ih hj"> <em class="jd">解卷积层</em> </strong>。它有可学习的参数。解码器使用转置卷积层来<em class="jd">增加</em>输入层的宽度和高度。它们的工作原理与卷积层几乎完全相同，但顺序相反。PyTorch为我们提供了一个创建图层的简单方法，使用这个函数'<a class="ae lu" href="https://pytorch.org/docs/stable/nn.html#convtranspose2d" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> <em class="jd"> nn。conv transpose 2d</em></strong></a>’。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lv"><img src="../Images/ead766a3e2956546cc685b16dc29a1d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QBXb9dxWf-6BwmoYUoleqA.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">去CNN</figcaption></figure><h2 id="7ce1" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">进展</h2><p id="ea75" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">输入层中的<em class="jd">步距</em>导致转置卷积层中的<em class="jd">步距</em>更大。例如，如果您有一个3x3内核，输入层中的一个3x3补丁将减少到卷积层中的一个单元。相比之下，输入层中的一个单元将在转置卷积层中扩展为3×3路径。</p><p id="5c4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用最近邻法时，我们需要采取的方法是放大图像。比方说，我们取一个2乘2的图像，然后，我们把它变成4乘4的区域。为了应用这一点，我们在forward函数中使用不同的语法。</p><pre class="kf kg kh ki fd lw lx ly lz aw ma bi"><span id="3cb9" class="je jf hi lx b fi mb mc l md me">F.upsample(input, scale_factor, mode='nearest')</span></pre><p id="4f1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这都是为了自动编码器。我们现在继续吧。</p></div><div class="ab cl mf mg gp mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="hb hc hd he hf"><h1 id="4bf5" class="km jf hi bd jg kn mm kp jk kq mn ks jo kt mo kv jr kw mp ky ju kz mq lb jx lc bi translated">风格转移</h1><p id="f066" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">神经风格转移</em> </strong>是指<em class="jd">操纵</em>数字图像或视频，以采用另一幅图像的外观或视觉风格。NST算法的特点是使用<em class="jd">深度神经网络</em>来执行<em class="jd">图像变换</em>。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es mr"><img src="../Images/612ee747d08d0afddcdb7a69293dc9b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X1QfgJC02dRdxwQRiibefA.jpeg"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">风格转移示例</figcaption></figure><p id="1771" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们使用一个<em class="jd"> CNN </em>时，我们输入图像，然后图像被转换成特征图。而且，功能地图越来越注重内容表现，而不是彩色图片中的细节。当我们研究我们模型的<em class="jd"> CNN </em>层时，我们发现每一层都越来越多地存储着越来越复杂模式的信息。一个<em class="jd"> CNN </em>图层的深度实际上是该图层中特征地图的数量。</p><blockquote class="ld le lf"><p id="bd1d" class="if ig jd ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">后面的层有时也称为内容表示。</p></blockquote><h2 id="a4a5" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">风格</h2><p id="21df" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">风格可以想象成一幅画的<em class="jd">笔触</em>，纹理、颜色、图案等等。</p><h2 id="1dc8" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">过程</h2><p id="830c" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">为此，我们有两个图像，内容图像和样式图像。<em class="jd"> CNN </em>看风格图像的风格和内容图像的内容。新形象是这两者的产物。新图像的对象取自内容图像的对象或内容，颜色和纹理取自样式图像。这意味着<em class="jd">样式转移</em>只是创建了两张图像的<strong class="ih hj"><em class="jd"/></strong>混合。</p><h2 id="cfa5" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">内容损失</h2><p id="d4f6" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">当我们保存内容图像中的内容并将其应用到我们的图像后，我们计算这个损失。它基本上是内容图像的内容与结果图像有多少不同的数字表示。它是内容图像的内容与目标图像之间的损失，在等式中分别用<em class="jd"> Cc </em> &amp; <em class="jd"> Tc </em>表示。请注意，‘<em class="jd">conv</em>’是我们想要从中获取权重的卷积层。</p><pre class="kf kg kh ki fd lw lx ly lz aw ma bi"><span id="a515" class="je jf hi lx b fi mb mc l md me">#Theory<br/>Content_Loss = 1/2 np.sum(Tc - Cc)**2</span><span id="c9ca" class="je jf hi lx b fi ms mc l md me">#Actual Code Representation<br/>content_loss = torch.mean((target_features['conv'] - content_features['conv'])**2)</span></pre><p id="fb79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们创建图像时，我们的目标是尽量减少损失。这里，我们不是在训练CNN，我们只是以一种方式改变输出图像，使其风格与风格图像的风格相匹配。</p><blockquote class="mt"><p id="d28b" class="mu mv hi bd mw mx my mz na nb nc jc dx translated">我们使用CNN作为特征提取器，并使用反向传播来最小化内容损失。</p></blockquote><h2 id="5016" class="je jf hi bd jg jh nd jj jk jl ne jn jo iq nf jq jr iu ng jt ju iy nh jw jx jy bi translated">格拉姆矩阵</h2><p id="e45d" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">图像的<em class="jd">样式表示</em>依赖于特征和各个层之间的<em class="jd">样式相关性</em>。为了理解这一点，让我们考虑以下情况。</p><p id="0b85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们从一个4x4的矩阵开始。和深度为8的卷积层。因此，我们希望找到8个特征图之间的关系。我们展平特征地图。通过这样做，我们将3d conv层转换为2d值矩阵。这个矩阵将是8x16。然后我们将得到的矩阵乘以它的转置，16x8。生成的gram矩阵(8×8)包含关于该层的非本地化信息。非本地化是即使图像被打乱，信息仍然存在。</p><blockquote class="ld le lf"><p id="21eb" class="if ig jd ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">Gram矩阵将是一个正方形矩阵，其宽度和高度等于所讨论的卷积层的深度。</p></blockquote><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es ni"><img src="../Images/041d8bf580b8b36aea35052888323c03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SpbjcOBafErVW46snHoKTg.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">格拉姆矩阵</figcaption></figure><h2 id="6338" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">风格丧失</h2><p id="8df0" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">这指的是内容图像的样式与结果图像有多大不同的数字表示。在其中，我们找到了风格和目标gram矩阵之间的均方差。它是风格图像的风格与目标图像的风格之间的风格损失，在等式中分别用<em class="jd"> Ss </em> &amp; <em class="jd"> Ts </em>表示。请注意，这里的'<em class="jd"> a </em>是每层的数值个数。公式如下。请注意'<em class="jd">Target _ gram</em>'&amp;'<em class="jd">Style _ Gram</em>'分别是目标&amp;样式图像的Gram矩阵。</p><pre class="kf kg kh ki fd lw lx ly lz aw ma bi"><span id="87ae" class="je jf hi lx b fi mb mc l md me">#Theory<br/>Style_Loss = a * np.sum(Weights * (Ts - Ss)^2)</span><span id="014f" class="je jf hi lx b fi ms mc l md me">#Actual Code Representation<br/>style_loss += style_weights['conv'] * torch.mean((target_gram - style_gram)**2) / (d * h * w)</span></pre><p id="c87b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">权重</em>是样式权重，给出或多或少给每个层的样式损失的权重。这将代表每一层对我们最终的风格图像的影响程度。我们也将风格损失正常化。</p><h2 id="10a1" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">全损</h2><p id="3933" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">现在，为了计算，我们将这两个求和如下。</p><pre class="kf kg kh ki fd lw lx ly lz aw ma bi"><span id="868d" class="je jf hi lx b fi mb mc l md me">Total_Loss = (<em class="jd">a</em> * Style_Loss) + (<em class="jd">B * </em>Content_Loss)</span></pre><p id="ada4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将这些损失与一些常数相乘，使它们在输出图像中相当相等。我们通常也保持样式损失不变，<em class="jd"> a </em>，比内容损失大得多，只是为了让更多的样式融入其中。</p><blockquote class="ld le lf"><p id="2960" class="if ig jd ih b ii ij ik il im in io ip lg ir is it lh iv iw ix li iz ja jb jc hb bi translated">Alpha/Beta比率越小，您看到的风格效果就越好。然而，如果我们认为Beta比Alpha大得多，那么我们将得到一个只包含样式而不包含内容的图像。</p></blockquote><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es nj"><img src="../Images/22216a31cd094fd241ae74b019e82a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*eUbK1rlMTCyvkLPK50mZsg.jpeg"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">风格转移的结果图像</figcaption></figure></div><div class="ab cl mf mg gp mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="hb hc hd he hf"><p id="088e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我一天能走的路。我还完成了第二个项目，用迁移学习建立的“狗的品种分类器”。首先从零开始构建它，然后实现迁移学习来导入VGG16，这是一个非常好的体验。正如你所看到的，我对模型的准确性非常满意，尽管我花了近7个小时在Mac Air上进行训练。下一集再见！</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es nk"><img src="../Images/8a74872c48fcc981127eeae5f63fa174.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*eBlqH1Y3_ZhCSoTF2YzKoQ.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">模型精度</figcaption></figure></div></div>    
</body>
</html>