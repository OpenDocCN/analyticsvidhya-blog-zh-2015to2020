# Python 中波士顿住房数据集的机器学习回归和数据分析—第 2 部分

> 原文：<https://medium.com/analytics-vidhya/machine-learning-regression-and-data-analysis-with-the-boston-housing-dataset-in-python-part-2-da589b905cc3?source=collection_archive---------20----------------------->

因此，在我的上一篇文章([这里](/@davemason_34760/machine-learning-regression-and-data-analysis-with-the-boston-housing-dataset-in-python-part-1-c7bc47f4d7bf))之后，我们将数据转换成一种我们可以使用的格式，并做了一些探索性的分析来理解这些数据。现在是时候动手制作一些模型来尝试预测价格了！

# 线性回归

![](img/2cebf2ceb329a78eb0c435e9dca51423.png)

在任何 ML 项目中，好的第一步是看我们是否能建立一个尽可能简单的模型来解释我们的数据。在某些情况下，这可能足以满足客户的需求，并且简单会使它们易于理解、解释和实现。由于这个特定分析的想法是用一些更高级的 ML 方法进行实验，所以我将快速构建一个模型，然后用它作为比较其他模型的基线。

考虑到数据集相对简单，只包含数值，没有丢失数据，ML 的准备阶段相对简单。我们将数据分为训练集和测试集。我们将在训练集上构建模型，然后看看一旦完成，模型是否继续在我们的测试集上工作。最后一步是标准化数据的单步管道(将所有值放在相似的尺度上)。然后，我们可以在所有未来的模型中使用这些转换后的值。

创建一个简单的线性回归模型，保留所有要素，给出以下系数，表明 RM 和 LSTAT 是我们预期的最重要的要素。然而，有趣的是，RAD 和 DIS 等特征在这个模型中是很大的因素，这不是一个好迹象，因为它们与中值房价的相关性不是很高。

![](img/871e0c8f62af2f289e9c19d819d4e5a9.png)

查看该模型的均方根误差(RMSE ),我们看到它是 4.65(以千为单位)。这似乎很高。通常，尝试模型中包含的特性是一个好主意，或许还可以做一些转换，这可以很好地减少这个错误。然而，我更愿意继续前进，尝试一些更先进的模式。

# 随机森林模型

![](img/f6d3c9166e038b63729e9acd3f4c7501.png)

图片来源:Flickr 上的埃里克·克莱夫斯·克里斯滕森[CC BY 2.0(【https://creativecommons.org/licenses/by/2.0/】T2)]

随机森林模型是指你采用许多[决策树](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052)模型，每个模型都建立在数据的随机子集上，然后将结果汇总得到最终模型。这已被证明是非常有效的，是一个非常受欢迎的模型类型。

有许多超参数(控制模型的设置)可用于这个模型，所以要得到一个好的模型可能需要更多的工作。这种额外的调整必须与“过度拟合”数据的风险相平衡，换句话说，使模型对我们可用的数据集如此具体，以至于当我们试图将其应用于新数据时，它不会一般化。

使用基本设置构建一个随机森林模型，在我们的训练数据上，我们得到 1.58 的 RMSE(由于模型的随机性，这个值会有所不同，但始终是这个数量级)。这比我们之前的努力要低得多，但是似乎模型可能在这里过度拟合(因为这种类型的模型倾向于基础设置)，所以我们使用交叉验证技术来避免这种情况。

不涉及细节，基本上模型建立在训练集的子集上，然后在子集的剩余部分上测试。这在不同的数据子集上重复几次，然后可以对产生的误差值进行平均，以查看模型的表现如何。我们现在得到的平均 RMSE 为 3.92，比以前高了很多，但仍然比线性回归好。

接下来，我用各种不同的超参数测试了模型的构建。我把自己限制在尝试“n_estimators”、“max_features”和“bootstrap”的不同变体上。表现最好的模型的“最大特征数”为 4，“n 估计数”为 1000，“bootstrap”为假。当进行交叉验证时，该模型给出了大约 3.3 的平均 RMSE。因此，我们似乎有另一个真正的改进。

在这个阶段，我决定使用这个模型，并将其应用于测试数据集，以了解如何在看不见的数据上执行。事实上，这返回了大约 2.7 的 RMSE，这是非常不寻常的，因为它比训练数据集好。这让我怀疑这种模式是否运转良好。

看着价值的分布(见下文),似乎我们实际上是相当远的，曲线的总体形状是相似的，但峰值在相当不同的地方，我们通常预测平均价格高于 18-45k 范围内的应有价格

然而，50k 处的峰值似乎已经向下移动到 42k 左右。根据客户的要求，这可能是足够的精度，他们也可能乐于牺牲上限价格，如果将其删除，可以很好地改善模型，因为它可能会导致主峰的偏斜。

![](img/96abd90ff15cb2963979b42069a14543.png)

在这个阶段，我决定尝试一个替代模型，看看我是否能以这种方式得到更好的拟合。

# 支持向量机回归模型

另一个流行的模型类型是支持向量机，通常用于分类问题，但它也有一个回归形式，我在这里使用。这是一个更复杂的模型，你可以在这里找到更多的细节[，但是我们可以把它当作一个“黑盒”,只是拟合模型，然后调整超参数，看看我们是否可以得到一个很好的拟合。](https://en.wikipedia.org/wiki/Support-vector_machine#Regression)

仅使用默认设置拟合基本模型效果不佳，使用交叉验证时，初始拟合的 RMSE 大约为 5.1。因此，乍一看，这似乎不是一个很好的模型。然而，在对超参数进行了一点调整之后，特别是将内核改为“RBF”而不是“线性”，我能够显著提高的拟合度，在测试集上具有大约 2.98 的误差，使用交叉验证进行测量。

优化后，我将该模型应用于测试集，并返回一个 3.45 的错误。这高于训练集上的错误，但在大多数情况下这是可以预料的。当观察价格的分布时，看起来这个模型比随机森林更适合一般的形状。

主峰在同一个地方，但是稍微低一点。它还能更好地估计价格较高的地区，尽管它在这里仍有一点不足。再一次，移除这些上限值可能会很好地改进模型，并使其在最重要的区域，即 20k 左右的主峰处更加准确。进一步调整超参数也可以提高性能。

![](img/c618631ef7ee3dd655e2233e41f6b24d.png)

不幸的是，这个模型很难评估其内部发生了什么，特别是使用 rbf 核，这限制了可用的模型细节。我们牺牲了模型性能的可解释性。这是否可以接受将取决于客户的愿望。

# 结论

所以，我们现在有两个基本模型可以用来预测波士顿的房价。我们选择使用哪个将取决于最终的用例以及我们对不同模型的适应程度。可以完成的其他工作如下:

根据数据训练和测试更多模型，其他更复杂的模型可能会产生更好的结果。

考虑到只有 LSTAT 和 Room 变量在总体上似乎是重要的，我们可以简化模型，只查看这些变量，然后一次添加一个额外的变量，以查看它们如何影响结果。减少变量的数量还有一个好处，即在估计新区域时，需要收集的数据较少。

尝试在删除了封顶的平均价格数据点的情况下重新运行分析，这些数据点可能会扭曲模型。

在我们选择的模型中进一步搜索超参数。

我们总是有进一步的工作要做，通常这将取决于模型的用例来决定这是否值得去做！这无疑是一个有趣的练习，并创建了一些有趣的示例模型来展示用 Python 构建 ML 模型是多么容易。

这些类型的模型可以应用于任何类型的数据，其中我们有一个标签良好的数据集，并正在寻找一个数字输出。在未来的博客文章中，我打算看看其他技术，如时间序列分析、监督分类模型、非监督模型等。所以，敬请关注。