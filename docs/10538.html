<html>
<head>
<title>Training your First Machine Learning Model with Python’s sklearn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python的sklearn训练你的第一个机器学习模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-your-first-machine-learning-model-with-sklearn-e03d5de3bfba?source=collection_archive---------0-----------------------#2020-10-23">https://medium.com/analytics-vidhya/training-your-first-machine-learning-model-with-sklearn-e03d5de3bfba?source=collection_archive---------0-----------------------#2020-10-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="b3c1" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">逐步指南</h2><div class=""/><div class=""><h2 id="2f21" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated">本文将指导您完成机器学习模型训练所需的所有步骤，从数据预处理到模型评估！</h2></div><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/cd9988483a0cfedb5197609133be27a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fSCVtg54LRWs1zDSiPCqyg.jpeg"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">照片由来自<a class="ae jw" href="https://www.pexels.com/photo/working-industry-internet-writing-4578660/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae jw" href="https://www.pexels.com/@markus-winkler-1430818?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Markus Winkler </a>拍摄</figcaption></figure><p id="c68a" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated"><strong class="jz hs">机器学习</strong>是教计算机使用过去看到的数据(对新的未知数据)进行预测。机器学习包括基于训练数据建立模型，对其他未知数据进行预测。<br/>机器学习的一些应用:推荐系统(例如，根据一个用户看过和喜欢的电影向他推荐新电影)，股票市场(预测股票的走势)，虚拟个人助理等。</p><p id="4999" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">机器学习通常分为三类:监督学习、非监督学习和强化学习。<br/>本教程将专注于使用<strong class="jz hs">监督学习</strong>训练一个机器学习模型。<br/>在监督学习中，我们对包含输入(特征)和输出(目标)的数据训练计算机，目标是学习将输入映射到输出的函数。<br/>你可以在这里阅读更多关于机器学习方法的信息<a class="ae jw" href="https://en.wikipedia.org/wiki/Machine_learning#Machine_learning_approaches" rel="noopener ugc nofollow" target="_blank">。</a></p><blockquote class="kt ku kv"><p id="c61e" class="jx jy kw jz b ka kb is kc kd ke iv kf kx kh ki kj ky kl km kn kz kp kq kr ks hb bi translated">对于本教程，我们将使用Python的<a class="ae jw" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> sklearn </a>库(sklearn是一个机器学习库，它包含各种机器学习算法的实现)和<a class="ae jw" href="https://www.kaggle.com/c/home-data-for-ml-course" rel="noopener ugc nofollow" target="_blank"> Kaggle的房价预测数据集</a>。</p></blockquote><p id="5e5d" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">考虑到你已经了解了机器学习和监督学习的基础知识，那就从我们的机器学习模型开始吧！</p><p id="b529" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们先在Kaggle上新建一个笔记本。<br/>登录你的Kaggle账号，进入<a class="ae jw" href="https://www.kaggle.com/c/home-data-for-ml-course/notebooks" rel="noopener ugc nofollow" target="_blank">房价竞赛笔记本版块</a>。<br/>点击‘新建笔记本’选项。它会将您重定向到笔记本设置页面。<br/>保留所有默认设置，然后点击“创建”。</p><p id="7fd6" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">你现在应该有一个新的笔记本，如下图所示。<br/>(删除给定的默认代码块)</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es la"><img src="../Images/9b6504a62f1c953b6c8b43704b6157ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UJhAVxBlttPfDwPZYYjnQg.png"/></div></div></figure><blockquote class="kt ku kv"><p id="f30a" class="jx jy kw jz b ka kb is kc kd ke iv kf kx kh ki kj ky kl km kn kz kp kq kr ks hb bi translated">我已经做了一个包含所有相关步骤和代码的笔记本。<br/>你可以在Kaggle上访问<a class="ae jw" href="https://www.kaggle.com/nisargkapkar/basic-ml-model" rel="noopener ugc nofollow" target="_blank">笔记本</a>。</p></blockquote><h2 id="d752" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤1-导入必要的库/函数</strong></h2><p id="4372" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">让我们导入所有我们需要的库和函数。</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="349c" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Import necessary libraries/functions</em></span><span id="7c69" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.preprocessing import OneHotEncoder<br/>from sklearn.ensemble import RandomForestRegressor<br/>from sklearn.metrics import mean_absolute_error</strong></span></pre><p id="3249" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">后续步骤中提供了每个功能的说明和文档链接。</p><h2 id="c991" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤2-加载数据</strong></h2><p id="b2a2" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">右上角应该有一个箭头符号，点击它将打开一个新的面板。该面板显示输入数据的详细信息。</p><p id="d947" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">点击'<strong class="jz hs">ml课程主页数据</strong>，然后点击'<strong class="jz hs"> train.csv </strong>'。点击“train.csv”将打开一个新面板。面板显示路径和存储在' train.csv' <br/>中的数据将'<strong class="jz hs"> train.csv </strong>数据存储在'<strong class="jz hs"> X dataset </strong> ' <br/>中，同样，将'<strong class="jz hs"> test.csv </strong>数据存储在'<strong class="jz hs"> X_test dataset </strong>中</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="1ec4" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Load the data</em></span><span id="8ae2" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#read train.csv and store it in 'X'<br/></em><strong class="mb hs">X=pd.read_csv('../input/home-data-for-ml-course/train.csv',index_col='Id')</strong></span><span id="37c7" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#read test.csv and store it in 'X_test'</em><br/><strong class="mb hs">X_test=pd.read_csv('../input/home-data-for-ml-course/test.csv',index_col='Id')</strong></span></pre><p id="ada7" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">顾名思义，<strong class="jz hs"> read_csv </strong>用于读取逗号分隔值(csv)文件。你可以在这里阅读更多关于功能<a class="ae jw" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html" rel="noopener ugc nofollow" target="_blank">的内容</a>。</p><h2 id="688c" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤3-检查数据</strong></h2><p id="2359" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">在继续下一步之前，让我们检查一下数据。</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="28b0" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Examine the data</em></span><span id="2d90" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">print(X.shape)<br/>print(X.columns)<br/>print(X.head(n=5))</strong></span></pre><ul class=""><li id="5188" class="mk ml hi jz b ka kb kd ke kg mm kk mn ko mo ks mp mq mr ms bi translated"><strong class="jz hs"> X.shape </strong>返回数据帧的尺寸(行数、列数)</li><li id="9c78" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated"><strong class="jz hs"> X.columns </strong>返回数据帧的列标签</li><li id="14ba" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated"><strong class="jz hs"> X.head() </strong>返回DataFrame的前n行</li></ul><p id="fab5" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">同样，您可以检查“X_test”数据集中的数据。</p><p id="5afc" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">下图显示了“X”数据集的前5行(X.head(n=5))</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es my"><img src="../Images/6a7a888491258c56fedea8b643ce4586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5YuitzH0TlNRAK63J2TVzg.png"/></div></div></figure><p id="5eb2" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated"><strong class="jz hs">一些观察:</strong></p><ul class=""><li id="6125" class="mk ml hi jz b ka kb kd ke kg mm kk mn ko mo ks mp mq mr ms bi translated">“X”数据集包含名为“SalePrice”的列，但此列不在“X_test”数据集中。这是因为“销售价格”是我们的目标变量(在步骤4中有更多关于目标变量的内容)，我们将预测“X_test”的“销售价格”值。</li><li id="1619" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated">有两种类型的列，包含数字的列(数字列)和包含非数字值的列(分类列)。</li><li id="f7cb" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated">分类列只接受固定数量的值。</li><li id="3409" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated">有些单元格的值为“NaN”，这些单元格缺少值。(关于步骤6中缺失数据的更多信息)</li></ul><h2 id="ed97" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤4-分离目标变量</strong></h2><p id="6db9" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated"><strong class="jz hs">一些关键定义:</strong></p><ul class=""><li id="1f88" class="mk ml hi jz b ka kb kd ke kg mm kk mn ko mo ks mp mq mr ms bi translated"><strong class="jz hs">特性</strong>:特性基本上就是模型用来做预测的独立列/变量。</li><li id="a0c8" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated"><strong class="jz hs">目标</strong>:目标是通过预测得到的输出。</li></ul><p id="7e61" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">在我们的数据库中，<strong class="jz hs"> SalePrice </strong>是Target，所有其他列是Features。</p><p id="b995" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">通常，真实世界的数据集有很多缺失值。(更多关于步骤6中缺失数据的信息)<br/>对于数据集中的某些行，我们的目标值本身可能会缺失。对于这种情况，我们从数据集中删除缺少目标值的行。</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="2db3" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#drop rows with missing target values from 'X'</em></span><span id="2d2e" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">X.dropna(axis=0,subset=['SalePrice'],inplace=True)</strong></span></pre><p id="2e4d" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated"><strong class="jz hs"> dropna() </strong>是熊猫才有的功能。它用于删除具有NaN(或Null)值的行/列。<br/>你可以在这里阅读更多关于功能及其参数<a class="ae jw" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="2315" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">放下后，我们会将目标与其他特征分开。<br/>我们将把目标存储在'<strong class="jz hs"> y </strong>'中，然后从数据集中删除目标列。</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="4b37" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Store target in 'y' and drop the target column from 'X'</em></span><span id="9652" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">y=X.SalePrice<br/>X.drop(['SalePrice'],axis=1,inplace=True)<br/>print(y)</strong></span></pre><p id="fa52" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated"><strong class="jz hs"> drop() </strong>是熊猫才有的功能。它用于删除行和列。<br/>您可以在这里阅读更多关于函数及其参数<a class="ae jw" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html" rel="noopener ugc nofollow" target="_blank">的信息。</a></p><h2 id="0c0f" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤5-提取分类和数字列</strong></h2><p id="f2be" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">我们看到数据集中存在两种类型的列:数字列和分类列。</p><p id="acfe" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">让我们首先来看看分类列的基数(一列中唯一值的数量)。</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="1968" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#print categorical column labels with cardinality</em></span><span id="d349" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">for i in X.columns:<br/>    if X[i].dtype=="object":<br/>        print(i,X[i].nunique(),sep=' ')</strong></span></pre><p id="ce00" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">上面的代码打印带有相应基数的分类列标签。(<a class="ae jw" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nunique.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz hs"> nunique() </strong> </a>用于计算非重复值)</p><p id="a9d2" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们将把列标签分为3个部分:分类列、删除列、数字列</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="3f48" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Divide columns in 3 parts: categorical_columns, numerical_columns and columns_to_drop</em></span><span id="3f21" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">categorical_columns=[]<br/>numerical_columns=[]<br/>columns_to_drop=[]</strong></span><span id="7da6" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">for i in X.columns:<br/>    if X[i].nunique()&lt;15 and X[i].dtype=="object":<br/>        categorical_columns.append(i)<br/>    elif X[i].nunique()&gt;=15 and X[i].dtype=="object":<br/>        columns_to_drop.append(i)<br/>    elif X[i].dtype in ["int64","float64"]:<br/>        numerical_columns.append(i)<br/>        <br/>print(categorical_columns)<br/>print(columns_to_drop)<br/>print(numerical_columns)</strong></span></pre><ul class=""><li id="6777" class="mk ml hi jz b ka kb kd ke kg mm kk mn ko mo ks mp mq mr ms bi translated"><strong class="jz hs">categorial _ columns</strong>是一个包含所有非数字值且基数小于15的列标签的列表。</li><li id="8106" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated"><strong class="jz hs">numeric _ columns</strong>是包含所有带数值的列标签的列表。</li><li id="fcf9" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated"><strong class="jz hs"> columns_to_drop </strong>是一个列表，包含所有非数字值且基数大于或等于15的列标签。</li></ul><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="e13d" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#drop 'columns_to_drop' from 'X' and 'X_test'</em></span><span id="aab7" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">X=X.drop(columns_to_drop,axis=1)<br/>X_test=X_test.drop(columns_to_drop,axis=1)</strong></span></pre><p id="28ab" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">上述代码将从“X”和“X_test”数据集中删除基数大于或等于15的所有分类列。</p><p id="1a95" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">为什么我们在步骤7中选择基数小于15的分类列并删除其他分类列的解释</p><h2 id="6298" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤6-估算缺失数据</strong></h2><p id="f94d" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">真实世界的数据集可能包含许多缺失值(NaN，Null)。数据丢失的原因有很多。例如，没有“车库”的房子不会有“车库质量”数据(因为房子里没有车库)</p><p id="b738" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">如果我们尝试对包含缺失值的数据训练模型，Scikit-learn (sklearn)将抛出错误。因此，我们需要在训练模型之前估算(填充/替换)缺失值。</p><p id="844f" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">在输入之前，让我们检查有多少单元格包含一个缺失值！</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="57ce" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#optional<br/>#print column labels with number of missing cells in that corresponding column</em></span><span id="e648" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X dataset</em><br/><strong class="mb hs">missing_columns=X.isnull().sum()<br/>print("X dataset")<br/>print(missing_columns[missing_columns&gt;0])</strong></span><span id="255d" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">print()</strong></span><span id="6fe1" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X_test</em><br/><strong class="mb hs">missing_columns_test=X_test.isnull().sum()<br/>print("For X_test set")<br/>print(missing_columns_test[missing_columns_test&gt;0])</strong></span></pre><p id="a021" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">代码打印相应列中缺少单元格的列标签。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mz"><img src="../Images/e1055cb35d02c4eb67884372de882526.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*mXY0V0jeGXtFxIhQYtY0AA.png"/></div></figure><p id="a2cc" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们将首先估算数字列</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="18b8" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#impute numerical_columns</em><br/><strong class="mb hs">numerical_imputer=SimpleImputer()</strong></span><span id="bf65" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X</em><br/><strong class="mb hs">for i in numerical_columns:<br/>    current_column=np.array(X[i]).reshape(-1,1)<br/>    updated_column=numerical_imputer.fit_transform(current_column)<br/>    X[i]=updated_column</strong></span><span id="749e" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X_test</em><br/><strong class="mb hs">for i in numerical_columns:<br/>    current_column=np.array(X_test[i]).reshape(-1,1)<br/>    updated_column=numerical_imputer.fit_transform(current_column)<br/>    X_test[i]=updated_column</strong></span></pre><p id="d589" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">对于输入，我们使用了sklearn中提供的内置输入器(<strong class="jz hs">simple import()</strong>)</p><p id="88c1" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">这个估算器将用某一列值的<strong class="jz hs">平均值</strong>替换该列中所有缺失的值。<br/>更多关于简单估算器<a class="ae jw" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank">的细节在这里</a>。</p><p id="2f40" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们迭代所有数值列(对于‘X’和‘X _ test’数据集),并将它们存储在np.array (current_column) <br/>我们的输入方法(numerical _ imputer.fit _ transform)需要一个2D数组，因此我们使用shape(-1，1)将我们的1D数组转换为2D数组。<br/>我们将最后一列(带有估算值)存储在‘updated _ column’中，最后，我们用获得的‘updated _ column’替换数据集中的相应列</p><p id="2768" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">类似地，我们将估算分类列</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="0007" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#impute categorical_columns</em><br/><strong class="mb hs">categorical_imputer=SimpleImputer(strategy="most_frequent")</strong></span><span id="8cba" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X</em><br/><strong class="mb hs">for i in categorical_columns:<br/>    current_column=np.array(X[i]).reshape(-1,1)<br/>    updated_column=categorical_imputer.fit_transform(current_column)<br/>    X[i]=updated_column</strong></span><span id="91ee" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X_test</em><br/><strong class="mb hs">for i in categorical_columns:<br/>    current_column=np.array(X_test[i]).reshape(-1,1)<br/>    updated_column=categorical_imputer.fit_transform(current_column)<br/>    X_test[i]=updated_column</strong></span></pre><p id="ca35" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">这里，我们用特定列的<strong class="jz hs">最频繁的</strong>值替换该列中缺失的值。</p><p id="761f" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">现在，让我们重新检查丢失细胞的数量！</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="fcd4" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#optional<br/>#print column labels with number of missing cells in that corresponding column</em></span><span id="4001" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X dataset</em><br/><strong class="mb hs">missing_columns=X.isnull().sum()<br/>print("X dataset")<br/>print(missing_columns[missing_columns&gt;0])</strong></span><span id="031d" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">print()</strong></span><span id="0303" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X_test</em><br/><strong class="mb hs">missing_columns_test=X_test.isnull().sum()<br/>print("For X_test set")<br/>print(missing_columns_test[missing_columns_test&gt;0])</strong></span><span id="3461" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#after imputation, there would be no columns with missing data</em></span></pre><p id="2f97" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">您应该会看到类似下图所示的输出。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es na"><img src="../Images/c3ff5636091acc44565babc35eac9367.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*miiGJTn8pUHtDtF2ZoWPbw.png"/></div></div></figure><h2 id="e69a" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤7-对分类列进行编码</strong></h2><p id="68e5" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">分类列采用固定数量的值。例如，列“宠物”将包含一些固定数量的值，例如猫、狗、鸟等。</p><p id="b337" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">在机器学习模型中使用这些类型的列之前，我们需要对它们进行预处理(编码),否则将会抛出错误。</p><p id="d9d3" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们将使用sklearn中提供的内置<strong class="jz hs"> OneHotEncoder </strong>。</p><p id="2432" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">OneHotEncoder为要编码的列中的每个唯一值创建一个新的布尔列。</p><p id="9ab0" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">考虑一个名为“pets”的列，它包含5个唯一值[“Cat”、“Dog”、“Bird”、“Fish”、“Rabbit”]。<br/>应用OneHotEncoding后，我们将得到5个新列</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es nb"><img src="../Images/36c60a430ce3f1d72f0a0ec2f1dc9f95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*teBKBdGb4-WeAKxNSQjEDw.png"/></div></div></figure><p id="2c5a" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">一键编码的一个缺点是它会增加数据集的大小。<br/>对于上述示例，我们有35–7 = 28个新单元(35个新布尔单元—我们将删除7个原始单元)<br/>现在考虑一个1000行的数据集，其中有50个分类列，每个分类列的基数是30。<br/>所以，我们每个分类列，我们将有1000 * 30–1000 = 29000个新单元格。<br/>对于所有50个分类列，29000*50个新单元格</p><p id="19bc" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">这就是我们在步骤5中删除基数大于/等于的分类列的原因</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="4161" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Encode categorical columns</em></span><span id="9298" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#STEPS:<br/>#get one-hot encoded columns for X and X_test (using fit_transform/transform)<br/>#give names to one-hot encoded columns (using get_feature_names)<br/>#drop categorical columns from X and X_test (using drop)<br/>#oh encoding removes index, add back index (using .index)<br/>#add one-hot encoded columns to X and X_test (using pd.concat)</em></span><span id="b4c4" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">ohencoder=OneHotEncoder(handle_unknown='ignore',sparse=False)</strong></span><span id="af8c" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X</em><br/><strong class="mb hs">ohe_X=pd.DataFrame(ohencoder.fit_transform(X[categorical_columns]))<br/>ohe_X.columns=ohencoder.get_feature_names(categorical_columns)<br/>X.drop(categorical_columns,axis=1,inplace=True)<br/>ohe_X.index=X.index<br/>X=pd.concat([X,ohe_X],axis=1)</strong></span><span id="6fe7" class="lb lc hi mb b fi mj mg l mh mi"><em class="kw">#for X_test</em><br/><strong class="mb hs">ohe_X_test=pd.DataFrame(ohencoder.transform(X_test[categorical_columns]))<br/>ohe_X_test.columns=ohencoder.get_feature_names(categorical_columns)<br/>X_test.drop(categorical_columns,axis=1,inplace=True)<br/>ohe_X_test.index=X_test.index<br/>X_test=pd.concat([X_test,ohe_X_test],axis=1)</strong></span></pre><p id="a10a" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">OneHotEncoder是sklearn中的内置函数。</p><p id="fbd4" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">有时，该验证集可能包含一些定型数据中不存在的分类特征，默认情况下，当遇到此类特征时，OneHotEncoder将引发错误。<br/>为了避免错误，我们将<strong class="jz hs"> handle_unknown </strong>参数设置为‘忽略’。现在，如果遇到未知特性，该特性的独热编码列将全为零。</p><p id="fa48" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">更多关于OneHotEncoder <a class="ae jw" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" rel="noopener ugc nofollow" target="_blank">的细节请点击</a>。</p><p id="2629" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">“oh_X”和“oh_X_test”分别包含“X”和“X_test”数据集的一键编码列。</p><p id="fafe" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">默认情况下，one-hot编码列的名称为1、2、3…为了获得基于特征值的列名，我们使用了<strong class="jz hs"> get_feature_names </strong>函数。<br/> OneHot编码删除了索引，所以我们添加回索引。</p><p id="516f" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">接下来，我们从X和X_test数据集中删除分类列。<br/>然后，我们连接(使用Pandas内置的<a class="ae jw" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jz hs"> Concat函数</strong> </a>)数据集“X”和“X_test”以及它们的独热编码列。(' oh_X '和' oh_X_test ')</p><p id="051e" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated"><strong class="jz hs">注意:<br/> </strong>我们对‘oh _ X’使用了<strong class="jz hs"> fit_transform </strong>，对‘oh _ X _ test’使用了<strong class="jz hs"> transform </strong>。你可以在这里阅读fit_transform和transform <a class="ae jw" href="https://stackoverflow.com/questions/23838056/what-is-the-difference-between-transform-and-fit-transform-in-sklearn" rel="noopener ugc nofollow" target="_blank">的区别。</a></p><h2 id="296c" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤8-将数据集分成训练集和验证集</strong></h2><p id="8a52" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">三种类型的数据集通常用于模型训练的不同阶段:训练集、验证集和测试集。</p><p id="5383" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">你可以在这里阅读更多关于这些类型的数据集<a class="ae jw" href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="08be" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们已经有了我们的测试集(X_test)。</p><p id="d0c7" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们将把“X”数据集分成两部分:训练集和验证集。</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="9b7d" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Split Dataset in train and validation set</em></span><span id="725a" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">X_train,X_valid,y_train,y_valid=train_test_split(X,y,train_size=0.8,test_size=0.2)</strong></span></pre><p id="848a" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">(<strong class="jz hs"> X_train </strong>，<strong class="jz hs"> y_train </strong>)分别是<strong class="jz hs">训练</strong>设定的特性和目标。(<strong class="jz hs"> X_valid </strong>，<strong class="jz hs"> y_valid </strong>)分别是<strong class="jz hs">验证</strong>设定的特性和目标。</p><p id="3f3e" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们将数据集的0.8%用于训练集，剩余的0.2%用于验证集。</p><p id="2cf0" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">关于<strong class="jz hs"> train_test_split </strong>功能<a class="ae jw" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank">的更多细节请点击</a>。</p><h2 id="9a9e" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤9-定义模型</strong></h2><p id="441c" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">我们将使用随机森林作为我们的机器学习模型。</p><p id="ea13" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">随机森林构建多个<strong class="jz hs">决策树</strong>并合并它们的输出以提供更准确的预测。</p><p id="91d7" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我建议在继续下一步之前，阅读并理解<a class="ae jw" href="https://www.javatpoint.com/machine-learning-decision-tree-classification-algorithm" rel="noopener ugc nofollow" target="_blank">决策树</a>和<a class="ae jw" href="https://en.wikipedia.org/wiki/Random_forest" rel="noopener ugc nofollow" target="_blank">随机森林</a>。</p><p id="0483" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们将使用sklearn中内置的<a class="ae jw" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html" rel="noopener ugc nofollow" target="_blank"><strong class="jz hs">RandomForestRegressor</strong></a>函数。</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="b612" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Define the model</em></span><span id="e6b8" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">model=RandomForestRegressor()</strong></span></pre><h2 id="89e6" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤10-拟合模型</strong></h2><p id="d08a" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">拟合模型基本上意味着根据训练数据训练模型。</p><p id="d54a" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们将使用<strong class="jz hs">。拟合sklearn中提供的</strong>方法，以根据训练数据拟合我们的模型。</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="e32f" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Fit the model</em></span><span id="6b46" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">model.fit(X_train,y_train)</strong></span></pre><h2 id="0496" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤11-预测并评估验证集</strong></h2><p id="4c85" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">让我们在验证集上测试我们的训练模型。</p><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="a5e6" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Predict and Evaluate on validation set</em></span><span id="04f6" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">preds_valid=model.predict(X_valid)<br/>score_valid=mean_absolute_error(y_valid,preds_valid)<br/>print("MAE: ",score_valid)</strong></span></pre><p id="4e65" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated"><strong class="jz hs">。predict() </strong>方法(在sklearn中可用)将对验证数据进行预测。这些预测存储在'<strong class="jz hs"> preds_valid </strong>'中。</p><p id="aa5c" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们已经用<strong class="jz hs"/><a class="ae jw" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html" rel="noopener ugc nofollow" target="_blank"><strong class="jz hs">mean _ absolute _ error</strong></a>(来自sklearn)估算了我们的预测值(preds_valid)与实际值(y_valid)有多远。</p><p id="9be3" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们将误差定义为实际值和预测值之间的差异。(误差=实际值-预测值)</p><p id="fdee" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">MAE (mean_absolute_error)取每行的误差绝对值，然后取这些绝对误差的平均值。</p><p id="8d70" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">在上面的代码中，'<strong class="jz hs"> score_valid </strong>'存储了我们的MAE分数。</p><h2 id="ac6c" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">步骤12-生成测试预测</strong></h2><pre class="jh ji jj jk fd ma mb mc md aw me bi"><span id="bc42" class="lb lc hi mb b fi mf mg l mh mi"><em class="kw">#Generate Test Prediction</em></span><span id="4b61" class="lb lc hi mb b fi mj mg l mh mi"><strong class="mb hs">preds_test=model.predict(X_test)<br/>submission=pd.DataFrame({'Id':X_test.index,'SalePrice':preds_test})<br/>submission.to_csv('submission.csv',index=False)</strong></span></pre><p id="9666" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们对测试集(X_test)的预测存储在'<strong class="jz hs"> preds_test' </strong>。</p><p id="a2dc" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">然后我们制作一个DataFrame(带有Id和SalePrice(我们预测的销售价格)列)并将其转换为. csv。csv将用于Kaggle竞赛评估。</p><p id="d8db" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated"><strong class="jz hs">提交您在Kaggle竞赛中的预测:</strong></p><ul class=""><li id="b9b4" class="mk ml hi jz b ka kb kd ke kg mm kk mn ko mo ks mp mq mr ms bi translated">点击保存版本(蓝色按钮，右上角)并选择“保存并运行全部”选项，然后点击保存。</li><li id="22db" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated">保存后，点击保存按钮旁边的数字。</li><li id="5032" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated">一个新的窗口将会打开，您应该在右侧看到版本历史面板。单击版本1旁边的省略号(…)按钮。</li><li id="a9b7" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated">点击“提交竞争”选项。</li></ul><p id="1dec" class="pw-post-body-paragraph jx jy hi jz b ka kb is kc kd ke iv kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">您可以查看您的提交，并查看您的分数(测试集的MAE)和在排行榜上的位置。</p><h2 id="1777" class="lb lc hi bd ld le lf lg lh li lj lk ll kg lm ln lo kk lp lq lr ko ls lt lu ho bi translated"><strong class="ak">奖金部分</strong></h2><p id="ea1c" class="pw-post-body-paragraph jx jy hi jz b ka lv is kc kd lw iv kf kg lx ki kj kk ly km kn ko lz kq kr ks hb bi translated">恭喜你训练了你的第一个机器学习模型！<br/>想要降低你的MAE并提高你在排行榜上的排名吗？这里有几样东西你可以试试！</p><ul class=""><li id="9368" class="mk ml hi jz b ka kb kd ke kg mm kk mn ko mo ks mp mq mr ms bi translated">使用不同型号进行测试(如<a class="ae jw" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>、<a class="ae jw" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> LightGBM </a>等。)并查看哪个模型提供了更好的准确性。</li><li id="8939" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated"><a class="ae jw" href="https://en.wikipedia.org/wiki/Feature_engineering#:~:text=Feature%20engineering%20is%20the%20process,as%20applied%20machine%20learning%20itself." rel="noopener ugc nofollow" target="_blank">特征工程</a>(从现有数据中提取附加特征)和<a class="ae jw" href="https://en.wikipedia.org/wiki/Feature_selection" rel="noopener ugc nofollow" target="_blank">特征选择</a>(选择用于模型训练的最佳特征子集)</li><li id="e7e3" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated">尝试对缺失数据使用各种插补方法。SimpleImputer可以用均值、中值、众数和常数来估算缺失数据。你也可以尝试使用<a class="ae jw" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html" rel="noopener ugc nofollow" target="_blank"> KNNImputer </a>输入。</li><li id="6abf" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated"><a class="ae jw" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization" rel="noopener ugc nofollow" target="_blank">超参数调整</a>(参考各型号的文档，了解更多关于其超参数的信息)。Sklearn learn有一个内置函数(<a class="ae jw" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank"> GridSearchCV </a>)，您可以使用它来搜索最佳超参数。(您也可以使用一个简单的循环来搜索最佳超参数)</li><li id="68a6" class="mk ml hi jz b ka mt kd mu kg mv kk mw ko mx ks mp mq mr ms bi translated"><a class="ae jw" href="https://en.wikipedia.org/wiki/Ensemble_learning" rel="noopener ugc nofollow" target="_blank">集成学习</a>(集成是一种结合多种机器学习算法以获得更好预测的技术)。你可以在这里阅读更多关于sklearn集成方法的内置模块<a class="ae jw" href="https://scikit-learn.org/stable/modules/ensemble.html" rel="noopener ugc nofollow" target="_blank">。</a></li></ul></div></div>    
</body>
</html>