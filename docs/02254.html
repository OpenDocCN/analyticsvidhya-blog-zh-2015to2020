<html>
<head>
<title>Load MySQL Database into BigQuery using Pandas</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Pandas将MySQL数据库加载到BigQuery中</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/load-mysql-databases-to-bigquery-using-pandas-d77d3ad76a0e?source=collection_archive---------3-----------------------#2019-12-08">https://medium.com/analytics-vidhya/load-mysql-databases-to-bigquery-using-pandas-d77d3ad76a0e?source=collection_archive---------3-----------------------#2019-12-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="38d0" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">简单的方法，避免模式错误、数据类型问题和长期头痛</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/db2c7bacaf3323d608b6ed4d75dfe1f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*85TST6Fym6gFysORDv7u6g.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">熊猫在吃东西(鸣谢:<a class="ae jn" href="https://unsplash.com/@mana5280" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@mana5280</a></figcaption></figure></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><h1 id="d547" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">问题是</h1><p id="ba07" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">您可能尝试过将MySQL或PostgreSQL之类的关系数据库加载到BigQuery之类的列式数据库系统中，即使这是一种标准且被广泛采用的格式，过程也并不明显。</p><p id="d39f" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">如果您遇到类似以下的错误:</p><blockquote class="lo lp lq"><p id="49c6" class="kn ko lr kp b kq lj ij ks kt lk im kv ls ll ky kz lt lm lc ld lu ln lg lh li hb bi translated">读取数据时出错，错误消息:CSV表遇到太多错误，放弃。行数:x；错误:1。有关更多详细信息，请查看errors[]集合。</p></blockquote><p id="5eb1" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">或者</p><blockquote class="lo lp lq"><p id="b25c" class="kn ko lr kp b kq lj ij ks kt lk im kv ls ll ky kz lt lm lc ld lu ln lg lh li hb bi translated">CSV表引用了x列位置，但从位置:0开始的行只包含x列。(错误代码:无效)</p></blockquote><p id="29ae" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">或者再一次…</p><blockquote class="lo lp lq"><p id="6367" class="kn ko lr kp b kq lj ij ks kt lk im kv ls ll ky kz lt lm lc ld lu ln lg lh li hb bi translated">分析从位置x开始的行时检测到错误。错误:右双引号(")和字段分隔符之间的数据。</p></blockquote><p id="919e" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">你绝对是来对地方了！😎</p><p id="c125" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">有些解决方案是存在的，你可以在Stackoverflow或互联网上找到它们。他们中的大多数建议您使用封闭方法在CSV中进行特定的导出，或者在换行符分隔的JSON中转换所有内容。</p><p id="fd8a" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">Google还提供了将MySql加载到BigQuery的文档，但是这个过程需要为每个表提供一个模式，并使用数据流来执行管道。另一个解决方案是使用Cloud Dataprep，它可以在接收数据之前帮助转换和清理数据。</p><p id="772f" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">这些方法效果很好，但有以下限制:</p><ul class=""><li id="5573" class="lv lw hi kp b kq lj kt lk kw lx la ly le lz li ma mb mc md bi translated">当您有数百个表时，为每个表提供一个模式可能会成为一个耗时的编写和更新过程。此外，如果关系数据库模式发生变化，动态管理会更加困难。</li><li id="2baa" class="lv lw hi kp b kq me kt mf kw mg la mh le mi li ma mb mc md bi translated">使用纯SQL命令导出CSV格式的数据需要开发一个bash脚本，并且获取表头通常会变得很复杂。</li><li id="9207" class="lv lw hi kp b kq me kt mf kw mg la mh le mi li ma mb mc md bi translated">将CSV表转换为NDJSON可以修复字段分隔符，但不能修复数据类型错误。</li><li id="5f9c" class="lv lw hi kp b kq me kt mf kw mg la mh le mi li ma mb mc md bi translated">使用数据流意味着设置许多步骤，使用谷歌存储，提供模式，然后映射/连接和转换每个字段。这个过程更加精确，但是也非常耗时，并且需要Apache Beam Python SDK方面的知识。</li></ul><p id="b9fb" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">以下是已知的现有解决方案列表，请随意尝试并使用最适合的解决方案:</p><ul class=""><li id="14d5" class="lv lw hi kp b kq lj kt lk kw lx la ly le lz li ma mb mc md bi translated"><a class="ae jn" href="https://cloud.google.com/solutions/performing-etl-from-relational-database-into-bigquery" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/solutions/performing-ETL-from-relational-database-into-big query</a></li><li id="431c" class="lv lw hi kp b kq me kt mf kw mg la mh le mi li ma mb mc md bi translated"><a class="ae jn" href="https://stackoverflow.com/questions/41774233/best-practice-to-migrate-data-from-mysql-to-bigquery" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/41774233/best-practice-to-migrate-data-from-MySQL-to-big query</a></li><li id="bac6" class="lv lw hi kp b kq me kt mf kw mg la mh le mi li ma mb mc md bi translated"><a class="ae jn" rel="noopener" href="/google-cloud/loading-mysql-backup-files-into-bigquery-straight-from-cloud-sql-d40a98281229">https://medium . com/Google-cloud/loading-MySQL-backup-files-into-big query-straight-from-cloud-SQL-d40a 98281229</a></li></ul><h1 id="3e99" class="jv jw hi bd jx jy mj ka kb kc mk ke kf io ml ip kh ir mm is kj iu mn iv kl km bi translated">解决方案</h1><p id="eebb" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">使用<em class="lr"> Pandas </em>(一个用于数据分析的开源python库)可以很容易地解决这个问题，而且最棒的是，它甚至不强制提供模式，你也不需要使用谷歌存储。用几行代码编写脚本、运行和部署也很容易。</p><p id="8f68" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">更重要的是，这种技术允许您加载到BigQuery，或者使用头文件、特定分隔符、编码等创建CSV转储文件！</p><p id="1bb7" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">下面的脚本中列出了这两种方法！😇</p><p id="023e" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">假设您已经:</p><ul class=""><li id="cb2e" class="lv lw hi kp b kq lj kt lk kw lx la ly le lz li ma mb mc md bi translated">在BigQuery中配置的项目和数据集(您需要您的项目ID和数据集ID)</li><li id="7127" class="lv lw hi kp b kq me kt mf kw mg la mh le mi li ma mb mc md bi translated">直接连接到您的MySql数据库</li><li id="3a50" class="lv lw hi kp b kq me kt mf kw mg la mh le mi li ma mb mc md bi translated">你的。用于访问GCP的json服务帐户文件</li></ul><p id="c826" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">以下是gist的完整代码，我们将一步一步解释:</p><p id="ebeb" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated"><a class="ae jn" href="https://gist.github.com/romain9292/89ba7cbef0715d07c8198a5ff1347805" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/Romain 9292/89 ba 7 cbef 0715d 07 c 8198 a5ff 1347805</a></p><h1 id="28ca" class="jv jw hi bd jx jy mj ka kb kc mk ke kf io ml ip kh ir mm is kj iu mn iv kl km bi translated">步骤1:声明变量</h1><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="4546" class="mt jw hi mp b fi mu mv l mw mx"># Service account file for GCP connection<br/>credentials = service_account.Credentials.from_service_account_file('key.json')</span><span id="c597" class="mt jw hi mp b fi my mv l mw mx">#  BigQuery Variables<br/>PROJECT_ID = 'your_project_ID'<br/>DATASET_ID = 'your_data_set_ID'</span><span id="9160" class="mt jw hi mp b fi my mv l mw mx">#  MySql Variables<br/>MYSQL_USERNAME = 'root'<br/>MYSQL_PASSWORD = 'root'<br/>MYSQL_HOST = '127.0.0.1'<br/>MYSQL_DATABASE = 'your_table'</span><span id="9b8a" class="mt jw hi mp b fi my mv l mw mx"># Path for the dump directory<br/>DIRECTORY = 'dump'</span></pre><p id="3a08" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">确保您的<em class="lr"> service-account.json </em>文件在您的python项目目录中。</p><p id="e9f8" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">然后，您可以提供您的BigQuery和MySql连接细节。最后但并非最不重要的一点是，需要一个特定的目录来将所有表写成CSV文件。</p><h1 id="6f77" class="jv jw hi bd jx jy mj ka kb kc mk ke kf io ml ip kh ir mm is kj iu mn iv kl km bi translated">步骤2:列出数据库中的所有表</h1><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="6ca7" class="mt jw hi mp b fi mu mv l mw mx">tables_query = 'SELECT table_name ' \<br/>               'FROM information_schema.tables ' \<br/>               'WHERE TABLE_TYPE = "BASE TABLE" ' \<br/>               'AND TABLE_SCHEMA = "{}";'.format(MYSQL_DATABASE)</span></pre><p id="8fe9" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">使用SQL查询，我们可以从数据库中选择所有表的名称。</p><h1 id="aea3" class="jv jw hi bd jx jy mj ka kb kc mk ke kf io ml ip kh ir mm is kj iu mn iv kl km bi translated">步骤3:上传到BigQuery</h1><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="d54c" class="mt jw hi mp b fi mu mv l mw mx">for index, row in list_tables.iterrows():</span><span id="fe67" class="mt jw hi mp b fi my mv l mw mx">    table_id = '{}.{}'.format(DATASET_ID, row['TABLE_NAME'])</span><span id="287a" class="mt jw hi mp b fi my mv l mw mx">    print 'Loading Table {}'.format(table_id)<br/>    df = pd_mod.read_sql_table(row['TABLE_NAME'], engine)<br/>    <br/>    pd_gbq.to_gbq(df, table_id,<br/>                  project_id=PROJECT_ID,<br/>                  if_exists='replace',<br/>                  chunksize=10000000,<br/>                  progress_bar=True)</span></pre><p id="6200" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">这是脚本中最有趣的部分(您可以在几行代码中看到它)。首先，我们迭代我们的数据框架以获得存储在<em class="lr">行['TABLE_NAME'] </em>中的每个表的名称，然后我们使用<em class="lr"> pd_mod.read_sql_table </em>函数，它的作用类似于<em class="lr">SELECT * FROM TABLE _ NAME；</em>获取完整的表格数据。</p><p id="adfa" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">我们使用<em class="lr">熊猫摩丁</em>来加速这部分过程。这个库允许我们透明地分发数据并并行运行计算。</p><p id="e3be" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">此时，SQL表存储在名为<em class="lr"> df </em>的数据框中，该数据框将使用pandas-gbq模块加载到BigQuery，该模块是Google big query的包装器，简化了检索/推送数据的过程。您还可以微调区块大小参数，以加快进程并优化IO成本。</p><h1 id="88b8" class="jv jw hi bd jx jy mj ka kb kc mk ke kf io ml ip kh ir mm is kj iu mn iv kl km bi translated">步骤#4:转储到CSV</h1><pre class="iy iz ja jb fd mo mp mq mr aw ms bi"><span id="79f9" class="mt jw hi mp b fi mu mv l mw mx">for index, row in list_tables.iterrows():</span><span id="5fee" class="mt jw hi mp b fi my mv l mw mx">    table_id = '{}.{}'.format(DATASET_ID, row['TABLE_NAME'])</span><span id="6752" class="mt jw hi mp b fi my mv l mw mx">    print 'Loading Table {}'.format(table_id)<br/>    df = pd_mod.read_sql_table(row['TABLE_NAME'], engine)</span><span id="6f6a" class="mt jw hi mp b fi my mv l mw mx">    pd_gbq.to_gbq(df, table_id,<br/>                  project_id=PROJECT_ID,<br/>                  if_exists='replace',<br/>                  chunksize=10000000,<br/>                  progress_bar=True)</span><span id="77fe" class="mt jw hi mp b fi my mv l mw mx">    print 'Exporter les  tables en csv'<br/>    if not os.path.exists(DIRECTORY):<br/>        os.makedirs(DIRECTORY)</span><span id="74dc" class="mt jw hi mp b fi my mv l mw mx">    df.to_csv('{}/{}.csv'.format(DIRECTORY, row['TABLE_NAME']),<br/>              index=None,<br/>              header=True)</span></pre><p id="7d06" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">正如你所看到的，这是与第3步相同的代码，但是我们添加并使用了这个<em class="lr"> to_csv </em>方法，它将把本地存储中的每个表写入csv文件。由于这种方法，您可以利用<em class="lr"> Pandas </em>库的所有功能和提供的所有特性，如编码、压缩、块大小、索引、缺失数据等…</p><h1 id="19eb" class="jv jw hi bd jx jy mj ka kb kc mk ke kf io ml ip kh ir mm is kj iu mn iv kl km bi translated">现在，快乐的SQL！</h1><p id="e625" class="pw-post-body-paragraph kn ko hi kp b kq kr ij ks kt ku im kv kw kx ky kz la lb lc ld le lf lg lh li hb bi translated">这种简单的方法可以集成到完全生产就绪的数据接收管道中。</p><p id="dd9e" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">我希望这种方法可以帮助您节省一些时间，并修补您与BigQuery中的关系数据库之间的问题！</p><p id="678b" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">我还要感谢我非常欣赏的同事和朋友Adrien，他在这个问题上与我一起工作。</p><p id="01f5" class="pw-post-body-paragraph kn ko hi kp b kq lj ij ks kt lk im kv kw ll ky kz la lm lc ld le ln lg lh li hb bi translated">是时候深入研究一些数据了！🤓</p></div></div>    
</body>
</html>