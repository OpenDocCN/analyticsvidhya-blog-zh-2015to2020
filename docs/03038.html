<html>
<head>
<title>All you need to know in Natural Language Processing!(Part-1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理你需要知道的！(第一部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/all-you-need-to-know-is-natural-language-processing-part-1-18ef6b1d3ba4?source=collection_archive---------15-----------------------#2020-01-13">https://medium.com/analytics-vidhya/all-you-need-to-know-is-natural-language-processing-part-1-18ef6b1d3ba4?source=collection_archive---------15-----------------------#2020-01-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/1c7970c2f65555b62620fbe837a337ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*Kwh-3D-76b3LvLF9wFHX5g.jpeg"/></div></figure><p id="9536" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">本系列涵盖了NLP中的所有内容，我将尝试涵盖NLP中的每个主题、每个问题，比如，<strong class="io hj">我们为什么需要NLP？NLP中的所有预处理步骤，词干化，词条化，词袋，Tf_Idf，词到向量，平均词到向量，Tf_Idf词到向量最后可能是BERT。</strong></p><p id="46b3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">伯特没有承诺，但除了这一系列文章将彻底涵盖一切。</p><h2 id="13e5" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">让我们从最基本的问题开始，为什么我们需要NLP？</h2><figure class="kg kh ki kj fd ij er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es kf"><img src="../Images/925a377ad51a02261e79bb42b63054bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LGnhQtUUpTdAkkxp_UJG2Q.jpeg"/></div></div></figure><p id="0cf1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">典型的NLP任务是机器翻译(语言翻译)、文章写作、检查语法、文本分类。</p><p id="11a9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我给你一个非常基本的真实世界的例子来澄清NLP背后的概念，假设你是AMAZON.COM的一名数据科学家，你的任务是建立一个模型，对正面评论和负面评论进行分类。</p><p id="d7df" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以基本上如果一个人写了一篇新的评论，我们的模型将能够分类它是积极的还是消极的。</p><p id="dd27" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这是一个文本分类的例子。</p><p id="2c19" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，作为一名数据科学家，你的工作是建立一个模型，而为了建立一个模型，你需要数据，所以假设你从亚马逊数据仓库获得数据，我们将学习在建立文本分类器时你可以使用的所有技术，我们将试图理解为什么特定的技术在特定的情况下是有用的。</p><h2 id="89ae" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">在这个NLP系列中，我的整个目标是给你关于NLP，关于数据科学家面临的实际现实世界问题，关于我们在NLP中使用的所有技术的最佳说明，所以不要担心编码部分，相信我，一旦你得到了整个想法，编写代码将非常容易，非常非常容易。</h2><p id="e9ab" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">在这个系列的最后，我会告诉你为什么我不关心编码部分。</p><p id="f2c0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，要建立任何机器学习模型，有几个步骤，</p><ol class=""><li id="40ec" class="kt ku hi io b ip iq it iu ix kv jb kw jf kx jj ky kz la lb bi translated"><strong class="io hj">数据收集</strong>(我们假设从亚马逊数据仓库获取)。</li><li id="489a" class="kt ku hi io b ip lc it ld ix le jb lf jf lg jj ky kz la lb bi translated"><strong class="io hj">数据预处理</strong></li></ol><figure class="kg kh ki kj fd ij er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lh"><img src="../Images/43ccc6b83f3b19da8d109f098ff8d99c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JCOv_L-7XDLhAwEuqRoEvA.png"/></div></div></figure><p id="a21d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当我们处理“文本”时，这涉及到一些非常有趣的想法，</p><p id="cb77" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> A .标记化</strong> -这个预处理步骤背后的想法非常简单，假设我们有一个句子，<strong class="io hj">“卡卓尔是一个非常漂亮的女孩”，</strong></p><p id="4ce0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">那么什么叫标记化呢，就是把一个句子里的每一个单词都拆分，比如<strong class="io hj">【“卡卓尔”、“是”、“一个”、“非常”、“漂亮”、“姑娘”】</strong></p><p id="57c9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> B .标准化</strong> -假设在写评论时，一个人写5秒为“5秒”，另一个人写5秒为“5 s”，我们知道两者是同一件事，因此为了简化模型，我们只标准化一件事，假设5秒&lt; s &gt;。</p><p id="c60b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> C .替换</strong> -有时我们需要替换一些单词，这个预处理步骤取决于我们正在处理的数据类型。</p><p id="58c1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> D. Case Folding(小写)</strong> -为了使模型简单，我们通常将评论或文本折叠成小写。</p><p id="b6a9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">词汇化和词干化是非常重要的步骤，我知道很多人会混淆这两个术语，尽管它们非常简单。</p><p id="cb9e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">词干化和词汇化</strong>都生成词根变化的单词。不同之处在于<strong class="io hj">词干</strong>可能不是一个真实的单词，而lemma是一个真实的语言单词。<strong class="io hj">词干提取</strong>遵循一种算法，通过对单词执行步骤来加快速度。</p><h2 id="4b1f" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">词干的例子是，学习变成学习，学习变成学习</h2><h2 id="18ea" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">词汇化的例子是，学习变成学习，学习变成学习</h2><p id="e58c" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">删除拼写错误的单词，我认为这是不言自明的。</p><p id="b4bc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> I .停用词移除</strong> -有些词对评论的意义没有任何价值，如“是”、“和”、“到”等。所以我们从文档中删除了这些单词。</p><p id="479d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这是一些预处理技术。</p><p id="7f16" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在到了重要的部分，我们需要将“文本”转换成“向量”，我们有一些漂亮的技术，比如:-</p><ol class=""><li id="5287" class="kt ku hi io b ip iq it iu ix kv jb kw jf kx jj ky kz la lb bi translated">TF_IDF</li><li id="970c" class="kt ku hi io b ip lc it ld ix le jb lf jf lg jj ky kz la lb bi translated">一袋单词</li><li id="d8fd" class="kt ku hi io b ip lc it ld ix le jb lf jf lg jj ky kz la lb bi translated">词到向量</li><li id="bd22" class="kt ku hi io b ip lc it ld ix le jb lf jf lg jj ky kz la lb bi translated">平均词向量比</li><li id="0528" class="kt ku hi io b ip lc it ld ix le jb lf jf lg jj ky kz la lb bi translated">TF_IDF字到向量</li></ol><p id="8f04" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将涵盖每一种技术，并了解为什么一种技术不足以将“文本”转换为“矢量”。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h2 id="d593" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">单词袋(蝴蝶结)</h2><figure class="kg kh ki kj fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/06a9c896ab42ef58325ee0cecd3d1d1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*LuvJ9PLW5kmbnqU0u6ZhXQ.jpeg"/></div></figure><p id="e8c2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">[tf1，tf2，tf3…的集合。tfn]被称为单词包，其中tf是术语频率或者是包中特定单词的计数，例如，如果“优秀”在文档中出现20次，则其tf(术语频率)通常将是20。</p><p id="2cf4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">不总是20，当它不是20的时候我们会看到。</p><p id="1316" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">举个例子，我们有两个评论</p><p id="c3a8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">点评1-这种意大利面非常好吃，而且价格实惠。</strong></p><p id="f0ef" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">点评2-这种面食不好吃，也买不起。</strong></p><p id="cec6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们来看看BOW是如何工作的</p><p id="651d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">第一步-制作一本字典，从所有的评论中收集所有独特的单词</p><p id="e9b7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">例- {'this':2，' pasta':2，..</p><p id="29c6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">。以此类推}“2”在这里表示在所有评论中“这个”出现了多少次</p><p id="b863" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">假设我们有d个独特的单词。</p><p id="7f58" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">步骤2-创建向量/构建一个长度为“d”的向量，比如复习1和复习2</p><figure class="kg kh ki kj fd ij er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lq"><img src="../Images/fa5ecda21a518e1aa8fb7e35ca3c0c00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMy37JULLM3L0zA7MquaXQ.jpeg"/></div></div></figure><p id="69f9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">每个数字是它在回顾1中出现的频率，所以“this”出现一次，这就是为什么“1”，</p><p id="18b3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果一个单词会出现两次，那就是“2”。</p><p id="821e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我提醒你，“每个字都是不同的维度”。因此，对于4篇评论，我们将有4个向量，这意味着对于“d”文档，有“d”个向量。</p><h2 id="dbed" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">现在，我们希望相似的文本必须导致更接近的向量，然后只有它将能够正确地分类文本。</h2><p id="1f21" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">这意味着，假设向量<strong class="io hj"> v1代表“食物是美味的”</strong>，向量<strong class="io hj"> v2代表“食物是美味的”</strong>，那么v1和v2之间的距离必须很小。</p><p id="ac6c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">假设向量<strong class="io hj"> v3代表“食物不好吃”，</strong>现在v1和v3之间的距离一定很大。</p><h2 id="6438" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">让我们检查一下…</h2><p id="b887" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">这种意大利面非常好吃，而且价格实惠。</p><p id="6106" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">点评2——这种面食不好吃，而且价格实惠。</strong></p><p id="5bb3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，两个评论中唯一的区别是“不是”，但它们不应该是相近的向量，因为评论1与评论2相矛盾。</p><p id="ccd5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">将评论转化为矢量</strong></p><figure class="kg kh ki kj fd ij er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lq"><img src="../Images/fa5ecda21a518e1aa8fb7e35ca3c0c00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMy37JULLM3L0zA7MquaXQ.jpeg"/></div></div></figure><p id="093d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">计算向量之间的距离</strong></p><figure class="kg kh ki kj fd ij er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lq"><img src="../Images/f2f42d25c96b4ab7d793191a454977cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kxk9HlZ5yX7B1Zp60cBSEg.jpeg"/></div></div></figure><p id="d612" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以√2不是一个好的距离，没有我们预期的远，距离一定很大。</p><p id="53e7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这就是弓的局限性</p><h2 id="f92a" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated"><strong class="ak">弓的限制</strong></h2><ol class=""><li id="a770" class="kt ku hi io b ip ko it kp ix lr jb ls jf lt jj ky kz la lb bi translated">当句子有小的变化时，BOW不能很好地工作。</li><li id="ba3d" class="kt ku hi io b ip lc it ld ix le jb lf jf lg jj ky kz la lb bi translated">BOW不考虑单词的相似性</li></ol><p id="10de" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以基本上“好吃”和“美味”是几乎相同的词，所以必须有相同的向量，但BOW并不保证所有的。</p><h2 id="4e2c" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated"><strong class="ak">二元弓</strong></h2><p id="8ff0" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">现在，如果我们只把“1”放在一个特定的单词存在的地方，把“0”放在一个单词不存在的地方，而不是计算单词的频率，这就是单词的二进制包。</p><p id="d94c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">示例-</p><p id="5ef8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">D1-“我知道英语和数学”</p><p id="10e3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">D2-“我懂英语、python和java”</p><p id="83a9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果我们创建一个所有单词的向量，我们会得到这个。</p><figure class="kg kh ki kj fd ij er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es lu"><img src="../Images/85baca0169815ae761c97abe70d8110d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eFf1d_AGksL-1bweoLTltg.jpeg"/></div></div></figure></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><p id="b66d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在让我们研究一些有趣的话题…</p><h2 id="ffec" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">UNIGRAM</h2><p id="31c5" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">每个单词都被视为一个维度。</p><h2 id="f691" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">二元模型</h2><p id="1760" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">每个维度都有一对词。</p><h2 id="2942" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">三线形</h2><p id="c40d" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">每个维度有三个词。</p><figure class="kg kh ki kj fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/e087418899729886720925628ee42e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*tufb2Ea4ZBVydTuvrIUT5A.png"/></div></figure><p id="9b0d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从上面的例子中，我认为unigram、bigram和trigram之间的区别很明显。</p><p id="4b76" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">我们为什么要谈论“N”克？</strong></p><p id="8ba5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Unigram BOW完全丢弃序列信息。理解整个句子而不知道单词的顺序是不公平的。</p><p id="80dd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一系列的单词比一个特定的单词更能让你理解一个句子。</p><p id="602e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">二元模型、三元模型、n元模型保留了一些序列。</p><h2 id="da4c" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated"><strong class="ak">但是N克还是有一个主要的限制</strong></h2><p id="9496" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">如果你观察，你会发现双字母组的数量多于单字母组的数量，这是因为在双字母组中，一个单词重复出现两次，而在单字母组中，一个单词只出现一次。</p><p id="27bc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当我们增加N gram中的“N”时，维数增加。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><p id="b920" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">文字袋代码</strong></p><p id="dedf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">bow的代码非常简单，Scikit learn为我们提供了一个非常有用的库，称为CountVectorizer</p><p id="7872" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">它将把一组文本文档转换成一个令牌计数矩阵</strong></p><h2 id="0a0d" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated"><strong class="ak">简单的鞠躬</strong></h2><p id="d0cc" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated"><strong class="io hj"><em class="lw">count _ vect = count vector izer()</em></strong></p><p id="7d01" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"><em class="lw">final _ count = count _ vect . fit _ transform(点评['text '。</em>值)</strong></p><h2 id="dafd" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated"><strong class="ak">带N克的弓</strong></h2><p id="61e3" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated"><strong class="io hj"><em class="lw">count _ vect = count vectorizer(n _ gram =(1，2)#这是针对bigram </em> </strong></p><p id="692c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"><em class="lw">final _ count = count _ vect . fit _ transform(点评['text '。值]) </em> </strong></p><p id="6856" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">由于这个n元，矩阵的维数会大大增加。</p><h2 id="9267" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">对于二元弓</h2><p id="6f4d" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated"><strong class="io hj"><em class="lw">count _ vect = count vectorizer(n _ gram =(1，2)，Binary = ' TRUE ')# Binary bow for bigram</em>T3】</strong></p><p id="7748" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果这对你来说太难了，不要担心，我们将做一个简单的项目，我们将看到所有细节，我们将看到为什么我们不必担心代码。</p><p id="948c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本文中，我们完成了BOW，并了解了BOW的局限性，即<strong class="io hj"> <em class="lw"> BOW不考虑单词之间的相似性</em> </strong>，为了解决这个问题，研究人员引入了一些漂亮的概念，如W2V(单词到向量)。</p><p id="45b9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">在下一篇文章中，我们将讨论Tf_idf、W2V、平均W2V、TF_IDF W2V等。</strong></p><p id="65b1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">感谢阅读…</p></div></div>    
</body>
</html>