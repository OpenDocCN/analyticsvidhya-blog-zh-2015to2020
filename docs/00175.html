<html>
<head>
<title>An Introduction to Text Summarization using the TextRank Algorithm (with Python implementation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TextRank算法的文本摘要介绍(Python实现)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/an-introduction-to-text-summarization-using-the-textrank-algorithm-with-python-implementation-2370c39d0c60?source=collection_archive---------0-----------------------#2018-11-01">https://medium.com/analytics-vidhya/an-introduction-to-text-summarization-using-the-textrank-algorithm-with-python-implementation-2370c39d0c60?source=collection_archive---------0-----------------------#2018-11-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/03f794beee1eaba245c5a2888bf5d099.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dQgutaEHX_ME2KvbO1LnNg.jpeg"/></div></figure><h1 id="3bb2" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">介绍</h1><p id="6c4b" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">文本摘要是自然语言处理(NLP)的应用之一，它必将对我们的生活产生巨大的影响。随着数字媒体和出版业的不断发展，谁有时间去浏览整篇文章/文档/书籍来决定它们是否有用呢？谢天谢地，这项技术已经出现了。</p><p id="2245" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">你有没有在shorts 里碰到过手机app <strong class="jm hj">？这是一个创新的新闻应用程序，可以将新闻文章转换成60字的摘要。而这正是我们在这篇文章中要学习的——<strong class="jm hj">自动文本摘要</strong>。</strong></p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/d4b116e1a7d0634a1bd51a23f5912c1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/0*lLWRrru0qVd0-O2_.png"/></div></figure><p id="d5ba" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">自动文本摘要是自然语言处理领域中最具挑战性和最有趣的问题之一。这是一个从多种文本资源(如书籍、新闻文章、博客帖子、研究论文、电子邮件和推文)中生成简明而有意义的文本摘要的过程。</p><p id="1edc" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">由于大量文本数据的可用性，目前对自动文本摘要系统的需求正在激增。</p><p id="876e" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">通过这篇文章，我们将探索文本摘要的领域。我们将理解TextRank算法是如何工作的，并将在Python中实现它。系好安全带，这将是一次有趣的旅程！</p><h1 id="6775" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">目录</h1><ol class=""><li id="e925" class="ks kt hi jm b jn jo jr js jv ku jz kv kd kw kh kx ky kz la bi translated">文本摘要方法</li><li id="b5bd" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh kx ky kz la bi translated">了解TextRank算法</li><li id="3002" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh kx ky kz la bi translated">理解问题陈述</li><li id="7b0f" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh kx ky kz la bi translated">TextRank算法的实现</li><li id="208f" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh kx ky kz la bi translated">下一步是什么？</li></ol><h1 id="f015" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">文本摘要方法</h1><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/0cf338873deff9bac2644f6e32b4e023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/0*svAghvHK0Ou2IzdJ.png"/></div></figure><p id="b640" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">自动文本摘要早在20世纪50年代就受到了关注。汉斯·彼得·鲁恩在20世纪50年代后期发表了一篇名为“文学摘要的自动创建”的<a class="ae lh" href="http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>，该论文使用词频和短语频等特征从文本中提取重要句子用于摘要目的。</p><p id="cb76" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">Harold P Edmundson在20世纪60年代后期进行的另一项重要的研究使用了一些方法，如提示词的存在、文本标题中出现的词以及句子的位置，来提取重要的句子用于文本摘要。从那时起，许多重要的和令人兴奋的研究已经发表，以解决自动文本摘要的挑战。</p><p id="8cd4" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">文本摘要可以大致分为两类— <strong class="jm hj">抽取摘要</strong>和<strong class="jm hj">抽象摘要</strong>。</p><ol class=""><li id="2ac8" class="ks kt hi jm b jn ki jr kj jv li jz lj kd lk kh kx ky kz la bi translated"><strong class="jm hj">提取摘要:</strong>这些方法依赖于从一段文本中提取几个部分，如短语和句子，并将它们堆叠在一起以创建摘要。因此，识别用于摘要的正确句子在抽取方法中是至关重要的。</li><li id="059f" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh kx ky kz la bi translated"><strong class="jm hj">抽象摘要:</strong>这些方法使用先进的自然语言处理技术来生成全新的摘要。本摘要的某些部分甚至可能不会出现在原文中。</li></ol><p id="1ec5" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在这篇文章中，我们将关注<strong class="jm hj">提取摘要</strong>技术。</p><h1 id="c3f5" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">了解TextRank算法</h1><p id="d148" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在开始使用TextRank算法之前，我们应该熟悉另一种算法PageRank算法。事实上，这实际上启发了TextRank！PageRank主要用于对在线搜索结果中的网页进行排名。让我们借助一个例子快速了解一下这个算法的基础。</p><h1 id="90b2" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">PageRank算法</h1><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/682a189abcb7ce974cd2fe7d7ade685f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/0*2g_aXpMcY6F0r_px.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated"><em class="lq">来源:</em><a class="ae lh" href="http://www.scottbot.net/HIAL/" rel="noopener ugc nofollow" target="_blank"><em class="lq">http://www.scottbot.net/HIAL/</em></a></figcaption></figure><p id="4a1a" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">假设我们有4个网页——w1、w2、w3和w4。这些页面包含相互指向的链接。有些页面可能没有链接，这些被称为悬挂页面。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/9e0fc0959919c71bb0ffdacacc7d588e.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/0*jvawSQ4h2Lnr9KNp.png"/></div></figure><ul class=""><li id="e7cb" class="ks kt hi jm b jn ki jr kj jv li jz lj kd lk kh ls ky kz la bi translated">网页w1具有指向w2和w4的链接</li><li id="3154" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">w2有w3和w1的链接</li><li id="9707" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">w4仅具有网页w1的链接</li><li id="363a" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">w3没有链接，因此它将被称为悬挂页面</li></ul><p id="bb19" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">为了对这些页面进行排名，我们必须计算一个叫做<strong class="jm hj"> PageRank score </strong>的分数。这个分数是用户访问该页面的概率。</p><p id="07ee" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">为了捕捉用户从一个页面导航到另一个页面的概率，我们将创建一个正方形矩阵M ，具有n行和n列，其中<strong class="jm hj"> n </strong>是网页的数量。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/0af8b283f69b0891a11ff574d252ff5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/0*iUzmGDu8Y0tW5ArD.png"/></div></figure><p id="16ab" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">这个矩阵的每个元素表示用户从一个网页转换到另一个网页的概率。例如，下面突出显示的单元格包含从w1过渡到w2的概率。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es lu"><img src="../Images/b8386a4ab24390f37e2091a5ee5b1151.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/0*46eFf9VHzIeJidCT.png"/></div></div></figure><p id="8adf" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">概率的初始化在下面的步骤中解释:</p><ol class=""><li id="50b8" class="ks kt hi jm b jn ki jr kj jv li jz lj kd lk kh kx ky kz la bi translated">从页面I到j的概率，即M[ i ][ j ]，用<strong class="jm hj"> 1/(网页wi中唯一链接的数量)</strong>初始化</li><li id="51d4" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh kx ky kz la bi translated">如果页面I和j之间没有链接，那么概率将被初始化为<strong class="jm hj"> 0 </strong></li><li id="cbd1" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh kx ky kz la bi translated">如果一个用户登陆了一个悬空页面，那么可以假设他同样有可能转换到其他页面。因此，M[ i ][ j ]将被初始化为<strong class="jm hj"> 1/(网页数量)</strong></li></ol><p id="8636" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">因此，在我们的情况下，矩阵M将被初始化如下:</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/ae0e6b3b8558070004244969c54ef6b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/0*0kl-s2Jn4csmPssM.png"/></div></figure><p id="0ff8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">最后，这个矩阵中的值将以迭代的方式更新，以得出网页排名。</p><h1 id="e62c" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">TextRank算法</h1><p id="871f" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">现在我们已经掌握了PageRank，让我们来理解一下TextRank算法。我在下面列出了这两种算法的相似之处:</p><ul class=""><li id="3afb" class="ks kt hi jm b jn ki jr kj jv li jz lj kd lk kh ls ky kz la bi translated">我们用句子代替网页</li><li id="f842" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">任意两个句子之间的相似度被用作网页转移概率的等价物</li><li id="681f" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">相似性得分存储在一个正方形矩阵中，类似于用于PageRank的矩阵M</li></ul><p id="2127" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">TextRank是一种抽取式无监督文本摘要技术。让我们来看看我们将遵循的TextRank算法的流程:</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/63925ad1d2c81c8308785ff6b2a8930a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/0*h3UOe6YSk4XCVH4-.png"/></div></figure><ul class=""><li id="940e" class="ks kt hi jm b jn ki jr kj jv li jz lj kd lk kh ls ky kz la bi translated">第一步是连接文章中包含的所有文本</li><li id="bb56" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">然后将文本分成单独的句子</li><li id="c17f" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">下一步，我们将为每一个句子找到向量表示(单词嵌入)</li><li id="f1a6" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">然后计算句子向量之间的相似度并存储在矩阵中</li><li id="33e9" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">然后将相似度矩阵转换成图，以句子为顶点，相似度得分为边，用于句子排名计算</li><li id="4c97" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">最后，一定数量的排名靠前的句子形成最终摘要</li></ul><p id="4d05" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">所以，事不宜迟，让我们启动Jupyter笔记本，开始编码吧！</p><p id="7fc4" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><em class="mb">注:如果你想了解更多关于图论的知识，那么我推荐你看看这篇</em> <a class="ae lh" href="https://www.analyticsvidhya.com/blog/2018/09/introduction-graph-theory-applications-python/" rel="noopener ugc nofollow" target="_blank"> <em class="mb">文章</em> </a> <em class="mb">。</em></p><h1 id="16d3" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">理解问题陈述</h1><p id="a8ea" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">作为一个主要的网球爱好者，我总是通过虔诚地浏览尽可能多的网上网球更新来让自己了解这项运动的最新进展。然而，事实证明这是一项相当困难的工作！有太多的资源和时间是一个限制。</p><p id="96fa" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">因此，我决定设计一个系统，通过浏览多篇文章为我准备一个要点摘要。如何着手做这件事？这就是我将在本教程中向您展示的内容。我们将把TextRank算法应用到一个收集文章的数据集上，目的是创建一个漂亮简洁的摘要。</p><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es mc"><img src="../Images/207a56d643ad890f257e4af2a3bb7f6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EkrQUYI5z5hFzrm-.png"/></div></div></figure><p id="46f9" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">请注意，这本质上是一个单领域多文档的摘要任务，也就是说，我们将把多篇文章作为输入，并生成一个要点摘要。多领域文本摘要不在本文讨论范围之内，但是您可以随时尝试一下。</p><h2 id="1adc" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">你可以从<a class="ae lh" href="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/10/tennis_articles_v4.csv" rel="noopener ugc nofollow" target="_blank">这里</a>下载我们将要使用的数据集。</h2><h1 id="8e7c" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">TextRank算法的实现</h1><p id="0710" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">所以，没有任何进一步的麻烦，点燃你的Jupyter笔记本，让我们实施我们到目前为止所学的。</p><h2 id="030d" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">导入所需的库</h2><p id="bcfe" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">首先，导入我们将用来应对这一挑战的库。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="0690" class="md in hi ms b fi mw mx l my mz">import numpy as np <br/>import pandas as pd <br/>import nltk nltk.download('punkt') # one time execution <br/>import re</span></pre><h2 id="6752" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">读取数据</h2><p id="5e11" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">现在让我们来阅读我们的数据集。我已经在前一节提供了下载数据的链接(以防您错过)。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="a415" class="md in hi ms b fi mw mx l my mz">df = pd.read_csv("tennis_articles_v4.csv")</span></pre><h2 id="1696" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">检查数据</h2><p id="d2ad" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">让我们快速浏览一下数据。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="c5b9" class="md in hi ms b fi mw mx l my mz">df.head()</span></pre><figure class="ko kp kq kr fd ij er es paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="er es na"><img src="../Images/73d4e605270092d5312a58f0b467184c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fyIP6BQCMHvoRhl-.png"/></div></div></figure><p id="1359" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们的数据集中有3列—“文章id”、“文章文本”和“来源”。我们对“article_text”列最感兴趣，因为它包含文章的文本。让我们打印数据中第一篇文章的文本，看看它是如何出现的。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="102f" class="md in hi ms b fi mw mx l my mz">df['article_text'][0]</span></pre><p id="a058" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">输出:</strong></p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="cdbf" class="md in hi ms b fi mw mx l my mz">"Maria Sharapova has basically no friends as tennis players on the WTA Tour. The Russian player has no problems in openly speaking about it and in a recent interview she said: 'I don't really hide any feelings too much. I think everyone knows this is my job here. When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person whether they're in the locker room or across the net...</span></pre><h2 id="b02b" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">将文本拆分成句子</h2><p id="4630" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">现在下一步是将文本分解成单独的句子。我们将使用<em class="mb"> nltk </em>库的<em class="mb"> sent_tokenize( ) </em>函数来完成这项工作。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="2506" class="md in hi ms b fi mw mx l my mz">from nltk.tokenize import sent_tokenize</span><span id="a7d2" class="md in hi ms b fi nb mx l my mz">sentences = [] <br/>for s in df['article_text']: <br/>  sentences.append(sent_tokenize(s))</span><span id="cb23" class="md in hi ms b fi nb mx l my mz"># flatten list<br/>sentences = [y for x in sentences for y in x]</span></pre><p id="7a03" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">让我们打印列表中的几个元素<em class="mb">句子</em>。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="85d8" class="md in hi ms b fi mw mx l my mz">sentences[:5]</span></pre><p id="7d28" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">输出:</strong></p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="27ae" class="md in hi ms b fi mw mx l my mz">['Maria Sharapova has basically no friends as tennis players on the WTA Tour.', </span><span id="67c7" class="md in hi ms b fi nb mx l my mz">"The Russian player has no problems in openly speaking about it and in a recent interview she said: 'I don't really hide any feelings too much.", </span><span id="041a" class="md in hi ms b fi nb mx l my mz">'I think everyone knows this is my job here.', </span><span id="9b54" class="md in hi ms b fi nb mx l my mz">"When I'm on the courts or when I'm on the court playing, <br/>I'm a competitor and I want to beat every single person whether they're in the locker room or across the net.So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match.", </span><span id="80ea" class="md in hi ms b fi nb mx l my mz">"I'm a pretty competitive girl."]</span></pre><h2 id="0626" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">下载手套单词嵌入</h2><p id="40f5" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated"><a class="ae lh" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">手套</a>单词嵌入是单词的向量表示。这些单词嵌入将用于为我们的句子创建向量。我们也可以使用单词袋或TF-IDF方法来为我们的句子创建特征，但是这些方法忽略了单词的顺序(并且特征的数量通常非常大)。</p><p id="c498" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们将使用预先训练好的<strong class="jm hj">维基百科2014 + Gigaword 5 </strong>手套向量<a class="ae lh" href="https://nlp.stanford.edu/data/glove.6B.zip" rel="noopener ugc nofollow" target="_blank">此处</a>。<em class="mb">注意——这些单词嵌入的大小是822 MB。</em></p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="0c23" class="md in hi ms b fi mw mx l my mz">!wget <a class="ae lh" href="http://nlp.stanford.edu/data/glove.6B.zip" rel="noopener ugc nofollow" target="_blank">http://nlp.stanford.edu/data/glove.6B.zip</a> <br/>!unzip glove*.zip</span></pre><p id="6f23" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">让我们提取单词嵌入或单词向量。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="855a" class="md in hi ms b fi mw mx l my mz"># Extract word vectors <br/>word_embeddings = {} </span><span id="37e6" class="md in hi ms b fi nb mx l my mz">f = open('glove.6B.100d.txt', encoding='utf-8') <br/>for line in f: <br/>    values = line.split() <br/>    word = values[0] <br/>    coefs = np.asarray(values[1:], dtype='float32')   <br/>    word_embeddings[word] = coefs <br/>f.close()</span></pre><p id="1fe1" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们现在在字典中存储了400，000个不同术语的单词向量——“单词嵌入”。</p><h2 id="c078" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">文本预处理</h2><p id="c569" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">让你的文本数据尽可能无噪声总是一个好的做法。所以，让我们做一些基本的文本清理。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="54d0" class="md in hi ms b fi mw mx l my mz"># remove punctuations, numbers and special characters clean_sentences = pd.Series(sentences).str.replace("[^a-zA-Z]", " ") </span><span id="b7d5" class="md in hi ms b fi nb mx l my mz"># make alphabets lowercase <br/>clean_sentences = [s.lower() for s in clean_sentences]</span></pre><p id="1372" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">去掉停用词(一种语言的常用词——是、是、是、的、的、在等)。)出现在句子中。如果您还没有下载<em class="mb"> nltk-stopwords </em>，那么执行以下代码行:</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="5a61" class="md in hi ms b fi mw mx l my mz">nltk.download('stopwords')</span></pre><p id="b625" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在我们可以导入停用词了。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="12e5" class="md in hi ms b fi mw mx l my mz">from nltk.corpus import stopwords <br/>stop_words = stopwords.words('english')</span></pre><p id="26cd" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">让我们定义一个函数来从数据集中删除这些停用词。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="3428" class="md in hi ms b fi mw mx l my mz"># function to remove stopwords <br/>def remove_stopwords(sen):     <br/>    sen_new = " ".join([i for i in sen if i not in stop_words])          <br/>    return sen_new</span><span id="906a" class="md in hi ms b fi nb mx l my mz"># remove stopwords from the sentences <br/>clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]</span></pre><p id="5a64" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们将使用<em class="mb"> clean_sentences </em>在GloVe word vectors的帮助下为我们数据中的句子创建向量。</p><h2 id="ea9e" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">句子的向量表示</h2><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="140a" class="md in hi ms b fi mw mx l my mz"># Extract word vectors <br/>word_embeddings = {} <br/>f = open('glove.6B.100d.txt', encoding='utf-8') <br/>for line in f: <br/>    values = line.split() <br/>    word = values[0] <br/>    coefs = np.asarray(values[1:], dtype='float32')    <br/>    word_embeddings[word] = coefs <br/>f.close()</span></pre><p id="409d" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在，让我们为我们的句子创建向量。我们将首先获取一个句子中组成单词的向量(每个向量的大小为100个元素),然后取这些向量的平均值以得到该句子的合并向量。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="4c03" class="md in hi ms b fi mw mx l my mz">sentence_vectors = [] <br/>for i in clean_sentences: <br/>  if len(i) != 0: <br/>    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in  <br/>        i.split()])/(len(i.split())+0.001) <br/>  else: <br/>    v = np.zeros((100,)) <br/>  sentence_vectors.append(v)</span></pre><h2 id="3b85" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">相似矩阵准备</h2><p id="ed24" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">下一步是找到句子之间的相似性，我们将使用余弦相似性方法来应对这一挑战。让我们为这个任务创建一个空的相似度矩阵，并用句子的余弦相似度填充它。</p><p id="6db1" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们先定义一个维数为零的矩阵(n * n)。我们将用句子的余弦相似度分数初始化这个矩阵。这里，<strong class="jm hj"> n </strong>是句子的数量。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="6975" class="md in hi ms b fi mw mx l my mz"># similarity matrix <br/>sim_mat = np.zeros([len(sentences), len(sentences)])</span></pre><p id="1034" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们将使用余弦相似度来计算一对句子之间的相似度。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="f218" class="md in hi ms b fi mw mx l my mz">from sklearn.metrics.pairwise import cosine_similarity</span></pre><p id="485d" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">并用余弦相似性得分初始化矩阵。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="7e67" class="md in hi ms b fi mw mx l my mz">for i in range(len(sentences)): <br/>  for j in range(len(sentences)): <br/>    if i != j: <br/>      sim_mat[i][j] = cosine_similarity <br/>                      (sentence_vectors[i].reshape(1,100),   <br/>                       sentence_vectors[j].reshape(1,100))[0,0]</span></pre><h2 id="0ca8" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">应用PageRank算法</h2><p id="1a4b" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在继续之前，让我们将相似性矩阵<em class="mb"> sim_mat </em>转换成一个图。该图的节点将代表句子，而边将代表句子之间的相似性得分。在这个图表上，我们将应用PageRank算法来得出句子的排名。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="dffc" class="md in hi ms b fi mw mx l my mz">import networkx as nx </span><span id="bc52" class="md in hi ms b fi nb mx l my mz">nx_graph = nx.from_numpy_array(sim_mat) <br/>scores = nx.pagerank(nx_graph)</span></pre><h2 id="05cd" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">摘要提取</h2><p id="c43c" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">最后，是时候根据排名提取前N个句子用于摘要生成了。</p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="de94" class="md in hi ms b fi mw mx l my mz">ranked_sentences = sorted(((scores[i],s) for i,s in <br/>                           enumerate(sentences)), reverse=True)</span><span id="3ae3" class="md in hi ms b fi nb mx l my mz"># Extract top 10 sentences as the summary <br/>for i in range(10): <br/>  print(ranked_sentences[i][1])</span></pre><p id="a007" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">输出:</strong></p><pre class="ko kp kq kr fd mr ms mt mu aw mv bi"><span id="f323" class="md in hi ms b fi mw mx l my mz">When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person <br/>whether they're in the locker room or across the net.So I'm not the one to strike up a conversation about the <br/>weather and know that in the next few minutes I have to go and try to win a tennis match.<br/><br/>Major players feel that a big event in late November combined with one in January before the Australian Open will <br/>mean too much tennis and too little rest.<br/><br/>Speaking at the Swiss Indoors tournament where he will play in Sundays final against Romanian qualifier Marius <br/>Copil, the world number three said that given the impossibly short time frame to make a decision, he opted out of <br/>any commitment.<br/><br/>"I felt like the best weeks that I had to get to know players when I was playing were the Fed Cup weeks or the <br/>Olympic weeks, not necessarily during the tournaments.<br/><br/>Currently in ninth place, Nishikori with a win could move to within 125 points of the cut for the eight-man event <br/>in London next month.<br/><br/>He used his first break point to close out the first set before going up 3-0 in the second and wrapping up the <br/>win on his first match point.<br/>The Spaniard broke Anderson twice in the second but didn't get another chance on the South African's serve in the <br/>final set.<br/><br/>"We also had the impression that at this stage it might be better to play matches than to train.<br/><br/>The competition is set to feature 18 countries in the November 18-24 finals in Madrid next year, and will replace <br/>the classic home-and-away ties played four times per year for decades.<br/><br/>Federer said earlier this month in Shanghai in that his chances of playing the Davis Cup were all but non-existent.</span></pre><p id="32be" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们走吧！对我们的文章来说，这是一个令人敬畏的、简洁的、有用的总结。</p><h1 id="b99e" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">下一步是什么？</h1><p id="8f94" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">自动文本摘要是一个热门的研究课题，在本文中，我们只涉及了冰山一角。展望未来，我们将探索深度学习发挥重要作用的抽象文本摘要技术。此外，我们还可以了解以下总结任务:</p><p id="7d47" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">特定问题:</strong></p><ul class=""><li id="22d0" class="ks kt hi jm b jn ki jr kj jv li jz lj kd lk kh ls ky kz la bi translated">多领域文本摘要</li><li id="ccdd" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">单文档摘要</li><li id="9b1f" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">跨语言文本摘要(某些语言的源和另一种语言的摘要)</li></ul><p id="977a" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">特定算法:</strong></p><ul class=""><li id="e70d" class="ks kt hi jm b jn ki jr kj jv li jz lj kd lk kh ls ky kz la bi translated">使用RNNs和LSTM的文本摘要</li><li id="2446" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">使用强化学习的文本摘要</li><li id="b3b9" class="ks kt hi jm b jn lb jr lc jv ld jz le kd lf kh ls ky kz la bi translated">使用生成对抗网络的文本摘要</li></ul><h1 id="a3c5" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">结束注释</h1><p id="9b7f" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">我希望这篇文章能帮助你理解自动文本摘要的概念。它有各种各样的用例，并产生了非常成功的应用程序。无论是为了利用你的业务，还是仅仅为了你自己的知识，文本摘要是所有NLP爱好者都应该熟悉的一种方法。</p><p id="02d3" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我将在以后的文章中尝试使用高级技术来介绍抽象文本摘要技术。同时，请随时使用下面的评论部分让我知道你的想法，或者问你对这篇文章的任何问题。</p><h2 id="3cd2" class="md in hi bd io me mf mg is mh mi mj iw jv mk ml ja jz mm mn je kd mo mp ji mq bi translated">请在这个<a class="ae lh" href="https://github.com/prateekjoshi565/textrank_text_summarization" rel="noopener ugc nofollow" target="_blank"> GitHub Repo </a>中找到代码。</h2><p id="6a45" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated"><em class="mb">欢迎致电</em><strong class="jm hj"><em class="mb">prateekjoshi565@gmail.com</em></strong><em class="mb">联系我，进行一对一讨论。</em></p></div></div>    
</body>
</html>