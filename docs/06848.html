<html>
<head>
<title>Decision Trees Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/decision-trees-d99d1646de73?source=collection_archive---------13-----------------------#2020-06-04">https://medium.com/analytics-vidhya/decision-trees-d99d1646de73?source=collection_archive---------13-----------------------#2020-06-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7277d50560e5371befbdf07208911d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*c7gWsvl-fkjwNVD8.jpeg"/></div></div></figure><p id="3a7f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">决策树是最流行的机器学习算法之一。它基本上是基于属性/特征构建的树状结构。决策树是</em> <strong class="is hj"> <em class="jo">的非参数</em> </strong> <em class="jo">的监督学习方法。</em></p><p id="07ce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">决策树以树结构的形式建立分类或回归模型。它将一个数据集分解成越来越小的子集，与此同时，一个相关的决策树被增量开发。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es jp"><img src="../Images/ae16636ea525964277cb672db28096eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/0*OWyTx9xN8DZTjpgY.png"/></div></figure><p id="404a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最终的结果是一个有决策节点和叶节点的树，叶节点代表一个决策或分类。树中最顶端的决策节点，对应于称为根节点的最佳预测器。</p><blockquote class="ju jv jw"><p id="b6dd" class="iq ir jo is b it iu iv iw ix iy iz ja jx jc jd je jy jg jh ji jz jk jl jm jn hb bi translated"><em class="hi">决策树可以处理分类数据和数字数据。</em></p></blockquote><p id="677e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有不同类型的算法来构建决策树，例如</p><ul class=""><li id="5d0c" class="ka kb hi is b it iu ix iy jb kc jf kd jj ke jn kf kg kh ki bi translated">ID3:迭代二分器3使用<em class="jo">熵函数</em>和<em class="jo">信息增益</em>作为度量。</li><li id="0cd3" class="ka kb hi is b it kj ix kk jb kl jf km jj kn jn kf kg kh ki bi translated">CART : <strong class="is hj">分类</strong>和回归<strong class="is hj">树</strong>使用<em class="jo">基尼指数(分类)</em>作为度量。</li><li id="2c41" class="ka kb hi is b it kj ix kk jb kl jf km jj kn jn kf kg kh ki bi translated">CHAID:卡方自动交互检测在计算<strong class="is hj">分类树</strong>时执行多级分裂</li><li id="ae84" class="ka kb hi is b it kj ix kk jb kl jf km jj kn jn kf kg kh ki bi translated">MARS:多元自适应回归样条</li></ul><h1 id="1451" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">决策树算法</h1><p id="1f70" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">ID3(迭代二分法3)使用<em class="jo">熵函数</em>和<em class="jo">信息增益</em>作为度量。</p><h1 id="6cf8" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">熵函数</h1><p id="8a66" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">ID3算法基本上是说，第一步是为决策树的分裂选择正确的属性，选择哪个特征作为节点。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/67b4a6d0725c34615b1f4e650c79e7a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/0*_iYHq9pxet63kjQn.png"/></div></figure><blockquote class="ju jv jw"><p id="5efa" class="iq ir jo is b it iu iv iw ix iy iz ja jx jc jd je jy jg jh ji jz jk jl jm jn hb bi translated"><em class="hi">我们使用</em> <strong class="is hj"> <em class="hi">熵函数</em> </strong> <em class="hi">来选择分割决策树的特征或属性。熵帮助我们测量分裂的纯度。为了快速获得叶节点，我们必须选择写入功能。</em></p></blockquote><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/5df5d98fb712238f192d0f6eb489781f.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/0*Q-GNyDhHHUp8JYFg.png"/></div></figure><p id="c8ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果熵值为1，那么它是最差的分裂，这意味着分裂是完全不纯的</p><p id="f429" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，让我们为著名的数据之一“是否数据集”创建决策树(根据“是否”条件玩Y或N游戏)。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/c460eccc618afb40ce0a74bc29893041.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/0*e_C6b4csEGyFsLXi.png"/></div></figure><ul class=""><li id="3670" class="ka kb hi is b it iu ix iy jb kc jf kd jj ke jn kf kg kh ki bi translated">天气、温度、湿度和风力是预测因素，或者你可以说是独立因素。</li><li id="ad5a" class="ka kb hi is b it kj ix kk jb kl jf km jj kn jn kf kg kh ki bi translated">打高尔夫球是目标还是从属属性</li></ul><h1 id="3026" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">信息增益</h1><p id="d7b8" class="pw-post-body-paragraph iq ir hi is b it lm iv iw ix ln iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">信息增益基于在属性上分割数据集后熵的减少。</p><p id="2283" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要创建一棵树，我们首先需要有一个根节点，我们知道节点是特征/属性(展望、温度、湿度和风)，</p><ul class=""><li id="1174" class="ka kb hi is b it iu ix iy jb kc jf kd jj ke jn kf kg kh ki bi translated">首先我们要计算打高尔夫的熵。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/aeb7971e9c2ed49e0ce04a22e01598a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/0*oZoEJXQ06Wp0MSTV.png"/></div></div></figure><ul class=""><li id="d5ea" class="ka kb hi is b it iu ix iy jb kc jf kd jj ke jn kf kg kh ki bi translated">然后求所有特征/属性的熵。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/f7b28a14d9a6ed66e0b07ba3638e9373.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/0*TMdEuWp5GlSn4Z_l.png"/></div></figure><ul class=""><li id="b628" class="ka kb hi is b it iu ix iy jb kc jf kd jj ke jn kf kg kh ki bi translated">从分割前的熵中减去得到的熵。结果是信息增加，或者熵减少。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/ea60873a32b891d9b33bc8568b567a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/0*Qab_P2uKdT2btwP-.png"/></div></figure><ul class=""><li id="97ed" class="ka kb hi is b it iu ix iy jb kc jf kd jj ke jn kf kg kh ki bi translated">选择具有最大信息增益的属性作为决策节点，按分支划分数据集，并在每个分支上重复相同的过程。</li></ul><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/a322b71d0cec649a9d7eb54f0690bbac.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/0*CrcVm_WX4G2dIUsL.png"/></div></figure><p id="914a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，Outlook是最好的预测器，因为它具有最大的信息增益，这意味着它是决策树的根节点。由于阴的熵值是0，那么阴的叶节点将是Yes</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/12847105221f13b5a7a9293da6f19fb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/0*bJ7UfkN9mJR8B8WL.png"/></div></figure><p id="3452" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对子树重复同样的操作，直到得到树。T3】</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/d67579dedd0427ce2dac1dc90bf2745c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/0*9KpW5XyjpZCh8nGa.png"/></div></figure><p id="72df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后我们得到了这样的树:</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/75a4f177660846e68655d3a6295b4174.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/0*GrSCsQB1FXMU1lZb.png"/></div></figure><h1 id="b416" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">优势</h1><blockquote class="ju jv jw"><p id="ed1c" class="iq ir jo is b it iu iv iw ix iy iz ja jx jc jd je jy jg jh ji jz jk jl jm jn hb bi translated"><em class="hi">一个</em> <strong class="is hj"> <em class="hi">决策树</em> </strong> <em class="hi">的一个显著的</em> <strong class="is hj"> <em class="hi">优势</em> </strong> <em class="hi">就是它强制考虑一个</em> <strong class="is hj"> <em class="hi">决策</em> </strong> <em class="hi">的所有可能的结果，并追溯每一条路径得出结论。它对每个分支的结果进行综合分析，并确定需要进一步分析的</em> <strong class="is hj"> <em class="hi">决策</em> </strong> <em class="hi">节点。</em></p></blockquote><p id="2956" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">决策树机器学习算法到此为止。敬请关注更多博客。</p><p id="3cfd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">谢谢</em></p></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><p id="51f1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">决策树算法在海量数据上的实现</p><blockquote class="ju jv jw"><p id="fe7b" class="iq ir jo is b it iu iv iw ix iy iz ja jx jc jd je jy jg jh ji jz jk jl jm jn hb bi translated"><em class="hi">数据集:</em> <a class="ae mh" href="https://github.com/InternityFoundation/MachineLearning_Navu4/blob/master/Day%208%20:%20Decision%20Tree/titanic.csv" rel="noopener ugc nofollow" target="_blank"> <em class="hi">泰坦尼克号</em> </a> <em class="hi">数据集</em></p></blockquote><p id="7c0d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">链接:<a class="ae mh" href="https://github.com/InternityFoundation/MachineLearning_Navu4/blob/master/Day%208%20:%20Decision%20Tree/Decision_tree_on_titanic_dataset.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/internity foundation/machine learning _ navu 4/blob/master/Day % 208% 20:% 20 Decision % 20 tree/Decision _ tree _ on _ titanic _ dataset . ipynb</a></p></div></div>    
</body>
</html>