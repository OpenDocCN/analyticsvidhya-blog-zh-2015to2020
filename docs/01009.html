<html>
<head>
<title>Classifying Song genres with Pipelines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用管道对歌曲流派进行分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classifying-song-genres-with-pipelines-c7186f66cebd?source=collection_archive---------21-----------------------#2019-09-24">https://medium.com/analytics-vidhya/classifying-song-genres-with-pipelines-c7186f66cebd?source=collection_archive---------21-----------------------#2019-09-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b7c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将探索如何使用管道来改善机器学习分类问题的工作流程。我们将通过向一个模型输入歌曲的特征来预测歌曲类型是摇滚还是嘻哈，这些特征是:声音、舞蹈性、活力、乐器性、生动性、语速、节奏和效价。这些数据是由一个名为Echo Nest的研究小组汇编的，该项目本身是基于DataCamp的一个名为“从音频数据中分类歌曲流派”的项目。在我们进入管道之前，让我们探索一下原始项目，然后与管道模型进行比较。此外，在<a class="ae jd" href="https://github.com/paulovictorcorreia/song_genre_classification" rel="noopener ugc nofollow" target="_blank"> github </a>上可以找到包含原始笔记本和用于管道的笔记本以及所用数据的存储库。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/358347f8544fc30deb03d86e80a7b9b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n4f84iaLiCE8zryc"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">由<a class="ae jd" href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">布雷特·乔丹</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="cf2e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">艰难探索歌曲类型</h1><p id="a0d5" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">项目的第一部分是导入包含在两个数据集中的数据:<em class="kx"> fma-rock-vs-hiphop.csv </em>和<em class="kx"> echonest-metrics.json. </em>然后下一步是在<em class="kx"> echonest-metrics.json </em>的dataframe和<em class="kx"> fma-rock-vs-hiphop.csv </em>的“track_id”和“genre_top”列之间进行合并目标列是“genre_top”。</p><p id="eb02" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是检查数据集的变量之间是否存在相关性。为此，需要打印用相关值着色的相关矩阵。这样做是为了检查是否有任何高度相关的变量可以从数据集中删除。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/7a52fdbd749cdd3a07a5e17f325dc2b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zXfn4M6LePZN2afb5zndPQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">变量的相关矩阵。</figcaption></figure><p id="ea4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所看到的，没有任何高度相关的变量，所以在这个数据帧上没有通过这个方法删除的列。</p><p id="40e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，为了尝试降低问题的维度，我们将使用主成分分析(PCA)并检查有多少结果成分描述了数据方差的90%。尽管如此，我们首先需要将数据分割成特征的数据帧和目标“genre_top”向量，然后使用sklearn的StandardScaler将数据标准化。在这样做之后，我们将PCA算法应用到特征中，并且以降序获得以下组件。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kz"><img src="../Images/c04bb1262152ad1de44424830d5150d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*Cxub5waMnOJuDhOTYh-eXQ.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">按降序排列的主成分。</figcaption></figure><p id="e5c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这幅图中，我们可以看到特性#0解释了几乎25%的差异，而组件#7解释了大约5%。为了减少维度，我们设置了90%的截止点，在这个截止点上，我们将选择解释这个百分比的特征。为此，我们将看到每个成分方差的累积图。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es la"><img src="../Images/607cc74268be1a8daf1364822b5e5688.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*5voWXlGQ75yrwMaVWnEi8w.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">每个分量方差的累积图。</figcaption></figure><p id="8e54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如该图所示，在#6特征上，我们解释了90%以上的方差，总共有7个分量，这意味着我们减少了8个特征数据框架中的1个维度。</p><p id="39c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然我们已经减少了数据的维数，但另一个问题仍然存在:我们的目标列是不平衡的。为了解决这个问题，我们进行了欠采样，减少了最常见的目标类别，即摇滚流派，有3892个样本，嘻哈歌曲有910个样本。因此，我们将3892个样本减少到910个，以消除预测模型中对摇滚歌曲的偏见。</p><p id="609b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们根据歌曲的特征训练了两个模型，分别是决策树分类器和逻辑回归，这两个模型都使用了sci-kit learn的默认超参数。在此之前，我们将数据分为训练和测试数据集，其中<em class="kx"> test_size </em>为数据集大小的25%。</p><p id="7fce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">利用这些模型和PCA算法的7个组件，决策树分类器在训练数据集的交叉验证上实现了78.82%的平均准确度，而它具有79.78%的测试准确度。LogisticRegressor在训练数据集的交叉验证上实现了85.27%的平均准确率，在测试数据集上实现了85.9%的平均准确率。有趣的是，数据集的训练精度比测试精度差，这可能是由于我们对数据进行了欠采样而导致的欠拟合。</p><p id="d0b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将在下一节中通过使用sklearn的管道来简化我们到目前为止所做的所有工作。</p><h1 id="44c8" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">使用管道</h1><p id="6f5b" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">这一部分的工作流程与上一部分类似。我们将使用相同的预处理步骤，并将它们作为步骤放到我们的管道中，除了数据集的平衡，它必须手动完成。在此部分之后，管道必须具有以下顺序:标准缩放数据，应用PCA提取组件，并应用所选模型。具有决策树分类器和逻辑分类器的管道的代码是:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lb"><img src="../Images/7c737433d50485733e8edfafea8636b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TOBYtAHqfCgf7HvylHWPeA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">决策树和逻辑回归器的流水线代码。</figcaption></figure><p id="6bae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">两条管道的分类报告如下:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lc"><img src="../Images/b7e4938b19743d8512d8d96ff4db4884.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*KzF23QvWMFIy2GsHU_qZow.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">流水线模型的分类报告。</figcaption></figure><p id="0889" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与上一节相比，我们对两个模型的测试精度相似，决策树为77.36%，逻辑回归器为85.71%。决策树的交叉验证训练准确率为80.44%，逻辑推理准确率为85.5%。在这种情况下，只有逻辑回归器的训练分数略低于测试准确度分数，因此我们不再有信心认为模型是欠拟合的。</p><p id="c787" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管我们已经简化了第一部分的工作流程，并且在两种情况下都表现得很好，但这并不是管道能为我们做的全部。如果我们想要一个更精确的模型，进行超参数调整是非常重要的，这就是调整模型的变量。当我们可以使用其他sklearn的分类器时，为什么只使用这两个模型呢？让我们使用其中的一些。</p><p id="4715" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要在我们的管道上使用其他模型，我们必须定义一个基础管道模型，如下图所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ld"><img src="../Images/115c51d508885e7912ae112fed62f311.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*6vEubr5PiRSmysgf3ephmw.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">这个问题的一般管道。</figcaption></figure><p id="1cbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将保持PCA的组件数量等于第一部分，因此我们将只改变分类器“clf”及其超参数，以便网格搜索比原始逻辑分类器性能更好的超参数。我们将在GridSearchCV函数上使用的管道搜索空间是:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es le"><img src="../Images/90e3fac8b446e91828dd6fbb95ef163c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*AUY_d37pF__kPz7PctIJnw.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">搜索空间以搜索更好的性能模型。</figcaption></figure><p id="705c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个搜索空间中，我们仍然有决策树和逻辑回归，尽管参数不同于默认值。此外，我们还添加了一个RandomForestClassifier、一个SupportVectorClassifier(SVC)、一个GradientBoostingClassifier和一个高斯朴素贝叶斯分类器。</p><p id="588b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练这个管道之后，在测试精度方面最好的性能模型是SVC模型，其中C=2，gamma=0.1，kernel =“RBF”，精度为87.25%，稍好的性能约为2%，训练精度为87.91%，也高于原始LogisticRegressor。</p><h1 id="f399" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">结论</h1><p id="856b" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在所有这些工作之后，我们可以得出结论，我们使用的管道节省了我们更多的编码，特别是在超参数调整期间，其中大部分工作是确定<em class="kx"> GridSearchCV </em>的搜索空间参数，使得在我们使用的参数网格内找到最优解更加容易和干净。</p><p id="99b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">找到的最优解略好于上一节的最优逻辑回归，但并不明显更好，但由于流水线的原因，它是在比我们对每个分类器进行gridsearch更短的时间窗口中找到的，从而为找到好的机器学习模型提供了一个好的解决方案。</p></div></div>    
</body>
</html>