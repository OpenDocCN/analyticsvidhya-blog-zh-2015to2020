<html>
<head>
<title>ML05: Neural Network on iris by Numpy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML05:Numpy的iris上的神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ml05-8771620a2023?source=collection_archive---------1-----------------------#2020-10-30">https://medium.com/analytics-vidhya/ml05-8771620a2023?source=collection_archive---------1-----------------------#2020-10-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="58b8" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">由感知器从零开始发现神经网络元素</h2></div><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="97e6" class="jg jh hi jc b fi ji jj l jk jl">Read time: 10~12 min</span><span id="f163" class="jg jh hi jc b fi jm jj l jk jl">Complete Python code: <a class="ae jn" href="https://bit.ly/2UZftXq" rel="noopener ugc nofollow" target="_blank">https://bit.ly/2UZftXq</a></span></pre><p id="f2bb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">神经网络的初学者往往第一眼就被复杂的数学和复杂的模型吓倒，所以我想在iris上分享一个相当简单的神经网络玩具示例，不利用任何DL框架，如日本人写的书[1]中的PyTorch或Tensorflow，只使用NumPy — —也就是说，我们需要自己创建损失函数、激活器和调整权重。</p><p id="bd49" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">神经元是神经网络的最小单位。感知器是单层神经网络。让我们尝试用感知器对虹膜进行二进制分类。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><blockquote class="kr ks kt"><p id="e9eb" class="jo jp ku jq b jr js ij jt ju jv im jw kv jy jz ka kw kc kd ke kx kg kh ki kj hb bi translated"><strong class="jq hj"> <em class="hi">大纲</em> </strong> <em class="hi"> <br/> (1) </em> <a class="ae jn" href="#0ecf" rel="noopener ugc nofollow"> <em class="hi">数据集</em></a><em class="hi"><br/>(2)</em><a class="ae jn" href="#6ad1" rel="noopener ugc nofollow"><em class="hi">神经网络复习</em></a><em class="hi"><br/>(3)</em><a class="ae jn" href="#6c15" rel="noopener ugc nofollow"><em class="hi">输入</em></a><em class="hi"><br/>(4)</em><a class="ae jn" href="#f709" rel="noopener ugc nofollow"><em class="hi">数据拆分</em></a><em class="hi"><br/><br/>【5】</em></p></blockquote></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="0ecf" class="ky jh hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated">(1)数据集</h1><p id="5928" class="pw-post-body-paragraph jo jp hi jq b jr lp ij jt ju lq im jw jx lr jz ka kb ls kd ke kf lt kh ki kj hb bi translated">著名的iris来自:<br/><a class="ae jn" href="https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data" rel="noopener ugc nofollow" target="_blank">https://archive . ics . UCI . edu/ml/machine-learning-databases/iris/iris . data</a></p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="6ad1" class="ky jh hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated"><strong class="ak"> (2)神经网络复习</strong></h1><figure class="ix iy iz ja fd lv er es paragraph-image"><div class="er es lu"><img src="../Images/acc6dbd3958989d4fda7e3287bc6e391.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*e1zMa0oT4mxDUYes-ykZbA.png"/></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图1:感知机的可视化[2]</figcaption></figure><figure class="ix iy iz ja fd lv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mc"><img src="../Images/6f7fa6af1ae2b22aa12fbf9a4a5710e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ub-ifcgdi9xgryqvo0_GRA.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图2:神经网络的可视化[2]</figcaption></figure><figure class="ix iy iz ja fd lv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mh"><img src="../Images/ab37aaaf7a3af31a1503aff786fe3e9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gh2bqnpeix3Bh12KB7hEoQ.jpeg"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图3:低级操作和DL算法[3]</figcaption></figure></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="6c15" class="ky jh hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated">(3)输入</h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="75ab" class="jg jh hi jc b fi ji jj l jk jl">import numpy as np<br/>import pandas as pd<br/>import os<br/>os.chdir("D:\\Python\\Numpy_JP\\ch04-3") <br/># Choose your own working directory</span><span id="eb9e" class="jg jh hi jc b fi jm jj l jk jl">df = pd.read_csv('iris.data', header=None)<br/>print(df)</span></pre><p id="6090" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">iris的数据帧如下:</p><figure class="ix iy iz ja fd lv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mi"><img src="../Images/ddf0c5a108d00c0d65f5da564b8c8d81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ml2KEaNEl6kf9dQ8eNQ-dw.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图iris的数据帧</figcaption></figure><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="36d1" class="jg jh hi jc b fi ji jj l jk jl">x = df.iloc[0:100,[0, 1, 2, 3]].values<br/>y = df.iloc[0:100,4].values<br/>y = np.where(y=='Iris-setosa', 0, 1)</span></pre><p id="d137" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们取前100行，将数据集分成<em class="ku"> x </em>(特征)&amp; <em class="ku"> y </em>(目标)。然后<em class="ku"> np.where </em>将名义数据<em class="ku"> y </em>从文本转换为数字。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="f709" class="ky jh hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated">(4)数据拆分</h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="34a4" class="jg jh hi jc b fi ji jj l jk jl">x_train = np.empty((80, 4))<br/>x_test = np.empty((20, 4))<br/>y_train = np.empty(80)<br/>y_test = np.empty(20)</span><span id="3c4c" class="jg jh hi jc b fi jm jj l jk jl">x_train[:40],x_train[40:] = x[:40],x[50:90]<br/>x_test[:10],x_test[10:] = x[40:50],x[90:100]<br/>y_train[:40],y_train[40:] = y[:40],y[50:90]<br/>y_test[:10],y_test[10:] = y[40:50],y[90:100]</span></pre><p id="28fb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">第1~50行为“<em class="ku">鸢尾-刚毛鸢尾</em>”，第51~100行为“<em class="ku">鸢尾-海滨鸢尾</em>”所以我们收集的第1~40行和第51~90行作为训练集，其余行作为测试集。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="81c3" class="ky jh hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated">(5)定义功能</h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="f2d9" class="jg jh hi jc b fi ji jj l jk jl">def sigmoid(x):<br/>    return 1/(1+np.exp(-x))</span><span id="5a5d" class="jg jh hi jc b fi jm jj l jk jl">def activation(x, w, b):<br/>    return sigmoid(np.dot(x, w)+b)</span><span id="f9b9" class="jg jh hi jc b fi jm jj l jk jl">def update(x, y_train, w, b, eta): <br/>    y_pred = activation(x, w, b) <br/>    # activator<br/>    a = (y_pred - y_train) * y_pred * (1- y_pred) <br/>    # partial derivative loss function</span><span id="3323" class="jg jh hi jc b fi jm jj l jk jl">    for i in range(4):<br/>        w[i] -= eta * 1/float(len(y)) * np.sum(a*x[:,i])<br/>    b -= eta * 1/float(len(y))*np.sum(a)<br/>    return w, b</span></pre><p id="5a9f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们探究一下上述代码背后的数学原理:</p><figure class="ix iy iz ja fd lv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mj"><img src="../Images/fd01eeed7d67069eb087d72901879110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xtjPR0OnFU0g-nkfLh-Xzw.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图5:神经网络函数和损失函数[4]</figcaption></figure><figure class="ix iy iz ja fd lv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mk"><img src="../Images/a39c4872bd6bcf559e121a1037f69f67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*glhxZ_T8B5WiojOVqly5XA.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图6:偏导数和sigmoid激活器</figcaption></figure><figure class="ix iy iz ja fd lv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es ml"><img src="../Images/01b19db2256ee4b2914b158df68a7d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5p_I_n4lJ9uP-2GR2Le99g.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图7:权重更新-1</figcaption></figure><figure class="ix iy iz ja fd lv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mm"><img src="../Images/6f5724d02a967ba7c904e05c16200dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tvjbuekade6vRZ9fCDsUIQ.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图8:权重更新-2</figcaption></figure><ul class=""><li id="9766" class="mn mo hi jq b jr js ju jv jx mp kb mq kf mr kj ms mt mu mv bi translated"><strong class="jq hj">激活器</strong>:乙状结肠功能</li><li id="97e2" class="mn mo hi jq b jr mw ju mx jx my kb mz kf na kj ms mt mu mv bi translated"><strong class="jq hj">损失函数</strong> : MSE(均方差)</li><li id="5d95" class="mn mo hi jq b jr mw ju mx jx my kb mz kf na kj ms mt mu mv bi translated"><strong class="jq hj">优化器</strong>:梯度下降</li><li id="f88c" class="mn mo hi jq b jr mw ju mx jx my kb mz kf na kj ms mt mu mv bi translated"><strong class="jq hj">权重更新</strong>:令人厌烦的数学工作</li></ul></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="371b" class="ky jh hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated">(6)培训</h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="12db" class="jg jh hi jc b fi ji jj l jk jl">weights = np.ones(4)/10 <br/>bias = np.ones(1)/10 <br/>eta = 0.1<br/>for _ in range(15): # Run both epoch=15 &amp; epoch=100 <br/> weights, bias = update(x_train, y_train, weights, bias, eta=0.1)</span></pre><ul class=""><li id="903f" class="mn mo hi jq b jr js ju jv jx mp kb mq kf mr kj ms mt mu mv bi translated"><strong class="jq hj">初始权重</strong>:设wi &amp; b均为0.1</li><li id="0da7" class="mn mo hi jq b jr mw ju mx jx my kb mz kf na kj ms mt mu mv bi translated"><strong class="jq hj">学习率</strong>:设定eta= 1</li><li id="32ae" class="mn mo hi jq b jr mw ju mx jx my kb mz kf na kj ms mt mu mv bi translated"><strong class="jq hj">历元</strong>:运行两个历元= 15 &amp;历元= 100</li></ul></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="5eb0" class="ky jh hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated">(7)测试</h1><pre class="ix iy iz ja fd jb jc jd je aw jf bi"><span id="d480" class="jg jh hi jc b fi ji jj l jk jl">print("Epochs = 15") # Run both epoch=15 &amp; epoch=100<br/>print('weights = ', weights, 'bias = ', bias)<br/>print("y_test = {}".format(y_test))<br/>activation(x_test, weights, bias)</span></pre><figure class="ix iy iz ja fd lv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es nb"><img src="../Images/2d73092fd5501e418ceef92d4a58c797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FLXauurAyWRaNFGcrDS3UQ.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图9:纪元= 15的测试结果</figcaption></figure><figure class="ix iy iz ja fd lv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es nc"><img src="../Images/b3b3d02a08980034fd5f2670a205321a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aCGnonTZMXfhTK_HksfBqQ.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">图10:epochs = 100的测试结果</figcaption></figure><p id="f0df" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果我们将决策边界设置为0.5，那么我们在15和100这两个时期都获得了100%的准确性。</p><p id="1df8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">纪元= 15的前10次预测在0.46~0.49之间，纪元= 100的前10次预测在0.23~0.30之间。纪元= 15的最近10次预测在0.57~0.63之间，纪元= 100的最近10次预测在0.64~0.81之间。随着时代的上升，两个花团的价值观越来越远。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="0a19" class="ky jh hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated">(8)总结</h1><p id="1f9e" class="pw-post-body-paragraph jo jp hi jq b jr lp ij jt ju lq im jw jx lr jz ka kb ls kd ke kf lt kh ki kj hb bi translated"><em class="ku">没有任何NN框架</em>，我们搭建了一个单层神经网络！我们发现了像<strong class="jq hj">激活器</strong>(<em class="ku">s形</em> <strong class="jq hj"> ) </strong>、<strong class="jq hj">损失函数</strong> ( <em class="ku"> MSE </em>)、<strong class="jq hj">优化器</strong> ( <em class="ku">梯度下降</em>)、<strong class="jq hj">权重更新</strong> ( <em class="ku">令人厌烦的数学工作</em>)、<strong class="jq hj">初始权重</strong> ( <em class="ku"> wi = b= 1 </em>)这样的概念</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="a6c6" class="ky jh hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated">(9)参考文献</h1><p id="7f83" class="pw-post-body-paragraph jo jp hi jq b jr lp ij jt ju lq im jw jx lr jz ka kb ls kd ke kf lt kh ki kj hb bi translated">[1]吉田，t .和Ohata，S. (2018年)。艮巴·德·冢原！数据科学。日本，JP: SHOEISHA。</p><p id="fd26" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[2]英国建筑研究所，f .等人(2020年)。一种有效的基于元模型的方法来执行多目标建筑性能优化。能源与建筑，206，(未知)。</p><p id="32ad" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[3] Subramanian，V. (2018)。用PyTorch进行深度学习。英国伯明翰:Packt出版公司。</p><p id="1399" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[4]拉夫加登，t .和瓦兰特，G.(2015年)。现代算法工具箱第15讲:梯度下降基础。从<br/><a class="ae jn" href="http://theory.stanford.edu/~tim/s15/l/l15.pdf" rel="noopener ugc nofollow" target="_blank">http://theory.stanford.edu/~tim/s15/l/l15.pdf</a>检索</p></div></div>    
</body>
</html>