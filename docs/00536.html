<html>
<head>
<title>A Random Walk in a Forest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">森林中的漫步</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-random-walk-in-forest-2017659f7f86?source=collection_archive---------3-----------------------#2019-07-24">https://medium.com/analytics-vidhya/a-random-walk-in-forest-2017659f7f86?source=collection_archive---------3-----------------------#2019-07-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/a0f15cdc7219222ac23234d77f44948f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*izRWQ1eRI6gQ8TvM899YRQ.png"/></div></figure><h1 id="6a14" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">用超参数调整随机森林算法</h1><h1 id="5a08" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">数据科学之旅—第4章</h1><p id="f87e" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi ki translated"><span class="l kj kk kl bm km kn ko kp kq di"> R </span> <strong class="jm hj"> andom Forest </strong>是基于<strong class="jm hj">决策树</strong>的最佳机器学习算法之一。除了从包括自举和打包在内的集成方法中获益之外，随机森林还通过随机选择树特征(不使用所有特征)对树进行去相关来进一步降低方差。当正确使用时，该模型在减少方差方面取得了显著的改进，同时偏差的增加最小。</p><p id="fdb1" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">然而，当使用<strong class="jm hj">管道</strong>和<strong class="jm hj">grid search</strong>调整随机森林模型的超参数时，我们将模型变成了黑盒。事实上，对于数据科学家来说，理解超参数以及如何使用它们非常重要。在本周的帖子中，我们将研究随机森林算法的一些最常用的超参数，包括<em class="kw"> min_samples_leaf、min_samples_split、max_leaf_node、max _ featues、min _ infinity _ decrease、</em>和<em class="kw"> n_estimators </em>。</p><p id="7c67" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">请注意，调整超参数的最终目的是找到一个平衡偏差和方差的模型，使总误差最小(记住总误差=偏差+方差+不可约误差)。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kx"><img src="../Images/60ba4055cad687183533983e006bf02a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CqACMJ1lyUFpDCAO0u0M5w.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">Scott Fortmann-Roe 2012:了解偏差-方差权衡</figcaption></figure><p id="f9a5" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">数据</strong></p><p id="a4af" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">为了获得更多的见解，我使用两个不同大小的数据集进行调查。这两个数据集来自我的两个机器学习项目，它们已经被清理和预处理。</p><ol class=""><li id="5c96" class="lk ll hi jm b jn kr jr ks jv lm jz ln kd lo kh lp lq lr ls bi translated">小数据集:来自Kaggle竞赛的著名的Titanic训练数据集(<strong class="jm hj"> 889行x 9列</strong>)。</li><li id="1c8c" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">大型数据集:来自我的401k资格分类项目的匿名个人财务数据(<strong class="jm hj"> 32，561行x 81列</strong>)。</li></ol><p id="b88d" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">法</strong></p><p id="a14b" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">为了试验超参数，我通过使用GridSearchCV和5重交叉验证来拟合数据集，从而简化了建模过程。我使用平均训练和测试精度，GridSearchCV输出的AUC分数(即cv_results_ attribute)是用于评估模型的偏倚、方差和整体质量的指标。通过保持所有其他超参数不变，一次评估一个超参数。下面是GridSearchCV设置的示例代码:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es ly"><img src="../Images/83037730805363184e6d356b24d529c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IGneagrir0VlrzlleEC-Qg.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">随机森林的GridSearchCV</figcaption></figure><p id="0a4b" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">下面讨论了用于评估每个超参数的6个模型(即，2个数据集的6个参数)。对于模型1-5，<em class="kw"> n_estimators </em>被设置为200。</p><h1 id="6b1f" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">模型#1: min_samples_leaf </strong></h1><p id="20ee" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated"><em class="kw"> min_samples_leaf </em>是用于通过在叶节点中设置最小样本数以避免过拟合来正则化模型的参数。但是，模型默认值为1，这很可能会使您的模型过拟合，因此不推荐使用。</p><p id="1201" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">对于小数据集，超参数的测试范围是1-300。对于大型数据集，测试范围是1–3，000。请参见下面的ROC AUC和准确性得分。为了获得更好的比较结果，我在相同的尺度上绘制了两个数据集的分数。图中有4条线，由2种颜色(即绿色和蓝色)和2种图案(即虚线和实线)区分。实线周围的晕圈代表测试分数的标准差。</p><div class="ky kz la lb fd ab cb"><figure class="lz ij ma mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/069c8587d5aa73164689a767788e56ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*h-SJ4UdzLEKOY4MgEA67og.png"/></div></figure><figure class="lz ij mf mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/9d53a5cdbbdd086ab57fcb304d5fb561.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*JIZyELfpXG-kaOhiiWCSGA.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx mg di mh mi translated">左:小数据集|右:大数据集</figcaption></figure></div><p id="6f45" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">1号模型观察</strong>:</p><ol class=""><li id="c4b0" class="lk ll hi jm b jn kr jr ks jv lm jz ln kd lo kh lp lq lr ls bi translated">当样本数量较低时(即训练分数远高于测试分数)，这两个模型都过拟合，这是有意义的。叶子越小(样本越少)，树就越深(分区越多)，因此更有可能过度拟合。</li><li id="d0ec" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">对于小数据集，当min_samples_leaf介于35(当精度破折号和实线变得更近时)和150(在精度得分下降之前)之间时，模型的性能最佳。</li><li id="8184" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">对于大型数据集，总体方差要低得多(也有意义)，尤其是当min_samples_leaf设置为50以上时。下面的缩小图显示，准确度分数在400之后开始下降得更快。</li></ol><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mj"><img src="../Images/38c5df540073de3926c58819f0f73d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YR77HBPHFir_0OiNLd2a7Q.png"/></div></div></figure><p id="77b0" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">模型#1结论:</strong></p><p id="2ad3" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">min_samples_leaf 是我最喜欢的超参数之一，因为它更直观，也更容易使用。如果您不知道从哪里开始，设置一个从<strong class="jm hj"> 40 </strong>到<strong class="jm hj"> 150 </strong>的范围是一个相当好的起点。根据实际数据集的大小和质量进一步调整。</p><h1 id="cc2e" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">模型#2: min_samples_split </strong></h1><p id="5c93" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">分割内部节点所需的最小样本数。模型默认值为2，这通常会导致过度拟合。</p><p id="c0e0" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><em class="kw"> min_samples_split </em>的测试范围:</p><ol class=""><li id="06bf" class="lk ll hi jm b jn kr jr ks jv lm jz ln kd lo kh lp lq lr ls bi translated">小数据集:2 - 440</li><li id="5a7b" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">大型数据集:2 - 3，000</li></ol><div class="ky kz la lb fd ab cb"><figure class="lz ij mk mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/0bffb31b781e190bd9e47eaa0b083b27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*iF3t0fTAfvxeIsLOf9wXLA.png"/></div></figure><figure class="lz ij ml mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/917bd0a1d90f27f085fe7cca02961ab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*gZN08k_HLZc4GBiprGw99A.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx mg di mh mi translated">左:小数据集|右:大数据集</figcaption></figure></div><p id="e00b" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">2号模型观察结果</strong>:</p><ol class=""><li id="6baa" class="lk ll hi jm b jn kr jr ks jv lm jz ln kd lo kh lp lq lr ls bi translated">当<em class="kw"> min_samples_split的值较小时，两个模型都过拟合。</em></li><li id="7c48" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">对于小数据集，图中显示了一个有趣的模式。当<em class="kw"> min_samples_split </em>在50和250之间时，精度缓慢下降，然后回升并在400处达到峰值(约为数据的50%)。方差随着<em class="kw"> min_samples_split值的增加而减小。</em></li><li id="f873" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">对于大型数据集，最好的平衡是1，000或总样本的3%。</li></ol><p id="a240" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">2号模型结论</strong>:</p><p id="59a9" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">与<em class="kw"> min_samples_leaf </em>相比，<em class="kw"> min_samples_split </em>对我来说不够人性化。它不适合我的小数据集。当<em class="kw"> min_samples_split </em>设置为400时，每棵树都是一个<strong class="jm hj">弱学习器</strong>(只分裂一次)。<strong class="jm hj">随机森林</strong>(或随机树桩)<strong class="jm hj"> </strong>字面上变成了<strong class="jm hj"> Adaboost </strong>，不过，没有“boost”部分。我找不到一个好的理由来设定这么高的数字。</p><p id="3d6a" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">对于大型数据集，我建议将“3%”包括在您的调整范围内(即，您可以为该超参数输入整数或分数)。</p><h1 id="2508" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">模型#3:最大叶节点数</strong></h1><p id="6981" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated"><em class="kw"> max_leaf_nodes </em>限制模型中叶节点的数量。模型默认是无限制的，这显然会导致过拟合。</p><p id="23bc" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><em class="kw"> max_leaf_nodes </em>的测试范围:</p><ol class=""><li id="33dc" class="lk ll hi jm b jn kr jr ks jv lm jz ln kd lo kh lp lq lr ls bi translated">小数据集:2-200，</li><li id="2f0a" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">大型数据集:2–3，000</li></ol><div class="ky kz la lb fd ab cb"><figure class="lz ij mk mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/447697bd89b728ef36e2458a416318d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*SoNtlEMatTZseIWicCJ4Rg.png"/></div></figure><figure class="lz ij ml mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/0b21244e1c64542b367df3545e0967bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*ufN0oJtz6AcUQBMiL7cwmw.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx mg di mh mi translated">左:小数据集|右:大数据集</figcaption></figure></div><p id="7a32" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">3号模型观察</strong>:</p><ol class=""><li id="cc7c" class="lk ll hi jm b jn kr jr ks jv lm jz ln kd lo kh lp lq lr ls bi translated">当<em class="kw"> min_samples_split的值变大时，两个模型变得更加过度拟合。</em></li><li id="5dc7" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">对于小数据集，方差和偏差很难平衡。</li><li id="595f" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">对于大型数据集，这个超参数在10到100之间工作得很好(取决于训练和测试分数之间的差距的容差)。</li></ol><p id="1fcc" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">3号模型结论</strong>:</p><p id="daa5" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">基于以上结果，当数据集很小时，我会谨慎地调整这个超参数。对于大型数据集，10到100可能是一个合理的起点。</p><h1 id="e923" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">型号#4: max_features </strong></h1><p id="444a" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">寻找最佳分割时要考虑的特征数量。默认为<strong class="jm hj"> sqrt(特性数)</strong>。还有一个经验法则指导:</p><ol class=""><li id="f563" class="lk ll hi jm b jn kr jr ks jv lm jz ln kd lo kh lp lq lr ls bi translated">对于回归:最大特征数=特征数/ 3</li><li id="59b0" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">对于分类:max_features = sqrt(要素数)</li></ol><p id="6a7b" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">max_features的输入范围设置为特征总数的0.01到1(即1%到100%)。注意，这个超参数并没有调整树的深度。为了避免自动过度拟合，我将两个模型的min_samples_leaf设置为50。</p><div class="ky kz la lb fd ab cb"><figure class="lz ij mm mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/066a0124a6b1402687e8464439943d07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*ijMl5vlFN-HFl1_pkrcQXA.png"/></div></figure><figure class="lz ij mn mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/e826387d278bd43648088fcf9d8cc990.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*OAgzoKQVfeYvYfgYHDm8cA.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx mo di mp mi translated">左:小数据集|右:大数据集</figcaption></figure></div><p id="a29b" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">4号模型观察</strong>:</p><ol class=""><li id="f71a" class="lk ll hi jm b jn kr jr ks jv lm jz ln kd lo kh lp lq lr ls bi translated">对于小数据集，偏差和变化在测试范围内保持不变。</li><li id="f246" class="lk ll hi jm b jn lt jr lu jv lv jz lw kd lx kh lp lq lr ls bi translated">对于大数据集，准确性和AUC分数保持在0.1和0.9之间。在此范围内，方差略有增加。在0–0.1和0.9–1之间，分数急剧下降。</li></ol><p id="57e9" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">模型#4结论</strong>:</p><p id="33d5" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">由于测试范围内的分数变化很小，我认为只要遵循这个超参数的经验法则就可以了。</p><h1 id="b4d5" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">模型#5:最小杂质减少</h1><p id="792c" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">如果该分裂导致杂质减少大于或等于该值，则该节点将被分裂。模型默认值为0。</p><p id="b9d1" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">两个模型都在0.00005到0.04的范围内进行测试。</p><div class="ky kz la lb fd ab cb"><figure class="lz ij mq mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/bd76d885b9a9c55df2eb84a77a00def1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*GDDXxI7m2LPThQnMaoSrVw.png"/></div></figure><figure class="lz ij mr mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/68dbfbcfda8dfaabcadef85991d18863.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*qDKRj9tnNBBdMSVOrh09Eg.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx mo di mp mi translated">左:小数据集|右:大数据集</figcaption></figure></div><p id="196f" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">5号模型观察结果</strong>:</p><p id="18d5" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">大数据集模型的精度分数对这个超参数更加敏感。</p><p id="501b" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">5号模型结论</strong>:</p><p id="8945" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">基于上述结果，我将细化较小步骤的杂质减少范围，尤其是对于较大的数据集。对于少于1，000个条目的数据集，0.02可能是一个好的起点。</p><h1 id="c9b6" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">模型# 6:n _估计量</h1><p id="3513" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">树的数量。我最初没有评估这个超参数，因为经验法则是，它取决于你的计算能力。更多的树带来更好的结果。我在另一个论坛上看到一个讨论，说你应该使用sqrt(行数*列数)CPUs数)。</p><p id="a277" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">两种型号的测试范围都是50到500。同样，n_estimators没有调整树的深度，所以我使用了<em class="kw"> min_features_leaf </em> = 50的模型。</p><div class="ky kz la lb fd ab cb"><figure class="lz ij ms mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/fca04e664f3a6fb87eb9e40d0bc28c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*pcKg8HOlwrLjJk-UgcbvTg.png"/></div></figure><figure class="lz ij mt mb mc md me paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/965a2daff7eff8a69ae0b63ad31967bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*ay6W872ZT4Ho_ZMmlNWAUw.png"/></div></figure></div><p id="215c" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">6号模型观察</strong>:</p><p id="6682" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">这个超参数对两个模型的分数没有什么影响。</p><p id="f785" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated"><strong class="jm hj">6号模型结论</strong>:</p><p id="9902" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">除非你有额外的计算能力，否则我不会过多强调这个超参数。</p><h1 id="7adc" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">总体结论</h1><p id="4d9d" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在我的模型中，大数据集比小数据集得分更高。没有万能的解决方案。每个超参数的实际影响也取决于数据的数量和质量。还有一些我不常使用的超参数，所以我不在这篇文章中讨论。希望下面的推荐能给你一个有价值的起点。和往常一样，请在评论区分享你的经验和建议。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mu"><img src="../Images/fe36eaf1b30eaff1bb18df5d571d354b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*egr9WB_weFSTIvqGc31f0w.png"/></div></div></figure><p id="0bca" class="pw-post-body-paragraph jk jl hi jm b jn kr jp jq jr ks jt ju jv kt jx jy jz ku kb kc kd kv kf kg kh hb bi translated">旁注:我的朋友帕特里克对NBA球员相对于选秀身份的价值进行了一次非常有趣的分析。如果你是一个篮球迷(并且玩梦幻游戏)，这将是一个无价的7分钟阅读(<a class="ae mv" href="https://towardsdatascience.com/when-to-give-up-117e2e2acdc9" rel="noopener" target="_blank">https://towardsdatascience.com/when-to-give-up-117e2e2acdc9</a>)。</p></div></div>    
</body>
</html>