<html>
<head>
<title>What should I use to validate classification models? Here are a few methods!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我应该用什么来验证分类模型？下面介绍几种方法！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/quick-model-validation-metrics-classification-e6e63fbf9aec?source=collection_archive---------44-----------------------#2020-05-03">https://medium.com/analytics-vidhya/quick-model-validation-metrics-classification-e6e63fbf9aec?source=collection_archive---------44-----------------------#2020-05-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2a8b0d814f7fa741e6a707b63bec79ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UUpKAs2o6PvSDvxs"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Daria Nepriakhina 在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="85d5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">精度</strong> —被归类为真的数据点的比例实际上是真的。也可以理解为“预测项有多少是相关的”。</p><p id="ab00" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> TP/(TP+FP)。</strong></p><p id="af08" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">特异性</strong> —实际为假的预测假值的比例。这也叫做<strong class="ix hj">【TNR】</strong><strong class="ix hj">【TN/(TN+FP)</strong></p><p id="7a29" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">准确性</strong> —这是预测为正确值的值的比例。这不一定是确定模型预测能力的最佳方法，因为它取决于目标变量中真值和假值的平衡。如果正面数量多于负面数量，模型将预测更高的正面数量，反之亦然。反过来，这将增加模型精度，而这不适合捕捉模型的能力。</p><p id="4340" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">回忆/TPR/敏感度</strong> —模型在分类中找到正确数据点的能力。也可以理解为“选择多少个相关项”。</p><p id="adec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> TP/(TP+FN) </strong></p><p id="aeec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">模型找出感兴趣的数据点的能力。如果我们提高精确度，我们就会降低回忆。需要在它们之间进行权衡。如果你的模型有一个1的回忆，这是没有必要的，因为在某些情况下，它会识别实际上是假的真实值，这对于用例是不好的。</p><p id="64d7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">F1——得分</strong> —这是精确度和召回率的混合，计算为两个值的调和平均值。以下公式适用— <strong class="ix hj"> F1 = 2*(精度*召回)/(精度+召回)</strong></p><p id="e50c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这种情况下，数值中的任何异常都将导致F1值降低，这将表明模型存在问题。一个平衡的模型会有更高的F1值。</p><p id="7b14" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">混淆矩阵</strong> —它显示矩阵表示中的真阳性、假阳性、真阴性和假阴性的数量，实际值与预测的标签相对比。这用于计算多个指标，如准确度、精确度、召回率(TPR)和特异性(TNR)。</p><p id="b4b2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> ROC —接收器工作特性</strong>这个想法是为了显示当我们改变阈值时精度关系的变化&amp;。阈值是一个值，用于判断预测是真还是假。ROC曲线可用于找出精确度和召回率之间的适当平衡。ROC曲线的轴线是y轴上的<strong class="ix hj">TPR</strong>和x轴上的<strong class="ix hj">FPR</strong>。随着我们提高阈值，我们倾向于降低找到真正阳性的可能性。这里，</p><p id="e939" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> TPR(召回/灵敏度)= TP / (TP+FN) </strong></p><p id="23e0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">FPR = 1-特异性或1-TNR = FP/(FP+TN) </strong></p><p id="8c4c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">随着我们降低阈值，我们开始找到真正的阳性，在某个点上，我们可以确定阈值的正确值，该值在精确度和召回率之间提供了正确的平衡。当我们提高阈值时，我们会提高召回率，因为我们会识别更多的真值，但是，这意味着我们会降低精确度，因为我们可能会将假值识别为真值。为了量化，我们计算<strong class="ix hj"> AUC，曲线下面积，</strong>，其基本上给出了关于模型在识别真/假方面有多好的信息。<strong class="ix hj">较高的值通常意味着好的模型。</strong>然而，一个真正高的值~ 0.9–1也可能意味着存在潜在的过度拟合，并且需要重新检查该过程以发现任何问题。</p></div></div>    
</body>
</html>