<html>
<head>
<title>PyTorch For Deep Learning — Convolutional Neural Networks ( Fashion-MNIST )</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习PyTorch卷积神经网络(时尚-MNIST)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/pytorch-for-deep-learning-convolutional-neural-networks-fashion-mnist-f7bff7b4e724?source=collection_archive---------1-----------------------#2020-09-15">https://medium.com/analytics-vidhya/pytorch-for-deep-learning-convolutional-neural-networks-fashion-mnist-f7bff7b4e724?source=collection_archive---------1-----------------------#2020-09-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/891e4e0765e685f20a60c89a94123a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GHhfWjp-YdsnHJkaux9l2Q.jpeg"/></div></div></figure><h1 id="89fb" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">时尚MNIST</h1><p id="a2e3" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">时尚Mnist是Zolando Fashion Wear创建的一个数据集，用来代替原来的Mnist，同时增加难度。这篇博文讲述了如何创建一个模型来预测时尚mnist图像，并展示了如何在网络中实现卷积层</p><p id="d36a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">让我们看看代码</p><ol class=""><li id="baac" class="kr ks hi jq b jr km jv kn jz kt kd ku kh kv kl kw kx ky kz bi translated"><strong class="jq hj">导入库</strong></li></ol><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="f96e" class="lj ir hi lf b fi lk ll l lm ln">#importing the libraries</span><span id="3aae" class="lj ir hi lf b fi lo ll l lm ln">import torch<br/>import torchvision<br/>import torchvision.transforms as transforms<br/>import matplotlib.pyplot as plt<br/>import numpy as np</span></pre><p id="abc9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">2.<strong class="jq hj">导入数据</strong></p><p id="ad61" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">Pytorch的torchvision包含用于实践的内置数据集，如MNIST、FashionMnist等</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="6faf" class="lj ir hi lf b fi lk ll l lm ln">#datatset</span><span id="ef8d" class="lj ir hi lf b fi lo ll l lm ln">train_set = torchvision.datasets.FashionMNIST(<br/>root = './data/FashionMNIST',<br/>download = True,<br/>train = True,<br/>transform = transforms.Compose([<br/>transforms.ToTensor(),<br/>])<br/>)</span><span id="ea0d" class="lj ir hi lf b fi lo ll l lm ln">test_set = torchvision.datasets.FashionMNIST(<br/>root = './data/FashionMNIST',<br/>download=True,<br/>train=False,<br/>transform = transforms.Compose([transforms.ToTensor()])<br/>)</span></pre><p id="20ee" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">作为预处理的一部分，需要在输入图像上完成的变换列表可以使用transforms.compose实现</p><p id="6c14" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 3。数据加载器</strong></p><p id="6183" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">pytorch中的Dataset类基本上覆盖了一个元组中的数据，并使我们能够访问每个数据的索引。这对于创建可用于混洗、应用小批量梯度下降等的dataloader类是必要的</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="a039" class="lj ir hi lf b fi lk ll l lm ln">#data loader</span><span id="405d" class="lj ir hi lf b fi lo ll l lm ln">train_loader = torch.utils.data.DataLoader(train_set,batch_size=20)<br/>test_loader = torch.utils.data.DataLoader(test_set,batch_size=60000)</span><span id="ba50" class="lj ir hi lf b fi lo ll l lm ln">images, labels = next(iter(train_loader))</span><span id="7208" class="lj ir hi lf b fi lo ll l lm ln">#used to create a grid of images<br/>grid = torchvision.utils.make_grid(images,nrow=20)<br/>plt.figure(figsize=(15,15))<br/>plt.imshow(np.transpose(grid,(1,2,0)),cmap='gray')</span></pre><p id="949c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 4。卷积神经网络</strong></p><p id="47f2" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">具有卷积层的神经网络称为卷积神经网络。这篇博文并没有涉及卷积神经网络是什么的理论。这仅适用于PyTorch实现。</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="8bb6" class="lj ir hi lf b fi lk ll l lm ln">import torch.nn as nn<br/>import torch.nn.functional as F</span><span id="cc38" class="lj ir hi lf b fi lo ll l lm ln"><br/>class Network(nn.Module):<br/>  def __init__(self):<br/>    super(Network,self).__init__()<br/>    self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)</span><span id="8907" class="lj ir hi lf b fi lo ll l lm ln">    self.conv2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)</span><span id="f6e9" class="lj ir hi lf b fi lo ll l lm ln">    self.fc1 = nn.Linear(in_features=12*4*4,out_features=120)</span><span id="bad1" class="lj ir hi lf b fi lo ll l lm ln">    self.fc2 = nn.Linear(in_features=120,out_features=60)</span><span id="0142" class="lj ir hi lf b fi lo ll l lm ln">    self.fc3 = nn.Linear(in_features=60,out_features=40)</span><span id="c936" class="lj ir hi lf b fi lo ll l lm ln">    self.out = nn.Linear(in_features=40,out_features=10)</span><span id="274b" class="lj ir hi lf b fi lo ll l lm ln">  def forward(self,x):</span><span id="75b3" class="lj ir hi lf b fi lo ll l lm ln">    #input layer<br/>    x = x</span><span id="e3f4" class="lj ir hi lf b fi lo ll l lm ln">    #first hidden layer<br/>    x = self.conv1(x)<br/>    x = F.relu(x)<br/>    x = F.max_pool2d(x,kernel_size=2,stride=2)</span><span id="4733" class="lj ir hi lf b fi lo ll l lm ln">    #second hidden layer<br/>    x = self.conv2(x)<br/>    x = F.relu(x)<br/>    x = F.max_pool2d(x,kernel_size=2,stride=2)</span><span id="eaad" class="lj ir hi lf b fi lo ll l lm ln">    #third hidden layer<br/>    x = x.reshape(-1,12*4*4)<br/>    x = self.fc1(x)<br/>    x = F.relu(x)</span><span id="fda4" class="lj ir hi lf b fi lo ll l lm ln">    #fourth hidden layer<br/>    x = self.fc2(x)<br/>    x = F.relu(x)</span><span id="a233" class="lj ir hi lf b fi lo ll l lm ln">    #fifth hidden layer<br/>    x = self.fc3(x)<br/>    x = F.relu(x)</span><span id="e055" class="lj ir hi lf b fi lo ll l lm ln">    #output layer<br/>    x = self.out(x)<br/>    return x</span></pre><p id="1b4b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">借助nn.conv2d层，可以在pytorch中实现卷积神经网络</p><p id="9a99" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 5。参数调谐</strong></p><p id="78b8" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">选择各种参数，如时期数、损失函数、学习率等</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="fcd1" class="lj ir hi lf b fi lk ll l lm ln">#defining few parameters</span><span id="6ae5" class="lj ir hi lf b fi lo ll l lm ln">model = Network()<br/>learning_rate = 0.005<br/>optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)<br/>criterion = nn.CrossEntropyLoss()<br/>epochs = 15</span></pre><p id="fc7b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 6。培训</strong></p><p id="8c64" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">从损失函数中找到的梯度被用于改变权重值，并且该过程被重复几次。<br/>这样做是为了最小化损失函数并提高精度</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="907d" class="lj ir hi lf b fi lk ll l lm ln">#training loop<br/>losses = []<br/>for i in range(epochs):<br/>  for j,(images,targets) in enumerate(train_loader):<br/>    <br/>    #making predictions<br/>    y_pred = model(images)<br/>  <br/>    #calculating loss<br/>    loss = criterion(y_pred,targets.reshape(-1))</span><span id="795f" class="lj ir hi lf b fi lo ll l lm ln">    #backprop<br/>    optimizer.zero_grad()<br/>    loss.backward()<br/>    optimizer.step()</span><span id="e6fd" class="lj ir hi lf b fi lo ll l lm ln">  if i&gt;10:<br/>    optimizer.lr = 0.0005</span><span id="bc19" class="lj ir hi lf b fi lo ll l lm ln">  print(loss)<br/>  losses.append(loss)</span><span id="5422" class="lj ir hi lf b fi lo ll l lm ln"><strong class="lf hj">Output: <br/></strong>tensor(0.9046, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.6423, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.5484, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.4991, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.4591, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.4245, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.4117, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.3995, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.3803, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.3726, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.3416, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.3100, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.3024, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.2911, grad_fn=&lt;NllLossBackward&gt;) <br/>tensor(0.2829, grad_fn=&lt;NllLossBackward&gt;)</span></pre><p id="cfb9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 7。模型性能分析</strong></p><p id="3c48" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">该模型在测试集上的准确率为:86.04%</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="ccff" class="lj ir hi lf b fi lk ll l lm ln">#accuracy of the model</span><span id="4169" class="lj ir hi lf b fi lo ll l lm ln">x_test,y_test = next(iter(test_loader))<br/>y_pred = (model(x_test).argmax(dim=1))</span><span id="2421" class="lj ir hi lf b fi lo ll l lm ln">print("Accuracy is : ",(y_pred.eq(y_test).sum()/10000.).item()*100,"%")</span><span id="b3a5" class="lj ir hi lf b fi lo ll l lm ln"><strong class="lf hj">output:</strong> <br/>Accuracy is :  86.04000210762024 %</span></pre><p id="b8fe" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 8。绘图</strong></p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="9f98" class="lj ir hi lf b fi lk ll l lm ln">#plotting loss</span><span id="64a4" class="lj ir hi lf b fi lo ll l lm ln">plt.plot(losses)<br/>plt.xlabel('epochs')<br/>plt.ylabel('loss')</span></pre><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/20353767569bac1135efe8c0f1b8b57b.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*Nol1Z1SagRTatIXL08qXfQ.png"/></div></figure><p id="7a09" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 9。从测试集进行随机预测</strong></p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="733a" class="lj ir hi lf b fi lk ll l lm ln">#random prediction</span><span id="8062" class="lj ir hi lf b fi lo ll l lm ln">import random<br/>rand_no = random.randint(0,10000)</span><span id="d5cb" class="lj ir hi lf b fi lo ll l lm ln">order_list = "T-shirt/Top Trouser PullOver Dress Coat Sandal Shirt Sneaker Bag AnkleBoot".split()</span><span id="4f9c" class="lj ir hi lf b fi lo ll l lm ln">plt.imshow(x_test[rand_no].reshape(28,28),cmap='gray')<br/>pred = model(x_test[rand_no].reshape(-1,1,28,28)).argmax()<br/>print("This is a/an {}".format(order_list[pred]))</span><span id="6dbf" class="lj ir hi lf b fi lo ll l lm ln"><strong class="lf hj">output: </strong></span><span id="b338" class="lj ir hi lf b fi lo ll l lm ln">This is a/an Trouser</span></pre><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/5e900b3998c50d2f990e1340a46fa867.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*YJzhmmCwZaKtei268XeqTw.png"/></div></figure><h1 id="24d6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">结论</strong></h1><p id="9869" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在测试集上，该模型的准确率为86%。这证明了卷积网络在预测图像方面有多强。这是因为卷积层的参数共享能力和边缘检测能力。</p><h1 id="8c10" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">谢谢你</h1></div></div>    
</body>
</html>