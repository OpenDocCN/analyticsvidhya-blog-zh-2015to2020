<html>
<head>
<title>Easily Implement Different TransformersğŸ¤—ğŸ¤— through Hugging Face</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">è½»æ¾å®ç°ä¸åŒçš„å˜å‹å™¨ğŸ¤—ğŸ¤—é€šè¿‡æ‹¥æŠ±è„¸</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/analytics-vidhya/easily-implement-different-transformers-through-hugging-face-e471035e9c86?source=collection_archive---------10-----------------------#2020-06-28">https://medium.com/analytics-vidhya/easily-implement-different-transformers-through-hugging-face-e471035e9c86?source=collection_archive---------10-----------------------#2020-06-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="1d47" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">å˜å½¢é‡‘åˆšæ˜¯æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå·²ç»è¢«ç”¨äºä»¥éå¸¸æœ‰æ•ˆçš„æ–¹å¼è§£å†³ä»æƒ…æ„Ÿåˆ†æåˆ°é—®é¢˜/å›ç­”çš„æ–°é¢–çš„NLPä»»åŠ¡ã€‚ç„¶è€Œï¼Œå˜å½¢é‡‘åˆšæœ€åŸºæœ¬çš„åŠŸèƒ½åªæ˜¯æ³¨æ„åŠ›æœºåˆ¶çš„ç¼–ç å™¨å±‚çš„å †å ã€‚å³ä½¿ä½¿ç”¨Pytorchæˆ–Tensorflowä¹‹ç±»çš„DLæ¡†æ¶ï¼Œä»å¤´å®ç°å®ƒä¹Ÿæ˜¯ç›¸å½“å›°éš¾å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚ç„¶è€Œæ‹¥æŠ±è„¸ä½¿å¾—å®ç°å„ç§ç±»å‹çš„å˜å½¢é‡‘åˆšå˜å¾—éå¸¸å®¹æ˜“ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•é€šè¿‡æ‹¥æŠ±äººè„¸åº“åœ¨Tensorflow(Keras)ä¸­è½»æ¾å®ç°å˜å½¢é‡‘åˆšã€‚</p></blockquote></div><div class="ab cl jh ji gp jj" role="separator"><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm"/></div><div class="hb hc hd he hf"><h1 id="d4f9" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">ä½ éœ€è¦ä»€ä¹ˆ:</strong></h1><p id="1b1f" class="pw-post-body-paragraph ii ij hi il b im km io ip iq kn is it ko kp iw ix kq kr ja jb ks kt je jf jg hb bi translated">é¦–å…ˆä½ éœ€è¦å®‰è£…æ‹¥æŠ±è„¸åº“ï¼Œè¿™çœŸçš„å¾ˆå®¹æ˜“ã€‚åªéœ€ç®€å•åœ°å®‰è£…å®ƒ:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="2407" class="ld jp hi kz b fi le lf l lg lh">pip install transformers </span></pre><p id="1f1e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">å…¶æ¬¡ï¼Œæ‚¨å°†éœ€è¦æœ€æ–°çš„TensorFlowç‰ˆæœ¬ï¼Œè¯¥ç‰ˆæœ¬ä¹Ÿå¯ä»¥é€šè¿‡pipè½»æ¾å®‰è£…ã€‚</p><p id="a49d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated"><strong class="il hj">æ•°æ®:</strong></p><p id="991f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">ä¸ºäº†æµ‹è¯•å’Œå®ç°ä¸åŒçš„è½¬æ¢å™¨ï¼Œæˆ‘ä½¿ç”¨äº†kaggleç«èµ›ä¸­çš„æ•°æ®ã€‚è¿™æ˜¯æœ€è¿‘çš„ä¸€ä¸ªæ¯”èµ›ï¼Œæˆ‘å‚åŠ äº†ä¸€ä¸ªåä¸º<a class="ae li" href="https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification" rel="noopener ugc nofollow" target="_blank">æ‹¼å›¾-å¤šè¯­è¨€-æœ‰æ¯’-è¯„è®º-åˆ†ç±»</a>çš„æ¯”èµ›ã€‚ä½†æ˜¯ï¼Œä½¿ç”¨ç›¸åŒçš„æ•°æ®å¹¶ä¸æ˜¯å¼ºåˆ¶æ€§çš„ï¼Œå› ä¸ºä¸‹é¢çš„å®ç°å¯ä»¥å¾ˆå®¹æ˜“åœ°é€‚åº”ä»»ä½•æ–‡æœ¬æ•°æ®ã€‚</p><p id="46c4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">è¿™åœºæ¯”èµ›ç»™å‡ºäº†ä¸åŒçš„è¯„è®ºï¼Œæˆ‘ä»¬çš„ä»»åŠ¡æ˜¯æ£€æµ‹ç‰¹å®šçš„è¯„è®ºæ˜¯å¦æœ‰æ¯’ã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ªäºŒå…ƒåˆ†ç±»ä»»åŠ¡ã€‚</p><p id="33db" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated"><strong class="il hj">å¼ºå¤§è®¡ç®—èƒ½åŠ›:</strong></p><p id="300e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">è¿˜è¦æ³¨æ„ï¼Œå˜å‹å™¨æœ‰æ•°ç™¾ä¸‡ä¸ªå‚æ•°ï¼Œå› æ­¤æˆ‘åˆ©ç”¨Kaggleå†…æ ¸æä¾›çš„TPUæ¥è®­ç»ƒæˆ‘çš„æ¨¡å‹ã€‚æˆ–è€…ï¼Œå¦‚æœæ‚¨æ²¡æœ‰å¼ºå¤§çš„æœ¬åœ°æœºå™¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨google colabæ¥è·Ÿè¸ªæœ¬æ–‡çš„å®ç°ã€‚</p></div><div class="ab cl jh ji gp jj" role="separator"><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm"/></div><div class="hb hc hd he hf"><h1 id="bdac" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">è®©æˆ‘ä»¬äº«å—å®ç°å˜å½¢é‡‘åˆšçš„ä¹è¶£:</strong></h1><figure class="ku kv kw kx fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lj"><img src="../Images/9cc09362cda60ea8bdcf31fe063246b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sQQ9KJMud6uGsv82XNU3TA.png"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">å›¾ç‰‡æ¥è‡ª<a class="ae li" href="https://huggingface.co/front/thumbnails/models.png" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/front/thumbnails/models.png</a></figcaption></figure><p id="ecbc" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated"><strong class="il hj">è¿›å£</strong></p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="1b1d" class="ld jp hi kz b fi le lf l lg lh">import numpy as np <em class="ik"># linear algebra</em><br/>import pandas as pd <em class="ik"># data processing, CSV file I/O (e.g. pd.read_csv)</em><br/>import tensorflow as tf<br/>import tensorflow_hub as hub<br/>from tqdm import tqdm<br/>from tqdm import tqdm_notebook<br/>from sklearn.metrics import auc<br/>from sklearn.metrics import classification_report<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/><br/>from transformers import AutoTokenizer,BertTokenizer,TFBertModel,TFOpenAIGPTModel,OpenAIGPTTokenizer,DistilBertTokenizer, TFDistilBertModel,XLMTokenizer, TFXLMModel<br/>from transformers import TFAutoModel, AutoTokenizer<br/>from kaggle_datasets import KaggleDatasets<br/>from sklearn.metrics import roc_curve,confusion_matrix,auc<br/>from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors<br/><em class="ik"># Input data files are available in the read-only "../input/" directory</em><br/><em class="ik"># For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory</em><br/>import matplotlib as mpl<br/><br/><br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.metrics import confusion_matrix, accuracy_score<br/>from sklearn.model_selection import train_test_split<br/><br/>from tensorflow.keras.preprocessing.text import Tokenizer<br/>from tensorflow.keras.preprocessing.sequence import pad_sequences<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import *<br/>from tensorflow.keras.initializers import Constant</span></pre><p id="c26f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated"><strong class="il hj">å“ªäº›å˜å‹å™¨:</strong></p><p id="3409" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">ä»¥ä¸‹å˜å‹å™¨æ¶æ„å·²åœ¨ç¬”è®°æœ¬ç”µè„‘ä¸­è¿›è¡Œäº†æµ‹è¯•</p><p id="e03c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">1-ä¼¯ç‰¹</p><p id="cc81" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">2-OpenAIGPT</p><p id="952b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">3-è’¸é¦å•¤é…’</p><p id="0af8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">4-XLM</p><p id="51f5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">5-xlmrobertalage</p><p id="1380" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">ä¸ç”¨æ‹…å¿ƒæ‰€æœ‰è¿™äº›å˜å½¢é‡‘åˆšçš„å®ç°ã€‚å®ç°ç®€å•ä¸”ç›¸ä¼¼ã€‚</p><p id="933f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated"><strong class="il hj">ä½¿ç”¨çš„è¶…å‚æ•°:</strong></p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="24ed" class="ld jp hi kz b fi le lf l lg lh">EPOCHS=2</span><span id="8de1" class="ld jp hi kz b fi lv lf l lg lh">max_seq_length = 192<br/>LEARNING_RATE=1e-5<br/>early_stopping=early_stopping = tf.keras.callbacks.EarlyStopping(<br/>    monitor='val_loss', <br/>    verbose=1,<br/>    patience=10,<br/>    mode='max',<br/>    restore_best_weights=True)</span></pre><p id="5c8b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated"><strong class="il hj">ç¼–ç åŠŸèƒ½:</strong></p><p id="d5de" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">æ¯ä¸€ä¸ªå˜å½¢é‡‘åˆšéƒ½å¯¹æ¯ä¸€å¥è¯è¿›è¡Œç¼–ç ã€‚æˆ‘å¸Œæœ›ä½ èƒ½ç†è§£è¿™å¥è¯çš„å«ä¹‰ã€‚å¦‚æœæ²¡æœ‰ï¼Œé‚£ä¹ˆä»–ä»¬åœ¨äº’è”ç½‘ä¸Šæœ‰è®¸å¤šäº†è§£ç¼–ç çš„å¥½èµ„æºã€‚åœ¨ä¸€ä¸ªéå¸¸åŸºæœ¬çš„å±‚é¢ä¸Šï¼Œç¼–ç æ„å‘³ç€é€šè¿‡ä¸ºæˆ‘ä»¬è¯­æ–™åº“ä¸­çš„æ¯ä¸ªå•è¯(æ ‡è®°)åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ•´æ•°æ¥å°†åŸå§‹æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºæ•°å­—æ•°æ®ã€‚ç„¶è€Œï¼Œtransformerç¼–ç ç¨å¾®å¤æ‚ä¸€ç‚¹ï¼Œå› ä¸ºå®ƒä¹Ÿä½¿ç”¨å­—ç¬¦çº§ç¼–ç ï¼Œå°†æœªçŸ¥å•è¯åˆ†è§£æˆå•ä¸ªå­—ç¬¦ï¼Œç„¶åè¿›è¡Œç¼–ç ã€‚ç„¶è€Œï¼Œæˆ‘ä¸ä¼šè¿›ä¸€æ­¥æ·±å…¥å˜å‹å™¨ç¼–ç å¦‚ä½•å·¥ä½œçš„ç»†èŠ‚ï¼Œå› ä¸ºå®ƒç›¸å½“è¯¦ç»†ã€‚å¯ä»¥è‚¯å®šåœ°è¯´ï¼Œä¸‹ä¸€ä¸ªå‡½æ•°åŸºæœ¬ä¸Šå°†æ•°æ®ä¸­çš„æ¯ä¸ªå¥å­è½¬æ¢æˆå„ç§è½¬æ¢å™¨å¯ä»¥ç†è§£çš„ç‰¹æ®Šæ•´æ•°åˆ—è¡¨:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="7336" class="ld jp hi kz b fi le lf l lg lh">def single_encoding_function(text,tokenizer,name='BERT'):<br/>    input_ids=[]<br/>    if name=='BERT':<br/>        tokenizer.pad_token ='[PAD]'<br/>    elif name=='OPENAIGPT2':<br/>        tokenizer.pad_token='&lt;unk&gt;'<br/>    elif name=='Transformer XL':<br/>        print(tokenizer.eos_token)<br/>        tokenizer.pad_token= tokenizer.eos_token<br/>    elif name=='DistilBert':<br/>        tokenizer.pad_token='[PAD]'<br/>    <br/>for sentence <strong class="kz hj">in</strong> tqdm(text):       encoded=tokenizer.encode(sentence,max_length=max_seq_length,<br/>pad_to_aax_length=True)## this is inside the loop<br/>        input_ids.append(encoded)<br/>    return input_ids</span></pre><p id="caca" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated"><strong class="il hj">åˆ¶ä½œæ•°æ®ç®¡é“:</strong></p><p id="b981" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">a)åˆ¶ä½œé˜µåˆ—:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="5e6b" class="ld jp hi kz b fi le lf l lg lh">X_train=np.array(single_encoding_function(train_raw['comment_text'].values.tolist(),tokenizer,name="BERT"))<br/>y_train=np.array(train_raw['toxic'])<br/>X_valid=np.array(single_encoding_function(valid_raw['comment_text'].values.tolist(),tokenizer,name="BERT"))<br/>y_valid=np.array(valid_raw['toxic'])<br/>X_test=np.array(single_encoding_function(test_raw['content'].values.tolist(),tokenizer,name="BERT"))</span><span id="1343" class="ld jp hi kz b fi lv lf l lg lh">steps_per_epoch = X_train.shape[0] // BATCH_SIZE</span></pre><p id="437f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">ä¸Šé¢çš„ä»£ç æ˜¯ä¸è¨€è‡ªæ˜çš„ï¼Œæˆ‘åªæ˜¯å°†åŸå§‹æ–‡æœ¬æ•°æ®ä½œä¸ºè¾“å…¥æä¾›ç»™å•ä¸ªç¼–ç å‡½æ•°ï¼Œç„¶åå°†ç»“æœè½¬æ¢ä¸ºç¼–ç ä»¤ç‰Œçš„æ•°ç»„ï¼Œè¿™æ˜¯æä¾›ç»™TensorFlowç®¡é“çš„æœ€ç»ˆæ•°æ®ã€‚</p><p id="97e0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">b)åˆ¶ä½œå¼ é‡æµç®¡é“:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="82db" class="ld jp hi kz b fi le lf l lg lh">def make_data():<br/>    train = (<br/>        tf.data.Dataset<br/>        .from_tensor_slices((X_train, y_train))<br/>        .repeat()<br/>        .shuffle(2048)<br/>        .batch(BATCH_SIZE)<br/>        .prefetch(AUTO))<br/><br/>    valid = (<br/>        tf.data.Dataset<br/>        .from_tensor_slices((X_valid, y_valid))<br/>        .batch(BATCH_SIZE)<br/>        .cache()<br/>        .prefetch(AUTO)<br/>    )<br/><br/>    test = (<br/>        tf.data.Dataset<br/>        .from_tensor_slices(X_test)<br/>        .batch(BATCH_SIZE)<br/>    )<br/>    return train,valid,test </span></pre><p id="b903" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated"><strong class="il hj">ä¸Kerasçš„å®é™…å®æ–½:</strong></p><p id="7de8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">ä¸‹ä¸€æ­¥çœŸçš„å¾ˆé‡è¦ï¼Œæ‰€ä»¥ä»”ç»†çœ‹çœ‹:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="a871" class="ld jp hi kz b fi le lf l lg lh">def build_model(transformer_layer,max_len=max_seq_length):<br/>    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name="input_word_ids")<br/>    sequence_output = transformer_layer(input_word_ids)[0]<br/>    <br/>    cls_token = sequence_output[:, 0, :]<br/>    out = tf.keras.layers.Dense(1, activation='sigmoid')(cls_token)<br/>    <br/>    model = tf.keras.Model(inputs=input_word_ids, outputs=out)<br/>    <br/>    <br/>    return model</span></pre><p id="c5f4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">ä»£ç å—å¾ˆé‡è¦ï¼Œå› æ­¤è®©æˆ‘è¿›ä¸€æ­¥é˜è¿°å®ƒã€‚é¦–å…ˆæœ‰ä¸€ä¸ªè¾“å…¥å±‚ï¼Œå®ƒä¸ºä¸€ä¸ªç‰¹å®šçš„å®ä¾‹æ¥å—ç»™å®šå˜æ¢å™¨çš„<strong class="il hj">ç¼–ç è¾“å…¥ã€‚ç„¶åï¼Œè¾“å…¥ä»¤ç‰Œè¢«è¾“å…¥åˆ°ä¸»transformerå±‚(ä»å³å°†åˆ°æ¥çš„ä»£ç å—ä¸­å®šä¹‰çš„åä¸ºcompile_modelçš„å‡½æ•°ä¸­åŠ è½½)ã€‚æˆ‘æƒ³è®©è¿™äº›ä»£ç å¯¹æ‰€æœ‰çš„å˜å½¢é‡‘åˆšéƒ½æ˜¯å¯é‡ç”¨çš„ï¼Œå› æ­¤ä¸æ˜¯å¤åˆ¶å’Œç²˜è´´æ¯ä¸ªå˜å½¢é‡‘åˆšçš„æ•´ä¸ªæ¨¡å‹ï¼Œå”¯ä¸€ä¸åŒçš„å±‚æ˜¯å˜å½¢é‡‘åˆšçš„å˜å½¢é‡‘åˆšå±‚ã€‚ç„¶åï¼Œè½¬æ¢å™¨å±‚è¾“å‡ºåºåˆ—è¾“å‡ºã€‚ç„¶è€Œï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œå› æ­¤ä»åºåˆ—è¾“å‡ºä¸­ï¼Œæˆ‘ä»¬å°†åªæå–ç»™å®šå¥å­ä¸­æ¯ä¸ªå•è¯çš„CLS(åˆ†ç±»æ ‡è®°)ã€‚è¿™ä¸ªcls_tokenç„¶åè¢«é¦ˆé€åˆ°ç”¨äºåŒºåˆ†ç»™å®šå¥å­çš„æ¯’æ€§çš„sigmoidå±‚ã€‚</strong></p><p id="3c23" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥é€šè¿‡æ·»åŠ æ›´å¤šçš„å±‚æ¥ä½¿æ¨¡å‹æ›´åŠ å¤æ‚ï¼Œä½†æˆ‘æ²¡æœ‰è¿™æ ·åšï¼Œå› ä¸ºè¿™ä¼šä½¿æˆ‘ä»¬çš„æ¨¡å‹æ›´åŠ å¤æ‚ï¼Œå¹¶ä¸”ä¼šèŠ±è´¹æ›´å¤šçš„è®­ç»ƒæ—¶é—´ã€‚</p><h2 id="89bf" class="ld jp hi bd jq lw lx ly ju lz ma mb jy ko mc md kc kq me mf kg ks mg mh kk mi bi translated"><strong class="ak">ä¸‹ä¸€èŠ‚ä»…å±•ç¤ºå¦‚ä½•ç»˜åˆ¶å„å˜å‹å™¨æ€§èƒ½çš„ç›¸å…³æœ‰ç”¨å›¾è¡¨ï¼Œä»¥ä¾¿å¯¹ä¸åŒæ¨¡å‹è¿›è¡Œå¯¹æ¯”åˆ†æã€‚å®ƒä»¬ä¸ä»»ä½•è½¬æ¢å™¨çš„ä¸»è¦å®ç°éƒ½æœ‰å…³ç³»ã€‚</strong></h2><p id="27f8" class="pw-post-body-paragraph ii ij hi il b im km io ip iq kn is it ko kp iw ix kq kr ja jb ks kt je jf jg hb bi translated"><strong class="il hj">ç»˜åˆ¶æœ‰ç”¨çš„å›¾è¡¨æ¥æ¯”è¾ƒæ€§èƒ½:</strong></p><p id="0b1e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">a)ç»˜åˆ¶æŸè€—å’Œåº¦é‡å›¾:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="d90c" class="ld jp hi kz b fi le lf l lg lh">mpl.rcParams['figure.figsize'] = (12, 10)<br/>colors = plt.rcParams['axes.prop_cycle'].by_key()['color']<br/><br/>def plot_loss(history):<br/><em class="ik"># Use a log scale to show the wide range of values.</em><br/>    plt.semilogy(history.epoch,  history.history['loss'],<br/>               color='red', label='Train Loss')<br/>    plt.semilogy(history.epoch,  history.history['val_loss'],<br/>          color='green', label='Val Loss',<br/>          linestyle="--")<br/>    plt.xlabel('Epoch')<br/>    plt.ylabel('Loss')<br/>  <br/>    plt.legend()<br/>    <br/>    <br/>def plot_metrics(history):<br/>    metrics =  ['loss', 'auc', 'precision', 'recall']<br/>    for n, metric <strong class="kz hj">in</strong> enumerate(metrics):<br/>        name = metric.replace("_"," ").capitalize()<br/>        plt.subplot(2,2,n+1)<br/>        plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')<br/>        plt.plot(history.epoch, history.history['val_'+metric],<br/>                 color=colors[0], linestyle="--", label='Val')<br/>        plt.xlabel('Epoch')<br/>        plt.ylabel(name)<br/>        if metric == 'loss':<br/>            plt.ylim([0, plt.ylim()[1]])<br/>        elif metric == 'auc':<br/>            plt.ylim([0.8,1])<br/>        else:<br/>            plt.ylim([0,1])<br/><br/>        plt.legend()</span></pre><p id="70fb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">è¿™ä¸¤ä¸ªå‡½æ•°éƒ½é‡‡ç”¨è®­ç»ƒçš„å†å²ï¼Œç„¶åç»˜åˆ¶ä¸¢å¤±å’Œåº¦é‡çš„ç›¸å…³å‡½æ•°ï¼Œå³AUCã€å¬å›å’Œå¤šä¸ªæ—¶æœŸçš„ç²¾åº¦ã€‚</p><p id="78c8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">b)ç»˜åˆ¶æ··æ·†çŸ©é˜µå’ŒROCæ›²çº¿:</p><p id="5f07" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">ä¸‹ä¸€ä¸ªä»£ç å—ä»æ¨¡å‹å’ŒåŸºç¡€äº‹å®ä¸­è·å–y_predictedï¼Œä¸ºæ¨¡å‹åˆ›å»ºæ··æ·†çŸ©é˜µå’ŒROCæ›²çº¿ã€‚</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="16d6" class="ld jp hi kz b fi le lf l lg lh">def plot_cm(y_true, y_pred, title):<br/>    <em class="ik">''''</em><br/><em class="ik">    input y_true-Ground Truth Labels</em><br/><em class="ik">          y_pred-Predicted Value of Model</em><br/><em class="ik">          title-What Title to give to the confusion matrix</em><br/><em class="ik">    </em><br/><em class="ik">    Draws a Confusion Matrix for better understanding of how the model is working</em><br/><em class="ik">    </em><br/><em class="ik">    return None</em><br/><em class="ik">    </em><br/><em class="ik">    '''</em><br/>    <br/>    figsize=(10,10)<br/>    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))<br/>    cm_sum = np.sum(cm, axis=1, keepdims=True)<br/>    cm_perc = cm / cm_sum.astype(float) * 100<br/>    annot = np.empty_like(cm).astype(str)<br/>    nrows, ncols = cm.shape<br/>    for i <strong class="kz hj">in</strong> range(nrows):<br/>        for j <strong class="kz hj">in</strong> range(ncols):<br/>            c = cm[i, j]<br/>            p = cm_perc[i, j]<br/>            if i == j:<br/>                s = cm_sum[i]<br/>                annot[i, j] = '<strong class="kz hj">%.1f%%\n%d</strong>/<strong class="kz hj">%d</strong>' % (p, c, s)<br/>            elif c == 0:<br/>                annot[i, j] = ''<br/>            else:<br/>                annot[i, j] = '<strong class="kz hj">%.1f%%\n%d</strong>' % (p, c)<br/>    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))<br/>    cm.index.name = 'Actual'<br/>    cm.columns.name = 'Predicted'<br/>    fig, ax = plt.subplots(figsize=figsize)<br/>    plt.title(title)<br/>    sns.heatmap(cm, cmap= "YlGnBu", annot=annot, fmt='', ax=ax)<br/><br/>def roc_curve_plot(fpr,tpr,roc_auc):<br/>    plt.figure()<br/>    lw = 2<br/>    plt.plot(fpr, tpr, color='darkorange',<br/>             lw=lw, label='ROC curve (area = <strong class="kz hj">%0.2f</strong>)' %roc_auc)<br/>    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')<br/>    plt.xlim([0.0, 1.0])<br/>    plt.ylim([0.0, 1.05])<br/>    plt.xlabel('False Positive Rate')<br/>    plt.ylabel('True Positive Rate')<br/>    plt.title('Receiver operating characteristic example')<br/>    plt.legend(loc="lower right")<br/>    plt.show()</span></pre><p id="fed8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated"><strong class="il hj">æœ€å:Dè®­ç»ƒä¸åŒçš„å˜å½¢é‡‘åˆš:</strong></p><p id="2dd4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">a)ç¼–è¯‘æ¨¡å‹:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="1e2b" class="ld jp hi kz b fi le lf l lg lh">def compile_model(name):<br/>    with strategy.scope():<br/>        METRICS = [<br/>          tf.keras.metrics.TruePositives(name='tp'),<br/>          tf.keras.metrics.FalsePositives(name='fp'),<br/>          tf.keras.metrics.TrueNegatives(name='tn'),<br/>          tf.keras.metrics.FalseNegatives(name='fn'), <br/>          tf.keras.metrics.BinaryAccuracy(name='accuracy'),<br/>          tf.keras.metrics.Precision(name='precision'),<br/>          tf.keras.metrics.Recall(name='recall'),<br/>          tf.keras.metrics.AUC(name='auc')]<br/>        if name=='bert-base-uncased':<br/>            transformer_layer = (<br/>                TFBertModel.from_pretrained(name)<br/>            )<br/>        elif name=='openai-gpt':<br/>            transformer_layer = (<br/>                TFOpenAIGPTModel.from_pretrained(name)<br/>            )<br/>        elif name=='distilbert-base-cased':<br/>            transformer_layer = (<br/>                TFDistilBertModel.from_pretrained(name)<br/>            )<br/>        elif name=='xlm-mlm-en-2048':<br/>            transformer_layer = (<br/>                TFBertModel.from_pretrained(name)<br/>            )<br/>        elif name=='jplu/tf-xlm-roberta-large':<br/>            transformer_layer = (<br/>                TFAutoModel.from_pretrained(name)<br/>            )<br/>        model = build_model(transformer_layer, max_len=max_seq_length)<br/>        model.compile(optimizer=tf.keras.optimizers.Adam(<br/>        learning_rate=LEARNING_RATE), loss='binary_crossentropy', metrics=METRICS)<br/>    return model</span></pre><p id="3151" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">ä¸Šé¢çš„ä»£ç å—çœŸçš„å¾ˆç®€å•ã€‚å¦‚å›¾æ‰€ç¤ºï¼Œå®ƒé‡‡ç”¨æ‚¨è¦ç¼–è¯‘æ¨¡å‹çš„å˜å‹å™¨çš„åç§°ï¼Œç„¶åä»hugging face libraryåŠ è½½ç›¸å…³çš„å˜å‹å™¨å±‚ã€‚ç„¶åï¼Œå®ƒå°†åŠ è½½çš„transformerå±‚æä¾›ç»™å‡½æ•°build_model(ä¸Šé¢å®šä¹‰çš„),ç„¶åæˆ‘ä»¬ç¼–è¯‘è¿™ä¸ªæ¨¡å‹ã€‚è¯·æ³¨æ„ï¼Œæˆ‘è¿˜åˆ›å»ºäº†ä¸€ä¸ªåä¸ºMETRICSçš„åˆ—è¡¨ï¼Œå› ä¸ºæˆ‘æƒ³æ£€æŸ¥ä¸åŒæŒ‡æ ‡çš„æ¨¡å‹æ€§èƒ½ï¼Œè€Œä¸æ˜¯é™åˆ¶è‡ªå·±åªå…³æ³¨å‡†ç¡®æ€§ã€‚</p><p id="6917" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">d)å®é™…åŸ¹è®­:</p><p id="6b19" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">ç°åœ¨ï¼Œæ¯ä¸ªå˜å‹å™¨çš„å®é™…è®­ç»ƒè¿‡ç¨‹æ˜¯ç›¸åŒçš„ã€‚ä½ åªéœ€è¦è¾“å…¥ç›¸å…³çš„åå­—å¹¶è°ƒç”¨æœŸæœ›çš„å‡½æ•°æ¥é€‚åº”è¿™ä¸ªæ¨¡å‹ã€‚</p><p id="65eb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä¸ä¼šæ˜¾ç¤ºæ¯ä¸ªæ¨¡å‹çš„è¾“å‡ºå›¾ï¼Œå› ä¸ºè¿™å°†å ç”¨å¤§é‡çš„ç©ºé—´ï¼Œä½†æ˜¯ï¼Œæˆ‘å°†åªæ˜¾ç¤ºä¸€ä¸ªå˜å‹å™¨çš„å›¾å½¢ï¼Œå³æå–çš„BERTã€‚å¯ä»¥ä»¥ç±»ä¼¼çš„æ–¹å¼ä¸ºå…¶ä»–æ¨¡å‹ç”Ÿæˆç›¸åŒçš„å›¾å½¢ã€‚</p><p id="3d6b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">æ¥ä¸‹æ¥çš„ä»£ç å—å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ä¸Šé¢ä¸ºæå–çš„BERTå®šä¹‰çš„å‡½æ•°ã€‚ä¸ºäº†è®­ç»ƒä»»ä½•å…¶ä»–è½¬æ¢å™¨ï¼Œæ‚¨åªéœ€è¦å°†åä¸ºâ€œdistilt-base-casedâ€å’Œâ€œDistilBertâ€(ç²—ä½“çªå‡ºæ˜¾ç¤º)çš„å­—ç¬¦ä¸²æ›´æ”¹ä¸ºç›¸å…³çš„è½¬æ¢å™¨åç§°ã€‚</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="042c" class="ld jp hi kz b fi le lf l lg lh"><em class="ik"># # First load the real tokenizer</em><br/>tokenizer = DistilBertTokenizer.from_pretrained(<strong class="kz hj">'distilbert-base-cased'</strong>)</span><span id="a1a7" class="ld jp hi kz b fi lv lf l lg lh">X_train=np.array(single_encoding_function(train_raw['comment_text'],tokenizer,<strong class="kz hj">'DistilBert'</strong>))#change the name<br/>y_train=np.array(train_raw['toxic'])<br/>X_valid=np.array(single_encoding_function(valid_raw['comment_text'],tokenizer,<strong class="kz hj">'DistilBert'</strong>))#change the name<br/>y_valid=np.array(valid_raw['toxic'])<br/>X_test=np.array(single_encoding_function(test_raw['content'],tokenizer,<strong class="kz hj">'DistilBert'</strong>))#change the name</span><span id="08db" class="ld jp hi kz b fi lv lf l lg lh">train,valid,test=make_data()</span><span id="9688" class="ld jp hi kz b fi lv lf l lg lh">steps_per_epoch = X_train.shape[0] // BATCH_SIZE</span><span id="df1e" class="ld jp hi kz b fi lv lf l lg lh">model=compile_model(<strong class="kz hj">'distilbert-base-cased'</strong>)#change the name<br/>print(model.summary())<br/><br/>history=model.fit(<br/>    train,steps_per_epoch=steps_per_epoch,<br/>    epochs=EPOCHS,callbacks=[early_stopping], validation_data=valid<br/>)</span></pre><figure class="ku kv kw kx fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mj"><img src="../Images/bb6b097781b3c8a80651fabc066ba0d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kQegPh6HQ8B-ieONnB5xCg.png"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">æ¨¡å‹æ€»ç»“å’ŒåŸ¹è®­ä¿¡æ¯</figcaption></figure><p id="1d0a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">è¯¥æ¨¡å‹å°†å¼€å§‹è®­ç»ƒï¼Œå¹¶éœ€è¦å¾ˆé•¿æ—¶é—´ï¼Œè¿™å–å†³äºæ‚¨çš„æ•°æ®å’Œè®¡ç®—èƒ½åŠ›ã€‚æœ€åï¼Œè·å–å†å²è®°å½•å¹¶ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„ç›¸å…³å‡½æ•°æ¥ç”Ÿæˆå›¾è¡¨:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="f6a4" class="ld jp hi kz b fi le lf l lg lh">plot_loss(history)</span></pre><figure class="ku kv kw kx fd lk er es paragraph-image"><div class="er es mk"><img src="../Images/0622602c26af4a6e4d692a588e969a0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*N-KP-5zSDoJ3JYP0lsr1Ow.png"/></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">distilt-BERTä¸¤ä¸ªæ—¶æœŸçš„æŸå¤±</figcaption></figure><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="e573" class="ld jp hi kz b fi le lf l lg lh">plot_metrics(history)</span></pre><figure class="ku kv kw kx fd lk er es paragraph-image"><div class="er es ml"><img src="../Images/5d45fd7f521f145c7f09195aaaf178cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*mMX5azrJFp_PBlta6msWWw.png"/></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">å„æ—¶æœŸçš„æŸå¤±ã€AUCã€ç²¾ç¡®åº¦å’Œå¬å›</figcaption></figure><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="1ad1" class="ld jp hi kz b fi le lf l lg lh">y_predict=model.predict(valid, verbose=1)<br/>y_predict[ y_predict&gt; 0.5] = 1<br/>y_predict[y_predict &lt;= 0.5] = 0<br/>plot_cm(y_valid, y_predict, 'Distil BERT Performance-Confusion Matrix')</span></pre><figure class="ku kv kw kx fd lk er es paragraph-image"><div class="er es mm"><img src="../Images/499f002b4dc58e6562124fc739bf2c9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*-uJRAurMINyIC_o-p5zHkA.png"/></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">è’¸é¦æ°´æ··æ·†çŸ©é˜µ</figcaption></figure><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="0414" class="ld jp hi kz b fi le lf l lg lh">y_predict_prob=model.predict(valid, verbose=1)<br/>fpr, tpr, _ = roc_curve(y_valid,y_predict_prob)<br/>roc_auc = auc(fpr, tpr)<br/>roc_curve_plot(fpr,tpr,roc_auc)</span></pre><figure class="ku kv kw kx fd lk er es paragraph-image"><div class="er es mn"><img src="../Images/7a9017abac03ac9ece4f812e19b73938.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*cEMpoJE_RThl-5dannOgWw.png"/></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">ä¸€ç§è’¸é¦å•¤é…’ç”¨æ‘‡åºŠ</figcaption></figure><h1 id="bed0" class="jo jp hi bd jq jr mo jt ju jv mp jx jy jz mq kb kc kd mr kf kg kh ms kj kk kl bi translated">ç»“è®º:</h1><p id="3e47" class="pw-post-body-paragraph ii ij hi il b im km io ip iq kn is it ko kp iw ix kq kr ja jb ks kt je jf jg hb bi translated">å—¯ï¼Œæ‹¥æŠ±è„¸çœŸçš„è®©transformerçš„å®ç°å˜å¾—éå¸¸å®¹æ˜“ã€‚ç„¶è€Œï¼Œç†è§£è½¬æ¢å™¨çš„åº•å±‚å·¥ä½œä¹Ÿéå¸¸é‡è¦ï¼Œå› ä¸ºå¦åˆ™ä¸Šè¿°å®ç°å°†åªæ˜¯ä¸€ä¸ªé»‘ç›’ï¼Œæ‚¨å°†æ— æ³•è¿›ä¸€æ­¥è°ƒæ•´å’Œä¼˜åŒ–æ‚¨çš„æ¨¡å‹ã€‚æˆ‘çš„kaggleè´¦æˆ·ä¸Šä¹Ÿæœ‰å®Œæ•´çš„ä»£ç :<a class="ae li" href="https://www.kaggle.com/keenborder/comparing-different-transformers-lstms" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/keen border/comparing-different-transformers-lstms</a>å¦‚æœä½ æƒ³æ›´è¯¦ç»†åœ°äº†è§£å˜å½¢é‡‘åˆšï¼Œè¿™é‡Œä¹Ÿæœ‰é“¾æ¥ã€‚</p></div><div class="ab cl jh ji gp jj" role="separator"><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm"/></div><div class="hb hc hd he hf"><p id="28e2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it ko iv iw ix kq iz ja jb ks jd je jf jg hb bi translated">æˆ‘ä¸ºè¿™ç¯‡æ–‡ç« çœŸçš„å¾ˆåŠªåŠ›ï¼Œå› æ­¤ï¼Œè¯·é¼“æŒï¼Œå¦‚æœä½ å–œæ¬¢å®ƒï¼Œå¹¶æƒ³çœ‹åˆ°æ›´å¤šå¯æ€•çš„NLPå†…å®¹ã€‚</p></div></div>    
</body>
</html>