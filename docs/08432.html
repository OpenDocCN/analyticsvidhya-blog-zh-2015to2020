<html>
<head>
<title>Mind Mapping Machine Learning for Intuitive Understanding (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于直觉理解的思维导图机器学习(第一部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/mind-mapping-machine-learning-for-intuitive-understanding-part-1-3dbf149028d7?source=collection_archive---------16-----------------------#2020-07-29">https://medium.com/analytics-vidhya/mind-mapping-machine-learning-for-intuitive-understanding-part-1-3dbf149028d7?source=collection_archive---------16-----------------------#2020-07-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c7b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快速浏览一下机器学习的构建模块</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/89db0f1dc4dc0360de1f8d27e4c6a162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J8Jb2RpPpYr8XDeo98KpVg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">机器学习主题的手写备忘单</figcaption></figure><p id="b1a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jt">从网站下载高分辨率备忘单:</em></p><div class="ju jv ez fb jw jx"><a href="https://www.visual-design.net/data-analytics" rel="noopener  ugc nofollow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">数据分析|可视化设计工作室</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">面向数据科学爱好者的免费数据分析教程和可下载笔记。</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">www.visual-design.net</p></div></div><div class="kg l"><div class="kh l ki kj kk kg kl jn jx"/></div></div></a></div></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="74d5" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">1.关联规则挖掘</h1><blockquote class="lr ls lt"><p id="f211" class="if ig jt ih b ii ij ik il im in io ip lu ir is it lv iv iw ix lw iz ja jb jc hb bi translated">给定一组事务，找出规则，这些规则将根据事务中其他项目的出现来<strong class="ih hj">预测项目</strong>的出现。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lx"><img src="../Images/ee80d18404a9e925f599ef154d19de7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IeGMc2MISfsIlflPFr4DGg.png"/></div></div></figure><h2 id="9913" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">核心概念:</h2><ul class=""><li id="dcf3" class="mm mn hi ih b ii mo im mp iq mq iu mr iy ms jc mt mu mv mw bi translated"><strong class="ih hj">支持</strong>:包含一个项目集 X 的事务的分数</li><li id="c878" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated"><strong class="ih hj">置信度:</strong>Y 中的项目在包含 X 的事务中出现的频率</li><li id="6dc8" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated"><strong class="ih hj"> lift </strong> : lift 计算为置信度除以支持度，考虑了规则的统计独立性</li></ul><h2 id="c7fe" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">算法:</h2><p id="c36b" class="pw-post-body-paragraph if ig hi ih b ii mo ik il im mp io ip iq nc is it iu nd iw ix iy ne ja jb jc hb bi translated"><strong class="ih hj"> Apriori 算法</strong></p><ul class=""><li id="2efa" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated"><strong class="ih hj">生成和测试方法</strong></li><li id="7ffe" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">生成候选项集并测试它们是否频繁</li><li id="f97f" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated"><strong class="ih hj">先验原则:</strong>如果一个项集是频繁的，那么它的子集也一定是频繁的</li><li id="451c" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated"><strong class="ih hj">反单调性质</strong>:一个项目集的支持度永远不会超过它的子集的支持度</li><li id="2840" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">规则生成基于频繁项集和最小置信度阈值</li></ul><p id="bb6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> FP 增长算法</strong></p><ul class=""><li id="441b" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated"><strong class="ih hj">分而治之的采矿方法</strong></li><li id="fc31" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">构建<strong class="ih hj">FP 树</strong>,它是事务数据库的一个紧凑表示，并且是按频率有序排列的</li><li id="5572" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">易于遍历和挖掘基于每个节点的条件模式</li></ul></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="f699" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">2.使聚集</h1><blockquote class="lr ls lt"><p id="aa14" class="if ig jt ih b ii ij ik il im in io ip lu ir is it lv iv iw ix lw iz ja jb jc hb bi translated">C <!-- -->光泽分析:寻找对象组，使得一个组中的对象彼此相似，而与其他组中的对象不同。</p></blockquote><h2 id="ca91" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">算法:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ni"><img src="../Images/18335d380d0b2e7d3f6acc5ac3f0f9fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1w5fEh17picdXgPum9qb5Q.png"/></div></div></figure><p id="d34b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> K 表示聚类</strong></p><ul class=""><li id="2b7d" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated"><strong class="ih hj">划分聚类方法</strong></li><li id="5f88" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">随机选择<strong class="ih hj">初始质心</strong>并将点分配到最近的质心</li><li id="a187" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">重新计算质心，直到它们不再改变</li></ul><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="3953" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">凝聚聚类</strong></p><ul class=""><li id="9ffe" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated"><strong class="ih hj">层次聚类方法</strong></li><li id="f22d" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">基于<strong class="ih hj">邻近矩阵</strong>将单个集群合并在一起</li><li id="c5cb" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">邻近矩阵通过特定策略计算，例如最小值、最大值、一般平均值、沃德方法等</li></ul><p id="cb92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据库扫描</strong></p><ul class=""><li id="3b66" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated"><strong class="ih hj">基于密度的聚类方法</strong></li><li id="366a" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">所有点分为三种类型:<strong class="ih hj">核心点、边界点和噪声点</strong></li><li id="b53e" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">由两个参数决定:指定的半径(<strong class="ih hj"> Eps </strong>)和范围内的最小点数(<strong class="ih hj"> MinPts </strong>)</li><li id="9310" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">集群是围绕核心点形成的</li></ul><div class="ju jv ez fb jw jx"><a href="https://towardsdatascience.com/how-dbscan-works-and-why-should-i-use-it-443b4a191c80" rel="noopener follow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">DBSCAN 如何工作，为什么要使用它？</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">首先，这是我在 medium 上的第一个故事，如果我做错了什么，我很抱歉。其次，我不太擅长…</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">towardsdatascience.com</p></div></div><div class="kg l"><div class="nl l ki kj kk kg kl jn jx"/></div></div></a></div></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="0062" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">3.基于实例的学习</h1><blockquote class="lr ls lt"><p id="9355" class="if ig jt ih b ii ij ik il im in io ip lu ir is it lv iv iw ix lw iz ja jb jc hb bi translated">不是所有的学习算法都是通过学习一个函数来推广的。基于实例的学习是一类不学习算法而是直接与已知实例进行比较的算法。</p></blockquote><h2 id="6da6" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">算法:</h2><p id="751c" class="pw-post-body-paragraph if ig hi ih b ii mo ik il im mp io ip iq nc is it iu nd iw ix iy ne ja jb jc hb bi translated"><strong class="ih hj"> k 近邻(kNN) </strong></p><ul class=""><li id="404b" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated">基于最近的 k 个邻居的标签的分类</li><li id="388d" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">所有属性都具有相同的权重</li></ul><p id="b830" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">支持向量机(SVM) </strong></p><ul class=""><li id="a870" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated">基于相对于正类和负类之间的边界的位置对数据进行分类</li><li id="bc74" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">创建一个<strong class="ih hj">超平面</strong>以最大化利润</li><li id="ecb0" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">引入<strong class="ih hj">复杂度参数</strong>以最小化分类误差</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nm"><img src="../Images/ae7580110086231630dc33eab74474bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MdaoxFHtaV00ipHYVw308g.png"/></div></div></figure><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="adf3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">SVM 的延伸</strong></p><ol class=""><li id="480d" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc nn mu mv mw bi translated">使用<strong class="ih hj">核技巧</strong>当实例是<strong class="ih hj">不可线性分离</strong> <em class="jt">(包括多项式核和 RBF 核)</em></li><li id="a76e" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj"> SVM 回归:</strong>将分类问题转化为回归问题</li><li id="3520" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">多类 SVM: </strong>处理非二元分类</li></ol></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="cfc9" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">4.贝叶斯学习</h1><h2 id="d47d" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">贝叶斯定理:</h2><blockquote class="lr ls lt"><p id="c0e0" class="if ig jt ih b ii ij ik il im in io ip lu ir is it lv iv iw ix lw iz ja jb jc hb bi translated">贝叶斯定理提供了一种基于其<strong class="ih hj">先验概率</strong>、假设下<strong class="ih hj">观察到各种数据的概率以及<strong class="ih hj">观察到的数据本身</strong>计算这种假设的概率的直接方法</strong></p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es no"><img src="../Images/4514e1da5162810529830d7a2499d2fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UNoiRoZbW7taGkkJ2KsIGA.png"/></div></div></figure><h2 id="4f58" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">贝叶斯分类器:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es np"><img src="../Images/6e7cbaaa061a6001ac42de62617cba04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*31biHCLNnJwiYVR9l2ltTg.png"/></div></div></figure><p id="d74f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">贝叶斯最优分类器</strong></p><ul class=""><li id="ecd1" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated">显式搜索假设空间</li><li id="9082" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated"><strong class="ih hj">用假设的<strong class="ih hj">后验概率</strong>加权假设预测</strong></li></ul><div class="ju jv ez fb jw jx"><a href="https://aidevelopmenthub.com/a-gentle-introduction-to-the-bayes-optimal-classifier/" rel="noopener  ugc nofollow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">贝叶斯最优分类器简介-人工智能开发中心</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">贝叶斯最优分类器是一个概率人体模型，它可能为一个品牌做出最可能的预测…</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">aidevelopmenthub.com</p></div></div><div class="kg l"><div class="nq l ki kj kk kg kl jn jx"/></div></div></a></div><p id="3d1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">朴素贝叶斯分类器</strong></p><ul class=""><li id="a719" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated">假设属性是相互独立的</li><li id="8830" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">通过属性值的结合来描述实例</li></ul><div class="ju jv ez fb jw jx"><a href="https://www.geeksforgeeks.org/naive-bayes-classifiers/" rel="noopener  ugc nofollow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">朴素贝叶斯分类器</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">贝叶斯定理是在给定另一个已经发生的事件的概率的情况下，求出一个事件发生的概率</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">www.geeksforgeeks.org</p></div></div><div class="kg l"><div class="nr l ki kj kk kg kl jn jx"/></div></div></a></div><p id="9c1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">贝叶斯网络</strong></p><ul class=""><li id="3b41" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated">考虑属性间的<strong class="ih hj">条件依赖</strong></li><li id="a6a1" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">使用<strong class="ih hj">简单的图形符号</strong>用于条件独立性断言，因此用于完全联合分布的紧凑规范</li><li id="c161" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">用<strong class="ih hj">条件概率表</strong>表示条件依赖</li></ul><div class="ju jv ez fb jw jx"><a href="https://machinelearningmastery.com/introduction-to-bayesian-belief-networks/" rel="noopener  ugc nofollow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">贝叶斯信念网络简介-机器学习掌握</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">概率模型可以定义变量之间的关系，并用于计算概率。比如说…</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">machinelearningmastery.com</p></div></div><div class="kg l"><div class="ns l ki kj kk kg kl jn jx"/></div></div></a></div></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="5cb3" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">5.强化学习</h1><blockquote class="lr ls lt"><p id="8ee7" class="if ig jt ih b ii ij ik il im in io ip lu ir is it lv iv iw ix lw iz ja jb jc hb bi translated">涉及代理人与提供奖励的环境相互作用的问题；目标是学习如何采取行动以获得最大回报</p></blockquote><h2 id="d248" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">马尔可夫决策过程(MDP)</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nt"><img src="../Images/d3473b3b57c1ed3ff6b73b719d74f5d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*aPZbGXPSPxVSOcViTuRlyQ.png"/></div></figure><ul class=""><li id="6745" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated">加固问题的数学公式</li><li id="645a" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">找到将状态映射到行动的最优策略，目标是最大化 T2 价值函数</li></ul><div class="ju jv ez fb jw jx"><a href="https://towardsdatascience.com/reinforcement-learning-demystified-markov-decision-processes-part-1-bf00dda41690" rel="noopener follow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">去神秘化的强化学习:马尔可夫决策过程(第一部分)</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">第 2 集，揭开马尔可夫过程、马尔可夫回报过程、贝尔曼方程和马尔可夫决策过程的神秘面纱。</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">towardsdatascience.com</p></div></div><div class="kg l"><div class="nu l ki kj kk kg kl jn jx"/></div></div></a></div><h2 id="404e" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">q 学习</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nv"><img src="../Images/abe8dd2266da2dd479c6646cf485812b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7S2zPohy6croyaRslKfNTw.png"/></div></div></figure><ul class=""><li id="05d9" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated">当 MDP 和<strong class="ih hj">未知报酬和转移函数</strong>时，代理经常迭代地学习状态和动作的评估函数。</li><li id="bf00" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">对于每个状态和该状态的每个动作:<strong class="ih hj"> Q(s，a) </strong>基于当前 r(s，a)的<strong class="ih hj">即时奖励</strong>和后续状态的<strong class="ih hj">折扣奖励</strong>进行更新</li><li id="e898" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">即使随机遍历环境，值迭代也是有效的，但是我们必须在无限运行中无限频繁地访问每个状态，以便<strong class="ih hj">收敛到最优策略</strong></li></ul><div class="ju jv ez fb jw jx"><a href="https://towardsdatascience.com/a-beginners-guide-to-q-learning-c3e2a30a653c" rel="noopener follow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">Q-Learning 初学者指南</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">无模型强化学习</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">towardsdatascience.com</p></div></div><div class="kg l"><div class="nw l ki kj kk kg kl jn jx"/></div></div></a></div></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="617e" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">6.数据预处理</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nx"><img src="../Images/d8de152c9f984fd10f57e1f9c1efbbb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MwUPuakmLH38cT2k67nyyg.png"/></div></div></figure><h2 id="6e1a" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">处理不完整的数据</h2><ol class=""><li id="b90b" class="mm mn hi ih b ii mo im mp iq mq iu mr iy ms jc nn mu mv mw bi translated">忽略元组</li><li id="d937" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated">手动填写缺失的数据</li><li id="08e7" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated">自动填写:<em class="jt">使用全局常数、属性平均值或最可能值</em></li><li id="797f" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated">矩阵分解方法</li><li id="22d5" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated">多重插补</li></ol><h2 id="6cc1" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">处理噪声数据</h2><ol class=""><li id="c884" class="mm mn hi ih b ii mo im mp iq mq iu mr iy ms jc nn mu mv mw bi translated"><strong class="ih hj">宁滨</strong></li><li id="58fe" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">回归</strong></li><li id="782a" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">聚类</strong></li></ol><h2 id="3873" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">处理冗余数据</h2><ol class=""><li id="ef85" class="mm mn hi ih b ii mo im mp iq mq iu mr iy ms jc nn mu mv mw bi translated"><strong class="ih hj">特征选择技术</strong> <em class="jt">，如相关性、启发式搜索、救济或包装</em></li><li id="3259" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">主成分分析</strong></li></ol><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nj nk l"/></div></figure><h2 id="97bd" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated"><strong class="ak">处理不平衡数据</strong></h2><ol class=""><li id="5020" class="mm mn hi ih b ii mo im mp iq mq iu mr iy ms jc nn mu mv mw bi translated"><strong class="ih hj">过采样</strong>少数或<strong class="ih hj">欠采样</strong>多数</li><li id="d330" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">基于聚类的过采样</strong></li><li id="96c0" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">重击</strong></li></ol><div class="ju jv ez fb jw jx"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/balance-your-data-using-smote-98e4d79fcddb"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">如何使用 SMOTE 处理不平衡数据</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">通过 Python 中的案例研究</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">medium.com</p></div></div><div class="kg l"><div class="ny l ki kj kk kg kl jn jx"/></div></div></a></div></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="cb97" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">7.异常检测</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nz"><img src="../Images/da26d478d94f462532bd151853354844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PW_Xmn0iFCceLNxmJgAIgw.png"/></div></div></figure><h2 id="3b06" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">基于统计的方法</h2><ul class=""><li id="22bb" class="mm mn hi ih b ii mo im mp iq mq iu mr iy ms jc mt mu mv mw bi translated">假设正态数据遵循某种统计模型</li><li id="5776" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated">两种类型的统计模型:</li></ul><ol class=""><li id="054d" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc nn mu mv mw bi translated"><strong class="ih hj">单变量模型</strong></li><li id="cb69" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">多元模型</strong></li></ol><h2 id="df2f" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">基于邻近的方法</h2><ol class=""><li id="55fe" class="mm mn hi ih b ii mo im mp iq mq iu mr iy ms jc nn mu mv mw bi translated"><strong class="ih hj">o 的 r 邻居:</strong>基于距离的邻近度量</li><li id="43be" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">局部异常因子(LOF): </strong>基于密度的邻近度量</li></ol><div class="ju jv ez fb jw jx"><a href="https://towardsdatascience.com/local-outlier-factor-for-anomaly-detection-cc0c770d2ebe" rel="noopener follow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">用于异常检测的局部异常因子</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">关于局部异常值因子(LOF)的简短摘要</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">towardsdatascience.com</p></div></div><div class="kg l"><div class="oa l ki kj kk kg kl jn jx"/></div></div></a></div><h2 id="8d04" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">基于聚类的方法</h2><ol class=""><li id="7b9a" class="mm mn hi ih b ii mo im mp iq mq iu mr iy ms jc nn mu mv mw bi translated"><strong class="ih hj"> DBSCAN: </strong>当离群值不属于任何聚类时</li><li id="2d18" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj"> k 表示:</strong>当离群点远离最近的聚类时</li><li id="8a55" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">基于聚类的局部离群因子(CBLOF) </strong>:离群点形成小聚类时</li></ol><h2 id="b136" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">基于分类的方法</h2><ol class=""><li id="1e97" class="mm mn hi ih b ii mo im mp iq mq iu mr iy ms jc nn mu mv mw bi translated"><strong class="ih hj">暴力破解算法</strong></li><li id="2696" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj"> SVM: </strong>学习正常数据和异常值之间的界限</li></ol></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="2da3" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">8.数据流挖掘</h1><blockquote class="lr ls lt"><p id="e7e7" class="if ig jt ih b ii ij ik il im in io ip lu ir is it lv iv iw ix lw iz ja jb jc hb bi translated">从<strong class="ih hj">实时、连续、有序的</strong>项目序列中提取知识结构的过程。</p></blockquote><h2 id="b04a" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">改变漂移检测器:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ob"><img src="../Images/7f5cda55bdcb2175e1b50cf46842bbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ytDQwIaf74bJJSvbnHLSA.png"/></div></div></figure><ul class=""><li id="54e7" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc mt mu mv mw bi translated"><strong class="ih hj">累积和(顺序分析):</strong>通过比较阈值和漂移速度来检测变化漂移</li><li id="f0ae" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated"><strong class="ih hj"> DDM(统计过程控制)</strong>:由漂移水平和警告水平控制</li><li id="87b0" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc mt mu mv mw bi translated"><strong class="ih hj"> ADWIN(自适应滑动窗口):</strong>使用指数直方图捕捉错误率的变化</li></ul><h2 id="8ffd" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">分类器:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es oc"><img src="../Images/4a9a19931b766f2f557a411e9343eb3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JGWVwriIVAaLY3k8qZmdaA.png"/></div></div></figure><ol class=""><li id="fd3b" class="mm mn hi ih b ii ij im in iq nf iu ng iy nh jc nn mu mv mw bi translated"><strong class="ih hj">基线分类器:</strong> <em class="jt">如多数类分类器、懒惰分类器。决策树等等</em></li><li id="276f" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj"> Hoeffding Tree </strong>:根据即将出现的实例决定是否增长树</li><li id="ef8e" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj"> Hoeffding 自适应树:</strong>结合 Hoeffding 树和 ADWIN，因此能够根据概念漂移进行自适应改变</li><li id="3ab6" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated">赫夫丁树的其他扩展: VDFT，CVFDT …</li><li id="48d6" class="mm mn hi ih b ii mx im my iq mz iu na iy nb jc nn mu mv mw bi translated"><strong class="ih hj">集成分类器</strong> : OzaBag，自适应随机森林</li></ol><div class="ju jv ez fb jw jx"><a href="https://www.cms.waikato.ac.nz/~abifet/book/chapter_5.html" rel="noopener  ugc nofollow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">数据流的机器学习</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">数据流模型的一个核心特征是数据流随着时间而发展，算法必须对这种变化做出反应…</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">www.cms.waikato.ac.nz</p></div></div><div class="kg l"><div class="od l ki kj kk kg kl jn jx"/></div></div></a></div></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="95d6" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">带回家的信息</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es oe"><img src="../Images/23a80a5163e52d34568939552ed63a01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dLh7WtlB7eXYtHp3JoGhVw@2x.jpeg"/></div></div></figure><p id="74ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是对机器学习中一些基本主题的概述，包括<em class="jt">基于实例的学习、聚类、关联规则挖掘、贝叶斯学习、强化学习、数据预处理、异常检测和数据流挖掘</em>。此外，简要介绍了每个主题下的算法和核心概念。这篇文章的主要目的是在一个抽象的层次上对概念进行分类和比较。每个主题的详细解释将在以后的文章中给出…</p><h2 id="72c1" class="ly ku hi bd kv lz ma mb kz mc md me ld iq mf mg lh iu mh mi ll iy mj mk lp ml bi translated">更多资源</h2><div class="ju jv ez fb jw jx"><a href="https://link.medium.com/hSwWWDqqw9" rel="noopener follow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">如何成为一流的大学</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">轻松学习的四个基本技巧和心理窍门</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">link.medium.com</p></div></div><div class="kg l"><div class="of l ki kj kk kg kl jn jx"/></div></div></a></div><div class="ju jv ez fb jw jx"><a href="https://www.visual-design.net/data-analytics" rel="noopener  ugc nofollow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">数据分析|可视化设计工作室</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">面向数据科学爱好者的免费数据分析教程和可下载笔记。</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">www.visual-design.net</p></div></div><div class="kg l"><div class="kh l ki kj kk kg kl jn jx"/></div></div></a></div><div class="ju jv ez fb jw jx"><a rel="noopener follow" target="_blank" href="/ai-in-plain-english/simplified-machine-learning-concepts-ep1-dd794ee7dd0c"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">简化机器学习</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">第 1 部分:机器学习简介</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">medium.com</p></div></div><div class="kg l"><div class="og l ki kj kk kg kl jn jx"/></div></div></a></div><div class="ju jv ez fb jw jx"><a rel="noopener follow" target="_blank" href="/dev-genius/simplified-machine-learning-66c7a47cde18"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">简化机器学习</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">第四部分:使用主动回忆学习集成方法</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">medium.com</p></div></div><div class="kg l"><div class="oh l ki kj kk kg kl jn jx"/></div></div></a></div><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nj nk l"/></div></figure></div></div>    
</body>
</html>