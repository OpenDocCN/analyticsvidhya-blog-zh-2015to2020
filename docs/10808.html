<html>
<head>
<title>Language Modeling for (తెలుగు) Telugu</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">(తెలుగు)泰卢固语的语言建模</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/language-modeling-for-%E0%B0%A4%E0%B1%86%E0%B0%B2%E0%B1%81%E0%B0%97%E0%B1%81-telugu-b590a029a565?source=collection_archive---------10-----------------------#2020-11-03">https://medium.com/analytics-vidhya/language-modeling-for-%E0%B0%A4%E0%B1%86%E0%B0%B2%E0%B1%81%E0%B0%97%E0%B1%81-telugu-b590a029a565?source=collection_archive---------10-----------------------#2020-11-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/e08496e62d660b35ef59bdb0cb918557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*0mvYM3VlHwyip2ogvo-27g.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来源:<a class="ae iq" href="https://te.wikipedia.org/wiki/%E0%B0%A6%E0%B1%87%E0%B0%B6_%E0%B0%AD%E0%B0%BE%E0%B0%B7%E0%B0%B2%E0%B0%82%E0%B0%A6%E0%B1%81_%E0%B0%A4%E0%B1%86%E0%B0%B2%E0%B1%81%E0%B0%97%E0%B1%81_%E0%B0%B2%E0%B1%86%E0%B0%B8%E0%B1%8D%E0%B0%B8" rel="noopener ugc nofollow" target="_blank">泰卢固语维基百科</a></figcaption></figure><p id="cea4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">你读过Yandamoori的<strong class="it hj"><em class="jp">anando Bram ha(</em></strong><a class="ae iq" href="https://www.goodreads.com/book/show/23510504-aanando-brahma" rel="noopener ugc nofollow" target="_blank"><strong class="it hj">ఆనందోబ్రహ్మ</strong></a><strong class="it hj">)</strong>？如果没有，你完全应该。这本书(泰卢固语小说)首次出版于1980年，远远领先于当时的时代。故事发生在2054年，印度的安德拉·德萨姆，是怀旧、幻想、浪漫和未来学的大杂烩。在这篇文章中，作者描述了一台(虚构的)“<strong class="it hj"> <em class="jp">第12代计算机</em> </strong>”它读入一部小说，并预测它将被市场接受的程度。此外，电脑会建议在哪里添加更多的浪漫、暴力等内容..让它更吸引人。</p><figure class="jr js jt ju fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es jq"><img src="../Images/38ac8a321e4a9e42e12b702120a1d337.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GY1kTAHqUveuKU4cDeHk3w.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来源:扬达姆里·韦伦德拉纳斯(阿南朵·布拉姆哈)</figcaption></figure><p id="4beb" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">今天，我们离这个虚构的现实不远了。OpenAI的研究人员实现了类似的特技，即教会计算机如何书写。如果你好奇，可以在这里和他们的demo <a class="ae iq" href="https://talktotransformer.com/" rel="noopener ugc nofollow" target="_blank">互动。</a></p><div class="jz ka ez fb kb kc"><a href="https://www.theverge.com/2019/11/7/20953040/openai-text-generation-ai-gpt-2-full-model-release-1-5b-parameters" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">OpenAI发布了文本生成人工智能，称其太危险，不能分享</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">研究实验室OpenAI宣布，它已经在2月份创建了一个名为GPT-2的新的文本生成人工智能系统，但拒绝透露…</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">www.theverge.com</p></div></div><div class="kl l"><div class="km l kn ko kp kl kq ik kc"/></div></div></a></div><p id="443f" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">谷歌的另一个团队创建了可以消化整部小说的模型，这使得生成长期连贯的作品成为可能。</p><div class="jz ka ez fb kb kc"><a href="https://venturebeat.com/2020/01/16/googles-ai-language-model-reformer-can-process-the-entirety-of-novels/" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">谷歌的人工智能语言模型重整器可以处理整部小说</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">无论是语言、音乐、语音还是视频，序列数据对于人工智能和机器学习模型来说都不容易…</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">venturebeat.com</p></div></div><div class="kl l"><div class="kr l kn ko kp kl kq ik kc"/></div></div></a></div><p id="4238" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">一种叫做<strong class="it hj"> <em class="jp">语言建模</em> </strong>的技术是所有这些进步的核心。我感兴趣的是了解这些技术进步如何被用于泰卢固语和泰卢固语使用者的利益。在这篇文章中，我将</p><ol class=""><li id="ae3d" class="ks kt hi it b iu iv iy iz jc ku jg kv jk kw jo kx ky kz la bi translated">浅谈泰卢固语</li><li id="a30e" class="ks kt hi it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la bi translated">解释语言建模及其应用</li><li id="659e" class="ks kt hi it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la bi translated">为泰卢固语创建BERT语言模型</li><li id="39a9" class="ks kt hi it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la bi translated">展示一些你可以用训练好的语言模型做的很酷的事情</li></ol></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><h1 id="8e9f" class="ln lo hi bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">泰卢固语</h1><p id="5ca7" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">泰卢固语通常被称为东方的意大利语(因为大多数单词都以元音结尾)，是一种德拉维甸语，全世界有超过8200万人使用。在泰卢固，</p><ol class=""><li id="d38f" class="ks kt hi it b iu iv iy iz jc ku jg kv jk kw jo kx ky kz la bi translated">语言类型学是<strong class="it hj">主语-宾语-动词</strong> (SOV)</li><li id="69c2" class="ks kt hi it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la bi translated"><strong class="it hj">名词</strong>有<strong class="it hj">屈折</strong>表示<strong class="it hj">数</strong>(单数/复数)<strong class="it hj">类</strong>(阳性、阴性、中性)<strong class="it hj">格</strong>(主格、宾格、所有格、与格等)..)</li><li id="25ca" class="ks kt hi it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la bi translated">书写系统是分段的(Abugida)，其中<strong class="it hj">辅音-元音</strong>序列作为一个单元书写。</li></ol></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><h1 id="9343" class="ln lo hi bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">什么是语言建模</h1><p id="184c" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">语言建模是一项在给定单词序列的情况下预测下一个单词是什么的任务。</p><blockquote class="mq"><p id="0a63" class="mr ms hi bd mt mu mv mw mx my mz jo dx translated">设<strong class="ak"> <em class="na"> X(1)，X(2)，X(3)，…。</em></strong>x(n)是一个单词序列；</p></blockquote><p id="94d8" class="pw-post-body-paragraph ir is hi it b iu nb iw ix iy nc ja jb jc nd je jf jg ne ji jj jk nf jm jn jo hb bi translated">语言模型的目标是<strong class="it hj"> <em class="jp">预测下一个单词X(n+1) </em> </strong>的概率分布</p><blockquote class="mq"><p id="606d" class="mr ms hi bd mt mu mv mw mx my mz jo dx translated">P(X(n+1)|X(n)，…。，X(1))；其中X(n+1)可以是词汇表(集合)中的任何单词<strong class="ak"> V </strong></p></blockquote><p id="318f" class="pw-post-body-paragraph ir is hi it b iu nb iw ix iy nc ja jb jc nd je jf jg ne ji jj jk nf jm jn jo hb bi translated">稍有不同的目的是屏蔽给定句子中的某些标记(单词)，并基于左右上下文预测屏蔽的单词(也称为<strong class="it hj"> <em class="jp">屏蔽语言建模</em> </strong>)。</p><h1 id="e1c0" class="ln lo hi bd lp lq ng ls lt lu nh lw lx ly ni ma mb mc nj me mf mg nk mi mj mk bi translated">谁在乎呢。</h1><p id="2c0e" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">语言建模是许多任务的子组件，如<strong class="it hj">预测打字</strong>、<strong class="it hj">语法纠错</strong>、<strong class="it hj">机器翻译</strong>、<strong class="it hj">摘要</strong>、<strong class="it hj">词性标注</strong>、<strong class="it hj">命名实体识别</strong>等。<strong class="it hj">句子嵌入</strong>，语言建模的副产品，可用于下游任务，如<strong class="it hj">文本分类</strong>和<strong class="it hj">蕴涵</strong>。</p><blockquote class="nl nm nn"><p id="63f3" class="ir is jp it b iu iv iw ix iy iz ja jb no jd je jf np jh ji jj nq jl jm jn jo hb bi translated">在语言建模任务中的完美表现，预测序列中的下一个单词，其猜测次数等于或低于人类参与者所需的猜测次数，这表明了人类水平的智能。</p></blockquote><h1 id="440a" class="ln lo hi bd lp lq ng ls lt lu nh lw lx ly ni ma mb mc nj me mf mg nk mi mj mk bi translated">代码和型号</h1><p id="4bb0" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">对于我下面展示的所有演示，我已经在我的知识库中提供了代码，并且已经通过<a class="ae iq" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> huggingface </a>模型库提供了模型。如果可能，请尽可能以最高分辨率观看youtube演示视频。</p><div class="jz ka ez fb kb kc"><a href="https://github.com/kuppulur/Telugu_Experiments" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">库普鲁尔/泰卢固语_实验</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">在这个资源库中，我使用我在……上培训的语言模型演示了泰卢固语语言建模的一些应用程序</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">github.com</p></div></div><div class="kl l"><div class="nr l kn ko kp kl kq ik kc"/></div></div></a></div><div class="jz ka ez fb kb kc"><a href="https://huggingface.co/kuppuluri" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">库普乌里(卡尔蒂克·乌普乌里)</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">我们正踏上通过自然语言解决人工智能并使其大众化的旅程。</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">huggingface.co</p></div></div><div class="kl l"><div class="ns l kn ko kp kl kq ik kc"/></div></div></a></div><h1 id="9beb" class="ln lo hi bd lp lq ng ls lt lu nh lw lx ly ni ma mb mc nj me mf mg nk mi mj mk bi translated">泰卢固语的BERT</h1><p id="e9a0" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">BERT (来自Transformers的双向编码器表示)是一个非常流行的语言表示模型，它已经在跨各种语言的不同NLP(自然语言处理)任务中取得了最先进的结果。其核心是，它使用屏蔽语言建模目标来创建语言表示模型。关于伯特的更多细节，请参考杰伊·阿拉玛的这篇精彩文章。</p><div class="jz ka ez fb kb kc"><a href="http://jalammar.github.io/illustrated-bert/" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">有插图的伯特、埃尔莫等人(NLP如何破解迁移学习)</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">讨论:黑客新闻(98分，19条评论)，Reddit r/MachineLearning (164分，20条评论)翻译…</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">jalammar.github.io</p></div></div></div></a></div><p id="62ce" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">为了在泰卢固语中创建一个<strong class="it hj">相似的语言表示模型，第一步是精选一些<strong class="it hj">数据</strong>。我从不同的来源(维基百科、书籍、报纸、博客等)搜集在线泰卢固语内容。).另外，我发现这个数据集非常有用。</strong></p><div class="jz ka ez fb kb kc"><a href="https://github.com/AnushaMotamarri/Telugu-Newspaper-Article-Dataset" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">AnushaMotamarri/泰卢固语-报纸-文章-数据集</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">这个项目从泰卢固语报纸网站Andhra Jyoti的档案中收集文章。创建一组查询，然后…</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">github.co</p></div></div><div class="kl l"><div class="nt l kn ko kp kl kq ik kc"/></div></div></a></div><p id="e358" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">一旦我整理了数据，我就使用下面两篇文章中的知识，用泰卢固语从头开始创建了一个词汇表大小为32k  的<strong class="it hj"> <em class="jp"> BERT模型。</em></strong></p><div class="jz ka ez fb kb kc"><a href="https://huggingface.co/blog/how-to-train" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">如何使用转换器和记号赋予器从零开始训练一个新的语言模型</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">在过去的几个月里，我们对我们的transformers和tokenizers库做了一些改进，目标是…</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">huggingface.co</p></div></div><div class="kl l"><div class="nu l kn ko kp kl kq ik kc"/></div></div></a></div><div class="jz ka ez fb kb kc"><a href="https://zablo.net/blog/post/training-roberta-from-scratch-the-missing-guide-polish-language-model/" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">从零开始训练罗伯塔-失踪的指南</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">经过数小时的研究和尝试，以了解所有必要的部分需要一个训练定制…</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">zablo.net</p></div></div><div class="kl l"><div class="nv l kn ko kp kl kq ik kc"/></div></div></a></div><p id="8bed" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在下面的演示中，我比较了我的<strong class="it hj"> <em class="jp">定制BERT泰卢固语模型</em> </strong>与一个<strong class="it hj"> <em class="jp">预训练BERT多语言模型</em> </strong>的结果。</p><figure class="jr js jt ju fd ij"><div class="bz dy l di"><div class="nw nx l"/></div></figure><h1 id="1b5b" class="ln lo hi bd lp lq ng ls lt lu nh lw lx ly ni ma mb mc nj me mf mg nk mi mj mk bi translated">快速文本模型</h1><p id="d691" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">我还根据我收集的数据训练了一个快速文本模型。所有的模型下载链接都可以在我的<a class="ae iq" href="https://github.com/kuppulur/Telugu_Experiments" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。</p><figure class="jr js jt ju fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es ny"><img src="../Images/b90de4ca1d7df5792b87af59536218e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sVIdEMAj9t-zBr6R1nQOMA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">我创建的快速文本模型中的单词<br/> స్టాక్的顶级邻居及其相似性</figcaption></figure><h1 id="1aa0" class="ln lo hi bd lp lq ng ls lt lu nh lw lx ly ni ma mb mc nj me mf mg nk mi mj mk bi translated">词性标注和命名实体识别</h1><p id="dc7c" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">一旦我有了泰卢固语的语言表示模型，我就用它来创建词类标记和命名实体识别模型。</p><div class="jz ka ez fb kb kc"><a href="https://github.com/anikethjr/NER_Telugu" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">NER泰卢固语</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">标题为“使用LSTM-CRF进行泰卢固语命名实体识别”的论文的代码。数据集可以在…中找到</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">github.com</p></div></div><div class="kl l"><div class="nz l kn ko kp kl kq ik kc"/></div></div></a></div><p id="b79a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我使用了<a class="ae iq" href="https://github.com/ThilinaRajapakse/simpletransformers" rel="noopener ugc nofollow" target="_blank"> SimpleTransformers </a>库来创建POS和NER模型。你可以在下面观看POS和NER的演示，如前所述，演示代码可以在我的Github上找到。</p><figure class="jr js jt ju fd ij"><div class="bz dy l di"><div class="nw nx l"/></div></figure><h1 id="f837" class="ln lo hi bd lp lq ng ls lt lu nh lw lx ly ni ma mb mc nj me mf mg nk mi mj mk bi translated">泰卢固语问答</h1><p id="7fc3" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">我从<strong class="it hj"> <em class="jp"> Tydiqa数据集</em> </strong>中分离出泰卢固语的训练数据，并使用这些数据来训练泰卢固语的小队式问答系统。可以看下面的演示。</p><figure class="jr js jt ju fd ij"><div class="bz dy l di"><div class="nw nx l"/></div></figure><h1 id="8acf" class="ln lo hi bd lp lq ng ls lt lu nh lw lx ly ni ma mb mc nj me mf mg nk mi mj mk bi translated">泰卢固语摘要</h1><p id="ebbb" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">你一直想知道长篇新闻的主旨吗？如果是，下面的演示将告诉你如何从长文章中提取摘要。为此，我使用了一个名为<a class="ae iq" href="https://github.com/dmmiller612/bert-extractive-summarizer" rel="noopener ugc nofollow" target="_blank">Bert-extract-summary</a>r的库和我构建的泰卢固语模型。</p><figure class="jr js jt ju fd ij"><div class="bz dy l di"><div class="nw nx l"/></div></figure><h1 id="ed42" class="ln lo hi bd lp lq ng ls lt lu nh lw lx ly ni ma mb mc nj me mf mg nk mi mj mk bi translated">分类问题可以用这个模型吗？</h1><p id="35c8" class="pw-post-body-paragraph ir is hi it b iu ml iw ix iy mm ja jb jc mn je jf jg mo ji jj jk mp jm jn jo hb bi translated">当然可以。下面的脚本展示了如何获取任何给定文本的句子嵌入。一旦有了嵌入，就可以通过简单地添加另一个分类层(或者根据问题添加一个回归层)来训练这些模型。</p><div class="jz ka ez fb kb kc"><a href="https://github.com/kuppulur/Telugu_Experiments/blob/main/bert_sentence_embeddings.py" rel="noopener  ugc nofollow" target="_blank"><div class="kd ab dw"><div class="ke ab kf cl cj kg"><h2 class="bd hj fi z dy kh ea eb ki ed ef hh bi translated">库普鲁尔/泰卢固语_实验</h2><div class="kj l"><h3 class="bd b fi z dy kh ea eb ki ed ef dx translated">泰卢固语语言模型实验。通过在…上创建帐户，为kuppulur/Telugu_Experiments的开发做出贡献</h3></div><div class="kk l"><p class="bd b fp z dy kh ea eb ki ed ef dx translated">github.com</p></div></div><div class="kl l"><div class="oa l kn ko kp kl kq ik kc"/></div></div></a></div></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="4734" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如果您已经读到这里，非常感谢您抽出宝贵的时间来阅读本文。对于更多像<strong class="it hj">语义搜索</strong>、<strong class="it hj">聚类</strong>等应用。请查看我的<a class="ae iq" href="https://github.com/kuppulur/Telugu_Experiments" rel="noopener ugc nofollow" target="_blank"> Github </a>。</p><p id="986a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">🙏 ధన్యవాదాలు 🙏</strong></p><h1 id="5c13" class="ln lo hi bd lp lq ng ls lt lu nh lw lx ly ni ma mb mc nj me mf mg nk mi mj mk bi translated">参考</h1><ol class=""><li id="348a" class="ks kt hi it b iu ml iy mm jc ob jg oc jk od jo kx ky kz la bi translated"><a class="ae iq" href="https://www.censusindia.gov.in/2011Census/Language_MTs.html" rel="noopener ugc nofollow" target="_blank">https://www.censusindia.gov.in/2011Census/Language_MTs.html</a></li><li id="fcfe" class="ks kt hi it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la bi translated"><a class="ae iq" href="https://en.wikipedia.org/wiki/Telugu_language" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Telugu_language</a></li><li id="d3ac" class="ks kt hi it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la bi translated"><a class="ae iq" href="https://huggingface.co/blog/how-to-train" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/blog/how-to-train</a></li><li id="9b0b" class="ks kt hi it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la bi translated"><a class="ae iq" href="https://zablo.net/blog/post/training-roberta-from-scratch-the-missing-guide-polish-language-model/" rel="noopener ugc nofollow" target="_blank">https://zablo . net/blog/post/training-Roberta-from scratch-the-missing-guide-polish-language-model/</a></li><li id="167c" class="ks kt hi it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la bi translated"><a class="ae iq" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1810.04805.pdf</a></li></ol></div></div>    
</body>
</html>