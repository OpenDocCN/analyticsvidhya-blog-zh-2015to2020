<html>
<head>
<title>Reduce the curse of (n × n) to (our choice × our choice)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">把(n × n)的诅咒简化为(我们的选择×我们的选择)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/reduce-the-curse-of-n-n-to-our-choice-our-choice-71c0322405cd?source=collection_archive---------18-----------------------#2020-02-03">https://medium.com/analytics-vidhya/reduce-the-curse-of-n-n-to-our-choice-our-choice-71c0322405cd?source=collection_archive---------18-----------------------#2020-02-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="fdd4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我将讨论PCA( <strong class="ih hj">主成分分析</strong>)如何帮助将(n × n)的任何数据集的维度降低到我们自己选择的维度。</p><p id="358f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从UCI机器学习库中的<a class="ae jd" href="https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">哈伯曼</strong> </a>的数据集中取几个行和列的例子。因此，在取出几个示例后，我们会收到这样一个数据集:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/3816856b6d27eb0db52f0a87dcb7bb08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*-ctivJ-wUKvMtMCQeN2V5A.png"/></div></figure><p id="4f8a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于PCA是一种<strong class="ih hj">无监督学习技术</strong>，我们不应该考虑输出列。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jm"><img src="../Images/ac250c623502f60a3f0bb617f1fe90c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*TeKTy2qxqDphA6AOfzH08g.png"/></div></figure><p id="4908" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们必须记住，如果我们有“n”个列，我们可以为数据集创建“n”个主成分。我们必须从中取长补短，这样才能准确预测我们的产出。</p><p id="4bba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，首先我们将从数据集的前2列开始，然后我们将从第3列开始，并且将知道如何计算主成分(PC)以用于随后的列增加。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jn"><img src="../Images/6b55ac0148279d2b17839dccc99085a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*LgesvAtfsd2uwhnfDPN7qQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">从前两列开始</figcaption></figure><p id="c8f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将第一列的数据点视为X1、X2、X3…等等。类似地，我们将第2列的数据点视为Y1、Y2、Y3、…等等。</p><p id="a478" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">之后，我们将计算第一列的平均值，然后计算第二列的平均值。因此，列1 =(31+31+33+38+41+42+42+62+62)/8 = 42.5 &amp;列2 =(59 = 65+58+69+60+69+65+62)/8 = 63.37</p><p id="40d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我们将在原点投影/移动这些平均点。我们将投影数据点(X1，Y1)，(X2，Y2)，……。相对于我们的新原点。<strong class="ih hj">注意</strong>:移动数据不会改变数据点相对于彼此的位置。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es js"><img src="../Images/9fe6cfd8b4f34adde7372da298fb57c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dEFsI5uAVdY_Hwqf"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">平均点到原点的投影</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es jx"><img src="../Images/ef19e4a2d06e4b30e75988cbaa14870c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LTtzoDgxGhVBjSQK"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">绘制了相对于原点的列1和列2数据点</figcaption></figure><p id="9c1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在相对于原点画出点之后，我们将尝试相对于画出的点拟合一条线。我们将从绘制一条随机线开始，最终通过更新数据点，我们将在线性回归的帮助下形成一条线。我们可以通过<a class="ae jd" rel="noopener" href="/@soumo.villa7/machine-learning-is-very-easy-to-understand-a2044c813999"> <strong class="ih hj">点击这里</strong> </a>查看与线性回归相关的博客。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es jy"><img src="../Images/327882919eebb91cfae07b4afa9d6bc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*iiXz6nV4IQFhJ8uAk2yTnw.gif"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">举例说明如何根据2D图上绘制的数据点拟合直线</figcaption></figure><p id="ce27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意</strong>:我们将生成的最佳拟合线有两个通过<strong class="ih hj">原点</strong>的重要特征</p><ol class=""><li id="7fc0" class="jz ka hi ih b ii ij im in iq kb iu kc iy kd jc ke kf kg kh bi translated">每个数据点与其在最佳拟合线上的投影的距离必须最小为<strong class="ih hj">最小</strong></li></ol><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es ki"><img src="../Images/6680a46b711a58686f1e5ba9320f327a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aPmhNd-68_4EdMyEd2BjTQ.jpeg"/></div></div></figure><p id="a67b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.从<strong class="ih hj">原点</strong>到<strong class="ih hj">每个投影</strong>(其数据点)的距离平方和必须是<strong class="ih hj">最大值</strong>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kj"><img src="../Images/8ba314e575196b349ebd1473dbc5159a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MI5SXLHy8Mico-82sV48jw.jpeg"/></div></div></figure><p id="7bad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们得到的第一条预测线将被称为穿过原点的<strong class="ih hj">主分量1 </strong>。</p><p id="6ebd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑如果<strong class="ih hj">主成分1 </strong> ( <strong class="ih hj"> PC1 </strong>)的斜率为0.75那么，</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kk"><img src="../Images/e4412a9deb41ddac87408170bdb2bb6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tQclyfEQdsR6ay0j9azkmQ.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">这显示PC1由列1的4部分和列2的3部分组成</figcaption></figure><p id="a726" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">而列2与列1之间的这种3:4的比例称为“<strong class="ih hj">线性组合</strong>”。因此，如果我们在这里加入毕达哥拉斯定理的概念，那么，4 + 3 = 25，它的平方根是5(斜边的长度)。如果我们借助斜边长度(即5)来计算三角形的边长</p><p id="9fa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，5/5 =<strong class="ih hj">1</strong>；3/5 =<strong class="ih hj">0.6</strong>；4/5 = <strong class="ih hj"> 0.8。因此，PC1的这1个单位由0.6个单位的column2和0.8个单位的<strong class="ih hj"> column1 </strong>组成，称为预测线PC1的<strong class="ih hj">奇异</strong>巡回<strong class="ih hj">、</strong>特征向量</strong></p><p id="ffd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意 : →现在，如果我们画一条穿过原点并垂直于两个PC1的直线。新的线将被称为PC2，因此，如果有3列，那么第三个PC将垂直于通过原点的PC1和PC2。类似地，PC4将垂直于PC1和PC2的PC3，如此继续下去。由此我们得知，数据集的<em class="kl">列数将给出PC的总数</em>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es km"><img src="../Images/5cc376ccd9248958e9b1382e4975b243.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dN2vzb0AQ6mDhi4AOQsrBg.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">PC1垂直于PC2</figcaption></figure><p id="8af1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Scree Plot : </strong> →这是一种表示，表示每个主成分所占的百分比变化。为了计算PC的每个变化，我们将应用公式[(从<strong class="ih hj">原点</strong> ) <strong class="ih hj"> / </strong>列数-1的<strong class="ih hj">每个投影</strong>(其数据点)的平方距离之和]。</p><p id="af3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算偏差后，我们将它们相加，然后用每个PC偏差<strong class="ih hj"/><strong class="ih hj"/><strong class="ih hj"/>除以总偏差<strong class="ih hj"/><strong class="ih hj"/>，得到每个PC的%偏差。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kn"><img src="../Images/593e676f28d611de2ad20bfac370012f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eFombaNN1GmruALQj9NzRw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">相对于数据集的不同PCs ,%变化的Scree图表示</figcaption></figure><p id="13ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们得出的结论是，代表数据集最大变化的PCs将仅用于数据集的进一步分析。因此，我们减少数据集维度的工作已经完成。</p><p id="f582" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您对此有任何疑问或意见，请告诉我，在此之前，请享受学习的乐趣。</p></div></div>    
</body>
</html>