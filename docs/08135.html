<html>
<head>
<title>Exploring Other Face Detection Approaches(Part 1) — RetinaFace</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">探索其他人脸检测方法(第一部分)——视网膜脸</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/exploring-other-face-detection-approaches-part-1-retinaface-9b00f453fd15?source=collection_archive---------3-----------------------#2020-07-19">https://medium.com/analytics-vidhya/exploring-other-face-detection-approaches-part-1-retinaface-9b00f453fd15?source=collection_archive---------3-----------------------#2020-07-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/9b6a8bede704e485f6d7e282265c1b4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*qurgpgDbxMa4p-QBfdbO_w.jpeg"/></div></figure><p id="277d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">每当我们致力于解决任何与人脸相关的问题，如人脸识别系统(FRS)、人脸活动性检测、面部属性、性别检测甚至年龄估计，解决方案的第一步总是检测人脸。目前，我在开源社区中看到的人脸检测要么是通过级联检测人脸，要么是通过<a class="ae jk" href="https://arxiv.org/abs/1604.02878" rel="noopener ugc nofollow" target="_blank"> MTCNN </a>。这些方法都很棒，但是仍然有许多其他算法可以帮助检测人脸，可能比MTCNN更好。这些文章将帮助您探索其他面部检测算法，这些算法可用于您的特定使用案例和环境条件。在第一部分中，我们将覆盖视网膜。</p><p id="abf7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将涵盖四种不同类型的人脸检测架构:<br/> <strong class="io hj"> 1 .视网膜脸</strong>2。<a class="ae jk" rel="noopener" href="/analytics-vidhya/exploring-other-face-detection-approaches-part-2-ssh-7c85179cd98d"> SSH:单级无头人脸检测器</a> <br/> 3。<a class="ae jk" rel="noopener" href="/analytics-vidhya/exploring-other-face-detection-approaches-part-3-pcn-395d3b07d62a"> PCN:渐进校准网络</a> <br/> 4。<a class="ae jk" rel="noopener" href="/analytics-vidhya/exploring-other-face-detection-approaches-part-4-tiny-face-684c8cba5b01">微型人脸检测器</a></p></div><div class="ab cl jl jm gp jn" role="separator"><span class="jo bw bk jp jq jr"/><span class="jo bw bk jp jq jr"/><span class="jo bw bk jp jq"/></div><div class="hb hc hd he hf"><h1 id="2a42" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">视网膜脸:野外单镜头多层次人脸定位</h1><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/2988e6e813d41d5e833a9e932235a53a.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*WDgJyd5B_WKdDRI6bqG0uQ.png"/></div></figure><p id="7e19" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">RetineFace同时执行三种不同的人脸定位任务，即人脸检测、2D人脸对齐和基于单镜头框架的3D人脸重建。所有三个目标被求解，记住只有一个共同的目标，即对于上述三个任务回归的所有点应该位于图像平面上。</p><h2 id="bffa" class="kv jt hi bd ju kw kx ky jy kz la lb kc ix lc ld kg jb le lf kk jf lg lh ko li bi translated"><strong class="ak">接近</strong></h2><ol class=""><li id="566c" class="lj lk hi io b ip ll it lm ix ln jb lo jf lp jj lq lr ls lt bi translated"><strong class="io hj"> 3D人脸重建</strong></li></ol><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/199d8e233295d0037a803e63254bb6c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*CwZdjkoI7osdxyieBnCGnw.png"/></div></figure><p id="c8b9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了从2D图像创建一个3D面，他们使用了一个预定义的具有N个顶点的三角形面，如上图所示。顶点在不同的面上共享相同的语义含义，并且利用固定的三角形拓扑，每个面像素可以通过<a class="ae jk" href="https://mathworld.wolfram.com/BarycentricCoordinates.html" rel="noopener ugc nofollow" target="_blank">重心</a>坐标来索引，并且三角形索引与3D面进行像素方面的对应。</p><p id="653d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了回归2D图像平面上的3D顶点，他们使用2个损失函数:</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/9ca0967a08f382308834446dc02f8b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*9YMWxQ6eEZ6c0-fe0p6MZg.png"/></div></figure><p id="a7dd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里，N是总顶点，即1103(68+1035)，V是预测点，V*是地面真实点。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/6383b86232527e9b6fd49a7be4b95cbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*nW70kgMSVmx1aTl7n56OMA.png"/></div></figure><p id="3d0d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这是边长损失，因为它是三角形拓扑。这里，M是三角形的数量，即2110(111+1999)，E是预测边长，E*是地面真实边长。</p><p id="64b1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，回归3D点的总损失损失变为:</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/658c09a8d0439987ed7984684c3c7fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*U_lMPK3pSID0noGbvfF7pw.png"/></div></figure><p id="589e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 2。多层次人脸定位</strong></p><p id="0241" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一个<a class="ae jk" rel="noopener" href="/@andersasac/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9">锚</a> i的完整损失函数变成:</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/a6ec512c90e5641c6abbb3abd641b92a.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*dQUWx6WSLKzmEjLX1F3pHw.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">多任务损失</figcaption></figure><p id="9e46" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">损失函数有4个部分:<br/> a) <a class="ae jk" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> Softmax </a>二元类(脸/非脸)的损失，其中，p是锚I是脸的预测概率，p*是地面真实。<br/> b)包围盒的回归损失。<br/> c)五个标志的回归损失<br/> d)如上所述的3D点的回归损失。</p><p id="df90" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所有坐标都归一化为:</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es md"><img src="../Images/9296b419f831e469ff37c0214ad7cbed.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*GacYa2F_ZUCIPJdlmKdBcA.png"/></div></figure><p id="eff5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里，x*和y*是面部框角的地面真实坐标，五个面部标志和(x*，y*，z*)是图像空间中的3D地面真实顶点。所有3D地面真实顶点被平移，使得鼻尖的z坐标为零。x^a、y^a是面边界框的中心坐标，s^a是比例。盒子的宽度和高度也被归一化为log(w*/s^a)和log(h*/s^a)，其中w*和h*是面盒的实际尺寸。<br/>损失函数的所有部分被赋予相等的权重-年龄，并通过L1范数进行平滑。</p><p id="3cea" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 3。</strong> <strong class="io hj">单镜头多层次人脸定位</strong></p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="er es me"><img src="../Images/4084ca5cb2718139be4fd3121eb3bc40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vpxax5XkJrAhWqOMc7-03Q.png"/></div></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">整体方法概述</figcaption></figure><p id="f412" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">该模型由三个主要组件组成:<br/> a)特征金字塔网络<br/> b)上下文头模块<br/> c)级联多任务丢失</p><p id="0b3f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">特征金字塔网络</strong></p><p id="5a7f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">它获取输入图像并输出不同比例的五个特征图。上图中的前四个特征图是使用在imagenet-11k数据集上预先训练的<a class="ae jk" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet </a>计算的。最上面的特征图是通过C5上的3×3与步幅2的卷积。</p><p id="36f8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">语境模块</strong></p><p id="266d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了加强上下文建模能力<a class="ae jk" href="https://towardsdatascience.com/review-dcn-deformable-convolutional-networks-2nd-runner-up-in-2017-coco-detection-object-14e488efce44" rel="noopener" target="_blank">变形卷积网络(DCN) </a>在该模块中用于除正常3×3卷积之外的特征映射。</p><p id="f244" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">级联多任务损失</strong></p><p id="03d3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了改善面部定位，如上所述，级联回归与多任务丢失一起使用。第一上下文模块使用常规锚点预测边界框，然后后续模块使用回归锚点预测更准确的边界框。</p><p id="b85a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">匹配策略</strong></p><p id="0c2b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从第一上下文头模块，如果锚的IoU大于0.7，则锚匹配到基础事实框，如果其小于0.3，则锚匹配到背景，对于第二上下文头模块，如果锚的IoU大于0.5，则锚匹配到基础事实框，如果其小于0.4，则锚匹配到背景。正面和负面的培训示例是使用<a class="ae jk" href="https://nextjournal.com/tempdata73/dealing-with-class-imbalances" rel="noopener ugc nofollow" target="_blank"> OHEM </a>的天平。</p></div><div class="ab cl jl jm gp jn" role="separator"><span class="jo bw bk jp jq jr"/><span class="jo bw bk jp jq jr"/><span class="jo bw bk jp jq"/></div><div class="hb hc hd he hf"><h2 id="2857" class="kv jt hi bd ju kw kx ky jy kz la lb kc ix lc ld kg jb le lf kk jf lg lh ko li bi translated">结论</h2><p id="9d7a" class="pw-post-body-paragraph im in hi io b ip ll ir is it lm iv iw ix mj iz ja jb mk jd je jf ml jh ji jj hb bi translated">我们学习了一种新的人脸检测算法，该算法在单次拍摄中获得所有三种信息，即人脸框、人脸标志和三维人脸结构。在下一部分，我们将再次学习新的人脸检测算法。</p></div><div class="ab cl jl jm gp jn" role="separator"><span class="jo bw bk jp jq jr"/><span class="jo bw bk jp jq jr"/><span class="jo bw bk jp jq"/></div><div class="hb hc hd he hf"><h2 id="c4d5" class="kv jt hi bd ju kw kx ky jy kz la lb kc ix lc ld kg jb le lf kk jf lg lh ko li bi translated">代码和参考</h2><p id="88c8" class="pw-post-body-paragraph im in hi io b ip ll ir is it lm iv iw ix mj iz ja jb mk jd je jf ml jh ji jj hb bi translated">代码:-<a class="ae jk" href="https://github.com/deepinsight/insightface/tree/master/RetinaFace" rel="noopener ugc nofollow" target="_blank">https://github . com/deep insight/insight face/tree/master/retina face</a></p><p id="1be8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">论文:-<a class="ae jk" href="https://arxiv.org/pdf/1905.00641.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1905.00641.pdf</a></p></div></div>    
</body>
</html>