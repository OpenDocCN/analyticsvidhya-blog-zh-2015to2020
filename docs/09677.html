<html>
<head>
<title>PyTorch For Deep Learning — Saving and Loading models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于深度学习的PyTorch保存和加载模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/pytorch-for-deep-learning-saving-and-loading-models-9f81ca6a069b?source=collection_archive---------4-----------------------#2020-09-16">https://medium.com/analytics-vidhya/pytorch-for-deep-learning-saving-and-loading-models-9f81ca6a069b?source=collection_archive---------4-----------------------#2020-09-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d9ec596172fd4321ec5014c3d4b302ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WwOF2nTIuNhu1tEAe-xjgg.jpeg"/></div></div></figure><p id="93db" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本帖中，我们将看到如何在pytorch中保存和加载模型</p><h1 id="1d78" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">为什么要保存模型？</h1><p id="ceed" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">尽管正在使用框架，保存模型是一件非常重要的事情，以便随时再次使用它，而不是从头开始再次训练神经网络。</p><p id="a201" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有时，训练甚至可能需要数周才能完成。所以，每当我们需要使用我们的网络时，我们不能从一开始就训练他们。</p><p id="3ae5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当场保存模型的另一个好处是，我们可以比较两种不同的模型，选择哪一种对给定的任务更有效。</p><p id="3252" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">说到这里，让我们直接进入代码</p><ol class=""><li id="a9fa" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated"><strong class="is hj">导入一些库</strong></li></ol><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="943c" class="lj jp hi lf b fi lk ll l lm ln">#importing the libraires<br/>import torch<br/>import torch.nn as nn</span></pre><p id="eab9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2。创建虚拟线性网络</strong></p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="2caf" class="lj jp hi lf b fi lk ll l lm ln">#creating a linear model</span><span id="aac0" class="lj jp hi lf b fi lo ll l lm ln">class Model(nn.Module):<br/>  def __init__(self):<br/>    super(Model,self).__init__()<br/>    self.fc1 = nn.Linear(in_features=3,out_features=5)</span><span id="d605" class="lj jp hi lf b fi lo ll l lm ln">  def forward(self,x):<br/>    return self.fc1(x)</span></pre><p id="c707" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3。保存模型</strong></p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="cdfc" class="lj jp hi lf b fi lk ll l lm ln">#saving the model<br/>model = Model()<br/>torch.save(model,'something.h5')</span></pre><p id="18c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">torch.save是一个接受两个参数的函数。<br/>一个是模型本身。<br/>第二个是需要保存模型的文件的路径。可以使用<em class="lp"> .h5 </em>文件格式或<em class="lp">。pth </em>文件格式</p><p id="8c3e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 4。加载模型</strong></p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="59de" class="lj jp hi lf b fi lk ll l lm ln">#loading the model</span><span id="86d3" class="lj jp hi lf b fi lo ll l lm ln">loaded_model = torch.load('something.h5')</span></pre><p id="173c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">torch.load是一个函数，可用于将模型加载回变量中。<br/>它采用的参数是保存原始模型的文件的路径，并返回可以存储在python变量中的模型</p><p id="34ee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 5。将原始模型的权重与保存的模型进行比较</strong></p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="a6f0" class="lj jp hi lf b fi lk ll l lm ln">#weights of the original model</span><span id="6ee0" class="lj jp hi lf b fi lo ll l lm ln">print(model.fc1.weight)</span><span id="85a2" class="lj jp hi lf b fi lo ll l lm ln"><strong class="lf hj">output: <br/></strong>Parameter containing: <br/>tensor([[ 0.0725,  0.1615, -0.0047],<br/>        [-0.0371, -0.2640, -0.3004],         <br/>        [ 0.2129,  0.1725, -0.0136],         <br/>        [-0.5025,  0.5496,  0.0448],         <br/>        [-0.2974,  0.1040,  0.0932]], requires_grad=True)</span><span id="9977" class="lj jp hi lf b fi lo ll l lm ln">#weights of the loaded model</span><span id="61d8" class="lj jp hi lf b fi lo ll l lm ln">print(loaded_model.fc1.weight)</span><span id="b010" class="lj jp hi lf b fi lo ll l lm ln"><strong class="lf hj">output:</strong></span><span id="5837" class="lj jp hi lf b fi lo ll l lm ln">Parameter containing: <br/>tensor([[ 0.0725,  0.1615, -0.0047],<br/>        [-0.0371, -0.2640, -0.3004],         <br/>        [ 0.2129,  0.1725, -0.0136],         <br/>        [-0.5025,  0.5496,  0.0448],         <br/>        [-0.2974,  0.1040,  0.0932]], requires_grad=True)</span></pre><p id="7cf6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 6。使用加载的模型进行预测</strong></p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="6d8b" class="lj jp hi lf b fi lk ll l lm ln">#making predictions with a loaded model</span><span id="d535" class="lj jp hi lf b fi lo ll l lm ln">tensor = torch.tensor([[1,2,3]],dtype=torch.float32)<br/>loaded_model(tensor)</span><span id="3e60" class="lj jp hi lf b fi lo ll l lm ln"><strong class="lf hj">output: </strong></span><span id="49d8" class="lj jp hi lf b fi lo ll l lm ln">tensor([[ 0.7429, -1.2462,  0.4356,  1.0646,  0.5010]],        grad_fn=&lt;AddmmBackward&gt;)</span></pre><h1 id="5d3a" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">结论</h1><figure class="la lb lc ld fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/711857401a9e526247a27dde4c52c5e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*EYOmaUMRR6m1hv-K0CFFNg.jpeg"/></div></figure><p id="911d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们已经看到的，保存模型非常重要，尤其是当涉及深度神经网络时。因此，在大型项目中工作时，不要忘记保存模型。</p><p id="3371" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面的代码是在pytorch中保存模型的简单方法。还有其他方法可以做到这一点。也许，那些会在其他博客文章中涉及。</p><p id="62b4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">代码文件可以在我的github存储库中找到</p><h1 id="11c7" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">谢谢你</h1></div></div>    
</body>
</html>