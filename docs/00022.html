<html>
<head>
<title>Interpret R Linear/Multiple Regression output</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释R线性/多元回归输出</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/interpret-r-linear-multiple-regression-output-lm-output-point-by-point-also-with-python-8e53b2ee2a40?source=collection_archive---------0-----------------------#2018-02-17">https://medium.com/analytics-vidhya/interpret-r-linear-multiple-regression-output-lm-output-point-by-point-also-with-python-8e53b2ee2a40?source=collection_archive---------0-----------------------#2018-02-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="036a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">(lm逐点输出)，也是用Python</h2></div><p id="b2a2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">线性回归是非常简单、基本但非常强大的监督学习方法。这种方法非常适合于预测分析，并在进入更复杂的机器学习算法之前，建立对任何数据的通用方法。</p><p id="d304" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">线性回归已经讨论了很多，几乎所有教我们分析的书都有它的描述，互联网上有更多的资料，所以我留下了很多细节，除了基本的理解，它都是关于预测基于单个预测因子X的定量反应Y，基于它们之间存在线性关系的假设，当然，一些系数，截距也起着决定性的作用，不要忘记随机误差，它使一切更真实，几乎无处不在！！！。更多详情请见<a class="ae jt" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Linear_regression</a></p><p id="1382" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设我们对这个概念有足够的了解，并尝试用真实的东西，例如用R/Python写代码。首先，与R一起工作，并采用一个已经干净的标准数据，为什么！！！因为获取和清理数据，数据争论几乎是任何数据科学或机器学习任务的60–70%。</p><h1 id="e686" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">了解您的数据</h1><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="5504" class="kv jv hi kr b fi kw kx l ky kz">library(alr3)<br/>Loading required package: car<br/>library(corrplot)<br/>data(water) <em class="la">## load the data</em><br/>head(water) <em class="la">## view the data</em><br/> <br/>  Year APMAM APSAB APSLAKE OPBPC  OPRC OPSLAKE  BSAAM<br/>1 1948  9.13  3.58    3.91  4.10  7.43    6.47  54235<br/>2 1949  5.28  4.82    5.20  7.55 11.11   10.26  67567<br/>3 1950  4.20  3.77    3.67  9.52 12.20   11.35  66161<br/>4 1951  4.60  4.46    3.93 11.14 15.15   11.13  68094<br/>5 1952  7.15  4.99    4.88 16.34 20.05   22.81 107080<br/>6 1953  9.70  5.65    4.91  8.88  8.15    7.41  67594<br/><br/>filter.water &lt;- water[,-1] <em class="la">## Remove unwanted year </em><br/><br/><em class="la"># Visualize the data </em><br/>library(GGally)<br/>ggpairs(filter.water) <em class="la">## It's multivaribale regaression</em></span></pre><figure class="km kn ko kp fd lc er es paragraph-image"><div class="er es lb"><img src="../Images/b138a3905a009992fe3a2afad6d18104.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*TeQoEEVLxPdDdAC8jT5hTg.jpeg"/></div></figure><h1 id="11b0" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">LM魔法开始，感谢R</h1><p id="cc1a" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">就像yi = b0 + b1xi1 + b2xi2 + … bpxip + ei，i = 1，2，… n，这里y = BSAAM，x1…xn是所有其他变量</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="c1b8" class="kv jv hi kr b fi kw kx l ky kz">mlr &lt;- lm(BSAAM~., data = filter.water)<br/>summary(mlr)<br/><br/><em class="la"># Output </em><br/><br/>Call:<br/>lm(formula = BSAAM ~ ., data = filter.water)<br/><br/>Residuals:<br/>   Min     1Q Median     3Q    Max <br/>-12690  -4936  -1424   4173  18542 <br/><br/>Coefficients:<br/>            Estimate Std. Error t value Pr(&gt;|t|)    <br/>(Intercept) 15944.67    4099.80   3.889 0.000416 ***<br/>APMAM         -12.77     708.89  -0.018 0.985725    <br/>APSAB        -664.41    1522.89  -0.436 0.665237    <br/>APSLAKE      2270.68    1341.29   1.693 0.099112 .  <br/>OPBPC          69.70     461.69   0.151 0.880839    <br/>OPRC         1916.45     641.36   2.988 0.005031 ** <br/>OPSLAKE      2211.58     752.69   2.938 0.005729 ** <br/>---<br/>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1<br/><br/>Residual standard error: 7557 on 36 degrees of freedom<br/>Multiple R-squared:  0.9248,	Adjusted R-squared:  0.9123 <br/>F-statistic: 73.82 on 6 and 36 DF,  p-value: &lt; 2.2e-16</span></pre><h1 id="f3ae" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">解释输出</h1><h1 id="4667" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">残差</h1><p id="19cd" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">通常，它给出了因变量(Y)的观测值和预测值(X)之间差异的基本概念，给出了具体细节，即最小值、第一季度、中值、第三季度和最大值，通常不用于我们的分析</p><h1 id="f263" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">系数截距</h1><p id="1e18" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">我们可以看到，所有剩余变量都有一行“截距”，截距是在所有变量都为0时给出的数据，因此所有测量都不考虑任何变量，这在正常情况下也不太常用，它是x = 0时y的平均值</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="0cd1" class="kv jv hi kr b fi kw kx l ky kz"><em class="la">#            Estimate    Std. Error t value Pr(&gt;|t|)    </em><br/><em class="la"># (Intercept) 15944.67    4099.80   3.889 0.000416 ***</em></span></pre><h1 id="5f51" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">系数估计</h1><p id="f813" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">这是X的一个单位增加，然后Y的预期变化，在这种情况下，OPS LAKE的一个单位变化，然后BSAAM的2211.58个单位变化</p><h1 id="dea5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">系数-标准。错误</h1><p id="89d4" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">估计值的标准偏差称为标准误差。系数的标准误差衡量模型估计系数未知值的精确程度。系数的标准误差总是正的。</p><p id="2746" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该误差的低值将有助于我们的分析，也用于检查置信区间</p><h1 id="cd5b" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">系数-t值</h1><p id="50bb" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">t值=估计值/标准误差</p><p id="8a60" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">高t值将有助于我们的分析，因为这将表明我们可以拒绝零假设，这是用来计算p值</p><h1 id="a17d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">系数Pr(&gt;|t|)</h1><p id="645d" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">每个参数接受或拒绝零假设的单个p值，这是x和y的统计估计值。降低p值允许我们拒绝零假设。如果我们错误地分析p值，所有类型错误(真阳性/阴性、假阳性/阴性)都会出现。</p><p id="a605" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">星号旁边的p值表示该值的显著性，较低的值表示显著性较高</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="727f" class="kv jv hi kr b fi kw kx l ky kz"># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></pre><h1 id="ab6a" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">剩余标准误差</h1><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="2d62" class="kv jv hi kr b fi kw kx l ky kz">Residual standard error: 7557 on 36 degrees of freedom</span></pre><p id="4511" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在正常工作中，一个模型的平均误差，我们的模型平均预测数据的能力</p><p id="39a0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">自由度类似于考虑参数的估计中考虑的数据点的数量，不确定，但在这种情况下，我们总共有43个数据点和7个变量，因此删除了7个数据点(43–7)= 36自由度</p><h1 id="390e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">多重R平方和调整R平方</h1><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="ae2e" class="kv jv hi kr b fi kw kx l ky kz">Multiple R-squared:  0.9248,	Adjusted R-squared:  0.9123</span></pre><p id="552e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它总是在0到1之间，高值是由解释变量的变化解释的响应变量的更好的变化百分比，这用于计算模型在解释事物方面做得有多好，当我们增加变量的数量时，它也会增加，并且没有适当的限制来定义我们可以增加多少。</p><p id="aa9f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们取的是灰值，其中我们不取所有变量，在调整后的R平方中只考虑显著变量</p><h1 id="a8eb" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">f统计量</h1><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="fca4" class="kv jv hi kr b fi kw kx l ky kz">F-statistic: 73.82 on 6 and 36 DF</span></pre><p id="45a4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这显示了预测值和反应之间的关系，数值越高，拒绝零假设的理由就越多，其对整个模型的意义不在于任何特定参数</p><p id="f917" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">DF——自由度</p><h1 id="26a5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">p值</h1><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="1d3e" class="kv jv hi kr b fi kw kx l ky kz">p-value: &lt; 2.2e-16</span></pre><p id="c312" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">基于F统计的总体p值，通常p值小于0.05表示总体模型显著</p><h1 id="2ee9" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">所以巨蟒</h1><p id="2f0d" class="pw-post-body-paragraph ix iy hi iz b ja lf ij jc jd lg im jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">我使用OLS(普通最小二乘法)方法，但同样可以使用SciPy产生，它给出了更标准的结果。</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="5dea" class="kv jv hi kr b fi kw kx l ky kz">import pandas as pd<br/>import scipy.stats as stats<br/>from statsmodels.formula.api import ols</span><span id="c131" class="kv jv hi kr b fi lk kx l ky kz">mlr = ols("BSAAM~OPSLAKE+OPRC+OPBPC+APSLAKE+APSAB+APMAM", df).fit()<br/>print(mlr.summary())</span></pre><figure class="km kn ko kp fd lc er es paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="er es ll"><img src="../Images/8c27a448c8b7db87f70b7c32169ff279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s_HTtaCpY9IhAIbmhoAkBw.png"/></div></div></figure><p id="944d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">大部分参数与R输出匹配，其余参数可用于下一步研究工作:)</p><p id="ea9e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所有的描述都是基于一般的看法，如果有什么不对的地方请告诉我，我们非常欢迎您的反馈。</p></div></div>    
</body>
</html>