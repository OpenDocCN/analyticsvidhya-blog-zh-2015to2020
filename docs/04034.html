<html>
<head>
<title>Layers of a Convolutional Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络的层</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/layers-of-a-convolutional-neural-network-168daddd2dd1?source=collection_archive---------16-----------------------#2020-03-02">https://medium.com/analytics-vidhya/layers-of-a-convolutional-neural-network-168daddd2dd1?source=collection_archive---------16-----------------------#2020-03-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="6c09" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">如果我们想让机器思考，我们需要教它们看。</p><p id="06d2" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">——费·李非，斯坦福大学人工智能研究员</p></blockquote><p id="8829" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">在本系列的前一章中，我们简单介绍了卷积神经网络(CNN ),它是大多数计算机视觉算法的基本构建模块。在这一章中，我们将介绍构成我们日常CNN的重要层面。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jk"><img src="../Images/63bd240c575e6887ad48fc19e65f92b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MH-w1Q3TN8EpgDYtcCXYcg.jpeg"/></div></div><figcaption class="jw jx et er es jy jz bd b be z dx translated">CNN不同层的轮廓[4]</figcaption></figure><h1 id="3091" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak">卷积层</strong></h1><p id="9eae" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it jh la iw ix ji lb ja jb jj lc je jf jg hb bi translated">卷积层最重要的功能是使用前一层的一组连接神经元来转换输入数据。它计算输入层中神经元区域和输出层中局部连接权重之间的点积。这提供了图层的最终输出体积。这项技术是通过一种叫做卷积的概念实现的。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es ld"><img src="../Images/bc2137a18e5c7fe13bc9cb89c3d9f7a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Fsi31TJSIWKrqgCBLWWuw.jpeg"/></div></div><figcaption class="jw jx et er es jy jz bd b be z dx translated">卷积层[4]</figcaption></figure><h2 id="9504" class="le kb hi bd kc lf lg lh kg li lj lk kk jh ll lm ko ji ln lo ks jj lp lq kw lr bi translated"><strong class="ak">卷积</strong></h2><p id="8b10" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it jh la iw ix ji lb ja jb jj lc je jf jg hb bi translated">这是一种数学运算，它规定了两组信息结合在一起的性质。该操作也称为CNN的特征检测器，它对输入应用卷积核，并返回特征图作为输出。这是通过在输入数据上滑动内核并将内核与其边界内的数据段相乘来在特征图中创建单个条目来实现的。最后，沿着深度维度将每个过滤器的激活图堆叠在一起，以构建3D输出体积[1]。像任何其他神经网络模型一样，使用梯度下降进行参数优化。卷积层的主要组件如下:</p><ol class=""><li id="9872" class="ls lt hi il b im in iq ir jh lu ji lv jj lw jg lx ly lz ma bi translated"><em class="ik">过滤器:</em>这些是CNN架构参数之一，其学习对空间局部输入模式产生最强的激活，即它们将仅在模式出现在训练数据中时被激活。随着CNN深度的增加，观察到滤波器能够识别特征的非线性组合。</li><li id="3b0e" class="ls lt hi il b im mb iq mc jh md ji me jj mf jg lx ly lz ma bi translated"><em class="ik">激活图:</em>在信息通过CNN向前传递期间，通过在输入体积的空间维度上滑动每个过滤器来计算激活图。如果神经元决定传递信息，就会得到一个数值。</li></ol><h2 id="7c0f" class="le kb hi bd kc lf lg lh kg li lj lk kk jh ll lm ko ji ln lo ks jj lp lq kw lr bi translated"><strong class="ak">超参数</strong></h2><p id="a38e" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it jh la iw ix ji lb ja jb jj lc je jf jg hb bi translated">这些规定了来自卷积层的输出体积的空间排列和大小。以下是一些最重要的超参数:</p><ol class=""><li id="548c" class="ls lt hi il b im in iq ir jh lu ji lv jj lw jg lx ly lz ma bi translated"><em class="ik">滤镜尺寸:</em>它通常在空间上很小，并且拥有三个维度——宽度、高度和颜色通道。</li><li id="a028" class="ls lt hi il b im mb iq mc jh md ji me jj mf jg lx ly lz ma bi translated"><em class="ik">输出深度:</em>控制卷积层中连接到输入体积中相同区域的神经元数量。</li><li id="6039" class="ls lt hi il b im mb iq mc jh md ji me jj mf jg lx ly lz ma bi translated"><em class="ik">步幅:</em>这定义了每个应用的过滤器滑动速度。输出音量的深度与步幅值成反比。</li><li id="93ba" class="ls lt hi il b im mb iq mc jh md ji me jj mf jg lx ly lz ma bi translated"><em class="ik">补零:</em>它决定了输出体积的空间大小，在输出体积中优先保持输入体积的空间大小时非常有用。</li></ol><h1 id="00cc" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">汇集层</h1><p id="7171" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it jh la iw ix ji lb ja jb jj lc je jf jg hb bi translated">该图层有助于逐步减小数据表示的空间大小，从而防止过度拟合训练数据。这些通常包含在连续的卷积层之间，并使用最大运算在空间上调整输入数据的大小。池层没有任何可学习的参数，通常有零填充。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es mg"><img src="../Images/5bfc88d58e2e994e81eb5fdd190c7666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZmTflAA_lqLaRB7ZIkevrg.png"/></div></div><figcaption class="jw jx et er es jy jz bd b be z dx translated">池层[4]</figcaption></figure><h1 id="1cba" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">全连接层</h1><p id="d372" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it jh la iw ix ji lb ja jb jj lc je jf jg hb bi translated">该图层充当网络的输出图层，其输出体积维度为[1 x 1 x N]，其中N是要评估的输出类的数量。全连接层具有通用神经网络层参数和超参数。</p><p id="3a3c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">在本文中，我们讨论了不同类型的层——卷积层、池层和卷积神经网络的全连接层，说明了每一层的重要性和效用。这结束了我们对CNN的部分。在本系列的后续章节中，我们将重点介绍不同种类的人工神经网络，如递归神经网络(RNNs)和长短期记忆网络，它们在自然语言处理和翻译领域有着独特的应用。</p></div><div class="ab cl mh mi gp mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="hb hc hd he hf"><p id="6ff6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">[1]谭耀辉和陈春生，2019。基于短语的分层LSTM网络图像字幕生成器。神经计算，333页，第86-100页。</p><p id="0850" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">[2]帕特森，j .，2017。深度学习。第一版。由…编辑O'Reilly媒体公司。</p><p id="ff70" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">[3]博登，m .，2002年。递归神经网络和反向传播指南。达拉斯项目。</p><p id="5b34" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">[4]Brilliant.org。(2020).<em class="ik">卷积神经网络|辉煌数学&amp;科学维基</em>。[在线]可在https://brilliant.org/wiki/convolutional-neural-network<a class="ae mo" href="https://brilliant.org/wiki/convolutional-neural-network" rel="noopener ugc nofollow" target="_blank"/>【2020年2月29日访问】。</p></div></div>    
</body>
</html>