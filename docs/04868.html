<html>
<head>
<title>How spark executes the code written in Structured API(dataframes, datasets, and SQL)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">spark如何执行用结构化API编写的代码(数据帧、数据集和SQL)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-spark-executes-the-code-written-in-structured-api-dataframes-datasets-and-sql-c344335740ef?source=collection_archive---------16-----------------------#2020-04-03">https://medium.com/analytics-vidhya/how-spark-executes-the-code-written-in-structured-api-dataframes-datasets-and-sql-c344335740ef?source=collection_archive---------16-----------------------#2020-04-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/875409359711f8e270c9522b55361c2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1uBRYfqNXChgeF9Tv279qg.jpeg"/></div></div></figure><p id="9305" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用结构化API编写的代码按以下方式执行:</p><ul class=""><li id="08af" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">首先，包含数据框、数据集或SQL <em class="jx">代码的代码通过控制台或提交的作业提交</em>给spark。</li></ul><figure class="jz ka kb kc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jy"><img src="../Images/7ffd6a943bd43741e31b6b08deb33540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-O7DWRFEbBWw_1PKJkIKkA.png"/></div></div></figure><ul class=""><li id="c865" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">然后如果代码正确，就转换成<em class="jx">逻辑计划</em>。</li></ul><figure class="jz ka kb kc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kd"><img src="../Images/0cbdcb4097c5d912cf46694d83902917.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tPLskEHtkbN8q2_4O-mk7w.png"/></div></div></figure><p id="2ae7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">逻辑规划与执行者或驱动者没有联系，它只是一组抽象的转换。旨在将用户给定的表情转换成<em class="jx">最佳版本</em>。这是通过将用户代码转换成<em class="jx">未解析的逻辑计划</em>来完成的。如果用户表达式中有任何spark analyzer无法解析的引用，那么它将拒绝未解析的逻辑计划。如果分析器通过了未解决的逻辑计划(成为<em class="jx">已解决的逻辑计划</em>，那么它被进一步传递给catalyst优化器。这将通过下推谓词或选择优化逻辑计划，并提供<em class="jx">优化的逻辑计划</em>。</p><ul class=""><li id="4a89" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">现在，物理规划过程开始，物理规划也被称为<em class="jx">星火计划。</em></li></ul><figure class="jz ka kb kc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ke"><img src="../Images/f8d8d1129c5d47c004c0dbe48a4e75fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BMxPLwljJGvq7MsJD3Ps_g.png"/></div></div></figure><p id="ed33" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark Plan指定如何在集群上执行获得的逻辑计划。它通过生成不同的物理执行策略并在成本模型的帮助下对它们进行比较来做到这一点。</p><p id="869f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jx">比较示例1: </em> </strong>如何通过查看表的物理属性来执行连接。</p><p id="3264" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jx">比较示例2: </em> </strong>查找最佳执行顺序，查询将按照该顺序执行，从而得到优化的结果。例如，假设在一个查询中，我们必须通过连接表来过滤掉一些候选人的信息。因此，最佳的物理计划应该是，首先过滤候选项，然后连接表，并显示结果。尽管存在另一种方法，即首先连接表，然后过滤并显示结果，但这在资源方面是很昂贵的。</p><p id="db7c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">物理规划给出了一系列的RDD和变换。这就是为什么Spark被称为<em class="jx">编译器</em>的原因，因为它接受数据帧、数据集和SQL代码，并将它们编译成RDD变换。</p><ul class=""><li id="f809" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">最后，完成物理计划的执行。在运行时，spark做了进一步的优化，通过生成本地Java字节码，它能够在执行过程中根据几个条件删除整个任务或阶段。现在，输出终于返回给用户了。</li></ul></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><p id="2d25" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这都是关于用结构化API编写的代码的火花执行。希望它清晰、明快、易于理解。</p></div></div>    
</body>
</html>