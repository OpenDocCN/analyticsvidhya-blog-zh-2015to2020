<html>
<head>
<title>Convolutional Neural Networks Recommender</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络推荐器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/modern-visual-recsys-part4-convolutional-neural-networks-recommender-c4174644ab0d?source=collection_archive---------12-----------------------#2020-03-20">https://medium.com/analytics-vidhya/modern-visual-recsys-part4-convolutional-neural-networks-recommender-c4174644ab0d?source=collection_archive---------12-----------------------#2020-03-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/4eb866302c29802a50e2ce8b3ff101d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tDEPgijshutIAZ0IsO_twQ.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">左边是目标图像，右边是由我们的模型生成的建议。服装从<a class="ae hv" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank"> DeepFashion、</a>开源由<a class="ae hv" href="https://liuziwei7.github.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd hw">刘z等人</strong> </a></figcaption></figure><h2 id="fe12" class="hx hy hz bd b fp ia ib ic id ie if dx ig translated" aria-label="kicker paragraph">现代RecSys</h2><div class=""/><div class=""><h2 id="36f2" class="pw-subtitle-paragraph jg ii hz bd b jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx dx translated">我们将使用transfer learning、Spotify的Annoy、PyTorch构建一个推荐器，并在2毫秒内返回240，000张图片中视觉上相似的产品</h2></div><p id="7f92" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">这是我的现代视觉RecSys系列的一部分；请在文章末尾随意查看该系列的其余部分。</p><h1 id="9a52" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">数据</h1><p id="1bca" class="pw-post-body-paragraph jy jz hz ka b kb ll jk kd ke lm jn kg kh ln kj kk kl lo kn ko kp lp kr ks kt hb bi translated">我们将使用<strong class="ka ij"/><a class="ae hv" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank"><strong class="ka ij">deep fashion</strong></a><strong class="ka ij">数据的子集，由香港中文大学刘z .等人</strong>开源。我们的数据由46个类别的28万张时尚图片组成。你可以从他们的网站上下载数据。T19】</p><p id="01e8" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">此外，团队已经发布了一个<a class="ae hv" href="https://github.com/switchablenorms/DeepFashion2" rel="noopener ugc nofollow" target="_blank">更新版本，增加了</a>的数据。你需要<a class="ae hv" href="https://docs.google.com/forms/d/e/1FAIpQLSeIoGaFfCQILrtIZPykkr8q_h9qQ5BoTYbjvf95aXbid0v2Bw/viewform?usp=sf_link" rel="noopener ugc nofollow" target="_blank">填写一份谷歌表格</a>来获取数据。</p><h1 id="e01f" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">什么是卷积？</h1><p id="437d" class="pw-post-body-paragraph jy jz hz ka b kb ll jk kd ke lm jn kg kh ln kj kk kl lo kn ko kp lp kr ks kt hb bi translated">卷积并不是一项新技术。本质上，我们正在对图像中的每个像素应用内核以实现一个目标，通常是模糊、锐化或检测边缘/对象。对于每个像素，我们将用内核做一个元素级的乘积，然后将结果相加得到一个单一的数。</p><p id="dbe8" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">让我们看一个由Victor Powell 开发的image <a class="ae hv" href="https://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">内核工具的例子。</a></p><figure class="lr ls lt lu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lq"><img src="../Images/130a153844a0ada832e6a48d98fe3ecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ls32N8k6ZbjVpl5l2oc1A.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">基本图像。来源:<a class="ae hv" href="https://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">图像内核</a>作者<a class="ae hv" href="http://twitter.com/vicapow" rel="noopener ugc nofollow" target="_blank">维克多·鲍威尔</a></figcaption></figure><p id="2f20" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">我们可以看到，图像的每个像素都有一个与之关联的颜色值，其中白色=255，黑色= 0。</p><figure class="lr ls lt lu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lv"><img src="../Images/d4b4d8b8a8e3d9c09e51ed5c25f1ba64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oja_6Az96lTJFP8Hm4ydZA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">采摘内核。来源:<a class="ae hv" href="https://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">图像内核</a>作者<a class="ae hv" href="http://twitter.com/vicapow" rel="noopener ugc nofollow" target="_blank">维克多·鲍威尔</a></figcaption></figure><p id="81f0" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">接下来，我们将挑选内核。内核可以是任意大小，但是当然，小内核扫描大图像需要更长的时间。<a class="ae hv" href="https://en.wikipedia.org/wiki/Sobel_operator" rel="noopener ugc nofollow" target="_blank"> Sobel </a>是一种无处不在的边缘检测算法，具有平滑功能，因此不易受噪声影响。注意有不同种类的Sobel(上、下、左、右),就像它们的名字一样，这些内核被设计成拾取图像的特定成分。</p><figure class="lr ls lt lu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lw"><img src="../Images/8b678d1c769a77edb27dbd9223ee0910.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*63CHendCrhrDJOOlx4COtQ.gif"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">这是卷积。来源:<a class="ae hv" href="https://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">图片内核</a>作者<a class="ae hv" href="http://twitter.com/vicapow" rel="noopener ugc nofollow" target="_blank">维克多·鲍威尔</a></figcaption></figure><p id="0235" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">正如您从动画中看到的，我们实际上是在图像中移动一个3x3内核，生成新的分数并将它们分配给输出图像。你会注意到，在应用底部Sobel后，只有部分输出图像以白色突出显示；这些白色部分是底部Sobel检测到的底部边缘。</p><blockquote class="lx"><p id="25d9" class="ly lz hz bd ma mb mc md me mf mg kt dx translated">由于每个内核专门检测图像的一个方面，你可以想象我们将不同的内核堆叠起来，制定一个全面的策略。事实的确如此，内核的集合被称为过滤器。在CNN中，我们甚至可以堆叠多层过滤器，每个过滤器都有特定的任务。</p></blockquote><p id="ef4f" class="pw-post-body-paragraph jy jz hz ka b kb mh jk kd ke mi jn kg kh mj kj kk kl mk kn ko kp ml kr ks kt hb bi translated">如果你有兴趣，你应该用不同类型的内核亲自测试一下这个工具。CNN是一个迷人的模型，因为它结合了卷积和神经网络的力量。有许多不同的架构，但通常由<a class="ae hv" href="https://algobeans.com/2016/01/26/introduction-to-convolutional-neural-network/" rel="noopener ugc nofollow" target="_blank">卷积、子采样、激活和完全连接的组合组成，如Algobeans </a>所述。您可以在附加资源部分了解更多关于内核和CNN的信息。</p><h1 id="e4e1" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">为什么CNN做视觉推荐？</h1><figure class="lr ls lt lu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mm"><img src="../Images/21a00114947710d607c21c45bd0900b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CrEn0opfPGlYrIgzB-GduA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">过滤器14、242、250和253的特写。来源:<a class="ae hv" href="https://benanne.github.io/2014/08/05/spotify-cnns.html#" rel="noopener ugc nofollow" target="_blank">推荐Spotify幻灯片上的音乐</a>作者<a class="ae hv" href="https://benanne.github.io/about/" rel="noopener ugc nofollow" target="_blank">桑德·迪勒曼</a></figcaption></figure><p id="ea2d" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">现在是回顾我们在本系列第1部分所学内容的绝佳时机。【Spotify的Sander设计了一个带有过滤器的CNN，根据音乐的频率模式来检测不同类型的音乐。CNN开创了一种全新的推荐音乐的方式，这种方式<strong class="ka ij">直观、</strong>，因为它是基于对音乐结构的分析和理解。机器缺乏理解和欣赏音乐的自然能力；CNN帮助弥合差距。</p><blockquote class="lx"><p id="118b" class="ly lz hz bd ma mb mc md me mf mg kt dx translated">CNN的强大之处在于它能够将复杂的视觉问题分解成一层层的过滤器——通常我们可以将这些过滤器可视化，以获得模型试图学习什么的直觉。</p></blockquote><figure class="mo mp mq mr ms hk er es paragraph-image"><div class="er es mn"><img src="../Images/c5b6429d1978f4d437e3b41e121bd23d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*avh0eZ6nF8DFLVCXgoPjVQ.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">基于CNN的推荐。来源:<a class="ae hv" href="https://symj07.wordpress.com/2018/03/19/poshnet/" rel="noopener ugc nofollow" target="_blank">波什内特</a>作者:<a class="ae hv" href="https://symj07.wordpress.com/author/windflower715hotmailcom/" rel="noopener ugc nofollow" target="_blank">夏元</a></figcaption></figure><p id="52cb" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">因此，我们的目标是构建一个CNN，它可以根据与输入图像的视觉相似性推荐商品。CNN可以应用于各种各样的视觉问题，我在下面收集了一些很棒的文章。请注意，在下一章的<a class="ae hv" rel="noopener" href="/@thiakx/modern-visual-recsys-part4b-covid-19-case-study-with-cnn-5f07fd93a11a">中，我们将调整CNN流程，以识别感染严重程度相似的X射线图像簇。</a></p><figure class="lr ls lt lu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mt"><img src="../Images/7bf7042c163bd5fcd10cece4e0e56e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f1-CfVAOaw1KuQAGp8W8cA.jpeg"/></div></div></figure><p id="90c5" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated"><em class="mu">严重感染的X射线扫描，由我们的模型生成36个最相似的扫描。来源:</em> <a class="ae hv" href="https://github.com/ieee8023/covid-chestxray-dataset" rel="noopener ugc nofollow" target="_blank"> <em class="mu">新冠肺炎影像资料收集</em> </a> <em class="mu">由</em> <a class="ae hv" href="https://josephpcohen.com/w/" rel="noopener ugc nofollow" target="_blank"> <em class="mu">约瑟夫·科恩</em> </a></p><ul class=""><li id="4e0b" class="mv mw hz ka b kb kc ke kf kh mx kl my kp mz kt na nb nc nd bi translated"><a class="ae hv" href="http://ai.sensilab.monash.edu/2018/09/17/similarity-search-engine/" rel="noopener ugc nofollow" target="_blank">搜索莫纳什·森西拉布的视觉相似艺术品</a></li><li id="bbdd" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://towardsdatascience.com/finding-familiar-faces-with-a-tensorflow-object-detector-pytorch-feature-extractor-and-spotifys-3e78858a8148" rel="noopener" target="_blank">使用Tensorflow对象检测器、Pytorch特征提取器和Spotify的Annoy寻找熟悉的面孔(在动漫角色中)</a></li><li id="ad86" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://blog.usejournal.com/fastai-image-similarity-search-pytorch-hooks-spotifys-annoy-9161bf517aaf" rel="noopener ugc nofollow" target="_blank"> Fastai —图片相似性搜索— Pytorch Hooks &amp; Spotify被Abhik Jha惹恼</a></li><li id="eef5" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://towardsdatascience.com/similar-images-recommendations-using-fastai-and-annoy-16d6ceb3b809" rel="noopener" target="_blank">gau tham Kumar an使用FastAi和Annoy推荐相似图片</a></li></ul><h1 id="270b" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">迁移学习:利用预先训练的深度CNN</h1><figure class="lr ls lt lu fd hk er es paragraph-image"><div class="er es nj"><img src="../Images/cf4631fa85ed3abd35c8a82339e3e8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*CnMaVu8eWoD9nnM6rBqMgw.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated"><a class="ae hv" href="https://arxiv.org/pdf/1810.00736.pdf" rel="noopener ugc nofollow" target="_blank">代表性深度神经网络架构基准分析(2018) </a>。来源:<a class="ae hv" href="https://arxiv.org" rel="noopener ugc nofollow" target="_blank">arxiv</a>s . Bianco等人。</figcaption></figure><blockquote class="lx"><p id="6fe4" class="ly lz hz bd ma mb nk nl nm nn no kt dx translated"><strong class="ak">对于大多数现实部署，我们不会从头开始训练CNN。</strong>多年来，像微软研究院这样的组织已经发布了最先进的、大规模的、预训练的深度CNN (DCNN)模型，我们应该通过在他们的基线模型上进行训练来利用他们的工作。这就是所谓的迁移学习。</p></blockquote><figure class="mo mp mq mr ms hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es np"><img src="../Images/9fd07f233c05340e05486e098f012725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8vDlURGKX711IUrogIu9uw.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">ResNet架构。18层ResNet是测试模型的优秀基准，而152层是很好的通用模型。来源:<a class="ae hv" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a>作者<a class="ae hv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K" rel="noopener ugc nofollow" target="_blank">何k等人</a>。</figcaption></figure><p id="d0fb" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">标准的预训练DCNN之一是ResNet。更深的网络具有更好地表示输入函数的潜力。深层网络的问题是消失梯度问题，因为我们需要重复乘以小数字来进行反向传播。ResNet通过跳过一层或多层的<strong class="ka ij">身份快捷连接解决了这个问题</strong>，允许我们构建非常深的网络，这些网络可以很好地概括各种问题。关于ResNet的更多细节，请参见进一步阅读部分。</p><h1 id="605d" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">用airy近似最近邻</h1><div class="lr ls lt lu fd ab cb"><figure class="nq hk nr ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/aba7adb4d6bf01e5ac342f9383950356.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/1*z3AtogfYPXWM_GdZAcuQKw.gif"/></div></figure><figure class="nq hk nw ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><img src="../Images/68444603965a21afb2ac467c2c7d7dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*IbgjQFZW4tHjmTG-wKKr8A.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx nx di ny nz translated"><a class="ae hv" href="https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html" rel="noopener ugc nofollow" target="_blank">谁说二叉树只对Leetcode面试有用？</a>来源<a class="ae hv" href="https://github.com/spotify/annoy" rel="noopener ugc nofollow" target="_blank">被<a class="ae hv" href="https://erikbern.com/about.html" rel="noopener ugc nofollow" target="_blank">埃里克</a>惹恼</a></figcaption></figure></div><p id="82a8" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">如果我们只有一个小的图像搜索语料库，简单的距离度量，如余弦相似性将工作。在现实世界的部署中，比如电子商务，我们通常有数百万张图片需要相互比较，API对每张图片进行成对比较是不切实际的。Spotify的Erik Bernhardsson开发了一个易于使用的API，可以集成到我们的PyTorch工作流程中。</p><blockquote class="lx"><p id="f279" class="ly lz hz bd ma mb mc md me mf mg kt dx translated">更重要的是，它帮助我们找到最近的邻居，而不需要计算每张图像之间的成对距离。</p></blockquote><p id="a068" class="pw-post-body-paragraph jy jz hz ka b kb mh jk kd ke mi jn kg kh mj kj kk kl mk kn ko kp ml kr ks kt hb bi translated">如果你有兴趣了解更多关于aroy的知识，请查看进一步阅读中Erik的文章。</p><h1 id="2caf" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">代码</h1><p id="64ae" class="pw-post-body-paragraph jy jz hz ka b kb ll jk kd ke lm jn kg kh ln kj kk kl lo kn ko kp lp kr ks kt hb bi translated">请参考<a class="ae hv" href="https://towardsdatascience.com/building-a-personalized-real-time-fashion-collection-recommender-22dc90c150cb" rel="noopener" target="_blank">https://towards data science . com/building-a-personalized-real-time-fashion-collection-recommender-22 DC 90 c 150 CB</a></p><h1 id="686e" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">查看来自推荐者的结果</h1><p id="0af1" class="pw-post-body-paragraph jy jz hz ka b kb ll jk kd ke lm jn kg kh ln kj kk kl lo kn ko kp lp kr ks kt hb bi translated">让我们看看推荐者的结果。比如我们观察到有些单品比较容易推荐，比如这件条纹毛衣。</p><figure class="lr ls lt lu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/0ff8eb0f1a74df4e1a668b86c96bd609.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0teTMPPgA9ZojwedCdlVCw.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">左边是目标图像，右边是由我们的模型生成的建议。服装来自<a class="ae hv" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank"> DeepFashion，</a>开源由<a class="ae hv" href="https://liuziwei7.github.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd hw">刘z等人</strong> </a></figcaption></figure><p id="f669" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">白色牛仔裤稍微硬一点；我们似乎以打底裤、黑色裤子和蓝色牛仔裤的搭配结束。</p><figure class="lr ls lt lu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/d2d695d7f68212daaefc52172c8fd883.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fG9xEqMyOWbGiPB9EpVMGg.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">左边是目标图像，右边是由我们的模型生成的建议。服装来自<a class="ae hv" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank"> DeepFashion，</a>开源由<a class="ae hv" href="https://liuziwei7.github.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd hw">刘z等人</strong> </a></figcaption></figure><p id="be10" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">虽然这…有趣的装备导致非常多样的一套建议。搭配复杂的颜色、层次和服装似乎很有挑战性。</p><figure class="lr ls lt lu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/27e580180ab6b2ffc96741e6775f4ac1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvqsxnEHYZLqCF_q9yWOPQ.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">左边是目标图像，右边是由我们的模型生成的建议。服装来自<a class="ae hv" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank"> DeepFashion，</a>开源来自<a class="ae hv" href="https://liuziwei7.github.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd hw">刘z等人</strong> </a></figcaption></figure><h1 id="4208" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">我们学到了什么</h1><p id="6865" class="pw-post-body-paragraph jy jz hz ka b kb ll jk kd ke lm jn kg kh ln kj kk kl lo kn ko kp lp kr ks kt hb bi translated">在这一章中，我们将探讨CNN在推荐中的应用。我们在这里使用了一些先进的技术，但是通过像ResNet、Fastai、aroy这样的现代工具，我们可以部署一个强大的推荐器，它可以立即生成新的推荐。</p><h1 id="40fa" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">探索现代视觉RecSys系列的其余部分</h1><div class="hh hi ez fb hj oa"><a rel="noopener follow" target="_blank" href="/@thiakx/modern-visual-recsys-part1-introduction-1241c02f76d6"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ij fi z dy of ea eb og ed ef ii bi translated">现代视觉推荐系统:推荐器是如何工作的？[基础]</h2><div class="oh l"><h3 class="bd b fi z dy of ea eb og ed ef dx translated">在这一系列文章中，我将介绍视觉推荐系统的现代方法。我们从一个案例开始…</h3></div><div class="oi l"><p class="bd b fp z dy of ea eb og ed ef dx translated">medium.com</p></div></div><div class="oj l"><div class="ok l ol om on oj oo hp oa"/></div></div></a></div><div class="hh hi ez fb hj oa"><a rel="noopener follow" target="_blank" href="/@thiakx/modern-visual-recsys-part2-the-recsys-design-framework-30d2352fff34"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ij fi z dy of ea eb og ed ef ii bi translated">现代视觉RecSys:如何设计推荐器？[基础]</h2><div class="oh l"><h3 class="bd b fi z dy of ea eb og ed ef dx translated">对于这一章，我将通过亚马逊的案例研究来介绍RecSys设计框架。</h3></div><div class="oi l"><p class="bd b fp z dy of ea eb og ed ef dx translated">medium.com</p></div></div><div class="oj l"><div class="op l ol om on oj oo hp oa"/></div></div></a></div><div class="hh hi ez fb hj oa"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/intro-to-visual-recsys-12d54976c521"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ij fi z dy of ea eb og ed ef ii bi translated">现代视觉记录系统:视觉记录系统介绍[核心]</h2><div class="oh l"><h3 class="bd b fi z dy of ea eb og ed ef dx translated">我们将探索视觉模型的“hello world”数据，来自Zalando和PyTorch的FashionMNIST数据集…</h3></div><div class="oi l"><p class="bd b fp z dy of ea eb og ed ef dx translated">medium.com</p></div></div><div class="oj l"><div class="oq l ol om on oj oo hp oa"/></div></div></a></div><div class="hh hi ez fb hj oa"><a rel="noopener follow" target="_blank" href="/@thiakx/modern-visual-recsys-part4b-covid-19-case-study-with-cnn-5f07fd93a11a"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ij fi z dy of ea eb og ed ef ii bi translated">现代视觉再现系统:CNN的新冠肺炎案例研究</h2><div class="oh l"><h3 class="bd b fi z dy of ea eb og ed ef dx translated">我们将使用迁移学习、Spotify的……通过CNN RecSys流程，根据严重程度对新冠肺炎x光图像进行聚类</h3></div><div class="oi l"><p class="bd b fp z dy of ea eb og ed ef dx translated">medium.com</p></div></div><div class="oj l"><div class="or l ol om on oj oo hp oa"/></div></div></a></div><div class="hh hi ez fb hj oa"><a href="https://towardsdatascience.com/building-a-personalized-real-time-fashion-collection-recommender-22dc90c150cb" rel="noopener follow" target="_blank"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ij fi z dy of ea eb og ed ef ii bi translated">构建个性化的实时时尚收藏推荐器[Pro]</h2><div class="oh l"><h3 class="bd b fi z dy of ea eb og ed ef dx translated">我们将利用PyTorch中的迁移学习、近似最近邻和嵌入质心检测来实现</h3></div><div class="oi l"><p class="bd b fp z dy of ea eb og ed ef dx translated">towardsdatascience.com</p></div></div><div class="oj l"><div class="os l ol om on oj oo hp oa"/></div></div></a></div><div class="hh hi ez fb hj oa"><a href="https://towardsdatascience.com/temporal-fashion-recommender-59c26313fa25" rel="noopener follow" target="_blank"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ij fi z dy of ea eb og ed ef ii bi translated">时尚推荐者</h2><div class="oh l"><h3 class="bd b fi z dy of ea eb og ed ef dx translated">建立一个随季节变化的推荐器</h3></div><div class="oi l"><p class="bd b fp z dy of ea eb og ed ef dx translated">towardsdatascience.com</p></div></div><div class="oj l"><div class="ot l ol om on oj oo hp oa"/></div></div></a></div><div class="hh hi ez fb hj oa"><a rel="noopener follow" target="_blank" href="/@thiakx/the-future-of-visual-recommender-systems-four-practical-state-of-the-art-techniques-bae9f3e4c27f"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ij fi z dy of ea eb og ed ef ii bi translated">视觉推荐系统的未来:四种实用的最新技术</h2><div class="oh l"><h3 class="bd b fi z dy of ea eb og ed ef dx translated">visual RecSys的未来令人振奋。让我们探索一些最前沿的技术和想法…</h3></div><div class="oi l"><p class="bd b fp z dy of ea eb og ed ef dx translated">medium.com</p></div></div><div class="oj l"><div class="ou l ol om on oj oo hp oa"/></div></div></a></div><p id="d0fd" class="pw-post-body-paragraph jy jz hz ka b kb kc jk kd ke kf jn kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">系列标签:</p><ul class=""><li id="b2be" class="mv mw hz ka b kb kc ke kf kh mx kl my kp mz kt na nb nc nd bi translated">基础:一般知识和理论，需要最低限度的编码经验。</li><li id="050b" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated">核心:更具挑战性的材料与代码。</li><li id="86a0" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated">亲:难的材料和代码，用生产级的工具。</li></ul><h1 id="5eb7" class="ku kv hz bd hw kw kx ky kz la lb lc ld jp le jq lf js lg jt lh jv li jw lj lk bi translated">进一步阅读</h1><ul class=""><li id="2e88" class="mv mw hz ka b kb ll ke lm kh ov kl ow kp ox kt na nb nc nd bi translated"><a class="ae hv" href="https://towardsdatascience.com/types-of-convolution-kernels-simplified-f040cb307c37" rel="noopener" target="_blank">卷积核的类型:简化的</a></li><li id="3e69" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://aishack.in/tutorials/image-convolution-examples/" rel="noopener ugc nofollow" target="_blank">图像卷积示例</a></li><li id="4db9" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://youtu.be/YRhxdVk_sIs" rel="noopener ugc nofollow" target="_blank">由deeplizard(视频)解释的卷积神经网络(CNN)</a></li><li id="a9c0" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://algobeans.com/2016/01/26/introduction-to-convolutional-neural-network/" rel="noopener ugc nofollow" target="_blank">卷积神经网络(CNN)简介</a></li><li id="ef91" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/" rel="noopener ugc nofollow" target="_blank">理解卷积神经网络的初学者指南</a></li><li id="548c" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://towardsdatascience.com/build-a-fashion-mnist-cnn-pytorch-style-efb297e22582" rel="noopener" target="_blank">让我们打造一个时尚——MNIST CNN，PyTorch Style </a></li><li id="e02e" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://symj07.wordpress.com/2018/03/19/poshnet/" rel="noopener ugc nofollow" target="_blank"> PoshNet:你的个人虚拟衣橱</a></li><li id="3c9d" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035" rel="noopener" target="_blank">ResNet及其变体的概述</a></li><li id="643f" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://towardsdatascience.com/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc" rel="noopener" target="_blank">回顾:Inception-v4——从GoogLeNet演化而来，与ResNet Idea(图像分类)合并</a></li><li id="17e3" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202" rel="noopener" target="_blank">盗梦空间网络版本的简单指南</a></li><li id="6d37" class="mv mw hz ka b kb ne ke nf kh ng kl nh kp ni kt na nb nc nd bi translated"><a class="ae hv" href="https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html" rel="noopener ugc nofollow" target="_blank">埃里克:骚扰:最近邻和向量模型——第二部分——算法和数据结构</a></li></ul></div></div>    
</body>
</html>