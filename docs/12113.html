<html>
<head>
<title>License Plate Detection on Indian Cars using YOLOv3 and Blurring of License Plates</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 YOLOv3 和车牌模糊的印度汽车牌照检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/license-plate-detection-on-indian-cars-using-yolov3-and-blurring-of-license-plates-9f2a24d48f04?source=collection_archive---------3-----------------------#2020-12-31">https://medium.com/analytics-vidhya/license-plate-detection-on-indian-cars-using-yolov3-and-blurring-of-license-plates-9f2a24d48f04?source=collection_archive---------3-----------------------#2020-12-31</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class="ev ex ie if ig ab cb"><figure class="ih ii ij ik il im in paragraph-image"><div role="button" tabindex="0" class="io ip di iq bf ir"><img src="../Images/79efbcbc8f08e953d6c09e66f4f75877.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*ethXfsJHXA2MLj8rUzNYwQ.png"/></div></figure><figure class="ih ii iu ik il im in paragraph-image"><div role="button" tabindex="0" class="io ip di iq bf ir"><img src="../Images/d6490a01d97d04608ed81d1b87e4c6d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*TmGxFWWin0Px4PHuY9B6CA.png"/></div><figcaption class="iv iw et er es ix iy bd b be z dx iz di ja jb translated">具有车牌检测和模糊的汽车图像</figcaption></figure></div><h2 id="44b0" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">介绍</h2><p id="c429" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku ha bi translated">自动车牌识别系统被执法机构、交通管理、控制机构、各种政府和非政府机构广泛使用。ANPR 还广泛应用于商业领域，如电子收费、个人安全、访客管理系统、停车管理等。</p><p id="8a47" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">本文将介绍检测和隐藏印度汽车牌照的用例。这个用例用于在线汽车转售公司，用户发布汽车图片进行销售。</p><p id="a3df" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">Google Colab 在本文中用于模型训练。你可以从这个<a class="ae la" href="https://colab.research.google.com/notebooks/intro.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a>了解更多关于 Google Colab 的信息。</p><h1 id="b8d9" class="lb jd hh bd je lc ld le ji lf lg lh jm li lj lk jq ll lm ln ju lo lp lq jy lr bi translated">步骤 1:准备数据集</h1><p id="ce31" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku ha bi translated">a.把有车牌的印度车拍下来。创建两个文件夹“测试”和“训练”,分别传输测试文件夹中 20%的图像和训练文件夹中 80%的图像。</p><p id="732a" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">或者，您可以使用我用于训练的测试和训练数据。请参考<a class="ae la" href="https://github.com/CodinjaoftheWorld/ANPR_INDIANCARS_YOLOV3" rel="noopener ugc nofollow" target="_blank"> Github 库</a>访问带有注释文件的测试和训练文件夹。</p><p id="589b" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">b.使用 LabelImg 对各个测试和训练文件夹中的所有图像中的牌照进行注释，并生成带注释的。各个文件夹中图像的 xml 文件。你可以从<a class="ae la" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">这里</a>获得更多关于标签的细节。</p><p id="2c82" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">这里值得一提的是，LabelImg 可以帮助你生成 2 种格式的注释。第一种是帕斯卡沃克格式，另一种是 YOLO 格式。</p><p id="7cac" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">在 LabelImg 的左窗格中提供了选择格式的选项。一旦你点击了一种 PascalVOC 格式，它就会切换到另一种格式。</p><p id="f6c2" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">YOLO 要求一个具体的。带有带标签的边界框细节的 txt 文件。所以你可以生成 YOLO 兼容的。txt 文件，也可以生成 pascalVOC 兼容的。xml 文件，并在以后将它们转换成 YOLO 兼容格式。(转换过程在步骤 3 中提到)</p><h1 id="a3fa" class="lb jd hh bd je lc ld le ji lf lg lh jm li lj lk jq ll lm ln ju lo lp lq jy lr bi translated">步骤 2:安装基础暗网系统</h1><p id="4ebf" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku ha bi translated">安装 Google Drive</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="3373" class="jc jd hh lx b fi mb mc l md me">from google.colab import drive<br/>drive.mount('/content/gdrive')</span><span id="8d37" class="jc jd hh lx b fi mf mc l md me">%cd /content/gdrive/MyDrive</span></pre><p id="2373" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">下载 YOLOv3 项目</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="bfe0" class="jc jd hh lx b fi mb mc l md me">! git clone <a class="ae la" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexeyAB/darknet</a></span></pre><p id="2ac4" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">打开 darknet/Makefile，在 GPU、CUDNN、OPENCV 前面放 1 而不是 0。如果你想在 google colab 上使用 GPU，这些改变是必需的。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="4d5f" class="jc jd hh lx b fi mb mc l md me">GPU=1</span><span id="cf52" class="jc jd hh lx b fi mf mc l md me">CUDNN=1</span><span id="ec5e" class="jc jd hh lx b fi mf mc l md me">CUDNN_HALF=0</span><span id="c950" class="jc jd hh lx b fi mf mc l md me">OPENCV=1</span></pre><p id="3891" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">用下面的命令安装基础 darknet 框架。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="2bed" class="jc jd hh lx b fi mb mc l md me">%cd darknet <br/>! make</span></pre><h1 id="ed70" class="lb jd hh bd je lc ld le ji lf lg lh jm li lj lk jq ll lm ln ju lo lp lq jy lr bi translated">步骤 3:在 Google Colab 中上传图片并生成 YOLO 兼容的注释文件</h1><p id="abd8" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku ha bi translated">从<a class="ae la" href="https://github.com/CodinjaoftheWorld/ANPR_INDIANCARS_YOLOV3" rel="noopener ugc nofollow" target="_blank"> Github 库</a>中解压缩 test.zip 和 train.zip 文件，并将它们上传到 darknet 目录中，或者手动将您的注释图像与 convert.py 文件一起上传到 darknet 目录中的 test 和 train 文件夹中。</p><p id="3b1c" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">将边框坐标从。xml 文件添加到。txt 文件(YOLO 兼容格式)。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="0627" class="jc jd hh lx b fi mb mc l md me">! python convert.py</span></pre><p id="1193" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">这一步将从每一个中选择坐标。xml 文件并把它们转换成 YOLO 兼容的。txt 文件放在相同的测试和训练目录中。此外，train.txt 和 test.txt 文件是在包含图像位置的 darknet 文件夹中创建的。</p><h1 id="d8b7" class="lb jd hh bd je lc ld le ji lf lg lh jm li lj lk jq ll lm ln ju lo lp lq jy lr bi translated">步骤 4:准备自定义“我的数据”文件夹</h1><p id="533d" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku ha bi translated">运行以下命令创建一个名为“my_data”的自定义文件夹</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="6aae" class="jc jd hh lx b fi mb mc l md me">! mkdir my_data</span></pre><p id="932f" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">将 train.txt 和 test.txt 文件从 darknet 目录移动到 my_data 目录。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="4c3a" class="jc jd hh lx b fi mb mc l md me">! mv train.txt my_data/ <br/>! mv test.txt my_data/</span></pre><p id="7436" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">在 my_data 目录下创建 class . names 文件，类名为“LP”。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="d232" class="jc jd hh lx b fi mb mc l md me">! touch /content/gdrive/MyDrive/darknet/my_data/classes.names</span><span id="d34d" class="jc jd hh lx b fi mf mc l md me">! echo LP &gt; /content/gdrive/MyDrive/darknet/my_data/classes.names</span></pre><p id="a62b" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">在 my_data 目录中创建权重目录。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="085d" class="jc jd hh lx b fi mb mc l md me">! mkdir my_data/weights</span></pre><p id="0839" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">在 my_data 目录中创建文件 darknet.data，以提供配置详细信息。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="eca7" class="jc jd hh lx b fi mb mc l md me">! touch /content/gdrive/MyDrive/darknet/my_data/darknet.data</span></pre><p id="e173" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">将以下详细信息粘贴到 darknet.data 文件中。</p><ul class=""><li id="67de" class="mg mh hh kc b kd kv kh kw jn mi jr mj jv mk ku ml mm mn mo bi translated">类别= 1</li><li id="0309" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">train = my_data/train.txt</li><li id="1e7b" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">有效= my_data/test.txt</li><li id="c7e3" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">names =我的数据/类</li><li id="e80a" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">备份=我的数据/重量/</li></ul><p id="d6cc" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">将 cfg 文件从 darknet/cfg/yolov3.cfg 复制粘贴到 darknet/my_data 目录。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="277b" class="jc jd hh lx b fi mb mc l md me">! cp /content/gdrive/MyDrive/darknet/cfg/yolov3.cfg /content/gdrive/MyDrive/darknet/my_data</span></pre><p id="020e" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">对 my_data 目录中的 yolov3.cfg 进行以下更改。</p><ul class=""><li id="8f28" class="mg mh hh kc b kd kv kh kw jn mi jr mj jv mk ku ml mm mn mo bi translated">第 603、693 和 780 行将过滤器改为 18。(过滤器=(类别+ 5) * 3)。在我们的例子中，我们只检测 1 个类别，因此过滤器的数量将等于 18。</li><li id="5be8" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">第 783 行，将类的数量更改为 1。</li></ul><h1 id="52e3" class="lb jd hh bd je lc ld le ji lf lg lh jm li lj lk jq ll lm ln ju lo lp lq jy lr bi translated">步骤 5:下载用于训练定制数据的初始 yolo 权重</h1><p id="8985" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku ha bi translated">从 darknet 目录运行以下命令。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="724e" class="jc jd hh lx b fi mb mc l md me">! wget https://pjreddie.com/media/files/darknet53.conv.74</span></pre><h1 id="a06c" class="lb jd hh bd je lc ld le ji lf lg lh jm li lj lk jq ll lm ln ju lo lp lq jy lr bi translated">步骤 6:设置将权重文件保存在权重目录中的标准</h1><p id="d9be" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku ha bi translated">从 darknet/examples 目录中打开 detector.c 文件，并如下所示更改行号 138。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="95a1" class="jc jd hh lx b fi mb mc l md me">if(i%1000==0 || (i &lt; 1000 &amp;&amp; i%200 == 0))</span></pre><p id="0c13" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">这一改变将每 200 次迭代的权重保存在 my_data/weights 目录中，直到 1000 次迭代，然后每 1000 次迭代。</p><h1 id="2d31" class="lb jd hh bd je lc ld le ji lf lg lh jm li lj lk jq ll lm ln ju lo lp lq jy lr bi translated">第七步:现在开始训练</h1><p id="039d" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku ha bi translated">从 darknet 目录运行以下命令。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="32e8" class="jc jd hh lx b fi mb mc l md me">! ./darknet detector train /content/gdrive/MyDrive/darknet/my_data/darknet.data /content/gdrive/MyDrive/darknet/my_data/yolov3.cfg /content/gdrive/MyDrive/darknet/darknet53.conv.74</span></pre><p id="b3ca" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">注意:万一你得到“/bin/bash:。/darknet:权限被拒绝”错误，然后运行下面的命令，然后运行上面的命令。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="5b92" class="jc jd hh lx b fi mb mc l md me">! chmod +x darknet</span></pre><p id="94dd" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">注意:由于 google colab 的限制，您可能无法一次性训练出模型。检查 my_data/weights 文件夹中存储的最新权重，然后使用更新后的权重再次训练模型。例如，如果您的 weights 文件夹中有 yolov3_8000.weights，则运行下面的命令，用新的权重再次训练模型。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="583f" class="jc jd hh lx b fi mb mc l md me">! ./darknet detector train my_data/darknet.data my_data/yolov3.cfg /content/gdrive/MyDrive/darknet/my_data/weights/yolov3_8000.weights</span></pre><p id="97f7" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">如果你看到下面的输出，这意味着你的模型正在训练。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="io ip di iq bf ir"><div class="er es mu"><img src="../Images/8c61093957b03886c642ad58ba7f65f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vz_OfC4Eb4afbm8iPlGcpQ.png"/></div></div><figcaption class="iv iw et er es ix iy bd b be z dx translated">yolov3 训练开始</figcaption></figure><p id="d5cc" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">模型的输出如下所示。</p><figure class="ls lt lu lv fd ii er es paragraph-image"><div role="button" tabindex="0" class="io ip di iq bf ir"><div class="er es mv"><img src="../Images/43d9ff9ae48bc347aab438d5c06dfcb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nQv9u8qPqdoQNX55KNDwbA.png"/></div></div><figcaption class="iv iw et er es ix iy bd b be z dx translated">yolov3 培训输出</figcaption></figure><p id="c379" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">对第一行输出的快速解释:</p><ul class=""><li id="87e6" class="mg mh hh kc b kd kv kh kw jn mi jr mj jv mk ku ml mm mn mo bi translated">7616 表示当前的训练迭代</li><li id="8341" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">0.064027 表示总损失。它应该低于 0.03 才能获得好的结果。</li><li id="082e" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">0.052343 表示平均损失误差。应该是越低越好。</li><li id="e456" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">0.000010 是当前学习率，如中所定义。cfg 文件。</li><li id="2742" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">9.568856 秒表示处理该批次花费的总时间</li><li id="a261" class="mg mh hh kc b kd mp kh mq jn mr jr ms jv mt ku ml mm mn mo bi translated">487424 表示训练期间使用的图像总量。</li></ul><h1 id="e6a2" class="lb jd hh bd je lc ld le ji lf lg lh jm li lj lk jq ll lm ln ju lo lp lq jy lr bi translated">第八步:检测并模糊图像中的车牌</h1><p id="9b78" class="pw-post-body-paragraph ka kb hh kc b kd ke kf kg kh ki kj kk jn kl km kn jr ko kp kq jv kr ks kt ku ha bi translated">在运行下面的代码之前，更改第 12 行的 weightsPath 和第 15 行的图像文件名。</p><p id="c339" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">你应该看到一辆车的图像，上面有检测和模糊的车牌。</p><p id="7338" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated">注意:OpenCV 的 imshow()函数在 google colab 笔记本上不起作用。所以我必须使用 matplotlib 在图像上显示预测。您可以从 Github 存储库中下载 predicton.py 文件，并在本地测试映像上运行它。不要忘记从 google colab 下载最新的权重文件，并在 weightspath 变量中提到位置。</p><pre class="ls lt lu lv fd lw lx ly lz aw ma bi"><span id="1b5c" class="jc jd hh lx b fi mb mc l md me">%matplotlib inline<br/>import numpy as np <br/>import imutils <br/>import cv2 <br/>import matplotlib.pyplot as plt <br/>import warnings <br/>warnings.filterwarnings('ignore')</span><span id="94aa" class="jc jd hh lx b fi mf mc l md me">CONF_THRESH, NMS_THRESH = 0.5, 0.5</span><span id="1fc1" class="jc jd hh lx b fi mf mc l md me">weightsPath = 'my_data/weights/yolov3_8000.weights'<br/>configPath = 'my_data/yolov3.cfg'<br/>namesPath = 'my_data/classes.names'<br/>image = 'images8.jpg'</span><span id="dd3f" class="jc jd hh lx b fi mf mc l md me"># Load the network using openCV<br/>net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)<br/>net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)<br/>net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)</span><span id="54e2" class="jc jd hh lx b fi mf mc l md me"># Get the output layer from YOLOv3<br/>layers = net.getLayerNames()<br/>output_layers = [layers[i[0] - 1] for i in net.getUnconnectedOutLayers()]</span><span id="4a74" class="jc jd hh lx b fi mf mc l md me"># Read and convert the image to blob and perform forward pass<br/>img = cv2.imread(image)<br/>gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br/>height, width = img.shape[:2]</span><span id="ae99" class="jc jd hh lx b fi mf mc l md me">blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), swapRB=True, crop=False)<br/>net.setInput(blob)<br/>layer_outputs = net.forward(output_layers)</span><span id="4ca3" class="jc jd hh lx b fi mf mc l md me">class_ids, confidences, b_boxes = [], [], []</span><span id="65ac" class="jc jd hh lx b fi mf mc l md me">for output in layer_outputs:<br/>    for detection in output:<br/>        scores = detection[5:]<br/>        class_id = np.argmax(scores)<br/>        confidence = scores[class_id]</span><span id="17d0" class="jc jd hh lx b fi mf mc l md me">if confidence &gt; CONF_THRESH:<br/>        center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype('int')<br/>        x = int(center_x - w / 2) <br/>        y = int(center_y - h / 2)</span><span id="9afb" class="jc jd hh lx b fi mf mc l md me">        b_boxes.append([x, y, int(w), int(h)])<br/>        confidences.append(float(confidence))<br/>        class_ids.append(int(class_id))</span><span id="f56b" class="jc jd hh lx b fi mf mc l md me"><br/># Perform non maximum suppression for the bounding boxes to filter overlapping and low confident bounding boxes<br/>indices = cv2.dnn.NMSBoxes(b_boxes, confidences, CONF_THRESH, NMS_THRESH).flatten().tolist()</span><span id="a33f" class="jc jd hh lx b fi mf mc l md me">if len(indices) &gt; 0:<br/>    # Draw the filtered bounding boxes with their class to the image<br/>    with open(namesPath, "r") as f:<br/>        classes = [line.strip() for line in f.readlines()]</span><span id="91ec" class="jc jd hh lx b fi mf mc l md me">    colors = np.random.uniform(0, 255, size=(len(classes), 3))</span><span id="2863" class="jc jd hh lx b fi mf mc l md me">    for index in indices:<br/>        (x,y) = (b_boxes[index][0], b_boxes[index][1])<br/>        (w,h) = (b_boxes[index][2], b_boxes[index][3])</span><span id="3c03" class="jc jd hh lx b fi mf mc l md me"># Blur the ROI of the detected licence plate<br/>        img[y:y+h, x:x+w] = cv2.GaussianBlur(img[y:y+h, x:x+w] ,    (35,35),0)<br/>        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)          <br/>        text = "{}: {:.4f}".format("LP", confidences[index])<br/>        cv2.putText(img, text, (x, y - 3),     cv2.FONT_HERSHEY_COMPLEX_SMALL, .75 , (0, 255, 0), 1)</span><span id="a621" class="jc jd hh lx b fi mf mc l md me">plt.figure(figsize=(10, 5)) <br/>plt.imshow(img) <br/>plt.show()</span></pre><p id="3297" class="pw-post-body-paragraph ka kb hh kc b kd kv kf kg kh kw kj kk jn kx km kn jr ky kp kq jv kz ks kt ku ha bi translated"><a class="ae la" href="https://github.com/CodinjaoftheWorld/ANPR_INDIANCARS_YOLOV3" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>的链接</p></div></div>    
</body>
</html>