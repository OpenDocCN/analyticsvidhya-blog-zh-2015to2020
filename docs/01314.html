<html>
<head>
<title>How To Calculate Feature Importances From A Data Envelopment Analysis Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何从数据包络分析模型中计算特征重要性</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-calculate-feature-importances-from-a-dea-model-c2d6ca1a3ccd?source=collection_archive---------10-----------------------#2019-10-14">https://medium.com/analytics-vidhya/how-to-calculate-feature-importances-from-a-dea-model-c2d6ca1a3ccd?source=collection_archive---------10-----------------------#2019-10-14</a></blockquote><div><div class="dt gx gy gz ha hb"/><div class="hc hd he hf hg"><figure class="hi hj fa fc hk hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et hh"><img src="../Images/d1ef6f3ab589d7126b7abfa292b810cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9LQVhQYlGmOzYK1OyDDj4A.jpeg"/></div></div></figure><div class=""/><p id="ae45" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">关于优化和数据科学的比较，我的一个体会在这篇文章中实现了。在研究处理表单提交的数据科学时，我遇到了DEA(数据包络分析)的<a class="ae jp" href="https://personal.utdallas.edu/~ryoung/phdseminar/CCR1978.pdf" rel="noopener ugc nofollow" target="_blank"> CCR模型</a>。我模拟的表单提交具有不同的输入和输出维度，并且它可以是任意的，以便在输入端和输出端都保持顺序参数的行为。</p><h1 id="be99" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">数据科学中使用的三种变量</strong></h1><p id="eb97" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hc bi translated">分类的:那些使用数据进行分类的类别数量有限的变量。分类变量可以是:</p><ul class=""><li id="1d02" class="kt ku hu it b iu iv iy iz jc kv jg kw jk kx jo ky kz la lb bi translated"><strong class="it hv">序数</strong>:这些变量有顺序或排名，大多数情况下kendall tau用于序数参数的关联。</li><li id="d5b5" class="kt ku hu it b iu lc iy ld jc le jg lf jk lg jo ky kz la lb bi translated"><strong class="it hv">名义</strong>:这些变量没有任何顺序，因为它们可以是布尔型或非等级分类变量，可以用数据类别来表示</li></ul><p id="d873" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated"><strong class="it hv">连续</strong>:这些变量是连续的，也可以是浮点变量。</p><p id="4d40" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">Charnes等人。艾尔。(1978)指出，将一组加权输入变量转换为一组加权输出变量的效率可以使用线性规划来表示，该线性规划使加权和的比率最大化。DEA方法通过为我们提供权重的解决方案，使用决策单元(DMU)来正式确定转移的效率。</p><p id="e1f3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">另一篇关于使用DMU(s)的DEA的论文通过考虑加权和来考虑加权和的比率的正则化，如果可能的话，在域中包括任何布尔变量。</p></div><div class="ab cl lh li gq lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hc hd he hf hg"><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><p id="67a5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated"><strong class="it hv">使用形状组合评估特征重要性</strong></p><p id="5ca3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">上面的代码是因子模型的代码，该模型分析发送到期望最大化模型和因子模型的重要性和整个输出域组合。我在这里使用了<a class="ae jp" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> shap </a>来生成所有这些特性组合的重要性，并理解它们是如何分层表示的。</p><p id="0284" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">在这里，我使用的特性已经在下面详细说明了它们与表单提交的关系:</p><p id="673e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">我们有n个输入和m个输出域组合，我们的目标是通过学习输出域来映射出输入组合。</p><p id="92d9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated"><em class="lu">输出域(4个箱中的m个组合— </em> <strong class="it hv"> <em class="lu"> w1，w2，w3，w4 </em> </strong> <em class="lu"> ) </em></p><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><p id="6c69" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated"><em class="lu">输入域(n个加权输入)</em></p><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><p id="89ec" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">由于它们是加权输入，因此采用DEA的线性规划方法来评价特征的重要性。DEA增加了额外的线性约束，并最大化了加权和的比率。在这个问题中，假设输入域的权重相等，因此如果有10个输入值，则比例取为1/10 = <strong class="it hv"> 0.1 </strong></p><h1 id="2c00" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">因子模型和来自因子分析的噪声</strong></h1><p id="f328" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hc bi translated">在定义域和定义域的表示问题中，具有最小噪声的因子模型对于理解输入定义域和输出定义域之间的关系具有重要意义。在当前示例中，我通过进行因子分析获得了这些值:</p><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><p id="da02" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">我们可以观察到权重<strong class="it hv"> w2 </strong>具有最小的噪声，并且可以使用<a class="ae jp" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">形状值</a>显示出<strong class="it hv">权重2 </strong>最不重要，因为输出密码子的行为受权重<strong class="it hv"> w2 </strong>的影响最小。事实上，映射到其后验概率的4×4矩阵的因子模型对于权重2是正相关的，这意味着其对散度最大化的贡献最小，而w4、w3、w1与它们的后验概率是负相关的，这反映了由于那些权重导致的KL散度。</p><h1 id="4194" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">数据包络分析</h1><p id="4551" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hc bi translated">一种优化技术，采用输出和输入的加权和，使净比率最大化，这样在决策单元(DMU)的情况下，比率不会超过1。</p><figure class="lo lp lq lr fe hl es et paragraph-image"><div class="es et lv"><img src="../Images/5e0c1ca0c1e011a7de39a1a5d029d18a.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*XuqKdx9zj0outso66rc0bA.png"/></div></figure><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><figure class="lo lp lq lr fe hl es et paragraph-image"><div class="es et lw"><img src="../Images/90944e4c2676eef8d01463f31e0248b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*h2hbH3r7MjKd9VXerksq0Q.png"/></div></figure><pre class="lo lp lq lr fe lx ly lz ma aw mb bi"><span id="27f0" class="mc jr hu ly b fj md me l mf mg">MinMaxScaler(feature_range=(0,1)).fit_transform(values)</span></pre><p id="2be1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">为了突出上面的代码，我们将相关值从0转换为1，因为在这种情况下，我们惩罚绝对不相关的向量，奖励高度相关的向量。总的来说，我们获得的结果类似于本文的<a class="ae jp" rel="noopener" href="/@aswinkvj/data-envelopment-analysis-using-decision-making-units-an-analytical-approach-d234475df92a"> <strong class="it hv">扩展版本</strong> </a>中所示的斑点权重。这种数据转换的层次结构如下所示:</p><h1 id="3e5d" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak"> -保留MinMaxScaler值，意味着高度不相关表现为无效值</strong></h1><blockquote class="mh"><p id="ef17" class="mi mj hu bd mk ml mm mn mo mp mq jo dy translated">-保持相关值不变，意味着高度不相关的行为与不相关的DMU相同</p><p id="f6b5" class="mi mj hu bd mk ml mm mn mo mp mq jo dy translated">-保留相关性的绝对值，这给出了双峰分布，意味着高度不相关值的行为与高度相关值相同</p></blockquote><p id="61c8" class="pw-post-body-paragraph ir is hu it b iu mr iw ix iy ms ja jb jc mt je jf jg mu ji jj jk mv jm jn jo hc bi translated"><strong class="it hv">将DEA问题转化为拉格朗日最小化问题</strong></p><p id="f545" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">假设拉格朗日乘数α和β分别为1 / vi和vi。在拉格朗日最小化中，最大化项是往复的，并且使用乘数添加约束项，该乘数被表示为输入域的权重。在我们的拉格朗日问题中，我们需要确定两者:</p><figure class="lo lp lq lr fe hl es et paragraph-image"><div class="es et mw"><img src="../Images/550567304dd43b4cc1f7f785e2f587ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:148/format:webp/1*O12Cg0jgP7TnnvUDWygLhQ.png"/></div><figcaption class="mx my eu es et mz na bd b be z dy translated"><strong class="bd js">在DEA中确定这些权重</strong></figcaption></figure><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et nb"><img src="../Images/55109b5cb9aff6a46c2b80f0bf5c56f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2s5C2Pwy0FQsdEELcV55DQ.png"/></div></div></figure><figure class="lo lp lq lr fe hl es et paragraph-image"><div class="es et nc"><img src="../Images/3faa2c70f59e78fde2e6d71af3de8983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*po2CU7rqkd7AldMovvmBRA.png"/></div></figure><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><p id="e06e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated"><strong class="it hv">使用支持向量机将特征重要性映射到输出域</strong></p><p id="7ccd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">我们需要知道输入端的权重映射将如何影响输出域。因此，我在Scikit Learn中创建了一个支持向量回归机，并发现使用推断的特征重要性对支持向量进行分类的分数并没有那么差。</p><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div><figcaption class="mx my eu es et mz na bd b be z dy translated"><strong class="ak">使用np.isclose方法，我们可以将支持向量的数量减少到显著的最小值，这反映了推断的特征重要性</strong></figcaption></figure><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et nd"><img src="../Images/de840946721d1236062fe94d41820d2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*8AlW_6AGsoLsC0ARzOyC4g.png"/></div></div><figcaption class="mx my eu es et mz na bd b be z dy translated">拉格朗日六点法</figcaption></figure><pre class="lo lp lq lr fe lx ly lz ma aw mb bi"><span id="13c6" class="mc jr hu ly b fj md me l mf mg">vi = \<br/>[9.48953131e-08 9.48953131e-08 0.00000000e+00 9.48953131e-08<br/> 9.48953131e-08 9.48953131e-08 9.48953131e-08 0.00000000e+00<br/> 0.00000000e+00 0.00000000e+00]</span></pre><figure class="lo lp lq lr fe hl es et paragraph-image"><div class="es et ne"><img src="../Images/b98770647c80c1a147c91a4a02098565.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*cLuRVhYmHV077f05Kh6ppA.png"/></div><figcaption class="mx my eu es et mz na bd b be z dy translated">拉格朗日绘制的特征重要性图</figcaption></figure><h1 id="f5af" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">如何将DEA模型扩展为广义SVM模型</strong></h1><p id="10c6" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hc bi translated">在构建SVM模型时，您可以使用拉格朗日方法或DEA凸优化技术，使用多个合成数据集，也可以使用此处提供的excel表和Jupyter笔记本作为参考(<a class="ae jp" href="https://drive.google.com/open?id=18NDnXLf71h2PTSxqpCWMBTrwhxbP3pZ2" rel="noopener ugc nofollow" target="_blank"> solver.xlsx </a>、<a class="ae jp" href="https://notebooks.azure.com/anon-hixsea/projects/svm-dea/html/SVM_DEA_Solver.ipynb" rel="noopener ugc nofollow" target="_blank"> SVM_DEA_Solver.ipynb </a>)。</p><h1 id="9ce1" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">用于推断特征重要性的形状值</strong></h1><blockquote class="mh"><p id="c15b" class="mi mj hu bd mk ml mm mn mo mp mq jo dy translated">我使用联盟博弈论中的<a class="ae jp" href="http://homepages.inf.ed.ac.uk/scohen/features+nc.pdf" rel="noopener ugc nofollow" target="_blank"> shap值来推断特性的重要性。我将每个shap组合归类为一个python函数，在这里描述。</a></p></blockquote><figure class="nf ng nh ni nj hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><pre class="lo lp lq lr fe lx ly lz ma aw mb bi"><span id="b8fb" class="mc jr hu ly b fj md me l mf mg"><strong class="ly hv">pip install shap</strong></span></pre><p id="ddc9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">这反映了使用因子分析对权重w1、w2、w3和w4进行的初步研究。这里发现w2是最不重要的，因为它的域范围。在上述函数中，w4和w1被排除在外，因此该函数的形状特征重要性将非常低，如下所示。</p><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div><figcaption class="mx my eu es et mz na bd b be z dy translated"><strong class="ak">问题值是指cvxpy中的优化最大值，mean_r.value是指DMU和输出值的系数，或简称为特征重要性</strong></figcaption></figure><p id="a301" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">此处显示的片段是关闭不同权重后所有形状特征重要性的平均值。</p><figure class="lo lp lq lr fe hl"><div class="bz dz l di"><div class="ls lt l"/></div></figure><pre class="lo lp lq lr fe lx ly lz ma aw mb bi"><span id="d06a" class="mc jr hu ly b fj md me l mf mg">(0.04301583009989807,<br/> 0.02558938157631804,<br/> 0.04301583009989809,<br/> 0.04301583009989807,<br/> 0.02558938157631804,<br/> 0.02558938157631811,<br/> 0.04301583009989807,<br/> 0.04301583009989809,<br/> 0.02558938157631811,<br/> 0.02558938157631804,<br/> 0.04301583009989809,<br/> 0.02558938157631811)</span></pre><p id="7f06" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">决策树通过定制的可调用函数来适应输出域和形状特征的重要性。下面给出的模型不是机器学习模型，因为该模型没有测试数据来进行交叉验证。正如你所看到的，分割决策树然后降低mse(均方误差)的节点都是shap特征。</p><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et nk"><img src="../Images/4b6f4b547cf1a258cbbbe0dc6213038b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rqIuwAYPHvTxtoC1x90Vjg.png"/></div></div><figcaption class="mx my eu es et mz na bd b be z dy translated">决策树回归器，使用输出共域的外观索引来分离数据</figcaption></figure><h1 id="1530" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="f101" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hc bi translated">在将DEA模型扩展到大型SVM模型时，使用带有适当运算符的等式。</p><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et nb"><img src="../Images/55109b5cb9aff6a46c2b80f0bf5c56f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2s5C2Pwy0FQsdEELcV55DQ.png"/></div></div></figure><p id="db4c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hc bi translated">在决策树算法中，Shap库解释节点的拆分，因为它本身有一些算法来解释决策树，如下所示:</p><blockquote class="nl nm nn"><p id="b498" class="ir is lu it b iu iv iw ix iy iz ja jb no jd je jf np jh ji jj nq jl jm jn jo hc bi translated"><strong class="it hv">部分图片/情节经过精心挑选，对图片的改动敬请谅解</strong></p></blockquote><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et nr"><img src="../Images/51055914aab75f23afeadf307a55c17a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ma7yWIG5txE0DB4puHOwhw.png"/></div></div><figcaption class="mx my eu es et mz na bd b be z dy translated"><strong class="bd js">第0指数的SHAP值</strong></figcaption></figure><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et nr"><img src="../Images/ef1b7d7a4f85e714f3932b18fac456f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E52yT_AwBaojAazsDuo8Pw.png"/></div></div><figcaption class="mx my eu es et mz na bd b be z dy translated">【1STINDEX的SHAP值</figcaption></figure><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et nr"><img src="../Images/bf4ba3d6da266e8dfd4a5ed51e8901bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YxwQM_BexcncmTJGhlkMaw.png"/></div></div><figcaption class="mx my eu es et mz na bd b be z dy translated"><strong class="bd js">第5个指标的SHAP值</strong></figcaption></figure><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et ns"><img src="../Images/c7ab7f1677255c1abfe7cda8251e3d08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QxNzbTADzJ97iNTuwnaaQQ.png"/></div></div><figcaption class="mx my eu es et mz na bd b be z dy translated"><strong class="bd js"> SHAP值为第136指数</strong></figcaption></figure><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et ns"><img src="../Images/eaa55b6dfaa5a1ed7ec34022e7dd4a64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gid20qZZijUi0fJDwZs8-g.png"/></div></div><figcaption class="mx my eu es et mz na bd b be z dy translated"><strong class="bd js"> SHAP值为第139指数</strong></figcaption></figure><figure class="lo lp lq lr fe hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et ns"><img src="../Images/a3778baa6311be64c16fb0d11524f786.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FIxAsaLCXXcbJF7il0zAhQ.png"/></div></div><figcaption class="mx my eu es et mz na bd b be z dy translated"><strong class="bd js">第143项指标的SHAP值</strong></figcaption></figure></div></div>    
</body>
</html>