<html>
<head>
<title>Building a Topic Modelling for Images using LDA and Transfer Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用LDA和迁移学习建立图像主题模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-topic-modelling-for-images-using-lda-and-transfer-learning-e55fcde024c6?source=collection_archive---------5-----------------------#2019-11-10">https://medium.com/analytics-vidhya/building-a-topic-modelling-for-images-using-lda-and-transfer-learning-e55fcde024c6?source=collection_archive---------5-----------------------#2019-11-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/55757787fd3535f23d768f07a1884904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*wkLhsTUn6phB6paybPgHNQ.png"/></div></figure><p id="fe7e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">摘要:</strong></p><p id="7800" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">主题建模</strong>是一种用于从大量文本中提取隐藏主题的技术。有几种算法用于主题建模，如潜在狄利克雷分配(LDA)，潜在语义分析(LSA)，非负矩阵分解(NMF)等。然而，挑战在于从图像中提取主题。这涉及到文本和图像处理，以提取高质量的主题。大多数博客都专注于从文本信息中发现话题。为了改变，我想扩展和探索图像的主题建模。本文解释了结合这两种处理技术来揭示图像主题的步骤。</p><p id="3a15" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">简介:</strong></p><p id="90e0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图像的自动主题建模</strong>在计算机视觉和自然语言处理中提出了一个特殊的挑战，因为它需要从视觉和文本这两种完全不同的信息形式中进行解释。</p><p id="0fd1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本文中，我们将了解如何利用图像标题数据集来构建图像主题检测模型。我们将使用<strong class="io hj">‘Flickr 8k’</strong>数据集来保持它的简单和易于训练。</p><p id="fee3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将使用<strong class="io hj">潜在狄利克雷分配(LDA) </strong>从字幕数据的词汇中提取主题，并使用预训练的<strong class="io hj"> VGGNet16 </strong>模型从图像中提取模式，然后训练模型来预测给定图像的主题。</p><p id="13b6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们开始吧！</p><p id="9f44" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">导入包:</strong></p><p id="3734" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">本文使用的核心包是<strong class="io hj"> Gensim、NLTK、Spacy、</strong>和<strong class="io hj"> Keras </strong>。除此之外，我们还使用<strong class="io hj"> Pandas、Numpy、Sklearn、</strong>和<strong class="io hj"> Matplotlib </strong>进行数据处理和可视化。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jk"><img src="../Images/703a538302a1f79230629fc828b23130.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XdqlKvv1C4D44rSyDgGFBw.png"/></div></div></figure><p id="43c4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据加载:</strong></p><p id="ed76" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你可以从<a class="ae jt" href="https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/" rel="noopener ugc nofollow" target="_blank">这里</a>下载‘Flickr 8k’数据集。</p><p id="c208" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从下载的数据集中提取zip文件后，您会发现下面的文件夹。</p><ul class=""><li id="0e20" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated"><strong class="io hj"> Flickr8k_Dataset: </strong>总共包含了8092张JPEG格式的不同形状和大小的图片。其中6000个用于训练，1000个用于验证，1000个用于测试数据集。</li><li id="47d4" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated"><strong class="io hj"> Flickr8k_text: </strong>包含描述train_set、test_set和dev_set的文本文件。<strong class="io hj"> Flickr8k.token.txt </strong>包含每幅图像的5个标题，即总共40460个标题。</li></ul><p id="b13f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，您从Flickr8k.token.txt文件中加载图像id和标题，并准备一个数据集。然后根据图片id对标题进行分组，使其成为每张图片的一个单独的句子。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ki"><img src="../Images/736d64aac9aeb2b2c9de53f4ceb6c039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rqO--FgCE3Rhks0R02bZnw.png"/></div></div></figure><p id="e4dc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们先来看一下数据集。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kj"><img src="../Images/278c3bd5367aee0e22868ca1de5e0e1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*juLDtmYIkqV-kqeJUjl5RQ.png"/></div></div></figure><p id="37d7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据清理:</strong></p><p id="a877" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">数据预处理和清洗是整个建模过程的重要组成部分。它包括以下步骤。</p><ul class=""><li id="7fdb" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated"><strong class="io hj">使用分割字符串函数对标题进行标记化</strong></li><li id="80ac" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">将所有记号的大小写规范化为<strong class="io hj">小写</strong></li><li id="046e" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">从令牌中删除所有的标点符号</li><li id="00ba" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">移除所有包含<strong class="io hj">数字</strong>数据的令牌</li><li id="1468" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">使用NLTK语料库包删除所有<strong class="io hj">停用词</strong></li></ul><p id="065e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下面定义了<em class="kk"> clean_text() </em>函数，该函数将清除加载的字幕数据。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kl"><img src="../Images/da8ae4797bc637385f7a736b3c8a0beb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VmkAJiYXZGFVVFV27JqFzA.png"/></div></div></figure><p id="e8fb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据术语化:</strong></p><p id="2342" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我们<strong class="io hj">使用Spacy将</strong>单词词条化为其词根形式，并过滤仅包含特定词性标签的单词，如<strong class="io hj">名词、ADJ、动词、</strong>和<strong class="io hj"> ADV </strong>。这将提高话题检测过程的准确性。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kj"><img src="../Images/83eca2f78a4c6aae1d471c574551ebfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3g8FD0M0bEIkj8oDnaFTOw.png"/></div></div></figure><p id="dd1b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">了解潜在狄利克雷分配(LDA): </strong></p><p id="07d8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">LDA算法不仅仅执行文本摘要，它还可以发现文档集合中重复出现的主题。</p><p id="e708" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">LDA算法从集合中的每个文本文档中提取一组关键字。然后将文档聚集在一起，以学习文档组中重复出现的关键词。这些重复出现的关键字集被认为是集合中几个文档的共同主题。</p><p id="8e62" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">更多详情，请参考<a class="ae jt" href="https://dzone.com/articles/lda-for-text-summarization-and-topic-detection" rel="noopener ugc nofollow" target="_blank"> LDA进行文本摘要和主题检测</a>。</p><p id="753e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">创建词典和语料库:</strong></p><p id="e271" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">LDA主题模型的两个主要输入是词典和语料库。我们可以使用<strong class="io hj"> Gensim </strong>中的工具为字幕数据准备字典和语料库。</p><p id="78ab" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">第一步是将字幕数据加载到训练数据集中，以创建包含单词标识符映射的字典。</p><p id="3b96" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，我们遍历标题数据，准备包含术语文档频率表的语料库。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es km"><img src="../Images/f3410b7970c5ad165541b882081407e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WXMd09wpjjeFwC36rEuTdw.png"/></div></div></figure><p id="0da5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">为LDA寻找最佳主题数量:</strong></p><p id="5135" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了构建LDA模型，我们需要找到从字幕数据集中提取的主题的最佳数量。我们可以使用LDA模型的一致性分数来确定主题的最佳数量。</p><p id="893a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们可以遍历几个主题的列表，并使用Gensim的<em class="kk"> LDAMulticore </em>类为每个数量的主题构建LDA模型。然后将模型对象加载到<em class="kk">coherence model</em>类以获得一致性分数。可以保存LDA模型及其相应的一致性分数，以便在课程的后面找到主题的最佳数量。最后，我们可以绘制所有主题的结果及其连贯性分数，以便更好地理解。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ki"><img src="../Images/5fcc7c628fd905a1e951020e593d7eb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2CZItq-gKJ1qv66myrtGRg.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ki"><img src="../Images/c95f8f842ac6937716e5659dc2902be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pgasii3v6f-x9M4LWp3j6A.png"/></div></div></figure><p id="f8b4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一旦我们获得了最佳模型，我们就可以打印主题摘要，其中包含对每个主题贡献最大的前10个单词。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es km"><img src="../Images/129fe954cf40ddb2928b44c8ef781d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pCnyyQTYOd7n7rg_kbqo0A.png"/></div></div></figure><p id="5907" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们检查最优模型的<strong class="io hj">困惑度</strong>和<strong class="io hj">一致性分数</strong>。理想的LDA模型应该具有低复杂度和高一致性分数。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kj"><img src="../Images/f35b26780b869cc43ccf65800f4ab4b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VbnQDV-acSRShrBSApgJNQ.png"/></div></div></figure><p id="d4f3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">预测字幕数据的主题:</strong></p><p id="1b45" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">既然我们已经找到了最佳LDA模型，我们就可以预测数据集中每个字幕数据的主题。首先，我们将训练、验证和测试数据集的语料库加载到LDA模型，并获得结果数据集，该结果数据集具有数据集中每个图像的主导主题、贡献百分比和主题的前10个关键词。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kj"><img src="../Images/3d454cf6d8450db2625d68ac924348ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CQJ_A8BYsAsMTtFvTU9jYw.png"/></div></div></figure><p id="e7c6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">到目前为止，我们已经使用数据集中可用的标题数据预测了每个图像的主题。接下来，我们将看到如何处理图像，并用预测的主题训练深度学习模型。</p><p id="2b16" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">迁移学习:</strong></p><p id="9921" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">迁移学习是一种机器学习方法，其中为一项任务开发的模型被重新用作第二项任务模型的起点。</p><p id="3e42" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这是深度学习中的一种流行方法，其中预先训练的模型被用作计算机视觉和自然语言处理任务的起点，因为开发关于这些问题的神经网络模型需要大量的计算和时间资源，并且它们在相关问题上提供的技能有巨大的飞跃。</p><p id="e337" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">更多详情，请参考<a class="ae jt" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">深度学习的迁移学习</a>。</p><p id="7db2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">模型构建:</strong></p><p id="6de7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将使用预训练的<strong class="io hj"> VGGNet16 </strong>模型进行图像处理，该模型是在Keras中提供的Imagenet数据集上训练的。Imagenet是用于分类的标准数据集。它在数据集中包含超过1400万幅图像，组或类略多于21000个。</p><p id="0d33" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们可以修改VGGNet16模型来满足我们的需求。我们可以删除softmax层，并附上下面的层。</p><ul class=""><li id="b7ce" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated">具有2056个单位和“tanh”激活的密集层</li><li id="b22e" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">0.5%的辍学层</li><li id="5bac" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">具有1024个单元的密集层，具有“tanh”激活</li><li id="e064" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">0.5%的辍学层</li><li id="7bb3" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">具有最佳主题数量单元的Softmax层</li></ul><p id="b040" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">包含层、单元和激活功能的选择受制于领域经验或通过经验发展的直觉。您可以尝试各种组合来获得更好的模型。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es km"><img src="../Images/06e0d5733fd25084d81bb7efe0299010.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vs7PzMFCYZtOl9gTb1kKPg.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kl"><img src="../Images/f49fabd9a5a652f0a92ffc123e29105d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7huV1zct-JOUXcjwMyCUhg.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kn"><img src="../Images/e3c1b7d0d6a3f16cbc23d334533c8a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uDxFNbhcUQzepLFzmEGCHQ.png"/></div></div></figure><p id="a91c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图像预处理:</strong></p><p id="e3e6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们可以使用下面的自定义生成器类来加载图像和主题，并将样本作为一个单独的批处理返回。我们使用Keras预处理模块的<em class="kk"> load_img </em>函数加载目标尺寸为(224，224，3)的图像。然后使用<em class="kk"> img_to_array </em>函数将加载的图像像素转换为Numpy数组格式。然后使用Keras Vgg16的<em class="kk"> preprocess_input </em>函数，对图像进行处理和准备，将其加载到预先训练好的VGGNet16模型中。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kl"><img src="../Images/75d0a243b1c189babc065e90a78b5ac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eyzmX__9Y5FVXsqwKqxFFw.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kl"><img src="../Images/c43629170701f80fc4b845862f9e83d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0g-NDlr9jT2C8TLuyLGH-w.png"/></div></div></figure><p id="9a84" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">模特培训:</strong></p><p id="e451" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，让我们使用批大小为50的20个时期的训练和验证数据集来训练模型。最后，我们绘制了每个时期模型的损失和准确性的结果。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kj"><img src="../Images/c5f63fb305e741d95aa4806240965c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tfiqdiVYs034prpovM3tiQ.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kl"><img src="../Images/d4a420512121f6a061a4b3b000224764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j_uFpL3uGae_EwoKtvjJRA.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kj"><img src="../Images/a921081c3fe0c701f78dc7346a238932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jqMR3Ch97ydhzb2AHk6Txw.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ko"><img src="../Images/fb2e864d73d00f737e4834a8f44d4f20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J8KCUUCL7YQKTCNFFmvItg.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ki"><img src="../Images/1ae318e64fa85e24d4cfd31ea358a155.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Q8pMRUDxXgCsGBmNMFyjg.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kj"><img src="../Images/e1851e5101a3bdd41247e403d0415272.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vyg2T4ZwYSpRhDfqiOq0yw.png"/></div></div></figure><p id="8bf6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">检测测试图像数据集的主题:</strong></p><p id="8d9c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，我们加载在上述步骤中训练的最佳VGGNet16模型的权重。然后将测试数据集加载到VGGNet16模型的<em class="kk"> predict_generator </em>函数中，检测每张图片的主题概率。现在，我们考虑具有最高概率的主题，并产生具有检测到的图像id及其相应主题的结果数据帧。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es km"><img src="../Images/ab863cfc592580433ba80b680048c6c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8dauYkO6m-uwsXO-AFoEqg.png"/></div></div></figure><p id="9879" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">模型评估:</strong></p><p id="c2da" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们通过将真实话题和预测话题加载到Sklearn metrics包的<em class="kk"> log_loss </em>(交叉熵损失)<em class="kk"> accuracy_score </em>和<em class="kk"> Confusion_matrix </em>函数来评估模型。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kp"><img src="../Images/9efb17cda95f43ca41dbc33046a70642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ovvuecY2qhHmJS0E3yOh-A.png"/></div></div></figure><p id="1c60" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">具有<strong class="io hj">低测井损失值</strong>和<strong class="io hj">高精度分数</strong>的模型将提供更好的预测结果。从上面的结果可以看出，我们达到了<strong class="io hj"> 53.2% </strong>的准确率。</p><p id="b1b2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">未来范围:</strong></p><ul class=""><li id="855b" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated">调整模型的超参数将有助于产生更好的结果。</li><li id="1f95" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">可以用<strong class="io hj"> Flickr30k </strong>或<strong class="io hj"> MS-COCO </strong>数据集对模型进行训练，以获得更好的结果。</li><li id="17f0" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">尝试其他话题检测算法，如<strong class="io hj"> LSA </strong>、<strong class="io hj"> NMF </strong>等。并比较结果。</li><li id="331c" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">使用预先训练好的模型，如<strong class="io hj"> VGGNet19 </strong>、<strong class="io hj"> Google的Inception </strong>、<strong class="io hj">微软的ResNet </strong>等。为了获得更好的准确性</li></ul><p id="aec0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">概要:</strong></p><p id="9c1e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本文中，我们发现了图像的主题建模，以及如何使用图像标题数据集来构建主题检测模型。具体来说，我们使用Gensim的LDA构建了主题模型。然后，我们看到了如何使用一致性分数找到最佳的主题数量，并选择最佳的LDA模型。然后，我们定制预训练的VGGNet16模型，并训练该模型来检测给定图像的主题。最后，我们看到了如何使用Sklearn中的指标生成结果和评估模型性能。</p><p id="7f28" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这就把我们带到了本文的结尾。</p><p id="6255" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如需完整代码，您可以从<a class="ae jt" href="https://github.com/jsaikmr/Building-a-Topic-Modeling-for-Images-using-LDA-and-Transfer-Learning" rel="noopener ugc nofollow" target="_blank">这里</a>下载ipython笔记本。</p><p id="f89e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">参考文献:</strong></p><ul class=""><li id="6c7f" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated"><a class="ae jt" href="https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/" rel="noopener ugc nofollow" target="_blank">https://www . machine learning plus . com/NLP/topic-modeling-gensim-python/</a></li><li id="497f" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated"><a class="ae jt" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/transfer-learning-for-deep-learning/</a></li><li id="59e3" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated"><a class="ae jt" href="https://machinelearningmastery.com/prepare-photo-caption-dataset-training-deep-learning-model/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/prepare-photo-caption-dataset-training-deep-learning-model/</a></li><li id="defc" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated"><a class="ae jt" href="https://dzone.com/articles/lda-for-text-summarization-and-topic-detection" rel="noopener ugc nofollow" target="_blank">https://dzone . com/articles/LDA-用于文本摘要和主题检测</a></li><li id="fd4a" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated"><a class="ae jt" href="https://nlpforhackers.io/topic-modeling/" rel="noopener ugc nofollow" target="_blank">https://nlpforhackers.io/topic-modeling/</a></li><li id="3d56" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated"><a class="ae jt" href="https://arxiv.org/pdf/1807.03514.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1807.03514.pdf</a></li></ul></div></div>    
</body>
</html>