<html>
<head>
<title>Object Localization using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras的目标定位</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/object-localization-using-keras-d78d6810d0be?source=collection_archive---------0-----------------------#2020-07-13">https://medium.com/analytics-vidhya/object-localization-using-keras-d78d6810d0be?source=collection_archive---------0-----------------------#2020-07-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6b38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我将解释<em class="jd">对象定位</em>的任务，以及如何实现一个基于CNN的架构来解决这个任务。</p><p id="ec31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">资源</strong> : <br/>代码:<a class="ae je" href="https://colab.research.google.com/drive/169pJ-xECBWDW9Q92naaNE3oRyBr7D-uh#scrollTo=IjFHABNA7nZL" rel="noopener ugc nofollow" target="_blank">https://colab . research . Google . com/drive/169 pj-xecbwd w9 q 92 naane 3 orybr 7d-uh # scroll to = ijfabna 7 nzl</a><br/>图片:<a class="ae je" href="https://drive.google.com/drive/folders/1YsxDywjUZi-l_YgzXt__9__eUU-I_6EH?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://drive . Google . com/drive/folders/1 ysxdywjuzi-l _ YgzXt _ _ 9 _ _ eUU-I _ 6EH？usp =分享</a></p></div><div class="ab cl jf jg gp jh" role="separator"><span class="ji bw bk jj jk jl"/><span class="ji bw bk jj jk jl"/><span class="ji bw bk jj jk"/></div><div class="hb hc hd he hf"><h1 id="b273" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">议程</strong></h1><ul class=""><li id="b5ca" class="kk kl hi ih b ii km im kn iq ko iu kp iy kq jc kr ks kt ku bi translated">什么是对象本地化？</li><li id="ad48" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">如何使用深度神经网络执行目标定位</li><li id="7396" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">逐步实施Keras</li></ul></div><div class="ab cl jf jg gp jh" role="separator"><span class="ji bw bk jj jk jl"/><span class="ji bw bk jj jk jl"/><span class="ji bw bk jj jk"/></div><div class="hb hc hd he hf"><h2 id="bab3" class="la jn hi bd jo lb lc ld js le lf lg jw iq lh li ka iu lj lk ke iy ll lm ki ln bi translated"><strong class="ak">物体定位</strong></h2><p id="8363" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated"><em class="jd">物体定位</em>是“带定位的分类”任务的名称。也就是说，给定一幅图像，对图像中出现的物体进行分类，并找到它在图像中的位置，通常使用边界框。在<em class="jd">对象定位</em>中，图像中只能出现一个对象。如果出现一个以上的物体，该任务称为“<em class="jd">物体检测</em>”。</p><figure class="ls lt lu lv fd lw er es paragraph-image"><div class="er es lr"><img src="../Images/6a57f213636076e11e3db0a650667c53.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*uI4AaqoDew9p9YRsVFDZNg.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">分类与目标定位</figcaption></figure><h2 id="7471" class="la jn hi bd jo lb lc ld js le lf lg jw iq lh li ka iu lj lk ke iy ll lm ki ln bi translated"><strong class="ak">如何使用DNNs进行物体定位？</strong></h2><p id="2d77" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">目标定位可以被视为一个回归问题——预测一个连续的值，如体重或工资。例如，我们可以将我们的输出(边界框)表示为大小为4的元组，如下:<br/> (x，y，height，width) <br/> - (x，y):边界框左上角的坐标<br/> - height:边界框的高度<br/> - width:边界框的宽度</p><figure class="ls lt lu lv fd lw er es paragraph-image"><div class="er es md"><img src="../Images/35f961187234d81da93b25e0f819ab46.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*n9_CTdtvMJxliKzFvYTG8A.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">(x，y，height，width)作为边界框表示</figcaption></figure><p id="a010" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们可以使用输出4个数字的CNN架构，但是我们的架构是什么呢？</p><p id="7b94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们会注意到这4个数字有一些限制:(x.y)必须在图像内部，x+宽度和y+高度也是如此。我们将缩放图像的宽度和高度为1.0。为了确保CNN输出在范围[0，1]内，我们将使用<em class="jd"> sigmoid </em>激活层——它将强制(x，y)在图像内，但不一定是x+宽度和y+高度。该属性将由网络在训练过程中学习。</p><p id="c3ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">建议的架构:</p><figure class="ls lt lu lv fd lw er es paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="er es me"><img src="../Images/76dc516d5ad249332a37fa7566ea65bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8g-sARieZ4TcMWWiDFW1Qg.png"/></div></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">给定一幅图像，网络将输出一个4数字表示的边界框</figcaption></figure><p id="45ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损失函数呢？一个<em class="jd">sigmoid</em><strong class="ih hj"><em class="jd"/></strong>的输出可以被视为概率值，因此我们可以使用<em class="jd">binary _ cross entropy</em>loss。</p><figure class="ls lt lu lv fd lw er es paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="er es mj"><img src="../Images/7c546ea87125a003c4aa50457db07fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5zVIyT9FN25IbLnm.png"/></div></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">二元交叉熵公式</figcaption></figure><p id="b901" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，这种损失与二进制值一起使用，作为基本事实({0，1})，但不一定要这样，我们可以使用[0，1]中的值。对于我们的使用，地面真实值确实在范围[0，1]内，因为它表示图像内的位置和维度。</p><p id="4924" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">逐步实施Keras】</strong></p><p id="3b20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将用三个步骤来解决一个目标定位任务:<br/> 1)合成用例——检测黑色背景上的白色斑点<br/> 2)半合成用例——检测黑色背景上的猫<br/> 3)最终用例——检测自然背景上的猫</p><ol class=""><li id="71c4" class="kk kl hi ih b ii ij im in iq mk iu ml iy mm jc mn ks kt ku bi translated"><strong class="ih hj">合成用例:</strong> <br/>首先，我们将导入并定义以下内容:</li></ol><figure class="ls lt lu lv fd lw"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="7f16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们将定义基于CNN的模型。我们将执行<em class="jd">迁移学习</em>:使用预训练版本的VGG。</p><figure class="ls lt lu lv fd lw"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="ls lt lu lv fd lw er es paragraph-image"><div class="er es mq"><img src="../Images/321d0239a1650cc78daa7d254911f74c.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*nBdVCP7iBj7YR2fLdwFOFw.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">模型的架构</figcaption></figure><p id="18dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的下一步将是使用python生成器创建数据集。它将在黑色背景上创建一批白色斑点。</p><figure class="ls lt lu lv fd lw"><div class="bz dy l di"><div class="mo mp l"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">x是一批图像，Y是真实边界框。对于每个图像，我们将创建一个白色的斑点，我们将确保它将在图像的边界内。</figcaption></figure><figure class="ls lt lu lv fd lw er es paragraph-image"><div class="er es mr"><img src="../Images/d7d87c2b7a10aec37c574f6db86f7c9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*lrY_v0PZUGYC66F-g_oZhQ.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">圆生成器的一个例子</figcaption></figure><p id="6522" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们可以训练模型来预测地面真实边界框，并可视化其性能:</p><figure class="ls lt lu lv fd lw"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="ls lt lu lv fd lw"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="ls lt lu lv fd lw er es paragraph-image"><div class="er es ms"><img src="../Images/506598dc8eed708d71e9b08e494d0879.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*r8Lf04JGBfIPVjoWywnmaw.png"/></div></figure><p id="6edf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">半合成用例:<br/> </strong>对于这个用例，我们将使用相同的架构，使用不同类型的图像——黑色背景上的猫的图像。这将通过使用不同的发电机来实现:</p><figure class="ls lt lu lv fd lw"><div class="bz dy l di"><div class="mo mp l"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">对于每张图片，这个生成器会将猫的大小调整为随机大小，并在黑色背景图片上的随机位置绘制它。</figcaption></figure><p id="c94d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的输出是:</p><figure class="ls lt lu lv fd lw er es paragraph-image"><div class="er es ms"><img src="../Images/eb24a331279e803d6f12b0f8b2f1638e.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*hVTWUFVmn1VUDsfreT1nfQ.png"/></div></figure><p id="aa9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们可以定义一个类似的模型，训练它并检查它的结果:</p><figure class="ls lt lu lv fd lw"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="5cca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们训练过的模型能够在黑色背景图像中定位一只猫:</p><figure class="ls lt lu lv fd lw er es paragraph-image"><div class="er es mt"><img src="../Images/6ab4d8037a8bd4cabe130c00556a9c6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*84Spf2m3tlFk0HfHT7xGAQ.png"/></div></figure><p id="441c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.<strong class="ih hj">最终用例<br/> </strong>在这个用例中，我们将在自然背景上绘制我们的猫。类似于第二个用例，我们将需要实现一个新的图像生成器——每个图像将由一个随机位置的随机大小的猫组成。这只猫将被画在一个自然的图像上，这将是它的背景。自然图像将从一组图像中随机抽取。</p><figure class="ls lt lu lv fd lw"><div class="bz dy l di"><div class="mo mp l"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">这个生成器从给定的集合中为每个图像绘制一个随机的自然背景图像。它会将猫的大小调整为随机大小，并在自然背景上的随机位置绘制它。</figcaption></figure><p id="2570" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">natural_cat_gen()输出将类似于:</p><figure class="ls lt lu lv fd lw er es paragraph-image"><div class="er es mr"><img src="../Images/46e24acf6a92235c71a15ea5c81401bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*kmE2T_lcKF9pcJqlfMnNeA.png"/></div></figure><p id="c8bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将定义一个新模型，对其进行训练并可视化其部分结果:</p><figure class="ls lt lu lv fd lw"><div class="bz dy l di"><div class="mo mp l"/></div></figure><figure class="ls lt lu lv fd lw er es paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="er es mu"><img src="../Images/5e7b21e7b656248ad2a7872856d96bfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WqJtHunJDMxwTlX5qJNIng.png"/></div></div></figure></div></div>    
</body>
</html>