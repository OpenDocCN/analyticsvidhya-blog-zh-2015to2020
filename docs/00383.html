<html>
<head>
<title>Unraveling Automatic Differentiation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解开自动微分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/unraveling-automatic-differentiation-6d5f0196f219?source=collection_archive---------1-----------------------#2019-05-16">https://medium.com/analytics-vidhya/unraveling-automatic-differentiation-6d5f0196f219?source=collection_archive---------1-----------------------#2019-05-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="db1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">梯度和导数是所有机器学习算法的核心。ML之所以只是“管用”，是因为渐变。基本思想是最小化目标损失函数，该目标损失函数取决于模型的输入和参数。这是用多元微积分和梯度的概念漂亮而优雅地完成的。</p><p id="32b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">任何学完微积分基础课程的人都会发现，由于链式法则，计算可微函数的导数和梯度的过程是一个非常机械和简单的过程。但是计算机如何计算任何一般可微函数的导数呢？</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/1256b64afc765399e3299be83a196335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NPA9jnpajooUcp4DCvNl-A.png"/></div></div></figure><p id="a436" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">手动计算导数的直接方法是行不通的，因为这一过程严重依赖于被微分的函数，并且不是通用的。让我们回到导数的第一个基本定义。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jp"><img src="../Images/8e4842874c98cff68fd17510167b6765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t8SDowXIq2wwwwJ1D0DHBA.png"/></div></div></figure><p id="86a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是这种方法的准确性高度依赖于选择的<em class="jq"> h </em>，因为<em class="jq"> h </em>趋向于0，这是一种非常简单的计算函数在某一点的导数的方法。</p><p id="2bba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">20世纪数学研究最重要的成果之一是自动微分(AD)，也称为算法微分。大多数ML/DL库使用AD来计算梯度和导数。它有两种模式:正向模式和反向模式。让我们首先理解正向模式，因为它非常直观，并且利用了偏导数的链式法则。</p><h2 id="a286" class="jr js hi bd jt ju jv jw jx jy jz ka kb iq kc kd ke iu kf kg kh iy ki kj kk kl bi translated"><strong class="ak">前进模式广告</strong></h2><p id="2991" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq ko is it iu kp iw ix iy kq ja jb jc hb bi translated">实现前向模式广告的一个非常聪明的方法是通过双数。双数与复数非常相似，有两个组成部分。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kr"><img src="../Images/e40ac3e632af9fa76668f01c6f4f80f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*qBvqGVMtoxPgfbWrchhg-Q.png"/></div></figure><p id="b88b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在复数中，我们有i = -1，同样在双数中，我们有ϵ = 0，但是反直觉地，ϵ不等于0。ϵ可以理解为浮点数精度内的一个非常小的数，但是当它被平方后，就变成了零，无法在浮点数精度内表示。双数的算术与复数算术完全相同。</p><p id="11f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在在对AD使用对偶数时，我们将实部设置为函数在某一点的值，虚部设置为函数在该点的导数。</p><p id="df95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让<em class="jq"> f </em> ( <em class="jq"> x) = x </em>写成<em class="jq">f(x</em>+<em class="jq">εx</em>'<em class="jq">)</em>=<em class="jq">x</em>+<em class="jq">εx</em>'。这是身份函数。</p><p id="57eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(<em class="jq">x</em>+<em class="jq">εx</em>’)+(<em class="jq">y</em>+<em class="jq">εy</em>’)=(<em class="jq">x</em>+<em class="jq">y</em>)+<em class="jq">ε</em>(<em class="jq">x</em>’+<em class="jq">y【T37’)</em></p><p id="2d94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(<em class="jq">x</em>+<em class="jq">εx</em>′)(<em class="jq">y</em>+<em class="jq">εy</em>′)=(<em class="jq">xy</em>)+<em class="jq">ε</em>(<em class="jq">xy</em>′+<em class="jq">x</em>′<em class="jq">y</em>)</p><p id="05f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jq">f</em>(<em class="jq">g</em>(<em class="jq">x</em>+<em class="jq">εx</em>’)=<em class="jq">f</em>(<em class="jq">g</em>(<em class="jq">x</em>)+<em class="jq">εg</em>’(<em class="jq">x</em>)<em class="jq">x【T19’)=<em class="jq">f</em>(<em class="jq">g</em>(<em class="jq"/></em></p><p id="50f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的例子可以清楚地看出，对偶数算术按照对偶数的实部是函数值，虚部是函数的导数的约定，服从链式法则。</p><p id="10fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们考虑一个可微函数，并通过正向模式AD获得它的梯度。让</p><p id="0ed6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jq"> y=f(x1，x2)= ln(x1)+x1 * x2 sin(x2)</em></p><p id="e6e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">任何函数都可以写成加、减、乘、除等基本数学运算和平方根、三角函数、对数、指数函数等函数的组合。我们将这些基本函数的导数定义为规则，并利用这些规则来获得它们的复合函数的导数。</p><p id="b667" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，如果我们将这个给定的函数分解为基本函数的组合，我们将获得一个计算图，其中每个基本函数/操作的输出作为节点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ks"><img src="../Images/98356bb15316b2f51a116c2b2a635048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*x74pIIW0aQ8UEU6D4lzhGg.png"/></div></div></figure><p id="c272" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里<em class="jq"> v-1和v0 </em>是输入节点，其余的是中间函数，它们产生所需的输出函数。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kt"><img src="../Images/de93130ea71055a96aa591a7b0319e08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*na7hVnND8Jzz6lU16shXEw.png"/></div></div></figure><p id="d5ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">表格的左栏显示了在<em class="jq"> x1 = 2和x2 = 5时函数值的计算。</em>从图中可以清楚地看出中间节点之间的关系。右栏显示每个中间函数相对于<em class="jq"> x1的偏导数。</em>由于<em class="jq"> v-1 = x1 </em>，所以<em class="jq"> v-1 </em>相对于<em class="jq"> x1 </em>的偏导数为1，由于<em class="jq"> v0 = x2 </em>，并且<em class="jq"> x1 </em>和<em class="jq"> x2 </em>相互独立，所以<em class="jq"> v0 </em>相对于<em class="jq"> x1 </em>的偏导数为零。</p><p id="5e34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由此，利用链式法则可以得到其余函数及其相对于<em class="jq"> x1 </em>的偏导数，最终我们将得到<em class="jq"> f </em>相对于<em class="jq"> x1 </em>的偏导数。导数的值是精确的。</p><p id="8299" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，如果我们有一个输入变量为<em class="jq"> n </em>的函数，我们将不得不执行<em class="jq"> n </em>次向前传递来获得所有的偏导数。由于输入获得输出的流动，以及偏导数的流动都是从输入到输出，这种模式称为正向模式。</p><p id="6fd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Julia有一个名为ForwardDiff.jl的转发模式AD包，它定义了一个名为Dual的结构，具有与上述相同的属性。它使用一套基本函数的微分规则，利用链式法则获得任何可微函数的偏导数。</p><h2 id="7b02" class="jr js hi bd jt ju jv jw jx jy jz ka kb iq kc kd ke iu kf kg kh iy ki kj kk kl bi translated"><strong class="ak">反向模式广告</strong></h2><p id="90bd" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq ko is it iu kp iw ix iy kq ja jb jc hb bi translated">在反向模式中，使用广义反向传播算法从输出反向传播梯度。这是通过用定义为<em class="jq"> v=∂y/∂v. </em>的伴随变量来补充每个输入变量v来实现的</p><p id="a2fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在反向模式AD下，导数在两阶段过程的第二阶段计算:</p><ol class=""><li id="46e9" class="ku kv hi ih b ii ij im in iq kw iu kx iy ky jc kz la lb lc bi translated">在第一阶段，原始功能代码向前运行，填充中间变量<em class="jq"> vi </em>，并在计算图中记录依赖关系。</li><li id="2ede" class="ku kv hi ih b ii ld im le iq lf iu lg iy lh jc kz la lb lc bi translated">在第二阶段，通过从输出到输入反向传播邻接来计算导数。</li></ol><p id="ea9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们用和之前一样的函数来理解反向模式AD。计算图也和以前一样。我们将计算函数在<em class="jq"> x1 = 2和x2 =5 </em>的梯度。</p><p id="1757" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jq"> y=f(x1，x2)= ln(x1)+x1 * x2 sin(x2)</em></p><p id="9b76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该函数被分解成基本函数以形成计算图。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ks"><img src="../Images/98356bb15316b2f51a116c2b2a635048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*x74pIIW0aQ8UEU6D4lzhGg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/f4d76321d3676bc4ce427c3c6485b66f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-pCBTy5-jt-7kq9UsjRdzQ.png"/></div></div></figure><p id="a4b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第一阶段，我们将完成一次向前传递，以计算所有中间变量v，并因此计算函数<em class="jq"> f在x1 = 2和x2 = 5时的输出。</em>在第二阶段，我们从输出变量开始。</p><p id="3ef3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">̄v5= ̄y=∂y/∂y= 1号。这是因为<em class="jq"> v5 = y. </em>因此偏导数为1。现在我们反向传播到<em class="jq"> v4，v3，</em>，直到我们到达上表右栏所示的输入变量。基本功能和操作的区分规则也已定义。我们通过反向模式AD和正向模式AD得出了相同的<em class="jq"> ∂y/∂x1 </em>值。</p><p id="4346" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种方法的美妙之处在于，我们只需向前和向后一次，就可以获得函数对所有输入变量的偏导数。所以如果我们有一个<em class="jq"> n </em>维的输入向量和一个标量输出函数，只需要反向模式AD的一次前后传递就足以获得函数的所有偏导数。而正向模式AD将要求每个输入变量有<em class="jq"> n个</em>正向传递。</p><p id="66ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果输出函数具有<em class="jq"> m </em>个维度，那么我们将需要<em class="jq"> m </em>个反向模式AD的向前和向后传递，以获得每个输出维度相对于输入维度的梯度。反向模式AD的名称是合理的，因为函数计算是从输入到输出进行的，但是梯度是以相反的方向计算的，即从输出到输入。</p><p id="59e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Julia在包ReverseDiff.jl中实现了反向模式AD，如上所述反向传播邻接以计算梯度。</p><p id="f80c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自动微分是机器学习中广泛使用的一个非常有力的武器。如果我们不能有效地计算梯度，我们肯定不会有这么多ML/DL库。Pytorch和Tensorflow也是基于自动微分的原理。</p><p id="1c66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献:</strong></p><ol class=""><li id="cd47" class="ku kv hi ih b ii ij im in iq kw iu kx iy ky jc kz la lb lc bi translated">https://arxiv.org/pdf/1502.05767.pdf<a class="ae lj" href="https://arxiv.org/pdf/1502.05767.pdf" rel="noopener ugc nofollow" target="_blank"/></li><li id="151e" class="ku kv hi ih b ii ld im le iq lf iu lg iy lh jc kz la lb lc bi translated"><a class="ae lj" href="https://alexey.radul.name/ideas/2013/introduction-to-automatic-differentiation/" rel="noopener ugc nofollow" target="_blank">https://Alexey . radul . name/ideas/2013/自动差异化简介/ </a></li></ol></div></div>    
</body>
</html>