<html>
<head>
<title>Reconciling Data Shapes and Parameter Counts in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Keras中协调数据形状和参数计数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/reconciling-data-shapes-and-parameter-counts-in-keras-f5057a35594?source=collection_archive---------2-----------------------#2019-06-18">https://medium.com/analytics-vidhya/reconciling-data-shapes-and-parameter-counts-in-keras-f5057a35594?source=collection_archive---------2-----------------------#2019-06-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b2f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">卷积层及其表亲在Keras/Tensorflow中检查汇集层的形状修改和参数计数，作为层参数的函数… </em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/19637364e86e3444c4a77fefc8ae775b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S2n2Xe3etRBZdMV9.png"/></div></div></figure><p id="b153" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Keras是深度学习的代名词。使用Keras构建连接图层的多输入多输出网络是一项常规任务。数据/张量(多维数字矩阵)从一层到另一层，从入口到出口，随着网络一路上积累了数百万个参数，扭曲并改变了它们的方式。数据形状在挤过一个层时如何变形，该层向网络模型添加了多少参数，这些当然是所讨论的层的函数，以及该层在Keras中是如何被实例化的。在之前的文章<a class="ae jq" href="http://xplordat.com/2019/06/06/flowing-tensors-and-heaping-parameters-in-deep-learning/" rel="noopener ugc nofollow" target="_blank">中深度学习中的流动张量和堆积参数</a>:</p><ul class=""><li id="851d" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated">我们详细研究了密集层、嵌入层和递归层(LSTM/GRU ),以了解数据在通过这些层时形状如何以及为什么会发生变化。</li><li id="fb20" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">使用描述层内数据修改的方程，我们导出了用于所述修改的这些层的每一层中使用的可训练参数的数量的公式。</li></ul><p id="db95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在这里继续练习图像分类中大量使用的卷积层和池层。我们通过运行<a class="ae jq" href="https://keras.io/getting-started/functional-api-guide/#visual-question-answering-model" rel="noopener ugc nofollow" target="_blank">视觉问题回答模型</a>来结束系列，并确认我们的公式/分析对于可训练参数和输出形状是正确的。片段的完整代码可以从<a class="ae jq" href="https://github.com/ashokc/Reconciling-Data-Shapes-and-Parameter-Counts-in-Keras" rel="noopener ugc nofollow" target="_blank"> github </a>获得。</p><h1 id="df56" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">1.卷积层</h1><p id="802f" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">卷积层基本上是特征提取器。它们主要用于图像，但也可以应用于文本，用于模式/特征识别及其分类。当处理文本时，我们首先使用嵌入层或使用外部提供的向量将单词转换为数字向量。</p><h2 id="fb3e" class="li kg hi bd kh lj lk ll kl lm ln lo kp iq lp lq kt iu lr ls kx iy lt lu lb lv bi translated">1.1输入形状</h2><p id="8c8f" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">卷积层的输入可以是成批的图像或句子。Keras默认输入数据为“通道_最后”,意味着通道/特征的数量<em class="jd"> N_c </em>将是最后一个维度，通常第一个维度是batch_size，此处为“无”。在这两者之间是图像的尺寸(或者在文本的情况下是序列长度)。</p><blockquote class="lw lx ly"><p id="8c23" class="if ig jd ih b ii ij ik il im in io ip lz ir is it ma iv iw ix mb iz ja jb jc hb bi translated"><em class="hi">【批量大小，{图像/文本尺寸}，通道/特征数量】</em></p></blockquote><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mc"><img src="../Images/8a4b4977dee52a27c715d2ce7f18b019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5E1cS_xeu42hn3sGM20jfQ.jpeg"/></div></div><figcaption class="md me et er es mf mg bd b be z dx translated">图一。一个句子可以被看作是一个一维图像，像素的数量与单词的数量相同，每个像素/单词的通道数量与单词向量的长度相同</figcaption></figure><h2 id="5acc" class="li kg hi bd kh lj lk ll kl lm ln lo kp iq lp lq kt iu lr ls kx iy lt lu lb lv bi translated">1.2输出形状</h2><p id="7540" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">卷积运算在几篇文章中用漂亮的图片等很好地解释了。我们感兴趣的是形状变换和参数计数。下面的图2和表1总结了下面关于形状转换的讨论。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mh"><img src="../Images/3f864b4e835773e2cd0a1486049e8fcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x7XsznMGQncsT57O.jpg"/></div></div><figcaption class="md me et er es mf mg bd b be z dx translated">图二。具有N_f过滤器的卷积层将[I_x，I_y，N_c]图像转换为[O_x，O_y，N_f]图像。O_x、O_y和可训练参数的数量由所示公式给出。</figcaption></figure><ol class=""><li id="8b21" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc mi jx jy jz bi translated">卷积层的输出由滤波器产生。例如在二维中，每个滤波器具有类似[ <em class="jd"> f_x，f_y </em>的大小。每个滤波器自动地<em class="jd"> N_c </em>深，其中<em class="jd"> N_c </em>是输入中的通道数。即它的实际形状是[ <em class="jd"> f_x，f_y，N_c </em> ]</li><li id="885b" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc mi jx jy jz bi translated">每个滤波器为输出生成一个新通道。也就是说，将图像与具有64个滤波器的<em class="jd">然而多个通道</em>进行卷积产生了具有64个通道的输出图像。</li><li id="518a" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc mi jx jy jz bi translated">上面2中输出图像的尺寸[ <em class="jd"> O_x </em>，<em class="jd"> O_y </em> ]取决于Keras中的两个设置。</li></ol><ul class=""><li id="0e28" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated"><em class="jd">步距</em> <strong class="ih hj"> <em class="jd"> s_x </em> </strong>，<strong class="ih hj"> <em class="jd"> s_y </em> </strong>:滤波器如何沿数字/像素的输入矩阵移动，以进行逐元素的乘积和求和运算。s=  1表示过滤器一次移动一个像素/单元</li><li id="79f9" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated"><em class="jd">填充</em>:当滤波器尺寸(<em class="jd"> f_x </em>和<em class="jd"> f_y </em>)及其跨越图像的步距(<em class="jd"> s_x </em>和<em class="jd">s _ y</em>)(<em class="jd">I _ x</em>和<em class="jd"> I_y </em>)不完全正确时，部分输入数据可能无法被卷积层处理。这是在Keras中默认发生的情况(填充= <strong class="ih hj">有效</strong>)。当填充设置为<strong class="ih hj"> same </strong>时，输入图像/矩阵被<em class="jd">填充</em>类似于0的假数据，这样所有的真实数据都会被过滤器处理。下表1总结了Keras与Tensorflow卷积后输出图像的形状和大小。</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mj"><img src="../Images/1ab1d885f2d4180dc40069a5450a592f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*i181S9Y9xe_1JK4h.jpg"/></div></div><figcaption class="md me et er es mf mg bd b be z dx translated">表1。在Keras(版本2.2.4)中与Tensorflow后端(版本1.13.1)卷积后输出图像形状</figcaption></figure><h2 id="cfd4" class="li kg hi bd kh lj lk ll kl lm ln lo kp iq lp lq kt iu lr ls kx iy lt lu lb lv bi translated">1.3参数计数</h2><p id="beec" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">除了增加输出图像中的通道数量之外，每个滤镜还会给表格带来一系列参数。我们已经看到，滤波器在二维中具有[ <em class="jd"> f_x，f_y，N_c </em> ]的形状(或者在一维图像/文本中具有[ <em class="jd"> f_x，N_c </em>)，其中<em class="jd"> N_c </em>是输入中的通道数。过滤器参数的关键属性如下。</p><ol class=""><li id="7dfe" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc mi jx jy jz bi translated">即使滤波器在输入图像/矩阵中大步前进和滑动，它也使用相同的参数。</li><li id="1732" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc mi jx jy jz bi translated">有一个权重与每个滤波器单元和通道相关联。换句话说，一个过滤器有<em class="jd"> f_x * f_y * N_c </em>个权重。</li><li id="57c4" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc mi jx jy jz bi translated">整个滤波器只有一个偏置参数。</li></ol><p id="b0b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，如果卷积层采用大小为[<em class="jd">f _ x，f _ y</em>]的<em class="jd"> N_f </em>滤波器，对具有<em class="jd"> N_c </em>通道的输入图像进行卷积，则以下等式给出了添加到模型中的参数数量。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mj"><img src="../Images/3efeb209cc5a1ee026c9c8bfbadcb937.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1QLu9oTSBHBJkXhD.jpg"/></div></div><figcaption class="md me et er es mf mg bd b be z dx translated">等式1。卷积层增加参数个数的公式</figcaption></figure><h2 id="1684" class="li kg hi bd kh lj lk ll kl lm ln lo kp iq lp lq kt iu lr ls kx iy lt lu lb lv bi translated">1.4示例</h2><p id="db30" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">考虑下面的代码片段，其中100×95大小的“rgb”图像被连续通过两个卷积层。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="b1bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将表1和等式1中的公式投入使用，我们应该会得到以下输出形状和参数计数。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mm"><img src="../Images/032f1da24b6373619230a92d4ed4322d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DvYEh3batbWT58KIsKgSxg.png"/></div></div></figure><p id="538a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面运行Keras的输出与我们的预测相符。</p><pre class="jf jg jh ji fd mn mo mp mq aw mr bi"><span id="d50a" class="li kg hi mo b fi ms mt l mu mv">Layer (type) Output Shape Param # <br/>=================================================================<br/>Conv_Layer_1 (Conv2D) (None, 49, 94, 55) 1045 <br/>_________________________________________________________________<br/>Conv_Layer_2 (Conv2D) (None, 17, 47, 35) 19285 <br/>=================================================================<br/>Total params: 20,330<br/>Trainable params: 20,330<br/>Non-trainable params: 0</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mw"><img src="../Images/62743c148557f2d554810336a8141837.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*1TcaaT97g_sfzTfhI4L99g.png"/></div><figcaption class="md me et er es mf mg bd b be z dx translated">图3。Keras中的输出形状和参数计数与预测相匹配</figcaption></figure><h1 id="b2c7" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">2.汇集层</h1><p id="3e4c" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">池层与卷积层密切相关。它们的目的是减少上游卷积层输出的图像的尺寸。他们通过从每个汇集区中挑选一个(例如平均值或最大值)来实现。池区域是一片区域(很像卷积层中的过滤器),根据步幅和填充的设置在输入图像中移动。以下是关于池化图层的要点。</p><ul class=""><li id="8998" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated"><strong class="ih hj">输入/输出形状</strong>:计算输出图像尺寸(O_x，O_y)的规则/公式<strong class="ih hj">与卷积层的规则/公式</strong>相同。参数<em class="jd"> pooling_size </em>充当在定义卷积层的过滤器中使用的kernel_size的角色。另外，除非另有说明，否则<em class="jd">步距</em>与<em class="jd">池大小</em>相同。所以我们简单参考表1。</li><li id="210f" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated"><strong class="ih hj">可训练参数:</strong>没有参数。</li></ul><p id="5da1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">池层所做的就是为数据/形状转换应用固定的规则。这是与1.4节相同的例子，但是使用了池层。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="mk ml l"/></div></figure><p id="7b3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运行它，我们得到的输出图像形状(<em class="jd"> O_x </em>和<em class="jd"> O_y </em>)与我们之前看到的卷积层完全相同。在所有<em class="jd"> N_c </em>通道中独立发生池化，因此保留了通道的数量。</p><pre class="jf jg jh ji fd mn mo mp mq aw mr bi"><span id="0590" class="li kg hi mo b fi ms mt l mu mv">Layer (type) Output Shape Param # <br/>=================================================================<br/>Valid_Pool_Layer_1 (MaxPooli (None, 49, 94, 3) 0 <br/>_________________________________________________________________<br/>Same_Pool_Layer_2 (MaxPoolin (None, 17, 47, 3) 0 <br/>=================================================================<br/>Total params: 0<br/>Trainable params: 0<br/>Non-trainable params: 0</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mx"><img src="../Images/725f17387f1667347e624fe23470ffb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*vJQJjBaq_5lnAOD7DpS7Ew.png"/></div><figcaption class="md me et er es mf mg bd b be z dx translated">图4:池层根据表1中的公式修改图像大小。保留图像中的通道数。他们没有给模型添加任何参数</figcaption></figure><h1 id="ec45" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">3.可视化问答模型</h1><p id="16c5" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">我们用我们的公式解决Keras指南中的<a class="ae jq" href="https://keras.io/getting-started/functional-api-guide/#visual-question-answering-model" rel="noopener ugc nofollow" target="_blank">例题</a>来结束这篇文章。在其他层中，该示例使用了我们在本系列中研究过的密集层、嵌入层、LSTM层、Conv2D层和池层。以下是他们描述中的引文:</p><blockquote class="lw lx ly"><p id="ff32" class="if ig jd ih b ii ij ik il im in io ip lz ir is it ma iv iw ix mb iz ja jb jc hb bi translated"><em class="hi">当被问到关于一张图片的自然语言问题时，这个模型可以选择正确的一个单词的答案。</em></p><p id="c182" class="if ig jd ih b ii ij ik il im in io ip lz ir is it ma iv iw ix mb iz ja jb jc hb bi translated"><em class="hi">它的工作原理是将问题编码成一个向量，将图像编码成一个向量，将两者连接起来，并在潜在答案的一些词汇上进行逻辑回归训练。</em></p><p id="6bf4" class="if ig jd ih b ii ij ik il im in io ip lz ir is it ma iv iw ix mb iz ja jb jc hb bi translated"><em class="hi"> Keras指南</em></p></blockquote><p id="b40f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里是我们公式的总结，包括上一篇文章中的公式。我们将在核实时参考它。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es my"><img src="../Images/ee62c3911b960b6a537ac69765cc1681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oZHC3PD-PpopMtclZhb27Q.jpeg"/></div></div><figcaption class="md me et er es mf mg bd b be z dx translated">图5。各层形状和参数计算公式的总结。</figcaption></figure><p id="73a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">需要注意Keras中各层的默认设置。</p><ul class=""><li id="7926" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated">卷积层:步幅=(1，1)，填充= '有效'</li><li id="8feb" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">池层:跨度=池大小，填充= '有效'</li><li id="ceac" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">密集的LSTM图层:use_bias = True</li></ul><p id="36d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据我们的公式，代码片段、<em class="jd">预期的</em>形状/参数计数和<em class="jd">实际的</em> Keras输出，并按顺序显示在下面的每一层中。</p><pre class="jf jg jh ji fd mn mo mp mq aw mr bi"><span id="d4d8" class="li kg hi mo b fi ms mt l mu mv">_____________________________________________________________<br/>Layer (type) Output Shape Param # <br/>=================================================================<br/>vision_model.add(Conv2D(64, (3, 3), activation=’relu’, padding=’same’, input_shape=(224, 224, 3))) # <strong class="mo hj">Code snippet</strong></span><span id="c38f" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil(224/1) = 224 # As per formulae in Figure 5<br/>Num. Params: 64 * (3 * 3 * 3 + 1) = 64*28 = 1792 # <strong class="mo hj">As per formulae in Figure 5</strong></span><span id="8b02" class="li kg hi mo b fi mz mt l mu mv">conv2d_1 (Conv2D) (None, 224, 224, 64) 1792 # <strong class="mo hj">Actual by Keras/Tensorflow</strong><br/>_________________________________________________________________<br/>vision_model.add(Conv2D(64, (3, 3), activation=’relu’))</span><span id="5658" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil((224–3 + 1)/1) = 222<br/>Num. Params: 64 * (3*3*64 +1) = 64 * 577 = 36928</span><span id="f4e6" class="li kg hi mo b fi mz mt l mu mv">conv2d_2 (Conv2D) (None, 222, 222, 64) 36928 <br/>_________________________________________________________________<br/>vision_model.add(MaxPooling2D((2, 2)))</span><span id="c122" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil((222–2 + 1)/2) = 111<br/>Num. Params: 0</span><span id="b9c8" class="li kg hi mo b fi mz mt l mu mv">max_pooling2d_1 (MaxPooling2 (None, 111, 111, 64) 0<br/>_________________________________________________________________<br/>vision_model.add(Conv2D(128, (3, 3), activation=’relu’, padding=’same’))</span><span id="3290" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil(111/1) = 111<br/>Num. Params: 128 * (3 * 3 * 64 + 1) = 73856</span><span id="1e52" class="li kg hi mo b fi mz mt l mu mv">conv2d_3 (Conv2D) (None, 111, 111, 128) 73856<br/>_________________________________________________________________<br/>vision_model.add(Conv2D(128, (3, 3), activation=’relu’))</span><span id="839e" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil((111–3 + 1)/1) = 109<br/>Num. Params: 128 * (3 * 3 * 128 + 1) = 147584</span><span id="8d45" class="li kg hi mo b fi mz mt l mu mv">conv2d_4 (Conv2D) (None, 109, 109, 128) 147584<br/>_________________________________________________________________<br/>vision_model.add(MaxPooling2D((2, 2)))</span><span id="9ef4" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil((109–2 + 1)/2) = 54<br/>Num. Params: 0</span><span id="f53c" class="li kg hi mo b fi mz mt l mu mv">max_pooling2d_2 (MaxPooling2 (None, 54, 54, 128) 0<br/>_________________________________________________________________<br/>vision_model.add(Conv2D(256, (3, 3), activation=’relu’, padding=’same’))</span><span id="b440" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil(54/1) = 54<br/>Num. Params: 256 * (3 * 3 * 128 + 1) = 295168</span><span id="7f1f" class="li kg hi mo b fi mz mt l mu mv">conv2d_5 (Conv2D) (None, 54, 54, 256) 295168<br/>_________________________________________________________________<br/>vision_model.add(Conv2D(256, (3, 3), activation=’relu’))</span><span id="077b" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil((54–3+1)/1) = 52<br/>Num. Params: 256 * (3 * 3 * 256 + 1) = 590080</span><span id="2fee" class="li kg hi mo b fi mz mt l mu mv">conv2d_6 (Conv2D) (None, 52, 52, 256) 590080<br/>_________________________________________________________________<br/>vision_model.add(Conv2D(256, (3, 3), activation=’relu’))</span><span id="6e99" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil((52–3+1)/1) = 50<br/>Num. Params: 256 * (3 * 3 * 256 + 1) = 590080</span><span id="edf4" class="li kg hi mo b fi mz mt l mu mv">conv2d_7 (Conv2D) (None, 50, 50, 256) 590080<br/>_________________________________________________________________<br/>vision_model.add(MaxPooling2D((2, 2)))</span><span id="39b7" class="li kg hi mo b fi mz mt l mu mv">O_x = O_y = ceil((50–2 + 1)/2) = 25<br/>Num. Params: 0</span><span id="f25b" class="li kg hi mo b fi mz mt l mu mv">max_pooling2d_3 (MaxPooling2 (None, 25, 25, 256) 0<br/>_________________________________________________________________<br/>vision_model.add(Flatten())</span><span id="f1e4" class="li kg hi mo b fi mz mt l mu mv">All data as a single vector of size: 25*25*256 = 160000<br/>Num. Params = 0</span><span id="77bc" class="li kg hi mo b fi mz mt l mu mv">flatten_1 (Flatten) (None, 160000) 0<br/>=================================================================<br/>Total params: 1,735,488<br/>Trainable params: 1,735,488<br/>Non-trainable params: 0<br/>_________________________________________________________________<br/>__________________________________________________________________________________________________</span><span id="afda" class="li kg hi mo b fi mz mt l mu mv">encoded_image = vision_model(image_input)</span><span id="594d" class="li kg hi mo b fi mz mt l mu mv">Layer (type) Output Shape Param # Connected to <br/>==================================================================================================<br/>question_input = Input(shape=(100,), dtype=’int32')</span><span id="0310" class="li kg hi mo b fi mz mt l mu mv">sequenceLength = 100<br/>Num. Params = 0</span><span id="5a21" class="li kg hi mo b fi mz mt l mu mv">input_2 (InputLayer) (None, 100) 0<br/>__________________________________________________________________________________________________<br/>embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)</span><span id="7de0" class="li kg hi mo b fi mz mt l mu mv">nWords = 10000<br/>Num. Params = size of weight matrix = nWords * output_dim = 10000 * 256 = 2560000</span><span id="b68f" class="li kg hi mo b fi mz mt l mu mv">embedding_1 (Embedding) (None, 100, 256) 2560000 input_2[0][0] <br/>__________________________________________________________________________________________________<br/>input_1 (InputLayer) (None, 224, 224, 3) 0 <br/>__________________________________________________________________________________________________<br/>encoded_question = LSTM(256)(embedded_question)</span><span id="07b2" class="li kg hi mo b fi mz mt l mu mv">nFeatures=256, nUunits=256<br/>Num. Params = 4*nUnits*(nUnits+nFeatures+1) = 4*256*513 = 525312</span><span id="2588" class="li kg hi mo b fi mz mt l mu mv">lstm_1 (LSTM) (None, 256) 525312 embedding_1[0][0] <br/>__________________________________________________________________________________________________<br/>(this is just the convolved image as a vector obtained above after ‘flatten_1’)<br/>sequential_1 (Sequential) (None, 160000) 1735488 input_1[0][0]<br/>__________________________________________________________________________________________________<br/>merged = keras.layers.concatenate([encoded_question, encoded_image])</span><span id="b08c" class="li kg hi mo b fi mz mt l mu mv">Output size: 256 (from question/LSTM) + 160000 (from image/Conv2D) = 160256<br/>Num. Params = 0</span><span id="db64" class="li kg hi mo b fi mz mt l mu mv">concatenate_1 (Concatenate) (None, 160256) 0 lstm_1[0][0] <br/> sequential_1[1][0] <br/>__________________________________________________________________________________________________<br/>output = Dense(1000, activation=’softmax’)(merged)</span><span id="dadd" class="li kg hi mo b fi mz mt l mu mv">nFeatures = 160256, nUnits=1000, Output size: 1000<br/>#Params = nUnits*(nFeatures+1) = 1000 * (160256 + 1) = 160257000</span><span id="a40f" class="li kg hi mo b fi mz mt l mu mv">dense_1 (Dense) (None, 1000) 160257000 concatenate_1[0][0] <br/>==================================================================================================<br/>Total params: 165,077,800<br/>Trainable params: 165,077,800<br/>Non-trainable params: 0</span></pre><p id="b5e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们满意地注意到，随着数据从输入移动到输出，我们对输出形状和可训练参数数量的预测与每一层的Keras gets完全匹配。</p><h1 id="0a5a" class="kf kg hi bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">4.结论</h1><p id="2f4c" class="pw-post-body-paragraph if ig hi ih b ii ld ik il im le io ip iq lf is it iu lg iw ix iy lh ja jb jc hb bi translated">在本系列中，我们深入一些流行的层，看看它们如何扭曲传入的数据形状，以及它们使用了多少参数。从根本上理解这些阴谋诡计，可以揭开其背后的神秘面纱，使我们能够为新的应用程序设计高效的模型。</p></div><div class="ab cl na nb gp nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="hb hc hd he hf"><p id="a1f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">原载于2019年6月18日</em><a class="ae jq" href="http://xplordat.com/2019/06/18/reconciling-data-shapes-and-parameter-counts-in-keras/" rel="noopener ugc nofollow" target="_blank"><em class="jd">http://xplordat.com</em></a><em class="jd">。</em></p></div></div>    
</body>
</html>