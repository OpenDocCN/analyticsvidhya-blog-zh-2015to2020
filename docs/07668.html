<html>
<head>
<title>Intuition and Implementation of Gradient Boost Part-2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">梯度增强的直觉和实现第2部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/intuition-and-implementation-of-gradient-boost-part-2-f519af48ee2c?source=collection_archive---------11-----------------------#2020-07-03">https://medium.com/analytics-vidhya/intuition-and-implementation-of-gradient-boost-part-2-f519af48ee2c?source=collection_archive---------11-----------------------#2020-07-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7004" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">理解分类问题的数学直觉和梯度推进的实现…！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/a27c4b1c69cbad960700a93babb950ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*il-2dHeRGjeqceNCwYrFyQ.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">助推</figcaption></figure><blockquote class="jt ju jv"><p id="226e" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">📢注意:在阅读本文之前，请阅读我的文章《梯度增强的直觉和实现第1部分》,以便更好地理解梯度增强算法，其中我们将GBM用于回归问题链接:<a class="ae ka" rel="noopener" href="/analytics-vidhya/intuition-and-implementation-of-gradient-boost-part-1-1728eb463cf0">https://medium . com/analytics-vid hya/Intuition-and-Implementation-of-Gradient-Boost-Part-1-1728 EB 463 cf 0</a></p></blockquote><h1 id="8542" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">💥用于分类的梯度增强背后的直觉:</h1><blockquote class="jt ju jv"><p id="f53f" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">在这里，我们将理解梯度推进算法如何对分类问题起作用。</p><p id="9a98" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">我们将使用下面的数据集来理解GBM背后的直觉，其中我们收集了六个人对爆米花的偏好以及他们最喜欢的颜色，以预测他们是否喜欢电影《巨魔2》。</p><p id="30b7" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">注意:当梯度增强用于预测离散值时，我们说我们正在使用梯度增强进行分类。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kz"><img src="../Images/d843511bafb4777db66c05590a927fc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*POWc652eUMDdFux1FgKMuA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">数据集</figcaption></figure><h1 id="f19a" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">💛步骤1-计算目标变量的对数(赔率):</h1><blockquote class="jt ju jv"><p id="6e17" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">就像在回归的梯度推进中一样，我们从代表每个个体的初始预测的叶子开始。</p><p id="765c" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">当我们使用梯度推进进行分类时，每个个体的初始预测是对数(几率)。</p><p id="45bd" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">所以，我们来计算一下有人爱巨魔2的log(赔率)。既然，训练数据集中有4个人爱巨魔2，2个人不爱。那么有人爱巨魔2的log(odds)是log (4/2) =0.7，我们会把它放入我们的初始叶子。这是我们最初的预测。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es la"><img src="../Images/3bd9704790fdae01674a05d83e3756f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*mu2zrZjiSokDfBwUx73gUw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">叶节点</figcaption></figure><blockquote class="jt ju jv"><p id="c232" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">我们得到了最初的预测，但是我们如何使用它进行分类。就像逻辑回归一样，使用对数(比值)进行分类的最简单方法是将其转换为概率，我们使用逻辑函数或Sigmoid函数来实现这一点。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lb"><img src="../Images/8b552febd1b405f56ba0f1f61a0c5993.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FNWhxsdQfHEmlEt5_2KIHw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">逻辑函数</figcaption></figure><blockquote class="jt ju jv"><p id="1de5" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">因此，我们在上面的逻辑函数中插入Log(odds)</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lc"><img src="../Images/8c2d3544eb98a8bd4b4f1ceb243cb9c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vg0Ep2OlBS7OX4oIMHuHBA.png"/></div></div></figure><blockquote class="jt ju jv"><p id="d2e9" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">对于训练数据的所有样本，我们得到0.7作为喜爱Troll 2的概率</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ld"><img src="../Images/9b097200d80e3cbf164cbda1c23269d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8bKbhdqgezBwZJT68HUTow.png"/></div></div></figure><blockquote class="jt ju jv"><p id="0059" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">既然喜欢巨魔2的概率大于0.5，我们就可以把训练数据集中的每个人都归为喜欢巨魔2的人。</p><p id="ddd0" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">📢注意:虽然0.5是基于概率进行分类决策的一个非常常见的阈值，但是我们也可以轻松地使用不同的值。</p></blockquote><h1 id="87e1" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">💙第二步:根据前一个树的错误建立树。</strong></h1><blockquote class="jt ju jv"><p id="72c0" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在，将训练数据集中的每个人归类为喜欢巨魔2的人是非常蹩脚的，因为其中两个人不喜欢这部电影，如下面的数据集所示。记录3和4表明他们不喜欢巨魔2。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/fb58f0809961758eb6ee8b6a2443f8d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*_hGFbm5w3gZjqdV92FWb9Q.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">数据集</figcaption></figure><blockquote class="jt ju jv"><p id="34aa" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">我们可以通过计算伪残差，即观察值和预测值之间的差异，来衡量初始预测有多差。</p><p id="4e0d" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">残差=(观察值-预测值)</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/371f1d7cf06af0ccd85005ba4def11ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*jXjw2caZ3xNUQzDrm68acQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图表</figcaption></figure><blockquote class="jt ju jv"><p id="8027" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">虽然数学很简单，但我认为如果我们在图上画出残差，会更容易理解发生了什么。</p><p id="120e" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">y轴是喜欢巨魔2的概率。喜欢巨魔2的预测概率是0.7，如上图虚线所示。喜欢Troll 2的概率=0的红点表示不喜欢Troll 2的两个人(训练数据集的样本3和4)，而喜欢Troll 2的概率=1的蓝点表示喜欢Troll 2的四个人(训练数据集的样本3和4除外)。换句话说，红点和蓝点是观察值，虚线是预测值。</p><p id="4328" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">📢注意:第一个蓝点代表训练数据集的第一个样本，第二个蓝点代表记录的第二个样本，依此类推，第一个红点代表训练数据集的第三个样本，第二个红点代表训练数据集的第四个样本。</p><p id="cb93" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">因此，现在我们将计算训练数据的所有样本的残差。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/32e9a87249edace8d4cc121f4311a7c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*dA1n8gF0H9nVj5y-IystDA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">样本1</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/d5177ca4d4727b1db10b4226b0d142c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*fsHDTWcbztSj-2XhXv6QjA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">剩余示例</figcaption></figure><blockquote class="jt ju jv"><p id="a44e" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">因此，对于上面的示例，我们为观察值(参考上图)插入1，为预测值插入0.7。</p><p id="e2a7" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">残差=(观察值-预测值)</p><p id="c827" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi">= (1–0.7) =0.3</p><p id="0e13" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">类似地，我们计算训练数据的所有样本的残差，并且我们得到如下所示的残差。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lg"><img src="../Images/8b7f54cea6a7d53a3725488b0fb20412.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*GTE-c2rfsRD3N2BY9Anc1g.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">新数据集</figcaption></figure><blockquote class="jt ju jv"><p id="63bf" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">📢注意:将训练数据集的样本3和样本4的观察值作为0，以获得残差。</p><p id="4e58" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在，我们将使用爆米花、年龄和喜欢的颜色作为自变量，残差作为因变量来构建一棵树。下面给出了形成的树。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lh"><img src="../Images/8e46a8cfdb2a4e24cb07176d44b55395.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*OuKonH7bmEi19DLToxeThg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">第一棵树</figcaption></figure><blockquote class="jt ju jv"><p id="74f3" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">注意:就像我们使用梯度推进回归一样，我们限制了树中允许的叶子数量。在上面的树中，我们将叶子的数量限制为3。实际上，人们通常将最大叶片数设置在8到32之间。</p><p id="cfa5" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在让我们来计算树叶的输出值。样本1、5和6放在第三片叶子上。样本2和3到第二个叶子，样本4到第一个叶子，如上树所示。</p><p id="159a" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">当我们使用梯度增强进行回归时，具有单个残差的叶子具有等于该残差的输出值。相比之下，当我们使用梯度推进进行分类时，情况就不那么复杂了。这是因为预测是根据对数(赔率)进行的，而上述树中的第一片叶子是从一个概率中派生出来的。所以，我们不能只是把它们加在一起，不经过某种转换就得到一个新的对数(几率)预测。</p><p id="dc4b" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">因此，当我们使用梯度增强进行分类时，我们使用的最常见的变换如下所示。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es li"><img src="../Images/5f5e1de6e09881e2922de9914c7d4941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*RlndWFVv-9oqk-TrBu-sJg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">转换公式</figcaption></figure><blockquote class="jt ju jv"><p id="e5b8" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">分子是叶子中所有残差的和，分母是每个残差的先前预测概率的和乘以1减去相同的预测概率。</p><p id="d96b" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在我们将使用公式来计算树的第一片叶子的输出值。因为我们在第一个叶子中只有一个残数，即-0.7，所以我们用残数值替换分子，并且因为我们正在构建第一棵树，所以先前的概率指的是来自初始叶子的概率0.7。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/78034cc1e579925c5bb23b6c16da630a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kMrYQNnp68N6VIes17t31g.png"/></div></div></figure><blockquote class="jt ju jv"><p id="693d" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在我们需要计算树的第二片叶子的输出值。因为我们在第二个叶中有两个残差，即0.3和-0.7，所以我们用两个残差的和替换分子，并且因为我们正在构建第一棵树，所以先前的概率指的是来自初始叶的概率0.7。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lk"><img src="../Images/c5bda12d1cd56f4a13d938425baafd3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jBnlDNoJKHwySpoie0fXbA.png"/></div></div></figure><blockquote class="jt ju jv"><p id="3e55" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">📢注意:现在，前面的概率对于所有的残差都是相同的，但是当我们构建下一棵树时，这将会改变。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/da9d025a07e7dcc57fc98eb8c8a78193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pjNg3aumIzfoye5JoVDZMA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lm"><img src="../Images/19655552dc0694f11e8afa13c8c66303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*wIvLL3-8DA0OqaxKemoQ6A.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">模型1 =第一片叶子+第一棵树</figcaption></figure><blockquote class="jt ju jv"><p id="6e5a" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">以上是添加带有初始叶节点的树后生成的模型。</p></blockquote><h1 id="83c5" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">🧡STEP 3:对完整的训练数据进行预测。</h1><blockquote class="jt ju jv"><p id="30fb" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">让我们通过将样本传递给上面的模型来尝试计算下面给出的人的对数(赔率)预测。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/c2b250a541b9e01c97fe8415830d1bff.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*UnroVFjsETm2Qsl4HwIFGg.png"/></div></figure><blockquote class="jt ju jv"><p id="dbfa" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">最初，当样本通过初始叶时，对数(优势)预测为0.7，当我们通过树时，对数(优势)预测为</p><p id="e45c" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi">= 0.7+(0.8*1.4)</p><p id="7a8c" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi">= 1.8</p><p id="27d8" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">📢注意:上面的0.7表示宝贵叶的对数(赔率)预测，0.8是与我们在回归问题的梯度推进中讨论的学习率相同的学习率，1.4是第三叶的输出，因为上面取得的样本落入第三叶。</p><p id="6b9d" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">对于上面的样本，我们得到的log(odds)预测值为1.8。现在，我们使用下面的公式将对数(赔率)预测转换成概率。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/7434cf046091f7d92945e72d98f3c5d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uF6wqG-UfbOdK9srbPGUaA.png"/></div></div></figure><blockquote class="jt ju jv"><p id="8127" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">上面的样本的新预测概率是0.9，上面的样本的初始概率是0.7，现在我们得到了0.9，所以我们在正确的方向上迈出了一小步，因为这个人喜欢巨魔2。</p><p id="4e91" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">类似地，我们计算训练数据的所有样本的对数(比值)预测，并且我们得到如下所示的预测概率列中的概率。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lp"><img src="../Images/64800263cc9f87be4114fab9291639ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*mFlVcNpfAAdojUAaxkFCyQ.png"/></div></figure><blockquote class="jt ju jv"><p id="68f9" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在重复第2步和第3步，直到残差变为0或达到您要求的树的数量。</p><p id="e536" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">下面是执行步骤2后我们得到的残差和树</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/020ac3efd7f59d77baa547c9d6cada5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*DDLB8F0Xe_tGKQP077VNHA.png"/></div></figure><blockquote class="jt ju jv"><p id="f1ff" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">下图是使用爆米花、年龄和喜爱的颜色作为自变量，残差作为因变量获得的树，如上图所示</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lr"><img src="../Images/117aef6599519443afffd95f47e231df.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*mZsHX7SHvySpMfENUX_7Mw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">第二棵树</figcaption></figure><blockquote class="jt ju jv"><p id="6445" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在我们需要计算每片叶子的输出值，就像我们在上面的步骤2中所做的那样。因为我们在上面的树上有三片叶子。第一片叶子的输出值是-2，第二片叶子的输出值是0.6，第三片叶子的输出值是2。</p><p id="d49d" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在我们需要通过下面的模型测试所有的训练元组，这是第三步</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/1208d2e6b24259a956ce4d5b98cdcbcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*dMUH38B6JlR2lNLqTu1yZA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">模型2</figcaption></figure><blockquote class="jt ju jv"><p id="cbf8" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">以上是将新构建的树添加到之前的模型后生成的模型2。现在我们将使用上述模型来获得训练数据的新概率。</p><p id="8f00" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">再次获得预测概率后，重复第2步和第3步，直到残差变为零或达到您要求的树的数量。只要您要求的树的数量尚未达到，新构建的树将被添加到以前的模型中。</p><p id="833e" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">假设我们只要求了两棵树，那么我们的训练到此结束。</p><p id="3d4c" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在，如果我们使用上面的模型2测试一个看不见的元组。设一个看不见的元组如下，现在我们需要分类他是否喜欢巨魔2。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lt"><img src="../Images/94f9ea1eafda274faaf8cf5f227ff0fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*42UIFkwrKHxpUiKYmGdudQ.png"/></div></figure><blockquote class="jt ju jv"><p id="5589" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">预测从叶开始，即0.7，然后我们沿着第一棵树运行数据，并添加缩放的输出值0.7+(0.8 *1.4)，然后我们沿着第二棵树运行数据，并添加缩放的输出值0.7+(0.8*1.4)+(0.8*0.6)。请仔细看模型2以便理解。</p><p id="bc9c" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">有人爱巨魔2的log(odds)预测= 0.7+(0.8*1.4) + (0.8*0.6)</p><p id="7b87" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi">= 2.3</p><p id="c12f" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在我们需要使用下面给出的公式将对数(赔率)预测转换成概率。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lu"><img src="../Images/21e6510991cd2e2f01f1dbd606ac15c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OZ7ZnqCJqPAY4lM5eR_tMA.png"/></div></div></figure><blockquote class="jt ju jv"><p id="9acd" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">现在预测这个人喜欢巨魔2的概率是0.9。既然，我们是用0.5作为阈值来决定如何对人进行分类，0.9 &gt;0.5我们就把这个人归类为喜欢巨魔2的人，如下图。</p></blockquote><h1 id="41ea" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">💥使用Python实现分类。</h1><p id="5af3" class="pw-post-body-paragraph if ig hi ih b ii lv ik il im lw io ip iq lx is it iu ly iw ix iy lz ja jb jc hb bi translated">这里我们使用虹膜数据集来解决分类问题</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ma"><img src="../Images/f7097591734c958f1b4e7cf679e2e81c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*am4v_K3L5297La72kP9A9A.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/63e780aebac543766369a604207c1bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3q2pN-XIJiKdacLgUyIqJA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mc"><img src="../Images/29b583cbe98958c4ca4ddfa981b85763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o36FmUtYBMR_gnq6WMO7pQ.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/a8e2a7fe08f91d5626df30ac0f4dfa0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kyAsXqAGJ-N6IaZbKWr1Ew.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es me"><img src="../Images/377a1514a108b27cab2272a079e39749.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GPn9jQ0MIvLQrnSfd9myBg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mf"><img src="../Images/099f1609d5a11214c11b13609eed677a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aGzcYllsOvN_lpZ9kU10Bw.png"/></div></div></figure><p id="a513" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您发现帖子中有任何错误或有任何补充，请在评论中讨论:P <br/>谢谢。</p><p id="46c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">信用和来源:</strong></p><ol class=""><li id="7d47" class="mg mh hi ih b ii ij im in iq mi iu mj iy mk jc ml mm mn mo bi translated"><a class="ae ka" href="https://statquest.org/video-index/" rel="noopener ugc nofollow" target="_blank"> StatQuest </a></li><li id="a28c" class="mg mh hi ih b ii mp im mq iq mr iu ms iy mt jc ml mm mn mo bi translated"><a class="ae ka" href="https://www.analyticsvidhya.com/blog/2016/03/pca-practical-guide-principal-component-analysis-python/" rel="noopener ugc nofollow" target="_blank">www.Analyticsvidhya.com</a></li></ol></div></div>    
</body>
</html>