<html>
<head>
<title>Tackle almost any Audio Classification challenge with this!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用这个解决几乎任何音频分类的挑战！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tackle-almost-any-audio-classification-challenge-with-this-34a1d0ac82b9?source=collection_archive---------0-----------------------#2019-08-18">https://medium.com/analytics-vidhya/tackle-almost-any-audio-classification-challenge-with-this-34a1d0ac82b9?source=collection_archive---------0-----------------------#2019-08-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="760b" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">音频分类问题的最终解决方案。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/ae4fb27251f0270ac01439fa79859bc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7pOTqAsFyYjJz6W1El56lA.png"/></div></div></figure><h2 id="dafa" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">介绍</h2><p id="7599" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp ju kq kr ks jy kt ku kv kc kw kx ky kz hb bi translated">在大学期间，我偶然发现了深度学习和T2学习的迷人世界，并决定在这个领域开始我的主要项目。虽然深度学习技术通常有助于解决像图像分类、语言翻译这样的问题，但是不存在用于音频分类的健壮技术，因为它们存在于上述问题中。本文将以我的主要项目<strong class="kj hj"><em class="la">为例，对任何音频分类挑战给出一个健壮的解决方案，该项目名为印度古典音乐</em> </strong>中的<a class="ae lb" href="https://en.wikipedia.org/wiki/Tabla" rel="noopener ugc nofollow" target="_blank"><strong class="kj hj"><em class="la">Tabla</em></strong></a><strong class="kj hj"><em class="la"/></strong><a class="ae lb" href="https://en.wikipedia.org/wiki/Tala_(music)" rel="noopener ugc nofollow" target="_blank"><strong class="kj hj"><em class="la">taala</em></strong></a><strong class="kj hj"><em class="la">的自动检测和分类。</em></strong></p><p id="964a" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated"><strong class="kj hj"> Nota受益人:</strong></p><p id="4682" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">Tabla →是一种印度打击乐器，一般用来为印度古典音乐伴奏。</p><p id="1155" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">Taala →是印度古典音乐中的一个术语，指的是一个音乐<a class="ae lb" href="https://en.wikipedia.org/wiki/Metre_(music)" rel="noopener ugc nofollow" target="_blank">节拍</a>。</p><h2 id="e253" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">一切都与数据有关！</h2><p id="b2e1" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp ju kq kr ks jy kt ku kv kc kw kx ky kz hb bi translated">使用的数据集是定制的。taala是使用<a class="ae lb" href="https://apps.apple.com/in/app/itablapro-lite/id919001492" rel="noopener ugc nofollow" target="_blank"> iOS应用</a>和舒尔SM58S话筒录制的。数据集可以在<a class="ae lb" href="https://github.com/pranav6670/Detection-Classification-of-Tabla-taals/tree/master/wavfiles" rel="noopener ugc nofollow" target="_blank">这里</a>找到。数据集包含10类taala，每类70-80个样本。记录的音频具有44.1 kHz的采样率。制作了一个CSV文件，其中包含所有样本及其对应的类名。</p><p id="1d69" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">使用以下工具实时录制音频:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lh li l"/></div></figure></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lq"><img src="../Images/f73dfceb04f6b638bb3d8f3be93a71f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7SseQ60aqLfRONmXqDj3pQ.png"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">每类随机样本的时域图。</figcaption></figure><p id="4e18" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">数据预处理包括:</p><ol class=""><li id="8149" class="lv lw hi kj b kk lc kn ld ju lx jy ly kc lz kz ma mb mc md bi translated">下采样至16 kHz →下采样是指降低信号的采样速率。由于数据的采样率为44.1 kHz(音频信号的通用采样率)，因此<a class="ae lb" href="https://en.wikipedia.org/wiki/Nyquist_frequency" rel="noopener ugc nofollow" target="_blank">奈奎斯特频率</a>将约为22 kHz。如同在语音或乐器音频中一样，变化发生在较低的频带中，即高达8 kHz，音频被下采样到16 kHz。进行这种下采样大大减少了数据/信息。但是由于在8kHz左右的频率之后没有相关数据，下采样没有导致数据丢失。</li><li id="04c0" class="lv lw hi kj b kk me kn mf ju mg jy mh kc mi kz ma mb mc md bi translated">音频清理→记录数据时，数据的某些部分(开头或结尾)没有声音。为了消除零幅度数据，实现了一种包络检测算法，该算法将寻找无声部分并消除它们。</li></ol><p id="74bc" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">数据降采样和清理:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lh li l"/></div></figure></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lq"><img src="../Images/70cafccd1264a58751e1d5bf5788ed3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*efjjl1QThYC8SVipeWkH1g.png"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">数据集的类别分布</figcaption></figure><p id="6e3d" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">使用以下方法获得如上饼图:</p><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="ded3" class="jj jk hi mk b fi mo mp l mq mr">fig, ax = plt.subplots()<br/>ax.set_title('Class Distribution', y=1.08)<br/>ax.pie(class_dist, labels=class_dist.index, autopct='%1.1f%%', shadow=False, startangle=90)<br/>ax.axis('equal')<br/>plt.show()</span></pre><p id="4105" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated"><code class="du ms mt mu mk b">class_dist</code>是一个变量，它是一个<a class="ae lb" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">熊猫</a>序列，包含所有同类样本长度的平均值，由下式得到:</p><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="33bb" class="jj jk hi mk b fi mo mp l mq mr">class_dist = df.groupby(['label'])['length'].mean()</span></pre><h2 id="c4a1" class="jj jk hi bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">终极解决方案:</h2><p id="8279" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp ju kq kr ks jy kt ku kv kc kw kx ky kz hb bi translated">音频是快速变化的数据。我们从时域图中注意到音频样本的变化。为了获得数据的相关表示，我们对原始(记录的)音频数据应用傅立叶变换。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lq"><img src="../Images/f4f426277e216c4342f7a809a5df4a72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vgOTBice18zPAxnGrXwolg.png"/></div></div></figure><p id="5f2a" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">但正如我们所见，在频域中，数据无法以可区分的方式表示。现在，为了表示数据，以便分类算法能够稳健地检测类别，我们需要从音频数据中提取特征。在这种情况下，提取音频数据的梅尔频率倒谱系数(MFCC)。</p><p id="1cbc" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">使用<code class="du ms mt mu mk b">python_speech_features</code>库，我们从音频中提取了<a class="ae lb" href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/" rel="noopener ugc nofollow" target="_blank"> MFCC </a> s。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lq"><img src="../Images/4b3e71bd7f4a83b94fd7b55bab926c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cfbq_kGULDmPjGPSPjsIhg.png"/></div></div></figure><blockquote class="mv mw mx"><p id="73cb" class="kh ki la kj b kk lc ij km kn ld im kp my le kr ks mz lf ku kv na lg kx ky kz hb bi translated">但主要的诀窍就在于这一步。从数据中提取特征时，会使用一个窗口。这里的窗口意味着只考虑0.1秒的音频并对其采取行动。</p></blockquote><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="1097" class="jj jk hi mk b fi mo mp l mq mr">n_samples = 2 * int(df['length'].sum()/0.1)</span></pre><blockquote class="mv mw mx"><p id="dd6b" class="kh ki la kj b kk lc ij km kn ld im kp my le kr ks mz lf ku kv na lg kx ky kz hb bi translated">使用这样的窗口可以从单个样本创建大量样本。想法是使用样本长度的1/10秒，提取该部分的特征，并以同样的方式进行。该窗口继续滚动，直到样品结束，以生成大量样品。这种技术允许使用深度学习，而不管数据集中的样本数量。</p></blockquote><p id="bfc8" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">瞧😉搞定了！！</p><p id="ee37" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">此外，CNN/RNN可以用于对音频进行分类。</p><p id="0836" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">我的CNN和RNN的项目实施:-</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lh li l"/></div></figure><p id="71c7" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated"><strong class="kj hj">结论:</strong></p><p id="7bb9" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">使用上述技巧，卷积神经网络(具有50个时期)提供了大约80%的准确度。</p><blockquote class="nb"><p id="2aef" class="nc nd hi bd ne nf ng nh ni nj nk kz dx translated">纪元50/50<br/>58597/58597[= = = = = = = = = = = = = = = = = = = = = = = = = = =]—313s 5 ms/step—loss:0.4587—ACC:0.8283—val _ loss:0.7678—val _ ACC:0.7354</p><p id="0811" class="nc nd hi bd ne nf ng nh ni nj nk kz dx translated">纪元00050: val_acc从0.74213开始没有改进</p></blockquote><p id="753d" class="pw-post-body-paragraph kh ki hi kj b kk nl ij km kn nm im kp ju nn kr ks jy no ku kv kc np kx ky kz hb bi translated">然而，LSTM提供了大约60%的准确度(10个时期)。</p><blockquote class="nb"><p id="ec0e" class="nc nd hi bd ne nf ng nh ni nj nk kz dx translated">epoch 10/10<br/>58597/58597[= = = = = = = = = = = = = = = = = = = = = = = = = =]—125s 2 ms/step—loss:1.0737—ACC:0.5969—val _ loss:1.0558—val _ ACC:0.6117</p><p id="0f6e" class="nc nd hi bd ne nf ng nh ni nj nk kz dx translated">Epoch 00010: val_acc从0.58762提高到0.61173，将模型保存到models/rec.model</p></blockquote><p id="b8d5" class="pw-post-body-paragraph kh ki hi kj b kk nl ij km kn nm im kp ju nn kr ks jy no ku kv kc np kx ky kz hb bi translated"><strong class="kj hj">资源:</strong></p><ol class=""><li id="1d29" class="lv lw hi kj b kk lc kn ld ju lx jy ly kc lz kz ma mb mc md bi translated"><a class="ae lb" href="https://www.analyticsvidhya.com/blog/2017/08/audio-voice-processing-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2017/08/audio-voice-processing-deep-learning/</a></li><li id="7256" class="lv lw hi kj b kk me kn mf ju mg jy mh kc mi kz ma mb mc md bi translated"><a class="ae lb" href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/" rel="noopener ugc nofollow" target="_blank">http://practical cryptography . com/miscellaneous/machine-learning/guide-Mel-frequency-ceps tral-coefficients-mfccs/</a></li><li id="e1f5" class="lv lw hi kj b kk me kn mf ju mg jy mh kc mi kz ma mb mc md bi translated">【https://keras.io/getting-started/functional-api-guide/ T4】</li></ol><p id="4535" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">本文中使用的所有代码都可以在这里找到:</p><div class="nq nr ez fb ns nt"><a href="https://github.com/pranav6670/Detection-Classification-of-Tabla-taals" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab dw"><div class="nv ab nw cl cj nx"><h2 class="bd hj fi z dy ny ea eb nz ed ef hh bi translated">pranav 6670/检测分类表</h2><div class="oa l"><h3 class="bd b fi z dy ny ea eb nz ed ef dx translated">这个项目工作的目的是开发一个系统，能够首先从一个混合(一首歌)和一个…</h3></div><div class="ob l"><p class="bd b fp z dy ny ea eb nz ed ef dx translated">github.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh jh nt"/></div></div></a></div><p id="4ca8" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated">取得联系！</p><p id="f257" class="pw-post-body-paragraph kh ki hi kj b kk lc ij km kn ld im kp ju le kr ks jy lf ku kv kc lg kx ky kz hb bi translated"><a class="ae lb" href="https://github.com/pranav6670" rel="noopener ugc nofollow" target="_blank"> Github </a> <a class="ae lb" href="https://mail.google.com/mail/u/0/?view=cm&amp;fs=1&amp;tf=1&amp;source=mailto&amp;to=pranavnat24@gmail.com" rel="noopener ugc nofollow" target="_blank">邮件</a>我的<a class="ae lb" href="https://pranav6670.github.io/" rel="noopener ugc nofollow" target="_blank">作品集</a></p></div></div>    
</body>
</html>