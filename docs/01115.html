<html>
<head>
<title>Writing a Spark Dataframe to an Elasticsearch Index</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将Spark数据帧写入弹性搜索索引</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/writing-a-spark-dataframe-to-an-elasticsearch-index-16fdedd74ff7?source=collection_archive---------4-----------------------#2019-10-02">https://medium.com/analytics-vidhya/writing-a-spark-dataframe-to-an-elasticsearch-index-16fdedd74ff7?source=collection_archive---------4-----------------------#2019-10-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/732a8ce2bba0867b7beead4caeb0ca42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*c1SVmMzkLSoPgBl5cv4nNw.png"/></div></figure><p id="44e8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本帖中，我们将详细介绍为弹性搜索指数写Spark <code class="du jk jl jm jn b">DataFrame</code>的过程。</p><p id="d3d7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Elastic通过<a class="ae jo" href="https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html" rel="noopener ugc nofollow" target="_blank"> elasticsearch-hadoop </a>提供Apache Spark支持，它具有elasticsearch和Apache Spark之间的原生集成。</p><p id="c375" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">注意:所有例子都是用Scala 2.11和Spark SQL 2.3.x编写的。有Apache Spark的经验是先决条件。</strong></p><h1 id="70e6" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">细分:</h1><ul class=""><li id="bd3e" class="kn ko hi io b ip kp it kq ix kr jb ks jf kt jj ku kv kw kx bi translated">Maven依赖项。</li><li id="64c0" class="kn ko hi io b ip ky it kz ix la jb lb jf lc jj ku kv kw kx bi translated">Spark-ES配置。</li><li id="5017" class="kn ko hi io b ip ky it kz ix la jb lb jf lc jj ku kv kw kx bi translated">writeToIndex()代码。</li></ul><h1 id="6bfb" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">Maven依赖性</h1><p id="cd37" class="pw-post-body-paragraph im in hi io b ip kp ir is it kq iv iw ix ld iz ja jb le jd je jf lf jh ji jj hb bi translated">下面提到的依赖项应该出现在您的<code class="du jk jl jm jn b">classpath</code>中。<code class="du jk jl jm jn b">elasticsearch-spark-20</code>为Spark提供原生的Elasticsearch支持，需要<code class="du jk jl jm jn b">commons-httpclient</code>对Elasticsearch APIs进行RESTful调用。出于某种奇怪的原因，这个版本的<code class="du jk jl jm jn b">elasticsearch-spark-20</code>省略了http客户端依赖，所以必须手动添加。</p><pre class="lg lh li lj fd lk jn ll lm aw ln bi"><span id="e0d9" class="lo jq hi jn b fi lp lq l lr ls">-------------------<br/>Snippet of the pom.xml<br/>-------------------<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;<br/>    &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt;<br/>    &lt;version&gt;2.3.0&lt;/version&gt;<br/>&lt;/dependency&gt;<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;commons-httpclient&lt;/groupId&gt;<br/>    &lt;artifactId&gt;commons-httpclient&lt;/artifactId&gt;<br/>    &lt;version&gt;3.1&lt;/version&gt;<br/>&lt;/dependency&gt;<br/>&lt;dependency&gt;<br/>    &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;<br/>    &lt;artifactId&gt;elasticsearch-spark-20_2.11&lt;/artifactId&gt;<br/>    &lt;version&gt;6.4.2&lt;/version&gt;<br/>&lt;/dependency&gt;</span></pre><h1 id="4828" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">Spark-ES配置</h1><p id="a351" class="pw-post-body-paragraph im in hi io b ip kp ir is it kq iv iw ix ld iz ja jb le jd je jf lf jh ji jj hb bi translated">为了让Spark与Elasticsearch通信，我们需要知道ES节点的位置以及与之通信的端口。这些通过设置<code class="du jk jl jm jn b">spark.es.nodes</code>和<code class="du jk jl jm jn b">spark.es.port</code>配置提供给<code class="du jk jl jm jn b">SparkSession</code>。</p><p id="498f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="lt">注意:这里的例子使用了托管到AWS的Elasticsearch，因此需要一个额外的配置</em> <code class="du jk jl jm jn b"><em class="lt">spark.es.nodes.wan.only</em></code> <em class="lt">来设置为</em> <code class="du jk jl jm jn b"><em class="lt">true</em></code> <em class="lt">。</em></p><p id="2dea" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们看一些创建<code class="du jk jl jm jn b">SparkSession</code>的代码。</p><pre class="lg lh li lj fd lk jn ll lm aw ln bi"><span id="43e0" class="lo jq hi jn b fi lp lq l lr ls"><strong class="jn hj">val</strong> spark <strong class="jn hj">=</strong> <strong class="jn hj">SparkSession</strong><br/>   <strong class="jn hj">.</strong>builder<strong class="jn hj">()</strong><br/>   <strong class="jn hj">.</strong>appName<strong class="jn hj">(</strong>"WriteToES"<strong class="jn hj">)</strong><br/>   <strong class="jn hj">.</strong>master<strong class="jn hj">(</strong>"local[*]"<strong class="jn hj">)</strong><br/>   <strong class="jn hj">.</strong>config<strong class="jn hj">(</strong>"spark.es.nodes"<strong class="jn hj">,</strong>"&lt;IP-OF-ES-NODE&gt;"<strong class="jn hj">)</strong><br/>   <strong class="jn hj">.</strong>config<strong class="jn hj">(</strong>"spark.es.port"<strong class="jn hj">,</strong>"&lt;ES-PORT&gt;"<strong class="jn hj">)</strong><br/>   <strong class="jn hj">.</strong>config<strong class="jn hj">(</strong>"spark.es.nodes.wan.only"<strong class="jn hj">,</strong>"true"<strong class="jn hj">)</strong> <em class="lt">//Needed for ES on AWS<br/></em>   <strong class="jn hj">.</strong>getOrCreate<strong class="jn hj">()</strong></span></pre><h1 id="faf2" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">writeToIndex()代码</h1><p id="ec48" class="pw-post-body-paragraph im in hi io b ip kp ir is it kq iv iw ix ld iz ja jb le jd je jf lf jh ji jj hb bi translated">首先，我们将定义一个<code class="du jk jl jm jn b"><strong class="io hj">case</strong> <strong class="io hj">class</strong></code>来表示我们的索引结构。</p><pre class="lg lh li lj fd lk jn ll lm aw ln bi"><span id="7cd3" class="lo jq hi jn b fi lp lq l lr ls"><strong class="jn hj">case</strong> <strong class="jn hj">class</strong> <strong class="jn hj">AlbumIndex(</strong>artist<strong class="jn hj">:String,</strong> yearOfRelease<strong class="jn hj">:Int,</strong> albumName<strong class="jn hj">:</strong> <strong class="jn hj">String)</strong></span></pre><p id="afa7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，我们将创建一个<code class="du jk jl jm jn b">AlbumIndex</code>对象的<code class="du jk jl jm jn b">Seq</code>，并使用方便的<code class="du jk jl jm jn b">.toDF()</code>函数将它们转换成一个<code class="du jk jl jm jn b">DataFrame</code>，该函数可以通过导入<code class="du jk jl jm jn b">spark.implicits._</code>来调用。</p><pre class="lg lh li lj fd lk jn ll lm aw ln bi"><span id="914f" class="lo jq hi jn b fi lp lq l lr ls"><strong class="jn hj">import</strong> spark.implicits._</span><span id="b26b" class="lo jq hi jn b fi lu lq l lr ls">   <strong class="jn hj">val</strong> indexDocuments <strong class="jn hj">=</strong> <strong class="jn hj">Seq(</strong><br/>        <strong class="jn hj">AlbumIndex(</strong>"Led Zeppelin"<strong class="jn hj">,</strong>1969<strong class="jn hj">,</strong>"Led Zeppelin"<strong class="jn hj">),</strong><br/>        <strong class="jn hj">AlbumIndex(</strong>"Boston"<strong class="jn hj">,</strong>1976<strong class="jn hj">,</strong>"Boston"<strong class="jn hj">),</strong><br/>        <strong class="jn hj">AlbumIndex(</strong>"Fleetwood Mac"<strong class="jn hj">,</strong> 1979<strong class="jn hj">,</strong>"Tusk"<strong class="jn hj">)</strong><br/>   <strong class="jn hj">).</strong>toDF</span></pre><p id="0d2c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="lt">注:</em> <code class="du jk jl jm jn b"><em class="lt">spark</em></code> <em class="lt">此处代表</em> <code class="du jk jl jm jn b"><em class="lt">SparkSession</em></code> <em class="lt">对象。</em></p><p id="61b0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一旦我们准备好了<code class="du jk jl jm jn b">DataFrame</code>，我们需要做的就是导入<code class="du jk jl jm jn b">org.elasticsearch.spark.sql._</code>并调用它的<code class="du jk jl jm jn b">.saveToEs()</code>方法。</p><pre class="lg lh li lj fd lk jn ll lm aw ln bi"><span id="3f9c" class="lo jq hi jn b fi lp lq l lr ls"><strong class="jn hj">import</strong> org.elasticsearch.spark.sql._</span><span id="082a" class="lo jq hi jn b fi lu lq l lr ls">indexDocuments<strong class="jn hj">.</strong>saveToEs<strong class="jn hj">(</strong>"demoindex/albumindex"<strong class="jn hj">)</strong></span></pre><p id="0ef4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这是完整的源代码。</p><pre class="lg lh li lj fd lk jn ll lm aw ln bi"><span id="af51" class="lo jq hi jn b fi lp lq l lr ls"><strong class="jn hj">import</strong> org.apache.spark.sql.SparkSession<br/><strong class="jn hj">import</strong> org.elasticsearch.spark.sql._</span><span id="a38a" class="lo jq hi jn b fi lu lq l lr ls"><strong class="jn hj">object</strong> <strong class="jn hj">WriteToElasticSearch</strong> <strong class="jn hj">{</strong></span><span id="39eb" class="lo jq hi jn b fi lu lq l lr ls"> <strong class="jn hj">def</strong> main<strong class="jn hj">(</strong>args<strong class="jn hj">:</strong> <strong class="jn hj">Array[String]):</strong> <strong class="jn hj">Unit</strong> <strong class="jn hj">=</strong> <strong class="jn hj">{</strong><br/>   <strong class="jn hj">WriteToElasticSearch.</strong>writeToIndex<strong class="jn hj">()</strong><br/> <strong class="jn hj">}</strong></span><span id="aea8" class="lo jq hi jn b fi lu lq l lr ls"> <strong class="jn hj">def</strong> writeToIndex<strong class="jn hj">():</strong> <strong class="jn hj">Unit</strong> <strong class="jn hj">=</strong> <strong class="jn hj">{</strong></span><span id="02bf" class="lo jq hi jn b fi lu lq l lr ls">   <strong class="jn hj">val</strong> spark <strong class="jn hj">=</strong> <strong class="jn hj">SparkSession</strong><br/>    <strong class="jn hj">.</strong>builder<strong class="jn hj">()</strong><br/>    <strong class="jn hj">.</strong>appName<strong class="jn hj">(</strong>"WriteToES"<strong class="jn hj">)</strong><br/>    <strong class="jn hj">.</strong>master<strong class="jn hj">(</strong>"local[*]"<strong class="jn hj">)</strong><br/>    <strong class="jn hj">.</strong>config<strong class="jn hj">(</strong>"spark.es.nodes"<strong class="jn hj">,</strong>"&lt;IP-OF-ES-NODE&gt;"<strong class="jn hj">)</strong><br/>    <strong class="jn hj">.</strong>config<strong class="jn hj">(</strong>"spark.es.port"<strong class="jn hj">,</strong>"&lt;ES-PORT&gt;"<strong class="jn hj">)</strong><br/>    <strong class="jn hj">.</strong>config<strong class="jn hj">(</strong>"spark.es.nodes.wan.only"<strong class="jn hj">,</strong>"true"<strong class="jn hj">)</strong> <em class="lt">//Needed for ES on AWS<br/></em>    <strong class="jn hj">.</strong>getOrCreate<strong class="jn hj">()</strong></span><span id="ddba" class="lo jq hi jn b fi lu lq l lr ls">   <strong class="jn hj">import</strong> spark.implicits._</span><span id="35e3" class="lo jq hi jn b fi lu lq l lr ls">   <strong class="jn hj">val</strong> indexDocuments <strong class="jn hj">=</strong> <strong class="jn hj">Seq(</strong><br/>       <strong class="jn hj">AlbumIndex(</strong>"Led Zeppelin"<strong class="jn hj">,</strong>1969<strong class="jn hj">,</strong>"Led Zeppelin"<strong class="jn hj">),</strong><br/>       <strong class="jn hj">AlbumIndex(</strong>"Boston"<strong class="jn hj">,</strong>1976<strong class="jn hj">,</strong>"Boston"<strong class="jn hj">),</strong><br/>       <strong class="jn hj">AlbumIndex(</strong>"Fleetwood Mac"<strong class="jn hj">,</strong> 1979<strong class="jn hj">,</strong>"Tusk"<strong class="jn hj">)</strong><br/>   <strong class="jn hj">).</strong>toDF</span><span id="33fc" class="lo jq hi jn b fi lu lq l lr ls">   indexDocuments<strong class="jn hj">.</strong>saveToEs<strong class="jn hj">(</strong>"demoindex/albumindex"<strong class="jn hj">)</strong><br/> <strong class="jn hj">}</strong><br/><strong class="jn hj">}</strong></span><span id="fb32" class="lo jq hi jn b fi lu lq l lr ls"><strong class="jn hj">case</strong> <strong class="jn hj">class</strong> <strong class="jn hj">AlbumIndex(</strong>artist<strong class="jn hj">:String,</strong> yearOfRelease<strong class="jn hj">:Int,</strong> albumName<strong class="jn hj">:</strong> <strong class="jn hj">String)</strong></span></pre><h1 id="0fbe" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">参考</h1><ol class=""><li id="dc23" class="kn ko hi io b ip kp it kq ix kr jb ks jf kt jj lv kv kw kx bi translated"><a class="ae jo" href="https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html" rel="noopener ugc nofollow" target="_blank">弹性搜索火花支持。</a></li></ol><p id="9d08" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="lt">还贴在</em><a class="ae jo" href="https://olivermascarenhas.com/2019-01-06-writing-spark-dataframes-to-es/" rel="noopener ugc nofollow" target="_blank"><em class="lt">https://olivermascarenhas . com/2019-01-06-writing-spark-data frames-to-es/</em></a></p></div></div>    
</body>
</html>