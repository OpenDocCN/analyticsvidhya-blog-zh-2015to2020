<html>
<head>
<title>YOLO V1- An Intuitive Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO V1-直观指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/yolo-v1-an-intuitive-guide-ad24c707b0eb?source=collection_archive---------8-----------------------#2020-05-16">https://medium.com/analytics-vidhya/yolo-v1-an-intuitive-guide-ad24c707b0eb?source=collection_archive---------8-----------------------#2020-05-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6426" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实时目标检测在许多应用中都有应用，如安全、监控、视频分析等。YOLO·V1算法于2016年提出，作为实时对象检测中最快、最有效的算法之一，风靡全球。下面的博客文章对此进行了深入分析，旨在让你在深入研究算法背后的数学知识之前，对算法有一个直观的理解。<br/>本帖假设你对神经网络和卷积神经网络的工作原理有所了解。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/ff79a2e36c63413837947a314760c605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HnJ9faDWtx8jMWHfax4VcQ.jpeg"/></div></div></figure><h1 id="619f" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">问题</strong></h1><p id="ec01" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">目标检测问题由两部分组成</p><ul class=""><li id="6d5a" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">目标定位:定位图像/视频中的特定目标。</li><li id="28e5" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">对象识别:位于图像/视频中的对象的标签是什么。</li></ul><h1 id="0f61" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">以前的工作及其局限性</h1><h2 id="7d92" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">可变形零件模型</h2><p id="6eed" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">该模型涉及一个复杂的管道，由用于特征提取、区域分类和边界框预测的独立模块组成。可以注意到，这个模型有太多的模块和复杂性。此外，图像被分成固定大小的窗口，并且特征提取器在所有窗口上滑动，以从整个图像中提取特征，这又是计算上昂贵的，并且不适于实时对象检测。</p><h2 id="1f97" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">区域卷积神经网络(R-CNN)</h2><p id="b277" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">这个模型又涉及到一个非常复杂的管道。它涉及一个区域建议网络，以建议最有可能包含一个对象的区域。CNN进一步用于特征提取，支持向量机用于生成置信度得分。考虑到它的复杂性，这个系统非常慢。</p><h2 id="d866" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">深多框</h2><p id="9478" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">这个算法非常类似于RCNN。唯一的不同是CNN被训练来预测地区提议，而不是选择性搜索。该模型的缺点是它能够进行单一类别的预测，但是不能检测一般的对象，即不同类型的对象。</p><h1 id="dddc" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">YOLO</h1><p id="091e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">YOLO代表你只看一眼。它表明，与在图像上多次滑动特征提取器不同，该算法只查看图像一次来检测其中的对象。YOLO涉及到将图像分成一个S×S的网格。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lv"><img src="../Images/22d3bc337ba4e4d13d986d0204f5917f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*CYTDLg54ol-NpBOnrhFo2A.jpeg"/></div></figure><p id="7354" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果对象的中心落入网格单元，则该特定单元被认为负责检测该特定对象。每个网格单元预测B个边界框和每个边界框的置信度得分，表示算法感觉到边界框中有物体的强烈程度。置信分数超过特定阈值(0.25)的盒子被认为是最终的盒子。置信度得分的公式如下:</p><p id="b546" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">公关(对象)* IOUᵗʳᵘᵗʰₚᵣₑₔ</p><p id="b4d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，Pr(obj)代表对象存在于预测边界框中的概率。IOU代表交集大于并集。顾名思义，它是实际边界框和预测边界框之间的相交面积，除以实际边界框和预测边界框之间的面积之和。</p><p id="2ebe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">预测边界框意味着预测5个值:x、y、w、h和置信度得分(如上所述)。(x，y)是预测框的中心相对于其相应网格单元的坐标，w和h是框相对于图像的宽度和高度。最后，该算法还预测条件类概率，即每个网格单元中预测的对象的名称。这些概率是有条件的，因为它们依赖于在特定边界框中实际检测到的对象。</p><h1 id="4609" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">电力网设计</h1><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lw"><img src="../Images/272c88155adfeb2a1e45c8b4edb07a6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BOQy9y-JxAylPWaF.jpeg"/></div></div></figure><p id="e6d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO CNN由24个卷积层和2个全连接层组成。详细结构见上图。它包括使用3 1 x 1的卷积层来减少进入的特征数量。</p><p id="1a43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出是一个7 x 7 x 30维的张量(3-D矩阵)。这是因为该模型是在Pascal VOC数据集上训练的，该数据集有20个要预测的对象类(C=20)。图像被分成7×7的网格(S=7)。每个单元负责2个边界框(B=2)。每个框预测5个值和C个要预测的概率。因此，输出结果是<br/> S x S x (B*5 +C ),替换后变成7 x 7 x 30。</p><h1 id="928b" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">培养</h1><p id="bbb2" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">yolo网络的卷积层在imagenet数据集上进行了一周多的预训练。由于imagenet数据集有超过1000个对象类，目标是提取尽可能多的特征。<br/>然后，网络执行检测并优化以下损失函数:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lx"><img src="../Images/bd3e375f03be43ed926b0a80e3a64829.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cp4hsihXQVGsJUV2.png"/></div></div></figure><p id="8f32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与其钻研数学，不如简单地说损失函数考虑了三种损失</p><ul class=""><li id="9506" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">分类损失:预测类别概率和实际类别概率之间的差异</li><li id="e0be" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">定位损失:预测边界框值(x，y，w和h)和实际边界框值之间的差异。</li><li id="eb1b" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">置信度损失:置信度得分中的错误</li></ul><p id="5e9f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了更深入地研究损失函数，我建议浏览一下<a class="ae ly" rel="noopener" href="/@jonathan_hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088">Jonathan Hui的这篇令人惊叹的文章</a>。</p><h1 id="f797" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">为什么是YOLO？</h1><h2 id="b291" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">速度</h2><p id="fa26" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">与之前的检测系统相比，YOLO的速度非常快，因为它不是滑动窗口方法，而是只需要将图像通过网络一次。它能够在Titan X GPU上以每秒45帧的速度运行，无需任何批处理。</p><h2 id="c807" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">简单</h2><p id="7bdb" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">不像许多其他模式，YOLO涉及一个单一的CNN。因此，不需要复杂的管道，这使得模型易于理解，执行速度更快。像特征提取、包围盒预测、对象分类这样的所有任务都由单个网络本身负责。</p><h2 id="0d71" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">更少的边界框</h2><p id="9fca" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">Yolo预测的边界框比其他模型少。相比之下，R-CNN建议每幅图像大约2000个盒子，YOLO只建议大约98个。</p><h1 id="9924" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="66f0" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">虽然YOLO v1非常成功，但它也有自己的局限性。它没有发现成群出现的小物体。它不能推广到具有不寻常长宽比的物体。此外，在该算法中，误差没有被归一化，即小误差在小盒子中不能像在大盒子中那样被忽略。也就是说，YOLO算法已经经历了多次修改，最新的版本是YOLO v4。我希望这篇文章能够让你理解这个算法是如何工作的。我鼓励您通读这篇文章，并在您自己的系统上尝试一下。</p><p id="3e28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">原文链接:</em>【https://arxiv.org/abs/1506.02640 T2】</p><p id="f624" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">链接到imageai api在你自己的系统上试用yolo:<a class="ae ly" href="https://imageai.readthedocs.io/en/latest/detection/" rel="noopener ugc nofollow" target="_blank">https://imageai.readthedocs.io/en/latest/detection/</a></p></div></div>    
</body>
</html>