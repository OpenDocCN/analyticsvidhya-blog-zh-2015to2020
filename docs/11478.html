<html>
<head>
<title>Azure Synapse Analytics End to End Machine learning — Model Development</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Azure Synapse 分析端到端机器学习-模型开发</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/azure-synapse-analytics-end-to-end-machine-learning-model-development-569bffb4263b?source=collection_archive---------4-----------------------#2020-12-05">https://medium.com/analytics-vidhya/azure-synapse-analytics-end-to-end-machine-learning-model-development-569bffb4263b?source=collection_archive---------4-----------------------#2020-12-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="93e7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">加载、转换、建模、存储数据</h1><h1 id="bd55" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">用例</h1><ul class=""><li id="4947" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">从数据源加载数据，在本例中为样本数据集</li><li id="147a" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">使用 Pyspark 处理数据(ETL)</li><li id="a52b" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">ETL 工作是结合 pyspark dataframe 和 Spark SQL 完成的</li><li id="c437" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">将处理后的数据保存到 Synapse 专用 SQLPools 中</li><li id="0c9b" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">当我们运行 ETL 时，恢复和暂停专用的 SQL 池</li><li id="363e" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">为无服务器活动在默认存储中保存一份副本</li><li id="54aa" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">建立和训练机器学习模型</li><li id="6e78" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">我们使用与 pyspark 相同的笔记本，但是使用 scala 代码构建</li><li id="2864" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">为恢复和暂停专用 SQL 池构建不同的管道</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="b312" class="kj ig hi kf b fi kk kl l km kn">Not every use case you have to resume and pause dedicated sql pools. If needed use, other wise please do ignore. The idea for this tutorial is to show all the combination of features working together.</span></pre><h1 id="ee08" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">端到端处理架构</h1><figure class="ka kb kc kd fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es ko"><img src="../Images/e05e2102aa48264801b93696c6d1f171.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6ZLjz6-OWDBoarHUb2hWg.jpeg"/></div></div></figure><h1 id="e818" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">先决条件</h1><ul class=""><li id="484f" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">需要 Azure 帐户</li><li id="cb2c" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">创建资源组</li><li id="125a" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">创建 Azure Synapse 分析工作区</li><li id="11cc" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">创建一个专用的 SQL 池(我使用的是 DW100c)</li><li id="9ec9" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">创建火花线轴</li><li id="e346" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">将自动创建无服务器 sql</li></ul><h1 id="856a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">创建代码的步骤</h1><ul class=""><li id="98a7" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">首先创建笔记本代码</li><li id="c6da" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">然后为专用 SQL 池创建恢复管道</li><li id="2d59" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">为专用 SQL 池创建暂停管道</li><li id="30fe" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">创建另一个管道来运行 resume，notebook，然后暂停</li></ul><h1 id="7578" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">创建简历集成的步骤</h1><ul class=""><li id="cc1d" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">创建新的管线</li><li id="2729" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">从常规部分拖动 Web 活动</li><li id="3593" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">转到设置和 URL</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="ff87" class="kj ig hi kf b fi kk kl l km kn">https://management.azure.com/subscriptions/subid/resourceGroups/rggroupname/providers/Microsoft.Synapse/workspaces/workspacename/sqlPools/poolname/resume?api-version=2019-06-01-preview</span></pre><ul class=""><li id="7152" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">现在是身体</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="61c5" class="kj ig hi kf b fi kk kl l km kn">{"sku":{"name":"DW100c"}}</span></pre><ul class=""><li id="e4fd" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">选择方法作为发布</li><li id="f601" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">对于资源类型的身份验证部分</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="0ddd" class="kj ig hi kf b fi kk kl l km kn">https://management.azure.com/</span></pre><h1 id="af3e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">创建暂停集成的步骤</h1><ul class=""><li id="cc89" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">创建新的管线</li><li id="3d58" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">从常规部分拖动 Web 活动</li><li id="95ce" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">转到设置和 URL</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="90ad" class="kj ig hi kf b fi kk kl l km kn">https://management.azure.com/subscriptions/subid/resourceGroups/rggroupname/providers/Microsoft.Synapse/workspaces/workspacename/sqlPools/poolname/pause?api-version=2019-06-01-preview</span></pre><ul class=""><li id="7c1b" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">现在是身体</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="3409" class="kj ig hi kf b fi kk kl l km kn">{"sku":{"name":"DW100c"}}</span></pre><ul class=""><li id="9b7b" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">选择方法作为发布</li><li id="3f07" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">对于资源类型的身份验证部分</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="1bd3" class="kj ig hi kf b fi kk kl l km kn">https://management.azure.com/</span></pre><h1 id="cce2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">使用笔记本创建 ETL 和 ML 代码的代码</h1><ul class=""><li id="6412" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">让我们加载数据集</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="213d" class="kj ig hi kf b fi kk kl l km kn">from azureml.opendatasets import NycTlcYellow<br/><br/>data = NycTlcYellow()<br/>data_df = data.to_spark_dataframe()<br/># Display 10 rows<br/>display(data_df.limit(10))</span><span id="92f3" class="kj ig hi kf b fi lb kl l km kn">from pyspark.sql.functions import *<br/>from pyspark.sql import *</span></pre><ul class=""><li id="7142" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">创建数据列</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="034b" class="kj ig hi kf b fi kk kl l km kn">df1 = data_df.withColumn("Date", (col("tpepPickupDateTime").cast("date"))) <br/>display(df1)</span></pre><ul class=""><li id="0da6" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">创建一个供以后使用的视图</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="7713" class="kj ig hi kf b fi kk kl l km kn">df1.createOrReplaceTempView("nycyellow")</span></pre><ul class=""><li id="3762" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">查找记录总数</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="5f30" class="kj ig hi kf b fi kk kl l km kn">#df1.count()</span></pre><ul class=""><li id="ae7b" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">删除重复项</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="aaf4" class="kj ig hi kf b fi kk kl l km kn">#df1.dropDuplicates("key","pickup_datetime","pickup_longitude","pick#up_latitude","dropoff_longitude","dropoff_latitude")</span></pre><ul class=""><li id="11c8" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">打印模式</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="48bb" class="kj ig hi kf b fi kk kl l km kn">df1.printSchema</span></pre><ul class=""><li id="e6b6" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">从派生日期列创建新列</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="5026" class="kj ig hi kf b fi kk kl l km kn">df2 = df1.withColumn("year", year(col("date"))) .withColumn("month", month(col("date"))) .withColumn("day", dayofmonth(col("date"))) .withColumn("hour", hour(col("date")))</span></pre><ul class=""><li id="5b7c" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">现在将数据分组</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="fdf6" class="kj ig hi kf b fi kk kl l km kn">dfgrouped = df2.groupBy("year","month").agg(sum("fareAmount").alias("Total"),count("vendorID").alias("Count")).sort(asc("year"), asc("month"))</span></pre><ul class=""><li id="6733" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">显示</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="fdf1" class="kj ig hi kf b fi kk kl l km kn">display(dfgrouped)</span></pre><ul class=""><li id="90d8" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">让我们将数据写入底层存储</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="6c50" class="kj ig hi kf b fi kk kl l km kn">dfgrouped.repartition(1).write.option("header","true").csv("/dailyaggrcsv/csv/dailyaggr.csv")</span></pre><ul class=""><li id="09dd" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">现在让我们使用 Spark SQL 尝试相同的聚合</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="6950" class="kj ig hi kf b fi kk kl l km kn">df2.createOrReplaceTempView("nycyellow")</span></pre><ul class=""><li id="7052" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">让我们显示数据并验证聚合不存在</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="eb24" class="kj ig hi kf b fi kk kl l km kn">%%sql<br/>select * from nycyellow limit 100</span></pre><ul class=""><li id="fff9" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">基于年、月、日和小时聚合记录</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="459d" class="kj ig hi kf b fi kk kl l km kn">%%sql<br/>select  year(cast(tpepPickupDateTime  as timestamp)) as tsYear,<br/>        month(cast(tpepPickupDateTime  as timestamp)) as tsmonth,<br/>        day(cast(tpepPickupDateTime  as timestamp)) as tsDay, <br/>        hour(cast(tpepPickupDateTime  as timestamp)) as tsHour,<br/>        avg(totalAmount) as avgTotal, avg(fareAmount) as avgFare<br/>from nycyellow<br/>group by  tsYear, tsmonth,tsDay, tsHour<br/>order by  tsYear, tsmonth,tsDay, tsHour</span></pre><ul class=""><li id="8bb6" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">如果存在属性，则删除</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="db52" class="kj ig hi kf b fi kk kl l km kn">%%sql<br/>DROP TABLE dailyaggr</span></pre><ul class=""><li id="9455" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">创建聚集表</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="9a62" class="kj ig hi kf b fi kk kl l km kn">%%sql<br/>CREATE TABLE dailyaggr<br/>  COMMENT 'This table is created with existing data'<br/>  AS select  year(cast(tpepPickupDateTime  as timestamp)) as tsYear,<br/>        month(cast(tpepPickupDateTime  as timestamp)) as tsmonth,<br/>        day(cast(tpepPickupDateTime  as timestamp)) as tsDay, <br/>        hour(cast(tpepPickupDateTime  as timestamp)) as tsHour,<br/>        avg(totalAmount) as avgTotal, avg(fareAmount) as avgFare<br/>from nycyellow<br/>group by  tsYear, tsmonth,tsDay, tsHour<br/>order by  tsYear, tsmonth,tsDay, tsHour</span></pre><ul class=""><li id="213c" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">验证记录是否已存储</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="fd8f" class="kj ig hi kf b fi kk kl l km kn">%%sql<br/>select * from dailyaggr</span></pre><h1 id="9a1d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">将聚合数据加载到专用的 sql 池中</h1><ul class=""><li id="f719" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">将 spark sql 表数据加载到 dataframe</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="bc87" class="kj ig hi kf b fi kk kl l km kn">dailyaggr = spark.sql("SELECT tsYear, tsMonth, tsDay, tsHour, avgTotal FROM dailyaggr")</span></pre><ul class=""><li id="6a72" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">显示要确认的数据集</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="55f3" class="kj ig hi kf b fi kk kl l km kn">display(dailyaggr)</span></pre><h1 id="0f23" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">是时候建立机器学习模型了</h1><h1 id="256c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">模型</h1><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="b2fd" class="kj ig hi kf b fi kk kl l km kn">from pyspark.ml.regression import LinearRegression</span></pre><ul class=""><li id="f828" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">让我们加载数据</li><li id="023c" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">从现在开始，我们使用 Scala 代码</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="0ed8" class="kj ig hi kf b fi kk kl l km kn">%%spark<br/>import org.apache.spark.ml.feature.VectorAssembler <br/>import org.apache.spark.ml.linalg.Vectors <br/>val dailyaggr = spark.sql("SELECT tsYear, tsMonth, tsDay, tsHour, avgTotal FROM dailyaggr")<br/>val featureCols=Array("tsYear","tsMonth","tsDay","tsHour") <br/>val assembler: org.apache.spark.ml.feature.VectorAssembler= new VectorAssembler().setInputCols(featureCols).setOutputCol("features") <br/>val assembledDF = assembler.setHandleInvalid("skip").transform(dailyaggr) <br/>val assembledFinalDF = assembledDF.select("avgTotal","features")</span><span id="b929" class="kj ig hi kf b fi lb kl l km kn">%%spark<br/>import com.microsoft.spark.sqlanalytics.utils.Constants<br/>import org.apache.spark.sql.SqlAnalyticsConnector._</span><span id="98e7" class="kj ig hi kf b fi lb kl l km kn">%%spark<br/>dailyaggr.repartition(2).write.synapsesql("accsynapsepools.wwi.dailyaggr", Constants.INTERNAL)</span><span id="b4a1" class="kj ig hi kf b fi lb kl l km kn">%%spark<br/>import org.apache.spark.ml.feature.Normalizer <br/>val normalizedDF = new Normalizer().setInputCol("features").setOutputCol("normalizedFeatures").transform(assembledFinalDF)</span></pre><ul class=""><li id="43e6" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">放弃 NA</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="a73c" class="kj ig hi kf b fi kk kl l km kn">%%spark<br/>val normalizedDF1 = normalizedDF.na.drop()</span></pre><ul class=""><li id="f021" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">为培训和测试拆分数据</li><li id="f562" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">我们将 70%的数据用于训练</li><li id="42df" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">30%数据用于测试</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="ed17" class="kj ig hi kf b fi kk kl l km kn">%%spark<br/>val Array(trainingDS, testDS) = normalizedDF1.randomSplit(Array(0.7, 0.3))</span></pre><ul class=""><li id="f8fa" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">训练模型</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="662c" class="kj ig hi kf b fi kk kl l km kn">%%spark<br/>import org.apache.spark.ml.regression.LinearRegression<br/>// Create a LinearRegression instance. This instance is an Estimator. <br/>val lr = new LinearRegression().setLabelCol("avgTotal").setMaxIter(100)<br/>// Print out the parameters, documentation, and any default values. println(s"Linear Regression parameters:\n ${lr.explainParams()}\n") <br/>// Learn a Linear Regression model. This uses the parameters stored in lr.<br/>val lrModel = lr.fit(trainingDS)<br/>// Make predictions on test data using the Transformer.transform() method.<br/>// LinearRegression.transform will only use the 'features' column. <br/>val lrPredictions = lrModel.transform(testDS)</span></pre><ul class=""><li id="299b" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">预测数据</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="9f49" class="kj ig hi kf b fi kk kl l km kn">%%spark<br/>import org.apache.spark.sql.functions._ <br/>import org.apache.spark.sql.types._ <br/>println("\nPredictions : " ) <br/>lrPredictions.select($"avgTotal".cast(IntegerType),$"prediction".cast(IntegerType)).orderBy(abs($"prediction"-$"avgTotal")).distinct.show(15)</span></pre><ul class=""><li id="c2ce" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">评估模型以确保它是有效的</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="967a" class="kj ig hi kf b fi kk kl l km kn">%%spark<br/>import org.apache.spark.ml.evaluation.RegressionEvaluator </span><span id="ee07" class="kj ig hi kf b fi lb kl l km kn">val evaluator_r2 = new RegressionEvaluator().setPredictionCol("prediction").setLabelCol("avgTotal").setMetricName("r2") <br/>//As the name implies, isLargerBetter returns if a larger value is better or smaller for evaluation. <br/>val isLargerBetter : Boolean = evaluator_r2.isLargerBetter <br/>println("Coefficient of determination = " + evaluator_r2.evaluate(lrPredictions))</span></pre><ul class=""><li id="e20f" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">打印指标</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="6169" class="kj ig hi kf b fi kk kl l km kn">%%spark<br/>//Evaluate the results. Calculate Root Mean Square Error <br/>val evaluator_rmse = new RegressionEvaluator().setPredictionCol("prediction").setLabelCol("avgTotal").setMetricName("rmse") <br/>//As the name implies, isLargerBetter returns if a larger value is better for evaluation. <br/>val isLargerBetter1 : Boolean = evaluator_rmse.isLargerBetter <br/>println("Root Mean Square Error = " + evaluator_rmse.evaluate(lrPredictions))</span></pre><ul class=""><li id="3fd9" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">建模现在完成了。</li><li id="6572" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">保存笔记本</li><li id="f0ed" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">单击全部提交。</li><li id="7901" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">一个接一个地运行单元并观察输出。</li></ul><h1 id="cb6e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">创建端到端集成</h1><ul class=""><li id="7cae" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">既然我们已经准备好了恢复、暂停集成管道以及 ETL 和 ML 建模代码。</li><li id="e8d3" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">让我们创建一个集成管道来将它们组合在一起，如下所示。</li></ul><figure class="ka kb kc kd fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es ko"><img src="../Images/e05e2102aa48264801b93696c6d1f171.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6ZLjz6-OWDBoarHUb2hWg.jpeg"/></div></div></figure><ul class=""><li id="ffbe" class="jd je hi jf b jg kw ji kx jk ky jm kz jo la jq jr js jt ju bi translated">创建新的集成</li><li id="ea33" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">首先选择执行管道，然后选择恢复专用 SQL 池管道</li><li id="c698" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">接下来拖动 Synapse 笔记本作业，并选择上面创建的笔记本</li><li id="0165" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">最后一步拖动执行管道并选择暂停专用 SQL 池管道</li><li id="ca4c" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">全部保存并提交</li><li id="7541" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">保存后，创建一个拉取请求并与主分支合并</li><li id="cd70" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">切换到主分支</li><li id="33fc" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">单击发布</li><li id="d434" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">单击立即触发</li><li id="e2f3" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">等着看管道如何执行。</li></ul><p id="af6b" class="pw-post-body-paragraph lc ld hi jf b jg kw le lf ji kx lg lh jk li lj lk jm ll lm ln jo lo lp lq jq hb bi translated">原文可以在这里找到<a class="ae lr" href="https://github.com/balakreshnan/synapseAnalytics/blob/master/synapseworkspace/E2EETLML.md" rel="noopener ugc nofollow" target="_blank"/></p><p id="3535" class="pw-post-body-paragraph lc ld hi jf b jg kw le lf ji kx lg lh jk li lj lk jm ll lm ln jo lo lp lq jq hb bi translated">分享你的想法和评论。</p></div></div>    
</body>
</html>