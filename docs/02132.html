<html>
<head>
<title>Best Practices: Advanced Deep Learning with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最佳实践:使用Keras进行高级深度学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/best-practices-advanced-deep-learning-with-keras-14ab73a24c?source=collection_archive---------12-----------------------#2019-12-02">https://medium.com/analytics-vidhya/best-practices-advanced-deep-learning-with-keras-14ab73a24c?source=collection_archive---------12-----------------------#2019-12-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es im"><img src="../Images/24a7c722b646a7df888bf9ff3453d4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*uokXCDa_O7jzfbUC9qS6cg.png"/></div><figcaption class="iu iv et er es iw ix bd b be z dx translated">信用:<a class="ae iy" rel="noopener" href="/difference-engine-ai/keras-a-thing-you-should-know-about-keras-if-you-plan-to-train-a-deep-learning-model-on-a-large-fdd63ce66bd2"> Somendra </a> P</figcaption></figure></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="1cf3" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">这个博客将帮助我们探索各种工具，这些工具将使我们更接近解决难题的最新发展水平。使用Keras functional API，我们可以构建一个类似图形的模型，跨不同的输入共享各层。Keras回调和Tensorboard可视化工具允许我们在训练期间监控模型。</p><p id="8ebc" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">请访问www.thelearnguru.com<a class="ae iy" href="http://www.thelearnguru.com" rel="noopener ugc nofollow" target="_blank">了解更多关于人工智能、云计算和量子计算的博客。</a></p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="11da" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb hj"> Keras功能API:超越顺序模型</strong></p><p id="c376" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">当我们谈论训练神经网络时，序列模型是非常常见的。它只有一个输入和一个输出，由线性层叠组成。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es jx"><img src="../Images/3f9ce955fc3883166f308994ba51ea7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*3yxIU_LTjxX3suJMCh1I7g.png"/></div><figcaption class="iu iv et er es iw ix bd b be z dx translated">顺序模型</figcaption></figure><p id="6319" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">一些场景需要多模态输入，我们将来自不同来源的数据合并，并在神经网络中进行处理。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es jy"><img src="../Images/45dc45c4f62e40fdf564a2b38f6afcc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*IPs1wM2OA74b2hqHHM8DPw.png"/></div></figure><p id="f8b9" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">此外，在神经网络结构中有许多发展需要非线性拓扑。有三种类型的用例——多输入模型、多输出模型和类似图形的模型。</p><p id="dd56" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb hj">简介:</strong></p><p id="adcd" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">在函数API中，我们直接处理张量，使用层作为取张量和返回张量的函数。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es jz"><img src="../Images/a7462712e063e35c3961d607c98bbf6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VgYXBIjQMSnMjcZ6kW36ZQ.png"/></div></div></figure><p id="2b54" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">代码中唯一令人惊讶的部分是“模型”对象的使用。这里，<strong class="jb hj">模型</strong>由输入张量和输出张量实例化。在图片背后，Keras检索了从输入张量到输出张量所涉及的所有层，将它们整合到一个类似图形的数据结构中。</p><p id="c1ad" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb hj">多输入型号:</strong></p><p id="82e1" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">函数式API可用于构建具有多个输入的模型。这种类型的模型总是有一个我们可以组合它们不同输入的点:通过添加它们或者连接它们。</p><p id="9e79" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">这通常通过Keras合并操作完成，例如<strong class="jb hj"> keras.layers.add </strong>，<strong class="jb hj">Keras . layers . concatenate</strong>。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es ke"><img src="../Images/a56a63e1dbbbe7f046298b9f9bd64bbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*pQ1YZmr7miDJxNov2QpvIw.png"/></div></figure><p id="69dc" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb hj">多输出型号:</strong></p><p id="f57a" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">以同样的方式，函数式API可以用于构建具有多个输出的模型。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es kf"><img src="../Images/92c6b846e370d318c588cd967cbdc333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*7dDvaZZ6mpXJsFuYVTHVqw.png"/></div></figure><p id="dd10" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">重要的是，训练这样的模型需要为网络的不同头部指定不同损失函数的能力。一种情况可能是回归，另一种情况可能是需要不同训练过程的二元分类。但是因为梯度下降要求我们最小化一个标量，所以我们必须将这些损失组合成单个值，以便训练模型。组合不同损失的最简单方法是将它们相加。在Keras中，对于不同的输出，我们可以在编译到不同的对象时使用一个损失列表或字典:得到的损失值被加到一个全局损失中，该损失在训练期间被最小化。</p><p id="a0db" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">请注意，非常不平衡的损失贡献将导致模型表示优先针对具有最大个体损失的任务进行优化，而以另一个任务为代价。为了补救这一点，我们可以根据损失价值对最终损失的贡献程度来分配不同的重要性级别。</p><p id="0b0c" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb hj">层的有向无环图:</strong></p><p id="6e53" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">在functional API中，我们还可以实现具有复杂内部拓扑的网络。Keras中的神经网络可以是任意层的有向无环图。限定词“非循环的”很重要:这些图不能有循环。张量x t不可能成为生成x的另一层的输入。唯一允许的处理循环(即循环连接)是循环层内部的处理循环。</p><p id="a547" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">几个常见的神经网络组件以图形形式实现:</p><p id="0446" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">1.初始模块</p><p id="3eb4" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">2.残留连接。</p><p id="c041" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">初始模块:</p><p id="d3d2" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">盗梦空间模型是由Christian Szegedy在2013-14年开发的。它包含分成并行分支的小独立模块。初始模块的最基本形式具有三个或四个分支，以1x1卷积开始，随后是3x3卷积，并以结果特征的连接结束。</p><p id="6656" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">这种设置有助于网络分别学习空间特征和通道特征，这比联合学习它们更有效。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es kg"><img src="../Images/c2961f82fd10e01d8f54cea70211b7c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XynbUs2LCkIzppy4O2Bwqg.png"/></div></div></figure><p id="b01a" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb hj">剩余连接:</strong></p><p id="f0c2" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">这是微软在2015年开发的。它处理深度学习模型中的两个主要问题:消失梯度和表示瓶颈。一般来说，向任何超过10层的模型添加剩余连接是有益的。</p><p id="64ed" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">剩余连接有效地将前一层的输出作为后一层的输入，有效地在q序列网络中创建了捷径。不是连接到后面的激活，而是将前面的激活与后面的激活相加，这假定两者的大小相同。如果它们是不同的形状，我们可以使用线性变换将其调整为目标形状。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es kh"><img src="../Images/492d1891fc48f3f09456769002313ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*eGJP9cXhFJ995zKr-dXYZw.png"/></div></figure></div></div>    
</body>
</html>