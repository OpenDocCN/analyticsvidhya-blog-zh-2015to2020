<html>
<head>
<title>Fine-Grained Sentiment Analysis of Smartphone Review</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">智能手机评论的细粒度情感分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fine-grained-sentiment-analysis-of-smartphone-review-d9f502a40c36?source=collection_archive---------10-----------------------#2020-11-26">https://medium.com/analytics-vidhya/fine-grained-sentiment-analysis-of-smartphone-review-d9f502a40c36?source=collection_archive---------10-----------------------#2020-11-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/14984453c20b0923bcfe183c2582c79b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eycKZ9TADFBcO8w_CSejwA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://www.ntaskmanager.com/wp-content/uploads/2020/01/Sentiment-Analysis.png" rel="noopener ugc nofollow" target="_blank">https://www . ntaskmanager . com/WP-content/uploads/2020/01/情操分析. png </a></figcaption></figure><p id="3c18" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">情感分析</strong>或<strong class="ix hj">意见挖掘</strong>是利用<strong class="ix hj">自然语言处理</strong>和<strong class="ix hj">机器学习对文字背后的情感进行分析。</strong>随着一切都转移到网上，品牌和企业对顾客评论给予了最大的重视，因此情感分析在过去10年中一直是一个活跃的研究领域。企业正投入巨资开发一种高效的情感分类器。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="0518" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">为什么要进行细粒度的情感分析？</strong></p><p id="8f06" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在探索中，我主要发现了那些使用二元分类的分类器(只是正面和负面情绪)，我自己面临的一个很好的原因是细粒度的分类器更具挑战性，并且没有太多的资源可用于此。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/5fa040e557ad81a6f5b756fe95625bb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*3uBa6UZ-KZWr-ARS40nRWA.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://surensinffotek.com/uploads/media/images/5f9921672ebad_b4d91f8c870f982a0e445a21e7bbc151.jpg" rel="noopener ugc nofollow" target="_blank">https://surensinfotek . com/uploads/media/images/5f 9921672 ebad _ b4d 91 F8 c 870 f 982 a 0e 445 a 21e 7 BBC 151 . jpg</a></figcaption></figure><p id="5871" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对细节的关注决定了普通和惊艳的区别。如果需要更精确的结果，可以使用细粒度分析。简而言之，你不仅可以确定谁在谈论某个产品，还可以确定他们的反馈中到底谈论了什么。例如，对于类似<em class="kf">“1992年的骗局比米尔札布尔2好得多”的比较表达— </em>细粒度情感分析可以提供比普通二元情感分类器更精确的信息。除了上述优势，像<em class="kf">这样的双极性评论的位置确实很糟糕…但是那里的人很棒。</em>“可能混淆二元情感分类器，给出不正确的预测。</p><p id="3563" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我认为上面的优势会给我们足够的动力去进行细粒度的情感分析。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="321a" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">如何进行细粒度的情感分析:方法和工具</h1><p id="e83b" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated"><strong class="ix hj">资料收集和准备。</strong>为了收集数据，我们使用<strong class="ix hj"> python </strong>、<strong class="ix hj"> selenium </strong>和<strong class="ix hj"> beautifulsoup </strong>库，从<a class="ae iu" href="https://www.amazon.in/" rel="noopener ugc nofollow" target="_blank"> www.amazon.in </a>中搜集了前100条智能手机评论。如果你不知道如何使用python和beautifulsoup和请求库进行网络抓取，这里有一个<a class="ae iu" rel="noopener" href="/@akshayakn95/web-scraping-with-beautifulsoup-8cd4e04274d5">快速教程</a>。<strong class="ix hj">Selenium</strong>python<strong class="ix hj"/>bindings提供了一个简单的API来使用Selenium WebDriver编写功能/验收测试。</p><p id="d546" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们现在开始编码吧！！</p><pre class="kb kc kd ke fd lj lk ll lm aw ln bi"><span id="d971" class="lo kh hi lk b fi lp lq l lr ls">import requests<br/>from fake_useragent import UserAgent<br/>import csv<br/>import re<br/>from selenium import webdriver<br/>from bs4 import BeautifulSoup</span><span id="2703" class="lo kh hi lk b fi lt lq l lr ls">from selenium import webdriver</span></pre><p id="bced" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们从导入一些库开始。<strong class="ix hj">请求</strong>库用于向url发送请求并接收网页内容。<strong class="ix hj"> BeautifulSoup </strong>用于将网页内容格式化为可读性更强的格式。selenium用于自动抓取网页，如果没有selenium，你必须发送标题和cookies，我发现这个过程更加繁琐。</p><p id="01d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">搜索产品并获取ASIN(亚马逊标准识别号)</strong></p><p id="ece9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们将创建基于搜索查询的助手函数，获取所有产品的编号。这些数字将帮助我们以后创建每个产品的URL。我们创建了两个函数<strong class="ix hj"> <em class="kf"> searching() </em> </strong>和<strong class="ix hj"> <em class="kf"> asin() </em> </strong>，这两个函数搜索网页<strong class="ix hj"> <em class="kf"> </em> </strong>并将所有的<strong class="ix hj"> ASIN </strong>号存储在列表中。我们发现，当我们在amazon.in上搜索某个特定产品时，它的URL可以分成三个部分。</p><p id="6bfe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"><em class="kf"/></strong><a class="ae iu" href="https://www.amazon.in/s?k=" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"><em class="kf">https://www.amazon.in/s?k=</em></strong></a><strong class="ix hj"><em class="kf">"+搜索查询+页码</em>。所以我们搜索了智能手机，直到7页，你可以扩展到你喜欢的任何数量的页面。</strong></p><pre class="kb kc kd ke fd lj lk ll lm aw ln bi"><span id="ae3f" class="lo kh hi lk b fi lp lq l lr ls">def searching(url,query,page_no):<br/>    """<br/>    This is a function which searches for the page based on the url and the query<br/>    Parameters :<br/>    url = main site from which the data to be parsed<br/>    query = product/word that to be searches<br/>    returns : page if found or else error<br/>    """<br/>    path = url + query +"&amp;page=" + str(page_no)<br/>    page = requests.get(path, headers =header)<br/>    if page.status_code == 200:<br/>        return page.content <br/>    else:<br/>        return "Error"</span><span id="b7f2" class="lo kh hi lk b fi lt lq l lr ls">def asin(url,query,page_no):<br/>    """<br/>    Get the ASIN(Amzon Standard Identification Number for the products)<br/>    Parameters:<br/>    url = main url from where the asin needs to be scraped<br/>    query = product category from which the asins to be scraped<br/>    returns : list of asins of the products<br/>    """<br/>    product_asin = []<br/>    response = searching(url,query,page_no)<br/>    soup = BeautifulSoup(response,'html.parser')<br/>    for i in soup.find_all("div",{"class":"sg-col-20-of-24 s-result-item s-asin sg-col-0-of-12 sg-col-28-of-32 sg-col-16-of-20 sg-col sg-col-32-of-36 sg-col-12-of-16 sg-col-24-of-28"}):<br/>        product_asin.append(i['data-asin'])<br/>    return product_asin</span></pre><p id="aeb7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">获取产品详情</strong></p><p id="994b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，下一步是为每个产品创建一个url，并转到该url，抓取该页面所需的所有必要细节。为此，我们使用selenium来自动化提取细节的过程。对于amazon.in，每个产品的url可以细分为</p><p id="9e7b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"><em class="kf">“</em></strong><a class="ae iu" href="https://www.amazon.in/dp/" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"><em class="kf"/></strong></a><strong class="ix hj"><em class="kf">”+asin</em></strong></p><p id="e55b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们创建了一个函数来访问使用asin编号创建的每个URL，并获取每个产品的<em class="kf">评论、评级和名称</em>。然后，我们使用python中的<strong class="ix hj"> csv </strong>模块将这些值存储为csv文件。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="ee4a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">预处理和探索性数据分析。</strong></p><p id="2f4b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用<strong class="ix hj">熊猫</strong>库和一些<strong class="ix hj"> <em class="kf"> EDA </em> </strong>加载保存的csv文件，如评级分布、评论中的字数以及哪些词在正面评论和负面评论中更占优势，然后完成<strong class="ix hj"> <em class="kf">预处理</em> </strong>，如清理评论和标题等。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/cb28883291092ea587451683c0c2304d.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*kAs2z2R8ro0f6O-gRGii-Q.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据集中正负分数的分布。</figcaption></figure><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/1052bebdbf0b9e9b33dba217b1502ae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*IYluVrB-bF0CJ_N-wxppVA.png"/></div></figure><p id="24d7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上图显示了正面和负面评论的字数分布。我们可以看到，正面评论中的字数的<em class="kf">频率大于负面评论，而且负面评论的字数<em class="kf">通常比正面评论的字数</em>短。</em></p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/023512e11cc68cac429401543d51d6eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*Hc9jl728NxS3PUqhh6YKtg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">正面评价</figcaption></figure><p id="0815" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可能因为数据集较小而无法了解太多，但我们可以注意到，可能是正面的单词<em class="kf"/>【good】是正面评论中的主导词之一。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/d38ca631597c90bfe20050c36a1b5932.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*qVMhHz5p23I-xGr9uu7pvQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">负面评论</figcaption></figure><p id="7324" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的词云中“<em class="kf">不要，买，电话</em>”是这里的主导词。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/c2548fd61f2c564b2b31f0d6266f4c6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*GNPaaGlKmr85kHFbh5Ok3Q.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">字数</figcaption></figure><p id="0a34" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于负字数，正态分布图清晰可见，但是对于正评论，没有清晰的模式。</p><p id="0b8e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">用于细粒度情感分析的文本块:</strong></p><p id="7e39" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> TextBlob </strong>是一个用于自然语言处理(NLP)的python库。TextBlob积极使用自然语言工具包(NLTK)来完成其任务。NLTK是一个库，它提供了对大量词汇资源的简单访问，并允许用户进行分类、归类和许多其他任务。TextBlob是一个简单的库，支持对文本数据的复杂分析和操作。</p><p id="2c85" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将创建一个返回情感极性得分的函数，然后使用该函数从<em class="kf">1–5预测情感得分。</em></p><pre class="kb kc kd ke fd lj lk ll lm aw ln bi"><span id="0f6b" class="lo kh hi lk b fi lp lq l lr ls">from textblob import TextBlob<br/>def textblob_score(sentence):<br/>    return TextBlob(sentence).sentiment.polarity</span></pre><p id="f3b3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将每次检查传递给上述函数，并存储返回的分数，并将其保存到dataframe中。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="d98d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">您可以查看我的GitHub以获得完整的代码和数据。</p><div class="ly lz ez fb ma mb"><a href="https://github.com/akshayakn13/Fine-Grained-Sentiment-Analysis" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hj fi z dy mg ea eb mh ed ef hh bi translated">akshayakn 13/细粒度情感分析</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">这个项目包括:数据挖掘使用硒，美丽的汤，并要求图书馆数据探索使用…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">github.com</p></div></div><div class="mk l"><div class="ml l mm mn mo mk mp io mb"/></div></div></a></div><p id="3ff3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请随时在任何平台上与我联系。</p><p id="b672" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">也可以看看我的其他文章</p><div class="ly lz ez fb ma mb"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/k-nearest-neighbor-k-nn-f4418a55b74f"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hj fi z dy mg ea eb mh ed ef hh bi translated">k-最近邻</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">K-最近邻(K-NN)算法是一种简单、易于实现的有监督机器学习算法。那个“K”…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">medium.com</p></div></div><div class="mk l"><div class="mq l mm mn mo mk mp io mb"/></div></div></a></div><div class="ly lz ez fb ma mb"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/support-vector-machines-805a24507f"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hj fi z dy mg ea eb mh ed ef hh bi translated">支持向量机</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">这是一篇两部分的文章，第一部分我将讨论硬边际支持向量机，下一部分我将…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">medium.com</p></div></div><div class="mk l"><div class="mr l mm mn mo mk mp io mb"/></div></div></a></div><p id="7e7d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" rel="noopener" href="/analytics-vidhya/logistic-regression-46a0f3cdecef">https://medium . com/analytics-vid hya/logistic-regression-46 A0 F3 CD ecef</a></p></div></div>    
</body>
</html>