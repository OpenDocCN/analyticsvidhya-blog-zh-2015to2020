# 优化不同的 Apache Spark SQL 连接

> 原文：<https://medium.com/analytics-vidhya/optimising-different-apache-spark-sql-joins-dc6120c3ff6a?source=collection_archive---------13----------------------->

![](img/608d3141cb919a56fb4b8edf4e581c93.png)

Spark SQL 中有不同类型的连接:

*   无序散列连接
*   广播散列连接
*   笛卡尔连接
*   θ连接
*   一对多加入

# 无序散列连接

无序散列连接是最基本的连接类型，也是它所使用的 MapReduce 基础

*   映射两个不同的数据框/表
*   使用连接条件中的字段作为输出键
*   通过输出键混洗两个数据集
*   在 reduce 阶段，连接两个数据集。相同的钥匙将在同一台机器上，并进行分类

## 无序散列连接性能

在以下情况下效果最佳:

*   密钥均匀分布
*   足够数量的并行键

这实质上意味着数据不应该是倾斜的。如果有数百万条记录，但唯一键的数量非常少，则混洗散列连接的性能将无法利用并行性，其性能将会降低。

## 让我们看几个例子:

**案例 1:**

```
rdd = sqlContext.sql("select * FROM software_jobs JOIN indian_states ON software_jobs.state = states.name")
```

由于表 2(状态数)中唯一键的数量将非常少，并且大多数记录将仅来自第二个表中的几个键，这将导致**不均匀共享和有限并行性的问题。**

table2 只有 35 个键(州数+ UT ),大多数行将来自卡纳塔克邦或安得拉邦键。

同样在这种情况下，如果我们将节点增加到 35 个以上，这并不能解决问题，因为我们只有 35 个键。

**如果 table2 足够小，可以放入内存，广播散列连接可以解决这个问题。**(我们很快会讨论这个问题)

**案例二:**

```
rdd = sqlContext.sql("select * from people_in_tamil_nadu 
LEFT JOIN people_in_india
ON people_in_tamil_nadu.id = people_in_india.id
```

查看这个查询，我们假设输出文件的大小等于 people_in_tamil_nadu 的大小。然而，这并不是混洗散列连接的工作方式！

table1 和 table2 中的所有行将在网络上混洗以连接，然后它将意识到大多数记录来自单个键，其余的被丢弃。

这可以通过在执行连接之前分析数据并删除未使用的数据来解决。这将极大地提高查询速度，并减少不必要的数据在网络上传输。

**检测洗牌问题:**

检查 shuffle 问题的最佳位置是查看 Spark UI 屏幕。

在 spark UI 中，在作业→任务下，我们可以检查:

*   哪项任务比其他任务花费的时间多
*   正在启动推测性任务

# 广播散列连接

当连接中的一个表足够小，可以放入内存时，可以使用广播散列连接。本质上，spark 获取小表并将其复制到每台机器的内存中。**这确保了网络中不会出现数据混排，并且大型数据集的并行性也将得以保持**。

如果我们使用拼花文件格式，spark catalyst optimiser 会自动将这个决定广播到内存小表中。但是，如果我们使用其他文件格式，如文本文件，spark catalyst optimiser 可能无法计算表格的大小，我们需要明确给出提示来广播表格。

# 笛卡尔连接

笛卡尔连接可以很容易地分解输出行数:

10 万* 10 万= 100 亿

为了优化这种连接，我们需要增加集群的大小。决定聚类大小的更好方法是计算样本集的时间，然后根据原始数据集的大小进行相应的调整。

# 一对多加入

一个表上的一行可以映射到另一个表上的多行。这也会导致输出行数激增。

这种类型连接可以通过使用拼花文件格式来优化。输出文件的大小将会减小，因为 parquet 对重复数据进行了编码。

因此输出文件的大小将小于输入表的大小。

# θ连接

```
rdd = sqlContext.sql("select * from table1 JOIN table2 ON (key1 < key2 + 10)")
```

这种类型的连接是当连接条件不相等时，而是在某个范围的键上连接。

在这种情况下，spark 在内部执行一个完整的笛卡尔连接，并遍历每个记录来执行条件。即使输出文件删除了大部分记录，查询也会运行得非常慢。

为了优化 theta 连接，我们可以使用 bucketing。我们可以用一种方式创建存储桶，这种方式可以在更少的数据集上以相同的条件连接查询。