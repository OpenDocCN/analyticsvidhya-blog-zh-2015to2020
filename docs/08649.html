<html>
<head>
<title>Using Tensorflow 2.0 to Build a CNN for Image Classification ğŸ˜</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ä½¿ç”¨ Tensorflow 2.0 æ„å»ºç”¨äºå›¾åƒåˆ†ç±»çš„ CNNğŸ˜</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/analytics-vidhya/using-tensorflow-2-0-to-build-a-cnn-for-image-classification-4e50848ce1c0?source=collection_archive---------6-----------------------#2020-08-07">https://medium.com/analytics-vidhya/using-tensorflow-2-0-to-build-a-cnn-for-image-classification-4e50848ce1c0?source=collection_archive---------6-----------------------#2020-08-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c42c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">ç›®æ ‡å—ä¼—:ç†Ÿæ‚‰ Pythonï¼Œå¯¹ç¥ç»ç½‘ç»œæœ‰åŸºæœ¬äº†è§£çš„ ML çˆ±å¥½è€…ã€‚æˆ‘ç»ä¸æ˜¯ä¸“å®¶ï¼Œæƒ³åˆ†äº«æˆ‘å­¦åˆ°çš„ä¸œè¥¿ï¼</strong></p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="1900" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TensorFlow ç‰ˆæœ¬äº 2019 å¹´ 9 æœˆ(å·®ä¸å¤š 1 å¹´å‰)å‘å¸ƒï¼Œä¿ƒè¿›äº†æœºå™¨å­¦ä¹ æ¨¡å‹çš„åˆ›å»ºå’Œä½¿ç”¨ã€‚å³ä½¿æœ‰ä¸€äº›ä½¿ç”¨ TensorFlow ç‰ˆçš„ç»éªŒï¼Œæˆ‘å‘ç°åœ¨ MNIST åŸºå‡†æ•°æ®é›†ä¸Šå®ç°ä¸€ä¸ªå‡†ç¡®ç‡çº¦ä¸º 98.5%çš„å·¥ä½œæ¨¡å‹æœ‰ä¸€ä¸ªé™¡å³­çš„å­¦ä¹ æ›²çº¿ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘æƒ³åˆ†äº«æˆ‘å¦‚ä½•åœ¨ Python 3 ä¸­ç”¨ TensorFlow 2.0 å®ç°äº†ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œä»¥ä¾¿å¸®åŠ©é‚£äº›å¯èƒ½æ­£åœ¨å­¦ä¹ æ›²çº¿ä¸­æŒ£æ‰çš„äººã€‚</p><h1 id="9ac6" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">å®‰è£…æ–¹æ³•:</h1><p id="36c4" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc hb bi translated">ä¸‹é¢æ˜¯æˆ‘ä½¿ç”¨çš„ç¡¬ä»¶å’Œè½¯ä»¶è§„æ ¼ï¼Œå®ƒä»¬å¯¼è‡´äº†ä¸€ä¸ªå·¥ä½œå®‰è£…å’Œä¸€ä¸ªå·¥ä½œæ¨¡å‹:</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es kn"><img src="../Images/43c90b68370a1517e7df9227f93ed53f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EfA4sIUXwL0CUs7N"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">ç”±<a class="ae ld" href="https://unsplash.com/@maxcodes?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">éº¦æ–¯å¨å°”Â·å°¼å°”æ£®</a>åœ¨<a class="ae ld" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>ä¸Šæ‹æ‘„çš„ç…§ç‰‡</figcaption></figure><ul class=""><li id="9205" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">æ“ä½œç³»ç»Ÿ:Windows 10</li><li id="1e2c" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">IDE: PyCharm 2019.3.5</li><li id="ef1e" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">Python 3.6.7</li><li id="b6cc" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">å¼ é‡æµ 2.3.0</li><li id="ece1" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">NVIDIA GeForce GTX1050</li><li id="c4a5" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">NVIDIA é©±åŠ¨ç¨‹åºç‰ˆæœ¬ 451.67</li><li id="4eca" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">CUDA 10.1(æ›´æ–° 2)</li><li id="0eaf" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">CUPTI 10.1(è‡ªå¸¦ CUDA)</li><li id="1eeb" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">cuDNN v7.6.5</li></ul><p id="e99a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ä¹‹å‰åœ¨ Tensorflow v1.0 (TF1)ä¸­ï¼Œæœ‰ä¸€ä¸ªå•ç‹¬çš„ GPU tensorflow åŒ…ï¼Œè€Œåœ¨ TF2ï¼Œæœ‰ä¸€ä¸ªé’ˆå¯¹ CPUã€GPU å’Œå¤š GPU tensorflow ç‰ˆæœ¬çš„å…¨å±€åŒ…ã€‚ç”¨ä½ çš„ Python åŒ…ç®¡ç†å™¨å®‰è£… TF2 (æˆ‘åœ¨ PyCharm ä¸­ä½¿ç”¨äº† pip)ã€‚ğŸ‘</p><p id="300b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TF2 åº”è¯¥é»˜è®¤ä½¿ç”¨ä½ çš„ CPUï¼Œä½†æ˜¯å¦‚æœä½ æœ‰ä¸€ä¸ª<a class="ae ld" href="https://developer.nvidia.com/cuda-gpus" rel="noopener ugc nofollow" target="_blank">æœ‰æ•ˆçš„ NVIDIA GPU </a>å¹¶ä¸”æƒ³åƒæˆ‘ä¸€æ ·ä½¿ç”¨å®ƒï¼Œé‚£ä¹ˆä½ å°±éœ€è¦å†éµå¾ªå‡ ä¸ª<a class="ae ld" href="https://www.tensorflow.org/install/gpu" rel="noopener ugc nofollow" target="_blank">å®‰è£…æ­¥éª¤</a>ã€‚ä½ å¿…é¡»å®‰è£…å„è‡ªçš„<a class="ae ld" href="https://developer.nvidia.com/cuda-toolkit-archive" rel="noopener ugc nofollow" target="_blank"> CUDA </a>ã€<a class="ae ld" href="https://developer.nvidia.com/cuda-toolkit-archive" rel="noopener ugc nofollow" target="_blank"> CUPTI </a>å’Œ<a class="ae ld" href="https://developer.nvidia.com/rdp/cudnn-archive" rel="noopener ugc nofollow" target="_blank"> cuDNN </a>åº“ã€‚TF ç½‘ç«™ä¿å­˜äº†è¿™äº›åº“çš„å…¼å®¹ç‰ˆæœ¬åˆ—è¡¨<a class="ae ld" href="https://www.tensorflow.org/install/source#linux" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œ</a>ã€‚</p><p id="b12a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">æ£€æŸ¥ TF2 æ˜¯å¦å·²æˆåŠŸå®‰è£…åœ¨æ‚¨çš„ç³»ç»Ÿä¸Š:</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="26da" class="lx jl hi lt b fi ly lz l ma mb">import tensorflow as tf<br/>print(tf.constant('Hello from TensorFlow ' + tf.__version__))</span></pre><p id="432a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">å¯¹äº GPU æ„å»ºï¼Œè¯·æ£€æŸ¥æ‚¨æ˜¯å¦æœ‰ä¸€ä¸ª GPUï¼Œå¹¶ä¸ºå…¶å®‰è£…äº† TF2:</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="ed51" class="lx jl hi lt b fi ly lz l ma mb">import tensorflow as tf<br/>print(tf.config.list_physical_devices('GPU'))<br/>print(tf.test.is_built_with_cuda())</span></pre><p id="f59c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">å¦‚æœè¿™äº›è¡Œå¦‚é¢„æœŸè¿è¡Œï¼Œé‚£ä¹ˆæ­å–œä½ ğŸ‰ï¼Œæ‚¨å°±å¯ä»¥åœ¨ TensorFlow 2.0 ä¸­å»ºç«‹æ¨¡å‹äº†ã€‚å¦‚æœä½ åœ¨å®‰è£…è¿‡ç¨‹ä¸­æœ‰é—®é¢˜(æˆ‘è‚¯å®šæœ‰)ï¼Œè¯·åœ¨ä¸‹é¢è¯„è®ºï¼Œæˆ‘ä¼šå°½åŠ›æä¾›åé¦ˆã€‚</p><h1 id="c273" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">æ„å»ºæ¨¡å‹æ¡†æ¶:</h1><p id="cf77" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc hb bi translated">ç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹æˆ‘ä»¬å°†ç”¨æ¥åœ¨ TF2 æ„å»ºå®šåˆ¶æœºå™¨å­¦ä¹ (ML)æ¨¡å‹çš„ä¸»å¹²ã€‚æ³¨æ„ï¼Œè¿™ä¸ªæ¡†æ¶ä½¿ç”¨äº† Keras åŒ…ï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜çº§ TensorFlow åŒ…è£…å™¨ï¼Œä½¿å¾—å®šåˆ¶ ML æ¨¡å‹(å°¤å…¶æ˜¯ CNN çš„)æ›´åŠ å®¹æ˜“ã€‚è¿™é‡Œæˆ‘ç”¨ 32c3p 2â€“32c3p 2â€“32c5s 2-D128-D10 æ¶æ„åšäº†ä¸€ä¸ª CNN å›¾åƒåˆ†ç±»å™¨:</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="e1c7" class="lx jl hi lt b fi ly lz l ma mb">import os<br/># Turn off TensorFlow warning messages in program output<br/>os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'<br/>import tensorflow as tf<br/>from tensorflow.keras import Model<br/>from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, BatchNormalization, Dropout<br/><br/>class Image_CNN(Model):<br/>  def __init__(self):<br/>    super().__init__()<br/>    self.conv1 = Conv2D(32, 3, input_shape=(..., 3), strides=1, activation='relu')<br/>    self.conv2 = Conv2D(32, 3, strides=1, activation='relu')<br/>    self.conv3 = Conv2D(32, 5, strides=2, activation='relu')<br/><br/>    self.pool1 = MaxPool2D(pool_size=(2,2))<br/>    self.batchnorm = BatchNormalization()<br/>    self.dropout40 = Dropout(rate=0.4)<br/><br/>    self.flatten = Flatten()<br/>    self.d128 = Dense(128, activation='relu')<br/>    self.d10softmax = Dense(10, activation='softmax')<br/><br/>  def call(self, x, training=False):<br/>    x = self.conv1(x)<br/>    x = self.pool1(x)<br/>    x = self.conv2(x)<br/>    x = self.pool1(x)<br/>    x = self.conv3(x)<br/>    x = self.batchnorm(x)<br/>    if training:<br/>        x = self.dropout40(x, training=training)<br/><br/>    x = self.flatten(x)<br/>    x = self.d128(x)<br/>    x = self.d10softmax(x)<br/><br/>    return x</span></pre><p id="9c85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">å¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬å¯¼å…¥äº† CNN çš„æ„å»ºå—ï¼Œå¹¶åœ¨æˆ‘ä»¬çš„â€œImage_CNNâ€ç±»ä¸­å®ç°äº†å®ƒä»¬ã€‚è‡ªå®šä¹‰æ¨¡å‹ç»§æ‰¿è‡ª Keras æ¨¡å‹ï¼Œå¿…é¡»åŒ…å« 2 ä¸ªæ–¹æ³•(å‡½æ•°):â€œ__init__â€å’Œâ€œcallâ€ã€‚â€œ__init__â€æ–¹æ³•å®šä¹‰äº†å±‚,â€œcallâ€æ–¹æ³•å®šä¹‰äº†åœ¨æ€¥åˆ‡æ‰§è¡Œä¸‹ä½¿ç”¨çš„å±‚çš„é¡ºåºå’Œæ•°é‡ï¼Œè¿™æ˜¯ TF2 æœ€å¤§çš„æ–°ç‰¹æ€§ä¹‹ä¸€ã€‚</p><p id="9878" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">æ³¨æ„#1 </strong>:ä¸ºäº†ä½¿ä½ çš„ ML æ¨¡å‹å®Œå…¨å®šåˆ¶åŒ–ï¼Œä½ åº”è¯¥å®šä¹‰ä½ çš„æ¨¡å‹çš„æ¯ä¸€ä¸ªæ„å»ºå—(å±‚),è€Œä¸æ˜¯ä½¿ç”¨é¢„å…ˆæ‰“åŒ…çš„ Keras å±‚ã€‚</p><p id="c467" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">æ³¨æ„#2 </strong>:åœ¨è¿™ä¸ª CNN ä¸­ï¼Œæˆ‘åœ¨å·ç§¯æ­¥éª¤åæ·»åŠ äº†ä¸€ä¸ªæ¼å±‚ã€‚è¿™ä¸ä»…æœ‰åŠ©äºè®­ç»ƒç¥ç»ç½‘ç»œï¼Œå®ƒåº”è¯¥åªç”¨äºè®­ç»ƒ(æˆ‘ä»¬ä¸æƒ³åˆ é™¤æˆ‘ä»¬çš„ä»»ä½•æµ‹è¯•ç»“æœ)ã€‚</p><h1 id="624c" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">å®šä¹‰è®­ç»ƒå’Œæµ‹è¯•æ­¥éª¤:</h1><p id="52a3" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc hb bi translated">æˆ‘ä»¬å®šä¹‰äº†å°†ä¸ºæ¯ä¸ªæ•°æ®ç‚¹å’Œæ¯ä¸ªæ—¶æœŸæ‰§è¡Œçš„è®­ç»ƒå‡½æ•°å’Œæµ‹è¯•å‡½æ•°ã€‚</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="61b3" class="lx jl hi lt b fi ly lz l ma mb">@tf.function<br/>def train_step(images, labels):<br/>  with tf.GradientTape() as tape:<br/>    # training=True is only needed if there are layers with different<br/>    # behavior during training versus inference (e.g. Dropout).<br/>    predictions = model(images, training=True)<br/>    loss = loss_object(labels, predictions)<br/>  gradients = tape.gradient(loss, model.trainable_variables)<br/>  optimizer.apply_gradients(zip(gradients, model.trainable_variables))<br/><br/>  train_loss(loss)<br/>  train_accuracy(labels, predictions)<br/><br/>@tf.function<br/>def test_step(images, labels):<br/>  # training=False is only needed if there are layers with different<br/>  # behavior during training versus inference (e.g. Dropout).<br/>  predictions = model(images, training=False)<br/>  t_loss = loss_object(labels, predictions)<br/><br/>  test_loss(t_loss)<br/>  test_accuracy(labels, predictions)</span></pre><p id="dd21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">æ¯ä¸ªå‡½æ•°éƒ½ç”±ä¸€ä¸ª tensorflow è£…é¥°å‡½æ•°åŒ…è£…ï¼Œè¯¥å‡½æ•°å°† Python å‡½æ•°è½¬æ¢ä¸ºé™æ€ tensorflow å›¾ã€‚å› ä¸º TF2 ä½¿ç”¨æ€¥åˆ‡æ‰§è¡Œï¼Œè¿™äº›å‡½æ•°çš„é€è¡Œæ±‚å€¼å¯èƒ½ä¼šå¾ˆæ…¢ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å‡½æ•°è½¬æ¢æˆä¸€ä¸ªé™æ€å›¾æ¥åŠ é€Ÿä»£ç æ‰§è¡Œã€‚ğŸ‘</p><p id="a929" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">æ‚¨è¿˜ä¼šæ³¨æ„åˆ°ï¼Œåœ¨â€œtrain_stepâ€æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† tfã€‚TF2 çš„å¦ä¸€ä¸ªæ–°ç‰¹è‰²ã€‚è¿™ä¹Ÿæ˜¯å‘ TensorFlow çš„æ€¥åˆ‡æ‰§è¡Œæ–¹æ³•è½¬å˜çš„ç»“æœã€‚å› ä¸ºæˆ‘ä»¬çš„æ¨¡å‹æ€¥åˆ‡åœ°æ‰§è¡Œ(è€Œä¸æ˜¯ä½œä¸ºé™æ€å›¾å½¢)ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å®ƒä»¬è¿è¡Œæ—¶è·Ÿè¸ªæ¯ä¸€å±‚çš„æ¢¯åº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨ GradientTape æ¥å®Œæˆè¿™é¡¹å·¥ä½œã€‚è¿™äº›æ¢¯åº¦ç„¶åè¢«é¦ˆé€åˆ°æ‰€é€‰æ‹©çš„ä¼˜åŒ–å™¨ä¸­ï¼Œä»¥é€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°æ¥ç»§ç»­å­¦ä¹ è¿‡ç¨‹ã€‚ğŸ§ </p><h1 id="b112" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">å‡†å¤‡æ•°æ®é›†å¹¶è¿è¡Œæ¨¡å‹:</h1><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es mc"><img src="../Images/a44dad8c82db9612dbefb062830eb91f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IrhPOPxI70n8zzJk"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">ç”±<a class="ae ld" href="https://unsplash.com/@swimstaralex?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">æ‹æ‘„çš„äºšå†å±±å¤§Â·è¾›æ©</a>åœ¨<a class="ae ld" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><p id="aa8e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">æˆ‘ä»¬ç°åœ¨å‡†å¤‡è®­ç»ƒå’Œæµ‹è¯•æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œï¼åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åŠ è½½äº†ç»å…¸çš„æ‰‹å†™æ•°å­— MNIST æ•°æ®é›†ï¼Œå®ƒå¯ä»¥ç›´æ¥ä» tf.keras.datasets å¯¼å…¥ã€‚æœ‰ 60ï¼Œ000 ä¸ªè®­ç»ƒå›¾åƒå’Œ 10ï¼Œ000 ä¸ªæµ‹è¯•å›¾åƒï¼Œæ¯ä¸ªå›¾åƒçš„ç»´æ•°ä¸º 28x28ã€‚ç„¶åä½¿ç”¨ tf.data.Dataset å°†è¿™äº›å›¾åƒä»¥ 32 ä¸ªä¸€æ‰¹çš„æ–¹å¼è¾“å…¥åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­ã€‚</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="d7c4" class="lx jl hi lt b fi ly lz l ma mb">if __name__ == '__main__':<br/>    import time<br/>    start_time = time.time()<br/><br/>    # Load MNIST images and normalize pixel range to 0-1.<br/>    mnist = tf.keras.datasets.mnist<br/>    (x_train, y_train), (x_test, y_test) = mnist.load_data()<br/>    x_train, x_test = x_train / 255.0, x_test / 255.0<br/><br/>    # Add a channels dimension.<br/>    x_train = x_train[..., tf.newaxis].astype("float32")<br/>    x_test = x_test[..., tf.newaxis].astype("float32")<br/><br/>    # Set up a data pipeline for feeding the training and testing data into the model.<br/>    shuff_size = int(0.25 * len(y_train))<br/>    batch_size = 32<br/>    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(shuff_size).batch(batch_size)<br/>    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)<br/><br/>    # Instantiate our neural network model from the predefined class. Also define the loss function and optimizer.<br/>    model = Image_CNN()<br/>    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)<br/>    optimizer = tf.keras.optimizers.Adam()<br/><br/>    # Define the metrics for loss and accuracy.<br/>    train_loss = tf.keras.metrics.Mean(name='train_loss')<br/>    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')<br/>    test_loss = tf.keras.metrics.Mean(name='test_loss')<br/>    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')<br/><br/>    # Run and iterate model over epochs<br/>    EPOCHS = 5<br/>    for epoch in range(EPOCHS):<br/><br/>      # Reset the metrics at the start of the next epoch<br/>      train_loss.reset_states()<br/>      train_accuracy.reset_states()<br/>      test_loss.reset_states()<br/>      test_accuracy.reset_states()<br/><br/>      # Train then test the model<br/>      for images, labels in train_ds:<br/>        train_step(images, labels)<br/>      for test_images, test_labels in test_ds:<br/>        test_step(test_images, test_labels)<br/><br/>      # Print results<br/>      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'<br/>      print(template.format(epoch + 1,<br/>                            train_loss.result(),<br/>                            train_accuracy.result() * 100,<br/>                            test_loss.result(),<br/>                            test_accuracy.result() * 100))<br/>    print("time elapsed: {:.2f}s".format(time.time() - start_time))</span></pre><p id="b667" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">å› ä¸ºæˆ‘ä»¬æ­£åœ¨æ‰§è¡Œå¤šæ ‡ç­¾å›¾åƒåˆ†ç±»ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ç²¾åº¦åº¦é‡å°†æ˜¯åˆ†ç±»äº¤å‰ç†µï¼Œå¹¶ä¸”æˆ‘ä»¬å°†åœ¨ 5 ä¸ªæ—¶æœŸå†…è®­ç»ƒæˆ‘ä»¬çš„ CNNã€‚è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬åšå¾—æ€ä¹ˆæ ·:</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="d3cc" class="lx jl hi lt b fi ly lz l ma mb">Epoch 1, Loss: 1.5532550811767578, Accuracy: 92.288330078125, Test Loss: 1.4825093746185303, Test Accuracy: 98.0</span><span id="f903" class="lx jl hi lt b fi md lz l ma mb">Epoch 2, Loss: 1.4951773881912231, Accuracy: 96.80332946777344, Test Loss: 1.4800351858139038, Test Accuracy: 98.12999725341797</span><span id="1d65" class="lx jl hi lt b fi md lz l ma mb">Epoch 3, Loss: 1.488990306854248, Accuracy: 97.30999755859375, Test Loss: 1.4788316488265991, Test Accuracy: 98.2699966430664</span><span id="96d9" class="lx jl hi lt b fi md lz l ma mb">Epoch 4, Loss: 1.4862409830093384, Accuracy: 97.55833435058594, Test Loss: 1.4759035110473633, Test Accuracy: 98.58000183105469</span><span id="f26e" class="lx jl hi lt b fi md lz l ma mb">Epoch 5, Loss: 1.484948992729187, Accuracy: 97.66667175292969, Test Loss: 1.475019931793213, Test Accuracy: 98.63999938964844</span><span id="c0f3" class="lx jl hi lt b fi md lz l ma mb">time elapsed: 26.20s</span></pre><p id="5991" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">æˆ‘ä»¬å·²ç»æˆåŠŸå®‰è£…äº† TF2ï¼Œåˆ›å»ºäº† CNN å›¾åƒåˆ†ç±»å™¨ï¼Œå¹¶ä½¿ç”¨ GPU åœ¨ 30 ç§’å†…å®ç°äº†è‰¯å¥½çš„æµ‹è¯•å‡†ç¡®æ€§ï¼</p><p id="18a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">å¦‚æœä½ å¯¹æˆ‘ä»¬åœ¨âœŒçš„è¿‡ç¨‹æœ‰ä»»ä½•é—®é¢˜å’Œè¯„è®ºï¼Œæ¬¢è¿åœ¨ä¸‹é¢å‘å¸–</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="5c3f" class="lx jl hi lt b fi ly lz l ma mb">import os<br/># Turn off TensorFlow warning messages in program output<br/>os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'<br/>import tensorflow as tf<br/>from tensorflow.keras import Model<br/>from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, BatchNormalization, Dropout<br/><br/>class Image_CNN(Model):<br/>  def __init__(self):<br/>    super().__init__()<br/>    self.conv1 = Conv2D(32, 3, input_shape=(..., 3), strides=1, activation='relu')<br/>    self.conv2 = Conv2D(32, 3, strides=1, activation='relu')<br/>    self.conv3 = Conv2D(32, 5, strides=2, activation='relu')<br/><br/>    self.pool1 = MaxPool2D(pool_size=(2,2))<br/>    self.batchnorm = BatchNormalization()<br/>    self.dropout40 = Dropout(rate=0.4)<br/><br/>    self.flatten = Flatten()<br/>    self.d128 = Dense(128, activation='relu')<br/>    self.d10softmax = Dense(10, activation='softmax')<br/><br/>  def call(self, x, training=False):<br/>    x = self.conv1(x)<br/>    x = self.pool1(x)<br/>    x = self.conv2(x)<br/>    x = self.pool1(x)<br/>    x = self.conv3(x)<br/>    x = self.batchnorm(x)<br/>    if training:<br/>        x = self.dropout40(x, training=training)<br/><br/>    x = self.flatten(x)<br/>    x = self.d128(x)<br/>    x = self.d10softmax(x)<br/><br/>    return x<br/><br/>@tf.function<br/>def train_step(images, labels):<br/>  with tf.GradientTape() as tape:<br/>    # training=True is only needed if there are layers with different<br/>    # behavior during training versus inference (e.g. Dropout).<br/>    predictions = model(images, training=True)<br/>    loss = loss_object(labels, predictions)<br/>  gradients = tape.gradient(loss, model.trainable_variables)<br/>  optimizer.apply_gradients(zip(gradients, model.trainable_variables))<br/><br/>  train_loss(loss)<br/>  train_accuracy(labels, predictions)<br/><br/>@tf.function<br/>def test_step(images, labels):<br/>  # training=False is only needed if there are layers with different<br/>  # behavior during training versus inference (e.g. Dropout).<br/>  predictions = model(images, training=False)<br/>  t_loss = loss_object(labels, predictions)<br/><br/>  test_loss(t_loss)<br/>  test_accuracy(labels, predictions)<br/><br/><br/>if __name__ == '__main__':<br/>    import time<br/>    start_time = time.time()<br/><br/>    # Load MNIST images and normalize pixel range to 0-1.<br/>    mnist = tf.keras.datasets.mnist<br/>    (x_train, y_train), (x_test, y_test) = mnist.load_data()<br/>    x_train, x_test = x_train / 255.0, x_test / 255.0<br/><br/>    # Add a channels dimension.<br/>    x_train = x_train[..., tf.newaxis].astype("float32")<br/>    x_test = x_test[..., tf.newaxis].astype("float32")<br/><br/>    # Set up a data pipeline for feeding the training and testing data into the model.<br/>    shuff_size = int(0.25 * len(y_train))<br/>    batch_size = 32<br/>    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(shuff_size).batch(batch_size)<br/>    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)<br/><br/>    # Instantiate our neural network model from the predefined class. Also define the loss function and optimizer.<br/>    model = Image_CNN()<br/>    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)<br/>    optimizer = tf.keras.optimizers.Adam()<br/><br/>    # Define the metrics for loss and accuracy.<br/>    train_loss = tf.keras.metrics.Mean(name='train_loss')<br/>    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')<br/>    test_loss = tf.keras.metrics.Mean(name='test_loss')<br/>    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')<br/><br/>    # Run and iterate model over epochs<br/>    EPOCHS = 5<br/>    for epoch in range(EPOCHS):<br/><br/>      # Reset the metrics at the start of the next epoch<br/>      train_loss.reset_states()<br/>      train_accuracy.reset_states()<br/>      test_loss.reset_states()<br/>      test_accuracy.reset_states()<br/><br/>      # Train then test the model<br/>      for images, labels in train_ds:<br/>        train_step(images, labels)<br/>      for test_images, test_labels in test_ds:<br/>        test_step(test_images, test_labels)<br/><br/>      # Print results<br/>      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'<br/>      print(template.format(epoch + 1,<br/>                            train_loss.result(),<br/>                            train_accuracy.result() * 100,<br/>                            test_loss.result(),<br/>                            test_accuracy.result() * 100))<br/>    print("time elapsed: {:.2f}s".format(time.time() - start_time))</span></pre></div></div>    
</body>
</html>