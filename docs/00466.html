<html>
<head>
<title>Customer Transaction Prediction using LightGBM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用LightGBM进行客户交易预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/https-medium-com-kushagrarajtiwari-customer-transaction-prediction-3191c6c634dc?source=collection_archive---------1-----------------------#2019-07-02">https://medium.com/analytics-vidhya/https-medium-com-kushagrarajtiwari-customer-transaction-prediction-3191c6c634dc?source=collection_archive---------1-----------------------#2019-07-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="6f76" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用LightGBM对不平衡数据进行探索性数据分析和建模。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/8443c4d686af5b2df5d32a186fef76ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*UX9hoBZJfvTa_PPEsXMeHg.jpeg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated"><a class="ae jj" href="https://www.pexels.com/photo/working-macbook-computer-keyboard-34577/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h2 id="27f5" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">我正在学习Python进行数据分析，并希望将这些概念应用到真实的数据集上——然后我发现了<a class="ae jj" href="https://www.kaggle.com/c/santander-customer-transaction-prediction" rel="noopener ugc nofollow" target="_blank">这个问题。</a></h2><p id="4a0d" class="pw-post-body-paragraph ki kj hi kk b kl km ij kn ko kp im kq jv kr ks kt jz ku kv kw kd kx ky kz la hb bi translated">在这个问题中，我们需要确定哪些客户将在未来进行特定的交易，而不考虑交易的金额。</p><p id="3747" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练数据是一个匿名数据集，包含200个数字特征变量、二进制目标列、字符串ID_code列和2，00，000个观察值。测试数据包括200个匿名数字变量和一个字符串ID_code列以及2，00，000个观察值。这是一个监督机器学习算法下的二元分类问题。任务是预测测试集中目标列的值。</p><p id="e8ff" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">在这篇文章中，我将讨论这个问题的一般商业意义是什么？如何发掘数据？以及如何通过调整模型参数来建立一个轻量级的GBM模型来解决不平衡数据的分类问题。本文使用的Python代码在这里是<a class="ae jj" href="https://github.com/KUSHAGRARAJTIWARI/Santander-Customer-Transaction-prediction-/blob/master/santander%20customer%20prediction_final.ipynb" rel="noopener ugc nofollow" target="_blank">。</a>让我们开始这段旅程吧👇。</p><h1 id="be48" class="lg jl hi bd jm lh li lj jq lk ll lm ju io ln ip jy ir lo is kc iu lp iv kg lq bi translated"><strong class="ak">一般业务意义</strong></h1><p id="b727" class="pw-post-body-paragraph ki kj hi kk b kl km ij kn ko kp im kq jv kr ks kt jz ku kv kw kd kx ky kz la hb bi translated">该项目可以在以下方面帮助公司-</p><p id="9bfa" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">1.将客户细分为小组，并根据实际行为来解决单个客户的问题，而不是硬编码任何使客户彼此相似的先入为主的概念或假设，也不是只查看隐藏了单个客户重要事实的汇总数据。</p><p id="3968" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">2.使用预测性客户行为建模技术准确预测客户的未来行为(例如，交易预测)，而不是只看历史数据的后视镜。</p><p id="8219" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">3.使用高级计算来确定每个客户的客户终身价值(LTV ),并以此为基础做出决策——而不是只看客户可能给组织带来的短期收入。</p><p id="bcfd" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">4.根据客观的衡量标准，准确地知道现在应该为每个客户做什么营销活动，以最大化每个客户的长期价值。</p><p id="7ab5" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">5.使用营销机器学习技术，该技术将揭示洞察并提出建议，以改善人类营销人员自己不太可能发现的客户营销。</p><h1 id="fd0a" class="lg jl hi bd jm lh li lj jq lk ll lm ju io ln ip jy ir lo is kc iu lp iv kg lq bi translated"><strong class="ak">探索性数据分析</strong></h1><p id="d7ef" class="pw-post-body-paragraph ki kj hi kk b kl km ij kn ko kp im kq jv kr ks kt jz ku kv kw kd kx ky kz la hb bi translated">探索性数据分析主要包括缺失值分析、异常值分析、相关性分析、描述性分析和可视化，以从数据中获得洞察力。</p><p id="990d" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">首先，让我们检查训练数据中少数和多数类的数量。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lr"><img src="../Images/181b792c02fc52bb337049d7499ae22f.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*7jiJA7pIMDXUAWQEijc7Rg.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">典型的不平衡数据</figcaption></figure><p id="e2e8" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">少数民族阶层几乎是训练数据中10%的目标变量。</p><p id="0874" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated"><strong class="kk hj">处理不平衡数据集</strong></p><p id="045c" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">在为这个数据集建模之前，让我们了解如何处理分类问题的不平衡数据集。当面对不平衡数据集时，传统的机器学习算法往往产生不令人满意的分类器。对于任何不平衡数据集，如果要预测的事件属于少数类，且事件发生率小于10%，通常称为罕见事件。当面对不平衡数据集时，传统的模型评估方法不能准确地测量模型性能。像决策树和逻辑回归这样的标准分类算法偏向于具有大量实例的类。他们倾向于只预测多数类数据。少数类的特征被当作噪音，常常被忽略。因此，与多数阶级相比，少数阶级被错误分类的可能性很高。分类算法的性能由混淆矩阵来衡量，混淆矩阵包含了实际类别和预测类别的信息。因此，我们需要处理这个不平衡的数据集。</p><p id="fafa" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">下面是<a class="ae jj" href="https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18" rel="noopener" target="_blank">处理不平衡数据</a>进行分类的一些方法。</p><p id="da85" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练和测试数据中没有缺失值。</p><p id="f563" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">让我们通过绘制每个变量的直方图来检查训练数据中前20个数字特征的分布。(关于完整功能的发布，请点击<a class="ae jj" href="https://github.com/KUSHAGRARAJTIWARI/Santander-Customer-Transaction-prediction-/blob/master/distribution%20of%20numeric%20variables.png" rel="noopener ugc nofollow" target="_blank">这里</a>。)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/048bf444ece729ff1205ab32f6f67f15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cpLyhRj0hA8VxzeDsMrl5Q.png"/></div></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">训练数据中前20个变量的分布。</figcaption></figure><p id="1a3a" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">观察直方图的形状，我们可以很容易地得出结论，几乎所有的数字变量都遵循正态分布。</p><p id="d468" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">根据Chauvenet的标准，我决定看看数据集中是否有异常值。在去除异常值(总观察值的0.87%)后，我们在训练数据中有1，98，264个观察值，在测试数据中有1，98，250个观察值。</p><p id="b2c9" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">现在让我们检查两个目标类的训练数据中前20个变量的分布。(要检查所有变量的分布，请到<a class="ae jj" href="https://github.com/KUSHAGRARAJTIWARI/Santander-Customer-Transaction-prediction-/blob/master/Distribution%20of%20column%20per%20each%20class.png" rel="noopener ugc nofollow" target="_blank">这里</a>。)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lx"><img src="../Images/ec817e4defde2ed4a52a8486183d5165.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3de8CiCkuZwllxtgVyPdVw.png"/></div></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">训练数据中每类前20个变量的分布。</figcaption></figure><p id="99aa" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">从上面的图中我们可以看到，对于不同的目标类别，一些变量显示出不同的分布。但是使用基于树的算法可以处理目标类中的这些不同分布，因为恢复0和1正是基于树的分类模型所做的。对于每个观察值，模型可以指定该观察值属于0的概率和该值属于1的概率。</p><p id="4894" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练和测试数据中前20个数值变量的分布。(完整的发行版请点击<a class="ae jj" href="https://github.com/KUSHAGRARAJTIWARI/Santander-Customer-Transaction-prediction-/blob/master/Distribution%20of%20train%20and%20test%20data..png" rel="noopener ugc nofollow" target="_blank">这里。</a>)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ly"><img src="../Images/052a3e2b31c9a5c148b03de50bace06a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aVEuuzGXgJOHepnNEG7rvw.png"/></div></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">训练和测试数据中前20个变量的分布。</figcaption></figure><p id="8228" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">就数字变量的分布而言，训练和测试似乎是平衡的。</p><p id="456b" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">可视化分类描述性统计，如训练数据的平均值、中值、标准差、最小值、最大值、峰度和偏斜度，我绘制了以下图表。峰度和偏斜度给出了关于数据分布形状的信息。(要了解这些形状变量的重要性，请点击<a class="ae jj" href="https://www.spcforexcel.com/knowledge/basic-statistics/are-skewness-and-kurtosis-useful-statistics" rel="noopener ugc nofollow" target="_blank">这里</a>。)</p><p id="a8c0" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练数据中均值的分类分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/4801a3545c392faa7887ec3baa8750e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kj_o3kRo7_LJvVhnyPl5qQ.png"/></div></div></figure><p id="371c" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练数据中中位数的分类分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/fd07e63f2b16085848b7949458163eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*50tYz_Lxvp5C9jaiHNBAiw.png"/></div></div></figure><p id="4a39" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练数据中标准偏差的分类分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/78bb3d6c70e6eaa5c10de73265e885e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nDM_rH8mjDMd8MUrdfAQSw.png"/></div></div></figure><p id="4cff" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练数据中偏度的分类分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/1c06632d7257202e91b442bd5401c3f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lO0vIChG9LYZsRaOMgDDoQ.png"/></div></div></figure><p id="4a7f" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练数据中峰度的分类分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ma"><img src="../Images/c151f4fa7b1373669ad3d6d9f3f6257c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YfUyfSiYv6qqrBIA3LzAaQ.png"/></div></div></figure><p id="156a" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练数据中最小值的分类分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ma"><img src="../Images/73da6b27112c88b444ada5d8f72f5839.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C1GdQ93QuL7iCNV1F6uhpg.png"/></div></div></figure><p id="8e38" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练数据中最大值的分类分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ma"><img src="../Images/a6a32e855d23a6d71e7af25c7b02836e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*90DsivP6m8_W4G-MPJkj_g.png"/></div></div></figure><p id="9d23" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">将训练和测试数据的平均值、中值、标准差、最小值、最大值、峰度和偏斜度等描述性统计数据可视化，我绘制了以下图表。</p><p id="897b" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练和测试数据的均值分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/14230902b6bb09160b1dedb592094801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0EgUh3iMqFBMw2p5Rib_dg.png"/></div></div></figure><p id="1e91" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练和测试数据中值的分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/530fcb2ca30c61df4134b4e5a0ed6dd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cPXxogZhvvoRFyepFTjDwA.png"/></div></div></figure><p id="568a" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练和测试数据中标准偏差的分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/9417261e3cf6919e7a3e80f04987f53d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*imFdL6NgSRE8Zkc2P2p-4w.png"/></div></div></figure><p id="375f" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练和测试数据中的偏态分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/7c63b3ff33dcc5ece04933435a2c80da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B2cz339CNfbYaAVzw6Cd2w.png"/></div></div></figure><p id="9901" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练和测试数据中峰度的分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ma"><img src="../Images/c293f0ad66c8aab28a685b7e57985aaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LNjo6x5ulR8c8PgxWQvyJA.png"/></div></div></figure><p id="3910" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练和测试数据中最小值的分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ma"><img src="../Images/79cd8b333bc9bf95f35a151326d538ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R6sLEctU0Umx16UNptRH8A.png"/></div></div></figure><p id="c70c" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">训练和测试数据中最大值的分布</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ma"><img src="../Images/558819cf48cdb3562dc916bb64bb7868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U373woC8e-nGIB0dhqn0Gw.png"/></div></div></figure><p id="fd82" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated"><strong class="kk hj">我们可以在这里做一些观察:</strong></p><p id="2777" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">对于训练和测试变量数据，标准差相对较大。然而，训练和测试数据的最小值、最大值、平均值、中值、标准偏差值看起来非常接近。平均值分布在很大的范围内。而且，均值和中位数有相似的分布。训练和测试数据都是极端的和负偏态的。</p><p id="9a91" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">现在检查数值变量之间的相关性，训练数据中数值变量之间的最小和最大相关性分别为-0.009839和0.009676。这表明数值数据之间的相关性接近于零。这意味着大多数数字数据在它们之间几乎是不相关的。</p><p id="a3c4" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">此时，我将进行主成分分析(PCA ),以检查是否所有200个变量都有用，或者我们可以在此时减少特征。为此，我将绘制从PCA获得的经验方差。如果它形成一条斜率为1的直线，那么我们可以得出结论，数据集已经经过了主成分分析。(了解更多PCA <a class="ae jj" href="https://towardsdatascience.com/a-step-by-step-explanation-of-principal-component-analysis-b836fb9c97e2" rel="noopener" target="_blank">这里</a>。)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mb"><img src="../Images/643e2936acfe7cd0e6f48d93b840848c.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*nCrRakLKFdi52H7DXhP8yA.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">解释了对应于不同数量数值变量的方差图。</figcaption></figure><p id="dbf6" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">因此，我们必须使用所有200个特征。</p><h1 id="f6fd" class="lg jl hi bd jm lh li lj jq lk ll lm ju io ln ip jy ir lo is kc iu lp iv kg lq bi translated">特征工程</h1><p id="0c90" class="pw-post-body-paragraph ki kj hi kk b kl km ij kn ko kp im kq jv kr ks kt jz ku kv kw kd kx ky kz la hb bi translated">添加行描述性统计，即均值、中值、标准差、最小值、最大值、峰度、偏斜度和总和，作为训练数据集中的独立特征。我在最初的200个特征的基础上创建了200个新特征，其中这些新特征的新值是特定变量的每个单元中该值唯一出现的次数(频率)。频率中通常会有相关信息，这取决于类别是如何划分的。但我们在添加功能时必须小心谨慎。我们应该检查训练和测试数据中的重复观测值。在测试数据中发现有1，000，000个重复的观察值。</p><p id="8449" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">现在我在训练数据集中有410个变量，在测试数据集中有409个变量。</p><p id="5d5b" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">在建模之前，让我们先了解一些关于分类评估指标AUC-ROC得分的资料(需要对<a class="ae jj" href="https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62" rel="noopener" target="_blank">混淆矩阵</a>有很好的理解。).它是检查任何分类性能的最重要的评估指标之一。也可以写成AUC-ROC(受试者操作特征下的面积)。AUC-ROC曲线是在各种阈值设置下对分类问题的性能测量。ROC是概率曲线，AUC代表可分性的程度或度量。它告诉我们模型在多大程度上能够区分不同的类。AUC越高，模型预测0为0和1为1的能力越强。ROC曲线用真阳性率(TPR)对假阳性率(FPR)作图，其中TPR在y轴上，FPR在x轴上。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mc"><img src="../Images/39675fb59eda16338862f478fb0e4606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*PUDp3DV5B-8br3NKhbgZTA.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">中华民国的代表。</figcaption></figure><p id="2583" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated"><strong class="kk hj">为什么要用轻型GBM </strong>？</p><p id="fe5c" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">正如我们在本文前面所讨论的，我们的数据集是不平衡的，因此我们不应该使用传统的模型，如逻辑回归。朴素贝叶斯的想法是好的，但我们应该确保预测变量的独立性，因为我们有几乎不相关的预测变量，但不能确保它们之间的独立性。</p><p id="1d8e" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">Light GBM一次构建一棵树，其中每个新的树都有助于纠正先前训练的树所犯的错误。它在函数空间(而不是参数空间)中执行优化，这使得自定义损失函数的使用更加容易。与装袋和自适应增压相比，它在速度和精度上也更快。与XGBOOST相比，它能够在训练时间显著减少的情况下，在大型数据集上表现得同样出色。但是除了这些优点之外，LGBM还有一个最不利的特点，即LightGBM 中的<a class="ae jj" href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html" rel="noopener ugc nofollow" target="_blank">参数调整。这件事应该仔细做。(了解更多</a><a class="ae jj" href="https://lightgbm.readthedocs.io/en/latest/Parameters.html" rel="noopener ugc nofollow" target="_blank">光GBM参数</a>。)</p><h1 id="a02d" class="lg jl hi bd jm lh li lj jq lk ll lm ju io ln ip jy ir lo is kc iu lp iv kg lq bi translated"><strong class="ak">造型</strong></h1><p id="d5b1" class="pw-post-body-paragraph ki kj hi kk b kl km ij kn ko kp im kq jv kr ks kt jz ku kv kw kd kx ky kz la hb bi translated">用标准参数LightGBM建模后，AUC得分为0.88576。在添加特征并在建模之前用相同的标准参数建模之后，我得到AUC分数0.89968。在调整参数并使用k=10的<a class="ae jj" rel="noopener" href="/datadriveninvestor/k-fold-and-other-cross-validation-techniques-6c03a2563f1e"> K倍分层交叉验证</a>后，我得到AUC分数9.0600。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es md"><img src="../Images/da1b45b747c68ca8b58e3ffb276e4eea.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*yDeQa2g-eobWF_-c4HnsUA.png"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">具有缩放阈值的ROC</figcaption></figure><p id="734a" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">最后，计算二元分类的其他度量。</p><pre class="iy iz ja jb fd me mf mg mh aw mi bi"><span id="76b1" class="jk jl hi mf b fi mj mk l ml mm">Accuracy Score for LightGBM is  0.86031<br/>Precision Score for  LightGBM is  0.777291272763459<br/>Recall Score for LightGBM is  0.39970320335687237<br/>f1 Score for LightGBM is  0.527930789767159</span></pre><p id="984f" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">可通过以下方式进一步改善</p><p id="7df2" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">使用并行处理和LightGBM算法。</p><p id="9ac8" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">尝试XGBoost以获得更快的速度。</p><p id="da3b" class="pw-post-body-paragraph ki kj hi kk b kl lb ij kn ko lc im kq jv ld ks kt jz le kv kw kd lf ky kz la hb bi translated">关于这个问题的专家观点，请点击这里。</p><h1 id="ad2a" class="lg jl hi bd jm lh li lj jq lk ll lm ju io ln ip jy ir lo is kc iu lp iv kg lq bi translated"><strong class="ak">结尾注释</strong></h1><p id="fcbc" class="pw-post-body-paragraph ki kj hi kk b kl km ij kn ko kp im kq jv kr ks kt jz ku kv kw kd kx ky kz la hb bi translated">这是一个典型的不平衡数据集上的二进制分类问题，没有丢失值。预测变量是匿名的和数字的，目标变量是分类的。可视化的描述性特征，最后我知道这些变量之间是不相关的。之后，我决定处理不平衡的数据集。使用LightGBM建模，使用具有特征工程数据的标准模型参数，我得到的AUC得分为0.899，并且在使用K倍分层抽样调整参数后，AUC得分的最终值为0.90600。</p><h1 id="b888" class="lg jl hi bd jm lh li lj jq lk ll lm ju io ln ip jy ir lo is kc iu lp iv kg lq bi translated"><strong class="ak">参考文献</strong></h1><p id="5f56" class="pw-post-body-paragraph ki kj hi kk b kl km ij kn ko kp im kq jv kr ks kt jz ku kv kw kd kx ky kz la hb bi translated">我从<a class="ae jj" href="https://www.kaggle.com/cdeotte/200-magical-models-santander-0-920/notebook" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/cdeotte/200-magic-models-Santander-0-920/notebook</a>和本文提到的其他链接中获取了本文的参考资料。我相信这些技术会很有用，你会从这篇文章中有所收获。直到那时快乐的分析！😎。</p></div></div>    
</body>
</html>