<html>
<head>
<title>An Introduction to Data Pipeline with Spark in AWS.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动气象站Spark数据管道介绍。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/an-introduction-to-spark-with-aws-425e6ccdff52?source=collection_archive---------3-----------------------#2020-02-20">https://medium.com/analytics-vidhya/an-introduction-to-spark-with-aws-425e6ccdff52?source=collection_archive---------3-----------------------#2020-02-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/6f8141b1a8f0a0bd2725b448a86afd45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fd_3sMh2FO1cZC-g"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">mihály kles在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="7e11" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个故事展示了一种使用<strong class="ix hj"> PySpark </strong>转换数据的简单方法。伴随着转换，Spark内存管理也受到关注。</p><p id="24b8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这里，房地美从1999年<strong class="ix hj">到2018年</strong>的收购和性能数据用于创建单个o/p文件，该文件可进一步用于<strong class="ix hj">数据分析</strong>或构建<strong class="ix hj">机器学习模型</strong>。最后在<strong class="ix hj"> MapReduce </strong>和<strong class="ix hj"> Spark </strong>之间进行比较。</p><h1 id="5a86" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">使用的工具/软件:</h1><ol class=""><li id="23d7" class="kr ks hi ix b iy kt jc ku jg kv jk kw jo kx js ky kz la lb bi translated">服务—数据块，EMR。</li><li id="86f0" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">存储—个人电脑，S3。</li><li id="61dc" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">语言— PySpark、Python、SAS(参考)。</li></ol><h1 id="a517" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">清单如下:</h1><ol class=""><li id="4048" class="kr ks hi ix b iy kt jc ku jg kv jk kw jo kx js ky kz la lb bi translated">理解数据和转换逻辑。</li><li id="de3d" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">Spark并行和作业生命周期。</li><li id="e11d" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">Spark内存管理。</li><li id="8bc3" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">用Spark-Submit进行数据处理。</li><li id="6921" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">数据验证。</li><li id="f274" class="kr ks hi ix b iy lc jc ld jg le jk lf jo lg js ky kz la lb bi translated">MapReduce和Spark的比较。</li></ol><p id="de76" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于完整卷，使用的两个I/p文件大小为145 Gb，o/p文件大小为5 Gb。对于示例文件，总的I/p和O/p文件大小接近3Gb。O/p文件类似于收购文件，但有更多的列，如贷款违约状态、违约UPB等。来自性能数据。</p><h1 id="0c4d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">1.理解数据和转换逻辑。</h1><blockquote class="lh li lj"><p id="ef79" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">使用一个简单的python脚本从房地美网站收集数据。它废弃网站，下载并解压文件到本地电脑。解压缩后的文件被上传到S3进行进一步处理。</p><p id="580f" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">采集文件有<strong class="ix hj"> 27 </strong>个属性，性能有26个属性。更多详情请点击<a class="ae iu" href="http://www.freddiemac.com/fmac-resources/research/pdf/user_guide.pdf" rel="noopener ugc nofollow" target="_blank">复制本</a>链接。转换逻辑从房地美<a class="ae iu" href="http://www.freddiemac.com/research/datasets/sf_loanlevel_dataset.page" rel="noopener ugc nofollow" target="_blank">网站</a>提供的<strong class="ix hj"> SAS </strong>代码中提取，并解码成<strong class="ix hj"> PySpark </strong>。使用<strong class="ix hj">窗口</strong> <strong class="ix hj">、Lag和UDF的</strong>从性能数据中提取出总共<strong class="ix hj"> 34个</strong>新属性，合计o/p文件中的<strong class="ix hj"> 61个</strong>属性。</p><p id="7873" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">从S3的房地美网站收集的所有输入数据都是字符串类型。因此，在实际处理之前，在PySpark脚本中相应地执行类型转换。</p><p id="9763" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">通过各种转换逻辑从性能数据创建了8个新的中间文件。最后，所有的<strong class="ix hj"> 8个新文件与采集数据结合</strong>,以创建具有61个属性的最终o/p。</p><p id="8463" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">使用<strong class="ix hj">数据块</strong>使用<strong class="ix hj">样本</strong>数据(3GB)进行初始PySpark代码开发，最后使用<strong class="ix hj">完整</strong> (145 GB)数据执行<strong class="ix hj"> EMR </strong>中的脚本。</p><p id="0098" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">在DataBricks community edition中(1个EC2实例，8个8Vcores，6Gb)，处理3GB的样本数据需要大约2.16小时。</p><p id="c9a0" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">AWS EMR(1个主节点+10个核心节点，每个节点有16个30Gb的Core)处理样本数据需要19分钟，持久存储完整数据需要2.6小时，不持久存储中间文件需要4.9小时。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/91cd9306583701b5a951d3795e0f1edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5_w_8kybwLRMDSU7gkoiCA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">样本数据，持久化和不持久化作业完成时间。</strong></figcaption></figure><p id="2375" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://github.com/abhilash499/An-Introduction-to-PySpark" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> <em class="lk"> Git链接所有必要的SAS、DataBricks、Python &amp; PySpark代码。</em> </strong> </a></p><h1 id="34a4" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">2.Spark并行和作业生命周期。</h1><blockquote class="lh li lj"><p id="2454" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">当提交一个普通的python作业时，程序在一个单独的Vcore中执行，尽管其他Vcore也是可用的。当一个类似的python程序与Scikit-learn Grid Search CV一起使用<strong class="ix hj"> njobs=-1 </strong>时，所有可用的内核都被单个作业用来并行执行不同的搜索作业。</p><p id="6f9e" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">下图描述了类似的执行过程。Windows处理器<strong class="ix hj"> 4 </strong>正在显示一个<strong class="ix hj">简单Python </strong>脚本和<strong class="ix hj"> 5 </strong>一个<strong class="ix hj">网格搜索</strong>两者同时执行。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/d8cd4136ac2b09a547c1d3def7b7c162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aNf1f8CclVH4PVz9oNoduA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">单机单核Vs多核。</strong></figcaption></figure><blockquote class="lh li lj"><p id="5cb3" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">当一个Spark任务在集群中提交时，<strong class="ix hj">所有</strong>可用的<strong class="ix hj">节点</strong>和<strong class="ix hj">所有</strong>节点<strong class="ix hj"> Vcores </strong>并行工作执行某个任务。下图显示了<strong class="ix hj"> spark flow </strong>读取csv文件，执行转换并将数据保存到磁盘。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/dccbbdeec923558b53eb9fce554f15a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*srKl80QomePusywE5EF0-g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv"> Spak作业生命周期。</strong></figcaption></figure><blockquote class="lh li lj"><p id="39cb" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">当我们提交一个<strong class="ix hj"> Spark作业</strong>时，该作业被分成不同的<strong class="ix hj">阶段</strong>。每个阶段又进一步分为<strong class="ix hj">任务</strong>。在某个时间，一个<strong class="ix hj">执行器</strong>执行某个<strong class="ix hj">数量的任务</strong>，其中<strong class="ix hj">最大任务数=执行器核心数</strong>取决于任务和执行器内存大小。</p><p id="485c" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">从上图中还可以清楚地看到，数据从未接触到驱动器/主节点。数据从源中提取，由执行者处理，然后传送到目的地。</p></blockquote><h1 id="fc2a" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">3.Spark内存管理。</h1><blockquote class="lh li lj"><p id="0162" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated"><strong class="ix hj">默认</strong>火花记忆分布如下图所示。在任何时候，Spark向YARN请求的总内存将是Executors内存<strong class="ix hj"> + </strong>开销内存。<strong class="ix hj">因此，在修改<strong class="ix hj"> spark.executor.memory </strong>时，应该始终记住10%的内存开销</strong>。为了控制开销内存，可以使用参数<strong class="ix hj">spark . executor . memory overhead</strong>。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/61eb387e0d367c2332c1ac675d01d425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eY0c2Y6qcCsk__qv5KjY1w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">默认火花存储器分配。</strong></figcaption></figure><blockquote class="lh li lj"><p id="24ab" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">这里将启动一个EMR集群，该集群包含1个主节点和10个工作节点。在<strong class="ix hj">集群</strong>和<strong class="ix hj"> Spark </strong>中可用的<strong class="ix hj">内存/内核分布</strong>如下所示。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/628b4c4d2149d8ae8f1249f3a53ed982.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*75xkG-Go0_QGjFCdHEeZ1Q.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">集群和火花分布。</strong></figcaption></figure><blockquote class="lh li lj"><p id="8ce6" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">由于这里只对数据进行转换，所以使用<strong class="ix hj">spark . storage . memory fraction = 0.1</strong>&amp;<strong class="ix hj">spark . shuffle . memory fraction = 0.9</strong>。下图描述了不同数量的<strong class="ix hj">执行器内核</strong>的火花分布。必要时，火花存储和混洗可互换使用总可用内存<strong class="ix hj"/>。上面设置了内存不足时<strong class="ix hj">将任何数据驱逐</strong>到磁盘的限制。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/1a43a4217142e9a22dd2fd0c78f41afe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_T-bt0d37fA8cTCkt0HmoA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">遗嘱执行人分配。</strong></figcaption></figure><blockquote class="lh li lj"><p id="ffe9" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">控制内存的另一种方式是我们的数据被Spark分成多少个分区来进行并行处理，Spark称之为RDD的分区。这是因为，在某个时刻，一个火花<strong class="ix hj">执行器</strong>在某个<strong class="ix hj"> RDD </strong> / <strong class="ix hj">分区</strong>上执行某个<strong class="ix hj">任务</strong>。因此，每个分区应该根据执行者的内存携带数据，以避免错误。</p><p id="606c" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">数据分区由参数控制，如<strong class="ix hj"> spark.default.parallelism、spark . SQL . shuffle . partition</strong>和<strong class="ix hj">repartition()/coalesce()</strong>。<strong class="ix hj">spark . default . parallelism</strong>代表<strong class="ix hj">从输入源读取数据</strong>时使用的RDD分区数量，而<strong class="ix hj">spark . SQL . shuffle . partition</strong>代表<strong class="ix hj">混洗数据时使用的RDD分区数量。</strong></p></blockquote><p id="a999" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">测试-1 </strong></p><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/c898cff374a3849143bd3bd1f2e31374.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fXulBJB2EB1b5xO6fmr5Zw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">Spark-Submit with SQL . shuffle . partitions = 400</strong></figcaption></figure><blockquote class="lh li lj"><p id="5817" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">通过上述作业的转换，每当从输入(S3)读取数据时，任务数=分区数=根据默认值<strong class="ix hj">spark . Default . parallelism</strong>设置，该值根据数据大小而变化。一直休息，任务数= spark-submit中设置的分区数=<strong class="ix hj">spark . SQL . shuffle . partition</strong>。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/4ffa3d879b6a8fc7ac00973355756503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dTgHOYiFFTmvpxIRRDuO_g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">仅在从S3读取数据或向其写入数据时执行阶段/任务。</strong></figcaption></figure><p id="841a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">测试-2 </strong></p><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/8f480fb46365d872ef9dfc4e3e2d7a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m_TtvvQNX7Tf-E0uy0OIrA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">Spark-Submit with SQL . shuffle . partitions = default . parallelism = 3200</strong></figcaption></figure><blockquote class="lh li lj"><p id="a812" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">通过上述作业的转换，每当从输入(S3)读取<strong class="ix hj">数据时，任务数=分区数=根据spark-submit <strong class="ix hj">中设置的<strong class="ix hj">spark . default . parallelism</strong>进行设置，对于大文件，但对于小文件，spark会对其进行整形。<strong class="ix hj">休息</strong> <strong class="ix hj">所有</strong>的时间，任务数=分区数=<strong class="ix hj">spark . SQL . shuffle . partition</strong>在spark-submit中设置。</strong></strong></p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/7348425b44977c77f0bb67ef72c385d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bm7eQVBJQeJdbOhYseCz5g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">仅在从S3读取数据或向其写入数据时的阶段/任务。</strong></figcaption></figure><blockquote class="lh li lj"><p id="de5c" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated"><strong class="ix hj">数据序列化</strong>是将复杂数据结构中的数据对象转换成字节流以便存储、传输和分发的过程。数据序列化在任何分布式应用程序的性能中扮演着重要的角色。这可以通过参数<strong class="ix hj"> spark.serializer </strong>来控制。正如Apache所建议的，序列化程序“org . Apache . spark . Serializer . kryoserializer”比默认的Java序列化程序更快。</p><p id="5e5b" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">可以使用<strong class="ix hj"> persist()/cache()将中间数据缓存到RAM或磁盘中。通过使用persist，我们可以让<strong class="ix hj">控制</strong>缓存数据的位置，就像<strong class="ix hj">磁盘</strong>、<strong class="ix hj">内存</strong>或<strong class="ix hj">两者都缓存</strong>。测试执行一次，只将中间数据保存到磁盘，其他数据不保存。当中间文件<strong class="ix hj">没有持久化</strong>时，处理整个数据所花费的<strong class="ix hj">时间</strong>几乎是<strong class="ix hj">的两倍</strong>。</strong></p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/648ab30296d0412b2b3db5885753eaf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w90n13OehtbftPc51IePVQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">持久化与非持久化中间文件的总作业时间。</strong></figcaption></figure><blockquote class="lh li lj"><p id="6c8c" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">向数据库读写数据时，如果数据量很大<strong class="ix hj">，则执行<strong class="ix hj">repartition()/coalesce()</strong>。这是为了避免同时大量连接到数据库。</strong></p><p id="a124" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">Spark在任何任务失败后都会尝试多次，然后才会放弃工作。这可以通过<strong class="ix hj"> spark.task.maxFailures </strong>和<em class="hi">来设置。</em>默认为<strong class="ix hj"> 4 </strong>。Spark能够在4次尝试内连接到S3，否则整个工作将会失败。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/ca5cb43cb9ab4606f22af5dcb7b3716a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JT0gfCfATFjAp8TBrEHXlA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">给S3写信时任务失败，但作业成功了。总共有300份文件被写到S3。</figcaption></figure><h1 id="6c8e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">4.数据处理。</h1><blockquote class="lh li lj"><p id="79cc" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">在DataBricks &amp; EMR中处理大小接近<strong class="ix hj"> 3Gb </strong>的样本数据时，默认设置运行良好。但是，当处理具有特定AWS EMR集群大小的所有<strong class="ix hj"> 145Gb </strong>数据时，上述参数被调整以成功执行作业。</p><p id="2631" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated"><strong class="ix hj">spark . dynamic allocation . enabled</strong>默认情况下由AWS设置为真，这将一些参数初始化为默认值<strong class="ix hj">。spark . SQL . shuffle . partition</strong>&amp;<strong class="ix hj">spark . default . parallelism</strong><strong class="ix hj">= 3200</strong>内存故障后用400/800。<strong class="ix hj">spark . shuffle . memory fraction = 0.9</strong>&amp;<strong class="ix hj">设置了spark . storage . memory fraction = 0.1</strong>，这里只进行变换。按照spark的建议，<strong class="ix hj">spark . serialize = " org . apache . spark . serializer . kryoserializer "</strong>按照Apache的建议更快。</p><p id="56dc" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">处理完整卷时创建的中间文件为81Gb，因此中间数据帧被<strong class="ix hj">持久化</strong>到<strong class="ix hj">纯磁盘</strong>。这个<strong class="ix hj">节省了50%的</strong>加工时间<strong class="ix hj">。在<strong class="ix hj">写</strong>输出的同时合并【20】</strong>以限制大量连接同时到达S3。这两处改动是在<strong class="ix hj"> PySpark脚本</strong>中执行的。</p><p id="39ae" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">利用<strong class="ix hj">这个</strong>簇<strong class="ix hj">的</strong>大小，AWS 中的<strong class="ix hj">默认<strong class="ix hj">spark . dynamic callocation . enabled</strong>被设置为<strong class="ix hj">真</strong>。通过此<strong class="ix hj">设置，spark.executor.memory </strong>被设置为<strong class="ix hj"> 4743M = 4.6g </strong>。</strong></p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/8b405d4144acd617447a4ad039ee42eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1B4lMP7BysqEMy5KDEeGRg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">spark . dynamic allocation . enabled设置为真。</strong></figcaption></figure><blockquote class="lh li lj"><p id="e406" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">有了<strong class="ix hj">这个集群</strong>，当<strong class="ix hj">maximize resource allocation</strong>设置为<strong class="ix hj"> True </strong>，<strong class="ix hj"> spark.executor.memory设置为20131M = 19.6g </strong>。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/e572e778fbf65c70200dc56f05a4c0ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h2Db9djeEnWRfX1JxsU-Hg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">通过运行集群中的json修改设置。</strong></figcaption></figure><blockquote class="lh li lj"><p id="1c9d" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">因此，在默认模式下，如果我们<strong class="ix hj">仅</strong>手动更改<strong class="ix hj">执行器内核</strong>，那么<strong class="ix hj">执行器内存分配</strong>不会发生变化，尽管使用了全部内存，但执行器数量会减少，从而导致并行性降低。因此当在<strong class="ix hj">动态分配</strong>或<strong class="ix hj">最大化资源分配</strong>模式下使用<strong class="ix hj">时，如果</strong>配置参数被修改，需要非常小心地<strong class="ix hj">完成</strong>。</p></blockquote><p id="1fdf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"><em class="lk">Test-1:spark . dynamic allocation . enabled = true，spark.executor.cores=4 </em> </strong></p><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/26a5cbd0c7db0c2439fb3c753a9a3be5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Baqi4vICW7WUJjOosSUJGA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">由AWS默认spark . dynamic allocation . enabled = true+spark . executor . cores = 4</strong></figcaption></figure><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/7f0d6dfc4afa1b3928f1b42e054dfb13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zTvZtkZVphhFPjsHL_tjhg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">执行器存储内存和分配的计数与之前计算的相同。</strong></figcaption></figure><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/7da96cdf4b3503a82521286df8095b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtBDAURha5COth5yY_SrIQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">执行器核心= 4的执行器状态</strong></figcaption></figure><p id="7a37" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"><em class="lk">Test-2:maximize resource allocation = true，spark . executor . cores = 16</em></strong></p><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/31d5a1e819e9a35abbfae91500ec98fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*drRSYLcSUg4tVbwTHyHpHw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">maximize resource allocation = true+spark . executor . cores = 16</strong></figcaption></figure><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/428d82b480eb35149c81270c06ed21c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*clrEgXo7EnqWgQnEwLmCMw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">执行器存储内存和计数完全按照之前的计算进行分配。</strong></figcaption></figure><blockquote class="lh li lj"><p id="cb2a" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">下图显示了任意时间点的执行器状态。因为每个执行器有16个内核，所以在任何时候，一个执行器最多可以执行16个任务。这里，在拍摄图像时执行了10项任务。任务数量取决于分配的执行器内核、内存和任务大小。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/620be8a0c0ac936768deb51e3235f0a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RcoCqG9AUSSNF42uPIrEQA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">执行器核心= 16的执行器状态</strong></figcaption></figure><p id="17f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">在该集群的AWS中，一旦<em class="lk">maximize resource allocation</em>被设置为true <em class="lk">，spark.executor.memory </em>也被自动设置为20131M = 19.6g。然后，如果在不修改<em class="lk"> spark.executor.memory的情况下修改<em class="lk"> spark.executor.cores </em>，则</em>最大<em class="lk">为每个节点</em>分配一个执行器<em class="lk">，这与内存约束(19.6g)无关</em></strong></p><p id="aa54" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">在最大并行化的最后一次运行中，启动了一个新集群，并使用了与测试用例1相同配置的spark-submit。</strong></p><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/3e45f7edfe79b5c73f1854f3d9333023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhMunyQcRfnwvJ5dpGnmgA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv"> EMR火花簇。</strong></figcaption></figure><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/26a5cbd0c7db0c2439fb3c753a9a3be5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Baqi4vICW7WUJjOosSUJGA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">最终火花提交配置。</strong></figcaption></figure><blockquote class="lh li lj"><p id="15e4" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">2.5小时后，转换工作成功完成<strong class="ix hj"/>。由coalesce在脚本中设置的写入S3的文件总数为20，记录计数与采集文件完全相同。在PyScript和Spark配置中仍然有很多优化的空间。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/e99dc8f42d4a3eb9fd673ca3e2dce62c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nhtblrJsXBPhP3tOFRiGAw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">最终加工作业完成时间。</strong></figcaption></figure><h1 id="1096" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">5.数据验证。</h1><blockquote class="lh li lj"><p id="faa3" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">总共创建了20个输出文件，因为在写入S3之前使用了coalesce。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/f7f6908de3a13dcf09673e9cc7d46c48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yyPNYFCLh8AF6U_zuhGiPQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">来自Spark的20个输出文件+ 1个作业完成确认。</strong></figcaption></figure><blockquote class="lh li lj"><p id="8855" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">收购文件和贷款总数。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/18e30a88d17f83acbf7093f8923d9898.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VvWlGSgIFRUlG38yFNoJ2A.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">采集文件和总贷款数。</strong></figcaption></figure><blockquote class="lh li lj"><p id="c24a" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">已处理的文件和贷款总数。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/7ca5f6b2c6a7da31dff10955cc95bac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZSGFMZNq2kRcbs1Wm249CA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">已处理文件和贷款总数。</strong></figcaption></figure><p id="7049" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">在读取已处理的文件时，注意标题，因为20个文件中的每一个都与一个标题记录相关联。</strong></p><h1 id="2de0" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">6.MapReduce和Spark的比较。</h1><blockquote class="lh li lj"><p id="c1b7" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">使用Hive处理相同的数据，Hive又使用MapReduce进行操作。而Hive中的预处理仅基于贷款id和周期进行排序。</p></blockquote><figure class="lp lq lr ls fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/2bb6cfea25c950233fbfe78610e7fe3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R3mL9aY9iI_jClyNFZJ9yA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd jv">以前使用的EMR配置单元集群大小。</strong></figcaption></figure><blockquote class="lh li lj"><p id="3c3f" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">大约花了<strong class="ix hj"> 3.5小时</strong>到<strong class="ix hj">订购和加载</strong> <strong class="ix hj">只有性能数据</strong>到蜂巢。</p><p id="d28b" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated"><a class="ae iu" rel="noopener" href="/analytics-vidhya/big-data-ml-pipeline-using-aws-533dc9b9d774"><strong class="ix hj">EMR中数据管道与Hive的链接。</strong> </a>这里处理的是相同的房地美数据，但只有日期转换。</p><p id="319c" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">在Spark，虽然我们创建了一个比以前更大的集群，但也执行了繁重的任务。像<strong class="ix hj">窗口、滞后、映射和连接9个不同的中间表</strong>这样的操作在Spark中执行，即使有大得多的记录，也只有<strong class="ix hj"> 2.5小时。</strong></p><p id="2079" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">性能差异的主要原因是MapReduce在操作时将中间数据写入<strong class="ix hj">磁盘</strong>，而Spark使用<strong class="ix hj">内存</strong> (RAM)。写入磁盘绝对是一个开销很大的操作。</p><p id="040f" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">还有一个观察，关于<strong class="ix hj">坚持</strong>在星火。在这里，当在<strong class="ix hj"> Spark </strong>中处理时，通过<strong class="ix hj">仅将大的中间文件持久化到磁盘</strong>中，节省了将近50%的时间。由于个人集群RAM大小的<strong class="ix hj">限制，使用Persist。但是在MapReduce <strong class="ix hj">中，大文件和小文件</strong>都被写到<strong class="ix hj">磁盘</strong>中，使得<strong class="ix hj">变慢</strong>。</strong></p></blockquote><p id="9385" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这标志着使用<strong class="ix hj"> PySpark </strong>和<strong class="ix hj"> AWS </strong>处理所有20年来房地美单一家庭贷款数据的结束。</p><blockquote class="lh li lj"><p id="3551" class="iv iw lk ix b iy iz ja jb jc jd je jf ll jh ji jj lm jl jm jn ln jp jq jr js hb bi translated">该o/p处理文件可进一步用于<strong class="ix hj">单户</strong> <strong class="ix hj">家庭贷款数据分析</strong>和<strong class="ix hj">使用机器学习建立贷款风险模型</strong>。</p></blockquote><p id="b330" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="lk">*除了</em><strong class="ix hj"><em class="lk">total-loss-generated</em></strong><em class="lk">之外，尝试将所有其他转换从SAS中。</em></p><p id="4894" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="lk">*在共享集群或单个应用程序中工作时，应仔细设置Spark默认设置，以最大限度地利用资源。</em></p><p id="b4ee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">* <em class="lk">这里由于数据大小是已知的，所以内存计算与分区一起精确地执行。当输入数据量不可用且很大时，可根据环境使用</em><strong class="ix hj"><em class="lk">【maximizeresourcelocation】</em></strong><em class="lk">或</em><strong class="ix hj"><em class="lk">dynamicAllocation</em></strong><em class="lk">与</em><strong class="ix hj"><em class="lk">broadcasting</em></strong><em class="lk">强制连接。</em></p><p id="eb5c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">* <em class="lk"> AWS集群会招致</em> <strong class="ix hj"> <em class="lk">费用</em> </strong> <em class="lk">，但是DataBricks社区版可以免费使用</em> <strong class="ix hj"> <em class="lk">的示例文件。</em>T11】</strong></p><p id="6612" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://github.com/abhilash499/An-Introduction-to-PySpark" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> <em class="lk"> Git链接所有必要的SAS、DataBricks、Python &amp; PySpark代码。</em> </strong> </a></p><p id="93dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">感谢阅读。欢迎提问和建议。</p><p id="d572" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">问候</p><p id="3032" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">阿比。</p></div></div>    
</body>
</html>