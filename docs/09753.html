<html>
<head>
<title>CUDA —CUDA Kernels &amp; Launch Parameters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CUDA——CUDA 内核和发布参数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cuda-compute-unified-device-architecture-part-2-f3841c25375e?source=collection_archive---------4-----------------------#2020-09-19">https://medium.com/analytics-vidhya/cuda-compute-unified-device-architecture-part-2-f3841c25375e?source=collection_archive---------4-----------------------#2020-09-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a27874f532fe8d322d7c20533a0d0e17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jP-PEICl2yzOUR3yVrtcOQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由米格尔·帕德里南提供</figcaption></figure><p id="de21" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在本文中，让我们关注设备启动参数、它们的边界值以及 CUDA 运行时在执行过程中初始化的隐式变量。这篇文章是这篇<a class="ae js" rel="noopener" href="/@rajprasannap/cuda-compute-unified-device-architecture-part-1-8f9ff3179440">文章</a>的续篇。</p><h1 id="bfa2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">那么什么是设备启动参数呢？</strong></h1><p id="c6e6" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">GPU 遵循单指令多线程(SIMT)架构，这意味着发出多个线程来处理同一条指令。这些线程被组织成块，而块被组织成网格。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/aac5c220722cec0094baf14e51eecb4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*kERR2lJ829imnGu3FmvN2Q.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来自维基百科</figcaption></figure><p id="289e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了启动 CUDA 内核，我们需要从主机代码中指定块维度和网格维度。我会考虑同样的 Hello World！前一篇文章中考虑的代码。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="cc5a" class="lg ju hi lc b fi lh li l lj lk">//Pre-processor directives<br/>#include &lt;stdio.h&gt;<br/>#include "cuda_runtime.h"<br/>#include "device_launch_parameters.h"</span><span id="60df" class="lg ju hi lc b fi ll li l lj lk">//Device code<br/>__global__<br/>void cuda_kernel()<br/>{<br/>    printf("Hello World!");<br/>}</span><span id="f35d" class="lg ju hi lc b fi ll li l lj lk">//Host code<br/>int main()<br/>{<br/>    cuda_kernel &lt;&lt;&lt; 1, 1 &gt;&gt;&gt; ();<br/>    cudaDeviceSynchronize();    <br/>    cudaDeviceReset();  <br/>    return 0;<br/>}</span></pre><p id="49e9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在上面的代码中，为了启动 CUDA 内核，在尖括号之间初始化了两个 1。第一个参数表示网格中块的总数，第二个参数表示块中线程的总数。因此，在上面的代码中，一个块中的线程总数是 1，并且在一个网格中有一个这样的块。</p><p id="4b5d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所有块中的线程总数保持不变。为了简单起见，我们可以将一个块中的线程总数命名为<strong class="iw hj">块</strong>，将一个网格中的线程总数命名为<strong class="iw hj">网格</strong>。从软件角度来看，块和网格变量是三维的。让我们看一些例子。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="2926" class="lg ju hi lc b fi lh li l lj lk">int nx;    //total threads in X dimension<br/>int ny;    //total threads in Y dimension<br/>int nz;    //total threads in Z dimension</span><span id="ee98" class="lg ju hi lc b fi ll li l lj lk">nx = 128;       //128 threads in X dim<br/>ny = nz = 1;    //1 thread in Y &amp; Z dim</span><span id="f48e" class="lg ju hi lc b fi ll li l lj lk">//32 threads in X and 1 each in Y &amp; Z in a block<br/>dim3 block(32,1,1); </span><span id="0704" class="lg ju hi lc b fi ll li l lj lk">//4 blocks in X &amp; 1 each in Y &amp; Z<br/>dim3 grid(nx/block.x, ny/block.y, nz/block.z) </span><span id="2467" class="lg ju hi lc b fi ll li l lj lk">cuda_kernel &lt;&lt;&lt;grid,block&gt;&gt;&gt;();</span></pre><p id="139f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">块和网格变量有边界值，边界值取决于 GPU 设备架构。我的机器有 NVIDIA GeForce GTX 1650 卡，其设备架构是<strong class="iw hj">图灵</strong>，以下是边界值。</p><p id="7e9d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">块边界值</strong> — (1024，1024，1024)和所有 3 个 dim 的乘积应小于或等于 1024。</p><p id="ef22" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">网格边界值</strong>——(2147483647，65535，65535)。</p><p id="7110" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们可以通过下面几行代码获得这些值。</p><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="722e" class="lg ju hi lc b fi lh li l lj lk">int devNo = 0;<br/>cudaDeviceProp iProp;</span><span id="a283" class="lg ju hi lc b fi ll li l lj lk">cudaGetDeviceProperties(&amp;iProp, devNo);</span><span id="4f28" class="lg ju hi lc b fi ll li l lj lk">printf("Maximum grid size is: (");<br/>for (int i = 0; i &lt; 3; i++)<br/>    printf("%d\t", iProp.maxGridSize[i]);</span><span id="34fe" class="lg ju hi lc b fi ll li l lj lk">printf(")\n");</span><span id="fd0c" class="lg ju hi lc b fi ll li l lj lk">printf("Maximum block dim is: (");<br/>for (int i = 0; i &lt; 3; i++)<br/>    printf("%d\t", iProp.maxThreadsDim[i]);</span><span id="f537" class="lg ju hi lc b fi ll li l lj lk">printf(")\n");</span><span id="8b02" class="lg ju hi lc b fi ll li l lj lk">printf("Max threads per block: %d\n", iProp.maxThreadsPerBlock);</span></pre><p id="5e09" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果不满足上述边界条件，那么内核就不会启动。</p></div><div class="ab cl lm ln gp lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="hb hc hd he hf"><h1 id="9c1d" class="jt ju hi bd jv jw lt jy jz ka lu kc kd ke lv kg kh ki lw kk kl km lx ko kp kq bi translated">CUDA 运行时初始化的隐式变量</h1><p id="2510" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated"><strong class="iw hj"> threadIdx </strong></p><ol class=""><li id="2e69" class="ly lz hi iw b ix iy jb jc jf ma jj mb jn mc jr md me mf mg bi translated">它是一个 dim3 变量，每个维度都可以由 threadIdx.x、threadIdx.y、threadIdx.z 访问。</li><li id="d9b0" class="ly lz hi iw b ix mh jb mi jf mj jj mk jn ml jr md me mf mg bi translated">引用块中的线程 ID，从 0 开始。因此，如果一个块中 X dim 中的线程数是 32，那么 threadIdx.x 在每个块中的范围是从 0 到 31。</li></ol><p id="5a2a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> blockIdx </strong></p><ol class=""><li id="5f2a" class="ly lz hi iw b ix iy jb jc jf ma jj mb jn mc jr md me mf mg bi translated">它是一个 dim3 变量，每个维度都可以由 blockIdx.x、blockIdx.y、blockIdx.z 访问。</li><li id="2193" class="ly lz hi iw b ix mh jb mi jf mj jj mk jn ml jr md me mf mg bi translated">指网格中的块 ID，从 0 开始。</li></ol><p id="b35f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> blockDim </strong></p><ol class=""><li id="94d0" class="ly lz hi iw b ix iy jb jc jf ma jj mb jn mc jr md me mf mg bi translated">它是一个 dim3 变量。</li><li id="34fc" class="ly lz hi iw b ix mh jb mi jf mj jj mk jn ml jr md me mf mg bi translated">指在所有维度中一个块中的最大线程数，从 1 开始。</li><li id="23a1" class="ly lz hi iw b ix mh jb mi jf mj jj mk jn ml jr md me mf mg bi translated">所有线程块都具有相同的维度。</li></ol><p id="5861" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> gridDim </strong></p><ol class=""><li id="87f3" class="ly lz hi iw b ix iy jb jc jf ma jj mb jn mc jr md me mf mg bi translated">它是一个 dim3 变量。</li><li id="51ff" class="ly lz hi iw b ix mh jb mi jf mj jj mk jn ml jr md me mf mg bi translated">指在所有维度上网格中的最大块数，从 1 开始。</li></ol><p id="0285" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">借助这四个变量，我们可以计算出每个线程的<strong class="iw hj">唯一全局索引</strong>。全局索引将帮助我们访问分配给 GPU 的数百万个线程中的单个线程。</p><p id="38d3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们看看几种情况，以及在每种情况下如何计算全局指数。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/56da99518142abdfe9a0820279e164a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AOyZP-9zJHW4fTmKWfFR7g.jpeg"/></div></div></figure><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="d0cf" class="lg ju hi lc b fi lh li l lj lk">int tid = threadIdx.x;<br/>int col_offset = blockIdx.x * blockDim.x;</span><span id="700d" class="lg ju hi lc b fi ll li l lj lk">int gid = tid + col_offset;</span></pre><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/bf90f3371b4fa9bf8c8cba4674200939.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*BVuoYplP8zmcjFhioR9HVA.jpeg"/></div></figure><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="38e0" class="lg ju hi lc b fi lh li l lj lk">int tid = threadIdx.x;<br/>int col_offset = blockIdx.x * blockDim.x;<br/>int row_offset = blockIdx.y * blockDim.y;</span><span id="5213" class="lg ju hi lc b fi ll li l lj lk">int gid = tid + col_offset + row_offset;</span></pre><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/d536505a41308e0e1422412b97aca36d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*3rDK4mb7oWy5jdGlDLK0YA.jpeg"/></div></figure><pre class="kx ky kz la fd lb lc ld le aw lf bi"><span id="0eab" class="lg ju hi lc b fi lh li l lj lk">int tid = threadIdx.x;<br/>int col_offset = blockDim.x * blockDim.y * blockIdx.x;<br/>int row_offset = gridDim.x * blockIdx.y * blockDim.x * blockDim.y + blockDim.x * threadIdx.y;</span><span id="956e" class="lg ju hi lc b fi ll li l lj lk">int gid = tid + col_offset + row_offset;</span></pre><p id="bb7e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后一种情况也可以用于前两种情况。</p></div><div class="ab cl lm ln gp lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="hb hc hd he hf"><p id="919d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在下一部分中，我将讨论 warps 以及如何优化 CUDA 内核的性能，并基于<strong class="iw hj">试错法</strong>和系统地使用<strong class="iw hj">分析器</strong>来最好地利用 GPU 资源。</p></div></div>    
</body>
</html>