<html>
<head>
<title>Regularized Linear Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">正则化线性模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/regularized-linear-models-in-machine-learning-d2a01a26a46?source=collection_archive---------10-----------------------#2020-05-03">https://medium.com/analytics-vidhya/regularized-linear-models-in-machine-learning-d2a01a26a46?source=collection_archive---------10-----------------------#2020-05-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="86f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在机器学习中，当我们的模型在训练数据上表现良好，但在测试数据上表现很差时，我们经常会面临这个问题。当模型紧密跟随训练数据时，即<a class="ae jd" rel="noopener" href="/analytics-vidhya/bias-variance-trade-off-in-machine-learning-ae6fc6e326ba">过拟合</a>数据时，就会发生这种情况。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/331982c2df19eca566d2b340963fcee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*FKrtc9VG75Ee0RiaFnhOzg.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">来源:谷歌</figcaption></figure><p id="7341" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正则化是一种减少过度拟合的技术。规则化一词指的是使统一的行为。</p><p id="d84c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">复杂的模型可以检测数据中的微妙模式，但如果数据有噪声(包含不相关的信息)或数据集太小，模型将最终检测到噪声本身中的模式。当我们用这个模型来预测我们的结果时，结果会不准确，误差会比预期误差大。</p><p id="adfc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在线性回归中，最终输出是特征变量的加权和，由下式表示。</p><blockquote class="jq jr js"><p id="caf0" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">y = w1x1+w2x2+w3x3+…+wn xn+w₀</p></blockquote><p id="b702" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，权重w1，w2，…，wn表示特征(x1，x2，..xn)。如果一个特征具有与其相关联的大权重，则该特征将具有高重要性。</p><p id="8a6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归中的误差将是均方误差，如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jx"><img src="../Images/4cd9b1a6bda7b3c79fa8dc57e9ca1663.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*OSB23M4o_Knmy-phBd1itg.png"/></div></figure><p id="61b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了改进模型或减少模型中噪声的影响，我们需要减少与噪声相关的权重。与噪声相关联的权重越小，它对预测输出的贡献就越小。</p><p id="409d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于线性模型，通过约束模型的权重来实现正则化。为了约束权重，我们首先需要了解这些权重是如何计算的。根据成本函数计算权重，对于线性回归，成本函数是均方误差。每次调整权重并计算MSE，具有最小MSE的集合将被视为最终输出。</p><p id="cbaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了正则化模型，正则化项将被添加到成本函数中。</p><blockquote class="jq jr js"><p id="dfa7" class="if ig jt ih b ii ij ik il im in io ip ju ir is it jv iv iw ix jw iz ja jb jc hb bi translated">正则化代价函数= MSE+正则化项</p></blockquote><p id="7e37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们将看到三个不同的正则化项来约束模型的权重，因此有三个不同的正则化线性回归算法:</p><ol class=""><li id="64fc" class="jy jz hi ih b ii ij im in iq ka iu kb iy kc jc kd ke kf kg bi translated">里脊回归</li><li id="e2a7" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">套索回归</li><li id="b8f1" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">弹性网</li></ol><p id="c8b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">岭回归:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es km"><img src="../Images/6b740597d3a967ac1681ca54089b2c33.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*uKuFfYUzzi5VZVuf_Lu4JA.png"/></div></figure><p id="4df7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在岭回归中，正则项是模型权重的平方和。在统计学中，这个正则项被称为L2范数。它迫使模型保持尽可能小的重量。</p><p id="9683" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里需要注意的是，正则化只应用于我们的训练数据，我们保持测试数据完整，因为我们希望我们的测试集尽可能接近最终目标。</p><p id="ad45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的等式中，alpha是一个超参数，它控制着我们想要正则化回归模型的程度。如果我们选择一个非常大的α，那么学习算法将试图保持权重尽可能小，因为大的权重将增加成本函数，因此结果将是一条穿过数据平均值的扁平线。如果α为0，那么岭回归就是线性回归。为了选择最佳超参数值，我们进行<strong class="ih hj">超参数调谐</strong>。</p><p id="996c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里需要注意的另一件重要事情是，每当我们应用此技术时，我们首先缩放数据，因为岭回归对输入要素的比例很敏感。对于大多数正则化模型来说都是如此。</p><p id="2d65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">拉索回归:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kn"><img src="../Images/3d4280049f7ff3a95d689516361bb4e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*BusX8c1E5e8rfU-VyIgJnw.png"/></div></figure><p id="a0e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最小绝对收缩和选择算子回归(Lasso)使用L1范数进行正则化，即模型权重的绝对和。</p><p id="8e65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">套索回归的一个重要特征是，它倾向于通过将权重缩小到零来消除不太重要的特征，因此它也用于特征选择。</p><p id="3040" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">弹力网:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ko"><img src="../Images/2767011e536cb8d6600d9044f6b3097f.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*Hk5nLKV1mpEcz1a80wR56A.png"/></div></figure><p id="e915" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">弹性网是脊和套索回归的混合，你想混合多少取决于' r '的值。例如，如果r设置为零，那么它将等于lasso，如果它是1，那么它将成为岭回归。</p><p id="0ccb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">重要的问题是，我们将如何决定我们应该遵循哪个回归。答案是，我们应该始终倾向于进行一些正则化，因此我们默认使用岭回归，但当您认为某些要素比其他要素更重要时，请使用套索回归或弹性网，但当数据集包含大量要素时，则更倾向于弹性网。当数据集包含大量要素时，弹性网的表现要比lasso好得多。</p><p id="8815" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢阅读！</p></div></div>    
</body>
</html>