<html>
<head>
<title>Introduction to Image Caption Generation using the Avenger’s Infinity War Characters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">介绍使用复仇者联盟的无限战争角色生成图像字幕</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-image-caption-generation-using-the-avengers-infinity-war-characters-6f14df09dbe5?source=collection_archive---------0-----------------------#2018-09-21">https://medium.com/analytics-vidhya/introduction-to-image-caption-generation-using-the-avengers-infinity-war-characters-6f14df09dbe5?source=collection_archive---------0-----------------------#2018-09-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b5a29bf30ee9c257cddc6bf51d549a0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kdiNDzyT07UfrmcfDFjVEw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源— <a class="ae iu" href="http://www.hdwallpapers.in" rel="noopener ugc nofollow" target="_blank"> www.hdwallpapers.in </a></figcaption></figure><p id="710b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于初学者来说，深度学习可能是一个令人生畏的领域。对我来说没什么不同——大多数算法和术语听起来来自另一个世界！我需要一种从头开始理解概念的方法，以便弄清楚事物实际上是如何工作的。你瞧，我发现了一种学习深度学习概念的有趣方法。</p><p id="b2fd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个想法很简单。为了理解任何深度学习概念，想象一下这个:</p><blockquote class="jt ju jv"><p id="27cc" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">新生婴儿的大脑能够进行一万亿次计算。而且，你需要的只是时间(epochs)和nuture(算法)来让它理解一个“东西”(问题案例)。我个人称之为<strong class="ix hj">育婴技术。</strong></p></blockquote><p id="1639" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这种直觉天生有效，因为神经网络首先是受人脑的启发。所以，再造问题肯定管用！让我用一个例子来解释一下。</p><p id="2318" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jw">如果我们用美国文化图像训练我们的模型，然后让它预测传统印度舞蹈的标签，会怎么样？</em> </strong></p><p id="9a62" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">把再造思想应用到问题上。这就好比想象一个在美国长大的孩子去了印度度假。猜猜一个美国小孩会给这张照片贴上什么标签？在继续滚动之前，请记住这一点。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ka"><img src="../Images/4706f89b45bc0f6230fd32b6289cb315.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qqGnH_8ISz-9_CmRpE9kFA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">猜猜标题？</figcaption></figure><p id="70b4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个形象有很多来自传统印度文化的传统着装。</p><p id="6429" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">出生在美国的孩子会给一个暴露在美国数据集下的模型起什么名字？T11】</p><p id="b048" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">根据我的实验，模型预测了以下标题:</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="68ba" class="kk kl hi kg b fi km kn l ko kp">A Man Wearing A Hat And A Tie</span></pre><p id="8404" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你了解印度文化，这听起来可能很可笑，但这是算法的偏见。图像标题生成以类似的方式工作。有两种主要的图像字幕模型架构。</p><h1 id="f49f" class="kq kl hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">了解图像标题生成</h1><p id="6161" class="pw-post-body-paragraph iv iw hi ix b iy ln ja jb jc lo je jf jg lp ji jj jk lq jm jn jo lr jq jr js hb bi translated">第一个是基于<strong class="ix hj">图像的模型</strong>，它提取图像的特征，另一个是基于<strong class="ix hj">语言的模型</strong>，它将基于图像的模型给出的特征和对象翻译成自然句子。</p><p id="a534" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本文中，我们将使用在ImageNet数据集上训练的预训练CNN网络。图像被转换成224 X 224 X 3的标准分辨率。这将使任何给定图像的模型的输入保持不变。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/131e3e5bf587698558955d44e1a3c7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZgm5y4hg5C592Abf0mG_Q.png"/></div></div></figure><p id="6009" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">压缩特征向量是从卷积神经网络(CNN)创建的。在技术术语中，这种特征向量被称为<strong class="ix hj"> <em class="jw">嵌入、</em> </strong> <em class="jw"> </em>，CNN模型被称为<strong class="ix hj">编码器。</strong>在下一阶段，我们将使用这些来自CNN层的嵌入作为LSTM网络的输入，一个<strong class="ix hj">解码器</strong>。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/e6cc941b4a3475743678b80a362bf71d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RmSqyNhcRIUwZPNBk8-NtA.png"/></div></div></figure><p id="c86b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在句子语言模型中，LSTM预测句子中的下一个单词。给定图像的初始嵌入，训练LSTM来预测序列的最可能的下一个值。这就像给一个人看一系列照片，并要求他们记住细节。然后给他们看一张和之前的图片内容相似的新图片，让他们回忆这些内容。这种“召回”和“记住”的工作是由我们的LSTM网络完成的。</p><p id="927d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从技术上来说，我们还插入了<start>和<stop>挡块来表示字幕结束。</stop></start></p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="cfc6" class="kk kl hi kg b fi km kn l ko kp">['&lt;start&gt;', 'A', 'man', 'is', 'holding', 'a', 'stone', '&lt;end&gt;']</span></pre><p id="a546" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过这种方式，模型从图像的各种实例中学习，并最终预测看不见的图像的标题。要学习和深入挖掘，我强烈推荐阅读以下参考资料:</p><ol class=""><li id="d9fb" class="lu lv hi ix b iy iz jc jd jg lw jk lx jo ly js lz ma mb mc bi translated"><a class="ae iu" href="https://arxiv.org/abs/1411.4555" rel="noopener ugc nofollow" target="_blank">展示和讲述:谷歌研究团队的神经图像字幕生成器</a></li><li id="6cbf" class="lu lv hi ix b iy md jc me jg mf jk mg jo mh js lz ma mb mc bi translated"><a class="ae iu" href="https://www.analyticsvidhya.com/blog/2018/04/solving-an-image-captioning-task-using-deep-learning/" rel="noopener ugc nofollow" target="_blank">在PyTorch中使用深度学习(CNN和LSTM)的自动图像字幕</a>由Analytics Vidhya提供</li></ol><h1 id="be4f" class="kq kl hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">先决条件</h1><p id="fbf8" class="pw-post-body-paragraph iv iw hi ix b iy ln ja jb jc lo je jf jg lp ji jj jk lq jm jn jo lr jq jr js hb bi translated">要复制本文的结果，您需要安装先决条件。确保你已经安装了anaconda。如果你想从头开始训练你的模型，按照下面的步骤，否则跳到预训练模型部分。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="bfad" class="kk kl hi kg b fi km kn l ko kp">git clone https://github.com/pdollar/coco.git<br/>cd coco/PythonAPI/<br/>make<br/>python setup.py build<br/>python setup.py install<br/>cd ../../<br/>git clone https://github.com/yunjey/pytorch-tutorial.git<br/>cd pytorch-tutorial/tutorials/03-advanced/image_captioning/<br/>pip install -r requirements.txt </span></pre><h2 id="2321" class="kk kl hi bd kr mi mj mk kv ml mm mn kz jg mo mp ld jk mq mr lh jo ms mt ll mu bi translated">预训练模型</h2><p id="94e3" class="pw-post-body-paragraph iv iw hi ix b iy ln ja jb jc lo je jf jg lp ji jj jk lq jm jn jo lr jq jr js hb bi translated">你可以从<a class="ae iu" href="https://www.dropbox.com/s/ne0ixz5d58ccbbz/pretrained_model.zip?dl=0" rel="noopener ugc nofollow" target="_blank">这里</a>下载预训练模型，从<a class="ae iu" href="https://www.dropbox.com/s/26adb7y9m98uisa/vocap.zip?dl=0" rel="noopener ugc nofollow" target="_blank">这里</a>下载词汇文件。您应该使用<code class="du mv mw mx kg b">unzip</code>命令将pretrained_model.zip提取到<code class="du mv mw mx kg b">./models/</code>并将vocab.pkl提取到<code class="du mv mw mx kg b">./data/</code>。</p><p id="8260" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在您已经准备好了模型，您可以使用以下内容来预测标题:</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="3f3d" class="kk kl hi kg b fi km kn l ko kp">$ python sample.py --image='png/example.png'</span></pre><p id="a66a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">原始存储库和代码是在命令行界面中实现的，您需要传递Python参数。为了使它更直观，我制作了一些方便的函数来利用我们的Jupyter笔记本环境中的模型。</p><p id="7abc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们开始吧！导入所有库，并确保笔记本位于存储库的根文件夹中:</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="29df" class="kk kl hi kg b fi km kn l ko kp">import torch<br/>import matplotlib.pyplot as plt<br/>import numpy as np <br/>import argparse<br/>import pickle <br/>import os<br/>from torchvision import transforms <br/>from build_vocab import Vocabulary<br/>from model import EncoderCNN, DecoderRNN<br/>from PIL import Image</span></pre><p id="41a3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将此配置片段和函数从笔记本添加到<em class="jw"> load_image </em>:</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="ea0a" class="kk kl hi kg b fi km kn l ko kp"># Device configuration<br/>device = torch.device(‘cuda’ if torch.cuda.is_available() else ‘cpu’)</span><span id="eec0" class="kk kl hi kg b fi my kn l ko kp">#Function to Load and Resize the image</span><span id="68b9" class="kk kl hi kg b fi my kn l ko kp">def load_image(image_path, transform=None): <br/> image = Image.open(image_path)<br/> image = image.resize([224, 224], Image.LANCZOS)<br/> if transform is not None:<br/>    image = transform(image).unsqueeze(0)<br/> return image</span></pre><p id="7c5d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">用预训练的模型参数硬编码常数。请注意，这些是硬编码的，不应修改。使用以下参数训练预训练模型。只有在从头开始训练模型时，才应该进行更改。</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="8104" class="kk kl hi kg b fi km kn l ko kp"># MODEL DIRS<br/>ENCODER_PATH = './models/encoder-5-3000.pkl'<br/>DECODER_PATH = './models/decoder-5-3000.pkl'<br/>VOCAB_PATH = 'data/vocab.pkl'</span><span id="efa4" class="kk kl hi kg b fi my kn l ko kp"># CONSTANTS<br/>EMBED_SIZE = 256<br/>HIDDEN_SIZE = 512<br/>NUM_LAYERS = 1</span></pre><p id="09aa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，编写一个PyTorch函数，它使用预先训练的文件来预测输出:</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="9aa8" class="kk kl hi kg b fi km kn l ko kp">def PretrainedResNet(image_path, encoder_path=ENCODER_PATH, <br/>                     decoder_path=DECODER_PATH,<br/>                     vocab_path=VOCAB_PATH,<br/>                     embed_size=EMBED_SIZE,<br/>                     hidden_size=HIDDEN_SIZE,<br/>                     num_layers=NUM_LAYERS):<br/>    # Image preprocessing<br/>    transform = transforms.Compose([<br/>        transforms.ToTensor(), <br/>        transforms.Normalize((0.485, 0.456, 0.406), <br/>                             (0.229, 0.224, 0.225))])<br/>    <br/>    # Load vocabulary wrapper<br/>    with open(vocab_path, 'rb') as f:<br/>        vocab = pickle.load(f)</span><span id="2255" class="kk kl hi kg b fi my kn l ko kp"># Build models<br/>    encoder = EncoderCNN(embed_size).eval()  # eval mode (batchnorm uses moving mean/variance)<br/>    decoder = DecoderRNN(embed_size, hidden_size, len(vocab), num_layers)<br/>    encoder = encoder.to(device)<br/>    decoder = decoder.to(device)</span><span id="1c86" class="kk kl hi kg b fi my kn l ko kp"># Load the trained model parameters<br/>    encoder.load_state_dict(torch.load(encoder_path))<br/>    decoder.load_state_dict(torch.load(decoder_path))</span><span id="a3df" class="kk kl hi kg b fi my kn l ko kp"># Prepare an image<br/>    image = load_image(image_path, transform)<br/>    image_tensor = image.to(device)<br/>    <br/>    # Generate a caption from the image<br/>    feature = encoder(image_tensor)<br/>    sampled_ids = decoder.sample(feature)<br/>    sampled_ids = sampled_ids[0].cpu().numpy()          # (1, max_seq_length) -&gt; (max_seq_length)<br/>    <br/>    # Convert word_ids to words<br/>    sampled_caption = []<br/>    for word_id in sampled_ids:<br/>        word = vocab.idx2word[word_id]<br/>        sampled_caption.append(word)<br/>        if word == '&lt;end&gt;':<br/>            break<br/>    sentence = ' '.join(sampled_caption)[8:-5].title() <br/>    # Print out the image and the generated caption<br/>    image = Image.open(image_path)<br/>    return sentence, image</span></pre><p id="47df" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要预测标签，请使用:</p><pre class="kb kc kd ke fd kf kg kh ki aw kj bi"><span id="d900" class="kk kl hi kg b fi km kn l ko kp">plt.figure(figsize=(12,12))<br/>predicted_label, image = PretrainedResNet(image_path='IMAGE_PATH')<br/>plt.imshow(image)<br/>print(predicted_label)</span></pre><h1 id="183f" class="kq kl hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">我们有浩克。现在我们有ML了！</h1><p id="22d9" class="pw-post-body-paragraph iv iw hi ix b iy ln ja jb jc lo je jf jg lp ji jj jk lq jm jn jo lr jq jr js hb bi translated">让我们开始为《复仇者联盟:无限战争》中的一些场景制作字幕，看看它概括得有多好！</p><p id="0cba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">测试图像:Mark I </em></p><p id="1540" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">看看下图:</em></p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/1e46eea41922518d02a8e1e481dd1656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gMR3ezxjF46IykyTK6MV9w.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><hold a="" caption="" in="" your="" mind=""/></figcaption></figure></div><div class="ab cl na nb gp nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="hb hc hd he hf"><p id="d18c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你认为这张图片是关于什么的？记住标题，不要向下滚动。</p><p id="4ea6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们看看我们的模型如何预测这个图像..</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nh"><img src="../Images/543e72737a2c76f65897bd82cbec2c5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jw40L3L2Ue7WOeTW-A_Zuw.png"/></div></div></figure><p id="84c4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这幅图像的预测非常准确。这让我很好奇，我是否可以在漫威宇宙中再次训练一个完整的模型来预测名字。就我个人而言，我很乐意看到托尼·斯塔克出演钢铁侠。</p><p id="1f43" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">测试图像:马克2号</em></p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ni"><img src="../Images/444709ecab59fe5c9022df12d2e67851.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*502HMjQ493-hpv_JF4tV7w.png"/></div></div></figure><p id="7d96" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">再次完美！事实上，托尼正拿着一个蜂窝遥控手机给史蒂夫·罗杰斯打电话。</p><p id="1453" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">测试图像:标记三</em></p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nj"><img src="../Images/b60f4749bb4c1a7895407ca754bab8b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cb-yl_g7xBavW3JNac4cUg.png"/></div></div></figure><p id="e02c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">老实说，即使是我也对模型的学习感到非常惊讶。该模型捕捉到了正面以及背景层的信息。尽管它错误地将黑豹雕像归类为一座山，但总体而言，它仍然是一个相当不错的预测。</p><p id="6bc4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">测试图像:标记四</em></p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nk"><img src="../Images/cfb1bea4e46d2b336c3188802f013d8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uZ_pkJ4fbVKQ1aUy3Xjo6Q.png"/></div></div></figure><p id="55ac" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">哦天啊！<a class="ae iu" href="https://en.wikipedia.org/wiki/Rocket_Raccoon" rel="noopener ugc nofollow" target="_blank"> <em class="jw">火箭Raccon </em> </a>要真的爆冷了。当银河系周围的人称他为兔子或会说话的熊猫时，他会非常恼火。狗会有点紧张的！</p><p id="1d0a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另外，这个模型是在汽车上训练的，因此飞船在这里是不可能的。但我很高兴，我们的模型成功地预测了火箭浣熊坐在“窗口”附近。</p><p id="2a36" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">测试图像:标记V </em></p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nl"><img src="../Images/269b3cd3d5b0da3823334fee9ec95091.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7x9y81Z0yDasxI9THvERA.png"/></div></div></figure><p id="3949" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">“伍兹</em>”，正确。<em class="jw">人坐</em>，正确。“一块石头”，很不幸，但很正确。</p><p id="1bee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的模型在为图像添加字幕方面绝对出色。接下来，我想在漫威宇宙中进一步训练它，看看这个模型是否能识别名称、上下文甚至幽默。</p><p id="d0ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">最终测试:复仇者联盟4预测</em></p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nm"><img src="../Images/008dad5518fc089f4d881cb61a564831.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jaUxX4nZs0nPmNEjspJKdQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">报仇雪恨粉丝海报——Reddit.com(提示:魂界！)</figcaption></figure><p id="14c8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该模型很大程度上暗示了《复仇者联盟4》情节中新的灵魂世界转折。我会把这个留给你！请在下面的评论中告诉我你对最后一张图片的理解。</p><h1 id="fecf" class="kq kl hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">结束注释</h1><p id="f436" class="pw-post-body-paragraph iv iw hi ix b iy ln ja jb jc lo je jf jg lp ji jj jk lq jm jn jo lr jq jr js hb bi translated">随着每一次突破，人工智能和机器学习变得越来越棒。我希望你现在对图像字幕的工作原理有了一个基本的直觉，并且喜欢用复仇者的方式来做。</p><p id="2c8e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">奥创永远离开了。我们向你保证，我们还没有在那个人工智能奇点上工作。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es nn"><img src="../Images/c3bfd63a8c11cd03aa7e6c7a76a8125b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*S9BW7OG2zdCKxEZo"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:吉菲Gify</figcaption></figure><p id="c7f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">所以，休息一下和</em> <em class="jw">分享你的爱通过</em> <strong class="ix hj"> <em class="jw">拍手、</em> </strong> <em class="jw">还有别忘了</em> <strong class="ix hj"> <em class="jw">订阅</em> </strong> <a class="ae iu" href="https://medium.com/analytics-vidhya" rel="noopener"> <strong class="ix hj"> <em class="jw">分析Vidhya </em> </strong> </a> <strong class="ix hj"> <em class="jw">出版</em> </strong> <em class="jw">获取更多牛逼的东西。</em></p></div></div>    
</body>
</html>