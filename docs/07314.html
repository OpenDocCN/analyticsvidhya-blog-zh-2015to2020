<html>
<head>
<title>Apache Spark for the Impatient</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不耐烦的阿帕奇火花</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/apache-spark-for-the-impatient-8bb6f86d38e1?source=collection_archive---------5-----------------------#2020-06-21">https://medium.com/analytics-vidhya/apache-spark-for-the-impatient-8bb6f86d38e1?source=collection_archive---------5-----------------------#2020-06-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="77c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面列出了Spark中最重要的主题，对于那些没有时间阅读整本书，但希望发现这种分布式计算框架的惊人能力的人来说，在开始之前绝对应该阅读这些主题。</p><h1 id="eb34" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">体系结构</h1><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es kb"><img src="../Images/1d0a84fa01cf8f9f8f1bf9801faef5cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1Tsvps41DC9VDYSL.jpg"/></div></div></figure><p id="53db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kn">星火架构图</em></p><h1 id="2575" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">MapReduce与Spark</h1><p id="ead6" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">尽管Apache Spark和MapReduce之间存在许多低级差异，但以下是最显著的差异:</p><ul class=""><li id="ae8b" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">Spark在内存中的运行速度比在磁盘上快100倍。</li><li id="f9bf" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">一个用于对100 TB数据进行排序的排序应用程序比运行在Hadoop MapReduce上的应用程序快三倍，而使用的是十分之一的机器。</li><li id="d53e" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">Spark在机器学习应用程序上的速度尤其快，如朴素贝叶斯和K-Means。</li><li id="5201" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">但是，如果Spark在带有其他共享服务的YARN上运行，性能可能会下降，并导致RAM开销内存泄漏。出于这个原因，如果用户有批处理的用例，Hadoop被认为是更高效的系统。</li></ul><h1 id="88d3" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">驱动者和执行者</h1><p id="aeab" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">运行您的<code class="du lh li lj lk b">main()</code>函数的<strong class="ih hj">驱动程序</strong>进程位于集群中的一个节点上，负责三件事情:</p><ol class=""><li id="3027" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ll kz la lb bi translated">维护关于Spark应用程序的信息。</li><li id="fd9c" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ll kz la lb bi translated">响应用户的程序或输入。</li><li id="6956" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ll kz la lb bi translated">在执行者之间分析、分配和调度工作。</li></ol><p id="c6fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">驱动程序进程是绝对必要的——它是Spark应用程序的核心，在应用程序的生命周期中维护所有相关信息。</p><p id="50e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">执行者</strong>负责实际执行司机分配给他们的工作。这意味着每个执行者只负责两件事:</p><ol class=""><li id="a601" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ll kz la lb bi translated">执行由驱动程序分配给它的代码。</li><li id="d9f7" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ll kz la lb bi translated">将该执行器上的计算状态报告回驱动节点。</li></ol><h1 id="a942" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">划分</h1><p id="8c4d" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">为了允许每个执行器并行执行工作，Spark将数据分成称为<strong class="ih hj">分区</strong>的块。分区是位于集群中一台物理机上的行的集合。数据帧的分区表示数据在执行期间如何在机器集群中物理分布。</p><p id="f48b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你有一个分区，Spark的并行度只有一个，即使你有几千个执行程序。如果有许多分区，但只有一个执行器，Spark的并行度仍然只有一个，因为只有一个计算资源。</p><h1 id="1526" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">执行模式:客户端、集群或本地</h1><p id="078f" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">执行模式使您能够在运行应用程序时确定上述资源(如驱动程序和执行器)的物理位置。</p><p id="0d23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您有三种模式可供选择:</p><ol class=""><li id="c27c" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ll kz la lb bi translated">集群模式。</li><li id="e01d" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ll kz la lb bi translated">客户端模式。</li><li id="575c" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ll kz la lb bi translated">本地模式。</li></ol><p id="858f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">集群模式</strong>可能是运行Spark应用程序最常见的方式。在集群模式下，用户向集群管理器提交预编译的代码。然后，除了执行器进程之外，集群管理器还在集群内部的一个工作节点上启动驱动程序进程。这意味着集群管理器负责管理所有与Spark应用程序相关的进程。</p><p id="3423" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">客户端模式</strong>与集群模式几乎相同，除了Spark驱动程序保留在提交应用程序的客户端机器上。这意味着客户机负责维护Spark驱动程序进程，而集群管理器维护执行器进程。我们运行Spark应用程序的机器不在集群上，通常被称为网关机器或边缘节点。</p><p id="c8fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">本地模式</strong>可以被认为是在你的电脑上运行一个程序，你告诉spark在同一个JVM中运行驱动程序和执行程序。</p><h1 id="9109" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">RDD、数据框和数据集</h1><p id="4027" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">Spark提供的主要抽象是一个<strong class="ih hj">弹性分布式数据集</strong> (RDD)，这是一个跨集群节点划分的元素集合，可以并行操作。rdd是通过从Hadoop文件系统(或任何其他Hadoop支持的文件系统)中的一个文件，或驱动程序中的一个现有Scala集合开始，并转换它而创建的。</p><p id="9f6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在单个RDD应该被多次使用的情况下，用户可以请求spark持久化一个RDD，有多个持久化级别，这将指示Spark应用程序保存RDD并允许有效使用。最后，rdd会自动从节点故障中恢复。</p><p id="0bdb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个<strong class="ih hj"> <em class="kn"> Dataframe </em> </strong>是最常见的结构化API，简单地表示一个包含行和列的数据表。这些列和它们的数据类型组合起来就形成了数据帧的模式。您可以将<em class="kn">数据框架</em>想象成一个带有命名列的电子表格。</p><p id="b897" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管有一个基本的区别:一个电子表格驻留在一台计算机的一个特定位置，而一个Spark <em class="kn">数据帧</em>可以跨越数千台计算机。将一个文件放在多个节点上可能有各种原因:数据太大，一台机器无法容纳，或者在一台机器上执行计算需要太长时间。</p><p id="8b83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从Spark 2.0开始，<strong class="ih hj"> <em class="kn">数据集</em> </strong>具有两种截然不同的API特征:强类型API和非类型API。从概念上讲，将<em class="kn"> Dataframe </em>视为通用对象数据集[Row]集合的别名，其中一行是通用的非类型化JVM对象。相比之下，数据集是强类型JVM对象的集合，由您在Scala中定义的case类或Java中的类决定。</p><h1 id="6e35" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">共享变量</h1><p id="febe" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">Spark中的第二个抽象是<strong class="ih hj">共享变量</strong>，在并行操作期间，这些变量可以在所有参与节点之间使用。尽管通常情况下，Spark会提供任务执行其功能所需的变量的副本。然而，有时候，一个变量需要跨任务共享，或者在任务和驱动程序之间共享。Spark支持两种类型的共享变量:</p><ol class=""><li id="c263" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ll kz la lb bi translated"><strong class="ih hj">广播变量</strong>，可用于在所有节点的内存中缓存一个值。</li><li id="0416" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ll kz la lb bi translated"><strong class="ih hj">累加器</strong>，是只“相加”的变量，如计数器和总和。</li></ol><h1 id="8ac9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">火花会议</h1><p id="6620" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">任何Spark应用程序的第一步都是创建一个<code class="du lh li lj lk b">SparkSession</code>。一些遗留代码可能会使用新的<code class="du lh li lj lk b">SparkContext</code>模式。鉴于可能有多个库试图在同一个Spark应用程序中创建一个会话，应该使用<code class="du lh li lj lk b">SparkSession</code>上的builder方法来避免这种情况，它更健壮地实例化Spark和SQL上下文，并确保没有上下文冲突:</p><p id="4493" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有了<code class="du lh li lj lk b">SparkSession</code>之后，你应该可以运行你的Spark代码了。从<code class="du lh li lj lk b">SparkSession</code>中，您也可以相应地访问所有低级和遗留的上下文和配置。</p><p id="d324" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意</strong>:只有在Spark 2.X中添加了<code class="du lh li lj lk b">SparkSession</code>类。您可能会发现更老的代码会直接为结构化API创建一个<code class="du lh li lj lk b">SparkContext</code>和一个<code class="du lh li lj lk b">SQLContext</code>。</p><p id="3aa9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du lh li lj lk b">SparkSession</code>中的<code class="du lh li lj lk b">SparkContext</code>对象表示与火花簇的连接。这个类是您与Spark的一些低级API(如rdd)通信的方式。通过一个<code class="du lh li lj lk b">SparkContext</code>，您可以创建rdd、累加器和广播变量，并且可以在集群上运行代码。如果你想初始化<code class="du lh li lj lk b">SparkContext</code>，你应该以最普通的方式创建它，通过<code class="du lh li lj lk b">getOrCreate</code>方法:</p><h1 id="3b94" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">懒惰评估</h1><p id="8684" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><strong class="ih hj">懒求值</strong>表示Spark会等到最后一刻才执行计算指令图。在Spark中，不是在表达某个操作时立即修改数据，而是构建一个希望应用于源数据的转换计划。</p><p id="c095" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过等到最后一分钟才执行代码，Spark将这个计划从原始数据帧转换编译成一个精简的物理计划，该计划将在集群中尽可能高效地运行。这提供了巨大的好处，因为Spark可以端到端地优化整个数据流。这方面的一个例子是数据帧上的谓词下推。</p><p id="311d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们构建了一个大的Spark作业，但是在最后指定了一个过滤器，只要求我们从源数据中获取一行，那么最有效的执行方式就是访问我们需要的单个记录。Spark将通过自动按下过滤器来为我们优化这一点。</p><h1 id="a2c1" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">行动和转变</h1><p id="812c" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><strong class="ih hj">转换</strong>允许我们建立逻辑转换计划。为了触发计算，我们运行一个动作。一个动作指示Spark计算一系列变换的结果。最简单的操作是count，它给出DataFrame中记录的总数:divisBy2.count()前面代码的输出应该是500。</p><p id="9b30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当然，计数不是唯一的动作。有三种操作:在控制台中查看数据的操作将数据收集到相应语言的本机对象的操作写入输出数据源的操作在指定此操作时，我们启动了一个Spark作业，它运行我们的过滤转换(窄转换)，然后是一个聚合(宽转换)，它在每个分区的基础上执行计数，然后是一个收集，它将我们的结果带到相应语言的本机对象。</p><p id="56cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以通过查看Spark UI来了解所有这些，Spark UI是Spark中包含的一个工具，您可以使用它来监视集群上运行的Spark作业。</p><p id="5e4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Spark中，核心数据结构是不可变的，这意味着它们在创建后不能更改。乍一看，这似乎是一个奇怪的概念:如果你不能改变它，你应该如何使用它？要“改变”一个数据帧，您需要指示Spark您希望如何修改它以达到您的目的。这些指令被称为转换。</p><p id="0e38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">转换是使用Spark表达业务逻辑的核心。有两种类型的转换:指定窄依赖关系的转换和指定宽依赖关系的转换。由窄依赖关系组成的转换(我们称之为窄转换)是指每个输入分区只贡献给一个输出分区的转换。在前面的代码片段中，where语句指定了一个<strong class="ih hj">窄依赖项，其中只有一个分区贡献至多一个输出分区</strong>。</p><p id="e1d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">宽依赖(或宽转换)风格的转换将使输入分区贡献给许多输出分区</strong>。您经常会听到这被称为洗牌，Spark将在集群中交换分区。对于窄转换，Spark将自动执行一个称为流水线的操作，这意味着如果我们在<em class="kn">数据帧</em>上指定多个过滤器，它们都将在内存中执行。洗牌就不一样了。当我们执行洗牌时，Spark将结果写入磁盘。</p><h1 id="c23b" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">阶段和任务</h1><p id="06de" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">Spark中的<strong class="ih hj">阶段</strong>表示可以在多台机器上一起执行以计算相同操作的任务组。一般来说，Spark会尝试将尽可能多的工作(即，在您的作业中尽可能多的转换)打包到同一个阶段中，但是引擎会在称为shuffles的操作之后开始新的阶段。</p><p id="257f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">shuffle表示数据的物理重新分区，例如，对数据帧进行排序，或者按键对从文件加载的数据进行分组(这需要将具有相同键的记录发送到相同的节点)。这种类型的重新分区需要跨执行器协调来移动数据。Spark在每次洗牌后开始一个新的阶段，并跟踪这些阶段必须以什么顺序运行来计算最终结果。</p><p id="ee6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark中的阶段由<strong class="ih hj">任务</strong>组成。每个任务对应于数据块的组合和一组将在单个执行器上运行的转换。如果我们的数据集中有一个大分区，我们将有一个任务。如果有1000个小分区，我们将有1000个可以并行执行的任务。任务只是应用于一个数据单元(分区)的一个计算单元。将数据划分成更多的分区意味着可以并行执行更多的数据。</p><h1 id="b6d7" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">有向无环图</h1><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es lm"><img src="../Images/3af0ca6bd2b62b920125d3b2c936511c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NfxCBeAGWl0xTodE.jpg"/></div></div></figure><p id="fa48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kn">有向无环图</em></p><p id="1b32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Apache Spark中的DAG是一组顶点和边，其中顶点表示RDD，边表示要应用于RDD的操作。在Spark DAG中，每个边在序列中从前面指向后面。</p><h1 id="6d32" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">资源管理器:独立或纱线或MESOS</h1><p id="8700" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">Spark用来执行任务的机器集群由一个集群管理器管理，比如Spark的独立集群管理器、YARN或Mesos。然后，我们向这些集群管理器提交Spark应用程序，集群管理器将向我们的应用程序授予资源，以便我们能够完成我们的工作。</p></div></div>    
</body>
</html>