<html>
<head>
<title>Image Classification Model in PyTorch and TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch和TensorFlow中的图像分类模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-classification-model-in-pytorch-and-tensorflow-25259cde8830?source=collection_archive---------17-----------------------#2020-07-23">https://medium.com/analytics-vidhya/image-classification-model-in-pytorch-and-tensorflow-25259cde8830?source=collection_archive---------17-----------------------#2020-07-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/de3bbd752799d93b2c5303060217a8dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NOQh2ORKauDfIAxhM0GZDA.jpeg"/></div></div></figure><h1 id="eaa0" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">理解问题陈述:MNIST</h1><p id="3304" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在我们开始之前，让我们了解一下数据集。在这篇文章中，我们将解决流行的MNIST问题。这是一项数字识别任务，其中我们必须将手写数字图像分为0到9这10类中的任何一类。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es km"><img src="../Images/9b1894c783f08855653f1d1208570152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*Mw20mFOOjS0fE1j2Tiz02A.jpeg"/></div></figure><p id="d448" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">在MNIST数据集中，我们有从各种扫描文档中获取的数字图像，这些图像的大小经过标准化，并且居中。随后，每个图像是一个28×28像素的正方形(总共784个像素)。数据集的标准分割用于评估和比较模型，其中60，000幅图像用于训练模型，而另一组10，000幅图像用于测试模型。</p><p id="53a7" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">这是CNN py torch和TensorFlow的初学者指南</p><h1 id="ef48" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">在PyTorch中实现CNN</h1><p id="3876" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">让我们首先从导入所有库开始:</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="8586" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># importing the libraries</em><br/><br/>import numpy as np<br/>import pandas as pd<br/>import torch<br/>import torchvision<br/>import matplotlib.pyplot as plt<br/>from time import time<br/>from torchvision import datasets, transforms<br/>from torch import nn, optim</span></pre><p id="8355" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">我们将对图像执行一些转换，比如归一化像素值，所以，让我们也定义这些转换</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="1838" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># transformations to be applied on images</em><br/><br/>transform = transforms.Compose([transforms.ToTensor(),<br/>                              transforms.Normalize((0.5,), (0.5,)),<br/>                              ])</span></pre><p id="9dae" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">现在，让我们加载MNIST数据集的训练集和测试集</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="1135" class="lb ir hi kx b fi lc ld l le lf">trainset = datasets.MNIST('./data', download=True, train=True, transform=transform)<br/>testset = datasets.MNIST('./', download=True, train=False, transform=transform)</span></pre><p id="046d" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">接下来，我定义了训练和测试加载器，它将帮助我们批量加载训练和测试集。我将把批量定义为64</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="1bd9" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># defining trainloader and testloader</em><br/>trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)<br/>testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)</span></pre><p id="bf73" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">我们先来看看训练集的概要</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="3fdf" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># shape of training data</em><br/>dataiter = iter(trainloader)<br/>images, labels = dataiter.next()<br/><br/>print(images.shape)<br/>print(labels.shape)</span></pre><p id="a4f1" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">输出</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="4b1f" class="lb ir hi kx b fi lc ld l le lf">torch.Size([64, 1, 28, 28])<br/>torch.Size([64])</span></pre><p id="f928" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">所以，在每一批中，我们有64张图片，每张图片的尺寸都是28，28，对于每一张图片，我们都有一个相应的标签。让我们想象一个训练图像，看看它是什么样子</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="f3cd" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># visualizing the training images</em><br/>plt.imshow(images[0].numpy().squeeze(), cmap='gray')</span></pre><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/d54d4bc4f4508b85a1a481724d3dfa58.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*0trRPA_BwNa1MfKUak9RsQ.png"/></div></figure><p id="dc8f" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">这是1号的图像。类似地，让我们可视化测试集图像</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="2882" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># shape of validation data</em><br/>dataiter = iter(testloader)<br/>images, labels = dataiter.next()<br/><br/>print(images.shape)<br/>print(labels.shape)</span></pre><p id="b285" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">输出</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="b402" class="lb ir hi kx b fi lc ld l le lf">torch.Size([64, 1, 28, 28])<br/>torch.Size([64])</span></pre><p id="eec1" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">在测试集中，我们也有64号的批次。现在让我们来定义架构</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="103f" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># defining the model architecture</em><br/>class <strong class="kx hj">Net</strong>(nn.Module):   <br/>  def __init__(self):<br/>      super(Net, self).__init__()<br/><br/>      self.cnn_layers = nn.Sequential(<br/>          <em class="lg"># Defining a 2D convolution layer</em><br/>          nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),<br/>          nn.BatchNorm2d(4),<br/>          nn.ReLU(inplace=True),<br/>          nn.MaxPool2d(kernel_size=2, stride=2),<br/>          <em class="lg"># Defining another 2D convolution layer</em><br/>          nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),<br/>          nn.BatchNorm2d(4),<br/>          nn.ReLU(inplace=True),<br/>          nn.MaxPool2d(kernel_size=2, stride=2),<br/>      )<br/><br/>      self.linear_layers = nn.Sequential(<br/>          nn.Linear(4 * 7 * 7, 10)<br/>      )<br/><br/>  <em class="lg"># Defining the forward pass    </em><br/>  def forward(self, x):<br/>      x = self.cnn_layers(x)<br/>      x = x.view(x.size(0), -1)<br/>      x = self.linear_layers(x)<br/>      return x</span></pre><p id="9f77" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">让我们也定义优化器和损失函数，然后我们将查看此模型的摘要</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="6980" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># defining the model</em><br/>model = Net()<br/><em class="lg"># defining the optimizer</em><br/>optimizer = optim.Adam(model.parameters(), lr=0.01)<br/><em class="lg"># defining the loss function</em><br/>criterion = nn.CrossEntropyLoss()<br/><em class="lg"># checking if GPU is available</em><br/>if torch.cuda.is_available():<br/>    model = model.cuda()<br/>    criterion = criterion.cuda()<br/>    <br/>print(model)</span></pre><p id="f3d4" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">现在我们的模型架构已经准备好了，让我们为这个模型训练10个时期</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="fb1d" class="lb ir hi kx b fi lc ld l le lf">for i <strong class="kx hj">in</strong> range(10):<br/>    running_loss = 0<br/>    for images, labels <strong class="kx hj">in</strong> trainloader:<br/><br/>        if torch.cuda.is_available():<br/>          images = images.cuda()<br/>          labels = labels.cuda()<br/><br/>        <em class="lg"># Training pass</em><br/>        optimizer.zero_grad()<br/>        <br/>        output = model(images)<br/>        loss = criterion(output, labels)<br/>        <br/>        <em class="lg">#This is where the model learns by backpropagating</em><br/>        loss.backward()<br/>        <br/>        <em class="lg">#And optimizes its weights here</em><br/>        optimizer.step()<br/>        <br/>        running_loss += loss.item()<br/>    else:<br/>        print("Epoch <strong class="kx hj">{}</strong> - Training loss: <strong class="kx hj">{}</strong>".format(i+1, running_loss/len(trainloader)))</span></pre><p id="5f15" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">输出</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="2612" class="lb ir hi kx b fi lc ld l le lf">Epoch 1 - Training loss: 0.18498120927162517<br/>Epoch 2 - Training loss: 0.09083321380383297<br/>Epoch 3 - Training loss: 0.08189530037383218<br/>Epoch 4 - Training loss: 0.07542595624832361<br/>Epoch 5 - Training loss: 0.07169675431065341<br/>Epoch 6 - Training loss: 0.06836385150025012<br/>Epoch 7 - Training loss: 0.06608668564340231<br/>Epoch 8 - Training loss: 0.0635401263072499<br/>Epoch 9 - Training loss: 0.06184220796615791<br/>Epoch 10 - Training loss: 0.06065309989843955</span></pre><p id="ab6d" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">您可以看到，训练随着时代数量的增加而减少。这意味着我们的模型正在从训练集中学习模式。让我们在测试集上检查这个模型的性能</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="32b3" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># getting predictions on test set and measuring the performance</em><br/>correct_count, all_count = 0, 0<br/>for images,labels <strong class="kx hj">in</strong> testloader:<br/>  for i <strong class="kx hj">in</strong> range(len(labels)):<br/>    if torch.cuda.is_available():<br/>        images = images.cuda()<br/>        labels = labels.cuda()<br/>    img = images[i].view(1, 1, 28, 28)<br/>    with torch.no_grad():<br/>        logps = model(img)<br/><br/>    <br/>    ps = torch.exp(logps)<br/>    probab = list(ps.cpu()[0])<br/>    pred_label = probab.index(max(probab))<br/>    true_label = labels.cpu()[i]<br/>    if(true_label == pred_label):<br/>      correct_count += 1<br/>    all_count += 1<br/><br/>print("Number Of Images Tested =", all_count)<br/>print("<strong class="kx hj">\n</strong>Model Accuracy =", (correct_count/all_count))</span></pre><p id="7825" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">输出</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="f438" class="lb ir hi kx b fi lc ld l le lf">Number Of Images Tested = 10000<br/><br/>Model Accuracy = 0.9728</span></pre><p id="84de" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">因此，我们总共测试了10000张图像，该模型在预测测试图像的标签方面的准确率约为90%。这就是如何在PyTorch中构建卷积神经网络。在下一节中，我们将研究如何在TensorFlow中实现相同的架构。</p><h1 id="a14b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">在TensorFlow中实现CNN</h1><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="c8a6" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># importing the libraries</em><br/>import tensorflow as tf<br/><br/>from tensorflow.keras import datasets, layers, models<br/>from tensorflow.keras.utils import to_categorical<br/>import matplotlib.pyplot as plt</span></pre><p id="9fd1" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">现在，让我们使用tensorflow.keras的数据集类加载MNIST数据集</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="00d0" class="lb ir hi kx b fi lc ld l le lf">(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data(path='mnist.npz')<br/><em class="lg"># Normalize pixel values to be between 0 and 1</em><br/>train_images, test_images = train_images / 255.0, test_images / 255.0</span></pre><p id="062d" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">这里，我们已经加载了MNIST数据集的训练集和测试集。此外，我们已经对训练图像和测试图像的像素值进行了归一化。接下来，让我们可视化数据集中的一些图像</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="9919" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># visualizing a few images</em><br/>plt.figure(figsize=(10,10))<br/>for i <strong class="kx hj">in</strong> range(9):<br/>    plt.subplot(3,3,i+1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(train_images[i], cmap='gray')<br/>plt.show()</span></pre><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es li"><img src="../Images/bde7766140869c38f8b70ca097b9145c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*7oD8SMNqC4ec3p7fJnKq1w.png"/></div></figure><p id="dd00" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">随后，这就是我们的数据集的样子。我们有手写数字的图像。让我们看看训练集和测试集的形状</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="b6c1" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># shape of the training and test set</em><br/>(train_images.shape, train_labels.shape), (test_images.shape, test_labels.shape)</span></pre><p id="e93e" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">输出</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="3684" class="lb ir hi kx b fi lc ld l le lf">(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))</span></pre><p id="3f7a" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">因此，我们在训练集中有60，000张28×28形状的图像，在测试集中有10，000张相同形状的图像。接下来，我们将调整图像的形状，并对目标变量进行一次性编码</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="8e0f" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># reshaping the images</em><br/>train_images = train_images.reshape((60000, 28, 28, 1))<br/>test_images = test_images.reshape((10000, 28, 28, 1))<br/><br/><em class="lg"># one hot encoding the target variable</em><br/>train_labels = to_categorical(train_labels)<br/>test_labels = to_categorical(test_labels)</span></pre><h1 id="7b06" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">定义模型架构</h1><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="a088" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># defining the model architecture</em><br/>model = models.Sequential()<br/>model.add(layers.Conv2D(4, (3, 3), activation='relu', input_shape=(28, 28, 1)))<br/>model.add(layers.MaxPooling2D((2, 2), strides=2))<br/>model.add(layers.Conv2D(4, (3, 3), activation='relu'))<br/>model.add(layers.MaxPooling2D((2, 2), strides=2))<br/>model.add(layers.Flatten())<br/>model.add(layers.Dense(10, activation='softmax'))</span></pre><p id="e001" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">让我们快速地看一下模型的概要</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="850a" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># summary of the model</em><br/>model.summary()</span></pre><p id="060d" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">输出</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="2611" class="lb ir hi kx b fi lc ld l le lf">Model: "sequential"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d (Conv2D)              (None, 26, 26, 4)         40        <br/>_________________________________________________________________<br/>max_pooling2d (MaxPooling2D) (None, 13, 13, 4)         0         <br/>_________________________________________________________________<br/>conv2d_1 (Conv2D)            (None, 11, 11, 4)         148       <br/>_________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2 (None, 5, 5, 4)           0         <br/>_________________________________________________________________<br/>flatten (Flatten)            (None, 100)               0         <br/>_________________________________________________________________<br/>dense (Dense)                (None, 10)                1010      <br/>=================================================================<br/>Total params: 1,198<br/>Trainable params: 1,198<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="24cc" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">总而言之，我们有两个卷积层，两个最大池层，一个平坦层和一个密集层。模型中的参数总数为1，198。现在我们的模型已经准备好了，我们将编译它</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="ce37" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># compiling the model</em><br/>model.compile(optimizer='adam',<br/>              loss='categorical_crossentropy',<br/>              metrics=['accuracy'])</span></pre><p id="56de" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">我们正在使用亚当优化，你也可以改变它。损失函数被设置为分类交叉熵，因为我们正在解决多类分类问题，并且度量是准确度。现在让我们为我们的模型训练10个纪元</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="ba77" class="lb ir hi kx b fi lc ld l le lf"><em class="lg"># training the model</em><br/>history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))</span></pre><p id="e9c6" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">输出:</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="12b1" class="lb ir hi kx b fi lc ld l le lf">Epoch 1/10<br/>1875/1875 [==============================] - 6s 3ms/step - loss: 0.4720 - accuracy: 0.8541 - val_loss: 0.2096 - val_accuracy: 0.9374<br/>Epoch 2/10<br/>1875/1875 [==============================] - 6s 3ms/step - loss: 0.2005 - accuracy: 0.9408 - val_loss: 0.1615 - val_accuracy: 0.9505<br/>Epoch 3/10<br/>1875/1875 [==============================] - 5s 3ms/step - loss: 0.1636 - accuracy: 0.9514 - val_loss: 0.1416 - val_accuracy: 0.9560<br/>Epoch 4/10<br/>1875/1875 [==============================] - 5s 3ms/step - loss: 0.1456 - accuracy: 0.9566 - val_loss: 0.1233 - val_accuracy: 0.9631<br/>Epoch 5/10<br/>1875/1875 [==============================] - 5s 3ms/step - loss: 0.1323 - accuracy: 0.9603 - val_loss: 0.1155 - val_accuracy: 0.9648<br/>Epoch 6/10<br/>1875/1875 [==============================] - 6s 3ms/step - loss: 0.1224 - accuracy: 0.9633 - val_loss: 0.1082 - val_accuracy: 0.9660<br/>Epoch 7/10<br/>1875/1875 [==============================] - 6s 3ms/step - loss: 0.1142 - accuracy: 0.9655 - val_loss: 0.1063 - val_accuracy: 0.9667<br/>Epoch 8/10<br/>1875/1875 [==============================] - 5s 3ms/step - loss: 0.1075 - accuracy: 0.9682 - val_loss: 0.0977 - val_accuracy: 0.9680<br/>Epoch 9/10<br/>1875/1875 [==============================] - 6s 3ms/step - loss: 0.1020 - accuracy: 0.9696 - val_loss: 0.0970 - val_accuracy: 0.9697<br/>Epoch 10/10<br/>1875/1875 [==============================] - 6s 3ms/step - loss: 0.0967 - accuracy: 0.9716 - val_loss: 0.0921 - val_accuracy: 0.9698</span></pre><p id="981c" class="pw-post-body-paragraph jo jp hi jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">训练损失约为0.46，10个周期后，训练损失减少到0.08。10个周期后的训练和验证准确率分别为97.31%和97.48%。谢谢你的宝贵时间。希望这有用。</p><div class="lj lk ez fb ll lm"><a href="https://www.kaggle.com/c/digit-recognizer" rel="noopener  ugc nofollow" target="_blank"><div class="ln ab dw"><div class="lo ab lp cl cj lq"><h2 class="bd hj fi z dy lr ea eb ls ed ef hh bi translated">数字识别器</h2><div class="lt l"><h3 class="bd b fi z dy lr ea eb ls ed ef dx translated">用著名的MNIST数据学习计算机视觉基础</h3></div><div class="lu l"><p class="bd b fp z dy lr ea eb ls ed ef dx translated">www.kaggle.com</p></div></div><div class="lv l"><div class="lw l lx ly lz lv ma io lm"/></div></div></a></div></div></div>    
</body>
</html>