# Caption-IT:图像到序列深度学习模型:开发到部署！

> 原文：<https://medium.com/analytics-vidhya/caption-it-image-to-sequence-deep-learning-model-development-to-deployment-7f9f04ab5fa0?source=collection_archive---------15----------------------->

—今天我们将研究深度学习的另一个有趣领域，称为序列到序列模型，具体来说就是图像到序列。

![](img/d8cc6d646eafcd71f0a4cd9d5147d6c5.png)

来源:谷歌图片

## 免责声明:这将是一个完整的端到端的项目教程，这将是相当漫长的。所以，既然提到了，那就继续吧。

有没有想过谷歌如何为你在谷歌图片搜索中提供的关键词找到一张完美的图片？

谷歌将我们所谓的相关标题以图片关键词的形式存储为一个知识库，每当你搜索特定关键词时，它就会检索出最佳匹配。

那么，它是如何为整个谷歌资料库中的这么多图片生成标题的呢？被人类？通过机器？靠软件？

众所周知，谷歌一直拥有最前沿的人工智能应用，其中一个应用就是我们所说的图像字幕生成器，它将图像作为输入，试图理解图像的上下文，并以文本的形式生成最佳结果，当然，文本描述了图像。

今天，我们将尝试实现这一点，将努力保持简单、优雅和易于理解，当然，它不会像谷歌的模型那样高效，但也不会愚蠢。

在进入它的本质之前，我想让你看看研究论文，“[展示和讲述:一个神经图像字幕生成器](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwi8__3L5uPrAhWb63MBHYB4AukQFjAIegQIAxAB&url=http%3A%2F%2Fresearch.google.com%2Fpubs%2Farchive%2F43274.pdf&usg=AOvVaw0AcJYN5K_UdnOECW9E6bnO)”，这是我们引用的地方，也可能是谷歌在它发布时引用的地方。

## 让我们深入研究一下:

现在，在我开始解释之前，我想先做一些澄清，因为我将从头开始解释一切，我们将一起构建一个模型，训练它，甚至部署它。是的，你没看错，我们将部署这种型号。我们做了一些假设，这将有助于我们保持这篇博客的可读性。以下是一些假设:

1.  你知道 Python 的基础知识，因为会涉及到很多代码。
2.  你知道深度学习模型的基础，以及它们如何运作，因为解释这两个概念本身就是一个巨大的领域。

好了，现在我们已经完成了先决条件，让我们继续核心概念。

对于任何 ML 或 DL 模型，主要成分是数据，所以让我们首先了解我们有什么数据，以及我们从哪里得到这些数据。

这里的数据可以公开获得[](https://www.kaggle.com/shadabhussain/flickr8k)****。****

**这是 Flicker 8k 数据集，由 8091 幅图像和每幅图像的 5 个标题组成，总共大约有 40K 个标题。**

**图像在里面。jpg 格式，尺寸大约为 500x600 像素，每个图像的尺寸都不相同，标题在 excel 文件中用图像的文件名表示，因此我们可以将图像映射到标题。**

**现在，让我们看一个这样的例子。**

**![](img/76997693b6ec3583b235dee29a9e36ff.png)**

**图像**

**标题:**

1.  **一只狗正在草地上跳跃**
2.  **一只狗在空中**
3.  **在草地上玩耍的狗**
4.  **狗跳**
5.  **白天拍照时，狗在草坪上跳跃**

**因此，正如我们所看到的，一幅图像有 5 个相关的标题，将用于训练。**

# **数据分析:**

**让我们做一些数据分析。成功地将数据转换成数据帧后，它看起来像这样:**

**![](img/7859696cfac913b89a8f3fc7b03d0d7e.png)**

**熊猫数据框**

**如你所见，文件名是重复的，我们有 5 个独特的标题。**

**现在，让我们检查一些统计数据…**

**让我们检查一下数据帧中唯一图像的总数。**

**![](img/0fea2e7f9f1aefb9101095d70e3bdcf8.png)**

**检查图像目录中的文件数量，以确保我们没有数据不匹配。**

**![](img/cbdd844113afde382aa47ba4fb73d4fb.png)**

**我们发现一个包含“.”的唯一文件名这可能会在训练中造成问题。当我手动检查时，图像目录中不存在这样的文件名。我们可以把它从数据框中删除。**

**![](img/2e5baa64c65c40a13e97f830e1375bfd.png)**

**这就是我们在系统中看到的物理图像文件，现在让我们继续进行数据预处理。**

# **数据预处理:**

**我们将首先把我们的文本数据从原始格式处理成干净的标准化格式，为此我们将写下一个函数，并把我们所有的标题传递给它，所以让我们看看这个函数:**

**![](img/b2f4c7addcdb0e98fb6d64c3d322ff20.png)**

**正如我们所看到的，我使用了正则表达式来转换模式和替换一些字符。**

**现在我们将标题传递给这个函数。我们遍历数据帧，并将单独的标题传递给上面的函数。**

**![](img/fbd2deaf9207c1edf26a0c548987052a.png)**

**我们来看看预处理后的字幕。**

**![](img/5bc290153cdfd913a8862e8188f8cdc6.png)**

## ****对文本数据进行矢量化:****

**现在，要将单词转换为记号，我们可以使用 Python 中现有的强大函数，它可以一次处理多件事情，即 CountVectorizer，**

**1.analyzer='word '，确保考虑单个单词进行标记化**

**2.min_df=10，确保只考虑出现次数超过 10 次的单词**

**![](img/329a1b991d8cedbecc5095952b30a036.png)**

**从矢量器中以单词的形式获取功能名称，并将其存储在索引映射字典中，这将在本模块的后面使用，我们将数字作为矢量器中每个单词的索引，并将其存储为 Index_to_Word 映射以及反向的 Word_to_Index 映射。**

**![](img/4056b750ca02903efc7bfbddf5d8dce3.png)**

**我们在字典中添加了 4 个额外的标记，它们是“a”，“startSeq”，“endSeq”和“【T2”)，它们的意义将在本博客稍后解释。**

**我们将单词索引映射反转为索引单词映射。感谢 python 的强大功能，这只是一行代码。我们需要这个作为将来的参考。**

**![](img/7307b9a77b0a5316cf6c971e1c4e4c29.png)**

**vocab 的大小保持为字典的长度+1，因为第 0 个索引实际上不是一个单词，但它是填充标记，因此 vocab 的大小总是单词的总数，在我们的例子中是 len(word_index_mapping) + 1**

**现在，让我们检查 dict 值的完整性，首先取任意一个单词，将其作为键传递给 word_index_mapping，并获取其对应的索引值。然后将它作为键传递给 index_word_mapping，如果两个单词(您作为键传递的和打印的)相同，那么它就是完美的。**

**![](img/a4036419c493d3543a37e7a6c70c8a54.png)**

**所以，在这里我们已经成功地将我们的单词转换为索引，反之亦然，这表明我们可以进一步前进。**

# **培训数据准备:**

**所以，我们总共有大约 8091 张图片。我们将 7091 幅图像作为训练数据，剩余的将用于评估模型。**

**我们通过将第一批 7091 幅图像作为训练图像来实现这一点，然后采用一组差值来分离出其余的图像。**

**![](img/85c4a4a9cffc6e0d1ccf0bdc9ae5b7e4.png)**

**现在将数据帧分为测试和训练。**

**![](img/adb8e818d51f1cc32811e9dc1ead1cf4.png)**

**现在，我们必须在每个标题的开头和结尾分别添加一个开始标记“startSeq”和一个结束标记“endSeq ”,以便让我们的模型了解标题在哪里开始，在哪里结束。基本上用作起点和终点。**

**![](img/31057dd7bcd557cffa51189ec642b81f.png)**

**现在让我们预览一下我们的字幕:**

**![](img/3b78321b6fc1b9389a77d4585f482c9e.png)**

**好的，它们看起来不错…**

**现在，我们必须得到标题的最大长度，这样做是因为我们想确保我们输入的句子长度相同。所以我们要做的是，取最大标题的长度，通过填充直到最大长度，使所有的句子长度相等。让我们看看如何实现它…**

**![](img/1c15a0a6a3e602ad8a141cce8bb404e9.png)**

**这就是我们如何从标题列表中获得最大长度，这里的最大长度是 39，这意味着我们有一个 39 个单词长的标题。**

**让我们先对标题进行矢量化处理。我们将嵌入那些出现在 word_index_Mapping 中的单词，因为 glove 文件中总共有 400，000 个单词，而我们只有 1955 个单词。所以我们只需要 1955 个向量形式的单词。这就是我们实现它的方式。**

**![](img/0eda58aaf681a257e2e7ea3cc3ee912c.png)****![](img/8bef48cfb6dfac0cc02244f5d0712328.png)**

**之所以是 1952 年而不是 1955 年，是因为我们自己包含了 3 个额外的标记，比如 startSeq、endSeq 和<pad>，它们实际上并不是单词。</pad>**

**我们将创建一个矩阵作为权重，以便在我们的模型中用于训练。**

**![](img/93393e4b5591e1402b99a3d525a8b7f2.png)**

**这就是我们对文本数据的所有处理，现在让我们看看我们的图像数据。**

# **处理图像数据:**

**使用 cv2 lib 检查图像的加载函数**

**由于 cv2.imshow()方法在 Google Colab 中是不允许的，因为它会使 jupyter 会话崩溃，所以我们使用 Google 自己的 cv2_imshow()**

**![](img/4ee3940497b64c4d00c130ee04092819.png)**

**现在，我们将使用名为 InceptionV3 的深度学习模型和预训练的“ImageNet”权重，将我们的图像转换为矢量。这将有助于我们利用开发 InceptionV3 并在 ImageNet 数据集上训练它的人们的辛勤工作。**

**为此，我们需要从 keras 下载 InceptionV3 模型，并加载“ImageNet”权重，我们必须删除模型的最后 2 层，因为它们是完全连接的分类层，因此我们不需要它。我们将使用的是由模型的最后第三层生成的矢量。**

**![](img/cb49975542b4d9aa77db14d20159a37d.png)**

**下一个任务是转换这些图像，然后将矢量化格式存储在 pickle 文件中，以便我们可以直接使用它进行训练，我们为什么要这样做？一旦我们研究了训练过程，这个问题就能得到解答，所以在那之前要有耐心，并坚持到底…**

**![](img/f7582271068fcab145deb4ab13bc3545.png)**

**让我们看看每一行的含义，这里我们只是检查我们是否已经创建了文件，如果没有，那么我们将创建文件并使用 pickle 存储它，否则如果文件已经创建，那么我们将使用 pickle.load()加载它。**

**因此，在我们将图像传递给 InceptionV3 模型之前，我们需要确保进行一些预处理，这正是我们正在做的事情:**

**第一步:阅读文件**

**步骤 2:将图像文件从 BGR 转换成 RGB**

**步骤 3:将图像的尺寸调整到 299 x 299，因为盗梦空间模型接受这个尺寸的图像**

**步骤 4:扩大尺寸为图像创建一个额外的尺寸**

**步骤 5:使用 keras preprocess_input，我们将标准化图像，使每个像素的值范围从 0 到 1，以及更多这样的操作**

**步骤 6:最后，我们将图像传递给初始模型，并为该图像生成一个矢量文件，并将尺寸更改为 1 x vector.shape[1]**

**第 7 步:然后我们最终将生成的 Numpy 数组作为值存储在一个 dict 中，key 作为文件名。**

**测试数据也遵循同样的程序。**

**![](img/d676d5f61314088962f2b3a8b1a596b4.png)**

**这就是图像所需的所有预处理。**

**现在，我们可以继续模型架构了。**

# **图像到序列模型:**

****图像编码器:**我们的图像编码器模型是 Inception V3 的输出，因此我们将直接将数据传递给模型，并使用 Dropout，然后是密集层。这就是我们所需要的，因为所有困难的部分都被我们预先训练好的模型解决了。**

****文本编码器:**我们的文本编码器模型是一个简单的嵌入层+ Dropout + LSTM 层。**

****解码器:**我们的解码器模型将输入作为编码器的两个值，合并它们，并通过一个密集层，最后是一个 Softmax 层，并将输出返回给我们。**

**理解模型并不困难，但是理解它是如何被训练的才是困难的。对于这类模型来说，训练部分是一个复杂的领域，因为数据传递的方式与通常略有不同。**

**但不用担心，它也会被覆盖。现在让我们看看模型的架构。**

**![](img/3112eca0968d39553250deb4395e7d55.png)****![](img/c56a432fd17b4096e6a3f3f7120d5af4.png)****![](img/392f63e3fc150bfa96144571e8558d2d.png)**

**现在，我们将把嵌入层的权重设置为上面创建的手套向量矩阵，并将可训练参数设置为 False，因为我们不希望这些值在训练时更新。**

**![](img/7268a6eca19839ee7346c1701876b5c5.png)**

**现在，我们可以选择我们的优化器和损失函数，因为我们想要设置我们的模型进行训练。**

**![](img/68d0bc966c6643926bf4130da8c86c60.png)**

**我们选择 Adam 作为优化器，选择 categorical _ crossentropy 作为损失函数。为什么分类 _ 交叉熵？一会儿会解释的，请多包涵…**

**在设置我们的训练方法之前，让我们先准备好一些实用函数:**

**![](img/259ec11c742a7369bcbdbc3e727bf96a.png)**

**这两种负载损失和保存损失的方法将在我们的培训中用于保存和检索损失值，以便我们可以绘制和检查我们的模型如何执行。**

# **培训:**

**我们将在生成器函数的帮助下训练我们的模型，该函数将以我们需要的格式生成数据。正如我前面提到的，训练这样的模型有点棘手。让我们首先理解我们应该如何在我们的模型中传递数据。**

**让我们借助一个例子来理解:**

**![](img/456d4c46e7940005902457d74329e086.png)**

**[照片特征向量]**

**描述:白天狗在草坪上跳跃。**

**![](img/e25ee2e3cc34431a2fae814e54c63570.png)**

**让我们逐步了解数据是如何传递到模型中进行训练的。**

**步骤 1:我们传递整个照片特征，并将“startSeq”作为索引值传递给我们的模型，并根据照片特征和“startSeq”训练它将“dog”作为我们的输出单词**

**步骤 2:我们输入整个照片特征，这次我们将“startSeq”和先前生成的输出(即“dog ”)传递给模型。请记住，我们不输入实际的单词，我们传递单词的索引，因为机器只理解数字，然后训练它在传递照片功能和 2 个单词后，它应该生成下一个单词“跳跃”**

**同样，你可以看到我们是如何一个接一个地传递数据的。**

**让我们理解模型是如何生成输出的。我们的模型以分类值的形式生成输出，它为必须生成的单词赋予最高的概率，我们将输出作为索引。然后使用上面的 index_to_word 字典，我们可以从中获取单词。**

**现在，由于模型生成作为分类变量的输出，因此损失了“分类交叉熵”。**

**一旦我们从模型中获得了 endSeq 输出，我们就停止对该图像的训练，并更改我们的照片特征和标题对，然后生成相同的数据集，以传递到我们的模型中进行进一步训练。**

**这就是我们的模型被训练的方式。**

**现在，主要的事情是如何创建一个自生成函数，它将为我们提供这样的数据细分，或者这样的数据形式，可以传递给我们的模型进行训练。**

**![](img/029a4c96b88bd355bf83e02c37e9a88c.png)**

**这是在给定图像名称的情况下，为 1 个图像生成数据集的照片标题对的函数。**

**让我们来理解这个函数的内容，如果你理解了这个，那么你就理解了这个模块中的所有内容，因为这可能是博客中最难的部分。**

**既然我们已经理解了数据传递的直观方式，那么让我们来理解我们将如何编写一个函数来为一个单独的图像生成相同的格式。**

**我将文件名传递给函数，现在我需要做两件事:**

**1.该图像的照片特征，我们将从上面生成的字典中检索它。**

**2.与之相关联的标题，我们将从现有的数据帧中获取。**

**由于一张照片有 5 个标题，我们需要从这些图片标题对中创建单独的数据集。**

**现在，我们的“seq”变量以索引形式存储标题序列。**

**我们将在“seq”变量上运行一个循环，并从中生成输入和输出值。**

**循环的范围设置为从 1 到(len-1)**

**所以，**

**in_seq = seq[:1]即索引 0**

**out_seq = seq[1]，即索引 1**

**in_seq 被填充到最大 seq 长度，以便为我们拥有的所有输入保持相同的输入长度，这里我们使用 max_caption_length。**

**out_seq 现在被转换为分类变量，这样我们的模型就可以将其预测为一个类别。**

**我们一次考虑一个单词，创建一个序列，然后把它附加到一个叫做输入和输出的变量上。因此，我们为我们的训练创建数据集，这只是一个图像。我们仍然需要为我们的模型创建生成器函数。**

**让我们看看 train generator 函数，它将为我们要传递给它的图像数量生成数据模式。**

**![](img/01af8e56b0998ec079ba57a921603ef4.png)**

**现在，我们已经知道了 get_photo_caption_pair()方法，让我们来理解这个方法是做什么的。**

**我们传递训练所需的图像总数，假设我们传递 3 个，现在值“n”最初被设置为 0，这样我们可以将它用作计数器变量。有一个无限的 while 循环，其中有一个 for 循环，对数据集中的所有图像运行。我们从上面的方法中获得每张照片的数据模式，然后我们检查数字 n 是否等于我们的图像总数。如果是，那么我们产生输出，并将变量设置为初始值。为了完全理解这个方法，你可能实际上必须理解“yield”是做什么的，如果你已经理解了，那么你就已经理解了这个方法的功能。**

**现在，让我们看看我们的培训是如何进行的…**

**![](img/5c3be56be8f903db680895fc0b017ebd.png)**

**我们将首先设置模块的权重，如果有的话，否则将从头开始。**

**![](img/45a3a49fc2ba3f04c4a37107858beefa.png)**

**然后，我们最后设置用于我们的训练生成器的纪元值、步骤值和图像数量，最后使用 Adam 优化器训练我们的模型。**

**我们从 train_generator 函数创建一个生成器，然后将它传递给我们的模型，并获得那个时期的损失值。如果损失值小于我们之前的损失值，那么我们保存权重，否则不保存。**

**![](img/653316b2905e7364e981f56f2c1ea1a8.png)**

**这是培训的样子…**

**![](img/6ede203d02a75a212fe9b8ae2405946d.png)**

**这是我们的模型在训练时的损失值。**

**最后，培训结束后，我们现在可以进入模型的评估阶段。**

# **评估:**

**由于模型的训练有点棘手，评价也有点不同。既然你已经理解了训练的过程，理解预测是如何发生的就不难了。**

**让我们来理解这是如何发生的。**

**![](img/879b07e06055812b3c89ac6598bdd72e.png)**

**get_caption_for_photo 是所有奇迹发生的地方，因为我们已经将测试数据从训练数据中分离出来。我们要做的是给这个方法一个文件名，然后它从我们已经为训练数据设置的位置检索文件。**

**我们已经从 Inceptionv3 模型中转换了图片的照片特性，并使用 pickle 将其保存到一个 dict 文件中，因此我们将利用它来获得照片特性。**

**字幕的生成是一个字一个字地进行的，因此我们从 startSeq 作为输入开始，同时输入照片特性。**

**我们运行一个从 1 到 max_caption_length 的循环，因为我们知道任何标题都不应该大于它，所以我们创建与训练序列相同的数据序列，我们从“in_text”中获取单词的索引，并将其转换为向量，然后制作我们的数据序列。**

**然后我们将两个输入都传递给我们的模型(照片特征和文本)。它给我一个输出，作为 word 的索引，我们使用 dict index_to_word 将其转换为 word，然后将其附加到我们的 in_text 变量，在下一次迭代中，这两个单词成为我的文本序列，同样的过程再次发生，直到我们的模型输出 endSeq。**

**然后，我们最终返回标题，从句子中删除 startSeq 和 endSeq。**

**这种生成标题的方法被称为贪婪搜索。**

# **最终结果:**

**让我们看看我们的模型的一些最终结果。会先看到一些相关的说明文字。**

**![](img/3b1e2e50cb92422c24d617677914b6e7.png)****![](img/d47ed44920f5b79561ef54d20ff562d1.png)****![](img/fb474f6bc952826e28329308819d6371.png)****![](img/0e6359eecd6cb7d12d2669049a208c7d.png)****![](img/725df4f5d27c6aaa3b9edb22e411e254.png)****![](img/fd68a8423ac4edf28ec980ead4598f41.png)****![](img/2416cc806c54342222860d5899ce7cc5.png)****![](img/95eb1c9b3e41b7109595b3121087d2a0.png)****![](img/c44e462768ec1fd7bccf578c92512d1e.png)**

**不显示不正确的结果是不公平的，因为如前所述，模型并不完美。下面是一些不正确的结果。**

**![](img/03d0ff67349dacf3fe559afb8af808e9.png)****![](img/3dab4cfad58c9ffda2e6c39bc129dfe4.png)****![](img/1d8ba2eed2b68114c680ac60c3c87c6d.png)****![](img/86a32e4b2fd42865201d2c55f964fae1.png)****![](img/064150957058b14480b3ffc6ad0a186d.png)****![](img/6e6b6b917f63723f6fabf0fdbfacb160.png)**

# **部署:**

**部署和建立机器学习模型完全是不同的阶段。我们需要为我们的模型建立一个用户界面，需要保存和加载模型。代码很简单，我们将构建一个 API 来访问模型并从中获得结果。**

**在开始之前，我们先来看看部署的一些主要内容，一些基本假设:**

**你知道什么是 API 吗**

**你知道如何拯救一个模特。**

**你知道 HTML 和 Javascript 的基础知识。**

**在我们进入部署阶段之前，我们必须从 ML 代码中保存某些模块，它们是:**

**图像到序列模型，使用 keras 模型保存方法作为 model.h5**

**我们需要将 index_to_word 字典和 word_to_index 字典保存为 pickle 文件。**

**这些点的代码将不会显示，因为我们已经提到，我们将假设你知道 python 的基础知识，保存 pickle 文件是非常容易的。如果你碰巧不知道如何保存 pickle 文件，我请求你谷歌一下，这很简单。**

**现在，让我们来了解一下，为了部署模型，我们需要编写哪些代码。让我明确一件事，我们将努力保持代码尽可能干净，尽可能优雅，尽可能小。载入内存的时间越短越好。**

**因此，需要删除不必要的代码。**

**我们来看看需要写些什么。**

**我们将把我们的代码文件命名为 app.py，我们会让你知道为什么这样，我们可以把它命名为任何东西，但为了方便起见，我们把它命名为 app.py。**

**![](img/29029b50dc46a24181bdf425f69ff7f4.png)**

**我们将首先设置我们需要的所有导入，只导入有助于我们简化代码的引用库。**

**![](img/4cc1329ea5b039ccc7f00d540fa01e92.png)**

**导入部分完成后，我们现在将逐行查看代码。**

**第 15 行:这指定了我们的 Flask 应用程序的名称，__name__ 实际上是我们的文件名，即 app.py**

**第 17–18 行:是我们从 ML 代码中使用的参数值，我们将使用它作为静态值，因为我们的模型是根据这些值训练的。**

**第 21–22 行:这是我们加载 word_to_index 和 index_to_word 字典模块的地方。**

**第 24 行:这是我们设置 vocab_size 的地方**

**第 26–27 行:正如我们已经看到的，我们使用了 Inception V3 模型来矢量化我们的图像，所以对于新图像，我们也需要使用相同的方法来矢量化它们，这样配置应该与我们训练的 ML 模型相匹配。**

**第 29–30 行:这里我们正在加载我们的模型，它保存在“model.h5”下**

**在进入下一部分之前，如前所述，我们必须设计自己的 UI 来接受用户输入并显示结果，因此我们将有 2 个 html 页面，如下所示:**

**Home.html**

**Results.html**

**我们的第一页是 Home.html，最终结果显示在 Results.html。我们稍后会研究这个设计，为什么现在提到它，因为这将被引入我们的代码中，我不希望你们迷失在其中。**

**好了，继续…**

**![](img/9dc0ece93b2184066cf40e58c5016c2b.png)**

**这指定了我们的主页，输入将从这个页面获取，并将传递到我们的服务器，代码驻留在那里执行。因为“/”，无论何时有人访问我们的服务器，他们都会被默认导航到这个页面。**

**@app.route 是 flask 的注释，它帮助我们路由代码中提到的页面。render_template 帮助我们将指定的 html 页面发送到客户端的浏览器。现在这个解释对你理解正在发生的事情是有益的，我们不会深入它。**

**![](img/8064e9cd13550678dd8c4019d4c6b8f6.png)**

**这是整个代码，所有的魔法都在这里发生，我们会理解它的每一行，不要害怕，我们之前已经看过了，这是我们的预测代码，类似于 get_caption_for_photo。唯一的区别是，我们不是从保存的文件或字典中获取图片，而是动态转换图像，然后进行预测。所以你在这里看到的是你之前在我们的 ML 代码中看到的，不同的是你看到了那些分散在不同地方的代码，现在它们被放在一起了。还有一些关于如何获取数据以及从哪里获取数据的附加部分，我们将对此进行研究。**

**要了解这是如何工作的，我们需要了解我们从用户界面的输入是什么，用户为我们提供来自互联网的图像链接，这应该是我们可以下载图像的直接链接，我们收到链接，我们将图像下载到一个文件夹中，其余的过程是我们已经完成的转换和预测。**

**@app.route ('/predict '，methods = ['POST'])**

**这一行指定我们的服务器将使用 POST 方法提交数据，当我们单击 UI 中的 submit 按钮时，我们将导航到这个方法和这个 url '/predict '。**

**第 38 行:指定我们拥有的 count 变量，只是为了记录我们到目前为止已经处理过的图像。**

**第 39–41 行:指定我们从输入的 url 中检索图像，下载并存储在文件夹中，为此，我们从 html 页面中表单的输入框中获取 URL。我们设置图像名称，检索它并存储在位置中。**

**第 42–46 行:在这些特定的行中，我们对图像进行预处理，并在将其作为模型的输入之前将其转换成矢量化的形式。**

**第 47–61 行:这些行与我们在 ML 模型中的预测方法相同，即 get_caption_for_photo，因此将被跳过。**

**第 62–71 行:这些行只是清除使用的变量和空间管理，并删除存储的图像，这样我们就不会耗尽空间。**

**第 72 行:我们返回模型的预测和图像的 url 作为方法的参数。它将在 html 页面的用户界面中使用。**

**![](img/f42357da9830ff4c552be1b4033e886c.png)**

**第 74–75 行:这指定了运行方法，如果我们运行这个文件，它应该调用 app.run()来启动我们的服务器。**

**现在，我们将为主页和结果页面制作一个简单的 UI。**

1.  **Home.html**

**![](img/cc946eff06f6e5a1f793434751dd4855.png)**

**这是用户界面的外观，我们将只看如何创建表单和其中的基本字段。**

**![](img/eb55a24223b41b81bcc6e46a89bdc3b7.png)**

**我们将关注代码的某些部分，即**

**form name = ' imageName ' action = { { URL _ for(' predictCaption ')} }，这里的 action 字段指定 predict caption()方法的 app.route。**

**我们只对 textarea name='imageSource '感兴趣，因为它将在从 url 检索图像的方法中使用。**

**2.Results.html**

**![](img/a62add39c7558e3aaf5cce13e11a9603.png)****![](img/a8f05c64581a6c723d232b499cd2a23b.png)**

**我们将聚焦 image.src="{{ urlImage }} "，这是第 72 行 render_template 中使用的参数**

**{{ prediction }}，这是第 72 行的 render_template 中使用的参数**

**此外，我们必须将这些文件保存在一个名为“模板”的文件夹中**

**接下来是一个名为 Procfile 的文件，这个文件被命名为“Procfile ”,是的，它没有任何扩展名，看起来像这样:**

**![](img/684df06bcf600e74997e22233684b4d3.png)**

**接下来是 requirements.txt，它将帮助我们的服务器机器安装 python 模块使用的所有必需的包。**

**![](img/81bab83c43fc96b01063db17db5ac96a.png)**

**gunicorn 是我们的 procfile 使用的命令。**

**![](img/66e83f8adc3682d07a991cc240853053.png)**

**这些都是我们需要的文件，我们必须将所有这些文件上传到 GitHub 的公共存储库中，这些都是非常基本的东西，你可以通过谷歌搜索到。**

**这就是我们所需要的，现在一切都取决于我们如何设置我们的 Heroku 部署环境。我将一步一步地指导你设置环境。**

**[https://dashboard.heroku.com/login](https://dashboard.heroku.com/login)**

**访问此链接并创建您自己的个人资料。**

**![](img/d6e636835a679445833f66af861f0269.png)**

**点击创建新应用程序。**

**![](img/1bc875229f93e30759fcb25d79c7f6bc.png)**

**给出所需的名称，并选择地区作为美国。**

**![](img/6f6da98dfdf2a678d98eefa960a1c6cd.png)**

**导航到 Deploy 选项卡，然后选择 GitHub 作为部署方法，并将 Heroku 应用程序连接到 GitHub 项目。**

**![](img/477cbc4ad07bc5aed81e5a69897d7e67.png)**

**向下滚动并选择手动部署，然后单击按钮部署分支，**

**![](img/ae9839fb6b93cec7ea6dc6232d19a19c.png)****![](img/6c42f47275f9510261cd0194469357a4.png)**

**等待它显示您的项目已经部署到 Heroku。**

**最后，点击打开应用程序，查看您的应用程序上线。**

****你可以在这里参观矿山:**[**【https://bbose-caption-it.herokuapp.com/】**](https://bbose-caption-it.herokuapp.com/)**

**请通读正确使用该应用程序的步骤。**

**![](img/5bf821b4f8068f5b471fe2b26da416ef.png)**

**如果你读到这里，那么感谢你阅读这篇博客，我知道这是有益健康的，但我相信你确实喜欢。**

**你可以在我的 GitHub 简介里找到完整的代码， [**这里**](https://github.com/bishalbose294/bbose-caption-it) **。****

**那么是什么阻止了你呢？开始吧，创建和部署，别忘了享受乐趣！！！**

> ****感谢阅读！****
> 
> **如果你想了解更多类似的话题或者看看我还能提供什么，一定要访问我的网站:[所有关于东西](https://digital.allaboutstuffs.com/)**
> 
> **准备好让你的学习更上一层楼了吗？查看我提供的课程:[课程](https://digital.allaboutstuffs.com/courses/)**
> 
> **生活工作压力大？花一点时间来放松和放松我的舒缓和放松的视频！现在就去我的频道，用"[灵魂镇定剂](https://www.youtube.com/c/TheSoulTranquilizer)"开始你的内心平和与宁静之旅**