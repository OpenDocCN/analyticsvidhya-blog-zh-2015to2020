<html>
<head>
<title>Bank Data: Classification Part 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">银行数据:分类第 3 部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/bank-data-classification-part-3-21aaa23c5ea4?source=collection_archive---------18-----------------------#2020-09-30">https://medium.com/analytics-vidhya/bank-data-classification-part-3-21aaa23c5ea4?source=collection_archive---------18-----------------------#2020-09-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/278d1a29c04d9ede9c4a51584e825b8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PkOugTvsvrzHliOx3pJNSw.png"/></div></div></figure><p id="2615" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这篇博客是 4 篇中的第 3 篇，我们将讨论助推。</p><h2 id="b419" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">梯度推进</h2><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kj"><img src="../Images/ab7a22c6f2210f4a9da44375149afb0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DwvwMlOcT1T9hZwIJvMfng.png"/></div></div></figure><p id="8379" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">梯度推进是一种用于分类和回归的机器学习技术，用于将弱学习者变成强学习者。</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="c29c" class="jo jp hi kp b fi kt ku l kv kw">gb_clf = GradientBoostingClassifier()</span><span id="caf5" class="jo jp hi kp b fi kx ku l kv kw"># Grid Search<br/>param_gb = {"n_estimators":[100, 300, 500], "max_depth":[3, 5]}<br/>grid_gb = GridSearchCV(gb_clf, param_grid=param_gb)</span><span id="750d" class="jo jp hi kp b fi kx ku l kv kw">grid_gb.fit(X_train_new, y_train_new)</span><span id="46fe" class="jo jp hi kp b fi kx ku l kv kw">grid_gb.cv_results_</span></pre><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/1038715028b8ec67700773c8151a0018.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tVvR-Cuh_Sq_TSXBzESFdw.png"/></div></div></figure><p id="b082" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们继续使用网格搜索，看看交叉验证的性能。看一下上面的结果，我们应该获得大约 76%的测试分数</p><h2 id="4e92" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">混淆矩阵</h2><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="15ae" class="jo jp hi kp b fi kt ku l kv kw"><em class="kz"># Confusion Matrix</em></span><span id="df7a" class="jo jp hi kp b fi kx ku l kv kw">print('Confusion Matrix - Testing Dataset')</span><span id="6120" class="jo jp hi kp b fi kx ku l kv kw">print(pd.crosstab(y_test, grid_gb.predict(X_test), rownames<strong class="kp hj">=</strong>['True'], colnames<strong class="kp hj">=</strong>['Predicted'], margins<strong class="kp hj">=True</strong>))</span></pre><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/807c0d23ead26928943673f10432f9f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3eVoXv3xVLpSNyHHWubf-Q.png"/></div></div></figure><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="0516" class="jo jp hi kp b fi kt ku l kv kw">confusion_matrix_metrics(TN=719, FP=3790, FN=829, TP=10166, P=10995, N=4509)</span></pre><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lb"><img src="../Images/40acef9959e067df3a49bd006a56ef80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZXSUo39aBJJ9hBogZedI6w.png"/></div></div></figure><p id="907a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面的混淆矩阵显示 F1 分数为 81%，其中回忆是主要因素。</p><h2 id="b141" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">特征重要性</h2><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="2bfa" class="jo jp hi kp b fi kt ku l kv kw"># Graphing<br/>fig, ax = plt.subplots(figsize=(15, 10))<br/>ax.barh(width=gb_clf.feature_importances_, y=X_train_new.columns)</span></pre><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/843680c87637124b53bfe827c8698e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*becaoSqJS_G8NdmrRKKWTw.png"/></div></div></figure><p id="3896" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过使用特征重要性，我们可以看到我们的梯度推进模型认为什么特征是最重要的。梯度增强和随机森林的主要区别在于，在决定哪些特征是重要的时，梯度增强更具体/清楚；没有细线，重要特征之间的区别一目了然。</p><h2 id="9094" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">重要特征上的梯度增强</h2><p id="0388" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">我们将选择一个阈值，然后执行特征选择，以对我们的新特征执行梯度增强。</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="9372" class="jo jp hi kp b fi kt ku l kv kw"># Selecting the top features at a cap of 0.08<br/>gb_important_features = np.where(gb_clf.feature_importances_ &gt; 0.08)<br/>print(gb_important_features)<br/>print(len(gb_important_features[0]))  # Number of features that qualify</span><span id="a12f" class="jo jp hi kp b fi kx ku l kv kw"># Extracting the top feature column names<br/>gb_important_feature_names = [columns for columns in X_train_new.columns[gb_important_features]]<br/>gb_important_feature_names</span></pre><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/aff679b100fe85b4c18dce8c9725b387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nKOpaccAuaVI757_Dvbwiw.png"/></div></div></figure><p id="bcdb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面的代码显示了高于我们的阈值 0.08 的重要特性。这些是将要被选择和测试的特性。</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="2a92" class="jo jp hi kp b fi kt ku l kv kw"># Creating new training and testing data with top features<br/>gb_important_train_features = X_train_new[gb_important_feature_names]<br/>gb_important_test_features = X_test[gb_important_feature_names]</span></pre><p id="dc51" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上述代码仅包括数据帧中的选定特征。</p><p id="a177" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们将使用网格搜索来浏览我们的训练数据，并查看结果:</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="f52f" class="jo jp hi kp b fi kt ku l kv kw">param_gb = {"n_estimators":[100, 500, 700], "max_depth":[3, 7, 9]}</span><span id="e387" class="jo jp hi kp b fi kx ku l kv kw"># Grid search<br/>grid_gb = GridSearchCV(gb_clf, param_grid=param_gb)</span><span id="8376" class="jo jp hi kp b fi kx ku l kv kw">grid_gb.fit(gb_important_train_features, y_train_new)</span><span id="32ec" class="jo jp hi kp b fi kx ku l kv kw">grid_gb.cv_results_</span></pre><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/3cc47699d8f3515b2a305a1b7ad2bb18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WOMwzs6L2NyefdB6EWVbfg.png"/></div></div></figure><p id="2b43" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">交叉验证的结果显示，我们一定会得到 72%左右的分数。</p><h2 id="9270" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">重要特征的混淆矩阵</h2><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="3bbe" class="jo jp hi kp b fi kt ku l kv kw"># Confusion Matrix<br/>print('Confusion Matrix - Testing Dataset')<br/>print(pd.crosstab(y_test, grid_gb.predict(gb_important_test_features), rownames=['True'], colnames=['Predicted'], margins=True))</span></pre><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/07a79da9814988f2122fe47a8a4a331a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-Dv0XdUUVigJZgPkyy71Q.png"/></div></div></figure><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="0231" class="jo jp hi kp b fi kt ku l kv kw">confusion_matrix_metrics(TN=593, FP=3916, FN=825, TP=10170, P=10995, N=4509)</span></pre><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/41f49ef3a5afeb328a49a02c0b6dd5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L7DHr1Va3TgZ8OP07QWg2g.png"/></div></div></figure><p id="335c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">回过头来看，我们可以看到功能选择在我们的 F1 得分结果中几乎没有差异。</p></div></div>    
</body>
</html>