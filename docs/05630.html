<html>
<head>
<title>Build Your Own Linear Regression Model From Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始构建您自己的线性回归模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/build-your-own-linear-regression-model-from-scratch-2b330a431626?source=collection_archive---------16-----------------------#2020-04-27">https://medium.com/analytics-vidhya/build-your-own-linear-regression-model-from-scratch-2b330a431626?source=collection_archive---------16-----------------------#2020-04-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/79ec131010d602f986a3e2cccfe26129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mg8y0CtLJqPHrqX3A3UJaw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">机器猫</figcaption></figure><p id="5c20" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们从一些真实的例子开始，考虑一个月大的婴儿，如果一条蛇来到婴儿面前，婴儿不会害怕，事实上他或她可能会试图触摸那条蛇。但是让我们假设现在婴儿已经长大，他已经20岁了，现在假设如果一条蛇出现在那个男孩面前，那么那个男孩肯定会逃离那条蛇。所以在这20年的时间里，这个男孩已经知道蛇是危险的，可能是从他的父母那里，可能是从电视频道，可能是从他的朋友那里，可能是蛇在过去咬过他，但不知何故他知道蛇等于危险的关系。</p><p id="e1b5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我会给你一个更实际的例子，所以让我们考虑下表。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es js"><img src="../Images/550655d5a1a52a8bf35e84dfc2991963.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*9cb9FYfpra0AFFPiJXBITg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">日期设置</figcaption></figure><p id="da17" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果一个人的身高是5.1，那么他的体重是54，如果身高是6.2，那么体重是75，所以我们定义了一个表。如果我问你一个人的身高是6.0，他的体重是多少？</p><p id="9ff9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">你的猜测是在70-72之间，对吗？</p><p id="8c73" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在让我们分析一下你是如何猜测重量的。首先，通过查看数据，我们可以很容易地找出身高和体重之间的关系，也就是说，如果身高增加，那么体重也增加。</p><p id="0774" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以这里你的大脑是如此强大，通过查看这些数据，他能够很容易地了解身高和体重之间的关系。</p><p id="8560" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这就是我们作为一个人类试图学习的模式。</p><h2 id="c8f0" class="jx jy hi bd jz ka kb kc kd ke kf kg kh jf ki kj kk jj kl km kn jn ko kp kq kr bi translated">但现在的问题是，机器学习到底是如何工作的？或者机器如何尝试学习这种关系？</h2><p id="6ec9" class="pw-post-body-paragraph iu iv hi iw b ix ks iz ja jb kt jd je jf ku jh ji jj kv jl jm jn kw jp jq jr hb bi translated">所以对于身高等于6.0，你的预测是对的？那么现在是机器预测体重的时候了？让我们来看看机器是如何预测体重的。<br/> <strong class="iw hj">所以这里我们的目的是预测身高为6.0时的体重</strong></p><p id="277c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在我用图形表示了身高和体重。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es kx"><img src="../Images/b3e631986a4faadd84fe3cc3dfb813ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*kDwn0lxeZiQzimeO6lnXog.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">身高与体重</figcaption></figure><p id="3255" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以在上图中，你可以清楚地看到，是的，身高和体重是成正比的。</p><p id="3a54" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在你可能想知道图中的那条线是什么？？？</p><p id="39da" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以我们都知道基本的线方程，即Y = m*X + c</p><p id="5144" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这里，<br/> m =直线的斜率<br/> c =截距，即X = 0时Y的值</p><p id="bba1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我将再次重写这条线方程，它将定义我们的问题陈述。</p><blockquote class="ky"><p id="aef2" class="kz la hi bd lb lc ld le lf lg lh jr dx translated"><strong class="ak">体重= m *身高+ c </strong></p></blockquote><p id="ec5d" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">这表明，如果我知道m的值，高度的值和c的值，那么我就可以很容易地求出重量。</p><p id="fe65" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们试一下，假设m = 10，c = 1，身高= 5.5，那么在这种情况下，我的体重将是56，即(体重= 10 * 5.5 + 1)。但是如果你去看上面的表格，你会发现当身高等于5.5的时候，我的体重是65。</p><p id="f4db" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以这里我的预测体重是56，实际体重是65，所以我得到了9个单位的误差。</p><p id="290e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">误差=预测值-实际值</strong></p><p id="aa52" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">n =示例数量。</p><p id="2db8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了便于理解，我只展示了一个例子的误差值，但是成本函数只不过是所有例子的均方误差的总和。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/f6b21d3b19c98c0c5eb210d2e9bb3c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*pRzAKRGC5kGvpWVh_eODCQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">价值函数</figcaption></figure><p id="d33e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以现在的问题是，我们如何最小化这个成本函数？或者，我们如何找到最合适的线方程，给我最小的成本函数？或者我如何能减少均方差值？对不对…？</p><p id="8947" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果你仔细观察，你就会知道，我在上面的线方程中随机选择了m和c的值，即体重= m *身高+ c，但是如果不是m=10和c=1，如果我用m和c中的一些其他值替代，那么成本函数值可能会最小。</p><p id="b7e9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，寻找更好的m和c值的过程被称为<strong class="iw hj">梯度下降算法</strong>，该过程给出了<strong class="iw hj">代价函数</strong>的最小值。</p><p id="1408" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，梯度下降是一种更新m和c的值以降低成本函数(均方误差)的方法。想法是，我们从m和c的一些值开始，然后我们迭代地改变这些值，以减少误差值或成本函数。梯度下降帮助我们了解如何改变这些值。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/61520ce021e47c96d95d37144678281f.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*IZQywT8DCz_SKxKnfvCkXg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">凸函数与非凸函数</figcaption></figure><p id="4e84" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以我们必须不断改变m和c的值，以达到这个凸函数的最小值。</p><p id="7aa3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">所以我们改变m和c值的每一次速率叫做<strong class="iw hj">学习速率(α)</strong>。所以我们的学习速度应该是这样的，我们不应该错过凸函数的最小值。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/9d4bfea8fcf5b5738a23178b6757b39d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*KTl5egJY1mRVmwKb3eXI5A.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">梯度下降(在我们的例子中，a0 = c，a1 = m)</figcaption></figure><p id="7c65" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">就这样…让我们试着用编程的方式执行上面的步骤，看看我们能得到的最合适的m和c值是多少。</p><pre class="jt ju jv jw fd lq lr ls lt aw lu bi"><span id="fce7" class="jx jy hi lr b fi lv lw l lx ly"><em class="lz">import pandas as pd</em></span><span id="a0c8" class="jx jy hi lr b fi ma lw l lx ly"><em class="lz"># Initialization of m and c<br/></em>m = 0<br/>c = 0<br/><br/>X = [5.1, 6.2, 5.8, 5.5, 5.0, 5.3, 6.0]<br/>Y = [54, 75, 67, 65, 54, 59, 69]<br/><br/>data = pd.DataFrame(list(zip(X, Y)), columns =[<strong class="lr hj">'X'</strong>, <strong class="lr hj">'Y'</strong>]) <br/><br/>print(data.head())<br/><br/>X = data.iloc[:, 0]<br/>Y = data.iloc[:, 1]</span><span id="1d98" class="jx jy hi lr b fi ma lw l lx ly"><em class="lz"># The learning Rate</em><br/>L = 0.0001</span><span id="b8e5" class="jx jy hi lr b fi ma lw l lx ly"><em class="lz"># The number of iterations to perform gradient descent<br/></em>epochs = 1000</span><span id="548d" class="jx jy hi lr b fi ma lw l lx ly"><em class="lz"># Number of elements in X<br/></em>n = float(len(X))  <em class="lz"><br/><br/># Performing Gradient Descent <br/></em><strong class="lr hj">for </strong>i <strong class="lr hj">in </strong>range(epochs):<br/>    Y_pred = m * X + c  <em class="lz"># The current predicted value of Y<br/>    </em>D_m = (-2 / n) * sum(X * (Y - Y_pred))  <em class="lz"># Derivative wrt m<br/>    </em>D_c = (-2 / n) * sum(Y - Y_pred)  <em class="lz"># Derivative wrt c    <br/>    </em>m = m - L * D_m  <em class="lz"># Update m<br/>    </em>c = c - L * D_c  <em class="lz"># Update c<br/><br/></em>print(m, c)</span><span id="5a7e" class="jx jy hi lr b fi ma lw l lx ly"># m = 11.05 , c = 1.94<br/><br/><strong class="lr hj">def </strong>predict(x):<br/>    <strong class="lr hj">return </strong>m * x + c</span><span id="aad9" class="jx jy hi lr b fi ma lw l lx ly">predict(6.0)</span><span id="94b7" class="jx jy hi lr b fi ma lw l lx ly"># 68.26</span></pre><p id="a2fb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，我们可以看到，使用我们自己的线性回归算法，我们能够预测重量。</p><p id="88cc" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">感谢阅读…</p><p id="9408" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> <em class="lz">第一条原则是，千万不要愚弄自己，自己是最容易被愚弄的人。——理查德·费曼。</em>T9】</strong></p></div></div>    
</body>
</html>