<html>
<head>
<title>Understanding OpenAI baseline source code and making it do self-play! Part 4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解OpenAI基线源代码，让它做自玩！第四部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-openai-baseline-source-code-and-making-it-do-self-play-part-4-a54e075386bf?source=collection_archive---------13-----------------------#2019-12-07">https://medium.com/analytics-vidhya/understanding-openai-baseline-source-code-and-making-it-do-self-play-part-4-a54e075386bf?source=collection_archive---------13-----------------------#2019-12-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/0c4e24ae4dd215d07c5cf52498b2ba0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*BY5NA77e54PDoBWiaKHufw.png"/></div></figure><p id="fc0d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我们将最终尝试实现OpenAI基线的自玩功能！要看第1部分、第2部分和第3部分，请在此处查看<a class="ae jk" rel="noopener" href="/analytics-vidhya/understanding-openai-baseline-source-code-and-making-it-do-self-play-part-1-9f30085a8c16"/>，在此处查看<a class="ae jk" rel="noopener" href="/@isamu.website/understanding-openai-baseline-source-code-and-making-it-do-self-play-part-2-9f8c4fd3e3b5"/>，在此处查看<a class="ae jk" rel="noopener" href="/@isamu.website/understanding-openai-baseline-source-code-and-making-it-do-self-play-part-3-23eeeb6ab817"/>。我认为如果没有这个基础，这将有点难以理解。我将尝试在基线中实现实际的自我游戏功能，所以我希望这很有趣！但是，我会谈谈我自己的工作流程，我不习惯，所以如果你觉得有些部分难以理解，请告诉我！</p><p id="12ad" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">要查看代码并跟进，请点击查看<a class="ae jk" href="https://github.com/isamu-isozaki/baseline-selfplay" rel="noopener ugc nofollow" target="_blank">！</a></p><h1 id="0aca" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">一个要求</h1><p id="c340" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">我的环境的一个要求是双方需要能够同时做决定。在这种情况下，我希望模型在环境迈出一步之前更新两边或任意数量的边。</p><p id="867d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这样我们就不会在每一个时间步发送某一方面的观察和更新环境。这是我最初的想法，但我认为它行不通。</p><p id="cc02" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">那么，我们从选择的一端运行每个操作，然后连接它们，最后运行step并更新环境，怎么样？例如，在step函数中，如果我们循环遍历所有的边，并根据它们观察到的情况采取行动，然后更新环境，我们可以有效地使它看起来像我们有边数的额外环境！</p><h1 id="20b8" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">环境又是如何产生的？</h1><p id="2b78" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">到目前为止，我们看到make_env提供的功能总体上获得了我们创建的环境，只是用附加功能包装了它。因此，原始功能不会改变。因此，我们仍然可以访问环境的属性。</p><p id="63b9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这解释了为什么要完成我们的目标，我们需要</p><ol class=""><li id="6e5f" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj kt ku kv kw bi translated">在worker函数中，它需要将各方的动作一次发送到远程/环境。或者说的更具体一点，是需要步骤阶段和实际步骤阶段的准备。这可以在工人函数中完成，也可以在实际环境中完成。我想我会在实际环境中做！</li><li id="1cb7" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj kt ku kv kw bi translated">观察空间是基于相同的环境，玩家人数相同(他们可以不同，因为你看不到一些玩家等)。因此，工人也需要以适当的方式发回观察结果！</li></ol><p id="dbb0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，我的想法是改变它</p><ol class=""><li id="36fc" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj kt ku kv kw bi translated">如果环境有一个属性“边”，它将表示环境拥有的边的数量，nenv乘以这个数量。</li></ol><p id="c916" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我不确定如何做到这一点，因为首先在SubprocVecEnv中创建环境，然后继续这样会很麻烦，因为在创建环境的过程中，我们首先需要环境的数量。</p><p id="7cbb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我很确定这是可能的，但是我想到的每一个方法都变得很混乱。因此，我决定在common_arg_parser中添加一个名为“no_self_play”的参数，该参数最初设置为False，如果用户将</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="47f8" class="ll jm hi lh b fi lm ln l lo lp">--no_self_play</span></pre><p id="514b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这将是真的，从而使一个普通的环境没有边。</p><p id="08d6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为此，我使用了make_vec_env函数</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="dd49" class="ll jm hi lh b fi lm ln l lo lp">if not env_kwargs.get("no_self_play", True):<br/>    num_env *= env_kwargs.get("sides", 2)#The default number of sides is 2</span></pre><p id="903a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">其中no_self_play是一个参数。)提供。然而，我发现用户发送的参数不在build env的env_kwargs参数中。最初，env_kwargs被设置为None</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="5e0c" class="ll jm hi lh b fi lm ln l lo lp">env_kwargs = env_kwargs or {}</span></pre><p id="b30f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">使它成为一个空字典。</p><p id="8055" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，由于我希望用户的参数放在env_kwargs参数中，我们只需要将build_env中的参数从arg_parse转换成一个字典，然后将它作为一个参数提供！</p><p id="dae9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">将arg_parse参数转换成一个字典可以很容易地完成(感谢<a class="ae jk" href="https://stackoverflow.com/questions/16878315/what-is-the-right-way-to-treat-python-argparse-namespace-as-a-dictionary" rel="noopener ugc nofollow" target="_blank"> Raymond </a>！)</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="780d" class="ll jm hi lh b fi lm ln l lo lp">args_dict = vars(args)</span></pre><p id="f2db" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">老实说这很酷！</p><p id="3032" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然后，我通过调用make_vec_env</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="2ded" class="ll jm hi lh b fi lm ln l lo lp">env = make_vec_env(env_id, env_type, args.num_env or 1, seed, reward_scale=args.reward_scale, flatten_dict_observations=flatten_dict_observations, env_kwargs=args_dict)</span></pre><p id="beaf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然后，我们成功的增加了边数的环境！</p><p id="0beb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.在子过程中，只有nenvs//侧多个环境实际运行，并将每侧多个行为指标应用于每个环境。</p><p id="8aa3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这可能不是最优雅的解决方案，因为我是所有花哨的线程和多处理的新手，所以如果你有更好的解决方案，请告诉我！</p><p id="8f27" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在__init__函数中，我写道</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="55ca" class="ll jm hi lh b fi lm ln l lo lp">if(hasattr(env_fns[0](), 'sides')):<br/>   self.sides = env_fns[0]().sides<br/>else:<br/>   self.sides = 1</span></pre><p id="f963" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">那么，由于nenvs//1 == nenvs，代码做的事情应该没有区别。我还在进行一些bug测试，所以这可能会改变！</p><p id="573a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">无论如何，在env_fns上的数组_split之前</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="1f9b" class="ll jm hi lh b fi lm ln l lo lp">env_fns = np.array_split(env_fns, self.nremotes)</span></pre><p id="7dd8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我做了</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="75e5" class="ll jm hi lh b fi lm ln l lo lp">env_fns = env_fns[:nenvs//self.sides]</span></pre><p id="f828" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">只获得第一个nenvs//self.sides许多环境，因为其余的将不会被使用！然后，我将断言和self.n_remotes更改为</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="488a" class="ll jm hi lh b fi lm ln l lo lp">assert nenvs//self.sides % in_series == 0, "Number of envs must be divisible by number of envs to run in series"</span><span id="80df" class="ll jm hi lh b fi lq ln l lo lp">self.nremotes = nenvs //self.sides // in_series</span></pre><p id="d61f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我没有改变n_envs变量的值的原因是，因为在实际的learn函数中，它在环境中训练算法(至少在ppo2中)，我看到</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="c9f6" class="ll jm hi lh b fi lm ln l lo lp">nenvs = env.num_envs</span></pre><p id="e0b8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">稍后用于计算批次！所以，我不能改变这个数字，因为那样的话，我就不能计算环境中的边数了！</p><p id="9701" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">无论如何，总的来说，这应该使得在众多的环境* self.sides，nenv动作中，每个self.sides动作形成一个调用正确环境的块！</p><p id="b46a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然后，我转到step_async并对其进行了更改，这样它就可以通过在远程i//self.sides上调用action i的操作来在每一侧执行sides number of action！</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="d34a" class="ll jm hi lh b fi lm ln l lo lp">def step_async(self, actions):<br/>        self._assert_not_closed()<br/>        actions = np.array_split(actions, self.nremotes)<br/>        for j in range(len(actions)):<br/>            for action in actions[j]:<br/>                self.remotes[j].send(('step', action))<br/>                <br/>        self.waiting = True</span></pre><p id="7056" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">更新:对不起，它最初没有工作，因为self.remotes的索引最初是错误的。固定2019/12/8</p><h1 id="c778" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">问题</h1><p id="3258" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">然而，这里有一个小问题。环境没有办法知道它正在发送的动作对应于哪一方！可以从第一面也可以从第二面，总的来说，很混乱。</p><p id="c27f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了解决这个问题，我在我的环境中添加了一个名为side的属性，该属性在__init__函数中初始设置为0，如下所示</p><h1 id="c5ff" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">我的环境</h1><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="889d" class="ll jm hi lh b fi lm ln l lo lp">self.side = 0</span></pre><p id="2699" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然后，我修改了我的环境，这样你就可以设置你想要的动作对应哪一面</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="6b91" class="ll jm hi lh b fi lm ln l lo lp">def step(self, action):<br/>    side = self.side<br/>    self.action[side] = action<br/>    self.finished_sides[side] = 1<br/>    self.side += 1<br/>    self.side %= self.sides<br/>    if self.finished_side[self.finished_side == 0].shape[0] == 0:<br/>        self.update_step()   <br/>return None, None, None, None</span></pre><p id="2eac" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">其中self.finished_side最初全为0，边的大小如下</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="93be" class="ll jm hi lh b fi lm ln l lo lp">self.finished_side = np.zeros(self.sides)</span></pre><p id="26f5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我确信</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="2612" class="ll jm hi lh b fi lm ln l lo lp">self.finished_side[self.finished_side == 0].shape[0] == 0</span></pre><p id="3502" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这不是最好的方法，我以后会想出更好的方法，但是现在，它很有效！</p><p id="f2b8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">update_step运行环境并返回观察结果、奖励、是否完成以及所有方面的空字典</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="6f57" class="ll jm hi lh b fi lm ln l lo lp">def update_step(self):<br/>    self.game_step()<br/>    done = False<br/>    if t&gt;=self.terminate_turn or self.end():<br/>        done = True<br/>    self.t += 1<br/>    self.finishe_sides[...] = 0<br/>    dones = [done for _ in range(self.sides)]<br/>    infos = [{} for _ in range(self.sides)]<br/>    return self.obs, self.rewards, dones, infos</span></pre><p id="6d51" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我这样做是为了让所有返回的东西，比如self.obs，基本索引显示它是哪一方。所以比如边0的观察可以在self.obs[0]找到！</p><p id="64ad" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，在step_wait中，由于返回了一些Nones，我们需要稍微修改一下代码，使数据分布在所有环境中，这样模型就能看到正确的观察结果，并且每个动作都对应于正确的方面和环境。</p><h1 id="120a" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">步骤_等待</h1><p id="f154" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">现在，虽然step_wait函数最初是从</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="671c" class="ll jm hi lh b fi lm ln l lo lp">results = [remote.recv() for remote in self.remotes]</span></pre><p id="e84d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们需要稍微修改一下</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="e611" class="ll jm hi lh b fi lm ln l lo lp">results = [self.remotes[i//self.sides].recv() for i in range(len(self.remotes)*self.sides)]</span></pre><p id="35dd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这将从每个远程获得双方的结果数！</p><p id="f76a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然后，这只是为了使稍后的重置函数变得平滑，但是我决定对结果数组进行排序，以便第一个len(self.remotes)或nenvs // self.sides将是实际的观察值，而不是在每个i % self.sides = self.sides-1响应中都出现观察值(这是因为只有当所有的边都记录了它们的动作时，我才得到响应)</p><p id="232a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以，在一定程度上去除了in_series效果的_flatten_list函数之后(至少我是这么理解的！)我做了</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="7ba9" class="ll jm hi lh b fi lm ln l lo lp">data = results.copy()[self.sides-1::self.sides]<br/>results = np.asarray(results)<br/>results[:len(self.remotes)] = data</span></pre><p id="2a8e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，完成了，如果self.sides大于1(意味着这是一个自我游戏环境)，我通过我的可怕命名的方法tactic_game_fix_results传递结果变量！</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="9cc6" class="ll jm hi lh b fi lm ln l lo lp">def tactic_game_fix_results(self, results):<br/>        for i in range(len(results)-1, -1, -1):<br/>            for j in range(len(results[i])):<br/>                results[i][j] = results[i//self.sides][j][i % self.sides]<br/>        return results</span></pre><p id="3b4f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">基本上，这里发生的是，我从后面迭代结果(其中都是none ),然后用代理I的实际观察、奖励、完成和信息覆盖这些none。我这样做是为了让代理看到i//self.sides环境的side i % self.sides，我认为这是相当一致的！j只是在观察、奖励、完成和信息之间循环。所以，len(results[i])这里是4！</p><p id="1bdb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，总的来说，step_wait函数最终变成了</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="b217" class="ll jm hi lh b fi lm ln l lo lp">def step_wait(self):<br/>        self._assert_not_closed()<br/>        #do recv on the same remote several times<br/>        results = [self.remotes[i//self.sides].recv() for i in range(len(self.remotes)*self.sides)]<br/>        results = _flatten_list(results)<br/>        data = results.copy()[self.sides-1::self.sides]<br/>        results = np.asarray(results)<br/>        results[:len(self.remotes)] = data<br/>        #push the observations to the first portion of the results array.<br/>        if self.sides &gt; 1:<br/>            results = self.tactic_game_fix_results(results)<br/>        self.waiting = False<br/>        obs, rews, dones, infos = zip(*results)<br/>        return _flatten_obs(obs), np.stack(rews), np.stack(dones), infos</span></pre><p id="6ae2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我没有把数据部分放在if self.sides &gt; 1中，因为如果self.sides = 1，应该没有变化！</p><h1 id="6b98" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">重置</h1><p id="6ee6" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">由于reset函数需要返回观察结果，但不需要任何操作(因为它是初始状态)，我可以做类似这样的事情</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="5583" class="ll jm hi lh b fi lm ln l lo lp">def reset(self):<br/>  self.__init__(**self.kwargs)<br/>  return self.obs</span></pre><p id="8428" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在我的环境和子环境中，我将reset改为</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="f6df" class="ll jm hi lh b fi lm ln l lo lp">def reset(self):<br/>        self._assert_not_closed()<br/>        for i in range(len(self.remotes)):<br/>            self.remotes[i].send(('reset', None))<br/>        obs = [self.remotes[i].recv() for i, _ in enumerate(self.remotes)]<br/>        obs = _flatten_list(obs)<br/>        if self.sides &gt; 1:<br/>            obs += [[None] for _ in range(len(self.remotes)*(self.sides-1))]<br/>            obs = self.tactic_game_fix_results(obs)     <br/>            obs = zip(*obs)<br/>            obs = obs.__next__()<br/>        return _flatten_obs(obs)</span></pre><p id="7513" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">坦白地说，我并不特别干净，我也不以从美学角度来看它为荣。但不管怎样，最主要的变化是</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="c2ba" class="ll jm hi lh b fi lm ln l lo lp">if self.sides &gt; 1:<br/>    obs += [[None] for _ in range(len(self.remotes)*(self.sides-1))]<br/>    obs = self.tactic_game_fix_results(obs)     <br/>    obs = zip(*obs)<br/>    obs = obs.__next__()</span></pre><p id="7803" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">第一部分填充观察值，这样所有模型都有足够的观察值。self.tactic_game_fix_results也应该是不言自明的！接下来的几行会发生什么？嗯，基本上，我试着做一些事情</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="4238" class="ll jm hi lh b fi lm ln l lo lp">obs, rews, dones, infos = zip(*results)</span></pre><p id="a518" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了得到观察结果。这里基本上发生的是，reset的obs的大小从[num_agents，1，rest of dims]变为[num_agents，rest_of_dims]。</p><p id="2636" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然而，在step函数中，返回的是4个值j是4，但是对于reset的观察，出现了一个问题，因为只返回了1个值，observation，j开始在观察的边上迭代，这破坏了一切，对我来说是一个调试噩梦。基本上，我所做的就是将self.obs放在我的环境中的一个列表中，如下所示！</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="cde5" class="ll jm hi lh b fi lm ln l lo lp">def reset(self):<br/>  self.__init__(**self.kwargs)<br/>  return [self.obs]</span></pre><p id="64a2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，经过一点调试，我发现了一些错误的另一个来源。这是worker函数中的step_env函数。它主要做的是当一个步骤被请求时，它只是从env的step函数中获得观察结果和所有好的输出，并在这样的过程中为所有环境发送它！</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="6949" class="ll jm hi lh b fi lm ln l lo lp">if cmd == 'step':<br/>                remote.send([step_env(env, action) for env, action in zip(envs, data)])</span></pre><p id="ed3d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">实际实现是</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="f6b2" class="ll jm hi lh b fi lm ln l lo lp">def step_env(env, action):<br/>        ob, reward, done, info = env.step(action)<br/>        if done:<br/>            ob = env.reset()<br/>        return ob, reward, done, info</span></pre><p id="075b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我最初有点困惑，但重要的是要注意，这是您的环境的重置函数，而不是您的SubprocVecEnv或任何包装器的重置函数或步骤函数！</p><p id="7e7d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">总之，在这里，我有一个问题。正是因为我把ob放在一个类似[ob]的列表中，并在reset函数中返回，所以我不能把它放在ob中。我需要得到它的第0个索引。</p><p id="126f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">同样，当我们检查done的条件时，如果我们有一个列表，我们需要检查一个索引是假还是真，看看它是否结束。这是因为，在python或者大多数语言中，</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="b4db" class="ll jm hi lh b fi lm ln l lo lp">bool([False, False])</span></pre><p id="26d2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">返回True。</p><p id="20c3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在我的例子中，我创造了一个环境，如果一面完成了，所有的面都完成了。所以，总的来说，我做到了</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="c9c5" class="ll jm hi lh b fi lm ln l lo lp">def step_env(env, action):<br/>        ob, reward, done, info = env.step(action)<br/>        if type(done) == list and done[0]:#For custom environments<br/>            ob = env.reset()<br/>            ob = ob[0]<br/>        if type(done) != list and done:#For non-custom environments<br/>            ob = env.reset()<br/>        return ob, reward, done, info</span></pre><p id="e109" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">就是这样！我基本上分成了两种情况，一种是我的游戏，一种是完成后返回的列表，另一种是通常的健身房环境。</p><p id="195c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我很确定我在这里可能有过于复杂的东西，所以如果你认为有些地方实现得不好，请告诉我，因为我喜欢学习。</p><p id="e04b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">3.渲染游戏</p><p id="dbc1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我只是使用了render函数，对环境做了与reset相同的事情(将渲染的图像放在一个列表中),并将get_image函数改为</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="c3a8" class="ll jm hi lh b fi lm ln l lo lp">def get_images(self):<br/>        self._assert_not_closed()<br/>        for pipe in self.remotes:<br/>            pipe.send(('render', None))<br/>        imgs = [pipe.recv() for pipe in self.remotes]<br/>        imgs = _flatten_list(imgs)<br/>        if self.sides &gt; 1:<br/>            imgs += [[None] for _ in range(len(self.remotes)*(self.sides-1))]<br/>            imgs = self.tactic_game_fix_results(imgs)<br/>            imgs = zip(*imgs)<br/>            imgs = imgs.__next__()<br/>        return imgs</span></pre><p id="cd36" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">4.这是稍微无关的，但由于**kwargs用于初始化游戏，我对我的环境做了修改</p><p id="f557" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">环境是通过中的代码获得的</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="7444" class="ll jm hi lh b fi lm ln l lo lp">self.entry_point(**_kwargs)</span></pre><p id="0cd1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">其中entrypoint是registeration.py中的模块！基本上，这是用除了env_id参数之外的所有参数来初始化函数。</p><p id="7884" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">此外，在我的类的__init__函数中，我这样做是为了使kwargs成为我的属性，因为在我的环境中，我已经用(argparse)做了类似的事情！你做这件事的方式，是我从<a class="ae jk" href="https://stackoverflow.com/questions/5624912/kwargs-parsing-best-practice" rel="noopener ugc nofollow" target="_blank">到这里</a>(都是迈克·刘易斯的功劳！)是</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="0d5e" class="ll jm hi lh b fi lm ln l lo lp">for k,v in kwarg.iteritems():<br/>   setattr(self, k, v)</span></pre><p id="7077" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">老实说，这很聪明！</p><p id="fa75" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">但是，自从健身房。Envs函数有一个重要的方法叫做seeds，它碰巧和我在build_env函数中使用的一个参数同名</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="0c20" class="ll jm hi lh b fi lm ln l lo lp">args_dict = vars(args)<br/>del args_dict["seed"]<br/>env = make_vec_env(env_id, env_type, args.num_env or 1, seed, reward_scale=args.reward_scale, flatten_dict_observations=flatten_dict_observations, env_kwargs=args_dict)</span></pre><p id="bce2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在我运行make_vec_env之前</p><p id="9141" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我能够成功地使用这个方法，因为之前种子参数被保存到种子变量中，该变量作为</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="8af8" class="ll jm hi lh b fi lm ln l lo lp">seed = args.seed</span></pre><h1 id="119d" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">一些其他的小细节</h1><ol class=""><li id="1560" class="ko kp hi io b ip kj it kk ix lr jb ls jf lt jj kt ku kv kw bi translated">这可能有点小，但我认为为了全面，我应该包括它。还记得我们包装环境和奖励等级的监视器包装吗？碰巧的是，每次我们调用step in the runner.py时，这些函数都会将奖励相加或乘以奖励。所以，因为我们没有返回任何奖励，这有点复杂，因为它会产生错误。因此，我需要检查它是否没有，但总的来说，我能够修复它，所以它很好！</li><li id="6b76" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj kt ku kv kw bi translated">我注意到gym不知道我的id，所以我需要在run.py中手动导入我的自定义环境来注册它。有点意思！也许有更好的方法，但现在，我会用这个！</li></ol><h1 id="9852" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">最终结果</h1><p id="dfa1" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">最后，我能够体面地开始训练了。我还没有运行一个全面的测试，所以仍然可能有错误，但目前为止看起来不错！</p><figure class="lc ld le lf fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/5a5b631a9a0cef9fab341406d52b1a64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*EvVWsrwHMzDpfpQ6ha1drw.gif"/></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">大约10分钟的训练后</figcaption></figure><p id="978f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以上是渲染的结果！要查看代码，请点击查看<a class="ae jk" href="https://github.com/isamu-isozaki/baseline-selfplay" rel="noopener ugc nofollow" target="_blank">！</a></p></div></div>    
</body>
</html>