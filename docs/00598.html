<html>
<head>
<title>Linear Regression Using Gradient Descent for Beginners— Intuition, Math and Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">初学者使用梯度下降的线性回归——直觉、数学和代码</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-gradient-descent-intuition-and-math-c9a8f5aeeb22?source=collection_archive---------0-----------------------#2019-08-12">https://medium.com/analytics-vidhya/linear-regression-gradient-descent-intuition-and-math-c9a8f5aeeb22?source=collection_archive---------0-----------------------#2019-08-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/4669bb0355027fb9767e0b4d90f70fa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*40ouuuw_xxnCzmXu9H6z-w.jpeg"/></div></div></figure><div class=""/><p id="fd86" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇博客中，我们将首先尝试直观地理解线性回归和梯度下降，然后我们将看到算法背后的数学，然后用python做一个基本的实现。</p><p id="bc4e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个博客的结构如下</p><ol class=""><li id="89db" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">我们将设置一个使用线性回归的假设问题。</li><li id="db1a" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">我们将逐渐发展对算法每一步的直觉。我们将回答为什么我们使用这个步骤以及它有什么作用。</li><li id="0516" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">然后我们会看看每一步背后的数学，并用数学表达式来表示</li><li id="0a9a" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">我们将使用python导出的数学表达式来实现该算法。</li></ol><blockquote class="kc kd ke"><p id="b473" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hb bi translated"><strong class="is hu">注:</strong></p><p id="42d4" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hb bi translated">由于中型博客编辑器不支持类似LaTex的数学表达式语法，我使用了以下约定</p><p id="d878" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hb bi translated"><strong class="is hu">w0</strong>表示0是W的<strong class="is hu">下标</strong></p><p id="9439" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hb bi translated"><strong class="is hu"> X^T </strong>表示t是x的<strong class="is hu">上标</strong></p></blockquote><h2 id="772d" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">先决条件</h2><p id="5c6b" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">即使你没有任何先验知识，你也可以对使用梯度下降的线性回归的工作原理有一些直觉，但是如果你知道就更好了</p><ul class=""><li id="d86b" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn lj ju jv jw bi translated">微积分中导数的一些概念</li><li id="2f58" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">矩阵乘法如何工作</li><li id="1d85" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">基本的python编程知识</li></ul><h2 id="0185" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">问题设置</h2><p id="2a83" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">让我们假设一个实验，在这个实验中，农业科学的学生多年来从不同的农场/温室收集了一些数据。收集的数据结构如下</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lk"><img src="../Images/c3c5066a1fbb0e50069c90853403ce50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*8qog0CDzschxHHCQBq8ivw.png"/></div></figure><p id="8a7a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们想做的是在给定平均温度和土壤中平均亚硝酸盐的情况下，预测不同农场/温室的收成。为此，我们基于对数据的初步分析做出了一些假设</p><ul class=""><li id="ad99" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn lj ju jv jw bi translated">温度和土壤中平均亚硝酸盐含量与产量呈线性关系</li><li id="20e1" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">为简单起见，我们还假设其他因素，如土壤中的水分、光照等。要么不影响产量，要么在所有农场中保持相当相似</li></ul><p id="bbfa" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们将平均温度(<strong class="is hu"> C </strong>)表示为x_1，将土壤中的平均亚硝酸盐(ppm)表示为x_2，并将收获产量(kg/sq。m)作为y</p><p id="5909" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那么基于上述假设，我们可以说存在一个线性方程</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lp"><img src="../Images/b0335c18076bde3189b8670de0627937.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*p_4rY_u6meSLXvpZ_tPnhw.png"/></div></figure><p id="c597" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将很好地描述我们的自变量和因变量x_1、x_2和y之间的关系。这种关系也被称为<strong class="is hu">假设方程</strong>。我们也将它称为<strong class="is hu">型号</strong>。</p><p id="f9bb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其中w_0 <strong class="is hu">是偏置项</strong>，w_1 <strong class="is hu">和</strong> w_2 <strong class="is hu">分别是x_1和x_2的权重</strong></p><p id="f6e9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们的目标是找到w0、w1和w2的值，它们最好地描述了这种关系</p><h2 id="13c8" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">价值函数</h2><p id="45b3" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">现在让我们找到衡量模型有多好的方法。一个直接的方法是测量模型在预测中的误差。比方说</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lq"><img src="../Images/622b60c8877b4afb2e7045328dee7e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*dChPIstFKuETAYDmFhaO7g.png"/></div></figure><p id="fc1b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">哪里</strong></p><p id="987f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> Y </strong>是我们示例中已知数据的目标值<br/> <strong class="is hu"> P </strong>是相应的预测值<br/> <strong class="is hu"> err </strong>是每次预测中产生的误差</p><p id="81ee" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里err是数组值，我们需要一个单一的数值来比较哪个模型更好。</p><p id="80ff" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要将<strong class="is hu"> err </strong>值组合起来给出一个单一的值，直和或平均都不行，因为正负误差会相互抵消。</p><p id="60ef" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以我们取个体误差的平方的平均值。我们取平均值，因为我们不希望该指标依赖于训练数据的项目数量。这个值称为<strong class="is hu">均方误差(MSE) </strong>，这是我们需要最小化的成本函数。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lr"><img src="../Images/10708615ecada502368a257591fee935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*jgoypO9wK1C258bT1EXmLw.png"/></div></figure><p id="432b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用我们得到的假设函数代替上述方程中的p_i</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es ls"><img src="../Images/e74a51f031419c687d8bd000afa00242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*O_oS49IVGJpo40g2QvPUJg.png"/></div></figure><p id="70d3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们加了下标I来表示第I行数据。因此，x(I，1)表示第I行训练数据的第一个特征</p><p id="95e9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">显然，另一个有效的成本函数将是单个误差绝对值的平均值，也称为<strong class="is hu">平均绝对误差(MAE) </strong>，但由于简单起见，我们现在将使用<strong class="is hu"> MSE </strong>。</p><h2 id="3917" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">寻找最佳模型(偏差和权重)</h2><p id="746a" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">现在我们得到了上面等式(2.2)中的成本函数，让我们仔细看看它</p><ul class=""><li id="625a" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn lj ju jv jw bi translated">MSE=MSE(w_0，w_1，w_2)是具有三个变量w_0，w_1，w_2的方程，因为它们是未知值。而x和y是来自训练数据的常数</li><li id="26b1" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">我们想找出能给出最小均方差的w0，w1和w2</li></ul><p id="5a16" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们会怎么做？</p><blockquote class="kc kd ke"><p id="3100" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hb bi translated"><strong class="is hu">旁注</strong>有一种直接的方法，使用微积分，需要找到函数的偏导数，并使它们等于零。在导数连续的函数的最低点，正切将等于零(即在这一点正切从正变到负，反之亦然)。然后通过解方程组求变量值。</p><p id="5a7e" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hb bi translated">但是由于以下原因，这种方法并不总是实用的</p><p id="11e8" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hb bi translated">-对于不同类型的方程，过程会有所不同</p><p id="57aa" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hb bi translated">-如果成本函数非常复杂，则很难找到符号偏导数或求解偏导数方程</p></blockquote><h2 id="f6f0" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">梯度下降</h2><p id="22da" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">有一个通用的算法来最小化任何函数(* *函数必须是凸的，否则它只会找到局部极小值)，称为梯度下降。我们可以将梯度下降算法总结为</p><ol class=""><li id="3c70" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">选择任意一点，比如说W_a，即任意值w_0，w_1和w_2</li><li id="85d4" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">找出w0、w1和w2中的小变化，这将导致MSE的最快降低/下降。</li></ol><p id="0610" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a.为了找到小的变化，我们将分别找到在w0，w1和w2方向上MSE的变化率，这些叫做偏导数。每个方向上变化率的组合矢量称为梯度。然后我们将梯度乘以一个小数字。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lt"><img src="../Images/5ba7436ee87e52738194d7d7b10acf9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/1*YFO2hvNKGXmUFA0Lc274fA.png"/></div></figure><p id="211c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">b.其中，η是小步长，∇MSE是点W_a处MSE的梯度。∇MSE表示点W_a处MSE变化最快的方向，其大小给出了该方向成本的变化率。</p><p id="967c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.现在用下面的等式找到新的点</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lu"><img src="../Images/15dd2c6e25251c614e3c243ab7e825b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*s6CimfDEFE5VLNWUxAW0vQ.png"/></div></figure><p id="3e0b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其将具有较低的MSE值。然后用W_b替换W_a，并从步骤2开始重复指定次数，或者直到每一步中MSE的变化变得非常小</p><h2 id="6ea8" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">思维实验</h2><p id="9eae" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">为了直观地理解算法，我们来做一个思维实验。</p><p id="cd49" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假设你在一个温度场中操作一个纳米机器人(温度在三维空间中变化，并且是位置的函数)，你的目标是让机器人尽可能快地达到最低温度，否则你有损坏它的危险。</p><p id="d144" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以向机器人询问其当前位置的温度，并在三维空间中向任意方向移动机器人，你将如何引导机器人达到最低温度？</p><p id="c67f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">一些注意事项</strong></p><ul class=""><li id="1c4e" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn lj ju jv jw bi translated"><strong class="is hu">这里温度类似于成本</strong>，机器人的<strong class="is hu">位置类似于点</strong>w0，w1，w2<strong class="is hu">你的目标是找到成本最低的点。</strong></li><li id="f8f8" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">假设w_0、w_1和w_2代表左右、上下和前后轴</li><li id="5f74" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">不可能一次将MSE与w0、w1、w2相对照，因为它将在4D平面上。所以我们需要把MSE和w0，w1，w2一次一个地画出来。</li><li id="f9a3" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">如果我们绘制温度与w_0的关系图，保持w_1和w_2在某个固定值，我们会看到如下曲线。该曲线是具有凸形的二次曲线。</li></ul><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lv"><img src="../Images/2b27264423abb2af858321c33f169298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6O_R0Z6P-l6ZIwDVP7NttQ.jpeg"/></div></div></figure><p id="78f0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">您可以遵循以下步骤</strong></p><ol class=""><li id="3635" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">假设机器人从当前位置W_a开始</li></ol><p id="0796" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.求左右方向的温度变化率</p><ul class=""><li id="e023" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn lj ju jv jw bi translated">将机器人向右移动一点，获得温度，然后回到原来的位置。</li><li id="1db4" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">温度变化率是温度变化<strong class="is hu">除以移动的距离<strong class="is hu">。</strong></strong></li><li id="cf4d" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">当移动的距离趋于零时，称为对w0的偏导数，因为我们保持w1和w2不变</li></ul><p id="43bd" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.同样，你可以找到上下和前后方向的温度变化率</p><p id="6873" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.将所有三个方向上的变化率组合成矢量，给出了场中的温度梯度。它是一个矢量，有温度变化最快的方向，它的大小给出了变化率。让我们用∇T来代表它</p><p id="8c3d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.现在我们需要将机器人向∇T相反的方向移动一步，这样每一步我们都移动到更低的温度。步长应该足够小，这样就不会跳到温度可能更高的曲线的另一边(见上面的曲线)。所以机器人的新位置将会是</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lw"><img src="../Images/8ee95145e2c6c27474d676e934c81e4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*jsumcAud63YNqZJ2y6rvLw.png"/></div></figure><p id="e674" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">7.现在重复从2开始的步骤，直到你达到一个满意的温度点或者电池电量耗尽(即步骤)</p><h2 id="a70d" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">偏导数</h2><p id="fefa" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">如果我们对等式(1.1)w . r . t . w _ j取偏导数，其中j是系数指数</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lx"><img src="../Images/fba6b13f64036c4cb1b331348d246333.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*hSaMrnFbj8ElDRSGoZcRgA.png"/></div></figure><p id="6c3d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从等式(1.1)我们知道</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es ly"><img src="../Images/ab92ba3053f9f6d67ed8208caaab2bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*F1eyCjCNBlvTyt5CTdWz7w.png"/></div></figure><p id="8d83" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那么如果我们对p_i w.r.t w_j取偏导数，除了w_j，其他项都是常数。所以结果会是</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es lz"><img src="../Images/e2bd0a9393406a3010b5c360e81d9294.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*6XxTupovkJDq96e7zpxstA.png"/></div></figure><p id="fcb1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">重新安排</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es ma"><img src="../Images/9cf43824e959e7d127d8e4edb22f9ec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*ypmABk3nH8I3nqAZrKH0SA.png"/></div></figure><h2 id="30f6" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">矩阵表示</h2><p id="9a16" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">矩阵乘法等矩阵运算经过优化，比简单的数组计算更高效。矩阵表示也使方程更具可读性。所以我们将把上述方程转换成矩阵运算</p><h2 id="565d" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">使用矩阵乘法的预测</h2><p id="02c9" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">我们可以将公式1.1表示为使用矩阵运算来预测一个实例的值，以同时预测所有实例，如下所示</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mb"><img src="../Images/d6435736c46eccf18d77c2fb1bc8dbb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nwpoHJulfc3IWdbTBSwu4g.png"/></div></div></figure><p id="d1b6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">这里:</strong></p><ul class=""><li id="e147" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn lj ju jv jw bi translated"><strong class="is hu"> P </strong>是预测，它是长度为m的列向量</li><li id="4ded" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated"><strong class="is hu"> X </strong>是具有m行和n列的矩阵，m是数据点数和n个特征加上一个总是为1的偏置项</li><li id="7fb7" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">W是长度为n的列向量</li></ul><h2 id="c340" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">使用矩阵运算的梯度</h2><p id="0194" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">在等式(4.1)中，我们发现MSE w.r.t w_j的偏导数是回归模型的第j个系数，它是梯度向量的第j个分量。基于等式(4.1)，整个梯度可以使用矩阵运算来表示，例如</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mc"><img src="../Images/cf4b2e91478153db2ab52a100a45c867.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Mx1NAAz1F32wbwfR9TdpQ.png"/></div></div></figure><p id="e549" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">这里:</strong></p><ul class=""><li id="9967" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn lj ju jv jw bi translated">X^T是矩阵x的转置。它将有n行和m列</li></ul><h2 id="1650" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">训练步骤</h2><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es md"><img src="../Images/1bea8ebd0ab7b4eb5b2e457a0974e12e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*nDsGWGAsqXCsV0u35rrMLQ.png"/></div></figure><h1 id="9bc3" class="me kk ht bd kl mf mg mh kp mi mj mk kt ml mm mn kw mo mp mq kz mr ms mt lc mu bi translated">编码时间</h1><p id="5cd3" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">在这一部分，我们将使用基本的python和numpy库实现线性回归。numpy库是python中科学计算的基础包。它使得对大量数据的计算变得简单而有效。</p><h2 id="7079" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">数字游戏攻略</h2><p id="5740" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">请不要被numpy弄得不知所措，我们只会使用它的一些基本功能。将在注释中解释每个函数的作用。</p><p id="9759" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">安装Numpy </strong>如果您已经使用conda或miniconda安装了python，那么它应该已经安装好了。如果您的系统中没有安装它，您可以使用pip来安装它</p><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="38c3" class="kj kk ht mw b fi na nb l nc nd">pip install numpy</span></pre><p id="fba2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，您可以将numpy库导入您的jupyter笔记本或python文件，如下所示</p><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="07c8" class="kj kk ht mw b fi na nb l nc nd"><strong class="mw hu">import</strong> numpy <strong class="mw hu">as</strong> np</span></pre><p id="3821" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> Numpy数组操作</strong> Numpy提供了在数组上执行算术操作的简写符号，一些例子如下</p><p id="1095" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du ne nf ng mw b">arr1+arr2</code>:将返回两个数组<br/> <code class="du ne nf ng mw b">2*arr1</code>的元素之和的新数组；将arr1的每个元素乘以2 <br/> <code class="du ne nf ng mw b">arr1*arr2</code>:将返回两个数组的元素之积的新数组</p><h2 id="b17a" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">让我们生成数据</h2><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="361a" class="kj kk ht mw b fi na nb l nc nd">import numpy as np</span><span id="c97b" class="kj kk ht mw b fi nh nb l nc nd"># np.random.randn(100) will give array of 100 normally distributed random <br/># numbers with mean 0 and std-dev 1</span><span id="24c3" class="kj kk ht mw b fi nh nb l nc nd"># 2*np.random.randn(100)+12 changes the normal distrubution to have mean 12 and std-dev 2<br/>nitrate = 2*np.random.randn(100)+12<br/>temperature = 4*np.random.rand(100) + 26</span><span id="f584" class="kj kk ht mw b fi nh nb l nc nd"># np.c_ concatinates (joins) two array column wise<br/>x_farm = np.c_[nitrate,temperature]</span><span id="e6fb" class="kj kk ht mw b fi nh nb l nc nd"># This is imaginary equation describing relation between yeild, nitrate and temperature.<br/># Obiously this is not know in real world problem. We are using it to generate dummy data.<br/>yeild_ideal = .1*nitrate + .08*temperature +.6</span><span id="437a" class="kj kk ht mw b fi nh nb l nc nd"># adding some noise on the ideal equation. <br/># The noise is normally distributed with 0 mean and std-dev 0.4<br/>yeild = yeild_ideal + .4*np.random.randn(100)</span><span id="d24b" class="kj kk ht mw b fi nh nb l nc nd">print("few instances of generated data\n", x_farm[:5])<br/>print("\nfew instances of generated targets\n", yeild[:5] )</span></pre><p id="cd5a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">输出</strong></p><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="395a" class="kj kk ht mw b fi na nb l nc nd">few instances of generated data<br/> [[12.15862374 26.41754744]<br/> [ 7.7100876  26.58160233]<br/> [12.39040209 27.5565463 ]<br/> [14.89781833 26.14161419]<br/> [12.89437241 29.96356333]]<br/><br/>few instances of generated targets<br/> [4.37946646 3.41541999 3.41400057 4.3290903  3.70089309]</span></pre><h2 id="1d46" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">让我们定义一些函数</h2><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="f4b4" class="kj kk ht mw b fi na nb l nc nd"># Our equations above need bais term in x which should always be 1 <br/>def add_bais_term(x):<br/>    <br/>    # np.ones(n) will give new array of length n whose all elements are 1 <br/>    # np.c_ concatinates two array column wise<br/>    return np.c_[np.ones(len(x)),x]</span><span id="55ab" class="kj kk ht mw b fi nh nb l nc nd"># Root mean square cost function<br/>def rmse_cost_func(P,Y):<br/>    ## model is array with bais and coffecients values<br/>    return np.sqrt(np.mean((P-Y)**2))</span><span id="c61e" class="kj kk ht mw b fi nh nb l nc nd"># Finds gradient of cost function using eq(5.2) above<br/>def gradient_of_cost(x,y,model):<br/>    preds = predict(x,model)<br/>    <br/>    error_term = preds-y<br/>    <br/>    # np.matmul performs matrix multiplication<br/>    # x.T is transpose of matrix x<br/>    xt_dot_error_term = np.matmul(x.T,error_term)/len(x)<br/>    return xt_dot_error_term</span><span id="c9ac" class="kj kk ht mw b fi nh nb l nc nd"># Do prediction using eq(5.1) above<br/>def predict(x,model):<br/>    #np.matmul performs matrix multiplication<br/>    return np.matmul(x,model)</span><span id="550f" class="kj kk ht mw b fi nh nb l nc nd">def find_linear_regression_model(x,y):<br/>    n_epochs = 10000<br/>    neta = 0.001<br/>    <br/>    # Initialize all parameters(wj's) to zero<br/>    model = np.zeros(len(x[0]))<br/>    <br/>    # do n_epochs iteration<br/>    for _ in range(n_epochs):<br/>        grad = gradient_of_cost(x,y,model)<br/>        <br/>        # move parameters closer to optimum solution in every step <br/>        next_model = model - neta*grad<br/>        model = next_model<br/>    return model</span></pre><h2 id="39d3" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">火车模型</h2><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="e553" class="kj kk ht mw b fi na nb l nc nd">x_farm_with_bais = add_bais_term(x_farm)<br/>print("First 3 data with bias\n",x_farm_with_bais[:3])<br/>model = find_linear_regression_model(x_farm_with_bais, yeild)<br/>print("\nmodel(w0,w1,w2)\n", model)</span></pre><p id="9964" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">输出</strong></p><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="be97" class="kj kk ht mw b fi na nb l nc nd">First 3 data with bias<br/> [[ 1.         12.15862374 26.41754744]<br/> [ 1.          7.7100876  26.58160233]<br/> [ 1.         12.39040209 27.5565463 ]]<br/><br/>model(w0,w1,w2)<br/> [0.03759733 0.09930154 0.10164468]</span></pre><h2 id="f67c" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">预测</h2><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="7986" class="kj kk ht mw b fi na nb l nc nd"># predict yeild for <br/>yeild_predicted = predict(x_farm_with_bais, model)<br/>yeild_predicted[:15]</span></pre><p id="0c68" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">输出</strong></p><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="27f0" class="kj kk ht mw b fi na nb l nc nd">array([3.93017065, 3.50509946, 4.06895977, 4.17412975, 4.36366529,<br/>       3.79386452, 3.74566146, 3.81563257, 4.19976404, 3.90262785,<br/>       4.21451357, 4.05253678, 4.34120954, 4.06686309, 4.24635708])</span></pre><h2 id="b55c" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">评价</h2><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="7731" class="kj kk ht mw b fi na nb l nc nd">cost = rmse_cost_func(yeild_predicted,yeild)<br/>print(cost)</span></pre><p id="8c7b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">输出</strong></p><pre class="ll lm ln lo fd mv mw mx my aw mz bi"><span id="7587" class="kj kk ht mw b fi na nb l nc nd">0.3679644024562277</span></pre><p id="1a60" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">万岁！！</strong>我们现在已经实现了线性回归，并使用它来进行预测。我们还测量了RMSE，它相当于做预测时产生的绝对误差的平均值。平均误差接近随机误差的标准差，这意味着模型工作得相当好。</p><h2 id="397b" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">揭露者</h2><p id="121a" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">上面的例子只是为了从内部理解线性回归的工作原理。以下是一些需要注意的事情</p><ul class=""><li id="7114" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn lj ju jv jw bi translated">在现实世界中，我们不会像现在这样预先知道因变量和自变量之间的关系。或者，即使我们不知道关系是否是线性的，我们也可以使用散点图或其他数据分析来推断关系。</li><li id="5316" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">我们通常不会使用训练数据来评估模型的性能，因为模型可以记住训练数据以在训练数据中获得高性能，但可能无法很好地处理新的未知数据。为了避免这种情况，我们通常将数据分成三组:训练、验证和测试。验证集用于验证模型性能，并用于改进模型。只有在找到最终模型后，才使用测试集来评估模型对未知数据的性能。</li><li id="aa43" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn lj ju jv jw bi translated">这是理解核心概念的线性回归的一个非常基本的实现。我们几乎不需要自己实现。我们将始终使用来自流行库的线性回归实现，它将更加健壮、高效并提供定制参数</li></ul><h2 id="e3f4" class="kj kk ht bd kl km kn ko kp kq kr ks kt jb ku kv kw jf kx ky kz jj la lb lc ld bi translated">摘要</h2><p id="53b7" class="pw-post-body-paragraph iq ir ht is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi translated">这里是线性回归算法的简短总结</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ni"><img src="../Images/71e0e5c20e504c486e0e1e52c2fafbee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w7wok8HMkaA4kg7bwGCWOA.png"/></div></div></figure><p id="36ec" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请在这里找到整个博客和代码<a class="ae nj" href="https://gist.github.com/devbkhadka/b848ecabb5ec141e1026358779bb8b70" rel="noopener ugc nofollow" target="_blank">的jupyter笔记本文件</a></p></div></div>    
</body>
</html>