<html>
<head>
<title>Live data extraction with Cron and R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Cron和R的实时数据抽取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/live-data-extraction-with-cron-and-r-f29324bf153e?source=collection_archive---------7-----------------------#2020-04-11">https://medium.com/analytics-vidhya/live-data-extraction-with-cron-and-r-f29324bf153e?source=collection_archive---------7-----------------------#2020-04-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ebde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">了解如何使用Cron和Docker容器安排健壮的数据提取。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/3995741d908a12b35eb43d27e99e55de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lyPYVz8iWMoMRsb2in2Qiw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">我们将要提取的Google Big Query上的公共实时数据集的模式</figcaption></figure><p id="e041" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jt">这篇文章还发表在【https://www.r-bloggers.com/】<a class="ae ju" href="https://www.r-bloggers.com/" rel="noopener ugc nofollow" target="_blank"><em class="jt"/></a><em class="jt">上。</em></em></p><p id="39be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是用R和Docker构建和部署一个健壮的API的系列文章的第二部分，这个API允许您从Google Big Query中提取实时数据。第一部分见 <a class="ae ju" rel="noopener" href="/analytics-vidhya/google-big-query-with-r-875facef7844"> <em class="jt">带R的Google大查询</em> </a> <em class="jt">。关于Docker的简短介绍，请参阅关于构建和部署仪表板的文章系列的第二部分，</em> <a class="ae ju" rel="noopener" href="/analytics-vidhya/deploying-a-shiny-flexdashboard-with-docker-cca338a10d12"> <em class="jt">使用Docker </em> </a> <em class="jt">部署闪亮的Flexdashboard。</em></p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><p id="07e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi kc translated">通过数据库查询或API调用定期提取数据是构建数据基础设施的重要组成部分。这使您能够轻松地复制数据源，并在一定的延迟后获得最新的数据。另一个用例是预先计算来自不断更新的源的聚合/过滤数据，以提高服务的性能。我将向您展示如何使用Unix cron作业来安排提取。最大限度减少陈旧数据的更高级的方法是设置一个监听器或web挂钩。</p><p id="f7d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将从<a class="ae ju" href="https://openaq.org/#/?_k=h8s64f" rel="noopener ugc nofollow" target="_blank"> openAQ </a>的公共大查询实时空气质量数据集中提取数据。这是一个开源项目，提供来自5490个全球空气质量测量站的实时数据(如果你扩展“实时”的定义)，但我们将只提取印度站的测量数据。全球空气质量数据集定期更新，但旧的条目被省略，可能是为了节省存储成本。为了保存旧的度量，我们将通过Docker容器中的cron作业设置数据提取。关于Docker的简短介绍以及我们为什么使用它，请看本文。关于Google Big Query的介绍，如何访问这个公共数据集并使用<code class="du kl km kn ko b">dplyr</code>动词查询它，请参见本系列的第一部分，<a class="ae ju" rel="noopener" href="/analytics-vidhya/google-big-query-with-r-875facef7844"> Google Big Query with R </a>。</p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h2 id="4cbb" class="kp kq hi bd kr ks kt ku kv kw kx ky kz iq la lb lc iu ld le lf iy lg lh li lj bi translated">r用于调度的提取脚本</h2><p id="9b5a" class="pw-post-body-paragraph if ig hi ih b ii lk ik il im ll io ip iq lm is it iu ln iw ix iy lo ja jb jc hb bi translated">如果数据集被更新，下面的脚本将用于提取数据。你可以在<a class="ae ju" href="https://github.com/timosch29/Dockerized-Plumber-API" rel="noopener ugc nofollow" target="_blank"> github repo </a>项目中找到<code class="du kl km kn ko b">cron/src/get_data_big_query.R</code>的脚本。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><h2 id="3113" class="kp kq hi bd kr ks kt ku kv kw kx ky kz iq la lb lc iu ld le lf iy lg lh li lj bi translated">使用Cron调度提取</h2><p id="66bd" class="pw-post-body-paragraph if ig hi ih b ii lk ik il im ll io ip iq lm is it iu ln iw ix iy lo ja jb jc hb bi translated">Cron是一个调度程序，已经包含在大多数现代的基于Unix的发行版中。所谓的cron作业的调度是通过crontab管理的。您可以通过<code class="du kl km kn ko b">crontab -l</code>在crontab表中看到当前用户的cron作业，或者通过<code class="du kl km kn ko b">crontab -e</code>编辑cron作业。以下语法用于通过五个时间参数定义执行间隔:</p><pre class="je jf jg jh fd lr ko ls lt aw lu bi"><span id="9fc4" class="kp kq hi ko b fi lv lw l lx ly">* * * * * command to be executed<br/>- - - - -<br/>| | | | |<br/>| | | | ----- Day of week (0 - 7) (Sunday=0 or 7)<br/>| | | ------- Month (1 - 12)<br/>| | --------- Day of month (1 - 31)<br/>| ----------- Hour (0 - 23)<br/>------------- Minute (0 - 59)</span></pre><p id="8775" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">相反，它也可以由特殊字符串定义:</p><pre class="je jf jg jh fd lr ko ls lt aw lu bi"><span id="e9c8" class="kp kq hi ko b fi lv lw l lx ly">string         meaning<br/>              ------         -------<br/>              <a class="ae ju" href="http://twitter.com/reboot" rel="noopener ugc nofollow" target="_blank">@reboot</a>        Run once, at startup.<br/>              <a class="ae ju" href="http://twitter.com/yearly" rel="noopener ugc nofollow" target="_blank">@yearly</a>        Run once a year, "0 0 1 1 *".<br/>              <a class="ae ju" href="http://twitter.com/annually" rel="noopener ugc nofollow" target="_blank">@annually</a>      (same as <a class="ae ju" href="http://twitter.com/yearly" rel="noopener ugc nofollow" target="_blank">@yearly</a>)<br/>              <a class="ae ju" href="http://twitter.com/monthly" rel="noopener ugc nofollow" target="_blank">@monthly</a>       Run once a month, "0 0 1 * *".<br/>              <a class="ae ju" href="http://twitter.com/weekly" rel="noopener ugc nofollow" target="_blank">@weekly</a>        Run once a week, "0 0 * * 0".<br/>              <a class="ae ju" href="http://twitter.com/daily" rel="noopener ugc nofollow" target="_blank">@daily</a>         Run once a day, "0 0 * * *".<br/>              <a class="ae ju" href="http://twitter.com/midnight" rel="noopener ugc nofollow" target="_blank">@midnight</a>      (same as <a class="ae ju" href="http://twitter.com/daily" rel="noopener ugc nofollow" target="_blank">@daily</a>)<br/>              <a class="ae ju" href="http://twitter.com/hourly" rel="noopener ugc nofollow" target="_blank">@hourly</a>        Run once an hour, "0 * * * *".</span></pre><p id="0645" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以在<a class="ae ju" href="https://crontab.guru/#23_0-20/2_*_*_*" rel="noopener ugc nofollow" target="_blank">https://crontab.guru/</a>查看如何设置具体的时间间隔。请注意，有各种cron监控工具值得一看，如<a class="ae ju" href="https://deadmanssnitch.com/" rel="noopener ugc nofollow" target="_blank">https://deadmanssnitch.com/</a>或<a class="ae ju" href="https://cronitor.io/" rel="noopener ugc nofollow" target="_blank">https://cronitor.io/</a>。</p><p id="dcc9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将设置用于数据提取的cron作业，每12小时在第11分钟运行一次R脚本。这是避免与任何以整小时或五分钟间隔运行的进程发生冲突的最佳做法。因为cronjobs是在主目录中执行的，所以第一次很容易弄错文件路径。<strong class="ih hj">检查您是否有正确的文件路径</strong>到R，到R脚本，以及在R脚本中的依赖关系。在cronjob中，<code class="du kl km kn ko b">&gt;&gt; var/log/cron.log 2&gt;&amp;1</code>将脚本输出附加到一个日志文件，并将标准错误重定向到标准输出，这样我们就有了所有打印的R输出以及记录的警告和错误。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="e334" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong>如果您的开发不是在Linux中，而是在Windows中，请确保行尾序列是LF，而不是CRLF，以便它是Linux容器的有效cron。</p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h2 id="eeaa" class="kp kq hi bd kr ks kt ku kv kw kx ky kz iq la lb lc iu ld le lf iy lg lh li lj bi translated">构建Dockerimage</h2><p id="7ed7" class="pw-post-body-paragraph if ig hi ih b ii lk ik il im ll io ip iq lm is it iu ln iw ix iy lo ja jb jc hb bi translated">这假设了Docker的基本知识，如果没有看到<a class="ae ju" rel="noopener" href="/analytics-vidhya/deploying-a-shiny-flexdashboard-with-docker-cca338a10d12"> <em class="jt">用Docker</em></a>T5】部署一个闪亮的Flexdashboard。为了运行我们预定的容器化提取，我们构建了一个映像，它是通过Dockerfile 中的<a class="ae ju" href="https://docs.docker.com/registry/recipes/" rel="noopener ugc nofollow" target="_blank">食谱构建的。我们将使用来自</a><a class="ae ju" href="https://hub.docker.com/r/rocker/tidyverse/dockerfile" rel="noopener ugc nofollow" target="_blank"> Dockerhub </a>的rocker/tidyverse映像作为基础映像，并在recipe的顶部添加具有所需R库和系统依赖项的层，将包含R脚本和cronjob的目录复制到映像，最后CMD将启动cron并结束日志文件，因此输出显示在Docker容器日志中:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="2e32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后在Dockerfile运行<code class="du kl km kn ko b"><strong class="ih hj">docker build -t openaq_extraction .</strong></code>的目录中，这将从Dockerfile构建图像，并将其标记为<em class="jt"> openaq_extraction </em>。</p><p id="ac4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以导出图像并将容器部署在服务器或云服务上，如<a class="ae ju" href="https://www.ybrikman.com/writing/2015/11/11/running-docker-aws-ground-up/" rel="noopener ugc nofollow" target="_blank"> AWS </a>、<a class="ae ju" href="https://blog.machinebox.io/deploy-docker-containers-in-google-cloud-platform-4b921c77476b" rel="noopener ugc nofollow" target="_blank"> Google Cloud </a>和<a class="ae ju" href="https://blog.machinebox.io/deploy-machine-box-in-digital-ocean-385265fbeafd" rel="noopener ugc nofollow" target="_blank"> DigitalOcean </a> <strong class="ih hj"> </strong>，或者部署在本地。通过以下方式启动容器:</p><pre class="je jf jg jh fd lr ko ls lt aw lu bi"><span id="e0da" class="kp kq hi ko b fi lv lw l lx ly">$ docker run -d \<br/>  --restart=always \<br/>  --name openaq_extraction_container \<br/>  --rm \<br/>  --mount type=bind,source=/filepath_to/openaq_extraction/shared-data,target=<!-- -->/src/shared-data<!-- --> \<br/>   openaq_extraction</span></pre><p id="e523" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将在分离模式下运行容器，总是在退出时重新启动并删除保存的文件系统。此外，这会将保存提取数据的目录挂载到主机上的现有源目录，如果容器停止，您需要使用该目录来保留提取的数据。</p><p id="1d16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jt">注意:查询开放数据集会在你的谷歌云计费账户上计费，但是你每月有5TB的免费查询。如果不需要数据提取，请记住停止这个Docker容器。此外，您还有一个秘密文件，其中包含复制到Docker映像的Google Cloud凭据。这通常是不好的做法，如果您将容器部署在其他地方作为本地机器，请使用秘密管理工具。不要在Dockerhub或GitHub上分享包含秘密的Docker图片！</em>T24】</strong></p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><p id="3cd6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们已经启动并运行了一个强大的、可共享的、可重复的计划数据提取。在项目的最后一部分，我们将在Docker容器网络中使用R构建一个REST API，以便轻松访问正在提取的印度空气质量的永久记录。请参阅本系列文章的第三部分。</p></div></div>    
</body>
</html>