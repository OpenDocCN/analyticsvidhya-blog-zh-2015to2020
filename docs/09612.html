<html>
<head>
<title>Different Model Evaluation methodologies — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不同的模型评估方法—第 2 部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/different-model-evaluation-methodologies-part-2-679fcb064c55?source=collection_archive---------10-----------------------#2020-09-13">https://medium.com/analytics-vidhya/different-model-evaluation-methodologies-part-2-679fcb064c55?source=collection_archive---------10-----------------------#2020-09-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2b1a0cb07411d4094ad1d88f9f5b1d59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e8E74ZgXLD0G1e2zKWrcKg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由昆泰·德威迪拍摄</figcaption></figure><p id="9fa5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在<a class="ae js" rel="noopener" href="/@kountaydwivedi/why-is-model-evaluation-a-crucial-step-in-machine-learning-part-1-eeb4882e7c8a"> <strong class="iw hj"> <em class="jt">上一部</em> </strong> </a>中，我们回答了以下主线任务:</p><ul class=""><li id="e0bb" class="ju jv hi iw b ix iy jb jc jf jw jj jx jn jy jr jz ka kb kc bi translated">对模型评估方法的需求。</li><li id="3475" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated">差值 b/w a <strong class="iw hj"> <em class="jt">参数</em> </strong>和 a <strong class="iw hj"> <em class="jt">超参数。</em>T13】</strong></li><li id="ef41" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated">差异 b/w <strong class="iw hj"> <em class="jt">欠拟合</em> </strong>和<strong class="iw hj"> <em class="jt">过拟合</em> </strong>。</li><li id="f749" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated">究竟什么是<strong class="iw hj"> <em class="jt">偏差</em> </strong>和<strong class="iw hj"> <em class="jt">偏差</em> </strong>。</li></ul><p id="cdc2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，让我们进入核心话题…</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><blockquote class="kp"><p id="fc55" class="kq kr hi bd ks kt ku kv kw kx ky jr dx translated">模型评估技术</p></blockquote><blockquote class="kz la lb"><p id="84c4" class="iu iv jt iw b ix lc iz ja jb ld jd je le lf jh ji lg lh jl jm li lj jp jq jr hb bi translated"><strong class="iw hj">再替代评估:</strong></p></blockquote><p id="5182" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">替代法，</strong>也称为<em class="jt">剩余法</em>，<strong class="iw hj"> </strong>是最基本的方法，由于其<strong class="iw hj">过拟合问题，不推荐用于模型评估。</strong></p><ul class=""><li id="8437" class="ju jv hi iw b ix iy jb jc jf jw jj jx jn jy jr jz ka kb kc bi translated"><strong class="iw hj"> <em class="jt">关键思想:</em> <br/> <em class="jt"> ** </em> </strong>使用所有可用的数据集来拟合使用任何适当的机器学习算法的模型；此后，根据数据集和我们可用的地面实况评估模型。</li><li id="c3b7" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated"><strong class="iw hj"> <em class="jt">为什么不推荐？</em> <br/> </strong>恢复替换方法使用所有可用的数据集进行模型拟合。因此，我们不会留下任何看不见的数据来评估<em class="jt">的泛化精度。因此，我们别无选择，只能测量地面实况的准确度。但是，由于模型已经看到了相应的数据集，因此当实时或不可见的数据输入其中时，它将显示出令人敬畏的训练准确度分数(也称为替代准确度分数)，但泛化或预测准确度分数很差。这导致<strong class="iw hj">高方差</strong>超过看不见的数据。</em></li><li id="f4ca" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated">以下代码片段说明了使用 python 在 iris 数据集上实现 resubstitution 方法。</li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/a62dc14b453a8813b05e9ec7187aae27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JgPK2wz9dUuOfmSuhsDGxQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">实施替代方法(照片由 Kountay Dwivedi 拍摄)</figcaption></figure><blockquote class="kz la lb"><p id="22ea" class="iu iv jt iw b ix iy iz ja jb jc jd je le jg jh ji lg jk jl jm li jo jp jq jr hb bi translated"><strong class="iw hj">维持评估:</strong></p></blockquote><p id="c3ca" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">维持评估方法考虑到了重新替代方法的缺点，但也带来了一些缺点:</p><ul class=""><li id="cf84" class="ju jv hi iw b ix iy jb jc jf jw jj jx jn jy jr jz ka kb kc bi translated"><strong class="iw hj"> <em class="jt">关键思想:</em> </strong> <br/>首先，我们把数据集分成两部分——<strong class="iw hj">一个训练集和一个测试集。然后，我们使用训练集和适当的机器学习算法来拟合模型。最后，当我们得到最佳模型时，我们输入测试集，以便计算<em class="jt">的泛化精度。</em></strong></li><li id="74df" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated"><strong class="iw hj"> <em class="jt">缺点:<br/>* *</em></strong>Holdout 方法的<strong class="iw hj">第一个缺点</strong>与数据集的<em class="jt">简单随机分裂</em>有关。如<em class="jt">第 1 部分所述，</em>简单的随机分割可能会扭曲数据集中存在的子类比例。因此，最好使用数据集的<em class="jt">分层随机分裂</em>成训练集和测试集。<br/><strong class="iw hj"><em class="jt">* *</em></strong><strong class="iw hj">第二个缺点</strong>与<em class="jt">数据集</em>数量不足有关。<strong class="iw hj">如果我们没有足够的数据集将它分成两部分</strong>该怎么办？<em class="jt"> </em>在那种情况下，模型将永远无法学习到它的全部能力(第一部分中的<em class="jt">图— 1)。对于容量，我们指的是模型的复杂性。因此，即使我们建立了一个合适的模型来处理手头问题的复杂性，由于学习数据量较少，该模型也无法达到其容量。</em></li><li id="6ffd" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated">以下代码对应于 iris 数据集上训练/测试分割比为<strong class="iw hj"> 0.7/0.3、</strong>的维持方法。您可以调整分割比率，玩玩代码，看看准确性如何受到自己的影响。</li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/7d9141d62b7502d875e1ace1177b4e18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qyZUTeYDhKaYqSvCwUINrw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">实施单一维持验证步骤(照片由 Kountay Dwivedi 拍摄)</figcaption></figure><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/a0a8aa658bd377e78a09f111025d6df5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FApzUecuHvREZAUNnGo4VA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">说明了不同的 b/w 替换方法和保持方法。(Kountay Dwivedi 摄)</figcaption></figure><ul class=""><li id="9bfa" class="ju jv hi iw b ix iy jb jc jf jw jj jx jn jy jr jz ka kb kc bi translated"><strong class="iw hj">重复维持方法(修改后的维持评估):<br/> </strong>这是一个修改后的、更加健壮的模型评估变体。这个方法没有什么新东西，除了我们只对数据集执行一次简单的维持方法；在重复维持方法中，<strong class="iw hj">我们重复过程<em class="jt"> k </em>次，每次迭代使用不同的随机种子，这样我们每次都不会得到相同的分割。</strong>因此，我们对<em class="jt"> k 次</em>迭代执行训练/测试分割，并且在每次迭代中，我们存储计算的预测准确度分数。最后，我们对所有迭代中计算的精度进行平均。假设<em class="jt"> ACC_j </em>是第<em class="jt"> j </em>次迭代的精度得分，则<em class="jt"> ACC_avg </em>为:</li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/6b55ffd1d5ea1a182a55c06e39384ca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*QbuzBluzYiUM85Sy5_SPNw.png"/></div></figure><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/d9ba9938101de7bf949df206538f29a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pouCUo50zf5se0l-fNJ9wg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">说明<strong class="bd lt">重复保持方法</strong>，列车测试分割= 50/50。请注意精确度分数栏。它们从未达到其最大能力(由于缺乏列车组)，但装备的可变性非常低。(Kountay Dwivedi 摄)</figcaption></figure><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/8ee979a04082843f97801915b1eb658d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNO5u6WvzfPpQEzkQ4fvRA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">这是使用 90/10 的训练测试比率的<strong class="bd lt">重复保持的另一种实现。请注意，当我们改变训练测试分割比时，准确度分数是如何变化的</strong></figcaption></figure><blockquote class="kz la lb"><p id="1bd7" class="iu iv jt iw b ix iy iz ja jb jc jd je le jg jh ji lg jk jl jm li jo jp jq jr hb bi translated"><strong class="iw hj">自举法:</strong></p></blockquote><ul class=""><li id="74b2" class="ju jv hi iw b ix iy jb jc jf jw jj jx jn jy jr jz ka kb kc bi translated">我们讨论了维持方法在数据集问题上的不足。重复的维持评估在一定程度上克服了这一缺点，但并不完全。</li><li id="98b4" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated">bootstrap 方法是模型评估的一种替代方法，当我们需要的数据集数量不足时，通常会考虑这种方法。它是专门为解决小数据集问题而设计的。</li><li id="1a50" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated"><strong class="iw hj"> <em class="jt">关键思想:<br/> </em> </strong>在自举中，我们从原始数据集中反复抽取<strong class="iw hj"> <em class="jt">样本进行替换。</em> </strong>也就是说，假设我们有一袋数据集，我们从其中挑选一个数据点，复制到一个单独的<strong class="iw hj"><em class="jt">“bootstrap sample”(即训练集)</em> </strong>中，再放回袋中。<br/>我们将此过程重复<em class="jt"> n </em>次，其中<em class="jt"> n </em>等于我们袋中的数据点数。之后，我们将查看没有被选作引导样本一部分的点，并将它们保存在一个单独的集合中。这一组被称为“<strong class="iw hj"> <em class="jt">”的自付样本(即测试组)。<br/> </em> </strong>最后，我们使用 bootstrap 样本拟合一个模型，并计算随机样本的精确度。</li><li id="2875" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated">以上过程实际上是对“<strong class="iw hj"> <em class="jt"> b 自举轮”</em> </strong>的重复(即<em class="jt"> b </em>迭代<em class="jt">)。</em>最后，总精度计算为“b”引导轮计算的所有精度的平均值，类似于重复维持评估。设<em class="jt"> ACC_i </em>为第<em class="jt"> i </em>轮引导的精度，则<em class="jt"> ACC_boot ( </em>整体精度)为:</li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/57fc95ec1d60db05671e42edcd23eccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*Key9m6Tjj3SiEzZF_19yEA.png"/></div></figure><ul class=""><li id="c3f4" class="ju jv hi iw b ix iy jb jc jf jw jj jx jn jy jr jz ka kb kc bi translated">具体到上述方法的一件事是——它实际上被称为<strong class="iw hj">留一个自举(LOOB)</strong>；一种特定类型的引导方法，其中我们不使用所有数据进行训练，而是将数据集分成<em class="jt">引导样本</em>和<em class="jt">出袋样本。</em></li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c9ad7517ad56499f0fc1f449cddf7818.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dualM2NOwiYeft4NMch7Cw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图示了一个分为“自举样本”和“<em class="lv">袋外样本</em>”的自举样本(照片由 Kountay Dwivedi 拍摄)</figcaption></figure><ul class=""><li id="2274" class="ju jv hi iw b ix iy jb jc jf jw jj jx jn jy jr jz ka kb kc bi translated"><strong class="iw hj"> <em class="jt">一个短暂的缺点:<br/> </em>虽然自举评测看似朗朗上口，但它有一点不好的地方，<em class="jt">即。</em>它还患有<em class="jt">悲观偏见。但是，这是一个不同的故事，所以更多的关于这一点。</em>T53】</strong></li></ul></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="c14f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这些是一些流行的模型评估技术。关键要点是:</p><ul class=""><li id="adb7" class="ju jv hi iw b ix iy jb jc jf jw jj jx jn jy jr jz ka kb kc bi translated">替代法是一种非常幼稚的方法，不推荐使用，因为它忽视了对看不见的数据进行测试的重要性，因此会带来非常高的方差。</li><li id="ea03" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated">维持方法可以被认为是一种标准的模型评估方法。当数据集不足时，缺点就出现了。因此，可以得出结论，当数据集非常大时，<strong class="iw hj">维持法(尤其是重复维持法)最适合模型评估。</strong></li><li id="6cff" class="ju jv hi iw b ix kd jb ke jf kf jj kg jn kh jr jz ka kb kc bi translated">另一方面，我们刚刚看到了 Bootstrap 方法及其环境。并且，毫无疑问，我们可以得出结论，当数据集不足时，<strong class="iw hj"> Bootstrap 方法是一个很好的方法。</strong>请注意，自举并不是最好的方法。我们将在接下来的<a class="ae js" rel="noopener" href="/@kountaydwivedi/model-selection-techniques-part-3-d5ebb6ea4c77">最后一部</a>中看到更多。</li></ul></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><blockquote class="kp"><p id="dc46" class="kq kr hi bd ks kt ku kv kw kx ky jr dx translated">接下来—第 3 部分</p></blockquote><p id="bc0b" class="pw-post-body-paragraph iu iv hi iw b ix lc iz ja jb ld jd je jf lf jh ji jj lh jl jm jn lj jp jq jr hb bi translated">我希望这篇文章能让你保持完整和兴趣。希望你已经掌握了主要的<strong class="iw hj">模型选择技巧。</strong>那么，不再多说，让我们进入下一个也是最后一个部分，第三部分——模型选择技术。<strong class="iw hj"><em class="jt"/></strong>敬请关注，快乐学习。<br/> :-}</p></div></div>    
</body>
</html>