<html>
<head>
<title>Assemble-ResNet that is 5 times faster with the same accuracy as EfficientNet B6 + AutoAugment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Assemble-ResNet比EfficientNet B6 +自动增强快5倍，但精度相同</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/assemble-resnet-that-is-5-times-faster-with-the-same-accuracy-as-efficientnet-b6-autoaugment-c752f1835c38?source=collection_archive---------1-----------------------#2020-02-02">https://medium.com/analytics-vidhya/assemble-resnet-that-is-5-times-faster-with-the-same-accuracy-as-efficientnet-b6-autoaugment-c752f1835c38?source=collection_archive---------1-----------------------#2020-02-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="1363" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">关于这篇文章</h1><p id="eaca" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">他的帖子是对2020年1月17日发表的论文“在卷积神经网络中组合组装技术的性能改进[1]”的解释。本文提出的汇编资源网具有与B6 +自动增强相同的精度，但速度快5倍。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es kb"><img src="../Images/688408b5400c9d46f139c213374d8abe.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*lV5lGTOUuLX3qAHHjtA7TA.png"/></div></figure><p id="cdb7" class="pw-post-body-paragraph jd je hi jf b jg kj ji jj jk kk jm jn jo kl jq jr js km ju jv jw kn jy jz ka hb bi translated">本帖解释:<br/> 1。论文摘要<br/> 2。基线法、效率网和自动增强<br/> 3。汇编使用的技术-ResNet <br/> 4。结果</p><p id="ec45" class="pw-post-body-paragraph jd je hi jf b jg kj ji jj jk kk jm jn jo kl jq jr js km ju jv jw kn jy jz ka hb bi translated">本文的主要内容如下。</p><blockquote class="ko kp kq"><p id="e201" class="jd je kr jf b jg kj ji jj jk kk jm jn ks kl jq jr kt km ju jv ku kn jy jz ka hb bi translated"><strong class="jf hj">构建网络，结合一些强大的现有技术，实现与EfficientNet B6 + AutoAug相同的准确性，但速度快5倍。作者说，这里没有使用AugMix等最新的，所以精度可能还有待提高。</strong></p></blockquote></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="2151" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">基线方法</h1><p id="3b55" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这一节中，我将解释EfficientNet和AutoAugment，它们是Assemble-ResNet的基线比较。EfficientNet是一个比2019年5月提出的现有网络更轻便、更精确的网络。AutoAugment是一篇发表于2018年的论文，是一项自动搜索最佳数据增强的研究。两者都是强大的技术，经常作为图像识别的基线出现。</p><h1 id="90c4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">效率网</h1><p id="4db9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">EfficientNet [2]是2019年5月28日提交的论文，比现有网络更快更准确。的摘要如下。</p><blockquote class="ko kp kq"><p id="4cc6" class="jd je kr jf b jg kj ji jj jk kk jm jn ks kl jq jr kt km ju jv ku kn jy jz ka hb bi translated"><strong class="jf hj">他们通过同时优化分辨率、深度和通道数量来构建高速、高精度的网络。通过在等式3中设置φ = 1，在MnasNet (B0)的搜索空间中优化αβγ，然后改变φ并重复重新优化以构造B1- &gt; B </strong></p></blockquote><div class="kc kd ke kf fd ab cb"><figure class="lh kg li lj lk ll lm paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><img src="../Images/9c9838854b7a8e94e561d474adb332f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*ggY3Ev4vxk3HF7208drrQg.png"/></div></figure><figure class="lh kg lr lj lk ll lm paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><img src="../Images/19ecfe277572f70249e1bba775d5333b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*hRdfbrhCGFp0jKEFOBzUJw.png"/></div></figure></div><p id="a1d5" class="pw-post-body-paragraph jd je hi jf b jg kj ji jj jk kk jm jn jo kl jq jr js km ju jv jw kn jy jz ka hb bi translated">同时搜索深度、模型宽度(CNN频道数)和分辨率的最佳参数。通过设置三个约束参数α、β和γ找到最合适的网络。并在该范围内进行网格搜索。EfficientNet B0，B1 … B7按照严格搜索约束的顺序。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es ls"><img src="../Images/f915352be5535807976d60889d5aa810.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uqqENHojznCVSR8fa6KBxg.png"/></div></div></figure></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="387f" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">自动增强</h1><p id="ebcc" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">AutoAugment是2018年5月24日提交的论文，讲的是通过强化学习寻找最佳的数据增强方法。作者优化了由五个子策略组成的数据扩充策略，从而减少了验证数据的丢失。</p><div class="kc kd ke kf fd ab cb"><figure class="lh kg lt lj lk ll lm paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><img src="../Images/adcc7ece35bb7070fbadd437987805f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*7RiCVLyq9JE6DQsYHhnI9A.png"/></div></figure><figure class="lh kg lu lj lk ll lm paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><img src="../Images/b1d7c055ffe6ae6884aea97f5655642d.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*Zzid6MuIHE8dnnTTU2g54A.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx lz di ma mb translated">(左)自动增强流程(右)五个子策略的示例</figcaption></figure></div><p id="eb15" class="pw-post-body-paragraph jd je hi jf b jg kj ji jj jk kk jm jn jo kl jq jr js km ju jv jw kn jy jz ka hb bi translated">以下是自动增强的结果。你可以看到自动增强是一个相当强大的方法。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mc"><img src="../Images/6d9cf1aabdc1f29261b21fa810a031c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kUz_kUTbnYc958KwEOFnFw.png"/></div></div></figure></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="4a65" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">关键见解和方法</h1><p id="0a9b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">assembly-ResNet如此强大以至于能够击败EfficientNet的一点在于，它把现有的所有好的网络结构和正则化方法都放在了ResNet上。</p><p id="95c4" class="pw-post-body-paragraph jd je hi jf b jg kj ji jj jk kk jm jn jo kl jq jr js km ju jv jw kn jy jz ka hb bi translated">作者使用ResNet-D [4]、选择性内核[5]、抗混叠下采样[6]和大小网络[10]来改进ImageNet的网络架构。并使用正则化方法，标记平滑，混合[7]，丢弃块[8]，知识蒸馏[9]和自动增强[2]。</p><p id="9f10" class="pw-post-body-paragraph jd je hi jf b jg kj ji jj jk kk jm jn jo kl jq jr js km ju jv jw kn jy jz ka hb bi translated">以下部分描述了用于assembly-ResNet的网络结构改进和正则化方法。</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="e544" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">网络调整</h1><h2 id="aad0" class="md ig hi bd ih me mf mg il mh mi mj ip jo mk ml it js mm mn ix jw mo mp jb mq bi translated">网络微调1。ResNet-D</h2><p id="65e3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">ResNet-D是在CVPR2019上提出的ResNet的改进架构[4]。它的结构如下图所示，是一种可以在不增加计算成本的情况下提高精度的方法。</p><div class="kc kd ke kf fd ab cb"><figure class="lh kg mr lj lk ll lm paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><img src="../Images/cf2240d0c76fede5849245fb9a496a5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*FovR9EMZlj4XpE1Nn-q7WA.png"/></div></figure><figure class="lh kg ms lj lk ll lm paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><img src="../Images/c6f89688e3b4a89f4f345bfa0f07a66c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*H6IAcbcnIqlsRjLqoKFJpg.png"/></div></figure></div><h2 id="b5e6" class="md ig hi bd ih me mf mg il mh mi mj ip jo mk ml it js mm mn ix jw mo mp jb mq bi translated">网络调整2。选择性内核</h2><p id="be7c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">选择性核[5]的灵感来自于人类图像识别中感受野的大小因神经元而异的事实。原始选择性核方法将核大小为3×3的流、5×5卷积的流与注意力相结合。在Assemble-ResNet中，考虑到速度和精度之间的平衡，作者考虑使用通道数量翻倍的3x3滤波器，而不是使用5x5内核。作为检查的结果，采用了表2中的C3结构。</p><div class="kc kd ke kf fd ab cb"><figure class="lh kg mt lj lk ll lm paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><img src="../Images/d3b28fb5df29922b9fb069f1254ac356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*cnmnw4uLBZscpJgGP_Pvyg.png"/></div></figure><figure class="lh kg mu lj lk ll lm paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><img src="../Images/5d3eaf0b97b2ef4c5c8d9233853957ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*ZG-zm8YV-Vnqu49qnTDWcQ.png"/></div></figure></div><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mv"><img src="../Images/3c2e58a94b242026c39a98a17509905f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7b8dZ8Jgs8zgrCold-UkPg.png"/></div></div></figure><h2 id="16da" class="md ig hi bd ih me mf mg il mh mi mj ip jo mk ml it js mm mn ix jw mo mp jb mq bi translated">网络调整3。抗锯齿下采样</h2><p id="561e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">抗混叠下采样[6]是一种旨在为CNN提供移位不变量的方法。诸如MaxPooling之类的下采样方法在像素上不会变得移位不变。因此，CNN的输出对位移并不鲁棒。在下采样过程中加入反走样处理(BlurPool)是一种具有平移不变性的方法。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mw"><img src="../Images/653b65170f0f93f28b30ea06250f0387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yOERrBk_lht2hswmWFvvcQ.png"/></div></div></figure><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mx"><img src="../Images/a3657487c3934a427e0eb65fac9d616a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8Hmdz2enrKAITrcoWizcg.png"/></div></div></figure><h2 id="2c8c" class="md ig hi bd ih me mf mg il mh mi mj ip jo mk ml it js mm mn ix jw mo mp jb mq bi translated">网络调整4。大大小小的网络</h2><p id="0b56" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">大小网络是一种有效处理多种分辨率图像的网络结构。下图显示了分辨率的分支数为K = 2的示例。下面的路线处理与输入分辨率相同的图像，上面的路线处理垂直和水平方向大小为一半的图像。在Assemble-ResNet中，除了普通的残差块之外，还增加了一条处理分辨率降低的图像的路径。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es my"><img src="../Images/62cee0acf4ccacfa0b3f3bd48a2aad62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6O4Aru5b3_8-WjXRUvt8PA.png"/></div></div></figure><h1 id="7ba3" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">组装ResNet架构</h1><p id="ad27" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">使用上述技术的网络如下所示。它被配置为将上述技术添加到正常的ResNet-50。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es mz"><img src="../Images/13c2317464e385ef7996fd73173fa7c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*dZVU4SQ-LFtsdHbE6K2-rg.png"/></div></figure></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="c937" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">正规化</h1><h2 id="64b2" class="md ig hi bd ih me mf mg il mh mi mj ip jo mk ml it js mm mn ix jw mo mp jb mq bi translated">正规化1。标签平滑</h2><p id="805b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">标签平滑是一种使用像[0.1，0.9]这样的软标签而不是像[0.0，1.0]这样的热标签(硬标签)的方法。根据这项研究[11]，标签平滑具有协调每个类别的分布的效果，并且在减少对数据的过度拟合方面也是有效的(对于一个热标签，即使softmax值为0.99，也会发生惩罚)。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es na"><img src="../Images/971a2b47090c8dba30f98c4c05e359cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8y4oNDFb1cVv-XjurjzVtg.png"/></div></div></figure><h2 id="9334" class="md ig hi bd ih me mf mg il mh mi mj ip jo mk ml it js mm mn ix jw mo mp jb mq bi translated">正规化2。混合</h2><p id="58be" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">MIXUP [7]是一种混合输入和输出的数据扩充方法。从β分布中取样混合比，并混合两个数据的输入和输出。据说，在每个类的聚类之间创建插值数据，使得潜在空间被平滑。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es nb"><img src="../Images/f982e87c39a447ddb00574b087ee387b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yLV-wZx8OM5gtcyCKnDhNw.png"/></div></div></figure><h2 id="c1ae" class="md ig hi bd ih me mf mg il mh mi mj ip jo mk ml it js mm mn ix jw mo mp jb mq bi translated">正规化3。下落滑车</h2><p id="901e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">DropBlock [8]是CNN的丢弃方法。在正常掉线的情况下，图像会出现下图b所示的丢失，但与被掉线像素相邻的像素往往不会掉线，所以图像的正则化会比较弱。因此，DropBlock通过丢弃二维空间中彼此相邻的像素来增强正则化效果。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es nc"><img src="../Images/5b03c25a453862789d74e6e55442b0a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kQltoEiM741N_kQPKMdUeA.png"/></div></div></figure><h2 id="261b" class="md ig hi bd ih me mf mg il mh mi mj ip jo mk ml it js mm mn ix jw mo mp jb mq bi translated">正规化4。知识蒸馏</h2><p id="88ba" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">知识蒸馏是一种将大量高精度网络知识转移到小型轻量级网络的技术。蒸馏源的大网络称为教师模型，蒸馏目的地的小网络称为学生模型。不仅使用与正常教师标签(硬标签)的交叉熵，而且使用教师模型的输出(软标签)来训练学生模型。众所周知，使用这种方法，轻量级学生模型可以获得更高的精度，接近高精度教师模型的精度，而不是仅使用学生模型和标记数据进行学习。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es nd"><img src="../Images/396e88a40afec8d7365dcdf5f977e704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Dtpr6zpeYg_giTHaHDhBA.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">(Ref:<a class="ae ne" href="https://nervanasystems.github.io/distiller/knowledge_distillation.html" rel="noopener ugc nofollow" target="_blank">https://nerv anasystems . github . io/distiller/knowledge _ distillation . html</a>)</figcaption></figure></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="a42a" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">结果</h1><p id="59bf" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">使用上述技术的Assemble-ResNet的结果如下。Assemble-ResNet-152的精度与efficient net B6+auto augment top-1精度相当，但推理速度快5倍。mCE是模型预测对噪声的稳健程度的度量。它是使用ImageNet上带有噪声的数据集来测量的。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div class="er es kb"><img src="../Images/688408b5400c9d46f139c213374d8abe.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*lV5lGTOUuLX3qAHHjtA7TA.png"/></div></figure><p id="db8b" class="pw-post-body-paragraph jd je hi jf b jg kj ji jj jk kk jm jn jo kl jq jr js km ju jv jw kn jy jz ka hb bi translated">另外，你可以看到每一种介绍的方法都是有效的。即使没有自动增强，准确性也可与EfficientNetB3 +自动增强相媲美，推理速度快3倍以上。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es nf"><img src="../Images/f8c070a604eb81f6565bc68aa2387afa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JvZYwCNZnIYQVkv4jnjIDA.png"/></div></div></figure></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="0e6b" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">结论</h1><p id="ceb9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这篇文章中，我解释了高精度和高速汇编-ResNet。由于使用了知识提炼和自动增强，这些精度不能通过仅使用这种网络结构的一次训练来实现。但你可以看到，通过以这种方式结合现有的有效方法，即使在现实世界的任务中，也有可能实现高精度的模型。</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h2 id="008c" class="md ig hi bd ih me mf mg il mh mi mj ip jo mk ml it js mm mn ix jw mo mp jb mq bi translated">推特，我贴一句纸评论。</h2><div class="ng nh ez fb ni nj"><a href="https://twitter.com/AkiraTOSEI" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab dw"><div class="nl ab nm cl cj nn"><h2 class="bd hj fi z dy no ea eb np ed ef hh bi translated">阿基拉</h2><div class="nq l"><h3 class="bd b fi z dy no ea eb np ed ef dx translated">akira的最新推文(@AkiraTOSEI)。机器学习工程师/数据科学家/物理学硕士/…</h3></div><div class="nr l"><p class="bd b fp z dy no ea eb np ed ef dx translated">twitter.com</p></div></div><div class="ns l"><div class="nt l nu nv nw ns nx kh nj"/></div></div></a></div></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="e971" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">参考</h1><ol class=""><li id="8f53" class="ny nz hi jf b jg jh jk jl jo oa js ob jw oc ka od oe of og bi translated">李荣奎，泰伦元，基奥洪。卷积神经网络组合技术的性能改进，<em class="kr"> arXiv:2001.06268 </em></li><li id="e843" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">谭明星诉乐。反思卷积神经网络的模型缩放。<em class="kr"> arXiv:1905.11946 </em></li><li id="21e6" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">Ekin D. Cubuk，Barret Zoph，Dandelion Mane，Vijay Vasudevan，Quoc V. Le。自动增强:从数据中学习增强策略。<em class="kr"> arXiv:1805.09501 </em></li><li id="52b5" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">佟鹤年，，张航，，军，。卷积神经网络用于图像分类的技巧包。在2019年IEEE计算机视觉和模式识别会议论文集第558–567页</li><li id="844a" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">李翔、王文海、胡小林和杨坚。选择性核网络。<em class="kr"> arXiv:1903.06586 </em> ( 2019)</li><li id="5978" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">张曦轲。让卷积网络再次保持平移不变，ICML2019</li><li id="0328" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">张弘毅，混合:超越经验风险最小化，arXiv:1710.09412 (2017)</li><li id="8b82" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">高尔纳兹·吉亚西、宗-林逸和郭伏·勒。Dropblock:卷积网络的正则化方法。在<em class="kr">神经信息处理系统进展</em>，10727–10737页，2018</li><li id="4828" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">杰弗里·辛顿、奥里奥尔·维尼亚尔斯和杰夫·迪恩。从神经网络中提取知识。<em class="kr"> arXiv预印本arXiv:1503.02531 </em>，2015年。</li><li id="7354" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">春-陈辅、范全福、尼尔·马利纳、汤姆·塞尔库和罗杰奥·费里斯。大-小网络:视觉和语音识别的有效多尺度特征表示。<em class="kr"> arXiv预印本arXiv:1807.03848 </em>，2018</li><li id="9273" class="ny nz hi jf b jg oh jk oi jo oj js ok jw ol ka od oe of og bi translated">拉斐尔·米勒，西蒙·科恩布鲁斯，杰弗里·辛顿。标注平滑何时有帮助？。NeurIPS 2019(2019)</li></ol></div></div>    
</body>
</html>