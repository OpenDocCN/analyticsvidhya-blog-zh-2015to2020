<html>
<head>
<title>Demystifying Generative Adversarial Networks: Real vs Fake discriminator</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭开生成对抗网络的神秘面纱:真实与虚假鉴别器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/demystifying-generative-adversarial-networks-real-vs-fake-discriminator-bb5383ce89f9?source=collection_archive---------11-----------------------#2020-04-21">https://medium.com/analytics-vidhya/demystifying-generative-adversarial-networks-real-vs-fake-discriminator-bb5383ce89f9?source=collection_archive---------11-----------------------#2020-04-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/b60e49b67aa5bda50c2d07e2f2f49c19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*gMQpgrQUPM3kuqRSdoKuAg.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">来源—<a class="ae iq" href="https://pt.slideshare.net/ShamaneSiriwardhana/generative-adversarial-networks-slides-auckland-ai-ml-meetup" rel="noopener ugc nofollow" target="_blank">https://pt . slide share . net/shamaniseriwardhana/generative-adversarial-networks-slides-Auckland-ai-ml-meetup</a></figcaption></figure><h1 id="236c" class="ir is hi bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo bi translated">介绍</h1><p id="fbdd" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km hb bi translated"><strong class="jr hj"> <em class="kn">生成对抗网络</em> </strong>是一类神经网络，用于生成数据集的样本，也用于对真假样本进行分类。它是由Ian Goodfellow和他的同事在2014年发明的。根据<strong class="jr hj">严乐存的说法——“<em class="kn">甘的是过去20年机器学习中最酷的想法”</em> </strong>。</p><p id="8c69" class="pw-post-body-paragraph jp jq hi jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hb bi translated">它在现实生活中有很多应用。其中一些是</p><ul class=""><li id="3a86" class="kt ku hi jr b js ko jw kp ka kv ke kw ki kx km ky kz la lb bi translated">生成图像数据集的示例</li><li id="f4b3" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km ky kz la lb bi translated">图像到图像的翻译</li><li id="4124" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km ky kz la lb bi translated">文本到图像的翻译</li><li id="221f" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km ky kz la lb bi translated">生成新的人体姿态</li><li id="4858" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km ky kz la lb bi translated">照片到表情符号</li></ul></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="2952" class="ir is hi bd it iu lo iw ix iy lp ja jb jc lq je jf jg lr ji jj jk ls jm jn jo bi translated">氮化镓的结构</h1><p id="e018" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km hb bi translated"><strong class="jr hj"> <em class="kn">甘的</em> </strong>由2个神经网络组合而成。在这两个神经网络中，正式名称为<strong class="jr hj"> <em class="kn">生成器</em> </strong>的一个网络试图生成与训练样本相似的假样本，并试图欺骗另一个网络<strong class="jr hj">。</strong>另一个正式名称为<strong class="jr hj"> <em class="kn">的网络鉴别器</em> </strong>试图在那些生成的假样本和真样本之间进行分类。这样，这两个网络就相互对立地工作，以最大化自己的利润。</p></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="d75c" class="ir is hi bd it iu lo iw ix iy lp ja jb jc lq je jf jg lr ji jj jk ls jm jn jo bi translated">甘的类型</h1><ol class=""><li id="3a85" class="kt ku hi jr b js jt jw jx ka lt ke lu ki lv km lw kz la lb bi translated">香草甘- 它们是甘最简单的一种。这里，生成器和鉴别器都基于深度神经网络(简单多层感知器)架构。</li><li id="a0e6" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km lw kz la lb bi translated"><strong class="jr hj">有条件GAN - </strong>有条件GAN(CGAN)是一种GAN，在生成假样本时，将某种条件(比如说<strong class="jr hj">‘y’</strong>)施加到生成器上。</li><li id="8ace" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km lw kz la lb bi translated"><strong class="jr hj">深度卷积GAN (DCGAN): </strong> DCGAN是最流行也是最成功实现的GAN之一。它有点类似于CGAN，只是有一点不同。不同之处在于它使用卷积转置层来代替卷积层。</li><li id="17db" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km lw kz la lb bi translated"><strong class="jr hj">超分辨率GAN (SRGAN): </strong> SRGAN是一种实现GAN的方法，其中深度神经网络与对抗网络一起使用，以产生更高分辨率的图像。这种GAN在放大低分辨率图像以增强细节方面特别有用。</li></ol></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="e1dd" class="ir is hi bd it iu lo iw ix iy lp ja jb jc lq je jf jg lr ji jj jk ls jm jn jo bi translated">甘损失函数</h1><p id="4538" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km hb bi translated"><strong class="jr hj">甘的</strong>损失函数直觉基于<strong class="jr hj">极大极小博弈理论。</strong></p><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/6545f636ee956cad2d6048789444338f.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*b9uQyN4PujTFT_bKNH9SHg.png"/></div></figure><p id="bbed" class="pw-post-body-paragraph jp jq hi jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hb bi translated">这里，<strong class="jr hj"> G </strong>表示<strong class="jr hj">发电机的</strong>损耗，<strong class="jr hj"> D </strong>表示<strong class="jr hj">鉴频器的</strong>损耗</p><p id="4db7" class="pw-post-body-paragraph jp jq hi jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hb bi translated">根据维基百科—</p><blockquote class="mc"><p id="0ae2" class="md me hi bd mf mg mh mi mj mk ml km dx translated">Minimax是人工智能、决策理论、博弈论、统计学和哲学中使用的决策规则，用于最小化最坏情况(最大损失)场景的可能损失。</p></blockquote><p id="dbe3" class="pw-post-body-paragraph jp jq hi jr b js mm ju jv jw mn jy jz ka mo kc kd ke mp kg kh ki mq kk kl km hb bi translated">你可以在我文章最后的链接中读到更多关于极大极小理论的内容。</p><h2 id="9421" class="mr is hi bd it ms mt mu ix mv mw mx jb ka my mz jf ke na nb jj ki nc nd jn ne bi translated">公式</h2><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es nf"><img src="../Images/393780aa6d7c58356aa0e010251b9017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*RAarofxuc4eJ-cvWWef-IQ.png"/></div></figure><ul class=""><li id="1a71" class="kt ku hi jr b js ko jw kp ka kv ke kw ki kx km ky kz la lb bi translated"><code class="du ng nh ni nj b">D(x)</code>是鉴别器对真实数据实例x为真实的概率的估计。</li><li id="01ba" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km ky kz la lb bi translated">Ex是所有真实数据实例的期望值。</li><li id="4017" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km ky kz la lb bi translated"><code class="du ng nh ni nj b">G(z)</code>是给定噪声z时发电机的输出。</li><li id="9b0b" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km ky kz la lb bi translated"><code class="du ng nh ni nj b">D(G(z))</code>是鉴别者对假实例为真的概率的估计。</li><li id="c9f8" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km ky kz la lb bi translated">E𝓏是对生成器的所有随机输入的期望值(对所有生成的伪实例G(z)的期望值)。</li><li id="1c72" class="kt ku hi jr b js lc jw ld ka le ke lf ki lg km ky kz la lb bi translated">该公式源自真实分布和生成分布之间的交叉熵。</li></ul><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="er es nk"><img src="../Images/60beb67fe796a9a064f28f6f07d1aa1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BE-NWPN4sIjJqFqPGdrjYw.jpeg"/></div></div></figure><h2 id="1de5" class="mr is hi bd it ms mt mu ix mv mw mx jb ka my mz jf ke na nb jj ki nc nd jn ne bi translated">上述公式的直觉</h2><p id="45b7" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km hb bi translated">对于鉴别器和发生器，上述公式可以有不同的解释。我们先来讨论一下鉴频器的情况——</p><p id="109b" class="pw-post-body-paragraph jp jq hi jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hb bi translated">对于鉴别器，上述公式可以理解为— <strong class="jr hj"> D(x) </strong>显示了我们的鉴别器能够将真实样本分类为真实样本的程度。如果它归类为实数，<strong class="jr hj">D(x)</strong><strong class="jr hj">≈</strong><strong class="jr hj">1</strong><strong class="jr hj">log(D(x))</strong><strong class="jr hj">≈0s</strong>如果不是，<strong class="jr hj">D(x)</strong><strong class="jr hj">≈</strong><strong class="jr hj">0 log(D(x))</strong>将是大负数<strong class="jr hj">。</strong>类似地，<strong class="jr hj"> D(G(z)) </strong>显示了我们的鉴别器能够多好地将生成器生成的假样本识别为假的。如果正确识别为假，<strong class="jr hj">D(G(z))</strong><strong class="jr hj">≈0 log(1—D(G(z))))≈0</strong>如果不正确，<strong class="jr hj">D(G(z))</strong><strong class="jr hj">≈1 log(1—D(G(z)))</strong>将是一个很大的负数。这样，鉴别器试图最小化上述损失函数。</p><p id="5821" class="pw-post-body-paragraph jp jq hi jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hb bi translated">现在来看发电机的例子—</p><p id="45fd" class="pw-post-body-paragraph jp jq hi jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hb bi translated">对于生成器，术语<strong class="jr hj"> log(D(x)) </strong>将是无用的，因为生成器不会被引入到任何真实样本中，相反，它仅被引入到训练样本的潜在特征中。以及术语<strong class="jr hj"> D(G(z)) ≈ </strong> <strong class="jr hj"> 1 </strong>如果生成器能够生成与训练样本非常相似的假样本。</p><p id="02fb" class="pw-post-body-paragraph jp jq hi jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hb bi translated">通过这种方式，生成器和鉴别器同时工作，以获得最佳结果。</p></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><p id="19a1" class="pw-post-body-paragraph jp jq hi jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hb bi translated">这次都是我这边的。下次会有另一个有趣的话题。</p><div class="np nq ez fb nr ns"><a href="https://en.wikipedia.org/wiki/Minimax" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab dw"><div class="nu ab nv cl cj nw"><h2 class="bd hj fi z dy nx ea eb ny ed ef hh bi translated">极大极小</h2><div class="nz l"><h3 class="bd b fi z dy nx ea eb ny ed ef dx translated">极大极小值(有时是最小最大值，MM或鞍点)是人工智能，决策理论…</h3></div><div class="oa l"><p class="bd b fp z dy nx ea eb ny ed ef dx translated">en.wikipedia.org</p></div></div></div></a></div></div></div>    
</body>
</html>