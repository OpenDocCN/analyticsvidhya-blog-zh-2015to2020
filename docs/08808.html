<html>
<head>
<title>Tutorial: A detailed notebook on Keras Sequential API (Tensorflow 2.0)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">教程:关于Keras顺序API (Tensorflow 2.0)的详细笔记</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tutorial-a-detailed-notebook-on-keras-sequential-api-tensorflow-2-0-30480ca8ea73?source=collection_archive---------9-----------------------#2020-08-14">https://medium.com/analytics-vidhya/tutorial-a-detailed-notebook-on-keras-sequential-api-tensorflow-2-0-30480ca8ea73?source=collection_archive---------9-----------------------#2020-08-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0afa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di"> S </span> o，这是我上一篇教程<a class="ae jm" rel="noopener" href="/analytics-vidhya/tutorial-a-quick-overview-of-tensorflow2-0-b28e5c6906fa">的下一部分教程:tensorflow2.0 </a>快速概览。在上一个教程中，我们学习了tensorflow2.0的所有基础知识和不同类型的Keras API。</p><p id="f9d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看看吧！如果你还没有！链接在上面。</p><p id="cc07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么我们就从Keras tensorflow2.0中的顺序API的详细分析开始吧，这里我们要借助顺序API在Titanic数据集上进行预测。你可以从<a class="ae jm" href="https://www.kaggle.com/c/titanic/data" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据集。和我一起做这件事。</p><p id="129b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我以前告诉过你的。我首选的运行tensorflow2.0的方式是Google Colab。它为我们提供CPU/ GPU/ TPU支持。在Google Colab中，直接导入TensorFlow，它会返回给你最新的版本。Keras运行tensorflow2.0作为后端。</p><blockquote class="jn jo jp"><p id="b1ce" class="if ig jq ih b ii ij ik il im in io ip jr ir is it js iv iw ix jt iz ja jb jc hb bi translated">我将在下一篇教程中展示如何将任何Kaggle数据集直接下载到Google Colab中。(此处将编辑/更新<a class="ae jm" href="https://media.giphy.com/media/3oz8xqUy7P6IWIq8G4/giphy.gif" rel="noopener ugc nofollow" target="_blank">链接。)</a></p></blockquote><ol class=""><li id="c5d6" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated"><strong class="ih hj">导入库</strong>:让我们导入助手库。</li></ol><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="cf8d" class="km kn hi ki b fi ko kp l kq kr"><em class="jq"># Import Basic Libraries<br/> </em><br/>import numpy as np <em class="jq"># numerical data processing</em><br/>import pandas as pd <em class="jq"># data processing, CSV file I/O</em></span><span id="8bc4" class="km kn hi ki b fi ks kp l kq kr"># This will be some files of titanic dataset downloaded from kaggle<br/>titanic/train.csv<br/>titanic/gender_submission.csv<br/>titanic/test.csv</span></pre><p id="8c7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们导入所需的TensorFlow库。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="a856" class="km kn hi ki b fi ko kp l kq kr"># Sklearn.preprocessing module for preprocessing of data <br/>from sklearn import preprocessing</span><span id="433f" class="km kn hi ki b fi ks kp l kq kr"># Import Keras from tensorflow backend<br/>from tensorflow.python import keras</span><span id="9841" class="km kn hi ki b fi ks kp l kq kr"># SimpleImputer for filling missing values<br/>from sklearn.impute import SimpleImputer</span><span id="5b14" class="km kn hi ki b fi ks kp l kq kr"># Import tensorflow<br/>import tensorflow as tf</span><span id="b014" class="km kn hi ki b fi ks kp l kq kr"># Import Sequential class (i.e for putting it together)<br/>from tensorflow.python.keras.models import Sequential</span><span id="c008" class="km kn hi ki b fi ks kp l kq kr"># Import different layers from Layer class<br/>from tensorflow.python.keras.layers import Dense, Dropout</span></pre><blockquote class="jn jo jp"><p id="9a15" class="if ig jq ih b ii ij ik il im in io ip jr ir is it js iv iw ix jt iz ja jb jc hb bi translated">在这里，我们导入将用于这个项目的库。我们将使用Keras库构建一个序列模型，并实现dropout来对抗任何类型的过度拟合。我们将使用sklearn的简单估算器来填充不在数据集中的值，并使用LabelEncoder来标记分类值，以便它们是数字值。</p></blockquote><p id="64b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">导入数据:</strong>现在让我们导入本地目录中的titanic数据集。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="0869" class="km kn hi ki b fi ko kp l kq kr"># Import Data<br/>train_data = 'titanic/train.csv'<br/>test_data = "titanic/test.csv"</span></pre><blockquote class="jn jo jp"><p id="89fe" class="if ig jq ih b ii ij ik il im in io ip jr ir is it js iv iw ix jt iz ja jb jc hb bi translated">对于接下来的2个单元格，我们将把csv文件转换成Pandas数据集。在我们将它们加载到Pandas中之后，我们将使用head()方法来检查文件是否被正确加载。</p></blockquote><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="5a5c" class="km kn hi ki b fi ko kp l kq kr"># Load data in pandas dataframe<br/>train = pd.read_csv(train_data, index_col = "PassengerId")</span><span id="6018" class="km kn hi ki b fi ks kp l kq kr"># Take look at the data<br/>train.head()</span></pre><figure class="kd ke kf kg fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es kt"><img src="../Images/e546a6337f8599c311bc60a42067fc8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lzjVFXKWQs6H3qjBnCk9sw.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">上述单元的输出</figcaption></figure><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="fa4c" class="km kn hi ki b fi ko kp l kq kr"># Load data in pandas dataframe<br/>test = pd.read_csv(test_data)</span><span id="d5d1" class="km kn hi ki b fi ks kp l kq kr"># Take look at the test data<br/>test.head()</span></pre><figure class="kd ke kf kg fd ku er es paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="er es lf"><img src="../Images/66866a796bf41f581b2ed1dad7457d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bG4YBinPe6ZsfW16B5xCeA.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">测试数据如上所示</figcaption></figure><p id="a680" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">厉害！一切看起来都已经正确加载。所以我们想去掉一些数据，因为它对我们的模型影响很小，甚至可能完全破坏我们的模型。有太多唯一值或缺少值的列对我们来说几乎没有用处。有一个方法可以返回一个列中所有唯一的值，但是我们在这里只是使用常识，说我们不想要这些列(“Name”、“Cabin”、“Ticket”)。这些都是对我们的模型的准确性几乎没有影响的列，甚至更糟的是可能使数据过度拟合，使它看起来在我们的验证集上表现很好，但在我们的测试集或真实世界中表现很差。这是因为模型将开始学习唯一变量(如名称)，并在训练时给它们太重的权重。我们可以通过使用drop()方法来实现这一点，但是我们会用一种不同的方式来排除它们，我稍后会对此进行解释。</p><p id="a47c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于我们的下一个单元格，我们将使用LabelEncoder。我可以从sklearn . preprocessing import label encoder中使用“<strong class="ih hj"> <em class="jq">”完全导入上面的内容，但是我还想展示另一种访问它的方法。我们已经导入了预处理，所以我们可以用点符号来访问这个方法。我们需要做的第一件事是找出哪些列是分类的(需要标记)，然后找出哪些列是数字的。我们可以通过简单地查找我们在上面打印了几个单元格的表格来做到这一点。对于标签编码，我们需要我们的分类列(任何不是int或float的列)，所以我们有(" Name "、" Sex "、" Cabin "、" Embarked ")。我们不希望名字或小屋出现在最终的训练集中，所以我们不会费心给它们贴标签。</em></strong></p><p id="e3f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，让我们继续前进，使自己成为一个标签编码器。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="9312" class="km kn hi ki b fi ko kp l kq kr"># Create Labelencoder object<br/>encoder = preprocessing.LabelEncoder()</span></pre><blockquote class="jn jo jp"><p id="f7a6" class="if ig jq ih b ii ij ik il im in io ip jr ir is it js iv iw ix jt iz ja jb jc hb bi translated">很简单吧！接下来，我们将列出要编码到数据中的特征。</p></blockquote><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="2622" class="km kn hi ki b fi ko kp l kq kr"># Select categorical features<br/>cat_features = ["Sex", "Embarked"]</span></pre><p id="7082" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们实际编码我们的标签时，我们会得到一个错误，说apolloed不属于str类型，但只用于训练数据集，而不是测试数据集。太奇怪了！这很容易解决。astype()方法！因此，我们将从我们的训练熊猫中提取列，并用下面的这行代码将其转换为一列字符串。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="e821" class="km kn hi ki b fi ko kp l kq kr">train["Embarked"] = train["Embarked"].astype(str)</span></pre><p id="e4f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们对训练和测试数据集进行编码。为什么？因为我们正在训练我们的模型，即“性别”列只有1和0，当我们进行预测时，它将无法连接“男性”是0或“女性”是1。因此，我们创建了一个编码数据集，其中包含我们为编码而留出的列(cat_features)。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="e4ad" class="km kn hi ki b fi ko kp l kq kr">encoded_train = train[cat_features].apply(encoder.fit_transform)<br/>encoded_test = test[cat_features].apply(encoder.fit_transform)</span></pre><p id="da5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们必须将所有的数字列(除了“Ticket”)放在一个列表中，我们还需要将测试数据的所有数字列(除了“Ticket”)放在一个组中。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="ec14" class="km kn hi ki b fi ko kp l kq kr"># Select num features<br/>num_features = ["Survived","Pclass","Age","SibSp","Parch","Fare"]<br/>test_features= ["Pclass","Age","SibSp","Parch","Fare"]</span></pre><p id="224a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，这就是我们创造奇迹的地方。我们会将编码数据重新加入到我们的常规测试和训练集中。但是当我们这样做时，我们将只接受我们想要的列(除了姓名、客舱和机票之外的所有内容)，并且我们已经做了所有的工作来实现这一点！</p><blockquote class="jn jo jp"><p id="1985" class="if ig jq ih b ii ij ik il im in io ip jr ir is it js iv iw ix jt iz ja jb jc hb bi translated">让我们看看我们的新数据是什么样的。</p></blockquote><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="b9eb" class="km kn hi ki b fi ko kp l kq kr">training_data.head()</span></pre><figure class="kd ke kf kg fd ku er es paragraph-image"><div class="er es lg"><img src="../Images/fe5f9453595fa6fc0d8ff3a2014a647e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*9PIFeAxi40hxPYtzQw-sOQ.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">预处理后的数据是这样的！</figcaption></figure><blockquote class="jn jo jp"><p id="8fbf" class="if ig jq ih b ii ij ik il im in io ip jr ir is it js iv iw ix jt iz ja jb jc hb bi translated">还有测试的那个。</p></blockquote><figure class="kd ke kf kg fd ku er es paragraph-image"><div class="er es lg"><img src="../Images/4dab12e55fa3c5ccf778d634bf536cf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*lz9LkX1_40k5v16c-AK6Hg.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">预处理后的测试数据是这样的！并且必须对两种数据进行相同的预处理。</figcaption></figure><p id="b390" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">酷，现在我们的数据是我们的模型可以理解的格式，但是等等，有没有丢失的值？！让我们通过使用<strong class="ih hj"> isnull() </strong>方法和<strong class="ih hj"> sum() </strong>方法获得数据中所有空值的总和来进行检查。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="fc9c" class="km kn hi ki b fi ko kp l kq kr"># Look for null values<br/>training_data.isnull().sum()</span></pre><figure class="kd ke kf kg fd ku er es paragraph-image"><div class="er es lh"><img src="../Images/cf27f4f43eda9c7c4f4f26dc910a2dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*-D6gmThbH394HA6wZeqlmQ.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">那么谁最缺少价值观呢？</figcaption></figure><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="49d6" class="km kn hi ki b fi ko kp l kq kr"># Look for missing values in test data<br/>test_data.isnull().sum()</span></pre><figure class="kd ke kf kg fd ku er es paragraph-image"><div class="er es lh"><img src="../Images/c4ddd55be279f62d5d1d8ee46fbb3030.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*oWniBuVrl9na9d5Yec_IOA.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">你现在只看！</figcaption></figure><p id="e463" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看起来我们的数据还没有完全准备好。这里有很多选择。我们可以放弃列年龄，但我们不喜欢丢失所有这些数据。我们可以用0填充它，但我们不希望它过多地偏离我们的数据，所以让我们继续使用插补来填充这些值。插补允许您使用列表中所有缺失年龄的平均值等值来填充值。这似乎是保持模型准确的最佳选择。</p><p id="4f73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将在同一个单元格中定义估算器并转换我们的数据集。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="7a93" class="km kn hi ki b fi ko kp l kq kr"># Define Imputer object<br/>my_imputer = SimpleImputer()</span><span id="2b65" class="km kn hi ki b fi ks kp l kq kr"># Fit and transform train data<br/>imputed_train = pd.DataFrame(my_imputer.fit_transform(training_data))</span><span id="7d87" class="km kn hi ki b fi ks kp l kq kr"># Fit and transform test data<br/>imputed_test_data = pd.DataFrame(my_imputer.fit_transform(test_data))</span></pre><p id="8ed8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们再次检查我们的数据。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="3edc" class="km kn hi ki b fi ko kp l kq kr">imputed_train.head()</span></pre><figure class="kd ke kf kg fd ku er es paragraph-image"><div class="er es li"><img src="../Images/2860bffd7200666a0c156dc021e41e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*GeZcYnQckypU3-5112w6RA.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">估算数据！</figcaption></figure><p id="0653" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">呃哦！看起来我们的列标签不见了！我们的索引标签也是如此！这很好，我将保留索引标签，因为它们并不重要，但我们确实需要重置列标签。每次估算时都会发生这种情况，需要解决。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="51c3" class="km kn hi ki b fi ko kp l kq kr"># Apply col names again<br/>imputed_train.columns = training_data.columns<br/>imputed_test_data.columns = test_data.columns</span></pre><blockquote class="jn jo jp"><p id="35ad" class="if ig jq ih b ii ij ik il im in io ip jr ir is it js iv iw ix jt iz ja jb jc hb bi translated">我们检查我们的数据</p></blockquote><figure class="kd ke kf kg fd ku er es paragraph-image"><div class="er es lj"><img src="../Images/1e371962749b61556f00226d9ba3c6c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*I51pORjWxJUjQpYteMKwxw.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">对不对？</figcaption></figure><p id="4c3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">终于！我们的数据已经准备好为我们的模型拆分。我们有我们想要预测的(y ),还有我们需要定义的预测因子(X)。对于X，我们将创建一个没有“<strong class="ih hj">幸存</strong>”的熊猫数据帧，因为这是我们试图预测的。我们告诉代码它可以在axis=1上找到(它表示列)。我们给Y贴上标签，除了“<strong class="ih hj">幸存</strong>”。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="d829" class="km kn hi ki b fi ko kp l kq kr"># Drop the target column<br/>X = imputed_train.drop("Survived", axis = 1)</span><span id="76f1" class="km kn hi ki b fi ks kp l kq kr"># Store the target column in y<br/>y = imputed_train["Survived"]</span><span id="b56e" class="km kn hi ki b fi ks kp l kq kr">X.shape # (891, 7)</span></pre><p id="9d31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一切看起来都很好！现在我们设置我们的随机种子。它可以是您想要的任何数字，但建议您为模型一致性设置一个数字。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="7576" class="km kn hi ki b fi ko kp l kq kr">tf.random.set_seed(42)</span></pre><p id="6cbd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在是时候建立我们的模型了！我们将构建一个<strong class="ih hj">顺序模型</strong>。这是您可以从头开始构建模型的地方。我知道这是一个初学者教程，但我们不会把这个弄得太复杂。让我们从定义模型变量开始。</p><blockquote class="jn jo jp"><p id="8a78" class="if ig jq ih b ii ij ik il im in io ip jr ir is it js iv iw ix jt iz ja jb jc hb bi translated">什么是<em class="hi">顺序API </em>？(一般来说)在这里勾选<a class="ae jm" rel="noopener" href="/analytics-vidhya/tutorial-a-quick-overview-of-tensorflow2-0-b28e5c6906fa">和</a></p></blockquote><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="ac92" class="km kn hi ki b fi ko kp l kq kr"># Create model object of Sequential type<br/>model = Sequential()</span></pre><p id="a0e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将第一层设置为具有7个神经元的<strong class="ih hj">密集</strong>，以及一个“<strong class="ih hj"> Relu </strong>激活函数。理解本笔记本的所有激活功能并不是非常重要，但建议您了解它们是什么以及如何使用它们。第一层需要始终具有参数input_shape。我们可以在使用shape方法的地方查找，找出它是什么。形状列为(891，7)，我们将输入行，因此input_shape为(7，)。我们还实现了一个叫做dropout的方法。简而言之，它在训练时关闭随机神经元，以避免过度拟合。使用参数(0.2)，我们告诉它关闭20%的神经元。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="120e" class="km kn hi ki b fi ko kp l kq kr"># Add dense layer to sequence with add() function.<br/>model.add(Dense(7, activation = "relu", input_shape = (7,)))</span><span id="cb6a" class="km kn hi ki b fi ks kp l kq kr"># Add dropout layer to sequence with add() function.<br/>model.add(Dropout(0.2))</span></pre><p id="b927" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们添加2个更密集的层，有50个神经元，重新激活。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="ba55" class="km kn hi ki b fi ko kp l kq kr"># Add more<br/>model.add(Dense(50, activation = "relu"))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(50, activation = "relu"))</span></pre><p id="0f21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们添加我们的输出层。我们有2个类或从这个死或活(1或0)的结果，所以我们指定的层。我们正在使用softmax激活来对乘客生存进行分类。Softmax将返回每个结果的概率，我们将选择最高的概率作为我们的预测。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="40eb" class="km kn hi ki b fi ko kp l kq kr"># Add output dense layer<br/>model.add(Dense(2, activation = "softmax"))</span></pre><p id="1bcb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">是时候将所有这些层编译在一起并构建模型了！我们需要定义我们的损失测量、我们的优化器和我们的准确性测量。有许多不同的选择，你绝对应该尝试一下。Adam被认为是最好的优化者之一，你的准确性指标总是取决于你的模型和它预测的数据。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="881a" class="km kn hi ki b fi ko kp l kq kr"># Compile the model (It's like providing metadata)<br/>model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer = "adam", metrics = ['accuracy'])</span></pre><p id="73fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">是时候调整(训练)我们的模型了！我们传递之前得到的X和y数据。我们的批量大小将是1，因为我们不会一次查看一个以上的乘客。历元是它将经历的训练周期的数量。我们将分离出20%的数据进行验证。如果您想观看实际的训练，可以将verbose更改为1。我觉得这很令人兴奋，但我相信如果其他人试图这样做，他们会觉得自己在看着油漆变干。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="1894" class="km kn hi ki b fi ko kp l kq kr"># Train the model<br/>model.fit(X, y,<br/>          batch_size=1,<br/>          epochs=700,<br/>          validation_split = 0.2,<br/>          verbose = 0)</span><span id="1ad5" class="km kn hi ki b fi ks kp l kq kr"># It returns training history<br/># Output will be &lt;tensorflow.python.keras.callbacks.History at 0x7f576807d1d0&gt;</span></pre><p id="9308" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我看着我的模特接受训练！</p><blockquote class="jn jo jp"><p id="50c1" class="if ig jq ih b ii ij ik il im in io ip jr ir is it js iv iw ix jt iz ja jb jc hb bi translated">一个小时后……除非你不用谷歌可乐。</p></blockquote><p id="3980" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们使用刚刚建立的模型来进行预测！</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="dcc9" class="km kn hi ki b fi ko kp l kq kr"># Make prediction<br/>preds = model.predict(imputed_test_data)</span></pre><p id="4e40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看它是什么样子的</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="39b7" class="km kn hi ki b fi ko kp l kq kr">print(preds)</span></pre><figure class="kd ke kf kg fd ku er es paragraph-image"><div class="er es lk"><img src="../Images/e6c7ecba44e15ec639d3d1783a37012b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*k3F6JOZQZ3ptX2tJh_TzEQ.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">这是什么？这是一个很长的列表</figcaption></figure><p id="6577" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这不是我们想要的！还记得我说过Softmax会返回每个答案的概率吗？我们需要选择概率最高的一个作为我们的预测。我们将使用<strong class="ih hj"> argmax </strong>()方法来实现这一点。</p><pre class="kd ke kf kg fd kh ki kj kk aw kl bi"><span id="dbae" class="km kn hi ki b fi ko kp l kq kr"># Single valued predictions<br/>predictions = np.array(model.predict(imputed_test_data)).argmax(axis=1)<br/>print(predictions)</span></pre><figure class="kd ke kf kg fd ku er es paragraph-image"><div class="er es lk"><img src="../Images/ce2b1824f7a1b7b6b179174490e5fe5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*6-I1CZIFTse-99N9Gt11Ew.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">输出是正的还是负的</figcaption></figure><h1 id="950b" class="ll kn hi bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">恭喜你从零开始为泰坦尼克号的生存预测建立了一个人工智能模型！</h1><figure class="kd ke kf kg fd ku"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">干杯！</figcaption></figure><p id="5ec3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来的教程，我们将学习！</p><ol class=""><li id="634b" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">如何评价回归模型？链接会在这里。</li><li id="2974" class="ju jv hi ih b ii mk im ml iq mm iu mn iy mo jc jz ka kb kc bi translated">如何评价分类模型？链接会在这里。</li><li id="75ea" class="ju jv hi ih b ii mk im ml iq mm iu mn iy mo jc jz ka kb kc bi translated">教程:关于Keras Functional API(tensor flow 2.0)的详细笔记本。链接会在这里。</li><li id="644d" class="ju jv hi ih b ii mk im ml iq mm iu mn iy mo jc jz ka kb kc bi translated">教程:Keras子类化API的详细笔记本(Tensorflow 2.0)。链接会在这里。</li><li id="9b85" class="ju jv hi ih b ii mk im ml iq mm iu mn iy mo jc jz ka kb kc bi translated">如何将Kaggle数据集直接下载到Google Colab中？链接会在这里。</li></ol><p id="c87c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好吧，那我就告辞了，完整的代码可以在这里找到。</p><h1 id="d45a" class="ll kn hi bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">谢谢大家！</h1></div></div>    
</body>
</html>