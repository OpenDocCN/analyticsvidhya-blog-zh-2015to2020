<html>
<head>
<title>Natural Language Processing — Basic Concepts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理—基本概念</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/natural-language-processing-basic-concepts-a3c7f50bf5d3?source=collection_archive---------12-----------------------#2020-10-04">https://medium.com/analytics-vidhya/natural-language-processing-basic-concepts-a3c7f50bf5d3?source=collection_archive---------12-----------------------#2020-10-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="41c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">让我们学习如何使用 Python 中一个简单有效的工具包——自然语言工具包</em><strong class="ih hj"><em class="jd">NLTK——来处理(基本上是理解)自然语言(非结构化数据的大文本)。</em> </strong> <em class="jd">(大部分)</em></p><p id="50e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们有趣的用例是处理 F.R.I.E.N.D.S .的脚本…这是我最喜欢的一集<strong class="ih hj"> <em class="jd">【拿着所有扑克的那个】</em> </strong>的开始脚本</p><blockquote class="je jf jg"><p id="a104" class="if ig jd ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">罗斯:嗯，瑞秋，我们这里的简历快用完了。</p><p id="67e6" class="if ig jd ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">莫妮卡:你真的想要一份大众机械师的工作吗？</p><p id="d0ee" class="if ig jd ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">好吧，如果你想为机械师工作，那就为他们工作吧。</p><p id="4311" class="if ig jd ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">嘿，听着，伙计们，我什么都愿意做，好吗？我不能再做服务员了，我是认真的。我受够了糟糕的小费，我受够了被人叫对不起。</p><p id="7e80" class="if ig jd ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">罗斯:瑞秋，你校对过这些吗？</p><p id="f142" class="if ig jd ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">瑞秋:嗯……是的，怎么了？</p><p id="b0bb" class="if ig jd ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">罗斯:嗯，没什么，我相信他们会对你出色的电脑技能印象深刻。</p><p id="8572" class="if ig jd ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">瑞秋:(沮丧地)哦，我的天啊！哦，你认为它们都在上面吗？</p><p id="91ce" class="if ig jd ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">乔伊:哦，不，我确定复印机有拍到一些。</p></blockquote><p id="99db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">怀旧。无论如何，让我们分析这篇课文，好吗？但是首先..</p><h2 id="71d8" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated">下载/导入 NLTK 库</h2><p id="88e1" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">首先<a class="ae kk" href="https://www.nltk.org/install.html" rel="noopener ugc nofollow" target="_blank">安装 NLTK </a>并检查你是否安装了它，要么导入它，要么查看命令“pip show nltk”是否给出任何输出。</p><p id="9b55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，您可能希望下载 NLTK 库下最“流行”的数据+预训练模型列表，因此使用以下代码:</p><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="89bb" class="jk jl hi kq b fi ku kv l kw kx">import nltk<br/>nltk.download(‘popular’) #run this once, no need to run it again</span></pre><h1 id="1196" class="ky jl hi bd jm kz la lb jq lc ld le ju lf lg lh jx li lj lk ka ll lm ln kd lo bi translated"><em class="lp"> 1。符号化</em></h1><p id="76ac" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">Tokenize 基本上意味着将文本字符串转换成单词列表。</p><h2 id="5694" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated">转换成句子= &gt;句子标记化:</h2><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="12de" class="jk jl hi kq b fi ku kv l kw kx">sentences = nltk.sent_tokenize(script)<br/>print(sentences)</span><span id="3db5" class="jk jl hi kq b fi lq kv l kw kx"><strong class="kq hj">OUTPUT:</strong> ["Ross: Uh, Rach, we're running low on resumes over here.", 'Monica: Do you really want a job with Popular Mechanics?', "Chandler: Well, if you're gonna work for mechanics, those are the ones to work for." .. (and so on)</span></pre><h2 id="a8c7" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated">转换为单词= &gt;单词标记化:</h2><p id="deab" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">我们可以将每个句子或整个脚本转换成单词，但是我们需要删除像句号、省略号、逗号等分隔符。所以我们使用 Python 的正则表达式库 RE 来做这件事。</p><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="34fc" class="jk jl hi kq b fi ku kv l kw kx">import re<br/>def remove_delimiters(sentence):<br/>    return re.sub(r'[^\w\s]', '', sentence)</span><span id="47f4" class="jk jl hi kq b fi lq kv l kw kx">trimmed_sentences = [remove_delimiters(sent) for sent in sentences]<br/>print(trimmed_sentences)</span><span id="c709" class="jk jl hi kq b fi lq kv l kw kx"><strong class="kq hj">OUTPUT:</strong> ['Ross Uh Rach were running low on resumes over here', 'Monica Do you really want a job with Popular Mechanics', 'Chandler Well if youre gonna work for mechanics those are the ones to work for', .. (and so on)</span></pre><p id="f530" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将修剪后的句子转换成单词:</p><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="f6d0" class="jk jl hi kq b fi ku kv l kw kx">all_words = [nltk.word_tokenize(sent) for sent in trimmed_sentences]<br/>print(all_words)</span><span id="acd4" class="jk jl hi kq b fi lq kv l kw kx"><strong class="kq hj">OUTPUT:</strong> [['Ross', 'Uh', 'Rach', 'were', 'running', 'low', 'on', 'resumes', 'over', 'here'], ['Monica', 'Do', 'you', 'really', 'want', 'a', 'job', 'with', 'Popular', 'Mechanics'], ['Chandler', 'Well', 'if', 'youre', 'gon', 'na', 'work', 'for', 'mechanics', 'those', 'are', 'the', 'ones', 'to', 'work', 'for'], ... (and so on)</span><span id="53a3" class="jk jl hi kq b fi lq kv l kw kx">(NOTE: Directly tokenizing into words causes some problems, like <strong class="kq hj">gonna</strong> became <strong class="kq hj">gon na, </strong>so one can use regex according to ones needs. The base here is creating tokens out of text, whether using NLTK or RE)</span></pre><h2 id="d0d5" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated">[或]一次将整个脚本转换为单词:</h2><p id="7b68" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">但是，如果您不想(转换成句子，使用正则表达式，然后单词标记器)…有一个更简单的单行正则表达式方法将整个语音转换成单词:</p><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="fa84" class="jk jl hi kq b fi ku kv l kw kx">all_words_easy = re.findall(r’\w+’, script)<br/>print(all_words_easy)</span><span id="9517" class="jk jl hi kq b fi lq kv l kw kx"><strong class="kq hj">OUTPUT: </strong>['Ross', 'Uh', 'Rach', 'we', 're', 'running', 'low', 'on', 'resumes', 'over', 'here', 'Monica', 'Do', 'you', 'really', 'want', 'a', 'job', 'with', 'Popular', 'Mechanics', 'Chandler', 'Well', 'if', 'you', 're', 'gonna', 'work', 'for', 'mechanics', 'those', 'are', 'the', 'ones', 'to', 'work', 'for', ... (and so on)</span></pre><h1 id="ac2b" class="ky jl hi bd jm kz la lb jq lc ld le ju lf lg lh jx li lj lk ka ll lm ln kd lo bi translated">2.停用字词删除:</h1><p id="8e29" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">停用词是在任何文本中频繁出现的不太重要的词，如<code class="du lr ls lt kq b">the</code>、<code class="du lr ls lt kq b">and</code>、<code class="du lr ls lt kq b">a</code>等。大多数时候，它们在我们的 NLP 任务中贡献很少或没有意义，所以我们通常移除它们..</p><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="c05e" class="jk jl hi kq b fi ku kv l kw kx">from nltk.corpus import stopwords<br/>stop_words=set(stopwords.words("english"))<br/>print(stop_words)</span><span id="abbd" class="jk jl hi kq b fi lq kv l kw kx"><strong class="kq hj">OUTPUT: </strong>'your', 'him', "that'll", 'hers', 'an', 'same', 'did', 'yours', 'that', 'as' .. (you get my point)</span><span id="0c0b" class="jk jl hi kq b fi lq kv l kw kx">#Remove stopwords<br/>words_without_stopwords = [word for word in all_words_easy if word not in stop_words]<br/>print(words_without_stopwords)</span><span id="d470" class="jk jl hi kq b fi lq kv l kw kx"><strong class="kq hj">OUTPUT: </strong>['Ross', 'Uh', 'Rach', 'running', 'low', 'resumes', 'Monica', 'Do', 'really', 'want', 'job', 'Popular', 'Mechanics', 'Chandler', 'Well', 'gonna', 'work', 'mechanics', 'ones', 'work', 'Rachel', 'Hey', 'look', 'guys', 'I', 'going', 'anything', 'OK', 'I', 'cannot', 'waitress', 'anymore', 'I', 'mean', 'I', 'sick', 'lousy', 'tips', 'I', 'sick', 'called', 'Excuse', 'Ross', 'Rach', 'proofread', 'Rachel', 'Uh', 'yeah', 'Ross', 'Uh', 'nothing', 'I', 'sure', 'impressed', 'excellent', 'compuper', 'skills', 'Rachel', 'upset', 'Oh', 'Goood', 'Oh', 'think', 'Joey', 'Oh', 'I', 'sure', 'Xerox', 'machine', 'caught']</span></pre><h1 id="fdee" class="ky jl hi bd jm kz la lb jq lc ld le ju lf lg lh jx li lj lk ka ll lm ln kd lo bi translated">3.单词标记(词性标记):</h1><p id="c169" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">词性标注基本上意味着将一个标签与句子中的每个单词相关联。例如:</p><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="41d2" class="jk jl hi kq b fi ku kv l kw kx">string = ‘You are awesome’<br/>words = nltk.word_tokenize(string)<br/>pos_tag = nltk.pos_tag(words)<br/>print(pos_tag)</span><span id="aaed" class="jk jl hi kq b fi lq kv l kw kx"><strong class="kq hj">OUTPUT: </strong>[('You', 'PRP'), ('are', 'VBP'), ('awesome', 'JJ')]</span><span id="3202" class="jk jl hi kq b fi lq kv l kw kx">Here, You =&gt; personal pronoun<br/>      are =&gt; verb<br/>      awesome =&gt; simple adjective</span></pre><h1 id="5d5d" class="ky jl hi bd jm kz la lb jq lc ld le ju lf lg lh jx li lj lk ka ll lm ln kd lo bi translated">4.词干:</h1><p id="495a" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">词干化意味着把这个词转换成它的词根或者去掉它的后缀。这里我们使用 NLTK 中的 PorterStemmer 类，正如您所看到的，词干处理将单词转换成它们的基本形式或者去掉后缀(例如:<code class="du lr ls lt kq b">cooking</code>变成了<code class="du lr ls lt kq b">cook</code>)</p><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="46c5" class="jk jl hi kq b fi ku kv l kw kx">from nltk.stem import PorterStemmer<br/>ps = PorterStemmer()<br/>print(ps.stem('cooking'))  -&gt; cook<br/>print(ps.stem('serving'))  -&gt; serv</span></pre><p id="c439" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">缺点:词干有时会使单词变得毫无意义。于是,<strong class="ih hj">来拯救被异化的</strong>。</p><h1 id="1761" class="ky jl hi bd jm kz la lb jq lc ld le ju lf lg lh jx li lj lk ka ll lm ln kd lo bi translated"><strong class="ak"> 5。词汇化</strong>:</h1><p id="1863" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">它将单词转换成它的(有意义的)基本词根或词条。这里唯一的问题是，我们需要提到作为参数的是哪种单词(即它的位置标签)。这里两者都是动词，所以我们将参数作为<code class="du lr ls lt kq b">'v'.</code>传递</p><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="b013" class="jk jl hi kq b fi ku kv l kw kx">from nltk.stem.wordnet import WordNetLemmatizer<br/>lm = WordNetLemmatizer()<br/>print(lm.lemmatize('cooking', 'v')) -&gt; cook<br/>print(lm.lemmatize('serving', 'v')) -&gt; serve</span></pre><h1 id="a045" class="ky jl hi bd jm kz la lb jq lc ld le ju lf lg lh jx li lj lk ka ll lm ln kd lo bi translated">6.依存句法分析</h1><p id="b23a" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">词性标注只会将每个单词转换成其各自的词性。然而，大多数时候，我们需要算法来理解单词之间的关系。依赖解析器做的<em class="jd">和</em>完全一样。让我们看看如何:</p><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="484e" class="jk jl hi kq b fi ku kv l kw kx">import spacy #another open-source library for NLP<br/>nlp = spacy.load(‘en_core_web_md’)<br/>from spacy import displacy</span><span id="6d60" class="jk jl hi kq b fi lq kv l kw kx">temp = nlp('You are awesome')<br/>displacy.serve(temp, style=’dep’)</span></pre><figure class="kl km kn ko fd lv er es paragraph-image"><div class="er es lu"><img src="../Images/85833ca317ddb2e4c28aa160d4ef1187.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*oG1rxLctg9TAsaHu9xomTA.png"/></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">使用空间的词性标注+依存句法分析</figcaption></figure><p id="ed54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，<strong class="ih hj"> you </strong>是主语，<strong class="ih hj"> awesome </strong>是形容词补语。这两者通过单词<strong class="ih hj"> are 相互连接。</strong></p><h1 id="a02e" class="ky jl hi bd jm kz la lb jq lc ld le ju lf lg lh jx li lj lk ka ll lm ln kd lo bi translated">7.命名实体识别</h1><p id="233e" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">这不是 NLP 工作流程中的一个强制步骤，但是，这是一个对你的单词进行分类的好方法。NER 是每个实体(句子中的基本主语和宾语)到它们的<strong class="ih hj">通用名的映射。</strong></p><figure class="kl km kn ko fd lv er es paragraph-image"><div class="er es mc"><img src="../Images/98da4b903aaffbb0896e10fe33b6ac44.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*cixVZMlC6aarqhYWIPexmQ.png"/></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">使用<a class="ae kk" href="https://excalidraw.com/" rel="noopener ugc nofollow" target="_blank">https://excalidraw.com/</a>绘制</figcaption></figure><pre class="kl km kn ko fd kp kq kr ks aw kt bi"><span id="4de0" class="jk jl hi kq b fi ku kv l kw kx">sentence = "Chandler works at Google"<br/>print (nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence))))</span><span id="36a6" class="jk jl hi kq b fi lq kv l kw kx"><strong class="kq hj">OUTPUT: </strong>(S (PERSON Chandler/NNP) works/VBZ at/IN (ORGANIZATION Google/NNP))</span></pre><p id="d572" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是关于 NLP 的基本概念，在深入分析文本并为进一步的任务进行处理之前，需要理解这些概念:)</p><figure class="kl km kn ko fd lv"><div class="bz dy l di"><div class="md me l"/></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">下次有人问你知不知道 NLP)</figcaption></figure><p id="f545" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">哦，嘿，也许以后你可以用这些处理过的脚本，应用 ML 来分析钱德勒使用的是哪种幽默。迁就我；)</p></div><div class="ab cl mf mg gp mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="hb hc hd he hf"><p id="01e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以上代码可以在<a class="ae kk" href="https://nbviewer.jupyter.org/github/riddhinn99/medium-articles-code/blob/main/nlp_basics.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> <em class="jd">这里找到</em> </strong> </a>！感谢阅读！如果你觉得这篇文章很有见地和/或很有趣，请为它鼓掌，关注我的<a class="ae kk" rel="noopener" href="/@riddhinn"><strong class="ih hj"><em class="jd"/></strong></a>！</p><p id="9c2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一如既往，你和我一起学习。如果我错过了什么明显的东西，请留下回复，我会检查一下。干杯！✨ </p></div></div>    
</body>
</html>