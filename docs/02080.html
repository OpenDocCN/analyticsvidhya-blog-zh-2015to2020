<html>
<head>
<title>Debugging DNN with help of Tensorboard</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">借助Tensorboard调试DNN</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/debugging-dnn-with-help-of-tensorboard-f737b7bc5ed9?source=collection_archive---------0-----------------------#2019-11-29">https://medium.com/analytics-vidhya/debugging-dnn-with-help-of-tensorboard-f737b7bc5ed9?source=collection_archive---------0-----------------------#2019-11-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="67bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">即使对于领域专家来说，调试神经网络也是一项艰巨的工作。数以百万计的参数粘在一起，即使一个小小的变化也可能毁掉你所有的努力。没有调试和可视化，你所有的行为都是在扔硬币，更糟糕的是，它在消耗你的时间。<br/>虽然您可能熟悉TensorFlow，但还有TensorBoard，这是一种内置的模型可视化工具和监视器，可让您专注于模型问题。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/87c5a9f1b5a274da382fd2d0fae288ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dPAK9jpxJolsEukLHYUi_A.png"/></div></div></figure><p id="3e9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在对TensorBoard的功能产生兴趣后，我想要一个简单但有用的演示来演示如何使用TensorBoard，但找不到，所以我决定制作一个。在本文中，我将设置一个示例问题，用TensorBoard在TensorFlow中实现一个简单的模型，并解释为了开始使用TensorBoard，<strong class="ih hj"> <em class="jp"> YOU </em> </strong>需要了解的细节。</p><p id="097c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，我将假设你熟悉机器学习和Python(如果你正在寻找一个关于机器学习的轻度非技术介绍，我强烈推荐:<a class="ae jq" rel="noopener" href="/@ageitgey/machine-learning-is-fun-80ea3ec3c471">机器学习很有趣</a>)。</p><p id="b444" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">那么，什么是Tensorboard呢？</strong></p><p id="b4ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TensorBoard是一个基于浏览器的应用程序，可以帮助您可视化您的训练参数(如重量和偏差)、指标(如损失)、超参数或任何统计数据。它是一种工具，用于提供机器学习工作流程中所需的测量和可视化。它支持跟踪实验指标，如损失和准确性，可视化模型图，将嵌入投影到低维空间，等等。</p><h1 id="47c3" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">Tensorboard入门</h1><p id="8f68" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated"><strong class="ih hj">步骤1:- </strong>如果你正在使用Jupyter Notebook并想在其中使用，那么在一个单元格中运行下面的代码。</p><pre class="je jf jg jh fd ku kv kw kx aw ky bi"><span id="b069" class="kz js hi kv b fi la lb l lc ld">%load_ext tensorboard</span></pre><p id="dc24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将为当前会话初始化笔记本中的tensorboard。</p><p id="ce7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了理解它是如何工作的，让我们用一个例子来测试一下，看看它是如何工作的。</p><p id="a938" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二步:- </strong>低载你要处理的数据。<br/>这里我们将使用最著名的MNIST数据集，它是数字(0–9)图像的集合。</p><pre class="je jf jg jh fd ku kv kw kx aw ky bi"><span id="3939" class="kz js hi kv b fi la lb l lc ld">mnist = tf.keras.datasets.mnist<br/><br/>(x_train, y_train),(x_test, y_test) = mnist.load_data()<br/>x_train, x_test = x_train / 255.0, x_test / 255.0</span></pre><p id="70ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤3:- </strong>创建模型架构。<br/>我们先用一个非常基础的模型架构做试错。</p><pre class="je jf jg jh fd ku kv kw kx aw ky bi"><span id="7837" class="kz js hi kv b fi la lb l lc ld">def create_model():<br/>  return tf.keras.models.Sequential([<br/>    tf.keras.layers.Flatten(input_shape=(28, 28)),<br/>    tf.keras.layers.Dense(512, activation='relu'),<br/>    tf.keras.layers.Dropout(0.2),<br/>    tf.keras.layers.Dense(10, activation='softmax')<br/>  ])</span></pre><p id="f6e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第四步:- </strong>创建一个Tensorboard回调函数。<br/><code class="du le lf lg kv b">tf.keras.callback.TensorBoard</code>回调确保日志被创建和存储。</p><pre class="je jf jg jh fd ku kv kw kx aw ky bi"><span id="e139" class="kz js hi kv b fi la lb l lc ld">log_dir="logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")<br/>tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)</span></pre><p id="0430" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里log_dir是我们将要存储所有生成的日志的目录</p><p id="8176" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第五步:- </strong>训练模型，通过回调函数。</p><pre class="je jf jg jh fd ku kv kw kx aw ky bi"><span id="7600" class="kz js hi kv b fi la lb l lc ld">model = create_model()<br/>model.compile(optimizer='adam',<br/>              loss='sparse_categorical_crossentropy',<br/>              metrics=['accuracy'])<br/>model.fit(x=x_train, <br/>          y=y_train, <br/>          epochs=5, <br/>          validation_data=(x_test, y_test), <br/>          callbacks=[tensorboard_callback])</span></pre><p id="9b54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第六步:- 想象张量板。</p><pre class="je jf jg jh fd ku kv kw kx aw ky bi"><span id="9d22" class="kz js hi kv b fi la lb l lc ld">%tensorboard --logdir logs/fit</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lh"><img src="../Images/0def9a52a64ec75309897d825fff377f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sCfNIA6HXRqzT8rvCXOq9g.jpeg"/></div></div></figure><p id="f577" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是张量板的样子。<br/>现在我们来看看有哪些可用的组件。</p><h1 id="bba1" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">张量板的组件</h1><p id="b728" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated"><strong class="ih hj">(一)图表:- </strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/7e1485938386c3e266874d08ab7777fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EYg4PFlHO1GdgHcoYdUvOw.jpeg"/></div></div></figure><p id="6986" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Tensorboard图是非常复杂的，让它工作的方法给了我们有用的洞察力，我们必须做一些工作来清理结构图。</p><p id="27d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们来理解如何解释这个图表。</p><ul class=""><li id="7e0c" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated">&gt;第一个要点是，具有相同颜色的节点表示它们具有相同的结构，而灰色节点表示每个节点都是唯一的。</li><li id="ef3c" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">&gt;您可以单击任何节点，以获取该节点内部的更多详细信息。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lx"><img src="../Images/3342df0dfbd65d5971f7f2f8ce7e8b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*78_T1tyOCJG6NDM0mal8aw.jpeg"/></div></div></figure><ul class=""><li id="39fc" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated">&gt;您可以使用trace_input按钮，选择任何节点并查看依赖关系。</li></ul><p id="a76d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> (b)摘要:- </strong></p><p id="e9f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">汇总是一种特殊的张量流运算。它将从您的图形中获取常规张量，然后输出包含“汇总”数据的协议缓冲区。<br/>有不同类型摘要-</p><ul class=""><li id="f794" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated"><em class="jp"> tf.summary.scalar:- </em></li></ul><p id="3442" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些将写下度量的单个值，如准确性、损失等，它将生成如下输出。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/b94ffcaa4025963763bb79c64d439347.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*yrOldK6EobvB_a8sDWFjXg.jpeg"/></div></figure><p id="602e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，第一个图形表示精度，第二个表示损耗。我们可以观察到该图从0.954上升到0.978，即我们的模型精度逐渐增加。类似地，损失从0.15减少到0.07，即我们的模型正在改进。<br/>但也有一些情况，如下图所示，模型没有学到任何东西，即损失只是在轴上徘徊。这可能表明我们的模型架构可能不好，或者梯度可能太大。这意味着我们的损失不会收敛到全局最小值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/3af9c74c0cbdddb58bca283b71925aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*CYAaOyT3derSNSP72F0CJw.jpeg"/></div></figure><p id="a027" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了最小化这个损失函数，你需要定义一个<strong class="ih hj">学习率。</strong>就是<strong class="ih hj"> </strong>你希望模型学习的速度。如果您将学习速率设置得太高，模型就没有时间学习任何东西。上图就是这种情况。这条线在上下移动，这意味着模型纯粹凭猜测来预测结果。下面的图片显示，损失随着迭代而减少，直到曲线变平，这意味着模型找到了解决方案。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/91654e81a488d47f79d3299e47f9d679.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*4NKhsfsdk7AoXk3-3vjwiQ.jpeg"/></div></figure><ul class=""><li id="f130" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated"><em class="jp"> tf.summary.image:- </em></li></ul><p id="08f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将写出一个图像。例如，它用于查找您是否有生成图像的创成式模型，或者您是否想要查看数据的格式是否正确。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mb"><img src="../Images/c61a9734f7f145bc4538e75fc6c1fc3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*3MX2FdYqPdcY58GGPh51Gg.jpeg"/></div></figure><ul class=""><li id="e1b7" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated"><em class="jp"> tf.summary.audio:- </em></li></ul><p id="0af5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您的模型生成音乐进行分析，则可以使用。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/e3908103dcffbd378e90f94d75ccafdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*tETe8NRCL1ioCmqK3w7uXQ.jpeg"/></div></figure><ul class=""><li id="1759" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated"><em class="jp"> tf.summary.histogram:- </em></li></ul><p id="4a83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您想观察值随时间或迭代的变化，直方图就派上了用场。它用于绘制非标量张量的直方图。这向您展示了张量值的分布如何随时间或迭代而变化。在DNN的情况下，它通常用于检查权重分布和偏差分布。这对于检测网络参数的不规则行为非常有帮助，例如当我们的网络梯度爆炸或收缩时。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/26650d6c080b57854b92335e99c62d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gThdIm1wDkB9EcWjmW0Mlg.jpeg"/></div></div></figure><p id="8727" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这显示了dense_1层的参数分布。</p><p id="36c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们来解释直方图。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es me"><img src="../Images/1d1cae7bdb259c772fc00ba3a599fbdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*ymQYk4up_JDmuB2h-irxpA.jpeg"/></div><figcaption class="mf mg et er es mh mi bd b be z dx translated"><a class="ae jq" href="https://stackoverflow.com/questions/38149622/what-is-a-good-explanation-of-how-to-read-the-histogram-feature-of-tensorboard" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/38149622/what ' s a-a-good-explain-of-how-to-read-the-histogram-feature-of-tensor board</a></figcaption></figure><p id="2aa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此处标记为93%的曲线是第93个百分位数，这意味着在时间步长1.00k时，93%的观察值低于值~0.130。因此，该图给出了3项信息，即在神经网络训练计算的每个时间步长，低于某一特定值的观察值百分比(至少在这种情况下，这是这些步骤的含义)。这让你感觉到你的人际网络的价值分布。</p><p id="ebd3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些最小值和最大值也可以给出训练期间值的范围。</p><blockquote class="mj mk ml"><p id="5a48" class="if ig jp ih b ii ij ik il im in io ip mm ir is it mn iv iw ix mo iz ja jb jc hb bi translated">所以y轴告诉你你感兴趣的值，曲线告诉你百分点，x轴告诉你步长。</p></blockquote></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><p id="3413" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们了解如何解释梯度:-</p><p id="2cd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于训练深度模型的问题:</p><ul class=""><li id="61d0" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated">重量初始化。如果你用随机的小权重初始化网络，当你观察顶层的梯度时，你会发现它们变得越来越小，然后第一层几乎没有变化，因为梯度太小而不能进行显著的更新。没有机会有效地学习第一层，就不可能更新和学习一个好的深度模型。</li><li id="6774" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">如果你设置的权重不正确，你的网络会因为零梯度或者所有神经元的相似更新而变得不可训练。你也应该记住，权重是与学习率相关联的，所以大的学习率和大的权重会导致NaN问题。</li><li id="0e0a" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">非线性激活。当人们用<code class="du le lf lg kv b">sigmoid</code>或<code class="du le lf lg kv b">tanh</code>作为激活函数时，梯度，同上，越来越小。只是提醒公式的参数更新和梯度。</li></ul><p id="7ee3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">那么我们怎么知道它的消失梯度问题呢？</strong> <em class="jp"> <br/> </em>如果网络遭受消失梯度问题，那么从顶部传递的梯度应该非常接近零，并且网络的权重几乎不变/更新。</p><p id="0f0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">那么我们怎么知道它的爆炸梯度问题呢？<br/> </strong>这个问题和消失问题一样，只是每一步的梯度变得越来越大。一个主要的解决方法是使用渐变剪辑，基本上是为渐变设置硬限制。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mw"><img src="../Images/65460843f3156c16cb6004a7e028205c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7bHNFiO84e-L_fefyL4uJA.jpeg"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated"><a class="ae jq" href="https://stackoverflow.com/questions/42315202/understanding-tensorboard-weight-histograms" rel="noopener ugc nofollow" target="_blank">示例:- </a>前三层梯度变化不大，这意味着模型在那个时期没有学习。</figcaption></figure><p id="8363" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有了这些知识，你就可以将TensorBoard应用到任何其他类型的模型中，以确保<strong class="ih hj">你</strong>在执行模型迭代时优化你的时间。</p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><h1 id="374b" class="jr js hi bd jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk nb km kn ko bi translated">示例:-消失梯度问题</h1><p id="b43c" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">让我们举一个小例子，看看爆炸梯度如何影响我们。我们将使用scikit_learn中的make_circles数据集。<br/>sci kit-learn类提供了<a class="ae jq" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html" rel="noopener ugc nofollow" target="_blank"> make_circles()函数</a>，该函数可用于创建具有指定数量的样本和统计噪声的二元分类问题。</p><p id="6bed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个例子都有两个输入变量，定义二维平面上的点的<em class="jp"> x </em>和<em class="jp"> y </em>坐标。这两个类的点排列成两个同心圆(它们有相同的中心)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nc"><img src="../Images/58874f14236ae39c802a698bcf5834f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lULnavvZ4eKmB3l21V5o0A.jpeg"/></div></div></figure><p id="bccb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们知道，梯度消失的问题出现在深层，那里的梯度变得如此之小，以至于两个时期之间的权重相差不大，换句话说，没有学习。<br/>所以一个更深层次的模型和不正确的激活函数可能会遇到这种问题。Sigmoid压缩0和1之间的值。因此，sigmoid函数输入的大变化会导致输出的小变化。因此，导数变小。对于只有几层使用这些激活的浅层网络，这不是一个大问题。然而，当使用更多的层时，它会导致梯度太小而不能有效地进行训练。</p><p id="660c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">小的梯度意味着初始层的权重和偏差不会随着每次训练而有效地更新。由于这些初始层通常对识别输入数据的核心元素至关重要，因此会导致整个网络的整体不准确。</p><p id="2c03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以现在让我们用一个简单的激活了<strong class="ih hj"> tanh </strong>的模型来尝试一下。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nd"><img src="../Images/a823813dde99a1c5d1a9a9819dbfcefb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1I2jNzxrdf1sJF-0HxJ6yw.jpeg"/></div></div></figure><p id="3eb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们检查结果。</p><div class="je jf jg jh fd ab cb"><figure class="ne ji nf ng nh ni nj paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/dd2c9459b8586d4037cc3fe801d2a954.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*kOoKvk-T2KXlzD4R2Vc1mw.jpeg"/></div></figure><figure class="ne ji nk ng nh ni nj paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/d15983cb170ce6ccdd2d02599a55d5c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*nU-1w972xPGBcs4MdScltw.jpeg"/></div></figure></div><p id="1872" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图名表示层，其中“<em class="jp"> dense_1 </em>表示输入层之后的隐藏层，“<em class="jp"> dense_6 </em>表示输出层。<br/>我们可以观察到，精度在54%之后没有增加，损耗停留在0.687左右。<br/>如果我们观察梯度的线图，那么我们可以看到输出层在整个运行过程中有很多活动，每个时期的平均梯度在0.05到0.1左右。我们还可以在第一个隐藏层中看到类似范围的一些活动。<a class="ae jq" href="http://," rel="noopener ugc nofollow" target="_blank"> <em class="jp">因此，渐变正在通过第一个隐藏层，但是最后一个层和最后一个隐藏层看到了大部分的活动。</em> </a> <br/>这基本上意味着内部隐藏层没有学到太多，因为渐变没有流过它。</p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><p id="45cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了克服这个问题，我们可以使用<strong class="ih hj"> Relu </strong>函数。当开发多层感知器网络时，校正的线性激活函数已经取代双曲正切激活函数作为新的优选默认。这是因为激活函数看起来和行为像线性函数，使其更容易训练且不太可能饱和，但事实上，它是非线性函数，将负输入强制为值0。它被认为是在训练更深的模型时解决消失梯度问题的一种可能的方法。有了它，使用he权重初始化方案是一个好的实践。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nl"><img src="../Images/2e096b164542c63be050b7294d28e44f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OZBq97RzkUS5zpmr5f7FrQ.jpeg"/></div></div></figure><p id="ea91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看结果。</p><div class="je jf jg jh fd ab cb"><figure class="ne ji nm ng nh ni nj paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/939831d4e0dbd503a9d65d4ce589eeca.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*GWKLBTRjoQdyywd3LfnzKw.jpeg"/></div></figure><figure class="ne ji nn ng nh ni nj paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/8b8f795cd3fe0d475b5f068fa04c9656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1534/format:webp/1*MhIQiq3rOdIBrCgkBvB1OQ.jpeg"/></div></figure></div><p id="b5b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">哇，在这种情况下，我们可以看到这个小变化已经允许模型学习问题，实现了大约84%的准确率，优于使用tanh激活函数的单层模型。ReLU activation函数的使用允许我们为这个简单的问题建立一个更深层次的模型，但是这个功能不能无限扩展。例如，增加层数会导致学习速度变慢，直到大约20层时，模型不再能够学习问题。</p><p id="ef81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，第一个隐藏层看到更多的梯度，更一致地具有更大的扩散，可能是0.2到0.4，与tanh看到的0.05和0.1相反。我们还可以看到，中间的隐藏层看到大的梯度。这意味着所有的层都在学习一些东西，否则我们不会得到84%的<strong class="ih hj">准确率。</strong></p><blockquote class="mj mk ml"><p id="e672" class="if ig jp ih b ii ij ik il im in io ip mm ir is it mn iv iw ix mo iz ja jb jc hb bi translated">ReLU激活功能允许更多的梯度在训练期间通过模型回流，这可能是性能提高的原因。</p></blockquote></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><p id="08b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们同样可以检测爆炸梯度问题。解决这些问题的其他方法是更高级的激活函数，如Leaky Relu，使用残差网络，批量标准化(这是一个重大成功),梯度裁剪。</p><h1 id="6477" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">参考资料:-</h1><p id="986b" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">(1)-<a class="ae jq" rel="noopener" href="/machine-learning-world/how-to-debug-neural-networks-manual-dc2a200f10f2">https://medium . com/machine-learning-world/how-to-debug-neural-networks-manual-dc2a 200 F10 f 2</a></p><p id="f0d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(2)-<a class="ae jq" href="https://ayearofai.com/rohan-4-the-vanishing-gradient-problem-ec68f76ffb9b#.bojpejg3o" rel="noopener ugc nofollow" target="_blank">https://ayearofai . com/rohan-4-the vanishing-gradient-problem-ec68f 76 FFB 9b # . bojpejg 3 o</a></p><p id="34b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(3)-<a class="ae jq" href="https://machinelearningmastery.com/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-fix-vanishing-gradients-using-the-corrected-linear-activation-function/</a></p></div></div>    
</body>
</html>