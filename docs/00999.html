<html>
<head>
<title>Highly Unbalanced Dataset — End to End Solution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高度不平衡的数据集—端到端解决方案</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/highly-unbalanced-data-set-end-to-end-solution-44822bc5ee85?source=collection_archive---------11-----------------------#2019-09-24">https://medium.com/analytics-vidhya/highly-unbalanced-data-set-end-to-end-solution-44822bc5ee85?source=collection_archive---------11-----------------------#2019-09-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5a01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">高度不平衡的数据集</strong> — &gt;其中一个类别高度支配另一个类别和类别比率(如总共10个数据点中的9个正和1个负)。</p><p id="9241" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在讨论解决方案之前，让我们先了解一些性能指标的知识。</p><p id="96e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">准确性</strong>→在所有实际点中，有多少被正确分类。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/0ad18fbef2ef94b9957cd83fadc1dc0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K8Kw1erNh45mNPlDliVoaQ.png"/></div></div></figure><p id="ac19" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">特异性</strong>→从所有实际阴性点中，有多少被正确预测为阴性。</p><p id="20be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">精度</strong>→从所有预测的阳性点中，有多少是实际阳性。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/f1bcc9cf00e876f0169e7b9f6d94b72f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vw12uqBfTs_rSeMXFRpu1g.jpeg"/></div></div></figure><p id="bb2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">回忆</strong>→从所有实际阳性点中，有多少被正确预测为阳性。</p><p id="ad3d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">F1-得分</strong>→是精度和召回率的调和平均值。它用在我们既需要精确又需要回忆的地方。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jp"><img src="../Images/300b2c58190ce201b322701a9a8d657f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ncB6vOwxECGinUBWSMZHGA.jpeg"/></div></div></figure><p id="28a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注:</strong>精度、召回率和F1_score只关心正分。精确度、召回率和F1_score也用于信息检索。</p><p id="6cbb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">If (Precision=Recall) THEN ( F1得分=PRECISION=RECALL)</p><p id="e506" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> AUC-ROC得分</strong>:如果曲线的AUC为(0.75)，则意味着:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jq"><img src="../Images/d38417916cf6ef7ba5a3ff973d832f94.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*_eito-Nu8l7wfbvan-U3RQ.png"/></div></figure><p id="2ea7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们有两个不同类别，我们不知道哪个是阳性的，哪个是阴性的，如果我们通过AUC (0.75)的模型传递这些点，那么我们的模型将有机会正确地分类75%的点。</p><p id="07d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注:随机模型的AUC为(0.5)。如果我们找到AUC (0.2)的模型，则交换类别标签。</p><p id="14df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AUC不关心实际值，即它不依赖于预测得分，它依赖于数据的排序。</p><h1 id="a481" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated"><strong class="ak">让我们深入探讨这个问题:</strong></h1><p id="b793" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated"><strong class="ih hj">设</strong>有两个分类问题，一个是正类，另一个是负类。在这里，一个阶级高度支配另一个阶级。例如，一个等级超过90%，另一个等级低于10%。</p><p id="33c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">众所周知，准确度是最简单的矩阵，我们在8年级左右的时候都学过……但我们在这里不会用准确度作为矩阵。</p><p id="cf56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">为什么不精确</strong>:让我们有一组数据，一组是95%，另一组是5%。现在把它想成，一个人要去写只有对和错的答案的考试。现在假设一个人没有任何准备就去参加考试，并把所有答案都标为真，实际的考试答案也是9对1错。所以现在一个没有准备就去考试的人会得90分。这是不应该接受的。</p><p id="c9fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，如果我们的模特很笨/表现不好…在此之后，它可以给我们一个非常好的准确率约90%的高度不平衡的数据集。<strong class="ih hj">所以我们在这里不会用准确度作为一个矩阵。</strong></p><p id="5e39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们将使用精确度、召回率、F1分数和AUC-ROC曲线作为矩阵，如上所述。我们还将使用TP、FP、TN、FN的混淆矩阵进行解释和测量。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ku"><img src="../Images/460bdad08d478863ab6c26491a25e055.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*shP_ij_pY2AV3lJnHyVo6g.jpeg"/></div></figure><p id="9f6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将在drop和Yi，s=yees之后分离Xi，s=df_tr，然后用分层进行拆分</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kv"><img src="../Images/24a73c0252723d54a1ebe49a1ec324b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k2yOfhZETwzalUeikdsB9Q.jpeg"/></div></div></figure><p id="ee38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们将检查NaN值，并用平均值替换它们，然后进行数据标准化。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kw"><img src="../Images/2a0fe8727e5e615a9f74a8158b5fd632.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*bSV4meXURlL_fkxq2vS9JQ.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">最后我们得到了准备好的建模数据</figcaption></figure><h2 id="523a" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">现在，重要的问题是我们应该采取哪种模式:</h2><p id="ae37" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">这里我们只有64个特征和大约30，000行，因为我们的特征数量较少，所以我们将使用决策树和梯度提升树来完成分类任务。</p><h2 id="4831" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated"><strong class="ak">如何从下面的混淆矩阵中为我们的模型选择最佳超参数</strong></h2><p id="1e43" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">选择最佳超参数的技术可能是肘方法。也就是说，我们将看到:</p><p id="ccf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1:我们将看到混淆矩阵，并看到相应单元之间的间隙在哪里最小。</p><p id="a252" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2:我们还会看到哪里的值偏差最小。</p><p id="7b84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3:如果我们在图中只有1个超参数，我们也可以使用肘方法。</p><p id="633c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4:我们也可以使用网格搜索CV来减少参数数量，使用随机搜索CV来增加参数数量。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lp"><img src="../Images/33a89f6612d17b62887f79c06ef9b27d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rJ4ZAjEJQWwFJH-nY093UQ.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">超参数调谐代码</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/b430888626a6bfb127c8d21b874fc07b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i6M1PWn7mpEPuhWLkn2tvA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lr"><img src="../Images/a029fd85189ad502cecb9d7d32d93b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*pjfhEMtCHuvpIDP_xAySww.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">SEABORN热图代码</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/89a4e585c6d327d6ee1efef34c60578c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AbJnj0cMwAprpCTto5ikQQ.png"/></div></div></figure><p id="54bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过观察上图，决策树的最佳超参数是:估计数= 50，深度=8。</p><h1 id="1286" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">训练和测试模型的代码:</h1><pre class="je jf jg jh fd ls lt lu lv aw lw bi"><span id="fe35" class="lb js hi lt b fi lx ly l lz ma">rf = RandomForestClassifier(n_estimators=100,max_depth=6)</span><span id="5de6" class="lb js hi lt b fi mb ly l lz ma"># fitting the model<br/>rf.fit(Xbow_tr_std, y_tr)</span><span id="a22f" class="lb js hi lt b fi mb ly l lz ma"># predict the response<br/>pred = rf.predict(Xbow_test_std)</span><span id="dedb" class="lb js hi lt b fi mb ly l lz ma"># evaluate accuracy<br/>acc = accuracy_score(y_test, pred) * 100</span><span id="f30d" class="lb js hi lt b fi mb ly l lz ma">precision_score1=precision_score(y_test, pred )</span><span id="18ad" class="lb js hi lt b fi mb ly l lz ma">recall_score1=recall_score(y_test, pred )</span><span id="a534" class="lb js hi lt b fi mb ly l lz ma">f1 = f1_score(y_test, pred)</span><span id="1519" class="lb js hi lt b fi mb ly l lz ma">print(‘\nThe accuracy of the Random forest classifier for n_estimaters=%f and Depth = %f is %f%%’ % (100,6, acc))</span><span id="cadc" class="lb js hi lt b fi mb ly l lz ma">print(‘\nThe precision_score of the Random forest classifier for n_estimaters=%d and Depth = %d is %f’ % (100,6,precision_score1))</span><span id="04a2" class="lb js hi lt b fi mb ly l lz ma">print(‘\nThe recall_score of the Random forest classifier for n_estimaters=%d and Depth = %d is %f’ % (100,6,recall_score1))</span><span id="ded6" class="lb js hi lt b fi mb ly l lz ma">print(‘\nThe f1_score of the Random forest classifier for n_estimaters=%d and Depth = %d is %f’ % (100,6,f1))</span><span id="b15a" class="lb js hi lt b fi mb ly l lz ma">The accuracy of the Random forest classifier for n_estimaters=100.000000 and Depth = 6.000000 is 86.638253%<br/><br/>The precision_score of the  Random forest classifier  for n_estimaters=100 and Depth = 6 is 0.222453<br/><br/>The recall_score of the  Random forest classifier  for n_estimaters=100 and Depth = 6 is 0.708609<br/><br/>The f1_score of the  Random forest classifier  for n_estimaters=100 and Depth = 6 is 0.338608</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/bf12aaf5e2404bc0420da2daa86be962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*a67d-nkB_CEco2UMt2K6Zw.jpeg"/></div></figure><h2 id="b236" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">训练和测试之间的AUC_ROC曲线:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/979302a23680a99d35802641e0f58373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*22U8U8T0aMJJTre1RteTBA.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">正如我们所见，训练和测试AUC之间没有这种差异，这意味着我们的模型做得很好。</figcaption></figure><p id="633b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的模型中，我们可以看到我们的召回和F1分数非常少，所以我们将尝试XG boost模型，因为它比决策树更强大。</p><h1 id="415d" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">应用XG BOOST改进我们的模型:</h1><p id="b105" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated"><strong class="ih hj">为超级参数调整创建热图:</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/2800723ccb647aa5bd7e657ff2c3e4f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fj4qpnceCEIzjSRjZRB18Q.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/bb9fed50ace4fa8aad7eec389cb988cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7tdRqebY51uZS-pwYIplVA.png"/></div></div></figure><p id="1793" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">调整超参数后，我们的估计数=50，深度=8</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/83fa747cd2cd446bb68ff0cbf6dc6023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WAt60L2OkcGehaa2zjegxQ.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es me"><img src="../Images/c7a61db4bd6e79da26eedd5f5f947e15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZAESC3AWfYp9SVfNglV4mg.jpeg"/></div></div></figure><h2 id="8d2a" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">训练和测试之间的AUC_ROC曲线:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es me"><img src="../Images/22aff28af7b079d6fd64ea497def237c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mCVl7BHtP8dMNE-Dgw5J5A.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">正如我们所见，训练和测试AUC之间没有这种差异，这意味着我们的模型做得很好。</figcaption></figure><p id="0622" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在数据集上使用我们的模型决策树和X.G boost，我们的性能没有显著变化。</p><h1 id="4eba" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">技巧1:</h1><h2 id="42d0" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">为什么不在样本多数下上课:</h2><p id="55df" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">如果我们将样本置于多数类之下，我们将丢失大部分信息。</p><p id="4027" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注</strong>:如果我们有大量来自少数类的数据，即拥有v.large数据集，我们也可以对多数类使用欠采样，或者我们也可以使用两者的组合(过采样少数类和欠采样多数类)。</p><p id="04eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们将使用称为SMOTE(少数过采样技术)的技术，通过过采样点的少数类来解决问题。了解更多:Referencing(<a class="ae mf" href="https://youtu.be/FheTDyCwRdE" rel="noopener ugc nofollow" target="_blank">https://youtu.be/FheTDyCwRdE</a>)(<a class="ae mf" href="https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/smote" rel="noopener ugc nofollow" target="_blank">https://docs . Microsoft . com/en-us/azure/machine-learning/studio-module reference/smote</a>)。</p><h1 id="6c24" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">使用SMOTE应用决策树:</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mg"><img src="../Images/24121e1818a4a68db8142a234bbd3010.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cfYzWiyvjlI7YLi8Mf1Bjw.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">train_test_split、缺失值插补以及SMOTE和标准化的代码。</figcaption></figure><p id="4a7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，我们将调整hyper参数，并像之前一样执行所有其他步骤</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/e9d63e6cc1cca1bf06494dd2309d4a8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KQNGdLqe69hj7p1QIzc6Ew.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mh"><img src="../Images/460dfcef92739ead8afe59111d4a2c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yw57223dNKl5fscUil1oEA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mi"><img src="../Images/dd70d2c993391ec11cbd478eed87c72b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0SlBrmZrtucxLrgeWXY-rQ.jpeg"/></div></div></figure><p id="6d4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们得到了更好的结果后，应用SMOTE技术。我们的召回率和F1分数大幅提高。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mj"><img src="../Images/ad7ac1224e970365689bb103980f1c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*bR3j3t-80D4M1tcq6_1Ljw.jpeg"/></div></figure><h2 id="e0fd" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">训练和测试之间的AUC_ROC曲线:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mj"><img src="../Images/09615b40966334d85b8073c2e4121da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*45wTiOGYyM2wE_7jx_ydqA.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">正如我们所见，训练和测试AUC之间没有这种差异，这意味着我们的模型做得很好。</figcaption></figure><p id="86d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们得到了更好的结果，但我们将尝试用同样的技术来提高我们的结果。</p><h1 id="997a" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">使用SMOTE应用X.G-BOOST:</h1><h2 id="ab5c" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">超参数调整和训练模型:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mh"><img src="../Images/7b3ea81ab045c94ad79e2e25be93216b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SlpJssRwBmeh0jU9G0YBgA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/720ee5b5dc0107392e7002f3728cae86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nTT9_OsUvZWgiG_mgDWekg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mk"><img src="../Images/259f9601d569ec4fff64cf107565f5b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H6vCegSr1piCU3jO48LWeA.jpeg"/></div></div></figure><p id="6661" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们得到了更好的召回率，但我们的精度和F1值明显下降。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ml"><img src="../Images/e9ed9fc79f54931f0ca6e2d77f68b47b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FocyHDVpFjtJqeynQj1_wg.jpeg"/></div></div></figure><h2 id="95eb" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">训练和测试之间的AUC_ROC曲线:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ml"><img src="../Images/c03d1ecb8450a485ed88a5085da58759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JmgvHx4oy06jSWEpR-tnPQ.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">正如我们所见，训练和测试AUC之间没有这种差异，这意味着我们的模型做得很好。</figcaption></figure><p id="fecd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们用两种方法进行了观察，一种是SMOTE，另一种是按原样取数据，SMOTE得到了更好的结果。让我们再做一些实验。</p><h1 id="4ea6" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">技巧2:</h1><p id="7476" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">现在我们将随机抽样少数民族点计数UPTO多数阶级:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mm"><img src="../Images/07ba3cf36782f8a16563e5a68e15f91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R-Q38wOO4cd1awC2xXiGOA.jpeg"/></div></div></figure><h2 id="3648" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">对少数类进行上采样，并使两个类的计数相等:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mn"><img src="../Images/aa03e6a6617007aa96a8d84c8d15a4d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oM9we9MMf-_qHcwF3hKlRg.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mo"><img src="../Images/581c8f2dac8f685f3700d5697381ec8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*8yzXbMqhWW4ahkT43BrTfw.jpeg"/></div></figure><h2 id="a6e0" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">用随机上采样技术实现决策树。</h2><h2 id="8306" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">超参数调整和训练模型:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/3a12d79fec659d9ca63df3355d39973d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lzwQNhwWIXi6nU-A3vXrxw.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/fccc8a98b34245cc1dae22ab886ae958.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gawme2ckeDKG7JrIKmGohg.png"/></div></div></figure><p id="51b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">这里我们得到调整后的估计数=100，深度= 6</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mp"><img src="../Images/09f9dea04658bce298b273ce85bf1863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Wwh6RDquQO2znVeqQXiiA.jpeg"/></div></div></figure><p id="fff9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们没有得到像SMOTE一样好的结果，现在我们将通过X.G BOOST来实现</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mq"><img src="../Images/3f58ba3e024fd7ab5fc1ee85e98c9ef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wOYNmKbVbmIQUvBA5x6CAw.jpeg"/></div></div></figure><h2 id="2d9e" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">训练和测试之间的AUC_ROC曲线:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mq"><img src="../Images/21b4ee1d9bce2b491d28092a9213f072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bJTX65gbPAaPNigAxyNRkQ.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">正如我们所见，训练和测试AUC之间没有这种差异，这意味着我们的模型做得很好。</figcaption></figure><h2 id="0d07" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">用随机上采样技术实现X.G Boost。</h2><h2 id="7ef2" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">超参数调整和训练模型:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/3a12d79fec659d9ca63df3355d39973d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lzwQNhwWIXi6nU-A3vXrxw.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/fccc8a98b34245cc1dae22ab886ae958.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gawme2ckeDKG7JrIKmGohg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mr"><img src="../Images/1b89731555f7de7b325951b0daea05b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OqNXD_stlU5_3WWuGTRSNQ.jpeg"/></div></div></figure><p id="cb1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们可以看到，我们得到了轻微的增加召回，但我们的精度和召回是下降的</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ms"><img src="../Images/9e7f20130adeee8d1be11e932aa22e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0MZs6GMa7gC5oBiV3VL9Fg.jpeg"/></div></div></figure><h2 id="4b16" class="lb js hi bd jt lc ld le jx lf lg lh kb iq li lj kf iu lk ll kj iy lm ln kn lo bi translated">训练和测试之间的AUC_ROC曲线:</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mt"><img src="../Images/59b1e30db846ddb0b5c52c1434ae3b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*fjrShX-pqGYTEdx1GCev8g.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">正如我们所见，训练和测试AUC之间没有这种差异，这意味着我们的模型做得很好。</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mu"><img src="../Images/77fb686b48622a6cc69878305278d5a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qmu28LBzff1rMxiyDPw7pw.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mv"><img src="../Images/c2d0ff5e8034c07298b18c8c9a756954.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gsUdWnduXazvJfXUadwmKg.jpeg"/></div></div></figure><h1 id="8d42" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">最后意见:</h1><p id="f5e0" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">正如我们在上面漂亮的表格中看到的:</p><p id="65c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们需要v.good F1分数，那么与其他模型相比，带有SMOTE的决策树做得非常好。</p><p id="37cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们需要很好的精度值，那么与其他模型相比，上采样决策树做得很好。</p><p id="1a3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们需要v.good召回值，那么与其他模型相比，XGB和SMOTE做得非常好。</p><p id="42f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注:如果我们有两个型号的得分相差不大，那么我们将选择成本较低或重量较轻的型号。例如，在上面的例子中，我们更喜欢决策树而不是X.G Boost。</p><p id="3b76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们需要在精确度和召回率之间取得良好的平衡，那么我们将考虑F1的分数。</p><p id="c191" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参见https://github.com/himanshuknegi/HIGHLY-UNBALANCED-DATA-SET<a class="ae mf" href="https://github.com/himanshuknegi/HIGHLY-UNBALANCED-DATA-SET--END-TO-END-SOLUTION" rel="noopener ugc nofollow" target="_blank">端到端解决方案</a>的代码文件</p></div></div>    
</body>
</html>