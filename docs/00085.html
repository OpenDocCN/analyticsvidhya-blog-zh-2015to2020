<html>
<head>
<title>FAST ICA vs Reconstruction ICA vs Orthonormal ICA in Tensorflow / Matlab [Manual Back Prop in TF]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow / Matlab中的快速独立分量分析与重构独立分量分析与正交独立分量分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fast-ica-vs-reconstruction-ica-vs-orthonormal-ica-in-tensorflow-matlab-manual-back-prop-in-tf-8b3212924ad0?source=collection_archive---------1-----------------------#2018-09-05">https://medium.com/analytics-vidhya/fast-ica-vs-reconstruction-ica-vs-orthonormal-ica-in-tensorflow-matlab-manual-back-prop-in-tf-8b3212924ad0?source=collection_archive---------1-----------------------#2018-09-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/fa3183b2a7f9324a2f31fdffd7368c8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*gBgTiIbCusL-cNvavY_bew.gif"/></div><figcaption class="im in et er es io ip bd b be z dx translated">GIF来自这个<a class="ae iq" href="https://giphy.com/gifs/snl-saturday-night-live-mind-blown-9SIqlPusz8iLh1IFFJ" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="65a4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在阅读吴恩达教授的<a class="ae iq" href="http://ufldl.stanford.edu/tutorial/StarterCode/" rel="noopener ugc nofollow" target="_blank">无监督特征学习和深度学习教程</a>时，我发现了两种不同的执行ICA的方法，我想将这些方法与FastICA进行比较。</p><blockquote class="jp jq jr"><p id="0b32" class="ir is js it b iu iv iw ix iy iz ja jb jt jd je jf ju jh ji jj jv jl jm jn jo hb bi translated"><strong class="it hj">请注意，这个帖子是为了我练习我的编码技能，也是为了我将来回顾这个帖子上的材料。</strong></p></blockquote></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="6632" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">数据集</strong></p><div class="kd ke kf kg fd ab cb"><figure class="kh ij ki kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/c59246bf8cff436f9304b8d9158ae29b.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*QYWK1rg_mgddJwniyRnCdQ.png"/></div></figure><figure class="kh ij kr kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/50d8adb994ee544a68c563bd7347bfe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*nqp8Ba2Paz-S4l-JPPdOQg.png"/></div></figure></div><p id="16b6" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在这篇文章中，我将使用两个不同的数据集，即<a class="ae iq" href="http://preprocessed-connectomes-project.org/NFB_skullstripped/" rel="noopener ugc nofollow" target="_blank">神经反馈颅骨剥离(NFBS)库</a> <strong class="it hj"> </strong>和<a class="ae iq" href="http://scikit-learn.org/stable/datasets/olivetti_faces.html#olivetti-faces" rel="noopener ugc nofollow" target="_blank">来自sklearn的Olivetti人脸数据集</a>。</p></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="6a58" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">通过主成分分析进行降维</strong></p><div class="kd ke kf kg fd ab cb"><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/3305e25156adfa7159775690dfcd38ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*x4jsPGPz2LZS9VWAycO3TA.png"/></div></figure><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/3186eaef805a9a09967f9683552e1c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dfaoYpRRbezyneMecpXKVQ.png"/></div></figure></div><p id="4abb" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在将我们的数据统计分离成独立的成分之前，让我们首先通过PCA将其投影到较低的子空间。如上所述，我们可以看到每个图像看起来像什么。</p><div class="kd ke kf kg fd ab cb"><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/0630457f093a72321732f9e5a9aff96a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*nAYTkT7LtY4uVIpOdezU4Q.png"/></div></figure><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/70162d9a7ff5b54e1a511bf000aa0270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*gTkbF8UKwdweX2RTl4hd3A.png"/></div></figure></div><p id="9cac" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，在减去每个维度的平均值之前，让我们看看平均脸和平均核磁共振脑。</p><div class="kd ke kf kg fd ab cb"><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/fa04589c82d0e9b1aec4f21902dac141.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*N0RZgvis3VnMSDzmIM3Mcw.png"/></div></figure><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/c95554305f928de84e9c4603523b2ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*OoBypuelmM6QQQE0kPumpA.png"/></div></figure></div><p id="ad86" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">从每幅图像中减去平均值后，我们可以看到这些图像现在看起来像幽灵。(尤其是人脸图像。)</p><div class="kd ke kf kg fd ab cb"><figure class="kh ij kt kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/5f2123ae73d1de11ce1d54d6b243c4c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*I-X2utLGVaueBQdraADA2w.png"/></div></figure><figure class="kh ij ku kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/e216e0d9dd309de7f582269722bfb7f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*OxgkrRUfsZBHzuiWgghziQ.png"/></div></figure></div><p id="d0f0" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在让我们计算每个数据集的协方差矩阵，每个数据集的左侧图像是手动计算的协方差矩阵，而右侧图像表示由np.cov()计算的协方差矩阵。</p><div class="kd ke kf kg fd ab cb"><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/e2e018fa0fb710793fae61028e8bf961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*iUhxcDYfwyTweRIFQxZyww.png"/></div></figure><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/f5d88052de819f8f2ab3ea2fb1298ab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*nyonOkz4JqlZRUe_G_Y03Q.png"/></div></figure></div><p id="ab09" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，在对每个协方差矩阵执行特征值分解后，我们可以按降序绘制特征值。(而且看起来50是个不错的截止值。)</p><div class="kd ke kf kg fd ab cb"><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/998eb79fe823ce2c568aec46ff250f63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*5vjKvNID2ULWc2QibgAjYA.png"/></div></figure><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/e895ad3012acafb1bcf42369baa93cad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*3RrrcE8RUDgND-LH7oQ1Qg.png"/></div></figure></div><p id="454a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">上图展示了前50名特征大脑和特征面孔。(看着吓人lol。)</p><div class="kd ke kf kg fd ab cb"><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/cc661c0b0897c2c30b38ce97a52baab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*1R8QQQGtR_9v6jzyvvjoLw.png"/></div></figure><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/f578e0fb1375a22e302bd03bd194da2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*leYDi0t1c11CZasFxR8Zfw.png"/></div></figure></div><p id="c0eb" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">使用这50个顶部特征图像，现在让我们重建我们的原始数据，如上所述，原始图像与重建图像并不完全相同。</p></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="f06d" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">执行PCA时的注意事项</strong></p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kv"><img src="../Images/c292a94ef2be4642450f6a0fa62df578.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sVhtnijcjVfhs4aSVSVWzA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="https://sebastianraschka.com/Articles/2014_pca_step_by_step.html" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="c391" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在这个<a class="ae iq" href="https://sebastianraschka.com/Articles/2014_pca_step_by_step.html" rel="noopener ugc nofollow" target="_blank">网站</a>上有一个关于执行PCA的很好的教程，但是在其中一节作者提到了这样一个事实，即协方差矩阵和散布矩阵之间唯一的区别是命名因子。然而，在实验过程中，我注意到由于np.cov()的实现方式，这个比率可能会被打破。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kw"><img src="../Images/0fa86b198fbaf9ad0b08c588412a3444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VOpd242zYu3E5rw9F-b-Gg.png"/></div></div></figure><p id="f8b4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如上所述，当我们比较散布矩阵和共方差矩阵时，我们可以看到共方差矩阵比散布矩阵清晰。这主要是因为numpy cov是如何实现的，在创建协方差矩阵之前，它还要减去每个示例的平均值。(因此将每个例子移动到零均值)，因此产生了差异。但是，如果我们减去每个示例的平均值，我们可以观察到相同的协方差矩阵。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kx"><img src="../Images/783797e6d500ca2536d34fd106214fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3VJqJSYWcUkQ6e3dKvqUKA.png"/></div></div></figure><p id="170d" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">因此，总之，如果您希望遵循numpy步骤，仔细检查中间的值可能是个好主意。</p></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="7492" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">快速ICA </strong></p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es ky"><img src="../Images/c31bf67c3ab186ade6a1eb1a5bb15dbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MBWjZ7AOuJBvQzqEvcbRwg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="http://cis.legacy.ics.tkk.fi/aapo/papers/IJCNN99_tutorialweb/node28.html" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="8e0a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">既然我们已经进行了维度缩减，现在让我们使用FastICA使我们缩减的数据相互独立。此外，我将使用log(cosh())作为我的激活函数，下面是激活函数log(cosh())的图像。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kz"><img src="../Images/17407744721a15c8d03f68d00c670c8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPNmmE2IeugnBErEUS2U9w.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="https://www.desmos.com/calculator" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="b495" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在tensorflow中，我们可以实现FastICA，如下所示。(我在关注sklearn FastICA的实现。)</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es la"><img src="../Images/ccf166fad0d7c430148057c11c609daa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3jzDKyFqQYOxD8RUGM0-tg.png"/></div></div></figure><p id="7eba" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在经过1000次迭代后，我们可以看到每个独立组件的最终结果。</p><div class="kd ke kf kg fd ab cb"><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/9a149116fb245b29586313336b84be5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*1o-PmnQ0byWEB6fIfDCrOg.png"/></div></figure><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/346679ecec6f451d7868831adf333cc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*teQazkarIscQKA2hUsffbA.png"/></div></figure></div><p id="32c0" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">这里需要注意的一点是，ICA捕捉的是局部变化，而不是全局变化。</p><div class="kd ke kf kg fd ab cb"><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/4cd1ad133cd9606d064ea38c0a0bcf69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*gTiNC-rWMPr8y34gKDVZpw.gif"/></div></figure><figure class="kh ij ks kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/e2882c009a2e53dd661544312d455daf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*LROQDhoZUbLpKmj4harv3Q.gif"/></div></figure></div><p id="1e32" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">当我们将每个组件的收敛过程制作成动画时，它看起来就像上面这样。</p></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="ce75" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">重构ICA </strong></p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lb"><img src="../Images/6f1ab84ef2391e659164d708e9c3dad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z5Mc9M4lIfLgrREiD5Xzvw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="http://ufldl.stanford.edu/tutorial/unsupervised/RICA/" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="8c76" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">接下来让我们看看RICA的行动，此外，如果有人想知道如何驱动权重w的反向传播，请参见此处的<a class="ae iq" href="http://ufldl.stanford.edu/tutorial/unsupervised/ExerciseRICA/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="913f" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">请注意！我不会提前执行降维，而是只执行zca白化。</strong></p><div class="kd ke kf kg fd ab cb"><figure class="kh ij lc kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/34a0aed866f334ecdfc290275896caa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*HOEYLaAqheBWyR8WzrpNOw.png"/></div></figure><figure class="kh ij ld kj kk kl km paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><img src="../Images/247d588bf2a60c3df420a035f9878074.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*OM9BY5-Zf7fXum5rrc5CyA.png"/></div></figure></div><p id="e6a4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">正如上面所看到的，白化后，我们可以看到，边缘变得更加清晰。右图是白化后得到的协方差矩阵。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es le"><img src="../Images/af73ca5d3ef9f2f10858d9d737cb6fcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RTkzrItvT-BqwLMjVUVfkg.png"/></div></div></figure><p id="d082" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如上所述，我们可以在tensorflow中以分层方式实现RICA。通过这样做，我决定不使用回溯线搜索算法。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lf"><img src="../Images/ce0480503459da97a82ba7f11732176d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hXklaTAW13w1JWusdrF84A.png"/></div></div></figure><p id="684c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">不幸的是，我无法收敛算法，这可能是由于一些事情。直接执行降维，需要更多的迭代来收敛，或者需要使用回溯算法来寻找最佳步长等等。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lg"><img src="../Images/b136eeec9cc1347d20c4738fa0a6571e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yQV3ZgPXgi9itY2n9Ea4mA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="http://ufldl.stanford.edu/wiki/index.php?title=Exercise:Independent_Component_Analysis&amp;direction=prev&amp;oldid=1016#Step_4b:_Reconstruction_ICA" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="ed50" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如上所述，我们可以看到在低维图像上使用RICA效果很好。上面的例子使用8乘8的图像，有3个通道，所以每个图像有192个矢量。(图像是来自STL数据集的自然图像。).面部图像具有4096的维度，即64 * 64。</p></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="86b1" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">正交独立分量分析—回溯线搜索</strong></p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lh"><img src="../Images/871fc034041ef1f968f866de7b18a07c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_op2CXCtEzHxuavuhqjXIA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="https://en.wikipedia.org/wiki/Backtracking_line_search" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="95f6" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在学习正交独立分量分析的细节之前，学习回溯线搜索可能是一个好主意，在回溯线搜索中找到用于更新给定权重的最佳步长。(我只是理解为学习最优学习速率。)</p><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="li lj l"/></div><figcaption class="im in et er es io ip bd b be z dx translated">来自本<a class="ae iq" href="https://sites.math.washington.edu/~burke/crs/408/lectures/L7-line-search.pdf" rel="noopener ugc nofollow" target="_blank">网站</a>的PPT</figcaption></figure><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="li lj l"/></div><figcaption class="im in et er es io ip bd b be z dx translated">来自本<a class="ae iq" href="https://people.maths.ox.ac.uk/hauser/hauser_lecture2.pdf" rel="noopener ugc nofollow" target="_blank">网站</a>的PPT</figcaption></figure><figure class="kd ke kf kg fd ij"><div class="bz dy l di"><div class="li lj l"/></div><figcaption class="im in et er es io ip bd b be z dx translated">来自本<a class="ae iq" href="https://www.cs.cmu.edu/~ggordon/10725-F12/slides/05-gd-revisited.pdf" rel="noopener ugc nofollow" target="_blank">网站的PPT</a></figcaption></figure></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="ba9b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">正交独立分量分析</strong></p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kx"><img src="../Images/7209fb476846d9c8f6e824a85c966ea5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PxrU8O-fvf-S8uvp2gsOKA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="http://ufldl.stanford.edu/wiki/index.php/Independent_Component_Analysis" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="59bb" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">最后，让我们尝试正交独立分量分析，需要注意的一点是，正交独立分量分析与重构独立分量分析非常相似，但它有一个更强的约束，即权重矩阵的协方差矩阵是单位矩阵。请注意，我使用了这个<a class="ae iq" href="https://github.com/cswhjiang/UFLDL-Tutorial-Exercise/blob/master/Exercise11_independent_component_analysis_exercise/ICAExercise.m" rel="noopener ugc nofollow" target="_blank"> GitHub </a>和这个<a class="ae iq" href="https://github.com/PedroCV/UFLDL-Tutorial-Solutions/blob/master/Additional_2_Independent_Component_Analysis/orthonormalICACost.m" rel="noopener ugc nofollow" target="_blank"> GitHub </a>的可用代码来实现这些结果。(在Matlab中)</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lk"><img src="../Images/473ddbb5bffeeaa108dfdc27ffa5a83e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*mzy-frZeIa5M_RJIlmaeBA.gif"/></div></div></figure><p id="9bcc" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如上所述，当我们使用8*8块彩色图像(总共192维)时，该算法能够学习类似gabor滤波器的滤波器。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lk"><img src="../Images/c27a8ed759186fc498496ad1d8918444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*LOFnFE6Q9auBUGH3wir1pg.gif"/></div></div></figure><p id="36b3" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">然而，当对高维图像使用相同的算法时，该算法不能够收敛。</p></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="8fca" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">互动码</strong></p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es ll"><img src="../Images/83c7661c38bfc0f93b294d55d700e785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mdd7_2B_Wc-Q9UNGVLX6kw.png"/></div></div></figure><p id="145a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">对于Google Colab，你需要一个Google帐户来查看代码，而且你不能在Google Colab中运行只读脚本，所以在你的操场上复制一份。最后，我永远不会请求允许访问你在Google Drive上的文件，仅供参考。编码快乐！</p><p id="f368" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">要访问磁共振成像<a class="ae iq" href="https://colab.research.google.com/drive/16W7nZEgGucgfUXWYeXn1Nurur5wYdRgc" rel="noopener ugc nofollow" target="_blank">上的FastICA代码，请点击此处。</a> <br/>要访问面部FastICA的代码<a class="ae iq" href="https://colab.research.google.com/drive/10Ho316AMm283JS-ODrU9CyuB71Hm2Seh" rel="noopener ugc nofollow" target="_blank">请点击此处。</a> <br/>要获取RICA的代码，请<a class="ae iq" href="https://colab.research.google.com/drive/1iSwbjHP5ZYfpXAT05OuUUozx_2ULdz4t" rel="noopener ugc nofollow" target="_blank">点击此处。</a> <br/>要访问标准正交ICA的代码，请<a class="ae iq" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/tree/master/Understanding_Concepts/RICA_FASTICA/independent_component_analysis_exercise" rel="noopener ugc nofollow" target="_blank">点击此处。</a></p></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="f137" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">最后的话</strong></p><p id="b6da" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">最后，我想再次把这一节作为我的个人笔记。下面我附上了一个链接，这是一个很好的矩阵演算练习，以及矩阵转置规则的好表格。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lm"><img src="../Images/8acc6a333c4983b13b160b73b12c3b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y5lFUrZYo-M7rvDsoePV9w.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="https://math.stackexchange.com/questions/1646008/derivative-of-l-1-norm" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/4615dfcc366fe05fb5a67bd11847c695.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*ecE4l-i33KsL874xEj1p1w.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="https://stattrek.com/matrix-algebra/matrix-theorems.aspx" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="6508" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">以及知道ICA，FA，PCA区别的好答案。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lo"><img src="../Images/6361b10974e3e53ad8831105052b043d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yQFrTB2yGOGZfKO5VMpoPA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自本<a class="ae iq" href="https://stats.stackexchange.com/questions/35319/what-is-the-relationship-between-independent-component-analysis-and-factor-analy" rel="noopener ugc nofollow" target="_blank">网站</a></figcaption></figure><p id="d458" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如何在python中使用协方差矩阵进行PCA可以看<a class="ae iq" href="https://stackoverflow.com/questions/13224362/principal-component-analysis-pca-in-python" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="ba90" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如果发现任何错误，请发电子邮件到jae.duk.seo@gmail.com给我，如果你想看我所有写作的列表，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">同时，在我的twitter上关注我<a class="ae iq" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>，访问<a class="ae iq" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae iq" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>了解更多内容。我还实现了<a class="ae iq" rel="noopener" href="/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec">广残网，请点击这里查看博文</a> t。</p></div><div class="ab cl jw jx gp jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="hb hc hd he hf"><p id="f335" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">参考</strong></p><ol class=""><li id="ef3e" class="lp lq hi it b iu iv iy iz jc lr jg ls jk lt jo lu lv lw lx bi translated">5.6.1.Olivetti faces数据集-sci kit-learn 0 . 19 . 2文档。(2018).Scikit-learn.org。检索于2018年8月31日，来自<a class="ae iq" href="http://scikit-learn.org/stable/datasets/olivetti_faces.html#olivetti-faces" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/datasets/olivetti _ faces . html # olivetti-faces</a></li><li id="9ef4" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">Faces数据集分解-sci kit-学习0.19.2文档。(2018).Scikit-learn.org。检索于2018年8月31日，来自<a class="ae iq" href="http://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/auto _ examples/decomposition/plot _ faces _ decomposition . html # sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py</a></li><li id="6a98" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">[复本]，H. (2018)。如何在一个图中正确显示多个图像？。堆栈溢出。检索于2018年8月31日，来自<a class="ae iq" href="https://stackoverflow.com/questions/46615554/how-to-display-multiple-images-in-one-figure-correctly" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/46615554/how-to-display-multiple-images-in-one-figure-right</a></li><li id="fc60" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">使用多输出估计器的面补全—sci kit—学习0.19.2文档。(2018).Scikit-learn.org。检索于2018年8月31日，来自<a class="ae iq" href="http://scikit-learn.org/stable/auto_examples/plot_multioutput_face_completion.html#sphx-glr-auto-examples-plot-multioutput-face-completion-py" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/auto _ examples/plot _ multi output _ face _ completion . html # sphx-glr-auto-examples-plot-multi output-face-completion-py</a></li><li id="d07e" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">tf.enable_eager_execution必须在程序启动时调用。第18304期张量流/张量流。(2018).GitHub。检索于2018年8月31日，来自<a class="ae iq" href="https://github.com/tensorflow/tensorflow/issues/18304" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/tensorflow/issues/18304</a></li><li id="18e1" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">急切执行| TensorFlow。(2018).张量流。检索于2018年8月31日，来自<a class="ae iq" href="https://www.tensorflow.org/guide/eager" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/eager</a></li><li id="3dfa" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">线性代数(SciPy . linalg)-SciPy v 1 . 1 . 0参考指南。(2018).Docs.scipy.org。检索于2018年8月31日，来自<a class="ae iq" href="https://docs.scipy.org/doc/scipy/reference/tutorial/linalg.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/scipy/reference/tutorial/Lina LG . html</a></li><li id="2ca5" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">ZCA美白(<a class="ae iq" href="http://ufldl.stanford.edu/wiki/index.php/Implementing_PCA/Whitening" rel="noopener ugc nofollow" target="_blank">http://ufldl . Stanford . edu/wiki/index . PHP/Implementing _ PCA/Whitening</a>)。(2018).要点。检索于2018年8月31日，来自https://gist.github.com/dmaniry/5170087<a class="ae iq" href="https://gist.github.com/dmaniry/5170087" rel="noopener ugc nofollow" target="_blank"/></li><li id="f5e6" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">tf.pow | TensorFlow。(2018).张量流。检索于2018年8月31日，来自<a class="ae iq" href="https://www.tensorflow.org/api_docs/python/tf/pow" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/pow</a></li><li id="0bc3" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">j . brown lee(2018年)。机器学习中向量范数的简明介绍。机器学习精通。检索于2018年8月31日，来自<a class="ae iq" href="https://machinelearningmastery.com/vector-norms-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/vector-norms-machine-learning/</a></li><li id="404c" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">数学倒三角符号是什么意思——谷歌搜索。(2018).Google.co.kr。检索于2018年8月31日，来自<a class="ae iq" href="https://www.google.co.kr/search?q=math+what+does+upside+down+triangle+symbol+mean&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=0ahUKEwi6pNeyl5fdAhXGzmEKHU0pAukQ_AUICigB&amp;biw=1600&amp;bih=907#imgrc=HtbVWFH2bEP3OM" rel="noopener ugc nofollow" target="_blank">https://www.google.co.kr/search?q = math+what+does+upside+down+triangle+symbol+mean&amp;source = lnms&amp;TBM = isch&amp;sa = X&amp;ved = 0 ahukewi6 pneyl 5 fdahxgzmekhu 0 paukq _ AUICigB&amp;biw = 1600&amp;BIH = 907 # im GRC = htbvwfh 2 BEP 3 om</a>:</li><li id="f8b9" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">RuntimeError:预期的Double tensor(get Float tensor)问题#2138 pytorch/pytorch。(2018).GitHub。检索于2018年8月31日，来自<a class="ae iq" href="https://github.com/pytorch/pytorch/issues/2138" rel="noopener ugc nofollow" target="_blank">https://github.com/pytorch/pytorch/issues/2138</a></li><li id="6fec" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">norm，D. (2018)。$l_1$范数的导数。数学栈交换。检索于2018年8月31日，来自<a class="ae iq" href="https://math.stackexchange.com/questions/1646008/derivative-of-l-1-norm" rel="noopener ugc nofollow" target="_blank">https://math . stack exchange . com/questions/1646008/derivative-of-l-1-norm</a></li><li id="b929" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">矩阵定理。(2018).Stattrek.com。检索于2018年8月31日，来自<a class="ae iq" href="https://stattrek.com/matrix-algebra/matrix-theorems.aspx" rel="noopener ugc nofollow" target="_blank">https://stattrek.com/matrix-algebra/matrix-theorems.aspx</a></li><li id="8cbe" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">分析？，W. (2018)。独立成分分析和因子分析有什么关系？。交叉验证。检索于2018年9月1日，来自<a class="ae iq" href="https://stats.stackexchange.com/questions/35319/what-is-the-relationship-between-independent-component-analysis-and-factor-analy" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/35319/what-is-the-relationship-between-independent-component-analysis-and-factor-analyst</a></li><li id="8ccb" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">tf.random_uniform | TensorFlow。(2018).张量流。检索于2018年9月1日，来自<a class="ae iq" href="https://www.tensorflow.org/api_docs/python/tf/random_uniform" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/random _ uniform</a></li><li id="7d1d" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">回溯线搜索。(2018).En.wikipedia.org。检索于2018年9月2日，来自https://en.wikipedia.org/wiki/Backtracking_line_search<a class="ae iq" href="https://en.wikipedia.org/wiki/Backtracking_line_search" rel="noopener ugc nofollow" target="_blank"/></li><li id="86d9" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">练习:独立成分分析— Ufldl。(2018).Ufldl.stanford.edu。检索于2018年9月2日，来自<a class="ae iq" href="http://ufldl.stanford.edu/wiki/index.php?title=Exercise:Independent_Component_Analysis&amp;oldid=1298" rel="noopener ugc nofollow" target="_blank">http://ufldl.stanford.edu/wiki/index.php?title = Exercise:Independent _ Component _ Analysis&amp;oldid = 1298</a></li><li id="f182" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">Pedro cv/uf LDL-教程-解决方案。(2018).GitHub。2018年9月2日检索，来自<a class="ae iq" href="https://github.com/PedroCV/UFLDL-Tutorial-Solutions/blob/master/Additional_2_Independent_Component_Analysis/orthonormalICACost.m" rel="noopener ugc nofollow" target="_blank">https://github . com/Pedro cv/uf LDL-Tutorial-Solutions/blob/master/Additional _ 2 _ Independent _ Component _ Analysis/orthonormalcacost . m</a></li><li id="601d" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">cswhjiang/UFLDL-教程-练习。(2018).GitHub。2018年9月2日检索，来自<a class="ae iq" href="https://github.com/cswhjiang/UFLDL-Tutorial-Exercise/blob/master/Exercise11_independent_component_analysis_exercise/ICAExercise.m" rel="noopener ugc nofollow" target="_blank">https://github . com/cswhjiang/UFLDL-Tutorial-Exercise/blob/master/Exercise 11 _ independent _ component _ analysis _ Exercise/ICA Exercise . m</a></li><li id="31ff" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">objects，S. (2018)。洗牌的对象列表。堆栈溢出。检索于2018年9月3日，来自<a class="ae iq" href="https://stackoverflow.com/questions/976882/shuffling-a-list-of-objects" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/976882/shuffling-a-list-of-objects</a></li><li id="e21c" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">order，R. (2018)。以相同的顺序随机打乱不同文件中的数据和标签。堆栈溢出。检索于2018年9月3日，来自<a class="ae iq" href="https://stackoverflow.com/questions/43229034/randomly-shuffle-data-and-labels-from-different-files-in-the-same-order/43229113" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/43229034/random-shuffle-data-and-labels-from-different-files-in-the-same-order/43229113</a></li><li id="47ea" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">无监督特征学习和深度学习教程。(2018).Ufldl.stanford.edu。检索于2018年9月3日，来自http://ufldl.stanford.edu/tutorial/unsupervised/RICA/<a class="ae iq" href="http://ufldl.stanford.edu/tutorial/unsupervised/RICA/" rel="noopener ugc nofollow" target="_blank"/></li><li id="0636" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">无监督特征学习和深度学习教程。(2018).Ufldl.stanford.edu。检索于2018年9月3日，来自<a class="ae iq" href="http://ufldl.stanford.edu/tutorial/unsupervised/ExerciseRICA/" rel="noopener ugc nofollow" target="_blank">http://ufldl . Stanford . edu/tutorial/unsupervised/exercise Rica/</a></li><li id="efa2" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">练习:独立成分分析— Ufldl。(2018).Ufldl.stanford.edu。检索于2018年9月3日，来自<a class="ae iq" href="http://ufldl.stanford.edu/wiki/index.php?title=Exercise:Independent_Component_Analysis&amp;direction=prev&amp;oldid=1016#Step_4b:_Reconstruction_ICA" rel="noopener ugc nofollow" target="_blank">http://ufldl.stanford.edu/wiki/index.php?title = Exercise:Independent _ Component _ Analysis&amp;direction = prev&amp;oldid = 1016 # Step _ 4b:_ re construction _ ICA</a></li><li id="3095" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">实施主成分分析(PCA)。(2014).塞巴斯蒂安·拉什卡博士。2018年9月4日检索，来自<a class="ae iq" href="https://sebastianraschka.com/Articles/2014_pca_step_by_step.html" rel="noopener ugc nofollow" target="_blank">https://sebastianraschka . com/Articles/2014 _ PCA _ step _ by _ step . html</a></li><li id="8d79" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">Python，P. (2018)。Python中的主成分分析(PCA)。堆栈溢出。检索于2018年9月5日，来自<a class="ae iq" href="https://stackoverflow.com/questions/13224362/principal-component-analysis-pca-in-python" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/13224362/principal-component-analysis-PCA-in-python</a></li><li id="c18e" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">解码降维，主成分分析和奇异值分解。(2015).大数据变得简单—一个来源。多角度..检索于2018年9月5日，来自<a class="ae iq" href="http://bigdata-madesimple.com/decoding-dimensionality-reduction-pca-and-svd/" rel="noopener ugc nofollow" target="_blank">http://bigdata-made simple . com/decoding-dimensionally-reduction-PCA-and-SVD/</a></li><li id="5fc0" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">分解，U. (2018)。使用Numpy (np.linalg.svd)进行奇异值分解。堆栈溢出。2018年9月5日检索，来自<a class="ae iq" href="https://stackoverflow.com/questions/24913232/using-numpy-np-linalg-svd-for-singular-value-decomposition" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/24913232/using-numpy-NP-linalg-SVD-for-singular-value-decomposition</a></li><li id="c5a7" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">tf.cosh | TensorFlow。(2018).张量流。检索于2018年9月5日，来自https://www.tensorflow.org/api_docs/python/tf/cosh<a class="ae iq" href="https://www.tensorflow.org/api_docs/python/tf/cosh" rel="noopener ugc nofollow" target="_blank"/></li><li id="0bde" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">[实现后]收集对独立成分分析有用的演示文稿。(2018).中等。检索于2018年9月5日，来自<a class="ae iq" rel="noopener" href="/@SeoJaeDuk/achieved-post-collection-of-useful-presentation-for-independent-component-analysis-8e07426bf095">https://medium . com/@ SeoJaeDuk/achieved-post-collection-of-used-presentation-for-independent-component-analysis-8e 07426 BF 095</a></li><li id="8d72" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">德斯莫斯图表。(2018).德斯莫斯图形计算器。检索于2018年9月5日，来自<a class="ae iq" href="https://www.desmos.com/calculator" rel="noopener ugc nofollow" target="_blank">https://www.desmos.com/calculator</a></li><li id="aa13" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">Python中的DICOM:用PyDICOM和VTK将医学图像数据导入NumPy。(2014).PyScience。2018年9月5日检索，来自<a class="ae iq" href="https://pyscience.wordpress.com/2014/09/08/dicom-in-python-importing-medical-image-data-into-numpy-with-pydicom-and-vtk/" rel="noopener ugc nofollow" target="_blank">https://pyscience . WordPress . com/2014/09/08/DICOM-in-python-importing-medical-image-data-into-numpy-with-pydicom-and-VTK/</a></li><li id="0fea" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">scipy.misc.imread，u. (2018)。使用skimage替换scipy.misc.imread. Stack溢出。检索于2018年9月5日，来自<a class="ae iq" href="https://stackoverflow.com/questions/49686013/using-skimage-to-replace-scipy-misc-imread" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/49686013/using-skim age-to-replace-scipy-misc-im read</a></li><li id="15aa" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">模块:io —浏览v0.15.dev0文档。(2018).Scikit-image.org。检索于2018年9月5日，来自<a class="ae iq" href="http://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imread" rel="noopener ugc nofollow" target="_blank">http://scikit-image . org/docs/dev/API/skim age . io . html # skim age . io . im read</a></li><li id="4317" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">动画示例代码:dynamic _ image . py—Matplotlib 2 . 0 . 2文档。(2018).Matplotlib.org。检索于2018年9月5日，来自<a class="ae iq" href="https://matplotlib.org/examples/animation/dynamic_image.html" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/examples/animation/dynamic _ image . html</a></li><li id="5169" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">使用图像列表的动画图像— Matplotlib 2.1.2文档。(2018).Matplotlib.org。检索于2018年9月5日，来自<a class="ae iq" href="https://matplotlib.org/gallery/animation/dynamic_image2.html" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/gallery/animation/dynamic _ image2 . html</a></li><li id="929a" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">使用图像列表的动画图像— Matplotlib 2.1.2文档。(2018).Matplotlib.org。检索于2018年9月5日，来自<a class="ae iq" href="https://matplotlib.org/gallery/animation/dynamic_image2.html" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/gallery/animation/dynamic _ image2 . html</a></li><li id="fc1f" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">无监督特征学习和深度学习教程。(2018).Ufldl.stanford.edu。检索于2018年9月5日，来自http://ufldl.stanford.edu/tutorial/unsupervised/ICA/<a class="ae iq" href="http://ufldl.stanford.edu/tutorial/unsupervised/ICA/" rel="noopener ugc nofollow" target="_blank"/></li><li id="c1a1" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">NFBS骷髅仓库。(2018).Preprocessed-connectomes-project.org。检索于2018年9月5日，来自<a class="ae iq" href="http://preprocessed-connectomes-project.org/NFB_skullstripped/" rel="noopener ugc nofollow" target="_blank">http://preprocessed-connecto mes-project . org/NFB _ skull stripped/</a></li><li id="be23" class="lp lq hi it b iu ly iy lz jc ma jg mb jk mc jo lu lv lw lx bi translated">Faces数据集分解-sci kit-学习0.19.2文档。(2018).Scikit-learn.org。2018年9月5日检索，来自<a class="ae iq" href="http://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/auto _ examples/decomposition/plot _ faces _ decomposition . html # sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py</a></li></ol></div></div>    
</body>
</html>