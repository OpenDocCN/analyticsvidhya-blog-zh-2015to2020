<html>
<head>
<title>Traffic Sign Detection Using YOLOv2 and Tensorflow 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 YOLOv2 和 Tensorflow 2 的交通标志检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/traffic-sign-detection-using-yolov2-and-tensorflow-2-e3d5243a6ab2?source=collection_archive---------5-----------------------#2020-08-20">https://medium.com/analytics-vidhya/traffic-sign-detection-using-yolov2-and-tensorflow-2-e3d5243a6ab2?source=collection_archive---------5-----------------------#2020-08-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii"><div class="bz dy l di"><div class="ij ik l"/></div><figcaption class="il im et er es in io bd b be z dx translated">参考:<a class="ae ip" href="https://gfycat.com/grimyfeistyhornbill" rel="noopener ugc nofollow" target="_blank">https://gfycat.com/grimyfeistyhornbill</a></figcaption></figure><p id="856a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi jo translated"><span class="l jp jq jr bm js jt ju jv jw di"> D </span> eep 学习彻底改变了计算机视觉领域。神经网络被广泛应用于几乎所有的尖端技术，如特斯拉的自动驾驶功能。他们表现得太好了，有时会导致道德问题和冲突。我们今天不会深入讨论这些。让我们来关注一下计算机视觉的一个子类，叫做“检测”。</p><p id="3b11" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">探测一个物体是什么意思？当我们看到一个物体时，我们可以准确地指出它在哪里，并轻松地确定它是什么。然而对于计算机来说，任务并不简单。多年来，这一直是一个活跃的研究领域，今天仍然如此。在过去的十年里，随着深度学习的出现(而不是复兴)，我们能够取得良好的结果，在一定程度上已经可以使用它的实时场景。</p><p id="2841" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我们将使用<a class="ae ip" href="http://benchmark.ini.rub.de/?section=gtsdb&amp;subsection=dataset" rel="noopener ugc nofollow" target="_blank">德国交通标志检测基准(GTSDB) </a>数据集。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="ca2c" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">概观</h1><p id="6065" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">有几种用于检测的神经网络结构</p><ul class=""><li id="5b89" class="lh li hi is b it iu ix iy jb lj jf lk jj ll jn lm ln lo lp bi translated">R-CNN 系列架构</li><li id="fddf" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">单发探测器</li><li id="97a8" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn lm ln lo lp bi translated">YOLO——你只能看一次</li></ul><p id="8bf3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们今天将看到 YOLOv2 的实现(最初 YOLO 架构的一个变种),但不会详细介绍它是如何工作的。</p><p id="403d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">YOLO 带着 Joseph Redmon 等人在 2015 年发表的开创性论文进入了计算机视觉领域。“<a class="ae ip" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">你只看一次:统一的实时对象检测</a>，”并立即引起了计算机视觉研究人员的关注。这是华盛顿大学研究人员 Redmon 在 2017 年的一次 TED 演讲，强调了计算机视觉的艺术状态。</p><h2 id="1f5b" class="lv kf hi bd kg lw lx ly kk lz ma mb ko jb mc md ks jf me mf kw jj mg mh la mi bi translated">什么是 YOLO？</h2><p id="211b" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">对象检测是计算机视觉中的经典问题之一，在这里，您需要识别什么和在哪里，特别是在给定的图像中有什么对象，以及它们在图像中的位置。目标检测的问题比分类更复杂，分类也可以识别目标，但不能指出目标在图像中的位置。此外，分类不适用于包含多个对象的图像。</p><p id="40e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">YOLO 很受欢迎，因为它实现了高精度，同时还能够实时运行。该算法“只看一次”图像，因为它只需要一次通过神经网络的前向传播来进行预测。在非最大值抑制(确保对象检测算法只检测每个对象一次)之后，它会输出已识别的对象以及边界框。</p><p id="cbe3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有了 YOLO，单个 CNN 同时预测多个边界框和这些框的类别概率。YOLO 在全图像上训练，直接优化检测性能。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="4f1e" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">预处理:</h1><p id="494c" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">在实现 YOLOv2 模型之前，我们必须将数据集准备成<a class="ae ip" href="https://towardsdatascience.com/coco-data-format-for-object-detection-a4c5eaf518c5#:~:text=Pascal%20VOC%20is%20an%20XML,for%20training%2C%20testing%20and%20validation." rel="noopener" target="_blank"> PASCAL VOC </a>格式。</p><p id="708b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是首先我们需要将图像文件(ppm 格式)转换成 jpg 格式。</p><p id="08f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">转换图像文件后，让我们创建 PASCAL VOC 格式的 XML 文件。我们可以通过使用<a class="ae ip" href="https://pypi.org/project/pascal-voc-writer/" rel="noopener ugc nofollow" target="_blank"> PASCAL VOC Writer </a>包来完成，或者你可以关注这个<a class="ae ip" rel="noopener" href="/deepquestai/object-detection-training-preparing-your-custom-dataset-6248679f0d1d">博客</a>的 GUI。</p><p id="0efd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您还可以根据自己的需要，通过关注这个<a class="ae ip" href="https://github.com/italojs/resize_dataset_pascalvoc" rel="noopener ugc nofollow" target="_blank">博客</a>来调整图片大小和创建 XML 文件。<strong class="is hj">(如果您在创建 PASCAL VOC XML 后调整图像大小，则必须根据新图像编辑 XML 文件。)</strong></p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="7458" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">实施:</h1><p id="099b" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">让我们先导入必要的库。</p><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><p id="f686" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们声明必需的重要参数。</p><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><h2 id="2530" class="lv kf hi bd kg lw lx ly kk lz ma mb ko jb mc md ks jf me mf kw jj mg mh la mi bi translated">定义 YOLO 模型:</h2><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><h2 id="eee5" class="lv kf hi bd kg lw lx ly kk lz ma mb ko jb mc md ks jf me mf kw jj mg mh la mi bi translated">加载预训练重量:</h2><p id="f7ef" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">首先，我们必须从<a class="ae ip" href="https://pjreddie.com/media/files/yolov2.weights" rel="noopener ugc nofollow" target="_blank">这里</a>为我们的 YOLOv2 架构下载正确的预训练权重文件。</p><p id="c70d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们加载权重文件。</p><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><h2 id="fbfb" class="lv kf hi bd kg lw lx ly kk lz ma mb ko jb mc md ks jf me mf kw jj mg mh la mi bi translated"><strong class="ak">读取数据集:</strong></h2><p id="bfe6" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">下面的代码用于读取数据集，以便我们可以计算数据集中存在的图像数、每个时期的步数和每个时期的图像数。</p><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><p id="0e80" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">读取训练数据集:</strong></p><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><p id="ab69" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mo">输出:</em></p><p id="5fee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每个时期的步骤=图像数量//批量大小</p><pre class="mj mk ml mm fd mp mq mr ms aw mt bi"><span id="a228" class="lv kf hi mq b fi mu mv l mw mx">Dataset:<br/>Images count: 506<br/>Step per epoch: 50<br/>Images per epoch: 500</span></pre><p id="2142" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">读取验证数据集:</strong></p><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><p id="c5ed" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mo">输出:</em></p><pre class="mj mk ml mm fd mp mq mr ms aw mt bi"><span id="4a38" class="lv kf hi mq b fi mu mv l mw mx">Dataset:<br/>Images count: 235<br/>Step per epoch: 23<br/>Images per epoch: 230</span></pre><h2 id="942f" class="lv kf hi bd kg lw lx ly kk lz ma mb ko jb mc md ks jf me mf kw jj mg mh la mi bi translated"><strong class="ak">图像增强:</strong></h2><p id="b4c0" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">图像数据扩充是一种可用于通过在数据集中创建图像的修改版本来人为扩展训练数据集的大小的技术。</p><p id="eac6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图像数据扩充用于扩展训练数据集，以提高模型的性能和概括能力。</p><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><h1 id="cf21" class="ke kf hi bd kg kh my kj kk kl mz kn ko kp na kr ks kt nb kv kw kx nc kz la lb bi translated">培训:</h1><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><p id="2e8d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，让我们针对 1000 个时期训练我们的模型，其中 10 个步骤用于训练时期，2 个步骤用于验证数据集的时期。</p><pre class="mj mk ml mm fd mp mq mr ms aw mt bi"><span id="8eb7" class="lv kf hi mq b fi mu mv l mw mx">train(EPOCHS, model, train_gen, val_gen, 10, 2, 'training_1')</span></pre><p id="d286" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">保存训练好的模型的权重:</strong></p><p id="cab7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练结束后，我们应该保存重量以备将来使用。</p><pre class="mj mk ml mm fd mp mq mr ms aw mt bi"><span id="e380" class="lv kf hi mq b fi mu mv l mw mx">model.save_weights('traffic.h5')</span></pre><h2 id="cb13" class="lv kf hi bd kg lw lx ly kk lz ma mb ko jb mc md ks jf me mf kw jj mg mh la mi bi translated">测试模型:</h2><p id="9f47" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">培训结束后，是时候测试我们的模型了。</p><p id="f6ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面的代码用于测试我们的模型。</p><figure class="mj mk ml mm fd ii"><div class="bz dy l di"><div class="mn ik l"/></div></figure><p id="d897" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们调用上面的函数:</p><pre class="mj mk ml mm fd mp mq mr ms aw mt bi"><span id="042c" class="lv kf hi mq b fi mu mv l mw mx">x_files =  glob.glob('data/test/*.jpg')</span><span id="0c8c" class="lv kf hi mq b fi nd mv l mw mx">score = SCORE_THRESHOLD<br/>iou_threshold = IOU_THRESHOLD</span><span id="15ed" class="lv kf hi mq b fi nd mv l mw mx">score = 0.65<br/>iou_threshold = 0.3</span><span id="5878" class="lv kf hi mq b fi nd mv l mw mx">for file in x_files[::]:<br/>    display_yolo(file, model, score, iou_threshold)</span></pre><figure class="mj mk ml mm fd ii er es paragraph-image"><div class="er es ne"><img src="../Images/397b110f156a0836ca8ee070ff86e7a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*nXFNBour9Pv2Zm0cBmIhxg.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx translated">图 1:检测到的迹象</figcaption></figure><h1 id="a810" class="ke kf hi bd kg kh my kj kk kl mz kn ko kp na kr ks kt nb kv kw kx nc kz la lb bi translated">使用 web 应用程序测试模型:</h1><p id="7806" class="pw-post-body-paragraph iq ir hi is b it lc iv iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn hb bi translated">在这里，我们将使用我们的模型测试另一个图像。</p><figure class="mj mk ml mm fd ii er es paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="er es nh"><img src="../Images/7ae19c163549c9530b689ee0d51547d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPOilJHh9OAgqfnF68eG1g.jpeg"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">图 2:演示图像</figcaption></figure><p id="2f20" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们启动 web 应用程序(使用 Flask 开发)</p><figure class="mj mk ml mm fd ii er es paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="er es nm"><img src="../Images/3614f29be8da4a1584434c1dc04d76de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i3gY8OKujNpyUnWsZfESYA.jpeg"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">图 3:索引页面</figcaption></figure><p id="f9f8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们上传图片并点击提交</p><figure class="mj mk ml mm fd ii er es paragraph-image"><div class="er es nn"><img src="../Images/e8b9bcefe35fc23b42099aedd42f46e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*zmEJ1kQmPw8mFG2HjTOnGA.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx translated">图 4:检测到的迹象</figcaption></figure><h1 id="0e8d" class="ke kf hi bd kg kh my kj kk kl mz kn ko kp na kr ks kt nb kv kw kx nc kz la lb bi translated">结论:</h1><ol class=""><li id="fb48" class="lh li hi is b it lc ix ld jb no jf np jj nq jn nr ln lo lp bi translated">如果我们增加历元的数量，模型会表现得更好。越多越好。</li><li id="b221" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn nr ln lo lp bi translated">我们还可以上传视频或使用网络摄像头进行实时检测。</li></ol><h1 id="1dc5" class="ke kf hi bd kg kh my kj kk kl mz kn ko kp na kr ks kt nb kv kw kx nc kz la lb bi translated">参考资料:</h1><ol class=""><li id="4c3c" class="lh li hi is b it lc ix ld jb no jf np jj nq jn nr ln lo lp bi translated">原创研究论文:<a class="ae ip" href="https://arxiv.org/abs/1612.08242" rel="noopener ugc nofollow" target="_blank"> YOLO9000:更好更快更强</a></li><li id="c928" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn nr ln lo lp bi translated">概念帮助:<a class="ns nt ge" href="https://medium.com/u/bc8571e39021?source=post_page-----e3d5243a6ab2--------------------------------" rel="noopener" target="_blank">应用人工智能课程</a></li><li id="675c" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn nr ln lo lp bi translated">数据集:<a class="ae ip" href="http://benchmark.ini.rub.de/?section=gtsdb&amp;subsection=dataset" rel="noopener ugc nofollow" target="_blank">德国交通标志检测基准(GTSDB) </a></li><li id="f30d" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn nr ln lo lp bi translated">GitHub 链接:<a class="ae ip" href="https://github.com/sandeeppanda22/GTSD-using-YOLOv2" rel="noopener ugc nofollow" target="_blank">使用 YOLOv2 的 GTSDB】</a></li><li id="71df" class="lh li hi is b it lq ix lr jb ls jf lt jj lu jn nr ln lo lp bi translated">领英简介:<a class="ae ip" href="https://www.linkedin.com/in/sandeepkumarpanda/" rel="noopener ugc nofollow" target="_blank">桑迪普·库马尔·熊猫</a></li></ol></div></div>    
</body>
</html>