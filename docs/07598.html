<html>
<head>
<title>Hyper-parameter optimization using EDAspy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用EDAspy进行超参数优化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hyper-parameter-optimization-using-edaspy-8b6490b953e3?source=collection_archive---------27-----------------------#2020-06-30">https://medium.com/analytics-vidhya/hyper-parameter-optimization-using-edaspy-8b6490b953e3?source=collection_archive---------27-----------------------#2020-06-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d1ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">调整机器学习超参数是一项乏味的任务，我们倾向于推迟到项目的最后。超参数无处不在，手动调谐几乎是不可能的。</p><p id="e17a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们只有一个超参数，我们想优化它。我们将不得不执行程序、脚本、算法或者我们正在调整的任何东西N次，N是参数的可能值的数量。有了两个参数，我们将不得不为第二个参数的每次执行N次，因此，N**2。诸如此类。</p><p id="ed09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">超参数调整存在许多可能性。在这种情况下，我将解释一种来自进化算法的方法。特别是<em class="jm">分布估计算法(EDAs)。</em>类似于遗传算法。该算法的核心是迭代地提出一些解决方案，从中选择最适合我们要优化的代价函数的方案。从这些选择中，我们基于从它们构建的正态分布生成新的解决方案。图1显示了一个流程图。在每次迭代中，对具有一组解的一代进行采样。这被称为具有多个个体的一代。在最佳个体的选择中，选择这一代的一个百分比(α参数)</p><p id="87ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种类型的算法可以用于进一步的任务，如特征选择(FS)或根据其他变量的一些进一步的固定值优化一些变量。以后的故事会谈到这个话题。</p><figure class="jo jp jq jr fd js er es paragraph-image"><div class="er es jn"><img src="../Images/4286b4555b8c36c8a0eb941c5512a453.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*Xd9GeEMmauM1fNrunZwSug.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">图一。分布估计算法(EDA)的流程图。</figcaption></figure><p id="b018" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看一个使用Python包<a class="ae jz" href="https://pypi.org/project/EDAspy/" rel="noopener ugc nofollow" target="_blank"> EDAspy </a>解决的简单例子。要安装该软件包，只需:</p><pre class="jo jp jq jr fd ka kb kc kd aw ke bi"><span id="c243" class="kf kg hi kb b fi kh ki l kj kk">pip install EDAspy</span></pre><p id="67fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有一个如下的成本函数。我们要优化的三个超参数是dictionary['param1']、dictionary['param2']和dictionary['param3']。成本函数也包含一些权重。该算法必须找到超参数的最佳值，以便最小化成本函数。</p><pre class="jo jp jq jr fd ka kb kc kd aw ke bi"><span id="a048" class="kf kg hi kb b fi kh ki l kj kk">weights = [20,10,-4]</span><span id="0642" class="kf kg hi kb b fi kl ki l kj kk">def cost_function(dictionary):<br/>    function = weights[0]*dictionary['param1']**2 + weights[1]*(np.pi/dictionary['param2']) - 2 - weights[2]*dictionary['param3']<br/>    if function &lt; 0:<br/>        return 9999999<br/>    return function</span></pre><p id="5d3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该算法需要一个开始评估解的初始范围作为输入。可选地，该算法可以设置超参数的最大值和最小值。它们都在pandas表中设置，每个数据占一行，每个超参数名占一列。如果未设置最大值和最小值，则不要引入最大值和最小值行。</p><pre class="jo jp jq jr fd ka kb kc kd aw ke bi"><span id="54e0" class="kf kg hi kb b fi kh ki l kj kk">from EDAspy.optimization.univariate import EDA_continuous as EDAc<br/>import pandas as pd<br/>import numpy as np<br/><br/>wheights = [20,10,-4]<br/><br/>def cost_function(dictionary):<br/>    function = wheights[0]*dictionary['param1']**2 + wheights[1]*(np.pi/dictionary['param2']) - 2 - wheights[2]*dictionary['param3']<br/>    if function &lt; 0:<br/>        return 9999999<br/>    return function<br/><br/>vector = pd.DataFrame(columns=['param1', 'param2', 'param3'])<br/>vector['data'] = ['mu', 'std', 'min', 'max']<br/>vector = vector.set_index('data')<br/>vector.loc['mu'] = [5, 8, 1]<br/>vector.loc['std'] = 20<br/>vector.loc['min'] = 0<br/>vector.loc['max'] = 100<br/><br/>EDA = EDAc(SIZE_GEN=40, MAX_ITER=200, DEAD_ITER=20, ALPHA=0.7, vector=vector, aim='minimize', cost_function=cost_function)</span><span id="8dbe" class="kf kg hi kb b fi kl ki l kj kk">bestcost, params, history = EDA.run()<br/>print(bestcost)<br/>print(params)<br/>print(history)</span></pre><p id="78bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，我们使用连续的单变量EDA。优化时，超参数之间没有相关性。它们都是独立调谐的。作为算法的参数，我们将SIZE_GEN设置为个体的数量(每次迭代的解的数量)；MAX_ITER为最大迭代次数；DEAD_ITER作为没有最佳全局成本改进的迭代次数，在此之后算法将停止；α为我们从哪个样本中选择作为最佳个体来更新正态分布的一代的百分比；和成本函数。注意，ALPHA和初始向量也可以根据需要进行调整。高alpha将选择大范围的解决方案，并且倾向于缓慢收敛(如果收敛的话)。较低的α值可能意味着会陷入局部最优。我建议在不同的执行中尝试不同的α值。</p><p id="2b0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果需要绘图，该算法将返回最佳成本、参数和历史记录。图2显示了一个曲线图。</p><figure class="jo jp jq jr fd js er es paragraph-image"><div class="er es km"><img src="../Images/7827b7fe19482ca2f9d2124b4ba9b24c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*_MrAnNhURDb9XVp8frQ2lg.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">图二。最佳全球成本演变。</figcaption></figure><p id="caaa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">未来的故事我将谈论与EDAs和这个惊人的优化包的其他方法的FS！</p></div></div>    
</body>
</html>