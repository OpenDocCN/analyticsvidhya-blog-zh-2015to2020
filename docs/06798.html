<html>
<head>
<title>Using TPUs on Google Colab with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过Keras在Google Colab上使用TPU</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/using-tpus-on-google-colab-with-keras-da9f6f7f80a6?source=collection_archive---------28-----------------------#2020-06-02">https://medium.com/analytics-vidhya/using-tpus-on-google-colab-with-keras-da9f6f7f80a6?source=collection_archive---------28-----------------------#2020-06-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="d86c" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">今天，我在温习一门关于情感分类的旧NLP课程，突然感觉到在一些大型数据集上尝试一下的冲动。我玩得很开心——我也看到了Colab上的免费TPU到底有多快。</h2></div><p id="e645" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">速度快了10倍，但过程并不简单。包括代码变更(大部分是样板文件)，因此这篇文章。</p><p id="c19a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">作为第一步，我只是想建立一个简单的模型来编译和提供一些预测。我选择了Kaggle上的<a class="ae jt" href="https://www.kaggle.com/kazanova/sentiment140" rel="noopener ugc nofollow" target="_blank">sensition 140数据集</a>。该数据集有160万条带有积极和消极情绪标签的推文。它的大小是288 MB，这对于我的目的来说是很好的。我为训练模型编写的代码非常简单，因为我正在做非常基本的预处理。</p><p id="e43c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">训练时间——差不多1小时30分钟一个时代！</strong>这对初始模型来说是行不通的。是时候测试一下Colab上提供的免费TPU了。</p><p id="6dd1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我最初以为这只是一个简单的设置变化。所以我进入编辑菜单中的笔记本设置，要求一个TPU硬件加速器。训练仍然需要一个多小时，所以很明显没有提供TPU。在浏览TPU文档时(这里:<a class="ae jt" href="https://www.tensorflow.org/guide/tpu" rel="noopener ugc nofollow" target="_blank">使用TPU </a>，很明显我们必须明确设置什么是<em class="ju">计算分发策略</em>，并在它下面构建我们的模型。以下文本中的解释，以及相关的样板文件:</p><ul class=""><li id="ef22" class="jv jw hi iz b ja jb jd je jg jx jk jy jo jz js ka kb kc kd bi translated">首先，我们必须明确要求在代码中使用TPU。Colab和真实的GCP云TPU是不同的，所以必须小心。</li></ul><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="2aa3" class="kn ko hi kj b fi kp kq l kr ks"><em class="ju">import tensorflow as tf<br/>#Get a handle to the attached TPU. On GCP it will be the CloudTPU itself<br/>resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=’grpc://’ + os.environ[‘COLAB_TPU_ADDR’])#Connect to the TPU handle and initialise it<br/>tf.config.experimental_connect_to_cluster(resolver)<br/>tf.tpu.experimental.initialize_tpu_system(resolver)</em></span></pre><p id="5394" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们设定分销策略</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="762b" class="kn ko hi kj b fi kp kq l kr ks"><em class="ju">strategy = tf.distribute.experimental.TPUStrategy(resolver)</em></span></pre><ul class=""><li id="8ec4" class="jv jw hi iz b ja jb jd je jg jx jk jy jo jz js ka kb kc kd bi translated">之后，我们创建模型</li></ul><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="c861" class="kn ko hi kj b fi kp kq l kr ks"><em class="ju">with strategy.scope():<br/> model = create_model()#Build your model<br/> model.compile(optimizer=…)#Set your parameters</em></span></pre><ul class=""><li id="61dd" class="jv jw hi iz b ja jb jd je jg jx jk jy jo jz js ka kb kc kd bi translated">然后用通常的方式训练它</li></ul><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="d682" class="kn ko hi kj b fi kp kq l kr ks"><em class="ju">model.fit(…)</em></span></pre><p id="1b80" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这现在起作用了。过去需要90分钟的训练，现在只需9.5分钟就能完成。毫无疑问非常有效和高效，尽管主题相当神秘。</p><p id="8782" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">问题是:它所需要的只是一些样板代码，那么为什么它没有隐藏在一些Keras抽象下呢？也许在未来的版本中会有。</p><p id="9498" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一篇:<a class="ae jt" rel="noopener" href="/@umash4/trials-and-tribulations-using-keras-on-colab-and-tpu-69378762468d"> <strong class="iz hj">风雨:在科lab和TPU上使用Keras</strong></a></p></div></div>    
</body>
</html>