<html>
<head>
<title>PyTorch For Deep Learning — Confusion Matrix</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习的 PyTorch 混淆矩阵</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/pytorch-for-deep-learning-confusion-matrix-e73163277c95?source=collection_archive---------3-----------------------#2020-09-13">https://medium.com/analytics-vidhya/pytorch-for-deep-learning-confusion-matrix-e73163277c95?source=collection_archive---------3-----------------------#2020-09-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/6d8d0b1b1dbfccb5d87766ce01191960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nsemd-K1tlODC2MZRFR-1Q.jpeg"/></div></div></figure><p id="3c37" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">注意:这是 PyTorch 的一个常规分类问题，与“深度学习 PyTorch”系列的前一篇文章中的问题一模一样。写这篇文章的原因是为了更多的参考分类问题和更好的理解。如果你对神经网络分类已经足够好了，跳到混淆矩阵出现的部分。</em></p><h1 id="e3d2" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">跳到代码部分</h1><ol class=""><li id="7e85" class="kn ko hi is b it kp ix kq jb kr jf ks jj kt jn ku kv kw kx bi translated"><strong class="is hj">导入所需的库</strong></li></ol><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="507c" class="lh jq hi ld b fi li lj l lk ll">#importing the libraries</span><span id="db7e" class="lh jq hi ld b fi lm lj l lk ll">import torch<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><p id="5313" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2。数据</strong></p><p id="76e4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据集可在卡格尔获得:<a class="ae ln" href="https://www.kaggle.com/dragonheir/logistic-regression" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/dragonheir/logistic-regression</a></p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="3d63" class="lh jq hi ld b fi li lj l lk ll">#importing the dataset<br/>df = pd.read_csv('Social_Network_Ads.csv')<br/>df.head()</span></pre><p id="f774" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3。删除用户 Id，因为它与广告点击无关</strong></p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="c651" class="lh jq hi ld b fi li lj l lk ll">#droping insignificant columns</span><span id="f7bf" class="lh jq hi ld b fi lm lj l lk ll">df.drop(['User ID'],inplace=True,axis=1)</span></pre><p id="43cc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 4。移除性别栏</strong></p><p id="431b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">经过一些探索性的数据分析，决定删除性别列，因为在这种情况下没有太大的意义。<br/>女性点击广告的次数往往略多于男性。但是，数量不是很大</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="7ffd" class="lh jq hi ld b fi li lj l lk ll">#removing the gender column as there is not much effect on the adclicks</span><span id="53c2" class="lh jq hi ld b fi lm lj l lk ll">df.drop(['Gender'],axis=1,inplace=True)</span></pre><p id="ada0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 5。分析年龄与广告点击的关系，以及工资与广告点击的关系</strong></p><p id="e58f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从下面的图表中可以明显看出，年龄和工资会影响一个人是否购买该产品。</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="c2a8" class="lh jq hi ld b fi li lj l lk ll">#plotting age vs purchased</span><span id="4c58" class="lh jq hi ld b fi lm lj l lk ll">sns.scatterplot(df['Age'],df['Purchased'],hue=df['Purchased'])</span></pre><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/d00fc2e2ef88935b863a62ae74e89142.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*nfYQm6neXKM2GSRz1rZNRw.png"/></div></figure><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="0a3a" class="lh jq hi ld b fi li lj l lk ll">#salary vs purchased</span><span id="9fdb" class="lh jq hi ld b fi lm lj l lk ll">sns.scatterplot(df['EstimatedSalary'],df['Purchased'],hue=df['Purchased'])</span></pre><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/40c403c8bd2a96d1ee7e357c200ec9e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*meieD7-4IM8nTH81gLOS4g.png"/></div></figure><p id="1159" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 6。列车试运行</strong></p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="fb05" class="lh jq hi ld b fi li lj l lk ll">x = np.array(df.iloc[:,:2])<br/>y = np.array(df.iloc[:,2])</span><span id="8998" class="lh jq hi ld b fi lm lj l lk ll">from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test =<br/>train_test_split(x,y,test_size=0.2)</span><span id="2680" class="lh jq hi ld b fi lm lj l lk ll">print('shape of the x_train: ',x_train.shape)<br/>print('shape of the x_test : ',x_test.shape)<br/>print('shape of the y_train: ',y_train.shape)<br/>print('shape of the x_test: ',y_test.shape)</span><span id="a474" class="lh jq hi ld b fi lm lj l lk ll"><strong class="ld hj">output:</strong></span><span id="b2e1" class="lh jq hi ld b fi lm lj l lk ll">shape of the x_train:  (320, 2) <br/>shape of the x_test :  (80, 2) <br/>shape of the y_train:  (320,) <br/>shape of the x_test:  (80,)</span></pre><p id="60b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 7。特征缩放</strong></p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="4eac" class="lh jq hi ld b fi li lj l lk ll">#feature scaling</span><span id="0197" class="lh jq hi ld b fi lm lj l lk ll">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>x_train = sc.fit_transform(x_train)<br/>x_test = sc.transform(x_test)</span></pre><p id="2206" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">8。数据集</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="6920" class="lh jq hi ld b fi li lj l lk ll">#dataset class</span><span id="a486" class="lh jq hi ld b fi lm lj l lk ll">from torch.utils.data import Dataset</span><span id="a78c" class="lh jq hi ld b fi lm lj l lk ll">class dataset(Dataset):<br/>  def __init__(self,x,y):<br/>    self.x = torch.tensor(x,dtype=torch.float32)<br/>    self.y = torch.tensor(y,dtype=torch.float32)<br/>    self.length = self.x.shape[0]<br/>  <br/>  def __getitem__(self,idx):<br/>    return self.x[idx],self.y[idx]</span><span id="1007" class="lh jq hi ld b fi lm lj l lk ll">  def __len__(self):<br/>    return self.length</span><span id="2c94" class="lh jq hi ld b fi lm lj l lk ll">#training and testing tensors</span><span id="2e79" class="lh jq hi ld b fi lm lj l lk ll">train_set = dataset(x_train,y_train)<br/>test_set = dataset(x_test,y_test)</span></pre><p id="89bb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">9。神经网络</p><p id="c386" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一个简单的神经网络，在最后一层有 sigmoid 激活</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="ab8d" class="lh jq hi ld b fi li lj l lk ll">#defining the network</span><span id="1f01" class="lh jq hi ld b fi lm lj l lk ll">from torch import nn<br/>from torch.nn import functional as F</span><span id="c694" class="lh jq hi ld b fi lm lj l lk ll">class LogisticRegression(nn.Module):<br/>  def __init__(self):<br/>    super(LogisticRegression,self).__init__()<br/>    self.fc1 = nn.Linear(2,1)<br/> <br/>  def forward(self,x):<br/>    x = torch.sigmoid(self.fc1(x))<br/>    return x</span><span id="aceb" class="lh jq hi ld b fi lm lj l lk ll"><br/>#some parameters</span><span id="d7ce" class="lh jq hi ld b fi lm lj l lk ll">model = LogisticRegression()<br/>learning_rate = 0.007<br/>optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)<br/>epochs = 1000<br/>criterion = nn.BCELoss()</span></pre><p id="1b75" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">10。数据加载器</p><p id="8020" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">dataloader 使向前传递变得更容易，在这种情况下，我通过指定批量大小等于训练集的大小来执行批量梯度下降</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="91ae" class="lh jq hi ld b fi li lj l lk ll">#data loader</span><span id="fbef" class="lh jq hi ld b fi lm lj l lk ll">from torch.utils.data import DataLoader<br/>train_loader = DataLoader(train_set,shuffle=True,batch_size=train_set.__len__())</span><span id="4037" class="lh jq hi ld b fi lm lj l lk ll">test_loader = DataLoader(test_set,batch_size=test_set.__len__())</span></pre><p id="7e82" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">11。前进和后退道具</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="4f53" class="lh jq hi ld b fi li lj l lk ll">#forward pass</span><span id="70af" class="lh jq hi ld b fi lm lj l lk ll">losses = []</span><span id="836d" class="lh jq hi ld b fi lm lj l lk ll">for i in range(epochs):<br/>  for j,(x_train,y_train) in enumerate(train_loader):<br/>    #get the prediction<br/>    y_pred = model(x_train)<br/> <br/>    #losses<br/>    loss = criterion(y_pred,y_train.reshape(-1,1))<br/>    losses.append(loss)</span><span id="cd51" class="lh jq hi ld b fi lm lj l lk ll">    #backprop<br/>    optimizer.zero_grad()</span><span id="5606" class="lh jq hi ld b fi lm lj l lk ll"><br/>    loss.backward()<br/>    optimizer.step()</span><span id="990c" class="lh jq hi ld b fi lm lj l lk ll">  #print loss<br/>  if i%100 == 0:<br/>    print("epoch : {} loss: {}".format(i,loss))</span><span id="3b01" class="lh jq hi ld b fi lm lj l lk ll"><strong class="ld hj">Output: <br/></strong>epoch : 0 loss: 0.6956004500389099 <br/>epoch : 100 loss: 0.47631335258483887 <br/>epoch : 200 loss: 0.41070833802223206 <br/>epoch : 300 loss: 0.38835814595222473 <br/>epoch : 400 loss: 0.37939146161079407 <br/>epoch : 500 loss: 0.3754518926143646 <br/>epoch : 600 loss: 0.3736688494682312 <br/>epoch : 700 loss: 0.37286680936813354 <br/>epoch : 800 loss: 0.37251609563827515 <br/>epoch : 900 loss: 0.3723692297935486</span></pre><p id="93a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">12。模型分析</p><p id="8ce0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">绘制训练集中各时期的损失，并计算模型对测试集预测的准确性</p><p id="eefc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">混淆矩阵也显示在下面</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="7841" class="lh jq hi ld b fi li lj l lk ll">plt.plot(losses)<br/>plt.title('loss vs epochs')<br/>plt.xlabel('epochs')<br/>plt.ylabel('loss')</span></pre><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/6d9282ffa054157e0e6514b932f17952.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*pQfI3ajJrIsEVkC3XvFiwg.png"/></div></figure><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="be1f" class="lh jq hi ld b fi li lj l lk ll">#testset</span><span id="36b0" class="lh jq hi ld b fi lm lj l lk ll">x_test,y_test = next(iter(train_loader))<br/>y_pred = model(x_test)<br/>print('accuracy of the model on test set : ',(((y_pred.round().reshape(-1) == y_test).sum())/float(y_pred.shape[0])).item(),"%")</span><span id="1d52" class="lh jq hi ld b fi lm lj l lk ll"><strong class="ld hj">output: <br/></strong>accuracy of the model on test set :  0.8374999761581421 %</span></pre><p id="fcca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 13。混乱矩阵</strong></p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/d5f57a81a550ac2894afdf0905d59045.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*YNoONs9T0IYclCqRSwa3ZQ.png"/></div></figure><p id="7dd4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它返回 4 个值:<br/>第一个值代表:真阳性<br/>第二个值代表:假阳性<br/>第三个值代表:假阴性<br/>第四个值代表:真阴性</p><pre class="ky kz la lb fd lc ld le lf aw lg bi"><span id="f8b1" class="lh jq hi ld b fi li lj l lk ll">from sklearn.metrics import confusion_matrix<br/>print("Confusion Matrix : ")<br/>confusion_matrix(y_pred.round().reshape(-1).detach(),y_test)</span><span id="c87f" class="lh jq hi ld b fi lm lj l lk ll"><strong class="ld hj">output: </strong></span><span id="c799" class="lh jq hi ld b fi lm lj l lk ll">Confusion Matrix :</span><span id="4c2c" class="lh jq hi ld b fi lm lj l lk ll">array([[184,  34],<br/>       [ 18,  84]])</span></pre><p id="6a8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">结论:</strong></p><p id="0d97" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这篇博客文章快速回顾了之前文章和混淆矩阵<br/>中的内容。从上面的混淆矩阵中，我们可以得出结论，这个模型做得很好，尽管它给出了一些错误。但是，现在没事了。</p><h1 id="43b4" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">谢谢</strong></h1></div></div>    
</body>
</html>