<html>
<head>
<title>License Plate Object Detection and Recognition using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的车牌目标检测和识别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/license-plate-object-detection-yolov3-and-recognition-pytesseract-d7628de1d110?source=collection_archive---------6-----------------------#2019-11-12">https://medium.com/analytics-vidhya/license-plate-object-detection-yolov3-and-recognition-pytesseract-d7628de1d110?source=collection_archive---------6-----------------------#2019-11-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="7c4c" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">为人类2019年使用Yolov3和pytesseract</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/f8b049dd59dc0f4812985685bc037083.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jL3abxoCaM2Y_ac4"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">汤姆·格伦鲍尔在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="c5e7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在尖端世界的不同部分下，信息发展的巨大融合，已经刺激了车辆作为信息系统中计算资源的处理。由于决策信息结构在没有任何数据的情况下没有任何意义，因此需要改变当前世界中的车辆信息。</p><p id="3bb3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">有两种方法来理解这些信息，要么在人类管理员的帮助下，要么在最新技术的帮助下，帮助我们通过车牌识别车辆的证据。监控在几乎每个行业都起着至关重要的作用，无论是建筑工地、安全驾驶、头盔检测，还是帮助我们识别未注册车牌的车牌检测。</p><p id="7e86" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">深度学习在通过计算机视觉进行检测和识别的领域有着广阔的前景。深度学习的使用包括使用用于图像分类的卷积神经网络、深度神经网络、递归神经网络等。为了检测目标，可能的方法是R-CNN或更快的R-CNN和其他预训练模型。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="8fec" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated"><strong class="ak">工作范围</strong></h1><p id="ea7b" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">车牌检测项目可以帮助我们识别违反交通规则的人，特别是在信号灯处，在学校附近超过一定的最低速度等。在两轮车的情况下，牌照检测可以与头盔检测相结合，用于在驾驶时可能不戴头盔的驾驶员。然而，与印度车牌检测问题相关的基本问题是缺乏从低分辨率相机拍摄的高质量图像。</p><p id="bb56" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">另一个问题是，与外国不同，缺乏明确或具体的车牌尺寸。在开发车牌检测的解决方案时，我想到的一个方面是车牌的一部分，通常是字符和数字上方的部分，指定了一些文字信息。例如，在高级政府官员的情况下，它规定了人员的职务(见下图)。我们不想考虑这一部分，并删除不需要的文字部分，只检索牌照上的数字和字符。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lo"><img src="../Images/17f0a78a4bf0f3ac7383af1cfd015ebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*OivIIEZz8uZHkhu1aHbYYw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">注意:所使用的图像仅用于解释目的，并不打算使用任何私人车牌号码或名称</figcaption></figure><p id="e110" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">印度人还可以在车牌上指定任意形状的数字，而不仅仅是机器生成的数字。例如，下图将数字“214”指定为一个字符序列，表示北印度语中Ram勋爵的姓名。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lp"><img src="../Images/9f2fc966f320e1662b353f5121e07a1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*T-swkhJBdDFixRJ1OK_9yQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">注意:所使用的图像仅用于解释目的，并不打算使用任何私人车牌号码或名称</figcaption></figure></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="2790" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated"><strong class="ak">解决方法</strong></h1><p id="d1f1" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated"><strong class="jq hj">使用的算法/库:</strong></p><ol class=""><li id="26a0" class="lq lr hi jq b jr js ju jv jx ls kb lt kf lu kj lv lw lx ly bi translated">Json文件预处理:数据集存在于json文件中，指定内容、标签、图像宽度、图像高度以及右下角和左上角边界框的x和y坐标。我们必须将所有字段分开，并以csv格式存储它们。为此，我使用了python中的pandas库。</li><li id="4084" class="lq lr hi jq b jr lz ju ma jx mb kb mc kf md kj lv lw lx ly bi translated">对于数据扩充:Darknet使我们能够通过改变yolo-tiny-obj.cfg中图像的饱和度、色调和亮度来执行数据扩充，yolo-tiny-obj . CFG包含了我们模型的架构。欲了解更多信息，请参考[2]</li><li id="73df" class="lq lr hi jq b jr lz ju ma jx mb kb mc kf md kj lv lw lx ly bi translated">对于目标检测:目标检测的主要部分是决定使用哪个模型。有大量的型号可供我们选择，每种型号都有所不同。宽泛的分类或广泛使用的可以分为YOLO(你只看一次)，RetinaNet和SSD5模型。</li></ol><p id="cf5c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从下图来看，最好的机型是YOLOv3和RetinaNet。YOLOv3的平均精度(map)时间与RetinaNet相当。尽管如此，推理时间比RetinaNet短。因此，我使用YOLOv3-tiny模型进行物体检测。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/cbaed9a3fddca9183430144ff97699ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xV6b0Fl5q8TX5Lj5IJOlAg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">各种模型在推理时间方面的比较[4]</figcaption></figure><p id="ab80" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">4.对于光学字符识别:在获得牌照上所需的边界框后，我们必须生成包含字符和数字的字符串。以下任务是使用库pytesseract库完成的。有关文档，请参考[4]。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="7454" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">实施细节</h1><p id="db53" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated"><strong class="jq hj">预处理步骤</strong></p><p id="65f6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">json文件中的数据被转换成. csv格式，包含内容、标签、边界框的给定坐标、图像高度、图像宽度、注释和附加内容等列。需要注意的是，坐标是归一化形式的。首先将所有细节转换成内容、注释、附加内容、左上角坐标等，并存储在csv文件中。为此，运行<strong class="jq hj"><em class="mf">separate . py</em></strong>文件。</p><p id="7336" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">获得csv文件中的所有细节后，我们将从web链接中抓取图像。图像以增量方式保存为图像(I)。jpg，其中I是I的值，从0到data-1的大小，还添加了另一列，即csv文件中每个图像的名称。运行<strong class="jq hj"><em class="mf">image _ save . py</em></strong></p><p id="c5d5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">左上和右下坐标以标准化形式存储在csv文件中。我们通过将图像的x坐标乘以宽度，y坐标乘以高度，将它们转换成非标准化形式。这四列被添加到指定非标准化坐标值的数据集中。这一步的完成是因为YOLO有一种特殊的格式来获取围绕感兴趣区域的边界框的输入坐标，这将在下一段中讨论。运行<strong class="jq hj"><em class="mf">binding _ box . py</em></strong>。要在图像上随机查看有界框，运行<strong class="jq hj"><em class="mf">draw _ bounding _ box . py</em></strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mg"><img src="../Images/84df7387355daf1d8839ed006c85649c.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*11yTd_fjqafMWFUNp45mmg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">横跨车牌的边界框</figcaption></figure><p id="a665" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在YOLO，我们必须为每个图像创建一个. txt文件，并且应该与图像同名。对于每个图像，txt文件将包含五个值——类标签，在我们的例子中是0，绝对中心坐标，x_center和y_center，以及边界框相对于整个图像形状的绝对宽度和高度</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mh"><img src="../Images/1df73ade4ae8ffe6d61b9c5937b42784.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*Nt9CdHMZ8-GONv6Zr4MzGQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">注释的方向。YOLO的txt文件</figcaption></figure><p id="981c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">例如，具有图像宽度806和高度466的坐标(582，274)和(700，321)的边界框被转换为:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mi"><img src="../Images/4e856cb85ce267b3aeb57a5071591b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*p3HyfM5NTqGGPd0PAGU1Gg.png"/></div></figure></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="dbc7" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">设置暗网YOLOv3:</h1><p id="5820" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">从[2]中克隆darknet YOLOv3架构。在命令提示符下执行以下命令来设置darknet。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mj"><img src="../Images/d6bcfa9386fd04e3c5dcc16192c261b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*zhdPAp62ZgRNJypCGmNAbA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">从[2]克隆Darknet</figcaption></figure><p id="2d86" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">将图像及其相应的txt文件复制到data下名为obj的文件夹中。创建指定类名的obj.names文件。在数据文件夹下，还创建一个obj.data文件，指定以下内容:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mk"><img src="../Images/9a856b72cdd0bbf5f322ee56bf844858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*nCdlGtZEo_Nt0g0hjl5o1g.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">在obj.data文件中指定详细信息</figcaption></figure><p id="2479" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因为我们只处理一个类，我们必须通过在输出YOLOv3层设置过滤器和classes参数来改变指定YOLO架构的配置文件。在我们的例子中，设置classes=1，filters =(classes+5) *3 = 18 [2]。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="99af" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">培训和测试</h1><p id="9ce2" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">按照图Run<strong class="jq hj"><em class="mf">split _ train _ test . py</em></strong>所示的格式将图像分成训练集和测试集</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ml"><img src="../Images/de23e55ab926f8180bb290f02dc83839.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*HOKGV7Xwmc2QnN5iTI2dqg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">存储在数据文件夹中的train.txt文件快照</figcaption></figure><p id="70c0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">运行以下命令来训练模型</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mm"><img src="../Images/52fc305ed7430d30438035d7d22fb9a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*2d4O6kPXs0kl9oqBK25AQQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">训练对象检测模型</figcaption></figure><p id="fff3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于Linux或Mac，将darknet.exe替换为。/darknet</p><p id="d095" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">要测试图像并获取感兴趣区域的坐标，请运行predict.py，命令行参数为image_name，architecture。cfg文件、训练重量文件和类别文件(对象名称)</p><p id="c720" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">注意:给出重量和其他文件的完整路径</strong>。</p><p id="c888" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"><em class="mf">predict . py—image path _ to _ img—config yolo v3-tiny-obj . CFG—weights yolo v3-tiny . conv . 15—classes data/obj . names</em></strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mn"><img src="../Images/124fe5aa4d064ab76efe53418b02e210.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*_C2GLnFeib3g-3V9J4eIVQ.jpeg"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">车牌预测。</figcaption></figure><p id="d95c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">获取字符(OCR): </strong></p><p id="6f1a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">一旦我们知道了包围盒的坐标值，就可以使用PIL库裁剪原始图像，使其只包含车牌，而不是整张图像。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mo"><img src="../Images/8da46edaab2bf6aae38844a5b690ca0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:232/format:webp/1*ohaI5P7qZMbP9sSsw1PgGg.jpeg"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">捕获感兴趣区域的裁剪图像</figcaption></figure><p id="a2e3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后使用tesseract从图像生成文本。</p><p id="cfff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"><em class="mf">python ocr . py trying.jpg</em>T3】</strong></p><p id="ee4b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">trying.jpg是裁剪图像的名称。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mp"><img src="../Images/24a6a6d45384732f58dc2f8daa3759e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:296/format:webp/1*F_lxm3GtZaottRpcJMqpkw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">宇宙魔方库的输出</figcaption></figure></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><p id="4cae" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">你可以在我的github库下载预训练的权重和必要的文件</p><p id="3349" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">【https://github.com/anuj200199/licenseplatedetection T4】</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="c013" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated"><strong class="ak">参考文献</strong></h1><p id="33d9" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">[1]Yann le Cun、Patrick Haffner、Leon Bottou、Yoshua Bengio使用基于梯度的学习进行目标检测。</p><p id="6d78" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[2]用于Windows的Yolo-v3和Yolo-v2，由AlexeyAB开发。</p><p id="f597" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[3]YOLOv3 —你只看一次(对象检测改进了YOLOv2，性能与RetinaNet相当，速度快3.8倍！作者Sik-Ho Tsang。</p><p id="9bc6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[4]Mathias A . Lee的Python宇宙魔方。</p></div></div>    
</body>
</html>