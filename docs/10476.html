<html>
<head>
<title>Understanding FastAI v2 Training with a Computer Vision Example- Part 3: FastAI Learner and Callbacks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过计算机视觉示例了解 FastAI v2 培训-第 3 部分:FastAI 学习者和回调</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-fastai-v2-training-with-a-computer-vision-example-part-3-fastai-learner-and-a3ea85c6fe78?source=collection_archive---------6-----------------------#2020-10-20">https://medium.com/analytics-vidhya/understanding-fastai-v2-training-with-a-computer-vision-example-part-3-fastai-learner-and-a3ea85c6fe78?source=collection_archive---------6-----------------------#2020-10-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7164ab30fc6ec39890eaef7ba6486205.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hc2LV0GFMaYQ47wH2w0lBg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来源:<a class="ae iu" href="https://images.app.goo.gl/juHhyxgoGhUPRNY38" rel="noopener ugc nofollow" target="_blank">https://images.app.goo.gl/juHhyxgoGhUPRNY38</a></figcaption></figure><p id="1f84" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是我在这个系列的第三篇文章。本系列的目标读者是那些已经熟悉 FastAI，并希望更深入地了解幕后发生的事情的人。在本文中，我们将使用第一篇文章中构建的 resnet 模型来理解 FastAI Learner &amp; Callbacks。该系列的总体结构如下:</p><ol class=""><li id="dc64" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated"><a class="ae iu" rel="noopener" href="/@rakesh.melezhath/understanding-fastai-v2-training-with-a-computer-vision-example-part-1-the-resnet-model-dd9270450bb8">研究 resnet34 模型架构，并使用普通 Python &amp; PyTorch </a>构建它。</li><li id="6948" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae iu" rel="noopener" href="/@rakesh.melezhath/understanding-fastai-v2-training-with-a-computer-vision-example-part-2-fastai-optimizers-df65cb018604">深入研究 FastAI 优化器&amp;实现一个 NAdam 优化器。</a></li><li id="5fc5" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae iu" rel="noopener" href="/@rakesh.melezhath/understanding-fastai-v2-training-with-a-computer-vision-example-part-3-fastai-learner-and-a3ea85c6fe78">学习 FastAI 学习器和回调&amp;用回调实现一个学习率查找器(lr_find 方法)。</a></li></ol><p id="1cf6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用 Google Colab 来运行我们的代码。你可以在这里 找到这篇文章<a class="ae iu" href="https://github.com/Rakeshsuku/Medium-Blog/tree/master/Understanding%20FastAI%20v2%20Training" rel="noopener ugc nofollow" target="_blank"> <em class="kh">的代码文件。我们开始吧..！</em></a></p><p id="249b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，我们将从第一篇文章中快速重建我们的模型。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ki"><img src="../Images/d48256dc0cf4fbdd13b3b364b3c61258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FIcSODYOU68lm11j_-nzlg.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/3467ff3fa33c26a25b9d6b88b432e9e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xdxDDTY2pdRYRwBfnqRcoA.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/832ab2efc8954b418a0190552184f426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FR-x0EBGV5yaKz9sk6PAew.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/2faabf5b4a937994032e55d8a7860a1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ANM1dJOlgZPkRtNiAHmvLg.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/2746c599a1a9a66343c5d4c52261d2b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*leKcOEcCIgyL0TPHO3S4cw.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/74627c3b7bae4d4032672b0578588fbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n_3vHJwuHIr-HdTaHvVBFw.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/fc3919be1e0bb433569ee8becbc0b209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lcIjVyIPH7SwicPaLVcNrg.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ki"><img src="../Images/e61d7754caab4461dbcede13c5d4b468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MBT4GDJdjhxa1LHUGm14eQ.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/1bd4a2eedf013173e26263036f8fac3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xudrObzeoroHIbeTu9JURw.png"/></div></div></figure><p id="925a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们使用我们的模型创建一个学习者。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kr"><img src="../Images/54cd92e935abcac0c7e6df51c5ee99cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ko6QSXIo_8Dgp7MHJfplQQ.png"/></div></div></figure><p id="8d8b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们来理解更精简的构造函数的参数:</p><ul class=""><li id="02df" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js ks jz ka kb bi translated">dls:包含训练和验证数据的 dataloaders 对象。</li><li id="251d" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">模型:神经网络模型。</li><li id="f436" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">loss_func:要使用的损失函数。如果未指定损失函数，则使用数据加载器对象的默认损失函数。dataloader 对象根据目标的类型选择适当的损失函数。在这里，由于我们已经使用了一个<em class="kh"> CategoryBlock </em>(见上面的 dblock 创建)<em class="kh">作为我们的目标变量，CrossEntropyLoss 被添加为默认损失函数。FastAI 有一个很好的关于创建自定义损失函数的教程<a class="ae iu" href="https://docs.fast.ai/tutorial.imagenette#Changing-the-loss-function" rel="noopener ugc nofollow" target="_blank"> <em class="kh">这里</em> </a>。</em></li></ul><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/f1ab6ede0ef890107f2033e2ce8148dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BblAQmNpT7w-7mtXsB421w.png"/></div></div></figure><ul class=""><li id="f8c6" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js ks jz ka kb bi translated">opt_func:用于创建优化器对象的函数(可调用)。默认情况下，会添加一个 Adam 优化器。</li><li id="07ec" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">lr:默认学习率。</li><li id="55bd" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">splitter:将模型作为输入并返回参数组列表的函数。默认函数'<em class="kh">trainiable _ param()</em>'将模型的所有可训练参数(参数要求 _grad = True)作为创建单个参数组的单个列表返回。</li><li id="4c65" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">cbs:定制训练循环的回调列表。默认情况下，FastAI 为学习者添加了以下回调:<em class="kh"> TrainEvalCallback </em>、<em class="kh">记录器</em>和<em class="kh"> ProgressCallback </em>。在本文中，我们将详细研究学员回访。</li></ul><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/21f5825777639c1947eab92857915bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FZ_bItVRtSg_vpLhOf3ZFA.png"/></div></div></figure><ul class=""><li id="66a6" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js ks jz ka kb bi translated">metrics:可选的度量列表，可以是函数，也可以是 FastAI 度量类的对象。默认情况下，不选择任何指标。</li></ul><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/d793cf2ef4be58dfd44880ffe1fca9fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1a8pOVDugk_OjUCJToNCCw.png"/></div></div></figure><ul class=""><li id="d84e" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js ks jz ka kb bi translated">路径&amp; model_dir:路径和 model_dir 用于保存和(或)装入模型。</li><li id="3381" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">wd:使用默认重量衰减。</li><li id="8e74" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">moms:learn . fit _ one _ cycle()方法中使用的默认动量。</li><li id="5764" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">wd_bn_bias:控制权重衰减是否应用于 batchnorm 类型图层和偏移参数。默认行为是不对这些层应用 wd。</li><li id="76d4" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">train_bn:控制是否要训练 batchnorm 类型层，即使它们属于模型的冻结部分。默认行为是训练 batchnorm 类型图层。</li></ul><p id="d390" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> FastAI 训练循环</strong></p><p id="0e6f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用 learn.fit()方法来研究 FastAI 训练循环。让我们训练一个时期的模型作为参考。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/ebba9fd9310430ead62eb91bdcc7f343.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aNBzFaqM1ObBGbfQFQxVMA.png"/></div></div></figure><p id="9821" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们看看 learn.fit()方法的参数。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/633415a8d7996d75f9dbd6dd33a78b1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ep0yVXsN9bK3ybBZNeWqlA.png"/></div></div></figure><p id="613c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">learn.fit()方法接受以下参数:</p><ul class=""><li id="770d" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js ks jz ka kb bi translated">n_epoch:模型必须被训练的时期数</li><li id="017b" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">lr &amp; wd:优化器使用的学习率和权重衰减</li><li id="7a0b" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">cbs:为 fit 操作添加到学习者的任何附加回调。注意，这是除了用学习者构造函数添加的回调之外的。在 fit()操作之后，这些回调将从学习者对象中移除。</li><li id="e52d" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">reset_opt:一个布尔标志，用于指示与学习者对象相关联的优化器是否需要重置。</li></ul><p id="b437" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">拟合操作(learn.fit()方法调用)由数据集中的<em class="kh">n _ epoch</em>epoch 组成。一个历元包括通过训练数据集的一次完整迭代，随后是通过验证数据集的一次完整迭代。FastAI 使用控制流的事件&amp;异常。在 FastAI fit 操作中有五种事件类型&amp;相关异常(括号中提供了异常):</p><ol class=""><li id="d336" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">fit(取消异常)</li><li id="4e61" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">纪元(CancelEpochException)</li><li id="790f" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">训练(CancelTrainException)</li><li id="e6d3" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">验证(CancelValidException)</li><li id="2023" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">批处理(CancelBatchException)</li></ol><p id="4112" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这些事件类型与以下事件相关联:</p><ul class=""><li id="f8ae" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js ks jz ka kb bi translated">在 _ {事件类型}之前</li><li id="fb01" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">after _ cancel _ {事件类型}</li><li id="c4fd" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">在 _ {事件类型}之后。</li></ul><p id="7fc0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这些事件类型的控制流如下(请参见下图以便更好地理解):</p><ol class=""><li id="8985" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated"><em class="kh">前 _ {事件类型} </em>事件。稍后我将解释事件的控制流。</li><li id="6726" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">调用与事件类型相关联的函数/方法。</li><li id="3dcc" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><em class="kh">after _ cancel _ { event _ type }</em>事件，如果在步骤 1 中引发了相关异常。请注意，如果异常发生在步骤 1 中，则只跳过步骤 2。</li><li id="3ce6" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><em class="kh">在 _ {事件类型} </em>事件之后。步骤 4 &amp; 5 始终运行，即使在步骤 1 中出现异常。</li><li id="368b" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">一个可选的“<em class="kh">最终</em>功能可以在事件类型结束时运行。在 learn.fit()方法调用中，只有'<em class="kh"> fit </em>'事件类型有'<em class="kh"> final </em>'函数(<em class="kh"> self。_end_cleanup() </em>)与之关联(见下图)。</li></ol><p id="63ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">除了上述事件之外，FastAI 还有以下事件，这些事件在训练/验证/推理运行期间每批都会遇到。</p><ul class=""><li id="e4d2" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js ks jz ka kb bi translated"><em class="kh"> after_pred </em></li><li id="eadd" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated"><em class="kh"> after_loss </em></li><li id="faa2" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated"><em class="kh">前 _ 后</em>(仅用于训练运行)</li><li id="44a5" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated"><em class="kh"> after_backwar </em> d(仅用于训练运行)</li><li id="7074" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated"><em class="kh"> after_step </em>(仅用于训练运行)</li></ul><p id="21ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">事件调用传入事件名称的学习者对象(例如:“after_pred”事件调用 learn(‘after _ pred’))。稍后我将详细解释事件的控制流。首先让我们研究一下 fit 操作。fit()操作过程中的控制流可以通过下图得到最好的解释。注意，如果在 _ {事件类型} 事件之前的<em class="kh">期间没有异常发生，则执行相关的方法，并且控制在 _ {事件类型} </em>事件之后传递到<em class="kh">。然而，如果在 _ {事件类型}之前的<em class="kh">期间引发了<em class="kh">取消{事件类型}异常</em>，则跳过</em>相关方法&amp;，控制传递到 _ 取消 _ {事件类型} </em>事件之后的<em class="kh">。</em></p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/9c2ec86c53d61c74d3984206044534fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZCqbw_9Qk6lLbWOn1KrhYg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">在 FastAI fit 操作期间控制流程。请注意，如果在 before_{event type}事件期间没有发生异常，则执行相关联的方法，并将控制传递给 after_{event type}事件。但是，如果在 before_{event type}事件期间引发了 Cancel { event type }异常，则跳过相关联的方法&amp;控制权将传递给 after_cancel_{event type}事件。</figcaption></figure><p id="37fb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我将简要解释这些方法/事件的作用。注意，下面的“learn”/“self”指的是学习者对象。</p><ol class=""><li id="20bb" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">learn . fit():learn . fit()方法创建一个上下文，将附加回调(传递给 fit 方法)添加到学习者对象中。这确保了在执行 fit()方法之后，从学习者中移除附加的回调。接下来，如果优化器对象尚未与学习器对象相关联，或者如果<em class="kh"> reset_opt </em>参数<em class="kh"> </em>为真，则创建新的优化器对象。然后，它将<em class="kh"> n_epoch </em>存储为学习者对象的属性，并用<em class="kh"> </em> torch 初始化损失值<em class="kh"> learn.loss </em>。张量([0。]).接下来，它启动从'<em class="kh"> before_fit' </em>事件开始的'<em class="kh"> fit' </em>事件类型的控制流。</li><li id="a35f" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">before_fit: before_fit 事件调用 learn('before_fit ')</li><li id="8d3f" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">学习。_do_fit():启动 for 循环，为<em class="kh">learn . n _ epoch</em>epoch 训练模型。对于每次迭代，将当前纪元编号存储为<em class="kh"> learn.epoch </em>，并从“<em class="kh"> epoch </em>”事件类型的“<em class="kh"> before_epoch </em>”事件开始启动控制流。</li><li id="dbec" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">before_epoch: before_epoch 事件调用 learn('before_epoch ')</li><li id="b96b" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">自我。_do_epoch():首先调用 self。_do_epoch_train()在训练数据集上运行 1 个 epoch，然后调用 self。_do_epoch_validate()对验证数据集运行 1 个 epoch(计算损失和指标)。</li><li id="853d" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">自我。_do_epoch_train():将训练数据加载器设置为<em class="kh"> self.dl </em>，并启动以'<em class="kh"> before_train </em>事件开始的'<em class="kh"> train </em>事件类型的控制流程。在执行完'<em class="kh">列车</em>事件类型后，self。调用 _do_epoch_validate()，将验证数据加载器设置为<em class="kh"> self.dl </em>，并使用 torch.no_grad()启动'<em class="kh"> validate </em>'事件类型的控制流，以便禁用验证运行的梯度计算。注意那个自我。_do_epoch_validate()方法也在推断时在 learn.predict()调用中使用，以获得新样本的预测。</li><li id="23a1" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">before_train: before_train 调用 learn('before_train ')。</li><li id="ecc4" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">self.all_batches():将<em class="kh"> self.n_iter </em>设置为 self.dl 的长度(即批次号)。注意，self.dl 在训练运行期间设置为训练数据加载器(事件类型:'<em class="kh"> train </em>')，在验证运行期间设置为验证数据加载器(事件类型:'<em class="kh"> validate </em>')。接下来，它在每个 I 上调用 self.one_batch(i，b)，在 enumerate 中调用 batch ' b(<em class="kh">self . dl)</em>。</li><li id="5758" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">self.one_batch(i，b):将“I”设置为<em class="kh"> self.ite </em> r，并将批处理“b”拆分为<em class="kh"> self.xb - </em>输入和<em class="kh"> self.yb </em> -目标。然后，从'<em class="kh"> before_batch </em>事件开始，启动'<em class="kh"> batch </em>事件类型的控制流程。</li><li id="f5b5" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">before_batch: before_batch 调用 learn('before_batch ')</li><li id="7e04" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">自我。_do_one_batch(): self。_do_one_batch()执行以下操作:</li></ol><p id="26ab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(I)获取该批的预测，并将其存储到 self.pred</p><p id="c23a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">㈡after _ pred:调用 learn(‘after _ pred’)</p><p id="5cb4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(iii)通过调用 self.loss_func()计算损失，并将其存储到 self.loss 中</p><p id="a6d5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(四)亏损后:调用 learn(‘亏损后’)。</p><p id="08ec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(v) before_backward:调用 learn('before_backward ')。(v)至(ix)仅在训练运行时执行。</p><p id="b3b8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">㈥自我。_backward():通过调用 self.loss.backward()计算渐变</p><p id="c33b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(vii)after_backward:调用 learn('after_backward ')</p><p id="6634" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(七)自我。_step():调用 self.opt.step()来更新参数。</p><p id="fe58" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(viii)在 _ 步骤之后:调用 learn(“在 _ 步骤之后”)</p><p id="e71f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(ix) self.opt.zero_grad():将梯度归零。</p><p id="019c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">12.自我。_end_cleanup():在 fit 事件类型结束时调用，以重置<em class="kh"> self.xb、self.yb、self.dl、self.pred </em>和<em class="kh"> self.loss </em>。</p><p id="82a7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们看看当调用 learn(事件名称)时，事件期间的控制流。</p><p id="e224" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">事件期间的流量控制</strong></p><p id="c9b5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当调用 learn(事件名称)时，FastAI 会执行以下操作:</p><ol class=""><li id="7952" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">获取与学习者对象相关联的所有回调。</li><li id="0fcf" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">按照正确的顺序对回调进行排序。(我将很快解释排序逻辑)。您可以使用 sort_by_run()函数检查回调的排序顺序。</li><li id="da90" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">对于排序列表中的每个回调(假设 cb ),运行与“事件名称”(即 cb)同名的方法。如果回调有这样一个方法，并且它满足以下 3 个条件中的任何一个:</li></ol><p id="343f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(i) (cb.run = True)和(事件名称是* <em class="kh">内部事件</em>之一)</p><p id="10ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(ii) (cb.run = True)和(cb.run_train = True)以及(learn.training = True，如果 learn 具有“training”属性。)</p><p id="da6e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(iii)(CB . run = True)AND(CB . run _ valid = True)AND(learn . training = False，如果 lean 具有“training”属性)</p><p id="51b6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kh">内部事件:</em> before_batch、after_pred、after_loss、before_backward、after_backward、after_step、after_cancel_batch、after_batch。</p><p id="da3d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">回调属性 cb.run、cb.run_valid 和 cb.run_train 可用于启用/禁用回调，默认情况下它们都被设置为真。顾名思义，属性“run_train”和“run_valid”可分别用于在训练或验证/推理期间有选择地运行回调。此外，请注意，在“after_fit”事件期间的拟合操作结束时，cb.run 属性会重置为 True。</p><p id="446a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">回调排序逻辑:</strong></p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/b5a5f085602e5d119df8155fee182bda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KozLSOwXJrE9PkLHwrLL-g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">回调的排序顺序</figcaption></figure><ol class=""><li id="a4d5" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">获取回调列表，我们称之为“cbs”。创建一个空列表，比如“res ”,作为存储排序回调的占位符。</li><li id="e511" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">将所有“朝向 _ 结束”属性为 True 的回调移到 cbs 的结尾。</li><li id="179c" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">对于 cbs 中的每个回调“cb ”,从第一个回调开始，检查 cb 是否有“run_after”属性，如果有，检查 cb.run_after 是否等于 cbs 中的任何其他回调。</li><li id="f726" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">对于 cbs 中的所有其他回调“o ”,检查 o 是否有“run_before”属性，如果有，检查 o.run_before 是否等于 cb。</li><li id="6d06" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">如果 3 和 4 的答案都是假，将 cb 添加到排序列表“res”中。重复 3 到 5 次，直到所有回调都移到 res。</li></ol><p id="fda5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以使用 learn.show_training_loop()方法来查看 fit 操作期间的事件和回调。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/d9af14fd6f33016acafc75a0c7e460ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BUvSHUhd8N8QZDG4E5dg-g.png"/></div></div></figure><p id="756f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们尝试实现我们自己的 LRFinder 回调。像往常一样，我从 FastAI 的 github 回购中复制了下面的大部分代码。</p><h1 id="59fb" class="ky kz hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak"> LR_Finder 回调</strong></h1><p id="1293" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">我们希望 lr finder 回调执行以下操作:</p><ul class=""><li id="6575" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js ks jz ka kb bi translated">lr finder 不应该干扰权重初始化，因此 lr finder 回调应该在开始前首先将模型参数保存到本地文件中，并在结束时重新加载。</li><li id="3660" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">lr finder 应使用指数增长的学习速率运行 fit，最大迭代次数(批次)为 100 次，因此它应找到运行 fit 所需的适当的纪元数。</li><li id="b62b" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">建立一个指数级增长的学习进度计划。</li><li id="7649" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">如果迭代次数&gt; 100 或者如果损失增加到所获得的最佳损失的 4 倍以上，则取消训练。</li><li id="db8d" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">在拟合操作结束时将梯度归零。</li><li id="a38b" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated">在 fit 操作后，绘制损失与学习率的关系图。</li></ul><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/390571916b9bda7a3525511be511488e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DLcCenDO9_5EHkZ5oASrlg.png"/></div></div></figure><p id="ca32" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们将向学习者添加一个自定义方法来运行我们的回调。@patch 是一个 FastAI decorator，用于向第一个参数的 type-annotation 类添加方法。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/41efd6e183f64d1f84f89bce4ecead12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8hirmyHBgwfOGujjPAzpsw.png"/></div></div></figure><p id="bd8f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们使用 lr_find 方法。但是首先我们将重新初始化模型权重。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/2ca0230c87d68eebb7c1d61837cc8f3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8F_Fq5woLNCRLQ6cG9Uk3Q.png"/></div></div></figure><p id="6b80" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在将尝试在迁移学习环境中使用我们的学习率查找器。我们将使用 Pets 数据集并下载 FastAI 在 Imagenet 数据上预先训练的 xresnet 模型。我决定不使用我们在 Imagenette 数据上训练的模型，因为我们的目标类中只有一个单一的狗品种(对于 Imagenette 数据)。</p><p id="429f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，让我们为 Pets 数据集构建数据加载器。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/c8ab835a4aa5c2191c97c3185d9e3c45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LecMj7B9ulUtLKvY_g3ibw.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/27e02c09cdae2e9797a0a3bd7a73e463.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZVQ88wD1SeMDAHySGgz_8w.png"/></div></div></figure><p id="ec21" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们在宠物数据集中有 37 种狗和猫。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ki"><img src="../Images/df1d6afffcff52f787f0a998db1a6e52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J7_BCpjn9ysZ-Q6mQZcbUA.png"/></div></div></figure><p id="3f59" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们从 FastAI 下载预训练的 xresnet34 模型。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/9a0183619066829d92fccbaf949992af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bitIVYYFAPfc7VFmOjkfPw.png"/></div></div></figure><p id="5b73" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">默认情况下，FastAI 在池层切割一个预训练模型，并根据目标类的数量添加一个自定义头。详情请参见<a class="ae iu" href="https://docs.fast.ai/vision.learner" rel="noopener ugc nofollow" target="_blank">视觉学习者文档，此处为</a>。让我们为我们的研究复制同样的。首先，我们将为我们的模型创建一个“头”。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/cbc646bcfc5488423cdbae4aeda4c715.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uBZ7ewiUH92W-NMWAcyQlA.png"/></div></div></figure><p id="1a2c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在将头部与模型的预训练部分结合之前，我们将初始化头部的参数，因为我们不想修改预训练参数。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/f3403055d3a30614a9f53b1f3340100c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UiMKcFnyTL0ilqNXGhSIog.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/50a2a14c1d5d6a5f8b80b6dbf35bd92b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jwxdRHgEY8yxtdm71x6HjA.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/92290bc9f6f89fbe7f19727c87dac98d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AdI67INpV1Ayhy7Lvu3FoQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">注意:这里我只显示了输出的顶部和底部..</figcaption></figure><p id="8e64" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用不同的学习率&amp;以相对于身体 100 倍的 lr 训练我们模型的头部。因此，我们将使用一个定制的 splitter 函数为优化器创建两个参数组，一个包含头部的参数，另一个包含其余部分的参数。请注意，我们的模型头只有 6 个参数。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/fdd63db8c6d56da7e97d95cdb14e0c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cgeGWbSDbDkPguR2GQK_Mg.png"/></div></div></figure><p id="0231" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们将冻结模型的预训练部分&amp;只训练头部的参数。我们仍将在冻结部分训练 batchnorm 层的参数。研究表明，在迁移学习环境中训练 batchnorm 层通常会产生更好的结果。这种行为由学习器构造函数的“train_bn”(默认值:True)参数控制。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/4cccccbe74fc0e6750a461cae9616f04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t2OQKh_RURU5Jd_g8zitkA.png"/></div></div></figure><p id="4be0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们检查参数组中的可训练参数。我们可以看到第一个参数组中的所有参数都属于 batchnorm 层(将参数名与上面 pet3_resnet34 架构的显示进行对比)。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/811203811b395e805b954d2fdef49f13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q2TqJ1OHIMrWMRoe64EHHw.png"/></div></div></figure><p id="8bf5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们在头部的学习速率应该是模型(身体)其余部分的学习速率的 100 倍的约束下，为我们的模型找到合适的学习。这可以通过向 learn.lr_find()方法的 start_lr &amp; end_lr 参数传递一个 numpy 数组来实现。然而，FastAI 只跟踪记录器回调中最后一个参数组的学习率。我将稍微修改下面记录器回调的几个方法，以便它跟踪两个参数组的学习率，并绘制它们。我将使用@patch decorator 进行适当的修改。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/327f62f12d736a04c7b2115b7441da41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JQ0QfxRX3trmbF-UkFGWbA.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/aa33b382baf8d56e98f8d5534adcfcd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VgARtOBumJuW8t2C8eWWSQ.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/d6ccc1a5c1b62cc2a3c3a8a3b762bce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h7jt0DenOmvT_zNoHMmeAw.png"/></div></div></figure><p id="654d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们用自己的 lr_find 来找一个合适的学习率:</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/f185ec4a99a3fef87809448288fc3862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x3X7N6rqI6Pd5sEHavqvjA.png"/></div></div></figure><p id="18e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将训练 3 个时期的模型。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/0857ee28c56a59c7df60f3e7b31d74e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5gq6A5kx2AUUpteeFaJoLw.png"/></div></div></figure><p id="4c0c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，解冻整个模型并再次训练。我们将再次使用 my_lr_find()找到一个合适的学习率。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/06a1af25534f03d1bbf5215e3ba05e4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CkZUGwqYj7cZBwxsgApQ3Q.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/f32879594281288e91f8a8a63dbd8f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lcch3KIvbieuy6vQTLxAWg.png"/></div></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ki"><img src="../Images/43874e3c4fe98f62420aba06249ebca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wLEor6sCPoY3IdGJKEgzGg.png"/></div></div></figure><p id="d1da" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇文章的代码文件可以在 这里找到<a class="ae iu" href="https://github.com/Rakeshsuku/Medium-Blog/tree/master/Understanding%20FastAI%20v2%20Training" rel="noopener ugc nofollow" target="_blank"> <em class="kh">。</em></a></p><p id="8ca7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">链接到本系列的其他文章:</strong></p><ul class=""><li id="822d" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js ks jz ka kb bi translated"><a class="ae iu" rel="noopener" href="/@rakesh.melezhath/understanding-fastai-v2-training-with-a-computer-vision-example-part-1-the-resnet-model-dd9270450bb8"> <em class="kh">研究 resnet34 模型架构，使用普通 Python &amp; PyTorch 构建。</em>T9】</a></li><li id="b2c9" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js ks jz ka kb bi translated"><a class="ae iu" rel="noopener" href="/@rakesh.melezhath/understanding-fastai-v2-training-with-a-computer-vision-example-part-2-fastai-optimizers-df65cb018604">深入 FastAI 优化器&amp;实现一个 NAdam 优化器。</a></li></ul><p id="1c18" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">参考文献:</strong></p><ol class=""><li id="3b4f" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated"><a class="ae iu" href="https://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="kh">程序员实用深度学习</em> </a></li><li id="b3f1" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae iu" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank"> <em class="kh"> FastAI GitHub 回购</em> </a></li><li id="c8ee" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae iu" href="https://github.com/fastai/fastbook" rel="noopener ugc nofollow" target="_blank"> <em class="kh">法泰书</em> </a></li><li id="80da" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><a class="ae iu" href="https://docs.fast.ai/index.html" rel="noopener ugc nofollow" target="_blank"> FastAI 文档</a></li></ol></div></div>    
</body>
</html>