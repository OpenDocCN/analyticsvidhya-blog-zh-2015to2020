<html>
<head>
<title>Image Classification using CNN and Transfer Learning approaches</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于CNN和迁移学习方法的图像分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-classification-using-cnn-and-transfer-learning-approaches-8be8ffe4ff39?source=collection_archive---------4-----------------------#2020-01-08">https://medium.com/analytics-vidhya/image-classification-using-cnn-and-transfer-learning-approaches-8be8ffe4ff39?source=collection_archive---------4-----------------------#2020-01-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="22e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">本博客阐述了使用卷积神经网络和迁移学习方法的深度学习</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/0e314bc7bbcca6d1f0f4b5432f807c48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*a2HC-HMvE61rTGwy.jpg"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jq"><img src="../Images/6b5c6db313820b0237fef88cc7707bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*4otme7q80k9Y35YM"/></div></figure><p id="7b86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">世界各地的超市</strong>需要<strong class="ih hj">将不同的水果</strong>集中起来，放到正确的货架上，贴上正确的价格<strong class="ih hj">。这并不容易，尤其是现在每种水果都有很多种，彼此之间差别很小，甚至人眼都分不清。</strong></p><p id="3d17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了解决这个问题，机器学习和深度学习技术可能非常有用，因为这些技术的发展，特别是在神经网络领域，在过去十年中已经取得了巨大的进步。</p><p id="ede9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我将探索深度学习方法。数据集和问题取自Kaggle。以下是相同内容的链接:</p><p id="3bc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jr" href="https://www.kaggle.com/moltean/fruits/tasks" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/moltean/fruits/tasks</a></p><p id="0eec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">探索的方法</strong> :-</p><p id="becd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1)构建<strong class="ih hj">卷积层</strong>以及最大池</p><p id="75ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2)从VGG16开始使用T <strong class="ih hj">转移学习</strong>方法，然后添加一些额外的卷积层以及最大池层。</p><p id="efe2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用google Colab，因为它提供了一个免费的GPU，并允许我们使用驱动器库。</p><p id="fc1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该数据集包含120种水果的大约83000张图片。</p><p id="6e85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将使用kaggle API将庞大的数据集下载到drive中，并使用Colab获取它们。</p><p id="2240" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们开始吧:</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="a8ad" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#unzipping training folder</em><br/><br/>!unzip -uq "/content/gdrive/My Drive/kaggle/Training.zip" -d "/content/gdrive/My Drive/kaggle"</span><span id="e481" class="jx jy hi jt b fi kd ka l kb kc"><em class="jd">#unzipping test folder</em>  !unzip -uq "/content/gdrive/My Drive/kaggle/Test.zip" -d "/content/gdrive/My Drive/kaggle"</span><span id="379f" class="jx jy hi jt b fi kd ka l kb kc"><em class="jd">#import necessary libraries</em><br/><br/><strong class="jt hj">import</strong> <strong class="jt hj">numpy</strong> <strong class="jt hj">as</strong> <strong class="jt hj">np</strong><br/><strong class="jt hj">import</strong> <strong class="jt hj">matplotlib.pyplot</strong> <strong class="jt hj">as</strong> <strong class="jt hj">plt</strong><br/><strong class="jt hj">from</strong> <strong class="jt hj">sklearn.datasets</strong> <strong class="jt hj">import</strong> load_files<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.utils</strong> <strong class="jt hj">import</strong> np_utils<br/><strong class="jt hj">from</strong> <strong class="jt hj">sklearn.model_selection</strong> <strong class="jt hj">import</strong> train_test_split<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.preprocessing.image</strong> <strong class="jt hj">import</strong> array_to_img, img_to_array, load_img<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.models</strong> <strong class="jt hj">import</strong> Sequential<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.layers</strong> <strong class="jt hj">import</strong> Conv2D,MaxPooling2D<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.layers</strong> <strong class="jt hj">import</strong> Activation, Dense, Flatten, Dropout<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.preprocessing.image</strong> <strong class="jt hj">import</strong> ImageDataGenerator<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.callbacks</strong> <strong class="jt hj">import</strong> ModelCheckpoint<br/><strong class="jt hj">from</strong> <strong class="jt hj">keras</strong> <strong class="jt hj">import</strong> backend <strong class="jt hj">as</strong> K</span></pre><p id="53db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我已经导入了所有必要的库，我将导入不同文件夹中的训练和测试数据。训练和测试文件夹包含120个文件夹，每个文件夹中有不同的水果图像。</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="bc65" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd"># Loading data and putting them into training and test sets</em><br/><br/><em class="jd">#locations setting for training and test datasets</em><br/>train_data='/content/gdrive/My Drive/kaggle/Training'<br/>test_data='/content/gdrive/My Drive/kaggle/Test'<br/><br/><em class="jd">#creates X_train and Y_train using file_names and folders</em><br/><strong class="jt hj">def</strong> get_data(path):<br/>    data = load_files(path)<br/>    files = np.array(data['filenames'])<br/>    targets = np.array(data['target'])<br/>    target_labels = np.array(data['target_names'])<br/>    <strong class="jt hj">return</strong> files,targets,target_labels<br/><br/>X_train, Y_train, labels = get_data(train_data)<br/>X_test, Y_test,_ = get_data(test_data)<br/>Y_train = np_utils.to_categorical(Y_train, 120)<br/>Y_test = np_utils.to_categorical(Y_test, 120)</span></pre><p id="bded" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们将数据集分成训练集和验证集。</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="0842" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd"># splitting train set into training and validation sets</em><br/><br/>X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=33)<br/>Y_train, Y_val = train_test_split(Y_train, test_size=0.2, random_state=33)</span></pre><p id="a8ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经为训练和测试创建了单独的x和y，让我们将图像加载到数组格式中(使用像素值)。</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="20da" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#converting images into array to start computation</em><br/><br/><strong class="jt hj">def</strong> convert_image_to_array(files):<br/>    images_as_array=[]<br/>    <strong class="jt hj">for</strong> file <strong class="jt hj">in</strong> files:<br/>        images_as_array.append(img_to_array(load_img(file)))<br/>    <strong class="jt hj">return</strong> images_as_array<br/><br/>X_train = np.array(convert_image_to_array(X_train))<br/>X_val = np.array(convert_image_to_array(X_val))<br/>X_test = np.array(convert_image_to_array(X_test))</span></pre><p id="3c73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于255是最大可能的像素值，我们将使用除以255来归一化我们的输入y。标准化输入有助于神经网络运行得更快，否则它会像碗中的球一样绕来绕去，直到达到最小目标点。</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="d909" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#nomalizing the pixel values before feeding into a neural network</em><br/><br/>X_train = X_train.astype('float32')/255<br/>X_val = X_val.astype('float32')/255<br/>X_test = X_test.astype('float32')/255</span></pre><p id="cf02" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">方法1 </strong> — <strong class="ih hj">定制CNN </strong></p><p id="5e0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们从使用定制卷积神经网络的第一种方法开始。CNN是帮助神经网络学习<strong class="ih hj">空间和相关特征</strong>的神奇技术。在CNN出现之前，空间信息很难被学习到神经网络中，因为所有的数据都是以扁平的格式输入的。CNN帮助神经网络学习图像的各个区域(如边缘、眼睛等)之间的关系。神经网络越深入，学习的复杂特征就越多。</p><p id="ab0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，作为方法1，我们将使用2 X 2过滤器，并随着深度增加层数，使用2 X 2 max-pooling层，该层在特定区域选择最大值。</p><p id="f938" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用RELU激活函数来消除线性以学习复杂的特征。</p><p id="4d20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用<strong class="ih hj"> dropout </strong>正则化，它使用我们将定义的概率来选择节点，这将有助于防止模型过拟合。</p><p id="594e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，一个<strong class="ih hj"> softmax </strong>单元将用于分类和寻找损失函数。</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="6756" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#Building model 1 using customized convolutional and pooling layers</em><br/><br/>model = Sequential()<br/><br/><em class="jd">#input_shape is 100*100 since thats the dimension of each of the fruit images</em><br/>model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=2))<br/><br/>model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))<br/>model.add(MaxPooling2D(pool_size=2))<br/><br/>model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))<br/>model.add(MaxPooling2D(pool_size=2))<br/><br/>model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))<br/>model.add(MaxPooling2D(pool_size=2))</span><span id="73c2" class="jx jy hi jt b fi kd ka l kb kc"><em class="jd"># specifying parameters for fully connected layer</em><br/>model.add(Dropout(0.3))<br/>model.add(Flatten())<br/>model.add(Dense(150))<br/>model.add(Activation('relu'))<br/>model.add(Dropout(0.4))<br/>model.add(Dense(120,activation = 'softmax'))<br/>model.summary()</span></pre><p id="d3ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我们模型的结构:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ke"><img src="../Images/cd1d80cb25a357ccd898d107e72f1155.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*WFFrQYyznkGL-x5zjWnWiA.png"/></div></figure><p id="6c83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了加快我们的训练，我们将使用<strong class="ih hj">亚当优化器</strong>代替随机梯度下降。Adam利用momentum和rmsprop，带领我们快速达到优化值。</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="3219" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#importing ootimizers</em><br/><br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.optimizers</strong> <strong class="jt hj">import</strong> SGD, Adam, RMSprop<br/><br/>optimizer = Adam()<br/>model.compile(loss='categorical_crossentropy',<br/>              optimizer=optimizer,<br/>              metrics=['accuracy'])</span></pre><p id="fd2d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">是时候适应我们的模型了。我们将使用128个的<strong class="ih hj">批量，并检查<strong class="ih hj">的20个时期</strong>。</strong></p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="f30b" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd"># creating a file to save the trained CNN model </em><br/>checkpointer = ModelCheckpoint(filepath = 'cnn_from_scratch_fruits.hdf5', verbose = 1, save_best_only = <strong class="jt hj">True</strong>)<br/><br/><em class="jd"># fitting model using above defined layers </em><br/>CNN_model = model.fit(X_train,Y_train,<br/>        batch_size = 128,<br/>        epochs=20,<br/>        validation_data=(X_val, Y_val),<br/>        callbacks = [checkpointer],<br/>        verbose=2, shuffle=<strong class="jt hj">True</strong>)</span></pre><p id="d856" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为说明起见，显示了最后4个时期:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kf"><img src="../Images/46ba298762efdb267d7cfa83838844b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*uMgURQV2pGsQfxQe8Oz7BQ.png"/></div></figure><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="e54f" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#checking testset accuracy</em><br/><br/>score = model.evaluate(X_test, Y_test)<br/>print('Test accuracy:', score[1])</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kg"><img src="../Images/c9c2199d22320b1a0f207a29a0424908.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*NdbmrsoR0BMLS3N9yQb5JA.png"/></div></figure><p id="cf8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗯，它给出了一个惊人的结果，精度为0.995 ，这对人眼来说也很难。想象一下深度学习和神经网络的力量。有卷积层的神经网络确实很神奇。</p><p id="49df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了获得更多的兴奋，让我们想象一下它预测的水果的名字以及实际的名字和图像。</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="92fc" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd"># using model to predict on test data</em><br/>Y_pred = model.predict(X_test)<br/><br/><em class="jd"># Lets plot the predictions of different fruits and check their original labels</em><br/><br/>fig = plt.figure(figsize=(20, 15))<br/><strong class="jt hj">for</strong> i, idx <strong class="jt hj">in</strong> enumerate(np.random.choice(X_test.shape[0], size=25, replace=<strong class="jt hj">False</strong>)):<br/>    ax = fig.add_subplot(5, 5, i + 1, xticks=[], yticks=[])<br/>    ax.imshow(np.squeeze(X_test[idx]))<br/>    pred_idx = np.argmax(Y_pred[idx])<br/>    true_idx = np.argmax(Y_test[idx])<br/>    ax.set_title("<strong class="jt hj">{}</strong> (<strong class="jt hj">{}</strong>)".format(labels[pred_idx], labels[true_idx]),<br/>                 color=("green" <strong class="jt hj">if</strong> pred_idx == true_idx <strong class="jt hj">else</strong> "red"))</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kh"><img src="../Images/54514c84b280c6b014dc0a3f9b80df7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*1UXeHdZqCjrTpvBe-cJsGQ.png"/></div></figure><p id="a5f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们看看当模型训练20个时期时，损失函数和准确度如何变化</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="1931" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#plotting the loss function and accuracy for different epochs</em><br/><br/>plt.figure(1, figsize = (10, 10))  <br/>plt.subplot(211)  <br/>plt.plot(CNN_model.history['acc'])  <br/>plt.plot(CNN_model.history['val_acc'])  <br/>plt.title('Model Accuracy')  <br/>plt.ylabel('Accuracy')  <br/>plt.xlabel('Epoch')  <br/>plt.legend(['train', 'validation'], loc='upper left')   <br/><br/><em class="jd"># plotting model loss </em><br/>plt.subplot(212)  <br/>plt.plot(CNN_model.history['loss'])  <br/>plt.plot(CNN_model.history['val_loss'])  <br/>plt.title('Model Loss')  <br/>plt.ylabel('Loss')  <br/>plt.xlabel('Epoch')  <br/>plt.legend(['train', 'validation'], loc='upper left')  <br/>plt.show()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ki"><img src="../Images/c7e6219fbed850470b40df69c8676098.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*BOvrVNElj00CmasraGHctw.png"/></div></figure><p id="81dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">方法2 </strong> : <strong class="ih hj">对基础层使用迁移学习，并添加更多卷积层和池层</strong></p><p id="4b10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种方法中，我们将使用迁移学习来准备基础层。<strong class="ih hj"> VGG16 </strong>是在<strong class="ih hj"> imagenet </strong>数据集上训练的神经网络架构，用于对1000幅不同的图像进行分类，我们将使用已经在VGG16上训练的权重用于我们的方法2。</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="115f" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#importing vgg16</em><br/><br/><em class="jd">#Part 2 using transfer learning</em><br/><br/><em class="jd">#importing vgg16 architecture which is trained on Imagenet</em><br/><br/><strong class="jt hj">from</strong> <strong class="jt hj">keras.applications.vgg16</strong> <strong class="jt hj">import</strong> VGG16<br/><br/>vgg_model = VGG16(input_shape=[100,100,3], weights='imagenet', include_top=<strong class="jt hj">False</strong>)</span><span id="a531" class="jx jy hi jt b fi kd ka l kb kc"><em class="jd">#We will not train the layers imported.</em><br/><br/><strong class="jt hj">for</strong> layer <strong class="jt hj">in</strong> vgg_model.layers:<br/>   layer.trainable = <strong class="jt hj">False<br/></strong>  <em class="jd"><br/>#summary of the imported vgg model</em>  vgg_model.summary()</span></pre><p id="d005" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是vgg16外观的总结:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kj"><img src="../Images/9b026e9438f41b9e28d6e4b49d6415f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*5KTQC01WMsdeTU9pUZis2g.png"/></div></figure><p id="38f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将向vgg模型添加一个具有1024个过滤器的卷积层，随后是最大池层和密集层，并在fruits数据集上拟合该模型，并遵循上述相同的过程。</p><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="3f8a" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#adding some layers to the vgg_model imported and again fitting the model to check the performance</em><br/><br/>transfer_learning_model = Sequential()<br/> <br/>transfer_learning_model.add(vgg_model)<br/><br/><br/>transfer_learning_model.add(Conv2D(1024, kernel_size=3, padding='same'))<br/><br/>transfer_learning_model.add(Activation('relu'))<br/><br/>transfer_learning_model.add(MaxPooling2D(pool_size=(2, 2)))<br/>transfer_learning_model.add(Dropout(0.3))<br/><br/>transfer_learning_model.add(Flatten())<br/>transfer_learning_model.add(Dense(150))<br/>transfer_learning_model.add(Activation('relu'))<br/>transfer_learning_model.add(Dropout(0.4))<br/>transfer_learning_model.add(Dense(120,activation = 'softmax'))<br/>transfer_learning_model.summary()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kk"><img src="../Images/3da2a174a59847b0f4b833292409d877.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*qRzy2x1x_9_LHEEdrffgrg.png"/></div></figure><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="3277" class="jx jy hi jt b fi jz ka l kb kc"><strong class="jt hj">from</strong> <strong class="jt hj">keras.optimizers</strong> <strong class="jt hj">import</strong> SGD, Adam, RMSprop<br/><br/>optimizer = Adam()<br/>transfer_learning_model.compile(loss='categorical_crossentropy',<br/>              optimizer=optimizer,<br/>              metrics=['accuracy'])</span><span id="71b4" class="jx jy hi jt b fi kd ka l kb kc"><em class="jd">#fitting the new model</em><br/><br/><br/>checkpointer = ModelCheckpoint(filepath = 'transfer_learning.hdf5', verbose = 1, save_best_only = <strong class="jt hj">True</strong>)<br/><br/><em class="jd"># running </em><br/>transfer_learning_cnn = transfer_learning_model.fit(X_train,Y_train,<br/>        batch_size = 128,<br/>        epochs=20,<br/>        validation_data=(X_val, Y_val),<br/>        callbacks = [checkpointer],<br/>        verbose=2, shuffle=<strong class="jt hj">True</strong>)</span></pre><p id="fccc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最近4个时期:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kl"><img src="../Images/f92d6bbebc868bae8f9a6cae720ec113.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*OPsTJUHMUJp_MeutnLUKBQ.png"/></div></figure><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="04f5" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#score of the new model built using transfer learning</em><br/><br/>score = transfer_learning_model.evaluate(X_test, Y_test)<br/>print('Test accuracy:', score[1])</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es km"><img src="../Images/bce860fb1c57cbbc04c2ca19b72603ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*6p4G3w7B30q0h7xjUoO0Ug.png"/></div></figure><p id="6365" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到精度下降了一点，但想象一下，我们甚至没有像在我们的第一种方法中那样建立一个复杂的层。我们只是使用了来自vgg16的权重，并添加了1层，即使这样，大约0.98的精度也不差。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kn"><img src="../Images/f3145a086a3936ae1c198585edec0657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*C8PB-K92n32egyRC6hAUxA.png"/></div></figure><pre class="jf jg jh ji fd js jt ju jv aw jw bi"><span id="6804" class="jx jy hi jt b fi jz ka l kb kc"><em class="jd">#plotting curves for the transfer learning model</em><br/><br/>plt.figure(1, figsize = (10, 10))  <br/>plt.subplot(211)  <br/>plt.plot(transfer_learning_cnn.history['acc'])  <br/>plt.plot(transfer_learning_cnn.history['val_acc'])  <br/>plt.title('Model Accuracy')  <br/>plt.ylabel('Accuracy')  <br/>plt.xlabel('Epoch')  <br/>plt.legend(['train', 'validation'], loc='upper left')   <br/><br/><em class="jd"># plotting model loss </em><br/>plt.subplot(212)  <br/>plt.plot(transfer_learning_cnn.history['loss'])  <br/>plt.plot(transfer_learning_cnn.history['val_loss'])  <br/>plt.title('Model Loss')  <br/>plt.ylabel('Loss')  <br/>plt.xlabel('Epoch')  <br/>plt.legend(['train', 'validation'], loc='upper left')  <br/>plt.show()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ko"><img src="../Images/5abdf276ed29301476a119133df01968.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*3FChfiIM2sQc4pJYRxh9PQ.png"/></div></figure><p id="202b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们拥有强大的计算能力，还能做些什么来提高方法1的准确性？</p><p id="2b1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1) <strong class="ih hj">数据增强</strong>:我们可以通过使用增强技术来增加我们的训练集，如旋转图像、裁剪图像等，这可以产生更大的训练集，因此可以产生更好的准确性。</p><p id="eff2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2) <strong class="ih hj">更复杂的层</strong>:我们可以尝试构建更复杂的层，例如再次训练所有的vgg层，这可能会导致更好的准确性</p><p id="baef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3) <strong class="ih hj">超参数调整</strong>:我们可以尝试使用不同的正则化技术，将参数网格用于动量参数、正则化参数、rmsprop参数、学习率等，这可能会导致更好的结果。</p><p id="fcf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4) <strong class="ih hj">增加周期数</strong>:我们可以运行更多的周期，尝试不同的批量。</p><p id="007b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望你在CNN和迁移学习上获得了一些直觉。如果你喜欢，请鼓掌。</p><p id="b809" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢你，一定要发表一些反馈。</p></div></div>    
</body>
</html>