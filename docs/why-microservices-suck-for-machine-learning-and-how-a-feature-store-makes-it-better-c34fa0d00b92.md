# 为什么微服务对机器学习来说很糟糕…以及功能商店如何让它变得更好！

> 原文：<https://medium.com/analytics-vidhya/why-microservices-suck-for-machine-learning-and-how-a-feature-store-makes-it-better-c34fa0d00b92?source=collection_archive---------10----------------------->

在本文中，我将描述为什么面向微服务的架构不适合机器学习。然后我将展示 AirBnB 和优步这样的公司如何使用 StreamSQL 这样的[功能商店来管理它。](https://streamsql.io/?ref=hackernoon.com)

特性存储允许您以声明方式定义 ML 特性定义，并在培训和服务中使用它们。它使团队能够跨团队和模型共享、重用和发现这些特性。它还管理功能版本和监控。他们的最终目标是让 ML 团队专注于构建模型，而不是数据管道。

微服务已经成为科技公司事实上的架构选择。微服务允许大公司的小团队构建小的、独立的组件。团队可以解决问题并满足需求，而不必改造成一个巨大的整体。它让团队移动得更快。但是，当过度使用时，将用户会话令牌转换为用户配置文件会触发二十个网络调用。

我最近在 Twitter 上看到了这个视频，它启发了我写那个帖子。该视频非常搞笑，完美地捕捉到了这个概念(相关文字来自下面的视频)

关于为什么微服务很烂的滑稽短剧

**产品经理:**为什么在个人资料页面显示生日这么难？

**工程师:**首先我们必须调用 Bingo 服务来获取用户 ID，然后我们调用 Papaya 来将它转换成用户会话令牌。我们用 LMNOP 验证这些，然后我们可以从 Racoon 下载用户信息。但是浣熊不能保证有[出生日期]，所以接下来，我们叫…

## 例如:Reddit 推荐系统

![](img/c32651ae00d5c55567cee48b8903466a.png)

在像用户行为这样复杂的数据源上建立机器学习模型时，微服务是异常痛苦的。在这些情况下，为了进行预测，您需要从大量的微服务中获取信息，这些微服务又从其他大量的服务中获取所需的所有上下文信息。例如，如果您要构建一个个性化的 Reddit 提要，您可能想知道用户所在的所有社区、这些社区中的热门帖子、他们点击和喜欢的任何帖子，以及更多详细信息。添加额外的输入可以为模型提供更多的信号。例如，某些用户在周末的行为可能与平日截然不同。为模型提供额外的输入——一周中的某一天——可以让它捕捉到这些趋势。

机器学习模型的每个逻辑输入称为一个特征。假设、构建和测试模型输入的过程称为特征工程。通常，特征工程是 ML 团队最耗时的任务之一。创造性地提出新功能只是过程的一部分；大部分时间花在寻找你需要的数据，学习它的特性和边缘情况，并建立数据管道来清理和转换成可用的形式。

在基于微服务的架构中，收集特定数据的唯一方式是通过 API 调用。一个模型可能有各种各样需要 API 调用的特性。例如，该模型可能需要查询用户所在社区的用户服务，然后需要查询每个社区中的热门帖子，然后查询每个社区获得的喜欢。由于系统几乎从未为这种用途而构建，这将引发下游网络调用的多米诺骨牌效应。与 web 前端不同，ML 模型不能灵活处理缺失的功能。它将不得不等待所有的请求完成，否则会有提供垃圾结果的风险。ML 模型本身计算量很大并且非常慢；把这个和微服务混在一起，就变得不可能提供实时推荐了。

## 获取训练数据很糟糕

机器学习模型通过模仿它们观察到的东西来工作。为此，模型需要一组观察结果和观察时间点的输入数据来进行训练。在基于微服务的架构中生成训练集很糟糕。在我们的 Reddit 示例中，我们想要一组用户 upvotes 以及他们执行 upvote 时的特性集。虽然这离理想还很远，但我们可以通过抓取用户和发布微服务，在技术上获得用户投票和所有发布数据。然而，在许多情况下，时间点正确性使得这个问题不可能解决。为了训练，我们需要知道帖子在子编辑中的排名；但是，subreddit 微服务不太可能支持追溯查询。

一种选择是通过破坏封装和从数据库转储中读取来完全避免微服务。我们现在可以绕过 API，将数据集直接插入 Apache Spark 或其他批处理系统。我们可以连接表，以更方便的方式处理数据。它还可以像 Spark 处理数据一样快速地生成训练数据集。虽然一开始使用数据湖似乎是合理的，但它导致 ML 服务依赖于原始数据的模式。这种模式肯定会随着时间的推移而改变。微服务被淘汰和替换。数据不一致、错误和问题越积越多。最终，每一个 ML 团队都不得不维护数据管道，这些管道已经退化成古老的意大利面条式代码的混乱局面。管道易受变化的影响，需要大量的时间和资源。

![](img/c6bfb2bde0b7ee8e7c69f2962691c042.png)

另一种选择是利用 Apache Kafka、Apache Pulsar 或 Segment 等事件流平台，允许 ML 团队订阅他们需要的事件流。数据湖的许多缺陷也适用于事件流。然而，与数据湖转储不同，事件流往往具有更高质量的数据。由于事件流通常为任务关键型服务提供动力，因此团队在数据质量和文档方面需要达到更高的标准。相反，数据湖是 ML 和分析团队的专属，并没有很高的标准。

事件流处理受到冷启动问题的困扰。事件流平台很少配置为长时间保留事件，通常只有一周。如果你想生成一个新的特征，你可能只能用上周的数据来生成一个训练集。当创建一个新的有状态特征时，冷启动问题变得更加突出。有状态特性要求您在某个时间窗口内聚合事件。例如，用户在上周发布的帖子数量。在这种情况下，甚至可能需要数周时间来开始生成训练数据集。

特征工程是一个迭代的过程。你产生一个假设，建立一个实验，然后运行一个测试。您要么将其合并到主模型中，要么将其废弃。迭代发生得越快，模型变得越好。如果执行一个测试需要几周时间，那么 ML 团队就失去了执行工作的能力。团队最终浪费了管道数据管道和玩弄政治来获取数据，而不是建立更好的模型。

![](img/8d218c4582234891baed5dfaece1b92e.png)

## 团队如何解决微服务问题

微服务问题不是新的或独特的。有趣的是，许多公司独立地采用了相同的解决方案。AirBnB 建立了 Zipline，优步建立了米开朗基罗，Lyft 建立了 Dryft。这些系统统称为特征库。

# 什么是功能商店？

一个[特征库](https://streamsql.io)为数据科学家定义特征提供了一种标准化的方式。要素存储负责生成训练数据并提供在线服务要素。它将数据工程从 ML 工作流中抽象出来。在引擎盖下，它协调多个大数据系统，无缝处理即将到来的事件和过去的事件。如果你对具体的技术感兴趣，[这里是我们的特色商店基础设施的布局。](https://streamsql.io/blog/from-apache-kafka-to-apache-pulsar)

在最初的“Reddit”微服务架构中，每个服务都拥有自己的数据。帖子微服务是帖子数据的真实来源，用户微服务是用户数据的真实来源，等等。特征存储试图在自己的内部数据结构中创建自己的数据视图。它通过将域事件流处理成物化状态来实现这一点。域事件是逻辑事件，比如当一个用户投票支持一篇文章或者当一个新帖子被创建时。物化视图是对事件流运行查询的结果集。因此，如果我们希望模型知道用户投票的帖子数量，那么我们可以用以下逻辑创建一个物化视图:

```
SELECT user, COUNT(DISTINCT item) FROM upvote_stream GROUP BY user;
```

所有物化视图都存在于同一个特征存储中，并为 ML 使用进行了预处理。我们已经将所有我们关心的微服务数据合并到一个整体数据存储中。这消除了与从微服务获取实时特征相关的问题。现在可以在一次往返中获取要素。由于物化视图存储在高度可用且最终一致的数据存储中，因此特性存储具有额外的容错优势。我们在创建特性时拥有自己的业务逻辑，因为我们自己处理原始事件，所以我们与每个微服务中的业务逻辑是松散耦合的。

# 生成训练数据的事件源

我们的特征与即将到来的事件保持一致。它本质上是微服务表的一个镜像，但是已经为在 ML 中使用进行了预处理，并且都在一个地方。与微服务不同，功能存储将每个传入事件无限期地保存在日志中。如果我们将日志中的每一个事件都重放到一个空白的功能存储中，我们最终会得到完全相同的物化状态。事件日志成为系统的事实来源。这种设计模式被称为事件源。

事件源使我们能够为我们的模型生成训练数据集。为了说明这是如何做到的，让我们以 Reddit 为例，我们希望预测用户将投票支持的下一篇帖子。相关的领域事件被传输到要素存储中，然后更新模型输入要素。观察到的结果也应该流式传输到功能存储，在这种情况下，每个用户都投赞成票。

```
feature_store.append_observation(userId, postId, now())
```

由于功能存储维护每个事件的日志以及将事件流转换为状态的逻辑，因此它可以获得功能在任何时间点的状态。为了生成训练集，它遍历观察值并在该点生成特征集。将两者结合起来，最终得到一个训练数据集。

```
def generate_training_set():
    for observed in observations:
        feature_store.process_events_until(observed.time)
        features = feature_store.get_features(observed.userId)
        yield (features, observed.postId)
```

## 设计考虑

特性存储允许我们从微服务架构中分离出来，拥有我们自己的特性。然而，构建和维护一个功能库并不是免费的。团队在部署功能库之前应该考虑以下几点。

# 系统范围的事件流

功能存储要求域事件通过 Kafka 或 Pulsar 等事件流平台传递。这允许功能存储独立于微服务来具体化其状态。持久化事件日志允许它在任何时间点具体化特征。

将一个大型的基于微服务的系统转移到使用事件流是一个巨大的转变。必须注入例程来捕捉重要事件。这可能需要用新的依赖性和新的错误条件来更新旧的关键任务微服务。另一种选择是使用每个数据库的变更数据捕获语义将更新转换成流。但是，微服务数据库中的模式变化会对功能存储造成影响。

# 处理事件架构更改

功能存储仍然依赖于事件流的模式。如果一个流更改了它的模式，或者一个微服务行为不当并上传了垃圾数据，它会使下游的功能存储失效。应该像对待数据库模式一样对待事件流模式。迁移程序应该清晰并经过测试。事件应该用 Protobuf 或 JSON 这样的可扩展格式编写。

# 存储和计算能力

处理和存储大量数据不是免费的。在许多情况下，特征存储将重复由单个微服务执行的计算。功能商店以基础设施成本和复杂性换取开发速度和易用性。建立和维护一个功能商店需要资金和专业工程师。

# 记录和共享输入要素和数据源

ML 特性通常适用于许多不同的用例。Reddit 可能有许多不同的 ML 支持的特性，它们都使用用户的活动来做出决策。发现和理解他人构建的特性可以加快 ML 开发时间，并在特性工程中提供灵感。由于特性存储是一个相对较新的架构，团队必须记录特性应该如何发布和共享。

## 查看 StreamSQL.io

StreamSQL 的特性库让 ML 团队专注于构建模型，而不是数据管道。ML 团队可以创建一个单一的特征定义用于培训和服务。StreamSQL 是跨团队和模型设计、共享和发现特性的基础。来看看[这里](https://streamsql.io)！

*最初发布于*[*https://stream SQL . io*](https://streamsql.io/blog/microservices-with-machine-learning-feature-store)*。*