<html>
<head>
<title>Pyspark User Defined Functions(UDF) Deep Dive</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pyspark用户定义函数(UDF)深入分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/pyspark-udf-deep-dive-8ae984bfac00?source=collection_archive---------6-----------------------#2019-12-28">https://medium.com/analytics-vidhya/pyspark-udf-deep-dive-8ae984bfac00?source=collection_archive---------6-----------------------#2019-12-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/fdc8fff2e3482064cbd772f18ed293b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2sjs64rq3nR-646o"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Jez Timms 在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="db62" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是我在星火深潜系列中的一个故事</p><div class="jt ju ez fb jv jw"><a rel="noopener follow" target="_blank" href="/@somanathsankaran"><div class="jx ab dw"><div class="jy ab jz cl cj ka"><h2 class="bd hj fi z dy kb ea eb kc ed ef hh bi translated">索玛纳特·桑卡兰培养基</h2><div class="kd l"><h3 class="bd b fi z dy kb ea eb kc ed ef dx translated">阅读索马纳特·桑卡兰在媒介上的作品。对python和spark感兴趣的大数据开发者。每天，索马纳特…</h3></div><div class="ke l"><p class="bd b fp z dy kb ea eb kc ed ef dx translated">medium.com</p></div></div><div class="kf l"><div class="kg l kh ki kj kf kk io jw"/></div></div></a></div><p id="73a9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">用户定义的函数非常常见，我们需要使用它，因为我们知道python有丰富的函数，所以我们可以使用python模块来改进spark的功能。</p><p id="2787" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇文章中，我们将看到</p><ol class=""><li id="b326" class="kl km hi ix b iy iz jc jd jg kn jk ko jo kp js kq kr ks kt bi translated">用户自定义函数</li><li id="fd27" class="kl km hi ix b iy ku jc kv jg kw jk kx jo ky js kq kr ks kt bi translated">熊猫_udf及其优势</li><li id="f93a" class="kl km hi ix b iy ku jc kv jg kw jk kx jo ky js kq kr ks kt bi translated">标量熊猫自定义项</li><li id="175e" class="kl km hi ix b iy ku jc kv jg kw jk kx jo ky js kq kr ks kt bi translated">分组熊猫自定义项</li><li id="216e" class="kl km hi ix b iy ku jc kv jg kw jk kx jo ky js kq kr ks kt bi translated">分组聚合熊猫自定义项</li></ol><p id="0352" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> UDF </strong></p><p id="2b0c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是spark提供的旧udf，它涉及到从JVM对象到python对象的序列化(pickling)转换，这会导致大量开销。</p><p id="10e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="kz">该udf将获取特定列的每一行，并应用给定的函数，添加一个新列</em> </strong></p><p id="1cfa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">步骤1:创建示例数据框架</p><p id="8fa9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们创建一个包含示例单词的示例udf，我们必须检查给定的字符串是否是回文</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/417f16bff482e4b251858b6fdf7938c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NvON3xIpKcbauZ05cCNSww.png"/></div></div></figure><p id="74e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第二步:创建回文python函数</strong></p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/41461d9fd5415549b7a893b3c810ca0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*o7pOrjCbPUnLuVW5iRm_7g.png"/></div></figure><p id="577f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里我们有一个函数回文，它接受一行，如果单词的reverse(row[::-1]将字符串反转并转换为小写)等于单词本身，它将返回true，否则将返回false</p><p id="2dfc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第三步:注册自定义项作为函数调用</strong></p><p id="bc18" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一步是用spark sql函数注册这个python，以便可以在类似df.select(回文(col)的列上调用它</p><p id="de6b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为此，我们必须使用udf函数，并通过指定函数和返回类型来创建spark可访问的udf函数，如下所示。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/644af2d05f3248cac86ddefb8a362e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*pQ-_EJLogmx6EbI-4-wA4A.png"/></div></figure><p id="3b37" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在可以用spark df调用check_palindrome，如下所示</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/70328cd59cc7252733b1d77c1b234db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*0YMlUiWIkagcNpMLoGFE5A.png"/></div></figure><p id="4450" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们可以用dtypes检查返回类型</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es li"><img src="../Images/91b4b0ba8e020be81b697fe242933010.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*qxa_7DLu0WardI5TQ4pG9g.png"/></div></figure><p id="6080" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">熊猫_自定义项及其优势</strong></p><p id="869a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上述udf的主要缺点是它涉及到从jvm对象到python序列化pickle对象的转换，这会导致大量开销，</p><p id="c0e8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以在spark 2.0中，引入了pandas_udf，它具有以下优点</p><ol class=""><li id="1db7" class="kl km hi ix b iy iz jc jd jg kn jk ko jo kp js kq kr ks kt bi translated">它使用apache arrow，这是一种列格式，不需要任何转换</li><li id="696a" class="kl km hi ix b iy ku jc kv jg kw jk kx jo ky js kq kr ks kt bi translated">它是矢量化的，可以像numpy数组或hive中的矢量化一样进行批量操作</li></ol><p id="6f72" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤1:检查Pyarrow安装</strong></p><p id="2517" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要使用pandas udf pyarrow，需要安装它，它的版本需要高于0.8，我们必须启用arrow执行</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/2a20ab2d14177917f6a6a55f201abd1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*ABeSb2rF339I-tU2-WFMNg.png"/></div></figure><p id="c9ce" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">标量熊猫自定义项:</strong></p><p id="691f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它与上面的udf类似，但它将通过将spark df转换为pandas系列来运行</p><p id="5c68" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要使用pandas udf，我们必须更改该函数，以便它将对序列进行操作，如下所示，方法是向称为vector palindrome的回文函数添加一个包装函数，该函数将使用pandas series的apply方法对pandas series使用回文函数</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/95fe34b8adfc73018ba214229e5a8b11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*f_GhuRxo5-wa-dc3M95FVw.png"/></div></figure><p id="647e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后我们必须用pandas udf注册这个函数并调用这个函数</p><p id="d037" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用functionType，返回如下所示的类型</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/f64addf71a8cefd9f3f0c62738325cb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uud8VheastVpUMsyVrvjAQ.png"/></div></div></figure><p id="232d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">分组熊猫自定义项:</strong></p><p id="c501" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这类似于pandas中的group by apply构造，因此，例如，我们必须按特定列进行分组，并计算该组的几何平均值</p><p id="54ab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，我们将创建id为的2列df和他们的购买</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/dbb637fdb108b68f48c1972420b2ccfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5nU6n96FSotBjrpZOky3Lg.png"/></div></div></figure><p id="bc58" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用python stats模块来获取平均值，并将其作为一个新列分配</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/5758a93b76815b69e64df0cf0880773d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*qfqlk587j4I4aFGw3nsiTw.png"/></div></figure><p id="b3d9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们将udf注册为grouped_map类型，并使用函数返回的df的返回模式，如下所示</p><p id="06f1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为上面的函数返回3列id、purchase和geometric mean以及它们在returntype中的模式，如下所示</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/176a2916b76f41b510463a30f7b5ab70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EierMvjV51YkCAp_cXun4g.png"/></div></div></figure><p id="143e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">按id分组后应用函数</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/4e026b50b731554a0c0c17155ef5e6f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yO4xfpN0h6ywj-nNh1u4bQ.png"/></div></div></figure><p id="3ccf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">分组聚合熊猫自定义项</strong>:</p><p id="6bfe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它是分组和执行自定义聚合功能，比如说只为每个id添加零头购买。</p><p id="885e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以使用decorator语法包装python函数，而不是创建像矢量化几何图形这样的新函数。比如我们可以在函数上修饰@熊猫_UDF</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/aeff9635edbe41a6a66787fd258d9c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*Bo_V1YizqC-TdEXvhzW4TA.png"/></div></div></figure><p id="4106" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">今天就到这里吧！！:)</p><p id="6607" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Github链接:<a class="ae iu" href="https://github.com/SomanathSankaran/spark_medium/tree/master/spark_csv" rel="noopener ugc nofollow" target="_blank">https://github . com/SomanathSankaran/spark _ medium/tree/master/spark _ CSV</a></p><p id="9dcd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"/></p><p id="a860" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">学习并让别人学习！！</strong></p></div></div>    
</body>
</html>