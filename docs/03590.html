<html>
<head>
<title>Hierarchical Agglomerative Clustering: Algorithm and when to use it.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">算法和何时使用它。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hierarchical-agglomerative-clustering-algorithm-and-when-to-use-it-58a3cdd6ffd2?source=collection_archive---------14-----------------------#2020-02-09">https://medium.com/analytics-vidhya/hierarchical-agglomerative-clustering-algorithm-and-when-to-use-it-58a3cdd6ffd2?source=collection_archive---------14-----------------------#2020-02-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ae8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作为一名数据科学家或营销人员，您应该已经遇到过集群。对数据进行聚类的目的是分离具有相似特征的组，并将它们分配到不同的聚类中。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/e8673bb385579c56c3bc3e7bb02cd468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q1Pt4rnHEjwwwT8kpP2RCw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来源—维基百科</figcaption></figure><p id="ab59" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据科学家大多知道Kmeans聚类是一种无监督的机器学习形式，当我们知道数据中的底层类时，它确实非常有用。但是当我们不知道数据中存在的聚类数时，事情就变得有点复杂了。</p><p id="a521" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">K-means的工作方式是获取一组参数，告诉它我们认为数据中存在多少个聚类，然后使用期望最大化(EM)算法，通过不断计算和重新计算质心的位置，将每个点分配给每个新步长最接近的聚类质心，然后将质心移动到当前分配给该质心的所有点的中心，来迭代地将每个聚类质心移动到最佳可能位置。对于非分层算法，不能有子组，也就是说，不能有簇中的簇。</p><p id="808a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">凝聚聚类是一种自下而上的聚类技术，在聚类数目未知时非常有用。该算法从𝑛聚类(其中𝑛是数据点的数量)开始，并通过合并最相似的聚类来进行，直到某个停止标准。</p><h1 id="ef9a" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">算法</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kr"><img src="../Images/a62c4ec2a9799f1cd6381507b9a81d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ET8kCcPpr893vNZFs8j4xg.gif"/></div></div></figure><ol class=""><li id="5bee" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">从所有观察值和测量标准(通常是欧几里德距离)开始，计算成对的欧几里德距离</li><li id="9227" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">考虑具有最低欧几里德距离的对作为我们的第一个聚类。</li><li id="3b7f" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">现在再次计算成对的距离，但这次将前一对视为一个点。我们可以选择计算聚类的三个不同的距离(最近点、最远点或聚类的中间点，我们将在后面讨论它们)。</li><li id="62e1" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">前一步会给我们另一个集群，我们将重复步骤3，直到我们得到一个巨大的集群。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lg"><img src="../Images/434959cb828530262d58979fe38cef65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3V4kp3tIZhbzegzeSBe5hg.png"/></div></div></figure></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="f6a1" class="jt ju hi bd jv jw lo jy jz ka lp kc kd ke lq kg kh ki lr kk kl km ls ko kp kq bi translated">联系</h1><p id="31cd" class="pw-post-body-paragraph if ig hi ih b ii lt ik il im lu io ip iq lv is it iu lw iw ix iy lx ja jb jc hb bi translated">正如算法中提到的，我们有三种不同的方法来测量从一个点到集群的距离。它们被称为链接，Scikit-learn提供了三个链接标准:</p><ul class=""><li id="5fcf" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc ly ky kz la bi translated"><strong class="ih hj"> Ward </strong>(默认):选择两个聚类进行合并，合并的方式是所有聚类内的方差增加最小。一般来说，这导致集群的大小相当一致。</li><li id="b058" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc ly ky kz la bi translated"><strong class="ih hj">平均</strong>:合并所有点之间<strong class="ih hj"> <em class="lz">平均</em> </strong>距离最小的两个簇。</li><li id="bc0c" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc ly ky kz la bi translated"><strong class="ih hj">完全</strong>(或最大链接):合并两个点之间具有最小<strong class="ih hj"> <em class="lz">最大</em> </strong>距离的簇。</li></ul><p id="d3c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些关联标准肯定会对聚类算法的执行产生影响。但是没有一个是“最好的”——您应该使用哪一个通常取决于您的数据结构和/或您自己的目标。</p><p id="7e84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，当您不知道数据中聚类的数量时，以及当您在数据中寻找潜在的或感兴趣的聚类时，层次凝聚聚类非常有用。</p></div></div>    
</body>
</html>