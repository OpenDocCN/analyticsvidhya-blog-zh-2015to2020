<html>
<head>
<title>XGBoost : “Thousand forests is in one acorn”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">XGBoost:“一颗橡子里有千片森林”</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/xgboost-thousand-forests-is-in-one-acorn-e7deefa9a64?source=collection_archive---------16-----------------------#2020-04-09">https://medium.com/analytics-vidhya/xgboost-thousand-forests-is-in-one-acorn-e7deefa9a64?source=collection_archive---------16-----------------------#2020-04-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/ced4c1583954b141482ee50973451b63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*BK2SBAz_InoLJZEIHF-d6Q.jpeg"/></div></figure><p id="92b6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">我们先来了解一下什么是XGBoost？</strong></p><p id="744b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">XGBoost代表“极限梯度提升”。它是梯度推进算法的扩展。这种强大算法的美妙之处在于其可扩展性，它通过并行和分布式计算驱动快速学习，并提供高效的内存使用。XGBoost是一种集成学习方法。集成学习提供了一个系统的解决方案来结合多个学习者的预测能力。</p><p id="fcfb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">XGBoost用于监督学习问题，其中我们使用训练数据(具有多个特征)x来预测结果变量y。XGBoost是梯度增强决策树的实施，旨在加快和提高性能。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div class="er es jk"><img src="../Images/5d9792bb80c625473181230977fedcbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*Vyd34AtHETeokRYB0XfQjQ.png"/></div></figure><p id="6fcb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">该模型的实现支持scikit-learn和R实现的特性，并增加了正则化等新特性。梯度增强的三种主要形式是:</p><ul class=""><li id="fd29" class="jp jq hi io b ip iq it iu ix jr jb js jf jt jj ju jv jw jx bi translated"><strong class="io hj">梯度推进</strong>算法也叫梯度推进机包括学习率。</li><li id="3fb6" class="jp jq hi io b ip jy it jz ix ka jb kb jf kc jj ju jv jw jx bi translated"><strong class="io hj">随机梯度推进</strong>，在每个分离级别的行、列和列进行子采样。</li><li id="0b31" class="jp jq hi io b ip jy it jz ix ka jb kb jf kc jj ju jv jw jx bi translated"><strong class="io hj">L1和L2正则化的正则化梯度增强</strong>。</li></ul><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es kd"><img src="../Images/f11692169cdfe0dc180a6065a1e499bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l4PN8hyAO4fMLxUbIxcETA.png"/></div></div></figure><h1 id="2a1d" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">XGBoost的独特功能</h1><p id="54de" class="pw-post-body-paragraph im in hi io b ip lg ir is it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj hb bi translated"><strong class="io hj">并行学习的块结构:</strong>为了更快的计算，XGBoost可以利用CPU上的多个内核。与其他算法不同，这使得数据布局可以被后续迭代重用，而不是再次计算</p><p id="a65e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">核外计算:</strong>该特性优化了可用磁盘空间，并在处理大型数据集时最大限度地利用了磁盘空间。</p><p id="6ed7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">处理稀疏数据:</strong> XGBoost结合了一个稀疏感知的分裂查找算法，以处理数据中不同类型的稀疏模式。缺少值或数据处理步骤(如一键编码)会使数据变得稀疏。</p><p id="af11" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">正则化:</strong>正则化应用于过拟合模型。XGBoost可以选择通过L1和L2正则化来惩罚复杂的模型。</p><p id="98ea" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">加权分位数示意图:</strong>。XGBoost有一个分布式加权分位数草图算法来有效地处理加权数据</p><h1 id="b53c" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">XGBoost的重要参数:</h1><h1 id="ed47" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated"><strong class="ak"> 1)助推器参数:</strong>在每一步，它引导单个助推器。</h1><h2 id="7e68" class="ll kj hi bd kk lm ln lo ko lp lq lr ks ix ls lt kw jb lu lv la jf lw lx le ly bi translated"><strong class="ak"><em class="lz">a)</em>min _ child _ weight[默认值=1]: </strong></h2><blockquote class="ma"><p id="290e" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">定义子级<em class="lz">所需的所有观察的最小权重和。</em></p></blockquote><h2 id="1dc0" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak">T27)b)max _ leaf _ nodes:T29】</strong></h2><blockquote class="ma"><p id="b32d" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">树中的最大终端节点或叶子数。</p></blockquote><h2 id="8f21" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> <em class="lz"> c) </em>伽玛[默认值=0]: </strong></h2><blockquote class="ma"><p id="f8f4" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">Gamma指定进行分割所需的最小损失减少量。</p></blockquote><h2 id="0da9" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> <em class="lz"> d) </em> max_delta_step【默认值= 0】</strong></h2><blockquote class="ma"><p id="88bf" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">在最大增量步骤中，我们允许每棵树的重量估计为。如果该值设置为0，则表示没有约束。如果将其设置为正值，则有助于使更新步骤更加保守。</p></blockquote><h2 id="5210" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> <em class="lz"> e) </em>子样本【默认= 1】</strong></h2><blockquote class="ma"><p id="4a32" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">表示每棵树随机抽样的观察分数。</p></blockquote><h2 id="2afe" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak">f)eta[默认值=0.3] </strong></h2><blockquote class="ma"><p id="0f6f" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">通过缩小每一步的权重，使模型更加健壮</p><p id="171b" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">要使用的典型最终值:0.01–0.2</p></blockquote><h2 id="d782" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"><em class="lz">g)</em>max _ depth[默认值=6]: </strong></h2><blockquote class="ma"><p id="b186" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">树的最大深度，与GBM相同。</p><p id="05e7" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">典型值:3–10</p></blockquote><h2 id="f5b7" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> <em class="lz"> h) </em> max_depth【默认值= 6】</strong></h2><blockquote class="ma"><p id="f9e7" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">树的最大深度，与GBM相同。</p></blockquote><h2 id="2c7c" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"><em class="lz">I)</em>scale _ pos _ weight[默认值=1] </strong></h2><blockquote class="ma"><p id="902d" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">在高等级不平衡的情况下，应该使用大于0的值，因为它有助于更快收敛</p></blockquote><h1 id="46c0" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt mp kv kw kx mq kz la lb mr ld le lf bi translated"><strong class="ak"> 2)学习任务参数:</strong>它指导优化的性能。</h1><h2 id="73aa" class="ll kj hi bd kk lm ln lo ko lp lq lr ks ix ls lt kw jb lu lv la jf lw lx le ly bi translated"><strong class="ak"> a)eval_metric : </strong></h2><ul class=""><li id="4d0b" class="jp jq hi io b ip lg it lh ix ms jb mt jf mu jj ju jv jw jx bi translated">用于验证数据的指标。</li><li id="3e8b" class="jp jq hi io b ip jy it jz ix ka jb kb jf kc jj ju jv jw jx bi translated">对于回归，默认值为rmse，对于分类，默认值为error。</li><li id="a4bf" class="jp jq hi io b ip jy it jz ix ka jb kb jf kc jj ju jv jw jx bi translated">典型值包括:</li></ul><h2 id="8c34" class="ll kj hi bd kk lm ln lo ko lp lq lr ks ix ls lt kw jb lu lv la jf lw lx le ly bi translated"><strong class="ak"><em class="lz">RMSE</em></strong><em class="lz">—</em></h2><blockquote class="ma"><p id="7cc0" class="mb mc hi bd md me mf mg mh mi mj jj dx translated"><em class="lz">均方根误差</em></p></blockquote><h2 id="c56f" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"><em class="lz"/></strong><em class="lz">——</em></h2><blockquote class="ma"><p id="d82a" class="mb mc hi bd md me mf mg mh mi mj jj dx translated"><em class="lz">平均绝对误差</em></p></blockquote><h2 id="1f94" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"><em class="lz"/></strong><em class="lz">——</em></h2><blockquote class="ma"><p id="1890" class="mb mc hi bd md me mf mg mh mi mj jj dx translated"><em class="lz">负对数似然</em></p></blockquote><h2 id="9b37" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> <em class="lz">错误</em></strong><em class="lz">——</em></h2><blockquote class="ma"><p id="05d6" class="mb mc hi bd md me mf mg mh mi mj jj dx translated"><em class="lz">二元分类错误率(0.5阈值)</em></p></blockquote><h2 id="9a76" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> <em class="lz">误差</em> </strong> <em class="lz"> — </em></h2><blockquote class="ma"><p id="ea85" class="mb mc hi bd md me mf mg mh mi mj jj dx translated"><em class="lz">多类分类错误率</em></p></blockquote><h2 id="5ca2" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"><em class="lz">mlogloss</em></strong><em class="lz">——</em></h2><blockquote class="ma"><p id="5318" class="mb mc hi bd md me mf mg mh mi mj jj dx translated"><em class="lz">多类对数损失</em></p></blockquote><h2 id="b33a" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> b)目标[default=reg:linear] </strong></h2><h2 id="1543" class="ll kj hi bd kk lm ln lo ko lp lq lr ks ix ls lt kw jb lu lv la jf lw lx le ly bi translated">-这定义了要最小化的损失函数。最常用的值有:</h2><h2 id="4d30" class="ll kj hi bd kk lm ln lo ko lp lq lr ks ix ls lt kw jb lu lv la jf lw lx le ly bi translated"><strong class="ak"> <em class="lz">二进制:逻辑</em></strong><em class="lz">–</em></h2><blockquote class="ma"><p id="806b" class="mb mc hi bd md me mf mg mh mi mj jj dx translated"><em class="lz">用于二元分类的逻辑回归，返回预测概率(非类)</em></p></blockquote><h2 id="85d2" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> <em class="lz">多:soft max</em></strong><em class="lz">–</em></h2><blockquote class="ma"><p id="e28f" class="mb mc hi bd md me mf mg mh mi mj jj dx translated"><em class="lz">使用softmax目标的多类分类返回预测类(非概率)</em></p></blockquote><h2 id="9129" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> <em class="lz">多:soft prob</em></strong><em class="lz">–</em></h2><blockquote class="ma"><p id="1aa7" class="mb mc hi bd md me mf mg mh mi mj jj dx translated"><em class="lz">与softmax相同，但返回属于每个类的每个数据点的预测概率。</em></p></blockquote><h1 id="fb13" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt mp kv kw kx mq kz la lb mr ld le lf bi translated"><strong class="ak"> 3)一般参数:</strong>它指导整体功能。</h1><h2 id="748d" class="ll kj hi bd kk lm ln lo ko lp lq lr ks ix ls lt kw jb lu lv la jf lw lx le ly bi translated"><strong class="ak"> <em class="lz"> a) </em>升压器【默认= GB tree】:</strong></h2><h2 id="f19e" class="ll kj hi bd kk lm ln lo ko lp lq lr ks ix ls lt kw jb lu lv la jf lw lx le ly bi translated">gbtree:</h2><blockquote class="ma"><p id="319d" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">基于树的模型</p></blockquote><h2 id="3899" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated">gblinear:</h2><blockquote class="ma"><p id="7932" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">线性模型</p></blockquote><h2 id="3d87" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated">n线程:</h2><blockquote class="ma"><p id="d98f" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">这用于并行处理，应输入系统中的内核数量。</p></blockquote><h2 id="79c3" class="ll kj hi bd kk lm mk lo ko lp ml lr ks ix mm lt kw jb mn lv la jf mo lx le ly bi translated"><strong class="ak"> <em class="lz"> c)无声【默认= 0】:</em></strong></h2><blockquote class="ma"><p id="e7b0" class="mb mc hi bd md me mf mg mh mi mj jj dx translated">通常最好保持为0，这样消息可以帮助理解模型。静音模式激活设置为1，即不打印任何运行消息。</p></blockquote><figure class="mw mx my mz na ij er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mv"><img src="../Images/2c30cb84865aecad0db8c24815f96662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SFKpEd3Aro4D2Hd2x_0ZZQ.jpeg"/></div></div></figure><p id="5e6b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">实现Xgboost </strong></p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es nb"><img src="../Images/3b1777d5d266c5104b76958e2bd04256.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qh5YKQMz9YJhdKPNqgCOFA.png"/></div></div></figure><p id="49ee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我使用的是2015年航班延误的Kaggle <a class="ae nc" href="https://www.kaggle.com/usdot/flight-delays/data" rel="noopener ugc nofollow" target="_blank">数据集</a>既有分类特征，也有数字特征。XGBoost本身不能处理分类特征，它只接受类似随机森林的数值。因此，在向XGBoost提供分类数据之前，必须执行各种编码，如标签编码、均值编码或一键编码。</p><p id="2f0f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里的Performer是XGBoost，它通常工作得很好。然而，XGBoost唯一的问题是它太慢了。</p><p id="0f52" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">谢谢，继续学习:)</strong></p></div></div>    
</body>
</html>