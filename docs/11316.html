<html>
<head>
<title>Style Transfer of Images using CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 CNN 的图像风格转换</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/style-transfer-of-images-using-cnn-e79472ee350b?source=collection_archive---------24-----------------------#2020-11-28">https://medium.com/analytics-vidhya/style-transfer-of-images-using-cnn-e79472ee350b?source=collection_archive---------24-----------------------#2020-11-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/892ee1ec85f10f208de990e0fcedd765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H-ot29Nmz646ziz-"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">丹尼·米勒在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><blockquote class="iv iw ix"><p id="ac8f" class="iy iz ja jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">风格转移是转移学习的一个应用，在这里你将得到一个<strong class="jb hj"> <em class="hi">【内容图像】</em> </strong>和一个<strong class="jb hj"> <em class="hi">【风格图像】</em> </strong>，目的是将风格从风格图像转移到内容图像，对内容图像应用风格后生成的图像称为<strong class="jb hj"> <em class="hi">【候选图像】。</em>T15】</strong></p></blockquote><p id="ef35" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">使用相同的内容图像和相同的风格图像可以生成许多可能的候选图像，任务是生成合适的候选图像。</p><p id="26a9" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">候选图像应该类似于内容图像和样式图像的样式。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ka"><img src="../Images/f9c68b2446af57c3902d0df70227f6b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4gV0Uekttw2OkgVwpffb2Q.jpeg"/></div></div></figure></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><h2 id="719a" class="km kn hi bd ko kp kq kr ks kt ku kv kw jx kx ky kz jy la lb lc jz ld le lf lg bi translated">将内容和风格的概念转化为数学形式:</h2><h2 id="95a4" class="km kn hi bd ko kp kq kr ks kt ku kv kw jx kx ky kz jy la lb lc jz ld le lf lg bi translated">内容丢失:</h2><p id="be06" class="pw-post-body-paragraph iy iz hi jb b jc lh je jf jg li ji jj jx lj jm jn jy lk jq jr jz ll ju jv jw hb bi translated">在将内容图像馈送到能够很好地提取特征的预先训练的卷积神经网络(例如 VGGNet)之后，我们得到一个'<strong class="jb hj"> <em class="ja">内容特征向量'</em> </strong>，它是网络最后层中内容图像的表示。</p><p id="6ed4" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">同样，如果你输入一个候选图像，你会得到一个<strong class="jb hj"> <em class="ja">【候选特征向量】</em> </strong>，这是一个候选图像的表示。</p><p id="9405" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">损失函数的<strong class="jb hj"><em class="ja">‘内容’</em></strong>部分保证内容&amp;候选图像对应的特征向量相同。</p><p id="a6f2" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">训练任务是学习候选图像，即，在训练期间，学习候选图像的各个像素值。您可以随机初始化候选图像，然后使用反向传播更新像素。</p><p id="8895" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">设内容特征向量为 Fn，前馈机制后候选特征向量为 Fd。为了使 Fd 接近 Fn，即，为了使候选图像的内容与内容图像的内容相同，Fd 和 Fn 的 L2 范数必须尽可能小。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/84d10aad7a70bcac192c9fbb9a27421d.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*6UT1qFyAYKAbksNtdE21Hg.png"/></div></figure><h2 id="e3fd" class="km kn hi bd ko kp kq kr ks kt ku kv kw jx kx ky kz jy la lb lc jz ld le lf lg bi translated">风格损失:</h2><p id="70f9" class="pw-post-body-paragraph iy iz hi jb b jc lh je jf jg li ji jj jx lj jm jn jy lk jq jr jz ll ju jv jw hb bi translated">一般来说，风格可以被认为是“图像的不同特征如何相互作用”。</p><p id="15b7" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">换句话说，风格是图像不同特征之间的相关性。</p><p id="4124" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">在将一幅图像输入 CNN 后，我们得到了每一个卷积层后的特征图。让我们假设我们在卷积层之后得到 128×128×256 的特征图，这意味着卷积层从图像中提取了总共 256 个特征。</p><p id="ae4a" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">展平后，我们将得到一个大小为 16384 X 256 的特征向量，它可以表示为一个相同大小的矩阵。</p><p id="bb53" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">如前所述，风格是不同特征之间的相关性，我们需要计算在每个卷积层获得的特征向量之间的相关性。</p><p id="d808" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">为了计算相关性，我们将每层的展平特征向量与其转置矩阵相乘。将一个特征向量与其自身的转置相乘后得到的矩阵称为<strong class="jb hj"><em class="ja">‘格拉姆矩阵’。</em>T3】</strong></p><p id="0d26" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">gram 矩阵的每个元素表示图像中一个特征与其他特征之间的相关性。</p><p id="9f97" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">g =[(fl)x[transpose(fl)])^2]</p><p id="d246" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">其中 G 是 Gram 矩阵，而 Fl 是层级别“l”处的展平特征向量，并且[Fl]表示矩阵。</p><p id="24b8" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">由于我们得到不同层的特征向量，我们可以提取多个 gram 矩阵。</p><p id="8cdd" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">为了从风格图像中捕获风格，我们需要捕获候选图像和风格图像之间的相关性的相似性。设风格图像的克矩阵为 Gs，候选图像的克矩阵为 Gc。风格损失是两个格拉姆矩阵的 L2 范数。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/b7041331bcef80ccf7bd2b6eeec5df28.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*EFmrK-bNC2r5Yw8ZfC7jJw.png"/></div></figure><p id="52cc" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">让我们找出总损失函数，基于该函数来训练网络。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/60d402e4687aa8c14082e08d8204aceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*WK7-34mtPgSQyLLn_CSE-A.png"/></div></figure><p id="0d6d" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">在哪里，</p><p id="a632" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">t 代表内容图像，</p><p id="ed89" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">c 代表候选图像，</p><p id="b7b2" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">s 代表图像样式，</p><p id="5d4c" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">f 代表特征向量矩阵，</p><p id="dd63" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">I 表示在层“l”的第“I”个特征向量，</p><p id="92c0" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">g 代表克矩阵，</p><p id="77a3" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">w 代表给予特定层的权重，</p><p id="7952" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">λ符号表示内容/风格损失的重要性。</p><p id="af30" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">在使用预训练网络进行风格转换的情况下，我们不改变网络的权重，因为预训练网络擅长从图像中提取用于计算内容和风格损失的特征。</p><p id="cda8" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj jx jl jm jn jy jp jq jr jz jt ju jv jw hb bi translated">因为目的是使用迁移学习进行风格迁移，所以我们不更新或改变网络的权重，而是训练候选图像，即，我们试图最小化对应于候选图像的总损失，这意味着反向传播机制基于候选图像的像素值。</p></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><blockquote class="iv iw ix"><p id="169a" class="iy iz ja jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb hj">参考:</strong></p><p id="8f70" class="iy iz ja jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">本帖基于 Leon A Gatys 等人于 2015 年发表的一篇名为<strong class="jb hj">“艺术风格的神经算法”</strong>的论文。</p><p id="f873" class="iy iz ja jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated">为了更好地理解<a class="ae iu" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1508.06576</a>，我建议浏览一下原文</p></blockquote></div></div>    
</body>
</html>