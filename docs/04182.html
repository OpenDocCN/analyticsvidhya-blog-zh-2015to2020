<html>
<head>
<title>What is Big data and brief introduction of all Hadoop technologies:</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是大数据以及所有Hadoop技术的简要介绍:</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/big-data-and-hadoop-918f8a13f3f0?source=collection_archive---------17-----------------------#2020-03-08">https://medium.com/analytics-vidhya/big-data-and-hadoop-918f8a13f3f0?source=collection_archive---------17-----------------------#2020-03-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4e0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大数据通常被认为是需要存储和处理的海量数据。海量的不同品种的数据都可以认为是大数据。数据正以前所未有的速度改变着我们的世界和生活方式。大数据是通过处理大量相关数据来分析和预测人类和机器行为的新科学。大数据是指结构化、半结构化和非结构化数据量的快速增长。据估计，2019年每秒将产生50，000 GB的数据。当今的企业正在生成大量数据，这些数据主要有3个属性:</p><p id="1940" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷:—数据的大小，我们这里指的是GB和TB<br/>速度:—数据生成的速率<br/>种类:—来自多个来源和多种类型的数据</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/16bf8251df843ca495f1947ada7e1798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*_NtN83WLyZgLzaeC"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/be66a069252bc85acf7b86f35b9f6383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*MSZxa0zUrpxJ1SY0"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/1864bb0e71eb8c04cfd45ba9136033b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*rqDcllyKdh5kool3"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/6b1109c16c171ec606caebb7fff79ad1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*rloMfq4a80MUAJkk"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/41f395d32d98081f4d26c6a40ca77c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*6Ya9bH2T-saBaNlA"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/b503401e5e7d1a6d705873aaf6ab2d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*sdySgDuIg6QNQRzy"/></div></figure><p id="93e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">传统框架无法处理这种增加的复杂性，因此Hadoop(不是唯一的解决方案)Hadoop是一种并行处理编程框架，在MapReduce中工作。Apache Hadoop是处理大数据的工具之一。它是运行在商用硬件上的开源软件框架。</p><p id="1182" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们为什么要讨论Hadoop？</strong></p><ul class=""><li id="e3ab" class="jl jm hi ih b ii ij im in iq jn iu jo iy jp jc jq jr js jt bi translated">我们之所以这么说，是因为在hadoop框架上，我们可以存储任何类型的数据，无论是结构化、半结构化还是非结构化数据，都可以存储在Hadoop分布式文件系统[HDFS]层中。</li><li id="c46e" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">Apache hadoop是开源的，这意味着你在商业使用时不需要支付许可费。</li><li id="8b46" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">Apache Hadoop运行在商用硬件上，这意味着您不需要依赖单一供应商。您可以选择任何供应商，他们以低成本提供基础架构。</li><li id="2b27" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">考虑一个问题，你需要计算一本5磅重的书的字数。对一个人来说是非常困难的，但是如果你撕开书页，分发给几百个人。每个人将计算他们“页面”中的字数，然后你可以简单地合计每个人的字数，很快就可以算出总字数。</li></ul><p id="3769" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">为什么用Hadoop做实时例子？</strong></p><p id="b278" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设您有一个非常大的文件(例如50 gb的日志文件),您想解析它，对它进行一些过滤并查看结果。有哪些选择？</p><p id="1306" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.如果你有一台ram超过64 gb的计算机(假设额外的16 gb将用于操作系统和其他进程),你可以写一些代码来完成它。仍然会超级慢。如果文件更大(Pb级)，这甚至是不可行的。目前还没有petabye规模的内存</p><p id="f82f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.将文件解析成较小的文件(可能有10000个文件，每个文件都以兆字节为单位)并按顺序读取它们</p><p id="3d58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.使用方法2，但使用多线程，每个线程读取一个较小的文件，最后合并线程并计算结果</p><p id="6270" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Hadoop只是第三步，只是与分布式计算有点关系。你有一堆电脑。其中一台计算机为主节点，其余为从节点。所有这些节点形成一个集群。这就是hdfs或者hadoop分布式文件系统。你上传了一个巨大的文件到集群。这个巨大的文件被分割成一定大小的小文件块(例如每个X兆字节)。这些区块按照复制因子在整个集群中复制。然后使用一个名为mapreduce的编程框架，对文件块的内容进行操作，并获得想要的结果。</p><p id="8f73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Hadoop生态系统:</strong></p><p id="ec2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它由在Hadoop中执行不同任务所需的各种工具组成。</p><p id="5ee3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些工具为您提供了许多Hadoop服务，可以帮助您更高效地处理大数据。</p><p id="3463" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有一些流行的工具是Hadoop生态系统的一部分:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es jz"><img src="../Images/dd9dfe0b306e93dec4bd3d99c470126e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4tyAmTnvmvCG0xl9PmSLDg.png"/></div></div></figure><p id="270f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ke" rel="noopener" href="/@msdilli1997/all-about-hadoop-and-its-ecosystem-d17ef4760dba"><strong class="ih hj"/></a>:代表Hadoop分布式文件系统，是Hadoop的存储单元。<a class="ae ke" rel="noopener" href="/@msdilli1997/all-about-hadoop-and-its-ecosystem-d17ef4760dba">详细讲解HDFS以及数据如何读写到hdfs </a>。</p><p id="2393" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">纱线:它代表又一个资源协商者。它处理集群资源管理。为不同的应用程序分配RAM、内存和其他资源。</p><p id="bc18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ke" rel="noopener" href="/@msdilli1997/all-about-hadoop-and-its-ecosystem-d17ef4760dba"><strong class="ih hj">MapReduce</strong></a>:MapReduce以并行分布的方式处理大量数据。</p><p id="0023" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> HBase: </strong>它是一个面向列的非关系数据库管理系统，运行在Hadoop分布式文件系统(HDFS)之上。HBase提供了一种存储稀疏数据集的容错方式，这在许多大数据用例中很常见。它非常适合实时数据处理或对大量数据的随机读/写访问。</p><p id="13e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Sqoop </strong>和<strong class="ih hj"> Flume </strong>用于数据收集和摄取:<strong class="ih hj"> Sqoop </strong>用于在Hadoop和外部数据存储(如关系数据库和企业数据仓库)之间传输数据。</p><p id="5e60" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Flume </strong>是用于收集、聚合和移动大量日志数据的分布式服务。</p><p id="b9dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Pig </strong> : Pig在Hadoop中用于分析数据。它提供了一种高级数据处理语言来对数据执行各种操作。</p><p id="0772" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">配置单元(Hive):配置单元使用SQL(配置单元查询语言)来帮助读取、写入和管理驻留在分布式存储中的大型数据集。</p><p id="feaa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark是一个开源的分布式计算引擎，用于处理和分析大量的实时数据。</p><p id="eab2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Mahout </strong> : Mahout用于创建可扩展的分布式机器学习算法。它有一个库，包含用于协作过滤、分类和聚类的内置算法。</p><p id="ee9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Ambari </strong> : Ambari是一个开源工具，负责跟踪正在运行的应用程序及其状态。</p><p id="9f0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Kafka </strong> : Kafka是一个分布式流媒体平台，用于存储和处理记录流。它构建了实时流数据管道，可以在应用程序之间可靠地获取数据。</p><p id="8eb8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Storm </strong> : Storm是一个处理引擎，以非常高的速度处理实时流数据。它能够在一个节点上几秒钟内处理一百多万个作业。</p><p id="00a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Oozie是一个工作流调度系统，用于管理Hadoop作业。它有两个部分:工作引擎和协调引擎。</p></div></div>    
</body>
</html>