<html>
<head>
<title>Modeling, Evaluation, and Ensembling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建模、评估和组装</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/modeling-evaluation-and-ensembling-f00fe1de6470?source=collection_archive---------24-----------------------#2020-12-30">https://medium.com/analytics-vidhya/modeling-evaluation-and-ensembling-f00fe1de6470?source=collection_archive---------24-----------------------#2020-12-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="3d4b" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">泰坦尼克号(二元分类法)和爱荷华州房价预测(回归)</h2></div><p id="2ac9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是我的数据科学系列的第三部分。</p><ul class=""><li id="fc65" class="js jt hh iy b iz ja jc jd jf ju jj jv jn jw jr jx jy jz ka bi translated"><a class="ae kb" href="https://vrevathi.medium.com/exploratory-data-analysis-of-titanic-survival-problem-e3af0fb1f276" rel="noopener">第一部分——关于泰坦尼克号生存问题的EDA</a></li><li id="deac" class="js jt hh iy b iz kc jc kd jf ke jj kf jn kg jr jx jy jz ka bi translated"><a class="ae kb" href="https://vrevathi.medium.com/exploratory-data-analysis-of-iowa-housing-price-prediction-problem-3d50a016797a" rel="noopener">第二部分——爱荷华州房价预测EDA</a></li><li id="1000" class="js jt hh iy b iz kc jc kd jf ke jj kf jn kg jr jx jy jz ka bi translated">第三部分——模型构建、评估和组装</li></ul><p id="910e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">第一部分和第二部分包括目标变量“幸存”是二元的泰坦尼克号幸存问题的探索性数据分析和目标变量“销售价格”是连续变量的爱荷华州房价预测。我的分析包括数据清理、特征工程、相关性研究、单变量、双变量和多变量分析，使用了一些基本统计数据、一些pandas操作和seaborn的一整套可视化工具。在本系列的第三部分中，我将讨论模型构建、评估和集成。</p><h1 id="b18c" class="kh ki hh bd kj kk kl km kn ko kp kq kr in ks io kt iq ku ir kv it kw iu kx ky bi translated">泰坦尼克号生存预测</h1><p id="8417" class="pw-post-body-paragraph iw ix hh iy b iz kz ii jb jc la il je jf lb jh ji jj lc jl jm jn ld jp jq jr ha bi translated">首先，让我们导入笔记本中使用的库。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="e857" class="ln ki hh lj b fi lo lp l lq lr">import pandas as pd</span><span id="ac37" class="ln ki hh lj b fi ls lp l lq lr">from sklearn.model_selection import cross_val_score<br/>from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier)</span></pre><p id="27b7" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们读取数据集(从以前的笔记本中清除数据),并将目标变量从数据集中分离出来。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="6143" class="ln ki hh lj b fi lo lp l lq lr">df = pd.read_csv('../data/titanic_clean_data.csv')<br/>target = 'Survived'<br/>features = [ col for col in df.columns if col != target ]<br/>X, y = df[features], df[target]</span></pre><p id="75f3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在是时候初始化我们的模型了。初始化之后，我正在计算每个模型预测的特征重要性。</p><p id="3f92" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">注意，我将一个固定的种子值作为随机状态传递给所有的模型。但是为什么呢？</p><p id="58bc" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">设置手动种子参数可以确保任何重新运行您的代码的人都将获得完全相同的输出。像sklearn这样的库使用的随机数生成器并不生成真正的随机值。它们是伪随机数生成器，这意味着生成数字有一个逻辑/顺序。这个顺序可以通过设置特定的种子来控制。不管实验做了多少次，当种子设定为一个特定的值，比如说2，结果总是一样的。再现性是数据科学中一个极其重要的概念。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="0e90" class="ln ki hh lj b fi lo lp l lq lr">seed = 2<br/>rf = RandomForestClassifier(random_state=seed)<br/>et = ExtraTreesClassifier(random_state=seed)<br/>ada = AdaBoostClassifier(random_state=seed)<br/>gb = GradientBoostingClassifier(random_state=seed)</span><span id="506f" class="ln ki hh lj b fi ls lp l lq lr">models = [rf, et, ada, gb]<br/>model_names = ['RandomForest', 'ExtraTrees', 'Ada', 'GradientBoost']<br/>[ m.fit(X, y) for m in models ]<br/>feature_importances = { name: m.feature_importances_ for name, m in zip(model_names, models) }</span></pre><p id="cf62" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在我们取每个模型计算出特征重要性的平均值。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="4d9e" class="ln ki hh lj b fi lo lp l lq lr">feature_df = pd.DataFrame(feature_importances)<br/>feature_df.insert(0, 'features', features)</span><span id="1921" class="ln ki hh lj b fi ls lp l lq lr">feature_df['mean'] = feature_df.mean(axis=1)<br/>feature_df</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es lt"><img src="../Images/351f73582f9719f5f0f2243e9c426a90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*D0jV30OUYWMmyA8WkEKg9g.png"/></div></figure><p id="c2f0" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从上述数据中，我们可以看出，性别、年龄和票价在预测目标变量“存活”方面发挥了重要作用。</p><p id="cdba" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在我们从sklearn包中导入一个助手方法<code class="du lx ly lz lj b">train_test_split </code>,用于将数据分成训练集和测试集。</p><p id="39cb" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这里，我将20%的数据用于测试，其余的80%用于训练。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="2890" class="ln ki hh lj b fi lo lp l lq lr">from sklearn.model_selection import train_test_split</span><span id="93c8" class="ln ki hh lj b fi ls lp l lq lr">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)</span></pre><p id="6b96" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">投票分类器是一种机器学习模型，它从一系列机器学习模型中集成预测，并通过对预测进行投票来预测输出。</p><p id="8aa9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们导入包并初始化模型，然后在数据上安装分类器。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="f675" class="ln ki hh lj b fi lo lp l lq lr">from sklearn.ensemble import VotingClassifier</span><span id="6344" class="ln ki hh lj b fi ls lp l lq lr">vc = VotingClassifier(estimators=[(name, m) for name, m in zip(model_names, models)<br/>])</span><span id="9616" class="ln ki hh lj b fi ls lp l lq lr">vc.fit(X, y)</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es ma"><img src="../Images/496cd6d7b8b51a815ddf9b7e10f2f211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*wzpVcIqZd3yECF2bBbtEdg.png"/></div></figure><p id="9b9f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">基于投票分类器预测，让我们计算交叉验证分数。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="01f5" class="ln ki hh lj b fi lo lp l lq lr">scores = cross_val_score(vc, X, y, cv=5, scoring='accuracy')<br/>scores</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es mb"><img src="../Images/f890243918b5ffc1697a9a0ca927d79a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*f9bTFW-bV41OGzuXnYTEVg.png"/></div></figure><p id="d29b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们拟合数据，然后将我们的预测与实际数据进行比较，以获得准确性。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="50ee" class="ln ki hh lj b fi lo lp l lq lr">vc.fit(X_train, y_train)</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es mc"><img src="../Images/fc37461efbfb3ec307e0e58de588b861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*hcq8AQqc913vBq5nbVCRNA.png"/></div></figure><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="255f" class="ln ki hh lj b fi lo lp l lq lr">pred = vc.predict(X_test)<br/>100. * (pred == y_test).mean()</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es md"><img src="../Images/8e7a950411cae6eece73f4bfa271c70f.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/format:webp/1*9AvoiwltWhIdKC3Z8b6Nsg.png"/></div></figure><p id="98ce" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们得到了81.56%的准确率，这不是很好。不过没关系。进步是一点一点地发生的。</p><blockquote class="me mf mg"><p id="2305" class="iw ix mh iy b iz ja ii jb jc jd il je mi jg jh ji mj jk jl jm mk jo jp jq jr ha bi translated">"移山的人是从搬走小石头开始的."~孔子</p></blockquote><h1 id="ae02" class="kh ki hh bd kj kk kl km kn ko kp kq kr in ks io kt iq ku ir kv it kw iu kx ky bi translated">爱荷华房价预测</h1><p id="cf79" class="pw-post-body-paragraph iw ix hh iy b iz kz ii jb jc la il je jf lb jh ji jj lc jl jm jn ld jp jq jr ha bi translated">泰坦尼克号的生存是一个二元分类问题。我们的下一个模型是一个回归模型，用于预测来自Kaggle的爱荷华州房价预测问题。数据清理和可视化部分已经在我以前的文章中分享过了。</p><p id="b25d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">二元分类和回归的模型建立和评估更加相似。</p><p id="bd0e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们导入用于构建回归模型的库。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="1661" class="ln ki hh lj b fi lo lp l lq lr">from sklearn.linear_model import ElasticNet, Lasso<br/>from sklearn.ensemble import GradientBoostingRegressor<br/>from sklearn.model_selection import cross_val_score, train_test_split<br/>import xgboost as xgb<br/>import lightgbm as lgb<br/>import pandas as pd<br/>from scipy import stats<br/>from scipy.stats import norm, skew</span></pre><p id="5f68" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们阅读在以前的笔记本中整理过的训练和测试数据集。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="89e2" class="ln ki hh lj b fi lo lp l lq lr">train = pd.read_csv('../data/clean_train-hpp.csv')<br/>y_train = pd.read_csv('../data/clean_y_train-hpp.csv')</span></pre><p id="8f7d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在让我们使用sklearn包中的<code class="du lx ly lz lj b">LabelEncoder</code>将分类变量转换成数字形式。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="1a5f" class="ln ki hh lj b fi lo lp l lq lr">from sklearn.preprocessing import LabelEncoder<br/>cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', <br/>        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', <br/>        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',<br/>        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', <br/>        'YrSold', 'MoSold')</span><span id="1d9e" class="ln ki hh lj b fi ls lp l lq lr"><br/>for c in cols:<br/>    lbl = LabelEncoder() <br/>    lbl.fit(list(train[c].values)) <br/>    train[c] = lbl.transform(list(train[c].values))</span><span id="9e0f" class="ln ki hh lj b fi ls lp l lq lr">       <br/>print('Shape of train data: {}'.format(train.shape))</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es ml"><img src="../Images/4a82bf7a2c0c07e9e5eb341ceca89d84.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*2hJK4zqMjMMEg3eF3mQetg.png"/></div></figure><h1 id="9997" class="kh ki hh bd kj kk kl km kn ko kp kq kr in ks io kt iq ku ir kv it kw iu kx ky bi translated"><strong class="ak">歪斜</strong></h1><p id="6e4f" class="pw-post-body-paragraph iw ix hh iy b iz kz ii jb jc la il je jf lb jh ji jj lc jl jm jn ld jp jq jr ha bi translated">在正态分布中，图表看起来是对称的，这意味着右侧数据点的数量或多或少等于左侧数据的数量。在这种情况下，数据的平均值、中值和众数或多或少是相同的。</p><p id="f203" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果曲线左侧较大，这意味着数据是正偏的。在这种情况下，平均值和中值大于众数，平均值大于中值。同样，如果曲线右侧较大，则数据是负向倾斜的。</p><p id="a0dc" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果数据是倾斜的，图形的尾部将包含异常值，这将影响模型的性能，尤其是在回归问题中。首先，让我们计算数据集的偏斜。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="29d6" class="ln ki hh lj b fi lo lp l lq lr">numeric_feats = train.dtypes[train.dtypes != "object"].index</span><span id="8de1" class="ln ki hh lj b fi ls lp l lq lr"># Check the skew of all numerical features<br/>skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)<br/>print("\nSkew in numerical features: \n")<br/>skew = pd.DataFrame({'Skew' :skewed_feats})<br/>skew.head(10)</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es mm"><img src="../Images/5aa2e437dd7b1a0342ee80455dc09e57.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*K43pW0ulfRZQ1zlnhYZthA.png"/></div></figure><h1 id="727a" class="kh ki hh bd kj kk kl km kn ko kp kq kr in ks io kt iq ku ir kv it kw iu kx ky bi translated"><strong class="ak"> Box-Cox变换</strong></h1><p id="0e7a" class="pw-post-body-paragraph iw ix hh iy b iz kz ii jb jc la il je jf lb jh ji jj lc jl jm jn ld jp jq jr ha bi translated">为了修复数据集中的偏差，我们通常使用几种方法。使用的一些方法有:<br/> 1。缩放比例<br/> 2。日志转换<br/> 3。立方根归一化<br/> 4。博克斯-考克斯变换。</p><p id="1d57" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在使用上述方法之前，需要记住一些重要的事情:</p><p id="a3a6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">1.对数转换用于将数据集转换成更小的值<br/> 2。如果数据有太多的极值，我们就使用这些技术。<br/> 3。这些技术并不总是能给出最佳结果<br/> 4。使用这些方法不会丢失数据</p><p id="dde0" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在所有上述方法中，Box-Cox变换给出了最好的结果。因此，我们在这个问题中使用Box-Cox变换。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="359b" class="ln ki hh lj b fi lo lp l lq lr">skew = skew[abs(skew) &gt; 0.75]<br/>print("There are {} skewed numerical features to Box Cox transform".format(skew.shape[0]))</span><span id="a973" class="ln ki hh lj b fi ls lp l lq lr">from scipy.special import boxcox1p<br/>skewed_features = skew.index<br/>lam = 0.15<br/>for feat in skewed_features:</span><span id="a369" class="ln ki hh lj b fi ls lp l lq lr">train[feat] = boxcox1p(train[feat], lam)</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es mn"><img src="../Images/bcebb31c19ccf4a51f4040bb431f6bac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*JzFNPnixXt5FHerQRNr5Tg.png"/></div></figure><p id="a4a9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="mh"> get_dummies() </em>方法将分类变量分成多个变量，每个变量用1和0表示特定类的存在或不存在。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="c62b" class="ln ki hh lj b fi lo lp l lq lr">df = pd.get_dummies(train)<br/>print(df.shape)</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es mo"><img src="../Images/57bb865a554db78d7c1b583d3e4dd6dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*GeRH_MFZPx4VpClw0-WUWw.png"/></div></figure><p id="fa44" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在是初始化回归模型的时候了。如前所述，我将一个通用的随机状态传递给所有模型，以确保可重复性。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="6d28" class="ln ki hh lj b fi lo lp l lq lr">seed=3<br/>lasso = Lasso(random_state=seed)<br/>ENet = ElasticNet(random_state=seed)<br/>GBoost = GradientBoostingRegressor(random_state =seed)<br/>model_xgb = xgb.XGBRegressor(random_state =seed)<br/>model_lgb = lgb.LGBMRegressor(random_state =seed)</span></pre><p id="021f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们将只利用训练集进行模型训练和评估。所以我们对从磁盘读取的清理后的训练数据进行适当的重命名。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="782b" class="ln ki hh lj b fi lo lp l lq lr">X, y = train, y_train</span></pre><p id="687a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们计算每个模型的平均交叉验证分数，并将结果可视化。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="74a8" class="ln ki hh lj b fi lo lp l lq lr">from sklearn.model_selection import cross_val_score<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>plt.style.use('ggplot')</span><span id="cbbe" class="ln ki hh lj b fi ls lp l lq lr">model_names = ['Lasso', 'ElasticNet', 'GradientBoostingRegressor', 'XGBRegressor', 'LGBMRegressor']<br/>models =  [lasso, ENet, GBoost, model_xgb, model_lgb]<br/>mean_score = []<br/>for model in models:<br/>    scores = cross_val_score(model, X, y.SalePrice, cv=10, scoring='neg_mean_squared_error')<br/>    mean_score.append(-1 * scores.mean())</span><span id="e3fc" class="ln ki hh lj b fi ls lp l lq lr">plt.figure(figsize=(15, 7))<br/>g = sns.scatterplot(x=model_names, y=mean_score, hue=mean_score, s=200)<br/>plt.xticks(rotation=45);<br/>plt.show();</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mp"><img src="../Images/4c9a92b5cbd5cd7baa1cb2ba7ce768eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bMupao1NKc0HRY0AIpXH2w.png"/></div></div></figure><p id="b228" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从上图可以看出，梯度推进回归器比其他模型表现更好。因此我们选择这个模型进行预测。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="0707" class="ln ki hh lj b fi lo lp l lq lr">from sklearn.model_selection import train_test_split</span><span id="02ef" class="ln ki hh lj b fi ls lp l lq lr">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)<br/>GBoost.fit(X_train, y_train)<br/>y_pred = GBoost.predict(X_test)<br/>y_real = y_test.SalePrice<br/>MAPE = abs((y_real - y_pred) / y_real).mean()</span></pre><p id="61e0" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们已经计算了MAPE(平均绝对百分比误差)。MAPE是回归问题的另一种性能指标，它用百分比表示结果，比均方误差(MSE)更容易解释。</p><p id="39c1" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们通过反演MAPE来计算精度。</p><pre class="le lf lg lh fd li lj lk ll aw lm bi"><span id="83ba" class="ln ki hh lj b fi lo lp l lq lr">100. - (100. * MAPE)</span></pre><figure class="le lf lg lh fd lu er es paragraph-image"><div class="er es mu"><img src="../Images/ee26f00aa10f04df9c09b245fc132313.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/1*0pa7RDOYH91277bjb48nfw.png"/></div></figure><p id="8f1b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">梯度推进回归器达到了90.39%的准确率。非常好。但仍有很大的改进空间。</p><p id="14c3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这正式结束了我的“开始数据科学”系列，开始了我的数据科学之旅。在过去的两个月里，我解决了几个数据科学问题，包括:</p><ul class=""><li id="7d74" class="js jt hh iy b iz ja jc jd jf ju jj jv jn jw jr jx jy jz ka bi translated"><a class="ae kb" href="https://www.kaggle.com/c/forest-cover-type-prediction" rel="noopener ugc nofollow" target="_blank">森林覆盖类型预测</a> —多级分类</li><li id="75e1" class="js jt hh iy b iz kc jc kd jf ke jj kf jn kg jr jx jy jz ka bi translated"><a class="ae kb" href="https://www.kaggle.com/blastchar/telco-customer-churn" rel="noopener ugc nofollow" target="_blank">电信客户流失预测</a> —二元分类</li><li id="3ec7" class="js jt hh iy b iz kc jc kd jf ke jj kf jn kg jr jx jy jz ka bi translated"><a class="ae kb" href="https://www.kaggle.com/c/web-traffic-time-series-forecasting" rel="noopener ugc nofollow" target="_blank">网络流量时间序列预测</a> —时间序列预测</li></ul><p id="3f93" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">作为本系列的后续，我将写一些关于这些问题以及我是如何处理它们的。时间序列预测特别吸引我，因为它不像其他问题那样简单。虽然深度神经网络和机器学习模型的集成主导了结构化数据、图像和文本的领域，但ARIMA及其变体等统计方法仍然统治着时间序列的领域。我花了相当多的时间来理解时间序列预测概念，如自相关(ACF)、部分自相关(PACF)、趋势、熵等。它值得拥有自己的博客系列。很快会看到更多令人兴奋的东西。</p><p id="d665" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我很重视您的反馈，很想知道您对这个系列的想法。</p></div></div>    
</body>
</html>