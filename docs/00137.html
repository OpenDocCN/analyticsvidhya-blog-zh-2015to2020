<html>
<head>
<title>Scikit-Learn: A silver bullet for basic machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Scikit-Learn:基础机器学习的银弹</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/scikit-learn-a-silver-bullet-for-basic-machine-learning-13c7d8b248ee?source=collection_archive---------0-----------------------#2018-10-06">https://medium.com/analytics-vidhya/scikit-learn-a-silver-bullet-for-basic-machine-learning-13c7d8b248ee?source=collection_archive---------0-----------------------#2018-10-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/140ed3b2f44f7824a8437067b4f32b32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z-_I-IKEjdGppk88ykIMaA.jpeg"/></div></div></figure><p id="76d1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi jo translated">cikit-Learn是python的核心机器学习包，它拥有支持基本机器学习项目的大多数必要模块。该库为从业者提供了统一的API(应用编程接口),以简化机器学习算法的使用，只需编写几行代码即可完成预测或分类任务。<strong class="is hj">python中为数不多的几个保持算法和接口层简单的库之一</strong>，并且不使其复杂化，以覆盖整个机器学习特性领域。这个包主要是用python编写的，它包含了C++库，如LibSVM和LibLinear，用于支持向量机和广义线性模型实现。这个包依赖于Pandas(主要用于dataframe进程)、numpy(用于ndarray构造)和scipy(用于稀疏矩阵)。</p><p id="7f42" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个包之所以有用，主要是因为它的项目愿景。<strong class="is hj">代码质量和适当的文档构成了核心愿景。</strong>对于给定的算法，健壮的实现优先于尽可能多的特性包含，并且该实现得到单元测试的有力支持(覆盖率&gt; 80%)。软件包文档包括叙述性文档、类参考、教程、安装说明和60多个对初学者非常有用的例子。并非所有即将到来的机器学习算法都会立即添加到包中，以保持包的整洁。对于新的机器学习算法，有一个明确的包含标准设置。纳入标准符合以下条件。</p><ol class=""><li id="ace2" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf bi translated">所提出的算法应该在某些方面优于在其中实现的方法。</li><li id="b796" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">应该无缝地适应API设计(应该将numpy数组作为输入，并遵循fit/transform/predict流程)。</li><li id="9967" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">新的实现必须得到研究论文或另一个包中的实现的支持。</li></ol><p id="f581" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">是的，直接用numpy和scipy编写算法代码是可能的，但这需要这个人擅长编程、数学、统计、性能调优、版本控制和测试。此外，编写的代码实现必须是可重用的和可伸缩的，以备将来使用。当整个社区都在朝着同一个目标努力时，为什么要大费周章编写自己的机器学习算法实现呢？Scikit-Learn正在积极开发中，这应该得到很好的利用，以便从业者可以专注于手头的业务问题，而不是花时间在如何实现算法以有效地使用底层硬件上。</p><p id="2bb1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一揽子计划中的基本要素将是一个评估者。估计器可以是转换数据(预处理和流水线)的估计器，也可以是机器学习算法实现。所有其他模块将支持估计器。即数据集、分解、度量、特征选择、模型选择、集成和效用</p><figure class="kl km kn ko fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/4d7d888d78500b3ec5674789e00d834d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1qOrApYAFKTurizFnsID1Q.jpeg"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">sci kit-了解一般流程</figcaption></figure><h2 id="9558" class="kt ku hi bd kv kw kx ky kz la lb lc ld jb le lf lg jf lh li lj jj lk ll lm ln bi translated">大多数Scikit-Learn模块遵循相同的步骤。</h2><ol class=""><li id="0887" class="jx jy hi is b it lo ix lp jb lq jf lr jj ls jn kc kd ke kf bi translated">用参数实例化一个估计器(否则它将采用默认参数)</li><li id="b2ca" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">通过fit方法向估计器实例提供输入数据(输入可以是包含选定列的pandas数据帧、Numpy 2d数组或Scipy稀疏矩阵)。拟合可以只采用一个数组或输入数组和目标组合</li><li id="5f99" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">如果是数据操作模块，它会附带一个转换方法。检查fit_transform方法，这样第2步和第3步都可以用一行代码完成</li><li id="40c3" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">在拟合方法之后，估计器应该有一个预测方法来预测测试输入的大小或类别</li></ol><p id="b1d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">并非所有python包都是平等的。Scikit-learn做了一件事，而且只有一件事做得很好，那就是实现基本的机器学习算法。</p><h2 id="4a43" class="kt ku hi bd kv kw kx ky kz la lb lc ld jb le lf lg jf lh li lj jj lk ll lm ln bi translated">这个包裹不应该是什么</h2><ol class=""><li id="bd6c" class="jx jy hi is b it lo ix lp jb lq jf lr jj ls jn kc kd ke kf bi translated">它不是一个深度/强化学习包，因为TensorFlow和PyTorch在这一类别中得分很高，而且Scikit-Learn不提供任何图形处理单元支持。包括GPU支持可能会使实现变得复杂，因为它需要为多种硬件和操作系统组合提供支持</li><li id="58fb" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">它不是一个可视化包，因为matplotlib、seaborn和plotly用于创建良好的探索性数据分析图和模型评估图</li><li id="db0e" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">它不是一个结构化学习和预测包，因为pystruct可以很好地处理一般的结构化学习，而seqlearn只能处理带有HMM推理的序列</li><li id="1c07" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">它不是一个自然语言处理包，因为NLTK和Gensim具有更好的NLP算法实现和相关的语言语料库</li><li id="7bd8" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">它不是一个基本的统计软件包，因为statsmodel包含基本的统计指标实现以及时间序列预测模块</li></ol><h1 id="f645" class="lt ku hi bd kv lu lv lw kz lx ly lz ld ma mb mc lg md me mf lj mg mh mi lm mj bi translated">预测问题的例子；使用内置癌症数据集</h1><figure class="kl km kn ko fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c365b344800c637cf34707617f481804.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VI3C1hMwAjSazcMU4X4mtw.jpeg"/></div></div></figure><figure class="kl km kn ko fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/538df2c18fd4f5a817258179dedfd38d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pm5O1NE07Yuo6U4XSs2Cjw.jpeg"/></div></div></figure><p id="2145" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们从这里开始一个机器学习项目的工作流程。此工作流程的目的不是提高分类问题的准确性或f1分数，而是触及所有必要的模块，以使用scikit-learn有效地完成分类问题。大多数分类示例都是从iris数据集开始的，因此让我们在scikit-learn中挑选另一个数据集用于此工作流。我们将主要研究威斯康星州乳腺癌数据集。目的是基于患者的临床观察参数对诊断(癌症诊断:真或假)进行分类。该数据集包含569个观测值和30个连续数值特征。212 —恶性，357 —良性。</p><ul class=""><li id="63f8" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">数据集和生成器</strong>:与无监督的学习任务不同，有监督的任务(即分类)需要带标签的数据集，并且该包带有多个数据集和数据集生成器，以开始机器学习</li></ul><p id="f564" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大致分为两种类型</p><p id="73bb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a.静态/玩具数据集:数据集是具有特征数据(numpy ndarray)、数据集描述、特征名称、目标(numpy array和用于多标签的ndarray)和目标名称(即，fetch_20newsgroups包含文本输入)的字典，并且被分组为20个不同的新闻组，如体育、政治、金融等。, ).这些数据集只有有限数量的观测值和目标类或预测范围。即著名的iris数据集只有150个观测值和3个目标类。我已经写了一个函数，将字典格式的内置数据集转换成熊猫数据帧，以便可视化和探索</p><figure class="kl km kn ko fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/034e147d1cbbd4b3400eb3e4a4c99c7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MIlPFNmTmwV878PyxmMwpA.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">使用seaborn的癌症数据集配对图</figcaption></figure><p id="003f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">b.样本生成器:与玩具数据集相比，大多数机器学习算法将需要更多的标记观察值，该包内置了样本生成器例程，以生成具有所需观察值数量的标记数据集。即，样本生成器make_moons采用两个关键参数n_samples和noise。从业者可以向例程提供大量样本来生成噪声并将其添加到输入特征中</p><figure class="kl km kn ko fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/881a663f4e4f1776a37ca55ba6f9f8d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZMT2Iix0mIAHsgX9S95MPg.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">make_blobs样本生成器生成的输出数据集</figcaption></figure><ul class=""><li id="c85b" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">训练和测试分割</strong>:加载数据集后，它必须分割成训练集和测试集，以开始算法训练。这个包有一个例程将pandas数据帧或numpy数组分解成训练集和测试集。该方法采用输入要素、目标数组、测试集的大小(观察值占整个数据集的百分比)和分层数组。分层是一个方便的选择，因为目标类的比例在训练集和测试集中是相同的。即，目标分布(良性与恶性的比率)在训练和测试数据集中是相同的</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="1e1b" class="kt ku hi mo b fi ms mt l mu mv">X_train, X_test, y_train, y_test =   </span><span id="7b7e" class="kt ku hi mo b fi mw mt l mu mv"> train_test_split(cancer_data_pd[cancer_data_dict.feature_names],<br/>   cancer_data_dict['target'],<br/>   test_size=0.20,<br/>   stratify=cancer_data_dict['target'],<br/>   random_state=111,<br/>   shuffle=True);</span><span id="6548" class="kt ku hi mo b fi mw mt l mu mv">INFO - X_train.shape : (455, 30)<br/>INFO - X_test.shape  : (114, 30)<br/>INFO - Y_train.shape : (455,)<br/>INFO - Y_test.shape  : (114,)</span></pre><ul class=""><li id="acaa" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">虚拟回归器和分类器:</strong>在探索性数据分析和特征选择之前，我强烈建议建立一个虚拟回归器或分类器。DummyClassifier将为模型提供偏差场景。即，在癌症数据集中，大多数(最频繁)类别是良性的(569个中的357个)，因此将任何未来的测试观察(患者)分配到良性类别将是伪分类器。虚拟估计器在目标变量中寻找模式，而不是从输入特征中学习模式。为什么我们需要一个虚拟评估者是为了获得模型性能度量的基线。任何其他机器学习算法至少应该优于虚拟估计器</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="6665" class="kt ku hi mo b fi ms mt l mu mv">dummy_classifier = DummyClassifier(strategy="most_frequent");</span></pre><ul class=""><li id="6bb5" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">模型性能度量:</strong>必须在训练集上训练算法，并在测试集上测试算法。应该使用模型性能指标来访问模型的性能。即，准确度是范围从0到1的分类度量(准确度越高越好)。<br/> <strong class="is hj"> <em class="mx">准确率=正确的类别预测/总预测。</em> </strong> <br/>该软件包提供了多种评估模型性能的指标。从业者还可以编写一个定制的度量标准，并将其包装在一个make_scorer方法中，这样它就可以很好地与包API集成</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="e2d9" class="kt ku hi mo b fi ms mt l mu mv">def cost_accuracy(actual, prediction):<br/>    """ Custom accuracy cost function to be used in the scorer """;<br/>    # accuracy = correct predictions / total predictions</span><span id="3e41" class="kt ku hi mo b fi mw mt l mu mv">    assert len(actual) == len(prediction);<br/>    return round((np.sum(actual == prediction) / len(actual)) , 4);</span><span id="ffd5" class="kt ku hi mo b fi mw mt l mu mv">accuracy_scorer = make_scorer(cost_accuracy, greater_is_better=True);</span></pre><ul class=""><li id="95ab" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj"> KFold和CrossVal Score/Predict: </strong>为了避免算法过度适应训练集，需要将其推广到一定程度。不是在整个训练集中运行训练算法，而是将训练集分成多个块(即，10个相等的块)并在几个卡盘上训练(9个用于训练)并在其余卡盘上测试(1个用于测试)。为了避免过度拟合，将重复该过程。过度拟合模型仅在训练集模式/场景下表现良好，而在测试集上却很难做出正确的分类预测。该包提供了KFOLD和CrossVal例程，以避免过度拟合。在下面的代码中，kfold设置了10个分割(10个不同的组。每组将具有训练输入特征、训练目标、测试输入特征、测试目标)。cross_val_score将适合10组kfold数据集上10个虚拟分类器。准确度分数将会列在一个列表上</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="8acb" class="kt ku hi mo b fi ms mt l mu mv">kfold = model_selection.KFold(n_splits=10, random_state=111);<br/>results = model_selection.cross_val_score(dummy_classifier, X_train, y_train, cv=kfold, scoring=accuracy_scorer);</span></pre><ul class=""><li id="fd8f" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">标准化:</strong>必须对所有连续的数字输入特征进行缩放，以便没有一个特征会影响模型性能。也就是说，输入要素A的范围可能是以百万计，而B的范围可能是以百计，如果没有缩放到标准比例，模型将不会学习要素B中的变化。该包带有最小最大值(在0和1之间缩放)和标准缩放器(比例输出将包括负值)</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="b323" class="kt ku hi mo b fi ms mt l mu mv">std_scaler = preprocessing.MinMaxScaler(); <br/>std_scaler = std_scaler.fit(X_train);<br/>scaled_X_train = pd.DataFrame(std_scaler.transform(X_train), columns=X_train.columns);</span></pre><ul class=""><li id="b2f0" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj"> SelectKBest: </strong>输入特征选择是任何模型建立过程中非常关键的一步。该软件包提供了基于给定标准选择n个最佳特征的例程。在下面的代码中，基于f_classif标准(分类模型性能度量之一)选择特性</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="a942" class="kt ku hi mo b fi ms mt l mu mv">selectKbest_est = SelectKBest(f_classif, k=8);<br/>selectKbest_X_train = selectKbest_est.fit_transform(X_train, y_train);</span></pre><ul class=""><li id="c4bc" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">多项式特征生成:</strong>结合输入特征生成多项式和交互项。包预处理模块附带了多项式要素例程，用于根据给定的次数生成新要素</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="bc89" class="kt ku hi mo b fi ms mt l mu mv">poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False, interaction_only=False);<br/>    <br/>X_train_poly = poly.fit_transform(X_train);<br/>X_train_p2 = pd.DataFrame(X_train_poly, </span><span id="2b8f" class="kt ku hi mo b fi mw mt l mu mv">columns=poly.get_feature_names(X_train.columns));</span></pre><ul class=""><li id="c0da" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">分解— PCA(核PCA —主成分分析):</strong>这是输入特征数量巨大的地方，需要分解成几个，但要保持特征间的方差。这个包附带了KernelPCA例程，将特性压缩到一个更小的集合中。该方法可以采用各种内核来执行PCA。数据必须针对PCA进行缩放</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="c7cc" class="kt ku hi mo b fi ms mt l mu mv">kernel_param = ('rbf', 1);<br/>kpca = KernelPCA(n_components=4, <br/>                 kernel=kernel_param[0], <br/>                 gamma=kernel_param[1], <br/>                 fit_inverse_transform=True, <br/>                 random_state=111)     <br/>kpca.fit(scaled_X_train);   # The data has to be scaled;<br/>kpca_X_train = kpca.transform(scaled_X_train);</span></pre><ul class=""><li id="4f2e" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">网格搜索(GridSearchCV): </strong>模型参数调整是一项令人生畏的任务，必须记录多次迭代及其性能指标，直到一次迭代达到最佳参数集。在Scikit-learn中，参数调整主要是通过GridSearchCV例程来简化的。给定模型参数组合的列表，该方法运行所有可能的组合，并返回最佳模型参数以及最佳估计量。该方法还执行交叉验证，因此最佳估计器不会过度拟合训练数据。在下面的代码中，有8个(2 x 2 x 2 x 1)参数组合，由于交叉验证是5，所以该例程将适合40个模型</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="dc9a" class="kt ku hi mo b fi ms mt l mu mv">tuning_parameters = [{'n_estimators' : [1, 10],<br/>                      'max_depth' : [10, 20],<br/>                      'max_features' : [0.80, 0.40],<br/>                      'random_state' : [111]<br/>                     }];</span><span id="7aa6" class="kt ku hi mo b fi mw mt l mu mv">clf = GridSearchCV(RandomForestClassifier(), <br/>                   tuning_parameters, <br/>                   cv=5, <br/>                   scoring=accuracy_scorer);</span><span id="cee8" class="kt ku hi mo b fi mw mt l mu mv">clf.fit(X_train, y_train);</span></pre><ul class=""><li id="3209" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">定制估计器和管道:</strong>从业者可以编写他们的定制估计器。定制估计器可以是流水线的一部分。管道接受多个估算器，并按顺序执行它们。它将把前一个估计器的输出作为输入传递给列表中的下一个估计器。可以使用流水线设计整个模型过程(标准缩放器、估算器、多项式特征生成和分类模型拟合),并且可以直接拟合到数据集。这个例程对于简化模型生产部署非常有帮助。在下面的代码中，ColumnTypeFilter将只返回numpy number类型的熊猫列。管道从ColumnTypeFilter获取输出，并使用标准缩放器和最小-最大缩放器对其进行缩放。输出的数字要素数量将是输入的两倍</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="931c" class="kt ku hi mo b fi ms mt l mu mv">class ColumnTypeFilter(BaseEstimator, TransformerMixin):<br/>    """ Custom transformer to select all columns of a particular type in a pandas dataframes """;</span><span id="e6b1" class="kt ku hi mo b fi mw mt l mu mv">    def __init__(self, dtype):<br/>        self.dtype = dtype;</span><span id="0250" class="kt ku hi mo b fi mw mt l mu mv">    def fit(self, X, y=None):<br/>        return self;</span><span id="162f" class="kt ku hi mo b fi mw mt l mu mv">    def transform(self, X):<br/>        assert isinstance(X, pd.DataFrame);<br/>        return X.select_dtypes(include=[self.dtype]);</span><span id="d63f" class="kt ku hi mo b fi mw mt l mu mv">ctf = ColumnTypeFilter(np.number);<br/>ctf.fit_transform(X_train).head();</span><span id="75bb" class="kt ku hi mo b fi mw mt l mu mv">custom_pipeline = make_pipeline(<br/>            FeatureUnion(transformer_list=[<br/>                ('StdScl', make_pipeline(<br/>                    ColumnTypeFilter(np.number),<br/>                    preprocessing.StandardScaler()<br/>                )),<br/>                ('MMScl', make_pipeline(<br/>                    ColumnTypeFilter(np.number),<br/>                    preprocessing.MinMaxScaler()<br/>                ))<br/>            ])<br/>    );</span></pre><ul class=""><li id="263e" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated">集成模型(Ensemble models)—voting classifier:我最喜欢的分类程序之一。向VotingClassifier中添加尽可能多的分类器估计器(估计器应该有预测概率的方法)。对于新的测试记录，例程会将该记录发送给所有评估者，并获得类别预测，然后根据多数投票分配类别</li></ul><p id="a346" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">工作中的民主。</p><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="a383" class="kt ku hi mo b fi ms mt l mu mv">ensemble_clf = VotingClassifier(estimators=[<br/>                            ('dummy', dummy_classifier),<br/>                            ('logistic', lr),<br/>                            ('rf', RandomForestClassifier())],<br/>                            voting='soft');</span><span id="b321" class="kt ku hi mo b fi mw mt l mu mv">ensemble_clf.fit(X_train, y_train);<br/>ensemble_clf_accuracy_ = cost_accuracy(y_test,<br/>   ensemble_clf.predict(X_test));</span></pre><ul class=""><li id="2652" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">处理分类和文本输入特征:</strong>任何机器学习模型都需要数字输入特征(连续或分类)，而文本特征不能很好地集成。Scikit-learn对此也有一种药物。使用标签编码器或一键编码器。下面婴儿的名字被转换成数字向量，一旦被转换，这些向量将作为模型训练的输入特征</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="c67b" class="kt ku hi mo b fi ms mt l mu mv">baby_names = ['Ava', 'Lily', 'Noah', 'Jacob', 'Mia', 'Sophia'];<br/>X_train_list = [ np.random.choice(baby_names) for i in range(40) ];<br/>X_test_list = [ np.random.choice(baby_names) for i in range(6) ];</span><span id="cea7" class="kt ku hi mo b fi mw mt l mu mv">bb_labelencoder = preprocessing.LabelEncoder();<br/>bb_labelencoder.fit(X_train_list);<br/>bb_encoded = bb_labelencoder.transform(X_test_list);</span><span id="3c2c" class="kt ku hi mo b fi mw mt l mu mv">bb_onehotencoder = preprocessing.OneHotEncoder(sparse=False);<br/>bb_encoded = bb_encoded.reshape(len(bb_encoded), 1);<br/>bb_onehot = bb_onehotencoder.fit_transform(bb_encoded);</span><span id="1fb2" class="kt ku hi mo b fi mw mt l mu mv">Actual : Ava   | LabelEncoded : 0   | OneHot : [ 1.  0.  0.  0.]<br/>Actual : Ava   | LabelEncoded : 0   | OneHot : [ 1.  0.  0.  0.]<br/>Actual : Noah  | LabelEncoded : 4   | OneHot : [ 0.  0.  0.  1.]<br/>Actual : Mia   | LabelEncoded : 3   | OneHot : [ 0.  0.  1.  0.]<br/>Actual : Lily  | LabelEncoded : 2   | OneHot : [ 0.  1.  0.  0.]<br/>Actual : Lily  | LabelEncoded : 2   | OneHot : [ 0.  1.  0.  0.]</span></pre><ul class=""><li id="26ac" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn mk kd ke kf bi translated"><strong class="is hj">特征提取(从图像和文本中):</strong>使用这些例程将文本文档列表直接转换为输入特征，无需太多代码。在下面的代码中，句子列表被转换成单词计数的观察值。</li></ul><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="bcf1" class="kt ku hi mo b fi ms mt l mu mv">corpus = ['This is the first document.',<br/>          'This document is the second document.',<br/>          'And this is the third one.',<br/>          'Is this the first document?', ]</span><span id="8dcf" class="kt ku hi mo b fi mw mt l mu mv">vectorizer = CountVectorizer();<br/>X = vectorizer.fit_transform(corpus);</span><span id="63ae" class="kt ku hi mo b fi mw mt l mu mv">cntvector_out = pd.DataFrame(X.toarray(), <br/>       columns=vectorizer.get_feature_names());</span><span id="f413" class="kt ku hi mo b fi mw mt l mu mv">Input text : This is the first document.<br/>Output counter vector : This is the first document.<br/>and         0<br/>document    1<br/>first       1<br/>is          1<br/>one         0<br/>second      0<br/>the         1<br/>third       0<br/>this        1</span></pre><h2 id="5d6e" class="kt ku hi bd kv kw kx ky kz la lb lc ld jb le lf lg jf lh li lj jj lk ll lm ln bi translated">快乐编码，不断学习。</h2><p id="dbed" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb my jd je jf mz jh ji jj na jl jm jn hb bi translated">链接到<em class="mx">代码</em>回购</p><div class="nb nc ez fb nd ne"><a href="https://github.com/manikandanj2207/dataibreathe/blob/master/03.Scikit_Learn_WorkFlow_V1.0.py" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab dw"><div class="ng ab nh cl cj ni"><h2 class="bd hj fi z dy nj ea eb nk ed ef hh bi translated">manikandanj2207/dataibreathe</h2><div class="nl l"><h3 class="bd b fi z dy nj ea eb nk ed ef dx translated">支持媒体博客的代码库。为manikandanj 2207/dataibreat的发展作出贡献</h3></div><div class="nm l"><p class="bd b fp z dy nj ea eb nk ed ef dx translated">github.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns io ne"/></div></div></a></div><blockquote class="nt nu nv"><p id="8488" class="iq ir mx is b it iu iv iw ix iy iz ja nw jc jd je nx jg jh ji ny jk jl jm jn hb bi translated">喜欢这篇文章就鼓掌</p></blockquote></div></div>    
</body>
</html>