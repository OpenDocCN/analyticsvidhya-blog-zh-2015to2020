<html>
<head>
<title>Explained Output of Nvidia-smi Utility</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释了Nvidia-smi实用程序的输出</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/explained-output-of-nvidia-smi-utility-fc4fbee3b124?source=collection_archive---------0-----------------------#2019-12-16">https://medium.com/analytics-vidhya/explained-output-of-nvidia-smi-utility-fc4fbee3b124?source=collection_archive---------0-----------------------#2019-12-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8e73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嘿学员们！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/a61d92a28004591ca5d12c2e3bac1170.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ianrgIuKkKuPBFrHczc_8g@2x.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来自<a class="ae jt" href="https://www.nvidia.com/en-us/about-nvidia/partners/" rel="noopener ugc nofollow" target="_blank">https://www.nvidia.com/en-us/about-nvidia/partners/</a></figcaption></figure><p id="a2ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi ju translated"><span class="l jv jw jx bm jy jz ka kb kc di"> M </span>机器学习和深度神经网络当进化时，CPU上的计算需要很长时间，甚至不可能按时完成。此后，GPU被引入这些，尽管它已经被用于游戏。要了解更多关于GPU及其监控的信息，可以快速浏览一下<a class="ae jt" rel="noopener" href="/@shachikaul35/crux-of-gpu-28fe7d37dd28">的博客</a>。</p><p id="9cac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">NVIDIA GPUs开始广泛用于许多机器学习和深度学习模型，然后需要监控和管理多GPU设置以获得其好处。好吧，那好消息！其中一个命令行实用工具“nvidia-smi”就是救星。我们来了解一下。</p><h1 id="239d" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak"> <em class="lb"> Nvidia-smi </em> </strong></h1><p id="33bd" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">有一个命令行实用工具Nvidia-smi ( <em class="lh">也叫NVSMI </em>)可以监控和管理NVIDIA GPUs，如Tesla、Quadro、GRID和GeForce。它与CUDA工具包一起安装，为您提供有意义的见解。</p><p id="fb66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是“nvidia-smi”命令行的输出。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/900118bf0be519aa799269ffc21ff28a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T3oo13vs9JdVWyR2qRvAYw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图1</figcaption></figure><p id="e782" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成两个表作为输出，其中第一个表反映了所有可用GPU的信息(上面的示例显示了1个GPU)。第二个表格告诉你使用GPU的进程。</p><p id="6865" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们一个一个来。</p><h1 id="afea" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">表一</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/c94c36f15c0fd653b827670b97888fcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uDXQY9_XZyw3exkg8JdL_Q.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图2</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lk"><img src="../Images/b64b34be21c2643dacc79c5aef3efd03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*BGNmZiEQy3uwdQxh3eKBmQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图3</figcaption></figure><p id="3a95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们深入了解一下。</p><p id="66d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh"> Temp: </em> </strong>核心GPU温度以摄氏度为单位。我们不需要担心它，因为它将由AWS数据中心控制，除了关心你的硬件。表格中显示的上述“44C”是正常的，但当它达到90+ C时，请拨打电话</p><p id="decb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh"> Perf: </em> </strong>表示GPU当前的性能状态。范围从P0到P12，分别指最大和最小性能。</p><p id="d8c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="lh">Persistence-M:</em></strong>Persistence模式标志的值，其中“On”表示NVIDIA驱动程序将保持加载状态(persist ),即使Nvidia-smi等活动客户端没有运行。这降低了CUDA程序等依赖应用程序的驱动程序加载延迟。</p><p id="35a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="lh">Pwr:Usage/Cap:</em></strong><em class="lh">是指</em>GPU当前的功耗占总功耗的比例。它的单位是瓦特。</p><p id="40ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh"> Bus-Id: </em> </strong> GPU的PCI总线Id为“domain:bus:device.function”，十六进制格式，用于过滤特定设备的统计信息。</p><p id="1e03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh">显示。</em> </strong> <em class="lh"> : </em> Display Active是一个标志，决定是否要在GPU设备上为显示分配内存，即初始化GPU上的显示。这里，“关闭”表示没有任何使用GPU设备的显示。</p><p id="81cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh">内存使用:</em> </strong>表示总内存中GPU上的内存分配。Tensorflow或Keras(TensorFlow后端)在启动时会自动分配整个内存，即使它不需要。因此，请浏览Keras上的<a class="ae jt" rel="noopener" href="/@shachikaul35/gpu-on-keras-and-tensorflow-357d629fb7e2"> GPU和Tensorflow </a>以了解更多有趣的信息。</p><p id="8b33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh">挥发不掉。ECC: </em> </strong> <em class="lh"> </em> ECC代表纠错码，通过定位和纠正传输错误来验证数据传输。NVIDIA GPUs提供ECC错误的错误计数。这里，易失性错误计数器检测自上次加载驱动程序以来的错误计数。</p><p id="b78b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh"> GPU-Util: </em> </strong>表示GPU利用率的百分比，即内核在采样周期内使用GPU的时间百分比。这里，周期可以在1到1/6秒之间。<em class="lh">例如</em>，上表中的输出显示时间为13%。在低百分比的情况下，如果代码花费时间从磁盘读取数据(小批量)，则GPU未得到充分利用。<br/>更详细参考:<a class="ae jt" href="https://docs.nvidia.com/deploy/nvml-api/structnvmlUtilization__t.html#structnvmlUtilization__t" rel="noopener ugc nofollow" target="_blank">https://docs . NVIDIA . com/deploy/nvml-API/structnvmlUtilization _ _ t . html # structnvmlUtilization _ _ t</a></p><p id="92f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh">计算M. </em> </strong>:特定GPU的计算模式是指每次重启后计算模式设置为默认的共享访问模式。“默认”值允许多个客户端同时访问CPU。</p><p id="759d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是GPU在进程中的应用。现在，让我们浏览一下第二个表格，它给出了使用GPU的每个进程的概念。</p><h1 id="6295" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">表二</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/80c72028795eb1ddfa941c63303e2166.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DVkG3_hJyjTXVePdzHoFaw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图4</figcaption></figure><p id="2425" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh"> GPU: </em> </strong>表示GPU索引，有利于多GPU设置。这决定了哪个进程使用哪个GPU。此索引代表设备的NVML索引。</p><p id="6301" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> PID: </strong>使用GPU通过进程ID引用进程。</p><p id="6acb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh">类型</em> </strong> <em class="lh"> : </em>是指“C”(计算)、“G”(图形)、“C+G”(计算和图形上下文)等进程的类型。</p><p id="a20f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh">流程名称:</em> </strong>不言自明</p><p id="9af7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> GPU内存使用:</strong>每个进程使用的特定GPU的内存。</p><p id="f8f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">其他指标和详细描述在Nvidia-smi手册页上。</em></p><p id="d00f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快乐阅读！</p><p id="434c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lh">可以通过</em></strong><a class="ae jt" href="https://www.linkedin.com/in/kaul-shachi" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="lh">LinkedIn</em></strong></a><strong class="ih hj"><em class="lh">与我联系。</em>T13】</strong></p></div></div>    
</body>
</html>