<html>
<head>
<title>Extracting Attributes from Image using Multi-Label classification based on Hypotheses-CNN-Pooling (HCP)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用基于假设的多标签分类从图像中提取属性-CNN-Pooling (HCP)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/extracting-attributes-from-image-using-multi-label-classification-based-on-hypotheses-cnn-pooling-e2f9ce80461?source=collection_archive---------3-----------------------#2019-12-13">https://medium.com/analytics-vidhya/extracting-attributes-from-image-using-multi-label-classification-based-on-hypotheses-cnn-pooling-e2f9ce80461?source=collection_archive---------3-----------------------#2019-12-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/77987b2ac6aabf48f2407fc76225b6cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*owZ3KJxUpIqSP2uM9zV1yw.png"/></div></figure><p id="bbe8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">简介:</strong></p><p id="03e3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从图像中自动提取属性在计算机视觉中是一项划时代的任务，因为它不仅需要精确预测对象，还需要精确预测它们的属性和活动。这可以看作是一个多标签分类问题，因为它需要从给定的图像中预测属性。在本文中，我们将使用Hypotheses-CNN-Pooling(HCP)网络来学习产生图像可能包含的每个属性的概率分数的属性，并将排名最高的属性作为预测属性。</p><p id="c75a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了简单起见，我们将使用“Flickr8K”数据集来构建“图像的属性提取模型”，以揭示图像的属性。</p><p id="408b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们开始吧！</p><p id="9542" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">进口包装:</strong></p><p id="f5fc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">本文中使用的核心包是NLTK和Tensorflow 2.0 Keras。除此之外，我们还使用Pandas、Numpy和Matplotlib进行数据处理和可视化。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jk"><img src="../Images/d3bc2c65328245c3f2ec347585ab8a38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6z22wU8sryvyEQiJPXlmBw.png"/></div></div></figure><p id="d86e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据理解:</strong></p><p id="c6e0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你可以从这里下载“Flickr8k”数据集<a class="ae jt" href="https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/" rel="noopener ugc nofollow" target="_blank">https://machinelingmastery . com/develop-a-deep-learning-caption-generation-model-in-python/</a>。</p><p id="484a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从下载的数据集中提取zip文件后，您会发现下面的文件夹。</p><ul class=""><li id="f50b" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated"><strong class="io hj"> Flickr8k_Dataset: </strong>总共包含了8092张JPEG格式的图片，形状大小不一。其中6000个用于训练，1000个用于验证，1000个用于测试数据集。</li><li id="e34a" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated"><strong class="io hj"> Flickr8k_text: </strong>包含描述train_set、test_set和dev_set的文本文件。<strong class="io hj"> Flickr8k.token.txt </strong>包含每张图片的5个标题，即总共40460个标题。</li></ul><p id="620c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据加载:</strong></p><p id="71fe" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，您从Flickr8k.token.txt文件中加载图像id和标题，并按如下方式准备数据集。</p><p id="3580" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">首先，我们加载包含用于训练、验证和测试数据集的图像id的文件，并分别准备图像id列表。下面定义了getImageList()函数，该函数返回给定数据集文件的图像id列表。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jk"><img src="../Images/222bb296902aa54286f1471325ad1172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cyvZKctkS5epO1xJnr1LMQ.png"/></div></div></figure><p id="e668" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，我们遍历图像描述列表。每个图像id都有一个唯一的标识符，每个标识符包含五个描述。我们将添加图像的完整路径，并将其存储在一个列表中。接下来，我们需要清理描述文本，如下面的预处理部分所示。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ki"><img src="../Images/f9c007c6cea86ef59c9478fac3ce5868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8bIATtp_t5grxO3w3090wA.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ki"><img src="../Images/69f033577f556a529865cef7a5e3842d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4CelcaCWP-wgHLFDsY6S5A.png"/></div></div></figure><p id="fd55" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据预处理:</strong></p><p id="7704" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们将描述中的所有单词转换成小写。然后我们从文本中删除所有的标点符号。最后，我们删除文本中出现的任何数字，并返回干净的描述文本。</p><p id="827c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一旦描述文本被清理，我们就可以应用描述文本的词干化和词汇化。现在让我们看一下词汇化和词干化过程。</p><ul class=""><li id="a9bb" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated"><strong class="io hj"><em class="kj"/></strong>:</li></ul><p id="e3b6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">词汇化是将单词简化为属于该语言的词根形式的过程。因为变元化返回语言的实际单词，所以在需要获得有效单词的地方使用变元化。我们使用Wordnet词条分类器，它使用Wordnet数据库来查找单词的词条。以确保它所属的词根正确，并过滤仅包含特定词类标签(如名词、ADJ、动词和副词)的单词。然后，我们将单词的相应词类标签以及描述文本提供给lemmatizer函数。</p><ul class=""><li id="3f66" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated"><strong class="io hj"> <em class="kj">词干</em> </strong>:</li></ul><p id="6df3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最后，一旦描述文本被词汇化，我们就在它上面应用词干来产生词干。我们使用雪球斯特梅尔，它有效地提供了后缀剥离器语法。</p><p id="a19d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">理想情况下，我们需要足够相关和紧凑的词汇表来表示属性列表。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kk"><img src="../Images/9e1034350f5cd03f5257a2b0748dff06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JORkYkAHpuzko-azZ5f_nQ.png"/></div></div></figure><p id="c3b9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们先睹为快处理过的数据集。结果数据集包含三列，如</p><ul class=""><li id="2dde" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated">image_name，表示带有完整文件路径的图像文件名</li><li id="e128" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">标题代表相应的描述文本(仅供参考)</li><li id="1e78" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">caption_lem表示来自描述的属性。</li></ul><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kl"><img src="../Images/3ad77c069f0d9d6599cc08849fe00332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oIMtDT4XA2Mmv9S4Qzi1WQ.png"/></div></div></figure><p id="29fa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">准备记号赋予器:</strong></p><p id="b2e9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因为给定语料库的属性词汇表很大，所以我们只使用训练数据集中前1000个最常见的属性。我们使用NLTK的FreqDist()函数来获取训练数据集中前1000个最常见的属性，并使用这些过滤后的属性来初始化标记器，以对文本进行编码并将其传递给模型。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es km"><img src="../Images/090c0930e7cbd64cc2beeff345eef49c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zlFQJuMpi4sBIL51oVhJug.png"/></div></div></figure><p id="34a4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">到目前为止，我们已经使用数据集中可用的描述文本提取了每个图像的属性。接下来，我们将看到如何处理图像，并用提取的属性训练深度学习模型。</p><p id="b88c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">模型构建:</strong></p><p id="7b91" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将使用Tensorflow-Keras中提供的用于图像处理的预训练<strong class="io hj"> Inception-V3 </strong>模型和基于<strong class="io hj">假设的<strong class="io hj">多标签分类</strong>-CNN-Pooling(HCP)</strong>网络来学习属性。</p><p id="0574" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">盗梦空间第三版:</strong></p><blockquote class="kn ko kp"><p id="fa10" class="im in kj io b ip iq ir is it iu iv iw kq iy iz ja kr jc jd je ks jg jh ji jj hb bi translated">“Inception-v3是一种广泛使用的图像识别模型，已被证明在ImageNet数据集上获得了超过78.1%的准确率。该模型是多年来多名研究人员开发的许多想法的结晶。它基于原始论文:<a class="ae jt" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank">“重新思考计算机视觉的初始架构”</a>，作者Szegedy等人。艾尔。该模型本身由对称和非对称构建块组成，包括卷积、平均池、最大池、连接、丢弃和完全连接层。Batchnorm在整个模型中广泛使用，并应用于激活输入。损失通过Softmax计算。”</p><p id="9de6" class="im in kj io b ip iq ir is it iu iv iw kq iy iz ja kr jc jd je ks jg jh ji jj hb bi translated">该模型的高级图表如下所示:</p></blockquote><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kt"><img src="../Images/22278d43c9813a996edf3d6e4e99ad98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nJ6IoHRvG_MSVIfxfRy2Ug.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx translated">资料来源:cloud.google.com</figcaption></figure><p id="313b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">假设-CNN-汇集(HCP) </strong></p><blockquote class="kn ko kp"><p id="7ec7" class="im in kj io b ip iq ir is it iu iv iw kq iy iz ja kr jc jd je ks jg jh ji jj hb bi translated">hypothesis-CNN-Pooling是一种灵活的深度CNN基础设施，其中任意数量的对象段假设被作为输入，然后共享的CNN与每个假设相连接，最后，来自不同假设的CNN输出结果通过max-pooling进行聚合，以产生最终的多标签预测。更多详细信息，请参考原论文:《<a class="ae jt" href="https://www.researchgate.net/publication/283323775_HCP_A_Flexible_CNN_Framework_for_Multi-label_Image_Classification" rel="noopener ugc nofollow" target="_blank">多标签图像分类的灵活CNN框架</a>》，作者:魏等。艾尔。</p></blockquote><p id="4560" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我们将介绍构建模型所涉及的步骤。</p><p id="8fe6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们可以修改Inception-V3模型来满足我们的需求。我们将删除softmax层，并附上下面的层。</p><ul class=""><li id="013d" class="ju jv hi io b ip iq it iu ix jw jb jx jf jy jj jz ka kb kc bi translated">0.5%的辍学层</li><li id="8af8" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">批量标准化</li><li id="da86" class="ju jv hi io b ip kd it ke ix kf jb kg jf kh jj jz ka kb kc bi translated">具有属性词汇大小单位的Sigmoid激活层</li></ul><p id="349e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">值得注意的是，对于多标签分类问题，我们使用“Sigmoid”作为输出层的激活函数，而不是“Softmax”函数，以便每个类别的概率将独立于其他类别概率，从而使用阈值(0.5)来获得多个标签作为结果，并使用“binary_crossentropy”作为损失函数来估计模型的损失。另一方面，对于多类分类问题，我们使用“Softmax”作为输出层的激活函数，使用“categorical _ crossentropy”作为模型的损失函数。</p><p id="c157" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">您可以尝试各种其他层、单元和激活功能的组合，以微调模型的性能。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ki"><img src="../Images/a5f67f7054fa6fbd3d12809c6d261cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pa60C1BRGbKaBHQzmK6gDg.png"/></div></div></figure><p id="306e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">准备数据生成器:</strong></p><p id="04d4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">既然我们已经构建并编译了模型，我们将继续准备数据生成器，将数据成批地输入到模型中。</p><p id="9a5b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">首先，我们从属性列表中获得编码的属性向量。下面定义了函数get _ attribute _ vector _ from _ caption()，该函数读取属性(caption_lem)并使用标记器的<em class="kj"> texts_to_matrix() </em>函数返回编码的属性向量。</p><p id="a860" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，我们使用tf.data.Dataset的from_tensor_slices()函数为训练和验证数据集准备数据生成器。下面定义了<em class="kj"> load_image_attribute() </em>函数，该函数使用TensorFlow图像模块的函数来加载和解码图像，并使用目标大小(299，299，3)来调整图像的大小。然后使用TensorFlow Keras inception_v3的preprocess_input函数，处理和准备图像张量以将其加载到预训练的Inception-V3模型中。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jk"><img src="../Images/b32224ecaf9f3d296e0a79bbd4295cd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yK536fKNHpN0vs9-GT8plA.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ki"><img src="../Images/c1c4c2f607f6a04ada5116989b79c660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8VDuFPkMU6u7tM5Vl--EQ.png"/></div></div></figure><p id="1306" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">模特培训:</strong></p><p id="e9a0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，让我们使用批大小为100的10个时期的训练和验证数据集来训练模型。为了训练模型，我们使用模型检查点回调来自动保存最佳模型的模型权重。然后，当连续5个时期的确认损失没有改善时，我们使用早期停止回调来停止模型训练，当连续2个时期的确认损失没有改善时，我们使用ReduceLROnPlateau回调来自动降低学习率。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ki"><img src="../Images/0208e82a297ca7dfdac431b3df67ece0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YcWhqMOjxiFumaHtmE67Uw.png"/></div></div></figure><p id="9796" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最后，我们绘制了每个时期模型的损失和准确性的结果。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kk"><img src="../Images/33555f8733a7b8357595ec3bca2715e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-fEX-7vy7r7sFbs6T_DYxw.png"/></div></div></figure><p id="bd1e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">模型预测:</strong></p><p id="51bf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在模型已经定型，我们将进行一些预测并评估结果。首先，我们使用<em class="kj"> load_image() </em>函数预处理并获取给定图像文件的图像张量。然后我们预测给定图像张量的属性。根据预测，我们考虑具有前10个概率的属性并打印结果。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es ky"><img src="../Images/70495803f6efdd64347688f236cfb7ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PTcy7eLbQeS1WEue3qTxOA.png"/></div></div></figure><p id="e6e8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们来看看预测的结果，用地面真实属性来评价。</p><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es kz"><img src="../Images/01f07bae2954a971493d5fde90fa9ef7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0jCAyIpeYg9-qEDKb3Cvgg.png"/></div></div></figure><figure class="jl jm jn jo fd ij er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es la"><img src="../Images/175ffea77e658bd3bcdd574034ebe209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a83Ob0SY6AxDcAqfbGgB-g.png"/></div></div></figure><p id="1773" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从上面的结果中，我们可以看到预测几乎是准确的，并且还可以从图像中预测更深入的属性。</p><p id="8da6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">概要:</strong></p><p id="fd59" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在本文中，我们发现了从图像中提取属性所涉及的步骤，以及如何使用图像标题数据集来构建基于假设-CNN-Pooling方法的多标签分类模型。具体来说，我们对图像描述文本进行了词法分析和词干分析，以获取属性。然后，我们定制了预训练的Inception-V3模型，并训练该模型来检测给定图像的属性。最后，我们看到了如何预测给定图像的属性并评估结果。</p><p id="f71c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这就把我们带到了本文的结尾。</p><p id="e4bf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">要获得完整的代码，你可以从<a class="ae jt" href="https://github.com/jsaikmr/Attribute_Extraction_for_Images_using_Hypotheses_CNN_Pooling" rel="noopener ugc nofollow" target="_blank">这里</a>下载ipython笔记本。</p><p id="b52f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">干杯！！！</p></div></div>    
</body>
</html>