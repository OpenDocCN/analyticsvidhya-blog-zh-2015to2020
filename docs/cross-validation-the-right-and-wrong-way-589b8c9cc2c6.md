# 交叉验证正确和错误的方式

> 原文：<https://medium.com/analytics-vidhya/cross-validation-the-right-and-wrong-way-589b8c9cc2c6?source=collection_archive---------1----------------------->

![](img/951b945bc4d5b1dedf89f5223d5e9b83.png)

米卡·鲍梅斯特在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

交叉验证是一种核心的机器学习技术，通常在在线数据科学入门课程中立即教授。这是有充分理由的，因为我们必须在真实数据上测试我们的模型，交叉验证比单个验证集单独测试更精确。然而，一个人可能会犯一个简单的错误，这个错误有时会被从业者忘记，我希望在这里快速地结束这个错误，这样你可以在将来避免它。

# 错误的方式

当应用一个模型时，通常有各种调谐选项可用，当然希望选择最小化一些误差特性的参数。一种方法是应用交叉验证并测试一组不同的调优参数，看哪一组给出最低的错误率。

你已经猜到了。这是错误的方式，但也仅仅是轻微的错误。这种方法的问题是，你要训练许多不同的模型，其中一些模型肯定会比其他模型做得更好，因此，通过选择性能最好的模型，并报告相应的错误率，你实际上是在选择最符合测试数据的模型。这种方法没有任何问题，因为这通常是人们为了选择最佳表现而拟合模型的方式。唯一缺少的部分是实际的测试部分，它应该用一个支持验证集或嵌套交叉验证来完成，以实际测试这个选择的模型执行得有多好。

对于包含大量要素和低 n 的数据，该问题变得尤为明显。基于与标注的相关性选择要素并不能保证真正的相关性，因为在许多不同要素之间进行选择时，选择过程必然会发现其中一些要素与标注相关。

假设我们有 5000000 个特征和 50 个样本。如果我们足够努力地寻找，这些特征中有一些与标签有很高的相关性，因此看起来像是很好的预测器。

因此，如果我们应用一些筛选程序，并基于标签选择有希望的特征，然后继续使用交叉验证来估计错误率，我们将能够获得非常低的错误率。问题是，筛选过程可以被认为是训练，因为我们是基于标签选择特征，并且应该执行单独的验证。

这个问题的另一个变体是使用交叉验证的模型调整。如果我们做了很多调整来改进一些评估指标，那么我们实际上是在评估过程中再次使用标签。

# 正确的方式

使用交叉验证选择功能，但使用保留验证集。首先使用交叉验证调整模型和功能选择，并对验证集执行最终评估。这样，实际的测试是在看不见的数据上进行的，而对误差的特征选择偏差只发生在数据集的交叉验证部分。

要点:保留一些数据用于最终验证，对剩下的数据做任何你想做的事情。

# 来自注释:建议的程序

对于第一个问题，通常建议使用 80/20 左右的值，因此 80%用于培训。

至于 2。问题，当你以这种方式训练你的模型时，你将丢失 20%数据中的任何信息。这就是能够实际测试你的模型的“代价”。但是，当所有的模型训练和选择完成后，您可以使用在整个数据集上找到的任何参数来保留模型。这样做时，您使用了所有的数据，在最终的模型中不会丢失任何信息。这些额外的数据有望改善你的模型，因为它不是基于更多的数据。

具体来说，工作流程如下所示:

1.  去掉 20%进行验证。
2.  对剩余的 80%进行交叉验证，以选择最佳参数或类似参数。
3.  用所有 80%的数据和最佳参数训练模型。
4.  在 20%验证集上测试模型，您可能会看到性能下降。
5.  如果对结果满意，则在 100%的数据上重新训练模型，并部署模型以供使用。