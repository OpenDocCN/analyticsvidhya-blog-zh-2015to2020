<html>
<head>
<title>Principle Component Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主成分分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/principle-component-analysis-a16e05003c50?source=collection_archive---------15-----------------------#2020-08-13">https://medium.com/analytics-vidhya/principle-component-analysis-a16e05003c50?source=collection_archive---------15-----------------------#2020-08-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="db88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">主要用于特征空间的降维，在不损失信息的情况下增加可解释性，这是通过创建一个新的不相关变量来实现的，以便强调方差并从中带来强模式。PCA 甚至在 3 维或更多维的情况下工作得更好。</p><p id="9eaa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">步骤</p><ol class=""><li id="56e3" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated">用 x 轴和 y 轴绘制图表</li></ol><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es jv"><img src="../Images/a82457d6bfa0278c3e8bfb5b5aa68197.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qqg_PgOJFUaQ1WpXec56-w.png"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated"><a class="ae kl" href="https://www.youtube.com/watch?v=FgakZw6K1QQ" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="cb1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.通过使用以下公式，找到平均值或中点，并使数据以原点为中心</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es km"><img src="../Images/bdb828821f57ef92f81a5fe117dbf843.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*BZiA6LrcSgb1cYLlzGKDJw.gif"/></div></div></figure><p id="9dcc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">T5】x = x—T7】</strong></p><p id="200d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中= x 的平均值</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es ko"><img src="../Images/3bc73ded23314d0870e73fbb0067404a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*YzeNv6ruK7IvKnxo9Fdtzg.png"/></div></figure><p id="90af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.开始拟合一条随机穿过原点的线，并旋转这条线，直到我们得到最佳拟合数据的最佳线。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es kp"><img src="../Images/51a2524183775a4fa06c432b096042ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*a016LX8_wNQBCgOwufAlRQ.gif"/></div></figure><p id="55ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以通过两种方式实现:</p><p id="2578" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a.通过找到从投影到直线的标记到实际点的最小距离</p><p id="0917" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b.通过最大化从标记投影到原点(0，0)的距离</p><p id="de5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.距离平方和最大的最后一条线称为主成分 1。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es kq"><img src="../Images/dd5185354146c2b6f6f12817097670cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*sL13bV5uJ_J46U_HVkntBw.png"/></div></figure><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es kr"><img src="../Images/b1a7239c6c3dd385d58e6462161ee6bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*7jfbPgl6Ctaq4WMTE20IdQ.png"/></div></figure><p id="0532" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从这条线，我们可以做统计分析，比如说，x 增加 4 个单位，我们得到 y 增加 4 个单位。</p><p id="5caf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.类似地，画一条与 PC1 线垂直的线，但找到与 PC1 相似的最佳距离</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es ks"><img src="../Images/8af2be0987ebfc81ccd069b798faa57f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*O2KwId2vy5qhQeEdQVDXSg.png"/></div></figure><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es kt"><img src="../Images/633c47f6b7111946aa4f733587e1e78a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*Y4MlSiOkTUAEU9TWK7stJw.png"/></div></figure><p id="7ea4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，最终的 PC1 和 PC2 线如下所示</p><p id="f924" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.下一步我们只需要旋转两条线</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es ku"><img src="../Images/4bd5834b399bbb93be6fa1aa78b4d4d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*eG_k59AxwxNNhxqYio2pGw.png"/></div></figure><p id="f306" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.最后一步是从线中投影点以绘制点</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kv"><img src="../Images/cba99895a3b9c71f5d2625bf631cda54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z8fJWMIIVjyfg4qAxh-XAQ.png"/></div></div></figure><p id="662c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要对所有样本进行同样的操作，以获得最终结果。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es kw"><img src="../Images/d762838bea886ed22a7468e77d3dff7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*bAy0TR3oFEhOChqbX9lQYg.png"/></div></figure><blockquote class="kx"><p id="6bf5" class="ky kz hi bd la lb lc ld le lf lg jc dx translated">使用奇异值分解进行主成分分析。</p></blockquote><blockquote class="lh li lj"><p id="c0ef" class="if ig kn ih b ii lk ik il im ll io ip lm ln is it lo lp iw ix lq lr ja jb jc hb bi translated">PC 的方差可通过以下方式获得:<br/>PC(I)的变化量= SS(σ(每个点和原点之间的距离))<br/>其中 SS-平方和<br/>总方差=σPC(I)<br/>求变化的比例:PC(I)/总方差</p></blockquote><p id="b0d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于独立变量的 N 个变量，遵循类似的步骤，以二维的观点来分析它。</p></div><div class="ab cl ls lt gp lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="hb hc hd he hf"><p id="466f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">一个优势</p><ul class=""><li id="aa41" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc lz js jt ju bi translated">与其他技术相比，信息损失将非常少</li><li id="6a35" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated">在主成分分析的帮助下，我们可以组合 N 个特征</li><li id="115f" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated">评估变得容易</li><li id="377b" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated">可以将特征选择与 PCA 组件相结合</li><li id="c5e6" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated">可以使用屏幕图来分析变化</li></ul></div><div class="ab cl ls lt gp lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="hb hc hd he hf"><p id="3106" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di"> D </span>是——优势</p><ul class=""><li id="24b8" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc lz js jt ju bi translated">这个过程理解起来有点复杂</li><li id="a5da" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated">寻找最佳的 PC1 和 PC2 更具挑战性</li></ul></div><div class="ab cl ls lt gp lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="hb hc hd he hf"><p id="551a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated"><span class="l je jf jg bm jh ji jj jk jl di">一种</span>替代方法</p><ol class=""><li id="8d63" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated">特征消除:这是一个用来从模型中消除无关紧要的变量的过程，以使模型不那么复杂，更容易解释</li><li id="c592" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc jr js jt ju bi translated">特征提取:这是一个过程，主要用于组合和/或选择我们希望进入特征空间的变量，使模型更容易执行。</li></ol></div><div class="ab cl ls lt gp lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="hb hc hd he hf"><p id="d803" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">参考文献:</p><ul class=""><li id="e959" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc lz js jt ju bi translated"><a class="ae kl" href="https://youtu.be/FgakZw6K1QQ" rel="noopener ugc nofollow" target="_blank">https://youtu.be/FgakZw6K1QQ</a></li><li id="5a1f" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated"><a class="ae kl" href="https://towardsdatascience.com/getting-data-ready-for-modelling-feature-engineering-feature-selection-dimension-reduction-39dfa267b95a" rel="noopener" target="_blank">https://towards data science . com/getting-data-ready-for-modeling-feature-engineering-feature-selection-dimension-reduction-39 DFA 267 b95a</a></li><li id="a495" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated">【https://setosa.io/ev/principal-component-analysis/ T4】</li><li id="ed24" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated"><a class="ae kl" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Principal_component_analysis</a></li><li id="3e36" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated"><a class="ae kl" href="https://deepai.org/machine-learning-glossary-and-terms/feature-extraction#:~:text=Feature%20extraction%20is%20the%20name,describing%20the%20original%20data%20set." rel="noopener ugc nofollow" target="_blank">https://deepai . org/machine-learning-glossary-and-terms/Feature-extraction #:~:text = Feature % 20 extraction % 20 is % 20 the % 20 name，描述%20original%20data%20set。</a></li><li id="6a66" class="jm jn hi ih b ii ma im mb iq mc iu md iy me jc lz js jt ju bi translated"><a class="ae kl" href="https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html#:~:text=Recursive%20feature%20elimination%20(RFE)%20is,number%20of%20features%20is%20reached.&amp;text=RFE%20requires%20a%20specified%20number,how%20many%20features%20are%20valid." rel="noopener ugc nofollow" target="_blank">https://www . sci kit-Yb . org/en/latest/API/model _ selection/RF ecv . html #:~:text = Recursive % 20 feature % 20 elimination % 20(RFE)% 20is，number % 20of % 20features % 20is %已达到。&amp;text = RFE % 20 需要% 20a %指定% 20 数量，多少% 20 功能% 20 有效。</a></li></ul></div></div>    
</body>
</html>