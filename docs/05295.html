<html>
<head>
<title>Video Classification Based On Action (from scratch &amp; without GPU support)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于动作的视频分类(从头开始，无需GPU支持)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/video-classification-based-on-action-without-gpu-f96ec9555197?source=collection_archive---------19-----------------------#2020-04-16">https://medium.com/analytics-vidhya/video-classification-based-on-action-without-gpu-f96ec9555197?source=collection_archive---------19-----------------------#2020-04-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c02b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">没有GPU！！没有外部重数据集！！阅读以学习和实现在任何机器上基于时间动作的基本视频分类技术。</p><p id="4a5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我将创建自己的视频数据，其中，一个矩形在不同的方向移动。示例代码(使用<strong class="ih hj"> Jupyter笔记本</strong>)如下:</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="fcbc" class="jm jn hi ji b fi jo jp l jq jr">import numpy as np<br/>import skvideo.io as sk</span><span id="ff26" class="jm jn hi ji b fi js jp l jq jr"># creating sample video data<br/>num_vids = 5<br/>num_imgs = 100<br/>img_size = 50<br/>min_object_size = 1<br/>max_object_size = 5<br/> <br/>for i_vid in range(num_vids):<br/> imgs = np.zeros((num_imgs, img_size, img_size)) # set background to 0<br/> vid_name = ‘vid’ + str(i_vid) + ‘.mp4’<br/> w, h = np.random.randint(min_object_size, max_object_size, size=2)<br/> x = np.random.randint(0, img_size — w)<br/> y = np.random.randint(0, img_size — h)<br/> i_img = 0<br/> while x&gt;0:<br/> imgs[i_img, y:y+h, x:x+w] = 255 # set rectangle as foreground<br/> x = x-1<br/> i_img = i_img+1<br/> sk.vwrite(vid_name, imgs.astype(np.uint8))</span><span id="b588" class="jm jn hi ji b fi js jp l jq jr"># play a video<br/>from IPython.display import Video<br/>Video(“vid3.mp4”) # the script &amp; video should be in same folder</span></pre><p id="9f34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我将创建4个不同类型的视频，其中，一个矩形在4个方向移动:左，右，上，下。因此，将有4个类，我将通过深度学习基于这些视频数据进行分类。浏览下面的代码(用<strong class="ih hj"> Jupyter笔记本</strong>中的<strong class="ih hj"> python 3.6.9，keras 2 . 2 . 4</strong>)；肯定看评论。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="46bd" class="jm jn hi ji b fi jo jp l jq jr">import numpy as np</span><span id="55e2" class="jm jn hi ji b fi js jp l jq jr"><strong class="ji hj"># preparing dataset</strong><br/>X_train = []<br/>Y_train = []<br/>labels = enumerate([‘left’, ‘right’, ‘up’, ‘down’]) #4 classes</span><span id="b612" class="jm jn hi ji b fi js jp l jq jr">num_vids = 30<br/>num_imgs = 30<br/>img_size = 20<br/>min_object_size = 1<br/>max_object_size = 5</span><span id="10ef" class="jm jn hi ji b fi js jp l jq jr"># video frames with left moving object<br/>for i_vid in range(num_vids):<br/> imgs = np.zeros((num_imgs, img_size, img_size)) # set background to 0<br/> #vid_name = ‘vid’ + str(i_vid) + ‘.mp4’<br/> w, h = np.random.randint(min_object_size, max_object_size, size=2)<br/> x = np.random.randint(0, img_size — w)<br/> y = np.random.randint(0, img_size — h)<br/> i_img = 0<br/> while x&gt;0:<br/> imgs[i_img, y:y+h, x:x+w] = 255 # set rectangle as foreground<br/> x = x-1<br/> i_img = i_img+1<br/> X_train.append(imgs)<br/>for i in range(0,num_imgs):<br/> Y_train.append(0)</span><span id="24fb" class="jm jn hi ji b fi js jp l jq jr"># video frames with right moving object<br/>for i_vid in range(num_vids):<br/> imgs = np.zeros((num_imgs, img_size, img_size)) # set background to 0<br/> #vid_name = ‘vid’ + str(i_vid) + ‘.mp4’<br/> w, h = np.random.randint(min_object_size, max_object_size, size=2)<br/> x = np.random.randint(0, img_size — w)<br/> y = np.random.randint(0, img_size — h)<br/> i_img = 0<br/> while x&lt;img_size:<br/> imgs[i_img, y:y+h, x:x+w] = 255 # set rectangle as foreground<br/> x = x+1<br/> i_img = i_img+1<br/> X_train.append(imgs)<br/>for i in range(0,num_imgs):<br/> Y_train.append(1)</span><span id="ad1b" class="jm jn hi ji b fi js jp l jq jr"># video frames with up moving object<br/>for i_vid in range(num_vids):<br/> imgs = np.zeros((num_imgs, img_size, img_size)) # set background to 0<br/> #vid_name = ‘vid’ + str(i_vid) + ‘.mp4’<br/> w, h = np.random.randint(min_object_size, max_object_size, size=2)<br/> x = np.random.randint(0, img_size — w)<br/> y = np.random.randint(0, img_size — h)<br/> i_img = 0<br/> while y&gt;0:<br/> imgs[i_img, y:y+h, x:x+w] = 255 # set rectangle as foreground<br/> y = y-1<br/> i_img = i_img+1<br/> X_train.append(imgs)<br/>for i in range(0,num_imgs):<br/> Y_train.append(2)<br/> <br/># video frames with down moving object<br/>for i_vid in range(num_vids):<br/> imgs = np.zeros((num_imgs, img_size, img_size)) # set background to 0<br/> #vid_name = ‘vid’ + str(i_vid) + ‘.mp4’<br/> w, h = np.random.randint(min_object_size, max_object_size, size=2)<br/> x = np.random.randint(0, img_size — w)<br/> y = np.random.randint(0, img_size — h)<br/> i_img = 0<br/> while y&lt;img_size:<br/> imgs[i_img, y:y+h, x:x+w] = 255 # set rectangle as foreground<br/> y = y+1<br/> i_img = i_img+1<br/> X_train.append(imgs)<br/>for i in range(0,num_imgs):<br/> Y_train.append(3)</span><span id="72d4" class="jm jn hi ji b fi js jp l jq jr"># data pre-processing<br/>from keras.utils import np_utils<br/>X_train=np.array(X_train, dtype=np.float32) /255<br/>X_train=X_train.reshape(X_train.shape[0], num_imgs, img_size, img_size, 1)<br/>print(X_train.shape)<br/>Y_train=np.array(Y_train, dtype=np.uint8)<br/>Y_train = Y_train.reshape(X_train.shape[0], 1)<br/>print(Y_train.shape)<br/>Y_train = np_utils.to_categorical(Y_train, 4)</span></pre><blockquote class="jt ju jv"><p id="57c9" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">(120，30，20，20，1) <br/> (120，1)</p></blockquote><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="8b57" class="jm jn hi ji b fi jo jp l jq jr"><strong class="ji hj"># building model</strong><br/>from keras.models import Sequential<br/>from keras.layers import Dense, Conv2D, Flatten, Dropout<br/>from keras.layers.pooling import MaxPooling2D<br/>from keras.layers.recurrent import LSTM<br/>from keras.layers.wrappers import TimeDistributed</span><span id="4fd1" class="jm jn hi ji b fi js jp l jq jr">model = Sequential()<br/># TimeDistributed layer is to pass temporal information to the n/w<br/>model.add(TimeDistributed(Conv2D(8, (3, 3), strides=(1, 1), activation=’relu’, padding=’same’), input_shape=(num_imgs, img_size, img_size, 1)))<br/>model.add(TimeDistributed(Conv2D(8, (3,3), kernel_initializer=”he_normal”, activation=’relu’)))<br/>model.add(TimeDistributed(MaxPooling2D((1, 1), strides=(1, 1))))<br/>model.add(TimeDistributed(Flatten()))<br/>model.add(Dropout(0.3))<br/>model.add(LSTM(64, return_sequences=False, dropout=0.3))<br/>model.add(Dense(4, activation=’softmax’))<br/>model.compile(optimizer=’adam’, loss=’categorical_crossentropy’, metrics=[‘accuracy’])<br/>model.summary()</span><span id="2122" class="jm jn hi ji b fi js jp l jq jr"><strong class="ji hj"># model training</strong><br/>model.fit(X_train, Y_train, nb_epoch=50, verbose=1)</span><span id="42f9" class="jm jn hi ji b fi js jp l jq jr"><strong class="ji hj"># model testing with new data (4 videos)</strong><br/>X_test=[]<br/>Y_test=[]<br/>for i_vid in range(2):<br/> imgs = np.zeros((num_imgs, img_size, img_size)) # set background to 0<br/> w, h = np.random.randint(min_object_size, max_object_size, size=2)<br/> x = np.random.randint(0, img_size — w)<br/> y = np.random.randint(0, img_size — h)<br/> i_img = 0<br/> while x&lt;img_size:<br/> imgs[i_img, y:y+h, x:x+w] = 255 # set rectangle as foreground<br/> x = x+1<br/> i_img = i_img+1<br/> X_test.append(imgs)<br/># 2nd class — ‘right’</span><span id="4bc4" class="jm jn hi ji b fi js jp l jq jr">for i_vid in range(2):<br/> imgs = np.zeros((num_imgs, img_size, img_size)) # set background to 0<br/> w, h = np.random.randint(min_object_size, max_object_size, size=2)<br/> x = np.random.randint(0, img_size — w)<br/> y = np.random.randint(0, img_size — h)<br/> i_img = 0<br/> while y&lt;img_size:<br/> imgs[i_img, y:y+h, x:x+w] = 255 # set rectangle as foreground<br/> y = y+1<br/> i_img = i_img+1<br/> X_test.append(imgs)<br/># 4th class — ‘down’</span><span id="5235" class="jm jn hi ji b fi js jp l jq jr">X_test=np.array(X_test, dtype=np.float32) /255<br/>X_test=X_test.reshape(X_test.shape[0], num_imgs, img_size, img_size, 1)</span><span id="a627" class="jm jn hi ji b fi js jp l jq jr">pred=model.predict_classes(X_test)<br/>pred</span></pre><blockquote class="jt ju jv"><p id="3727" class="if ig jw ih b ii ij ik il im in io ip jx ir is it jy iv iw ix jz iz ja jb jc hb bi translated">数组([1，1，3，3]，dtype=int64)</p></blockquote><p id="b221" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，4个测试视频被正确分类。</p></div><div class="ab cl ka kb gp kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="hb hc hd he hf"><p id="15ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢阅读。也在这里浏览我的第一篇相关文章<a class="ae kh" rel="noopener" href="/tvs-motors-technology-blog/learning-cnn-using-simple-keras-python-programs-7be7b9efa852"/>。</p></div></div>    
</body>
</html>