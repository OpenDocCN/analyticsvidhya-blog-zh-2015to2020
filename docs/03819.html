<html>
<head>
<title>Why Linear Regression does not work for classification-Part II?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么线性回归不适用于分类-第二部分？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/why-linear-regression-does-not-work-for-classification-part-ii-82937927d301?source=collection_archive---------13-----------------------#2020-02-20">https://medium.com/analytics-vidhya/why-linear-regression-does-not-work-for-classification-part-ii-82937927d301?source=collection_archive---------13-----------------------#2020-02-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f97f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">完成分析。</em></p><p id="e2d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">我建议你在继续之前先检查一下第一部分</em><a class="ae je" rel="noopener" href="/@ka1shi/why-linear-regression-does-not-work-for-classification-part-i-97b04cab36d9"><strong class="ih hj"><em class="jd"/></strong><em class="jd"/></a><em class="jd">。</em></p><p id="f2a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">在第一部分中，我们检查了线性回归是否适用于超过2类的定性响应变量。在这里，我们将检查它是否适用于二元分类？</em></p><p id="439c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这次我们将使用<a class="ae je" href="https://www.kaggle.com/merishnasuwal/breast-cancer-prediction-dataset" rel="noopener ugc nofollow" target="_blank">乳腺癌预测数据集</a>。为了简单起见，我只考虑了肿瘤的平均周长作为数据中的唯一特征。</p><p id="4653" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基于平均周长大小，我们将通过线性回归确定肿瘤是良性的(非癌性的)还是恶性的(癌性的)。</p><p id="4cdf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的数据看起来像这样:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jf"><img src="../Images/4db43171b12549bd9dd98bc48b7355dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*G32sYXb2lveR5iivQqSmVw.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">乳腺癌数据分布(B代表良性肿瘤，M代表恶性肿瘤)</figcaption></figure><p id="10ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了处理线性回归，让我们假设B和M的编码分别为0和1。</p><p id="4df1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们对此进行线性回归:</p><p id="0d97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae je" href="https://github.com/ka1shi-medium/Linear-Regression-on-Cancer-data" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">代号</strong> </a>。</p><pre class="jg jh ji jj fd jr js jt ju aw jv bi"><span id="49ad" class="jw jx hi js b fi jy jz l ka kb">coefficient: [0.01291051]<br/>Intercept: -0.9710559009446079<br/>MSE:  0.03373167568329971<br/>R2_score: 0.747858980220586</span></pre><p id="4b04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们选择另一种可能的编码，即B为1，M为0，然后重新运行代码。</p><pre class="jg jh ji jj fd jr js jt ju aw jv bi"><span id="de2d" class="jw jx hi js b fi jy jz l ka kb">coefficient: [-0.01291051]<br/>Intercept: 1.9710559009446085<br/>MSE:  0.03373167568329972<br/>R2_score: 0.747858980220586</span></pre><p id="ffd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">两种编码的均方误差和R平方值完全相同。甚至系数都是相同的，只有符号不同。</p><p id="e39e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们绘制两种编码的假设h(x ):</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es kc"><img src="../Images/7ca060a93050d3e97899e466406db685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cl1BLwL5PacCu6KBsQAI0Q.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">二元分类的线性回归(左表示B为0，M为1，右表示B为1，M为0)</figcaption></figure><h2 id="3ce8" class="jw jx hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">所以在编码方面没有问题，就像我们在超过2个类别的<a class="ae je" rel="noopener" href="/@ka1shi/why-linear-regression-does-not-work-for-classification-part-i-97b04cab36d9">分类中遇到的那样</a>。我们可以假设其中任何一个，我们会得到相同的结果。</h2><p id="c479" class="pw-post-body-paragraph if ig hi ih b ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc hb bi translated">为了对任何给定的肿瘤大小x进行预测，如果h(x)大于0.5，我们预测恶性肿瘤，否则，我们预测良性肿瘤，特别是对于B为0且M为1的情况。</p><p id="8ef8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是我们得到的结果:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lf"><img src="../Images/7951d157ebcb6ad57680ad888e6bd2de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*fqrHaGyptXxwVZRaQSvrQA.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">使用第一个编码通过线性回归得出的实际和预测结果(红圈表示实际结果与预测结果不同的点)</figcaption></figure><p id="a983" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看起来我们已经正确地预测了每一个数据点，除了一个，但是现在让我们稍微改变一下数据。</p><p id="b755" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们添加另一个具有巨大肿瘤大小的样本，并再次运行线性回归:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lg"><img src="../Images/a195be89726b27e348c9db76b729303d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*RO3Qrw0LsbfScWtTd9NhZQ.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">二元分类的线性回归(左边代表实际数据，右边代表带有一些异常值的实际数据)</figcaption></figure><p id="dc6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在h(x)&gt;0.5是恶性的会看起来像这样:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lf"><img src="../Images/686bda3770ddff563fb2c805fc275a36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*kld2Un0vMX_0hLZNoLOVOQ.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">阈值为0.5的二元分类线性回归(左侧代表实际数据，右侧代表带有一些异常值的实际数据)</figcaption></figure><p id="7b10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了继续做出正确的预测，我们需要将它改为h(x)&gt;0.3，但这不是算法应该工作的方式。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lh"><img src="../Images/48a9e045d8c463f9b99de48fbe198a2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*ScF23R-UrIWDzANlTmYQyw.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">阈值为0.3的带有异常值的新数据的二元分类的线性回归</figcaption></figure><p id="6f20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们不能在每次数据更新时都改变假设。相反，假设应该从训练数据中学习它，然后对它以前没有见过的数据做出正确的预测。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h1 id="4fa5" class="lp jx hi bd kh lq lr ls kl lt lu lv kp lw lx ly ks lz ma mb kv mc md me ky mf bi translated">结论</h1><p id="666a" class="pw-post-body-paragraph if ig hi ih b ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc hb bi translated">综上所述，线性回归也不适合二元分类。</p><p id="4a14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过施加判定规则，例如当假设h(x)&gt;0.5时，则肿瘤是恶性的，可以将它用作二元分类器。但这也不是对所有情况都适用。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h2 id="829b" class="jw jx hi bd kh ki kj kk kl km kn ko kp iq kq kr ks iu kt ku kv iy kw kx ky kz bi translated">参考资料:</h2><p id="25aa" class="pw-post-body-paragraph if ig hi ih b ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc hb bi translated"><a class="ae je" href="https://faculty.marshall.usc.edu/gareth-james/ISL/" rel="noopener ugc nofollow" target="_blank">统计学习简介</a></p><p id="2b2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae je" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>吴恩达著</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><p id="5b75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完整的代码，请查看这个<a class="ae je" href="https://github.com/ka1shi-medium/Linear-Regression-on-Cancer-data" rel="noopener ugc nofollow" target="_blank"> GitHub </a>链接。</p><p id="24df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请对任何类型的建议、纠正或批评进行评论。</p><p id="ea72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢大家！</p></div></div>    
</body>
</html>