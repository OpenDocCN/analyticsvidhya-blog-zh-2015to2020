<html>
<head>
<title>Understanding Multiple Linear Regression.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解多元线性回归。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-multiple-linear-regression-e5cc68bef652?source=collection_archive---------10-----------------------#2020-09-08">https://medium.com/analytics-vidhya/understanding-multiple-linear-regression-e5cc68bef652?source=collection_archive---------10-----------------------#2020-09-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b384" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">多元线性回归中的术语“<strong class="ih hj">多重</strong>”表示两个或多个独立输入变量与一个响应变量之间的关系。</p><p id="8494" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当一个变量不足以创建好的模型并做出准确的预测时，就需要多元线性回归。</p><p id="10a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从一个住房数据集开始理解它…</p><h1 id="6d3b" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">问题陈述。</h1><p id="57f6" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">假设一家房地产公司有一个包含德里地区房产价格的数据集。它希望利用这些数据，根据面积、卧室、停车场等重要因素，优化房产的销售价格。</p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><p id="232c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">本质上，公司想要— </em> </strong></p><ul class=""><li id="9145" class="ko kp hi ih b ii ij im in iq kq iu kr iy ks jc kt ku kv kw bi translated">确定影响房价的变量，如面积、房间数量、浴室等。</li><li id="f6b2" class="ko kp hi ih b ii kx im ky iq kz iu la iy lb jc kt ku kv kw bi translated">创建一个线性模型，将房价与房间数量、面积、浴室数量等变量定量联系起来。</li><li id="113f" class="ko kp hi ih b ii kx im ky iq kz iu la iy lb jc kt ku kv kw bi translated">了解模型的准确性，即这些变量对房价的预测能力。</li></ul><p id="b445" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">我们开始编码吧……..</em>T15】</strong></p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="e87d" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">步骤1:阅读和理解数据</h1><p id="5103" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">让我们首先导入NumPy和Pandas并读取住房数据集。</p><p id="fddd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">导入所需的库</em> </strong></p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="acf5" class="lq je hi lm b fi lr ls l lt lu"># importing required libraries</span><span id="3093" class="lq je hi lm b fi lv ls l lt lu">import numpy as np<br/>import pandas as pd</span></pre><p id="d276" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">读取数据集</em> </strong></p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="b41b" class="lq je hi lm b fi lr ls l lt lu">housing = pd.read_csv("Housing.csv")</span></pre><p id="4d4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">显示数据集</em> </strong></p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="1fa9" class="lq je hi lm b fi lr ls l lt lu"># Check the head of the dataset<br/>housing.head()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es lw"><img src="../Images/729fe20f8430f5ed8332c04c90b6431b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uW_PNMeRPJ1RjV-GjXKVhA.png"/></div></div></figure></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="e93a" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">步骤2:可视化数据</h1><p id="9786" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">现在让我们花一些时间来做可以说是最重要的一步——理解数据。</p><ul class=""><li id="bcaf" class="ko kp hi ih b ii ij im in iq kq iu kr iy ks jc kt ku kv kw bi translated">如果存在明显的多重共线性，这是发现它的第一个地方</li><li id="2329" class="ko kp hi ih b ii kx im ky iq kz iu la iy lb jc kt ku kv kw bi translated">在这里，您还可以确定一些预测因素是否与结果变量直接相关</li></ul><p id="19e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用<code class="du me mf mg lm b">matplotlib</code>和<code class="du me mf mg lm b">seaborn</code>来可视化我们的数据。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="48ea" class="lq je hi lm b fi lr ls l lt lu">import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><h2 id="e0cf" class="lq je hi bd jf mh mi mj jj mk ml mm jn iq mn mo jr iu mp mq jv iy mr ms jz mt bi translated">可视化数字变量</h2><p id="958b" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">让我们做一个所有数字变量的配对图。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="da2e" class="lq je hi lm b fi lr ls l lt lu">sns.pairplot(housing)<br/>plt.show()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mu"><img src="../Images/7642f2c61dd519c6f27662d783ceddb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aOWf1YbM55C5fpwINpss9A.png"/></div></div><figcaption class="mv mw et er es mx my bd b be z dx translated">数值变量的配对图。</figcaption></figure><h2 id="1e17" class="lq je hi bd jf mh mi mj jj mk ml mm jn iq mn mo jr iu mp mq jv iy mr ms jz mt bi translated">可视化分类变量</h2><p id="420c" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">您可能已经注意到，还有一些分类变量。让我们为这些变量做一个箱线图。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="dee1" class="lq je hi lm b fi lr ls l lt lu">plt.figure(figsize=(20, 12))<br/>plt.subplot(2,3,1)<br/>sns.boxplot(x = 'mainroad', y = 'price', data = housing)<br/>plt.subplot(2,3,2)<br/>sns.boxplot(x = 'guestroom', y = 'price', data = housing)<br/>plt.subplot(2,3,3)<br/>sns.boxplot(x = 'basement', y = 'price', data = housing)<br/>plt.subplot(2,3,4)<br/>sns.boxplot(x = 'hotwaterheating', y = 'price', data = housing)<br/>plt.subplot(2,3,5)<br/>sns.boxplot(x = 'airconditioning', y = 'price', data = housing)<br/>plt.subplot(2,3,6)<br/>sns.boxplot(x = 'furnishingstatus', y = 'price', data = housing)<br/>plt.show()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mz"><img src="../Images/3ad4f7959ba6e6d0602b5dbab42ff1ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lBvxAOj3KtC6HEgfJRHgGA.png"/></div></div><figcaption class="mv mw et er es mx my bd b be z dx translated">各种分类变量的箱线图</figcaption></figure><p id="bf8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们也可以通过使用<code class="du me mf mg lm b">hue</code>论证来平行地想象这些分类特征。下面是以<code class="du me mf mg lm b">airconditioning</code>为色调的<code class="du me mf mg lm b">furnishingstatus</code>的剧情。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="98a4" class="lq je hi lm b fi lr ls l lt lu">plt.figure(figsize = (10, 5))<br/>sns.boxplot(x = 'furnishingstatus', y = 'price', hue=airconditioning', data = housing)<br/>plt.show()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es na"><img src="../Images/a1687bf339011f804a80292abdd55ba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z163Q8fYZas2gzXpGCAruw.png"/></div></div></figure></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="c1da" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">第三步:数据准备</h1><ul class=""><li id="0eeb" class="ko kp hi ih b ii kb im kc iq nb iu nc iy nd jc kt ku kv kw bi translated">您可以看到我们的数据集有许多值为“是”或“否”的列。</li><li id="7ef1" class="ko kp hi ih b ii kx im ky iq kz iu la iy lb jc kt ku kv kw bi translated">但是为了拟合回归线，我们需要数值而不是字符串。因此，我们需要将它们转换成1和0，其中1表示“是”，0表示“否”。</li></ul><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="50f4" class="lq je hi lm b fi lr ls l lt lu"># List of variables to map</span><span id="3c6e" class="lq je hi lm b fi lv ls l lt lu">varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']</span><span id="8430" class="lq je hi lm b fi lv ls l lt lu"># Defining the map function<br/>def binary_map(x):<br/>    return x.map({'yes': 1, "no": 0})</span><span id="ca01" class="lq je hi lm b fi lv ls l lt lu"># Applying the function to the housing list<br/>housing[varlist] = housing[varlist].apply(binary_map)</span><span id="dc44" class="lq je hi lm b fi lv ls l lt lu"># Check the housing dataframe now</span><span id="98ae" class="lq je hi lm b fi lv ls l lt lu">housing.head()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es ne"><img src="../Images/ec39e9b3464140a0af85549560d50cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T8pbksPaXo_tF9gnn-WauQ.png"/></div></div></figure><h1 id="8b95" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">虚拟变量</h1><p id="aeda" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">变量<code class="du me mf mg lm b">furnishingstatus</code>有三个级别。我们还需要将这些级别转换成整数。</p><p id="1e39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们将使用一个叫做<code class="du me mf mg lm b">dummy variables</code>的东西。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="0e3e" class="lq je hi lm b fi lr ls l lt lu"># Get the dummy variables for the feature 'furnishingstatus' and store it in a new variable - 'status'</span><span id="0764" class="lq je hi lm b fi lv ls l lt lu">status = pd.get_dummies(housing['furnishingstatus'])</span></pre><p id="c2e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们为变量“furnishingstatus”创建虚拟变量</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="c18e" class="lq je hi lm b fi lr ls l lt lu"># Check what the dataset 'status' looks like<br/>status.head()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div class="er es nf"><img src="../Images/f5c4f97e7c8bf51066e2da3ddcc13da9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*1kjtCT0vd2I7ywMWbGMs8g.png"/></div></figure><p id="c1fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，你不需要三列。您可以删除<code class="du me mf mg lm b">furnished</code>列，因为只需最后两列即可识别家具类型，其中—</p><ul class=""><li id="eef6" class="ko kp hi ih b ii ij im in iq kq iu kr iy ks jc kt ku kv kw bi translated"><code class="du me mf mg lm b">00</code>将对应<code class="du me mf mg lm b">furnished</code></li><li id="33f3" class="ko kp hi ih b ii kx im ky iq kz iu la iy lb jc kt ku kv kw bi translated"><code class="du me mf mg lm b">01</code>将对应<code class="du me mf mg lm b">unfurnished</code></li><li id="9690" class="ko kp hi ih b ii kx im ky iq kz iu la iy lb jc kt ku kv kw bi translated"><code class="du me mf mg lm b">10</code>将对应于<code class="du me mf mg lm b">semi-furnished</code></li></ul><p id="3aa4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是为了避免冗余和多重共线性效应。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="c5d4" class="lq je hi lm b fi lr ls l lt lu"># Let's drop the first column from status df using 'drop_first = True'</span><span id="6c98" class="lq je hi lm b fi lv ls l lt lu">status = pd.get_dummies(housing['furnishingstatus'], drop_first = True)</span></pre><p id="50f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里我们删除了<strong class="ih hj"> <em class="kn">带家具的</em> </strong>变量</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="4825" class="lq je hi lm b fi lr ls l lt lu"># Add the results to the original housing dataframe</span><span id="f5d4" class="lq je hi lm b fi lv ls l lt lu">housing = pd.concat([housing, status], axis = 1)</span></pre><p id="9666" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将新的虚拟变量连接到数据集</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="9096" class="lq je hi lm b fi lr ls l lt lu"># Drop 'furnishingstatus' as we have created the dummies for it</span><span id="4b5a" class="lq je hi lm b fi lv ls l lt lu">housing.drop(['furnishingstatus'], axis = 1, inplace = True)</span></pre><p id="31de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">删除<strong class="ih hj"><em class="kn">furnishingstatus</em></strong>，因为我们已经为它创建了虚拟变量。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="dee6" class="lq je hi lm b fi lr ls l lt lu">housing.head()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mz"><img src="../Images/b3e41658d67f1b476707db7bc3f21168.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ilzgOFWZNvORyYCctQEkrA.png"/></div></div></figure></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="20f7" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">步骤4:将数据分成训练集和测试集</h1><p id="1698" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">如你所知，回归的第一个基本步骤是执行训练测试分割。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="18cc" class="lq je hi lm b fi lr ls l lt lu">from sklearn.model_selection import train_test_split</span><span id="ce54" class="lq je hi lm b fi lv ls l lt lu"># We specify this so that the train and test data set always have the same rows, respectively</span><span id="7296" class="lq je hi lm b fi lv ls l lt lu">np.random.seed(0)</span><span id="9ae0" class="lq je hi lm b fi lv ls l lt lu">df_train, df_test = train_test_split(housing, train_size = 0.7, test_size = 0.3, random_state = 100)</span></pre><h1 id="ca53" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">重新缩放要素</h1><p id="2077" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">这里我们可以看到，除了<code class="du me mf mg lm b">area</code>，所有的列都是小整数值。因此，重新调整变量以使它们具有可比较的规模是极其重要的。</p><p id="7e7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们没有可比较的尺度，那么通过拟合回归模型获得的一些系数与其他系数相比可能非常大或非常小。</p><p id="38b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在模型评估时，这可能会变得非常烦人。因此，建议使用标准化或规范化，以便获得的系数单位都在同一标度上。</p><p id="b228" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所知，有两种常见的重新调整方法:</p><ol class=""><li id="feda" class="ko kp hi ih b ii ij im in iq kq iu kr iy ks jc ng ku kv kw bi translated">最小-最大缩放</li><li id="656d" class="ko kp hi ih b ii kx im ky iq kz iu la iy lb jc ng ku kv kw bi translated">标准化(平均值-0，西格玛-1)</li></ol><p id="0fd9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一次，我们将使用最小最大缩放。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="c5e8" class="lq je hi lm b fi lr ls l lt lu">from sklearn.preprocessing import MinMaxScaler</span></pre><p id="26e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将scaler()应用于除“是-否”和“虚拟”变量之外的所有列</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="3ff0" class="lq je hi lm b fi lr ls l lt lu">scaler = MinMaxScaler()</span><span id="93dc" class="lq je hi lm b fi lv ls l lt lu"># Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables</span><span id="e0fc" class="lq je hi lm b fi lv ls l lt lu">num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price']</span><span id="78ed" class="lq je hi lm b fi lv ls l lt lu">df_train[num_vars] = scaler.fit_transform(df_train[num_vars])</span></pre><p id="db2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们检查相关系数，看看哪些变量是高度相关的。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="c117" class="lq je hi lm b fi lr ls l lt lu"># Let's check the correlation coefficients to see which variables are highly correlated</span><span id="2493" class="lq je hi lm b fi lv ls l lt lu">plt.figure(figsize = (16, 10))<br/>sns.heatmap(df_train.corr(), annot = True, cmap="YlGnBu")<br/>plt.show()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es nh"><img src="../Images/0be1c5a25ebe70514de221865c8edd29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5zp7WT-qo_ZC1GzD55XvGQ.png"/></div></div><figcaption class="mv mw et er es mx my bd b be z dx translated">列车数据热图。</figcaption></figure><p id="f2ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可能已经注意到了，<code class="du me mf mg lm b">area</code>似乎与<code class="du me mf mg lm b">price</code>最相关。让我们来看看<code class="du me mf mg lm b">area</code>和<code class="du me mf mg lm b">price</code>的配对图。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="b46c" class="lq je hi lm b fi lr ls l lt lu">plt.figure(figsize=[6,6])<br/>plt.scatter(df_train.area, df_train.price)<br/>plt.show()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es ni"><img src="../Images/f108e61fba5975bd946d7609f7cd90b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N1RFH2Kk0zKu5Uty9if_Vg.png"/></div></div><figcaption class="mv mw et er es mx my bd b be z dx translated">x轴代表面积，y轴代表价格</figcaption></figure><p id="fee4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们选择<code class="du me mf mg lm b">area</code>作为第一个变量，并尝试拟合一条回归线。</p><h1 id="666d" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">分为X和Y两个集合进行建模</h1><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="90a7" class="lq je hi lm b fi lr ls l lt lu">y_train = df_train.pop('price')<br/>X_train = df_train</span></pre></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="c7a5" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">步骤5:建立线性模型</h1><p id="9a56" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">使用<code class="du me mf mg lm b">statsmodels</code>通过训练数据拟合一条回归线。</p><p id="795d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请记住，在<code class="du me mf mg lm b">statsmodels</code>中，您需要使用<code class="du me mf mg lm b">sm.add_constant(X)</code>明确拟合一个常数，因为如果我们不执行这个步骤，默认情况下，<code class="du me mf mg lm b">statsmodels</code>会拟合一条穿过原点的回归线。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="7baf" class="lq je hi lm b fi lr ls l lt lu">import statsmodels.api as sm</span><span id="dd0d" class="lq je hi lm b fi lv ls l lt lu"># Add a constant<br/>X_train_lm = sm.add_constant(X_train[['area']])</span><span id="b100" class="lq je hi lm b fi lv ls l lt lu"># Create a first fitted model<br/>lr = sm.OLS(y_train, X_train_lm).fit()</span></pre><p id="3f7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">lr.params返回变量的系数。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="79f5" class="lq je hi lm b fi lr ls l lt lu"># Check the parameters obtained</span><span id="1e8f" class="lq je hi lm b fi lv ls l lt lu">lr.params</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div class="er es nj"><img src="../Images/f3433737d82246a64a3f87fb16492f1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*JRLPtijyO_O-3OBTudv9Mw.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="a29d" class="lq je hi lm b fi lr ls l lt lu"># Let's visualise the data with a scatter plot and the fitted regression line</span><span id="a8d3" class="lq je hi lm b fi lv ls l lt lu">plt.scatter(X_train_lm.iloc[:, 1], y_train)<br/>plt.plot(X_train_lm.iloc[:, 1], 0.127 + 0.462*X_train_lm.iloc[:, 1], 'r')<br/>plt.show()</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es nk"><img src="../Images/500a19865ae70a78d7d7a235ef5f7802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z2Wc23asos5Ph3fHW8tLcg.png"/></div></div></figure><p id="d920" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们打印线性回归模型的摘要。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="972b" class="lq je hi lm b fi lr ls l lt lu"># Print a summary of the linear regression model obtained<br/>print(lr.summary())</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es nl"><img src="../Images/024dfbd2816533c4937709f7b9583735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RpmuuHxBTX48F_b_7iqJMw.png"/></div></div></figure><p id="f31e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">得到的R平方值为<code class="du me mf mg lm b">0.283</code>。</p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="5610" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">添加另一个变量</h1><p id="59b0" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">既然我们有如此多的变量，我们显然可以做得比这更好。因此，让我们继续添加第二高度相关的变量，即<code class="du me mf mg lm b">bathrooms</code>。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="bdf9" class="lq je hi lm b fi lr ls l lt lu"># Assign all the feature variables to X</span><span id="c845" class="lq je hi lm b fi lv ls l lt lu">X_train_lm = X_train[['area', 'bathrooms']]</span></pre><p id="330a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">导入统计库并拟合OLS</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="4d22" class="lq je hi lm b fi lr ls l lt lu"># Build a linear model</span><span id="bc55" class="lq je hi lm b fi lv ls l lt lu">import statsmodels.api as sm<br/>X_train_lm = sm.add_constant(X_train_lm)</span><span id="b140" class="lq je hi lm b fi lv ls l lt lu">lr = sm.OLS(y_train, X_train_lm).fit()</span><span id="5a13" class="lq je hi lm b fi lv ls l lt lu">lr.params</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div class="er es nm"><img src="../Images/c89537cb9ee4e5381c599dc23f7815f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*4bMZyoPtZji_U0Y8GwO3IQ.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="fb68" class="lq je hi lm b fi lr ls l lt lu"># Check the summary<br/>print(lr.summary())</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es nn"><img src="../Images/7e20ef495b7038f091b5a34e4185a0ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_0oIYKE0luhfsPsryrmgeA.png"/></div></div></figure><p id="c6f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们明显改进了模型，调整后的R平方值从<code class="du me mf mg lm b">0.281</code>上升到<code class="du me mf mg lm b">0.477</code>。让我们继续添加另一个变量<code class="du me mf mg lm b">bedrooms</code>。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="3aac" class="lq je hi lm b fi lr ls l lt lu"># Assign all the feature variables to X<br/>X_train_lm = X_train[['area', 'bathrooms','bedrooms']]</span><span id="cd35" class="lq je hi lm b fi lv ls l lt lu"># Build a linear model</span><span id="084e" class="lq je hi lm b fi lv ls l lt lu">import statsmodels.api as sm<br/>X_train_lm = sm.add_constant(X_train_lm)</span><span id="4c00" class="lq je hi lm b fi lv ls l lt lu">lr = sm.OLS(y_train, X_train_lm).fit()</span><span id="bbb7" class="lq je hi lm b fi lv ls l lt lu">lr.params</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div class="er es no"><img src="../Images/b688f79e4ddbbf062b3c09c6cdea9ef0.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*mUGOobWueauBFTiVBsFOKw.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="314b" class="lq je hi lm b fi lr ls l lt lu"># Print the summary of the model</span><span id="7cfc" class="lq je hi lm b fi lv ls l lt lu">print(lr.summary())</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es np"><img src="../Images/7e8d2de288558b864ee7387c9f2a77c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dVcbl7RhTzK_fBRUYGd1WA.png"/></div></div></figure><p id="1641" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们再次改进了调整后的R平方。现在让我们继续添加所有的特征变量。</p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="4968" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">将所有变量添加到模型中</h1><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="6711" class="lq je hi lm b fi lr ls l lt lu"># Check all the columns of the dataframe</span><span id="a453" class="lq je hi lm b fi lv ls l lt lu">housing.columns</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es nq"><img src="../Images/a8d3b06f49b3791b6e66580da95ceae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h_bIyx9HQh-_7f0IZeZuvw.png"/></div></div></figure><p id="f3f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">让我们建立一个线性模型</strong></p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="c793" class="lq je hi lm b fi lr ls l lt lu">#Build a linear model</span><span id="0864" class="lq je hi lm b fi lv ls l lt lu">import statsmodels.api as sm<br/>X_train_lm = sm.add_constant(X_train)</span><span id="d3cb" class="lq je hi lm b fi lv ls l lt lu">lr_1 = sm.OLS(y_train, X_train_lm).fit()</span><span id="ebcc" class="lq je hi lm b fi lv ls l lt lu">lr_1.params</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div class="er es nr"><img src="../Images/4fe8cf2acc5fe1fd9659d2c8af022b48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*pRpqLorAp1UiNVppXPNkTg.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="f250" class="lq je hi lm b fi lr ls l lt lu">print(lr_1.summary())</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es ns"><img src="../Images/7c9136fba2170557175e23967def4384.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nVntCw6V1gZXy6WZY1jKUw.png"/></div></div></figure><p id="d8eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看p值，看起来有些变量并不真正重要(在存在其他变量的情况下)。</p><p id="f441" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">也许我们可以放弃一些？</p><p id="cc28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以简单地去掉p值最高、不重要的变量。一个更好的方法是用VIF的信息来补充这一点。</p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="cfc3" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">检查VIF</h1><p id="faad" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">方差膨胀因子或VIF给出了一个基本的量化概念，即特征变量之间的相关程度。这是检验我们的线性模型的一个极其重要的参数。计算<code class="du me mf mg lm b">VIF</code>的公式为:</p><p id="3774" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn"> VIF = 1/1-R . </em> </strong></p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="84c7" class="lq je hi lm b fi lr ls l lt lu"># Check for the VIF values of the feature variables. </span><span id="88c5" class="lq je hi lm b fi lv ls l lt lu">from statsmodels.stats.outliers_influence import variance_inflation_factor</span><span id="50c8" class="lq je hi lm b fi lv ls l lt lu"># Create a dataframe that will contain the names of all the feature variables and their respective VIFs</span><span id="3ad2" class="lq je hi lm b fi lv ls l lt lu">vif = pd.DataFrame()</span><span id="af4b" class="lq je hi lm b fi lv ls l lt lu">vif['Features'] = X_train.columns</span><span id="b299" class="lq je hi lm b fi lv ls l lt lu">vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]</span><span id="78c4" class="lq je hi lm b fi lv ls l lt lu">vif['VIF'] = round(vif['VIF'], 2)</span><span id="17c0" class="lq je hi lm b fi lv ls l lt lu">vif = vif.sort_values(by = "VIF", ascending = False)<br/>vif<br/></span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div class="er es nt"><img src="../Images/bd4e19182a4d96f12232bd26efcc64b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*zLGVY_DeGDM97CcpoHbPDg.png"/></div></figure><p id="09d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们通常希望VIF小于5。所以很明显我们需要去掉一些变量。</p><p id="3075" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为什么我们还要考虑数字5？？？我来解释……</p><p id="3efe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设VIF=5。即</p><p id="96d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1/1-R = 5</p><p id="2430" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1-R = 1/5</p><p id="785e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1-R = 0.2</p><p id="079a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">R = 0.8</p><p id="6015" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这意味着任何VIF分数大于等于5的变量都可以解释数据中80%以上的变异。</p><p id="b89a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果是这种情况，我们可能会面临多重共线性问题。</p><p id="87fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此有了数字5。</p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="274d" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">删除变量并更新模型</h1><p id="16bd" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">从摘要和VIF数据框架中可以看出，一些变量仍然无关紧要。其中一个变量是<code class="du me mf mg lm b">semi-furnished</code>，因为它具有非常高的p值<code class="du me mf mg lm b">0.938</code>。让我们继续下去，放弃这个变量。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="a655" class="lq je hi lm b fi lr ls l lt lu"># Dropping highly correlated variables and insignificant variables</span><span id="48b9" class="lq je hi lm b fi lv ls l lt lu">X = X_train.drop('semi-furnished', 1,)</span><span id="a1c1" class="lq je hi lm b fi lv ls l lt lu"># Build a third fitted model<br/>X_train_lm = sm.add_constant(X)</span><span id="0cff" class="lq je hi lm b fi lv ls l lt lu">lr_2 = sm.OLS(y_train, X_train_lm).fit()</span><span id="189a" class="lq je hi lm b fi lv ls l lt lu"># Print the summary of the model<br/>print(lr_2.summary())</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es nu"><img src="../Images/b62c204edf764ae2934b625c42a97bd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*25ulMeZwX_KQruEd9a7_cg.png"/></div></div></figure><p id="4834" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们再次计算vif分数。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="7a55" class="lq je hi lm b fi lr ls l lt lu"># Calculate the VIFs again for the new model</span><span id="27c1" class="lq je hi lm b fi lv ls l lt lu">vif = pd.DataFrame()</span><span id="0372" class="lq je hi lm b fi lv ls l lt lu">vif['Features'] = X.columns</span><span id="75f6" class="lq je hi lm b fi lv ls l lt lu">vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]</span><span id="d5b2" class="lq je hi lm b fi lv ls l lt lu">vif['VIF'] = round(vif['VIF'], 2)</span><span id="17d8" class="lq je hi lm b fi lv ls l lt lu">vif = vif.sort_values(by = "VIF", ascending = False)<br/>vif<br/></span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div class="er es nv"><img src="../Images/fc53cf9c7d84339533d29b5c8ce14285.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*WPsRVoAx5KUmmGmCK07jow.png"/></div></figure></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="2252" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">删除变量并更新模型</h1><p id="f62f" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">正如您所注意到的，一些变量具有高VIF值和高p值。这样的变量是无关紧要的，应该放弃。</p><p id="d310" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可能已经注意到，变量<code class="du me mf mg lm b">bedroom</code>具有非常高的VIF ( <code class="du me mf mg lm b">6.6</code>)和高p值(<code class="du me mf mg lm b">0.206</code>)。因此，这个变量没有多大用处，应该删除。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="a054" class="lq je hi lm b fi lr ls l lt lu"># Dropping highly correlated variables and insignificant variables<br/>X = X.drop('bedrooms', 1)</span><span id="140e" class="lq je hi lm b fi lv ls l lt lu"># Build a second fitted model<br/>X_train_lm = sm.add_constant(X)</span><span id="7420" class="lq je hi lm b fi lv ls l lt lu">lr_3 = sm.OLS(y_train, X_train_lm).fit()</span><span id="a77b" class="lq je hi lm b fi lv ls l lt lu"># Print the summary of the model</span><span id="2322" class="lq je hi lm b fi lv ls l lt lu">print(lr_3.summary())</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es nw"><img src="../Images/df7c4640f7f691102397131916a97555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rRRtrSTCmDcmx2Ovx-GpUw.png"/></div></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="e0dd" class="lq je hi lm b fi lr ls l lt lu"># Calculate the VIFs again for the new model<br/>vif = pd.DataFrame()</span><span id="099a" class="lq je hi lm b fi lv ls l lt lu">vif['Features'] = X.columns</span><span id="7835" class="lq je hi lm b fi lv ls l lt lu">vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]</span><span id="260a" class="lq je hi lm b fi lv ls l lt lu">vif['VIF'] = round(vif['VIF'], 2)</span><span id="8678" class="lq je hi lm b fi lv ls l lt lu">vif = vif.sort_values(by = "VIF", ascending = False)</span><span id="58aa" class="lq je hi lm b fi lv ls l lt lu">vif<br/></span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div class="er es nx"><img src="../Images/7d4b7353d13ecb9491906e3da76699f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*5ZB7GRN67SrATslRhDA9tg.png"/></div></figure></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="dd6b" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">删除变量并更新模型</h1><p id="1536" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">正如你可能已经注意到的，掉落<code class="du me mf mg lm b">semi-furnised</code>也减少了<code class="du me mf mg lm b">mainroad</code>的VIF，所以它现在低于5。</p><p id="6d2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是从总结中，我们仍然可以看到他们中的一些人有很高的p值。例如，<code class="du me mf mg lm b">basement</code>的p值为0.03。我们也应该去掉这个变量。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="ccc8" class="lq je hi lm b fi lr ls l lt lu">X = X.drop('basement', 1)</span><span id="6ca0" class="lq je hi lm b fi lv ls l lt lu"># Build a fourth fitted model</span><span id="51ec" class="lq je hi lm b fi lv ls l lt lu">X_train_lm = sm.add_constant(X)</span><span id="8e71" class="lq je hi lm b fi lv ls l lt lu">lr_4 = sm.OLS(y_train, X_train_lm).fit()</span><span id="9d71" class="lq je hi lm b fi lv ls l lt lu">lr_4.params</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es ny"><img src="../Images/50b3c8da6fce8b2fb1dd349c915b1c2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xe8u_iG-fgS1CyiXcX2nQg.png"/></div></div></figure><p id="7237" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">现在你可以看到，VIFs和p值都在可接受的范围内。所以我们只使用这个模型进行预测。</em>T9】</strong></p><p id="4304" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">我们训练数据集的最终R分数是0.676 </em> </strong></p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="ca05" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">步骤7:训练数据的残差分析</h1><p id="1d4e" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">因此，现在检查误差项是否也是正态分布的(事实上，这是线性回归的主要假设之一)，</p><p id="9ee8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们画出误差项的直方图，看看它是什么样子。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="6df1" class="lq je hi lm b fi lr ls l lt lu">y_train_price = lr_4.predict(X_train_lm)</span><span id="5bd6" class="lq je hi lm b fi lv ls l lt lu"># Plot the histogram of the error terms<br/>fig = plt.figure()</span><span id="beca" class="lq je hi lm b fi lv ls l lt lu">sns.distplot((y_train - y_train_price), bins = 20)</span><span id="f7b1" class="lq je hi lm b fi lv ls l lt lu">fig.suptitle('Error Terms', fontsize = 20)   <br/>               <br/>plt.xlabel('Errors', fontsize = 18)                         </span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es nz"><img src="../Images/d3cfeff0dd263552af8998d7cc010626.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6qUpp2bKxMNvLqgH3IZtFg.png"/></div></div></figure></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="f19e" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">步骤8:使用最终模型进行预测</h1><p id="6959" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">既然我们已经拟合了模型并检查了误差项的正态性，那么是时候继续使用最终模型，即第四个模型进行预测了。</p><h2 id="0772" class="lq je hi bd jf mh mi mj jj mk ml mm jn iq mn mo jr iu mp mq jv iy mr ms jz mt bi translated">对测试集应用缩放</h2><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="ff52" class="lq je hi lm b fi lr ls l lt lu">num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price']</span><span id="7063" class="lq je hi lm b fi lv ls l lt lu">df_test[num_vars] = scaler.transform(df_test[num_vars])</span></pre><h2 id="3ce1" class="lq je hi bd jf mh mi mj jj mk ml mm jn iq mn mo jr iu mp mq jv iy mr ms jz mt bi translated">分为X检验和y检验</h2><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="3849" class="lq je hi lm b fi lr ls l lt lu">y_test = df_test.pop('price')</span><span id="486c" class="lq je hi lm b fi lv ls l lt lu">X_test = df_test</span><span id="c7b5" class="lq je hi lm b fi lv ls l lt lu"># Adding constant variable to test dataframe</span><span id="918b" class="lq je hi lm b fi lv ls l lt lu">X_test_m4 = sm.add_constant(X_test)</span><span id="a42a" class="lq je hi lm b fi lv ls l lt lu"># Creating X_test_m4 dataframe by dropping variables from X_test_m4</span><span id="7eb6" class="lq je hi lm b fi lv ls l lt lu">X_test_m4 = X_test_m4.drop(["bedrooms", "semi-furnished", "basement"], axis = 1)</span><span id="0e2c" class="lq je hi lm b fi lv ls l lt lu"># Making predictions using the fourth model</span><span id="4508" class="lq je hi lm b fi lv ls l lt lu">y_pred_m4 = lr_4.predict(X_test_m4)</span></pre><p id="acbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算测试数据集的R分数</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="6112" class="lq je hi lm b fi lr ls l lt lu">from sklearn.metrics import r2_score</span><span id="cabc" class="lq je hi lm b fi lv ls l lt lu">r2_score(y_true=y_test,y_pred=y_pred_m4)</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div class="er es oa"><img src="../Images/ed2f46ef53eec86be1c33aadc2581198.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*NNPRq2_acZQtlmE3egcz6g.png"/></div></figure><p id="e0c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">我们训练数据集的最终R分数是0.676 </em> </strong></p><p id="ff8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">对于我们的测试数据集，我们得到了0.66的R分数。</em> </strong></p><p id="52bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这意味着我们的模型在测试数据集上也表现良好。</p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h1 id="5639" class="jd je hi bd jf jg lc ji jj jk ld jm jn jo le jq jr js lf ju jv jw lg jy jz ka bi translated">步骤9:模型评估</h1><p id="59a1" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">现在让我们绘制实际值与预测值的图表。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="d4aa" class="lq je hi lm b fi lr ls l lt lu"># Plotting y_test and y_pred to understand the spread</span><span id="93ed" class="lq je hi lm b fi lv ls l lt lu">fig = plt.figure()</span><span id="00c4" class="lq je hi lm b fi lv ls l lt lu">plt.scatter(y_test, y_pred_m4)</span><span id="1854" class="lq je hi lm b fi lv ls l lt lu">fig.suptitle('y_test vs y_pred', fontsize = 20)  <br/>           <br/>plt.xlabel('y_test', fontsize = 18)  <br/>                        <br/>plt.ylabel('y_pred', fontsize = 16)</span></pre><figure class="lh li lj lk fd lx er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es ob"><img src="../Images/98248001f48790d323708714ef89e4a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hI0alZbnWQsFCM1pYGoZmw.png"/></div></div></figure><p id="512d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，最佳拟合线的方程为:</p><p id="5729" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">𝑝𝑟𝑖𝑐𝑒=<strong class="ih hj">0.236×𝑎𝑟𝑒𝑎+0.202×𝑏𝑎𝑡ℎ𝑟𝑜𝑜𝑚𝑠+0.11×𝑠𝑡𝑜𝑟𝑖𝑒𝑠+0.05×𝑚𝑎𝑖𝑛𝑟𝑜𝑎𝑑+0.04×𝑔𝑢𝑒𝑠𝑡𝑟𝑜𝑜𝑚+0.0876×ℎ𝑜𝑡𝑤𝑎𝑡𝑒𝑟ℎ𝑒𝑎𝑡𝑖𝑛𝑔+0.0682×𝑎𝑖𝑟𝑐𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛𝑖𝑛𝑔+0.0629×𝑝𝑎𝑟𝑘𝑖𝑛𝑔+0.0637×𝑝𝑟𝑒𝑓𝑎𝑟𝑒𝑎−0.0337×𝑢𝑛𝑓𝑢𝑟𝑛𝑖𝑠ℎ𝑒𝑑.</strong></p><p id="7f24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意:为了删除与目标变量相关性低的变量，我们可以<em class="kn">使用sklearn提供的递归特征消除。</em> </strong></p><p id="8c36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结论:</strong></p><p id="bee8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望读者对多元线性回归有一个直观的认识。</p></div></div>    
</body>
</html>