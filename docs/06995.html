<html>
<head>
<title>YOLO: You Only Look Once.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO:你只能看一次。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/yolo-you-look-only-once-9af63cb143b7?source=collection_archive---------3-----------------------#2020-06-10">https://medium.com/analytics-vidhya/yolo-you-look-only-once-9af63cb143b7?source=collection_archive---------3-----------------------#2020-06-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="db91" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><strong class="il hj"> YOLO </strong>目标检测算法，可以同时执行分类和目标定位(检测)，只需查看图像一次。因此，这种算法的名字叫做<strong class="il hj">你只看一次</strong>。</p></blockquote><h1 id="c1f7" class="jh ji hi bd jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke bi translated">1.介绍</h1><p id="67df" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">多年来，计算机视觉领域一直与我们一起生活和成长，从Instagram滤镜、谷歌镜头到特斯拉汽车，这些都是受计算机视觉算法创作启发的产品。在本文中，我将向您解释最流行的对象检测算法YOLOv3背后的工作原理。但在此之前，让我试着解释一下，<strong class="il hj">分类任务vs物体检测的区别。</strong></p><p id="3dbc" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">注意:所有3个版本的YOLO都具有相似的工作原理，只是在网络架构上有微小的变化，这有助于整体性能的提高。</p><h2 id="663f" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">先决条件</h2><p id="5bf4" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">要彻底理解这篇文章</p><ul class=""><li id="f928" class="lb lc hi il b im in iq ir kh ld kj le kl lf jg lg lh li lj bi translated">你应该明白<a class="ae lk" rel="noopener" href="/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148">卷积神经网络背后的工作原理。</a></li><li id="4c51" class="lb lc hi il b im ll iq lm kh ln kj lo kl lp jg lg lh li lj bi translated">能够轻松构建简单的神经网络。</li><li id="18d5" class="lb lc hi il b im ll iq lm kh ln kj lo kl lp jg lg lh li lj bi translated">最重要的是，学习的欲望。</li></ul><h1 id="ca3a" class="jh ji hi bd jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke bi translated">2.分类与目标检测</h1><p id="874e" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated"><strong class="il hj">分类</strong>的任务是预测图像中物体的类别。例如，训练图像分类网络来分类一副牌，或者区分猫和狗的图像。</p><p id="bf93" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated"><strong class="il hj">目标检测</strong>的任务是识别图像中目标的位置以及目标的类别。图像中的对象包含在一个矩形框中，也表示对象的类别。<br/>例如，如果一个人想要在点击自拍的同时计数交通路口的汽车数量或面部数量，则采用对象检测的任务。分类的任务不能直接应用于现实世界场景中的输入图像馈送，它总是伴随着检测或分割的任务。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es lq"><img src="../Images/a56de0a8e220c4fee64690607f8aa24f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XV0QjOo7fdrOyLA2ON9uUA.jpeg"/></div></div></figure><h1 id="d92a" class="jh ji hi bd jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke bi translated">3.YOLO的工作原理</h1><p id="3ba1" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">YOLO使用一个CNN来预测物体的种类，并且通过只看一次图像来检测物体的位置。让我们先看看YOLO的网络架构。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mc"><img src="../Images/73f61afd9da5fa3e88acde0af0c1a943.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SDwVL66ie6roLTC25oNYlQ.png"/></div></div><figcaption class="md me et er es mf mg bd b be z dx translated">图一</figcaption></figure><p id="dd82" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">让我试着用文字描述上面的图(图1)，YOLO网络接受一个固定输入维度的图像。理论上，YOLO对于输入图像的大小是不变的(灵活的)。然而，在实践中，我们将输入尺寸调整为416x416或608x608的固定尺寸。这样做使我们能够批量处理图像(批量图像可以由GPU并行处理)，这有助于我们更快地训练网络。</p><p id="2dd9" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">当图像通过网络向前传播时，对图像应用多重卷积，学习物体的特征、颜色、形状和许多其他方面。在每一层，我们获得一个复杂的图像，即该层的特征图。<strong class="il hj">CNN图层的输出是3D特征图。每个深度通道对图像或对象的特征进行编码。</strong></p><p id="4ed5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">了解更多关于<a class="ae lk" href="https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2" rel="noopener" target="_blank">的特色地图</a>。</p><p id="e480" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">当网络步距达到32时，在一定数量的卷积之后，我们得到<strong class="il hj">输出特征图，</strong>我们从中获得它的层被称为<strong class="il hj">检测层</strong>。</p><h2 id="20c6" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">3.1如何解释这个输出特征图？</h2><p id="b167" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">输出特征图是表示在将图像从输入层传递到检测/输出层时，所有前面的卷积层所学习的特征的合成张量。<strong class="il hj">输出/检测特征图</strong>为<strong class="il hj"> 13x13x125。</strong></p><h2 id="07c5" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">3.2我们来分解一下，看看里面有什么。</h2><p id="441f" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">13是输出特征地图的宽度和高度。由于发生了卷积，13x13中的每个单元(正方形)可以看到输入图像的一个区域/部分。这叫做<a class="ae lk" href="http://blog.christianperone.com/2017/11/the-effective-receptive-field-on-cnns/#:~:text=The%20receptive%20field%20in%20Convolutional,particular%20unit%20of%20the%20network.&amp;text=The%20numbers%20inside%20the%20pixels,sliding%20step%20of%20the%20filter)." rel="noopener ugc nofollow" target="_blank"> <strong class="il hj">感受野</strong> </a> <strong class="il hj">。</strong>网络的<strong class="il hj">感受</strong> <strong class="il hj">域</strong>是输出特征图中细胞(神经元)可见的输入图像区域。</p><p id="58c4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">此外，13x13x125特征地图中的每个单元都有5个边界框来检测图像中的对象。只有当对象落在该单元的感受野内(感受野是该单元可见的输入图像的区域/部分)时，该单元才能通过其5个边界框中的一个来检测图像中的对象。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mh"><img src="../Images/0b2615f133cd26495a6b73dabf708446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*ZiPlhZzM8mIbc6EfsFHQiA.png"/></div><figcaption class="md me et er es mf mg bd b be z dx translated">图2</figcaption></figure><p id="1b2b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">为此，YOLO将输入图像分成13x13的网格。13x13x125输出要素地图中的每个像元代表输入图像的每个相应的13x13格网。(比如，特征图的红色单元格代表狗的图像上的红色网格)。(狗图像上的每个正方形13x13称为一个<strong class="il hj">网格</strong>T26】13x 13特征图上的每个神经元称为一个<strong class="il hj">细胞</strong>。)</p><p id="cadb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">现在，由于13x13x125中的每个单元有5个边界框，这些边界框可以使用输入上的13x13网格进行本地化(用于定位对象)。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mi"><img src="../Images/a5455b7605e5f520bba71fbf4fc70932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*kodho4JjG_9zyPAysWns9A.jpeg"/></div></figure><p id="f2ef" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">如果对象的中心/中点落在特定的网格内(红色网格包含狗的中点)，则该网格负责检测对象。</p><p id="e626" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">更简单地说，包围对象或对象的一部分的边界框是将用于检测/定位图像中的对象的框。这些盒子比其他盒子具有更高的置信度得分。</p><h2 id="50f6" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">3.3现在来看张量的第三个维度，125。这代表了什么？</h2><p id="0127" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">这是实际产量预测被封闭的地方。如前所述，13x13x125特征地图中的每个像元都有5个边界框来进行预测。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mj"><img src="../Images/3484fb67855b8fdc72c38be3633243f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*DRRIxqysKnkwII4z5vDIjw.png"/></div></figure><p id="2fe6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">每个边界框由它的，</p><ul class=""><li id="8a01" class="lb lc hi il b im in iq ir kh ld kj le kl lf jg lg lh li lj bi translated"><strong class="il hj">质心-x (tx)，质心-y (ty)，包围盒宽度(btw)，包围盒高度(th) </strong>。</li><li id="795b" class="lb lc hi il b im ll iq lm kh ln kj lo kl lp jg lg lh li lj bi translated"><strong class="il hj">置信度/客观分数(Po) </strong>(对象在边界框内的概率)。</li><li id="1568" class="lb lc hi il b im ll iq lm kh ln kj lo kl lp jg lg lh li lj bi translated"><strong class="il hj">类别概率(P1，P2…)</strong>即对象属于哪个类别(数据集中每个类别的softmax值)。</li></ul><p id="82d2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">总的来说，这相当于来自边界框坐标的4个值，1个客观分数的值，N个正在被训练的类(这里，N=20)。每个边界框总共有25个值。</p><p id="a4a9" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">每个单元有5个边界框(YOLOv2)，因此在特征图中每个单元有125个值。</p><p id="1fe3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">特征图中的深度方向条目(13x13xd)由以下公式控制:</p><p id="7cbc" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">((5+C)xB)=深度方向的条目。(四)</p><p id="abd1" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">x，y，w，h，对象得分— 5。</p><p id="f272" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">C —类别概率(C=20)。</p><p id="269c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">B —每个像元的边界框数量(B=5)。</p><p id="c732" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">将这些值放入公式中，我们得到的深度值为125。13x13x125，如图所示。</p><h2 id="bcb1" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">3.4 YOLO生产了多少个边界框？</h2><p id="bcc7" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">每个13x13单元通过其指定数量的边界框13x13xB检测输入图像中的对象。在YOLOv2中，B=5。总边界框(13x13)x5=845。</p><p id="3ac5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">在YOLOv3中，每个单元格有3个边界框。因此，使用13x13特征地图的边界框的总数将是。</p><p id="e078" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">(13x13)x3 = 507个边界框。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mk"><img src="../Images/188471ab8108825528fbeaef5ec964ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*spgrhq1RQ4WdRxZLWyfYfw.jpeg"/></div></figure><p id="a1c4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">从上面的图中，包含狗或狗的一部分的边界框将被用来检测这张图片中的狗。剩余的边界框被丢弃，因为它们没有在图片中定位狗。</p><h2 id="52d5" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">3.5不同尺度的预测</h2><p id="0c02" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">YOLOv3为对象检测生成多个输出特征图。在达到32的步距之后，网络为尺寸为416x416的输入图像产生13×13的特征图。YOLOv3还以16步距和8步距生成特征图。步长16处的层产生26×26的特征图&amp;在步长8处，产生52×52的特征图(416×416输入)。尽管特征图的宽度和高度在不同的步幅值下变化，但是包围边界框坐标的深度方向条目的数量、置信度得分和类别概率保持不变。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es ml"><img src="../Images/8975a08ef51d89ac92ae748d77dd7187.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*h0lA6qEbtq-kikyHAJFvbA.png"/></div></figure><p id="ed36" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">随着网络向前传播图像，当步幅为32时，在第一检测层，我们获得13x13输出特征图。进一步的层(在第一检测层之后)以因子2进行非采样，并与具有相似尺寸的先前层的特征图连接。另一个检测层当步幅为16时，我们在检测层获得26×26的输出特征图，当步幅为8时，获得52×52的特征图。因此，当输入图像尺寸为416x416时，YOLOv3的边界框的总数为</p><h2 id="2afa" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">((13x13)+(26x26)+(52x52))x3 =每幅图像10647个边界框。</h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mk"><img src="../Images/030360c474d43be3a5d775a7175af4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*C4tb1J-4SXz4Vt9F3FJERQ.jpeg"/></div></figure><p id="eec9" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">现在，有很多边界框来检测图像中的对象。</p><p id="65c9" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">但是我们需要10647个包围盒来检测图像中的一只狗吗？在我试图回答这个问题之前，让我们看看YOLO网络如何预测边界框的尺寸坐标。</p><h1 id="cceb" class="jh ji hi bd jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke bi translated">4.包围盒预测</h1><p id="9cea" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated"><strong class="il hj">在第一版YOLO中，边界框坐标是输出特征图</strong>的回归值。</p><p id="1007" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">YOLOv1网络试图直接预测边界框坐标和尺寸，而不对目标对象的形状进行任何假设。例如，图像中的人总是适合放在一个矩形框中&amp;而不是正方形框中，但在某些情况下，网络无法为人类输出矩形边界框。<strong class="il hj"> YOLOv1无法捕获数据</strong>中对象的广义长宽比&amp;大小。</p><p id="4b44" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">当网络被赋予预测边界框坐标和尺寸的责任时，它导致定位误差，精确边界框尺寸的错误。简单地说，网络发现很难输出精确标记在物体上的包围盒坐标。</p><p id="1817" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">然而，这个缺点已经在YOLOv2中通过使用一种叫做Anchors的东西解决了。</p><h2 id="514e" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">4.1锚</h2><p id="745d" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">锚点是训练数据集中对象的预定义大小。由于直接预测的边界框坐标非常倾斜(YOLO的直接输出)，这可以通过应用对数空间变换来消除&amp;然后将它们应用于预定义的边界框，称为锚点。</p><p id="9706" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated"><strong class="il hj">锚是先前的边界框，其倾向于捕捉训练数据中对象的长宽比&amp;大小。</strong>例如，当一个人从侧面看一辆汽车时，它的长宽比为2:1 (w=2xh)，当从前面看时，它的长宽比为1:1(正方形)，如果有一个人，如果他/她站着，他/她的长宽比为1:3。类似地，前景中的对象将具有较大的边界框尺寸，而背景中的对象将具有较小的尺寸。锚是对训练数据中对象的形状&amp;大小做出的假设。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mm"><img src="../Images/b95423fe17c7d4e85acc5927bf2c5e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yKlWDBQT7e5OkOsWTOHvNg.jpeg"/></div></div></figure><p id="0875" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">锚是通过训练数据中所有包围盒的K均值聚类来计算的。此过程创建相似边界框的群集，并选择质心来表示每个群集的尺寸。</p><p id="1642" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">YOLOv3从k-means聚类生成9个锚盒。(每个单元格3个边界框，跨3种不同比例13x13、26x26和52x52的预测。总共3x3 = 9个锚)</p><p id="a0fe" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">锚点或先前的边界框是有用的，因为YOLO可以学习对这些锚点进行小的调整，以正确地检测对象上的框。</p><h2 id="ba21" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">4.2这些锚点调整是如何进行的？</h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mn"><img src="../Images/54c136afe8a4fa3fbb920d89a380a81d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*ldleuwHM8V-GzfP-TRTLSA.png"/></div></figure><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mo"><img src="../Images/192aa8a72574e80619a648e4c4dd718d.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*GdljXAhilc-sSUtg_AnM5Q.png"/></div></figure><p id="dc0f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">tx，ty，tw，th是来自检测图层的回归(直接)边界框值。sigmoid函数应用于centroid-x和centroid-y，将值限制在0-1之间，确保边界框质心保持在网格内。Cx和Cy是图像上网格的左上角坐标。</p><p id="1221" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">pw和ph是盒子锚定尺寸。通过将YOLO输出应用于锚而不是预测它们，YOLOv3减少了定位误差并增加了其预测的精度。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es lq"><img src="../Images/578a6a3ec3a183a5e18670fb4fafbe06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7b3nF6K4F1DlUPLdsErYHg.png"/></div></div></figure><p id="52fb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated"><strong class="il hj">注意:</strong> <strong class="il hj">锚点可以是任意大小，因此可以延伸到13x13网格单元的边界之外，以检测大型对象。</strong></p><h2 id="fa9d" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">4.3如何把10647个箱子减少到一个更小的数字？</h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mp"><img src="../Images/d78a2ef9f3d3021a7a8b57923966f943.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*DFwpVRJw3mmcqasNdmvHKA.jpeg"/></div></figure><p id="1a57" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">我们不需要多个盒子来检测图像中的单个对象。单个边界框看起来很优雅。有两种方法可以限制预测框的数量。</p><ol class=""><li id="2602" class="lb lc hi il b im in iq ir kh ld kj le kl lf jg mq lh li lj bi translated"><strong class="il hj">设定置信度/客观分数的阈值<br/> </strong>客观分数指示边界框内的对象成为对象的概率，换句话说，<strong class="il hj">“由边界框包围的区域包含对象的置信度”。</strong></li></ol><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mn"><img src="../Images/54c136afe8a4fa3fbb920d89a380a81d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*ldleuwHM8V-GzfP-TRTLSA.png"/></div></figure><ol class=""><li id="0d14" class="lb lc hi il b im in iq ir kh ld kj le kl lf jg mq lh li lj bi translated"><strong class="il hj">非最大抑制。<br/>将盒子的数量减少到一个盒子。我们采用一种叫做非最大抑制的方法。</strong></li></ol><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mr"><img src="../Images/1baa02ca4beae0a931e52b3e00c30d4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sylNkAFSr17GKzKfFb5cug.png"/></div></div></figure><p id="98f5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">非最大值抑制是一种广泛使用的策略，用于从多个重叠实体中找出单个实体。在YOLOv3中，NMS使用IOU公制。</p><p id="be17" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">IOU metric计算两个边界框输出之间重叠面积与联合面积的比率。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mh"><img src="../Images/48e91c8b1b812862bc82532166a1c272.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*2LPQLE87SJBRCSXhpow9sA.png"/></div></figure><p id="2b2e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">选择其IOU值等于或大于阈值NMS值的框。</p><p id="bd1b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">YOLOv3的最终训练输出。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es ms"><img src="../Images/d9c3326077b7b297d102edba87d38354.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wnr2e-W3WvYk_G51Y4oMCQ.png"/></div></div></figure><h1 id="10c8" class="jh ji hi bd jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke bi translated">5.YOLOv3损失函数</h1><p id="e40e" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated"><strong class="il hj"> YOLOv3 </strong>使用预测值和实际值之间的平方差来计算<strong class="il hj">损失</strong>。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mt"><img src="../Images/3a80241e46716b09a30c2a7c0e19ea15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*WqFMjonNvEmyYy9x-oMTLw.png"/></div></figure><p id="83f5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">损失函数是以下各项的组合</p><ol class=""><li id="6911" class="lb lc hi il b im in iq ir kh ld kj le kl lf jg mq lh li lj bi translated"><strong class="il hj">分类</strong>损失。</li><li id="f900" class="lb lc hi il b im ll iq lm kh ln kj lo kl lp jg mq lh li lj bi translated"><strong class="il hj">本地化</strong>损失。(预测边界框和地面真实框之间的误差)。</li><li id="73c5" class="lb lc hi il b im ll iq lm kh ln kj lo kl lp jg mq lh li lj bi translated"><strong class="il hj">信心</strong>丧失。</li></ol><p id="d7c4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated"><strong class="il hj"> ∑^B </strong>表示单元格w.r.t中所有边界框相对于其质心-x、质心-y、宽度、高度&amp;置信度得分的损失值之和。</p><p id="4063" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated"><strong class="il hj"> ∑^S </strong>表示输出特征图中所有像元间所有损失值的总和。(在13x13地图中，S=13，将包含169个单元)。</p><p id="7834" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated"><strong class="il hj">当单元格中有物体时，1^obj </strong>为<strong class="il hj"> 1 </strong>。<strong class="il hj"> 0 </strong>无对象时</p><p id="6625" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated"><strong class="il hj"> 1^noobj </strong>当单元格中没有对象时为1&amp;当单元格中有对象时为0。</p><p id="d13e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated"><strong class="il hj"> λ </strong> s为常数。<strong class="il hj"> λ </strong>为坐标最高，更专注于检测。</p><h2 id="cf10" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">5.1分类损失</h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mu"><img src="../Images/4c9b5f1839f88ebf2530822823abad07.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*AjW0yFxsioj6CGMzjj4t3g.png"/></div></figure><p id="5d09" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">如果像元包含对象，这是每个类的条件类概率的平方误差。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mv"><img src="../Images/25519fdb6cc940beead8a7293f591918.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*AicyUn5tQKCHv9Tt_Y_mbA.png"/></div></figure><h2 id="7ef1" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">5.2本地化损失</h2><p id="d2d5" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">定位损失是在包围盒形心的误差和它的宽度和高度之间计算的。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mw"><img src="../Images/2c9d531f8bc38a2d0ef8e3a926cb2f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*kSbq7XuQFPPmSp6t4HEu5w.png"/></div></figure><p id="aa0c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">我们在平方根函数中使用宽度和高度来惩罚较小的边界框，因为我们需要对较小的对象使用精确的边界框。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es mx"><img src="../Images/8ba534ce696e5041b1cad0106f889c04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*AQsRIXvDqCMou2_-Ra3SxA.png"/></div></figure><h2 id="77e5" class="kn ji hi bd jj ko kp kq jn kr ks kt jr kh ku kv jv kj kw kx jz kl ky kz kd la bi translated">5.3信心丧失</h2><p id="3ae3" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">测量存在于边界框内的对象的置信度时的误差。</p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="er es my"><img src="../Images/c408f73f1ef31404c2231514d07f63d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*lOfJFqiKbFIJRDKy-8rtOg.png"/></div></figure><p id="e3f6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated">我们计算了两次信心损失，一次是1^obj，另一次是1^noobj.这样做是为了确保我们在没有检测到对象时降低置信度，而在检测到对象时提高置信度。</p><p id="3f85" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it kh iv iw ix kj iz ja jb kl jd je jf jg hb bi translated"><strong class="il hj">网络的总损失值是分类损失、定位损失&amp;置信度损失的总和。</strong></p><h1 id="9296" class="jh ji hi bd jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke bi translated">6.结论</h1><p id="13da" class="pw-post-body-paragraph ii ij hi il b im kf io ip iq kg is it kh ki iw ix kj kk ja jb kl km je jf jg hb bi translated">YOLO算法的理论到此结束。参考资料原文版<a class="ae lk" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank"> YOLO </a>论文&amp;一个最流行的YOLO框架<a class="ae lk" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank">暗网</a>。</p></div></div>    
</body>
</html>