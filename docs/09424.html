<html>
<head>
<title>Spark Parallel Job Execution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark并行作业执行</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spark-parallel-job-submission-38b41220397b?source=collection_archive---------0-----------------------#2020-09-06">https://medium.com/analytics-vidhya/spark-parallel-job-submission-38b41220397b?source=collection_archive---------0-----------------------#2020-09-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8dd7c094cf6a4df5e5387e8807183b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cVZgaMA_9uL2IVPR6zKYqw.jpeg"/></div></div></figure><p id="c251" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark以分解大任务和并行运行单个任务而闻名。但是，这并不意味着它可以并行运行两个独立的作业。本文将帮助您最大限度地提高Spark的并行性。</p><h2 id="1ade" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">异步编程</h2><p id="008d" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">这是一种并行编程，允许一个工作单元独立于主应用程序线程运行。当工作完成时，它通知主线程工作线程的完成或失败。在Scala中，你可以使用<em class="ko"> Future </em>来实现这一点。</p><h2 id="b9aa" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">Scala期货</h2><p id="9535" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">期货是Scala中执行异步编程的一种方式。一个<em class="ko"> Future </em>为您提供了一种在spark应用程序中并发运行作业的简单方法。</p><p id="3510" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们看看我们编写Spark代码的通常方式，然后看看<em class="ko">未来</em>能如何帮助我们。</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="32da" class="jo jp hi ku b fi ky kz l la lb"><em class="ko">val </em>employee = spark.read.parquet("s3://****/employee")<br/><em class="ko">val </em>salary = spark.read.parquet("s3://****/salary")<br/><em class="ko">val </em>ratings = spark.read.parquet("s3://****/ratings")<br/><br/><em class="ko">println</em>("Joining employee with salary")<br/>employee.join(salary, Seq("employee_id"))<br/>  .exportToS3AndJSON("s3://****/employee_salary")<br/><br/><em class="ko">println</em>("Joining employee with ratings")<br/>employee.join(ratings, Seq("employee_id"))<br/>  .exportToS3AndJSON("s3://****/employee_ratings")</span></pre><p id="a28d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的代码中，我们读取了3个数据集——员工、工资和评级。</p><ul class=""><li id="3309" class="lc ld hi is b it iu ix iy jb le jf lf jj lg jn lh li lj lk bi translated">在第一个语句中，我们基于Employee_ID连接Employee和Salary表，并将结果保存为parquet和JSON格式。</li><li id="cac9" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">在第二个语句中，我们基于Employee_ID连接Employee和Ratings表，并再次以parquet和JSON格式保存结果。</li></ul><p id="2b48" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第一个和第二个语句没有任何关系，但是Spark会按顺序运行它。如果你看一下Spark UI的图片，你会对此有一个更好的了解。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/5728feddf07de60613c71b4874d31ea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fBh5o_bziFOktAga1CRx0g.png"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">Spark UI</figcaption></figure><p id="ba05" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">作业ID 0 —首先启动并运行5.5分钟，第一个作业完成后，将开始第二个作业，依此类推。你也可以通过查看事件时间表来推断出同样的结论。所有作业都不会重叠，每个作业都是在前一个作业完成后拾取的。</p><p id="a6e7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果作业0利用了50%的群集，则剩余的50%将未被利用。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="2acb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们了解如何通过使用scala futures来提高利用率。下面是同样的代码，但是加入了未来的。</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="5765" class="jo jp hi ku b fi ky kz l la lb"><em class="ko">import </em>java.util.concurrent.Executors<br/><em class="ko">import </em>scala.concurrent.duration.Duration<br/><em class="ko">import </em>scala.concurrent.{Await, ExecutionContext, Future}</span><span id="5484" class="jo jp hi ku b fi mc kz l la lb"><em class="ko">//Allowing a maximum of 2 threads to run<br/>val </em>executorService = Executors.<em class="ko">newFixedThreadPool</em>(2)<br/><em class="ko">implicit val </em>executionContext = ExecutionContext.<em class="ko">fromExecutorService</em>(executorService)</span><span id="4975" class="jo jp hi ku b fi mc kz l la lb"><em class="ko">val </em>employee = spark.read.parquet("s3://****/employee")<br/><em class="ko">val </em>salary = spark.read.parquet("s3://****/salary")<br/><em class="ko">val </em>ratings = spark.read.parquet("s3://****/ratings")</span><span id="0d87" class="jo jp hi ku b fi mc kz l la lb"><em class="ko">val futureA = Future {<br/>   println</em>("Joining employee with salary")<br/>   employee.join(salary, Seq("employee_id"))<br/>     .exportToS3AndJSON("s3://****/employee_salary")<br/>   <em class="ko">println</em>("Future A Complete")<br/>   }</span><span id="dbce" class="jo jp hi ku b fi mc kz l la lb">val futureB = Future {<br/>   <em class="ko">println</em>("Joining employee with ratings")<br/>   employee.join(ratings, Seq("employee_id"))<br/>     .exportToS3AndJSON("s3://****/employee_ratings")<br/>   <em class="ko">println</em>("Future B Complete")<br/>   }</span><span id="9297" class="jo jp hi ku b fi mc kz l la lb">Await.result(futureA, Duration.inf)<br/>Await.result(futureB, Duration.inf)</span></pre><p id="f93d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些变化包括</p><ul class=""><li id="78b4" class="lc ld hi is b it iu ix iy jb le jf lf jj lg jn lh li lj lk bi translated">导入ExecutionContext以访问线程池。</li><li id="f92f" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">定义要运行的线程数量。</li><li id="3d4d" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">将转换包含在未来的构造中。</li><li id="45e7" class="lc ld hi is b it ll ix lm jb ln jf lo jj lp jn lh li lj lk bi translated">Await.result方法调用声明它将等待未来执行。</li></ul><p id="6daa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们通过查看Spark UI来了解一下这项工作现在是如何执行的。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/33716f179e3639310b1734b5b205f6bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wJ_GhaiPiEQ05q4L7afzrw.png"/></div></div></figure><p id="6836" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，您可以看到作业0和1几乎同时开始。您还可以从事件时间线中看到，这两个作业正在并行运行。</p></div><div class="ab cl lv lw gp lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="hb hc hd he hf"><p id="cacb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你喜欢这篇文章，请点击👏所以其他人会在媒体上看到它。</p></div></div>    
</body>
</html>