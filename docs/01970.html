<html>
<head>
<title>Can we predict stock market changes by applying Natural Language Processing (NLP) techniques to news headers?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们可以通过将自然语言处理(NLP)技术应用于新闻标题来预测股市变化吗？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-e2861d4a45a0?source=collection_archive---------13-----------------------#2019-11-24">https://medium.com/analytics-vidhya/introduction-e2861d4a45a0?source=collection_archive---------13-----------------------#2019-11-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/6c0a62614e27f0beea6bccbc36d6ca1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gOnKwGpvD-Q9rC_HnRJytw.png"/></div></div></figure><div class=""/><p id="c625" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">新闻标题与我们的股票市场有多大关联？本文应用了NLP数据预处理技术，如标记化、规范化、词干化和词条化。然后，我们使用word2vec库将单词转换为向量，看看是否可以创建一个预测模型。</p><h1 id="5c09" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">密码</h1><p id="17ba" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">你可以在GitHub链接找到这篇文章的代码。</p><h1 id="cc24" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">介绍</h1><p id="fb26" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">NLP怎么用才能赚钱？人类语言是各种内容的表现:情感、思想、事实和虚构。同样，媒体中使用的语言可以代表那个特定时期的世界。</p><p id="dcb5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这就是为什么我们决定参加由Kaggle主办的“<a class="ae kr" href="https://www.kaggle.com/aaron7sun/stocknews" rel="noopener ugc nofollow" target="_blank">每日股票市场预测新闻</a>”挑战赛。挑战试图看看主要新闻标题是否可以用来预测股票价格。<strong class="is hu">标题数据集</strong>是从<a class="ae kr" href="https://www.reddit.com/r/worldnews" rel="noopener ugc nofollow" target="_blank"> Reddit世界新闻频道</a> (/r/worldnews)收集的，新闻标题的重要性由它从Reddit用户那里获得的“投票”数量来衡量。最终数据集是从2008年6月8日到2016年7月1日每个日期的<strong class="is hu">前25个标题</strong>的集合。股票价格被选为道琼斯工业平均指数，取自同一日期跨度。</p><p id="555a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最终的挑战将是衡量标题的绝对重要性，并将这些权重乘以每个标题的情绪，以提供一般的逐日期情绪分析。这种情绪测量将能够预测股票的涨跌幅度。</p><p id="2222" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本文描述了上述过程的粗略简化。标题不是绝对重要，而是根据日期相对衡量，筛选出前25个标题。一旦入选25强，每一个头条都一视同仁。我们不是对每个标题进行综合情感分析，而是生成一个向量，聚合每个日期的某些词。最终的预测不是对下一级股票的预测，而是对股票可能上涨或下跌的简单二元分类。</p><h1 id="0204" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">资料组</h1><p id="59bc" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">该数据集由1，989个数据点组成，每个数据点对应于2008年6月8日至2016年7月1日期间的某个日期。每个日期数据点有27个特征。一个特征描述了确切的日期，另一个特征是对应于该日期的股票水平变化的二进制代码，以及新闻标题的25个特征。这个原始数据集存储在名为<strong class="is hu"> data </strong>的pandas数据集中。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="8c5f" class="lb jp ht kx b fi lc ld l le lf"># import data<br/>data = pd.read_csv('Combined_News_DJIA.csv')</span><span id="4316" class="lb jp ht kx b fi lg ld l le lf">print('data is %d data points with %d features'%(data.shape[0],data.shape[1]))<br/>data.head()</span></pre><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lh"><img src="../Images/c466004f2206038dd88d31ab4dcceb27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MWQniuF4jSGdIBBCNUCmDA.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">包含27个特征的1989个数据点的数据集。第一个功能是日期，第二个是DJIA标签，其余的是当天的25大新闻标题</figcaption></figure><h1 id="c3e8" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">数据预处理</h1><h2 id="3a3c" class="lb jp ht bd jq lm ln lo ju lp lq lr jy jb ls lt kc jf lu lv kg jj lw lx kk ly bi translated">数据清理</h2><p id="3edb" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">标题是从Reddit网站上刮下来的。因此，所有标题都在标题文本周围加上引号，并在文本前面加上标题HTML代码，如“b”。这在数据预处理的第一步中被清除。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="1c9b" class="lb jp ht kx b fi lc ld l le lf">dataClean.iloc[:,i]=dataClean.iloc[:,i].str.strip("b'")</span></pre><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lz"><img src="../Images/c539c5369cb5c487bf1f5f6fb8acb5ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uCGX5ubyVcbsxXT4"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">第一层清洗去除了开头的b '和结尾的'</figcaption></figure><h2 id="1fbf" class="lb jp ht bd jq lm ln lo ju lp lq lr jy jb ls lt kc jf lu lv kg jj lw lx kk ly bi translated">正常化</h2><p id="7104" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">通过删除标点符号、将所有字符转换为小写并将数字替换为文本“num”来规范化数据。标点符号取自字符串库。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="5c36" class="lb jp ht kx b fi lc ld l le lf">## All punctuations found in string.punctuation were substituted with blanks<br/>dataClean.iloc[:,i]=dataClean.iloc[:,i].str.translate(str.maketrans('', '', string.punctuation))<br/>dataClean.iloc[:,i]=dataClean.iloc[:,i].str.lower()</span></pre><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ma"><img src="../Images/863705653b021b83ad1403ce789c33bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4VxE92GRLz_t8ZSz"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">从清理过的文字到去掉的标点，“特大城市”变成了“特大城市”。</figcaption></figure><h2 id="4d0b" class="lb jp ht bd jq lm ln lo ju lp lq lr jy jb ls lt kc jf lu lv kg jj lw lx kk ly bi translated">标记化</h2><p id="ec24" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">然后，数据被单词标记。每个标题文本通过<strong class="is hu"> str.split() </strong>方法被空格分隔。从标记列表中识别停用词，并从词列表中移除停用词。停用词是从NLTK库的英语停用词列表中导入的。停用词存储在字典集中，以便更快地访问和识别。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="3182" class="lb jp ht kx b fi lc ld l le lf">dataClean.iloc[:,i]=dataClean.iloc[:,i].str.split()<br/>dataClean.iloc[:,i]=dataClean.iloc[:,i].apply(lambda sent: 'num' if isinstance(sent,float) else ['num' if token.isdigit() else token for token in sent])</span></pre><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mb"><img src="../Images/b4f2220b048b8074d5c468c12fd3f75a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Zs58ciOE-MHKfWMB"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">在标记化中，单个字符串对象被转换成字符串对象的列表，其中每个字符串对象是单个单词。在替换数字时，数字“55”被替换为文本“num”在删除停用词时，从列表中删除了单词“as”、“the”、“Into”、“a”和“in”。</figcaption></figure><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="4548" class="lb jp ht kx b fi lc ld l le lf">## Stopwords were imported from NLTK package. The list of stopwords was stored in a set for faster accessing.<br/>stops = set(stopwords.words('english'))</span></pre><p id="7a45" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每个标题每个日期清理过的单词都存储在<strong class="is hu">数据清理</strong>熊猫数据集中。</p><h1 id="be78" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">词干化和词汇化</h1><p id="34bf" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">这些词然后被蒸或词条化。这两个过程都试图识别语料库中每个单词的词根。词干处理使用NLTK包中的<strong class="is hu"> PorterStemmer </strong>类。词干处理会删除给定单词的后缀和前缀，即使生成的词根不是字典中的单词。词汇化过程使用了<strong class="is hu"> WordNetLemmatizer </strong>类，也来自NLTK包。词汇化识别单词的规范词根，其中结果单词是字典中的合法单词。在本文中，我们将记号符号化，但是代码也允许开关使用词干。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="8eed" class="lb jp ht kx b fi lc ld l le lf">if stemming:<br/>    porter = PorterStemmer()   <br/>    for i in range(2,dataNormal.shape[1]):<br/>        dataNormal.iloc[:,i]=dataNormal.iloc[:,i].apply(lambda x: [porter.stem(y) for y in x])<br/>    <br/>elif lemmatization:<br/>    lemmatizer = WordNetLemmatizer()<br/>    for i in range(2,data.shape[1]):<br/>        dataNormal.iloc[:,i]=dataNormal.iloc[:,i].apply(lambda x: [lemmatizer.lemmatize(y) for y in x])</span></pre><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mc"><img src="../Images/a5ebea7b4692793e03e23db51029580e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uDVSngnQXupuKWdM"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">词汇化将“tanks”后面的复数“s”删除为“tank”WordNetLemmatizer未能对"移动"、"朝向"、"据报道"、"完全"、"摧毁"和"格鲁吉亚"这些词进行词汇化，这些词本应是" moe "、"朝向"、"报告"、"完全"、"摧毁"和"乔治"。</figcaption></figure><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es md"><img src="../Images/cfa489aeb667944631b14a15f2f02a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Le6kQXEgPiGygoVZewAH_g.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">在一个更完整的例子中，标题开头的“b”Al-Qa ' EDA会聚合为“alqaeda”。“un-Islamic”中间的连字符也被删除为“unislamic”，而“un-Islamic”和“including”之间的连字符也被删除。</figcaption></figure><p id="1307" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结果数据存储在<strong class="is hu">数据正常</strong>数据集中。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es me"><img src="../Images/015f742e0d93933e5213d086551cd2bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d8LATo2LPRs9I73WgMrqoQ.png"/></div></div></figure><h1 id="a129" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">数据矢量化</h1><p id="d6c5" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">为了从整体上分析整个日期的单词，我们将使用数据矢量化过程。每个单词将被转置到高维空间中的一个向量，这将允许将每个日期的单词聚合到一个向量中。</p><h2 id="fc6e" class="lb jp ht bd jq lm ln lo ju lp lq lr jy jb ls lt kc jf lu lv kg jj lw lx kk ly bi translated">数据扁平化</h2><p id="1144" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">目前，数据集是1989个数据点(1989年的日期)，有27个特征，对应于日期、标签和25个标题。在这个模型中，我们不区分标题的排名，所以没有额外的权重给予具有最大点赞量的标题和在当天标题中排名第25的标题。因此，我们将标题简化为每个日期的一个单词列表。展平后的数据存储在<strong class="is hu"> dataFlat </strong>数据集中，该数据集中有1989个数据点，具有三个特征。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mf"><img src="../Images/045a506b0becfe1e9fcdd62bf35ef14c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c82btBWEqlpXQe763ab-jQ.png"/></div></div></figure><h2 id="7269" class="lb jp ht bd jq lm ln lo ju lp lq lr jy jb ls lt kc jf lu lv kg jj lw lx kk ly bi translated">数据矢量化</h2><p id="55a0" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">词与词之间没有直接的可比性。<strong class="is hu"> Gensim </strong>包的<strong class="is hu"> Word2Vec </strong>类创建了一个表示每个单词的数字向量。向量代表意义以及单词之间的关系。使用100维空间以合理的准确度表示向量，如果该词在语料库中重复至少5次，则创建向量。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mg"><img src="../Images/6aa087266a98a53024627f7978227cda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vQKPaNUulXBp9_ZQqZpkMw.png"/></div></div></figure><p id="2b25" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> Word2Vec模型</strong>花了1.4秒来训练，结果产生了一个<strong class="is hu">10197个单词的字典</strong>。粗略地看一下Word2Vector模型，可以看出该模型相当准确。例如，向量形式最接近“战争”对应向量的单词是“人类”、“犯罪”、“卡特尔”和“伊拉克”。它还表明，正如预期的那样，“和平”和“恐怖”这两个词与“战争”的关联度更高，而不是“学校”。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mh"><img src="../Images/bc8beea14105f01505e85596032b00f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AORJgLl7Qz1xzwtMG0yT1Q.png"/></div></div></figure><p id="c388" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">dataFlat数据集通过首先移除没有出现在W2V模型中的单词来进行矢量化。剩余的单词具有相应的100维向量，这些向量按日期保存在一个<strong class="is hu"> words_in_date </strong>列表中。对每个日期形成的向量取平均值。因此，单个100维向量现在表示每个数据点(日期)，作为单词字典中显示的该日期标题<strong class="is hu"> <em class="mi">和</em> </strong>中使用的所有单词的代理。该平均向量作为附加列保存到<strong class="is hu">数据平面</strong>，成为<strong class="is hu">数据向量</strong>。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mj"><img src="../Images/eddbca51b973df461c0fc1417374f817.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*egn7LChTNHVLf8Dox1dbQQ.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">dataVector数据集添加了“Average”列，该列存储100维向量，该向量对当天前25条新闻中记录的所有词典单词进行平均</figcaption></figure><h1 id="74e5" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">数据分割</h1><p id="611b" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">DataVector是1989个数据点，具有四个特征:日期、标签、单词列表，最后是一个100维向量，即每个日期的平均向量值。对于分类器模型，它只对每个向量的100个特征感兴趣。因此，这100个维度在<strong class="is hu">数据模型</strong>中各自扩展到自己的列，这是具有102个特征的1989个数据点。两个非向量维特征是日期和DJIA变化标签。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mf"><img src="../Images/733a8177904add0f88ca9d59ea6c0874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ti2BmowISoF0hkvmcwDVTg.png"/></div></div></figure><p id="91e7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过按日期2014年12月31日分割数据集，创建了一个<strong class="is hu">训练/测试数据集</strong>。这导致<strong class="is hu"> 1610个向量</strong>在训练数据集中，而<strong class="is hu"> 379个向量</strong>在测试数据集中，一个<strong class="is hu">大约80.9%到19.1%的分割</strong>。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ca"><img src="../Images/eb9ca34a6aecf6df7d9a7e9abc928f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kS_eptRqjIQMV_mfCp6_vw.png"/></div></div></figure><h1 id="ed33" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">建模</h1><p id="ee3b" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">构建了5种不同的模型来进行二元分类预测。所有模型都取自<strong class="is hu"> scikit-learn包</strong>，这些模型是随机森林分类器(“RF”)、XG Boost(“XGB”)、逻辑回归(“LogReg”)、支持向量分类器(“SVC”)和多层感知器分类器(“MLP”)。</p><h1 id="77c0" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">结果</h1><p id="cac8" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">所有五个模型都预测了<strong class="is hu">接近概率的结果</strong>。结果几乎与<strong class="is hu">准确度</strong>指标和<strong class="is hu"> ROC AUC </strong>(曲线下的接收器工作特性面积)指标相同，后者是Kaggle竞赛定义的待测指标。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mk"><img src="../Images/cb5f9843e7e0bf2de958e910d8d3d1b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2QM0sNoqT6zW9wu-"/></div></div></figure><p id="afc3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">奇怪的是，LogReg、SVC和MLP模型都预测所有测试数据点的结果为“1”(即DJIA将上升)。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ml"><img src="../Images/65f2fccd00d62e4570d50b8a0bd4342e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pzib2D8AzflVg1TlHjpcrg.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">五个模型的混淆矩阵。注意，对数、SVC和MLP模型预测所有数据点都是正的</figcaption></figure><p id="ab56" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">仔细观察ROC曲线可以发现，RF的ROC曲线相对平滑，而XGB、LogReg和SVC的ROC曲线更为崎岖，而MLP的ROC曲线是绝对线性的。但是所有五个模型的ROC曲线都接近简单随机分类线，导致AUC分数接近-0.5。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es mm"><img src="../Images/1784ceaff020d4aa4233377af4428443.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*93cJyxtqCyf87lBx"/></div></figure><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es mm"><img src="../Images/b038e057ed8fa17c1a8216b2fcf63cb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*Q1u7gcOxAJulMBmK"/></div></figure><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es mm"><img src="../Images/7652f3e45a1b06a303065c024c40b995.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*tb4FDB7b55uYjGJ1"/></div></figure><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es mm"><img src="../Images/a6cc20d24e6fbe0eee4e34286aaed2ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*GFld43nVKiun8ubH"/></div></figure><figure class="ks kt ku kv fd hk er es paragraph-image"><div class="er es mm"><img src="../Images/bf2a250939c18cd85c5f01f1d06b5734.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*wuhxQjkvZtdolZoC"/></div></figure><h1 id="64c9" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">结论</h1><p id="ee7f" class="pw-post-body-paragraph iq ir ht is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">从我们的代码得出的结论是，我们的模型不亚于DJIA股票价格的随机预测器。次优结果可能是由以下任何原因或任何原因组合造成的。</p><p id="6751" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，<strong class="is hu">平均机制</strong>可能会使最终的100维向量携带<strong class="is hu">没有意义的信息</strong>。在我们的数据集中，对应于单词的100维向量被数学平均以创建单个向量。我们的假设之一是，这种平均的结果可以代表当时的经济情绪。如果任何有意义的信息在大多数情况下相互抵消，或者如果无意义的信息(如由停用词传达的信息)在平均值中占主导地位，则得到的平均向量彼此不会有太大不同。</p><p id="2a9f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其次，有意义的信息可能会在<strong class="is hu">矢量化过程中丢失。</strong>在我们当前的模型中，某个特定单词在当天新闻标题中的<strong class="is hu">频率</strong>被忽略。然而，有意义的信息可能不是“战争”或“恐怖”这个词被展示，而是在那个特定的日子里<strong class="is hu">如何经常</strong>被使用。当矢量化过程不能准确捕捉矢量的方向时，这种加权系统尤其重要。</p><p id="e1df" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第三，<strong class="is hu">矢量化过程</strong>不足以表示单词的<strong class="is hu">情感</strong>。理论上，Word2Vec模型应该能够用足够大的语料库来捕捉这样的情感。但是从战争与和平和战争与恐怖的例子来看，战争与和平比战争与恐怖更相似。这可能是因为语料库不足以建立情感分析，并且相似性更多地受共现的影响。当感情上对立的词(如“战争”和“和平”)经常一起出现时，这种方法是有害的。</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mn"><img src="../Images/ffec9f40beb8dce2db27f0d007edcc8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RwfD19YM9BE4KkmHrTK05g.png"/></div></div></figure><p id="6d21" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，很可能前25条新闻标题的内容与股价变化没有太大关联。虽然股票价格受实时事件的影响很大，但世界经济是一个新兴产业，同一条新闻在不同的背景下可能会对股票价格产生不同的影响。也许“25条”新闻标题的信息量不足以捕捉真实世界的情况。也许Reddit选择“头条”新闻的投票机制并不能准确衡量一篇新闻的重要性。</p></div></div>    
</body>
</html>