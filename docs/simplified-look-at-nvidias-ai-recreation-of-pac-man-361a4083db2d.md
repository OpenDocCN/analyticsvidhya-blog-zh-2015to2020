# 简化看英伟达的 AI 再造的吃豆人

> 原文：<https://medium.com/analytics-vidhya/simplified-look-at-nvidias-ai-recreation-of-pac-man-361a4083db2d?source=collection_archive---------18----------------------->

为了庆祝《吃豆人》游戏首次在日本电子游戏厅发布 40 周年，并自走上全球明星之路以来，英伟达开始致力于用人工智能和机器学习重新创造这款游戏。

# 实际发生了什么？

Nvidia 使用他们自己开发的名为 GameCan 的神经网络模型，该模型旨在模仿计算机游戏引擎。这个模型是通过分析游戏如何互动，游戏看起来如何，以及游戏的规则是什么，通过 100 个小时的游戏来训练的。

你可能会很快认为 GameCan 用通常与游戏开发相关的传统代码重新创建了这个游戏。但是 GameCan 通过理解基于用户输入的游戏应该是什么样子来实现娱乐。

一个简单的例子是，GameCan 模型已经观察了 Pac-Man 足够长的时间，可以理解每次 Pac-Man 移动到一个小的黄色圆圈上，这个圆圈就会从屏幕上消失。所以这个模型现在可以直观地理解吃豆人吃点时的样子。

该模型不是输出一个传统的编码游戏，它实际上只是一帧一帧地输出模型根据它在过去 100 多个小时中学习的所有规则和视觉元素认为游戏应该看起来像的每一帧。

> 我们想看看人工智能是否可以通过观看代理人在游戏中移动的剧本来学习环境的规则。确实如此。

# 游戏引擎

GameGAN 版依靠神经网络，而不是传统的游戏引擎，来生成吃豆人的环境。人工智能跟踪虚拟世界，记住已经生成的内容，以保持帧与帧之间的视觉一致性。

![](img/214fe087c486b0efe43722dcddab0760.png)

GameGAN 由三个模型组成:一个**动态引擎**用于维护循环更新的内部状态变量，一个外部**内存模块**用于记住模型生成的内容，一个**渲染引擎**用于在每个时间点解码输出图像。

核心模块是端到端训练的神经网络。在训练期间，GameGAN 接受用户命令——剧本和键盘动作——然后根据这些命令预测下一帧。GameGAN 因此可以从图像和动作对的展开中学习，而不需要访问底层游戏逻辑或引擎。

![](img/1cb86275be35e51da4de4c1e17718d98.png)

GameGAN 学习遵循用户命令 Pacman 如何移动——以及其他游戏规则。当一个胶囊被消耗时，它将鬼变成紫色，并且也学习他们的政策。你可以看到幽灵在正常状态下追吃豆人，但是一个胶囊消耗完就开始跑了。

GameGAN 还获得了从动态组件(如射火球的敌人)中分离静态组件(如背景和蓝色墙壁)的能力。在下面的 Pac-man GIF 中，观察它是如何记住它生成的布局(蓝色墙壁)的。当 Pac-man 回到相同的位置时，它会学习恢复生成的布局。

# GameCAN 的未来

想象一下，能够在游戏世界的视觉风格和“规则”上训练一个人工智能，并让它产生在那个世界的背景下有意义的新艺术资产。即使是程序生成也需要大量的初始工作来设置。

> 这可能是一种简化这些工作的方法。—黎巴嫩语

传统的自主机器人使用模拟器进行训练，因此它可以在被释放到现实世界之前学习环境的规则。对于开发人员来说，创建一个模拟器是一个耗时的过程，他们必须编写关于对象如何相互作用以及光线如何在环境中工作的规则。

GameGAN 介绍了为类似任务编写模拟器的工作有一天可能会被简单地训练神经网络所取代。

> 我们最终可能会有一个人工智能，它可以学习模仿驾驶规则和物理定律，只需通过观看视频和看到代理在环境中采取行动即可

NVIDIA Research 在全球拥有 200 多名科学家，专注于人工智能、计算机视觉、自动驾驶汽车、机器人和图形等领域。这个项目的潜力是巨大的，可以标志着 ML 和 AI 可视化学习的一个关键阶段。

Nvidia 计划在今年夏天公开发布 GameGAN 生成版本的*吃豆人*。