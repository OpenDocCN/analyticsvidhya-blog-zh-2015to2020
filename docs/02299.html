<html>
<head>
<title>Introduction to Computer Vision with Baseline VGG Blocks on the CIFAR-10 Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在CIFAR-10数据集上使用基线VGG块的计算机视觉简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-computer-vision-with-baseline-vgg-blocks-on-the-cifar-10-dataset-731d19439922?source=collection_archive---------5-----------------------#2019-12-10">https://medium.com/analytics-vidhya/introduction-to-computer-vision-with-baseline-vgg-blocks-on-the-cifar-10-dataset-731d19439922?source=collection_archive---------5-----------------------#2019-12-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f14553862997d06ed57bafeec9c42eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NjFNfUd8WyWI7xqN"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@jeroendenotter?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">耶鲁安穴獭</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><p id="e008" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">根据<a class="ae iu" href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener ugc nofollow" target="_blank">维基百科</a>，<br/>的说法，计算机视觉是一个跨学科的科学领域，研究如何让计算机从数字图像或视频中获得高层次的理解。</p><p id="4d6a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">多年来，计算机视觉已经取得了很大的进步，当一家名为AlexNet的CNN在<a class="ae iu" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>挑战赛中实现了标记图片的艺术表现时，它取得了重大的飞跃。</p><p id="7652" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在像Tensorflow和PyTorch这样的深度学习框架越来越流行，只需要几行代码就可以相对容易的实现各种深度学习算法。</p><p id="344c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这里，我将使用不同数量的VGG块以及一些众所周知的正则化技术来分类来自CIFAR-10数据集的对象并比较结果。</p><p id="5ad4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">CIFAR-10是计算机视觉和深度学习中使用的标准数据集。该数据集主要用于计算机视觉研究。该数据集由60，000张32*32像素的彩色照片组成，这些照片来自10类物体，如飞机、汽车、鸟类等。类别标签及其相关的标准整数值如下所示:</p><ul class=""><li id="60ee" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">0:飞机</li><li id="c099" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">1:汽车</li><li id="fc86" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">2:鸟</li><li id="791f" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">3:猫</li><li id="e46a" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">4:鹿</li><li id="02b9" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">5:狗</li><li id="3246" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">6:青蛙</li><li id="d128" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">7:马</li><li id="5a68" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">8:船</li><li id="2f3e" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">9:卡车</li></ul><p id="109e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据集中的图像非常小，比典型的照片小得多。CIFAR-10是一个很好理解的数据集，广泛用于计算机视觉算法的基准测试。问题被有效地“解决”。达到80%的分类准确率是比较容易的。然而，通过使用深度学习卷积神经网络，我们可以在测试数据集上获得90%以上的分类精度。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/93f355836b31d5eadca76369c910e807.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*ecE7n8WVVVCQChEvtFau3Q.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">CIFAR-10数据集</figcaption></figure><p id="affc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面的示例从Keras API加载CIFAR-10数据集，并绘制一个示例。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="9ccc" class="kr ks hi kn b fi kt ku l kv kw">#load the CIFAR-10 dataset and plot a sample image </span><span id="7ad2" class="kr ks hi kn b fi kx ku l kv kw">from tensorflow import keras <br/>from keras.datasets import cifar10 <br/>import matplotlib.pyplot as plt </span><span id="4146" class="kr ks hi kn b fi kx ku l kv kw">#load dataset <br/>(trainX, trainY), (testX, testY) = cifar10.load_data()</span><span id="9806" class="kr ks hi kn b fi kx ku l kv kw">#classes array for the 10 different classes of images in the dataset<br/>classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']</span><span id="b5bc" class="kr ks hi kn b fi kx ku l kv kw">#summarize the loaded dataset <br/>print('Train: X = %s, y = %s' %(trainX.shape, trainY.shape))<br/>print('Test: X = %s, y = %s' %(testX.shape, testY.shape))</span><span id="8c22" class="kr ks hi kn b fi kx ku l kv kw">#plot a sample image </span><span id="1d84" class="kr ks hi kn b fi kx ku l kv kw">plt.figure()<br/>plt.imshow(trainX[0])<br/>plt.grid(False)<br/>plt.xlabel(classes[trainY[0].item()])<br/>plt.show()</span></pre><p id="c34b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到，训练集中有50000个样本，测试集中有10000个样本。稍后，我们将测试集分成两个不同的子集，验证集和测试集，我们将在训练期间和之后连续使用它们来验证我们的模型。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="1913" class="kr ks hi kn b fi kt ku l kv kw">Train: X = (50000, 32, 32, 3), y = (50000, 1)<br/>Test: X = (10000, 32, 32, 3), y = (10000, 1)</span></pre><p id="21cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">还从训练集中绘制了样本图像。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/ff815bde795c340cf55a01d63af07cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*1Pc5sIbDSZZluhNJYcXp8A.jpeg"/></div></figure><p id="62f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">很明显，与正常图像相比，该图像非常小并且分辨率低，因此人眼很难看清图像中包含的内容。低分辨率很可能是顶级算法在数据集上能够实现的有限性能的原因。</p><p id="eaa5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">加载数据集后，我们可以进入数据预处理步骤。</p><p id="cfe9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们知道在CIFAR-10数据集中有10个类，并且这些类被表示为唯一的整数。因此，我们可以对每个样本的类元素使用一个热编码，将整数转换成10个元素的二进制向量，其中1表示类值的索引。我们可以使用Keras为一个热编码提供的to _ categorical实用函数。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="c5c3" class="kr ks hi kn b fi kt ku l kv kw">#one hot encode the target <br/>trainY = keras.utils.to_categorical(trainY)<br/>testY = keras.utils.to_categorical(testY)</span></pre><p id="738d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">load_dataset()函数实现了这些步骤，并可用于加载数据和对类元素进行热编码。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="a459" class="kr ks hi kn b fi kt ku l kv kw">def load_dataset():<br/>    #load dataset<br/>    (trainX, trainY),(testX, testY) = cifar10.load_data()<br/>    #one hot encode the target <br/>    trainY = keras.utils.to_categorical(trainY)<br/>    testY = keras.utils.to_categorical(testY)<br/>    return trainX, trainY, testX, testY</span></pre><p id="d366" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们知道数据集中图像的像素值是0到255之间的无符号整数。我们需要将像素值标准化，例如将它们重新调整到范围[0，1]。这包括将像素值除以最大值。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="8a84" class="kr ks hi kn b fi kt ku l kv kw">train_norm = train_norm / 255.0<br/>test_norm = test_norm / 255.0<br/>valid_norm = valid_norm / 255.0</span></pre><p id="9dff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">normalize()函数实现了这一点:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="aa03" class="kr ks hi kn b fi kt ku l kv kw">def normalize(train, test,valid): <br/>    #change the values from unsigned int to float<br/>    train = train.astype('float32')<br/>    test = test.astype('float32')<br/>    valid = valid.astype('float32')</span><span id="dbb4" class="kr ks hi kn b fi kx ku l kv kw">    #Normalize the pixel values by dividing by 255<br/>    train_norm = train / 255.0<br/>    test_norm = test/ 255.0<br/>    valid_norm = valid / 255.0<br/>    <br/>    return train_norm, test_norm, valid_norm</span></pre><p id="693f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还需要定义一个验证集，用于在训练期间验证我们的模型。validation_split()函数实现了这一点:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="b9db" class="kr ks hi kn b fi kt ku l kv kw">def validation_split(testX, testY, valid_X, valid_Y, v_split):<br/>    index_of_validation = int(v_split * len(testX))<br/>    valid_X.extend(testX[-index_of_validation:])<br/>    valid_Y.extend(testY[-index_of_validation:])<br/>    trainX = trainX[:-index_of_validation]<br/>    trainY = trainY[:-index_of_validation]<br/>    return testX, testY, np.asarray(valid_X), np.asarray(valid_Y)</span></pre><p id="f75f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">训练集和验证集将在训练期间使用，而测试集将在模型完成训练后用于评估模型。将数据拆分为单独的训练集、测试集和验证集是一种很好的做法，这样可以在对验证集进行训练期间以及在对模型以前从未见过的测试集进行训练之后对模型进行评估。</p><p id="82e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">定义神经网络模型</strong></p><p id="993b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在对图像进行预处理之后，我们需要一种方法来定义我们的神经网络模型。在这里，我们将尝试不同版本的VGG模型，以测试其在CIFAR-10数据集上的准确性。可以调用define_model()函数来获取CNN模型。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="bf7d" class="kr ks hi kn b fi kt ku l kv kw">#define the CNN model <br/>def define_model():<br/>    #............<br/>    #............<br/>    return model</span></pre><h1 id="2610" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">评估模型</strong></h1><p id="9d36" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">在定义了模型之后，我们需要对模型进行拟合和评估。我们将使用训练集来训练模型，使用验证集来计算训练过程中的损失和准确性。稍后，将在单独的测试集上训练后评估该模型。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="0f16" class="kr ks hi kn b fi kt ku l kv kw"># fit model <br/>history = model.fit(trainX,trainY, epochs = 50, batch_size = 64,    validation_data = (testX, testY), verbose = 1)</span></pre><p id="4504" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦模型合适，我们就可以直接在验证集上评估它。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="32a4" class="kr ks hi kn b fi kt ku l kv kw"># evaluate model<br/>_, acc = model.evaluate(validX, validY, verbose=0)</span></pre><p id="7cf8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">显示结果</strong></p><p id="8e17" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦模型被评估，我们就可以展示结果。</p><p id="7cb9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有两个关键方面需要提出:训练期间模型学习行为的诊断和模型性能的评估。</p><p id="4847" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，诊断包括创建一个线图，显示训练和测试集在训练期间的模型性能。这些图对于了解模型是过度拟合、欠拟合还是非常适合数据集很有价值。</p><p id="c8e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将创建一个有两个支线剧情的单一图形，一个是损失，一个是准确性。蓝线表示模型在训练数据集上的表现，橙线表示模型在坚持测试数据集上的表现。给定收集的训练历史，下面的<em class="mb">summary _ diagnostics()</em>函数创建并显示该图。情节被保存到文件，特别是与脚本同名的文件，扩展名为“<em class="mb"> png </em>”。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="90b2" class="kr ks hi kn b fi kt ku l kv kw"># plot diagnostic learning curves<br/>def summarize_diagnostics(history):<br/>    # plot loss<br/>    plt.subplot(211)<br/>    plt.title('Cross Entropy Loss')<br/>    plt.plot(history.history['loss'], color='blue', label='train')<br/>    plt.plot(history.history['val_loss'], color='orange',  label='test')</span><span id="a993" class="kr ks hi kn b fi kx ku l kv kw">    # plot accuracy<br/>    plt.subplot(212)<br/>    plt.title('Classification Accuracy')<br/>    plt.plot(history.history['accuracy'], color='blue', label='train')<br/>    plt.plot(history.history['val_accuracy'], color='orange', label='test')<br/>    plt.show()</span><span id="be37" class="kr ks hi kn b fi kx ku l kv kw">    # save plot to file<br/>    filename = sys.argv[0].split('/')[-1]<br/>    plt.savefig(filename + '_plot.png')<br/>    plt.close()</span></pre><p id="1c15" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还可以将模型的分类精度打印为:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="f98b" class="kr ks hi kn b fi kt ku l kv kw">print(‘&gt; %.3f’ % (acc * 100.0))</span></pre><p id="9558" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在需要一个函数来驱动培训和测试过程。下面定义的test_model()函数执行此操作，并可用于启动给定模型的评估:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="d24d" class="kr ks hi kn b fi kt ku l kv kw"># run all the defined functions for evaluating a model<br/>def test_model():<br/> # load dataset<br/> train_X, train_Y, testX, testY = load_dataset()<br/> #get validation set <br/> valid_X = []<br/> valid_Y = []<br/> trainX, trainY, validX, validY = validation_split(train_X, train_Y, valid_X, valid_Y,v_split=0.1)<br/> <br/> # normalize the data<br/> trainX, testX,validX = normalize(trainX, testX,validX)<br/> # define model<br/> model = define_model()<br/> # fit model<br/> history = model.fit(trainX, trainY, epochs=50, batch_size=64, validation_data=(validX, validY), verbose=1)<br/> # evaluate model<br/> _, acc = model.evaluate(testX, testY, verbose=0)<br/> print(‘&gt; %.3f’ % (acc * 100.0))<br/> # learning curves<br/> summarize_diagnostics(history)</span></pre><p id="a4e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦我们调用test_model()函数，模型将被训练和评估。</p><p id="d707" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是，我们还没有定义一个合适的CNN模型，所以这个脚本还不能运行。</p><h1 id="d6fa" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">如何开发基线模型</strong></h1><p id="9969" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">基线模型将建立一个最低的模型性能，我们所有的其他模型都可以与之进行比较。</p><p id="042b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用不同版本的VGG模型。该架构包括堆叠带有小型3*3滤波器的卷积层，然后是最大池层。这些层一起形成一个块，并且这些块可以重复，其中每个块中的滤波器数量随着网络的深度而增加，例如对于模型的前四个块为32、64、128、256。在卷积图层上使用相同的填充，以确保输出要素的高度和宽度与输入相匹配。</p><p id="0690" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以在CIFAR-10问题中探索这种体系结构，并将一个模型与这种具有1、2、3和4个数据块的体系结构进行比较..</p><p id="1948" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每一层将使用ReLU激活函数和“he_uniform”权重初始化，这通常是最佳实践。例如，两个街区的VGG式建筑可以在Keras中定义如下:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="ca62" class="kr ks hi kn b fi kt ku l kv kw">#example of a 2 block VGG architecture </span><span id="ebcf" class="kr ks hi kn b fi kx ku l kv kw">model = Sequential()<br/>model.add(Conv2D(32,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (32,32,3)))<br/>model.add(Conv2D(32,(3,3), activation = 'relu', kernel_initializer =  'he_uniform', padding = 'same'))<br/>model.add(MaxPooling2D((2,2)))<br/>model.add(Conv2D(64,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))<br/>model.add(Conv2D(64,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))<br/>model.add(MaxPooling2D((2,2)))<br/>.....</span></pre><p id="3b79" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这定义了模型的特征检测器部分。这将通过模型的分类器部分来耦合，该分类器部分解释特征并预测给定照片属于哪个类别。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="d031" class="kr ks hi kn b fi kt ku l kv kw">#example output part of the model <br/>model.add(Flatten())<br/>model.add(Dense(128, activation = 'relu', kernel_initializer =  'he_uniform'))<br/>model.add(Dense(10, activation = 'softmax'))</span></pre><p id="205f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该模型将使用随机梯度下降进行优化。我们将使用0.001的学习率和0.9的动量。该模型将优化多类分类所需的分类交叉熵损失函数，并将监控分类准确性。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="5b3c" class="kr ks hi kn b fi kt ku l kv kw">#compile model <br/>opt = SGD(lr = 0.001, momentum = 0.9)<br/>model.compile(optimizer = opt, loss = ‘categorical_crossentropy’, metrics = [‘accuracy’])<br/>return model</span></pre><p id="5ef5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在有足够的元素来定义我们的VGG风格的基线模型。我们将有1、2和3个VGG模块的不同模型架构，这要求我们定义不同版本的define_model函数，这些函数都在下面提供。</p><p id="a73b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将依次看看每个define_model()函数以及对结果测试的评估。</p><h1 id="93d9" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">VGG街区1号</h1><p id="e129" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">一个VGG块的define_model()函数如下所示:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="7f53" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">运行模型会打印出测试数据集的分类准确度。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es me"><img src="../Images/047db9a16467f663069ebd5013608088.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*rFCamu_8yXdj6iL7u1GTpA.jpeg"/></div></figure><p id="e598" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这种情况下，我们可以看到该模型实现了大约67%的分类准确率。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/124b9f3bc2c3e2e87c3417f30372c0c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*icNTWO68UWJakt1UaGz0IA.jpeg"/></div></figure><p id="3bb8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这里，我们可以清楚地看到模型在训练数据集上是过拟合的。第一个图绘制了训练集相对于测试集的交叉熵损失，显示了训练集的损失持续减少，而测试集中的损失先减少，然后继续增加。第二张图描绘了训练集相对于测试集的分类准确度，也遵循类似的趋势。</p><h1 id="9ba6" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak"> 2 VGG街区</strong></h1><p id="29b2" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">两个VGG块的define_model()函数如下所示:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="e648" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">运行该模型打印出分类准确度，其略好于我们的1-VGG块，接近71.5%，并且还在训练数据集和测试数据集上绘制交叉熵损失和分类准确度。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/2896e12faf2cc9043c8929fa81deac06.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*P2oXylhQsJtYjk17OvuVrA.jpeg"/></div></figure><p id="955a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">与1-VGG区块一样，模型在训练数据集上过度拟合。测试数据集上的交叉熵损失正在减少，直到大约15个时期，然后开始增加，而训练集上的损失持续减少。分类准确度图也遵循类似的趋势。</p><h1 id="c746" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">3个VGG街区</h1><p id="4c94" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">3个VGG块的define_model()函数如下所示:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="7708" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样，模型也在改进，但不是很大。在验证集上的分类精度刚刚超过74%,而交叉熵损失和分类精度图显示了与1和2个VGG块相似的趋势。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/e274c6a33b4422677d9a78c7a810873b.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*95S7f_A_qHUITvmAw_RrrA.jpeg"/></div></figure><h1 id="c4af" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">4个VGG街区</h1><p id="37c6" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">当我们实施4 VGG区块模型时，与3 VGG区块模型相比，模型精度没有显著变化。然而，与3 VGG块模型相比，该模型明显过度拟合，如训练和测试数据集上交叉熵损失的差异所示。因此，我们将使用3 VGG区块模型作为我们的基线模型。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/bb4a9c5088cd7344968d8bf3a51153a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*4P9OwNBG_QvrmIvZ2JdfIQ.jpeg"/></div></figure><p id="5638" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们使用不同的正则化技术来尽可能地改进模型。</p><h1 id="a80b" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">辍学正规化</h1><p id="12c6" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated"><em class="mb">据</em> <a class="ae iu" href="https://en.wikipedia.org/wiki/Dropout_(neural_networks)" rel="noopener ugc nofollow" target="_blank"> <em class="mb">维基百科</em></a><em class="mb">——<br/>术语“辍学”指的是在神经网络中放弃单元(隐藏的和可见的)。</em></p><p id="4c42" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在每个训练阶段，个体节点或者以概率<em class="mb"> 1-p </em>退出网络，或者以概率<em class="mb"> p </em>保留，从而留下简化的网络；被删除节点的输入和输出边也被删除。</p><p id="d5af" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里，我们将在每个VGG块后使用固定的丢弃概率0.2，这意味着20%的节点将被忽略，只有80%的节点将被保留。</p><p id="023b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可以通过向神经网络添加新的脱落层来将脱落添加到模型中，其中移除节点的概率作为参数传递。</p><p id="5daf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于3个VGG模块以及0.2的压差，define_model()函数如下所示:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="725a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当该模型被训练100个时期时，我们实现了大约81.5%的分类准确度，这显著高于我们的基线3块VGG模型。检查交叉熵和分类准确度图，我们可以看到模型在以后的时期开始重新拟合训练数据集。验证集上的分类精度几乎恒定在80%左右，而训练集上的精度持续下降。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/fcb6035ae0e1a7cdedf1dcbd83b20da9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*fuAckXLFBDyE9P3lhTZL9Q.jpeg"/></div></figure><p id="b4fb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们在连续的VGG块上分别使用变化的丢弃概率0.2、0.3、0.4，并且在密集层上使用0.5的丢弃时，在测试集上的分类准确度增加到大约83.5%。也减少了模型对训练集的过度拟合。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/ecf443b665fa0242c6ca7fc5f5d3a71e.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*UxZ40tddS6zzXGBfJCeilA.jpeg"/></div></figure><h1 id="b049" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">数据扩充</h1><p id="f24a" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">图像数据扩充是一种可用于通过在数据集中创建图像的修改版本来人为扩展训练数据集的大小的技术。</p><p id="05ba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了进一步改进我们的模型，我们可以对现有模型使用数据扩充，该模型包含具有不同压差的3个VGG区块。</p><p id="c1b5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可以使用ImageDataGenerator类在Keras中实现数据扩充。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="de6d" class="kr ks hi kn b fi kt ku l kv kw">#create data generator<br/>datagen = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True)</span><span id="83d4" class="kr ks hi kn b fi kx ku l kv kw">#iterator<br/>train = datagen.flow(trainX, trainY, batch_size = 64)</span></pre><p id="c609" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在定义了单个epoch中的批次数之后，我们可以将迭代器传递给model.fit_generator()函数。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="295c" class="kr ks hi kn b fi kt ku l kv kw">steps = int(trainX.shape[0] / 64)<br/>#fit model<br/>history = model.fit_generator(train, steps_per_epoch = steps, epochs = 200, validation_data=(validX, validY), verbose=1)</span></pre><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/b5bcc7acbdaad3f117ecff5a97ba19a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*_N4FbUZpNlAzKmIoVRKVEA.jpeg"/></div></figure><p id="eada" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在训练了多达200个时期后，我们可以看到测试数据集上的精度略微下降到83%，但该模型概括得很好，如两个图上的训练精度和验证精度之间的差异非常小所示。即使直到200个历元，交叉熵损失也在不断减少。进一步训练模型，可能达到400-500个历元，肯定会改进模型。</p><h1 id="164d" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">批量标准化</h1><p id="c1c7" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">接下来，我们添加批量标准化，希望能够稳定网络并缩短训练时间。添加批处理规范化后的define_model()函数如下所示:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="182b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们对模型进行400个时期的训练时，我们在测试数据集上获得了88%的分类准确率。此外，交叉熵损失图和随后的分类准确度图显示，该模型概括得相当好。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/5b798f8181dc55f3bf578c101bd3e9f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*CaC2o0Dn0de0fA8Mtxrr6g.jpeg"/></div></figure><p id="0fef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面提供了具有所有正则化的神经网络模型的最终实现:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mc md l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">最终实现了3个VGG块以及不同的正则化技术</figcaption></figure><h1 id="940e" class="kz ks hi bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">结论</h1><p id="59b5" class="pw-post-body-paragraph iv iw hi ix b iy lw ja jb jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">我们探索了各种不同的方法来扩展用于图像分类的VGG块。最终模型学习良好，甚至在400个时期之后，交叉熵损失似乎在减少。我们还可以通过改变不同的超参数来进一步优化我们的模型，例如学习率、时期数等。通过将优化器更改为Adam、RMSprop或Adagrad之类的东西，我们可能会得到更好的模型。CIFAR-10是一个已解决的问题，我们可以在网上找到该数据集的许多不同实现。这只是对卷积神经网络和一些优化技术的介绍，我们可以实施这些技术来提高模型的准确性。</p></div></div>    
</body>
</html>