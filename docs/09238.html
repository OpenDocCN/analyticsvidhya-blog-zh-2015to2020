<html>
<head>
<title>Comprehensive Guide to Machine Learning (Part 2 of 3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习综合指南(第2部分，共3部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/comprehensive-guide-to-machine-learning-part-2-of-3-cab36d4cf2a7?source=collection_archive---------32-----------------------#2020-08-29">https://medium.com/analytics-vidhya/comprehensive-guide-to-machine-learning-part-2-of-3-cab36d4cf2a7?source=collection_archive---------32-----------------------#2020-08-29</a></blockquote><div><div class="dt gx gy gz ha hb"/><div class="hc hd he hf hg"><div class=""/><figure class="ew ey ih ii ij ik es et paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="es et ig"><img src="../Images/9f1a58c6dee9a943f1f3db2e554cc743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zJikCzcfw9M3ZX0xxhB8eQ.png"/></div></div><figcaption class="ir is eu es et it iu bd b be z dy translated">图片提供:<a class="ae iv" href="https://www.educative.io/track/become-ml-engineer" rel="noopener ugc nofollow" target="_blank">https://www.educative.io/track/become-ml-engineer</a></figcaption></figure><p id="3385" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">欢迎来到“机器学习综合指南”系列的第二部分。在本系列的<a class="ae iv" rel="noopener" href="/analytics-vidhya/comprehensive-guide-to-machine-learning-part-1-of-3-bbe058222278"> <strong class="iy hk">第一部分</strong> </a>中，我们探讨了下面的机器学习概念。</p><ul class=""><li id="3f75" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt jz ka kb kc bi translated">获取数据</li><li id="616e" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated">数据清理</li><li id="0868" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated">探索性数据分析</li></ul><p id="23f5" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">我希望你们在自己的数据集上玩这些概念玩得开心。在这篇文章中，让我们深入探讨以下概念，这将极大地有助于建立一个强大的机器学习模型。</p><ul class=""><li id="2ef0" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt jz ka kb kc bi translated">特征工程</li><li id="73ea" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated">特征选择</li><li id="5c05" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated">培训/验证/测试分割</li></ul><blockquote class="ki kj kk"><p id="dab6" class="iw ix kl iy b iz ja jb jc jd je jf jg km ji jj jk kn jm jn jo ko jq jr js jt hc bi translated"><strong class="iy hk">注意:</strong>这三个概念构成了整个机器学习模型开发生命周期的主干。<strong class="iy hk">任何机器学习模型都只能与它在</strong>上训练的功能一样好。一名优秀的数据工程师或数据科学家应该能够识别和创建直观的特征，并丢弃非直观的特征。</p></blockquote></div><div class="ab cl kp kq gq kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hc hd he hf hg"><h1 id="dc9c" class="kw kx hj bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">4)特征工程</h1><p id="1ee4" class="pw-post-body-paragraph iw ix hj iy b iz lu jb jc jd lv jf jg jh lw jj jk jl lx jn jo jp ly jr js jt hc bi translated">我们先来了解一下“<strong class="iy hk">特性</strong>到底是什么意思。根据维基百科—</p><blockquote class="ki kj kk"><p id="4bb2" class="iw ix kl iy b iz ja jb jc jd je jf jg km ji jj jk kn jm jn jo ko jq jr js jt hc bi translated">特征是所有独立单元共享的属性或特性，将对其进行分析或预测。<strong class="iy hk">任何属性都可以是特征，只要对模型有用。</strong></p></blockquote><p id="991b" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">因此，在机器学习的上下文中，<em class="kl">特征</em>有两个基本属性。</p><ul class=""><li id="3090" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt jz ka kb kc bi translated"><strong class="iy hk">所有功能都应该相互独立。</strong>也就是说，它们之间应该有最小的相关性或者没有相关性。(我们已经在本系列的第一部分 的<a class="ae iv" rel="noopener" href="/analytics-vidhya/comprehensive-guide-to-machine-learning-part-1-of-3-bbe058222278"> <strong class="iy hk">中讨论过相关分析)</strong></a></li><li id="37fa" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated"><strong class="iy hk">该特征应该直观且对模型有用。丢弃不直观或无用的功能通常被认为是最佳实践。</strong></li></ul><p id="e4db" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">现在，让我们来定义一下“<strong class="iy hk">特征工程</strong>”。</p><blockquote class="ki kj kk"><p id="69b0" class="iw ix kl iy b iz ja jb jc jd je jf jg km ji jj jk kn jm jn jo ko jq jr js jt hc bi translated">特征工程是使用领域知识通过数据挖掘技术从原始数据中提取特征的过程。这些特征可以用来提高机器学习算法的性能。</p></blockquote><p id="ca63" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated"><em class="kl">领域知识</em>是建立一个好的机器学习模型的关键之一。在实际开始开发机器学习模型之前，获取足够的领域或业务领域的知识是明智的。</p><p id="b76f" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">既然我们已经有了特征工程的理论知识，让我们看看同样的代码。</p><ul class=""><li id="1557" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt jz ka kb kc bi translated"><strong class="iy hk">日期时间特性</strong></li></ul><p id="2f80" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">给定一个日期时间值，我们可以从中导出以下属性。</p><ol class=""><li id="4922" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt lz ka kb kc bi translated">年</li><li id="aced" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">月</li><li id="5f3b" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">四分之一</li><li id="e05b" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">周</li><li id="4901" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">一年中的某一天</li><li id="bd61" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">一月中的某一天</li><li id="bc3b" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">星期几</li><li id="7dda" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">如果日期是不是周末</li><li id="b977" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">小时</li><li id="ddd9" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">分钟</li><li id="2baf" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">第二</li><li id="8020" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt lz ka kb kc bi translated">经过的分钟数</li></ol><p id="d251" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated"><em class="kl"> pandas </em> python库已经有现成的功能来派生上面提到的特性，如下图所示。</p><figure class="mb mc md me fe ik es et paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="es et ma"><img src="../Images/688332622fd085b7e6778124929ae566.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kkvzZdclyzzNkwFk6pHsgA.png"/></div></div></figure><ul class=""><li id="1802" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt jz ka kb kc bi translated"><strong class="iy hk">分类特征</strong></li></ul><p id="9723" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">通常，以下两种技术用于分类变量的特征工程。</p><ol class=""><li id="d41b" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt lz ka kb kc bi translated"><strong class="iy hk">一键编码</strong></li></ol><p id="2048" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">这可以使用Pandas库的“<em class="kl"> get_dummies </em>”功能来完成，如下所示。</p><figure class="mb mc md me fe ik es et paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="es et mf"><img src="../Images/52f05534190223896a4eb2dcf05f36ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKQCFcNHmJp3LZ5-lPWt0A.png"/></div></div></figure><p id="4e10" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated"><strong class="iy hk"> 2。标签编码</strong></p><p id="b71d" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">这可以使用Pandas库的“<em class="kl">因式分解</em>”功能来完成，如下所示。</p><figure class="mb mc md me fe ik es et paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="es et mg"><img src="../Images/2b3b83e91a8d0e5cbfecdab0e9ee1c70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uy2sEv332HwcrUusDvwmfA.png"/></div></div></figure><p id="fd0d" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">您可以查看下面的帖子，进一步了解分类特征编码。</p><div class="mh mi fa fc mj mk"><a href="https://towardsdatascience.com/encoding-categorical-features-21a2651a065c" rel="noopener follow" target="_blank"><div class="ml ab dx"><div class="mm ab mn cl cj mo"><h2 class="bd hk fj z dz mp eb ec mq ee eg hi bi translated">编码分类特征</h2><div class="mr l"><h3 class="bd b fj z dz mp eb ec mq ee eg dy translated">介绍</h3></div><div class="ms l"><p class="bd b fq z dz mp eb ec mq ee eg dy translated">towardsdatascience.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my ip mk"/></div></div></a></div><ul class=""><li id="3e13" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt jz ka kb kc bi translated"><strong class="iy hk">连续特征</strong></li></ul><p id="6387" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">对于分类特征，它归结为生成新特征的领域知识。在下图中，我使用“<em class="kl">长度</em>”和“<em class="kl">高度</em>”特征导出了“<em class="kl">面积</em>”和“<em class="kl">对角线</em>”值。</p><figure class="mb mc md me fe ik es et paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="es et mg"><img src="../Images/656f8aedd1c82c26746df7fa858d0fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Em1hstUvVSoCMqXPS765sA.png"/></div></div></figure><p id="cd7e" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">类似地，我通过使用现有变量的不同算术组合生成了新的特征，如下图所示。</p><figure class="mb mc md me fe ik es et paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="es et mz"><img src="../Images/4abbab948c6f0bd2a08b20c1c2194218.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AfWx2873tT4QakKG5Khi3Q.png"/></div></div></figure><p id="0d25" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">我真的鼓励去阅读下面的帖子，以获得对特征工程技术的进一步理解。</p><div class="mh mi fa fc mj mk"><a href="https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114" rel="noopener follow" target="_blank"><div class="ml ab dx"><div class="mm ab mn cl cj mo"><h2 class="bd hk fj z dz mp eb ec mq ee eg hi bi translated">面向机器学习的特征工程基本技术</h2><div class="mr l"><h3 class="bd b fj z dz mp eb ec mq ee eg dy translated">用熊猫例子进行综合数据预处理所需的所有方法。</h3></div><div class="ms l"><p class="bd b fq z dz mp eb ec mq ee eg dy translated">towardsdatascience.com</p></div></div><div class="mt l"><div class="na l mv mw mx mt my ip mk"/></div></div></a></div></div><div class="ab cl kp kq gq kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hc hd he hf hg"><h1 id="92b5" class="kw kx hj bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">5)特征选择</h1><p id="19d9" class="pw-post-body-paragraph iw ix hj iy b iz lu jb jc jd lv jf jg jh lw jj jk jl lx jn jo jp ly jr js jt hc bi translated">让我们首先理解为什么执行特性选择如此重要。</p><blockquote class="ki kj kk"><p id="eec1" class="iw ix kl iy b iz ja jb jc jd je jf jg km ji jj jk kn jm jn jo ko jq jr js jt hc bi translated">机器学习的工作原理很简单——<strong class="iy hk">如果你把垃圾放进去，你只会让垃圾出来</strong>。这里的垃圾是指数据中的噪音。</p></blockquote><p id="0edb" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">当特征的数量非常大时，这变得更加重要。你不需要使用每一个特性来创建一个算法。你可以通过只输入那些真正重要的特征来帮助你的算法。</p><p id="59a6" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">以下是使用特征选择的优点。</p><ul class=""><li id="a368" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt jz ka kb kc bi translated">它使机器学习算法能够更快地训练。</li><li id="0ac5" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated">它降低了模型的复杂性，使其更容易解释。</li><li id="8b4d" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated">如果选择了正确的子集，就可以提高模型的准确性。</li><li id="553b" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated">它减少了过度拟合。</li></ul><p id="a34c" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">在这篇文章中，我将只讨论使用主成分分析作为特征选择方法。</p><blockquote class="ki kj kk"><p id="d048" class="iw ix kl iy b iz ja jb jc jd je jf jg km ji jj jk kn jm jn jo ko jq jr js jt hc bi translated">PCA(主成分分析)是一种降维技术，它将数据投影到一个更低维的空间中。</p></blockquote><p id="a97e" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">让我们先来看看我完成特征工程后的特征数量。</p><figure class="mb mc md me fe ik es et paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="es et nb"><img src="../Images/38210bcc0dc9a82d4ca0e9b3f1485b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6o2wvNTYCT0VYO_E7o6UvA.png"/></div></div></figure><p id="bc25" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">所以我最终得到了667个特征，并不是所有的特征都对最终的机器学习模型直观或有用。现在让我们应用PCA，只保留有用的特征，丢弃其余的。</p><figure class="mb mc md me fe ik es et paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="es et nc"><img src="../Images/419eac0d1ed0d3f71cfe570fc268ce87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iMRV1aAzjRKOJJN96LGBhg.png"/></div></div></figure><p id="f7ba" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">如上图所示，只保留了100个有用的特征用于训练机器学习模型。</p><p id="20a3" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">我建议浏览下面的帖子，以便更好地理解PCA和其他特征选择技术。</p><div class="mh mi fa fc mj mk"><a rel="noopener follow" target="_blank" href="/apprentice-journal/pca-application-in-machine-learning-4827c07a61db"><div class="ml ab dx"><div class="mm ab mn cl cj mo"><h2 class="bd hk fj z dz mp eb ec mq ee eg hi bi translated">主成分分析:在机器学习中的应用</h2><div class="mr l"><h3 class="bd b fj z dz mp eb ec mq ee eg dy translated">主成分分析在机器学习中的应用介绍</h3></div><div class="ms l"><p class="bd b fq z dz mp eb ec mq ee eg dy translated">medium.com</p></div></div><div class="mt l"><div class="nd l mv mw mx mt my ip mk"/></div></div></a></div><div class="mh mi fa fc mj mk"><a href="https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2" rel="noopener follow" target="_blank"><div class="ml ab dx"><div class="mm ab mn cl cj mo"><h2 class="bd hk fj z dz mp eb ec mq ee eg hi bi translated">每个数据科学家都应该知道的5种特征选择算法</h2><div class="mr l"><h3 class="bd b fj z dz mp eb ec mq ee eg dy translated">额外收获:是什么让一个优秀的足球运动员变得伟大？</h3></div><div class="ms l"><p class="bd b fq z dz mp eb ec mq ee eg dy translated">towardsdatascience.com</p></div></div><div class="mt l"><div class="ne l mv mw mx mt my ip mk"/></div></div></a></div></div><div class="ab cl kp kq gq kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hc hd he hf hg"><h1 id="e844" class="kw kx hj bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">6)培训/验证/测试分割</h1><p id="eb16" class="pw-post-body-paragraph iw ix hj iy b iz lu jb jc jd lv jf jg jh lw jj jk jl lx jn jo jp ly jr js jt hc bi translated">在训练机器学习模型时，监控模型性能并确保没有“<strong class="iy hk"><em class="kl"/></strong>”欠拟合或“<strong class="iy hk"><em class="kl"/></strong>”是至关重要的。这两个术语的含义将会很清楚。</p><p id="09ac" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">假设我们有一个包含10，000条记录的数据集，我们必须用它来构建机器学习模型。在训练模型时，我有以下3种可能的情况。</p><ul class=""><li id="4c7f" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt jz ka kb kc bi translated">在10，000条记录的整个数据集上训练模型。但是，我没有任何进一步的数据来验证该模型是否如预期的那样工作。</li><li id="f2e1" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated">我可以分离出2000条记录(<strong class="iy hk">测试数据集</strong>)并在剩余的8000条记录上训练模型(<strong class="iy hk">训练数据集</strong>)。这样，一旦训练完成，我就可以在剩余的2，000条记录上验证模型。然而，这种方法的唯一问题是，当我们调整超参数并重新训练/重新验证模型时，它会偏向测试数据集，因为模型现在已经看到了两个数据集。</li><li id="54aa" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated">我可以分离出1，000条记录(<strong class="iy hk">测试数据集</strong>)，只有当我非常确定它能按预期工作时，我才会向模型展示这些记录。我将进一步分离出另外1000条记录(<strong class="iy hk">验证数据集</strong>)，我将使用这些记录在不同的超参数上验证模型。我将使用剩余的8000条记录(<strong class="iy hk">训练数据集</strong>)来训练模型。这样我可以解决第二种方法中的偏差问题。</li></ul><p id="ad51" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">既然我们对训练/验证/测试数据集分割有了一个理论上的想法，我们就来简单讨论一下“<strong class="iy hk">欠拟合</strong>”和“<strong class="iy hk">过拟合</strong>”。</p><blockquote class="ki kj kk"><p id="4d94" class="iw ix kl iy b iz ja jb jc jd je jf jg km ji jj jk kn jm jn jo ko jq jr js jt hc bi translated"><strong class="iy hk">欠拟合</strong> —当模型在训练和验证数据集上表现不佳时。例如，如果模型在训练数据上给出了70%的准确性，在验证数据上给出了55%的准确性，那么我们可以说该模型是欠拟合的。在这种情况下，最佳做法是使模型更加复杂，或者增加特征的数量来训练模型。</p><p id="4f67" class="iw ix kl iy b iz ja jb jc jd je jf jg km ji jj jk kn jm jn jo ko jq jr js jt hc bi translated"><strong class="iy hk">过度拟合</strong> —当模型在训练数据上表现优异，但在验证数据上表现不佳时。例如，如果模型对训练数据给出了99%的准确性，而对验证数据给出了60%的准确性，那么我们可以说该模型是过度拟合的。在这种情况下，最佳实践是简化模型或减少特征的数量来训练模型。</p></blockquote><p id="5931" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">现在让我们看看训练/验证/测试数据集分割的代码。“<strong class="iy hk">sk learn</strong>”python库为此提供了2个功能。</p><ul class=""><li id="09a1" class="ju jv hj iy b iz ja jd je jh jw jl jx jp jy jt jz ka kb kc bi translated"><strong class="iy hk">sk learn . model _ selection . train _ test _ split</strong>—对于回归问题，我通常更喜欢这个。</li><li id="ac10" class="ju jv hj iy b iz kd jd ke jh kf jl kg jp kh jt jz ka kb kc bi translated"><strong class="iy hk"> sklearn.model_selection。StratifiedShuffleSplit</strong>——对于分类问题，我通常更喜欢这样。</li></ul><p id="660c" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">下图显示了执行数据集分割的python代码。</p><figure class="mb mc md me fe ik es et paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="es et mf"><img src="../Images/63c34c5947977b65b76afe5d47dc2576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3gxxdD2e9RJNNWp0T0nkBw.png"/></div></div></figure><p id="2534" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">您可以查看下面的帖子，进一步了解模型验证的数据集分割。</p><div class="mh mi fa fc mj mk"><a href="https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6" rel="noopener follow" target="_blank"><div class="ml ab dx"><div class="mm ab mn cl cj mo"><h2 class="bd hk fj z dz mp eb ec mq ee eg hi bi translated">在Python中训练/测试分割和交叉验证</h2><div class="mr l"><h3 class="bd b fj z dz mp eb ec mq ee eg dy translated">大家好！在我上一篇关于Python中线性回归的文章之后，我认为写一篇文章是很自然的…</h3></div><div class="ms l"><p class="bd b fq z dz mp eb ec mq ee eg dy translated">towardsdatascience.com</p></div></div><div class="mt l"><div class="nf l mv mw mx mt my ip mk"/></div></div></a></div></div><div class="ab cl kp kq gq kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hc hd he hf hg"><h1 id="107f" class="kw kx hj bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">结束语</h1><p id="fa8f" class="pw-post-body-paragraph iw ix hj iy b iz lu jb jc jd lv jf jg jh lw jj jk jl lx jn jo jp ly jr js jt hc bi translated">全面的机器学习指南的第二部分到此结束。在下一篇 的<a class="ae iv" rel="noopener" href="/@tdtapas/comprehensive-guide-to-machine-learning-part-3-of-3-907cd1dd41dd"> <strong class="iy hk">中，我将介绍模型构建、超参数调整和模型验证技术。然后，我们将对测试数据集进行预测，以确保模型按预期工作。</strong></a></p><p id="6d1a" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">和往常一样，你可以在下面的链接找到这篇文章的代码库。我强烈建议获得你自己的数据集(从Kaggle或使用网络搜集),并尝试这篇文章中详述的不同特征工程和特征选择方法。</p><div class="mh mi fa fc mj mk"><a href="https://github.com/dlaststark/machine-learning-projects/blob/master/HackerEarth%20Competitions/Adopt%20a%20Buddy/Pet%20Adoption%20%28EDA%29.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dx"><div class="mm ab mn cl cj mo"><h2 class="bd hk fj z dz mp eb ec mq ee eg hi bi translated">dlaststark/机器学习项目</h2><div class="mr l"><h3 class="bd b fj z dz mp eb ec mq ee eg dy translated">permalink dissolve GitHub是超过5000万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="ms l"><p class="bd b fq z dz mp eb ec mq ee eg dy translated">github.com</p></div></div><div class="mt l"><div class="ng l mv mw mx mt my ip mk"/></div></div></a></div><p id="746d" class="pw-post-body-paragraph iw ix hj iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hc bi translated">请访问我的博客(下面的链接)来探索更多关于机器学习和Linux计算的内容。</p><div class="mh mi fa fc mj mk"><a href="https://www.techgeekramblings.com/" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dx"><div class="mm ab mn cl cj mo"><h2 class="bd hk fj z dz mp eb ec mq ee eg hi bi translated">自由博客作者|技术极客漫谈</h2><div class="mr l"><h3 class="bd b fj z dz mp eb ec mq ee eg dy translated">技术极客漫谈|关于我不同技术事业的自由博客</h3></div><div class="ms l"><p class="bd b fq z dz mp eb ec mq ee eg dy translated">www.techgeekramblings.com</p></div></div><div class="mt l"><div class="nh l mv mw mx mt my ip mk"/></div></div></a></div></div></div>    
</body>
</html>