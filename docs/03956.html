<html>
<head>
<title>Detecting Russian trolls and estimating post controversiality on Reddit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">检测俄罗斯巨魔并评估Reddit上的帖子争议性</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/detecting-russian-trolls-and-estimating-post-controversiality-on-reddit-revising-the-nlp-3080cf393131?source=collection_archive---------10-----------------------#2020-02-27">https://medium.com/analytics-vidhya/detecting-russian-trolls-and-estimating-post-controversiality-on-reddit-revising-the-nlp-3080cf393131?source=collection_archive---------10-----------------------#2020-02-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="135a" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">用NLP猎杀巨魔</h2><div class=""/><div class=""><h2 id="5fac" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated"><strong class="ak">修改NLP方法</strong></h2></div></div><div class="ab cl jg jh gp ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="hb hc hd he hf"><p id="dfab" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">TL；博士:<a class="ae kj" href="https://github.com/pashadude/troll_detection_nlp" rel="noopener ugc nofollow" target="_blank">用我的github </a>上的代码检查ipython笔记本。</p><h1 id="92ad" class="kk kl hi bd km kn ko kp kq kr ks kt ku ix kv iy kw ja kx jb ky jd kz je la lb bi translated">1.问题是</h1><p id="39cd" class="pw-post-body-paragraph jn jo hi jp b jq lc is js jt ld iv jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">巨魔在社交媒体上的存在是2020年的一个问题。外国势力利用巨魔作为<a class="ae kj" href="https://www.nytimes.com/interactive/2019/09/18/world/asia/hk-twitter.html" rel="noopener ugc nofollow" target="_blank">一场政治战争</a>和<a class="ae kj" href="https://www.wired.com/story/russia-ira-propaganda-senate-report/" rel="noopener ugc nofollow" target="_blank">选举干预过程</a>的一部分。</p><p id="aa22" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">公众对平台的压力迫使他们实施有毒内容过滤。这导致了巨魔禁令和曝光的浪潮。</p><p id="5c44" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">社交媒体平台举办了诸如<a class="ae kj" href="https://www.kaggle.com/c/quora-insincere-questions-classification" rel="noopener ugc nofollow" target="_blank"> Quora虚假问题分类</a>或<a class="ae kj" href="https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview" rel="noopener ugc nofollow" target="_blank"> Jigsaw毒性分类中的意外偏差</a>等Kaggle竞赛，以便从数据科学家那里获得一些想法。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div class="er es lh"><img src="../Images/c134c0fb8fc95b9e70abcf03f1d0f993.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*SFaayhLn0BGp-uI0EZIZvw.jpeg"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">通过标准许可证购买的adobe stock image by<a class="ae kj" href="https://stock.adobe.com/ru/contributor/201958550/dan177?load_type=author&amp;prev_url=detail&amp;asset_id=105778543" rel="noopener ugc nofollow" target="_blank">Dan 177</a></figcaption></figure><p id="0232" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然而，某些问题仍然存在。</p><p id="d229" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">首先，自然语言处理在2019年继续取得巨大进展(在模型可用性和规范方面)——你不仅可以从发表的优秀论文中看到，还可以从由<a class="ae kj" href="https://www.kaggle.com/c/google-quest-challenge/overview" rel="noopener ugc nofollow" target="_blank"> Google </a>和<a class="ae kj" href="https://www.kaggle.com/c/tensorflow2-question-answering/overview" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>举办的2019年末Kaggle竞赛的SOTA解决方案中看到(它们有很多，但我使用了<a class="ae kj" href="https://www.kaggle.com/abhishek/distilbert-use-features-oof" rel="noopener ugc nofollow" target="_blank">这个</a>、<a class="ae kj" href="https://www.kaggle.com/shuheigoda/23th-place-solusion/comments" rel="noopener ugc nofollow" target="_blank">这个</a>、<a class="ae kj" href="https://www.kaggle.com/c/google-quest-challenge/discussion/129840" rel="noopener ugc nofollow" target="_blank">这个</a>和<a class="ae kj" href="https://www.kaggle.com/christofhenkel/inference-v3-224" rel="noopener ugc nofollow" target="_blank">这个</a>作为主要来源</p><p id="a9fe" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">第二，预先估计由巨魔帖子引起的不满是至关重要的。Reddit已经有了一个有趣的指标，叫做帖子争议性。它涵盖了一个帖子获得的支持票和反对票的数量，以及它们的平均比例。我建议用它来衡量巨魔的伤害。</p><p id="8444" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这篇文章中，我将应用一些来自顶级kagglers的新方法来解决Reddit俄罗斯巨魔检测问题，并尝试用一个模型来估计Reddit帖子的争议性。</p></div><div class="ab cl jg jh gp ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="hb hc hd he hf"><h1 id="06db" class="kk kl hi bd km kn lt kp kq kr lu kt ku ix lv iy kw ja lw jb ky jd lx je la lb bi translated"><strong class="ak"> 2。数据和预处理</strong></h1><p id="263c" class="pw-post-body-paragraph jn jo hi jp b jq lc is js jt ld iv jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">我将坚持使用<a class="ae kj" href="http://web.archive.org/web/20190704222221/https://towardsdatascience.com/predicting-russian-trolls-using-reddit-comments-57a707653184" rel="noopener ugc nofollow" target="_blank"> Brandon Punturo </a>和<a class="ae kj" href="https://towardsdatascience.com/using-bert-and-cnns-for-russian-troll-detection-on-reddit-8ae59066b1c" rel="noopener" target="_blank"> Henry Weller </a>的伟大文章中使用的问题环境，以便为所取得的结果和使用的方法提供一些基准。该数据由2个数据集组成，包含巨魔帖子和普通用户帖子。</p><div class="li lj lk ll fd ab cb"><figure class="ly lm lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/02a3eea01116afb994eba5939b3bb329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*iGuQk721vwISjwtpQY_e4Q.png"/></div></figure><figure class="ly lm mi ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/171c57f160a2cea9f9a699862f9bcb54.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*ON6y-NABfcsQtf5sDotqwQ.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx mj di mk ml translated">左边是普通用户post数据帧，右边是troll post数据帧</figcaption></figure></div><p id="082c" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">虽然普通用户数据包含更多的帖子，但troll数据更详细，包含帖子链接和链接标题等重要功能。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mm"><img src="../Images/46dcef0c4cea7789cd8aa6818646fd8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ann071c10IuvU-m82UKODw.png"/></div></div></figure><p id="faca" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">让我们从普通用户的帖子中提取相同的特征，并将所有相关数据放入“link_data”列。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mn"><img src="../Images/f1c62a6dc874b3937f52a921049784ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z_ctiHDTHec3TCMKJgUzMw.png"/></div></div></figure><p id="be2e" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">拥有相同格式的子编辑名称也很重要，因为我们将在分类器中广泛使用这个特性。</p><p id="7c78" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">让我们清除文本字段中的特殊符号和技术垃圾(如链接和html标签)。我已经修复了标点符号，并用文本替换了表情符号。表情符号分类部分确实很随意，但它提高了模型性能。我可以用俄罗斯互联网文化的某些特征来解释。表情符号的使用被认为是“蹩脚的”。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mo"><img src="../Images/99ed7a5ca9b46cc59d2d9d25e436107a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oohCB33pviu4JNNBf6UOUg.png"/></div></div></figure><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mp"><img src="../Images/afa6093ef6ea7cacf44003101a514e62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AOYqQbyLa2O_8ZTiKdioOg.png"/></div></div></figure><p id="e765" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">一个重要的标志是，普通用户有2%的争议帖子，而巨魔有4%。从逻辑上讲，有争议的帖子在可用数据中所占的整体份额相当小。我将在下面的数据选择步骤和一些模型微调中解决这个问题。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mq"><img src="../Images/518c1a98807b8f745886ab1cbe4c3f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cYpuETlZVYAz-ycmmWxYZQ.png"/></div></div></figure><figure class="li lj lk ll fd lm er es paragraph-image"><div class="er es mr"><img src="../Images/f4a07fefc6853cd2cd8760b008055759.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*ZsAwzrtOeBkVflElaKGyRw.png"/></div></figure><p id="bcb7" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">现在，让我们用等量的巨魔和非巨魔帖子对我们的实验数据进行采样。</p><p id="ac0e" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我还把所有有争议的帖子放入实验数据集，以获得足够的训练数据。</p><p id="dc42" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">请记住，我们的目标不仅是识别巨魔，而且是预测危害。</p></div><div class="ab cl jg jh gp ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="hb hc hd he hf"><h1 id="0fd9" class="kk kl hi bd km kn lt kp kq kr lu kt ku ix lv iy kw ja lw jb ky jd lx je la lb bi translated">3.从nlp的角度解释数据。</h1><p id="ede5" class="pw-post-body-paragraph jn jo hi jp b jq lc is js jt ld iv jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">为了构建一个具有BERT风格的模型的分类模型，该模型向底层提供输入(我使用了<a class="ae kj" href="https://arxiv.org/abs/1910.01108" rel="noopener ugc nofollow" target="_blank"><strong class="jp hs">distil BERT</strong></a><strong class="jp hs"/>进行初步检查，并在最终模型之后使用BERT ),我们需要将文本数据裁剪成BERT要求的大小(512)的批次，并对其进行标记化。当前数据如下所示:</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es ms"><img src="../Images/1f009f563bf8d76c90f63b772766ed24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ew7o4Vu6f__bGNT8eVkAsA.png"/></div></div></figure><p id="a63f" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我建议将实验文本数据解释为BERT模型的问答数据集。其中问题标题为<strong class="jp hs"> 'link_data' </strong>单元格，问题正文为<strong class="jp hs"> 'body' </strong>单元格，答案为<strong class="jp hs"> 'subreddit' </strong>单元格。</p><blockquote class="mt mu mv"><p id="960d" class="jn jo mw jp b jq jr is js jt ju iv jv mx jx jy jz my kb kc kd mz kf kg kh ki hb bi translated"><strong class="jp hs"> <em class="hi">基本上在我们的模型中，一个巨魔获取一些新闻文章或讨论点作为输入(问题)，并搜索最佳子编辑来发布它(答案)。</em>T15】</strong></p></blockquote><p id="0e6c" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">简而言之，一个数据点的输入如下所示:</p><blockquote class="mt mu mv"><p id="b2e2" class="jn jo mw jp b jq jr is js jt ju iv jv mx jx jy jz my kb kc kd mz kf kg kh ki hb bi translated"><strong class="jp hs"><em class="hi">Input =【CLS】+&lt;link _ data&gt;+【SEP】+&lt;body&gt;+【SEP】+&lt;subreddit&gt;+【SEP】</em></strong></p></blockquote><p id="fa8a" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">用[CLS]标记表示该数据点用于分类，[SEP]标记用于输入部分分离，<tokenized>数据来自输入数据点的各个单元</tokenized></p><p id="11db" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">但是，在标记化之前，我们应该设置输入字段的大小，并根据我们的数据集特征修剪输入字段</p><figure class="li lj lk ll fd lm er es paragraph-image"><div class="er es na"><img src="../Images/a2d7c0071e708f93394485c5b23d5cc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*gmFIuk4EdDdb_TH-6HRjQA.png"/></div></figure><p id="8f90" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在两个原始数据集中，subreddit的名称都不超过25个符号，所以我将答案的最大长度设置为25，将问题的最大长度(包括标题和正文)设置为483。我们还应该为一个[CLS]和3个[SEP]标记保留4个字符，以便按照BERT的要求得到总长度为512的输入。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nb"><img src="../Images/fa69a8c3150c3f18a80db94605913a75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uIkuLiVVEpPk2ayx6CmyoA.png"/></div></div></figure><p id="d8f6" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然后我们应该修剪数据并将其标记化。</p><p id="8d2d" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">请注意，我们真正关注的是修剪问题，因为答案长度总是低于或等于限制(由于上面描述的ANSWER_MAX_LENGTH值选择)。</p><p id="53ee" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">不熟悉BERT的人应该注意，回答和问题部分的标记类型是不同的。</p><p id="96b5" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">下面是一个从数字转换而来的标记化数据的示例，让您有一种感觉:</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mm"><img src="../Images/2c92f9fa5ab71bfed947767b12264c84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q6IJKJj6BYl8nEKpiRbyaw.png"/></div></div></figure><p id="daab" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我在输入创建函数中添加了一个<strong class="jp hs">‘记号赋予器’</strong>参数，这样你就可以使用不同的记号赋予器了(DistilBERT，<a class="ae kj" href="https://arxiv.org/abs/1907.11692" rel="noopener ugc nofollow" target="_blank"> RoBERTa </a>等等)</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nb"><img src="../Images/13c203ca3e704fcc83eb2fb88f3ec1ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bGy_lREaRwIHSC50Y2ug2A.png"/></div></div></figure><h1 id="b24e" class="kk kl hi bd km kn ko kp kq kr ks kt ku ix kv iy kw ja kx jb ky jd kz je la lb bi translated">4.模型:网络和优化设置。</h1><p id="ce05" class="pw-post-body-paragraph jn jo hi jp b jq lc is js jt ld iv jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">model类非常简单，但是它在构造函数中还包含一个<strong class="jp hs">‘model _ type’</strong>参数，因此可以使用不同的模型:</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nb"><img src="../Images/85878ff2c21ffa787cfd7d0223d985c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lpme6mt9zIC3FiRVKA05YA.png"/></div></div></figure><p id="d0ef" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然后，我使用基于[CLS]头隐藏状态输出的分类模型。我假设一个人实际上可以通过额外单独使用[SEP]隐藏状态数据来获得更好的结果。</p><p id="5d19" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我唯一想强调的是<a class="ae kj" href="https://arxiv.org/abs/1905.09788" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hs">多样本缺失</strong> </a> <strong class="jp hs"> </strong>的用法，它提高了模型的泛化能力。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nc"><img src="../Images/c5ef829992cc355b9428998b9c2e287d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hnV7jDTq6d8MM3_dRAormg.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">图片来自原创文章<a class="ae kj" href="https://arxiv.org/abs/1905.09788v2" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1905.09788v2</a></figcaption></figure><blockquote class="mt mu mv"><p id="cb77" class="jn jo mw jp b jq jr is js jt ju iv jv mx jx jy jz my kb kc kd mz kf kg kh ki hb bi translated">“而原始脱落在每次训练迭代中从输入中创建随机选择的子集(称为脱落样本)，而多样本脱落创建多个脱落样本。计算每个样本的损失，然后对样本损失进行平均，得到最终损失。通过在丢失层之后复制网络的一部分，同时在复制的完全连接的层之间共享权重，这种技术可以很容易地实现，而不需要实现新的运营商。多样本丢失不会显著增加每次迭代的计算成本，因为大部分计算时间消耗在丢失层之前的卷积层中，这些层是不重复的。实验还表明，使用多样本脱落训练的网络对于训练集和验证集都实现了较低的错误率和损失。”</p></blockquote><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nb"><img src="../Images/963113355702a89fa8240f30e3716a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2yZYfkqZANs7sVVly7Qe4Q.png"/></div></div></figure><p id="c1b9" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我使用了具有参数化学习率和权重衰减的ADAM优化器。人们当然可以利用这些参数来获得更好的结果。分期数为3个，批量为8个。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nb"><img src="../Images/92b9df765db238d146274d7d0f3fb3d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dqSK4GgEn3_at09q8H3RTQ.png"/></div></div></figure><p id="48e4" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我使用了<code class="du nd ne nf ng b"><a class="ae kj" href="https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss" rel="noopener ugc nofollow" target="_blank">torch.nn.BCEWithLogitsLoss</a> </code>，它结合了一个Sigmoid层(需要得到属于模型输出的类的概率)和一个单一类中的BCELoss。这个版本在数值上比使用普通的Sigmoid后跟一个BCELoss更稳定，因为通过将运算合并到一个层中，pytorch利用了log-sum-exp技巧来获得数值稳定性)。最终损失由负责troll检测和争议性预测的模型权重来加权。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nb"><img src="../Images/e7485023cc9606a9685063f3d3321336.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5einV8P-6I8BqAFM3xQgdg.png"/></div></div></figure><p id="0dd5" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">训练/测试分配为80/20。我使用了基于<strong class="jp hs">子循环</strong>特征值的组K折叠。尽管考虑到当前数据集中按子漩涡分布的帖子可能有风险(尽管K是3)，但这种方法更适合于大量的红编辑数据。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nh"><img src="../Images/f5f3e1f5d416d3026f16f85d04f3a26e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xW0IUgwUnYwER6vADHWJLA.png"/></div></div></figure><h1 id="cbd3" class="kk kl hi bd km kn ko kp kq kr ks kt ku ix kv iy kw ja kx jb ky jd kz je la lb bi translated">5.结果:解读与比较。</h1><p id="b720" class="pw-post-body-paragraph jn jo hi jp b jq lc is js jt ld iv jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">为了验证概念和评估整个模型的性能，我使用了DistilBERT作为NLP核心模型。它在计算上比其他BERT模型便宜得多，但具有相当好的性能。我使用了来自<a class="ae kj" href="https://huggingface.co/transformers/model_doc/distilbert.html" rel="noopener ugc nofollow" target="_blank">变形金刚</a>的DistilBERT实现。</p><div class="li lj lk ll fd ab cb"><figure class="ly lm ni ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/ce5d2e126165828cce96ce5e1e610d1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*ajwBMhr0G6_AGJDsSR9XMA.png"/></div></figure><figure class="ly lm nj ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/4476e9f7f9fa4590a0e87fe32da62525.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*8gUkKpBQMTW2vrkVKdG_Tw.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx nk di nl ml translated">模型与蒸馏:troll后预测准确性指标与后争议性预测准确性。</figcaption></figure></div><p id="6e4a" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">与过去的方法相比，集成了DistilBERT的整体模型非常适合测试，并提供了很好的结果。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div class="er es nm"><img src="../Images/1de1462d657c20391187e3117866fb79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*cvUA_tXQkreXNmntjGPzaw.png"/></div></figure><p id="357f" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">巨魔检测任务结果<strong class="jp hs"> auc 0.99 </strong>以显著优势超过Brandon Punturo和<a class="ae kj" href="https://towardsdatascience.com/using-bert-and-cnns-for-russian-troll-detection-on-reddit-8ae59066b1c" rel="noopener" target="_blank"> Henry Weller </a> /Jeff Woo <strong class="jp hs">(分别为auc 0.74和AUC 0.85)</strong>的旧方法结果。基本上2685个数据点只有一个预测错了。</p><p id="f58b" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然而，争议性预测的性能不够好(<strong class="jp hs"> auc 0.54 </strong>)，部分原因是数据标签差异。</p><p id="7c67" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">现在，让我们将BERT-BASE-UNCASED模型作为NLP核心运行，这将花费更多的时间。</p><div class="li lj lk ll fd ab cb"><figure class="ly lm nn ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/5ac372b93016cc7b616e8a28d11900a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*zv3V0lB2CG_xujLSEv6xtw.png"/></div></figure><figure class="ly lm no ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/1c71f08519f446451521ab7fc98e1e5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*ji3ZJfvBhsFoi8C_vkHEQQ.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx np di nq ml translated">使用DistilBERT的模型速度与使用BERT-BASE-UNCASED的模型速度</figcaption></figure></div><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nr"><img src="../Images/de716f37b7fda27347140612d29dc145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jjE6nkiAkQQ0FiANx0YtVg.png"/></div></div></figure><p id="4c2c" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">让我们使用不同的Out-Of-Fold来估计模型在用于对新数据进行预测时的性能。这项技术将侧重于输出排名，而不是价值(采取无偏的平均)。因此，我们相应地重新调整输出数组。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div class="er es ns"><img src="../Images/b7a2a070dafda5e130df07a2d3e4a917.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*dDE1FRQ6JxmD6iX9igLeWQ.png"/></div></figure><p id="0fc8" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">troll检测AUC略有下降(<strong class="jp hs">但仍为0.99 </strong>)。然而，我们在争议性预测指标上提高了15.5个百分点。<strong class="jp hs">其AUC为0.7 </strong>。这种改进主要是通过改变OOF方法实现的。下面您可以找到这两种功能的分类准确性报告。</p><div class="li lj lk ll fd ab cb"><figure class="ly lm nt ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/788fd8eb7d7ced495035f7f19869294d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*wCdbNTYdlW09PRwwzEq2Qw.png"/></div></figure><figure class="ly lm nu ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/9e0ece04628aed96541742ef10674e4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*9JxxHLm-Dj9wqBEegXYP4g.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx nv di nw ml translated">具有BERT和OOF的模型:troll后预测准确性度量与后争议性预测准确性。</figcaption></figure></div><h1 id="e668" class="kk kl hi bd km kn ko kp kq kr ks kt ku ix kv iy kw ja kx jb ky jd kz je la lb bi translated">6.结论和未来步骤</h1><p id="c71c" class="pw-post-body-paragraph jn jo hi jp b jq lc is js jt ld iv jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">NLP的进步提高了我们探测巨魔的能力。我认为争议性预测还有很大的改进空间，因为很多争议性数据可以从<a class="ae kj" href="https://bigquery.cloud.google.com/table/fh-bigquery:reddit_comments.2015_05?pli=1" rel="noopener ugc nofollow" target="_blank">谷歌大查询</a>获得。</p><figure class="li lj lk ll fd lm er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es nx"><img src="../Images/5699572a064b72a7d10c0c19c1465741.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SHD5AtYRTxFcv4GPvU0rqA.png"/></div></div></figure><p id="50e4" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">正如Brandon和Henry正确指出的，存在troll数据可用性的问题。我们可以尝试用一种叫做伪标签的技术来解决这个问题。它在卡格勒人中广为人知，也在一些学术论文中使用，如<a class="ae kj" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank">这篇</a>。我将使用当前模型作为教师模型，它将从新的普通用户数据中挑选标记为troll的帖子。在下一步中，我将使用这些帖子和我们目前拥有的troll数据来训练一个新模型。这种方法包含巨大的过度拟合的风险，但是有一定的技术来对抗它。</p><p id="1e9d" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我将更新模型，并在通过上述方法获得的更大数据块上对其进行训练。</p><p id="c535" class="pw-post-body-paragraph jn jo hi jp b jq jr is js jt ju iv jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我鼓励所有阅读这篇文章的人从我的github 中尝试原始的<a class="ae kj" href="https://github.com/pashadude/troll_detection_nlp" rel="noopener ugc nofollow" target="_blank">代码，报告错误，尝试参数更改，运行一些采样实验，并给我发送改进建议。</a></p></div></div>    
</body>
</html>