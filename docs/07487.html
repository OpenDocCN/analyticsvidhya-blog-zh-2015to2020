<html>
<head>
<title>Precision and Recall in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的精度和召回率</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/precision-and-recall-in-machine-learning-c8a1b9638eeb?source=collection_archive---------6-----------------------#2020-06-27">https://medium.com/analytics-vidhya/precision-and-recall-in-machine-learning-c8a1b9638eeb?source=collection_archive---------6-----------------------#2020-06-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e503" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">精确召回曲线及其在不平衡数据集上的性能</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/ee92ec2c376855d5255cca32542bdff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hgiyREZkP80TJkx3"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">威廉·沃比在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="95a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器学习中的查准率和查全率是评价分类器的重要指标。这两种度量不仅在机器学习中，而且在信息检索、模式识别等方面都有重要的用途。</p><p id="ff28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然有很多关于精确召回的博客和教程，但是关于精确召回曲线和曲线下面积的资料很少。</p><p id="1d07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我试图从机器学习的角度，使用一个示例数据集和r代码来解释精确度、召回率及其相关的F₁分数。<br/>我也解释了相对于ROC曲线，在平衡和不平衡的数据上精度和召回是如何表现的。(关于ROC曲线及其在R中的AUC，你可以参考我之前的一篇<a class="ae jt" href="http://ruchideshpande.com/2020/06/roc-curve-and-auc-detailed-understanding-and-r-proc-package/" rel="noopener ugc nofollow" target="_blank">博客</a>)。</p><p id="fa71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了建立我们对精确度和召回率的理解，让我们从混淆矩阵开始。</p><h1 id="356e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">混淆矩阵</h1><p id="ca40" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们先用混淆矩阵来定义这些术语。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kx"><img src="../Images/a94ea3dbe963a3a4c5f3d7b17a80309b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PNsylKWmUHC9LZVz3coCrA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="2c8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">精度= TP/TP+FP</p><p id="a2e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">召回= TP/TP+FN</p><p id="369a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简而言之，Precision回答了这样一个问题:在积极预测的值中，有多少值被分类器预测为积极的？</p><p id="b0e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回忆回答了这个问题——在实际的正值中，有多少值被分类器预测为正值？</p><p id="b00b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们理解精确度和召回率如何随着分类器的阈值而变化。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ky"><img src="../Images/c144ebbdff30ab2410a50882a4039c63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BBKFgNYmcUHyl7fWB94RKg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="128d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，假设我的阈值最初为0.5，因此当我的分类器预测高于0.5的概率时，我将其分配给肯定类，对于低于0.5的概率，我将其分配给否定类。现在，我把阈值提高到0.7。精度会更高，因为我的FP(实际为负，预测为正)会更低。另一方面，回忆会更低，因为现在FN(实际上为正，但预测为负)会更高。</p><p id="19f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们将阈值移动到一个较低的值，比如0.3。这里精度会低一些，召回率会高一些。</p><p id="c214" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的讨论中，很明显我们需要一个度量来解释精确度和召回率。然后，可以在该指标表现良好的地方设置阈值。这个指标被称为F₁分数，它是精确度和召回率的调和平均值。<br/>数学上，F₁分数由下式给出:</p><p id="9346" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">F₁分数= 2 (P*R)/(P+R)</p><p id="b85e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里需要注意的重要一点是，F₁分数对于不平衡数据集也非常有效。</p><p id="7be7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们深入研究，并通过一个示例数据集来实现上面的讨论。在这个过程中，我们还将查看精确召回曲线。</p><h1 id="f742" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">使用示例数据集的精确度和召回率</h1><p id="c1e1" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我使用了一个来自Analytics vid hya hackathons-<a class="ae jt" href="https://datahack.analyticsvidhya.com/contest/wns-analytics-hackathon-2018-1/" rel="noopener ugc nofollow" target="_blank">“HR Analytics”</a>的数据集。我特意选择了这个数据集，因为它是不平衡数据集的一个很好的例子。这里的问题陈述是根据许多变量，如他们的服务记录、培训分数、上一年的评级等，来预测将被提升的员工。<br/>在这里，我只使用了训练数据集，并进行了最少的数据预处理，以保持分析简单明了。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="d72e" class="le jv hi la b fi lf lg l lh li">train &lt;- read.csv("train.csv") <br/>summary(train) dim(train)</span></pre><p id="6d7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们使用freq函数来检查因变量以及它的不平衡程度。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="e1bb" class="le jv hi la b fi lf lg l lh li">library(summarytools)</span><span id="7e94" class="le jv hi la b fi lj lg l lh li">freq(train$is_promoted)</span><span id="b9ed" class="le jv hi la b fi lj lg l lh li">## Frequencies  <br/>## train$is_promoted  <br/>## Type: Numeric  <br/>## <br/>##                Freq   % Valid   % Valid Cum.   % Total   <br/>## ----------- ------- --------- -------------- --------- <br/>##           0   50140     91.48       91.48       91.48          <br/>##           1    4668      8.52       100.00      8.52         <br/>##        &lt;NA&gt;       0                             0.00         <br/>##       Total   54808    100.00       100.00     100.00         </span></pre><p id="2f88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此处的因变量“is_promoted”高度不平衡，8.5%的员工获得晋升，91.5%的员工未获得晋升。</p><p id="66fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们快速检查丢失的值。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="30cb" class="le jv hi la b fi lf lg l lh li">train[train == ""] &lt;- NA sapply(train,function(x) sum(is.na(x)))</span><span id="a1d4" class="le jv hi la b fi lj lg l lh li">library(DataExplorer)</span><span id="9357" class="le jv hi la b fi lj lg l lh li">plot_missing(train)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lk"><img src="../Images/9d906f71710fc2bd273f53c3012c0329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*7W4mYNCEJBQG9LD_HI8q_A.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">绘图输出(plot_missing)</figcaption></figure><p id="c88c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">变量“教育”和“前一年评级”都缺少值。我使用模式替代法进行缺失值插补。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="0890" class="le jv hi la b fi lf lg l lh li">mode_calc &lt;- names(which.max(table(train$education))) <br/>mode_calc1 &lt;- names(which.max(table(train$previous_year_rating))) </span><span id="c381" class="le jv hi la b fi lj lg l lh li">train$education &lt;- ifelse(is.na(train$education),mode_calc,train$education) </span><span id="9703" class="le jv hi la b fi lj lg l lh li">train$previous_year_rating &lt;- ifelse(is.na(train$previous_year_rating),mode_calc1,train$previous_year_rating)</span></pre><p id="cbf2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将数据拆分为训练数据集和验证数据集。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="ed3f" class="le jv hi la b fi lf lg l lh li"># Training and validation <br/>data set.seed(123) <br/>partition &lt;- sample(2, nrow(train), replace=TRUE, prob=c(0.7, 0.3)) tdata &lt;- train[partition==1,] <br/>vdata &lt;- train[partition==2,] <br/>vdata_X &lt;- vdata[,-14] <br/>vdata_Y &lt;- vdata[,14] <br/>dim(tdata)<br/>dim(vdata)</span><span id="c85f" class="le jv hi la b fi lj lg l lh li">## [1] 38553 14</span><span id="7789" class="le jv hi la b fi lj lg l lh li">## [1] 16255 14</span></pre><p id="ec0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们拟合一个逻辑回归并检查ROC和精确回忆曲线。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="fb70" class="le jv hi la b fi lf lg l lh li"># Logistic regression <br/>LR_fit &lt;- glm(is_promoted~.,data=tdata,family = binomial()) summary(LR_fit) </span><span id="59f0" class="le jv hi la b fi lj lg l lh li">LR_predict &lt;- predict(LR_fit,newdata = vdata_X ,type="response") LR_predict_bin &lt;- ifelse(LR_predict &gt; 0.5,1,0)</span></pre><p id="0ab0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们检查所有评估指标。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="1815" class="le jv hi la b fi lf lg l lh li"># Confusion matrix <br/>cm_lr &lt;- table(vdata_Y,LR_predict_bin) <br/># Accuracy <br/>accuracy &lt;- (sum(diag(cm_lr))/sum(cm_lr)) <br/># Precision <br/>precision &lt;- cm_lr[2,2]/(cm_lr[2,2]+cm_lr[1,2]) <br/># Recall <br/>recall &lt;- cm_lr[2,2]/(cm_lr[2,2]+cm_lr[2,1]) <br/># <!-- -->F₁<!-- --> score <br/>f_score &lt;- 2*(precision*recall)/(precision+recall)</span></pre><p id="67a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准确率— 93% <br/>精度— 0.79 <br/>召回率— 0.27 <br/> F₁评分— 0.4</p><p id="ea14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里模型的精度很高，虽然我没有在模型的微调上做任何努力。如此高的准确性可能是因为所用的数据集高度不平衡，即使我将所有员工分配到0类，准确性仍然很高。但是F₁分数看起来并不乐观。让我们也检查一下ROC曲线。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="bccb" class="le jv hi la b fi lf lg l lh li">library(pROC)</span><span id="ed51" class="le jv hi la b fi lj lg l lh li">par(pty="s") <br/>curve_roc &lt;- roc(vdata_Y ~ LR_predict,plot=TRUE,print.auc=TRUE,col="blue",lwd =4,legacy.axes=TRUE,main="ROC Curve - Imbalanced Data")</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/90fc10750a55171e49fa9ed15b3dde86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*9Glgc7eW4ptBO8LUHn9wYg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">roc()输出</figcaption></figure><p id="a4e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">观察到AUC很高，为0.871。因此，很明显，在这种不平衡的数据集中，ROC曲线通常不是一个很好的选择。</p><p id="16d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们绘制精确回忆曲线或PR曲线，它的AUC。<br/>与ROC曲线一样，PR曲线也是针对所有阈值绘制的。<br/>我已经为此使用了PRROC包。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="6da3" class="le jv hi la b fi lf lg l lh li">library(PRROC)</span><span id="d153" class="le jv hi la b fi lj lg l lh li">curve_pr &lt;- pr.curve(LR_predict,weights.class0 = vdata_Y,curve=TRUE) plot(curve_pr,main="PR Curve - Imbalanced Data")</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/4e822453f63a9aa8e5df0451ce27c616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*pnkZafpuoVqRzCOU0LrhlQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">参数曲线()输出</figcaption></figure><p id="ec07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，PR曲线AUC = 0.53似乎是合理的。</p><p id="16f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们更进一步，尝试平衡数据集，然后检查相同的评估指标。</p><p id="6471" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SMOTE(合成少数过采样技术)是一种非常好的技术，它使用过采样方法来平衡数据集，以产生类平衡的数据。R中的ROSE包使用了SMOTE技术，但是它只处理连续的和分类的数据，所以我们必须首先转换这里的几个变量的数据类型。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="b896" class="le jv hi la b fi lf lg l lh li">library(ROSE) <br/>set.seed(123456) <br/>train$is_promoted &lt;- as.numeric(train$is_promoted) <br/>train$education &lt;- as.numeric(train$education) train$previous_year_rating &lt;- as.numeric(train$previous_year_rating) train_rose &lt;- ROSE(is_promoted ~ .,data=train,seed=1)$data</span><span id="97b2" class="le jv hi la b fi lj lg l lh li">freq(train_rose$is_promoted)</span><span id="1295" class="le jv hi la b fi lj lg l lh li">## Frequencies  <br/>## train_rose$is_promoted  <br/>## Type: Numeric  <br/>## <br/>##                Freq   % Valid   % Valid Cum.   % Total   <br/>## ----------- ------- --------- -------------- --------- <br/>##           0   26181     49.96          49.96     49.96          <br/>##           1   26218     50.04         100.00     50.04         <br/>##        &lt;NA&gt;       0                               0.00         <br/>##       Total   52399    100.00         100.00    100.00         </span></pre><p id="6457" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，数据与类0和类1都是50%平衡。</p><p id="9045" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">再次将此数据集拆分为训练数据集和验证数据集。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="600c" class="le jv hi la b fi lf lg l lh li">set.seed(123) <br/>partition &lt;- sample(2, nrow(train_rose), replace=TRUE, prob=c(0.7, 0.3)) <br/>trdata &lt;- train_rose[partition==1,] <br/>vrdata &lt;- train_rose[partition==2,] <br/>vrdata_X &lt;- vrdata[,-14] <br/>vrdata_Y &lt;- vrdata[,14] <br/>dim(trdata)<br/>dim(vrdata)</span><span id="cde3" class="le jv hi la b fi lj lg l lh li">## [1] 36873 14</span><span id="7790" class="le jv hi la b fi lj lg l lh li">## [1] 15526 14</span><span id="f094" class="le jv hi la b fi lj lg l lh li"># Fitting logistic regression again on balanced dataset <br/>LR_fit1 &lt;- glm(is_promoted ~.,data=trdata,family = binomial()) LR_predict1 &lt;- predict(LR_fit1,newdata = vrdata_X ,type="response") LR_predict_bin1 &lt;- ifelse(LR_predict1 &gt; 0.5,1,0)</span><span id="5ec0" class="le jv hi la b fi lj lg l lh li"># Confusion matrix <br/>cm_lr1 &lt;- table(vrdata_Y,LR_predict_bin1) <br/># Accuracy <br/>accuracy1 &lt;- (sum(diag(cm_lr1))/sum(cm_lr1)) <br/># Precision <br/>precision1 &lt;- cm_lr1[2,2]/(cm_lr1[2,2]+cm_lr1[1,2]) <br/># Recall <br/>recall1 &lt;- cm_lr1[2,2]/(cm_lr1[2,2]+cm_lr1[2,1]) <br/># <!-- -->F₁<!-- --> score <br/>f_score1 &lt;- 2*(precision1*recall1)/(precision1+recall1)</span></pre><p id="89d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于平衡数据集，下面是评估指标。这里需要注意的重要一点是，尽管准确性比早期的不平衡数据集有所降低，但F₁评分已经从0.4提高到0.73。<br/>准确率— 73% <br/>精度— 0.73 <br/>召回率— 0.72 <br/> F₁评分— 0.73</p><p id="33e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们检查平衡数据的ROC曲线。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="b771" class="le jv hi la b fi lf lg l lh li">par(pty="s") <br/>curve_roc1 &lt;- roc(vrdata_Y ~ LR_predict1,plot=TRUE,print.auc=TRUE,col="green",lwd =4,legacy.axes=TRUE,main="ROC Curve - Balanced Data")</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/68e02dd96bb0e9a5003f9378db18c347.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*zOShq3eknnIH2yK_n055Og.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">roc()输出</figcaption></figure><p id="4970" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ROC AUC从0.871略微下降到0.818。让我们检查一下PR曲线的AUC。</p><pre class="je jf jg jh fd kz la lb lc aw ld bi"><span id="b2c5" class="le jv hi la b fi lf lg l lh li">curve_pr1 &lt;- pr.curve(LR_predict1,weights.class0 = vrdata_Y,curve=TRUE) plot(curve_pr1,main="PR Curve - Balanced Data")</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/4fee822860e5861e51ae786caa31b519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*Z0UZ9TO-YR2cNqMkP0Nmtw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">参数曲线()输出</figcaption></figure><p id="a5d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PR曲线的AUC从0.53显著提高到0.807。</p><h1 id="d6fb" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">结论</h1><p id="01aa" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">精确度、召回率和F₁评分是测试模型的好方法，F₁评分同时考虑了精确度和召回率。理想情况下，我们希望精确度和召回率都很高，从而最小化FP和FN。然而，在现实生活中，精确度和召回率之间的权衡是可取的，这通常取决于我们正在处理的领域。<br/>在上面的数据集例子中，我们看到在不平衡数据集的情况下，PR曲线比ROC曲线更可靠。</p><p id="8f73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望本教程有助于更好地理解PR曲线及其在平衡和不平衡数据集中的表现。</p><p id="8769" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢阅读。我很高兴收到关于内容的反馈、评论和任何问题。</p><h2 id="2b6e" class="le jv hi bd jw lm ln lo ka lp lq lr ke iq ls lt ki iu lu lv km iy lw lx kq ly bi translated">参考</h2><p id="c700" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">[1].Jan Grau等人，PRROC:在R中计算和可视化精度-召回和接收器操作特性曲线</p><p id="bf4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2].不平衡数据:如何处理分类不平衡问题，AnalyticsVidhya<a class="ae jt" href="https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/" rel="noopener ugc nofollow" target="_blank">https://www . AnalyticsVidhya . com/blog/2017/03/unbalanced-Data-Classification/</a></p><p id="5d94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">开心连线<a class="ae jt" href="https://www.linkedin.com/in/ruchideshpande/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>！！</p></div></div>    
</body>
</html>