<html>
<head>
<title>Hyper Parameter Tuning (GridSearchCV Vs RandomizedSearchCV)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超级参数调整(GridSearchCV 与 RandomizedSearchCV)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hyper-parameter-tuning-gridsearchcv-vs-randomizedsearchcv-499862e3ca5?source=collection_archive---------3-----------------------#2020-12-22">https://medium.com/analytics-vidhya/hyper-parameter-tuning-gridsearchcv-vs-randomizedsearchcv-499862e3ca5?source=collection_archive---------3-----------------------#2020-12-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="902f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据科学家经常在日常的机器学习实现中处理超参数调整。那么什么是超参数，我们为什么需要它们？我们将更多地讨论两种主要类型的超参数调整，即网格搜索 CV 和随机搜索 CV。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/1fca0ed0be3a44e9314c374fe418871e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Pyi6xkiNMjg4vkyf"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">照片由<a class="ae jt" href="https://unsplash.com/@denisseleon?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">丹尼斯·莱昂</a>在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><blockquote class="ju jv jw"><p id="c5d0" class="if ig jx ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">什么是超参数？</p><p id="f7c9" class="if ig jx ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">超参数更像是可用于控制用于建模的算法的输出或行为的手柄。它们可以作为参数提供给算法。例如:model = decision tree classifier(criterion = ' entropy ')，这里的标准熵是传递的超级参数。</p></blockquote><p id="e9fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">函数 get_params()是用于获取任何算法的所有超参数列表的函数。</p><p id="bae7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当超参数没有给算法时，选择默认值来运行模型。这使得超参数调整成为机器学习实现中涉及的关键步骤之一。</p><p id="9bbd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">超参数调整中涉及的步骤</p><ol class=""><li id="7186" class="kb kc hi ih b ii ij im in iq kd iu ke iy kf jc kg kh ki kj bi translated">为模型选择合适的算法</li><li id="b5db" class="kb kc hi ih b ii kk im kl iq km iu kn iy ko jc kg kh ki kj bi translated">决定参数空间</li><li id="9f44" class="kb kc hi ih b ii kk im kl iq km iu kn iy ko jc kg kh ki kj bi translated">决定搜索参数空间的方法</li><li id="4b4e" class="kb kc hi ih b ii kk im kl iq km iu kn iy ko jc kg kh ki kj bi translated">决定交叉验证方法</li><li id="dcbe" class="kb kc hi ih b ii kk im kl iq km iu kn iy ko jc kg kh ki kj bi translated">决定评估模型的评分标准</li></ol><p id="305f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了在超参数空间中搜索最佳值，我们可以使用</p><ol class=""><li id="3502" class="kb kc hi ih b ii ij im in iq kd iu ke iy kf jc kg kh ki kj bi translated">GridSearchCV(考虑所有可能的超参数组合)</li><li id="c1df" class="kb kc hi ih b ii kk im kl iq km iu kn iy ko jc kg kh ki kj bi translated">RandomizedSearchCV(仅随机选择少量样本)</li></ol><blockquote class="ju jv jw"><p id="7fbe" class="if ig jx ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated"><strong class="ih hj"> Cross </strong> - <strong class="ih hj"> validation </strong>是一个用于评估机器学习模型的重采样程序。该方法具有单个参数 k，该参数指的是给定数据样本将被分割成的分区的数量。所以，它们通常被称为<strong class="ih hj"> k 倍</strong> <strong class="ih hj">交叉</strong> - <strong class="ih hj">验证</strong>。数据分为训练集、验证集和测试集，以防止数据泄露。因此，只有在使用训练和验证集拟合模型之后，才应该转换测试集。每次模型拟合训练数据时，都用测试数据对它们进行评估，评估分数的平均值用于分析整个模型。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kp"><img src="../Images/9375401f20f00355961873f86e0dea1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*5Ccu_OfokOZ1m4-pD0wjYg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><h1 id="4719" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">GridSearchCV</h1><p id="cdd4" class="pw-post-body-paragraph if ig hi ih b ii lo ik il im lp io ip iq lq is it iu lr iw ix iy ls ja jb jc hb bi translated">网格搜索是使用的最基本的超参数技术之一，因此它们的实现非常简单。特定模型的超参数的所有可能排列被用于建立模型。评估每个模型的性能，并选择性能最好的一个。由于 GridSearchCV 使用每个组合来构建和评估模型性能，因此这种方法的计算成本非常高。随机森林算法 GridSearchCV 的 python 实现如下。</p><pre class="je jf jg jh fd lt lu lv lw aw lx bi"><span id="f0fc" class="ly kr hi lu b fi lz ma l mb mc"># Run GridSearch to tune the hyper-parameter<br/>from sklearn.model_selection import GridSearchCV<br/>rfr=RandomForestRegressor()<br/>k_fold_cv = 5 # Stratified 5-fold cross validation<br/>grid_params = {<br/> “n_estimators” : [10,50,100],<br/> “max_features” : [“auto”, “log2”, “sqrt”],<br/> “bootstrap” : [True, False]<br/> }<br/>grid = GridSearchCV(rfr, param_grid=grid_params, cv=k_fold_cv, <br/> n_jobs = 1, verbose = 0, return_train_score=True)<br/>grid.fit(X_train, y_train)<br/>print(‘Best hyper parameter:’, grid.best_params_)<br/></span></pre><div class="md me ez fb mf mg"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">sklearn.model_selection。GridSearchCV-scikit-学习 0.24.0 文档</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">对估计量的特定参数值的穷举搜索。重要成员是适合的，预测。GridSearchCV…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">scikit-learn.org</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu jn mg"/></div></div></a></div><p id="92fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您注意到 grid_params，超参数 n_estimators 和 max_features 各有三个值。因此，仅这两个超参数就有 3 x 3 = 9 种组合。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/92fd4e22c8227a5298fd25c3df99f57c.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*EgOmtcE3PfaurUTp3EPKaQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="cffd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，超参数的所有排列将产生大量的模型，随着数据量的增加，计算速度急剧下降。这就是为什么数据科学家在处理庞大的数据集时更喜欢 RandomizedSearchCV 而不是 GridSearchCV。</p><h1 id="0cb7" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">随机搜索</h1><p id="bd68" class="pw-post-body-paragraph if ig hi ih b ii lo ik il im lp io ip iq lq is it iu lr iw ix iy ls ja jb jc hb bi translated">在 randomizedsearchcv 中，我们提供了超参数的统计分布或列表，而不是提供一组离散的值来研究每个超参数。不同超参数的值从该分布中随机选取。随机森林算法 GridSearchCV 的 python 实现如下。</p><pre class="je jf jg jh fd lt lu lv lw aw lx bi"><span id="ebe1" class="ly kr hi lu b fi lz ma l mb mc"># Run RandomizedSearchCV to tune the hyper-parameter<br/>from sklearn.model_selection import RandomizedSearchCV<br/>rfr=RandomForestRegressor()<br/>k_fold_cv = 5 # Stratified 5-fold cross validation<br/>params = {<br/> “n_estimators” : [10,50,100],<br/> “max_features” : [“auto”, “log2”, “sqrt”],<br/> “bootstrap” : [True, False]<br/> }<br/>random = RandomizedSearchCV(rfr, param_distributions=params, cv=k_fold_cv,<br/> n_iter = 5, scoring=’neg_mean_absolute_error’,verbose=2, random_state=42,<br/> n_jobs=-1, return_train_score=True)<br/>random.fit(X_train, y_train)<br/>print(‘Best hyper parameter:’, random.best_params_)</span></pre><div class="md me ez fb mf mg"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">sklearn.model_selection。randomized search cv-sci kit-learn 0 . 24 . 0 文档</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">超参数随机搜索。RandomizedSearchCV 实现了一个“fit”和一个“score”方法。它还实现了…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">scikit-learn.org</p></div></div><div class="mp l"><div class="mw l mr ms mt mp mu jn mg"/></div></div></a></div><p id="4b53" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以得出结论，GridSearchCV 只适用于小数据集。当涉及到更大的数据集时，RandomizedSearchCV 优于 GridSearchCV。</p><p id="bfe9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望你能从这篇文章中得到一些启示。关注更多！</p><p id="a18f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可能还喜欢:</p><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/machine-learning-algorithms-logistics-regression-8ba38af531b3"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">机器学习算法:逻辑回归</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">Tom Mitchell 最著名的定义之一是将机器学习定义为“一个性能良好的计算机程序…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="mx l mr ms mt mp mu jn mg"/></div></div></a></div><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/machine-learning-algorithms-support-vector-machines-ddfc413540d2"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">机器学习算法:支持向量机</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">在机器学习算法系列的第三篇文章中，我将讨论最流行的监督学习算法</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="my l mr ms mt mp mu jn mg"/></div></div></a></div><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/machine-learning-algorithms-naïve-bayes-classifier-and-knn-classifier-266537e9c2f2"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">机器学习算法:朴素贝叶斯分类器和 KNN 分类器</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">在机器学习算法的第二篇文章中，我将重点介绍朴素贝叶斯分类器和 KNN…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="mz l mr ms mt mp mu jn mg"/></div></div></a></div></div></div>    
</body>
</html>