<html>
<head>
<title>Simplest Introduction to Neural Networks in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras中神经网络的最简单介绍</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/simplest-introduction-to-neural-networks-in-keras-c6ce8d666461?source=collection_archive---------14-----------------------#2020-02-21">https://medium.com/analytics-vidhya/simplest-introduction-to-neural-networks-in-keras-c6ce8d666461?source=collection_archive---------14-----------------------#2020-02-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="a30c" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">解决非线性异或问题</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/71e539226b3d91f3f7448a27329d3bd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*QHT_gsz58qO-iYUKCSJZYA.png"/></div></figure><p id="7566" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">神经网络是一种非常有用的工具，可以用来解决许多不同性质的问题，因为它是一种通用的近似方法，T2。在这个世界中，一个好的开始方法是使用一个众所周知的简单神经网络库:<a class="ae kb" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="jh hj"> Keras </strong> </a></p><p id="62a0" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在本文中，将展示解决机器学习和神经网络中最简单的问题之一的最简单的方法。</p><h1 id="07e8" class="kd ke hi bd kf kg kh ki kj kk kl km kn io ko ip kp ir kq is kr iu ks iv kt ku bi translated">异或问题</h1><p id="04b7" class="pw-post-body-paragraph jf jg hi jh b ji kv ij jk jl kw im jn jo kx jq jr js ky ju jv jw kz jy jz ka hb bi translated">首先，XOR是一个<strong class="jh hj">逻辑运算</strong>，可以用下面的真值表来定义:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es la"><img src="../Images/696a3fe44df2413c3e43b99731c6c68f.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*7XWE4YbrC55zXb-LZblgIA.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">异或的真值表。</figcaption></figure><p id="9b2e" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在给定输入<em class="kc"> A </em>和<em class="kc"> B </em>的情况下，当情况<strong class="jh hj">不是线性问题</strong>时，使用神经网络来学习该函数如何生成答案<em class="kc"> C </em>的巨大动机出现了。</p><p id="923f" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">以教导的方式，为了理解说XOR问题不是线性的意味着什么，从几何学上看，用笛卡尔平面中的一条<strong class="jh hj">单线</strong>来分隔答案<em class="kc"> 0 </em>和<em class="kc"> 1 </em>是<strong class="jh hj">不可能的:</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lf"><img src="../Images/e755bb60fde1d4dfa87ffcc8e0136c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*QPB3jN7FpjUDRc47WZV_iw.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">这个问题需要不止一条线来聚类答案，它是一个非线性问题。</figcaption></figure><p id="4852" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">因此，在实践中，将验证单个神经元(<a class="ae kb" href="https://en.wikipedia.org/wiki/Perceptron" rel="noopener ugc nofollow" target="_blank"> <em class="kc">感知器</em> </a> ) <strong class="jh hj">不能</strong>解决问题，但是<a class="ae kb" href="https://en.wikipedia.org/wiki/Deep_learning" rel="noopener ugc nofollow" target="_blank"> DNN </a> <strong class="jh hj">可以</strong>。</p><h1 id="2b15" class="kd ke hi bd kf kg kh ki kj kk kl km kn io ko ip kp ir kq is kr iu ks iv kt ku bi translated">我们来编码吧！</h1><p id="9fed" class="pw-post-body-paragraph jf jg hi jh b ji kv ij jk jl kw im jn jo kx jq jr js ky ju jv jw kz jy jz ka hb bi translated">为了解决这个问题，使用了<strong class="jh hj"> Keras </strong>神经网络库和<a class="ae kb" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jh hj"> numpy </strong> </a>，它们都可以使用<strong class="jh hj"> pip </strong>下载，如下所示:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="4485" class="ll ke hi lh b fi lm ln l lo lp">pip install <strong class="lh hj">keras<br/></strong>pip install<strong class="lh hj"> numpy</strong></span></pre><p id="ad18" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">因此可以开始导入这些库:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="592f" class="ll ke hi lh b fi lm ln l lo lp"><strong class="lh hj">import</strong> numpy <strong class="lh hj">as</strong> np<br/><strong class="lh hj">from</strong> keras.models <strong class="lh hj">import</strong> Sequential<br/><strong class="lh hj">from</strong> keras.layers.core <strong class="lh hj">import</strong> Dense, Dropout, Activation<br/><strong class="lh hj">from</strong> keras.optimizers <strong class="lh hj">import</strong> SGD</span></pre><p id="93bd" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了<strong class="jh hj">训练</strong>神经网络系统，需要定义什么将是<strong class="jh hj">输入向量</strong>和对应的对输入进行分类的<strong class="jh hj">输出向量</strong>。</p><p id="125d" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于这个问题，输入向量<em class="kc"> x </em>被定义为所有<em class="kc"> A </em>和<em class="kc"> B </em>的可能性，每个可能性有<em class="kc"> 1位</em>，输出向量<em class="kc"> y </em>作为异或答案(查看<strong class="jh hj">真值表</strong>中的<em class="kc"> C </em>变量)，</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="af8c" class="ll ke hi lh b fi lm ln l lo lp">x = np.array([[<strong class="lh hj">1</strong>,<strong class="lh hj">0</strong>], [<strong class="lh hj">1</strong>,<strong class="lh hj">1</strong>], [<strong class="lh hj">0</strong>,<strong class="lh hj">1</strong>], [<strong class="lh hj">0</strong>,<strong class="lh hj">0</strong>]])<br/>y = np.array([[<strong class="lh hj">1</strong>], [<strong class="lh hj">0</strong>], [<strong class="lh hj">1</strong>], [<strong class="lh hj">0</strong>]])</span></pre><p id="80f9" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">之后，现在可以描述将用于训练系统的<strong class="jh hj">架构</strong>。由于我们希望简单，我们将比较一个单神经元(<em class="kc">感知器</em>模型)与一个<strong class="jh hj">两个ReLU隐层DNN </strong>与<strong class="jh hj"> 8 </strong>神经元:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="7288" class="ll ke hi lh b fi lm ln l lo lp">model = Sequential()<br/>model.<strong class="lh hj">add</strong>(Dense(<strong class="lh hj">8</strong>, input_dim=<strong class="lh hj">2</strong>))<br/>model.<strong class="lh hj">add</strong>(Activation('<strong class="lh hj">relu</strong>'))<br/>model.<strong class="lh hj">add</strong>(Dense(<strong class="lh hj">8</strong>))<br/>model.<strong class="lh hj">add</strong>(Activation('<strong class="lh hj">relu</strong>'))<br/>model.<strong class="lh hj">add</strong>(Dense(<strong class="lh hj">1</strong>, activation='<strong class="lh hj">sigmoid</strong>'))</span></pre><p id="d1c6" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了<strong class="jh hj">编译</strong>Keras模型，损失函数被定义为<strong class="jh hj">二元</strong> <strong class="jh hj">交叉熵</strong>，并且<strong class="jh hj">随机梯度下降</strong>作为<strong class="jh hj">优化器</strong>，以<strong class="jh hj"> 0.1 </strong>作为<em class="kc">学习率</em>系数:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="f729" class="ll ke hi lh b fi lm ln l lo lp">sgd = <strong class="lh hj">SGD</strong>(lr=0.1)<br/>model.<strong class="lh hj">compile</strong>(loss='<strong class="lh hj">binary_crossentropy</strong>', optimizer='<strong class="lh hj">sgd</strong>')</span></pre><p id="6b51" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了完成实现，使用<strong class="jh hj">1000</strong>T38】历元和<strong class="jh hj">批量1 </strong>到<strong class="jh hj">拟合</strong>模型:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="96b5" class="ll ke hi lh b fi lm ln l lo lp">model.<strong class="lh hj">fit</strong>(x, y, epochs=<strong class="lh hj">1000</strong>, batch_size= <strong class="lh hj">1</strong>)</span></pre><p id="17d9" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">要查看实现是否正确，可以让系统<strong class="jh hj">预测</strong>期望的答案:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="5f04" class="ll ke hi lh b fi lm ln l lo lp">predictions = model.<strong class="lh hj">predict</strong>(x)<br/><strong class="lh hj">print</strong>(predictions)</span></pre><p id="c5d7" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">因此，<strong class="jh hj">的完整代码</strong>将是:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="46c4" class="ll ke hi lh b fi lm ln l lo lp">"""<br/>Created on Fri Feb 21 02:01:40 2020</span><span id="c484" class="ll ke hi lh b fi lq ln l lo lp"><a class="ae kb" href="http://twitter.com/author" rel="noopener ugc nofollow" target="_blank">@author</a>: Matheus Farias<br/>"""</span><span id="abe7" class="ll ke hi lh b fi lq ln l lo lp">#importing libraries</span><span id="58eb" class="ll ke hi lh b fi lq ln l lo lp"><strong class="lh hj">from</strong> keras.models import Sequential<br/><strong class="lh hj">from</strong> keras.layers.core <strong class="lh hj">import</strong> Dense, Dropout, Activation<br/><strong class="lh hj">from</strong> keras.optimizers <strong class="lh hj">import</strong> SGD<br/><strong class="lh hj">import</strong> numpy <strong class="lh hj">as</strong> np<br/></span><span id="5121" class="ll ke hi lh b fi lq ln l lo lp">#defining the input and output training vectors</span><span id="25da" class="ll ke hi lh b fi lq ln l lo lp">x = np.array([[<strong class="lh hj">1</strong>,<strong class="lh hj">0</strong>], [<strong class="lh hj">1</strong>,<strong class="lh hj">1</strong>], [<strong class="lh hj">0</strong>,<strong class="lh hj">1</strong>], [<strong class="lh hj">0</strong>,<strong class="lh hj">0</strong>]])<br/>y = np.array([[<strong class="lh hj">1</strong>], [<strong class="lh hj">0</strong>], [<strong class="lh hj">1</strong>], [<strong class="lh hj">0</strong>]])<br/></span><span id="f4df" class="ll ke hi lh b fi lq ln l lo lp"># defining the keras model</span><span id="ab2d" class="ll ke hi lh b fi lq ln l lo lp">model = Sequential()<br/>model.<strong class="lh hj">add</strong>(Dense(<strong class="lh hj">8</strong>, input_dim=<strong class="lh hj">2</strong>))<br/>model.<strong class="lh hj">add</strong>(Activation('<strong class="lh hj">relu</strong>'))<br/>model.<strong class="lh hj">add</strong>(Dense(<strong class="lh hj">8</strong>))<br/>model.<strong class="lh hj">add</strong>(Activation('<strong class="lh hj">relu</strong>'))<br/>model.<strong class="lh hj">add</strong>(Dense(1, activation='<strong class="lh hj">sigmoid</strong>'))<br/></span><span id="8cc3" class="ll ke hi lh b fi lq ln l lo lp"># compiling the keras model</span><span id="e69f" class="ll ke hi lh b fi lq ln l lo lp">sgd = <strong class="lh hj">SGD</strong>(lr=0.1)<br/>model.<strong class="lh hj">compile</strong>(loss='<strong class="lh hj">binary_crossentropy</strong>', optimizer='<strong class="lh hj">sgd</strong>')<br/></span><span id="1ded" class="ll ke hi lh b fi lq ln l lo lp"># fitting the keras model on the training vectors<br/>model.<strong class="lh hj">fit</strong>(x, y, epochs=<strong class="lh hj">1000</strong>, batch_size= <strong class="lh hj">1</strong>)<br/></span><span id="fb94" class="ll ke hi lh b fi lq ln l lo lp"># predicting the desired answers</span><span id="8b75" class="ll ke hi lh b fi lq ln l lo lp">predictions = model.<strong class="lh hj">predict</strong>(x)<br/><strong class="lh hj">print</strong>(predictions)</span></pre><h1 id="1e98" class="kd ke hi bd kf kg kh ki kj kk kl km kn io ko ip kp ir kq is kr iu ks iv kt ku bi translated">结果</h1><p id="5549" class="pw-post-body-paragraph jf jg hi jh b ji kv ij jk jl kw im jn jo kx jq jr js ky ju jv jw kz jy jz ka hb bi translated">输出精度如下所示:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="5f4a" class="ll ke hi lh b fi lm ln l lo lp">[[0.9876364 ]<br/> [0.02138409]<br/> [0.9333476 ]<br/> [0.02856272]]</span></pre><p id="7d38" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这证明了<strong class="jh hj">这个非线性模型解决了问题</strong>。</p><p id="dc36" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在，让我们看看单个神经元，例如，一个线性模型能否解决这个问题。为此，使用了以下模型:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="04f4" class="ll ke hi lh b fi lm ln l lo lp">model = Sequential()<br/>model.<strong class="lh hj">add</strong>(Dense(1, activation='<strong class="lh hj">sigmoid</strong>'))</span></pre><p id="8c5e" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于这种新模型，输出精度如下所示:</p><pre class="iy iz ja jb fd lg lh li lj aw lk bi"><span id="83cb" class="ll ke hi lh b fi lm ln l lo lp">[[0.5178774 ]<br/> [0.49577093]<br/> [0.48331842]<br/> [0.5054262 ]]</span></pre><p id="e6f6" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">验证这个问题<strong class="jh hj">不能用线性模型</strong>解决。</p></div></div>    
</body>
</html>