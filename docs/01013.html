<html>
<head>
<title>Building a Model to Classify and Predict defects in Steel</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建立分类和预测钢中缺陷的模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/severstal-steel-defect-detection-5e5b50fe21ce?source=collection_archive---------2-----------------------#2019-09-25">https://medium.com/analytics-vidhya/severstal-steel-defect-detection-5e5b50fe21ce?source=collection_archive---------2-----------------------#2019-09-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="7120" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">图像掩模的多标记分类和预测</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/9bc9d22fb8fe31828118022ac537d961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*beOmeTDtdKBITQFJrH_MWQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">一场追逐赛</figcaption></figure><p id="2e7b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kk">钢材缺陷检测是由美国最大的钢铁制造公司</em> <a class="ae jn" href="https://www.severstal.com/eng/about/" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj"> <em class="kk">谢韦尔</em> </strong> </a> <strong class="jq hj"> <em class="kk">主办的一场竞赛。</em> </strong> <a class="ae jn" href="https://www.kaggle.com/c/severstal-steel-defect-detection" rel="noopener ugc nofollow" target="_blank"> <em class="kk">这里的</em> </a> <em class="kk">是本次比赛的环节。请访问kaggle网站了解更多关于本次比赛的详情</em></p><h1 id="b191" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">问题陈述</h1><p id="c9c6" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">本次比赛的目的是使用提供的图像预测钢铁制造中发现的缺陷的位置和类型。这些图像以唯一的<em class="kk"> ImageId </em>命名，我们的任务是分割每一幅图像并对测试集中的缺陷进行分类。</p><p id="ad72" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">关于数据:</strong> <a class="ae jn" href="https://www.kaggle.com/c/severstal-steel-defect-detection/data" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj"> <em class="kk">来源</em></strong></a><strong class="jq hj"><em class="kk"/></strong><br/><strong class="jq hj"><em class="kk">DataTrain _ images。Zip </em> </strong>:包含所有列车图像的Zip文件(12568唯一)<br/><strong class="jq hj"><em class="kk">Test _ images . Zip</em></strong>:包含所有列车图像的Zip文件(1801唯一)<br/><strong class="jq hj"><em class="kk">train . csv</em></strong>:包含Imageid和编码像素列<br/><strong class="jq hj"><em class="kk">submission . CSV:</em></strong>测试包含Imageid和编码像素的CSV文件</p><p id="b768" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">数据描述:</strong> <br/>每张图像可能有<strong class="jq hj"><em class="kk"/></strong>，一个<strong class="jq hj"> <em class="kk">缺陷的单个类</em> </strong>，或<strong class="jq hj"> <em class="kk">缺陷的多个类</em> </strong> (ClassId = [1，2，3，4])。</p><p id="aac2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">目的</strong> : <br/>给定一幅图像，我们的任务是对缺陷进行分类，并定位缺陷的分割。对于每一幅图像，如果它属于每一类(ClassId = [1，2，3，4])，你必须分割缺陷。<br/> <strong class="jq hj"> <em class="kk">类标签和掩码信息:</em> </strong> <br/>有两个任务与此问题相关<br/> 1。将图像分类为4个缺陷类(ClassId = [1，2，3，4])。<br/> 1。预测发现缺陷的位置(分段)</p><p id="0013" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">注意</strong>:每个缺陷类别的段将被编码成一个单独的行，即使一幅图像上有几个不连续的缺陷位置，你也可以在这里  <em class="kk">了解更多信息<a class="ae jn" href="https://www.kaggle.com/c/severstal-steel-defect-detection/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="kk">。</em></a></em></p><h1 id="8153" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">各种渠道策略</h1><p id="f184" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">由于这个问题涉及到二元分类，多标签分类和回归，有许多方法可以解决这个问题，我将讨论我在比赛中遇到的一些方法。</p><h2 id="337c" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">管道1:使用分段模型的基本管道</h2><p id="e393" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">第一个也是最有效的策略是使用分割模型，使用分割模型是因为它们将图像划分为多个区域，并可以对图像中的对象进行分类，您可以在此了解更多信息<a class="ae jn" href="https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lw"><img src="../Images/6e76838ee1b8e0ac25c108fa533e5534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TqgNL1Z11KtfG8P3o4q75Q.png"/></div></div></figure><p id="be7f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这是一个简单的管道，所有的输入数据都使用一个强大的训练模型进行训练(很可能是预先训练好的)。该模型的输出层是CNN(4)，其中对于每个输入图像，我们得到四个具有该类分割的掩模(图像)，即类([1，2，3，4])。</p><h2 id="ca19" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated"><strong class="ak">管道-2:使用二元分类进行分割</strong></h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/354168f4f3e617adc32d03208454f3f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TNFzUusfkxzyvDQI8_Gb0g.png"/></div></div></figure><p id="134a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">该策略处理建立分段模型以及二进制分类，强分段模型(预训练的)建立在所有训练数据上，并使用model.save(model_name.h5)保存模型。同样地，保存二进制分类模型，当开始测试数据时，使用预先训练的二进制分类器过滤有缺陷的图像，并且仅将有缺陷的图像发送到分割模型，这样我们可以更快地测试结果，因为我们保存了我们的模型并且还从原始数据中过滤了有缺陷的图像。</p><h2 id="bf1c" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">管道-3:使用多标签分类的分段</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ly"><img src="../Images/5e51de5fd5ff2b4a185442d88ab0c070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XsI1pjxk2k7MEo9fTge-Rw.png"/></div></div></figure><p id="05db" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这是一个与前一个类似的策略，我们不是过滤有缺陷的图像，而是使用一个预先训练的多标签分类模型来获得有缺陷的图像，因为这是一个多标签分类器，一个图像可以属于多个类别。我们直接将来自多标签分类通道的输出用于类别的四个分割模型([1，2，3，4])，这里每个模型是具有各自缺陷类别([1，2，3，4])的预训练分割模型。</p><h2 id="cab7" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">pipeline-4:使用二元和多标签分类的分割模型</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lz"><img src="../Images/92c77e318de2b87d3baf49ff229d730f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8IxmlnTfFzgTMqnFAfK5og.png"/></div></div></figure><p id="3a80" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">你可能已经猜到了，是的！它是管道3和管道4的组合。我部分尝试了上述所有策略，并坚持这样做，因为它给了我比所有更好的结果。这也花费了更少的时间来测试结果，因为我们过滤掉了没有缺陷的图像，并且只将有缺陷的图像发送到分割模型。下面让我给你一个我实现这个方法的详细视图。</p><h1 id="b15b" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">探索性数据分析</h1><p id="4fad" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">让我们看一些EDA来了解更多的数据！</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/717d87b21545d4ccc307e0424d51a346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VLF6VC70-XLfYiC8WTKmsg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">二元分类</strong></figcaption></figure><p id="3022" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如我们在上面看到的缺陷类和非缺陷类的分布，我们说这是一个平衡的<strong class="jq hj">二元分类</strong>问题</p><h2 id="e5e0" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">多标签分类</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mb"><img src="../Images/8110603a4d9095d32ae6ce85fb24c722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*GrHl0sEWpKkiHrADCQBymw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">多标签分类</strong></figcaption></figure><p id="7dc6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如我们看到的，这是一个具有挑战性的问题，其中我们的多标签分类在数据上不平衡，因为2类缺陷图像在数据大小上非常小，而1类缺陷在数据上非常大，3、4类在某种程度上是平衡的。</p><p id="d188" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">考虑到多标签分类的不平衡，我们绘制了每幅图像的类别数</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mc"><img src="../Images/4b3a4c6f8a93181c66c32a0563e64da7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K5YSznN8kHTXyC5fSE4BIA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">每幅图像的类别数量</strong></figcaption></figure><p id="6807" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们可以观察到图像中前2类分布较多，3，4类几乎为零</p><h1 id="eabf" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">可视化训练数据中的每种缺陷:</h1><p id="b3a1" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">让我们看看每一类的一些图像。这种可视化可以很容易地通过掩蔽列车数据图像上给定的编码像素来完成，您可以在这里查阅代码<a class="ae jn" href="https://www.kaggle.com/kenmatsu4/visualize-steel-defect" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="744f" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">一级缺陷</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es md"><img src="../Images/15b45c9ca7622e1f69b95af22cf5e47c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dlj7kIR9QRv2jsEl10z2gg.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/2748f1e52faa21c87c1635afdedbb374.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AQR4oqgO5-b1MNmBMWF2qA.png"/></div></div></figure><p id="a37f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">图像中的红色阴影表示1级。1类似乎缺陷较少，几乎与无缺陷图像相似。</p><h2 id="852f" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">二级缺陷</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mf"><img src="../Images/ddc12be7c8906f4971a305cc52ce22e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ae0bOI-UEwLY-_HMGYgGcA.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mg"><img src="../Images/e50b2b620853bad11589df0db276de1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QFeN3Atg2NmpVf5py1ExWw.png"/></div></div></figure><p id="ddf6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">图像中的绿色阴影表示2级。可以使用训练数据中提供的编码像素来绘制这些缺陷，正如我们可以注意到的，这些缺陷类似于1级缺陷，并且在它们之间进行分类有些困难。</p><h2 id="4340" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">三级缺陷</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mh"><img src="../Images/4d62c1426630489ff204a57a6c196be1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ff7d6pHN-yGhYPgp_ZzPGA.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mi"><img src="../Images/8f1952ba907f4cc1465931929523d225.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v2A49qrqXi-bekBcVUgq5g.png"/></div></div></figure><p id="3ebc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">图像中蓝色、黄色的像素表示3级图像。我们可以观察到，与1、2级图像相比，3级图像在缺陷方面更差。</p><h2 id="4fb3" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">四级缺陷</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mj"><img src="../Images/b7398fc628f43701e760a70920713704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bYw0qD7zo8Yhzu9uBahkLQ.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mk"><img src="../Images/ca334da806fe0dbdfb51594a7ac0965c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pF4bhYNymO3UJU-BqNqZ9A.png"/></div></div></figure><p id="1b2c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">图像中以青色表示的像素描述了第4类。我们可以看到，这些第4类图像是受损最严重的图像。我们最终得出结论，类别1、2是相似的且缺陷较少，而类别3、4不太相似但缺陷较多，因此对它们进行分类是容易的。</p><h1 id="c48d" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">使用二元和多标签分类的分割模型</h1><p id="0fc9" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">正如我提到的，我使用pipeline-4作为我的策略，让我们详细查看一下！</p><h2 id="a1c4" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">二元和多标签分类</h2><p id="4364" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated"><strong class="jq hj">列车-Cv分离:</strong></p><p id="9293" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们的数据不是时间序列数据，所以我们可以将数据随机分成train-Cv。通过阅读kaggle讨论和其他笔记本，我发现训练数据与提供的测试数据不相似。因此，建议至少进行数据扩充。这样做我们不能完全解决问题，只能部分解决问题。下面是使用keras数据生成器生成和扩充数据的代码。</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="69dc" class="li km hi mm b fi mq mr l ms mt"><em class="kk">#</em><a class="ae jn" rel="noopener" href="/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c"><em class="kk">reference </em></a></span><span id="dc9b" class="li km hi mm b fi mu mr l ms mt">columns =['class1','class2','class3','class4']<br/><br/>mtr_df, mval_df = train_test_split( mc, random_state=42, test_size=0.1825)<br/>print('train_data shape:',mtr_df.shape,'val_data:',mval_df.shape)<br/><br/>datagen=ImageDataGenerator(rescale=1./255.,<br/>                           shear_range=0.1,<br/>                           zoom_range=0.1,<br/>                           brightness_range=[0.6,1.0],<br/>                           rotation_range=60,<br/>                           horizontal_flip=True,<br/>                           vertical_flip=True<br/>                           )<br/><em class="kk">#test_datagen=ImageDataGenerator(rescale=1./255.)</em><br/><br/>train_gen=datagen.flow_from_dataframe(<br/>dataframe=mtr_df,<br/>directory=dir1+"./train_images",<br/>x_col="imageid",<br/>y_col=columns,<br/>batch_size=16,<br/>seed=42,<br/>shuffle=False,<br/>class_mode="other",<br/>target_size=(299,299))<br/><br/>val_gen=datagen.flow_from_dataframe(<br/>dataframe=mval_df,<br/>directory=dir1+"./train_images",<br/>x_col="imageid",<br/>y_col=columns,<br/>batch_size=16,<br/>seed=42,<br/>shuffle=False,<br/>class_mode="other",<br/>target_size=(299,299))</span></pre><p id="c487" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">二元和多标签分类模型</strong></p><p id="ff68" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于这两个模型，我使用keras的预训练InceptionResNetV2()模型和从image-net数据训练的权重。</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="48fa" class="li km hi mm b fi mq mr l ms mt">model = InceptionResNetV2(weights=None, input_shape=(299,299,3), include_top=False)<br/>model.load_weights('/kaggle/input/inceptionresnetv2/inception_resent_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')<br/>model.trainable=False<br/><br/>x=model.output<br/>x=GlobalAveragePooling2D()(x)<br/>x=Dense(128,activation='relu')(x)<br/>x=Dense(64,activation='relu')(x) <br/>out=Dense(1,activation='sigmoid')(x) <em class="kk">#final layer binary classifier</em><br/><br/>model_binary=Model(inputs=model.input,outputs=out) </span></pre><p id="1953" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">类似的<strong class="jq hj">多标签分类</strong>模型除了输出层也以同样的方式加载，因此它是一个四标签分类器，即<strong class="jq hj"> out=Dense(4，activation =‘sigmoid’)(X)</strong></p><p id="11ce" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在对生成器进行几个时期的训练后，我们得到了模型的良好性能</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mv"><img src="../Images/071c61274eb1f55221e721239552d537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GVXjhtLU4xa_BDbVBf9zbQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">二元模型性能</strong></figcaption></figure><p id="7277" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如我们可以看到的，在17个时期结束时，out <strong class="jq hj">二元模型</strong>获得了90的准确率和96的召回率，这意味着out二元模型做得很好:)。</p><p id="c616" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们看看我们的<strong class="jq hj">多标签分类器</strong>工作得有多好。我一次展示两个模型，因为我们使用了相同的预训练模型，这样我们就可以使用公共代码而不重复。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mw"><img src="../Images/aa89c4c4fbe044f277b5ee3fa7b3fa51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EKrKG0897uLRxIUujsLVxA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">多标签分类</strong></figcaption></figure><p id="72a3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们的多标签模型也有很好的性能，它有95的准确率。</p><p id="b9db" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">绩效衡量模型:</strong></p><p id="d5e3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们为什么要用精准和召回？</p><p id="c61c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">召回</strong>实际计算我们的模型通过将它标记为阳性(真阳性)而捕获了多少实际阳性，并且<strong class="jq hj">召回</strong>应该是当存在与假阴性相关联的高成本时的模型度量。在我们的例子中,<strong class="jq hj">假阴性</strong>是将有缺陷的图像分类为无缺陷的，所以对我们来说，我们不能允许我们的模型产生假阴性是有意义的，因为这可以完全放弃将图像发送给进一步的模型。</p><p id="184d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于<strong class="jq hj">多标签分类</strong>，我们同时使用了精度和召回率，因为在进行多标签或多类别分类时，建议同时使用这两个指标。</p><p id="f7ab" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因为我们已经保存了我们的模型以备将来使用，并且它有keras中默认没有的指标，所以它必须通过以下方式加载</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="e08a" class="li km hi mm b fi mq mr l ms mt">#For multi label classification, precision and recall</span><span id="9830" class="li km hi mm b fi mu mr l ms mt">model_mul=load_model('/kaggle/input/multicaugg/multic_aug.h5',<br/>                     custom_objects="recall":recall,<br/>                     "precision":precision}<br/>)</span><span id="fa4d" class="li km hi mm b fi mu mr l ms mt">#use only recall for binary classification</span></pre><h2 id="59f1" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">测试时间增加</h2><p id="0f42" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">为了更好的模型性能，我们使用了测试时间增加，这提高了我们的模型性能。我们已经将TTA用于二元和多标签分类。我将提供一个简单的TTA代码片段，你可以了解更多关于TTA <a class="ae jn" href="https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d" rel="noopener" target="_blank">在这里</a>。</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="301b" class="li km hi mm b fi mq mr l ms mt"><em class="kk">#TTA</em><br/>tta_steps = 10<br/>multi_class= []<br/>for val <strong class="mm hj">in</strong> tqdm_notebook(test_gen_mul):<br/>    <br/>    batch_pred = []<br/>    for i <strong class="mm hj">in</strong> range(tta_steps):<br/>        preds = model_mul.predict_generator(augmentation_gen.flow(val,batch_size=bs, shuffle=False),steps=1)<br/>        batch_pred.append(preds)<br/><br/>    pred = np.mean(batch_pred, axis=0)<br/>    multi_class.append(pred)</span></pre><h1 id="af39" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">分割模型(掩模预测)</h1><h2 id="0504" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">数据加载</h2><p id="92ea" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">有必要使用其他类型的生成器，而不是keras generatot，因为我们必须将编码的像素(data_y)输入到我们的生成器中进行训练，这是使用keras图像生成器无法实现的。这可以通过使用斯坦福edu定制的数据生成器来完成。</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="5d80" class="li km hi mm b fi mq mr l ms mt">class <strong class="mm hj">DataGenerator</strong>(keras.utils.Sequence):<br/>    'Generates data for Keras'<br/>    def __init__(self, list_IDs, df, target_df=None, mode='fit',<br/>                 base_path='../input/severstal-steel-defect-detection/train_images',<br/>                 batch_size=16, dim=(128, 800),preprocess=None, n_channels=3,<br/>                 n_classes=1, random_state=2019, shuffle=False):<br/>        self.dim = dim<br/>        self.batch_size = batch_size<br/>        self.df = df<br/>        self.mode = mode<br/>        self.preprocess = preprocess<br/>        self.base_path = base_path<br/>        self.target_df = target_df<br/>        self.list_IDs = list_IDs<br/>        self.n_channels = n_channels<br/>        self.n_classes = n_classes<br/>        self.shuffle = shuffle<br/>        self.random_state = random_state<br/>        self.on_epoch_end()<br/>    <br/><br/>    def __len__(self):<br/>        'Denotes the number of batches per epoch'<br/>        return int(np.floor(len(self.list_IDs) / self.batch_size))<br/><br/>    def __getitem__(self, index):<br/>        'Generate one batch of data'<br/>        <em class="kk"># Generate indexes of the batch</em><br/>        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]<br/>        <em class="kk">#print(indexes)</em><br/>        <em class="kk"># Find list of IDs</em><br/>        list_IDs_batch = [self.list_IDs[k] for k <strong class="mm hj">in</strong> indexes]<br/>        <br/>        X = self.__generate_X(list_IDs_batch)<br/>        <br/>            <br/>        if self.mode == 'fit':<br/>            y = self.__generate_y(list_IDs_batch)<br/>            return X, y<br/>        <br/>        elif self.mode == 'predict':<br/>            return X<br/><br/>        else:<br/>            raise <strong class="mm hj">AttributeError</strong>('The mode parameter should be set to "fit" or "predict".')<br/>        <br/>    def on_epoch_end(self):<br/>        'Updates indexes after each epoch'<br/>        self.indexes = np.arange(len(self.list_IDs))<br/>        if self.shuffle == True:<br/>            np.random.seed(self.random_state)<br/>            np.random.shuffle(self.indexes)<br/>    <br/>    def __generate_X(self, list_IDs_batch):<br/>        'Generates data containing batch_size samples'<br/>        <em class="kk"># Initialization</em><br/>        X = np.empty((self.batch_size, *self.dim, self.n_channels))<br/>        <br/>        <em class="kk"># Generate data</em><br/>        for i, ID <strong class="mm hj">in</strong> enumerate(list_IDs_batch):<br/>            <em class="kk">#print(i,ID)</em><br/>            im_name = self.df['imageid'][ID]<br/>            img_path = f"<strong class="mm hj">{self.base_path}</strong>/<strong class="mm hj">{im_name}</strong>"<br/>            img = self.__load_rgb(img_path)<br/>            <em class="kk">#print(im_name,img_path)</em><br/>            <em class="kk"># Store samples</em><br/>            img = cv2.resize(img,(800,128))<br/>            X[i,] = img <br/>            <em class="kk">#print(" X sahpe",X.shape)</em><br/>            <em class="kk">#print(" img sahpe",img.shape)</em><br/>            <em class="kk"># normalize </em><br/>            <em class="kk">#X = X / 255</em><br/>        if self.preprocess!=None: X = self.preprocess(X)<br/><br/>        return X<br/>    <br/>    def __generate_y(self, list_IDs_batch):<br/>        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)<br/>        <br/>        for i, ID <strong class="mm hj">in</strong> enumerate(list_IDs_batch):<br/>            im_name = self.df['imageid'][ID]<br/>            <em class="kk">#image_df = self.target_df[self.target_df['imageid'] == im_name]</em><br/>            <br/>            rles = self.df['EncodedPixels'][ID]<br/>            h,w=self.dim<br/>            masks = rle_to_mask(rles, 256,1600)<br/>            masks = cv2.resize(masks,(800,128))<br/><br/>            <em class="kk">#print(" y sahpe",y.shape)</em><br/>            <em class="kk">#print(" masks sahpe",masks.shape)</em><br/>            y[i, ] = np.expand_dims(masks, -1)<br/>            y = (y &gt; 0).astype(int)<br/>        return y <br/><br/>        <br/>    <br/>    def __load_rgb(self, img_path):<br/>        img = cv2.imread(img_path)<br/>        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)<br/>        img = img.astype(np.float32) / 255.<br/><br/>        return img<br/>    <br/>    def __load_grayscale(self, img_path):<br/>        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)<br/>        img = img.astype(np.float32) / 255.<br/>        img = np.expand_dims(img, axis=-1)<br/><br/>        return img</span></pre><h2 id="0086" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated"><strong class="ak"> RLE(行程长度编码器)</strong></h2><p id="9757" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">为了预测有缺陷的像素区域，我们需要把它们转换成RLE区域。kaggle这样做是为了减少提交文件的大小。我将提供代码片段这样做，你可以参考<a class="ae jn" href="https://www.kaggle.com/c/severstal-steel-defect-detection/overview/evaluation" rel="noopener ugc nofollow" target="_blank"> <em class="kk">这里</em> </a>更多关于如何转换像素到RLE的细节。</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="8c93" class="li km hi mm b fi mq mr l ms mt">def mask_to_rle(mask):<br/>    <em class="kk">'''</em><br/><em class="kk">    Convert a mask into RLE</em><br/><em class="kk">    </em><br/><em class="kk">    Parameters: </em><br/><em class="kk">    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background</em><br/><br/><em class="kk">    Returns: </em><br/><em class="kk">    sring: run length encoding </em><br/><em class="kk">    '''</em><br/>    pixels= mask.T.flatten()<br/>    pixels = np.concatenate([[0], pixels, [0]])<br/>    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1<br/>    runs[1::2] -= runs[::2]<br/>    return ' '.join(str(x) for x <strong class="mm hj">in</strong> runs)</span></pre><p id="4b21" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">此外，我们需要将RLE提供的训练数据转换为掩码，以适应训练数据，因此我们做如下</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="1fcb" class="li km hi mm b fi mq mr l ms mt">def rle_to_mask(rle_string, height, width):<br/>    <br/>    rows, cols = height, width<br/>    img = np.zeros(rows * cols, dtype=np.uint8)<br/>    if len(str(rle_string)) &gt; 1:<br/>        rle_numbers = [int(numstring) for numstring <strong class="mm hj">in</strong> rle_string.split(' ')]<br/>        rle_pairs = np.array(rle_numbers).reshape(-1, 2)<br/>        for index, length <strong class="mm hj">in</strong> rle_pairs:<br/>            index -= 1<br/>            img[index:index+length] = 255<br/>    else: img = np.zeros(cols*rows)<br/>    img = img.reshape(cols, rows)<br/>    img = img.T<br/>    return img</span></pre><h2 id="fe8a" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated"><strong class="ak">分割模型</strong></h2><p id="d338" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">来自先前模型的输出(有缺陷的图像)将是分割模型的输入。分割模型对于预测区域是非常有用的，分割模型给了我们很好的结果，GitHub知识库中有很多精彩的预先训练好的分割模型。我用的一个来自quvbel，他在keras和pytorch都发布了模型。你需要做的就是输入<code class="du mx my mz mm b">pip install segmentation-models</code>，然后导入。</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="e388" class="li km hi mm b fi mq mr l ms mt">from segmentation_models import Unet<br/>model = Unet('resnet34')</span></pre><p id="27ff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">开始训练</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="c672" class="li km hi mm b fi mq mr l ms mt">model.compile()<br/>model.fit(X,y)</span></pre><p id="c252" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">培训模式</strong></p><p id="f2fc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们将建立四个分割模型来分别训练四个缺陷类别，以便我们可以将每个缺陷图像(它是多标签的输出)传递给相应的分割模型来预测缺陷区域的位置。</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="9f05" class="li km hi mm b fi mq mr l ms mt">#For class-1 defective images<br/>pred_c1 = Unet('resnet50', input_shape=(128, 800, 3), classes=1, activation='sigmoid')<br/>pred_c1.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])<br/><em class="kk">#pred_c1.summary()</em></span><span id="7b49" class="li km hi mm b fi mu mr l ms mt">history = pred_c1.fit_generator(<br/>    trainc1,<br/>    validation_data=valc1,<br/>    use_multiprocessing=False,<br/>    workers=1,<br/>    epochs=25 )</span></pre><p id="c26c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">类似地，对于班级2、3、4，我们已经建立并训练了类似的模型，并且保存了这些模型以供将来使用。让我们看看训练数据性能结果。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es na"><img src="../Images/36b77284d906ff9b95020a1ec3b2a7cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wQcpXgKN75OThIm-Z8QlFQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">有缺陷的1级列车结果</strong></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nb"><img src="../Images/62da541626e4d3e0d73ea9e48e44b581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*krUpbe6A7aWQU0nzDTsibw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">有缺陷的二级列车结果</strong></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nc"><img src="../Images/7b63055f7bdce43bc95f67f94e5c5013.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UyyE_J2dnFuRHyOP7GXs1w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">有缺陷的3级列车结果</strong></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/fab01a52f111e99e69641aa499876d0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uTJR4lCEiknhSKj6FeXAwA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">有缺陷的4级列车结果</strong></figcaption></figure><p id="cb89" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如我们已经讨论过的，并且可以从train-Cv结果中观察到，类1，2具有低dice-coef，而类3，4具有良好的dice_coef，因为类3，4具有更多的边和大的缺陷。</p><h2 id="82fa" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">骰子系数</h2><p id="fcda" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">Dice系数可用于比较预测的分割与其对应的基本事实之间的逐像素一致性。该公式由下式给出:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="3ea3" class="li km hi mm b fi mq mr l ms mt"><a class="ae jn" href="https://www.kaggle.com/c/severstal-steel-defect-detection/overview/evaluation" rel="noopener ugc nofollow" target="_blank">#reference</a></span><span id="b81b" class="li km hi mm b fi mu mr l ms mt">2 ∗(|X∩Y|) / (|X|+|Y|)</span></pre><p id="df78" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">其中X是预测的像素组，Y是地面实况。当X和Y都为空时，Dice系数定义为1。排行榜分数是测试集中每对<code class="du mx my mz mm b">&lt;ImageId, ClassId&gt;</code>骰子系数的平均值。</p><h1 id="642b" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">结果</h1><p id="5f78" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">让我们看一下一些随机掩码预测结果。</p><p id="189d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">一级</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ne"><img src="../Images/1804ec128e56c8fa84c562b01bed9918.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*oHuCtK3v5CAx1_zp2KT3yw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">有缺陷的一级Cv结果</strong></figcaption></figure><p id="4736" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">二级</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nf"><img src="../Images/ac9a3b3801c0f0015ddc3e5568e708ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*cThH_ZLgMUXFiKHlwBRYnw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">有缺陷的二级Cv结果</strong></figcaption></figure><p id="7bc2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">三级</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ng"><img src="../Images/1bb3bd10be503a4e09d048740ba84cf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*5OIuHVVmjmXtPPwWn4TGHA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">三级缺陷Cv结果</strong></figcaption></figure><p id="38dd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">四级</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nf"><img src="../Images/fafb03951b166b557ccc2c4b19eeee77.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*sZQBbNxL01Hm0Ex1V-RAVw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd kn">有缺陷的四级Cv结果</strong></figcaption></figure><p id="36ef" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这些结果表明，我们的模型性能良好</p><h1 id="4d1e" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">进一步的范围</h1><p id="8306" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">到目前为止，我们取得了不错的结果，但仍有一些改进模型的空间:</p><ul class=""><li id="a394" class="nh ni hi jq b jr js ju jv jx nj kb nk kf nl kj nm nn no np bi translated">由于训练测试数据之间的相似性较小，我们可以使用对抗性验证来提高性能。</li><li id="ad34" class="nh ni hi jq b jr nq ju nr jx ns kb nt kf nu kj nm nn no np bi translated">您还可以使用其他数据扩充技术进行训练和测试扩充。</li><li id="9059" class="nh ni hi jq b jr nq ju nr jx ns kb nt kf nu kj nm nn no np bi translated">你可以用更好的流水线，可能比这个性能更好。</li></ul><h1 id="20f2" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">参考</h1><ol class=""><li id="297c" class="nh ni hi jq b jr ld ju le jx nv kb nw kf nx kj ny nn no np bi translated"><a class="ae jn" href="https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"><em class="kk">https://Stanford . edu/~ sher vine/blog/keras-how-to-generate-data-on-the-fly</em></strong></a></li><li id="66c5" class="nh ni hi jq b jr nq ju nr jx ns kb nt kf nu kj ny nn no np bi translated"><a class="ae jn" href="https://github.com/qubvel" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"><em class="kk">https://github.com/qubvel</em></strong></a></li><li id="ffda" class="nh ni hi jq b jr nq ju nr jx ns kb nt kf nu kj ny nn no np bi translated"><a class="ae jn" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"><em class="kk">https://www.appliedaicourse.com/</em></strong></a></li><li id="f613" class="nh ni hi jq b jr nq ju nr jx ns kb nt kf nu kj ny nn no np bi translated"><a class="ae jn" href="https://www.kaggle.com/c/severstal-steel-defect-detection" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"><em class="kk">https://kaggle.com/c/severstal-steel-defect-detection</em></strong></a></li></ol><h1 id="6968" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak">联系人</strong></h1><p id="f9d3" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated"><strong class="jq hj">领英:</strong><a class="ae jn" href="https://www.linkedin.com/in/sai-krishna-reddy-1bbb56169/" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj"><em class="kk">https://www.linkedin.com/in/sai-krishna-reddy-1bbb56169/</em></strong></a></p></div></div>    
</body>
</html>