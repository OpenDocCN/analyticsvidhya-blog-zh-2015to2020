<html>
<head>
<title>Introduction to FaceNet: A Unified Embedding for Face Recognition and Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">FaceNet简介:用于人脸识别和聚类的统一嵌入</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-facenet-a-unified-embedding-for-face-recognition-and-clustering-dbdac8e6f02?source=collection_archive---------0-----------------------#2019-07-26">https://medium.com/analytics-vidhya/introduction-to-facenet-a-unified-embedding-for-face-recognition-and-clustering-dbdac8e6f02?source=collection_archive---------0-----------------------#2019-07-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="da4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">FaceNet研究论文插图</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/8a8d1e9624c065edf24b6e5ea91efc4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*doxFVXgG6Wviqjp86On9wQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来源:Fortinet</figcaption></figure><p id="5743" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">面部识别是深度学习最令人兴奋的应用之一。近年来，面部识别系统的采用率显著上升；然而，它最近受到了大量的审查。有各种各样的人工智能爱好者认为，任何类型的面部识别系统的使用都应该得到适当的监管，以防止邪恶的活动。</p><p id="9d2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据泄露、隐私侵犯等威胁。起源于不小心使用面部识别系统是相当真实的，因此应该采取适当的措施来避免它们，但即使在最近所有的批评之后，你不得不承认它仍然是一个非常有用的应用程序，可以广泛用于使人们的生活变得更好。</p><p id="6a88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">FaceNet提供了一个独特的架构，用于执行人脸识别、验证和聚类等任务。它使用深度卷积网络以及三重损耗来实现最先进的精度。</p><p id="7c19" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我将解释FaceNet研究论文中使用的概念。我把这篇文章分成了以下几个部分</p><ul class=""><li id="ef7b" class="jt ju hi ih b ii ij im in iq jv iu jw iy jx jc jy jz ka kb bi translated">介绍</li><li id="0d00" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">三重态损失和选择</li><li id="f411" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">深度学习基础(SGD、AdaGrad和ReLU)</li><li id="8f3d" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">CNN架构</li><li id="9202" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">估价</li></ul><p id="968f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">先决条件</strong> —对CNN的基本了解。</p></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="da45" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">介绍</h1><p id="2f24" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">FaceNet为人脸识别、验证和聚类任务提供了统一的嵌入。它将每个人脸图像映射到欧几里德空间，使得该空间中的距离对应于人脸相似性，即，与数据集中存在的任何其他人的图像相比，人A的图像将被放置得更靠近人A的所有其他图像。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lr"><img src="../Images/dd64f1e44e0cb90c4e307901fef04935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PaxDM5QUt8ZzUgCo2dzf4w.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图1:三连败:形象学分——<a class="ae ls" href="https://mc.ai/face-recognition-using-one-shot-learning/" rel="noopener ugc nofollow" target="_blank">MC . ai</a></figcaption></figure><p id="0d6d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">FaceNet与其他技术的主要区别在于，它从图像中学习映射并创建嵌入，而不是使用任何瓶颈层来执行识别或验证任务。一旦嵌入被创建，所有其他的任务，如验证，识别等。可以使用该特定领域的标准技术，使用这些新生成的嵌入作为特征向量来执行。例如，我们可以通过使用嵌入作为特征向量来使用k-NN进行人脸识别，类似地，我们可以使用任何聚类技术来将人脸聚类在一起，并且为了验证，我们只需要定义一个阈值。</p><blockquote class="lt"><p id="6cef" class="lu lv hi bd lw lx ly lz ma mb mc jc dx translated">因此，这里要注意的最重要的事情是，FaceNet没有定义任何新的算法来执行上述任务，而是创建了嵌入，可以直接用于人脸识别、验证和聚类。</p></blockquote><p id="2463" class="pw-post-body-paragraph if ig hi ih b ii md ik il im me io ip iq mf is it iu mg iw ix iy mh ja jb jc hb bi translated">FaceNet使用深度卷积神经网络(CNN)。训练网络，使得嵌入之间的平方L2距离对应于人脸相似性。用于训练的图像被缩放、变换并在脸部区域周围被紧密裁剪。</p><p id="1c70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">FaceNet的另一个重要方面是它的损失函数。它使用三重损失函数(参见图1)。为了计算三重损失，我们需要3个图像，即锚、正和负。我们将在下一节详细探讨三重态损失。</p></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="d81d" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">三重态损失和选择</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mi"><img src="../Images/ca37ef5127cf045593821963d2b1cdfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*IZEsEztCsy8ibdUaZ-7CRw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图2:三重态损失</figcaption></figure><p id="b9c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">三元组损失函数背后的直觉是，与负面图像(所有其他图像)相比，我们希望我们的锚图像(特定人A的图像)更接近正面图像(人A的所有图像)。</p><p id="f376" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">换句话说，我们可以说，我们希望我们的锚图像的嵌入和我们的正图像的嵌入之间的距离小于我们的锚图像的嵌入和我们的负图像的嵌入之间的距离。</p><p id="54ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">三重态损失函数可以正式定义为—</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mj"><img src="../Images/4443a235135afa3b370e784af7eedbb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*QnscpwgGTlznX_rTyRdKcQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图3:三重态损耗公式</figcaption></figure><p id="91ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你不明白这个公式，不要太担心，我会解释每一个术语。只要记住公式背后的直觉，那么记住它就会变得非常容易。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mk"><img src="../Images/3d34a92de0710db20a609a428d4b4188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*xeyhNFIjzWL73yvd2qC9ew.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图4:三重损耗项</figcaption></figure><p id="d5de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，上标a、p和n分别对应于锚定图像、正图像和负图像。</p><p id="eeb7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">α在这里被定义为正对和负对之间的余量。它本质上是一个阈值，决定了我们的图像对之间的差异。如果我们假设alpha设置为0.5，那么我们希望锚正和锚负图像对之间的差异至少为0.5。</p><h2 id="e6b1" class="ml kp hi bd kq mm mn mo ku mp mq mr ky iq ms mt lc iu mu mv lg iy mw mx lk my bi translated">三联体选择</h2><p id="53e6" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">选择正确的图像对是非常重要的，因为会有很多图像对满足这个条件，因此我们的模型不会从它们那里学到很多东西，并且会因此而收敛缓慢。</p><p id="ec7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了确保快速收敛，选择违反三元组约束的三元组是至关重要的。</p><p id="7f0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们本质上想要选择以下的——</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mk"><img src="../Images/8bf62dbe0e1db88f1791aa90fb4dc7fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*armBzkqmmYqPGJP0eFH0eg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图5:硬阳性和硬阴性</figcaption></figure><p id="0aec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果上面的等式不清楚，那我来澄清一下。</p><p id="2f71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">等式(1)意味着给定人A的锚图像，我们想要找到A的正图像，使得这两个图像之间的距离最大。</p><p id="c4ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">等式(2)意味着给定人A的锚图像，我们想要找到负图像，使得这两个图像之间的距离最小。</p><p id="2265" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们在这里只选择了<strong class="ih hj">硬阳性</strong>和<strong class="ih hj">硬阴性</strong>。当我们的模型学习有用的表示时，这种方法帮助我们加速收敛。但是这种方法有一个问题，在整个数据集上计算硬阳性和硬阴性在计算上是不可行的。</p><p id="4b0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里一个聪明的变通方法是计算小批量的硬阳性和阴性。这里，我们将选择大约1000–2000个样本(在大多数实验中，批量大约为1800)。</p><blockquote class="lt"><p id="d8f7" class="lu lv hi bd lw lx ly lz ma mb mc jc dx translated">为了有一个锚正距离的有意义的表示，我们必须确保在每个小批量中有任何一个身份的最小数量的样本。我们将选择每个身份每小批约40张脸。此外，随机取样的反面被添加到每个小批量中。</p></blockquote></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="2798" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">深度学习基础</h1><p id="f60b" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">FaceNet使用带有标准反向投影的<strong class="ih hj">随机梯度下降</strong> (SGD)和<strong class="ih hj"> AdaGrad </strong>来训练CNN。初始学习率为0.05，α设置为0.2，选择<strong class="ih hj"> ReLU </strong>为<strong class="ih hj"> </strong>作为激活函数。</p><p id="1a22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我知道我在这里抛出了很多术语，这可能会让这个领域的新手却步，所以，我将尝试简要解释所有上述概念。</p><h2 id="4112" class="ml kp hi bd kq mm mn mo ku mp mq mr ky iq ms mt lc iu mu mv lg iy mw mx lk my bi translated">随机梯度下降—</h2><p id="24c6" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">这是一种优化技术，用于优化我们的损失函数。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mz"><img src="../Images/53d7d0fab96f0c6ae98219d17a2184f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5NldlsgUU8QQJvJVkU4FuA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图6:新加坡元:图像信用-数据科学. stackexchange</figcaption></figure><p id="6a03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">两个轴(x和y)代表重量，第三个轴(z)代表相对于这两个重量的损失。</p><p id="d7e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们把这个红点称为点a，我们将从这个点a开始我们的旅程，SGD背后的直觉是，我们希望以这样一种方式穿越这个类似小山的结构，以达到全局最小值(这个小山的最低点)。现在你可能已经理解了SGD的<strong class="ih hj">下降</strong>部分。所以现在我们把重点放在<strong class="ih hj">渐变</strong>部分。</p><p id="1e0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Gradient只是给了我们n维平面上<strong class="ih hj">最陡上升</strong>的方向(类似于导数，决定了一条线的斜率)。</p><blockquote class="lt"><p id="d0ce" class="lu lv hi bd lw lx ly lz ma mb mc jc dx translated">这里要注意的关键是，它给出了最陡上升的方向，而不是下降的方向，所以，我们取这个梯度给定值的负值，以便向山下移动。</p></blockquote><h2 id="83fb" class="ml kp hi bd kq mm na mo ku mp nb mr ky iq nc mt lc iu nd mv lg iy ne mx lk my bi translated">阿达格拉德</h2><p id="6b10" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">AdaGrad用于生成可变学习率。固定的学习速率在深度学习中效果不佳。在每层用于检测不同特征(边缘、图案等)的CNN的情况下。)，固定的学习是行不通的，因为我们网络中的不同层需要不同的学习速率来优化工作。为了更好地理解AdaGrad，让我们看几个方程。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nf"><img src="../Images/c66e9eaebdbf3ef060075178ede8d634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*crUu9dkcj9bF92e4zw1_aQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图7:阿达格拉德</figcaption></figure><p id="cbe3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你在看了这么多数学之后还在读这篇文章，那么我想你一定很好奇。所以让我通过分解和解释来帮助你们更好地理解这些方程。</p><p id="033b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">等式(1) —它只是SGD的常规权重更新等式。这里我们使用一个固定的学习率(η)。</p><p id="bb25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">等式(2) —它是AdaGrad的权重更新等式。在这种情况下，我们使用可变学习率(η't)。</p><p id="8da5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">等式(3) —它决定了计算可变学习率的公式。</p><p id="653b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">等式(4) —它决定了计算t-1的公式。</p><p id="2b46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">t-1只是直到t-1的梯度的平方和。“t”是迭代次数。因此，我们只需计算每一步的梯度，并将它们的平方相加，生成t-1，由于t-1会随着每次迭代而变化，因此我们的学习速率也会变化。</p><h2 id="474f" class="ml kp hi bd kq mm mn mo ku mp mq mr ky iq ms mt lc iu mu mv lg iy mw mx lk my bi translated">热卢</h2><p id="df3d" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">ReLU是我们正在使用的非线性激活函数。在深入研究ReLU的细节之前，让我们了解一下为什么我们需要非线性激活函数？我们需要它们，就好像我们只使用线性激活函数，那么本质上我们的输出将只是我们输入的线性组合，而不管我们网络的层数。</p><p id="0374" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一个要考虑的点是，没有非线性激活函数，我们不能创建可以解决复杂问题的神经网络，即如果我们使用线性激活函数，我们的决策边界将总是线性的。</p><p id="cfe2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，希望你现在相信我们确实需要非线性激活函数。那么现在让我们了解一下ReLU的基础知识。</p><p id="a0b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ReLU是sigmoid和tanh激活函数的继承者。我不会在这里详细介绍这些函数，但我会简要解释sigmoid和tanh中导致ReLU发现的问题。因此，sigmoid和tanh的大问题是<strong class="ih hj">消失梯度</strong>，即它们都输出0和1之间的值，并且在使用反向传播计算梯度时(参考等式(1))，我们必须乘以0和1之间的各种值。在几次迭代之后，这个值可能变得如此之小和不重要，以至于我们的权重将停止更新。这两种方法的另一个问题是它们的计算成本都很高，也就是说，我们必须计算指数和tan等函数，这些函数的计算成本很高。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ng"><img src="../Images/9da59753a921fe961048b9dd6649f0c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aIgTWE1223EGTqmi8lYBlA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图8: ReLU激活功能:图像信用— <a class="ae ls" href="https://sebastianraschka.com/faq/docs/relu-derivative.html" rel="noopener ugc nofollow" target="_blank">塞巴斯蒂安·拉什卡</a></figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nh"><img src="../Images/7eaa720b371d8b688ccb891e9a830b6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/1*I0uTErN5gF7iZ9Dwr2u9rQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图9 : ReLU公式:图像学分— <a class="ae ls" href="https://sebastianraschka.com/faq/docs/relu-derivative.html" rel="noopener ugc nofollow" target="_blank">塞巴斯蒂安·拉什卡</a></figcaption></figure><p id="7656" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们可以看到，我们的值既不在0和1之间，也不需要计算任何昂贵的函数。所以ReLU解决了这两个问题。</p></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="f6d4" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">CNN架构</h1><p id="7821" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">FaceNet使用两种类型的CNN，即泽勒&amp;弗格斯架构和谷歌网络风格的初始模型。</p><p id="459d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将在这里简单解释一下。</p><h2 id="0ba1" class="ml kp hi bd kq mm mn mo ku mp mq mr ky iq ms mt lc iu mu mv lg iy mw mx lk my bi translated">1.泽勒&amp;弗格斯建筑公司</h2><p id="b457" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">泽勒&amp;弗格斯建筑被用来形象化CNN的训练过程。我们试图借助这种架构来理解CNN的内部运作。这种架构引入了一种新颖的可视化技术，可以洞察中间层的功能和分类器的操作。</p><p id="b98f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里就不多赘述了。我建议你阅读泽勒的弗格斯建筑研究论文。</p><p id="634e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">FaceNet研究论文中使用的泽勒&amp;弗格斯架构如下所示。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ni"><img src="../Images/d4057710708a5de6652674da3ab18758.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*9lsMHeHKdQveuFpwXNkpVA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图10:泽勒&amp;弗格斯建筑</figcaption></figure><p id="7fe3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个模型有1.4亿个参数，每个图像有16亿次FLOPS(每秒浮点运算)。</p><h2 id="b0ce" class="ml kp hi bd kq mm mn mo ku mp mq mr ky iq ms mt lc iu mu mv lg iy mw mx lk my bi translated">2.初始模型</h2><p id="07f9" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">初始网络架构背后的主要思想是同时使用多个不同大小的过滤器。在任何其他传统网络架构中，我们通常选择大小为3*3、5*5等的过滤器，但在Inception架构中，我们同时使用多个过滤器并将它们的结果连接起来。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nj"><img src="../Images/5ca6402a028dde6fac510a632b315cf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mZBAm9W8gDzDYbNwhKwSLA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图11:初始网络</figcaption></figure><p id="288b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在图11 (a)中，我们使用了大小为1*1、3*3和5*5的多个过滤器以及一个最大池层，然后我们将结果连接起来。这是盗梦空间网络架构背后的主要直觉。这种方法的问题是计算量非常大。因此，为了避免这个问题，我们使用1*1卷积进行降维。</p><p id="1cbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在图11 (b)中，我们将每隔一个卷积使用一个1*1滤波器，以降低维数并使该架构在计算上可行。</p><p id="384f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想更详细地理解这个架构，那么我强烈建议你阅读<a class="ae ls" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">的《盗梦空间》研究论文</a>。</p><p id="82c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">FaceNet研究论文中使用的这种初始模型架构具有6.6M-7.5M的参数和大约500m-1.6 B的FLOPS。在FaceNet中使用了各种不同的初始模型，其中一些被优化为在手机上运行，因此具有相对较少的参数和过滤器。</p></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="d59c" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">估价</h1><p id="ecce" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">我们计算真实接受值(TA)如下—</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nk"><img src="../Images/c769071fea9c831aa27123288c01cb59.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*mYjBvNKwNGToygIdrHRWFw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">false接受</figcaption></figure><p id="5fac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">真接受是在阈值‘d’处被正确地<strong class="ih hj">分类为<em class="nl">相同</em>的人脸对。</strong></p><p id="3732" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将错误接受(FA)定义如下—</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nk"><img src="../Images/c2f38f4a83c682b17c53ad1c66ce3b92.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*u0R8f28Zl67PNIHhN1r41g.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">错误接受</figcaption></figure><p id="aad1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">错误接受是被<strong class="ih hj">错误地</strong>分类为<em class="nl">相同的</em>的人脸对</p><pre class="je jf jg jh fd nm nn no np aw nq bi"><span id="facb" class="ml kp hi nn b fi nr ns l nt nu">P same - It represents the pair of same identities  <br/>P diff - It represents the pair of different identities<br/>D(xi,xj) -  It is the square L2 distance between the pair of images<br/>d - It is the distance threshold</span></pre><p id="659f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">给定人脸距离“d”的验证率(VAL)和错误接受率(FAR)定义为</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nk"><img src="../Images/aaed09bd0e9937dd749e702b67935eb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*WMVC74oafuSKsVTpm_QtPA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">验证率和错误接受率</figcaption></figure><h1 id="f503" class="ko kp hi bd kq kr nv kt ku kv nw kx ky kz nx lb lc ld ny lf lg lh nz lj lk ll bi translated">参考</h1><ul class=""><li id="ea3d" class="jt ju hi ih b ii lm im ln iq oa iu ob iy oc jc jy jz ka kb bi translated">盗梦空间模型—<a class="ae ls" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1409.4842</a></li><li id="f784" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">https://arxiv.org/abs/1311.2901泽勒&amp;弗格斯建筑公司<a class="ae ls" href="https://arxiv.org/abs/1311.2901" rel="noopener ugc nofollow" target="_blank"/></li><li id="db82" class="jt ju hi ih b ii kc im kd iq ke iu kf iy kg jc jy jz ka kb bi translated">FaceNet—<a class="ae ls" href="https://arxiv.org/abs/1503.03832" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1503.03832</a></li></ul></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><p id="2f2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就把我们带到了本文的结尾。如果你愿意，你可以鼓掌。它是免费的。</p><p id="7865" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我的<a class="ae ls" href="https://www.linkedin.com/in/dhairya-kumar/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae ls" href="https://twitter.com/DhairyaKumar16" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae ls" href="https://github.com/Dhairya10" rel="noopener ugc nofollow" target="_blank"> Github </a>。<br/>你可以查看我的<a class="ae ls" href="https://alpha-dev.in/" rel="noopener ugc nofollow" target="_blank">网站</a>来了解更多关于我和我的工作。</p></div></div>    
</body>
</html>